{"title": "HistoKernel: Whole Slide Image Level Maximum Mean Discrepancy Kernels for Pan-Cancer Predictive Modelling", "authors": ["Piotr Keller", "Muhammad Dawood", "Brinder Singh Chohan", "Fayyaz ul Amir Afsar Minhas"], "abstract": "Machine learning in computational pathology (CPath) often aggregates patch-\nlevel predictions from multi-gigapixel Whole Slide Images (WSIs) to generate\nWSI-level prediction scores for crucial tasks such as survival prediction and drug\neffect prediction. However, current methods do not explicitly characterize distri-\nbutional differences between patch sets within WSIs. We introduce HistoKernel,\na novel Maximum Mean Discrepancy (MMD) kernel that measures distributional\nsimilarity between WSIs for enhanced prediction performance on downstream\nprediction tasks.\nOur comprehensive analysis demonstrates HistoKernel's effectiveness across var-\nious machine learning tasks, including retrieval (n = 9,362), drug sensitivity\nregression (n = 551), point mutation classification (n = 3,419), and survival anal-\nsis (n = 2,291), outperforming existing deep learning methods. Additionally, His-\ntoKernel seamlessly integrates multi-modal data and offers a novel perturbation-\nbased method for patch-level explainability. This work pioneers the use of\nkernel-based methods for WSI-level predictive modeling, opening new avenues\nfor research. Code is available at https://github.com/pkeller00/HistoKernel.", "sections": [{"title": "1 Introduction", "content": "Advances in Computational Pathology (CPath) have demonstrated that machine\nlearning can effectively utilize Whole Slide Images (WSIs) to address various clinically\nrelevant problems [1, 2]. Due to their large size and high memory demands, WSIs are\ndivided into smaller patches for model training using weakly supervised approaches\nto perform patch-level predictions. These are then aggregated into a single slide-level\nprediction. The development of patch-level foundation models has further increased\nthe need for efficient aggregation techniques [3].\nThree main branches of aggregation techniques have emerged [4]. Heuristic meth-\nods generate predictions for each patch independently and aggregate them using\nfixed statistics, such as majority voting [5, 6]. These methods assume equal contribu-\ntion from all patches, which fails to capture complex relationships and dependencies,\nand can lead to sensitivity to outliers and the overshadowing of significant patches\nif they are in the minority. Clinically driven aggregations use domain-specific rules,\nlike calculating overall WSI tumor cell percentage based on patch-level counts [4].\nWhile interpretable, they require established clinical rules, limiting their appli-\ncability. Data-driven methods, including attention mechanisms and graph neural\nnetworks (GNNs) [7], can weigh patches based on relevance and context, but their\nlearned parameters are task-specific, making them less generalizable without extensive\nretraining, and are computationally intensive.\nCrucially, existing aggregation approaches cannot explicitly quantify the differ-\nences or similarities in the multi-variable distributions of patches in two WSIs, limiting\ntheir effectiveness. This gap is addressed by our novel WSI-level Maximum Mean Dis-\ncrepancy (MMD) kernels. These kernels act as statistical tests to determine if two\nWSIs, modeled as sets of patches, are drawn from different distributions by comparing\ninfinite statistical moments [8]. This capability allows us to define pairwise simi-\nlarity between WSIs, facilitating numerous downstream tasks such as visualization,\nclustering, regression, classification, and survival analysis [9, 10]."}, {"title": "2 Results", "content": "At its core, the proposed approach allows calculation of the degree of similarity\nbetween two WSIs in the form of a kernel function (henceforth called HistoKernel)\nbased on patche feature embeddings. These patch-level feature embeddings can be\nobtained from any pre-trained embedding or foundation model (See Methods: 4.3 and\nFig 1 part (a)). Intuitively, if the kernel score between two WSIs is high then, with\nhigh probability, patches in these WSIs come from the same underlying distribution.\nConversely, if the kernel score between two WSIs is small then that implies there is a\nsubstantial difference between the statistical distributions of patches comprising the\ntwo WSIs. This provides a principled way for identifying relationships between WSIs"}, {"title": "2.1 Visualization and Clustering", "content": "Fig 1 (b) shows HistoKernel for the entire TCGA dataset comprising more than 74\nmillion pairs of WSIs. The degree of similarity between any two WSIs is expressed\nas a single number leading to the interpretation of the kernel matrix as an affinity\nmatrix that can be used for hierarchical clustering or two-dimensional visualization\nthrough UMAP (see Fig 1 (b) and (c)). These visualizations clearly show WSIs of\nthe same cancer type are clustered closer to each other in comparison to those from\nother types. Thus, HistoKernel is able to capture meaningful similarities between\nWSIs based on cancer type despite the fact that no cancer type labels or any other\ntype of target labels are used in kernel computation. The kernel matrix visualization\nprovides useful insights into similarities and differences in WSIs of different cancer\ntypes which typical patch-based approaches cannot do. For example, the UMAP plot\nshows some cancer types are very distinguishable such as brain and prostate whilst\nothers are more closely clustered such as liver and endocrine tumours. It also allows\nfor identification of cancer sub-populations such as the two predominant sub-clusters\nin endocrine tumours. Investigating the reasons for these patterns can help broaden\nour understanding of cancer. Dataset visualization can also be used for identifying\npotential noise or outliers, allowing interactive quality control in a CPath pipeline."}, {"title": "2.2 Whole Slide Image Retrieval", "content": "We utalise HistoKernel for WSI retrieval. Here, we are interested in retrieving the top\nk most similar WSIs for a given query image, $X_q$. Effective retrieval can be used to\naid in clinical diagnosis for new patients based on diagnosis of similar patients. It may\nalso help train new histopathologists by showing them similar images with the same\ndiagnosis to help identify common histology patterns such as gland shape often used\nfor prostate cancer grading [12].\nTo perform WSI retrieval we directly query HistoKernel matrix to find the\nmost similar images (see Methods: 4.8). We compared performance of the proposed\napproach with current State of the art (SOTA), RetCCL, under the same validation\nprotocol [13].\nTable 1 shows the majority vote at the top five search results (mMV@5) achieved\nby HistoKernel and SOTA [13] for each cancer sub-type. The mMV@5 measures the\npercentage of samples in test set for which the majority cancer sub-type in the top - k\nretrieved samples is the same as the query image. We see HistoKernel consistently out-\nperformed RetCCL, 12% higher mMV@5 macro-average across all sub-types. Further,\nHistoKernel's results are statistically significantly higher than comparative method\n(Wilcoxon paired signed rank test found p < 0.01). Thus, overall we can be confident\nHistoKernel has significantly outperformed the SOTA for WSI retrieval."}, {"title": "2.3 Regressing Cancer Drug Sensitivities", "content": "Next, we demonstrate HistoKernel's capability for regression tasks by predicting can-\ncer drug sensitivity from WSIs. We want to predict if a patient will respond to a\ndrug using only a WSI. The target drug sensitivity values are inferred as real num-\nbers by aligning patients gene expression profile with cell line expression profile for\nwhich drug sensitivity values of drugs exist [14]. This is an important task as drug\nsensitivities can be used to optimise a patient's treatment, many studies supporting\nthis approach [15]. Predicting drug sensitivities just from images is particularly inter-\nesting as histopathological assessment is considered routine and may be more readily\navailable than genetic molecular tests which have high costs.\nWe can utilise the pre-computed HistoKernel to train a Support Vector Regressor\n(SVR) to perform predictions. We compare performance of HistoKernel with the exist-\ning SOTA approach in this domain by Dawood et al.'s SlideGraph under the same\nevaluation protocol [16] with spearman rank correlation between true and predicted\nsensitivities for each drug as a performance metric.\nFig 2 part (a) shows the comparison between Spearman correlation coefficient\n(SCC) of predicted sensitivity for HistoKernel (y-axis) and the comparative method (x-\naxis) [16] for each compound. HistoKernel outperformed comparative method in terms\nof SCC for 94% of compounds clearly showing its superiority. HistoKernel's results\nare statistically significantly higher than comparative method (Wilcoxon paired signed\nrank test found p < 0.01) indicating a genuine increase in performance that was not a\nresult of chance. Finally, in Supplementary Figure 1 we see HistoKernel produced 1.5\ntimes as many statistically significant predictors (p-value < 1e-3) compared to com-\nparative method indicating greater reliability of HistoKernel. Fig 2 part (b) shows the\ndistribution of HistoKernel's top 10 models which can have numerous advantages for\npatients treatment success. For example, Vincristine (SCC=0.65\u00b10.05) and Paclitaxel\n(SCC=0.69 \u00b1 0.06) are not effective for all patients [17]. Consequently, HistoKer-\nnel provides a potential mechanism for early identification of patients for alternative\ntherapies leading to improved treatment efficacy and minimising side effects [18]."}, {"title": "2.4 Classification of Point Mutations", "content": "To illustrate the efficacy of HistoKernel for slide-level classification problems, we per-\nform point mutation classification. Point mutations are genetic mutations that involve\na change in a single nucleotide base within the DNA or RNA sequence [19]. Numerous\nstudies reported associations between various genetic mutations and tumour progres-\nsion and therapeutic response, highlighting the tasks importance [20]. WSI-based\npoint mutation predictors can act as alternatives to genetic test leading to reduced\nturnaround times and costs [21].\nHistoKernel was used as a precomputed kernel to train a Support Vector Machine\n(SVM) to perform gene point mutation classification. We compared performance of the\nproposed approach with the current SOTA under the same validation protocol [22].\nComparison results in Fig 3 part (a) show the number of genetic point mutations\nfor a given cancer type that were predicted with high, moderate or weak confidence"}, {"title": "2.5 Survival Analysis", "content": "Thirdly, we use HistoKernel for survival analysis. Here we use WSIs to predict the\nexpected time until a clinically important event occurs, for example, disease progres-\nsion or death, given other patients survival data. Accurate survival predictions can\nbe used by pathologists to make data-driven decisions about best treatment course,\nimproving overall patient care. Using WSI-based deep learning we can reduce human"}, {"title": "2.6 Multi-Modal Integration with Kernels", "content": "Finally, we show the ease of integrating multiple data modalities with HistoKernel. As\na proof of concept, we demonstrate results for multi-modal survival analysis in BRCA.\nHere we want to combine information from different data sources such as histological\nimage data and transcriptomics in order to capture complementary information about\npatient survival.\nWe build on Multiple Kernel learning to combine the pre-computed HistoKernel\nwith a kernel based on patient transcriptomic profiles or topics (see methods: 4.11) [30].\nWe can then utilise this combined kernel as a precomputed kernel for a KSSVM (as\nexplained in Results: 2.5). Specifically, we use additive and multiplicative combinations\nof kernels from the two modalities.\nFigure 5 (a) shows the results of survival prediction in terms of C-index for BRCA\nfor two multi-modal kernels. We see that both multi-modal kernels perform better\nthan their single-modal counterparts. A clear increase in C-index as well as a smaller\nstandard deviation clearly shows a multi-modal approach better captures patters asso-\nciated with survival whilst being more robust. Part (c) and (d) support this idea\nas Kaplan-Meier curves produced for both multi-modal kernels show a clear sepa-\nration between high and low risk patients. Further analysis of the best performing\n$K_{TOPIC} + K_{WSI}$ kernel shows that unsupervised hierarchical clustering of the kernel\n(b) finds clear clusters forming with respect to BRCA subtypes. For example, basal-\nlike breast cancer forms a clear cluster and is known to be associated with worse\nprognosis [31]. These results show the ease with which imaging and transcriptomic\ndata can be integrated."}, {"title": "2.7 Time Complexity", "content": "For kernel computation we computed similarity between 12,186 WSIs, resulting in\n74,243,205 WSI pairs. Calculating a single pairwise computation varies depending on\nnumber of patches but on average took 4 miliseconds. Thus, for all pairs the distance\nmatrix computation requires 3.4 days on single GPU. This can be accelerated with\nparallelisation and by preloading WSI feature vectors into the GPUs."}, {"title": "3 Discussion", "content": "We presented a novel MMD-based kernel approach that quantifies similarity between\nWSIs. By computing MMD between WSIs represented as sets of patch-level features\nwe generate a single kernel for entire dataset where the similarity between any two\ngiven WSIs is expressed by a single number. This kernel is only computed once for the\nentire dataset, after which it can be used for a variety of downstream tasks. Avoiding\nlong retraining times per task makes HistoKernel very fast and flexible. Nevertheless,\nHistoKernel captures meaningful information as it is comparable to SOTA approaches\nfor numerous fundamental tasks. To strengthen this claim, our perturbation-based\npatch-level explainer found logical patterns in HistoKernel's predictions, highlighting\nthe potential for clinical applications.\nFirstly, we visualised HistoKernel. Fig 1 part (a) shows that numerous cancers like\nbrain form clear clusters, supporting the idea that HistoKernel is finding patterns in\ndata. This clustering is not perfect potentially due to tumour heterogeneity. Fig 1 part\n(b) further support idea of cancers clustering. Interestingly, both clustering methods\ncoincide with the cancer types that are most distinguishable. It may be beneficial\nto study underlying reasons for this. It seems HistoKernel is capturing meaningful\npatterns in the data. It is unlikely HistoKernel is picking up stain variations or pos-\nsible artefacts as these have been accounted for during feature extraction and tissue\nsegmentation. However, other confounding variables may exist.\nWe investigated WSI retrieval where HistoKernel significantly outperformed SOTA\nfor majority of sites\u00b9, 12% higher macro-average. A strong retrieval method is useful\nfor diagnosis of new patients, based on similarity with patients with existing diagno-\nsis. Further, retrieval can be used to discover new patterns, for example identifying\ngenetic patterns in patients who have high image-based similarity. Overall, HistoKer-\nnel has outperformed SOTA for retrieval without any processing of the kernel. This\nstrengthens the argument that HistoKernel has found meaningful patterns.\nNext, we looked at the regression task of predicting drug sensitivities. HistoKernel\nsignificantly outperformed SOTA, achieving higher SCC for 94% of compounds. For\nVincristine and Paclitaxel HistoKernel achieved highest SCC. Knowledge of patient"}, {"title": "4 Methods", "content": "For all the experiments we used WSIs of Formalin-Fixed paraffin-Embedded (FFPE)\nHematoxylin and Eosin (H&E) stained tissue section from The Cancer Genome Atlas\n(TCGA) [32]. After excluding WSIs having missing baseline resolution information in\ntotal we end up with 12,186 WSIs belonging to 9,374 patients. We used data of 32\ncaner sub-types spanning across 25 anatomic sites.\nTo obtain the target labels of patients point mutation status we downloaded muta-\ntion data of patients in 6-cancer types (endometrial, breast, lung adenocarcinoma, lung\nsquamous cell carcinoma and glioblastoma) from cBioportal [33]. Inline with previous\nwork we curated cancer-related genes with at least 25 mutations of known significance\nwith a matching WSI [22]. However, unlike previous work we relabelled TCGA brain\nsamples to obtain a new glioblastoma sub-population based on modern classification\nstandards [34] (2021 fifth edition WHO). This edition incorporated molecular features\ninto the diagnostic decision tree for brain tumours thus causing a major change in the\nclassification of samples. These reclassified labels for the TCGA were obtained from\nZakharova et al. [35]. Due to this relabelling and after excluding WSIs with missing\nbaseline resolution from analysis we obtained 76 analysable genes in six cancer types.\nFor cancer drug sensitivity prediction to be consistent with comparative method,\nwe used data of 1,098 patients with breast invasive carcinoma from TCGA (TCGA-\nBRCA). For these patients we acquired their estimated sensitivity to 427 experimental\nand FDA-approved compounds from a previously published work that has used\ngenomic and drug response data of Cancer Cell Lines (CCL) data [36] to infer these\nnumbers. Based on these labels the comparative method restricted the analysis to\npatients with gene expression-based imputed sensitivity scores for all compounds to\nget a total of 551 patients for analysis. The labels were also normalised using z-score\nnormalisation to account for the different ranges of the drug scores.\nFor survival analysis, we restricted our analysis to kidney renal clear cell carci-\nnoma (n=504), uterine corpus endometrial carcinoma (n=504), astrocytoma (n=219),\nglioblastoma (n=266), bladder urothelial carcinoma (n=372) and lung adenocarci-\nnoma (n=426). To obtain labels for astrocytoma and glioblastoma we relabelled the"}, {"title": "4.2 Pre-processing of WSIs", "content": "For each WSI we first identify its viable tissue regions by using a U-Net-based tissue\nsegmentation model from the TIAToolbox [11]. This ensures any artefacts such as pen\nmarkings or tissue folds as well as background regions are removed. This generates\na mask for each image with a score of one for tissue area and zero otherwise. Since\nWSIs at full resolution can be very large (150,000 \u00d7 150, 000 pixels) and cannot fit into\nGPU memory, we apply the previously generated masks and then tile each WSI into\npatches of size 1024 \u00d7 1024 at a spatial resolution of 0.50 micrometers-per-pixel (MPP).\nPatches capturing less than 40% of informative tissue area (mean pixel intensity above\n200) are discarded, and the rest of the patches are used, both tumour and non-tumour\npatches. For each patch pj in a WSI J, we obtain its d = 2048-dimensional feature\nrepresentation x \u2208 $R^d$ by passing it through a convolutional neural network (CNN)\nencoder. Any feature extractor can be used to encode patch-level features however we\nused the RetCCL model [13]."}, {"title": "4.3 Maximum Mean Discrepancy Kernels", "content": "We are interested in defining a (dis)similarity metric between two arbitrary WSIs\n$X_I$ and $X_J$. To do this we will instead try to solve the analogous problem of defin-\ning a distance metric which can then easily be converted to a similarity metric via a\ntransformation (See Equation 5). We first require that this distance metric is valid,\nit should satisfy the non-negativity, identity, symmetry, and triangle inequality pro-\nprieties [39]. On top of this, since we are working with WSIs we need the distance\nmetric to be independent of the orientation or shape of tissue, work with arbitrary\nfeature representations, and it should be able to compare WSIs with different num-\nbers of patches. To capture these additional properties we model each WSI as a set\nof patches since by definition sets are unordered and can have different sizes thus any\nmetrics defined will implicitly be forced to include these assumptions. More specifi-\ncally, $X_I = {x_1, x_2,...,x_{N_I}}$ where $X_I$ is a WSI such that $N_I$ is the number of patches\nin the image and $x_m$ represents the mth patches feature embedding in image $X_I$."}, {"title": "4.4 Computation of Maximum Mean Discrepancy Kernels", "content": "In line with our previous work, we used the GPU-based GeomLoss library to efficiently\ncompute MMD between WSIs [43]. In this paper, we use a Gaussian kernel thus to\nreduce computation the standard deviation for the kernel is set to $\\sigma = 10$. By paral-\nlelising the matrix computation the MMD-dissimilarity matrix for the entire TCGA\n(12, 186 \u00d7 12, 186 dimensional matrix) took around 2 days to compute with paralleli-\nsation. It is important to note this computation was only done once and then the\nrelevant subsections of this kernel were utilised for each task mentioned in Section 2."}, {"title": "4.5 Explainability of Maximum Mean Discrepancy Kernels", "content": "Since MMD generates a slide-level kernel any models trained with the precomputed\nkernel are intrinsically unable to generate patch-level predictions since patch-level\ninformation has already been condensed during the computation of moments. Thus, it\nwas previously impossible to see which patches were most important for HistoKernel.\nExplainability is vital in CPath to ensure pathologists can make informed decisions\nabout any models they use as well as to ensure the safety, approval, and acceptance\nof such models in a clinical setting [44]. To overcome this limitation, we developed\na model-agnostic patch sensitivity metric that tells us how sensitive our predictor\nis with respect to a certain patch. This method takes inspiration from the field of\nperturbation-based instance explainability which perturb inputs of a given sample to\nobserve the effects of these perturbations on the model's output [45, 46]. Traditionally,\nperturbations are applied to the features of a particular instance and any change in"}, {"title": "4.6 Kernel Visualisation", "content": "To perform kernel visualisation we first carried out Uniform Manifold Approximation\nand Projection for Dimension Reduction (UMAP). This works by constructing a high-\ndimensional graph representation of the data and then optimising a low-dimensional\ngraph to be as structurally similar as possible [48]. Since the current implementation\nof UMAP accepts a precomputed square distance matrix we can simply pass in the\nHistoKernel matrix as input. The two main hyper-parameters of the model are the\nminimum distance between embedded points, $d_{min} = 0.0$, and the size of the local\nneighbourhood, $S_{local} = 100$ (see the documentation for more details [48]). Secondly,\nwe generated a heatmap of the distance matrix. This is done by first converting the\ndistance matrix to a similarity kernel, $K_{MMD}$, with $\\gamma$ set to the median of the flattened\ndistance matrix. This standardises all the values between zero and one. Then to get"}, {"title": "4.7 Drug Sensitivity Prediction", "content": "In order to predict drug sensitivity we made use of support Vector Regression (SVR)\nwith our precomputed kernel. SVRs work similarly to traditional SVMs however the\ntwo major differences are that they predict scalar values instead of a binary label and\nuse epsilon-insensitive loss for the loss function. This loss function introduces a new\nhyper-parameter that is not present in traditional SVMs, $\\epsilon$, which sets errors that are\nwithin $\\epsilon$ distance of the true value to zero. For this experiment, we trained an SVR\nfor each chemical compound separately resulting in 427 models.\nIn line with the comparison study, for evaluation we made use of 5-fold cross-\nvalidation where we reserve 10% of the training data as a validation set for\nhyper-parameter optimisation. The metric used for evaluation was Spearman's rank\ncorrelation coefficient (SCC) between the ground truth and predicted values. The p-\nvalue associated with each SCC was also computed. A Wilcoxon paired signed rank\ntest was also calculated between HistoKernel and the comparative method results [49].\nThis test is used to establish if two groups of samples are statistically significantly\ndifferent from one another. A one-sided test was carried out to see if the distribution\n$d=R_{MMD}- R_B$, where $R_{MMD}$ and $R_B$ are the results of HistoKernel and compara-\ntive method respectively, is stochastically greater than a distribution symmetric about\nzero. This test was chosen as the Shapiro-Wilk test for normality revealed that both\nthe comparative method and HistoKernel results do not follow a normal distribution\n(p < 0.01) [50]."}, {"title": "4.8 Whole Slide Image Retrieval", "content": "In this task for a query WSI, $X_Q$, given that we know the site of origin of $X_Q$ we aim to\nretrieve the top k most \"similar\" WSIs. In the comparative method paper, similarity\nis defined as images from the same cancer sub-type. For example, if $X_Q$ originates\nfrom the brain and is of sub-type brain lower grade glioma (LGG) a database of WSIs\noriginating from the brain is searched and the algorithm is considered successful if it\nreturns images of the same sub-type (in this case LGG). To remain fair we will utilise\nthe same definition.\nTo perform Whole Slide Image Retrieval we directly query the precomputed kernel.\nThus to retrieve the top-k most similar WSIs for an arbitrary query image $X_Q$ using\nMMD kernels we first generate a similarity kernel of the entire dataset $K_{MMD} =$\n$e^{-\\gamma D_{MMD}}$. Here $\\gamma$ is set to the median of the flattened distance matrix. Then we select\nthe $q^{th}$ row of the matrix, $K_{q*}^{MMD}$. Since $K_{q*}$ captures the similarity between $X_Q$ and\nevery other image in the dataset we just need to sort the row in descending order of\nsimilarity to find out which images are most similar to the query. We will also need\nto exclude the entry from the this sorted row which corresponds to similarity between\n$X_Q$ with itself since the similarity kernel includes the entire dataset and an image will"}, {"title": "4.9 Point Mutation Prediction", "content": "To predict point mutations we made use of kernelized binary SVMs. Inline with the\ncomparative method we trained a separate model (SVM) for each of the 76 genes.\nFor performance evaluation, we used 4-fold cross-validation with 40% of the train-\ning data used as a validation set for hyperparameter tuning (both kernel $\\gamma$, see\nSection 4.3, and SVM regularisation parameter) [51]. The model's performance was\nmeasured by using Area Under the Receiver Operating Characteristic curve (AUC-\nROC). In Figure 3 part (a) predcitons are binned based on AUC-ROC into weak\n(AUC-ROC < 0.6), moderate (AUC-ROC 0.6 to 0.7) and strong (AUC-ROC 0.7 to\n1.0) predictors. In Fig 3 part (b) we filtered out genes where both comparative method\nand HistoKernel achieved an AUC-ROC less than 0.6, leaving 34 genes. This is because\ncomparing genes for which both predictors are weak is meaningless."}, {"title": "4.10 Survival Analysis", "content": "In order to perform survival analysis we utilised kernelized survival SVMs (KSSVM)\nwith our precomputed kernel. These predict a risk score $f(X_I)$ for a given patient, I,\nafter training a model over a training dataset in the form of $\\{(X_I, T_I, \\delta_I)|I =$\n1... $N_{train}\\}$. Each patient is modelled as a tuple comprised of a patient's WSI $X_I$,\ntheir disease-specific survival time $T_I$ and a binary event indicator variable $\\delta_I \\in {0,1}$\nwhich shows if the patient has passed away from the recorded cancer or not within\na censoring time $T_{censor} = 10$ years. The implementation of KSSVM accepts a pre-\ncomputed kernel and has a single hyperparameter a that controls the loss penalty\nterm in its objective function [26]. We chose, a = 0.0625 and $\\gamma$, for the kernel, is set\nto the median of the flattened distance matrix. This is done to reduce the number of\ntunable hyper-parameters as the effect of $\\gamma$ is also modulated by the blur parameter\nof the patch level kernel [52]."}, {"title": "4.11 Multi-Modal Kernels", "content": "To perform multi modal learning we first have to define our kernels. The first kernel is\nour precomputed HistoKernel that captures morphological information, $K_{WSI}$. The\nsecond is a transcriptomic kernel that is computed from gene expression topics defined\nby Dawood et al [38]. In this work, each BRCA patient has been characterised by 200\nbinary variables or topics. The status of each topic variable represents specific gene\nexpression patterns of co-dependent genes. Thus for each patient, $P_I$, we can express\ntheir genetic information as a 200 binary feature vector, $t_{PI}$:\n$t_{P1} = \\begin{bmatrix}\nt_1^{P1}\\\\\n.\\\\\\n.\\\\\\nt_{200}^{P1}\\end{bmatrix}$ (8)\nwhere $t_j^{1} \\in {0,1}$ is the binary status of topic j of patient I. To define a topic kernel\nwe can compute the radial basis function between topic representations of two patients\nas:\n$K_{TOPIC} = e^{-\\frac{||t^{P1}-t^{PJ}||^2}{2\\sigma^2}}$ (9)\nwhere $\\sigma$ is the bandwidth of the RBF kernel function. In this work, for simplicity, we\nset $\\sigma = 10$.\nWe can then utilise the rich theory of Multi Kernel Learning (MKL) in order to\ncombine our set of kernels $K = {K_{TOPIC}, K_{WSI}}$. The simplest type of method to\ncombine kernels is Unweighted Multiple Kernel Methods (UMKL) where we perform a\nspecific arithmetic operation to combine kernels without assigning kernel weights [30].\nThe first operation we use is addition where we define a new kernel $K^{WSI} + K^{TOPI\\acute C}$."}]}