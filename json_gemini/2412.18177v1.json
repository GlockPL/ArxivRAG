{"title": "Enhancing Online Continual Learning with Plug-and-Play State Space Model and Class-Conditional Mixture of Discretization", "authors": ["Sihao Liu", "Yibo Yang", "Xiaojie Li", "David A. Clifton", "Bernard Ghanem"], "abstract": "Online continual learning (OCL) seeks to learn new tasks from data streams that appear only once, while retaining knowledge of previously learned tasks. Most existing methods rely on replay, focusing on enhancing memory retention through regularization or distillation. However, they often overlook the adaptability of the model, limiting the ability to learn generalizable and discriminative features incrementally from online training data. To address this, we introduce a plug-and-play module, S6MOD, which can be integrated into most existing methods and directly improve adaptability. Specifically, S6MOD introduces an extra branch after the backbone, where a mixture of discretization selectively adjusts parameters in a selective state space model, enriching selective scan patterns such that the model can adaptively select the most sensitive discretization method for current dynamics. We further design a class-conditional routing algorithm for dynamic, uncertainty-based adjustment and implement a contrastive discretization loss to optimize it. Extensive experiments combining our module with various models demonstrate that S6MOD significantly enhances model adaptability, leading to substantial performance gains and achieving the state-of-the-art results.", "sections": [{"title": "1. Introduction", "content": "Continual learning (CL) [9, 28, 30, 42] is a task that requires models to continuously and efficiently learn new ability when receiving new data. It tests the model's ability to adapt to dynamically changing environments while retaining existing knowledge. For example, autonomous vehicles are expected to continuously learn new driving environments and traffic regulations, thereby improving detection accuracy under complex driving scenes. From the perspective of task format, CL can be divided into offline and online [9, 42]. Unlike offline CL [6, 32], online CL (OCL) [9, 16] aligns with real-world implementations as it requires data to arrive sequentially in mini-batches and allows only one epoch of training, posing greater challenges for efficient adaptation with data accessible for learning only once.\nTo tackle the challenging OCL, existing studies widely rely on the replay technique [17] that selectively stores a subset of old-class data to strengthen the memory ability of existing knowledge and mitigate catastrophic forgetting. Building on replay, various methods have been proposed with regularization, buffer allocation, and distillation strategies [17, 18, 33, 43, 45, 49]. For example, MIR [3] aims to mitigate mutual interference among tasks through a retrieval strategy, OCM [17] seeks to reduce forgetting by maximizing mutual information between different tasks, and CCLDC [43] adopts collaborative learning and distillation to improve plasticity. However, learning generalizable and discriminative features incrementally from online training data is still intractable, and imprecise features will impede and even mislead the replay strategies [44]. Therefore, inducing accurate and efficient adaptation with limited data access is critically important for OCL and there still remains significant potential for improvement.\nRecently, selective state space models (SSMs), also known as S6 in Mamba [13], have shown promising results in modeling long-range dependencies with computational efficiency. Selective SSMs introduce a selective scan mechanism to make the interactions among sequential states aware of input context, and have been applied to vision tasks by integrating various scan directions [26, 56]. In addition to the success in sequence modeling [8, 25, 34, 48], selective SSMs also exhibit stronger adaptability than static parameters in few-shot class-incremental learning due to the dynamic operation weights, as reported in a recent pioneering work [23]. Despite the increased capacity of adaptation, directly applying selective SSMs to OCL will be infeasible because it is challenging for selective SSMs to capture a precise discretization pattern with limited context from online data that appears only once for training. Moreover, a single discretization mechanism may fail to capture all the essential details in some nonlinear dynamic systems or systems with multi-scale characteristics [1, 15].\nTo this end, we develop a plug-and-play branch based on selective state space model and class-conditional mixture of discretization. The branch with an equiangular tight frame classifier [28, 36, 47, 50, 51, 55] can be integrated on any existing OCL methods to supervise the original classification head and improve the adaptation ability in OCL. Considering multiple discretization methods can exhibit varying sensitivity to the dynamic characteristics of a system, we introduce a mixture of discretization into SSMs to enrich selective scan patterns such that the model can adaptively select the most sensitive discretization method for current dynamics. This flexibility allows our method to comprehensively capture the system's complex dynamic features, particularly in cases of rapid state changes and evolving systems as exemplified by OCL.\nIn order to guide the mixture of discretization for OCL, where a delicate trade-off between maintaining the stability of old knowledge and fostering the plasticity for new ability is needed, we further introduce a class-conditional routing to aggregate the discretization patterns. Concretely, we maintain a feature prototype for each class to calculate the class uncertainty based on the margin among different classes. For classes with less uncertainty, fewer discretization patterns will be aggregated to stabilize the abilities already acquired for these classes, while for classes with large uncertainty, more discretization patterns will be included to allocate additional capacity for adapting to these undeveloped abilities. After aggregation of the mixture of discretization, we employ a contrastive discretization loss that enforces within-class consistency and between-class diversity, contributing to the learning of generalizable and discriminative features after the selective scan. In experiments, we integrate our plug-and-play branch on numerous OCL methods and significant improvements can be consistently observed on multiple datasets.\nOur contributions can be summarized as follows:\n\u2022 To enhance the adaptability of existing methods for OCL, we propose S6MOD, a plug-and-play module based on selective state space model and class-conditional mixture of discretization, which can strengthen the base method.\n\u2022 We further develop a class-conditional gating strategy that dynamically satisfy both objectives of maintaining the stability of knowledge already acquired and fostering the plasticity for undeveloped abilities. A contrastive discretization loss is employed to facilitate the learning of generalizable and discriminative features.\n\u2022 In experiments, our method can be easily integrated on different OCL methods and is compatible with distillation techniques, to consistently achieve significant improvements on multiple datasets including CIFAR-10, CIFAR-100, and Tiny-ImageNet."}, {"title": "2. Related Work", "content": "Continual Learning(CL). CL can be categorized into three types based on the implementation methods [9, 28, 30, 42]: regularization-based, parameter isolation-based, and replay-based. Regularization-based methods [2, 20, 24, 41, 54] introduce regularization terms to restrict changes in model parameters, thereby protecting the already learned knowledge. Parameter isolation-based methods [12, 35, 37, 46, 52] typically assign different model parameters or subnetworks to different tasks to avoid interference between tasks. Replay-based methods [5, 7, 27, 32, 33] perform joint training by either storing a portion of old data or generating pseudo-data. This allows the model to revisit old data while learning new data, thereby reducing forgetting.\nOnline Continual Learning(OCL). OCL is a specialized form of CL designed to test the ability to continuously learn and update as data arrives in real-time streams [9, 16]. This means that OCL can only train for a single epoch and typically process only individual samples or mini batches at a time. Replay-based methods are widely used in OCL [17]. ER [33] introduces the combination of cross-entropy loss with a random buffer. OCM [17] uses mutual information maximization to reduce feature bias and preserve past knowledge. GSA [18] proposes a gradient-based adaptive optimization method to address dynamic training bias. On-Pro [45] uses online prototype equilibrium to address shortcut learning problem. Some methods introduce knowledge distillation based on replay. CCL-DC [43] introduces Collaborative Continual Learning (CCL) and Distillation Chain (DC) to enhance model plasticity. MOSE [49] alleviates forgetting by integrating multi-level supervision and reverse self-distillation. However, these models carry a risk when the features used to distill are not precise. In comparison, our method S6MOD as a plug-and-play module is applicable to most OCL methods to improve the adaptability of these models, enabling them to learn generalizable and discriminative features more efficiently.\nSelective State Space Model (S6) Selective State Space Model (S6) [13] has gained increasing interest as an alternative to self-attention [40] with lower computational complexity. S6 enhances the S4 model [14] by introducing the selective scan mechanism, and its effectiveness in vision tasks has been extensively studied [26, 56]. For example, Vmamba [26] introduces SS2D, a cross-scanning mechanism for images, facilitating the extension of Mamba to process vision data. A recent study Mamba-FSCIL [23] leverages the dynamic weights and sequence modeling capability of Mamba to achieve dynamic adaptation in few-shot class-incremental learning. But their method rely on an effective selective scan learned from training data. In OCL, the online data that appears only once for training provides limited context for Mamba models, and thus poses challenges to capture a precise discretization pattern. Different from these studies, our method integrates S6 with class-conditional mixture of discretization and effectively helps to improve the adaptability for OCL. Some existing works have introduced mixture of experts (MoE) into Mamba [4, 25, 31], following the design of switch-transformer [11]. Our method differs from them in that each expert in our mixture of discretization is only a simple linear layer for computation efficiency, and discretization patterns are aggregated with our class-conditional gating to balance between maintaining stability of old knowledge and allocating capacity for learning new abilities."}, {"title": "3. Preliminaries", "content": ""}, {"title": "3.1. Problem Definition of OCL", "content": "OCL requires a model to continuously update itself from a data stream, with each mini-batch containing new data sampled from a changing distribution Dt. At each time step t, the model receives a mini-batch of data {(x(t), y(t)) } 1\nYiSi=1, where x(t) represents the input data, y(t) represents the corresponding labels, and nt is the number of samples. The goal of OCL is to sequentially update the model to adapt to both gradual and task-specific shifts in the data distribution. Given a pre-trained network fo with parameters 0, the model updates its parameters by solving an optimization problem arg min e L(fe(x), y), where L is the loss function, thereby enabling it to adapt effectively to the evolving data distribution."}, {"title": "3.2. State Space Models", "content": "State Space Models (SSMs) can be viewed as linear time-invariant systems. They map input sequences x(t) \u2208 R to output sequences y(t) \u2208 R through hidden states h(t) \u2208 RN. Mathematically, these models can be represented as linear ordinary differential equations (ODE) :\n$$h'(t) = Ah(t) + Bx(t),$$\n$$y(t) = Ch(t),$$ (1)\nwhere A \u2208 RN\u00d7N represents the state transition matrix, while B \u2208 RN\u00d71 and C \u2208 R1\u00d7N denote the mapping matrices from input to latent state and from latent state to output, respectively, where N indicates the size of the hidden state.\nTo apply the SSM to real discrete data, zero-order hold (ZOH) [14] is employed. It discretizes the continuous parameters A, B, and C using the time scale parameter \u2206. The discretized SSM equations can be rewritten as follows:\n$$ht = Aht-1 + Bxt,$$\n$$Yt = Cht.$$ (2)\nRecently, Gu [13] proposed a new parameterization method for SSM with a selective scan mechanism, which is known as S6 and serves as the core of the Mamba model. To enhance S6's capability in processing visual data, Liu et al. [26] introduced SS2D, which can serialize image data from four different directions. Given the input data x, the output x processed by SS2D can be expressed as follows:\n$$x = SS2D(x) = \\sum_{i=1}^4 S6(scan(x, i)).$$ (3)"}, {"title": "4. Proposed Method", "content": "In this section, we will first introduce the overall structure of our plug-and-play module S6MOD in Sec. 4.1. After that, we will present the detailed design of the state space model with mixture of discretization in Sec. 4.2. Then, we will introduce the class-conditional routing and its corresponding contrastive discretization loss in details in Sec. 4.3. Finally, we will specify the optimization details in Sec. 4.4."}, {"title": "4.1. Overall structure", "content": "To better enhance existing methods' ability in learning generalizable and discriminative features incrementally from online training data, we propose a plug-and-play module named S6MOD that can be easily applied to existing OCL methods, as shown in Fig. 1 (a). Overall, S6MOD strengthens the original method by introducing a plug-and-play branch after the backbone. It consists of a block and a fixed equiangular tight frame (ETF) classifier [50, 51]. The intermediate features F generated by the backbone are duplicated and sent into the classification head of the original base method, and the selective state space model (SSM) branch introduced by our method.\nIn our SSM branch, F is projected into two paths through an MLP. The first one X = fx (F) is used to perform selective scan with our class-conditional mixture of discretization, as will be detailed in later subsections. The other one Z = f(F) performs a gating mechanism as commonly adopted in Mamba models [23, 26, 29]. The output feature of this branch can be formulated as:\n$$\u03bc = SiLU(Z) \u2297 S6MOD(SiLU(Conv(X))).$$ (4)\nTo assist the learning of the base method for generalizable and discriminative features, we adopt a regularization, LDiff, on the predicted distribution of the base method,"}, {"title": "4.2. S6 with Mixture of Discretization", "content": "We integrate the selective space state model with a mixture of discretization, borrowing the concept of mixture of experts [10, 19, 38, 53]. Its structure is shown in Fig. 1 (c). Similar to the typical SSM structure, we also use an MLP layer to produce the projection matrices B and C from the input features, which can be expressed as follows:\n$$B = f_B(X), C = f_C(X),$$ (6)\nwhere X denotes the input of the selective scan module S6MOD, i.e., X = SiLU(Conv(X)). To enable selective SSM to capture a precise discretization pattern with limited context from online data, we develop a sparse MoE system for the discretization transformation A in S6 models, utilizing specialized projection layers to enrich the discretization patterns and adaptively selecting the most sensitive discretization based on the current dynamics. Specifically, each discretization candidate is produced by a projection layer as follows:\n$$Ai = f_{Oi}(X).$$ (7)\nThe input feature X is also fed into a sparse gating mechanism, which produces associated importance weights wi corresponding to each discretization A\u00bf. Through the class-conditional gating that will be introduced in Sec. 4.3, we dynamically control the number of discretization patterns, Nk, to be selected for each class k based on the input features X. Finally, the selected discretization patterns are aggregated with their importance weights as follows:\n$$\u0394 = \\sum_{\\Gamma\\in \\Omega(X)} Wi\u2206i, |\u03a9(X)| = Nk,$$ (8)\nwhere \u03a9(X) is the index set of the top-Nk discretization candidates of X, according to their importance weights.\nIt's noteworthy that \u2206 is important because it controls the decay rate during the state update process, enabling the model to flexibly select and retain important information when handling long sequences, while avoiding the accumulation of redundant and irrelevant information [13], especially in cases of rapid changing states and evolving systems, as exemplified by OCL. Our method with mixture of discretization facilitates the learning of a precise selective scan pattern with limited data context in OCL."}, {"title": "4.3. Class-Conditional Routing", "content": "With more discretization patterns selected, the model is able to allocate more capacity for learning new knowledge, but may cause a significant shift of the model that impairs the existing ability. If we can calculate Nk based on the misclassification probability of each class k, we can dynamically control the capacity of mixture of discretization based on the learning conditions of all classes. Therefore, in order to guide the mixture of discretization to strike a balance between maintaining the stability of old knowledge and fostering the plasticity for new ability, we further design class-conditional routing. During training, we maintain the feature prototypes M = {M} by moving average, where Mc is the within-class feature mean for class c. Then, we estimate the class uncertainty \u03c3k based on the average margin of class k with different classes,\n$$\u03c3\u03ba = Avgc{exp(-\u03bb\u03bf||Mk - Mc||2)},$$ (9)\nwhere do is a hyper-parameter and \u03c3k denotes the class uncertainty for class k ranging from (0,1). A large \u03c3k indicates that the class center k has narrow margins with the other class centers, and thus tends to be misclassified, while a small \u03c3k happens when class center k is distant from the other class centers with a lower likelihood of being misclassified. In inference, we replace Mk with the input feature X and calculate its uncertainty by Eq. (9) with the feature prototypes Me of all classes.\nThen, we multiply the uncertainty by the number of total discretization candidates N, to get the discretization number to select for class k or input feature X as follows,\n$$Nk = ceil(N\u00b7\u03c3\u03ba),$$ (10)\nwhere ceil refers to the operation that rounds up \u039d\u00b7 \u03c3k to the nearest integer.\nThe institution is that classes that are more prone to mis-classification have smaller margins with the other classes in the feature space, and thus needs to aggregate more discretization patterns to allocate additional capacity for adapting to these undeveloped abilities. Conversely, for categories that are easier to classify with low uncertainty, a smaller Nk is favored to only include the most likely discretization patterns, which can spare optimization efforts for the uncertain classes and stabilize these already acquired abilities. The combination of class-conditional routing and our mixture of discretization achieves dynamic structures dependent on input features and classes, such that the final prediction of each class selectively optimizes the corresponding discretization patterns.\nTo further reduce interaction among different classes and facilitate the learning of generalizable and discriminative features, we also incorporate contrastive discretization loss function LCont, as shown in Fig. 1 (d). It encourages \u2206 to have within-class consistency and between-class diversity as follows:\n$$LCont = \\frac{1}{B^2} \\sum_{m=1}^B \\sum_{n=1}^B (1_{ym=yn} - 1_{ym\u2260Yn}) \\frac{\u0394 m . \u0394 n}{||\u0394 m ||.||\u0394 n||},$$ (11)\nwhere B is the batch size, \u2206m represents the aggregated \u2206 by Eq. (8) for input m, Ym denotes the class of m and 1ym=yn is an indicator function that takes a value of 1 when the condition Ym = yn holds, and 0 otherwise."}, {"title": "4.4. Optimization", "content": "In addition to the previously mentioned loss functions in Eqs. (5) and (11), we also directly used the classification loss function LDR specifically designed for ETF classifier [50, 51] to supervise our introduced plug-and-play branch, and the loss function Lz for maintaining load balancing among the discretization patterns [57]. In summary, when integrating S6MOD on a base method, the overall loss function can be expressed as follows:\n$$Lall = Lbase + LS6MOD,$$\n$$LS6MOD = LDR + \u03b1 LDiff + \u03b2\u00b7 LCont + Lz,$$ (13)\nwhere \u03b1 and \u03b2 are hyperparameters."}, {"title": "5. Experiments", "content": ""}, {"title": "5.1. Experimental Setups", "content": "Datasets. We test three datasets that are widely used in OCL, i.e., CIFAR-10 (10 classes) [21], CIFAR-100 (100 classes) [21] and TinyImageNet (200 classes) [22]. The dataset settings we adopted are the same as those in CCLDC[45]. We divide CIFAR-10 into 5 tasks, with 2 classes per task; CIFAR-100 into 10 tasks, with 10 classes per task; and TinyImageNet into 100 tasks, with 2 classes per task. Further details about the datasets will be provided in the supplementary materials."}, {"title": "5.2. Results", "content": "We combine our method with both classical and state-of-the-art approaches on CIFAR-10, CIFAR-100, and Tiny-ImageNet. The experimental results in Table 1 demonstrate the universality of our method, as it consistently improves accuracy across numerous baselines. On CIFAR-10 and CIFAR-100, our method generally leads to a 1% improvement, while on Tiny-ImageNet, we achieve significant gains under OCM, OnPro and MOE-MOSE. Notably, in settings like CIFAR100 (M = 2k) and Tiny-ImageNet (M = 5k), OnPro result in an approximate 4.2% and 4.5% improvement, respectively. It is also worth mentioning that even for state-of-the-art distillation-based methods"}, {"title": "5.3. Ablation Studies", "content": "As mentioned in Sec. 1, the S6MOD module we propose is very simple and can be directly applied to existing baselines. By adding an extra branch and using the LDiff to supervise the original classification head, we can achieve a significant improvement. To demonstrate this, we conduct an ablation study where we only add the extra branch and LDiff to the baseline. The results in Table 3 confirm this, showing a 3.3% improvement with supervision from the extra branch alone.\nIn addition, to verify the effectiveness and adaptability of class-conditional routing and contrastive discretization loss LCont, we conduct separate ablation experiments. As shown in Table 3, when added to the base method with the extra branch, the improvements brought by adding class-conditional routing or LCont alone are not significant, with accuracy gains of only 0.31% and 0.32%, respectively. However, when both components are used together, the improvement becomes significant, with an approximate 1% increase in accuracy, and the forgetting rate still decreases. This indicates that when our module is correctly combined, it can significantly enhances the model's adaptability by learning more generalizable and discriminative"}, {"title": "5.4. Analysis", "content": "Analysis of Feature Embeddings. To verify that S6MOD improves the adaptability of the baseline and helps it learn more discriminative features, we use t-SNE [39] visualization for analysis. We compare with the baseline under the CIFAR-100 (M = 2k) setting. As shown in Fig. 2, we visualize the features of the samples in the buffer after the final training, which are the features F output by the backbone just before they are passed to the classifier for classification. The features shown in Fig. 2 (a) and (c) are very scattered, with only a few classes showing some degree of aggregation. Most classes do not have clear separations between other classes, making it difficult to distinguish. In contrast, Fig. 2 (b) and (d) present the feature distribution after adding our module. We can observe that many categories have noticeably converged, forming small clusters with consistent intra-class compactness and clear inter-class separations. These features are much easier to distinguish and more conducive to classification by the classifier, which aligns with the significant improvements we demonstrate in the experiments.\nAnalysis of Class-conditional Routing. We further investigate the effectiveness of class-conditional routing. Under the CIFAR-100 (M = 2k) setting, we design experiments to compare the impact of a fixed Nk and dynamically calculated Nk using class-conditional routing. Specifically, we set Nk = N, meaning all patterns are activated, and Nk = 1, meaning only the pattern with the highest prob-"}, {"title": "6. Conclusion", "content": "In this paper, we propose a plug-and-play module S6MOD to enhance the adaptability of existing OCL methods by introducing selective state space models (SSMs) with a class-conditional mixture of discretization. By integrating a dynamic discretization mechanism and leveraging class-conditional strategies, our method can efficiently allocate discretization patterns based on class uncertainty, improving both the model's generalization and its ability to adapt to new data. Experimental results on multiple OCL datasets demonstrate that our method consistently optimize existing techniques, contributing to more robust OCL systems."}, {"title": "A. Implementation details", "content": ""}, {"title": "A.1. Training details", "content": "In Table 5, we provide the hyper-parameter settings for our method when ER is used as the baseline. As shown in the table, for the same dataset, we tend to set the total number of patterns N to a fixed value and set a and \u03b2 to a ratio of 1:5. When we need to reduce the impact of our module, we can proportionally decrease the weights. Actually, different hyper-parameter settings help to unleash the potential of various classifiers (linear classifier, ETF classifier, NCM classifier). hyper-parameters not mentioned in the table remain consistent with the original baseline."}, {"title": "A.2. Dataset", "content": "As stated in Sec. 5 (Experiments), we primarily conduct experimental validation on three datasets: CIFAR10, CIFAR100, and TinyImageNet. It is important to note that the sample sizes and the number of classes vary across these datasets, which may lead to the use of different hyperparameters in our method. Our experimental implementation follows the guidelines of CCLDC [43]. Specifically:\nCIFAR-10 is a dataset composed of 10 classes, which we divide into 5 tasks, with each task containing 2 classes. It includes a total of 50,000 training samples and 10,000 test samples, with image dimensions of 32\u00d732.\nCIFAR-100 consists of 100 classes, divided into 10 tasks, with each task containing 10 classes. It also contains 50,000 training samples and 10,000 test samples, with image dimensions of 32\u00d732.\nTinyImageNet comprises 200 classes, divided into 100 tasks, with each task containing 2 classes. It includes 100,000 training samples and 10,000 test samples, with image dimensions of 64\u00d764."}, {"title": "A.3. Pseudo-code", "content": "To facilitate understanding and usage of our proposed plug-and-play module, S6MOD, we provide pseudo-code in Algorithm 1 to demonstrate how to integrate S6MOD with the current baseline. For simplicity, we omit the workflows of LDR and Lz, as well as the samples in the memory buffer."}, {"title": "A.4. Metrics", "content": "We use three commonly employed evaluation metrics Average Accuracy (Acc), Average Forgetting (AF) and New-Task Average Accuracy (N-Acc) in the main text [43], and we will introduce their definitions in detail here.\nIn continual learning, after each task t is completed, the model needs to be tested on all previously learned tasks {1,2,..., t}. The Acc is defined as:\n$$\u0410\u0441\u0441\u0442 = \\frac{1}{T} \\sum_{t=1}^T \u0410_{t,T},$$ (14)\nwhere T is the total number of tasks, and Att is the test accuracy on task t after learning task T:\n$$At,T = \\frac{1}{Nt} \\sum_{i=1}^{Nt} \u03b5 1(Yit = Yi,t)$$ (15)\nHere, Nt is the number of samples in task t, \u0177i,t is the predicted class of the i-th sample, and Yi,t is the true class of the i-th sample.\nThe Average Forgetting (AF) is the average of the forgetting rates over all tasks. It provides an overall measure of how much the model forgets across all previously learned tasks as new tasks are added. A low AF indicates that the model effectively retains knowledge from previous tasks, while a high AF suggests that the model suffers from significant forgetting when learning new tasks. AF is defined as:\n$$AF = \\frac{1}{T-1} \\sum_{t=2}^T FRt,$$ (16)\nwhere T is the total number of tasks. FRt is the Forgetting Rate for task t, defined as:\n$$FRt = max_{i\u2208{1,...,t-1}} (Ai,i - Ai,t),$$ (17)\nwhere Ai,i is the accuracy on task i after learning task i, and Ai,t is the accuracy on task i after learning task t. The AF is averaged over all tasks after the first one, as the first task does not cause any forgetting.\nThe New-Task Average Accuracy (N-Acc) is the average accuracy of the model on all tasks when they are first learned. This metric provides an overall measure of how well the model performs on each task at the time it is introduced, without considering any changes in performance as other tasks are learned later. N-Acc is defined as:\n$$N-Acc = \\frac{1}{T} \\sum_{t=1}^T Att$$ (18)\nwhere T is the total number of tasks and At,t is the accuracy on task t immediately after task t is learned, i.e., when the model first encounters the task. This metric directly reflects the model's ability to learn new tasks."}, {"title": "B. Extra Experiments", "content": ""}, {"title": "B.1. Performance with NCM classifier.", "content": "The Nearest Class Mean (NCM) classifier is a simple yet effective classification method, often used as a component in continual learning scenarios. To further demonstrate that our method also learns more generalizable and discriminative features with NCM, we use an NCM classifier to test"}]}