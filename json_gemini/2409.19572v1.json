{"title": "Mitigating the Negative Impact of Over-association for Conversational Query Production", "authors": ["Ante Wang", "Linfeng Song", "Zijun Min", "Ge Xu", "Xiaoli Wang", "Junfeng Yao", "Jinsong Su"], "abstract": "Conversational query generation aims at producing search queries from dialogue histories, which are then used to retrieve relevant knowledge from a search engine to help knowledge-based dialogue systems. Trained to maximize the likelihood of gold queries, previous models suffer from the data hunger issue, and they tend to both drop important concepts from dialogue histories and generate irrelevant concepts at inference time. We attribute these issues to the over-association phenomenon where a large number of gold queries are indirectly related to the dialogue topics, because annotators may unconsciously perform reasoning with their background knowledge when generating these gold queries. We carefully analyze the negative effects of this phenomenon on pretrained Seq2seq query producers and then propose effective instance-level weighting strategies for training to mitigate these issues from multiple perspectives. Experiments on two benchmarks, Wizard-of-Internet and DuSinc, show that our strategies effectively alleviate the negative effects and lead to significant performance gains (2%~5% across automatic metrics and human evaluation). Further analysis shows that our model selects better concepts from dialogue histories and is 10 times more data efficient than the baseline. The code is available at https://github.com/DeepLearnXMU/QG-OverAsso.", "sections": [{"title": "1. Introduction", "content": "Leveraging external knowledge has been proven to be important for dialogue response generation (Dinan, Roller, Shuster, Fan, Auli and Weston, 2018; Zhou, Prabhumoye and Black, 2018; Zhou, Zheng, Huang, Huang and Zhu, 2020; Wang, Li, Zhao and Yu, 2021). Along this line, exploring the Internet for external knowledge is gaining popularity because of its continually updated content and broad coverage on a variety of domains (Komeili, Shuster and Weston, 2022; Zhou, Xu, Wu, Niu, Wu, Bao, Wang and Wang, 2022). To retrieve useful knowledge from the Internet, the task of query production is proposed to assemble search queries from dialogue contexts to effectively interact with search engines. This task is crucial because the quality of generated queries directly affects the relatedness of retrieved knowledge to the current dialogue contexts and user intent.\nThe current efforts consider query production as a typical text-to-text generation task and adopt Transformer (Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser and Polosukhin, 2017) as the backbone to build their query producers. As a common practice, Komeili et al. (2022) adopt a pretrained encoder-decoder model, such as BART (Lewis, Liu, Goyal, Ghazvininejad, Mohamed, Levy, Stoyanov and Zettlemoyer, 2020) or T5 (Raffel, Shazeer, Roberts, Lee, Narang, Matena, Zhou, Li and Liu, 2020), and further finetune the model on a manually annotated query-generation dataset with the standard cross-entropy (CE) loss. Benefited from a better initialization, the query producer can reach promising performance.\nHowever, we find that these query producers (Komeili et al., 2022; Zhou et al., 2022) still suffer from the data hunger issue as they usually require tens of thousands of training instances to reach decent performance. Additionally, they tend to ignore important concepts from dialogue contexts and/or generate irrelevant concepts at inference time. Our analyses show that these issues are related to the prevalent over-association phenomenon in the gold queries of major query generation benchmarks. Particularly, a large number of gold queries"}, {"title": "2. Research Objectives", "content": "In this work, we aim to investigate the over-association phenomenon of conversational query generation task. This phenomenon means that many manually labeled queries in training data are indirectly related to their dialogue contexts. Intuitively, a query producer trained on these instances can be misleading, thus it will drop important concepts or generate irrelevant concepts when inference. Therefore, our research objectives are as follows:\n\u2022 Systematically analyze the negative impacts of the over-association phenomenon. We first define a metric to measure the over-association degree of each query. Then, we examine the behaviors of query producers trained on queries with different over-association degrees.\n\u2022 Propose instance-wise weighting strategies to ease the negative impact of over-association. We explore improv-ing the training objective term to solve this problem by decreasing the influence of search queries with high over-association degrees."}, {"title": "3. Over-association in Conversational Query Production", "content": "In this section, we analyze the negative effects of the over-association phenomenon. We take both T5 and BART as the baselines and evaluate them on two benchmarks in different languages, Wizard-of-Internet (WoI, Komeili et al. 2022) and DuSinc (Zhou et al., 2022). Following Zhou et al. (2022), we report the Summation score (Sum.) of Unigram F\u2081 and BLEU-1/2 as the evaluation metric in this section. We first introduce the baseline model (\u00a73.1), then present our observations (\u00a73.2)."}, {"title": "3.1. Baseline: Pretrained Text-to-text models with the Cross-Entropy Loss", "content": "Formally, taking a concatenated dialogue history H = (h\u2081, ..., h\u2099) of n turns as inputs, the baseline query producer (QP) generates a search query q = (q\u2081, ..., q\u2098) of m tokens. Following previous work (Komeili et al., 2022), the baseline model is initialized from either T5 (Raffel et al., 2020) or BART (Lewis et al., 2020) before being finetuned on the query generation benchmark. As an encoder-decoder model, the baseline model first consumes the concatenated dialogue history with its encoder, and then generates each query token q\u1d62 given the previously generated tokens q_{<i}:\np(q\u1d62 | H, q_{<i}; \u03b8) = QP(H, q_{<i}),\nwhere \u03b8 represents the model parameters. This model is trained by maximizing the probability of the gold query with the standard CE loss:\nL_{CE} = -\\sum_{i=1}^{m} log p(q\u1d62 | H, q_{<i}; \u03b8)."}, {"title": "3.2. Preliminary Study", "content": "To better understand the negative effects of over-association, we first propose a metric to estimate the over-association degree of a query considering its dialogue context. Intuitively, a query suffering over-association usually can not be assembled from the dialogue history (e.g., \u201cthe effect of eating oranges\u201d in Table 1). Therefore, we roughly measure the over-association degree of a query based on the rate of its word-level overlap with corresponding dialogue history:\nd(q) = 1 - \\frac{1}{m} \\sum_{i=1}^{m} 1_H(q_i)\nwhere 1_H(q\u1d62) is an indicator on whether the query word q\u1d62 is contained by the dialogue history H. Thus a higher score (lower word-level overlap) indicates that the query may suffer from a more serious over-association phenomenon. To estimate it more reasonably, we remove the stop words and punctuations from the query and employ Spacy to perform lemmatization for both dialogue history and query in advance. Notice that our defined automatic over-association degree is not completely accurate, but we find that it is highly related to the model performance (Pearson correlation coefficient 40.1% for the over-association degree and Sum. score of model prediction on the WoI development set). Based on the over-association degree, we categorize the training instances into three datasets:\n{\\begin{cases}q \\in \\otimes_1 & d(q) \\le \\frac{1}{3}\\\\q \\in \\otimes_2 & \\frac{1}{3} < d(q) \\le \\frac{2}{3}\\\\q \\in \\otimes_3 & \\frac{2}{3} < d(q)\\end{cases}}\nThen, we conduct experiments that train the baseline models (QP) with the combinations of these datasets and analyze their evaluation metric scores , predictive information entropies (Figure 2(a)), and validation losses (Figure 2(b)) on the development sets. Particularly, four models are considered: QP(\u2460) is trained on the dataset \u2460 and thus suffers from the least influences of over-association; QP(\u2460+\u2461) and QP(\u2460+\u2462) use more training instances with different degrees of over-association; QP(ALL) is trained on the whole dataset. Our conclusions are as follows.\nAs shown in Table 1, more training data from \u2461 or \u2462 is not always leading to performance gains. For example, QP(\u2460) performs worse than QP(\u2460+\u2461) in all settings. This indicates that more instances of moderate over-association degree can be beneficial. However, QP(\u2460) and QP(\u2460+\u2461) outperforms QP(\u2460+\u2462) and QP(ALL), respectively, showing that extreme cases in \u2462 hurt the model performance instead."}, {"title": "4. Mitigating the Negative Effects of Over-association", "content": "Our analysis in \u00a73 has shown the necessity to alleviate the side effects of over-association phenomenon. In this section, we propose two training strategies to alleviate the side effects: 1) data-based weighting (\u00a74.1) guides the model with our automatic over-association degree. 2) model-based weighting (\u00a74.2) adjusts the training target considering some of the model outputs. In addition to independent usage, the two strategies can also be combined, where data-based weighting is served as the warm-up step for model-based weighting."}, {"title": "4.1. Data-based Weighting", "content": "As mentioned in \u00a73.2, we have explored data-pruning, which directly prunes the training instances with high over-association degrees, thus the side effects can be avoided. However, data-pruning is so strict that ignoring the harms from kept instances with moderate over-association degrees and the benefits from discarded ones. Thus we further propose data-weighting that carefully adjusts the learning rate of each instance.\nAs shown in Figure 4(a), data-weighting applies a 0-1 scaling value to each training instance. The scaling value is decided by the over-association degree (d(q) in Equation 2) for the instance. Formally, the scaling value w is defined as\nw = (1 - d(q))^\u03b1,\nwhere \u03b1 is a hyperparameter determining the penalty to the over-association query. Finally, the loss function using the data-weighting becomes\nL_{weight} = -w \\sum_{i=1}^{m} log P(q\u1d62 | H, q_{<i}; \u03b8).\nPlease note that a larger \u03b1 denotes a smaller scaling value w given a fixed over-association degree, meaning a larger penalty. For instance, when over-association degree d(q) = 0.5, increasing \u03b1 from 1.0 to 2.0 yields a decrease of w from 0.5 to 0.25."}, {"title": "4.2. Model-based Weighting", "content": "Though the data-based weighting strategy can ease the side effects to some extent, it can only capture the surface overlap between dialogue contexts and gold queries while ignoring the behaviors of the model. Therefore, we further propose model-based weighting strategy, which considers either model stepwise predictive probability (model-stepwise) or generated whole sequences (model-wholeseq) to capture model behaviors as well. This is inspired by our findings in \u00a73.2 that both model behaviors can reflect over-association degrees of input cases from another aspect. However, if asked to imitate these behaviors only, the model would suffer from its predicted noise. Thus, both strategies we proposed jointly consider the model behaviors and gold queries, balancing the harms from the noise and the benefits from mitigating side effects of over-association.\nModel-stepwise Weighting. As shown in Figure 4(b), this approach unites the original target vector and model predictive vector for each token in a query as the training target, which is also known as self-knowledge distillation (Hahn and Choi, 2019; Kim, Ji, Yoon and Hwang, 2021; Liu, Shen and Lapata, 2021). The original target vector y\u1d62 is the |V|-dimensional one-hot vector of q\u1d62, where V is the vocabulary. The model predictive vector P(H, q_{<i}; \u03b8) (P\u1d62 for clarifying) is the model output logit vector after the softmax normalization, which shares the same shape as y\u1d62. The model-stepwise weighting target for q\u1d62 is the additive of y\u1d62 and P\u1d62 after scaling. Formally, the model is trained given by\nL_{step} = -\\sum_{i=1}^{m} (\u03b2P_i + (1 - \u03b2)y_i)^T log P_i,\nwhere \u03b2 is a hyperparameter and a large (small) \u03b2 denotes a favour to model (annotation) distribution.\nIntuitively, L_{step} serves as a balance between trusting the model and entirely using the annotation when there is a large discrepancy between model predictive distribution and training target.\nModel-wholeseq Weighting. It is shown in Figure 4(c) and updates model parameters in reinforcement learning style. The weight (i.e., reward) is used to ensure the quality of a generated prediction. For each training instance, we first sample a candidate query c from top-k generated predictions using beam search according to their predictive probabilities. Then, we calculate the score of quality s for it against the gold query Q using a scoring function f (e.g., Unigram F\u2081). Both \u03ba and the scoring function f are hyperparameters selected by development experiments. Lastly, we adopt standard reinforcement learning (Williams, 1992) to update our model, and the loss is defined as\nL_{whole} = -\u03b3 \\sum_{i=1}^{c} log p(c\u1d62 | H, c_{<i}; \u03b8),\nwhere c\u1d62 is the i-th token in c, and \u03b3 is the reward for c defined as s - s_p. s_p is the baseline reward designed to decrease the high variance of the gradient estimator, which is calculated by averaging the quality scores of top-k generated predictions.\nCompared with model-stepwise weighting that only explores each annotated query, model-wholeseq weighting further expands to other candidates over the gold query. Besides, model-wholeseq weighting deals with every whole candidate query, while model-stepwise weighting works on each decoding step."}, {"title": "5. Experiment", "content": "5.1. Setup\nDataset. We study on the following two benchmarks of query production in different languages.\n\u2022 Wizard-of-Internet (WoI, Komeili et al. 2022). It is a recently released English dataset that contains 35,765 / 2,534 / 2,164 pairs of dialogue contexts and queries in its training/development/test set. Each dialogue context corresponds to around 1.16 queries on average. For the test set, we merge instances according to the dialogue context and take the corresponding queries as multiple references.\n\u2022 DuSinc (Zhou et al., 2022). It is a recent shared task on Chinese conversational query production containing 5,759 / 616 / 1,610 (dialogue context and query) pairs for training/development/test, respectively.\nEvaluation Metrics. We use the following automatic metrics to evaluate model performance:\n\u2022 Unigram F\u2081 (Uni. F\u2081) measures the unigram overlap between predictions and gold references.\n\u2022 BLEU-1/2 is a typical metric for text generation tasks. We use sacrebleu (Post, 2018) for score calculation.\n\u2022 ROUGE-1/2/L (Lin, 2004) is also a popular metric used for evaluating automatic summarization and machine translation.\nWe follow Zhou et al. (2022) to use Uni. F\u2081, BLEU-1/2 and their summation (Sum., the main metric for overall performance evaluation). The ROUGE scores will be provided in Appendix B as the supplementary evaluation.\nModel Configuration. For the experiments on WoI, we use T5-v1.1-base or BART-base. For the experiments on DuSinc, we use mengzi-t5-base (Zhang, Zhang, Chen, Guo, Hua, Wang and Zhou, 2021), a strong model pretrained on a corpus derived from Chinese Wikipedia, Chinese News, and Common Crawl. All models are trained using Adam optimizer with the linear scheduler and initial learning rate of 5e-5. The batch size for models on WoI and DuSinc are 64 and 16, respectively. We train all models until convergence and select the checkpoints with best Sum. score on development set as final models.\nSpecially, for the model-based weighting, we first pretrain the model using the standard CE loss or data-based weighting strategy. It ensures the quality of model predictive probability or generated predictions at the beginning. The selection of hyperparameters \u03b1, \u03b2, and \u03ba for WoI/DuSinc are 2.0/0.5, 1.0/0.75, and 10/10 respectively given development experiment results. We directly take QP(\u2460+\u2461) for data-pruning as it performs best in our preliminary study (\u00a73.2). For scoring function f, we consider Uni. F\u2081, BLEU-2 and semantic similarity score calculated by Sentence-BERT (Reimers and Gurevych, 2019). We select Uni. F\u2081 as f considering performance and cost. Related experiment results are shown in Appendix \u00a7A."}, {"title": "5.2. Main Results", "content": "Table 2 shows the overall results on WoI and DuSinc, where BlenderBot2 represents the query generation model by Komeili et al. 2022. BlenderBot2 is based on BART-large (Lewis et al., 2020) and is trained on the same data split as our models. All our models are based on T5-base, thus they all take smaller amounts of parameters than BlenderBot2 (220M vs. 406M).\nWe can draw the following conclusions. First, we are surprised to find that T5-base performs better than BlenderBot2, even though T5-base takes a smaller amount of parameters. Except for the difference between their pretraining styles, one possible reason may be the metric used for checkpoint selection: we use Sum. score instead of perplexity adopted by BlenderBot2, given our finding that the CE loss (highly related to perplexity) and Sum. are not well-related in \u00a73.2. Nevertheless, this also indicates that our comparisons are based on a strong baseline. Second, all models of either the data-based weighting or the model-based weighting outperform the baselines on both datasets, indicating the effectiveness and generalization of all methods for mitigating the negative effects of the over-association. For the models using data-based weighting, Data-weighting performs better than Data-pruning because it provides more sophisticated control for learning the over-association cases. For the models using model-based weighting, Model-stepwise is superior to Data-pruning but inferior to Data-weighting. It may be because the model-stepwise weighting provides control at a finer granularity (i.e., token-level), which is not suitable for a generation task taking a sequence of tokens as the reference. Model-wholeseq significantly outperforms other approaches. By not fitting the training instances directly, it benefits from the most flexible supervision signal and minimal constraint on fitting over-association cases. Finally, we report Data-weighting\u2192Model-wholeseq, which simply combines the stronger weighting strategies in data-based and model-based strategies, respectively. It gives the best results among all models and has more gains on DuSinc than WoI. This may be because T5-base can provide promising initialization parameters with a fair amount of training instances (WoI is 5.7 times of DuSinc). We will further discuss it in low-resource experiments. As an unfair setup, we also compare our models with baselines using T5-large, which are 3.5 times larger than our models. Data-weighting\u2192Model-wholeseq show slightly inferior results on DuSinc (-1.2 on Sum.) but still give much better results on WoI (+5.01 on Sum.). This again strongly validates the effectiveness of our approach."}, {"title": "5.3. Analysis", "content": "In this section, we conduct more detailed comparisons between our strategies and the T5-base on WoI to validate how we address the negative effects of over-association. We also explore model performances in low-resource settings, as this is important in real-world scenarios. We mainly report Data-weighting\u2192Model-wholeseq (which is named as Combine for simplicity), but also Data-weighting and Model-wholeseq as they perform stronger within data-based and model-based weighting strategies respectively.\nMitigating the side effects of over-association eases data hunger issue. Because of the over-association, a model can need massive data to well fit the ground-truth answers. This is a typical data hunger issue. Figure 5 compares the Sum. scores of our models and the baseline when trained with different ratios (5%, 10%, 20%, 100%) of the whole training corpus. When training instances are limited, a model may be not robust enough to resist the negative effects. By mitigating these side effects, our methods require less data to train a model with decent performance. Particularly, we observe the significant performance gain when using limited training data adopting either the data-based or model-based weighting strategy. More importantly, using 10% training instances, Combine has performed comparably with the baseline trained with the whole dataset. And when using 20% instances, it performs significantly better. Interestingly, Model-wholeseq is slightly worse than Data-weighting when using 5% or 10% data. It is due to the unsatisfying initialization of model parameters, which meets the common practice: pretraining is important for reinforcement-learning-based finetuning (Li, Monroe, Ritter, Jurafsky, Galley and Gao, 2016; Paulus, Xiong and Socher, 2018).\nImprovements for different over-association degrees. Similar to \u00a73.2, we split the test set into 3 subsets according to the over-association degree defined in Equation 2: \u2460, \u2461 and \u2462. They cover 76.1%, 15.9%, and 8.0% of the original test set, respectively. Figure 6 shows the comparison of T5-base and our models for each subset. Generally, the performance of all models shows a clear downward trend with over-association degree increasing. Compared with T5-base, both data-weighting and model-wholeseq weighting benefit all subsets even for \u2462 with the most severe over-association. Besides, we notice that with a smaller over-association degree, the improvement of our models over T5-base model is also more significant. When combining the two strategies, Combine gives further improvements on \u2460 but is slightly worse on \u2461 and \u2462. It shows that our methods mainly help a model perform better on faithful cases than the over-association ones. This meets our expectations as our approach aims to alleviate the side effect of over-association training instances."}, {"title": "5.4. Human Evaluation", "content": "Because of the high variance of annotations, automatic evaluation may not reasonably measure the performance of different models. Thus, we conduct a quantitative human study. Specifically, we sample 200 dialogue context and query pairs from WoI test set to conduct this study, asking 3 annotators capable of fluent English communication to score with 3-point schema (e.g. 0, 1 and 2) based on the soundness of each model-generated query. The inner-annotator agreement (Fleiss' \u03ba) is 0.75, which is at the Substantial level. We average the 3 scores for each instance, and scores of all instances are averaged as the final score for the corresponding model. Table 3 shows the results where our final model scores 0.13 points higher than the baseline. This is roughly a 6.5% gain, confirming the effectiveness of our method."}, {"title": "5.5. Case Study", "content": "As shown in Table 4, we further demonstrate two typical examples from our human study to help visualize the benefits of our approach on alleviating the negative effects of over-association phenomenon. Both cases suffer from over-association. For the first example, the User asks \u201cWhat year was the lancet study\u201d, which indicates \u201cgrip strength correlates with heart health\u201d. Compared with the gold query (\u201cis grip strength an indicator of longevity\u201d), we believe the query by Combine (\u201clancet grip strength study\u201d) is more related to the context. The baseline generates \u201clancet study", "study\".\nFor the second example, generating the word \u201ccoffee": "eeds guessing with commonsense knowledge. All models fail to predict \u201ccoffee\u201d. However, our Model-wholeseq and Combine are more accurate that both of them correctly predict the following topic about \u201ccomplex brew\u201d."}, {"title": "6. Related Work", "content": "Conversational query production is a fundamental task for building search-engine-augmented dialogue systems. To accelerate the study of this research line, Komeili et al. (2022) and Zhou et al. (2022) have contributed Wizard-of-Internet and DuSinc respectively, and trained their models in standard supervised learning. As labeled queries are costly to obtain, Wang, Song, Liu, Mi, Wang, Tu, Su and Yu (2023a) proposed to train their query producer in a weak-supervised manner by leveraging feedback from a search engine. More recently, Wang, Song, Xu and Su (2023b) and Huang, Wang, Gao, Song and Su (2023) further enhanced their models using semi-supervised learning to tackle low-resource and domain adaptation challenges. Differently, our method does not rely on any external resources thus we believe our method is also orthogonal to these concurrent approaches.\nOur model-stepwise weighting is inspired by Self-knowledge distillation (SKD, Hahn and Choi 2019; Kim et al. 2021; Liu et al. 2021), which is adopted as a regularization term to improve model generalization in both Computer Vision and Natural Language Processing fields. Typically, previous work adopt SKD to tackle the over-confidently predicting problem or resist outliers in a noisy corpus. Different from these efforts, we are the first to investigate SKD on query production to alleviate the challenge caused by the over-association phenomenon.\nReinforcement learning is a popular technique to solve the inconsistency between token-level training objective functions and sequence-level evaluation metrics on Seq2Seq generation tasks (Ranzato, Chopra, Auli and Zaremba, 2015; Bahdanau, Brakel, Xu, Goyal, Lowe, Pineau, Courville and Bengio, 2016; Wu, Tian, Qin, Lai and Liu, 2018). In this work, our model-wholeseq weighting mainly focuses on leveraging model predictions to exclude over-association cases instead of easing the inconsistency between training and testing. As model predictions may contain errors, we design the reward term using annotations to ensure the quality of training targets.\nConversational query production is remotely related to keyphrase generation (Meng, Zhao, Han, He, Brusilovsky and Chi, 2017; Chen, Zhang, Wu, Yan and Li, 2018; Chen, Gao, Zhang, King and Lyu, 2019; Chan, Chen, Wang and King, 2019; Yuan, Wang, Meng, Thaker, Brusilovsky, He and Trischler, 2020), which aims at producing keyphrases that summarize the main topics of research articles. We propose to alleviate the severe negative effects of over-association in annotated gold queries. To our knowledge, we are the first to investigate and alleviate such an issue for both tasks. Besides, our findings can be beneficial to the keyphrase generation task as well.\nIn this work, we follow common practices (Komeili et al., 2022; Wang et al., 2023a) to conduct experiments on encoder-decoder structured models (T5 and BART). Our preliminary study has shown that the over-association phenomenon can significantly affect the performance of both T5 and BART, which are pretrained with different corpora and training objectives. Therefore, we believe that models with alternative architectures, such as decoder-only based GPT2 (Radford, Wu, Child, Luan, Amodei, Sutskever et al.), may also face similar challenges. Furthermore, given that both data-based weighting and model-based weighting strategies primarily concentrate on enhancing loss terms during fine-tuning without modifying the model structure, they can theoretically be adapted for use with various other types of models as well.\nCurrently, it is popular to adopt large language models (LLMs) to solve various natural language processing tasks using in-context learning. However, as shown in previous work (Wang et al., 2023b; Huang et al., 2023), even advanced models like InstructGPT (Ouyang, Wu, Jiang, Almeida, Wainwright, Mishkin, Zhang, Agarwal, Slama, Ray, Schulman, Hilton, Kelton, Miller, Simens, Askell, Welinder, Christiano, Leike and Lowe, 2022) and ChatGPT still demonstrate suboptimal performance compared to a much smaller task-specific model based on T5-base. Nonetheless, given the exceptional capabilities of LLMs on text comprehension and generation (Achiam, Adler, Agarwal, Ahmad, Akkaya, Aleman, Almeida, Altenschmidt, Altman, Anadkat et al., 2023), we believe equipping LLMs with a task-specific query producer can further benefit the conversational query production and downstream response generation tasks (Xu, Xu, Wang, Liu, Zhu and McAuley, 2023; Shen, Song, Tan, Li, Lu and Zhuang, 2024)."}, {"title": "7. Implications", "content": "We investigate the under-explored over-association phenomenon and propose two instance-wise weighting strate-gies from different perspectives in this work. Our findings not only help to build stronger query producers but also bring inspiration to future work in this field.\nFirst, it is important to carefully design the annotation guidelines for labeling search queries. Our preliminary study shows that the over-association phenomenon is common across current benchmarks, Wizard-of-Internet and DuSinc. Their guidelines can pay more attention to annotating responses but ignore the checking of labeled queries. As annotators may unconsciously perform reasoning with their background knowledge, a good response can sometimes come up with an unrelated query, e.g., \u201cthe effect of eating orange\" in Figure 1, that a model struggles to predict. Based on our conclusions, researchers can ask annotators to recognize the dialogue topic first before annotating and avoid introducing new concepts that are not necessary.\nSecond, our proposed instance-wise weighting strategies can be used to improve the robustness of a model on noisy training data. As a dialogue system may serve users with different backgrounds, the topics of conversations can also vary across various domains. To ease the scarcity of annotations, a commonly used technique is data augmentation. For instance, Huang et al. (2023) leverage dialogue responses to collect pseudo queries for semi-supervised training. Similar to handling instances with high over-association degrees, our methods can help ease the negative impact of noisy instances as well by assigning smaller weights to these instances."}, {"title": "8. Conclusion", "content": "In this work, we have studied the over-association phenomenon in conversational query production, which is inherited from the open-ended nature of human dialogues. We first systematically analyze the negative influence of over-association on standard text-generation models. Then, we designed several data-based and model-based weighting strategies that help to better train a model on the corpus suffering from over-association. Experiments on two major datasets showed that all strategies and their combination indeed greatly alleviated the side effects. Our methods also effectively help solve data hunger and unfaithful issues raised by over-association."}, {"title": "A. Selection of f", "content": "For scoring function f, we consider Uni. F\u2081, BLEU-2 and semantic similarity calculated by a trained Sentence-BERT(SBERT). Results are shown in Figure 7. Using any scoring function significantly improves the model performance. We notice that Uni. F\u2081 and SBERT perform competitively after 300 steps, but using SBERT converges faster, which shows some benefits of considering deep semantic information. However, SBERT takes much more time because of text embedding construction. Using BLEU-2 performs worst. It may be because BLEU-2 only focuses on precision while ignoring recall. In short, we select Uni. F\u2081 as f considering performance and cost."}, {"title": "C. Annotation Guidelines", "content": "The human study aims to evaluate the quality of generated queries. The evaluation is based on a 3-point scheme:\n2 means flawless; 1 means having major flaw but with values; 0 means being completely wrong.\nA soundness query should be factual and closely related to the current topic (especially the topic of the last few turn). Take the following conversation as an example:\n\u201cUser: Have you ever seen the TV show Gilmore Girls? I just finished watching it for the third time!\"\n\u201cBot: I have not ever seen it! But, one of my favorite actors is in it.\"\n\"User: Who is that? Alexis Bledel? She's one of my favorites.\"\nThe gold query of the last turn is \u201cJared Pad Gilmore Girls\u201d, which is a typical over-association query because the actor \u201cJared Pad\u201d is hard to be predicted from the dialogue context.\nFor the model predictions to this case, the following answers should be scored as 2:\n\u2022 Alexis Bledel Gilmore Girls. It is highly related to the current topic about actors in \u201cGilmore Girls\u201d.\n\u2022 actors in Gilmore Girls. It helps the model reply to the question of user \u201cWho is that (actor)?", "1": "n\u2022 Gilmore Girls. It is not well related because the user tends to talk about favourite actor instead of the show at the last turn.\n\u2022 Alexis Bledel. It is not accurate enough that the retrieved documents may not contain knowledge about the role played by \"Alexis Bledel\u201d in the show.\nThe following answers should be scored as 0:\n\u2022 my favourite actor. It does not contain meaningful information and can not help retrieving related knowledge to the conversation.\n\u2022 Lionel Messi Gilmore Girls. It is factually incorrect."}]}