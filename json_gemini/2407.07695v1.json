{"title": "African Democracy in the Era of Generative Disinformation: Challenges and\nCountermeasures against Al-Generated Propaganda", "authors": ["Chinasa T. Okolo"], "abstract": "As the interest in developing and utilising generative Al grows, there is considerable potential in\nleveraging these technologies to enhance educational curricula, improve the delivery of healthcare\nservices, and streamline business processes. However, concerns about the negative implications of\nthese technologies have become more prevalent in public discourse, particularly in the context of\nelectoral processes. In light of this prominent discourse, an emerging area of research is investigating\nthe current and estimated impacts of Al-generated propaganda on African citizens participating in\nelections (Okolo, 2023). Throughout Africa, there have already been suspected cases of Al-generated\npropaganda influencing electoral outcomes or precipitating coups in countries like Nigeria\n(Awojulegbe, 2022), Burkina Faso (Smith Galer, 2023), and Gabon (Breland, 2019), underscoring the\nneed for comprehensive research in this domain.\nIn 2024, over a dozen African countries are scheduled to have elections. Given the existing rate of\ndisinformation that plagues African elections, coupled with social unrest (Salehyan & Linebarger, 2015;\nGoldsmith, 2015), internet blackouts (Mpofu, 2022), and ballot tampering (Friesen, 2019; Mapuva,\n2013), the increasing ubiquity of generative Al heightens concerns that Al-fueled disinformation\ncampaigns could exacerbate current issues within the African continent (Timcke & Hlomani, 2024).\nWith this in mind, concerted efforts are needed to combat such disinformation. Encouragingly, the\npast decade has led to independent fact-checking organisations throughout Africa. These\norganisations, like Dubawa in Nigeria, PesaCheck in Kenya, and Africa Check, which operates across\nSouth Africa, Kenya, Nigeria, and Senegal, have worked diligently to fact-check widely circulated\nmemes, doctored social media content, and claims made by political figures.\nWhile social media platforms have enacted various safeguards to hinder the proliferation of\ndisinformation, many of these efforts are undermined by loopholes such as the lack of moderation for\naudio content (Bickert, 2020), as evidenced by recent elections in Slovakia (Meaker, 2023), or\nautomated content moderation systems that have limited understanding of low-resource languages", "sections": [{"title": "Introduction", "content": "As the interest in developing and utilising generative Al grows, there is considerable potential in\nleveraging these technologies to enhance educational curricula, improve the delivery of healthcare\nservices, and streamline business processes. However, concerns about the negative implications of\nthese technologies have become more prevalent in public discourse, particularly in the context of\nelectoral processes. In light of this prominent discourse, an emerging area of research is investigating\nthe current and estimated impacts of Al-generated propaganda on African citizens participating in\nelections (Okolo, 2023). Throughout Africa, there have already been suspected cases of Al-generated\npropaganda influencing electoral outcomes or precipitating coups in countries like Nigeria\n(Awojulegbe, 2022), Burkina Faso (Smith Galer, 2023), and Gabon (Breland, 2019), underscoring the\nneed for comprehensive research in this domain.\nIn 2024, over a dozen African countries are scheduled to have elections. Given the existing rate of\ndisinformation that plagues African elections, coupled with social unrest (Salehyan & Linebarger, 2015;\nGoldsmith, 2015), internet blackouts (Mpofu, 2022), and ballot tampering (Friesen, 2019; Mapuva,\n2013), the increasing ubiquity of generative Al heightens concerns that Al-fueled disinformation\ncampaigns could exacerbate current issues within the African continent (Timcke & Hlomani, 2024).\nWith this in mind, concerted efforts are needed to combat such disinformation. Encouragingly, the\npast decade has led to independent fact-checking organisations throughout Africa. These\norganisations, like Dubawa in Nigeria, PesaCheck in Kenya, and Africa Check, which operates across\nSouth Africa, Kenya, Nigeria, and Senegal, have worked diligently to fact-check widely circulated\nmemes, doctored social media content, and claims made by political figures.\nWhile social media platforms have enacted various safeguards to hinder the proliferation of\ndisinformation, many of these efforts are undermined by loopholes such as the lack of moderation for\naudio content (Bickert, 2020), as evidenced by recent elections in Slovakia (Meaker, 2023), or\nautomated content moderation systems that have limited understanding of low-resource languages\n(Nicholas & Bhatia, 2023). Furthermore, citizens with limited digital and media literacy often\ninadvertently disseminate propaganda (Rubin, 2019). As efforts increase to curb the spread of\nAl-generated disinformation, governments must allocate resources toward increasing citizen\nengagement in Al literacy efforts. Governments will also have to establish regulatory frameworks that\ncan effectively govern the use of generative Al and other emerging technologies while promoting\nsafeguards to prevent the spread of disinformation.\nThis paper aims to highlight the risks associated with the spread of generative Al-driven disinformation\nwithin Africa while concurrently examining the roles of government, civil society, academia, and the\ngeneral public in the responsible development, practical use, and robust governance of Al. To\nunderstand how African governments might effectively counteract the impact of Al-generated\npropaganda, this paper presents case studies illustrating the current usage of generative Al for\nelection-related propaganda in Africa. Subsequently, this paper discusses efforts by fact-checking\norganisations to mitigate the negative impacts of disinformation, explores the potential for new\ninitiatives to actively engage citizens in literacy efforts to combat disinformation spread, and\nadvocates for increased governmental regulatory measures. Overall, this research seeks to increase\ncomprehension of the potential ramifications of Al-generated propaganda on democratic processes\nwithin Africa and propose actionable strategies for stakeholders to address these multifaceted\nchallenges."}, {"title": "Background literature", "content": "Powered by advances in technical research and computing architecture, artificial intelligence (AI) has\nemerged as a way for people and organisations to create content, optimise workflows, and refine\nbusiness processes. However, these newfound abilities have increased the harms of Al, introducing\nnew nuances regarding Al-generated content and fueling disinformation. Given the rising concerns\nabout the ability of Al-generated content to impact democratic processes, it is crucial to understand\nhow to actively prevent further harm. To provide sufficient context on the impact of Al on democracy,\nthis section provides a brief overview of generative Al, details the landscape of Al-fueled\ndisinformation throughout Africa, and outlines how Al has shaped democratic processes within African\ncountries."}, {"title": "Generative Al", "content": "Generative Al is a subfield of Al employing advanced machine learning (ML) techniques such as\ngenerative adversarial networks (GANs), variational autoencoders (VAEs), and transformers to analyse\nvast amounts of data to produce content such as text, images, audio, and videos. A prominent form of\ngenerative Al is large language models (LLMs), which are Al models trained to interpret linguistic\npatterns and relationships. Many generative Al methods rely on a range of inputs to generate content,\nincluding text, image, audio, and video prompts. Prominent examples of generative Al include\ntext-to-text applications such as ChatGPT, developed by OpenAl; Gemini, developed by Google; and\nClaude, developed by Anthropic. Popular text-to-image models include DALL-E, by OpenAl, and other\ntools such as Midjourney and Stable Diffusion. Text-to-video has also seen significant advances with\nGoogle's VideoPoet, an LLM that generates zero-shot, variable-length videos and leverages\nimage-to-video functionality and video-to-audio functionally to produce audio output matching video\nscenes without text guidance (Google Research, 2024). In April 2024, OpenAl released Sora, an Al\nmodel that creates hyperrealistic video scenes from text prompts (OpenAl, 2024). In May 2024, Google\nDeepMind released Veo, a video generation model that leverages prior Google advancements in image\nand video generation.\nWhile generative Al has been presented as a powerful method to revolutionise how people\ncommunicate and create, it is fraught with a plethora of ethical concerns arising from its development,\nimplementation, and usage (Bommasani et al., 2021; UK DSIT, 2024). Vast amounts of data used to\ntrain generative Al models were scraped from the internet, mostly without consent. This data includes\nmillions of websites, blogs, research articles, social media posts, books, code repositories, images,\nvideos, audio recordings, and databases. As companies developing Al increase their data needs, the\nGlobal South has routinely become a destination for outsourced data labelling labour, with companies\nsuch as Appen, Scale Al (Remotasks), Samasource, Clickworker, Mighty Al, Surge Al, Lionbridge Al, and\nAmazon Mechanical Turk, which played a significant role in the development of notable ML\nbenchmark datasets such as ImageNet, relying heavily on workers in this region. Recent coverage has\nalso highlighted the harms data workers in East Africa have faced when repeatedly exposed to graphic\ncontent in their work labelling data for OpenAl's ChatGPT (Perrigo, 2023).\nRising concerns about generative Al have also exposed issues regarding the climate impacts of training\nlarge Al models and using generative Al tools, with estimates showing excessive water usage\n(Crawford, 2024), significant greenhouse gas emissions (Luccioni et al., 2024), and extreme levels of\nenergy consumption (Luccioni et al., 2023). Using generative Al tools has also had many implications\nwithin the disinformation landscape. Text and image generation tools have been shown to generate\nincorrect information (Jo, 2023), spread false narratives (Ferrara, 2024), and manipulate public opinion\n(Funk et al., 2023; Kidd & Birhane, 2023). Many of the premier generative Al systems are also trained on\ndata that primarily represents dominant languages like English and Western cultures (Shankar et al.,\n2017; De Vries et al., 2019; Nwatu et al., 2023). Given that content produced by generative Al systems is\noften hard to detect, such content can easily deceive users who may be unaware of the presence and\nability of these tools (Sadasivan et al., 2023; Lu et al., 2023). Thus, it will be essential for researchers,\npolicymakers, and developers to make concerted efforts towards enacting sufficient measures to\ncombat Al-fueled disinformation."}, {"title": "Disinformation in Africa", "content": "Disinformation is the intentional creation and spread of deliberately deceptive information to mislead\nor influence people, communities, and institutions (Fallis, 2015). African countries particularly struggle\nwith disinformation, with research showing that media consumers in Kenya, Nigeria, and South Africa\nare exposed to disinformation regularly (Wasserman & Madrid-Morales, 2019). Disinformation has also\nbeen an issue long before the internet played a prominent role. It is estimated that from 2000 to 2005,\ndisinformation around the role of HIV in causing AIDS and antiretroviral drugs led to more than\n300,000 deaths in South Africa (Chigwedere et al., 2008). Traditional media outlets, including private\nand state-sponsored platforms, can spread disinformation through radio and television long before it\nis amplified online (Africa Center for Strategic Studies, 2021). Issues with disinformation have been\nfueled by greater access to information through social media and other digital platforms (Ceylan et al.,\n2023). These issues have been further exacerbated by the introduction of generative Al, which has\nmade it easier to create various forms of content (Xu et al., 2023; Chu-Ke & Dong, 2024).\nWithin Africa, disinformation affects democratic processes along with routine aspects of daily life, such\nas health and well-being. Research has shown that 20% of media coverage of genetically modified\nfoods by African outlets contains misinformation (Lynas et al., 2022). The COVID-19 pandemic had a\nmajor impact on the spread of health disinformation. Repeatedly forwarded messages purporting\nhomoeopathic remedies to prevent and treat COVID-19 were commonly spread through messaging\nand social media platforms (Nwankwo et al., 2020; Walcott, 2020). Disinformation often appears in\ncycles, and older news pieces or reports can be brought back into resurgence. In 2020, an article\npublished in 2013 claiming that 50 children in Chad were paralysed by a vaccine supported by the\nGates Foundation was debunked (Africa Check, 2020). In 2013, Africa Check was also vital in debunking\nclaims made by the World Health Organization in 1983, stating that 80% of rural Africans primarily\ndepend on traditional medicine for their healthcare needs (Africa Check, 2013). Within Africa,\ndisinformation is often present and rises during elections and periods of social unrest. The recently\npublished book, \u201cDigital Disinformation in Africa\u201d details government-fueled disinformation during the\n#EndSARS protests in Nigeria, efforts by citizens to counter state disinformation in Angola,\ndisinformation by the Kenyan news media during the 2022 elections, disinformation during the 2018\npresidential election period in Cameroon, and how nefarious actors use selfies and hashtags to fuel\ndisinformation during armed conflict in Ethiopia (Roberts & Karekwaivanane, 2024).\nWhile disinformation in Africa is spread by local actors, a growing number of reports have uncovered\nthe rising influence of foreign disinformation campaigns within African countries (Mare et al., 2019;\nMaweu, 2019; Lyammouri & Eddazi, 2020). These campaigns have either been state-sponsored or\noperated by private, foreign entities. Research from the Africa Center for Strategic Studies has analysed\nhundreds of misinformation campaigns throughout African countries, showing that 60% of\ndisinformation campaigns are foreign-sponsored. The majority of these state-sponsored campaigns\ncome from Russia, China, and the Gulf States, such as the United Arab Emirates, Saudi Arabia, and\nQatar, and are primarily focused on supporting authoritarian governments and military juntas (Africa\nCenter for Strategic Studies, 2024). These campaigns also disproportionately target West African\ncountries such as Burkina Faso, Mali, and Nigeria. West Africa accounts for 43% of targeted\ndisinformation campaigns, followed by East Africa (20%), Southern Africa (15%), Central Africa (13%),\nand North Africa (9%)."}, {"title": "Al case studies", "content": "Given the recent cascade of generative Al tools, understanding of the usage and impact of Al within\nAfrican elections continues to emerge. Reports and surveys have shown that African governments are\nleveraging Al to assist with voter registration, authentication, management, and engagement, along\nwith detecting cyber threats and aiding in oversight and decision-making (Itodo, 2024). From\n2023-2025, an estimated 36 African countries will hold general or presidential elections to appoint a\nnew head of state. Over the elections and recent political events that occurred before May 2024, there\nhave been many suspected and confirmed cases of Al-generated propaganda influencing electoral\noutcomes or precipitating coups in countries like Nigeria, Burkina Faso, and Senegal, underscoring the\nneed for comprehensive documentation of generative Al use cases in democratic processes\nthroughout Africa. Recent work by Rest of World, a global news platform, has begun to make headway\ntowards tracking Al-generated election content globally. However, this work only covers one African\ncountry, South Africa\u00b9. There is also a strong need for research examining the spread of generative\nAl-produced disinformation and its respective impacts within and outside of Africa, given that the\nmajority of reports on such usage are relegated to short-form news stories. To help make headway\ntowards this issue, this section presents case studies illustrating the current usage of generative Al for\nelection and political-related propaganda in Africa."}, {"title": "Multimedia Al-generated election propaganda", "content": "The Nigerian 2023 presidential election was likely one of the first elections within the African continent\nto experience a deluge of Al-generated content. There were multiple cases of fake endorsements from\nprominent Nigerians, Hollywood actors, celebrities, and current and former United States presidents\n(Awojulugbe, 2022; Owoeye, 2022; Adeyemi, 2023). There were also two prominent cases of\nAl-generated audio, one shared hours before the election in February 2023, purportedly depicting a\ncandidate's plan to rig the election (Shibayan, 2023) and another shared over a month after the\nelections claimed to depict a call between another presidential candidate and a prominent Nigerian\nreligious figure, which is still under contention as being Al-generated. Electoral Al-generated\npropaganda can also be disseminated even after elections take place, as seen in Nigeria and Senegal.\nAfter the election of Senegal's president, Bassirou Diomaye Faye, in March 2024, a video purporting to\ndepict the president giving a speech was widely spread. However, this video depicted the president's\nmentor, Ousmane Sonko, giving a speech at a press conference in 2021. However, fact-checkers\nuncovered that generative Al technology was used to translate his original speech, spoken in French,\nto appear as if he was speaking English (Kabweza, 2024).\nSouth Africa held their 2024 elections on May 29th. Throughout their election period, Rest of World has\ntracked at least four cases of generative Al use for political campaigning. The first, detected in February\n2024, was a TikTok video posted on a South African meme account appearing to show the American\nrapper Eminem endorsing the third-largest political party in South Africa, the Economic Freedom\nFighters. In March 2024, a video depicting United States President Joe Biden was shared on TikTok,\nFacebook, X, and WhatsApp, claiming that the United States would enact sanctions on South Africa if\nthe African National Congress, the incumbent party, won the election. Also in March, another video\nposted on TikTok appeared to show Donald Trump endorsing uMkhonto we Sizwe, a paramilitary\nparty. Rest of World has also shown that the South African Referendum Party has frequently used\nAl-generated imagery in campaign material since November 2023."}, {"title": "Political Al-generated propaganda influencing coups", "content": "Since 2020, 9 military coups have occurred within West, Central, and East African countries (Green,\n2023; Vines, 2024). Countries affected by these coups include Mali (2020, 2021), Guinea (2021), Burkina\nFaso (January and September 2022), Niger (2023), Gabon (2023), Chad (2021), and Sudan (2021). There\nhave also been a number of attempted coups during this period in Niger, Gabon, Sudan,\nGuinea-Bissau, The Gambia, Sudan, Sierra Leone, Burkina Faso, S\u00e3o Tom\u00e9 and Pr\u00edncipe, and the\nDemocratic Republic of Congo (Duzor & Williamson, 2023). The most recent coup took place in May\n2024, when security forces foiled a coup attempt by the Congolese opposition party in the Democratic\nRepublic of Congo. Political propaganda has been shown to impact coups before, during, and after\nthey happen. One of the earliest cases of generative Al propaganda in Africa occurred in December\n2018, when a video claiming to depict Ali Bongo, Gabon's president at the time, stirred concern on\nsocial media due to unnatural expressions and posture (Breland, 2019). Reports claim that this video\nraised concerns about his ability to rule and sparked a coup in January 2019, which later failed (Patil &\nGori, 2023). Burkina Faso's most recent coup in September 2022 was followed by a series of\nAl-generated videos from American-based Pan-Africanists appearing to express support for the new\nmilitary regime. These videos were initially detected on Twitter and Facebook and were shared by\nusers who had received these videos on WhatsApp. While an investigation from VICE confirmed that\nthe videos were created using a tool from the company \u201cSynthesia,\u201d the company would not confirm\nwho created the videos, stating that the user had been banned from the platform (Smith Galer, 2023).\nWhile the BBC reported a large amount of disinformation shared after Niger's coup in July 2023, there\nis insufficient evidence to understand the role that generative Al may have played in producing this\ncontent, given that mostly older content and manipulated images and videos were shared (Mwai,\n2023)."}, {"title": "Understanding efforts toward combating disinformation", "content": "Over the past decade, independent fact-checking organisations have been established throughout\nAfrica. These organisations often leverage data-driven practices to advance their work, which has had\nan impact on increasing media transparency across the continent (Cheruiyot & Ferrer-Conill, 2018).\nAfrica Check, the oldest and most prominent fact-checking organisation in Africa, was founded in 2012.\nAfrica Check operates across South Africa, Kenya, Nigeria, and Senegal have worked diligently to\nfact-check widely circulated memes, doctored social media content, and claims made by political\nfigures. Africa Check\u00b2 screens around 100,000 inquiries from media consumers yearly and has\npartnered with platforms such as Facebook as an independent fact checker. Africa Check covers local\nAfrican languages like Igbo, Yoruba, Hausa, Swahili, Wolof, Afrikaans, Zulu, Setswana, Sotho, Northern\nSotho and Southern Ndebele. Other organisations, like PesaCheck\u00b3, established in 2016 in Kenya,\nfocus on verifying financial and statistical information by public figures in East Africa, unpacks budget\nand census data, and builds Al tools to verify claims automatically. In 2018, the Center for Journalism"}, {"title": "Media literacy educational efforts in Africa", "content": "Throughout the continent, fact-checking organisations have been essential in advancing media\nliteracy training for journalists and the general public. Organisations like Dubawa run the Kwame\nKarikari Fact-checking Fellowship. This 6-month program provides technical training on fact-checking\nand project mentorship to full-time employees of media organisations in anglophone West Africa. This\nprogram also aims to help fellowship recipients establish fact-checking capabilities within their\nrespective organisations. In March 2024, UNESCO supported the Media Academy for Journalism and\nCommunication to host fact-checking and media verification training for 25 journalists in The Gambia\n(UNESCO, 2024). Other organisations such as Africa Check, the Code for Africa African Fact-Checking\nAlliance, Inform Africa, and the Media Foundation for West Africa frequently host workshops for media\norganisations across the continent. The vast majority of fact-checking training programs in Africa have\nfocused on researchers, journalists, or employees of media organisations. This presents a gap in how\nsuch efforts reach the general public. While fact-checking training can help journalists conduct their\nwork with the highest integrity, it will be important to develop programs that can effectively target the\ngeneral public and focus on audiences with lower levels of traditional literacy, those in rural areas, and\nolder adults."}, {"title": "Tech companies' efforts against disinformation", "content": "Along with employing independent fact-checkers to help support efforts to handle disinformation,\nsocial media companies have enacted several measures to identify, decelerate, and eradicate such\ncontent over the years. Prompted by the increase in message forwarding during the COVID-19\npandemic, much of which was disinformation, Meta introduced global limits on message forwarding in\nApril 2020. Meta reported that these measures helped decrease the spread of highly forwarded\nmessages by 70% (Singh, 2020). WhatsApp had already enacted prior limits on message forwarding\ndue to a series of murders and lynchings in India that occurred from widely spread rumours on the"}, {"title": "Leveraging Al tools to combat disinformation", "content": "Al-assisted measures to identify disinformation and slow its spread have grown in prominence\n(Santos, 2023). While many of these methods are developed through academic research, social media\ncompanies have increasingly leveraged Al tools to automatically detect disinformation in tandem with\nmore manual processes, such as employing manual fact-checkers. While Al could help scale\nautomated fact-checking, several issues exist with these methods. The majority of LLMs represent a\nsmall portion of languages spoken worldwide. If employed as a primary measure to identify\ndisinformation, this may result in inaccurate translations that could falsely identify harmless content\nas disinformation and inadvertently let harmful content spread. Al datasets and models have also\nbeen shown to underrepresent non-Western cultures (Shankar et al., 2017; De Vries et al., 2019;\nPrabhakaran et al., 2022; Nwatu et al., 2023; Ghosh & Caliskan, 2023), and automated\nimage-verification tools may not have been trained on sufficiently representative datasets to\nunderstand cultural nuances. This could exacerbate existing issues with automated content\nmoderation, where users have falsely had their social media accounts deleted due to deficiencies in\nlanguage translation and misunderstandings of cultural contexts (Shahid & Vashistha, 2023). These\nissues may also impact how audio-based disinformation is spread, given that automated content\nmoderation systems have a limited understanding of low-resource languages (Nicholas & Bhatia,\n2023)."}, {"title": "Navigating the impact of generative on democratic processes in Africa", "content": "Generative Al has a strong potential to impact democratic processes, primarily in elections. Within\nAfrican countries, elections are often plagued by high rates of disinformation, social unrest (Salehyan &\nLinebarger, 2015; Goldsmith, 2015), internet blackouts (Mpofu, 2022), and ballot tampering (Friese,\n2019; Mapuva, 2013). Many of these factors impact civic participation and undermine democracy. The\nincreasing ubiquity of generative Al heightens concerns that Al-fueled disinformation campaigns could\nexacerbate current issues affecting democratic processes within the African continent. While measures\nsuch as internet blackouts could have the unintended positive effect of slowing down the spread of\nAl-generated disinformation, this content could continue to proliferate in other ways. As countries\nworldwide continue to grapple with the new complexities posed by Al, especially regarding its impact\non democracy, there is a need for coordinated efforts between academia, civil society, governments,\nand industry to develop novel sociotechnical methods to address these issues. Combating the spread\nof misinformation will take coordinated efforts from government, civil society, and academic\nstakeholders to research pressing issues around disinformation, develop novel methods to identify\nand slow disinformation, help educate and increase public media and Al literacy, and enforce\nregulatory measures on the production and dissemination of disinformation."}, {"title": "Issues with disinformation spread", "content": "Disinformation is often spread through social media and digital platforms and can be hard to\ndecelerate, given the ability of these platforms to amplify information at scale. The prior section has\ndiscussed a number of strategies employed by digital platforms to hinder disinformation. However,\nissues with the robustness of platform policies and the effectiveness of automated and manual\nmethods persist. While companies such as Meta have enacted a variety of safeguards to identify\ndisinformation and limit its spread, users intent on spreading information can thwart these measures\nrelatively easily (e.g., copying and pasting a WhatsApp message to circumvent forwarding limits).\nMeasures to stop disinformation from spreading through platforms and services that leverage\nend-to-end encryption, such as WhatsApp, Messenger, Telegram, and Signal, may also be complex to\nimplement due to the respective technical requirements around encryption. Independent\nfact-checking has also arisen as a popular measure to decelerate the spread of disinformation.\nHowever, given that fact-checking is often a very detailed and manual process, efforts to slow down\nthe spread of disinformation and present verified information may not reach impacted consumers in a\ntimely manner. This can have extreme implications regarding disinformation in sensitive contexts,\nsuch as dangerous health remedies, false accusations, and social conflict. The offline transference of\nmisinformation can exacerbate these issues as it shifts from digital platforms to print media to word of\nmouth. An emerging area of research is focused on examining mis/disinformation spread in\ncommunities with low internet penetration (Gadjanova et al., 2022), which will become increasingly\nimportant to understand as researchers and companies broaden their mitigation methodologies."}, {"title": "Improving Al, digital, and media literacy through citizen engagement", "content": "Research has shown that citizens with limited digital and media literacy often inadvertently\ndisseminate propaganda (Rubin, 2019). However, there are instances, such as the 2019 Nigerian\nelections, where citizens intentionally shared disinformation about specific presidential candidates,\nknowing this information was false (Hitchen et al., 2019). Research has also shown that Al-generated\ncontent is often difficult to detect (Sadasivan et al., 2023; Lu et al., 2023). While the research is mixed\non the specific demographics of populations who are more likely to spread mis/disinformation, older\nadults and those with lower educational attainment are less likely to identify disinformation (Full Fact\net al., 2020; Unfried & Priebe, 2024). In Nigeria specifically, reports have indicated that younger adults\noften received WhatsApp broadcasts about viral protection and remedies from older relatives during\nthe 2014 Ebola outbreak (Kazeem, 2019). These nuances, combined with the increasing digital divide\nin Africa, necessitate the development of efforts that ensure marginalised populations such as those in\nrural areas, older adults, and women are equally involved in educational activities against\ndisinformation.\nTo help mitigate many of the impacts of disinformation, organisations, and governments should focus\non increasing Al, digital, and media literacy of the general public. Given the concentration of\nfact-checking initiatives dedicated to serving media stakeholders, such efforts could be adapted and\nexpanded to meet the needs of communities across the continent. Civil society and non-profit\norganisations will also have a prominent role in supplementing existing efforts to increase media and\nAl literacy. To help support the increasing number of efforts focused on curbing the spread of\nAl-generated disinformation, governments must increase funding for these initiatives. While there may\nbe limited funds for external expenditures, governments can also seek partnerships with companies,\nmultinational agencies, and foundations to support these initiatives. Investing in such efforts would\nalso scale the significant work being conducted by fact-checking organizations across the continent.\nWhile issues of Al, digital, and media literacy are complex, sufficient funding of educational programs,\nsystematised approaches to collaboration, and dedicated research agendas to examine best strategies\nfor upskilling can help make a significant difference."}, {"title": "Increasing governmental and regulatory efforts toward combating disinformation", "content": "Since bad actors versus specific individuals within the general public are often the primary architects\nof disinformation campaigns, dedicated efforts are needed to control the spread of disinformation\nthrough these respective means. Engaging citizens in Al, digital, and media literacy efforts will only be\neffective if measures are taken to stop disinformation at its source. The ability of bad actors to evade\ndetection and mitigation techniques set in place by digital platforms also heightens the importance of\nimproved technical standards to increase the efficacy of these techniques and increased regulation to\nensure compliance and accountability for violations. At the same time, the majority of countries within\nAfrica have passed data privacy and protection measures. With an estimated 36 out of 54 African\ncountries having enacted comprehensive data protections, comprehensive continental-wide\nframeworks are needed to address the unique data issues posed by generative Al. While the African\nUnion (AU) Convention on Cyber Security and Personal Data Protection (also known as the Malabo\nConvention) aims to establish comprehensive norms and regulations for cybersecurity and data\nprivacy across the African continent, only 15 countries have ratified this treaty, posing concerns about\nthe ability of the AU to enforce the outlined protections. African governments will also have to\nestablish regulatory frameworks that can effectively govern the use of generative Al and other\nemerging technologies while promoting safeguards to prevent the spread of disinformation."}, {"title": "Conclusion", "content": "While the landscape of Al-generated disinformation is still evolving within Africa, this emerging\ntechnology poses severe threats to African democracy. The preliminary impact of generative Al on\nelections in Africa shows serious indications of what will likely come for subsequent elections within\nthe continent as this technology evolves over the next few years. With additional concerns about the\nimpact of disinformation on gender equality, conflict prevention, and national security, African\ngovernments must address these issues and support civil society, academic, and industry\nstakeholders to develop robust solutions. This paper reviews the state of Al-generated disinformation\nwithin African countries to understand how African governments might effectively counteract the\nimpact of Al-generated propaganda and propose tangible recommendations stakeholders can adopt\nto address these multifaceted challenges."}]}