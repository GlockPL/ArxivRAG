{"title": "Diffusion Prior Interpolation for Flexibility Real-World Face Super-Resolution", "authors": ["Jiarui Yang", "Tao Dai", "Yufei Zhu", "Naiqi Li", "Jinmin Li", "Shu-Tao Xia"], "abstract": "Diffusion models represent the state-of-the-art in generative modeling. Due to their high training costs, many works leverage pre-trained diffusion models' powerful representations for downstream tasks, such as face super-resolution (FSR), through fine-tuning or prior-based methods. However, relying solely on priors without supervised training makes it challenging to meet the pixel-level accuracy requirements of discrimination task. Although prior-based methods can achieve high fidelity and high-quality results, ensuring consistency remains a significant challenge. In this paper, we propose a masking strategy with strong and weak constraints and iterative refinement for real-world FSR, termed Diffusion Prior Interpolation (DPI). We introduce conditions and constraints on consistency by masking different sampling stages based on the structural characteristics of the face. Furthermore, we propose a condition Corrector (CRT) to establish a reciprocal posterior sampling process, enhancing FSR performance by mutual refinement of conditions and samples. DPI can balance consistency and diversity and can be seamlessly integrated into pre-trained models. In extensive experiments conducted on synthetic and real datasets, along with consistency validation in face recognition, DPI demonstrates superiority over SOTA FSR methods.", "sections": [{"title": "Introduction", "content": "Image super-resolution (SR) is a classic ill-posed problem aimed at enhancing image quality by restoring high-resolution (HR) details from low-resolution (LR) images. In the context of face super-resolution (FSR), this technology is applied in areas such as face recognition and visual enhancement. These applications typically require SR images to exhibit both high consistency and fidelity. Previous SR work has tended to overly pursue distortion-based quantitative metrics (such as PSNR, SSIM). Blau et al. mathematically prove that distortion and perceptual quality are at odds with each other, implying that excessive pursuit of PSNR or SSIM indirectly leads to poorer fidelity. Moreover, discriminative model-based SR methods typically employ end-to-end training, achieving it by minimizing pixel-wise loss between the SR output image and the GT image. It is well-known that such learning objectives favor distortion measures and constrain the SR output to the average of multiple possibilities. This maintains a certain consistency but potentially results in over-smoothing outputs. \nIn contrast, generative methods such as Variational Autoencoders (VAEs), Normalizing Flows (NFs), Generative Adversarial Networks (GANs) and Diffusion Models (DMs) have the capability to generate high-fidelity images. Among these, Denoising Diffusion Probabilistic Models (DDPMs) have recently gained significant attention and research interest due to their impressive generative capabilities. DDPMs exhibit advantages such as stable training and enhanced controllability compared to other generative models. At present, diffusion-based FSR work can be broadly categorized into those that require task-directed retraining and prior-based methods. Training a conditional DDPM from scratch requires significant computational resources and can limit the prior space to lead to sub-optimal results. Introducing conditions to utilize the priors encapsulated in the pre-trained model is an alternating solution. However, adding conditions to a pre-trained model introduces errors and visual artifacts in the intrinsic probability distributions at each time step, leading to the generation of results that deviate from the model's prior manifold. As shown in Fig. 9(e-f), although these prior-based methods achieve good visual perception, the issue of consistency remains unresolved. This is primarily because prior-based methods are unsupervised and generative in nature. When dealing with low-level tasks requiring pixel-level accuracy, it is challenging to achieve precise discrimination.\nWe are aware that the sampling process of DDPMs is an iterative one, progressing from coarse to fine. Wang et al. have been demonstrated that there exists a time step that partitions the sampling interval, and beyond this time step, the error between the real posterior"}, {"title": "Related work", "content": "Face images possess distinctive characteristics such as subject-centered focus, prominent foreground-background contrast, and well-defined face structures. Leveraging these prior information in previous work has effectively improved FSR performance . FSRCH introduces a pre-prior guiding method that extracts face priors from HR images and incorporates it into LR inputs, generating LRmix as a new SR input. Wang et al. employ distillation to propagate real face priors learned by a teacher network to guide the learning of a student network for FSR. In order to enhance the ability of face restoration, Wang et al. propose a Restoreformer that utilizes a high-quality dictionary that not only provides priors for the face, nose, and mouth but is generated through a high-quality face network that learns from a large number of undegraded faces. GLEAN directly leverages rich and diverse priors encapsulated in a pre-trained"}, {"title": "Preliminary", "content": "DDPMs define a Markovian forward diffusion process with T steps, which continuously transforms the initial state $x_0$ through pre-specified noise scheduler ${\\beta_1, \\beta_2, ..., \\beta_T}$ into an isotropic Gaussian distribution $x_T \\sim N(0, I)$. Each step of the forward process can be represented as a Gaussian transition, denoted as:\n$q(x_t|x_{t-1}) = N(x_t|\\sqrt{\\alpha_t}x_{t-1}, (1 - \\alpha_t)I)$ (1)\nwhere $\\alpha_t = 1 - \\beta_t$. Additionally, we can obtain the state at step t through a single-step transition:\n$q(x_t|x_0) = N(x_t|\\sqrt{\\bar{\\alpha}_t}x_0, (1 -\\bar{\\alpha}_t)I)$ (2)\nwhere $\\bar{\\alpha}_t = \\prod_{i=1}^t\\alpha_i$. The inverse process starts from N(0, I) and employs a U-Net denoiser with learnable parameters $\\theta$ to fit the true posterior distribution $q(x_{t-1}|x_t)$. A judicious noise scheduler is employed to ensure that the inverse process also follows a Gaussian distribution, which can be represented as:\n$p_\\theta(x_{t-1}|x_t) = N(x_{t-1}|\\mu_\\theta(x_t, t), \\Sigma_\\theta(x,t))$ (3)\nwhere $\\mu_\\theta(x_t,t)$ and $\\Sigma_\\theta(x,t)$ are the mean and variance predicted by the denoiser, respectively. Ho et al. observe that directly predicting the mean is not optimal. Instead, a prevalent methodology involves parameterizing the $\\mu_\\theta(x_0, x_t, t)$ using a simplified loss function $L_{simple} = ||\\epsilon - \\epsilon_\\theta||^2$ to predict the noise $\\epsilon_\\theta$. This can be represented by the following formula:\n$\\mu_\\theta(x_0, x_t,t) = \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}(1-\\alpha_t)}{1-\\bar{\\alpha}_t}x_t + \\frac{\\alpha_{t-1}\\beta_t}{1-\\bar{\\alpha}_t}x_0$ (4)\nwhere $x_0 = \\frac{1}{\\sqrt{\\bar{\\alpha}_t}}(x_t - \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon_\\theta(x_t,t))$. Furthermore, Dhariwal et al. propose that"}, {"title": "Diffusion Prior Interpolation", "content": "As shown in the upper part of Fig. 10, it represents an unconditional diffusion sampling process. Conditions are introduced through masking, as illustrated in the lower half. The conditions consist of an initial condition $y_T$ and intermediate conditions $y_t$. We design a fixed mask $m_f$ and an adaptive mask $m_a$ for generating Condition Masks (CMs). We will describe the form of CMs in detail in the following subsection.\nThe prior knowledge of the DDPMs is encapsulated in the denoiser, requiring alignment of the condition with the noise of the posterior distribution to effectively leverage the priors. We start by forward sampling the condition, and we get:\n$y_t = \\sqrt{\\alpha_t}y + \\sqrt{1 - \\bar{\\alpha}_t}\\epsilon(x_t, t)$ (6)\nwhere $y_t$ represents the noisy condition obtained through the reparameterization of Eq. 2 and $\\epsilon$ corresponds to the noise predicted by the pre-trained DDPM. Subsequently, we sample the conditional posterior distribution $y_{t-1}$ through the following equation:\n$p_\\theta(y_{t-1}|y_t) = N(x_{t-1}|\\mu_\\theta(y_t, y_t^x, t), \\Sigma_\\theta(x_t,t))$ (7)\nwhere the mean and variance are aligned with the posterior distribution of the pre-trained DDPM $(x_{t-1}^x)$. We divide the sampling interval by a scalar $\\tau$. In the first stage, i.e. for $t \\geq \\tau$, we mask the $x_{t-1}$ to constrain the sample space, ensuring consistent sampling. We obtain:\n$x_{t-1} = (1 - m_f) \\odot x_{t-1}^x + m_f \\odot y_{t-1}$ (8)\nwhere $m_f \\odot y_{t-1}$ is the Fixed Condition Mask (FCM) and $x_{t-1}$ denotes the new posterior distribution obtained from this CM masking. $x_{t-1}^x$ are injected with conditional information, and in the subsequent sampling, the denoising prior is utilized to interpolate the $x_{t-1}$. In the second stage, fidelity is further enhanced by incorporating a weighted Randomly Adaptive Condition Mask (RACM). When $t < \\tau$, the condition is added as follows:\n$x_{t-1} = (1-m_a)\\odot x_{t-1}^x+wm_a\\odot y_{t-1}+(1-w)m_a\\odot X_{t-1}$ (9)\nwhere $w = t/w$ represents a time-dependent weight controlled by the parameter $w$ and $m_a \\odot y_{t-1}$ is the RACM. w gradually decreases over time steps, leading to a reduction in the intensity of the conditioning."}, {"title": "Condition Masks", "content": "In this section, we will mainly discuss the forms of the CMs and how to design both the strongly constrained FCM and the weakly constrained RACM. With the constraints of different CMs, we can flexibly realize consistent sampling and diversity generation.\nGiven an LR image $I_L$ of size $(h, w)$, the objective of FSR is to upscale it to the size $(H, W)$ of HR image $I_H$ with a scale factor of $H/h$. To achieve this, we first upsample $I_L$ using Bicubic interpolation to the size $(H/k, W/k)$, which serves as the base condition $I_L^{bc}$. Here, the parameter k controls sparsity. Subsequently, we design different forms of masks for the two stages of posterior sampling. Specifically, in the first stage, a fixed mask $m_f$ is designed as shown in Fig. 10. The specific definition of $m_f$ is as follows:\n$m_f(i, j) = \\begin{cases} 1, & \\text{if } i, j \\mod k = 0 \\\\ 0, & \\text{otherwise} \\end{cases}$ (10)\nwhere $m_f \\in R^{H \\times W}$. When k is set to 2, the form of $m_f$ resembles a grid mask with a grid size of 1 pixel. We project $I_L^{bc}$ onto $m_f$ to generate an initial condition, denoted as $y_T$:\n$y_T(i, j) = \\begin{cases} I_L^{bc}(\\frac{i}{k}, \\frac{j}{k}), & \\text{if } m_f(i,j) = 1 \\\\ 0, & \\text{otherwise} \\end{cases}$ (11)\nwhere $I_L^{bc} \\in R^{H \\times W}$ and $y_T \\in R^{H \\times W}$. The $y_T$ is initially composed of information from the LR image, then is updated to an intermediate condition $y_t$ by CRT during the sampling phase. In the second stage, we backtrack the intermediate condition $y_t$ and we obtain $y_t'$:\n$y_t'(i, j) = y_t(ki, kj)$ (12)\nwhere $y_t' \\in R^{H \\times W}$ and $y_t \\in R^{\\frac{H}{k} \\times \\frac{W}{k}}$. In Fig. 10, we illustrate the visualization of $y_t'$. Then, we extract an edge map $\\nabla^2y_t'$ using the first-order Laplacian operator, which exhibits characteristics where pixel values are smaller in low-frequency regions and larger in high-frequency regions. Next, we normalize the edge map to the range of (0-1) to obtain a probability map p:\n$p = \\frac{\\nabla^2y_t' - \\min \\nabla^2y_t'}{\\max \\nabla^2y_t' - \\min \\nabla^2y_t'}$ (13)\nFor each pixel value p(i, j), we use it as a probability and then project it to $m_f$ to generate a randomly adaptive mask $m_a$ as follows:\n$m_a(i, j) = \\begin{cases} 0, & \\text{if } m_f(i,j) = 0 \\\\ 1, & \\text{otherwise with probability } p(\\frac{i}{k}, \\frac{j}{k})* \\end{cases}$ (14)\nwhere $m_a \\in R^{H \\times W}$ and s adjusts the probability distribution. We refer to the aforementioned process as Maskgen $(y_t, s)$. It's important to note that a different $m_a$ is generated at each time step. We generate the RACM by masking the conditional posterior distribution $y_{t-1}^x$ using $m_a$. The RACM exhibits high sparsity and features similar to the edge guidance in ControlNet . This amplifies the prior space, enabling the generation of more texture details, thereby enhancing the fidelity and diversity of the results."}, {"title": "Condition Corrector", "content": "In the real world, LR images often suffer from various unknown degradations, leading to conditions that significantly deviate from the prior manifold. We propose a condition Corrector (CRT), to pull back the conditions to the prior space and establish a reciprocal sampling, as illustrated in Fig. 11. CRT is a small neural network conditioned on the initial condition $y_T$, designed to denoise the posterior distribution of the ground truth (GT) and predict GT conditions. The loss function of CRT is defined as follows:\n$L_{prior} = ||I_G \\odot m_f - CRT(m_f \\odot I_{G_{t-1}}', y_T,t)||_2$ (15)\nwhere CRT() stands for the CRT function, $I_G$ represents the GT image and $I_{G_{t-1}}'$ is obtained by Eq. 3. Building upon the assumptions presented in , it is assumed that there exists a time step $\\gamma$ such that for $t > \\gamma$, the distance between $q(x_t|x)$ and $q(y_t|y)$ becomes sufficiently small. At this point, we can get the approximate estimate:\n$y_{t-1} = CRT(m_f \\odot y_{t-1}, y_T,t) \\approx CRT(m_f \\odot I_{G_{t-1}}', y_T,t)$ (16)\nHowever, the CRT is essentially a discriminative model that favors the average output and the gap between $q(x_t|x)$ and $q(y_t|y)$ progressively increases for $t < \\gamma$. For this reason, we need to adapt the CRT to the intermediate conditions as well as mitigate the gap. Ultimately, the objective function for training the CRT is as follows:\n$L_{gap} = ||I_G \\odot m_f - CRT(m_f \\odot crt, y_T, t)||_2$ (17)\n$L_{crt} = \\lambda L_{prior} + (1 - \\lambda) L_{gap}$ (18)"}, {"title": "Experimental Setup", "content": "We employ a pre-trained DDPM from DPS . The model is pre-trained on 49k face images from FFHQ at a resolution of 256 \u00d7 256. For evaluation, we utilize synthetic datasets FFHQ1000 and CelebA1000, along with real-world datasets LFW, WebPhoto, and WIDER, serving as our testsets. Following the settings of the latest diffusion-based methods , we compare them on synthetic datasets at scales of \u00d74, x8, and \u00d716. Additionally, for each of these three scales, the parameters ($\\tau$, s, w) is set to (100, 1.4, 500), (300, 1.2, 750), and (500, 1, 1000) respectively. For real-world datasets, we adhere to the experimental settings in CodeFormer , with fixed parameters set to (500, 1, 1000). The sparsity parameter k for CMs is set to 2 for all experiments."}, {"title": "Comparison with Previous Work", "content": "Synthetic Datasets: Diffusion-based FSR works typically use Bicubic settings of different scales as benchmarks. For this purpose, we train CRT at different scales to compare them . All Table 1 demonstrates the outstanding performance of DPI across all scales, showcasing SOTA perceptual metrics compared to other diffusion-based methods. Fig. 13 illustrates DPI's superior performance in visual consistency.\nReal-world Datasets: We adhere to the general degradation model represented as follows:\n$I_L = \\{\\[(I_H \\otimes k_{\\sigma,s})\\downarrow_r + n_s]JEPG_q\\}\\downarrow_r$ (19)\nwhere $k_{\\sigma,s}$ denotes a Gaussian blur kernel with a kernel size of s, $n_s$ represents Gaussian noise, JPEGq signifies compression with quality q, and r denotes the sampling scale. CRT is trained on this degradation model to address real-world issues. Our DPI achieves SOTA performance in no-reference metrics on three real-world datasets, as shown in Table 7. We demonstrate the diversity generation capability of DPI in Fig. 12."}, {"title": "Ablation Studies", "content": "In this section, we conduct ablation experiments to analyze the effects of strong and weak constraints, masking strategies, and hyperparameters on consistency and diversity. All ablation studies are performed on the CelebA1000 testset at a scale of \u00d7 8. Please refer to the visual ablation studies in Appendix D for further insight.\nEffectiveness of Condition Correction and Refinement: The conditions undergo pixel correction and iterative refinement to provide accurate guidance. Initially, the degraded pixels' impact on performance is analyzed by not using the CRT to repair the conditions. Subsequently, the corrected condition are used solely as conditions at each time step without participating in the iterative refinement. As shown in the the second and third columns of Table 4, degraded pixels lead to poor metrics and significantly affect image quality, while the absence of refinement only marginally impacts performance.\nBalancing Consistency and Diversity: Our proposed method allows the user to tune the consistency and diversity of FSR by simply adjusting the scalar values, as shown in Fig. 8. In our default settings (Fig. 8 (e)), the parameters ($\\tau$, s, w) are set to (300, 1.2, 750). We will elaborate on the impact of these scalars on the results: 1) By adjusting $\\tau$, we can flexibly partition the sampling stages. Increasing the range of the second stage significantly enhances diversity, while conversely improving consistency. As seen in the fourth column of Table 4, removing the second stage ($\\tau$ = 0) initially yields the best SSIM, but the FID metric noticeably increases, indicating enhanced consistency but reduced fidelity. The second row of Fig. 8 (e-g) clearly demonstrates that increasing $\\tau$ leads to greater diversity. 2) Under the premise of ensuring consistency (Fig. 8 (e, j, k)), we fine-tune the diversity by changing the sparsity. 3) In Eq. 9, w is used to reduce conditional intensity for better utilization of prior information. A larger w implies a smaller weight attached to the condition. From the comparison in Fig. 8 (b) and (c), reducing conditions intensity enhances fidelity and diversity, such as details in hair. The ablation study in the sixth column of Table 4 also confirms this. Furthermore, the comparison of Fig. 8 (f) and Fig. 8 (h) reflects the control of s and w over consistency and diversity."}, {"title": "Conclusion", "content": "We propose DPI, which effectively leverages the prior knowledge of pre-trained models for face super-resolution. By implementing a masking strategy tailored to facial features, we achieve a balance between consistency and diversity during the sampling process. Additionally, we introduce CRT to establish a reciprocal sampling process, where samples and conditions are iteratively refined. Extensive experiments demonstrate the superior performance of DPI and its ability to ensure consistency."}, {"title": "A. Diffusion Prior Interpolation with DDIM", "content": "Algorithm 2 demonstrates the utilization of DDIM for our DPI. As the sampling interval is compressed, it necessitates the adjustment of parameters. We set the hyperparameters ($\\tau$, s, w) for different tasks (x4, x8, x16, real) as (6, 1.8, 15), (7, 1.4, 30), (7, 1.4, 60) and (7, 1.4, 60) respectively. n is set to 0.1 for all experiments. It is noteworthy that the condition Corrector (CRT) has not undergone retraining with respect to the rescaled noise scheduler. As shown in Fig. 10, we present visualization results at different steps. It can be observed that with an increase in the number of steps, the images exhibit higher fidelity."}, {"title": "B. Condition Corrector", "content": "The condition Corrector (CRT) proposed in this paper employs a U-Net architecture sourced from. We utilize the Adam optimizer with parameters $\\beta_1$ = 0.9 and $\\beta_2$ = 0.999 for training. Throughout all experiments, we employ an exponential moving average (EMA) decay rate of 0.9999. The PyTorch framework is employed, and the training is conducted in parallel on 3080Ti GPUs with a batch size of 32. For all experiments, CRT is trained on the FFHQ dataset using various degradation models. For instance, in synthetic experiments, we train CRT at different scales, while for real-world experiments, we train CRT based on the degradation model described in Eq. 19. CRT is applicable to any pre-trained face diffusion model. Furthermore, the model architecture of CRT is not constrained to a specific structure.\nWe train the network using the GT posterior distribution $I_{G_{t-1}}$ as input, with the initial condition $y_T$ and time t as conditions, as depicted in Fig. 9. The grayscale $y_T$ is directly added to the feature extraction layer, and we apply residual learning. This approach offers the advantage that the CRT consistently produces accurate conditions, regardless of the noise intensity in the posterior distribution. Specifically, the CRT can extract meaningful features from the input or condition $y_T$ to produce the desired output. Moreover, conventional techniques that combine discriminative and generative models, such as , typically involve generating initial blurry images using MSE-based estimations, followed by enriching details using generative models to attain high-quality images. However, these methods lack the capability to refine samples alongside pre-trained models. Our proposed method adheres to the paradigm of diffusion model sampling and seamlessly integrates into the posterior, enabling the CRT to refine the conditions throughout the entire sampling process, providing precise guidance."}, {"title": "C. More Experiments", "content": "We conduct comprehensive experiments to validate the superiority of our algorithm compared to other diffusion-based methods, including DDRM , DDNM , SR3 , ILVR , DR2 , DPS , DiffFace , and PGdiff. Among these approaches, only SR3 requires training from scratch, while the others are based on pre-trained models. Our method, along with DDRM and other diffusion-based methods, utilizes the same pre-"}, {"title": "D. Complexity analysis", "content": "Since SR3 and DiffFace require training a diffusion model from scratch, we do not compare their complexity with other methods. Most other works rely on the Guided Diffusion framework and pre-trained weights, which allows for a fair complexity analysis. Methods based on pre-trained diffusion models generally have similar generation speeds to the orig-"}, {"title": "E. Visualizations of Ablation Studies", "content": "Here, we present visualizations of ablation studies to better understand the impact of hyperparameters on the balance between consistency and diversity. From left to right in Fig. 12, several key observations can be made. Firstly, it is evident that the application of the CRT has the most pronounced impact on image quality (first column). This phenomenon arises from the fact that the degradation cues impose erroneous guidance, causing the results to conform closely to the manifold of the LR representation. When $r = 0$, we furnish the entire sampling with the corrected Fix Conditional Mask (FCM). While the FCM offers commendable consistency guidance, it is worth noting that deficiencies in MSE estimator, compounded by the high intensity of FCM, contribute to generating suboptimal results in regions demanding intricate textural details (second column). The results of applying the Randomly Adaptive Conditional Mask (RACM) without weighted are demonstrated in Fig. 12, appearing in the third column, wherein heightened texture details in high-frequency regions such as hair and eyes are evident."}, {"title": "F. Discussion and Limitations", "content": "The real-world degradation model encompasses various downstream tasks such as denoising, deblurring, image enhancement, and super-resolution. Our approach is effective in handling real-world and mixed degradation scenarios, meaning that DPI is capable of addressing individual sub-tasks efficiently. Moreover, DPI is akin to prior-based inpainting methods . Consequently, we do not focus on the specific sub-task of face restoration. In this work, we design a conditional mask specifically for facial priors and validate it across numerous face benchmarks. We find that the distribution of natural images is highly diverse and rich in high-frequency information. Without relying on supervised fine-tuning, it is challenging to ensure high consistency of results solely through conditional prior constraints. For instance, the prior-based diffusion work cited in this paper still requires further exploration for natural image restoration. Furthermore, methods that utilize supervised fine-tuning, such as StableSR, still face challenges in achieving consistency."}, {"title": null, "content": "DPI can be seamlessly adapted for natural image SR. We train a CRT on ImageNet using the degradation model based on Eq. 19 to handle natural images. The hyperparameters in DPI and CRT are consistent with those used for the real-world FSR. We validate natural images using a DDPM pre-trained on ImageNet from DPS , as shown in Fig. 15. Since facial features are relatively fixed and lack complex background information, we can effectively use masking strategies to ensure consistency. However, the details and backgrounds of natural images are more complex. As a result, the effectiveness of ensuring consistency through RACM constraints is diminished."}]}