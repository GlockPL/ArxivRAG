{"title": "From Open Vocabulary to Open World: Teaching Vision Language Models to Detect Novel Objects", "authors": ["Zizhao Li", "Zhengkang Xiang", "Joseph West", "Kourosh Khoshelham"], "abstract": "Traditional object detection methods operate under the closed-set assumption, where models can only detect a fixed number of objects predefined in the training set. Recent works on open vocabulary object detection (OVD) enable the detection of objects defined by an unbounded vocabulary, which reduces the cost of training models for specific tasks. However, OVD heavily relies on accurate prompts provided by an \"oracle\u201d, which limits their use in critical applications such as driving scene perception. OVD models tend to misclassify near-out-of-distribution (NOOD) objects that have similar semantics to known classes, and ignore far-out-of-distribution (FOOD) objects. To address theses limitations, we propose a framework that enables OVD models to operate in open world settings, by identifying and incrementally learning novel objects. To detect FOOD objects, we propose Open World Embedding Learning (OWEL) and introduce the concept of Pseudo Unknown Embedding which infers the location of unknown classes in a continuous semantic space based on the information of known classes. We also propose Multi-Scale Contrastive Anchor Learning (MSCAL), which enables the identification of misclassified unknown objects by promoting the intra-class consistency of object embeddings at different scales. The proposed method achieves state-of-the-art performance in common open world object detection and autonomous driving benchmarks.", "sections": [{"title": "1. Introduction", "content": "Object detection is a fundamental computer vision task, which involves localization and classification of foreground objects. Although there has been significant progress in this area, many methods rely on the closed-set assumption [3, 11, 12, 28, 29, 48, 49, 60], where all object categories to be predicted are available in the training set.\nIn many real world applications, such as autonomous driving, the closed-set assumption is unrealistic and even dangerous, because it forces the model to misclassify or ignore unknown objects [6]. Scheirer et al. [52] defines the problem of rejecting unknown classes (U) and simultaneously classifying known classes (K) as open set recognition (OSR). Subsequent works [6, 40] extend this problem to open set object detection (OSOD). Joseph et al. [19] further proposes Open World Object Detection (OWOD), which involves detecting both known and unknown objects and incrementally learning new classes.\nOpen world object detection is a challenging task due to the complexity of both open-set recognition [6, 40] and incremental learning [56]. The model must generalize beyond predefined classes to capture the objectness of diverse unknown objects, and avoid confusing them with known classes. Additionally, it needs to incrementally learn new classes without forgetting previously acquired knowledge. Despite some progress [14, 19, 33, 35, 58, 64, 67, 68, 72] in this area, several key issues still remain unresolved. Many existing methods perform poorly at discovering unknown objects, leading to low recall for unknown classes. Additionally, existing OWOD methods [14, 19, 33, 35, 58, 64, 67, 68, 72] employ a replay strategy during incremental learning, where data from previous tasks are reintroduced"}, {"title": "2. Related Works", "content": "Open World Object Detection Closed set object detection has been extensively studied over the past decade [3, 11, 12, 28, 29, 48, 49, 60]. To handle unknown objects and incrementally learn new classes, Joseph et al. [19] first proposed an open world object detector, which extends the Faster R-CNN [49] with contrastive clustering and energy-based unknown-object identification. Subsequent works [14, 35] used contextual information to improve unknown identification and knowledge transfer between known and unknown classes. To effectively detect unknown objects, Zohar et al. [72] proposed Probabilistic Objectness (PROB) to estimate the objectness of different proposals. Wang et al. [64] introduced random proposals in detector training to encourage the unknown discovery and reduce confusion between known and unknown classes. Ma et al. [33] proposed decoupling object localization and classification via cascade decoding. Sun et al. [58] further decorrelates objectness and class information by enforcing orthogonality.\nOpen Vocabulary Object Detection Open vocabulary object detection (OVD) aims to detect novel classes with the help of vocabulary knowledge [65]. OVD methods are implemented in various ways, including knowledge distillation [13, 37, 46], region-text pretraining [5, 23, 69] and"}, {"title": "3. Method", "content": "Problem Definition Open World Object Detection (OWOD) [19] aims to detect both known and unknown objects while continuously learning new classes. At an arbitrary stage t, we consider the known classes as $K_t = \\{1, ..., N\\}$, and unknown classes as U. An OWOD model should be able to detect objects in $K_t$ and $U$, and extend known classes to $K_{t+1} = K_t \\cup \\{N + 1, ..., N + k\\}$ when k new classes are provided by human annotator. In this way, the object detector continuously discovers and learns new classes in the open world.\nGeneral Architecture Fig. 2 shows the general architecture of the proposed method. Following [5], we use text T and image I as inputs and match the text embeddings with image embeddings to predict class labels and bounding boxes of objects. Let $W_K = \\{W_1,...,w_n\\}$ denote the text embedding of N known classes, which is initialized from class names encoded by the pre-trained CLIP [45] text encoder. $W_K$ can be parameterized as model's weight and optimized via Open World Embedding Learning (OWEL). During inference, a pseudo unknown embedding is constructed and appended to $W_k$, and the CLIP text encoder is disposable. The image encoder (DarkNet backbone inherited from Yolo v8 [18, 47]) extracts multi-scale features C from the input image I. Then the multi-modal neck (RepVL-PAN [5]) uses multi-level cross-modal fusion to combine image and text features, forming the feature pyramids P. The detection head predicts bounding boxes and class labels by matching the cosine similarity of text embedding with each spatial location in P. Concurrently, MSCAL modules make dense predictions of out-of-distribution (OOD) scores and reject unknown bounding boxes in the detection head. Finally, the redundant predictions are filtered by Non-Maximum Suppression (NMS).\nOpen World Embedding Learning Large pre-trained vision-language models have spawned many prompt learning methods [1, 70, 71], which optimize text prompts rather than fine-tune the entire model to improve performance in downstream tasks. But they are not suitable for OWOD, because known K and unknown U classes are ever-changing. To address this, we propose a simple and effective way to learn new classes and detect unknown objects, called Open World Embedding Learning (OWEL). For N known classes, we initialize known class embeddings $W_{\\kappa} = \\{1, ..., w_n\\}$, and optimize them with the object detection loss. When k new classes are introduced, we simply freeze $W_k$ and train new class embeddings.\nAs shown in Fig. 1, when an OVD model is given an unknown object, it will either misclassify it as a semantically similar text prompt, or ignore it if the semantic difference"}, {"title": "4. Experiments", "content": "Datasets\nWe evaluate our method with common open world object detection benchmarks used in previous works [33, 58, 72], and proposal a novel benchmark of OWOD for autonomous driving. Common OWOD benchmarks include the superclass-mixed benchmark (M-OWODB) [19] and the superclass-separated benchmark (S-OWODB) [14]. The M-OWODB benchmark combines COCO [27] and PASCAL VOC [8], while the S-OWODB benchmark is based solely on COCO. Both are divided into four distinct tasks, where the model learns some new classes in each task, while the remaining classes are unknown. Additionally, we propose"}]}