{"title": "Comparative Analysis of Deep Learning Approaches for Harmful Brain Activity Detection Using EEG", "authors": ["Shivraj Singh Bhatti", "Aryan Yadav", "Mitali Monga", "Neeraj Kumar"], "abstract": "The classification of harmful brain activities, such as seizures and periodic discharges, play a vital role in neurocritical care, enabling timely diagnosis and intervention. Electroencephalography (EEG) provides a non-invasive method for monitoring brain activity, but the manual interpretation of EEG signals are time-consuming and rely heavily on expert judgment. This study presents a comparative analysis of deep learning architectures, including Convolutional Neural Networks (CNNs), Vision Transformers (ViTs), and EEGNet, applied to the classification of harmful brain activities using both raw EEG data and time-frequency representations generated through Continuous Wavelet Transform (CWT). We evaluate the performance of these models use multimodal data representations, including high-resolution spectrograms and waveform data, and introduce a multi-stage training strategy to improve model robustness. Our results show that training strategies, data preprocessing, and augmentation techniques are as critical to model success as architecture choice, with multi-stage TinyViT and EfficientNet demonstrating superior performance. The findings underscore the importance of robust training regimes in achieving accurate and efficient EEG classification, providing valuable insights for deploying AI models in clinical practice.", "sections": [{"title": "I. INTRODUCTION", "content": "The accurate interpretation of electroencephalogram (EEG) signals are essential for diagnosing neurological conditions such as seizures, Generalized Periodic Discharges (GPD), Lateralized Periodic Discharges (LPD), and other harmful brain activities [1]. Traditionally, expert neurologists manually review these recordings a process that is time-consuming, subjective, and difficult to scale [2]. The increasing availability of large EEG datasets, coupled with advancements in machine learning [3], offers the potential to automate this process, enabling the efficient analysis of complex brain activity patterns [4].\nEEG signals are non-stationary and present complex time-frequency characteristics, making them challenging to interpret using traditional methods. Transforming EEG data into time-frequency representations, such as spectrograms generated through the Continuous Wavelet Transform (CWT) [5], enables machine learning models to capture the dynamic oscillatory patterns of neural activity [6]. Spectrograms provide a structured visual format ideal for models to process, especially in deep learning contexts [7], [8].\nRecent advances in deep learning have positioned Convolutional Neural Networks (CNNs) [9] and Vision Transformers (ViTs) [10] as promising approaches for EEG classification [8]. CNNs excel at extracting spatial patterns from spectrograms [11], while Vision Transformers, with their self-attention mechanisms, capture long-range dependencies across spectrogram data [6], [13]. Additionally, specialized architectures like EEGNet, designed specifically for EEG data, offer efficient and compact solutions for EEG-based tasks [12].\nThis study focuses on modelling how expert neurologists classify EEG signals-whether waveforms or spectrograms-into categories of harmful brain activity. Expert labels are generated based on their consensus votes over EEG data, and the aim is to replicate their decision-making process through machine learning models [2], [4]. The study includes both deep learning models and Gradient Boosting Models (GBMs) such as CatBoost, despite the need for feature engineering with GBMs in unstructured data like EEG [14]. GBMs are included to provide a baseline for comparison, emphasizing interpretability and computational efficiency [1], which are crucial in clinical settings [13].\nA key insight from recent research and experimental platforms (e.g., the work from Barnett et al. [4] and public experimentation at the 2024 HMS: Harmful Brain Activity Classification Contest hosted by Kaggle) is that training strategies such as data preprocessing, augmentation, and multi-stage training-often plays a larger role in performance than the specific architecture itself [2], [6]. By comparing CNNs, ViTs, and CatBoost under uniform training strategies, this study identifies the factors that most significantly influence classification accuracy in EEG data. This research builds on the insights gained from previous works and experimental results, aiming to identify the most effective strategies for deploying EEG analysis systems in clinical settings."}, {"title": "II. LITERATURE SURVEY", "content": "This literature survey reviews key developments in machine learning models, particularly deep learning, for classifying harmful brain activities from EEG data. It covers Spectrogram-based EEG analysis, transformer-based architectures, and how training strategies affect model performance."}, {"title": "A. Machine Learning in EEG Classification", "content": "EEG signals, known for their non-stationary and noisy nature, have long posed challenges in effective classification. Early approaches by Shoeb et al. [1] demonstrated the potential of machine learning for automating manual EEG review, particularly using Support Vector Machines (SVMs) for seizure detection. This foundational work set the stage for the adoption of more advanced techniques like deep learning [15]."}, {"title": "B. Deep Learning Architectures in EEG", "content": "Recent advancements in deep learning, specifically the use of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), have reshaped EEG analysis. Roy et al. [6] and Acharya et al. [9] demonstrated the effectiveness of CNNs in capturing time-frequency representations of EEG data, improving the detection of seizures and other harmful brain activities. Lawhern et al. [12] introduced EEGNet, a compact neural network optimized for EEG tasks, providing a lightweight yet effective solution for EEG classification, especially in clinical environments with limited computational resources."}, {"title": "C. Spectrograms as Preprocessing for EEG Analysis", "content": "Spectrograms have become a common preprocessing step, transforming EEG signals into time-frequency representations [16]. Bashivan et al. [5] and Roy et al. [6] demonstrated that using spectrograms significantly enhances model performance by enabling models to capture both temporal and frequency-based features. These representations are particularly useful for deep learning models like CNNs and transformers, which excel in image-based and sequential data tasks [15], [17]."}, {"title": "D. Transformer Based Models", "content": "Transformers [19] have emerged as a powerful alternative to traditional deep learning methods in EEG classification, especially for handling complex data. Vision Transformers (ViTs), introduced by Dosovitskiy et al. [10], leverage self-attention mechanisms to model long-range dependencies, offering improved performance on EEG data. Ortega Caro et al. [18] demonstrated the utility of transformers in fMRI and brain activity recordings with BrainLM, and Kerr et al. [15] showed how transformer-based models offer strong potential for continuous seizure detection and brain activity classification."}, {"title": "E. Comparative Analysis of Machine Learning Models", "content": "Several studies have conducted comparative analyses of traditional machine learning models versus deep learning architectures for EEG classification. Schirrmeister et al. [11] compared SVMs, Random Forests, and deep learning models (CNNs and LSTMs), finding that deep learning approaches consistently outperformed traditional methods. Pfeffer et al. [13] showed that transformers [18], although more computationally demanding, achieved superior performance over CNNs in handling large, complex EEG datasets."}, {"title": "F. Practical Adoption Challenges", "content": "Despite advancements, challenges remain in the clinical adoption of deep learning models for EEG classification. Shoeb [1] and Acharya et al. [13] highlighted the difficulties in scaling models from controlled, small datasets to real-world clinical environments. Additionally, interpretability and computational resource requirements remain significant barriers to the deployment of deep learning models in practice, as discussed by Schirrmeister et al. [11] and Jing et al. [2]."}, {"title": "G. Recent Advances and Training Techniques", "content": "Recent studies have focused on improving the performance and efficiency of deep learning models for EEG analysis. Kerr et al. [15] explored transformer-based models for continuous seizure detection, highlighting their ability to reduce false positives while maintaining high sensitivity. Additionally, public experimentation platforms like HMS: HBAC 2024 have provided opportunities to rapidly test a diverse variety of methods, suggesting that training protocols often outweigh architectural choices in their impact on performance [6]."}, {"title": "III. METHODOLOGY", "content": ""}, {"title": "A. Data Characteristics and Representation", "content": "The training dataset contains 106,800 rows with 17,089 unique EEG IDs, 11,138 unique spectrogram IDs, and 1,950 unique patients. Each row represents a specific 50-second EEG window and a corresponding 600-second spectrogram window. The models predict the event occurring in the middle 10 seconds of these windows. EEG data is stored in parquet files, each containing multiple rows, while spectrogram data is stored in fewer parquet files due to shared time windows across rows."}, {"title": "B. Data Preprocessing", "content": "\u2022 EEG-HR: High-resolution EEG waveform segments, 50\nseconds long, sampled at 200 Hz.\n\u2022 Spec-HR: High-resolution spectrograms generated from\nthe raw EEG Data, using CWT and the Double Banana\nmontage, focusing on a frequency range of 0.5-40 Hz,\n40 scales, and a stride of 16.\n\u2022 Spec-LR: Low-resolution spectrograms generated from\nlonger 10-minute EEG segments, providing broader but\nless temporally granular insights. [2]\nA Butterworth bandpass filter (0.5\u201320 Hz) was applied with\nclipping to ensure data consistency across electrodes."}, {"title": "C. Data Augmentation", "content": "For 2-D models, several augmentation techniques were employed. XY Masking involved random masking of 1 to 8 spectrogram nodes in 50% of the samples, simulating missing or noisy data. Mixup combined spectrogram images and labels during training, promoting generalization by generating new data points as weighted combinations of the original samples. Window Shifting augmented the training data by shifting the central 50s window by up to 5 seconds, introducing temporal variability in the data.\nFor 1-D models, augmentations such as the Left-Right Flip were applied, randomly flipping the EEG signal temporally to simulate different orientations of brain activity. Additionally, the Brain-Side Flip randomly switched the left-right brain data, further capturing variability in spatial brain signal distributions.\nThese augmentations helped capture spatial and temporal variability in the brain's electrical activity, improving the model's ability to generalize to unseen EEG data."}, {"title": "D. Training Procedure", "content": "The training procedure follows a two-stage approach: Stage 1: High-Confidence Data: Models were trained us-ing data with \u2265 10 expert votes, focusing on reliable and consensus-labeled examples. Cosine Annealing's learning rate scheduler with an initial learning rate of 0.0012 and a batch size of 32 was used for 5 epochs."}, {"title": "E. Model Architectures", "content": "MLP Multilabel Classifier: Baseline model.\nWaveNet: WaveNet is adapted for raw EEG waveform processing, learning long-term dependencies through causal convolutions [15].\nCatBoost: CatBoost is a gradient-boosting model used for both spectrogram and waveform features, offering interpretability and efficiency [10], [13].\nEfficientNetB2: EfficientNetB2 is pre-trained on ImageNet and processes spectrograms using its CNN architecture [6].\nEEGNet: EEGNet is a compact neural network optimized for EEG tasks, trained directly on raw EEG features [1].\nResNet34d: CNN pre-trained on the CIFAR-10 dataset, with residual connections to capture hierarchical patterns [5].\nEEGNet & EfficientNet/TinyViT Ensemble: This setup combines a 1-D CNN model (EEGNet) with either Efficient-Net or TinyViT as the 2-D backbone to capture temporal dynamics from EEG waveforms and feature embeddings from spectrograms. A two-stage training process is employed, where each ensemble is first trained on high-confidence samples for 5 epochs and then fine-tuned on the broader dataset for an additional 15 epochs, for a total of 20 epochs. The outputs from the 1-D EEGNet and the 2-D EfficientNet or Tiny ViT models are concatenated in a final layer, allowing for a direct comparison between EfficientNet and TinyViT in terms of their ability to process high-resolution spectrograms for EEG classification [5], [18]."}, {"title": "F. Model Evaluation", "content": "The performance of the models was evaluated using KL Di-vergence across cross-validation folds, assessing the alignment between model predictions and the true label distributions [11].\n$D_{KL}(P || Q) = \\sum P(i) log \\frac{P(i)}{Q(i)}$\nAs shown in Equation 2, the Kullback-Leibler (KL) Di-vergence measures the difference between two probability distributions P and Q."}, {"title": "IV. RESULTS", "content": "This section provides a comprehensive analysis of the models used in the study, evaluating their performance and discussing key insights gained from training and testing on the EEG dataset.\nThe selected epoch count aimed to balance computational efficiency with effective model convergence. For smaller mod-els, we limited training to 4-5 epochs, as extending further led to overfitting and did not yield significant gains in perfor-mance. This conservative approach prevented excessive train-ing on limited data, avoiding diminishing returns. Although preliminary tests indicated that additional epochs had limited impact, future exploration with increased epoch counts could provide further insights into model robustness and convergence behaviour."}, {"title": "A. Model Performance Analysis", "content": "MLP Multilabel Classifier: The MLP, a shallow architecture lacking the ability to capture complex spatial and temporal patterns in the EEG data, performed poorly, with a cross-validation (CV) score of 1.037 and an inference score of 0.77. This highlights the limitations of simple architectures when dealing with intricate EEG data, which requires advanced feature extraction methods for accurate classification.\nWaveNet: WaveNet, designed for sequential data, was applied to raw EEG waveforms and performed moderately well, achieving a CV score of 0.91 and an inference score of 0.66. The model's ability to capture long-term dependencies in raw EEG data through causal convolutions was beneficial, though it struggled with spectrogram data, which requires a different processing approach.\nCatBoost: CatBoost, a gradient-boosting model applied to both raw EEG and spectrogram data, showed reasonable results with a CV score of 0.74 and an inference score of 0.60. Although it excels in handling structured data, its lack of deep spatial and temporal feature extraction capabilities limited its overall performance on the unstructured, high-resolution EEG spectrogram data.\nEfficientNetB2 & EfficientNetB0: EfficientNetB2 performed better than its smaller variant EfficientNetB0, with a CV score of 0.72 and an inference score of 0.57. EfficientNetB0, after undergoing multi-stage training (with high-confidence labels followed by full dataset fine-tuning), improved significantly, achieving a CV score of 0.34 and an inference score of 0.26. This multi-stage training approach helped mitigate overfitting and align the model better with the expert-labeled test data.\nAnalysis of the Confusion Matrix: Although confusion matrices provide a breakdown of true positives, false positives, and misclassifications across different classes, they offer limited value for EEG classification tasks like ours, where understanding the model's probabilistic predictions is more critical. The confusion matrix presented (see Figure 5) highlights the model's ability to classify harmful brain activities, but it oversimplifies the complex decision-making process involved in EEG analysis.\nOur models produce probability distributions across multiple potential classes, and focusing solely on the final predicted labels, as in a confusion matrix, neglects the importance of prediction confidence. In clinical applications, this confidence is vital, particularly when distinguishing between closely related classes like Seizures and LPDs. Therefore, metrics such as Kullback-Leibler (KL) divergence provides a more nuanced evaluation by assessing how well the predicted probability distribution aligns with the true class distribution, reflecting the model's uncertainty and confidence more effectively than traditional evaluation methods.\nEEGNet: Specifically designed for EEG data, EEGNet demonstrated strong performance on raw EEG data, with a CV score of 0.69 and an inference score of 0.58. Its architecture, which captures spatial-temporal EEG patterns without requiring a frequency transformation, allowed it to handle raw data efficiently. However, it was slightly outperformed by models trained on spectrogram data, which provided richer feature representations.\nResNet34d: ResNet34d, used for spectrogram analysis, performed well on low-resolution spectrograms, with a CV score of 0.715 and an inference score of 0.49. The residual connections in ResNet allowed the model to capture hierarchical patterns in the spectrogram data. However, its depth was not sufficient to outperform more modern transformer-based approaches, particularly in the multi-stage setups.\nTinyViT and Multi-Stage EfficientNet Ensemble: TinyViT, a variant of the Vision Transformer (ViT), was selected for its compact and efficient architecture, particularly suited to noisy EEG data. The multi-stage TinyViT model achieved the best results, with a CV score of 0.24 and an inference score of 0.24. EfficientNetB0, using a similar multi-stage approach, also improved significantly (CV score: 0.34, inference score: 0.26). However, TinyViT outperformed EfficientNetB0, particularly in terms of generalization and computational efficiency, due to its pretraining and knowledge distillation techniques."}, {"title": "B. Key Insights and Discussion", "content": "Training Strategy Over Model Choice: Across all mod-els, the two-stage training approach-pre-training on high-confidence samples followed by fine-tuning the broader dataset-proved to be the most effective strategy. This finding aligns with existing research, such as SPaRCNet and Improving Clinician Performance, which emphasizes the importance of training strategies in handling variable and noisy EEG data. TinyViT and EfficientNet models, when trained in this staged manner demonstrated significant improvements over their single-stage counterparts, supporting the idea that a tailored training regimen is often more crucial than the model architecture itself.\nPreprocessing and Data Representation: Spectrogram-based models consistently outperformed those trained solely on raw EEG data. The Continuous Wavelet Transform (CWT), used to generate time-frequency spectrograms, allowed models to capture complex oscillatory patterns that were not easily extractable from raw waveforms. The Double Banana Montage further enhanced feature extraction by reducing noise and emphasizing spatial information, much like expert neurologists' clinical practice of examining different brain regions through montages.\nAugmentation and Regularization: Augmentation tech-niques, particularly those mimicking real-world variability (e.g., channel flipping, signal distortion), played a critical role in reducing overfitting. Models trained with such augmentations, including TinyViT and EfficientNet, showed better generalization during cross-validation and inference. These augmentations helped simulate clinical scenarios where EEG data might be noisier or more difficult to interpret.\nMulti-Modal Architectures: Models that leveraged both raw EEG waveforms and spectrograms, such as the multi-stage TinyViT and EfficientNetB0, benefited from the ability to extract complementary features from both time-domain and frequency-domain representations. This multi-modal approach mirrors clinical practices, where EEG readings are evaluated from multiple perspectives (e.g., time-domain waveforms and frequency-domain analyses) to provide a comprehensive view of brain activity.\nState-of-the-Art Models: Not Always the Best Choice: Surprisingly, smaller and more efficient models like TinyViT outperformed larger, state-of-the-art architectures such as the full-size Vision Transformers (ViT). While larger models often overfit the small and noisy EEG dataset, TinyViT's compact architecture, when paired with pretraining and multi-stage training, provided more consistent and robust performance. This underscores the importance of choosing models that balance complexity with the specific characteristics of the dataset at hand."}, {"title": "Limitations", "content": "This study is limited by dataset size, class imbalance, and dependence on high-quality spectrograms, which may impact generalizability to more diverse and minimally processed EEG datasets. Additionally, our approach does not fully explore model ensembling, which could enhance robustness by integrating complementary strengths across architectures. Further work is needed to address interpretability challenges and to develop preprocessing techniques that effectively expand the dataset while preserving clinical relevance."}, {"title": "V. CONCLUSION", "content": "This study explored a variety of machine learning architectures and training strategies for EEG classification, demonstrating that the most significant performance improvements stem not solely from adopting state-of-the-art models, but from employing an optimized combination of data preprocessing, multi-stage training strategies, and effective augmentation techniques. The results show that models like TinyViT and EfficientNet, when paired with multi-stage training and multimodal data representations, significantly outperform their single-stage counterparts. This highlights the critical role that training regimes and preprocessing play in handling the inherent noise and complexity of EEG data.\nThe insights gained from comparing these models under uniform training conditions build upon and extend the work of previous research, such as SPaRCNet [2] and Improving Clinician Performance in EEG Classification [4], by demonstrating the potential of AI-based classification tools to assist clinicians in diagnosing harmful brain activities. The findings underscore the importance of tailoring models to the specific characteristics of EEG signals, focusing on strategies that enhance both model robustness and generalization to clinical datasets. As the field advances, future research should prioritize refining these techniques and further exploring multimodal data integration to bolster the clinical applicability and reliability of AI-driven EEG analysis."}]}