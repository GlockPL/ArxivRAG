{"title": "BRIDGING THE DATA PROVENANCE GAP ACROSS TEXT, SPEECH, AND VIDEO", "authors": ["Shayne Longpre", "Nikhil Singh", "Manuel Cherep", "Kushagra Tiwary", "Joanna Materzynska", "William Brannon", "Robert Mahari", "Manan Dey", "Mohammed Hamdy", "Nayan Saxena", "Ahmad Mustafa Anis", "Emad A. Alghamdi", "Vu Minh Chien", "Naana Obeng-Marnu", "Da Yin", "Kun Qian", "Yizhi Li", "Minnie Liang", "An Dinh", "Shrestha Mohanty", "Deividas Mataciunas", "Tobin South", "Jianguo Zhang", "Ariel N. Lee", "Campbell S. Lund", "Christopher Klamm", "Damien Sileo", "Diganta Misra", "Enrico Shippole", "Kevin Klyman", "Lester JV Miranda", "Niklas Muennighoff", "Seonghyeon Ye", "Seungone Kim", "Vipul Gupta", "Vivek Sharma", "Xuhui Zhou", "Caiming Xiong", "Luis Villa", "Stella Biderman", "Alex Pentland", "Sara Hooker", "Jad Kabbara"], "abstract": "Progress in Al is driven largely by the scale and quality of training data. Despite this, there is a deficit of empirical analysis examining the attributes of well-established datasets beyond text. In this work we conduct the largest and first-of-its-kind longitudinal audit across modalities-popular text, speech, and video datasets\u2014 from their detailed sourcing trends and use restrictions to their geographical and linguistic representation. Our manual analysis covers nearly 4000 public datasets between 1990-2024, spanning 608 languages, 798 sources, 659 organizations, and 67 countries. We find that multimodal machine learning applications have overwhelmingly turned to web-crawled, synthetic, and social media platforms, such as YouTube, for their training sets, eclipsing all other sources since 2019. Secondly, tracing the chain of dataset derivations we find that while less than 33% of datasets are restrictively licensed, over 80% of the source content in widely- used text, speech, and video datasets, carry non-commercial restrictions. Finally, counter to the rising number of languages and geographies represented in public AI training datasets, our audit demonstrates measures of relative geographical and multilingual representation have failed to significantly improve their coverage since 2013. We believe the breadth of our audit enables us to empirically examine trends in data sourcing, restrictions, and Western-centricity at an ecosystem-level, and that visibility into these questions are essential to progress in responsible AI. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire multimodal audit, allowing practitioners to trace data provenance across text, speech, and video.", "sections": [{"title": "1 INTRODUCTION", "content": "The capabilities and flaws of multimodal foundation models are often directly attributable to their training data [66], [74], [75], [90], [91], [117], [130]. While the importance of data measurement has been widely established by prior work [118], so has a prevailing absence of data documentation [10], [39], transparency [73], and detailed understanding [34], [37], [47]\u2014especially for modalities other than text. A lack of thorough data analysis has led to significant challenges, including privacy issues [107], retracting datasets with harmful content [35], [80], adversarially bypassing safety filters [66], facial recognition bias with respect to gender and skin type [11], gender bias in hiring [77], benchmark contamination from overlapping train and test sets [87], and challenges in copyright [84]. Understanding data provenance can aid mitigation attempts to reduce model bias and toxicity [50], [102] address representation in data [51], contamination [81], and quality [59], [95], as well as practical challenges with identifying copyright-free and permissively licensed sets [96]."}, {"title": "2 METHODOLOGY", "content": "While many prior works have surveyed the dataset ecosystem [15], [42], [103], [114], [121], few empirically examine data corpora at scale, and those that do focus present a more narrow focus around a specific feature like geographic bias or hate content[8], [62], [71] or a single modality [36], [37], [81], [123]. The goal of this work is to provide an empirical, ecosystem-level, and multimodal analysis of widely used training datasets [76]. Our audit focuses on text, speech, and video, as prominent data modalities behind modern multimodal systems, such as Sora, Whisper, Gemini, GPT-40, and others [100], [104], [108], [115], [129], [140]. Since training data for modalities can often be independent, multimodal models tend to interleave training batches with different combinations of one or two"}, {"title": "2.1 TEXT", "content": "Scope We focus on providing an extensive audit for post-training datasets, used in training language models. We include single and multi-turn formats, encompassing both datasets typically used for instruction finetuning (SFT) and preference alignment [105]. This scope reflects the prominent role of general-purpose language models, which benefit from multi-task training on heterogeneous collections that span a variety of linguistic, reasoning, and knowledge intensive tasks like question answering, coding, tool use, translation, and classification [49], [64].\nDataset Selection We expand the study conducted by the Data Provenance Collection [123], from 44 dataset collections (of 1858 supervised text datasets) to a superset of 108 collections of 3717 datasets, prioritizing recent, popular publicly available HuggingFace Datasets introduced between 2022 and April 2024. Our collection sourced popular datasets from recent survey papers [114], [121] and tools [122]. We additionally reviewed HuggingFace Datasets' most downloaded datasets every month, from April to July 2024, under the Natural Language Processing category, as well as the SFT/DPO datasets associated with popular open model releases. We also drew from major multilingual data repositories, including the SEACrowd Catalogue [126], the Masader Arabic Data Catalogue [52], AI4Bharat [27], and the Aya Collection [134]. Lastly, our list of datasets was reviewed and supplemented by language model experts to fill in notable omissions. In total, we trace"}, {"title": "2.2 SPEECH", "content": "Scope We audit speech datasets for which automatic speech recognition (ASR) was noted as a pri- mary task. We focus on ASR datasets because: (1) ASR is fundamental to many speech technologies, including dictation tools, voice assistants, and chatbots [32], [68]; (2) large-scale speech datasets are typically designed for ASR [89]; (3) ASR data follows standardized formats, making comparisons easier (e.g., corpus of audio clips paired with text); and (4) ASR data can often be reused for other tasks like text to speech (TTS) [7] or language identification [20].\nDataset Selection To curate a representative sample of popular ASR datasets, we relied on a combination of survey repositories\u00b3, and HuggingFace Datasets using the \u201cAutomatic Speech Recog- nition\u201d and \u201cText-to-Speech\u201d task tags. We expanded coverage to well-documented datasets on the OpenSLR4 platform, even if they were newer or less widely used. We expect this might reflect datasets that could be adopted more widely in the future. Finally, we included datasets related to low-resource languages and other languages not well-covered by our initial searches. Speech recognition models are increasingly highly multilingual [33], [104], [131], and datasets serving different communities of builders and end-users around the world are a priority for making speech recognition technologies more inclusive. In total, we trace the provenance and features of 95 speech datasets, covering 18 popular ASR tasks, spanning from 1990 to 2024."}, {"title": "2.3 VIDEO", "content": "Scope Early video understanding models primarily focused on video classification, detection and action recognition, where short clips were categorized into predefined classes [30], [69]. More advanced tasks such as temporal action segmentation, video question answering, and video captioning were later introduced to build upon these foundational tasks [63], [111]. Recently, following the success in the field of image generation, video generation from text has become a new task that has shown promising results [72], [82], [115], [140]. Given the scarcity of datasets for text-to-video and the often undocumented sources of data used in recent video generation models [127], we take a broader approach to our collection of video datasets. We focus on annotating popular video tasks and limit our scope to datasets corresponding to video tasks that are either published, highly cited, or have 100+ downloads on HuggingFace. This approach is justified by three key factors: (1) the usefulness of video data to the research community stems from its collection and presentation in peer-reviewed work, (2) datasets can often be repurposed between different tasks, allowing for applicability to new tasks such as video generation from text, and (3) focusing on highly cited datasets ensures that datasets' quality and relevance has been validated by the research community.\nDataset Selection We include datasets tagged with \"Video Classification\u201d, \u201cText-to-Video\", and \"Video-Text-to-Text\" from HuggingFace Datasets. We augmented this with datasets tagged by \"Video Understanding\u201d or \u201cVideo Generation\u201d in PapersWithCode, as well as datasets listed in a popular Github survey repository. We also consulted the proceedings of recent video workshops: the Large Scale Video Understanding and Egocentric Vision workshops. We separately consulted a committee of non-author video experts to supplement the list with relevant datasets published at CVPR, ICCV, ECCV, and IJCV. In total, we trace the provenance and features of 104 video datasets, covering 33 popular video tasks, spanning from 2009 to 2024.\""}, {"title": "3 RESULTS", "content": "We discuss three key results related to (1) the rising use of web, social media and synthetic sources, (2) inconsistent and opaque restrictions on data use, and (3) a lack of improvement in geographical or linguistic representation. Each of these findings holds across modalities, at the ecosystem level."}, {"title": "3.1 RISING USE OF WEB, SOCIAL MEDIA & SYNTHETIC DATA", "content": "The need for scale, and heterogeneity have driven rising use of data from web-crawled, social media, and synthetic data sources. Developers have sought out ever larger and conveniently"}, {"title": "3.2 INCONSISTENT USE RESTRICTIONS", "content": "In the United States, creators of a work automatically have a copyright interest that gives them exclusive rights to make copies and derivatives of the work (17 U.S.C. \u00a7 106). Licenses are legal documents through which the owners of a work express how others may use their work. By contrast, Terms of Service express a contract between a platform and its users to spell out how a platform and its content may be used [28]. For simplicity, we use \u201cLicenses\u201d to refer to dataset restrictions, and \"Terms\" to refer to restrictions on the sources of datasets. There remain open questions about whether certain data licenses are enforceable, but these licenses signal the intention of data creators and therefore warrant consideration as the data creators may be best positioned to understand the sensitivities of the data (privacy, copyright, representation, etc.), and the most impacted by its downstream use [88], [93], [94], [97]. The extent to which a practitioner adheres to dataset licenses or source terms remains"}, {"title": "3.3 GEOGRAPHICAL & LINGUISTIC REPRESENTATION IS NOT IMPROVING", "content": "The importance and progress of representation in AI training data. Diversity and representation in training datasets, and among their creators, are widely acknowledged as essential to building AI models that are less biased, more useful, and more equitable [6], [18], [25], [31], [61], [101], [112], [113], [134], [137]. Prior work has measured the diversity of languages in data along with cultural, ideological, and geographical imbalances [8], [14], [41], [55], [62]. These studies have exposed significant flaws, often in the form of bias and discrimination, stemming directly from poor representation in data [12], [35]. As this problem has now been widely acknowledged for decades, recent efforts have foregrounded sourcing data multilingually and multi-culturally, from native speakers and creators (e.g. ROOTS [60], the Aya Dataset [134], the SEACrowd Catalogue [126], the Masader Catalogue [52], Common Voice [13], Causal Conversations V2 [101] or Moments in Time [18]).\nMeasuring geographical and linguistic representation. Naturally, we aim to use our audit to measure the progress of these efforts on geographical and linguistic representation in the AI ecosystem. We measure the progress of two forms of representation: (1) language diversity of text and speech data, and (2) geographical diversity of the creators, in all three modalities. For languages, we use the ISO 639-1 and 639-3 language codes and categories of language families from Glottolog 5.0.5 In Figure 4(a, c) we display the cumulative sum of unique languages and countries present across all audited datasets, at each time period since 2013. While these measurements illustrate the absolute rise in diversity, we also hope to measure the relative dispersion, or equality of languages and countries in the distribution. In Figure 4(b, d), we use the Gini Index [1], [2], a traditional measure of statistical dispersion, frequently used to quantify inequality. This allows us to understand if the distributions of languages and creators are more representative of the international community over the last decade, or equally concentrated despite apparent efforts at the margins."}, {"title": "4 DISCUSSION", "content": "The rise of web-based, social media, and synthetic datasets may pose greater risks to privacy, copyright, and bias. Section 3.1 discusses the rise of web-based sources and particularly social media as primary sources for speech and video. Figure 1 shows these sources now exceed more traditional, curated sources such as movies, audiobooks, radio, TV, or content hand-crafted by human participants-by at least one order of magnitude. These websites made of mostly user-generated content are a natural choice, given that they scale in the quantity, freshness, and heterogeneity that is best suited to train general-purpose models [70], [92]. However, prior work suggests that crowd-sourced, user-generated web content also introduces more challenges than curated content, particularly for privacy, copyright, bias, harm, and factuality.\nWeb-based and particularly user-generated content is disproportionately likely to include personally identifiable information (PII) [40], [81], [107], and copyrighted content [16], [88]. These can be reproduced in the outputs of AI models [53], [78], creating privacy and copyright concerns [110]. Open datasets being used to train GPAI often attempt to filter\u2014but frequently miss\u2014PII and copyrighted data [107], [136] (although not all do [99]). Social media, in particular, is also known to have bias, toxicity and factuality issues [19], which can manifest in trained models, even after alignment [85]. Lastly, while synthetic data can help reduce the prevalence of PII, copyright, or bias in data, it comes with its own challenges [86], [120]."}]}