{"title": "LOCAL OPTIMA IN DIVERSITY OPTIMIZATION: NON-TRIVIAL OFFSPRING POPULATION IS ESSENTIAL", "authors": ["Denis Antipov", "Aneta Neumann", "Frank Neumann"], "abstract": "The main goal of diversity optimization is to find a diverse set of solutions which satisfy some lower bound on their fitness. Evolutionary algorithms (EAs) are often used for such tasks, since they are naturally designed to optimize populations of solutions. This approach to diversity optimization, called EDO, has been previously studied from theoretical perspective, but most studies considered only EAs with a trivial offspring population such as the (\u03bc + 1) EA. In this paper we give an example instance of a k-vertex cover problem, which highlights a critical difference of the diversity optimization from the regular single-objective optimization, namely that there might be a locally optimal population from which we can escape only by replacing at least two individuals at once, which the (\u03bc + 1) algorithms cannot do.\nWe also show that the (\u03bc + \u03bb) EA with \u03bb > \u03bc can effectively find a diverse population on k-vertex cover, if using a mutation operator inspired by Branson and Sutton (TCS 2023). To avoid the problem of subset selection which arises in the (\u03bc + \u03bb) EA when it optimizes diversity, we also propose the (1\u03bc + 1\u00b5) EAD, which is an analogue of the (1 + 1) EA for populations, and which is also efficient at optimizing diversity on the k-vertex cover problem.", "sections": [{"title": "1 Introduction", "content": "Obtaining a diverse set of good solutions is a complex optimization task, which often arises in real-world problems such as planning [1], satisfiability [2], architectural planning [3], cutting materials [4] and others. The most common reason for the need of a diverse set of solutions is that some objectives or constraints cannot be strictly formalized (e.g., for political, ethical, aesthetic or other reasons), therefore an algorithm user would like to get not a single best solution, but a set of good solutions to choose from. And if this set is not diverse enough, all solutions might occur infeasible in terms of those non-formalizable constraints.\nFormalizing diversity is also a non-trivial task, and often it is problem-specific. One of the ways to get a set which can be called diverse is to divide the search space into regions and to optimize the objective (or objectives) in each region simultaneously [5, 6]. This approach, called the quality diversity (or QD for brevity), has been mainly developed in the domains of robotics and games [7, 8, 9, 10, 11, 12]. Recently this approach has been applied to the traveling thief problem, and various domains such as design and health [13, 14, 15].\nAnother way to formalize the problem, which we adopt in this paper, is to define a diversity measure over the space of sets of solutions, and turn the problem into optimizing this measure under some constraints on the quality of solutions in the population."}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Diversity Optimization", "content": "The problem of diversity optimization was defined in [30]. We slightly generalize it as follows. Given a fitness function f: \u03a9 \u2192 R (where \u03a9 is the search space), population size \u03bc, quality threshold B and diversity measure D, the goal is to find a population P, which is a multiset of u elements from \u03a9, with the best value of D(P) under condition that all x \u2208 P meet the quality threshold, that is, f(x) \u2265 B.\nUsually the definition of the diversity measure is problem-specific, but it always reflects how different the solutions are in the search space (but not in the fitness space). In this paper we study the total Hamming distance, a diversity measure which has been previously studied in the context of theoretical runtime analysis of EDO [27, 31, 32]. Given a population P of bit strings, the total Hamming distance is defined as D(P) = \u2211x,y\u2208p H(x, y), where H is the Hamming distance and the sum is over all unique unordered pairs of individuals.\nAn important property of this measure for pseudo-Boolean optimization (that is, when the search space is the set {0, 1}\u207f of all bit strings of length n) which has been previously used in the analysis of EDO algorithms is that it can\nAs in the vast majority of theoretical studies, we focus on estimating the number of iterations rather than the wall-clock time."}, {"title": "2.2 Vertex Cover", "content": "For a given undirected graph G = (V, E) we call any set of vertices such that all edges in E are adjacent to at least one vertex in this set a vertex cover (or cover for short). The minimum vertex cover is a problem of finding a cover of minimum size, and the k-vertex cover is a fixed-target\u00b2 variant of this problem, that is, the problem of finding a cover of a size of at most k.\nFinding a k-vertex cover for an arbitrary graph and an arbitrary k is a classic NP-hard problem, and therefore, there is no known algorithm which could solve this problem efficiently (that is, in a polynomial time). For this reason the EAs have been previously applied to it in many different ways. In [35, 36] it has been shown that the classic EAs can be very ineffective on some instances of the vertex cover, when they use a single-objective formulation. Hybrid evolutionary approaches have been studied in [37], and in [38, 39] an effectiveness of the multi-objective approach has been shown. A typical representation of the vertex cover when applying EAs is a bit string of length n = |V|, where the i-th bit indicates if the i-th vertex is included into the set. We use this representation in this paper.\nIt is also well-known that the k-vertex cover is a fixed parameter tractable (FPT) problem [39], that is, there exists a parameter of the instance k such that the time we need to optimize the instance is f(k) \u00b7 Poly(|V|). In our case, this parameter k is the size of the optimal cover. To address the FPT property of this problem, in [29] Branson and Sutton used a modified representation for individuals and proposed a jump-and-repair mutation operator which allowed the (1 + 1) EA to find a k-vertex cover in expected number of O(2\u1d4fn\u00b2 log(n)) iterations, if such cover exists. The main idea behind that operator is that if there exist a vertex cover y of size at most k such that none of the vertices can be removed from it, then we can get it from any other vertex cover x by removing all vertices belonging to x \\ y and adding their neighbours (see Lemma 4 in [29]).\nIn this work we aim at finding a diverse (in terms of the total Hamming distance) set of vertex covers of size at most k for a given graph G = (V, E), assuming that at least one such cover exists. We also assume that the target population size u and the cover size k are relatively small, namely that k\u00b5 = o(\u221an). This implies that by the pigeonhole principle, in any population there will be only o(\u221an) different positions which have at least one one-bit, and therefore there will be many positions i, in which all individuals would have a zero-bit (that is, vertex i is not included in any cover in the population). If a population has some individuals which have l < k vertices, than adding k - l vertices not included into any individual in the population will increase the corresponding terms in eq. (1) by |P| = \u00b5, hence it never makes sense to have covers of size less than k in the population.\nHowever, the mutation operator used in [29] cannot generate all covers of size k, but only non-excessive ones, that are, those covers from which we cannot remove any vertex and keep it a cover. For this reason, in this work we modify their mutation operator. Our modified operator is shown in Algorithm 1. Given a cover x, this jump-and-repair mutation first removes each vertex from it with probability 1/2 and then adds all neighbours of the removed vertices, similar to the operator from [29]. Since we add all neighbours of the removed vertices, it guarantees that the result of this mutation is a cover, that is, there is no edge for which none of the two adjacent vertices is in the resulting individual. This cover might be of size less than k, and in this case we add some randomly chosen vertices to make the size of the vertex cover exactly k.\nThe following lemma is an extension of Lemma 4 in [29].\nLemma 1. Let x be a k-vertex cover of graph G and let y be a non-excessive cover of size at most k. Then the probability that the jump-and-repair mutation (Algorithm 1) applied to x generates y before adding additional random vertices (that is, by line 14 in Algorithm 1) is exactly 2\u207b\u1d4f.\n\u00b2For more information about fixed-target analysis and notation see [34]."}, {"title": "2.3 The Considered EAS", "content": "In this paper we consider population-based EAs which are commonly used in the diversity optimization. Most of the- oretical studies of EDO considered the (\u03bc + 1) EAD, which optimizes the diversity only when it breaks ties between candidates for the next generation [23, 21, 31]. We describe a generalized version of this EA in Algorithm 2. This algorithm stores a population P of u individuals. We do not specify the way these individuals are initialized. In each iteration this algorithm creates a new individual y by applying variation operators (usually, mutation and crossover)"}, {"title": "3 Locally Optimal Population", "content": "In this section we give examples of vertex cover instances, for which there exists a population with sub-optimal diversity, such that to improve its diversity we need to change at least two individuals together. This implies that if a (\u03bc + 1)-kind of algorithm gets such a population, it gets stuck in it, since it only changes one individual in each iteration. Note that in this section the diversity is always measured via the total Hamming distance.\nWe start with a simple example, where the population size is 2 and the graph has 8 vertices. We then extend this simple example to an arbitrary even population size \u00b5 and any even problem size n \u2265 10."}, {"title": "3.1 The Simple Example", "content": "Consider graph G = (V, E) with 8 vertices {v\u2081, . . ., v\u2088} and edges as shown in Figure 1."}, {"title": "3.2 Extending the Example to Arbitrary Population and Problem Sizes", "content": "Based on the example given in the previous subsection, we now show that a population with sub-optimal diversity which cannot be escaped by the (\u03bc + 1) EA exists also for larger \u00b5 and |V|. We start with extending our example for larger population sizes, keeping |V| = 8.\nWe consider the same graph G as shown in Figure 1, and give an example of a locally optimal population in the following lemma.\nLemma 4. Let \u00b5 \u2265 4 be even and let \u03bd = \u03bc/2 \u2212 1. Let also V\u2081, V\u2082, V\u2083 and V\u2084 be the same vertex covers as in Lemma 3. Consider a population which has one individual V\u2081, one individual V\u2082, \u03bd individuals V\u2083, and \u03bd individuals V\u2084. Then this population has a sub-optimal diversity (the total Hamming distance) and replacing any individual with any different vertex cover of size at most 4 reduces the diversity.\nProof. We exploit the expression of the total Hamming distance given in eq. (1). In the given population all n\u1d62 (the number of one-bits in position i) are \u03bd, except for i = 2 and i = 3. Since the bit strings representing V\u2081 and V\u2082 have a one-bit in position 2 and a zero-bit in position 3, we have n\u2082 = \u03bd + 1 and n\u2083 = \u03bd \u2212 1. Hence, if we change the number of one-bits in any position (except 2 and 3) by one, it decreases the corresponding term in eq. (1) by one, since we have\n$\\binom{\\mu}{2}-\\binom{\\mu/2+1}{2}-\\binom{\\mu/2-1}{2} = 1$.\nFor the same reason, increasing the number of one-bits in position 2 decreases this term by 3 and decreasing the number of one-bits by one increases it by 1. For position 3 it is the other way around.\nWe now consider different cases of replacing individuals in the population with different 4- or 3-covers, and show that all of them would only decrease the total Hamming distance.\nCase 1: replacing V\u2081. If we replace the only individual V\u2081 with V\u2083, then we increase the number of one-bits in position 3 (and therefore, its contribution to the diversity is increased by one), and we change the number of one-bits in positions 4, 7 and 8, which decreases the diversity by 3. Therefore, the total diversity is decreased. Similarly, if we replace V\u2081 with V\u2084, we make the diversity in position 2 better, but we unbalance positions 1, 5 and 6, hence, we decrease the diversity.\nIf we replace V\u2081 with any other 3 or 4-cover, then this cover has the same values in positions 2 and 3 by Lemma 2, and at least one other value should be different. This would decrease the term in eq. (1) which corresponds to this different position. Hence, the diversity is decreased.\nCase 2: replacing V\u2082. This case is similar to Case 1. Replacing V\u2082 with either V\u2083 or V\u2084 decreases the diversity by two, and any other replacement decreases it by at least one.\nCase 3: replacing V\u2083. In this case we consider replacing one of the \u03bd individuals V\u2083 with a different one. If we replace it with V\u2084, then we decrease n\u2082, which increases the diversity by one. However, it also decreases n\u2083, which decreases the diversity by 3 and changes all other n\u1d62, which decreases the diversity by 6 more. Hence, the diversity is decreased by 8. Since by Lemma 2 all other covers include v\u2082 and do not include v\u2083, replacing V\u2083 with one of such covers does not change n\u2082 and decreases n\u2083 by one, which reduces the diversity by 3. The changes in other positions\ncan only reduce diversity even more. Therefore, any replacement of any individual representing V\u2083 would decrease the diversity.\nCase 4: replacing V\u2084. This case is similar to Case 3. If we replace it with V\u2083, we balance position 3, but we unbalance all other positions, which decreases the diversity. Replacing it with any other cover would unbalance at least one position.\nBringing all cases together, we conclude that replacing any individual in this population with a different 3- or 4-vertex cover decreases the total Hamming distance, and therefore is not accepted by the algorithm.\nTo extend this result to larger problem sizes it is enough to add to the graph in Figure 1 a complete bipartite graph Kn,n, which is not connected with the basic graph and consider the (n + 4)-cover problem. Then the locally optimal population will be the same as in Lemma 4, but half of the individuals in that population must contain one half of the bipartite graph, and another half of individuals\u2014another half of the bipartite graph. This results in a population in which all positions except 2 and 3 are balanced. Hence, the arguments of Lemma 4 will work on this graph as well, if we note that changing the value of any bit corresponding to an added vertex would result in decreasing the corresponding term in (1) and therefore, reducing the diversity."}, {"title": "4 Large Offspring Populations Are Effective", "content": "In this section we show that the (1\u00b5 + 1\u00b5) EAD and also the (\u03bc + \u03bb) EA\u0189 with \u03bb > \u03bc can effectively find a diverse population of k-vertex covers. The main result is the following theorem.\nTheorem 1. Consider the (1\u00b5 + 1\u00b5) EAD or the (\u03bc + X) EA\u0189 with > > \u00b5, which optimize the total Hamming distance on a k-vertex cover instance, for which at least one k-cover exist. If we have k\u00b5 = o(\u221an), then in each iteration the probability of these two algorithms to find a population of k-vertex covers with optimal diversity is at least 2\u207b\u1d4f\u00b5(1 \u2212 o(1)), and therefore, its runtime is dominated by geometric distribution Geom(2\u207b\u1d4f\u00b5(1 \u2212 o(1))).\nProof. Let Popt be a population of u individuals which meet the constraint on fitness and which has the best possible diversity. As it was discussed in Section 2.2, all individuals in this population have exactly k vertices, since otherwise we could add additional vertices to some of them and increase diversity. Let Popt be another population of \u00b5 covers, where the i-th individual is a non-excessive cover, which is a subset of the i-th individual in Popt\nTo get Popt from Popt we need to add vertices to individuals which have less than k vertices. If we add a vertex to position i, in which^ni > 0 individuals have a one-bit (that is, they include vertex i), then the improvement of the corresponding term in eq. (1) will be\n$(n_i + 1)(\\mu - n_i - 1) - n_i(\\mu - n_i) = \\mu - n_i - 1 - n_i + 1 < \\mu$.\nHence, we can add this vertex to another position i, in which n\u1d62 = 0 and improve the diversity more, namely, by \u03bc. Therefore, if at least one vertex is added to a position with ni > 0, then it contradicts with optimality of D(Popt). We also note that any way of adding the missing vertices to Popt to positions with ni = 0, would yield the same increase in diversity, therefore, to get an optimal diversity, we do not have to get Popt: any other population obtained in this way from Popt has an optimal diversity.\nThe probability that we create such a population in one iteration of the (1\u03bc + 1\u03bc) EAD or the (\u03bc + 1) EAD with \u03bb > \u03bc is at least the probability that for each i we generate the i-th offspring yi by first creating the i-th individual x of Popt and then we add the missing vertices (if there are any) to positions with no vertices in other individuals. For the (1\u03bc + 1\u00b5) EAD it gives a population with optimal diversity, and for the (\u03bc + \u5165) EAD the population with optimal diversity is a subset of the new offspring, hence the diversity of the next-generation population cannot be sub-optimal.\nBy Lemma 1, the probability to create an individual from P\u00f3pt is 2\u207b\u1d4f, hence the probability that we create exactly \u03bc such individuals is at least 2\u207b\u1d4f\u00b5. We then add the missing vertices. At each point of time there are at least n \u2013 k\u00b5 good positions in which there is no vertex in any individual, and there are at most n positions to which we add a vertex, hence the probability that we add it to a good position is at least (1 \u2013  \u03ba\u03bc/n). Since we need to add at most k\u00b5 vertices, the probability that all of them are added to good positions is at least\n$(1 - \\frac{k\\mu}{n})^{\\kappa \\mu} \\geq 1 - \\frac{(\\kappa \\mu)^2}{n} = 1 - o(1)$,\nwhere we used Bernoulli inequality and the lemma condition k\u00b5 = o(\u221an). Hence, we conclude that the probability to create a population with optimal diversity in each iteration is at least 2\u207b\u1d4f\u00b5(1 \u2212 o(1))."}, {"title": "5 Conclusion", "content": "In this paper we showed the first example of a local optimum in the diversity optimization problem, from which it is impossible to escape by replacing only one individual in the population if we optimize diversity in an elitist way. This result illustrates that when optimizing in the space of populations, the (\u03bc + 1) algorithms can be interpreted as local search in that space. To get a positive probability of finding an optimally diverse population in any iteration we have to be able to perform global changes on the population, which demands from us creating at least \u03bc offspring. This idea brought us to the (1\u03bc + 1\u03bc) EAD, which is an analogue of the (1 + 1) EA, where in role of individuals we have populations represented with bit strings of size \u03b7\u03bc.\nThe first signs of this result might have been seen in the previous empirical study [25]. There it was shown that the amount of diversity of the obtained solutions in the context of constructing a wireless communication network can be increased in most of the cases by even slightly increasing the offspring population size. This also rises a question on how many individuals should we replace at once to escape such local optima. Creating the number of offspring which is at least the size of the parent population is definitely enough, and, as we have shown in this paper, might be effective when the parent population size is not too large. However, if we want to obtain large diverse populations, then counting on generating the whole optimal population in one iteration is not promising, and our hope would be on improving the diversity via replacing a small number of individuals per iteration.\nBefore we find an answer to the question on what the offspring population size should be, a lazy approach to such problems would be using variable population size in the (\u03bc + \u03bb) EAD. A good strategy for this might be choosing \u5165 according to the power-law distribution, which on the one hand gives us a decent probability to have a large population size, but also preserves a small expected cost of one iteration, as it was shown in [40]."}]}