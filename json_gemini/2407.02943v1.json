{"title": "PII-Compass: Guiding LLM training data extraction prompts towards the target PII via grounding", "authors": ["Krishna Kanth Nakka", "Ahmed Frikha", "Ricardo Mendes", "Xue Jiang", "Xuebing Zhou"], "abstract": "The latest and most impactful advances in large models stem from their increased size. Unfortunately, this translates into an improved memorization capacity, raising data privacy concerns. Specifically, it has been shown that models can output personal identifiable information (PII) contained in their training data. However, reported PII extraction performance varies widely, and there is no consensus on the optimal methodology to evaluate this risk, resulting in underestimating realistic adversaries. In this work, we empirically demonstrate that it is possible to improve the extractability of PII by over ten-fold by grounding the prefix of the manually constructed extraction prompt with in-domain data. Our approach, PII-Compass, achieves phone number extraction rates of 0.92%, 3.9%, and 6.86% with 1, 128, and 2308 queries, respectively, i.e., the phone number of 1 person in 15 is extractable.", "sections": [{"title": "1 Introduction", "content": "Memorization in Large Language Models (LLMs) has recently enjoyed a surge of interest (Hartmann et al., 2023) ranging from memorization localization (Maini et al., 2023), quantification (Carlini et al., 2022) to controlling (Ozdayi et al., 2023) and auditing (Zhang et al., 2023a). The major reason for this is the risk of training data extraction (Carlini et al., 2021; Ishihara, 2023). To assess this risk, various methods have been proposed in prior work (Yu et al., 2023; Zhang et al., 2023b; Panda et al., 2024; Wang et al., 2024). In this work, we aim to assess the privacy leakage risk of a subclass of training data, namely personal identifiable information (PII) from base LLMs. More specifically, we focus on the PII extraction attacks in the challenging and realistic setting of black-box LLM access.\nThe simplest attack in this scenario involves generating hand-crafted templates that attempt to extract PII (Shao et al., 2023; Kim et al., 2024). For example, an adversary might prompt the model with \"the phone number of {name} is.\", substituting \"{name}\" with the victim's name. While such an attack requires no prior adversarial background information, its performance largely depends on the quality of the templates, particularly their comprehensiveness and relevance to the data being targeted. A more advanced approach is to use prefixes found in the training data in the hope that the model outputs the exact PII suffix (Lukas et al., 2023). This approach significantly outperforms the simplest attack but requires the strong assumption that the adversary has access to the real prefixes from the training data.\nIn this paper, we take a deeper look at PII extraction in the setting where the exact true prefixes of the data subjects are not known. Our contribution is threefold. First, we demonstrate that simple adversarial prompts are ineffective in PII extraction. Hereby, we investigate over 100 hand-crafted and synthetically generated prompts and find that the correct PII is extracted in less than 1% of cases. In contrast, using the true prefix of the target PII as a single query yields extraction rates of up to 6%. Second, we propose PII-Compass, a novel method that achieves a substantially higher extraction rate than simple adversarial prompts. Our approach is based on the intuition that querying the model with a prompt that has a close embedding to the embedding of the target piece of data, i.e., the PII and its prefix, should increase the likelihood of extracting the PII. We do this by prepending the hand-crafted prompt with a true prefix of a different data subject than the targeted data subject. Although this augmented prompt is not exactly the same as the true prefix, they ground the model, thus enhancing extraction. Third, we empirically evaluate our method and demonstrate the high effectiveness of our method in PII extraction. Specifically, almost 7% of all phone numbers in the considered dataset"}, {"title": "2 Experiments", "content": "can be extracted, i.e., the phone number of one person out of 15 is easily extractable.\nFollowing the experimental setup in (Shao et al., 2023), we use a post-processed version of the Enron email dataset (Shetty and Adibi, 2004) which maps persons to their phone numbers. We further filter out annotations (pairs of names and phone numbers) that are non-numeric or have ambiguous multiple ground-truth annotations, resulting in a total of 2,080 data subjects containing (name, phone number) pairs. Similar to (Shao et al., 2023), we use the GPT-J-6B (Gao et al., 2020) model as the target LLM which was trained on the Enron email dataset.\nWe split this dataset into two parts: the Adversary dataset containing 128 data subjects that can serve as additional knowledge available to the attacker, and the Evaluation dataset that containing the 1,952 remaining data subjects. We assume black-box access to the target base LLM and the availability of true prefixes of the data subjects in the Adversary dataset. We believe our assumption about access to an adversary dataset is realistic since (small) portions of the dataset could be acquired legally, e.g., purchased, or illegally, e.g., leaked. We perform greedy decoding during the generation process. We report the PII extraction rate as the percentage of data subjects in the evaluation dataset for which we can extract the correct phone number. We provide more details about the experimental setting in the Appendix A."}, {"title": "2.1 Extraction with True-Prefix Prompting", "content": "We first evaluate PII extraction when the attacker has access to the true-prefix associated with the phone numbers in the evaluation dataset. The results of this experiment are presented in Figure 1. We observe that the rate of extraction improves significantly from a 10-token to a 25-token prefix. This is in line with the results of (Carlini et al., 2022), where the training data memorization of a 50-token suffix is shown to be higher with a larger context length of the prefix prompts. Moreover, we observe that the extraction rate saturates at higher prefix lengths above 100 tokens."}, {"title": "2.2 Extraction with Manual-Template Prompting", "content": "In this setting, we assume the attacker has no access to the pretraining dataset and can only probe the LLM with hand-crafted prompt templates. We experiment with six template prompts containing the subject name: T1: \u201cWhat is the phone number of {name}?", "T2": "Please contact {name} by phone number\"; T3: \"You can reach {name} by phone number\u201d; T4: \u201cContact {name} at phone number\u201d; T5: \u201cI am {name}. My phone number is\"; T6: \"the phone number of {name} is\".\nWe observe that the performance of these templates in extracting the phone numbers is less than 0.15% for all templates (left side purple bars in Figure 3), strongly contrasting with the extraction rates when using true prefixes (Figure 1). While (Kim et al., 2024) improves these adversarial queries by leveraging soft-prompt tuning (Lester et al., 2021), we take a different approach based on the insights from our embedding space analysis of the training data extraction mechanisms."}, {"title": "2.3 Understanding the PII Extraction", "content": "In this section, we study the factors that contribute to PII extraction. To do so, we extract the sentence embeddings of prompts for 100 data subjects in the evaluation dataset and visualize them in a UMAP plot in Figure 2. We observe that the template prompts T4 and T6 are far away from the region of true-prefix prompts, where we observed the highest PII extraction rates. We conjecture that the poor extraction rates with manual templates can be attributed to the difference in the embedding space between the true-prefix prompts and the manually crafted template prompts."}, {"title": "PII-Compass: Guiding manual prompts towards the target PII via grounding", "content": "We hypothesize that the PII extraction rates of the manually crafted prompts templates can be improved by moving them closer to the region of the true-prefix prompts in the embedding space. Our hypothesis is based on the intuition that querying the model with a prompt that has a close embedding to the embedding of the target piece of data, i.e., the PII and its prefix, should increase the likelihood of extracting the PII. To validate this assumption, we query the model with a prompt that combines: 1) a manually crafted prompt to extract the PII of a specific data subject from the evaluation set, and 2) one of the true prefixes of a different data subject in the adversary set that we prepend to the manually crafted prompt. We observe that the embedding of such combined prompts for all 100 evaluation data subjects is pushed closer to the true-prefix embeddings from the evaluation set. We provide examples of these prompts in Figure 4 and Appendix B.\nMoreover, we prepend the template T6 with an example from another subdomain in the PILE dataset (Gao et al., 2020), namely GitHub which includes coding examples. Here, the embeddings of the combined prompts are pushed away from the true-prefix embeddings.\nBased on our finding that by prepending the template with a random true prefix of a different subject, we can ground the model in the region closer to the region of the true prefix of the data subject in the evaluation set. We prepend the hand-crafted template with the true prefix of a maximum of 100 tokens of the data subject in the adversary set and evaluate PII extraction. We repeat the experiment 128 times by prepending with the true prefix of each data subject in the adversary dataset. We report the PII extraction results of our method in Figure 3. Our findings show that the PII extraction rates increase by 5 to 18 times for different templates when using the optimal prefix among these 128 queries. For instance, the extraction rate of Template T4 with the optimal prefix is 0.92%. Besides, the aggregated PII extraction rate, defined as the rate of extracting PII at least once in 128 queries, reaches 3.89% with T4. Moreover, by aggregating over different templates resulting in a total of 768 queries (128 prefixes \u00d7 6 templates), we reach 5.68% extracting PII at least once. We further scale the queries by prepending with true prefixes of other context lengths of 25 and 50 and achieve an extraction rate of 6.86% with 2308 queries as shown in Figure 5. Further details about obtaining this visualization are provided in Appendix D. Overall, we observe that with our prompt grounding strategy, the average extraction rates (computed over 11 seeds) sharply increase to 3.3% within a small query budget of 128 and saturate to 6.8% in the higher query budget of 2304."}, {"title": "Scaling Number of Manual Templates", "content": "Thus, even though we scaled to a large number of templates, we were unable to bridge the gap observed in the performance of true-prefix prompting from Figure 1. In other words, grounding manual-templates with a true-prefix of an in-domain data subject is far more effective than searching with a large number of naive templates that do not provide sufficient context to evoke the memorization.\nTo account for higher query counts as in the previous experiment, we extend the six templates discussed in Section 2.2 to 128 templates by prompting GPT-4 (OpenAI, 2023) to generate PII probing questions. The resulting 128 prompt templates are provided in the Appendix B. The PII extraction performance of the best-performing template from this set is 0.2%, which is 0.05% higher than the performance of the hand-crafted template T4, where it extracts one more phone number. However, this extraction rate is substantially lower than the optimal extraction rates previously achieved by prepending true prefixes of different data subjects (green bars in Figure 3). Moreover, the rate of extracting PII at least once through these 128 GPT queries is only 0.92%, significantly lower than the best-achieved extraction rate of 3.63% using our proposed method (yellow bars in Figure 3)."}, {"title": "Manual Template Prompting with Sampling", "content": "In this section, we account for higher query counts by sampling in the output layer. We set the top-k to 40 and run the experiments with manual templates, querying 128 times with sampling. We provide the results of this experiment in Figure 6. We observe that with sampling 128 times, the PII extraction rate of finding at least one match in 128 queries improves for templates T2 and T3, from 0.15% and 0.05% to 1.3% and 1.0% respectively. For other templates, the performance remains in a similar range as with a single query (represented by the left side purple bars in Figure 3), indicating no significant improvement with increased querying via top-k sampling. However, this performance rate is substantially lower than with our PII-compass method using a similar 128 query count, achieved by prepending the manual prompt with the 128 true prefixes from the Adversary dataset. This underscores the superiority of our prompt grounding strategy over template-prompting by sampling."}, {"title": "In-Context Learning for PII Extraction", "content": "Prior works (Shao et al., 2023; Huang et al., 2022) have explored in-context learning (ICL) for email entity PII extraction. We explore this paradigm by leveraging the data subjects in the adversary"}, {"title": "3 Conclusion", "content": "dataset and prompt the model with varying numbers of in-context shots. An example of this prompt is provided in the Appendix Figure 9. We observe that the PII extraction rate with ICL reaches the best extraction rate of 0.36%, which is substantially lower than results achieved by PII-Compass. More importantly, the extraction performance is not linear with the number of shots in the in-context examples.\nIn this work, we highlight the limitations of hand-crafted templates in extracting phone number PII. To overcome this, we propose PII-Compass, a simple yet effective prompt grounding strategy that prepends the manual templates with the true prefix of a different data subject. Our empirical experiments demonstrate the effectiveness of PII-Compass, yielding an impressive over ten-fold increase in PII extraction rates compared to the baselines. In the future, we aim to study the PII extraction rate by leveraging the zero-shot capabilities of GPT-4 to generate prefixes that can guide the extraction towards the target PII even in the absence of an adversary dataset."}, {"title": "4 Limitations", "content": "the base LLMs that are not trained with instruction-following datasets.\nDue to the absence of publicly available PII entities like credit card numbers and SSNs, we limit our analysis to a single PII, i.e., phone numbers. We also assume the availability of true-prefixes for data subjects in the adversary dataset to conduct our experiments. Additionally, the PII dataset annotations are extracted from GPT-4 by (Shao et al., 2023), which we pruned by retaining only those that are non-ambiguous. We manually verified the annotations of a limited number of data points by searching in the Enron email dataset, but we cannot rule out some mistakes in the annotation process by GPT. Furthermore, our experiments are limited to"}, {"title": "A Additional Details", "content": "Experimental Setting. We conduct our experiments using Python 3.9.18 and PyTorch 2.1.1 libraries. For the experiments, we utilize the pretrained GPT-J-6B model (Gao et al., 2020) available in the HuggingFace library (Wolf et al., 2019). This model is selected due to its widespread use in previous studies (Shao et al., 2023; Huang et al., 2022) and the availability of its exact training dataset.\nOur PII extraction experiments are performed on data subjects within the Enron email dataset (Shetty and Adibi, 2004), which is part of the PILE corpus used for training GPT-J-6B model (Gao et al., 2020). Furthermore, many recent open-source models such as LLaMa2 and Vicuna (Touvron et al., 2023; Chiang et al., 2023) do not disclose detailed information about their training datasets, making it challenging to reliably conduct PII extraction on recent models.\nDataset Preparation. In the original dataset provided by (Shao et al., 2023), there are 3,100 datapoints containing data subject names and their associated phone numbers. We observe that some datapoints have multiple phone numbers associated with a single person, some of which are possibly fax numbers, requiring expensive manual inspection to remove. Therefore, we prune this dataset by only retaining the data subjects that have a single and unique phone number associated with them. Furthermore, we only retain the datapoints with phone numbers that follow the regex pattern shown below. Since we extract the phone numbers from the generated string using the regex pattern, we only include datapoints that follow this regex pattern in the ground truth as well. Finally, we limit the datapoints to those with phone numbers that are exactly 10 digits. Overall, we end up with 2,080 datapoints after preprocessing the dataset. We tokenize the prompts in the dataset before starting each experiment by left padding them to match the length of the longest prefix found in the entire dataset.\nTo extract the true prefixes, we iterate through the body of emails in the raw Enron dataset and search for the joint occurrence of phone numbers and subject names. In these retrieved email bodies, we extract the 150 tokens preceding the first occurrence of the phone number string as the"}, {"title": "B Prompt Demonstrations", "content": "true-prefix.\nEvaluation. During evaluation, we generate 25 tokens and first search the phone number in the generated output string using the below regex expression:\n```\nimport re\npattern = re.compile(r\"\\)?[0-9]{3}\\)\n?(?:\\s|-|\\.)?[0-9]{3}(?:\\s|-|\\.)\n\u2192?[0-9]{4}\")\n```\nWe then extract the digit in string form by removing non-digits characters from both the ground-truth and prediction strings, then compare them to check if they are similar or not.\nIndomain and Outdomain Prefix prompts. In Figure 2 of the main paper, we visualise the UMAP plot with prefix grounding with indomain and out-domain data. The Indomain prefix is taken as the true-prefix of one of the data subject in the adversary dataset. Outdomain prefix is taken from the GitHub of the PILE corpus dataset. Note that both Indomain and Outdomain prefixes are part of the training PILE dataset (Gao et al., 2020) of the target GPT-J-6B model (Gao et al., 2020). We provide the prompts used to construct the prefixes below.\n```\n# Prefix of a data subject in adversary\ndataset\nIndomain_prefix = [\n]\n\"Jeff Shorter (your counterpart at\n\u2192TXU) just called me to inform me\nthey will not be trading with\nEnron until further notice. They\n\u2192 are evalutating their net\nexposure with us, including London\n.\\n\\nHis number is\"\n# sampled from GitHub subdomain from the\nPILE dataset\nOutdomain_prefix = [\n]\n\"config BR2_PACKAGE_EUDEV bool\ndepends on\nBR2_ROOTFS_DEVICE_CREATION\n_DYNAMIC_EUDEV depends on\nBR2_USE_MMU # uses fork() depends\non BR2_USE_WCHAR\",\n```\nOptimal prefixes from Adversary dataset. We provide in Figure 8 the optimal prefixes for each template found in the adversary dataset that achieve the highest PII extraction rate. Prepending these prefixes to the corresponding templates yields"}]}