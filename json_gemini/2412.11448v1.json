{"title": "TRAIL: Trust-Aware Client Scheduling for Semi-Decentralized Federated Learning", "authors": ["Gangqiang Hu", "Jianfeng Lu", "Jianmin Han", "Shuqin Cao", "Jing Liu", "Hao Fu"], "abstract": "Due to the sensitivity of data, Federated Learning (FL) is employed to enable distributed machine learning while safeguarding data privacy and accommodating the requirements of various devices. However, in the context of semi-decentralized Federated Learning (SD-FL), clients' communication and training states are dynamic. This variability arises from local training fluctuations, heterogeneous data distributions, and intermittent client participation. Most existing studies primarily focus on stable client states, neglecting the dynamic challenges present in real-world scenarios. To tackle this issue, we propose a trust-aware client scheduling mechanism (TRAIL) that assesses client states and contributions, enhancing model training efficiency through selective client participation. Our focus is on a semi-decentralized Federated Learning framework where edge servers and clients train a shared global model using unreliable intra-cluster model aggregation and inter-cluster model consensus. First, we propose an adaptive hidden semi-Markov model (AHSMM) to estimate clients' communication states and contributions. Next, we address a client-server association optimization problem to minimize global training loss. Using convergence analysis, we propose a greedy client scheduling algorithm. Finally, our experiments conducted on real-world datasets demonstrate that TRAIL outperforms state-of-the-art baselines, achieving an improvement of 8.7% in test accuracy and a reduction of 15.3% in training loss.", "sections": [{"title": "Introduction", "content": "The integration of advanced communication technologies with industrial manufacturing significantly enhances production efficiency and flexibility, accelerating the transition to smart manufacturing (Chen et al. 2024; Lu et al. 2021; Tan et al. 2023). This integration facilitates seamless connectivity between devices and systems through real-time data collection and analysis, which greatly improves the transparency and controllability of production processes (Yu et al. 2023; Wang et al. 2020). Additionally, the incorporation of Artificial Intelligence (AI) further enhances these capabilities. By enabling systems to process and analyze large volumes of data, AI provides solutions for predictive maintenance, intelligent decision-making, and process optimization (Wu et al. 2024).\nIn modern Al systems, local data on end devices often contains sensitive or private information, rendering traditional edge AI training architectures impractical (Zhang et al. 2024; Wu et al. 2023). To address security and privacy concerns while minimizing communication costs, a new distributed machine learning framework called Federated Learning (FL) has emerged (Wu et al. 2023; McMahan et al. 2016). In FL, each client uploads only model parameters, safeguarding their local data. Typically, this process involves coordination with a single edge server, which can result in high communication overhead and potential single points of failure, particularly in environments with numerous end devices (Zhang et al. 2023a; Lu et al. 2022).\nThis paper investigates semi-decentralized Federated Learning (SD-FL) as a framework to enhance the reliability of model training. As illustrated in Figure 1, we focus on a multi-edge server, multi-client SD-FL framework (Sun et al. 2021b). This architecture employs a two-tier aggregation approach: first, intra-cluster aggregation, where local models are aggregated by their respective servers, followed by inter-cluster consensus, where models from multiple servers are exchanged and collaboratively aggregated to train a shared global model. By distributing computational and communication loads, SD-FL improves both the robustness and scalability of the Federated Learning process. While SD-FL mitigates risks associated with single points of failure, existing research often overlooks the dynamic nature of clients, particularly fluctuations in model contributions and communication quality, which can adversely affect training efficiency (Sun et al. 2021a).\nResearch has been conducted to address the issue of unreliable clients. In (Sefati and Navimipour 2021), the authors introduce an effective service composition mechanism based on a hidden Markov model (HMM) and ant colony optimization to tackle IoT service composition challenges related to Quality-of-Service parameters, achieving significant improvements in availability, response time, cost, reliability, and energy consumption. In (Ma et al. 2021), the FedClamp algorithm is proposed, which enhances the performance of the global model in Federated Learning environments by utilizing HMM to identify and isolate anomalous nodes. This algorithm is specifically tested on short-term energy forecasting problems. The authors of (Vono et al. 2021) present the Quantized Langevin Stochastic Dynamics (QLSD) algorithm, which employs Markov Chain Monte Carlo methods to improve dynamic prediction capabilities in Federated Learning while addressing challenges related to privacy, communication overhead, and statistical heterogeneity. Additionally, (Wang et al. 2024) introduces a trust-Age of Information (AoI) aware joint design scheme (TACS) aimed at enhancing control performance and reliability in wireless communication networks within edge-enabled Industrial Internet of Things (IIoT) systems operating in harsh environments, utilizing a learning-based trust model and scheduling strategy. While these studies explore various dynamic aspects, they do not adequately address the interplay between dynamics and client selection strategies.\nTo address this gap, we employ a Markov model to predict dynamic changes in client performance and communication quality, allowing us to schedule clients based on these predictions to minimize loss. We propose a joint design scheme that integrates dynamic prediction with client selection, significantly enhancing the control performance and reliability of Federated Learning systems. Extensive experiments and theoretical analyses demonstrate the effectiveness and robustness of our approach under varying client dynamics. The main contributions of this paper are summarized as follows:\n\u2022 We propose a unified optimization framework for SD-FL that integrates performance prediction and client scheduling, enhancing model robustness, accelerating convergence speed, and improving overall performance.\n\u2022 We introduce an adaptive hidden semi-Markov model (AHSMM) to predict client performance and channel variations to obtain trust levels. This model effectively accounts for both dynamic and static aspects of clients, enabling efficient state predictions for each one.\n\u2022 Through convergence analysis, we assess the anticipated effects of client-server relationships on convergence. This analysis allows us to reformulate the initial optimization challenge as an Integer Nonlinear Programming problem, for which we devise a greedy algorithm to optimize client scheduling efficiently.\n\u2022 Our experiments on real-world datasets demonstrate that our proposed mechanism outperforms state-of-the-art baselines, achieving an 8.7% increase in test accuracy and a 15.3% reduction in training loss."}, {"title": "Related Work", "content": "In Federated Learning (FL), model training is distributed across multiple clients to protect data privacy and minimize the need for centralized data aggregation. Traditional Federated Learning assumes reliable and frequent communication between clients and the server. However, this assumption often fails in real-world applications, particularly in environments with heterogeneous devices and unstable communication. To address these challenges, researchers have introduced semi-decentralized Federated Learning (SD-FL). This approach combines the benefits of centralized and distributed architectures by enabling direct communication among some clients, thereby reducing the server's workload and communication costs. SD-FL is better equipped to adapt to dynamic network environments and heterogeneous data distributions, enhancing the system's robustness and efficiency.\nCurrent research efforts primarily focus on the following areas. Communication Optimization: Efficient communication protocols are designed to reduce the frequency of interactions between clients and the server, lowering latency and bandwidth usage (Lin et al. 2021; Wang et al. 2024; Yemini et al. 2022; Sun et al. 2023). Trust Management: Trust mechanisms are introduced to evaluate and select clients for participation in training, thereby improving the overall credibility and performance of the model (Beltr\u00e1n et al. 2023; Parasnis et al. 2023; Xu et al. 2024; Valdeira et al. 2023). While there are studies that focus separately on communication optimization and trust management, existing methods often fail to effectively integrate these aspects. This gap negatively impacts the efficacy and efficiency of Federated Learning systems. An integrated approach that addresses both communication efficiency and participant reliability is essential for enhancing the robustness and performance of SD-FL, especially in diverse and potentially unreliable environments."}, {"title": "System Model", "content": "Here, we explore the SD-FL framework, as illustrated in Figure 1. We first present SD-FL's basic workflow, then establish an adaptive semi-Markov model to estimate each client's model quality and communication quality."}, {"title": "Basics of SD-FL", "content": "In this paper, we examine the SD-FL training process across T rounds, involving S edge servers represented by $\\mathcal{S} = \\{1, 2, ..., S\\}$, and U client devices represented by $\\mathcal{U} = \\{1, 2, ..., U\\}$. Each round consists of the following steps:"}, {"title": "AHSMM Model", "content": "The Adaptive Hidden Semi-Markov Model (AHSMM) extends the traditional Hidden Semi-Markov Model (HSMM) (Dai et al. 2022) by integrating adaptive training to facilitate device training quality diagnostics, communication quality diagnostics, and lifespan prediction and using multi-sensor information, thereby enhancing both modeling and analytical capabilities. The AHSMM model can be described by the parameters $\\Sigma = (\\pi, A, B, E)$, where: $\\pi$ represents the initial state probabilities, A denotes the macro state transition probabilities, B corresponds to the observation probabilities after adaptive training, E represents the state dwell time after adaptive training, encompassing both the existing and remaining dwell times. In addition, similar to HSMM, AHSMM addresses three core problems: evaluation, recognition, and training. To this end, AHSMM defines new forward-backward variables and proposes improved algorithms for forward-backward processes, the Viterbi algorithm (Zhang et al. 2023b), and the Baum-Welch algorithm (Zhang et al. 2023c).\nThe computational complexity of the Hidden Semi-Markov Model (HSMM) is relatively high. To address this complexity, the Adaptive Hidden Semi-Markov Model (AHSMM) introduces a new forward variable, denoted as $\\alpha_t(i, e)$. This variable represents the probability of generating the observations $Z_1, Z_2,..., Z_t$, given that the quality state i has a specific dwell time of $e_t(i, e) = e$. In this context, $\\mathcal{E}_t$ signifies the current dwell time of the quality state $q_t$.\nWhen $(q_t, \\&_t)$ is assigned the value $(i, e)$, it indicates that the device has remained in its current quality state i up to time t. During this period, the state i has accumulated a dwell time of e and is prepared to transition to a different quality state at time t+ 1. Therefore, for $1 \\leq t \\leq T-1$ and $e \\in [1, E]$, we can define the forward variable as follows:\n$\\alpha_t(i, e) = p (z_1, (q_{[t-e+1,t]} = i, \\mathcal{E}_t = e) | \\Sigma).$ (1)\nThe forward recursion is obtained as:\n$\\alpha_t(i, e) =\\begin{cases}\\sum_{j \\neq i} a_{jt} b_i(z_t) (\\sum_{e=1}^{\\mathcal{E}} \\alpha_{t-1}(j, \\epsilon) p_i(e)), & \\text{if } e = 1, \\\\ \\alpha_{t-1}(i, e - 1) \\prod_{s=1}^{N} b_i(z_{t-s+1}), & \\text{if } e > 1, \\\\ \\pi_i b_i(z_1) p_i(e), & \\text{if } t = 1, \\\\ 0, & \\text{if } \\tau < 1.\\end{cases}$ (2)\nIn the context of AHSMM, let $\\mathcal{E}$ represent the maximum state dwell time among all quality states. Given the model $\\Sigma$, the probability of observing the sequence Z is expressed as:\n$p (\\bold{z} | \\Sigma) = \\sum_{(i,e)} \\alpha_T(i, e).$ (3)\nIn this context, the variable $\\alpha_T(i, e)$ is defined as the joint probability of observing the sequence $z_1, z_2,..., z_T$ while the system is in quality state i over the dwell time interval from T-e +1 to T. Mathematically, it can be expressed as:\n$\\alpha_T(i, e) = p (q_{[T-e+1,T]} = i | z_1, z_2, ..., z_T, \\Sigma) \\cdot p (z_1, z_2,..., z_T | \\Sigma).$ (4)\nFor $1 \\leq t \\leq T- 1, e \\in [1, E]$, and $i, j \\in S$, the backward variable can be defined as:\n$\\beta_t(i, e) = p (z_{(t+1):T} | q_{[t-e+1,t]} = i, \\Sigma).$ (5)\nThis formulation improves the efficiency of computing the forward and backward variables in the AHSMM, leading to reduced computational complexity compared to the traditional HSMM. In the backward variable $\\beta_t(i, e)$, the quality state i has been active for e time steps. By summing over all quality states and potential dwell times, the backward recursion can be expressed as follows:\n$\\beta_t(i, e) = \\sum_{j} (\\mathbb{I}(j \\neq i) \\beta_{t+1}(j, 1) a_{ij} p_i(e) b_j (z_{t+1})) + \\beta_{t+1}(j, e + 1) \\prod_{s=1}^{e} b_i (z_{t+s}).$ (6)\nWe estimate the quality state $q_t$ and update the parameters of the model $\\Sigma$. Using the previously defined forward and backward variables, we derive $q_t$ and adjust the model parameters. Given the model $\\Sigma$ and the observation sequence $z_{1:T}$, let $\\xi_t(i, j)$ represent the joint probability of the observation sequence $z_{1:T}$ and the transition from quality state i to quality state j (where $i \\neq j$) at time t. The specific formula is as follows:\n$\\xi_t(i, j) = p (z_{1:T} | q_{t-1} = i, q_t = j, \\Sigma) \\cdot P (q_{t-1} = i, q_t = j | \\Sigma).$ (7)"}, {"title": "AHSMM Prediction and Client Scheduling", "content": "To determine quality states from a sequence of observations, it is essential to have both a predefined model and the sequence of observations. The following equation describes the recursive estimation of quality states based on this model:\n$\\gamma_t(i) = \\sum_{j=1}^{\\mathcal{E}} \\alpha_t (j, e) p (q_t = i | \\Sigma) \\cdot P (z_{1:T} | q_t = i, \\Sigma).$ (8)\nThis recursive formulation allows for the estimation of the quality state at time t based on the observation sequence $z_{1:T}$ and the given model parameters $\\Sigma."}, {"title": "AHSMM Parameter Estimation", "content": "Monitoring a device with multiple sensors can significantly improve quality prediction. Given the inherent differences among sensors, effective data fusion is essential for integrating their information. Consequently, estimating the parameters of the AHSMM becomes necessary. This estimation process utilizes Maximum Likelihood Linear Regression (MLLR) transformations to address the variations across sensors. Simultaneously, a canonical model is trained based on a set of MLLR transformations. Linear transformations are then applied to the mean vectors of the state output and dwell time distributions in the standard model, allowing for the derivation of mean vectors for these distributions.\nThe formulas are given by:\n$\\begin{cases}b_i (z^{(s)}) = \\mathcal{N} (z^{(s)}; \\mu_i^{(s)}, \\Sigma_i)\\\\p_i(e) = \\mathcal{N} (e; \\mu_e^{(s)}, \\sigma_i^2)\\\\ \\mu_e^{(s)} = \\delta^{(s)} m_i + \\psi^{(s)}\\end{cases}$ (9)\nHere, $b_i (z^{(s)})$ represents the probability density function for the state i based on the observed data $z^{(s)}$ from sensor s, modeled as a multivariate normal distribution with mean $\\mu_i^{(s)}$ and covariance $\\Sigma_i$. The term $p_i(e)$ signifies the probability density function for the dwell time e in state i, also following a normal distribution characterized by mean $\\mu_e^{(s)}$ and variance of $\\sigma_i^2$. The mean dwell time $\\mu_e^{(s)}$ is calculated using the formula $\\mu_e^{(s)} = \\delta^{(s)} m_i + \\psi^{(s)}$, where $\\delta^{(s)}$ is a scaling factor, $m_i$ represents a parameter related to state i, and $\\psi^{(s)}$ is a sensor-specific offset.\nJoint Estimation of AHSMM Parameters. Let S denote the number of sensors, and let $\\mathbb{Z} = (z^{(1)}, ..., z^{(s)})$ represent the monitoring data, where $z^{(s)} = (z_{1:s},z_{T:s})$ represents the monitoring data of sensor s with length $T_s$.\nHere, the parameters are estimated by jointly considering the contributions of all sensors and their respective transformations. The term $\\mathcal{Y}_i^{(e)}$ represents the probability of being in state i with dwell time d at time t, $n^{(s)}$ and $g^{(s)}$ are the transformation matrices and vectors for sensor s, and $\\Sigma_i$ is the covariance matrix for state i. This joint estimation process ensures that the model parameters are optimally adjusted for the diverse sensor data.\nThe MAP estimation of state $q_t$ using the AHSMM is calculated in the following way:\n$\\hat{q}_t = \\arg \\max_q \\prod_{s=1}^{S} (p (z^s | q_t, \\Sigma).$ (10)\nIn client quality diagnostics and forecasting, information from various sensors often plays distinct roles in decision-making. The AHSMM addresses the challenge of effectively integrating data from multiple sensors."}, {"title": "Prediction Process Based on AHSMM", "content": "Assuming $F(0) = 0$ and the failure probability density function $f(t) = F'(t)$, the HR function is defined as:\n$\\Sigma(t) = \\frac{f(t)}{1 - F(t)} = \\frac{dk(t)}{N - k(t)dt}$ (11)\nA device transitions through multiple quality states before ultimately reaching a failure state. Let $E(i)$ represent the residence time in quality state i. We can express $E(i)$ as follows:\n$E(i) = m(i) + \\rho \\sigma^2(i),$\nwhere $m(i)$ denotes the mean dwell time in state i, and $\\sigma^2(i)$ is the variance of the dwell time in that state. The term $\\rho$ serves as a proportionality constant, which adjusts the influence of the variance on the overall residence time.\nThis formulation captures the idea that the total time spent in a quality state is influenced not only by the average time spent there but also by the variability of that time. A higher variance indicates greater uncertainty in the duration spent in state i, which can lead to longer overall residence times. By incorporating both mean and variance, we obtain a more comprehensive view of the dynamics in quality states.\nThe proportionality constant $\\rho$ is defined as:\n$\\rho = \\frac{T - \\sum_{i=1}^{N} m(i)}{\\sum_{i=1}^{N} \\sigma^2(i)}$ (12)\nwhere T is the total lifespan, $m(i)$ is the mean dwell time in state i, and $\\sigma^2(i)$ is the variance.\nThe reliability function $R(t + e\\Delta t)$ represents the probability that the client remains in the current quality state i at time t + e$\\Delta$t. Thus:\n$\\gamma_e (i) = R(t + e\\Delta t).$ (13)\nTherefore:\n$\\frac{\\Sigma(t + e\\Delta t)}{\\gamma_e(i)} = \\frac{\\xi(i, j)}{\\Delta t}$ (14)\nBased on above equations, $\\tilde{E}(i, e)$ is expressed as:\n$\\tilde{E}(i, e) = E(i) \\frac{E(i) \\xi_e (i, j)}{\\gamma_e (i)}$ (15)"}, {"title": "Client Selection", "content": "Using the previous equations, once the client reaches state i and has a dwell time, the trust level (TL) is determined as:\n$TL_{(i,e)} = \\frac{E(i, e)}{\\sum_{j=1}^{N} E(j)} + \\frac{1}{\\sum_{j=1}^{N} E(j)}$ (16)\nConsidering the above configuration, the model aggregation within the cluster at server s can be described as follows:\n$w_{s,t} = \\sum_{i \\in U_s} \\frac{N_i}{\\sum_{i \\in U_s} N_i} w_{i,t}.$ (17)\nFurthermore, the model consensus between clusters at server s during training round t is characterized as follows:\n$g_{s,t} = \\frac{1}{S} \\sum_{s=1}^{S} \\Omega_s w_{s,t}$ (18)\nFurthermore, during the next round of training, each client utilizes the updated local model along with their respective datasets. The local models are trained using the gradient descent mechanism described below. This mechanism allows for distributed learning, where clients can collaboratively train a model while keeping their data localized, thus addressing privacy concerns and reducing bandwidth requirements for data transmission."}, {"title": "Problem Formulation", "content": "Client scheduling aims to determine the optimal client-server association matrix d, minimizing the overall training loss. Each element $d_{ij}$ is binary (1 for associated, 0 for not), optimizing data locality, reducing communication overhead, and balancing computational loads. Factors like client data, server capacity, and network conditions influence d's configuration, while adaptive scheduling further enhances performance. The global loss function is:\n$F(g) = \\frac{1}{N} \\sum_{s=1}^{S} \\sum_{i \\in U_s} F_i (g).$ (19)\nTherefore, the optimization of the client-server association matrix can be achieved by solving the problem of minimizing the global training loss:\n$\\min_d F(g) = \\frac{1}{N} \\sum_{s=1}^{S} \\sum_{i \\in U_s} F_i (g)$ (20)\nsubject to $\\sum d_{i,s} \\leq 1, \\forall s \\in S\\quad \\quad d_{i,s} \\in \\{0, 1\\}, \\quad \\quad TL_i > \\Theta.$"}, {"title": "Convergence Analysis", "content": "We rely on current trust levels of client i to tackle these challenges, reduce data loss, and guarantee consistent model updates. $\\Theta$ denotes the threshold for the trust level of clients involved in training. Reformulating the optimization problem to incorporate parameters that reflect communication link stability will enhance the modeling of the FL system's conditions.\nWe also plan to enhance FL system robustness through redundancy strategies, like multiple communication paths or backup servers, to mitigate risks from unreliable links. Dynamically adjusting client-server associations based on real-time assessments will help maintain optimal performance despite trust fluctuations. This approach maximizes resource utilization and minimizes training time, leading to more robust convergence and broader adoption in real-world applications.\n$\\textbf{Theorem 1} . Setting the learning rate to $ \\alpha = \\frac{2}{\\mu}$ allows us to establish the upper limit of $E (F (g_{t+1}) - F (g^*))$ in the following manner. The expected difference between the function value at the updated iterate $g_{t+1}$ and the optimal function value $g^*$ can be bounded as shown below:\n$E (F (g_{t+1}) - F (g^*)) \\leq DE (F (g_{0}) - F (g^*))$ (21)\n$\\frac{2 \\omega \\mu B}{L} + \\frac{1 - D_t}{1 - D}$ $ where $\\quad \\quad D = 1 - \\frac{\\mu}{L} + \\frac{4 \\omega \\mu B}{L}$ (22)\n$\\text{and} \\quad \\mathcal{B} = \\sum_{m \\in \\mathcal{E}} \\Psi , \\quad \\Psi = (L_{i \\in U} N_i d_{i,m} (D_m - 1 + I (TL_i < \\theta))) .$ (23)\nIn the definition of $\\mathcal{B}$, the following equations hold:\n$N(s) = \\sum_m n_i d_{i,m}, i \\in U \\qquad$ (24)\n$\\text{and} \\quad D_m = \\frac{1}{|S|}$ (25)\nFrom Theorem 1, the global training loss minimization initially outlined in the problem can be reinterpreted to focus primarily on minimizing the parameter $\\mathcal{B}$. This revised formulation, therefore, positions $\\mathcal{B}$ as the central target for reduction, aiming to directly influence and improve the overall system performance by addressing the underlying factors contributing to $\\mathcal{B}$'s value.\n$\\min_d \\frac{1}{\\mathcal{N}(s)} \\sum_m (L_{i \\in U} N_i d_{i,m} (D_m - 1 + I (TL_i < \\theta)). \\qquad$ (26)\nTo solve this nonlinear integer programming problem, we propose a greedy algorithm described in Algorithm 1."}, {"title": "Experiments Evaluation", "content": "This section will evaluate our proposed mechanisms using four real-world datasets. First, we will introduce the basic setup of the experiments and the benchmark for comparison. Then, we will present the results of our experimental comparisons."}, {"title": "Experments Setting", "content": "1. Basic Setup:\n\u2022 Here, we have configured a system with five edge servers and fifty clients. Each client possesses 1,000 local training data samples. Additionally, we have set up the system so that approximately 30% of the clients experience a gradual decline in training quality as the training progresses.\n2. Datasets:\n\u2022 Real-world Datasets. Four standard real-world datasets, e.g. MNIST (Rana, Kabir, and Sobur 2023), EMNIST (Majeed et al. 2024), SVHN (Pradhan et al. 2024), and CIFAR-10 (Aslam and Nassif 2023) are utilized to make performance evaluation.\n3. Training Setup:\n\u2022 Training Parameters. We utilize a CNN training architecture. The batch size is 32, the local update round e is set to 5, and the global training round E is set to 100. The learning rate \u03b7 is configured to 0.01 and the SGD momentum is set to 0.05.\n4. Baselines: In order to validate the effectiveness of our proposed mechanism, we compared our mechanism with the following three mechanisms.\n\u2022 GUROBI: In (Muley 2021), the authors utilize the GURUBI optimizer for the client's optimal allocation problem. The prediction part of the front end does not utilize the prediction mechanism of AHSMM.\n\u2022 TRUST. In (Wang et al. 2023), the authors introduce a trust-age of information (AoI)-aware co-design scheme (TACS), employing a learning-based trust model and trust-AoI-aware scheduling to optimize data selection for plant control dynamically.\n\u2022 RANDOM. Here, we continue to use the AHSMM for the prediction component, while employing random allocation for client assignments.\n5. Evaluation metrics: We use two metrics to evaluate our mechanisms: test accuracy and training loss. The results are obtained from the average of multiple experiments.\n\u2022 Test accuracy. Test accuracy is a crucial metric for model training in FL, representing the performance that model owners can achieve with their trained models.\n\u2022 Training loss. Training loss quantifies the discrepancy between the predicted outputs of a model and the actual data, guiding the optimization process to improve model accuracy and performance."}, {"title": "Experiments Results", "content": "In Figure 2, we analyze the variations in test accuracy and training loss over multiple training rounds for four distinct mechanisms, specifically under conditions where only 10% of users are classified as low quality. Our proposed mechanism stands out by achieving the highest performance across four real datasets. This success can be attributed to the effective integration of our AHSMM and a greedy algorithm, which work synergistically to accurately predict fluctuations in client learning and communication quality. By optimizing the participation of low-quality clients, our approach significantly enhances overall training outcomes. In contrast, the TRUST mechanism, despite employing a predictive approach, lacks an effective client distribution strategy. This deficiency leads to suboptimal performance, as it fails to adaptively manage client participation based on their quality. Similarly, the RANDOM mechanism incorporates the AHSMM to forecast client behavior, but it does not allocate clients efficiently, leading to less effective training sessions. Although the GUROBI mechanism is capable of determining an optimal client distribution scheme, its solution process is notably time-consuming, making it less efficient compared to our proposed greedy algorithm. Additionally, GUROBI does not incorporate client quality predictions, which hinders its ability to exclude low-quality clients from training participation in a timely manner, ultimately affecting the training efficiency. Overall, our mechanism demonstrates a superior ability to navigate the complexities of client quality by leveraging predictive modeling and strategic allocation, ensuring robust training performance in Federated Learning environments.\nIn Figure 3, we analyze the comparative performance of four mechanisms across scenarios characterized by varying proportions of low-quality clients. As the percentage of low-quality clients increases, all mechanisms demonstrate a decline in both training and testing accuracy, albeit to different extents. Notably, our proposed mechanism consistently delivers the best results across four real datasets, showcasing its robustness in challenging environments. The superior performance of our mechanism can be attributed to the integration of the AHSMM and a greedy-based client allocation scheme. This combination effectively predicts fluctuations in client learning and communication quality, enabling efficient client allocation that significantly enhances model training quality, even under adverse conditions. By optimizing the participation of higher-quality clients, we mitigate the negative impact of low-quality users on overall performance. In contrast, while the TRUST mechanism is capable of identifying unreliable clients, it lacks an efficient client distribution strategy. This limitation results in poorer training outcomes compared to our mechanism, as it fails to adaptively manage client participation based on their quality. Similarly, the RANDOM mechanism employs the AHSMM to accurately predict changes in client training quality but relies on a random allocation strategy during the client distribution phase. Consequently, this randomness undermines the final training effectiveness, leading to suboptimal results. The GUROBI mechanism, despite its potential for determining optimal client distributions, performs the worst in our experiments. Its inability to accurately predict changes in client learning quality restricts its effectiveness, as it cannot exclude low-quality clients in a timely manner. Our findings reveal a notable 8.7% increase in test accuracy and a 15.3% reduction in training loss compared to existing baselines, highlighting the efficacy of our approach in enhancing model performance in Federated Learning settings. These results underscore the importance of both predictive modeling and strategic client allocation in achieving high-quality training outcomes."}, {"title": "Conclusion", "content": "In this work, we proposed TRAIL, a novel mechanism designed to address the dynamic challenges in SD-FL. TRAIL significantly improves training efficiency and robustness by integrating an AHSMM to predict client states and contributions and a greedy algorithm to optimize client-server associations. Experimental results on real-world datasets show an improvement compared to state-of-the-art baselines.\nFor future work, we aim to enhance TRAIL by incorporating more complex dynamic modeling, multi-objective optimization, robustness against failures, scalability for large-scale systems, and stronger privacy and security mechanisms. These improvements will further broaden TRAIL's applicability and effectiveness in real-world decentralized learning scenarios."}]}