{"title": "Embedding with Large Language Models for Classification of HIPAA Safeguard Compliance Rules", "authors": ["Md Abdur Rahman", "Md Abdul Barek", "ABM Kamrul Islam Riad", "Md Mostafizur Rahman", "Md Bajlur Rashid", "Smita Ambedkar", "Md Raihan Miaa", "Fan Wu", "Alfredo Cuzzocrea", "Sheikh Iqbal Ahamed"], "abstract": "Although software developers of mHealth apps are responsible for protecting patient data and adhering to strict privacy and security requirements, many of them lack awareness of HIPAA regulations and struggle to distinguish between HIPAA rules categories. Therefore, providing guidance of HIPAA rules patterns classification is essential for developing secured applications for Google Play Store. In this work, we identified the limitations of traditional Word2Vec embeddings in processing code patterns. To address this, we adopt multilingual BERT (Bidirectional Encoder Representations from Transformers) which offers contextualized embeddings to the attributes of dataset to overcome the issues. Therefore, we applied this BERT to our dataset for embedding code patterns and then uses these embedded code to varioud machine learning approaches. Our results demonstrate that the models significantly enhances classification performance, with Logistic Regression achieving a remarkable accuracy of 99.95%. Additionally, we obtained high accuracy from Support Vector Machine (99.79%), Random Forest (99.73%), and Naive Bayes (95.93%), outperforming existing approaches. This work underscores the effectiveness and showcases its potential for secure application development.", "sections": [{"title": "I. INTRODUCTION", "content": "As Android devices become increasingly popular due to their flexibility and affordability, the need for secure software development remains critical. The Android platform is a main target for attackers seeking to exploit security vulnerabilities within mobile applications [1]. Therefore, software developers need to ensure their apps must be HIPAA (Health Insurance Portability and Accountability Act) compliant because mHealth apps handle sensitive personal health information (PHI). The Open Web Application Security Project (OWASP) has stressed the significance of tackling these vulnerabilities through its OWASP Mobile Top 10 list [2]. This list identifies the most prevalent security issues in mobile apps and serves as a key benchmark for evaluating tools designed to detect vulnerabilities [3]. Following OWASP guidelines is essential for improving app security and protecting users.\nThe number of reported software vulnerabilities has steadily increased over the past decade (Fig. 1). Fig. 2 shows vulnerabilities distribution reported over the years, grouped by severity levels. It highlights how vulnerabilities have varied in frequency and severity across different time periods."}, {"title": "II. HIPAA", "content": "HIPAA compliance for Android applications is crucial for developers building mobile health (mHealth) apps that handle sensitive patient data. Health Insurance Portability and Accountability Act (HIPAA) creates stringent guidelines inoder to protect personal health information (PHI), ensuring that apps adhere to privacy, security, and confidentiality standards.\nAndroid apps must implement secure data storage, transmission, and processing mechanisms. This includes encryption of PHI both in transit and at rest, as well as secure authentication and access controls to prevent unauthorized access. Developers should also implement secure logging and auditing features to track access and changes to sensitive data.\nMoreover, Android apps need to comply with HIPAA's breach notification rules, requiring developers to inform users and authorities in case of data breaches. Failing to meet these standards can result in severe penalties. Therefore, ensuring HIPAA compliance is essential for building trustworthy and secure Android-based healthcare applications, protecting patient privacy, and avoiding legal risks."}, {"title": "B. HIPAA Technical Safeguard Rules", "content": "HIPAA's Technical Safeguard Rules play a critical role in protecting electronic protected health information (ePHI). These rules, outlined by the Health Insurance Portability and Accountability Act (HIPAA), require healthcare providers and mHealth app developers to implement stringent security measures to safeguard patient data. These measures are intended to prevent unauthorized access, alteration, or exposure of sensitive health information. By complying with these regulations, organizations can protect patient data from potential security breaches and cyberattacks. Key defenses, such as encryption, access controls, and activity monitoring systems, must be employed to ensure the confidentiality and integrity of ePHI. Non-compliance with these security standards can lead to serious legal consequences and privacy risks, making it imperative for any entity handling ePHI to fully adhere to HIPAA's technical and administrative safeguards.\nKey components of the Technical Safeguard Rules include access control, which ensures only authorized individuals can access ePHI. This is typically achieved through mechanisms like unique user identification, automatic logoff, and encryption. Audit controls must also be implemented to record and examine activity related to ePHI, allowing organizations to track data access and prevent breaches.\nIntegrity controls ensure that ePHI is not improperly altered or destroyed, maintaining its accuracy and reliability. Finally, transmission security safeguards require encryption methods to protect ePHI when being transmitted over electronic networks. By adhering to these rules, organizations can maintain the confidentiality, integrity, and security of sensitive patient information."}, {"title": "III. LARGE LANGUAGE MODELS FOR SOFTWARE VULNERABILITIES", "content": "Large Language Models (LLMs) have demonstrated potential for identifying software vulnerabilities, but they come with notable limitations. Their accuracy averages around 60% across datasets, and while they excel at detecting simpler vulnerabilities that require basic local reasoning, they face challenges with more complex vulnerabilities found in real-world programs. In comparison to static analysis tools like CodeQL, LLMs fall short in terms of precision and accuracy. Additionally, they struggle to differentiate between vulnerable and patched code. Larger LLMs, such as GPT-4, are also vulnerable to adversarial attacks, where their performance mildly drops when malicious code is introduced. Furthermore, LLMS can be susceptible to data poisoning, where attackers inject harmful data into the training process, as well as backdoor attacks that manipulate the model during training to embed hidden vulnerabilities.\nDespite these challenges, LLMs offer distinct advantages. They can explain their predictions in natural language, making it easier for users to understand the results. LLMs also excel in few-shot learning, meaning they can generalize from very few examples, which can be highly beneficial when limited training data is available. Additionally, using prompts specifically tailored to detect certain Common Weakness Enumerations (CWEs) can boost LLM performance. Incorporating advanced prompting strategies, such as step-by-step analysis, can further enhance their capabilities, enabling more accurate detection of software vulnerabilities."}, {"title": "IV. BERT FOR CODE PROCESSING", "content": "BERT can be effectively applied for embedding datasets by transforming raw text into high-dimensional vector representations. By leveraging its bidirectional architecture, BERT comprehends the context of each word in relation to the entire sentence, resulting in embeddings that reflect the nuances of language. This ability allows BERT to generate embeddings that retain important information, making them suitable for various natural language processing tasks. Fine-tuning BERT on specific datasets further enhances the quality of these embeddings, enabling models to better understand domain-specific terminology and relationships within the data.\nWhen applied to embedding datasets, BERT utilizes its masked language modeling and next sentence prediction tasks during pretraining to create context-aware representations. These embeddings can be used in downstream applications such as text classification, code analysis, vulnerabilities detection and classification. By representing each piece of text as a dense vector, BERT facilitates the identification of semantic similarities and relationships between different data points. This capability allows for improved performance in various machine learning tasks, particularly in applications where understanding context and meaning is crucial."}, {"title": "V. DATASET", "content": "This research utilizes a unique dataset developed by the HIPAA lab at UBITRIX INTERNATIONAL, INC., as part of the STTR-II project. The project focuses on creating HIPAA compliance rule patterns for various platforms, including Android, iOS, and web applications. We have collected code samples of Android applications from our HIPAA engine codebase to create our own dataset, STTR-HIPAA, by our lab members. The dataset was specifically generated by testing Android applications and identifying matching code segments related to HIPAA guidelines. It contains four key attributes: ID, which uniquely identifies each record; Description, providing a brief explanation of the detected vulnerability; Code_Segment, which highlights the relevant portion of the Android code; and Label, indicating which of the HIPAA rules is being violated. The Label has 10 rules which are: user_inactivity, phi_encryption, encryption_decryption, data_integrity, authorization, auth_destruction, user_authentication, unique_id, transmition_secuirity, and audit. Fig. 3. shows the frequencies of observations for all HIPAA rules. The dataset comprises 252,384 observations, covering ten distinct HIPAA rules that govern the protection and security of sensitive healthcare data."}, {"title": "VI. METHODS", "content": "Our methodology focuses on analyzing and classifying code patterns associated with various HIPAA rules present in source code. This process begins by collecting samples of code patterns from our codebase, specifically targeting segments that may violate HIPAA compliance. We label these code samples accurately, depending on their specific rule matches.\nTo ensure the quality of the created dataset, we employ machine learning techniques for further analysis. Specifically, we use an \"evaluating and correcting\" approach to adjust the labels in the datasets based on the classification outcomes we obtain from our models. This step is crucial for maintaining the integrity of our dataset.\nOnce we assess whether an application complies with HIPAA, our HIPAA engine stores the relevant set of codes, indicating which rules have been matched. Initially, we create and compile the STTR dataset, which we then split into training and testing sets. The dataset is utilized with multilingual BERT to embed attributes sourced from the Hugging Face Hub [11] (Fig. 4). This embedded dataset serves as the foundation for training four distinct types of machine learning models, each have been focused with optimized parameters (Fig. 5). After training, we test all models to evaluate how it works to classify HIPAA rule code patterns effectively. This classification process is essential for software developers, enabling them to identify and rectify specific areas within their applications that require compliance adjustments."}, {"title": "VII. RESULTS AND DISCUSSIONS", "content": "Accuracy is quantified using the following formula:\nAccuracy = $\\frac{TP + TN}{TP + TN + FP + FN}$\n* TP (True Positives): The number of positive cases correctly identified by the model.\n* TN (True Negatives): The count of negative cases accurately classified.\n* FP (False Positives): Negative instances mistakenly classified as positive.\n* FN (False Negatives): Positive instances that the model failed to identify as positive.\nPrecision evaluates the correctness of the model when it predicts positive cases:\nPrecision = $\\frac{TP}{TP + FP}$\nRecall, on the other hand, measures the proportion of actual positive cases that the model successfully identifies:\nRecall = $\\frac{TP}{TP + FN}$\nThe F1-score, which ranges from 0 to 1, provides a single metric to gauge model performance by balancing precision and recall. A score of 0 reflects poor performance, while a score of 1 indicates exceptional performance:\nF1-Score = 2 \u00d7 $\\frac{Precision \u00d7 Recall}{Precision + Recall}$\nThese statistical measures are vital for evaluating the efficacy of the prompt injection detection system in recognizing malicious prompt attacks.\nIn our research, we implemented DistilBERT to detect malicious prompts and multilingual BERT for embedding attributes. Our findings indicate that the multilingual BERT model generally outperforms other classifier when it comes to classifying HIPAA rules patterns as the BERT-base-multilingual-uncased model is specifically designed to handle multiple languages effectively. This model has been trained on a diverse range of texts across various languages, enabling it to comprehend and generate text embeddings suitable for different linguistic contexts. Consequently, this design leads to enhanced performance and improved accuracy when processing multilingual data, making it particularly adept at understanding nuanced text variations. In summary, our analysis highlights the importance of selecting the right machine learning model for specific tasks, particularly in the context of multilingual code patterns processing for classification.\nThe performance metrics presented in TABLE I indicate that the machine learning models applied to the direct dataset yielded moderate results. For instance, the highest accuracy recorded was 0.8011 for Support Vector Regression (SVR), while other models, such as Logistic Regression and Naive Bayes, displayed lower accuracy and precision scores. The overall F1-scores, which ranged from 0.7228 to 0.7440 suggest that the models struggled with accurately identifying true positives.\nIn contrast, TABLE II highlights significant enhancements in model performance after applying data engineering techniques to the dataset. The metrics show impressive accuracy, with Logistic Regression achieving 0.9995 and SVR also demonstrating high precision and recall. The corresponding F1 scores reflect this improvement, soaring to 0.9995. Additionally, a bar diagram visually compares these two sets of performance metrics, clearly illustrating the dramatic improvements achieved through data engineering (Fig. 6). The enhanced metrics underscore the vital role of preprocessing in optimizing machine learning models and their ability to deliver reliable predictions, emphasizing the importance of quality data in model training.\nTable III compares the accuracy between our proposed model and existing works. The existing models include LSTM and HDSF applied to the \"Fake or Real News\" dataset, which achieved accuracies of 80.54% and 82.19%, respectively. The TCNN and TCNN-URG models, evaluated on the Weibo dataset, demonstrated a slightly better performance, reaching accuracies of 88.08% and 89.84% (Fig. 7)."}, {"title": "VIII. CONCLUSION", "content": "We found the challenges of HIPAA rules classification and identified the limitations of traditional Word2Vec embeddings. To address this, we processed attributes through data engineering and applied multilingual BERT to enhance the classification of the rules patterns using various ML algorithms. After applying data engineering, the Logistic Regression reached an impressive accuracy of 99.95%. Other models, including SVR and Random Forest, also demonstrated high performance, highlighting the effectiveness of multilingual BERT in promoting secure and compliant application development compared to exiting detection approaches. This work underscores the potential for improved security and compliance in the development of healthcare-related applications. We would like to fine the pre-trained LLMs with specific dataset for detection whether the applications are HIPAA compliant or not."}]}