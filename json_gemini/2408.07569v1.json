{"title": "Multi-task Heterogeneous Graph Learning on Electronic Health Records", "authors": ["Tsai Hor Chan", "Guosheng Yin", "Kyongtae Bae", "Lequan Yu"], "abstract": "Learning electronic health records (EHRs) has received emerging attention because of its capability to facilitate accurate medical diagnosis. Since the EHRs contain enriched information specifying complex interactions between entities, modeling EHRs with graphs is shown to be effective in practice. The EHRs, however, present a great degree of heterogeneity, sparsity, and complexity, which hamper the performance of most of the models applied to them. Moreover, existing approaches modeling EHRs often focus on learning the representations for a single task, overlooking the multi-task nature of EHR analysis problems and resulting in limited generalizability across different tasks. In view of these limitations, we propose a novel framework for EHR modeling, namely MulT-EHR (Multi-Task EHR), which leverages a heterogeneous graph to mine the complex relations and model the heterogeneity in the EHRs. To mitigate the large degree of noise, we introduce a denoising module based on the causal inference framework to adjust for severe confounding effects and reduce noise in the EHR data. Additionally, since our model adopts a single graph neural network for simultaneous multi-task prediction, we design a multi-task learning module to leverage the inter-task knowledge to regularize the training process. Extensive empirical studies on MIMIC-III and MIMIC-IV datasets validate that the proposed method consistently outperforms the state-of-the-art designs in four popular EHR analysis tasks - drug recommendation, and predictions of the length of stay, mortality, and readmission. Thorough ablation studies demonstrate the robustness of our method upon variations to key components and hyperparameters.", "sections": [{"title": "1. Introduction", "content": "The process of clinical decision making heavily relies on the medical records of patients. These records, however, present a great degree of heterogeneity, sparsity, and complexity in practice, making feature representation learning difficult.  illustrates the current challenges of EHR analysis. In order to provide accurate clinical decisions, clinicians have to traverse through the complex records to search for evidential information, which is time-consuming and cost-ineffective. Recently, with the increasing availability of electronic health records (EHRs) in machine-readable forms, deep learning models have shown their powerful capability to mine the deep connections between medical entities and facilitate accurate decision making. These deep learning models on EHRs have shown great potential in developing personalized medical treatment and improving healthcare quality.\nMost of the early methods leverage the longitudinal characteristics of the clinical visits by patients and adopt recurrent neural networks (RNNs) [3, 24, 20] to capture the temporal features in the EHR data. While these methods highlight the temporal or spatial features in the EHR data, they ignore the relational features in the EHRS which are potentially the most important features. In light of the importance of relational features, there are attempts in recent research to adopt graph neural networks (GNNs) to model the EHR data. GNNs operate on the graph domain and can highlight the relational features between the EHR entities. Despite their successes, most of these methods operate on homogeneous graphs which focus on relations between the neighboring nodes. This strategy does not address the heterogeneity and the semantic relations in the EHR data.  illustrates the complexity of relations between medical entities in the EHRs, highlighting the limitations of using homogeneous graphs that lead to suboptimal clinical decision performance.\nFurthermore, the EHR data encompass various tasks such as drug recommendation, and predictions of in-hospital mortality, readmission, and the length of stay. These tasks heavily depend on the features of patients and their visits. However, existing designs predominantly focus on single-task prediction, and thus they fail to incorporate the multi-task characteristics of EHR data. By sharing the learned patient or visit representations among tasks, the task-level knowledge can be leveraged to yield a better predictive performance. Hence, a multi-task model would potentially benefit from these characteristics of EHRs.\nAdditionally, it is well-known that EHRs suffer from severe noise and confounding effects, as patients have diverse backgrounds and medical records (e.g., diagnosis, medications, and prescriptions). Most of the existing methods directly operate on the features with heavy noises without adjusting for confounding effects, which hinder their performance on downstream tasks. Hence, a denoising measure is necessary to mitigate the confounding effects in the EHRs.\nMotivated by the aforementioned limitations in existing research, we propose a novel multi-task framework for EHR analysis, namely MulT-EHR (Multi-Task EHR). MulT-EHR adpots a heterogeneous graph, which is trained by a causal denoising module and a multi-task aggregation module. Our contributions are summarized as follows:\n\u2022 We propose a novel heterogeneous graph-based framework for modeling EHR data, namely MulT-EHR, which effectively mines EHR data by multi-task graph learning.\n\u2022 To effectively model the structural relationships in the EHR heterogeneous graph, we first enhance the relational features within the graph by leveraging a pretraining module based on graph contrastive learning. We then adopt a transformer-based GNN architecture to effectively learn the node-level representations.\n\u2022 We reinterpret denoising using the causal inference framework and propose a causal denoising module to adjust for the confounding effects to mitigate the catastrophically heavy noise in the EHRs.\n\u2022 We design a task-level aggregation mechanism to regularize the multi-task learning procedure by minimizing the cross-task extrapolation risk. This enables the single shared-weight model to leverage the cross-task knowledge more effectively.\n\u2022 We perform extensive experiments on two benchmark datasets to validate the effectiveness of our method over state-of-the-art methods. Our model is shown to consistently outperform the competitors over four popular clinical tasks based on EHRS - predictions of mortality, readmission, length-of-stay, and drug recommendation. Enriched ablation studies demonstrate the robustness of our method to different components and hyperparameters."}, {"title": "2. Related Works", "content": "2.1. Graph Neural Networks\nGNNs are gaining significant success in many problem domains [16, 11, 18, 2]. Most of the existing GNN architectures focus on homogeneous graphs [35, 33, 37, 45]. They learn node representations by aggregating information from the neighboring nodes on the graph topology. These algorithms are effective when the level of node and edge heterogeneity is negligible. As a heterogeneous graph contains enriched semantic information, several works [34, 11, 12, 42] attempt to design GNN algorithms on heterogeneous graphs. These works mine the complex relational information in a heterogeneous graph by designing the node-type-specific and relation-specific convolutional layers. The research on aggregation of heterogeneous graphs is well-developed, and hence we directly use a state-of-the-art (SOTA) heterogeneous GNN architecture (i.e., the heterogeneous graph transformer [11]) in our framework.\n2.2. EHR Representation Learning\nKnowledge distillation from massive EHRs has been a popular topic in healthcare informatics. To address the longitudinal features in the EHR data, several early works [20, 23, 22] learned the EHR features with recurrent neural networks. Since the EHR data represent relational information between the medical entities (e.g., patients make clinical visits), graph-based models are widely adopted for EHR analysis in recent works [3, 4, 21, 18]. Early works on graph-based EHR analysis model EHR data with a homogeneous graph. GRAM [3] is a well-known method that learns robust medical code representations by adopting a graph-based attention mechanism. To address the heterogeneity in the EHR entities, recently there are works [18, 21, 50, 46] attempting to model EHR data as a heterogeneous graph or a knowledge graph. They design heterogeneous GNNs to integrate the node and edge heterogeneity in graph representation learning. However, almost all the existing attempts are trained on each individual task separately, which does not incorporate the multi-task nature of the EHR data.\n2.3. Confounding Effect Adjustment\nThe challenge of addressing confounding effects in EHR data is amplified by its high degree of heterogeneity. Variations in patients' medical histories, comorbidities, and treatment plans contribute to these confounding effects. Consequently, there is a growing focus on learning feature representations in the counterfactual world, where confounding effects are excluded, within the healthcare research community.\nMany recent works [44, 25, 9, 48] take advantage of the advances in causal inference and aim to learn a representation of the data that captures the causal relationships between the variables. By doing so, they can separate the confounding factors from the causal factors and provide a more accurate representation of the underlying causal mechanism. CAL [31] learns the causal features by disentangling a set of random features. By excluding the shortcut/trivial features, it achieves promising predictive and interpretation enhancement to vanilla GNN architectures (e.g., GCN [35]).\n2.4. Multi-task Learning\nMulti-task learning aims to design a learning paradigm to obtain superior performance by training the tasks jointly rather than learning them independently [29]. Existing works on multi-task learning can be categorized into two major trends: hard parameter sharing [29, 5] and soft parameter sharing [43, 19, 38]. Soft parameter sharing takes all the trainable parameters task-specific but constrains them via Bayesian priors [38] or a joint dictionary [43, 19]. Hard parameter sharing takes a subset of parameters as shared while others remain as task-specific. We adopt hard parameter sharing in this paper and optimize the joint objective using an environment-invariant approach."}, {"title": "3. Preliminaries", "content": "Heterogeneous Graph. A heterogeneous graph is defined by a graph G = (V, E, A, R), where V, E, A represent the set of entities (vertices or nodes), relations (edges), and entity types respectively, and R represents the space of edge attributes. For v \u2208 V, v is mapped to an entity type by a function \u03c4(\u03bd) \u2208 A. An edge e = (h, r,t) \u2208 & links the head node h and the tail node t, and r\u2208 R. Every node v has a d-dimensional node feature x \u2208 X, where X is the embedding space of node features.\nProblem: Multi-task EHR Learning. Given the EHR data D, our goal is to construct a heterogeneous graph G from D. Let T1, ..., Tk on G be a series of K tasks on D. We aim to train a multi-task graph neural network model M such that M can deliver high performance on T1,..., TK."}, {"title": "4. Methodology", "content": "Our proposed framework starts with a heterogeneous graph construction stage. We learn the heterogeneous graph through a GNN that incorporates causal disentanglement for debiasing, which reduces the effects of confounding variables. We then improve cross-task performance by minimizing the task-level variance.  illustrates the workflow of our proposed method, and Algorithm 1 presents the training paradigm.\n4.1. Modeling EHR with Heterogeneous Graph\nHeterogeneous Graph Construction. We construct the heterogeneous graph by merging the tabular components in the EHR data. We define six node types: patients, visits, diagnoses, prescriptions, procedures, and lab events. We further define five types of connections between the nodes: patient-visit, visit\u2014diagnosis, visit-prescription, visit-procedure, visit-lab events.  presents the example of the heterogeneous graph constructed from EHR data. The heterogeneous graph data structure highlights the meta-relations between the medical entities, which provides an effective data structure for mining EHRs. Examples of the meta-relations modeled by the EHR heterogeneous graph are illustrated in . There are visits which are indirectly connected through a common medication (upper-left panel) or one visit leads to two diagnoses (lower-right panel), and there are patients who are indirectly connected with a treatment via a specific visit (upper-right panel) or a prescription with a diagnosis (lower-left panel). By leveraging the relational features introduced by these meta relations, we can obtain a better graph representation for EHRs and thus better performances on downstream tasks.\nSelf-supervised Embedding Pretraining Module. Node features are important for optimal GNN performance. Randomly initializing the embeddings would cause difficulties for GNN to distinguish the distributions of node embeddings, and thus might lead to trivial results. Moreover, the randomly initialized embeddings contain no information (including the most important relational features) on the nodes, which makes learning difficult. Hence, instead of randomly initialized node features, we pretrain the embeddings of EHRs with relational graph embedding methods, such that the relational features can be encoded into node features in this stage. Translational methods [1, 13, 17] are classic approaches to translating relational features into node embeddings. We adopt a simple unsupervised translation method TransE [1] to obtain the pretrained node embeddings,\n$f(h, r, t) = ||h + r - t||,$\nwhere h, t \u2208 Rd are the embeddings of the head and the tail of an edge, and r represents the embeddings corresponding to the relation type of the edge. We then adopt a contrastive learning-based score function to calculate the relational similarity between the nodes and backpropagate the loss to the node embeddings,\n$L_{sim} = \\Sigma \\Sigma [f(e) \u2013 f(e') + y]^+,$\nwhere y is the margin for contrastive learning, [x]+ = max(x, 0), and S' = {(h', r, t)|h' \u2208 V} \u222a {(h, r, t')|t' \u2208 V} is the set of negative samples by replacing either a head h or a tail t with another node in the graph. Through self-supervised learning, nodes sharing similar features would be pulled together and those whose features are different would be pushed away, leading to more distinguishable node features. Since most medical entities (e.g., diagnosis) are static, pretraining the node embeddings would also lead to improved inductive inference performance when new nodes (e.g., visits or patients) arrive."}, {"title": "Learning with Heterogeneous GNN", "content": "We perform node-level aggregation by adopting graph convolutional methods, which aggregate node features by passing the information of each node to its neighboring nodes (i.e., message-passing neural networks). However, homogeneous GNNs ignore the potential differences in node types and edge types when performing graph convolution. To leverage the heterogeneity in the EHR graph, we adopt heterogeneous GNN architectures, where the graph convolution procedures through the layers, in general, can be formulated as\n$\\hat{y} = softmax(\\Sigma^{L}_{l=1}act(Agg(G_l)))$,\nwhere Agg is the aggregation rule, either convolution-based (e.g., GCN [35]) or attention-based (e.g., GAT [33, 34]), Gi is the output subgraph from layer l, act and softmax are the activation function and softmax normalizing module, respectively, and \u0177 is the classification probabilities output by the GNN. In particular, we adopt the heterogeneous graph transformer (HGT) [11] as it yields state-of-the-art performance in predictive tasks on heterogeneous graphs. Detailed formulation of the aggregation rule of HGT is described by Hu et al. [11]. Latent representations of nodes are obtained after the aggregation. We then use a readout layer (e.g., multiple-layer perceptron) to obtain the prediction for each task. We study the effects of different GNN architectures in Section 6.3."}, {"title": "4.2. Adjusting for Confounders with Causal Inference", "content": "The EHR graph is known to be noisy and suffers from confounding effects. The trivial effects are presented as noise or shortcut features that mislead the learning process of GNNs.  presents an illustration of the causal diagram. The variable nodes S represent the trivial features in the data, which impose noise (or confounding effects) to target prediction. The path A \u2192 S \u2192 Y is called the shortcut path or the backdoor path that the model would take during the forward propagation. If there are too many shortcut paths in the graph learning process, the GNN model would be heavily affected by the shortcut (or trivial) features and this affects the learning knowledge representation in the graph. For example, patients with presumed (but unconfirmed) interstitial lung disease may be biased toward specific or optimized imaging protocols that are intended to confirm the diagnosis, versus unsuspected cases that receive generic screening protocols [27]. Here, the lung disease is the predictive variable Y, R is the latent features which are used by the GNN to predict Y, and S the imaging protocol is the shortcut variable. Hence, removing the shortcuts (or backdoor paths) is critical for noise-free representation learning with GNNs.\nMotivated by Sui et al. [31], we introduce a causal denoising module into our framework adjusting for the confounders in the EHR data. We first disentangle the features in G into two components the causal features and the trivial features. Sui et al. [31] proved that the causal features are invariant across training and testing distributions. The objective of the trivial features is to match a uniform distribution to ensure the randomness of the trivial graph G\u2081 [31],\n$L_{unif} = \\frac{1}{P} \\Sigma_{G \\in D} JS(y_{unif}, Z_G),$\nwhere JS is the Jensen-Shannon divergence [6] between two distributions, zG, is the trivial representation predictive with the node features from trivial graph G\u2081, and yunif is the noise feature vector where each element is sampled from U(0, 1).\nLearning from causal features can adjust the GNN architecture to confounding (i.e., backdoor) effects, especially when learning the EHR data with significant noise. Sui et al. [31] showed how learning through Eq. (4) can adjust for backdoor effects. The causal features potentially follow the counterfactual distributions which enable generalization invariability. Hence, the GNN model can be better generalized to the testing distributions or other tasks\nThe loss functions used to train the GNN model for a single task are\n$L_{bce} = -\\Sigma^{P}_{i=1} [y_i log((i)) + (1 - y_i) log(1 \u2013 (zi))],$\n$L_{ce} = \\frac{1}{P} \\Sigma^{P}_{i=1} \\Sigma^{C}_{c=1} y_{i,c} log(softmax(z_{i,c})),$\nwhere Lbce is the binary cross-entropy loss, Lce is the cross-entropy loss, y; is the ground truth label for patient i, P is the number of patients, C is the number of classes, and zi and zi,c are logits obtained from the model. The final loss for task k is then given by\n$L_k = L(y, \\hat{y}) + \\lambda L_{unif},$\nwhere L(y, \u0177) = Lce for binary classification tasks, and L(y, \u0177) = Lbce for multi-label classification tasks, Lunif is computed by Eq. (4), and \u03bb is the regularization coefficient."}, {"title": "4.3. Multi-task Learning via Environment-Invariant Objective", "content": "We obtain the task-specific loss Lk for each task k in the previous step. We aggregate the losses from all tasks to train the single shared-weight GNN for multi-task learning. We propose a task-invariant objective similar to [36] to minimize the extrapolation risks in both training and testing environments. In addition to the mean of the loss in each task, we also minimize the variance of all the K losses to control the extrapolation risk,\n$Var({L_k: 1\u2264 k \u2264 K)}) + \\beta (\\Sigma^{K}_{k=1} L_k),$\nwhere Var() returns the variance of the set, \u03b2 is the task-level regularization hyperparameter. The rationale on why controlling the inter-task variance can minimize the interpolation risk is provided by Wu et al. [36].\nEach task can be considered as an environment that specifies a distribution of embeddings. If the predictions for different tasks are very different, then the model may be overfitting to the current task and not learning generalizable representations. To address this issue, the invariance objective is used in multi-task learning to encourage the model to learn task-invariant representations that are consistent across different tasks. One way to achieve this goal is by minimizing the cross-task variance regularization term, which penalizes the model for producing very different predictions for different tasks. By minimizing this term, the model is encouraged to learn representations that are both task-specific and invariant across tasks, leading to better generalization performance."}, {"title": "5. Experiments", "content": "5.1. Settings\nDatasets. We use the MIMIC-III and MIMIC-IV datasets to evaluate our method in comparison with the competitors. Because the lab events are sparse and introduce heavy noise to the heterogeneous graph, we exclude them when constructing the graph.  presents a summary of the types and counts of the entities in the MIMIC-III and MIMIC-IV datasets, and the details of each task.\nTasks and Evaluation Metrics. We evaluate our proposed method with common tasks on EHR data. Our model is trained by four supervised tasks - in-hospital mortality prediction (MORT), readmission prediction (READM), length of stay (LoS) prediction, and drug recommendation (DR). The trained multi-task model is then evaluated on each individual task using the testing data from each task. We treat mortality prediction and readmission prediction as binary classification tasks, LoS as the multi-class classification task (with 10 classes), and drug recommendation as multi-label classification tasks (with 351 labels for MIMIC-III and 501 labels for MIMIC-IV). We report the areas under the receiver operating curve (AUROC) and precision-recall curve (AUPR), accuracy, F1-scores, and Jaccard index for the tasks when appropriate. We perform five-fold cross-validation for each experiment. Detailed definitions of the evaluation metrics are provided in the appendix.\n5.2. Implementation Details\nThe proposed framework is implemented in Python with the Pytorch library on a server equipped with four NVIDIA TESLA V100 GPUs. We use the dgl library to perform graph-related operations, and pyhealth [49] to benchmark SOTA methods and perform EHR-related operations. The dropout ratio of each dropout layer is set as 0.2. All models are trained with 1000 epochs with early stopping. We choose the model at the epoch where it yields the best performance in terms of AUROC. We adopt the cross-entropy loss to train the network for classification tasks, and MSE for regression tasks. We use the Adam optimizer to optimize the model with a learning rate of 5\u00d710-5 and a weight decay of 1\u00d710\u22125. We perform data augmentations on the training graphs by randomly dropping the edges and nodes, and adding Gaussian noises to the node and edge features.\nTemperature Annealing. We are aware of the vanishing classification loss in practice. Therefore, we alleviate this issue by annealing the temperature over the training epochs with the schedule \u03c4 = max(0.05, exp(rp)), where p is the training epoch and r = 0.01.\nSubgraph Sampling. Since it is not always possible to pass the whole EHR graph into the memory (especially for MIMIC-IV), we compose subgraphs by sampling nvisit visits nodes and their connected nodes at each epoch. We set nvisit = 2000 as this parameter is fine-grained with empirical experience to which the performance is less sensitive.\nDownsampling for MORT Task. We are aware that the samples in the mortality prediction task are heavily imbalanced (i.e., most of the samples are alive). We therefore perform downsampling during the training to balance the samples."}, {"title": "5.3. Comparable Methods", "content": "We compare our method to the following competitors: GRU [24], Transformer [32], GRAM [3], StageNet [8], AdaCare [22], Concare [23], GRASP [46], Deepr [26], and GraphCare [14]. For the drug recommendation task, we further include the following competitors which are distinctively designed to tackle this task: MICRON [39], Safedrug [40] and MoleRec [41]. Detailed description of each baseline method can be found in the appendix."}, {"title": "5.4. Quantitative Results", "content": "present the results of different tasks on the MIMIC-III and MIMIC-IV datasets. We observe that our proposed framework outperforms the competitive methods on all tasks, which validates its predictive performance. Our method adopts one model for all benchmark tasks, which does not require training a GNN for each individual task. Remarkably, despite using a single-shared weight model, our approach consistently outperforms single-task methods across all individual tasks. We also observe that for the drug recommendation task, our method not only outperforms the SOTA methods for EHR prediction but also recent methods [39, 41, 40] specifically tackling the drug recommendation tasks. This compelling evidence suggests that through multi-task learning, we exert the potential to surpass the limitations of single-task models by leveraging knowledge from other downstream tasks. Our model can even consistently outperform the large language model-based methods (e.g., GraphCare [14]) in the downstream tasks, where these methods borrow excessive knowledge from the open-world knowledge base."}, {"title": "5.5. Qualitative Evaluation", "content": "Embedding Visualization. We visualize the node embeddings of each type of entity to evaluate the performance of feature representation learning.  presents the T-SNE (t-distributed stochastic neighbor embedding) plots of the embeddings generated by different methods. In general, the embeddings are clustered according to their node types, which validates that the embeddings can learn the unique representation of each node type. We also compare the embeddings across different methods. We observe that all the methods can capture the patterns of medical entities. However, the pattern captured by MulT-EHR is more unique and complex than other methods. This shows that our method is more capable of capturing the unique pattern presented in the EHR data.\nWe also compare the embeddings from different GNN architectures. We observe that the embeddings generated by heterogeneous GNNs have more unique patterns than those generated by homogeneous GNNs. This also validates that modeling EHRs by heterogeneous graphs can potentially learn the more complex relationships and patterns in the EHR data. Visualizations of embeddings generated by other GNN architectures can be found in the appendix.\nPrediction Interpretations. We perform a case study on a specific visit of a patient to evaluate the decision process on readmission prediction. For the selected visit node, we select the top 3 diagnosis edges that have the highest edge attention scores.  presents the visit and the selected diagnoses associated with their readmission prediction (together with the ICD9 codes and description of the diagnoses). We observe that our model can select diagnoses related to brain functionality and cancer according to their attention scores, which provides evidence that the model can effectively capture the semantic information in EHRs when making read-"}, {"title": "6. Ablation Analysis", "content": "6.1. Ablation Study on Different Components\nTo validate the contributions of each component of our model, we deactivate the causal debiasing and/or multi-task learning modules to examine their effects on the results.  presents the results on the readmission task. We observe that including either the causal denoising module or the multi-task aggregation module leads to improvement in performance, while including both modules results in the best performance. This validates both modules proposed in our framework improve the learning performance.\n6.2. Effects of Different Numbers of Tasks\nWe show that as more tasks are incorporated into our multi-task learning method, the predictive task performance can be improved due to cross-task knowledge sharing. We experiment with one to four tasks, and  presents the results. We observe that as the number of tasks in the training increases, the performance on readmission prediction improves accordingly. This validates that our multi-task learning framework can leverage more inter-task knowledge as more tasks are included in the training stage."}, {"title": "6.3. Effects of Different GNN Architetures", "content": "We compare different graph convolutional methods to show how ablations in aggregation methods affect our framework.  presents the results of the MIMIC-III hospital readmission task. We observe that our method is overall robust when the GNN architecture changes. However, using a homogeneous GNN architecture (e.g., GCN) would hamper the predictive performance since they only consider direct connections in the graph by neighbour averaging. Hence, they cannot leverage the structural information in the EHR data, which leads to less satisfactory performance."}, {"title": "6.4. Hyperparameter Tuning", "content": "Tuning Parameters for Objectives. We evaluate the effect of the regularization parameter \u03bb of different task losses.  presents the change in performance as \u03bb increases. We observe that the performance is in general robust to \u03bb, where a slightly decreased performance is observed when \u03bb is too large. Since \u03bb represents the regularization of learning, larger \u03bb imposes a heavier penalty on the shortcut features and thus more restrictions on the feature space. The predictive performance would be sacrificed as a result due to the more tightly constrained feature space\nNumber of GNN Layers. We evaluate the performance of our framework with respect to the change in the number of GNN layers, as shown in . We observe that for both datasets, as long as the GNN is not too shallow (i.e., depth > 1), it can achieve satisfactory performance. On the other hand, the performance is slightly compromised due to the well-known over-smoothing problem in deeper GNNs.\nHidden Embedding Dimension.  presents the comparison of different dimensions of hidden features. We observe that the performance generally improves when a larger number of feature dimensions is adopted. The number of feature dimensions controls the width of the neural network. Hence, this verifies that increasing the width instead of depth can improve the feature representation learning performance while more effectively preventing the over-smoothing issue [30, 47]."}, {"title": "7. Discussion and Conclusion", "content": "To address the significant confounding effects present in EHR data, we propose a denoising module based on causal inference. This module effectively adjusts for the confounding effects and yields causal features by eliminating most of the backdoor paths associated with trivial features. Not only do these causal features enhance predictive performance, but they also offer potential for causal explanations. While in this work we interpret the model using attention weights on causal features from the GNN model, this does not necessarily provide a causal explanation. Developing algorithms for causal explanations would require rigorous theoretical work to ensure causality, which falls outside of the focus of this paper. However, based on the causal features obtained for each entity, there is a promising potential to develop a robust causal interpretation model that can identify the causes of medical events such as mortality, diseases, or readmission. This has significant implications for medical reasoning and future clinical research.\nEHRs present a great degree of heterogeneity each medical entity in the EHR has a distinct node type. Each node type thus introduces a unique distribution of the medical entities of that type. By using a heterogeneous graph, we can model EHRs with the awareness of different types of medical entities and relations. Consequently, an effective heterogeneous GNN is employed to align the embedding distributions of nodes from different node types into a unified latent space. The transformer architecture, known for its ability to align embedding distributions across different spaces, demonstrates superior empirical performance compared to other GNN designs (as shown in Table 8). Additionally, not only do EHRs include enriched medical records in the tabular form, but they also encompass information from various modalities, such as clinical/discharge reports in text and radiology scans in images. To incorporate this multimodal information, we merge these observations into the heterogeneous graph as individual nodes, assigning different node types based on their modalities. By leveraging transformer-based heterogeneous GNN architectures [11], we can align the distributions from different modalities, potentially leading to significant performance improvements on EHR analysis tasks.\nTo Conclude. We propose a novel multi-task learning framework for EHR modeling, named MulT-EHR, which mines the heterogeneity in EHR data while adjusting for confounding effects. Our proposed framework employs a GNN architecture that incorporates causal disentanglement for debiasing and minimizes the task-level variance to improve cross-task performance. Empirical studies on various datasets validate the superiority of our proposed method over existing single-task and multi-task designs. Qualitative analysis on node embeddings and interpretability suggests that our method can potentially provide interpretations to key medical entities (e.g., diagnosis) leading to the event (e.g., readmission). Enriched ablation studies verify the robustness of our method to variations on the proposed components and hyperparameters. Our framework can potentially be generalized to any other application domains based on graph representation learning, such as recommendation systems and molecular chemistry."}]}