{"title": "Multimodal large language model for wheat breeding: a new exploration of smart breeding", "authors": ["Guofeng Yang", "Yu Li", "Yong He", "Zhenjiang Zhou", "Lingzhen Ye", "Hui Fang", "Yiqi Luo", "Xuping Feng"], "abstract": "UAV remote sensing technology has become a key technology in crop breeding, which can achieve high-throughput and non-destructive collection of crop phenotyping data. However, the multidisciplinary nature of breeding has brought technical barriers and efficiency challenges to knowledge mining. Therefore, it is important to develop a smart breeding goal tool to mine cross-domain multimodal data. Based on different pre-trained open-source multimodal large language models (MLLMs) (e.g., Qwen-VL, InternVL, Deepseek-VL), this study used supervised fine-tuning (SFT), retrieval-augmented generation (RAG), and reinforcement learning from human feedback (RLHF) technologies to inject cross-domain knowledge into MLLMs, thereby constructing multiple multimodal large language models for wheat breeding (WBLMs). The above WBLMs were evaluated using the newly created evaluation benchmark in this study. The results showed that the WBLM constructed using SFT, RAG and RLHF technologies and InternVL2-8B has leading performance. Then, subsequent experiments were conducted using the WBLM. Ablation experiments indicated that the combination of SFT, RAG, and RLHF technologies can improve the overall generation performance, enhance the generated quality, balance the timeliness and adaptability of the generated answer, and reduce hallucinations and biases. The WBLM performed best in wheat yield prediction using cross-domain data (remote sensing, phenotyping, weather, germplasm) simultaneously, with R\u00b2 and RMSE of 0.821 and 489.254 kg/ha, respectively. Furthermore, the WBLM can generate professional decision support answers for phenotyping estimation, environmental stress assessment, target germplasm screening, cultivation technique recommendation, and seed price query tasks. This study aims to provide intelligent and integrated solutions for wheat breeding goals, to help breeding work be carried out efficiently, to accelerate the breeding process of excellent varieties, and to provide scientific basis and technical support for achieving sustainable agricultural development and ensuring food security.", "sections": [{"title": "1. Introduction", "content": "As one of the basic food crops for mankind, wheat breeding is facing unprecedented challenges and opportunities due to the global food crisis and the promotion of sustainable agricultural development (Cheng et al., 2024; Senapati et al., 2022). Although traditional breeding methods have achieved remarkable results, their efficiency and accuracy have gradually revealed their limitations in the face of complex and changing climatic conditions, increasingly serious threats from pests and diseases, and constantly upgrading consumer demands (Hu et al., 2022; Xiong et al., 2021). Due to the diversity of wheat varieties, breeding information has long lacked a unified tool, and data knowledge has shown an \"isolated\" distribution, which has created barriers to the learning of wheat breeding knowledge (Bhat et al., 2023). Simultaneously, since wheat breeding involves the intersection of multiple disciplines such as biology, genetics, weather, and soil science, professionals have to cross literature and data from many fields when engaged in breeding work, and even need to write code to access data, which greatly limits their work efficiency (Kaur et al., 2021). Smart breeding, as an innovative mode that integrates modern information technology, biotechnology, and agricultural science, is gradually becoming a key path to solving this problem (H. Li et al., 2024; Xu et al., 2022).\nWith the rapid development of unmanned aerial vehicle (UAV) technology, its application in the agricultural field has become more and more extensive, especially UAVs have shown great potential in intelligent breeding (Das et al., 2021; Fei et al., 2023; Jiang et al., 2021). With its advantages of high efficiency, precision and flexibility, it is becoming an indispensable tool in smart breeding and can provide important monitoring data for smart breeding. Image recognition technology can accurately extract wheat growth indicators from RS images, such as chlorophyll content (Feng et al., 2023; Zhang et al., 2024) and leaf area index (Chen et al., 2022; Du et al., 2023); text analysis technology can extract valuable germplasm descriptions (L. Liu et al., 2024; Sansaloni et al., 2020), breeding optimization strategies (J. Xu et al., 2023; Yao et al., 2022) and market trends (Garg et al., 2022; Padhy et al., 2024) from research manuscripts, reports and databases. The complementarity of image and text information not only enhances the credibility and interpretability of the data, but also promotes the integration of interdisciplinary knowledge, opening up new avenues for wheat breeding research. At present, there is an urgent need to integrate cross-domain data (RS data, phenotyping data, environment data, germplasm data, cultivation data, and price data), use artificial intelligence algorithms and big data technology to build a cross-scale and cross-domain comprehensive analysis tool for wheat breeding, accelerate the screening and optimization of wheat target varieties, and improve the efficiency and accuracy of wheat breeding.\nIn recent years, the large language model (LLM) has attracted much attention due to their powerful text generation and understanding capabilities (X. Huang et al., 2024; Lin et al., 2024). After fine-tuning, the LLM has shown strong interactive capabilities and the potential to improve productivity (Min et al., 2024). However, since the LLM can only process plain text and cannot process images, voice, and video, their application scope is limited (Wang et al., 2023). In the context of cross-domain, multi-modal data fusion applications, several multimodal large language models (MLLM) have been developed to enhance the ability of LLM to perceive and understand visual signals (AI et al., 2024, p. 0; Bai et al., 2023; Z. Chen et al., 2024; DeepSeek-AI et al., 2024; GLM et al., 2024; F. Li et al., 2024). Although a lot of study has been done to explore the limitations and effectiveness of MLLM, the current open-source general MLLM still has the problem of insufficient accuracy in professional applications (D. Huang et al., 2024; C. Li et al., 2024), such as wheat breeding selection. When faced with wheat breeding query, general MLLM often evades the question or gives irrelevant answers due to lack of breeding knowledge. This hinders the further exploration and application of MLLM in the field of wheat breeding.\nHowever, the research and application of MLLM in crop breeding is still in its early stages and faces many challenges and opportunities (Zhu et al., 2024). The MLLM needs to integrate more complex data from different sources, including but not limited to RS data, phenotyping data, and environment data during the crop growth period. Data from these sources vary significantly in format, dimensionality, and sparsity. How to efficiently and accurately integrate these cross-domain heterogeneous data is a difficulty in current research (Kuska et al., 2024). MLLM needs to have strong learning and generalization capabilities to adapt to the needs of smart breeding and predict the performance of crops under different environmental conditions, which places extremely high demands on the model's algorithm design and computing resources. Additionally, professional knowledge and experience in the field of crop breeding are crucial for the development and application of the model (J. Li et al., 2024). How to integrate professional knowledge into model design to make the model more in line with actual breeding needs, while discovering new breeding strategies and optimization solutions through the model, is another issue that needs in-depth exploration. MLLM is expected to reveal the deep mechanisms of crop trait formation by integrating cross-modal information and accelerate the screening and breeding process of new varieties.\nThis study aims to innovatively construct a MLLM for wheat breeding (WBLM) through cross-domain data fusion and cutting-edge technology application, and explore"}, {"title": "2. Study area and data", "content": "The experiment was conducted for two years (2021-2022 and 2022-2023), with 305 and 351 varieties, respectively. The varieties in the second year included the varieties in the first year and 46 varieties were added (Table S1). The experimental sites were set up in Changxing and Yuhang Agricultural Experimental Bases of Zhejiang University Agricultural Experiment Station in Zhejiang Province, China (Fig.1a, Table S2). Specific planting information is shown in Table S3. The experimental fields were not sprayed with pesticides and herbicides, and weeds were not controlled manually or mechanically. Maintaining the natural growth environment is to develop competitive wheat varieties that have a greater competitive advantage than wheat weeds. The water required for wheat growth comes from natural rainfall. Both places have a subtropical monsoon climate."}, {"title": "2.2. Data acquisition", "content": "For the experimental field, we used multiple sensors and multiple UAVs to acquire hyperspectral (HS), lidar, multispectral (MS), and RGB (red, green, blue) data on the same day and compiled them into a RS dataset (Fig. 1b). The Matrice 300 RTK (DJI, China) was selected as the flight platform to carry the Zenmuse L1 (DJI, China) lidar camera and the FireflEYE S185 (Cubert, Germany) hyperspectral camera to obtain lidar data and HS data respectively. FireflEYE S185 covers the visible and near-infrared bands from 450 to 950 nm, has 125 spectral channels, and can achieve synchronous frame imaging, spectral resolution: 8 nm 532 nm, spectral sampling interval 4 nm. Zenmuse L1 has a range of 190m @ 10%, 100 klx, point cloud data rate multi-echo: maximum 480,000 points/second, elevation accuracy: 5cm @ 50m, plane accuracy: 10cm @ 50m. The Phantom 4 multispectral (DJI, China) and the Mavic 3E (DJI, China) were used to obtain MS data and RGB image respectively. The MS includes five bands, blue: 450 nm \u00b1 16 nm; green: 560 nm \u00b1 16 nm; red: 650 nm \u00b1 16 nm; red edge: 730 nm \u00b1 16 nm; near infrared: 840 nm \u00b1 26 nm. The Mavic 3E is equipped with a wide-angle camera 4/3 CMOS, with 20 million effective pixels and a maximum photo size of 5280\u00d73956. The telephoto camera has an equivalent focal length of 162 mm, 12 million pixels, and 56x hybrid zoom."}, {"title": "2.2.2. Phenotypic data", "content": "Phenotypic data collection involves chlorophyll content, leaf area index (LAI), canopy height (CH) and yield (Fig. 1b). Field phenotyping data of wheat were collected six times during 2021-2022 (on January 19, March 8, April 2, April 15, April 29, and May 18, 2022) and nine times during 2022-2023 (on December 27, 2022; February 16, March 4, March 19, April 7, April 22, May 1, May 13, May 19, 2023). UAV RS and phenotyping data were collected on the same day.\nThe chlorophyll content of the wheat canopy was measured using a SPAD-502 PLUS chlorophyll meter (Konica Minolta, Japan). Five wheat plants with representative growth in each wheat planting plot of the field experiment were randomly selected. For each wheat plant, three leaves without pests and diseases, physiological spots, and mechanical damage were selected, and the tip, middle, and base of each leaf were measured. All the measured values were averaged as the SPAD value of the canopy leaves of the wheat germplasm in the plot. The LAI of the wheat canopy in each plot was measured using a LAI-2000C plant canopy analyzer (LI-COR, USA). Five sampling points with uniform growth were selected at the four corners and the center of each plot, and the LAI values were measured and recorded using a LAI-2200C according to the standard method. Each sampling point was measured three times and the average value was taken as the LAI of the sampling point. We recorded"}, {"title": "2.2.3. Environmental data", "content": "The weather data continuously recorded by meteorological equipment at each agricultural experimental base and the meteorological observation station of the China Meteorological Administration were used to provide us with weather data for two-year growing season (Fig. 1b). The data mainly include daily average temperature, dew point temperature, precipitation, net solar radiation intensity, wind speed and other data. The average annual temperature is 15.6 \u00b0C, the average relative humidity is 76%, the annual rainfall is 1309 mm, and the average of 1810 hours of sunlight per year at Changxing Agricultural Experiment Station. The average annual temperature is 16.2 \u00b0C, the average relative humidity is 68%, the annual rainfall is 1400 mm, and the average of 1970 hours of sunlight per year at Yuhang Agricultural Experiment Station.\nThe test soil was collected before sowing at different locations (0-20 cm) in the experimental field. The collected soil was placed in turnover boxes and then sent for testing in time to determine the physical and chemical properties of the soil. Soil pH = 6.2, total N = 1.32 g kg-\u00b9, available potassium = 94.9 mg kg\u00af\u00b9, available phosphorus = 1.9 mg kg\u00af\u00b9 and soil organic C = 12.4 g kg\u00af\u00b9 at Changxing Agricultural Experiment Station. Soil pH = 6.14, total N = 1.68 g kg\u00af\u00b9, available potassium = 187 mg kg\u00af\u00b9, available phosphorus = 63.6 mg kg\u00af\u00b9 and soil organic C = 16 g kg\u00af\u00b9 at Yuhang Agricultural Experiment Station."}, {"title": "2.3. Data processing", "content": null}, {"title": "2.3.1. Data preprocessing", "content": "The acquired UAV data were preprocessed to generate digital orthophoto map (DOM) for subsequent processing according to each plot. Hyperspectral data were converted into reflectance images after radiometric correction using the supporting Cubert Utils Touch software (Cubert, Germany) and radiometric correction plates. Then, Agisoft Metashape (Agisoft, Russia) was used to align photos, create dense point clouds, generate grids, and generate textures to get DOM for subsequent processing. The MS data was imported into Pix4Dmapper (Pix4D, Switzerland) software for initialization processing, point cloud and texture, DSM and DOM generation operations. The irradiance value captured by the light intensity sensor during flight was used to compensate the MS bands for illumination, eliminating the interference of ambient light on data collection. The bands are then radiometrically calibrated using the radiometric calibration plate image acquired simultaneously during data collection. Furthermore, the radiometrically calibrated images were stitched to generate DOM. Finally, the DOM was normalized to obtain reflectance images for subsequent generation of vegetation indexes (VI). The lidar data were processed using DJI Terra (DJI, China) to generate three-dimensional point clouds. The RGB images were imported into Pix4Dmapper to stitch RGB DOM. In addition, one frame of the video obtained by manual flight is extracted every five seconds as an image for storage. These images were divided according to different germplasms (different plots). Then, the wheat heads (WH) in the images were manually annotated to produce a WH dataset."}, {"title": "2.3.2. Spectral data processing", "content": "The processed MS and HS bands were used for VIs calculation to analyze the canopy spectral features of different plots. VIs commonly used for phenotyping estimation and grain yield prediction were selected, including NDVI, SAVI, kNDVI, NIRv and PSRI (Table 1).\nThe fractional vegetation cover (FVC) of the plots, i.e., the percentage of the vegetation area to the plot area (Yang et al., 2022), was calculated as a valuable indicator of crop density and structural information. The vegetation area of the plot was extracted from the MS image by excluding the background soil using a Transformer-based segmentation algorithm, similar to related study (Cui et al., 2023). The number of vegetation pixels in each plot was then divided by the total number of pixels in that plot to calculate FVC (Maimaitijiang et al., 2020)."}, {"title": "2.3.3. Lidar data processing", "content": "The CH was extracted from LiDAR point clouds and used as canopy structure features. The bare ground digital elevation model (DEM) was created using point cloud data acquired before the emergence of seedlings in the field. Then, the digital surface model (DSM) representing all objects (vegetation) on the ground was constructed based on the point cloud data acquired at different times. Thus, the CH is obtained by pixel-level subtraction of the generated DSM and DEM (Maimaitijiang et al., 2020). Finally, the obtained lidar data were used to extract CH in different plots in the wheat field.\nIn addition, the measurement tool of Terra software (DJI, China) was used to mark the reference surface for canopy volume (CV) measurement of each plot based on the lidar point cloud and the boundaries of different plots. The sum of the excavated volume and the filled volume above and below the reference surface is taken as the spatial volume of the reference surface. It should be noted that since there are two types of reference planes, the lowest point (the plane on which it is located) and the average plane, the average value of the volumes obtained from the lowest point and the average plane is taken as the spatial volume of the plot (Table 1)."}, {"title": "2.3.4. RGB image processing", "content": "To obtain the lodging level of different plots in the wheat field, we refer to a study to construct a wheat lodging area segmentation model (Zhang et al., 2023). Then we use the ratio of the lodging area extracted from the plot to the plot area to determine the plant lodging (PL) level of the plot. In our experiment, the lodging levels were divided into: no lodging (0), slight lodging (0-50%), severe lodging (50-100%), and special (no crop or only a few plants) (Saskatchewan Seed Growers' Association, 2024).\nWe implemented the detection and counting of WH in the field based on the two-stage method FR-Transformer proposed in our previous study (Zhu et al., 2022) and RGB images. Then, we used this method to obtain the number of WH in the preprocessed WH images of each plot, and averaged the number of WH in each plot. Finally, the ground coverage area of the WH image was calculated using the UAV flight altitude and camera field of view (Avola et al., 2021), and the number of WH per unit area of the plot was further calculated.\nDue to the lack of herbicide spraying and manual weeding, weeds in wheat fields grow randomly and in large numbers. To study the environmental (weed) stress of wheat growth, we focused on the severity of weeds in each plot and the area 10 to 20 cm wide outside the plot in the wheat field. We referred to a study (Anderegg et al., 2023) to extract the number of pixels in the plot and specific area and the number of weed pixels in them, and then used the ratio of the number of weed pixels to the number of pixels in the plot and specific area to classify each plot according to the weed level (WL). The weed level can be roughly divided into: no weeds (0-10%), slight weeds (10-40%), moderate weeds (40-70%), and severe weeds (70-100%)."}, {"title": "2.4. Construction of Cross-domain knowledge base", "content": "The cross-domain knowledge base (in Chinese and English) consists of multi-source datasets in the field (Fig. 2a) and external domain knowledge base (Fig. 2b). The multi-source datasets in the field include UAV RS data, phenotyping data, weather data. The external domain knowledge base includes:\n(1) wheat germplasm data (22k), mainly including variety name, place of origin, nutritional quality, resistance and agricultural traits. In terms of nutritional quality, key parameters such as crude protein, lysine, and sedimentation value are involved. In terms of resistance, it covers important characteristics such as disease resistance (stripe rust, leaf rust, powdery mildew, etc.), drought resistance, and cold resistance. In addition, agronomic traits such as maturity, plant height, thousand grain weight, and grain hardness are also recorded.\n(2) wheat cultivation technique data (10k), covers the entire process from pre-planting preparation to post-harvest storage, mainly including the selection of suitable varieties, soil preparation, sowing, fertilizer management, irrigation and pest and disease control techniques.\n(3) wheat plant protection technique data (10k), mainly including disease prevention and control, pest prevention and control, weed management, as well as new techniques such as precision plant protection based on artificial intelligence and RS, agricultural UAV flight control and green prevention and control.\n(4) wheat seed price data (20k), mainly including observation point, variety name, price, specification, planting area and time, etc. For observation points, the economic level and planting demand of different regions lead to price differences; for varieties, different varieties have different characteristics and application scenarios, and high-quality varieties are usually more expensive; different specifications of packaging and planting areas affect the final selling price; prices change over time due to changes in market supply and demand, especially natural disasters or policy adjustments.\nThe wheat germplasm data comes from the Chinese Crop Germplasm Information Network (https://www.cgris.net/). The data on wheat cultivation technique and wheat plant protection technique come from search engines (Google, Bing, Baidu), and the search terms include \"wheat cultivation technique, wheat plant protection technique, \u5c0f\u9ea6\u683d\u57f9\u6280\u672f,\u5c0f\u9ea6\u690d\u4fdd\u6280\u672f\". The wheat seed price data comes from the National Seed Market Monitoring Information Release Platform (http://202.127.45.18/). All data from this study have been made publicly available (https://doi.org/10.5281/zenodo.13736773)."}, {"title": "3. Methods", "content": null}, {"title": "3.1. Construction of WBLM", "content": "We construct a WBLM with domain knowledge using the supervised fine-tuning (SFT), retrieval augmented generation (RAG) and reinforcement learning from human feedback (RLHF) technologies based on different MLLMs and cross-domain knowledge base. WBLM consists of two parts. The part 1 builds a RAG system based on the LlamaIndex large model application framework (https://www.llamaindex.ai/) and the Milvus vector database (https://milvus.io/) (Fig. 2c, yellow line). The part 2 uses STF and RLHF methods to obtain a WBLM that follows breeding preferences (Fig. 2c, red line). We regard the input of part 1 as a query (Fig. 2d), and the original query and the output of part 1 as a new query. The part 2 receives the new query, processes it, and then outputs the result to the Q/A system (Fig. 2e).\nTo make WBLM better adapt to breeding tasks, we use RAG technology to conveniently and efficiently supplement the knowledge not covered by STF and RLHF methods. First, we convert the data of the files in the external domain knowledge base, use BGE-M3 to generate embedding vectors (J. Chen et al., 2024), and then import the data into the Milvus vector database. Then, LlamaIndex receives user input and initiates a retrieval request to the Milvus database based on the input, using a hybrid retrieval (BGE-M3) and re-ranking (BGE-Reranker-V2-M3) pipeline. LlamaIndex merges the retrieval results with the input to form a new prompt. After that, LlamaIndex inputs the new prompt to InternLM2.5-7B-Chat to achieve reasoning and answer generation based on the retrieved knowledge (Cai et al., 2024).\nThe training process using the STF and RLHF methods is divided into three stages. In the first stage, we collect demonstration data and train a supervised policy. Based on the cross-domain knowledge base, we artificially construct a question-answering dataset that we hope the model generates aligned answers to SFT the pre-trained MLLM. For questions we want the model to answer well, we collect the answers we want the model to output to increase the probability of the model generating the expected answers. We choose currently popular and competitive open-source MLLMs for model construction and fine-tuning, including Qwen-VL (Qwen-VL-Chat), InternVL (InternVL2-8B and InternVL2-2B), Yi-VL (Yi-VL-6B), Deepseek-VL (DeepSeek-VL-7B-chat and DeepSeek-VL-1.3B-chat) and GLM-4 (GLM-4V-9B), all of which support English and Chinese. It cannot be denied that we mainly provide a method to build an MLLM suitable for wheat breeding, rather than having to choose a specific open-source MLLM, as models with better performance are constantly emerging. We used Scalable lightWeight Infrastructure for Fine-Tuning (SWIFT) to fine-tune the MLLM (The"}, {"title": "3.2. WBLM evaluation benchmark", "content": "In order to comprehensively evaluate the performance of MLLM in scientific breeding work, it is necessary to build a standardized machine and human evaluation benchmark. This benchmark aims to integrate challenges from various wheat breeding tasks. This benchmark aims to integrate challenges from various wheat breeding tasks. We have specifically designed many professional Chinese and English questions on wheat breeding and corresponding standard answers, covering five tasks: phenotyping estimation, environmental stress assessment, target germplasm screening, cultivation technique recommendation, and seed price query. The phenotyping estimation includes seven subtasks (Yield, SPAD, LAI, CH, CV, WH and PL), the environmental stress assessment includes two subtasks (WL and FVC), the target germplasm screening includes five subtasks: high quality (HQ), disease resistance (DS), drought resistance (DR), maturity period (MP), adapt to mechanized (AM), the cultivation technique recommendation includes two subtasks: cultivation technique (CT) and plant protection technique (PPT), and the seed price query includes one subtask seed price (SP) query. Through objective evaluation indicators and manual scoring and sorting, the evaluation team conducted a detailed evaluation of the answers of multiple MLLMs including WBLM, covering three aspects: accuracy, stability, and reasoning.\nWe evaluate different subtasks under five tasks, respectively. For the phenotyping estimation task and the environmental stress assessment task, the RMSE and R2 evaluation indicators are selected for regression tasks (estimating the values of FVC, SPAD, LAI, CH, CV, WH, and Yield), and the accuracy evaluation indicator is selected for the classification task (estimating the categories of WL and PL). For each subtask under the target germplasm screening task and cultivation technique recommendation task, each MLLM is tested multiple times (1k), and each test is manually judged whether the answer is correct. Then the proportion of the number of correct answers to the total number of tests is used as the evaluation indicator. For the seed price query task, we counted whether each result after multiple (1k) tests was consistent with the data in the knowledge base (price \u00b1 10%), and took the proportion of the total number"}, {"title": "Stability", "content": "We evaluate the consistency and robustness of the answers. The evaluation indicator of stability is the proportion of times that satisfy the stability requirements in the total number of tests (1k), where the stability requirement is that the deviation of the numerical value in the answer is within \u00b110%, and whether the text satisfies the requirement is manually judged. Consistency: Since cross-domain data are related, the answers given after inputting different data from cross-domain data into the model should remain basically consistent. Robustness: The model's answer or performance should not change significantly when faced with small changes in input data. Robustness requires that the model should have a certain degree of fault tolerance."}, {"title": "Reasoning", "content": "We evaluate the logical deduction, inductive reasoning, and explanation of the answers. The evaluation indicator of reasoning is the proportion of the total reasoning score of a single model after multiple tests (1k) to all scores. After one test, x MLLM models output x answers. After manually analyzing x answers, we select a score from 1 to x points for each answer and the score can only be selected once until all answers are scored. We sum up the answer scores of different models after multiple tests as the total reasoning score of the corresponding model. Then calculate the proportion of the total reasoning score of different models to all scores ((1+x) * x / 2). Logical deduction: The model can deduce new conclusions or answers through logical reasoning based on known facts, rules and conditions. This requires the model to understand the logical relationships in the question and accurately apply these relationships to deduce answers. Inductive reasoning: The model can summarize general rules or patterns from a series of specific examples or observations and give reasonable answers based on them. Inductive reasoning requires the model to have the ability to abstract and generalize information. Explanation: The reasoning process is explained or visualized to a certain extent to help user understand the source and basis of the answer."}, {"title": "4. Results and Discussion", "content": null}, {"title": "4.1. Evaluation of WBLM", "content": "The newly constructed wheat breeding model evaluation benchmark was used to evaluate closed-source MLLMs (Qwen 2.5, ERNIE Bot 4 Turbo, GPT-40 Plus and Gemini Pro 1.5, abbreviated as Qwen, ERNIE Bot, ChatGPT, Gemini) and WBLMs built based on different open-source MLLMs (Qwen-VL, InternVL, Yi-VL, Deepseek-VL and GLM-4) (Fig. 3-5, Table S5).\nAccuracy evaluation: On various tasks of the evaluation benchmark, the comprehensive performance of WBLM based on InternVL2-8B is better than that of WBLM built on other open-source MLLMs, and is significantly better than closed-source ChatGPT, Gemini, and Qwen. Among them, for LAI evaluation, the R2 based on InternVL2-8B is 0.795 and the RMSE is 1.302. The R2 and RMSE of other open-source MLLMs range from [0.674, 0.772] and [1.542, 2.486], and the R\u00b2 and RMSE of closed-source MLLMs range from [0.118, 0.142] and [3.61, 3.985], respectively. ChatGPT shows leading performance among open-source models, although still far behind the WBLM based on InternVL2-8B. In addition, we find that consistent with existing study (Z. Chen et al., 2024), the performance of MLLMs with small parameters in the same series is lower than that of MLLMs with larger parameters, such as InternVL2-8B and InternVL2-2B. We attribute this modest decline to the smaller size of the MLLMs.\nStability evaluation: Compared with closed-source MLLMs, WBLMs based on open-source models outperform in stability tests. Specifically, the WBLM based on InternVL2-8B achieved the best performance in consistency, with a stability score of 0.811, while the stability score of the lowest-performing Qwen 2.5 was only 0.053. The robustness scores of closed-sources MLLM ([0.829, 0.895]) are higher than those of WBLM based on open-source MLLM ([0.735, 0.802]), because closed-source MLLM cannot accurately answer relevant breeding questions in most tasks, and the answers are still wrong and similar when faced with slight changes in input data. However, among multiple WBLMs based on open-source MLLM, WBLM based on InternVL2-8B has a higher robustness score."}, {"title": "Reasoning evaluation:", "content": "The WBLM based on InternVL2-8B outperforms other MLLMs in logical deduction and explanation evaluation, with the highest scores of 0.158 and 0.15, respectively. The WBLM based on GLM-4V-9B-chat outperforms other MLLMs in inductive reasoning evaluation, with the highest score of 0.16. Compared with accuracy and stability evaluation, reasoning evaluation tests the model's breeding decision support and problem-solving capabilities more. Excellent reasoning ability can enhance users' trust in MLLM and improve user satisfaction (J. Li et al., 2024).\nInternVL2-8B based WBLM shows leading performance in most benchmark tests (Fig. 3-5, Table S5). However, the closed-source commercial MLLMs used in this study encountered significant difficulties in the wheat breeding evaluation benchmark test and performed poorly. The main reason is that closed-source commercial MLLM lacks domain knowledge related to wheat breeding, while open-source MLLM obtains it using a combination of domain knowledge technologies (Ming and Li, 2024). Although closed-source MLLMs represented by ChatGPT achieved better performance on the popular MLLM evaluation benchmarks (Fu et al., 2024; Y. Liu et al., 2024; Yue et al., 2024), we did not build WBLM based on closed-source MLLMs because these MLLMs do not support further implementation of the process of this study. If closed-source MLLMs support richer fine-tuning and downstream task customization, they may gain greater commercial value and more users. Although all open-source MLLMs can handle multimodal tasks, different network architectures have different abilities to solve semantic alignment between modalities when integrating visual and textual data, thus affecting the accuracy of the final results. In addition, different training processes, tricks, and private training data are also important factors affecting model performance (D. Huang et al., 2024). In the future, researchers can build breeding models based on MLLM with better performance to provide stronger breeding assistance efficiency and results."}, {"title": "4.2. Impact of domain knowledge on breeding goals", "content": null}, {"title": "4.2.1. Contribution of the combination of domain knowledge and technology to breeding goals", "content": "We evaluated WBLM on the wheat breeding model evaluation benchmark and observed strong performance of WBLM based on InternVL2-8B. In this section, we conduct ablation experiments to test the performance of different domain knowledge technologies combinations in different tasks (Fig. 6 and Table S6).\nFor the phenotyping estimation task, Yield, SPAD, LAI, CH, and CV show poor performance under the MLLM-only method due to the same lack of domain knowledge. Compared with the MLLM-only method, the MLLM and SFT method, the MLLM and RAG method, and the MLLM and RLHF method all greatly improve the prediction performance of these subtasks. Additionally, for the WH and PL subtasks, MLLM has certain detection and classification capabilities. With the addition of SFT, RAG, and RLHF technologies, the performance is further improved to achieve relatively high R2 and low RMSE. For"}]}