{"title": "COGNITIVE NEURAL ARCHITECTURE SEARCH\nREVEALS HIERARCHICAL ENTAILMENT", "authors": ["Lukas Kuhn", "Sari Saba-Sadiya", "Gemma Roig"], "abstract": "Recent research has suggested that the brain is more shallow than previously\nthought, challenging the traditionally assumed hierarchical structure of the ven-\ntral visual pathway. Here, we demonstrate that optimizing convolutional network\narchitectures for brain-alignment via evolutionary neural architecture search re-\nsults in models with clear representational hierarchies. Despite having random\nweights, the identified models achieve brain-alignment scores surpassing even\nthose of pretrained classification models\nas measured by both regression and\nrepresentational similarity analysis. Furthermore, through traditional supervised\ntraining, architectures optimized for alignment with late ventral regions become\ncompetitive classification models. These findings suggest that hierarchical struc-\nture is a fundamental mechanism of primate visual processing. Finally, this work\ndemonstrates the potential of neural architecture search as a framework for com-\nputational cognitive neuroscience research that could reduce the field's reliance\non manually designed convolutional networks.", "sections": [{"title": "1 INTRODUCTION", "content": "Throughout the last decade, Convolutional Neural Networks (CNNs) have emerged as powerful cog-\nnitive models capable of providing valuable insight into the neural mechanisms underlying primate\nvisual processing (Yamins et al., 2014; St-Yves et al., 2023; Guo et al., 2025). In their seminal work,\nYamins et al. (2014) demonstrated that CNNs trained to perform image classification can be used\nto predict brain activity. Moreover, their findings suggested a shared representational hierarchy be-\ntween CNN layers and visual cortex regions, where intermediate and late CNN layers correspond to\nintermediate and late visual processing regions, respectively. However, recent research that directly\nexplored the emergence of brain-like hierarchy in neural networks trained to directly predict brain\nactivity found evidence against the necessity of entailment hierarchy (St-Yves et al., 2023). Based\non their results, the authors posit the shallow brain hypothesis, arguing that low-level representations\nmay not be necessary as preprocessing stages for higher-level representations. Our work expands\non this shallow vs deep-brain debate by employing Neural Architecture Search (NAS) to explore\nthe emergence of early visual cortex-like representation in network architectures optimized to align\nwith late ventral representation.\nPrevious studies have demonstrated that it is possible to identify CNNs with state-of-the-art classifi-\ncation performance by directly optimizing model architectures using methods such as reinforcement\nlearning or genetic algorithms. For instance, (Xie & Yuille, 2017; Liu et al., 2018) leveraged ge-\nnetic algorithms to 'evolve' architectures that outperform manually designed CNNs on MNIST and\nCIFAR-10 datasets. More recently, Mundt et al. (2021) employed NAS to identify network architec-\ntures that, even without gradient descent training, compute representations that enable classification\nperformance comparable to fully trained deep networks by simply training a linear probe to predict\nthe image label. Building on this, we evolved CNNs to predict cognitive representations across dif-\nferent regions of the ventral stream. We formulate a simple hypothesis in favor of the deep-brain\nmodel: optimizing CNNs to predict late visual representations in the inferior temporal (IT) cortex"}, {"title": "2 METHOD", "content": "We follow the standard evolutionary NAS methodology of allowing the genetic algorithm to perform\nselection, mutation, and crossover of the best networks in each generation to find an optimal CNN\narchitecture (Liu et al., 2018). In the following section, we present the specifics of this evolutionary\narchitecture search. That is, we discuss the search space, the evaluation strategy, and the genetic\noperators used to evolve each new generation of CNNs."}, {"title": "2.1 SEARCH SPACE", "content": "Following Xie & Yuille (2017), we construct an initial generation of random individual networks,\nwhere each is a standard hierarchical stack of multiple convolution and max-pooling layers. We\nempirically found that linear layers are bad predictors of brain-alignment and therefore excluded\nthem from the search space to allow for faster convergence. We also limit the searchable hyper-\nparameter ranges of the convolution layers kernel size (3 to 11), stride (1 to 4) and number of\nfilters (64 to 512). Furthermore, the max-pooling layers kernel size range was 2 to 3. Finally, to\nfurther restrict the search space we also enforce the CNNs to always have a monotonically increasing\nnumber of filters across the layers."}, {"title": "2.2 GENETIC OPERATORS", "content": "After all the models in a generation are evaluated, we remove the bottom 50% of the CNN population\nbased on fitness. We then create new offspring networks to repopulate the population. This is\nachieved using standard mutation and crossover genetic operators (Xie & Yuille, 2017).\nOur mutation strategy employs three operators on each selected parent network: addition, modifi-\ncation, and removal. The addition operation introduces new layers while maintaining architectural"}, {"title": "2.2.1 EVALUATION", "content": "Adapting the approach of Mundt et al. (2021) we evaluate multiple randomly initialized versions\nof the same network, guaranteeing that the models are picked based on architecture, rather than\na lucky weight initialization (the lottery ticket hypothesis). We evaluate network performance by\nextracting the last layer image encoding and training a ridge regression to predict fMRI responses to\nthe same image. The fitness of each model was calculated by taking the mean Pearson correlation\ncoefficient over ten consecutive random seeds for each subject. Finally, to speed convergence, in\nthe first two generations we artificially increase the population size by evaluating every layer of\neach network (not just the last) and use the best performing sub-network in following generations.\nFollowing common practice, the random network weights were initialized using a Kaiming uniform\ndistribution with a bias of zero."}, {"title": "2.3 DATASET", "content": "The regression was trained using data from the NSD Dataset Allen et al. (2022), a large-scale fMRI\ndataset of 8 subjects viewing thousands of natural scenes. Specifically, we used a set of 872 im-\nages shared across all subjects. Following (Guo et al., 2025), we used a subset of five subjects\n(subjects 1,2,4,5,7) with a high signal-to-noise ratio (SNR). Moreover, we focused on the brain ac-\ntivity recorded in V2, V4, and the Inferior Temporal cortex (IT) as stand-ins for representations in\nthe early, intermediate, and late ventral stream respectively. Specifically, IT activations were con-\nstructed by concatenating activations from the FFA, FBA, EBA and PPA regions."}, {"title": "2.4 BASELINE MODELS", "content": "We compare the brain-alignment of our models against well known CNNs such as AlexNet and\nVGG16 which are often used as cognitive models (see Yamins et al. (2014); Guo et al. (2025)).\nMoreover, we also use CORNetS which was specifically designed to process information in a more\nbrain-like manner Kubilius et al. (2019)."}, {"title": "3 EXPERIMENTS AND RESULTS", "content": "The brain alignment results reported in this section are in terms of percent of variance explained\nrelative to the lower noise ceiling. For representational similarity analysis we followed the standard\nlower noise ceiling calculation Nili et al. (2014). For the regression based alignment score we used\nthe estimation method presented by Lage-Castellanos et al. (2019)."}, {"title": "3.1 EVOLUTIONARY SEARCH FOR COGNITIVE MODELS", "content": "We ran our evolutionary search three times for each brain region. Each run consisted of 100 genera-\ntions with a mutation rate of 0.25 and a crossover rate of 0.5. The optimal architectures discovered\nwere virtually identical in all runs optimizing for the alignment with the same brain region, indicat-\ning that the identified networks are robust to noise in the evolutionary search process. Moreover,\nthe three optimal architectures EvoV2, EvoV4, and EvoIT had high alignment with their respective\nbrain regions, outperforming most baseline models (Table 1). The number of layers for EvoV2,\nEvoV4, and EvoIT was five, six, and nine respectively."}, {"title": "3.2 REPRESENTATIONAL HIERARCHY IN EVOLUTIONARY COGNITIVE MODELS", "content": "We formulated the following hypothesis in favor of the existence of hierarchical entailment across\nbrain region representations: optimizing CNNs to predict activations in the IT representations will\nalso spontaneously optimize the networks to learn V2 and V4 representations. To accomplish this\nwe tested the brain-alignment of each brain region with each layer in all CNNs (Table 1). Indeed,\nwe find that EvoIT contained sub-networks that are competitive predictors of V2 and V4 (in fact,\na subnetwork of EvoIT was the best in class V4 model). Specifically, the EvoIT layer that was\nmost correlated with V4 was the third pooling layer (Figure 2 left). Moreover, manually inspecting\nthe best performing architectures we observed that the EvoV4 and EvoIT architectures contained\nsubnetworks virtually identical to EvoV2 and EvoV4 respectively. Overall, these results indicate\nthat to compute representations similar to those found in the IT it is indeed beneficial to first compute\nrepresentations similar to those found in V2 and V4."}, {"title": "3.3 TRAINING EVOLUTIONARY COGNITIVE MODELS FOR IMAGE CLASSIFICATION", "content": "CNNs designed to perform image classification are state-of-the-art cognitive models Yamins et al.\n(2014). Here we investigate if CNNs with architectures that were specifically optimized for brain-\nalignment can be trained to perform image classification. To achieve this we used the best archi-"}, {"title": "3.4 REGRESSION AND REPRESENTATIONAL SIMILARITY ANALYSIS", "content": "Both regression and representational similarity analysis have been used to measure brain-model\nsimilarity. The evolutionary search fit function we used was directly based on the Pearson correlation\nbetween ground truth fMRI and the predictions of a trained ridge regression. Therefore, it is to\nbe expected that, while the models identified by this optimization outperform the baselines when\nthe evaluation is done with regression, the RSA results are less consistent. Moreover, training the\nnetworks using the CIFAR-10 classification task improved brain-alignment as measured through\nRSA while hurting the regression score. This might indicate that the representation space of the\nevolved models lacks some structural elements that can only be learned through gradient descent\ntraining. We look forward to exploring this further using experiments that employ other brain-\nalignment scores such as RSA and CKA."}, {"title": "4 DISCUSSION AND FUTURE WORK", "content": "In this paper we used genetic algorithm based neural architecture search to optimize the architecture\nof the convolutional neural networks directly to be more brain-like. Through this framework we\nidentified network architectures that had high similarity to various brain regions despite the lack of\nany gradient descent based training. Moreover, we found that the model optimized for similarity\nwith late ventral stream areas contained subnetworks that were virtually identical to those identified\nas the optimal models for similarity with early and intermediate visual cortex representations. This\nfinding directly contributes to the recent discussion regarding the hierarchy - or lack thereof - found\nacross visual cortex representation (Yamins et al., 2014; St-Yves et al., 2023).\nMore broadly, the framework presented here is a potential new useful tool for computational cog-\nnitive neuroscience research. Previous research tackling questions regarding the architecture of\nthe brain often followed a specific recipe: CNN architectures are modified in a controlled manner\nwhile the training data and function are held constant. Model-brain alignment is then measured to\ndetermine if the modification improves brain similarity, which would be taken as evidence that the\nmodification constitutes an abstraction of a mechanism found in the brain (for example see Guo et al.\n(2025)). In contrast, the cognitive NAS framework presented here optimizes the model architecture\ndirectly, instead of relaying on handcrafted CNNs, which might introduce unwanted bias.\nThe initial results presented here highlight the potential utility of Cognitive NAS for the research\ncommunity. However, the results of our experiments also raise multiple questions. Specifically,\nwhile the evolved networks were powerful encoding models, their performance was subpar when\nmeasured through representational similarity analysis. Future work should carefully investigate the\nimpact of the brain-similarity measure used during the NAS on the trajectory of the architecture\nsearch and the final networks identified as optimal cognitive models."}]}