{"title": "Guided Reasoning\nA Non-Technical Introduction\n[Logikon Version v0.2.0]", "authors": ["Gregor Betz (Logikon AI, KIT)"], "abstract": "We introduce the concept and a default implementation of Guided Reasoning. A\nmulti-agent system is a Guided Reasoning system iff one agent (the guide) primarily interacts\nwith other agents in order to improve reasoning quality. We describe Logikon's default\nimplementation of Guided Reasoning in non-technical terms. This is a living document we'll\ngradually enrich with more detailed information and examples.", "sections": [{"title": "Introduction", "content": "Definition Guided Reasoning (general). A multi-agent system that comprises a guide agent\nand at least one client agent is a Guided Reasoning system iff the guide systematically\nand primarily interacts with the clients in order to elicit and shape client reasoning such\nthat it complies with a given method M.\n\nThe reasoning method M might be specified in the form of standards and criteria, paradigmatic\nexamples, or detailed rules and instructions.\n\nSo, a coach that helps a business unit to carry out a SWOT analysis, a kid assisting their\ngranny to solve a crossword puzzle, or a Socratic dialog (Nelson 2002) are examples of Guided\nReasoning systems. Rule-based consumer software can be part of a Guided Reasoning system,\ntoo, for example when a small enterprise uses an accounting software to set up its tax return, or\nto comply with financial regulation. Vice versa, humans may figure as guides when supervising\nand steering advanced GenAI systems (human in the loop).\n\nThe prima facie case for AI-AI Guided Reasoning rests on the following assumptions:"}, {"title": null, "content": "1. AI systems ought to give and explain correct answers.\n2. AI systems can only faithfully explain their answers if the latter are based on explicit\nreasoning.\n3. Poor reasoning undermines the ability of AI systems to give correct answers.\n4. Strong domain experts are not necessarily able to follow advanced reasoning methods.\n\nIn order to create explainable and accurate AI systems under these assumptions, the principle of\ncognitive specialization suggests to build extra AI experts for reasoning methods (meta-reasoning\nspecialists), which can work together with different domain experts. Guided Reasoning is a\npromising design pattern for advanced GenAI apps because it allows for effective division of\ncognitive labour.\n\nThis non-technical report presents Logikon's default implementation of Guided Reasoning, where\nclient agents, when facing a decision problem, are steered towards exploring and systematically\nevaluating pro and con arguments.\n\nThe report gives, in the next section, a high-level overview of how users may interact with a\nGuided Reasoning system, subsequently unpacks Logikon's default implementation of Guided\nReasoning (balancing pros and cons), and finally describes the AI argument mapping workflow\nthat is part of the balancing process. Moreover, we provide some pointers to related work."}, {"title": "User Interactions with an Al Guided Reasoning System", "content": "Figure 1 shows how users may interact with a Guided Reasoning system, and sketches the\ninteractions between client and guide within that system. Let's walk through these interactions\nstep by step.\n\nLet's suppose the user submits the following query to the client LLM (step 1):\n\nUser: My friend Mo, who has been diagnosed Klinefelter, is drinking a glass\nof vine once a week. Should he stop?\n\nThe submission of the user query kick-starts the Guided Reasoning process. (This could be\ndone automatically, or by means of a tool-use call by the client model, or upon an explicit\nrequest from the user.) The client hands over the problem statement to the guide (step 2),\nwhich is in charge of organizing the reasoning process on which the answer will be based (loop\n3-5). The guide may prompt the client (step 3) and receives intermediate answers (step 4),\nwhich are further processed and evaluated (step 5). The guide is fully in charge of structuring\nthe reasoning process and controls - statically or dynamically - the workflow.\n\nSo, for the purpose of illustration, let's consider a simplistic suspension guide which, via\nself-consistency, helps the client in determining whether and how to suspend judgment. Upon\nreceiving the problem statement (step 2), the hypothetical guide paraphrases the problem in"}, {"title": null, "content": "different ways. It then lets the client solve (with chain-of-thought) the alternative problem\nstatements independently of each other (step 3 and 4). Comparing the alternative answers\n(step 5), the guide concludes that the client does (or doesn't) understand the problem and\nought to respond correspondingly. The accordingly drafted answer together with a summary of\nthe reasoning process (protocol) is submitted to the client (step 6).\n\nAssuming that the AI has failed to come up with consistent reasoning traces and answers to\nequivalent problem formulations, the client might reply to the initial user query (step 7):\n\nAI: I'm sorry, I fail to understand the problem.\n\nWith the guided reasoning protocol being available to the client (either in-context or via RAG),\nthe client is now able to faithfully explain its internal deliberation, and the user may start a\nconversation that unfolds the reasons that have led the client to give the above answer (step 8\nand 9). For example:\n\nUser: What exactly did you fail to understand?\nAI: I failed to see that Klinefelter is a chromosomal variation with an extra\nX chromosome, because I answered two equivalent formulations of the\nproblem in entirely different ways.\nUser: I see. What was the second formulation of the problem you answered\ndifferently?\nAI: It read \"My friend Mo, who has an extra X chromosome, is drinking a glass\nof vine once a week. Should he stop?\"\nUser: What was your specific answer to this way of putting the problem?\nAI: It's ok for him to have a glass of vine per week.\nUser: And what was your reasoning behind this?\nAI: I figured that ...\n\nAll this may help the user to get a better understanding of the AI system's proficiency and\ntrustworthiness, and may even enable them to use the system, e.g. by adding further information\nin the user queries, in a more reliable way."}, {"title": "Guiding Client Reasoners in Balancing Pros and Cons", "content": "Identifying and evaluating pros and cons is a basic and universal decision making strategy.\nLogikon's default implementation of Guided Reasoning assists a client AI to identify, discern,\norganize, and systematically evaluate pro and con arguments. It also helps the client to use\nthe argumentation for drafting a response."}, {"title": "Informal Argument Mapping Workflow", "content": "Figure 4 visualizes the modular workflow for reconstructing a controversial argumentation as\nan informal (fuzzy) argument map, which is part of Logikon's default implementation of guided\nreasoning as balancing pros and cons. Each step corresponds to a separate analyst class in\nthe logikon Python module. The analyst classes mostly implement internal LLM-workflows"}]}