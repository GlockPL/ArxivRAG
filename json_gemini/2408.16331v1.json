{"title": "Guided Reasoning: A Non-Technical Introduction [Logikon Version v0.2.0]", "authors": ["Gregor Betz"], "abstract": "We introduce the concept and a default implementation of Guided Reasoning. A multi-agent system is a Guided Reasoning system iff one agent (the guide) primarily interacts with other agents in order to improve reasoning quality. We describe Logikon's default implementation of Guided Reasoning in non-technical terms. This is a living document we'll gradually enrich with more detailed information and examples.", "sections": [{"title": "Introduction", "content": "Definition Guided Reasoning (general). A multi-agent system that comprises a guide agent and at least one client agent is a Guided Reasoning system iff the guide systematically and primarily interacts with the clients in order to elicit and shape client reasoning such that it complies with a given method M.\nThe reasoning method M might be specified in the form of standards and criteria, paradigmatic examples, or detailed rules and instructions.\nSo, a coach that helps a business unit to carry out a SWOT analysis, a kid assisting their granny to solve a crossword puzzle, or a Socratic dialog (Nelson 2002) are examples of Guided Reasoning systems. Rule-based consumer software can be part of a Guided Reasoning system, too, for example when a small enterprise uses an accounting software to set up its tax return, or to comply with financial regulation. Vice versa, humans may figure as guides when supervising and steering advanced GenAI systems (human in the loop).\nThe prima facie case for AI-AI Guided Reasoning rests on the following assumptions:\n1. AI systems ought to give and explain correct answers.\n2. AI systems can only faithfully explain their answers if the latter are based on explicit reasoning.\n3. Poor reasoning undermines the ability of AI systems to give correct answers.\n4. Strong domain experts are not necessarily able to follow advanced reasoning methods.\nIn order to create explainable and accurate AI systems under these assumptions, the principle of cognitive specialization suggests to build extra AI experts for reasoning methods (meta-reasoning specialists), which can work together with different domain experts. Guided Reasoning is a promising design pattern for advanced GenAI apps because it allows for effective division of cognitive labour.\nThis non-technical report presents Logikon's default implementation of Guided Reasoning, where client agents, when facing a decision problem, are steered towards exploring and systematically evaluating pro and con arguments.\nThe report gives, in the next section, a high-level overview of how users may interact with a Guided Reasoning system, subsequently unpacks Logikon's default implementation of Guided Reasoning (balancing pros and cons), and finally describes the AI argument mapping workflow that is part of the balancing process. Moreover, we provide some pointers to related work."}, {"title": "User Interactions with an Al Guided Reasoning System", "content": "Figure 1 shows how users may interact with a Guided Reasoning system, and sketches the interactions between client and guide within that system. Let's walk through these interactions step by step.\nLet's suppose the user submits the following query to the client LLM (step 1):\nThe submission of the user query kick-starts the Guided Reasoning process. (This could be done automatically, or by means of a tool-use call by the client model, or upon an explicit request from the user.) The client hands over the problem statement to the guide (step 2), which is in charge of organizing the reasoning process on which the answer will be based (loop 3-5). The guide may prompt the client (step 3) and receives intermediate answers (step 4), which are further processed and evaluated (step 5). The guide is fully in charge of structuring the reasoning process and controls - statically or dynamically - the workflow.\nSo, for the purpose of illustration, let's consider a simplistic suspension guide which, via self-consistency, helps the client in determining whether and how to suspend judgment. Upon receiving the problem statement (step 2), the hypothetical guide paraphrases the problem in"}, {"title": "Guiding Client Reasoners in Balancing Pros and Cons", "content": "Identifying and evaluating pros and cons is a basic and universal decision making strategy. Logikon's default implementation of Guided Reasoning assists a client AI to identify, discern, organize, and systematically evaluate pro and con arguments. It also helps the client to use the argumentation for drafting a response."}, {"title": "Informal Argument Mapping Workflow", "content": "Figure 4 visualizes the modular workflow for reconstructing a controversial argumentation as an informal (fuzzy) argument map, which is part of Logikon's default implementation of guided reasoning as balancing pros and cons. Each step corresponds to a separate analyst class in the logikon Python module. The analyst classes mostly implement internal LLM-workflows\n(not fully documented here, check the code base for details) to produce the desired logical artifacts.\nThe IssueBuilder takes the raw brainstorming reasoning trace and, using expert LLMs, describes the central issue addressed in the text, which is typically a reformulation of the original problem statement.\nThe ProsConsBuilder reconstructs, from the reasoning trace, a multi-root pros and cons list which addresses the central issue identified before. This process is itself composed of several steps: First of all, all reason statements that are relevant for the issue are extracted from the reasoning trace \u2013 irrespective of their valence. In a second step, these reasons are organized in one or several pros and cons list. It's only at this step that the central root claims are identified and added. The resulting pros and cons lists are checked for redundancies and completeness (given initially identified reasons), and revised if necessary.\nThe RelevanceNetworkBuilder uses a series of prompt templates to assess the pairwise probabilistic relevance for any two reason statements, and for any pair consisting of one reason statement and a central claim. This gives us a complete graph on all reason statements and central claims with weighted support and attack relations. (It is assumed that any two root claims maximally disconfirm each other.)\nThe FuzzyArgmapBuilder uses an optimal branching algorithm to extract a tree from the complete graph that connects all argument nodes with maximally strong edges. It then adds additional edges with weights above a given threshold. This yields a fuzzy argument map, which is finally exported in various convenient formats."}, {"title": "Related work", "content": "Explainability and Safety\nScholars and scientists associated with Anthropic have consistently pursued and advanced the idea of \"AI Safety via Debate\" (Irving, Christiano, and Amodei 2018; Michael et al. 2023; Khan et al. 2024).\nEhsan et al. (2024) recognize that the principal ability of LLM-based systems to explain their actions in natural language (Rajani et al. 2019), systematically exploited by AI startups as Wayve, may disrupt the XAI debate. But LLMs do not necessarily produce faithful self-explanations (Turpin et al. 2023; Paul et al. 2024). In a conceptual paper, Baum et al. (2022) show in detail why good reasoning is required for reliable AI explainability. Similarly, Leofante et al. (2024) have argued recently that contestable AI systems must be able to rationally respond to objections and counter-arguments, which in turn requires argumentative skills. Bezou-Vrakatseli, Cocarascu, and Modgil (2024) suggest to increase AI safety through integrative epistemic inquiries that involve both AI agents and humans.\nGuiding Al Reasoning\nPan et al. (2023) review the vast landscape of self-check systems for chain-of-thought, which steer LLM reasoning by providing feedback.\nHong et al. (2024) build an AI Guided Reasoning system that constrains the reasoning of AI medical expert systems by informal argumentation schemes.\nAl Argumentation Analysis\nLawrence and Reed (2020) give a gentle introduction to the field of argument mining.\nEin-Dor et al. (2020) have proven the feasibility of argument retrieval from large text corpora with LLMs.\nBetz and Richardson (2021) have presented, implemented and verified an LLM-based system design for deep logical reconstruction of natural language arguments."}, {"title": "Appendix", "content": "A. Illustrative Problem Statement and Answer\nAn illustrative problem statement and answer based on guided deliberation (screenshot from demo app, with illustrative configuration):\nB. Illustrative Guided Reasoning Protocol\nThe following reasoning protocol summarizes the guided deliberation for the example problem statement:"}]}