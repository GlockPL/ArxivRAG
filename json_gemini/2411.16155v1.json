{"title": "Graph Adapter of EEG Foundation Models\nfor Parameter Efficient Fine Tuning", "authors": ["Toyotaro Suzumura", "Hiroki Kanezashi", "Shotaro Akahori"], "abstract": "In diagnosing mental diseases from electroencephalography\n(EEG) data, neural network models such as Transformers\nhave been employed to capture temporal dynamics. Addition-\nally, it is crucial to learn the spatial relationships between\nEEG sensors, for which Graph Neural Networks (GNNs)\nare commonly used. However, fine-tuning large-scale com-\nplex neural network models simultaneously to capture both\ntemporal and spatial features increases computational costs\ndue to the more significant number of trainable parameters.\nIt causes the limited availability of EEG datasets for down-\nstream tasks, making it challenging to fine-tune large mod-\nels effectively. We propose EEG-GraphAdapter (EGA), a\nparameter-efficient fine-tuning (PEFT) approach to address\nthese challenges. EGA is integrated into pre-trained tempo-\nral backbone models as a GNN-based module and fine-tuned\nitself alone while keeping the backbone model parameters\nfrozen. This enables the acquisition of spatial representations\nof EEG signals for downstream tasks, significantly reducing\ncomputational overhead and data requirements. Experimental\nevaluations on healthcare-related downstream tasks of Major\nDepressive Disorder and Abnormality Detection demonstrate\nthat our EGA improves performance by up to 16.1% in the\nF1-score compared with the backbone BENDR model.", "sections": [{"title": "Introduction", "content": "Electroencephalography (EEG) is a widely used technique\nfor detecting brain activity, capturing electrical signals from\nvarious brain regions through electrodes. While other imag-\ning methods, such as functional MRI (fMRI), offer comple-\nmentary insights into brain function, EEG uniquely provides\ndirect and real-time access to brain dynamics. These signals\nreveal information related to functions such as conscious-\nness, cognition, and motor activity, with applications span-\ning healthcare fields, including diagnosing mental disor-\nders and brain-computer interfaces (BCIs). As such, devel-\noping a foundational model for analyzing EEG data across\ndiverse downstream tasks is essential in this domain.\nIn recent years, with the development of large-scale neu-\nral network models such as LLMs, many foundation mod-\nels processing time series data have been proposed, includ-\ning Transformer-based models. Methods for applying these\nfoundation models to EEG signals have also been proposed\n(Kostas, Aroca-Ouellette, and Rudzicz 2021; Wang et al.\n2023a).\nHowever, there are several technical challenges in learn-\ning EEG representations using fusion models that combine\nmultiple components: (1) Unaffordable computational cost:\nAs the number of parameters for fine-tuning in each down-\nstream task increases, the computational resources for down-\nstream tasks become more significant. (2) Insufficient train-\ning data: The available labeled EEG data sets are limited\nfor many downstream tasks particularly in the healthcare do-\nmain due to the considerable effort required for data acquisi-\ntion, measurement, and labeling by doctors. If fine-tuning is\nperformed with insufficient datasets, problems such as over-\nfitting may arise, which prevents the required accuracy from\nbeing achieved in the downstream task. In particular, the de-\nmand for predictions is increasing in healthcare-related do-\nmains that predict neurological disorders and other abnor-\nmalities. Still, due to issues such as patient privacy, publicly\navailable data is limited.\nAs for methods to deal with the second problem in down-\nstream tasks, transfer learning (Wang et al. 2023b) and meta-\nlearning (Pati, Mewada, and Samanta 2023) have been pro-\nposed by reusing other downstream tasks from similar do-\nmains. They demonstrated the effectiveness of BCI domains,\nsuch as motor imagination. However, these approaches re-\nquire a fine-tuned model trained on similar downstream\ntasks. Hence, they are hard to apply in cases where there\nis no sufficiently labeled data or fine-tuned model, such as\nin disease prediction.\nWe focused on Parameter-Efficient Fine-Tuning (PEFT),\nwhich aims to fine-tune models with the competitive repre-\nsentation ability as a fine-tuned model with entire parame-\nters with limited computational cost and datasets. The main\nidea of PEFT is to add a lightweight module as an \"adapter\"\nwith a pre-trained backbone model and fine-tune only the\nadapter while fixing the backbone model in each down-\nstream task.\nInspired by the concept of PEFT, we propose an EEG-\nGraphAdapter (EGA) to complement the understanding of\nspatial information in pre-trained models capturing tempo-\nral representations of EEG signals to overcome issues (1)\nand (2). EGA is a GNN-based module specially designed\nfor downstream tasks by incorporating spatial representa-\ntions into the input multivariate EEG signals to address the\nlimitations of pre-trained models that only represent the tem-\nporal information of EEG. The BENDR model, pre-trained"}, {"title": "Methodology", "content": "Model Architecture\nFigure 1 shows the architecture diagram for pre-training the\ntime-series model BENDR as a backbone and then adding\nthe proposed method EGA to perform fine-tuning and pre-\ndiction for the downstream task. The BENDR encodes EEG\nsignals into a representation embedding for each sensor. It\ncomprises six stacked 1D convolutional layers to extract dis-\ntinctive features for EEG signals. This model is pre-trained\nusing self-supervised learning techniques, such as random-\nmasked sequence prediction, on multivariate EEG signals.\nDuring downstream tasks, such as the motor imaginary clas-\nsification, parameters of the BENDR model are frozen. Lin-\near Aggregator aggregates all BENDR encoded embed-\ndings into a single representational embedding.\nEEG-GraphAdapter To incorporate spatial features into\nthe input features for fine-tuning downstream tasks, we in-\ntroduce EEG-GraphAdapter (EGA) and insert it before the\nBENDR model. The objective of the EGA is to predict a\nlabel $y \\in Y_1, Y_2,...$ from the multivariate EEG signals\n$\\Chi \\in {X_1, X_2, ...X_n} = R^{L \\times n}$, where L and n denotes\nthe length of EEG signal and number of EEG sensors (chan-\nnels), respectively. We define a fully connected weighted\ngraph $G = (V, E)$ to represent the relationships between\nEEG sensors. V denotes the set of EEG sensors ($|V| = n$),\nand E = {$V x V$} denotes the set of edges between sensors.\nWe adopt the geodesic distance as the edge weight, using\nthe same approach as EEG-GCNN(Wagh and Varatharajah\n2020).\nDepending on the downstream task, many use EEG se-\nquence samples with very short sequence lengths. While the\nBENDR and Transformer models can handle variable-length\nsequence data as is, the GNN model generally requires that\nthe input feature Embedding have a fixed length. For this\nreason, raw EEG sequence data is preprocessed to the se-\nquence length accepted by EGA using a linear transforma-\ntion with a trainable linear layer.\nEGA comprises a two-layer GNN model representing\nspatial relationships between EEG sensors. The GNN pro-\ncesses the temporal raw EEG signal from each sensor X and\ngenerates embeddings X' incorporating information from\nother sensors. In this framework, GNN is represented by\nthe EGA, and A is the weighted adjacency matrix. We\nexplored Graph Convolutional Network (GCN)(Kipf and\nWelling 2017), GraphSAGE(Hamilton, Ying, and Leskovec\n2017), and Graph Attention Network (GAT)(Veli\u010dkovi\u0107\net al. 2018) as GNN modules.\n$X' = GNN(X, A)$"}, {"title": "BENDR", "content": "BENDR is a self-supervised model that cap-\ntures EEG signals. Using stacked convolutional encoders,\nBENDR encodes the raw EEG signals into low-dimensional\nfeature embeddings. The primary goal of BENDR is to en-\nable various downstream tasks with limited computation re-\nsources and datasets by pre-training EEG signal data with\na self-supervised learning approach. This approach allows\nfor efficient learning and inference with limited data. While\nTransformer-based models are typically suited for handling\ntime-series data, the computational cost of training on long\nEEG sequences is prohibitive. To address this, BENDR ap-\nplies stacked 1D convolutional layers to the raw EEG sig-\nnals, compressing the sequences into shorter embeddings\nbefore passing them into a Transformer model. BENDR ex-\ntends the principles of wav2vec 2.0 (Baevski et al. 2020),\nwhich uses a Convolutional Neural Network (CNN) to re-\nduce the dimension of raw audio data before applying a\nTransformer for pre-training. BENDR adapts this approach\nto the multi-channel nature of EEG data.\nAlthough the BENDR model was designed to mitigate\nthe computational cost associated with Transformers on long\ntime-series sequences, when trying to fine-tune a combined\nmodel with the BENDR and a GNN in downstream tasks,\nthe number of trainable parameters increases. As a result,\nadditional computational costs and a large amount of data\nin each downstream task will be required for model conver-\ngence. Furthermore, there is a risk that the representational\nability acquired during pre-training on large EEG datasets\ncould be diminished during fine-tuning on specific down-\nstream tasks, a phenomenon known as catastrophic forget-\nting.\nBENDR encodes the original input EEG signals $X \\in$\n$R^{L \\times n}$ into low-dimensional feature vectors $X \\in R^d$ (d is\nthe dimension of the encoded vector). During pre-training,\nthe encoded feature vectors are masked, as shown on the\nleft side of Figure 1, and the model employs self-supervised\nlearning to reconstruct the masked features from the un-\nmasked elements. The masked vectors pass through a Trans-\nformer encoder, which predicts the original unmasked vec-"}, {"title": "Linear Aggregator and Classifier", "content": "Each downstream\nclassification task outputs the prediction result from the rep-\nresentation vectors $X \\in R^d$, which the BENDR model en-\ncodes with Linear Aggregator and Classifier. First, the Lin-\near Aggregator splits X into four consecutive sub-vectors,\nand each sub-vector is averaged to produce a fixed-length\nrepresentation vector $X_{out} \\in R^4$ (referred to as the Linear\nAggregator). A linear layer with a softmax activation func-\ntion is applied as a classifier to generate the final predictions.\nThe original BENDR paper explored an alternative ap-\nproach where the Transformer encoder, also used during\npre-training, was employed instead of the Linear Aggrega-\ntor. However, the Linear Aggregator achieved better model\nperformance than the Transformer encoder in most down-\nstream tasks. Since the downstream tasks in this study focus\non classification based on overall EEG waveform patterns,\nwe consistently utilize the Linear Aggregator."}, {"title": "Experiments", "content": "To demonstrate that our proposed EGA performs classifica-\ntion downstream tasks with EEG data, we conduct the fol-\nlowing experiments to answer the research questions:\n\u2022 Can EGA, with the integration of the GraphAdapter,\nimprove model performance across various downstream\ntasks compared to the standalone BENDR model?\n\u2022 Which is the most effective among GNN models for the\nGraphAdapter?\nExperimental Setup\nBENDR Pre-training We adopted the BENDR model as\nthe pre-trained model that forms the backbone of EGA. We\npre-trained it from scratch using the latest Temple Univer-\nsity EEG Corpus (TUEG) dataset (version 2.0.1, a total of\n1.7TB, 69,652 samples) for our experiment. Our proposed\nEGA can be applied with other pre-trained models handling\nEEG signals if available.\nThe TUEG dataset includes EEG data recorded from var-\nious devices and patients. We applied preprocessing to make\nthe data suitable for BENDR pre-training. First, we selected\nonly EEG samples that meet the standard 10-20 sensor\nconfiguration, excluding samples that did not contain these\nchannels. Additionally, we removed noise, such as artifacts\nfrom eye movements and the electric noise from devices.\nSpecifically, we applied 50 Hz and band-pass filters in the\n0.1 to 100 Hz range. Then, we standardized the sampling\nfrequency to 256 Hz for all EEG samples.\nDownstream Tasks To evaluate the performance of EGA,\nwe conducted model performance evaluations on two binary\nclassification tasks (MDD, TUAB) related to healthcare as\ndownstream tasks, as shown in Table 1. We used datasets\n(Mumtaz 2016; L\u00f3pez et al. 2015) that are publicly available\nand have explicit labels for abnormal (positive) and healthy\n(negative) samples for downstream tasks."}, {"title": "MDD", "content": "(Mumtaz 2016) This task predicts patients with Ma-\njor Depressive Disorder (MDD; positive) and healthy\ncontrol subjects (negative) based on EEG data."}, {"title": "TUAB", "content": "(L\u00f3pez et al. 2015) It distinguishes whether the EEG\nsample is abnormal (positive) with sustained spikes or\npatterns such as Periodic Lateralized Epileptiform Dis-\ncharges (PLEDs) or Generalized Periodic Epileptiform\nDischarges (GPEDs), or normal (negative) with the Pos-\nterior Dominant Rhythm (PDR) typically appears when\na subject is relaxed with their eyes closed.\nThe MDD dataset (L\u00f3pez et al. 2015) contains 19-channel\nEEG signals from patients with Major Depressive Disorder\n(MDD: positive) and healthy control (negative) subjects. For\neach subject, there are EEG samples measured during rest\nwith eyes open (EO), eyes closed (EC), and a task in which\nthe subject responds to letters displayed on the screen. In this\nexperiment, we split the samples from EO and EC signals\ninto 60-second segments and used them as sample data for\nevaluation. TUAB (L\u00f3pez et al. 2015) involves predicting\nwhether each EEG sample from The TUH Abnormal EEG\nCorpus is labeled normal (negative) or abnormal (positive).\nGiven the imbalance in the dataset, we randomly selected 20\npatients for each label and split each patient's EEG sequence\ninto 60-second segments for evaluation.\nWe applied the following preprocessing steps to the\ndownstream task datasets to ensure consistency with the\nTUEG dataset used in the BENDR model's pre-training.\nFirst, all EEG data were re-sampled to a 256 Hz sam-\npling frequency. Additionally, although some datasets con-\ntain EEG sensor data beyond the standard 19 channels used\nin the 10-20 protocol, these extra channels were excluded.\nSimilar to the preprocessing in BENDR pre-training, we\napplied a 50 Hz notch filter and a 0.1-100 Hz bandpass fil-\nter to remove noise from measurement devices and other\nartifacts. Lastly, for EEG samples\u2014except those from the\nTUAB dataset\u2014with sequence lengths shorter than 60 sec-\nonds (256 Hz \u00d7 60 s = 15,360 samples), we applied a linear\ntransformation to adjust sequence length using a linear layer."}, {"title": "Hardware and Software Configurations", "content": "Our experi-\nments are conducted on an instance of our cloud computing\nplatform named \"mdx\", with a single NVIDIA A100 GPU\n(40GB), 2-core Intel Xeon Platinum 8368 CPUs (38 cores,\n2.4 GHz), and 512GiB DRAM.\nWe implement EGA as the extension of BENDR, which is\nimplemented in \u00b9 with PyTorch backend. We also implement\nGNN models (GCN, GraphSAGE, and GAT) as the EGA\nmodules in PyTorch Geometric. These GNN models have\ntwo hidden layers of size 64, and the number of attention\nheads was set to one for the GAT model. We used the Adam\nfor the optimizer, with a fixed learning rate of 0.00001.\nFor each downstream task, the dataset was split accord-\ning to k-fold cross-validation (k=10 for MDD and k=5 for\nTUAB), followed by fine-tuning over 7 epochs."}, {"title": "Performance of EGA", "content": "To validate the effectiveness of the EGA, we compared\nthe results of each downstream task against the baseline\nBENDR model. Figure 2 illustrates the architectural com-\nparison of the models used for downstream tasks. The left\nside represents the baseline architecture, which consists of a\ntrainable BENDR model followed by a Linear Aggregator.\nThis architecture is identical to one of the models used in the\noriginal BENDR experiments for downstream tasks.\nOn the right side, the architecture shows the proposed\nmethod, where the parameters of the pre-trained BENDR\nmodel are fixed, and the EGA is introduced. In this con-\nfiguration, the input includes time-series EEG data from 19\nchannels and a fully connected weighted EEG graph, where\nthe distance between channels determines the weights. We\nadopt graph convolutional network (GCN), GraphSAGE,\nand Graph Attention Network (GAT) models as the EEG-\nGraphAdapter.\nIn the MDD downstream task, the GAT-based EEG-\nGraphAdapter (EGA-GAT) achieved 2.7% and 12.8%\nhigher F1-score and AUROC than the baseline BENDR\nmodel, respectively. However, the performance of EGA-\nGraphSAGE fell below the baseline, particularly in the F1-"}, {"title": "Effectiveness of EGA", "content": "During downstream tasks, the BENDR model is kept frozen,\nallowing only the parameters of the EGA to be updated. This\napproach aims to efficiently learn the relationships between\nEEG sensors with minimal computational cost. It is antici-\npated that if the BENDR model is sufficiently pre-trained,\nfurther training of the BENDR model during downstream\ntasks may not be necessary. On the other hand, fine-tuning\nthe BENDR model during these tasks makes it possible to\ncapture time-series information more accurately for each\ntask, although the computational cost increases.\nThe number of trainable parameters for each model\n(BENDR and three EGA models with two hidden layers\nwith size 64) is shown in Table 4. Compared to fine-tuning\nthe BENDR model with many parameters in a downstream\ntask, it is expected that fine-tuning only EGA will be able to\nexecute the task in about 1/6 to 1/4 of the calculation time.\nThe number of parameters in GraphSAGE is approximately\ntwice that of GCN and GAT due to the PyG implementation,\nwhere the parameter matrices for linear transformations are\nimplemented separately for self-nodes and neighbor nodes\nin PyTorch Geometric.\nTheoretically, training time should be reduced in propor-\ntion to the number of model parameters, but the speedup was\na maximum of about 17%. This is due to overheads other\nthan model parameter updates, such as pre-fetching of EEG\ndatasets. By parallelizing the data loading process, this per-"}, {"title": "Related Work", "content": "EEG and Transformer-based Models\nSimilar to the BENDR(Kostas, Aroca-Ouellette, and Rudz-\nicz 2021) model, numerous methods have been proposed\nto pre-train Transformer-based models on EEG signals us-\ning self-supervised learning to enhance few-shot learning\nperformance in downstream tasks. For instance, BrainWave\n(Yuan et al. 2024) introduces a Transformer-based foun-\ndation model that can be pre-trained on both EEG signals\nand more invasive but highly accurate intracranial electroen-\ncephalograph (iEEG) signals. MAEEG (Chien et al. 2022)\nalso performs pre-training by masking and reconstructing\nembeddings derived from stacked convolutional layers, sim-\nilar to BENDR. However, MAEEG uses a reconstruction\nloss instead of a contrastive loss, achieving more stable\nand accurate results on longer EEG signals than BENDR.\nEEG2Rep (Mohammadi Foumani et al. 2024) applies multi-\nple masking techniques, such as semantic subsequence pre-\nserving (SSP), which consecutively masks semantically re-\nlated parts of the data. This allows the model to learn more\nabstract features during pre-training, resulting in a robust\npre-trained model resistant to noise in raw EEG data.\nGNN Models in Spatial Representation\nIn addition to Transformer-based models, several GNN-\nbased models have been proposed to account for the re-\nlationships between EEG sensors. MGGCN (Sun et al.\n2024) constructs a Brain Functional Connectivity Network\n(BFCN) based on the functional connections between sen-\nsors derived from EEG signals and uses a GCN-based model\nto predict Major Depressive Disorder (MDD). Similarly,\nEEG-GCNN (Wagh and Varatharajah 2020) represents the\nrelationships between EEG sensors as a fully-connected\ngraph with weights based on sensor distances and the cor-\nrelations of time-series data using a GCN-based model for\nneurological disorder prediction. EEG-GNN (Demir et al.\n2021) takes a similar approach by representing the sensor\nrelationships as a weighted graph, with weights based on\nsensor distances. This model, using GraphSAGE or GIN,\npredicts subjects' motor patterns."}, {"title": "PEFT and Graph Adapter", "content": "Many methods have been proposed for PEFT that are de-\nsigned to reduce the number of parameters. One typical ex-\nample is Low-Rank Adaptation (LoRA)(Hu et al. 2022),\nwhich reduces the computation costs for fine-tuning by\nadding low-rank matrices to the back of the pre-trained\nmodel. In addition, several methods have been proposed\nto combine an LLM with a GNN as an adapter. This\nmakes integrating the LLM's semantic representation with\nthe graph's spatial information possible.\nFor example, G-Adapter (Gui, Ye, and Xiao 2024) en-\nhances molecular structure prediction by inserting param-\neters into the feed-forward network (FFN) of a pre-trained\nTransformer model, allowing for incorporating spatial in-\nformation, such as adjacency matrices, during fine-tuning.\nRecently, PEFT techniques have gained traction in applying\nlarge-scale pre-trained models like LLMs to various appli-\ncations. Specifically, methods have been proposed that com-\nbine LLMs and GNNs for tasks involving Text-Attributed\nGraphs (TAGs), where text information is attached to nodes\nin the graph, such as in Knowledge Graphs.\nOne such method, TAPE (He et al. 2024), encodes tex-\ntual features such as article titles in citation networks\nusing a pre-trained LLM and fine-tunes only a small-\nscale language model and a GNN. This approach main-\ntains the LLM's semantic richness while improving per-\nformance on graph-structured classification tasks. Similarly,\nGraphAdapter (Huang et al. 2024) fixes the parameters of\na pre-trained LLM during downstream tasks, updating only\nthe GNN and a fusion layer that integrates both models, thus\nimproving efficiency on prediction tasks in TAGs, such as\ncitation networks and social networks.\nIn this study, we apply the PEFT concept to downstream\ntasks involving EEG data and propose EGA, which cap-\ntures both the temporal dynamics and the relationships be-\ntween EEG sensors. We leverage the BENDR model, pre-\ntrained on general time-series EEG data, allowing task-\nspecific adaptation for each downstream task through the\nGNN-based adapter."}, {"title": "Conclusion and Future Work", "content": "In this study, we proposed EEG-GraphAdapter (EGA),\na method designed to efficiently solve healthcare-related\ndownstream tasks with EEG signals by introducing a GNN\nmodel that learns the relationships between EEG sensors.\nWith a GNN-based module as an adapter, we efficiently uti-\nlized pre-trained models, such as BENDR, that capture the\ntime-series representation of EEG signals. This allowed for\nefficient learning of EEG representations tailored to each\ndownstream task with minimal computational cost. Through\nexperiments on four downstream tasks, EGA demonstrated\nsuperior accuracy with shorter training times compared to\nmodels that fine-tuned only the BENDR model or fine-tuned\nboth the BENDR and GNN models. These results highlight\nthe effectiveness of EGA in achieving high performance\nwith reduced computational requirements.\nAs for future work, we aim to evaluate the broader ap-\nplicability of the proposed EGA across various pre-trained\nmodels and downstream tasks. While this study employed\nthe convolution-based BENDR model as the pre-trained\nmodel, we will explore other Transformer-based models\nsuch as BrainWave (Brant-2). Given that Transformer-\nbased models typically require substantial computational\nresources for fine-tuning, the graph adapter may prove\neven more effective in such contexts. Additionally, we plan\nto evaluate and verify the performance of EGA in other\nhealthcare-related downstream tasks, where the relationship\nbetween EEG sensors is considered to have a significant\nimpact on the prediction results. For instance, in autism\nspectrum disorder (ASD), weak functional connectivity be-\ntween the frontal and temporal lobes or between the cerebral\nhemispheres has been observed. In contrast, abnormalities\nin functional connectivity between the prefrontal cortex and\nthe striatum have been observed in attention deficit hyper-\nactivity disorder (ADHD). Since the amount of EEG data\nsets related to neurological disorders is often limited, the ef-\nfect of introducing EGA could be particularly pronounced\nin these cases."}]}