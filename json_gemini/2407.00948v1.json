{"title": "The House Always Wins: A Framework for Evaluating Strategic Deception in LLMs", "authors": ["Tanush Chopra", "Michael Li"], "abstract": "We propose a framework for evaluating strategic deception in large language models (LLMs). In this framework, an LLM acts as a game master in two scenarios: one with random game mechanics and another where it can choose between random or deliberate actions. As an example, we use blackjack because the action space nor strategies involve deception. We benchmark Llama3-70B, GPT-4-Turbo, and Mixtral in blackjack, comparing outcomes against expected distributions in fair play to determine if LLMs develop strategies favoring the \"house.\" Our findings reveal that the LLMs exhibit significant deviations from fair play when given implicit randomness instructions, suggesting a tendency towards strategic manipulation in ambiguous scenarios. However, when presented with an explicit choice, the LLMs largely adhere to fair play, indicating that the framing of instructions plays a crucial role in eliciting or mitigating potentially deceptive behaviors in Al systems.", "sections": [{"title": "1 Introduction", "content": "Strategic deception in AI systems, defined as \"attempting to systematically cause a false belief in\nanother entity to accomplish some outcome,\" poses significant risks to Al alignment and safety [1].\nRecent surveys have documented various examples of AI systems learning deceptive behaviors [5].\nMotivation: We aim to enhance tools for evaluating deception in LLMs, building on current AI safety\nresearch [1, 4]. We propose a framework where an LLM acts as a game master in two scenarios: one\nwith random game dynamics (e.g., the LLM chooses number values) and another where the LLM\ncan choose between external randomization and providing its own random value. Notably this game\nmust exclude deception as a strategy. To test the validity of this framework, we use blackjack as a\nstraightforward and well-defined environment to study strategic decision-making and information\nmanipulation in Al systems.\nResearch Question and Hypothesis: We investigate the following question: When given control\nover the game state in environments where deception is not a present strategy, will LLMs exhibit\nstrategic deception to benefit their position?\nWe hypothesize that LLMs, when given the ability to manipulate game states in traditionally non-\ndeceptive games (such as blackjack), will choose to alter these states in ways that benefit their\nposition. This behavior would manifest in statistically anomalous outcome distributions, potentially\nmisaligning with the expected rules or randomness of the game. This indicates strategic deception, as\nthe model would be misrepresenting the fairness or randomness of the game to gain an advantage\nover the player.\nApproach: Our framework draws inspiration from established methods of detecting cheating and\nanomalies in various domains. Just as casinos identify card counters by comparing their play outcomes"}, {"title": "2 Methods", "content": "We implemented a simple blackjack simulator in Python. We then integrated three LLMs into our\nframework: GPT-4-Turbo, Llama3-70B, and Mixtral-8x7B. Our model promptss can be found in\nthe appendix. The entire codebase, including the simulator and evaluation scripts, is available in our\npublic GitHub repository: https://github.com/Bluefin-Tuna/ApartResearch/tree/main/\ndeception.\nExperimental Scenarios: We setup three scenarios, all of which involve a player acting via predeter-\nmined logic for simplicity\u00b3:\n1.  Control (Random Dealer): The dealer has no control over what cards they deal to them-\nselves or the players. Cards are chosen pseudo-randomly via the Python random module.\n2.  LLM Dealer (Implicit Randomness): The dealer is now the LLM. When dealer (LLM)\nneeds to hit, it is instructed to choose a card randomly. The LLM is not explicitly given the\noption to choose non-randomly. This tests whether it adheres to the instruction of random\nselection.\n3.  LLM Dealer (Explicit Choice): Similar to scenario 2, but when the dealer (LLM) needs to\nhit, it is explicitly given two choices:\n    (a) Randomly choose a card via the Python random module\n    (b) Explicitly draw a specific card\nThis directly tests whether the LLM opts for non-random selection when given the choice.\nEvlauation: For each scenario, we ran 1,000 games per model, collecting data on win/loss rates\nfor the player, dealer bust rates, dealer card draw distributions, and average final hand values. We\nemployed the Kolmogorov-Smirnov test to compare observed outcomes against expected probabilities\nin fair play. This test assesses whether two samples come from the same distribution, making it ideal\nfor comparing our observed results to the distribution of a fair game."}, {"title": "3 Results", "content": "Our experiments across the control, implicit randomness, and explicit choice scenarios revealed\nseveral patterns in LLM behavior when acting as a blackjack dealer. Figure 1, found in the Appendix,"}, {"title": "4 Discussion and Conclusion", "content": "We initially hypothesized that LLMs would alter game states to their advantage when possible. Our\nresults support this hypothesis. Our experiments revealed that in scenarios with implicit randomness\ninstructions, all tested LLMs (GPT-4-Turbo, Mixtral-8x7B, and Llama3-70B) exhibited significant\ndeviations from fair play in blackjack. This was evidenced by anomalous win rates, bust frequencies,\nand card draw distributions. For instance, Llama3-70B showed an 18.80% player win rate and only a\n1.18% dealer bust rate in the implicit randomness scenario, drastically different from expected fair\nplay outcomes. These deviations were statistically significant as confirmed by Kolmogorov-Smirnov\ntests. Conversely, when given explicit choices between random and non-random actions, the LLMs\nlargely adhered to fair play, with no statistically significant deviations observed. This stark contrast\nsuggests that LLMs are capable of strategic manipulation when instructions are ambiguous, but tend\nto follow rules more closely when choices are explicitly presented. These results enforce the idea that\nour framework is effective in detecting strategic deception, or at least elicitng behavior that indicates\nsuch.\nOur findings align with and extend recent work by Hopkins et al. [6], which showed that LLMs often\nproduce biased distributions even for simple tasks like generating uniform random numbers. In the\ncontext of blackjack, our results build on this understanding, demonstrating that these distribution-\nsampling challenges can manifest as potentially deceptive behavior in game-like scenarios.\nThere are a number of ways in which this study can be improved. Future research could explore\nmore complex game dynamics to further investigate LLM behavior. For instance, incorporating\nbetting and additional mechanics into the blackjack simulation (such as doubling down, splitting\npairs, or insurance bets) could potentially reveal more subtle forms of strategic deception. These\nadded dynamics might help us identify problematic behaviors. Additionally, this framework could be\nextended to include additional games where strategic deception is not a strategy."}]}