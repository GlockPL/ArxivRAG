{"title": "Self-Supervised Transformers as Iterative Solution Improvers for Constraint Satisfaction", "authors": ["Yudong W. Xu", "Wenhao Li", "Scott Sanner", "Elias B. Khalil"], "abstract": "We present a Transformer-based framework for Constraint Satisfaction Problems (CSPs). CSPs find use in many applications and thus accelerating their solution with machine learning is of wide interest. Most existing approaches rely on supervised learning from feasible solutions or reinforcement learning, paradigms that require either feasible solutions to these NP-Complete CSPS or large training budgets and a complex expert-designed reward signal. To address these challenges, we propose ConsFormer, a self-supervised framework that leverages a Transformer as a solution refiner. ConsFormer constructs a solution to a CSP iteratively in a process that mimics local search. Instead of using feasible solutions as labeled data, we devise differentiable approximations to the discrete constraints of a CSP to guide model training. Our model is trained to improve random assignments for a single step but is deployed iteratively at test time, circumventing the bottlenecks of supervised and reinforcement learning. Our method can tackle out-of-distribution CSPs simply through additional iterations.", "sections": [{"title": "1. Introduction", "content": "Constraint Satisfaction Problems (CSPs) are fundamental to many real-world applications such as scheduling, planning, and resource management. However, solving CSPs efficiently in practice remains a significant challenge due to their NP-complete nature. Traditional solvers based on constraint propagation and backtracking search can be computationally expensive, especially for large problem instances. This has motivated the exploration of learning-based approaches as fast neural heuristics for CSP solving (Dai et al., 2017; Selsam et al., 2019; Bengio et al., 2021)."}, {"title": "2. Background", "content": "A Constraint Satisfaction Problem (CSP) is a mathematical model used to represent problems that involve finding values for a set of variables subject to (possibly discrete and non-linear) constraints. Formally, a CSP is defined as a tuple (X, D, C'), where X = {x1, x2, ..., Xn} is a finite set of variables, D = {D1, D2, ..., Dn}, Di C Z Vi\u2208 [n] represents the discrete domains of these variables, and C = {C1, C2,..., Cm } is the set of constraints, where each constraint ci is defined over a subset of variables X\u2081 C X, restricting the values that can be simultaneously assigned to them. The goal in solving a CSP is to assign to each variable a value from its domain such that all constraints in C are satisfied.\nConstraint Programming (CP) (Rossi et al., 2006) is the study of mathematical models and solution algorithms for CSPs. CP uses highly expressive global constraints (Beldiceanu et al., 2005) that involve multiple variables and are designed to capture common constraint structures that appear in a wide range of real-world applications. One prominent example of a global constraint is the ALLDIFFERENT constraint (R\u00e9gin, 1994), which ensures that a subset of the variables take on distinct values."}, {"title": "2.2. Related Work", "content": "Constraint solving with supervised learning. Supervised learning has been extensively applied to constraint solving. For example, Pointer Networks (Vinyals et al., 2015) are used for the sequential generation of combinatorial problems involving permutations such as the traveling salesperson problem. Palm et al. (2018) propose a graph-based recurrent network to model CSPs, effectively leveraging the graph structure to refine variable assignments iteratively. SATNet (Wang et al., 2019) differentiates through semidefinite programming relaxations in a supervised setting to handle logical constraints. Du et al. (2024) introduce a method for iterative reasoning through energy diffusion, focusing on progressive refinement of solutions. More recently, Yang et al. (2023) proposed a recurrent Transformer architecture that reuses the same Transformer weights across multiple steps, iteratively refining inputs before projecting them to the final outputs. The common drawback for supervised approaches is the need for labels, which is not easy to generate for many large CSP problems. Additionally, for problems with more than one unique solution, label generation becomes non-trivial.\nConstraint solving without labels. A common recipe for Reinforcement Learning (RL) in constraint solving is to express the problem with a graph which is then processed using Graph Neural Networks (GNN). The GNN's weights are updated using RL based on a reward function expressing an objective function and/or constraint satisfaction (Dai et al., 2017; Chalumeau et al., 2021; Li et al., 2024b; Boisvert et al., 2024). For example, T\u00f6nshoff et al. (2023) converts a CSP instance into a tripartite variable-domain-constraint graph which is then solved using a GNN trained by RL. Wu et al. (2022) use a Transformer architecture to learn discrete transformation steps with RL for routing problems. However, RL approaches require significant computational resources for training, as well as an expertly designed reward signal for each problem.\nNon-RL based methods require addressing the non-differentiability of discrete constraints. Yang et al. (2022) use the straight-through estimator (Bengio et al., 2013) for logical constraints and Tang et al. (2024) explore a similar approach for mixed-integer non-linear programs. Toenshoff et al. (2021) devise a continuous relaxation for binary constraints (i.e., constraints involving two variables) which are used to guide a recurrent GNN to generate solutions; this approach is limited in applicability as many CSPs of interest have non-binary constraints. Bai et al. (2021) design continuous relaxations for some constraint classes in conjunction with a reconstruction loss to tackle a visual Sudoku problem; it is unclear how their architecture can be adapted to CSP solving in general.\nContinuous relaxation of discrete functions. Continuous relaxations have been used effectively to approximate discrete functions. For example, T-norm has been widely implemented as a continuous approximation for discrete binary logic operations (Petersen et al., 2022; Giannini et al., 2023; Gimelfarb et al., 2024). Petersen et al. (2021) introduced continuous relaxations for discrete algorithms, such as if-statements and while-loops. Similarly, Chen et al. (2019) proposed entropy-based relaxations to handle discrete constraints."}, {"title": "Recurrency for generalization.", "content": "The incorporation of recurrency has been shown to improve a model's generalization. Bansal et al. (2022) implement recurrent ResNet blocks to solve simple logic puzzles and show that increasing recurrent steps at test-time allows generalization to harder unseen tasks. Recurrency was introduced to the Transformer architecture by sharing weights across Transformer layers (Dehghani et al., 2019; Takase & Kiyono, 2023), yielding improved generalization capabilities on arithmetic and logic-based string manipulation tasks (McLeish et al., 2024; Fan et al., 2024). Our method differs from the existing work as recurrency is only introduced during test-time deployment."}, {"title": "3. ConsFormer: a Single-Step Self-Supervised Transformer", "content": "We introduce ConsFormer, a single-step Transformer trained with self-supervision. Given an assignment of values to variables (hereafter referred to as variable assignment), ConsFormer attempts to generate a refined variable assignment that is closer to satisfying the constraints of the input CSP. An overview of our model is shown in Figure 2.\nSection 3.1 presents a Transformer-compatible representation of variable assignments. Section 3.2 details the Transformer design and how it generates an updated assignment. Section 3.3 focuses on the self-supervised training process. Finally, Section 3.4 discusses how the model, trained for single-step solution refinement, can be deployed iteratively at test time to solve CSPs."}, {"title": "3.1. Input Representation", "content": "The input to the model includes the current variable assignment (which may be infeasible), variable indices, and a binary relational constraint graph indicating the participation of a variable in a constraint. We adapt the Transformer architecture to process a CSP instance by encoding these elements as follows.\nVariable assignments as tokens. Let X = {X1,X2,..., Xn} be the set of variables in a CSP, each of which has a finite domain Di. A variable assignment xi = \u03c5, \u03c5 \u2208 Di, is treated as a token. A learnable embedding e(v) is assigned to each unique value v \u2208 U1 Di. The input variable assignment, represented as X = {x1 = V1, X2 = U2, ..., xn = Un}, forms the input token set to the Transformer. Thus, the input embedding set is given by\n$$E = {e(v1), e(v2),...,e(vn)}.$$\nIn this paper, we focus on problems where all variables share the same domain D."}, {"title": "Representing variable indices with Absolute Positional Encoding.", "content": "Transformers use Absolute Positional Encoding (APE) to represent the position of tokens in a sequence. For CSPs, we use APE to encode the indices of variables. If the indices of a variable x\u2081 are multi-dimensional, we concatenate the positional encodings for each dimension. Specifically, let Xi1,2,...,ik denote a variable with k-dimensional indices (i1, 12, ...,ik). The APE for this variable is computed as:\n$$APE(Xi1,i2,...,ik) = Concat(PE(i1), PE(i2), . . ., PE(ik)),$$\nwhere PE(ik) is the positional encoding for dimension k. For example, in Sudoku, a variable x12 would have an APE formed by concatenating the encodings for row 1 and column 2. This approach is inspired by the APE design in Vision Transformers (Carion et al., 2020; Li et al., 2024a)."}, {"title": "Constraint relations as Relative Positional Encoding.", "content": "A Relative Positional Encoding (RPE) is typically used by Transformers to capture the positional relationship between tokens independently of their absolute positions in a sequence. For CSPs, we use RPE to encode the constraint relationships between variables. Specifically, we represent the CSP constraints as a binary constraint graph G = (V, E), where V = {1, 2, . . ., n} corresponds to the variables and E contains edges between pairs of variables that participate together in at least one constraint of the CSP.\nThe RPE is incorporated into the attention mechanism by modifying the attention logits. Let Aij denote the attention logit between variables i and j. The modified logits are computed as:\n$$Aij = Aij + RPE(i, j),$$\nwhere\n$$RPE(i, j) = c. I[(i, j) \u2209 E],$$\nand c\u2264 0 is either a constant hyperparameter or a learned parameter. Setting c to -\u221e effectively masks the attention between variables that do not have any constraints in common. The inclusion of the constraint graph via the RPE helps the model identify variable pairs that have a strong effect on each other's assignments."}, {"title": "3.2. A Single-Step Transformer Architecture", "content": "Our model takes the inputs described in the previous section and outputs a new variable assignment. Below, we outline the key components of the Transformer architecture.\nVariable subset selection. Inspired by the local search principle, we posit that small modifications to a variable assignment are preferable as it is easier to assess their impact on constraint satisfaction. Our model essentially performs a stochastic local search by randomly selecting a subset SCX of the variables to update. We do this by flipping a biased coin with probability of selection p for each variable, where p is a hyperparameter. A special learned embedding es is added to the variables in S. The Transformer's output for the variables in S is used to update the assignment; variables not in S take on the same values as in the input variable assignment. The input to the first Transformer block for a variable x\u2081 is given by:\n$$h^{(0)}_{i} = \u03b1\u00b7 e(vi) + \u03b2\u00b7 APE(xi) + \u03b3e_{s} \u00b7 I[xi \u2208 S],$$\nwhere e(vi) is the token embedding of variable xi's current value vi as described in Equation (1), and APE(xi) is its positional encoding as computed in Equation (2). \u03b1, \u03b2,\u03b3 are learnable scalars that allow the model to balance the contributions of each encoding, inspired by Li et al. (2024a). The set of embeddings for all variables forms the input set H(0) = {h(0), h\u00ba), ..., h}.\nWe note that this allows for easy handling of problems where certain variables have fixed values, such as in Sudoku. We simply bypass the variable subset selection step for the fixed variables, ensuring they are never updated by ConsFormer.\nSelf-attention. ConsFormer employs a self-attention mechanism to compute updated representations of variables based on other variables. For each variable token hi \u2208 Rh\u00d71 at layer l, the self-attention mechanism proceeds as follows:\n1. Each input token is projected to query, key, and value vectors:\n$$qi = W^{(l)}_{Q} h^{(l)}_{i}, k_{i} = W^{(l)}_{K}h^{(l)}_{i}, vi = W^{(l)}_{V}h^{(l)}_{i},$$\nwhere WQ \u2208 Rdxh, WK \u2208 Rdxh, and WV \u2208 Rdxh are learnable weight matrices.\n2. The relative positional encoding RPE(i, j) as described in Equation (3) is added to the attention logits Aij:\n$$A_{ij} = \\frac{q_i^T k_j}{\\sqrt{d}} + RPE(i, j).$$\n3. The attention weights are computed using a softmax:\n$$\\alpha_{ij} = \\frac{exp(A_{ij})}{\\Sigma_{k \\in S} exp(A_{ik})}$$\n4. The output representation for token i is computed as:\n$$z_i = \\Sigma_{j \\in S} \\alpha_{ij}V_{j}.$$\nFeedforward network and layer stacking. The output of the self-attention mechanism z\u00bf is passed through a position-wise feedforward network (FFN):\n$$h_i^{(l+1)} = FFN(z_i) = W_2(GeLU(W_1z_i + b_1)) + b_2,$$$\nwhere W1, W2, b1, and b2 are learnable parameters. The Transformer consists of multiple such layers.\nOutput: one-hot variable assignments. At the final layer, the Transformer outputs a one-hot vector over the domain Di of each variable in the subset S, representing its new assignment. Specifically, for variable xi, the output is:\n$$\\hat{y}_{i} = GumbelSoftmax (W_{out}h_i^{(L)} + b_{out} ),$$\nwhere |\u0177i = |Di, Wout and bout are learnable, and L is the number of Transformer layers. The Gumbel-Softmax (Jang et al., 2017) operator serves as a differentiable proxy to selecting the highest-output domain value. The predicted assignment for xi is then:\n$$v_i = arg \\max \\hat{y}_i, \\forall i \\in S.$$"}, {"title": "3.3. Self-supervised Loss Function", "content": "How should the Transformer learn to refine an input variable assignment into a better one? In the CSP context, the loss function must reflect the level of constraint satisfaction achieved by the predicted assignment. As argued earlier, one could use a supervised approach in which a feasible solution is first computed for each training CSP and a loss function measuring the variable-wise mismatch between the prediction and the solution is used. However, this approach hinges on solving many NP-Complete CSPs, a substantial overhead for large and complex problems. Additionally, there may be multiple feasible solutions, making supervision by a single solution somewhat arbitrary. Alternatively, our Transformer could be trained by RL, with the reward function reflecting the level of constraint satisfaction. We argue that this is unnecessarily complicated. An input CSP instance is fully observable as is the amount of violation of a constraint for any given variable assignment. Treating this violation signal as part of a reward function given by a black-box \"environment\" is thus overkill. Should we be able to derive differentiable approximations to the constraints, their violations could be used directly in a loss function, enabling end-to-end differentiable training.\nWith these design principles in mind, we train our Transformer using self-supervision. As our loss function, we use a linear combination of approximations to the amount of constraint violations by the predicted variable assignment to guide the model towards a satisficing predicted assignment.\nHowever, many constraints in CSP are discrete and not differentiable. To address this, we introduce simple continuous penalties that approximate discrete constraints, which are then used to compute the loss for guiding the model. Let P = {P1,P2,...,pm} be the set of continuous penalties approximating constraints C = {C1, C2, ..., Cm} such that\n$$pi(Xi) = 0 \\Leftrightarrow ci(Xi) = True,$$\nimplying that X* is a feasible solution for the CSP when\n$$pi(X) = 0 \\forall pi \\in P.$$\nThe loss for ConsFormer for a single CSP training instance is therefore\n$$L = \\Sigma \\lambda_i f(p_i (Xi)) \\forall p_i \\in P,$$\nwhere hyperparameter \u5165\u2081 is the weight assigned to pi, and f is an optional operation to transform the penalty for better learning. In practice, we implemented the common quadratic penalty, f(x) = x\u00b2. The discrete constraints and their relaxed continuous counterparts we implemented for our experiments are shown in Table 1, and numerical examples of valid and invalid assignments for each constraint can be found in Appendix A."}, {"title": "3.4. Iterative Test-Time Deployment", "content": "Another issue with RL is its multi-step nature which requires exploring an extremely large space of iterative solution refinement sequences. We show that learning a single-step solution refiner with self-supervision suffices as the model can be be deployed iteratively at test time. More specifically, our method refines an initial solution by repeatedly feeding its output variable assignment back as input to the next iteration as visualized in Figure 2.\nIn this sense, ConsFormer can be viewed as performing a single step of neural local search to improve the candidate solution. Our experiments focus on basic iterative solution refinement in one continuous sequence, without additional augmentations. However, this capability can be combined with techniques such as backtracking and random restarts (Rossi et al., 2006) to create a neuro-symbolic solver. Another possible extension is to incorporate ConsFormer as an evolutionary algorithm (Holland, 1992) utilizing the Transformer's parallel processing ability to update a pool of candidate solutions all at once. We leave these explorations as future work."}, {"title": "4. Experimental Results", "content": "Sudoku is a well-known CSP problem that involves filling a 9 \u00d7 9 grid with digits from 1 to 9 such that each row, column, and 3 \u00d7 3 sub-grid contain each digit exactly once. A single Sudoku instance consists of a partially filled board and a unique assignment to the unfilled cells that satisfies the constraints. A Sudoku instance's difficulty is determined by the initial board: fewer initially filled cells in the board involve a larger space of possible assignments to the unfilled cells, with the hardest Sudoku puzzles having only 17 of the 81 numbers provided (McGuire et al., 2014). We use the ALLDIFFERENTm=n(X1,...,xn) constraint from Table 1 to formulate the problem and its corresponding continuous penalty as the loss function to guide the model learning. The Graph Coloring is the problem of finding an assignment of colors to vertices in a graph such that no two neighboring nodes share the same color. The problem is defined by the graph's structure and the number of available colors k. We generate two sets of graph instances for k = 5 and k = 10 following a similar procedure as (T\u00f6nshoff et al., 2023) (See Appendix C for details). Training graphs have 50 vertices for k = 5 and 100 vertices for k = 10 whereas OOD graphs have 100 for k = 5 and 200 for k = 10. We use inequality constraints of the form xi \u2260 xj for an edge between nodes i and j and their penalty in Table 1 to represent the coloring constraints.\nNurse Scheduling is an operations research problem of assigning nurses to shifts. A problem instance has a specified number of days n, number of shifts per day s, number of nurses per shift ns, and a total number of nurses. The variables Xd,n,ns are the shift slots indexed by the day, shift, and nurse and their domains are the indices of the nurses. A feasible solution ensures that no nurse is assigned to more than one shift per day and avoids assigning the same nurse to both the last shift of one day and the first shift of the following day. We use both the inequality xi \u2260 xj and the ALLDIFFERENTm>n(x1,...,xn) constraints for this problem; see Appendix B for the full formulation."}, {"title": "4.2. Training", "content": "For each of the problems, we train the model with randomly initialized variable assignments guided by the loss function defined in Equation (5) and the corresponding pi associated with the constraints used to define the CSP. The training set contains 9K instances for all problems. The training details and hyperparameters for the best performing model for each problem is detailed in Appendix D."}, {"title": "4.3. Results", "content": "Table 2 reports the performance of ConsFormer and various neural methods on the Sudoku task. ConsFormer solves 100% of the Sudoku tasks from the in-distribution test dataset. On the harder out-of-distribution dataset, ConsFormer significantly outperforms all learned methods, demonstrating superior generalization capabilities. ConsFormer achieves instance solve rates of 65.88% and 77.74% with 2k and 10k iterations, respectively.\nThis highlights the iterative reasoning nature of our approach. Harder instances can be solved with additional reasoning steps, whereas other solvers with fixed reasoning steps struggle. Notably, Yang et al. (2023)'s approach also employs iterative reasoning with Transformers, but their performance degraded with more test-time iterations while ConsFormer's continued to improve. This could be due to Yang et al. (2023)'s approach being trained for 32 iterations, while ConsFormer was trained for a single iteration, allowing it to generalize better when applied iteratively.\nGraph Coloring. Table 3 summarizes the performance of OR-Tools, ANYCSP (T\u00f6nshoff et al., 2023), and ConsFormer on Graph Coloring instances. OR-Tools is a state-of-the-art traditional solver for constraint programming applications and serves as a strong baseline (Perron & Didier), achieving 100% on Sudoku instances. We ran test instances sequentially through all models with a 10-second timeout, though ConsFormer can process instances significantly faster if processed in batches due to the Transformer architecture. We note that the harder dataset is not out of distribution for OR-Tools, since it solves each task individually and is not a learning-based solver.\nConsFormer demonstrates competitive performance on in-distribution Graph Coloring with k = 5, solving 81% of the test instances approaching the 83.08% achieved by OR-Tools. While it lags behind the state-of-the-art solver with 47.33% on the harder OOD test set, ConsFormer outperforms ANYCSP on both distributions, which again shows our method's high generalization ability.\nOn the more challenging Graph Coloring with k = 10 datasets, ConsFormer surpasses OR-Tools in performance, showcasing the advantage of learned heuristic approaches: it may not surpass state-of-the-art solvers on smaller instances, but it excels in complex cases under short time limits crucial for real-world applications. Surprisingly, ANYCSP failed to solve any instances within 10 seconds for both datasets, underscoring the scalability limitations of its graph-based representation and the difficulty of training with RL.\nNurse Scheduling. For the Nurse Scheduling problem, ConsFormer matches OR-Tools in solving all tasks across both in-distribution and out-of-distribution instances within the 10-second timeout. This high accuracy is expected, given the large number of feasible solutions for each instance, as detailed in Appendix C. However, solving this problem neurally is non-trivial, as the model must learn to balance multiple constraints within a single step of solution refinement. ANYCSP was not evaluated on this dataset due to their difficulty dealing with the ALLDIFFERENT constraint. This result highlights ConsFormer's potential to generalize to more complex problems with diverse constraint structures."}, {"title": "4.4. Ablations", "content": "Figure 3 examines the impact of varying probability of selection p on the performance of the model. The horizontal axis refers to the number of iterations at test time while the vertical axis represents the percentage of in-distribution test instances solved. We investigate the behavior of the model under different probabilities p\u2208 {1.0,0.9, 0.7, 0.5, 0.3, 0.1}, where p determines the probability of selecting each variable for updates during a single iteration as detailed in Section 3.2. A larger p results in more variables being selected to be updated.\nWhen p = 1.0 (blue line), all variables are selected for updates during every iteration. This approach leads to rapid improvement in the early stages, as the model converges quickly to local optima. This is clearly observed in Graph Coloring, where the p = 1.0 model rapidly solved 65% of instances. Performance plateaus after the initial surge whereas the stochastic models surpass it in accuracy after 50 iterations. The difference in model performance is even more drastic for Sudoku, with the p = 1.0 model reaching 20% instances solved early and converging, while the p = 0.9, p = 0.7, and p = 0.5 models surpass it and reach near 100% within 50 iterations.\nThese findings highlight the importance of incorporating stochasticity into the update process for combinatorial optimization tasks. While deterministic updates provide faster initial convergence, they are prone to premature stagnation. Stochastic updates, by selectively updating a subset of variables, improve generalization and allow the model to achieve higher final performance.\nEffect of variable information as positional encodings. Table 4 and 5 show the performance of ConsFormer with different positional encodings. The value displayed indicates the percentage of in-distribution test instances solved by the model running 1k iterations\nAcross both Graph Coloring and Sudoku, we observe that the inclusion of relative variable relations with RPE provides a significant performance boost. This is especially true in the Graph Coloring problem, which heavily relies on the constraint graph, since the vertices have no inherent ordering to them, and therefore the indices have little meaning for the model to learn from.\nIn Sudoku however, we see that the Transformer is able to achieve strong performance using only 2D APE, without leveraging explicit constraint graph information. This indicates that in highly structured problems like Sudoku, the positional indices of variables alone contain sufficient information for solving the instances. We also observe that 2D APE outperforms the standard 1D APE typically used in Transformers. These results suggests the importance of supporting both forms of positional encodings, as different properties of different problems requires distinct spatial or relational information.\nWe also note that when RPE is implemented as masked RPE, attention scores for each variable are restricted to its connected variables, closely resembling the behavior of a graph neural network with attention."}, {"title": "5. Conclusion", "content": "We introduced ConsFormer, a self-supervised Transformer for iteratively solving Constraint Satisfaction Problems. We showed that our method, trained to perform a single step of solution improvement, is able to generalize to harder out-of-distribution instances at test time, outperforming supervised and reinforcement learning approaches. Future work includes exploring neural-symbolic approaches incorporating ConsFormer such as those discussed in Section 3.4, other performance boosting techniques such as self-improvement techniques to augment the training data (Lee et al., 2025), as well as extending ConsFormer to more problems and more constraints, with the goal of devising a general continuous approximation for constraints."}, {"title": "B. Constraint Programming formulations", "content": "We define the Sudoku problem as a constraint satisfaction problem (CSP) with the following components:\nVariables: Let Xij denote the variable representing the value assigned to cell (i, j), where i, j \u2208 {1, 2, . . ., 9}.\nDomains: Each variable Xi,j takes values from the discrete domain:\nXi,j \u2208 {1,2,...,9}.\nConstraints: The solution must satisfy the following AllDifferent constraints:\n\u2022 Each row must contain unique values:\n$$ALLDIFFERENT_{m=n}(X_{i,1}, X_{i,2}, ..., X_{i,9}), \\forall i \\in {1, ..., 9}.$$\n\u2022 Each column must contain unique values:\n$$ALLDIFFERENT_{m=n}(X_{1,j}, X_{2,j}, ..., X_{9,j}), \\forall j \\in {1,...,9}.$$\n\u2022 Each 3 \u00d7 3 subgrid must contain unique values. Let (r, c) index the subgrid with r, c \u2208 {0, 1, 2}, then:\n$$ALLDIFFERENT_{m=n}(\nX_{3r+1,3c+1}, X_{3r+1,3c+2}, X_{3r+1,3c+3},\\\nX_{3r+2,3c+1}, X_{3r+2,3c+2}, X_{3r+2,3c+3},\\\nX_{3r+3,3c+1}, X_{3r+3,3c+2}, X_{3r+3,3c+3}\n),\\ \\forall r, c \\in {0,1,2}.$$"}, {"title": "B.2. Graph Coloring", "content": "Given a graph G = (V, E), we define the graph coloring problem as a constraint satisfaction problem (CSP) with the following components:\nVariables: Let X be a variable representing the color assigned to vertex v \u2208 V.\nDomains: Each variable X takes values from a set of k available colors:\n$$X_{v} \\in {1,2,...,k},\n\\forall v \\in V.$$\nConstraints: The solution must satisfy that any two adjacent vertices must be assigned different colors:\n$$X_{u} \\neq X_{v}, \\forall (u, v) \\in E.$$"}, {"title": "B.3. Nurse Rostering", "content": "We define the nurse rostering problem as a constraint satisfaction problem (CSP) with the following components:\nVariables: Let Xd,s,ns be a variable representing the nurse assigned to the ns-th slot of shift s on day d, where:\n$$X_{d,s,ns} \\in {1,2,...,N}, \\forall d\\in {1,..., n}, \\forall s \\in {1,...,S}, \\forall ns \\in {1, ...,NS}.$$\nConstraints: A feasible schedule must satisfy the following constraints:\n\u2022 No nurse can be assigned to more than one shift per day:\n$$ALLDIFFERENT_{m>n}(X_{d,1,1}, X_{d,1,2},\u06f0\u06f0\u06f0, X_{d,1,NS}, X_{d,2,1}, X_{d,2,2}, \u06f0 \u06f0 \u06f0 , X_{d,2,NS}, \u06f0 \u06f0 \u06f0 , X_{d,S,1}, X_{d,S,2},\u06f0\u06f0\u06f0, x_{d,S,NS})\n\\forall d \\in {1, ..., n}.$$\n\u2022 A nurse cannot be assigned both the last shift of a given day and the first shift of the following day:\n$$X_{d,S,ns} \\neq X_{d+1,1,ns'},\\\n\\forall d \\in {1, . . ., n \u2212 1}, \\forall ns, ns' \\in {1, ..., NS}.$$"}, {"title": "C. Dataset Details", "content": "We generate Nurse Rostering instances with varying difficulties. Each problem instance is defined by the number of days n, number of shifts per day s, number of nurses required per shift ns, and the total number of available nurses N."}, {"title": "C.1. Graph Coloring", "content": "Following (T\u00f6nshoff et al., 2023), we generate Graph Coloring instances with the following 3 distributions:\n\u2022 Erd\u0151s-R\u00e9nyi graphs with edge probability p ~ U[0.1, 0.3]\n\u2022 Barab\u00e1si-Albert graphs with parameter m ~ U[2, 10]\n\u2022 Random geometric graphs with vertices distributed uniformly at random in a 2-dimensional 1 \u00d7 1 square and edge threshold radius drawn uniformly from r ~ U[0.15, 0.3].\nThe 5-coloring instances were drawn uniformly for all 3 distributions, with vertices count 50 for training and in-distribution testing data, vertices count 100 for out of distribution testing. The 10-coloring instances were drawn uniforming from Erd\u0151s-R\u00e9nyi graphs and Random geometric graphs, with vertices count 100 for training and in-distribution testing data, and 200 for out of distribution testing.\nFor each graph G generated a linear time greedy coloring heuristic as implemented by NetworkX (Hagberg et al., 2008) to color the graph without conflict. If the greedy heuristic required k' colors for G, then we pose the problem of coloring G with k colors as the training CSP instance, where k is chosen as:\nk = max{3, min{10, k\u2032 \u2013 1}}\nWe generate instances until a fixed number of instances for a specific k is reached. 9000 for training sets, 1200 for test sets."}, {"title": "C.2. Nurse Scheduling", "content": "\u2022 in-distribution instances were generated with n = 10 days, s = 3 shifts per day, ns = 3 nurses per shift, and a total of N = 10 nurses.\n\u2022 Out-of-distribution instances were generated with n = 10, s = 3, ns = 3, and N = 10.\nThe in-distribution instances consisted of 9000 training instances and 1000 test instances. Out-of-distribution instances also had 1000 samples.\nTo initialize different instances, we assign one random shift to every nurse as an initial assignment. This ensures that each instance starts with a minimally constrained but valid configuration.\nWe note that these instances are relatively easy to solve due to the large number of feasible solutions available. The constraints in the problem formulation do not drastically limit the space ofValid Assignments. The purpose of this dataset is to examine ConsFormer's ability to solve instances with a combination of different constraints."}]}