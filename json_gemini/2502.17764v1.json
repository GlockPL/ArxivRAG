{"title": "DeepSeek vs. ChatGPT: A Comparative Study for Scientific Computing and Scientific Machine Learning Tasks", "authors": ["Qile Jiang", "Zhiwei Gao", "George Em Karniadakis"], "abstract": "Large Language Models (LLMs) have emerged as powerful tools for tackling a wide range of problems, including those in scientific computing, particularly in solving partial differential equations (PDEs). However, different models exhibit distinct strengths and preferences, resulting in varying levels of performance. In this paper, we compare the capabilities of the most advanced LLMs-ChatGPT and DeepSeek along with their reasoning-optimized versions in addressing computational challenges. Specifically, we evaluate their proficiency in solving traditional numerical problems in scientific computing as well as leveraging scientific machine learning techniques for PDE-based problems. We designed all our experiments so that a non-trivial decision is required, e.g. defining the proper space of input functions for neural operator learning. Our findings reveal that the latest model, ChatGPT 03-mini-high, usually delivers the most accurate results while also responding significantly faster than its reasoning counterpart, DeepSeek R1. This enhanced speed and accuracy make ChatGPT 03-mini-high a more practical and efficient choice for diverse computational tasks at this juncture.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs), such as ChatGPT [1, 2, 3] and, most recently, DeepSeek [4] are general-purpose artificial intelligence (AI) chatbots based on the transformer architecture [5], trained on large amounts of data from the Internet, and have learned to engage in conversations based on user requests. Among their many applications, there has been growing interest in leveraging LLMs for scientific research, particularly in coding, mathematics, and problem-solving. This interest has driven rapid recent advancements in LLM development. For example, on January 31, 2025, OpenAI released OpenAI 03-mini [2], the latest reasoning model supposed to deliver particular strength in science, math, and coding. This came only a few days after DeepSeek unveiled its own reasoning model DeepSeek-R1 [6] that also specializes in math, coding, and reasoning tasks. These models build on prior advancements such as ChatGPT-40 [1] and DeepSeek V3 [4], marking a new phase of competition among LLM developers seeking to optimize performance in scientific fields.\nLLMs have already demonstrated potential in various domains of scientific research, not only in synthesizing information [7, 8] and as a coding assistant [9, 10, 11], but also being utilized to solve complex domain-specific problems, including material sciences [12, 13, 14], genetics [15, 16], medical imaging [17, 18, 19], and computational fluid dynamics [20, 21, 22]. The integration of LLMs into scientific workflows has expanded their role from mere information retrieval tools to automated agents capable of performing reasoning-based tasks to aid and complement human researchers. However, despite these promising applications, LLMs can still exhibit fundamental limitations that raise concerns about their reliability in scientific research and computing [23, 24, 25, 26, 27]. In particular, when tasked to solve complex scientific problems, they may produce hallucinated reasoning [28], low level of mathematical cognition [29], and even self-contradiction [30]. Unlike conversational AI tasks, where fluency and coherence are primary evaluation criteria, scientific and engineering problems demand precision, logical consistency, and rigorous reasoning. The limitations of LLMs have thus made them unsuitable for high-stakes applications."}, {"title": "Experiments", "content": "In this section, we evaluate DeepSeek and OpenAI LLMs by testing them on a range of challenging benchmark problems in numerical algorithms and scientific machine learning. The models under consideration are:\n1. DeepSeek V3 [4]: A general-purpose model developed by DeepSeek, trained on a broad dataset covering multiple domains. While it is not explicitly specialized for scientific tasks, its training includes extensive exposure to mathematical and engineering-related data.\n2. DeepSeek R1 [6]: A model developed by DeepSeek specifically designed for reasoning tasks, including math- ematics and coding. Compared to DeepSeek V3, R1 is fine-tuned with additional reinforcement learning strategies to improve logical consistency and structured problem-solving. It is positioned as a direct competi- tor to OpenAI's reasoning models.\n3. ChatGPT 40 [1]: OpenAI's flagship model designed for general reasoning and multimodal capabilities, in- cluding text, code, and vision processing. It employs an optimized transformer architecture and focuses on improving efficiency and reducing latency while maintaining performance in coding, mathematics, and logical inference.\n4. ChatGPT 03-mini-high [2]: ChatGPT 03-mini-high is a variant of OpenAI's 03-mini model, optimized for tasks requiring intensive reasoning in coding, mathematics, and science. Despite its smaller size, 03-mini-high is supposed to deliver performance comparable to larger models by employing advanced reasoning techniques.\nTo ensure fairness, all chat memory and user-personalized settings are disabled. This prevents models from benefiting from prior context and ensures that each query is treated independently. Additionally, since LLM response time can be significantly affected by server latency rather than the LLM's evaluation speed, we do not compare or report response times. Instead, our evaluation focuses on the quality of the generated solutions and, for reasoning models, the reasoning process and decision-making. To differentiate the model performances, the test problems selected are tricky but also leave enough flexibility for the LLMs to make their own decisions in what method and parameters to use in their solutions. Most problems are advanced, typically at the PhD level, and demand a deep understanding of computational mathematics and familiarity with recent research advancements. The coding languages tested are chosen to be TensorFlow [40] and Jax [41] in Python, which are frameworks frequently used in the scientific machine learning community.\nThis section will be divided into two parts. In the first, we conduct experiments to test the models' knowledge in implementing traditional numerical methods in applied mathematics, particularly in solving ordinary and partial differential equations (PDEs), such as finite difference and finite element methods. In the second part, we test the models on scientific machine learning tasks, including learning digits from the MNIST dataset and implementing PINNs and DeepONets for different problems."}, {"title": "Traditional numerical methods", "content": "We present the four LLMs under consideration with a variety of problems in numerical methods and solving differential equations. We compare the performance of their generated solutions and discuss the decisions the LLMs made."}, {"title": "Numerical solution to stiff ODES", "content": "The Robertson Problem Equation 1 is a famous example for a stiff system of ODEs that describes the chemical reaction of H. H. Robertson [42].\n$\\begin{aligned}\n\\frac{dx}{dt} &= -0.04x + 10^4yz, \\\\\n\\frac{dy}{dt} &= 0.04x - 10^4yz \u2013 3 \\times 10^7y^2, \\\\\n\\frac{dz}{dt} &= 3 x 10^7y^2.\n\\end{aligned}$  (1)\nThe problem models the concentrations of three species x(t), y(t), z(t) over time with initial conditions x =\n1, y = z = 0. The reactions have very different time scales, particularly for y(t). Solving such stiff ODEs with explicit integration methods leads to unstable behavior unless an extremely small step size is used. Implicit methods such as implicit Runge-Kutta and backward differentiation formula (BDF) are usually more suited to solving these problems.\nTo assess if the LLMs can implement an appropriate numerical scheme for solving this very stiff system, we ask them with the following prompt:\nImplement an appropriate numerical method from scratch to solve the following system of ODES in Python:\n$\\frac{dx}{dt} = -0.04x + 10^4yz, \\frac{dy}{dt} = 0.04x - 10^4yz \u2013 3 \\times 10^7y^2, \\frac{dz}{dt} = 3 x 10^7y^2$.\non a time interval of t\u2208 [0,500] with the initial conditions x = 1, y = z = 0.\nThe LLMs' responses are summarized in Table 1, and the computed solutions are plotted in Figure 1. For reference, the ODE system is also solved in scipy using an implicit Runge-Kutta method of Radau IIA family of order 5 (Radau) [43]. The RK4 schemes implemented by DeepSeek V3 and ChatGPT 40 failed to solve the problem and yielded exponentially growing solutions, while the backward Euler schemes implemented by the reasoning models DeepSeek R1 and ChatGPT 03-mini-high both gave the correct solution. Additionally, ChatGPT 03-mini- high implements an adaptive time stepping that compares one full step of size \u0394t with two half-steps (each of size\n\u0394t/2) to estimate the local error. If the error is below a prescribed tolerance, the step is accepted; otherwise, it is rejected and a new (smaller) time step is computed.\nIt is worth noting that both reasoning models, DeepSeek R1 and ChatGPT 03-mini-high, recognized the stiffness of the ODE system and chose an implicit method, while both non-reasoning models failed. During the reasoning,\nboth DeepSeek R1 and ChatGPT 03-mini-high also gave explanations for their choice of implicit methods over explicit methods. DeepSeek R1 reported that\n\"Given the time interval is up to 500, and the equations have terms with coefficients like\n1e4 and 3e7, which are quite large, this might be a stiff system. If the system is stiff, using\nan implicit method like backward Euler or a solver designed for stiff systems (like Rosenbrock\nmethods) would be better.\"\nSimilarly, ChatGPT 03-mini-high reported that\n\"Since it's stiff, explicit methods like Euler or RK4 won't work well. I think we'll need\nsomething like an implicit method, maybe implicit Euler, or a modified explicit method like an\nadaptive Runge-Kutta.\"\nThis experiment demonstrates the superior performance of the reasoning LLMs over non-reasoning ones, as reasoning models are able to analyze the problem first before choosing an appropriate method to implement."}, {"title": "Finite difference for Poisson equation", "content": "In this section, we test the ability of ChatGPT and DeepSeek models to implement finite difference methods for partial differential equations. In this experiment, we consider the following Poisson equation [44]\n$\\begin{cases}\n-\u0394u = f, x \u2208 \u03a9 \\\\\nn = 0,\n\\end{cases}$\nand set \u03a9 = [-1,1]2/[0, 1]2 to be the L-shaped domain. The right hand side is set to be f(x, y) = 1. The following question was asked to all four LLMs:\nUse finite difference method to solve the 2D Poisson equation in L-shaped domain [-1,1]2/[0,1]2 with zero boundary condition and right hand side f(x,y) = 1, where the coding language is Python.\nTo ensure fairness across different models, the question was asked in a new chat for each. Except for ChatGPT, all three other models provided error-free, executable codes. Notably, DeepSeek employed the most advanced iterative methods to solve the problem, whereas the others relied on conventional finite difference methods for discretization and solving the linear system.\nWe can clearly see that DeepSeek-R1 not only mistakes the sign of the solution but gives wrong scales, leading to worse performance. However, other models only mistake the sign of the solution, which means that the coding ability of these models surpasses the mathematical ability. Furthermore, for the comparison between the two reasoning models, ChatGPT 03-mini-high responds much faster than DeepSeek R1, with less thinking time."}, {"title": "Finite element methods for Vibrating Beam equation", "content": "In this experiment, we consider the beam equation [45]:\n$EI \\frac{d^4u}{dx^4} = \u03c0^2x \\sin \u03c0\u03b1 \u2212 4\u03c0^3 \\cos \u03c0x, 0 \u2264 x \u2264 L,$\nwith corresponding non-homogeneous boundary conditions:\nu(0) = 0,  u''(0) = 2\u03c0,\nu(L) = 0, u'' (L) = \u22122\u03c0.\nHere, EI = 1N/m\u00b2 is the constant flexural rigidity. For simplicity, we set L 1. The true solution is obtained by solving the ODE and given as\nu(x) = x \\sin(\u03c0\u03c7).\nNow, we ask all four LLMs the same question:\nUsing finite element method from scratch to solve the beam equation:\n$\\begin{cases}\n\\frac{d^4u}{dx^4} = \u03c0^2x \\sin \u03c0\u03b1 \u2212 4\u03c0^3 \\cos \u03c0x, 0 \u2264 x \u2264 1, \\\\\nu(0) = 0, u\u2033(0) = 2\u03c0, \\\\\nu(1) = 0, u\u2033(1) = \u22122\u03c0.\n\\end{cases}$\nThe coding language is Python.\nOur results demonstrate that none of the four LLMs can correctly apply finite element methods to get the right solution. In detail, the predicted solutions obtained by these four models are demonstrated in Figure 5. Additional details can be found in Table 3.\nWe observe that all four LLMs use Hermite basis functions to approximate the solution. However, the non- reasoning models perform worse, showing significantly larger L2 errors. In contrast, consistent with results from other experiments, the reasoning models solve the problem more effectively, with DeepSeek R1 achieving the lowest L2 error."}, {"title": "Quadratures for integrals", "content": "Next, we evaluate the LLMs' ability to apply quadrature rules correctly for numerically computing integrals with singularities. Consider the following integral:\n$I = \\int_0^1 \\frac{e^{-x}}{x^{2/3}} dx.$\nThe question posed to all four models is\nUsing quadrature rules to calculate the integral $\\int_0^1 \\frac{e^{-x}}{x^{2/3}} dx$ with python from scratch.\nThe approaches of different models vary significantly. DeepSeek-V3 directly uses the scipy.integrate module to compute the integral, while the other three first apply a transformation to remove the singularity. Specifically, by setting x = t\u00b3, we can obtain\n$I = \\int_0^1 \\frac{e^{-t^3}}{(t^3)^{2/3}} 3t^2 dt = \\int_0^1 3e^{-t^3}t^{-2+2}dt = 3 \\int_0^1 e^{-t^3} dt.$\nAfter this transformation, the LLMs all chose Gaussian quadrature rules to approximate the integral. The additional details for the chosen methods and errors are summarized in Table 4.\nOverall, except DeepSeek-V3, all models achieve comparable performance. They are smart to make the transfor- mation first and then apply quadrature rules. It can still be seen that the reasoning model ChatGPT 03-mini-high achieves the most accurate results using more nodes than the others."}, {"title": "Scientific Machine Learning", "content": "In this section, we test the LLMs on a range of tasks in scientific machine learning, in both image recognition and physics-informed machine learning methods."}, {"title": "MNIST digits prediction", "content": "Many problems in science and engineering require analyzing image data and classification. The MNIST [46] dataset is chosen as a test problem because it is a well-established benchmark for evaluating image recognition models. All DeepSeek and ChatGPT models are asked with the following prompt:\nImplement a CNN in tensorflow to learn the MNIST dataset. Choose appropriate architecture and hyperparameters to aim for both high accuracy and computational efficiency.\nThe goal is to evaluate how the LLMs make decisions to balance the trade-off between achieving high accuracy and saving computational costs. The generated responses are summarized in Table 5. All tests were conducted on a Quadro RTX 6000 GPU.\nNote that the DeepSeek R1 model implements an early stopping criterion, which may stop the training of the model early according to changes in the validation loss to prevent overfitting, which was activated in the 10-th epoch. Additionally, both DeepSeek R1 and ChatGPT 40 implement dropout with a probability of 0.5. All models achieved comparable training time and high testing accuracy."}, {"title": "Physics-informed neural networks", "content": "In this section, we will test their performance by solving the above equation with physics-informed neural networks (PINNs) [38], a framework used to solve PDEs with the power of neural networks. The Poisson equation we want to solve here is\n\u2212\u2206u(x, y) = 1, (x, y) \u2208 [-1,1]2/[0, 1]2\nwith zero Dirichlet boundary conditions. Therefore, the question that we ask the four models is:\nUse PINNs to solve the 2D Poisson equation in L-shaped domain [-1,1]2/[0,1]2 with zero boundary condition and right hand side f(x,y) = 1, where the coding language is Jax.\nWe observe that only ChatGPT 03-mini-high gives the right result, which outperforms other models. Moreover, compared to non-reasoning models, DeepSeek-R1 can realize the boundary of the problem domain is L-shaped\nand thus generate corresponding boundary points. The non-reasoning model can not realize this and still train\nthe model in the original problem domain. These behaviors demonstrate the reasoning model can have better generalization abilities and better responses to user-specified requests. The detailed parameter settings are listed in Table 6. It is clear that the reasoning model can achieve much better accuracy compared to the non-reasoning model. Furthermore, as for the training time, ChatGPT 03-mini-high takes over 1000 seconds to train the model as it needs to generate samples every training epoch, but it achieves the best performance."}, {"title": "DeepONet for learning the antiderivative operator", "content": "The Deep Operator Network (DeepONet) [39] is a neural operator designed to learn mappings between function spaces using data, based on the universal approximation theorem for operators [47]. Given an input function u : x \u2192 u(x) defined on a domain D C R\", and an output function v : y \u2192 v(y) defined on a domain \u03a9CRm, the goal is to approximate the operator:\nG: \u0418 \u042d\u0438\u043d\u03bd\u03b5\u03bd.\nThe architecture of DeepONet consists of two components: a trunk network that takes the coordinates y \u2208 \u03a9; and a branch network that takes a discretized version of the input function u, sampled at m arbitrary sensor locations {x1,x2,...,xm}. The output of DeepONet is given as v(y) = \u2211i=1 bi(u)ti(y) + bo \u2248 G(u)(y), where bi and ti are the outputs of the branch and trunk networks, respectively, and bo is a trainable bias term.\nFor a first test of the LLMs' knowledge in operator learning, we consider a task for learning the general anti- derivative operator G(u) : u(x) \u2192 s(x) = \u222b u(t)dt on a domain of [0,1]. All four LLMs are asked with the following prompt:\nImplement a Deep Operator Network (DeepONet) in Tensorflow to learn the anti-derivative operator. Choose appropriate architecture and hyperparameters to aim for both high accuracy and low computational cost. Make sure that the model can generalize to a wide variety of functions.\nNote that the choice of the input function space is left deliberately ambiguous in the prompt. Therefore, the LLMs need to strategically sample from a function space, and generate the antiderivatives of these functions to use as the targets for training the DeepONet. The models' responses to the data generation task are very different:\n1. DeepSeek V3: Input functions: simply generated point-wise as uniformly random numbers in numpy. The functions are then numerically integrated using cumulative sums (cumsum) in numpy.\n2. DeepSeek R1: Data are randomly generated from the following 4 types:\n(a) Input function: A 6th-degree polynomial with uniformly random coefficients ranging from [-2,2]. An- tiderivative: calculated analytically.\n(b) Input function: u(x) = Asin(wx) + B cos(wx), where A, B are chosen randomly from [-2, 2], and w from [1,5]. Antiderivative: calculated analytically.\n(c) Input function: u(x) = Aexp(Bx), where A, B are chosen randomly from [-1,1]. Antiderivative: calculated analytically.\n(d) Input function: a mixture of 1, 2, and 3 given as u(x) = c1x2 + c2 sin(wx) + c3 exp(x), where ci are chosen randomly from [-1,1] and w from [1,5]. Antiderivative: calculated analytically.\n3. ChatGPT 40: Input functions: 5-th degree polynomial without constant term: u(x) = c\u2081x + \u00b7\u00b7\u00b7 5x5, where the coefficients c\u2081 are chosen randomly from [-1,1]. Antiderivative: calculated analytically.\n4. ChatGPT 03-mini-high: Input functions: Fourier series with 3 modes u(x) = \u22113-1 A\u2081 sin(2\u03c0\u03afx) + Bi cos(2\u03c0\u03afx) where Ai, Bi are chosen randomly from [-1,1]. Antiderivative: calculated numerically using cumulative trapezoidal rule with scipy.integrate.cumtrapz.\nThe model architectures are summarized in Table 7. Some bugs were fixed from the code generated by the LLMS:\n1. DeekSeek V3's code has errors due to unmatched tensor dimensions in the dot product between branch net and trunk net outputs, which was manually corrected.\n2. ChatGPT 4o's code incorrectly sets the trunk net input dimension to 100 (the number of evaluation points) instead of 1 (the dimension of the dependent variable). This mistake was also manually corrected.\nWe observe that the DeepSeek R1 model generates data with the greatest complexity and variety. In terms of model design, DeepSeek R1 again implements an early stopping mechanism, which was not activated in this training. Additionally, all models opt for only a few hundreds of epochs, which is usually not enough for the loss to fully converge.\nSince the models are trained on different datasets, we build a universal testing set to evaluate their perfor- mances. The testing set consists of functions generated by Gaussian Random Fields (GRF) with length scales 0.05, 0.1, 0.2, 0.5. An example of the data is shown in Figure 7. The results for each model are shown in Table 8. Functions generated with smaller length scales are more difficult to predict for most models. The DeepSeek R1 model excelled in generalizing to unseen functions, largely due to its training data complexity. The DeepSeek V3 model failed to make meaningful predictions."}, {"title": "DeepONet for learning the Caputo fractional derivative operator", "content": "For a more advanced test problem, we present the task of learning the Caputo fractional derivative operator with an arbitrary fractional order. The 1D Caputo fractional derivative operator G(u)(y, a) is defined as\nG(u)(y, a) : u(x) \u2192 s(y, a) = $\\frac{1}{\u0393(1 \u2212 \u03b1)} \\int_0^y (y \u2212 \u03c4)^{-\u03b1}u'(\u03c4)d\u03c4,$\ny \u2208 [0, 1], \u03b1 \u2208 (0,1)\nwhere a is an arbitrary fractional order, and u' denotes the first derivative of u.\nAll LLMs are asked with the following prompt:\nImplement a Deep Operator Network (DeepONet) in Tensorflow to learn the 1D Caputo fractional derivative operator G(u)(y,a), which is defined as\nG(u)(y, a) : u(x) \u2192 s(y,a) = $\\frac{1}{\u0393(1 \u2212 \u03b1)} \\int_0^y (y \u2212 \u03c4)^{-\u03b1}u'(\u03c4)d\u03c4,$ y \u2208 [0, 1], \u03b1\u2208 (0,1)\nwhere a is an arbitrary fractional order, and u' denotes the first derivative of u. Function u is sampled from a Gaussian Random Field with a length scale of 0.2.\nThe input function space is specified in this test, but the LLMs are responsible for generating their own training and testing datasets. For data generation, the input function must be numerically differentiated and integrated. The methods used by each LLM for differentiation and integration are summarized in Table 9. Note that while most models implemented valid numerical schemes, ChatGPT 4o made a critical mistake in the integration step. Specifically, instead of computing the integral over the correct domain [0, y], it mistakenly computed it over [0, 1]. This led to a division by zero error as the term (y \u2212 \u315c)\u00af\u00ba becomes singular when y = \u03c4. This bug was manually corrected and trapezoidal rule was adopted for integration.\nWe are specifically interested in seeing if the LLMs know how to correctly encode the fractional order a into the DeepONet, as the fractional order a does not usually appear in other DeepONet applications and the LLMS' knowledge in this particular task might be limited. In the original DeepONet paper [39], the order a along with the evaluation coordinates y are put together into the trunk network. Notably, all four LLMs correctly placed a into the trunk but they repeatedly made the exact same mistake in formulating the input tensor. Specifically, they incorrectly paired each y with a different a and structured the input as follows:\nTrunk net input =$\\begin{bmatrix}\nY1 & \u03b11 \\\\\nY2 & \u03b12 \\\\\n: & : \\\\\nYN & \u03b1\u03bd\n\\end{bmatrix}$\nHowever, for each fractional derivative order a, there should be multiple evaluation points {Y1, Y2,..., Yn} at which the output function is computed. Using distinct pairs of (yi, ai) reduces to evaluating the fractional derivative at a single point yi per ai and therefore prevents the DeepONet from learning a complete representation of the derivative across the domain on [0,1]. As a result, models trained solely on LLM-generated implementation, without human intervention, yield more than 150% 12 relative error. Since comparison under such an incorrect formulation does not provide meaningful insights, we manually corrected the code to ensure that the spatial input to the trunk network,\ny, is evaluated at 100 distinct points. For each function sample, the fractional order a is randomly chosen from the\ninterval [0.1, 0.9].\nAdditionally, DeepSeek V3 made the mistake of training the DeepONet for only a single fixed fractional order a = 0.5, even though the user request has stated clearly that a \u2208 (0,1) is an arbitrary fractional order. We train\nand test the generated models on GRF-generated functions with length scale 0.2 and random orders a \u2208 (0,1).\nThe results, along with model architecture and hyperparameters, are reported in Table 10.\nNote that the testing error for DeepSeek V3 is very high, as it was trained on a single fractional order and thus failed to generalize. Additionally, similar to our previous experiment results, all models opted for training for no more than 100 epochs, which is insufficient for proper convergence. In fact, simply increasing the number of epochs to 1000 reduces the relative error to single digits, with exactly the same model."}, {"title": "Summary", "content": "In this study, we evaluated and compared the performance of recently released large language models from OpenAI (ChatGPT 40, ChatGPT 03-mini-high) and DeepSeek (DeepSeek V3, DeepSeek R1) for diverse tasks in compu- tational mathematics and scientific machine learning. We designed challenging problems that required advanced mathematical reasoning and domain-specific knowledge, including numerical integration, finite difference methods (FDM), finite element methods (FEM), and scientific machine learning tasks such as image recognition, physics- informed neural networks (PINNs), and Deep Operator Networks (DeepONet). Our focus was on assessing the models' ability to select appropriate numerical methods or neural network architecture and implement them cor- rectly in Python. The results show that reasoning-optimized models, DeepSeek R1 and ChatGPT 03-mini-high, consistently performed better in recognizing the nature of the problem and making their decisions accordingly. In fact, many of their choices are similar to what we would do in solving these problems both for scientific computing and scientific machine learning. In contrast, general-purpose models, DeepSeek V3 and ChatGPT 40, sometimes fail to account for specific properties of the problem or instructions from the user, consequently generating incorrect or inaccurate solutions.\nOur study highlights the growing usefulness of LLMs in scientific research, as well as the increasing competition between OpenAI and DeepSeek models, as both developers continue to refine their models for tasks in mathematics, coding, and scientific computing. Our findings also expose the limitations of these LLMs, as they may respond to user instructions with ambiguous or incorrect solutions, which could further confuse a human researcher. Our findings highlight the need for continued improvements in LLMs for scientific problem-solving. Future work should explore additional benchmarking methods and assess LLMs on more complex, real-world computational challenges, where a cascade of decisions is required at the different stages of a project. By doing so, researchers can make more informed decisions on when and how to use LLM assistants effectively and responsibly in their daily work."}]}