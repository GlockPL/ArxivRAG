{"title": "Transferring disentangled representations: bridging the gap between synthetic and real images", "authors": ["Jacopo Dapueto", "Nicoletta Noceti", "Francesca Odone"], "abstract": "Developing meaningful and efficient representations that separate the fundamental structure of the data generation mechanism is crucial in representation learning. However, Disentangled Representation Learning has not fully shown its potential on real images, because of correlated generative factors, their resolution and limited access to ground truth labels. Specifically on the latter, we investigate the possibility of leveraging synthetic data to learn general-purpose disentangled representations applicable to real data, discussing the effect of fine-tuning and what properties of disentanglement are preserved after the transfer. We provide an extensive empirical study to address these issues. In addition, we propose a new interpretable intervention-based metric, to measure the quality of factors encoding in the representation. Our results indicate that some level of disentanglement, transferring a representation from synthetic to real data, is possible and effective.", "sections": [{"title": "Introduction", "content": "Developing meaningful, reusable and efficient representations is a critical step in representation learn-ing [1, 56, 55, 64]. Disentangled Representation Learning (DRL) [1, 39, 24, 64] aims to learn models that can identify and disentangle underlying Factors of Variation (FoVs), hidden in the observable data, encoding them in an interpretable and compact shape [31, 9, 1, 69], independently from the task at hand [22, 38, 63, 64]. Moreover, DRL enhances explainability, robustness, and generalization capacity across various applications [64]. Disentangled representations have been shown useful for various downstream tasks, such as FoVs prediction [40, 39], image generation [68, 46, 42, 41, 57] and translation [21, 19, 37], fair classification [54, 38], abstract reasoning [63, 60], domain adaptation [35], and out-of-distribution (OOD) generalization [11, 20].\nWhile all the abovementioned methods may rely on different definitions of disentanglement (see just as examples [1, 23, 61]), and in this sense a comprehensive comparison is hard, they usually share the observation that some level of supervision on the FoVs is beneficial for disentanglement. However, labelling every single factor to achieve fully supervised disentanglement is costly or even unfeasible [67, 50]. For this reason, DRL has been mostly validated on synthetic or simulated data, usually acquired on purpose [11, 40, 58], and there is a limited understanding of the potential of DRL to address general-purpose representation tasks, as well as the specific challenges of the real world (e.g. the presence of clutter and occlusion, correlation between factors [11], etc.). Such challenges may"}, {"title": "Evaluating the quality of disentanglement", "content": "prevent the model from learning perfectly disentangled representations [62].\nIn this work, we propose the adoption of Disentangled Representation (DR) transfer to deal with complex realistic/real dataset. DL tranferring was explored in [20], where Source models learnt in an unsupervised manner were transferred to a Target dataset, by transferring hyperparameters. The authors observed a limited effectiveness in the direct transfer of representations. Instead, Dittadi et al. [11] found out that disentangled representation can help in OOD generalization from a simulated to a smaller real dataset. In both cases, the study involved very specific types of dataset, built to emulate the real one in every detail. Recently, Fumero et al. [18] addressed disentanglement in real data without the need for FoVs annotation, leveraging the knowledge extracted from a diversified set of supervised tasks to learn a common disentangled representation to be transferred to real settings. We follow a different direction, setting up a very straightforward and generalizable procedure: we resort to a weakly supervised approach [40, 25, 26] to learn DRs on Source datasets where the FoVs are known and annotated, to then transfer (with no supervision) such representation to a Target dataset where the FoVs are not known or available. Our final aim is to consider real datasets as a Target, while synthetic data (where FoVs annotation is easy to obtain) can be employed as a Source.\nThe paper presents three main contributions: (1) a novel metric to assess the quality of disen-tanglement, which is interpretable, classifier-free and informative on the structure of the latent representation; (2) a DR transfer methodology to Target datasets without FoV annotation; (3) an extensive experimental analysis that considers different (Source, Target) pairs and quantitatively assesses the expressiveness of the learnt DR on Target of different nature (including the case where the gap between Source and Target is large), taking into consideration the main expected properties of disentangled representation. We discuss the role of fine-tuning and the need to reason on the distance between Source and Target datasets.\nThe paper is organized as follows. In Section 2, we propose and discuss our new intervention-based metric, OMES. In Section 3.3, we introduce our transfer approach to DRL, and provide a thorough analysis of different types of transfer scenarios (synthetic to synthetic, synthetic to real, real to real). Section 4 is left to the conclusions."}, {"title": "Background", "content": "While there is no universally accepted definition of disentanglement, there is common agreement on the properties that a DR should have [12, 52, 63, 1, 55, 2]:\nModularity [53]: A factor influences only a portion of the representation space, and only this factor influences this subspace. This is achievable if the FoV are independent, meaning that a variation in one FoV does not affect others.\nCompactness [53]: The subset of the representation space affected by a FoV should be as small as possible (ideally, only one dimension). This property is also called completeness in [13].\nExplicitness [52]: DR should explicitly describe the factors, thus it should favour FoVs classification.\nThe taxonomy presented in [12] groups all metrics in three families (see a summary in Table 6 in App.): Intervention-based metrics compare codes by intervention, either creating subsets of data in which one or more factors are kept constant(BetaVAE [24] and FactorVAE [27]), or in which only one factor is varying (RF-VAE [28]), and predicting which factors were involved in the in-tervention; Predictor-based metrics use regressors or classifiers to predict factors from DR (DCI Disentanglement [13] and SAP [32]) or intervened subsets (BetaVAE, FactorVAE and RF-VAE); Information-based metrics leverage information theory principles, such as mutual information, to quantify factor-DR relationships (Mutual Information Gap (MIG) [8, 12], MED [6], Modularity [53] and InfoMEC [25]).\nIntervention-based metrics have the advantage of providing control over the factor and the corre-sponding representation. However, they are all based on classifiers, thus they depend on method, hyperparameter settings and model capacity. The latter consideration can be extended to all Predictor-based metrics. On the other hand, Information-based methods are mainly ground on the computation of Mutual Information, which is dependent on an estimator and its parameters [49, 7].\nMotivated by these limitations, we introduce in the next section a new metric, to the best of our knowledge, the first classifier-free intervention-based metric."}, {"title": "Our metric: OMES", "content": "OMES (Overlap Multiple Encoding Scores) is an intervention-based metric measuring the quality of factor encoding in the representation while providing information about its structure: we measure modularity, analyzing how the FoVs overlap, and compactness, detecting and quantifying how a factor is encoded in the dimensions of the representation. To the best of our knowledge, the only metrics capturing more than one property are DCI [13] and the very recent InfoMEC [25]. Differently from DCI, our metric is intervention-based with no influence on the choice of the specific classifier that may inevitably impact the results, as observed in [7]. With respect to InfoMEC, that must be applied to quantized latent codes, our metric is more general and accepts continuous latents.\nOMES is based on the intervention of the FoVs, thus we require the FoV to be (at least partially) known: in particular, samples are coupled so that they differ in one FoV only. In this, OMES differs from existing intervention-based metrics [24, 27] in which the intervention is the opposite (samples have only one FoV in common). Our pairing requires less supervision, and it is usually easier to obtain during data acquisition (for instance, from videos [40]). In addition, it has been shown that this type of pairing provides more guarantees on disentanglement properties [58, 40].\nFinally, compared to Information-based methods, we exploit Correlation instead of Mutual Informa-tion, hence we do not need its estimation that can be sensitive to parameters choice (e.g. granularity of the discretization [7]) and choice of estimator [49, 7].\nGiven an image X, I is its mapping into a d-dim. latent disentangled space, \u03a6(X) = r, r \u2208 Rd. We discard dimensions whose empirical standard deviation is extremely small (< 0.05), meaning that the dimensions are inactive [65, 10]. This leaves us with a subset of m \u2264 d active dimensions, to which we will refer in the following. Let D be a dataset formed by image pairs, D = {(X1, X3, k\u2081)}=1, where X1, X2 are two images that differ for only the FoV ki (e.g. object color).\nN\nOMES requires computing a weighted association matrix S between the dimensions of the represen-tation and the FoVs, with higher association values if the factor is encoded in a certain dimension. The procedure is described in Algorithm 1. We consider the representations of the image pairs in dataset D, obtaining D. In matrix notation we may write it as D\u2081 = [R1, R2, k], where the pair R\u00b9 and R\u00b2 are N \u00d7 m-dimensional matrices with each row i is the representation of the i-th image pair \u03a6(X) = r and \u0424(X\u00b2) = r\u00b2 respectively. For each FoV k we extract the rows of D4 such that the i-th entry of vector k is ki = k, we call this set D.\nEach matrix entry S[h, j] relates a dimension h of the estimated disentangled representation with"}, {"title": "OMES assessment", "content": "we compute the overall score and a score for each FoV separately: we can thus interpret the effect of hyperparameters on the single FoV, and evaluate the FoV separately in each dimension of the representation. Moreover, by inspecting the metric at a factor level, we may identify uneven behaviours (e.g. models performing similarly on average but for different contributions from the factors).\nFig. 1 (Left) shows the metric scores for different values of \u1e9e keeping the different FoV separated: the FoVs less affected by reconstruction (e.g. PosX and PosY) exhibit an increasing disentanglement score as \u1e9e grows. On the other hand, Shape and Orientation present a maximum value around B = 6 and then decrease because they are more susceptible to the reconstruction quality, which degrades for larger values of \u03b2. In Fig. 1 (Center Left) an association matrix S is generated from one of the unsupervised models, B-VAE, trained with \u03b2 = 6: Shape and Orientation are encoded in the same dimension (overlapping) and produce lower values because of the reconstruction, while PosX and PosY are encoded in multiple dimensions and mostly overlapping. Scale does not seem to be well represented."}, {"title": "Transferring disentangled representations", "content": "Fully unsupervised disentangled representation learning has been shown unsatisfactory in many scenarios [39]. However, annotating the FoVs can be a very critical and uncertain process. In this section, we propose a general-purpose methodology for transferring disentangled representations learned from supervised synthetic or simulated data to an unsupervised dataset (in terms of the FoVs). This approach allows us to evaluate the effectiveness of disentangled representations transfer, and its potential in real world applications."}, {"title": "Our methodology and research questions", "content": "Most of the focus in learning disentangled representations has been on synthetic datasets whose ground truth factors exhibit perfect independence by design [43, 51, 15, 34, 4]. Instead, real-world scenarios present several challenges that we want to investigate in our analysis.\nWe consider B-VAE models with weakly supervised learning specifically we adopted Ada-GVAE [40], for its simplicity and its sampling strategy similar to our metric, on a Source Dataset, using pairs of images that differ in l factors of variation. We set l = 1 as it was shown to lead to higher disentanglement [40]. Following [11], we vary the parameter \u1e9e in {1,2}, sufficient to achieve high disentanglement with weak supervision [11, 40].\nWe evaluate the quality of the disentanglement in a transfer learning scenario, assessing the trans-"}, {"title": "Datasets", "content": "In our analysis, we consider both synthetic and real datasets offering different challenges, a summary of their properties is in Tab. 1. Some of the datasets are DRL-compliant, meaning that there is full independence between the FoVs (this is reported in column Indepencence), and FoVs appear in all their possible combinations. This is easy to achieve if the dataset is specifically tailored for DRL, but it can not be easily obtained in general.\ndSprites[43] is a dataset of 2D shapes generated from 5 ground truth FoVs: Shape, Scale, Rotation, x and y Positions. Variants of the dataset have been proposed: in Noisy-dSprites the background is filled with uniform noise; Color-dSprites includes Color as an additional FoV; Noisy-Color-dSprites adds uniform noise to the latter. We refer to them as: N-dSprites, C-dSprites and N-C-dSprites. Shapes3D [4] is a dataset of 3D shapes, generated from 6 ground truth FoVs: Floor colour, Wall colour, Object colour, Scale, Shape and Orientation. It is characterized by the presence of Occlusions.\nThere are few real datasets available specifically meant for DRL. [20] is a collection of datasets covering the transitions from simulated to real data, which is, however, not fully available at the moment. [11] is not appropriate for our analysis since the real data section is very small compared to the complexity of the task. We consider instead real benchmarks proposed for classification tasks, chosen to reflect some of the real-world challenges but possessing some \"semantic connection\" with the synthetic dataset we refer to, e.g. in terms of the expected FoVs. This allows us to reason on the potential of transferability."}, {"title": "Experimental analysis", "content": "Implementation details. We trained 20 different models (10 random seeds \u00d7 2 values of \u1e9e) for each Source dataset. We adopted the same training strategy as in [11] (see Appendix C.2). As for FoVs classification, following [11, 40], we consider Gradient Boosted Trees (GBT) [16] and a Multilayer Perceptron (MLP) [36] with 2 hidden layers of size 256. Since the specific choice of a classifier is not crucial for our analysis, here we report GBT, MLP can be found in Appendix C.6. Fine-tuning to the Target dataset of the VAE models is unsupervised and it is carried out for 50k steps.\nTables description. The tables group different experiments based on the Target dataset. For each FoV, we report under the name the number of values the factor can assume (i.e. its granularity). The tables report the average classification performance over the 20 models, before and after fine-tuning. The latter is reported in parenthesis in terms of gain or loss w.r.t. the performance before the fine-tuning. All is the average performance of all FoVs.\nThe column Pruned highlights the two different representation modalities: if the classifier is trained on the whole representation (X), or using only one dimension, the one showing the strongest encoding of a certain FoV according to the OMES metric (\u2714). As already mentioned, a good performance of the former is an indication of explicitness, while the latter is a positive sign of compactness. Tables also report metrics assessing Modularity (our MES and DCI) and Compactness (our OS and MIG).\n(1) Synthetic to synthetic. As a baseline, we consider the case in which both Source and Target datasets are synthetic and we have access to the annotation of the FoVs, they are DRL-compliant. If Source and Target have the same FoVs (S=dSprites with T=Noisy-dSprites or S=Color-dSprites with T=Noisy-Color-dSprites, see Table 2) we observe the following: pruning the representation to just one dimension maintains, on average, stable performances, showing that the compactness of the representation is preserved for the Target dataset, both before and after fine-tuning. Fine-tuning allows for improved performance in terms of explicitness preserving the remaining properties of the representation, also in the case of the pruned representation. The Orientation FoV is difficult in these datasets as it suffers from reconstruction errors. We increase complexity by adding a new FoV to the Target dataset (S=dSprite with T=Color-dSprite, see Table 2). All FoVs in common between Source and Target are effectively classified, again except Orientation. As for the new FoV (Color), we report lower performances, but we can appreciate a significant improvement with fine-tuning if we exploit a global representation. Instead, we observe a lower improvement with the pruned representation, suggesting that the new factor is not encoded in one single dimension."}, {"title": "Conclusions", "content": "In this paper, we discussed the potential of transferring a Disentangled Representation learnt from a Source Dataset in a weakly supervised manner to a Target Dataset as a strategy to address disentan-glement in real data, where supervision on the FoVs may be difficult or impossible. We identified three main scientific questions, summarised in Section 3.2, which we use to draw conclusions on our study. Starting from question Q2, on the properties of disentangled representations that are preserved after transferring, we may conclude Explicitness is usually well maintained, while Modularity and Compactness are reduced as we move from synthetic to real. More precisely, we appreciate a degra-dation in the global metrics (such as OS and ME), while on the compactness through the analysis of the 1-dimensional pruned representations, we notice that some FoV may transfer very well.\nAs for Q3, we may observe that fine-tuning is almost always beneficial, and it never causes any harm. Q1, a much wider question discussing under what circumstances transfer is effective leads us to conclude that some structural similarity between Source and Target datasets is necessary, including"}]}