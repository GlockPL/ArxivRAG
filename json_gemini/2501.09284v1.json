{"title": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation", "authors": ["Giyeong Oh", "Seajin Kim", "Woohyun Cho", "Sangkyu Lee", "Jiwan Chung", "Dokyung Song", "Youngjae Yu"], "abstract": "Recently, LoRA and its variants have become the de facto strategy for training and sharing task-specific versions of large pretrained models, thanks to their efficiency and simplicity. However, the issue of copyright protection for LORA weights, especially through watermark-based techniques, remains underexplored. To address this gap, we propose SEAL (SEcure wAtermarking on LoRA weights), the universal white-box watermarking for LoRA. SEAL embeds a secret, non-trainable matrix between trainable LORA weights, serving as a passport to claim ownership. SEAL then entangles the passport with the LORA weights through training, without extra loss for entanglement, and distributes the finetuned weights after hiding the passport. When applying SEAL, we observed no performance degradation across commonsense reasoning, textual/visual instruction tuning, and text-to-image synthesis tasks. We demonstrate that SEAL is robust against a variety of known attacks: removal, obfuscation, and ambiguity attacks.", "sections": [{"title": "1. Introduction", "content": "Recent years have witnessed an increasing demand for protecting deep neural networks (DNNs) as intellectual properties (IPs), mainly due to the significant cost of collecting quality data and training DNNs on it. In response, researchers have proposed various DNN watermarking methods for DNN copyright protection (Uchida et al., 2017; Darvish Rouhani et al., 2019; Zhang et al., 2018; Fan et al., 2019; Zhang et al., 2020; Xu et al., 2024; Lim et al., 2022), which work by secretly embedding identity messages into the DNNs during training. The IP holders can present the identity messages to a verifier in the event of a copyright dispute to claim ownership."}, {"title": "2. Preliminary", "content": ""}, {"title": "2.1. Low-Rank Adaptation", "content": "LORA (Hu et al., 2022) assumes that task-specific updates lie in a low-rank subspace of the model's parameter space. It freezes the pretrained weights W \u2208 Rb\u00d7a and trains two low-rank matrices A \u2208 Rrxa and B \u2208 Rb\u00d7r. After training, the adapted weights are:\nW' = W + AW = W + BA\nBecause there are no activation functions between A and B, one can simply add BA to W for efficient integration into the pretrained model."}, {"title": "2.2. White-box DNN Watermarks", "content": "White-box DNN watermarking techniques can be broadly categorized based on the location of secret embedding or verification:\n\u2022 Weight-based. These methods directly embed a secret bit sequence (e.g., {+1, -1}) into the model parameters. Verification often entails examining the trained weights to extract or validate the embedded bits (Uchida et al., 2017; Liu et al., 2021; Fernandez et al., 2024).\n\u2022 Activation-based. Here, watermarks are embedded in the feature maps of specific layers. By injecting specialized inputs, one can detect the hidden signature from the activations that uniquely respond to the watermark (Darvish Rouhani et al., 2019; Lim et al., 2022).\n\u2022 Output-based. These approaches ensure that the final output from the model contains a watermark. Even in a white-box scenario, the verification is primarily conducted on the model's output rather than its internal parameters (Kirchenbauer et al., 2024; Fernandez et al., 2023; Feng et al., 2024).\n\u2022 Passport-based. This line of work inserts an additional linear or normalization layer (passport layer) into the model, so that using the correct passport yields normal performance, while invalid passports degrade the accuracy. During ownership verification, the legitimate passport is presented to confirm the model's fidelity, effectively distinguishing rightful owners from adversaries (Fan et al., 2019; Zhang et al., 2020).\nUnlike weight-, activation-, or output-based methods, passport-based watermarking ties model performance to hidden parameters (passports). It does not require special triggers or depend solely on model outputs. Instead, ownership is verified by a passport that restores high accuracy, securely linking model weights and the embedded secret."}, {"title": "3. SEAL: The Watermarking Scheme", "content": "For clarity, the symbols used throughout this section are listed in Table 6."}, {"title": "3.1. Impact of the Constant Matrix between LoRA", "content": "In Fig. 2, we compare the distributions of negative log singular values, \u2013 log(\u03c3), from a standard LORA model , N(B, A), against our proposed SEAL, N(B, A, C'), approach on multiple models: Llama-2-7B/13B (Touvron et al., 2023), Mistral-7B-v0.1 (Jiang et al., 2023), and Gemma-2B (Team et al., 2024). For each trained model, we reconstruct the learned weight AW, collect the top-32 singular values \u03c3 from each module, and plot \u2013 log(\u03c3) in a cumulative distribution function (CDF).\nWe observe that the SEAL curves systematically shift to the right compared to LoRA. This shift implies that the learned subspace under SEAL is more evenly spread across multiple singular directions, rather than being dominated by just a few large singular values. Such broad coverage in the singular spectrum can bolster robustness: altering or removing the watermark in one direction has a limited effect, as the watermark is \"spread out\" in multiple directions. Further gradient-based analyses are provided in Appendix B."}, {"title": "3.2. Comparison with Existing Passport Methods", "content": "Unlike prior passport-based methods (Fan et al., 2019; Zhang et al., 2020) that typically introduce an additional loss term (a regularization or constraint to embed the passport) and keep the passport layer trainable, SEAL employs a non-trainable matrix C inserted directly into LoRA's block, eliminating the need for auxiliary loss terms. Consequently, our approach differs from existing methods on two key fronts-no extra loss and a non-trainable passport-making a one-to-one comparison problematic."}, {"title": "3.3. Entangling Passports during Training", "content": "SEAL embeds the watermark during training by inserting the non-trainable, constant matrix C between the trainable parameters B and A. Doing so effectively entangles the given passport with B and A. The concept of entanglement is superficially similar to the entanglement proposed by Jia et al. It involves indistinguishable distributions between host and watermarked tasks. In our context, we define entanglement as follows.\nGiven trainable parameters A and B, and a non-trainable parameter C, A and B are in entanglement via C if and only if they produce the correct output for the host task when C is present between them."}, {"title": "3.4. Hiding Passport for Distribution", "content": "After successfully establishing the entanglement between the passport and other trainable parameters, the passport must be hidden before distribution. Therefore, we decompose the passport, C, of the IP holder into two matrices such that their product reconstructs C, as shown in Fig. 1.\nFor a given constant C, a function f is a decomposition function of C where\nf: C \u2192 (C1, C2) such that C1C2 = C.\nThe decomposition function ensures that models trained with SEAL, which contain three matrices per layer, N(B, A, C), can be distributed in a form that resembles standard LoRA implementations with only two matrices, N(B', A'). In the decomposition process, the IP holder can camouflage the passport C within the open-sourced weight by distributing its decomposed components into B and A.\nAn example of decomposition using SVD is\nfsud(C) = (Uc\u221a\u03a3,\u221a\u03a3VE),\nwhere C = UC\u03a3VE. Using SVD decomposition function, fsvd, the resulting component of N(B', A') is\nB' = B (UC\u221a\u03a3) and A' = (\u221a\u03a3VE) A.\nWe will use fsud as the default decomposition function unless otherwise specified. Notably, Cp is not distributed into either B or A."}, {"title": "3.5. Extraction on Embedded Passport", "content": "To extract the embedded passport from LoRA converted SEAL weight, N(B', A'), we have to assume that A and B, which are trained SEAL weights, are full rank matrices.\nTrained SEAL weights B and A are full rank matrices with r.\nBy Assumption 3.3, A and B have the pseudo-inverse A\u2020, B\u2020 such that AA\u2020 = Ir, B\u2020B = Ir, where Ir \u2208 Rror is the identity matrix. As shown in Alg. 2, the method for extracting the passport from B'A' is multiplying A\u2020, B\u2020 in the right/left side of B'A', respectively. Thus, only the legitimate owner, who has original SEAL weights B and A, can extract the concealed passport, C', from N(B', A')."}, {"title": "3.6. Passport-based Ownership Verification", "content": ""}, {"title": "3.6.1. EXTRACTION", "content": "Yan et al. demonstrate that it is possible to neutralize the extraction process of watermarking schemes by altering the distribution of parameters while maintaining functional invariance. Given that the adversary is aware of SEAL and we assume a white-box scenario, the adversary could generate the triplet A, B, C for the verifier during the extraction process such that\nrank(A) = r and, B = B'A'AtCtAt\nIn this process, even if C \u2260 C, which is the truly distributed passport, the verifier could be confused about who the legitimate owner is. For this reason, extraction should only be used when the legitimate owner is attempting to verify whether their passport is embedded in a suspected model. It should not be relied upon in scenarios where a third-party verifier is required for a contested model, as it is vulnerable in such cases.\nTherefore, it is crucial to leverage the inherent characteristic of passport-based schemes\u2014where performance degradation occurs if the correct passport is not presented-allowing a third-party verifier to determine the legitimate owner accurately (Fan et al., 2019)."}, {"title": "3.6.2. MEASURING FIDELITY", "content": "Recall that SEAL entails two passports, (C', C'p), both entangled with the LoRA weights (B, A). To gauge how similarly these two passports preserve the model's performance, we define a fidelity gap:\n\u03b5T = |MT (N(B, A, C)) \u2013 MT (N(B, A, Cp)),\nwhere MT is the task-specific metric for the adaptation layer N(B, A, \u00b7) on task T. A small \u03b5T indicates that C and Cp yield near-identical performance, implying they were jointly entangled during training. By contrast, if two passports are not entangled with (B, A), switching between them would degrade the model's accuracy, producing a large \u03b5T.\nIn a legitimate setting, the owner's (C, Cp) should incur almost no performance difference (\u03b5T close to zero). An attacker forging a second passport, however, cannot maintain the same fidelity gap without retraining the entire LoRA model. Hence, \u03b5T naturally serves as a verification criterion for rightful ownership. Detailed formulation is in Sec. 3.6.3"}, {"title": "3.6.3. VERIFICATION", "content": "The fundamental idea behind passport-based watermarking is that any forged passport significantly degrades the model's performance (Fan et al., 2019), resulting in a fidelity gap \u0394 > \u03b5T. As shown in Alg. 3, the suspected model (B', A') is first checked against the claimant's (B, A, Ca) to ensure they reconstruct the same adaptation weights. If so, we measure \u0394 between Ca and Co (the two passports) via the task metric MT. Def. 3.4 then concludes that ownership is verified if and only if \u25b2 < \u20ac\u03c4:\nAssume N(B', A') =\nN(B, A, Ca) \u2260 N(B, A, C\u266d). Define\n\u0394 := | MT(N(B, A, Ca)) \u2013 MT(N(B, A, C\u266d))|,\nTrue, if \u0394 < \u03b5\u03c4,\nV (\u041c\u0442, \u0435\u0442, N(B, A, \u00b7)) =\nFalse, otherwise."}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Experimental Setup", "content": ""}, {"title": "4.1.1. FIDELITY", "content": "To demonstrate that the performance of models after embedding SEAL passports does not degrade, we conducted experiments across both language and image modalities. Initially, we evaluate our model by comparing it with various open-source Large Language Models (LLMs) such as LLaMA-2-7B/13B (Touvron et al., 2023), LLaMA-3-8B (AI@Meta, 2024), Gemma-2B (Team et al., 2024), and Mistral-7B-v0.1 (Jiang et al., 2023) on commonsense reasoning tasks. Next, we verify the model's effectiveness on instruction tuning tasks. Following this, we extend our approach to the Vision Language Model (VLM) (Liu et al., 2024a) by evaluating the model's performance on visual instruction tuning. Finally, we assess SEAL's capabilities on image-generative tasks (Rombach et al., 2022)."}, {"title": "4.1.2. ROBUSTNESS", "content": "We evaluated the robustness of SEAL against removal, obfuscation and ambiguity attacks by evaluating fidelity scores in commonsense reasoning tasks. For removal and obfuscation attacks, the presence of the extracted watermark was confirmed through hypothesis testing. For ambiguity attacks, fidelity scores were used to verify genuine versus counterfeit passports, as defined in Def. 3.4."}, {"title": "4.2. Commonsense Reasoning Task", "content": "Table 1 presents the performance comparison across commonsense reasoning tasks: BoolQ (Clark et al., 2019), PIQA (Bisk et al., 2020), SIQA (Sap et al., 2019), HellaSwag (Zellers et al., 2019), Wino. (Sakaguchi et al., 2021), ARC-e, ARC-c (Clark et al., 2018), and OBQA (Mihaylov et al., 2018). The dataset combines multiple sources, as detailed in (Hu et al., 2023). We train LLMs on 3-epochs on the combined dataset. The experimental results emphasize that SEAL can be seamlessly integrated into existing LoRA architectures, without affecting performance degradation."}, {"title": "4.3. Textual Instruction Tuning", "content": "Table 2 shows the scores for LLaMA-2-7B, instruction tuned with both LoRA and SEAL, using Alpaca dataset (Taori et al., 2023) with 3-epochs. The scores are averaged ratings given by gpt-4-0613 on a scale of 1 to 10 for the models' responses to questions from MT-Bench (Zheng et al., 2023). Since the Alpaca dataset is optimized for single-turn interactions, the average score for single-turn performance from MT-Bench is used. The results indicate that SEAL achieves performance comparable to LoRA, thereby confirming its fidelity."}, {"title": "4.4. Visual Instruction Tuning", "content": "Table 2 shows the average performance across seven visual instruction tuning benchmarks (Goyal et al., 2017; Hudson & Manning, 2019; Gurari et al., 2018; Lu et al., 2022; Singh et al., 2019; Li et al., 2023b; Liu et al., 2023) for LORA and SEAL on LLaVA-1.5 (Liu et al., 2024a) with detailed elaboration in Appendix F.3. As shown in Table 2, the performance of SEAL is comparable to that of LoRA."}, {"title": "4.5. Text-to-Image Synthesis", "content": "The experimentation with the Stable Diffusion model (Rombach et al., 2022) in conjunction with the dataset of DreamBooth (Ruiz et al., 2023) trained with LoRA elucidates the versatility SEAL when integrated into diverse architectures. Table 2 provides a detailed comparison of subject fidelity, CLIP-I (Radford et al., 2021), DINO. (Caron et al., 2021), and prompt fidelity, CLIP-T, using the methods employed in (Nam et al., 2024). Our results confirm that SEAL maintains high fidelity and prompt accuracy without any degradation in model performance."}, {"title": "4.6. Integrating with LoRA Variants", "content": "Table 3: Average Commonsense Reasoning Performance on Llama-2-7B for LoRA, DORA, and SEAL. The notation SEAL+DORA signifies that the SEAL approach has been applied in conjunction with the DoRA variant. Hyperparameter settings are in Appendix F.\nThanks to its flexible framework, SEAL can easily be applied to a wide variety of LoRA variants. In Table 3, we use DORA (Liu et al., 2024b) as a case study to demonstrate that"}, {"title": "4.7. Pruning Attack", "content": "Pruning attacks were performed on trained SEAL weights by zeroing out N(B', A') based on their L1 norms. And we extract passport, C, on pruned weight. We used statistical testing instead of Bit Error Rate (BER) because, unlike prior work (Uchida et al., 2017; Fernandez et al., 2024; Zhang et al., 2020; Feng et al., 2024) that used a small number of bits, N~102, the amount of our passport bits is approximately N~105, necessitating a different approach. In hypothesis testing, if the p-value is smaller than our significance level (\u03b1 = 0.0005), we reject the null hypothesis, the extracted watermark is an irrelevant matrix with C. Re-"}, {"title": "4.8. Finetuning Attack", "content": "In this experiment, we aimed to assess the robustness of SEAL's watermark under finetuning attacks. The notation Tne represents a task T fine-tuned for n epochs. Specifically, we resumed training on SEAL weights, N(B', A'), that had been trained for 3 epochs on two tasks: commonsense reasoning (C3e) and instruction tuning with Alpaca dataset (Taori et al., 2023) (I3e). The notation T3e \u2192 T1e represents post-finetuning with the respective dataset for 1 additional epoch using standard LoRA training, where A' and B' are the trainable parameters.\nThese finetuning scenarios were designed to simulate an adversarial attack, where the model is fine-tuned either on the original or a different dataset, such as finetuning on Alpaca for one epoch (\u2192 I1e) or on commonsense reasoning for one epoch (\u2192 C1e). After finetuning, we evaluated the robustness of the embedded watermark by extracting it and measuring the p-value. The results demonstrated a p-value significantly lower than 5e-4, with N = 163840, indicating the passport C remains detectable."}, {"title": "4.9. Structural Obfuscation Attack.", "content": "Structural obfuscation attacks target the structure of DNN models while maintaining their functionality (Yan et al.,"}, {"title": "4.10. Ambiguity Attack", "content": "In the context of SEAL, ambiguity attacks pose a significant threat when an adversary attempts to create counter-"}, {"title": "5. Conclusion", "content": "We introduced SEAL, a novel watermarking scheme specifically tailored for LoRA weights. By inserting a constant matrix C during LoRA training and factorizing it afterward, our approach enables robust ownership verification without impairing the model's performance. Empirical results on commonsense reasoning, instruction tuning, and text-to-image tasks confirm both high fidelity and strong resilience"}, {"title": "C. On Forging Multiple Passports from a Single Factorization", "content": "This section clarifies why an adversary cannot simply factorize the released LoRA weights (B', A') into some (B, C, \u00c3) and then create an additional passport Cp-adv in order to circumvent our multi-passport verification. We also reiterate that SEAL is intentionally indistinguishable from a standard LoRA, so an attacker generally cannot even discern that SEAL was used."}, {"title": "C.1. Indistinguishability from Standard LORA", "content": "By design, the publicly distributed weights are simply B' \u2208 Rb\u00d7r and A' \u2208 Rrxa, analogous to standard LoRA. No additional matrix parameters (or suspicious metadata) are visible. Hence, without insider knowledge, an attacker cannot tell a priori if (B', A') derives from SEAL or a conventional LoRA finetuning. This alone imposes a significant hurdle:\nAttacker must first discover (or guess) that SEAL was used.\nOnly then might they attempt forging hidden passports."}, {"title": "C.2. Attempting a Single Factorization for Two Passports", "content": "Assume, hypothetically, that an attacker somehow knows a given (B', A') came from SEAL. They might try a factorization of the form:\n(B', A') \u2192 (B, C, \u00c3),\nso that BCA = B'A'. Then they could designate C as a forged version of the original C.\nCreating a Second Passport. Furthermore, to break multi-passport verification (see Sec. 3.6.3), the attacker would need another passport, Cp-adv, that also yields near-identical fidelity scores:\nMT(N(B, \u00c3, C)) \u2248 MT(N(B, \u00c3, Cp-adv)) (for all relevant data for task, T).\nHowever, this requires that B, A be simultaneously entangled with two distinct passports, which is nontrivial for a single factorization."}, {"title": "C.3. Why a Single Factorization Cannot Produce Two Entangled Passports", "content": "\u2022 Concurrent Entanglement is Required. In SEAL, B and A are co-trained (entangled) with both C and Cp at the same time during finetuning. This ensures that, for any batch, either C or Cp is used, such that B, A adapt to both passports. Merely performing a post-hoc factorization on (B', A') does not replicate this simultaneous learning process.\n\u2022 One Factorization Yields One Mapping. A single factorization typically captures one equivalence, e.g. C. Generating an additional Cp-adv that also achieves the same function (or fidelity) using the same B, A is a significantly more constrained problem. In practice, an attacker would need to re-finetune (B, A) twice, once for each passport, effectively mimicking the original training-but without knowledge of the original dataset D.\n\u2022 Costly and Uncertain Outcome. Even if the attacker invests major computational resources, re-training two passports from scratch is as expensive as (or more expensive than) training a brand-new LoRA model. Moreover, success is not guaranteed, since the attacker must ensure Cp-adv \u2260 C but still replicates near-identical behavior on the entire dataset, all while not knowing the original dataset D or training schedule."}, {"title": "C.4. Proof of Non-Existence of Two Distinct Passports from One Factorization", "content": "We assume the attacker fixes rank-r matrices\nB\u2208Rbxr, \u00c3\u2208Rrxa with rank(B) = rank(\u00c3) = r.\nThis aligns with standard LoRA dimensionality and preserves maximum utility (see Remark C.4 below)."}, {"title": "Statement.", "content": "Suppose the attacker finds two different passports, C \u2260 Cp-adv, each in Rr\u00d7r, satisfying\nBCA = BCp-adv A = B'A'.\nWe show this leads to a contradiction.\nIf the attacker specifically uses the pseudoinverse-based approach,\nC = B\u2020 (B'A') \u00c3\u2020, Cp-adv = B\u2020 (B'A') \u00c3\u2020,\nthen clearly C = Cp-adv, contradicting C\u2260Cp-adv."}, {"title": "More general linear algebra argument (rank-r).", "content": "Even without explicitly constructing B\u2020 or A\u2020, one can show:\n(C - Cp-adv) \u2192 B (C - Cp-adv) \u00c3 = 0.\nSince B, \u00c3 each have rank r, this forces C \u2013 Cp-adv = 0, implying C = Cp-adv. Hence, no two distinct passports can arise from the same factorization (B, \u00c3).\nC\u2260 Cp-adv \u2190 C - Cp-adv = O."}, {"title": "Remark on rank-deficient factorizations.", "content": "If B or \u00c3 has rank < r, then infinitely many C can satisfy BC \u00c3 = B'A'. However, such rank-deficient choices almost always degrade the model's fidelity (losing degrees of freedom), thus failing to preserve the same performance as (B', A'). Consequently, attackers seeking to maintain full utility have no incentive to choose rank-deficient B, \u00c3. Therefore, we assume rank(B) = rank(\u00c3) = r to ensure that (B'A') is matched faithfully."}, {"title": "C.5. No Practical Payoff for Such an Attack", "content": "1. Attackers Typically Lack Data. To even begin constructing (C, Cp-adv), attackers must have access to the original training data (or certain proportion of dataset with similar distribution) and be certain SEAL was used. Both are high barriers. Training dataset is not a part of SEAL, and is mostly proprietary. It does not violate Kerckhoff's principal.\n2. Equivalent to Costly Re-Training. Producing two passports that match all fidelity checks essentially replicates the original multi-passport entanglement from scratch. This yields no distinct advantage over simply training a new LoRA.\n3. Cannot Disprove Legitimate Ownership. Even if they succeed in forging C, Cp-adv, the legitimate owner's original pair (C, Cp) still correctly verifies, preserving the rightful ownership claim."}, {"title": "C.6. Conclusion", "content": "In summary, forging multiple passports from a single factorization of (B', A') is infeasible because SEAL's multi-passport structure relies on concurrent entanglement of B, A with both passports C and Cp during training. A single post-hoc factorization can at best replicate one equivalent mapping, but not two functionally interchangeable mappings without a re-finetuning process that is as expensive and uncertain as building a new model. Furthermore, since SEAL weights are indistinguishable from standard LoRA, the attacker generally cannot even detect the scheme in the first place. Therefore, this approach does not offer a viable pathway to break or circumvent SEAL's multi-passport verification procedure."}, {"title": "D. Extensions to Matmul-based LoRA Variants", "content": "Beyond the canonical LoRA (Hu et al., 2022) formulation, numerous follow-up works propose modifications and enhancements while still employing matrix multiplication (matmul) as the underlying low-rank adaptation operator. In this section, we illustrate how SEAL is compatible or can be adapted to these matmul-based variants. Although we do not exhaustively enumerate every LoRA-derived approach, the general principle remains: if the adaptation primarily uses matrix multiplication (possibly with additional diagonal, scaling, or regularization terms), then SEAL can often be inserted by embedding a non-trainable passport C between the up and down blocks."}, {"title": "E. Extensions to Generalized Low-Rank Operators", "content": "In the main text, we considered a standard LoRA (Hu et al., 2022) that uses a matrix multiplication operator:\nAW = BCA,\nwhere B \u2208 Rb\u00d7r, C' \u2208 Rr\u00d7r, and A \u2208 Rr\u00d7a. Recent work has explored alternative low-rank adaptation mechanisms beyond simple matmul, such as Kronecker product-based methods (Edalati et al., 2022; Yeh et al., 2023) or even elementwise (Hadamard) product (Hyeon-Woo et al., 2021) forms. Our approach can be extended in a straightforward manner to these generalized operators, which we denote as *."}, {"title": "E.1. General Operator *", "content": "Let \u2217 be any bilinear or multilinear operator used for low-rank adaptation.\u00b9 We can then write the trainable adaptation layer as\nAW = B\u2217 C \u2217 A,\nwhere B, A are the trainable low-rank parameters, and C is the non-trainable passport in SEAL. During training, B and A are optimized in conjunction with C held fixed (just as in the matrix multiplication case).\nTo distribute C into (B, A) after training, we require a decomposition function\nAW = B\u2217 C1 \u2217 A, A' = C2 \u2217 A,\n(B \u2217 C1) \u2217 (C2 \u2217 A) = B \u2217 (C1C2) \u2217 A = B \u2217 C \u2217 A.\nHence, the final distributed weights (B', A') for public remain functionally equivalent to using B, A, C."}, {"title": "E.2. Implications and Future Directions", "content": "\u2022 Broader Applicability. By permitting to be any bilinear or multilinear operator (Kronecker, Hadamard, etc.), SEAL naturally extends beyond the canonical matrix multiplication used in most LoRA implementations. This flexibility can be valuable for advanced parameter-efficient tuning methods (Edalati et al., 2022; Hyeon-Woo et al., 2021; Yeh et al., 2023)."}, {"title": "F. Training Details", "content": ""}, {"title": "F.1. Commonsense Reasoning Tasks", "content": "We conduct evaluations on commonsense reasoning tasks using eight distinct sub-tasks: Boolean Questions (BoolQ) (Clark et al., 2019), Physical Interaction QA (PIQA) (Bisk et al., 2020), Social Interaction QA (SIQA) (Sap et al., 2019), Narrative Completion (HellaSwag) (Zellers et al., 2019), Winograd Schema Challenge (Wino) (Sakaguchi et al., 2021), ARC Easy (ARC-e), ARC Challenge (ARC-c) (Clark et al., 2018), and Open Book QA (OBQA) (Mihaylov et al., 2018).\nWe benchmark SEAL and LoRA against LLaMA-2-7B/13B (Touvron et al., 2023), LLaMA-3-8B (AI@Meta, 2024), Gemma-2B (Team et al., 2024), and Mistral-7B-v0.1 (Jiang et al., 2023) across these commonsense reasoning tasks.\nThe hyperparameters used for these evaluations are listed in Table 14."}, {"title": "F.2. Textual Instruction Tuning", "content": "We conducted textual instruction tuning using Alpaca dataset (Taori et al., 2023) on LLaMA-2-7B (Touvron et al., 2023), trained for 3 epochs. The hyperparameters used for this process are detailed in Table 8."}, {"title": "F.3. Visual Instruction Tuning", "content": "We compared the fidelity of SEAL, LoRA, and FT on the visual instruction tuning tasks with LLaVA-1.5-7B (Liu et al., 2024a). To ensure a fair comparison, we used the same original model provided by (Liu et al., 2024a) uses the same configuration as the LoRA setup with the same training dataset. We adhere to (Liu et al., 2024a) setting to filter the training"}, {"title": "F.4. Text-to-Image Synthesis", "content": "The DreamBooth dataset (Ruiz et al., 2023) encompasses 30 distinct subjects from 15 different classes, featuring a diverse array of unique objects and live subjects, including items such as backpacks and vases, as well as pets like cats and dogs. Each of the subjects contains 4-6 images. These subjects are categorized into two primary groups: inanimate objects and live subjects/pets. Of the 30 subjects, 21 are dedicated to objects, while the remaining 9 represent live subjects/pets.\nFor subject fidelity, following (Ruiz et al., 2023), we use CLIP-I, DINO. CLIP-I, an image-text similarity metric, compares the CLIP (Radford et al., 2021) visual features of the generated images with those of the same subject images. DINO (Caron et al., 2021), trained in a self-supervised manner to distinguish different images, is suitable for comparing the"}, {"title": "G. Ablation Study", "content": ""}, {"title": "G.1. Passport Example", "content": "In order to provide a concrete illustration of our watermark extraction process, we construct a small 32\u00d732 grayscale image as the passport C (or Cp). Specifically, we sampled 100 frames from a publicly available YouTube clip, applied center-cropping on each frame, converted them to grayscale, and then downsampled to 32\u00d732. From these frames, we selected one representative image (shown in Fig. 8) to embed as the non-trainable matrix C in our SEAL pipeline Sec. 3.3.\nThis tiny passport image, while derived from a movie clip, is both unrecognizable at 32\u00d732 and used exclusively for educational, non-commercial purposes. Nevertheless, it visually demonstrates how a low-resolution bitmap can be incorporated into the model's parameter space and later extracted (possibly with minor distortions) to verify ownership."}, {"title": "G.2. Rank Ablation", "content": "To evaluate versatility of the proposed SEAL method under varying configurations, we conducted additional experiments focusing on different rank settings (4, 8, 16). The results are summarized in Table 15. We used the Gemma-2B model (Team et al., 2024) on commonsense reasoning tasks, as described previously. For comparison, we included the results of LoRA with r = 32 and SEAL with r = 32 as mentioned in Table 2."}, {"title": ""}]}