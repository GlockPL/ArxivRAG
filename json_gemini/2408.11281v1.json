{"title": "BearLLM: A Prior Knowledge-Enhanced Bearing Health Management Framework with Unified Vibration Signal Representation", "authors": ["Haotian Peng", "Jiawei Liu", "Jinsong Du", "Jie Gao", "Wei Wang"], "abstract": "We propose a bearing health management framework leveraging large language models (BearLLM), a novel multimodal model that unifies multiple bearing-related tasks by processing user prompts and vibration signals. Specifically, we introduce a prior knowledge-enhanced unified vibration signal representation to handle various working conditions across multiple datasets. This involves adaptively sampling the vibration signals based on the sampling rate of the sensor, incorporating the frequency domain to unify input dimensions, and using a fault-free reference signal as an auxiliary input. To extract features from vibration signals, we first train a fault classification network, then convert and align the extracted features into word embedding, and finally concatenate these with text embedding as input to an LLM. To evaluate the performance of the proposed method, we constructed the first large-scale multimodal bearing health management (MBHM) dataset, including paired vibration signals and textual descriptions. With our unified vibration signal representation, BearLLM using one set of pre-trained weights achieves state-of-the-art performance on nine publicly available fault diagnosis benchmarks, outperforming specific methods designed for individual datasets. We provide a dataset, our model, and code to inspire future research on building more capable industrial multimodal models (https://github.com/hatton613/BearLLM).", "sections": [{"title": "Introduction", "content": "Bearings are the core components of mechanical rotating equipment but have high failure rates due to complex operational and environmental conditions [40]. Bearing health management (e.g., anomaly detection, fault diagnosis, and maintenance recommendations) is of great practical significance in industrial safety production to reduce economic losses and maintenance costs [32, 44, 35].\nCurrent bearing health management frameworks rely on designing specialized methods for different working conditions and tasks, as shown in Fig. 1 (a). To apply specific methods to complex real-world industrial scenarios, domain adaptation, and generalization have attracted widespread attention. Domain adaptation enables a model trained on one source domain to perform well on different but related target domains by reducing the domain shift or discrepancy [43, 46], but it suffers from low accuracy when the source and target domains are category-inconsistent (e.g., transitioning from working condition C\u2081 with four fault types to C2 with five types). Domain generalization aims to extract domain-invariant features to improve performance on unseen domain [19, 47, 4], but it is often constrained to a limited number of working conditions with small differences, e.g., fewer than ten working conditions in [5, 22]. These purely data-driven methods often fail to strike an optimal balance between high accuracy and strong generalization for fault diagnosis.\nIn this paper, we propose a prior knowledge-enhanced bearing large language model (BearLLM), which can unify multiple bearing health management tasks over hundreds of different working conditions from multiple datasets, as shown in Fig. 1 (b). To handle various working conditions, we introduce a prior knowledge-enhanced unified vibration signal representation. Unlike most fault diagnosis methods that use fixed-length input segments, we sample vibration signals as variable-length but fixed-duration segments. These duration-consistent segments are then converted to the frequency domain and are aligned. We further utilize a fault-free reference signal as a prior input, eliminating the need for complex mechanism analysis for various bearing designations [47].\nSpecifically, we first design a fault classification network (FCN) to extract fault features based on the differ-"}, {"title": "Related Works", "content": "Multiple Working Condition: Fault diagnosis under various working conditions from multiple datasets presents a challenge due to the heterogeneity of collected signals arising from variations in the test rigs, sensors, and environment, making it difficult to obtain unified features [41]. Existing domain adaptation methods [6, 38, 25, 14] typically involves training a model under known working conditions (source domain) and subsequently transferring knowledge to an unknown working condition (target domain). However, these approaches still necessitate individual transfer fine-tuning for each working condition in practice, hindering its ability to generalize across multiple scenarios. Domain generalization methods leverage training on multiple working conditions and aim to align the feature distributions of different domains through the design of network architectures and loss functions [15, 48, 12]. However, these approaches often rely on complex data preprocessing and augmentation techniques to help models learn fault features from vibration signals.\nMultiple Tasks: Data-driven machinery health management have gained significant traction [37]. The concept of health management usually involves multiple tasks [29, 49], including anomaly detection, fault diagnosis, degradation prediction, maintenance decision-making, etc. LLMs such as ChatGPT-4 [30] have demonstrated exceptional capabilities across a wide range of tasks. The emergence of open-source foundational models like LLaMA 3 [27] and Qwen 2 [1] have further empowered researchers in various disciplines to integrate these models into their own applications. In the aviation domain, Liu et al. [23] applied generalized linear models to achieve multiple tasks, including assembly guidance and assembly error identification for aircraft engines. In the petroleum industry, Eckroth et al. [9] designed a question-answering system based on LLM and knowledge graph, enabling retrieval of functionalities such as stratigraphy data and geological age determination. However, research integrating multiple tasks using LLMs for bearing health management remains limited [20]."}, {"title": "A Multimodal Bearing Health Management Dataset", "content": "Although several bearing-related datasets in Tab. 1 are available, they generally collect vibration signals on a single test rig, have a limited number of working conditions, and have no corresponding textual descriptions for training LLM. We have constructed a large-scale publicly multimodal dataset for bearing health management (MBHM).\nThe MBHM contains 135,516 pairs of vibration signal segments and fault types, and 542,064 pairs of text cues and responses, of which each sample is shown in Fig. 3, contains a vibration signal, a fault label, an operating condition id, a user prompt, and a text response, ie, (Xv, Lv, C, Xt, Lt) \u2208 MBHM. Our dataset contains 262 working conditions collected from nine publicly accessible datasets, i.e., CWRU [2], DIRG [7], HIT [11], IMS [33], JNU [16], JUST [34], MFPT [10], PU [18], XJTU [39]. For each vibration signal, we have four different tasks, i.e., anomaly detection, fault diagnosis, maintenance recommendations, and potential risk analysis by generating text responses using ChatGPT [30]. Detailed methodologies for dataset construction are provided in Appendix A.3. Our MBHM dataset contains the following features:\n\u2022 Multi-modal: Each vibration signal is paired with four"}, {"title": "Method", "content": "In this section, we propose BearLLM, a novel multimodal model that unifies multiple bearing-related tasks. To handle various working conditions across multiple datasets, we introduce a prior knowledge-enhanced unified vibration signal representation in Section 4.1. The unified vibration signal is fed to a fault classification network to extract features in Section 4.2. We convert and align the extracted features into word embedding, and finally concatenate these with text embedding as input to an LLM in Section 4.3."}, {"title": "Prior Knowledge-Enhanced Unified Vibration Signal Representation", "content": "BearLLM aims to manage multiple bearing-related tasks across hundreds of working conditions. The basis for this is to build a unified vibration signal representation, involving adaptively sampling the vibration signal segments based on the sensor sampling rate, incorporating the frequency domain to unify input dimensions, and using a fault-free reference signal to calculate residual as auxiliary inputs to improve data utilization efficiency.\nAdaptive Sampling To monitor various mechanical devices across different working conditions and industrial scenarios, vibration sensors are deployed with varying designations and sampling rates. However, most fault diagnosis methods [48, 8] use fixed-length signal segments in the time domain as inputs, where the fault frequency components in the inputs deviate from their original intrinsic values and vary with the sampling rate, hindering accurate fault diagnosis. Instead of sampling fixed-length signal segments, we adaptively sample vibration signals as variable-length but fixed-duration segments using prior knowledge of the sensor sampling rate. We extract the m-th query signal segment X \u2208 R\u00b9\u00d7s from the original signal Xo by\n$$X = X_o[ms, (m + 1)s],$$\nwhere s denotes the sampling rate of the sensor and controls the length of the X.\nFrequency-domain Input Alignment After adaptive sampling, each query segment (X) has an equal duration, and the frequencies of X are aligned. However, varying lengths of X (due to different sampling rates) result in different numbers of frequency components, making them unsuitable for input to the network. We design a discrete cosine normalization (DCN) that consists of converting the vibration signal to the frequency domain using the discrete cosine transform (DCT), unifying the number nf of frequency components using a pad or cut, and standardizing the amplitude using the normalization N. The normalized frequency representation Fv \u2208 R1\u00d7nf is obtained by\n$$F = \\begin{cases} N(DCT(X)[0, n_f]), & \\text{if } s \\geq n_f \\\\ N(DCT(X) \\cup [0]_{n_f-s}), & \\text{if } s < n_f \\end{cases}$$\nSignals with sampling rates below nf are zero-padded, while those exceeding nf are cut. To balance computational resources and fault classification accuracy, we empirically set nf = 24000 (more detail in Tab. 3). To enhance training stability, the amplitude of the frequency sequence is normalized to [-1, 1],\n$$N(x) = \\beta \\frac{x}{\\|x\\|_2},$$"}, {"title": "Feature extraction", "content": "To extract the features of vibration signals, we propose a fault diagnosis network (FCN) containing a feature encoder parameterized by \u03b8e and a linear classification layer parameterized by \u03b8c, as shown in Fig. 4. We extract features from the unified vibration signal representation (R2) using three separate convolutional layers with large kernels [45] and no weight sharing. We then transform features by three multiscale channel attention blocks (MSCAB) where the multiscale features are fused using the channel attention module (CAM) [42]. Finally, we use two linear layers for fault classification.\nOur FCN takes unified representation (R) as input and outputs the fault type (P). The shape of P is [1, \u03b3] and \u03b3"}, {"title": "Feature Alignment", "content": "We propose a feature alignment layer to embed vibration features into word embedding, which is an MLP consisting of three linear layers (i.e., l1, l2, 13). The weights of alignment layer is \u03b8\u03b1 = [\u03b8, \u03b8\u03b93], where \u03b8 is the weights of l1&l2 (i.e., two linear classification layers in FCN) and \u03b8\u03b93 is the weights of 13. We use 13 transforms the output P of 12 into the word embedding H\u2082 = reshape(l3(P)), i.e.,\n$$P \\in \\mathbb{R}^{1\\times\\gamma} \\overset{l_3}{\\rightarrow} \\mathbb{R}^{1 \\times l_h} \\overset{\\text{reshape}}{\\rightarrow} H_v \\in \\mathbb{R}^{\\tau \\times h},$$\nwhere T signifies the token length after transformed, h is the hidden size of the LLM.\nThe weight \u03b8\u03b93 of 13 is initialized from the textual descriptions K of all fault categories by\n$$K \\in \\mathbb{T}^{Y \\times 1} \\overset{\\mathbb{E}}{\\rightarrow} \\mathbb{R}^{Y \\times T} \\overset{\\tau}{\\rightarrow} \\mathbb{R}^{Y \\times T \\times h} \\overset{\\text{reshape}}{\\rightarrow} \\theta_{l_3} \\in \\mathbb{R}^{\\tau \\times h},$$\nwhere T stands for the text domain. E and T indicate the embedding layer and tokenizer of the pre-trained LLM, respectively. Using a tokenizer T and an embedding layer E, we generate a word embedding from K, which is then reshaped into the weight matrix \u03b8\u03b93. See Appendix C.3 for more details on initializing weights.\nWe use the pre-trained Qwen2-1.5B [1] as our LLM parameterized by OL, achieving basic human-computer interaction. However, its knowledge of specific domains and generation quality still requires improvement. We used the existing LoRA technique [13] and a general pipeline PEFT [26] for simultaneous fine-tuning of the LLM and our proposed alignment layer, which is detailed in Algo. 1."}, {"title": "Experiments", "content": "We implemented the proposed method using PyTorch [31]. Both pre-training and fine-tuning are performed on a single Nvidia RTX 4090 GPU. For pre-training, comparison trials, and ablation experiments, we used AdamW [24] as the optimizer, and the batch size was set to 1024 for up to 50 epochs of training. Fine-tuning was performed using the existing PEFT [26] library.\nTo evaluate the effectiveness of our method, we provide quantitative comparison results for fault diagnosis, ablation of key components, and a user study to assess the quality of language responses. Other tasks including anomaly detection, maintenance recommendations, and potential risk analysis can be found in Appendix D."}, {"title": "Comparison with Fault Diagnosis Methods", "content": "We compared BearLLM with the following fault diagnosis methods. BearFM [17] and MagNet [36] are intended for diagnosing faults under cross-working conditions, while WDCNN [45], TCNN [6], and QCNN [21] are aimed at handling specific working conditions. Detailed descriptions of these methods can be found in Appendix B. To ensure a fair comparison, we re-implement these methods and test them under the same setup in section 5.1. The results are displayed in Tab. 2.\nOur DCN achieves greater accuracy compared to BearingFM [17] when used with the same FCN (see Fig. 5 (a)). The reason for this enhancement is likely due to BearingFM using absolute values after the FFT of the envelope spectrum. This method captures only the amplitude and ignores crucial phase information. In contrast, DCN leverages real-number computations, which help to reduce potential information loss, and operates in less than 20% of the time required by the comparison method. Combining DCN with MagNet [36] and utilizing aligned data for fusion augmentation has noticeably improved performance on datasets with substantial distribution differences.\nReflected in Tab. 2, the three methods (WDCNN, TCNN, QCNN) lacking data augmentation or alignment indicate strong accuracy on some specific datasets. However, their capacity to manage massive distribution differences is restricted when trained on the MBHM dataset. Including DCN eases the marked overfitting in QCNN [21], leading to a substantial improvement in validation accuracy (see Fig. 5 (b)). Similarly, adding DCN to both WDCNN [45] and TCNN [6] led to higher accuracy. Among all the methods tested, our proposed method achieves the highest accuracy and con-"}, {"title": "Experimental Setup", "content": "We implemented the proposed method using PyTorch [31]. Both pre-training and fine-tuning are performed on a single Nvidia RTX 4090 GPU. For pre-training, comparison trials, and ablation experiments, we used AdamW [24] as the optimizer, and the batch size was set to 1024 for up to 50 epochs of training. Fine-tuning was performed using the existing PEFT [26] library.\nTo evaluate the effectiveness of our method, we provide quantitative comparison results for fault diagnosis, ablation of key components, and a user study to assess the quality of language responses. Other tasks including anomaly detection, maintenance recommendations, and potential risk analysis can be found in Appendix D."}, {"title": "Ablation Experiments and Generalization", "content": "Ablation studies were conducted to further validate the effectiveness of each component in our proposed method. We evaluated the performance by directly using raw timedomain vibration signals (fixed-length segments) as input and removing fault-free channels and residual channels separately and together.\nExperimental results in Tab. 4 demonstrate significant accuracy and generalization drops when using time-domain signals only, further highlighting the efficacy of DCN. Applying the t-SNE, we compared the visualization of output with and without fault-free and residual channels. The blue box in Fig. 6 (b) shows how signal segments from the same dataset cluster closely in the feature space. This indicates that the model first identifies the dataset type before refining fault classification. Conversely, our proposed method, as shown in Fig. 6 (a), reduces inter-dataset differences. The model targets the residual between the query signal segments and the fault-free signal segments, creating a unified feature representation across the varying working conditions, and improving the generalization.\nWe evaluate the generalization ability of our proposed method using zero-shot settings. Among the publicly available datasets employed, JUST [34] and IMS [33] are the largest. We trained on the MBHM(w/o JUST&IMS) dataset, comprising only 35% of the MBHM training data, and performed zero-shot tests on the JUST and IMS datasets separately. On the JUST dataset, our method achieves an accuracy of 90.22% without any fine-tuning. In contrast, the method without fault-free and residual channels achieves an accuracy of only 87.54%.\nFig. 7 (a,b) illustrates a comparison of confusion matrices for zero-shot testing on the IMS dataset [33], with and without fault-free and residual channels. Given that the IMS dataset is unbalanced (most samples are fault-free), the overall accuracy drops slightly from 98.52% to 97.81%. However, the method without two auxiliary channels tends to grossly underestimate the severity. For example, 61% of severe outer ring faults are classified as moderate, and 23% of moderate outer ring faults are identified as minor.\nThe CWRU [2] and XJTU [39] datasets are the only ones that include all ten types of faults. To confirm the potential to create a unified representation, we trained our model on the MBHM(w/o CWRU) and MBHM(w/o CWRU&XJTU) datasets, respectively. We then performed zero-shot testing on the commonly used CWRU dataset, with the results of the confusion matrices displayed in Fig. 7 (c,d). Our method achieves remarkable accuracies of 90.26% and 89.14% on the untrained CWRU dataset for each setting, respectively. This result is even better than some methods trained on CWRU, which shows the generalization of our unified representation method and does not depend on any specific complete dataset for training."}, {"title": "User Study", "content": "Tab. 5 summarizes the outcomes of four different tasks, with users choosing the best outputs from FCN, untuned BearLLM, and fine-tuned BearLLM in blind trials. Notably, in simpler tasks, few users chose the fault code output, while most preferred the natural language output. Fig. 8 illustrates examples of outputs before and after fine-tuning. Appendix D provides further comparisons for various tasks. Fine-tuning did not significantly affect the output of the simple anomaly detection task. In the fault diagnosis task, the model without fine-tuning sometimes missed information on fault severity, an issue that was resolved with fine-tuning. For the two more complex tasks, the fine-tuned model produced more accurate and detailed responses. Our method addresses the challenge faced by non-experts in utilizing maintenance systems due to their complexity, reducing the required level of expertise."}, {"title": "Conclusion", "content": "We propose BearLLM, a novel multimodal bearing health management framework that is the first attempt to unify multiple bearing-related tasks using LLMs, including anomaly detection, fault diagnosis, maintenance recommendations, and potential risk analysis. To build this unified framework, we introduce a prior knowledge-enhanced vibration signal representation for hundreds of different working conditions and construct the first large-scale multimodal bearing health management (MBHM) dataset. Experimental results on nine public fault diagnosis datasets show that BearLLM outperforms state-of-the-art methods, even surpassing those specifically trained on individual datasets. In addition, our frequency domain input alignment and feature extrac-"}, {"title": "Construction of MBHM Dataset", "content": "We perform non-overlapping sampling at equal timing times on nine publicly available datasets, i.e., CWRU [2], DIRG [7], HIT [11], IMS [33], JNU [16], JUST [34], MFPT [10], PU [18], XJTU [39].\nThese datasets typically involve multiple vibration sensors performing simultaneous signal acquisition. These vibration signals reflect different time-domain characteristics (see Fig. 9) due to differences in sensor designations, mounting locations and orientations. We generalize the different sensors as part of the working conditions, i.e., the same working conditions represent the same sensors, speeds, and loads from the same dataset.\nWe collected vibration signals X and fault labels Lv from these datasets as the vibration signal portion of the MHBM dataset (details in Algo. 2) while abstracting the specific working condition information Cinfo into condition index C to facilitate quick indexing of reference vibration signals for the same working conditions."}, {"title": "Generation of Text Responses", "content": "For LLMs, the corpus consists of three parts, i.e., system prompts Xsys, user prompts Xt, and responses Lt. The system prompts and user prompts are taken as inputs and response text is the output of LLM. For all samples, the same system prompt text Xsys is provided:\nAs an expert in bearing fault diagnosis with extensive knowledge in mechanical engineering and failure analysis, you can assess the condition of bearings. Typically, bearing states are categorized as normal, outer ring fault, inner ring fault, and ball fault. These defects are further classified into three levels: minor, moderate, and severe. Based on your description of the bearing state, you will answer my questions concisely and directly, providing only the answer without reiterating the user's prompt or bearing status description.\nWe provide templates Xt for user prompts Xt for each of the four different types of tasks:\n\u2022 Anomaly Detection: Bearing status description: #placeholder%23. Based on the bearing condition description, determine whether the bearing is in a faulty state. Answer yes or no.\n\u2022 Fault Diagnosis: Bearing status description: #placeholder%3. Based on the bearing condition description, identify the type of bearing fault. Bearing conditions are classified as normal, outer ring fault, inner ring fault, and ball fault. All defects are categorized into three levels: minor, moderate, and severe.\n\u2022 Maintenance Recommendations: Bearing status description: #placeholder%23. Based on the bearing condition description, report"}, {"title": "Differences between Ours and Comparative Methods", "content": "Methods to Cope with Single Working Condition\nThe main existing fault diagnosis methods are designed for a single working condition only, and we select several representative methods for comparison. The WDCNN [45] is arguably the most popular diagnostic network, incorporating BatchNorm for fault diagnosis and demonstrating the effectiveness of using larger kernels in the first convolutional layer for improved accuracy. Due to its straightforward architecture, it enjoys widespread application in both practical scenarios and methodological comparisons. The TCNN [6] presents a potential enhancement by adding Dropout techniques and increasing the depth of the network to augment feature learning capabilities from raw data. The QCNN [21] introduced quadratic convolution to the fault diagnosis domain, improving diagnostic accuracy through enhanced nonlinear representational ability within convolutional layers. In contrast to our methods, all of these methods utilize raw vibration signals as input."}, {"title": "MagNet with Data Augmentation", "content": "The MagNet [36] enhanced the mixup data augmentation method, transitioning from a Beta distribution (mixing two distributions) to a Dirichlet distribution (mixing multiple distributions). During training, in addition to a classification head, a discriminator was designed via adversarial training to render the obtained features difficult for correct source domain identification. This process compelled the feature extractor to learn common features across domains. The authors also introduced a self-adaptive screening weight strategy to mitigate the use of feature-deficient samples in the augmentation sample synthesis.\nSimilar to our method, this approach attempts to transform the vibration signal from multiple independent distributions into a smooth single distribution. However, our approach achieves alignment through simple spectral changes, whereas MagNet performs signal mixing in the time domain, which made it difficult to perform effective sample mixing in cases with large distributional differences such as our MBHM dataset."}, {"title": "BearingFM with Data Preprocessing", "content": "The BearingFM [17] employs a resampling strategy to align input signals to the angular domain. This method assumes that the bearing's rotational speed and sampling frequency are known, enabling resampling of the raw signal to a uniform target speed and sampling rate. Subsequently, it utilizes the Hilbert transform and FFT to extract the envelope spectrum of the signal. Finally, further data augmentation is performed through translation and scaling operations on the signal in both the frequency and amplitude axis to model input.\nThe similarity to our method lies in the use of preprocessing techniques to uniformly represent signals with different sampling rates. However, BearingFM requires more a priori knowledge (the RPM value of the test rig is needed) and performs more complex calculations. What's more, the authors take absolute values after the FFT, resulting in a loss of phase information of the vibration signal."}, {"title": "Details of Experience", "content": "Details of Experimental Setup All training and testing were conducted on a Windows 11 system equipped with a Core i7-13700F CPU and a single RTX 4090 GPU. Python and PyTorch [31] versions utilized were 3.11 and 2.3.1, respectively.\nA batch size of 1024 was employed for pre-training, comparison trials, and ablation experiments, with an initial learning rate of 10-4. AdamW [24] served as the optimizer, and the learning rate scheduler was set to ReduceLROnPlateau with parameters patience=150 and factor=0.5. This implies that if the loss did not decrease for consecutive 150 batches, the learning rate would be halved. A maximum of 50 epochs was allowed, and training was considered converged and terminated prematurely if the learning rate fell below 10-7. Fine-tuning was performed using the existing PEFT [26] library.\nPre-training We use the MBHM dataset to pre-train the Fault Classification Network (FCN). To prevent the problem of data leakage, we first randomly divide the data"}, {"title": "More Experimental Results", "content": "The"}]}