{"title": "On the Feasibility of Fully AI-automated Vishing Attacks", "authors": ["Jo\u00e3o Figueiredo", "Afonso Carvalho", "Daniel Castro", "Daniel Gon\u00e7alves", "Nuno Santos"], "abstract": "Abstract-A vishing attack is a form of social engineering where attackers use phone calls to deceive individuals into disclosing sensitive information, such as personal data, finan-cial information, or security credentials. Attackers exploit the perceived urgency and authenticity of voice communication to manipulate victims, often posing as legitimate entities like banks or tech support. Vishing is a particularly serious threat as it bypasses security controls designed to protect information.\nIn this work, we study the potential for vishing attacks to escalate with the advent of AI. In theory, Al-powered software bots may have the ability to automate these attacks by initi-ating conversations with potential victims via phone calls and deceiving them into disclosing sensitive information. To validate this thesis, we introduce ViKing, an AI-powered vishing system developed using publicly available AI technology. It relies on a Large Language Model (LLM) as its core cognitive processor to steer conversations with victims, complemented by a pipeline of speech-to-text and text-to-speech modules that facilitate audio-text conversion in phone calls. Through a controlled social experiment involving 240 participants, we discovered that ViKing has successfully persuaded many participants to reveal sensitive information, even those who had been explicitly warned about the risk of vishing campaigns. Interactions with ViKing's bots were generally considered realistic. From these findings, we conclude that tools like ViKing may already be accessible to potential malicious actors, while also serving as an invaluable resource for cyber awareness programs.", "sections": [{"title": "I. INTRODUCTION", "content": "Social engineering attacks, such as phishing [1, 2], vishing (voice phishing) [3], and smishing (SMS phishing) [4, 5], are particularly dangerous because they exploit human psychology instead of technical vulnerabilities to gain unauthorized access to personal information, financial data, or secure systems. The consequences of such attacks are profound and widespread, resulting in significant financial losses, identity theft, compro-mised corporate security, and a diminishing trust in digital communications [6-8].\nVishing attacks typically involve fraudsters making phone calls to unsuspecting individuals [3], relying on pretexting and impersonation of legitimate entities to manipulate or trick them into disclosing sensitive information [9, 10]. Modern vishing attacks often employ VoIP technology, enabling attackers to spoof caller ID information and reach a global audience with minimal cost and effort compared to traditional telephony. The integration of vishing with other cyberattack techniques, such as phishing emails that prompt victims to call a fraudulent number, has become widespread [11]. Organized cybercrime operates entire scam call centers [9], frequently targeting victims with fabricated IRS demands, tech support frauds, or bank security alerts, to extract sensitive personal and financial information or coerce victims into making payments under false pretenses.\nHowever, with the rapid advancement in AI, there is a growing concern that the sophistication of vishing attacks could escalate. Compared to phishing, its voice counterpart has been noted for a higher success rate [9, 10, 12], but an impaired scalability due to its reliance on direct, one-on-one voice interactions with humans. In contrast, phishing campaigns can easily target thousands of potential victims through broadcast of email messages by software bots. How-ever, with the widespread use of AI models, in particular Large Language Models (LLMs), these dynamics could shift. LLMs have shown an unprecedented ability to generate and interpret human language [13, 14], raising the question of whether they could replace the human operator with an AI-powered software bot in a vishing call. While this development could enable threat actors to deploy such attacks at scale, it would also enable corporations and schools to train individuals more effectively against such threats.\nIn this paper, we present ViKing, a new AI-powered vishing system capable of autonomously interacting with potential victims through phone calls and designed to extract sensitive information during targeted vishing attacks. Deriving its name from a blend of 'Vishing' and 'King', ViKing demonstrates the potential of using readily available AI technologies to develop software bots with dual capabilities \u2013 both offensive and defensive. Built primarily on OpenAI's GPT, our system also incorporates key components such as Twilio, Google Speech to Text, and ElevenLabs to assemble fully automated, AI-powered vishing bots.\nWe implemented and evaluated ViKing through a controlled social experiment, recruiting 240 participants via Prolific. Out of ethical considerations, we devised a scenario in which participants assumed the role of an employee at a fictitious company with access to both sensitive and non-sensitive"}, {"title": "II. GOALS AND THREAT MODEL", "content": "In this work, we hypothesize that AI techniques have reached a level of maturity sufficient to develop Al-powered vishing systems that can automate the deployment of social engineering attacks via phone calls with victims. We aim to create such a system with readily accessible AI technology and use it to investigate four research questions (RQs):\nRQ1 - Can an AI-powered vishing system effectively extract information from victims? We want to assess if the system is able to steer the conversation in order to extract a specific piece of data from the victim.\nRQ2 - Can an AI-powered vishing system be perceived as trustworthy by humans? We aim to determine if the system's behavior can elicit a positive response from the victim, making them more susceptible to the attack.\nRQ3 - Can an AI-powered system sound and feel like a real person in a phone call? We intend to show if the"}, {"title": "III. VIKING", "content": "This section presents the design and implementation of ViKing, a new AI-powered vishing system capable of auto-matically initiating a phone call with a victim and engaging in dialogue to persuade them to disclose information.\nA. Architecture\nFigure 2 depicts ViKing's architecture, which is structured as a pipeline linking several key components: (i) a telephony interface for initiating calls and handling the corresponding media streams; (ii) a speech-to-text (STT) service tasked with"}, {"title": "B. Interaction with the LLM", "content": "The LLM plays an essential role in ViKing's cognitive processing of the data exchanged with the victim over a phone call. Its primary role is to analyze, interpret, and generate human-like responses based on the transcribed text received from the audio processing component. However, choosing and customizing an LLM for our system to perform this function is not trivial because, as explained next, its effectiveness is highly dependent on this component.\nChoosing the LLM: The selected LLM for ViKing must be able to produce responses that are not only contextually"}, {"title": "C. Audio processing", "content": "STT and TTS processing components enable ViKing to interact with victims in real-time through telephonic conver-sations. While both components present unique challenges to ensure seamless and realistic interactions, reducing the delay between the end of the victim's speech and the beginning of the playback of the synthesized speech is paramount.\nSTT: The speech-to-text capability is crucial for converting the victim's spoken words into text, which is then fed into ViKing's LLM. We faced two primary challenges with the STT module: (i) ensuring real-time transcription without noticeable delays, as any lag in response could jeopardize the realism of the conversation; and, (ii) ensuring it could detect when the victim stopped speaking, in order to then forward the transcription to the cognitive processing unit.\nMany STT solutions are available, including local mod-els [19, 20] and online services [21, 22]. For ViKing, we adopted Google's Speech to Text [21] service, which has the capability to work in real-time, thus resulting in little delay between the end of victim's speech and the final transcription. Moreover, it is trained specifically for telephonic conversa-tions. Additionally, its capability to detect speech endpoints was crucial in maintaining a natural conversation flow. This ability to recognize when a speaker had finished speaking allowed us to avoid manual logic for detecting speech pauses, thus streamlining the process.\nTTS: The text-to-speech capability is crucial for converting the generated text responses back into speech, which is vital for maintaining the illusion of a real conversation. The main challenge for this module is finding a balance between voice quality and synthesis speed, as realistic speech takes longer to synthesize. Although minimal delays are a general requirement across the entire system, this is particularly true for TTS, as it is one of the tasks with the longest duration.\nThere are many TTS systems available, both as local models [23-27], and as cloud services [28, 29]. We opted for ElevenLabs [29] due to its balance between voice quality and synthesis speed. It also includes several options to reduce the delay of the process as much as possible, including fine-tuning parameters of voice realism, and the capability to work in real-time in the form a FIFO queue, constantly synthesising results as they come from the LLM. We used ElevenLabs' pre-made voices, as we found their extensive library more than enough for our use cases."}, {"title": "D. Call processing", "content": "We had several requirements for processing phone calls, as this is the main interface between ViKing and its victims.\nTelephony: Telephony component serves two critical func-tions: acquiring a publicly credible phone number and man-aging phone calling services. The public phone number is key for establishing initial trust, as numbers that appear local or familiar are less likely to raise suspicion. Twilio [30] was selected for its extensive range of available phone numbers and its capability to facilitate bidirectional media streaming through WebSockets, which is crucial for both receiving audio from phone calls and transmitting synthesized responses.\nEnd of call: In order to prevent an everlasting phone call, it was important to give ViKing the ability to detect when it should hang up. For this, we gave the LLM the task of outputting a specific string when it felt that either the objective was fulfilled or the phone call was going nowhere. Afterwards, in the pipeline from the LLM to the TTS, we added an if condition to search for this string \u2013 if it was detected, it would instruct the telephony to hang up the call.\nSynchronization: LLMs are not designed to receive streaming inputs. Therefore, we needed a mechanism to prevent feeding"}, {"title": "E. Implementation", "content": "To facilitate scaling and enable our system to run multiple bots in parallel, we implemented ViKing as a distributed system. This setup features several workers, each responsible for conducting vishing calls. Each worker is assigned an individual phone number acquired through Twilio. In addition, there is a master service tasked with continuously querying the workers to identify those available for initiating new calls. To launch as many workers as required, we deployed them as Docker containers.\nWe implemented a full prototype of ViKing's software in JavaScript for Node.js for the worker, as we found it had better integration with our third-party services, and Python for the master service. We wrote approximately 1000 lines of code 750 in JavaScript for the worker, and 250 in Python for the master. We used GPT model \u2018gpt-4-1106-preview', ElevenLabs model \u2018eleven_turbo_v2' and Google Speech to Text model 'phone_call'. ViKing ran on a local server equipped with 2 Intel Xeon Gold 5320 CPUs, 128GB of Memory and an NVidia RTX A4000 GPU."}, {"title": "IV. EVALUATION METHODOLOGY", "content": "In this section, we present our methodology to investigate the research questions introduced in \u00a7II using ViKing in a con-trolled environment. We detail the experiment design (\u00a7IV-A), ethical precautions of our study (\u00a7IV-B), and the experiments effectively performed to perform our study (\u00a7IV-C).\nA. Experiment design\nTo evaluate ViKing, we must conduct vishing calls with potential victims, which introduces two major challenges. First, deploying our system to extract sensitive data from real individuals is ethically untenable. Second, running tests with a controlled volunteer group is not trivial, as we cannot use participants' personal information or fully disclosure the study's true intent given the need to employ deception to effectively assess our tool's success in mimicking vishing attacks. This level of openness could influence their responses to ViKing calls, thus affecting the validity of our results.\nStaged scenario: To address these challenges, we recruited a group of voluntary participants to partake in a simulated scenario. Participants were assigned the role of a character, specifically a secretary for a fictitious company named Inno-vatech Solutions. They were provided with a mix of sensitive and non-sensitive information pertaining to the company and tasked with handling external phone calls, assisting potential customers or third-parties. These calls were made by ViKing bots, but participants were not informed that the calls were AI-automated, nor were they made aware of the callers' true intentions. This approach allowed us to (i) consistently use fictitious data, (ii) assess the effectiveness of vishing attacks without participants knowing whether the caller had malicious or benign intentions, and (iii) observe whether (and when) they could discern that the caller was not human.\nProvided information: To interact with the callers, we gave participants a mix of public and sensitive information. The public information includes: (i) the name of the company and its public contacts; (ii) some financial information, such as annual revenue, Tax ID, and Innovatech's bank name and corresponding IBAN; (iii) opening and closing hours; (iv) a general description of each of Innovatech's service lines; and (v) Innovatech's address. The sensitive information consists of: (i) the names, positions, and direct phone numbers of several employees, including high-profile individuals such as the CEO, CFO, Marketing Manager, IT Manager, and Sales Representative; (ii) the secretary's username and password for the company's information system; and (iii) the secretary's social security number (SSN). If stolen, this information could be used by malicious actors for nefarious purposes, such as proceeding with further smishing/vishing, identity theft schemes, or harassment campaigns [31\u201333].\nPhone calls: To establish a baseline of willingness to disclose information to ViKing, we chose to perform three phone calls, each from a different caller, with their own needs/goals, tone and personality. One out of the three calls had a malicious intent while the others portrayed benign interactions. The order in which the calls were performed was randomized for every participant. In the malicious call, ViKing could either attempt to trick the participant into (i) divulging Innovatech's CEO's personal phone number by impersonating a partner company's CEO, (ii) divulging the secretary's username and password by impersonating an IT support specialist from Innovatech, (iii) divulging the secretary's SSN by impersonating an HR representative from Innovatech. During the benign calls, our system either played the role of a DHL courier asking for public information in order to deliver a package or a different company's representative enquiring about a possible partner-ship and public financial information. Playing specific roles was done by switching between three personas (\u00a7III-B). In"}, {"title": "Participant session workflow", "content": "To facilitate interaction with the participants, we developed a simple web application using Node.js, the Pug template engine, and a SQLite3 database. We hosted this application on our own servers and made it accessible via an Ngrok tunnel. The interaction with each participant was conducted through this web application across three phases. An introduction phase initiated with each par-ticipant's entry into the experiment, covering: (i) disclosure of the study's terms and conditions and acquisition of the participant's consent; (ii) collection of relevant profiling infor-mation (e.g., gender, age, technological proficiency), a valid phone number for ViKing calls, and the participant's name for allowing ViKing to address individuals by name as required; and (iii) an overview of the experiment scenario, including a one-minute instructional video. Participants proceeded to a voice call phase only after viewing the video in full. Then, participants received three calls from our ViKing bots, responding as they saw fit, with uninterrupted access to the fic-titious company's details. Each call had a maximum duration of ten minutes. Lastly, in a feedback phase the participants filled three forms: (i) Form 1 has ten questions to gauge the tool's perceived trustworthiness and social skills \u2013 participants were unaware at this stage that the calls were AI-generated; (ii) Form 2 has nine questions, aimed to measure ViKing's perceived realism after informing they had interacted with an automated system; and (iii) Form 3 allows open comments.\nData discretion: To evaluate whether participants' knowledge about the nature of the study influenced their reluctance to disclose sensitive information, we organized four distinct sets of experiments, termed as waves. In each wave, we enlisted a different group of participants and incrementally disclosed more warnings on the risks of revealing sensitive data to unfamiliar callers. To this end, we tailored the instructions for each wave to mirror four levels of discretion:\nLevel 1 - minimal caution: In the first wave, we only told subjects to role-play as a secretary and be professional.\nLevel 2 \u2013 moderate alert: In the second wave, we further mentioned to consider that secretaries should not disclose sensitive or confidential information to unknown callers.\nLevel 3 - heightened awareness: For the third wave, we included examples of sensitive information that secretaries should not disclose (e.g., direct phone numbers, employee names and addresses, SSNs, passwords).\nLevel 4 \u2013 maximum vigilance: In the final wave, we used another video that: (i) reinforced that secretaries should be careful when sharing information with others, and (ii) informed that Innovatech had been a victim of social engineering attacks via phone calls, and its employees had the responsibility to protect its information.\nRecruitment platform: To recruit the participants at scale, we adopted a crowdsourcing participant recruitment platform and considered several different services, including Amazon Me-"}, {"title": "Pilot studies", "content": "To streamline our methodology, we conducted three pilot studies: one within our research group and two with smaller volunteer groups via Prolific. The initial pilot focused on fine-tuning the LLM parameters and prompt engineering, helping us adjust the prompt template and tailor response lengths for phone calls. Subsequent pilots refined the clarity of instructions and videos, as well as question clarity, response options, questionnaire ordering, and experiment stage sequenc-ing. Key methodological adjustments from the pilots included: (i) reducing instruction verbosity and enhancing video clarity; (ii) limiting response options to five, representing degrees of a specific quality to ensure ordinality where possible; and (iii) excluding questions perceived as confusing. In the final questionnaire setup, we keep control questions to assess closely related properties."}, {"title": "Role playing considerations", "content": "As described above, we em-ployed a role-playing methodology to evaluate ViKing, al-lowing us to use mock-up data rather than real sensitive data in our experiments. To reduce the risk of introducing bias among participants, we adopted a three-fold strategy: we described the tasks objectively in the instructions page of our study, encouraged professional interactions with clients, and emphasized the importance of upholding confidentiality in line with standard business practices."}, {"title": "B. Ethical considerations", "content": "In developing and operating ViKing, we placed a strong em-phasis on ethics. The whole project, including the design of the experiments, recruitment of participants, management of data, and publication of results, was carried out with the guidance and approval of our Institutional Review Board (IRB). All par-ticipants in our study volunteered through Prolific, adhering to its Terms of Service. Our IRB followed established guidelines on using deception and not fully disclosing information in research [40]. We also abided by Prolific's recommended best practices for studies involving deception and handling personal data [39].\nDuring the vishing attacks conducted by our bots, we did not collect any real personal information from the participants. The personally identifiable information (PII) we did gather was solely for the purpose of characterizing the participants' pro-files for the study, including their names and phone numbers to facilitate the attacks. No further PII was collected. To ensure the participants' privacy, all collected PII was anonymized"}, {"title": "C. Characterization of participants", "content": "Table I provides a detailed breakdown of all the volunteers who interacted with us via Prolific, a total of 1099. From these, we ultimately selected 240 suitable participants evenly distributed across four experimental waves. Each wave in-volved 60 participants (20 per target information), facilitating a consistent analysis of the experiment's outcomes under different conditions. The experiments for each wave were conducted sequentially. Before initiating the next wave, we reviewed the participation of each volunteer to either accept or reject it. Participants could only take part once in our study and were excluded from further waves.\nA total of 801 volunteers did not complete the study. The majority (71.06%) were classified as \u2018Returned' indicating they began the study but exited without submitting their responses. Our logs indicate that these participants begin interacting with the webpage only after several minutes have elapsed. This delay could be due to participants opening multiple research studies simultaneously to \"reserve\u201d them, and then proceeding to engage with each one sequentially. A minimal fraction of volunteers (1.82%), also having not concluded, were marked as \u2018Timed-out' meaning they failed to complete the experiment within one hour.\nFrom the 298 participants who completed the experiment, we rejected 38. Those who either did not complete all three phone calls or failed to fill out the forms were labeled as 'Incomplete' (1%). Those who finished the calls and the forms but disregarded the experiment's guidelines were deemed 'Low Effort' (0.6%). Participants who let the call go to an answering machine, were tagged as 'Answering Machine' (1.8%). Ultimately, 260 experiments were approved, but we further excluded 20: 19 due to technical issues and one that was mistakenly approved.\nThe 240 selected participants represent a diverse mix across various demographic and professional dimensions. The distri-bution is slightly imbalanced in favor of female participants, at 56.25%. Average participant age is 37 years, spanning from 18 to 68 years old. There is a wide range of academic qualifica-tions although a significant portion of participants completed either high school (32.92%) or bachelor's degrees (45.83%). Technical proficiency is high, with 95% rating themselves as competent, proficient, or experts. Detailed information is given in the Appendix (Table VIII)."}, {"title": "V. EVALUATION RESULTS", "content": "In this section, we present our evaluation results. Our goals are the following: to evaluate the tool's effectiveness on performing successful vishing attacks on unsuspecting victims (\u00a7V-A); to assess the victims perception of the bot as a trustworthy actor or not (\u00a7V-B); to evaluate the realism of ViKing in a voice interaction with a human (\u00a7V-C); and, to assess the tool's costs in launching vishing attacks (\u00a7V-D).\nA. Can an Al-powered vishing system effectively extract in-formation from victims?\nTo assess ViKing's effectiveness in extracting information from potential vishing attack victims, we reviewed the dia-logues between the bots and participants and quantified the number of instances in which the bot extracted sensitive information for each of the designed scenarios. In Figure 3, we present the success rate of our system across all scenarios per wave. Next, we discuss these findings and offer insights into ViKing's capability to gather information, as derived from our analysis of the conversations with participants.\nIn total, 52% of participants disclosed sensitive informa-tion: Across all waves, ViKing persuaded 124 out of 240 participants to reveal sensitive information, which could be the CEO's direct phone number, the secretary's username and password, or the secretary's SSN, depending on the used attack scenario. To understand the reasons behind the unsuccessful attempts, we analyzed the participants' responses and discov-ered that most failures were due to the participants' reluctance to disclose the sensitive information. Table II identifies the four primary reasons. Predominantly, in 25.83% of calls,"}, {"title": "Longer calls led to slightly lower success of attacks", "content": "Performing a logistic regression, we identified a statistically significant and slightly negative effect of conversation duration in seconds on attack success ($\\beta = -0.0224, p < 0.001$). This finding indicates that as the length of the conversation increases, the likelihood of a successful attack decreases. It suggests that longer conversations may provide targets with more chances to detect and counteract vishing attempts."}, {"title": "Word spelling by the participants negatively impacted the attack effectiveness", "content": "Our analysis revealed a technical diffi-culty with ViKing in handling conversations where participants spelled out words. In such cases, ViKing often interrupted and processed the incomplete answer as final, requiring the infor-mation to be repeated. This issue arises because humans often spell out complex words or large numbers, like passwords or SSNs, character by character and in irregular intervals. Notably, all attack scenario calls with this problem involved either a password (Inn0V4t3CH) or an SSN (324125748). Although this occurred in only 45 out of 720 calls, and just 15 were attack scenarios, it was statistically significant and suggests the need for further improvements in the AI pipeline. Specifically, the password scenario was significantly impacted by these difficulties, as it demonstrated a clear relationship between calls with spelled words and unsuccessful attacks ($\\chi^2 = 5.08, p = 0.024$)."}, {"title": "The success rate of the attack dropped significantly but is not entirely mitigated as discretion levels increase", "content": "As illustrated in Figure 3, the success rate of ViKing attacks decreased as we provided participants with progressively more explicit instructions on the protection of sensitive information. In the first wave, when participants were simply instructed to role-play as a secretary acting professionally, 46 out of 60 par-ticipants disclosed fake sensitive information to ViKing bots, revealing a general inclination among participants to prioritize perceived job responsibilities over safeguarding sensitive in-formation. As instructions and warnings became more explicit, the number of participants disclosing sensitive information declined, especially in waves 3 and 4 (see Table II). A chi-squared test of independence ($\\chi^2 = 28.43, p < 0.001$) shows a strong association between the wave number and the attack success rate. A logistic regression revealed a significant neg-ative effect of wave number on attack success ($\\beta = -0.642, p < 0.001$), thus, confirming this decreasing trend.\nWhile these findings underscore the importance of sustained training and awareness programs in enhancing cybersecurity defenses, 20 out of 60 participants (33%) in wave 4 have still disclosed sensitive information, suggesting the need to develop more effective defenses against such attacks.\nAcademic qualifications, gender, age, and profession had no statistical significance on the attack effectiveness: Our"}, {"title": "A favorable initial impression of ViKing significantly influences the success of the attacks", "content": "To analyze the influence of initial impressions on the success of vishing attacks, we used both the chi-squared test of independence and logistic regres-sion. When participants were asked, \u201cHow would you describe your initial impression of the caller?\" in question Q1, better impressions were linked to more successful attacks. The chi-squared test showed a trend towards significance ($\\chi^2 = 8.87, P = 0.064$), indicating a potential association between the initial impression and attack success. More robustly, logistic regression demonstrated a significant positive effect of the ini-tial impression on attack success ($\\beta = 0.317, p = 0.017$). This suggests that a more favorable initial impression substantially increases the likelihood of a successful vishing attack.\""}, {"title": "B. Can an Al-powered vishing system be perceived as trustworthy by humans?", "content": "To determine if ViKing is perceived as trustworthy, we analyzed the responses given by participants to Form 1, the initial questionnaire consisting of 10 questions that we asked them to complete after the voice call phase (see \u00a7IV-A). To ensure unbiased responses, Form 1 was administered without explicitly informing participants they had been interacting with an AI-powered vishing system. To illustrate our findings, Figure 4 shows a subset of questions that received numeric answers, simplifying interpretation on a scale from 1 to 5 (with 5 being the highest rating), and in Table III, we display the remaining questions from Form 1 that elicited qualitatively richer responses. The full set of questions and their responses is available in the Appendix (Table IX).\nViKing's credibility and trustworthiness was considered average or better by 68.33% of participants, and it related to higher chances of successful attacks: In Q5 (see Figure 4), 68.33% rated their interlocutor between 'neutral' (grade 3) and 'highly credible' (grade 5), with 46.25% giving above-average scores (32.5% for grade 4 and 13.75% for grade 5). Feedback on Q6, about comfort level in sharing information, aligned with this finding, with 41.67% giving above-average responses. Participants also had favorable impressions of the caller (Q1) and found the conversation mostly natural (Q3), with neutral emotional responses in Q9 and Q10. The Mann-Whitney U Test, which was used because we are dealing with a 5-point Likert scale that we considered to be purely ordinal, which prevented the usage of parametric tests, showed significant differences in responses to Q5 and Q6 between successful and unsuccessful attack victims, confirming the association between positive perceptions of ViKing and higher attack success rates (U = 9183.5, p < 0.001 for Q5, U = 9661.0, p < 0.001 for Q6). This suggests that attackers who quickly build trust and ease are more likely to succeed."}, {"title": "C. Can an Al-powered system sound and feel like a real person in a phone call?", "content": "To evaluate the realism of ViKing's phone calls and their success in emulating a real person, we examined the feedback from Form 2 and the comments and suggestions participants provided in Form 3. Both these forms where filled by the participants after being informed they had been interacting with AI-powered bots. The insights from Form 2 are depicted in Figures 5 and 6: Figure 5 illustrates responses to questions 1 through 8, while Figure 6 is dedicated to question 9. More de-tails can be found in the Appendix (Table X). We also curated a selection of ten insightful comments and suggestions from Form 3, and listed them in Table IV. Overall, our experiments garnered positive feedback, receiving compliments for the engaging dialogues and proficient management of interactions. User experience when interacting with ViKing was deemed realistic by 62.92% of participants: Responses to Q7 in Figure 5 show that 42.5% of participants classify their ex-perience with our system as 'comparable' to typical phone conversations with real people. A further 20.42% grade the interactions with the system higher than those with humans. Finally, 37.08% of responses rate their experience as worse. The fact that 62.92% perceive calls with ViKing to be on par with or better than interactions with humans highlights the potential of AI-powered vishing systems, as well as the existence of considerable scope for enhancement. Nonetheless, the participants' recognition that they were engaging with AI 82.08% recognized this either immediately or after a few exchanges (Q8 in Figure 5) \u2013 suggests a need for creating a more seamless and human-like interaction.\nViKing's effectiveness in responding to questions stood out, with 71.25% rating it as 'mostly' or 'very effective': Participants acknowledged our tool's effectiveness in handling queries, as indicated by their responses to question 4. A substantial 71.25% rated the ViKing's ability to respond to questions as 'mostly' or 'very effective' (grades 4-5). This feedback aligns with the qualitative comments, such as C1 in Table IV, where a participant highlighted our tool's com-petence in sustaining engaging conversations and lauded the quality of these interactions. This particular comment also mentions how the system is able to engage its interlocutor with original information instead of 'mirroring' them.\n78.76% of participants rated ViKing's responses as highly appropriate: Contextual appropriateness emerged as a notable strength of our system, evident in responses to question 5, as 78.76% of participants classified the AI's responses from 'rarely inappropriate' to 'always appropriate and in context' (grades 3-5). This is further emphasized by the fact that grade 5, the maximum possible classification, was the most common answer to this question, at 35.42%. The qualitative feedback reflects the participants' positive experiences. Comments like C2 and C3 show how the participants felt impressed at ViKing's ability to handle information and use it to engage them in the conversation.\nViKing's performance was generally robust: Technical performance was gauged by question Q6, where 82.92% of participants reported 'very few' or 'no technical issues' (grades 4-5). This emphasizes the robustness of the system in delivering a glitch-free and smooth user experience during the experimental phase. Given that technical issues, independently of severity, can compromise ViKing's realism and its ability to deliver the intended results, the fact that only 61.67% of participants encountered no such problems reveals a clear improvement path for the system.\nAchieving complete voice realism remains a challenge, but relates to higher chances of a successful attack: Voice real-ism proved challenging, as indicated by participant responses to Q1 and Q2. A significant 34.59% of participants felt that the AI voices were \u2018mostly' or 'completely' artificial (grades 1-2). Further analysis reveals a notable impact of perceived voice realism on attack efficacy. Responses to question Q1 showed a statistically significant difference between successful and unsuccessful attacks, indicated by the Mann-Whitney U test (U = 8742.0, p = 0.0026). This suggests that higher voice realism correlates with increased success rates. For question Q2, the results were marginally non-significant (U = 8187.0, p = 0.0524), showing a trend where higher believability is associated with successful attacks. Spearman correlation analysis further supported this, demonstrating a modest but significant positive correlation between perceived voice quality and attack success (p = 0.1950, p = 0.0024) and a similar"}, {"title": "D. What are the operating costs of an Al-powered vishing system?", "content": "We now analyze the economics of operating ViKing. We start by detailing all the costs associated with conducting our experiments", "0.59": "Table V reports the costs that we incurred in the experiment with participants. The total cost of $1", "diverse": "vishing calls ('Vishing Attempts' column) are much shorter than the average call.\nFor an attacker", "call": "Table VI also reports the incurred costs per call. For reference, we present the service prices in the Appendix Table VII. We observed that the average cost (95% confidence interval) of a vishing call is $0.385 (+$0.02), irrespective of the attack's outcome. We have omitted the recurring costs that become negligible over a high volume of calls, such as"}]}