{"title": "Oracular Programming", "authors": ["Jonathan Laurent", "Andr\u00e9 Platzer"], "abstract": "Large Language Models have proved surprisingly effective at solving a wide range of tasks from just a handful of examples. However, their lack of reliability and modularity limits their capacity to tackle large problems that require many steps of reasoning. In response, researchers have proposed advanced pipelines that leverage domain-specific knowledge to chain smaller prompts, provide intermediate feedback and improve performance through search. However, the current complexity of writing, tuning, maintaining and improving such pipelines has limited their sophistication. We propose oracular programming, a foundational paradigm for building LLM-enabled applications that lets domain experts express high-level problem-solving strategies as programs with unresolved choice points. These choice points are resolved at runtime by LLMs, which generalize from user-provided examples of correct and incorrect decisions. An oracular program is composed of three orthogonal components: a strategy that consists in a nondeterministic program with choice points that can be reified into a search tree, a policy that specifies how to navigate this tree with the help of LLM oracles, and a set of demonstrations that describe successful and unsuccessful search tree navigation scenarios across diverse problem instances. Each component is expressed in a dedicated programming language and can be independently improved or substituted. We address the key programming language design challenges of modularly composing oracular programs and enforcing consistency between their components as they evolve.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) trained on vast corpora of text, such as GPT-4 [15], have demonstrated remarkable capability in learning new tasks from a handful of examples and generating complex, structured data [2]. These models have driven breakthroughs across a wide range of problem areas, including reasoning-intensive domains like program synthesis [13], mathematical problem-solving [12] and formal theorem proving [4, 7]. Still, their lack of reliability and their propensity to hallucinate have limited their practical impact and their ability to tackle large problems that require combining many steps of reasoning without error. In response, researchers have proposed integrating LLMs into software pipelines that leverage domain-specific knowledge to decompose complex tasks into smaller prompts [20], provide intermediate feedback through external tools or separate LLM critics [23, 24], and improve reliability through search and validation [12, 23].\nAt first glance, developing such pipelines may seem deceptively simple. After all, LLMs can be prompted through straightforward APIs, and developers have access to the full arsenal of existing programming languages and software-engineering tools to build sophisticated systems on top of them. However, developing LLM-enabled software raises unique challenges that we argue are not properly addressed by existing programming abstractions:\n\u2022 LLMs offer a powerful but inherently unreliable programming primitive, making the ubiquitous use of search and validation essential for ensuring dependability. At the same time, prompting an LLM is an expensive operation, making retrials and backtracking particularly costly. Resolving this tension requires the careful tuning of this search logic, which must also be adaptable to user-specific constraints (e.g. inference budget, latency tolerance...). Evolving this logic can require costly and frequent refactorings, especially when it is intertwined with the higher-level logic that specifies how large problems are decomposed into smaller problems and prompts."}, {"title": "2 Overview", "content": "Let us illustrate the key concepts of oracular programming using a simple but relevant example.\nStrategies and Trees. Figure 1 shows a simple strategy for the problem of program synthesis named generateProg. Concretely, generateProg is a nondeterministic program that takes a specification as an argument and returns a program that respects it. To do so, it proceeds in several steps. First, it conjectures a program. Then, it reflects on this program, determining a likelihood that the program indeed respects the specification. After that, it generates a machine-checkable proof establishing that the program is correct, and verifies this proof. If the proof is verified as correct, the program can be returned. In turn, the first conjecturing step is implemented via a separate strategy named conjectureProg . Given a specification, this strategy conjectures a correct program by generating executable unit tests, producing a program and then returning it if it passes every test.\nOnce its arguments are instantiated, a strategy such as generateProg can be reified into an infinitely-branching search tree. Calls to the branch operator induce branching nodes. A strategy can branch over the result of another strategy (e.g. conjectureProg ) or over the result of a query (e.g. ProveProg, ProposeTests ...). A query is an object that denotes a question being asked to an external oracle. For each query type, one must define two prompting functions along with a parsing function for converting raw textual answers to values of suitable type. The systemPrompt function generates a textual description of the general class of questions associated with a query type (e.g. \u201cGiven a program and a specification, estimate the likelihood that the program matches the specification. Answer with a real number in the [0, 1] interval.\u201d) while the instancePrompt function generates a textual description of a specific query instance (e.g. a labeled code block containing a program followed by a labeled code block containing a specification). This separation between"}, {"title": "Policies", "content": "As illustrated in Figure 2, a policy specifies how the search tree induced by a strategy should be navigated, with the help of one or several LLMs. The structure of a policy reflects the modular structure of the associated strategy. More precisely, a policy is defined as a pair of a search policy and of an inner policy. The search policy describes an algorithm for navigating the top-level tree (e.g. depth-first search, breadth-first search, best-first search, MCTS...) while the inner policy recursively specifies a policy for every sub-strategy, along with a prompting policy for each query.\nA prompting policy describes how a query should be answered: which LLM should be used, how the prompt should be formed, how many answer attempts should be made... One standard prompting policy is few-shot prompting, where the prompt features a series of examples that answer queries of the same type. These examples are themselves extracted from demonstrations, as we discuss shortly. The prompt is formed by concatenating the system prompt of the query, the instance prompt for each example along with the associated answer, and finally the instance prompt of"}, {"title": "Demonstrations", "content": "Few-shot prompting depends on the availability of examples. We propose a dedicated language for writing, organizing and maintaining such examples with minimal effort in the form of demonstrations. A demonstration bundles a set of query answers with a sequence of unit tests that describe concrete scenarios of navigating a specific strategy tree using these answers, thereby ensuring their relevance and consistency with the associated strategy. An example of a demonstration is shown in Figure 3 for the generateProg strategy. It ends with a queries section that contains one or more answers for a sequence of queries. Answers can be attached optional labels and tagged according to whether or not they are eligible to being used as examples for few-shot prompting.\nEach test describes a path through the search tree and can either succeed or fail. Also, each test is composed of a sequence of instructions that are chained together using the | pipe operator. The first test ( run | success) ensures that the provided examples are sufficient for solving the particular problem instance that the demonstration is about. The run instruction can be informally interpreted as \u201cwalk through the tree, using the first listed answer as a response every time a listed query is encountered\" ; the success instruction checks that the node at the end of this path is a success leaf. The second test demonstrates how to recover from a suboptimal choice by assigning it a low value. The at EvalProg \u2018wrong\u2018instruction is similar to run, except that the answer labeled wrong must be selected when applicable and navigation must stop upon reaching a node associated with a query of type EvalProg ;the answer instruction ensures that this query is answered in the demonstration. Since the answer labeled with wrong is not optimal and only included for the purpose of demonstrating how to reflect on a bad choice, it is marked as unsuitable for use as an example. Finally, the third test aims for a full walk through the tree, selecting the wrong -labeled answer when appropriate. However, it hits a query that is not listed in the demonstration and thus fails as stuck, providing the user with appropriate information on what query must be answered for navigation to proceed. With proper tooling, this mechanism allows writing and repairing demonstrations interactively. Section 3.3 motivates and discusses our proposed demonstration language in detail, emphasizing the empirical observations that it is based on and the evolvability guarantees that it provides."}, {"title": "3 The Oracular Programming Triad", "content": "This section justifies and describes the design of the three languages that, together, form the triad of oracular programming. In particular, we define a strategy and a policy language via shallow embeddings in Haskell. Haskell is a good candidate for a host language, because of its expressive type system and of its syntactic facilities for expressing monadic code. A Python embedding is also discussed in Section 4, as we introduce our Delphyne framework."}, {"title": "3.1 The Strategy Language", "content": "Reifying nondeterministic programs as search trees is not a new idea, but it has arguably failed to meet its potential as a programming paradigm so far, in the absence of a systematic way of producing oracles to navigate the resulting search spaces at scale. Our suggestion of using large language models for this role is a key contribution of this paper. Beyond this, our proposed strategy language innovates significantly on classical implementations of nondeterministic programming by addressing the key challenges of modularity and extensibility. To better convey this point, we first explore a naive design based on well-known techniques and showcase its limitations."}, {"title": "3.1.1 An initial design attempt", "content": "A strategy is a nondeterministic program that can be reified into a (possibly infinite) search tree. Let us consider the following initial definition for such a tree:"}, {"title": "3.1.2 A Modular and Extensible Strategy Language", "content": "The generateProg strategy shown in Figure 1 has type Strategy '[Branch, Fail, Value] GPIP Prog. The last type argument indicates its return type, which is the type of values attached to the success leaves of the induced tree. The first argument indicates its signature, which is the list of effects that it is allowed to invoke. Finally, the second argument indicates its associated inner policy type. Every strategy must be associated an inner policy type, which reflects its modular structure and defines the shape of compatible inner policies. Inner policies recursively specify prompting policies and search policies for all inner queries and strategies. The inner policy type for generateProg is named GPIP and is defined in Figure 2. It is a record type with field cp for the search policy and inner policy associated with inner strategy conjectureProg, ep for the prompting policy associated with inner query EvalProg, and pp for the prompting policy associated with inner query ProveProg. The branch and value operators take opaque search spaces as arguments. An opaque search space can be seen as a map from an inner policy to a search stream. It can be defined from either a query or a strategy, although this implementation detail is deliberately kept hidden from search strategies for the sake of modularity."}, {"title": "3.1.3 Strategy Trees", "content": "A strategy induces a search space in the form of a strategy tree. A tree consists of either a success leaf that carries a value or in a node associated with some effect. The list of effects allowed inside a tree constitutes its signature. Each node features an action type along with a family of children trees indexed over this type. Actions cannot be built directly but only assembled by combining elements belonging to some nested spaces attached to the node. A space is either associated a query or another tree, possibly with a different signature. For example, both Branch"}, {"title": "3.1.4 References and Tracked Values", "content": "We provide formal type definitions for references and tracked values in Figure 10. References play a key role in defining the concept of a trace, which is central to our proposed demonstration language (Section 3.3). Any element of the search space defined by a tree can be recomputed from its reference, using the successValue function (Line 27). A node"}, {"title": "3.1.5 Queries", "content": "A query is an object that represents a question being asked to an oracle. Queries can be classified according to their type. A query type is defined as an arbitrary Haskell datatype that implements the Query type class defined in Figure 11. This definition differs slightly from the simpler version that is used implicitly in the Overview section (Figures 1 and 2) for simplicity. Each"}, {"title": "3.2 The Policy Language", "content": "An oracular program is defined by three components: a strategy, a policy and a set of demonstrations. The previous section explored the first component, defining a language for expressing high-level problem-solving strategies as nondeterministic programs that can be reified into search trees. We now focus on the definition of policies that navigate such trees with the assistance of LLM oracles."}, {"title": "3.2.1 The Search Stream Protocol", "content": "Modularity requires a shared protocol that allows heterogeneous search algorithms to cooperate. For example, in our example from Figure 1, the generateProg strategy leverages another strategy conjectureProg to produce program candidates. Both strategies can invoke different effects and be associated independent policies. For example, the former may use best-first search while the latter may use depth-first search.\nAs a first approximation, a search policy (e.g. dfs from Figure 2) maps a search tree to a lazy stream of tracked values. Thus, an outer policy can generate elements of an opaque nested space on demand. However, it is typically undesirable for an outer policy to yield full control to an inner one until the latter successfully generates an element, which may never happen. Thus, finer-grained control is required. Policies must be allowed to make interleaved calls to inner policies and allocate a specific search budget every time a new attempt is made to generate an element of a nested space."}, {"title": "3.2.3 Assembling Policies", "content": "Although our framework allows writing search and prompting policies from scratch, it is more convenient to assemble them by instantiating and combining standard building blocks: LLM querying, RAG-based example selection [5], depth-first search, breadth-first search, MCTS [3], budget limits, majority voting [20]... Building blocks of par-ticular interest are tree transformers, which can alter a tree signature so that it can be used with a specific pol-icy. For example, a strategy featuring the Branch, Fail and Join effects cannot directly be used in combina-"}, {"title": "3.2.4 Tracing", "content": "When debugging oracular programs, it is useful to remember every node and space that was encountered by the policy during search. We define a trace as a sequence of objects of type GlobalNodeRef or GlobalSpaceRef (Figure 10). Traces can be manually created by search policies, or automatically by using tracing tree wrappers. Traces can be visualized as trees with proper tooling (Section 4). In addition, future work will explore how to automatically extract demonstrations from traces so as to implement self improvement loops for oracular programs [11]."}, {"title": "3.3 The Demonstration Language", "content": "Although queries can sometimes be successfully answered via zero-shot prompting, LLMs typically work better when examples of answering queries of the same type are provided (Figure 12). Therefore, such examples must be an integral part of an oracular program and the question arises of how to best write and maintain them. A naive approach is to have a user-created database of raw query-answer pairs. However, such a collection would be hard to read, write and maintain. It would be hard to read because individual examples are accumulated with no context and are not grounded in concrete narratives of solving specific problems. It would be hard to write because determining what instances to answer for queries occurring in the middle of complex pipelines and then manually writing them down is error-prone and time-consuming. Most importantly, it"}, {"title": "4 Delphyne: a Python-Based Oracular Programming Framework", "content": "We release Delphyne, an open-source framework for oracular programming based on Python.\" Delphyne offers rich tooling support for writing demonstrations and inspecting traces in the form of a VSCode extension. Beyond being a popular and accessible programming language with a"}, {"title": "5 Related Work", "content": "Many frameworks exist to simplify the development of LLM-enabled programs [14]. However, our framework is unique in harnessing the full power and generality of nondeterministic programming to robustly integrate prompting into modular, first-class programs. To the best of our knowledge, it is also the first to identify and address the challenge of treating few-shot examples as maintainable program components. Finally, while existing frameworks offer a restricted set of search primitives, such as repeated trials and majority voting, our framework allows writing and composing arbitrary, modular policies. While this level of power and generality may not be necessary for all applications, we expect Delphyne to be particularly useful in scenarios where reliable external feedback enables the full exploitation of search. This is notably the case in areas such as program synthesis, program"}, {"title": "6 Conclusion", "content": "Symbolic AI methods based on logic and rules naturally complement subsymbolic methods [17] based on deep learning. The former are reliable and interpretable, while the latter enable harnessing commonsense knowledge from vast amounts of data. Oracular programming provides a foundation for integrating those approaches. Delphyne provides a basis for fostering new idioms for building intersymbolic AI systems. Future work will focus on large-scale case studies and developing methods to automatically evolve oracular programs through self-improvement loops [11]."}]}