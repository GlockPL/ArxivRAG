{"title": "Active learning of digenic functions with boolean matrix logic programming", "authors": ["Lun Ai", "Stephen H. Muggleton", "Shi-shun Liang", "Geoff S. Baldwin"], "abstract": "We apply logic-based machine learning techniques to facilitate cellular engineering and drive biological discovery, based on comprehensive databases of metabolic processes called genome-scale metabolic network models (GEMs). Predicted host behaviours are not always correctly described by GEMs. Learning the intricate genetic interactions within GEMs presents computational and empirical challenges. To address these, we describe a novel approach called Boolean Matrix Logic Programming (BMLP) by leveraging boolean matrices to evaluate large logic programs. We introduce a new system, $BMLP_{active}$, which efficiently explores the genomic hypothesis space by guiding informative experimentation through active learning. In contrast to sub-symbolic methods, $BMLP_{active}$ encodes a state-of-the-art GEM of a widely accepted bacterial host in an interpretable and logical representation using datalog logic programs. Notably, $BMLP_{active}$ can successfully learn the interaction between a gene pair with fewer training examples than random experimentation, overcoming the increase in experimental design space. $BMLP_{active}$ enables rapid optimisation of metabolic models and offers a realistic approach to a self-driving lab for microbial engineering.", "sections": [{"title": "1 Introduction", "content": "Our study explores the applicability of abductive reasoning and active learning to extensive biological systems. Given that biological relationships are commonly described logically, ILP is particularly adept at operating on biological knowledge bases. We employ boolean matrices as underlying bottom-up evaluation mechanisms of datalog programs to scale to state-of-the-art genome-scale metabolic network model iML1515 [18]. The integration of abductive reasoning and active learning via ILP was successfully demonstrated in the context of biological discovery by the prominent Robot Scientist [13]. The Robot Scientist performed active learning by strategically selecting key experiments to achieve more data- and cost-effective gene function learning than random experimentation. However, this demonstration was limited to only 17 genes in the aromatic amino"}, {"title": "2 Related work", "content": "Computational systems [15,28,3,11,22] were primarily designed to formulate symbolic hypotheses from experimental results. One cannot directly employ these systems for experimental planning. In contrast, the Robot Scientist [13,14] automatically proposed explanatory hypotheses, actively devised validation experiments and performed experiments using laboratory robotics. Experiments were actively selected to minimise the expected cost of experimentation for learning gene functions in yeast [4]. In comparison, we apply $BMLP_{active}$ to a genome-scale metabolic network, which is significantly larger than the models in the Robot Scientist [13,14].\nOur BMLP approach uses boolean matrices for iterative bottom-up computation. Obtaining the least Herbrand model of linear recursive datalog programs can be reduced to computing the transitive closure of boolean matrices [21,7]. Fischer and Meyer [9] and Ioannidis [12] showed a divide-and-conquer boolean matrix computation technique by viewing relational databases as graphs. An ILP system called DeepLog [19] employed boolean matrices for choosing optimal background knowledge to derive a compact bottom clause. A great body of work [16,10,25,5,27,26] only studied the approximation of logic program evaluation in tensor spaces. Solving certain recursive programs is difficult whereas these can be solved by iterative bottom-up evaluations [25]."}, {"title": "3 Modelling a GEM with a Petri net", "content": "In an auxotrophic mutant experiment, a gene is removed from a cell. Some key metabolic reactions might no longer be viable due to the removal, leading to insufficient cell growth. We model such metabolic mechanisms via genome-scale metabolic networks. A genome-scale metabolic network model contains biochemical reactions of substances, which is often represented by Petri nets [24]. A GEM is a Petri net in the sense that reactions are transitions (edges in a Petri net), and reactants and products are places (nodes in a Petri net). A reaction involves chemical substances $x_i$ and $y_j$:\nIrreversible: $x_1 + x_2 + ... + x_m \\rightarrow y_1 + y_2 + ... + y_n$\nReversible: $x_1 + x_2 + ... + x_m \\rightleftharpoons y_1 + y_2 + ... + y_n$\nWe associate binary phenotypic effects, e.g. reduced cell growth between wild-type and auxotrophic mutants, with reachability to key substances in the metabolic"}, {"title": "4 Boolean matrix logic programming", "content": "We propose the Boolean Matrix Logic Programming (BMLP) problem. In contrast to traditional logic program evaluation, BMLP uses boolean matrices to evaluate recursive datalog programs with arity at most two and at most two body literals, namely the H2 program class [20].\nDefinition 1 (Boolean Matrix Logic Programming (BMLP) problem).\nLet P be a datalog program containing a set of clauses with the predicate symbol"}, {"title": "5 Active learning", "content": "Our active learning system $BMLP_{active}$ selects experiments to minimise the expected value of a user-defined cost function and iteratively prunes hypotheses inconsistent with experimental outcomes. $BMLP_{active}$ uses the Minimal Description Length principle [6] and the compression score of a hypothesis h [4] to optimise the posterior probability:\n$compression(h, E) = |E+| - \\frac{|E+|}{p_{ch}} (size(h) + f_{ph})$\n$p'(h/E) = \\frac{2^{compression(h,E)}}{\\sum_{h_i \\in H} 2^{compression(h_i,E)}}$\nwhere $E^+$ is the set of positive examples seen by the active learner, $p_{ch}$ is the positive coverage by h and $f_{ph}$ is false positives covered by h. This compression"}, {"title": "6 Experiments", "content": "We focused on re-discovering the function associated with the key gene tyrB in the Tryptophan biosynthesis pathways. Overlapping functions between two genes tyrB and aspC is a digenic interaction since they are responsible for producing an important amino acid. We removed the metabolic reaction associated with tyrB from iML1515. This state-of-the-art GEM model iML1515 [18] was first represented as a datalog program and then as boolean matrices for computation. The random selection strategy randomly sampled N instances from the instance space. $BMLP_{active}$ selected N experiments from this instance space to actively learn from the hypothesis space. Both methods output the hypothesis with the highest compression.\nIn Fig 1 we observed that $BMLP_{active}$ provides higher information gain from each experiment and successfully guarantees recovery of the correct gene function with as few as 20 experiments. This demonstrates $BMLP_{active}$'s ability to discover digenic interactions in GEM. This result also shows that $BMLP_{active}$ significantly reduced the number of experiments needed compared to random ex-"}, {"title": "7 Conclusion and future work", "content": "We integrated abductive reasoning and Bayesian active learning in the new approach Boolean Matrix Logic Programming (BMLP), which utilises low-level boolean matrices encoded in Prolog to compute datalog programs. We applied our active learning system $BMLP_{active}$ to learn a key digenic function in a state-of-the-art genome-scale metabolic network. Though we focused on a reduced set of hypotheses in the experiment, the combinatorial space was sufficiently large that random experiment selection became non-viable as an experimentation strategy in a discovery process. The remarkable increase in efficiency with $BMLP_{active}$ with this task demonstrates it has potential even as the experimental design space grows exponentially.\nPetri nets complement knowledge representation with dynamic analysis. However, the simulation of Petri nets in logic programming has been much less explored. Future work will explore the natural link between Petri nets and Probabilistic Logic Programming [8]. Transitions could have firing likelihood constraints and this uncertainty can be modelled by probabilistic logic programs."}]}