{"title": "Coupling Neural Networks and Physics Equations\nFor Li-Ion Battery State-of-Charge Prediction", "authors": ["Giovanni Pollo", "Alessio Burrello", "Enrico Macii", "Massimo Poncino", "Sara Vinco", "Daniele Jahier Pagliari"], "abstract": "Estimating the evolution of the battery's State of\nCharge (SoC) in response to its usage is critical for implementing\neffective power management policies and for ultimately improving\nthe system's lifetime. Most existing estimation methods are either\nphysics-based digital twins of the battery or data-driven models\nsuch as Neural Networks (NNs). In this work, we propose two\nnew contributions in this domain. First, we introduce a novel NN\narchitecture formed by two cascaded branches: one to predict\nthe current SoC based on sensor readings, and one to estimate\nthe SoC at a future time as a function of the load behavior.\nSecond, we integrate battery dynamics equations into the training\nof our NN, merging the physics-based and data-driven approaches,\nto improve the models' generalization over variable prediction\nhorizons. We validate our approach on two publicly accessible\ndatasets, showing that our Physics-Informed Neural Networks\n(PINNS) outperform purely data-driven ones while also obtaining\nsuperior prediction accuracy with a smaller architecture with\nrespect to the state-of-the-art.", "sections": [{"title": "I. INTRODUCTION", "content": "Safe and efficient operations of battery-powered devices at\nany scale (from portable electronics to electric vehicles) require\nadvanced Battery Management Systems (BMS) in order to\nmonitor the internal state of a battery and optimize its usage.\nAmong the crucial parameters monitored by the BMS, the SoC,\nwhich measures the remaining battery charge, plays a critical\nrole in ensuring battery longevity and averting potential failures.\nMoreover, the SoC serves as an input for the calculations of\nother quantities, such as the State-of-Health (SoH), battery\npower, and cell balancing.\nThe accurate and reliable estimation of the current SoC\nand the prediction of its future value in response to specific\nstimulation of the battery is a challenging task due to its de-\npendence on factors like battery age, manufacturing variability,\nambient temperature, etc. As a matter of fact, previous works\nhave even claimed that it is virtually impossible to measure\nall the actual electrochemical factors that affect the SoC [1].\nTherefore, purely physics-based models that try to relate the\nSoC to quantities that affect it (or may affect it) are not easy to\ndevise [2]. For this reason, a number of data-driven approaches\nhave recently appeared, which are essentially Machine Learning\n(ML) models trained offline on easily measurable quantities\n(i.e., current, voltage, and temperature) to approximate the\nmathematical relation between them and/or some statistical\naggregation thereof, and a ground truth SoC value [3].\nData-driven models have some key advantages over physical\nones. Firstly, not being linked to the physics of a specific"}, {"title": "II. BACKGROUND AND RELATED WORKS", "content": "is non-trivial. Qmax is typically assumed to be the nominal\nbattery capacity as provided by the manufacturers, which might\nnot be an accurate guess due to various variability effects [8].\nMoreover, Qmax is not constant throughout the battery life due\nto aging [4]. Because of these and other subtle factors, accurate\nSoC estimation remains a challenging problem to solve, thereby\ninspiring a wealth of literature on the topic. The landscape of\nSoC estimation methods is so vast that there exists a number\nof surveys that provide excellent overviews of the various\nsolutions [2], [3].\nAs a compact summary, SoC estimation methods can be\nbroadly classified in three categories:\n1) Direct measurements, which use some measurable quan-\ntity (voltage, resistance/impedance, current) that can be\ncorrelated to SoC. This includes methods based on open\ncircuit voltage (OCV) [9], impedance [10], and Coulomb\ncounting, in which the SoC is estimated by integrating\nthe discharging current over time [11];\n2) Physics-based approaches, which model the battery by\nfollowing or approximating the underlying physics; these\ninclude electro-chemical models [12], electrical-circuit\nequivalent models [13], and models based on state es-\ntimation (e.g., Kalman filters) [14];\n3) Data-driven approaches, which also rely on a model that\nis, however, directly extracted from a dataset of cur-\nrent, voltage, and temperature measurements associated\nto ground-truth SoC values [3], [15], [16]; unlike the\nprevious class, such models are not based on physics,\nand their parameters are rather obtained through a fitting\n(or training) procedure.\nWhen addressing the more complex problem of SoC prediction\n(i.e., not just estimating the current SoC but rather predicting its\nfuture value in response to how the battery will be stimulated),\ndirect measurements as in (1) are unfeasible, and the only\navailable options are either to build a physics-based digital\ntwin of the battery using a model from category (2), or to\ntrain a data-driven forecasting model as in (3). For the former\noption, we refer the reader to the above-mentioned surveys for\na detailed analysis. In the rest of the section, we overview the\nmost relevant data-driven models, which are the main focus of\nour work."}, {"title": "A. Data-Driven SoC Models", "content": "A number of different data-driven solutions have been pro-\nposed to estimate battery states (SoC and/or SoH). They differ\nessentially in the structure and complexity of the ML model\nadopted, ranging from simple classic ones such as tree-based\nensembles [4] to deep feedforward [16] or recurrent NNs [17].\nThe survey of [3] provides an exhaustive overview of ML-based\napproaches for battery state estimation.\nIn this domain, the problem of the generalization of ML\nmodels (i.e., their ability to accurately model data different\nfrom those seen during training) is particularly critical. In\nfact, in-field data might correspond to widely varying system\nworkloads (i.e., current and temperature profiles), while most\ntraining datasets are obtained by controlled lab measurements.\nHowever, recent studies have observed that by incorporating\nprior information (e.g., physical laws or domain knowledge) in\nthe learning process, it is possible to enhance the generalization\nof the models and also accelerate training [18].\nPhysics-informed neural networks (PINNs) are an example\nof this learning bias, in which the physics of the underlying\nphenomenon is added to the model's training loss function as\npenalty constraint in the form of partial differential equations\n(PDEs) [19]. A few recent works have used physics-informed\nML models for SoC estimation [7], [20]\u2013[22], by incorporating\nsome form of battery dynamics inside the model. Our work\nis closest to [7] in that it is the only \u201ctrue\u201d, canonical PINN\narchitecture of the above list; the authors include the PDEs\ncorresponding to the dynamics of a first-order circuit-equivalent\nRC battery model into the loss function of conventional NN\nmodels, namely a Multi-Layer Perceptron (MLP), and two\ntypes of recurrent NNs. However, our work differs from [7] in\nseveral aspects. First, similarly to [23], we target SoC prediction\nrather than estimation, although our proposed model is capable\nof both. As a second element of novelty, we propose a novel\nNN architecture formed by two cascaded branches: one to\npredict the current SoC based on sensor readings and one to\nestimate the SoC at a future time as a function of the expected\nbattery usage. This architecture is significantly smaller and\nless computationally expensive than the ones in [7]. Third, we\nincorporate physics equations in our model's loss function with\na different purpose, that is, to enhance its generalization in\npredicting the future SoC at multiple time horizons."}, {"title": "III. METHODOLOGY", "content": "Accurately predicting the future SoC in response to a cur-\nrent profile drawn from the battery enables several advanced\npower management optimizations. On an electric vehicle, either\nterrestrial or aerial (e.g., a small drone), it allows taking\nruntimedecisions on the best route to follow to maximize\nbattery lifetime [24]. On a battery-operated embedded device,\nit could be used to find the most appropriate scheduling of\ncomputing tasks [25]. Being able to perform this prediction\nwith multiple time horizons enables the combination of faster-\nyet-approximate long-term decisions (e.g., on the best overall\nroute) with slower-yet-precise short-term ones (e.g., on the\noptimal speed and altitude for the next route segment). In the\nrest of this section, we present a data-driven SoC prediction\nmethod that favors such multi-horizon applications. Namely,\nwe first introduce our proposed NN structure and then describe\nhow we enhance its training using a physics law."}, {"title": "A. Network Architecture", "content": "Figure 1 depicts the architecture of our proposed NN. The\noverall model is formed by cascading together two Fully-\nConnected (FC) feed-forward sub-networks, or branches.\nBranch 1 takes as inputs easily measurable (and available\nin any public dataset) information on the state of the battery\nat time t, namely: the voltage V(t), the drawn current I(t)\nand the temperature T(t). Its output is an estimation of the\nSoC at the same time instant, i.e., SoC(t). Notice that all three\ninputs are required since both current and temperature influence\nthe instantaneous SoC, e.g., through the voltage drops across\ninternal battery resistances.\nBranch 2 has the objective of predicting the future value\nof the SoC in response to how the battery is used; its output\nis $SoC(t + N)$, where N denotes the time horizon of the\nprediction. Branch 2 takes the output of Branch 1 as input and\nuses it as initial condition for the prediction. In addition to the\nestimated initial SoC, Branch 2 receives three additional inputs,\nrepresenting the workload for which we want to estimate the\nfuture SoC. These are the average current $I(t + N)$ applied\nbetween t and t + N, the corresponding average temperature\n$T(t + N)$, and the prediction horizon N.\nWhen querying the second model, these three inputs serve\nas user-specified parameters; while the inputs of Branch 1 are\nmeasurable quantities, $I(t + N),T(t + N)$, and N are used\nto define the workload conditions and the temporal horizon\nfor which we want to calculate the future SoC, based on the\ncurrent SoC(t). While $I(t + N)$ represents a hypothetical\nworkload, estimating the future temperature $T(t + N)$ is not\ntrivial. However, for a relatively short horizon, it is reasonable\nto assume constant temperature without significant losses of\naccuracy, i.e., setting $T(t + N) = T(t)$.\nThe prediction horizon N is needed as input because the\namount of time elapsed is obviously strictly correlated with\nthe SoC variation. Thus, adding it as an external input, rather\nthan letting the model infer the elapsed time from data, allows\nus to have a single NN that can generate predictions at multiple\ninstants in the future, which is fundamental to support multi-\nhorizon power management as discussed above.\nFigure 2 shows how the proposed model can be used to esti-\nmate the SoC over multiple future timesteps with non-constant\ncurrent requests. Here, the NN layers have been schematized as\nboxes for simplicity, where Bx-FCy indicates the y-th FC layer\nof the x-th branch. As shown, after executing Branch 1 a single\ntime to estimate the initial SoC(t), k consecutive executions of\nBranch 2 in an autoregressive fashion (i.e., feeding the output\nof the i-th invocation as input for the i + 1-th) are used to\nobtain a complete estimate of the SoC evolution in response to\nthe battery's stimulation pattern.\nIn this work, we use the same hyper-parameters for the two\nbranches (except for the number of inputs, set to 3 and 4,\nrespectively). Namely, each branch has 3 FC hidden layers\nwith ReLU activation functions and 16, 32, and 16 units,\nrespectively, following an inverted bottleneck structure. The\noutput layer has a single unit in both cases, with no activation,\nto predict an unrestricted scalar value. While we leave the\nexploration of the NN architecture to future work, we remark\nthat this model requires a pretty small number of trainable\nparameters (2,322 corresponding to approximately 9kB of\nstorage with float32 representation), thus being suited for\nperforming low-cost runtime predictions on-board a BMS or a\nPower Management Integrated Circuit (PMIC)."}, {"title": "B. Training Scheme and Loss Function", "content": "The network architecture described in Sec. III-A can be\ntrained in a purely data-driven fashion. In that case, both\nbranches use the Mean Absolute Error (MAE) between the pre-\ndicted and ground truth SoC as a loss function to be minimized\nvia gradient descent. We empirically observed that training the\ntwo branches separately, i.e., stopping the back-propagation of\ngradients from Branch 2 to Branch 1, yields superior results.\nIn other words, during training, the weight updates of Branch 1\nonly depend on the error on the prediction of SoC(t), and not\non the propagated error from Branch 2. Moreover, exclusively\nat training time, Branch 2 is fed with ground truth SoC(t)\nvalues from the dataset (whereas at inference times it receives\nthe estimated SoC from Branch 1). This split training also\nimproves the explainability of our model, as Branch 1 outputs\na physically relevant quantity (SoC(t)) rather than a black-box\nintermediate value.\nTo enhance the purely data-driven setup and improve the\nnetwork's generalization, Branch 2 can be turned into a PINN,\nadding a physics component to its loss function. In particular,\nin our work, we use the simple Coulomb counting equation,\nwhich associates the SoC difference over time to the total\nnet charge exchanged (provided or absorbed) by the battery.\nMathematically, the equation is the following:\n$SoC_p(t + N_p) = \\frac{1}{C_{rated}}\\int_{t}^{t+N_p} I(t) dt + SoC(t)$ (1)\nwhere subscript p stands for \u201cphysics\u201d, and $C_{rated}$ is the\nbattery\u2019s nominal capacity, as reported in the datasheet. When\nusing this setup, the overall loss function of Branch 2 becomes:\n$L = MAE(SoC(t + N), S\\hat{o}C(t + N))+$\n$MAE(SoC_p(t + N_p), S\\hat{o}C(t + N_p))$ (2)\nwhere S\\hat{o}C indicates the NN prediction.\nDuring training, in correspondence with each minibatch of\ndata used to evaluate the first loss component, the physics-based\nloss is computed over a set of different, randomly generated\nvalues of initial SoC, current, and time delta conditions. In\nparticular, the time delta for this second term ($N_p$) takes\nmultiple values drawn from a set N, which are in general\ndifferent from the fixed value of N used for the data-driven\npart, which is constrained by the sampling frequency of the\ndataset. Conversely, N includes smaller and/or larger values,\nthus enabling the model to learn how to predict the SoC\ndegradation at multiple future instants simultaneously.\nWhile Eq. 1 clearly neglects many secondary effects (ther-\nmal, cell-to-cell variability, etc.), it still enforces the first-order\nbehavior of the SoC evolution as a function of the requested\ncurrent, thus acting as a regularization component in the loss.\nThis has the effect of improving the NN performance on unseen\ndata, even when using a value of N different from the ones\napplied during training.\nIt has to be noted that, currently, our model does not account\nfor battery SoH degradation. Therefore, it is accurate only for\nrelatively short horizons (e.g., hours, not months), and only as\nlong as the actual SoH is comparable to the one of batteries\nincluded in the training set. While out-of-scope for this paper,\none simple way to cope with this limitation, and make sure\nthat the proposed system remains accurate across varying SoH\nconditions, follows the approach of [26]. There, the authors\nbuild an ensemble of SoC prediction models, each trained with\ndata at a different SoH level, and select the appropriate one to\nuse based on a separate SoH estimation model."}, {"title": "IV. DATASETS", "content": "A. Sandia\nThis dataset, collected by the Sandia National Lab [5],\ncontains charge and discharge cycles of three different 18650\ncommercial batteries (NCA, NMC, and LFP). The batteries are\ncharged and discharged using different currents until the end\nof their capacity, leading to cycles with different durations.\nThe charge/discharge current ranges from 0.5C to 3C, and the\ntemperature from 15\u00b0C to 35\u00b0C. The data are sampled every\n120 seconds. In our benchmarking, we consider all the data with\na charge/discharge current of 0.5C/-1C to train the network and\nwith a charge/discharge current of 0.5C/-2C and 0.5C/-3C to\ntest the network.\nWe consider SoC predictions over a time horizon of N =\n120s, i.e., the time delta between two consecutive samples in\nthe dataset, for the data-driven loss component of Branch 2.\nFor the physics loss, we generate an identical number of cycles,\nwith the same current conditions of the dataset, and prediction\nhorizions $N_p$ set to 120s, 240s, 360s, or to an even mix of all\nthree. We identify the corresponding trained PINNS as PINN-\n120s, PINN-240s, PINN-360s, and PINN-All, respectively.\nIt's important to note that for the physics loss, labels are not\nnecessary, as future SoC values come directly from Eq. 1. This\nis a significant advantage of the PINN, as it allows the network\nto be trained across any time horizon (longer or shorter than\nthe one of the data), without relying on ground truth labels,\nunlike traditional data-driven methods. In our experiments, we\nlimit ourselves to values of $N_p > N$ just because it allows us\nto later test the models in those conditions by under-sampling\nthe dataset, as detailed below (whereas testing with $N_p < N$\nwould be impossible).\nWe assess the goodness of the trained Branch 1 (SoC\nestimation part) by predicting SoC(t) on the unseen dataset\ncycles and computing the MAE w.r.t. the ground truth. For\ntesting the whole model (Branch 1 + Branch 2), in order to\ndemonstrate the advantage of our PINN, we consider three\ntest sets, targeting the prediction of: SoC(t+120s), SoC(t+240s),\nand SoC(t+360s), where the former is directly obtained from\nconsecutive dataset samples, and the other two are obtained by\ntaking sliding windows of the dataset, averaging current and\ntemperature values in each window, and using the final SoC\nvalue as prediction target."}, {"title": "B. LG", "content": "This dataset was collected at McMaster University [6] on\nan LGHG2 3Ah battery. Contrary to Sandia, charge/discharge\ncycles collected in this dataset are not characterized by a con-\nstant current but are created using specific patterns belonging\nto different driving conditions. Specifically, the patterns consid-\nered are the UDDS (Urban Dynamometer Driving Schedule),\nthe HWFET (Highway Fuel Economy Test), the LA92, and\nthe US06. Temperatures are in the -20\u00b0C to +40\u00b0C range. The\nsampling rate is set to 0.1s, and a single cycle is present for each\ndriving condition. Furthermore, eight charge/discharge cycles\ncomposed of a mixture of the four patterns are also collected.\nAs done in [17], we selected seven out of eight mixed cycles as\ntraining data, with temperatures ranging from 0\u00b0C to 25\u00b0C. For\ntesting, we used the remaining four cycles, each representing a\ndifferent driving pattern, along with the final mixed cycle.\nIn this case, due to the higher granularity of the samples,\nwe decided to use shorter time horizons of 30s, 50s, and 70s\nfor testing. Before feeding the data to our neural network, we\nadded a moving average of 30s as pre-processing that smooths\nthe I, V, and T values and removes noisy peaks that could arise\nfrom the fine-grained sampling of this dataset. Both the physics\ndata and the test conditions have been generated identically to\nthe Sandia dataset, except for the different time horizons."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "A. Results on the Sandia Dataset\nWe first benchmark our proposed network on the Sandia\nDataset, showing the network performance on the three test\nconditions described in the previous section. Figure 3 shows"}, {"title": "B. Results on the LG Dataset", "content": "Given the limited charge/discharge conditions (i.e., constant\ncurrent) of the Sandia dataset, we also benchmark our approach\non the LG dataset, which contains more complex charge and\ndischarge patterns with varying currents. Figure 4 illustrates\nthe result for this dataset with a visualization analogous to the\nprevious section, but using 30, 50, and 70 seconds as prediction\nhorizons. It is worth observing that for this dataset, contrary\nto the previous one, the PINN trained with $N_p$ equal to the\ntime horizon used for testing always achieves the best result on\nthe corresponding test condition. Namely, they achieve 0.0217,\n0.0218, and 0.0210 MAE on the predicted SoC, outperforming\nthe No-PINN result by 3%, 69%, and 82%, respectively.\nHowever, similarly to the Sandia experiments, using the physics\nequation with multiple time horizons simultaneously (PINN-\nAll), allows the network to closely approach the best perfor-\nmance in all test conditions. In particular, PINN-All achieves\nthe second lowest MAE overall of 0.0214, being just 1.8% less\naccurate than the best model (PINN-70s). This shows that the\nphysics loss allows the network to better generalize even when\ncharge and discharge currents change over time.\nIt is also noteworthy that as the value of $N_p$ increases,\nthe error of the No-PINN architecture grows, and the overall\nimprovement in MAE due to physics becomes more pro-\nnounced. This confirms the importance of the physics loss in\nregularization, especially when dealing with data farther from\nthe training dataset."}, {"title": "C. State-of-the-art Comparison", "content": "In this section, we focus on the LG dataset to compare\nour proposed approach with the best SoA algorithm for SOC\nestimation [17] and with [7], that is the most similar work\nto ours (as presented in Sec. II, as it also exploits physics\nequations during training).\nTable I reports the results obtained on SoC estimation, i.e.,\nthe error on SoC(t), computed with data measured from the\nbattery, and on SoC prediction, i.e., the error on SoC(t+N).\nFor our method, we report the output of Branch 1 for the\nformer, and of the full network for the latter, using a 30s\ntime horizon. Note that none of the previous works tested\non this dataset have considered the prediction of future SoC\nvalues. Our work addresses this more complex task, achieving\nan impressive SoC prediction MAE of 0.014 when exploiting\nphysics equations to train our networks. Moreover, we also\ndemonstrate comparable performance on the same task of the\nSoA, i.e., the instantaneous SoC estimation. When compared\nto [17], our approach reaches almost the same MAE (0.014\nvs. 0.012) on the same test dataset, with a model that requires\nan impressive 260k\u00d7 fewer operations and 400\u00d7 less memory.\nCompared to [7], we obtain 4.2\u00d7 lower MAE than their best\nsolution, an LSTM with comparable dimensions of the one\nof [17], and up to ~6\u00d7 lower MAE when compared to their\nproposed MLP architecture. We argue that we achieve better\nperformance thanks to the introduced moving average on input\nwindows, used as pre-processing before feeding the data to\nBranch 1. This allows the network to account for I, V, and\nT information of the last 30 seconds instead of their noisy\ninstantaneous values."}, {"title": "D. Full discharge analysis", "content": "In this final section, we illustrate the estimation of a complete\ndischarge cycle, leveraging the autoregressive application of our\nmodel, depicted in Fig. 2. We target the entire four \u201cdriving\u201d\ncycles of the LG test dataset. We highlight that this is a critical\ntask, i.e., predicting the battery lifetime given a target workload,\nthat can not be solved by SoA methods, given that they require\ninstantaneous voltage information, whereas we use voltage as\ninput only at the first timestamp. In Fig. 5, each line represents\na different network configuration. For all models, the single-\nstep time horizon for SoC prediction is set as the one that\nresulted in the lowest MAE in the previous experiments. Then,\nmultiple autoregressive predictions are performed. For instance,\nfor the PINN-50s, we use 50 seconds as the time horizon:\nwe first predict SoC(0) with Branch 1, and then recursively\nuse Branch 2 to predict SoC(50), SoC(100), etc. The black\nline represents the golden SoC of the battery. The No-PINN\nand the Physics-Only configurations use a time horizon of 30s,\ncorresponding to the same value of N present in the dataset,\nand to their best testing condition (see Fig. 4). The first thing\nthat we notice is that the No-PINN architecture achieves poor\nperformance on SoC prediction for 3 out of 4 cycles. Similarly,\nthe Physics-Only approach consistently performs the worst\namong all cycles. This is primarily because errors accumulate\nwith each iteration, and without accounting for voltage in the\nequation, the predictions tend to diverge rapidly. Interestingly,\nwhile values are overestimated, the shape of the discharge\npatterns predicted by Physics-Only closely align with the\nground truth, hinting at why incorporating the physics equation\nduring training can enhance performance. Indeed, combining\nphysics and data-driven training strongly improves the results,\nstepping from an average final SoC prediction of 0.234 (ground\ntruth is SoC=0.0) for the No-PINN case to 0.089 for the\nbest PINN setup, i.e., PINN-30s. The only cycle where the\nPINNs marginally underperform is the US06. Importantly, the\nhigher errors shown in this experiments are due to accumulation\ncaused by the autoregressive inference, demonstrating that this\ntask is much more challenging compared to the estimation of\nthe instantaneous SoC, or to the prediction of the SoC at a\nsingle future time instant. However, we note that running an\nautoregressive prediction that lasts for a full discharge cycle is\nan extreme case, that would probably not occur in practice.\nA more realistic usage of our model would run a limited\nnumber of autoregressive steps, depending on the length of\nthe workload whose effect on the SoC shall be predicted, thus,\nlimiting the error accumulation."}, {"title": "VI. CONCLUSIONS", "content": "The prediction of future battery SoC for different time\nhorizons is a topic not as popular as the instantanous SoC\nestimation. It requires models including as parameters the\nfuture expected workload for which one wants the SoC to be\npredicted. In this work we proposed one such model, which\nrelies on: i) a novel, two-stage NN that decouples the problem\nin two steps (current SoC estimation first, and then future\nSoC prediction using the expected workload as input); ii) the\nintegration of a very simple yet effective equation that describes\nSoC evolution over time into the learning process, making the\nabove NN physics-informed. The proposed method shows ac-\ncuracy comparable with the SoA (0.014 vs 0.012 MAE) with a\nmuch simpler architecture (409\u00d7 fewer parameters and 260k\u00d7\nless operations), and, more importantly, demonstrates excellent\nfuture SoC prediction capability even for time horizons that\ndiffer from those available in the training dataset."}]}