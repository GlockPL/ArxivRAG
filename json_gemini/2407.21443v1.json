{"title": "Improving Faithfulness of Large Language Models in Summarization via Sliding Generation and Self-Consistency", "authors": ["Taiji Li", "Zhi Li", "Yin Zhang"], "abstract": "Despite large language models (LLMs) have demonstrated impressive performance in various tasks, they are still\nsuffering from the factual inconsistency problem called hallucinations. For instance, LLMs occasionally generate\ncontent that diverges from source article, and prefer to extract information that appears at the beginning and end\nof the context, especially in long document summarization. Inspired by these findings, we propose to improve\nthe faithfulness of LLMs in summarization by impelling them to process the entire article more fairly and faithfully.\nWe present a novel summary generation strategy, namely SliSum, which exploits the ideas of sliding windows\nand self-consistency. Specifically, SliSum divides the source article into overlapping windows, and utilizes LLM to\ngenerate local summaries for the content in the windows. Finally, SliSum aggregates all local summaries using\nclustering and majority voting algorithm to produce more faithful summary of entire article. Extensive experiments\ndemonstrate that SliSum significantly improves the faithfulness of diverse LLMs including LLaMA-2, Claude-2 and\nGPT-3.5 in both short and long text summarization, while maintaining their fluency and informativeness and without\nadditional fine-tuning and resources. We further conduct qualitative and quantitative studies to investigate why\nSliSum works and impacts of hyperparameters in SliSum on performance.", "sections": [{"title": "1. Introduction", "content": "Abstractive summarization aims to generate sum-\nmaries that are fluent, informative, and faithful to the\nsource articles. Benefiting from the popularity and\ndevelopment of large language models (LLMs), ab-\nstractive summarization has achieved remarkable\nprogress in fluency and coherence (Zhang et al.,\n2023b; Goyal et al., 2023; Zhang et al., 2023a).\nHowever, LLMs have propensity to generate con-\ntent that contradicts or is not present in the source\narticle (Tam et al., 2023; Maynez et al., 2020; Lin\net al., 2022; Li et al., 2023a), which is commonly re-\nferred to as hallucination. Alleviating the hallucina-\ntion of LLMs is a critical challenge for their reliability\nin real-world applications.\nMany works (Zhang et al., 2023c; Zheng et al.,\n2023) explore the mechanisms why LLMs exhibit\nhallucinations. Liu et al. (2023a) observe that the\nperformance of LLMs significantly decreases as\nthe length of input contexts increases, resulting in\nthe hallucination phenomenon of LLMs being par-\nticularly serious in long document summarization.\nFurthermore, LLMs are sensitive to the order of\ncontext and are more likely to select information\npresented first or last, even for short contexts (Xie\net al., 2024; Wang et al., 2023a). That is, the sum-\nmaries generated by LLMs contain more content\nthat occurs at the beginning and end of the source\narticle, which has a detrimental effect on the sum-\nmary quality of the entire article."}, {"title": "2. Related Works", "content": "Factual Consistency of Summarization The\nfactual consistency in abstractive summarization\nhas received increasing attention recently. Existing\nwork has proposed various methods to improve the\nfactual consistency, such as contrastive learning\n(Wan and Bansal, 2022; Xie et al., 2023), adver-\nsarial learning (Wang et al., 2022; Wu et al., 2022),\ntextual entailment (Zhang et al., 2022b; Roit et al.,\n2023) and post-editing (Fabbri et al., 2022; Bal-\nachandran et al., 2022). However, these methods\ncan not be directly applied in long document sum-\nmarization due to the difficulty of modeling long\ntexts accurately. Although recent studies have ad-\ndressed this problem by leveraging Graph Neural\nNetworks (Zhang et al., 2022a; Doan et al., 2022;\nPhan et al., 2022; Xie et al., 2022), reinforcement\nlearning (Gu et al., 2022) and structure informa-\ntion (Cao and Wang, 2022; Cho et al., 2022; Pu\net al., 2023), they do not improve the faithfulness\nof long document summarization systems. There\nare currently few works that focus on improving fac-\ntual consistency of long document summarization.\nIn contrast, we propose a unified architecture that\nconsistently improves factual consistency of both\nshort and long text summarization.\nMitigation of LLM Hallucination Recent studies\nhave made several attempts to mitigate the hal-\nlucination of LLMs, including retrieval-augmented\ngeneration (Peng et al., 2023; Ram et al., 2023;\nKang et al., 2023; Xu et al., 2024), post-processing\nmodels (Chen et al., 2023; Gou et al., 2024; Huang\net al., 2023), prompt engineering (Xue et al., 2023;\nShi et al., 2023; Luo et al., 2023; Dhuliawala et al.,\n2023) and self-supervised learning (Gekhman et al.,\n2023; Manakul et al., 2023; Du et al., 2023). How-\never, most of these works require training additional"}, {"title": "3. Approach", "content": "3.1. Sliding Generation\nSliding Window SliSum first divide the source\narticle A into a list of sentences [C1, C2,\uff65\uff65\uff65, Cn].\nThe sliding window with predefined window size\ninitially consists of several consecutive sentences\n[C1,..., Ct] at the beginning of the article. The\nnumber of words in the window only needs to be\napproximately equal to the window size. Figure 1\nshows that LLM generates a local summary for the\ncontent in the sliding window. SliSum restricts the"}, {"title": "3.2. Events Filtering", "content": "Lexical Clustering The event is usually com-\nposed of entity, behavior, reason, result and other\nelements, so statements about different events\nhave their own characteristic words that can be\nused to distinguish them. We observe that the\nstatements generated by LLMs for the same event\nare usually lexically similar. Consequently, we can\nobtain a set of sentences about the same event by\nlexical similarity clustering. As shown in Figure 1,\nSliSum divides all summaries into sentences, then\nuses DBSCAN (Ester et al., 1996) algorithm to clus-\nter them based on lexical similarity. Specifically, we\nuse ROUGE-1 (Lin, 2004) F1 score to define the\ndistance between two sentences C\u2081 and C2:\n$$dist(C_1, C_2) = 1 - R(C_1, C_2)$$\nwhere R(.) is ROUGE-1 F1 score, and is computed\nas follow:\n$$R(C_1, C_2) = \\frac{2 * \\text{number of overlap words}}{\\text{length of } C_1 + \\text{length of } C_2}$$\nObviously, $R(C_1, C_2) \\in [0,1]$. There are two im-\nportant parameters in the DBSCAN algorithm: dis-\ntance threshold $\u03b5$ and minimum number of points\n(MinPts) in a cluster. Formally, let $\\hat{C}$ represents\na sentence, if exists a set of sentences (including\n$\\hat{C}$ itself) $C = {C_1,C_2,\u00b7\u00b7\u00b7,C_N}$ and the number of\nsentences $|C > \\text{MinPts}$, every sentence $C\\in C$\nsatisfies\n$$dist(\\hat{C}, C) < \u03b5$$\nC will be considered a cluster. A lower MinPts\ninduces the algorithm to construct more clusters,\nwhile a higher MinPts will ensure more robust and\nconsistent clusters.\nFiltering Noise Intuitively, if an event appears\nin the local summary of a window, it means that\nthe event is important to the content in the window.\nWe notice that some sentences are only important\nin minority windows and should not appear in the\noverall summary. Furthermore, LLMs occasionally\ngenerate few hallucination statements that deviate\nfrom the source article. These statements tamper\nwith information in the source article or add informa-\ntion that cannot be inferred from the source article,\nthus they generally have low lexical similarity to\nfactually consistent statements. These undesirable\nstatements are treated as outliers and noise in DB-\nSCAN algorithm. Due to MinPts determines the\nminimum number of points in a cluster, so we can\nfilter out unimportant and hallucination statements\nby using an appropriate MinPts.\nAs mentioned in Section 3.1, SliSum generate K\nsummaries for the content of the source article by\nsliding generation, that is, sentences about the"}, {"title": "3.3. Contradictions Detection and\nSentences Aggregation", "content": "Sentences Selection As shown in Table 1 and\nFigure 1, there may be contradictory statements\nin sentences about the same event. Due to LLMs\nhave ability to detect self-contradictory statements\nwithout relying on additional knowledge (M\u00fcndler\net al., 2024), SliSum first manipulates the LLM used\nin the sliding generation to divide sentences into\ndifferent categories according to their semantics.\nGenerally, the more times a certain response is\noutput by LLMs, the higher the probability that the\nresponse is desirable (Wang et al., 2023b; Manakul\net al., 2023), since self-consistency reflects factual\nconsistency. Consequently, SliSum can utilize ma-\njority voting algorithm to select sentences that are\nfaithful to the source article.\nAfter distinguishing sentences that are high lexi-\ncally similar but semantically different, sentences\nof the same category state the same fact. SliSum\nselects the sentence with the largest proportion\nto output to the final summary. When there are\nclusters of sentences with the same proportion or\nwhen it is necessary to choose sentence from a cer-\ntain cluster, the relatively last generated sentence\nis selected by SliSum. Because the last gener-\nated sentence is located at the beginning of the\ncorresponding window, and LLMs have the highest\nfactual consistency for the information occurs at the\nbeginning of the input context (Ravaut et al., 2024;\nChhabra et al., 2024). For example, an event has\nfive related statements [D\u2081,\uff65\uff65\uff65, D5] generated se-\nquentially, and LLM divides them into [D2], [D1, D4],\n[D3, D5], SliSum selects D5 as the most faithful\nstatement to form the summary of the entire article.\nSentences Integration SliSum finally integrates\nall selected sentences to output the final summary\nof the entire article. SliSum uses LLM to generate\nconnectives and concatenate these sentences in\norder, so that the order of the final summary is\nconsistent with the source article. We determine\nthe order of the sentences according to the order of\nthe events they describe. In the integration stage,\nSliSum do not need to change any information of\nthe selected sentences."}, {"title": "4. Experimental Setup", "content": "4.1. Datasets\nWe evaluate the performance of SliSum for short\nand long text summarization on four popular bench-\nmark datasets: CNN/DM (Hermann et al., 2015)\nand XSum (Narayan et al., 2018) are two widely-\nused short news summarization datasets. PubMed\nand arXiv (Cohan et al., 2018) are two scientific\npaper datasets for long document summarization,\nwhich are much longer than the common news arti-\ncles. PubMed contains academic papers from the\nbiotechnology domain, while arXiv contains papers\nfrom different scientific domains. Limited by the\nmaximum number of requests and time cost, we\nrandomly select 100 articles from test set of each\ndataset to construct our test set, respectively.\n4.2. Baselines\nTo validate the effectiveness of our proposed ap-\nproach, we apply SliSum to three state-of-the-art\ninstruction-tuned LLMs, including LLaMA-2 13B\nChat, Claude-2 and GPT-3.5-Turbo-0613.\nWe also compare SliSum with recent faithfulness\nenhancement summarization models on CNN/DM\nand XSum, such as CLIFF (Cao and Wang, 2021)\nand FES (Chen et al., 2022). We select GPT-3.5\nwith SumCoT (Wang et al., 2023c) as LLM news\nsummarization baseline. For arXiv and PubMed,\nwe compare SliSum with two long document sum-\nmarization baselines: FactorSum (Fonseca et al.,\n2022), a factorized energy-based abstractive model\nthat improves the performance and applicability by\nseparate budget decisions from selecting important\ncontent in the document, and Lodoss (Cho et al.,\n2022), an extractive architecture that learns robust"}, {"title": "4.3. Metrics", "content": "We evaluate the factual consistency, fluency and\ninformativeness of summaries using four different\nmetrics: (1) FactCC (Kryscinski et al., 2020), a\nweakly-supervised, model-based approach for ver-\nifying factual consistency and identifying conflicts\nbetween source documents and generated sum-\nmaries, (2) SummaC (Laban et al., 2022) that en-\nables natural language inference models to detect\ninconsistency, (3) ROUGE(Lin, 2004), an automatic\nevaluation metric for the informativeness and flu-\nency of a summary based on lexical overlap, and\n(4) BERTScore (Zhang et al., 2020), that computes\na similarity score between candidate and reference\nsummaries using contextual embeddings."}, {"title": "4.4. Implementation", "content": "We run LLaMA-2-13B with Text Generation Infer-\nence on 8 \u00d7 24GB NVIDIA GeForce RTX 3090\nGPUs. For CNN/DM and XSum, we cluster and\nfilter sentences using the DBSCAN algorithm with &\n= 0.25 and MinPts = 2. The window size Lw is 150"}, {"title": "5. Results", "content": "5.1. Main Results\nOverall Performance. The experimental results\nof SliSum and baselines on four summarization\ndatasets are reported in Table 3. In terms of short\ntext summarization, Claude-2 with SliSum achieves\na relative gain of 13.9% on FactCC and 15.8%\non SummaC for CNN/DM respectively. Notably,\nClaude-2 with SliSum also performs the best on\nboth ROUGE and BERTScore compared with other\nbaselines, indicating that SliSum simultaneously im-\nproves informativeness and fluency of summaries.\nFor long document summarization, Claude-2 with\nSliSum achieves a notable relative gain of 20.5%\non FactCC and 22.2% on SummaC for arXiv\nrespectively. Although FactorSum and Lodoss\nachieve close performance to SliSum on reference-\nbased similarity metrics, they are significantly lower\nthan SliSum on FactCC and SummaC. Regarding"}, {"title": "SliSum enhances the ability to process long\ncontexts.", "content": "We observe that SliSum has different\nperformance gains on different datasets, which may\nbe due to the style or length of the text. To eliminate\nthe distractor of the text style and further demon-\nstrate the effectiveness of our approach on news\ntexts. We evaluate the factual consistency of GPT-\n3.5 on test samples of length ranges from 500 to\n3000. We select 25 samples from CNN/DM and\nXSum with a length that is less than 5% different\nfrom the specified length to construct the test sets,\nrespectively.\nAs shown in Figure 2, compared to the original\nmodel, SliSum significantly improves the faithful-\nness of GPT-3.5 in news texts of various length,\nand the performance gain is positively correlated\nwith the length. This is consistent with the results\nin Table 3 and indicates that SliSum is capable of\nleading to larger benefits from increasingly long con-\ntext. Besides, SliSum prevents the FactCC and R-1\nscore of the summaries from continually decreas-"}, {"title": "5.2. Ablation Study", "content": "SliSum contains two essential modifications: slid-\ning generation, filteration and aggregation based on\nself-consistency. In order to investigate the effect\nof modification designed in the SliSum, we conduct\nthe following ablation studies by comparing SliSum\nwith corresponding variation on GPT-3.5."}, {"title": "Sliding Windows vs. Parallel Windows.", "content": "Par-\nallel window(PW), a special case of sliding win-\ndow(SW), partitions contexts in a non-overlapping\nmanner. To investigate the contribution of sliding\ngeneration to SliSum, we compare comprehensive\nperformance of SW and other baselines (also gen-\nerate the summary K times to perform aggrega-\ntion). Table 4 shows that single window method is"}, {"title": "Filteration and Aggregation improve faithful-\nness.", "content": "In order to understand the importance of fil-\nteration and aggregation based on self-consistency,\nwe conduct ablation study by comparing SliSum to\nvariation w/o aggregation. We remove two steps\nby directly generating global summaries for all lo-\ncal summaries (Map-Reduce (LangChain, 2023a)).\nAs shown in Figure 3, the FactCC scores of both\nSW and PW w/o aggregation are lower than their\ncounterparts. Notably, sliding windows w/o aggre-\ngation substantially diminish the factual consistency\nof summaries, even worse than parallel windows\nw/o aggregation. This indicates that aggregation\nis essential for SliSum, because sliding generation\nwhile providing more diverse information also leads\nto self-contradiction problem, which asks us to ad-\ndress this problem by filteration and aggregation\nbased on self-consistency."}, {"title": "5.3. Impacts of Hyperparameters", "content": "We conduct quantitative experiments to investigate\nimpacts of hyperparameters in SliSum on perfor-\nmance. Limited by computational resources and\nbudget, we randomly select 25 articles from corre-\nsponding dataset to construct reduced test sets.\nRatio of Lw to Ls. Figure 4 (left) shows that the\nFactCC score when varying in ratio K = [Lw/Ls]\nfrom 1 to 10. As shown in Equation 1, K repre-\nsents the minimum number of process content of\nthe article. A large K can more adequately ex-\nploit the self-consistency of LLMs to improve per-\nformance. When the ratio grows from 1 to 5, the\nFactCC scores increased by 9.5% and 11.5% on\narXiv and PubMed respectively, yet gradually con-\nverges when the ratio grows from 5 to 10, which\nindicates that processing articles too many times\nis extremely expensive and unnecessary. To save\ncomputational resources, we set the Lw/Ls to 5 in\nour experiments."}, {"title": "Window Size.", "content": "Intuitively, shorter window means\nthat LLMs can more accurately exploit information\nin context. But this has harmful effect on global\nunderstanding of entire article, resulting in the sum-\nmary only contains locally important content. Nev-\nertheless, a longer window will cause distraction\nissue and more uncertainty. As shown in Figure\n4 (right), the FactCC score of summaries initially\nraises as the window size grows. However, when\nwindow size increases from 750 to 1200, the perfor-\nmance remains stable or slightly drops. The quan-\ntitative experiments results indicate that LLMs re-\nquire sufficient information to generate high-quality\nsummaries from context, but a larger window will\nnot further boost performance."}, {"title": "Minimum Number of Clusters (MinPts).", "content": "MinPts\ncontrols clustering and filtering of sentences about\nthe same event. A higher MinPts forces SliSum to\nselect sentences that are important in more win-\ndows. Table 5 shows the FactCC and R-1 scores\nsignificantly increase with a bigger MinPts, but it will\nalso lower R-1 score when MinPts greater than 3,\nas a result of many relatively important sentences\nare filtered out. Therefor, we set MinPts to 3 for\narXiv and PubMed. More generally, considering the\nbalance between faithfulness and informativeness\nof summaries, the MinPts is set to K for different\nparameter configurations."}, {"title": "Distance Threshold $\u03b5$", "content": "The choice of distance\nthreshold $\u03b5$ depends on the data distribution. We\ncount the average and the maximum distance be-\ntween statements about the same event on the\nfour datasets. Besides, we also calculate the aver-\nage Hausdorff distance between sets of statements\nabout different events. Given the set of statements\nX and Y for events A and B, the Hausdorff distance\nbetween X and Y is\n$$dH(X,Y) = \\max\\{\\sup_{x\\in X} \\inf_{y\\in Y} d(x, y), \\sup_{y\\in Y} \\inf_{x\\in X} d(x, y)\\}$$\nTable 6 shows that the average distance between\nstatements about the same event is around 0.25,\nwhich is much smaller than the distance between\nstatements about different events. Hence, we set\n$\u03b5$ to 0.25 for all datasets. The results in table 6\nare consistent with our observation that statements\ngenerated by LLMs for the same event are lexically\nsimilar."}, {"title": "5.4. Complexity Analysis", "content": "Theoretical Analysis SliSum reduces the com-\nputational complexity in the process of summary\ngeneration compared with the base model. For\nthe input of length L, the computational complexity\nof most LLMs (such as LLaMA) is O(L\u00b2). How-\never, after applying SliSum to base models, the\ncomputational complexity of summary generation\ndecreases to O(L).\nGenerally, given window size Lw, step size Ls\n(Ls \u2264 Lw) and an article whose length is Lis\nfar larger than the window size, K = Lw/Ls (see\nEquation 1). Our approach needs to process a total\nof (L/Ls + (K \u2212 1)\u00b2) text segments of length Lw,\nhence, the complexity of SliSum is\n$$O(K \\times L_w \\times L + (K \u2212 1)^2 \\times L_s^2) = O(L)$$\nBy solving the equation, we can see that when\nthe input length is greater than 1.36 \u00d7 K \u00d7 Lw,\nthe computational cost of summary generation of\nSliSum is less than base model.\nOf course, SliSum also includes filteration and ag-\ngregation, which brings additional computational\ncosts. However, the DBSCAN algorithm runs very"}, {"title": "6. Conclusion", "content": "In this paper, we propose SliSum, a novel LLM\nsummary generation architecture, which improves\nfaithfulness of LLMs in both short and long text\nsummarization without additional resources and\nfine-tuning. SliSum leverages sliding generation\nas instruments for exploiting the self-consistency of\nLLMs, enables LLMs to more fairly and faithfully pro-\ncess contexts of various length, and solve contra-\ndictions between local summaries by clustering and\nfiltering. Extensive experiments demonstrate the\neffectiveness of SliSum in diverse LLMs. SliSum\nempowers LLMs to generate faithful summaries\nwhile maintaining their fluency and informativeness.\nFurthermore, we conduct ablation studies to justify\nthe modification made in the SliSum and investi-\ngate the impact of hyperparameters in SliSum. We\nalso demonstrate through theoretical analysis and\nquantitative experiments that SliSum only slightly\nincreases the computational cost."}]}