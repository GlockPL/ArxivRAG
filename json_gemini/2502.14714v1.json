{"title": "From Knowledge Generation to Knowledge Verification: Examining the BioMedical Generative Capabilities of ChatGPT", "authors": ["Ahmed Abdeen Hamed", "Byung Suk Lee"], "abstract": "The generative capabilities of LLM models present opportunities in accelerating tasks and concerns with the authenticity of the knowledge it produces. To address the concerns, we present a computational approach that systematically evaluates the factual accuracy of biomedical knowledge that an LLM model has been prompted to generate. Our approach encompasses two processes: the generation of disease-centric associations and the verification of them using the semantic knowledge of the biomedical ontologies. Using ChatGPT as the select LLM model, we designed a set of prompt-engineering processes on the other hand to generate linkage between diseases on one hand and drugs, symptoms, and genes to establish grounds for assessments. Experimental results demonstrate high accuracy in identifying disease terms (88%-97%), drug names (90%-91%), and genetic information (88%-98%). The symptom term identification accuracy was notably lower (49%-61%), as verified against the DOID, ChEBI, SYMPTOM, and GO ontologies accordingly. The verification of associations reveal literature coverage rates of (89%-91%) among disease-drugs, and disease-genes. The low identification symptom terms also contributed to the verification of symptom-related associations (49%-62%). The work shows that while ChatGPT has a strong potential for generating correct biomedical terms, limitations such as generating incorrect ontology term IDs and improper mapping of terms with their corresponding IDs. The work also shows that the recent the publications, the high coverage rate of the generated association. Such evidence suggests the reliance on training data within the last five years. However, there is an exception of this observation, where some associations were covered in older publication. This observation may suggest that the genAI tool may have been also trained from real- world evidence which could have the caused the emergence of a forgotten in recent literature. Further work is needed to investigate such associations to conclude their significance.", "sections": [{"title": "1. Introduction", "content": "Large language models (LLMs) possess impressive generative capabilities, presenting op- portunities to accelerate various tasks while also raising concerns about the reliability of the knowledge they generate. To address these concerns, we introduce a computational approach for systematically evaluating the factual accuracy of biomedical information produced by an LLM. Our method consists of two core processes: generating disease-centric associations and validating these associations using the semantic framework of biomedical ontologies. With ChatGPT as our selected LLM, we implemented a set of prompt-engineering techniques to establish associations between diseases and related drugs, symptoms, and genes, providing a robust foundation for accurate and reliable assessments."}, {"title": "1.1. Background and motivation", "content": "Concerned with the authenticity of scientific knowledge as one of the major concerns since the emergence of ChatGPT [1], we have published a perspective that provided a research agenda on how the scientific community may protect authenticity [2]. The research agenda included two main research issues to combat misinformation and safeguard authenticity. The first issue is to fight fake science, which ChatGPT may exacerbate due to its generative capabilities. To address this issue, in our previous work we introduced the xFakeSci algorithm as a learning algorithm designed to distinguish fake articles generated by ChatGPT from real articles [3]. The algorithm distinguished real articles from fake ones with high precision. The second issue on the agenda is the verification of the factuality of ChatGPT-generated content. In this paper, we address this issue algorithmically with demonstrations through experiments against literature in the biomedical field."}, {"title": "1.2. Literature review", "content": "Various studies directly addressed the significance of authenticity with emphasis on fact- checking. Our earlier effort addressed the fact-checking aspects of simulated medical ab- stracts to assess the correctness of disease and gene names in the content [4]. Another effort that explored issues related to factuality pertaining to large language models (LLMs), and how they may pose threats on authenticity and fact-checking [5]. With the emergence of LLMs and their powerful generative capabilities, some efforts were called for to use such models as tools for fact-checking. One study presented their work in a review of the literature that evaluated the use of LLMs for fact-checking and presented various strategies similar to xFakeSci [3], to mitigate issues in education and professional practice [6]. Another study examined the use of LLMs in fact-checking news headlines. The study found that such tools may influence the perception in the headline and shake the trust in the sources. The authors concluded the need to address the use of AI in fact- checking by introducing guidelines [7]. A similar study assessed various LLMs ChatGPT, Bing AI CoPilot, and Bard (currently known as Gemini) [1, 8, 9] to perform news fact- checking. While the study highlighted the potential advantages LLMs may provide, it also emphasized the importance of the role of human cognitive skills in establishing trustworthy news [10]. Another study also used LLMs as tools for multilingual fact-checking [11]. The study analyzed the contents of five languages - Spanish, Italian, Portuguese, Turkish, and Tamil and employed various prompt-engineering techniques such as zero-shot, chain of"}, {"title": "1.3. Goal and objectives", "content": "The goal of our work is to test the generative capabilities of ChatGPT to generate disease- centric biomedical terms and associations. There are two objectives under this goal. Objective 1: Assess the model for its accuracy of the terms and associations they generate. The terms and associations represent the two structural aspects of the biological networks generated by the models, and their verifications are performed separately. Objective 2: Assess the model for its ability to generate simulated biomedical abstracts with valid associations embedded in them."}, {"title": "2. Experiment Tasks", "content": "Three tasks are performed in our experiments the first two tasks address the first objective and the third task addresses the second objective. Task 1 (Term correctness verification): This task is to verify the biomedical terms that make up a generated association, where we use biomedical ontology, such as GO, DOID, ChEBI, and Symptoms ontology [26, 27, 28, 29, 30, 31, 32], as the ground truth to verify the term's identity. When a term is not found in an ontology, it is said to be \u201cunverified.\u201d (\"Unverified\" does not mean \"invalid\u201d as the ontology may not be complete for some terms.) The second task is to verify the associations using the PubMed database as an authentic source of biomedical knowledge."}, {"title": "Task 2 (Association reliability verification)", "content": "This task is to verify associations between terms (i.e., named entities denoted by the terms), represented as a binary relation. Mathematically the association is expressed as $R_{AB} \\subseteq A \\times B$, where $A$ is a set of terms belonging to one category, such as diseases, and $B$ is a set of terms from another category, such as genes, drugs, and symptoms. For instance, the association between diseases and genes can be expressed as $R_{DG} \\subseteq D \\times G$, where $D$ is the set of disease terms and $G$ is the set of gene terms. A pair $(d, g) \\in R_{DG}$ signifies that a particular gene, $g$, is associated with a specific disease, $d$. This formal representation provides a structured way to model associations between different categories of terms."}, {"title": "Task 3 (Association consistency verification)", "content": "This task is to verify the consistency of knowledge (centered on associations between biomedical terms) among different chatGPT models. It generates simulated abstracts from the different models and compares the asso- ciations detected from the simulated abstracts with the original associations generated in Task 2."}, {"title": "3. Experiment Methods", "content": ""}, {"title": "3.1. Data generation via prompt engineering", "content": "To test the knowledge generation capabilities of ChatGPT, we used means of prompt engineering via the APIs. The purpose was to instruct ChatGPT to generate various types of disease-centric term associations to enable the verification process. These term associa- tions are the basic building blocks of more complex forms of knowledge represented in the knowledge networks. Generating and verifying various types of associations makes the task of knowledge verification easy and efficient by decomposing the verification tasks to fine- grained unit of term associations, thereby reducing the effort to build a large and complex knowledge graph. Specifically, we instructed ChatGPT to generate 5000 associations be- tween disease on one side, and gene, symptom, and drug, respectively, on the other side. Recall that the main idea for verification is to verify (1) whether the terms of the associa- tions are verifiable from the corresponding ontology and (2) whether the actual association instances are rooted in the literature. To this end, the prompt included generating pairs of verifiable ontology-terms with their IDs. For the purpose of smooth processing, the prompt also instructed ChatGPT to format the output in JSON format, which was then validated and saved to a file. Figure 1 shows samples containing a few records from each of the three types of associations generated. Specifically, Figure 1a shows three diseases (breast cancer, asthma, and hypercholesterolemia) and the as- sociated three drugs (Carbamazepine, Zidovudine, and Fluoxetine); Figure 1b and Figure 1c show three genes (ACE, INS, and IL4) and three disease symptoms (headache, frequent urination, and shortness of breath), respectively."}, {"title": "3.2. Term correctness verification against biomedical ontologies", "content": "In this work, we address four types of terms that make up the three types of associations that can be represented formally as binary relations.\nDisease-drug association: This type of association is represented as $R_{DD} \\subseteq D \\times D_r$, where $D_r$ denotes the set of drugs. It signifies the relationship between diseases and the drugs used for their treatment or management."}, {"title": "4. Experiment Results", "content": "We present the results of the experiments in evaluating ChatGPT's capabilities in the following key tasks:\nVerifying the correctness of the biomedical terms that make up the associations (i.e., disease, symptom, drug, and genes);\nVerifying the associations linkage against biomedical literature from different periods;\nTesting the randomness of ChatGPT by generating simulated articles using various ChatGPT models."}, {"title": "4.1. Task 1 Verification of the correctness of biomedical terms", "content": "We evaluated the names of the three types of associations generated disease-drug, disease- symptom, and disease-gene/genetic process that made up the ChatGPT-generated associa- tions using domain-specific ontologies as ground truth. The verification of the terms that make up the generated associations was checking against the DOID ontology for disease terms, the ChEBI ontology for the drug terms, the SYMPTOM ontology for the symptom terms, and the GO ontology for the genetic terms (gene names and genetic processes). The encoding of those ontology offer means of literal and semantic matching, which offers fair means of comparisons. For instance, the (\u201chypertension\u201d) disease term in the DOID ontol- ogy (\"DOID:10763\") [33]. Additionally, the ontology entity of this term also includes the list of synonyms (\u201cHTN [EXACT], hyperpiesia [EXACT], hypertensive disease [RELATED], vascular hypertensive disorder [EXACT]\"), which are also checked during the algorithmic process. Hence, the claim of a semantic verification process.\""}, {"title": "4.2. Tasks 1.1 Verification of disease terms", "content": "The task of of generating disease terms was common across three types of associations. The verification result of the terms in the three types of associations are as follows.\nFor disease-drug associations, the literal matching process verified 93% of disease terms, while the semantic matching verified 87% of the generated names. Combined, 98% of disease names were successfully verified.\nFor disease-symptom associations, the literal matching verified 97% of the disease terms, while the semantic matching verified 82% of the generated terms. Combined, 99% of disease names were successfully verified.\nFor disease-gene associations, the literal matching verified 88% of the disease terms, while semantic matching verified 97% of the generated terms. Due to the high per- centage of verification, the task of a combined matching was omitted."}, {"title": "4.2.1. Tasks 1.2 \u2013 Verification of non-disease terms", "content": "Here we summarize the results of ChatGPT generating correct drugs, symptoms, genes, and genetic processes as part of the associations:\nDrug names: the literal matching verified 90% of drug names, with an 90% verified through synonym matching. The combined verification rate was 91%.\nSymptom names: literal matching verified 49% of symptom names, with an addi- tional 25% verified through semantic matching. The combined verification rate was 61%.\nGenetic processes and gene names: the verification resulted in the verification 80% of the gene names and 97% of the genetic processes."}, {"title": "4.3. Task 2: Verification of the reliability of biomedical association links", "content": "While domain-specific ontologies offer verification of individual entities of the associa- tions, they do not offer the means of verifying the actual relationships between the individual"}, {"title": "4.4. Task 3: Verification of the association consistency against ChatGPT-simulated Abstracts by various models", "content": "To assess how consistent (or random) the ChatGPT-generated associations are, we gen- erated disease-centric simulated abstracts using various ChatGPT models. Specifically, we prompted four ChatGPT models ChatGPT-4, ChatGPT-4turbo, ChatGPT-40, and ChatGPT-4omini to generate simulated abstracts centered on human diseases. Due to the computational cost of this task, we limited the generation to approximately 5,000 ab- stracts per model. Figure 5 shows number of hits per model for three types os associations in three layers: the top layer in blue is for disease-drug, the middle layer in red shows the drug-genes, while the bottom layer in green is for the disease-symptom. The verification process is summarized in Table 5.\nDisease-drug association achieved coverage rate of (1% to 15%);"}, {"title": "5. Discussion", "content": "In this work, we tested the capabilities of ChatGPT to generate biomedical associations as building blocks for more complex data models such as biomedical networks and knowl- edge graphs. Specifically, we designed a prompt-engineering algorithm that produces human disease-centric associations in the context of symptoms, drugs, genetics. The algorithm prompted for generating association terms that match the corresponding specialized ontol- ogy, namely, DOID, ChEBI, SYMPTOM, and GO ontology. The prompt also provided a shot as an example of what is to be produced for a valid association. Each association was to be between two terms, a source and a target, where each term is encoded by a term ID"}, {"title": "5.1. Term correctness verification", "content": "The most striking observation is in the outcome of term verifications using ontology. Though the terms ChatGPT produced were highly accurate, IDs of the terms were entirely imaginary. Consequently, the term IDs failed to match the actual IDs in their corresponding ontology; the term IDs did not exist in the ontology and, even if it existed, it did not match the actual mapped disease in the ontology. Another surprising observation was that some of those IDs were repeated in different terms, which violates the idea of ID being unique; this observation leads to the belief that the pre-training of ChatGPT did not include formal ontology terms and, therefore, ChatGPT was unaware of the term uniqueness requirement. Concerning the coverage rate of term match, we observed a consistent trend of highest coverage with the most recent 5-year publications. The number of hits decreased as we searched for coverage in the older (10 to 15 years old) datasets. This is also another training issue, which may indicate that ChatGPT training was performed only on recent biomedical publications."}, {"title": "5.2. Association reliability verification", "content": "Among the three types of associations, the disease-symptom associations demonstrated the lowest coverage. Despite that the term matching algorithm was semantic and explored the list of synonyms, the coverage remained noticeably lower than the other two types. This is another indication of training issue, that ChatGPT was not pre-trained using such resources as biomedical ontologies. What is also surprising with this observation is that verification of the actual associations between disease terms and their symptom terms using the biomedical literature did not hold. This confirms that ChatGPT generated valid terms and associations but used the literature terminology, not the formal domain-specific terminology. Association verification against the biomedical literature results in a positive outcome of very high coverage for some associations. This observation offers some confidence knowing that ChatGPT has certain knowledge that may be considered the fundamentals of science, common knowledge, or frequently studied associations; examples of such associations are the disease-drug association between diabetes mellitus and insulin, which was covered by 3000+ co-occurrences; the disease-gene association between breast cancer and ataxia telangiectasia mutated (ATM), where 9000 co-occurrences pointed to it that the ATM gene may cause the breast cancer. Generating such associations may summarize the basic building blocks in the human diseases, which is the ultimate objective of this study. It may also trigger incremental generation of associations while performing verification, to construct a more comprehensive human disease landscape."}, {"title": "5.3. Association consistency verification", "content": "When performing the association consistency verification we observed that some of the frequencies is only a single occurrence in a publication abstract. These low coverage associ- ations may be coincidental in most cases. However, after investigating various instances we"}, {"title": "6. Future Directions", "content": "We have tested our verification methods and algorithms on various ChatGPT models as the first and foremost stable models. However, we plan on pushing the boundaries of open- source models to eliminate the cost limitation. Particularly, the lack of ChatGPT awareness of the ontology term ID and ontology term name connection requires exploration that may include retrieval augmented generation (RAG)-oriented prompt engineering. This process may result in encoding a selected instance of various ontology terms as part of a prompt to inject such connection into the selected model. Some of the open-source LLMs plan to use are (Microsoft Phi-3, Meta Llama, QWen2.5, TiniZero) [42, 43, 44, 45, 46, 43] among others. To further investigate the interesting associations covered during our analysis. For in- stance, the association between non-small cell lung cancer and lapatinib can also be further explored using retrieval augmented generation (RAG) prompt engineering. In this case, we will attempt injecting the verified associations, along with their full PubMed abstracts that co-occur, as part of a series of prompts to learn all the surrounding facts around this associ- ation. For instance, we may inject the association as part of a prompt along with a given set of PubMed abstracts, and instruct the LLM to generate knowledge about the drug-target,"}, {"title": "7. Declaration of generative AI and AI-assisted", "content": "During the preparation of this work the author(s) used ChatGPT in order to generate associations and simulated articles to produce the datasets of this work. The authors also used ChatGPT to perform LaTeX formatting to enhance the presentation of the work. How- ever, the writing was written entirely by the authors and no GenAI tool was invloved in the writing process."}]}