{"title": "Evaluating the Translation Performance of Large Language Models Based on Euas-20", "authors": ["Yan Huang", "Wei Liu"], "abstract": "In recent years, with the rapid development of deep learning technology, large language models (LLMs) such as BERT and GPT have achieved breakthrough results in natural language processing tasks. Machine translation (MT), as one of the core tasks of natural language processing, has also benefited from the development of large language models and achieved a qualitative leap. Despite the significant progress in translation performance achieved by large language models, machine translation still faces many challenges. Therefore, in this paper, we construct the dataset Euas-20 to evaluate the performance of large language models on translation tasks, the translation ability on different languages, and the effect of pre-training data on the translation ability of LLMs for researchers and developers.", "sections": [{"title": "Introduction", "content": "The application and performance of Large Language Models (LLMs) on translation performance has become an important research direction and practical achievement in the field of modern natural language processing. In the recent emergence of large language models (LLMs), e.g., GPT-3 and GPT-4, their translation performance on Zero-shot can be compared to that of powerful fully supervised machine translation systems [1,2,3,4]. However, the massive corpus used for training big language models is usually dominated by monolingual data, in which the English corpus is dominant, while the proportion of corpus in other languages is relatively small [5,6]. Under this data distribution, whether the big language models can effectively model the correspondence between different languages and learn reliable translation knowledge is a great concern for researchers [7]. Models may face challenges in handling translation tasks between these languages. Therefore, we evaluate the popular large language models currently available in the market to acquire a better perception of the translation performance of large language models.\nIn this paper, the translation ability of Large Language Models (LLMs) is investigated by answering two questions, 1) What is the translation ability of LLMs?2) Factors affecting the translation ability of LLMs?3) What are the translation results of the LLMS?"}, {"title": "Background", "content": ""}, {"title": "Large Language Models", "content": "Large Language Models (LLMs) have made significant progress in translation performance. Based on deep learning, especially the Transformer architecture[14,15,16]\n, these Large Language Models have learned rich linguistic knowledge by pre-"}, {"title": "Machine Translation", "content": "Machine Translation (MT) is a technology that uses computers to automatically translate text from one language to another. In recent years, with the rapid development of artificial intelligence and natural language processing technology, especially the emergence of large language models (e.g., OpenAI's GPT series and Google's BERT), the ability of machine translation has been significantly improved.\nModern machine translation systems mainly rely on Neural Machine Translation (NMT) technology [17,18] . NMT utilises deep learning and neural network models, and is able to efficiently capture and process complex relationships between source and target languages through encoder-decoder architectures and self-attention mechanisms. Compared with traditional rule-based methods and statistical machine translation (SMT)[19,20], NMT performs better in terms of translation accuracy, fluency, and context understanding.\nMachine translation, as one of the core tasks of natural language processing, has also benefited from the development of large language models and achieved a qualitative leap. However, machine translation still faces challenges, including translation of low-resource languages and maintaining coherence and fluency of translation in long texts [21]."}, {"title": "Experimental Setup", "content": ""}, {"title": "Dataset", "content": "In order to evaluate the real translation capabilities of large language models, we constructed a dataset called Euas-20. This dataset contains twenty representative languages (Table 1), covering a large part of the global population, while demonstrating a diverse background of writing systems and language families. We have selected a number of important languages that not only have a large number of speakers, but also include some languages that are considered under-resourced in the research community. With this diverse dataset, we are able to comprehensively evaluate the translation performance of the large language models in different language contexts, and thus gain a more accurate understanding of their performance in real-world applications.\nlanguages we use in our work are listed in Table 1. Referring to the information provided in Goyal et al. (2022)[22], we populated the table. For each language, we show the ISO code, language name, language grouping, alphabet and resource level.\nWe selected about twenty domains such as medicine, science, art, education, environment, finance, entertainment, sports, politics, agriculture, etc. to ensure a wider coverage of the dataset. After that, we designed a prompt (Fig.1) and fed it into ChatGPT, allowing it to act as a data annotator and generate sentences according to specified rules. In each domain, ChatGPT generated fifty sentences, including different sentence types such as declarative, interrogative and exclam-atory sentences. We deleted sentences with high similarity and repeated the process, eventually selecting about fifty different sentences in each domain and constructing a document containing one thousand Chinese sentences.\nNext, we used Google Translate to translate this Chinese document into other target languages to build a complete dataset. In this way, we ensure that the"}, {"title": "LLMS", "content": "We evaluated the translation capabilities of nine currently popular LLMSs: falcon7b, mistral-7b, Llama-2-7b-hf, bloom-7b1, bloomz-7b1-mt, Meta-Llama-3-8B, mpt-7b, vicuna-7b, and gemma-7b."}, {"title": "Evaluation Methods", "content": "Focusing on Chinese and English, through a prompt (Fig. 2), 'source-sentence' stands for the original sentence and 'target-sentence' stands for the target sentence, and the original sentence is input to the LLMs by the command (Translate the following sentence from 'source-language' to 'target-language' and The 'target- language' translation is), so that the LLMs can translate and output the target sentence under Zero-Shot learning. In this way, various languages in the dataset are translated into Chinese and English."}, {"title": "Evaluation Indicators", "content": "Evaluation metrics are an important measure of translation quality. We adopt commonly used automatic evaluation metrics including BLEU [23], which calculates translation accuracy by comparing the n-gram overlap between candidate"}, {"title": "Testing of machine translation for LLMs", "content": "In this section, we report the results of the translation of LLMs (Fig.3) and analyse the translation performance of LLMS."}, {"title": "Continuous Improvement of Translation Ability of LLMs", "content": "In recent years, the multilingual translation capability of Large Language Models (LLMs) has been significantly improved. Even under Zero-Sample Learning (Zero-Shot) conditions, LLMs still exhibit good translation performance in most translation directions, as shown in Fig. 4. Based on the scores of LLMs on different languages, we can find that the translation ability of LLMs has gradually improved, especially the recent LLMs have reached new heights in terms of translation performance. For example, Llama-3-8B significantly outperforms the previous Llama-2-7B, and vicuna-7B outperforms Llama-2-7B. Overall, Llama-3-8B performs the best among all the LLMs evaluated, and it obtains the highest"}, {"title": "Translation performance of LLMSs across languages", "content": "The translation performance of large-scale language models (LLMs) varies significantly across languages. Typically, LLMs translate well on high-resource languages, but have relatively poor translation performance on low- and medium-resource languages. We find that LLMs perform particularly well when translating into English and relatively poorly when translating into Chinese. For languages similar to English, LLMs also demonstrate better translation perfor-"}, {"title": "Effect of corpus on the translation performance of LLMs", "content": "By analysing pre-training data and corpora of large-scale language models (LLMs), we can investigate the relationship between translation performance and corpus"}, {"title": "Illusions in the translation of LLMS", "content": "Neural Machine Translation (NMT) is a task that translates a source language into a target language through inference and relies on parallel data samples used for training. Compared to Statistical Machine Translation (SMT), the output of NMT is usually very fluent, with a quality close to the human level. However, this poses a potential problem: when NMT hallucinates (i.e., generates inaccurate or spurious translations), its smooth output may mislead users and make it difficult for them to identify errors in the translation.\nBy analysing the translation results of LLMs, we classified the hallucinations in NMT as two categories [25], intrinsic and extrinsic hallucinations. Intrinsic Illusion: Incorrect information is included in the translation that does not match what is in the source text. An example of such an illusion is \u2018\u4e0d\u592a\u4e86\u89e3', which negates \u2018\u4e86\u89e3\u591a\u5c11,in the source text. Extrinsic illusions: the translation produces additional content that does not exist in the source text.'\u6211\u5fd8\u4e86\u5e26\u624b\u673a is an example of illusory content because it is added without any apparent connection to the input."}, {"title": "Translation words that LLMs tend to choose in translation tasks", "content": "This section explores the translation words that Large Language Models tend to choose in translation tasks and the reasons behind them.\nThrough previous analyses of the translation results of Gemma-7B and Falcon-7B, we found that LLMs tend to choose common word collocations in the target language during the translation process. This not only improves the naturalness of the translation, but also makes it more in line with the usage habits of the target language. For example, 'make a decision' in English is often translated as\u2018\u505a\u51b3\u5b9a'instead of\u2018\u5236\u9020\u51b3\u5b9a'in Chinese because the former is a common collocation in Chinese and is more in line with the language conventions. This is because the former is a common collocation in Chinese, which is more in line with the language convention.\nIn addition, we also found that the model selects those words that are closest in meaning to be translated by deep understanding of the original and the translated text. For example, when translating the English word 'computer' into Chinese, the model chooses\u2018\u7535\u8111\u2019instead of \u2018\u8ba1\u7b97\u673a\u2019because\u2018\u7535\u8111\u201d is a com-mon collocation in modern Chinese. 'is more commonly used and semantically accurate in modern Chinese.\nLLMs tend to choose the most appropriate translation words in translation tasks by comprehensively analysing various factors such as semantics, fluency and culture. This approach not only improves the accuracy and naturalness of the translation, but also makes the translation result more in line with the usage habits of the target language."}, {"title": "Phenomenon of unregistered words", "content": "Out-of-vocabulary words (OOV words), refer to words that have not been encountered during model training. These words may be new terms, technical terms, foreign language vocabulary, or recently emerged buzzwords. We found that due to the lack of training on these words, the model cannot understand or process them accurately. We choose the translation results of Gemma-7B and Falcon-7B as representative.\nFor monolingual models, when the model is confronted with words that have not been trained across languages, such as \u2018madilim na bagay' (dark matter) in Filipino, the model will ignore or mistranslate them to other nouns. For multi-lingual models, even if the model has been trained cross-linguistically, when the model encounters a new word like 'schadenfreude' (a German word that refers to the emotion of taking pleasure in someone else's misfortunes), it may not be"}, {"title": "Related Work", "content": "In the field of large language model translation capability evaluation, there have been a large number of related studies devoted to exploring the translation performance of different models on multiple language pairs and text types.Bang et al. (2023) [26]and Hendy et al. (2023)[27] evaluated ChatGPT on 13 and 18 languages, respectively; Zhu et al. (2023)[28] evaluated the translation capability of four popular large language models, XGLM, BLOOMZ, OPT, and ChatGPT, on 102 languages, on 202 directions. 202 directions The multilingual translation capabilities of four popular large language models, XGLM, BLOOMZ, OPT and ChatGPT, were evaluated.\nIn this paper, 20 representative languages are selected to evaluate nine current mainstream large-scale language models. The evaluation focuses on Chinese and English, but covers a wide range of other languages as well. Multilingual translations are performed with these models and the results are compared with a state-of-the-art translation engine (Google Translate) in order to comprehensively evaluate the translation capabilities and performance of these large language models. The aim of the study is to determine the performance of these models in different linguistic contexts, as well as their usability and accuracy in real translation tasks.\nDespite the significant progress made by large-scale language models on translation tasks, a number of challenges remain. For example, there is still room for improvement in the model's ability to handle low-resource languages and diverse texts. Future research directions include improving the evaluation metrics, optimising the model structure and enhancing the training methods to further improve the performance and generalisation of large language models on translation tasks. These improvements will not only help to enhance the model's translation accuracy, but also enhance its adaptability in dealing with complex and diverse language environments."}, {"title": "Conclusion", "content": "In this paper, a dataset called Euas-20 is constructed and nine popular large language models (LLMs) are evaluated using this dataset. The evaluation process focuses on Chinese and English, and compares the translation performance of these models and their translation capabilities on various languages through translations in 20 languages. Also, the paper analyses the impact of pre-training data and corpus on the translation performance of large language models. The translation results of the LLMs were analysed in various ways.\nThe results show that although the translation performance of LLMs is improving, with Llama-3 performing particularly well, far exceeding other models, the translation ability of these models on different languages is still very unbalanced. Especially when dealing with low-resource languages, they still face great challenges. In addition, a high-quality and diverse corpus plays a significant role in improving the translation performance of large language models.\nFuture research needs to continue to explore how to enhance the translation capabilities of LLMs on more languages to achieve more balanced and comprehensive translation performance. This includes improving the model structure, optimising training methods, and extending and enhancing the quality and diversity of the corpus."}]}