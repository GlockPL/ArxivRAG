{"title": "IDCIA: Immunocytochemistry Dataset for Cellular Image Analysis", "authors": ["Abdurahman Ali Mohammed", "Catherine Fonder", "Donald S. Sakaguchi", "Wallapak Tavanapong", "Surya K. Mallapragada", "Azeez Idris"], "abstract": "We present a new annotated microscopic cellular image dataset to improve the effectiveness of machine learning methods for cellular image analysis. Cell counting is an important step in cell analysis. Typically, domain experts manually count cells in a microscopic image. Automated cell counting can potentially eliminate this tedious, time-consuming process. However, a good, labeled dataset is required for training an accurate machine learning model. Our dataset includes microscopic images of cells, and for each image, the cell count and the location of individual cells. The data were collected as part of an ongoing study investigating the potential of electrical stimulation to modulate stem cell differentiation and possible applications for neural repair. Compared to existing publicly available datasets, our dataset has more images of cells stained with more variety of antibodies (protein components of immune responses against invaders) typically used for cell analysis. The experimental results on this dataset indicate that none of the five existing models under this study are able to achieve sufficiently accurate count to replace the manual methods. The dataset is available at https://figshare.com/articles/dataset/Dataset/21970604.", "sections": [{"title": "1 INTRODUCTION", "content": "Cell biology is a sub-discipline of biology where the structure and physiological functioning, and interaction of cells are studied [3]. Cells are examined under a microscope and imaged at a high resolution. In immunocytochemistry (ICC), different antibodies are used to visualize the presence of particular proteins to identify specific cell types in a given sample. Cell analysis involves a wide range of tasks, such as counting cells and measuring and evaluating cell state (e.g., shape, motility), cell health, and cell growth. Cell biology is closely intertwined with other fields, such as neuroscience, genetics, and molecular biology. One fascinating application area of cell biology is research for the potential diagnosis and treatment of diseases. The research in this area is full of potential and possibilities that could improve quality of life.\nDeep Neural Networks (DNNs) have been applied in the analysis of microscopic cell images, including cell counting [26, 35], segmentation [1, 9, 10, 23], and detection [8, 11, 34]. Given an input image, cell counting provides the number of cells in the image. In contrast, cell segmentation finds the contours of individual cells, separating them from each other and the background. On the other hand, cell detection localizes a cell by drawing the smallest rectangle around each cell in the input image. The advantages of DNNs over traditional machine learning methods are that DNNs automatically extract important properties (features) of the object of interest and use them to perform the intended task. However, the major drawback of DNNs is that it requires a large high-quality labeled dataset for accurate predictions. Existing DNN methods for cell counting can be broadly categorized into two groups: detection-based and regression-based categories.\nThe detection-based category undertakes the counting task by first detecting individual cells (contours, bounding boxes, or centroids of the cells) in a given image and counting the detected cells to obtain the final cell count [13, 23]. These methods hinge on the availability of the annotated ground truth of the bounding box or a centroid of a cell. The methods are also dependent on the characteristics of the microscopic input images. In particular, detection-based methods fail to offer good performance when there is a high occlusion in the images. The regression-based category [26, 35] predicts the cell count without detecting individual cells. Some of these methods use only the ground truth cell count for each training image for training. Other methods predict a corresponding density map for a given image and obtain the final count from the predicted density map.\nOur team examines cellular images taken after electrical stimulation experiments on stem cells for cell differentiation. Cell differentiation is the process in which an unspecialized cell develops and matures to become a specialized cell. Electrical stimulation of stem cells is potentially useful for stem cell therapy in patients with nerve"}, {"title": "2 EXISTING DATASETS", "content": "Several cellular image datasets are available publicly. Some datasets are for detection based methods [6, 15, 21, 23, 24]. These datasets, consisting of either contour or smallest bounding box annotations of individual cells, are suitable for cell counting tasks. A few datasets are specifically intended for cell counting [12, 17, 18, 22, 31]. To the best of our knowledge, the proposed dataset is the only dataset that contains images of Adult Hippocampal Progenitor Cells with different antibodies for staining."}, {"title": "3 IDCIA: PROPOSED IMAGE DATASET", "content": "We describe the data collection process and annotation process and the structure of the dataset."}, {"title": "3.1 Data Collection", "content": "Our dataset contains images of rat Adult Hippocampal Progenitor Cells (AHPCs) [14] after electrical stimulation experiments and ICC. AHPCs have the potential to differentiate into the three primary cell types of the central nervous system in vitro: Neurons, Astrocytes, and Oligodendrocytes. The experiments were performed in the Sakaguchi Lab\u00b9 at Iowa State University. The cells were generously gifted by Dr. Fred H Gage\u00b2. \nFor this dataset, the cultured cells underwent electrical stimulation at 125 mV for 10, 15, or 20-minute durations, once a day for a period of 7 days. An additional scaffold was set aside as a control and received no stimulation. After the 7-day period, ICC was performed on both the stimulated and non-stimulated samples to evaluate various neural differentiation markers. The process occurred as follows."}, {"title": "3.2 Dataset Structure and Details", "content": "After the completion of annotating all the images, we split the dataset into three non-overlapping sets: Training, Validation, and Testing at the ratio of 60:20:20. To ensure that each of these sets contains a proportional number of samples from each antibody type, we used stratified sampling based on antibody type. We then ran a program to extract the coordinates of individual dots from a dot-annotated image by thresholding the color of the dot and saving the coordinates in a csv file.\nWe used dot annotations to label the cells for counting purposes. First, dot annotation enables the accurate marking of individual cells. This is to avoid double counting some cells or missing to count other cells for images with a large number of cells or with densely packed or overlapping cells. Second, dot annotation is a fast and efficient way to count and identify cells since the exact cell contour or bounding box is not required. It is useful for expanding the dataset in the future. Third, dot annotations can be used to verify how a DNN model arrives at the predicted cell count, which should improve cell biologists' trust in the model. Finally, dot annotations are useful for the development and evaluation of both detection-based and regression-based DNN methods for cell counting."}, {"title": "4 USAGE SCENARIOS OF IDCIA", "content": "The dot-annotated microscopic cell images and accompanying immunolabeling and staining information provided in this dataset offer opportunities for computer scientists to contribute to advancing cell biology research. Here, we outline a few potential applications.\nThe dot annotations with the number and location of cells marked for each image are useful for developing effective and interpretable counting methods, as outlined in Section 2. As cell counting is an important task in cell analysis, desirable automated methods should produce the predicted count within the experts' acceptable error rate of, at most 5% difference from the actual cell count. If automated cell counting is quick, accurate, and trustworthy, electrical stimulation experiments for stem cell therapy can be accelerated. Due to a high variance in the number of cells labeled for each staining antibody, the name of the antibody used may be useful for improving automated cell counting methods. For instance, the DAPI staining of cell nuclei identifies many more cells than the immunolabeling with the antibodies. This dataset includes images from the experiments covering the use of seven primary antibodies for immunolabeling. On the contrary, DNN methods may be developed to classify images to predict the antibody used for cell labeling. We refer to this problem as antibody classification problem.\nGiven the limited number of datasets for cellular image analysis and the limited number of images for each dataset, more high-quality datasets are needed. Our dataset supplements existing datasets and may be useful for transfer learning that extracts information from data in one domain and transfers the learned knowledge to another domain [16, 29].\nBoth the cell count and the locations of individual cells are useful for developing cell segmentation or cell detection methods based on high-level labeling (i.e., weak supervision). Dot annotations, which are faster to acquire than detailed annotations, can be leveraged to obtain more detailed annotations and reduce manual labeling time. Utilizing ground truth information obtained through weak supervision can help in the automated segmentation and detection of individual cells. This allows the measurement of cell shape and orientation. Currently, proprietary software such as MetaXpress exists for measuring cell shape and cell orientation. However, the software requires that cell culture be done on a smooth surface, which greatly limits the opportunities for using custom-designed scaffolds for electrical stimulations, as shown in Fig. 1."}, {"title": "4.1 Suggested Metrics", "content": "Suggested metrics for the cell counting task are Mean Absolute Error (MAE) [2] and Root Mean Squared Error (RMSE) [2]. MAE is the average of the absolute difference between the label ground truth count $y_i$ and the predicted value count $\\hat{y_i}$ for all $n$ images in a given dataset. RMSE penalizes large errors to a greater extent compared to MAE. See Equations 1-2. We introduce Acceptable Error Count Percent (ACP) to measure the percentage of images whose predicted count is within a 5% difference from the true count by the domain expert, as shown in Equation 3. We use Iverson brackets [[.]] to denote a function that returns 1 if the condition is satisfied or 0 otherwise. These metrics are calculated below. Due to limited space, we only report MAE and ACP in this paper.\nMAE = $\\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y_i}|$ (1)\nRMSE = $\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}$ (2)\nACP = $\\frac{1}{n} * 100 \\sum_{i=1}^{n} [[ |\\hat{y_i} - y_i| \\leq 0.05 * y_i ]] $ (3)\nThe lower the values of MAE, the more accurate a model's predictions are. On the other hand, a higher ACP indicates that more predictions are in the acceptable margin. For the antibody classification problem, traditional performance metrics for classification problems such as accuracy, precision, recall, and F1-score can be used [2]."}, {"title": "5 BASELINE EXPERIMENTS FOR CELL COUNTING", "content": "We evaluated five different models for cell counting using the IDCIA dataset. They are a Convolutional Neural Network (CNN) with regression output (CNN Regression), two crowd-counting methods (CSRNet [19], MCNN [36]), and two cell-counting methods (Count-ception [26], FCRN [35]). All these four methods are based on density map estimation. For CSRNet and Count-ception, we used the source code provided by the original authors of the methods. Our CNN Regression model has a pre-trained VGG16 [30] network with a fully connected layer at the end of it, followed by one output neuron for the predicted cell count for a given image. We excluded [13, 23] from our experiments since they require detailed annotations for training. All models were implemented in Python using the PyTorch [25] library and trained on NVIDIA Tesla T4 and P2000 GPUs.\nCount-ception and FCRN were developed for cell counting. Count-ception is a network of fully convolutional layers without any pooling layer. This is to avoid losing pixel information and to ease the calculation of the receptive field. Given an input image, Count-ception produces an intermediate count map. Each network inside it counts the number of objects in its receptive field. FCRN uses CNN to regress a cell's spatial density across an image. It first maps the input image to feature maps with dense representation and then recovers the spatial span by bilinear up-sampling. FCRN allows prediction for input with an arbitrary size. FCRN-A is a version of FCRN that uses small 3 \u00d7 3 kernels for every convolutional layer, and each convolutional layer is followed by a pooling layer.\nCSRNet [19] and MCNN [36] are density-map based models developed for counting people in a congested environment. These models can handle dense crowds, which makes them well-suited for handling cell congestion. In addition, these models were designed to be robust to variations in object size and shape, lighting, and contrast conditions. CSRNet is a two-component network with a CNN as the first component for feature extraction. The second component is a dilated CNN to produce larger reception fields, replacing pooling operations. MCNN extracts scale-relevant features by using filters with different sizes of receptive fields. The authors proposed a network of three parallel CNNs with different filter sizes. For an input image, the network averages the predicted density maps of the three CNNs and outputs a final count prediction. To use the dot-annotated images for training CSRNet and MCNN, we followed the ground truth generation method in [36] by blurring each dot annotation using a Gaussian kernel to produce corresponding density maps. Since the generated density maps have a high impact on the performance of the models for cell counting, we used geometry-adaptive kernels [19] to accurately generate corresponding density maps for input images.\nAll models were then trained using an end-to-end stochastic gradient descent method [27] and data augmentations per the original authors' code. The loss function used in training was PyTorch L1Loss. The grid search method was conducted to obtain the best hyperparameter values on the validation dataset. For each method, we performed five runs on the IDCIA dataset. Each run involved training the model using the hyperparameter values that give the best MAE on the validation dataset. The average of the MAEs over the five runs was reported for each model."}, {"title": "6 CONCLUSION AND FUTURE WORK", "content": "In this paper, we present a new annotated dataset of images of cells from a fluorescence microscope. The cells were immunolabeled using a panel of cell type-specific antibody markers, and all cell nuclei stained using DAPI. The dataset is available for public use along with the source code and the trained models. We present the effectiveness of deep-learning methods for counting on the dataset. We found that different existing deep-learning models are best for different antibodies used for labeling. All the methods still underperform when using the ACP metric based on the domain experts, leaving room for improvement. The results of our study highlight the challenges in accurately predicting cell counts. We plan to continue to explore different architectures and training techniques in order to increase the performance on the ACP metric. Future work includes the development of a new DNN method that is sufficiently accurate and acceptable by domain experts."}]}