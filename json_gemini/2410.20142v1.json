{"title": "Mask-based Membership Inference Attacks for Retrieval-Augmented Generation", "authors": ["Mingrui Liu", "Sixiao Zhang", "Cheng Long"], "abstract": "Retrieval-Augmented Generation (RAG) has been an effective approach to mitigate hallucinations in large language models (LLMs) by incorporating up-to-date and domain-specific knowledge. Recently, there has been a trend of storing up-to-date or copyrighted data in RAG knowledge databases instead of using it for LLM training. This practice has raised concerns about Membership Inference Attacks (MIAs), which aim to detect if a specific target document is stored in the RAG system's knowledge database so as to protect the rights of data producers. While research has focused on enhancing the trustworthiness of RAG systems, existing MIAs for RAG systems remain largely insufficient. Previous work either relies solely on the RAG system's judgment or is easily influenced by other documents or the LLM's internal knowledge, which is unreliable and lacks explainability. To address these limitations, we propose a Mask-Based Membership Inference Attacks (MBA) framework. Our framework first employs a masking algorithm that effectively masks a certain number of words in the target document. The masked text is then used to prompt the RAG system, and the RAG system is required to predict the mask values. If the target document appears in the knowledge database, the masked text will retrieve the complete target document as context, allowing for accurate mask prediction. Finally, we adopt a simple yet effective threshold-based method to infer the membership of target document by analyzing the accuracy of mask prediction. Our mask-based approach is more document-specific, making the RAG system's generation less susceptible to distractions from other documents or the LLM's internal knowledge. Extensive experiments demonstrate the effectiveness of our approach compared to existing baseline models.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs) such as ChatGPT [3] and Llama [34], have revolutionized natural language processing. Despite these advancements, challenges remain, particularly in handling domain-specific or highly specialized queries [16]. LLMs often resort to \"hallucinations,\" fabricating information outside their training data [43].\nRetrieval-Augmented Generation (RAG) addresses this by integrating external data retrieval into generation, improving response accuracy and relevance [11, 19]. And RAG has been widely adopted by many commercial question-and-answer (Q&A) systems to incorporate up-to-date and domain-specific knowledge. For instance, Gemini [33] leverages the search results from Google Search to enhance its generation, while Copilot\u00b9 integrates the documents or pages returned by Bing search into its context.\nA recent trend involves storing up-to-date or copyrighted data in RAG knowledge databases instead of using it for LLM training. The SILO framework [25] exemplifies this approach, training LLMs on low-risk data (e.g., public domain or permissively licensed) and storing high-risk data (e.g., medical text with personally identifiable information) in the knowledge base. However, the legal implications of using data for generation models or systems are under scrutiny, with lawsuits filed globally due to potential copyright infringement [6, 24, 29, 30, 35]. This concern has spurred the development of Membership Inference Attacks (MIAs) to detect if specific data records were stored in RAG's knowledge database and could potentially appear in the generated texts, which raises concerns about fair use doctrine [12] or General Data Protection Regulation (GDPR) compliance [42].\nEven though a growing body of research has focused on enhancing the trustworthiness of RAG systems [26, 36, 41, 44, 45], to the best of our knowledge, there are only two existing works targeting at the MIAs in RAG system. RAG-MIAs [1] judges whether a target document is in the knowledge database by directly asking the RAG system (i.e., utilizing the RAG's response (yes or no) as the judgement). This approach relies solely on the RAG system's judgment, which is unreliable and lacks explainability. S\u00b2MIAs [20] prompts the RAG system with the first half (typically the question part) of the target document, and if the RAG's response is semantically similar to the remaining half (typically the answer part) of"}, {"title": "2 RELATED WORK", "content": "Retrieval-Augmented Generation (RAG) enhances response accuracy and relevance by incorporating external data retrieval into the generation process [11]. A common RAG paradigm involves using the user query to retrieve a set of documents, which are then concatenated with the original query and used as context [19].\nRecent research has focused on various retrieval methods, including token-based retrieval [18], data chunk retrieval [28], and graph-based retrieval [9, 17]. Additionally, studies have explored adaptive retrieval [15] and multiple retrieval [14]. More advanced techniques such as query rewriting [10, 21] and alignment between retriever and LLM [5, 40] are beyond the scope of this paper.\nMembership Inference Attacks (MIAs) [13, 32] are privacy threats that aim to determine if a specific data record was used to train a machine learning model. MIAs for language models [4, 23, 31, 39] have been the subject of extensive research. Some representative attacking methods are: 1) Loss Attack: A classic MIA approach that classifies membership based on the model's loss for a target sample [39]; 2) Zlib Entropy Attack: It refines the Loss Attack by calibrating the loss using zlib compression size [4]; 3) Neighborhood Attack: This method targets MIAs in mask-based models by comparing model losses of similar samples generated by replacing words with synonyms [23]; 4) The Min-k% Prob Attack: this approach calculates membership by focusing on the k% of tokens with the lowest likelihoods in a sample and computing the average probabilities. However, these works may not be directly applicable to RAG systems. Additionally, many of them rely on the loss or token output probabilities, which require access to LLM parameters or intermediate outputs that may not be available in black-box RAG systems."}, {"title": "3 PRELIMINARIES", "content": "In this section, we establish the notation, provide a brief overview of Retrieval-Augmented Generation (RAG), and outline the specific task addressed in this paper.\nRAG systems typically consist of three primary components: a knowledge database, a retriever, and a large language model (LLM). The knowledge database, denoted as $D = \\{P_1,..., P_N\\}$, comprises a collection of documents sourced from authoritative and up-to-date sources. The retriever is a model capable of encoding both queries and documents into a common vector space to facilitate retrieval. The LLM, such as ChatGPT or Gemini, is a trained language model capable of generating text.\nThe RAG process unfolds as follows: Given a user query q, the system retrieves k relevant documents from D using the retriever:\n$P_k = \\text{RETRIEVE}(q, D, k)$\nTypically, retrieval is based on similarity metrics like inner product or cosine similarity. The retrieved documents, concatenated as $P_k = [p_1\\dots p_k]$, are then combined with a system prompt s and the original query to generate a response using the LLM:\n$r = \\text{LLM}(s \\oplus P_k \\oplus q)$\nHere, [] represents the concatenation operation."}, {"title": "3.2 Task Formulation", "content": "We introduce the task of Membership Inference Attacks (MIAs) in RAG system.\nAttacker's Target: Given a target document d, the objective is to determine whether d is present in the RAG system's knowledge database D.\nAttacker's Constraints: We target at the black-box setting in RAG system. The attacker cannot access the RAG system's knowledge base (D) or the LLM's parameters. However, they can interact with the system freely and repeatedly. The RAG system's response is solely textual, providing answers to the user's questions without explicitly displaying the contents of the retrieved documents. This scenario is realistic, as users typically have unrestricted access to chatbots.\nAttacker's Task: The attacker's task is to design a Binary Membership Inference Classifier (BMIC) that takes the target document (d), and the response of the RAG system (r) as input. Formally, the probability of d being in D is calculated as:\n$P(d \\in D) = \\text{BMIC} (d, r)$,\n$r = \\text{LLM} (s \\oplus Q_d \\oplus P_k)$\nwhere r is generated by the LLM using a system prompt s, a well designed question generated from d (denoted as $Q_d$), and retrieved documents $P_k$. Designing a method to generate $Q_d$ that can effectively differentiate between responses generated with and without the target document in the context is a key challenge in MIAs for RAG systems.\nMIA Workflow: The MIA process involves generating questions based on the target document d. If the RAG system's response (answer) r accurately matches the original content of d, it can be inferred that d is present in the knowledge database D. Conversely, if there is a significant mismatch, it suggests that d is not in D. Designing Principals: There are three main principals on designing the classifier and the adaption function:\nEffective Retrieval: $Q_d$ should successfully retrieve d if d \u2208 D. Recall that in RAG, relevant documents are retrieved based on the user query and used as context for generation. In this context, $Q_d$ serves as the user query. If d cannot be successfully retrieved, it implies that d is not in D, leading to a negative judgment.\nIndirect Information: $Q_d$ shall not directly reveal the information to be verified in the BMIC. While using d directly as $Q_d$ might seem straightforward, it introduces bias: the RAG system will always include d in the context, regardless of its presence in the knowledge base, making the inference unreliable.\nTargeted Questions: Questions should be challenging for the RAG system to answer if d is not in the knowledge base, and vice versa. Overly simple questions can be answered using internal knowledge or other retrieved documents, hindering judgment. Conversely, irrelevant questions may not elicit expected responses, even if d is successfully retrieved."}, {"title": "4 METHODS", "content": "This section presents our proposed Mask-Based Membership Inference Attacks (MBA) framework, illustrated in Figure 2. We begin by explaining our motivation (Section 4.2). Subsequently, we introduce the two key components of our framework: Mask Generation (Section 4.3), which generates M masks within the original target document as our document-specific question ($Q_d$), and a Binary Membership Inference Classifier (BMIC, Section 4.4), which infers membership based on the masked texts. Our framework is non-parametric and can be applied to any black-box RAG system, regardless of LLM parameters or retrieval methods."}, {"title": "4.2 Motivation", "content": "We observe that when LLMs are tasked with cloze tests (predicting masked terms or phrases in a given text), they can accurately fill in the blanks if the complete original text is provided as a reference. This phenomenon inspired us to conduct MIAs in RAG systems using a cloze test approach.\nSpecifically, the masked target document is used as a query to retrieve relevant documents from the knowledge database. Due to the high similarity between the masked document and the original one, the target document is highly likely to be retrieved if it appears in the knowledge database. In this case, the masked words can be accurately predicted. Conversely, if the target document is not in the database, there is no direct information to guide mask prediction, leading to inaccurate predictions. Therefore, the accuracy of mask prediction can serve as an indicator of the target document's membership."}, {"title": "4.3 Mask Generation", "content": "The first step involves generating masked text from the original target document, which acts as the document-specific question ($Q_d$). We aim to select terms that are challenging to predict based solely on the LLM's internal knowledge or the context. While cloze question generation research [22, 38] exists, these works primarily focus on educational applications and may not be suitable for our purposes.\nWhile it's tempting to use LLMs to generate masks, their inherent uncertainty presents two main challenges. First, LLMs may not always follow instructions to generate the desired number of masks. Second, the generated mask answers may not accurately align with the original words in the target document, potentially altering the document's content or even resulting in completely blank masked texts in some cases.\nA straightforward approach would be to use a proxy language model to select terms based on their prediction difficulty (i.e., the probabilities to correctly predict them). However, we observed three challenges:\nFragmented words: Datasets often contain specialized terms or proper nouns that may not be recognized by language model tokenizers. For example, GPT-2 might split \"canestan\" (a medicine) into \"can,\" \"est,\" and \"an\". Masking such terms based solely on prediction probability, which might generate \"can[Mask]an\", could hinder accurate prediction, even with the entire text retrieved.\nMisspelled words: Datasets collected from human-generated content may contain misspelled words (e.g., the word \"nearly\" is written as \"nearlt\"). If such words are masked, LLMs tend to accurately predict the correct spelling (e.g., \"nearly\"), despite prompted to follow the original text, affecting prediction accuracy.\nAdjacent masks: Masking two adjacent words can be problematic for LLMs. For instance, masking \"walking\" and \"unsteadily\" in the sentence \"I went to the bathroom [Mask_1] (walking) [Mask_2] (unsteadily), as I tried to focus...\" might lead the LLM to incorrectly predict \"[Mask_1]: walking unsteadily; [Mask_2]: as I tried to focus\". Specifically, the LLM might incorrectly identify the locations of the masked terms, despite its ability to effectively extract nearby terms or phrases.\nTo address these challenges, we incorporate an fragmented tokens extraction algorithm (Section 4.3.1), misspelled words correction (Section 4.3.2) and rule-based filtering methods into our mask proxy language model based generation process (Section 4.3.3)."}, {"title": "4.3.4 Mask integration", "content": "Finally, the masked words are integrated and numbered. The \"[Mask]\" labels in the masked text are numbered from \"[Mask_1]\" to \"[Mask_M]\". A ground truth mask answer dictionary is maintained in the format \"[Mask_i]: answer_i,\" where \"answer_i\" is the i-th masked word."}, {"title": "4.4 Binary Membership Inference Classifier", "content": "The RAG system is prompted with the template shown in Figure 6 in Appendix B.1, where the masked document is obtained using the method introduced in Section 4.3, and the {retrieved documents} represent those retrieved from the RAG's knowledge database.\nThe response will be in the format \"[Mask_i]: answer_i,\" where \"answer_i\" represents the predicted answer for \"[Mask_i]\". We then compare the predicted answers with the ground truth answers and count the number of correct predictions. If this count exceeds $y \\cdot M$, where y \u2208 (0, 1] is a hyperparameter, we judge the target document as a member of the RAG's knowledge database; otherwise, we conclude it is not a member."}, {"title": "5 EXPERIMENTS", "content": "We evaluate our method on three publicly available question-answering (QA) datasets:\nHealthcareMagic-100k\u00b3: This dataset contains 112,165 real conversations between patients and doctors on HealthCareMagic.com.\nMS-MARCO [2]: This dataset features 100,000 real Bing questions with retrieved passages and human-generated answers. We use the \"validation\" set (10,047 QA pairs) for knowledge base construction. The knowledge base includes all unique documents retrieved by at least one question.\nNQ-simplified\u2074: This is a modified version of the Natural Questions (NQ) dataset. Each question is paired with a shortened Wikipedia article containing the answer. We use the \"test\" set (16,039 QA pairs) to build a knowledge base by storing the shortened Wikipedia articles.\nFollowing previous research [1, 20], we randomly selected 80% of the documents as member samples (stored in the RAG's knowledge base) and the remaining 20% as non-member samples. We randomly selected 1,000 instances for training (500 member and 500 non-member) and another 1,000 for testing (500 member and 500 non-member) to determine any necessary thresholds."}, {"title": "5.2 Baselines", "content": "We evaluated our method against the following baseline approaches:\nMin-k% Prob Attack [31]: A state-of-the-art membership inference attack (MIA) for LLMs. It calculates a score based on the sum of the least likely tokens to determine membership.\nRAG-MIA [1]: This method directly queries the RAG system about the target document's inclusion in the retrieved context.\nS\u00b2MIA [20]: This approach divides the target document into two halves, prompts the RAG system with the first half, and compares the semantic similarity between the second half and the RAG's response. We compare 2 settings of S2MIA: S2MIAs: Relies solely on semantic similarity for MIA.\nS2MIAs&p: Incorporates both semantic similarity and perplexity for membership inference.\nOf these methods, Min-k% Prob Attack and S\u00b2MIAs&p require token prediction probabilities, which may not be accessible in certain black-box settings."}, {"title": "5.3 Evaluation Metric", "content": "We evaluate performance using a comprehensive set of metrics. Notably, we introduce Retrieval Recall as a unique metric for MIAs in RAG systems, distinguishing our work from previous studies [1, 20]. Retrieval recall measures whether the target document is successfully retrieved from the knowledge base when it exists. If the target document is among the top K retrieved documents, the recall is 1; otherwise, it is 0. We calculate the overall retrieval recall as the average across all membership documents, excluding non-member documents. In addition to retrieval recall, we also employ standard metrics commonly used in MIAs [8] and binary classification tasks, including ROC AUC, Accuracy, Precision, Recall, and F1-score. Specifically, member documents are labeled as 1, and non-member documents are labeled as 0. Each method outputs a logit value between 0 and 1 (e.g., the mask prediction accuracy), which is then used to calculate the metrics."}, {"title": "5.4 Settings and implementation", "content": "We leverage GPT-40-mini5 as our black-box LLM, which is accessed by OpenAI's API. For the RAG system, we utilize LangChain framework and integrate BAAI/bge-small-en [37] as the retrieval model, which encodes both queries and documents into 384-dimensional vectors. Retrieval is performed by calculating the inner product between these vectors, and an approximate nearest neighbor search is conducted using an HNSW index implemented in FAISS [7]. We set the number of retrieved documents (K) to 10 for all methods, a common setting in RAG systems. All experiments were conducted on a single NVIDIA RTX A5000 GPU."}, {"title": "5.4.2 Method-specific settings", "content": "We now detail the specific settings used in each method:\nMin-k% Prob Attack: k is a hyperparameter in this method. We varied k from 1 to 20, and selects the k with the best performance. This method also involves calculating the sum of minimum k% log probabilities as the indicator for membership inference. To obtain the log probabilities, we leverage the \"logprobs\" parameter within the OpenAI API\u2077.\nS\u00b2MIA: Cosine similarity is used to measure the similarity between the second half of the original target document and the response generated by RAG. To calculate perplexity, the \"logprobs\" parameter is enabled to obtain the log probabilities of tokens, similar to the Min-k% Prob Attack method. XGBoost, as recommended in the original paper, is used as the binary classifier.\nSpelling Correction Model: We leverage the pre-trained \"oliverguhr/spelling-correction-english-base\" model (139M parameters) from Hugging Face\u2078 to address potential spelling errors.\nProxy Language Model: We employ the \"openai-community/gpt2-xl\" [27] model with 1.61B parameters as a proxy language model for difficulty prediction.\nM: The number of masks is a hyperparameter in our method. We experimented with different values of M in {5, 10, 15, 20} for each dataset and selected the optimal M that produced the highest ROC AUC value.\ny: The threshold for mask prediction accuracy, used to determine membership, is a hyperparameter in our method. We varied this threshold from 0.1 to 1 for each dataset and selected the optimal threshold (y) that produced the highest F1-score.\nThe results obtained using the optimal M are presented as our overall results."}, {"title": "5.5 Overall Performance", "content": "Table 1 presents the experimental results comparing our proposed MBA4RAG framework with baseline methods.\nA key premise of MIAs in RAG is the successful retrieval of the target document if it exists in the knowledge database. Retrieval recall is therefore a crucial metric. Both RAG-MIA and MBA4RAG achieve high overall retrieval recall (over 0.9) due to their use of the full original target document or masked versions with high similarity. In contrast, S2MIA and Min-k% Prob Attack retrieve documents based on fragments, leading to potential discrepancies, especially in chunked knowledge databases. These methods exhibit lower retrieval recall, particularly in the HealthCareMagic dataset, likely due to the similarity of many patient-doctor dialogues.\nFor the specific performance, ROC AUC is a dominant metric for evaluating MIAs [1, 8, 20, 23]. Our method consistently outperforms baseline methods by over 20% across all datasets. Even though baseline methods may achieve notable performance on metrics like precision and recall, these results can be attributed to arbitrary strategies, such as judging all documents as members.\nIn conclusion, our mask-based MIA method effectively retrieves the target document when it exists in the knowledge database and focuses on the target document without being distracted by other retrieved documents. This leads to high performance and reliability."}, {"title": "5.6 Ablation Study", "content": "To assess the effectiveness of our mask generation method and its individual components, we compared it to several baseline approaches:\nRandom: A simple baseline where masks are selected randomly.\nLLM-based: An alternative approach using an LLM to select words or phrases for masking. The prompt template is provided in Figure 7 in Appendix B.2.\nMBAPLM: This variant only uses the proxy language model for word selection, omitting fragmented word extraction (Section 4.3.1) and misspelled word correction (Section 4.3.2).\nMBAw/o SC: This variant excludes the misspelled word correction (Section 4.3.2) component from our full method.\nThe results are presented in Table 2. Due to the similarity between the masked text and the original text (with only a few words or phrases replaced), retrieval recall is generally high for all masking strategies. Even random masking achieves competitive performance (ROC AUC of around 0.7) due to the mask-based method's ability to resist distractions from other retrieved documents. However, random masking may generate masks for simple words (e.g., stop words), which can be easily predicted by the LLM, leading to false positives.\nThe LLM-based mask generation method is straightforward to implement and achieves acceptable performance in most cases (ROC AUC of about 0.8). However, due to the inherent uncertainty of LLMs, the original texts may be altered, and the number of generated masks may deviate from the desired amount.\nOur proxy language-based mask generation method guarantees stable generation, ensuring exactly M masks are generated and distributed evenly throughout the text. However, challenges such as fragmented words, adjacent masks, and misspelled words can hinder prediction accuracy. By incorporating fragmented word processing and misspelled word correction, our method achieves effective and reliable MIAs for RAG systems."}, {"title": "5.7 Parameter Study", "content": "To analyze the impact of M, the number of masks generated in the target document, we varied M in {5, 10, 15, 20} and observed the retrieval recall and ROC AUC values (Figure 3).\nAs M increases, retrieval recall slightly decreases. This is because more masked words reduce the similarity between the masked text and the original document. The ROC AUC value also fluctuates slightly. When M is too small (e.g., below 5), the error tolerance decreases, meaning mispredictions have a larger impact on the final membership inference performance. When M is too large (e.g., over 20), simple words may be masked, leading to accurate prediction without the target document being retrieved. Additionally, decreased retrieval recall can lower the prediction accuracy of member samples, impacting overall performance.\nTherefore, setting M between 5 and 15 (exclusive) is an optimal choice.\nTo analyze the impact of the membership threshold y, we varied y from 0.1 to 1.0. Since retrieval recall and ROC AUC scores are independent of y (as y does not affect mask generation), we focused on f1-scores.\nFigure 4 illustrates the results. While the optimal y value varies across datasets (5, 6, and 7), performance is relatively consistent within the range of 0.5 to 0.7. This indicates that the performance is not highly sensitive to y, and setting y around 0.5 is generally a good choice.\nK is a system parameter representing the number of retrieved documents in the RAG system, which may influence performance. However, this parameter is beyond our framework and inaccessible to users. We verified that our method is insensitive to K in Figure 5 of Appendix C."}, {"title": "6 CONCLUSION", "content": "In this paper, we address the problem of membership inference for RAG systems, and propose a Mask-Based Membership Inference Attacks (MBA) framework. Our approach involves a proxy language-based mask generation method and a simple yet effective threshold-based strategy for membership inference. Specifically, we mask words that have the largest rank scores as predicted by a proxy language model. The target RAG system would have most of the masks correctly predicted if the document is a member. Extensive experiments demonstrate the superiority of our method over existing baseline models."}]}