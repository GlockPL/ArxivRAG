{"title": "Are Large Language Models In-Context Graph Learners?", "authors": ["Jintang Li", "Ruofan Wu", "Yuchang Zhu", "Huizhe Zhang", "Liang Chen", "Zibin Zheng"], "abstract": "Large language models (LLMs) have demonstrated remarkable in-context reasoning capabilities across a wide range of tasks, particularly with unstructured inputs such as language or images. However, LLMs struggle to handle structured data, such as graphs, due to their lack of understanding of non-Euclidean structures. As a result, without additional fine-tuning, their performance significantly lags behind that of graph neural networks (GNNs) in graph learning tasks. In this paper, we show that learning on graph data can be conceptualized as a retrieval-augmented generation (RAG) process, where specific instances (e.g., nodes or edges) act as queries, and the graph itself serves as the retrieved context. Building on this insight, we propose a series of RAG frameworks to enhance the in-context learning capabilities of LLMs for graph learning tasks. Comprehensive evaluations demonstrate that our proposed RAG frameworks significantly improve LLM performance on graph-based tasks, particularly in scenarios where a pretrained LLM must be used without modification or accessed via an API.", "sections": [{"title": "1. Introduction", "content": "Large language models (LLMs) exhibit astonishing reasoning capabilities across a wide variety of real-world tasks, including text generation (Yang et al., 2024), code completion (Guo et al., 2024), and question answering (Lewis et al., 2020). The widespread success of LLMs is often attributed to their in-context learning capabilities (Luo et al., 2024). Building on top of just raw reasoning abilities, LLMs can solve a new task for which they have not been explicitly trained, by being provided with a few examples (few-shot) (Brown et al., 2020) or even with instructions describing the task (zero-shot) (Kojima et al., 2022).\nLeveraging their success in handling unstructured data, LLMs have increasingly been applied to tasks involving structured data, such as graphs (Chen et al., 2023; Ye et al., 2024). Essentially, language models are trained on semantic text as next-token predictors, which are inherently capable of learning from any textual input, including graph-like structures represented as text. For example, graphs can be encoded into textual representations, such as edge lists, adjacency matrices, or even graph descriptions in natural language (Ye et al., 2024; Guo et al., 2023). When presented with such textual representations, LLMs are expected to understand the relationships and properties of the graph, extending their reasoning abilities to the graph domain.\nHowever, breaking down the graph representation into verbal semantic prompts (i.e., graph tokenization) leads to the loss of critical structural information (Guo et al., 2023). We argue that the intrinsic relationships and dependencies between nodes and edges require a deeper understanding of spatial and relational structures, which cannot be fully captured through textual encoding alone. As a result, despite their impressive performance on unstructured tasks, LLMs without additional fine-tuning struggle to match the effectiveness of specialized models like graph neural networks (GNNs) (Kipf & Welling, 2017; Velickovic et al., 2018), which are explicitly designed to process graph data and leverage its structural properties.\nAs LLMs continue to evolve, new techniques such as retrieval-augmented generation (RAG)(Lewis et al., 2020) and chain-of-thought (CoT) reasoning(Wei et al., 2022b) have been introduced to mitigate their limitations in reasoning. These techniques demonstrate that LLMs can be strong"}, {"title": "2. Preliminary", "content": "In this section, we introduce the notation and formalize key concepts related to (large) language models and graph neural networks for learning over text-attributed graphs.\nNotations. We define a text-attributed graph $G = (V,E,T)$ with N nodes, where V is the set of nodes and $E \u2286 (V \u00d7 V)$ is set of edges connecting them. For each node $v_i \u2208 V$ is associated with a textual attribute $x_i$, and $X = {x_i|V_i \u2208 V}$ is the attribute set. We consider a fundamental task, namely node classification, which predicts the class label of a node $v_i$. This task can be conceptualized and approached as a text classification problem but with additional graph context. For simplicity, let $Y = {y_i}_{i=1}^{N}$ denote the set of ground-truth labels, where $y_i \u2208 C$ for node classification, with C representing the set of class labels.\nIn-context learning. In-context learning is a paradigm that enables language models to learn tasks using only a few examples as demonstrations. Formally, given a pretrained LLM, the model is expected to generate an output r for a"}, {"title": "3. Present work", "content": "In this section, we begin with an empirical study to investigate the in-context learning capabilities of LLMs in graph learning tasks. Next, we establish the connection between RAG and GNNs. Finally, we introduce three novel RAG frameworks designed to improve LLMs' understanding of graph data, as illustrated in Figure 2."}, {"title": "3.1. Empirical study", "content": "We introduce a concrete node classification task on graphs and investigate prompting techniques in in-context learning settings. Our goal is to explore the potential of LLMs to reason on graph data without any additional fine-tuning, focusing solely on their pure in-context capabilities.\nExperimental settings. We experiment with two representative text-attributed graph datasets: Cora and Pubmed (Sen et al., 2008). For the node classification task, we use LLAMA-3.1-8B-INSTRUCT(Dubey et al., 2024) and DEEPSEEK-V3(Liu et al., 2024a) as base models, representing state-of-the-art open-source and closed-source large language models (LLMs) for natural language tasks, respectively. Our approach to in-context learning follows (Chen et al., 2023; Brown et al., 2020); however, in this work, we systematically explore additional settings to enhance learning within the context."}, {"title": "3.2. Connecting GNNs with RAG", "content": "In our empirical experiments, RAG generally achieves the best performance among in-context baselines, although it still significantly underperforms supervised GNNs. This motivates us to explore potential improvements in RAG for graph learning tasks.\nIn the literature, it has been shown that improving the quality of retrieved context significantly enhances the performance of LLMs (Ram et al., 2023). However, in RAG, the textual attributes of nodes (i.e., the queries) are treated as an external corpus to retrieve relevant textual context for each node, which differs from traditional RAG methods (Lewis et al., 2020). In this regard, the objective of retrieving 'neighborhood' information from the graph has led us to explore the connections between RAG and GNNs.\nBoth RAG and GNNs are context-based methods that leverage contextual information in a similar way. Specifically, RAG retrieves relevant information from an external corpus based on the query to serve as context, while GNNs aggregate information from the local neighborhood of the query"}, {"title": "3.3. Graph-guided RAG frameworks", "content": "Building on the inherent connections between GNNs and RAG, we propose three graph-guided RAG frameworks: QUERYRAG, LABELRAG, and FEWSHOTRAG. Specifically, QUERYRAG utilizes the query context of neighboring nodes from the graph, while LABELRAG incorporates the label information. Combining these two approaches, FEWSHOTRAG leverages both query and label information from graph-guided contexts.\nFrom GNN to QUERYRAG. Although we have demonstrated that GNNs can be conceptualized as RAG networks, there are key differences between them. Unlike RAG, where context is dynamically retrieved from an external corpus, the context in GNNs is inherently relational, relying on the graph's topology and interactions between nodes. This makes GNNs particularly well-suited for graph learning tasks, where relationships and dependencies play a critical role. Furthermore, the retrieved context in GNNs is more akin to retrieving a similar query based on node features or representations, rather than relying on an external corpus, as is typical in vanilla RAG. In this regard, we propose the concept of QUERYRAG, which utilizes the queries from other queries as the external corpus for retrieval:\n$r_i = GEN (\\{q_i, AUG (\\{q_j: V_j \u2208 N(v_i)\\})\\}).$\nIn QUERYRAG, we take inspiration from GNNs and utilize the text attributes of neighboring nodes N as inherently retrieved context. Each neighboring node contributes to the contextual understanding of the query node. By treating the local graph neighborhood as a source of context, QUERYRAG combines the strengths of GNN-style aggregation with the flexibility of generative models. This design enables QUERYRAG to effectively handle tasks that require relational reasoning. Additionally, this inherently relational"}, {"title": "4. Experiments", "content": "In this section, we present a rigorous evaluation of general-purpose LLMs augmented with our proposed RAG frameworks. The experiments are divided into two main parts: a comparative analysis of QUERYRAG, LABELRAG, and FEWSHOTRAG against state-of-the-art GNNs and graph LLMs on the node classification task, and an investigation of how different configurations impact the performance of general-purpose LLMs. Due to space limitations, we defer the detailed experimental settings to Appendix B and the ablation studies to Appendix C."}, {"title": "4.1. Experimental configurations", "content": "Datasets. We conducted experiments on eight text-attributed graph datasets: Cora, Pubmed (Sen et al., 2008), and the CS-TAG (Yan et al., 2023) benchmarks, which include Sports-Fitness, Ele-History, Ele-Computers, Books-Children, Books-History, and Ogbn-Arxiv-TA. These datasets span diverse domains, such as citation networks and e-commerce, and vary in sparsity and size, ranging from small to large scales.  Since the primary focus of our work is node classification based on textual attributes, we also report the average number of input tokens for the textual attributes of nodes in these graphs. For the Cora and Pubmed datasets, we follow the public splits from (Kipf & Welling, 2017), using 20 samples per class for training and 1,000 labeled examples for evaluation. For the CS-TAG datasets, we adopt a low-label-rate split, allocating 10% of the data for training, 10% for validation, and 80% for testing.\nLarge language models. Our goal is to explore the in-context learning capabilities of LLMs. To this end, we evaluate a range of advanced language models, including LLAMA-3.1-8B-INSTRUCT (Dubey et al., 2024), QWEN2.5-7B-INSTRUCT (Yang et al., 2024), GEMMA-2-9B (Team, 2024), PHI-3.5-MINI-INSTRUCT (Abdin et al., 2024), and MISTRAL-7B-INSTRUCT-V0.3 (Jiang et al., 2023). Additionally, we conduct experiments with DEEPSEEK-V3 (Liu et al., 2024a), a closed-source LLM, to assess its performance on the node classification task under in-context learning settings. Due to budget constraints, we did not conduct comprehensive experiments with other advanced models, such as GPT-4o.\nBaselines. In our experimental evaluation, we include a diverse range of state-of-the-art methods to ensure a comprehensive assessment: (i) supervised baseline without graph structure: MLP; (ii) supervised message-passing GNNs, including GCN (Kipf & Welling, 2017), GAT (Velickovic et al., 2018), GraphSAGE (Hamilton et al., 2017), and RevGAT (Li et al., 2021); (iii) specialized graph LLMs, including GLEM (Zhao et al., 2023b), TAPE (He et al., 2024a), PRODIGY (Huang et al., 2023), and LLaGA (Chen et al., 2024a); and (iv) in-context baselines, including zero-shot, few-shot (Brown et al., 2020), and RAG (Lewis et al., 2020)."}, {"title": "4.2. Results", "content": "In-context performance. We investigate how our proposed RAG frameworks enhance the in-context learning capabilities of LLMs. Results show that LLMs generally benefit from the additional contextual information provided by our RAG frameworks. In particular, LLMs with LABELRAG and FEWSHOTRAG achieve significant performance improvements, outperforming supervised MLPs and, in some cases, matching or even surpassing supervised LLMs. Overall, these findings indicate that our proposed RAG frameworks, especially FEWSHOTRAG, serve as strong alternatives for graph-related tasks, enabling effective in-context learning without requiring any modifications to the LLMs.\nLimitations. Despite the promising results, our work has certain limitations. First, our approach assumes homophily in the graph structure, which may not generalize well to heterophilic graphs, where nodes with dissimilar attributes or labels are more likely to be connected. Second, our experiments primarily focus on static graphs, leaving the performance on dynamic or temporal graphs unexplored.\nFuture work. For future work, we aim to investigate the in-context learning performance of LLMs in more challenging settings, where graphs may be dynamic, noisy, incomplete, or entirely unavailable."}, {"title": "5. Related Work", "content": "In-context learning. In-context learning (ICL) is a task adaptation strategy where a large language model (LLM) is provided with examples or demonstrations within the input prompt to guide its responses for various tasks (Brown et al., 2020). ICL enables LLMs to adapt to unseen tasks by observing a few demonstrations in their input, without requiring additional training data or fine-tuning (Luo et al., 2024). Since in-context demonstrations are crucial for ICL performance, various strategies have been proposed to improve demonstration selection, including retrieving semantically similar examples (Liu et al., 2022), employing chain-of-thought reasoning (Kojima et al., 2022), and decomposing tasks into subproblems using least-to-most prompting (Zhou et al., 2023).\nRetrieval-augmented generation. Retrieval-augmented generation (RAG) is a context-based strategy that enhances LLMs by dynamically retrieving relevant information from a knowledge base or document corpus (Lewis et al., 2020). Unlike ICL, which relies solely on in-prompt demonstrations, RAG provides external context to guide LLM responses, making it particularly effective for tasks that require up-to-date or domain-specific information where static prompts may be insufficient (Fan et al., 2024).\nGraph neural networks. GNNs are powerful tools designed to operate on graph-structured data (Gilmer et al., 2017). They have revolutionized the landscape by introducing the message-passing mechanism, where nodes iteratively aggregate information from their neighbors (Chen et al., 2020). This paradigm has led to the development of several influential GNN architectures. Popular GNN variants include graph convolutional networks (GCN)(Kipf & Welling, 2017), graph attention networks (GAT)(Velickovic et al., 2018), and scalable architectures such as GraphSAGE (Hamilton et al., 2017) and RevGAT (Li et al., 2021), each advancing the message-passing paradigm in distinct ways."}, {"title": "6. Conclusion", "content": "In this work, we establish a close connection between message-passing GNNs and RAG, which provides a holistic understanding of how GNNs process and leverage contextual information in graph data. By introducing QUERYRAG, LABELRAG, and FEWSHOTRAG, we extend the RAG paradigm to incorporate graph structure as inherent context, enabling effective in-context learning for LLMs without requiring fine-tuning or additional training. Extensive experimental evaluations demonstrate that our proposed RAG frameworks enable LLMs to achieve outstanding performance across multiple datasets, in some cases even surpassing state-of-the-art supervised GNNs and specialized graph LLMs. By conceptualizing message passing as a recursive retrieval process, we bridge the gap between structured and unstructured learning, opening new avenues for applying LLMs to graph-based learning tasks."}, {"title": "Impact Statement", "content": "This paper advances the field of machine learning by exploring the intersection of in-context learning and graph-based reasoning. Our proposed RAG frameworks enable LLMs to leverage structured graph data without requiring additional fine-tuning, expanding their applicability to knowledge-intensive domains."}]}