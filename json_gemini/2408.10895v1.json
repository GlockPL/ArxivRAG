{"title": "Analytical and Empirical Study of Herding Effects in Recommendation Systems", "authors": ["Hong Xie", "Mingze Zhong", "Defu Lian", "Zhen Wang", "Enhong Chen"], "abstract": "Online rating systems are often used in numerous web or mobile applications, e.g., Amazon and TripAdvisor, to assess the ground-truth quality of products. Due to herding effects, the aggregation of historical ratings (or historical collective opinion) can significantly influence subsequent ratings, leading to misleading and erroneous assessments. We study how to manage product ratings via rating aggregation rules and shortlisted representative reviews, for the purpose of correcting the assessment error. We first develop a mathematical model to characterize important factors of herding effects in product ratings. We then identify sufficient conditions (via the stochastic approximation theory), under which the historical collective opinion converges to the ground-truth collective opinion of the whole user population. These conditions identify a class of rating aggregation rules and review selection mechanisms that can reveal the ground-truth product quality. We also quantify the speed of convergence (via the martingale theory), which reflects the efficiency of rating aggregation rules and review selection mechanisms. We prove that the herding effects slow down the speed of convergence while an accurate review selection mechanism can speed it up. We also study the speed of convergence numerically and reveal trade-offs in selecting rating aggregation rules and review selection mechanisms. To show the utility of our framework, we design a maximum likelihood algorithm to infer model parameters from ratings, and conduct experiments on rating datasets from Amazon and TripAdvisor. We show that proper recency aware rating aggregation rules can improve the speed of convergence in Amazon and TripAdvisor by 41% and 62% respectively.", "sections": [{"title": "1 INTRODUCTION", "content": "Nowadays, online product rating systems are often used in numerous web or mobile applications, e.g., Amazon, eBay, TripAdvisor, Google App Store, etc. Online product rating systems aim to reveal the ground-truth quality of products via user contributed ratings or reviews. Product ratings not only improve users' purchasing experience [1-3], but can also improve revenues of sellers [4\u20136]. Formally, each user provides ratings to a subset of products, and their ratings are known to all users. For each product, the historical collective opinion (i.e., aggregation of historical ratings) and shortlisted representative product reviews are usually displayed to assist users assess the product quality. For example, Figure 1 shows such displays in Amazon.\nHowever, user ratings are \u201cbiased\u201d toward the displayed historical collective opinion and short-listed product reviews due to herding effects [7, 8]. Informally, the herding effects means that users simply \"follow\u201d the historical ratings or reviews of the crowd in providing ratings. This rating bias makes it difficult to reveal the ground-truth product quality. To illustrate, let us consider a com-monly used rating metric {1 = \u201cTerrible\u201d, 2 = \u201cPoor\u201d, 3 = \u201cAverage\u201d, 4 = \u201cGood\u201d, 5 = \u201cExcellent\u201d}. Assume the ground-truth collective opinion of the whole user population is (0.01, 0.02, 0.07, 0.4, 0.5), i.e., the fraction of users hold an overall opinion of 1, 2, 3, 4 and 5 are 1%, 2%, 7%, 40% and 50% respectively. Suppose we use the average scoring rule to summarize the collective opinion, i.e., the ground-truth quality is 0.01 \u00d7 1 + 0.02 \u00d7 2 + 0.07 \u00d7 3 + 0.4 \u00d7 4 + 0.5 \u00d7 5=4.36. For simplicity, we use the following two simplified examples to illustrate the herding effect.\nExample 1 (Unbiased ratings). Consider the ideal case that users provide unbiased ratings, i.e., each rating is of 1, 2, 3, 4 and 5, with probability 0.01, 0.02, 0.07, 0.4 and 0.5 respectively. If the number of historical ratings is sufficiently large [9], then its average is around 4.36, which is exactly the ground-truth quality of the product.\nExample 2 (Ratings under herding effects). For simplicity, consider one possible herding ef-fect, i.e., each user provides a rating according to the historical collective opinion, i.e., the empirical distribution of past ratings. Suppose the first rating is 1, then the second rating will be 1 because the historical collection opinion is (1, 0, 0, 0, 0). Similarly, the third and all subsequent ratings will be 1. The average of historical ratings will be 1, no matter how large the number of ratings is, and it is very different from the ground-truth quality of 4.36.\nExample 1 and 2 highlight that as the strength of herding effects increases, revealing the ground-truth product quality via historical ratings (i.e., mean of the historical ratings) varies from accurate to erroneous. In general, the strength of herding effects may lie between that of Example 1 and 2, and the initial ratings is not given in advance. Some users may even provide high or low ratings intentionally to promote or badmouth a product. Furthermore, the shortlisted product reviews can also influence subsequent ratings. This paper explores three fundamental questions under such general settings: (1) Under what conditions the historical collective opinion converges to the ground-truth collective opinion? (2) What's the convergence speed of the historical collective opinion? (3) What are some effective rating aggregation rules and review selection mechanisms to reveal the ground-truth product quality? The convergence guarantee implies that the ground-truth product quality can be revealed, and the rating bias caused by the herding effects can be eliminated. Namely, it reflects the accuracy of an online rating system. The speed of convergence reflects the efficiency of an online rating system, i.e., a faster speed implies that the ground-truth product quality can be revealed using a smaller number of ratings. The complicated psychological nature of herding effects makes it challenging to explore these three questions. Our contributions are:\n\u2022 We develop a mathematical model to capture important factors of herding effects in online product ratings. Our model also characterizes the decision space of an online rating system operator in selecting rating aggregation rules and review selection mechanisms.\n\u2022 We apply the stochastic approximation theory to derive sufficient conditions, under which the historical collective opinion converges to the ground-truth collective opinion (both the honest and misbehaving rating scenarios). These conditions identify a class of rating aggregation rules and review selection mechanisms, which can reveal the ground-truth product quality.\n\u2022 We quantify the speed of convergence via the \u201cmartingale theory\u201d, which reflects the ef-ficiency of rating aggregation rules and review selection mechanisms. We prove that the herding effects slow down the speed of convergence while an accurate and robust review selection mechanism speeds it up. We also study the speed of convergence numerically and find a number of interesting findings. For example, the improvement of convergence speed via an accurate selection mechanism becomes small when we increase the recency aware-ness of a rating aggregation rule.\n\u2022 To show the utility of our framework, we design a maximum likelihood algorithm to infer model parameters from online product ratings and conduct experiments on rating datasets from Amazon and TripAdvisor. We find that TripAdvisor has a higher strength of herding effects than Amazon and appropriate recency aware rating aggregation rules can improve the convergence speed in Amazon and TripAdvisor by 41% and 62% respectively.\nThis paper organizes as follows. Section 2 presents the herding model and the decision model. Section 3 presents the convergence analysis. Section 4 presents a maximum likelihood algorithm to infer model parameters from data. Section 5 and 7 presents the experimental results on synthetic and real-world data (from Amazon and TripAdvisor) respectively. Section 9 discusses the related work and Section 10 concludes."}, {"title": "2 MODEL", "content": "We start with the baseline model of unbiased product ratings. We then model herding effects and present the decision model in managing product ratings. Finally, we model misbehavior in ratings."}, {"title": "2.1 Unbiased Product Rating", "content": "We consider an online product rating system, which deploys an $M \\in \\mathbb{N_+}$ level cardinal rating metric to assess product quality\n$M = \\{1, ..., M\\}$."}, {"title": "2.2 Rating Under Herding Effects", "content": "Modeling herding effects. We denote all the historical ratings of $P$ up to the i-th rating as\n$H_i = \\{R_1, ..., R_i\\},\\quad \\forall i \\in \\mathbb{N_+}.\nFor presentation convenience, we define $H_0 = \\emptyset$. We denote historical collective opinion associ-ated with $H_i$ as $\\beta_i = [\\beta_{i,1},..., \\beta_{i,M}]$, where $\\beta_{i,m} \\in [0,1]$ and $\\sum_{m\\in M}\\beta_{i,m} = 1$. Note that the $\\beta_i$ is public to all users. Rating recency is important for a variety of applications [10, 11]. We consider a class of weighted aggregation rules to capture it, which is expressed as\n$\\Beta_{i,m} = \\frac{\\sum_{j=1}^{i} w_jI\\{R_j=m\\}}{\\sum_{j=1}^{i} w_j} \\quad \\forall m\\in M, i \\in \\mathbb{N_+},$  (1)\nwhere $w_j \\geq 0$ denotes the weights for the j-th rating, and $I$ is an indicator function. For example, $w_j = 1, \\forall j$, corresponds to the simple \u201cunweighted average rule\" and $\\beta_{i,m} = \\sum_{j=1}^{i} I\\{R_j=m\\}/i$ corre-sponds to the fraction of historical ratings equals m. Thus rule is deployed in many web services like Amazon, TripAdvisor, etc. Furthermore, $w_i = i$ denotes a \u201crecency aware aggregation rule\u201d, i.e., assigning higher weights to recent ratings.\nMany online rating systems also display shortlisted representative product reviews. Each review selection mechanism can be characterized by the accuracy (in identifying representative reviews) vs. cost (e.g., complexity) trade-off. We aim to understand the impact of the selection accuracy in managing product ratings. Let $\\theta_i = [\\theta_{i,1},..., \\theta_{i,M}]$ denote the initial collective opinion that users form from $\\beta_i$ and the shortlisted product reviews, where $\\theta_{i,m} \\geq 0$ and $\\sum_{m\\in M}\\theta_{i,m} = 1$. One interpretation of $\\theta_{i,m}$ is the probability that a user forms an opinion $m\\in M$. When the review selection mechanism is not deployed, we model the baseline initial collective as $\\theta_i = \\beta_i$.\nAssumption 1. Under an accurate review selection mechanism, it holds that $|\\theta_i -\\alpha|| \\le ||\\beta_i-\\alpha||$, where $|| \\cdot ||$ denotes a vector norm.\nAssumption 1 captures that the initial collective opinion is closer to the ground-truth collective opinion than the historical collective opinion, when representative reviews are presented.\nOne possible example of $\\theta_i$ is\n$\\theta_i = (1 - \\eta_i)\\beta_i + \\eta_i\\alpha,\\quad \\forall i \\in \\mathbb{N_+},$  (2)\nwhere $\\eta_i \\in [0, 1]$. Note that $\\eta_i = 0$ captures the case that the review selection mechanism is not deployed, and $\\eta_i$ models the accuracy of a review selection mechanism stated in the following lemma.\nLemma 1. $||\\theta_i - \\alpha||$ is decreasing in $\\eta_i$.\nDue to page limit, selected proofs are presented in the appendix and missing proofs can be found in our supplementary file [12]. Lemma 1 states that as we increase $\\eta_i$, users form an initial collective opinion $\\theta_i$ being closer to the ground-truth collective opinion $\\alpha$. Namely, increasing the $\\eta_i$ models that the review selection mechanism is more accurate in selecting representative reviews. One possible example of $\\eta_i$ is $\\eta_i = 0.6(1 - 1/i)$, where 0.6 captures the accuracy of a review selection mechanism and $(1 - 1/i)$ captures that the selected reviews is more accurate in reflecting the ground-truth collective opinion, when the number of reviews increases.\nAfter purchasing a product, a user's rating is modeled as a combination of the initial collective opinion and the intrinsic collective opinion. Formally, we have\n$P[R_i = m|H_{i-1}] = \\gamma_{i-1}\\theta_{i-1,m} + (1 - \\gamma_{i-1})\\alpha_m,$\nwhere $\\gamma_i \\in [0, 1]$ models the strength of herding effects. Increasing $\\gamma_i$ models a stronger strength of herding effects. We define $\\theta_0 = \\alpha$, to capture that when there is no historical ratings, a user provides her ground-truth rating. Note that we consider this simple model for the purpose of capturing key factors of herding effects while reducing the number of parameters to tune. The following assumption eliminates a trivial case that users purely follow the initial opinion.\nAssumption 2. The $\\gamma_i$ satisfies that $sup_{i\\in \\mathbb{N_+}} \\gamma_i < 1$.\nOne possible example of $\\gamma_i$ is $\\gamma_i = 0.8(1 - 1/i)$, which captures that the strength of herding effects increases as the number of ratings increases. Note that our work is general in the sense that our model is not restricted to any specific evolving pattern of the strength of herding effects $\\gamma_i$. In other words, it is allowed to increase, decrease, or even go up and down in the number of ratings $i$ (i.e., over time).\nManaging product ratings. The strength of herding effects $\\gamma_i$ is an intrinsic characteristic of the user population, which the online rating system operators can not control. To manage product ratings, their decision is to select the rating aggregation rule, i.e., $w_j$, and the review selection mechanism, i.e., $\\theta_i$. Our objective to make $\\beta_i$ converge to $\\alpha$ as fast as possible. This paper aims to provide fundamental understandings on how to select $w_j$ and $\\theta_i$. For the ease of presentation, we denote $w = [w_i : i \\in \\mathbb{N_+}], \\eta \\equiv [\\eta_i: i \\in \\mathbb{N_+}], \\gamma \\equiv [\\gamma_i : i \\in \\mathbb{N_+}],$ and $\\Theta \\equiv [\\theta_i : i \\in \\mathbb{N_+}]."}, {"title": "2.3 Rating Under Misbehavior", "content": "Now, we extend our model to capture misbehaving ratings, which is also known as spam/fake ratings [13]. It has been reported that some sellers use fake ratings to promote their own products, some even use fake ratings to badmouth their competitors' products [13]. We consider a $(k, m, I)$-misbehavior model, which is defined as follows.\nDefinition 1. $(k, m, I)$-misbehavior is to inject $k \\in \\mathbb{N_+}$ ratings equal to $m \\in M$ toward product $P$, where $I \\equiv \\{i_1,...,i_k\\}$ denotes the index set of the injected ratings and $i_1 < i_2 < ... < i_k$.\nFor example, a $(2, 5, \\{4, 5\\})$-misbehavior means injecting two ratings of 5 and the indices of these two injected ratings are 4, 5. Note that this simple misbehavior model can model many misbehavior and our objective is to understand the impact of misbehaving ratings on the convergence of $\\beta_i$."}, {"title": "3 THEORETICAL ANALYSIS AND IMPLICATIONS", "content": "We first study the convergence of the historical collective opinion via the stochastic approxima-tion theory. Through this we establish conditions under which the historical collective opinion converges to ground-truth collective opinion. Then we study the speed of convergence via the martingale theory. Through this we identify a metric to guide product rating managing. Lastly, we derive the minimum number of ratings to guarantee an accurate estimation on the ground-truth product quality."}, {"title": "3.1 Convergence of Historical Collective Opinion", "content": "A commonly used product quality estimation method is $A(\\beta_i)$. Studying the convergence of the his-torical collective opinion $\\beta_i$ is important, because it lays the foundation for revealing the ground-truth product quality. In the following theorem, we apply stochastic approximation theory to in-vestigate the convergence of $\\beta_i$ under the honest rating scenario, i.e., there are no misbehaving ratings.\nTheorem 1. Suppose Assumption 1 and 2 hold, and there are no misbehaving ratings. If $w_i$ satisfies\n$\\sum_{i=1}^{\\infty} w_i = \\infty,\\quad \\sum_{i=1}^{\\infty} w_i^2 < \\infty,$ (3)\nwhere $w_i = w_i/\\sum_{j=1}^{i} w_j$, then $\\beta_i$ converges to $\\alpha$ almost surely, i.e., $P [\\lim_{i\\rightarrow\\infty} \\beta_i = \\alpha] = 1$.\nTheorem 1 derives sufficient conditions under which the historical collective opinion $\\beta_i$ con-verges to the ground-truth collective opinion $\\alpha$. Note that $\\beta_i$ converges to $\\alpha$ implies that the ground-truth quality will be revealed, i.e., $A(\\beta_i)$ converges to $A(\\alpha)$. In other words, the rating bias caused by herding effects will eventually be eliminated. It is important to note that the con-vergence of $\\beta_i$ is achieved without adding any condition on $\\eta_i$. This means that the convergence can be achieved even without any review selection mechanism. Condition (3) identifies a class of weighted aggregation rules to guarantee the convergence of historical collective opinion. It char-acterizes a broad class of aggregation rules for the online rating system operator to choose as we proceed to illustrate.\nCondition (3) characterizes a large supply of rating aggregation rules. Let us use some examples to illustrate this point. Consider $w_i = 1,\\forall i \\in \\mathbb{N}$, which corresponds to the simple unweighted average rule. We have $w_i = w_i/\\sum_{j=1}^{i} w_j = 1/i$. One can easily check that Condition (3) holds, i.e.,\n$\\sum_{i=1}^{\\infty} w_i = \\sum_{i=1}^{\\infty} \\frac{1}{i} = \\lim_{i\\rightarrow\\infty} \\ln i = \\infty,\\quad \\sum_{i=1}^{\\infty} w_i^2 = \\sum_{i=1}^{\\infty} \\frac{1}{i^2} < 2$."}, {"title": "3.2 Convergence Speed of Historical Collective Opinions", "content": "The convergence speed of historical collective opinion reflects the efficiency of online rating sys-tems, because a faster speed implies that the ground-truth product quality can be revealed with a smaller number of ratings. Under general initial opinion vector $\\theta_i$, it is difficult to study the convergence speed of $\\beta_i$ analytically. We therefore we focus on one class of initial opinion vector $\\theta_i$ derived in Equation (2). The convergence speed for this case can already provide important insights on selecting rating aggregation rules and review selection mechanisms. In the following theorem, we apply martingale theory to study the honest rating scenario.\nTheorem 3. Suppose Assumption 1 and 2 hold, and there are no misbehaving ratings. Suppose $w_i$ satisfies Condition (3) and $\\theta_i$ satisfies Equation (2). Let $\\epsilon \\in [0, 1]$ denote an estimation error. For each $m\\in M$ and $i \\in \\mathbb{N_+}$, we have\n$P [|\\beta_{i,m} - \\alpha_m| > \\epsilon] \\le 2 exp (-i\\varphi_i(w, \\eta, \\gamma)\\epsilon^2),$ \nwhere $\\varphi_i(w, \\eta, \\gamma)$ is defined as\n$\\varphi_i(w, \\eta, \\gamma) \\equiv \\frac{1}{i} \\frac{\\{\\frac{\\sum_{j=1}^{i} w_j^2}{\\left(\\sum_{j=1}^{i} w_j\\right)^2}\\}^{-1}}{\\prod_{l=1}^{i} [1 - w_{l+1}(1 - \\gamma_l + \\eta_l\\gamma_l)]}, \\quad \\forall i \\in \\mathbb{N_+},$\n$\\varphi_j(w, \\eta, \\gamma) = \\prod_{l=1}^{j} [1 - w_{l+1}(1 - \\gamma_l + \\eta_l\\gamma_l)], \\quad \\forall j\\in \\mathbb{N_+},$\nand we define $\\varphi_0(w, \\eta, \\gamma) \\equiv 1$.\nTheorem 3 derive a metric, i.e., $\\varphi_i(w, \\eta, \\gamma)$, to quantify the convergence speed of the historical collective opinion. Given the number of ratings i, larger $\\varphi_i(w, \\eta, \\gamma)$ implies faster convergence speed. The $\\varphi_i(w, \\eta, \\gamma)$ serves as a building block to study product rating managing. It enables us to analyze the impact of w, $\\eta$, $\\gamma$ on the convergence speed, so as to draw important insights on managing product ratings. Algorithmically, it enables online rating system operators to design algorithms to select proper rating aggregation rule and review selection mechanisms to speed up convergence.\nTo illustrate, let us consider the simple unweighted average rule with $w_i = 1$ and $\\gamma_i = 0$ (i.e., there is no herding bias). In this special case, ratings are independently and identically generated according to $\\alpha$. We have $w_l = 1/l, \\varphi_j (w, \\eta, \\gamma) = \\prod_{l=1}^{j-1} (1-1/(l+1)) = 1/(j+1)$. Then it follows that $\\varphi_i(w, \\eta, \\gamma) = \\frac{1}{i(\\sum_{j=1}^{i} \\frac{1}{j^2})} \\approx \\frac{2}{i}$. Note that this corresponds to the Chernoff bound for IID ratings. This example shows that the Chernoff bound is a special case of Theorem 3. In the following theorem, we characterize the impact of $\\eta$ and $\\gamma$ on the speed of convergence.\nTheorem 4. $\\varphi_i(w, \\eta, \\gamma)$ is non-increasing in $\\gamma_j, \\forall j \\le i$, and non-decreasing in $\\eta_j, \\forall j \\le i$.\nTheorem 4 states that $\\varphi_i(w, \\eta, \\gamma)$ decreases as the strength of herding effects $\\gamma_j$ increases, and increases as the accuracy of the review selection mechanism $\\eta_j$ increases. This implies that as users' ratings are more prone to herding effects, the speed convergence slows down, and it speeds up if the online rating system operator can improve the accuracy of the review selection mechanism. The impact of aggregation rules (i.e., w) is not as clear as $\\eta$ and $\\gamma$, and we will study it through numerical analysis. In the following theorem, we study the impact of misbehaving ratings.\nTheorem 5. Suppose Assumption 1 and 2 hold. Suppose Condition (3) hold, and $\\theta_i$ satisfies Equa-tion (2). If the $(k, m, I)$-misbehavior satisfies $k < \\infty$, then we have\n$P[|\\beta_{i,m} - \\alpha_m| > \\epsilon] \\le 2 exp(-i\\tilde\\varphi_i(w, \\eta, \\gamma)\\epsilon^2),$\nwhere $\\tilde\\varphi_i(w, \\eta, \\gamma)$ is defined as\n$\\tilde\\varphi_i(w, \\eta, \\gamma) I \\{\\epsilon\\varphi_{i^{k}-1}(w, \\eta, \\gamma) \\le 1\\}$\n$\\frac{\\varphi_{i}(w, \\eta, \\gamma)}{\\epsilon\\varphi_{i^{k}-1}(w, \\eta, \\gamma)} I \\{\\epsilon\\varphi_{i^{k}-1}(w, \\eta, \\gamma) \\le 1\\}$\n1/\\{\\frac{\\sum_{j=i^{k}+1}^{i} \\tilde{w}_j^2}{\\left(\\sum_{j=i^{k}+1}^{i} \\tilde{w}_j\\right)^2}}\\}\n2,\nfor all $i > i_k$, $\\tilde\\varphi_i(w, \\eta, \\gamma) = 0$ for all $i \\le i_k$ and $\\varphi_{i^{k}-1}(w, \\eta, \\gamma) \\pm \\infty$. Furthermore, $\\tilde\\varphi_i(w, \\eta, \\gamma) \\le \\varphi_i(w, \\eta, \\gamma)$ for all $k \\ge 1$ and $\\tilde\\varphi_i(w, \\eta, \\gamma) = \\varphi_i(w, \\eta, \\gamma)$ for $k = 0$ and $i_0 = 0$.\nTheorem 5 derives a metric, i.e., $\\tilde\\varphi_i(w, \\eta, \\gamma)$, to quantify the convergence speed of historical collective opinion under misbehaving rating attacks. It states that misbehaving ratings slows down the convergence, as $\\tilde\\varphi_i(w, \\eta, \\gamma) \\le \\varphi_i(w, \\eta, \\gamma)$. Theorem 3 is a special case of Theorem 5 with $k = 0$ and $i_0 = 0$."}, {"title": "3.3 Product Quality Estimation", "content": "As an application of the above convergence rate metric, we now derive the minimum number of ratings needed to reveal the intrinsic product quality. In particular, we consider two commonly used opinion aggregation rules:\naverage scoring rule: $A(\\alpha) = \\sum_{m=1}^{M} m\\alpha_m,$ (4)\nmajority rule: $A(\\alpha) = \\arg \\max_{m\\in M} \\alpha_m.$ (5)\nNote that these two opinion aggregation rules are not conflicting. They reflect two perspectives on producing an indicator on the product quality. For brevity, we only consider the honest rating case, and one can easily extend to accommodate misbehaving ratings based on Theorem 5. In the following theorem, we apply theorem 3 to derive the minimum number of ratings needed."}, {"title": "4 INFERRING MODEL PARAMETERS", "content": "In this section, we first present a maximum likelihood estimation (MLE) framework to infer model parameters from ratings. We show that without adding extra conditions, there is an issue of over fitting caused by the high dimensionality of model parameters. To resolve this issue, we propose a linear approximation approach."}, {"title": "4.1 MLE Framework & the Over Fitting Issue", "content": "MLE framework. Without loss of generality, we focus one infer the model parameters for one product. We consider the scenario that we are given $N \\in \\mathbb{N_+}$ ratings $R_1, . . ., R_N$ of product $P$ and the associated rating aggregation rule w. Our objective is to infer $\\alpha, \\gamma$ and $\\Theta = [\\theta_i : i \\in \\mathbb{N_+}]$ from these ratings via maximum likelihood estimation. The log-likelihood function can be derived as\n$L(\\alpha, \\gamma, \\Theta) = \\sum_{i=2}^{N} \\ln (\\gamma_{i-1}\\theta_{i-1,R_i} + (1 - \\gamma_{i-1})\\alpha_{R_i}) .$\nProblem 1. Given $R_1,...,R_N$ of the product $P$ and w. Select model parameters to maximize $L(\\alpha, \\gamma, \\Theta)$:\n$\\begin{array}{ll} \\text{maximize} & L(\\alpha, \\gamma, \\Theta) \\\\ \\alpha,\\gamma.\\Theta & \\\\ \\text{subject to} & ||\\theta_i - \\alpha|| \\le ||\\beta_i - \\alpha||, \\beta_i \\text{ satisfies Eq. (7)}, \\\\ & \\sum_{m\\in M} \\alpha_m = 1, \\sum_{m\\in M} \\theta_{i,m} = 1, \\\\ & \\alpha \\in [0,1]^M, \\theta_i \\in [0,1]^M, \\gamma_i \\in [0, 1]. \\end{array}$\nThe over fitting issue. The following theorem characterizes the optimal solution of Problem 1, which reveals an issue of over fitting."}, {"title": "4.2 Linear Approximation", "content": "To address the over fitting issue, we consider the linear approximation of $\\theta_i$ derived in Equation (2), where the parameter $\\eta_i$ is interpreted as the accuracy of a review selection mechanism. To further reduce the number of parameters to tune, we set $\\eta_i = \\eta, \\gamma_i = \\gamma, \\forall i \\in \\mathbb{N_+}$. The $\\eta$ and $\\gamma$ can be interpreted as the overall accuracy of a review selection mechanism or overall strength of herding effects. Then, it boils down to infer $\\alpha, \\eta, \\gamma$ from ratings. Log-likelihood function is\n$L(\\alpha, \\eta, \\gamma) = \\sum_{i=2}^{N} \\ln [(1 - \\eta)\\gamma\\beta_{i-1,R_i} + (1 - (1 - \\eta)\\gamma)\\alpha_{R_i}] .$\nOne can observe that $\\eta$ and $\\gamma$ is not identifiable. This is because two pairs $(\\eta, \\gamma)$ and $(\\eta', \\gamma')$ can give the same log-likelihood, i.e., $L(\\alpha, \\eta, \\gamma) = L(\\alpha, \\eta', \\gamma')$, if $(1 - \\eta)\\gamma = (1 - \\eta')\\gamma'$. To resolve this issue, we define $\\tilde{\\gamma} \\equiv (1 - \\eta)\\gamma$, which can be interpreted as effective strength of herding effects under a review selection mechanism. The corresponding log-likelihood function is\n$L(\\alpha, \\tilde{\\gamma}) = \\sum_{i=2}^{N} \\ln [\\tilde{\\gamma}\\beta_{i-1,R_i} + (1 - \\tilde{\\gamma})\\alpha_{R_i} ] .$\nThe inference problem can be stated as follows.\nProblem 2. Given $R_1, ..., R_N$ of the product $P$ and w. Select $\\alpha, \\tilde{\\gamma}$ to maximize $L(\\alpha, \\tilde{\\gamma})$:\n$\\begin{array}{ll} \\text{maximize} & L(\\alpha, \\tilde{\\gamma}) \\\\ \\alpha,\\tilde{\\gamma} & \\\\ \\text{subject to} & \\sum_{m\\in M} \\alpha_m = 1, \\beta_i \\text{ satisfies Eq. (7)}, \\\\ & \\alpha \\in [0,1]^M, \\tilde{\\gamma} \\in [0,1]. \\end{array}$\nProblem 2 reduces the number of models parameters from infinite to M + 1. Through this we resolve the over fitting issue of Problem 1, and all the M+1 parameters have clear physical meaning. Note that the objective function of Problem 2 is non-linear and not concave. This means that it may have multiple local optimal solutions. One can apply a gradient method to locate one local optimal solution of it. To increase the chance of hitting one global optimal point, one can repeat the gradient method with multiple different initial points. Through this we may obtain multiple local optimal solutions, and among them we select the one with the largest objective functional value. We denote the selected one as $\\alpha_N, \\tilde{\\gamma}_N$. In the next section, we evaluate the accuracy of this search scheme via experiments on synthetic data."}, {"title": "5 EXPERIMENTS ON SYNTHETIC DATA", "content": "We conduct experiments on synthetic data to quantitatively study the impact of w, $\\eta$ and $\\gamma$ on the convergence speed. We also evaluate the accuracy of our inference algorithm. Code and dataset can be found in the link\u00b9."}, {"title": "5.1 Evaluating the Convergence Speed", "content": "We focus on the honest rating scenario, because the convergence speed under misbehaving rat-ings has similar analytical expressions as the honest rating case. The importance of rating recency was justified by a variety of evidences in real-world applications [10, 11"}]}