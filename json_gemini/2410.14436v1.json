{"title": "Learning to refine domain knowledge\nfor biological network inference", "authors": ["Peiwen Li", "Menghua Wu"], "abstract": "Perturbation experiments allow biologists to discover causal relationships between\nvariables of interest, but the sparsity and high dimensionality of these data pose\nsignificant challenges for causal structure learning algorithms. Biological knowl-\nedge graphs can bootstrap the inference of causal structures in these situations, but\nsince they compile vastly diverse information, they can bias predictions towards\nwell-studied systems. Alternatively, amortized causal structure learning algorithms\nencode inductive biases through data simulation and train supervised models to\nrecapitulate these synthetic graphs. However, realistically simulating biology is\narguably even harder than understanding a specific system. In this work, we take\ninspiration from both strategies and propose an amortized algorithm for refining\ndomain knowledge, based on data observations. On real and synthetic datasets, we\nshow that our approach outperforms baselines in recovering ground truth causal\ngraphs and identifying errors in the prior knowledge with limited interventional\ndata.", "sections": [{"title": "Introduction", "content": "Large-scale perturbation experiments have the potential to uncover extensive causal relationships\nbetween biomolecules (Replogle et al., 2022), which may facilitate myriad applications in drug\ndiscovery, from disease understanding to mechanism of action elucidation (Schenone et al., 2013).\nCausal structure learning (discovery) algorithms are designed to extract these very relationships\ndirectly from data (Spirtes et al., 2001). Yet due to the high number of variables (genes), compounded\nwith the low numbers of observations (cells) per setting (perturbation) (Nadig et al., 2024), these\nalgorithms struggle to scale and perform robustly on such datasets. A key challenge is that causal\ndiscovery algorithms must not only infer the causal direction between variables, but also which\nvariables are related in the first place. The latter can be alleviated in part by incorporating noisy\npriors regarding the data, e.g. by initializing the graph prediction using a biological knowledge\ngraph (Ashburner et al., 2000). However, these graphs compile decades of discoveries from disparate\nexperiments, rendering their relevance and correctness uncertain in individual cellular contexts.\nWhile the choice and quality of these priors generally does not impact consistency in the infinite\ndata limit (Hauser & B\u00fchlmann, 2012; H\u00e4gele et al., 2023), there are rarely sufficient data for these\nguarantees to hold in practice.\nAn orthogonal line of work aims to capture inductive biases that cannot be easily represented by\nindividual graphs via amortized inference over synthetic data (Ke et al., 2022; Lorch et al., 2022). A\nsimulator first generates pairs of \"ground truth\" causal graphs and datasets, following known rules\nregarding the domain of interest. For example, biological networks have been hypothesized to be\nscale-free (Barab\u00e1si & Bonabeau, 2003), and transcription dynamics can be described through sets of\ndifferential equations (Chen et al., 1999). Once these data have been generated, a neural network is"}, {"title": "Background and related work", "content": ""}, {"title": "Biological network inference", "content": "Biological network inference is a classic systems biology problem, in which the goal is to un-\ncover interactions between experimentally-quantifiable entities (e.g. genes, proteins) in the form of\ngraphs (Albert, 2007; Huynh-Thu & Sanguinetti, 2018). For example, graphs of interest include gene\nregulatory networks (Badia-i Mompel et al., 2023), protein-protein interaction networks (Tsitsiridis\net al., 2022), and metabolic pathways (Milacic et al., 2024). Early efforts towards biological network\ninference included the DREAM challenges (Marbach et al., 2012), which provided harmonized\nmicroarray data and were evaluated against known interactions at the time. Probabilistic graphical\nmodels are commonly used to infer gene regulatory networks in specific disease areas (Mao & Resat,\n2004; Zhao & Duan, 2019; Dai et al., 2024). More recent works have also used graph neural networks\nto predict \"missing\" edges in these graphs (Feng et al., 2023). However, while biological network"}, {"title": "Causal structure learning", "content": "Causality provides a formal framework for inferring data-generating mechanisms from experimental\ndata. A causal graphical model is defined by a distribution $P_X$ over a random variables $X$, associated\nwith a directed acyclic graph $G = (V, E)$, where each node $i \\in V$ corresponds to a random variable\n$X_i \\in X$, and each edge $(i, j) \\in E$ indicates a direct causal relationship from $X_i$ to $X_j$ (Spirtes\net al., 2001). It is common to assume that the data distribution $P_X$ is Markov to $G$, i.e. variables\n$X_i$ are independent of all other $X_j \\notin X_{\\text{desc}(i)} \\cup X_{\\pi_i}$ (not descendants or parents), given its parents\n$X_{\\pi_i}$. Causal graphical models introduce the concept of interventions on node $i$, by changing the\nconditional distribution $P(X_i | X_{\\pi_i})$ to a new distribution $P(X_i | X_{\\pi_i})$.\nCausal structure learning is the task of predicting causal graph $G$ from dataset $D \\sim P_X$. Classical\ndiscrete optimization methods operate over the combinatorial space of edge sets, and they make\ndiscrete changes to add/delete/orient edges. These include constraint-based algorithms, such PC and\nFCI for observational data (Spirtes et al., 1995), and JCI for mixed data (Mooij et al., 2020). While\nthese algorithms can be initialized with an undirected graph as a prior, they cannot recover edges\nthat are not present in this initial skeleton. There are also score-based methods that optimize a score,\nwhich represents the \"goodness\" of a particular graph, with respect to the data. These include GES\n(Chickering, 2002), GIES (Hauser & B\u00fchlmann, 2012), CAM (B\u00fchlmann et al., 2014), LiNGAM\n(Shimizu et al., 2006) and IGSP (Wang et al., 2017). Algorithms like GIES iterate between adding\nand deleting edges, so they can (in principle) identify edges that are missing from an initial estimate.\nHowever, due to the exponential space of potential graphs and the reliance on statistical power for\ndiscrete judgments, these classical approaches scale poorly with the number of variables and require\ncopious data for reliable performance.\nOn the other hand, continuous optimization methods approach causal discovery through constrained\ncontinuous optimization over weighted adjacency matrices. Many of these approaches, exemplified by\nNoTears (Zheng et al., 2018), DCDI (Brouillard et al., 2020), and GranDAG (Lachapelle et al., 2020)\ntrain a generative model to capture the empirical data distribution, which is parameterized through\nthe adjacency matrix. Several works have also been specifically designed to address challenges in\nbiological problems. DCD-FG (Lopez et al., 2022) aims to scale to single-cell transcriptomics data\nand proposes a low-rank extension of DCDI. The hybrid IGSP algorithm (Wang et al., 2017) has also\nbeen applied to single-cell data. Prior knowledge can be used to initialize the graph parameters in\nthese frameworks, but the same limitations apply with regards to data-efficiency."}, {"title": "Biological knowledge graphs for perturbations", "content": "Knowledge graphs have been indispensable to modeling biological perturbations. They are com-\nmonly used as undirected graphs, over which graph neural networks predict the cellular effects of\nunseen perturbation (Roohani et al., 2023; Bai et al., 2024) or infer perturbation targets for active\nlearning (Huang et al., 2023) and target discovery (Gonzalez et al., 2024). This work focuses on an\nadjacent but distinct task: of inferring relationships between variables, rather their effects or identity\nas targets."}, {"title": "Methods", "content": "Let $D \\sim P_X$ be a dataset containing $M$ samples of $N$ variables, and let $G = (V, E)$ be the causal\ngraph that generated $P_X$. Let $G' = (V, E')$ be an undirected graph, where $E \\setminus E' \\approx E'$ but\n$E \\cup E^T \\neq E'$. Given $D$ and $E'$, the goal is to predict $E$."}, {"title": "Inference", "content": "When given a new dataset $D$ and graph prior $E'$, we summarize $D$ in terms of local and global\nsummary statistics, which are combined with $E'$ as input to an attention-based neural network,\ntrained to predict $E$ (Figure 2A). We adapt the Sample, Estimate, Aggregate workflow (SEA, Wu\net al. (2024)) to the task of refining noisy graph priors based on data observations as follows."}, {"title": "Training", "content": "At inference time, $E'$ is provided (either a corrupted synthetic graph or a biological knowledge graph).\nDuring training, we sample graph priors by adding noise to the ground truth undirected graph. We\ncompute $E'$ as follows.\n1. Sample noise level $p \\sim \\text{Uniform}(0, 0.5)$, and binary mask $M \\in \\{1\\}^{N\\times N}$ where\n\n$M_{i,j} = 1\\{z_{i,j} \\sim \\text{Uniform}(0, 1) < p\\}.$\n\n2. Compute undirected graph $E = E + E^T$.\n3. Compute noisy prior $E'$ where\n\n$E'_{i,j} = \\begin{cases}\nE_{i,j} & M_{i,j} = 0\\\\\n1 - E_{i,j} & \\text{otherwise}.\n\\end{cases}$\n\nWe finetune all weights with the binary classification objective of predicting $E$, at the edge level.\nThus, the objective both encourages the model to denoise $E'$ and orient edges."}, {"title": "Implementation details", "content": "We adopt the same axial-attention architecture as SEA. Specifically:\n1. The $k \\times k \\times T$ marginal estimates (local graph structures, inferred by standard causal\ndiscovery algorithms) are aligned by matching the same edges across estimates, and mapped\nto a $K \\times T \\times d$ marginal feature, where $K$ is the number of unique edges.\n2. $E'$ is embedding using the same edge embeddings as marginal graphs (since they are in the\nsame input space), and the result is added to that of the global statistic (since they are over\nthe same nodes). The result is a $N \\times N \\times d$ global feature.\n3. A series of 2D axial attention layers (Ho et al., 2020) attend over the rows and columns of\nboth matrices. The final output is a $N \\times N$ matrix, which is supervised by the (synthetic)\nground truth $E$.\nOur synthetic training set contains approximately 4000 datasets of size $N = 10, 20$ with linear\nadditive and neural network (additive and non-additive) causal mechanisms. We use pretrained SEA\nweights with the GIES (Hauser & B\u00fchlmann, 2012) estimation algorithm and inverse covariance as\nthe global statistic. The introduction of $E'$ does not add any new parameters, as we use the same\nembeddings as the existing edge estimates, which support undirected edges."}, {"title": "Experimental setup", "content": "We evaluate our approach against a variety of causal structure learning baselines on real and synthetic\ndatasets. While it would be ideal to evaluate entirely on real applications, synthetic experiments\nallow us to systematically assess how performance changes based on the quality of our noisy priors\nand the availability of interventional data. In real settings, it is difficult to quantify the relevance\nof knowledge graphs to each cell line, disease type, or other factors, as these labels themselves are\ninherently approximations to the underlying biology."}, {"title": "Data preparation", "content": "Biological experiments The Sachs proteomics dataset (Sachs et al., 2005) is a common benchmark\nfor causal structure learning approaches. In this work, we use the subset proposed by Wang et al.\n(2017), which contains 1755 observational samples and 4091 interventional samples, associated with\na consensus graph of 11 nodes and 17 edges. We use both a corrupted version of the ground truth\ngraph (\"Synthetic KG\u201d) and the CORUM (comprehensive resource of mammalian protein complexes)\nknowledge graph (Tsitsiridis et al., 2022) as noisy priors. CORUM focuses on physical interactions\nbetween proteins, which are likely relevant for, but do not directly translate to quantifiable effects of\nperturbing certain proteins on others. Figure 3 depicts the CORUM graph alongside the ground truth.\nSynthetic experiments The raw synthetic datasets were generated following DCDI (Brouillard\net al., 2020): (1) sampling Erd\u0151s-R\u00e9nyi graphs with $N = 10, 20$ nodes and $E = N$ expected edges;\n(2) sampling random instantiations of causal mechanisms (Linear, Neural Networks, Sigmoid with\nadditive Gaussian noise, and Polynomial mechanisms); and (3) iteratively sampling observations\nin topological order. For each graph, we generated one observational regime and ten interventional\nregimes, with each regime consisting of 1000 samples, i.e., $1000 \\times N$ data points, either entirely\nobservational or following a set of single-node perfect interventions.\nDown-sampling In perturbation experiments, observational data are generally easy to collect and\nabundant, while interventional data are costly and limited. For example, large-scale Perturb-seq\ndatasets may include thousands of non-targeting control cells, but only a median of ~50 cells per\nperturbation (Nadig et al., 2024). To emulate this setting on all datasets, we sub-sample 50 or 100\nexamples from each interventional regime, while preserving all observational examples. This allows\nus to evaluate all models in realistic data settings."}, {"title": "Baselines", "content": "We compare our method to several state-of-the-art causal discovery algorithms, which are able to\nincorporate prior knowledge by initializing their graph parameters based on these undirected graphs.\nSpecifically, the \u201cvanilla\u201d setting indicates that models do not consider prior knowledge, while\nthe other settings specify the noise level (10%, 25%) that the undirected graphs were subject to\n(Section 3.2)."}, {"title": "Results", "content": ""}, {"title": "Real experiments", "content": "Table 1 illustrates our results on the Sachs proteomics dataset with varying graph priors. Incorporating\nsynthetic KGs with 10% and 25% noise consistently improves performance in predicting the ground\ntruth graph for OURS on mAP, but the effect is less evident on SHD. When provided with the CORUM\nKG, which contains a much higher noise level (34%), the advantage of leveraging prior knowledge\ndiminishes. In terms of identifying noisy edges, OURS maintains robust performance across all prior\nknowledge settings, while the baselines are less consistent."}, {"title": "Synthetic experiments", "content": "Given the limited availability and challenges of evaluating real-world datasets \u2013 particularly in\nbiological contexts where no standard evaluation exists we perform a comprehensive comparison\nacross synthetic datasets under various settings to assess the performance of each model (Table 2,\nFigure 4). We make the following observations.\nGraph priors are useful in low-data scenarios, even at higher levels of noise. Incorporating\ngraph priors improves performance for both our model and the DCDI baselines. For DCDI-G and\nDCDI-DSF, the performance with a prior noisy graph containing 25% noise is significantly better\nthan that of the vanilla setting, particularly in the down-sampling scenario with only 50 samples per\ninterventional regime. Our model is more sensitive to noise (perhaps because the SEA baseline starts\nat a high level), but a graph prior with 10% is consistently helpful across both data settings.\nGraph priors are particularly helpful on hard settings. On easy settings (e.g. linear), the\nSEA baseline already achieves near-perfect mAP and SHD scores, as the assumptions of SEA'S\nsummary statistics (inverse covariance) match the linear Gaussian setting exactly. Correspondingly,\nour approach's improvement is less pronounced on linear Gaussian. However, there is slight mismatch"}, {"title": "Conclusion", "content": "In this work, we have presented an amortized inference algorithm for refining prior knowledge\ninto data-dependent graphs. We demonstrated in synthetic and real settings that incorporating prior\nknowledge is particularly helpful in low-data settings, and that our approach is able to detect errors\nin these priors with high accuracy. However, we also observed that biological knowledge graphs\ncontain high levels of noise in their connectivity alone, so it could be valuable to incorporate semantic\ninformation regarding the graphs and/or data for future work."}]}