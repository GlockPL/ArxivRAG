{"title": "MIND THE REMAINING: MECHANISM DESIGN FOR ROBUST FEDERATED UNLEARNING", "authors": ["Jiaqi Shao", "Tao Lin", "Bing Luo"], "abstract": "Federated Unlearning (FU) aims to remove target clients' influence from trained models for privacy regulations. However, due to data distribution shifts, it can introduce side effects, including global model performance degradation and uneven impacts on the remaining clients. These effects potentially cause remaining clients to deviate, threatening the system's robustness. To address these challenges, we present a novel and robust mechanism modeling a Stackelberg game for FU. In this game, the server designs an optimal payment to stimulate remaining clients to participate in FU, ensuring unlearning effectiveness and stability. In response, the remaining clients strategically determine their participation level to maximize profit, accounting for offered payments and unlearning impacts. In modeling FU outcomes, we develop, for the first time, a comprehensive framework analytically capturing FU-induced side effects for both the server and clients. Based on this, we establish utility functions for the server and clients in FU, inherently determining their dynamic strategic decision-making. Our rigorous equilibrium analysis reveals how data heterogeneity affects the side effects in their utility and decision-making. Additionally, we develop a low-complexity algorithm for the non-convex optimization problem, enabling efficient computation of the equilibrium. Experiments on text and image classification tasks demonstrate that our approach achieves effective unlearning while reducing side effects compared to uniform pricing.", "sections": [{"title": "1 Introduction", "content": "Federated Learning (FL) is a promising paradigm for collaborative machine learning, allowing multiple data owners to train a shared model without exchanging raw data [1-3]. However, as data privacy regulations (such as GDPR [4] and CCPA [5]) become more stringent, individuals grow increasingly aware of their digital rights, including \u201cthe right to be forgotten\u201d [6]. In response to these evolving privacy concerns and compliance requirements, Federated Unlearning (FU) has emerged to enable the removal of a client's influence from a trained model [8, 9, 16], illustrated in Figure 1.\nIn FU, the intuitive approach to removing a client's influence is to retrain the model from scratch, excluding the data of the removed clients. However, this method is computationally expensive and impractical, especially for large-scale models and datasets [10]. Recent works in FU primarily focus on efficiently achieving unlearning effectiveness that approximates full retraining through various techniques, such as leveraging remaining client data or utilizing server-side historical information to produce an unlearned model (e.g., [11-16]). However, due to data heterogeneity, the unlearned model may introduce new side effects for the server and remaining clients, which haven't been systematically analyzed.\nThe side effects of FU primarily manifest as local performance changes and global performance changes (impacting global stability). For the former, removing a client's data may significantly degrade performance for some remaining clients. For the latter, global stability may be compromised if the removed data represents a unique subset of the overall distribution. Notably, removed data may still represent real-world scenarios the model encounters, making it a relevant concern. These side effects will cause robust issues in FU and thus make the remaining clients deviate from the federated system, especially in heterogeneous settings where data distributions vary significantly across clients."}, {"title": "2 Related Work & Preliminaries", "content": "Existing FU techniques primarily focus on effectively removing the influence of the target data. These approaches can be broadly categorized into methods using historical information [16-18], gradient manipulation [19, 20], knowledge distillation [21], continuous learning [22-25] and reverse training [26, 27]. While Shao et al. [25] has investigated trade-offs between stability/fairness and unlearning effectiveness, a comprehensive framework that simultaneously addresses system-wide objectives with individual client interests is underexplored.\nRecent studies on FU have explored incentive design for both data removal requests and the unlearning process. Ding et al. [28, 29] investigated incentives for data revocation, aiming to retain users and balance partial revocation with model performance. However, the model performance evaluation relied on the assumption of diminishing marginal utility for additional data, overlooking the critical role of data heterogeneity.\nIn contrast, Lin et al. [15] and Liu et al. [30] shifted focus on incentivizing remaining clients to participate in the unlearning process given removal requests. Lin et al. [15] proposed an incentive mechanism considering remaining clients' utility in terms of payment and participation cost for additional unlearning computations. Building on this, [30] incorporated privacy considerations by integrating secure aggregation techniques into the incentive design. However, they overlooked the heterogeneous impact of unlearning on individual clients and focused on either client utility or server objectives without capturing their complex interplay.\nWhile incentive design for client sampling in FL has been extensively studied (e.g., [31\u201336]), these methods primarily address bias reduction for a static data distribution. In contrast, FU presents unique challenges due to dynamic data distributions for balancing global objectives with individual client concerns.\nTo address these limitations, our work focuses on incentivizing remaining clients to participate in unlearning. We incorporate two crucial factors overlooked in previous studies: (1) unlearning impacts on individual clients' utility, influencing participation willingness, and (2) a new server utility including both unlearning effectiveness and global stability."}, {"title": "2.2 Preliminaries", "content": "In this section, we provide an overview of federated learning and unlearning, introducing the formulation of FL, the objectives of FU, and the metrics used to evaluate unlearning effectiveness, global stability, and client performance change."}, {"title": "2.2.1 Federated learning", "content": "Federated learning is a distributed machine learning paradigm that enables training models on decentralized data. Consider a set of clients $O = \\{1, . . ., M\\}$, where each client $i$ has a local dataset with distribution $D_i \\in D$ and $n_i$ data points. The optimal model $w^*$ in FL is typically obtained by:\n$$w^* = \\underset{w}{\\operatorname{argmin}} [F(w) := \\sum_{i \\in O} f_i(w)],$$ where $n_O = \\sum_{i \\in O} n_i$, and $f_i(w)$ is the local loss function for client $i$."}, {"title": "2.2.2 Federated unlearning", "content": "Federated unlearning removes the influence of target clients from a trained federated model. Let $R \\subset O$ be the set of clients requesting removal, and $N = O \\backslash R$ be the set of remaining clients. The goal of FU is to approximate the"}, {"title": "3 System Model", "content": "We consider an FU system where a subset of clients has requested data removal, leaving a set of remaining clients $N = \\{1, ..., N\\}$. The server incentivizes remaining clients to participate in unlearning while balancing effectiveness, stability, and costs. The clients care about the unlearning's impact on their individual local performance against participation costs.\nIn the following, we first define utility functions and decision problems for both the server and clients, incorporating the concepts of unlearning effectiveness, global stability, and client performance change (Section 3.1), Then, in Section 3.2, we propose a Stackelberg game formulation to characterize the strategic interactions between the server and clients."}, {"title": "3.1 Utilities and Strategies of Players", "content": ""}, {"title": "3.1.1 Server's Utility", "content": "The server's utility function, denoted by $U_s(x, p)$, depends on the clients' strategies $x = (x_1,...,x_N)$ and the payments $p = (p_1,...,p_N)$ for clients. The server's objective is to minimize the FU effectiveness metric $V$ (defined in Definition 2.1) and the total payments while maintaining the global stability metric $S$ (defined in Definition 2.2). The server's utility function can be defined as:\n$$U_s(x, p) = -\\lambda_V V(w^u(x)) - \\sum_{i=1}^{N} p_i x_i - \\lambda_S S(w^u(x)),$$ where $w^u(x)$ is the unlearned model from client participation $x$, and $\\lambda_V, \\lambda_S > 0$ are weighting factors that represent the relative importance of the effectiveness and stability metrics in the utility function. For simplicity, we use $V(x)$ and $S(x)$ to denote $V(w^u(x))$ and $S(w^u(x))$ respectively.\nServer's Decision Problem: The server aims to maximize its utility in (3) by choosing the optimal payment scheme $p = (p_1, ..., p_N) \\in R_+^N$:\n$$\\max_{p \\in R_+^N} U_s(x(p), p)$$"}, {"title": "3.1.2 Client's Utility", "content": "The utility function of client $i$, denoted by $U_i(x_i, x_{-i}; p_i)$, depends on their own strategy $x_i$, the strategies of other clients $x_{-i}$, and the payment $p_i$ determined by the server. The client's objective is to maximize their profit, balancing the payment received, the local performance change metric $Q_i$ (defined in Definition 2.3), and the participation cost. The utility function is defined as:\n$$U_i(x_i, x_{-i}; p_i) = p_i x_i - \\lambda_q Q_i(w^u(x)) - c_i x_i,$$ where $\\lambda_q > 0$ represents the importance of the performance change metric, and $c_i > 0$ is the cost incurred by client $i$ for participating in FU. For simplicity, we use $Q_i(x)$ to denote $Q_i(w^u(x))$.\nThe client's utility function captures the trade-off between payment received (measured by $p_ix_i$), potential performance degradation (measured by $\\lambda_q Q_i(x)$), and participation cost (measured by $c_ix_i$) in FU process.\nClient's Decision Problem: Given the payment $p_i$ offered by the server and the strategies of other clients $x_{-i}$, each client $i$ aims to maximize their utility function defined in (5) by choosing the optimal participation level $x_i \\in [0, 1]$, where $x_i = 1$ indicates full participation (utilizing all local data) in FU and $x_i = 0$ indicates non-participation.\nEach client $i \\in N$ solves their own optimization problem to determine their best response $x_i^*(p_i)$ to the server's payment scheme $p_i$, given the strategies of other clients $x_{-i}$:\n$$\\max_{x_i \\in [0,1]} U_i(x_i, x_{-i}; p_i)$$"}, {"title": "3.2 Stackelberg Game Formulation", "content": "We model this sequential decision-making between the server and remaining clients in FU as a two-stage Stackelberg game [37], where the server (leader) first determines the optimal payment scheme, and then the clients (followers) respond by choosing their optimal participation strategies.\nThe Stackelberg equilibrium $(p^*, x^*)$ is characterized by:\nDefinition 3.1 (Stackelberg Equilibrium). A strategy profile $(p^*, x^*)$ constitutes a Stackelberg equilibrium if:\n\u2022 The server's optimal payment scheme $p^* = (p_1^*,...,p_N^*)$, given the best responses of the clients, maximizes its utility: $p^* = \\underset{p}{\\operatorname{argmax}} U_s(x^* (p), p)$\n\u2022 The clients' optimal strategies $x^* = (x_1^*,...,x_N^*)$ maximize their individual utilities: $x_i^* = \\underset{x_i \\in [0,1]}{\\operatorname{argmax}} U_i (x_i, x_{-i}^*; p), \\forall i \\in N$\nThis Stackelberg equilibrium captures the strategic interdependence between the server's payment decisions and the clients' participation choices. The equilibrium payment scheme $p^*$ and the resulting participation strategies $x^*$ offer insights into the optimal design of incentives for the expected outcomes in terms of both individual and system-wide performance.\nIn the rest of the paper, we analyze the FU Stackelberg game, focusing on the strategic interactions between the clients and the server. We first develop a framework that explicitly incorporates data heterogeneity into the utility functions of both clients and the server in Section 4. Then, we examine the clients' strategic behavior (Section 5.1) and server's payments for achieving desired system-wide outcomes (Section 5.2)."}, {"title": "4 Heterogeneity-Aware performance evaluationing", "content": "In this section, we develop a heterogeneity-aware performance evaluation with analytical tractability of FU dynamics. Then, we express the client and server utility functions with this evaluation.\nTo analyze strategic behaviors and design effective incentive mechanisms in FU, it is essential to quantify the impact of unlearning on both individual clients and the overall system. However, capturing the performance change metric $Q_i$ in the client utility function and the metrics $V$ and $S$ in the server utility function presents significant challenges. These challenges stem from the complex interplay between clients' data distributions, participating decisions, and the unlearned model's characteristics."}, {"title": "4.1 Loss Function and Data Distribution", "content": "Assumption 4.1 (Loss Function and Data Distribution). For any data distribution $D \\in D$ and loss function $L : W \\times D \\rightarrow R$ that measures the performance of a model on a given data distribution, we assume there exists a function $g : D \\times D \\rightarrow R$ such that: $L(w, D) = g(D_w, D)$, where $D_w$ is the data distribution that model $w$ is best-fitted to\u2074, and $g$ satisfies: $\\frac{\\partial g(D_w, D)}{\\partial d(D_w, D)} \\geq 0$, where $d$ is a distance metric.\nRemark 4.2. This assumption formalizes that model performance deteriorates with increasing discrepancy between fitted and other distributions. The non-negative partial derivative implies worse performance on divergent distributions, aligning with principles in statistical learning theory and domain adaptation. This assumption establishes the foundation for FU metrics, e.g., S in Definition 2.2 that measures the unlearned model's performance on the original FL system distribution."}, {"title": "4.3 Heterogeneity Measure", "content": "Definition 4.3 (Heterogeneity Measure). Let $H_i \\in R$ represent the data heterogeneity between client $i$ and the removed clients, capturing the data distribution of client $i$, such that: $\\frac{\\partial g(D_w, D)}{\\partial d(H_D, H_D)} \\geq 0$, where $H_D$ and $H_D$ are the heterogeneity measures of $D_w$ and $D$ respectively. $H_{D_w}, H_D$ can be expressed in terms of $H = (H_1,..., H_N)$.\nThis definition of data heterogeneity captures each client's data distribution independently of the participation profile $x$ in the FU process, providing a foundation for analyzing the impact of heterogeneity on unlearning outcomes. Besides, to measure the data distribution of dynamic participated clients, we introduce aggregated heterogeneity:\n$$H(x) = \\frac{\\sum_{k \\in N} \\alpha_k x_k H_k}{\\sum_{j \\in N} \\alpha_j x_j},$$ where $\\alpha_k$ represents the weight of client $k$ relative to the total data quantity of all remaining clients in $N$. This aggregated heterogeneity assumes a linearity of heterogeneity, allowing for tractable analysis of how client participation affects the unlearned model. This property is consistent with standard distance metrics (e.g., Wasserstein distance) under appropriate conditions, revealing the impact of dynamic client participation on overall heterogeneity.\nHeterogeneity-aware Performance Evaluation. Based on Assumption 4.1 and Definition 4.3, we can express the loss function in terms of the heterogeneity measure $H$ as $L(w, D) = l(H_{D_w} - H_D)^2$, where $l > 0$ is a constant. This formulation analytically quantifies performance degradation as the discrepancy between fitted and other distributions increases."}, {"title": "Heterogeneity-Aware Utility Functions", "content": "By heterogeneity-aware performance evaluation, we can now express the utility functions for both clients and the server. For the server's optimization problem, we approximate the unlearning effectiveness metric $V(x)$ and the global stability metric $S(x)$ as:\n$$V(x) \\approx l_V (H(x) - H_N)^2 \\text{ and } S(x) \\approx l_S (H(x) - H_O)^2,$$ where $l_V, l_S > 0$ are scaling factors, $H_N = \\sum_{i \\in N} \\alpha_i H_i$ is the heterogeneity measure of remaining clients (correspond to the best fitted overall distribution), and $H_O$ is the heterogeneity measure of the original FL model (correspond to the best-fitted distribution). Therefore, we can express the server's utility function (3) as:\n$$U_s(x,p) \\approx - u_s(x, p) - \\sum_{i \\in N} p_i x_i,$$ where $u_s(x, p) = \\lambda_V l_V (H(x) - H_N)^2 + \\lambda_S l_S (H(x) - H_O)^2$.\nSimilarly, for the client utility function (5), we can approximate the performance change metric $Q_i$ for each client $i \\in N$ in Definition 2.3 as:\n$$Q_i(x) \\approx l_q [(H(x) - H_i)^2 - (H_O - H_i)^2],$$ where $l_q > 0$ is a scaling factor, $H(x)$ is the aggregated heterogeneity of participated clients corresponding to the unlearned model $w^u(x)$, and $H_O$ is the data heterogeneity corresponding to the original model $w^o$.\nThese heterogeneity-aware utility functions highlight how the similarity (or dissimilarity) between a client's data distribution and the aggregate distribution of participating clients influences both individual decisions and overall system performance."}, {"title": "Discussion of heterogeneity measure H", "content": "Due to privacy concerns, the heterogeneity measure $H_i$ cannot be directly"}, {"title": "Lemma 4.4 (Non-increasing Performance Change Metric)", "content": "Lemma 4.4 (Non-increasing Performance Change Metric). For any client $i \\in N$, given fixed strategies $x_{-i}$ of other clients, the performance change metric $Q_i(x)$ is non-increasing with respect to client $i$'s strategy $x_i$.\nRemark 4.5. This lemma implies that client $i$ benefits from increased participation $x_i$ in the FU process as it reduces $Q_i$. Intuitively, participation helps to mitigate the performance drop by aligning the FU system's data distribution with the client's Besides, if client $i$'s data distribution is identical to that of other clients, $Q_i$ remains constant regardless of participation level. In this scenario, the client's decision does not affect its local performance.\nBuilding on this lemma, we can quantify the impact of performance metric $Q_i$ when comparing full participation to non-participation of individual client $i$ in FU:"}, {"title": "Corollary 4.6 (Full Participation Impact)", "content": "Corollary 4.6 (Full Participation Impact). The change in the performance metric $Q_i$ when client $i$ moves from no participation to full participation is:\n$$\\Delta Q_i = Q_i(1, x_{-i}) - Q_i(0, x_{-i})$$\n$$= l_q (H_{-i} - H_i)^2 - \\frac{1}{(\\frac{m_i}{a_i} + 1)^2} < 0,$$\nwhere $H_{-i} = \\frac{\\sum_{k \\in N \\{i\\}} \\alpha_k x_k H_k}{m_i}$ and $m_i = \\sum_{j \\in N \\{i\\}} \\alpha_j x_j$.\nRemark 4.7. The benefit of participation (smaller $\\Delta Q_i$) increases as $\\alpha_i$ increases, implying that clients with larger datasets have a potentially stronger incentive to participate. The participation of clients with a larger $\\alpha_i$ (larger dataset) has a greater impact on shaping the unlearned model, potentially leading to a model that better reflects their local data distribution (smaller $Q_i(1, x_{-i})$). However, larger datasets also introduce higher local computational costs $c_i$ to utility.\nTo characterize the performance change metric and its dependence on heterogeneity, we present the following proposition:"}, {"title": "Proposition 4.8 (Performance Change Metric Properties)", "content": "Proposition 4.8 (Performance Change Metric Properties). Given the strategies of other clients $x_{-i}$, consider two heterogeneity profiles $H = (H_1, ..., H_i, . . .)$ and $H' = (H_1, . . ., H'_i, . . .)$ that differ only in client $i$'s heterogeneity. The performance change metric $Q_i$ has the following properties:\n1. $Q_i(1, x_{-i}; H) - Q_i(0, x_{-i}; H) \\leq Q_i(1, x_{-i}; H') - Q_i(0, x_{-i}; H')$ if and only if $|H_i - H_{-i}| < |H'_i - H_{-i}|$;\n2. $Q_i(x_i, x_{-i}; H') \\leq Q_i(x_i, x_{-i}; H)$ only if $|H'_i - H_{-i}| < |H_i - H_{-i}|$ and $|H'_i - H^O_i| < |H_i - H^O_i|$.\nwhere $H^O_i = \\frac{\\sum_{k \\in O \\{i\\}} \\gamma_k H_k}{1-\\gamma_i}$ denote the data heterogeneity of all original clients excluding client $i$. $\\gamma_i = n_i / \\sum_{j \\in O} n_j$ represents the weight of client $i$ related to the data quantity of all clients, including the removed clients.\nRemark 4.9. This proposition captures the relationship between a client's data heterogeneity and its incentive to participate in the FU process.\nSpecifically, Property 1 states that as client $i$'s data distribution becomes more divergent from the FU system (represented by a larger $|H_i - H_{-i}|$), the client gains more utility from joining the FU process (captured by a lower value of $Q_i(1, x_i; H) - Q_i (0, x_{-i}; H)$). This indicates a higher incentive for client $i$ to participate in the FU process. As suggested by Lemma 4.4, participation in the FU process helps mitigate potential performance drops by aligning the FU system's data distribution more closely with client $i$. As a result, clients with more divergent data distributions have a stronger motivation to engage in the FU process.\nProperty 2 addresses the impact of data heterogeneity on individual client performance change, considering both the FU system and the original system. It states that if client $i$'s data distribution is closer to the original system (smaller $|H_i - H^O_i|$) but more divergent from the FU system (larger $|H_i - H_{-i}|$), then client $i$ experiences a more significant performance drop (larger $Q_i$). In other words, when the FU system diverges more from client $i$'s distribution than the original system, unlearning is unfavorable for client $i$. This property also highlights how the composition of both participating clients and removed clients affects individual utility."}, {"title": "5 Analysis for FU Stackelberg Game", "content": "This section delves into the strategic interactions between clients and the server in FU. Our analysis unfolds in two key stages. In Section 5.1, we analyze the clients' (followers) participation strategies that form a Nash equilibrium in response to a server payment scheme, proving the existence and uniqueness conditions and revealing how data heterogeneity influences client behaviors. In Section 5.2, we explore the server's (leader) optimal payment strategy, considering the anticipated Nash equilibrium responses of the clients. To efficiently solve this non-convex optimization problem, we propose an efficient algorithm by transforming the server's decision problem into a quasiconvex optimization."}, {"title": "5.1 Client Participation Strategies and Equilibrium", "content": "This section examines the strategic behavior of clients in the FU process, focusing on how data heterogeneity and incentive mechanisms influence client participation decisions. We analyze the Nash equilibria in the client-side game, providing insights into the stable outcomes of client participation strategies.\nWe begin by formally defining the Nash equilibrium concept in the context of our client-side game:\nDefinition 5.1 (Nash Equilibrium among Clients). Given the server's payment scheme $p = (p_1,..., p_N)$, a strategy profile $x^* = (x_1, . . ., x_N)$ is a d-Nash equilibrium among the clients if, for each client $i \\in N$:\n$$U_i(x_i^*, x_{-i}^*; p_i) \\geq U_i(x_i, x_{-i}^*; p_i), \\forall x_i \\in [0, 1].$$ To establish the existence of a Nash equilibrium, we first prove a key property of the client utility function:\nLemma 5.2 (Concavity of Client Utility Function). Given fixed strategies $x_{-i}$ of other clients, the utility function $U_i$ of client $i$ is concave in $x_i$ for $x_i \\in [0, 1].$"}, {"title": "Proposition 5.3 (Existence of Nash Equilibrium)", "content": "Proposition 5.3 (Existence of Nash Equilibrium). Given the server's payment scheme $p = (p_1,..., p_N)$, there exists a Nash equilibrium in the client-side game.\nThe existence of Nash equilibrium ensures stable client strategies in response to the server's payment scheme. To fully understand the strategic landscape, we need to characterize the structure of these equilibria:\nTheorem 5.4 (Characterization of Nash Equilibrium). In any Nash Equilibrium $x^*$, for each client $i \\in N$, given payment rate $p_i$, the equilibrium strategy $x_i^*$ is characterized as follows:\n$$x_i^*(p_i) = \\begin{cases} 0 & \\text{if } p_i < \\underline{p}_i \\\\ (\\frac{\\alpha_i (c_i - p_i)}{2 l_q d_q \\phi(x_{-i}^*)} )^{1/3} \\frac{m}{\\alpha_i} & \\text{if } \\underline{p}_i \\leq p_i \\leq \\overline{p}_i \\\\ 1 & \\text{if } p_i > \\overline{p}_i \\\\ \\end{cases}$$\nwhere $\\phi(x_{-i}^*) = 2 l_q d_q m^2 (H^*_{-i} - H_i)^2$, $H^*_{-i} = \\frac{\\sum_{k \\in N \\{i\\}} \\alpha_k x_k H_k}{m}$, $m = \\sum_{j \\in N \\{i\\}} \\alpha_j x_j$, and the threshold payment are defined as:\n$$\\underline{p}_i = c_i - \\frac{\\alpha_i \\phi(x_{-i}^*)}{m^3} \\quad \\overline{p}_i = c_i + \\frac{\\alpha_i \\phi(x_{-i}^*)}{(\\alpha_i+m)^3}$$\nThis characterization reveals a threshold structure in the clients' equilibrium strategies, providing insights into un- derstanding how clients will respond to different payment schemes and how their data heterogeneity influences their decisions. In practical scenarios, it's desirable to have a unique equilibrium to ensure predictable outcomes. To this end, we provide a sufficient condition for the uniqueness of the Nash equilibrium:"}, {"title": "Theorem 5.5 (Sufficient Condition for Uniqueness of Nash Equilibrium)", "content": "Theorem 5.5 (Sufficient Condition for Uniqueness of Nash Equilibrium). Let $H_{max} = \\underset{k}{\\operatorname{max}} H_k$ and $H_{min} = \\underset{k}{\\operatorname{min}} H_k$. The Nash Equilibrium characterized in Theorem 5.4 is unique, if for all client $i \\in N$:\n$$\\frac{4 \\sqrt[3]{3 d(1-\\alpha_i)}}{4 \\sqrt[3]{\\lambda_q \\lambda_a}} > H_{max} - H_{min}$$\nRemark 5.6. The sufficient condition for the uniqueness of the Nash Equilibrium offers several game-theoretic insights:\n1. Data Heterogeneity Bound: The equilibrium is unique when the range of data heterogeneity $(H_{max} - H_{min})$ is bounded below a certain threshold. If clients are sufficiently homogeneous $(H_{max} \u2013 H_{min} \\approx 0)$, uniqueness is guaranteed.\n2. Heterogeneity-Participation Trade-off: The equilibrium uniqueness condition is most relaxed when client participation is balanced $(\\alpha_i \\approx \\frac{1}{3})$, allowing for higher data heterogeneity. Conversely, systems dominated by a single client $(\\alpha_i \\rightarrow 1)$ require near-homogeneous data distributions to guarantee uniqueness. For example, a system with highly skewed participation (e.g., 80%-10%-10%) demands low heterogeneity for a unique equilibrium, while a more balanced distribution (e.g., 40%-30%-30%) can tolerate higher levels of heterogeneity while still maintaining a unique equilibrium.\n3. Incentive Mechanism for Heterogeneity: The absolute difference $c_i - p_i$ between participation cost and payment positively contributes to satisfying the condition. In more heterogeneous environments, more aggressive pricing strategies (larger $|c_i \u2013 p_i|$) are necessary to ensure a unique equilibrium.\nThe above insights from the sufficient condition for uniqueness highlight the challenges posed by heterogeneity and the importance of carefully designed incentive mechanisms. For the special case of homogeneous clients, the strategic landscape simplifies considerably:\nCorollary 5.7 (Existence of Unique Nash Equilibrium for Homogeneous Clients). In the FU client-side game with homogeneous remaining clients, there exists a unique Nash equilibrium. The best response of client $i$ is therefore:\n$$BR_i(p_i) = \\begin{cases} 1 & \\text{if } p_i > c_i \\\\ 0 & \\text{if } p_i \\leq c_i \\\\ \\end{cases}$$\nThis corollary provides the special case of homogeneous clients in the FU client-side game where clients do not experience performance reductions in FU, as all clients have similar data distributions. This best response function is independent of other clients' strategies, making it dominant."}, {"title": "5.2 Server's Optimal Payment", "content": "This section addresses the server's challenge of determining the optimal payment scheme for the server (leader) in the FU Stackelberg game. We first formulate the server's decision-making process as a non-convex optimization problem. Then, we transform the initial non-convex into a quasiconvex optimization problem and introduce an efficient solution method.\nThe server's utility function involves a trade-off between minimizing $|H(x) \u2013 H_N|$ (to reduce V) and minimizing $|H(x) \u2013 H_O|$ (to maintain S). These objectives can be conflicting, making the optimization problem non-trivial.\nGiven the clients' best responses characterized in Theorem 5.4, we formulate the server's optimization problem as:\nP1:\n$$\\underset{p}{\\operatorname{min}} u_s(x^* (p))$$\ns.t.\n$$p_i \\geq 0, \\forall i \\in N$$\n$$p^T x^*(p) \\leq B$$\nwhere $x^*(p)$ is the vector of clients' best responses to the payment scheme p, B is the budget.\nThe non-convexity of P1 presents a significant challenge for finding global optimal solutions efficiently. To address this, we transform P1 into a quasiconvex optimization problem, which allows for efficient solution methods. Specifically, we establish the quasiconvexity of the server's utility function (Lemma 5.8) by linearizing $u_s$ with respect to $H(x)$ around $H_O = H(x^*(p_0))$, where $x^*(p_0)$ is the Nash equilibrium strategy profile for some initial payment scheme $p_0$:\n$$\\tilde{u}_s(H(x^*(p))) = u_s(x^*(p_0), p_0) + [2 \\lambda_V l_V (H_O \u2013 H_N) + 2 \\lambda_S l_S (H_O \u2013 H_O)] \\cdot (H(x^*(p)) \u2013 H_O)$$\nLemma 5.8 (Quasiconvexity of $\\tilde{u}_s$). The function $\\tilde{u}_s(x^*(p), p)$ is quasiconvex."}, {"title": "Lemma 5.9", "content": "Lemma 5.9. The function $p^T x^*(p)$ is monotonically decreasing in $p$ for $p_i \\in [\\underline{p}_i, \\overline{p}_i], \\forall i \\in N$.\nFor each client $i$, there exists a unique $PB,i$ such that $PB,i x_i^*(PB,i) = Bi$, where $Bi$ is client $i's$ share of the total budget $B$. For $p_i < \\underline{p}_i$, we have $x_i = 0$, so we can set $PB,i = \\underline{p}_i$. This allows us to transform the budget constraint into individual upper bounds on payments: $p^T x^*(p) < B \\Leftrightarrow p_i \\leq PB,i$ for all $i$.\nTherefore, we can reformulate P1 as the following quasiconvex optimization problem:\nP2:\n$$\\underset{p}{\\operatorname{min}} \\tilde{u}_s (H(x^*(p)))$$\ns.t.\n$$0 \\leq p_i \\leq PB,i, \\forall i \\in N$$\nP2 explicitly incorporates the heterogeneity constraint derived from our analysis, ensuring that the resulting payment scheme accounts for the critical role of data heterogeneity in federated unlearning outcomes.\nFor the quasiconvex optimization problem P2, we now present an efficient algorithm, Heterogeneity-Aware Incremental Payment Optimization (HAIPO), detailed in Algorithm 1. Specifically, we employ a two-stage approach:"}, {"title": "1. Budget Upper Bound Computation", "content": "We first determine the budget upper bounds $PB$ for each client using bisection search (Lines 1-5) so that the resulting payment scheme always satisfies the budget constraint."}, {"title": "2. Optimal Payment Search"}]}