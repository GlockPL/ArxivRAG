{"title": "TOWARDS SCIENTIFIC DISCOVERY WITH DICTIONARY LEARNING: EXTRACTING BIOLOGICAL CONCEPTS FROM MICROSCOPY FOUNDATION MODELS", "authors": ["Konstantin Donhauser", "Kristina Ulicna", "Gemma Elyse Moran", "Aditya Ravuri", "Kian Kenyon-Dean", "Cian Eastwood", "Jason Hartford"], "abstract": "Dictionary learning (DL) has emerged as a powerful interpretability tool for large language models. By extracting known concepts (e.g., Golden-Gate Bridge) from human-interpretable data (e.g., text), sparse DL can elucidate a model's inner workings. In this work, we ask if DL can also be used to discover unknown concepts from less human-interpretable scientific data (e.g., cell images), ultimately enabling modern approaches to scientific discovery. As a first step, we use DL algorithms to study microscopy foundation models trained on multi-cell image data, where little prior knowledge exists regarding which high-level concepts should arise. We show that sparse dictionaries indeed extract biologically-meaningful concepts such as cell type and genetic perturbation type. We also propose a new DL algorithm, Iterative Codebook Feature Learning (ICFL), and combine it with a pre-processing step that uses PCA whitening from a control dataset. In our experiments, we demonstrate that both ICFL and PCA improve the selectivity of extracted features compared to TopK sparse autoencoders.", "sections": [{"title": "1 INTRODUCTION", "content": "Large scale machine learning systems are extremely effective at generating realistic text and images. However, these models remain black boxes: it is difficult to understand how they produce such detailed reconstructions, and to what extent they encode semantic information about the target domain in their internal representations. One approach to better understanding these models is to investigate how models encode and use high-level, human-interpretable concepts. A challenge to this endeavor is the \u201csuperposition hypothesis\u201d Bricken et al. (2023), which states that neural networks encode many more concepts than they have neurons, and as a result, one cannot understand the model by inspecting individual neurons. One hypothesis for how neurons encode multiple concepts at once is that they are low-dimensional projections of some high-dimensional, sparse feature space. Quite surprisingly, there is now a large body of empirical evidence that supports this hypothesis in language models (Mikolov et al., 2013; Elhage et al., 2022; Park et al., 2023), games (Nanda et al., 2023) and multimodal vision models (Rao et al., 2024), by showing that high-level features are typically predictable via linear probing. Further, recent work has shown that model representations can be decomposed into human-interpretable concepts using a dictionary learning model, estimated via sparse autoencoders (Templeton,\n2024; Rajamanoharan et al., 2024b;a; Gao et al., 2024).\nHowever, all of these successes have relied on some form of text supervision, either directly through next-token prediction or indirectly via contrastive objectives like CLIP (Radford et al., 2021), which align text and image representations. Further, these successes appear in domains which are naturally human-interpretable (i.e. text, games and natural images), and as a result, one may worry that high-level features can be extracted only in settings that we already understand. This raises a natural question: can we extract similarly meaningful high-level features from completely unsupervised models in domains where we lack strong prior knowledge? For example, in computational biology, masked autoencoders (MAE) trained on cellular microscopy images have been shown to be very effective at learning representations that recover known biological relationships (Kraus et al., 2024). However, it is not known whether analogous high-level features can be extracted from these large MAEs. These settings are precisely where extracting high-level features could be most valuable: given that models can detect subtle differences in images (even\nthose that are very challenging for human experts to interpret), we might hope that we can use these techniques to better understand these subtle differences.\nWe study the extraction of high-level features from large-scale MAEs trained on microscopy images of cells that have been perturbed in genetic and small molecule perturbations screens (Fay et al., 2023). Understanding the morphological changes induced by genetic and small molecule perturbations is an inherently difficult and fundamental problem that plays a crucial role in drug discovery (Celik et al., 2022). Recent progress in this field using machine learning has been made by building similarity maps of genetic perturbations via cosine-similarities of post-processed representations from MAEs (Kraus et al., 2024; Celik et al., 2022; Lazar et al., 2024). However, a limitation of these deep learning-based methods is that we only gain limited insights about the morphological changes arising from the perturbations: we can tell whether two perturbations are similar (or dissimilar) via cosine similarity, but we cannot tell why (or the ways in which) they are different. That is, we collapse the multidimensional representations down to a single score.\nIn this paper, we train unsupervised dictionary learners on top of intermediate representations of large-scale MAES (Kraus et al., 2024) and find features correlated with single concepts such as individual cell types or genetic perturbations. Moreover, via linear probing, we show that the learned features preserve significant amounts of biologically-meaningful information. Through this research, we make several key contributions:\n\u2022 We show that dictionary learning can be used to extract biologically-meaningful concepts from microscopy foundation models (see Figure 1), opening the path to scientific discovery using tools from mechanistic interpretability.\n\u2022 We propose a new dictionary learning algorithm-Iterative Codebook Feature Learning (ICFL)\u2014which naturally avoids \"dead\" features (Section 4).\n\u2022 We further show how PCA whitening on a control dataset can act as a form of weak supervision for dictionary learning (Section 5), resulting in more specific features.\n\u2022 We demonstrate empirically that both ICFL and PCA improve the selectivity of extracted features compared to TopK sparse autoencoders (Section 6)."}, {"title": "2 RELATED WORK", "content": "Dictionary Learning The dictionary learning (DL) problem has already been around since the 90's (Mallat and\nZhang, 1993; Olshausen and Field, 1996) and has since then been extensively studied in the literature (see e.g., Aharon\net al. (2006); Donoho et al. (2001); Spielman et al. (2012)). Recently, Bricken et al. (2023) proposed to use dictionary\nlearning to extract \u201cmonosemantic\" features from internal representations of LLMs, with several followup works\n(see e.g., Rajamanoharan et al. (2024b;a); Gao et al. (2024)) including different modalities such as vision (see e.g,\nGorton (2024); Rao et al. (2024)). These works build upon the assumption that large-scale transformer models lay out\n\"concepts\" as linear directions (see Jiang et al. (2024) for an overview), which is often referred to as linear representation\nhypothesis. We further mention Rajendran et al. (2024) as a theoretic work aiming to give provable guarantees for when\n\"concepts\" can be recovered.\nCausal representation learning The disentanglement and causal representation literature (CRL) share the goal of\nlearning high-level, interpretable concepts (Bengio et al., 2013; Kulkarni et al., 2015; Higgins et al., 2017; Chen et al.,\n2016; Eastwood and Williams, 2018; Sch\u00f6lkopf et al., 2021). Two key differences with the dictionary learning approach\nare: (i) disentanglement/CRL methods consider low-dimensional representations to capture the factors of variation\nin data, whereas overcomplete dictionary learning seeks a higher-dimensional representation to capture a large set of\nsparsely-firing concepts; and (ii) disentanglement/CRL methods aim to be inherently interpretable, whereas this paper\nconsiders a post-hoc approach to interpret pre-trained models. Related work on post-hoc explainability also learns\n\"concept vectors\" in neural network internal states (Kim et al., 2018; Ghorbani et al., 2019); a key difference is that these\nmethods use class-labeled data, whereas this paper uses an unsupervised approach to discover concepts. Another line of\nfeature-visualization works aim to interpret internal states/neurons by finding the data points (or gradient-optimized\ninputs) that lead to maximal activation (Mordvintsev et al., 2015; Olah et al., 2017; Borowski et al., 2021). In contrast to\nthese local data point centric approaches, dictionary learning methods seek global parameters (dictionaries) to explain\nmodels."}, {"title": "3 BACKGROUND", "content": "The superposition hypothesis. Let $x_i \\in \\mathbb{R}^d$ denote a representation for token i; as an example, $x_i$ may be the embedding of token i after a transformer layer. Bricken et al. (2023) hypothesize that (i) such token representations $x_i \\in \\mathbb{R}^d$ are linear combinations of concepts; (ii) the number of available concepts M significantly exceed the dimension of the representation d; and (iii) each token representation is the sum of a sparse set of concepts. These desiderata are satisfied by the following model that is widely studied in compressed sensing and dictionary learning:\n$x_i \\approx \\mathbf{W}z_i = \\sum_{m=1}^M z_{im}\\mathbf{W}_m \\quad \\text{where } ||z_i||_0 < d$ \nwhere $ \\mathbf{W} = [\\mathbf{W}_1,\\ldots,\\mathbf{W}_M] \\in \\mathbb{R}^{d \\times M}$ is a latent dictionary matrix and $z_i \\in \\mathbb{R}^M$ is a sparse latent vector. In this paper, we will refer to the columns $ \\mathbf{W}_m$ as \"feature directions\" and $z_i$ as \"features\".\nFeature learning using TopK SAEs. Given a set of token representations $\\{x_i\\}_{i=1}^N$, learning both $ \\mathbf{W}$ and $\\{z_i\\}_{i=1}^N$ is a dictionary learning or sparse coding problem (Olshausen and Field, 1997), with a long history of works proposing efficient algorithms with provable guarantees (Aharon et al., 2006; Arora et al., 2014; 2015). In the context of mechanistic interpretability, the dominant choice for learning these parameters are two-layer sparse autoencoders. In this paper, we compare to the state-of-the-art method called TopK SAE, originally proposed by Makhzani and Frey"}, {"title": "4 ITERATIVE CODEBOOK FEATURE LEARNING (ICFL)", "content": "Sparse autoencoders such as TopK SAEs face two major limitations: (i) they require regularization to avoid \u201cdead features\" after training (Gao et al., 2024; Bricken et al., 2023) and (ii) some feature directions may be overrepresented in the samples $\\{x_i\\}_{i=1}^N$, biasing the estimation. To overcome these limitations, we propose Iterative Codebook Feature Learning (ICFL). ICFL retains the decoder of TopK SAEs; however, instead of using an encoder to learn the features z, ICFL updates z using a variant of the orthogonal matching pursuit algorithm of Mallat and Zhang (1993) as described in Algorithm 1. Specifically, given the current matrix of feature directions $ \\mathbf{W}_{dec}$, we first select the top-k columns most aligned with $x^{(1)} = x$. Then, we learn the features $z^{(1)}$ that best reconstruct $x \\approx \\mathbf{W}_{dec}z^{(1)}$, using only these columns (i.e. $z^{(1)}$ is K-sparse). Next, to obtain $z^{(2)}$, we repeat this step, but replace x with the residual $x^{(2)} = x - \\mathbf{W}_{dec}z^{(1)}$. Repeating this process, the final output z is taken to be $z = \\sum_{t=1}^J z^{(t)}$. Consequently, z is at most Jk-sparse. We call the columns of $ \\mathbf{W}_{dec}$ the corresponding feature directions of z.\nThe key idea of ICFL is that early iterations subtract dominant feature directions from x, allowing the algorithm in later iterations to select a broader set of feature directions that are not as correlated with the main features in x. After updating z as detailed in Algorithm 1, the decoder parameters $\\{\\mathbf{W}_{dec}, b_{pre}\\}$ are updated to minimize the reconstruction loss from (2) with $x = \\mathbf{W}_{dec}z + b_{pre}$. As z is fixed in this gradient step, the algorithm does not propagate gradients through z. Consequently, the algorithm results in very few \u201cdead\u201d features. As a result, we do not require any additional regularization to address this \u201cdead feature\u201d issue that often hinders SAEs, as shown in Table 1.\nIn practice, we leverage random resets to ensure that the columns of $ \\mathbf{W}_{dec}$ are not too correlated. To prevent the collapse of multiple feature directions (i.e. columns of $ \\mathbf{W}_{dec}$) to the same direction, after every 100 stochastic gradient descent steps, we take every pair of columns of $ \\mathbf{W}_{dec}$ that have cosine-similarity above 0.9 and randomly initialize one of the pairs with a vector selected uniformly at random from the hypersphere. Before running Algorithm 1, we always center the representations x by subtracting the average representation of unperturbed samples from the control distribution, such that the origin represents the unperturbed state. Finally, we normalize the representations before applying the dictionary learner."}, {"title": "5 EXPERIMENTAL SETUP", "content": "Data source and foundation model We evaluated our dictionary learning approach on two large-scale masked autoencoders trained on cellular microscopy Cell Painting image data using 256x256x6 pixel crops as input and a patch size of 8, following the same procedures as those described in Kraus et al. (2024). These models were trained on data from multiple cell types that were perturbed with both CRISPR gene-knockouts and small molecule perturbations. Both models used the architecture hyperparameters from Kraus et al. (2024), with the smaller of the two using the ViT-L/8 configuration, while the larger model used the ViT-G/8 configuration. We refer to these models as MAE-L and MAE-G, respectively. We obtain a single token per input crop by aggregating all patch tokens (excluding the class token). For both the residual stream and the attention output (after the out-projection), the dimension d of the tokens (representations) are 1024 and 1664 for MAE-L and MAE-G, respectively. All the visualizations used Cell Painting microscopy images from the public RxRx1 (Sypetkowski et al., 2023) and RxRx3 (Fay et al., 2023) datasets.\nWe extract the tokens from layer 16 (MAE-L) and layer 33 (MAE-G), respectively. The motivation for using intermediate instead of final layers is that these tokens are more likely to capture abstract high level concepts that are internally used\nby the model to solve the SSL task (Alkin et al., 2024). We selected this layer by finding the layer which maximized linear probing performance on the functional group tasked (described below) from the original embeddings.\nPreserving linear probing signals To investigate whether the features found by sparse dictionary learning retain important information from the original representation, we define five different classification tasks, summarized in Table 2. For each classification task, we use a separate (potentially overlapping) dataset and split it into train and test data to distinguish labels across:\n(1) 23 different cell types which are almost perfectly distinguishable via linear classification.\n(2) 272 different experiment batches. Even in controlled conditions, subtle changes in experimental conditions can induce strong batch effects, i.e. changes in experimental outcomes due to experiment-specific variations unrelated to the perturbation that is being tested.\n(3) 1138 siRNA perturbations from the RxRx1 dataset (Sypetkowski et al., 2023), where the single-gene expression (i.e. gene mRNA level) is partially (or completely) silenced using short interfering (si-)RNA. siRNA targets the gene mRNA for destruction via the RNA interference pathway (Tuschl, 2001). As the extent of siRNA knock-downs is hard to quantify and prone to significant but consistent off-target effects, we also evaluated:\n(4) 5 single-gene CRISPR perturbation knockouts which induce strong and consistent morphological profiles across cell types, known as \"perturbation signal benchmarks\u201d (Celik et al., 2024). Unlike the siRNA approach, CRISPR cuts the gene DNA directly, which induces mutation in the sequence and represses the gene function. To evaluate whether our method retrieves signal which corresponds to similar phenotypes, we also assessed:\n(5) 39 functional gene groups composed of CRISPR single-gene knockouts categorized by phenotypic relation-ships between the genes, including major protein complexes, as well as metabolic and signaling pathways. Each gene group targets similar or related cellular process, which results in inducing morphologically similar changes in the cells (Celik et al., 2022).\nTo remove the impact of spurious correlations between perturbations and batch effects on the test accuracy, we always use mutually exclusive experiments for test and train data, except for Task (2), where the goal is to predict the experiment. Except for Task (1), all classification tasks use HUVEC cells and always use well-level aggregated representations; that is, we take the mean over the total of 1,024 (8 \u00d7 8 pixel regions) individual 1,024-dimensional tokens from all 36 256 \u00d7 256 non-edge crops from an 2,048 \u00d7 2,048 pixel image of a given well. Because some of the classes are heavily imbalanced (particularly for Task (1)), we always report the balanced test accuracy and train our linear probes using logistic regression on a class-balanced cross-entropy loss.\nPCA whitening using a control dataset As dictionary learners seek to minimize the Euclidean distance between the model representations x and their reconstructions z = Wz, the learned features z are naturally biased towards capturing the dominant directions in the data (i.e., those that explain the most variance). Unfortunately, these directions often do not align with meaningful concepts. To address this, we use a dataset of control samples as a form of weak supervision, downweighting dominant directions in this control dataset as we know they do not correspond to the biological perturbations of interest. In particular, we learn a PCA-and-centerscale transform on this control dataset and apply it to the entire dataset before normalization. For our multi-cell data, unperturbed HUVEC-cell images act as our control dataset. Note that similar PCA whitening on a control dataset has been used to improve the quality of the learned multi-cell image representations (Kraus et al., 2024).\nTraining the DL models By default, we always choose a sparsity of $K = 100$ for TopK SAEs and $J = 20, k = 5$ (resulting in a max sparsity of 100) for ICFL as described in Section 4, and use a total of M = 8192 features. Unless otherwise specified, we always apply the PCA whitening described in Section 5 and use representations from the"}, {"title": "6 EXPERIMENTAL RESULTS", "content": "In this section we present our experimental results. If not further specified, we always use features extracted from ICFL in combination with PCA whitening.\n6.1 DICTIONARY FEATURES ARE CORRELATED WITH BIOLOGICAL CONCEPTS\nPreserving linear probing signals We compare the accuracy of linear probes on the representations, x, with linear probes on the reconstructions from ICFL, X = Wdec, to measure how much \u201cbiologically-relevant\u201d information is lost when extracting sparse features. Figure 2a shows that almost the entire signal is preserved for simple concepts such as cell types (1), batch effects (2) and perturbations with strong morphological changes (4). For the difficult tasks of distinguishing between many genetic perturbations (3,5), a substantial amount of the linear signal is preserved. Both TopK SAEs and ICFL features yield a similar linear probing accuracy, while we can see a clear drop if no PCA whitening is used during pre-processing. We further present in Figure 2b an ablation for the sparsity of the extracted feature vector. While increasing the number of non-zeros improves the accuracy, the effect is limited compared to PCA whitening.\nReconstruction loss To evaluate the quality of unsupervised DL, the cosine similarity (or l2-error) has been often used as a benchmark (Rajamanoharan et al., 2024a; Gao et al., 2024). Figure 2c shows that the reconstruction quality of ICFL is much higher than TopK SAE for the same sparsity constraints when using PCA whitening. We provide further ablations in Appendix C.\nSelectivity of features for biological concepts As a third experiment, we investigate how strongly correlated the features are with labels from the classification tasks in Table 2. For each dataset associated with a classification task, we extract from every image a feature vector using the center crop as input to the MAE. For each feature, we then compute two selectivity scores: the avg selectivity score, which is the % of times that the feature is active given that label i occurs minus the % of times the feature is active given any other label. As a stronger notion of correlation, we also use the max selectivity score, that subtracts the maximum % for any other label. The selectivity score has been originally proposed in the context of neuroscience (Hubel and Wiesel, 1968) and has also been used by Madan et al. (2022) to measure the \u201cmonosemanticity\u201d of neurons.\nWe plot in Figure 2d-2f the selectivity scores for both ICFL features and TopK SAEs. We see that ICFL features consistently achieve higher selectivity scores than TopK SAE features. Moreover, especially for cell types, we observe a high max selectivity across almost all cell types, while for more complex features we still observe a moderate selectivity score of more than 0.1 across all labels. We present in Table 3 the number of features exhibiting an average selectivity greater than a given threshold for at least one label, across all five classification tasks. This is done using three different thresholds for ICFL with PCA whitening. We observe that dominant concepts, such as cell types, batch effects, and siRNA perturbations that induce strong morphological changes, lead to a substantial portion of features displaying high selectivity. However, also for labels from the functional gene groups (Task 5), we identify more than 100 features with selectivity scores of at least 0.1.\nSeparation along feature directions The selectivity score analysis showed that activation patterns of the sparse features can be strongly correlated with genetic perturbations. To further strengthen this argument, we illustrate in Figure 3 the cosine similarities between representations from different genetic perturbations and selected feature directions, that is the i-th column of Wdec for Feature i. While we could also directly look at the feature values zi, due to the sparsity, most of the values are 0.\nWe plot Figure 3 the cosine similarities between selected feature directions and the crop-level aggregated tokens. The histogram in blue represent tokens from specific siRNA perturbations, while the histogram in orange represent all other tokens from Task 3. The plot shows that feature directions effectively separate the two groups, showing that certain features capture important biological information, which shed light on the morphological changes caused by genetic perturbations.\n6.2 COMPARISON WITH FEATURES FROM CellProfiler\nAs a second set of experiments, we compare the average selectivity scores of features from ICFL with those from a set of 964 handcrafted features generated by CellProfiler (CP) (Carpenter et al., 2006). These features are designed by domain experts and are widely used for microscopy image analysis. This task compares the selectivity of unsupervised features extracted from foundation models to that of human expert-designed features. We obtain sparse features by thresholding the average CP features obtained from all cells from a multi-cell image taken from a subset of the public RxRx1-dataset (Sypetkowski et al., 2023). We threshold at the a and 1 a quantiles with a chosen such that the average number of non-zeros is \u2248 100. A feature was classified as \u201cactivated\" when its value, under perturbation conditions, exceeded these quantiles. The selectivities corresponding to both CP and our SAEs, measured using the same datasets.\nComparison of selectivity scores In Figure 3e, we plot the highest average selectivity score for each genetic perturbation (a subset of Task 3 in sorted order for both CP features and ICFL features). The results show that the features extracted by ICFL almost match the selectivity scores of the handcrafted, human-designed features. Additionally, in Figure 3f, we show the average score across all labels as a function of various thresholding levels for the CP features. On the x-axis, we plot the average number of non-zero elements. We again observe that our features perform comparably to CP features. Interestingly, CP features peak at high levels of non-zeros (\u2248 300), leaving future work to assess whether this peak selectivity can be matched using deep learning-based approaches which use significantly fewer non-zero elements. We further illustrate the correlation between the best average selectivity scores from the CP and ICFL features for each label (Figure 3g). The plot demonstrates a strong correlation (Pearson coefficient of 0.71), suggesting that ICFL is capable of identifying features that capture patterns similar to those detected by CP."}, {"title": "7 INTERPRETABILITY ANALYSIS OF SELECTED FEATURES", "content": "In this section, we illustrate striking, non-trivial patterns captured by selected features and provide an example for how domain experts can interpret, study and validate features found by DL. To study the \u201csemanticity\u201d of features in ViTs, we propose interpreting them at the pixel level by examining which patches exhibit the highest cosine similarities with the feature directions. More precisely, for the multi-cell image crops strongly correlated with selected feature directions, we compute heatmaps of the cosine-similarities of the individual tokens from 8 \u00d7 8 patches and feature directions.\n7.1 CHANNEL-SPECIFIC PROPERTIES OF SINGLE-GENE PERTURBATIONS\nWe begin our interpretability analysis by examining the extent to which we can recover channel-specific signal associated with the gene perturbations. For this exercise, we queried 3 specific single gene perturbations: (i) OPA-1, which contributes to the maintenance of correct shape of mitochondria, (ii) ALG-3, which aids in the modification of proteins and lipids in the endoplasmic reticulum (ER) after synthesis, and (iii) TSC-2, which contributes to the control of the cell size (Figure 4).\nOPA-1 The mitochondrial channel shows that most correlated tokens are overlaid with distant regions where enlarged mitochondria are present (pink arrows). Quantitatively, this nuanced relationship does not show a strong correlation in the mitochondrial channel (0.41) due to the aberrant image background, but qualitative examination of this channel highlights this delicate detail which is not obvious from the composite images (Figure 4, 1st column, middle row), confirming that our approach identifies channel-specific level of detail.\nALG-3 The most aligned tokens appear specific to regions of endoplasmic reticulum (ER) and RNA with which ALG-3 co-localizes, where it aids with attachment of a sugar-like groups to proteins. In this dense image, we report that the correlation of endoplasmic reticulum (0.63) and RNA-specific channels (0.63) are much higher than for channels staining other cellular compartments, e.g. plasma membrane (0.24) or actin (0.16). This suggests that our token heatmap is prevalently focused on ER-specific information (Figure 4, 2nd column), which is consistent with what we would expect from our understanding of the protein function.\nTSC-2 We examine the plasma membrane- and Golgi apparatus-specific channel to relate perturbed cell size control to the token alignment. We confirm that this channel correlates most strongly with the queried concept direction, but this time in a negative direction. As the plasma membrane and, hence, cytoplasmic area are the most extensive from the cell center, the mostly aligned tokens appear to focus specifically on regions which are not covered by the cell membrane, or the membrane pixel intensity fades away (Figure 4, 3rd column, bottom row). This relationship shows highly negative correlation (-0.71), making it a stronger signal than actin (-0.43) or mitochondria (-0.49), and in this case is likely monitoring the lack of channel-specific signal.\nInverse focus Building on our previous observation, we additionally show that the tokens are not always co-localized with regions occupied by cells. Here, we selected two genes which appear to follow an \u201cinverse\u201d trend, namely affecting PLK-1, which enables cell cycle progression through mitosis, and TMED-2, which helps to regulate intracellular protein transport. While both of these gene perturbations render the cells in a characteristic affected state (small, clumped cells struggling to divide vs. large, spread out and actively dividing cells), it appears that their most aligned tokens correspond to areas not covered by cells, which we confirm with highly negative correlations across all channels (Figure 4, last 2 columns). Although this behavior is harder to interpret, it is suggestive of that the salient feature for these perturbations is the lack of cell density in a well.\n7.2 SINGLE-CELL RESOLUTION WITH TOKEN-LEVEL FEATURES\nNext, we delved deeper into examining a single feature direction, which we chose because it demonstrated a clear biological relationship. This feature is strongly correlated with gene knockouts from the adherens junctions pathway, a label from the functional gene perturbation group from Task (5) (\u00a7 5). The adherens junctions connect cell membranes to cytoskeletal elements and form cell-cell adhesions; they can be thought of as \"glue proteins\" that stick cells together to maintain tissue integrity."}, {"title": "8 CONCLUSION", "content": "In this paper we have explored the extent to which dictionary learning can be used to extract biologically-meaningful concepts from microscopy foundation models. The results are encouraging: with the right approach, we were able to extract sparse features that are associated with distinct and biologically-interpretable morphological traits. That said, these sparse features are clearly incomplete: we see significant drops in their linear-probing performance on tasks that involve more subtle changes in morphology. It is not clear to what extent this is a limitation of our current dictionary learning techniques, the scale of our models, or whether these more subtle changes are simply not represented linearly in embedding space. Nonetheless, it is clear that the choice of dictionary learning algorithm matters to extract meaningful features.\nWe also proposed a new dictionary learning algorithm, Iterative Codebook Feature Learning (ICFL), and the use of PCA whitening on a control dataset as a form of weak supervision for the feature extraction. In our experiments, we found that both ICFL and PCA significantly improve the selectivity of extracted features, compared to TopK sparse autoencoders. We hope that future work further explores the use of dictionary learning for scientific discovery, as well as the use of ICFL for other modalities like text."}, {"title": "A DISCUSSION: LINEAR CONCEPT DIRECTIONS IN VIT MAES", "content": "We have shown that DL is a powerful approach for finding linear concept directions (features) that are strongly correlated with biological concepts such as cell-types and genetic perturbations. From an interpretability perspective, a question that remains, however, is whether these correlations solely appear due to first order effects of complex non-linear structures used by the model to store abstract information, or whether linear directions are actually inherently meaningful to the model? While linear causal interventions offer strong evidence that the latter may indeed at least be partially true for large language models (see e.g.., (Ferrando et al., 2024) for an overview), there exists relatively little evidence for ViT MAEs besides the high linear probing accuracies on e.g., natural and microscopy image classification tasks Huang et al. (2022); Alkin et al. (2024).\nIn this section, we provide an argument further supporting the hypothesis that MAEs may rely on linear concept directions when processing data by analyzing at which point in the model are the concepts are the most linearly separable.\nSeparation into row- and nullspace. We note that standard MAE architectures (Huang et al., 2022) use two different embedding dimensions for the encoder block and the decoder block. Both blocks are connected via an encoder-decoder projection matrix $W : \\mathbb{R}^{d_e\\times d_d}$ with, in our case, $d_e = 1664$ (ViT-G model from (Zhai et al., 2022)) and $d_d = 512$. This projection matrix gives raise to a separation of the the tokens into the row-space and null space of $W$, $x = X_{row} + X_{null}$ where only the information stored in $x_{row}$ is passed to the decoder. ViTs and more generally transformer models have shown to align the basis across layers, allowing for decoding of tokens from intermediate layers (Alkin et al., 2024).\nWe visualize this behavior in Figure 6a where we show the reconstructions when using the tokens from intermediate layers. Thus, we observe that the row-space component $x_{row}$ of tokens from early and intermediate layers $x^{(l)}$ already store a reconstruction of the masked image that is refined over the layers. Thus the question appears what is the role of the null space component $X_{null}$ which won't be passed to the decoder and thus serves as a \"register\" (in analogy to Darcet et al. (2023))?\nComponent-wise linear probing We analyze in Figure 6b the different components, showing the relative linear probing accuracy of the probing accuracies using the null and row space components, compared to the entire token (dashed line at 1) across different layers. As observed, the null space component consistently yields the same probing accuracy as the entire token, while the row space component yields significantly lower accuracy. For comparison, we also show the relative probing accuracy when using a random $d_d$-dimensional subspace (the same dimension as the row space), which consistently yields higher accuracy than that obtained from the row space. These findings suggest that biological concepts (i.e., genetic perturbations) are most linearly separable in the component used only for internal processing during the forward pass and not passed to the decoder, and therefore aligns with the hypothesis that the model represents abstract concepts as linear directions accessed by the layers while processing the data Bricken et al. (2023)."}]}