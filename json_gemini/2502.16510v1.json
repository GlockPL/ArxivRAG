{"title": "Gaussian Process Regression for Improved\nUnderwater Navigation", "authors": ["Nadav Cohen", "Itzik Klein"], "abstract": "Accurate underwater navigation is a challenging\ntask due to the absence of global navigation satellite system\nsignals and the reliance on inertial navigation systems that suffer\nfrom drift over time. Doppler velocity logs (DVLs) are typically\nused to mitigate this drift through velocity measurements, which\nare commonly estimated using a parameter estimation approach\nsuch as least squares (LS). However, LS works under the\nassumption of ideal conditions and does not account for sensor\nbiases, leading to suboptimal performance. This paper proposes\na data-driven alternative based on multi-output Gaussian pro-\ncess regression (MOGPR) to improve DVL velocity estimation.\nMOGPR provides velocity estimates and associated measurement\ncovariances, enabling an adaptive integration within an error-\nstate Extended Kalman Filter (EKF). We evaluate our proposed\napproach using real-world AUV data and compare it against LS\nand a state-of-the-art deep learning model, BeamsNet. Results\ndemonstrate that MOGPR reduces velocity estimation errors\nby approximately 20% while simultaneously enhancing overall\nnavigation accuracy, particularly in the orientation states. Addi-\ntionally, the incorporation of uncertainty estimates from MOGPR\nenables an adaptive EKF framework, improving navigation\nrobustness in dynamic underwater environments.", "sections": [{"title": "I. INTRODUCTION", "content": "Underwater navigation is of great interest due to its potential\napplications and the challenges it presents. The underwater\ndomain imposes significant navigation challenges, primarily\nbecause the global navigation satellite system (GNSS) signals\ncannot penetrate water and thus cannot be used for global\nlocalization. Additionally, large robotic platforms are typically\nemployed due to extreme depths, high pressure, tempera-\nture variations, and low visibility. These platforms include\nautonomous underwater vehicles (AUVs), remotely operated\nvehicles (ROVs), and underwater gliders [1].\nUnderwater navigation systems commonly rely on an inertial\nnavigation system (INS) and a Doppler velocity log (DVL).\nThe INS estimates the navigation solution, namely the posi-\ntion, velocity, and orientation, in a global frame by integrating\nthe inertial measurements through dead-reckoning. However,\ndue to inherent stochastic errors and other error terms, this\nnavigation solution accumulates errors over time. A DVL\nis typically used to mitigate this drift. The DVL transmits\nacoustic beams toward the seabed and utilizes the Doppler\neffect to estimate the vehicle's velocity relative to the seabed.\nThis velocity information is then integrated into a nonlinear\nfiltering framework to correct the INS drift [2]. The most\ncommon nonlinear filters used in INS/DVL fusion are the\nextended Kalman filter (EKF) [3] and the unscented Kalman\nfilter (UKF) [4].\nIn a loosely coupled approach, the platform velocity vector\nfrom the DVL is obtained by applying a parameter estima-\ntion approach such as a least squares (LS) estimator to the\nraw beam measurements. Under Gaussian assumptions, LS\nis considered the best unbiased estimator, as it achieves the\nCram\u00e9r-Rao lower bound (CRLB). However, if the funda-\nmental assumptions are not met\u2014such as in the presence of\nbiases, the LS solution is no longer optimal, leaving room for\nimprovement [5].\nWith recent advancements in hardware and the growing in-\nterest in data-driven and deep learning applications, machine\nlearning methods have begun to be explored for inertial naviga-\ntion [6]. Specifically, in the context of INS/DVL fusion, some\ndata-driven approaches have started to emerge. Our previous\nwork, BeamsNet, introduced an end-to-end, one-dimensional\nconvolutional neural network model designed to replace the\nLS estimator for DVL velocity estimation [7]. In addition,\nBeamsNet was designed to handle scenarios where the DVL\nprovides only partial measurements due to environmental\nconditions [8], [9]. In [10], the authors introduced NavNet,\na neural network architecture that leverages a recurrent neural\nnetwork (RNN) combined with an attention mechanism and\nfully connected (FC) layers to estimate AUV displacement.\nVarious RNN-based models have been explored for underwater\nnavigation, including hybrid gated RNNs, which eliminate the\nneed for predefined motion models, thereby reducing mod-\neling errors commonly encountered in traditional navigation\nalgorithms. Other notable approaches include hybrid-RNN\n[11], long short-term memory (LSTM) networks [12], and\nposition estimation using RNNs [13]. Additionally, a radial\nbasis function-based neural network has been proposed for\nINS/DVL fusion [14]. More recently, [15] introduced a deep\nsequence learning-based virtual GPS model integrated into an\nEKF framework to enhance AUV navigation accuracy."}, {"title": "II. INS/DVL FUSION", "content": "The INS provides a complete navigation solution, including\nthe platform's position, velocity, and orientation, by per-\nforming dead-reckoning. This process involves integrating the\nspecific force measured by the accelerometer and the angular\nvelocity provided by the gyroscope to produce the navigation\nsolution. However, due to inherent errors such as sensor\nbiases and white noise, the integration is not optimal and\nresults in error accumulation over time. The DVL operates\nby transmitting acoustic beams toward the seabed. As its\nname suggests, it utilizes the Doppler effect and measures\nthe frequency shift of the returning signals to calculate the\nplatform's velocity relative to the seabed. The DVL provides\nvelocity measurements at a relatively low rate, typically around\n1 Hz, compared to the INS, which operates at 100 Hz.\nHowever, DVL measurements are significantly more accurate\nthan those provided by the INS. A nonlinear filter can be\nutilized to fuse data from these two sensors and achieve an\nimproved navigation solution. In our case, we have chosen\nto employ the EKF. The EKF effectively integrates the high-\nfrequency but drift-prone data from the INS with the low-\nfrequency yet highly accurate velocity measurements from the\nDVL, resulting in enhanced overall navigation accuracy and\nrobustness.\nTo formulate the INS/DVL sensor fusion, we define the error-\nstate vector as $d\u00e6 \u2208 R^{12\u00d71}$. The error-state dynamics are\ndescribed by the following equation:\n$\\delta \\dot{x} = F\\delta x + Gw$ (1)\nwhere $w \u2208 R^{12\u00d71}$ represents the system noise vector, $F \u2208\nR^{12\u00d712}$ denotes the system matrix, and $G \u2208 R^{12\u00d712}$ is the\nsystem noise distribution matrix. The system is subject to\nmultiple independent noise sources, each assumed to follow\na zero-mean Gaussian distribution. The error-state vector is\ndefined as:\n$\\delta x = [(\\delta v^n)^T \\quad (\\epsilon^n)^T \\quad {\\delta b_a}^T \\quad {\\delta b_g}^T ] \\in R^{12\u00d71}$ (2)\nIn this formulation:\n* $\\delta v^n \u2208 R^{3\u00d71}$ represents the velocity error-state in the\nnavigation frame\n* $\\epsilon \u2208 R^{3\u00d71}$ denotes the misalignment error\n* $\\delta b_a \u2208 R^{3\u00d71}$ corresponds to the accelerometer bias\nresidual error\n* $\\delta b_g \u2208 R^{3\u00d71}$ represents the gyroscope bias residual error\nWhile the INS operates and no DVL measurements are avail-\nable, the EKF remains in the prediction phase, where the a\npriori mean is defined as:\n$\\delta \\hat{x} = 0$ (3)\nNext, the state covariance is propagated using the known\nmodel, which, in this case, corresponds to the nonlinear\nequations of motion of the INS:\n$P_k^- = \\Phi_{k-1}P_{k-1}^+ \\Phi_{k-1}^T + Q_{k-1}$ (4)\nIn this context, $P_k^-$ represents the predicted state covariance\nat time k, while $P_{k-1}^+$ corresponds to the updated state\ncovariance from the previous time step k-1. The matrix $Q_{k\u22121}$\nrepresents the discrete process noise covariance, while the\ntransition matrix $\u03a6_{k-1}$ is typically obtained through a power-\nseries expansion of the system matrix F over the sampling\ninterval $T_s$.\nOnce DVL measurements are available, the EKF performs the\nupdate step, during which the state estimates are refined using\nthe following expressions:\n$K_k = P_k^- H_k^T(H_k P_k^- H_k^T + R_k)^{-1}$ (5)\n$P_k^+ = [I - K_k H_k]P_k^-$ (6)"}, {"title": "$\\delta \\hat{x}_k = K_k \\delta z_k$", "content": "$\\delta \\hat{x}_k = K_k \\delta z_k$ (7)\nIn these equations, $K_k$ denotes the Kalman gain, which\ndetermines the optimal weighting between new sensor data and\npredicted values from the system dynamics. The terms $H_k$ and\n$R_k$ refer to the observation matrix and the covariance of the\nmeasurement noise, respectively. Finally, $\\delta \\hat{x}_k$ represents the\ncorrected error-state estimate, while $P_k^+$ denotes the updated\nerror covariance matrix. All the variables mentioned above are\nwell-defined and can be found in the literature, for example,\nin [22], [23].\nTo incorporate velocity observations into the EKF model, it\nis essential to first analyze the geometric configuration of\nthe DVL's operation. The DVL is mounted within the AUV\nwith its transducers oriented toward the seabed. It employs an\n\"x\" pattern configuration, commonly referred to as the \"Janus\nDoppler configuration\" [24]. An illustration can be seen in\nFig.1. In this configuration, the transducers are positioned at\nspecific yaw and pitch angles relative to the DVL sensor's\nframe, which typically differs from the platform's body frame.\nThe relationship is given by:\n$b_i = [cos \\phi_i sin \\theta \\quad sin \\phi_i sin \\theta \\quad cos \\theta]_{1x3}$ (8)\nwhere $b_i$ (for $i = 1, 2, 3, 4$) corresponds to the beam number,\nand $\u03c6$ and $\u03b8$ represent the yaw and pitch angles relative to\nthe body frame. The pitch angle is predetermined by the\nmanufacturer and remains constant across all beams. The yaw\nangle, on the other hand, can be defined as follows:\n$\\psi_i = (i - 1) \u00b7 90\u00b0 + 45\u00b0, i = 1, 2, 3, 4$ (9)\nLet $v^{DVL}$ denote the velocity vector in the DVL frame, and\nlet $T$ be the transformation matrix that maps it to the beam-\naligned velocity vector $v^{Beam}$. This relationship is expressed\nas:\n$v^{Beam} = T v^{DVL}, T = \\begin{bmatrix} b_1\\\\ b_2\\\\ b_3\\\\ b_4 \\end{bmatrix}_{4x3}$ (10)\nThe beam measurements are affected by various errors, which\ncan be modeled as:\n$\\tilde{v}^{Beam} = T[v^{DVL}(1 + s_{DVL})] + b_{DVL} + n_{DVL}$ (11)\nwhere, $b_{DVL} \u2208 R^{4\u00d71}$ represents the bias vector, $s_{DVL} \u2208\nR^{3\u00d71}$ denotes the scale factor vector, and $n_{DVL} \u2208 R^{4\u00d71}$ is\nmodeled as zero-mean Gaussian noise. Once the raw measure-\nments are obtained, the velocity $v^{DVL}$ can be estimated by\nminimizing the following cost function:\n$\\hat{v}^{DVL} = argmin_{v^{DVL}} || \\tilde{v}^{Beam} - T v^{DVL} ||^2$. (12)\nThe solution to this least-squares problem is computed by\nmultiplying the measurements by the pseudo-inverse of the\ntransformation matrix $T$ [5]:\n$\\hat{v}^{DVL} = (T^T T)^{-1} T^T \\tilde{v}^{Beam}$. (13)\nThis outcome can be integrated into the EKF in a loosely\ncoupled manner [23]."}, {"title": "III. MULTI-OUTPUT GAUSSIAN PROCESS REGRESSION", "content": "Gaussian Process (GP) regression is a powerful non-parametric\nBayesian approach for modeling functions. Given a training set\ndefined as:\n$D = {(x_i, y_i) | i = 1,..., n}$ (14)\nwhere:\n* $x_i \u2208 R^D$ represents the input vector\n* $y_i \u2208 R$ is the corresponding output (target)\n* n denotes the number of observations\nThe entire training set can be represented in matrix form as:\n$D = (X, y),$ (15)\nwhere the design matrix X and the target vector y are defined\nas:\nX = \\begin{bmatrix}x_{11} & x_{12} & ... & x_{1D}\\\\x_{21} & x_{22} & ... & x_{2D}\\\\vdots & : & : & :\\\\x_{n1} & x_{n2} & ... & x_{nD}\\end{bmatrix}; y = \\begin{bmatrix}y_1\\\\y_2\\\\vdots\\\\y_n\\end{bmatrix} (16)\nThe objective in regression tasks is to infer the relationship\nbetween inputs and outputs by modeling the conditional\ndistribution $p(y | X)$, without explicitly modeling the input\ndistribution.\nA GP is fully defined by its mean function $m(x)$ and covari-\nance function $c(x, x')$, which together define the distribution\nover possible functions. Formally, for a real-valued function\n$f(x)$, the mean and covariance functions are given by:\n$m(x) = E[f(x)],$ (17)\n$c(x, x') = E[(f(x) \u2013 m(x))(f(x') \u2013 m(x'))].$ (18)\nThe Gaussian process is then expressed as:\n$f(x) \\sim GP(m(x), c(x, x')).$ (19)\nFor simplicity, the mean function is often assumed to be zero.\nIn machine learning applications, the random variables in a GP\nrepresent function values at different input locations. Unlike\nconventional parametric models, a GP defines a distribution"}, {"title": "IV. PROPOSED APPROACH", "content": "over functions without requiring an explicit functional form.\nInstead, it captures correlations between function values via\nthe covariance function $c(x, x')$.\nIn practice, function values are not directly observable and are\nsubject to added stochastic noise:\n$y = f(x) + \u03b5,$ (20)\nwhere $\u03b5 ~ N(0, \u03c3^2)$ represents Gaussian observation noise.\nGiven the training data $D = (X,y)$, and test locations $X_*$,\nthe joint distribution of observed and predicted values is:\n$\\begin{bmatrix} y \\\\ f_* \\end{bmatrix} \\sim N (0, \\begin{bmatrix} C(X, X) + \u03c3^2I & C(X, X_*)\\\\ C(X_*, X) & C(X_*, X_*) \\end{bmatrix})$ (21)\nwhere the predictive distribution $f_* = f(x_*)$ at $x_*$. Using\nstandard Gaussian conditioning rules, the predictive distribu-\ntion for test points is given by:\n$E[f_*|X, y] = C(X_*, X)[C(X, X) + \u03c3^2I]^{-1}y,$ (22)\n$cov(f_*) = C(X_*, X_*)\n\u2013 C(X_*, X) [C(X, X) + \u03c3^2I]^{-1}C(X, X_*).$ (23)\nIf there are n training points and $n_*$ test points, the ker-\nnel matrix $C(X,X_*)$ is an n\u00d7$n_*$ matrix that contains\nthe covariances computed for all pairs of training and test\npoints using the kernel function $c(,)$. The same notation\napplies to other kernel matrices $C(X, X), C(X_*, X_*)$, and\n$C(X_*, X)$, where C represents the kernel matrix and $c$ denotes\nthe underlying kernel function. Equations (22)-(23) form the\nfoundation of Gaussian process regression, enabling robust\nfunction approximation and uncertainty quantification [16],\n[17].\nExtending single-output GPR to MOGPR aims to model\nmultiple correlated outputs simultaneously while preserving\ndependencies across different input and output dimensions. In\norder to achieve this, separable kernels are used to decouple\nthe contributions of the input and output spaces. The kernel\nmatrix for a dataset X can then be written as:\n$C(X, X) = B \\otimes c(X, X)$ (24)\nwhere $\\otimes$ denotes the Kronecker product between matrices.\nThis formulation enhances computational efficiency by ex-\nploiting the structure of the covariance matrix. The simplest\ncase occurs when B is set as an identity matrix I, implying\nan assumption of independent outputs [25].\nOur proposed approach aims to provide a data-driven alter-\nnative to the LS solution, which is commonly used in the\nliterature and industry, for estimating velocity vector and its\nassociated variance. The motivation stems from the fact that\nDVL measurements are, in practice, subject to bias, even after\ncareful calibration. This bias renders the LS solution subopti-\nmal and inefficient. This inherent bias creates an opportunity\nfor improvement through a more robust modeling approach."}, {"title": "To apply the MOGPR framework to DVL velocity estimation,\nwe construct the training set as follows:\n$\\mathbb{D}_{DVL} = {(\\tilde{v}_i^{Beam}, v_i^{DVL}) | i = 1, ..., n},$ (25)\nwhere $v_i^{DVL}$ and $\\tilde{v}_i^{Beam}$ are defined in (10) and (11), re-\nspectively. The training set pairs beam velocity measurements\n$\\tilde{v}_i^{Beam}$ with their corresponding DVL velocities $v_i^{DVL}$, en-\nabling the model to learn the mapping between these variables.\nTo enhance the flexibility of the MOGPR model, we employ\na combination of three automatic relevance determination\n(ARD) kernels by adding them:\nThe ARD squared exponential kernel:\n$c(x_i, x_j|\\theta) = \u03c3_f^2 exp[-\\frac{1}{2} \\sum_{m=1}^4 \\frac{(x_{im} - x_{jm})^2}{\u03c3_m^2}]$ (26)\nThe ARD Mat\u00e9rn $\\frac{3}{2}$ kernel:\n$c(x_i, x_j|\\theta) = \u03c3_f^2 (1 + \\sqrt{3r}) exp(-\\sqrt{3r}),$\nr=\\sum_{m=1}^4 \\frac{(x_{im} - x_{jm})^2}{\u03c3_m^2}$ (27)\nwith the ARD rational quadratic kernel defined by:\n$c(x_i, x_j|\\theta) = \u03c3_f^2 (1 + \\frac{1}{2 \\alpha} \\sum_{m=1}^4 \\frac{(x_{im} - x_{jm})^2}{\u03c3_m^2})^{-1}$ (28)\nARD kernels allow the model to automatically determine\nthe relevance of each input feature by assigning individual\nlength scales $\u03c3_m$ to each input dimension. This capability\nmakes ARD kernels particularly effective for feature selection\nand dimensionality reduction, enabling the model to focus\non the most informative features while down-weighting less\nrelevant ones. Before being combined, each kernel is adjusted\nto the MOGPR framework according to (24), with B set\nas the identity matrix, as the outputs represent uncorrelated\nvelocities.\nNext, we construct a learnable variables vector $\u03b8 =$\\n{$\u03c3_f^2,..., \u03c3_m^2,..., \u03b1, \u03c3_n^2$}, which can be optimized by minimizing\nthe negative log-likelihood function $p(y | X, \u03b8)$. Further details\non this optimization process can be found in [16]. In this work,\nthe optimization was performed using gradient descent and\nthe ADAM optimizer, with a learning rate of 0.1 and first\nand second moment coefficients $\u03b2_1 = 0.9$ and $\u03b2_2 = 0.999$,\nrespectively, over 50 iterations [26].\nOnce the above steps are completed, the MOGPR solution,\ndefined by (22) and (23), is obtained and can be utilized in\na loosely coupled approach within the error-state EKF. More-\nover, the MOGPR provides uncertainty in the measurements,\nwhich can be used as an adaptive measurement noise matrix\n$R_k$, further enhancing the performance of the EKF. A block\ndiagram of the suggested approach is shown in Fig. 2."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "A sea experiment was conducted in the Mediterranean Sea\nusing an AUV to collect the data. Specifically, the \"Snapir\"\nAUV, a modified ECA Group A18D mid-size platform, was\nutilized. This AUV can autonomously execute missions at\ndepths of up to three kilometers with an endurance of 21\nhours. The inertial sensor employed in the AUV is the iXblue\nPhins Subsea INS [27], a navigation-grade INS, while the DVL\nused is the Teledyne RDI Workhorse Navigator [28]. Over\nseven hours of data were collected, from which 13 distinct\nmission scenarios were carefully selected for training and\ntesting the model. These missions are characterized by varying\nmaneuvers, speeds, depths, and other factors, providing a\nrobust representation of typical AUV tasks. Further details\nregarding the dataset are provided in [24]. Trajectories 12 and\n13 are used to test and evaluate the suggested approach and\ncan be seen in Fig.3."}, {"title": "VI. PERFORMANCE", "content": "The suggested approach was trained using eleven out of the\nthirteen trajectories. In addition to the proposed method, we\ncompared its performance against the LS estimator and another\ndata-driven approach named BeamsNet. BeamsNet is a deep\nlearning method based on a one-dimensional convolutional\nneural network, which has been shown to provide better\nestimations than the LS solution. Similar to the proposed\napproach, BeamsNet takes the beam velocity measurements\nas input but also includes past DVL measurements. Further\ndetails about BeamsNet, including its architecture, hyperpa-\nrameters, and implementation, can be found in [7].\nWe used the error model presented in (10) to create scenarios\nthat mimic inadequate calibration. A range of bias vectors was\nadded, starting from 0.001 [m/s] and increasing in increments\nof 0.002 [m/s] up to 0.011 [m/s]. Additionally, white noise\nwith a standard deviation of 0.02 [m/s] was included under\na zero scale factor assumption. First, the three approaches'\nroot mean squared error (RMSE) was calculated relative to\nthe ground truth data, and as a function of the added bias,\nthe results are summarized in Fig. 4. The results demonstrate\nthat the LS estimation error increases as the bias grows,\nwhereas both data-driven approaches maintain a relatively\nconstant estimation accuracy. For trajectory 12, with a bias\nof 0.011 [m/s], MOGPR and BeamsNet performed similarly,\nachieving an approximately 20% improvement over the LS\nestimation. In trajectory 13, BeamsNet outperformed MOGPR\nby a small margin while still providing a comparable improve-\nment relative to the LS method. A key advantage of MOGPR is\nthat it also provides the covariance, which can be dynamically"}, {"title": "13. The results show that both data-driven approaches, when\nintegrated into the EKF in a loosely coupled manner, outper-\nformed the LS method across all states. Additionally, when\ncomparing the norm of the RMSE vector across methods,\nfor trajectory 12, the MOGPR approach outperformed the\nLS by at least 25% in terms of velocity RMSE and at\nleast 42% in terms of angle RMSE. When compared to the\nsecond data-driven approach, BeamsNet, MOGPR achieved at\nleast a 15.8% improvement in velocity RMSE and at least a\n45% improvement in angle RMSE. The larger improvement\nin angle RMSE is primarily due to the yaw error, while\nBeamsNet slightly outperformed MOGPR in roll and pitch\nestimation. For trajectory 13, the data-driven approaches once\nagain outperformed the model-based LS approach across all\nstates. MOGPR showed at least a 13% improvement over LS", "content": "13. The results show that both data-driven approaches, when\nintegrated into the EKF in a loosely coupled manner, outper-\nformed the LS method across all states. Additionally, when\ncomparing the norm of the RMSE vector across methods,\nfor trajectory 12, the MOGPR approach outperformed the\nLS by at least 25% in terms of velocity RMSE and at\nleast 42% in terms of angle RMSE. When compared to the\nsecond data-driven approach, BeamsNet, MOGPR achieved at\nleast a 15.8% improvement in velocity RMSE and at least a\n45% improvement in angle RMSE. The larger improvement\nin angle RMSE is primarily due to the yaw error, while\nBeamsNet slightly outperformed MOGPR in roll and pitch\nestimation. For trajectory 13, the data-driven approaches once\nagain outperformed the model-based LS approach across all\nstates. MOGPR showed at least a 13% improvement over LS"}, {"title": "Next, the velocity estimation values from each approach were\nintegrated into the error-state EKF as measurement updates.\nFor the proposed MOGPR-based approach, the estimated\ncovariance was also incorporated as adaptive measurement\nnoise covariance. The standard deviation of each method's\nmeasurement noise matrix $R_k$ is shown in Fig. 5, illustrating\nhow MOGPR can adaptively adjust its prediction uncertainty,\nwhereas, in the other approaches, it remains constant and\npredefined. The reason the measurement noise in the LS\napproach remains constant is due to the linear nature of the\ntask and the constant transformation matrix in (10). For the\nBeamsNet approach, the uncertainty decreases, resulting in a\nconstant but smaller noise value. The MOGPR also provides\nthe smallest standard deviation over time.\nSix states were observed for comparison: velocity in the north,\neast, and down directions within the navigation frame, as well\nas roll, pitch, and yaw angles transforming from the body\nframe to the navigation frame. The RMSE of each state is", "content": "Next, the velocity estimation values from each approach were\nintegrated into the error-state EKF as measurement updates.\nFor the proposed MOGPR-based approach, the estimated\ncovariance was also incorporated as adaptive measurement\nnoise covariance. The standard deviation of each method's\nmeasurement noise matrix $R_k$ is shown in Fig. 5, illustrating\nhow MOGPR can adaptively adjust its prediction uncertainty,\nwhereas, in the other approaches, it remains constant and\npredefined. The reason the measurement noise in the LS\napproach remains constant is due to the linear nature of the\ntask and the constant transformation matrix in (10). For the\nBeamsNet approach, the uncertainty decreases, resulting in a\nconstant but smaller noise value. The MOGPR also provides\nthe smallest standard deviation over time.\nSix states were observed for comparison: velocity in the north,\neast, and down directions within the navigation frame, as well\nas roll, pitch, and yaw angles transforming from the body\nframe to the navigation frame. The RMSE of each state is"}, {"title": "in velocity RMSE and at least an 18% improvement in angle\nRMSE. When comparing MOGPR to BeamsNet, BeamsNet\nslightly outperformed MOGPR in both velocity and angle\nRMSE for this trajectory.", "content": "in velocity RMSE and at least an 18% improvement in angle\nRMSE. When comparing MOGPR to BeamsNet, BeamsNet\nslightly outperformed MOGPR in both velocity and angle\nRMSE for this trajectory."}, {"title": "In this work, we leveraged the capabilities of GPR and,\nthrough a MOGPR, estimated the AUV velocity using raw\nDVL measurements as an alternative to the LS approach. The\nMOGPR not only provides velocity estimates but also yields\nan adaptive covariance that reflects the model's confidence\nin its predictions. This covariance was incorporated as the\nmeasurement noise covariance matrix in the update phase of\nthe error-state EKF, enabling an adaptive EKF framework for\na complete AUV navigation solution. The results show that,\nbeyond improving the velocity estimation by approximately\n20%, MOGPR also enhances the overall navigation solution\nwithin the EKF, leading to improvements in other states, such\nas orientation angles. Additionally, MOGPR outperformed\nBeamsNet in most state estimations.", "content": "In this work, we leveraged the capabilities of GPR and,\nthrough a MOGPR, estimated the AUV velocity using raw\nDVL measurements as an alternative to the LS approach. The\nMOGPR not only provides velocity estimates but also yields\nan adaptive covariance that reflects the model's confidence\nin its predictions. This covariance was incorporated as the\nmeasurement noise covariance matrix in the update phase of\nthe error-state EKF, enabling an adaptive EKF framework for\na complete AUV navigation solution. The results show that,\nbeyond improving the velocity estimation by approximately\n20%, MOGPR also enhances the overall navigation solution\nwithin the EKF, leading to improvements in other states, such\nas orientation angles. Additionally, MOGPR outperformed\nBeamsNet in most state estimations."}, {"title": "While data-driven approaches hold promise for real-time sys-\ntems requiring reliability, their limitations are well known.\nMOGPR requires storing the entire training set and involves\ninverting a high-dimensional matrix, which is computationally\nexpensive. These challenges and the necessity of acquiring\nsufficiently generalized and high-quality training data must be\naddressed before these methods can be fully integrated into\nreal-time navigation systems.", "content": "While data-driven approaches hold promise for real-time sys-\ntems requiring reliability, their limitations are well known.\nMOGPR requires storing the entire training set and involves\ninverting a high-dimensional matrix, which is computationally\nexpensive. These challenges and the necessity of acquiring\nsufficiently generalized and high-quality training data must be\naddressed before these methods can be fully integrated into\nreal-time navigation systems."}, {"title": "VII. CONCLUSIONS", "content": "AUVs are typically required to conduct long-duration missions\nat depths beyond human reach. Although these platforms\nare equipped with high-end sensors, they must be carefully\ncalibrated to achieve optimal performance. However, such\ncalibrations are often challenging to perform and, in some\ncases, are neglected. Even with meticulous calibration, sensors\nare never entirely bias-free. When this occurs, the model-\nbased LS estimation is no longer, by definition, an optimal\nestimator, leaving room for improvement. In the case of\nDVL velocity estimation, the previously proposed data-driven\nmodel, BeamsNet, has demonstrated the potential to achieve\nsuch improvements.\nIn this work, we leveraged the capabilities of GPR and,\nthrough a MOGPR, estimated the AUV velocity using raw\nDVL measurements as an alternative to the LS approach. The\nMOGPR not only provides velocity estimates but also yields\nan adaptive covariance that reflects the model's confidence\nin its predictions. This covariance was incorporated as the\nmeasurement noise covariance matrix in the update phase of\nthe error-state EKF, enabling an adaptive EKF framework for\na complete AUV navigation solution. The results show that,\nbeyond improving the velocity estimation by approximately\n20%, MOGPR also enhances the overall navigation solution\nwithin the EKF, leading to improvements in other states, such\nas orientation angles. Additionally, MOGPR outperformed\nBeamsNet in most state estimations.\nWhile data-driven approaches hold promise for real-time sys-\ntems requiring reliability, their limitations are well known.\nMOGPR requires storing the entire training set and involves\ninverting a high-dimensional matrix, which is computationally\nexpensive. These challenges and the necessity of acquiring\nsufficiently generalized and high-quality training data must be\naddressed before these methods can be fully integrated into\nreal-time navigation systems."}]}