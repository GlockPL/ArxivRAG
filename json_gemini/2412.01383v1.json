{"title": "Second FRCSyn-onGoing: Winning Solutions and Post-Challenge Analysis to Improve Face Recognition with Synthetic Data", "authors": ["Ivan DeAndres-Tame", "Ruben Tolosana", "Pietro Melzi", "Ruben Vera-Rodriguez", "Minchul Kim", "Christian Rathgeb", "Xiaoming Liu", "Luis F. Gomez", "Aythami Morales", "Julian Fierrez", "Javier Ortega-Garcia", "Zhizhou Zhong", "Yuge Huang", "Yuxi Mi", "Shouhong Ding", "Shuigeng Zhou", "Shuai He", "Lingzhi Fu", "Heng Cong", "Rongyu Zhang", "Zhihong Xiao", "Evgeny Smirnov", "Anton Pimenov", "Aleksei Grigorev", "Denis Timoshenko", "Kaleb Mesfin Asfaw", "Cheng Yaw Low", "Hao Liu", "Chuyi Wang", "Qing Zuo", "Zhixiang He", "Hatef Otroshi Shahreza", "Anjith George", "Alexander Unnervik", "Parsa Rahimi", "S\u00e9bastien Marcel", "Pedro C. Neto", "Marco Huber", "Jan Niklas Kolf", "Naser Damer", "Fadi Boutros", "Jaime S. Cardoso", "Ana F. Sequeira", "Andrea Atzori", "Gianni Fenu", "Mirko Marras", "Vitomir \u0160truc", "Jiang Yu", "Zhangjie Li", "Jichun Li", "Weisong Zhao", "Zhen Lei", "Xiangyu Zhu", "Xiao-Yu Zhang", "Bernardo Biesseck", "Pedro Vidal", "Luiz Coelho", "Roger Granada", "David Menotti"], "abstract": "Synthetic data is gaining increasing popularity for face recognition technologies, mainly due to the privacy concerns and challenges associated with obtaining real data, including diverse scenarios, quality, and demographic groups, among others. It also offers some advantages over real data, such as the large amount of data that can be generated or the ability to customize it to adapt to specific problem-solving needs. To effectively use such data, face recognition models should also be specifically designed to exploit synthetic data to its fullest potential. In order to promote the proposal of novel Generative AI methods and synthetic data, and investigate the application of synthetic data to better train face recognition systems, we introduce the 2nd FRCSyn-onGoing challenge, based on the 2nd Face Recognition Challenge in the Era of Synthetic Data (FRCSyn), originally launched at CVPR 2024. This is an ongoing challenge that provides researchers with an accessible platform to benchmark i) the proposal of novel Generative AI methods and synthetic data, and ii) novel face recognition systems that are specifically proposed to take advantage of synthetic data. We focus on exploring the use of synthetic data both individually and in combination with real data to solve current challenges in face recognition such as demographic bias, domain adaptation, and performance constraints in demanding situations, such as age disparities between training and testing, changes in the pose, or occlusions. Very interesting findings are obtained in this second edition, including a direct comparison with the first one, in which synthetic databases were restricted to DCFace and GANDiffFace.", "sections": [{"title": "I. INTRODUCTION", "content": "Face biometrics is a very popular area within Computer Vision and Pattern Recognition, finding applications across various domains such as person recognition [1], [2], healthcare [3], [4], and e-learning [5], among others. In recent years, with the fast development of deep learning, significant ad- vances have been made in areas like face recognition (FR) [6], [7], surpassing previous benchmarks. However, FR tech- nology still faces challenges in several research directions, including explainability [8]\u2013[10], demographic bias [11], [12], privacy [13]\u2013[15], and robustness against adverse conditions [7], such as aging [16], pose variations [17], [18], illumination changes [19], and occlusions [20].\nSynthetic data has gained popularity as a good solution to mitigate some of these drawbacks [22], [23], allowing the generation of i) a large number of facial images from different"}, {"title": "II. SECOND FRCSYN-ONGOING: DATABASES", "content": "One of the main novelties of the 2nd FRCSyn-onGoing is that there are no restrictions in terms of the generative methods used to create synthetic data. Unlike the 1st FRCSyn- onGoing, where only synthetic data created using DCFace [28] and GANDiffFace [21] was available, in this 2nd edition we allow participants to use any generative framework of their choice to create synthetic data, limiting in some sub-tasks the number of synthetic face images used to train the FR systems (more details in Section III-A). As a reference, after the registration in the challenge, we provide all the participants with a list of possible state-of-the-art generative frameworks. For completeness, we summarize next and in Table I the most popular approaches available at the beginning of the challenge:\n\u2022 DCFace4 [28]: This framework is entirely based on Diffusion models, composed of a sampling stage for the generation of synthetic identities XID, and a mixing stage for the generation of images XID,sty with the same identities XID from the sampling stage and the style selected from a \u201cstyle bank\u201d of images Xsty\n\u2022 GANDiffFace [21]: This framework combines Style- GAN [38] and a Diffusion Model, i.e., DreamBooth [39], to generate fully synthetic FR databases with desired properties such as human face realism, controllable de- mographic distributions, and realistic intra-class varia- tions (e.g., changes in pose, expression, and occlusions). Graphical examples are shown in Figure 1.\n\u2022 IDiff-Face [29]: This framework uses a Diffusion Model conditioned on identity context, which allows the model to either generate variations of existing authentic images by using authentic embeddings or to generate novel syn- thetic identities by using synthetic face embeddings. The authors presented two distinct datasets: one by generating identity context in a two-stage process, and the other through a synthetic uniform representation.\n\u2022 DigiFace-1M7 [31]: This framework can generate large- scale synthetic face images with many unique subjects based on 3D parametric model rendering. It considers the method introduced by Wood et al. [40], tackling the ethical and labeling problems associated with the generation of synthetic data.\n\u2022 ID3PM [30]: This framework considers a Diffusion Model to perform an inversion of a FR model gen- erating new images from Gaussian noise with various backgrounds, lighting, poses, and expressions while pre- serving the identity.\n\u2022 SFace [27]: This framework uses a conditional GAN to synthetically generate face images with an adaptive discriminator augmentation to increase the diversity of the training database.\n\u2022 SYNFace [26]: This framework uses DiscoFace- GAN [41] to generate face images with different identities from a Mixup Face Generator.\n\u2022 ITI-GEN10 [32]: This framework uses CLIP [33] to generate embeddings to translate the visual attribute dif- ferences into natural language differences and perform a Text-to-Image generation that is inclusive.\nThese are just some possible generative frameworks, with the corresponding synthetic databases available, that can be used by participants. But, as indicated before, the purpose of the 2nd FRCSyn-onGoing is to promote the proposal of novel generative methods and the creation of better synthetic databases to improve the performance of FR systems. It is important to mention that in the 2nd FRCSyn-onGoing, synthetic data is exclusively used in the training stage of FR technology, replicating realistic operational scenarios."}, {"title": "III. SECOND FRCSYN-ONGOING: SETUP", "content": "Due to the success of the 1st FRCSyn-onGoing [34], [35], we also decided to run the 2nd edition in Codalab\u00b9\u00b9, an open- source framework designed for conducting scientific competi- tions and benchmarks. On this platform, participants can find the competition's requirements and limitations and can submit their scores to automatically obtain i) the evaluation metrics of their system, and ii) the position on the challenge leaderboard."}, {"title": "A. Tasks", "content": "Similar to the 1st FRCSyn-onGoing [34], [35], in this 2nd edition we also explore the application of synthetic data for training FR systems, with a specific focus on addressing two critical aspects in current FR technology: i) mitigating de- mographic bias, and ii) enhancing overall performance under challenging conditions that include variations in age and pose, the presence of occlusions, and diverse demographic groups. To investigate these two areas, we consider two different tasks, each comprising three sub-tasks. Each sub-task considers different types (real/synthetic) and amounts of data for training the FR systems. Consequently, the 2nd edition comprises 6 different sub-tasks. We summarize in Table III the key aspects of the experimental protocol, metrics, and restrictions for each sub-task.\nTask 1: The first task focuses on using synthetic data to mitigate demographic biases within FR systems. To evaluate the performance of these systems, we create sets of mated and non-mated comparisons using subjects from the BUPT- BalancedFace database [43]. We consider the eight demo- graphic groups defined in Section II-B, which result from the combination of four ethnicities (White, Black, Asian, and In- dian) and two genders (Male and Female), ensuring a balanced representation across these groups in the comparison lists. For non-mated comparisons, we exclusively pair subjects within the same demographic group, as these hold greater relevance compared to non-mated comparisons involving subjects from different demographic groups.\nTask 2: The second proposed task focuses on using synthetic data to enhance the overall performance of FR sys- tems under challenging conditions. To assess the effectiveness of the proposed systems, we use lists of mated and non-mated comparisons selected from subjects from the different evaluation databases, each one designed to address specific challenges in FR. Specifically, BUPT-BalancedFace is used to consider diverse demographic groups, whereas AgeDB, CFP- FP, and ROF to assess age, pose, and occlusion challenges respectively."}, {"title": "B. Experimental protocol", "content": "Training: The six sub-tasks introduced in the 2nd FRCSyn-onGoing are mutually independent. This implies that participants have the flexibility to participate in any number of sub-tasks based on their preferences. For each selected sub-task, participants are required to develop a FR system and train it twice: i) using the authorized real databases"}, {"title": "C. Evaluation Metrics", "content": "We evaluate the FR systems using a protocol based on lists of mated and non-mated comparisons for each sub- task and database. From the scores and thresholds provided by participants, we calculate the binary decision and the verification accuracy. Additionally, we calculate the gap to real (GAP) [28] as follows: GAP = (REAL \u2013 SYN) /SYN, with REAL representing the verification accuracy of the baseline system and SYN the verification accuracy of the proposed system, trained with synthetic (or real + synthetic) data. Other metrics such as False Non-Match Rate (FNMR) at a fixed operational point, or the Area Under the ROC Curve which are very popular for the analysis of FR systems in real-world applications, are also computed from the scores provided by participants. Next, we explain how participants are ranked in the different tasks.\nTask 1: To rank participants and determine the winners of Sub-Tasks 1.1, 1.2, and 1.3, we closely examine the trade- off between the average (AVG) and standard deviation (SD) of the verification accuracy across the eight demographic groups defined in Section II-B. We define the trade-off metric (TO) as follows: TO = AVG - SD. This metric involves plotting the average accuracy on the x-axis and the standard deviation on the y-axis in a 2D space. Multiple 45-degree parallel lines are drawn to identify the winning team, whose performance is located on the far right of these lines. With this proposed metric, we reward FR systems that achieve good"}, {"title": "D. Restrictions", "content": "Participants have the freedom to choose the FR system for each task as long as the number of Floating Point Operations Per Second (FLOPs) of the system does not exceed 50 GFLOPs. This threshold has been established to facilitate the exploration of innovative architectures and encourage the use of diverse models while preventing the dominance of excessively large models. Participants are also free to use their preferred training modality, with the requirement that only the specified databases are used for training. Generative models cannot be used to generate supplementary data. Participants are allowed to use non-face databases for pre-training purposes and use traditional data augmentation techniques using the authorized training databases. To maintain the integrity of the evaluation process, the organizers reserve the right to disqualify participants if anomalous results are detected or if participants fail to adhere to the challenge's rules."}, {"title": "IV. SECOND FRCSYN-ONGOING: SYSTEMS DESCRIPTION", "content": "In this 2nd FRCSyn-onGoing, we encourage participants to propose novel Generative AI methods for the creation of synthetic data. Besides, we also give participants the freedom to choose the FR architecture and training methods. Table IV summarizes for each team the key information in terms of the proposed synthetic data and FR system. Teams are arranged by their average ranking in the 6 sub-tasks from the 2nd FRCSyn-onGoing. In general, we can see that most teams have decided to use synthetic data from DCFace [28] and IDiff-Face [29] databases, improving also the original data through cleaning and selection approaches, among other more sophisticated techniques. Also, regarding the FR technologies, most of them are based on ResNet [36] and IResNet [48] architectures, with AdaFace [7] and ArcFace [6] as the main used losses. However, some teams proposed their own methods to generate synthetic facial images, as well as to train their FR models. Next, we describe the specific details of the top-11 proposed systems in the 2nd FRCSyn-onGoing.\nADMIS (All sub-tasks): This team comprises members from Fudan University and Tencent Youtu Lab, China. They used a Latent Diffusion Model (LDM) [49] based on IDiff- Face [29] to synthesize faces. The LDM was conditioned"}, {"title": "V. SECOND FRCSYN-ONGOING: RESULTS", "content": "Next, we describe in Sections V-A and V-B the main results achieved in Tasks 1 and 2, respectively. These results are further analyzed in Section V-C focusing on specific demographic groups and individual databases. Finally, we discuss in Section V-D common trends among the different"}, {"title": "A. Task 1: Bias Mitigation", "content": "Table VI shows the results achieved by participants in Task 1, focused on demographic bias mitigation. Teams are ranked by descending order of TO, which tends to correlate to the ascending order of SD (i.e., from less to more biased FR systems). Notably, the winner of Sub-Tasks 1.1 and 1.2, ID R&D (96.73% TO), demonstrates a significant negative GAP value (-5.31%), showing a higher performance when training the FR system with synthetic data compared to real data (i.e., CASIA-WebFace [42]). Furthermore, in Sub-Task 1.1, we can observe that teams with negative GAP values considered Diffusion Models for the generation of synthetic data (i.e., ID R&D uses HDT, SRCN_AIVL combines DCFace and IDiff-Face, and CTAI combines DCFace and GANDiffFace), showing that this generation method may work better than real data in scenarios with limited data. Next, after removing the limitation on the number of synthetic images (i.e., Sub-Task 1.2), the TO value of most FR systems increases, which leads to performance and fairness improvement simultaneously. For instance, for the ADMIS team (ranked top-2 in both Sub- Task 1.1 and 1.2), the TO value increases to 95.72% in Sub- Task 1.2 (i.e., 1.42% TO improvement compared to Sub- Task 1.1). Also, the GAP value decreases from 1.47% to 0.56%, obtaining better results when increasing the amount of synthetic data in comparison to limited real data (i.e., CASIA- WebFace). Another example is the OPDAI team, which raised from top-4 to top-3 positions between Sub-Task 1.1 and 1.2. Its TO value increases to 94.12% (i.e., 0.37% TO improvement from Sub-Tasks 1.1 to 1.2), and the GAP value is reduced from 1.02% to 0.71%. These findings emphasize the potential of generating large number of synthetic face images from different demographic groups to mitigate bias in existing FR technology. Finally, we analyze in Sub-Task 1.3 the case of using both, real and synthetic data, in the FR training process. In general, we can observe considerable improvements in"}, {"title": "B. Task 2: Overall Improvement", "content": "Table VII provides the results achieved by participants in Task 2, focusing not only on bias mitigation but also other challenges in FR such as age, pose, and occlusions. Teams are ranked in descending order based on the average verification accuracy across the four databases. Notably, in all sub-tasks, the AVG is lower than the achieved in Task 1 for the BUPT- BalancedFace [43] database, showing the additional challenges introduced by the AgeDB [44], CFP-FP [45], and ROF [46] databases. This trend can also be observed in GAP results, which tend to be worse for Sub-Tasks 2.1 and 2.2 compared to Sub-Tasks 1.1 and 1.2, suggesting that it is far more difficult"}, {"title": "C. Demographic Groups and Evaluation Databases", "content": "This section provides an in-depth analysis of the results in terms of the different demographic groups and individual databases considered in the 2nd FRCSyn-onGoing. Figure 12 shows the Detection Error Tradeoff (DET) curves of Sub- Tasks 1.1, 1.2, and 1.3, including the results achieved for the top-1 team in each demographic group. For completeness, the information and graphical representations for all the teams can be found on the challenge Codalab platform12.\nFor Sub-Tasks 1.1 and 1.2, the team that achieves the first place, ID R&D, demonstrates high performance across the different demographic groups considered (above 96.50% Accuracy for all demographic groups). However, a slight gender bias can be observed (improvements of \u22481% between 'Male' and 'Female' labels for some ethnicities). Regarding the ethnicity, the proposed FR model showed better results for subjects from the 'Indian' ethnicity (99.20% Accuracy for Indian Male; 98.10% Accuracy for Indian Female). Finally, for Sub-Task 1.3, the winning team, ADMIS, also performs well across all demographic groups (all above 96% Accuracy). However, there exists variability in performance between dif- ferent demographic groups. For example, 'Asian Females' and 'Indian Females' have the lowest Accuracy (96.20%) while 'White Females' have the highest Accuracy (98.60%)."}, {"title": "D. Post-Challenge Analysis and Comparison with 1st Edition", "content": "Analyzing the contributions of all eleven top teams, we can observe the prevalence of well-established methodologies. Notably, most teams used DCFace [28] either independently or in conjunction with other synthetic databases such as GANDiffFace [21], DigiFace-1M [31], or IDiff-Face [29]. Fur- thermore, several teams, including CTAI and CBSR-Samsung, adopted interesting approaches involving synthetic data clean- ing and selection. It is interesting to highlight the ID R&D and Idiap-SynthDistill teams as they considered novel methods to generate synthetic data. Specifically, the ID R&D team used an HDT [54] to generate synthetic facial images along with identity and style embeddings, wich were used by a Style-NAT [56] model to generate more variability in the synthetic data. Another example is the Idiap-SynthDistill team, which proposed an end-to-end method that dynamically generated facial images through StyleGAN2 [62] and trained a FR model through model distillation. Regarding the backbone architec- ture, all teams opted for either ResNet [36] or IResNet [48], mainly for their widespread adoption in state-of-the-art FR methodologies. The selection of the loss functions was also similar among the teams, with AdaFace [7] and ArcFace [6] the prevalent choices. Nevertheless, there were exceptions such as for the ID R&D team that used the recent UniFace [58], or the UNICA team that considered CosFace [61].\nFinally, we compare the results achieved in the 2nd FRCSyn- onGoing with the results of the 1st edition [34]. Table VIII shows the best results achieved in the 1st and 2nd editions of the challenge, including also the GAP values. It is important to remark that Sub-Tasks 1.2 and 2.2 of the 2nd FRCSyn-onGoing are not included in the analysis as they are novel sub-tasks only available in the 2nd edition. Notably, two observations can be made: i) the main metric for ranking teams (i.e., TO and AVG) shows improvements across all cases in this 2nd edition for both Task 1 (e.g., 96.73% vs. 92.25% TO in Sub- Task 1.1 and 96.50% vs. 95.25% TO in Sub-Task 1.3) and Task 2 (e.g., 91.93% vs. 90.50% AVG in Sub-Task 2.1 and 95.42% vs. 94.95% AVG in Sub-Task 2.3), and ii) in terms of the GAP value, the FR models of this 2nd edition follow a similar"}, {"title": "VI. CONCLUSION", "content": "The 2nd FRCSyn-onGoing has presented a comprehensive exploration of the applications of synthetic data in FR, ef- fectively addressing existing limitations in the field. In this 2nd edition, two additional sub-tasks have been introduced, showing that impressive results can be achieved using un- limited synthetic data, even outperforming in some cases the scenario of training with only real data. With an increased number of participants in this last edition, we have witnessed a considerable performance improvement in all sub-tasks in comparison to the 1st edition [34], [35]. This has been possible thanks to the proposal of novel methods to generate and select better synthetic data, as well as FR models and loss functions. These approaches can be compared across a variety of sub- tasks, with many being reproducible thanks to the materials made available by the participating teams.\nFuture studies will include recent AI techniques [80], to make sure that only the databases available by the challenge are used by participants. We will also perform a more detailed analysis of the results and comparison with recent challenges in the topic, such as SDFR [81], or evaluate over a more diverse set of databases that include other FR challenges, like quality, surveillance, or large distance images [82]. Finally, we plan to focus on the explainability of these FR models and the frameworks that generate synthetic images [8]. Debi- asing face recognition models using synthetic datasets is an important task and in this challenge, we found that the use of synthetic data can furhter increase the performance. However, the concept of \"bias\" itself is complex and often subjective. What constitutes a \"fair\" representation can vary significantly depending on cultural context, individual experiences, and even personal beliefs. Therefore, debiasing efforts should be approached with an accurate understanding of the multifaceted nature of bias. Simply generating synthetic data to reflect a particular demographic distribution might not fully address the complexities of real-world inequalities. Rather than seeking to eliminate bias, perhaps a more productive approach is to pur- sue research in the direction of transparency, interpretability, and controllability. This translates to research questions that allow researchers to easily define what bias should be and allow them to fine-tune their models accordingly. Ultimately, the goal should be to develop face recognition systems that are not only accurate but also fair and ethical."}]}