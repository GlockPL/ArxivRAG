{"title": "Evolving Neural Networks Reveal Emergent Collective\nBehavior from Minimal Agent Interactions", "authors": ["G. S. Y. Giardini", "J. F. Hardy II", "C. R. da Cunha"], "abstract": "Understanding the mechanisms behind emergent behaviors in multi-agent systems\nis critical for advancing fields such as swarm robotics and artificial intelligence.\nIn this study, we investigate how neural networks evolve to control agents' be-\nhavior in a dynamic environment, focusing on the relationship between the net-\nwork's complexity and collective behavior patterns. By performing quantitative\nand qualitative analyses, we demonstrate that the degree of network non-linearity\ncorrelates with the complexity of emergent behaviors. Simpler behaviors, such\nas lane formation and laminar flow, are characterized by more linear network op-\nerations, while complex behaviors like swarming and flocking show highly non-\nlinear neural processing. Moreover, specific environmental parameters, such as\nmoderate noise, broader field of view, and lower agent density, promote the evo-\nlution of non-linear networks that drive richer, more intricate collective behaviors.\nThese results highlight the importance of tuning evolutionary conditions to induce\ndesired behaviors in multi-agent systems, offering new pathways for optimizing\ncoordination in autonomous swarms. Our findings contribute to a deeper under-\nstanding of how neural mechanisms influence collective dynamics, with implica-\ntions for the design of intelligent, self-organizing systems.", "sections": [{"title": "1. Introduction", "content": "Many physical systems display properties that are absent in their components.\nFrom the atomic level [1] to the biological [2] and social realms [3], we see count-\nless examples of systems exhibiting emergent properties [4, 5]. This concept also\napplies to artificial environments like cities where the interactions of countless\nindividuals result in a dynamic structure that grows, consumes energy, and con-\ntinually reshapes itself [6]. Understanding these natural and social examples of\nemergence can inform the design of artificial systems with practical applications.\nFor instance, drones used in search and rescue missions, environmental monitor-\ning, or disaster management must coordinate effectively while avoiding collisions\n[7]. By applying our understanding of emergent behavior, we can design agents\nthat self-organize and adapt in dynamic environments, forming a collective intel-\nligence [8].\nSeveral approaches model emergent behaviors in multi-agent systems. Early\nattempts, for example, introduce a polarized motion to point-like agents that in-\nteract with their neighbors according to fixed rules [9]. The consecrated Vicsek\nmodel [10], on the other hand, uses the alignment with nearest neighbors as a fun-\ndamental rule. Other attempts rely on game theoretical strategies as an approach\nfor collective emergence [11, 12].\nFinding the minimal and primitive set of interaction rules capable of produc-\ning emergent behavior, however, is a challenging task. In most existing models,\nthe interaction is given a priori without explaining if these rules form a minimal\nor primitive set [9]. This limitation is sometimes solved via reinforcement learn-\ning techniques [13] where agents learn optimal behaviors by adjusting strategies\ndepending on rewards and penalties provided by their environment. This pro-\ncess can lead to agents that eventually develop coordinated collective behavior.\nHowever, reinforcement learning usually requires precise knowledge about the\nenvironment. Moreover, the search space in natural systems can be huge, which\nlimits exploration [14].\nEvolutionary programming is a competing strategy where collective dynamics\narise naturally. Under evolutionary pressure, agents pass their most adapted fea-\ntures to offspring through reproduction and mutation [15, 16]. These and similar\napproaches are often complex, making heuristic analysis complicated [17].\nOur objective in this work is to investigate minimal and primitive conditions\nthat lead to collective and spontaneous self-organization in decentralized systems.\nFor this, we draw inspiration from natural processes [18, 19, 20] and propose a\nmodel of minimally intelligent agents endowed with explainable shallow neural"}, {"title": "2. Computational Methods", "content": "Our model is formalized by the tuple v = (N, X, L, L, N, N, 8, Rcol, \u03c6,\u03c9,\u03c6), where N is the number of agents in the system, X = {X1,X2,...,x} is the set\nof positions of the agents. Each position x\u00a1(t) \u2208 L, where L C Z2 is a finite\nL \u00d7 L lattice. N = {n1, n2,...,nv} is a set of shallow neural networks [28, 29, 30]\nwhose outputs give the directions the polarized agents move. These neural net-\nworks mimic some level of intelligence found in most complex living organisms\n[31]. Even some cells, the biological units of life, have been shown behaviors\nanalogous to intelligence [32]. N = {1,2,\u2026\u2026\u2026, y6} is a ranked metric neighbor-\nhood consisting of the 6 nearest neighbors. For a metric function d, and positions\n\u00a51<i<6 around x, d(x,y1) < d(x,y2) < ... < d(x,y6). This is based on the fact\nthat many animals interact with a fixed number of neighbors rather than with all\nneighbors within an interaction radius [33, 34, 35, 36], for birds the number of\nnearest neighbors was verified to be 6 ~ 7 [37]."}, {"title": "3. Results", "content": "The overall fitness indicates how well the agents are evolutionarily adjusted\nto the environment, showing a progressive increase, as depicted in Fig. 2. The\nshared fitness, however, is defined as the overall fitness normalized by the com-\nplement of the average distance between the neural networks in parameter space.\nIf evolution leads to an increase in overall fitness at the cost of declining diversity,\nthe shared fitness decreases. The shared fitness increases at the beginning of the\ntraining process but eventually saturates, indicating the homogenization of agents\n(homogeneity phase). Shared fitness makes more diverse agents more likely to be"}, {"title": "3.2. Emerging Patterns", "content": "Incorporating collision avoidance was essential for observing the emergence\nof complex patterns. This adjustment also makes the system more closely resem-\nble natural behaviors, where agents maintain personal space and avoid overlap\n[46, 47, 24]. Without this treatment, emergent patterns like flocks and lanes would\nonly form in the presence of external perturbations.\nWith collision handling introduced, we systematically explored the parameter\nspace described in Tab. 1. Varying the system density, external noise, field of view,\nand maximum turning angle produced distinct migration patterns. Moreover, we\nobserved order-disorder transitions by increasing noise."}, {"title": "3.3. Effects of Noise", "content": "Figure 6 shows the stationary average fitness as a function of the noise level.\nLow noise levels (10\u22124 < \u03be < 4 \u00d7 10-4 rads) are characterized by a sudden in-\ncrease in fitness. We attribute this phenomenon to noise-induced ordering, a type\nof stochastic resonance [49] where frequency modes in the noise signal resonate\nwith the main signal, increasing its strength. While we observe patterns such as\nshort segments at noise levels smaller than 10-4 rads, more complex patterns,\nsuch as lanes, emerge at slightly higher noise levels.\nAdditionally, the fitness curve is well-fitted by an innovation model that we\npreviously derived using a birth-death Markov process [50]. Here, however, noise\ndictates the evolution of the innovation, forcing agents to quickly adapt to the"}, {"title": "3.4. Explaining Agent Behaviors", "content": "Next, we analyze the internal workings of neural networks within agents, aim-\ning to connect the emergent patterns in collective behavior with the properties of\nthe networks. The goal is to understand how these networks process informa-\ntion. The analysis is performed using a quantitative method (through multilinear\nregression) and a qualitative visualization of the neural networks' structure.\nFor the quantitative study, we use a multilinear regression to assess the rela-\ntionship between the inputs and outputs of an agent's neural network. Multilinear"}, {"title": "4. Discussion", "content": "The maximum turning angle defines the agility or maneuverability of an agent.\nWhen the maximum turning angle is large, agents can make sharper turns and re-\nact more dynamically to their surroundings. Conversely, a small maximum turn-\ning angle limits the agent's ability to make sharp turns, encouraging more gradual\nchanges in direction.\nDuring the evolutionary training process, agents with a large maximum turn-\ning angle are likely to evolve neural networks that prioritize short-term, localized\nresponses to neighbor interactions, since they can immediately adjust their be-\nhavior. In contrast, agents with a small turning angle might rely on longer-range\ncoordination to avoid getting stuck in inefficient local configurations. This implies\nthat their neural networks may be selected to process more global information."}, {"title": "5. Conclusions", "content": "In this study, we investigated the emergence of collective behavior in min-\nimally intelligent agents using a minimalistic approach based on evolutionary\nalgorithms and shallow neural networks. By conducting a detailed analysis of\nthe agent's decision-making process, both quantitatively through multilinear re-\ngression and qualitatively by visualizing the neural networks, we uncovered key\ninsights into how different environmental parameters shape collective dynamics.\nWe observed a wide range of collective patterns, including swarms, flocks,\nlanes, and fronts, emerging from simple evolutionary pressures and local interac-\ntions. Our findings indicate that the degree of non-linearity in the neural networks\nis closely linked to the richness and complexity of collective behavior. Simpler,\nmore predictable behaviors such as stationary swarms and sparse flocks can be\nlargely explained by linear networks that average out inputs, suggesting that these\npatterns arise from relatively straightforward interactions. In contrast, more com-\nplex behaviors like flowing swarms and large-scale flocking are associated with\nmore non-linear behaviors where the networks need to integrate and process di-\nverse, non-local information from multiple neighbors.\nWe also explored the impact of system parameters, such as maximum turn-\ning angle, agent density, field of view, and noise, on the evolution of the agents'\nneural networks. Our results show that conditions promoting long-range interac-\ntions, moderate noise, and intermediate fields of view tend to select more complex\nand non-linear neural networks, leading to emergent collective behaviors that are\nmore intricate and difficult to predict. On the other hand, both high-density envi-\nronments and extreme fields of view (whether too narrow or too wide) encourage\nsimpler, more linear decision-making in neural networks."}]}