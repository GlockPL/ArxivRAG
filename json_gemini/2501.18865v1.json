{"title": "REG: Rectified Gradient Guidance for Conditional Diffusion Models", "authors": ["Zhengqi Gao", "Kaiwen Zha", "Tianyuan Zhang", "Zihui Xue", "Duane S. Boning"], "abstract": "Guidance techniques are simple yet effective for\nimproving conditional generation in diffusion\nmodels. Albeit their empirical success, the prac-\ntical implementations of guidance diverges signif-\nicantly from its theoretical motivation. In this\npaper, we reconcile this discrepancy by replac-\ning the scaled marginal distribution target, which\nwe prove theoretically invalid, with a valid scaled\njoint distribution objective. Additionally, we show\nthat the established guidance implementations are\napproximations to the intractable optimal solution\nunder no future foresight constraint. Building on\nthese theoretical insights, we propose rectified gra-\ndient guidance (REG), a versatile enhancement\ndesigned to boost the performance of existing\nguidance methods. Experiments on 1D and 2D\ndemonstrate that REG provides a better approx-\nimation to the optimal solution than prior guid-\nance techniques, validating the proposed theoreti-\ncal framework. Extensive experiments on class-\nconditional ImageNet and text-to-image genera-\ntion tasks show that incorporating REG consis-\ntently improves FID and Inception/CLIP scores\nacross various settings compared to its absence.", "sections": [{"title": "1. Introduction", "content": "Generative machine learning endeavors to model the under-lying data distribution, enabling the synthesis of new data\nsamples that closely mirror the characteristics of the original\ndataset. While many generative model families (Kingma,\n2013; Goodfellow et al., 2020) have emerged over time,\nthe recent surge in diffusion models (Ho et al., 2020; Song\net al., 2021) has marked a significant breakthrough, allow-ing for diverse and high-quality generation. These diffusion\nmodels now dominate a wide range of tasks, such as class-conditional image generation (Peebles & Xie, 2023; Karras\net al., 2024b), text-to-image generation (Ramesh et al., 2022;\nRombach et al., 2022), video generation (Ho et al., 2022),\nand audio and speech synthesis (Kong et al., 2021). De-\nspite the varied theoretical foundations, such as DDPM (Ho\net al., 2020), score matching (Song et al., 2021), Schr\u00f6dinger\nBridge (De Bortoli et al., 2021), and flow matching (Lip-\nman et al., 2023), diffusion models converge on a unified\nimplementation: a forward process progressively corrupts\ndata by adding Gaussian noise, while a reverse process, pa-rameterized by a neural network, is trained to denoise and\nreconstruct high-quality samples from pure noise.\nOne pivotal factor behind the success of diffusion models\nis the guidance technique (Dhariwal & Nichol, 2021; Ho &\nSalimans, 2022; Kynk\u00e4\u00e4nniemi et al., 2024; Karras et al.,\n2024a). Concretely, guidance is a sampling-time method\nthat balances mode coverage and sample fidelity (Ho & Sali-mans, 2022) by updating the noise prediction network output\nas a weighted sum of its original output and a user-defined\nguidance signal, with the mixing coefficient (i.e., guidance\nstrength) controlled by hyper-parameters. When initially\nproposed by Dhariwal & Nichol (2021), the guidance signal\nis provided by an auxiliary classifier trained alongside the\ndiffusion model, giving rise to the name classifier guidance.\nSubsequently, Ho & Salimans (2022) eliminate the need\nfor an additional classifier, relying instead on an implicit\nBayes posterior classifier to produce the guidance signal.\nThis classifier-free guidance method has since become a\npervasive component of modern diffusion models, enabling\neffective conditional generation across various applications.\nDespite the practical effectiveness of the guidance technique,\nits motivation and theoretical formulation remain poorly\nunderstood and, at times, conflicting in existing literature.\nSpecifically, guidance is originally stated as constructing\na new noise prediction network post-training correspond-ing to sampling from a scaled distribution (Ho & Salimans,\n2022). However, recent works (Bradley & Nakkiran, 2024;\nChidambaram et al., 2024) using Gaussian mixture case\nstudies reveal that this newly constructed noise prediction\nnetwork does not result in sampling from the intended scaled\ndistribution. This fundamental inconsistency weakens the\ntheoretical foundation of current guidance techniques, rais-ing misinterpretations and concerns about the implemen-tation optimality. In this paper, we reconcile this conflict\nand build a unified theoretical framework for understanding\nguidance techniques in conditional diffusion models. Our\nmain contributions include:"}, {"title": "2. Preliminary", "content": "We briefly review guidance techniques (Dhariwal & Nichol,\n2021; Ho & Salimans, 2022) developed for conditional\nimage generation in diffusion models. For simplicity, we\nadopt the notation of discrete-time DDPM (Ho et al., 2020)\nthroughout this paper, while noting that all of our results can\nbe similarly derived in other diffusion settings (Song et al.,\n2021; Karras et al., 2024b). Let us denote the conditional\ndistribution of interest as $q(x_0|y)$. We attempt to learn a\ndiffusion model to generate samples $x_0 \\in \\mathcal{X} \\subset \\mathbb{R}^D$ given\nthe conditioning variable $y \\in \\mathcal{Y}$, where $y$ can be either\ncontinuous (e.g., a text embedding) or discrete (e.g., a class\nlabel). Starting from a clean data $x_0$, the forward process of\nDDPM produces samples ${x_t}_{t=0}^T$ at progressively higher\nnoise levels by gradually injecting Gaussian noises through\n$T$-step transitions $q(x_t|x_{t-1})$:\n$q(x_t|x_{t-1}) = \\mathcal{N}(x_t|\\sqrt{\\alpha_t}x_{t-1}, (1 - \\alpha_t)I),$\n$q(x_{0:T}|y) = q(x_0|y) \\prod_{t=1}^T q(x_t|x_{t-1}),$\nwhere ${\\alpha_t}_{t=1}^T$ is a decreasing series in $[0, 1]$ controlling the\nnoise variance. The reverse process of DDPM starts from\na noisy sample $x_T$, and gradually denoises it by $T$-step\ntransitions $p_\\theta(x_{t-1}|x_t, y)$, yielding a clean sample $x_0$:\n$p_\\theta(x_{t-1}|x_t, y) = \\mathcal{N}(x_{t-1}|\\mu_{\\theta, t}, \\sigma_t^2I),$\n$p_\\theta(x_{0:T}|y) = p_\\theta(x_T|y) \\prod_{t=1}^T p_\\theta(x_{t-1}|x_t, y),$\nwhere $\\theta$ represents learnable parameters, and $p_\\theta(x_T|y)$ is\nusually fixed to a standard Gaussian distribution regardless\nof $y$, i.e., $p_\\theta(x_T|y) = \\mathcal{N}(x_T|0, I)$. The variance term $\\sigma_t^2$\nis fixed in DDPM (Ho et al., 2020), but can also be learned\nas a function of $(x_t, t, y)$ (Nichol & Dhariwal, 2021). The\nmean $\\mu_{\\theta, t} \\in \\mathbb{R}^D$ is parameterized by a noise prediction"}, {"title": "3. Guidance Theory Pitfall", "content": "Common Interpretation of Guidance. The original mo-tivation underlying guidance (which later we will correct)\nis that we attempt to sample from a constructed $p_\\theta(x_0|y)$\ngiven a trained diffusion $p_\\theta(x_0|y)$ (Ho & Salimans, 2022):\n$p_\\theta(x_0|y) \\propto p_\\theta(x_0|y) \\cdot R_0(x_0, y),$"}, {"title": "4. Guidance Theory from Joint Scaling", "content": "Scaling the Joint Distribution. Examining the interpre-tation of guidance in the previous section, we identify the\ncritical flaw lies in that it scales the marginal distributions,\nwhereas the joint distribution should serve as the cornerstone\nof our analysis. Specifically, to build the correct guidance\ntheory, we begin with a joint distribution scaled objective:\n$p_\\theta(x_{0:T}|y) \\propto p_\\theta(x_{0:T}|y) R_0(x_0, y).$\nEq. (13) is similar to Eq. (5) in that the reward value depends\nonly on the final generated sample $x_0$ and the conditioning\nvariable $y$. However, it differs from Eq. (5) in that the\nreward influences the entire denoising chain $x_{0:T}$. Further-more, Eq. (13) can derive Eq. (5) by marginalizing out $x_{1:T}$.\nConsequently, both of them have the same impact to the\ngeneration, since the generation is determined solely by the\nmarginal $p_\\theta(x_0|y)$. Before moving forward, we define the\ninduced expected reward $E_t(x_t, y)$ at time step $t$ as:\n$E_t(x_t, y) = \\int p_\\theta(x_0|x_t, y) R_0(x_0, y) dx_0,$\nwhere $t = 0, 1, ..., T$. Note that the definition gives\n$E_0(x_0, y) = R_0(x_0, y)$ at $t = 0$. For later simplicity,\nwe introduce $x_{T+1} = \\emptyset$, and thus $E_{T+1}(x_{T+1}, y) =$\n$\\int p_\\theta(x_0|y) R_0(x_0, y) dx_0$ based on Eq. (14). Since this\nexpression does not depend on any specific $x_t$ or $t$, we also\ndenote it as $E_{T+1}(x_{T+1}, y) = E(y)$ and will use them\ninterchangeably in subsequent discussions.\nWe now summarize our main result in Theorem 4.1, with\nthe proof deferred to Appendix C. Theorem 4.1 introduces"}, {"title": "5. Experimental Results", "content": "In this section, we conduct qualitative experiments on 1D\nand 2D synthetic examples. Based on the definition in\nEq. (14), the exact calculation of $\\nabla_{x_t} \\log E_t(x_t, y)$ involves\ngradient propagation through the denoising chain, which is\ngenerally computationally intensive but can be affordably\ncomputed in 1D or 2D."}, {"title": "6. Related Work", "content": "Guidance techniques are indispensable in modern diffusion\nmodels, significantly improving conditional generation qual-ity. Classifier guidance (CG), introduced by Dhariwal &\nNichol (2021), improves the quality of conditional samples\nby using the gradient of an auxiliary classifier as a guidance\nsignal, enabling a trade-off between the FID and IS metric.\nClassifier-free guidance (CFG) removes the need for an ex-ternal classifier by training a noise prediction network to\nhandle both conditional and unconditional generation via\nrandom conditioning dropout (Ho & Salimans, 2022). CFG\nhas shown significant empirical success and inspired numer-ous extensions (Kynk\u00e4\u00e4nniemi et al., 2024; Karras et al.,\n2024a; Bansal et al., 2023; Zheng & Lan, 2024; Chung et al.,\n2024; Ahn et al., 2024). Building on CFG, auto-guidance"}, {"title": "7. Conclusions and Limitations", "content": "In this paper, we rebuild the guidance theory on the correct\ntheoretical foundation based on joint scaling and reconcile\nthe practice and theory gap. We demonstrate that guidance\nmethods are an approximation to the optimal solution under\nno future foresight constraint. Leveraging this framework,\nwe introduce rectified gradient guidance (REG), a versatile\nenhancement that consistently improves the performance of\nexisting guidance techniques. Comprehensive experiments\nvalidate the effectiveness of REG. Our work resolves long-standing misconceptions about guidance methods and paves\nthe way for its future advancements.\nOur proposed REG is grounded in theoretical insights and\nmainly serves as an experimental validation of our theory's\ncorrectness. Its practical use depends on application needs,\nas it improves conditional generation performance with a\nminor computational overhead due to gradient calculations."}, {"title": "Impact Statement", "content": "Our research focuses on building the correct guidance the-ory for conditional generation in diffusion models. We ac-knowledge that large-scale diffusion models pose significant\nsocietal risks, such as generating fake images and videos,\nexacerbating misinformation, amplifying biases, and under-mining trust in visual media. While our method enhances\nthe generative capabilities of diffusion models, it may inad-vertently amplify these associated risks. To mitigate these\nconcerns, we emphasize the importance of responsible devel-opment and deployment of diffusion models under stringent\noversight. This includes, but is not limited to, integrating\nbias-reduction strategies and implementing advanced mech-anisms for detecting and preventing misuse."}]}