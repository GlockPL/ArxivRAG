{"title": "Leveraging Large Language Models to Predict Antibody Biological Activity Against Influenza A Hemagglutinin", "authors": ["Ella Barkan", "Ibrahim Siddiqui", "Kevin J. Cheng", "Alex Golts", "Yoel Shoshan", "Jeffrey K. Weber", "Yailin Campos Mota", "Michal Ozery-Flato", "Giuseppe A. Sautto"], "abstract": "Monoclonal antibodies (mAbs) represent one of the most prevalent FDA-approved modalities for treating autoimmune diseases, infectious diseases, and cancers. However, discovery and development of therapeutic antibodies remains a time-consuming and expensive process. Recent advancements in machine learning (ML) and artificial intelligence (AI) have shown significant promise in revolutionizing antibody discovery and optimization. In particular, models that predict antibody biological activity enable in-silico evaluation of binding and functional properties; such models can prioritize antibodies with the highest likelihoods of success in costly and time-intensive laboratory testing procedures. We here explore an Al model for predicting the binding and receptor blocking activity of antibodies against influenza A hemagglutinin (HA) antigens. Our present model is developed with the MAMMAL framework for biologics discovery to predict antibody-antigen interactions using only sequence information. To evaluate the model's performance, we tested it under various data split conditions to mimic real-world scenarios.\nOur models achieved an AUROC \u2265 0.91 for predicting the activity of existing antibodies against seen HAs and an AUROC of 0.9 for unseen HAs. For novel antibody activity prediction, the AUROC was 0.73, which further declined to 0.63\u20130.66 under stringent constraints on similarity to existing antibodies. These results demonstrate the potential of Al foundation models to transform antibody design by reducing dependence on", "sections": [{"title": "Introduction", "content": "The influenza A virus is responsible for one of the most prevalent infectious diseases worldwide, with associated influenza infections impacting an estimated 20-40 million people annually in the United States alone [1,2]. Despite its wide prevalence, the influenza A virus remains a significant global health concern due to its rapid mutation rate and potential spillovers from animal reservoirs that enable persistence and continued evolution [3]. In resource-limited countries, seasonal outbreaks of influenza A can result in severe illness and even death [4]. A key factor in the virus's ability to infect host cells is hemagglutinin (HA), the main protein on the viral surface that facilitates binding to host cell receptors. Importantly, HA also serves as a primary target for the immune system: when an antibody binds to HA, that antibody can neutralize the virus and prevent infection [5]. In fact, HA is the primary antigen contained in all the current standard of care for influenza vaccine formulations, serving as the main target for developing immunity to influenza A.\nOver the past two decades, we and other groups have characterized a plethora of monoclonal antibodies (mAbs) directed against the influenza HA that are endowed with different breadth of recognition, neutralization, and protection profiles [6\u201318]. These highly specific antibodies are critical for the development of diagnostic and immunotherapeutic tools for treating diseases spanning cancer, autoimmune, and infectious disease foci. In particular, mAbs have shown great promise in the prevention and treatment of infections caused by respiratory pathogens like the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and the respiratory syncytial virus (RSV) [19].\nThough mAbs now constitute almost a third of all newly FDA-approved treatments, therapeutic antibody discovery remains a lengthy and costly process [20]. Researchers' ability to test new antibody formulations in silico represents a critical choke-point; predicting antibody binding to influenza A with Al technology offers a groundbreaking opportunity to model immunology and deliver tangible benefits for global health.\nIn recent years, Al models have opened new pathways for developing therapeutic molecules. AlphaFold architectures [21\u201323] achieve impressive single-domain protein structure prediction accuracy but encounter significant challenges with predicting antibody-antigen complex structures and, independent of application, require computationally intensive large-scale sampling [23\u201325]. Biomedical language models,"}, {"title": "Related Work", "content": "Predicting the binding affinity or functional activity of an antibody candidate against a given target antigen represents a key step in therapeutic and vaccine design. Simulation methods like molecular dynamics (MD) and free energy perturbation (FEP) [36\u201338] can accurately capture the physical states of antibody-antigen complexes and offer one avenue toward making affinity predictions. However, these atomistic simulation approaches are computationally expensive and typically rely on accurate static structural information as a starting point. Molecular docking methods offer higher-throughput but less accurate estimates of intermolecular binding modes; docking scores exhibit notoriously weak correlations with affinity data [39,40]. Other knowledge-based scoring functions [41,42] offer alternative means of estimating binding affinities, but with limited accuracy and validity.\nMachine learning (ML) methods (like those based on random forests) have set the standard for affinity prediction for small molecule-target complexes for decades. Similar approaches have since gained prevalence in the antibody discovery space. With the growing availability of large scale molecular datasets, deep learning (DL) techniques have emerged as favored methods for both small molecule-protein [43\u201345] and antibody-antigen binding prediction [46,47]. The recent trend of using very large protein datasets to pretrain biomolecular LLMs [26,27,48\u201350], with some models even being specific to antibodies [29\u201331,51], has redefined antibody-antigen binding affinity prediction as a downstream task. Most approaches in this domain rely on making"}, {"title": "Methods", "content": "Monoclonal antibodies, recombinant HA and influenza viruses\nThe 188 human and mouse anti-HA mAbs used to generate the binding and HAl dataset featured in this study were previously described by our group or derived from BEI and"}, {"title": "Data description", "content": "This study's dataset comprises pairs of mAbs and influenza A HA antigens, evaluated using two assays: binding activity and HAI activity. These assays characterize 1) the breadth of binding, indicating the number of strains the mAb can bind; and 2) the breadth of receptor binding inhibition (i.e., HAI), which reflects the antibody's ability to prevent viral binding to the sialic acid receptor, thereby blocking virus entry and neutralizing the virus.\nBinding activity assays were conducted as previously described [9,11,13,17] using an Enzyme-Linked Immunosorbent Assay (ELISA), a method to detect and quantify antibody-antigen interactions by measuring a signal, such as color change, proportional to binding strength [5]. Binding strength is quantified as the area under the binding curve (AUC-ELISA), derived from 3-fold serial dilutions of mAbs (20 to 0.009 \u00b5g/mL). AUC-ELISA values range from 0.5 (negative) to 20, with higher values indicating stronger binding. We considered AUC-ELISA values greater than 1 as positive binding.\nHAI represents the ability of an antibody to block the interaction between HA and the sialic acid cell receptor, measured as the minimum antibody concentration required to inhibit red blood cell agglutination by the virus. In particular, the HAI assay involves mixing serially diluted mAbs with a fixed amount of virus and adding red blood cells to detect hemagglutination. Ultimately, the ability of an antibody to inhibit this agglutination is indicative of its neutralizing potency [19]. HAI assays with mAbs were performed as previously described [9\u201312,17]. HAl values range from 0.005 to 20 \u00b5g/mL, with lower values indicating higher potency. We classified HAl values below 10 \u00b5g/mL as positive outcomes. The mAbs in the dataset are represented as amino acid sequences of the variable regions of the heavy (HC) and light (LC) chains.\nThe antigens in the dataset are represented as amino acid sequences of the HA protein. The amino acid sequences for 79% of antigens were obtained from publicly available databases including NCBI GenBank and GISAID. The remaining 21% of antigens were derived from experimental results conducted against previously described COBRA (Computationally Optimized Broadly Reactive Antigen) HA. These include H2_COBRA.Z7[70], H3_NG5 [71], H3_NG7 [72], H5_COBRA2 [73], H1N1 COBRA P1 [74], H1N1 COBRA X3 [75], H1N1 COBRA X6 [76], H3N2 COBRA NG2 [77], H1N1 COBRA Y2 [78], H3N2 COBRA T10 [79], and H3N2 COBRA T11 [80]. COBRA antigens are computationally optimized to elicit broader reactivity than wild-type antigens and were designed to enhance breadth of response by reconciling the variability among different seasonal and/or pandemic HA strains in a single HA antigen [7]. Additional metadata"}, {"title": "Data splits", "content": "We assessed model robustness through 5-fold cross validation across four distinct data splitting strategies: lenient, HA-exclusive, mAb-exclusive, and mAb-cluster exclusive. In the lenient split, mAb-HA pairs were randomly distributed between training and testing sets. For the HA-exclusive split, we ensured all pairs containing the same HA sequence were assigned to the same fold, appearing exclusively in either the training or test set. The mAb-exclusive split followed a similar principle, keeping all pairs involving the same mAb within a single fold. In the mAb-cluster exclusive split, we grouped mAb-HA pairs based on antibody clusters, which were determined using MMseqs2 [81] with a minimum sequence identity threshold of 50%. We generated these four splitting strategies separately for each label type (binding activity and HAI), maintaining consistent proportions of positive antibody-HA pair labels across all folds."}, {"title": "Binding and HAI classification models", "content": "We developed predictive models using MAMMAL [50], a recently published biomolecular foundation model framework. MAMMAL is part of IBM's Biomedical Foundation Modeling (BMFM) technology suite\u00b9. Specifically, we used the model ibm/biomed.omics.bl.sm.ma-ted-458m, which was trained on extensive multi-domain data, including proteins (UniProt [82]), antibodies(OAS [83]), and protein-protein interactions (STRING [84]) via various self-supervised tasks. For brevity, we refer to this foundation model as MAMMAL. The model code and pretrained weights are publicly available at https://github.com/BiomedSciAl/biomed-multi-alignment and https://huggingface.co/ibm/biomed.omics.bl.sm.ma-ted-458m respectively. The developed model take a pair of antibody and antigen sequences as input, as represented by their amino acid sequences and using the prompt syntax of the AbAg Bind task described in past work [50]. Model training and evaluation were conducted using the FuseMedML framework [85].\nFor each task and training fold, we fine-tuned MAMMAL with the default hyperparameters outlined in [50]: AdamW optimizer with \u03b21 = 0.9 and \u03b22 = 0.999, weight decay of 0.01, and gradient clipping with a norm of 1.0. We employed 2K warm-up steps to reach the maximum learning rate, followed by a cosine decay scheduler that reduces the learning rate to 10% of the maximum by the end of training. The maximum input length was set to 900, ensuring input sequences are not truncates. For all models, training involved 1000 iterations on a V100-32G GPU using batch sizes of 8."}, {"title": "Model Evaluation", "content": "We evaluated the models' classification performance using the Area Under the Receiver Operating Characteristic Curve (AUROC) and the Area Under the Precision-Recall Curve (AUPRC). Both metrics have values ranging between 0 and 1 For a random classifier, the expected AUROC is 0.5; the expected AUPRC for a random classifier corresponds to the rate of positivity in the dataset [86]. For each 5-fold cross-validation experiment, we report average performance metrics along with their standard deviations across five folds."}, {"title": "Results", "content": "Data statistics\nThe classification dataset consists of 188 mAbs and 79 hemagglutinins HAs. The data include 4,922 unique mAb-HA pairs from 176 mAbs and 59 HAs in the binding activity assays and 5,035 pairs from 186 mAbs and 59 HAs in the HAI assays. Among these, 3,188 mAb-HA pairs are shared between the binding activity and HAl assays, involving"}, {"title": "Prediction of binding activity and hemagglutination inhibition", "content": "We conducted 8 experiments using 5-fold cross-validation, corresponding to two classification outcomes\u2014binding and HAI\u2014and four data splits (lenient, HA-exclusive, mAb-exclusive, and mAb-cluster-exclusive). Each experiment was repeated twice: once with random weight initialization (the \"random-initialization\" model) and once with initialization using MAMMAL weights (the \"MAMMAL-finetuned\" model). Both the random-initialization and MAMMAL-finetuned models exhibited performance metrics significantly higher than random, where a random classifier is expected to produce an AUROC of 0.5 for both datasets and AUPRCs of 0.35 and 0.11 for the binding and HAI datasets, respectively.\nComparing the two models, the MAMMAL-finetuned model consistently outperformed the random-initialization model, except for the AUROC metric on the mAb-cluster-exclusive split for the HAl classification task. However, this difference fell within the range of the estimated standard errors (SEs, calculated as the standard deviation divided by the square root of 5) and was therefore not statistically significant (P = 0.43, one-sided t-test). Given that the HAl dataset is imbalanced (with only an 11% positivity rate), the AUPRC metric may be more relevant [86]. A significant difference was observed in AUPRC, with the MAMMAL-finetuned model showing superior performance."}, {"title": "Prediction of antibody breadth of protection", "content": "We assessed the models' ability to predict antibody breadth for binding activity and HAI across the HA subtypes H1 and H3. The analysis was conducted separately for each HA subtype (H1 and H3) and assay type (binding activity and HAI). Antibodies featured in fewer than five assays were filtered out. For each antibody, we measured its breadth of protection by aggregating assay results and calculating the proportion of positive assays. We then computed a prediction score for broad protection by averaging the predictions from validation folds across all assays in which the antibody appears. Only antibody-exclusive splits were considered, as the analysis aimed to predict the broad protection of unseen antibodies.\nTo evaluate the predictive power of the aggregated model scores, we calculated the Pearson correlation between these scores and the antibodies' rates of positive assay results. Additionally, we calculated the AUROC for scores associated with at least 30% positive assays."}, {"title": "Discussion", "content": "In this study, we developed and evaluated Al models to predict antibody binding and HAI activity on influenza A HA using antibody HC and LC variable region sequences as input. Our approach leveraged MAMMAL, a language model pre-trained on extensive biomedical datasets, which we fine-tuned using laboratory-derived antibody-HA binding and HAI assay data. We evaluated model performance through comprehensive cross-validation analyses, employing multiple split paradigms to simulate diverse real-world scenarios and assess the robustness of our models.\nTo address the computational challenges posed by high-dimensional sequence data, we employed transformer architectures [87], which excel at capturing complex patterns in protein sequences data [28,27,88]. The superior performance of models initialized with MAMMAL weights compared to those with random initialization underscores the value of transfer learning from large-scale pre-trained biomedical models, particularly when working with limited task-specific data. These results underscore the transformative potential of pretraining on large-scale protein and antibody datasets to boost model performance on small, specialized datasets.\nThe high predictive performance (AUROC > 0.9) of our fine-tuned MAMMAL models under lenient split conditions highlights those models' ability to generalize across randomly held-out antibody-HA pairs. This result implies potential utility in reducing experimental workloads by predicting outcomes for untested combinations within known sequence spaces. Similarly, the strong performance (AUROC = 0.9) in the HA-exclusive split scenario demonstrates reliable prediction capabilities for novel HA sequences against previously analyzed antibodies, offering support for strain surveillance and antibody evaluation against emerging variants.\nThe more challenging antibody-exclusive split scenario, relevant for novel antibody design, showed moderate performance (AUROC = 0.73) for both binding activity and HAI prediction. This decrease in performance compared to other scenarios suggests current limitations in generalizing predictions to entirely new antibody sequences. The further reduction in performance under the HA-cluster-exclusive split (AUROC = 0.66 for binding, 0.63 for HAI) highlights particular challenges in extrapolating to more divergent HA sequences. Despite these limitations, the models showed promising results toward identifying broadly protective antibodies, especially against H3 subtypes (AUROC 0.64-0.73). Performance limitations likely arise because of the scarcity of characterized mAbs in datasets used in this study.\nA key factor to improving model performance regards the expansion of training datasets through automated collection and curation of influenza neutralization assays from public repositories. Training on larger datasets with more diverse antibody sequence data is likely needed to enhance model generalization, particularly for novel antibody"}, {"title": "Conclusion", "content": "Our findings demonstrate the potential of fine-tuned language models for predicting antibody-HA interactions across various practical scenarios. While performance on novel antibodies, particularly those divergent from training data, remains an area for improvement, these models hold significant promise for accelerating influenza research and antibody design. Integration with computational antibody design pipelines, including Al-based systems, could enable rapid in-silico assessment of candidate antibodies and significantly expedite the antibody design process."}]}