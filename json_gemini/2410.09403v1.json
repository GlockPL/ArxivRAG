{"title": "TWO HEADS ARE BETTER THAN ONE: A MULTI-AGENT SYSTEM HAS THE POTENTIAL TO IMPROVE SCIENTIFIC IDEA GENERATION", "authors": ["Haoyang Su", "Renqi Chen", "Shixiang Tang", "Xinzhe Zheng", "Jingzhe Li", "Zhenfei Yin", "Wanli Ouyang", "Nanqing Dong"], "abstract": "The rapid advancement of scientific progress requires innovative tools that can accelerate discovery. While recent AI methods, particularly large language models (LLMs), have shown promise in tasks such as hypothesis generation and experimental design, they fall short in replicating the collaborative nature of real-world scientific practices, where diverse teams of experts work together to tackle complex problems. To address the limitation, we propose an LLM-based multi-agent system, i.e., Virtual Scientists (VIRSCI), designed to mimic the teamwork inherent in scientific research. VIRSCI organizes a team of agents to collaboratively generate, evaluate, and refine research ideas. Through comprehensive experiments, we demonstrate that this multi-agent approach outperforms the state-of-the-art method in producing novel and impactful scientific ideas, showing potential in aligning with key insights in the Science of Science field. Our findings suggest that integrating collaborative agents can lead to more innovative scientific outputs, offering a robust system for autonomous scientific discovery.", "sections": [{"title": "1 INTRODUCTION", "content": "The rapid acceleration of scientific progress necessitates more efficient and innovative tools for exploring new concepts and tackling complex challenges (Park et al., 2023b). The concept of automatic scientific discovery has emerged as a promising solution to expedite innovation, representing a long-standing ultimate goal within the scientific community (Langley, 1987). With the development of artificial intelligence (AI), automatic scientific discovery has witnessed the potential to revolutionize how research is conducted by automating key steps in the scientific process, ranging from hypothesis generation to experimental design (Raghu & Schmidt, 2020; Spangler et al., 2014).\nMore recently, foundational models, especially the large language models (LLMs) (OpenAI, 2023; Dubey et al., 2024), have shown significant progress in general capabilities, facilitating their applications in various stages of scientific discovery (Abramson et al., 2024; Chang & Ye, 2024), including literature reviews (Hsu et al., 2024), experimental designs (Huang et al., 2024), etc. A notable development is the AI Scientist (Lu et al., 2024), which introduces a scalable system for end-to-end scientific paper generation, highlighting the potential of LLMs to drive autonomous scientific discovery. Despite its capabilities, AI Scientist operates with ONE agent, which falls short of replicating real-world scientific practices, where research is often conducted through collaborative efforts involving diverse teams of experts (Kayacik et al., 2019).\nTo address the limitations of a single executive system, such as the AI Scientist, and to better replicate the collaborative nature of real-world scientific discovery (Gauch, 2003), we focus on the idea generation phase in the research process, which demonstrates more collaborative aspects (Linsey et al., 2005). From this end, we propose an LLM-based multi-agent system, Virtual Scientists (VIRSCI), designed to harness the potential of LLM agents in assisting autonomous scientific idea generation. Leveraging the inherent human-like reasoning capabilities of LLMs (Xie et al., 2024),"}, {"title": "2 RELATED WORK", "content": "In recent years, AI has fundamentally reshaped the landscape of scientific discovery by providing powerful tools that enhance various research processes (Xu et al., 2021). AI techniques, especially generative AI, can facilitate basic scientific discoveries, such as identifying complex molecular (Vignac et al., 2022) and protein structures (Abramson et al., 2024), drastically reducing the time required for experimental iterations. These advancements have found wide application across diverse fields such as chemistry (Liu et al., 2023a), meteorology (Bi et al., 2023), and medicine (Rajpurkar et al., 2022), etc. Besides, with the advent of LLMs, AI methodologies can step further and collaborate in streamlining critical stages of the scientific pipeline, including hypothesis generation, experimental design, data acquisition, and analysis(Zheng et al., 2023; Wang et al., 2023; Miret &\nNevertheless, these approaches lack the collaborative nature of the scientists intrinsic to real-world research. VIRSCI is the first to harness the power of an LLM-based multi-agent system to facilitate the generation of research ideas in autonomous scientific discovery."}, {"title": "2.2 MULTI-AGENT SYSTEMS IN TEAM COLLABORATION", "content": "A multi-agent system for team collaboration leverages autonomous agents to coordinate, communicate, and solve tasks within a shared environment, mimicking human teamwork dynamics (Dorri et al., 2018). Traditional multi-agent systems typically involve semi-autonomous agents coordinating through explicit protocols and structured messages to achieve common goals (Dunin-Keplicz\nthe advent of LLMs has revolutionized this landscape by enabling agents to utilize natural language for communication and collaboration in a believable proxy of human behavior (Park et al., 2023a), thereby fostering a more intuitive and flexible interaction model. Recent studies have further verified the superior performance of LLM-based multi-agent systems in various domains, such as programming, game playing, and complex reasoning tasks when compared to single-agent execution (Liu et al., 2023b; Wang et al., 2024; Light\nmulti-agent systems to function as collaborative scientists, promoting de novo scientific ideas."}, {"title": "3 THE VIRTUAL SCIENTISTS", "content": "In this paper, we aim to build a multi-agent system using a real-world academic dataset to simulate how a scientist assembles a research team and collaboratively generates an abstract that details a novel scientific idea. Our VIRSCI system consists of two components: a scientific research ecosystem and a multi-agent system for scientific idea generation."}, {"title": "3.1 THE SCIENTIFIC RESEARCH ECOSYSTEM", "content": "The scientific research ecosystem comprises two main components: paper information and corresponding author information ranging from year $Y_{start}$ to $Y_{end}$. First, we select a year $Y_{bound}$ as a time point and split the papers into two subsets: past papers $B_{past}$ and contemporary papers $B_{con}$. We further extract authors from $B_{past}$ to form the complete set of scientists $S$, with each scientist's background information stored in the author knowledge bank, and the adjacency matrix $A$, which represents the collaboration counts between scientists."}, {"title": "3.2 THE MULTI-AGENT SYSTEM FOR SCIENTIFIC COLLABORATION", "content": "We first randomly sample a scientist $s_0$ from $S$ as the team leader. The team leader then follows these steps to produce an abstract: (1) Collaborator Selection, (2) Topic Discussion, (3) Idea Generation, (4) Idea Novelty Assessment, and (5) Abstract Generation. To help each agent become familiar with the backgrounds of other team members without overloading the initialization prompt, we employ retrieval-augmented generation (RAG) (Lewis et al., 2020), used throughout all five steps. All necessary prompts and example scenarios are shown in Appx. G and H.\nCollaborator Selection The first step in our system is collaborator selection, aimed at forming a team of scientists, $T = \\{s_0, ..., s_i, ..., s_n\\}$, where n denotes the team size. When $s_0$ is selecting collaborators, we convert the adjacency matrix, A, into a probability distribution using the following equation: $P_{i,j} = \\frac{A_{i,j}}{\\Sigma_{j=1}^{N}A_{i,j}}$, where N denotes the size of S. This allows the team leader to iteratively send invitations to preferred collaborators. Upon receiving an invitation, the invited scientist"}, {"title": "Topic Discussion", "content": "The next step is to propose a research topic, which will guide the research direction. Inspired by multi-round collaboration (Mezirow, 2003; Sunstein, 2005; Amgoud & Prade, 2009) and multi-agent collaboration strategies (Xu et al., 2023; Zhang et al., 2023; Shinn et al., 2024), we design a general team discussion mechanism. In this mechanism, team members engage in discussions based on a specific task description prompt. This process is applied not only to topic discussion but also to subsequent collaboration steps. While allowing agents to decide when to stop the discussion would better reflect real-world scenarios, fixing the number of turns ensures consistent inference costs across different team settings in our experiments. Therefore, we leave the discussion of adaptive turn numbers to the ablation study (See Sec. 4.4). Given the team T, the prompt during the topic discussion is:\n$Q_{k,i} = (Q_{team}, Q_{topic}, \\cup_{t=1}^{k-1}(D_{t}), \\cup_{j=0}^{n-1}(R_{k,j})),$"}, {"title": "Idea Generation", "content": "Third, the team is tasked with proposing several potential ideas. To align with genuine research workflows and mitigate LLM illusions (Huang et al., 2023), each agent is required to generate a comprehensive response that includes three key components: (1) a description of the idea, (2) a specific experimental plan, and (3) a self-assessment covering metrics such as novelty, feasibility, and clarity, representing the agent's confidence (See Appnx. 12).\nAt the start of the idea generation process, when no ideas have yet been proposed, the agent is provided with references by searching $B_{past}$ using the topic $R_{topic}$, denoted as $B_{past} (R_{topic})$. The first idea-generation prompt is defined as:\n$Q_{1,0} = (Q_{idea}, R_{topic}, B_{past}(R_{topic})),$"}, {"title": "4 EMPIRICAL STUDY", "content": "Dataset We build our scientific research ecosystem using real scientists' information from the AMiner Computer Science Dataset , which was constructed by extracting scientists' profiles from online web databases (Tang et al., 2008). This dataset includes 1,712,433 authors and 2,092,356 papers, covering the period from 1948 to 2014, with disambiguated author names. To manage the large volume of data, we set $Y_{start}$, $Y_{bound}$, and $Y_{end}$ to 2000, 2010, and 2014, respectively. For quality assurance, we filtered out past papers lacking abstracts or with fewer than 10 citations, contemporary papers with fewer than 5 citations or missing abstracts, and authors with fewer than 50 papers or 50 co-authors. As a result, we extracted detailed information from 156 authors and 85,217 papers to construct the ecosystem and initialize the corresponding agents for the simulation. All paper and author data are embedded using the \u201cmxbai-embed-large\" model (Lee et al., 2024).\nImplementation We implement our system on top of the Agentscope framework (Gao et al., 2024), which serves for LLM-empowered multi-agent applications. We evaluate our system using different publicly available LLMs: GPT-40 (OpenAI, 2023) and Llama-3.1 (8b and 70b) (Dubey et al., 2024). GPT-40 is accessible exclusively via a public API, while the Llama-3.1 models are open-weight and invoked using the Ollama (Ollama, 2024) in our experiments. Each experimental run on Llama-3.1 (8b) takes approximately 10 minutes on 1 NVIDIA A100 40G GPU within a team discussion setting of 4 members and 5 turns (K = 5). All experimental results are averaged on 20 runs.\nEvaluation Metrics Since no single evaluation metric perfectly captures the novelty of scientific outputs, we employ three common metrics that align with our intuition: (1) Historical Dissimilarity"}, {"title": "4.2 COMPARISONS WITH AI SCIENTIST", "content": "Table 1: Comparisons with AI Scientist. Results show that our multi-agent system outperforms the AI Scientist across all metrics, with GPT-4o achieving the highest performance."}, {"title": "4.3 EXPLORING SCIENCE OF SCIENCE: THE IMPACT OF TEAM DYNAMICS ON NOVELTY", "content": "While the effects of team size, team freshness, and team research diversity on the novelty of research outputs have been established in the Science of Science field using traditional statistical methods (Wu et al., 2019; Zeng et al., 2021; Shi & Evans, 2023), they have yet to be verified in an LLM-based multi-agent system. We conduct the following experiments to demonstrate VIRSCI'S potential to simulate key findings in Science of Science."}, {"title": "4.3.1 HoW TEAM SIZE AND DISCUSSION TURNS AFFECT NOVELTY", "content": "Effects of Team Size on Novelty The results shown in indicate that increasing the number of team members can enhance the novelty score of the generated abstracts. By adding new team mem-bers, a broader range of ideas and perspectives can be facilitated, leading to more creative solutions and innovative outputs. However, this relationship is not strictly linear; our findings suggest that the peak novelty occurs with a team size of 8 members. While a moderate increase in team size may boost novelty, excessively large teams can introduce coordination challenges and communication barriers. These issues may dilute individual contributions and foster groupthink, where the focus shifts from original ideas to achieving consensus. Thus, there appears to be an optimal team size that maximizes creativity without overwhelming the collaborative process. This conclusion aligns with existing literature, which suggests that while smaller teams tend to disrupt science and technology with new ideas and opportunities, larger teams often concentrate on refining and developing existing concepts (Wuchty et al., 2007; Fortunato et al., 2018; Wu et al., 2019).\nEffects of Discussion Turns on Novelty The number of discussion turns plays a crucial role in enhancing the novelty score (Mezirow, 2003; Li et al., 2023; Shinn et al., 2024; Lu et al., 2024). Our analysis (Fig. 3) indicates that an appropriate number of turns enables team members to explore topics thoroughly, iterate on ideas, and refine their abstracts. This iterative process is essential for deepening understanding and producing more sophisticated research outputs. While initial turns are beneficial for generating ideas and facilitating discussions, an excessive number of turns can lead to fatigue and reduced engagement. This may stifle creativity, as members may conform to dominant"}, {"title": "4.3.2 HoW TEAM FRESHNESS AFFECTS NOVELTY", "content": "As shown in Fig. 4, team freshness, the fraction of team members who have not previously collab-orated, has a notable effect on the novelty of generated outputs. Notably, team freshness shows its strongest effects at 50%, particularly for larger teams (size 8). At this level, historical dissimilarity reaches its peak, suggesting that a balanced mix of new and returning collaborators promotes divergence from past research, enhancing overall innovation. As team freshness increases, contemporary dissimilarity decreases, indicating that teams with fresh members tend to generate abstracts that align more closely with future research trends. Furthermore, both CI and ON achieve their highest values at 50% freshness. This suggests that a balanced team composition, where half the members are new, optimally combines novelty and future relevance, driving impactful research outcomes. Al-though our findings focus specifically on novelty in scientific abstracts, the broader principle aligns, to some extent, with prior work in this field (Guimera et al., 2005; Zeng et al., 2021)."}, {"title": "4.3.3 HoW TEAM RESEARCH DIVERSITY AFFECT NOVELTY", "content": "Team research diversity, defined as the proportion of team members who specialize in unique re-search topics different from others in the team, plays a significant role in influencing various novelty metrics. As shown in Fig. 5, increasing diversity enhances HD, with both team sizes showing a peak at 50% diversity, indicating that moderately diverse teams produce work that is distinct from previous research. CD decreases most notably at 50% diversity, suggesting that teams with balanced diversity align better with future research trends while maintaining innovation. In terms of contem-porary impact, larger teams (size 8) benefit more from higher diversity, seeing a significant increase, while smaller teams exhibit a more stable, moderate impact. Finally, Overall Novelty is highest at 50% diversity, particularly for larger teams, reflecting the value of having a balanced mix of diverse and non-diverse members for producing novel and impactful work. This conclusion mirrors find-ings from the Science of Science, where an unexpected combination of team members can increase research impact (Uzzi et al., 2013; Shi & Evans, 2023)."}, {"title": "4.4 ABLATION STUDY", "content": "Effects of Components Designed for Novelty In this section, we respectively test the effects of the invitation mechanism in team discussion, the role of the novelty assessment step, and the im-pact of self-review in abstract generation. All experiments are conducted with a 5-turn discussion. The results consistently show improvements in ON when these components are applied. For the invitation mechanism (Tab. 2), introducing new scientists into the discussion positively impacts the team's performance across both 4-member and 8-member teams. This indicates that seeking exter-nal insights from relevant but non-team scientists fosters more diverse and novel ideas. The novelty assessment step (Tab. 3) also significantly boosts the scores. If novelty assessment is not considered, then the output of idea generation will not be an idea list but the idea from the last scientist. Nov-elty assessment ensures that the generated ideas are continuously evaluated for originality, helping teams avoid overlap with existing research. The improvement is most noticeable in larger teams, where more ideas are being generated and assessed. Finally, the self-review mechanism (Tab. 4) is crucial in further refining the abstracts. By allowing the team leader to re-evaluate the abstract for novelty after it is fully generated, low-quality abstracts are discarded, and the team engages in a new discussion to generate a better idea, as evidenced by the score improvements for both team sizes."}, {"title": "5 CONCLUSION", "content": "We build the virtual scientist (VIRSCI), a pioneering LLM-based multi-agent system designed to replicate the collaborative dynamics of scientific discovery. By addressing the limitations of tradi-tional single-agent systems, our model effectively simulates the initial phase of autonomous science discovery\u2014idea generation. Through a structured five-step process, VIRSCI showcases how special-ized agents can collaborate, offering diverse expertise and insights that mirror real-world scientific teamwork. The experiments reveal that VIRSCI significantly outperforms single-agent approaches and highlights emergent social behaviors among the scientist agents, suggesting promising avenues for further exploration of collaborative mechanisms in scientific research."}, {"title": "A DATA AND CODE AVAILABILITY", "content": "The code for this project is available at https://github.com/open-sciencelab/Soci al_Science."}, {"title": "A.2 DATA", "content": "The preprocessed data is available at https://drive.google.com/drive/folders/1 ZwWMBQ50K-14VuzMa60GbMND0g2EIxIu?usp=sharing."}, {"title": "B LIMITATIONS AND FUTURE WORK", "content": "While our multi-agent system demonstrates notable improvements over the single-agent approach in generating novel and impactful scientific ideas, it has several limitations. First, we have only validated our system on a single computer science dataset, which restricts the diversity of research ideas and limits its capacity for simulating interdisciplinary collaborations. This focus on a single do-main also reduces the generalizability of our results to other scientific fields. Additionally, while our system effectively models collaboration, the simulated interactions may oversimplify the complexi-ties of real-world teamwork, where multiple teams can collaborate dependently or independently on related research, and agents often participate in different teams simultaneously.\nTo address these limitations, several future directions can be pursued. Expanding the system to incorporate datasets from various scientific disciplines is a crucial next step. This would increase the diversity of generated ideas and enable simulations of interdisciplinary collaborations, providing a more realistic and holistic representation of real-world research environments. Another important direction is to enhance the simulation of teamwork by allowing multiple teams to work concurrently and enabling agents to contribute to multiple teams or projects simultaneously. Such improvements would better reflect the collaborative dynamics of modern scientific research and provide a more powerful tool for the Science of Science community. This would allow researchers to probe deeper into the underlying processes of scientific collaboration, engaging with the dynamic and interactive nature of teamwork to gain insights into how collaboration fosters innovation."}, {"title": "C ETHICS STATEMENT", "content": "This research uses publicly available data from the AMiner dataset, ensuring compliance with data privacy policies. Author names are masked to prevent data leakage during simulations. Our system is intended to augment, not replace, human researchers, emphasizing the need for human oversight to ensure the quality and integrity of generated outputs. To promote transparency, we commit to sharing all relevant codes for reproducibility within the research community."}, {"title": "D EFFECT OF THE POTENTIAL DATA LEAKAGE", "content": "We acknowledge that the use of papers published between 2011 and 2014 may raise concerns about data leakage, given that the LLMs employed in our experiments are trained on data within this time period. However, this potential issue does not pose a significant threat to the validity of our experiments for the following reasons. First, both the comparisons between our multi-agent system and AI Scientist, as well as the comparisons between different team settings, utilize the same LLMs. Since all models encounter the same exposure to training data from this period, any potential data leakage would affect all experiments equally. Thus, the relative performance differences we observe are not skewed by uneven data leakage. This ensures that the evaluation process remains fair and that the corresponding conclusions drawn are valid. Moreover, our goal is not to demonstrate an absolute measure of novelty but rather to explore how different collaboration strategies and team settings influence the novelty of generated research outputs. As all team settings face the same potential exposure to historical data, the novelty metrics still provide an accurate comparison of the agents' ability to generate distinct and original ideas under varying conditions. In summary, while"}, {"title": "E MORE DETAILS OF METHODS", "content": "A self-review mechanism is considered after $R_{abstract}$ is finalized to pre-check its novelty. In this self-review, the optimized abstract $R_{abstract}$ is provided to the team leader to assess novelty by comparing it to similar papers in $B_{past}$. The prompt is:\n$Q_{review} = (Q_{check}, R_{abstract}, B_{past}(R_{abstract}))$"}]}