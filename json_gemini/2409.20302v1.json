{"title": "OM4OV: Leveraging Ontology Matching for Ontology Versioning", "authors": ["Zhangcheng Qiang", "Kerry Taylor"], "abstract": "Due to the dynamic nature of the semantic web, ontology version control is required to capture time-varying information, most importantly for widely-used ontologies. Despite the long-standing recognition of ontology versioning (OV) as a crucial component for efficient ontology management, the growing size of ontologies and accumulating errors caused by manual labour overwhelm current OV approaches. In this paper, we propose yet another approach to performing OV using existing ontology matching (OM) techniques and systems. We introduce a unified OM4OV pipeline. From an OM perspective, we reconstruct a new task formulation, performance measurement, and dataset construction for OV tasks. Reusing the prior alignment(s) from OM, we also propose a cross-reference mechanism to effectively reduce the matching candidature and improve overall OV performance. We experimentally validate the OM4OV pipeline and its cross-reference mechanism using three datasets from the Alignment Evaluation Initiative (OAEI) and exploit insights on OM used for OV tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Ontologies serve as the backbone of the semantic web, providing formal descriptions of shared concepts across various applications [7]. An ontology is not static, and the need for version control arises with its birth. While Web data is dynamic, any ontology that is used needs to undergo periodic revisions to keep up with growth in domain knowledge, modifications to application adaptation, or corrections to the shared conceptualisation [11]. For example, it is unrealistic to expect ontologies created in the 1990s to contain concepts such as \"touchscreen\", \"fingerprint sensor\u201d, or \u201cWiFi antenna\" [8]. This may cause undesirable deficiencies in downstream artefacts that conform to or reuse the ontology that is being changed, leading to severe non-compliance and incompatibility issues.\nThe foundation of ontology versioning (OV) aims at distinguishing and recognising changes between different ontology versions."}, {"title": "2 RELATED WORK", "content": "Version control is recognised as a vital element in ontology management. Different versions of an ontology need to be interoperable so that version changes do not impede the effective and sustainable use of the ontology. There have been two main approaches towards OV that aim to enhance an ontology with the ability to represent different versions and to identify their differences.\nOne option is to include version information inside the ontology. The Simple HTML Ontology Extensions (SHOE) [9] uses the tag BACKWARD-COMPATIBLE-WITH to record version information. Klein et al. [10] argue that a carefully-managed version numbering system embedded in the URI of the ontology (and therefore the fully expanded name of entities defined in the ontology) can minimise the impact of adopting updated versions because unchanged entities will be unaffected in practice. These approaches have largely been adopted by the later OWL Web Ontology Language [3], where a set of annotation properties related to version information is defined. These include owl:versionInfo and owl:priorVersion to describe the version number of the ontology, owl: backwardCompatibleWith and owl: incompatibleWith to specify the entity's compatible or incompatible corresponding entity in the previous version, and owl: DeprecatedClass and owl: DeprecatedProperty to declare the deprecated entities. Later, the ontology language TOWL [20] was introduced to extend the OWL triple schema to quadruples to represent the versioning of concepts within an ontology. This idea is now incorporated in the new proposals for RDF 1.2, which allow time-varying information to be deduced from a temporal dimension within the quadruple [18].\nA second option is to create a separate version log to track version changes. Unlike traditional approaches that use an unstructured plain text file, the authors in [16] propose a new approach that uses a version ontology with the change definition language (CDL) to create a version log. In [4], the authors construct an historical knowledge graph (HKG). Storing the version log in the knowledge graph not only avoids repetition, but also enables advanced search functions. The authors in [19] argue that version logs may contain redundancy and inconsistent information. They propose a graph-of-relevance approach for interlinking different version logs and removing less relevant versions.\nWhile current approaches simply record human-generated version information, less attention has been paid to machine-generated version information. In other words, both previous approaches rely on the version information contained in or attached to the ontology. If such information is missing or incorrect, there is no way to automatically detect versioning of ontology concepts. In this study, we introduce a lightweight and fully automatic OV approach. Our approach advances by reusing existing OM systems and techniques for OV tasks, rather than creating a new OV framework from scratch. This paves the way for transferring well-studied OM solutions to OV tasks. With minor modifications required, we can reuse existing OM techniques and systems for OV tasks. To the best of our knowledge, our work is the first attempt to systemically analyse and utilise OM for OV."}, {"title": "3 OM4OV PIPELINE", "content": "Fig. 1 illustrates the overall OM4OV pipeline. Given a source ontology (Os) and a target ontology (Ot), an OM task can be considered as finding an alignment (A) that contains a collection of mappings. Similarly, given an old version of an ontology (O) and a new version of the same ontology (O'), an OV task can be considered as finding an alignment (A) that contains a collection of mappings over the two different versions. However, while an alignment for OM only considers matched entities, OV tracks both matched and non-matched entities. Further, matched entities are composed of two subsets remain and update, and non-matched entities are composed of add and delete entities. In practice, we expect for OV that unchanged remain entities dominate."}, {"title": "3.1 Task Formulation", "content": "The OM task is to find an alignment A with respect to a given similarity threshold s\u2208 [0, 1], defined as A = {(e1, e2, r, c)|e1 \u2208 Os, e2 \u20ac Ot, c \u2265 s}, where e1 and e2 are ontology entities in Os and Ot respectively, r states the relation between e1 and e2 which can be equivalence (=), subsumption (\u2286), or another relation, and c\u2208 [0, 1] is the level of confidence for the match (e1, r, e2) [5].\nSimilarly, an OV task can be formalised as finding two variants of an alignment $A_{match}$ and $A_{non-match}$ between ontology versions O and O' with respect to a given similarity threshold s \u2208 [0, 1]. While OM may have different mapping relations, OV narrows down the task and focuses only on the equivalence relation. We classify four subset alignments produced in the OV process, namely $A_{remain}$ ($A^{\\equiv}$), $A_{update}$ ($A^{\\neq}$), $A_{add}$ ($A^{\\oplus}$), and $A_{delete}$ ($A^{\\ominus}$).\n$A_{match} = \\{(e_1, e_2, =, c) | e_1 \\in O, e_2 \\in O', c \\geq s\\} = A^{\\equiv} \\cup A^{\\neq}$\n$A_{non-match} = \\{(e_1, e_2, =, c) | e_1 \\in O, e_2 \\in O', c < s\\} = A^{\\oplus} \\cup A^{\\ominus}$"}, {"title": "3.2 Performance Measurement", "content": "Given a gold standard reference (R) and a system-discovered alignment (A), OM typically measures performance using precision, recall, and F1 score. While precision measures matching correctness and recall measures matching completeness, there is an inherent trade-off between precision and recall. The F1 score offers a harmonic mean to balance the matching correctness and completeness. They are defined as:\n$Precison = \\frac{|A \\cap R|}{|A|}$\n$Recall = \\frac{|A \\cap R|}{|R|}$\n$F_1 Score = \\frac{2}{Precison^{-1} + Recall^{-1}}$\nOV can reuse these measures, but they need to be extended into four sub-measures for add, delete, remain, and update performance. Within each sub-measure, the precision-recall trade-off still holds. Across different sub-measures, they are not independent but satisfy the following equations, where N(O) is the number of entities in O and N(O') is the number of entities in O':\n$N(O) + N(O') = 2 \u00d7 (|A^{\\equiv}| + |A^{\\neq}|) + |A^{\\oplus}| + |A^{\\ominus}|$ \nFor each change in a part of an alignment, other parts will change accordingly. For example, if a new alignment is found in $A^{\\oplus}$ or $A^{\\ominus}$, then the number of alignments in $A^{\\oplus}$ and $A^{\\ominus}$ will be reduced by one each, and vice versa. If we define \u2206A as a universal change in OV, any changes in the alignments satisfy the following equation:\n$|\\Delta A| = |\\Delta A^{\\equiv}| + |\\Delta A^{\\neq}| = - |\\Delta A^{\\oplus}| = -|\\Delta A^{\\ominus}|$ \nWe define the corresponding changes of |A\u2229R| in remain, update, add, and delete as \u2206(A\u2229R)\u2261, \u2206(A \u2229 R)\u2260.\n$Recall^{\\equiv}\\uparrow = \\frac{|A^{\\equiv} \\cap R| + |\\Delta(A \\cap R)^{\\equiv}\\uparrow|}{|R^{\\equiv}|}$\n$Recall^{\\neq}\\uparrow = \\frac{|A^{\\neq} \\cap R| + |\\Delta(A \\cap R)^{\\neq}\\uparrow|}{|R^{\\neq}|}$\n$Precision \\uparrow ?= \\frac{|A^{\\equiv} \\cap R| + |\\Delta(A \\cap R)^{\\equiv}\\uparrow|}{|A^{\\equiv}|+|\\Delta A^{\\equiv}\\uparrow|} < 1 \\implies Precision \\uparrow$\n$\\frac{|\\Delta(A \\cap R)^{\\equiv}|}{|\\Delta A^{\\equiv}|} > \\frac{|A^{\\equiv} \\cap R|}{|A^{\\equiv}|} \\implies Precision \\downarrow$\n$Precision \\downarrow ?= \\frac{|A^{\\neq} \\cap R| + |\\Delta(A \\cap R)^{\\neq}\\uparrow|}{|A^{\\neq}|+|\\Delta A^{\\neq}\\uparrow|} < 1 \\implies Precision \\uparrow$\n$\\frac{|\\Delta(A \\cap R)^{\\neq}|}{|\\Delta A^{\\neq}|} > \\frac{|A^{\\neq} \\cap R|}{|A^{\\neq}|} \\implies Precision \\downarrow$"}, {"title": "3.3 Dataset Construction", "content": "We propose an approach to constructing synthetic OV datasets from OM datasets. Figure 2 illustrates the generation of OM4OV datasets. Our approach is described in the following steps:\n(1) The original OAEI datasets for OM provide two ontologies, Os and Ot. We choose one to be the intermediate ontology Oi. We retrieve all ontology entities from Oi.\n(2) There are four possible changes in OV tasks: remain, update, add, and delete. Each ontology entity in Oi is randomly assigned one of these.\n(3) For entities assigned to update, we need to generate the updated entity name. We should expect the new name to have a similar meaning to its original name. For example, the entity name \"ConferenceVenuePlace\" could be replaced with \u201cConference_hall\" or \"Conference_building\u201d, but not the general names \u201cPlace\" or \u201cLocation\u201d. To achieve this goal, we retrieve all equivalent entities provided by reference.xml included in the original OAEI datasets and use them as a replacement synonym corpus. For those entities whose names are unique identifiers or codes (and not textually-meaningful names), we use their annotation properties (e.g. rdfs:label, rdfs:comment, skos:prefLabel, and skos:definition) instead. For those entities that do not have synonyms in the generated list, we randomly re-assign the entity to remain, add, or delete.\nFor notational convenience henceforth, we will treat each element of remain, add, or delete to be either a single entity e or equivalently the idempotent mapping (e, e). Elements of update are necessarily mappings (e, e') (also written e \u2192 e') where e \u2260 e' and e' is the updated entity name of e, but when we write e \u2208 update we mean (e, e') \u2208 update for some e'. By construction, we also have that the four sets are pairwise disjoint.\n(4) Based on the entity assignments, we generate four corresponding versioning references, namely vr-remain.xml, vr-update.xml, vr-add.xml, and vr-delete.xml. For entities assigned to remain, no operation is required. For entities assigned to update, add, and delete, we will generate a corresponding update, add, and delete list.\n(5) We generate O and O' according to the following two rules:\n(a) O = O\u00a1 \\ {(s, p, o)|(s, p, o) is a triple \u2208 O\u00a1 ands \u2208 addorp e \u2208 add or o \u2208 add}. That is, O is constructed as Oi without all the triples related to entities in the add list.\n(b) Let e be an entity and A be a mapping of the form {e1 \u2192\ne', e2 \u2192 e'',... en \u2192 e\"\u2026' }. Then map(e, M) is defined to be e' if there is an e' such that e \u2192 e' \u2208 A and to be e otherwise. Now, O' = O\u00a1 \\ {(s, p, o)|(s, p, o) is a triple \u2208 O\u00a1 and s \u2208 delete orp \u2208 delete or o \u2208 delete} \u222a {(s', p', o')|(s, p, o) is a triple \u2208 O\u00a1 and s' = map(s, update) or p' = map(p, update) or o' = map(o, update)}. That is, O' is constructed as Oi without all the triples related to entities in the delete list and updated for all the triples related to entities in the update list.\nUnlike the original OAEI datasets for OM, randomness ensures that the synthetic OAEI datasets for OV are different each time they are constructed. This suits the dynamic nature of OV, where the changes vary between different versions. For this reason, we consider the new OAEI datasets for OV more like a testbed, as they can simulate a variety of situations for OV tasks."}, {"title": "3.4 Pipeline Optimisation", "content": "Often, ontology creators provide cross-references to other ontologies to enhance interoperability. For example, the cross-reference between the CMT ontology and the Conference ontology is provided along with the CMT ontology. Reusing these cross-references developed for OM tasks, we propose a novel mechanism to reduce matching candidates and also to improve overall OV performance.\nFigure 3 illustrates the cross-reference mechanism used in the OM4OV pipeline. We can see that, without using the cross-reference Or, the matching candidates cover the range of O\u222aO'. This number can be significantly reduced by removing prior matches (i.e. O\u2229 Or \u2229 O') and non-matches (i.e. O\u2229O,\\O' and O'\u2229O,\\O). The prior matching will be part of the final alignment, while the known non-matching will be completely removed in the subsequent OV process.\nThe OV process then only determines the posterior alignment. In practice, the prior alignment usually contains a large number of remain entities and a small number of update entities. Matching performance is also improved by using these known mappings.\nSince $A_{\\pi}$ are inferred from the OM references validated by domain experts, they represent a solid ground truth for alignment in a specific domain. On the other hand, while the known non-matches are removed from the OV process, this reduces the complexity of detecting the posterior alignment.\nGiven a reference ontology ($O_r$) with an old version of an ontology (O) and a new version of the same ontology (O'), two cross-references between O and Or ($R_{or}$) and between O' and Or ($R_{o'r}$) are defined as:\n$R_{or} = \\{(e_1, e_3, =, c) |e_1, e_3 \\in O, O_r, c \\geq s\\}$\n$R_{o'r} = \\{(e_2, e_3, =, c) | e_2, e_3 \\in O, O', c \\geq s\\}$ \nWe can use $R_{or}$ and $R_{o'r}$ to infer some known mappings between O and O' before performing OV. We call these mappings a prior alignment ($A_{\\pi}$). After subsequently performing OV, we have our posterior alignment ($A_{\\pi^*}$). Therefore, Amatch in OV can be decomposed into two parts:\n$A_{match} = A_{\\pi} \\cup A_{\\pi^*}$\n(1) $A_{\\pi}$ can be directly inferred from the two cross-references $R_{or}$ and $R_{o'r}$. The equivalence relation is transitive, so for $e_1 \\in O$, $e_2 \\in O'$, and $e_3 \\in O_r$, if $e_1 = e_3$ and $e_2 = e_3$ then $e_1 = e_2$.\n$A_{\\pi} = R_{or} \\cup R_{o'r} = \\{(e_1, e_2, =, c) |e_1, e_2 \\in O \\cap O_r \\cap O', c \\geq s\\}$\n(2) $A_{\\pi^*}$ aims to detect missing mappings from the cross-reference. None of these mappings would come from any pairwise intersection of O, Or, and O' because $O \\cap O_r \\setminus O'$ and $O' \\cap O_r \\setminus O$ are pre-defined as non-matched entities, and the matched entities in $O \\cap O_r \\cap O'$ have already been captured in the $A_{\\pi}$. As a result, $A_{\\pi^*}$ can be defined within a smaller scope:\n$A_{\\pi^*} = \\{(e_1, e_2, =, c) | e_1 \\in O \\setminus O_r, e_2 \\in O' \\setminus O_r, c \\geq s\\}$\nAn ontology can have multiple cross-references available. In such cases, the prior reference becomes the union of all known cross-references ($R_{or1}... R_{orn}$), and the ontology used in the posterior alignment ($O_{ra}$) become the union of all reference ontologies ($O_{r1} ... O_{rn}$). Therefore, $A_{\\pi}$ and $A_{\\pi^*}$ in multiple cross-references can be formulated as:\n$A_{\\pi} = (R_{or1} \\cap R_{o'r1}) \\cup (R_{or2} \\cap R_{o'r2}) \\cup...\\cup (R_{orn} \\cap R_{o'rn})$\n$A_{\\pi^*} = \\{(e_1, e_2, =, c) | e_1 \\in O \\setminus O_{ra}, e_2 \\in O' \\setminus O_{ra}, c \\geq s\\}$\nwhere $O_{ra} = O_{r1} \\cup O_{r2} \\cup... O_{rn}$\nOur cross-reference mechanism has no impact on our proposed measures for OV. However, our cross-reference mechanism is incorporated into our OV testbed. For this, Ror and Ro'r are created according to the following rules:\n(1) Ror is the original reference.xml removing all the mappings related to add entities.\n(2) Ro'r is the original reference.xml removing all the mappings related to delete entities and updating all the mappings related to update entities."}, {"title": "4 IMPLEMENTATION & EVALUATION", "content": "The OM4OV pipeline is implemented in Agent-OV, a variant of Agent-OM [17]. Agent-OM is an agent-powered LLM-based OM system. Its foundation framework is designed for traditional OM tasks. We extend the original framework with the OM4OV pipeline so that it can be used to handle OV tasks.\nWe use the LLM model gpt-4o-mini for evaluation. As an extension of Agent-OM, Agent-OV also supports a wide range of LLMs, including commercial API-accessed LLMs OpenAI GPT [14], Anthropic Claude [2], and Mistral AI [13], as well as open-source LLMs Meta Llama [12], Google Gemma [6], and Alibaba Qwen [1]. For the performance of Agent-OV using different LLMs, we refer the reader to [17], where we find that API-accessed LLMs generally perform better than open-source LLMs. The hyperparameter settings are set to similarity_threshold = 0.90 and top@k = 3 across all alignments generated from the OV testbed."}, {"title": "4.1 Evaluation of OV testbed", "content": "The current version of the OV testbed contains a total of 12 distinct ontologies from three different OAEI tracks. The anatomy track contains two large ontologies, while the MSE track has three medium ontologies, and the conference track has 7 small ontologies.\n(1) Our experiments show that the OM system achieves acceptable performance in tracking changes over different versions of the ontologies. Interestingly, the performance of our system on OV tasks is generally better than on OM tasks. This could be due to the fact that the ontologies used in the OV tasks are two versions of the same ontology that share consistent ontology design patterns.\n(2) For the four micro-level sub-measures, we observe:\n(a) The performance is highest in remain, followed by add and delete, and it is relatively low in update. This trend is consistent across different tracks and ontologies.\n(3) For the computational time, we observe a longer computation time for the large-scale ontologies in the Anatomy Track. Although Agent-OV has an optimisation module for the matching candidate selection process (inherited from Agent-OM), it is still not sufficient for some OV tasks."}, {"title": "4.2 Evaluation of pipeline optimisation", "content": "We apply the cross-reference mechanism on the same alignments that we evaluated in Section 4.1. Figure 7 shows the comparison of the OV performance with and without using the cross-reference (CR) mechanism to detect update entities. We can see that the CR mechanism significantly improves recall and precision in most ontologies, resulting in a solid improvement in the F1 score."}, {"title": "4.3 Evaluation of hyperparameter settings", "content": "Unlike OM tasks, changes in hyperparameter settings in OV tasks do not lead to a trade-off in precision and recall. Instead, the hyperparameter settings directly influence the sub-measures. Lower similarity thresholds and higher top@k values can result in more update entities being detected, while higher similarity thresholds and lower top@k values may find more add and delete entities. The hyperparameter setting has no impact on remain entities."}, {"title": "5 DISCUSSION", "content": "So far, we have experimentally validated the OM4OV pipeline with a novel cross-reference mechanism for pipeline optimisation. Although matching performance has been improved, it still does not achieve 100% as false mappings may still exist. Are these mappings genuinely false?\n(1) False mappings in OV can be a wrong ontology design choice. In the following example, the reference shows that cmt:writtenBy is updated to cmt:isWrittenBy, but the OV system will consider this entity to remain unchanged because a false mapping (cmt:writtenBy,\ncmt:writtenBy, =, 1) is detected in the remain subset. This issue is caused by incorrect name conventions. In the CMT ontology, cmt:hasAuthor and cmt:writtenBy are different entities because one is targeting the paper (cmt:Paper, cmt:hasAuthor, cmt:Author) and one is targeting the review (cmt:review, cmt:writtenBy, cmt:reviewer). However, using cmt:writtenBy for paper still makes sense (cmt:Paper, cmt:writtenBy, cmt:Author). Within one ontology, the meaning of two entities is too close to be distinguished and therefore leads to them being synonyms for each other. Ideally, we should avoid this type of ontology design. This example also demonstrates a unique benefit of using OM for OV, which could potentially aid in a more effective ontology design.\n$cmt: hasAuthor \\implies cmt: written By$\n$cmt: written By \\implies cmt: is Written By$\n(2) False mappings in OV can be an ambiguous \u201cequivalent\u201d relationship. In the following example, the reference shows that cmt:ConferenceChair can be updated to cmt:General_Chair to indicate a specific type of chair responsible for coordinating the conference. However, the OV system may predict that cmt:ConferenceChair is equivalent to cmt:Chair. This interpretation is not wrong but follows a different ontology design pattern. It is important to notice that the term \"equivalent\" in OV is weaker than that in OM. OV allows for roughly equivalent\u201d mappings. The entities mapped in OV can slightly alter their meanings in response to changes in the domain knowledge understanding.\n$cmt: Chairman \\implies cmt: Chair$\n$cmt: Conference Chair \\implies cmt: General_Chair$\n(3) False mappings in OV can be an inappropriate setup on the similarity threshold. In the following example, if similarity_threshold = 0.95, cmt:SubjectArea in O will be assigned to delete entities as it does have matching entities; If similarity_threshold = 0.90, cmt:SubjectArea in O will be assigned to update entities as it has a matching entity cmt:Topic in O'. Both results are valid because defining the boundary between matching and non-matching is context- and application-dependent. For example, the similarity threshold is relatively higher in the biomedical domain to ensure each terminology is unique, whereas the similarity threshold in the conference domain can be relatively lower to improve the interoperability of terminologies used in research conferences.\n$similarity\\_threshold = 0.95, cmt: SubjectArea \\implies None$\n$similarity\\_threshold = 0.90, cmt: SubjectArea \\implies cmt: Topic$"}, {"title": "6 LIMITATIONS", "content": "(1) We focus mainly on tracking conceptual changes of classes and properties (e.g. adding, deleting, or updating a class). In practice, there are also internal relationship changes (e.g. changing the domain and range of a class or moving a sibling class to a different parent). These changes are currently only indicated by the changes in the similarity score, while details can only be observed by inspecting the classes and properties. Our future work aims to improve the explainability of changes.\n(2) While OM has a universal measure, our proposed measures for OV have four sub-measures. It is necessary to find a single universal measure combining these sub-measures so that we can fairly assess and compare the system performance in OV and OM. We plan to investigate a merged formula for OV sub-measures in the future. For example, using a harmonic mean to combine sub-measures."}, {"title": "7 CONCLUSION", "content": "In this paper, we systematically analyse the similarities and differences between the OM and OV tasks and validate that they can share a unified pipeline with the necessary modifications. We propose a novel OM4OV pipeline with a cross-reference mechanism that leverages OM for OV. The new pipeline (1) overcomes several pitfalls in using OM for OV tasks, (2) significantly reduces the matching candidates, and (3) improves overall performance. We incorporate the OM4OV pipeline into a new OV system called Agent-OV, a functional extension of Agent-OM to handle OV tasks. Evaluations of three OAEI datasets validate the feasibility and reliability of our system. We also argue that the false mappings detected by OV systems are not necessarily actual false mappings.\nOur approach is compatible with ontologies using different versioning methods (using URIs or additional versioning triples), and even ontologies missing or without version information. Our approach stores the version information independently from the ontology, offering a simple and lightweight way to track versioning changes in ontologies."}]}