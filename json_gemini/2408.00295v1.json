{"title": "Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck", "authors": ["Yuntao Shou", "Haozhi Lan", "Xiangyong Cao"], "abstract": "Graph Neural Networks (GNNs) have received extensive research attention due to their powerful information aggregation capabilities. Despite the success of GNNs, most of them suffer from the popularity bias issue in a graph caused by a small number of popular categories. Additionally, real graph datasets always contain incorrect node labels, which hinders GNNs from learning effective node representations. Graph contrastive learning (GCL) has been shown to be effective in solving the above problems for node classification tasks. Most existing GCL methods are implemented by randomly removing edges and nodes to create multiple contrasting views, and then maximizing the mutual information (MI) between these contrasting views to improve the node feature representation. However, maximizing the mutual information between multiple contrasting views may lead the model to learn some redundant information irrelevant to the node classification task. To tackle this issue, we propose an effective Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (CGRL) for node classification, which can adaptively learn to mask the nodes and edges in the graph to obtain the optimal graph structure representation. Furthermore, we innovatively introduce the information bottleneck theory into GCLs to remove redundant information in multiple contrasting views while retaining as much information as possible about node classification. Moreover, we add noise perturbations to the original views and reconstruct the augmented views by constructing adversarial views to improve the robustness of node feature representation. Extensive experiments on real-world public datasets demonstrate that our method significantly outperforms existing state-of-the-art algorithms.", "sections": [{"title": "1. Introdution", "content": "Graph Neural Networks (GNNs) have attracted extensive attention from researchers due to the increase in large amounts of real-world graph-structured data [1, 2, 3, 4, 5, 6, 7, 8]. Meanwhile, GNNs are widely used in intelligent recommender systems, and social media fields because they provide a practical way to aggregate high-order neighbor information [9, 10, 11, 12, 13].\nAlthough GNNs have achieved reliable performance on node classification tasks, we argue that most of the node classification models based on GNNs suffer from the following two problems. i) Popularity Bias. As shown in"}, {"title": "2. Related Work", "content": "Graph Representation Learning Early work [33, 34, 35] have made great progress in representation learning tasks (e.g., node classification, entity alignment, and link prediction, etc). Specifically, GNNs on graph representation learning usually follow the information aggregation mechanism to update the feature representation of nodes, i.e., stimulating connected neighbor nodes to have similar semantic information. Inspired by GNNs, several works (e.g., AROPE [36], DeepWalk [37], and GraphSAGE [38], etc) on graph representation learning usually follows the label propagation mechanism to update the feature representation of nodes, i.e., stimulating connected neighbor nodes to have similar labels. In recent years, GNNs (e.g., GraphSMOTE [39], Nodeformer [40], DisGNN [41], and GraphFL [42], etc) have applied GNN algorithms to learn discriminative latent representations on node classification tasks [43, 44].\nContrastive Learning Contrastive learning (CL) [45, 46, 47], which is originally widely used in computer vision to obtain better image feature representations, has received extensive research attention in graph learning. Specifically, graph contrastive learning (GCL) learns discriminative node representations by maximizing mutual information (MI) between multiple graph views. For instance, DGI [14] learns more discriminative node representations by contrasting node embeddings of local and global graph views. GIC [48] maximizes the MI between node clusters with high similarity to make full use of coarse-grained and fine-grained information between nodes. CMC [46] maximizes MI by contrasting feature representations from different views. GMI [25] estimates and maximizes the MI between the input graph and the feature representation from two aspects of node features and network topology. Some recent self-supervised graph learning (SGLs) methods (e.g., MGAE [49], GraphMAE [50], and GAE [51]) generate multiple graph views of nodes and edges and force the consistency between different graph views. On the one hand, all these methods generate multiple contrasting graph views by randomly masking nodes or edges, which may cause some important structural and semantic"}, {"title": "Information-Bottleneck Representation Learning", "content": "The information bottleneck (IB) theory [27] argues that if the feature representation learned by the model from the input data discards information that is not useful for the given task while retaining as much as possible the information relevant to the given task, it will increase the generalization of downstream tasks. Formally, IB needs to construct multiple views for feature representation learning. Motivated by the effectiveness of the IB, several works have considered transferring information bottleneck theory to graph representation learning tasks. For instance, MIB [52] designs an unsupervised multi-view method and uses the information bottleneck theory to minimize the representation of redundant information. DeepIB [53] reduces redundant information irrelevant to a given task by minimizing mutual information between multiple views and input data. CMIB [28] combines information bottleneck theory to capture the complementarity of intrinsic information between different views and balance the consistency of multi-view latent representations. Nevertheless, almost all the above-mentioned methods aim to obtain a discriminative graph view to replace the original input graph, which may cause some semantic information and topological information of the original graph to be lost. In conclusion, existing information bottleneck methods for node classification suffer from insufficient information utilization, i.e., input graph information and multi-view information."}, {"title": "3. Preliminaries", "content": "Notations. Suppose G = {V,E,R, W} represents a graph where V = {U1, U2, ..., vm} is the nodes set, M is the number of nodes, E \u2286 V \u00d7 V represent the edges set, $r_{ij}$ ($r_{ij} \\in E$) represents the connection relationship between node i and node j, and $w_{ij}$ ($W_{ij} \\in W, 0 \\leq W_{ij} \\leq 1$) the weight of the edge Eij. The feature matrix and degree matrix of nodes are expressed as X = {$x_i$}$_{i=1}^{M}$ amd A = {$a_{ij}$} $\\in$ {$0,1$}$^{M \\times M}$, respectively, where xi represent the features of the node vi, and if (vi,vj) \u2208 E then aij = 1 otherwise aij = 0. G = G(x) is regarded as the process of graph processing.\nGCN Processing. For input features X \u2208 $\\mathbb{R}^{M \\times D}$, a graph G = F = G(X) is constructed based on the features X. A GCN layer is utilized to update features representations between nodes by aggregating information from their neighbor nodes. Specially, GCN operates as follows:\nG' = F(G,W)\n= Update (Aggregate (G, Wagg), Wupdate)\nWupdate = $\\frac{1}{|N_i|} \\sum_{r\\in R} \\sum_{j \\in N_i} (w_{ij} W_{agg} G_j + w_{ii}W_{agg}G_i)$\nwhere N is the set of neighbor nodes of node i under the edge relationship r \u2208 R, and Wagg and Wupdate represent the learnable weights of the nodes in aggregating surrounding neighbor nodes information and updating the aggregated features, respectively.\nIn addition, we also introduce a multi-head attention mechanism in the GNN layer to capture node feature information and topology information in a more fine-grained manner. The feature vectors x after being aggregated and updated is divided into N heads, i.e., h\u00b9, h\u00b2, . . .,hN, and each head is assigned a learnable parameter. Therefore, the feature vectors x is finally updated as follows:\nx = [h\u00b9Wupdate, h\u00b2 Wupdate,..., hN Wupdate],\nInformation Bottleneck (IB). IB is an information theory-based strategy that describes the information in the data that is relevant to downstream tasks. IB argues that if the obtained feature representation excludes semantic information in the original input that is irrelevant to a given downstream task, it improves the robustness of the model. Specifically, for a given input data x, with associated label information is y, using the IB strategy for model optimization can obtain a compact feature representation"}, {"title": "4. Methodology", "content": "In this section, we introduce our proposed Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (CGRL) method in detail.\n4.1. Automatically Generated Multi-view Augmentation\nAdversarial View. By adding perturbed adversarial examples to the original image views, the robustness of the model is significantly enhanced. This improvement can be attributed to a possible explanation that there is still non-predictive redundant information in the information shared between the two augmented views. When adversarial examples are introduced, this redundant information is weakened or eliminated, forcing the model to focus on more important and discriminative features. We define adversarial view as follows:\nG(1)adv = G + \u03b4*\n\u03b4* = argmaxLadv (GED, GND, G + d)\n||\u03b4||\n= argmax max [LCL (GND, G + \u03b4*)\n\u03b4\u03b5\u03b4adv\n+LCL (GED, G+ \u03b4*)]\nwhere G = {V', E',R',W'}, V = {01, 02,..., vm}, dis the randomly initialized Gaussian noise, LCL is the in-foNCE loss, e is the radius. Inspired by recent work [55],\nwe add a perturbation d to the output of the first hidden layer. It has been empirically shown that it can more effectively perturb the intermediate representation of the model than adding perturbations to the initial node features, allowing the model to learn and predict in more complex environments.\nNode-Masking View. As shown in Fig. 1, both the category of nodes and the degree of nodes in citation data show data imbalance, which hinders GCN from learning the feature representation of minority class nodes. Therefore, we perform automatic learnable node masking before each information aggregation and feature update of GCN to alleviate the shielding effect of influential nodes on minority class nodes. The node-masking view we created is formulated as follows:\nGND = {{v(1)i\u03b7 | vi \u2208 v'},E', R', W'}\nwhere $\u03b7 \\in$ {0, 1} is sampled from a parameterized Bernoulli distribution Bern(wi), and $\u03b7 = 0$ represents masking node vi, $\u03b7 = 1$ represents keeping node vi.\nRandomly removing some nodes and their connections in the graph may result in a large loss of minority class node information, thereby affecting the information aggregation of minority class nodes and leading to unsatisfactory classification results. Therefore, instead of directly removing the selected nodes from the graph, we replace the selected nodes by sampling the representation of the local subgraph using a random walk strategy to obtain a local representation of the node.\nEdge Perturbation View. The goal of perturbing edges is to generate an optimized graph structure that filters noisy edges and alleviates the problem of popularity bias. The edge perturbation view is formulated as follows:\nGED = {V', {e(1)ijnij|ej \u2208 E', R', W'}\nwhere $\u03b7 \\in$ {0,1} is also sampled from a parameterized Bernoulli distribution Bern($w_{ij}$), and $\u03b7 = 0$ represents perturbating edges eij, $\u03b7 = 1$ represents keeping edge lij.\nTo enable the model to automatically learn whether to mask nodes and perturb edges, we formally define the learnable parameter wi and $w_{ij}$ as follows:\nw(1)i = Lineare([e(1)i]);\nw(1)ij = Lineare(([e(1)i;e(1)j]))\nTo ensure that the model can automatically optimize and generate augmented multi-views in an end-to-end learning method, we use reparameterization technology [56] to convert the discretized \u03b7 into a continuous function. The formula is defined as follows:\n$N_i = \\frac{exp ((log (\u03c0_i) + g_i) /T)}{\\sum_{j=1}^{m} exp ((log (\u03c0_j) + g_j) /T)},  for i = 1,...,m$\nwhere gi = -log (-log ($\u20ac_i$)), \u20ac\u00a1 ~ Uniform(0,1), \u05d3\u2208R+ means annealing temperature, \u05d3 represents the class probability, and m represents number of categories.\nAfter obtaining the masked node and edge perturbed views, we input them into GCN for feature representation to obtain optimized multi-views. The formula is defined as follows:\nEND = GraphConv (E(1)ND, GND)\nEED = GraphConv (E(1)ED, GED)\nwhere GraphConv represents the graph convolution operation, and we choose GAT as our graph encoder. END and EED represent the node feature representations of node-masking view and edge perturbation view respectively, GND and GED represent node-masking view and edge perturbation view respectively.\n4.2. Contrastive Learning via IB\nAlthough CGRL combines an automatic learnable view augmentation and a node classification process for model optimization, we argue that relying solely on the classification objective does not well guide the node masking and edge perturbation process to create optimal multi-views. Therefore, we follow the information bottleneck strategy [27] to retain sufficient semantic information relevant to downstream tasks in the augmented node mask and edge perturbation views. Specifically, unlike traditional CL strategies, we encourage maintaining topological heterogeneity between the augmented view and the original graph while maximizing the information relevant to the node classification task. Based on the above strategy, we can obtain topologically heterogeneous but semantically similar enhanced multi-view representations and effectively remove noise information in the graph. Therefore, the objective in Eq. 3 is summarized as:\nmin LCLS + I(E, \u00c9)\n(E,E)\nn\u2211\n= -\u2211yilog(\u0177) + I(E, \u00c9)\ni=1\nwhere LCLS represents the cross-entropy loss, I(E, \u00c9) represents the mutual information between the original view and the augmented view.\nFollowing [57, 58], minimizing the lower bound of mutual information (i.e., Eq. 9) is equivalent to maximizing the InfoNCE loss [59]. Therefore, we adopt negative In-foNCE to optimize the feature representation between the augmented view and the original graph. Specifically, we treat the same node representations in the original graph and the automatically generated view as positive pairs (i.e., {(e, e) v \u2208 V'}), and different node representations"}, {"title": "Adversarial Cross-view Reconstruction", "content": "To further achieve feature disentanglement, we propose a cross-view reconstruction mechanism. Specifically, we hope that the representation pairs within and across enhanced views can recover the original data. More specifically, we define (END, EED), (E, EED), (E, EED) as a cross-view representation pair, and repeat the reconstruction process on it to predict the original view, aiming to ensure that END, EED, E are optimized to approximately disentangle each other. Intuitively, the reconstruction process is able to separate the information of the shared feature set from the information in the unique feature set between the two enhanced views. We formally define the reconstruction process as:\nLrecon =$\\frac{1}{2N}$ [||E \u2013 END||2 + ||E - EED||2]\nwherer N represents the number of nodes.\n4.4. Model Training\nWe train the model with the goal of optimizing the node mask view, edge perturbation view, and node classification:\nL = LCLS + aLCLS + (1 - aLELS)\n+ \u03b2 (\u0399 (E, END) + I (E, EED)) + Lrecon + 1||||"}, {"title": "5. Theoretic Analysis", "content": "Theorem 1. Specifically, we regard the augmented view as G, the noisy view as G', and the node label information as YCLS. We assume that \u0177 is not related to the classification information YCLS. Therefore, the upper bound of I (G;G) is defined as follows:\nI (\u00ce,\u011e) \u2264 I(G,\u011e) \u2013 I (YCLS, 9)\nProof. We assume that the clean graph G is defined by G' and label information Y, and we can get (G', YCLS) \u2192 G\u2192 G according to the Markov chain [60]. Therefore, we can get:\nG\nI(G,\u011e) \u2265 I ((YCLS, \u00ce),\u011e)\n= I (\u011c,\u011e) + I (YCLS, \u011e | \u011c)\n= I (\u011c,\u011e) + H (YCLS | G) \u2013 H (YCLS | \u011c,\u011e)\nBecause there is no correlation between G and YCLS, H(YCLS | \u011e) = H(YCLS). Furthermore, H (YCLS | \u011c,\u011e) \u2264 H (YCLS). Therefore, we simplify the Eq. 22 as follows:\nI(G,\u011e) \u2265 I (\u011c,\u011e) + H (YCLS) H (YCLS | G)\n= I (\u011c,\u011e) + I (YCLS,\u011e)\nTherefore, we prove that Eq. 21 holds. In summary, we provide a theoretical basis to ensure that graph contrastive learning via information bottlenecks can achieve noise invariance by reducing redundant and interfering information in augmented views.\nTheorem 2. We optimize the reconstruction by minimizing the entropy H (E | END, EED). Ideally, when H(E | END, EED) \u2013 EE, END,EED [logp(E | END, EED)] = 0, we achieve the best feature disentanglement. However, in practice, the estimation of conditional probability P(E | END, EED) is very tricky and complicated. Therefore, we use an approximate variational distribution q(E | END, EED) to simplify the calculation and optimization process. We provide a theoretical upper bound on H(E END, EED) as follows:\nH(E | END, EED) \u2264 max{||E \u2013 END ||2, ||E \u2013 EED ||2}\nProof. For a given original view E and two augmented views END and EED, we have:\nP(END, EED) = p (END) P (EED)\nP(END, EED | E) = p (ENDE) P (EED |E)\nLemma 1. For three given random variables a, b, c, if p(b, c) = p(b)p(c) and p(b,c | a) = p(b | a)p(c | a), then I(a, b | c) = I(a, b). Based on the definition of mutual information, we deduce:\nI (a; b | c) =\n=\n= \u03a3\u03a3\u03a3p (a, b, c) log abc p (a,b,c) p (c) p (a, c) p (b, c)\n= p (a)p (b, c | a) log p (ca) p (b) p (c)\nabc\n\u03a3\u03a3\u03a3p(a)p(ba) p (c | a) log p(ba) p (ca) p (b) p (c)\nab\n\u03a3\u03a3p(a)p (ba) log\n= \u03a3\u03a3p (a, b) log P (ba)\na b\np(b) p(a)p (b)\n= I (a;b)\nAccording to Lemma 1, we can derive the theoretical bound of I(E; END, EED) as follows:\nI (E; END, EED)\n= I (E; END | EED) + I (E; END) + I (E; EED)\n\u2265 I(END, EED; E)\n= I(END; E) + I(EED; E)\n> I (END; EED)\nAssuming q is a Gaussian distribution, the reconstruction process can be equivalent to minimizing the information entropy and its theoretical upper bound is formally defined as follows:\nH(E | END, EED) \u2264 max{||E \u2013 END||2, ||E \u2013 EED||2}\nProof. The estimation of conditional probability p(E | END, EED) is very tricky and complicated. Therefore, we use an approximate variational distribution q(E | END, EED) to simplify the calculation and optimization process. Therefore, we have,\nH(E END, EED)\n= -Ep(E|END,EED) [log p (E | END, EED)]\n< -Ep(E|END,EED) [log q (E | END, EED)]\nDKL (P (E | END, EED) ||q (E | END, EED))\nAssume q (E END, EED) is a Gaussian distribution N (E | END, EED, 021):\nH(E END, EED)\n<-Ep(E|END,EED) [log q (E | END, EED)]\n= -Ep(E|END,EED) log [- e2\u03c0\u0399\u03c3 (E-END,ED})\u00b2\n= -Ep(E|END,EED) log - 2\u03c0\u0399\u03c3 e (21) (E- END,ED})\u00b2]\nTherefore, we get the upper bound of H(E | END, EED)."}, {"title": "6. Experiments", "content": "6.1. Experimental Setup\nDatasets Description In our experiments, seven publicly available benchmark datasets are used including two Amazon items datasets [61] (i.e., Computers, and Photo), five citation network datasets [62] (i.e., Citeseer, Pubmed, DBLP, CoraFull, and Cora), three large-scale datasets [63] (i.e., Ogbn-arxiv, Ogbn-mag, and Ogbn-products), page network datasets [64, 65] (i.e., Wiki-CS and Croco).\nEvaluation Metrics We use classification accuracy to evaluate the performance of our method CGRL and other comparative methods.\nComparison Methods We compare our method CGRL with twelve state-of-the-art deep learning-based algorithms, including two traditional graph embedding algorithms (i.e., raw features [66], and DeepWalk [37]), three semi-supervised algorithms (i.e., GCN [67], NIGCN [73], and GAT [68]), and nine self-supervised algorithms (i.e., GAE [69], VGAE [69], DGI [14], GCA [18], MVGRL [71], GIC [48], GRACE [70], GMI [25], and CRLC [72]).\nSetting-up All the experiments in this paper are implemented on a server with 2 A100 (total 160GB memory). For each experiment, we run the code five times with a random seed to obtain the final mean and corresponding standard deviation to avoid experimental chance. Futhermore, for some parameter settings of the model, we set epochs to 1000/300, batch-size to full-batch/mini-batch, learning rate to 0.005, mask rate to 0.5, a to 0.5, \u03b2is 0.5, the activation function to GELU, dropout is 0.2, the weight decay to 1e-4, learning rate scheduling to cosine, warmup epochs to 100, and hidden size to 128. We utilize the Adam optimization algorithm to update parameters.\n6.2. Results and Analysis\nNode classification. Tables 1 and 2 summarize the node classification accuracy of the baselines and the proposed method CGRL on twelve real graph-structured data sets. Specifically, our approach leverages traditional graph embedding algorithms (i.e., raw features and DeepWalk). For example, our method CGRL improves the average accuracy by 20.31% and 10.76% compared to raw features and DeepWalk methods respectively. Compared with self-supervised methods (e, g., DGI, and GCA, etc.), CGRL also achieves better performance. In addition, CGRL also outperforms semi-supervised algorithms (i.e., GCN,NIGCN, and GAT). The performance improvement may be attributed to the design of the multi-view contrast learning strategy for adaptive masking nodes and perturbed edges, which enables the model to automatically learn whether to mask nodes and perturbed edges. To ensure that our model can reconstruct nodes and edges, we use a random walk strategy to sample the node's subgraph structure to blur its representation. However, most other baselines perform multi-view contrastive learning by randomly dropping nodes and edges, which will seriously destroy the semantic information of the graph. In addition, we also introduce the information bottleneck theory to ensure that the augmented views are structurally heterogeneous but semantically similar. The intuition behind this is that maximizing the mutual information between multiple views will lead to a consistent representation of the augmented views learned by the model, which leads to overfitting of the model.\nEffect of noise. In order to verify the anti-interference ability of our model CGRL, we perform experiments to demonstrate the performance by varying the noise rate in {0, 0.1, 0.2, 0.3, 0.4,0.5} and the \u1e9e in {0.1,0.2, 0.3, 0.4, 0.5 , 0.6, 0.7, 0.8, 0.9}. The experimental results are shown in Fig. 3, We can find that when the parameter \u1e9e is 0, CGRL has the worst effect on the Cora, Citeseer and PubMed data sets. When \u1e9e is greater than 0, CGRL's anti-interference ability is significantly reflected, and the best effect is in the range of 0.2 to 0.6. The experimental results show that the introduction of information bottleneck theory can enhance the noise invariance ability of the model.\nHyper-parameter analysis. We set two hyperparameters a and \u1e9e during the model optimization process. Their settings will have a relatively large impact on the performance of the model. Therefore, we also investigated the impact of hyperparameters on CGRL. We performed the node classification task by varying a and \u1e9e from 0.1 to 0.9 and visualized the accuracy in Fig. 4. When a and B are set to relatively large values, the node classification effect of the model is better, and when set to smaller values, the performance is poor. The difference in performance can be attributed to the inability of smaller parameter settings to eliminate redundant information in the graph structure and to obtain optimal augmented multi-view.\n6.3. Ablation Study\nWe performed three ablation experiments to verify the effectiveness of our proposed node-masking view, edge perturbation view, and information bottleneck theory.\n6.3.1. Effectiveness of adaptive graph contrastive learning via IB.\nWe perform ablation studies to analyze the impact of node-masking view, edge perturbation view, and IB criterion on experimental results. The experimental results are shown in Table 3. Firstly, when CGRL includes all modules, the accuracy of node classification on seven data sets is the highest. Secondly, We find that the node-masking view has a greater impact on the experimental results than the edge perturbation view. Experimental phenomena show that node classification mainly depends on the features of nodes. Thirdly, node-mask view and edge perturbation view combined with IB accuracy can further improve the accuracy of node classification. The performance improvement may be attributed that the IB criterion can promote multi-views to obtain structurally heterogeneous but semantically similar graph structures.\n6.3.2. Impact of GNN variants.\nWe explore the impact of different graph neural network variants on experimental results. As shown in Table 4, GAT has the best effect on seven graph structure"}, {"title": "6.3.3. Effectiveness of multi-view optimization.", "content": "We perform ablation experiments to verify the impact of multi-view augmentation on the optimization process of model training. The experimental results are shown in Fig. 5. On Cora, Citeseer, and PubMed datasets, we found that in the absence of node-masking view or edge perturbation view, the loss value of the model cannot converge to the optimal value, and the edge perturbation view has the worst convergence effect. When CGRL combines the node-masking view, edge perturbation view and information bottleneck criterion, the loss value of the model can converge to close to 0. The experimental results show that the performance of the augmented node-masking view is better than the augmented edge perturbation view, but worse than the augmented multi-view that combines information bottlenecks, which shows that the information bottleneck theory can further enhance the utilization of information."}, {"title": "6.3.4. Visualization.", "content": "We use the T-SNE method to project the high-dimensional node features into a 2-dimensional space and visualize them. The visualization results are shown in Figs. 6 and 7. In the"}, {"title": "7. Conclusions", "content": "In this paper, we propose a Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck for node classification to automatically generate structurally heterogeneous but semantically similar multi-views. Specifically, CGRL can adaptively learn to mask nodes and perturb edges in the graph to obtain optimal graph structure representation. Furthermore, we innovatively introduce the information bottleneck theory into GCL to eliminate redundant information in multiple contrasting views while retaining as much information about node classification as possible. Moreover, we add noise perturbations to the original views and reconstruct the augmented views by constructing adversarial views to improve the robustness of node feature representation. Extensive experiments on real-world public datasets show that our approach significantly outperforms existing the SOTA algorithms."}]}