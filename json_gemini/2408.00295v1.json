{"title": "Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck", "authors": ["Yuntao Shou", "Haozhi Lan", "Xiangyong Cao"], "abstract": "Graph Neural Networks (GNNs) have received extensive research attention due to their powerful information aggregation capa-bilities. Despite the success of GNNs, most of them suffer from the popularity bias issue in a graph caused by a small number of popular categories. Additionally, real graph datasets always contain incorrect node labels, which hinders GNNs from learning effective node representations. Graph contrastive learning (GCL) has been shown to be effective in solving the above problems for node classification tasks. Most existing GCL methods are implemented by randomly removing edges and nodes to create multiple contrasting views, and then maximizing the mutual information (MI) between these contrasting views to improve the node feature representation. However, maximizing the mutual information between multiple contrasting views may lead the model to learn some redundant information irrelevant to the node classification task. To tackle this issue, we propose an effective Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (CGRL) for node classification, which can adaptively learn to mask the nodes and edges in the graph to obtain the optimal graph structure representation. Furthermore, we innovatively introduce the information bottleneck theory into GCLs to remove redundant information in multiple contrasting views while retaining as much information as possible about node classification. Moreover, we add noise perturbations to the original views and reconstruct the augmented views by constructing adversarial views to improve the robustness of node feature representation. Extensive experiments on real-world public datasets demonstrate that our method significantly outperforms existing state-of-the-art algorithms.", "sections": [{"title": "1. Introdution", "content": "Graph Neural Networks (GNNs) have attracted exten-sive attention from researchers due to the increase in large amounts of real-world graph-structured data [1, 2, 3, 4, 5, 6, 7, 8]. Meanwhile, GNNs are widely used in intelli-gent recommender systems, and social media fields because they provide a practical way to aggregate high-order neigh-bor information [9, 10, 11, 12, 13].\nAlthough GNNs have achieved reliable performance on node classification tasks, we argue that most of the node classification models based on GNNs suffer from the fol-lowing two problems. i) Popularity Bias. As shown in Fig. 1, different categories of papers have different num-bers, and the number of citations of papers also varies, and this unbalanced learning can lead to the popularity bias problem in GNNs learning. In most node classifi-cation tasks, the categories and degrees of nodes follow a long-tail distribution, which means that popular categories have many papers, while most papers have few citations. In other words, most of the nodes have less interaction, which hinders the information update of the nodes. The above-mentioned popularity bias problem cause GNNs to tend to learn node representations that are popular and have many interactions, which hinders the representation learning of GNNs. ii) Noise Interference. There may be miscitations in the citation process of papers (i.e., there is a citation relationship between two unrelated papers in different fields), which leads to noise in the information contained in the data. Studies have shown that the fea-ture extraction ability of GCN is closely related to the quality of the input graph, which means that the input image with noise may cause the model to learn poor solu-tions. In response to the above problems, existing graph contrastive learning (GCL) methods [14, 15, 16, 17], [18], [19], [20], [21] propose an effective solution mechanism to alleviate popular bias and improve the robustness of the GCN model.\nNonetheless, the above-mentioned methods suffer from two limitations. 1) Most GCL methods perform data aug-mentation to optimize the graph structure by randomly masking nodes or perturbing edges. However, the strat-egy of randomly masking nodes and edge perturbations is too random, which may cause serious damage to the se-mantic information of the graph structure. For example, in the functional prediction of molecular structural proper-ties, if edges are randomly perturbed, the structural prop-erties of the molecule will change greatly. In addition, the interpretability that can alleviate popular paranoia and improve model robustness through the above methods is relatively poor. 2) The purpose of existing GCL methods [22, 23, 24], [25], [26] to generate multiple views through data augmentation is to maximize the mutual informa-tion between views, which may cause the model to capture task-irrelevant feature information. Inspired by the infor-mation bottleneck theory [27], we believe that a good GCL method should reduce as much redundant information as possible while retaining as much task-related information as possible.\nTo tackle the aforementioned issues, we propose a novel method called Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Informa-tion Bottleneck (CGRL) for node classification. CGRL consists of two key components: i.e., adaptive automatic generation of graph-augmented views and graph contrastive learning via information bottlenecks.\nFirst, this paper designs an automatic graph augmen-tation that adaptively learns node masks and edge pertur-bations to optimize the original graph into relevant views. In addition, SCGCL employs a joint training strategy to train an adaptive learnable view generator and node clas-sifier in an end-to-end manner, thereby generating aug-mented views with structural heterogeneity but seman-tic similarity. As a result, the generated augmented view can undersample the popular nodes in the original graph while retaining the majority of isolated nodes to allevi-ate the model's popularity bias problem. Intuitively, ran-dom masking nodes or perturbed edges do not consider the distribution probabilities and neighborhood informa-tion of different types of nodes in the original graph, but dropout them randomly. However, GCN based on mes-sage passing is difficult to reconstruct the information of isolated nodes and it is easier to optimize the semantic information of popular nodes. Therefore, the model may achieve better classification results on popular nodes and poor classification results on isolated nodes. The method CGRL proposed in this paper takes the augmented views of debias information and inputs them into GCN for node classification, which improves the model's ability to resist popular bias.\nSecond, we integrate multiple views that are semanti-cally similar and contain complementary information into a shared feature space for compact representation, which can improve the robustness of CGRL. The intuition be-hind is that when different views contain complementary semantic information, the model can obtain more prior knowledge to improve the performance of node classifica-tion tasks [28, 29, 30, 31]. However, we argue that maxi-mizing mutual information between different views forces the model to learn redundant information that is irrele-vant to downstream tasks. Inspired by the information bottleneck (IB) theory [32], it obtains optimal solutions by maximizing label information relevant to downstream tasks and minimizing mutual information between differ-ent views. Based on the IB strategy, an automatic graph augmenters learns to generate augmented views that re-move noise information and contain semantically similar and complementary views. In addition, when calculat-ing the contrastive loss, we not only use the node feature representations of the two augmented views, but also in-troduce the node feature representations of the original view perturbed in an adversarial manner as a third view. This additional adversarial view introduces perturbations that force the model to not only accurately distinguish the semantic features of the augmented views, but also to maintain an understanding of the semantic integrity of the original graph in the face of perturbations. Through multi-view adversarial reconstruction, we further improve the robustness of the feature representations.\nCompared with the previous methods, the contribu-tions of this paper method are summarized as:\nFirstly, we propose a Contrastive Graph Representa-tion Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (CGRL) for node classifica-"}, {"title": "2. Related Work", "content": "Graph Representation Learning Early work [33, 34, 35] have made great progress in representation learning tasks (e.g., node classification, entity alignment, and link prediction, etc). Specifically, GNNs on graph representa-tion learning usually follow the information aggregation mechanism to update the feature representation of nodes, i.e., stimulating connected neighbor nodes to have similar semantic information. Inspired by GNNs, several works (e.g., AROPE [36], DeepWalk [37], and GraphSAGE [38], etc) on graph representation learning usually follows the label propagation mechanism to update the feature rep-resentation of nodes, i.e., stimulating connected neighbor nodes to have similar labels. In recent years, GNNs (e.g., GraphSMOTE [39], Nodeformer [40], DisGNN [41], and GraphFL [42], etc) have applied GNN algorithms to learn discriminative latent representations on node classification tasks [43, 44].\nContrastive Learning Contrastive learning (CL) [45, 46, 47], which is originally widely used in computer vision to obtain better image feature representations, has received extensive research attention in graph learning. Specifically, graph contrastive learning (GCL) learns dis-criminative node representations by maximizing mutual information (MI) between multiple graph views. For in-stance, DGI [14] learns more discriminative node represen-tations by contrasting node embeddings of local and global graph views. GIC [48] maximizes the MI between node clusters with high similarity to make full use of coarse-grained and fine-grained information between nodes. CMC [46] maximizes MI by contrasting feature representations from different views. GMI [25] estimates and maximizes the MI between the input graph and the feature repre-sentation from two aspects of node features and network topology. Some recent self-supervised graph learning (SGLs) methods (e.g., MGAE [49], GraphMAE [50], and GAE [51]) generate multiple graph views of nodes and edges and force the consistency between different graph views. On the one hand, all these methods generate multiple con-trasting graph views by randomly masking nodes or edges, which may cause some important structural and semantic"}, {"title": "3. Preliminaries", "content": "Notations. Suppose $G = {V,E,R, W}$ represents a graph where $V = {U_1, U_2, ..., U_m}$ is the nodes set, M is the number of nodes, $E \\subseteq V \\times V$ represent the edges set, $r_{ij} (r_{ij} \\in E)$ represents the connection relationship between node i and node j, and $w_{ij} (W_{ij} \\in W, 0 \\leq W_{ij} \\leq 1)$ the weight of the edge $E_{ij}$. The feature matrix and degree matrix of nodes are expressed as $X = {x_i}_{i=1}^M$ amd $A = {a_{ij}} \\in {0,1}^{M\\times M}$, respectively, where $x_i$ represent the features of the node $v_i$, and if $(v_i,v_j) \\in E$ then $a_{ij}=1$; otherwise $a_{ij} = 0$. $G = G(x)$ is regarded as the process of graph processing.\nGCN Processing. For input features $X \\in \\mathbb{R}^{M\\times D}$, a graph $G = F = G(X)$ is constructed based on the features X. A GCN layer is utilized to update features representa-tions between nodes by aggregating information from their"}, {"title": "4. Methodology", "content": "In this section, we introduce our proposed Contrastive Graph Representation Learning with Adversarial Cross-view Reconstruction and Information Bottleneck (CGRL) method in detail.\n4.1. Automatically Generated Multi-view Augmentation\nAdversarial View. By adding perturbed adversar-ial examples to the original image views, the robustness of the model is significantly enhanced. This improvement can be attributed to a possible explanation that there is still non-predictive redundant information in the information shared between the two augmented views. When adver-sarial examples are introduced, this redundant information is weakened or eliminated, forcing the model to focus on more important and discriminative features. We define adversarial view as follows:\n$G^{(1)}_{adv}= G + \\delta*$\n(10)\n$\\delta* = argmaxL_{adv} (G_{ED}, G_{ND}, G + d)$\n$||\\delta||\\leq e$\n= argmax max $[L_{CL} (G_{ND}, G + \\delta*)$\n(11)\n$\\delta\\in \\delta$ $adv$\n$+L_{CL} (G_{ED}, G+ \\delta*)]$\nwhere $G' = {V', E',R',W'}$, $V = {v_1, v_2,..., v_m}$, d is the randomly initialized Gaussian noise, $L_{CL}$ is the in-foNCE loss, e is the radius. Inspired by recent work [55], we add a perturbation d to the output of the first hid-den layer. It has been empirically shown that it can more effectively perturb the intermediate representation of the model than adding perturbations to the initial node fea-tures, allowing the model to learn and predict in more complex environments.\nNode-Masking View. As shown in Fig. 1, both the category of nodes and the degree of nodes in citation data show data imbalance, which hinders GCN from learning the feature representation of minority class nodes. There-fore, we perform automatic learnable node masking before each information aggregation and feature update of GCN to alleviate the shielding effect of influential nodes on mi-nority class nodes. The node-masking view we created is formulated as follows:\n$G_{ND}^{(1)} = {{v \\odot \\eta | v \\in v'},E', R', W'}$ (12)\n(1)\nwhere $\\eta \\in {0, 1}$ is sampled from a parameterized Bernoulli distribution $Bern(w_i)$, and $\\eta$ = 0 represents masking node $v_i$, $\\eta$ = 1 represents keeping node $v_i$.\nRandomly removing some nodes and their connections in the graph may result in a large loss of minority class node information, thereby affecting the information aggre-gation of minority class nodes and leading to unsatisfac-tory classification results. Therefore, instead of directly removing the selected nodes from the graph, we replace the selected nodes by sampling the representation of the local subgraph using a random walk strategy to obtain a local representation of the node.\nEdge Perturbation View. The goal of perturbing edges is to generate an optimized graph structure that fil-ters noisy edges and alleviates the problem of popularity bias. The edge perturbation view is formulated as follows:\n$G_{ED}^{(1)} = {V', {e_{ij}\\odot \\eta_{ij} |e_{ij} \\in E', R', W'}}$ (13)\n(1)\nwhere $\\eta_{ij} \\in {0,1}$ is also sampled from a parameterized Bernoulli distribution Bern($w_{ij}$), and $\\eta_{ij} = 0$ represents perturbating edges $e_{ij}$, $\\eta = 1$ represents keeping edge $e_{ij}$.\nTo enable the model to automatically learn whether to mask nodes and perturb edges, we formally define the learnable parameter $w_i$ and $w_{ij}$ as follows:\n$w_i^{(1)} = Linear \\left (e_i^{(e)} \\right ) ; \n\\qquad w_{ij}^{(1)} = Linear \\left (\\left [e_i; e_j \\right ]\\right )$ (14)\nTo ensure that the model can automatically optimize and generate augmented multi-views in an end-to-end learn-ing method, we use reparameterization technology [56] to convert the discretized \u03b7 into a continuous function. The formula is defined as follows:\n$\\eta_i = \\frac{exp \\left ((log (\\pi_i) + g_i) /\\tau \\right )}{\\sum_{j=1}^m exp \\left ((log (\\pi_j) + g_j) /\\tau \\right )}, for i = 1,...,m$ (15)"}, {"title": "4.2. Contrastive Learning via IB", "content": "Although CGRL combines an automatic learnable view augmentation and a node classification process for model optimization, we argue that relying solely on the classi-fication objective does not well guide the node masking and edge perturbation process to create optimal multi-views. Therefore, we follow the information bottleneck strategy [27] to retain sufficient semantic information rel-evant to downstream tasks in the augmented node mask and edge perturbation views. Specifically, unlike tradi-tional CL strategies, we encourage maintaining topological heterogeneity between the augmented view and the orig-inal graph while maximizing the information relevant to the node classification task. Based on the above strategy, we can obtain topologically heterogeneous but semanti-cally similar enhanced multi-view representations and ef-fectively remove noise information in the graph. Therefore, the objective in Eq. 3 is summarized as:\nmin $L_{CLS} + I(E, \\acute{E})$\n$(E,\\acute{E})$\n=-$\\sum_{i=1}^{n}y_ilog(\\acute{y_i}) + I(E, \\acute{E})$ (17)\nwhere $L_{CLS}$ represents the cross-entropy loss, $I(E, \\acute{E})$ rep-resents the mutual information between the original view and the augmented view.\nFollowing [57, 58], minimizing the lower bound of mu-tual information (i.e., Eq. 9) is equivalent to maximizing the InfoNCE loss [59]. Therefore, we adopt negative In-foNCE to optimize the feature representation between the augmented view and the original graph. Specifically, we treat the same node representations in the original graph and the automatically generated view as positive pairs (i.e., ${(e,\\acute{e})|v\\acute{i}, v \\in V'}$, and different node representations"}, {"title": "4.3. Adversarial Cross-view Reconstruction", "content": "To further achieve feature disentanglement, we propose a cross-view reconstruction mechanism. Specifically, we hope that the representation pairs within and across en-hanced views can recover the original data. More specif-ically, we define ($\\acute{E}_{ND}, \\acute{E}_{ED}$), (E, $\\acute{E}_{ED}$), (E, $\\acute{E}_{ND}$) as a cross-view representation pair, and repeat the reconstruc-tion process on it to predict the original view, aiming to ensure that $\\acute{E}_{ND}$, $\\acute{E}_{ED}$, E are optimized to approximately disentangle each other. Intuitively, the reconstruction pro-cess is able to separate the information of the shared fea-ture set from the information in the unique feature set between the two enhanced views. We formally define the reconstruction process as:\n$L_{recon} = \\frac{1}{2N} [||E - \\acute{E}_{ND}|| + ||E - \\acute{E}_{ED}||^2]$ (19)\nwherer N represents the number of nodes."}, {"title": "4.4. Model Training", "content": "We train the model with the goal of optimizing the node mask view, edge perturbation view, and node classi-fication:\n$L = L_{CLS} + \\alpha L_{CLS}^{(ND)} + (1 - \\alpha) L_{CLS}^{(ED)}$ (20)\n$+ \\beta (I (E, \\acute{E}_{ND}) + I (E, \\acute{E}_{ED})) + L_{recon} + \\lambda||\\theta||^2$\nwhere $\\lambda$ and $\\beta$ represent the learning weights of L2 reg-ularization and information bottleneck contrast learning respectively."}, {"title": "5. Theoretic Analysis", "content": "Theorem 1. Specifically, we regard the augmented view as G, the noisy view as $\\acute{G}$, and the node label in-formation as $Y_{CLS}$. We assume that $\\hat{g}$ is not related to the classification information $Y_{CLS}$. Therefore, the upper bound of $I (\\hat{G};\\acute{G})$ is defined as follows:\n$I (\\hat{G},\\acute{G}) \\leq I(G,\\acute{G}) - I (Y_{CLS},\\acute{G})$ (21)\nProof. We assume that the clean graph G is defined by $\\acute{G}$ and label information Y, and we can get ($\\acute{G}', Y_{CLS}$) $\\rightarrow$"}]}