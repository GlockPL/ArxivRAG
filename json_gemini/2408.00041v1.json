{"title": "Con4m: Context-aware Consistency Learning Framework for Segmented Time Series Classification", "authors": ["Junru Chen", "Tianyu Cao", "Jing Xu", "Jiahe Li", "Zhilong Chen", "Tao Xiao", "Yang Yang"], "abstract": "Time Series Classification (TSC) encompasses two settings: classifying entire se- quences or classifying segmented subsequences. The raw time series for segmented TSC usually contain Multiple classes with Varying Duration of each class (MVD). Therefore, the characteristics of MVD pose unique challenges for segmented TSC, yet have been largely overlooked by existing works. Specifically, there exists a natural temporal dependency between consecutive instances (segments) to be clas- sified within MVD. However, mainstream TSC models rely on the assumption of independent and identically distributed (i.i.d.), focusing on independently modeling each segment. Additionally, annotators with varying expertise may provide incon- sistent boundary labels, leading to unstable performance of noise-free TSC models. To address these challenges, we first formally demonstrate that valuable contextual information enhances the discriminative power of classification instances. Leverag- ing the contextual priors of MVD at both the data and label levels, we propose a novel consistency learning framework Con4m, which effectively utilizes contextual information more conducive to discriminating consecutive segments in segmented TSC tasks, while harmonizing inconsistent boundary labels for training. Extensive experiments across multiple datasets validate the effectiveness of Con4m in handling segmented TSC tasks on MVD.", "sections": [{"title": "1 Introduction", "content": "Time Series Classification (TSC) is one of the most challenging problems in the field of machine learning. TSC aims to assign labels to a series of temporally ordered data points. These points either form a complete sequence or are subsequences (segments) resulting from the segmentation of a long time series. Existing works [46, 18] largely focus on the assumption of independent and identically distributed (i.i.d.), in which case each sequence or segment is regarded as an independent instance to be classified, not differentiating between these two settings. In fact, for many practical applications, the raw time series before segmentation for segmented TSC tasks contain Multiple classes with Varying Duration of each class (MVD). For example, in the healthcare domain, the brain signals of"}, {"title": "2 Theoretical Analysis", "content": "In this section, we aim to formally demonstrate the benefit of contextual information for classification tasks, and to establish the existence of an upper bound for this benefit. Consequently, by introducing prior knowledge, we can guide the model to focus on valuable contextual information more conducive to improving the benefit for segmented TSC tasks.\nAssuming that the random variables of the instances to be classified and the corresponding labels are denoted as $x_t$ and $y_t$.  $x_t^{A+}$ represents the contextual instance set introduced for $x_t$. $X_{A+}$ denotes the random variable for the contextual instance set. Mutual information measures the correlation between two random variables. In a classification task, a higher correlation between instances and labels indicates that the instances are more easily distinguishable by the labels. This benefits the classification task, making it more readily addressable. Therefore, from an information-theoretic perspective, we elucidate the benefit of contextual information through the following theorem.\nTheorem 2.1. The more the introduced contextual instance set enhance the discriminative power of the target instance, the greater the benefit for the classification task.\nProof. Firstly, we establish that the introduction of contextual information does not compromise classification tasks, i.e., it does not diminish the correlation between instances and labels.\n$I(y_t; x_t, X_A) = I(y_t; x_t^{A+} | X_t) + I(y_t; x_t) \\ge I(y_t; x_t)$.\n(1)\nThe inequality holds due to the non-negativity of conditional mutual information.\nAccording to (1), the increase in $I(y_t; x_t^{A+} | X_t)$ determines the extent to which the introduction of contextual information can be beneficial for classification tasks. Expanding $I(y_t; x_t^{A+} | X_t)$, we have:\n$I(y_t; x_t^{A+}|x_t) = \\sum_{X_t} P(x_t) \\sum_{X_{At}} \\sum_{Y_t} P(y_t, X_{At}|x_t) \\log \\frac{P(y_t, X_{At}|x_t)}{P(y_t|x_t)p(X_{At}|x_t)}$"}, {"title": "3 The Con4m Method", "content": "In this section, we introduce the details of Con4m. Based on the insights of Theorem 2.1, we introduce contextual prior knowledge of data locality (Sec. 3.1) and label coherence (Sec. 3.2) to guide the model to focus on contextual information more conducive to discriminating consecutive segments in segmented TSC tasks. In Sec. 3.3, inspired by the idea of noisy label learning, we propose a label harmonization framework to achieve a more robust model. Before delving into the details of Con4m, we provide the formal definition of the segmented TSC task in our work.\nDefinition 3.1. Given a time interval comprising of $T$ consecutive time points and labels, denoted as $(X,Y) = \\{(X_1, Y_1), (X_2,Y_2), . . ., (X_T, Y_T)\\}$, a $w$-length sliding window with stride length $r$ is em- ployed for segmentation. $(X,Y)$ is partitioned into $L$ time segments, represented as $(x,y) = \\{(\\textbf{X}_i, y_i) = (\\{X_{(i-1)\\times r+1},..., X_{(i-1)\\times r+w}\\}, Majority(\\{Y_{(i-1)\\times r+1},..., Y_{(i-1)\\times r+w}\\})\\}|i = 1, . . ., L\\}$. The model is tasked with predicting segmented labels $y_i$ for each time segment $x_i$.\n3.1 Continuous Contextual Representation Encoder\nLocal continuity is an inherent attribute of MVD, meaning each class should be locally continuous and only change at its actual boundary. Smoothing with a Gaussian kernel [17, 15, 62] promotes the continuity of representations of time segments in a local temporal window. This not only helps the model make similar predictions of consecutive segments within the same class but also aligns with the gradual nature of class transitions. Furthermore, for graph neural networks based on the homophily assumption, aggregating neighbor information belonging to the same class can improve the discriminative power of the target instance [45, 69]. Therefore, we introduce the Gaussian prior to guide the model to focus on contextual instances $X_t$ proximate to the target instance.\nVanilla self-attention [14] with point-wise attention computations often fail to obtain continuous representations after aggregation. Therefore, we use the Gaussian kernel $\\Phi(x, y|\\sigma)$ as prior weights to aggregate neighbors to obtain smoother representations. Since the neighbors of boundary segments may belong to different classes, we allow each segment to learn its own scale parameter $\\sigma$. Formally,"}, {"title": "3.2 Context-aware Coherent Class Prediction", "content": "In the segmented TSC task of MVD, consecutive time segments not only provide contextual infor- mation at the data level but also possess their own class information. As depicted in Figure 1(a), considering the persistence of each class and the gradual nature of class transitions, the model's pre- dictions should exhibit more coherence and concentration, rather than being interspersed. Therefore, we integrate and constrain the model's predictions from both the individual and holistic perspectives to achieve more coherent predictions.\nNeighbor Class Consistency Discrimination. In graphs, label propagation algorithms [26, 29] are often utilized to refine and smooth the predictions of neighbor instances, thereby enhancing their discrimination. Drawing inspiration from this, by weightedly aggregating predictions from similar time segments, the model can focus on contexts $X_t$ more likely to belong to the same class as the target segment. Although there is no explicit graph structure between time segments, we can train a discriminator to determine whether two segments belong to the same class. The model then aggregates the contextual class predictions based on the discriminator's outputs, thus making more robust predictions. As the left part of Figure 3 shows, we formalize this process as follows:\n$R = SoftMax ([MLP_2 (c_i||c_j)]_{i,j\\in\\{1,...,L\\}}), p = SoftMax (MLP_1 (c)), p = R \\cdot_i p,$\nwhere $R \\in \\mathbb{R}^{L\\times L\\times 2}$ is the probability of whether two segments in the same time interval belong to the same class and $(\\cdot||\\cdot)$ denotes tensor concatenation. We then define the two training losses as $l_1 = CrossEntropy (p, y)$ and $l_2 = CrossEntropy(R, \\tilde{Y})$, where $\\tilde{Y} = [1_{y_i=y_j}]_{i,j\\in\\{1,...,L\\}}$. Given that $l_1$ and $l_2$ are of the same magnitude, we equally sum them as the final loss.\nPrediction Behavior Constraint. Unlike graphs, there exists a holistic temporal relationship between consecutive time segments. Therefore, we should further constrain the overall predictive behavior along the time axis. For MVD, as Figure 1(a) shows, within a suitably chosen time interval, consecutive segments almost span at most two classes. Therefore, we ensure the monotonicity of"}, {"title": "3.3 Label Consistency Training Framework", "content": "Due to inherent ambiguity, the annotation of MVD often lacks quantitative criteria, resulting in experiential differences across individuals. Such discrepancies are detrimental to models and we propose a training framework to enable Con4m to adaptively harmonize inconsistent labels.\nLearning from easy to hard. We are based on the fact that although people may have differences in the fuzzy transitions between classes, they tend to reach an agreement on the most significant core part of each class. In other words, the empirical differences become more apparent when approaching the transitions. Therefore, we adopt curriculum learning techniques to help the model learn instances from the easy (core) to the hard (transition) part. Formally (see the diagram in Figure 1(b)), for a continuous $K$-length class, we divide it into $N_\\iota = 5$ equally sized levels as follows:\n$[(\\frac{1}{2N_{\\iota}}K), (\\frac{(N-1)}{2N_{\\iota}}K)], [(\\frac{(N+1)}{2N_{\\iota}}K), (\\frac{K}{2N_{\\iota}})], ..., [(\\frac{(2N_{\\iota}-1)}{2N_{\\iota}}K),(\\frac{K}{2N_{\\iota}})]$\n(2)\nThen we sample the same number of time intervals from each level. The higher the level, the more apparent the inconsistency. Therefore, as the right part of Figure 3 shows, during the training stage, Con4m learns the time intervals in order from low to high levels, with a lag gap of $E_\\eta = 5$ epochs.\nHarmonizing inconsistent labels. Inspired by the idea of noisy label learning, we gradually change the raw labels to harmonize the inconsistency. The model preferentially changes the labels of the core segments that are easier to reach a consensus, which can avoid overfitting of uncertain labels. Moreover, the model will consider both the independent and constrained predictions to robustly change inconsistent labels. Specifically, given the initial label $y_0$, we update the labels $y_e = arg\\ max \\ p_e$ for the $e$-th epoch, where $p_e$ is obtained as follows:\n$p_e = w_e \\cdot [p_{e-m}]_{m\\in\\{0,...,4\\}}, p_e = \\omega_e \\cdot [\\bar{p}_{e-m}]_{m\\in\\{0,...,4\\}},$"}, {"title": "5 Conclusion and Discussion", "content": "In this work, we focus on the raw time series MVD for segmented time series classification (TSC) tasks, demonstrating unique challenges that are overlooked by existing mainstream TSC models. We first formally demonstrate that valuable contextual information enhances the discriminative power of classification instances. Based on the insights, we introduce contextual prior knowledge of data locality and label coherence to guide the model to focus on contextual information more conducive to discriminating consecutive segments in segmented TSC tasks. Leveraging effective contextual information, a label consistency learning framework Con4m is proposed to progressively harmonize inconsistent labels during training. Extensive experiments validate the superior performance achieved by Con4m and highlight the effectiveness of the proposed consistent label training framework. Our work still has some limitations. We have solely focused on analyzing and designing end-to-end supervised models. Further exploration of large-scale models would be challenging yet intriguing. When faced with more diverse label behaviors, the function fitting module needs to engage in more selection and design of basis functions. Nevertheless, our work brings new insights to the TSC domain, re-emphasizing the importance of the inherent temporal dependence of time series."}, {"title": "A Details of Related Works", "content": "Time series classification (TSC). TSC has become a popular field in various applications with the exponential growth of available time series data in recent years. In response, researchers have proposed numerous algorithms [30]. High accuracy in TSC is achieved by classical algorithms such as Rocket and its variants [11, 12], which use random convolution kernels with relatively low computational cost, as well as ensemble methods like HIVE-COTE [40], which assign weights to individual classifiers.\nMoreover, the flourishing non-linear modeling capacity of deep models has led to an increasing preva- lence of TSC algorithms based on deep learning. Various techniques are utilized in TSC: RNN-based methods [50, 13] capture temporal changes through state transitions; MLP-based methods [19, 61] encode temporal dependencies into parameters of the MLP layer; and the latest method TimesNet [60] converts one-dimensional time series into a two-dimensional space, achieving state-of-the-art per- formance on five mainstream tasks. Furthermore, Transformer-based models [63, 9] with attention mechanism have been widely used.\nThe foundation of our work lies in these researches, including the selection of the backbone and experimental setup. However, mainstream TSC models [46, 18] are often designed for publicly avail- able datasets [3, 10] based on the i.i.d. samples, disregarding the inherent contextual dependencies between classified segments in MVD. Although some time series models [51, 47] use patch-by-patch technique to include contextual information, they are partially context-aware since they only model the data dependencies within each time segment, ignoring the dependencies between consecutive segments.\nNoisy label learning (NLL). NLL is an important and challenging research topic in machine learning, as real-world data often rely on manual annotations prone to errors. Early works focus on statistical learning [1, 37, 5]. Researches including Sukhbaatar et al. [53] launch the era of noise-labeled representation learning.\nThe label noise transition matrix, which represents the transition probability from clean labels to noisy labels [25], is an essential tool. Common techniques for loss correction include forward and backward correction [49], while masking invalid class transitions with prior knowledge is also an important method [22]. Adding an explicit or implicit regularization term in objective functions can reduce the model's sensitivity to noise, whereas re-weighting mislabeled data can reduce its impact on the objective [2, 65, 42]. Other methods involve training on small-loss instances and utilizing memorization effects. MentorNet [31] pretrains a secondary network to choose clean instances for primary network training. Co-teaching [23] and Co-teaching+ [66], as sample selection methods, introduce two neural networks with differing learning capabilities to train simultaneously, which filter noise labels mutually. The utilization of contrastive learning has emerged as a promising approach for enhancing the robustness in the context of classification tasks of label correction methods [39, 68, 28].\nThese works primarily focus on handling noisy labels. And ensuring overall label consistency by modifying certain labels is crucial for MVD. To the best of our knowledge, Scale-teaching [43] and SREA [8] are the only NLL works specifically designed for time series. Scale-teaching designs a fine-to-coarse cross-scale fusion mechanism for learning discriminative patterns by utilizing time series at different scales to train multiple DNNs simultaneously. SREA trains a classifier and an autoencoder with a shared embedding representation, progressively self-relabeling mislabeled data samples in a self-supervised manner. However, they still face the issue of overlooking contextual dependencies across consecutive time segments.\nCurriculum learning (CL). Bengio et al. [6] propose CL, which imitates human learning by starting with simple samples and progressing to complicated ones. Based on this notion, CL can denoise noisy data since learners are encouraged to train on easier data and spend less time on noisy samples [20, 56]. Current mainstream approaches include Self-paced Learning [36], where students schedule their learning, Transfer Teacher [59], based on a predefined training scheduler; and RL Teacher [21, 44], which incorporates student feedback into the framework. The utilization of CL proves to be particularly advantageous in situations involving changes in the training labels. Hence, this technique is utilized to enhance the harmonization process of boundary labels from MVD in a more stable manner.\nTemporal action segmentation (TAS). TAS is a critical task in video understanding and analysis. It involves segmenting an untrimmed video sequence into meaningful temporal segments and assigning a"}, {"title": "B Implementation Details of Prediction Behavior Constraint", "content": "To fit the hyperbolic tangent function (Tanh), we use the mean squared error (MSE) loss function. In practice, we use the Adam optimizer with a learning rate of 0.1 to optimize the trainable parameters. The maximum number of iterations is set to 100, and the tolerance value for stopping the fitting process based on loss change is set to 1e \u2013 6. Sequences belonging to one minibatch are parallelized to fit their respective Tanh functions. To adapt to the value range of the standard Tanh function, we rescale the sequential predictions to [-1, 1] before fitting.\nHowever, it can be difficult to achieve a good fit when fitting with the Tanh function. Specifically, random initialization may fail to fit the sequential values properly when a long time series undergoes a state transition near the boundary. For example, as Figure 6(a) shows, we fit a sequence in which only the last value is 1. We set all default initial parameters as 1 and fit it. It can be observed that the fitting function cannot properly fit the trend and will mislabel the last point.\nAppropriate parameter initialization is needed to avoid excessive bias. After careful observation, we find that parameter $k$ controls the slope at the transition part of Tanh, and parameter $b$ controls the abscissa at the transition point. In the process, all fitting values are assigned with uniform abscissa values. Therefore, we calculate the maximum difference between adjacent values and the corresponding position in the entire sequence. And these two values are assigned to parameters $k$ and $b$, respectively. This allows us to obtain suitable initial parameters and avoid getting trapped in local optima or saddle points during function fitting. Formally, given the L-length input sequence p, we initialize parameters k and b as follows:\n$d_i = [p_{i+1} - p_i]_{i\\in\\{1,...,L-1\\}},$"}, {"title": "C Hyperparameter Analysis", "content": "The dynamic weighting factor $\\eta$ is introduced to progressively update the labels, preventing the model from overly relying on its own predicted labels too early. To validate the utility of $\\eta$ and determine an appropriate linear growth epoch $E_\\eta$, we conduct the hyperparameter search experiment on SEEG data. As shown in Figure 7(b), with smaller $E_\\eta$ (corresponding to a higher growth rate), there is a significant improvement in model performance. This aligns with our motivation that during the early stage of model training, the primary objective is to better fit the original labels. At this stage, the model's own predictions are unreliable. If the predicted results are used as training labels too early in subsequent epochs, the model would be adversely affected by its own unreliability. On the other hand, excessively large $E_\\eta$ leads to a slower rate of label updates, making it more challenging for the model to timely harmonize inconsistent labels. Nonetheless, considering the impact of variance, the model exhibits robustness to slightly larger $E_\\eta$. In this work, we uniformly use $E_\\eta = 30$ as the default value."}, {"title": "D Details of Datasets", "content": "fNIRS. All signals are sampled at a frequency of 5.2Hz. At each time step, they record 8 real-valued measurements, with each measurement corresponding to 2 concentration changes (oxyhemoglobin and deoxyhemoglobin), 2 types of optical data (intensity and phase), and 2 spatial positions on the forehead. Each measurement unit is a micromolar concentration change per liter of tissue (for oxy-/deoxyhemoglobin). They label each part of the active experiment with one of four possible levels of n-back working memory intensity (0-back, 1-back, 2-back, or 3-back). More specifically, in an n-back task, the subject receives 40 numbers in sequence. If a number matches the number n steps back, the subject is required to respond accordingly. There are 16 rounds of tasks, with a 20-second break between each task. Following Huang et al. [27], we only apply classification tasks for 0-back and 2-back tasks in our work. Therefore, we only extract sequences for 0-back and 2-back tasks and concatenate them in chronological order.\nSleep. The Sleep-EDF database records PolySomnoGraphic sleep data from 197 subjects, including EEG, EOG, chin EMG, and event markers. Some data also includes respiration and temperature- related signals. The database contains two studies: the Sleep Cassette study and the Sleep Telemetry study. The former records approximately 40 hours of sleep from two consecutive nights, while the latter records around 18 hours of sleep. Well-trained technicians manually score the corresponding sleep graphs according to the Rechtschaffen and Kales manual. The data is labeled in intervals of 30"}, {"title": "E Implementation Details of Baselines", "content": "\u2022 SREA [8]: This time series classification model with noisy labels jointly trains a classifier and an autoencoder with shared embedding representations. It gradually corrects the mislabelled data samples during training in a self-supervised fashion. We use the default model architecture from the source code provided by the author (https://github.com/Castel44/SREA).\n\u2022 Scale-teaching [43]: This work designs a fine-to-coarse cross-scale fusion mechanism for learning discriminative patterns by utilizing time series at different scales to train multiple DNNs simultane- ously. It uses well-learned multi-scale time series embeddings for noise label correction at sample feature levels. We modify the code to match our datasets based on the code provided by the author (https://github.com/qianlima-lab/Scale-teaching).\n\u2022 SIGUA [24]: This model adopts gradient descent on good data as usual, and learning-rate-reduced gradient ascent on bad data, thereby trying to reduce the effect of noisy labels. We modify the network for time series data based on the open source code provided by SREA, using the code from the author (https://github.com/bhanML/SIGUA).\n\u2022 UNICON [32]: UNICON introduces a Jensen-Shannon divergence-based uniform selection mechanism and uses contrastive learning to further combat the memorization of noisy la- bels. We modify the model for time series data according to the code provided by the author (https://github.com/nazmul-karim170/UNICON-Noisy-Label)\n\u2022 Sel-CL [39]: Selective-Supervised Contrastive Learning (Sel-CL) is a latest baseline model in the field of computer vision. It selects confident pairs out of noisy ones for supervised contrastive learning (Sup-CL) without knowing noise rates. We modify the code for time series data, based on the source code provided by the author (https://github.com/ShikunLi/Sel-CL)\n\u2022 MiniRocket [12]: Rocket [11] achieves state-of-the-art accuracy for time series classification by transforming input time series using random convolutional kernels, and using the transformed features to train a linear classifier. MiniRocket is a variant of Rocket that improves processing time, while offering essentially the same accuracy. We use the code interface from the sktime package (https://github.com/sktime/sktime).\n\u2022 TimesNet [60]: This model focuses on temporal variation modeling. With TimesBlock, it can discover the multi-periodicity adaptively and extract the complex temporal variations from trans- formed 2D tensors by a parameter-efficient inception block. We use the code from the TSlib package (https://github.com/thuml/Time-Series-Library).\n\u2022 PatchTST [47]: This is a self-supervised representation learning framework for multivariate time series by segmenting time series into subseries level patches, which are served as input tokens to Transformer with channel-independence. We modify the code to achieve classifica- tion for each patch, based on the source code from the Time Series Library (TSlib) package (https://github.com/thuml/Time-Series-Library).\n\u2022 MS-TCN2 [38]: This work proposes two multi-stage architectures for the temporal action segmen- tation task. While the first stage generates an initial prediction, this prediction is iteratively refined by the higher stages. Instead of the commonly used temporal pooling, they use dilated convolutions"}, {"title": "F Implementation Details of Con4m", "content": "The non-linear encoder genc used in Con4m is composed of three 1-D convolution layers. The number of kernels vary across different data and you can find corresponding parameters in the default config file of our source code. We construct the Con-Transformer based on the public codes implemented by HuggingFace\u00b9. We set d=128 and the dimension of intermediate representations in FFN module as 256 for all experiments. The number of heads and dropout rate are set as 8 and 0.1 respectively. Since we observe that one-layer Con-Attention can fit the data well, we do not stack more layers to avoid overfitting. Note that Con4m consists of two Con-Transformers and we use two Con-Attention layers. The model is optimized using Adam optimizer [34] with a learning rate of 1e-3 and weight decay of 1e-4, and the batch size is set as 64. We build our model using PyTorch 2.0.0 [48] with CUDA 11.8. And the model is trained on a workstation (Ubuntu system 20.04.5) with 2 CPUs (AMD EPYC 7H12 64-Core Processor) and 8 GPUs (NVIDIA GeForce RTX 3090). You can find more technical details in our source code attached in the supplementary materials."}, {"title": "G Full Results", "content": "The full results of the label disturbance experiment are listed in Table 4, 5 and 6. For fNIRS, we first divide the data into 4 groups by subjects and follow the 2 training-1 validation-1 testing (2-1-1) setting to conduct cross-validation experiments. Therefore, there are $C^2_4 \\times C^2_4 = 12$ experiments in total. Similarly, we divide the Sleep data into 3 groups and follow the 1-1-1 experimental setting. Therefore, we carry out $C^3_3 \\times C^2_3 = 6$ experiments. For SEEG data, we follow the same setting as fNIRS. Notice that for SEEG data, inconsistent labels already exist in the raw data. We obtain a high-quality testing group by using a majority voting procedure to determine the boundaries. Then we leave the testing group aside and only change the validation group to report the mean value of $C^3_3 = 3$ experiments. All the experimental results are listed in lexicographical order according to the group name composition. We also report the mean value and standard derivation of all experiments. Specifically, we use the STDEVA to estimate standard deviation based on a sample of data."}, {"title": "H Case Study", "content": "As shown in Figure 8, we present four cases to compare and demonstrate the differences between our proposed Con4m and other baselines. The first two cases involve transitions from a seizure state of label 1 to a normal state of label 0. The third case consists of entirely normal segments, while the fourth case comprises entirely seizure segments. As illustrated in the figure, Con4m exhibits more coherent narratives by constraining the predictions to align with the contextual information of the data. Moreover, it demonstrates improved accuracy in identifying the boundaries of transition states. In contrast, other baselines exhibit fragmented and erroneous predictions along the time segments. This verifies that Con4m can achieve clearer recognition of boundaries, and it can also make better predictions on the consecutive time segments belonging to the same class."}]}