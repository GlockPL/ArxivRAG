{"title": "Con4m: Context-aware Consistency Learning Framework for Segmented Time Series Classification", "authors": ["Junru Chen", "Tianyu Cao", "Jing Xu", "Jiahe Li", "Zhilong Chen", "Tao Xiao", "Yang Yang"], "abstract": "Time Series Classification (TSC) encompasses two settings: classifying entire se- quences or classifying segmented subsequences. The raw time series for segmented TSC usually contain Multiple classes with Varying Duration of each class (MVD). Therefore, the characteristics of MVD pose unique challenges for segmented TSC, yet have been largely overlooked by existing works. Specifically, there exists a natural temporal dependency between consecutive instances (segments) to be clas- sified within MVD. However, mainstream TSC models rely on the assumption of independent and identically distributed (i.i.d.), focusing on independently modeling each segment. Additionally, annotators with varying expertise may provide incon- sistent boundary labels, leading to unstable performance of noise-free TSC models. To address these challenges, we first formally demonstrate that valuable contextual information enhances the discriminative power of classification instances. Leverag- ing the contextual priors of MVD at both the data and label levels, we propose a novel consistency learning framework Con4m, which effectively utilizes contextual information more conducive to discriminating consecutive segments in segmented TSC tasks, while harmonizing inconsistent boundary labels for training. Exten- sive experiments across multiple datasets validate the effectiveness of Con4m in handling segmented TSC tasks on MVD.", "sections": [{"title": "1 Introduction", "content": "Time Series Classification (TSC) is one of the most challenging problems in the field of machine learning. TSC aims to assign labels to a series of temporally ordered data points. These points either form a complete sequence or are subsequences (segments) resulting from the segmentation of a long time series. Existing works [46, 18] largely focus on the assumption of independent and identically distributed (i.i.d.), in which case each sequence or segment is regarded as an independent instance to be classified, not differentiating between these two settings. In fact, for many practical applications, the raw time series before segmentation for segmented TSC tasks contain Multiple classes with Varying Duration of each class (MVD). For example, in the healthcare domain, the brain signals of epileptic patients often record over several days, encompassing multiple seizure onsets, each with varying durations and intervals. In the field of activity recognition, sensors continuously record users' behavior data, including walking, riding, and running, among other activities, each with varying durations. Therefore, the characteristics of the raw MVD lead to the uniqueness of segmented TSC tasks. Given this, our research concentrates on effectively modeling segmented TSC tasks based on MVD, presenting distinctive challenges.\n(1) Leveraging contextual information. In contrast to TSC tasks for complete sequences, in which classified sequences are relatively independent, there exist natural temporal dependencies between consecutive classified segments for segmented TSC. We take the seizure detection task as an example, in which given the brain signals of epileptic patients, the model should identify whether a segment includes seizure waves or not. As illustrated in Figure 1(b), given the sustained nature of seizure onsets, the model predictions for consecutive segments should exhibit coherence, with seizure and normal predictions appearing in continuous and concentrated patterns. However, mainstream TSC models [54, 67, 57] focus on the i.i.d. assumption and model the internal context within each segment to be classified, largely overlooking the dependencies between consecutive segments.\nIn the domain of video analysis, works in temporal action segmentation (TAS) [16] have modeled the temporal dependency between different video frames and made frame-wise predictions. However, unlike the I3D features [7] used as input in these works, time series lack a unified pretrained model for feature extraction, and the dependency between segments is more variable and ambiguous. Further- more, TAS works focus on modeling the dependency of instances from a data perspective, without explicitly leveraging contextual label information. Therefore, how to leverage contextual information in segmented TSC tasks to make more reasonable classifications is crucial and challenging.\n(2) Inconsistent boundary labels. In domains with precious labels, different annotators collabo- ratively contribute annotations. The raw annotations of MVD typically include information about the start and end times for each class. However, due to inherent ambiguity and a lack of unified quantification standards, differences in annotator experience may lead to inconsistent boundary labels. Returning to Figure 1(a), in the seizure detection task, owing to the natural fuzzy transition from seizure onset to completely normal, different physicians have varying experiences regarding when seizure waves terminate.\nFurthermore, inconsistent boundary labeling causes that boundary segments with similar patterns may have opposite labels, leading to unstable model training. To validate the detrimental impact, as shown in Figure 1(c), we divide each class sequence in the seizure detection task into 5 levels, where higher levels indicate proximity to the boundary. We then sample an equal number of balanced binary"}, {"title": "2 Theoretical Analysis", "content": "In this section, we aim to formally demonstrate the benefit of contextual information for classification tasks, and to establish the existence of an upper bound for this benefit. Consequently, by introducing prior knowledge, we can guide the model to focus on valuable contextual information more conducive to improving the benefit for segmented TSC tasks.\nAssuming that the random variables of the instances to be classified and the corresponding labels are denoted as xt and yt. At represents the contextual instance set introduced for xt. XA+ denotes the random variable for the contextual instance set. Mutual information measures the correlation between two random variables. In a classification task, a higher correlation between instances and labels indicates that the instances are more easily distinguishable by the labels. This benefits the classification task, making it more readily addressable. Therefore, from an information-theoretic perspective, we elucidate the benefit of contextual information through the following theorem.\nTheorem 2.1. The more the introduced contextual instance set enhance the discriminative power of the target instance, the greater the benefit for the classification task.\nProof. Firstly, we establish that the introduction of contextual information does not compromise classification tasks, i.e., it does not diminish the correlation between instances and labels.\n$\\I(y_t; x_t, X_A) = I(y_t; x_{t} |X_t) + I(y_t; x_t) \\geq \u2161(y_t; x_t).$\nAccording to (1), the increase in $I(y_t; x^+ |x_t)$ determines the extent to which the introduction of contextual information can be beneficial for classification tasks. Expanding $I(y_t; x^A+ |x_t)$, we have:\n$\\begin{aligned} I(y_t; X_{t} |x_t) &=\\sum_{x_t} P(x_t) \\sum_{X_At} \\sum_{y_t} P(y_t, X_A |x_t) \\log \\frac{P(y_t, X_A |x_t)}{P(y_t |x_t) p(x_A |x_t)} \\end{aligned}$\n\\begin{aligned} &= \\sum_{x_t} P(x_t) \\sum_{X_At} \\sum_{y_t} P(y_t |x_t, X_A) P(x_A |x_t) \\log \\frac{P(y_t |x_t, X_A)}{P(y_t |x_t)} \\end{aligned}\n$\\begin{aligned} &= \\sum_{x_t} P(x_t) \\sum_{X_At} P(x_A |x_t) D_{K L}(P(y_t |x_t, X_{A_t}) || P(y_t |x_t)). \\end{aligned}$\nGiven a fixed instance xt and the inherent distribution p(yt|xt) of the data, the KL divergence is a convex function for x\u0104\u0141 that attains its minimum at p(yt|xt, xat) = P(ytxt). As p(ytxt, XA+) approaches the boundary of the probability space, where the predictive probability of one class approaches 1 and the rest approach 0, the value of KL divergence increases. A stronger discriminative power regarding x\u0165 implies less uncertainty regarding y\u0142, which is equivalent to approaching the boundary of the probability space.\nDue to the convexity of the KL divergence and the boundedness of p(ytxt, x^\u2081), there exists a contextual instance set in the data that maximizes $D_{K L}(p(y_t |x_t, X_{At}) || P(y_t |x_t))$. We denote the instance set as $A$ and the maximum value of KL divergence as D. Besides, we note that $E_{x_t} P(X_{A_t} |x_t) = 1$. Hence, we can obtain the upper bound for the information gain $I(y_t; x_{A_t} |x_t) < \\sum_{x_t} P(x_t) E_{xA4} P(X_{A_t} |x_t)D \\leq \\sum_{x_t} P(x_t)D^*$. The convexity of the KL diver- gence also implies monotonicity, indicating that as At approaches A, the KL divergence increases, leading to a greater information gain for the classification task.\nAccording to Theorem 2.1, valuable contextual information enhances the discriminative power of the instances. While the optimal instance set At is challenging to directly obtain or optimize, focusing the model on contextual instances more likely to be included in At is beneficial for enhancing the performance of the classification task. Furthermore, XA, not only contains information at the data level but also encompasses information at the label level (which can be replaced with y^,). Therefore, we can guide the model to focus on contextual information more conducive to segmented TSC tasks by simultaneously introducing prior knowledge from both the data and label perspectives."}, {"title": "3 The Con4m Method", "content": "In this section, we introduce the details of Con4m. Based on the insights of Theorem 2.1, we introduce contextual prior knowledge of data locality (Sec. 3.1) and label coherence (Sec. 3.2) to guide the model to focus on contextual information more conducive to discriminating consecutive segments in segmented TSC tasks. In Sec. 3.3, inspired by the idea of noisy label learning, we propose a label harmonization framework to achieve a more robust model. Before delving into the details of Con4m, we provide the formal definition of the segmented TSC task in our work.\nDefinition 3.1. Given a time interval comprising of T consecutive time points and labels, denoted as (X,Y) = {(X1, Y1), (X2,Y2), . . ., (XT, Y\u2081)}, a w-length sliding window with stride length r is em- ployed for segmentation. (X,Y) is partitioned into L time segments, represented as (x,y) = {(Xi, Yi) = ({X(i\u22121)\u00d7r+1,..., X(i\u22121)\u00d7r+w}, Majority({Y(i\u22121)\u00d7r+1,..., Y(i\u22121)\u00d7r+w}))|i = 1, . . ., L}. The model is tasked with predicting segmented labels yi for each time segment xi.\n3.1 Continuous Contextual Representation Encoder\nLocal continuity is an inherent attribute of MVD, meaning each class should be locally continuous and only change at its actual boundary. Smoothing with a Gaussian kernel [17, 15, 62] promotes the continuity of representations of time segments in a local temporal window. This not only helps the model make similar predictions of consecutive segments within the same class but also aligns with the gradual nature of class transitions. Furthermore, for graph neural networks based on the homophily assumption, aggregating neighbor information belonging to the same class can improve the discriminative power of the target instance [45, 69]. Therefore, we introduce the Gaussian prior to guide the model to focus on contextual instances At proximate to the target instance.\nVanilla self-attention [14] with point-wise attention computations often fail to obtain continuous representations after aggregation. Therefore, we use the Gaussian kernel \u03a6(x, y|\u03c3) as prior weights to aggregate neighbors to obtain smoother representations. Since the neighbors of boundary segments may belong to different classes, we allow each segment to learn its own scale parameter \u03c3. Formally, as Figure 2 shows, the two-branch Con-Attention in the l-th layer is:\n$Q, K, V_s, V_g, \u03c3 = c^{l-1}, c^{l-1}, c^{l-1}, c^{l-1}, c^{l-W!}$"}, {"title": "3.2 Context-aware Coherent Class Prediction", "content": "In the segmented TSC task of MVD, consecutive time segments not only provide contextual infor- mation at the data level but also possess their own class information. As depicted in Figure 1(a), considering the persistence of each class and the gradual nature of class transitions, the model's pre- dictions should exhibit more coherence and concentration, rather than being interspersed. Therefore, we integrate and constrain the model's predictions from both the individual and holistic perspectives to achieve more coherent predictions.\nNeighbor Class Consistency Discrimination. In graphs, label propagation algorithms [26, 29] are often utilized to refine and smooth the predictions of neighbor instances, thereby enhancing their discrimination. Drawing inspiration from this, by weightedly aggregating predictions from similar time segments, the model can focus on contexts At more likely to belong to the same class as the target segment. Although there is no explicit graph structure between time segments, we can train a discriminator to determine whether two segments belong to the same class. The model then aggregates the contextual class predictions based on the discriminator's outputs, thus making more robust predictions. As the left part of Figure 3 shows, we formalize this process as follows:\nPrediction Behavior Constraint. Unlike graphs, there exists a holistic temporal relationship between consecutive time segments. Therefore, we should further constrain the overall predictive behavior along the time axis. For MVD, as Figure 1(a) shows, within a suitably chosen time interval, consecutive segments almost span at most two classes. Therefore, we ensure the monotonicity of predictions across consecutive segments through hard constraints, thereby utilizing contextual label information yA, to integrate and refine predictions across these segments.\nAs shown in the middle part of Figure 3, for each class in the predictions, there are only four prediction behaviors for consecutive segments, namely high confidence, low confidence, confidence decreasing, and confidence increasing. To constrain the behavior, we use function fitting to integrate p. Considering the wide applicability, we opt for the hyperbolic tangent function (i.e., Tanh) as our basis. Formally, we introduce four tunable parameters to exactly fit the monotonicity as:\n$p = Tanh(xa, k, b, h) = a \\times Tanh (k \\times (x + b)) + h,$\nwhere parameter a constrains the range of the function's values, k controls the slope of the transition of the function, b and h adjust the symmetry center of the function, and x is the given free vector in the x- coordinate. We use the MSE loss to fit the contextual predictions p as l3 = ||Tanh(x|a, k, b, h) \u2013 p||2.\nIt deserves to be emphasized that p in the process has no gradient and therefore does not affect the parameters of the encoder. Please see Appendix B for more fitting details.\nAfter function fitting, we obtain independent predictions \u00ee\u00ea\u00ee for each segment and constrained predic- tions that leverage contextual label information. For the inference stage, we use the average of them as the final coherent predictions, i.e., \u0177 = arg max (p + p)/2."}, {"title": "3.3 Label Consistency Training Framework", "content": "Due to inherent ambiguity, the annotation of MVD often lacks quantitative criteria, resulting in experiential differences across individuals. Such discrepancies are detrimental to models and we propose a training framework to enable Con4m to adaptively harmonize inconsistent labels.\nLearning from easy to hard. We are based on the fact that although people may have differences in the fuzzy transitions between classes, they tend to reach an agreement on the most significant core part of each class. In other words, the empirical differences become more apparent when approaching the transitions. Therefore, we adopt curriculum learning techniques to help the model learn instances from the easy (core) to the hard (transition) part. Formally (see the diagram in Figure 1(b)), for a continuous K-length class, we divide it into N\u2081 = 5 equally sized levels as follows:\n$[\\frac{(N-1) K}{2N}], [\\frac{(N+1) K}{2N}], \\ldots, [\\frac{K}{2N}]; [\\frac{(2N_{1} \u2212 1)K}{2N}].$\nThen we sample the same number of time intervals from each level. The higher the level, the more apparent the inconsistency. Therefore, as the right part of Figure 3 shows, during the training stage, Con4m learns the time intervals in order from low to high levels, with a lag gap of Eg = 5 epochs.\nHarmonizing inconsistent labels. Inspired by the idea of noisy label learning, we gradually change the raw labels to harmonize the inconsistency. The model preferentially changes the labels of the core segments that are easier to reach a consensus, which can avoid overfitting of uncertain labels. Moreover, the model will consider both the independent and constrained predictions to robustly change inconsistent labels. Specifically, given the initial label yo, we update the labels Ye = arg max pe for the e-th epoch, where pe is obtained as follows:\n$Pe = (1 - \u03b7) yo + \u03b7 ((1-\\frac{\\gamma}{2}) \\hat p_e + \\frac{\\gamma}{2} p^),$\nwhere we = Rescale([exp((e \u2013 m)/2)]m\u2208{0,...,4}) is the exponentially averaged weight vector to aggregate the predictions of the latest 5 epochs to achieve a more robust label update. Pe-m and Pe-m are the independent and constrained predictions in the e m-th epoch respectively and denotes the dot product. The dynamic weighting factor, \u03b7, is used to adjust the degree of label update. As Figure 3 shows, \u03b7 linearly increases from 0 to 1 with En epochs, gradually weakening the influence of the original labels. Besides, in the initial training stage, the model tends to improve independent predictions. As the accuracy of independent predictions increases, the model assigns a greater weight to the constrained predictions. See the hyperparameter analysis for En in Appendix C."}, {"title": "4 Experiment", "content": "4.1 Experimental Setup\nDatasets. In this work, we use two public [27, 33] and one private MVD data to measure the performance of models. Specifically, the Tufts fNIRS to Mental Workload [27] data (fNIRS) contains brain activity recordings from adult humans performing controlled cognitive workload tasks. The SleepEDF [33] data (Sleep) contains PolySomnoGraphic sleep records for subjects over a whole night. The private SEEG data records brain signals indicative of suspected pathological tissue within the brain of epileptic patients. More detailed descriptions can be found in Table 1 and Appendix D.\nLabel disturbance. We introduce a novel disturbance method to the raw labels Y of the public datasets to simulate scenarios where labels are inconsistent. Specifically, we first look for the boundary points between different classes in a complete long MVD data. Then, we randomly determine with a 0.5 probability whether each boundary point should move forward or backward. Finally, we randomly select a new boundary point position from r% of the length of the class in the direction of the boundary movement. In this way, we can interfere with the boundaries and simulate label inconsistency. Meanwhile, a larger value of r% indicates a higher degree of label inconsistency. For SEEG dataset, inconsistent labels already exist in the raw data and we do not disturb it.\nBaselines. We compare Con4m with state-of-art models from various domains, including two noisy label learning (NLL) models for time series classification (TSC): SREA [8] and Scale-teaching [43] (Scale-T), three image classification models with noisy labels: SIGUA [24], UNICON [32] and Sel-CL [39], three supervised TSC models: MiniRocket [12], TimesNet [60] and PatchTST [47], and three temporal action segmentation (TAS) models: MS-TCN2 [38], ASFormer [64] and DiffAct [41]. See more detailed descriptions of the baselines in Appendix E.\nImplementation details. We use cross-validation [35] to evaluate the model's generalization ability by partitioning the subjects in the data into non-overlapping subsets for training and testing. As shown in Table 1, for fNIRS and SEEG, we divide the subjects into 4 groups and follow the 2 training-1 validation-1 testing (2-1-1) setting to conduct experiments. We divide the Sleep dataset into 3 groups and follow the 1-1-1 experimental setting. Therefore, we only report the mean values of cross-validation results in the main context. See more details and the full results in Appendix G.\n4.2 Label Disturbance Experiment\nThe average results over all cross-validation experiments are presented in Table 2. Overall, Con4m outperforms almost all baselines across all datasets and all disturbance ratios.\nResults of different methods. For fNIRS, TAS models achieve competitive performance compared to Con4m, demonstrating the advantage in modeling contextual data dependency among segments. For Sleep and SEEG data with more ambiguous boundaries, the performance of TAS models deteriorates significantly, and TSC and NLL models slightly outperform TAS models. Benefiting from multi-scale modeling, Scale-T exhibits significantly better performance on the Sleep and SEEG data compared to SREA. Nevertheless, Con4m that fully consider contextual information demonstrate a notable performance improvement (Sleep-0%: 7.15%; SEEG: 6.45%) in more complex and ambiguous data.\nResults of different r%. NLL methods demonstrate close performance degradation as r% increases from 0% to 20% compared with Con4m. However, with a higher ratio from 20% to 40%, SIGUA, UNICON, Sel-CL, SREA, and Scale-T show averaged 3.01%, 5.23%, 1.92%, 3.34%, and 3.22% decrease across fNIRS and Sleep data respectively, while Con4m shows 2.37% degradation. For TSC models, non-deep learning-based MiniRocket shows a more robust performance compared to other TSC models. The performance of PatchTST on fNIRS data exhibits significant instability, possibly due to its tendency to overfit inconsistent labels too quickly. DiffAct in TAS models shows the most sensitive performance to boundary perturbations (14.44% decrease). The stable performance of Con4m indicates that our proposed training framework can effectively harmonize inconsistent labels.\nResults of symmetric disturbance. We also corrupt the labels with symmetric disturbance based on segmented labels y rather than raw MVD labels, which is commonly employed in the NLL works [58, 39, 28] of the image classification domain. As shown in Figure 4(b), compared to our novel boundary disturbance, Con4m exhibits stronger robustness to symmetric disturbance. Even with the 20% disturbance ratio, Con4m treats it as a form of data augmentation, resulting in improved performance. This indicates that overcoming more challenging boundary disturbance aligns better with the nature of time series data."}, {"title": "4.3 Label Substitution Experiment", "content": "Since ambiguous boundaries are inherent to SEEG data and the majority voting procedure is costly, we limit this procedure to only one high-quality testing group in the label disturbance experiment. Besides, on the SEEG data, Con4m modifies approximately 10% of the training labels, which is a significant proportion. Therefore, it is necessary to further evaluate the effectiveness of our label harmonization process on SEEG data. Specifically, we train the TSC baselines based on the harmonized labels generated by Con4m and observe to what extent the performance of TSC models is improved. As shown in Figure 4(a), PatchTST and TimesNet, employing deep learning architectures, are more susceptible to label inconsistency, so they obtain more significant performance improvement"}, {"title": "4.4 Ablation Experiment", "content": "We introduce two types of model variations. (1) Preserve only one module. We preserve only the Con-Transformer (Con-T), Coherent Prediction (Coh-P), or Curriculum Learning (Cur-L) module separately. (2) Remove only one component. In addition to removing the above three modules, we also remove the function fitting component (-Fit) and \u03b7 (\u0395\u03b7 = 0) to verify the necessity of prediction behavior constraint and progressively updating labels.\nAs shown in Table 3, when keeping one module, +Coh-P achieves the best performance with an averaged 2.78% decrease in F\u2081 score, indicating that introducing the contextual label information are most effective for MVD. The utility of each module varies across datasets. For example, for Sleep data, the Con-T contributes more to performance improvement compared to the Cur-L module, while the opposite phenomenon is observed for SEEG data. As for removing one component, even when we only remove the Tanh function fitting, the F\u2081 score significantly decreases 1.72% on average. On the Sleep-20% and SEEG data, the drop caused by -Fit is more significant than that caused by some other modules. Moreover, the model variation -\u03b7 achieves the worst results (9.23% decrease in F\u2081). The results imply that during early training stages, the model tends to learn the consistent parts of the raw labels. Premature use of unreliable predicted labels as subsequent training supervision signals leads to model poisoning and error accumulation."}, {"title": "4.5 Case Study", "content": "We present a case study to provide a specific example that illustrates how Con4m works for MVD in Figure 5. We show comparative visualization results for the predictions in a continuous time interval in the SEEG testing set. In SEEG data, we assign the label of normal segments as 0 and that of seizures as 1. As the figure shows, Con4m demonstrates a more coherent narrative by constraining the prediction behavior and aligning with the contextual data information. In contrast, Scale-T, Sel-CL and MiniRocket exhibit noticeably interrupted and inconsistent predictions. MS-TCN2 fails to identify normal segments. More impressively, Con4m accurately identifies the consistent boundary within the time interval spanning across two classes. This verifies that the label consistency framework can harmonize the boundaries more effectively. Refer to Appendix H for more cases."}, {"title": "5 Conclusion and Discussion", "content": "In this work, we focus on the raw time series MVD for segmented time series classification (TSC) tasks, demonstrating unique challenges that are overlooked by existing mainstream TSC models. We first formally demonstrate that valuable contextual information enhances the discriminative power of classification instances. Based on the insights, we introduce contextual prior knowledge of data locality and label coherence to guide the model to focus on contextual information more conducive to discriminating consecutive segments in segmented TSC tasks. Leveraging effective contextual information, a label consistency learning framework Con4m is proposed to progressively harmonize inconsistent labels during training. Extensive experiments validate the superior performance achieved by Con4m and highlight the effectiveness of the proposed consistent label training framework. Our work still has some limitations. We have solely focused on analyzing and designing end-to-end supervised models. Further exploration of large-scale models would be challenging yet intriguing. When faced with more diverse label behaviors, the function fitting module needs to engage in more selection and design of basis functions. Nevertheless, our work brings new insights to the TSC domain, re-emphasizing the importance of the inherent temporal dependence of time series."}, {"title": "A Details of Related Works", "content": "Time series classification (TSC). TSC has become a popular field in various applications with the exponential growth of available time series data in recent years. In response, researchers have proposed numerous algorithms [30]. High accuracy in TSC is achieved by classical algorithms such as Rocket and its variants [11, 12], which use random convolution kernels with relatively low computational cost, as well as ensemble methods like HIVE-COTE [40], which assign weights to individual classifiers.\nMoreover, the flourishing non-linear modeling capacity of deep models has led to an increasing preva- lence of TSC algorithms based on deep learning. Various techniques are utilized in TSC: RNN-based methods [50, 13] capture temporal changes through state transitions; MLP-based methods [19, 61] encode temporal dependencies into parameters of the MLP layer; and the latest method TimesNet [60] converts one-dimensional time series into a two-dimensional space, achieving state-of-the-art per- formance on five mainstream tasks. Furthermore, Transformer-based models [63, 9] with attention mechanism have been widely used.\nThe foundation of our work lies in these researches, including the selection of the backbone and experimental setup. However, mainstream TSC models [46, 18] are often designed for publicly avail- able datasets [3, 10] based on the i.i.d. samples, disregarding the inherent contextual dependencies between classified segments in MVD. Although some time series models [51, 47] use patch-by-patch technique to include contextual information, they are partially context-aware since they only model the data dependencies within each time segment, ignoring the dependencies between consecutive segments.\nNoisy label learning (NLL). NLL is an important and challenging research topic in machine learning, as real-world data often rely on manual annotations prone to errors. Early works focus on statistical learning [1, 37, 5]. Researches including Sukhbaatar et al. [53] launch the era of noise-labeled representation learning.\nThe label noise transition matrix, which represents the transition probability from clean labels to noisy labels [25], is an essential tool. Common techniques for loss correction include forward and backward correction [49], while masking invalid class transitions with prior knowledge is also an important method [22]. Adding an explicit or implicit regularization term in objective functions can reduce the model's sensitivity to noise, whereas re-weighting mislabeled data can reduce its impact on the objective [2, 65, 42]. Other methods involve training on small-loss instances and utilizing memorization effects. MentorNet [31] pretrains a secondary network to choose clean instances for primary network training. Co-teaching [23] and Co-teaching+ [66], as sample selection methods, introduce two neural networks with differing learning capabilities to train simultaneously, which filter noise labels mutually. The utilization of contrastive learning has emerged as a promising approach for enhancing the robustness in the context of classification tasks of label correction methods [39, 68, 28].\nThese works primarily focus on handling noisy labels. And ensuring overall label consistency by modifying certain labels is crucial for MVD. To the best of our knowledge, Scale-teaching [43] and SREA [8] are the only NLL works specifically designed for time series. Scale-teaching designs a fine-to-coarse cross-scale fusion mechanism for learning discriminative patterns by utilizing time series at different scales to train multiple DNNs simultaneously. SREA trains a classifier and an autoencoder with a shared embedding representation, progressively self-relabeling mislabeled data samples in a self-supervised manner. However, they still face the issue of overlooking contextual dependencies across consecutive time segments.\nCurriculum learning (CL). Bengio et al. [6] propose CL, which imitates human learning by starting with simple samples and progressing to complicated ones. Based on this notion, CL can denoise noisy data since learners are encouraged to train on easier data and spend less time on noisy samples [20, 56]. Current mainstream approaches include Self-paced Learning [36], where students schedule their learning, Transfer Teacher [59], based on a predefined training scheduler; and RL Teacher [21, 44], which incorporates student feedback into the framework. The utilization of CL proves to be particularly advantageous in situations involving changes in the training labels. Hence, this technique is utilized to enhance the harmonization process of boundary labels from MVD in a more stable manner.\nTemporal action segmentation (TAS). TAS is a critical task in video understanding and analysis. It involves segmenting an untrimmed video sequence into meaningful temporal segments and assigning a"}, {"title": "B Implementation Details of Prediction Behavior Constraint", "content": "To fit the hyperbolic tangent function (Tanh), we use the mean squared error (MSE) loss function. In practice, we use the Adam optimizer with a learning rate of 0.1 to optimize the trainable parameters. The maximum number of iterations is set to 100, and the tolerance value for stopping the fitting process based on loss change is set to 1e \u2013 6. Sequences belonging to one minibatch are parallelized to fit their respective Tanh functions. To adapt to the value range of the standard Tanh function, we rescale the sequential predictions to [-1, 1] before fitting.\nHowever, it can be difficult to achieve a good fit when fitting with the Tanh function. Specifically, random initialization may fail to fit the sequential values properly when a long time series undergoes a state transition near the boundary. For example, as Figure 6(a) shows, we fit a sequence in which only the last value is 1. We set all default initial parameters as 1 and fit it. It can be observed that the fitting function cannot properly fit the trend and will mislabel the last point.\nAppropriate parameter initialization is needed to avoid excessive bias. After careful observation, we find that parameter k controls the slope at the transition part of Tanh, and parameter b controls the abscissa at the transition point. In the process, all fitting values are assigned with uniform abscissa values. Therefore, we calculate the maximum difference between adjacent values and the corresponding position in the entire sequence. And these two values are assigned to parameters k and b, respectively. This allows us to obtain suitable initial parameters and avoid getting trapped in local optima or saddle points during function fitting. Formally, given the L-length input sequence p, we initialize parameters k and b as follows:\ndi = [Pi+1 \u2212 Pi]i\u2208{1,...,L\u22121},"}, {"title": "C Hyperparameter Analysis", "content": "The dynamic weighting factor \u03b7 is introduced to progressively update the labels, preventing the model from overly relying on its own predicted labels too early. To validate the utility of n and determine an appropriate linear growth epoch En, we conduct the hyperparameter search experiment on SEEG data. As shown in Figure 7(b), with smaller En (corresponding to a higher growth rate), there is a significant improvement in model performance. This aligns with our motivation that during the early stage of model training, the primary objective is to better fit the original labels. At this stage, the model's own predictions are unreliable. If the predicted results are used as training labels too early in subsequent epochs, the model would be adversely affected by its own unreliability. On the other hand, excessively large En leads to a slower rate of label updates, making it more challenging for the model to timely harmonize inconsistent labels. Nonetheless, considering the impact of variance, the model exhibits robustness to slightly larger En. In this work, we uniformly use En = 30 as the default value."}, {"title": "D Details of Datasets", "content": "fNIRS. All signals are sampled at a frequency of 5.2Hz. At each time step", "27": "we only apply classification tasks for 0-back and 2-back tasks in our work. Therefore", "studies": "the Sleep Cassette study and the Sleep Telemetry study. The former records approximately 40 hours of sleep from two consecutive nights, while the latter records around 18 hours of sleep. Well-trained technicians manually score the corresponding sleep graphs according to the Rechtschaffen and Kales manual. The"}]}