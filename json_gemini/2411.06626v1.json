{"title": "Exploring social bots: A feature-based approach to improve bot detection in social networks", "authors": ["Salvador Lopez-Joya", "Jose A. Diaz-Garcia", "M. Dolores Ruiz", "Maria J. Martin-Bautista"], "abstract": "The importance of social media in our daily lives has unfortunately led to an increase in the spread of misinformation, political messages and malicious links. One of the most popular ways of carrying out those activities is using automated accounts, also known as bots, which makes the detection of such accounts a necessity. This paper addresses that problem by investigating features based on the user account profile and its content, aiming to understand the relevance of each feature as a basis for improving future bot detectors. Through an exhaustive process of research, inference and feature selection, we are able to surpass the state of the art on several metrics using classical machine learning algorithms and identify the types of features that are most important in detecting automated accounts.", "sections": [{"title": "1 Introduction", "content": "The proliferation of social media has undeniably transformed our daily lives, becoming an integral part of our communication with family and friends, a source of information"}, {"title": "2 Related works", "content": "This section aims to provide context and some of the related work in the literature. It starts with an introduction to the concept of a bot in social media, followed by a categorisation of feature-based bot detection methods, and finally an in-depth look at feature engineering and selection for bot detection."}, {"title": "2.1 Bots in social media", "content": "Although the authors generally agree that a bot in social networks is an account with a certain degree of automation, there is no extended definition that covers all the details related to these accounts. This is due to the speed at which technology advances and the doubts that exist when attributing certain characteristics to a bot. One of these characteristics is the level of automation required for an account to transition from a human-managed account to a bot; there are accounts that are partially automated, and establishing a threshold to differentiate between accounts that are not bots and accounts that are bots is complex. Examples of this can be seen in the work conducted by Pastor et al. [15], where they carried out a thorough experimentation focused on profiling bots according to their level of automation and behaviour across social media platforms, utilising social network analysis and graph theory.\nAnother of these features is the similarity to human behaviour. Some authors pay particular attention to this aspect by defining a bot in a social network context as an account that attempts to mimic human behaviour to a greater or lesser extent [16]. The last point to consider is the different fields of study from which these bots are studied;"}, {"title": "2.2 Feature-based bot detection", "content": "There are three types of approaches for bot detection in the literature: feature-based, graph-based and crowdsourcing techniques. The most popular bot detection approaches are feature-based methods. Feature-based methods attempt to leverage the data contained in both the account metadata and the user-written text itself. Most methods based on deep learning and machine learning techniques fall into this category. These methods are divided into three categories: account-based, content-based and hybrid [22].\n\u2022 Account-based. Account-based bot detection techniques use the information from the user's account as features or to infer new ones, e.g., account age, username length, number of retweets, number of followers, or follower growth rate. An example of such a method is given in [23]. In this study, the authors use only account-based features, making use of feature engineering and feature selection techniques. They provide a hybrid deep learning architecture divided into two layers, one for the most relevant numerical variables and another for the description of the profile using embeddings. This study achieves a good generalisation and competitive results compared to other baselines.\n\u2022 Content-based. Content-based bot detection techniques use information from the content of tweets as features, e.g., the number of URLs, the number of hashtags, the sentiment or the length of the tweet. An interesting example that falls into this cat-egory is presented in [24]. Their approach relies on analysing the temporal retweet activity among X accounts. They employ an LSTM 2 variational autoencoder, a specialised neural network combining LSTM's sequential data modelling with vari-ational autoencoders' probabilistic distributions. This fusion allows the extraction of latent features from the retweet time series of individual accounts. Finally, they use a clustering algorithm for bot detection. Notably, this study stands out not only for its competitive results but also for its use of graphical representations. These"}, {"title": "2.3 Feature engineering and feature selection for bot detection", "content": "The process of creating, selecting, or transforming attributes or features that machine learning models use for making predictions is known as feature engineering. It involves extracting relevant information from the raw data and creating informative features that can improve the performance of the model [28, 29].\nIn the context of bot detection in social media, feature engineering entails craft-ing features that capture the distinctive behaviour and characteristics of bots. These features may include:\n\u2022 Temporal patterns: Metrics related to the frequency and timing of the user activity.\n\u2022 Social interactions: Measures of the user's interactions, such as the number of followers, friends, and mentions.\n\u2022 Platform attributes: Platform-dependent features, such as the presence of a profile picture, profile background colour or source of the user activity.\n\u2022 Language and content: Features that describe the content and language used in tweets or posts, including sentiment analysis, stylometry, and linguistic complexity.\n\u2022 Network features: Attributes related to the user's connections and network structure, such as centrality measures.\nEffective feature engineering aids in identifying the underlying patterns that sep-arate real users from automated programs. These features serve as a critical input to machine learning models and contribute to the ability of the model to accurately classify and detect bots.\nIn the same way, the process of choosing a subset of the most relevant features from the available feature set is known as feature selection. It is aimed at reduc-ing dimensionality, improving model interpretability, and potentially enhancing model performance. Feature selection techniques are particularly valuable when working with high-dimensional datasets or when dealing with noisy and irrelevant features. Types of feature selection methods include:"}, {"title": "3 Enhancing feature engineering and feature selection for bot detection", "content": "A feature engineering approach has been followed to identify the features that are useful for differentiating genuine accounts from automated accounts. Three of the most widely spread datasets on bot detection have been chosen: Cresci-15 [42], Cresci-17"}, {"title": "3.1 New-Crafted features", "content": "Two new sets of features have been proposed. The first one is account-based and aims to take advantage of the information that can give us the level of personalisation of the user's account when detecting bots, in the second one we recover the measures exposed in [50] that allow modelling the credibility and engagement of a user based on the metadata of the tweets."}, {"title": "3.1.1 Colour binning", "content": "Among the raw features that can be extracted from the X account are those that represent how the user has customised the profile using colours in hexadecimal base. To our knowledge, these features have not been exploited in the literature. Intuition tells us that these features may be relevant in identifying bots. It is expected that a high degree of personalisation of an account will tend to be more like a real user.\nThree binary value categories have been created from the colours in each dataset including default (if not modified), common (among the top eight colours used), and uncommon (if not in any previous category). The process is illustrated in Figure 2 where the colours from the profile sidebar are categorised."}, {"title": "3.1.2 Credibility and engagement", "content": "In the study conducted by the authors in [50, 51], a filter based on the assignment of credibility and knowledge of users on a specific topic is proposed. The main objective of this study is to reduce irrelevant content coming from social networks, thus allowing to filter and highlight useful and credible content.\nIn this filter, engagement is mathematically modelled by relating the number of favourites and the number of retweets on a topic to the number of followers, to then establish a cut-off threshold. In the same way they model credibility relating the number of followers, the number of listings, the number of retweets and the number of favourites to establish another cut-off threshold.\nIn this work they do not use general engagement but engagement on a certain topic. For the authors, the fact that a person generates quality content on a specific topic does not mean that he/she has to do it for other topics. In the context of our"}, {"title": "4 Experiments", "content": "In this section the datasets will be briefly described, as well as the methodology used. Following this, the results obtained will be presented, and it will conclude with an ablation study comparing the model using both sources of features: account and content."}, {"title": "4.1 Data", "content": "Cresci-17. This is a dataset of user accounts and tweets obtained from \u2717 with the help of users of the CrowdFlower platform [43]."}, {"title": "4.2 Methodology of experimentation", "content": "A rigorous methodology has been followed to provide valid and consistent results (see Figure 3). As explained above, a literature review has been performed in order to find as many relevant features as possible. For each dataset we have implemented these features (see Tables 1, 2) in addition to the new ones we have suggested (see Tables 3, 4). Once the features related to hashtags, mentions, emojis and URLs were calculated, we proceeded to the elimination of these elements in the text. For language detection we used the FastText library, specifically a language detection model trained"}, {"title": "4.3 Results", "content": "In this section, we present the outcomes and observations derived from the conducted experiments aimed at addressing the research questions outlined in the preceding sections.\nIn Figure 4 we can see the ranking of features in the three datasets using Mutual Information and Random Forest Importance, in addition we can see where each feature comes from, in green the features coming from the account and in blue the ones coming from the content. Only these two methods have been visualised in order to show one method that takes into account the relationships between features and one that does not. After this analysis of the features, Random Forest Importance has been chosen as the base method for feature selection. The reasons for this choice are: filtering methods do not take into account the correlation between features and, although some generalisation is lost, the embedded methods are more accurate than the methods belonging to the other two categories [55]. In Figure 5 we can see 40 runs with cross-validation of 10 of a Random Forest on each dataset comparing the accuracy obtained with each subset of features as well as the computation time required for each run.\nIn Table 8 we can see the results of model selection in the Cresci-17 dataset. It should be noted that since the feature selection method is Random Forest Importance, it is expected that this same model will be among the first positions since embedded methods are dependent on the model in which they are embedded."}, {"title": "Accuracy", "content": "$\n\\varepsilon(u) = \\frac{\\frac{n\\_Favorites}{n\\_Followers} + \\frac{n\\_Retweets}{n\\_Followers}}{2}\n$"}, {"title": "Engagement", "content": "$\n\\zeta(u) = \\frac{n\\_Followers + n\\_Lists + n\\_Retweets + n\\_Favorites}{4}\n$"}, {"title": "4.4 Ablation study", "content": "In this section, our objective is to determine the influence of different types of fea-tures on the classification system. To justify this, we conducted an ablation study on our sets of characteristics. This involved systematically assessing the impact first with solely content-based features, then exclusively with account-based features, and ulti-mately with a combined approach incorporating both types. It is important to note that, typically, ablation studies involve the addition or removal of different layers of data processing. In our case, as we delve into the distinctions among sets of features, our approach to the ablation study focuses on understanding the final behaviour of the classifier based on which features and combinations does thereof achieve optimal performance. For more robust comparison results, we performed an ablation study using two distinct feature selection methods. We selected the top-performing method among filter methods, specifically mutual information, and the most effective among"}, {"title": "5 Discussion", "content": "The application of deep learning models has significantly advanced the state-of-the-art performance across various domains, including computer vision, natural language processing, and pattern recognition. However, despite their remarkable success, these models often suffer from a critical limitation: interpretability. In contrast, employing non-deep learning approaches or simpler machine learning models, such as decision trees, linear models, or rule-based systems, often results in more interpretable models. These traditional models operate on explicit rules or features, enabling users to com-prehend how specific inputs influence the final prediction. The transparency offered by these models provides insights into the decision-making process, facilitating model debugging, error analysis, and feature importance identification.\nIn this study we have relied on feature engineering, feature selection and traditional machine learning techniques not only gaining in interpretability but also surpassing the state-of-the-art approaches that are based on both the user's account and its content. This is especially relevant in the practical approach because, even if you do not want to follow a detection algorithm based on machine learning, this study can serve as a basis to identify which features you should pay special attention to when facing the task of identifying bots. Having said this, we proceed to answer the research questions posed above:"}, {"title": "RQ. 1: What features define a social bot?", "content": "To answer this question we will look at Figure 4, as can be seen, there are several features that appear at the top of most of the graphs. First we look at the features related to social interactions with other users. We can see that these occupy the first positions in the 6 graphs, among them we can highlight the reputation and the followers_friends_ratio, these features are very similar and appear in the top in 5 of the 6 graphs. The importance of favourites, the number of followers, the number of listings, the number of mentions and the growth of these features are also striking. Furthermore, we can see that in Cresci-17 dataset the proposed measure of credibility, also based on these interactions, is considered within the top. With these observations"}, {"title": "RQ. 2: Which source of features holds greater importance in social bot detection, account-based or content-based features?", "content": "To answer this question we must look at Figure 4 and the ablation study performed in the previous section. In Figure 4 we can see how in the three datasets the first positions of the top are occupied by the features coming from the account, this agrees well with what is observed in Table 10 where we can see that only using features coming from the user's account we reach a higher accuracy than using features coming from the account. With this we could consider the question answered if it were not for a nuance, taking a closer look at Table 10 we can see that in the Cresci-15 dataset the difference between the accuracy obtained with the two sources of features is very small, but this difference is accentuated in the other two datasets. If we remember the Cresci-15 dataset consists of only one type of bot, while the other two contain more variety. So"}, {"title": "RQ. 3: Can a social bot be identified based on user-profile features? Are they enough?", "content": "To answer this question we will rely once again on the results of the baselines imple-mented in [74]. In Table 11 we have collected the baselines that use graphs as well as other techniques. As can be seen, in the cases of the Cresci-15 and Cresci-17 datasets our proposal is still superior to those presented, on the other hand, in the Twibot-20 dataset our proposal lags behind the best proposal by 1.46 points in terms of accu-racy, specifically it is in fifth position compared to the other methods. This means that there is information in the network structure that cannot be captured with account and content-based methods, so if this network is available, it could be interesting to use it for detection. This does not mean that methods that do not use networks are not competitive, in fact they can achieve results close to and in some cases superior to those based on networks, but there are users who are not willing to put all their data in their account, or who use the platform to promote a personal project, or who simply have not written enough posts for many of the features obtained to be rele-vant. In these cases, it would be interesting to support techniques based on account features with other types of techniques."}, {"title": "6 Conclusions", "content": "In this paper, we emphasize the necessity of leveraging a blend of account and content-based features for effective bot detection. Through the creation of a large set of features made up of literature features and proposed new features, a feature selection and a combination process, we managed, through a traditional random forest algorithm, to surpass the state of the art results across three distinct benchmark datasets."}]}