{"title": "Urdu Digital Text Word Optical Character Recognition Using Permuted Auto Regressive Sequence Modeling", "authors": ["Ahmed Mustafa", "Hasan Sajid", "Muhammad Ijlal Baig"], "abstract": "This research paper introduces an innovative word level Optical Character Recognition (OCR) model designed specifically for digital Urdu text recognition. Leveraging the power of transformer-based architectures and attention mechanisms, the proposed model was trained on a comprehensive dataset comprising approximately 160,000 Urdu text images. The model achieved a character error rate (CER) of 0.178, indicating its superior accuracy in recognizing Urdu characters. The key strength of the model lies in its unique architecture, incorporating the permuted autoregressive sequence (PARSeq) model. This advanced approach enables context-aware inference and iterative refinement, leveraging bidirectional context information to enhance recognition accuracy. Additionally, the model's ability to handle a diverse range of Urdu text styles, fonts, and variations further enhances its applicability in real-world scenarios. While the model demonstrates promising results, it does have some limitations. Blurred images, non-horizontal orientations, and the overlay of patterns, lines, or other text can occasionally lead to suboptimal results. Additionally, trailing or following punctuation marks may cause noise in the recognition process. Addressing these challenges will be a focal point of future research. The proposed model's exceptional performance and its ability to adapt to various text styles make it a valuable tool for applications that require accurate and efficient Urdu text recognition. Future work will focus on refining the model, exploring data augmentation techniques, optimizing hyperparameters, and integrating context-aware language models to further improve its overall performance and robustness.", "sections": [{"title": "I. INTRODUCTION", "content": "Optical Character Recognition (OCR) plays a vital role in various applications, such as document analysis, image understanding, and intelligent character recognition. Over the years, significant progress has been made in the field of OCR, with numerous techniques and models developed to tackle the challenges posed by different languages and scripts. However, much of the existing research focuses on widely studied languages, such as English, Chinese, and French. Urdu, an important language spoken by millions of people, has received limited attention in the context of OCR. Urdu, with its unique script and inherent complexities, presents significant challenges for accurate text recognition.\nThis paper aims to bridge this research gap by focusing on Urdu text recognition in scenes.\nThe core problem addressed in this paper is the recognition of digital Urdu text, specifically focusing on Optical Character Recognition (OCR) for Urdu. Despite the significant progress in English OCR, the scope of research in this domain is limited when it comes to Urdu, a complex and challenging language with unique script characteristics. Recognizing digital Urdu text poses several challenges due to the diversity of font styles, sizes, orientations, and illumination conditions. Additionally, potential occlusions and distortions further complicate the accurate transcription of Urdu text from images captured in real-world environments. The scarcity of research in Urdu OCR demands novel solutions and tailored deep learning architectures that can effectively tackle the complexities of this language. Our research aims to bridge this research gap by designing and developing an optimized deep learning model for Urdu OCR. It intends to explore and compare various deep learning approaches, including Transformer-based models, to identify the most suitable and effective architecture for recognizing digital Urdu text in natural scenes. In addition to addressing the core challenges of recognizing digital Urdu text, this research will investigate the adaptability of state-of-the-art OCR models originally designed for English to the Urdu language. The study will delve into the necessary modifications in preprocessing, training, and inference processes to accommodate the nuances of the Urdu script and linguistic characteristics. By expanding the scope of research in digital Urdu text recognition, this paper endeavors to contribute to the development of reliable and robust OCR systems for Urdu, with potential applications in a wide range of domains, including augmented reality, self-driving cars, and accessibility tools for the visually impaired. Ultimately, the goal is to unlock the potential of Urdu OCR and facilitate the effective integration of Urdu text recognition technology into various digital platforms and real-world applications.\nUrdu is one of the most widely spoken languages in South Asia, with a rich literary tradition and cultural heritage. Recognizing and understanding Urdu text from scene images can have profound implications in various domains. In information retrieval and document analysis, accurate Urdu text recognition enables efficient indexing and searching of digital content, contributing to improved"}, {"title": "II. RELATED WORK", "content": "Optical Character Recognition (OCR) has undergone significant advancements over the years, transforming from traditional computer vision techniques to more sophisticated deep learning architectures. Early OCR systems relied on pattern recognition and template matching [1], but faced limitations in handling complex fonts and variations in handwriting. With the advent of machine learning, OCR witnessed improvements through techniques like Support Vector Machines (SVM), Hidden Markov Models (HMM), and neural networks [2]. However, these methods were often constrained by their inability to capture long-range dependencies in sequential data. The emergence of Recurrent Neural Networks (RNNs), particularly Long Short-Term Memory (LSTM) networks [3], addressed some of the challenges associated with sequential data like text. LSTMs proved effective in preserving contextual information for multi-line and variable-length text recognition, enabling OCR models to achieve better accuracy and robustness. These early RNN-based OCR systems showed great promise but still struggled with some inherent limitations, such as slow inference times due to the sequential nature of character generation. The integration of attention mechanisms into OCR models brought about a significant breakthrough [4]. Attention mechanisms, inspired by human visual attention, allowed OCR models to selectively focus on relevant image regions during the recognition process. This approach improved recognition accuracy and mitigated the challenges posed by variations in font size, style, and orientation. Attention-based OCR models demonstrated enhanced performance, especially for scene text recognition tasks where text might be embedded in complex backgrounds.\nIn recent years, Non-Autoregressive (NAR) OCR models have gained popularity for their parallel processing capabilities [5]. Unlike Autoregressive (AR) models that generate output sequentially, NAR models process input and output in parallel, significantly reducing inference time. This improvement in efficiency made NAR models suitable for real-time applications and large-scale OCR tasks, where speed is critical. Despite these advancements, OCR researchers faced challenges related to handling context and global dependencies in long documents. To overcome these issues, the field of OCR intersected with the domain of natural language processing, leading to the adoption of Transformer networks. Transformers, originally designed for machine translation tasks, demonstrated remarkable capabilities in handling long-range dependencies and capturing global context in sequential data. Transformer-based OCR models employ self-attention mechanisms, which allow each token in the sequence to attend to all other tokens, capturing relevant contextual information. This parallel processing enables Transformers to handle long documents with efficiency, a significant advantage over traditional RNN-based OCR systems. The breakthrough came in 2017 with the introduction of the \"Attention is All You Need\" paper by Vaswani et al., which described the Transformer architecture and its potential in handling sequential data more efficiently [6]. By leveraging the power of Transformers, OCR researchers achieved state-of-the-art results in various text recognition tasks, including scene text recognition, handwritten text recognition, and document digitization. Transformer-based OCR models have surpassed previous methods in terms of accuracy, robustness, and speed, making them a preferred choice for large-scale OCR applications. RNNs and attention mechanisms brought significant improvements in handling sequential data, while NAR models addressed the inefficiencies of AR models. However, the real revolution came with the adoption of Transformer networks, enabling OCR models to process long documents efficiently and achieve state-of-the-art results in text recognition.\nAs the field of Optical Character Recognition (OCR) continues to witness significant advancements, much of the research has historically focused on English and other widely-used languages. However, there has been a growing recognition of the importance of OCR for languages like Urdu, which present unique challenges due to their complex cursive nature. While the research on OCR for Urdu has been relatively limited compared to English, the recent years have seen a notable surge in interest, with researchers exploring various approaches to tackle the complexities of Urdu script recognition. From segmentation-based methods to segmentation-free techniques, multiple avenues have been explored to enhance OCR accuracy and performance for Urdu, paving the way for a promising future in this domain. Segmentation-based OCR approaches work on the premise of segmenting the text into individual characters, which are then recognized separately. One of the main advantages of these approaches is that the number of classes to be recognized is relatively small, as it corresponds to the number of characters in the script. This simplifies the recognition task, but character segmentation itself poses significant challenges [7][8][9]. Morphological processing combined with contour analysis is employed in [10] for character extraction. Moment invariant descriptors are used for recognition in [11], while [12] utilizes edge point matching for character recognition. In [13], authors employ horizontal and vertical projection profiles for segmentation,"}, {"title": "III. DATA PREPROCESSING", "content": "The dataset collection process involved capturing images of different scenes containing Urdu text. The digitally printed text encompassed various sources, such as text written on pages, banners, signboards, identity cards and other printed materials. Handwritten text samples were collected from sources like pages, forms, and other handwritten documents. This diverse collection of digitally printed and handwritten samples aimed to represent the real-world scenarios encountered in Urdu text recognition applications. To ensure variability and diversity in the dataset, various factors such as lighting conditions, camera settings, image resolutions, and zoom levels were deliberately varied during image acquisition. This deliberate variation helps in improving the robustness and generalization capabilities of the trained models. Different lighting conditions, including low light, natural light, and artificial light sources, were utilized to simulate the real-world scenarios that OCR models might encounter. Additionally, camera settings, such as exposure, focus, and white balance, were adjusted to capture images under different conditions. Moreover, images were captured at different resolutions and zoom levels to account for varying distances and text sizes, commonly found in scene images. The total size of the dataset ended up close to 160k images of cropped digital Urdu words. Once the dataset was collected, it was necessary to annotate the data for training the OCR model. In this research, the dataset was annotated at the word level to provide ground truth labels for training and evaluation. To facilitate the annotation process, the CVAT (Computer Vision Annotation Tool) annotation tool was employed. This tool enabled efficient and accurate labeling of the words present in the scene images. Annotating at the word level allows the model to learn the context and dependencies among the characters within each word, improving the recognition accuracy. Due to the nature of the research, the dataset is not available for public use.\nImage preprocessing is a crucial step in any vision based machine learning task, and it plays a significant role in Optical Character Recognition (OCR) as well. After data annotation, the dataset underwent several preprocessing steps to enhance the quality and readability of the Urdu text images.\n* Images were processed to reduce noise caused by factors such as sensor noise, compression artifacts, or environmental factors. Techniques such as median filtering or Gaussian filtering were applied to suppress noise while preserving the text details\n* Skew refers to the slant or tilt in the orientation of the text. Skewed text can adversely affect recognition accuracy. Therefore, skew correction algorithms were applied to align the text lines horizontally, improving the legibility and reducing recognition errors caused by skewed text.\n* Contrast enhancement techniques were employed to improve the visibility and contrast of the text against varying backgrounds and lighting conditions. These techniques adjusted the image's pixel intensities to enhance the text's visibility and make it more distinguishable from the surrounding elements.\n* Data augmentation techniques were applied to increase the diversity and size of the dataset. These techniques included random rotations, translations, scaling, applying filters and cropping of the images. Augmentation helped the model generalize better by exposing it to different variations and distortions that might occur in real-world scenarios.\nBy employing these preprocessing techniques, the dataset was prepared for training the Urdu text recognition model. The processed dataset, consisting of digitally printed and handwritten scene images with Urdu text, along with word-level annotations, provided the necessary inputs for the subsequent stages of model development and evaluation."}, {"title": "C. Label Conversion", "content": "Preprocessing of text data plays a crucial role in preparing it for input to neural networks. However, when dealing with Urdu text, a different preprocessing approach is required compared to English due to the unique characteristics of the Urdu script. In this section, we discuss the specific preprocessing steps necessary for Urdu text recognition and highlight the differences that arise from the distinct nature of Urdu script. One of the fundamental differences in Urdu script is that each alphabet can take multiple shapes based on its position within a word. Unlike English, where characters remain relatively consistent regardless of their placement, Urdu characters change their form depending on whether they appear at the beginning, middle, or end of a word. This variation in shape introduces additional complexity to the recognition process. To handle these shape variations effectively, instead of treating each alphabet as a separate label, each distinct shape that an alphabet can take, based on its position within a word, is assigned a separate label. This significantly increases the number of labels beyond the actual number of alphabets, symbols, and numbers in the Urdu language. By treating each shape as a separate label, the model can learn the positional dependencies of characters within words, which is crucial for accurate recognition."}, {"title": "IV. EXPERIMENTAL SETUP", "content": "At the heart of the architecture lies the innovative Permutation Autoregressive Sequence (PARSeq) model, which introduces a groundbreaking approach to address the intricacies of Urdu text recognition. While the intricate details of PARSeq's mechanics are extensively elaborated in its dedicated research paper [35], a concise overview of its adaptation for Urdu OCR is essential. PARSeq disrupts the conventional autoregressive paradigm by introducing permutation-based language modeling, enabling the model to transcend the limitations of traditional left-to-right (LTR) sequential predictions. This is particularly advantageous for languages like Urdu, characterized by intricate ligatures, non-standard character arrangements, and irregular text orientations. The strength of PARSeq lies in its ability to predict multiple permutations of token orderings, effectively encompassing the diverse ways characters can be sequenced. Within the realm of Urdu OCR, PARSeq's integration changes how characters, words, and sentences are predicted. By accommodating a range of token permutations, PARSeq inherently adapts to the nuances of Urdu script, mitigating the shortcomings of sequential autoregressive models. This flexibility resonates well with the complex nature of Urdu script, allowing the model to consider a broader contextual spectrum when generating predictions.\nThe practical implementation of PARSeq involves training the model to predict a multitude of token permutations during its training phase. Instead of generating a single sequential output, the model learns a comprehensive array of token permutations, effectively capturing various character orders. During inference, this adaptability empowers the model to select the most contextually fitting"}, {"title": "B. Loss Function", "content": "Cross-entropy loss is a fundamental concept in machine learning that plays a vital role in training neural networks. It is commonly used as the objective function for classification tasks, including Optical Character Recognition (OCR) performed by Transformer-based networks. In OCR, the goal is to accurately classify input images into corresponding character or symbol categories. The cross-entropy loss measures the dissimilarity between the predicted probability distribution and the true distribution of the target labels. By taking the negative logarithm of the predicted probability assigned to the correct label, the loss function penalizes incorrect predictions more severely. This encourages the model to adjust its parameters in a way that improves recognition accuracy.\n$$L = - \\sum_{i}^{N} y_{i} \\log(\\hat{y}_{i})$$\nThe introduction of K permutations in our permuted autoregressive sequence (PARSeq) model brought about a fundamental change in the cross-entropy loss function. Unlike the standard autoregressive (AR) models that consider only one fixed permutation for likelihood factorization, our approach aims to train on multiple T! factorizations by sampling K permutations. This change required the formulation of a novel loss function that incorporates the individual cross-entropy losses for each permutation-derived attention mask:\n$$L = \\mathbb{E}_{k}L_{ce}(y, \\hat{y}_{k})$$"}, {"title": "C. Model Evaluation", "content": "The evaluation of the performance of the proposed architecture focuses on measuring the accuracy and effectiveness of the model in recognizing Urdu text accurately. To this end, the primary measure of accuracy applied is the Character Error Rate (CER), which is a widely used metric in OCR evaluation. The Character Error Rate is a metric commonly used to evaluate the performance of OCR systems. It quantifies the dissimilarity between the predicted text output and the ground truth text. The CER measures the accuracy of the model by considering the number of character-level substitutions, deletions, and insertions required to transform the predicted text into the ground truth text. To calculate the CER, the model's predicted text and the corresponding ground truth text are compared at the word level. The CER is computed by dividing the total number of character-level errors (substitutions, deletions, and insertions) by the total number of characters in the ground truth text. The resulting ratio is"}, {"title": "V. RESULTS AND ANALYSIS", "content": "By analyzing the CER results on a diverse test dataset, we gained valuable insights into the model's strengths and identified areas that require improvement to enhance its performance in real-world applications. The sample results obtained from the Urdu OCR model were highly encouraging. The OCR model demonstrated an average 0.178 CER over a test set of 1470 images belonging to the same distribution the model was trained on. The model demonstrated a remarkable ability to accurately recognize and extract text from various digital Urdu images. The output text closely matched the ground truth, showcasing the effectiveness of the proposed transformer-based architecture and the integration of permutation language modeling. Even for challenging cases with overlapping characters, variations in font styles, and inconsistent\nillumination, the model exhibited robust performance. The sample results depicted the successful recognition of Urdu characters, words, and even complete sentences, demonstrating the model's adaptability to a wide range of real-world scenarios. These sample results serve as strong evidence of the model's proficiency in accurately recognizing and extracting Urdu text from scene images."}, {"title": "B. Suboptimal Results", "content": "The OCR model demonstrated suboptimal results on a short set of images, the cause for which were narrowed down to four reasons.\n1) Blurred images pose a significant challenge to the OCR model as they lead to incomplete or distorted character representations. The lack of sharpness in these images hinders proper feature extraction, resulting in misinterpretations and erroneous character recognition. To mitigate this issue, advanced preprocessing techniques, such as image enhancement and deblurring algorithms, can be employed to improve the image quality and enhance the model's performance.\n2) Non-horizontal orientation of the text adds complexity to the OCR process, especially when the text appears at various angles or is curved. Traditional OCR models are primarily designed for horizontally aligned text, and when faced with non-horizontal orientation, they may struggle to accurately identify characters. Addressing this challenge requires the development of more sophisticated models capable of handling text at various angles and curves.\n3) Overlay or background interference, such as patterns, lines, or other text, can hinder character segmentation and lead to confusion during recognition. These elements can create noise in the image and interfere with the OCR model's ability to distinguish individual characters. To overcome this issue, advanced image segmentation techniques, coupled with attention mechanisms, can be used to focus on relevant regions of the image and improve character recognition.\n4) Punctuation trailing or following the text can introduce noise into the OCR process, causing misinterpretation and inaccurate results. For instance, punctuation marks placed too close to characters may be mistaken as part of the character itself, leading to incorrect interpretations. To address this challenge, specialized handling of punctuation marks during preprocessing and post-processing stages is essential to ensure accurate character recognition.\nAlthough these reasons hinder the performance of OCR, these reasons can be attributed to lack of diversity in the dataset and can be rectified by incorporating images with these attributes in the training set for better results in the future."}, {"title": "C. Comparative Analysis", "content": "In the context of comparing the strengths of our Urdu OCR model with contemporary approaches, several challenges arise due to the absence of standardized benchmarks and limited accessibility to proposed architectures. Research in this domain primarily occurs at university levels, with promising models often confined to academic circles and unavailable on public repositories. The lack of a consistent evaluation metric further complicates meaningful comparisons between models. Given these complexities, we turn to an alternative approach for assessment comparing our model against established commercial OCR systems like Google Vision OCR. This offers a relevant yardstick for evaluation, as Google Vision OCR serves as an industry-standard benchmark. This approach allows us to contextualize our model's performance and identify areas for enhancement.\nOur model demonstrated a CER of 0.172 on our test dataset, substantially outperforming Google Vision OCR, which yielded a CER of 0.891 on the same dataset. This notable difference showcases the robustness and efficacy of our approach. Such a substantial performance gap offers us valuable insights into the unique strengths of our model and its capabilities in handling the complexities of Urdu text. By employing this comparison, we gain a comprehensive understanding of our model's performance and its position within the broader realm of Urdu OCR research."}, {"title": "VI. CONCLUSION AND FUTURE RECOMMENDATION", "content": "This paper addresses the critical problem of Text Recognition for digital Urdu text, a domain that has received limited research attention. The primary objective was to design an effective Optical Character Recognition model specifically tailored for the unique characteristics of Urdu script. Additionally, the study aimed to explore the PARSeq architecture for OCR in the context of Urdu and assess the model's performance compared to state-of-the-art approaches. The results obtained from this research demonstrate the remarkable strengths of the developed OCR model. Its innovative approach addresses the specific challenges posed by Urdu text, such as non-contiguous and overlapping characters, which traditional off-the-shelf OCR models struggle to handle. The model's adaptability to varying font styles, skew, and environmental conditions allows for accurate recognition of Urdu text even in challenging real-world scenarios. Extensive training with diverse Urdu text samples equips the model with a comprehensive understanding of the language, further enhancing its recognition capabilities. Other notable strengths of the developed OCR model include its robustness to variations in font styles and illumination conditions. Urdu script presents numerous font styles, and the model's ability to handle such variations effectively ensures high accuracy across a wide range of text appearances. Additionally, the model's resilience to skew, a common issue in text images captured at different angles, enhances its applicability to various practical scenarios.\nA critical area however that necessitates attention is the quality of image crops during the recognition process. Refining the cropping process is imperative to preserve vital context information, ensuring accurate recognition and maintaining the overall context of the text, especially for longer sequences. Additionally, the model's limitation to recognizing only horizontal text poses a constraint on its applicability. To expand its usability, future work should focus on extending the model's capabilities to handle non-horizontal text orientations, enabling it to cater to a broader range of practical scenarios. By addressing these recommendations, the potential of Urdu OCR technology can be fully realized, fostering increased accuracy, usability, and versatility for real-world applications. The findings from this research offer promising contributions to the advancement of multilingual OCR technologies, propelling the field towards greater innovation and efficiency."}]}