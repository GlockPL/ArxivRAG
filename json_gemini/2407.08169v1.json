{"title": "Faster Machine Unlearning via Natural Gradient Descent", "authors": ["Omri Lev", "Ashia Wilson"], "abstract": "We address the challenge of efficiently and reliably deleting data from machine learning models trained using Empirical Risk Minimization (ERM), a process known as machine unlearning. To avoid retraining models from scratch, we propose a novel algorithm leveraging Natural Gradient Descent (NGD). Our theoretical framework ensures strong privacy guarantees for convex models, while a practical Min/Max optimization algorithm is developed for non-convex models. Comprehensive evaluations show significant improvements in privacy, computational efficiency, and generalization compared to state-of-the-art methods, advancing both the theoretical and practical aspects of machine unlearning.", "sections": [{"title": "Introduction", "content": "The exponential growth in data collection and machine learning applications has intensified concerns about user privacy and data security. Legislative frameworks such as the European Union's General Data Protection Regulation (GDPR), California's Consumer Privacy Act (CCPA), and Canada's proposed Consumer Privacy Protection Act (CPPA) emphasize the right of individuals to have their data deleted upon request. These new requirements have catalyzed the development of \"machine unlearning\" the process of modifying a trained model to eliminate the influence of specific data inputs, effectively making the model \"forget\" this data. The main challenge is making this process efficient without resorting to retraining models from scratch, which is computationally expensive and unsustainable as the scale of models and data grows.\nHistorically, theoretical approaches to machine unlearning have predominantly focused on convex models, where the problem space allows for the development of algorithms with provable guarantees of privacy and correctness [1, 2]. These methods often rely on operations like the Newton step, which, while effective, are computationally demanding for large-scale applications. In contrast, practical approaches typically address more complex, non-convex models using heuristic methods that lack formal privacy guarantees [3]. These methods often re-optimize the model on a pruned dataset, which is believed not to contain the information intended for unlearning-a computationally expensive process that can inadvertently retain data influence and thus compromise privacy.\nThis paper proposes a novel algorithm based on Natural Gradient Descent (NGD)\u2014a gradient algorithm that preconditions a gradient descent update with the inverse of the Fisher information matrix of the underlying statistical model. By treating the ERM problem through the lens of maximum-likelihood estimation, we first develop an algorithm for convex models, proving it maintains strong unlearning guarantees and is more computationally efficient than existing methods, which are based on the Newton step. Leveraging NGD's adaptability to large models, we design a practical unlearning algorithm based on a Min/Max optimization procedure for realistic settings. Our new algorithm outperforms state-of-the-art unlearning algorithms in multiple aspects."}, {"title": "Related Work", "content": "The goal of exact unlearning, first proposed by Cao and Yang [4], is to find a model whose predictions match those of a retrained model. This can be achieved through retraining or using other techniques that tend to be computationally or memory-intensive [5, 6, 7]. In contrast, approximate unlearning is a less stringent requirement that allows the unlearned model to deviate from the retrained model by a bounded amount. Several works have introduced more efficient methods that satisfy these inexact criteria [1, 2, 8, 9, 10, 11].\nWe develop a computationally efficient algorithm that satisfies the (\u20ac, \u03b4)-approximate unlearning definition from Sekhari et al. [1]. Sekhari et al. [1] also prove that approximate unlearning can be achieved using a Newton step towards the gradient of the points we aim to unlearn in the convex case. This algorithm was later generalized to efficiently remove points online and to delete points in scenarios involving non-differentiable regularizers [2].\nIn contrast to previous work that utilizes Newton-style updates and requires a full Hessian inversion, we aim to reduce this computational burden by leveraging the NGD [12]. NGD offers a low-cost second-order update by replacing the Hessian with the Fisher Information Matrix (FIM). As we will show, the NGD update is closely related to the Fisher-unlearning methods studied by Golatkar et al. [11, 13] and Wang et al. [14]. Our contributions improve upon these previous algorithms in two key ways. First, we are the first to prove that FIM-based methods satisfy the (\u20ac, \u03b4)-unlearning definition, establishing the correctness of our algorithm in the convex case. Second, we demonstrate that FIM-based methods are specific cases of second-order unlearning methods that replace the Hessian with its Positive Semi-Definite (PSD) approximation, given by the Gauss-Newton Matrix [12]. This exploration introduces a more general framework that paves the way for developing advanced unlearning methods.\nWe end by turning our sights to unlearning in the non-convex regime. While recent works have also introduced unlearning algorithms based on the Min/Max training procedure [9], we extend this theory and show how these methods can be enhanced by incorporating Min/Max training based on NGD."}, {"title": "Background", "content": "We now discuss the problem of learning and unlearning and review NGD algorithm."}, {"title": "Machine Learning", "content": "In our learning setting, we aim to minimize an objective function comprised of a loss function l, a regularizer \u03c0, and a regularization parameter \u03bb\u2208 [0,\u221e). The goal of learning is to find a parameter \u03b8*(\u03bb) \u2208 \u0398 that minimizes the population risk\n$\\theta^* (\\lambda) \\triangleq \\underset{\\theta \\in \\Theta}{\\text{argmin }} L(P_z, \\theta, \\lambda), \\quad L(P_z, \\theta, \\lambda) \\triangleq \\mathbb{E}_{z \\sim P_z} [l(z, \\theta) + \\lambda \\pi(\\theta)]$\nwhere usually z = (x,y) comprised of a covariate x and a label y that distributed according to Px(x)Py|x(y|x). Our analysis assumes a one-dimensional label, as is common in many typical machine-learning problems (regression, classification, etc). The distribution Pz is often inaccessible,"}, {"title": "Machine Unlearning", "content": "After using a dataset S to train and publish a model \u03b8s(\u03bb), a set of m users in the training set U \u2282 S might request that their data points be deleted and that any models produced using their data to be removed. An organization might initially consider re-optimizing the leave--out objective L(S\\U, \u03b8, \u03bb) to produce \u03b8s\\U(\u03bb) to comply with this request. While re-optimizing from scratch constitutes a baseline for unlearning, the computational cost makes complying with every data deletion request undesirable. Thus, our goal is to derive an efficient method to approximate \u03b8s\\U(\u03bb) without retraining over the entire dataset S\\U from scratch. Ultimately, our method will only require access to the samples to be deleted U and possibly additional statistics about the original dataset S, B(S), obtained during the training process. Moreover, we aim to prevent an external observer from distinguishing between the approximated solution (denoted by \u03b8s\\U) and the ERM-minimizer \u03b8s\\U. This goal can be defined similarly to the classical definition of Differential Privacy (DP) [1, 2], which can be informally explained as the requirement that, with high-probability, an observer cannot differentiate between the two cases:\n1. The model is trained on the set S and then a set U is deleted by the unlearning algorithm.\n2. The model is trained on the set S\\U, and no points are deleted thereafter.\nMathematically, this notion is captured by the next definition by Sekhari et al. [1], which generalizes the privacy notions from the DP literature [16, 17]\nDefinition 1 ((\u03b5, \u03b4)-unlearning). For all S of size n, delete requests U \u2282 S such that |U| \u2264 m, and learning algorithm A : S \u2192 \u03b8 \u2208 \u0398, an unlearning algorithm A is (\u20ac, \u03b4)-unlearning if Y\u2286 \u0398\nP $( \\bar{\\mathcal{A}} (\\mathcal{U}, A(\\mathcal{S}), B(\\mathcal{S})) \\in \\Upsilon) \\leq e^{\\epsilon} \\cdot \\mathbb{P} (\\bar{\\mathcal{A}} (\\emptyset, A(\\mathcal{S} \\setminus \\mathcal{U}), B(\\mathcal{S} \\setminus \\mathcal{U})) \\in \\Upsilon) + \\delta, $\n$\\mathbb{P} (\\bar{\\mathcal{A}} (\\emptyset, A(\\mathcal{S} \\setminus \\mathcal{U}), B(\\mathcal{S} \\setminus \\mathcal{U})) \\in \\Upsilon) \\leq e^{\\epsilon} \\cdot \\mathbb{P} (\\bar{\\mathcal{A}} (\\mathcal{U}, A(\\mathcal{S}), B(\\mathcal{S})) \\in \\Upsilon) + \\delta$\nwhere \u2205 is the empty set, \u0454 and \u03b4 are some positive constants, and B(S) are some statistics.\nIntuitively, this definition asserts that an external observer cannot distinguish between a model trained on S\\U and a model trained on S and then unlearning A."}, {"title": "Natural Gradient Descent", "content": "Natural Gradient Descent (NGD) is considered an efficient method to optimize the sum of likelihood functions from a parametric family [18, 19, 20]. In supervised learning, given a training set S and a loss l(\u00b7), we aim to minimize the population risk (1) by minimizing the empirical risk (2). This problem is equivalent to the following maximum-likelihood estimation over the model parameters\n$\\theta_\\mathcal{S} = \\underset{\\theta}{\\text{argmax }} \\sum_{(x,y) \\in \\mathcal{S}} \\log (P_{y|x} (y|x; \\theta)) \\triangleq \\underset{\\theta}{\\text{argmin }} L(\\mathcal{S}, \\theta, \\lambda = 0),$\ngiven our assumption that the data is distributed according to $P_{y|x}(y|x;\\theta)P_x(x)$ and where $l(z, \\theta) \\triangleq - \\log (P(y|x; \\theta))$. This interpretation comes up naturally in many machine learning problems when"}, {"title": "Computationally Efficient Unlearning for Convex Models", "content": "Our goal is to develop a computationally efficient second-order algorithm for machine unlearning that provably satisfies the (\u20ac, \u03b4)-unlearning of Def. 1. To that end, we use the NGD to develop such an algorithm. We start by proposing an algorithm for the convex case, for which we formally prove the unlearning requirement. In Sec. 5, we will extend our algorithm for non-convex cases. Our notations correspond to the ERM framework presented in Sec. 3.1. Our development targets regression and classification tasks."}, {"title": "Method: Unlearning via the NGD", "content": "The aim of our first algorithm is to guarantee fast unlearning in convex models. Building on the existing unlearning techniques, which are based on the Newton step [1, 2], our method shows that the Newton step can be replaced by an NGD step while still maintaining the same unlearning guarantees. However, since the NGD step is computationally cheaper than the Newton step in many models, this algorithm leads to significant savings in terms of computational time. Throughout the analysis, we will make use of the proximal operator, defined via\n$\\text{prox}_{\\Theta}^H(v) = \\underset{\\theta \\in \\Theta}{\\text{argmin }} \\{ (v - \\theta)^T H (v - \\theta) + 2 \\lambda \\pi(\\theta) \\}$\nBeyond the computational efficiency of the NGD step, the FIM is guaranteed to be PSD, further improving computational stability [10, 26, 27, 28]. The FIM structure also supports many practical approximation algorithms useful in neural network optimization and training [25, 26, 29]. Our NGD-based unlearning algorithm is presented in Alg. 1."}, {"title": "Unlearning Non-Convex Models via NGD-Based Min/Max Training", "content": "Using classical theoretical developments established for NGD, we now apply Alg. 1 to real-world models, which usually violate assumptions 1.a and 1.b. Alg. 1 employs a natural gradient ascent step towards the data in U, which amounts to natural gradient descent step over the data in S\\U, assuming that \u2207L(S,\u03b8s(\u03bb), \u03bb) = 0. Therefore, we propose using a Min/Max optimization algorithm that entails executing both steps iteratively. This formulation amounts to first maximizing the loss on U and then minimizing it on S\\U and can be mathematically captured by employing a Min/Max training [37, 38] over the combined loss\n$L_{\\text{Min/Max}} = L(\\mathcal{S} \\setminus \\mathcal{U}, \\theta, \\lambda) - L(\\mathcal{U}, \\theta, \\lambda) = \\frac{1}{|\\mathcal{S} \\setminus \\mathcal{U}|} \\sum_{z \\in \\mathcal{S} \\setminus \\mathcal{U}} l(z, \\theta) - \\frac{1}{|\\mathcal{U}|} \\sum_{z \\in \\mathcal{U}} l(z, \\theta).$\nAs is usually done in Min/Max training, we minimize LMin/Max with an additional smoothing term [38]. Our algorithm is presented in Alg. 2 where we calculate the NGD steps of Alg. 2 using one of the K-FAC schemes proposed for scaling NGD to large models [25, 26].\nComparison of our Alg. 2 to Scrub. Alg. 2 resembles the state-of-the-art Scrub algorithm [9], which has been proposed for unlearning data. While our algorithm directly minimizes a linear combination of loss functions, Scrub optimizes a more complicated linear combination of the loss function and KL-divergences. The combination of losses and KL terms used by Scrub requires careful tuning of the weighting of both factors and scheduling of learning-rate decay. Our algorithm, on the other hand, does not require this weighting and thus requires fewer hyperparameters, making its training process more stable. As demonstrated in Sec. 5.1, our algorithm outperforms Scrub in multiple settings."}, {"title": "Experiments", "content": "We compare our Min/Max NGD algorithm to other unlerning algorithms such as Scrub by examining (1) the amount of information that is left about the removed examples in the new model and (2) test accuracy. The experimental setting is similar to that described in Sec. 4.2. To measure the amount of information that is left about the removed examples, we use a Membership Inference Attack (MIA) that assesses if a sample was part of the training set [9, 39, 40]. In particular, we have implemented the MIA that uses logistic regression to classify losses that correspond to both examples from the forget set and from the test set [9]. The success rate of this attack (i.e., the number of correct guesses between the test set and the forget set) is measured on ResNet18 and CNN models trained to classify the CIFAR-10 dataset [41] (a precise description of the models is given in App. H). Baseline unlearning algorithms include a fine-tuning algorithm on the retain set and the Scrub algorithm from [9]. Each algorithm ran for six epochs. We measured the test accuracy and the MIA score of the"}, {"title": "Discussion", "content": "We study the unlearning problem from a probabilistic approach, utilizing NGD as an unlearning algorithm due to its known computational efficiency compared to existing second-order methods."}]}