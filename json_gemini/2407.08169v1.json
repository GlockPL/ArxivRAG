{"title": "Faster Machine Unlearning via Natural Gradient Descent", "authors": ["Omri Lev", "Ashia Wilson"], "abstract": "We address the challenge of efficiently and reliably deleting data from machine learning models trained using Empirical Risk Minimization (ERM), a process known as machine unlearning. To avoid retraining models from scratch, we propose a novel algorithm leveraging Natural Gradient Descent (NGD). Our theoretical framework ensures strong privacy guarantees for convex models, while a practical Min/Max optimization algorithm is developed for non-convex models. Comprehensive evaluations show significant improvements in privacy, computational efficiency, and generalization compared to state-of-the-art methods, advancing both the theoretical and practical aspects of machine unlearning.", "sections": [{"title": "Introduction", "content": "The exponential growth in data collection and machine learning applications has intensified concerns about user privacy and data security. Legislative frameworks such as the European Union's General Data Protection Regulation (GDPR), California's Consumer Privacy Act (CCPA), and Canada's proposed Consumer Privacy Protection Act (CPPA) emphasize the right of individuals to have their data deleted upon request. These new requirements have catalyzed the development of \"machine unlearning\" the process of modifying a trained model to eliminate the influence of specific data inputs, effectively making the model \"forget\" this data. The main challenge is making this process efficient without resorting to retraining models from scratch, which is computationally expensive and unsustainable as the scale of models and data grows.\nHistorically, theoretical approaches to machine unlearning have predominantly focused on convex models, where the problem space allows for the development of algorithms with provable guarantees of privacy and correctness. These methods often rely on operations like the Newton step, which, while effective, are computationally demanding for large-scale applications. In contrast, practical approaches typically address more complex, non-convex models using heuristic methods that lack formal privacy guarantees. These methods often re-optimize the model on a pruned dataset, which is believed not to contain the information intended for unlearning-a computationally expensive process that can inadvertently retain data influence and thus compromise privacy.\nThis paper proposes a novel algorithm based on Natural Gradient Descent (NGD)\u2014a gradient algorithm that preconditions a gradient descent update with the inverse of the Fisher information matrix of the underlying statistical model. By treating the ERM problem through the lens of maximum-likelihood estimation, we first develop an algorithm for convex models, proving it maintains strong unlearning guarantees and is more computationally efficient than existing methods, which are based on the Newton step. Leveraging NGD's adaptability to large models, we design a practical unlearning algorithm based on a Min/Max optimization procedure for realistic settings. Our new algorithm outperforms state-of-the-art unlearning algorithms in multiple aspects."}, {"title": "Related Work", "content": "The goal of exact unlearning, first proposed by Cao and Yang [4], is to find a model whose predictions match those of a retrained model. This can be achieved through retraining or using other techniques that tend to be computationally or memory-intensive [5, 6, 7]. In contrast, approximate unlearning is a less stringent requirement that allows the unlearned model to deviate from the retrained model by a bounded amount. Several works have introduced more efficient methods that satisfy these inexact criteria [1, 2, 8, 9, 10, 11].\nWe develop a computationally efficient algorithm that satisfies the (\u20ac, \u03b4)-approximate unlearning definition from Sekhari et al. [1]. Sekhari et al. [1] also prove that approximate unlearning can be achieved using a Newton step towards the gradient of the points we aim to unlearn in the convex case. This algorithm was later generalized to efficiently remove points online and to delete points in scenarios involving non-differentiable regularizers [2].\nIn contrast to previous work that utilizes Newton-style updates and requires a full Hessian inversion, we aim to reduce this computational burden by leveraging the NGD [12]. NGD offers a low-cost second-order update by replacing the Hessian with the Fisher Information Matrix (FIM). As we will show, the NGD update is closely related to the Fisher-unlearning methods studied by Golatkar et al. [11, 13] and Wang et al. [14]. Our contributions improve upon these previous algorithms in two key ways. First, we are the first to prove that FIM-based methods satisfy the (\u20ac, \u03b4)-unlearning definition, establishing the correctness of our algorithm in the convex case. Second, we demonstrate that FIM-based methods are specific cases of second-order unlearning methods that replace the Hessian with its Positive Semi-Definite (PSD) approximation, given by the Gauss-Newton Matrix [12]. This exploration introduces a more general framework that paves the way for developing advanced unlearning methods.\nWe end by turning our sights to unlearning in the non-convex regime. While recent works have also introduced unlearning algorithms based on the Min/Max training procedure [9], we extend this theory and show how these methods can be enhanced by incorporating Min/Max training based on NGD."}, {"title": "Background", "content": "We now discuss the problem of learning and unlearning and review NGD algorithm."}, {"title": "Machine Learning", "content": "In our learning setting, we aim to minimize an objective function comprised of a loss function l, a regularizer \u03c0, and a regularization parameter \u03bb\u2208 [0,\u221e). The goal of learning is to find a parameter \u03b8*(\u03bb) \u2208 \u0398 that minimizes the population risk\n$\\theta^*(\\lambda) \\triangleq \\underset{\\theta \\in \\Theta}{\\operatorname{argmin}} L(P_z, \\theta, \\lambda), \\quad L(P_z, \\theta, \\lambda) \\triangleq \\mathbb{E}_{z \\sim P_z} [l(z, \\theta) + \\lambda \\pi(\\theta)]$\nwhere usually z = (x,y) comprised of a covariate x and a label y that distributed according to Px(x)Py|x(y|x). Our analysis assumes a one-dimensional label, as is common in many typical machine-learning problems (regression, classification, etc). The distribution Pz is often inaccessible,"}, {"title": "Machine Unlearning", "content": "After using a dataset S to train and publish a model \u03b8S(\u03bb), a set of m users in the training set U \u2286 S might request that their data points be deleted and that any models produced using their data to be removed. An organization might initially consider re-optimizing the leave--out objective L(S\\U, \u03b8, \u03bb) to produce \u03b8S\\U(\u03bb) to comply with this request. While re-optimizing from scratch constitutes a baseline for unlearning, the computational cost makes complying with every data deletion request undesirable. Thus, our goal is to derive an efficient method to approximate \u03b8S\\U(\u03bb) without retraining over the entire dataset S\\U from scratch. Ultimately, our method will only require access to the samples to be deleted U and possibly additional statistics about the original dataset S, B(S), obtained during the training process. Moreover, we aim to prevent an external observer from distinguishing between the approximated solution (denoted by \u03b8\u02c6S\\U) and the ERM-minimizer \u03b8S\\U. This goal can be defined similarly to the classical definition of Differential Privacy (DP) [1, 2], which can be informally explained as the requirement that, with high-probability, an observer cannot differentiate between the two cases:\n1.  The model is trained on the set S and then a set U is deleted by the unlearning algorithm.\n2.  The model is trained on the set S\\U, and no points are deleted thereafter.\nMathematically, this notion is captured by the next definition by Sekhari et al. [1], which generalizes the privacy notions from the DP literature [16, 17]\nDefinition 1 ((\u03b5, \u03b4)-unlearning). For all S of size n, delete requests U \u2286 S such that |U| \u2264 m, and learning algorithm A : S \u2192 \u03b8 \u2208 \u0398, an unlearning algorithm A is (\u20ac, \u03b4)-unlearning if \u2200Y\u2286 \u0398\n$P(\\bar{A}(U, A(S), B(S)) \\in \\Upsilon) \\leq e^{\\epsilon} \\cdot P(\\bar{A}(\\emptyset, A(S\\backslash U), B(S\\backslash U)) \\in \\Upsilon) + \\delta, \\\\ P(\\bar{A}(\\emptyset, A(S\\backslash U), B(S\\backslash U)) \\in \\Upsilon) \\leq e^{\\epsilon} \\cdot P(\\bar{A}(U, A(S), B(S)) \\in \\Upsilon) + \\delta$\nwhere \u00d8 is the empty set, \u0454 and \u03b4 are some positive constants, and B(S) are some statistics.\nIntuitively, this definition asserts that an external observer cannot distinguish between a model trained on S\\U and a model trained on S and then unlearning A."}, {"title": "Natural Gradient Descent", "content": "Natural Gradient Descent (NGD) is considered an efficient method to optimize the sum of likelihood functions from a parametric family [18, 19, 20]. In supervised learning, given a training set S and a loss l(\u00b7), we aim to minimize the population risk (1) by minimizing the empirical risk (2). This problem is equivalent to the following maximum-likelihood estimation over the model parameters\n$\\theta_S = \\underset{\\theta}{\\operatorname{argmax}} \\sum_{(x,y) \\in S} \\log (P_{y|x} (y|x; \\theta)) \\triangleq \\underset{\\theta}{\\operatorname{argmin}} L(S, \\theta, \\lambda=0),$\ngiven our assumption that the data is distributed according to Py|x(y|x;\u03b8)Px(x) and where l(z, 0) \uc2ac \u2212 log (P (y|x; 0)). This interpretation comes up naturally in many machine learning problems when"}, {"title": "Computationally Efficient Unlearning for Convex Models", "content": "Our goal is to develop a computationally efficient second-order algorithm for machine unlearning that provably satisfies the (\u20ac, \u03b4)-unlearning of Def. 1. To that end, we use the NGD to develop such an algorithm. We start by proposing an algorithm for the convex case, for which we formally prove the unlearning requirement. In Sec. 5, we will extend our algorithm for non-convex cases. Our notations correspond to the ERM framework presented in Sec. 3.1. Our development targets regression and classification tasks."}, {"title": "Method: Unlearning via the NGD", "content": "The aim of our first algorithm is to guarantee fast unlearning in convex models. Building on the existing unlearning techniques, which are based on the Newton step [1, 2], our method shows that the Newton step can be replaced by an NGD step while still maintaining the same unlearning guarantees. However, since the NGD step is computationally cheaper than the Newton step in many models, this algorithm leads to significant savings in terms of computational time. Throughout the analysis, we will make use of the proximal operator, defined via\n$\\operatorname{prox}_\\Theta^H (v) = \\underset{\\theta \\in \\Theta}{\\operatorname{argmin}} \\{ (v - \\theta)^T H (v - \\theta) + 2 \\lambda \\pi(\\theta) \\}$\nfor a PSD H. Beyond the computational efficiency of the NGD step, the FIM is guaranteed to be PSD, further improving computational stability [10, 26, 27, 28]. The FIM structure also supports many practical approximation algorithms useful in neural network optimization and training [25, 26, 29]. Our NGD-based unlearning algorithm is presented in Alg. 1."}, {"title": "Unlearning Non-Convex Models via NGD-Based Min/Max Training", "content": "Using classical theoretical developments established for NGD, we now apply Alg. 1 to real-world models, which usually violate assumptions 1.a and 1.b. Alg. 1 employs a natural gradient ascent step towards the data in U, which amounts to natural gradient descent step over the data in S\\U, assuming that VL(S, \u03b8S(\u03bb), \u03bb) = 0. Therefore, we propose using a Min/Max optimization algorithm that entails executing both steps iteratively. This formulation amounts to first maximizing the loss on U and then minimizing it on S\\U and can be mathematically captured by employing a Min/Max training [37, 38] over the combined loss\n$L^{Min/Max} = L(S\\backslash U, \\theta, \\lambda) - L(U, \\theta, \\lambda) = \\frac{1}{|S\\backslash U|} \\sum_{z \\in S\\backslash U} l(z, \\theta) - \\frac{1}{|U|} \\sum_{z \\in U} l(z, \\theta).$\nAs is usually done in Min/Max training, we minimize LMin/Max with an additional smoothing term [38]. Our algorithm is presented in Alg. 2 where we calculate the NGD steps of Alg. 2 using one of the K-FAC schemes proposed for scaling NGD to large models [25, 26].\nComparison of our Alg. 2 to Scrub. Alg. 2 resembles the state-of-the-art Scrub algorithm [9], which has been proposed for unlearning data. While our algorithm directly minimizes a linear combination of loss functions, Scrub optimizes a more complicated linear combination of the loss function and KL-divergences. The combination of losses and KL terms used by Scrub requires careful tuning of the weighting of both factors and scheduling of learning-rate decay. Our algorithm, on the other hand, does not require this weighting and thus requires fewer hyperparameters, making its training process more stable. As demonstrated in Sec. 5.1, our algorithm outperforms Scrub in multiple settings."}, {"title": "Experiments", "content": "We compare our Min/Max NGD algorithm to other unlerning algorithms such as Scrub by examining (1) the amount of information that is left about the removed examples in the new model and (2) test accuracy. The experimental setting is similar to that described in Sec. 4.2. To measure the amount of information that is left about the removed examples, we use a Membership Inference Attack (MIA) that assesses if a sample was part of the training set [9, 39, 40]. In particular, we have implemented the MIA that uses logistic regression to classify losses that correspond to both examples from the forget set and from the test set [9]. The success rate of this attack (i.e., the number of correct guesses between the test set and the forget set) is measured on ResNet18 and CNN models trained to classify the CIFAR-10 dataset [41] (a precise description of the models is given in App. H). Baseline unlearning algorithms include a fine-tuning algorithm on the retain set and the Scrub algorithm from [9]. Each algorithm ran for six epochs. We measured the test accuracy and the MIA score of the"}, {"title": "Discussion", "content": "We study the unlearning problem from a probabilistic approach, utilizing NGD as an unlearning algorithm due to its known computational efficiency compared to existing second-order methods.\nTheoretically, our study is the first to formally prove that, in a convex setting, NGD-based unlearning satisfies the (\u03b5, \u03b4) notion of unlearning. Since NGD is often approximated using Kronecker factors [26], investigating the unlearning capabilities of these approximated NGD algorithms presents another intriguing research direction. Furthermore, in many instances, an explicit NGD step can be directly computed by taking gradients relative to transformed versions of the model parameters [42, 43]. Exploring efficient NGD-based unlearning algorithms using these methods is a promising avenue for future research. Unlike the Scrub algorithm, which lacks theoretical support, our algorithm is proven to meet the (\u03b5, \u03b4)-unlearning requirement in convex cases. Extending this theory to more complex scenarios could demonstrate that Min/Max NGD formally satisfies the (\u20ac, \u03b4)-unlearning requirement.\nOn the practical side, we developed a Min/Max training algorithm leveraging NGD to delete samples. Our results show that our algorithm enhances the MIA score while maintaining nearly the same test accuracy as state-of-the-art baselines. Additionally, our algorithm requires fewer hyperparameters than existing algorithms. Given the known instability issues of Min/Max training procedures [9, 44], our approach results in a more stable training process. We encourage future work to explore the applicability of Min/Max NGD in larger models, various architectures, different training objectives, and across diverse domains and modalities. It is important to note that while most unlearning baselines report MIA as a measure of the amount of information the model retains about the unlearned samples, MIA still lacks a meaningful interpretation in terms of the privacy guarantees of the system, specifically regarding the (\u20ac, \u03b4) from Def. 1 (see a detailed discussion in [40]). The practical"}, {"title": "Broader Impact", "content": "The ability to unlearning at scale is crucial for the practical deployment of artificial intelligence (AI) systems, providing an effective tool for users to manage the amount of sensitive information that machine learning models reveal about their training data. Our proposed technique offers a provable solution for unlearning data in convex cases, significantly enhancing privacy control in such scenarios. However, it is important to recognize that while the Min/Max NGD method shows promise, it lacks a formal privacy proof for non-convex cases. Therefore, any application of this algorithm for data deletion should be approached with caution. Rigorous auditing and validation processes must be in place to ensure that the intended privacy guarantees are met and that the system does not inadvertently retain sensitive information. By highlighting these considerations, we aim to encourage responsible use and further research to extend formal privacy guarantees to non-convex models."}, {"title": "Notation", "content": "The notation used in this manuscript is outlined as follows. We denote random variables using sans-serif fonts (x, y, z) and their realizations using regular italic fonts (x, y, z). The Probability Density Function (PDF) of a random variable z is denoted by Pz(\u00b7). Groups of values are represented by capital calligraphic letters, such as S \u2252 {z1, z2,..., zn}. Real numbers are denoted by R. Matrices are denoted by bold capital letters, with the symbol Id specifically representing the d \u00d7 d identity matrix. When it is clear from the context that we are referring to matrices (for example, \u22072 f(\u00b7)), regular notation is used. L2 norms are denoted by ||\u00b7||. We use the usual convention of f(x) = o(g(x)) to denote that $\\lim_{x\\to\\infty} \\frac{f(x)}{g(x)} = 0$, and f(x) = O(g(x)) to denote that $\\lim_{x\\to\\infty} \\frac{f(x)}{g(x)} = C$ for some finite constant c (c \u2260 0)."}, {"title": "Definitions", "content": "The manuscript uses the next classical definitions from the convex optimization theory [46].\nDefinition 2 (Strong convexity). Let \u03b2 > 0. A function f(\u00b7) is called \u03b2-strongly convex if and only if\n$f(y) \\geq f(x) + \\nabla^T f(x)(y - x) + \\frac{\\beta}{2} ||x - y||^2, \\quad \\forall (x, y) \\in \\operatorname{dom}(f)$\nDefinition 3 (Lipschitzness). A function f(\u00b7) is called C-Lipschitz if\n$|| f(x) - f(y)|| \\leq C ||x - y||, \\quad \\forall (x, y) \\in \\operatorname{dom}(f)$.\nIf f(\u00b7) is differentiable, then f(\u00b7) is called K-smooth if\n$||\\nabla f(x) - \\nabla f(y)|| \\leq K ||x - y||, \\quad \\forall (x, y) \\in \\operatorname{dom}(f)$.\nFurthermore, if f(\u00b7) is further twice differentiable, then f(\u00b7) is called M-Hessian Lipschitz if\n$||\\nabla^2 f(x) - \\nabla^2 f(y)|| \\leq M ||x - y||, \\quad \\forall (x, y) \\in \\operatorname{dom}(f)$"}, {"title": "Loss Functions With an Exponential Family Structure", "content": "In this section, we present a few examples of common loss functions in machine learning of the form l (P (y|f(x; 0))) where P (y|f(x; 0)) belongs to an exponential family. Throughout the paper, we use the following convention to denote an exponential family\n$\\log (P (y|f(x; \\theta))) = f^T(x; \\theta)t(y) - \\log \\sum_{y \\in Y} \\exp \\{f^T(x; \\theta)t(\\tilde{y})\\} + \\beta(y)$\nand where t(y) are called the natural statistics and f(x; 0) are the natural parameters. Using this convention, we provide two popular examples of loss functions whose models fit this exponential family framework (see also [12, Sec. 9.2]).\n1.  Let\n$\\log (P(y|f(x; \\theta))) = f_y^T(x; \\theta) - \\log \\sum_{\\tilde{y}=1}^{|Y|} \\exp \\{f_{\\tilde{y}}^T(x; \\theta)\\}$\nwhere f (x; 0) is a vector of size |Y| and (f(x; 0))y denotes it y'th entry. By defining ey as a vector of zeros with the y'th entry equal to 1, we get that\n$\\log (P(y|f(x; \\theta))) = f^T (x; \\theta)e_y - \\log \\sum_{\\tilde{y}=1}^{|Y|} \\exp \\{ f^T (x; \\theta)e_{\\tilde{y}}\\}$\nwhich corresponds to an exponential family defined over a discrete alphabet of Y letters. Here, the natural statistics are t(y) = ey and the natural parameters are f(x;0)."}, {"title": "Fisher Information Matrix for Exponential Families", "content": "Using the fact that the distribution P (y|f(x; 0)) belongs to an exponential family, namely\n$\\log (P (y|f(x; \\theta))) = f^T (x;\\theta)t(y) - \\log \\sum_{y \\in Y} \\exp \\{f^T(x;\\theta)t(\\tilde{y})\\} + \\beta(y)$,\nwe can directly evaluate the terms $\\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [\\nabla_f \\log (P (y|f(x; \\theta)))) \\nabla_f \\log (P (y|f(x; \\theta)))]$ and $\\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [-\\nabla_f^2 \\log (P (y|f(x; \\theta)))]$ to establish the desired equality.\nFirst, we find that:\n$\\nabla_f \\log (P (y|f(x; \\theta))) = \\nabla_f \\left( f^T (x;\\theta)t(y) - \\log \\sum_{\\tilde{y} \\in Y} \\exp \\{f^T(x;\\theta)t(\\tilde{y})\\} \\right)$\n$= t(y) - \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)]$,\nthus,\n$\\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [\\nabla_f \\log (P (y|f(x; \\theta)))) \\nabla_f \\log (P (y|f(x; \\theta))))] = \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [(t(y) - \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)]) (t(y) - \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)])^T]$.\nNext, we observe that:\n$-\\nabla_f^2 \\log (P (y|f(x; \\theta))) = \\nabla_f \\frac{\\sum_{\\tilde{y}}t(\\tilde{y}) \\exp (f^T (x; \\theta)t(\\tilde{y}))}{\\sum_{\\tilde{y}} \\exp (f^T (x; \\theta)t(\\tilde{y}))}$\n$= \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y) t(y)^T] - (\\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)]) (\\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)])^T$\n$=\\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [(t(y) - \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)]) (t(y) - \\mathbb{E}_{y \\sim P_{y|x=\\tilde{x}; \\theta}} [t(y)])^T]$.\nMoreover, we note that this final result holds for any y. This concludes the proof."}, {"title": "Proof of Th. 1 in the Differentiable Case", "content": "We give the proof for the case where \u03c0(\u00b7) is a differentiable function. The proof for the non-differentiable case is given in App. F.\nProof. Recall that we have defined the loss function as\n$L(S,\\theta,\\lambda) = \\frac{1}{|S|} \\sum_{(x,y) \\in S} - \\log (P(y|f(x; \\theta))) + \\lambda \\pi(\\theta)$"}, {"title": "Proof of Generalization Guarantees", "content": "The proof follows similarly to [1, Lem. 9] and [2, Thm. 1]. Let \u03b8\u02c6S \u2261 \u03b8\u02c6S(\u03bb). We first re-write the difference between the population risks as\n$L (P_z, \\bar{\\theta}_{S \\backslash U}, \\lambda) - L (P_z, \\theta^*( \\lambda), \\lambda)$\n$= L (P_z, \\bar{\\theta}_{S \\backslash U}, \\lambda) - L (P_z, \\theta_{S}, \\lambda) + L (P_z, \\theta_{S}, \\lambda) - L (P_z, \\theta^*( \\lambda), \\lambda)$"}, {"title": "Experiments Details", "content": "All experiments were implemented using the PyTorch [49] framework, and we ran all experiments on NVIDIA Geforce RTX 3090 GPU. The datasets and models used in our experiments are detailed below."}, {"title": "Datasets", "content": "We utilized the MNIST [50] and CIFAR10 [41] datasets, as provided by the torchvision package in PyTorch. During training and for our unlearning simulations, the data was shuffled. We trained the models without data augmentation to stay aligned with previous unlearning works. The CIFAR10 dataset was pre-processed using the next two main steps: first, we converted the images to tensors using the transforms.ToTensor() method. Next, the images were normalized using the transforms.Normalize() method. The normalization process adjusts the image data so that the pixel values have a mean of 0.4914, 0.4822, and 0.4465 and a standard deviation of 0.2023, 0.1994, and 0.2010 for the red, green, and blue channels, respectively. The MNIST dataset was pre-processed using a similar pipeline, where we normalized the mean and the standard deviation to 0.5."}, {"title": "Neural Networks Architectures", "content": "All models were trained using a cross-entropy loss.\nOne-Layer Perceptron (OLP): We trained a one-layer perceptron to classify the MNIST dataset. The classifier has one hidden layer with 200 neurons and a ReLU activation function. It was trained for 100 epochs using the Adam optimizer, with a learning rate of 0.02, \u03b21 = 0.9, \u03b22 = 0.99, \u03f5 = 10\u22128, a weight decay of 10\u22124, and a batch size of 256.\nMulti-Layer Perceptron (MLP): Similar to the OLP architecture, the MLP was trained to classify the MNIST dataset. This model comprises three fully connected layers with widths of 784 \u00d7 784, 784 \u00d7 256, and 256 \u00d7 10, with ReLU activation between the layers. The classifier was trained using SGD for 100 epochs with a learning rate of 0.01, a weight decay of 10\u22124, and a batch size of 128. The learning rate was reduced by a factor of 10 at epoch 50.\nConvolutional Neural Network (CNN): The CNN architecture was designed to classify the CIFAR10 dataset. It comprises convolutional layers followed by fully connected layers. The convolutional part includes two convolutional layers with 16 and 32 output channels, respectively, and"}, {"title": "Unlearning Algorithms", "content": "This section details the implementation of our unlearning algorithms, Fine-Tuning, Scrub, and Min/Max NGD.\nFine-tunning: The fine-tunning algorithm fine-tunes the model on the retain set. In our implementation, we use batches of size 128, weight decay of 5 10\u22124, momentum of 0.9, and an initial learning rate of 0.05, reduced by a factor of 5 after each epoch. We have used two different optimizers: the first is the vanilla SGD optimizer of Pytorch, and the second aims to approximate an NGD according to the algorithm from [51]. Our implementation is based on the one presented in https://github.com/YiwenShaoStephen/NGD-SGD/tree/master, with the update-period parameter set to 4.\nScrub: Our implementation of the Scrub algorithm follows the procedure detailed in [9], based on the code provided at https://github.com/meghdadk/SCRUB. We set our hyperparameters similarly to those in the original paper [9]: we have used an Adam optimizer with an initial learning rate of 0.0005, reduced by a factor of 10 after each epoch, a weight-decay of 0.1, a smoothing factor of 0.5 and the parameter a of the Scrub algorithm (which weights the KL-term and the loss term) was set to 0.5. We used batches of 64 for the retain-set and of size 16 for the forget set. The rest of the hyperparameters were chosen similarly to those of [9].\nMin/Max NGD: The Min/Max NGD algorithm (Alg. 2) is implemented using a Min/Max training procedure similar to that in the Scrub implementation. Smoothing is performed using PyTorch's built-in function torch.optim.swa_utils.AveragedModel. The NGD was implemented based on the method from [51], with code from https://github.com/YiwenShaoStephen/NGD-SGD/tree/master. The learning rate is 0.0007 for the CNN example and 0.0005 for the ResNet example. We reduced the learning rate by a factor of 10 after 4 epochs. We set the momentum to 0.9, the weight-decay to 0.1, and the update period of the NGD to 4. The smoothing parameter (\u0398 of Alg. 2) was set to 0.4. We used batches of size 128 for the retain-set and 32 for the forget set."}, {"title": "Computing the Newton and the NGD Steps Using Li\u0130SSA", "content": "In this section, we review the Linear time Stochastic Second-Order Algorithm (LiSSA) algorithm, used for efficient implementation of second-order optimization methods [30] and which we used to demonstrate the computational efficiency of the NGD relative to a Newton step."}, {"title": "The LiSSA Algorithm", "content": "The LiSSA algorithm approximates the result of a matrix inverse times a vector by using a truncated Neumann series. Following our ERM framework, let A(S) be a positive-definite matrix of the form A(S) \u2259 \u03a3z\u2208S A(z) for some matrix A(z) that depends on the training point z. Using Neumann expansion, we can approximate its inverse via the next summation\n$\\left(A (S)\\right)^{-1} = \\sigma^{-1} \\cdot \\sum_{t=0}^T \\left(I_d - \\sigma^{-1} \\cdot (A (S))\\right)^t$\nwhere the approximation becomes exact as T \u2192 \u221e and where \u03c3 > 0 is a scaling hyperparameter chosen sufficiently large to ensure convergence of the series. We note that can be used to"}]}