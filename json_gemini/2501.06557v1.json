{"title": "A Survey on Spoken Italian Datasets and Corpora", "authors": ["Marco Giordano", "Claudia Rinaldi"], "abstract": "Spoken language datasets are vital for advancing linguistic research, Natural Language\nProcessing, and speech technology. However, resources dedicated to Italian, a linguistically\nrich and diverse Romance language, remain underexplored compared to major languages like\nEnglish or Mandarin. This survey provides a comprehensive analysis of 66 spoken Italian\ndatasets, highlighting their characteristics, methodologies, and applications. The datasets are\ncategorized by speech type, source and context, and demographic and linguistic features, with\na focus on their utility in fields such as Automatic Speech Recognition, emotion detection,\nand education. Challenges related to dataset scarcity, representativeness, and accessibility\nare discussed alongside recommendations for enhancing dataset creation and utilization. The\nfull dataset inventory is publicly accessible via GitHub and archived on Zenodo, serving as a\nvaluable resource for researchers and developers. By addressing current gaps and proposing\nfuture directions, this work aims to support the advancement of Italian speech technologies\nand linguistic research.", "sections": [{"title": "1 Introduction", "content": null}, {"title": "1.1 Background and Motivation", "content": "Spoken language datasets play a pivotal role in linguistic research, natural language processing\n(NLP), and speech technology. They provide the foundational data necessary for tasks such as\nautomatic speech recognition (ASR), speech synthesis, and sociolinguistic analysis. Despite sig-\nnificant advancements in the field, linguistic resources specific to Italian remain relatively limited,\nparticularly in comparison to languages such as English and Mandarin. Italian, as a Romance\nlanguage with rich phonological and dialectal diversity, offers unique challenges and opportuni-\nties for research. Its linguistic variability across regions, combined with socio-cultural nuances,\nmakes it a compelling subject of study for developing robust speech models. The increasing de-\nmand for speech-based applications\u2014ranging from virtual assistants to automated transcription"}, {"title": "1.2 Objectives of the Survey", "content": "This survey provides a comprehensive overview of spoken Italian datasets, cataloging them by\nspeech type, source, demographic diversity, and linguistic features. It examines methodologies for\ndata collection, annotation, and validation, highlighting best practices and challenges. Practical\napplications, such as speech recognition, emotion detection, sociolinguistics, and education, are also\nexplored.\nTo ensure inclusivity, the survey includes both public and commercial datasets, focusing on\nthose actively maintained as of November 2024 with sufficient available information. While dataset\nquality and availability were not independently verified, the survey synthesizes information provided\nby creators or documentation. By identifying gaps and limitations, it offers recommendations for\ncreating future datasets, emphasizing collaboration and standardization to expand and improve\nspoken Italian corpora. While the paper highlights key datasets to illustrate the discussed categories\nand methodologies, the full collection comprises 66 datasets, encompassing a wide range of speech\ntypes, linguistic features, and applications. This complete dataset inventory is publicly accessible\nvia GitHub and archived on Zenodo (DOI: 10.5281/zenodo.14246196), providing an useful and\ncollaborative resource for researchers and developers."}, {"title": "1.3 Structure of the paper", "content": "The remainder of this paper is organized as follows.\n\u2022 Section 2 categorizes spoken Italian datasets based on speech type, source, and demographic\nfeatures, providing an overview of their characteristics and applications.\n\u2022 Section 3 describes the methodologies for data collection, annotation, and transcription, high-\nlighting best practices and common challenges.\n\u2022 Section 4 explores the practical applications of spoken Italian datasets in linguistic research,\nNLP, and speech technology.\n\u2022 Section 5 discusses the challenges and limitations of existing datasets, including issues related\nto accessibility, representation, and technical constraints.\n\u2022 Section 6 outlines future directions and recommendations for addressing the identified gaps\nand improving dataset quality.\n\u2022 Section 7 concludes by summarizing the findings and emphasizing the importance of collabo-\nrative efforts for advancing spoken Italian datasets."}, {"title": "2 Categorization of Spoken Italian Datasets and Corpora", "content": "Spoken Italian datasets vary widely in their structure, scope, and focus, reflecting the diverse needs\nof linguistic research and speech technology development. To provide a clear understanding of their\ncharacteristics and applications, this section categorizes the datasets based on speech type, source"}, {"title": "2.1 By Type of Speech", "content": "The categorization of spoken Italian datasets by type of speech provides a structured way to under-\nstand their applications and relevance. This classification reflects the diversity of speech contexts,\neach serving unique research and technological objectives."}, {"title": "2.1.1 Conversational Speech", "content": "Datasets in this category capture dialogues and interactions, often in natural settings. Examples\ninclude datasets derived from interviews, informal conversations, or scripted dialogues for dialogue\nsystems. These datasets are critical for training conversational agents, studying discourse patterns,\nand advancing dialogue-based NLP applications.\nThe KIParla corpus [1] [2] provides a diverse range of conversational data collected through\nsemi-structured interviews, table discussions, and spontaneous conversations across different cities\nin Italy, such as Bologna and Turin. Similarly, the Italian Spontaneous Dialogue Dataset [3],\nencompassing 1,797 hours of unscripted conversations recorded in domains like banking and insur-\nance, simulates real-world interactions. Another key resource is the DIA - Dialogic Italian [4],\nwhich focuses on spontaneous dialogues between well-acquainted speakers, recorded under controlled\nconditions to ensure the authenticity of natural speech patterns."}, {"title": "2.1.2 Monologues", "content": "Monologue datasets consist of continuous speech from a single speaker and are instrumental for\ntasks such as public speaking tools, prosody analysis, and speech synthesis [5], [6].\nThe Italian Scripted Monologue Dataset [7], containing over 2,500 hours of pre-scripted speech\nrecorded on mobile devices, is a prime example. Additionally, VoxPopuli [8, 9] provides a rich\nsource of formal monologues, drawn from European Parliament sessions, that capture structured\nspeech in professional settings, furthering research in areas like speech translation and recognition."}, {"title": "2.1.3 Spontaneous Speech", "content": "Spontaneous speech datasets capture the variability and unpredictability of natural, unplanned\nlanguage use, making them essential for robust ASR systems and linguistic analysis [10] [11].\nThe LABLITA corpus [12,13], featuring recordings from face-to-face conversations and telephone\ncalls, is a cornerstone for studying prosodic and pragmatic features in natural Italian speech. An-\nother valuable dataset is the C-ORAL-ROM corpus [14], which focuses on authentic spoken\ninteractions in various informal contexts, including group discussions and everyday exchanges. Its\nrich spontaneous speech data supports research in conversational analysis and natural language\nprocessing."}, {"title": "2.1.4 Read Speech", "content": "Read speech datasets provide clean, controlled recordings, ideal for tasks like ASR training and\ntext-to-speech systems [15], [16]."}, {"title": "2.2 By Source and Context", "content": "The source and context of speech datasets determine their applicability and potential use cases.\nCategorizing datasets by source sheds light on their relevance to specific domains and scenarios\naligning the dataset with particular real world scenarios. Categorizing by context impacts the\ndataset applicability to use cases requiring specific conditions or settings (e.g. noisy environments,\nemotional speech, accents etc). From an acoustic point of view different sources (studio vs. field\nrecordings) vary in signal-to-noise ratios, reverberation, and other acoustic properties while contexts\nsuch as background noise [20], speaker diversity, or overlapping speech may affect pre-processing\nand model training strategies e.g. [21]."}, {"title": "2.2.1 Broadcast Media", "content": "Broadcast media datasets capture formal and semi-formal speech styles and are particularly useful\nfor applications in media transcription, sentiment analysis, media monitoring and sociolinguistic\nstudies [22], [23]. The IBNC [24], a collection of 15 hours of transcribed Italian radio broadcasts\ncovering diverse news topics, highlights this category. Similarly, the Italian Lifestyle Podcast\nDataset [25] includes recordings from live podcasts centered on lifestyle topics, such as mindfulness,\noffering conversational data in semi-formal contexts."}, {"title": "2.2.2 Telephone Speech", "content": "Telephone speech datasets are indispensable for developing telephony-based systems such as cus-\ntomer service automation, voice-based authentication, and call transcription tools [26]. The Italian\nSpontaneous Dialogue Telephony Speech Dataset - Nexdata [27] is a prominent resource,\nfeaturing 500 hours of conversational recordings made via mobile phones. These recordings include\na balanced representation of regional accents and cover various familiar topics, simulating natural\ninteractions in telephonic environments. Another notable dataset is the Italian Spontaneous\nDialogue Dataset [3] by Defined.ai, which includes telephony-based conversations recorded under\nboth noisy and silent conditions. This dataset's emphasis on diverse environments makes it highly\napplicable to real-world telephony use cases. Additionally, the Aurora Project Database [28],\ncollected over the GSM telephone network in vehicular environments, provides speech data influ-\nenced by background noise and motion, contributing to advancements in noise-robust telephony\nsystems. Together, these resources support the development of telephony applications with robust\nperformance across varied acoustic and contextual challenges."}, {"title": "2.2.3 Social Media and Online Platforms", "content": "Datasets sourced from social media and online platforms capture informal, dynamic, and contem-\nporary speech styles, making them invaluable for studying spontaneous language use and training\nNLP systems for social media applications. The MuST-C dataset [29], derived from TED Talks,"}, {"title": "2.2.4 Field Recordings", "content": "Field recordings capture natural speech in authentic, often uncontrolled environments, making\nthem essential for studying real-world linguistic diversity and for applications requiring robust\nASR systems. The VIVALDI corpus [31], for instance, focuses on regional dialects and mi-\nnority languages, offering rich insights into Italy's linguistic diversity through recordings gathered\nfrom public and informal settings. Similarly, the DEMOS [32,33] corpus includes recordings that,\nalthough conducted in controlled settings, elicit emotions that mimic natural interactions. This\napproach bridges the gap between spontaneous and emotionally charged speech, adding valuable\ndimensions to field-recording-like data. Currently, no additional datasets in this survey explicitly\nfeature field recordings as a primary characteristic, underscoring a potential gap in the representa-\ntion of naturalistic and spontaneous speech in public or outdoor environments within the scope of\nItalian spoken corpora."}, {"title": "2.3 By Demographic and Linguistic Features", "content": "Spoken Italian datasets vary significantly in their demographic and linguistic coverage. Datasets\nskewed toward a particular demographic (e.g., one gender, age group, or ethnicity) may lead to\nbiased models, while including balanced demographics ensures models perform equitably across\nall groups, avoiding unfair outcomes. If instead the purpose is toward the study of a particular\nregion or ethnic group, then it is worth noticing that the speech may be characterized by a different\nrhythm or intonation even within the same language, thus it is important to characterize these\nfeatures to make the dataset useful in applications targeting a specific community. Also the lack of\nlinguistic diversity in datasets leads to models that fail in real-world settings where varied accents\nor code-switching (mixing languages) are common. These distinctions highlight the sociolinguistic\ndimensions of speech data."}, {"title": "2.3.1 Regional Varieties and Dialects", "content": "Datasets highlighting regional varieties and dialects are essential for preserving linguistic diver-\nsity and understanding the intricate patterns of variation within Italian. These datasets enable\nresearchers to analyze phonological, syntactic, and lexical differences across regions and promote"}, {"title": "2.3.2 Sociolinguistic Variation", "content": "Sociolinguistic datasets capture variations in speech influenced by factors such as age, gender, socio-\neconomic status, and educational background. These datasets are critical for understanding how\nsocial variables shape linguistic practices and for building inclusive language technologies. The\nKIParla corpus [1, 2] is a key resource for sociolinguistic research, featuring participants from\ndiverse socio-economic, educational, and regional backgrounds. By including speakers of different\nages and genders, this dataset allows for nuanced analyses of how social factors interact with lin-\nguistic features in Italian. The LABLITA corpus [12,13] further enriches sociolinguistic research\nwith its recordings of natural speech collected from various social contexts, such as face-to-face\nconversations and telephone calls. The dataset includes participants across a wide age range and\nfrom different social strata, offering a comprehensive view of spoken Italian as influenced by soci-\nolinguistic diversity. The DEMOS corpus [32,33], focused on emotional speech, also contributes\nto sociolinguistic studies by involving participants aged 20 to 64 from varied socio-economic back-\ngrounds. This range supports the examination of how emotion and sociolinguistic variables interact\nin speech. Another significant dataset is the ITALIC corpus [34,35], which features crowdsourced\nrecordings from 70 speakers spanning different Italian regions, age groups, and genders. The di-\nversity of contributors ensures broad coverage of sociolinguistic variation, making it suitable for\nresearch in intent classification and linguistic variation. Lastly, the Common Voice project [19]\nby Mozilla includes contributions from a wide demographic spectrum, with metadata detailing the\nage, gender, and accents of speakers. This sociolinguistic richness makes the dataset valuable for\nstudying how demographic factors influence speech patterns in Italian."}, {"title": "2.3.3 Bilingual and Multilingual Corpora", "content": "Bilingual and multilingual corpora enable cross-linguistic studies and support the development\nof multilingual speech technologies, such as machine translation, speech synthesis, and multilin-\ngual ASR systems. These datasets are particularly valuable for studying language contact, code-"}, {"title": "3 Data Collection and Annotation Methodologies", "content": null}, {"title": "3.1 Data Collection Techniques", "content": "Effective data collection techniques are fundamental for creating robust spoken language datasets.\nThese techniques involve selecting representative samples of speakers, designing recording protocols,\nand ensuring high-quality audio capture. The methods employed vary significantly depending on the\ndataset's purpose, ranging from controlled studio settings to spontaneous field recordings. Proper\nplanning in data collection ensures the resulting datasets meet the specific requirements for linguistic\nresearch, ASR training, or speech technology applications."}, {"title": "3.1.1 Recording Methods", "content": "Recording methods play a crucial role in determining the quality and applicability of speech\ndatasets. They can range from controlled environments with professional equipment to real-world\nsettings with ambient noise, each providing unique advantages depending on the research goals.\nThe Apasci dataset [41] exemplifies a highly controlled approach, with recordings conducted in an\ninsulated room using a Sennheiser MKH 416 T microphone. This setup ensures high-fidelity audio,\nmaking the dataset suitable for phonetic research and speech recognition development. In contrast,\nthe Aurora Project Database [28] focuses on real-world scenarios by capturing speech in vehicles\nunder various driving conditions. Speech was recorded using multiple microphones connected to\ncomputers and mobile phones, providing data valuable for noise-robust speech recognition and in-\ncar voice command systems. The Italian Kids Speech Recognition Corpus (Desktop) [42] features\nrecordings of children in a quiet office setting, using high-quality microphones to ensure clarity while\nfocusing on a demographic often underrepresented in speech corpora. The Italian Spontaneous"}, {"title": "3.1.2 Participant Selection", "content": "Participant selection is a critical step in data collection, ensuring that speech datasets are repre-\nsentative of the target population and suitable for their intended applications. Factors such as\nage, gender, regional origin, socio-economic background, and linguistic proficiency are carefully\nconsidered to achieve demographic diversity and coverage. The KIParla corpus [1, 2] exempli-\nfies a well-rounded approach to participant selection, drawing speakers from diverse age groups,\ngenders, educational levels, and regional origins. This ensures the dataset captures sociolinguistic\nvariations across Italy, making it a valuable resource for comprehensive linguistic analysis. The\nDEMOS corpus [32,33], focused on emotional speech, employs a more targeted selection strategy.\nIt includes 68 native Italian speakers aged 20 to 64, chosen specifically for their vocal expressiv-\nity. This careful selection enhances the dataset's utility for research in speech emotion recognition\nand affective computing. For datasets targeting specific demographics, the Italian Kids Speech\nRecognition Corpus [42] is a prime example. It exclusively features recordings from children, en-\nsuring its relevance for applications such as educational tools and child-specific speech recognition\nsystems. The M-AILABS Speech Dataset [39] adopts a crowdsourced model, relying on volun-\nteer contributors from diverse backgrounds. While this approach introduces variability in speaker\ndemographics and recording conditions, it also ensures a wide-ranging representation, particularly\nfor read speech. Similarly, the Common Voice project [19] by Mozilla encourages open partici-\npation, with contributors from various age groups, genders, and regional accents. The associated\nmetadata provides valuable information about the speakers, enabling detailed demographic analysis\nand customization of speech models. In the case of dialectal and minority language preservation,\nthe VIVALDI corpus [31] focuses on native speakers of regional dialects and minority languages\nacross Italy. By selecting participants based on linguistic heritage, the dataset provides authentic\nrepresentations of Italy's linguistic diversity."}, {"title": "3.2 Annotation and Transcription Processes", "content": "Annotation and transcription add significant value to raw speech data, enabling downstream ap-\nplications like speech recognition, phonetic analysis, and linguistic studies."}, {"title": "3.2.1 Transcription Standards", "content": "Transcription standards are critical for ensuring that speech data can be accurately analyzed and\nutilized across diverse applications. Depending on the dataset's purpose, transcription may be\northographic [43], phonetic [44], or include additional linguistic annotations such as prosody or dis-\nfluencies. Proper transcription practices ensure data consistency, facilitate downstream processing,"}, {"title": "3.2.2 Annotation Levels", "content": "Annotation levels refer to the granularity and types of linguistic information included in speech\ndatasets. These levels can range from basic lexical transcriptions to detailed syntactic, semantic, and\nprosodic annotations, depending on the dataset's intended use. Comprehensive annotation enriches\nthe dataset, making it more versatile for applications in linguistics, speech technology, and natural\nlanguage processing. Automated annotation tools, such as those discussed in Stan's study [46], have\nincreasingly supported the generation of multi-level annotations. These tools streamline the anno-\ntation process, particularly for large-scale multilingual datasets. The LABLITA corpus [12, 13]\nexemplifies multi-level annotation, combining orthographic transcription with prosodic and prag-\nmatic features. This dataset includes annotations for intonation, stress patterns, and discourse\nmarkers, enabling research in prosody and discourse analysis for spontaneous speech. Its multi-\nlayered approach provides a rich resource for examining the interaction of linguistic and prosodic\nfeatures. Similarly, the VIVALDI corpus [31] incorporates lexical, syntactic, and phonetic an-\nnotations, with additional layers for dialectal and regional features. By documenting speech from\nvarious Italian dialects, the dataset supports studies in sociolinguistics and dialectology, while its\nsyntactic annotations facilitate syntax-based linguistic research. In the KIParla corpus [1,2],\nannotations include lexical content, turn-taking cues, and speaker metadata such as gender and\nage. This multi-level annotation enables the study of conversational dynamics and sociolinguis-\ntic variation, making it a valuable resource for analyzing spoken Italian in social contexts. The\nItalian Kids Speech Recognition Corpus [42] employs lexical and phonetic annotation to support\nchild-specific ASR development. This dual-layer annotation is particularly important for modeling\nthe phonological characteristics of children's speech, which differ from adult speech in pronunci-\nation, prosody, and syntax. Advanced datasets like MULTEXT Prosodic Database [40] integrate\nprosodic, syntactic, and semantic annotations. This database focuses on cross-linguistic prosody\nresearch, offering detailed annotations for stress patterns, pitch contours, and syntactic structures.\nSuch comprehensive annotation facilitates comparative studies across languages and applications\nin multilingual ASR systems. For emotional and expressive speech, the DEMOS corpus [32,33]"}, {"title": "3.2.3 Tools and Software Used", "content": "The quality and efficiency of speech data annotation depend significantly on the tools and soft-\nware employed. These tools facilitate tasks such as transcription, segmentation, and annotation\nof linguistic and prosodic features. Below are key tools and software used in annotating spoken\nItalian datasets, along with their contributions and applications. One of the most widely used\ntools is Praat [47], a software designed for phonetic analysis and annotation. Praat enables the\nannotation of pitch, intensity, and formant structures, making it indispensable for datasets like the\nLABLITA corpus [12,13], where prosodic features such as intonation patterns and stress need to\nbe analyzed in detail. ELAN [48], developed by the Max Planck Institute for Psycholinguistics, is\nanother key tool. ELAN supports multi-tier annotations, enabling researchers to align audio with\nlexical, syntactic, and semantic layers. It is frequently used in datasets like the VIVALDI cor-\npus [31], where dialectal and regional features require detailed annotation across multiple linguistic\ndimensions. The WebMAUS tool [49], developed by the Bavarian Archive for Speech Signals, au-\ntomates phonetic segmentation and alignment. Its ability to handle multilingual data, including\nItalian, makes it a valuable resource for datasets such as the KIParla corpus [1,2], where phonetic\nalignment is critical for analyzing conversational dynamics. For corpora focusing on emotion and\nexpressivity, tools like Emu-SDMS [50] provide integrated solutions for speech database manage-\nment and annotation. The DEMOS corpus [32,33] benefits from Emu-SDMS's ability to handle\nemotional speech annotations, including intensity levels and affective markers. SPPAS - SPeech\nPhonetization Alignment and Syllabification [51,52] is a specialized tool for generating annotations\nfor speech synthesis applications. It has been applied in datasets such as the Italian Scripted\nMonologue Dataset [7], where precise lexical and phonetic alignment is crucial for synthesizing\nhigh-quality speech. Finally, Annotald [53], a tool developed for syntactic and morphological an-\nnotation, has been utilized in datasets requiring deep linguistic analysis, such as the MULTEXT\nProsodic Database [40]."}, {"title": "3.3 Quality Control and Validation", "content": "Quality control and validation are essential steps in the creation of spoken language datasets,\nensuring that the data is accurate, consistent, and reliable for research and technology development.\nTechniques for maintaining quality vary depending on the dataset's purpose, size, and complexity\nbut typically include manual verification, automated checks, and statistical analyses.\nFor phonetic and lexical transcriptions, grapheme-to-phoneme (G2P) converters are often used\nto verify pronunciation patterns against standardized rules. In projects employing tools like RE-\nCOApy [46], automated G2P conversion identifies discrepancies in phonetic transcriptions, flagging\nthem for manual review, but according to our current knowledge, none of the documented datasets\nmade use of this tool in validation processes.\nOne common approach is manual validation, where trained linguists or annotators review a\nsubset of the dataset for errors or inconsistencies. For example, in the KIParla corpus [1,2], an-\nnotations were manually cross-checked by multiple experts to ensure the accuracy of transcriptions\nand metadata, particularly for conversational dynamics and turn-taking cues.\nInter-annotator agreement (IAA) [54] is another widely used metric for evaluating annotation\nconsistency. In the LABLITA corpus [12,13], IAA scores were computed to ensure that anno-"}, {"title": "4 Applications of Spoken Italian Datasets", "content": "Spoken Italian datasets could serve as foundational resources across a range of disciplines, enabling\nadvancements in both theoretical research and practical applications. Their diverse scope, encom-"}]}