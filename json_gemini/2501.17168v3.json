{"title": "EvoGP: A GPU-accelerated Framework for\nTree-based Genetic Programming", "authors": ["Lishuang Wang", "Zhihong Wu", "Kebin Sun", "Zhuozhao Li", "Ran Cheng"], "abstract": "Tree-based Genetic Programming (TGP) is a key\nevolutionary algorithm widely used in symbolic regression, fea-\nture engineering, and scientific modeling. Its high computational\ndemands make GPU acceleration essential for scalable and high-\nperformance evolutionary computation. However, GPU accelera-\ntion of TGP faces three key challenges: inefficient tree encoding,\nhighly heterogeneous genetic operations, and limited parallelism\nin fitness evaluation. To address these challenges, we introduce\nEvoGP, a comprehensive GPU-accelerated TGP framework.\nFirst, we design a tensorized encoding scheme to represent tree\nwith different structures as tensors with the same shape, opti-\nmizing memory access and enabling efficient parallel execution.\nSecond, we propose a unified parallel framework for genetic\noperations by leveraging shared computational primitives and\nimplementing dedicated CUDA kernels for scalable performance.\nThird, we present a fully parallel fitness evaluation strategy for\nsymbolic regression, exploiting both population-level and data-\nlevel parallelism to maximize GPU utilization. Moreover, we\nimplement a comprehensive library to provide rich algorithm\noperators and benchmark problems. EvoGP is extensively tested\non various tasks, including symbolic regression, classification, and\nrobotics control, demonstrating its versatility and effectiveness\nacross diverse application scenarios. Experimental results show\nthat EvoGP achieves up to a 140.89x speedup over the state-\nof-the-art GPU-based TGP implementation, while maintaining\nor exceeding the accuracy of baseline methods. EvoGP is open-\nsource and accessible at: https://github.com/EMI-Group/evogp.", "sections": [{"title": "I. INTRODUCTION", "content": "GENETIC Programming (GP) [1] is an evolutionary al-\ngorithm that autonomously evolves programs by emu-\nlating the principles of natural selection and genetic inher-\nitance. Unlike black-box models such as neural networks,\nGP provides human-readable solutions, making it a highly\ninterpretable machine learning paradigm [2]. Depending on\nthe representation of programs, GP is categorized into several\nvariants, including Linear GP (LGP) [3], [4], Cartesian GP\n(CGP) [5], [6], Gene Expression Programming (GEP) [7], and\nGrammatical Evolution (GE) [8]. Among these, TGP is the\nmost widely adopted approach [9], [10]. TGP represents pro-\ngrams as hierarchical tree structures, where nodes correspond\nto functions or operations, and edges denote data flow. This\nstructured representation allows flexible program evolution\nthrough genetic operations such as crossover, mutation, and\nselection. As a result, TGP has been successfully applied\nto a wide range of tasks, including regression [11]\u2013[14],\nclassification [15], [16], feature learning [17], [18], image and\nsignal processing [19], production scheduling [20], etc.\nTGP evolves a population of candidate solutions through\niterative genetic operations such as selection, crossover and\nmutation, followed by fitness evaluation. However, this process\nis computationally intensive, especially for large populations,\nas each generation requires performing genetic operations\nand evaluating every individual. Like other evolutionary algo-\nrithms, TGP is inherently parallelizable, since these operations\ncan be executed independently across individuals. Conse-\nquently, leveraging modern hardware architectures, particu-\nlarly GPUs, has become a compelling approach to alleviating\ncomputational overhead. In recent years, GPU acceleration\nhas gained widespread adoption in evolutionary computation,\nwith studies demonstrating significant speedups across various\nevolutionary algorithms [21]\u2013[26]. Given these advancements,\ndeveloping efficient GPU-accelerated techniques for TGP is\ncrucial to enhancing its scalability and performance.\nDespite the potential of GPU acceleration in TGP algo-\nrithms, designing an efficient TGP implementation for GPUs\npresents three major challenges. First, existing tree-encoding\nmethods are not directly suitable for GPU execution. The\ntwo primary encoding strategies, pointer-based tree encoding\n[27], [28] and prefix encoding [29]\u2013[31], both exhibit sig-\nnificant inefficiencies when applied to GPUs. Pointer-based\ntree encoding suffers from frequent global memory accesses\nand noncontiguous memory storage, leading to poor mem-\nory coalescing and increased latency. Prefix encoding, while\ncompact, loses structural information, requiring costly tree-\nparsing operations that introduce excessive logical branching\non GPUs. Additionally, both encoding methods struggle to\nhandle dynamic tree growth efficiently, necessitating memory\nreallocation, which further degrades GPU performance [32].\nSecond, the diverse variants of genetic operations in TGP,\nsuch as crossover and mutation, pose significant challenges for\nGPU acceleration. Each variant modifies the tree differently,\nmaking a comprehensive GPU implementation a substantial\nengineering effort. Additionally, some complex genetic op-\nerations require tree parsing and reconstruction, which are\ndifficult to parallelize efficiently on GPUs.\nThird, symbolic regression is one of the most important\napplications of TGP. However, the current state-of-the-art\nsymbolic regression [31] fitness evaluation primarily relies\non data-parallelism, which enables simultaneous processing of\ndifferent data points but does not support evaluating multiple\ntrees in parallel. This limitation becomes particularly problem-\natic when the number of data points in the symbolic regression\ntask is limited. In such cases, GPU computational resources\nare underutilized, leading to inefficiencies in execution.\nCurrently, several existing TGP libraries provide hardware\nacceleration. DEAP [29] and gplearn [30] enable parallel\nfitness evaluation on CPUs through multiprocessing, leverag-\ning multi-core architectures to speed up computations. Ka-\nrooGP [27] and TensorGP [28] employ TensorFlow-based\nvectorization to evaluate GP trees on multiple data points\nsimultaneously, improving the inference speed through GPU-\naccelerated computation. SR-GPU [31], the current state-\nof-the-art TGP implementation, further advances GPU-based\nevaluation by implementing CUDA kernels specifically de-\nsigned for symbolic regression. These implementations focus\nsolely on accelerating the evaluation phase, leaving other\nessential TGP operations such as crossover and mutation\nunoptimized. Moreover, during the evaluation process, they do\nnot support parallel evaluation of multiple individuals from the\npopulation on the GPU, which limits scalability in large-scale\nevolutionary experiments.\nTo overcome these challenges, we introduce EvoGP, the\nfirst comprehensive GPU-accelerated TGP framework. Firstly,\nwe extend prefix encoding by introducing a maximum-length\nconstraint, ensuring that all trees in the population share a\nuniform tensor shape. This design eliminates memory real-\nlocation overhead and enables efficient, fully parallel tree\noperations on the GPU. Then, we systematically analyze all\nmutation and crossover operations in TGP and extract their\ncore computational primitives. By identifying these shared\ncomponents, we develop a unified GPU-accelerated framework\nthat efficiently supports various mutation and crossover vari-\nants, significantly improving computational efficiency. Finally,\nwe propose a novel fitness evaluation strategy for symbolic\nregression that leverages both population-level and data-point-\nlevel parallelism. This hybrid parallelism ensures that GPU\nresources are fully utilized, leading to substantial performance\nimprovements. Experimental results demonstrate that EvoGP\nachieves up to a 140.89x speedup over the state-of-the-art\nGPU-based TGP implementation [31].\nThe rest of this paper is organized as follows. Section II\nintroduces the fundamentals of TGP, outlines the GPU com-\nputing model, and discusses existing TGP implementations.\nSection III presents the main challenges associated with GPU\nacceleration of TGP. In Section IV, we describe our proposed\napproach to address these challenges. Section V details the\nimplementation of the EvoGP framework. In Section VI, we\nverify the effectiveness of our approach through experimental\nevaluation. Finally, a conclusion is drawn in the last section."}, {"title": "II. BACKGROUND AND RELATED WORKS", "content": "In this section, we briefly review the TGP algorithm and\nintroduce the GPU architecture and CUDA. Finally, we intro-\nduce the existing TGP implementations."}, {"title": "A. Tree-based Genetic Programming", "content": "TGP is a core evolutionary algorithm widely used in sym-\nbolic regression [11]\u2013[14], feature engineering [15], [17], [18],\ncomplex system design [33]\u2013[36], and robotic control [37]-\n[39]. In TGP, solutions are represented as trees, which define\nthe flow of computation from inputs to output. Formally, a\nTGP tree can be described as\n$T = (V, E, r)$,\nwhere V is the set of nodes, $E \\subset V \\times V$ is the set of edges, and\n$r \\in V$ is the distinguished root node. Every node $v \\in V \\backslash {r}$\nhas exactly one parent.\nA TGP tree represents a function Func that maps an input\nvector x to an output y:\n$y = Func(x)$.\nThe computation proceeds in a bottom-up manner: each node\nv calculates its result $res[v]$, and the root node's result $res[r]$\nserves as the final output y.\nEach node in the tree is represented by a tuple $v = (t, val)$,\nwhere t is the node type, and val stores the node's value.\nNodes in a TGP tree fall into three categories:\nConstant Node: Represents a numerical constant. Its compu-\ntation is:\n$res[v] = val$.\nVariable Node: Represents an input variable. Here, val in-\ndicates the index of the input vector x, and its computation\nis:\n$res[v] = x[val]$.\nFunction Node: Represents a mathematical or logical func-\ntion. In this case, val specifies the function type f, and its\ncomputation is:\n$res[v] = f (res[c_1], res[c_2], ..., res[c_n])$,,\nwhere $c_1, c_2,..., c_n$ are the children of the node.\nBy using this tree-based representation, TGP supports flex-\nible modeling of mathematical expressions and decision pro-\ncesses, which constitute the foundation of Genetic Program-\nming.\nTGP iteratively refines a population of trees through a\nseries of genetic operations, including selection, crossover,\nand mutation, to evolve optimal or near-optimal solutions.\nSelection is a process that chooses individuals from the\npopulation based on their performance, ensuring that better-\nperforming solutions have a higher probability of propagating\nto subsequent generations. Crossover involves exchanging\ninformation between selected parent trees, facilitating genetic\ndiversity and exploration of the solution space. Mutation\nintroduces random modifications by altering nodes or branches\nwithin an individual tree, thus promoting further diversity\nand preventing premature convergence. [40] The evolutionary\nprocess is described in Algorithm 1."}, {"title": "B. GPU Architecture and CUDA Programming", "content": "With the increasing demand for parallel computing, GPUs\nhave evolved into highly efficient accelerators for data-\nintensive tasks. Modern GPUs consist of thousands of process-\ning cores organized into Streaming Multiprocessors (SMs),\nenabling massive parallelism. The memory hierarchy includes\nhigh-latency global memory, multilevel caches (L1, L2) for\nfaster access, and constant memory optimized for read-only\ndata [41]. Since GPUs do not support dynamic memory\nmanagement as CPUs, handling variable-sized data structures\nsuch as trees is challenging [42].\nCUDA (Compute Unified Device Architecture) is a paral-\nlel computing platform and programming model developed\nby NVIDIA, designed to harness the computing power of\nGPUs for general purpose computing [43], [44]. One of the\nfundamental execution models in CUDA is SIMT (Single\nInstruction, Multiple Threads) [45]. CUDA organizes parallel\nexecution in a hierarchical manner, consisting of three key\nlevels: grid, block, and thread. A CUDA kernel launches a grid\nof thread blocks, where each block contains multiple threads.\nThese threads execute in parallel, and the execution is coor-\ndinated through shared memory, synchronization mechanisms,\nand optimizations of the memory hierarchy [32], [46]."}, {"title": "C. Existing TGP Implementations", "content": "DEAP [29] is a general purpose evolutionary computation\nframework designed for flexibility and extensibility. It supports\na wide range of evolutionary algorithms, including genetic\nprogramming, with features such as custom operators, com-\nprehensive logging, and parallelization via multiprocessing.\ngplearn [30], built on top of scikit-learn, provides tools for\nsymbolic regression, classification, and transformation tasks.\nIt offers customizable function sets, mutation, and crossover\noperators, making it suitable for feature engineering and inter-\npretable machine learning. gplearn leverages joblib for parallel\ncomputation, enabling efficient evaluation of large populations.\nKarooGP [27] is a genetic programming framework that\nintegrates with TensorFlow [47], using its graph execution\nmodel to execute GP expressions as directed acyclic graphs\n(DAG). It is particularly useful for symbolic regression and\nclassification tasks. KarooGP is designed to be user-friendly,\nproviding a command-line interface for configuration and\nexecution.\nTensorGP [28] is a genetic programming engine built on\nTensorFlow's eager execution model. It simplifies the imple-\nmentation of genetic programming tasks, particularly symbolic\nregression, by eliminating the need for DAG construction.\nTensorGP is designed with scalability in mind, leveraging\nTensorFlow's ecosystem to support high-performance compu-\ntation.\nSRGPU [31] focuses on symbolic regression tasks using\nCUDA for efficient parallel computation. Its core design maps\nGPU threads to process data points within the same individ-\nual, optimizing regression workflows. SRGPU is particularly\ndesigned for tasks that require large-scale data analysis, com-\nbining evolutionary computation with hardware acceleration."}, {"title": "III. CHALLENGES OF GPU ACCELERATION FOR TGP", "content": "In this section, we discuss three key challenges that hinder\nefficient GPU acceleration of TGP."}, {"title": "A. Inefficient Tree Encoding", "content": "TGP primarily employs two encoding schemes: pointer-\nbased tree encoding [27], [28] and prefix encoding [29]\u2013[31].\nPointer-based tree encoding represents trees as object struc-\ntures in programming models, where each node stores pointers\nto its child nodes. This approach efficiently preserves the hier-\narchical relationships of the tree structure, enabling genetic op-\nerations such as subtree crossover by merely updating pointer\nreferences. However, the non-contiguous memory layout of\ntree nodes poses significant challenges for GPU acceleration.\nAdditionally, frequent pointer dereferencing leads to excessive\nnon-coalesced global memory accesses, severely degrading\ncomputational performance.\nPrefix encoding represents a tree using its prefix sequence,\nleveraging the fixed arity of nodes in TGP to fully encapsu-\nlate the tree structure without requiring explicit pointer-based\nconnections. This encoding scheme offers a straightforward\nstorage format with a contiguous memory layout, leading\nto improved memory access efficiency. However, its primary\ndrawback lies in the lack of explicit structural information.\nDuring genetic operations, it is often necessary to parse the\nprefix sequence to determine subtree boundaries and sizes.\nThis process involves extensive logical branching, which sig-\nnificantly hampers execution speed on GPUs.\nAdditionally, both encoding methods struggle with dynamic\ntree growth, as it requires frequent GPU memory reallocation,\nincurring high overhead and disrupting memory coalescing,\nwhich degrades performance."}, {"title": "B. Highly Heterogeneous Genetic Operations", "content": "The diverse genetic operations in TGP introduce signifi-\ncant challenges for GPU acceleration due to their structural\ncomplexity and variability. For instance, crossover operations\ncan be categorized into leaf-biased crossover and normal\ncrossover, while mutation includes multiple variants such as\nsubtree mutation, hoist mutation, and insert mutation. Each of\nthese variants modifies the tree structure differently, requiring\ndistinct processing strategies.\nFurthermore, new genetic operations are often introduced\nto optimize performance for specific tasks, further increasing\nthe complexity of a comprehensive GPU implementation.\nAchieving efficient parallelization for such a diverse set of\noperations is a substantial engineering effort, as it involves\nhandling dynamic tree modifications while maintaining mem-\nory coherence and minimizing thread divergence. Additionally,\nensuring scalability in GPU acceleration remains a key chal-\nlenge, as future extensions may require flexible and adaptive\nimplementations that can efficiently incorporate novel genetic\noperations without significant overhead."}, {"title": "C. Limited Parallelism in Fitness Evaluation", "content": "Symbolic regression (SR) [11]\u2013[14] is one of the primary\napplications of TGP, where the goal is to evolve mathematical\nexpressions that best fit a given dataset. The fitness evaluation\nin SR typically measures how well a candidate expression\napproximates the target function by computing the loss over\nall given data points.\nThe state-of-the-art SR fitness evaluation method [31] pre-\ndominantly rely on data-parallelism, where the loss for differ-\nent data points is computed in parallel for a single tree. This\napproach leverages parallel reduction techniques to aggregate\nthe individual losses into a single fitness value. However, to\nevaluate the entire population, the kernel must be launched\niteratively for each tree, which introduces additional overhead.\nWhile this data-parallel approach efficiently utilizes GPU\nresources when the number of data points is sufficiently large,\nit allows a single tree's computation to fully occupy available\nthreads. However, it becomes inefficient when the dataset is\nsmall. In such cases, individual tree evaluations fail to saturate\nthe GPU, and the lack of population-level parallelism leads to\nsignificant underutilization of computational resources, result-\ning in execution inefficiencies."}, {"title": "IV. PROPOSED METHOD", "content": "In this section, we present our proposed method to address\nthe challenges introduced in Section III."}, {"title": "A. Tensorized Encoding", "content": "To overcome the inefficiencies associated with both pointer-\nbased and prefix encodings discussed in Section III-A, we\npropose a tensorized encoding scheme that addresses two\nmajor issues in TGP. First, it mitigates the need for repeated\nstructural parsing of trees on GPUs, which introduces abundant\nlogical branching and degrades performance. Second, it avoids\nfrequent memory reallocation caused by dynamic tree growth,\na well-known challenge for GPU-based systems.\nWe adopt prefix encoding, which stores the nodes of a tree\nin a contiguous sequence. Generally, a simple prefix sequence\ndoes not suffice to fully represent an arbitrary tree structure, as\nthe number of children for each node may vary. However, in\nTGP, the number of children is determined by the node's type\n(t) and its value (val). For instance, Constant and Variable\nnodes have no children, whereas a Function node (e.g., sum)\nhas two children. Consequently, for TGP applications, a single\nprefix sequence can encode all critical information about a\ntree's topology and values.\nIn existing implementations [31], prefix encoding typically\nconsists of two arrays:\n$N_{type} = [t_1, t_2,..., t_n] \\in \\mathbb{R}^{len(T)}$,\n$N_{val} = [val_1, val_2, ..., val_n] \\in \\mathbb{R}^{len(T)}$,\nwhere $t_i$ and $val_i$ represent the type and value of the i-th\nnode, respectively, and $len(T)$ denotes the total number of\nnodes in the tree T. Although this representation is compact,\nit does not store explicit structural information. As a result,\noperations such as subtree crossover or mutation typically\nrequire repeated parsing of the prefix sequence to locate\nsubtrees, making GPU-based execution inefficient.\nTo remedy this, we introduce an additional array that records\nthe size of each subtree:\n$N_{size} = [size(1), size(2), ..., size(n)] \\in \\mathbb{R}^{len(T)}$,\nwhere $size(i)$ indicates the size of the subtree rooted at the\ni-th node. By incorporating this subtree size array, one can\ndirectly determine the boundaries of any subtree in T, thereby\nobviating the need for costly tree parsing during genetic\noperations on the GPU.\nAlthough prefix encoding provides a suitable representation\nfor trees in TGP, it remains challenging to efficiently batch-\nprocess these structures on GPUs due to their variable sizes.\nTo address this, we introduce a hyperparameter $|T|_{max}$, which\ndenotes the maximum allowed number of nodes in a tree. Each"}, {"title": "B. Unified Genetic Operation Framework", "content": "In order to address the challenges discussed in Section III-B\nregarding highly heterogeneous genetic operations, we propose\na Unified Genetic Operation Framework for GPU-based TGP.\nOur key idea is to identify and accelerate the core subtree\nexchange procedure that underlies most TGP genetic oper-\nations, such as one-point crossover, subtree mutation, and\nhoist mutation. By offloading subtree exchange to the GPU,\nwe enable a comprehensive and extensible set of genetic\noperations to be efficiently executed in parallel.\nSubtree exchange refers to replacing a designated subtree\nof one tree with a subtree from another source. In conven-\ntional prefix encoding, this process can be computationally\nexpensive because it involves tree parsing to determine subtree\nboundaries. However, our tensorized encoding obviates the\nneed for extensive parsing by explicitly storing each node's\nsubtree size. Consequently, subtree boundaries can be located\nthrough direct indexing, substantially reducing the complexity\nof subtree exchange.\nWe define the subtree exchange operation as\n$exchange(T_{old}, n, T_{new}) \\rightarrow T^*$,\nwhere $T_{old}$ is the original tree for subtree exchange, n denotes\nthe root of the target subtree in $T_{old}$, and $T_{new}$ is the subtree\nthat will replace the original subtree rooted at n. Under\nour tensorized encoding, each tree is represented by three\ntensors: $N_{type}$, $N_{value}$, and $N_{size}$. We use $\\oplus$ to denote the tensor\nconcatenation operation, and define\n$N_{type}^* = N_{type}^{old}[1,2,...,s] \\oplus N_{type}^{new} \\oplus N_{type}^{old}[e, e + 1,...]$,\n$N_{value}^* = N_{value}^{old}[1,2,...,s] \\oplus N_{value}^{new} \\oplus N_{value}^{old}[e, e + 1, ...]$,\n$N_{size}^* = N_{size}^{updated}[1,2,...,s] \\oplus N_{size}^{new} \\oplus N_{size}^{node} \\oplus N_{size}^{old}[e, e + 1, ...]$,\nwhere s = index(n) is the starting position of the subtree,\nand $e = s + N_{size}^{old}(n)$ is the ending position in $T_{old}$. The tensor\n$N_{size}^{updated}$ is computed by adding $N_{size}^{new}[0]$ to the subtree sizes of\nall ancestor nodes of n:\n$N_{size}^{updated}[i] = \\begin{cases} N_{size}^{old}[i] + N_{size}^{new}[0], & \\text{if i is an ancestor of n}, \\\\ N_{size}^{old}[i], & \\text{otherwise}. \\end{cases}$\nBy focusing on subtree exchange, we can efficiently imple-\nment virtually all TGP genetic operations. For instance, the\none-point crossover, a fundamental crossover variant, replaces\na random subtree of one parent with a random subtree from\nthe other parent:\n$T^* = exchange(T_1, n, T_{sub})$,\nwhere $T_1$ and $T_2$ are parent trees, n is a random node in $T_1$,\nand $T_{sub}$ is a randomly selected subtree from $T_2$.\nSimilarly, subtree mutation replaces a randomly selected\nsubtree with a newly generated subtree:\n$T^* = exchange(T, n, T_{new})$,\nwhere T is the tree to be mutated, n is a random node in T,\nand $T_{new}$ denotes the newly generated subtree. \nOnce the subtree exchange operation is offloaded to the\nGPU, any genetic operator that can be decomposed into\nsubtree exchange steps can be accelerated with minimal effort.\nMoreover, researchers can easily incorporate novel genetic\noperators into the framework by defining the required subtree\nselection or replacement strategies. As a result, this Unified\nGenetic Operation Framework greatly simplifies and unifies\nthe process of designing GPU-accelerated TGP algorithms,\nfacilitating both performance and extensibility."}, {"title": "C. Hybrid Parallelism in SR Evaluation", "content": "As mentioned in Section III-C, existing GPU-based sym-\nbolic regression (SR) evaluation methods [31] predominantly\nrely on data-level parallelism. In these methods, a single kernel\ninvocation computes the fitness of one tree by evaluating\nit across all data points. This approach efficiently utilizes\nGPU resources when the dataset size is large, since each\ntree evaluation can occupy a substantial portion of the GPU's\nthreads. However, it also requires launching a separate kernel\nfor each individual in the population. When the population size\ngrows, these repeated kernel launches introduce significant\noverhead, which limits overall efficiency.\nTo overcome this limitation, EvoGP employs a hybrid\nparallelism approach that distributes computation across both\nthe population and data dimensions in a single kernel launch."}, {"title": "V. EvoGP IMPLEMENTATIONS", "content": "In this section, we introduce the overall architecture of\nEvoGP along with some additional features."}, {"title": "A. Overview of EvoGP", "content": "We present EvoGP, the first fully GPU-accelerated TGP\nframework. EvoGP is developed in Python and leverages the\nPyTorch [48] framework for efficient tensor management and\nGPU control. To further enhance computational performance,\nEvoGP integrates dedicated CUDA kernels for key evolution-\nary operations, including tree generation, mutation, crossover,\ninference, and symbolic regression (SR) fitness evaluation.\nSpecifically, to accommodate input data of various scales in SR\nfitness evaluaion, EvoGP implements both data parallelism and\nhybrid parallelism mentioned in Section IV-C. These CUDA\nkernels are provided as PyTorch custom operators, ensuring\nseamless interoperability with PyTorch's existing infrastruc-\nture. As a result, EvoGP benefits from both the flexibility of\nthe Python AI ecosystem and the computational advantages of\nnative GPU acceleration.\nBeyond GPU acceleration of TGP algorithms, EvoGP also\nincludes built-in support for common application domains\nwhere TGP has proven effective. These domains include\nsymbolic regression, policy optimization, and classification\ntasks. Furthermore, EvoGP provides a collection of stan-\ndardized problem benchmarks, including symbolic regression,\nclassification, and policy optimization. It allows users to\nsystematically evaluate different TGP strategies and tune their\nalgorithms.\nThe overall architecture of EvoGP is illustrated , providing\na visual representation of its modular components\nand their interactions."}, {"title": "B. Rich Features and User Customization", "content": "EvoGP extends beyond basic GPU-accelerated TGP opera-\ntions by offering a diverse set of evolutionary operator variants\nand a flexible interface for customization. In addition to the\npreviously mentioned problem benchmarks, EvoGP provides\nmultiple variations of key TGP operators, including selection,\nmutation, and crossover. These variants allow users to freely\ncombine and configure different evolutionary strategies, en-\nabling the design of customized TGP algorithms tailored to\nspecific optimization tasks. \nhighlighting that EvoGP provides the most comprehensive set\nof supported operators.\nTo further enhance usability, EvoGP offers an intuitive inter-\nface for defining custom operators and problem formulations.\nUsers can leverage low-level CUDA implementations to effi-\nciently develop and execute their own optimized genetic oper-\nators, ensuring high performance while maintaining flexibility.\nAdditionally, EvoGP's modular design allows researchers and\npractitioners to apply TGP algorithms to their own problem\ndomains, making it a versatile tool for both academic research\nand real-world applications."}, {"title": "C. Multi-Output Support", "content": "EvoGP extends traditional TGP by incorporating multi-\noutput functionality, allowing the application of TGP to tasks\nthat require multiple output values, such as policy optimization\nin reinforcement learning. This enhancement enables EvoGP\nto handle complex problem domains where a single-output GP\nframework would be insufficient.\nTo achieve multi-output computation, EvoGP uses Modi\nnodes [49] into the tree structure. These nodes possess two\nkey characteristics:\n1) Each Modi node specifies the output to which its value\ncontributes. The contributions from multiple Modi nodes\nassociated with the same output are aggregated accord-\ning to a predefined rule, which in this case is summation,\nto produce the final output value.\n2) If a Modi node has a parent node, it does not propagate\nits computed value upwards like regular nodes. Instead,\nit directly adopts the value of its rightmost child node.\nThis mechanism effectively transforms the tree structure\ninto a directed acyclic graph (DAG), enabling simulta-\nneous computation of multiple outputs.\nThis distinction between regular nodes and Modi nodes\nis crucial when performing multi-output computations. While\nregular nodes operate under standard GP rules, Modi nodes\nfollow a specialized processing scheme to ensure proper output\nassignment. This approach enables EvoGP to effectively sup-\nport multi-output GP, making it well-suited for reinforcement\nlearning and other tasks requiring multiple correlated outputs.\nThe computational process of Modi nodes is illustrated,\nproviding a visual representation of how multi-output\nvalues are generated within the EvoGP framework."}, {"title": "VI. EXPERIMENTS", "content": "This section presents a comprehensive evaluation of EvoGP,\nhighlighting its performance across diverse tasks, datasets,\nand hardware configurations. The experiments are designed\nto validate the effectiveness of the proposed GPU-accelerated\nframework in addressing the computational challenges inher-\nent in TGP. Specifically, we aim to answer four key questions:"}, {"title": "A. Experimental Setup", "content": "This section outlines the experimental setup used to evaluate\nEvoGP. The setup is designed to comprehensively assess the\nframework's performance across a variety of tasks, hardware\nconfigurations, and parameter settings.\nWe assess the performance of EvoGP on three types of tasks\nto highlight its flexibility:\nSymbolic Regression: This task uses the Pagie polynomial as\na benchmark function, a widely adopted test case in genetic\nprogramming (GP) research due to its complexity and non-\nlinear structure. The function is defined as:\n$f(x, y) = \\frac{1}{1 + x^{-4}} + \\frac{1}{1 + y^{-4}}$\nThe performance on this task is measured using the Mean\nSquared Error (MSE) loss between the predicted outputs and\nthe true values of the function. A lower MSE indicates a better\napproximation of the target function.\nClassification: Four datasets from the sklearn library [50]\nare used for classification tasks: Iris, Wine, Breast Cancer,\nand Digits. These datasets differ in terms of complexity,\nthe number of features, and the number of classes, making\nthem suitable for evaluating classification performance. The\ndetailed information about these datasets is summarized.\nThe performance metric for this task is classification\naccuracy, defined as the ratio of correctly predicted labels to\nthe total number of test samples. Higher accuracy indicates\nbetter classification performance.\nRobotics Control: Environments from the Brax frame-\nwork [51] are used to test EvoGP in reinforcement learning\ntasks. The chosen environments include Swimmer, Hopper,\nWalker2d, and HalfCheetah, each presenting unique challenges\nin control dynamics.\nprovides the observation and\naction dimensions of these environments. Performance in these\ntasks is evaluated based on the cumulative reward obtained\nduring an episode. The cumulative reward measures the total\nquality of the control policy, with higher rewards indicating\nbetter task performance."}, {"title": "B. Comparison with Existing TGP Implementations", "content": "We compare the performance of EvoGP with other\nmainstream TGP implementations including SRGPU [31],\nDEAP [29], gplearn [30] and TensorGP [28]. The primary\nfocus of this experiment is to evaluate the execution time\ndifferences among these libraries when performing Symbolic\nRegression tasks. The experiments were conducted for 100\ngenerations, and the number of data points (64, 256, 1024,"}, {"title": "C. Effectiveness of Hybrid Parallelism", "content": "Hybrid parallelism in EvoGP was introduced to address\nthe inefficiencies of traditional GPU-based approaches that\nrely solely on data-level parallelism. This experiment aims to\nevaluate the effectiveness of hybrid parallelism compared to\ndata-level parallelism under various dataset sizes and popula-\ntion scales. The goal is to assess how well hybrid parallelism\nadapts to different computational demands and identifies the\nconditions under which it outperforms data-level parallelism.\nThe experimental results are presented\nFrom the results, we observe a clear performance pattern.\nFor small datasets, hybrid parallelism consistently outperforms\ndata-level parallelism in execution time. This advantage is\nattributed to the ability of hybrid parallelism to process\nmultiple trees concurrently across the GPU's computational\nthreads, maximizing resource utilization when the dataset size\nis insufficient to saturate the GPU using data-level parallelism\nalone.\nHowever, as the dataset size increases, the efficiency gap\nbetween the two approaches narrows. For datasets exceed-\ning a critical threshold (approximately $2^{14}$ = 16,384 data\npoints), data-level parallelism surpasses hybrid parallelism in\nperformance. This transition is due to two key factors: 1.\nLarge datasets allow data-level parallelism to fully utilize\nthe GPU's computational capacity by evaluating a single\ntree across all data points without requiring population-level\nparallelism. 2. Data-level parallelism stores tree structures in\nconstant memory, enabling faster memory access compared to\nthe global memory used in hybrid parallelism.\nDespite these trade-offs, hybrid parallelism remains highly\neffective for moderate dataset sizes and provides flexibil-\nity in accommodating diverse computational scenarios. This\nadaptability underscores EvoGP's innovative design, which\nleverages hybrid parallelism to balance workload distribution\nbetween data and population dimensions.\nThese findings highlight the importance of tailoring par-\nallelism strategies to the specific characteristics of the task.\nWhile data-level parallelism is optimal for very large datasets,\nhybrid parallelism offers superior performance for small to\nmedium-sized datasets, where GPU resources might otherwise\nbe underutilized. By incorporating both strategies, EvoGP\ndemonstrates its capability to optimize performance across a\nwide range of problem scales and configurations."}, {"title": "D. Performance across Tasks with Scalable Populations", "content": "This subsection evaluates EvoGP's performance on sym-\nbolic regression"}]}