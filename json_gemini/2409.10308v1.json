{"title": "Know your limits! Optimize the robot's behavior through self-awareness", "authors": ["Esteve Valls Mascar\u00f3", "Dongheui Lee"], "abstract": "As humanoid robots transition from labs to real-world environments, it is essential to democratize robot control for non-expert users. Recent human-robot imitation algorithms focus on following a reference human motion with high pre-cision, but they are susceptible to the quality of the reference motion and require the human operator to simplify its move-ments to match the robot's capabilities. Instead, we consider that the robot should understand and adapt the reference motion to its own abilities, facilitating the operator's task. For that, we introduce a deep-learning model that anticipates the robot's performance when imitating a given reference. Then, our system can generate multiple references given a high-level task command, assign a score to each of them, and select the best reference to achieve the desired robot behavior. Our Self-AWare model (SAW) ranks potential robot behaviors based on various criteria, such as fall likelihood, adherence to the reference motion, and smoothness. We integrate advanced motion generation, robot control, and SAW in one unique system, ensuring optimal robot behavior for any task command. For instance, SAW can anticipate falls with 99.29% accuracy.", "sections": [{"title": "I. INTRODUCTION", "content": "Imagine a world where bipedal robots walk among us, mimicking human movements and behaviors with remark-able precision. Such robots could revolutionize industries ranging from healthcare to disaster response, offering unpar-alleled assistance and efficiency. However, teaching robots how to robustly imitate human behaviors is very challenging, especially for bipedal robots. Recent works [1]-[7] have shown promising potential by training a robot to imitate a given human reference using goal-conditioned reinforcement learning (RL) [8]. However, exactly following a human reference motion might fall out of the robot's capabilities. To address this issue, previous works filtered out unfeasible motions and limited the commanded behaviors to upper body movements [1], [2] or one specific task [3]-[6]. However, this strategy presents two main problems: (a) Should the human operator adapt its reference behavior to the robot's abilities and constraints? (b) How can robots handle dy-namic motions that are out of their expertise? This paper is motivated to answer those questions by doting the robots with self-awareness: the ability to understand any motion command and adapt it according to their own limitations and capabilities.\nAs humans, we inherently possess self-awareness, which helps us recognize our physical and cognitive boundaries. For instance, a novice parkour enthusiast understands that attempting a high-risk maneuver without sufficient skill can lead to injury. This self-awareness guides them to modify their actions, opting for safer, more manageable moves until they gain more experience and confidence. Similarly, self-awareness in robots is equally important to ensure safety, ef-ficiency, and high task performance. Without it, robots might blindly try to imitate human motions without considering their own physical constraints, leading to falls, collisions, or mechanical damage. In fact, self-awareness should also entail the robot's expertise: a robot might be able to jump with one leg, but still has not learned how. Therefore, during execution, the robot should ideally explore how to move like a human jumping with one leg and adapt its movement based on its own capabilities. By incorporating self-awareness, robots can assess their capabilities and make informed decisions, preventing actions beyond their abilities, as shown in Fig. 1. In this paper, we reformulate this adaptation problem by first generating potential movements and later selecting the most optimal according to the current situations and robot expertise and limitations.\nIn fact, this area of developing intelligent embodied sys-tems that understand their own limitations has already been explored in the past. Prior works have considered physical self-awareness by predicting whether a robot will fall in the near future [9]\u2013[14]. The main goal of these works is to avoid falls by adjusting its motion before high disturbances are encountered. Both model-based [9], [10] and learning-based approaches [11]-[14] have been considered for the task of fall prediction. For instance, [13], [14] used deep-learning strategies to anticipate falls from the last observed robot states. However, all learning-based methods generated the training data using model-based controllers that were limited to simple movements, such as standing [14] or walking [13]. They collect the falling examples by applying exter-nal force perturbations to the robot's torso in a simulator. Consequently, their fall prediction approach was limited to very specific tasks (i.e., walking) and did not generalize to diverse human behaviors. On the contrary, this work proposes a system that understands the robot's capabilities when imitating any human reference provided, even high-dynamic movements such as backflips or handstands. We envision a general approach that allows a robot to imitate any human and any behavior commanded if it knows how or adapt the movement to its own expertise.\nMoreover, instead of just predicting a robot's potential fall, we anticipate how good a robot's imitation will be given a human reference. For that, we introduce a Self-AWare model, shorted as SAW, that infers a score to inform a robot on how smooth, safe, and faithful a robot's behavior will be if it decides to follow a human reference motion. Additionally, by integrating SAW with a real-time text-to-motion generator, such as MotionLCM [15], we can adapt the human's reference so that the robot imitates the high-level task commanded but improving the quality of the generated behavior. SAW can be used to generate and rank diverse potential robot behaviors and select the most adequate in advance, ensuring an optimal imitation. In conclusion, our efforts resulted in the following contributions:\n1) A transformer-based model to anticipate the robot's performance when following any human motion given as reference.\n2) A pipeline to optimize the robot's behavior, prevent falls, and enable non-expert users to control a bipedal robot using text or trajectory commands."}, {"title": "II. RELATED WORKS", "content": "This section reviews the existing literature on robots imitating diverse human behavior, focusing on recent ad-vancements and identifying current limitations. This analysis underscores the importance of integrating physical self-awareness in robots to facilitate their effective deployment in real world-applications."}, {"title": "A. Imitation Learning", "content": "As robots are increasingly utilized in more complex and unstructured environments, manually preprogramming their behavior or defining it through reward functions is becoming exceedingly difficult [16], [17]. Instead, imitation learning (IL) provides an avenue for teaching robots a desired behav-ior by simply demonstrating it. During the learning process, robots are provided with a dataset of expert demonstrations, and the goal is either to replicate them by mapping the observed states to actions, known as behavior cloning (BC) [18], or to understand the underlying reward functions behind the expert's behavior with inverse RL (IRL) [19]. While IRL provides a more robust solution, its learning process is computationally more expensive and has lately struggled to scale to larger environments and replicate expert behaviors compared to BC [19]. In fact, BC has the advantage of being more efficient, as merely follows a traditional supervised learning task, but might suffer from a covariate shift problem [20]. This problem arises due to the bias induced during training where the state distribution is led by an expert, while in testing the state is induced by its action [21]. Different attempts [18], [22], [23] have focused on solving the covari-ate shift problem, either by incorporating the human expert in the loop [18] or by limiting the agent actions to be in the distribution covered by the expert demonstrations [23]. For instance, [23] learned to detect states that could lead to failures, and encourage BC to shift to known states. In fact, our work shares some common beliefs with [23] where anticipating potentially unstable states is crucial for ensuring optimal behaviors during BC, but we differ in nature. While [23] constraints the agent policy to be in the distribution of the expert demonstrations, we adapt the policy to the expertise of the agent itself. Our work builds upon behavior cloning but relaxes the imitation process, where the agent should perform a task optimally in its own domain. One similar motivation is proposed in [24], where the goal is to overcome discrepancies between agent embodiments without forcing a shared latent domain."}, {"title": "B. Human Imitation in Bipedal Robots", "content": "Imitating human motion is no trivial task, especially for bipedal robots. Traditional methods in robot motion planning often rely on pre-defined movement patterns and control algorithms [25], [26] inspired by human movements. These methods, though effective in controlled environments, strug-gle to adapt to the unpredictability of real-world settings. The lack of flexibility in these approaches results in robots that can perform specific tasks but fail when faced with novel or dynamically changing situations.\nReinforcement Learning (RL) has emerged as a powerful technique to address these limitations of traditional methods, showing high performance in animated characters [27]- [29], quadruped robots, [30], [31] and recently in bipedal humanoids [1]-[7]. All these approaches tackled behavior cloning through goal-conditioned RL [8], where a robot is trained to replicate a given human reference while consider-ing environmental and physical constraints. For instance, [3], [4] focused on training an RL agent to follow either velocity commands or jumps, respectively, and performed zero-shot transfer to a real Cassie robot. To gain more fine-grained control over the robot's behavior, [5], [6] designed extensive rewards to overfit a policy for specific tasks in a bipedal hu-manoid robot. However, the ultimate goal of robot imitation is to enable a humanoid to follow any human demonstration, independent of its complexity and diversity. To address this task, [1], [2] focused on only imitating the upper-body part to account for more expressive robot behaviors, but only controlled the robot legs to ensure motion feasibility. Instead, I-CTRL [7] focused on whole-body humanoid imitation and showcased high performance in four different bipedal robots, generalizing over 10.000 different motions. For that, I-CTRL constrained the exploration phase during learning so that the produced physics-based behavior only modified the retargeted human reference within a defined margin, ensuring a highly visual resemblance.\nHowever, all the aforementioned works focused on blindly following a reference human motion with high precision, which could lead to falls or non-smooth behaviors when the intended reference behavior exceeds the robot's capabilities. In fact, previous works filter out complex human behaviors (i.e., remove high jumps, backflips, ...) [2], [6], [7], so that their generated behavior underperforms for complex reference motions, leading to falls. To overcome this issue, we propose to anticipate the resulting robot behavior of a trained policy when given a human reference. If a robot is aware that a commanded motion is out of its expertise and might lead to falls or poor imitation, the robot can decide to relax the reference motion constraints and further explore new reference behaviors that might lead to better performance. We described this ability as physical self-awareness, which refers to the robot's understanding of its own limitations and capabilities and enables the robot to make informed decisions."}, {"title": "C. Self-Awareness in Robotics", "content": "Psychologists describe self-awareness as the ability to become the object of one's attention [32], which entails a per-son's knowledge of themselves. This capability significantly influences human motivations, decisions, and intentions [33], either at the cognitive or physical level. For instance, [33] states that when a human performs a movement, their ac-tion awareness is unconsciously monitoring discrepancies between the planned movement and the current state. If this error becomes significant, this awareness alerts a higher-level cognitive system to correct and replan this movement. Our work is inspired by this physical self-awareness and attempts to design a similar system for robots. Our developed Self-AWare model (SAW) continuously monitors discrepancies between the planned movements, the human references, and the current robot states. If SAW anticipates a potential discrepancy, such as a fall or a wrong robot imitation, our system proposes to replan the movement by consciously reasoning about the robot's limitations and capabilities.\nIn fact, preventing falls in robots, which can be considered as a subarea among physical self-awareness, has already been explored in the past. Early efforts focused on avoiding falls when small disturbances occurred using stabilizing controllers [34], [35]. However, when dealing with large disturbances, a robot requires more time to adjust its motion to avoid falling. Therefore, [9], [10] proposed to anticipate and prevent falls using model-based approaches. [9] used a stand space inverted pendulum model for fall prediction, while [10] modified the zero moment point (ZMP) for a simplified multi-rigid body model to predict falls in humans. Despite some advancements, these methods often oversim-plify fall prediction by making assumptions that limit the robot's behavior to specific motions.\nTo address these limitations and build models that can better adapt to uncertainties, learning-based approaches were proposed [11]\u2013[14]. [11], [12] hand-crafted robot state fea-tures to predict falls. Later, [13] inferred the likelihood of falling using a bidirectional Long-Short Term Memory (BiLSTM) network, which processed the evolution of robot sensor measurements such as the center of mass (CoM), the center of pressure (CoP) and the linear and angular momentum and its derivative. More recently, [14] adopted a 1D convolutional neural network (1D-CNN) with the same goal. However, these learning-based methods generated the training data using model-based controllers that were limited to simple movements, such as standing [14] and walking [13]. Consequently, their approach did not generalize to more diverse human behaviors a robot might want to imitate.\nOn the contrary, we use I-CTRL [7] to generalize our SAW model to more complex and diverse motions, such as dancing, walking, running, and jumping. Moreover, and contrary to prior works [11]-[14] that only focus on the observed robot states to predict falls, we incorporate the reference human motion to imitate as input to our model. For instance, when a bipedal robot imitates a human performing a high jump, the robot's self-awareness can recognize that the skill is out of its limits and adapt the behavior to perform a simpler jump that is feasible with the current abilities. Note that this prevention formulation differs from prior works on quadruped robots [36] or small bipedal robots [37] that train a specific policy for fall recovery, where the robot has already fallen. In our case, by accurately knowing the robot's limits and anticipating potential failures in advance, we can replan the robot's behavior to be optimal while remaining as close as possible to the intended movement."}, {"title": "III. METHODOLOGY", "content": "This section is structured as follows. First, we introduce the task of robot behavior generation and control from high-level commands with self-awareness. Then, we present our motion adaptation system with the Self-AWare model (SAW) to tackle this task, which is illustrated in Fig. 2."}, {"title": "A. Problem Formulation", "content": "We envision the control of bipedal robots using high-level task commands (c), such as natural language descriptions or root trajectories. Instead of directly translating those commands to robot signals, we opted for using the human embodiment as a bridge and defining the task as an imitation problem. Therefore, our first subtask is to translate those high-level task commands c to an appropriate human motion Hr, which will serve as the reference for the robot to imitate. For that, we adopt a pre-trained MotionLCM [15] as a text-to-motion generation model f, where (f : c \u2192 Hr). Our second subtask is to translate this human reference Hr to a physics-based robot movement Rp, such as (g: Hr\u2192 Rp). In fact, we attain the description of g as presented in [7], where first a human-to-robot retargeting module gh2r translates a human reference Hr to a robot reference Rr, only considering visual resemblance between the embodiments, and then a pre-trained RL module gr2p refines Rr to ensure plausibility under the real-world physics, generating Rp. Following [7], we define gh2r as ImitationNet [38] and gr2p as I-CTRL [7].\nHowever, due to the differences between kinematics and dynamics between humans and robots, as well as the error accumulation from ensembling multiple modules (f, gh2r and gr2p), the resulting Rp might largely deviate from Hr. Thus, we design a Self-AWare model (SAW) that learns how g performs under different human references Hr, and slightly adapts those references motions \u0124r to achieve an optimal robot behavior that still satisfies the task command c.\nNote that, given the use of multiple pre-trained models (f is MotionLCM, gh2r is ImitationNet and gr2p is I-CTRL), Hr, Rr, and Rp are represented differently. A human motion Hr \u2208 RT\u00d7J\u00d73 is represented as a sequence of T human poses, where each pose is defined as J joints in Cartesian representation. On the contrary, Rr \u2208 RT\u00d7D, includes the root position p\u00b9 \u2208 R\u00b3 and orientation \u03b8' \u2208 R4 in quaternion, as well as the robot joint angles q\u02bb \u2208 RS, so that D = 3+4+S. Similarly, Rp \u2208 RT\u00d7D,+S also includes the robot joint velocities \u0121\u02bb\u2208RS."}, {"title": "B. Motion Adaptation", "content": "We consider the motion adaptation task as finding a new human reference \u0124r that ensures optimal robot behavior Rp while still resembling the original reference Hr and the task command c. Our reference adaptation block utilizes the last To observed robot states R-T:t = [rt-T0,..., rt] to ensure that the new references are feasible with the current robot state, simplified as Rt, and the subsequent Tf human reference poses Ht:t+T = [ht,...,ht+Tf] which we aim to adapt, simplified as Ht, where t represents the current time.\nWe define the motion adaptation similarly to a brainstorm-ing process, where we first generate a set of n modified reference motions [\u01241,...,\u0124n], and then we rank those potential motions to select the most optimal \u0124f,i according to the robot feasibility. For that, we employ MotionLCM [15] which allows joint and trajectory-level editing and can ensure that the edited reference motions start from the current pose ht and closely approximate to ht+Tf and its root trajectory. An example of this behavior is shown in Fig. 3.\nLater, we convert those edited references to robot refer-ences [Rr1,...,Rrn] using ImitationNet [38]. Finally, each edited reference \u0154\u00a1 generated is then processed by SAW alongside the observed robot states Rt, inferring a score si that informs on how optimal a reference \u0154\u00a1 is. By calculating a scoresi for each edited reference \u0154\u00a1, we can rank and select the most suitable option that prioritizes avoiding falls and then optimize the quality of robot behavior. This chosen reference is followed until the SAW module identifies a better alternative for I-CTRL to guide the robot's actions. An overview of this process is shown in Fig. 2."}, {"title": "C. Self-AWare model (SAW)", "content": "This section provides a thorough description of our deep-learning-based Self-AWare model (SAW) for evaluating ref-erence motions for optimal robot control. SAW is designed based on two main ideas: a robot's behavior might lead to failure as the current robot state is already not adequate or if the reference is unfeasible for the current situation. Therefore, we first encode the reference motion R\u00a1 and the observed robot states Rt using individual multi-layer perceptrons (MLPs), which leads to Ei and Et respectively. Next, we make use of the attention mechanisms [39] to summarize both sequences. For that, we append a learnable class token cls [40] to the Et to aggregate all motion infor-mation during the transformer process. We add a sinusoidal positional embedding to Et and forward it to a self-attention transformer model to learn the temporal relationships of the observed robot states, embedded as \u00cat. Finally, we condition this representation with the planned reference motion E\u00a1 us-ing cross-attention. Following [40], we extract the appended cls token from the cross-attention output which represents the expected robot behavior in the future if imitating the provided reference motion. clss is then projected to a score vectors that assesses factors such as the likelihood of falling (fall), the smoothness of the generated robot's behavior (A), and the alignment of joint angles (\u00c2\u2084), joint velocities (A), and root position (Ap) and orientation (\u00c2e) with the reference. We define alignment as the mean square error between the reference state and the generated robot state, and smoothness as low robot joint accelerations (no jittering). Thus, a predicted score s = [fall,\u00c2q,\u00c2\u0121,\u00c2\u00ff,\u00c2p,\u00c2\u0259] \u2208 R6."}, {"title": "IV. EXPERIMENTS", "content": "To train the SAW model effectively, we automatically generate a dataset that accounts for the robot's ability to accurately mimic real-world motions. This involved synthe-sizing 100,000 human motion references using MotionLCM, incorporating 10,000 diverse textual annotations, with motion durations ranging from 3 to 12 seconds. For each reference, we simulated three unique JVRC-1 robot behaviors [41] using I-CTRL within the IsaacGym simulator, culminating in a comprehensive dataset of 300,000 robot behaviors. To ensure a fair evaluation, in our validation and testing dataset, the robot falls in half of the motions. Our SAW module observes 0.5 seconds in the past to score the reference of the next 1, 2, or 3 seconds."}, {"title": "B. Metrics", "content": "To evaluate our SAW module we make use of simple mean-square error metrics between the predicted and ground-truth alignment scores (\u00c2q, \u00c2\u0121, \u00c2p,\u00c2o). We also use accuracy as a metric to assess the falling prediction ability of SAW. Note that a robot is considered to have fallen when the root height of the robot is lower than a predefined threshold, following the definition from [7]."}, {"title": "C. Robot", "content": "In this work, we demonstrate the benefit of self-awareness on the JVRC-1 robot [41]. This robot has 23 DoFs with a height of 140 centimeters and a weight of 62.2 kilograms."}, {"title": "D. Quantitative and Qualitative Evaluation", "content": "Due to the absence of existing benchmarks for score prediction, we conducted an ablation study to assess (a) different variations of our proposed architecture, and (b) different future horizons in which we anticipate the robot's behavior. The results in Table I showcase the high accuracy of SAW in predicting if a robot will fall (\u2248 99%), as well as the high precision in determining the quality of the generated motion across multiple horizons.\nFirst of all, we observe that when only considering the observed robot states (w/o Rf), SAW underperforms when predicting the alignment of the robot with the reference, as expected. Likewise, when SAW only considers the reference motion (w/o Ro), it can not ground the expected behavior to its current state, thus also failing to correctly predict an alignment. Later on, we evaluate two modifications on how to integrate Rf and Ro for the score prediction. First, we consider one independent self-attention block per sequence and compute the score from the concatenation of the cls token from both sequences (w/o C.A.). Secondly, we inverted the sequences in the computation, such as the self-attention is computed over the reference and later conditioned on Eo. Both variants achieve higher alignment errors and lower fall prediction accuracy. In general, we observe that the observed motion Ro has a higher influence on the future robot behavior quality rather than Rf, as also shown in SAW w/o Rf.\nAdditionally, we evaluated the performance of SAW over longer future horizons (from 1 second to 3 seconds) as reported in Table I, which showcases that we can still predict falls with high accuracy with low error in the robot performance behavior. We observed that the anticipation of the smoothness and joint angle and velocity alignment is independent of the future horizon, but rather depends strongly on the reference motion to follow. On the contrary, it is harder to anticipate the root alignment the longer the future horizon.\nFinally, we evaluated the overall system when the original robot's behavior (without self-awareness) was falling. Fig. 4 showcases the benefit of SAW when commanding motions out of the robot expertise. In general, our results demonstrate that our motion adaptation system can prevent 62% falls while still following the same root trajectory."}, {"title": "E. Limitations and future work", "content": "Despite our SAW module's high performance in predicting the quality of the robot's motion when following a given reference (\u2248 99%), the end-to-end system only prevents 62% of falls during tasks. We recognize that simply stopping the robot's motion and avoiding complex motions when a fall is anticipated could address these issues. However, this approach would prevent the robot from following the original commands of the human operator which was part of the scope of the motion adapter. Our analysis indicates that the primary cause of the system's limited fall prevention is the noisy reference motions generated by MotionLCM when conditioned on prior poses. These noisy references can lead to abrupt changes that I-CTRL cannot effectively predict. Additionally, we currently generate only 15 reference motions and rank the robot's choices among them. Increasing this number to 30 or 50 would provide greater diversity, giv-ing SAW better options to choose from, thereby potentially improving fall prevention."}, {"title": "V. CONCLUSION", "content": "Controlling any robot with high-level task commands often requires operators who understand the capabilities of the robots and limit the command accordingly. Instead, we propose to provide robots with self-awareness so that they can autonomously adjust the commanded instruction to their own ability. Our end-to-end system converts natural language and trajectory instructions into a human motion reference for the robot to follow. To mitigate the risk of poor robot performance due to strict adherence to commands, we introduce the Self-AWare model (SAW). Our SAW module is able to anticipate a fall with \u2248 99% accuracy at different future horizons, and rank different references with high precision. Finally, we extend our self-awareness model with a motion adapter system that enables the robot to intelligently select the optimal reference motion according to the current robot states and capabilities, enhancing performance and preventing falls."}]}