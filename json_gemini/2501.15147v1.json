{"title": "A Causality-aware Paradigm for Evaluating Creativity of Multimodal Large Language Models", "authors": ["Zhongzhan Huang", "Shanshan Zhong", "Pan Zhou", "Shanghua Gao", "Marinka Zitnik", "Liang Lin"], "abstract": "Recently, numerous benchmarks have been developed to evaluate the logical reasoning abilities of large language models (LLMs). However, assessing the equally important creative capabilities of LLMs is challenging due to the subjective, diverse, and data-scarce nature of creativity, especially in multimodal scenarios. In this paper, we consider the comprehensive pipeline for evaluating the creativity of multimodal LLMs, with a focus on suitable evaluation platforms and methodologies. First, we find the Oogiri game\u2014a creativity-driven task requiring humor, associative thinking, and the ability to produce unexpected responses to text, images, or both. This game aligns well with the input-output structure of modern multimodal LLMs and benefits from a rich repository of high-quality, human-annotated creative responses, making it an ideal platform for studying LLM creativity. Next, beyond using the Oogiri game for standard evaluations like ranking and selection, we propose LoTbench, an interactive, causality-aware evaluation framework, to further address some intrinsic risks in standard evaluations, such as information leakage and limited interpretability. The proposed LoTbench not only quantifies LLM creativity more effectively but also visualizes the underlying creative thought processes. Our results show that while most LLMs exhibit constrained creativity, the performance gap between LLMs and humans is not insurmountable. Furthermore, we observe a strong correlation between results from the multimodal cognition benchmark MMMU and LoTbench, but only a weak connection with traditional creativity metrics. This suggests that LoTbench better aligns with human cognitive theories, highlighting cognition as a critical foundation in the early stages of creativity and enabling the bridging of diverse concepts. Project Page.", "sections": [{"title": "1 INTRODUCTION", "content": "LARGE language models (LLMs) [1], [2], [3], [4], [5], [6], [7] have catalyzed in a transformative era in neural network reasoning, revolutionizing various domains within artificial intelligence. Recently, numerous benchmarks [8], [9], [10], [11], [12], [13], [14] have been proposed to evalu-ate LLMs' rigorous logical reasoning abilities, spurring the development of methods to enhance these capabilities, par-ticularly the representative Chain-of-Thought (CoT) based methods [15], [16], [17], [18], [19]. These methods equip LLMs with human-like step-by-step reasoning capacity, en-abling them to excel in complex reasoning tasks ranging from language comprehension to visual understanding. As illustrated in Fig. 1 (a), CoT instills LLMs with a sequential thinking process where each subsequent thought builds upon the previous one. This paradigm enhances precision and rigor in logical processing, making it highly effective for problems requiring closely linked logical reasoning. While CoT-based methods have proven effective for logical rea-soning, they may fall short in capturing another equally im-portant thinking mode: creative reasoning. This limitation stems primarily from their sequential nature. For instance, proving an algebraic inequality often follows a step-by-step CoT process, progressing from one inequality to the next. In contrast, a more creative solution might arise from an intuitive flash, such as a geometric interpretation. This type of insight, known as \"Leap-of-Thought\" (LoT) or mental leap [22], [23], [24], [25], represents the art of non-sequential thinking through association, drawing parallels between seemingly unrelated concepts, and facilitating a \"leap\" in knowledge transfer. Unlike CoT reasoning, LoT, as depicted in Fig. 1 (a), fosters associative reasoning and encourages thinking outside the box, bridging disparate ideas and fa-cilitating conceptual leaps. Embracing LLMs with strong LoT abilities can unlock significant potential for creativ-ity, contributing to advancements in creative applications."}, {"title": "2 RELATED WORKS", "content": "(1) Multimodal LLMs and their creativity. Recently, multi-modal Language Models [34], [43], [44], [45] have garnered significant attention, particularly due to their impressive reasoning abilities [4], [5], [6]. Moreover, there is a growing focus on exploring the creativity [46], [47], [48] of LLMs for applications such as scientific discovery [49], [50], [51], creative writing [52], [53], [54], etc.\n(2) Computational humor is a branch of computational linguistics and artificial intelligence that uses computers in humor research [55], [56], which encompasses various tasks, including humor detection [57], [58], [59] and hu-mor generation [60], [61], [62], etc. With the advancement of generative LLMs [34], [35], [45], humor generation has become a popular focus while humor generation still faces challenges such as insufficient punchlines [63] and limited in multimodal contexts [64], [65].\n(3) Chain-of-Thought based Methods provide the models with \"chain of thoughts\" [15], [16], [18], [19], [66], [67], [68], [69], i.e., reasoning exemplars [15], or a simple prompt \"Let's think step by step\" [17], to encourage LLMs to engage in rea-soning rather than simply providing answers directly [70]."}, {"title": "3 EVALUATION PLATFORM: OOGIRI GAME", "content": "Unlike most logic reasoning benchmarks [8], [9], [10], [11], [12], [13], [14], creativity tasks suffer from a severe lack of data and high annotation costs, as it is challenging even for humans to generate a large number of creative responses. Recently, some works [31], [32], [33] have been proposed to study the lateral thinking capabilities of LLMs, but they primarily focus on information in the pure text modality. This makes exploring the creativity of multimodal LLMs a significant challenge, thereby hindering the development of methods to enhance their creativity. Fortunately, in this paper, we find that the Oogiri game serves as an ideal evaluation platform."}, {"title": "3.1 Oogiri-GO Dataset", "content": "In this section, we collect Oogiri game data to build a large-scale Oogiri-GO dataset which serves as the sample of benchmarks to explore the LoT ability.\nSpecifically, Oogiri-GO is a multimodal and multilingual humor dataset, and contains more than 130,000 Oogiri sam-ples in English, Chinese, and Japanese. Notably, in Oogiri-GO, 77.95% of samples are annotated with human prefer-ences, namely the number of likes, indicating the popularity of a response. As illustrated in Fig. 1 (b), Oogiri-GO contains three types of Oogiri games according to the input that can be images, text, or both, and are respectively called \"Text to Text\" (T2T), \u201cImage to Text\" (I2T), and \u201cImage & Text to Text (IT2T) for brevity. Table 1 summarizes the distribution of these game types. For training purposes, 95% of the samples are randomly selected to construct the training dataset, while the remaining 5% form the test dataset for validation in standard evaluation and analysis."}, {"title": "4 STANDARD EVALUATION WITH OOGIRI GAME", "content": "Inspired by the humor benchmarks in [71] and other stan-dard LLM evaluations [1], [31], [32], [33], we first develop a standard evaluation, i.e., choice and ranking questions, as shown in Fig. 2 (Left), and then quantitatively evaluate the LoT ability of LLMs on the Oogiri-GO test dataset. For the choice questions, mTn for short, they need LLMs to choose n \u201cleap-of-thought\u201d humor responses from m options given the input. Here we build four types of mTn questions, including 2T1, 3T1, 4T1, and 5T2. 2T1 means two options, the ground-truth response (GTR) and an image caption generated by BLIP2 [72]. 3T1 adds unrelated answers, e.g., other image captions. 4T1 further adds the GTR rewrite by Qwen-14B [2]. 5T2 has an extra GTR. For these questions, their difficulty increases progressively, and is diverse to ensure comprehensive evaluation. For choice questions, we use accuracy as the evaluation metric. Additionally, for the questions in test set whose responses have ground-truth human preference, e.g., the number of likes, we develop the ranking questions that always rank five candidates. For evaluation, we adopt the top-1 accuracy and the widely used ranking metric,i.e., Normalized Discounted Cumula-tive Gain (NDCG) [73], [74]. See more experimental details in the Appendix of conference version [1]."}, {"title": "5 LOTBENCH WITH OOGIRI GAME", "content": "As mentioned in Section 1, most existing standard eval-uations of LLMs [10], [12], [14], [31], [32], [33], including the evaluation presented in Section 4, are largely based on objective questions such as selection and ranking. These paradigms have significantly contributed to estimating LLM performance and have provided quantitative results, and"}, {"title": "5.1 The formulation of LoTbench", "content": "For brevity, we only consider constructing LoTbench with the Chinese and English data in Oogiri game. Inspired by situation puzzles [36], [75], given a input image $I_{in}$ with its caption C, we ask the LLM to provide an creative response $R_t$ by a masked language modeling (MLM) task as shown in Fig. 4 . And in each round of interaction, we determine whether it reaches the creativity level of HHCR R by causal"}, {"title": "5.2 Tuning LLM for Data Synthesis by CLoTv2", "content": "In this section, we tune the LLM through two steps: asso-ciable instruction tuning and explorative self-refinement, as shown in Fig. 7, to acquire the ability to generate specific HHCRs in preparation for the test data synthesis of LoT-bench in Section 5.3."}, {"title": "5.2.1 Associable Instruction Tuning", "content": "LoT ability mainly includes associable generation and dis-crimination ability [77]. Given an input, associable genera-tion draws its parallels with seemingly unrelated concepts via remote association and then generates innovative re-sponses, e.g., the unexpected humor for the Oogiri input. Associable discrimination is to judge the matchiness among input and responses though they are seemingly unrelated, and then to select the most creative response.\nUnfortunately, both associable generation and discrim-ination are not present in current LLMs, e.g., not good performance of GPT40 [78] in the Oogiri game observed in Sec. 6. Moreover, it is hard to improve these two LoT abilities via popular CoT-like prompt techniques. Indeed, as shown in Sec. 6, CoT even sometimes impairs the LoT performance of the LLMs like Qwen-VL [45] in the Oogiri game. To address this issue, we propose associable instruction tuning which trains LoRA [79] for LLMs on the Oogiri-GO dataset to achieve certain associable generation and discrimination abilities. It has two steps, including instruction generation and discrimination template design, and associable instruc-tion learning."}, {"title": "5.2.2 Explorative Self-Refinement", "content": "After associable instruction tuning, we aim to generate more HHCRs which are then used to train LLM for self-refinement. To this end, we introduce an innovative stage called explorative self-refinement, inspired by human LoT exercise process of \u201cremote association & self-refinement\u201d, also known as mental leap [22], [25], [77]. The remote associ-ation process refers to generating new ideas by associating remote concepts or thoughts, and self-refinement uses the generated data to enhance one's own LoT ability. In the following, we design two similar LoT exercise processes for LLM to improve its LoT ability.\n(1) Explorative Remote Association. The core here is to prompt the LLM to generate a diverse array of creative responses under weakly-associated conditions.\nTo implement this, as shown in Fig. 7 (Right), we first extract a set of keywords, including nouns, verbs, adjectives, and adverbs, denoted as S, from the text in the Oogiri-GO training data. Then, for given image and text in each sample, we construct a series of effective weakly-associated conditions as follows. We sample n candidate conditions $\\{C_i\\}_{i=1}^{n}$ from S with equal probability, then use CLIP or SimCSE [80], [81] to batch compute the similarity between these candidates and the image or text in samples. The similarities of I2T and IT2T are determined by their CLIP scores based on their images and keywords, while SimCSE is used to calculate the similarity for T2T. The candidates are ranked by similarity in descending order to get $\\{C_i'\\}_{i=1}^{n}$.\nWe remove the top \u03b1% and bottom \u03b2% of elements from"}, {"title": "5.3 The Data Construction in LoTbench", "content": "Task type. The primary task in LoTbench is a masked lan-guage modeling (MLM) task, as illustrated in Fig.4. Unlike I2T tasks that directly generate a complete response, MLM is a variation of IT2T. This design choice is guided by two key considerations: (1) To ensure the task leverages LLM's core strengths. Otherwise, limitations in some specific ca-pabilities might lead to mediocre performance, interfering with the assessment of LLM creativity. MLM is precisely the type of task where LLMs excel [84]; (2) To simplify evaluation complexity. Since creativity is inherently diverse, allowing LLMs to freely generate responses $R_t$ as in I2T tasks would make it difficult to assess whether they match the creativity level of given HHCR R due to high variability. Therefore, some constraints on $R_t$ are necessary, and MLM tasks naturally provide this by fixing certain textual content, making it a suitable choice.\nSpecifically, as shown in Fig. 4, we manually annotate the key text \u03ba in each HHCR R, mask it, and ask the LLM to complete the response, aiming for creative and high-quality responses. The \u201ckey text\u201d \u03ba refers to some textual contents that most crucially link the image and response, making the responses creative. Removing these contents would strip the text-image combination of its creativity. For example, in Fig. 4 Example 1, \"alarm clock\" is the key text in R. Moreover, identifying such key text accurately is challenging for different automated tools, including LLMs, so in this paper, we manually annotate them one by one during the data construction process.\nData structure. Each sample in LoTbench consists of six parts: the input image $I_{in}$ with its corresponding HHCR R, image caption C, and key text \u03ba. It also includes a detailed explanation Exp of why each R is innovative, and a Clue set $C_t = \\{C_i\\}_{i=1}^{N}$ designed to help LoTbench complete the evaluation within a limited number of rounds. For instance, in the sample shown in Fig. 4 Example 1, the input image $I_{in}$ is the one on the left, with R being \"Vibrant alarm clock\", C being \u201cA freshly caught fish, still flopping on the table, made a loud noise\u201d, and \u03ba being \u201calarm clock\u201d. The expla-nation Exp is \u201cThe lively fish rapidly flopping on the table and making a lot of noise closely resembles the moment when an alarm clock goes off. In R, the visual association of imagining the fish's flopping as an alarm clock ringing is both surprising and intriguingly interesting.\" Additionally, we have structured the Clue set $C_t = \\{C_i\\}_{i=1}^{N}$ to include both substantive clues and empty clues. At regular intervals, such as every several rounds (set as 5 in our paper) as indicated in line eight of Alg. 1, a substantive clue is added to the user-input. An example of a substantive clue is \u201cIt is a noun; It is a commonly used object at home; Pay attention to rapid jumping; Related to sound; Related to time.\u201d\nData volume."}, {"title": "5.4 The Details of It and Rt", "content": "In Alg. 1, $I_t$ initially includes only the input image $I_{in}$ and its corresponding image caption C. The generation prompt G contains the complete instruction, including the system prompt, example prompt for in-context learning, and task-specific prompts. Additionally, G also includes R with the key text \u03ba masked. In each round of evaluation, the LLM under test is required to creatively fill in the masked key text in R through the given $I_t$ and prompt G. As the LoTbench interactive evaluation progresses, $I_t$ will continuously in-corporate the current round's generated response $R_t$, the obtained clue $C_t$, and the question and answer $Q_t$ and $A_t$. In the next round, this historical information will help the LLM to further produce a creative response. See supplementary for all prompts and other details."}, {"title": "5.5 To Measure DAESO with Causal Evaluator E\u2081?", "content": "5.5.1 Criteria\nIn Alg. 1, we need an evaluator $E_1$ to determine whether $R_t$ and a given HHCR R exhibit a similar level of creativity. On one hand, since creativity is diverse, $R_t$ and R are unlikely to be identical at the character level, so $E_1$ cannot assess them through string matching. On the other hand, we also cannot rely solely on semantic similarity, as is common in natural language processing [81]. For example, as illustrated in Fig. 4 Example 1, if R is \"vibrant alarm clock\" and an LLM outputs $R_t$ as \"vibrant cell phone,\" we may still con-sider $R_t$ to have a similar level of creativity to R despite the semantic distance between \"cell phone\" and \"alarm clock\u201d. Through the analysis above, in this paper, the $E_1(R_t, R)$ is set to assess whether $R_t$ and R are a \"different approach but"}, {"title": "5.5.2 Modeling", "content": "Causal Construction. For a given sample, we can first lever-age the image caption C and carefully annotated explanation Exp of \u201cWhy R is creative,\u201d as mentioned in Section 5.3, to model the causal chain for R and C. R and C are expanded in the form of Eq. (2) as follows:\n$C \\sim (c^{(1)}, c^{(2)} ..., c^{(last(C))})$\n$R \\sim (R^{(1)}, R^{(2)},..., R^{(last(R))}) ,$\n(2)\nwhere $C^{(i)}$ and $R^{(i)}$ represent individual nodes within C and R, respectively, with Fig. 8 (b) illustrating a diagram. last(C) and last(R) denote the number of nodes in chain of C and R, respectively, and they may not be equal. First, for criterion (1), there should be a creative explanation f and i < last(R), j \u2264 last(C), ensuring that:\n$f(R^{(i)}) \\rightarrow C^{(i)},$\n(3)\ni.e., there exists a function f such that one node in R can be mapped to another node in R, and this mapping f is the reason why R is considered creative. Fig. 8 (c) provides a specific analysis for Fig. 4 Example1 where the \"alarm"}, {"title": "5.5.3 Measuring DAESO by E1", "content": "In this section, we provide the details of evaluator $E_1$ by the modeling in Section 5.5.2. According to Section 5.5.2, there are three steps to determine whether $R_t$ and R are DAESO:"}, {"title": "5.6 How to ask a Question Qt and answer it by E2?", "content": "As mentioned in section 5.1, the rethinking about spon-taneous questioning is also a manifestation of one's own creativity [75], [76], which can visualize the process of achieving creativity in LLMs. Given the current input $I_t$ and an incorrect response $R_t$, LLMs utilize a question prompt Q, which includes a series of instructions related to questioning, such as system prompts, example prompts for in-context learning, and task-specific prompts. We require the LLM to propose a speculative question $Q_t$ about R, such as \"Is it related to daily life?\" or \"Is it a type of appliance?\" and so on, to help itself generate more human-like creative responses in the next round. Subsequently, for $Q_t$, we consider using a textual independent LLM, denoted"}, {"title": "5.7 The Creativity Score Sc", "content": "As mentioned in section 5, LoTbench aims to explore how many rounds of creative thinking are required for LLMs to achieve HHCRs, with fewer rounds indicating statistically higher creativity. Therefore, we believe the creativity score $S_c$ should meet at least two requirements for the set of the number of rounds $r = [t_1, t_2 ,...,t_m]$ with m times repeated evaluation: (1) As min(r) \u2192 \u221e, $S_c$ \u2192 0, meaning that if an LLM has not reached the creativity level of HHCR after a sufficiently large number of rounds, its contribution to creativity in the current sample tends to zero; (2) $S_c$ should be inversely proportional to the round, meaning that the faster the LLM reaches HHCR, the more creative it is considered to be. Thus, we propose the following formula to define $S_c$.\n$S_c = \\frac{1}{m n} \\sum_{i=1}^{m} \\sum_{j=1}^{n} B_c exp[-\\alpha_c \\cdot t],$\n(8)\nwhere n represents the number of test samples in LoTbench, while $\u03b2_c$ and $\u03b1_c$ are hyperparameters, and set to 1.0 and 0.2 respectively in this paper. The m denotes the number of rounds for repeating independent tests on a single sample. The rationale behind conducting multiple experiments is to reduce the errors in evaluator judgments as shown in Section 8 and provide more opportunities for LLMs to engage in creative thinking, as creative responses are not always produced [1]. Additionally, considering the cost of inference, we set m = 3."}, {"title": "6 EXPERIMENTS UNDER STANDARD EVALUATION", "content": "In this section, we explore the creativity of different LLMs through standard evaluation shown in Section 4, while test-ing the creative response generation capability of CLoTv2 proposed in Section 5.2. Noticing that we considered setting"}, {"title": "6.1 Evaluation by Choice and Ranking Questions", "content": "Evaluation on Multimodal Multilingual LLMs. We plug our associable instruction tuning (AITv2) and our CLoTv2 into the advanced open-source multimodal multilingual model Qwen-VL [45] to obtain Qwen-VL+AITv2 and Qwen-VL+CLoTv2, respectively. Table 2 shows that, on three tasks (IT2T, I2T and T2T) which include English, Chinese and Japanese questions, Qwen-VL achieves the best LoT per-formance among all open-source baselines in most cases. In comparison, Qwen-VL+AITV2 achieves a noticeable im-provement on the advanced Qwen with average accuracy enhancements of 7.4%, 7.6%, and 5.3% on the three tasks, respectively. Importantly, Qwen-VL+CLoTv2 further enhances Qwen-VL, showing improvements of 9.6%, 11.7%, and 9.1% in accuracy across these tasks. These results demonstrate the efficacy of the two stages in CLoTv2, i.e., associable instruction tuning and explorative self-refinement.\nEvaluation on Multimodal Non-multilingual LLMs. Here we integrate our CLoTv2 with the advanced multimodal"}, {"title": "6.2 Experiments under LoTbench", "content": "In this section, we assess the creativity of various mul-timodal LLMs using LoTbench. To better understand the creativity score $S_c$, we introduced 21 human subjects aged between 13 and 44, testing only the samples in LoTbench for languages they are proficient in. Ultimately, we divided their $S_c$ into three equal groups based on their $S_c$ rankings, with each group containing 9 individuals, and calculated the average $S_c$ for reference, naming them human (high), human (medium), and human (low).\nFrom the results in Fig. 10, most LLMs do not exhibit high creativity in the LoTbench scenario, but the gap be-tween their creativity and the average level of human par-"}, {"title": "7 ANALYSIS", "content": "7.1 Ohter Types of Evaluation\nIn Section 5, we shown that the truly reasonable creativity evaluation should assess the \"measure the creativity level of LLM\" rather than \"recognize the creativity from LLM.\u201d Actually, to evaluate the \"measure the creativity level of LLM\", there are also some previous methods like human evaluation and LLM-as-a-Judge [98], [99], [100], [101]. In this section, we consider these two kinds of evaluations for LLM's creativity, and show the necessity of LoTbench."}, {"title": "7.1.1 Human Evaluation for LLMs' Creativity", "content": "We conduct a user preference study to test creativity of LLMs. Here we select eight LLMs to generate responses for a total of twenty-one questions across three tasks (IT2T, I2T and T2T). We use choice questions, and ask users to choose the creative and humorous responses they think. Fig. 13 summarizes the statistical analysis of 56 valid sur-veys. The results indicate a strong user preference for the enhanced outputs from both the associable instruction tun-ing and explorative self-refinement stages across all three tasks, highlighting the effectiveness of our proposed method for synthesizing HHCRs. See more details in Appendix of the conference version [1]. The human evaluation provides"}, {"title": "7.1.2 LLM-as-a-Judge for LLMs' Creativity", "content": "Moreover, following analysis through the Oogiri game, we find that directly using LLM-as-a-Judge might also struggle to accurately assess creativity of LLM.\nSpecifically, we consider the following settings to explore the relationship between LLM-as-a-Judge and human pref-erences in Fig. 13. Using the setup shown in Fig. 13, we randomly select 5 responses out of 8 generated for each sample and construct a ranking based on human preferences as the ground truth. Then, we have Qwen-VL and Qwen-VL+CLOTv2 rank the 5 responses as well, comparing their rankings to the ground truth using the Spearman (SP) rank correlation coefficient [102]. A higher SP score indicates a ranking closer to the human preference; a lower score indi-cates less similarity. As shown in Fig. 14 (Left), we observe that while the original Qwen-VL has some ability to align with human-recognized creativity, it is nearly unusable in practice since a large number of SP values are concentrated around zero, and even in the negative region. In contrast, the enhanced Qwen-VL+CLoTv2 significantly improves the LLM's judgment of responses. These observations are con-sistent with the standard evaluation results in Section 6.1. However, since SP scores for Qwen-VL+CLoTv2 occasionally fall below 0.0, it indicates that this model is not fully reliable for judging or precisely scoring arbitrary responses.\nNext, we further analyze Qwen-VL+CLoTv2's ranking ac-curacy by counting the ranking errors across different rank indices. Fig. 14 (Right) shows the error distribution across these indices. We observe that Qwen-VL+CLoTv2 has fewer errors at the highest and lowest ranks, performing best at identifying the highest- and lowest-quality responses, while its performance is more ambiguous with mid-range quality responses. This suggests that although Qwen-VL+CLoTv2 may struggle to give fine-grained scores or make fully accurate judgments for any sample, it remains viable as a data filtering tool as discussed in Section 5.2.\nIn summary, due to the limitations of different eval-uation methods mentioned above, we propose LoTbench in this paper is necessary. Instead of directly scoring LLM responses, LoTbench estimates creativity by measuring the"}, {"title": "7.2 The Effectiveness of E1", "content": "To validate this LLM-based DAESO judgment method pro-posed in Section 5.5, we used a validation set of 43 DAESO samples collected during the construction of LoTbench to perform tests from multiple perspectives. First, we con-ducted experiments on causal chain construction and inter-vention using Qwen-7B, Qwen-14B, MiniGPTv2, Baichuan2, Llama2, GPT-3.5, GPT40 mini and GPT-4 with this valida-tion set, manually inspecting each result for accuracy. As shown in Fig. 15 (Left), we can find significant performance differences in causal chain construction and intervention among these LLMs, with GPT series outperforming the others. Moreover, in Fig. 15 (Right), we considered three settings: (1) Using only a prompt to let the LLM directly zero-shot determine whether $R_t$ and R are DAESO; (2) Zero-shot DAESO judgment with detailed Exp and C provided; (3) Our proposed method of causal chain modeling in text space based on Exp and C. From the results, we can see that $E_{xp}$ and C are crucial\u2014without them, all LLMs performed poorly, almost guessing randomly. When this information is provided, modeling and intervening in the causal chain resulted in better judgment outcomes. Therefore, based on these experimental results, to ensure the accuracy of LoT-bench and minimize reasoning costs, like API fee, we adopt GPT-40 mini as $E_1$ in the actual evaluation of LoTbench and provided detailed Exp for each sample."}, {"title": "7.3 The Effectiveness of E2", "content": "In Section 5.6, we need a powerful text-based LLM as eval-uator $E_2$ to accurately respond to the tester's spontaneous questioning $Q_t$ with a precise answer $A_t$. In this section, we find that selecting GPT-40 mini is suitable for this task as shown in Fig. 15 (Left). Specifically, during the construction of the LoTbench test set, we also collect a simple validation set of 130 examples to test whether various LLMs have the ability to provide judgments for $Q_t$. Fig. 15 (Left) shows the judgment results of different LLMs, where most LLMs can achieve an accuracy rate of over 80%, and GPT-40 mini not only has a relatively low reasoning cost but also an accuracy rate of up to 98%. Therefore, we choose it as the judge $E_2$."}, {"title": "7.4 The Correlation with Cognition Benchmark", "content": "(2) The creativity assessment results from LoTbench align more closely with current human cognitive theories [38], [39], [40], [41], [42]. In this Section, we compare the evalua-tion results of the well-known and comprehensive cognitive ability assessment MMMU with those of our proposed"}, {"title": "7.5 Limitation", "content": "While the proposed LoTbench offers intuitive and user-friendly features, it does have certain limitations. For in-stance, as a multi-turn interactive benchmark, it may not be suitable for evaluating all types of subjects. For example, as mentioned in Section 6.2, humans are not particularly adept at long-term interactions. Similarly, CLoTv2 faces this issue as well. Due to the multi-turn tuning described in Section 5, while its creativity shows some improvement in standard evaluations, other abilities may be slightly diminished [103], especially the ability to follow context. This limitation pre-vents it from being assessed using LoTbench. Currently, LoTbench is primarily designed for evaluating the creativity of general LLMs. In the future, we need to explore bet-ter methods to stimulate LLM creativity using LoTbench while minimizing the catastrophic forgetting [103] of gen-eral capabilities. On the other hand, LoTbench constructs creativity scores by estimating the average cost for the target LLM to achieve certain HHCRs through interactive methods. While this definition of LLM creativity facilitates benchmark design, it is not the only definition, and the concept of creativity still lacks a clear consensus [104], [105]. In the future, the community should explore more advanced definitions of creativity to address potential risks associated with LoTbench."}, {"title": "8 CONCLUSION", "content": "This paper investigates creativity in LLMs and provides an in-depth analysis of their Leap-of-Thought (LoT) abilities through the Oogiri game. In particular, given some inherent issues, like information leakage, in current assessments of LLM creativity, we introduce a novel interactive benchmark, LoTbench, to effectively evaluate LLM creativity. Our find-ings reveal that while LLMs exhibit limited creativity, the gap between LLM and human creativity is not significant."}]}