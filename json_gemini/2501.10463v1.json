{"title": "GLow - A Novel, Flower-Based Simulated Gossip Learning Strategy", "authors": ["Aitor Belenguer", "Jose A. Pascual", "Javier Navaridas"], "abstract": "Abstract-Fully decentralized learning algorithms are still\nin an early stage of development. Creating modular Gossip\nLearning strategies is not trivial due to convergence challenges\nand Byzantine faults intrinsic in systems of decentralized nature.\nOur contribution provides a novel means to simulate custom\nGossip Learning systems by leveraging the state-of-the-art Flower\nFramework. Specifically, we introduce GLow, which will allow\nresearchers to train and assess scalability and convergence of\ndevices, across custom network topologies, before making a\nphysical deployment. The Flower Framework is selected for being\na simulation featured library with a very active community\non Federated Learning research. However, Flower exclusively\nincludes vanilla Federated Learning strategies and, thus, is not\noriginally designed to perform simulations without a centralized\nauthority. GLow is presented to fill this gap and make simulation\nof Gossip Learning systems possible. Results achieved by GLow in\nthe MNIST and CIFAR10 datasets, show accuracies over 0.98 and\n0.75 respectively. More importantly, GLow performs similarly in\nterms of accuracy and convergence to its analogous Centralized\nand Federated approaches in all designed experiments.", "sections": [{"title": "I. INTRODUCTION", "content": "HE number of IoT devices has surged in recent decades,\ndriven by smart cities, wearables, self-driving cars and\nautomation. The data generated by these devices is crucial\nfor training complex ML/DL models, traditionally done in\ncentralized datacenters (CNL). However, due to scalability,\nprivacy and resource concerns, new paradigms like Federated\nLearning (FL) [1] have emerged, offering reduced communi-\ncation costs and privacy benefits. Gossip Learning (GL) [2]\nfurther addresses central authority issues by enabling fully\ndecentralized communication among neighbors.\nGLow is a novel simulated GL strategy, built on top of\nthe Flower Framework [3]. That allows researchers to test\ncustom GL systems in terms of convergence, scalability and\nperformance. Flower is a state-of-the-art framework developed\nto support FL studies by implementing strategies based on\na centralized aggregation server. Nevertheless, we envision a\nscenario where different nature IoT devices are connected to\neach other following a decentralized interconnection scheme\nwithout an aggregation server. GLow leverages Flower\ncapabilities to enable fully decentralized Gossip Learning,\nin which each agent holds a dedicated model and benefits\nfrom neighbor parameter interchange. An important feature of\nGLow is that network topology and agents behavior can be\ncustomized, providing an enormous degree of freedom in the\ndesign of decentralized systems. In particular, we propose a\nnovel methodology where agents can be instructed to behave\nin a predefined fashion, which can be leveraged to ensure the\ncorrect evolution of the decentralized learning system."}, {"title": "II. STATE OF THE ART", "content": ""}, {"title": "A. Self Learning and Centralized Learning", "content": "In Self Learning (SL), each agent trains a model exclusively\nrelying on local data. It can be a good and simple learning\napproach, when the local database is large enough and the\ndevice is placed in a remote location with no access to the\nnetwork or under restrictive policies that force it to work in\noffline mode. However, receiving data or other model param-\neters from the network can potentially benefit the creation of\nstronger models. Specifically, learning from other agents is of\nspecial interest in scenarios where the nature of data changes\nconstantly or stream learning is performed, e.g., Anomaly\nDetection, Network Intrusion Detection Systems [4] and so\non. In order to overcome the SL scenario, working with\nmultiple IoT agents with a similar task allows sharing dataset\ninstances in a raw way to a centralized authority, that is when\ntraditional Datacenter or Centralized Learning (CNL) appears.\nHowever, new privacy, reliability and scalability challenges\nemerge: (1) sharing highly sensitive data through the network\ncan violate privacy constraints, (2) relying on a particular\ncentralized authority to perform all the training, makes the\nsystem vulnerable against a weak spot, (3) sharing data from\na cross-device [5] environment with a large number of devices\nto a datacenter can cause network throughput issues, even to\nthe point of saturating the whole network."}, {"title": "B. Federated Learning", "content": "Federated Learning (FL) enables multiple parties to jointly\ntrain an ML model without exchanging local data. FL was\nfirst proposed by B. McMahan et al. (FedAVG) [1], involving\ndistributed systems, ML and privacy research areas. Currently,\nFL has become a hot-topic of research and different Federated\nLearning Systems have emerged. Depending on their nature"}, {"title": "C. Gossip Learning", "content": "Gossip Learning (GL) is a decentralized learning method\nin which different agents interchange local parameters with\ntheir neighbors (peers) and perform the aggregation of the\nmodels asynchronously without needing an orchestration\nserver. Although Ormandi et al. [8] introduced the idea of GL\nfor classification using linear models back in 2013, research\nabout fully decentralized algorithms has not attracted as many\nresearches as vanilla FL, mostly because of the additional\nconvergence and orchestration challenges GL entails. How-\never, L. Yuan et al. [9] introduce a different point of view of\nFL, dividing it into Centralized FL (CFL) and Decentralized\nFL (DFL), based on the existence of an aggregator server.\nMoreover, a taxonomy of DFL systems is proposed in which\nGL is considered a communication protocol and other aspects\nsuch as iteration order and network topology are taken into\naccount. Additionally, E. Martinez et al. [10] claim the lack\nof contributions gathering information about existing DFL\nframeworks and classify them based on how mature and\ncustomizable those frameworks are. It is remarkable that, in\nspite of mentioning frameworks such as TensorFlow Federated\n(TFF), PySyft or FedML, there is no research involving DFL\nusing Flower [3], even when it is a consolidated framework\nin the FL community."}, {"title": "D. Flower Framework", "content": "Flower is a comprehensive open-sourced FL framework that\noffers new facilities to carry out large-scale FL experiments\nand considers richly heterogeneous FL device scenarios [3].\nIt unlocks scalable algorithmic research as well as system\nlevel aspects. In other words, it allows the transition from\nexperimental research in simulation to system research in\nheterogeneous edge devices. D. Beutel et al. [3] present\na comparison among different FL frameworks, stating that\nFlower provides a larger feature set in comparison to TFF,\nSyft, FedScale and LEAF. Although Flower is interesting in\nterms of simulation, scalability and multi-platform deployment\nproperties; current research and designed algorithms are CFL\noriented (e.g., FedAVG, FedProx and so on). To the best of\nour knowledge, a research line involving DFL in Flower is not\nfully covered by the state-of-the-art."}, {"title": "E. Related Work", "content": "Although FL is a hot-topic of research, contributions to\nDecentralized FL strategies are limited. Roy et al. [11] present\nBrainTorrent, a dynamic peer-to-peer environment, and carry\nout a proof-of-concept study that performs medical image\nsegmentation. The authors propose a fully connected network,\nwhere each agent maintains a vector containing its own and\nthe last versions of the models used during the merging\nstep. Another interesting contribution is Fedstellar [12], which\nproposes a novel platform to train FL models in a centralized,\ndecentralized and semi-decentralized fashion, across physical\nor virtualized devices. The platform is custom-made, merging\nPyTorch, asynchronous sockets and Docker containers. Fed-\nstellar presents a robust comparison against other literature\nsolutions, including BrainTorrent, using MNIST and CIFAR10\ndatasets to assess system performance.\nL. Chen et al. [13] propose the usage of quantization meth-\nods to improve DFL convergence. Specifically, the authors\nsuggest using Lloyd-Max algorithm to minimize quantization\ndistortion by adjusting quantization levels again, system\nperformance is assessed using MNIST and CIFAR10 datasets.\nAnother alternative is GossipFL [14] which presents a novel\nsparsification algorithm, built on FedML framework, to enable\neach agent to communicate with just one peer while better\nusing bandwidth resources.\nThe number of approaches that try to adapt the Flower\nframework to support DFL scenarios is scarce. The only one\nwe are aware of is introduced by Y. Kanamori et al. [15] which\ndeveloped an asynchronous FL framework for decentralized\nsystems. The authors take advantage of gRPC (Google Remote\nProcedure Calls) present in Flower communication layer to\noperate at agent message passing level. This approach differs\nfrom ours in that it focuses on system deployment rather\nthan on simulated environments. Their ultimate objective is to\nunderstand how the order of learning and aggregation affects\nthe performance of DFL and their evaluation tests various\ntopology-agnostic decentralized algorithms in their framework.\nIn contrast, our approach is more interested in assessing the\neffects of agent topology, density of communications, etc.\nFurthermore, our simulation-oriented strategy enables decen-\ntralized learning research while preserving Flower framework\ncore unaltered. Specifically, we focus on simulating fully\ndecentralized systems by proposing a custom Flower strat-\negy from an upper level without interfering with internal\ncommunication layers."}, {"title": "III. DESIGNED STRATEGY", "content": "Flower does not support a fully decentralized aggregation\nmechanism able to orchestrate multiple network agents and\nmake them converge without a centralized authority. Specif-\nically, Flower simulation engine is not originally designed"}, {"title": "Algorithm 1 GLow Simulation Procedure", "content": "Require: Head model weights $W_k$ for selected head agent\nk, Local model weights $W_i$ for each neighbor agent i of\nhead; total_rounds, $E \\in \\mathbb{Z}^+$\nEnsure: Aggregated head model weights $\\widehat{W}_k$\nfor each iteration in 1 to total_iterations do\n$k = iteration \\mod K$\n$W_k'$ = agent k performs local training E times\nk gets current $W_i$ of each Neighbour agent $N_k$\n$\\widehat{W}_k = \\frac{\\sum_{i \\in N_k}W_i}{\\sum_{i \\in N_k}W_i}$\nend for\nAlgorithm 1 shows how GLow simulation procedure is\nperformed: (1) the agent head is selected in a round-robin\nfashion by using the modulus of current iteration 2 \nstrategies such as random or priorities would be straight-\nforward to implement, (2) the selected head performs local\ntraining using local instances for E epochs, (3) the Head\nagent asks his neighbors $N_k$ for their current weights $W_i$,\n(4) aggregation (weighted average) among locally trained and\nneighbor parameters is performed, updating head model $\\widehat{W}_k$.\nIn order to select how agents are connected, GLow in-\ncludes a Topology Generator (TG) tool which allows as-\nsessing system behavior in different decentralized scenarios.\nThe output generated by TG is completely compatible with"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "GLow is a novel Flower-based GL strategy that needs\nto be compared against other learning paradigms to assess\nits feasibility and benefits. Although creating a fair testing\nscenario among systems of different nature is challenging, a\ncommon frame is designed to analyze the trade-off of using\nCNL, FedAVG (FL) and GLow (GL) approaches.\nIn order to assess GLow performance, two different se-\ntups are prepared under an image classification task. The\nconvergence of the system is tested with 8 and 16 agents.\nMoreover, experimentation is performed with MNIST [16] and\nCIFAR10 [17] datasets to have a solid test bench. We ana-\nlyze how the interconnection degree impacts in each agents'\nlearning performance by launching experiments from a discon-\nnected (Self Learning) to a fully connected graph scenario. In\nthe proposed scenarios, illustrated in Figure 1, each topology\nprogressively adds new links to agents by connecting them to\nthe next two closest agents. In other words, 2 new undirected\nedges are added per agent in each topology; each agent will\nbe connected to 0 neighbors in topology 0, to 2 neighbors\nin topology 2,  to n neighbors in topology n. Hence, in\nthe 8-agent case, 5 topologies are studied from a completely\ndisconnected to a fully connected graph. Similarly, in the\n16-agent case, 9 topologies are studied from a completely\ndisconnected to a fully connected graph.\nIn the creation of the mentioned common benchmark for\nassessing GLow, two additional versions are created based\non: (1) CNL learning, where the training is carried out over\nthe whole dataset in a single server and (2) FL, using vanilla\nFedAVG [1] algorithm (splitting the dataset in an IID way\namong all the agents). Although the performance of CNL and\nFL versions is expected to be higher (due to their simplicity\nagainst fully decentralized), the benefits of using GLow makes\nit potentially more attractive in cross-device scenarios as\nmentioned in Section II."}, {"title": "A. Datasets and models", "content": "MNIST and CIFAR10 datasets are selected due to their wide\nusage in state-of-the-art for testing convergence in distributed"}, {"title": "B. Special Agents", "content": "In this work, we introduce a novel methodology for as-\nsessing the correct behavior of a fully decentralized learning\nsystem: special agents which behave in a predictable way\nand serve as control agents that will remain stable during\nsimulation. Therefore, if special agents start running unpre-\ndictably, simulation will need to be re-assessed. Table I clusters\neach agent by Code and Color Group to make results more\nrepresentative in Figures 5 and 7. In particular, we consider\nthe following expected behaviors: (1) agents with no local\ndata (E) and disconnected from the network (D) are expected\nto behave as random guessers (ED), (2) agents with local data\nand disconnected (D \u2013 performing SL) are expected to behave\nsimilar or worse than connected agents with local data, (3)\nagents with no local data but connected to their neighbors (E)\nare expected to learn from other agents and achieve certain\ndegree of convergence. The remaining agents have data and\nare connected (R \u2013 Regular)."}, {"title": "C. Configurations", "content": "To ascertain the effects of agent scale in GLow, two experi-\nmentation scenarios are carried out with 8+2 and 16+4 agents\nrespectively. In the experiments we refer to communication\nrounds as the total number of times each agent is designated\nas head and performs parameter averaging. Therefore, the total\nnumber of iterations used in Algorithm 1 is the number of\nagents times the number of communication rounds. Depending\non the selected dataset and its complexity, the number of\ncommunication rounds is set differently to ensure proper\nconvergence: 24 communication rounds per agent as head in\nMNIST, whereas 101 communication rounds per agent as head\nin CIFAR10. Section III shows how an agent is selected as\nhead (operating as server and client) while neighbor parame-\nters are aggregated with the local ones in each communication\nround."}, {"title": "V. RESULTS", "content": "We now move on to the evaluation of our case study, where\nwe assess the feasibility of the GLow strategy by comparing\nit with CNL and FL. We carried out an extensive evaluation4"}, {"title": "A. CNL and FL", "content": "CNL slightly outperforms the rest of the systems. This is\nreasonable as it uses the whole dataset and does not have\nto deal with the challenges associated to distributed systems.\nCNL achieves 0.989 and 0.789 accuracy in MNIST and\nCIFAR10, respectively. Moreover, its loss evolution, shown\nin Figures 2 (MNIST) and 3 (CIFAR10), is two orders of\nmagnitude below the distributed approaches; denoting lower\ninitial convergence challenges.\nRegarding the FL systems, MNIST 10-agent scenario\nachieves an accuracy of 0.985 after 24 communication rounds.\nFigure 2 shows a fast convergence rate during the evaluation\nstage of each communication round. On the other hand, in\nthe CIFAR10 dataset, convergence rate is slower, but still\nrelatively good results are achieved: 0.791 accuracy after 101\ncommunication rounds. This is reasonable because CIFAR10\nis more complex than MNIST in terms of color channels, size\nand diversity of the images. The larger, 20-agent, scenarios still\nfeature competitive results which show the good scalability of\nthe FL models. As shown in Table II, accuracies achieved in\nthe MNIST dataset are 0.986 and the ones achieved in the\nCIFAR10 dataset are 0.778. Overall, FL results are similar, if\nslightly lower, to those of CNL."}, {"title": "B. GLow", "content": "Figure 4 shows final accuracies obtained by each agent\nin the evaluation stage, after running each system for 24\ncommunication rounds in the MNIST dataset \u2013 for both 8+2\nand 16+4 scenarios. In the 8+2 agent scenario, in topology 0, E\nagents are not capable of learning any model and act as random\nguessers. In topology 2, E agents manage to learn information\nfrom their neighbors and are able to obtain an accuracy below\n0.7 in the final stage of the training ED agent 9 is always\ndisconnected from the network acting as a random guesser.\nIn the rest of the topologies (4, 6 and 7), E agents converge\nsimilarly compared to R agents in the network. Interestingly,\nfurther increasing the degree of inter-connectivity does not\nimprove the results any further. Lastly, D agents achieve an\naccuracy of 0.99 despite being disconnected from the network."}, {"title": "VI. CONCLUSIONS AND FUTURE WORK", "content": "GLow is a novel, simulation-oriented Gossip Learning strat-\negy built on top of Flower, a state-of-the-art framework. It is\ncompletely modular and easy to deploy. We relied on Flower to\nensure GLow implementation is community-friendly and open\nfor research purposes. Moreover, the availability of different\nagent/topology configurations, models and datasets can be\ndone with minimal changes in the codes. It is worth mention-\ning that GLow includes a topology generator and result visu-\nalization features \u2013 providing a robust tool-set for the study of\nconvergence subject to the degree of inter-connectivity among\nagents. In addition, the possibility of adding agents operating\nin SL mode, disconnected from the network (with or without\nlocal instances), adds extra flexibility to the evaluation of\nthe system; showing the benefits of performing decentralized\nparameter averaging among neighbors.\nResults obtained in Section V show a good performance\nof GLow as a Flower built fully decentralized GL strategy.\nIn the 8+2 agent scenario, the three systems achieve very\nsimilar accuracies in both MNIST and CIFAR10 datasets\naverage GLow accuracies in MNIST: 0.987, and CIFAR10:\n0.754. On the other hand, in the 16+4 scenario, GLow obtains\nsimilar results to CNL and FL in the MNIST dataset - 0.971\naverage accuracy. Nevertheless, slightly lower accuracies are\nachieved by GLow in the 16+4 CIFAR10 scenario 0.683\naverage accuracy. Arguably, this happens as a consequence of\nsplitting the dataset among a larger set of agents, where some\nof them are disconnected (operating in SL); not contributing to\ntheir neighbors. However, the benefits of using a fully decen-\ntralized learning strategy against a centralized one (vanilla FL)\nwhich requires an aggregation authority are worth underlining.\nSpecifically, in terms of scalability and fault tolerance, where\nthe FL orchestration server is, potentially, the bottleneck and a\nsingle point of failure. Therefore, GLow gains special interest\nin the current circumstance, where the research on GL is scarce"}]}