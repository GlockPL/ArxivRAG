{"title": "Combining Open-box Simulation and Importance Sampling for Tuning Large-Scale Recommenders", "authors": ["Kaushal Paneri", "Michael J. Munje", "Kailash Singh Maurya", "Adith Swaminathan", "Yifan Shi"], "abstract": "Growing scale of recommender systems require extensive tuning to respond to market dynamics and system changes. Tunable system parameters are often continuous, influence ranking, and consequently key performance indicators (KPIs) such as revenue per thousand impressions (RPM), clicks, and impression yield (IY). The exploding dimensions of tunable parameters coupled with scale of the system impose significant computational challenges.\nOpen-box simulators [1] have been successful in parameter tuning in complex systems [1]. By replaying user sessions along with simulated user behaviors in those sessions, the open-box simulators provide faithful estimates for KPIs under counterfactual parameters. Let A be the parameter space, and f be a KPI (e.g., as estimated by a simulator). For parameter a \u2208 A, The objective is to find \u00e2 such that\n f(a) \u2248 maxa Af (a)\nThis baseline approach using simulator and finds \u00e2 by enumerating all a \u2208 A (discretizing A if the parameters are continuous). For a complex system like for ads recommendation, f can be very expensive to evaluate. Given N as number of sessions to be replayed (in order of Millions in case of large-scale systems), s be the cost of replaying each session, and A be the number of candidate parameters to be evaluated, the cost is O(ANs). Stochastic sampling can be used to reduce effective N, but when there are plenty of continuous parameters to tune, A can be prohibitively large.\nImportance sampling (IS) is another popular approach which offers a cheap surrogate to evaluate many counterfactual parameters efficiently [2, 4]. The idea is to randomize the parameters chosen for a subset of traffic, so as to capture the effects of changing the parameters. Let ao be an initial parameter, and q be a distribution imposed to randomize around ao (e.g. Gaussian), i.e. a ~ q(a|ao). Importance sampling returns an unbiased surrogate f(a') = \u2211if(ai | xi) q(ai|ao) for a' \u201cclose to\u201d ao [2, 5]. Fig 2 shows empirically that in our application the IS estimates f correlate well with true f evaluations. IS can therefore be used to maximize\n \u00e2 = maxa' \u2208 {ao+8} f(a'),\nwhere {ao + 8} denotes the effective coverage of parameter values through importance sampling (the effective neighborhood \u03b4 depends on N, randomization q, variability of f across xi, etc.). This suggests another practical baseline approach for our original problem: Initialize ao and iteratively improve it using ai+1 = argmaxa'\u2208 {ai+8}f(a'). We can evaluate the iterates found by IS using the true f to detect progress. For T iterations, the cost of this approach is O(T * (s + NAs)). Since As (the effective number of parameters searched in each iteration) can be much smaller than A, and re-weighting samples can be much faster than O(s), this approach is typically computationally efficient compared to enumerating all a \u2208 A, however it is sensitive to the choice of ap.\nWe propose Simulator-Guided Importance Sampling (SGIS), which leverages strengths of both simulations and IS. Other approaches (e.g. doubly robust estimators [3]) that combine simulations and IS are motivated by a bias-variance trade-off (offsetting the potential bias of simulator using an unbiased IS alternative); whereas we are motivated to combine two unbiased estimators of KPIs to achieve a computation trade-off. Using real-world A/B tests, we show that SGIS driven parameter tuning perform significantly better than open-box simulator, while keeping lower computation cost.", "sections": [{"title": "1 INTRODUCTION", "content": "Growing scale of recommender systems require extensive tuning to respond to market dynamics and system changes. Tunable system parameters are often continuous, influence ranking, and consequently key performance indicators (KPIs) such as revenue per thousand impressions (RPM), clicks, and impression yield (IY). The exploding dimensions of tunable parameters coupled with scale of the system impose significant computational challenges.\nOpen-box simulators [1] have been successful in parameter tuning in complex systems [1]. By replaying user sessions along with simulated user behaviors in those sessions, the open-box simulators provide faithful estimates for KPIs under counterfactual parameters. Let A be the parameter space, and f be a KPI (e.g., as estimated by a simulator). For parameter a \u2208 A, The objective is to find \u00e2 such that\n\\(f(a) \u2248 \\max_{a \\in A} f(a)\\)\nThis baseline approach using simulator and finds \u00e2 by enumerating all a \u2208 A (discretizing A if the parameters are continuous). For a complex system like for ads recommendation, f can be very expensive to evaluate. Given N as number of sessions to be replayed (in order of Millions in case of large-scale systems), s be the cost of replaying each session, and A be the number of candidate parameters to be evaluated, the cost is O(ANs). Stochastic sampling can be used to reduce effective N, but when there are plenty of continuous parameters to tune, A can be prohibitively large.\nImportance sampling (IS) is another popular approach which offers a cheap surrogate to evaluate many counterfactual parameters efficiently [2, 4]. The idea is to randomize the parameters chosen for a subset of traffic, so as to capture the effects of changing the parameters.\u00b9 Let ao be an initial parameter, and q be a distribution imposed to randomize around ao (e.g. Gaussian), i.e. a ~ q(a|ao). Importance sampling returns an unbiased surrogate \\(f(a') = \\sum_i f(a_i | x_i) \\frac{q(a_i|ao)}{q(a_i|a')}\\) for a' \u201cclose to\u201d ao [2, 5]. Fig 2 shows empirically that in our application the IS estimates f correlate well with true f evaluations. IS can therefore be used to maximize\n\\(\u00e2 = \\max_{a' \\in {a_o+\u03b4}} f(a'),\\)\nwhere {ao + 8} denotes the effective coverage of parameter values through importance sampling (the effective neighborhood \u03b4 depends on N, randomization q, variability of f across xi, etc.). This suggests another practical baseline approach for our original problem: Initialize ao and iteratively improve it using ai+1 = argmaxa'\u2208 {a:+8}f(a'). We can evaluate the iterates found by IS using the true f to detect progress. For T iterations, the cost of this approach is O(T * (s + NAs)). Since As (the effective number of parameters searched in each iteration) can be much smaller than A, and re-weighting samples can be much faster than O(s), this approach is typically computationally efficient compared to enumerating all a \u2208 A, however it is sensitive to the choice of ap.\nWe propose Simulator-Guided Importance Sampling (SGIS), which leverages strengths of both simulations and IS. Other approaches (e.g. doubly robust estimators [3]) that combine simulations and IS are motivated by a bias-variance trade-off (offsetting the potential bias of simulator using an unbiased IS alternative); whereas we are motivated to combine two unbiased estimators of KPIs to achieve a computation trade-off. Using real-world A/B tests, we show that SGIS driven parameter tuning perform significantly better than open-box simulator, while keeping lower computation cost."}, {"title": "2 METHOD", "content": "Considering m continuous parameters to tune, a parameter setting is a vector in the subspace of Rm. As this space can be very large, we first generate a grid on every component of the vector to do a coarse search. Let C be a coarse grid after partitioning all the parameters.\nWe use simulator to get KPIs for each grid point using eq. 1. Details about simulator is mentioned in Appendix A.1. We rank parameter settings using an objective function L : Rm \u2192 R with score r (Appendix B.1). For each of the top k settings ranked by L, simulator generated artificial user sessions are used to perform importance sampling according to eq. 2 (Appendix A.1.1, A.2)."}, {"title": "3 EXPERIMENTS AND RESULTS", "content": "For a real-world ad recommendation system, we consider m = 3, c = 15, d = 25, k = 5. Assuming parameters following Gaussian distribution to collect randomized data for SGIS search, the grid for IS search is specified in terms of the sigma multiplier of each parameter. We select 25 equal distance values from [-1 * \u03c3, 1 * \u03c3]. SGIS search is done through a capped-weighted importance sampling estimator (Appendix A.2)) [4]. For this experiment, we keep iterations for SGIS search to be m = 1. If cost of coarse search is too high, more iterations can be used to reach to an optimal point. (Appendix B.2)\nFig 2 shows SGIS predicted AIY on x-axis and open-box simulator predicted AIY on y-axis on randomly sampled settings from first iteration. With the high correlation between the two estimators, we note that the SGIS estimator can plausibly rank parameters similar to if we had evaluated all settings with the simulator (Eq. 1). This observation motivates our Algorithm 1. We consider open-box simulations performed for parameter settings with coarse grid in Algo 1 step 4 as baseline."}, {"title": "4 CONCLUSION", "content": "We propose an off-policy evaluator SGIS that uses expensive simulator to guide a cheap IS search; and show using simulations and real world A/B tests that our evaluator lowers the computation cost for off-policy optimization while maintaining performance."}, {"title": "A OFF-POLICY ESTIMATORS", "content": "Open-box monte-carlo simulators replaying user sessions are widely used for parameter tuning in complex systems. [1]. They use historical user sessions and replay them by running the exact binary that online system runs. Machine learning models are then used to estimate user response signals.\nAs shown in Fig 3, given a recommender system laid out as a causal graph that can be replayed by a simulator, combined with a user response model, can be used to evaluate different parameter settings and capture their effect on various KPIs. As open-box simulations depict the true underlying data generating processes, they provide faithful counterfactual estimates that hold in A/B experiments."}, {"title": "A.1 Open-box Simulator", "content": "Let X = [x1,...,xM] be historical user sessions. We first learn a model M from X to predict user responses for the simulations. For each policy a \u2208 A, each user session x is replayed to generate a counterfactual session \u00ee, which in conjunction with the model M is used to calculate KPIs. Let p be a vector containing each KPI, it is aggregated all sessions to produce score vector for each policy. This score vector can be used to perform multi-objective constrained optimization."}, {"title": "A.1.1 Artificial User Sessions", "content": "Step 5 in the algorithm generating a counterfactual user session \u00ee can be collected for all historical logs in X for a parameter setting a. Considering a has been randomized to capture small region 8, these simulated sessions can be used to perform importance sampling to cheaply evaluate lots of parameter settings."}, {"title": "A.2 Importance Sampling", "content": "Observational approaches like importance sampling is used for iterative tuning of large-scale recommender systems. The portion of traffic is randomized to capture the effect of changing parameters. A popular choice for randomization is imposing a Gaussian distribution [4]. The randomization is controlled with the variance of the proposal distribution q, importance sampling is used to evaluate the effect of changing proposal to a candidate distribution a. Let x be a user session and f be a KPI function, the effect of candidate distribution can be captured in the following way.\n\\(E_a[f(x)] = E_q[f(X) \\frac{a(x)}{q(x)}] = \\frac{\\sum_{i=1}^N f(x_i) \\frac{a(x_i)}{q(x_i)}}{\\sum_{i=1}^N \\frac{a(x_i)}{q(x_i)}}\\)\nAs randomization cost can become significant if it is imposed to real traffic, adaptive importance sampling is used in practice to iteratively come up with a better policies to reach an optimal point. This approach is not restricted to be used only for real observational data. If we have an accurate simulator representing true underlying processes, we can use it to generate such randomized data, and such iterative importance sampling can be done with no real randomization cost.\nWe use data collected by simulator for a setting a as explained in A.1.1 to perform importance sampling."}, {"title": "B HYPERPARAMETER CONSIDERATIONS", "content": "Algorithms for Simulator (2) and importance sampling (3) output a vector pa containing estimated KPIs like RPM, Clicks, IY for each a. This can be used to construct a multi-objective optimization. Let"}, {"title": "B.1 Top-k Optimization", "content": "L:p\u2192r be an arbitrary objective function to rank all p, we can use hyperparameter k to select top-k parameter settings.\nKPIs considered for L influence choice of hyperparameters in algorithm 1. In our experiments, IY shows high correlation with simulations as shown in Fig 2. If L is constructed only with KPIs that are highly correlated with simualtions, choosing k = 1 for each iteration works well. However, KPIs including user-response model predictions like RPM or clicks can have lower correlation. In such cases, one option is to choose higher k that allows more candidates to be evaluated with simulator at each iteration. Another option is to collect large number of artificial user sessions to reduce variance of importance sampling."}, {"title": "B.2 Number Of Iterations for IS Search", "content": "The number of iterations for importance sampling search u is used to tread-off compute cost of simulator and importance sampling estimator. If coarse grid is sparse due to large parameter space (many continuous parameters) or high cost of simulator, we would benefit with big u to reach to an optimal point. We can also use early stopping if changes in parameter values or KPI gains are less than some e with each iteration.\nChoice of u also depends on randomization applied while collecting simulated user sessions. As there is no online cost for random-izing simulated user sessions, large randomization can be applied to reduce the number of iterations u. Further study is required on the impact of large randomization applied to collect simulated user sessions on IS search."}]}