{"title": "Encrypted Large Model Inference: The Equivariant Encryption Paradigm", "authors": ["James Buban", "Hongyang Zhang", "Claudio Angione", "Harry Yang", "Ahmad Farhan", "Seyfal Sultanov", "Michael Du", "Xuran Ma", "Zihao Wang", "Yue Zhao", "Arria Owlia", "Fielding Johnston", "Patrick Colangelo"], "abstract": "Artificial Intelligence (AI), particularly machine learning (ML), has grown significantly in recent decades [1]. Since the introduction of large language models (LLMs) such as ChatGPT [2], Claude [3], Gemini [4], and LLaMA [5], as well as diffusion models [6] like DALLE-3 [7] and Sora [8], these foundation models have attracted significant interest [9]. They exhibit advanced capabilities such as in-context learning [10] and chain-of-thought reasoning [11], yet privacy challenges arise when these models are deployed across distributed or decentralized infrastructures [12].\n\nIn many scenarios especially in healthcare [13], finance, or other regulated domains [14]-data privacy is a central requirement. Users often need to ensure that sensitive data (e.g., medical images, personal identifiers, or transaction records) are not visible to untrusted nodes in a distributed inference pipeline. Existing methods like secure multiparty computation (SMPC) [15], homomorphic encryption (HE) [16], and differential privacy (DP) [17] can help, but each involves trade-offs in communication overhead, computational latency, or accuracy.\n\nTo address these limitations, we propose Equivariant Encryption (EE), a technique that enables large-scale model inference on encrypted data while maintaining near-zero performance overhead. By transforming internal representations so that the model can operate on ciphertext as if it were plaintext, EE eliminates the high computational costs typically associated with fully homomorphic approaches. In this work, we:\n\n\u2022 Review background approaches like SMPC, HE, and DP, emphasizing their strengths and shortcomings for large-model inference (\u00a72.1-\u00a72.3).\n\n\u2022 Introduce Equivariant Encryption (\u00a72.4) as a new framework for preserving data confidentiality throughout neural network pipelines.\n\n\u2022 Demonstrate a decentralized infrastructure example where EE can protect queries and outputs from untrusted nodes (\u00a72.5).", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI), particularly machine learning (ML), has grown significantly in recent decades [1]. Since the introduction of large language models (LLMs) such as ChatGPT [2], Claude [3], Gemini [4], and LLaMA [5], as well as diffusion models [6] like DALLE-3 [7] and Sora [8], these foundation models have attracted significant interest [9]. They exhibit advanced capabilities such as in-context learning [10] and chain-of-thought reasoning [11], yet privacy challenges arise when these models are deployed across distributed or decentralized infrastructures [12].\n\nIn many scenarios especially in healthcare [13], finance, or other regulated domains [14]-data privacy is a central requirement. Users often need to ensure that sensitive data (e.g., medical images, personal identifiers, or transaction records) are not visible to untrusted nodes in a distributed inference pipeline. Existing methods like secure multiparty computation (SMPC) [15], homomorphic encryption (HE) [16], and differential privacy (DP) [17] can help, but each involves trade-offs in communication overhead, computational latency, or accuracy.\n\nTo address these limitations, we propose Equivariant Encryption (EE), a technique that enables large-scale model inference on encrypted data while maintaining near-zero performance overhead. By transforming internal representations so that the model can operate on ciphertext as if it were plaintext, EE eliminates the high computational costs typically associated with fully homomorphic approaches. In this work, we:\n\n\u2022 Review background approaches like SMPC, HE, and DP, emphasizing their strengths and shortcomings for large-model inference (\u00a72.1-\u00a72.3).\n\n\u2022 Introduce Equivariant Encryption (\u00a72.4) as a new framework for preserving data confidentiality throughout neural network pipelines.\n\n\u2022 Demonstrate a decentralized infrastructure example where EE can protect queries and outputs from untrusted nodes (\u00a72.5)."}, {"title": "Equivariant Encryption: A Middle Ground for Secure Model Inference", "content": "Before detailing our new method, Equivariant Encryption (EE), we will briefly recap three key tools in privacy-preserving data processing\u2014differential privacy (DP) (\u00a72.1), secure multi-party computation (SMPC) (\u00a72.2), and homomorphic encryption (HE) (\u00a72.3). DP manages privacy at the dataset level by adding noise, thereby limiting how much an attacker can deduce about any single record, yet does not encrypt intermediate states during inference. SMPC splits data and computation across multiple participants, reducing exposure but often demanding complex protocols. HE allows computations on encrypted data at all times, though it can impose substantial overhead and may struggle with non-linear network layers. Our Equivariant Encryption (\u00a72.4) seeks a balanced approach: rather than fully encrypting every component or depending solely on noise or multi-party flows, EE selectively obfuscates crucial internal representations within LLMs and more, retaining strong confidentiality while minimizing performance cost."}, {"title": "Background: Differential Privacy (DP)", "content": "Differential Privacy (DP) is a statistical framework designed to protect individual data records in a dataset, while still allowing meaningful aggregate computations or analyses. Formally, let D and D' be two neighboring datasets differing by a single record. A randomized algorithm M is said to satisfy (\u03b5, \u03b4)-DP [18] if, for any measurable set S,\n\nPr[M(D) \u2208 S] < e^\u03b5 Pr[M(D') \u2208 S] + \u03b4.\n\nIntuitively, altering one individual's record does not significantly change the distribution of the algorithm's outputs, thus limiting privacy risks for each participant.\n\nClassical Mechanisms. Several mechanisms can ensure DP under different assumptions:\n\n\u2022 Laplace Mechanism: Injects noise drawn from a Laplace distribution whose scale depends on the function's sensitivity, thereby hiding individual contributions.\n\n\u2022 Gaussian Mechanism: Uses Gaussian noise to achieve (\u03b5, \u03b4)-DP in settings where high-dimensional outputs are required.\n\n\u2022 Exponential Mechanism: Chooses outputs with probabilities proportional to a utility function, balancing usefulness with DP constraints."}, {"title": "Background: Secure Multi-Party Computation (SMPC)", "content": "Secure Multi-Party Computation (SMPC) is a cryptographic approach that enables multiple parties, each holding private inputs, to compute a joint function without revealing these inputs to one another. Formally, suppose there are n parties {P1, P2,..., Pn} with private inputs X1,X2,...,xn, and they wish to compute a deterministic function\n\nf(x1, x2,...,xn) = Y,\n\nwhere y is the output revealed to some or all of the parties, but each xi remains hidden.\n\nClassical Constructions. SMPC can be realized through various protocols, each with different security assumptions and performance characteristics:\n\n\u2022 Yao's Garbled Circuits: Originating with Yao [20], this approach encrypts a Boolean circuit such that each party learns nothing beyond its own inputs and the final output.\n\n\u2022 Secret-Sharing Protocols (BGW): Introduced by Ben-Or, Goldwasser, and Wigderson (BGW) [21], each input is split into multiple shares distributed among parties. Intermediate computations proceed on these shares, ensuring no single share reveals the original input.\n\nA hallmark of such constructions is that all parties learn the correct final result y, while intermediate values remain masked."}, {"title": "Background: Homomorphic Encryption (HE)", "content": "Homomorphic Encryption (HE) is a cryptographic framework that keeps data encrypted while still allowing meaningful computations on it. This capability supports many secure outsourcing and cloud computation scenarios [16, 25], though practical applications often face significant performance challenges. Understanding the basics of HE clarifies why EE focuses on a more targeted approach for neural networks."}, {"title": "Equivariant Encryption: A Practical Solution for Blind Inference", "content": "Equivariant Encryption (EE) is presented here as a selective encryption technique for neural network inference, avoiding the high overhead of fully HE and circumventing the limitations of trusted execution environments (TEEs) or DP. EE keeps inputs and outputs confidential while preserving near-zero additional latency, making it suitable for large-scale models or time-critical applications.\n\nKey Characteristics and Advantages. EE has the following advantages:\n\n\u2022 Complete Server Blindness: In an EE-based pipeline, raw data, queries, and intermediate activations never appear in plaintext on the server.\n\n\u2022 Negligible Latency: EE sidesteps the typical performance pitfalls of full HE, allowing inference speeds comparable to standard unencrypted processing.\n\n\u2022 Broad Model Applicability: From CNNs to LLMs with attention blocks, EE can accommodate a variety of deep-learning architectures, including multimodal pipelines.\n\n\u2022 Cost-Effectiveness: By eliminating the need for specialized hardware (as in TEEs) or complex parameter setups (as in HE), EE can lower operating expenses for on-prem or cloud-based deployments.\n\n\u2022 RAG and Beyond: Retrieval-augmented generation workflows remain encrypted end to end, preserving both queries and retrieved documents from external inspection.\n\n\u2022 Simple Integration: EE typically requires minimal changes in code, such as replacing specific layer operations with \"encrypted\" equivalents.\n\nMotivation: \u201cBlind AI\u201d Without Performance Penalties. Safeguarding privacy during inference poses significant challenges, particularly for large-scale models and real-time systems. Existing methods have notable drawbacks:\n\n\u2022 HE: Encrypts all operations but struggles with non-linear layers and can incur large runtime expansions.\n\n\u2022 TEEs: Rely on hardware trust, granting potential backdoor privileges to system administrators."}, {"title": "Use Case: A Decentralized Infrastructure Example of EE", "content": "Although EE applies broadly to any scenario requiring private model inference, this section presents a concrete decentralized infrastructure example, inspired by frameworks that split model execution among multiple nodes or shards. Figure 2 illustrates a setting where:\n\n\u2022 A query enters the system through a decentralized application (dApp) [31] and a wallet mechanism.\n\n\u2022 The query, along with relevant state, is dispatched across a blockchain-like infrastructure, performing a distributed hash table (DHT) lookup for transactions.\n\n\u2022 A message-broker subsystem manages job routing to multiple nodes, each responsible for processing a portion (shard) of a large model [32].\n\n\u2022 Activations and partial outputs flow through gRPC-based links, and final results are stitched together for the user.\n\nSuch distributed systems are attractive for scalability and fault-tolerance but can raise privacy questions: intermediate activations, user queries, or model outputs may be visible to untrusted parties at each node. Equivariant Encryption addresses this challenge by encrypting the internal representations, ensuring that no node except the original client can interpret the raw data or glean sensitive information. As described in \u00a72.4, EE focuses on carefully chosen transformations that maintain the correctness of computations while preventing adversaries from reconstructing user inputs or outputs. In this sense, it complements existing decentralized methods by preserving high performance without sacrificing privacy."}, {"title": "Threat Analysis and Attack Models", "content": "Having introduced EE as a general technique for secure model inference, we now focus on potential attacks against such systems. This section formalizes how attackers"}, {"title": "Attack Vector Background", "content": "We focus on the scenario in which requests and responses are transmitted via HTTP in an equivariantly encrypted form. Specifically, the tokens that represent inputs and outputs for a large language model (LLM) are permuted or transformed according to an unknown mapping. Bad actors intercepting these encrypted token IDs gain access only to a transformed sequence; the legitimate user or trusted client alone knows the key(s) or mapping required to recover the original token IDs.\n\nFor concreteness, assume the attacker obtains input-output pairs over some duration. Each pair (Ii, Oi) is represented by sequences of token IDs that have been scrambled"}, {"title": "A Unified Analytical Framework", "content": "To systematically study potential attacks, we consider a mathematical optimization viewpoint. Consider a target LLM, such as a Llama-family model, which implements a function\n\nf: C\u2192C,\n\nmapping a token-sequence input in some dictionary V (where |V| may be up to 128K tokens) to a token-sequence output. Depending on the sampling mechanism, f can be deterministic (greedy decoding) or stochastic (temperature-based or top-k sampling).\n\nAn attacker observes n pairs of encrypted input-output sequences {(Ii, Oi)}=1, with each Ii, Oi \u2208 C after scrambling by EE. The adversary knows the vocabulary set V but not the specific permutation or mapping IP that recovers plaintext tokens. To mount an attack, the adversary tries to find a mapping P : V \u2192 V such that:\n\nP(O\u2081) \u2248 f(P(Ii)),\n\nand the decrypted sequences (P(Ii), P(O\u00bf)) form a semantically valid question-answer or prompt-response pair. Formally, one might frame this as:\n\nmin 1/n \u2211\u1d62\u208c\u2081\u207f L(P(Ii), P(Oi)) s.t. P(Oi) = f(P(Ii)) \u2200i,\n\nwhere L(\u00b7,\u00b7) is a loss function that captures how well the decrypted pairs match valid natural language usage and plausible model responses.\n\nChallenges. We witness the following challenges for solving Equation (3):\n\n\u2022 Loss Function Design: What semantic or linguistic constraints best reflect the adversary's prior knowledge? For instance, knowledge of frequency distribution (e.g., tokens like \"the,\" \"of,\" \"and\" occur frequently) or grammar structure might be integrated into L.\n\n\u2022 Discrete Optimization: Finding a permutation P that satisfies the above constraints is a high-dimensional combinatorial problem on the order of |V|!, which is intractable to solve exactly for large vocabularies."}, {"title": "Baseline Attacks", "content": "In practice, adversaries often resort to heuristic or partial methods for solving (3). Below, we outline several baseline approaches."}, {"title": "Designing a Loss Function", "content": "LLM-as-a-Judge. One concept is to leverage a powerful reference model (e.g., GPT-4 or another advanced LLM) to score how consistent a decrypted output P(O)"}, {"title": "Secret Sharing and Arithmetic Operations.", "content": "A common variant of secret sharing is additive sharing, where a secret x over a ring Zq is divided into n shares (X1,X2,...,xn) such that\n\nx= \u2211\u1d62\u208c\u2081\u207f Xi  (mod q).\n\nEach party receives one xi. Adding two secrets can be done locally on each party's shares, whereas multiplication often requires additional steps. The BGW model and later protocols such as SPDZ [22] use multiplication triplets and integrity checks to allow correct evaluation of products, even in the presence of malicious adversaries.\n\nSecurity Models. SMPC protocols typically consider:\n\n\u2022 Semi-Honest Adversaries: Parties follow the protocol correctly but try to infer extra information from received messages.\n\n\u2022 Malicious Adversaries: Parties can deviate arbitrarily to extract data or alter the outcome.\n\nSecurity proofs guarantee that any subset of corrupted parties learns nothing beyond the legitimate final output.\n\nPractical Considerations. While SMPC obviates the need for a fully trusted server, it often introduces higher computational and communication overhead than a single trusted third party [23]. Large-scale SMPC can involve frequent message exchanges, especially for complex operations like matrix multiplication in neural networks. Nonetheless, specialized circuit optimizations and precomputation (e.g., random-beaver triplets in SPDZ) have improved the practicality of SMPC for certain machine learning workloads [24].\n\nConnection to EE. Although SMPC conceals inputs from other parties, it does not necessarily hide internal computations from the machine performing those computations. By contrast, EE (see \u00a72.4) encrypts the internal representations used within neural network layers. In scenarios where partial computations are offloaded to untrusted infrastructure, SMPC ensures data are shared among multiple parties without revealing secrets, and EE obfuscates the intermediate states of the network. Combined, they form a multi-layered approach, with SMPC covering multi-party input privacy and EE preventing visibility into intermediate neural activations or parameters."}, {"title": "Motivation and Basic Setup.", "content": "Consider a user with private data m\u2208 M that must be processed by an untrusted server. Rather than sending m in plaintext, the user encrypts m to produce c = E(m), where\n\nE:M\u2192C.\n\nThe server then operates on c to yield some output \u010d. Crucially, the homomorphic property ensures:\n\nD(f'(C1, C2, ...)) = f (D(c1), D(c2),...),\n\nwhere D is the corresponding decryption function, f(\u00b7) is the desired plaintext operation, and f'(.) is its encrypted analog. This principle lets the server process encrypted data without learning m [26, 27].\n\nTypes of HE Schemes. HE systems are commonly categorized by how many operations on ciphertexts they support:\n\n\u2022 Partial HE (PHE): Permits repeated use of one operation\u2014addition or multiplication. For instance, RSA-based schemes support multiplicative homomorphism [26], whereas the Paillier cryptosystem supports additive homomorphism [27].\n\n\u2022 Somewhat or Leveled HE: Allows both addition and multiplication up to a certain depth, controlled by noise management. This depth determines how many multiplied ciphertexts can be handled before decryption becomes invalid.\n\n\u2022 Fully HE (FHE): Provides unlimited additions and multiplications, often through \"bootstrapping\" to periodically refresh ciphertexts and limit noise [16].\n\nRing-Based Construction and Polynomial Representation. Modern FHE schemes (e.g., BFV [28], CKKS [25]) typically use polynomial rings for computational efficiency. A cyclotomic polynomial ring\n\nN R = Zq[x]/(x^N + 1)\n\nserves as the plaintext space, with additional polynomials denoting ciphertexts. Security derives from adding controlled \"noise\" that grows with each operation. If not managed, excessive noise can invalidate decryption."}, {"title": "Deployment Scenarios.", "content": "LLMs and Conversational Systems: Token embeddings become encrypted embeddings so no plaintext tokens ever appear on the server.\n\nVision Models: Encrypted feature maps flow through convolution and activation layers with minimal overhead.\n\nRAG Pipelines: Queries and retrieved content remain enciphered, preventing servers from inspecting user context or knowledge sources."}]}