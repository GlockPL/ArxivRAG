{"title": "Improving the network traffic classification using the\nPacket Vision approach", "authors": ["Rodrigo Moreira", "Larissa Ferreira Rodrigues", "Pedro Frosi Rosat", "Fl\u00e1vio de Oliveira Silva"], "abstract": "Abstract\u2014 The network traffic classification allows improving\nthe management, and the network services offer taking into\naccount the kind of application. The future network architectures,\nmainly mobile networks, foresee intelligent mechanisms in their\narchitectural frameworks to deliver application-aware network\nrequirements. The potential of convolutional neural networks\ncapabilities, widely exploited in several contexts, can be used\nin network traffic classification. Thus, it is necessary to develop\nmethods based on the content of packets transforming it into\na suitable input for CNN technologies. Hence, we implemented\nand evaluated the Packet Vision, a method capable of building\nimages from packets raw-data, considering both header and\npayload. Our approach excels those found in state-of-the-art by\ndelivering security and privacy by transforming the raw-data\npacket into images. Therefore, we built a dataset with four traffic\nclasses evaluating the performance of three CNNs architectures:\nAlexNet, ResNet-18, and SqueezeNet. Experiments showcase the\nPacket Vision combined with CNNs applicability and suitability\nas a promising approach to deliver outstanding performance in\nclassifying network traffic.", "sections": [{"title": "I. INTRODUCTION", "content": "Classifying network traffic allows us to know the kind\nof application running on the network, benefiting the mod-\nels for forecasting, capacity utilization, quality of service,\nsecurity, and planning and management steps. Besides, in\nthe frameworks of new communication, network architectures\nrequire intelligent entities to support resources management\nand operation. Traffic classification mechanisms are known and\nwidely explored in the state-of-the-art, however, with the ad-\nvent of convolutional neural networks (CNNs), new methods of\ntraining, validation, and classification are available, especially\nthose based on images raising the opportunity to propose and\nevaluate mechanisms for network traffic classification [1] [2].\nAmong the known traffic classification mechanisms, we\ncan categorize them as port-based, payload-based, machine-\nlearning approaches based on statistics and deep learning\n3]. In particular, CNNs demonstrate capabilities beyond its\nfields of action with highly accurate mechanisms for clus-\ntering and classifying medical images [4], biomolecular [5],\nenvironmental [6], and others contexts [7]. The success of"}, {"title": "II. RELATED WORK", "content": "Lim et al. [2], proposed a traffic classification mechanism\naims to improve the quality of service for applications without\ninterference from the network operator. Its structure generates\na dataset containing images of flows analyzed over time inter-\nvals. The approach uses CNN and Long short-term memory\n(LSTM) to train and evaluate the classification performance\nusing the F1-score metric. The proposed architecture considers\nthree layers, the lowest containing data switches, including\nswitches and hosts that exchange data between their own, on\ntop of previous the control including classification mechanisms\nand traffic entities. The topmost layer allows the implementa-\ntion of specific network behaviors based on the type of traffic.\nThe image generation mechanism for the dataset comprises\ncapturing the flow: a set of packets with similar characteristics\n(source and destination host, port, and transport protocol) in\na specific time interval. Therefore, for each packet of a flow,\nextracts its payload and performs mathematical operation over\na set of bits to transform it into a single numerical value,\nconsequently a single pixel. Thus, a single figure, containing\nmany pixels, is the set of packet representing an application's\nflow. This approach does not carry out cross-validation and\ndisregard the entire package structure, requiring additional\ncomputation in the processing step that consists of extracting\nthe payload of each package.\nVasan et al. [12] proposed an architecture of CNN and\nevaluates the virtual threats as malware close classification\nreal-time. The construction of the dataset transforms the binary\nsignature of malware, which is an 8-bit vector into an 8-\nbit array, afterward in a grayscale figure and then applying\na 2-D color map. The classification performance evaluation\ntakes into account approaches with data augmentation and fine-tuning. Unlike the present proposal, this article proposes cross-\nvalidation to avoid bias and over model adjustment, besides\nthere is no need to transform the image of the 2-D color maps\ndataset, maintaining performance.\nChen et al. [13] presents an IP traffic classification frame-\nwork based on CNNs named Seq2Img. This approach consists\nof capturing the packets of a flow and extracting its charac-\nteristics and behaviors. A probability distribution model called\nReproducing Kernel Hilbert Space (RKHS) is mandatory to\nconstruct the figures for each traffic class, consisting of the\nnetwork protocols and popular social networking applications.\nAccuracy was the performance metric held in the validation\nof the traffic classification model. Unlike the present paper,\nthe authors did not validate the proposal with hold-out, and\nthe data collection mechanism depends on a third non-open\nsource application. On the other hand, our approach consists of\nan open-source collector and does not handle images as flows\nand does not require processing with complex mathematical\nmodels.\nWang et al. [1] proposed a framework for classifying\nmalicious traffic in domestic environments through home-\ngateway equipment containing an embedded traffic prediction\nmechanism. The mechanism based on CNNs is similar to ours\nbecause they take into account the figure from each package as\na data suitable for Machine learning models. However, differ-\nent from us in the pre-processing stage, the ethernet header of\nthe package is removed. Besides, to avoid bias and overfitting"}, {"title": "III. PACKET VISION", "content": "The resource sharing turn up in different ways in the litera-\nture. The architecture of the operating systems, especially those\nfor time-sharing processing, has been inspiring new formats of\nresource sharing, impacting computing resources, and network\nsharing. Sharing network resource relies on to assign part of\ngeneral-purpose hardware to a specific user while safeguarding\nessential aspects of isolation and guarantees. In the context of\nmobile networks, especially in the 5G standardization, sharing\ntook the form of network slicing, which provides logical\nnetworks with independent data and control plans for users\nto meet specific application requirements.\nTherefore, among the network slicing approaches rising\nthe Network and Slice Orchestrator (NASOR) [18] that im-\nplements the network slicing beyond the mobile network\necosystem, providing logical connectivity over the Internet data\nplane. The NASOR ecosystem includes interfaces that facilitate\nnetwork slice management, called the Open Policy Interface\n(OPI). The OPI interface allows third-party mechanisms to\nsupport network slicing and management. Consequently, we\npropose a component that performs this interface, offering\ntraffic classification to lead the NASOR path configuring agent,\ncalled Packet Vision.\nThe Packet Vision is a method, originated from the\ndrawing-packet action, capable of receiving a network packet\nin the raw format and transforming it into images considering\nboth the header and the payload. After generating images, it is\npossible to classify them according to the traffic class. Traffic\nclasses range across the network according to the overlying\napplication. This classification guides the network slicing agent\nas to the path that logical connectivity must take along Internet\nrouters. We present Packet Vision as a method of building a\ndataset of network traffic class images to train and evaluate\ndeep learning algorithms. Hence, Fig. 1 depicts Packet Vision\nas a method for creating Datasets.\nThe first step comprises collecting network packets carried\nover a network interface. The open-source application Wire-\nshark and its extension libraries allow collecting packet from a\nnetwork interface without affecting the application. The Packet\nVision handles packets traces from four sources, collected\nthrough the open-source tool Wireshark, containing pcap files\nfor each traffic class."}, {"title": "IV. CLASSIFICATION METHOD", "content": "In this study, the classification was performed using CNNs,\nwhich uses multi-layer neural networks to learn features and\nclassifiers in different layers, at running time, and does not\nrequire handcrafted feature extraction [23]. Three state-of-the-\nart CNN architectures were selected based on their past perfor-\nmance in image classification tasks: AlexNet [24], ResNet-18\n25], and SqueezeNet [26].\nAlexNet [24] was the champion of ImageNet Large Scale\nVisual Recognition Challenge (ILSVRC) 2012 and is responsi-\nble for the recent popularity of neural networks. This CNN has\nfive convolutional layers, three max-pooling layers, two fully\nconnected layers with a final softmax. It was a breakthrough\narchitecture since it was the first to employ non-saturating\nneurons and dropout connections to prevent overfitting.\nResNet, presented in [25], was the champion of ILSVRC\n2015 [27] and has several variations with 18 to 152 layers.\nThis network has a series of residual blocks, each composed\nof several stacked convolutional layers. This configuration\nallows accelerating the convergence of the deep layers without\noverfitting. In this study, we choose to work with the ResNet-\n18 for the sake of simplicity.\nSqueezeNet [26] has a compact architecture with approx-\nimately 50 times fewer parameters than AlexNet. This CNN\nreduces parameters through 1\u00d71 convolutions and eight fire\nmodules, which performs the functions of fully connected and\ndense layers."}, {"title": "V. RESULTS AND DISCUSSION", "content": "All experiments were performed on a machine with an Intel\ni5 3.00 GHz processor, 16 GB RAM, and a GPU NVIDIA\nGeForce GTX Titan Xp with 12 GB memory. The experiments\nwere programmed using Python (version 3.6) and PyTorch [30]\n(version 1.4) deep learning framework.\nWe trained the CNN architectures using Stochastic Gra-\ndient Descent (SGD) [31] optimizer, with a learning rate of\n0.001, the momentum of 0.9, batch size of 32, and 50 epochs\nfor both, training from scratch and fine-tuning. All images were\nresized to 224\u00d7224 pixels to adapt for the input of the CNNS\nevaluated. The training images had augmented through vertical\nand horizontal flips, rotating images around its center through\nrandomly chosen angles of between 0\u00b0 and 360\u00b0.\nOur experiments aim to answer the following questions:\n1)\nWhat is the highest classification performance among\nthree evaluated CNNs?\n2) Considering accuracy, training from scratch, and fine-\ntuning, what is the most suitable training method for\nthis dataset?\n3)\nIs the performance of pre-trained CNNs statistically\nequivalent?\nTo assess the impact of the training from scratch and fine-\ntuning, we analyze the classification performance of each CNN\narchitecture according to metrics of accuracy, precision, recall,\nand f1-score. Regarding the classification performance, the\nTables II and III presents the average 5-fold cross-validation\nfor each CNN considering training from scratch and fine-\ntuning, respectively. As shown, the best performance results\nare achieving with the training from scratch. Consequently, the\nbest result among the three has been obtaining by the AlexNet\narchitecture, especially the strategy which use from scratch\ntraining.\nAlthough the fine-tuning technique did not improve the\nperformance indices compared to training from scratch, this\napproach requires less time to train the unfrozen layers and\ncould be suitable in real scenarios (see Table IV). Thus, we\ncompared only the pre-trained CNNs in order to identify the\nbest model."}, {"title": "VI. CONCLUDING REMARKS", "content": "This paper presents the Packet Vision method for building\nand evaluating datasets representing traffic on communication\nnetworks through CNNs. This method allows representing the\nraw-data of network packets in images for training and clas-\nsification in a deep learning mechanism. The image creation\nmechanism considering the header and the payload advances\nthe state-of-the-art since its peers consider only the payload,\namong other approaches such as the semantic and statistical\nrepresentation of flows. Besides, our approach is suitable for\nclassifying traffic with similar characteristics implying in chal-\nlenging tasks, achieving excellent performances according to\nstate-of-the-art metrics, and its implementation in the network\nbeing direct by handling the packets as they are.\nCarried experiments showcase that SqueezeNet perfor-\nmance is at least equal or higher against AlexNet and ResNet-\n18 trained with fine-tuning, enabling us to answer questions\nabout the quality of CNNs performance. Besides, we point\nout training approaches suitability for this problem, including a\nstatistical test seeking possible performance equivalence. Also,\nunlike the approaches found in the state-of-the-art, the Packet\nVision shuffling step enhances the privacy claim upon packets,\navoiding fixed fields of the packets at the same pixel location,\navoids rebuilding the original packet from the image.\nWe believe that Packet Vision is a robust application for\nthe traffic network classification with a significant degree of"}]}