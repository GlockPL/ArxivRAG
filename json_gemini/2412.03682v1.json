{"title": "Designing DNNs for a trade-off between robustness and processing performance in embedded devices*", "authors": ["Jon Guti\u00e9rrez-Zaballa", "Koldo Basterretxea", "Javier Echanobe"], "abstract": "Machine learning-based embedded systems employed in safety-critical applications such as aerospace and autonomous driving need to be robust against perturbations produced by soft errors. Soft errors are an increasing concern in modern digital processors since smaller transistor geometries and lower voltages give electronic devices a higher sensitivity to background radiation. The resilience of deep neural network (DNN) models to perturbations in their parameters is determined, to a large extent, by the structure of the model itself, and also by the selected numerical representation and used arithmetic precision. When compression techniques such as model pruning and model quantization are applied to reduce memory footprint and computational complexity for deployment, both model structure and numerical representation are modified and thus, soft error robustness also changes. In this sense, although the choice of activation functions (AFs) in DNN models is frequently ignored, it conditions not only their accuracy and trainability, but also compressibility rates and numerical robustness. This paper investigates the suitability of using bounded AFs to improve model robustness against DNN parameter perturbations, assessing at the same time the impact of this choice on deployment in terms of model accuracy, compressibility, and computational burden. In particular, we analyze encoder-decoder fully convolutional models aimed at performing semantic segmentation tasks on hyperspectral images for scene understanding in autonomous driving. Deployment characterization is performed experimentally on an AMD-Xilinx's KV260 SoM.", "sections": [{"title": "I. INTRODUCTION", "content": "Deploying AI accelerators on the edge help to reduce issues related to security, reliability, and high response latencies by avoiding the communication of data from/to external, more powerful computing platforms. Moreover, by providing full execution autonomy to complex AI algorithms such as deep neural networks (DNNs), AI can be applied to tasks with strict communication, reliability, and real-time response requirements. Computer vision-based intelligent systems for autonomous driving systems (ADSs) and aerospace applications are two relevant examples with high economic impact. However, the success of DNNs in many applications very often comes at the cost of designing highly complex models with millions of parameters that require tens of giga floating-point operations (GFLOPS) per inference. Deploying such models on resource-constrained embedded AI processors inevitably requires applying certain compression techniques and addressing a trade-off between accuracy, hardware occupation, and inference speed.\nIn addition to the above, a major concern in the deployment of AI-based autonomous systems is the requirement of meeting strict safety and reliability standards, especially in the aerospace (ARP-4754) and automotive (ISO 26262) industries,\nOne of the main factors that jeopardize the reliability of such systems is the exposure of electronic components to background radiation. This is particularly true for memory devices that rely on storing small amounts of charge and that also occupy large proportions of total silicon area. In the simplest case, the logical value stored in a cell may be perturbed, resulting in a single event upset (SEU) or a single bit upset (SBU) if just a single bit is altered. Field programmable gate arrays (FPGAs), which are increasingly being used in these fields, are particularly sensitive to SBUs, since both the configuration memory (LUTs) and the sequential elements of the deployed circuit (flip-flops or Block RAMs) can be affected. Without sufficient protection against soft errors, the mean time between failures could be seconds.\nMost published papers on the field have focused on image classification tasks, with little attention to semantic segmentation models. The most widely used approach to assess DNN robustness is through simulated software fault injection (FI) campaigns, while only a few authors report a theoretical analysis based on vulnerability models [1]. One of the most exhaustive analyses of the vulnerability of 32-bit floating-point convolutional neural networks for image classification is described in [2]. The key findings are that most of errors come from drastic spikes in parameter values, with positive ones being more threatening, and that dropout and batch normalization layers are ineffective in preventing error propagation. It is also worth mentioning the work presented in [3], in which two software tools for exhaustive FI in both TensorFlowl and TensorFlow2 [4] frameworks are explained.\nRegarding methods to harden DNNs against soft errors, the main approaches include redundancy, parameter modification,"}, {"title": "II. MODELS' DEVELOPMENT", "content": "The reference segmentation model in this study is a U-Net, an encoder-decoder fully convolutional network for image segmentation tasks. This DNN has been adapted to use hyperspectral images (HSI) from HSI-Drive v2.0 [7], a dataset intended for developing ADS systems using HSI. The most recent version, described in [8], is based on a 5-level encoder-decoder architecture containing two sequences of 3x3 conv2D layers (initially with 32 filters) followed by Batch Normalization and Rectified Linear Unit (ReLU) AFs at each level. Additionally, it includes one 2x2 Max-pooling 2D layer per encoder level and one 2x2 conv2Dtr layer per decoder level. The resulting model features 31.14 million parameters and requires 34.60 GFLOPS per inference to execute.\nSince the lack of bounds in most widely used AFs for DNN implementation (e.g. ReLU) facilitates the propagation of soft errors, in this article we also explore the use of squashing AFs, such as Sigmoid and Hard Sigmoid, being the latter a more basic, computationally efficient version of the former [9]. The objective is to analyze their potential benefits on model robustness, while also assessing their impact on performance and implementability. The DNNs have been designed with TensorFlow2 and trained on a Dell Precision 7920 Workstation equipped with an NVIDIA RTX 3090 GPU."}, {"title": "A. Reference model's performance", "content": "First, the three AFs are evaluated based on their performance in training and testing using the reference noncompressed model. The Sigmoid-based and Hard Sigmoid-based models required 1000 epochs, while the ReLU-based DNN, which allows for faster convergence, was trained for only 200 epochs. Table I shows the best Intersection Over Union (IoU) results of the 32-bit floating-point DNNs on the test set according to the used AF.\nThe best metrics are obtained for the ReLU model, although in all three cases, the Global IoU (GIoU) is above 92%. The Weighted IoU (WIoU), which is calculated by weighting each class by the inverse of its frequency in the dataset, is above 82%. These results are considered satisfactory given the highly unbalanced nature of the dataset [7]."}, {"title": "B. Model pruning", "content": "For this model to be implemented on an edge device, it is necessary to apply certain compression techniques such as pruning and quantization. Channel pruning aims to reduce both the number of parameters and the number of FLOPS by removing channels that have minimal impact on the output. This is achieved through a model sensitivity analysis which consists of gradually pruning (in increments of 0.1 in our case) each of the parameters, while the rest of the model remains frozen, to estimate which layers are the least essential ones. After choosing an overall pruning ratio in terms of FLOPS, each of the layers is pruned accordingly, and then the DNN is fine-tuned for a certain number of epochs (60 for ReLU and 200 for the other two AFs) to recover any lost accuracy.\nThis process is repeated twice for each model in what is known as iterative pruning, thus requiring the whole process to be repeated on the pruned model after the first iteration. To consider pruning as valid, a maximum degradation of 1.5 points in both GIoU and WIoU has been accepted, ensuring both remain above 90% and 80%, respectively.\nThe overall pruning ratios have been: 0.75 (0.5 and 0.5) for the ReLU-based model, 0.52 (0.4 and 0.2) for the Sigmoid-based model, and 0.7 (0.5 and 0.4) for the Hard Sigmoid-based model."}, {"title": "C. Quantization", "content": "Quantization is another compression technique aimed at reducing the size of the parameters to store and accelerating model inference when deployed on customized hardware. In this article, we apply a homogeneous post-training quantization scheme where all parameters and activations are converted to 8-bit integers. For further details on the quantization pro-cess, the reader is referred to [10]. It is worth noting that after quantization, the Sigmoid-based model has experienced a noticeable degradation. To recover the lost accuracy, a process called fast finetuning has been carried out."}, {"title": "III. ANALYSIS OF ROBUSTNESS AGAINST SBUS", "content": "To test the models' robustness against SBUs, an extensive FI campaign was conducted on the aforementioned models, which involved injecting single bit-flips into the parameters of the DNNs. Perturbations were inserted using our modified version of the original TensorFI2 framework [4], and the code is shared at https://github.com/jonGuti13/TensorFI2. To ensure the statistical significance, which is very important as stated in [11], of the performed FI campaign 1550 different soft errors per parameter set (a 2.5% error margin, a 95% confidence level, and a 50% failure probability to maximize sample size [12]) have been injected. To evaluate the impact of the FI campaign, it is first necessary to define what an inference error is. A bit-flip is considered to have caused an error if the predicted class at any pixel in the test images changes with regard to the prediction made by the unperturbed original model, i.e., critical errors. The error rate is therefore presented as a percentage between 0 and 100, with 100 representing the situation where a bit-flip has changed the predicted class of every single pixel."}, {"title": "A. Original noncompressed models", "content": "Fig. 2 displays the error rate for each parameter set and flipped bit for the ReLU-based 32-bit floating-point DNN (for an in-depth analysis of this model the reader is referred to [8]).\nFirstly, errors primarily occur as a consequence of the increment of the perturbed parameters' values. Secondly, the most sensitive bit is the MSB bit of the exponent as it is originally a '0' in most of the DNNs parameters (the ones in $0 \\le |x| < 2$ range). In fact, if the original parameter value is 1 or is in $1 < |x| < 2$ range, a bit-flip converts the parameter into a $\\pm\\infty$ or a NaN, respectively. Thirdly, the most sensitive parameter is the gamma set of Batch Normalization layers as it usually has a value near 1. Finally, leaving aside the MSB, the most sensitive zones are the initial layers of the encoder and the final layers of the decoder, which are both directly connected to the output as a consequence of the skip-connections typical of encoder-decoder architectures."}, {"title": "B. Pruned models", "content": "In this subsection it is analyzed to what extent the vulnerability of the DNNs against SBUs changes as a consequence of the pruning process described in Section II-B. From the comparison between Fig. 3 and Fig. 5 it can be concluded that the error rate has augmented after the DNNs have been pruned. However, the three models have not experienced an equal loss of robustness. The more over-parameterized a model is, the greater the likelihood that a bit-flip will occur on a less critical parameter, thus not impacting the predicted classes. Indeed, the two most pruned models (ReLU and Hard Sigmoid) have shown the most degradation, while the Sigmoid-based DNN now exhibits the highest robustness, surpassing the Hard-Sigmoid in terms of mean bit-flip error rate (as indicated by the black bar in Fig. 5). Nevertheless, albeit marginally, the Hard-Sigmoid demonstrates a lower standard deviation, suggesting less variability in the bit-flip error rate across different positions."}, {"title": "C. Pruned quantized models", "content": "Finally, the combined effects of applying pruning and full integer quantization are assessed. Since this is a general analysis based on simulations, we used TensorFlow Lite's quantization scheme [13] to evaluate robustness against SBUs. According to [13], the quantized version r of a real number r is approximated by (1), where S is a positive real scale factor, q is an 8/32-bit integer value, and Z is the zero-point, an integer value which is 0 for symmetric quantization.\n$r \\approx \\hat{r} = S(q - Z)$\nThus, the value $q_y$ resulting from $Y = Wx + b$ is:\n$q_y = \\frac{S_wS_x}{S_y}(q_wq_x - Z_x q_w + q_b)$"}, {"title": "IV. DEPLOYMENT AND PERFORMANCE CHARACTERIZATION", "content": "The DNNs were implemented on an AMD-Xilinx K26 SoM,. The DNNs have been deployed using AMD-Xilinx's Vitis AI 3.5 environment on a single-core B4096 Deep Processing Unit (DPU). To characterize the performance of the models, the IoU on the test images, the throughput and the power consumption during DPU inference were measured on the KV260 SoM running Petalinux operating system.\nThroughput measurements were conducted by averaging the inference execution of 100 iterations on the test images. The fact that the ReLU-based model was the most compressed after pruning, combined with the simplicity of calculating the AF, results in the highest throughput among the three, closely followed by the Hard Sigmoid-based model."}, {"title": "V. CONCLUSIONS", "content": "This article explores the use of bounded AFs in image segmentation DNNs to assess the robustness of these models against soft errors when deployed on embedded processing platforms for safety-critical applications. As a general conclusion, we found that it is a trade-off between the resilience enhancements that bounded squashing AFs provide and the need for more aggressive model compression to improve computational performance and reduce memory footprint.\nRegarding pruneability, ReLU-based and Hard Sigmoid-based models prove to have the larger pruneability factors, achieving a reduction in the number of parameters by over 95% and a reduction in the number of GFLOPS by over 70% in both cases. When it comes to robustness against single bit-flips, bounded AFs show the best resilience as the propagation of generated perturbations throughout the model layers is notably reduced. In 32-bit floating-point models, the most critical situation occurs when a bit-flip affects the MSB of the exponent for values in the range $1 < |x| < 2$, resulting in a conversion to NaN. This primarily affects the Gamma parameters in Batch Normalization layers. The over-parameterized nature of the original DNNs imply that as a model is pruned deeper, it seems to lose robustness. However, the relative difference between ReLU-based and Hard Sigmoid-based models, both with similar pruning ratios, remains constant. Nevertheless, the advisability of applying pruning techniques in relation to its influence over robustness must be contrasted with the particular design of the processor for deployment, since smaller models generally require fewer logic resources, decreasing the likelihood of an SBU occurring in a sensitive parameter. For pruned and quantized integer models, the inherent binary representation prevents the occurrence of NaNs or infinities, significantly reducing the error rate, while the relative robustness between different AFs show an identical pattern.\nIn terms of IoU, for DNNs implemented on an AMD-Xilinx KV260 SoM, the ReLU-based model achieved the best results. This, combined with the computational complexity and high latencies of computing Sigmoid AF, makes the ReLU-based DNN the most efficient in terms of throughput and power consumption. However, using Hard-Sigmoids as nodal AF deserves to be considered as a suitable design option for a good trade-off between robustness and performance."}]}