{"title": "CBM: Curriculum by Masking", "authors": ["Andrei Jarc\u0103", "Florinel-Alin Croitoru", "Radu Tudor Ionescu"], "abstract": "We propose Curriculum by Masking (CBM), a novel\nstate-of-the-art curriculum learning strategy that effectively creates\nan easy-to-hard training schedule via patch (token) masking, offer-\ning significant accuracy improvements over the conventional train-\ning regime and previous curriculum learning (CL) methods. CBM\nleverages gradient magnitudes to prioritize the masking of salient\nimage regions via a novel masking algorithm and a novel masking\nblock. Our approach enables controlling sample difficulty via the\npatch masking ratio, generating an effective easy-to-hard curricu-\nlum by gradually introducing harder samples as training progresses.\nCBM operates with two easily configurable parameters, i.e. the num-\nber of patches and the curriculum schedule, making it a versatile\ncurriculum learning approach for object recognition and detection.\nWe conduct experiments with various neural architectures, ranging\nfrom convolutional networks to vision transformers, on five bench-\nmark data sets (CIFAR-10, CIFAR-100, ImageNet, Food-101 and\nPASCAL VOC), to compare CBM with conventional as well as\ncurriculum-based training regimes. Our results reveal the superiority\nof our strategy compared with the state-of-the-art curriculum learn-\ning regimes. We also observe improvements in transfer learning con-\ntexts, where CBM surpasses previous work by considerable margins\nin terms of accuracy. We release our code for free non-commercial\nuse at https://github.com/CroitoruAlin/CBM.", "sections": [{"title": "1 Introduction", "content": "Humans learn by grasping the easier concepts before gradually mov-\ning to the more complex ones. Inspired by this observation, Bengio\net al. [3] proposed curriculum learning, a training regime that intro-\nduces a structured order of the data samples to train neural models\nfrom easy to hard. This method ensures that the examples are pre-\nsented to the model in a logical and meaningful sequence, allow-\ning the model to effectively learn and develop its knowledge base.\nThe method has been employed in multiple scenarios yielding signif-\nicant performance improvements [46]. Furthermore, over the course\nof time, various methods have been developed to integrate curricu-\nlum learning [3, 7, 10, 19, 25, 30, 36, 37, 39, 43, 44, 45]. While\nmany of these approaches involve different components of the train-\ning process, Soviany et al. [46] have classified them into four main\ncategories. The first category, known as data-level curriculum, in-\nvolves sorting the data samples based on certain difficulty criteria.\nThis approach aligns with the initial implementation of Bengio et\nal. [3]. The second category, referred to as model-level curriculum,\nincludes methods that gradually increase the capacity of the model\nas the training progresses. The third category, represented by task-\nlevel curriculum, aims to make the learning task more intricate over\ntime. Lastly, objective-level curriculum begins with a simplified ob-\njective, e.g. a convex objective, and transforms it during training until\nit becomes the final target objective, which is usually non-convex.\nThe data-level curriculum learning approaches involve sorting the\ntraining examples based on some difficulty metric [3, 23, 30, 38,\n45, 48, 54, 60], before proceeding with the actual learning process.\nHowever, this approach has a significant challenge associated with\nit, namely the need to use a custom difficulty metric for each do-\nmain. The choice of the difficulty metric may vary depending on the\nspecific learning task, and, in certain cases, it can be very hard to pro-\npose a useful difficulty metric [10]. Building on the success of self-\nsupervised approaches [22, 11] used to train deep learning models to\nreconstruct masked information (tokens), we propose a novel data-\nlevel curriculum learning approach, termed Curriculum by Masking\n(CBM), that artificially raises the difficulty level of each training im-\nage by masking a certain number of patches, where the number of\nmasked patches gradually increases during the training process, as il-\nlustrated in Figure 1. Hence, our approach does not require the prior\nsorting of data samples, as it enables full control over the complexity\nof a data sample via the masking ratio. However, we conjecture that\nrandomly masking patches does not necessarily induce an easy-to-\nhard curriculum. For example, if the masked patches happen to hide\nmost of the background in an image, leaving the foreground object\nthat needs to be recognized or detected visible, we will actually end\nup with an easier example instead of a more difficult one. To this end,\nwe propose to sample the masked patches from a probability distri-\nbution derived from image gradient magnitudes, essentially priori-\ntizing the masking of salient image patches. Since salient regions are\nmore likely to contain discriminative patterns, masking patches with\nlarger gradient magnitudes reduces the number of visible discrimina-\ntive patterns, thus increasing the difficulty of recognizing objects in\nimages.\nWe conduct experiments to determine the effectiveness of our ap-\nproach in object recognition and object detection. We apply CBM\non different types of convolutional and transformer neural net-\nworks, e.g. ResNet-18 [21], Wide-ResNet-50 [58], CvT-13 [55], and\nYOLOv5 [27]. Our empirical study is carried out on five data sets:\nCIFAR-10 [31], CIFAR-100 [31], ImageNet [42], Food-101 [4] and\nPASCAL VOC [14]. We compare our approach with four state-of-\nthe-art curriculum learning methods [10, 12, 44, 53], as well as two\nmore baseline training regimes. The first baseline is the vanilla train-\ning regime, while the second one employs the vanilla patch masking\ntechnique proposed by He et al. [22]. Lastly, we present ablation re-\nsults and a comprehensive comparison of masking ratio schedules,\nidentifying multiple successful configurations and parameter choices"}, {"title": "2 Related Work", "content": "Curriculum learning is a training technique introduced by Bengio\net al. [3], which provides the training examples in a meaningful\norder, from easy to hard, to neural networks. The objective is to\nenhance the performance of neural models, while also improving\nthe convergence speed of the training process. Since its introduc-\ntion, curriculum learning has proven its effectiveness in various do-\nmains, such as computer vision [3, 7, 10, 19, 25, 43, 44, 45], natural\nlanguage processing [3, 10, 30, 36, 39, 47], and signal processing\n[1, 10, 40]. The method has been very successful and has under-\ngone extensive development, as illustrated in some recent surveys\n[46, 52]. These developments range from strategies for measuring\ndata difficulty [3, 23, 30, 38, 43, 45, 48, 54, 60] to methods focusing\non other aspects of the training process [5, 10, 6, 28, 44]. A well-\nknown method to apply curriculum learning is by defining a metric\nthat evaluates the complexity of the data, and subsequently arrang-\ning the training examples from the simplest to the most challenging\nones based on the respective metric. Researchers have made signif-\nicant strides in finding improved metrics for various domains and\ntasks. For instance, images containing fewer and larger objects in\ncomputer vision are deemed easier than other images [43, 45]. In\nnatural language processing, word frequency [3, 36] and sequence\nlength [8, 30, 48, 60] are utilized to assess the sample difficulty. In\nsome cases, researchers have also integrated human feedback into\ntheir metric design [26, 38, 54].\nThe aforementioned curriculum strategies have proven to be ef-\nfective. However, they have been found to lack practicality due to\ntheir reliance on human expert input [26], which may not always\nbe available. Moreover, these methods remain fixed during train-\ning and may not adapt the curriculum to the changing needs of\nthe models. As a result, the research community developed new\ncurriculum-based approaches to overcome these limitations. For in-\nstance, Kumar et al. [32] introduced self-paced learning, a method\nthat measures the difficulty of the training samples based on the\nperformance of the trained model. Thus, the order of the training\nsamples changes according to the model feedback during training,\nand thanks to this property, several works adopted the approach\n[15, 18, 24, 32, 33, 41, 61]. Moreover, it is possible to implement\na combination of self-paced learning and classic curriculum learn-\ning approaches. This approach has been previously utilized under\nthe name of self-paced curriculum learning [24, 46]. Another popu-\nlar method is teacher-student curriculum learning [20, 56, 59], where\nthe teacher learns to supervise the student network via a curriculum.\nMethods that fall under the model-level curriculum learning\nparadigm [5, 10, 28, 44, 46] are closer to our work. In this setting, the\ncurriculum does not imply ordering the samples in ascending order of\ntheir difficulty. Instead, the curriculum is implemented by increasing\nthe model capacity as the training progresses, or by adjusting the task\nto become more accessible at the beginning of the training. Curricu-\nlum by Smoothing (CBS), a technique developed by Sinha et al. [44],\nblurs the activation maps resulting from convolutional layers during\nthe training process to let the model focus on the bigger picture. CBS\ngradually reduces the amount of blur as the model improves. This\napproach has been successful on various data sets and models. How-\never, it does require extra processing steps during training, which can\nmake the learning process last longer. The work of Burduja et al. [5]\nis an alternative to CBS, where the input images are blurred instead\nof the intermediary activation maps. Another example is Learning\nRate Curriculum (LeRaC) [10]. This method assigns different learn-\ning rates to the network layers based on their proximity to the input.\nLayers closer to the input have higher learning rates, while those far-\nther away have lower rates. Over time, the learning rates are adjusted\nto converge to a consistent value. Similar to [5, 10, 44], our approach\ndoes not require an external difficulty measure.\nDifferent from other curriculum learning approaches, we propose\nto induce a curriculum via a progressive masking of input patches.\nTo the best of our knowledge, we are the first to introduce a cur-\nriculum learning method based on patch masking. Furthermore, we\ngo beyond a naive implementation and apply the masking operation\nby taking into consideration the salience (gradient magnitude) of the\npatches to create the premises for an easy-to-hard curriculum. This\ndiffers significantly from other approaches [5, 44] which apply the\nsmoothing operation uniformly in space, using a single filter applied\nat every location of the input via convolution. Another advantage in\nfavor of CBS [44] is that our approach does not include auxiliary op-\nerations after each neural layer of the model, so the training time is\nidentical to that of the conventional training regime."}, {"title": "3 Method", "content": "Masking specific parts, e.g. patches or tokens, of input data sam-\nples has been demonstrated to be a successful technique to train deep\nlearning models in a self-supervised manner, in both natural language\nprocessing [11, 34] and computer vision [2, 16, 17, 22, 34, 49] do-\nmains. This method has been primarily used as a pre-training task\n[11, 22], in which the model is tasked with reconstructing the masked\ninformation. Through this approach, the model is able to learn and\nrecognize patterns in the data, leading to improved accuracy and\nmore effective performance in downstream tasks. In this work, we re-\ndesign the masking procedure to create a curriculum learning method\nbased on masking patches according to their salience level. Our ap-\nproach is able to artificially generate examples of various difficulty\nlevels. We name the resulting learning procedure Curriculum by\nMasking (CBM).\nOur curriculum learning procedure starts from the original sam-\nples and gradually creates more difficult images as the training pro-\ngresses. We increase the image difficulty by masking a higher num-\nber of heterogeneous patches. We estimate the heterogeneity (or\nsalience) of a patch via the average gradient magnitude computed\non both horizontal and vertical axes. Such patches are likely to con-\ntain regions of interest, such as object parts or other discriminative\npatterns. Before the training starts, our approach creates a curricu-\nlum schedule vector $r \\in \\mathbb{R}^N$, where each element $r_k$ represents the\npercentage of patches that are to be masked during the $k$-th training\niteration. We note that the maximum number of iterations is denoted\nby $N$, and $r_N$ is equal to a maximum masking ratio, which is fixed\nbeforehand through validation. We empirically study various alter-\nnative functions to generate the curriculum schedule $r$ and regulate\nits growth rate. For details about the results obtained with different\ncurriculum schedules, please refer to Section 4.\nOur salience-based masking procedure is described in Algo-\nrithm 1. The algorithm operates on the input image $\\hat{I}$, which is di-\nvided into non-overlapping patches and represented as a tensor of\ndimensions $\\mathbb{R}^{n \\times \\hat{h} \\times \\hat{w} \\times c}$, where $n$ denotes the number of patches, $\\hat{h}$\nand $\\hat{w}$ refer to the height and width of each patch, and $c$ represents\nthe number of color channels. In addition to the input image, the al-\ngorithm also relies on the ratio of masked patches $r_k$ for the current\ntraining iteration $k$, and an array of probabilities $p \\in [0,1]^n$ that\ncontrols the likelihood of masking each patch.\nFirst, the algorithm computes the number of patches to be masked,\ndenoted as $n_{\\text{mask}}$, based on the specified percentage $r_k$. Then, at\neach loop iteration $i$, the algorithm samples a patch index $j$ from\nthe set ${1, ..., n}$ according to a categorical distribution described\nby the vector $p$. Then, the patch at index $j$ is masked by setting its\npixels to zero in the output image $\\hat{I}_{\\text{mask}}$.\nAs previously stated, the masking algorithm prioritizes salient re-\ngions of the input image. This property is accomplished by control-\nling the probabilities in $p$, such that salient patches (likely to contain\ndiscriminative patterns) are assigned with higher probabilities, thus\nincreasing their chances of being selected for masking. We hypoth-\nesize that salient regions can be identified to a certain extent by an-\nalyzing the magnitudes of the image gradients. We transform color\nimages to the grayscale, before computing the gradients. Formally,\ngiven a grayscale image $I \\in \\mathbb{R}^{h \\times w}$, where $h = n_h\\cdot \\hat{h}, w = n_w \\cdot \\hat{w}$\nand $n = n_h\\cdot n_w$, we compute its gradient as follows:\n$\\bigtriangledown I = (\\frac{\\partial I}{\\partial x},\\frac{\\partial I}{\\partial y})$\nThen, we computed the magnitude $M \\in \\mathbb{R}^{h \\times w}$ of the gradient as\nfollows:\n$M = ||\\bigtriangledown I|| = \\sqrt{(\\frac{\\partial I}{\\partial x})^2+(\\frac{\\partial I}{\\partial y})^2}$\nNext, we split $M$ into $n$ patches and obtain the tensor denoted by\n$\\underline{M} \\in \\mathbb{R}^{n \\times \\hat{h} \\times \\hat{w}}$. Finally, we compute the elements of $p$ via the fol-\nlowing equations:\n$m_i = \\frac{\\sum_{j=1}^{\\hat{h}}\\sum_{l=1}^{\\hat{w}} \\underline{M}[i, j, l]}{\\hat{h}\\hat{w}}, \\forall i \\in \\{1, ..., n\\},$\n$p_i = \\frac{m_i}{\\sum_{j=1}^{n} m_j}, \\forall i \\in \\{1, ..., n\\},$\nwhere $m_i$ is the unnormalized gradient magnitude of the $i$-th patch,\nand $p_i$ is the probability of masking the $i$-th patch.\nWe underline that CBM has two important hyperparameters,\nnamely the vector $r$ and the number of patches $n$. Given that the im-\nages are divided into non-overlapping patches, the number of patches\n$n$ is directly determined by the patch dimensions. In our experiments,\nwe use square patches (having the same height and width). To gen-\nerate $r$, we consider one of the various schedules depicted in Figure\n2. The constant schedule emulates the framework proposed by He\net al. [22], which does not represent an actual curriculum, since it\ngenerates equally difficult examples during training, i.e.:\n$r_k = r_N, \\forall k \\in \\{1, 2, ..., N\\},$\nwhere $N$ is the number of training epochs. The constant schedule is\nonly added as a baseline.\nWe propose three curriculum schedules that generate a logarith-\nmic, linear or exponential growth of the masking ratio. The log\nschedule creates a more aggressive curriculum, increasing the mask-"}, {"title": "...", "content": "ing ratio much sooner:\n$r_k = r_N \\text{log}_2(1+\\frac{k}{N-1}), \\forall k \\in \\{1, 2, ..., N\\}.$\nIn contrast, the exp schedule is the least aggressive curriculum, in-\ntroducing high masking ratios only at the very end:\n$r_k = r_N \\cdot e^{\\frac{k-N}{N}}, \\forall k \\in \\{1, 2, ..., N\\}.$\nThe linear schedule is between the log and exp schedule, its formula\nbeing given by:\n$r_k = r_N \\frac{k}{N}, \\forall k \\in \\{1, 2, ..., N\\}.$\nWhile humans learn from easy to hard, reminding easy concepts\nwhen trying to learn complex ones is generally helpful. To this end,\nwe consider an additional curriculum learning schedule called lin-\near repeat, which repeats the easy-to-hard curriculum multiple times\nduring training. This schedule is depicted in Figure 2 along with the\nother schedules. It is repeated 10 times, at every 20 epochs, just for il-\nlustration purposes. On easy (unmasked) images, the model can learn\nsome generic patterns from the data. As the images get harder by in-\ncreasing the masking ratio, the model will try to identify new patterns\nthat are robust to the masking procedure. In this process, the model\ncan forget the initially learned patterns due to catastrophic forgetting.\nThe linear repeat scheduler helps to avoid the catastrophic forgetting\nof the generic patterns learned on easy images, by reintroducing easy\nimages at various stages during the entire optimization process.\nFor all the aforementioned schedules, the maximum masking ratio\n$0 < r_N < 1$ is a hyperparameter that can be established via grid or\nrandom search on the validation set. The rate of masking can be used\nto control the trade-off between underfitting and overfitting. If there\nis no masking, the classification task becomes easy and the model\ncan overfit the training data. In contrast, if the masking ratio is too\nhigh, the classification task can become too hard, and the model will\nbe unable to learn from the masked data, leading to underfitting.\nOne of the curriculum schedules needs to be chosen before train-\ning begins. In the experiments, we present extensive results with the\nproposed schedules, which generate more or less aggressive curricu-\nlum learning strategies."}, {"title": "4 Experiments", "content": "4.1 Experimental Setup\nData sets. We evaluate our curriculum learning method on four ob-\nject recognition data sets (CIFAR-10 [31], CIFAR-100 [31], Ima-\ngeNet [42] and Food-101 [4]) and one object detection data set (PAS-\nCAL VOC [14]). Each of the CIFAR-10 and CIFAR-100 data sets\nconsists of 50,000 training images and 10,000 test images with a res-\nolution of 32 \u00d7 32 pixels. CIFAR-10 contains 10 object categories,\nwhile CIFAR-100 contains 100 categories. ImageNet-1K [42] is the\nmost popular benchmark in computer vision. We use 200 ImageNet\ncategories in the evaluation. Food-101 [4] contains 75,750 training\nimages and 25,250 test images from 101 food categories. PASCAL\nVOC 2007+2012 [14] is a well-known data set for object detection,\nwhich consists of 21,503 images. Objects from 20 categories are an-\nnotated with bounding boxes.\nArchitectures. To evaluate the generalization capabilities of CBM\nacross different architectures, we perform object recognition exper-\niments with two convolutional neural networks and one transformer\nmodel. More precisely, we employ ResNet-18 [21], Wide-ResNet-50\n[58] and CvT-13 [55]. Being a transformer-based architecture, CvT\nbenefits significantly from pre-training. Thus, we use a checkpoint\npre-trained on ImageNet-21K in our experiments. As such, we ap-\nply CBM in both \"training from scratch\" and fine-tuning scenarios.\nFurthermore, we employ an object detection pipeline, YOLOv5 [27],\nto evaluate the benefits of CBM in object detection. We specifically\nchoose the YOLOv5s [27] model, which is pre-trained on the MS\nCOCO data set [35].\nBaselines. We compare CBM with the conventional training regime,\nwhich uses the optimal hyperparameters (learning rate, batch size,\nweight decay, and so on) specific to each of the subsequent exper-\niments. Moreover, we compare our curriculum learning approach\nwith four competing curriculum learning methods, namely Curricu-\nlum by Smoothing (CBS) [44], Label-Similarity Curriculum Learn-\ning (LSCL) [12], Learning Rate Curriculum (LeRaC) [10] and Ef-\nficientTrain [53]. In the ablation study, we also compare with the\nframework of He et al. [22], which can be seen as an ablated version\nof CBM.\nHyperparameter tuning. The optimal hyperparameter configura-\ntions of the ResNet-18, Wide-ResNet-50 and CvT-13 models are\nshown in Table 1. Regardless of the training regime, ResNet-18 and\nWide-ResNet-50 are trained with SGD for 200 epochs on the CIFAR-\n10, CIFAR-100 and Food-101 data sets, and 100 epochs on Ima-\ngeNet. Since CvT-13 is pre-trained on ImageNet, it only requires 40\nepochs of fine-tuning to converge. The SGD optimizer is used along-\nside an annealing learning rate scheduler for ResNet-18 and Wide-\nResNet-50, requiring a large initial learning rate of $10^{-1}$. In contrast,\nAdaMax does not require a scheduler, as it adjusts its learning rate\nbased on data characteristics. We optimize all models with the cross-\nentropy loss. The maximum masking ratio for each model is found\nthrough grid search on the validation set, considering values between\n0.1 and 0.8. The optimal maximum masking ratio for CIFAR-10 is\n0.4, while ImageNet seems to benefit from a higher ratio of 0.6 when\nusing ResNet-18 or CvT-13. Among the proposed curriculum sched-\nules, we select the masking ratio at each epoch based on a linear\nschedule, which is repeated every 5 epochs. We present results with\nvarious curriculum schedules later. The number of patches is chosen\nbetween 2 \u00d7 2 and 16 \u00d7 16. The optimal choice for all models is\n4 x 4.\nWe perform the object detection experiments with a YOLOv5s\ninstance that uses the CSPDarknet53 [51] backbone. The model is\ntrained for 100 epochs, using SGD with momentum. We set the learn-\ning rate to 0.01 in all experiments and use a weight decay of $5 \\cdot 10^{-4}$,\nwith a warm-up stage of 3 epochs, where the learning rate is increas-\ning from $3 \\cdot 10^{-6}$ to $10^{-2}$. For the LeRaC experiments, we replace\nthe warm-up stage with the actual curriculum method. The momen-"}, {"title": "...", "content": "tum is set to 0.8 during warm-up, and 0.94 afterwards. The masking\nschedule is the same as the one employed for the recognition models,\nbut the maximum masking ratio is 0.3 and the number of patches is\n16 x 16.\nEnvironment. The experiments are conducted on a server with two\nIntel Xeon v4 3.0GHz CPUs, 256GB of RAM, and four Nvidia\nGeForce GTX 1080 GPUs, each with 11GB of VRAM.\nEvaluation. The object recognition models are evaluated in terms of\nthe classification accuracy. We repeat each experiment five times and\nreport the average accuracy and the standard deviation.\nFor the object detection models, we compute the Average Preci-\nsion (AP) on each class and report the performance over all classes,\ni.e. the mean Average Precision (mAP). Following standard evalu-\nation protocols, we consider that an object is correctly detected if\nthe intersection over union (IoU) between the predicted and ground-\ntruth bounding boxes is at least 0.5. Hence, the reported measure is\nmAP@IoU=0.5.\n4.2 Results\nObject recognition. In Table 2, we report the object recognition re-\nsults with six training regimes (conventional, CBS, LSCL, LeRaC,\nEfficientTrain and CBM) on CIFAR-10, CIFAR-100, ImageNet and\nFood-101. We report the average accuracy rates and the standard de-\nviations over five runs with each model and training regime.\nOn CIFAR-10, the only training regime that makes ResNet-18 sur-\npass the 90% threshold is CBM, boosting the performance by 1.28%\nover the baseline. We observe similar gains brought by our method\n(CBM) to the Wide-ResNet-50 (+1.45%) and CvT-13 (+1.44%) ar-\nchitectures. In contrast, CBS is only able to bring improvements for\nResNet-18, and LSCL is only able to improve CvT-13. EfficientTrain\nseems to be slightly better than CBS and LSCL, although it degrades\nthe performance of Wide-ResNet-50. LeRaC is the top competitor,\nbeing consistent across all architectures, but its accuracy gains are\nalways below 1% on CIFAR-10.\nOn CIFAR-100, we observe that the CBS regime is not helpful for\nWide-ResNet-50 and CvT-13, degrading their performance rates by\nsignificant margins. LeRaC proves to be a worthy competitor, always\nboosting the accuracy rate of the baseline. Its performance boosts are\nabove 1% for Wide-ResNet-50 and CvT-13. EfficientTrain is the best\nregime for ResNet-18, but it only ranks third and fourth for Wide-\nResNet-50 and CvT-13. In contrast, CBM brings the highest accuracy\ngains for Wide-ResNet-50 and CvT-13, remarkably surpassing all its\ncompetitors by more than 1.52% for Wide-ResNet-50 and 2.21% for\nCvT-13, respectively.\nImageNet is the most challenging benchmark included in our ex-\nperiments. Still, the trends observed on CIFAR-10 and CIFAR-100\nalso apply to ImageNet. For example, CBS degrades the perfor-\nmance, just as before. In contrast, LSCL, LeRaC and EfficientTrain\noutperform the conventional training regime, regardless of the under-\nlying architecture. Yet, CBM stands out as the best training regime,\noutperforming all competitors by more than 1.64% for ResNet-18.\nThe results reported on Food-101 are mostly consistent with the\nresults reported on ImageNet. CBS is often harmful, while LSCL,\nLeRaC and EfficientTrain are usually able to increase performance.\nStill, CBM exhibits the highest gains for all three architectures,\nshowing significant differences with respect to its competitors. For\ninstance, CBM surpasses the second-best regime for CVT-13 by\n1.91%.\nIn summary, the object recognition experiments point towards\nsome generic conclusions. The CBS [44] training regime is only use-\nful in some cases. LSCL [12] and EfficientTrain [53] are usually\nhelpful, although they sometimes reduce performance. LeRaC [10]\nbrings consistent accuracy gains, but the improvements are often be-\nlow 1%. In contrast, the proposed regime, CBM, outperforms the\nother training regimes on all four data sets and for all three architec-"}, {"title": "...", "content": "tures. We performed Cochran's Q statistical testing for conventional\ntraining versus CBM. The statistical tests indicate that our perfor-\nmance gains (on all data sets and architectures) are significant, at a\np-value of 0.001.\nObject detection. We explore the applicability of the curriculum\nlearning methods on the object detection task, reporting the mAP\nscores of YOLOv5s on PASCAL VOC [14], while alternating be-\ntween the six training regimes. The corresponding results are re-\nported in Table 3. The object detection results indicate that LeRaC,\nEfficientTrain and CBM lead to sizeable improvements, while CBS\nseems to degrade performance. Our method obtains an mAP of\n0.847, outperforming all other regimes. Hence, the object detection\nresults confirm that our approach is a viable curriculum learning\nstrategy.\n4.3 Ablation Results\nCurriculum schedules. We present additional results with various\ncurriculum schedules in Table 4. We include the vanilla training\nregime as a baseline. The constant schedule makes our framework\nequivalent to that of He et al. [22]. Although He et al. [22] showed\nthat masked auto-encoders reach optimal results in self-supervised\nlearning, we observe that their training regime leads to marginal\nimprovements in supervised learning. However, there are multiple\ncurriculum learning schedules that bring significant performance im-\nprovements over the vanilla training regime and the constant sched-\nule, for each combination of model and data set. Thus, the lower\naccuracy rates of the constant schedule can be attributed to the lack\nof easy-to-hard curriculum in this type of schedule. Among the con-\nsidered schedules, the linear, log and linear repeat schedules exhibit\nthe highest performance gains, but the best choice is clearly linear re-\npeat. This observation motivates our use of the linear repeat schedule\nin the experiments presented in Tables 2 and 3.\nAblation of gradient masking and curriculum. We first study the\neffect of our gradient-based masking procedure, replacing it with\nmasking based on the uniform distribution of the patches. We jointly\nassess the influence of the curriculum schedule, as opposed to using a\nconstant masking ratio during the whole training process. We present\nthese experiments on CIFAR-100 in Table 5. Without the curriculum,\nthe gradient-based masking brings accuracy gains for ResNet-18 and\nWide-ResNet-50, but not for CvT-13. We performed Cochran's Q\nstatistical tests to assess the significance of gradient-based masking.\nFor ResNet-18 and Wide-ResNet-50, the gains are significant, at p-\nvalues of 0.001 and 0.01, respectively. Replacing the constant sched-\nule with the proposed curriculum schedule (linear repeat) improves\nthe accuracy rates of all models. When the easy-to-hard curriculum is\nactivated, the gradient-based masking increases the accuracy, but the\nimprovements seem low. While the results indicate that both our con-\ntributions are effective, our curriculum approach has a much higher\npositive impact on performance. We report the highest gains when\ncombining the gradient-based masking with our curriculum learning\nschedule, confirming the effectiveness of our joint design. From a\npractical point of view, we thus judge our contributions as relevant."}, {"title": "...", "content": "4.4 Additional Results\nAugmentation versus curriculum. We underline that the constant\nschedule is equivalent to simple data augmentation via masking\npatches. As shown in Table 4 from the main article"}, {"title": "CBM: Curriculum by Masking", "authors": ["Andrei Jarc\u0103", "Florinel-Alin Croitoru", "Radu Tudor Ionescu"], "abstract": "We propose Curriculum by Masking (CBM), a novel\nstate-of-the-art curriculum learning strategy that effectively creates\nan easy-to-hard training schedule via patch (token) masking, offer-\ning significant accuracy improvements over the conventional train-\ning regime and previous curriculum learning (CL) methods. CBM\nleverages gradient magnitudes to prioritize the masking of salient\nimage regions via a novel masking algorithm and a novel masking\nblock. Our approach enables controlling sample difficulty via the\npatch masking ratio, generating an effective easy-to-hard curricu-\nlum by gradually introducing harder samples as training progresses.\nCBM operates with two easily configurable parameters, i.e. the num-\nber of patches and the curriculum schedule, making it a versatile\ncurriculum learning approach for object recognition and detection.\nWe conduct experiments with various neural architectures, ranging\nfrom convolutional networks to vision transformers, on five bench-\nmark data sets (CIFAR-10, CIFAR-100, ImageNet, Food-101 and\nPASCAL VOC), to compare CBM with conventional as well as\ncurriculum-based training regimes. Our results reveal the superiority\nof our strategy compared with the state-of-the-art curriculum learn-\ning regimes. We also observe improvements in transfer learning con-\ntexts, where CBM surpasses previous work by considerable margins\nin terms of accuracy. We release our code for free non-commercial\nuse at https://github.com/CroitoruAlin/CBM.", "sections": [{"title": "1 Introduction", "content": "Humans learn by grasping the easier concepts before gradually mov-\ning to the more complex ones. Inspired by this observation, Bengio\net al. [3] proposed curriculum learning, a training regime that intro-\nduces a structured order of the data samples to train neural models\nfrom easy to hard. This method ensures that the examples are pre-\nsented to the model in a logical and meaningful sequence, allow-\ning the model to effectively learn and develop its knowledge base.\nThe method has been employed in multiple scenarios yielding signif-\nicant performance improvements [46]. Furthermore, over the course\nof time, various methods have been developed to integrate curricu-\nlum learning [3, 7, 10, 19, 25, 30, 36, 37, 39, 43, 44, 45]. While\nmany of these approaches involve different components of the train-\ning process, Soviany et al. [46] have classified them into four main\ncategories. The first category, known as data-level curriculum, in-\nvolves sorting the data samples based on certain difficulty criteria.\nThis approach aligns with the initial implementation of Bengio et\nal. [3]. The second category, referred to as model-level curriculum,\nincludes methods that gradually increase the capacity of the model\nas the training progresses. The third category, represented by task-\nlevel curriculum, aims to make the learning task more intricate over\ntime. Lastly, objective-level curriculum begins with a simplified ob-\njective, e.g. a convex objective, and transforms it during training until\nit becomes the final target objective, which is usually non-convex.\nThe data-level curriculum learning approaches involve sorting the\ntraining examples based on some difficulty metric [3, 23, 30, 38,\n45, 48, 54, 60], before proceeding with the actual learning process.\nHowever, this approach has a significant challenge associated with\nit, namely the need to use a custom difficulty metric for each do-\nmain. The choice of the difficulty metric may vary depending on the\nspecific learning task, and, in certain cases, it can be very hard to pro-\npose a useful difficulty metric [10]. Building on the success of self-\nsupervised approaches [22, 11] used to train deep learning models to\nreconstruct masked information (tokens), we propose a novel data-\nlevel curriculum learning approach, termed Curriculum by Masking\n(CBM), that artificially raises the difficulty level of each training im-\nage by masking a certain number of patches, where the number of\nmasked patches gradually increases during the training process, as il-\nlustrated in Figure 1. Hence, our approach does not require the prior\nsorting of data samples, as it enables full control over the complexity\nof a data sample via the masking ratio. However, we conjecture that\nrandomly masking patches does not necessarily induce an easy-to-\nhard curriculum. For example, if the masked patches happen to hide\nmost of the background in an image, leaving the foreground object\nthat needs to be recognized or detected visible, we will actually end\nup with an easier example instead of a more difficult one. To this end,\nwe propose to sample the masked patches from a probability distri-\nbution derived from image gradient magnitudes, essentially priori-\ntizing the masking of salient image patches. Since salient regions are\nmore likely to contain discriminative patterns, masking patches with\nlarger gradient magnitudes reduces the number of visible discrimina-\ntive patterns, thus increasing the difficulty of recognizing objects in\nimages.\nWe conduct experiments to determine the effectiveness of our ap-\nproach in object recognition and object detection. We apply CBM\non different types of convolutional and transformer neural net-\nworks, e.g. ResNet-18 [21], Wide-ResNet-50 [58], CvT-13 [55], and\nYOLOv5 [27]. Our empirical study is carried out on five data sets:\nCIFAR-10 [31], CIFAR-100 [31], ImageNet [42], Food-101 [4] and\nPASCAL VOC [14]. We compare our approach with four state-of-\nthe-art curriculum learning methods [10, 12, 44, 53], as well as two\nmore baseline training regimes. The first baseline is the vanilla train-\ning regime, while the second one employs the vanilla patch masking\ntechnique proposed by He et al. [22]. Lastly, we present ablation re-\nsults and a comprehensive comparison of masking ratio schedules,\nidentifying multiple successful configurations and parameter choices"}, {"title": "2 Related Work", "content": "Curriculum learning is a training technique introduced by Bengio\net al. [3], which provides the training examples in a meaningful\norder, from easy to hard, to neural networks. The objective is to\nenhance the performance of neural models, while also improving\nthe convergence speed of the training process. Since its introduc-\ntion, curriculum learning has proven its effectiveness in various do-\nmains, such as computer vision [3, 7, 10, 19, 25, 43, 44, 45], natural\nlanguage processing [3, 10, 30, 36, 39, 47], and signal processing\n[1, 10, 40]. The method has been very successful and has under-\ngone extensive development, as illustrated in some recent surveys\n[46, 52]. These developments range from strategies for measuring\ndata difficulty [3, 23, 30, 38, 43, 45, 48, 54, 60] to methods focusing\non other aspects of the training process [5, 10, 6, 28, 44]. A well-\nknown method to apply curriculum learning is by defining a metric\nthat evaluates the complexity of the data, and subsequently arrang-\ning the training examples from the simplest to the most challenging\nones based on the respective metric. Researchers have made signif-\nicant strides in finding improved metrics for various domains and\ntasks. For instance, images containing fewer and larger objects in\ncomputer vision are deemed easier than other images [43, 45]. In\nnatural language processing, word frequency [3, 36] and sequence\nlength [8, 30, 48, 60] are utilized to assess the sample difficulty. In\nsome cases, researchers have also integrated human feedback into\ntheir metric design [26, 38, 54].\nThe aforementioned curriculum strategies have proven to be ef-\nfective. However, they have been found to lack practicality due to\ntheir reliance on human expert input [26], which may not always\nbe available. Moreover, these methods remain fixed during train-\ning and may not adapt the curriculum to the changing needs of\nthe models. As a result, the research community developed new\ncurriculum-based approaches to overcome these limitations. For in-\nstance, Kumar et al. [32] introduced self-paced learning, a method\nthat measures the difficulty of the training samples based on the\nperformance of the trained model. Thus, the order of the training\nsamples changes according to the model feedback during training,\nand thanks to this property, several works adopted the approach\n[15, 18, 24, 32, 33, 41, 61]. Moreover, it is possible to implement\na combination of self-paced learning and classic curriculum learn-\ning approaches. This approach has been previously utilized under\nthe name of self-paced curriculum learning [24, 46]. Another popu-\nlar method is teacher-student curriculum learning [20, 56, 59], where\nthe teacher learns to supervise the student network via a curriculum.\nMethods that fall under the model-level curriculum learning\nparadigm [5, 10, 28, 44, 46] are closer to our work. In this setting, the\ncurriculum does not imply ordering the samples in ascending order of\ntheir difficulty. Instead, the curriculum is implemented by increasing\nthe model capacity as the training progresses, or by adjusting the task\nto become more accessible at the beginning of the training. Curricu-\nlum by Smoothing (CBS), a technique developed by Sinha et al. [44],\nblurs the activation maps resulting from convolutional layers during\nthe training process to let the model focus on the bigger picture. CBS\ngradually reduces the amount of blur as the model improves. This\napproach has been successful on various data sets and models. How-\never, it does require extra processing steps during training, which can\nmake the learning process last longer. The work of Burduja et al. [5]\nis an alternative to CBS, where the input images are blurred instead\nof the intermediary activation maps. Another example is Learning\nRate Curriculum (LeRaC) [10]. This method assigns different learn-\ning rates to the network layers based on their proximity to the input.\nLayers closer to the input have higher learning rates, while those far-\nther away have lower rates. Over time, the learning rates are adjusted\nto converge to a consistent value. Similar to [5, 10, 44], our approach\ndoes not require an external difficulty measure.\nDifferent from other curriculum learning approaches, we propose\nto induce a curriculum via a progressive masking of input patches.\nTo the best of our knowledge, we are the first to introduce a cur-\nriculum learning method based on patch masking. Furthermore, we\ngo beyond a naive implementation and apply the masking operation\nby taking into consideration the salience (gradient magnitude) of the\npatches to create the premises for an easy-to-hard curriculum. This\ndiffers significantly from other approaches [5, 44] which apply the\nsmoothing operation uniformly in space, using a single filter applied\nat every location of the input via convolution. Another advantage in\nfavor of CBS [44] is that our approach does not include auxiliary op-\nerations after each neural layer of the model, so the training time is\nidentical to that of the conventional training regime."}, {"title": "3 Method", "content": "Masking specific parts, e.g. patches or tokens, of input data sam-\nples has been demonstrated to be a successful technique to train deep\nlearning models in a self-supervised manner, in both natural language\nprocessing [11, 34] and computer vision [2, 16, 17, 22, 34, 49] do-\nmains. This method has been primarily used as a pre-training task\n[11, 22], in which the model is tasked with reconstructing the masked\ninformation. Through this approach, the model is able to learn and\nrecognize patterns in the data, leading to improved accuracy and\nmore effective performance in downstream tasks. In this work, we re-\ndesign the masking procedure to create a curriculum learning method\nbased on masking patches according to their salience level. Our ap-\nproach is able to artificially generate examples of various difficulty\nlevels. We name the resulting learning procedure Curriculum by\nMasking (CBM).\nOur curriculum learning procedure starts from the original sam-\nples and gradually creates more difficult images as the training pro-\ngresses. We increase the image difficulty by masking a higher num-\nber of heterogeneous patches. We estimate the heterogeneity (or\nsalience) of a patch via the average gradient magnitude computed\non both horizontal and vertical axes. Such patches are likely to con-\ntain regions of interest, such as object parts or other discriminative\npatterns. Before the training starts, our approach creates a curricu-\nlum schedule vector $r \\in \\mathbb{R}^N$, where each element $r_k$ represents the\npercentage of patches that are to be masked during the $k$-th training\niteration. We note that the maximum number of iterations is denoted\nby $N$, and $r_N$ is equal to a maximum masking ratio, which is fixed\nbeforehand through validation. We empirically study various alter-\nnative functions to generate the curriculum schedule $r$ and regulate\nits growth rate. For details about the results obtained with different\ncurriculum schedules, please refer to Section 4.\nOur salience-based masking procedure is described in Algo-\nrithm 1. The algorithm operates on the input image $\\hat{I}$, which is di-\nvided into non-overlapping patches and represented as a tensor of\ndimensions $\\mathbb{R}^{n \\times \\hat{h} \\times \\hat{w} \\times c}$, where $n$ denotes the number of patches, $\\hat{h}$\nand $\\hat{w}$ refer to the height and width of each patch, and $c$ represents\nthe number of color channels. In addition to the input image, the al-\ngorithm also relies on the ratio of masked patches $r_k$ for the current\ntraining iteration $k$, and an array of probabilities $p \\in [0,1]^n$ that\ncontrols the likelihood of masking each patch.\nFirst, the algorithm computes the number of patches to be masked,\ndenoted as $n_{\\text{mask}}$, based on the specified percentage $r_k$. Then, at\neach loop iteration $i$, the algorithm samples a patch index $j$ from\nthe set ${1, ..., n}$ according to a categorical distribution described\nby the vector $p$. Then, the patch at index $j$ is masked by setting its\npixels to zero in the output image $\\hat{I}_{\\text{mask}}$.\nAs previously stated, the masking algorithm prioritizes salient re-\ngions of the input image. This property is accomplished by control-\nling the probabilities in $p$, such that salient patches (likely to contain\ndiscriminative patterns) are assigned with higher probabilities, thus\nincreasing their chances of being selected for masking. We hypoth-\nesize that salient regions can be identified to a certain extent by an-\nalyzing the magnitudes of the image gradients. We transform color\nimages to the grayscale, before computing the gradients. Formally,\ngiven a grayscale image $I \\in \\mathbb{R}^{h \\times w}$, where $h = n_h\\cdot \\hat{h}, w = n_w \\cdot \\hat{w}$\nand $n = n_h\\cdot n_w$, we compute its gradient as follows:\n$\\bigtriangledown I = (\\frac{\\partial I}{\\partial x},\\frac{\\partial I}{\\partial y})$\nThen, we computed the magnitude $M \\in \\mathbb{R}^{h \\times w}$ of the gradient as\nfollows:\n$M = ||\\bigtriangledown I|| = \\sqrt{(\\frac{\\partial I}{\\partial x})^2+(\\frac{\\partial I}{\\partial y})^2}$\nNext, we split $M$ into $n$ patches and obtain the tensor denoted by\n$\\underline{M} \\in \\mathbb{R}^{n \\times \\hat{h} \\times \\hat{w}}$. Finally, we compute the elements of $p$ via the fol-\nlowing equations:\n$m_i = \\frac{\\sum_{j=1}^{\\hat{h}}\\sum_{l=1}^{\\hat{w}} \\underline{M}[i, j, l]}{\\hat{h}\\hat{w}}, \\forall i \\in \\{1, ..., n\\},$\n$p_i = \\frac{m_i}{\\sum_{j=1}^{n} m_j}, \\forall i \\in \\{1, ..., n\\},$\nwhere $m_i$ is the unnormalized gradient magnitude of the $i$-th patch,\nand $p_i$ is the probability of masking the $i$-th patch.\nWe underline that CBM has two important hyperparameters,\nnamely the vector $r$ and the number of patches $n$. Given that the im-\nages are divided into non-overlapping patches, the number of patches\n$n$ is directly determined by the patch dimensions. In our experiments,\nwe use square patches (having the same height and width). To gen-\nerate $r$, we consider one of the various schedules depicted in Figure\n2. The constant schedule emulates the framework proposed by He\net al. [22], which does not represent an actual curriculum, since it\ngenerates equally difficult examples during training, i.e.:\n$r_k = r_N, \\forall k \\in \\{1, 2, ..., N\\},$\nwhere $N$ is the number of training epochs. The constant schedule is\nonly added as a baseline.\nWe propose three curriculum schedules that generate a logarith-\nmic, linear or exponential growth of the masking ratio. The log\nschedule creates a more aggressive curriculum, increasing the mask-"}, {"title": "...", "content": "ing ratio much sooner:\n$r_k = r_N \\text{log}_2(1+\\frac{k}{N-1}), \\forall k \\in \\{1, 2, ..., N\\}.$\nIn contrast, the exp schedule is the least aggressive curriculum, in-\ntroducing high masking ratios only at the very end:\n$r_k = r_N \\cdot e^{\\frac{k-N}{N}}, \\forall k \\in \\{1, 2, ..., N\\}.$\nThe linear schedule is between the log and exp schedule, its formula\nbeing given by:\n$r_k = r_N \\frac{k}{N}, \\forall k \\in \\{1, 2, ..., N\\}.$\nWhile humans learn from easy to hard, reminding easy concepts\nwhen trying to learn complex ones is generally helpful. To this end,\nwe consider an additional curriculum learning schedule called lin-\near repeat, which repeats the easy-to-hard curriculum multiple times\nduring training. This schedule is depicted in Figure 2 along with the\nother schedules. It is repeated 10 times, at every 20 epochs, just for il-\nlustration purposes. On easy (unmasked) images, the model can learn\nsome generic patterns from the data. As the images get harder by in-\ncreasing the masking ratio, the model will try to identify new patterns\nthat are robust to the masking procedure. In this process, the model\ncan forget the initially learned patterns due to catastrophic forgetting.\nThe linear repeat scheduler helps to avoid the catastrophic forgetting\nof the generic patterns learned on easy images, by reintroducing easy\nimages at various stages during the entire optimization process.\nFor all the aforementioned schedules, the maximum masking ratio\n$0 < r_N < 1$ is a hyperparameter that can be established via grid or\nrandom search on the validation set. The rate of masking can be used\nto control the trade-off between underfitting and overfitting. If there\nis no masking, the classification task becomes easy and the model\ncan overfit the training data. In contrast, if the masking ratio is too\nhigh, the classification task can become too hard, and the model will\nbe unable to learn from the masked data, leading to underfitting.\nOne of the curriculum schedules needs to be chosen before train-\ning begins. In the experiments, we present extensive results with the\nproposed schedules, which generate more or less aggressive curricu-\nlum learning strategies."}, {"title": "4 Experiments", "content": "4.1 Experimental Setup\nData sets. We evaluate our curriculum learning method on four ob-\nject recognition data sets (CIFAR-10 [31], CIFAR-100 [31], Ima-\ngeNet [42] and Food-101 [4]) and one object detection data set (PAS-\nCAL VOC [14]). Each of the CIFAR-10 and CIFAR-100 data sets\nconsists of 50,000 training images and 10,000 test images with a res-\nolution of 32 \u00d7 32 pixels. CIFAR-10 contains 10 object categories,\nwhile CIFAR-100 contains 100 categories. ImageNet-1K [42] is the\nmost popular benchmark in computer vision. We use 200 ImageNet\ncategories in the evaluation. Food-101 [4] contains 75,750 training\nimages and 25,250 test images from 101 food categories. PASCAL\nVOC 2007+2012 [14] is a well-known data set for object detection,\nwhich consists of 21,503 images. Objects from 20 categories are an-\nnotated with bounding boxes.\nArchitectures. To evaluate the generalization capabilities of CBM\nacross different architectures, we perform object recognition exper-\niments with two convolutional neural networks and one transformer\nmodel. More precisely, we employ ResNet-18 [21], Wide-ResNet-50\n[58] and CvT-13 [55]. Being a transformer-based architecture, CvT\nbenefits significantly from pre-training. Thus, we use a checkpoint\npre-trained on ImageNet-21K in our experiments. As such, we ap-\nply CBM in both \"training from scratch\" and fine-tuning scenarios.\nFurthermore, we employ an object detection pipeline, YOLOv5 [27],\nto evaluate the benefits of CBM in object detection. We specifically\nchoose the YOLOv5s [27] model, which is pre-trained on the MS\nCOCO data set [35].\nBaselines. We compare CBM with the conventional training regime,\nwhich uses the optimal hyperparameters (learning rate, batch size,\nweight decay, and so on) specific to each of the subsequent exper-\niments. Moreover, we compare our curriculum learning approach\nwith four competing curriculum learning methods, namely Curricu-\nlum by Smoothing (CBS) [44], Label-Similarity Curriculum Learn-\ning (LSCL) [12], Learning Rate Curriculum (LeRaC) [10] and Ef-\nficientTrain [53]. In the ablation study, we also compare with the\nframework of He et al. [22], which can be seen as an ablated version\nof CBM.\nHyperparameter tuning. The optimal hyperparameter configura-\ntions of the ResNet-18, Wide-ResNet-50 and CvT-13 models are\nshown in Table 1. Regardless of the training regime, ResNet-18 and\nWide-ResNet-50 are trained with SGD for 200 epochs on the CIFAR-\n10, CIFAR-100 and Food-101 data sets, and 100 epochs on Ima-\ngeNet. Since CvT-13 is pre-trained on ImageNet, it only requires 40\nepochs of fine-tuning to converge. The SGD optimizer is used along-\nside an annealing learning rate scheduler for ResNet-18 and Wide-\nResNet-50, requiring a large initial learning rate of $10^{-1}$. In contrast,\nAdaMax does not require a scheduler, as it adjusts its learning rate\nbased on data characteristics. We optimize all models with the cross-\nentropy loss. The maximum masking ratio for each model is found\nthrough grid search on the validation set, considering values between\n0.1 and 0.8. The optimal maximum masking ratio for CIFAR-10 is\n0.4, while ImageNet seems to benefit from a higher ratio of 0.6 when\nusing ResNet-18 or CvT-13. Among the proposed curriculum sched-\nules, we select the masking ratio at each epoch based on a linear\nschedule, which is repeated every 5 epochs. We present results with\nvarious curriculum schedules later. The number of patches is chosen\nbetween 2 \u00d7 2 and 16 \u00d7 16. The optimal choice for all models is\n4 x 4.\nWe perform the object detection experiments with a YOLOv5s\ninstance that uses the CSPDarknet53 [51] backbone. The model is\ntrained for 100 epochs, using SGD with momentum. We set the learn-\ning rate to 0.01 in all experiments and use a weight decay of $5 \\cdot 10^{-4}$,\nwith a warm-up stage of 3 epochs, where the learning rate is increas-\ning from $3 \\cdot 10^{-6}$ to $10^{-2}$. For the LeRaC experiments, we replace\nthe warm-up stage with the actual curriculum method. The momen-"}, {"title": "...", "content": "tum is set to 0.8 during warm-up, and 0.94 afterwards. The masking\nschedule is the same as the one employed for the recognition models,\nbut the maximum masking ratio is 0.3 and the number of patches is\n16 x 16.\nEnvironment. The experiments are conducted on a server with two\nIntel Xeon v4 3.0GHz CPUs, 256GB of RAM, and four Nvidia\nGeForce GTX 1080 GPUs, each with 11GB of VRAM.\nEvaluation. The object recognition models are evaluated in terms of\nthe classification accuracy. We repeat each experiment five times and\nreport the average accuracy and the standard deviation.\nFor the object detection models, we compute the Average Preci-\nsion (AP) on each class and report the performance over all classes,\ni.e. the mean Average Precision (mAP). Following standard evalu-\nation protocols, we consider that an object is correctly detected if\nthe intersection over union (IoU) between the predicted and ground-\ntruth bounding boxes is at least 0.5. Hence, the reported measure is\nmAP@IoU=0.5.\n4.2 Results\nObject recognition. In Table 2, we report the object recognition re-\nsults with six training regimes (conventional, CBS, LSCL, LeRaC,\nEfficientTrain and CBM) on CIFAR-10, CIFAR-100, ImageNet and\nFood-101. We report the average accuracy rates and the standard de-\nviations over five runs with each model and training regime.\nOn CIFAR-10, the only training regime that makes ResNet-18 sur-\npass the 90% threshold is CBM, boosting the performance by 1.28%\nover the baseline. We observe similar gains brought by our method\n(CBM) to the Wide-ResNet-50 (+1.45%) and CvT-13 (+1.44%) ar-\nchitectures. In contrast, CBS is only able to bring improvements for\nResNet-18, and LSCL is only able to improve CvT-13. EfficientTrain\nseems to be slightly better than CBS and LSCL, although it degrades\nthe performance of Wide-ResNet-50. LeRaC is the top competitor,\nbeing consistent across all architectures, but its accuracy gains are\nalways below 1% on CIFAR-10.\nOn CIFAR-100, we observe that the CBS regime is not helpful for\nWide-ResNet-50 and CvT-13, degrading their performance rates by\nsignificant margins. LeRaC proves to be a worthy competitor, always\nboosting the accuracy rate of the baseline. Its performance boosts are\nabove 1% for Wide-ResNet-50 and CvT-13. EfficientTrain is the best\nregime for ResNet-18, but it only ranks third and fourth for Wide-\nResNet-50 and CvT-13. In contrast, CBM brings the highest accuracy\ngains for Wide-ResNet-50 and CvT-13, remarkably surpassing all its\ncompetitors by more than 1.52% for Wide-ResNet-50 and 2.21% for\nCvT-13, respectively.\nImageNet is the most challenging benchmark included in our ex-\nperiments. Still, the trends observed on CIFAR-10 and CIFAR-100\nalso apply to ImageNet. For example, CBS degrades the perfor-\nmance, just as before. In contrast, LSCL, LeRaC and EfficientTrain\noutperform the conventional training regime, regardless of the under-\nlying architecture. Yet, CBM stands out as the best training regime,\noutperforming all competitors by more than 1.64% for ResNet-18.\nThe results reported on Food-101 are mostly consistent with the\nresults reported on ImageNet. CBS is often harmful, while LSCL,\nLeRaC and EfficientTrain are usually able to increase performance.\nStill, CBM exhibits the highest gains for all three architectures,\nshowing significant differences with respect to its competitors. For\ninstance, CBM surpasses the second-best regime for CVT-13 by\n1.91%.\nIn summary, the object recognition experiments point towards\nsome generic conclusions. The CBS [44] training regime is only use-\nful in some cases. LSCL [12] and EfficientTrain [53] are usually\nhelpful, although they sometimes reduce performance. LeRaC [10]\nbrings consistent accuracy gains, but the improvements are often be-\nlow 1%. In contrast, the proposed regime, CBM, outperforms the\nother training regimes on all four data sets and for all three architec-"}, {"title": "...", "content": "tures. We performed Cochran's Q statistical testing for conventional\ntraining versus CBM. The statistical tests indicate that our perfor-\nmance gains (on all data sets and architectures) are significant, at a\np-value of 0.001.\nObject detection. We explore the applicability of the curriculum\nlearning methods on the object detection task, reporting the mAP\nscores of YOLOv5s on PASCAL VOC [14], while alternating be-\ntween the six training regimes. The corresponding results are re-\nported in Table 3. The object detection results indicate that LeRaC,\nEfficientTrain and CBM lead to sizeable improvements, while CBS\nseems to degrade performance. Our method obtains an mAP of\n0.847, outperforming all other regimes. Hence, the object detection\nresults confirm that our approach is a viable curriculum learning\nstrategy.\n4.3 Ablation Results\nCurriculum schedules. We present additional results with various\ncurriculum schedules in Table 4. We include the vanilla training\nregime as a baseline. The constant schedule makes our framework\nequivalent to that of He et al. [22]. Although He et al. [22] showed\nthat masked auto-encoders reach optimal results in self-supervised\nlearning, we observe that their training regime leads to marginal\nimprovements in supervised learning. However, there are multiple\ncurriculum learning schedules that bring significant performance im-\nprovements over the vanilla training regime and the constant sched-\nule, for each combination of model and data set. Thus, the lower\naccuracy rates of the constant schedule can be attributed to the lack\nof easy-to-hard curriculum in this type of schedule. Among the con-\nsidered schedules, the linear, log and linear repeat schedules exhibit\nthe highest performance gains, but the best choice is clearly linear re-\npeat. This observation motivates our use of the linear repeat schedule\nin the experiments presented in Tables 2 and 3.\nAblation of gradient masking and curriculum. We first study the\neffect of our gradient-based masking procedure, replacing it with\nmasking based on the uniform distribution of the patches. We jointly\nassess the influence of the curriculum schedule, as opposed to using a\nconstant masking ratio during the whole training process. We present\nthese experiments on CIFAR-100 in Table 5. Without the curriculum,\nthe gradient-based masking brings accuracy gains for ResNet-18 and\nWide-ResNet-50, but not for CvT-13. We performed Cochran's Q\nstatistical tests to assess the significance of gradient-based masking.\nFor ResNet-18 and Wide-ResNet-50, the gains are significant, at p-\nvalues of 0.001 and 0.01, respectively. Replacing the constant sched-\nule with the proposed curriculum schedule (linear repeat) improves\nthe accuracy rates of all models. When the easy-to-hard curriculum is\nactivated, the gradient-based masking increases the accuracy, but the\nimprovements seem low. While the results indicate that both our con-\ntributions are effective, our curriculum approach has a much higher\npositive impact on performance. We report the highest gains when\ncombining the gradient-based masking with our curriculum learning\nschedule, confirming the effectiveness of our joint design. From a\npractical point of view, we thus judge our contributions as relevant."}, {"title": "...", "content": "4.4 Additional Results\nAugmentation versus curriculum. We underline that the constant\nschedule is equivalent to simple data augmentation via masking\npatches. As shown in Table 4 from the main article, the differences\nbetween the baseline and the constant schedule (which correspond\nto data augmentation) and the differences between the constant and\nlinear repeat schedules show that curriculum learning brings higher\nimprovements on CIFAR-100 and ImageNet. Moreover, simple data\naugmentation degrades performance for CVT-13 on CIFAR-100 and\nImageNet. This confirms that the reported improvements are mostly\ndue to curriculum learning.\nTo further show that our curriculum strategy can be applied to\nother data augmentations, we conduct experiments with CutMix [57", "10": "one of our\nmain competitors, which"}]}]}