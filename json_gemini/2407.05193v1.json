{"title": "CBM: Curriculum by Masking", "authors": ["Andrei Jarc\u0103", "Florinel-Alin Croitoru", "Radu Tudor Ionescu"], "abstract": "We propose Curriculum by Masking (CBM), a novel state-of-the-art curriculum learning strategy that effectively creates an easy-to-hard training schedule via patch (token) masking, offering significant accuracy improvements over the conventional training regime and previous curriculum learning (CL) methods. CBM leverages gradient magnitudes to prioritize the masking of salient image regions via a novel masking algorithm and a novel masking block. Our approach enables controlling sample difficulty via the patch masking ratio, generating an effective easy-to-hard curriculum by gradually introducing harder samples as training progresses. CBM operates with two easily configurable parameters, i.e. the number of patches and the curriculum schedule, making it a versatile curriculum learning approach for object recognition and detection. We conduct experiments with various neural architectures, ranging from convolutional networks to vision transformers, on five benchmark data sets (CIFAR-10, CIFAR-100, ImageNet, Food-101 and PASCAL VOC), to compare CBM with conventional as well as curriculum-based training regimes. Our results reveal the superiority of our strategy compared with the state-of-the-art curriculum learning regimes. We also observe improvements in transfer learning contexts, where CBM surpasses previous work by considerable margins in terms of accuracy. We release our code for free non-commercial use at https://github.com/CroitoruAlin/CBM.", "sections": [{"title": "1 Introduction", "content": "Humans learn by grasping the easier concepts before gradually moving to the more complex ones. Inspired by this observation, Bengio et al. [3] proposed curriculum learning, a training regime that introduces a structured order of the data samples to train neural models from easy to hard. This method ensures that the examples are presented to the model in a logical and meaningful sequence, allowing the model to effectively learn and develop its knowledge base. The method has been employed in multiple scenarios yielding significant performance improvements [46]. Furthermore, over the course of time, various methods have been developed to integrate curriculum learning [3, 7, 10, 19, 25, 30, 36, 37, 39, 43, 44, 45]. While many of these approaches involve different components of the training process, Soviany et al. [46] have classified them into four main categories. The first category, known as data-level curriculum, involves sorting the data samples based on certain difficulty criteria. This approach aligns with the initial implementation of Bengio et al. [3]. The second category, referred to as model-level curriculum, includes methods that gradually increase the capacity of the model as the training progresses. The third category, represented by task-level curriculum, aims to make the learning task more intricate over time. Lastly, objective-level curriculum begins with a simplified objective, e.g. a convex objective, and transforms it during training until it becomes the final target objective, which is usually non-convex.\nThe data-level curriculum learning approaches involve sorting the training examples based on some difficulty metric [3, 23, 30, 38, 45, 48, 54, 60], before proceeding with the actual learning process. However, this approach has a significant challenge associated with it, namely the need to use a custom difficulty metric for each domain. The choice of the difficulty metric may vary depending on the specific learning task, and, in certain cases, it can be very hard to propose a useful difficulty metric [10]. Building on the success of self-supervised approaches [22, 11] used to train deep learning models to reconstruct masked information (tokens), we propose a novel data-level curriculum learning approach, termed Curriculum by Masking (CBM), that artificially raises the difficulty level of each training image by masking a certain number of patches, where the number of masked patches gradually increases during the training process, as illustrated in Figure 1. Hence, our approach does not require the prior sorting of data samples, as it enables full control over the complexity of a data sample via the masking ratio. However, we conjecture that randomly masking patches does not necessarily induce an easy-to-hard curriculum. For example, if the masked patches happen to hide most of the background in an image, leaving the foreground object that needs to be recognized or detected visible, we will actually end up with an easier example instead of a more difficult one. To this end, we propose to sample the masked patches from a probability distribution derived from image gradient magnitudes, essentially prioritizing the masking of salient image patches. Since salient regions are more likely to contain discriminative patterns, masking patches with larger gradient magnitudes reduces the number of visible discriminative patterns, thus increasing the difficulty of recognizing objects in images.\nWe conduct experiments to determine the effectiveness of our approach in object recognition and object detection. We apply CBM on different types of convolutional and transformer neural networks, e.g. ResNet-18 [21], Wide-ResNet-50 [58], CvT-13 [55], and YOLOv5 [27]. Our empirical study is carried out on five data sets: CIFAR-10 [31], CIFAR-100 [31], ImageNet [42], Food-101 [4] and PASCAL VOC [14]. We compare our approach with four state-of-the-art curriculum learning methods [10, 12, 44, 53], as well as two more baseline training regimes. The first baseline is the vanilla training regime, while the second one employs the vanilla patch masking technique proposed by He et al. [22]. Lastly, we present ablation results and a comprehensive comparison of masking ratio schedules, identifying multiple successful configurations and parameter choices for our method. In summary, our contribution is threefold:\n\u2022 We propose a novel curriculum learning method based on masking an increasingly higher number of patches during training.\n\u2022 We introduce a patch selection strategy that prioritizes the masking of patches with larger gradient magnitudes, ensuring an easy-to-hard curriculum.\n\u2022 We empirically demonstrate the effectiveness of CBM in object recognition and object detection for multiple neural architectures, comparing it with several competing training regimes."}, {"title": "2 Related Work", "content": "Curriculum learning is a training technique introduced by Bengio et al. [3], which provides the training examples in a meaningful order, from easy to hard, to neural networks. The objective is to enhance the performance of neural models, while also improving the convergence speed of the training process. Since its introduction, curriculum learning has proven its effectiveness in various domains, such as computer vision [3, 7, 10, 19, 25, 43, 44, 45], natural language processing [3, 10, 30, 36, 39, 47], and signal processing [1, 10, 40]. The method has been very successful and has undergone extensive development, as illustrated in some recent surveys [46, 52]. These developments range from strategies for measuring data difficulty [3, 23, 30, 38, 43, 45, 48, 54, 60] to methods focusing on other aspects of the training process [5, 10, 6, 28, 44]. A well-known method to apply curriculum learning is by defining a metric that evaluates the complexity of the data, and subsequently arranging the training examples from the simplest to the most challenging ones based on the respective metric. Researchers have made significant strides in finding improved metrics for various domains and tasks. For instance, images containing fewer and larger objects in computer vision are deemed easier than other images [43, 45]. In natural language processing, word frequency [3, 36] and sequence length [8, 30, 48, 60] are utilized to assess the sample difficulty. In some cases, researchers have also integrated human feedback into their metric design [26, 38, 54].\nThe aforementioned curriculum strategies have proven to be effective. However, they have been found to lack practicality due to their reliance on human expert input [26], which may not always be available. Moreover, these methods remain fixed during training and may not adapt the curriculum to the changing needs of the models. As a result, the research community developed new curriculum-based approaches to overcome these limitations. For instance, Kumar et al. [32] introduced self-paced learning, a method that measures the difficulty of the training samples based on the performance of the trained model. Thus, the order of the training samples changes according to the model feedback during training, and thanks to this property, several works adopted the approach [15, 18, 24, 32, 33, 41, 61]. Moreover, it is possible to implement a combination of self-paced learning and classic curriculum learning approaches. This approach has been previously utilized under the name of self-paced curriculum learning [24, 46]. Another popular method is teacher-student curriculum learning [20, 56, 59], where the teacher learns to supervise the student network via a curriculum.\nMethods that fall under the model-level curriculum learning paradigm [5, 10, 28, 44, 46] are closer to our work. In this setting, the curriculum does not imply ordering the samples in ascending order of their difficulty. Instead, the curriculum is implemented by increasing the model capacity as the training progresses, or by adjusting the task to become more accessible at the beginning of the training. Curriculum by Smoothing (CBS), a technique developed by Sinha et al. [44], blurs the activation maps resulting from convolutional layers during the training process to let the model focus on the bigger picture. CBS gradually reduces the amount of blur as the model improves. This approach has been successful on various data sets and models. However, it does require extra processing steps during training, which can make the learning process last longer. The work of Burduja et al. [5] is an alternative to CBS, where the input images are blurred instead of the intermediary activation maps. Another example is Learning Rate Curriculum (LeRaC) [10]. This method assigns different learning rates to the network layers based on their proximity to the input. Layers closer to the input have higher learning rates, while those farther away have lower rates. Over time, the learning rates are adjusted to converge to a consistent value. Similar to [5, 10, 44], our approach does not require an external difficulty measure.\nDifferent from other curriculum learning approaches, we propose to induce a curriculum via a progressive masking of input patches. To the best of our knowledge, we are the first to introduce a curriculum learning method based on patch masking. Furthermore, we go beyond a naive implementation and apply the masking operation by taking into consideration the salience (gradient magnitude) of the patches to create the premises for an easy-to-hard curriculum. This differs significantly from other approaches [5, 44] which apply the smoothing operation uniformly in space, using a single filter applied at every location of the input via convolution. Another advantage in favor of CBS [44] is that our approach does not include auxiliary operations after each neural layer of the model, so the training time is identical to that of the conventional training regime."}, {"title": "3 Method", "content": "Masking specific parts, e.g. patches or tokens, of input data samples has been demonstrated to be a successful technique to train deep learning models in a self-supervised manner, in both natural language processing [11, 34] and computer vision [2, 16, 17, 22, 34, 49] domains. This method has been primarily used as a pre-training task [11, 22], in which the model is tasked with reconstructing the masked information. Through this approach, the model is able to learn and recognize patterns in the data, leading to improved accuracy and more effective performance in downstream tasks. In this work, we redesign the masking procedure to create a curriculum learning method based on masking patches according to their salience level. Our approach is able to artificially generate examples of various difficulty levels. We name the resulting learning procedure Curriculum by Masking (CBM).\nOur curriculum learning procedure starts from the original samples and gradually creates more difficult images as the training progresses. We increase the image difficulty by masking a higher number of heterogeneous patches. We estimate the heterogeneity (or salience) of a patch via the average gradient magnitude computed on both horizontal and vertical axes. Such patches are likely to contain regions of interest, such as object parts or other discriminative patterns. Before the training starts, our approach creates a curriculum schedule vector $r \\in \\mathbb{R}^N$, where each element $r_k$ represents the percentage of patches that are to be masked during the k-th training iteration. We note that the maximum number of iterations is denoted by N, and $r_N$ is equal to a maximum masking ratio, which is fixed beforehand through validation. We empirically study various alternative functions to generate the curriculum schedule r and regulate its growth rate. For details about the results obtained with different curriculum schedules, please refer to Section 4.\nOur salience-based masking procedure is described in Algorithm 1. The algorithm operates on the input image $\\hat{I}$, which is divided into non-overlapping patches and represented as a tensor of dimensions $\\mathbb{R}^{n \\times \\hat{h} \\times \\hat{w} \\times c}$, where n denotes the number of patches, $\\hat{h}$ and $\\hat{w}$ refer to the height and width of each patch, and c represents the number of color channels. In addition to the input image, the algorithm also relies on the ratio of masked patches $r_k$ for the current training iteration k, and an array of probabilities $p \\in [0, 1]^n$ that controls the likelihood of masking each patch.\nFirst, the algorithm computes the number of patches to be masked, denoted as $n_{\\text{mask}}$, based on the specified percentage $r_k$. Then, at each loop iteration i, the algorithm samples a patch index j from"}, {"title": "3 Method", "content": "the set $\\{1, ..., n\\}$ according to a categorical distribution described by the vector p. Then, the patch at index j is masked by setting its pixels to zero in the output image $\\hat{I}_{\\text{mask}}$.\nAs previously stated, the masking algorithm prioritizes salient regions of the input image. This property is accomplished by controlling the probabilities in p, such that salient patches (likely to contain discriminative patterns) are assigned with higher probabilities, thus increasing their chances of being selected for masking. We hypothesize that salient regions can be identified to a certain extent by analyzing the magnitudes of the image gradients. We transform color images to the grayscale, before computing the gradients. Formally, given a grayscale image $I \\in \\mathbb{R}^{h \\times w}$, where $h = n_h \\cdot \\hat{h}$, $w = n_w \\cdot \\hat{w}$ and $n = n_h \\cdot n_w$, we compute its gradient as follows:\n$$\\nabla I = \\Big(\\frac{\\partial I}{\\partial x}, \\frac{\\partial I}{\\partial y}\\Big),$$\nThen, we computed the magnitude $M \\in \\mathbb{R}^{h \\times w}$ of the gradient as follows:\n$$M = ||\\Delta I|| = \\sqrt{\\Big(\\frac{\\partial I}{\\partial x}\\Big)^2 + \\Big(\\frac{\\partial I}{\\partial y}\\Big)^2}.$$$$\\begin{aligned} m_i &= \\frac{\\sum_{j=1}^{\\hat{h}} \\sum_{l=1}^{\\hat{w}} M[i, j, 1]}{\\hat{h} \\hat{w}}, \\forall i \\in \\{1, ..., n\\}, \\\\ p_i &= \\frac{m_i}{\\sum_{j=1}^{n} m_j}, \\forall i \\in \\{1, ..., n\\}, \\end{aligned}$$\nwhere $m_i$ is the unnormalized gradient magnitude of the i-th patch, and $p_i$ is the probability of masking the i-th patch.\nWe underline that CBM has two important hyperparameters, namely the vector r and the number of patches n. Given that the images are divided into non-overlapping patches, the number of patches n is directly determined by the patch dimensions. In our experiments, we use square patches (having the same height and width). To generate r, we consider one of the various schedules depicted in Figure 2. The constant schedule emulates the framework proposed by He et al. [22], which does not represent an actual curriculum, since it generates equally difficult examples during training, i.e.:\n$$r_k = r_N, \\forall k \\in \\{1, 2, ..., N\\},$$\nwhere N is the number of training epochs. The constant schedule is only added as a baseline.\nWe propose three curriculum schedules that generate a logarithmic, linear or exponential growth of the masking ratio. The log schedule creates a more aggressive curriculum, increasing the masking ratio much sooner:\n$$r_k = r_N \\log_2\\Big(1 + \\frac{k}{N}\\Big), \\forall k \\in \\{1, 2, ..., N\\}.$$$$\\begin{aligned} r_k = r_N \\cdot e^{\\frac{k-N}{N}}, \\forall k \\in \\{1, 2, ..., N\\}. \\end{aligned}$$\nThe linear schedule is between the log and exp schedule, its formula being given by:\n$$r_k = r_N \\frac{k}{N}, \\forall k \\in \\{1, 2, ..., N\\}.$$$$\\begin{aligned}T = \\frac{1}{\\text{batch size}}\\sum_{i=1}^{\\text{batch size}} L(w; x_i, y_i) + \\lambda R(w)\n\\end{aligned}$$\nWhile humans learn from easy to hard, reminding easy concepts when trying to learn complex ones is generally helpful. To this end, we consider an additional curriculum learning schedule called linear repeat, which repeats the easy-to-hard curriculum multiple times during training. This schedule is depicted in Figure 2 along with the other schedules. It is repeated 10 times, at every 20 epochs, just for illustration purposes. On easy (unmasked) images, the model can learn some generic patterns from the data. As the images get harder by increasing the masking ratio, the model will try to identify new patterns that are robust to the masking procedure. In this process, the model can forget the initially learned patterns due to catastrophic forgetting. The linear repeat scheduler helps to avoid the catastrophic forgetting of the generic patterns learned on easy images, by reintroducing easy images at various stages during the entire optimization process.\nFor all the aforementioned schedules, the maximum masking ratio $0 < r_N < 1$ is a hyperparameter that can be established via grid or random search on the validation set. The rate of masking can be used to control the trade-off between underfitting and overfitting. If there is no masking, the classification task becomes easy and the model can overfit the training data. In contrast, if the masking ratio is too high, the classification task can become too hard, and the model will be unable to learn from the masked data, leading to underfitting.\nOne of the curriculum schedules needs to be chosen before training begins. In the experiments, we present extensive results with the proposed schedules, which generate more or less aggressive curriculum learning strategies."}, {"title": "4 Experiments", "content": "Data sets. We evaluate our curriculum learning method on four object recognition data sets (CIFAR-10 [31], CIFAR-100 [31], ImageNet [42] and Food-101 [4]) and one object detection data set (PASCAL VOC [14]). Each of the CIFAR-10 and CIFAR-100 data sets consists of 50,000 training images and 10,000 test images with a resolution of 32 \u00d7 32 pixels. CIFAR-10 contains 10 object categories, while CIFAR-100 contains 100 categories. ImageNet-1K [42] is the most popular benchmark in computer vision. We use 200 ImageNet categories in the evaluation. Food-101 [4] contains 75,750 training images and 25,250 test images from 101 food categories. PASCAL VOC 2007+2012 [14] is a well-known data set for object detection, which consists of 21,503 images. Objects from 20 categories are annotated with bounding boxes.\nArchitectures. To evaluate the generalization capabilities of CBM across different architectures, we perform object recognition experiments with two convolutional neural networks and one transformer model. More precisely, we employ ResNet-18 [21], Wide-ResNet-50 [58] and CvT-13 [55]. Being a transformer-based architecture, CvT benefits significantly from pre-training. Thus, we use a checkpoint pre-trained on ImageNet-21K in our experiments. As such, we apply CBM in both \"training from scratch\" and fine-tuning scenarios. Furthermore, we employ an object detection pipeline, YOLOv5 [27], to evaluate the benefits of CBM in object detection. We specifically choose the YOLOv5s [27] model, which is pre-trained on the MS COCO data set [35].\nBaselines. We compare CBM with the conventional training regime, which uses the optimal hyperparameters (learning rate, batch size, weight decay, and so on) specific to each of the subsequent experiments. Moreover, we compare our curriculum learning approach with four competing curriculum learning methods, namely Curriculum by Smoothing (CBS) [44], Label-Similarity Curriculum Learning (LSCL) [12], Learning Rate Curriculum (LeRaC) [10] and EfficientTrain [53]. In the ablation study, we also compare with the framework of He et al. [22], which can be seen as an ablated version of CBM.\nHyperparameter tuning. The optimal hyperparameter configurations of the ResNet-18, Wide-ResNet-50 and CvT-13 models are shown in Table 1. Regardless of the training regime, ResNet-18 and Wide-ResNet-50 are trained with SGD for 200 epochs on the CIFAR-10, CIFAR-100 and Food-101 data sets, and 100 epochs on ImageNet. Since CvT-13 is pre-trained on ImageNet, it only requires 40 epochs of fine-tuning to converge. The SGD optimizer is used alongside an annealing learning rate scheduler for ResNet-18 and Wide-ResNet-50, requiring a large initial learning rate of 10\u207b\u00b9. In contrast, AdaMax does not require a scheduler, as it adjusts its learning rate based on data characteristics. We optimize all models with the cross-entropy loss. The maximum masking ratio for each model is found through grid search on the validation set, considering values between 0.1 and 0.8. The optimal maximum masking ratio for CIFAR-10 is 0.4, while ImageNet seems to benefit from a higher ratio of 0.6 when using ResNet-18 or CvT-13. Among the proposed curriculum schedules, we select the masking ratio at each epoch based on a linear schedule, which is repeated every 5 epochs. We present results with various curriculum schedules later. The number of patches is chosen between 2 \u00d7 2 and 16 \u00d7 16. The optimal choice for all models is 4 x 4.\nWe perform the object detection experiments with a YOLOv5s instance that uses the CSPDarknet53 [51] backbone. The model is trained for 100 epochs, using SGD with momentum. We set the learning rate to 0.01 in all experiments and use a weight decay of 5\u00b710\u207b\u2074, with a warm-up stage of 3 epochs, where the learning rate is increasing from 3\u00b710\u207b\u2076 to 10\u207b\u00b2. For the LeRaC experiments, we replace the warm-up stage with the actual curriculum method. The momen-"}, {"title": "4.2 Results", "content": "Object recognition. In Table 2, we report the object recognition results with six training regimes (conventional, CBS, LSCL, LeRaC, EfficientTrain and CBM) on CIFAR-10, CIFAR-100, ImageNet and Food-101. We report the average accuracy rates and the standard deviations over five runs with each model and training regime.\nOn CIFAR-10, the only training regime that makes ResNet-18 surpass the 90% threshold is CBM, boosting the performance by 1.28% over the baseline. We observe similar gains brought by our method (CBM) to the Wide-ResNet-50 (+1.45%) and CvT-13 (+1.44%) architectures. In contrast, CBS is only able to bring improvements for ResNet-18, and LSCL is only able to improve CvT-13. EfficientTrain seems to be slightly better than CBS and LSCL, although it degrades the performance of Wide-ResNet-50. LeRaC is the top competitor, being consistent across all architectures, but its accuracy gains are always below 1% on CIFAR-10.\nOn CIFAR-100, we observe that the CBS regime is not helpful for Wide-ResNet-50 and CvT-13, degrading their performance rates by significant margins. LeRaC proves to be a worthy competitor, always boosting the accuracy rate of the baseline. Its performance boosts are above 1% for Wide-ResNet-50 and CvT-13. EfficientTrain is the best regime for ResNet-18, but it only ranks third and fourth for Wide-ResNet-50 and CvT-13. In contrast, CBM brings the highest accuracy gains for Wide-ResNet-50 and CvT-13, remarkably surpassing all its competitors by more than 1.52% for Wide-ResNet-50 and 2.21% for CvT-13, respectively.\nImageNet is the most challenging benchmark included in our experiments. Still, the trends observed on CIFAR-10 and CIFAR-100 also apply to ImageNet. For example, CBS degrades the performance, just as before. In contrast, LSCL, LeRaC and EfficientTrain outperform the conventional training regime, regardless of the underlying architecture. Yet, CBM stands out as the best training regime, outperforming all competitors by more than 1.64% for ResNet-18.\nThe results reported on Food-101 are mostly consistent with the results reported on ImageNet. CBS is often harmful, while LSCL, LeRaC and EfficientTrain are usually able to increase performance. Still, CBM exhibits the highest gains for all three architectures, showing significant differences with respect to its competitors. For instance, CBM surpasses the second-best regime for CVT-13 by 1.91%.\nIn summary, the object recognition experiments point towards some generic conclusions. The CBS [44] training regime is only useful in some cases. LSCL [12] and EfficientTrain [53] are usually helpful, although they sometimes reduce performance. LeRaC [10] brings consistent accuracy gains, but the improvements are often below 1%. In contrast, the proposed regime, CBM, outperforms the other training regimes on all four data sets and for all three architectures. We performed Cochran's Q statistical testing for conventional training versus CBM. The statistical tests indicate that our performance gains (on all data sets and architectures) are significant, at a p-value of 0.001.\nObject detection. We explore the applicability of the curriculum learning methods on the object detection task, reporting the mAP scores of YOLOv5s on PASCAL VOC [14], while alternating between the six training regimes. The corresponding results are reported in Table 3. The object detection results indicate that LeRaC, EfficientTrain and CBM lead to sizeable improvements, while CBS seems to degrade performance. Our method obtains an mAP of 0.847, outperforming all other regimes. Hence, the object detection results confirm that our approach is a viable curriculum learning strategy."}, {"title": "4.3 Ablation Results", "content": "Curriculum schedules. We present additional results with various curriculum schedules in Table 4. We include the vanilla training regime as a baseline. The constant schedule makes our framework equivalent to that of He et al. [22]. Although He et al. [22] showed that masked auto-encoders reach optimal results in self-supervised learning, we observe that their training regime leads to marginal improvements in supervised learning. However, there are multiple curriculum learning schedules that bring significant performance improvements over the vanilla training regime and the constant schedule, for each combination of model and data set. Thus, the lower accuracy rates of the constant schedule can be attributed to the lack of easy-to-hard curriculum in this type of schedule. Among the considered schedules, the linear, log and linear repeat schedules exhibit the highest performance gains, but the best choice is clearly linear repeat. This observation motivates our use of the linear repeat schedule in the experiments presented in Tables 2 and 3.\nAblation of gradient masking and curriculum. We first study the effect of our gradient-based masking procedure, replacing it with masking based on the uniform distribution of the patches. We jointly assess the influence of the curriculum schedule, as opposed to using a constant masking ratio during the whole training process. We present these experiments on CIFAR-100 in Table 5. Without the curriculum, the gradient-based masking brings accuracy gains for ResNet-18 and Wide-ResNet-50, but not for CvT-13. We performed Cochran's Q statistical tests to assess the significance of gradient-based masking. For ResNet-18 and Wide-ResNet-50, the gains are significant, at p-values of 0.001 and 0.01, respectively. Replacing the constant schedule with the proposed curriculum schedule (linear repeat) improves the accuracy rates of all models. When the easy-to-hard curriculum is activated, the gradient-based masking increases the accuracy, but the improvements seem low. While the results indicate that both our contributions are effective, our curriculum approach has a much higher positive impact on performance. We report the highest gains when combining the gradient-based masking with our curriculum learning schedule, confirming the effectiveness of our joint design. From a practical point of view, we thus judge our contributions as relevant."}, {"title": "4.4 Additional Results", "content": "Augmentation versus curriculum. We underline that the constant schedule is equivalent to simple data augmentation via masking patches. As shown in Table 4 from the main article, the differences between the baseline and the constant schedule (which correspond to data augmentation) and the differences between the constant and linear repeat schedules show that curriculum learning brings higher improvements on CIFAR-100 and ImageNet. Moreover, simple data augmentation degrades performance for CVT-13 on CIFAR-100 and ImageNet. This confirms that the reported improvements are mostly due to curriculum learning.\nTo further show that our curriculum strategy can be applied to other data augmentations, we conduct experiments with CutMix [57] and curriculum learning for CVT-13 on CIFAR-100. As shown in Table 6, the CutMix augmentation does not work at all without the curriculum learning strategies, namely linear and linear repeat. Notably, combining CutMix and masking with the linear repeat curriculum leads to additional gains. These results support our previous observation, namely that the performance gains are rather the effect of employing curriculum learning.\nCompatibility with vision transformers. In Table 2, we report results with CvT for a direct comparison with LeRaC [10], one of our main competitors, which also uses CvT. However, our method is not tied to a certain architecture. To demonstrate this, we conduct additional experiments with ViT [13] on CIFAR-10. The results shown in Table 7 confirm that CBM is also useful for ViT.\nQualitative results. In Figure 6, we include a few examples to illustrate the benefits brought by our curriculum learning method on the classification task. We can see that the model trained with our strategy is able to better discriminate between similar classes. Indeed, the"}, {"title": "5 Conclusion", "content": "In this paper, we proposed a new curriculum learning method based on masking input patches. Our method uses a gradient-based masking procedure in conjunction with a gradually increasing masking ratio to create an easy-to-hard curriculum without having to estimate the difficulty of training samples. To demonstrate the effectiveness of CBM, we carried out a comprehensive set of experiments, considering multiple neural architectures and data sets. Our empirical results show that CBM surpasses the vanilla training regime, as well as four state-of-the-art curriculum learning strategies [10, 12, 44, 53]. Moreover, we performed ablation experiments to justify our design integrating the gradient-based masking and the easy-to-hard curriculum."}, {"title": "6 Supplementary", "content": "In the supplementary, we present more qualitative results to further assess the performance of the proposed curriculum learning strategy in object detection. Additionally, we provide an empirical comparison with CL-MAE."}, {"title": "6.1 Additional Qualitative Results", "content": "Figure 7 includes qualitative results for the object detection task. We observe that CBM performs better than the baseline in all three examples. Moreover, in the first example, CBM is the only method that correctly identifies the dining table."}, {"title": "7 Comparison with CL-MAE", "content": "CL-MAE [37] employs curriculum learning during the pre-training stage of a masked auto-encoder, whereas CBM is used either for fine-tuning or for training models from scratch. Additionally, CL-MAE relies on a learnable module to determine which patches to mask, while keeping the masking ratio constant during training. In contrast, our method utilizes image gradients to mask the salient regions and leverages progressively higher masking ratios to create the curriculum. Moreover, CBM is independent of the underlying network architecture (shown through experiments with various architectures, e.g. ResNet and CvT), while CL-MAE is specifically designed for masked auto-encoders.\nTo provide a quantitative comparison between our method and CL-MAE [37], we conduct additional experiments, applying CBM to the CVT architecture on the Architectural Heritage Elements [29], Sea Animals [50] and Sports Ball [9] datasets, which are used in the CL-MAE paper [37]. The results of these experiments are shown in Table 8. While CBM produces significantly better results, we acknowledge that the training regimes of CL-MAE (pre-training and linear probing) and CBM (fine-tuning) are different."}]}