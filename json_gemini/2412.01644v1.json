{"title": "Concept Based Continuous Prompts for Interpretable Text Classification", "authors": ["Qian Chen", "Dongyang Li", "Xiaofeng He"], "abstract": "Continuous prompts have become widely adopted for augmenting performance across a wide range of natural language tasks. How-ever, the underlying mechanism of this enhancement remains obscure. Previous stud-ies rely on individual words for interpreting continuous prompts, which lacks comprehen-sive semantic understanding. Drawing inspi-ration from Concept Bottleneck Models, we propose a framework for interpreting continu-ous prompts by decomposing them into human-readable concepts. Specifically, to ensure the feasibility of the decomposition, we demon-strate that a corresponding concept embedding matrix and a coefficient matrix can always be found to replace the prompt embedding matrix. Then, we employ GPT-40 to generate a concept pool and choose potential candidate concepts that are discriminative and representative us-ing a novel submodular optimization algorithm. Experiments demonstrate that our framework can achieve similar results as the original P-tuning and word-based approaches using only a few concepts while providing more plausible results.", "sections": [{"title": "Introduction", "content": "Continuous prompts are widely used in NLP with stable performance and easy-hand training com-pared to discrete prompts. However, the introduc-tion of dense prompt tokens compromises the inter-pretability.\nRecent trials exploring the underlying mecha-nism found that models do not rely on context aug-mented by complementary prompt tokens, which is puzzling (Kavumba et al., 2022). Hambardzumyan et al. (2021) suggest that adding non-perceptible perturbation to prompt embedding could bring a different outcome. Khashabi et al. (2022) propose Prompt Waywardness Hypothesis, which means it is impossible to match a continuous prompt with one exact discrete text. Ju et al. (2023) introduce numerous words to mitigate the gap between dis-crete tokens and dense learned embedding. How-ever, generated word explanations may lack com-prehensible and integral semantics. Moreover, due to the infeasibility of discrete words regression to continuous prompt, the inher-ent gap would driven the abuse of words, as shown in Figure 2, simply increasing vocabulary capacity fails to rise up the performance. And word-based methods cannot apply to BPE encoding (Sennrich et al., 2016) based models directly like GPTs (Rad-ford et al., 2018, 2019).\nInspired by Concept Bottleneck Models (CBMs) (Koh et al., 2020), we propose Concept Decom-position (CD) framework, which decomposes the prompt embeddings into concepts. In detail, we start by reclaiming the formulation of the vanilla transformer block, in which we find that the out-puts essentially correspond to linear combinations of column vectors from the outer layer of the Feed-Forward Network (FFN). Based on findings in Geva et al. (2021), we argue that continuous prompts could be decomposed into several compre-hensible fragmented semantic patterns, which can"}, {"title": "Related Work", "sections": [{"title": "Concept Bottleneck Models", "content": "CBMs have garnered significant attention, with spe-cific concepts serving as fundamental units of ex-planation, also known as rationales. These models solve for rationales and combine them to produce outputs. For instance, Yeh et al. (2020) propose a concept discovery method that aims to infer a complete set of concepts. Recently, CBMs have been found to have a backdoor path due to inher-ent structures (Kumar and Talukdar, 2020), which complicates their integration with causal inference. Zhang et al. (2023) propose two casual metrics to identify valid rationales when two or more snippets are highly inter-correlated."}, {"title": "Continuous Prompts and Explanations", "content": "Continuous prompts refer to continuous vectors in-corporated into the input of a prompted language model. These prompts are typically tuned using gradient-based methods, which are directed by the labeled training examples of the tasks (Qin and Eis-ner, 2021; Su\u010dik et al., 2023; Huang et al., 2023; Shah et al., 2023; Liu et al., 2023). Although these prompts generally enhance model performance, their continuous nature poses challenges for human understanding and interpretation (Kavumba et al., 2022; Hambardzumyan et al., 2021; Khashabi et al., 2022; Ju et al., 2023). Hambardzumyan et al. (2021) test whether few-shot prompt-based mod-els depend on shallow cues, the results reveal that simple shortcuts still exist. Khashabi et al. (2022) use adversarial prompts to inject knowledge into models, outperforming manually designed prompts. Ju et al. (2023) propose to use discrete words to explain the continuous prompts in a bag-of-words manner. The interpretations, as shown in Figure 1, made up of words sorted by the learned weights, exhibit fragmented semantics, which impairs plau-sibility."}]}, {"title": "Start From Attention", "content": "In this section, we give a brief formulation on how the continuous prompts can be decomposed into semantically related concepts. Given a prompt aug-mented sequence of token representations T = (t\u2081, \u2026, t\u2099) \u2208 \u211d^(d\u00d7n), and a model with H heads. d is the embedding dim and d\u2095 = d/H. For sim-plicity, we suppose the continuous token is the i-th token. Each Multi-Head Attention (MHA) com-"}, {"title": "Problem Formulation", "content": "Given a training set of text X = {(x\u2097, y\u2097) | l \u2208 |X|}, where x is the text and y \u2208 Y represents a label from a set of N classes. Normally we use X to tune the continuous prompts P\u2208 \u211d^(d\u00d7Nq) with Nq being the number of continuous prompt tokens. Let S be the superset of candidate textual concepts generated from GPT-40 and C \u2286 S be the desired set with N\u0441 concepts.\nWe then initialize concept embeddings C\u2208 \u211d^(d\u00d7N\u0441) and coefficient Q \u2208 \u211d^(Nc\u00d7Nq). Our goal is to decompose the continuous prompts into CQ and ensure the explanation fidelity (Yeh et al., 2019).\nNow we give the following lemma to ensure the decomposition is feasible\u00b9."}, {"title": "Methodology", "content": "As illustrated in Figure 3, our framework prompts GPT-40 to generate a set of candidate concepts for each class (Section 5.1). We employ submodular optimization to greedily select a subset of concepts for each class such that we maximize diversity and coverage scores (Section 5.2). We then initialize the concept embedding C by feeding the concepts into a text encoder and the coefficient embedding Q. Ultimately we design a loss to tune the two embeddings (Section 5.3)."}, {"title": "Generate the Candidates", "content": "We first generate a candidate set of concepts by combining prompts from labeled text. To ensure text diversity, we generate 50 samples and de-sign corresponding prompts for the experimental dataset, as shown in Table 1. Universal prompt templates need to adapt to specific information in the dataset. For instance, in the IMDB dataset (Maas et al., 2011), template 1 will be modified to \"describe what a positive review looks like\". Ad-ditionally, due to the uncontrollability of LLMs (Bhargava et al., 2024), we append auxiliary in-structions following prompts to avoid label leakage. However, even with these precautions, we still find some text instances containing labels. Therefore, we remove parts of the generated text through reg-ular expression matching."}, {"title": "Submodular Optimization", "content": "To ensure that each category contributes equally to each concept, we need to select k relevant concepts for each category y. We use the corresponding"}, {"title": "Optimize Interpretations", "content": "In this section, we introduce the method for solving C and Q. A classic post-hoc explanation system derives the corresponding explanation based on the input and output (Kenny et al., 2021). We require our explanations to stay consistent with original continuous prompts while maintaining the perfor-mance. Based on prior studies (Yeh et al., 2019; Ju et al., 2023), we construct two loss terms to meet these requirements. For mitigating deviation, we introduce the following constraint:\nLf = D\u2096L(P(y|X, P) || P(y|X,CQ))\nwhere P(\u00b7) represents the output probability. For performance retention, we introduce the following constraint:\nLi = -logP(y|X,CQ).\nWe combine these two terms in the following man-ner:\nL = \u00b5Lf + Li\nwith \u00b5\u2208 [0, 1]."}, {"title": "Local Level Interpretations", "content": "In this section, we deliberately introduce our strat-egy for generating explanations. Explaining a con-tinuous prompt is non-trivial. The difficulty lies in the fact that a global explanation may not be plausible enough (Ju et al., 2023). We are more concerned with why a continuous prompt model makes a particular decision given the input and output (i.e. post-hoc manner).\nTherefore, we propose the following local level explanation strategy. For input (x, y)1, we optimize F(Cy) (3) to obtain candidates. Then we select top-k concepts as our explainable concepts sorted by keys derived from Q. The sorting key of Cy,p is calculated as:\nkey(Cy,p) = (\u2211Qp,q) / (Ng-1)"}, {"title": "Experiments", "sections": [{"title": "Experimental Setups", "content": "Metrics and Baselines We investigate the inter-pretability of CD by comparing it to other expla-nation methods using two metrics: accuracy and concept correlation. Following Ju et al. (2023), we use accuracy to assess how well the concept prompt aligns with the continuous prompts. We adopt Discrete-1500 explanation methods as our baseline, with 1500 being the maximum number of vocabularies according to Ju et al. (2023). Inspired by Jin et al. (2020), we introduce a new metric called Concept Correlation, denoted as \u03c1, to eval-uate concept-level explanations. Concretely, we compute the Pearson correlation between the coef-ficients learned by a bag-of-concepts model and the attribution scores provided by various explanation methods. For baselines, we choose three attribution methods to assign scores for each prompt. These scores are comparable to coefficients for explana-tion faithfulness. Specifically we choose Token-SHAP (Goldshmidt and Horovicz, 2024), IG (Sun-dararajan et al., 2017), and grad (Shrikumar et al., 2017).\nDatasets and Backbones Throughout our exper-iments, we primarily study BERT-Large (335M) and GPT-2-Medium (345M) on text classification tasks. In Section 6.2, we utilize the SST-2 (Socher et al., 2013), IMDB (Maas et al., 2011), and AG-News (Zhang et al., 2015) datasets.\nImplementation Details We implement both full and few-shot learning settings (i.e. 4-shot, 8-shot, 16-shot, 32-shot, and full-shot). We design two different types of prompts for each dataset and cus-tomize them to suit diverse datasets. Through-out our experiments, we implement four differ-ent prompt length settings, including 1, 2, 5, 10. Following Liu et al. (2023), we train continu-ous prompts and concept embeddings using the AdamW optimizer with a learning rate of 10\u207b\u2074. We employ early stopping with 100 iteration steps. Additional hyperparameters are provided in the Ap-pendix. Results are reported using five random seeds."}, {"title": "General Results", "content": "We first evaluate CD using accuracy metric across three datasets"}]}, {"title": "Interpretation Visualization", "content": "According to results from Table 3, we choose top-3 concepts as sample explanations because top-5 or top-10 concepts contain noises which decreases the correlations. The examples are provided in the"}, {"title": "Longer Nq Scenario", "content": "To test the performance when Nq increases, we conduct experiments with Nq = 5 and Nq = 10 on SST-2 dataset. The results are reported in Table 5. We can draw the conclusion that CD could apply to scenarios which Nq are larger than 1 and 2."}, {"title": "Conclusion", "content": "In this paper, we introduce CD, a framework to interpret continuous prompts employing generated optimized concepts to decompose the prompt em-beddings. Specifically, we prove that continuous prompts could be decomposed into concepts. Then we prompt GPT-40 to generate candidates and use a submodular optimization algorithm to select the concepts. Finally we design a specific loss tune the concept embeddings and propose a local-level strat-egy to generate explanations. We conduct extensive experiments on three datasets across two typical language model architectures with various prompt types. Results demonstrate that the effectiveness of our framework."}, {"title": "Limitations", "content": "Based on the correlation experiment results, the selected concepts still suffer from noise issue, in this study we only propose a simple heuristic strat-egy to filter irrelevant samples. How to efficiently choose vital concepts needs further exploration."}, {"title": "Proof", "content": "Lemma For any P \u2208 \u211d^(d\u00d7Ng), \u20ac > 0, there exist C\u2208 \u211d^(d\u00d7Nc), Q\u2208 \u211d^(Nc\u00d7Nq) that satisfies ||CQ  P|| \u2264 \u20ac.\nProof. First, it is straightforward that if h(C) = ||CQ \u2013 P||} is convex, then we can obtain a Q* such that ||CQ \u2013 P|| < \u20ac (Zinkevich, 2003). Therefore we only need to prove that h(C) is con-vex. For any \u0421,\nh(C) = ||CQ \u2013 P||} = tr((CQ-P)\u1d40 (CQ-P)).\nTo prove that the function h(C) is convex, we need to show that its Hessian matrix is positive semi-definite for all C. Let's denote the ij-th element of the Hessian matrix as H\u1d62\u2c7c. The Hessian matrix of h(C) is given by:\nHij= \u2202\u00b2h / (\u2202C\u1d62\u2c7c\u2202C\u2096\u2097)\nTo prove convexity, we need to show that for any vector v, v\u1d40Hv \u2265 0.\nHij =  (\u2202\u00b2 / (\u2202C\u1d62\u2c7c\u2202C\u2096\u2097)) (||CQ \u2013 P||).\nUsing the properties of the Frobenius norm, we can rewrite\nHij = (\u2202/\u2202C\u1d62\u2c7c) (\u2202/\u2202C\u1d62\u2c7c) (tr((CQ-P)\u1d40(CQ \u2013 P)))\n= \u2202 / (\u2202C\u1d62\u2c7c) (2(Q\u1d40 (CQ \u2013 P))\u2096\u2097)\n= \u2202 / (\u2202C\u1d62\u2c7c) ((Q\u1d40 (CQ \u2013 P))\u2096\u2097)\n= 2((Q\u1d40Q)\u1d62\u2096\u03b4\u2c7c\u2097),\nd\u2c7c\u2097 is the Kronecker delta. Note that Q\u1d40Q is posi-tive semi-definite, and \u03b4\u2c7c\u2097 \u2265 0, so H\u1d62\u2c7c is positive semi-definite."}, {"title": "Implementation Details", "content": "In this work, all language models are implemented using Transformers. All our experiments are con-ducted on a single A800 GPU, and the results are reported using 5 random seeds (i.e. 1, 42, 100, 999, 17561).\nFor BERT-Large and GPT2-Medium check-points (including MedBERT, LEGAL-BERT and"}, {"title": "Trade-off between Interpretability and Performance", "content": "We conduct an analysis on with how the number of concepts per class (i.e. |Cy|) affect the accuracy performance."}, {"title": "Dataset Statistics", "content": "The statistical information for mentioned six datasets is shown in Table 9."}]}