{"title": "A Survey on Graph Neural Networks for Remaining Useful Life Prediction: Methodologies, Evaluation and Future Trends", "authors": ["Yucheng Wang", "Min Wu", "Xiaoli Li", "Lihua Xie", "Zhenghua Chen"], "abstract": "Remaining Useful Life (RUL) prediction is a critical aspect of Prognostics and Health Management (PHM), aimed at predicting the future state of a system to enable timely maintenance and prevent unexpected failures. While existing deep learning methods have shown promise, they often struggle to fully leverage the spatial information inherent in complex systems, limiting their effectiveness in RUL prediction. To address this challenge, recent research has explored the use of Graph Neural Networks (GNNs) to model spatial information for more accurate RUL prediction. This paper presents a comprehensive review of GNN techniques applied to RUL prediction, summarizing existing methods and offering guidance for future research. We first propose a novel taxonomy based on the stages of adapting GNNs to RUL prediction, systematically categorizing approaches into four key stages: graph construction, graph modeling, graph information processing, and graph readout. By organizing the field in this way, we highlight the unique challenges and considerations at each stage of the GNN pipeline. Additionally, we conduct a thorough evaluation of various state-of-the-art (SOTA) GNN methods, ensuring consistent experimental settings for fair comparisons. This rigorous analysis yields valuable insights into the strengths and weaknesses of different approaches, serving as an experimental guide for researchers and practitioners working in this area. Finally, we identify and discuss several promising research directions that could further advance the field, emphasizing the potential for GNNs to revolutionize RUL prediction and enhance the effectiveness of PHM strategies. The benchmarking codes are available in GitHub: https://github.com/Frank-Wang-oss/GNN_RUL_Benchmarking.", "sections": [{"title": "1. Introduction", "content": "The prediction of Remaining Useful Life (RUL) is a critical component in the field of Prognostics and Health Management (PHM), which aims to predict the future state of a system to ensure timely maintenance and prevent unexpected failures (Wang, Xu, Li, Ren, Dong, Chen, Du, Wang, Shi and Zhang, 2024f; Karatzinis, Boutalis and Van Vaerenbergh, 2024; Zhang, Yuan, Jiang and Zhao, 2024b). Accurate RUL prediction enable predictive maintenance, which can significantly reduce downtime, improve safety, and optimize the lifecycle management of machinery and equipment. Additionally, effective RUL prediction can enhance decision-making processes, improve resource allocation, and reduce maintenance costs. In recent years, deep learning has become increasingly important in RUL prediction due to its ability to model complex patterns and dependencies, providing more accurate and reliable predictions compared to traditional methods, such as statistical approaches (Si, Wang, Hu and Zhou, 2011) and physics-based models (Lei, Li, Gontarz, Lin, Radkowski and Dybala, 2016; Sikorska, Hodkiewicz and Ma, 2011; Li, Zhang, Li and Si, 2024).\nExisting studies in RUL prediction have primarily focused on utilizing temporal encoders such as Temporal Convolutional Networks (TCN) (Qiu, Niu, Shang, Gao and Xu, 2023), Gated Recurrent Units (GRU), Convolutional Neural Networks (CNN) (Shang, Xu, Qiu, Gao, Jiang and Yi, 2024), and Long Short-Term Memory (LSTM) networks. These methods have achieved strong performance due to their ability to capture temporal information, which refers to the time-based patterns and sequences within the data, such as trends and periodic behaviors. However, they are not effective at capturing spatial information, which limits their performance in RUL prediction. Spatial information"}, {"title": "2. Problem Formulation", "content": "Given a sample $X \\in \\mathbb{R}^{S\\times L}$ collected from machines, where $S$ represents the number of channels and $L$ represents the time length, we denote $x_s$ as the signals with $L$ timestamps, i.e., $\\{x_{s,1}, x_{s,2},..., x_{s,L}\\}$, collected from the $s$-th channel. Here, $S$ could be one or more than one, depending on specific downstream tasks. The data $X$ is used to construct the graph $G = \\{V, E\\}$, where:\n\u2022 $V = \\{v_n\\}_{n=1}^N$ represents the set of nodes, with node features $Z = \\{z_n\\}_{n=1}^N$, derived from the signals $X$, where $N$ is the number of nodes. These features could be the raw signals themselves or features extracted through some preprocessing or feature engineering methods.\n\u2022 $E$ represents the set of edges, indicating the connections between nodes. To represent the connections mathematically, the adjacency matrix $A \\in \\mathbb{R}^{N\\times N}$ is defined, encoding the graph structure $G$. Each element $A_{nm}$ in the matrix represents the presence (and possibly the strength) of an edge between node $n$ and node $m$:\n$A_{nm} = \\begin{cases} 1 & \\text{if } (v_n, v_m) \\in E, \\\\ 0 & \\text{otherwise}. \\end{cases}$\nIf the edges have weights to indicate the strength of the relationships, $A$ can be defined as a weighted adjacency matrix:\n$A_{nm} = \\begin{cases} w_{nm} & \\text{if } (v_n, v_m) \\in E, \\\\ 0 & \\text{otherwise}. \\end{cases}$\nThen, the dependency information within the graph can be captured by graph models, learning effective final representations for RUL prediction."}, {"title": "3. Graph Neural Network for RUL prediction", "content": "The overall workflow of GNN for RUL prediction is illustrated in Fig. 2. Time-series data is collected from machines, such as turbofan engines or bearings. Since graphs are implicit within the data, it is necessary to construct graphs to model the spatial-temporal dependencies. Thus, after processing the data, a graph construction module is typically required. With the constructed graphs, graph models and temporal encoders are utilized to capture the spatial and temporal information within the graphs, respectively. Finally, a graph readout function is used to aggregate and extract high-level information from these graphs to predict RUL values."}, {"title": "3.2. Taxonomy", "content": "To better adapt GNNs for RUL prediction, existing works have made significant contributions at different stages of the workflow. Based on this workflow, we introduce a taxonomy, as shown in Fig. 3, to highlight these contributions. This taxonomy includes graph construction, graph models, graph information, and graph readout functions, all of which are critical components to impact GNNs' performance for RUL prediction. Each of these components is further subdivided into fine-grained categories, with a critical analysis provided for each, evaluating the advantages and disadvantages of the various approaches within each component. Notably, temporal encoders are not included in this taxonomy, as we focus on summarizing the contributions of GNNs for RUL prediction."}, {"title": "3.3. Graph Construction", "content": "Given the absence of explicit graphs to represent spatial-temporal information in RUL prediction, graphs are typically constructed before applying GNNs. With a sample $X$, nodes and edges are defined to establish the graph structure. Notably, creating effective graphs for GNN-based RUL prediction necessitates considering the characteristics of the data to accurately define nodes and edges. In the subsequent sections, we delve into the process of graph construction in existing works by detailing the definitions of nodes and edges tailored specifically for this domain."}, {"title": "3.3.1. Nodes", "content": "Node definition involves specifying the properties of nodes $V = \\{v_n\\}_{n=1}^N$, where $N$ represents the number of nodes in the graph, and the features of these nodes are represented as $\\{z_n\\}_{n=1}^N$. Based on the number of available channels, current research to define nodes can be categorized as multi-channel-based and single-channel-based approaches.\nMulti-Channel When monitoring complex machines like turbofan engines in aircraft, multiple sensors are typically deployed to measure various parameters such as fan speed, temperature, and pressure. These sensors can be considered as different channels, and nodes in graphs are defined based on these channels to represent spatial dependencies among these physical parameters. In the case of multiple channels, three main approaches are commonly adopted to define nodes, as shown in Fig. 4, including each channel as a node, channel clusters as a node, and channel expansion.\nFirst, channels can directly correspond to nodes, where $S = N$, indicating that the number of nodes equals the number of channels. Zhang et al. (Zhang, Li, Wei and Jia, 2020) applied GNN to turbofan engines with 14 sensors."}, {"title": "Single-Channel", "content": "In applications where space constraints limit the installation of multiple sensors, such as in compact machinery like bearings, leveraging GNNs for improved RUL prediction from single-channel data has been explored through various approaches. One perspective involves using graphs to model long-range temporal dependencies between timestamps in time-series data $X = \\{X_1, X_2, ..., X_L\\}$. Traditional temporal encoders like TCNs and CNNs"}, {"title": "3.3.2. Edges", "content": "Once nodes are defined, the next step involves establishing connections between them through edges to model their structural information. This is achieved by learning the adjacency matrix $A$ which defines the relationships between nodes $V = \\{v_n\\}_{n=1}^N$. Specifically, this part requires designing a function $A = F(Z)$, where $A_{nm} = F(z_n, z_m)$, aiming to learn edges by considering the properties between nodes. Currently, most methods for learning the adjacency matrix can be categorized into three main types: metric-based, attention-based, and prior-knowledge-based.\nMetric-based Metric-based methods aim to establish connections between nodes based on the similarity or distance metrics computed from their feature representations. Here are six commonly used metric-based methods for learning the adjacency matrix in graph construction: dot-product distance, cosine similarity distance, Pearson Correlation Coefficient (PCC), Euclidean distance, Gaussian kernel weight function, and generalized Mahalanobis distance:\nDot-Product Distance:\n$A_{nm}^{DP} = z_n \\cdot z_m = \\sum_{i=1}^d z_{n,i} \\cdot z_{m,i}$  (1)\nwhere $z_{n,i}$ and $z_{m,i}$ represents the $i$-th feature of channels $n$ and $m$ respectively.\nCosine Similarity Distance:\n$A_{nm}^{CS} = \\frac{z_n \\cdot z_m}{||z_n|| \\cdot ||z_m||}$   (2)\nEuclidean Distance:\n$A_{nm}^{ED} = \\sqrt{\\sum_{i=1}^d (z_{n,i} - z_{m,i})^2}$   (3)\nPearson Correlation Coefficient:\n$A_{nm}^{PCC} = \\frac{\\sum_{i=1}^d (z_{n,i} - \\overline{z_n})(z_{m,i} - \\overline{z_m})}{\\sqrt{\\sum_{i=1}^d (z_{n,i} - \\overline{z_n})^2} \\sqrt{\\sum_{i=1}^d (z_{m,i} - \\overline{z_m})^2}}$  (4)\nwhere $\\overline{z_n}$ and $\\overline{z_m}$ are the mean values of node features $z_n$ and $z_m$ respectively.\nGaussian Kernel Weight Function:\n$A_{nm}^{GK} = exp(-\\frac{||z_n - z_m||^2}{2 \\sigma^2})$   (5)\nwhere $||z_n - z_m||$ is the Euclidean distance between $z_n$ and $z_m$, and $\\sigma$ is a parameter that determines the width of the Gaussian kernel.\nGeneralized Mahalanobis Distance:\n$A_{nm}^{MD} = \\sqrt{(z_n - z_m)^T \\Sigma^{-1} (z_n - z_m)}$   (6)\nwhere $\\Sigma^{-1}$ is the inverse of the covariance matrix of the node features."}, {"title": "Attention-based", "content": "By allowing models to learn node relationships, attention-based methods can well address the mentioned problems. These methods involve three steps: a linear transformation to increase the non-linear expressiveness of each node, calculation attention coefficients to compute weights between nodes, and normalization to restrict connection weights within [0,1]. Here, $\\mathcal{N}(n)$ represents the neighbor nodes of the node $n$, and $f_{att}(Wz_n, Wz_m)$ is normally achieved by $W[Wz_n||Wz_m]$, where $[a||b]$ represents the concatenation operation. It is noted that the attention coefficient part is the core part to obtain edges for node connections.\nLinear Transformation: $z'_n = Wz_n$ (7)\nAttention Coefficient: $a_{nm} = f_{att}(Wz_n, Wz_m)$ (8)\nNormalization: $A_{nm} = \\frac{exp(a_{nm})}{\\sum_{k \\in \\mathcal{N}(n)} exp(a_{nk})}$ (9)\nCurrently, attention-based methods have shown effective for graph construction. For example, Wei et al. (Wei and Wu, 2023b) employed the self-attention mechanism to compute the adjacency matrix from node features, aiming to adaptively generate graph edges. Furthermore, some researchers have leveraged attention as an auxiliary task. Zeng et al. (Zeng et al., 2022) calculated the average and maximum values of each node and concatenated them to determine the attention weight for each node. Nodes with attention weights above a predefined threshold were then connected to form the adjacency matrix. Wang et al. (Wang et al., 2023b) introduced an attention-based framework to learn masks for edge filtering. Initially, they computed the adjacency matrix using node features via a fully connected layer and then derived a masking matrix through node-to-node attentions. The masking matrix was integrated with the graph edges using the Hadamard product to filter edges. Notably, attention-based methods typically involve more trainable weights, which can increase the demand for training data. To address this, Gupta et al. (Gupta et al., 2020) simplified the attention mechanism by eliminating linear transformation weights, thereby reducing the number of trainable parameters and the dependency on extensive training data. Although attention-based methods show promise in fully capturing complex and non-linear relationships between nodes, they still suffer when dealing with limited data. Unlike metric-based approaches that rely on predefined metrics, attention-based methods learn node relationships solely from data. When data is scarce, these methods struggle to learn effective graph structures, making them more prone to overfitting."}, {"title": "Prior-Knowledge-based", "content": "The metric-based and attention-based approaches primarily rely on data for graph construction. However, data bias and noise can adversely impact graph construction, leading to inaccurate graphs that affect GNN-based RUL prediction. To mitigate this issue, some researchers have proposed incorporating prior-knowledge for enhanced graph construction. Most existing prior-knowledge-based approaches utilize knowledge of physical parameters or physical locations. Kong et al. (Kong, Jin, Xu and Zhang, 2022) defined the connections of nodes with their physical relations. Jiang et al. (Jiang et al., 2022) collected data from 15 channels of an electrical system. They constructed graphs by classifying these channels according to physical parameters, such as power factor, reactive power, current. Wang et al. (Wang et al., 2023b) introduced a component graph representing the physical connections between"}, {"title": "Others", "content": "Some works employ unique methods for graph construction that differ from previously discussed approaches. Yang et al. (Yang et al., 2022) defined nodes using shapelets, where the relationship between two nodes is determined by the probability of one shapelet appearing after another. If one shapelet is more likely to follow another, their correlation is considered high, and the graph edge is represented by these probabilities. Wu et al. (Wu et al., 2024) designed a hypergraph by computing hyperedges for nodes, connecting multiple nodes to model high-order relationships. Specifically, KNN is used to filter close samples, and a hypergraph with m hyperedges is produced by grouping these samples with K neighboring samples in Euclidean space to form hyperedges. Multi-resolution hypergraphs are also generated to enhance the effectiveness of the hypergraph."}, {"title": "3.4. Graph Models", "content": "Graph models aim to capture spatial information from the constructed graphs for improved RUL prediction. In this part, we introduce the most widely used GNN models, including spectral convolution and spatial convolution methods, and meanwhile, how they have been applied to RUL prediction."}, {"title": "3.4.1. Spectral Convolution", "content": "Spectral graph convolution pioneers the research to capture the information within graph-structured data by extending the concept of convolution to graphs, enabling powerful neural network architectures for non-Euclidean data. Spectral graph convolution is based on the graph Fourier transform. Consider the constructed graph $G = \\{V, E\\}$ with $N$ nodes and an adjacency matrix $A$. The graph Laplacian $L$ is defined as $L = D \u2013 A$, where $D$ is the degree matrix. The normalized graph Laplacian is $\\mathcal{L} = I \u2013 D^{-1/2}AD^{-1/2}$.\nThe eigen decomposition of $\\mathcal{L}$ is $\\mathcal{L} = U\\Lambda U^T$, where $U$ is the matrix of eigenvectors and $\\Lambda$ is the diagonal matrix of eigenvalues. The graph Fourier transform of a signal $Z$ is defined as $\\hat{Z} = U^T Z$, and its inverse is $Z = U\\hat{Z}$.\nA spectral convolution operation on the graph is defined as:\n$g_{\\theta} * Z = Ug_{\\theta}(\\Lambda)U^T Z$ (10)\nwhere $g_{\\theta}(\\Lambda)$ is a filter applied in the spectral domain."}, {"title": "ChebNet (Chebyshev Spectral Graph Convolution)", "content": "ChebNet, introduced by Defferrard et al. (Defferrard, Bresson and Vandergheynst, 2016), approximates spectral graph convolution using Chebyshev polynomials to avoid the computationally expensive eigen decomposition. The filter $g_{\\theta}(\\Lambda)$ is approximated by a truncated expansion of Chebyshev polynomials $T_k(\\mathcal{L})$:\n$g_{\\theta}(\\mathcal{L}) \\approx \\sum_{k=0}^K \\theta_k T_k(\\mathcal{L})$ (11)\nwhere $\\tilde{\\mathcal{L}} = 2\\mathcal{L}/\\lambda_{max} \u2013 I$, $\\lambda_{max}$ is the largest eigenvalue of $\\mathcal{L}$, and $T_k$ is the Chebyshev polynomial of degree $k$. The convolution operation becomes:\n$g_{\\theta} * Z \\approx \\sum_{k=0}^K \\theta_k T_k(\\tilde{\\mathcal{L}})Z$ (12)\nThis formulation allows for efficient computation of convolutions on large graphs by leveraging the recursive definition of Chebyshev polynomials."}, {"title": "Graph Convolutional Networks (GCNs)", "content": "GCNs, proposed by Kipf and Welling (Kipf and Welling, 2016), simplify the spectral graph convolution further by restricting the filters to be first-order polynomials. The convolution operation in a GCN is:\n$g_{\\theta} * Z \\approx \\theta_0 IZ + \\theta_1 \\mathcal{L}Z = \\theta(I + D^{-1/2}AD^{-1/2})Z$ (13)\nFor computational efficiency and to avoid numerical instabilities, they approximate $\\lambda_{max}$ by 2, leading to the following simplified convolution:\n$Z^{(l+1)} = \\sigma(\\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}Z^{(l)}W^{(l)})$ (14)\nwhere $\\tilde{A} = A + I$ is the adjacency matrix with added self-loops, $\\tilde{D}$ is the degree matrix of $\\tilde{A}$, $Z^{(l)}$ is the feature matrix at layer $l$, $W^{(l)}$ is the layer-specific trainable weight matrix, and $\\sigma$ is an activation function such as ReLU."}, {"title": "3.4.2. Spatial Convolution", "content": "By directly operating on the graphs and aggregating information from a node's neighbors, spatial graph convolution effectively addresses the limitations of spectral methods. This approach models spatial relationships among nodes without relying on spectral properties, facilitating efficient and effective learning on graph-structured data. Two prominent spatial graph convolution approaches are Message Passing Neural Networks and Graph Attention Networks."}, {"title": "Message Passing Neural Networks (MPNN)", "content": "MPNNs, introduced by Gilmer et al. (Gilmer, Schoenholz, Riley, Vinyals and Dahl, 2017), generalize various graph neural networks by defining a framework for message passing and node update. During the message passing phase, each node $u_n \\in V$ aggregates messages from its neighbors. For $T$ message passing steps, the messages $h_n^{(t)}$ and node states $z_n^{(t)}$ are updated as follows:\n$h_n^{(t+1)} = \\sum_{k \\in \\mathcal{N}(n)} M_t(z_n^{(t)}, z_k^{(t)}, A_{nk})$ (15)\n$z_n^{(t+1)} = U_t(z_n^{(t)}, h_n^{(t+1)})$\nwhere $M_t$ is the message function, $U_t$ is the node update function, $A_{nk}$ represents the element of the adjacency matrix, and $\\mathcal{N}(n)$ denotes the neighbors of node $n$."}, {"title": "Graph Attention Networks (GAT)", "content": "GATs, introduced by Veli\u010dkovi\u0107 et al. (Veli\u010dkovi\u0107, Cucurull, Casanova, Romero, Lio and Bengio, 2017), leverage attention mechanisms to weigh the importance of neighboring nodes adaptively. This allows the model to focus on the most relevant neighbors during the aggregation process.\nAttention Mechanism: In GAT, the attention coefficients $\\alpha_{nm}$ between nodes $n$ and $m$ are computed as:\n$\\alpha_{nm} = \\frac{exp(LeakyReLU(a^T[Wz_n||Wz_m]))}{\\sum_{k \\in \\mathcal{N}(n)} exp(LeakyReLU(a^T[Wz_n||Wz_k]))}$ (16)\nwhere $W$ is a learnable weight matrix, $a$ is the attention vector, $||$ denotes concatenation, and $\\mathcal{N}(n)$ represents the neighbors of node $n$.\nNode Update: The node features are updated by computing a weighted sum of the neighbors' features using the attention coefficients:\n$z'_n = \\sigma(\\sum_{k \\in \\mathcal{N}(n)} \\alpha_{nk} WZ_k)$ (17)\nwhere $\\sigma$ is an activation function such as ReLU.\nMulti-Head Attention: To stabilize the learning process, GAT employs multi-head attention, where the above process is repeated $P$ times with independent attention mechanisms, and the results are aggregated:\n$z'_n = ||_{p=1}^P \\sigma(\\sum_{k \\in \\mathcal{N}(n)} \\alpha_{nk}^p W^p Z_k)$ (18)\nwhere $||$ denotes concatenation."}, {"title": "3.5. Graph Information", "content": "Spatial and temporal information has been widely studied in RUL prediction (Xiang, Qin, Luo and Pu, 2021; Zhang, Tian, Li, Leon, Franquelo, Luo and Yin, 2022). With graphs constructed with the aforementioned approaches to model the information, existing can be categorized into three main approaches to capture the information with GNN models, including sequential, parallel, and integrated. The differences of the categories are shown in Fig. 6. The definitions of these categories, their pros and cons, and how they are utilized to capture graph information are detailed in the subsequent sections."}, {"title": "3.5.1. Sequential", "content": "Most existing works capture spatial and temporal information in a sequential scheme, where spatial and temporal information is respectively captured by graph models and temporal encoders, such as CNN (Jiang et al., 2022), TCN (Xing et al., 2023; Zhou and Wang, 2024; Li et al., 2021a), LSTM (Chaoying et al.; Yang et al., 2024; Wang et al., 2023c,e; Wei and Wu, 2023a; Kong et al., 2022), GRU (Wang et al., 2023c; Liu et al., 2023a; Wu et al., 2024), Transformer (Ma et al., 2024; Zhang et al., 2023b; Zhou, Zhang, Peng, Zhang, Li, Xiong and Zhang, 2021), etc., for RUL prediction. Based on the order of capturing spatial and temporal information, existing works can be mainly categorized into two approaches: spatial first and temporal first.\nMost of the existing works adopt the spatial-first approach, where spatial information is initially captured to learn spatial features, followed by capturing temporal dependencies among these spatial features. Kong et al. (Kong et al., 2022) and Wang et al. (Wang et al., 2023c) constructed sequential graphs where spatial information is first captured within each graph, and then temporal dependencies among these sequential features at the node level are captured using LSTM. Kong et al. (Kong et al., 2022) further enhance this by designing an attention sequence embedding layer, learning attention scores to weight the importance of each sequential graph. Similarly, Wen et al. (Wen et al., 2024) also leveraged MPNN to capture spatial information in each sequential graph. Differently, they designed a novel module to capture temporal information by gathering all historical neighbor information across past time steps in a time-decaying manner. Huang et al. (Huang et al., 2024) capture spatial information using a multi-head spatial attention-based GCN. Subsequently, they introduce a multi-head temporal attention-based TCN to compute attentions for nodes in each sequential graph, effectively capturing temporal dependencies.\nIn contrast to the above methods mainly capturing temporal information at the node-level, some researchers focus on capturing temporal information using graph-level features after capturing spatial information. Zeng et al. (Zeng et al., 2022) captured spatial information among frequency components in constructed frequency graphs. They employed a readout function to aggregate features for each graph, followed by capturing temporal dependencies among these graph features using BiLSTM. With the same idea, Liang et al. (Liang et al., 2023) utilized a readout function to learn low-level features after capturing spatial information within each graph. These lower-level features were further processed by Transformer to capture temporal dependencies. Similarly, Zhang et al. (Zhang et al., 2023b) employed GIN to capture spatial information, followed by a designed pooling operation to learn low-level features. Informer (Zhou et al., 2021) was then adopted to capture temporal information. Additionally, Zhou et al. (Zhou and Wang, 2024) constructed three graphs to represent local and global spatial information. They leveraged GAT to capture the spatial information in each graph. Temporal dependencies among these concatenated graph features were then captured using TCN.\nIn the spatial-first approach, capturing spatial information serves as a preprocessing stage, allowing for the learning of better features before applying a temporal encoder to capture temporal dynamics. This method is intuitive and straightforward for introducing GNNs into RUL prediction. However, constructing graphs directly from raw data may lead to inaccuracies in the graph structure. To address this, several methods have been developed based on the temporal-first approach. In this approach, temporal information is first captured to extract meaningful temporal features, which are then used to construct graphs for more effective modeling of spatial relationships (Wang et al., 2023a; Wei and Wu, 2024; Wang et al., 2023d). Zhang et al. (Zhang et al., 2020) introduced TCN to capture temporal information, which was then combined with GCN for spatial information extraction. They further introduced a gating mechanism to control the feature flow for better capturing temporal information. Li et al. (Li et al., 2021b) utilized BiLSTM to learn temporal features, followed by graph construction to model spatial relationships. By fixing the graphs, three GIN"}, {"title": "3.5.2. Parallel", "content": "Parallel-based approaches can address the limitations of the sequential method by capturing spatial and temporal information simultaneously through two parallel branches. These approaches utilize dual processing streams: one for extracting spatial features using graph models and the other for capturing temporal features with temporal encoders. The extracted spatial and temporal features are then concatenated for final representation learning, as illustrated in Fig. 6 (b). For example, Zhang et al. (Zhang et al., 2021) utilized two branches with GCN and TCN to capture spatial and temporal information respectively. Meanwhile, a gating mechanism was introduced for the temporal branch to capture temporal information. Wei et al. (Wei and Wu, 2023b) proposed a self-attention mechanism to generate two parallel temporal-correlated and feature-correlated graphs to represent temporal and spatial information. Both graphs are captured by GCN and then concatenated for final feature representation. Gao et al. (Gao et al., 2024) learned spatial features with a GAT and designed masked temporal multi-head attention to capture temporal information. Then, a designed cross multi-head attention mechanism is used to fuse the spatial and temporal features for RUL prediction.\nTo effectively leverage the benefits of sequential and parallel schemes for capturing spatial and temporal information, some researchers proposed to combine these approaches. Wang et al. (Wang et al., 2021) combined the sequential and parallel schemes by designing two branches. In one branch, GCN and CNN are used for spatial and temporal information respectively, while another branch captures temporal information using TCN. Song et al. (Song et al., 2024) proposed a framework combining both schemes with two routes. Specifically, they designed a spatial route to capture spatial information with GCN and temporal information with LSTM. Simultaneously, a time route was designed to leverage multiple layers of LSTM to capture temporal information.\nCompared to sequential-based methods, parallel can simultaneously capture spatial and temporal information, allowing the model to learn more complex and interdependent features. However, running multiple models in parallel increases computational and memory demands. Most importantly, how to effectively combine features from separate branches can be difficult, potentially leading to suboptimal fusion and reduced performance."}, {"title": "3.5.3. Integrated", "content": "To more effectively integrate spatial and information, researchers propose integrated approaches, where temporal and spatial information are captured in a more comprehensive and unified manner within a single module. This approach does not treat temporal and spatial information as separate phases but rather integrates them into a cohesive process to capture spatial and temporal information simultaneously.\nExisting solutions can be divided into two categories. In the first category, researchers proposed combining graph models with temporal encoders to generate temporal graph models. Yang et al. (Yang et al., 2022) designed a temporal GCN, integrating temporal information into the GCN to achieve information extraction in both temporal and spatial domains. Leveraging the property of GRU to process hidden states from previous timestamps along with current states, the authors introduced spatial features learned by GCN as current states and features from previous timestamps as hidden states, enabling GRU to simultaneously capture spatial and temporal information. Kong et al. (Kong, Jin, Wang and Xu, 2024) developed a similar method by incorporating node features from past timestamps into the message propagation of MPNN, introducing temporal information into the process of capturing spatial information. This approach allows for the simultaneous capture of spatial and temporal dependencies. Wang et al. (Wang et al.,"}, {"title": "3.6. Graph ReadOut", "content": "With graph models to learn node features by capturing the spatial-temporal information, the learned node-level features should be aggregated to produce graph-level features for RUL prediction. Two common readout methods, stacking readout and pooling readout, are employed by existing methods. In stacking readout, all node features are concatenated to learn graph-level features, while in pooling readout, nodes are selectively aggregated using techniques such as SAGPool and DiffPool."}, {"title": "3.6.1. Stacking ReadOut", "content": "In stacking readout, the features of all nodes are concatenated to form graph-level features. Given node features $z_n$ for $n = 1, 2, ..., N$, the stacking readout can be represented as:\n$h_c = ||_{n=1}^N z_n$ (19)\nHere, $h_c$ is the graph-level representation, and $||$ denotes the operation of concatenating node features. This method captures all node information but can be computationally expensive for large graphs."}, {"title": "3.6.2. Pooling ReadOut", "content": "To address these limitations, pooling readout methods have been introduced to aggregate node features hierarchically, aiming to reduce computational complexity while capturing the hierarchical relationships. Two notable pooling methods, SAGPool and DiffPool, have been widely used.\nSAGPool (Self-Attention Graph Pooling) SAGPool, introduced by Lee et al. (Lee, Lee and Kang, 2019), leverages self-attention mechanisms to determine the importance of nodes and perform pooling based on these attention scores. The steps involved in SAGPool are:\nSelf-Attention: Self-attention scores are computed for each node:\n$s = GNN_{att}(Z, A)$ (20)\nwhere $Z = [Z_1, Z_2, \u2026, Z_N]^T \\in \\mathbb{R}^{N\\times f}$ and $GNN_{att}$ is a graph neural network layer used to compute attention scores $s$.\nNode Selection: The neighbors with the $N'$ highest attention scores for each node are then selected for the pooling operation:\n$Z' = Z_{top-k}$ (21)\n$A' = A_{top-k}$\nwhere $Z' \\in \\mathbb{R}^{N'\\times f}$ and $A' \\in \\mathbb{R}^{N'\\times N'}$ are node features and the adjacency matrix of the subgraph formed by the selected nodes, respectively."}, {"title": "Pooled Graph Representation:", "content": "The selected node features are then used to form the new pooled graph representation. This step involves applying another graph neural network layer to the selected nodes:\n$h_c = GNN_{pool"}, "Z', A')$ (22)\nDiffPool (Differentiable Pooling) DiffPool, introduced by Ying et al. (Ying, You, Morris, Ren, Hamilton and Leskovec, 2018), constructs a hierarchy of nodes by learning a differentiable soft clustering assignment matrix, which is used to pool node features hierarchically. The steps involved in DiffPool are:\nAssignments Matrix: An assignment matrix is computed with noded features and their adjacency matrix.\n$S = GNN_{cluster}(Z, A)$ (23)\nwhere $S \\in"]}