{"title": "Multiverse of Greatness: Generating Story Branches with LLMs", "authors": ["Pittawat Taveekitworachai", "Chollakorn Nimpattanavong", "Mustafa Can Gursesli", "Antonio Lanata", "Andrea Guazzini", "Ruck Thawonmas"], "abstract": "This paper presents Dynamic Context Prompt-ing/Programming (DCP/P), a novel framework for interacting with LLMs to generate graph-based content with a dynamic context window history. While there is an existing study utilizing LLMs to generate a visual novel game, the previous study involved a manual process of output extraction and did not provide flexibility in generating a longer, coherent story. We evaluate DCP/P against our baseline, which does not provide context history to an LLM and only relies on the initial story data. Through objective evaluation, we show that simply providing the LLM with a summary leads to a subpar story compared to additionally providing the LLM with the proper context of the story. We also provide an extensive qualitative analysis and discussion. We qualitatively examine the quality of the objectively best-performing generated game from each approach. In addition, we examine biases in word choices and word sentiment of the generated content. We find a consistent observation with previous studies that LLMs are biased towards certain words, even with a different LLM family. Finally, we provide a comprehensive discussion on opportunities for future studies.", "sections": [{"title": "I. INTRODUCTION", "content": "A visual novel game has unique characteristics in offering freedom to players in making choices that potentially affect the course of the storyline and its ending [1]. It is obvious that storylines are a core part of the visual novel experience and what sets it apart from other game genres. This unique characteristic of choice opportunities throughout the story allows the player to interact and choose to branch into a new storyline. We can view a visual novel game as a tree traversal, starting from a root and traversing down the tree based on choices made throughout the storyline, forming a branch and reaching a leaf node at the end of the story. More strictly, visual novel storylines are often represented by a directed acyclic graph (DAG), as there is a possibility that each player may have a different starting node and it is possible for two storylines to merge into the same storyline at some point.\nDespite this fundamental characteristic of visual novels, we found that an existing study [2] utilizing large language models (LLMs) [3] for generating a visual novel game employed a very basic approach for generating a short visual novel game. Not only did their approach not take into account this fundamental property as a graph of visual novel stories, but it also required extensive human labor in extracting the LLM's responses and crafting a game. On the other hand, there already exist studies utilizing LLMs to generate narrative elements compatible with graph-based data [4], showing us the potential for utilizing LLMs to fully generate content as a graph and automatically generate a visual novel game.\nNevertheless, utilizing LLMs to generate a visual novel game is not trivial. LLMs have a limited context window [5], and visual novel games present a challenge in fitting all story branches into a limited context window. Moreover, we discovered that simply prompting LLMs with an initial story data without giving the previous context of the actual story branch does not work well. Therefore, we propose a novel approach in utilizing LLMs to generate graph-based content with a dynamic context window, named dynamic context prompting/programming (DCP/P). We leverage an idea that has already existed in the computer science algorithm community for a long time in solving problems with graphs, called dynamic programming, and common graph traversal algorithms, such as breadth-first search, to craft our novel approach in interacting with LLMs. Furthermore, we also suggest that we can view LLMs as a magical, arbitrary, text-generation function that can be programmed via prompting.\nWe also note that our approach lets LLMs decide almost everything, e.g., who the main characters are, what possible locations are, what possible choices are, how each choice is going to affect the course of the story, and when to use a narrator or a character to progress the story. There is minimal interference from the user of our framework, and most decisions are made by LLMs. However, we also accept a number of arguments from the user to offer control over what type of game is generated and the approximate length of the game; the framework accepts themes that the user wants to focus on for the game, how many chapters exist in the game, what the minimum and maximum number of choices at each opportunity are, and more.\nA visual novel game does not only contain text but also images, hence the word visual in the name. In order to make our approach able to generate a visual novel game, and not simply a text-based adventure game, we also incorporate a mechanism to utilize an image generative model [6] to generate game assets for each game. While audio is another important part of the game experience, we opted not to pursue it in this current study and plan to explore this aspect in the future."}, {"title": "II. RELATED WORK", "content": "In video games, various factors such as graphics quality, physics mechanics, and in-game audio contribute considerably to the player's immersion and enjoyment [8], [9]. Moreover, the depth and sophistication of the game's narrative, including its characters and dialogue, are critical in creating a compelling and engaging experience [10]. A well-written narrative can enhance the player's connection to the game, making narrative design a crucial component of game development [11].\nCreating complex and diverse character-driven stories has traditionally been a challenging task for human writers. How-ever, advances in LLMs have provided significant opportu-nities to automate various aspects of narrative creation [12]. LLMs are now able to generate coherent and contextually rich narratives, supporting the development of dynamic game storylines. Numerous studies have focused on the factors that influence the effectiveness of LLMs in narrative generation,"}, {"title": "III. FRAMEWORK", "content": "In this section, we discuss our framework for generating a visual novel game using generative Als. We detail our proposed approach to prompting/programming LLMs, DCP/P, in Section III-A. Additionally, details on our approach to"}, {"title": "A. DCP/P Approach", "content": "An overview of our approach is shown in Figure 1. The first step of the algorithm is to have an LLM generate story data consisting of seven essential narrative elements: the story title, main scenes (locations), main characters, a story synopsis, chapter synopses, story beginning, and story endings. We allow the LLM to independently generate each element with minimal interference, guiding the generation only with themes, game genre, and other parameters determining the size of the story. These parameters include the minimum and maximum num-bers of choices and choice opportunities, number of chapters, number of endings, number of main characters, and number of main scenes. The prompt used to generate the story data, along with the generated story data, serves as the initial messages in the context window history of the LLM. Once the story data are successfully generated, the process proceeds to generating story chunks.\nOur DCP/P approach draws inspiration from dynamic pro-gramming and breadth-first search methodologies. Each it-eration involves generating a story chunk through LLM in-teraction with the conversation history of the parent chunk, which varies based on each story branch. This dynamic context history is inspired by dynamic programming, where the algo-rithm continuously expands the solution frontier by solving subproblems. Similarly, our DCP/P approach continues to cover subparts of the story by generating story chunks, treating each chunk as a subproblem. A prompt is dynamically chosen based on the current branching type attached to the chunk-to-be-generated information in a frontier.\nThe branching types consist of normal, end-of-chapter, and end-of-game branching. Each story chunk encapsulates crucial narrative elements: the current story progression, detailed narrative events, and decision points that shape the narrative direction. After the story chunk is generated, a list of children is inserted into the processing queue, determined by its branch-ing type. The conversation history used in generating this story chunk is saved within the story chunk data for generating its subsequent children chunks."}, {"title": "1) Context Overflow Policy", "content": "The context overflow policy in our framework plays a crucial role in managing conversation histories efficiently while adhering to token limits. LLMs' token limits are determined from the pre-training time and are an inherent limitation. Therefore, this policy employs a rolling history mechanism to monitor and adjust the accumulated to-ken count within the context of ongoing interactions. Initially, the policy calculates the total token count of the conversation history. If this count exceeds 80% of the maximum allowable tokens, indicating potential overflow, the policy initiates a selective history truncation process.\nDuring truncation, the policy prioritizes retaining recent user messages, ensuring essential context is preserved. It starts from the latest user message and iteratively checks the format and order of preceding assistant messages to maintain conversation coherence. The policy also includes a few initial chunks of story data to provide enough contextual information about the game.\nFurthermore, to optimize resource utilization and ensure sustained performance, the policy limits the total token count to 60% of the maximum tokens after truncation. This threshold ensures that sufficient context is retained. The retained history is integrated back into the conversation flow, and the normal generation process continues."}, {"title": "2) Baseline Approach", "content": "In contrast to our DCP/P approach, the baseline method simplifies the generation process by utilizing only the initial history from the story data generation phase for each interaction with the LLM. Unlike our method, which saves the conversation history within each story chunk generation, the baseline approach does not maintain a detailed record of previous interactions."}, {"title": "IV. OBJECTIVE EVALUATION", "content": "We follow an existing study [2] for objective evaluation of five linguistic aspects of generated stories: 1) coherence, 2) inspiration, 3) narrative fluency, 4) readability, and 5) word complexity. The previous study proposed utilizing LLMs as judges to evaluate narrative content, using generated knowledge prompting [18] to condition the LLM to evaluate based on specific criteria for each aspect. We adopt the same evaluation settings and reuse their prompts for evaluating our stories.\nHowever, our game is more complex than the one in the previous study, as each game consists of multiple story chunks across all story branches. Therefore, we evaluate each story chunk first and then average the objective scores for each aspect. Finally, we compute an average score for each aspect to represent the final standing of each game. We evaluate each game only once, as the sampling temperature is already set to 0 for deterministic behavior, as in the previous study."}, {"title": "V. EXPERIMENTAL SETUP", "content": "We generated a total of 20 stories, with 10 stories for each approach. Each story was generated using three specified themes: \"adventure\", \"high-fantasy\", and \"science fiction\u201d. We selected these themes because they are broad enough for LLMs to be creative about the story, and these LLMs should have a sufficient understanding of these concepts from their training data. The remaining parameters for generating our visual novel games are as follows: three chapters, three endings, five main characters, and five main scenes. We arbitrarily selected these values to ensure an engaging and adequately lengthy story, balancing depth and complexity without overwhelming the generative model.\nTo reduce generation costs, we limited the number of choice opportunities for each chapter to a minimum of 1 and a maximum of 2. To mitigate biases from the story data, we also cross-initialized the story data. This means that there are a total of 10 unique story data sets, and we generated two games from each story data set: one using the baseline approach and another using the DCP/P approach. We utilized Claude 3 Opus as the LLM to generate and decide on each story transition point, choices, casts, scenes, and endings."}, {"title": "VI. RESULTS AND DISCUSSIONS", "content": "We generated a total of 20 games using the method described in Section V. Each game is stored in a graph database and can be visualized similar to what is shown in Figure 2. Across all approaches, there are 649.55 \u00b1 36.49 story chunks per game on average. Separately, there are 577.7 \u00b1 53.29 story chunks on average for games generated using the baseline approach and 721.4 \u00b1 40.45 story chunks for games generated using the DCP/P approach.\nIt is evident that games generated using the DCP/P approach have a higher number of story chunks on average. This difference is due to the fact that the DCP/P approach enables LLMs to better follow instructions in the prompts and reduces the likelihood of deviation from the instructions. We observed instances where the model followed our instruction to generate a specific number of choices-for example, instructing it to generate three choices but only generating one. This occurred more frequently when using the baseline approach. Therefore, the number of choices at each choice opportunity, i.e., the branching factor, is reduced, resulting in a decreased number of chunks.\nThis behavior occurs because the generation model lacks enough context to fully understand the current state of the game and what to generate next, causing it to miss its gener-ation targets. Furthermore, instructing the model to generate structured output in JSON also contributes to this issue, as the model needs to decide and generate not only the content but also syntactical symbols. Contrary to our expectation that generating content using a longer context may confuse the LLM, it actually helps the LLM follow our instructions better."}, {"title": "A. Objective Evaluation", "content": "We performed objective evaluation as described in Sec-tion IV. Out of 20 games, two games were unsuccessful in the objective evaluation, one from each approach. This was due to improperly formatted responses causing the evaluation model to fail to continue. Therefore, we present the objective evaluation results of the remaining 18 games, nine from each approach, in Table I.\nThe game with the highest average objective score is from the DCP/P approach, scoring 6.81 \u00b1 0.36, outperforming the best-performing game from the baseline approach, which scored 6.53. The best game from the DCP/P approach also holds the highest scores in all linguistic aspects except for word complexity. The highest word complexity score is held by the first runner-up, also from the DCP/P approach. Ad-ditionally, all games generated using the DCP/P approach perform better than the best-performing game using the base-line approach, considering the average objective scores. This observation clearly demonstrates the superiority of the DCP/P approach.\nWe also observe that, in general, games generated from the DCP/P approach have high coherence scores. This is anticipated as DCP/P aims to provide the generative model with previous context to generate more coherent story chunks. We discuss this aspect further in the next section on qualitative quality. This trend extends to the inspiration aspect as well. For the inspiration aspect, we aim to assess how consistently the generated game aligns with the specified themes provided at the beginning of the context during the generation process. We observe that DCP/P is better at drawing inspiration from the themes compared to the baseline approach.\nNarrative fluency and readability are related aspects, and we also see that DCP/P-generated games generally have higher scores in these areas as well. The results show that DCP/P not only effectively reminds the model of previous content but also aids the LLM in generating more fluent narrative elements. For word complexity, we observe generally equivalent results from both approaches, with games from the DCP/P approach having slightly higher scores. Therefore, we conclude that word complexity is more related to the LLMs' innate preferences and less dependent on whether it knows the previous context or not."}, {"title": "B. Qualitative Analysis", "content": "While objective evaluation is useful in providing a nu-merical metric to understand the generated content, it falls short in helping us understand the actual qualitative quality of the generated game. Therefore, we conducted a qualitative analysis by closely examining a game with the top score from each approach. We also provide a title and synopsis generated by the model for each game to give an overview of the story. Then, we discuss each game from each approach in subsequent sections.\nThrough our testing, we found that each game generally takes about 15 minutes to play through. The image assets, characters, and scenes are quite impressive. However, the generated images are not perfect. There are instances where the generated characters contain decorative elements, resulting in the background removal model failing to remove these distracting elements. Cases of malformed shapes appearing in the generated scenes or artifacts and solid color borders, such as in Figure 3, are also not uncommon."}, {"title": "1) Baseline: The Chronicles of Zephyr", "content": "The best-performing game generated by the baseline ap-proach, with an ID starting with d979, has the title \"The Chronicles of Zephyr.\" We show screenshots of this game in Figure 3. A synopsis of this game is provided in Section VII-A.\nWe observe that, in general, the story progresses according to the synopsis. However, there are several issues with the coherence of the story. The narrative may progress in a disconnected manner; for example, while the protagonist and the crew are in one place, such as the Ancient Library, they may suddenly jump to another location, like a Sunken City, in the next scene without a proper connection or transition. This sudden transition results in an abrupt and disjointed experience. Moreover, various characters may appear suddenly without a proper introduction. These observations indicate that the LLM did not understand the context well enough to craft a coherent story, which is also reflected in the lower coherence score.\nFurthermore, the LLM is apparently confused regarding the matching between speakers and dialogue lines. For instance, a dialogue line that is supposed to be spoken by Aria, hinted at by the mention of Zephyr's name, is instead assigned to Zephyr. This issue also occurs when referencing certain locations, but the chosen scene does not match up. This extends to mentioning characters' names that never exist in the story, such as Aurora and Kai, causing confusion and showing signs of hallucination [25]. It is clear that without sufficient context, the LLM is not only unable to generate a coherent story but also struggles with smaller narrative elements and simple tasks like choosing the correct scene picture.\nAs previously mentioned, there also appears to be an issue with the LLM stopping the generation of choices too early, resulting in fewer choices than specified. Consequently, there are instances when a choice screen is shown, but only one choice is available for selection. Therefore, the story lacks depth in its progression."}, {"title": "2) DCP/P: Celestial Odyssey", "content": "Similar to the previous sub-section, we show screenshots from the best performing game generated by DCP/P approach in Figure 4. This game has an ID starts with d979 and a title of \"Celestial Odyssey\". A synopsis of this game is available in Section VII-A.\nFirst, it is worth noting that the synopsis of this game is similar to the previous one, even though they both originate from different story data. The information we conditioned to the LLM includes themes, while the rest is left open to the LLM's imagination. This similarity shows that LLMs lack creativity and are influenced by their probability distribution resulting from the training process. Similar observations were also made by previous studies [7], [26]. We note that we utilized a default sampling temperature for the LLM, and we may gain a more diverse response if we increase the sampling temperature. However, increasing the sampling temperature also increases the chance of generating unrelated tokens, resulting in a higher failure rate for JSON structured output generation.\nStory-wise, this game has a more coherent story compared to the game generated from the baseline approach. We also ob-serve that this game has smoother transitions and cues before moving the protagonist and the team to another location. For example, a supporting character may inform them that they need to visit a certain place to learn more about something or obtain certain artifacts. Another interesting note is that the story also progresses with an epilogue, i.e., what happens to the world after the protagonist completes their quest to save"}, {"title": "3) Discussions", "content": "The story progression of the games is quite standard and involves elements commonly found in this genre. The story progresses by having the protagonist embark on a quest to restore his memory and find the true purpose of his life. Throughout the journey, they visit various places and solve problems for the citizens of these places. While there is nothing inherently wrong with this story progression style, it highlights an area where further improvement is possible.\nThe story style heavily depends on the prompt that instructs the LLM. In our case, we kept the initial prompt quite simple due to the nature of our work focusing on introducing the framework. To improve further, one may utilize expert prompt-ing [27] to help the LLM generate a story with more depth and an interesting narrative style. Role prompting [28] also shows potential in further improving the generation of more consistent dialogue and helping the LLM stay in character. We acknowledge that there is room for improvement in prompts.\nAnother issue that often arises in the game generated from the baseline approach is the occurrence of black screens and unknown characters. In our current framework, we instruct LLMs to only utilize existing scenes and characters that were pre-generated in the first step of the algorithm. While there are cases when LLMs exhibit their creativity by using never-before-generated characters and scenes, there are also times when they fail to select the correct character and scene, resulting in such experiences.\nOne way to improve this further is to trade-off with gen-eration cost by decomposing the task. We can first generate the dialogues and story and then have another round of LLM interaction to select the best scenes and characters or entirely generate new ones. We plan to explore this aspect further in our future work."}, {"title": "C. Word Choice Biases", "content": "We follow an existing study style of investigation [7], [26] on biases resulting from LLMs' training data distribution. We collect all words utilized in the games of each approach and apply standard text pre-processing steps, i.e., tokenization, and removal of single character, stop words,pych' and punctuation. We then visualize word frequency as a word cloud for each approach in Figures 5a and 6a.\nOverall, we observe that word distributions of the games generated from each approach are similar. The most frequent word is \"Aria\", which should not be surprising as this character often plays an important role in the story. However, the next most frequent words show us how LLMs are biased towards very similar stories for each game. \"Celestial\" indicates that given the specified theme, the LLM always connects these to certain themes, reinforcing our previous observation that LLMs are unable to generate entirely creative and novel stories. The generated stories often reflect the most common occurrences in their training distribution.\nMore concerning is the appearance of the word \"Power\". We use Claude 3 Opus as our text generative model, different from previous studies [7], [26], which utilized GPT-3.5 Turbo"}, {"title": "D. Word Sentiment Biases", "content": "We also conducted an investigation on biases towards certain sentiments, i.e., positive or negative. We utilized a sentiment word list [29] that was previously used in a similar study [7]. We counted the number of occurrences of words from the list, either positive or negative, that appeared in the entire game across all games for each approach. We note that we pre-processed the text as described in the previous subsection before counting. We present the results in Table II."}, {"title": "E. Limitations and Future Work", "content": "In this paper, we demonstrate the potential of utilizing various generative models to create a visual novel game. LLMs are employed for generating text content and deciding story progression, while an image generative model is used for character and scene asset generation. We acknowledge the potential for incorporating audio generative models [32], [33] and the various aspects that could be improved in the generation process and the quality of the generated game.\nWe only tried Claude 3 Opus in this paper, but there are various other LLMs and image generative models available. One drawback of utilizing state-of-the-art LLMs is the long inference time, and we are intrigued by how our approach may generalize to smaller LLMs. There are reliability issues with LLMs that could be improved further, such as utilizing tools like Instructor2 or function calling\u00b3 for better structured output generation.\nTechniques commonly deployed for LLM-integrated sys-tems, such as retrieval-augmented generation [34], are worth further exploration to personalize story branches. We also plan to conduct a subjective evaluation to understand how humans perceive the games generated by LLMs and explore different subgenres of the game. We note the potential of this algorithm to go beyond visual novel games and generate any type of graph-based content."}, {"title": "VII. CONCLUSIONS", "content": "We propose DCP/P, a framework for generating a visual novel game using generative models. Our framework utilizes a dynamic context to generate a coherent narrative branch at each point in the game story. Our algorithm is able to generate content and store it in a graph database, using our developed web interface to display and provide a game experience. We evaluate our proposed approach against a baseline that interacts with an LLM without providing previous context but only the story data. We show that games generated from the DCP/P approach are better than games generated using the baseline approach based on our objective evaluation of various linguistic aspects.\nWe also perform a qualitative analysis on the best-performing game of each approach. We observe a more coherent story and better transitions between story chunks in a game generated using the DCP/P approach. Following existing studies, we conduct word bias and sentiment analyses, finding that even with a different LLM family from previous studies, the LLM still exhibits biases towards certain words. We also provide various suggestions for further improving the DCP/P algorithm. We conclude that generative models show potential for generating a visual novel game when utilized properly."}, {"title": "APPENDIX", "content": "In this subsection, we provide a synopsis of the best-performing game from each approach. This information should aid in understanding our qualitative analysis and discussion. Figure 7 shows a synopsis of a game generated using the baseline approach, and Figure 8 shows a synopsis of a game generated using the DCP/P approach. Additional screenshots of the games generated from the baseline and DCP/P ap-proaches are available in Figures 9 and 10, respectively."}, {"title": "B. Additional Details of the Framework", "content": "We design various prompts for different pur-poses in interacting with generative models. There are a total of five prompt templates for an LLM that we designed for different purposes. Each prompt template utilizes a pattern of template [35] to specify JSON structured output template. This decision is made to aid in the automation process of output extraction by supporting systems. We also incorporate a JSON magic phrase in all prompt templates to enhance the reliability of generating a structured output. This phrase is adapted from a phrase used to improve the reliability of LLMs in generating a Markdown code block for level generation tasks [36].\nThe first prompt template is a plot prompt. The plot prompt instructs the LLM to generate story data, including informa-tion such as title, synopsis, and chapter synopses, given the specified arguments. The second and third prompts are used to generate a story chunk before the ending of a chapter or game. The differences between these two prompts are whether we provide information on a selected choice or not. However, they are largely the same, providing information about the current chapter out of all chapters, current chapter synopsis, and selected choice in the case of the prompt used to generate a story chunk based on a story choice. It is crucial to note that our prompt instructs an LLM to generate a story that progresses by multiple dialogues by a character or a narrator as an array of complex objects. The LLM is also instructed to generate a summary of the story so far. This approach ensures that the LLM is grounded in the current story before generating a new part.\nFinally, the fourth and fifth prompts are used to generate a story chunk that serves as a chapter ending chunk or game ending chunk (leaf node). Both prompts share similarity in the instruction. However, in the case of the chapter ending prompt, we also provide the next chapter synopsis, while in the game ending prompt, we provide information on the selected game ending.\nAside from these prompt templates for the LLM, we also craft two additional prompt templates for image generative models used to generate assets for characters and scenes. For character assets, we instruct a model to generate a profile im-age of a 2D character based on their basic profile information, i.e., name, age, gender, species, and their physical appearance. On the other hand, the scene prompt is based on the scene name, location, and description."}, {"title": "2) Supporting Systems", "content": "Our framework utilizes Neo4J4, a graph database, to facilitate efficient data management and retrieval. By leveraging Neo4J's graph-based structures, we can manage interconnected data effectively, supporting the dynamic creation of story branches and decision paths. This capability enhances our platform's ability to adapt and scale, providing robust support for a wide range of interactive storytelling and content creation applications. As previously stated, we can structure a typical visual novel game's story as a graph. Therefore, a graph database is very suitable for storing this type of data.\nAdditionally, our framework includes an orchestration pro-gram with a retry mechanism. The retry mechanism enhances the reliability of content generation by attempting to generate content multiple times until success or exhaustion of retries. LLMs are not perfect due to their inherent stochastic nature; therefore, the generation of malformed structured output is un-avoidable. The mechanism ensures robustness against transient errors or validation issues encountered during the generation process. Each attempt involves validating the generated story chunk and associated choices, logging validation errors or exceptions, and incrementing the retry counter. If all attempts fail to produce valid content, the mechanism logs detailed error messages and exits the script.\nWe also leverage DALL-E 3 [37], an advanced image gen-erative model from OpenAI. We employ this model to create diverse visual assets through customized prompts, designed to generate high-quality images while avoiding undesirable attributes. In addition, our framework utilizes BriaRMBG-1.45, an advanced background removal model that uses deep learning techniques to seamlessly remove backgrounds from images. Integrated into our system, BriaRMBG-1.4 processes character and scene images for background removal while preserving image quality. This step enhances the immersive experience of the game."}, {"title": "3) Web Game Interface", "content": "We develop our own web game interface that communicates with the graph database to display any games generated by the LLM. Our game interface allows users to play the visual novel with the ability to choose any available options. While there are many potential features that exist in a typical visual novel game, we keep this initial version of the game interface minimal. We expect that the game interface will be improved over time as the algorithm evolves with new features.\nWe decide to use web technology as our main platform because it requires no installation on the player's part and enables them to experience the game easily. Web technology also supports responsive design, allowing us to provide an experience on mobile devices as well. We also implement a fallback mechanism to display a default image for a character or a scene. Since LLMs are not perfect and there is a chance that a model might select a non-existent character or scene to display, this mechanism helps provide a smoother gameplay experience."}]}