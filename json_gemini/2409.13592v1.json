{"title": "YesBut: A High-Quality Annotated Multimodal Dataset for evaluating\nSatire Comprehension capability of Vision-Language Models", "authors": ["Abhilash Nandy", "Yash Agarwal", "Ashish Patwa", "Millon Madhur Das", "Aman Bansal", "Ankit Raj", "Pawan Goyal", "Niloy Ganguly"], "abstract": "Understanding satire and humor is a challeng-\ning task for even current Vision-Language mod-\nels. In this paper, we propose the challenging\ntasks of Satirical Image Detection (detecting\nwhether an image is satirical), Understanding\n(generating the reason behind the image being\nsatirical), and Completion (given one half of\nthe image, selecting the other half from 2 given\noptions, such that the complete image is satiri-\ncal) and release a high-quality dataset Yes But,\nconsisting of 2547 images, 1084 satirical and\n1463 non-satirical, containing different artistic\nstyles, to evaluate those tasks. Each satirical\nimage in the dataset depicts a normal scenario,\nalong with a conflicting scenario which is funny\nor ironic. Despite the success of current Vision-\nLanguage Models on multimodal tasks such as\nVisual QA and Image Captioning, our bench-\nmarking experiments show that such models\nperform poorly on the proposed tasks on the\nYesBut Dataset in Zero-Shot Settings w.r.t both\nautomated as well as human evaluation. Addi-\ntionally, we release a dataset of 119 real, satiri-\ncal photographs for further research\u00b9.", "sections": [{"title": "1 Introduction", "content": "Satire is a form of humor that uses irony or exag-\ngeration to criticize or mock people, politics, or\nsociety. It serves as a powerful tool to highlight\nissues, provoke thought, and often encourages a\ncritical perspective on the subject matter. Satiri-\ncal images posted on social media often consist\nof conflicting scenarios to convey irony and hu-\nmor. Understanding such conflicting scenarios re-\nquires understanding interaction among entities and\ntext (if any) within the image, along with common-\nsense knowledge and reasoning capabilities. Fig.\n1 shows an example image conveying satire. The\nirony in the image is that the person is messaging\nsomeone a very heartfelt message on the mobile,\nwhile sitting on a toilet seat!\nPeople convey humor on the internet and social\nmedia using images, GIFs, and videos. Previous\nstudies have shown that memes (Buchel, 2012) and\nTV show Clips (Attardo et al., 2003) are prevalent\nmeans for expressing such humor. There have also\nbeen attempts at detecting (Hasan et al., 2019; Cas-\ntro et al., 2019; Tanaka et al., 2022) and describing\n(Hwang and Shwartz, 2023) multimodal satire and\nhumor. However, very few works have simulta-\nneously studied the detection, understanding, and\ncomprehension of satirical situations in society in\nthe multimodal setting.\nThere has been a rise in the development of\nVision-Language (VL) models (Liu et al., 2023;\nHuang et al., 2023; Peng et al., 2023; Zhu et al.,\n2023; OpenAI, 2023; Team, 2023). Such models\nhave shown remarkable State-Of-The-Art (SOTA)\nperformance on several downstream tasks such as\nVisual Question Answering and Image Captioning.\nSuch models are pre-trained in a manner that im-\nages and text have shared embedding space, and\nthat, images and their corresponding text descrip-\ntions have similar representations in that embed-\nding space (Radford et al., 2021; Zhai et al., 2023)."}, {"title": "2 Background", "content": "Previous works on satire and humor in NLP and\nComputer Vision mostly revolve around detecting\nsatire in text (Rogoz et al., 2021) and multimodal\nscenarios (Li et al., 2020; Ionescu and Chifu, 2021),\ndetecting humor in multimodal scenarios (Hasan\net al., 2019; Castro et al., 2019), meme caption-\ning (Hwang and Shwartz, 2023), etc. However, no\nsuch work performs a comprehensive and simul-\ntaneous evaluation of satire and humor detection,\nunderstanding, and comprehension capabilities of\nVL Models in Multimodal Scenarios."}, {"title": "2.2 Other Image Datasets", "content": "The WHOOPS benchmark, introduced by Bitton-\nGuetta et al. (2023), comprises unconventional im-\nages challenging commonsense expectations, both\nhuman-created and machine-generated, accompa-\nnied by corresponding textual descriptions. Specif-\nically designed for tasks such as image captioning,\nimage-text matching, visual question answering,\nand explanation generation, it provides a unique\ndataset for evaluating model performance in these\ndomains. In contrast, our work performs a holistic\nevaluation of different SOTA VL Models on their\nability to detect, understand, and comprehend satire\nin images."}, {"title": "3 Our Annotation Pipeline", "content": "The entire data collection and annotation pipeline\nis shown in Fig. 2. We curated a collection of\nannotated satirical and non-satirical images in this\nsection in 4 stages."}, {"title": "3.1 Stage 1: Collecting Satirical Images from\nSocial Media", "content": "We manually downloaded images from the posts in\n'X' (erstwhile known as Twitter) handle @_yesbut_\n(with proper consent). We manually filtered 283\nimages that are satirical, and annotated them in the\nnext stage. Each image contains two sub-images\n(which are colorized sketches), one on the left\nshowing a normal scenario, while one on the right\nis ironical/pokes fun at the left sub-image."}, {"title": "3.2 Stage 2: Annotation of satirical images", "content": "Textual descriptions and certain categorical fea-\ntures of satirical images were annotated using 5\nannotators, all of whom met the qualification cri-\nteria of being undergraduate sophomore students"}, {"title": "3.3 Stage 3: Generating 2D stick images using\nDALL-E 3 on the annotated descriptions", "content": "To increase the size and the diversity of the dataset,\nwe use the DALL-E 3 (Betker et al., 2023) image\ngeneration model to generate synthetic sub-images\nusing the annotated left and right sub-image de-\nscriptions (obtained in Stage 2). We use the fol-\nlowing prompt - \"Draw using stick figures (black\nsilhouette against a white background) - <SUB-\nIMAGE DESCRIPTION>\". Given the original\nsub-images, 3 new combinations of sub-images\nare obtained ([original left sub-image, generated\nright 2D stick sub-image], [generated left 2D stick\nsub-image, original right sub-image], [generated\nleft 2D stick sub-image, generated right 2D stick\nsub-image]). We manually label each new com-\nbined image as satirical or non-satirical (details of\nthis manual labelling is given in Section C.3 of\nAppendix). At the end of the image generation fol-\nlowed by manual labelling, we end up adding 302\nsatirical and 547 non-satirical images. Each satir-\nical image generated is assigned the same textual\ndescriptions as the original image."}, {"title": "3.4 Stage 4: Generating 3D stick images using\nDALL-E 3 on the annotated descriptions", "content": "Similar to Stage 3, we further increase the size and\ndiversity using DALLE-3. We use the following\nprompt - \"Draw using 3D black silhouettes against\na white background - <SUB-IMAGE DESCRIP-\nTION>\". Given the original sub-images and the\nsub-images generated in Stage 3, 5 new combi-\nnations of sub-images are obtained ([original left\nsub-image, generated right 3D stick sub-image],\n[generated left 3D stick sub-image, original right\nsub-image], [generated left 2D stick sub-image,\ngenerated right 3D stick sub-image], [generated\nleft 3D stick sub-image, generated right 2D stick\nsub-image], [generated left 3D stick sub-image,\ngenerated right 3D stick sub-image]). We manu-\nally label each new combined image as satirical or\nnon-satirical. At the end of the image generation\nfollowed by manual labelling, we end up adding\n499 satirical and 916 non-satirical images. Each\nsatirical image generated is assigned the same tex-\ntual descriptions as the original image."}, {"title": "4 The Yes But Dataset", "content": "The Yes But dataset has a total of 2,547 images,\n1.084 of which are satirical, the rest 1,463 images\nbeing non-satirical. These images spread across 3\ndiverse artistic styles - colorized sketch, 2D stick\nfigure, 3D stick figure.\nThe satirical images cover several aspects of so-\ncietal satire. To analyze this, we use topic modeling\non the left and right sub-image descriptions using\nBERTopic (Grootendorst, 2022). We get 7 topics\n(each topic being an unordered set of representative\nwords), which are further elaborated using Chat-\nGPT to get intuitive descriptions for each topic\n(refer to Section D of Appendix).\nWe further visualize the diversity of these sub-\nimages by plotting the compressed 2D image repre-"}, {"title": "5 Experimental Setup", "content": "We report the performance of various SOTA VL\nModels (described in Sec. 5.1) for performance\nevaluation on the tasks (described in Sec. 5.2) de-\nvised for the YesBut Dataset. The evaluation setup\nand experimental results are described in Sec. 5.3\nand 5.4, respectively."}, {"title": "5.1 Models", "content": "Gemini. Gemini (Team, 2023) is a closed-source\nfamily of Large Multimodal Models (LMMs) from\nGoogle. The Gemini project comprises Ultra, Pro,\nand Nano variants, designed to excel in image and\ntext comprehension. These models cater to di-\nverse applications, from intricate reasoning tasks to\nmemory-constrained on-device scenarios. Notably,\nthe Gemini Ultra model demonstrates SOTA per-\nformance across 30/32 benchmarks. Furthermore,\nit outperforms existing models in all 20 multimodal\nbenchmarks examined. The Gemini models show-\ncase remarkable capabilities in cross-modal rea-\nsoning and language understanding. We leverage\nGemini Pro Vision API for all tasks in our paper.\nGPT4. GPT4 (OpenAI, 2023) is an advanced,\nclosed-source multimodal model capable of pro-\ncessing both image, text inputs to generate coherent\ntextual outputs. GPT4 demonstrates human-level\nproficiency across professional, academic bench-\nmarks. It achieves commendable performance,\nranking within the top 10% of test takers in a\nsimulated bar exam. Operating on an Autoregres-\nsive Transformer-based architecture (Vaswani et al.,\n2017), GPT4 undergoes pre-training to predict sub-\nsequent tokens in a document. The subsequent\npost-training alignment enhances its performance\nin terms of factuality and adherence to desired be-\nhavior. We use gpt-4-vision-preview API for\nall tasks in our paper.\nLLaVA. LLaVA (Large Language and Vision As-\nsistant), proposed by Liu et al. (2023), utilizes vi-\nsual encoder from pre-trained CLIP (Radford et al.,\n2021) along with LLaMA (Touvron et al., 2023)\nlanguage model. The approach involves instruction\ntuning on visual instruction data assisted by GPT4\n(OpenAI, 2023) for enhanced performance.\nMiniGPT4. MiniGPT4 (Zhu et al., 2023) has\nfrozen pre-trained language and vision components.\nIt utilizes a singular projection layer to align visual\nand language features. Notably, it exhibits analo-\ngous capabilities to GPT4 in comprehending con-\ntext. MiniGPT4 uses Vicuna (Chiang et al., 2023)\nlanguage model, built upon LLaMA-13B, demon-\nstrating performance on par with ChatGPT. In the\ndomain of vision, it integrates BLIP-2 (Li et al.,\n2023), comprising CLIP ViT-G/14 (Radford et al.,\n2021) and a Q-Former (Zhang et al., 2024) archi-\ntecture. Training MiniGPT4 encompasses diverse\nmultimodal datasets, incorporating images from\nLAION (Schuhmann et al., 2022), Conceptual Cap-\ntions (Sharma et al., 2018), and SBU (Ordonez\net al., 2011)."}, {"title": "5.2 Tasks", "content": "We describe the tasks that are evaluated on the\nYes But Dataset -\nSatirical Image Detection: This is a binary clas-\nsification task, where given an image, the model\nneeds to predict whether the image is satirical or\nnot. This task is carried out on all the 2547 images.\nSome example input images, along with input the\ntext prompt used for all images is mentioned in\nSection E.2 of Appendix.\nSatirical Image Understanding: Given a satiri-\ncal image, we evaluate the model's satire under-\nstanding capability in images by (1) prompting the\nmodel to generate a textual description of each sub-\nimage as input, using the prompt \u201cDescribe the\nimage\". (2) prompting the model to generate the\npunchline in the image using the following prompt\n(referred to as \u201cWHYFUNNY_PROMPT\" here-\nafter) - \"Why is this image funny/satirical?\". This\ntask is carried out on only the 1084 satirical images\nof the Yes But Dataset.\nSatirical Image Completion: Given either the left\nor right sub-image having the style of a colorized\nsketch, the other sub-image needs to be chosen\nfrom two options, one having a 2D, and the other\nhaving a 3D stick figure style, such that the en-\ntire image so formed is meaningful and satirical.\nThe options are curated based on existing satirical\nand non-satirical images from the YesBut Dataset.\nWe curate 150 such samples for evaluation. Some\nexample input images, along with input the text"}, {"title": "5.3 Evaluation Setup", "content": "Satirical Image Detection: We use Zero-Shot and\nZero-Shot Chain-of-Thought (CoT) (Kojima et al.,\n2022) setups for inference, and metrics used for bi-\nnary classification such as Accuracy and F1-Score\nfor evaluation.\nSatirical Image Understanding: We use Zero-Shot\nsetup for inference, and standard metrics for au-\ntomatic evaluation of text generation-based tasks\n- lexical overlap metrics such as BLEU (Papineni\net al., 2002), ROUGE-L (Lin, 2004), and METEOR\n(Banerjee and Lavie, 2005), and semantic similarity\nmetrics such as BERTScore (Zhang* et al., 2020)\nto evaluate the image understanding capabilities\nof the images and corresponding sub-images (we\nalso experiment with an image-based evaluation\nmetric Polos (Wada et al., 2024), whose results\nare shown in Section E.4 of the Appendix). Ad-\nditionally, we randomly sample 30 images (10 im-\nages from each obtained in Stage 2, Stage 3, Stage\n4) along with their model-generated and human-\nwritten overall image descriptions. Each image\ndescription is human-evaluated based on the fol-\nlowing (binary) criteria (adopted from (Hwang and\nShwartz, 2023) and slightly changed to better suit\nevaluation on YesBut) - (1) Correctness: Is the im-\nage description correctly able to convey the satire\nthe image wanted to convey? (2) Appropriate\nLength: Is the image description length appropri-\nate for conveying the meaning (i.e. it is not too\nverbose)? (3) Visual Completeness: Does the im-\nage description describe all the important elements\nin the image? (4) Faithfulness: Are all the ele-\nments of the image description supported by either\nthe visual or text elements (i.e. there are no made-\nup elements)? - The annotation is carried out by 3\nstudents in the lab, and the majority vote is taken\nfor each image.\nSatirical Image Completion: We use Zero-Shot and\nZero-Shot CoT setups for inference. and accuracy\nas the evaluation metric.\nNote that we do not use In-Context Learning\nSetting for inference because this would make the\ntasks less challenging for the models. Also, we\nwant to analyze how well VL models can compre-"}, {"title": "5.4 Results", "content": "Satirical Image Detection: Table 3 shows the re-\nsults of satirical image detection capability of VL\nModels on the Yes But Dataset. We can infer that -\n(1) Kosmos-2 in zero-shot CoT and zero-shot set-\ntings give the best test accuracy and F1 Score re-\nspectively due to its superior visual grounding ca-\npabilities (2) Improvement in test accuracy and F1\nScore due to CoT is seen only in 2/5 and 1/5 mod-\nels respectively, suggesting that SOTA VL Models\nare unable to properly reason/rationalize whether a\ngiven image has an element of satire in it (3) Both\ntest accuracy and F1 Score do not cross 60% for\nany SOTA VL Model, suggesting that there is a\nsignificant scope for improvement when it comes\nto detecting satire/humor in a given image.\nSatirical Image Understanding: Fig. 5 shows the\naverage value of the 4 automated metrics (discussed\nin Sec. 5.3) to evaluate satirical image understand-\ning capability of VL Models at different stages of\nannotation of YesBut (see Table 6 in Section E.4\nof Appendix to get individual values of the evalua-\ntion metrics, along with performance variation w.r.t\nannotation difficulty and presence of text in im-\nages). We observe that - (1) There is a reduction in\nthe overall understanding capability (average met-\nric corresponding to \u2018WHYFUNNY PROMPT')\nof the majority of models in Stages 3 and 4 com-\npared to Stage 2, as images in Stages 3 and 4\nhave different artistic styles in the same image, un-\nlike Stage 2 (2) Kosmos-2 almost always performs\nbetter than other open-source models LLaVA and\nMiniGPT4, as Kosmos-2 has multimodal ground-\ning and referring capabilities, which LLaVA and\nMiniGPT4 do not have (3) 4 out of 5 models do not\nunderstand the entire image better than sub-images"}, {"title": "6 Summary and Conclusion", "content": "We present YesBut, a high-quality annotated mul-\ntimodal dataset for Satire Comprehension Evalua-\ntion. Our work is one of the first to systematically\nbenchmark multimodal Satire Comprehension abil-\nity of SOTA VL Models by proposing 3 non-trivial\ntasks of Satire Detection, Understanding, and Com-\npletion. We observe that SOTA VL Models strug-\ngle in those tasks, as YesBut, unlike other bench-\nmarks, contains images with sub-images having\ndifferent artistic styles and no text in most cases,\nmaking Yes But a challenging multimodal dataset\nfor satire detection and comprehension."}, {"title": "7 Limitations", "content": "Subjectivity of annotations: The annotation task\ninvolves utilizing background knowledge that may\ndiffer among annotators. Consequently, we manu-\nally reviewed the annotations to minimize the num-\nber of incorrect annotations in the dataset. How-\never, some subjectivity still remains.\nExtension to languages other than English: This\nwork is in the English Language. However, we\nplan to extend our work to languages other than\nEnglish."}, {"title": "A Introduction", "content": "Dataset of real, satirical images: We collected\na dataset of 119 images containing irony, satire\nfrom instagram posts by different users, who re-\nsort to using \u201cYes, But\u201d theme over real photos\n(e.g. see Figure 6). We perform following 2 tasks\non these images - (1) Satirical Image Detection,\nwhere we report detection accuracy, as all images\nhave ground truth of \"Satirical\u201d (2) Satirical Image\nUnderstanding, where we use the WHYFUNNY\ntext prompt and the image as input to the VL Mod-\nels. The output is evaluated using human evalua-\ntion, where the annotator needs to answer whether\nmodel-generated text correctly describes satire in\nthe image, and the corresponding accuracy for each\nVL Model is reported. The results are shown in Ta-\nble 5. We can infer that 3 out of 5 models give less\nthan satisfactory performance on Detection, and all\nmodels give an accuracy of less than 50% on Image\nUnderstanding. Hence, even on real photographs,\nSOTA VL Models fail to perform well."}, {"title": "B Background", "content": ""}, {"title": "B.1 Satirical and Humor Datasets", "content": ""}, {"title": "B.2 Other Image Datasets", "content": ""}, {"title": "C Our Annotation Pipeline", "content": ""}, {"title": "C.1 Stage 1: Collecting Satirical Images from\nSocial Media", "content": ""}, {"title": "C.2 Stage 2: Annotation of Satirical Images", "content": ""}, {"title": "C.3 Stage 3: Generating 2D stick images using\nDALL-E 3 on the annotated descriptions", "content": "Details of the manual labelling: The manual la-\nbelling of whether an image with one or more gen-\nerated sub-images is satirical or not is carried out\nby a graduate student in our lab. The annotator was\ngiven 10 satirical and 10 non-satirical images prior\nto the manual labelling to provide assistance for\nthe labelling."}, {"title": "C.4 Stage 4: Generating 3D stick images using\nDALL-E 3 on the annotated descriptions", "content": ""}, {"title": "D The Yes But Dataset", "content": "Topics obtained after topic-modelling on the left\nand right sub-image descriptions of satirical im-\nages in YesBut, along with topic descriptions\nfrom ChatGPT -"}, {"title": "E Experimental Setup", "content": ""}, {"title": "E.1 Models", "content": "Compute Details: We use an NVIDIA A40 GPU\nfor experiments using the open-source models. The\ninference time per sample on the GPU for the Satir-\nical Image Detection, Understanding and Com-\npletion Tasks for the open-source models go upto\naround 10 seconds, 1 minute, and 10 seconds re-\nspectively."}, {"title": "E.2 Tasks", "content": "Text Prompt for Satirical Image Detection:\nYou are an AI expert in detecting humour\nor satire. User gives you an image, and\nyou have to make a choice \"Y\" or \"N\".\nInstructions: Users image has 2 halves\ncalled yes and but, and the combination\nof those might make no sense at all,\nor be extremely funny. Your job is to\nfind out which one it is and output Y if\nits EXTREMELY funny and N for otherwise.\nOutput format: one character, exactly\neither \"Y\" or \"N\""}, {"title": "E.3 Evaluation Setup", "content": ""}, {"title": "E.4 Results", "content": ""}]}