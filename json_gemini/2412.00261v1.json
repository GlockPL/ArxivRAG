{"title": "Attribute-Enhanced Similarity Ranking for Sparse Link Prediction", "authors": ["Jo\u00e3o Mattos", "Zexi Huang", "Mert Kosan", "Ambuj Singh", "Arlei Silva"], "abstract": "Link prediction is a fundamental problem in graph data. In its most realistic setting, the problem consists of predicting missing or future links between random pairs of nodes from the set of disconnected pairs. Graph Neural Networks (GNNs) have become the predominant framework for link prediction. GNN-based methods treat link prediction as a binary classification problem and handle the extreme class imbalance-real graphs are very sparse-by sampling (uniformly at random) a balanced number of disconnected pairs not only for training but also for evaluation. However, we show that the reported performance of GNNs for link prediction in the balanced setting does not translate to the more realistic imbalanced setting and that simpler topology-based approaches are often better at handling sparsity. These findings motivate Gelato, a similarity-based link-prediction method that applies (1) graph learning based on node attributes to enhance a topological heuristic, (2) a ranking loss for addressing class imbalance, and (3) a negative sampling scheme that efficiently selects hard training pairs via graph partitioning. Experiments show that Gelato outperforms existing GNN-based alternatives.", "sections": [{"title": "1 INTRODUCTION", "content": "Machine learning on graphs supports various structured-data applications including social network analysis [42, 65, 76], recommender systems [33, 53, 79], natural language processing [67, 74, 89], and physics modeling [18, 32, 69]. Among the graph-related tasks, one could argue that link prediction, which consists of predicting missing or future links [48, 51], is the most fundamental one. This is because link prediction not only has many concrete applications [46, 63] but can also be considered an (implicit or explicit) step of the graph-based machine learning pipeline [2, 50, 82]-as the observed graph is usually noisy and/or incomplete.\nGraph Neural Networks (GNNs) [27, 40, 78] have emerged as the predominant paradigm for machine learning on graphs. Similar to their great success in node classification [41, 83, 102] and graph classification [54, 90, 96], GNNs have been shown to achieve state-of-the-art link prediction performance [10, 47, 60, 81, 93, 95]. Compared to classical approaches that rely on expert-designed heuristics to extract topological information (e.g., Common Neighbors [56], Adamic-Adar [1], Preferential Attachment [4]), GNNs can naturally incorporate attributes and are believed to be able to learn new effective heuristics directly from data via supervised learning.\nHowever, we argue that the evaluation of GNN-based link prediction methods paints an overly optimistic view of their model performance. Most real graphs are sparse and have a modular structure [3, 55]. In CORA and CITESEER (citation networks), less than 0.2% of the node pairs are links/positive (see Table 1) and modules arise around research topics. Yet GNN-based link prediction methods are evaluated on an artificially balanced test set that includes every positive pair but only a small sample of the negative ones chosen uniformly at random [28]. Due to modularity, the majority of negative pairs sampled are expected to be relatively far from each other (i.e. across different modules) compared to positive pairs. As a consequence, performance metrics reported for this balanced setting, which we call biased testing, differ widely from the ones observed for the more challenging unbiased testing, where the test set includes every disconnected pair of nodes. In particular, we have found that unsupervised topological heuristics are more competitive in the unbiased setting, often outperforming recent GNN-based link prediction methods. This finding has motivated us to rethink the design of link prediction methods for sparse graphs.\nA key hypothesis of our work is that effective unbiased link prediction in sparse graphs requires a similarity metric that can distinguish positive pairs from hard negative ones. More specifically,"}, {"title": "2 LIMITATIONS IN SUPERVISED LINK\nPREDICTION EVALUATION", "content": "Supervised link prediction is often formulated as binary classification, where the positive (or negative) class includes node pairs connected (or not connected) by a link. A key difference between link prediction and other classification problems is that the two classes in link prediction are extremely imbalanced as most graphs of interest are sparse-e.g. the datasets from Table 1 are significantly more imbalanced than those in [77]. However, the class imbalance is not properly addressed in the evaluation of existing approaches.\nExisting link prediction methods [8, 11, 14, 39, 60, 86, 95, 98, 105] are evaluated on a test set containing all positive test pairs and only an equal number of random negative pairs. Similarly, the Open Graph Benchmark (OGB) ranks predicted links against a very small sample of random negative pairs. We term these approaches biased testing as they highly overestimate the ratio of positive pairs in the graph. This issue is exacerbated in most real graphs, where community structure [57] causes random negative pairs to be particularly easy to identify [43]-they likely involve members of different communities. Evaluation metrics based on biased testing provide an overly optimistic assessment of the performance in unbiased testing, where every negative pair is included in the test set. In fact, in real applications where positive test edges are not known a priori, it is impossible to construct those biased test sets to begin with.\nRegarding evaluation metrics, Area Under the Receiver Operating Characteristic Curve (AUC) and Average Precision (AP) are the two most popular evaluation metrics for supervised link prediction [8, 11, 14, 39, 60, 86, 95, 98, 105]. We first argue that, as in other imbalanced classification problems [19, 68], AUC is not an effective evaluation metric for link prediction as it is biased towards the majority class (non-edges). On the other hand, AP and other rank-based metrics such as Hits@k-used in OGB [28]-are effective for imbalanced classification but only if evaluated on an unbiased test.\nExample: Consider an instance of Stochastic Block Model (SBM) [35] with 10 blocks of size 1k, intra-block density 0.9, and inter-block density 0.1. The number of inter-block negative pairs is 10 \u00d7 1k x (10-1) \u00d7 1k \u00d7 (1 \u2013 0.1)/2 = 40.5M, while the number of intra-block negative pairs, which have high topological similarities like the ground-truth positive pairs and are much harder to contrast against, is 10 \u00d7 1k \u00d7 1k \u00d7 (1 \u2013 0.9)/2 = 0.5M. Biased testing would select less than 0.5M/(0.5M + 40.5M) < 2% of the test negative pairs among the (hard) intra-block ones. In this scenario, even a random classifier is expected to obtain 50% precision. However, the expected precision drops to less than 22% (9M positive pairs vs. 41M negative pairs) under unbiased testing.\nWe will formalize the argument used in the example above by performing link prediction on a generic instance of the SBM with intra-block density p, inter-block density q, where p > q, and k blocks of size n. In particular, we will consider an instance of SBM corresponding to the expected node pattern given the parameters, where a node is connected to (n - 1)p other nodes within its block and (nk - n)q nodes outside its block. In this setting, the optimal link prediction algorithm can only distinguish potential links within or across blocks-as pairs within each set are connected with probability p and q, respectively.\nLEMMA 1. The ratio a between inter-cluster and intra-cluster negative node pairs in the SBM is such that:\n$a \\ge (k-1) \\frac{q}{1-p}$"}, {"content": "The above lemma follows directly from the definition of the SBM and shows that the set of negative pairs is dominated by (easy) inter-cluster pairs as p increases compared to q.\nTHEOREM 2.1. In the unbiased setting, the optimal accuracy link prediction method based on binary classification for the SBM predicts no links if p < 0.5.\nThe proof is given in the Appendix B. Intuitively, even if the classifier has access to the SBM block structure, most within-block pairs are disconnected and thus the accuracy is maximized if no links are predicted. On the other hand, if p > q, an effective link prediction method should be able to leverage the SBM block structure to predict within block links. This motivates our formulation of link prediction as a \"needle in the haystack\" type of problem, where even the top candidate links (i.e., within-block pairs) are still more likely to be negative due to the sparsity of the graph. We show datasets considered fit this scenario, as shown in Appendix G.\nLEMMA 2. In the biased setting, there exist non-trivial link prediction methods with optimal accuracy based on binary classification for the SBM with p < 0.5.\nThe proof is given in the Appendix C. The idea is that in the biased setting, a link prediction method that predicts within-block pairs as links can outperform the trivial classifier described in Theorem 2.1. This illustrates how biased testing, which is applied by recent work on supervised link prediction, can be misleading for sparse graphs. More specifically, a model trained under the biased"}, {"title": "3 METHOD", "content": "The limitations of supervised link prediction methods, including GNNs, to handle unbiased testing in sparse graphs motivate the design of a novel link prediction approach. First, preliminary results (see Table 7) have shown that topological heuristics are not impacted by class imbalance. That is because these heuristics are sensitive to small differences in structural similarity between positive and hard negative pairs while not relying on any learning-and thus not being affected by biased training. However, local structure proximity heuristics, such as Common Neighbors, are known to be less efficient in highly sparse scenarios observed in many real-world applications [49]-Table 1 shows the sparsity of our datasets. Further, unlike GNNs, topological heuristics are unable to leverage attribute information. Our approach addresses these limitations by integrating supervision into a powerful topological heuristic to leverage attribute data via graph learning.\nNotation and problem. Consider an attributed graph G = (V, E, X), where V is the set of n nodes, E is the set of m edges (links), and X = (x1, ..., xn)T \u2208 Rn\u00d7r collects r-dimensional node attributes. The topological (structural) information of the graph is represented by its adjacency matrix A \u2208 Rn\u00d7n, with Auv > 0 if an edge of weight Auv connects nodes u and v and Auv = 0, otherwise. The (weighted) degree of node u is given as du = \u03a3v Auv and the corresponding degree vector (matrix) is denoted as d\u2208 Rn (D \u2208 Rn\u00d7n). The volume of the graph is vol(G) = \u2211u du. Our goal is to infer missing links in G based on its topological and attribute information, A and X.\nModel overview. Figure 1 provides an overview of our model. It starts by selecting training node pairs using a novel partitioning-based negative sampling scheme. Next, a topology-centric graph learning phase incorporates node attribute information directly into the graph structure via a Multi-layer Perceptron (MLP). We then apply a topological heuristic, Autocovariance (AC), to the attribute-enhanced graph to obtain a pairwise score matrix. Node pairs with the highest scores are predicted as links. The scores for training pairs are collected to compute an N-pair loss. Finally, the loss is used to train the MLP parameters in an end-to-end manner. We name our model Gelato (Graph enhancement for link prediction with autocovariance). Gelato represents a different paradigm in supervised link prediction combining a graph encoding of attributes with a topological heuristic instead of relying on node embeddings. While the building blocks of Gelato have been proposed by previous"}, {"title": "3.1 Graph learning", "content": "The goal of graph learning is to generate an enhanced graph that incorporates node attribute information into the topology. This can be considered as the \"dual\" operation of message-passing in GNNs, which incorporates topological information into attributes (embeddings). We propose graph learning as a more suitable scheme to combine attributes and topology for link prediction since it does not rely on the GNN to learn a topological heuristic, which we have verified empirically to be a challenge.\nSpecifically, our first step of graph learning is to augment the original edges with a set of node pairs based on their (untrained) attribute similarity (i.e., adding an e-neighborhood graph):\n$E = E + \\{(u, v) | s(x_u, x_v) > \\epsilon_\\eta\\}$"}, {"content": "where s() can be any similarity function (we use cosine in our experiments) and en is a threshold that determines the number of added pairs as a ratio n of the original number of edges m.\nA simple MLP then maps the pairwise node attributes into a trained edge weight for every edge in E:\n$W_{uv} = MLP([x_u; x_v]; \\theta)$"}, {"content": "where [xu; xv] denotes the concatenation of xu and xu and @ contains the trainable parameters. For undirected graphs, we instead use the following permutation invariant operator [13]:\n$W_{uv} = MLP([x_u + x_v; x_u - x_v]]; \\theta)$"}, {"content": "The final weights of the enhanced graph are a combination of the topological, untrained, and trained weights:\n$A_{uv} = \\alpha A_{uv} + (1 - \\alpha)(\\beta w_{uv} + (1 - \\beta)s(x_u, x_v))$"}, {"content": "where a and \u1e9e are hyperparameters. The enhanced adjacency matrix A is then fed into a topological heuristic for link prediction introduced in the next section. The MLP is not trained directly to predict the links but instead trained end-to-end to enhance the input graph given to the topological heuristic. Further, the MLP can be easily replaced by a more powerful model such as a GNN (see Appendix O), but the goal of this paper is to demonstrate the general effectiveness of our framework and we will show that even a simple MLP leads to significant improvement over the base heuristic."}, {"title": "3.2 Topological heuristic", "content": "Assuming that the learned adjacency matrix A incorporates structural and attribute information, Gelato applies a topological heuristic to A. Specifically, we generalize Autocovariance, which has been shown to be effective for non-attributed graphs [30], to the attributed setting. Autocovariance is a random-walk-based similarity metric. Intuitively, it measures the difference between the co-visiting probabilities for a pair of nodes in a truncated walk and in an infinitely long walk. Given the enhanced graph G, the Autocovariance similarity matrix R \u2208 Rn\u00d7n is given as\n$R = \\frac{D}{vol(G)} - \\frac{(D^{-1}A)^tD(D^{-1}A)^T}{vol^2(G)}$"}, {"title": "3.3 N-pair loss", "content": "Supervised link prediction methods rely on the cross entropy loss (CE) to optimize model parameters. However, CE is known to be sensitive to class imbalance [7]. Instead, Gelato leverages the N-pair loss [72] that is inspired by the metric learning and learning-to-rank literature [9, 52, 66, 80] to train the parameters of our graph learning model from highly imbalanced unbiased training data. The N-pair loss (NP) contrasts each positive training edge (u, v) against a set of negative pairs N(u, v). It is computed as follows:\n$L(\\theta) = - \\sum_{(u,v) \\in E} log \\frac{exp(R_{uv})}{exp(R_{uv}) + \\sum_{(p,q)\\in N(u,v)} exp(R_{pq})}$"}, {"content": "Intuitively, L(0) is minimized when each positive edge (u, v) has a much higher similarity than its contrasted negative pairs: Ruv \u00bb Rpq, V(p,q) \u2208 N(u, v). Compared to CE, NP is more sensitive to negative pairs that have comparable similarities to those of positive pairs-they are more likely to be false positives. While NP achieves good performance in our experiments, alternative losses from the learning-to-rank literature [6, 24, 84] could also be applied."}, {"title": "3.4 Negative sampling", "content": "Supervised methods for link prediction sample a small number of negative pairs uniformly at random but most of these pairs are expected to be easy (see Section 2). To minimize distribution shifts between training and test, negative samples N(u, v) should ideally be generated using unbiased training (see additional example in Appendix A). This means that N(u, v) is a random subset of all disconnected pairs in the training graph, and |N(u, v) | is proportional to the ratio of negative pairs. In this way, we enforce N(u, v) to include hard negative pairs. However, due to graph sparsity (see Table 1), this approach does not scale to large graphs as the total number of negative pairs would be O(|V|2 \u2013 |E|).\nLEMMA 3. Let a Stochastic Block Model with intra-block density p, inter-block density q, and p > q. Then the expected Autocovariance of intra-block pairs (Rintra) is greater than the expected Autocovariance of inter-block pairs Rinter, i.e. E[Rintra] > E[Rinter].\nLEMMA 4. Let a Stochastic Block Model with intra-block density p, inter-block density q, and p > q. Then, E[Rintra] monotonically increases as the number of partitions increases.\nConsidering Lemma 3 (see proof in the Appendix D), we argue that it is unlikely for an inter-block pair to be ranked within the top Autocovariance pairs, implying that removing these pairs from training would not affect the results. To efficiently generate a small number of hard negative pairs, we propose a novel negative sampling scheme for link prediction based on graph partitioning [17, 22]. The idea is to select negative samples inside partitions (or communities) as they are expected to have similarity values comparable to positive pairs. We adopt METIS [36] as our graph partitioning method due to its scalability and its flexibility to generate partitions of a size given as a parameter (see Appendix M). METIS' partitions are expected to be densely connected inside and sparsely connected across (partitions). We apply METIS to obtain k partitions in which Vi \u2208 {1, 2, ..., k} : Gi = (Vi, Ei, Xi), Vi C V, Ei C E, Xi C X, such that V = Uki=1 Vi and |Vi| \u2248 |V|/k. Then, we apply unbiased training only within each partition, reducing the number of sampled"}, {"title": "4 EXPERIMENTS", "content": "In this section, we provide empirical evidence for our claims regarding supervised link prediction and demonstrate the accuracy and efficiency of Gelato. We present ablation studies in Subsection 4.4 and training time comparisons in Appendix L. Our implementation is available at Anonymous GitHub\u00b9."}, {"title": "4.1 Experiment settings", "content": "Datasets. Our method is evaluated on four attributed graphs commonly used for link prediction [11, 14, 28, 60, 86, 98, 105]. Table 1 shows dataset statistics."}, {"title": "4.2 Partitioned Sampling and Link prediction as\na similarity task", "content": "This section provides empirical evidence for some of the claims made regarding limitations in the evaluation of supervised link prediction methods (see Section 2). It also demonstrates the effectiveness of Gelato to distinguish true links from hard negative node pairs in sparse graphs.\nNegative sampling for harder pairs. Based on the hardness of negative pairs, the easiest scenario is the biased testing, followed by unbiased testing and partitioned testing-i.e. only negative pairs from inside partitions are sampled. This can be verified by Figure 3, which compares the predicted scores of NCN against the similarities computed by Gelato on the test set of CITESEER. Biased testing, the easiest and most unrealistic scenario, shows a good separation between positive and negative pairs both in NCN and Gelato. For unbiased testing, which is more realistic, Gelato is better at distinguishing positive and negative pairs. Finally, partitioned testing presents a particular challenge but Gelato still ranks most positive pairs above negative ones. Other GNN-based link prediction approaches have shown similar behaviors to NCN.\nSimilarity-based link prediction. Figure 3 shows densities normalized by the size of positive and negative sets, respectively. However, in real-world sparse graphs, the number of negative pairs is much larger than that of positive ones. To better understand the ranking of positive pairs over negative pairs, we also show the same plot with non-normalized densities by the total number of all pairs in Figure 9 in the Appendix K. The results show that for unbiased and partitioned testing, ranking positive pairs over hard negative pairs is especially challenging due to their overwhelming number, i.e. positive pairs are \"needles in a haystack\". This provides evidence that classifiers, such as GNNs for link prediction, are not"}, {"title": "4.3 Link prediction performance", "content": "Table 2 summarizes the link prediction performance in terms of the mean and standard deviation of hits@1000 for all methods. We show the same results for varying values of k in Figure 4. We also include the results of MRR (Mean Reciprocal Rank), AP (Average Precision) (see Tables 7 and 8) and prec@k results for varying values of k (see Figure 8) in Appendix J.\nFirst, we want to highlight the drastically different performance of GNN-based methods compared to those found in the original papers [10, 81, 93, 95]. Some of them underperform even the simplest topological heuristics such as Common Neighbors under unbiased testing. Moreover, Autocovariance, which is the base topological heuristic applied by Gelato and does not account for node attributes, outperforms all the GNN-based baselines for the majority of the datasets. These results support our arguments from Section 2 that evaluation metrics based on biased testing can produce misleading results compared to unbiased testing.\nThe overall best-performing GNN model is NCNC, which generalizes a pairwise topological heuristic (Common Neighbors) using message-passing. NCNC only outperforms Gelato on OGBL-DDI, which is consistent with previous results [49] showing that local structural heuristics are effective for very dense networks (see Table 1). Moreover, OGBL-DDI is the only dataset considered that does not contain natural node features, which explains why our approach achieves the same performance as AC. Gelato also remains superior for different values of hits@K, especially for CORA, CITESEER and OGBL-COLLAB, and being remains competitive for OGBL-DDI being competitive as shown in Figure 4. This characteristic is especially relevant in real-world scenarios where robustness is desired, mainly in more conservative regimes with lower values of k. Overall, Gelato outperforms the best GNN-based method by 138%, 125%, 156%, and 11% for CORA, CITESEER, PUBMED, and OGBL-COLLAB, respectively. Further, Gelato outperforms its base topological heuristic (Autocovariance) by 48%, 39%, 10%, and 139% for CORA, CITESEER, PUBMED, and OGBL-COLLAB, respectively. Additional results are provided in Appendices J and N."}, {"title": "4.4 Ablation study", "content": "Here, we collect the results with the same hyperparameter setting as Gelato and present a comprehensive ablation study in Table 3. Specifically, Gelato-MLP (AC) represents Gelato without the MLP (Autocovariance) component, i.e., only using Autocovariance (MLP) for link prediction. Gelato-NP (UT) replaces the proposed N-pair loss (unbiased training) with the cross entropy loss (biased training) applied by the baselines. Finally, Gelato-NP+UT replaces both the loss and the training setting.\nWe observe that removing either MLP or Autocovariance leads to inferior performance, as the corresponding attribute or topology information would be missing. Further, to address the class imbalance problem of link prediction, both the N-pair loss and unbiased training are crucial for the effective training of Gelato."}, {"title": "5 RELATED WORK", "content": "Topological heuristics for link prediction. The early link prediction literature focuses on topology-based heuristics. This includes approaches based on local (e.g., Common Neighbors [56], Adamic Adar [1], and Resource Allocation [104]) and higher-order (e.g., Katz [37], PageRank [59], and SimRank [34]) information. More recently, random-walk based graph embedding methods, which learn vector representations for nodes [25, 30, 62], have achieved promising results in graph machine learning tasks. Popular embedding"}, {"title": "6 CONCLUSION", "content": "This work exposes key limitations in evaluating supervised link prediction methods due to the widespread use of biased testing. These limitations led to a consensus in the graph machine learning community that (1) GNNs are superior for link prediction, casting topological heuristics obsolete; and (2) link prediction is now an easy task due to deep learning advances. We challenge both assumptions, demonstrating that link prediction in sparse graphs remains a hard problem when evaluated properly. GNNs struggle with link prediction in sparse graphs due to extreme class imbalance, motivating Gelato, our novel link prediction framework.\nGelato is a similarity-based method that combines graph learning and autocovariance to leverage attribute and topological information. Gelato employs an N-pair loss instead of cross-entropy to address the class imbalance and introduces a partitioning-based negative sampling scheme for efficient hard negative pair sampling. Through extensive experiments, we demonstrate superior accuracy and scalability of Gelato when compared to state-of-the-art GNN-based solutions across various datasets."}, {"title": "A ANALYSIS OF LINK PREDICTION\nEVALUATION METRICS WITH DIFFERENT\nTEST SETTINGS", "content": "Example: Consider a graph with 10K nodes, 100K edges, and 99.9M disconnected (or negative) pairs. A (bad) model that ranks 1M false positives higher than the true edges achieves 0.99 AUC and 0.95 in AP under biased testing with equal negative samples.\nFigures 5a and 5b show the receiver operating characteristic (ROC) and precision-recall (PR) curves for the model under biased testing with equal number of negative samples. Due to the down-sampling, only 100k (out of 99.9M) negative pairs are included in the test set, among which only 100k/99.9M \u00d7 1M \u2248 1k pairs are ranked higher than the positive edges. In the ROC curve, this means that once the false positive rate reaches 1k/100k = 0.01, the true positive rate would reach 1.0, leading to an AUC score of 0.99. Similarly, in the PR curve, when the recall reaches 1.0, the precision is 100k/(1k + 100k) \u2248 0.99, leading to an overall AP score of ~0.95.\nBy comparison, as shown in Figure 5c, when the recall reaches 1.0, the precision under unbiased testing is only 100k/(1M + 100k) \u2248 0.09, leading to an AP score of ~0.05. This demonstrates that evaluation metrics based on biased testing provide an overly optimistic measurement of link prediction model performance compared to the more realistic unbiased testing setting."}, {"title": "B PROOF OF THEOREM 2.1", "content": "There are only three classifiers that we need to consider in this setting, assuming that the classifier can recover the block structure:\n(1) It predicts every disconnected pair as a link;\n(2) It predicts every disconnected pair as a non-link;\n(3) It predicts within-block pairs as links and across-block pairs as non-links.\nThe classifier 1 cannot be optimal for sparse graphs-i.e., density lower than .5-and thus we will focus on classifiers 2 and 3. We will compute the expected number of True Positives (TP), False Positives (FP), False Negatives (FN), and True Negatives (TN) per node for each of them:\nClassifier 2:\nTP = 0\nFN = 0\nFP = (n - 1)p + (nk \u2013 n)q\nTN = (n \u2212 1)(1 \u2212 p) + (nk \u2013 n)(1 \u2013 q)\nClassifier 3:\nTP = (n - 1)p\nFN = (nk - n)q\nFP = (n - 1)p\nTN = (nk \u2013 n)(1 \u2013 q)\nThe accuracy of the classifiers is computed as (TP + TN)/(TP +\nTN + FP + FN). It follows that the difference between accuracy of the classifier 2 and 3 is as follows:\n$\\frac{(n - 1)(1-p) + (nk-n)(1-q)}{nk - 1} - \\frac{(n - 1)p + (nk \u2013 n) (1 \u2013 q)}{nk - 1}$"}, {"content": "And thus, classifier 2 outperforms classifier 3 for p < 0.5."}, {"title": "C\nPROOF OF LEMMA 2", "content": "We will consider the same classifiers 2 and 3 from the proof of Theorem 2.1. Moreover, we will assume that the number of sampled negative pairs is the same as the number of positive pairs (i.e., balanced sampling).\nBy definition, the accuracy of classifier 2 is 0.5, as all predictions for negative pairs will be correct and all those for positive pairs will be incorrect. Thus, we only have to show that there exists an SBM instance for which classifier 3 achieves better accuracy than 2. The accuracy of classifier 3 is computed as a1 + a2/2, where:\n$a_1 = \\frac{(n - 1)p}{(n - 1)p + (nk \u2013 n)q}$\n$a_2 = \\frac{(nk-n) (1-q)}{(nk \u2013 n) (1 \u2013 q) + (n \u2212 1) (1 \u2212 p)}$"}, {"content": "It follows that, as q\u2192 0, classifier 3 can achieve an accuracy higher than 0.5."}, {"title": "D PROOF OF LEMMA 3", "content": "Let us initially consider Autocovariance with t = 1 computed in the Stochastic Block Model described in Lemma 3. We will adopt the entry-wise notation of the original Autocovariance definition presented in Section 3.2, using lower-case letters to represent individual entries in matrices and vectors, and for the sake of consistency with the Modularity definition, we adopt vol(G) = 2m. We first obtain the shortened form of Autocovariance for t = 1:\n$R_{ij} = \\frac{1}{2m}(a_{ij} - \\frac{d_i d_j}{2m})$"}, {"content": "We can obtain the expected expression value for the case where (i, j) is an intra-cluster pair (E[Rintra]):\n$E[R_{intra}] = \\frac{1}{2m}((1 - p) + (0) (1-p))$\n$ = \\frac{1}{2m}(p - \\frac{d_i d_j}{2m})$"}, {"content": "Likewise, we follow the same procedure for the case where (i, j) is an inter-cluster pair (E[Rinter]):\n$E[R_{inter}] = \\frac{1}{2m}((1 - p) + (0)p)$\n$ = \\frac{1}{2m}(1-p - \\frac{d_i d_j}{2m})$\n$ = \\frac{1}{2m}(q - \\frac{d_i d_j}{2m})$"}, {"content": "Due to the reversible property of Markov chains, this holds for larger values of t.\nSince p > q\u21d2 E[Rintra] > E[Rinter]."}, {"title": "E PROOF OF LEMMA 4", "content": "From Appendix D, we have $E[R_{intra}] = \\frac{1}{2m}(p - \\frac{d_i d_j}{2m})$ is solely dependent on the value of p, since all the other terms are constants."}, {"title": "F CAN GNNS LEARN AUTOCOVARIANCE?", "content": "Message-passing Neural Networks: Classical message-passing neural networks (MPNNs) are known to be as powerful as the 1-WL isomorphism test. Recent papers have shown how this limitation affects link prediction performance [10, 73, 91, 94]. Node pairs (u, v) and (u, x) are indistinguishable by MPNNs if u and x have the same receptive field (or k-hop neighborhood). Figure 6 shows that MPNNs are also unable distinguish node pairs with different values of Autocovariance within a graph G. Recently, more powerful GNNs for link prediction have also been proposed [29]. These GNNs are as powerful as the 2-WL and 2-FWL isomorphism tests, which are two versions of the 2-dimensional WL test and are more discriminative than 1-WL for link prediction. While 2-WL powerful GNNs are still not able to distinguish pairs (u, v) and (u, x) in Figure 6, 2-FWL powerful GNNs can. This is due to the ability of 2-FWL powerful GNNs to count open and closed triads involving pairs of nodes-(u, v) is part of two triangles while (u, x) is part of none. However, we notice that counting triads is not sufficient to compute probabilities of paths longer than 2 hops connecting a\npair of nodes. Moreover, training a GNN based on a 2-dimensional WL test takes O(n\u00b3) time, which prevents their application to large graphs.\nSubgraph Neural Networks: Subgraph neural networks (SGNNs) differ from MPNNs as they learn representations based on node enclosing subgraphs [16, 29, 44, 94, 97]. These subgraphs are augmented with structural features that have been proven to increase their expressive power. However, SGNNs are also known to be computationally intractable [10]. Previous work has shown that SGNNS can count the number of paths of fixed length between pairs of nodes when the aggregation operator is SUM [91]. Autocovariance is a function of path counts, node degrees, and the graph volume (constant). Therefore, it is straightforward to design a SGNN that can predict Autocovariance. However, we note that our empirical results show that SEAL and BUDDY are often outperformed by Gelato. This can be explained by the specific design of these GNNs (e.g. aggregation operator) and the sampling complexity of accurately learning Autocovariance directly from data."}, {"title": "G ESTIMATED STOCHASTIC BLOCK MODEL\nPARAMETERS", "content": "We estimate the intra-block (p) and inter-block (q) parameters of each dataset considered in our experiments using either the node labels as ground-truth partitions (for Cora, CiteSeer, and PubMed) or MET"}]}