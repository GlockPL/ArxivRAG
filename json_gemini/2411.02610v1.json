{"title": "Investigating Idiomaticity in Word Representations", "authors": ["Wei He", "Marcos Garcia", "Marco Idiart", "Tiago Kramer Vieira", "Carolina Scarton", "Aline Villavicencio"], "abstract": "Idiomatic expressions are an integral part of human languages, often used to express complex ideas in compressed or conventional ways (e.g. eager beaver as a keen and enthusiastic person). However, their interpretations may not be straightforwardly linked to the meanings of their individual components in isolation and this may have an impact for compositional approaches. In this paper, we investigate to what extent word representation models are able to go beyond compositional word combinations and capture multiword expression idiomaticity and some of the expected properties related to idiomatic meanings. We focus on noun compounds of varying levels of idiomaticity in two languages (English and Portuguese), presenting a dataset of minimal pairs containing human idiomaticity judgments for each noun compound at both type and token levels, their paraphrases and their occurrences in naturalistic and sense-neutral contexts, totalling 32,200 sentences. We propose this set of minimal pairs for evaluating how well a model captures idiomatic meanings, and define a set of fine-grained metrics of Affinity and Scaled Similarity, to determine how sensitive the models are to perturbations that may lead to changes in idiomaticity. Affinity is a comparative measure of the similarity between an experimental item, a target and a potential distractor, and Scaled Similarity incorporates a rescaling factor to magnify the meaningful similarities within the spaces defined by each specific model. The results obtained with a variety of representative and widely used models indicate that, despite superficial indications to the contrary in the form of high similarities, idiomaticity is not yet accurately represented in current models. Moreover, the performance of models with different levels of contextualisation suggests that their ability to capture context is not yet able to go beyond more superficial lexical clues provided by the words and to actually incorporate the relevant semantic clues needed for idiomaticity. By proposing model-agnostic measures for assessing the ability of models to capture idiomaticity, this paper contributes to determining limitations in the handling of non-compositional structures, which is one of the directions that needs to be considered for more natural, accurate and robust language understanding. The source code and additional materials related to this paper are available at our GitHub repository\u00b9.", "sections": [{"title": "1. Introduction", "content": "The evolution of word representation models has resulted in models with seemingly remarkable language abilities. Not surprisingly these models have been found to store a wealth of linguistic information (Henderson 2020; Manning et al. 2020; Vuli\u0107 et al. 2020; Lenci et al. 2022), displaying high levels of performance on various tasks ranging from the abilities of even the static models of detecting semantic similarities between different words (Lin 1999; Mikolov et al. 2013; Baroni, Dinu, and Kruszewski 2014) to those of contextualised models of grouping representations in clusters which seem to be related to the various senses of the word (Schuster et al. 2019) and can be matched to specific sense definitions (Chang and Chen 2019). While substantial evaluation efforts have concentrated on word and subword units and on larger compositional combinations derived from them, there is less understanding about their ability for handling less compositional structures, such as those found on multiword expressions (MWEs), like noun compounds (NCs) (Garcia et al. 2021a), verb-noun combinations (King and Cook 2018; Hashempour and Villavicencio 2020) and idioms (Yu and Ettinger 2020; Dankers, Lucas, and Titov 2022). Indeed, MWEs include a variety of distinct phenomena and have been described as interpretations that cross word boundaries (Sag et al. 2002), whose meanings are not always straightforwardly derivable from the meanings of their individual components. Moreover, although they include, on the one hand, more transparent and compositional expressions (like salt and pepper) or expressions with implicit relations (like olive oil as oil made from olives), on the other hand they also include more idiomatic expressions (like eager beaver as a person who is willing to work very hard\u00b2), falling into a continuum of idiomaticity\u00b3 (Sag et al. 2002; Fazly, Cook, and Stevenson 2009). This leads to potential problems for models if they follow the Principle of Compositionality (Frege 1956; Montague 1973), building the meaning of a larger unit (like a sentence or an expression) from a combination of the individual meanings of the words that are contained in it, as this would result in potentially incomplete or incorrect interpretation for more idiomatic cases (e.g. the idiomatic eager beaver interpreted literally as impatient rodent). Although understanding the meaning of an MWE may require knowledge that goes beyond that of the meanings of these individual words in isolation (Nunberg, Sag, and Wasow 1994), failure to take idiomaticity into account can affect the quality of downstream tasks (Sag et al. 2002; Constant et al. 2017; Cordeiro et al. 2019) such as reasoning and inference (Chakrabarty, Choi, and Shwartz 2022; Chakrabarty et al. 2022; Saakyan et al. 2022), information retrieval (Acosta, Villavicencio, and Moreira 2011) and machine translation (Dankers, Lucas, and Titov 2022). For machine translation, for example, the degree of idiomaticity"}, {"title": "2. Representing Multiword Expressions and Idiomaticity", "content": ""}, {"title": "2.1 Static and contextualised models for representing MWES", "content": "A variety of vector models have been used to investigate the representation of multiword expressions (MWEs), ranging from static to contextualised representations, each with its own set of challenges (Contreras Kallens and Christiansen 2022; Garcia et al. 2021a; Liu and Neubig 2022). The former include models like Word2Vec (Mikolov et al. 2013), GloVe (Pennington, Socher, and Manning 2014) and fastText (Bojanowski et al. 2017), which represent words at type-level, producing a single vector for each word that conflates all its senses. At this level, MWEs are often represented based on their overall syntactic and semantic properties as they are generally understood, without taking into account the variability of contexts. For example, both the literal and the idiomatic meaning of gold mine would be represented jointly in a single vector regardless of its use in any specific sentence. At the other end of the scale are the contextualised models, from ELMO (Peters et al. 2018), BERT (Devlin et al. 2019) and GPT-3 (Brown et al. 2020) to LLAMA (Touvron et al. 2023) and other large language models, which produce token-level dynamic representations dedicated to capturing specific usages of a word in a particular context, resulting in several vectors for each word (Lenci et al. 2022; Apidianaki 2022). Token-level representations focus on the specific occurrences of words or subwords within contexts, and how their meaning or function may vary or be influenced by the surrounding text. Therefore, they have the potential for accurately representing MWEs, capturing the interdependence of the idiomatic meaning on a particular configuration of words, while also anchoring the MWEs in relation to their immediate linguistic environment. The primary challenge at token-level is accurately determining the presence, meaning and role of MWEs in specific contexts, especially when they have possibly multiple literal and idiomatic readings or when they are part of complex syntactic structures (Zeng and Bhat 2021).\nEvaluation of successive generations of word representation models, ranging from static (Landauer and Dumais 1997; Lin 1999; Baroni and Lenci 2010; Mikolov et al. 2013; Bojanowski et al. 2017) to contextualised models (Peters et al. 2018; Devlin et al. 2019; Brown et al. 2020; Touvron et al. 2023), has devoted considerable attention to their linguistic abilities (Mandera, Keuleers, and Brysbaert 2017; Wang et al. 2018; Henderson 2020; Rogers, Kovaleva, and Rumshisky 2020; Lenci et al. 2022). On lexical semantics, the representations extracted from contextualised models seem to be able to reflect word senses in clusters of vectors (e.g., Wiedemann et al. (2019) for BERT) including in cross-lingual alignments involving polysemous words (e.g., Schuster et al. (2019) for ELMo). However, controlled uniform evaluations of different generations of word representation models settings have also reported strong performances from static models, which were able to outperform contextualised models in most tasks (Lenci et al. 2022)."}, {"title": "2.2 Vector models evaluation on idiomaticity", "content": "Regarding idiomaticity, uniform assessment of the performance of different models on the processing of MWEs are particularly important, as independent evaluations have reported mixed results (King and Cook 2018; Nandakumar, Baldwin, and Salehi 2019; Cordeiro et al. 2019; Hashempour and Villavicencio 2020; Garcia et al. 2021b; Klubi\u010dka, Nedumpozhimana, and Kelleher 2023). For instance, for the task of identifying the degree of idiomaticity of MWEs at type level (i.e. the potential of an MWE to be idiomatic in general), good performances have been obtained with static word embeddings (Mitchell and Lapata 2010; Reddy, McCarthy, and Manandhar 2011; Cordeiro et al. 2019), and they have even been reported as obtaining better performance than contextualised models for capturing idiomaticity in MWEs in some evaluations (King and Cook 2018; Nandakumar, Baldwin, and Salehi 2019). Likewise, BERT-based models obtained similar results to those of static vector representations for predicting the degree of compositionality of a given NC (Miletic and Schulte im Walde 2023).\nHowever, a potential limitation of static models is that in representing different word senses in the same vector, the literal usage of an expression may differ considerably from its idiomatic usage (e.g. a brass ring as an idiomatic prize or as a literal ring made of brass), and complex operations may be required to deal with semantic phenomena like polysemy (Erk 2012). In this sense, contextualised models may provide the means for distinguishing literal from idiomatic usages, along with fine-grained sense distinctions. In this respect, Garcia et al. (2021a) proposed probing metrics to investigate and understand the linguistic information encoded in the models' representations. Similarly, using a method of probing with noise and a repurposed idiomatic usage probing task revealed better performance by BERT in encoding idiomaticity compared to GloVe (Klubi\u010dka, Nedumpozhimana, and Kelleher 2023). These types of intrinsic evaluations have also been framed as shared tasks, like SemEval-2022 task 2B (Tayyar Madabushi et al. 2022) which proposed the assessment of idiomaticity representation in multilingual texts (English, Portuguese and Galician) while also requiring models to predict the semantic text similarity (STS) scores between sentence pairs, regardless of whether or not either sentence contains an idiomatic expression.\nExtrinsic evaluations have measured how well the representation of idiomaticity in a model impacts downstream tasks, e.g., sentence generation (Zhou, Gong, and Bhat 2021), or conversational systems (Adewumi, Liwicki, and Liwicki 2022). For instance, evaluations of different classifiers initialised with static and contextualised embeddings in five tasks related to lexical composition (including the literality of NCs) found that contextualised models led to better performance across all tasks (Shwartz and Dagan 2019), and supervised methods that used contextualised models also outperformed alternatives on the classification of potentially idiomatic expressions in both monolingual and cross-lingual (English and Russian) scenarios (Kurfal\u0131 and \u00d6stling 2020; Fakharian and Cook 2021). Alternatively, both types of representations can be combined, as for example, in a supervised neural architecture to identify and classify potentially idiomatic expressions combining contextualised and static embeddings in an attention flow (Zeng and Bhat 2021). Regarding machine translation, a recent evaluation of compositional generalisation in transformer models found that they tend to perform too compositional translations even for idiomatic expressions (Dankers, Lucas, and Titov 2022). Furthermore, an analysis of GPT-3 (Brown et al. 2020) reported 50.7% accuracy in idiom comprehension (Zeng and Bhat 2022), suggesting that the models' ability to deal with idiomaticity is not yet adequate."}, {"title": "2.3 Vector operations and idiomatic knowledge induction", "content": "In addition to the level of contextualisation, the performance of vector space models may also be affected by the way the target words of an expression are composed, with functions like sum, concatenation and multiplication used for combining the words of static models (Cordeiro et al. 2019; Mitchell and Lapata 2010; Reddy, McCarthy, and Manandhar 2011) or the subwords of contextualised models (Garcia et al. 2021b). For the embeddings extracted from language models, other potential sources of variation include which input is given to the model (e.g., one vs. several sentences including the target MWE in evaluations at the type level), or the number of layers that will be taken into account to obtain the vector representation (Mileti\u0107 and Walde 2024). In this regard, the intermediate and last layers seem to encode more semantic information at the token level (Tenney, Das, and Pavlick 2019; Garcia 2021), while other evaluations at the type level found that the averaging the initial layers of the target expressions achieved the best results (e.g., Miletic and Schulte im Walde (2023) for NCs and Vuli\u0107 et al. (2020) for single word semantic tasks). With respect to semantic composition, Yu and Ettinger (2020) explored the type level representation of two word phrases (which in many cases correspond to NCs as the ones used in our study) in various contextualised models, showing that phrase representations miss compositionality effects as they heavily rely on word content. Similar conclusions, for neural machine translation, can be inferred from Dankers, Lucas, and Titov (2022). While some of these evaluations rely on substitutivity and the changes to a larger phrase representation caused by substitutions to its constituents (Garcia et al. 2021b; Yu and Ettinger 2020), alternatively, the notion of localism has also been analysed (Liu and Neubig 2022) focusing on whether the operations of a model are local (Hupkes et al. 2021), that is, the extent to which the representation of a phrase is derivable from its local structure.\nCrucially, a substantial amount of the discussed studies evaluate idiomaticity at the type-level, i.e., they obtain the embedding of a given MWE by averaging its representation in several sentences that have been previously extracted in an automatic way. A more detailed controlled comparison of type-level and token-level idiomaticity reported compatible results for both levels, with type-level being a close approximation for token-level (Garcia et al. 2021a) in sentences where the NC occurs with the same sense. Further analysis of the occurrences of these NCs in fine-grained sense annotations of literal and idiomatic usages (Tayyar Madabushi et al. 2021) provided additional confirmation that the ability of contextualised models to capture idiomaticity during pre-training was limited, with approaches for building single token representations (Phelps et al. 2022) and for fine-tuning leading to more accurate representations (Tayyar Madabushi et al. 2022). Recent alternatives for representing idiomatic expressions also include adding a new adapter module which has been developed and trained to recognise idioms (Zeng and Bhat 2022). This module functions as a language expert for idioms, augmenting the learning process of BART (Lewis et al. 2019) with additional information, and this approach effectively improves the representation of idiomatic expressions in off-the-shelf pre-trained language models, equipping them with greater ability to navigate the intricacies of natural language. Zeng and Bhat (2023) also proposed PIER+, a language model improvement for handling both literal and figurative language. This is achieved by combining a base model with an additional curriculum learning framework that gradually introduces more complex potentially idiomatic expressions. Compared to other models, PIER+ demonstrates better performance at identifying, understanding, and maintaining proficiency in both types of expressions. Finally, Zeng et al. (2023) introduce a knowledge graph designed to enhance the understanding of idiomatic expressions, which integrates commonsense knowledge to aid in deciphering the non-literal meanings of idioms. This work demonstrates how to inject MWE-related knowledge into pre-trained language models effectively. However, it is still unclear to what extent the context and its representation in contextualised models are"}, {"title": "2.4 Towards a more controlled assessment of idiomaticity in vector space models", "content": "Shedding some light on these questions requires a more controlled evaluation setup and measures that can abstract away from the particularities of these word representation spaces. In this effort, we take inspiration in psycholinguistic methodologies, which have been traditionally used to examine how humans process language in controlled experimental setups, to allow the removal of obvious biases and potentially confounding factors from evaluations (Linzen, Dupoux, and Goldberg 2016; Gulordava et al. 2018). They also enable comparative analyses of performance in artificially constructed but controlled sentences and in naturally occurring sentences.\nSetups like these have been used, for instance, to investigate how models represent syntax, if they understand negation (van Schijndel and Linzen 2018; Prasad, van Schijndel, and Linzen 2019; Ettinger 2020; Kassner and Sch\u00fctze 2020), and if they are aware of which properties are relevant for which concepts (Misra, Rayz, and Ettinger 2023). Adopting evaluation protocols that use minimal pair sentences (e.g.,Warstadt et al. (2020); Misra, Rayz, and Ettinger (2023)) allows for a controlled comparison of the target item against carefully selected distractors that may share linguistic properties with them. For instance, a dataset of Conceptual Minimal Pair Sentences (COMPS) was used to compare the performance of 22 large language models including both masked language models (like BERT) and autoregressive language models (like GPT-2), where the models have to validate which of two concepts a given property belongs to (e.g. stripes for zebras vs. oaks). Although the models seem to obtain relatively high accuracies for attributing properties to concepts, when semantically related concepts are involved or distractors are included, performances drop substantially, and go below chance even for models like GPT-3 (Misra, Rayz, and Ettinger 2023). Similarly, in targeted syntactic evaluation (Marvin and Linzen 2018), models are assessed using minimal pairs datasets focused on specific syntactic phenomena, such as those included in the BLiMP dataset for English (Warstadt et al. 2020). Analyses like these highlight the importance of adding controls to the experimental setup to distinguish seemingly sophisticated behaviour with high performances that give the illusion of knowledge from robust understanding with access to meaning (Misra, Rayz, and Ettinger 2023; de Dios-Flores, Garcia Amboage, and Garcia 2023). With this is mind, we follow Garcia et al. (2021b) and use minimal pairs to propose a set of intrinsic evaluations including probes and affinity measures aimed at gaining a better understanding of how vector space models represent MWEs with different degrees of semantic compositionality in context."}, {"title": "2.5 Datasets for exploring idiomaticity in computational models", "content": "Concerning experimental data, the first datasets to evaluate computational models were composed of different types of multiword expressions annotated at the type-level (McCarthy, Keller, and Carroll 2003; Venkatapathy and Joshi 2005). Further studies released annotations of MWEs in context, such as the VNC-tokens dataset (Cook, Fazly, and Stevenson 2008), which includes 60 English verb-noun combinations occurring in almost 3,000 sentences annotated as idiomatic or literal, or the IDIX corpus (Sporleder et al. 2010), with almost 6,000 labeled sentences of 78 expressions extracted from the BNC. Using a crowdsourcing platform, Reddy, McCarthy, and Manandhar (2011) released a dataset with numerical ratings of the compositionality degree of 90 noun compounds in English, which also includes the contribution of each component to the meaning of the MWEs. Similar efforts were carried out for other languages, such as the GhoSt-NN dataset for German (Schulte im Walde et al. 2016), or the NC Compositionality (NCC) dataset (Cordeiro et al. 2019), which expanded the resource provided by Reddy, McCarthy, and"}, {"title": "3. Materials and Methods", "content": ""}, {"title": "3.1 Noun Compound Idiomaticity Minimal Pairs Dataset", "content": "The Noun Compound Idiomaticity Minimal Pairs (NCIMP) dataset contains 32,200 sentences targeting two-word NCs in two languages, 280 in English (EN) and 180 in Portuguese (PT), with idiomatic (e.g. gravy train), partly compositional (e.g., grandfather clock) and compositional (e.g., research project) NCs. For each NC, the dataset contains minimal pairs formed by a first sentence with the target NC and a second sentence where the NC was replaced by an experimental item. These experimental items were selected on the basis of MWE properties, like more limited substitutability (or greater lexical fixedness), and can be used to determine if models are sensitive to perturbations to these properties, and if this is affected by how idiomatic the NCs are. For example, depending on the degree of lexical fixedness of an NC, the variants generated may not fully retain its original meaning (e.g. panda car and ?bear automobile). In particular, we analyse the following:\n\u2022 NCSyn: the minimal pairs are formed by the NC being replaced by one of the gold standard synonyms provided holistically for the NC by the annotators (e.g. brain for grey matter). In this case, we adopted the synonyms provided by the Noun Compound Senses (NCS) dataset (Garcia et al. 2021b), which were selected on the basis of the most frequent paraphrases given by native speaker annotators. These pairs are used to assess if the models"}, {"title": "3.2 Word Representation Models", "content": "We evaluate representative static and contextualised models. For the former, we compare GloVe and Word2Vec, using the official models for English, and the 300 dimensions vectors for Portuguese (Hartmann et al. 2017).\nFor the latter, we evaluate a large set of models, including the Bi-LSTM-based ELMO (Peters et al. 2018), and several Transformer-based language models: BERT (Devlin et al. 2019) and"}, {"title": "3.2.1 Sentence and NC Embeddings", "content": "Embeddings for the whole sentence as well as for the NCs are generated by averaging the (sub)word embeddings of the relevant tokens involved, according to the model:\n\u2022 for static models, the word embeddings are derived directly from the vocabulary, with missing out-of-vocabulary words being ignored;\n\u2022 for ELMo the output word embeddings are averaged, and the concatenation of its three layers is adopted;\n\u2022 for Transformer-based models, the word embeddings are generated by averaging the representations of the sub-tokens and we report results using the last four layers.\nIn general we adopt standard widely used configurations to determine what the landscape of results is before any task optimisation, even if alternative tokenisation approaches (Gow-Smith et al. 2022), dedicated representations for MWEs as single-tokens (Cordeiro et al. 2019; Phelps et al. 2022) and different combinations of layers and weighting schemes (Reimers and Gurevych 2019a; Vuli\u0107, Korhonen, and Glava\u0161 2020; Rogers, Kovaleva, and Rumshisky 2020) may generate better results in downstream tasks. Additional configurations were also extensively analysed and as they produced qualitatively similar results, they are not included in the paper."}, {"title": "3.3 Measuring idiomatic meaning", "content": "The general premises of this work, shared by many similar investigations, are that:\n1. Vector embeddings approximate meaning. We assume that the vector embeddings produced by the models are representations of usages in a semantic space that can approximate meaning. Since there is no absolute reference frame for meaning in that space, the meaning of a word/sentence is always relative and it is evaluated in terms of its similarity to other relevant words/sentences in the same semantic space.\n2. Word/multiword/sentence representations are the combinations of the (sub)word representations. We adopt as the meaning of a word, multiword expression, or of a sentence, the compositional combination of its components. In this paper we focus on the additive combination, summing/averaging the vector embeddings of each token in the word, expression or sentence, and summing/averaging the vector embeddings of the relevant layers, when more than one layer is used.\n3. Similarity of meanings can be approximated by similarity of vectors. Similarity is a measure of the proximity between two vector embeddings. Throughout this paper we adopt cosine similarity as the similarity metric. As contextualised models provide different vector representations for the same linguistic expression in different contexts, its vector representations would be found among different clusters of meaning as it transitions between its meanings in different sentences, and this would be reflected by the similarity measures."}, {"title": "3.3.1 The probing strategies", "content": "To evaluate how word representation models deal with idiomaticity, we propose a probing strategy where a target item in a sentence, in this case an NC, is systematically replaced by a set of different paraphrases or probes (P), forming the minimal pairs discussed in section 3.1. We then use similarity measures to compare the representation for the sentence before and after replacing NC by P. Given the focus on idiomaticity we select a set of probes specifically for the expected changes in meaning they would induce in a sentence, and we refer to these potential changes in meaning as Linguistic Predictions (LPs). If the representations generated by a model reflect these predictions, passing the probing tests, then we consider that particular model as capturing to some extent the idiomatic meaning in NCs. The idiomatic probes are defined as follows, where $Comp$ is the average human annotation compositionality score:\n\u2022 $P_{Syn}$ - The true synonym. The replacement is a single word or a two word compositional noun compound that represents closely the meaning of the target NC, forming the minimal pair NCSyn. Linguistic Prediction: after the replacement, the resulting sentence should be a near perfect paraphrase of the original sentence. Therefore high similarities are expected for all minimal pairs independently of the degree of compositionality of the target NC, from the more idiomatic grey matter (and brain) to the more literal economic aid (and financial assistance), with no correlation expected with Comp.\n\u2022 $P_{Comp}$ - The partial expression. The replacement is one of the component words of the target compound, and in particular we consider the one that preserves most of the meaning, forming the minimal pair NCComp. Linguistic Prediction: the resulting sentence may preserve some of the original meaning for more compositional cases, but not for idiomatic cases. Therefore, high similarities are only expected between minimal pairs involving compositional and partly compositional cases (e.g. economic aid and aid, crocodile tears and tears, but not for wet blanket and blanket or wet), with some correlation expected with Comp.\n\u2022 $P_{WordsSyn}$ - The literal synonyms of the individual NC components. The replacement is a two-word expression formed from frequent out-of-context synonyms for each of the component words of an NC when considered independently, forming the minimal pair"}, {"title": "3.4 Metrics", "content": ""}, {"title": "3.4.1 The Human Compositionality score (Comp)", "content": "Assuming a list of N NCs, chosen to provide balanced test scenarios of different levels of idiomaticity, we denote $NC_\u03b1$ with \u03b1 = 1, ..., N the different NCs to be evaluated. The meaning of theses NCs is exemplified by a set of N \u00d7 M sentences $Sent_{\u03b1\u03b2}$ with \u03b1 = 1, ..., N and \u03b2 = 1, ..., M the sentence index. The dataset contains M=3 naturalistic sentences to exemplify the use of each NC (see section 3.1), with each sentence annotated by human judges according to the compositionality of the target NC in the sentence. The resulting scores are denoted $Comp_{\u03b1\u03b2j}$, with \u03b1 = 1, ..., \u039d, \u03b2 = 1, ..., M, and j = 1, ..., $A_{\u03b1\u03b2}$ where $A_{\u03b1\u03b2}$ is the number of annotators for sentence $Sent_{\u03b1\u03b2}$. $Comp_{\u03b1\u03b2j}$ are integer values derived from a Likert scale and range from 0 (totally idiomatic) to 5 (totally compositional). We define the compositionality score for a specific NC as the average of the annotations for sentences $Sent_{\u03b1\u03b2}$,\n$Comp(NC_\u03b1) = \\langle \\langle Comp_{\u03b1\u03b2j} \\rangle_{Annot.} \\rangle_{Sent.}$\nwhere \u27e8...\u27e9Sent are averages on sentences and \u27e8...\u27e9Annot averages on annotations. These average values are the gold standard in this work."}, {"title": "3.4.2 The Similarity score (Sim)", "content": "Probing the meaning of a compound NC in a sentence $Sent_{\u03b1\u03b2}$ requires the generation of a new set of modified sentences $Sent^p_{\u03b1\u03b2\u03b3}$ where $NC_\u03b1$ is replaced by a probe $P_i$ (discussed in section 3.3.1). We measure the effect of the probe substitution directly from the similarity between the representation of the original expression, X, and the representation of the new expression after substitution, Y, adopting, throughout this paper, cosine similarity as a measure of the similarity of meaning between two vector embeddings.\n$cossim(X, Y) = \\frac{\u20acx\u00b7\u20acy}{||\u20acx|| ||\u20acy||}$"}, {"title": "3.4.3 The Affinity score (Aff)", "content": "Cosine similarity measures are not sensitive enough to capture subtle meaning differences, especially in anisotropic representation spaces (Ethayarajh and Jurafsky 2021). Additionally, there may be a 'horizon of interest,' beyond which word connections lose meaningful inference (Karlgren and Kanerva 2021), which may be a challenge for representing idiomatic expressions, as the necessary context may lie within this critical boundary. Investigating measures that account for anisotropic spaces and for a horizon of interest are interesting avenues for future research for improving idiomaticity detection. In this paper, we propose a comparative measure that we refer to as Affinity (Assessment of Feature Familiarity and Idiomatic Nuance by Interpreting Target Yielding), that identifies which between two representations is the closest to a given target representation.\nGiven a target representation Target and two possible probes $P_i$ and $P_j$, the affinity is defined as:\nAff($P_i$, $P_j$ | Target) = Sim ($P_i$, Target) \u2013 Sim ($P_j$, Target)\nAffinities closer to 1 or larger indicate a greater similarity between the target and the first probe $P_i$, values closer to -1 or lower indicate the opposite situation where the target is more similar to the second probe $P_j$, and values near zero indicate no preference. Given the focus of this paper on detecting idiomaticity in representations, we measure the affinities involving the minimal pairs defined in section 3.3.1, analysing if, as expected, the target NCs have higher similarities with probes with substitutions that maintain the original meaning as Pi than with probes that involve potential changes in meaning as Pj. In particular:\n\u2022 Affinity Asyn|WordsSyn = Aff($P_{Syn}$, $P_{WordsSyn}$|NC) measures if the target NCs have greater similarities with their gold synonyms than with synonyms of the individual components (e.g. eager beaver with hardworking person than with restless rodent).\n\u2022 Affinity Asyn|Rand = Aff($P_{Syn}$, $P_{Rand}$|NC) compare if the target NCs display greater similarities to their gold synonyms than to random substitutions.\nOur Affinity measure extends traditional forced-choice evaluations (Warstadt et al. 2020) by quantifying the degree of similarity preference between two options. Unlike binary choices, Affinity provides a continuous measure of relative similarity, offering a more detailed assessment of how well models capture idiomatic meanings. This nuanced analysis reveals subtle differences in model performance, providing deeper insights into the representation of idiomatic expressions."}, {"title": "3.4.4 The Scaled Similarity score (SimR)", "content": "Even though Affinity is an advance over the simple similarity measure, additional measures may still need to be adopted for models if the average similarity between two random embeddings is larger than zero, as affinities will tend to have small"}, {"title": "values even for very dissimilar probes (see discussion). To address this issue, we propose a scaled version of the similarity", "content": "SimR(Pi Target) =\n$\\frac{\\langle Sim(P_i, Target) \\rangle_{Sent} - \\langle Sim (P_{Rand}, Target) \\rangle_{Sent}}{1- \\langle Sim(P_{Rand}, Target)\\rangle_{Sent}}$\nwhere \u27e8...\u27e9Sent denotes the average over the M sentences that illustrate the meaning of a particular NC and $P_{Rand}$ is a random substitution. The scaled similarity is defined such that if replacing the target with a probe Pi results in cosine similarities close to one (Sim(Pi, Target) \u2248 1), the scaled similarity is also close to one, SimR \u2248 1. Conversely, if the replacement is similar to a random replacement (Sim(Pi, Target) \u2248 Sim(PRand, Target)), then SimR \u2248 0. This approach is equivalent to a max-min normalisation in the anisotropic space of a model.\n\u2022 SimR|Syn = SimR($P_{Syn}$|NC), where the NCs are replaced by gold synonyms and no changes in meaning are expected, therefore SimR|Syn should be close to 1.\n\u2022 SimR|WordsSyn = SimR($P_{WordsSyn}$|NC), where the NCs are replaced by synonyms of the individual components and greater changes in meaning, and therefore small values (~ 0) of Simr, are expected for more idiomatic cases."}, {"title": "4. Probing for Idiomaticity", "content": ""}, {"title": "4.1 Are the representations of the NCs and their synonyms similar?", "content": "A first indication of the successful modeling of idiomaticity is if a model assigns similar represen-tations for the target NCs and for their synonyms, regardless of their level of compositionality. We measure this using the minimal pairs of probe Psyn and compare it with less appropriate substitutions represented by the other probes Pj"}]}