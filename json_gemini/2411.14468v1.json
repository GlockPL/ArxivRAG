{"title": "A Neural Network Training Method Based on Distributed PID Control", "authors": ["Jiang Kun"], "abstract": "In the previous article, we introduced a neural network framework based on symmetric differential equations. This novel framework exhibits complete symmetry, endowing it with perfect mathematical properties. While we have examined some of the system's mathematical characteristics, a detailed discussion of the network training methodology has not yet been presented. Drawing on the principles of the traditional backpropagation algorithm, this study proposes an alternative training approach that utilizes differential equation signal propagation instead of chain rule derivation. This approach not only preserves the effectiveness of training but also offers enhanced biological interpretability. The foundation of this methodology lies in the system's reversibility, which stems from its inherent symmetry a key aspect of our research. However, this method alone is insufficient for effective neural network training. To address this, we further introduce a distributed Proportional-Integral-Derivative (PID) control approach, emphasizing its implementation within a closed system. By incorporating this method, we achieved both faster training speeds and improved accuracy. This approach not only offers novel insights into neural network training but also extends the scope of research into control methodologies. To validate its effectiveness, we apply this method to the MNIST dataset, demonstrating its practical utility.", "sections": [{"title": "1. Introduction", "content": "In previous research, we proposed a novel neural network architecture that integrates the symmetrical Five Elements (Wuxing) Theory with the asymmetrical predator-prey equation, resulting in a set of fully symmetrical differential equations[1]. This complete symmetry endows the system with favorable mathematical properties, such as the ability to specify fixed points and reversible propagation directions, both of which preserve the system's causality. Specifying fixed points enables the system to operate in a desired state, while reversible propagation enhances the network's training capabilities. Although we briefly outlined the training method for this neural network in the previous article, we did not provide a detailed theoretical foundation or explanation. In this article, we offer a comprehensive introduction to the training methodology, including both the underlying theory and a distributed Proportional-Integral-Derivative (PID) training approach, aimed at achieving higher accuracy.\n\nThe training of neural networks is a highly complex problem that involves various aspects, including strategy formulation, method implementation, structural design, and parameter adjustment. This complexity has led to the development of a wide range of neural network training methods. Among these, the traditional backpropagation algorithm remains the dominant approach. While backpropagation has achieved significant success, its biological plausibility has been widely questioned[2]. As a result, numerous alternative algorithms have been proposed to replace backpropagation, although they have yet to gain widespread adoption.\n\nTo develop an effective alternative to the backpropagation algorithm, it is essential to first understand the fundamental strengths of backpropagation. In our view, the key advantage of the"}, {"title": "2. Wuxing neural network", "content": "In this section, we will briefly introduce the Wuxing neural network structure, fixed point calculation, and signal propagation method. For more details, please refer to our previous article[1]."}, {"title": "2.1 Wuxing neural network differential equations", "content": "Traditional neural networks can generally be divided into two categories: those based on mathematical principles, such as multilayer perceptron (MLPs) and Hopfield networks[4]. And those inspired by biological systems, such as chaotic neural networks and cellular neural networks[5, 6].\nMathematically driven neural networks have given rise to models like convolutional neural networks (CNNs) and recurrent neural networks (RNNs), which serve as the foundation for many large-scale, widely deployed models today. In contrast, while biologically inspired neural networks offer strong biological interpretability, they lack scalability for practical deployment. This limitation stems from their reliance on differential equations, for which suitable mathematical formulations to accurately describe neural activity are still lacking.\n\nIn the Wuxing neural network, neurons are modeled as systems composed of a series of symmetrical differential equations. The primary objective of introducing this structure is to address the challenge of manipulating differential equations effectively. Traditional biological neural networks often employ differential equations derived from experimental observations. However, this approach can introduce detailed inconsistencies that undermine the equations' mathematical properties. To address this issue, our research adopts symmetrical logic based on the Five Elements (Wuxing) theory as its foundation. By incorporating elements of the predator-prey equation, we develop a set of fully symmetrical differential equations to model neural activities, replacing conventional neurons with systems governed by these equations."}, {"title": "2.2 Fixed points of differential equations", "content": "In chaos theory, the fixed point of a differential equation is a critical property, as it determines the equilibrium state of the system. In Equation 2.2, three distinct sets of parameters are involved. To analytically determine the fixed point of the equation, it is necessary to simplify the parameters. We assume that the parameters within each of the three sets denoted as K1, K2 and K3-are equal, allowing us to analytically derive the fixed point B0 of the equation.\n\n$B=\\frac{K_1-K_2}{K_3}$ \n\nEquation 2.3 plays a central role in adjusting the differential equation. Through this equation, we can modify the fixed point of the system. Even when the parameters in K1, K2 and K3 no longer satisfy the condition of equality, the adjustment method remains effective. Furthermore, Equation 2.3 establishes the relationship between the system's parameters and the fixed point. For instance, increasing K\u2081 and decreasing K3 produces the same effect on the fixed point."}, {"title": "2.3 Signal propagation and network structure", "content": "In our study, we regard the state where the differential equation is at a fixed point as the zero state of the system. Therefore, we can get the input equation of the system:\n\n$\\frac{dE(t)}{dt} = K_1 E(t)-K_2 E(t)-K_3 E(t) E(t)+ Input(t)$ \n\nIn 2.4, Input(t) is the input signal. Similarly, we can also get the output equation of the system:\n\n$D(t) = E(t) \u2212 B$ \n\nIn 2.5, D(t) is the output signal, which reflects the magnitude of the system's deviation from the fixed point. When we have both input and output signals, we can further define the network links of the system:"}, {"title": "3. Training Wuxing neural network", "content": "In this section, we will introduce how to use differential equations for signal propagation and achieve point-to-point parameter adjustment."}, {"title": "3.1 Training theory", "content": "In neural network training, the traditional backpropagation algorithm has been highly successful. Despite ongoing doubts regarding its biological plausibility, no alternative methods have yet been able to match the accuracy achieved by backpropagation. The key advantage of the backpropagation algorithm lies in its point-to-point training approach, which establishes a one-to-one relationship between each parameter and the output. Therefore, when considering the development of a new training method, it is crucial to preserve this point-to-point relationship. From a mathematical perspective, this relationship embodies a form of symmetry, but maintaining this symmetry in practice is not straightforward.\n\nDue to various practical constraints, the equations we derive often lose this symmetry. To address this, we begin with the principle of symmetry and construct symmetric differential equations, which ensure that the system remains symmetric and, consequently, reversible. This reversibility allows us to"}, {"title": "3.2 Training method", "content": "According to our definition, the system's signals can propagate in both directions. Based on the system's topological structure, we define the inverse equation of the system:\n\n$\\frac{dE(t)}{dt} = K_1 E(t)-K_2 E(t)-K_3 E(t) E(t)+ Input(t)$ \n\nEquation 3.1 and Equation 2.2 are symmetrical of each other. In 3.1, the orders of K1, K2 and K3 parameters are also adjusted. This is because K1, K2 and K3 parameters are actually parameters located between two elements (Figure 1.a). Therefore, when the signal propagation direction changes, the order of parameters must also change.\n\nEquation 3.1 and Equation 2.2 seem to be very different, but they have one thing invariant, that is, the connection between the two elements. This is the core method of training in this paper, which leads to a strong correlation between the forward propagation signal and the reverse propagation signal. This correlation is the core of adjusting the system parameters. In the traditional back-propagation training method, people use the chain rule to find the partial derivative of the parameter to the error to adjust the system, and this derivation process is to find the correlation between the parameter and the signal. Therefore, if we do not use the back-propagation method of derivation, then we must first explain how our method preserves the correlation of the system, and secondly how to apply this correlation to the system and achieve the desired results by changing the parameters.\n\nMore generally speaking, finding partial derivatives is also looking for a reversible causal relationship. If the forward input signal and the reverse input signal are located at the two ends of the system, then according to the propagation of the two signals, the signal connection can be established at different nodes. Depending on the way the coefficients are adjusted, different types of connections can be established within the system.\n\nThrough this reversible causal relationship, we can achieve many functions. The following is an example. In Figure 2, we have built a 4-layer network with three inputs and three outputs. The signal transmitted in the forward network is marked as D(t), and the signal transmitted in the reverse network is marked as D(t). Therefore, we can define an output variable Leb within time T and take the largest Leb component as the output result.\n\n$Leb=\\frac{1}{T}\\int_0^T \\overrightarrow D(t)dt$ \n\nAssuming that the Pth component of Leb should be the largest, according to our previous research, the input signal for backpropagation can be defined as follows[1]:\n\nFor the Pth component, the adjustment error is:\n\n$Error_p = \\begin{cases} target1-Leb_p, & \\text{if } Leb_p < target1 \\\\ 0 & \\text{if } Leb_p > target1 \\end{cases}$"}, {"title": null, "content": "For other component, the adjustment error is:\n\n$Error_{other} = \\begin{cases} \\frac{targtet2-Leb_{other}}{Leb_{other}}, & \\text{if } Leb_{other} > target2 \\\\ 0 & \\text{if } Leb_{other} < target2 \\end{cases}$ \n\nIn these equations, target1 and target2 represent two predefined target values, where target1 is the larger value and target2 is the smaller one. This method will make the value of the Pth component larger after training, while the others will be smaller, allowing the system to achieve a higher accuracy rate.\n\nSimilar to before, D(t) is determined by the back-propagated element value \u00ca(t) and the back-propagated fixed point Bo.\n\n$\\overrightarrow D(t) = \\overrightarrow E(t) - \\overrightarrow B_0$ \n\nAssuming that in the forward network of Figure 2, only A12 and A13 have input signals, then the signal propagation diagram is shown in Figure 2a, where only the paths marked in red have signal propagation. When the signal reaches the output end, it can be compared with the set target. If the comparison is successful, no error signal is returned. If the comparison is unsuccessful, the corresponding error signal is returned. In Figure 2a, we assume that only the result of A43 does not meet the requirements, so in Figure 2b, only A43 has an input error signal. Based on the forward and reverse signals propagated within time T, we can define a correlation variable G\u2081.\n\n$G_1 = \\int_0^T \\overrightarrow D(t)dt \\cdot \\int_0^T \\overrightarrow D(t)dt$\n\nSince G\u2081 may exceed a certain limit, we use the inverse tangent function (other similar functions are also possible) to limit it and get G2\n\n$G_2 = atan(G_1 * k_t) / k_t$\n\nkt is the adjustment parameter, G2 is the adjusted correlation value. The parameter can be adjusted based onG2.\n\n$K_{3\\_new} = K_{3\\_old} \\cdot exp(-G_2)$"}, {"title": "4. Distributed PID Control", "content": "In this section, we will discuss how to implement distributed PID control in closed systems to address parameter redundancy issues encountered in neural network training."}, {"title": "4.1 Redundant parameter adjustment", "content": "In the Wuxing neural network, there are three sets of parameters K1, K2 and K3; in previous studies, we only gave the method to adjust K3 because the method is not reusable. The following is an example trained on the MNIST dataset. The model has 784 inputs, 10 outputs, and a total of 6 layers. The number of neurons in each layer is: {784, 839, 283, 96, 32, 10}, of which the first and last layers are fully connected, and all interfaces have inputs or outputs. The initial parameters of the model are K\u2081={1, 1, 1, 1, 1}; K2={0.5, 0.5, 0.5, 0.5, 0.5}; and K3={0.5, 0.5, 0.5, 0.5, 0.5}. We use the training method in Chapter 3. One is to adjust only K3, and the other is to adjust K\u2081 and K3 at the same time. The method of adjusting K1 can refer to formula 3.5. Combined with the relationship in 2.1, we can get:\n\n$K_{1\\_new} = K_{1\\_old} exp(G_2)$"}, {"title": "4.2 Typical PID control method", "content": "In the automatic control system, PID control is the absolute leader. PID control adjusts the input by feeding back the error signal and finally achieves the ideal control result.\n\nFigure 4 illustrates a typical PID control process. Assuming the input signal represents the target value we set, the corresponding error signal is derived by comparing the output signal with the input signal. The error signal is then processed through proportional, integral, and derivative control, before being re-input into the system. This results in an adjusted signal. After several iterations of parameter adjustments, the desired outcome is typically achieved. However, an important question arises: why is a feedback loop necessary in this process?"}, {"title": "4.3 Distributed PID control strategy", "content": "Traditional PID control is based on modeling the overall system, which allows for system control without the need to analyze its intricate details. Instead, it suffices to recognize the system as causal, thus bypassing the need for complex analysis. However, this approach has its limitations. When PID control is applied to the entire system, it sacrifices strong generalization capabilities. Moreover, a closed system implies that any external input is merely a projection of an external state within the system. From a mathematical standpoint, a closed system is considered complete, yet this does not imply that the system's output fully captures all relevant information. As a result, additional systems must be integrated to expand the system's state space. This concept is central to our approach of replacing digital neurons with systems in this study.\n\nTo implement PID control within a group of differential equations, we must adapt the PID method accordingly. This differs from traditional PID control because we are working within a closed system, necessitating an approach that accounts for the specific characteristics of such systems rather than simply applying open-loop system principles[7]. Given that we have three distinct sets of parameters, we assign different control strategies to each. Specifically, we apply the integral control method to K\u2081, the differential control method to K2, and the proportional control method to K3\n\nFor K\u2081, an integral control method is adopted\n\n$G_{1\\_k1} = \\sum_{i=1}^{k_n} \\int_0^T \\overrightarrow D(t)dt(\\overrightarrow D(t)dt)$ \n\n$G_{2\\_k1} = atan(G_{1\\_k1} *k_t) / k_t$\n\n$K_{1\\_new} = K_{1\\_old}exp(G_{2\\_k1})$\n\nAs we can see, a similar method is adopted to adjust K\u2081. The difference is that the calculation method of G\u2081 is different. In the integration strategy, we add all the signals in a single neuron together. kn is the number of elements in a single neuron. This is how the integration strategy is implemented in a closed system.\n\nFor K2, a differential control method is adopted:\n\n$G_{1\\_k2} = \\int_0^T \\overrightarrow D(t)dt \\cdot \\overrightarrow D(t)dt-inputnode$\n\n$G_{2\\_k2} = atan(G_{1\\_k2} *k_t)/k_t$"}, {"title": null, "content": "$K_{2\\_new} = K_{2\\_old} \\cdot exp(-G_{2\\_k2})$\n\nIn 4.5, inputnode is a variable. If this node is an input node in the forward propagation process, then this variable is equal to 1, otherwise it is equal to 0. Because in the system, the generation of the signal is always caused by the input node, from the causal logic, the input node is in front of other nodes, which is similar to the differential control method.\n\nFor K3, a proportional control method is adopted:\n\n$G_{1\\_k3} = \\int_0^T \\overrightarrow D(t)dt \\cdot \\int_0^T \\overrightarrow D(t)dt$\n\n$G_{2\\_k3} = atan(G_{1\\_k3} *k_t)/k_t$\n\n$K_{3\\_new} = K_{3\\_old} exp(-G_{2\\_k3})$\n\nThe proportional control method is the easiest to understand. According to Equation 2.3, changing K3 has the most direct impact on the fixed point. Therefore, we use the method of changing K3 as the proportional control strategy. Although we designed three different control strategies, their efficiencies are different due to the network structure and system structure, and this design method is not the only one. More research is needed to determine their adjustment methods."}, {"title": "5. Summary", "content": "In this paper, we present a novel training method for the Wuxing neural network, incorporating innovations in both mathematics and biology. From a mathematical perspective, we propose the use of differential equations in place of chain derivation to address the one-to-one correspondence between parameters and outcomes. From a biological standpoint, we adopt the concept of instinctive design, limiting the adjustment process to individual neurons, which enhances the biological interpretability of the system. Building on this foundation, we further introduce a distributed PID method, applying PID control theory to individual neurons, with promising results. The use of the distributed PID method not only provides a new approach to neural network training but also offers fresh insights into the development of automatic control theory.\n\nIn this article, we expand on the method of replacing the function of a single neuron with a system as a whole. We argue that a closed system is complete in itself, and this completeness enables the system to fully respond to signal characteristics. However, this response cannot be directly observed from the external environment. Consequently, multiple systems must be interconnected, and a distributed PID control strategy must be employed to enhance the system's generalization capabilities. This approach forms the core of our perspective on neural networks.\n\nOur research aims to establish a general neural network architecture. While the operational modes of individual neurons are diverse, this paper focuses on one particular mode for the sake of clarity. Within this framework, training methods are also varied. Here, we introduce one such method, though we have identified four other effective training strategies, which will be discussed in future work. In the next stages of our research, we plan to explore how combining different training methods can further enhance accuracy, with parameter adjustments to be addressed in subsequent studies."}]}