{"title": "Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models", "authors": ["Haoran Ye", "Tianze Zhang", "Yuhang Xie", "Liyuan Zhang", "Yuanyi Ren", "Xin Zhang", "Guojie Song"], "abstract": "Values are core drivers of individual and collective perception, cognition, and behavior. Value systems, such as Schwartz's Theory of Basic Human Values, delineate the hierarchy and interplay among these values, enabling cross-disciplinary investigations into decision-making and societal dynamics. Recently, the rise of Large Language Models (LLMs) has raised concerns regarding their elusive intrinsic values. Despite growing efforts in evaluating, understanding, and aligning LLM values, a psychologically grounded LLM value system remains underexplored. This study addresses the gap by introducing the Generative Psycho-Lexical Approach (GPLA), a scalable, adaptable, and theoretically informed method for constructing value systems. Leveraging GPLA, we propose a psychologically grounded five-factor value system tailored for LLMs. For systematic validation, we present three benchmarking tasks that integrate psychological principles with cutting-edge Al priorities. Our results reveal that the proposed value system meets standard psychological criteria, better captures LLM values, improves LLM safety prediction, and enhances LLM alignment, when compared to the canonical Schwartz's values.", "sections": [{"title": "Introduction", "content": "Personal values are broad, fundamental motivations behind individual and collective actions. They serve as guiding principles that shape perceptions, cognition, and behaviors across situations and over time. As Large Language Models (LLMs) continue to permeate and transform human society, researchers have increasingly sought to evaluate, understand, and align LLM values. Rather than relying solely on specific risk metrics, implicit preference modeling, or atomic ethical principles, framing these studies through the lens of intrinsic values offers a more comprehensive, adaptable, and transparent approach.\nHowever, value systems used in existing research-primarily Schwartz's values are designed for humans. A psychologically informed value system specifically tailored for LLMs remains largely unexplored, obscuring a structured and holistic perspective on their values. A preliminary attempt"}, {"title": "Background and Related Work", "content": ""}, {"title": "Values, Value Measurement, and Theory-Driven Value Systems", "content": "Values. Values are broad, fundamental beliefs or principles that guide individuals' behaviors, cognition, and decisions. They represent what people consider important in life and serve as motivational forces when evaluating actions, people, and events. Unlike other psychological constructs such as personalities, values are stable, motivational, and transituational. These characteristics make values uniquely powerful for understanding human behaviors, evaluating individual and cultural differences, and resolving conflicts rooted in clashing priorities.\nValue Measurement. Values are measurable constructs. Value measurement seeks a quantitative assessment of the importance individuals or organizations assign to specific values. Traditionally, it relies on tools like self-report questionnaires, behavioral observation, and experimental techniques. However, these tools are hindered by response biases, resource demands, inaccuracies in capturing authentic behaviors, and inability to handle historical or subjective data. Recently proposed Generative Psychometrics for Values (GPV) leverage LLMs to dynamically parse unstructured texts into perceptions and measure values therein. GPV is shown to be more scalable, reliable, and flexible than traditional tools in measuring LLM values, and is utilized for non-reactive value measurement in this work.\nTheory-Driven Value Systems. Isolated values are structured into a value system for a holistic understanding of their relationships and implications. Theory-driven value systems like"}, {"title": "Psycho-Lexical Approach", "content": "In contrast to the theory-driven approaches, the psycho-lexical approach organizes psychological constructs such as values, personality traits, and social attitudes, under a data-driven paradigm. It operates on the fundamental principle that language naturally evolves to capture salient and socially relevant individual differences. The pioneering attempts date back to the early 20th century, and the paradigm has then been developed and extended to different psychological constructs for decades.\nMost of these works, taking values as an example, involve the following steps: 1) compilation of value-descriptive terms, mostly from dictionaries and thesauruses; 2) refinement and reduction to eliminate synonyms, ambiguous terms, and those that are not commonly used or understood; 3) value measurement, through collecting self-reports and peer ratings, to identify underlying correlations between the value descriptors; and 4) uncovering the hidden value factors or dimensions through statistical methods like principal component analysis or factor analysis.\nIn this work, we aim to harness the extensive knowledge and semantic understanding of LLMs to address the limitations of traditional psycho-lexical approaches. These limitations include: 1) extensive manual labor required to compile and refine the lexicons, 2) insufficient coverage of values of different linguistic forms, 3) lack of criteria for prioritizing values lexicons when filtering, 4) the responses bias and inscalability of self-report value measurement, and 5) the inability to adapt to changing values or specific contexts."}, {"title": "From Human Values to LLM Values", "content": "The rise of LLMs also brings the critical need to evaluate, understand, and align their values. Extensive works focus on evaluating the values of LLMs using traditional self-report tools, static customized inventories, dynamically generated inventories, or directly from the model's free-form outputs. Other works attempt to understand the LLM values in aspects like the consistency of shown values, the ability to reason about human values, and the ability to express or role-play human values. Another line of research aligns LLM values with human values, setting the alignment goal as specific risk metrics, human demonstrations, implicit preference modeling, or intrinsic values. Among different alignment goals, intrinsic values, as transituational decision-guiding principles, demonstrate unique advantages. However, prior works are mostly based on Schwartz's value system, which is established and validated for humans and may not necessarily capture the unique LLM psychology. Therefore, it is essential to construct a value system for LLMs grounded in psychological theories and principles, based on which we can more effectively evaluate, understand, and align the values of LLMs."}, {"title": "Generative Psycho-Lexical Approach for Constructing LLM Value System", "content": "This section presents the Generative Psycho-Lexical Approach (GPLA), illustrated schematically in Fig. 1 and algorithmically in Algorithm 1, as the foundation for constructing the LLM value system. GPLA adopts an agentic framework, comprising three LLM agents and four sequential steps, to systematically collect, filter, measure, and structure the LLM value system."}, {"title": "Are LLMs Capable for GPLA?", "content": "LLMs assume three roles in GPLA: Perception Parser, Value Generator, and Value Evaluator. This section validates the capabilities of LLMs in these roles.\nPerceptions are value-laden expressions dynamically extracted from LLM outputs. They resemble the stimuli in traditional psychometric tools. The Perception Parser Mp extracts such perceptions from the LLM outputs. As validated by Ye et al., Mp can extract high-quality perceptions suitable for subsequent analysis. In addition, related research confirms that LLMs demonstrate abilities beyond human golden standards in value-related generation tasks.\nThe Value Generator MG identifies values from the extracted perceptions. As validated by Sorensen et al., MG, instantiated with the Kaleido model, can generate values that are both comprehensive and high-quality, with 91% of the generations marked as good by all three annotators, and missing values detected 0.35% of the time.\nThe Value Evaluator ME measures the value orientations of LLMs given the extracted perceptions. When instantiated with ValueLlama, ME can approximate the psychologists' judgments on held-out values with about 90% accuracy."}, {"title": "Advantages of GPLA over Prior Psycho-Lexical Approaches", "content": "Here we discuss the main advantages of GPLA over the traditional psycho-lexical approach in constructing value systems. We defer the comparison with ValueLex, a recent study that constructs LLM value systems, to Appendix C.\nFull Automation. Traditional psycho-lexical approaches involve extensive manual labor in compiling and refining lexicons, collecting self-reports, and analyzing data. In contrast, given pre-collected corpora, GPLA automates the entire process, from value lexicon extraction and value filtering, to non-reactive value measurement and system construction.\nLexicon Collection. The traditional approach relies on values lexicons compiled from dictionaries and thesauruses, which lack comprehensive coverage in diverse linguistic forms, criteria for prioritizing values, and adaptability to evolving values or specific contexts. In contrast, GPLA utilizes LLMs to dynamically extract perceptions and generate corresponding values, offering the following advantages.\n\u2022 Comprehensive Coverage. LLMs can generate values in diverse linguistic forms, beyond words in dictionaries and thesauruses, and thus provide more comprehensive coverage of values. Please refer to Appendix B.1 for the empirical evidence.\n\u2022 Prioritization Criteria. The scalable collection of value lexicons by LLMs enables the concurrent collection of their occurrence frequencies. Since these frequencies reflect the salience of values, they can serve as criteria for prioritizing values during the filtering process.\n\u2022 Adaptability. Since LLMs are trained on Internet-scale data with evolving language patterns, they effectively encode up-to-date knowledge of values and are readily adaptable to changing values in changing corpora distributions.\n\u2022 Context Specificity. GPLA constructs value systems given corpora from specific contexts, which can capture the unique values and value structures in those contexts. It enables the construction of LLM value systems."}, {"title": "Benchmarking LLM Value Systems", "content": "The power of a value system lies in its validity and utility. This work introduces, for the first time, three benchmarking tasks for LLM value systems, rooted in both psychological theories and AI priorities: (1) Confirmatory Factor Analysis, which evaluates their structure validity given LLM value measurements; (2) LLM Safety Prediction, which assesses their predictive validity for LLM safety; and (3) LLM Value Alignment, which examines their representation power in aligning LLMs with human values."}, {"title": "Confirmatory Factor Analysis for Evaluating Structure Validity", "content": "Confirmatory Factor Analysis (CFA) is a statistical technique used to test whether a set of observed variables (atomic values) accurately represents and loads onto a smaller number of underlying latent factors (high-level values). Mathematically, the CFA model is represented as:\n$X = FAT + \\epsilon$,\nwhere $X \\in \\mathbb{R}^{n\\times|V|}$ is the observed data matrix (measuring atomic values); $F \\in \\mathbb{R}^{n\\times|V_H|}$ is the matrix of latent factors (aggregated measurements of high-level value factors); $A \\in \\mathbb{R}^{|V|\\times|V_H|}$ is the matrix of factor loadings (the contribution of each atomic value to each latent factor); and $\\epsilon \\in \\mathbb{R}^{n\\times|V|}$ is the matrix of error terms.\nThis task evaluates the model fit on held-out value measurement data. Better model fit indicates higher structure validity of the system."}, {"title": "LLM Safety Prediction for Evaluating Predictive Validity", "content": "Predictive validity refers to how well measurement results based on a particular value system can anticipate future decisions, actions, or outcomes. In the context of human values, evaluating predictive validity often involves examining the correlations between values and other psychological constructs, such as personality traits and attitudes. For LLMs, we propose to evaluate the predictive validity of a value system by examining the relationship between its values and LLM safety, arguably one of the most critical concerns and \"psychological constructs\" for LLM deployment.\nTo this end, we draw prompts and safety scores from the established safety benchmark SALAD-Bench. We administer the prompts to LLMs, collect their responses, and measure the revealed values using GPV. We follow the linear probing protocol to evaluate the predictive validity of the value representations under different value systems. Using the Bradley-Terry model, we train a linear classifier with pairwise cross-entropy loss to predict the relative safety of LLM pairs:\n$s_{M_i} = Linear(x_{M_i}),$\n$P(M_i > M_j) = \\frac{exp(s_{M_i})}{exp(s_{M_i}) + exp(s_{M_j})}.$\nHere, $s_{M_i} \\in \\mathbb{R}$ is the predicted LLM safety score, and $x_{M_i} \\in \\mathbb{R}^{|V_H|}$ is the vector of LLM values under a particular value system. In this case, we only care about the relative safety of LLM pairs, not absolute safety scores. Therefore, the predictive validity is indicated by the binary classification accuracy of a well-trained linear classifier."}, {"title": "LLM Value Alignment for Evaluating Representation Power", "content": "Values are cognitive representations of motivational goals. A well-constructed value system should be able to fully represent the broad motivations behind LLM outputs, therefore enabling effective transituational alignment of LLMs with human values."}, {"title": "Results", "content": "This section presents the results of our experiments, including the proposed LLM value system, the analysis of the system, and the benchmarking of our system against the well-established Schwartz's values."}, {"title": "Proposed Value System", "content": "Fig. 2 visualizes the value system constructed by GPLA. Table 1 gathers its factor loadings, Cronbach's Alpha, and confidence intervals. The factor loadings indicate the strength of the relationship between each factor and its atomic values, with higher loadings suggesting more contribution to the factor. Cronbach's Alpha measures the internal consistency of each factor, with higher values indicating greater reliability. Some atomic values are removed to ensure clear loading patterns and desirable factor reliability. After that, all our factors reach the standard psychometric threshold of 0.7, indicating strong internal consistency.\nBy analyzing the factor loadings, we can better understand the system structure and the underlying implications of each factor.\nFactor 1: Social Responsibility. This factor reflects values centered on collective well-being and ethical social engagement. The high loadings on Equity (0.890), Empathy (0.885), and Teamwork (0.872) highlight its emphasis on fairness and collaboration. Values such as Equality (0.827) and Unity (0.825) indicate a strong focus on inclusivity. Public Benefit (0.820) and Democracy (0.813) support the broader societal perspective and prioritize the common good.\nFactor 2: Risk-Taking. This factor embodies a preference for dynamism, exploration, and adaptability. High loadings for Challenge (0.812), Boldness (0.804), and Adventure (0.798) illustrate a willingness to confront uncertainty and seek new experiences. Values such as Change (0.730), Flexibility (0.721), and negatively loaded Stability (-0.701) underscore openness to transformation, while Thrill-seeking (0.728) further conveys a desire for excitement."}, {"title": "Analyzing Value System", "content": "Value Correlation Analysis. Fig. 3 (Top) presents the correlations between the factors in our value system. Similar to Schwartz's theory of basic human values, LLM values also exhibit both compatible and opposing relationships. Notably, social responsibility, rule-following, and rationality show positive correlations with one another, while all of them are negatively correlated with risk-taking.\nCircumplex Analysis. Circumplex analysis is a statistical method that examines whether the underlying structure of variables aligns with a circumplex pattern, and, if so, the positions of variables on a circle. The stronger the correlation between variables, the shorter their distance on the circumference. We conduct circumplex analysis based on the correlations between factors. Fig. 3 (Bottom) illustrates the analysis results based on Browne's circular stochastic process model. The compatible values are closer on the circle (e.g., Social Responsibility and Rule-Following) while opposing values are positioned diagonally (e.g., Risk-Taking and Rule-Following). The results verify the presence of a circumplex structure in the value system.\nConsistency Across Datasets. To evaluate the consistency and robustness of our multivariate system structure (i.e., the 5-dimensional relationship), we measure LLM values using two distinct prompt datasets: the psychometric prompts from GPV and the red-teaming prompts from SALAD-Bench, which feature distinct prompt distributions. Their measurements yield an average intra-LLM correlation of 0.87; here we use intra-LLM correlations because the relative value hierarchy within an LLM is more important than their absolute measurements. This result indicates a high level of consistency in the value structure across prompt distributions. We also find a high correlation (0.73) between intra-LLM value consistency and LLM safety scores. It suggests that LLMs with higher value consistency tend to be safer.\nComparing Value Systems. We benchmark the proposed value system against Schwartz's value system, the most established framework for human values and commonly used in LLM value studies."}, {"title": "Conclusion", "content": "This study presents GPLA, a novel psychologically grounded paradigm that enables automated, scalable, adaptable, and non-reactive value system construction. With GPLA, we introduce the first theoretically and empirically validated five-factor LLM value system, encompassing Social Responsibility, Risk-Taking, Rule-Following, Self-Competence, and Rationality. We accompany the value system with three benchmarking tasks, rooted in both psychological theories and AI priorities. Experimental results confirm the superior validity and utility of the proposed value system compared to the canonical Schwartz's values."}, {"title": "Limitations", "content": "This study is limited to identifying and measuring values in English. Values are both culturally and linguistically sensitive, and LLM value orientations can vary across languages. Future work will extend GPLA to multilingual contexts.\nIn addition, we follow BaseAlign when benchmarking value systems on value alignment. However, the algorithm, like many existing alignment methods, assumes a single, consistent alignment target. Future work should explore distributional and pluralistic alignment to more holistically evaluate a value system."}, {"title": "Experimental Details", "content": ""}, {"title": "Data Statistics for Collecting Value Lexicons", "content": "We collect value-laden LLM generations from four data sources: ValueBench, GPV, ValueLex, and BeaverTails. They provide data of different forms: raw LLM responses, parsed perceptions (a sentence that is highly reflective of values), and annotated values.\nValueBench is a collection of customized inventories for evaluating LLM values based on their responses to advice-seeking user queries. By administering the inventories to a set of LLMs, the authors collect 11,928 responses, each considered as one perception. The responses are annotated with 37,526 values by Kaleido, of which 330 are unique.\nGPV is a psychologically grounded framework for measuring LLM values given their free-form outputs. Perceptions are considered atomic measurement units in GPV, and the authors collect 24,179 perceptions from a set of LLM subjects. The perceptions are annotated with 62,762 values, of which 361 are unique.\nIn ValueLex, the authors collect 745 unique values from a set of fine-tuned LLMs via direct prompting.\nBeaverTails is an AI safety-focused collection. We use a subset of the BeaverTails dataset, which contains 3012 LLM responses, which are then parsed into 10,008 perceptions. The perceptions are annotated with 21,968 values, of which 395 are unique.\nWe combine the data from the four sources and obtain 123 unique values after filtering."}, {"title": "LLM Subjects", "content": "Our experiments involve 33 LLMs coupled with 21 profiling prompts."}, {"title": "Value Measurement for Structuring Value System", "content": "We measure the value orientations of the LLMs subjects following GPV. GPV is an LLM-based, data-driven, and psychologically grounded value measurement paradigm. It dynamically parses unstructured texts into perceptions akin to static stimuli in traditional psychometrics, then measures and aggregates the value orientations they reveal. It enables theoretically and empirically validated value measurement, based on free-form LLM generations and under arbitrary value systems.\nIn this study, we measure LLM values to compute the correlations between our 123 atomic values and derive the value system structure. Similar to , we generate one advice-seeking and value-eliciting prompt for each of the atomic values, using Prompt 1. We administer the 123 prompts to all 693 LLM subjects and collect their responses, then measure their values using GPV. Each value dimension is measured using all responses. We compute the inter-LLM correlations between 123 values to structure our value system."}, {"title": "Extended Results", "content": ""}, {"title": "Comprehensiveness of the Collected Lexicon", "content": "The utility of value systems lies in their ability to capture the nuances of real-world behaviors and attitudes. We refer to real-world human-LLM conversations to evaluate the comprehensiveness of the collected lexicon.\nWe draw real-world Human-LLM conversations from LMSYS-Chat-1M. Its 1M conversations are clustered into 20 types in the original literature. Some of the types are purely task-oriented, such as discussing software errors and solutions, while others are more likely to involve value-laden interactions, such as role-playing and discussing various characters. We select four types of conversations of the latter category: 1) discussing and describing various characters, 2) creating and improving business strategies and products, 3) discussing toxic behavior across different identities, and 4) generating brief sentences for various job roles. Since the open-source dataset does not provide the cluster labels, we label the conversations using text-embedding-3-large as the zero-shot classifier. After that, we randomly select 512 conversations covering all four types as the test dataset."}, {"title": "Principal Component Analysis", "content": "We apply principal component analysis (PCA) to identify the underlying factors in our value system. The number of factors to retain is determined using both the scree plot and Cronbach's alpha. The scree plot, shown in Fig. 4, reveals an elbow at the fifth or sixth component. We retain five factors due to their high reliability. Full factor loadings are provided in Table 10."}, {"title": "Consistency Across Datasets", "content": "In \u00a7 6, we use the default profiling prompt for evaluating cross-dataset consistency. Table 11 displays the intra-LLM correlation of the two value measurements for each LLM. In addition, we include the model safety scores from SALAD-Bench for reference. The results show that the intra-LLM correlation is generally high (0.87 on average), indicating the robustness of our value system. We also find that the intra-LLM value consistency is positively correlated with its safety (0.73)."}, {"title": "Correlation with Schwartz's Values", "content": "We also measure the Schwartz's values of the LLMs subjects. Table 12 presents the correlation between our factors and Schwartz's values. The results can offer additional insights into our values.\nSome of our values demonstrate a strong correlation with Schwartz's values, such as Social Responsibility with Benevolence, Rule-Following with Security, and Self-Competence with Achievement. This indicates that LLMs exhibit partial similarity to the human value system. However, the correlation between rationality and all Schwartz values is less than 0.5, revealing a divergence between LLMs and human value systems. This is consistent with the fact that LLMs typically demonstrate higher levels of rationality than humans in many scenarios."}, {"title": "Contributions of Values to Safety", "content": "In the LLM safety prediction (\u00a7 5.2) task, we train a linear classifier to predict the safety score of LLMs based on their values. The parameters of a well-trained classifier can be interpreted as the contributions of each value to the safety score. Such parameters, averaged over all trails, are gathered in Table 13. The results show that Social Responsibility, Rule-Following, and Rationality positively contribute to safety, while Risk-taking and Self-Competence negatively contribute to safety."}, {"title": "Comparative Analysis Against ValueLex", "content": "Biedma et al. proposed a lexical approach to constructing value systems for LLMs. While their work offers valuable contributions, we believe that core aspects of their approach could benefit from further theoretical and empirical development. In the following, we present a detailed comparative analysis of GPLA in relation to their work."}, {"title": "Lexicon Collection", "content": "Biedma et al. employ direct prompts such as \"List the words that most accurately represent your value system\" to extract value lexicons. However, direct questioning may not fully capture an LLM's complete spectrum of values. This work, in contrast, uses indirect, contextually guided questions to elicit a more comprehensive expression of values from LLMs."}, {"title": "Computing Value Correlations", "content": "The structure of a value system is derived from correlations between different values. In psychology research, researchers measure the value hierarchies of the participants to gather data, then use correlation derived from the data to evaluate interrelationships among these values. High positive correlations indicate values that are often endorsed together, while negative correlations show contrasting values. From these correlations, researchers can map and cluster values, revealing underlying value structures and hidden value factors (\u00a7 3, Value Measurement and System Construction).\nThe method proposed by Biedma et al. derives correlations based on the co-occurrence of value lexicons in LLM self-reports in response to direct prompts. However, this approach lacks a theoretical foundation in psychology. We hypothesize that the co-occurrence of value lexicons in LLM responses does not necessarily indicate a true correlation between values. To test this hypothesis, we examine the correlation derived from their method for Schwartz's values.\nExperimental Setup. We pair each of the collected value lexicons in with the most semantically similar Schwartz's value according to the embedding model. Then, we can compute the correlation between Schwartz's values using the normalized co-occurrence frequency of the original lexicons, following the method in.\nSubjects. Biedma et al. tune the generation hyperparameters (e.g., temperature, top-p) for different LLMs, attempting to generate diverse LLM subjects. However, simply tuning the generation hyperparameters is not sufficient to ensure the diversity and coverage of the LLM subjects, as they are not effective"}]}