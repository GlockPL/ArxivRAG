{"title": "EVALUATING EXPLAINABLE AI METHODS IN DEEP LEARNING MODELS FOR EARLY DETECTION OF CEREBRAL PALSY", "authors": ["Kimji N. Pellano", "Inga Str\u00fcmke", "Daniel Groos", "Lars Adde", "Espen Alexander F. Ihlen"], "abstract": "Early detection of Cerebral Palsy (CP) is crucial for effective intervention and monitoring. This paper tests the reliability and applicability of Explainable AI (XAI) methods using a deep learning method that predicts CP by analyzing skeletal data extracted from video recordings of infant movements. Specifically, we use XAI evaluation metrics namely faithfulness and stability to quantitatively assess the reliability of Class Activation Mapping (CAM) and Gradient-weighted Class Activation Mapping (Grad-CAM) in this specific medical application. We utilize a unique dataset of infant movements and apply skeleton data perturbations without distorting the original dynamics of the infant movements. Our CP prediction model utilizes an ensemble approach, so we evaluate the XAI metrics performances for both the overall ensemble and the individual models. Our findings indicate that both XAI methods effectively identify key body points influencing CP predictions and that the explanations are robust against minor data perturbations. Grad-CAM significantly outperforms CAM in the RISv metric, which measures stability in terms of velocity. In contrast, CAM performs better in the RISb metric, which relates to bone stability, and the RRS metric, which assesses internal representation robustness. Individual models within the ensemble show varied results, and neither CAM nor Grad-CAM consistently outperform the other, with the ensemble approach providing a representation of outcomes from its constituent models. Both CAM and Grad-CAM also perform significantly better than random attribution, supporting the robustness of these XA\u0399 methods. Our work demonstrates that XAI methods can offer reliable and stable explanations for CP prediction models. Future studies should further investigate how the explanations can enhance our understanding of specific movement patterns characterizing healthy and pathological development.", "sections": [{"title": "1. INTRODUCTION", "content": "Cerebral Palsy (CP) is the most common motor disability in children, and it is essential to detect it early for effective early intervention and surveillance [1]. Machine learning based technologies are increasingly being explored in the early detection of CP due to its potential for more accurate, accessible, and timely diagnoses. Specifically, deep learning methods have shown great potential in medical diagnostics due to their ability to detect complex patterns in large sets of data. For instance, McCay et al. developed a deep learning framework that classifies infant movements from RGB videos using extracted pose-based features to identify Fidgety Movements (FMs) [2]. Similarly, Groos et al. introduced a method leveraging deep learning to predict CP from skeletal data captured in spontaneous infant movements, validated across a multicenter cohort [3]. Additionally, Zhang et al. designed CP-AGCN, a graph convolutional network (GCN) that uses skeletal data from RGB videos and a frequency-binning module to classify CP risks in infants [4]. Gao et al. implemented a deep learning model to automate early CP detection by analyzing FMs in video sequences [5]. There are several data modalities that can be analyzed for early CP prediction such as in the sensor fusion approach proposed by Kulvicius et al. [6], but this paper focuses on analyzing skeletal data extracted from video recordings via pose estimation, noting its broader applicability to areas such as abnormal gait detection [7], Parkinson's disease gait assessment [8], fall detection [9], and other health-related applications.\nDespite its promising potential, the use of AI in medical diagnostics introduces new challenges, including the widely discussed problem of explainability and transparency. Deep learning models' inherent lack of interpretability \u2013 commonly referred to as the 'black box' challenge \u2013 is problematic in a medical setting, where clear explanations for diagnoses is a requirement. To build trust in AI-driven diagnostic tools among clinicians and patients, and facilitate possible imple-"}, {"title": "1.1. \u03a7\u0391\u0399 Methods", "content": "The following section discusses the various XAI methods implemented for the skeleton-based CP prediction model. These methods will subsequently be assessed using the XAI evaluation metrics."}, {"title": "1.1.1. Class Activation Mapping (CAM)", "content": "CAM was originally introduced as a method for identifying important pixels in an image [15] as determined by a CNN model. It projects the model's output layer weights onto a convolutional layer's feature maps (usually from the final layer), creating a heatmap that highlights the areas influencing the network's predictions,\n$e_{x, CAM} = \\sum_n w^{class}_n F_n$ (1)"}, {"title": "1.1.2. Gradient-Weighted Class Activation Mapping (Grad-CAM)", "content": "CAM has several weaknesses, such as the lack of flexibility in model architecture due to the need for a GAP layer and a Fully Connected (FC) layer for classification. Gradient-weighted Class Activation Mapping (Grad-CAM) [17] addresses this by using gradients entering the FC layer instead of weights, calculated via\n$e_{x, Grad-CAM} = \\sum_n \\alpha^{class}_n F_n$, (2)\nthus making it adaptable to various CNN architectures. Since the introduction of Grad-CAM, many other CAM-based methods have been introduced to further improve the original CAM. Similarly to CAM, Grad-CAM has been shown to be applicable to GCN-based HAR using skeleton data, as illustrated by Das et al. [18]."}, {"title": "1.2. \u03a7\u0391\u0399 \u0395valuation Metrics", "content": "In our previous work [19], we explored various metrics proposed in [20] to evaluate explanations from different X\u0391\u0399 methods within the context of skeleton-based HAR. Building on these foundations, this paper aims to extend these evaluation techniques to a specific medical application, which is skeleton-based CP prediction. The following subsections give a brief overview of the applied metrics, illustrating their applicability and relevance in a specific medical use-case. Consider X as the original input data, with its corresponding explanation $e_x$, and let $f(\\cdot)$ denote the model's output, representing CP risk. Then, X' is the perturbed version of X, and $e'_x$ stands for its corresponding explanation following the perturbation. Top-k refers to the most important features in the input data, while non-top-k refers to the remaining, less important features."}, {"title": "1.2.1. Faithfulness", "content": "Fidelity or faithfulness [21, 22, 23] checks whether an explanation accurately identifies the features that influence a model's predictions. The Prediction Gap on Important features (PGI) in Equation (3) quantifies the prediction change when key features are altered, while the Prediction Gap on Unimportant features (PGU) in Equation (4) measures the change when minor features are modified. Ideally, when important features are perturbed, there should be a significant change in the model prediction. Conversely, perturbing unimportant features should have little effect on the prediction. By this logic, a good XAI method should identify both important and unimportant features in a way that results in a high PGI and a low PGU.\n$PGI(X, f,e_x, k) = E_{X'\\sim perturb(X,e_x,top-k)}[| f(X) - f(X')|]$ (3)\n$PGU(X, f,e_x, k) = E_{X'\\sim perturb(X,e_x,non top-k)}[| f(X)-f(X')|]$ (4)"}, {"title": "1.2.2. Stability", "content": "Stability or robustness [24, 25], measures how much an explanation changes relative to changes in the model's input, output, or internal representation when the original input data undergo minor perturbations, as shown in Equations (5)-(7). Relative Input Stability (RIS) includes three components for each of the model's multiple input streams: position, velocity, and bone, referred to as RISp, RISv, and RISb, respectively. ROS refers to Relative Output Stability and RRS refers to Relative Representation Stability. To better understand these concepts in relation to the variables in the model,\n$RIS (X, X', e_x, e_{x'}) = max_{X'}  max (\\frac{||e_x - e_{x'}||_p}{||e_x||_p}, \\epsilon_{min})$\n$\\forall X' s.t. X' \\in N_x; f(X) = f(X')$ (5)\n$ROS (X, X', e_x, e_{x'}) = max_{X'}  max (\\frac{||e_x - e_{x'}||_p}{||e_x||_p},\\frac{|(f(X)-f(X'))|}{f(X)}, \\epsilon_{min})$\n$\\forall X' s.t. X' \\in N_x; f(X) = f(X')$ (6)\n$RRS (X, X', e_x, e_{x'}) = max_{X'}  max (\\frac{||e_x - e_{x'}||_p}{||e_x||_p},\\frac{|(L_x-L_{x'})|}{L_x}, \\epsilon_{min})$\n$\\forall X' s.t. X' \\in N_x; f(X) = f(X').$ (7)"}, {"title": "1.3. CP Dataset", "content": "The dataset used in this study originates from Groos et al. [3], and is made up of 557 infants at elevated risk of perinatal brain injury, gathered from 13 different hospitals in Norway, Belgium, India, and the US. In compliance with Prechtl's GMA tool protocols, the infants were filmed during the FM period occurring between 9 and 18 weeks' corrected age. Using the CP decision tree from the Surveillance of Cerebral Palsy in Europe [26], a pediatrician determined their CP statuses at 12 months corrected age or older. Of the 557 videos, 75% were allocated for model training and validation, while the remaining 25% formed the test set which is used in this paper.\nOf the 139 videos in the test set, 21 are true CP cases and 118 are true No CP cases. For the XAI metrics testing, extracted skeleton tracker data from the original videos were used instead of the videos themselves. Given the long testing times for computing XAI metrics (approximately 1 hour per 5-second window on an RTX3090 GPU), random 5-second window samples were taken from the tracker data, proportional to the video length. For example, only one 5-second window sample was taken from the shortest videos.\nMoreover, since testing for stability metric requires that the true label matches the predicted label, only correctly predicted data were used, resulting in 15 CP and 111 No CP cases. From these, 24 random 5-second windows were selected from CP data and 136 from No CP data, maintaining the original CP to No-CP ratio. Additionally, windows at the beginning or end of the videos were avoided to reduce noise, and non-overlapping 5-second windows were chosen to avoid redundant data."}, {"title": "1.4. CP Prediction Model", "content": "The same deep learning-based CP prediction model from the Groos et al. study [3] was evaluated for the XAI metrics. This model uses a GCN architecture to process infants' biomechanical movement properties, namely positions, velocities, and bones (distances between body keypoints). The GCN architecture was optimized through an automatic search, which created 70 distinct model instances, each trained on different sections of the dataset. Refinement of the model involved hyperparameter tuning and an automatic Neural Architecture Search (NAS) approach, exploring various architectural designs and configurations. The final Ensemble-NAS-GCN model combines predictions from the 70 GCN instances,\nfrom all 70 GCN instances were collected and unified by calculating the median score for each body point. There were no alterations made to the CP prediction pipeline except for capturing intermediate variables, such as model weights and gradients needed for the XAI metric evaluation."}, {"title": "2. METHODS", "content": ""}, {"title": "2.1. Skeleton Data Perturbation", "content": "As demonstrated in our previous work [19], skeleton joints can be perturbed by converting Cartesian coordinates to spherical coordinates. This is performed using the equations below, where dx and dy represent the perturbation magnitudes along the x- and y-axes respectively, P is the original point, P' is the new perturbed point, x' and y' are the new coordinates, x and y are the original coordinates, and @ is the randomly generated azimuthal angle:\nr = ||P - P'||\ndx = r cos \u03b8\nx' = x + dx\ndy = r sin 0\ny' = y + dy.\nEquations (5), (6), (7) require that the perturbed input data X' remains close to the original data X, which also maintains accurate human kinematics and preserving the integrity of model predictions. To achieve this, r is set to 1% of the median height of the infant across all frames in a 5-second window. The infant coordinate data are in pixels and height is calculated as the Euclidean distance between the head and left ankle. The values dx and dy are computed once for each joint and applied consistently across all video frames, producing a perturbed 2D point."}, {"title": "2.2. Calculation and Evaluation of XAI Metrics", "content": "The first step is to obtain the explanation for the original unperturbed data. The skeleton tracker data is fed into the CP prediction pipeline after Data Preprocess stage. Each model in the ensemble generates its own explanation according to Equations (1) and (2). These individual explanations are combined by calculating the median values, representing the overall explanation for the ensemble. Similarly, individual model output predictions are combined by taking the median value, representing the ensemble's output prediction. This process yields the terms f(X), ex, and X. The term Lx is derived by collecting internal representations from the final FC layer before the softmax function of each model and flattening them into a single array."}, {"title": "3. RESULTS AND DISCUSSION", "content": "A line plot is used to comparatively show the metrics performance of each XAI method. The numerical results with confidence intervals are shown in the Appendix."}, {"title": "3.1. Faithfulness", "content": "PGI results indicate that the ensemble's predictions are influenced by key features identified by the two XAI methods (i.e. the change in output probability f(X) increases when important nodes are perturbed), with a significant difference compared to the random attribution at p < 0.005 for both CAM versus random and Grad-CAM versus random. There was no significant difference in PGI and PGU between CAM and Grad-CAM. Overall, the faithfulness tests indicate that XAI methods effectively distinguish important from unimportant body points influencing predictions."}, {"title": "3.2. Stability", "content": "The plots of RISp, RISv, RISb, ROS, and RRS immediately show us that random explanations cause significant changes in the stability results, with p < 0.005 for both CAM versus random and Grad-CAM versus random. This indicates that both XAI methods are less susceptible to large explanation changes with small input perturbations. Most notably, Grad-CAM offers a highly significant improvement (with p < 8.507 \u00d7 10-7) of input stability compared to CAM for RISv of the ensamble model. In contrast, CAM offers a significantly better input stability (with p < 0.05) compared to Grad-CAM for RISb and RRS."}, {"title": "4. CONCLUSION AND RECOMMENDATION", "content": "This study evaluated the reliability and robustness of two XAI techniques, CAM and Grad-CAM, within a deep learning ensemble model. The faithfulness metrics show both methods are effective in identifying important and unimportant body points influencing CP predictions, while stability tests demonstrate robustness against minor data perturbations. Specifically, CAM significantly outperformed Grad-CAM in RISb and RRS, while Grad-CAM excelled in RISv. The choice of XAI method depends on the specific application and key metrics. For instance, to identify potential movement biomarkers for CP related to joint velocity, Grad-CAM is recommended for its superior RISv performance. This also suggests exploring the velocity input branch for possible CP movement biomarkers, which aligns with previous studies where a velocity parameter is used in classical machine learning assessments of CP. If similar explanations for body points are found in multiple 5-second windows, Grad-CAM offers better insight into body point velocity due to its stable explanations despite input variations. Conversely, for quick explanations (i.e. for visual inspection purposes), CAM is preferable due to its faster calculation time.\nIndividual models in the ensemble show varied results in metrics tests, while the ensemble provides a combined outcome from its constituent models. This study has evaluated XAI metrics in both an ensemble and the individual models composing it, revealing that neither CAM nor Grad-CAM consistently outperforms the other in all metrics. Overall, our findings demonstrate that both XAI methods can provide reliable and stable explanations in CP prediction models. By finding patterns and doing further studies into the explanations, these could potentially supplement GMA observers with specialized domain knowledge, contributing to more interpretable and trustworthy AI diagnostics. The study's insights into the comparative performance of CAM and Grad-CAM can also guide future research in improving AI explainability in other high-stakes medical applications. As a next step, it is crucial to introduce more XAI metrics that incorporate domain-specific knowledge to further validate the relevance and accuracy of the explanations provided. It is also necessary to perform clinical interpretations on the explanations to enhance the practical utility of the models."}]}