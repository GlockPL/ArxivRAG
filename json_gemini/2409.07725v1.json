{"title": "GRE2-MDCL: Graph Representation Embedding\nEnhanced via Multidimensional Contrastive\nLearning", "authors": ["Kaizhe Fan", "Quanjun Li"], "abstract": "Abstract\u2014Graph representation learning aims to preserve\ngraph topology when mapping nodes to vector representa-\ntions, enabling downstream tasks like node classification and\ncommunity detection. However, most graph neural network\nmodels require extensive labelled data, limiting their practical\napplicability. To address this, researchers have explored Graph\nContrastive Learning (GCL), which uses enhanced graph data\nand contrastive learning to better capture graph structure and\nfeatures, providing new avenues for solving real-world problems\nwith limited labelled data. Building on this, this work proposes\nGraph Representation Embedding Enhanced via Multidimen-\nsional Contrastive Learning (GRE2-MDCL). GRE2-MDCL first\nglobally and locally augments the input graph using SVD and\nLAGNN. The enhanced data is then fed into a triple network\nwith a multi-head attention GNN as the core model. Finally,\nGRE2-MDCL constructs a multidimensional contrastive loss,\nincorporating cross-network, cross-view, and neighbor contrast,\nto optimize the model. Evaluated on Cora, Citeseer, and PubMed,\nGRE2-MDCL achieves average accuracies of 82.5%, 72.5%,\nand 81.6%, outperforming baseline GCL models. Visualizations\nalso show tighter intra-cluster aggregation and clearer inter-\ncluster boundaries, demonstrating the framework's effectiveness\nin improving upon the baseline.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, graph representation learning, an emerging\nmachine learning approach, has become increasingly preva-\nlent in fields such as social networks, knowledge graphs,\nand recommender systems, garnering substantial attention and\nresearch from both academia and industry. Unlike traditional\nclassification methods, graph representation learning can ef-\nfectively process graph-structured data. Its primary goal is\nto preserve the topological information of the graph as ac-\ncurately as possible when mapping the graph structure to a\nlow-dimensional vector space, enabling more effective data\nprocessing.\nIn a typical graph contrastive learning (GCL) framework,\nthe first step is to generate differential graph-enhanced views\nthrough various graph augmentation techniques. For example,\nDGI [19] enhances the original graph by blending node\nattributes, GRACE [8] destroys the graph by uniformly remov-\ning edges and masking attributes, and MVGRL [14] enhances\nthe input graph through graph diffusion to generate local and\nglobal structural views. GraphCL [20] involves four types\nof graph augmentation: node discarding, edge perturbation,\nattribute masking, and subgraph extraction. However, due to\nthe diverse nature of graphs, these manual augmentations\nhave been shown to be sensitive to different graph datasets,\nlimiting the efficiency and generalizability of GCL methods.\nTo address this, researchers have conducted in-depth studies\non adaptive graph augmentation. Building upon GRACE,\nGCA [15] adaptively adjusts edge probabilities and attribute\nmasking based on centrality heuristics. G-Mixup [21] performs\ndata augmentation by inserting a generator with different graph\nclasses, while AutoGCL [22] employs a set of learnable graph\nview generators with an automatic enhancement strategy.\nNCLA [18] generates a comprehensive learnable graph using a\nmulti-head graph attention mechanism. Additionally, Bernstein\npolynomial approximations have been used to design and learn\narbitrary graph filters [2]. In terms of spatial methods, the core\noperation of graph convolution is to propagate or aggregate\nneighborhood information directly along the edges to the\ncentral node. GAT [7] introduced a novel neural network ar-\nchitecture that utilizes a masked self-attentive layer to address\nthe limitations of previous graph convolution-based methods.\nInspired by GAT, Graph Converter [1] uses explicit rela-\ntional encoding to allow direct communication between distant\nnodes, providing a more efficient approach for modeling global\ngraph structures. Geom-GCN [3] argues that graph aggregation\ncan benefit from the continuous space underlying the graph,\nproposing a replacement-invariant aggregation scheme. To\naddress the limitations of current graph neural networks, Zhu\net al. [15] emphasized the need for separating self-embedding"}, {"title": "II. GRE2-MDCL MODEL CONSTRUCTION", "content": "In this paper, we propose a new algorithm, GRE2-MDCL,\nto learn node representations through the framework of triple\ngraph neural networks and multidimensional graph contrast\nlearning. As shown in Fig. 1, the model in this paper mainly\nconsists of three parts: graph enhancement, triple graph neural\nnetwork and multi-dimensional graph comparison learning.\nWhen performing model training, this paper first generates two\naugmented graph views, denoted as $G_1$ and $G_2$, based on the\noriginal view G, and then inputs them into a triple graph neural\nnetwork, the main model of each network of the triple graph\nneural network is a multi-head attention graph neural network,\nand in addition, the online network adds an extra predictor t\ncompared with the target network to satisfy the heterogeneity\nof the model. Afterwards, the three views are processed\nby the online network and the two target networks thus\nobtaining node representations for different views and different\nnetworks. And then, different graph comparison methods are\nconstructed in multiple dimensions in the potential space,\nand the loss obtained from comparison learning is used to\ncontinuously guide the model to update the parameters and\napply the trained embedded representations to the downstream\ntasks.\nGraph data enhancement is a key component of self-\nsupervised visual representation learning. In GRE2-MDCL,\nthis paper firstly selects the LAGNN approach and the ret-\nrograde local graph enhancement to solve the problem of\ninsufficient graph neural network expressive ability when the\nnumber of nodes is small in graph comparison learning.\nSecondly, in order to make the graph comparison learning have\nthe ability of global structure learning and avoid destroying the\nglobal structure or important topological features of the graph,\nthe SVD scheme is chosen for global graph data enhancement."}, {"title": "A. LAGNN", "content": "In this paper, we draw on the local graph enhancement\napproach in the LAGNN model to enhance the original data,\nwhich generates more features in the local neighbourhood,\nespecially for nodes with few neighbours to enhance the\nexpressive power of various GNNs. In order to generate more\nfeatures in the neighbourhood $N_v$, of node v, the distribution\nof features of its neighbouring nodes needs to be known. Since\nthis distribution is associated with the central node v, the\nLAGNN learns by generating models based on the features\nof the central node.\nLAGNN uses conditional variational autoencoders to learn\nthe conditional distribution of the node features of the\nconnected neighbour nodes of a given central node v. In\nCVAE, $X_v$ is used as a condition since the distribution\nof $X_u$ ($u \\in N_v$) is related to $X_v$. The latent variable z is\ngenerated by the prior distribution $p_\\theta(z | X_v)$ and $X_u$ is\ngenerated by the generative distribution $p_\\theta(X_u | X_v, z)$, where\n$z \\sim p_\\theta(z | X_v)$, $X_u \\sim p_\\theta(X_u | X_v, z_v)$. Let $\\phi$ denote the\nvariational parameter and $\\theta$ denote the generating parameter.\n$\\log p_\\theta (X_u | X_v)$ is shown in Equation (1) as follows:\n$\\log p_\\theta(X_u | X_v) = \\int q_\\phi(z | X_u, X_v) \\log \\frac{p_\\theta (X_u, z | X_v)}{q_\\phi(z | X_u, X_v)} dz + KL(q_\\phi(z | X_u, X_v) ||p_\\theta(z | X_v)) \\\\ \\geq \\int q_\\phi(z | X_u, X_v) \\log \\frac{p_\\theta (X_u, z | X_v)}{q_\\phi(z | X_u, X_v)} dz$\nAnd the evidence lower bound (ELBO) can be expressed as\nshown in Equation (2):\n$L(X, X_v; \\theta, \\phi) = -KL(q_\\phi(z | X_u, X_v) ||p_\\theta(z | X_v)) + \\frac{1}{L} \\sum_{l=1}^{L} \\log p_\\theta (X_u | X_v, z^{(l)})$"}, {"title": "B. SVD Graph Enhancement", "content": "Singular value decomposition is a method to decompose a\nmatrix into singular vectors and singular values. Specifically,\nin this paper, the SVD operation is first performed on the\nfeature matrix F, i.e., $F = USV^T$. Where, U, V are column\northogonal matrix and row orthogonal matrix S are the diago-\nnal matrices storing the singular values of the feature matrix F,\nrespectively. The singular values indicate the importance of the\nmatrix in different directions, the singular vectors correspond-\ning to the first ranked singular values usually contain the most\nimportant information the largest singular values, associated\nwith the principal components of the matrix. Retaining the\nlargest singular values and the corresponding singular vectors\nachieves data enhancement by retaining the most important\ninformation, i.e., the most dominant features of the data and\nignoring the minor features that have less impact on the overall\ndata. Therefore, in this paper, the list of singular values is\ntruncated to keep the larger singular values and the truncated\nreconstructed normalised adjacency matrix is used to obtain\nthe globally enhanced view $G_2$."}, {"title": "C. Multi-Dimensional Contrastive Learning", "content": "Contrastive learning, a widely used unsupervised data aug-\nmentation method, has demonstrated excellent performance\nacross various domains. By constructing pairs of positive\nand negative samples and training a model to make the\npositive samples as close to each other as possible and the\nnegative samples as far apart as possible, contrastive learning\nenables the model to extract more accurate and informative\nrepresentations. In this work, three modes of comparison are\nintegrated to construct sample pairs at the node level: cross-\nnetwork comparison, cross-view comparison, and neighbor\ncomparison. The schematic diagrams of these comparison\nmodes are shown in Fig. 2. (See the appendix for details of\nthe specific proof of derivation.)\n1) Cross-network Contrastiveness: In this paper, cosine\nsimilarity (sim) is chosen to measure the degree of similarity\nbetween two nodes, and by adopting the logarithmic form in\norder to facilitate the calculation of entropy for similarity.\nMeanwhile, the hyperparameter $\\alpha$ is introduced to measure\nthe rate of information transfer between networks due to the\nemphasis on the guiding role of the online network to the\ntarget network. Therefore, the crossnetwork comparison loss\nfunction of $G_1$ is shown in Equation (3) as follows:\n$L_{cn}^{1}(v_i) = -\\alpha \\log\\frac{\\exp{(sim(h_i^1, h_i^2))}}{\\sum_{j=1}^{N} \\exp{(sim(h_i^1, h_j^2))}} - (1-\\alpha) \\log\\frac{\\exp{(sim(h_i^1, h_i^1))}}{\\sum_{j=1}^{N} \\exp{(sim(h_i^1, h_j^1))}}$\nSimilarly, the cross-network comparison loss for $G_2$ is as\nfollows Equation (4):\n$L_{cn}^{2}(v_i) = -\\alpha \\log\\frac{\\exp{(sim(h_i^2, h_i^1))}}{\\sum_{j=1}^{N} \\exp{(sim(h_i^2, h_j^1))}} - (1-\\alpha) \\log\\frac{\\exp{(sim(h_i^2, h_i^2))}}{\\sum_{j=1}^{N} \\exp{(sim(h_i^2, h_j^2))}}$\nAfter obtaining the inter-network loss functions, they are\ncombined by taking the arithmetic mean to obtain the final\ncross-network comparison loss $L_{cn}$; as shown in Equation (5):\n$L_{cn} = \\frac{1}{2N} \\sum_{i=1}^{N} (L_{cn}^{1}(v_i) + L_{cn}^{2}(v_i))$\n2) Cross-view Contrastiveness: Cross-view comparison\nworks by bringing the representations of the same nodes in the\ntwo augmented views closer together while pushing the other\nnodes out of the way, similar to the objective function used\nin the previous section, and the loss of inter-view comparison\nfor view 1 can be expressed as shown in Equation (6):\n$L_{inter} (v_i) = -\\log \\frac{\\exp{(sim(h_i^1, h_i^2))}}{\\sum_{j=1}^{N} \\exp{(sim(h_i^1, h_j^2))}}$\nSimilarly, the $L_{inter} (v_i)$ of view 2 can be obtained in the\nsame way. On the other hand, as shown by the dashed line\nin Fig. 3(b), the intra-view comparison treats all nodes except\nthe anchor node as negative numbers within a particular view.\nThus, it shares the same positive pair with our inter-view\ncontrast loss, and the intra-view contrast loss for view 1 can\nbe constructed as shown in Equation (7):\n$L_{intra} (v_i) = -\\log \\frac{\\exp{(sim(h_i^1, h_i^1))}}{\\sum_{j=1,j \\neq i}^{N} \\exp{(sim(h_i^1, h_j^1) + \\exp{(sim(h_i^1, h_i^1))}}$\nBy combining the inter-view and intra-view comparability\nof the two views, the two different view comparison objective\nfunctions are shown in Equation (8):\n$L_{cv} (v_i) = L_{inter} (v_i) + L_{intra} (v_i), k \\in \\{1, 2, 3\\}$\nIn summary, the cross-view comparison objective function\nproposed in this paper is shown in Equation (9):\n$L_{cv} = \\frac{1}{3N} \\sum_{i=1}^{N} (L_{12} (v_i) + L_{13} (v_i) + L_{23} (v_i))$\n3) Neighbourhood Contrastiveness: This paper draws on\nthe concept of neighbour comparison learning, unlike InfoNCE\nand NT-Xent where only a single positive pair is formed for\neach anchor in the two comparison loss functions, neighbour\ncomparison learning allows for multiple positives for each\nan chor, i.e., not only are the same nodes of the anchors in\ndifferent views considered as positives, but also neighbours\nof the anchors within a view and neighbours of the anchors\nacross different views are considered as additional positives,\nand the non-neighbours of the anchors in the view and the\nnon-neighbours across different views will be considered as\nboth intra- and inter-view negations. Considering that multiple\nviews, i.e. $H^{(1)}, H^{(2)}, ..., H^{(k)}$, are also generated after the\noriginal graph data G is input to the multi-head GAT, in\nthis paper, the neighbour contrast loss is also computed for\nthe views generated by multiple heads, and the computation\nformula is shown in Equation (10) as follows:\n$L_{ev}^{Chead} = \\frac{1}{K} \\sum_{k=1,k \\neq l}^{K} [\\frac{1}{2N} \\sum_{i=1}^{N} (L_{ev}^{k}(h_i^1) + L_{ev}^{l}(h_i^2))]$\nwhere $L_{ev}^{k}(h_i^1)$ is calculated as shown in Equation (11):\n$L_{ev}^{k}(h_i^1) = - \\log[\\frac{\\exp{(w(h_i^1, h_i^2))}}{\\sum_{v_j \\in N_i}^{} \\exp{(w(h_i^1, h_j^2))}} + \\frac{\\exp{(w(h_i^1, h_i^1))}}{\\sum_{i \\neq j}^{T} \\exp{(w(h_i^1, h_j^1))}} + \\frac{\\exp{(w(h_i^1, h_i^2))}}{\\sum_{}^{T} \\exp{(w(h_i^1, h_j^2))}} ]$\nIn summary, in this paper, the cross-network, cross-view and\nneighbour comparison losses are combined to obtain the final\ncomparison loss function, specifically as shown in Equation\n(12):\n$L_{loss} = \\alpha \\cdot L_{cn} + \\beta \\cdot L_{cv} + \\gamma \\cdot L_{ev}^{Chead}$\nwhere $\\alpha, \\beta$ are balancing factors by minimising the $L_{loss}$ for\nthe purpose of model training."}, {"title": "III. EXPERIMENTS", "content": "In order to demonstrate the effectiveness of the proposed\nGRE2-MDCL, extensive experiments are conducted on five\nbenchmark datasets for semi-supervised node classification,\nincluding three widely used citation networks, i.e., Cora,\nCiteseer, and Pubmed, where Cora is a dataset of citation\nnetworks of academic papers on machine learning; Citeseer is\na dataset of citation networks of academic papers on computer\nscience; Pubmed is a dataset of citation networks of academic\npapers on medical literature. Cora is a citation network dataset\nof academic papers in the field of machine learning; Citeseer\nis a citation network dataset of academic papers in the field\nof computer science; Pubmed is a citation network dataset of\nmedical literature. The statistics of the datasets are shown in\nTable I."}, {"title": "B. Evaluation Metrics", "content": "For Cora, Citeseer and Pubmed this paper follows the\nexperience of previous research, i.e. for each class of the\ndataset 20 nodes were randomly selected for training, 500\nnodes were used for validation and the remaining nodes were\nused for testing. For the self-supervised GCL base model and\nGRE2-MDCL, which learns embeddings from unlabelled data,\nthe validation set is used only to tune the hyperparameters of\nthe LR classifier. For each dataset, this paper performs 20\nrandom splits of training/validation/testing and calculates the\naverage accuracy for each dataset."}, {"title": "C. Experimental Results and Analysis", "content": "1) Comparative experiment: In this paper, three datasets,\nCora, Citeseer, and PubMed, are used to evaluate the per-\nformance of the proposed model, and 10 recent node clas-\nsification methods with good performance are selected as\nthe baseline model:including two semi-supervised GNNs, i.e.,\nGCN and GAT, two semi-supervised graph comparison learn-\ning methods, i.e., CGPN and CG3, and five types of self-\nsupervised graph comparison learning methods, i.e. GRACE,\nMVGRL, GCA, SUGRL, and AF-GRLNCLA.The model\ntraining results are shown in Table II, where the best and\nsecond best results are highlighted in bold and underlined,\nrespectively.\nBased on the node classification accuracy of each model\non the three baseline graph datasets shown in Table II, the\nfollowing observations can be made:\n1) GRE2-MDCL outperforms other baseline models on\nboth the Cora and Citeseer datasets, and is a competitive\nmodel on the PubMed dataset. This indicates that GRE2-\nMDCL has a superior classification performance across\ndifferent datasets compared to the other models.\n2) GRE2-MDCL outperforms NCLA on the Cora and Cite-\nseer datasets, and is slightly inferior to NCLA on the\nPubMed dataset, but the difference is not significant.\nThis suggests that by incorporating the multi-head GAT\nof NCLA into the triple graph neural network and using\nmulti-dimensional contrastive loss for learning, GRE2-\nMDCL is able to provide a more effective graph encoder\nthrough the mutual regularization between the online\nnetwork and the target network, thus improving model\nperformance.\n3) The contrastive learning model proposed in this work\ncan not only fully capture the diverse information within\nthe same network, but also enrich the shared infor-\nmation across different networks, achieving a balance\nbetween the two. Compared to the baseline models, the\nintroduction of contrastive learning enables the model\nto achieve higher classification accuracy through data\naugmentation, once again demonstrating the importance\nof mining multi-scale relationships in graphs.\nIn summary, the proposed GRE2-MDCL model outperforms\nor matches the state-of-the-art models on the tested graph\ndatasets, showcasing its superior ability to learn effective graph\nrepresentations through the integration of multi-dimensional\ncontrastive learning.\n2) Ablation Experiment: This paper conduct ablation ex-\nperiments by gradually removing the local graph enhance-\nment strategy, global graph enhancement strategy, and multi-\ndimensional comparative learning method from the GRE2-\nMDCL model, and then comparing the performance difference\nbetween the ablated models and the original model. This\nallows us to gain a clearer understanding of the contribution"}, {"title": "IV. CONCLUSION", "content": "In this paper, we propose a graph neural network archi-\ntecture called GRE2-MDCL for node classification. Firstly,\nGRE2-MDCL performs local-global graph enhancement. Lo-\ncal graph enhancement via LAGNN refines the graph neural\nnetwork's representation ability when node degrees are small.\nMeanwhile, global graph enhancement is achieved through\nSVD decomposition to preserve the overall graph structure\nand important topological features. Secondly, the proposed\napproach introduces a triple graph neural network model,\nwhich provides a more efficient graph encoder by exploiting\nthe mutual regularization between the online network and\nthe target network for self-supervised node representation\nlearning. Finally, GRE2-MDCL introduces multi-dimensional\ncontrastive loss learning, which fuses three types of contrastive\nloss: cross-network, cross-view, and neighbor contrast. The\nneighbor contrast loss utilizes the network topology as a\nsupervisory signal, rather than directly using a contrast loss\nthat ignores the graph structure. These three contrastive loss\nfunctions are combined to form the total graph contrast loss,\nwhich is then used to optimize the model parameters.\nThrough extensive experiments, the proposed GRE2-MDCL\nmodel achieves average accuracies of 82.5%, 72.6%, and\n77.8% on the Cora, Citeseer, and PubMed datasets, respec-\ntively, outperforming the baseline comparison models and even\nsome supervised learning methods. This demonstrates the high\neffectiveness and robustness of the proposed approach.\nAlthough the experimental results are promising, there are\nstill several areas that warrant further investigation:\n1. Expanding the dataset: Collecting more diverse and\nextensive literature data can help further verify the model's\ngeneralization ability and performance; 2. Optimizing the loss\nfunction: Exploring additional contrastive loss functions that\nbetter capture the structural features of graphs and the relation-\nships between nodes could lead to stronger generalization and\nbetter performance on a wider range of tasks. 3. Considering\nmore complex graph structures: The current method focuses\non simple graph structures. Extending GRE2-MDCL to handle\nmore complex graph types, such as heterogeneous graphs with\nmultiple node and edge types, could enhance the model's\neffectiveness and pervasiveness."}]}