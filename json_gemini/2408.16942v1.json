{"title": "A longitudinal sentiment analysis of Sinophobia during COVID-19 using large language models", "authors": ["Chen Wang", "Rohitash Chandra"], "abstract": "The COVID-19 pandemic has exacerbated xenophobia, particularly Sinophobia, leading to widespread discrimination against individuals of Chinese descent. Large language models (LLMs) are pre-trained deep learning models used for natural language processing (NLP) tasks. The ability of LLMs to understand and generate human-like text make them particularly useful for analyzing social media data to detect and evaluate sentiments. We present a sentiment analysis framework utilising LLMs for longitudinal sentiment analysis of the Sinophobic sentiments expressed in X(Twitter) during the COVID-19 pandemic. The results show a significant correlation between the spikes in Sinophobic tweets, Sinophobic sentiments and surges in COVID-19 cases, revealing that the evolution of the pandemic influenced public sentiment and the prevalence of Sinophobic discourse. Furthermore, the sentiment analysis revealed a predominant presence of negative sentiments, such as \"annoyed\" and \"denial\" which underscores the impact of political narratives and misinformation shaping public opinion. The lack of empathetic sentiment which was present in previous studies related to COVID-19 highlights the way the political narratives in media viewed the pandemic and how it blamed the Chinese community. Our study highlights the importance of transparent communication in mitigating xenophobic sentiments during global crises.", "sections": [{"title": "1. Introduction", "content": "The COVID-19 pandemic was a result of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [1, 2] that broke out in December 2019 in Wuhan City, Hubei Province of China. Since then, COVID-19 spread rapidly throughout the world [3, 4] and to date (2024-05-21), there have been 704 million recorded cases and over 7 million deaths worldwide [5]. The pandemic had an effect on nearly all aspects of life, particularly in health, economy, and social interactions [3]. Clemente-Su\u00e1rez et al. [6] studied the psychological effects created by COVID-19 and the economic downturn caused by the pandemic. Long et al. [7] examined the disruption in social relationships and health caused by COVID-19, noting both the positive aspects, such as the growth of community support in times of lockdown and negative aspects, including the rise of mental health issues, unemployment, and the drastic rise of economic and social inequality. Lopez-Leon et al. [8] presented a review of studies about COVID-19 and long-term effects, and reported that about 80% of infected COVID-19 patients developed one or more long-term symptoms. Furthermore, they identified long term impacts of COVID-19, with fatigue, headache, and attention disorder being the most common.\nDuring the epidemic, social media played a vital role in the process of spreading information which had a significant impact on public behaviour, because of the high penetration rate, fast transmission spread, and wide coverage [9, 10, 11, 12]. Well-known social media platforms such as Twitter, Facebook, and Instagram featured information from official reports, misinformation, and rumours with conspiracy theories that promoted anti-vaccination and other related problems. Gao et al. [9] considered this information to be one of the causes of mental health issues and found that high exposure to social media was linked to increased anxiety and depression among users. Depoux et al. [13] highlighted the need for effective communication strategies to manage public perception. The study also highlighted that the spread of misinformation, most of the time accompanied by fearmongering and racism, was faster than the virus itself. Consequently, the Chinese diaspora were one of the first targets of abuse and discrimination [14].\nSinophobia, also known as anti-Chinese sentiment, refers to the fear and hatred of China and those of Chinese ancestry[15, 16]. The COVID-19 pandemic has greatly exacerbated this form of prejudice-with an early appearance in the form of street graffiti and abusve in social media [17]. In later stages, Chinese restaurants were avoided, and a stop of housing Chinese students by homestay operators was also observed [14]. Viladrich [18] examined the stigmatisation of Chinese and East Asian populations during the COVID-19 pandemic and highlighted how the association of COVID-19 with China led to widespread racial stigma, fuelled by terms such as the \"Chinese virus.\"\nLarge language models (LLMs) [19, 20] consist of pre-trained deep learning models used for natural language processing (NLP) [21, 22] tasks. LLMs use deep learning models that are trained using a vast corpus of text data such as Wikipedia and possess the capacity to undertake a wide range of NLP"}, {"title": "2. Related work", "content": "LLMs face challenges and limitations despite having successful applications [40, 41]. Hadi et al. [42] conducted a comprehensive survey of LLMs and listed challenges such as model biases inherited from training data, high computational resource requirements, privacy concerns, and data security issues. These limitations are significant as they can affect the reliability of LLMs in different applications, including sentiment analysis. For instance, LLMs for sentiment analysis would give biased sentiment classifications if the training dataset contains biased language. This is a crucial issue since it may fuel stereotypes and misinformation, thus affecting the fairness of the sentiment analysis outcome.\nHussein [43] categorised challenges as theoretical such as handling of negation, spam and fake detection, and sarcasm detection. In addition, the technical category considered effective feature extraction, multilingual processing and managing bipolar words, i.e. words that can have different meanings depending on context. Studies have also highlighted the challenges in sentiment analysis. Wankhade et al. [35] highlighted the difficulties of handling unstructured sentiments, which are found quite commonly in social media, where the writers are not constrained by any regulations or guidelines. This involves dealing with slang, abbreviations, and emojis, which can significantly"}, {"title": "3. Methodology", "content": "The Global COVID-19 Twitter dataset provides an extensive collection of tweets related to the COVID-19 pandemic from March 2020-February 2022 [55] and is publicly available on Kaggle. This dataset includes a wide array of tweets from six different countries: Australia, Brazil, India, Indonesia, Japan and the United Kingdom (as shown in Table 1). It encompasses a wide range of public reactions and sentiments regarding the pandemic, allowing for complete analysis across various cultural and regional contexts. This dataset has also been employed by Chandra et al. [38] to analyse vaccine-related sentiments, demonstrating its applicability in studying public sentiment across different contexts. By leveraging this dataset, we can compare our findings with those from previous studies, ensuring consistency and robustness in our sentiment analysis framework.\nThe preprocessing of the datasets is crucial to ensure clean and standardised input for the BERT model. The preprocessing steps involve various tasks such as lowercasing text, expanding contractions, removing hashtags and mentions, and handling emojis and abbreviations. We ensured consistency in data"}, {"title": "3.2. BERT-based model", "content": "BERT (Bidirectional Encoder Representations from Transformers) is a state-of-the-art language representation model developed by Devlin et al. [30]. BERT has been pre-trained on a large corpus of text from the English Wikipedia and BookCorpus using two unsupervised tasks including Masked Language Modelling (MLM) and Next Sentence Prediction (NSP). Unlike traditional unidirectional language models, BERT adopts a deep bidirectional approach, allowing it to simultaneously consider both the left and right context of text. BERT employs the Transformer deep learning model which utilises a self-attention mechanism to capture nuanced relationships between words in a sentence.\nFine-tuning BERT involves adapting the pre-trained model using task-specific data. BERT has been fine-tuned on various NLP tasks, such as modelling US general elections [57], demonstrating its versatility and effectiveness [58, 59]. There are industry-specific implementations of BERT such as Legal-BERT [60, 61] and Medical-BERT [62, 63], using domain-specific data. There are several challenges in fine-tuning BERT models. The performance of fine-tuning is highly sensitive to hyperparameters such as learning rate, batch size, and number of epochs. Additionally, fine-tuning involves addressing challenges such as handling sarcasm, understanding nuanced sentiments, and ensuring the model generalises effectively from training data to unseen data. In our study, by fine-tuning BERT on the SenWave dataset, which includes tweets labelled into ten emotions, we leverage its deep contextual understanding to accurately classify sentiments in social media posts."}, {"title": "3.3. Framework", "content": "Our sentiment analysis framework involves multiple stages, as illustrated in Figure 1.\nIn Stage 1, we clean and preprocess the SenWave dataset, which includes tweets labelled into ten distinct emotion categories. We clean tweets by removing the web links, hashtags and profile tags, and expanding contractions and abbreviations. This step ensures the data is clean and suitable for refining the BERT model. We obtained the Global COVID-19 X (Twitter) dataset, which includes a diverse set of tweets from different countries. We filter the data using specific Sinophobic keywords including \"China\", \"Chinese\", \"Wuhan\" and \"Sinophobia\". We also included several Sinophobic slurs that occurred frequently on Twitter from the study by Tahmasbi et al. [17], such as \"cn\", \"chink\", and \"chingchong\". Table 4 shows all the keywords we used to determine Sinophobic tweets. We concatenated the filtered tweets into a single dataset ensuring no duplicates remain. We clean and preprocess the dataset using the same ways as the SenWave datasets, as demonstrated in Table 3.\nIn Stage 2, we provide an analysis of the data using n-gram (bigram and trigram) analysis and visualisation of Sinophobic tweets extracted from different countries. We also present COVID-19 infection rates for other countries that would be used for further analysis in the final stage.\nIn Stage 3, we utilise a pre-trained BERT model available through Hugging Face 2, which provides open-source NLP tools. In our study, we fine-tune the pre-trained BERT model for sentiment analysis of COVID-19-related tweets. This step involves fine-tuning the pre-trained BERT model using the cleaned and preprocessed SenWave dataset. The fine-tuning process utilises the Adam optimiser [64] which is known for its efficiency in handling large deep learning models. The SenWave dataset is divided into training and testing subsets, with a split ratio of 90% for training, and 10% for testing. Each subset undergoes a series of transformations to convert the tweets into a format suitable for the BERT model. This involves tokenization, where each tweet is broken down into tokens using the BERT tokenizer, and padding, where sequences are padded to ensure uniform length. The model architecture comprises three layers. The process starts with initialising pre-trained weights from BERT-base-uncased 3 which provides a rich contextual representation of the input tweets. Next, we add a dropout layer to prevent overfitting and then a linear layer that maps the output to the ten sentiment categories. During training, we iterate over the training data to present it it to the model in batches and compare the output against the actual labels using the binary cross-entropy loss function. We use the Adam optimiser to adjust the model's weights to minimise the loss. We conduct the training for four epochs monitor the model's performance at regular intervals and evaluate the model's performance on the test dataset. During the evaluation, we pass the test data through the model and calculate various metrics, such as Hamming Loss, Jaccard Score, Label Ranking Average Precision"}, {"title": "4. Results", "content": "Firstly, we analyse the Sinophobic tweets extracted from the dataset as depicted in Figure 2 and Figure 3, these tweets span from April 2020 to January 2022. The monthly distribution of these tweets reveals notable fluctuations in their frequency throughout the selected period.\nFigure 2 shows a major spike in cases in May 2020, indicating a significant increase in Sinophobic tweets. Afterwards, there is a noticeable drop in the number of Sinophobic tweets in the subsequent months, with relatively low activity during the summer of 2020. The overall distribution of tweets shows a gradual increase from the beginning of the pandemic, peaking in early 2021. This trend suggests that as the pandemic progressed with more information and discussion, there was a"}, {"title": "4.4. Sentiment Analysis for different countries", "content": "Next, we conduct a longitudinal analysis of the sentiments expressed in tweets across different countries from 2020-04 2022-01. Firstly, we examine the total number of tweets with each sentiment, as illustrated in Figure 9. The most common sentiment is \"annoyed,\" with over 40,000 tweets classified under this label. This is followed by \"denial,\" with a slightly lower count, and \"official report,\" which also has a significant number of tweets. The sentiments \"joking\" and \"optimistic\" follow next, with counts slightly lower but still substantial. Besides"}, {"title": "4.5. Polarity Score", "content": "We evaluate the polarity scores of the tweets using two different methods: TextBlob and a custom weight ratio approach. The polarity score is a measure of the sentiment expressed in a text, with positive scores indicating positive sentiment, negative scores indicating negative sentiment, and scores close to zero indicating neutral sentiment. TextBlob is a popular Python library for processing text using tools for NLP tasks. The custom weight ratio approach involves assigning weights to each sentiment, as shown in Table 5. This approach aims to capture more nuanced sentiment expressions that might be overlooked by generic sentiment analysis tools. The distribution of TextBlob polarity scores for the dataset is shown in Figure 12-Panel (a). From the figure, it is evident that the majority of the tweets have a polarity score close to zero, indicating neutral sentiment. The distribution of the custom weight ratio polarity scores is illustrated in Figure 12-Panel (b). Similar to the TextBlob results, the custom method also shows a concentration of polarity scores around zero. However, the custom method reveals more granularity in the distribution, with several distinct peaks at various negative scores, especially -0.50. This indicates that the custom method might be capturing more subtle variations in sentiment.\nTo further analyze the sentiment distribution across different countries, we plotted the polarity scores of tweets from six countries: Australia, India, Indonesia, Brazil, Japan, and the UK. Figure 13 illustrates the box plot of polarity scores for each country using the custom weight ratio method. The median polarity scores for all six countries are slightly below zero and the interquartile range boxes span from around -0.4 to 0.0, indi-"}, {"title": "5. Discussion", "content": "Our study on the sentiment analysis of Sinophobia during the COVID-19 pandemic has provided insightful observations into the dynamics of public sentiment across different countries. The findings reveal that the polarity scores of the sentiments are associated with the monthly new COVID-19 cases (Figure 4). As depicted in Figures 2 and 16, the peaks in COVID-19 cases often coincided with spikes in the number of Sinophobic tweets and a drop in mean polarity scores, particularly during major outbreaks and public health interventions. In March 2021, The World Health Organization (WHO) released the results of the first investigation into the origins of COVID-19 [70, 71]. The speculation around the virus's origins, particularly the role of China, has significantly impacted public sentiment globally. This is evident from the significant drop after March 2021 in the polarity scores across various countries, as depicted in Figure 16-(b). Such events underscore the interplay between public health communications and social media sentiment, emphasising the need for transparent and accurate dissemination of information.\nOur analysis of the predicted sentiment labels shows that a significant majority (91.1%) of tweets were assigned one or two sentiment labels. This finding is consistent with the studies conducted by Chandra et al. [36] on sentiment analysis during COVID-19 and sentiment analysis of anti-vaccine tweets during COVID-19 [38]. This consistency suggests that the sentiment analysis models are robust across different datasets and contexts, capturing the predominant emotions expressed in social media discourse.\nOur sentiment analysis highlighted a predominant presence of negative sentiments towards China, with \"annoyed\" and \"denial\" being the most frequently expressed emotions, as shown in Figure 9. This trend is consistent across all selected countries, as illustrated in Figures 11, where positive sentiments, though less frequent, were still present, with \"optimistic\" and"}, {"title": "6. Conclusions", "content": "The COVID-19 pandemic has significantly amplified xenophobia, particularly Sinophobia, resulting in widespread discrimination against individuals of Chinese descent. Our study utilised deep learning-based language models to conduct sentiment analysis on social media data, focusing on Sinophobic sentiments expressed during the pandemic. By leveraging the SenWave dataset and fine-tuning a BERT model, we capture the nuances and evolution of these sentiments across the selected countries over time. The BERT-based model demonstrated moderate effectiveness, highlighting the need for advancements to better handle complex sentiments such as sarcasm and irony. The analysis revealed a correlation between spikes in Sinophobic tweets, drops in sentiment polarity scores and major COVID-19 outbreaks, indicating that the pandemic's progression fuelled Sinophobia. Negative sentiments like \"Annoyed\" and \"Denial\u201d were predominant, though some positive sentiments were also observed. Political narratives and misinformation, particularly linking COVID-19 to China, significantly impacted public sentiment. Finally, there was a lack of \"empathetic\" sentiment which was present in previous studies related to COVID-19 sentiment analysis; hence, empathy was expressed despite the catastrophic effect of COVID-19. Since Sinophoic tweets contain hate speech and despise a community, the lack of empathy in such tweets is natural which highlights the way the political narratives in media viewed the pandemic and how it blamed the Chinese community."}]}