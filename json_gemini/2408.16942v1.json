{"title": "A longitudinal sentiment analysis of Sinophobia during COVID-19 using large language models", "authors": ["Chen Wang", "Rohitash Chandra"], "abstract": "The COVID-19 pandemic has exacerbated xenophobia, particularly Sinophobia, leading to widespread discrimination against individuals of Chinese descent. Large language models (LLMs) are pre-trained deep learning models used for natural language processing (NLP) tasks. The ability of LLMs to understand and generate human-like text make them particularly useful for analyzing social media data to detect and evaluate sentiments. We present a sentiment analysis framework utilising LLMs for longitudinal sentiment analysis of the Sinophobic sentiments expressed in X(Twitter) during the COVID-19 pandemic. The results show a significant correlation between the spikes in Sinophobic tweets, Sinophobic sentiments and surges in COVID-19 cases, revealing that the evolution of the pandemic influenced public sentiment and the prevalence of Sinophobic discourse. Furthermore, the sentiment analysis revealed a predominant presence of negative sentiments, such as \"annoyed\" and \"denial\" which underscores the impact of political narratives and misinformation shaping public opinion. The lack of empathetic sentiment which was present in previous studies related to COVID-19 highlights the way the political narratives in media viewed the pandemic and how it blamed the Chinese community. Our study highlights the importance of transparent communication in mitigating xenophobic sentiments during global crises.\nKeywords: Sinophobia, COVID-19, Sentiment Analysis, Large Language Models", "sections": [{"title": "1. Introduction", "content": "The COVID-19 pandemic was a result of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) [1, 2] that broke out in December 2019 in Wuhan City, Hubei Province of China. Since then, COVID-19 spread rapidly throughout the world [3, 4] and to date (2024-05-21), there have been 704 million recorded cases and over 7 million deaths worldwide [5]. The pandemic had an effect on nearly all aspects of life, particularly in health, economy, and social interactions [3]. Clemente-Su\u00e1rez et al. [6] studied the psychological effects created by COVID-19 and the economic downturn caused by the pandemic. Long et al. [7] examined the disruption in social relationships and health caused by COVID-19, noting both the positive aspects, such as the growth of community support in times of lockdown and negative aspects, including the rise of mental health issues, unemployment, and the drastic rise of economic and social inequality. Lopez-Leon et al. [8] presented a review of studies about COVID-19 and long-term effects, and reported that about 80% of infected COVID-19 patients developed one or more long-term symptoms. Furthermore, they identified long term impacts of COVID-19, with fatigue, headache, and attention disorder being the most common.\nDuring the epidemic, social media played a vital role in the process of spreading information which had a significant impact on public behaviour, because of the high penetration rate, fast transmission spread, and wide coverage [9, 10, 11, 12]. Well-known social media platforms such as Twitter, Facebook, and Instagram featured information from official reports, misinformation, and rumours with conspiracy theories that promoted anti-vaccination and other related problems. Gao et al. [9] considered this information to be one of the causes of mental health issues and found that high exposure to social media was linked to increased anxiety and depression among users. Depoux et al. [13] highlighted the need for effective communication strategies to manage public perception. The study also highlighted that the spread of misinformation, most of the time accompanied by fearmongering and racism, was faster than the virus itself. Consequently, the Chinese diaspora were one of the first targets of abuse and discrimination [14].\nSinophobia, also known as anti-Chinese sentiment, refers to the fear and hatred of China and those of Chinese ancestry[15, 16]. The COVID-19 pandemic has greatly exacerbated this form of prejudice-with an early appearance in the form of street graffiti and abusve in social media [17]. In later stages, Chinese restaurants were avoided, and a stop of housing Chinese students by homestay operators was also observed [14]. Viladrich [18] examined the stigmatisation of Chinese and East Asian populations during the COVID-19 pandemic and highlighted how the association of COVID-19 with China led to widespread racial stigma, fuelled by terms such as the \"Chinese virus.\"\nLarge language models (LLMs) [19, 20] consist of pre-trained deep learning models used for natural language processing (NLP) [21, 22] tasks. LLMs use deep learning models that are trained using a vast corpus of text data such as Wikipedia and possess the capacity to undertake a wide range of NLP"}, {"title": "2. Related work", "content": "LLMs face challenges and limitations despite having successful applications [40, 41]. Hadi et al. [42] conducted a comprehensive survey of LLMs and listed challenges such as model biases inherited from training data, high computational resource requirements, privacy concerns, and data security issues. These limitations are significant as they can affect the reliability of LLMs in different applications, including sentiment analysis. For instance, LLMs for sentiment analysis would give biased sentiment classifications if the training dataset contains biased language. This is a crucial issue since it may fuel stereotypes and misinformation, thus affecting the fairness of the sentiment analysis outcome.\nHussein [43] categorised challenges as theoretical such as handling of negation, spam and fake detection, and sarcasm detection. In addition, the technical category considered effective feature extraction, multilingual processing and managing bipolar words, i.e. words that can have different meanings depending on context. Studies have also highlighted the challenges in sentiment analysis. Wankhade et al. [35] highlighted the difficulties of handling unstructured sentiments, which are found quite commonly in social media, where the writers are not constrained by any regulations or guidelines. This involves dealing with slang, abbreviations, and emojis, which can significantly\naffect the accuracy of sentiment analysis models. These additions reflect how the field of sentiment analysis is evolving, particularly with the increasing prevalence of social media data.\nIn the realm of sentiment analysis, LLMs have demonstrated substantial advancements. Zhan et al. [44] noted the limitations of traditional sentiment analysis methods and emphasized the efficacy of GPT-3 in capturing complex emotional nuances through fine-tuning techniques, also achieving notable improvements in accuracy and contextual understanding. Deng et al. [45] utilised LLMs such as GPT-3 and PaLM for market sentiment analysis on Reddit, demonstrating the effectiveness of in-context learning with Chain-of-Thought reasoning to generate sentiment labels for social media content. This study has underscored the transformative potential of LLMs in enhancing sentiment analysis."}, {"title": "2.2. Sinophobia", "content": "Extensive research has documented Sinophobia during the COVID-19 pandemic [18]. Chen et al. [46] presented a review that examines the rise in anti-Asian sentiment in the United States amid the COVID-19 pandemic, showing similarities to historical instances of racism against Asians. The study highlighted the society and healthcare contributions made by Asian Americans, while also addressing the recent increase in discrimination and hate crimes targeting Asians due to the pandemic. Gao [14] provided a comprehensive framework using sociological, discursive and interpretive approaches for understanding the rise of Sinophobia during the COVID-19 pandemic. They reported that Sinophobia is driven not only by the stereotypical association of Chinese people with the coronavirus, but a complex phenomenon influenced by health, racial, and political factors. Masters-Waage et al. [47] conducted two studies at different time points during COVID-19, each with around 500 participants from the United States, Canada and India. These studies used Bayesian analysis and found no evidence that using place-specific names such as \u201cWuhan Virus\u201d or \u201cChina Virus\u201d increased Sinophobia. Cheah et al.[48] focused on Chinese American families and collected data by self-reported surveys from hundreds of participants, and provided empirical evidence of the mental health impacts of COVID-19-related racial discrimination. Tahmasbi et al. [17] analysed two large datasets from Twitter and 4chan\u2019s\u00b9 Politically Incorrect board (pol) over a five-month period by using temporal analysis and word embedding to examine the dissemination and evolution of Sinophobic content. This study also identified several Sinophobic slurs that were used frequently on Twitter, which can serve as filtration terms in our study."}, {"title": "2.3. Longitudinal Analysis", "content": "Longitudinal analysis is a crucial research method that focuses on studying changes over time by repeatedly observing the same subjects [49] allowing researchers to track changes and identify trends. Longitudinal analysis is widely used across different fields, including psychology [50], medicine [51], and social sciences [52]. Related to our study, longitudinal analysis by Lucas et al. [53] on the immunological response in severe COVID-19 cases helped in understanding complex temporal dynamics that identified key patterns and correlations between immune response profiles and disease severity. Wang et al. [54] conducted a study utilising longitudinal analysis for understanding the evolving psychological impact of the COVID-19 pandemic on a selected population in China. They highlighted how continuous monitoring can reveal persistent and emerging mental health issues despite interventions.\nChandra and Krishna [36] provided longitudinal sentiment analysis of COVID-19 tweets in India, highlighting the fluctuations in public mood corresponding to the rise and fall of new cases. Chandra et al. [38] also employed longitudinal analysis to examine sentiments towards COVID-19 vaccines, covering the early stages of the pandemic to the widespread rollout of vaccination programs. This research demonstrated how sentiment polarity fluctuated with key events, such as the announcement of vaccine efficacy results and the emergence of new variants."}, {"title": "3. Methodology", "content": "In Stage 1, we clean and preprocess the SenWave dataset, which includes tweets labelled into ten distinct emotion categories. We clean tweets by removing the web links, hashtags and profile tags, and expanding contractions and abbreviations. This step ensures the data is clean and suitable for refining the BERT model. We obtained the Global COVID-19 X (Twitter) dataset, which includes a diverse set of tweets from different countries. We filter the data using specific Sinophobic keywords including \"China\", \"Chinese\", \"Wuhan\" and \"Sinophobia\". We also included several Sinophobic slurs that occurred frequently on Twitter from the study by Tahmasbi et al. [17], such as \"cn\", \"chink\", and \"chingchong\". We concatenated the filtered tweets into a single dataset ensuring no duplicates remain. We clean and preprocess the dataset using the same ways as the SenWave datasets\nIn Stage 2, we provide an analysis of the data using n-gram (bigram and trigram) analysis and visualisation of Sinophobic tweets extracted from different countries. We also present COVID-19 infection rates for other countries that would be used for further analysis in the final stage.\nIn Stage 3, we utilise a pre-trained BERT model available through Hugging Face 2, which provides open-source NLP tools. In our study, we fine-tune the pre-trained BERT model for sentiment analysis of COVID-19-related tweets. This step involves fine-tuning the pre-trained BERT model using the cleaned and preprocessed SenWave dataset. The fine-tuning process utilises the Adam optimiser [64] which is known for its efficiency in handling large deep learning models. The SenWave dataset is divided into training and testing subsets, with a split ratio of 90% for training, and 10% for testing. Each subset undergoes a series of transformations to convert the tweets into a format suitable for the BERT model. This involves tokenization, where each tweet is broken down into tokens using the BERT tokenizer, and padding, where sequences are padded to ensure uniform length. The model architecture comprises three layers. The process starts with initialising pre-trained weights from BERT-base-uncased 4 which provides a rich contextual representation of the input tweets. Next, we add a dropout layer to prevent overfitting and then a linear layer that maps the output to the ten sentiment categories. During training, we iterate over the training data to present it it to the model in batches and compare the output against the actual labels using the binary cross-entropy loss function. We use the Adam optimiser to adjust the model\u2019s weights to minimise the loss. We conduct the training for four epochs monitor the model\u2019s performance at regular intervals and evaluate the model\u2019s performance on the test dataset. During the evaluation, we pass the test data through the model and calculate various metrics, such as Hamming Loss, Jaccard Score, Label Ranking Average Precision"}, {"title": "3.4. Experimental setting", "content": "We present the details for the implementation of our sentiment analysis framework including model topology, hyperparameters, and other relevant settings used during experimentation. Our sentiment analysis framework is implemented using Python. We use Python-based libraries including PyTorch"}, {"title": "4. Results", "content": "Firstly, we analyse the Sinophobic tweets extracted from the dataset as depicted , these tweets span from April 2020 to January 2022. The monthly distribution of these tweets reveals notable fluctuations in their frequency throughout the selected period.\nshows a major spike in cases in May 2020, indicating a significant increase in Sinophobic tweets. Afterwards, there is a noticeable drop in the number of Sinophobic tweets in the subsequent months, with relatively low activity during the summer of 2020. The overall distribution of tweets shows a gradual increase from the beginning of the pandemic, peaking in early 2021. This trend suggests that as the pandemic progressed with more information and discussion, there was a rise in Sinophobic sentiment on social media platforms. We further compare the monthly distribution of Sinophobic tweets with the number of new COVID-19 cases in various countries , where the monthly new COVID-19 cases for Australia, Brazil, India, Indonesia, Japan, and the United Kingdom. The COVID-19 case data was sourced from Dong et al. [66], which is an online interactive dashboard that monitors reported cases of COVID-19 led by Johns Hopkins University. There is a clear correlation between the spikes in Sinophobic tweets and the surges in COVID-19 cases. We find that the major peak in Sinophobic tweets in February and March 2021 aligns with a notable increase in COVID-19 cases, particularly in countries such as India. Similarly, the December 2021 peak coincides with another wave of COVID-19 cases, which could have influenced the rise in anti-Chinese sentiment.\nWe performed n-gram analyses [67] to delve deeper into the content of the extracted Sinophobic tweets, focusing on bigrams and trigrams."}, {"title": "4.2. Sentiment Analysis using BERT", "content": "We evaluate the performance of the BERT model for sentiment analysis of Sinophobic tweets which provides a detailed summary of performance metrics.\nThe evaluation metrics indicate that our fine-tuned BERT model performs moderately well in identifying and ranking sentiments within the Sinophobic tweets. The low Hamming Loss and relatively high LRAP Score suggest that the model is effective at accurately predicting multiple relevant sentiments per tweet. The Jaccard, F1 Macro, and F1 Micro-Scores show that the model successfully captures significant aspects of sentiment, making it a valuable tool for understanding the emotional undertones of Sinophobic discourse during the COVID-19 pandemic."}, {"title": "4.3. Model Prediction", "content": "We use the BERT-based refined sentiment analysis model for sentiment classification on the extracted Sinophobic tweets."}, {"title": "4.4. Sentiment Analysis for different countries", "content": "Next, we conduct a longitudinal analysis of the sentiments expressed in tweets across different countries from 2020-04 2022-01. Firstly, we examine the total number of tweets with each sentiment, as illustrated . The most common sentiment is \"annoyed,\" with over 40,000 tweets classified under this label. This is followed by \"denial,\" with a slightly lower count, and \"official report,\" which also has a significant number of tweets. The sentiments \"joking\" and \"optimistic\" follow next, with counts slightly lower but still substantial. Besides\nthese labels, the occurrence of the label \"Empathetic\" is extremely low, with the number of tweets carrying it being close to zero.\nWe excluded the \"official report\" for the rest of the analysis to focus on the emotional content of the tweets. Moving on to a country-wise analysis depicts the percentage distribution of specific sentiments across different countries. In  -Panel (a), the sentiments analysed include \"optimistic\", \"joking\", \"thankful\", and \"annoyed\". The data reveal that \"annoyed\" is the most dominant sentiment in all countries, with the highest percentage observed in Australia, India and the UK. The \"Joking\" sentiment also appears consistently across all countries but at a lower percentage compared to \"annoyed\". -Panel (b) examines the distribution of \"empathetic\", \"pessimistic\", \"sad\", \"anxious\", and \"denial\" sentiments. We observe that \"denial\u201d emerges as the most frequent sentiment across all countries, especially in India, Australia and the United Kingdom. The \"anxious\" sentiment shows a notable presence, particularly in Indonesia and the United Kingdom. Despite the prevalence of negative sentiments, there are also notable occurrences of positive sentiments such as \"optimistic\" and \"thankful\u201d. Among the countries analysed, we find that Japan exhibits a higher proportion of tweets with positive sentiments.\nThe two heatmaps illustrates the frequency of co-occurring sentiments in the extracted tweets for the years 2020 and 2021, respectively. In 2020, , the most frequent individual sentiment is \"annoyed\", followed by \"denial\" and \"joking\". The highest co-occurrence is observed between \"annoyed\" and \"denial,\u201d indicating that these sentiments are often expressed together. In 2021, , the trends are similar to 2020. However, there is an increase in the occurrence of these sentiments. The spikes in new COVID-19 cases in early 2021, particularly in India, , correspond to an increase in the number of tweets expressing sentiments of \"annoyed\" and \"denial\", as observed in the heatmap for 2021."}, {"title": "4.5. Polarity Score", "content": "We evaluate the polarity scores of the tweets using two different methods: TextBlob and a custom weight ratio approach. The polarity score is a measure of the sentiment expressed in a text, with positive scores indicating positive sentiment, negative scores indicating negative sentiment, and scores close to zero indicating neutral sentiment. TextBlob is a popular Python library for processing text using tools for NLP tasks. The custom weight ratio approach involves assigning weights to each sentiment, as shown . This approach aims to capture more nuanced sentiment expressions that might be overlooked by generic sentiment analysis tools. The distribution of TextBlob polarity scores for the dataset is shown . From the figure, it is evident that the majority of the tweets have a polarity score close to zero, indicating neutral sentiment. The distribution of the custom weight ratio polarity scores is illustrated . Similar to the TextBlob results, the custom method also shows a concentration of polarity scores around zero. However, the custom method reveals more granularity in the distribution, with several distinct peaks at various negative scores, especially -0.50. This indicates that the custom method might be capturing more subtle variations in sentiment.\nTo further analyze the sentiment distribution across different countries, we plotted the polarity scores of tweets from six countries: Australia, India, Indonesia, Brazil, Japan, and the UK. illustrates the box plot of polarity scores for each country using the custom weight ratio method. The median polarity scores for all six countries are slightly below zero and the interquartile range boxes span from around -0.4 to 0.0, indicating a predominantly negative sentiment. Notably, Australia, India, and the UK have a lower bottom quartile (Q1) compared to other countries, suggesting a stronger negative sentiment in these regions. presents the violin plot of polarity scores for the same six countries. The violin plots provide a detailed view of the distribution and density of the polarity scores. The violin plot shows that most tweets have negative polarity scores which is consistent with the box plot. The density peaks at around -0.5 and 0.0 for all countries which further confirms the overall negative sentiment.\nWe observe the mean polarity scores calculated using TextBlob and a custom-weighted approach from April 2020 to January 2022. The mean polarity score for each month and country is calculated by averaging the polarity scores of all tweets from that specific country within that month. Examining the TextBlob polarity scores (Figure 16-(a)), we observe an initial positive spike around May 2020, which coincides with the early stages of the pandemic when countries were implementing initial response measures. However, as the pandemic progressed, the sentiment became more negative. In comparison, TextBlob generally yields higher (more positive) polarity scores than the custom-weighted approach suggesting that the latter is more sensitive to negative sentiments. There is"}, {"title": "5. Discussion", "content": "Our study on the sentiment analysis of Sinophobia during the COVID-19 pandemic has provided insightful observations into the dynamics of public sentiment across different countries. The findings reveal that the polarity scores of the sentiments are associated with the monthly new COVID-19 cases As depicted in Figures 2 and 16, the peaks in COVID-19 cases often coincided with spikes in the number of Sinophobic tweets and a drop in mean polarity scores, particularly during major outbreaks and public health interventions. In March 2021, The World Health Organization (WHO) released the results of the first investigation into the origins of COVID-19 [70, 71]. The speculation around the virus's origins, particularly the role of China, has significantly impacted public sentiment globally. This is evident from the significant drop after March 2021 in the polarity scores across various countries, as depicted in Figure 16-(b). Such events underscore the interplay between public health communications and social media sentiment, emphasising the need for transparent and accurate dissemination of information.\nOur analysis of the predicted sentiment labels shows that a significant majority (91.1%) of tweets were assigned one or two sentiment labels. This finding is consistent with the studies conducted by Chandra et al. [36] on sentiment analysis during COVID-19 and sentiment analysis of anti-vaccine tweets [38]. This consistency suggests that the sentiment analysis models are robust across different datasets and contexts, capturing the predominant emotions expressed in social media discourse.\nOur sentiment analysis highlighted a predominant presence of negative sentiments towards China, with \"annoyed\" and \"denial\" being the most frequently expressed emotions, as shown . This trend is consistent across all selected countries illustrated, where positive sentiments, though less frequent, were still present, with \"optimistic\" and"}, {"title": "6. Conclusions", "content": "The COVID-19 pandemic has significantly amplified xenophobia, particularly Sinophobia, resulting in widespread discrimination against individuals of Chinese descent. Our study utilised deep learning-based language models to conduct sentiment analysis on social media data, focusing on Sinophobic sentiments expressed during the pandemic. By leveraging the SenWave dataset and fine-tuning a BERT model, we capture the nuances and evolution of these sentiments across the selected countries over time. The BERT-based model demonstrated moderate effectiveness, highlighting the need for advancements to better handle complex sentiments such as sarcasm and irony. The analysis revealed a correlation between spikes in Sinophobic tweets, drops in sentiment polarity scores and major COVID-19 outbreaks, indicating that the pandemic's progression fuelled Sinophobia. Negative sentiments like \"Annoyed\" and \"Denial\u201d were predominant, though some positive sentiments were also observed. Political narratives and misinformation, particularly linking COVID-19 to China, significantly impacted public sentiment. Finally, there was a lack of \"empathetic\" sentiment which was present in previous studies related to COVID-19 sentiment analysis; hence, empathy was expressed despite the catastrophic effect of COVID-19. Since Sinophoic tweets contain hate speech and despise a community, the lack of empathy in such tweets is natural which highlights the way the political narratives in media viewed the pandemic and how it blamed the Chinese community."}]}