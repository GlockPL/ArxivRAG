{"title": "Understanding Federated Learning from IID to Non-IID dataset: An Experimental Study", "authors": ["Jungwon Seo", "Ferhat Ozgur Catak", "Chunming Rong"], "abstract": "As privacy concerns and data regulations grow, federated learning (FL) has emerged as a promising approach for training machine learning models across decentralized data sources without sharing raw data. However, a significant challenge in FL is that client data are often non-IID (non-independent and identically distributed), leading to reduced performance compared to centralized learning. While many methods have been proposed to address this issue, their underlying mechanisms are often viewed from different perspectives. Through a comprehensive investigation from gradient descent to FL, and from IID to non-IID data settings, we find that inconsistencies in client loss landscapes primarily cause performance degradation in non-IID scenarios. From this understanding, we observe that existing methods can be grouped into two main strategies: (i) adjusting parameter update paths and (ii) modifying client loss landscapes. These findings offer a clear perspective on addressing non-IID challenges in FL and help guide future research in the field.", "sections": [{"title": "1 Introduction", "content": "Federated Learning (FL) is a distributed machine learning framework that prioritizes privacy preservation [14]. Unlike traditional centralized methods, where client data is aggregated on a central server for model training, FL allows clients to keep their data locally. Clients collaborate by sharing only their locally trained models with a central server, which aggregates these models to build a global model. This approach enables learning from diverse, distributed datasets without exposing data, making FL especially valuable for privacy-sensitive applications.\nAlthough similar distributed learning frameworks have existed before [3,23,4], the term \"Federated Learning\" was officially coined by McMahan et al. in 2016 [14]. Since then, particularly in deep learning, FL has gained significant attention in both research and industry [6]. One of the primary challenges in FL is the heterogeneity of data across clients [22]. When client data distributions are non-IID (not Independent and Identically Distributed), the learning direction of individual clients may diverge from that of the global model. This divergence, often referred to as \"client drift\", can degrade the overall performance of the"}, {"title": "2 From Gradient Descent to FedAvg", "content": "Gradient Descent (GD) is one of the most fundamental algorithms in machine learning for optimizing model parameters, such as those in neural networks [17]. Consider an objective function $F(0)$ that we seek to minimize, where e represents the model parameters, with $\\theta \\in R^d$, and d is the dimensionality of 0. The parameter update rule in GD is given by:\n$\\theta^{t+1} = \\theta^t \u2013 \\eta \\nabla F(\\theta^t; D)$\n(1)\nHere, t denotes the iteration step, and $\\nabla F(\\theta^t; D)$ represents the gradient of the objective function with respect to $\\theta^t$, evaluated on the dataset D. By updating the parameters in the negative direction of the gradient with a learning rate n, the parameters move towards a more optimal solution. This iterative process is repeated until the gradient VF($\\theta^t$) converges to zero, indicating that the model has reached a local or global minimum.\nA major limitation of GD lies in its dependence on a static dataset D. This becomes problematic when the dataset is too large to fit into a single device's memory or when full-batch training becomes computationally expensive. GD requires computing the gradient over all data points and using the averaged gradient for each update at iteration t. Expanding the update rule in Eq. 1, we obtain:\n$\\theta^{t+1} = \\theta^t - \\frac{\\eta}{|D|} \\sum_{i \\in D} \\nabla F(\\theta^t; x_i, y_i)$\n(2)\nHere, $x_i$ and $y_i$ represent the feature and label pairs from the dataset D in a supervised learning scenario. Eq. 2 highlights that, before each update, the gra- dient must be computed and averaged across all data points. Each data point contributes a distinct gradient, and the average of these gradients determines the final update direction. This gradient averaging is fundamental to optimization and closely relates to the parameter averaging concept in Federated Averaging (FedAvg). FedAvg can thus be viewed as a generalization of traditional optimiza- tion methods, a connection that will be elaborated upon.\nTo address GD's inefficiencies, SGD was introduced. Unlike GD, which up- dates after computing the gradient over the entire dataset, SGD updates the parameters after each individual data sample. This leads to faster updates and reduced memory usage, making it suitable for large-scale problems. However, this method can be unstable, as computing gradients from a single data point may introduce bias and slow convergence in terms of model performance, despite the higher computational efficiency."}, {"title": "4 Experimental Results", "content": "We first assess how three hyperparameters-\u0395, \u03b7, and B-affect test accuracy, test loss, and training loss. As illustrated in Fig. 4, increasing E or n, or decreasing B, speeds up convergence. This is evident from the curvature of the accuracy plots and the more rapid decline in training loss, which is consistent with our update amount equation u (Eq. 3). Notably, the point of overfitting occurs earlier with faster convergence, as marked by the minimum test loss (indicated by the circle).\nHowever, some notable observations can be made. While higher E values result in faster convergence, they lead to suboptimal minimum test loss and"}, {"title": "3.1 Basic Configuration", "content": "We conduct our experiments using the CIFAR-10 dataset (50,000 instances in the training set and 10,000 in the test set), a standard benchmark in FL research. The model architecture is a convolutional neural network (CNN) with two con- volutional layers followed by ReLU activations and max-pooling. It includes two fully connected layers, leading to a 10-class output, as described in [14]. The task is a classification problem, with cross-entropy loss serving as the objective function. To ensure a controlled experimental environment, we deliberately exclude additional techniques such as weight decay, data augmentation, and advanced optimizers (e.g., momentum or adaptive techniques). This approach allows us to isolate the impact of the hyperparameters B, E, and \u03b7 on the SGD process."}, {"title": "3.2 FL Setup", "content": "We evaluate model performance by analyzing both convergence speed and generalization quality. While rapid convergence is desirable, it does not inherently guarantee strong generalization, making it crucial to track both aspects throughout training. In our setup, global model accuracy (Top-1) is measured server-side using a dedicated test set. Test loss is also computed server- side to assess generalization, while training loss is computed locally by clients. The server averages client-side training losses to monitor overall optimization progress.\nTo set initial hyper- parameters, we first establish reasonable baseline performance in a centralized learning (CL) setup, corresponding to K = 1. We use B = 500, \u03b7 = 0.005, and E = 1, yielding a final accuracy of around 68%. These hyperparameters are not fine-tuned for peak performance in CL; rather, the aim is to observe how performance evolves as we transition from CL to FL.\nWhen K changes, the dataset is proportionally divided among K clients. For K = 1 (CL), a single client holds the entire training dataset of 50,000 samples, while for K = 10, each client is allocated 5,000 unique training samples. We initialize with a balanced IID dataset, ensuring that all clients have an equal distribution of labels and an identical number of samples. The effect of varying the number of clients on FL training dynamics is shown in Fig. 2."}, {"title": "Transition from Centralized to Federated Learning", "content": "In this setup, as K increases, there is a noticeable decline in performance within a fixed number of communication rounds, highlighting a common oversight. When transitioning from CL to FL with a limited dataset, the critical factor that must be consistently controlled for a fair comparison is the amount of effective updates per round, u, rather than the number, due to the influence of n. It is defined as:\n$u = \\eta \\cdot \\frac{ED}{B \\cdot K}$\n(3)\nTherefore, local epoch E, batch size B, and learning rate \u03b7 must be adjusted based on each client's dataset size to ensure all scenarios achieve an equal u. In Fig. 3, we present three accuracy charts corresponding to adjustments in B, E, and \u03b7. Unlike the previous fixed hyperparameter setting, these adjustments"}, {"title": "4.1 Impact of Hyperparameters under IID Condition", "content": "First, increasing E results in faster convergence, and unlike the IID setting, a higher number of epochs leads to improved final performance. The difference in accuracy between the smallest and largest E is +1.7% (from 56.16% to 57.86%), whereas in the IID setting, this difference is -1.55% (from 68.75% to 67.2%). Second, lower values of B result in both higher final accuracy and faster conver- gence. The accuracy gap between the smallest and largest B is +6.45% (from 53.74% to 60.19%), compared to +3.57% (from 67.77% to 71.34%) in the IID case. Finally, \u03b7 plays a crucial role in the non-IID scenario. The accuracy differ- ence between the smallest and largest \u03b7 is +15.48% (from 46.43% to 61.91%), compared to +7.79% (from 63.22% to 71.01%) in the IID setting. Notably, lowest test loss decreases as n increases."}, {"title": "4.2 Partial Participation and Imbalanced Data under IID Condition", "content": "This section explores the effects of partial client participation and imbalanced data in the context of FL under IID conditions. While these are not hyperparam- eters, they are key aspects of the experimental setup. In FL, the server cannot always ensure that all clients participate in every training round. As a result, the server either waits for all clients or proceeds with only those that respond in time, leading to partial participation (PP), where only a subset of clients contribute to model updates in each round.\nEven under IID conditions, where each client has an equal proportion of labels, the number of data samples per client can vary, creating imbalanced datasets. Some clients may have significantly more data than others.\nWe now examine how partial participation and data imbalance influence training dynamics, particularly with regard to convergence and model performance."}, {"title": "Impact of Partial Participation", "content": "To evaluate the impact of partial participa- tion (PP), we vary the number of clients involved in each communication round, randomly selecting 1, 2, 5, or 10 out of a total of 10 clients. While one might as- sume that involving more clients per round would result in better performance, our experiments under IID conditions reveal minimal performance differences across varying levels of participation, as shown in Fig. 5."}, {"title": "Impact of Imbalanced Data", "content": "In our experiments with imbalanced datasets, we construct the environment using a Standard Gaussian Mixture (SGM) model. Here, an SGM value of 0 corresponds to a balanced dataset, while higher SGM values indicate increasing levels of data imbalance, as illustrated in Fig. 6."}, {"title": "4.3 Training Dynamics Under Non-IID Setting", "content": "Next, we experiment non-IID label distribution with a Dirichlet distribution for data partitioning across clients, which introduces varying degrees of non-IID behavior. In this setup, the degree of non-IID distribution is controlled by the Dirichlet a: a lower a leads to more distinct distributions across clients, while a higher a results in more similar distributions. The resulting distributions are visualized in Fig. 8."}, {"title": "Impact of Hyperparameters under Non-IID Condition", "content": "We investigate the effects of varying hyperparameters, as shown in Fig. 10.\nFirst, increasing E results in faster convergence, and unlike the IID setting, a higher number of epochs leads to improved final performance. The difference in accuracy between the smallest and largest E is +1.7% (from 56.16% to 57.86%), whereas in the IID setting, this difference is -1.55% (from 68.75% to 67.2%). Second, lower values of B result in both higher final accuracy and faster conver- gence. The accuracy gap between the smallest and largest B is +6.45% (from 53.74% to 60.19%), compared to +3.57% (from 67.77% to 71.34%) in the IID case. Finally, \u03b7 plays a crucial role in the non-IID scenario. The accuracy differ- ence between the smallest and largest \u03b7 is +15.48% (from 46.43% to 61.91%), compared to +7.79% (from 63.22% to 71.01%) in the IID setting. Notably, lowest test loss decreases as n increases."}, {"title": "5 Understanding FL from a Loss Landscape Perspective", "content": "We have performed a series of experiments across datasets ranging from IID to non-IID, incorporating both partial participation and imbalanced data. As expected, the performance of the global model declines as the level of non-IIDness increases. The most commonly cited explanation for this behavior is client drift. But what drives this phenomenon?\nTo uncover the underlying causes, we examine the problem through the lens of the loss landscape [11]. The loss landscape is shaped by the interaction between the loss function, dataset, and model parameters. It provides valuable insights into how the loss changes as model parameters are updated for a fixed dataset."}, {"title": "6 Discussion and Conclusion", "content": "Our experiments consistently show that a higher \u03b7 and lower B improve performance in both IID and non-IID settings. According to our categorization, these hyperparameters are part of adjusting the update path. A larger \u03b7 leads to bigger steps in gradient descent, which can skip sharp minima and converge on flatter ones, although too large of a step risks divergence. Similarly, a smaller B aids in escaping sharp minima and encourages convergence to flatter min- ima [11], improving generalization [8] and potentially increasing the likelihood of finding overlapping local optima, a topic that requires further investigation.\nIn conclusion, our exploration of optimization algorithms, from GD to FL, reveals that client drift stems from inconsistencies in loss landscapes. Based on these findings, we suggest that methods addressing performance degradation in non-IID settings can be categorized into two main strategies: adjusting the update path or modifying the loss landscape. While the motivations behind these methods may vary, they generally align with these categories. We hope this analysis provides valuable insights for new FL researchers and contributes to ongoing discussions in the field."}]}