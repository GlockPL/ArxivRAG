{"title": "SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions", "authors": ["Zhi-Qi Cheng", "Yifei Dong", "Aike Shi", "Wei Liu", "Yuzhi Hu", "Jason O'Connor", "Alexander Hauptmann", "Kate Whitefoot"], "abstract": "The electric vehicle (EV) battery supply chain's vulnerability to disruptions necessitates advanced predictive analytics. We present SHIELD (Schema-based Hierarchical Induction for EV supply chain Disruption), a system integrating Large Language Models (LLMs) with domain expertise for EV battery supply chain risk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a comprehensive knowledge library, (2) a disruption analysis system utilizing fine-tuned language models for event extraction, multi-dimensional similarity matching for schema matching, and Graph Convolutional Networks (GCNs) with logical constraints for prediction, and (3) an interactive interface for visualizing results and incorporating expert feedback to enhance decision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023), SHIELD outperforms baseline GCNs and LLM+prompt methods (e.g. GPT-40) in disruption prediction. These results demonstrate SHIELD's effectiveness in combining LLM capabilities with domain expertise for enhanced supply chain risk assessment.", "sections": [{"title": "1 Introduction", "content": "The expected widespread adoption of electric vehicles (EVs) is threatened by risks associated with the geographic and economic concentration of critical battery minerals, such as lithium, cobalt, and nickel. To enhance the resilience of the EV battery supply chain, manufacturers must anticipate disruptions caused by natural disasters and geopolitical tensions. Proactive strategies and supply diversification are essential to mitigate these risks\u00b9."}, {"title": "2 Schema Learning for EV Supply Chains", "content": "Schema Learning Dataset. Our dataset comprises 239 diverse sources: 200 academic papers, 22 industry reports, and 17 Wikipedia entries (Fig. 5 and Fig. 6). This collection provides an up-to-date view of the EV battery supply chain, covering advanced battery technologies (e.g. LFP, NiMH), production processes, and six key raw materials. We categorized events into 8 categories, three with long-term impacts, subdivided into 18 subcategories. Our analysis includes five-year price trends for all materials, correlated with 39 significant supply chain events. Industry expert feedback refined our categorization into 11 main categories with 27 subcategories, each illustrated with 1-2 real-world events (Tab. 6). The academic dataset was distilled from 239 sources to 125 highly relevant entries. This dataset of over 1,000 events spans the EV battery lifecycle, enabling our methods to acquire expert knowledge for accurate, real-world predictions. More details are in Appx. B.1.\nSchema Generation & Merging. Building upon our collected dataset, our Schema Learning System facilitates the extraction, visualization, and management of schemas from the 125 diverse textual sources (Fig. 2). The process begins with data cleaning using regular expressions and a locally deployed Llama3-8b model. Subsequently, we em-"}, {"title": "3 Dynamic Disruption Analysis", "content": "Supply Chain News Dataset. We developed an EV Supply Chain News Dataset (January 2022 - December 2023) to evaluate our system's real-world performance (Appx. B.2). The dataset comprises 247 articles from major news outlets and 118 enterprise reports from EV battery-related companies (Fig. 7 and Fig. 8). After preprocessing\u2014including text extraction, language standardization, and noise reduction\u2014we obtained Meta data with 3,022 para-\ngraphs. We then fused international news with contemporaneous corporate stories in the meta data, creating 354 diverse documents comprising 12,070 paragraphs. The final dataset contains approximately 660K words (Table 9), providing a robust foundation for evaluating supply chain disruption detection and analysis. Comprehensive replication details, including the full dataset and preprocessing pipeline, are provided to ensure reproducibility.\nEvent Extraction. Our pipeline extracts multi-faceted events from textual data, focusing on their impact on the EV battery supply chain. We begin with custom-trained SpaCy models\u00b2 for tokenization, sentence segmentation, named entity recognition, and dependency parsing (Appx. F).\nBuilding on this, we deploy a fine-tuned RoBERTa model for cross-sentence event detection:\nEventDetectmulti-sentence(T) \u2192 Ec\nwhere T represents the input text and Ec the detected events. These events are then enriched with contextual information using BERT:\nBERTcontext(EC) \u2192 CE\ngenerating contextual embeddings CE. To enhance analytical coherence, we implement coreference resolution and event linking:\nCorefLink(Ec) \u2192 EL\nThis critical step, yielding linked events EL, maintains contextual continuity across documents. Subsequently, Conditional Random Fields (CRFs) extract event parameters Pc:\nCRF(EL) \u2192 Pc"}, {"title": "Leveraging Graph Convolutional Networks", "content": "(GCNs), we model complex event relationships and score each event's impact as:\nImpactScore(ei) = Centrality(ei)+Magnitude(er)\nThis scoring mechanism balances two crucial factors. Centrality(er) represents the event's importance within the network, reflecting its centrality or influence in the supply chain context. Meanwhile, Magnitude(ei) quantifies the event's impact intensity, indicating its severity or significance.\nFinally, we apply logical constraints and argument coreference to ensure robustness:\nLogicCoref(Pc) \u2192 PF\nproducing a refined, logically consistent set of event parameters PF. More implementation details are in Appx. F.\nEvent Matching & Instantiation. We link extracted events with schema library to detect supply chain disruption patterns using a multi-dimensional approach of semantic and structural similarities. We align each extracted event Eext \u2208 Eext (extracted events) with each schema event Eschema \u2208 Eschema (schema events) using a composite similarity:\nSim(Eext, Eschema) = \u03b1 \u00b7 SemSim(Eext, Eschema)\n+ \u03b2\u00b7 StrSim(Eext, Eschema)\nwhere SemSim captures contextual meaning using BERT embeddings, and StrSim assesses structural similarity. Specifically, semantic similarity mea-\nsures contextual alignment using cosine similarity between BERT embeddings:\nSemSim(Eext, Eschema) = \\frac{Vext \\cdot Vschema}{|| Vext || || Vschema ||}\nwhere vext and vschema are BERT embeddings of extracted and schema events. Similarly, structural similarity evaluates parameter overlap using Jaccard similarity:\nStrSim(Eext, Eschema) = \\frac{Pext \\cap P schema}{Pext \\cup P schema}\nwhere Pext and Pschema are the parameter sets for the extracted and schema events.\nFollowing the calculation of semantic and structural similarities, we refine matching using heuristic rules from annotated datasets. Successful"}, {"title": "4 Experiments", "content": "Our evaluation comprises two parts: (1) Schema Learning Assessment and (2) Supply Chain Disruption Prediction. We assess learned schemas against expert knowledge and evaluate our schema induction process's effectiveness in predicting supply chain events. Detailed experimental setup and evaluation metrics are in Appx. I."}, {"title": "4.1 Schema Learning Performance", "content": "We evaluate GPT-40, Llama3-3b, and Llama3-70b for schema learning, comparing individual schema extraction and integrated library generation. Tables 1 and 2 present quantitative metrics and subjective evaluations by domain experts. GPT-40 outperforms Llama models, achieving F-scores of 0.652 and 0.238 for individual schemas and integrated library generation, respectively. All models perform better in individual schema extraction than integrated library generation, indicating challenges in schema integration. Subjective assessments align with quantitative metrics, with GPT-40 scoring highest across all criteria (consistency: 4.5, accuracy: 4.3, completeness: 4.6). Individual schemas show strong consistency and completeness but slightly lower accuracy, suggesting a tradeoff between comprehensive coverage and precise detail representation."}, {"title": "4.2 Disruption Detection Performance", "content": "Event Extraction & Matching. Table 3 presents quarterly results for 2022 and 2023 on event extraction and matching using a supply chain news dataset. Our system maintains consistent performance across quarters, with F-scores ranging from 0.671 to 0.700. This stability suggests robust generalization across different time periods and varying event types. The slight improvement in 2023 (average F-score 0.687 vs 0.683 in 2022) indicates potential refinement in our model's ability to adapt to evolving supply chain dynamics.\nDisruption Detection. Our advanced GCNs model, augmented with logical constraints and coreference resolution, was rigorously evaluated against"}, {"title": "5 Conclusion", "content": "We present SHIELD, a two-stage framework that integrates Large Language Models (LLMs) with domain expertise, yielding promising results in EV battery supply chain analytics and risk assessment. While demonstrating particular strength in early disruption detection and event prediction for critical battery materials, significant challenges remain in schema integration, real-time adaptability, and error reduction. Future research will systematically address these limitations, enhance the system's robustness, and explore broader applications across diverse industries and supply chain ecosystems."}, {"title": "Algorithm 1 Supply Chain Disruption Prediction", "content": "Input: Historical supply chain events E, adjacency matrix A, initial predictions \u0177\nOutput: Refined predictions \u0177'\nGCN-based Prediction  Initial prediction using GCN\nforl = 1 to L doRefer to Eq. 12\nH(l+1) = \u03c3(AH(l)W(l))\nend for\n\u0177 H(L)\nConstrained Prediction Apply logical constraints\nfor each prediction \u0177i do\n\u0177 Constrain(yi)\nsuch that C(y) = true Refer to Eq. 14\nend for\nCoreference ResolutionLink related events\nfor each pair of events (Ei, Ej) do\nRij Coref(Ei, Ej)Refer to Eq. 15\nif Rij is coreferential then\nLink Ei and Ej\nend if\nend for\nReturn: Refined predictions \u0177"}, {"title": "Rij = \\operatorname{arg}_{E_{i}, E_{j} \\in E} \\max Coref(E_{i}, E_{j})", "content": "subject to Coref(E\u017c, Ej) = true"}, {"title": "Algorithm 2 Schemas Merging Pseudocode", "content": "Input: List of schemas\nOutput: Merged schema\n1. Merge contexts from all schemas:\nfor all schema in schemas do\nfor all context in schema[\"@context\"] do\nif context not in merged_contexts then\nAdd context to merged_contexts\nend if\nend for\nend for\n2. Merge events from all schemas by event name:\nfor all schema in schemas do\nfor all event in schema[\"events\"] do\nevent_name = event[\"name\"]\nif event_name not in merged_events then\nmerged_events[event_name] = event\nelse\nmerged_events[event_name]\nmerge_event_details(merged_events[event_name],\nevent)\nend if\nend for\nend for\n3. Merge relations / update event IDs by event names:\nfor all schema in schemas do\nfor all relation in schema[\"relations\"] do\nsubject_name = GET event name by event ID relation[\"relationSubject\"]\nobject_name = GET event name by event ID relation[\"relationObject\"]\nif subject_name in name_to_id and object_name in name_to_id then\nrelation[\"relationSubject\"] name_to_id[subject_name]\nrelation[\"relationObject\"] name_to_id[object_name]\nif relation not in merged_relations then\nAdd relation to merged_relations\nend if\nend if\nend for\nend for\n4. Final Schema:\nThe final merged schema includes all merged contexts, events, and relations, and is saved for evaluation."}, {"title": "H(l+1) = \u03c3(AH(l)W(l))", "content": "H.2 Constrained Prediction\nThis stage applies logical constraints and hierarchical relations to refine the initial predictions from the schema-guided prediction stage. Key steps include:\nLogical Constraints: We refine initial predictions (y) to produce final predictions (\u0177') that adhere to known rules:\n\u0177' = arg min Constrain(y)\n\u0177' EY\nsubject to C(\u0177') = true\nwhere C represents constraint sets. For example, a constraint might ensure that a major supplier's disruption increases risk for dependent manufacturers.\nHierarchical Relationships:\nChild-to-Parent Propagation: If a child event node is predicted or matched, its parent node is also predicted.\nAND-Siblings Propagation: If a predicted node has AND-sibling nodes, all its siblings are also predicted.\nIterative Refinement: The constrained prediction approach is applied iteratively until no further nodes can be predicted.\nH.3 Argument Coreference\nIn this phase, we utilize coreference entity links and instantiated entities to generate predictions for the arguments associated with the predicted events. Key steps include:\nCoreference Links: Coreference entity links specified in the schema are used to ensure consistency among entity mentions:\nRij = arg, max Coref(Ei, Ej)\n\u0395,, \u0395; \u0395\u0395\nsubject to Coref(E\u00bf, Ej) = true\nwhere (Ei, Ej) denotes each event pair and Rij represents their relation."}, {"title": "\u0177' = arg \\min_{\\hat{y'} \\in Y} Constrain(y)", "content": "subject to C(\\hat{y'}) = true"}, {"title": "H.3 Argument Coreference", "content": "Rij = \\mathop{\\operatorname{arg}}_{E_i, E_j \\in E} \\max Coref(E_i, E_j)\nsubject to Coref(E_i, E_j) = true"}, {"title": "The key components include", "content": "Semantic Similarity: We use a sentence transformer model to encode events into semantic vectors. The cosine similarity between these vectors provides a measure of how semantically similar two events are:\nSemSim (Eext, Eschema) = \\frac{Vext \\cdot Vschema}{|| Vext || || Vschema ||}\nwhere vext and vschema are BERT embeddings of extracted and schema events.\nStructural Similarity: We consider the context of events within their respective hierarchies. For example, an event's predecessors and successors, its parent event, and its child events all contribute to its structural context. Events with similar structures in both schema and extracted graphs are more likely to match:\nStrSim(Eext, Eschema) = \\frac{Pext \\cap P schema}{Pext \\cup P schema}\nwhere Pext and Pschema are the parameter sets for the extracted and schema events."}, {"title": "H.3 Argument Coreference", "content": "Instantiate(Ematched, Sschema) \u2192 Einst"}, {"title": "H.3 Argument Coreference", "content": "ConsistencyCheck(Einst, Sschema)"}, {"title": "Precision", "content": "number of matched quadruples in St\ntotal quadruples in St"}, {"title": "Recall", "content": "number of matched quadruples in St\ntotal quadruples in Sgt"}, {"title": "F-score = 2 \\cdot \\frac{\\text { Precision } \\cdot \\text { Recall }}{\\text { Precision }+\\text { Recall }}", "content": "J.2 Case 2: Nickel and Cobalt Supply Issues\nin March 2023\nIn March 2023, a major disruption in the global supply chain occurred due to large-scale worker strikes and regulatory changes in the Democratic Republic of Congo (DRC), a primary supplier of cobalt. Cobalt is crucial for EV batteries, and the disruption had a significant negative impact on the global supply chain.\nSystem Prediction: Our system successfully fore-\ncasted the potential supply chain interruptions by analyzing news reports on strike activities and up-\ndates on government regulations in the DRC. It\nalso assessed historical data on cobalt supply and\ndemand to identify vulnerabilities and integrated\nexpert feedback on the impact of labor strikes and\nregulatory changes on cobalt production.\nOutcome: The system provided early warnings\nabout the potential disruptions, enabling compa-\nnies to adjust their supply chain strategies. This\nincluded diversifying sources of cobalt and increas-\ning inventories to buffer against supply shortages."}]}