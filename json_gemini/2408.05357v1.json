{"title": "SHIELD: LLM-Driven Schema Induction for Predictive Analytics in EV Battery Supply Chain Disruptions", "authors": ["Zhi-Qi Cheng", "Yifei Dong", "Aike Shi", "Wei Liu", "Yuzhi Hu", "Jason O'Connor", "Alexander Hauptmann", "Kate Whitefoot"], "abstract": "The electric vehicle (EV) battery supply chain's vulnerability to disruptions necessitates advanced predictive analytics. We present SHIELD (Schema-based Hierarchical Induction for EV supply chain Disruption), a system integrating Large Language Models (LLMS) with domain expertise for EV battery supply chain risk assessment. SHIELD combines: (1) LLM-driven schema learning to construct a comprehensive knowledge library, (2) a disruption analysis system utilizing fine-tuned language models for event extraction, multi-dimensional similarity matching for schema matching, and Graph Convolutional Networks (GCNs) with logical constraints for prediction, and (3) an interactive interface for visualizing results and incorporating expert feedback to enhance decision-making. Evaluated on 12,070 paragraphs from 365 sources (2022-2023), SHIELD outperforms baseline GCNs and LLM+prompt methods (e.g. GPT-40) in disruption prediction. These results demonstrate SHIELD's effectiveness in combining LLM capabilities with domain expertise for enhanced supply chain risk assessment.", "sections": [{"title": "Introduction", "content": "The expected widespread adoption of electric vehicles (EVs) is threatened by risks associated with the geographic and economic concentration of critical battery minerals, such as lithium, cobalt, and nickel. To enhance the resilience of the EV battery supply chain, manufacturers must anticipate disruptions caused by natural disasters and geopolitical tensions. Proactive strategies and supply diversification are essential to mitigate these risks\u00b9."}, {"title": "Schema Learning for EV Supply Chains", "content": "Schema Learning Dataset. Our dataset comprises 239 diverse sources: 200 academic papers, 22 industry reports, and 17 Wikipedia entries (Fig. 5 and Fig. 6). This collection provides an up-to-date view of the EV battery supply chain, covering advanced battery technologies (e.g. LFP, NiMH), production processes, and six key raw materials. We categorized events into 8 categories, three with long-term impacts, subdivided into 18 subcategories. Our analysis includes five-year price trends for all materials, correlated with 39 significant supply chain events. Industry expert feedback refined our categorization into 11 main categories with 27 subcategories, each illustrated with 1-2 real-world events (Tab. 6). The academic dataset was distilled from 239 sources to 125 highly relevant entries. This dataset of over 1,000 events spans the EV battery lifecycle, enabling our methods to acquire expert knowledge for accurate, real-world predictions. More details are in Appx. B.1.\nSchema Generation & Merging. Building upon our collected dataset, our Schema Learning System facilitates the extraction, visualization, and management of schemas from the 125 diverse textual sources (Fig. 2). The process begins with data cleaning using regular expressions and a locally deployed Llama3-8b model. Subsequently, we employ GPT-40, Llama3-3b, and Llama3-70b with specific prompts to extract hierarchical structures (H) capturing main events (E) and sub-events (Esub). More details are in Appx. \u0421.\nThe extracted structures are then converted into individual schemas (Si) and visualized as graphs, demonstrating the hierarchical nature of the schemas and the relationships between main events and sub-events. These schemas are then integrated into a single library (Sfinal), aggregating contexts (Cfinal = U1 Ci), merging events (Efinal = U1 Ei), and updating event IDs for relations (Rfinal = U1 Ri). The detailed schema generation and merging algorithm is provided in Appx. D.\nTo ensure efficient retrieval and updates, a dedicated Database & Storage module manages schema storage, while the Schema Management System incorporates a Schema Viewer, Editor, collaboration tools, and AI-driven suggestions are built to manage and annotate schemas (Appx. E). This human-in-the-loop curated framework streamlines schema extraction and management, enabling interactive knowledge extraction from structured documents, leveraging supply chain experts' insights."}, {"title": "Dynamic Disruption Analysis", "content": "Supply Chain News Dataset. We developed an EV Supply Chain News Dataset (January 2022 - December 2023) to evaluate our system's real-world performance (Appx. B.2). The dataset comprises 247 articles from major news outlets and 118 enterprise reports from EV battery-related companies (Fig. 7 and Fig. 8). After preprocessing\u2014including text extraction, language standardization, and noise reduction-we obtained Meta data with 3,022 paragraphs. We then fused international news with contemporaneous corporate stories in the meta data, creating 354 diverse documents comprising 12,070 paragraphs. The final dataset contains approximately 660K words (Table 9), providing a robust foundation for evaluating supply chain disruption detection and analysis. Comprehensive replication details, including the full dataset and preprocessing pipeline, are provided to ensure reproducibility.\nEvent Extraction. Our pipeline extracts multi-faceted events from textual data, focusing on their impact on the EV battery supply chain. We begin with custom-trained SpaCy models\u00b2 for tokenization, sentence segmentation, named entity recognition, and dependency parsing (Appx. F).\nBuilding on this, we deploy a fine-tuned RoBERTa model for cross-sentence event detection:\n$EventDetect_{multi-sentence}(T) \\rightarrow E_{c}$\nwhere T represents the input text and Ec the detected events. These events are then enriched with contextual information using BERT:\n$BERT_{context}(E_{C}) \\rightarrow C_{E}$\ngenerating contextual embeddings CE. To enhance analytical coherence, we implement coreference resolution and event linking:\n$CorefLink(E_{C}) \\rightarrow E_{L}$\nThis critical step, yielding linked events EL, maintains contextual continuity across documents. Subsequently, Conditional Random Fields (CRFs) extract event parameters Pc:\n$CRF(E_{L}) \\rightarrow P_{c}$"}, {"title": "Leveraging Graph Convolutional Networks", "content": "Leveraging Graph Convolutional Networks\n(GCNs), we model complex event relationships\nand score each event's impact as:\n$ImpactScore(e_{i}) = Centrality(e_{i})+Magnitude(e_{i})$\nThis scoring mechanism balances two crucial factors. $Centrality(e_{i})$ represents the event's importance within the network, reflecting its centrality or influence in the supply chain context. Meanwhile, $Magnitude(e_{i})$ quantifies the event's impact intensity, indicating its severity or significance.\nFinally, we apply logical constraints and argument coreference to ensure robustness:\n$LogicCoref(P_{c}) \\rightarrow P_{F}$\nproducing a refined, logically consistent set of event parameters PF. More implementation details are in Appx. F.\nEvent Matching & Instantiation. We link extracted events with schema library to detect supply chain disruption patterns using a multi-dimensional approach of semantic and structural similarities. We align each extracted event $E_{ext} \\in E_{ext}$ (extracted events) with each schema event $E_{schema} \\in E_{schema}$ (schema events) using a composite similarity:\n$Sim(E_{ext}, E_{schema}) = \\alpha \\cdot SemSim(E_{ext}, E_{schema}) + \\beta \\cdot StrSim(E_{ext}, E_{schema})$\nwhere SemSim captures contextual meaning using BERT embeddings, and StrSim assesses structural similarity. Specifically, semantic similarity measures contextual alignment using cosine similarity between BERT embeddings:\n$SemSim(E_{ext}, E_{schema}) = \\frac{V_{ext} \\cdot V_{schema}}{|| V_{ext} || || V_{schema} ||}$\nwhere $v_{ext}$ and $v_{schema}$ are BERT embeddings of extracted and schema events. Similarly, structural similarity evaluates parameter overlap using Jaccard similarity:\n$StrSim(E_{ext}, E_{schema}) = \\frac{|P_{ext} \\cap P_{schema}|}{|P_{ext} \\cup P_{schema}|}$\nwhere $P_{ext}$ and $P_{schema}$ are the parameter sets for the extracted and schema events.\nFollowing the calculation of semantic and structural similarities, we refine matching using heuristic rules from annotated datasets. Successful matches lead to event instantiation, enriching the event representation with schema attributes:\n$Instantiate(E_{matched}, S_{schema}) \\rightarrow E_{inst}$\nwhere $E_{matched}$ represents the matched event, $S_{schema}$ yields the schema library, and $E_{inst}$ refers to the instantiated event with enriched attributes.\nTo ensure logical adherence to schema constraints, we perform consistency checks. These checks validate the instantiated events against the schema library, ensuring they conform to predefined logical and structural constraints:\n$ConsistencyCheck (E_{inst}, S_{schema})$\nThis step is crucial for maintaining the integrity of the schema and the reliability of the predictions.\nFinally, we incorporate a continuous improvement process through manual review and feedback. Feedback from domain experts is used to update and refine the models, ensuring they adapt to new patterns and maintain high performance. The complete process is summarized in Algorithm 3. More implementation details are in Appx. G.\nDisruption Prediction. Building on the extracted and matched events, we employ Graph Convolutional Networks (GCNs), logical constraints, and argument coreference resolution to predict supply chain disruptions. Note that the events are represented as nodes and interactions as edges using GCNs with the propagation rule:\n$H^{(l+1)} = \\sigma(AH^{(l)}W^{(l)})$\nwhere $H^{(l)}$ is the hidden state at layer l, A is the adjacency matrix, $W^{(l)}$ is the weight matrix, and \u03c3 is a non-linear activation function. We optimize using mean squared error loss with L2 regularization:\n$L= \\frac{1}{N} \\sum_{i=1}^{N} (y_i - \\hat{y_i})^2 + \\lambda ||W||^2$\nwhere $y_{i}$ and $\u0177_{i}$ are actual and predicted disruption scores, and \u03bb is a regularization parameter. This approach balances prediction accuracy and model complexity, preventing overfitting.\nTo ensure consistency with domain knowledge, we apply logical constraints, refining initial predictions (y) to produce final predictions (\u0177') that adhere to known rules:\n$\\hat{y}' = \\underset{\\hat{y}' \\in Y}{arg \\underset{\\hat{y}'}{\\text{min}}} Constrain(y)$\nsubject to $C(\\hat{y}') = true$"}, {"title": "Experiments", "content": "Our evaluation comprises two parts: (1) Schema Learning Assessment and (2) Supply Chain Disruption Prediction. We assess learned schemas against expert knowledge and evaluate our schema induction process's effectiveness in predicting supply chain events. Detailed experimental setup and evaluation metrics are in Appx. I."}, {"title": "Schema Learning Performance", "content": "We evaluate GPT-40, Llama3-3b, and Llama3-70b for schema learning, comparing individual schema extraction and integrated library generation. Tables 1 and 2 present quantitative metrics and subjective evaluations by domain experts. GPT-40 outperforms Llama models, achieving F-scores of 0.652 and 0.238 for individual schemas and integrated library generation, respectively. All models perform better in individual schema extraction than integrated library generation, indicating challenges in schema integration. Subjective assessments align with quantitative metrics, with GPT-40 scoring highest across all criteria (consistency: 4.5, accuracy: 4.3, completeness: 4.6). Individual schemas show strong consistency and completeness but slightly lower accuracy, suggesting a tradeoff between comprehensive coverage and precise detail representation."}, {"title": "Disruption Detection Performance", "content": "Event Extraction & Matching. Table 3 presents quarterly results for 2022 and 2023 on event extraction and matching using a supply chain news dataset. Our system maintains consistent performance across quarters, with F-scores ranging from 0.671 to 0.700. This stability suggests robust generalization across different time periods and varying event types. The slight improvement in 2023 (average F-score 0.687 vs 0.683 in 2022) indicates potential refinement in our model's ability to adapt to evolving supply chain dynamics.\nDisruption Detection. Our advanced GCNs model, augmented with logical constraints and coreference resolution, was rigorously evaluated against ablation versions and LLM+prompt methods. Tables 4 and 5 present the comparative performance metrics. The full system achieved the highest F-score (0.732), significantly outperforming both ablation versions (GCNs+Logical Constraints: 0.707, GCNs only: 0.685) and LLM+prompt methods (GPT-40: 0.624). However, the incremental improvement from the GCNs-only model to our full system (0.685 to 0.732) suggests that while the additional components significantly enhance performance, there remains substantial potential for further optimization in the future."}, {"title": "Qualitative Analysis & User Interface", "content": "Our qualitative analysis of SHIELD's disruption predictions, focusing on real-world case studies (detailed in Appx. J), complements the quantitative findings and further illuminates the system's practical utility. A particularly salient example emerged in SHIELD's accurate prediction of a semiconductor shortage resulting from geopolitical tensions, made three weeks prior to widespread reporting. This early insight enabled proactive adjustments to procurement strategies, thereby demonstrating the system's considerable potential in mitigating complex supply chain risks. We have developed an interactive user interface (Fig. 4) for online disruption analysis. This interface allows users to upload news report texts (Fig. 4a), evaluate prediction scores, and edit visualization results for the final disruption analysis (Fig. 4b). More details can be found in Appx. \u041a."}, {"title": "Conclusion", "content": "We present SHIELD, a two-stage framework that integrates Large Language Models (LLMs) with domain expertise, yielding promising results in EV battery supply chain analytics and risk assessment. While demonstrating particular strength in early disruption detection and event prediction for critical battery materials, significant challenges remain in schema integration, real-time adaptability, and error reduction. Future research will systematically address these limitations, enhance the system's robustness, and explore broader applications across diverse industries and supply chain ecosystems."}, {"title": "Related Work", "content": "Supply Chain Risk Management. AI techniques have been increasingly applied to predict and mitigate supply chain risks (Ganesh and Kalpana, 2022). While agent-based approaches (Pino et al., 2010; Giannakis and Louis, 2011, 2016; Blos et al., 2015) enable inter-agent communication for forecasting, they often lack robust predictive capabilities and have limited parameter sets. Rule-based reasoning methods (Gallab et al., 2019; Behret et al., 2012; Paul, 2015; Paul et al., 2017; Awasthi et al., 2018; Camarillo et al., 2018) offer decision-making frameworks but provide minimal quantitative insights. To address these limitations, Machine Learning (DL) and Deep Learning (DL) techniques have been employed (Silva et al., 2017; Hegde and Rokseth, 2020; Garvey et al., 2015; Ruz et al., 2020; Aljohani, 2023; Carbonneau et al., 2008), enhancing demand forecasting and disruption prediction (Hendriksen, 2023; Makridis et al., 2023). Recent studies have begun exploring the potential of large language models (LLMs) in supply chain management (Ray, 2023). However, most current works prioritize predictive performance over interpretability, hindering practitioners' ability to make informed decisions. Our approach addresses this gap by integrating LLMs for schema induction, extracting hierarchical knowledge-graph structures from academic resources to predict supply chain disruptions, thereby enhancing both predictive performance and interpretability.\nSchema Induction & Learning. Building on foundational works (Anderson et al., 1979; Evans, 1967), recent advancements in language modeling have revolutionized schema induction. Large-scale language models (LLMs) (Brown et al., 2020; Rae et al., 2021) have demonstrated remarkable capabilities in learning and generating schemas with minimal supervision. Researchers have explored various strategies to enhance these models, including contextual explanations (Wei et al., 2021; Lampinen et al., 2022), rationale-augmented ensembles (Wang et al., 2022b), and incremental prompting (Li et al., 2023). Transformer-based approaches (Li et al., 2020, 2021) have proven particularly effective in managing schema generation for complex scenarios, representing schemas as graphs. Integrating human feedback (Mondal et al., 2023; Yang et al., 2024; Zhang et al., 2023) has been crucial in refining schema induction processes, addressing the limitations of automated methods. Our approach leverages these advancements by employing an LLM-driven framework that integrates human feedback and expert knowledge into a human-in-loop system, thereby enhancing the practical accuracy and relevance of induced schemas.\nEvent Extraction & Analysis. Event extraction has evolved from manually crafted features (Ahn, 2006) to neural models, including recurrent networks (Nguyen et al., 2016; Sha et al., 2018), convolutional networks (Chen et al., 2015), graph networks (Zhang and Ji, 2021), and transformers (Liu et al., 2020). Recent research has focused on event argument extraction (Wang et al., 2019) and explored zero-shot learning (Huang et al., 2018) and weak supervision (Chen et al., 2015) to enhance performance. Our approach incorporates various event extraction techniques, utilizing fine-tuned ROBERTa models and graph convolutional networks (GCNs) to capture and analyze complex event relationships and their cascading impacts. This approach enables a deeper understanding of supply chain disruptions, distinguishing our system from traditional extraction techniques."}, {"title": "Dataset", "content": "Schema Learning Dataset. Our research began by examining the current state of EV batteries, focusing on the predominant types in use, such as lithium iron phosphate and nickel lithium batteries. We analyzed the battery production process and identified key raw materials, including lithium, cobalt, nickel, and graphite. Subsequently, we investigated the primary sources and production volumes of these materials. Through an extensive review of literature and statistical data, we categorized significant supply chain events into eight groups, three of which have long-term impacts. Each category was further divided into subcategories, and real-world events were identified to illustrate their impact on raw material supplies.\nWe also analyzed price trends for key raw materials over the past five years, using data from the London Metal Exchange (LME)\u00b3, to assess how news events influenced these prices. This research produced an initial scenario document listing the primary raw materials for EV batteries, their price trends, and an analysis of events causing supply chain issues and price fluctuations. Each category"}, {"title": "Hierarchical Structure Extraction", "content": "We utilize large language models (LLMs) to extract hierarchical structures (H) that capture main events (E) and sub-events (Esub) based on our prompt, as illustrated in Fig. 9.\nIn a hierarchical structure (H):\n\u2022 An event (E) refers to anything that happens related to the EV battery supply chain. There can be multiple events (E1, E2, ..., En) in one hierarchical structure H.\n\u2022 An event_id is a unique identifier code assigned for each specific event."}, {"title": "Schema Generation & Merging", "content": "With human-in-the-loop schema induction, our schema learning dataset generated 125 individual schemas (S1, S2, ..., S125). To create a single comprehensive schema, it is essential to merge all individual schemas into a final schema (Sfinal). The process of merging schema format files involves systematically integrating multiple schemas into a cohesive schema. The key components include context, id, events, and relations. These components determine the information in each event and its correlation with other events, hence the merging process must address all of them."}, {"title": "Schema Management System", "content": "The schema management interface (Fig. 10) facilitates the visualization, editing, and management of schemas. It includes the following modules:\nSchema Viewer\nThe schema viewer is crucial for visualizing schemas, providing an intuitive representation of events. It organizes events into a left-to-right tree structure, highlighting parent-child relationships. Within this structure, before-after relationships among child nodes are indicated through arrows and vertical ordering. Users can expand event nodes to reveal details such as descriptions, importance levels, and participant roles.\nKey features of the schema viewer include:\n\u2022 Interactive Exploration: Users can click on nodes to expand or collapse details about events and sub-events.\n\u2022 Contextual Information: Hovering over a node displays additional context and metadata associated with the event.\n\u2022 Dynamic Layout: The tree structure dynamically adjusts to accommodate the addition or removal of nodes, maintaining a clear and organized visual representation.\n\u2022 Collapsible Subtrees: Users can collapse and expand subtrees to manage large schemas.\nSchema Editor\nThe schema editor allows users to interactively modify schemas. Users can add, edit, and delete events, sub-events, and relationships within the schema. Key functionalities include:\n\u2022 Drag-and-Drop Interface: Users can drag and drop nodes to reassign parent-child relationships or reorder events.\n\u2022 Form-Based Editing: Clicking on a node opens a form where users can edit event details, such as descriptions, importance levels, and participant roles.\n\u2022 Validation Checks: The editor performs real-time validation to ensure that all changes adhere to the schema format and constraints.\n\u2022 Undo/Redo Features: Users can easily undo or redo changes to maintain the integrity of the schema editing process.\n\u2022 Schema Versioning: The editor maintains different versions of schemas, allowing users to track changes over time and revert to previous versions if necessary.\n\u2022 Bulk Operations: Users can perform bulk operations such as adding multiple events or updating several nodes at once.\n\u2022 Conflict Resolution: The editor provides tools to resolve conflicts when multiple users make changes simultaneously.\nFrontend Architecture\nThe frontend of system is implemented as a single-page web application using React and TypeScript. This setup connects to an API server that provides application logic and access to a centralized schema database. The use of a browser-based application offers several advantages, including no need for user installations, centralized data management, and extensive functionality through JavaScript libraries. Key components include:\n\u2022 React: A JavaScript library for building user interfaces, providing the foundation for the application's dynamic and responsive design.\n\u2022 TypeScript\u00b9\u2070: A statically typed superset of JavaScript, enhancing code reliability and"}, {"title": "Backend Architecture", "content": "The backend of the interface is developed in Python, leveraging the Falcon web server framework, served by Gunicorn and nginx, and supported by a SQLite database. The backend is designed to be lightweight, minimalist, and easy to comprehend. Most functionalities are concentrated in the frontend to maintain responsiveness and interactivity, allowing the backend to focus primarily on data management. Python's versatility and popularity make it a suitable choice for the dynamic requirements of the system. Static typing in Python is enforced using Mypy\u00b9\u00b2 to facilitate development and reduce trivial bugs. Key components include:\n\u2022 Falcon\u00b9\u00b3: A minimalist web framework for building high-performance APIs, facilitating efficient communication between the frontend and backend.\n\u2022 Gunicorn\u00b9\u2074: A Python WSGI HTTP server for running web applications, ensuring robust"}, {"title": "AI-Driven Suggestions", "content": "The interface incorporates AI-driven suggestions to assist users in schema creation and modification. Large Language Models (LLMs) analyze existing schemas and user inputs to provide recommendations for schema elements, relationships, and structures. These suggestions are presented in real-time, enhancing user productivity and ensuring the creation of accurate and comprehensive schemas.\nKey features of AI-driven suggestions include:\n\u2022 Contextual Recommendations: The system provides context-aware suggestions based on the current schema and user actions.\n\u2022 Smart Auto-Completion: As users type or modify schema elements, the interface offers auto-completion options to expedite the editing process.\n\u2022 Error Detection: The AI models detect potential errors or inconsistencies in the schema and suggest corrections.\n\u2022 Learning from User Feedback: The AI models improve over time by learning from user feedback and interactions, refining their suggestions and increasing accuracy.\n\u2022 Interactive Tutorials: The interface includes tutorials and guidance to help users understand and leverage AI-driven suggestions effectively."}, {"title": "Details of Event Extraction", "content": "Event Span Identification\nEvent span identification involves locating and marking the spans of events within input text. We use two models for this task:\nBase Model: This model is a fine-tuned version of the ROBERTa-large language model (Liu et al., 2019), trained on an internally annotated dataset. The task is formulated as sequence tagging, where the model identifies the start and end positions of event spans. For instance, in the context of supply chain disruptions, the model identifies spans corresponding to events like factory shutdowns, transport delays, or material shortages. This aligns with the cross-sentence event detection described in the main text:\n$EventDetect_{multi-sentence}(T) \\rightarrow E_{c}$\nwhere T represents the input text and Ec the detected events. The model uses contextual information from neighboring sentences to accurately detect event boundaries, ensuring that even complex events spanning multiple sentences are correctly identified.\nGuided Model: Inspired by Wang et al. (2021), this model uses a query-based approach to focus on schema-related events. The process involves two stages as follows:\n1. Discriminator Stage: Queries representing event types are paired with sentences to predict if the query corresponds to an event type mentioned in the sentence. For example, queries include \"factory shutdown due to labor strike\" or \"delay in shipping materials.\" This stage helps in filtering sentences that are likely to contain relevant events.\n2. Span Extraction Stage: Sentences identified in the discriminator stage are further processed to extract event spans using sequence tagging. This ensures that the extracted spans are relevant to the supply chain context. By using sequence tagging, the model accurately marks the start and end points of events within the identified sentences.\nThis approach supports the cross-sentence event detection described in the main text, enriching event spans with relevant context and ensuring high precision in event identification.\nEvent Argument Extraction\nEvent argument extraction involves identifying the roles and participants associated with events. This task is framed as extractive question answering, where the model extracts argument spans from the text based on role-specific questions. We fine-tune ROBERTa-large (Liu et al., 2019) on our internally annotated dataset with a sequence tagging loss function. For supply chain disruptions, arguments might include the specific factories, transportation modes, or materials directly affected by the event.\nThe extraction process is as follows:\n1. Role-Specific Questions: The model is trained to answer questions like \"Which factory was shut down?\" or \"What material was delayed?\" This method ensures that the arguments are specific and relevant.\n2. Contextual Embeddings: This step is enriched by contextual embeddings generated by BERT:\n$BERT_{context}(E_{C}) \\rightarrow C_{E}$\ngenerating contextual embeddings CE. These embeddings provide rich semantic information, enabling the model to better understand the context and improve the accuracy and relevance of the extracted arguments.\nTime Expression Linking & Normalization\nTime expression linking connects time expressions to their corresponding events. Similar to argument extraction, this task uses extractive question answering to find start and end times for events. We fine-tune RoBERTa-base using the TempEval3 dataset (UzZaman et al., 2012).\nThe process includes:\n1. Extraction: The model identifies time expressions within the text and links them to the corresponding events, ensuring that the timeline of events is accurately captured.\n2. Normalization: Identified time expressions are then normalized into standard formats using SUTime (Chang and Manning, 2012) and HeidelTime (Str\u00f6tgen and Gertz, 2013). For example, expressions like \"next Monday\" are converted into specific dates."}, {"title": "Event Temporal Ordering", "content": "For supply chain disruptions, this ensures that timelines for events like \"shipment delayed from March 15 to March 20\" are accurately captured. This integrates into the event parameter extraction process, ensuring coherence and consistency.\nEvent Temporal Ordering\nEvent temporal ordering determines the chronological sequence of events. We frame this task as extractive question answering to address label imbalance issues, fine-tuning RoBERTa-large (Liu et al., 2019) with a sequence tagging loss.\nSteps include:\n1. Pairwise Temporal Relations: The model identifies pairwise temporal relations between events, such as \"Event A happened before Event B.\"\n2. Consistency Checking: Pairwise temporal relations are processed using Integer Linear Programming (ILP) (Schrijver, 1998) to ensure consistency and resolve any conflicts. This method helps in constructing a coherent timeline of events.\nThis is crucial for understanding the sequence of disruptions in supply chains, such as how a factory shutdown leads to delayed shipments. This aligns with the logical constraints and argument coreference to maintain event relationships modeled by GCNs:\n$LogicCoref(P_{c}) \\rightarrow P_{F}$"}, {"title": "Coreference Resolution", "content": "We perform both within-document and cross-document coreference resolution using models fine-tuned on datasets like OntoNotes 5.0 (Pradhan et al., 2013).\nThe resolution process involves:\n1. Entity Clustering: Entity and event coreference clusters are identified and linked to ensure consistency across documents. This helps in tracking the same entities and events mentioned in different parts of the text.\n2. Cross-Document Linking: Linking entities and events across multiple documents ensures that all references to a specific factory, supplier, or shipment are recognized as the same entity."}, {"title": "Graph Convolutional Networks (GCNs) for Event Relationship Modeling", "content": "We leverage Graph Convolutional Networks (GCNs) to model complex event relationships and assess each event's impact. This involves constructing a graph where events are nodes and their interactions are edges.\nSteps include:\n1. Node Importance Calculation: Each node's importance is calculated using centrality measures, such as degree centrality, betweenness centrality, and eigenvector centrality. These measures help in understanding the influence of each event within the network.\n2. Edge Impact Calculation: Edges represent the magnitude of impact, quantified by measures such as event severity and frequency of occurrence.\nThe impact score is then calculated as:\n$ImpactScore(e_{i}) = Centrality(e_{i})+Magnitude(e_{i})$\nwhere $Centrality(e_{i})$ reflects the event's importance within the network, and $Magnitude(e_{i})$ quantifies the event's impact intensity."}, {"title": "Logical Constraints and Argument Coreference", "content": "To ensure the robustness of our event extraction pipeline, we apply logical constraints and argument coreference resolution.\nThis involves multiple steps to refine the extracted event parameters and ensure logical consistency:\nLogical Constraints Application:\n1. Defining Logical Rules: We define a set of logical rules to maintain consistency within the extracted events. These rules include:\n\u2022 Temporal constraints: An event must occur before another if there is a chronological dependency."}, {"title": "Details of Event Matching & Instantiation", "content": "Event matching and instantiation involve aligning a schema from the schema library with events extracted by the schema extraction component, specifically for predicting supply chain disruptions. This process begins by instantiating one of the Eschema from the integrated library or selecting the extracted event Eext that best matches the schema event Eschema. Subsequently, the task entails matching events in the Eschema with their corresponding events in Eext extracted from the news dataset. Events in both Eext and Eschema are organized in a highly structured manner, with parent events divided into child events. Events also contain temporal information, indicating that some events must precede others. Logical relationships are also defined: AND-gates connect all necessary child events for a parent event, OR-gates connect one or more needed child events, and XOR-gates indicate that only one child event can be present.\nFor example, a document about a raw material shortage in the EV battery supply chain might align with a \"Supply Chain Disruption\" schema in the schema library. Following the instantiation, a \"notify suppliers\" event in the schema might match with a graph G event describing a notification sent to cobalt suppliers. The \"suppliers\" participant of the schema event might match with the \"cobalt suppliers\" participant of the extracted event.\nMatching Process & Techniques\nOur approach to event matching and instantiation involves several key steps and techniques to ensure accurate alignment between schema events and extracted events. This is particularly critical in the context of predicting supply chain disruptions, where precise event matching can provide actionable insights."}, {"title": "Similarity Calculation", "content": "To determine the similarity between schema events and extracted events, we calculate a similarity score based on semantic and structural similarities. Semantic similarity (SemSim) is computed using sentence transformers to encode the semantic content of events. Structural similarity (StrSim) takes into account the hierarchical and temporal relationships between events.\nSemantic Similarity: We use a sentence transformer model to encode events into semantic vectors. The cosine similarity between these vectors provides a measure of how semantically similar two events are:\n$SemSim (E_{ext}, E_{schema}) = \\frac{V_{ext} \\cdot V_{schema}}{|| V_{ext} || || V_{schema} ||}$\nwhere $v_{ext}$ and $v_{schema}$ are BERT embeddings of extracted and schema events.\nStructural Similarity: We consider the context of events within their respective hierarchies. For example, an event's predecessors and successors, its parent event, and its child events all contribute to its structural context. Events with similar structures in both schema and extracted graphs are more likely to match:\n$StrSim(E_{ext}, E_{schema}) = \\frac{|P_{ext} \\cap P_{schema}|}{|P_{ext} \\cup P_{schema}|}$\nwhere $P_{ext}$ and $P_{schema}$ are the parameter sets for the extracted and schema events."}, {"title": "Event Matching", "content": "Once the similarity scores are calculated, we match each extracted event Eext with the schema event Eschema that has the highest similarity score. This involves instantiating the schema event with information from the extracted event, ensuring that all relevant details and relationships are preserved.\nExample: Consider a schema event \"notify suppliers\" in the context of a raw material shortage. An extracted event describing an email notification to cobalt suppliers would match this schema event if the similarity score is high. The instantiation process involves mapping the \"suppliers\" participant in the schema to the \"cobalt suppliers\" entity in the extracted event:\n$Instantiate(E_{matched}, S_{schema}) \\rightarrow E_{inst}$\nwhere Einst is the instantiated event enriched with attributes from the schema."}, {"title": "Consistency Checks", "content": "After matching events, we perform consistency checks to ensure that the instantiated schema adheres to logical and temporal constraints. This includes verifying that:\n\u2022 All necessary child events are present (AND-gates).\n\u2022 At least one required child event is present (OR-gates).\n\u2022 Only one of the mutually exclusive child events is present (XOR-gates).\nThese checks ensure that the instantiated schema is logically coherent and temporally consistent:\n$ConsistencyCheck(E_{inst}, S_{schema})$"}, {"title": "Continuous Improvement", "content": "To enhance the accuracy and robustness of our matching and instantiation process, we incorporate continuous improvement through manual review and feedback from domain experts. This involves:\n\u2022 Validating the instantiated events with domain experts to ensure they accurately reflect real-world scenarios.\n\u2022 Refining our models based on feedback, adjusting similarity metrics, and improving our semantic and structural encoding techniques.\n\u2022 Iteratively updating our schema library and extraction models to incorporate new insights and improve performance.\nBy leveraging domain expertise and feedback, we continually refine our event matching and instantiation process, ensuring it remains effective and relevant for predicting and analyzing supply chain disruptions."}]}