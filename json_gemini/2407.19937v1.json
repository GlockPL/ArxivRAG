{"title": "AOTree: Aspect Order Tree-based Model for Explainable Recommendation", "authors": ["Wenxin Zhao", "Peng Zhang", "Hansu Gu", "Dongsheng Li", "Tun Lu", "Ning Gu"], "abstract": "Recent recommender systems aim to provide not only accurate recommendations but also explanations that help users understand them better. However, most existing explainable recommendations only consider the importance of content in reviews, such as words or aspects, and ignore the ordering relationship among them. This oversight neglects crucial ordering dimensions in the human decision-making process, leading to suboptimal performance. Therefore, in this paper, we propose Aspect Order Tree-based (AOTree) explainable recommendation method, inspired by the Order Effects Theory from cognitive and decision psychology, in order to capture the dependency relationships among decisive factors. We first validate the theory in the recommendation scenario by analyzing the reviews of the users. Then, according to the theory, the proposed AOTree expands the construction of the decision tree to capture aspect orders in users' decision-making processes, and use attention mechanisms to make predictions based on the aspect orders. Extensive experiments demonstrate our method's effectiveness on rating predictions, and our approach aligns more consistently with the user's decision-making process by displaying explanations in a particular order, thereby enhancing interpretability.", "sections": [{"title": "Introduction", "content": "With the overwhelming amount of information on the Internet, recommender systems that aim to provide users with suitable items (products or services) by predicting a user's interest have been widely integrated into e-commerce, social network, and other web applications (Karn et al. 2023; Zheng et al. 2023). Recommender systems play a crucial role in alleviating the information overload problem, thereby rendering the decision-making process more user-friendly and enhancing the overall user experience in domains such as online shopping, social interaction, and more. The dual objectives of recommender system development encompass not only accurately predicting user preferences but also enhancing user satisfaction and trust. This dual focus motivates research to emphasize both recommendation accuracy and user-centric metrics, with interpretability standing out as an important one. This involves creating explainable recommender systems capable of not just suggesting items but also providing users with explanations for those recommendations (Tan et al. 2021). For instance, in an online shopping scenario, a recommendation for a mobile phone could include an explanation like \"This phone is purchased by 80% of your peers.\"\nIn the realm of explainable recommender systems, item reviews emerge as a valuable resource for generating explanations. Reviews offer insights from users' perspectives, serving a dual purpose: 1) a user's reviews contribute to characterizing their preferences (Li et al. 2017), and 2) an item's reviews can be leveraged to generate explicit explanations for its recommendation (Mcauley and Leskovec 2013). So many recent studies in recommendations have focused on using advanced techniques like multi-view deep learning approaches to analyze features from user reviews as well as item reviews, and integrate them into recommender systems (Elkahky, Song, and He 2015; Fan et al. 2022). The key concept involves using attention mechanisms to capture the importance of different aspects reflected in user preferences and item characteristics from reviews and generating explanations accordingly (Zhang et al. 2014b; Pan et al. 2022). For instance, considering a user's emphasis on the aspect of price in their reviews, the explanation could be framed as \u201cWe recommend this phone to you because its price matches with your taste on affordability.\"\nDespite the success of existing review-based explainable recommender systems, a crucial factor often overlooked is the aspect order in users' decision-making processes. The \"Order Effects Theory\" suggests that humans tend to follow a specific order of factors when making decisions (Anderson 1965), and the sequence in which factors are considered can influence decisions. For instance, a mobile photography enthusiast may prioritize the camera when buying a phone, while students might prioritize appearance and price over other factors. The different orders of considered aspects can significantly reveal users' preferences. Existing methods in explainable recommendations primarily focus on decisive factors in the decision-making process but neglect the ordering relationship between these factors.\nIncorporating aspect order into review-based explainable recommendations poses key challenges. Firstly, constructing aspect order is intricate due to its personalized and dynamic nature for both users and items across diverse situations, presenting complexities in modeling. Users exhibit different decision orders, and likewise, various items entail distinct orders of consideration during selection. Furthermore, users' contemplation of each aspect is not predetermined but dynamically influenced by contextual factors such as item characteristics and prior decisions (Meshram, Gopalan, and Manjunath 2016). Secondly, integrating aspect orders from both users and items for interpretable recommendations is non-trivial, given the inherent trade-off between explainabil-"}, {"title": "Related Works", "content": "Since our work is to apply the Order Effects Theory to the construction of explainable recommender systems, we divide the related work into two subsections: (a) Explainable Recommender Systems; and (b) Order Effects Theory.\nExplainable Recommender Systems. In the domain of explainable recommender system research, there are two types of dominant models, namely model-agnostic and model-intrinsic approaches (Lipton 2018). Since there is generally a trade-off between performance and transparency in recommender systems, these two approaches have their own advantages and shortcomings regarding performance and transparency (Zhang, Chen et al. 2020).\nThe model-agnostic approach, also named post-hoc explanation approach (Peake and Wang 2018), allows the rec-ommendation model to be a black box and generates ex-"}, {"title": "Preliminary Analysis", "content": "In this section, we explore the applicability of the Order Ef-fects Theory within the realm of recommendation, analyzingthe ordering relationship among user concerns in reviews.The analysis is conducted on the Yelp dataset, which is apublicly available user review dataset and commonly usedfor recommendation tasks. Following the senti-ment analysis toolkit, named Sentires, built by Zhang et al.(2014b), the triplets (Aspect, Opinion, Sentiment) were ex-tracted from the reviews to represent each datum, where inAspect is the focus in our analysis. This phrase-level senti-ment analysis toolkit is a widely used tool for aspect analy-sis in recommendation system due to its accuracy and easeof use in capturing aspect and sentiment (Zhang, Chen et al.2020; Zhang et al. 2014a). Based on Yelp dataset, we presenta scenario where users make decisions regarding restau-rants, highlighting the existence of order effects and revealaits difference among users/items. This comprehensive analy-sis yields valuable insights into the applicability of the OrderEffects Theory.\nWe show the following randomly picked review from theYelp dataset (by user Hie3_7_Nan3R3HaygoCFvA for item"}, {"title": "Methodology", "content": "In this section, we introduce our proposed Aspect Order Tree-based explainable recommendation method AOTree, which aims to simulate human decisive behavior according to Order Effects Theory. We first present the Problem Formulation of this work followed by the general architecture shown in Figure 3, which consists of three key modules: 1) the AOTree Generator, 2) the Aspect Order Generator, and 3) the final Predictor.\nProblem Formulation\nIn this work, we target at the rating prediction task. Let $U = \\{U_1, U_2, ..., U_m \\}$, $V = \\{V_1, V_2, ..., V_n \\}$ denote the user set and item set, respectively, where m and n represent the number of users and items. Then, $r_{i,j}$ is the rating value for a user $u_i$ toward an item $v_j$. And a set of observed data is represented as $O = \\{(u, v)|u \\in U, v \\in V, u \\text{ has reviewed }v\\}$.\nThe construction of the sentiment set, represented by triplets (Aspect, Opinion, Sentiment), follows the same procedure outlined in the Data Analysis Section. Suppose we finally get the aspect set $A = \\{a_1, a_2, ..., a_l\\}$, where l denotes the number of aspects. Then, we construct the user aspect matrix $X \\in R^{m*l}$ as well as the item aspect matrix $Y \\in R^{n*l}$ as (Zhang et al. 2014a):\n$X_{i,k} = \\begin{cases} 0, & \\text{if } u_i \\text{ did not mention aspect } a_k, \\\\ \\frac{2}{1+(N-1)(1+exp(-f_{i,k}s_{i,k}))}, & \\text{otherwise.} \\end{cases}$\n$Y_{j,k} = \\begin{cases} 0, & \\text{if aspect } a_k \\text{ was not mentioned for item } v_j, \\\\ \\frac{2}{1+(N-1)(1+exp(-f_{j,k}s_{j,k}))}, & \\text{otherwise.} \\end{cases}$\nN denotes the rating scale, which is 5 in our datasets. $f_{j,k}$ is the frequency of user $u_i$ mentioning aspect $a_k$, and $s_{j,k}$ is the average sentiment calculated from the sentiment set. Since $X_{i,k}$ and $Y_{j,k}$ measure the importance of aspect $a_k$ to user $u_i$ and item $i_j$, respectively, we thus call them \u201caspect importance\" in this paper and X and Y are called individual aspect importance matrices.\nGroup Aspect\nBefore building AOTree, we first process the user/item aspect matrix into a general representation for all users/items rather than construct trees for each user/item in order to reduce the time complexity. We take the user AOTree genera-"}, {"title": "AOTree Generator", "content": "The tree-based model is considered to be explainable andtransparent when applied to recommendation tasks (Zhang,Chen et al. 2020). Also, it is easy for humans to simulate andthus understand and trust (Wu et al. 2017). Rather than learn-ing features for prediction like other deep learning methods,the tree-based model learns decision rules from datasets.However, the traditional decision tree method aims to solveclassification problems, which is not applicable to our sit-uation. So, we design our own decision rules to split item-s/users according to the matching degree within aspect qual-ity/preference value to find an aspect order representing theconsidering decision process of users.\nDue to the variances of aspect order effects suggestedin the Preliminary Analysis Section, we personalize the or-der construction for both users and items when building theAOTree, respectively. To be more specific, when building theUser-AOTree, we could split user sets and get the consider-ing aspect sequence for each user by matching the generalitem aspect importance vector $ \\hat{Y} $ with the individual useraspect importance matrix X, meaning how the sequence ofgeneral item quality is shown according to different users.The Item-AOTree can be constructed in the same way withthe corresponding general user aspect importance vector Xwith the individual item aspect importance matrix Y.\nIn general, inspired by the decisive process of Markov De-cision Processes (MDP), the goal is to maximize its rewardstream, and thus, each decisive step is chosen based on thebest current state (Shani et al. 2005). There are various ap-proaches existing for obtaining optimal policy, exactly or ap-proximately. In our scenario, each step of our aspect order isdefined as the chosen aspect, which is based on the minimalSplit Expense for the optimal Split Value. Specifically, ourAOTree is constructed as the following three steps:\n1. Calculate Split Value (SV) for each aspect, representingthe optimal split criteria to match user preference anditem characteristic corresponding to each aspect;\n2. Calculate Split Expense (SE) for each aspect with its cor-responding SV, representing the reward for each aspect;"}, {"title": "Calculate Split Value (SV)", "content": "We first traverse all aspects to calculate the split value for each aspect, representing the matching degree between the user's preference and the item's quality. Rather than directly using values in the general item aspect importance vector ($ \\hat{Y} $) to split nodes, which may cause biases among different users, we focus on the degree of ranking matching between users and items on each aspect (Nevo 1989).\nIn detail, for each aspect, we first get the item quality rank position ($PI_k = 1,2,..., l$) according to the general item aspect importance vector ($ \\hat{Y} $) and find the corresponding user rank position ($PU_k$) in the individual user aspect importance matrix (X) for the same aspect ($a_k$). $PI_k$ and $PU_k$ satisfy the Equation 2, which means the item's quality rank matches the user's preference rank.\n$PI_k/l = PU_k/m$. (2)\nAs the values of $PI_k$, m and l are already known, the corresponding user rank position ($PU_k$) could be calculated. Then, the Split Value (SV), the value in the individual user aspect importance matrix (X) at the corresponding position, could be obtained by the following equation inspired by the matching-ranking technique (Nevo 1989):\n$\\frac{PU_k - PU_{kl}}{PU_{kr} - PU_{kl}} = \\frac{SV_k - X_{PU_{kl},k}}{X_{PU_{kr},k} - X_{PU_{kl},k}}$ (3)\nAs $PU_k$ is obtained as a decimal, $PU_{kr}$ and $PU_{kl}$ represent the right and the left integer rank position index of $PU_k$ ($PU_{kr} > PU_k > PU_{kl}$). And $X_{PU_{kr},k}$ and $X_{PU_{kl},k}$ are the corresponding values in the individual user aspect importance matrix (X) for aspect $a_k$. As $SV_k$ is the only unknown value in Equation 3, it can be easily derived given other values."}, {"title": "Calculate Split Expense (SE)", "content": "Then, we decide which aspect should be chosen as the node split criterion and split users by comparing the corresponding aspect value in the individual user aspect importance matrix (X) with $SV_k$ based on the chosen aspect. Take $a_k$ as an example, if the aspect importance value for the user ($X_{ik}$) is larger than $SV_k$, the user is split into the right node, otherwise, into the left node. Our goal is to find one aspect that could make the best matching between user preference and item quality, simultaneously ensuring the robustness of the decision tree. Targeting the rationality and robustness of the decision tree construction, we specify the split principles into the following three components, $SE_1$, $SE_2$ and $SE_3$ aiming at the child nodes after splitting the node. The specific division principles refer to classification and clustering methods, such as Support Vector Machine (SVM) and K-Nearest Neighbors (KNN), aiming to enhance intra-class similarity while promoting inter-class dissimilarity: (suppose $a_k$ is the split criterion for the current node):\n1) $SE_1$: users in the same child node should be similar on aspect $a_k$, i.e., with minimal distance:\n$\\min SE_1 = \\frac{1}{N} \\sum_{i} |X_{ik} - \\bar{X}_k|$, (4)\nwhere $\\bar{X}_k$ and $X_{ik}$ are the average aspect importance value in the individual user aspect importance matrix (X) and the specific value for user i, both on aspect $a_k$.\n2) $SE_2$: users in the different child node groups should be different on aspect $a_k$, i.e., with maximal distance:\n$\\max SE_2 = |\\bar{X}_{right,k} - \\bar{X}_{left,k}|$, (5)\nwhere $\\bar{X}_{right,k}$ and $\\bar{X}_{left,k}$ are the average aspect importance values for aspect $a_k$ in the right and left child node.\n3) $SE_3$: users in the same child node group should be different on aspects except $a_k$, to continually split users:\n$\\max SE_3 = \\sum_{o=1}^{l-k} \\sum_{i} |X_{io} - \\bar{X}_o|$, (6)\nwhere $X_{io}$ is the aspect importance for user i on aspect except $a_k$, and $\\bar{X}_{o}$ is the average aspect importance for all users on aspect $a_o$.\nThen, we could get the Split Expense (SE) value by traverse all aspects according to the corresponding Split Value (SV) as follows:\n$SE = NV * SE_l * SE_r$, (7)\nwhere NV represents the normalization constant to normalize the value of SE, and we set it to $\\frac{1}{10 * N_l * N_r}$ in our method, where $N_l$ and $N_r$ are the number of users in each child node. The subscripts \"r\" and \"l\" denote the values of the right and left child nodes, respectively. $SE_l$ and $SE_r$ are Split Expense (SE) for the left and right nodes after splitting, which could be obtained by:\n$SE_l = \\frac{SE_{l1}}{SE_{l2} * SE_{l3}}$, $\\quad SE_r = \\frac{SE_{r1}}{SE_{r2} * SE_{r3}}$ (8)"}, {"title": "Choose Aspect and Split Value", "content": "We finally choose the aspect with the minimal Split Expense (SE) in order to satisfy our goal:\n$k = arg \\min_k SE$. (9)\nThen the aspect $a_k$ is the split aspect for this node, and the corresponding Split Value (SV) can be obtained by Equation 3."}, {"title": "Build AOTree", "content": "We continue the above three steps to decide on each node with a split aspect and its corresponding Split Value (SV). The criteria for stopping the division is until each node has only one item or the tree depth has reached the predefined threshold.\nThe obtained User-AOTree represents how the sequence of general item quality is shown according to different users. By deciding the split aspect for each node, we could construct aspect order for certain user sets. In each leaf node, users with similar aspect quality share the same aspect order (e.g., $UP_i = \\{N_1, N_2, ..., N_e\\}$ for user $u_i$, where N and e denote the aspect id and the path length).\nSimilarly, the Item-AOTree can be built following the same process (e.g., the aspect order is $IP_j = \\{N_1, N_2, ..., N_e\\}$ for user $v_j$), representing how the sequence of general user preference is shown according to different items."}, {"title": "Aspect Order Generator", "content": "For each interaction (user-item pair), we could convert it into aspect order $UP_i$ for $u_i$ and aspect order $IP_j$ for $v_j$ according to the User-AOTree and Item-AOTree, respectively. The above two orders are considered separately from the user and item sides, providing information for the final decision sequence. So we combine these two considering orders by a simple average:\n$Ind_k = \\frac{Ind_{UP,k} + Ind_{IP,k}}{2}$ (10)\nwhere $Ind_{UP}$ and $Ind_{IP,k}$ denote the ranking index of aspect $a_k$ in $UP_i$ and $IP_j$ respectively. Then, the average aspect index Indk can be sorted to construct the final aspect sequence TP = {$TP_1, TP_2, ..., TP_e$}, and each element is the id for aspect, representing the decisive aspect process for certain user toward certain item. We fill each sequence into a fixed-length e with random aspect id if the length is less than e.\nCorresponding to the aspect id sequence TP, we could get the final user or item aspect importance sequence USeq or ISeq by picking the value of the corresponding aspect id from the original individual user/item aspect importance matrix (X/Y). For example, the value for USeq = {$USeq_1, USeq_2, ..., USeq_e$} is picked from $X_i$ based on the aspect id in TP, which means, $USeq_i$ is equal to $X_{i,TP_i}$."}, {"title": "Prediction with Aspect Order", "content": "The final rating prediction result is obtained mainly by two components, the decision process information, which is the core part of our method, and the user/item context information. In the learning process, we refer to the traditional latent factor method, but extend with our designed components: applying position embedding and self-attention layer to the sequence, and then the final ratings are obtained with a linear model.\nPosition Embedding Layer Given the aspect order generated by AOTree (TP), which is represented by aspect id, we project each id into an embedding vector with size d. Then, we could obtain the path embedding $TP = \\{TP_1, TP_2, ..., TP_\\ell\\} \\in R^{\\ell \\times d}$.\nIn order to highlight the position of each aspect in the sequence, we consider combining our sequence with a position embedding vector. Inspired by Kang and McAuley (2018), we add a position embedding $E = \\{E_1, E_2, ..., E_\\ell\\} \\in R^{\\ell \\times d}$"}, {"title": "Self-Attention Layer", "content": "We use scaled dot-product attention to achieve self-attention as (Vaswani et al. 2017):\n$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d}})V$, (12)\nwhere Q, K and V denote queries, keys and values, respectively. The scaling factor $\\sqrt{d}$ is to avoid overly large values of the inner product, especially when the dimensionality is high, and K and V are with the same values. In our method, N is converted to the three input for self-attention as:\n$Att = Attention(NW^Q,NW^K,NW^V)$, (13)\nwhere $W^Q, W^K$ and $W^V$ are projection matrices. Then, the result is added to the normalized input N to obtained the Sequence Feature (SF) as:\n$SF = LayerNorm(N + Att)$. (14)\nDue to the order consideration, we should mask the first t-1 aspects in the order when processing the t-th layer of aspect, so we add a triangular matrix for masking the unseen position. Layer normalization is used to normalize the inputs, which is beneficial for stabilizing and accelerating neural network training, represented as:\n$LayerNorm(x) = \\alpha \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$, (15)\nwhere \u03bc and \u03c3 represent mean and variance of N, \u03b1 is scaling factor, \u03b2 is bias term, and is element-wise product. Finally, we optimize aspect order for user (USeq) and item (ISeq) by element-wise product with SF as:\n$\\hat{U}_{Seq} = U_{Seq} \\cdot SF$.\n$\\hat{I}_{Seq} = I_{Seq} \\cdot SF$. (16)"}, {"title": "Prediction Layer", "content": "In the prediction layer, we apply a simple linear model to integrate all the components:\n$\\hat{r}_{ij} = W_1 (\\hat{U}_{Seq_i} \\odot \\hat{I}_{Seq_j}) + W_2 (p_i \\odot q_j)+b_u+b_i+\\mu$, (17)\nwhere $W_1 \\in R^d$ and $W_2 \\in R^d$ are weight matrices of the linear model, and $p_i$ and $q_j$ denote the ID embedding for user $u_i$ and item $v_j$. $\\hat{U}_{Seq_i}$ and $\\hat{I}_{Seq_j}$ is the decision process information, and $p_i \\odot q_j$ represents the interaction between user $u_i$ and item $v_j$."}, {"title": "Model Training", "content": "We use Mean Square Error (MSE) as our objective function:\n$MSE = \\sum_{(i,j) \\in O} (r_{ij} - \\hat{r}_{ij})^2$, (18)\nwhere $r_{ij}$ denotes the ground truth rating for user $u_i$ on item $v_j$, and $\\hat{r}_{ij}$ is the predicted rating from our method."}, {"title": "Experiment", "content": "In this section, we present experimental setup, comprehensive experimental results and detailed analysis, aiming at answering the following research questions (RQs):\n* RQ1: Does AOTree outperform the state-of-the-art methods in terms of recommendation accuracy?\n* RQ2: Does the considering aspect order obtained by AOTree help to improve recommendation accuracy?\n* RQ3: Does the considering aspect order obtained from AOTree help to improve explainability?"}, {"title": "Experimental Setup", "content": "Dataset. The experiments are conducted on five publicly available user review datasets from Amazon and Yelp. For Amazon, we chose four common datasets: Cells Phones and Accessories, Office Product, Patio, Lawn and Garden and Digital Music.\nWe first adopt the sentiment analysis toolkit (Zhang et al. 2014b) and only keep users/items with more than Tu/Ti review records due to the sparsity of the datasets (Wang et al. 2018a; Pan et al. 2022). As we focus on the aspects extracted from reviews, we also set Ta to the minimal number of appearing times for each aspect. The specific value of the threshold and the statistics of the datasets after preprocessing are shown in Table 1. The Density value denotes the average number of aspects mentioned by users. It is worth noting that the Tu/Ti for Digital Music and Yelp are set differently in order to keep a relatively consistent density value. In the experiments, each dataset is divided into training set, validation set, and test set by 8:1:1.\nCompared Methods. In order to validate the performance of our proposed AOTree method, several baselines are selected for comparison. Specifically, we choose several commonly-used traditional and state-of-the-art methods in the field of recommender systems, such as the classic benchmark method (MF), tree-based methods (XGBoost and TEM), review-based method (NARRE, R3), and aspect-based prediction methods (SULM, ANR and ERRA). All the compared methods are evaluated based on the code published by the authors with careful hyper-parameter tuning. The compared methods are:\n* MF (Koren, Bell, and Volinsky 2009): Matrix Factorization (MF) is a classic rating prediction method using bias terms and latent features for prediction.\n* XGBoost (Chen and Guestrin 2016): XGBoost is the state-of-the-art tree-based method. The final tree captures complex feature dependencies, that is the cross feature combination for different paths.\n* TEM (Wang et al. 2018b): Tree-enhanced Embedding Method (TEM) is also a tree-based model. It is constructed into two cascade parts with GBDT and an easy-to-interpret attention network, making the recommendation process fully transparent and explainable.\n* NARRE (Chen et al. 2018): Neural Attentional Regression model with Review-level Explanations (NARRE) is a widely used state-of-the-art explainable recommendation method. This method focuses on the reviews usefulness and uses an attention mechanism to learn the importance weights over different reviews.\n* R3 (Pan et al. 2022): Recommendation via Review Rationalization (R3) is a causal-aware explainable method, which extracts rationales from reviews via a rationale generator to alleviate the effects of spurious correlations in recommendation. Then, the final recommendation and causal-aware explanation can be generated according to the rationales.\n* SULM (Bauman, Liu, and Tuzhilin 2017): Sentiment Utility Logistic Model (SULM) is a basic aspect-based model, which uses sentiment analysis of user reviews to identify the most valuable aspects for recommendation."}, {"title": "Evaluation Metrics", "content": "The proposed AOTree method andall compared methods can be evaluated by the Mean SquareError (MSE), except SULM. For the MSE metric, describedas Equation (18), a lower value means better performance.In order to make a comparison with the aspect-based algo-rithm, SULM, which converts the rating prediction probleminto a preference classification problem for 0 and 1, we convert our scenario into a ranking task. To be more specific,we sort the recommended items into a list according to rat-ings for each user and evaluate the ranking performance bycalculating the NDCG value. NDCG, short for NormalizedDiscounted Cumulative Gain, is a metric commonly used inrecommendation systems to assess the quality of ranked rec-ommendations (Kanoulas and Aslam 2009). The formulasare as follows:\n$NDCG@K = \\frac{DCG@K}{IDCG@K}$ (19)\n$DCG@K = \\sum_{j=1}^K \\frac{2^{rel_j}-1}{log_2(j+1)}$ (20)\n$IDCG@K = \\sum_{j=1}^K \\frac{2^{rel_j}-1}{log_2(j+1)}$ (21)\nwhere K denotes the position up to which the relevanceis accumulated, and it is omitted and default to 5 in ourmethod. $rel_j$ denotes the graded relevance at position j, andthe set consisting of the top K results is taken. Then, the fi-nal NDCG is calculated by normalizing DCG as Equation(19), and a larger value means better performance.\nThe goal of our method is to achieve human simulability,that is, to obtain considering aspect order as explanations.As the order of the aspects mentioned in reviews appears asa decision process, we could compare it with the predictedaspect order as the evaluation of the explanation. On the onehand, we verify the coverage of aspects, aiming to show theperformance from the importance dimension (Num%). Onthe other hand, inspired by the metrics in rank evaluation,we use NDCG and F1 metrics to test the ordering effec-tiveness. Specifically, we assess the aspect composition or-der's quality at the aspect level using the NDCG metric,"}, {"title": "Results", "content": "Overview Performance (RQ1)\nWe first report the overall performance of AOTree in Table 2 and Table 3, which show the MSE and NDCG results according to the competitors. From the results, AOTree significantly outperforms all the other competitors on all datasets (p < 0.05), which could answer RQ1. The performance of R3 method ranks second due to the dependence on causal relations rather than spurious correlations. And NARRE and ANR also show quite good performance, especially in Cell Phones and Accessories and Office Product datasets, which demonstrates that attention mechanism can capture implicit finer-grained properties from reviews. TEM captures the explicit cross features, which ignore the relationship from the \u201cordering\u201d dimension, and it only shows a slight advantage in Office Product. By exploring the \u201cordering\u201d dimension among aspects, the AOTree is constructed by using sequence property and shows promising performance. From the ranking score results on NDCG compared with SULM, the AOTree method still significantly outperforms"}, {"title": "Effectiveness of the Aspect Order (RQ2)", "content": "For RQ2, we perturb the obtained aspect order to demonstrate the superiority of the current order. However, the results are not stable for the whole dataset. So we split users according to the MSE results shown in Table 2. To be specific, we focus on the samples with MSE less than the average value in the training set. If all interactions for one user meet the above criterion, the user will be selected. In fact, this is a very strict partition criterion since it requires each of a user's interactions meets such a criterion, and the selected users should have strong order effect. So we mark the selected users as Identified Strong Sensitive Users and the others as Identified non-Strong Sensitive Users. Our analysis suggests that the fraction of Identified Strong Sensitive Users reaches 20% to 30% in different datasets (20.37% in Cells Phones and Accessories, 26.61% in Office Product, 21.60% in Patio, Lawn and Garden, 21.05% in Digital Music, and 31.57% in Yelp). Such a proportion is close to that of the Strong Sensitive Users with consistency_disuser higher than 0.5 in our Preliminary Analysis, indicating our method's effectiveness in capturing order effect.\nThen, for each user, we verify the effectiveness of the captured aspect order for each interaction by adopting two perturbation operations related to the \"ordering\u201d: 1) shuffling the whole order to verify whether the sequence generated by the model is effective, and 2) replacing the first five aspects with random ones to see whether the Primacy principle contributes. The final results are shown in Table 4. From the results, we can obtain the following findings. For the Identified Strong Sensitive Users, the results after perturbation show higher MSE values, which suggests the superiority of the aspect order obtained by our method. While for the Identified non-Strong Sensitive Users, the above conclusion seems to be dismissed since the results after perturbation do not make"}, {"title": "Ablation and Hyper-parameter Study", "content": "Ablation Study The ablation study for each designedcomponent in AOTree is considered to justify its validity.As our main goal is for accuracy, we conduct ablation experiments on the MSE metrics. The two main componentsare specifically the AOTree Generator (Tree) and the Prediction Generator. Furthermore, we split the Prediction Generator into more detailed parts, which are the Position Embedding Layer (PEL), the Self-Attention Layer (SAL) and theLayer Normalization (LN). We test it on three datasets, andthe MSE results are shown in Table 7, where w/o means theMSE results without the corresponding component. Whenreplacing each of the components, the corresponding MSEvalue increases, especially for SAL part and LN part. Although the design of AOTree is not complicated and is constructed by several independent components, the ablation re-sults could confirm the effectiveness of each design."}, {"title": "Time Complexity Analysis", "content": "We separate complexity analysis into two parts since thereare two phases in the learning process of our method. Forthe AOTree building phase, the time complexity is $O(m \\cdot\\ell\\log\\ell)$ or $O(n \\cdot e \\cdot \\ell \\cdot \\log\\ell)$, where m/n represents the number of users/items for User-AOTree/Item-AOTree,e is the maximum depth of trees, and l is the number ofextracted aspects. For the embedding phase, the time complexity is $O(2 \\cdot a \\cdot d \\cdot N)$, where a is the attention size, d is the embedding size and N is the number of training instances. Above all, the overall time complexity of our modelis $O(l \\cdot e \\cdot m \\cdot \\log l + l \\cdot e \\cdot n \\cdot \\log l + 2 \\cdot a \\cdot d \\cdot N)$.The time complexity of the comparison algorithm TEM is"}, {"title": "Discussion", "content": "In this work, we confirm both the existence and"}]}