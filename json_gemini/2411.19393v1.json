{"title": "Global Tensor Motion Planning", "authors": ["An T. Le", "Kay Hansel", "Jo\u00e3o Carvalho", "Joe Watson", "Julen Urain", "Armin Biess", "Georgia Chalvatzaki", "Jan Peters"], "abstract": "Abstract\u2014Batch planning is increasingly crucial for the scalability of robotics tasks and dataset generation diversity. This paper presents Global Tensor Motion Planning (GTMP)\u2014 a sampling-based motion planning algorithm comprising only tensor operations. We introduce a novel discretization structure represented as a random multipartite graph, enabling efficient vectorized sampling, collision checking, and search. We provide an early theoretical investigation showing that GTMP exhibits probabilistic completeness while supporting modern GPU/TPU. Additionally, by incorporating smooth structures into the multipartite graph, GTMP directly plans smooth splines without requiring gradient-based optimization. Experiments on lidar- scanned occupancy maps and the MotionBenchMarker dataset demonstrate GTMP's computation efficiency in batch planning compared to baselines, underscoring GTMP's potential as a robust, scalable planner for diverse applications and large-scale robot learning tasks.", "sections": [{"title": "I. INTRODUCTION", "content": "Motion planning with probabilistic completeness has been a foundation of robotics research, with seminal works like PRM [1] and RRTConnect [2] serving as cornerstone meth- ods for years [3]. However, as the complexity of robotic tasks grows, there is a growing demand for batch-planning methods. Several factors drive this interest: (i) the need to gather large datasets for policy learning [4]\u2013[6], (ii) the inherent non-linearity of task objectives that lead to multiple local minima [7]\u2013[9], and (iii) the increasing availability of powerful GPUs or TPUs for planning [10], [11].\nDespite these advancements, batching traditional sampling-based planners, such as RRT/PRM and their variants, remains an ongoing challenge [12]\u2013[15]. Their underlying discretization techniques, such as the incremental graph construction of RRT/PRM or the search mechanism of A* [16], [17], are not conducive to efficient vectorization over planning instances. This paper revisits classical motion planning, introducing a simple yet effective discretization structure with layers of waypoints, which can be represented as tensors, enabling GPU/TPU utilization. We propose Global Tensor Motion Planning (GTMP), which enables highly batchable operations on multiple planning instances, such as batch collision checking and batch Value Iteration (VI) while maintaining an easily vectorizable implementation with JAX [18]. This simplicity allows for differentiable planning and rapid integration with modern frameworks, making the algorithm particularly desirable for real-time applications and scalable data collection for robot learning. Our experimental results demonstrate x300 faster in batch planning than OMPL with PyBullet collision-checking while achieving better smoothness and path diversity with spline discretization structure.\nOur contributions are twofold: i) we propose a vectorizable sampling-based planner exhibiting probabilistic complete- ness, which does not require simplification routines [19], and ii) we extend GTMP with a spline discretization structure, enabling batch C\u00b9 spline planning with path quality compa- rable to trajectory optimizers."}, {"title": "II. RELATED WORKS", "content": "Vectorizing motion planning has been an active research topic for decades. Here, we briefly survey the most relevant works on vectorizing either at the algorithmic-level (e.g., collision-checking) or instance-level (e.g., batch trajectory planning).\nSampling-based Vectorization. Recognizing the impor- tance of planning parallelization, earliest works [12], [13], [15], [21], [22] propose a vectorizable collision-checking data structure. State-of-the-art work on leveraging CPU- based single instruction, multiple data [23] (i.e., VAMP) has pushed collision-checking efficiency to microseconds. In a different vein, a body of works [24]\u2013[29] proposes a learning heuristic or batch-sampling strategies to inform or refine the search-graph with new samples, effectively reducing collision checkings. Despite the hardware or algorithmic acceleration efforts, past works still resort to discretization structures such as trees (for RRT variants) or graphs (for PRM variants) [30], which are unsuitable for instance-level vectorization.\nVectorizing Trajectory Optimization. Vectorizing optimization-based planner with GPU-acceleration [7], [10], [11], [31]\u2013[33] gained traction recently due to their computational efficiency, the solutions' multi-modality and"}, {"title": "III. PROBLEM DEFINITION", "content": "We consider the path planning problem [34] in a compact configuration space CC Rd having d-dimensions, with Ccoll being the collision space such that C \\ Ccoll is open. Let Cfree = cl(C \\ Ccoll) be the free space, with cl(.) the set closure. Denote the start configuration qo and a set of goal configurations G. The path planning problem is defined by the triplet (Cfree, qo, G). Let f : [0, 1] \u2192 q, we can define its total variation as its arc length\n$$TV(f) = \\sup_{M \\in \\mathbb{N}, 0=t_0,...,t_M=1} \\sum_{i=1}^{M} ||f(t_i) - f(t_{i-1}) ||$$\nDefinition 1 (Feasible Path). The function f : [0,1] \u2192 q with TV(f) < \u221e is\n\u2022 a path, if it is continuous.\n\u2022 a feasible path, if and only if \u2200t \u2208 [0,1], f(t) \u2208 Cfree, f(0) = qo, f (1) \u2208 G.\nLet F be the set of all paths.\nProblem 1 (Feasible Path Planning). Given a planning problem (Cfree, 90, G) and cost function c : F \u2192 R>0, find a feasible path f and report failure if no feasible path exists.\nHere, we do not consider dynamics constraints, invalid configurations that violate collision constraints and configu- ration limits. This problem definition is standard for several robotic settings, such as serial manipulators with joint limits."}, {"title": "IV. TENSORIZING MOTION PLANNING", "content": "GTMP leverages a fixed discretization structure, repre- sented as a random multipartite graph, to enable efficient planning vectorization. This approach contrasts with the incremental discretization structures of classical motion plan- ning algorithms, which procedurally expand the search space during planning.\nA. Discretization Structure\nWe introduce the random multipartite graph as a novel configuration discretization structure designed for seamless representation using tensors.\nDefinition 2 (Random Multipartite Graph Discretization). Consider a geometric_graph G = (V,E) on configuration space C, the node set V is represented by {qs, M, G}, where M = {Lm}m=1 is a set of M layers. Each layer Lm = {qi \u2208 C | qi ~ Pm}_1 contains N waypoints sampled by an associated proposal distribution pm on C. The edge set E is defined by the union of (forward) pair-wise connections between the start and first layer {(qs,q) | \u2200q \u2208 L1}, between layers in M\n{(qm,qm+1) |\u2200qm \u2208 Lm,qm+1 \u20ac Lt+1, 1 < m < M},\nand between the last layer and goals {(q,qg) | \u2200q \u2208 LM, qg \u2208 G}, leading to a complete (M+2)-partite directed graph.\nWe typically set pm = U(C) as uniform distributions over configuration space (bounded by configuration limits cf. Fig. 2). Extending Definition 2 to spline discretization structure by replacing the straight line with the cubic polyno- mials, representing any edge (q, q') \u2208 E, is straightforward with Akima spline [20], [35] (cf. Appendix).\nDefinition 3 (Path In G). A path f : [0,1] \u2192 q in G exists if it f(0) = qo, f(1) \u2208 G and its piecewise linear segments correspond to edges connecting qo and qg E G.\nB. Deterministic Markov Decision Process On Graph\nWe augment an Deterministic Markov Decision Process (DMDP) on G by the tuple (V,E,c,t, \u03b3), where the state set is the node set of G, the action set is equivalent to the edge set E, the transition cost function c :VxE \u2192 R, deterministic state transition probability t(q' | q, (q, q')) =\n1, (q, q') \u2208 E and discount factor \u03b3\u2208 [0,1). The goal set\nGCV is the terminal set with terminal costs cg(q), q \u2208 G.\nA policy \u03c0 : V \u2192 E depicts the decision to transition to the next layer given the current state at the current layer.\nWe employ typically unbounded occupancy collision cost\n$$C_{coll} (q) = 0 \\text{ if } q \\in int_s (C_{free}), \\text{ else } \\infty,$$  \nwhich merges the planning and verification steps (cf. Theo- rem 1). Then, the transition cost function can be defined\n$$c(q, (q, q')) =  \\alpha \\int \\limits_0^1 C_{coll} (q(t)) dt + ||q-q'||, $$\nwhere the collision term is a straight-line integral with \u03b1 = 1/ ||qq|| between q(a) = q and q(b) = q'. Finding the optimal value function for this DMDP is straightforward with the Bellman optimality operator\n$$V_G(q) = \\min_{(q,q')}\\sum t(q'|q,(q,q')) (c(q,(q,q')) + \\gamma V_G(q'))$$\n$$V_G(q) \\leftarrow \\min_{(q,q')} (c(q,(q,q')) + \\gamma V_G(q'))$$\nIt is well-known that Eq. (4) converges to a fixed point [36], and the optimal policy is extracted by tracing the optimal value function\n$$\\pi^* (q) = argmin_{(q,q')} (c(q, (q, q')) + \\gamma V(q')),$$\nfrom qo until q' \u2208 G. This produces a sequence of edges P = {(qo, q\u2081), ..., (qM, qg) | qg \u2208 G}.\nProposition 1. By following any policy on (V, E, c, t, y) from 90, P has a constant cardinality of M + 1.\nProof. By construction of graph G, each application of Eq. (5) increases the layer number m strictly mono- tonically, since t(qm+1 | qm, \u03c0(qm)) = t(qm+1 |\nqm, (qm, qm+1)) = 1, (qm, qm+1) \u2208 E. Hence, |P| = M + 1."}, {"title": "C. Batching The Planner", "content": "In practice, we do not need to construct an explicit graph data structure due to G's multipartite structure. Observing the deterministic state transition and the equal cardinality of layers, we just need to compute and maintain the transition cost matrices Cs \u2208 RM, Ch\u2208R(M\u22121)\u00d7N\u00d7N, CN\u00d7|G| and value matrices V, \u2208 R, V\u2082 \u2208 RMXN, V, \u2208 RIGI, where\nCs is the transition costs from qo to the first layer; Ch, C\u03b9 hold transition costs between middle layers and last layer to goals; Vs, Vh, V9 = Cg hold values of start, layers costs and terminal goal costs. First, we sample in batches the waypoints for all layers Q \u2208 RM\u00d7N\u00d7d within the state limits and form the goal configuration G \u2208 R|G|\u00d7d from G. The cost-to-go term of the transition costs Eq. (3) is approximately computed by first probing an H number of equidistant points on all edges, evaluating them in batches, and taking the mean values over the probing dimension. We assume all cost functions are batch-wise computable. Then, the Bellman optimality operator Eq. (4) becomes\nVh [M-1] \u2190 min(C1 + VVg)\nVh[: M - 1] \u2190 min(Ch +yVh[1 :], axis = -1)\nV \u2190 min(Cs + YVh[0])\nGiven the converged value matrix Vh*, a sequence of indices is traced by Eq. (5) (cf. Algorithm 1), which is used to extract the waypoints from Q and G. Notice that all component matrices can be straightforwardly vectorized by adding the batch dimension B for all matrices. Note that [12]\u2013[14], [23] focus on vectorizing collision checking or forward kinematics in a single planning instance, while we can ensure that Eqs. (4) and (5) can be vectorized at instance-level [7] by Proposition 1.\nComplexity Analysis. Eq. (6) is an asynchronous update in batches (i.e., updates based on values of previous iteration) and also known to converge [38]. Considering the layer num- ber M, waypoint number per layer N, and probing number H, we assume that Eq. (6) is executed on P processor units, a rough estimate of time complexity per VI iteration is O(MN/P), since the layers are independently updated and each processing unit is assigned M/P layers. [39] shows that the worst-case complexity of VI for any MDP is K = 0(1/(1 \u2013 \u03b3)log(1/(1 \u2013 \u03b3))), where K is the convergence rate of Bellman optimality operator. Hence, the"}, {"title": "V. THEORETICAL ANALYSIS", "content": "Notations. We denote F as the set of feasible paths for a feasible planning problem. Let R be the set of all paths in G. The path cost is the sum of (discounted) straight-line integrals over the edges c(g) = \u2211m=0Ymc(qm, qm+1) + cg(g(1)), g\u2208 R.\nAssumption 1. We assume that all associated proposal distributions at each layer are uniformly distributed on the configuration space \u22001 < m < M, pm := U(C).\nAssumption 2. Consider a feasible planning problem, there exists a feasible path f : [0,1] \u2192 Cfree having margin r = inft\u2208[0,1] || f(t) \u2013 q||, q \u2208 Ccoll, such that r > 0.\nThis assumption is common in path planning applications, where the free-path set is not zero-measure \u03bc(F) \u2260 0.\nTheorem 1 (Feasibility Check). For any planning problem with \u03b3 > 0, v(q\u2030) < \u221e if and only if there exists a feasible path in G.\nProof. According to Bellman optimality, (90) = ming{c(g) | g \u2208 R} is the minimum path cost reaching the goals. By definition, the smoothness term in Eq. (3) is bounded with q \u2208 C, since TV(g) < \u221e. Thus, with \u03b3 > 0, any unbounded path cost c(P) = \u221e occurs, if and only if \u2203t, f(t) \u2208 Ccoll. Hence, with \u03b3 > 0, v\u1ed7(qq) = minp{c(P) |\nP\u2208 R} < \u221e, if and only if \u2203P \u2208 R, c(P) < 8.\nTheorem 1 is useful to filter collided paths after VI.\nLemma 1 (Solvability In Finite Path Segments). If assump- tion 2 holds, there exists a minimum number of segments\nMm \u2208 N>0 for piecewise linear paths to be feasible.\nProof. We first show that there exists a piecewise linear path g : [0,1] \u2192 C such that ||f-g||\u221e < r, where ||fg|| = maxt\u2208[0,1] || f(t) \u2013 g(t)||. We construct g by dividing the interval [0,1] into M subintervals with length less than \u03b4 > 0, i.e., [to, t1], ..., [t\u043c\u22121,t\u043c] with 0 = to <\nt1 < ... < tm = 1. On each subinterval [tm,tm+1], we"}, {"title": "VI. EXPERIMENT RESULTS", "content": "We assess the performance of GTMP and its extension w.r.t. task success, success path diversity, and smoothness compared to popular baselines and collision-checking mech- anisms. Hence, we investigate the following questions for batch trajectory generation, or for finding the global solution: i) how does GTMP with JAX/GPU-implementation compare to highly optimized probabilistic-complete planners imple- mented in PyBullet/OMPL [19], [40] or in VAMP [23]?, ii) how does GTMP-Akima compare to popular gradient- based smooth trajectory optimizers such as CHOMP [41] or GPMP [8]?, and iii) Can the probabilistic completeness The- orem 2 be verified experimentally?\nWe run all CPU-based planners (RRTC, BKPIECE) on\nAMD Ryzen 5900X clocked at 3.7GHz and GPU-based plan- ners (GTMP, CHOMP, and GPMP) on a single Nvidia RTX 3090. Note that all GPU-based planners are implemented in\nJAX [18], and the planning times are measured after JIT 1. We set a default probing H = 10 and use uniform sampling for all GTMP runs. For all CPU-based planners, we give a timeout of one minute and report metrics after simplification routines. Planning time per task is the sum of all planning instances, which includes simplification time for CPU-based planners, while GTMP does not need path simplification.\nMetrics. The metrics are chosen for comparing across probabilistically-complete planners and trajectory optimiz- ers: (i) Planning Time (s) in seconds of a batch of paths given a task, (ii) Collision Free (CF %) percentage of paths in a batch (failure cases are either in collision or timeout), (iii) Minimum/Mean Cosine Similarities (Min Cosim/Mean Cosim) over consecutively path segments and averaging over the batch of paths in a task, (iv) Paths Diversity (PD) as the mean of pairwise Sinkhorn [42] distances in a batch having B paths\n$$PD =  \\sum_{i \\neq j} OTx (P_i, P_j), i, j\\in \\{1, ..., B\\},$$\nwhere we treat the path P = {qo,...qr} as empirical distribution with uniform weights, and different paths can have different horizons T. The entropic scalar X = 5e-3 is constant. The metric Min/Mean Cosim measures the worst/average rough turns over path segments, while the"}, {"title": "A. Planar Occupancy Dataset", "content": "Fig. 3 (top-row) compares GTMP (M=200, N=4) with OMPL implementation of (single-query) RRTConnect [2] and BKPIECE [43]. The environments are planar occupancy maps of Intel Lab, ACES3 Austin, Orebro, Freiburg Cam- pus, and Seattle UW Campus generated from the Radish dataset [44]. The maps are chosen to include narrow pas- sages, large spaces, and noisy occupancies (cf. Fig. 1). We randomly sample 100 start-goal pairs as tasks on each map and plan 100 paths per task.\nWe clearly see a comparable Min/Mean Cosim (i.e., sim- ilar statistics of rough turns) and PD of GTMP (M=200, N=4) compared to baselines across maps and in aggregated statistics over maps (cf. Table I). With JIT and GPU utiliza- tion, GTMP consistently produces batch paths with a fixed number of segments and x250 less wall-clock time compared to baselines across maps."}, {"title": "B. Motion Bench Maker Dataset", "content": "We choose the standard MOTIONBENCHMAKER (MBM) dataset [45] of challenging 7-DoF Franka Emika Panda tasks such as table-top manipulation (table pick and table under pick), reaching (bookshelf small, tall and thin), and highly-constrained reaching (box and cage). Each task is pre-generated with 100 problems available publicly. We implement our collision-checking in JAX via primitive shape approximation, such as a Panda spherized model, oriented cubes, and cylinders representing tasks in MBM. The de- fault hyperparameters and compilation configurations for VAMP/RRTC, OMPL/RRTC, and OMPL/BKPIECE are also adopted following [23]. CHOMP and GPMP plan first-order trajectories having an horizon of T = 32. All algorithms are compared on the planning performance of a batch of B = 50 paths for all tasks.\nFig. 3 (bottom-row) shows the planning performance comparisons between GTMP (N=30, M=2) and baseline probabilistically-complete planners and gradient-based tra- jectory optimizers. We see that GTMP consistently has the best diversity (PD) and worst rough turn statistics (Min Cosim) in all tasks. This is due to the maximum exploration behavior of GTMP by sampling uniformly over configuration space, which increases the risk of rough paths. In principle, increasing points per layer N while having minimum solving layers M would improve Min Cosim due to having more chances to discover smoother paths with fewer segments, as long as GPU memory allows (cf. Fig. 4). Compared with gradient-based optimizers on Table II, GTMP-Akima"}, {"title": "C. Ablation Study", "content": "This section explores various aspects of GTMP by inves- tigating hyperparameter sweeps.\nProbabilistic Completeness Ablation. Fig. 4 shows the sweeping statistics of M\u2208 {2, ..., 80}, N\u2208 {10,...,100} the Intel Lab occupancy map with a chosen start-goal pair to study the probabilistic completeness Theorem 2. Fig. 4 shows experimentally polynomial planning time-complexity after JIT. The CF(%) metric directly reflects the path existence probability Eq. (9). Notice that the minimum layer Mm = 3 must be set for collision-free paths in the batch. Interestingly, Mm is also the optimal number of layers to achieve non-zero CF(%) with a minimal point per layer N (red star), which confirms the observation in Section V. Further observations on Min/Mean Cosim also confirm that with less M, the paths are smoother. Finally, higher path diversity is induced by having higher CF(%).\nGTMP Hyperparameter Characteristics. In Table III, we ask how many tasks in the Panda MBM dataset can be solved with just one layer since M = 1 is a trivial realization of GTMP (i.e., VI is not required at M = 1). Solving a task means at least one collision-free path exists in a batch of B = 50 paths per problem. We report for GTMP and GTMP-Akima the aggregated planning times of 250 \u00b1 60\u03bcs, 300 \u00b1 80\u00b5s and Min Cosim of -0.20 \u00b1"}, {"title": "VII. DISCUSSION & CONCLUSIONS", "content": "GTMP offers several advantages algorithmically, as it is vectorizable over a large number of planning instances, it does not require joint-limit enforcement (i.e., sampling points in the limits), gradients or simplification routines. On the practical side, GTMP is easy to implement (i.e., only tensor manipulation), easy to tune (i.e., hyperparameter set (\u039c, \u039d, \u0397, \u03b3 = 0.99)), and easy to incorporate motion planning objectives in Eq. (16).\nHowever, we do not argue for replacing classical sampling- based algorithms such as RRT with GTMP; rather, using it as a complementary tool. GTMP excels as a generator of diverse, globally optimal trajectories for dataset creation, whereas RRT variants focus on rapid single-path execution. GTMP addresses global exploration challenges but comes with memory requirements, especially for GPU accelera- tion. In contrast, local methods such as CHOMP or GPMP leverage gradient-based, more memory-efficient trajectory optimization. GTMP-Akima, for instance, avoids the need for gradients while delivering smooth velocity trajectories by a spline discretization structure, making it a viable initialization for methods like GPMP, potentially combining the strengths of both approaches.\nVariants of GTMP emphasize maximum exploration while maintaining smooth trajectory structures. Exploring further smooth discretization structures for higher-order planning is exciting, as the current Akima discretization structure only provides a C\u00b9 spline grid. Furthermore, we are eager to adopt the efficient collision-checking of VAMP [23] for GTMP, when the VAMP batching configuration collision-checking becomes available. Lastly, GTMP suggests the direction of probabilistically-complete batch planners, serving as a differ- entiable global planner or a competent oracle for learning."}, {"title": "APPENDIX", "content": "The Akima spline [20], [35] is a piecewise cubic in- terpolation method that exhibits C\u00b9 smoothness by using local points to construct the spline, avoiding oscillations or overshooting in other interpolation methods, such as cubic splines or B-splines.\nDefinition 4 (Akima Spline). Given a point set {qiq \u2208 C}=1, the Akima spline constructs a piecewise cubic poly- nomial f(t) for each interval [ti, ti+1]\n$$f_i(t) = d_i(t-t_i)^3 + c_i(t - t_i)^2 + b_i(t-t_i) + a_i, $$\nwhere the coefficients ai, bi, ci, di \u2208 C are determined from the conditions of smoothness and interpolation. Let mi = (qi+1 - qi)/(ti+1 - ti) at ti, the spline slope is computed from mi\u22121, Mi+1\n$$s_i = \\frac{|m_{i+1} - m_i|m_{i-1} + |m_{i-1} - m_{i-2}| m_i}{|m_{i+1} - m_i| + |m_{i-1} - m_{i-2}|}$$\nThe spline slopes for the first two points at both ends are S1 = M1, S2 = (m1 + m2)/2, SP\u22121 = (mP-1 +\nMP-2)/2,SP = mp-1. Then, the polynomial coefficients are uniquely defined\nai = qi,\nbi = si,\nci = (3mi \u2013 2si - Si+1)/(ti+1 - ti),\ndi = (si + Si+1 \u2013 2mi)/(ti+1 \u2013 ti)\u00b2.\nThe Akima spline slope is determined by the local be- havior of the data points, preventing oscillations that can occur when using global information. Interpolating with Akima spline does not require solving large systems of linear equations, making it computationally efficient as an ideal extension to Definition 2 to a spline discretization structure.\nDefinition 5 (Akima Spline Graph). Given a geometric graph G = (V,E) (cf. Definition 2), the Akima Spline graph GA has the edge set & geometrically augmented by cubic polynomials. In particular, consider an edge (qm, i, qm+1,j) \u2208 E with i,j are respective indices of points at layers Lm, Lm+1, the spline slope is defined with\nmm,i,j = (qm+1,j-qm,i)/(ti+1-ti) as Modified Akima interpolation [20]\n$$\\delta_{m,i,j} =  \\frac{w_{m,i,j} m_{m-1,i,j} + w_{m-1,i,j}m_{m,i,j}}{w_{m,i,j} + w_{m-1,i,j}}$$\n$$w_{m,i,j} = \\frac{1}{\\frac{N_2}{mm+1,i,j} - \\frac{N_2}{mm-1,i,j}}$$\n$$w_{m-1,i,j} = \\frac{1}{\\frac{N_2}{mm-2,i,j} - \\frac{N_2}{mm-1,i,j}}$$\nThen, the augmented cubic polynomial fi,j(t), t [tm, tm+1] is computed following Eq. (13)\n$$Sm = \\frac{1}{N^2}\\sum  \\delta_{m,i,j}, a_{m,i,j} = q_{m,i}, b_{m,i,j} = Sm, $$\n$$c_{m,i,j} = (3m_{m,i,j} \u2013 2s_m - S_{m+1})/(t_{m+1} - t_m),$$\n$$d_{m,i,j} = (s_m + S_{m+1} 2m_{m,i,j})/(t_{m+1} - t_m)^2.$$\nThe original Akima interpolation [35] computes equal weight to the points on both sides, evenly dividing an undulation. When two flat regions with different slopes meet, this modified Akima interpolation [20] gives more weight to the side where the slope is closer to zero, thus giving priority to the side that is closer to horizontal, which avoids overshoot. Notice that after pre-computing mm,i,j for every edge in GA, every polynomial segment Eq. (15) can be computed in batch for GA. Furthermore, given a batch of graphs GA, adding a batch dimension for these equations is straightforward. The transition cost is then defined\n$$c(q, q') =  (C_{coll}(f(t)) + 1) || f' (t) || dt, $$\nwhere f(t) is the cubic polynomial representing the edge (q, q') \u2208 GA.\nRemark 1. With some algebra derivations, one can verify the cubic polynomial fi,j(t), t \u2208 [tm,tm+1] representing any edge (qm,i,qm+1,j) \u2208 GA satisfying four conditions of continuity\n$$f_{i,j}(t_m) = q_{m,i}, f_{i,j}(t_{m+1}) = q_{m+1,j},$$\n$$f_{i,j}(t_m) = s_m, f_{i,j}(t_{m+1}) = S_{m+1},$$\nfor any m\u2208 {0, . . ., M + 1}, i, j \u2208 {1, ..., N}. Hence, any path f\u2208 GA is an Akima spline.\nThe Akima spline provides C\u00b9-continuity for first-order planning; however, the second derivative is not necessarily continuous. Note that Theorem 2 does not necessarily hold for Akima Spline Graph GA and is left for future work."}]}