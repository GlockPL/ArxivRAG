{"title": "Client-Centric Federated Adaptive Optimization", "authors": ["Jianhui Sun", "Xidong Wu", "Heng Huang", "Aidong Zhang"], "abstract": "Federated Learning (FL) is a distributed learning paradigm where clients collaboratively train a model while keeping their own data private. With an increasing scale of clients and models, FL encounters two key challenges, client drift due to high degree of statistical/system heterogeneity, and lack of adaptivity. However, most existing FL research is based on unrealistic assumptions that virtually ignore system heterogeneity. In this paper, we propose Client-Centric Federated Adaptive Optimization, which is a class of novel federated adaptive optimization approaches. We enable several features in this framework such as arbitrary client participation, asynchronous server aggregation, and heterogeneous local computing, which are ubiquitous in real-world FL systems but are missed in most existing works. We provide a rigorous convergence analysis of our proposed framework for general nonconvex objectives, which is shown to converge with the best known rate. Extensive experiments show that our approaches consistently outperform the baseline by a large margin across benchmarks.", "sections": [{"title": "1 INTRODUCTION", "content": "Federated learning (FL) is a distributed learning setting where many clients collaboratively train a machine learning model under the coordination of a central server, while keeping the training data decentralized and private [39]. In cross-device FL setting, clients are usually an enormous number of edge devices, which own data that are critical to train a large-scale model on server but are not allowed to share the private data due to privacy concerns or regulatory requirements [8, 19].\nFederated Averaging (FedAvg) [51] solves this problem by taking a \"computation then aggregation\" approach, i.e., having each client train locally with its own data, and the server aggregates the local models every once in a while. FedAvg and its variants [33, 40, 58, 77] enjoy communication efficiency as well as an appealing \u201clinear speedup\", i.e., the convergence accelerates with increasing number of clients and local steps, even with only a small fraction of clients participating in each round [41, 91], and have thus become the most popular FL algorithms.\nIn spite of the empirical success, FedAvg and its variants face the following two key challenges that may severely destabilize the training and deteriorate its performances,\n\u2022 High degrees of heterogeneity. The statistical heterogeneity (i.e., the local data distributions of clients are non i.i.d.), and system heterogeneity (i.e., the completely different levels of system characteristics such as battery level, computational/memory capacity, network connection), are both ubiquitous in large-scale edge networks. Such high degrees of heterogeneity may result in client drift, where local client models move away from globally optimal models [33, 46, 58]. FedAvg converges slowly or even diverges in presence of client drift.\n\u2022 Lack of adaptivity. Despite its simplicity, there is a disadvantage that FedAvg scales its gradient uniformly and applies an identical learning rate to all features throughout the entire training process, which is similar to its non-federated counterpart Stochastic Gradient Descent (SGD). Such isotropic training leads to inferior performances when the feature space is sparse, or there exists a few dominant feature directions, which is quite common in training large-scale overparameterized deep models such as [7, 15, 17, 25].\nThough various attempts have been made to tackle part of the above challenges, most of them belong to a regime which we refer to as Server-Centric FL. In server-centric FL, the following unrealistic assumptions on server-client coordination have been implicitly made: (1) each client is available upon the server's request, and the server determines the sampling scheme of clients; and (2) all clients conduct a highly synchronized and homogeneous local computing, i.e., all clients synchronize with the same global model and they conduct identical number of local computations.\nSpecifically, if we observe the clients' local computation part in Algorithm 1 (i.e. Line 5-9), we would summarize that the following assumptions have been intrinsically made, (a) (Homogeneous Local Updates) Clients run an identical number of K steps; (b) (Uniform Client Participation) Each client is sampled by the server in a given round uniformly and independently according to an underlying distribution; (c) (Synchronous Local Clients) All participating clients synchronize at any round t, i.e., they initialize with the global model at current time $x_t$.\nThese assumptions provide a useful yet over-simplified characteristic of real-world system. Due to their simplicity, most existing FL algorithms and their corresponding convergence analysis are proposed and derived based on the above assumptions, see e.g. [1, 27, 33, 40, 41, 51, 58, 64, 77, 78, 80, 91, 96] (please check Section 6 and Appendix ?? for a comprehensive review of existing works).\nWith the above assumptions, server takes a centric role in the federated learning system, as all clients always synchronize with the server, and the server determines the client sampling scheme as well as number of local updates, we therefore refer to this setting as Server-Centric Federated Learning System.\nHowever, we would like to argue that server-centric federated learning is an unrealistic characterization of real-world system. Especially considering that it typically takes thousands of communication rounds to converge in large-scale cross-device deployments, it is impossible to ensure these assumptions hold throughout the entire process. Instead, clients in a realistic cross-device FL system usually have the following characteristics [32, 39],\n\u2022 (Heterogeneous Client Capability) The clients may have completely different computational capability, and faster clients are able to carry out more local computations than slower clients during the same time period. Requesting identical local updates would straggle the training and incur unnecessary energy waste.\n\u2022 (Unpredictable Client Availability) The clients may have arbitrary availability due to various constraints, e.g., unstable network connection, battery outage, or low participation willingness. Thus, each client determines to participate or not in a given communication round purely dependent on its own condition and the decision is completely unpredictable by the server.\n\u2022 (Asynchronous Local Model) Due to the random nature of client participation and capability, a reasonable server does not wait until the slowest client completes local computation, but would instead start the next round as long as a sufficient number of clients respond. The rest of the clients would participate in a future round when they finish and decide to respond. Though this paradigm is more efficient than its synchronous counterpart, the behavior of clients may be more chaotic as clients may compute based on an outdated global model $x_{t-\\tau_{t,i}}$ instead of $x_t$ (up to a time-varying, device-dependent random delay $\\tau_{t,i}$).\nIn summary, due to their discrepancy against real-world settings, the applicability of these server-centric FL algorithms is questionable. Traditionally, most works that recognize client heterogeneity focus explicitly on statistical heterogeneity [42, 91], i.e., the local data distribution distinguishes with each other, while in reality the system heterogeneity is as ubiquitous as statistical heterogeneity and largely remains unexplored."}, {"title": "3 CLIENT-CENTRIC FEDERATED ADAPTIVE OPTIMIZATION", "content": "In light of the limitations of server-centric FL, we propose an FL regime which we refer to as Client-Centric Federated Learning (CC-FL) to have a more precise characterization of real-world settings. And to further address the two key challenges FL algorithms encounter, i.e., client drift and lack of adaptivity, we propose Client-Centric Federated Adaptive Optimization, which is a general framework that consists of a class of novel federated optimization approaches, such as CC-FedAdam/CC-FedAdagrad/CC-FedAMS, which are formalized in Algorithm 2.\nSpecifically, in CC-Federated Adaptive Optimization, we enable several unique features which are missed by most existing works: (1) arbitrarily heterogeneous local computation, client participates only when it intends to, and each client can self-determine a time-varying and device-dependent number of local epochs; (2) asynchronous aggregation, each participating client can work with an asynchronous view of the global model from an outdated timestamp; and (3) concurrent server-client optimization, global optimization on server happens concurrently with local update by client, which avoids stragglers from stopping the entire training process. Each client takes an independent role in deciding the participation, and how much computation it carries out in this regime, which is why we refer to it as Client-Centric FL (CC-FL).\nOne key ingredient we incorporate is the server-side adaptive optimization, which is extremely helpful in mitigating client drift and adding adaptivity when training large-scale overparameterized models. Another critical advantage is that as the design of adaptive optimizers leverages the average of historical gradient information, the global update no longer relies only on current model update as in FedAvg baseline. Note that historical information would effectively regularize the global update from going wild when there is unexpected client distributional drift. Data-driven model training often leads to poor out-of-distribution performance [99].\nWe then provide the convergence analysis for CC-Federated Adaptive Optimization. Our theory reveals key factors that affect the performances, and shows that our proposed approach obtains the best known convergence rate. We are unaware of any existing analysis that studies federated adaptive optimization with asynchrony and heterogeneous local computing.\nFinally, extensive experiments show that any of the proposed CC-FedAdam/CC-FedAdagrad/CC-FedAMS can outperform FedAvg and its variants by a large margin across benchmarks. The improvement is consistent across various levels of statistical/system heterogeneity. We also carry out an exhaustive hyperparameter sensitivity analysis and our approach turns out to be quite easy to tune to obtain a much better performance than FedAvg.\nOur main contributions can be summarized as follow,\n\u2022 We propose a class of novel FL optimization approaches, which is effective in mitigating the client drift and lack of adaptivity issues in presence of system heterogeneity.\n\u2022 We show our approach matches a best known convergence rate $O(\\frac{1}{mKT})$ for general nonconvex objectives. To our best knowledge, this is the first convergence analysis on federated adaptive optimization with both statistical and system heterogeneity 1.\n\u2022 Empirical results demonstrate that our approaches consistently outperform widely used baseline by a large margin, across benchmarks and levels of client heterogeneity.\nOrganization. The rest of the paper is organized as follows. In Section 2, we introduce background that is pertinent to our proposed algorithm. In Section 3, we first discuss the limitations of existing server-centric FL algorithms and then introduce our proposed Client-Centric Federated Adaptive Optimization. In Section 4, we provide the convergence analysis of our proposed approach, followed by Section 5, where we provide experimental results that validate the effectiveness of our proposed algorithm. We discuss the related works in Section 6, and conclude our works in Section 7. We defer the proof of our convergence analysis and extra related works/experiments to Appendix due to space limit."}, {"title": "2 BACKGROUND", "content": "2.1 Federated Averaging (FedAvg)\nMost Federated Learning problems can be formalized as,\n$\\min_{x \\in \\mathbb{R}^d} f(x) \\triangleq \\frac{1}{n} \\sum_{i=1}^n f_i(x)$, where $f_i(x) = \\mathbb{E}_{\\xi \\sim D_i}f_i(x, \\xi)$.\nwhere $n$ is the total number of clients and $x$ is the model parameter with $d$ as its dimension. Each client $i$ is associated with a local data distribution $D_i$ and a local objective function $f_i(x) = \\mathbb{E}_{x \\sim D_i}f_i(x, \\xi)$. The global objective function is the averaged objective among all clients. We consider the general non i.i.d. setting, i.e., $D_i$ can be completely different from $D_j$ when $i \\neq j$.\nFederated Averaging (FedAvg) [51] is the first and probably most popular algorithm to optimize (1), formalized in Algorithm 1. Suppose the total number of communication rounds is $T$, at each round $t \\in \\{1, ..., T\\}$, FedAvg is composed of client-level optimization"}, {"title": "3.1 Limitations of Server-Centric FL", "content": "Most existing federated learning algorithms universally make the following assumption that rarely holds in real world deployment,\nAt a given round, all clients synchronize with the same global model and they conduct identical number of local computations.\nSpecifically, if we observe the clients' local computation part in Algorithm 1 (i.e. Line 5-9), we would summarize that the following assumptions have been intrinsically made, (a) (Homogeneous Local Updates) Clients run an identical number of K steps; (b) (Uniform Client Participation) Each client is sampled by the server in a given round uniformly and independently according to an underlying distribution; (c) (Synchronous Local Clients) All participating clients synchronize at any round t, i.e., they initialize with the global model at current time $x_t$.\nThese assumptions provide a useful yet over-simplified characteristic of real-world system. Due to their simplicity, most existing FL algorithms and their corresponding convergence analysis are proposed and derived based on the above assumptions, see e.g. [1, 27, 33, 40, 41, 51, 58, 64, 77, 78, 80, 91, 96] (please check Section 6 and Appendix ?? for a comprehensive review of existing works).\nWith the above assumptions, server takes a centric role in the federated learning system, as all clients always synchronize with the server, and the server determines the client sampling scheme as well as number of local updates, we therefore refer to this setting as Server-Centric Federated Learning System.\nHowever, we would like to argue that server-centric federated learning is an unrealistic characterization of real-world system. Especially considering that it typically takes thousands of communication rounds to converge in large-scale cross-device deployments, it is impossible to ensure these assumptions hold throughout the entire process. Instead, clients in a realistic cross-device FL system usually have the following characteristics [32, 39],\n\u2022 (Heterogeneous Client Capability) The clients may have completely different computational capability, and faster clients are able to carry out more local computations than slower clients during the same time period. Requesting identical local updates would straggle the training and incur unnecessary energy waste.\n\u2022 (Unpredictable Client Availability) The clients may have arbitrary availability due to various constraints, e.g., unstable network connection, battery outage, or low participation willingness. Thus, each client determines to participate or not in a given communication round purely dependent on its own condition and the decision is completely unpredictable by the server.\n\u2022 (Asynchronous Local Model) Due to the random nature of client participation and capability, a reasonable server does not wait until the slowest client completes local computation, but would instead start the next round as long as a sufficient number of clients respond. The rest of the clients would participate in a future round when they finish and decide to respond. Though this paradigm is more efficient than its synchronous counterpart, the behavior of clients may be more chaotic as clients may compute based on an outdated global model $x_{t-\\tau_{t,i}}$ instead of $x_t$ (up to a time-varying, device-dependent random delay $\\tau_{t,i}$)."}, {"title": "3.2 Methodology", "content": "In light of the limitations of server-centric federated learning settings and the convincing empirical results of federated adaptive optimization, in this section, we propose a novel framework which we refer to as Client-Centric Federated Adaptive Optimization, which is formalized in Algorithm 2.\n3.2.1 Workflow of Algorithm 2.\nIn the Client-Centric FL (CC-FL) framework, each client takes an independent role in deciding the participation, and how much computation it carries out. Note that CC-Federated Adaptive Optimization is a general and flexible framework in which any adaptive optimizer could serve as a plug-and-play module, and we display only three examples in Algorithm 2, i.e., CC-FedAdagrad/CC-FedAdam/CC-FedAMS. For expository purposes, we walk through the workflow of Client-Centric Federated Adaptive Optimization only with CC-FedAMS.\nSuppose $T$ is the total number of rounds in CC-FedAMS. At round $t \\in \\{1,2,..., T\\}$, each client can self-determine whether to participate, and staying idle in the entire training process is allowed. Once it determines to participate, it downloads the global model $x_\\mu$ from the server. Note that since each client may choose to participate at a different timestamp, the global model $x_\\mu$ may not be from the current timestamp $x_t$. The client then triggers local computation CC-Local (i.e., Algorithm 3). It first initializes $x_{\\mu,0}^i = x_\\mu$ locally and carries out $K_{t,i}$ steps of local SGD (i.e., $x_{\\mu,k+1}^i = x_{\\mu,k}^i - \\eta_l g_{\\mu,k}^i$ for $K_{t,i}$ steps). Note that in server-centric FL algorithm, $K_{t,i}$ is a constant that does not vary with $t$ and $i$ (see e.g., Algorithm 1). Here, we allow $K_{t,i}$ to be time-varying and device-dependent. The client then computes a normalized model update by $\\Delta_\\mu^i = \\frac{x_{\\mu,0}^i - x_{\\mu,K_{t,i}}}{K_{t,i}}$ and sends $\\Delta_\\mu^i$ to server. The normalization is to de-bias the global model to avoid favoring clients with more local updates.\nConcurrently with the local computation CC-Local, the server collects the model updates from responsive clients $\\{\\Delta_{t-\\tau_{t,i}}^i, i \\in S_t\\}$, where $S_t$ is a \"buffer\" of responsive clients. Note that for each client $i \\in S_t$, it may participate at a historical timestamp $t - \\tau_{t,i}$, which is up to a random delay $\\tau_{t,i}$. In server-centric FL algorithm, $\\tau_{t,i} = 0$. The global update only takes place once the buffer collects $m$ client updates, i.e., as long as $|S_t|$ reaches $m$, regardless of the status of the rest of the clients. Such parallel runs of clients and server avoid unnecessary waiting time and wasteful resources. The global updating rule is adapted from a popular non-federated adaptive optimizer AMSGrad [59], which uses a max stabilization step $\\hat{v}_t = \\max(\\hat{v}_{t-1}, v_t)$ that generates a non-decreasing $\\hat{v}_t$ sequence to solve the non-convergence issue in Adam."}, {"title": "3.2.2 Key Algorithmic Designs.", "content": "Several unique features of Algorithm 2 distinguish itself from ordinary server-centric FL, which include (a) Normalized Model Update (Line 9 in Alg 3), (b) Size m Buffer $S_t$ (Line 8 in Alg 2), (c) Server-side Adaptive Optimization (Line 11-15 in Alg 2). These features are key to alleviate system heterogeneity and client drift. We summarize the details and reasoning in Appendix"}, {"title": "4 CONVERGENCE ANALYSIS", "content": "In this section, we provide the convergence analysis for our proposed Client-Centric Federated Adaptive Optimization and its practical implications.\nTo our best knowledge, this is the first definitive convergence result on federated adaptive optimization with system heterogeneity. Please note that enabling adaptive scaling in asynchronous FL is challenging in theoretical proof and is not an extension of results in [58] or [92], since the chaotic iterates caused by asynchrony and a nonzero momentum factor $\\beta$ are ignored in [58, 92].\nWe study general non-convex objective functions under statistical heterogeneity, i.e., each local loss $f_i(x)$ (and thus the global loss $f(x)$) may be non-convex 2, and $D_i \\neq D_j$ when $i \\neq j$.\nAssumption 1 (Smoothness). Each local loss $f_i(x)$ has L-Lipschitz continuous gradients, i.e., $\\forall x, x' \\in \\mathbb{R}^d$, we have\n$||\\nabla f_i(x) - \\nabla f_i(x')|| \\leq L ||x - x' ||$, where L is the Lipschitz constant. And f has finite optimal value, i.e., $f^* \\triangleq \\min_x f(x)$ exists, and $f^* > -\\infty$.\nAssumption 2 (Unbiased Bounded Gradient). We could access an unbiased estimator $g_k = \\nabla f_i(x_{\\mu,k}^k)$ of true gradient $\\nabla f_i(x_\\mu^k)$ for all $t, k, i$, where $g_k$ is the stochastic gradient with minibatch $\\xi_{t,k}$. And the stochastic gradient is bounded, i.e., $||g_k|| \\leq G$.\nAssumption 3 (Bounded Local Variance). Each stochastic gradient on the i-th client has a bounded local variance, i.e., we have\n$\\mathbb{E}_\\xi [||g_{t,k}^k - \\nabla f_i(x_\\mu^k)||^2] \\leq \\sigma_i^2$.\nAssumption 4 (Bounded Global Variance). Local loss $\\{f_i\\}_{i=1}^n$ have bounded global variance, i.e., $\\forall x, \\frac{1}{n} \\sum_{i=1}^n ||\\nabla f_i(x) - \\nabla f(x)||^2 \\leq \\sigma^2$.\nAssumptions 1 - 4 are all standard and mild assumptions in federated learning research, and have been universally adopted in most existing works [4, 34, 35, 42, 56, 58, 59, 80]. Assumption 2 is a standard assumption when studying adaptive optimization approaches and has been widely adopted in [13, 35, 58, 59, 80].\nNote that Assumption 4 marks that we are studying general non i.i.d. settings, where we allow each client has heterogeneous data distributions, as $\\sigma^2 = 0$ corresponds to the i.i.d. setting. We also do not require stronger and unrealistic assumptions such as convex objective or Lipschitz Hessian that are used in existing works such as [22, 88]."}, {"title": "Remark 4.1.1 (How Random Delay Impacts Convergence?).", "content": "Intuitively, due to the chaotic behavior brought by asynchronous clients, the convergence of CC-federated adaptive optimization is expected to be negatively impacted by the random delay $\\tau$. Corollary 4.1.1 indicates the slowdown effect from the random delay $\\tau$ through the $O(\\sqrt{\\frac{\\tau}{T}})$ term. But fortunately, Corollary 4.1.1 also implies, if $\\tau$ is only moderately large, then client-centric federated adaptive optimization can obtain an $O(\\frac{1}{mKT})$ rate, which does not depend on $\\tau$, i.e. the negative impact of using outdated information vanishes asymptotically. Such $O(\\frac{1}{mKT})$ rate indicates our client-centric federated adaptive optimization can converge with chaotic system heterogeneity, and matches the best known convergence rate in asynchronous computing [3, 44, 92]."}, {"title": "Remark 4.1.2 (Convergence Rate of Arbitrary Participation).", "content": "A natural question is that what happens if the clients participate entirely arbitrarily, since we assume client is included in participation uniformly at random in Theorem 4.1. We could show the resulting convergence rate is $O(\\frac{\\sigma}{\\sqrt{T}}) + O(\\frac{\\tau}{T}) + O(\\frac{1}{m}) + \\Omega(\\sigma)$. And we could further show $\\Omega(\\sigma)$ is indeed the lower-bound rate (i.e. unavoidable) by constructing worst-case scenario (imagine only two clients $f(x) = \\frac{1}{2}(f_1 + f_2)$, where the loss for 1st client is $f_1(x) = (x+G)^2$ and the 2nd client is $f_1(x) = (x - G)^2$. In this case $\\sigma^2 = 4G^2$. Suppose client 1 never participates, then the optimum $x^*$ any algorithm could find is G, where $\\mathbb{E}[||\\nabla f(x^*)||^2] = \\Omega(\\sigma)$). Thus, if there is no condition for the participation, any algorithm is subject to non-convergence. Theorem 4.1 is shown with one particular participation pattern, which can be relaxed or altered."}, {"title": "Remark 4.1.3 (Linear Speedup w.r.t m, K).", "content": "The $O(\\sqrt{\\frac{\\tau}{mKT}})$ also reveals an appealing linear speedup effect of number of participating clients m and number of local epochs K. Linear speedup in terms of m indicates the convergence is faster with more participating clients. Such speedup is not revealed by existing bound in [54]. The speedup in terms of K reflects an important trade-off between local computation and server-client communication, i.e., more local computation (larger K) can shorten the convergence, thus requiring fewer rounds of communication (smaller T)."}, {"title": "5 EXPERIMENTS", "content": "We present extensive experimental results on vision and language tasks in 5.2 that validate the effectiveness of our proposed approaches. We also analyze the hyperparameter sensitivity in 5.3. We defer extra experimental results to Appendix due to space limit. Our codes are available at https://anonymous.4open.science/r/CC-Federated-Adaptive-Optimization.\n5.1 Experimental Setting\nWe experiment with benchmark datasets such as Fashion-MNIST [87], CIFAR10, CIFAR100 [36], and StackOverflow. For baseline and our proposed approaches, we sweep a wide range of hyperparameters and display the curves under best hyperparameter settings [9, 50, 98, 100].\nHow Statistical Heterogeneity is Implemented?\nWe enforce the label imbalance across all clients to simulate the statistical heterogeneity (i.e. non i.i.d. settings). Specifically, each client is allocated a proportion of the samples of each label according to a Dirichlet distribution 6 which is parameterized by a concentration parameter $\\alpha > 0$. $\\alpha$ controls the degree of non i.i.d. across clients, with $\\alpha \\rightarrow \\infty$ indicates all clients have identical distributions (i.e., no statistical heterogeneity) and $\\alpha \\rightarrow 0$ indicates each client only has samples from one random class. Same procedure has been used in [27, 38, 77, 93].\nHow System Heterogeneity is Implemented?\nSystem heterogeneity has two facets in this paper, i.e., asynchronous aggregation and heterogeneous local computing. To simulate the asynchrony, we allow each client to select one global model randomly from the last recent $\\tau + 1$ global models, where $\\tau$ is the maximum random delay and controls the degree of asynchrony. Note that ordinary synchronous setting is a special example when $\\tau = 0$. To simulate the heterogeneous local computation, we allow each worker to randomly select local epoch number from $\\{1, 2,..., K * R\\}$ at each round so that each worker has a time-varying, device-dependent local epoch, where K is a default number of local epoch, and R is a degree of randomness. For example, if K = 3, ordinary homogeneous setting enforces all clients"}, {"title": "5.2 Performances on Benchmark Datasets", "content": "We sweep $\\eta$ in a wide grid $\\eta \\in \\{10^{-3}, 10^{-2.5}, ..., 10^{1}\\}$, and show the curves with best hyperparameter settings below [43, 49, 74, 97]. Figure 1(a) and 1(b) show the training/testing performances of training ResNet [26] on CIFAR-10 for 500 rounds. The concentration parameter $\\alpha = 3.0$ and maximum delay $\\tau = 5$. Note that CC-FedAvg in the figures denotes the ordinary FedAvg [51] (i.e. $\\eta = 1$) in CC framework, while CC-FedSGD denotes a generalized FedAvg (i.e. search the best $\\eta$ from the same grid as our proposed approaches). We could observe that this extra degree of freedom brings a significant acceleration in training (CC-FedSGD converges much faster than CC-FedAvg in Figure 1(a)). Though it only exhibits a marginal improvement in testing, CC-FedSGD is apparently a stronger baseline than CC-FedAvg. As of our proposed approaches, any of CC-FedAMS/CC-FedAdam/CC-FedAdagrad outperforms CC-FedSGD by more than 10% in testing performances after only 300 rounds. CC-FedSGD could catch up the training curve of CC-FedAMS in Figure 1(a), while the large gap between testing curves persists in Figure 1(b).\nImprovement is Consistent under Various Settings\nWe test the performances across different settings of $\\tau, R$, datasets, and architectures.\nWe run experiments on more benchmarks, one image task (CIFAR-100) and one language task (tag prediction on StackOverflow). The results are presented in Table 2. Our proposed approaches outperform the baseline significantly across benchmarks, especially in NLP task (approximately 30%), where gradient tends to be more sparse which adaptive optimizers can capitalize on [58].\nIn Figure 1(c) and 1(d), we show the training/testing performances with a higher level of statistical heterogeneity, i.e. $\\alpha = 0.5$ while all other settings are identical to Figure 1(a) and 1(b). The similarly superior performances of CC-FedAMS/CC-FedAdam/CC-FedAdagrad persist (by a 10% margin over CC-FedSGD).\nIn Figure 2, we show results across different $\\tau, R$, and benchmarks. Note that we only show the testing curves here as it is a more important metric than training curves. We defer training curves to Appendix due to space limit.\nSpecifically, in Figure 2(a), we test a higher level of system heterogeneity $\\tau = 10$, i.e., each client is allowed to randomly sample from the most recent 10 global models, while all other settings are identical to Figure 1(d) where $\\tau = 5$. Still, under a more asynchronous environment, it is obvious our proposed approaches outperform CC-FedSGD consistently. In Figure 2(b), we test R = 3, i.e., each client is allowed to randomly select a local epoch in $\\{1, 2, ..., 9\\}$ instead of R = 2 in Figure 1(d). We could observe, the performance gap between CC-FedAMS and CC-FedSGD actually increases to a 15% margin with more heterogeneous local computations.\nFigure 2(c) shows the results of running a shallow CNN architecture from [51] on Fashion-MNIST dataset. The CC-Federated Adaptive family of approaches still perform better than CC-FedSGD. But the gap is not as large as ResNet. The reason is likely due to adaptivity is most advantageous in settings where the feature space is sparse or anisotropic, which is common in training overparameterized deep models such as ResNet."}, {"title": "5.3 Ease of Hyperparameter Tuning", "content": "We sweep a wide range of key hyperparameters $\\{\\beta, \\gamma, \\epsilon\\}$ in CC-Federated Adaptive Optimizers under default experimental settings. Specifically, we sweep a $\\beta$ grid: $\\{0.0, 0.5, 0.7, 0.8, 0.9, ..., 0.995\\}$, $\\epsilon$ grid: $\\{10^{-4}, 10^{-3.5}, ..., 10^{-1}\\}$, and $\\gamma$ grid: $\\{0.0, 0.5, 0.7, 0.9, 0.95, 0.99\\}$, and report results in Figure 3. We plot the best performance of CC-FedSGD as a reference. We could see it is quite easy to tune the hyperparameters to obtain a much better performance compared to CC-FedSGD, e.g., $\\beta \\geq 0.7$, $\\epsilon \\in [10^{-3.5}, 10^{-1.5}]$ and $\\gamma$ is flexible."}, {"title": "6 RELATED WORK", "content": "In this section, we discuss related work and how this paper develops on top of prior arts. We mainly review works on (1) Adaptive Optimization Approaches, (2) Server-Centric Federated Optimization, and (3) System Heterogeneity Aware FL.\n6.1 Adaptive Optimization Approaches\nMachine learning models have been widely applied in many different domains, e.g. [14, 16, 23, 25, 53, 70, 72, 73, 81\u201383, 89], and the de facto optimizer for these ML models especially in the era of deep models is a large class of adaptive optimizers represented by Adam.\nThere is a wealth of work on adaptive optimization approaches in non-federated settings. As this paper is mainly focused on FL, we only provide a brief review of this line of research. SGD type optimizers rely heavily and sensitively on proper hyperparameters (learning rate, batch size) setup [21, 24, 30, 47, 63, 65, 66, 68, 69] and also motivated by the poor performances of SGD type optimizers in presence of sparse features and heavy-tail stochastic gradient noise distributions, adaptive optimizers, is shown to converge much faster than SGD in many applications [84]. Most adaptive optimizers share similar design, i.e. scale coordinates of the gradient by square roots of some form of averaging of the squared coordinates on a per-feature basis [59]. Most representative adaptive optimizers include AdaGrad [18], Adam [35], and their variants, e.g. RMSProp [71], AdaDelta [95], AdaBound [48], AMSGrad [59], AdaBelief [103], RAdam [45].\nNote that most of the adaptive optimizers listed above can serve as a plug-and-play server-side module in our proposed client-centric federated adaptive optimization framework, similarly as how we construct CC-FedAdam. This paper shows the empirical and theoretical properties of three of them, i.e. Adam/AMSGrad/Adagrad."}, {"title": "6.2 Server-Centric Federated Optimization", "content": "As we explained in Section 1, most of the existing federated optimization researches belong to the server-centric FL regime, which naturally distinguish from this paper. We mainly review the works through the lens of how they mitigate statistical heterogeneity, which this paper also considers as a source of the client drift. We refer readers to [76] for a complete survey of federated optimization."}, {"title": "6.3 System Heterogeneity Aware FL", "content": "Existing works that study system heterogeneity can be categorized into the following classes,\n(1) Heterogeneous local computing but synchronous aggregation. [77", "6": "."}]}