{"title": "Mass-Editing Memory with Attention in Transformers: A cross-lingual exploration of knowledge", "authors": ["Daniel Tamayo", "Aitor Gonzalez-Agirre", "Javier Hernando", "Marta Villegas"], "abstract": "Recent research has explored methods for up-dating and modifying factual knowledge in large language models, often focusing on specific multi-layer perceptron blocks. This study expands on this work by examining the effectiveness of existing knowledge editing methods across languages and delving into the role of attention mechanisms in this process. Drawing from the insights gained, we propose Mass-Editing Memory with Attention in Transformers (MEMAT), a method that achieves significant improvements in all metrics while requiring minimal parameter modifications. MEMAT delivers a remarkable 10% increase in magnitude metrics, benefits languages not included in the training data and also demonstrates a high degree of portability. Our code and data are at https://github.com/dtamayo-nlp/MEMAT.", "sections": [{"title": "Introduction", "content": "w Large Language Models (LLMs) based on trans-formers (Vaswani et al., 2017) are designed to predict the probability of tokens occurring in a sentence rather than comprehending the true se-mantics that underlie it. As a result, they are sus-ceptible to generating content that lacks a solid grounding in reality and accuracy. Even when two prompts relate to the same factual association (s,r,) = (Google, CEO, \u00b7); \u201cThe CEO of Google is\" and \"Google's CEO is\", the model lacks an internal constraint that compels it to generate iden-tical answers.\nDifferent investigations have already highlighted the limitations of the models' genuine understand-ing by analyzing its dependency on the dataset patterns (Gururangan et al., 2018; Jia and Liang, 2017). Furthermore, even when these models seem to know the correct answer to a given prompt, they exhibit vulnerability when provided harmful con-text (Halawi et al., 2023).\nIn an initial pursuit of exploring the model's true understanding when using knowledge editors, we analyze Mass-Editing Memory in Transform-ers (MEMIT) (Meng et al., 2023b), a knowledge-editing method asserting its capability to insert up to 10,000 factual associations without heavily in-ducing catastrophic forgetting. Aligned with previ-ous research (Wang et al., 2023a), our first investi-gation involves a cross-lingual examination of the limitations associated with MEMIT.\nAlthough the cross-lingual consistency is depen-dent on the similarity between languages (Qi et al., 2023), our study specifically delves into examin-ing the polyglot capabilities between English and Catalan. In this segment, we construct a transla-tion pipeline to mitigate differences between these languages and proceed to investigate the impact of subject tokenization on knowledge incorporation.\nMotivated by the potential of language-independent knowledge neurons (Chen et al., 2023), and the relevance of the attention mecha-nism in the factual associations domain (Geva et al., 2023), we further our study by exploring a particu-lar part of the attention mechanism: the attention heads. Attention heads have proven to be useful in enhancing the model's reliability under Inference-Time Intervention (ITI) (Li et al., 2023a). The foundational hypothesis behind ITI suggests that attention heads serve as key sources of information for evaluating the truthfulness of models when pre-sented with sentences. Through our experiments, we not only validate the extension of this claim to the domain of factual associations but also ob-serve promising outcomes from a cross-lingual lens. Building on these insights, we propose MEMAT, a method that introduces a novel approach to guide the model towards a better understanding of the edited factual associations.\nThe proposed method demonstrates improve-ment across all evaluation metrics from both cross-lingual and monolingual perspectives, showcasing differences exceeding 10% in some cases. Fur-"}, {"title": "Related Work", "content": "Retrieval Methods. Rather than directly rely-ing in LLMs for specific queries, open-domain question answering systems has historically been driven by the development of algorithms aligning queries with external database sources (Robertson et al., 2009). Recent advancements in aligning retrieval-based methods with LLMs have demon-strated promise in this domain (Karpukhin et al., 2020; Mao et al., 2020; Borgeaud et al., 2022), with retrieval augmented generation (Lewis et al., 2021) showing capabilities in both multimodal (Chen et al., 2022a,b; Yasunaga et al., 2022) and mul-tilingual (Wang et al., 2023b) contexts. However, while the use of external sources avoids the need for fine-tuning, challenges still persist in precisely identifying the relevant context for a given query (Gao et al., 2023).\nTruthfulness. Efforts to enhance the relia-bility of LLMs without depending on external sources have been a focal point of recent research. Aligning LLMs with human feedback has been explored through Reinforcement Learning from Human Feedback (Stiennon et al., 2020; Ouyang et al., 2022) and Direct Preference Optimization (Rafailov et al., 2023), offering valuable insights for veracity alignment (Chen and Li, 2024). Addi-tionally, approaches contrasting hidden representa-tions of these models have also yielded significant results (Li et al., 2022; Chuang et al., 2023) in this direction.\nFactual Knowledge Editors. This research builds upon MEMIT, a method adept at efficiently introducing knowledge by modifying the inter-nal weights of decoder-only architectures, surpass-ing the effectiveness of earlier meta-learning tech-niques like MEND (Mitchell et al., 2022a) and constrained fine-tuning (Zhu et al., 2020). Never-theless, less intrusive alternatives, which selectively modify specific hidden states of the model during inference according to the provided prompt, have also demonstrated remarkable efficacy in knowl-edge editing. Notable examples include REMEDI (Hernandez et al., 2023), GRACE (Hartvigsen et al., 2022), and SERAC (Mitchell et al., 2022b)."}, {"title": "Preliminaries", "content": "3.1 Background\nSince in our experimental setup English and Cata-lan were chosen as the languages for conducting experiments, we opted for the utilization of Aguila-7B, a decoder-only model consisting of 6.85 bil-lion parameters based on Falcon-7B (Penedo et al., 2023). The internal process performed by this ar-chitecture to process text is similar to other decoder-only architectures. It first convert an input to a sequence of N tokens t1, t2, ..., tN by using Byte-level Byte-Pair Encoding (Wang et al., 2020). Then, it process each token by assigning a vector xusing an embedding matrix $E \\in \\mathbb{R}^{|V| \\times d}$, where V denotes the set of vocabulary tokens and d denotes the size of each vector. Following this, the input embeddings undergo a series of L transformer lay-ers, each comprising a Multi-Query Self-Attention (MQSA) sublayer (Shazeer, 2019) and a parallel Multi-Layer Perceptron (MLP) sublayer.\nFollowing the notation proposed in Elhage et al. (2021); Geva et al. (2023), we avoid representing bias terms, layer normalization (Ba et al., 2016), and Rotary Position Embeddings (Su et al., 2023) for simplicity and denote the transformation as:\n$x_i^l = x_i^{l-1} + a_i^l + m_i^l$,\nwhere $a_i^l$ and $m_i^l$ are the outputs from the l-th MQSA and MLP sublayers. In the attention term, for each layer, we assign different projection matrices $W_q^{l,h}$, $W_k^{l,h}$, $W_v^{l,h} \\in \\mathbb{R}^{d \\times d'}$ and $W_o^{l,h} \\in \\mathbb{R}^{d' \\times d}$ for h \u2208 [1, H], l \u2208 [1, L]. Then, given the hidden states of the sentence at layer l denoted as $X^l \\in \\mathbb{R}^{N \\times d}$, we define:\n$A^{l,h} = S\\left(\\frac{(X^{l-1} W_q^{l,h})(X^{l-1} W_k^{l,h})^T}{\\sqrt{d/H}} + M^{l,h}\\right)$,\n$a_i^l = \\sum_{h=1}^H A_i^{l,h} (x^{l-1} W_v^{l,h})W_o^{l,h}$"}, {"title": "Proposed Framework", "content": "3.2 Proposed Framework\nWhile the architecture of large language models is extensively documented, grasping the precise mechanisms that empower them to extract fac-tual information is still matter of research. No-tably, studies have revealed the impact of adjusting MLP layers in the generation of factual associations (Geva et al., 2021; Dai et al., 2022a; Chen et al., 2023). This comprehension has paved the way for the development of frameworks such as ROME (Meng et al., 2023a), PMET (Li et al., 2023b), and MEMIT. In the case of PMET and MEMIT, a sub-set of MLP layers are changed by the introduction of a correction matrix ($W_{out,l} = W_{out,l}+\\Delta_l$) such that:\n$\\begin{aligned}W_{out,l}^* = \\argmin_{W_{out,l}} \\sum_{j=1}^{n} ||k_j^{l-1}W_{out,l} - m_j^l||^2 + \\sum_{j=n+1}^{n+u} ||k_j^{l-1}W_{out,l} - m_j^l||^2\\end{aligned}.$\nwhere n represents the number of factual associ-ations already encoded in the pre-trained model, u represents the number of new factual associa-tions being introduced, each $k^{l-1}$ is taken from the final position of the subject entities of each factual triplet, and the representation of $m^l$ is the one that should be capable of making the model predict the correct factual entity. Refer to Meng et al. (2023b) for more details.\nDespite the notable performance of these pro-posals, recent studies highlight the critical role of attention mechanisms in accurate response genera-tion (Dai et al., 2022b; Yuksekgonul et al., 2023). Specifically, its relevance in factual associations when the attribute extraction is performed (Geva et al., 2023). These findings have already prompted some intervention of attention layers for knowledge editing (Li et al., 2023b; Sakarvadia et al., 2023), a"}, {"title": "Dataset and Evaluation", "content": "4 Dataset and Evaluation\nThe dataset employed in this document is a reduced version of the CounterFact dataset (Meng et al., 2023a,b). For each sample, the relevant prompts utilized in our experiments are:\n1. Efficacy Prompts (EP). Two distinct objects associated with the same (s, r, \u00b7) pair, one cor-responding to the true fact o* and the other representing a false fact o\u00ba.\n2. Paraphrase Prompts (PP). Two prompts that have the same meaning of the (s, r,) pair, but are paraphrased and receive an addition of noise at the beginning. In evaluations, these prompts can also be referred to as indicators of the model's generalization capability.\n3. Neighborhood Prompts (NP). Ten different prompts which contain different subjects (sj \u2260 s) with the same relation (sj, r, \u00b7) that would be true with the object o\u00ba. In evalu-ations, these prompts are referenced as indi-cators of the model's ability to specify the insertion of knowledge.\nAs discussed in Schott et al. (2023), a purifica-tion of the original dataset is necessary to elimi-nate sentences with awkward phrasing, consistent"}, {"title": "Experiments", "content": "5 Experiments\nBefore the introduction of MEMAT, the main as-pects that motivate the use of our method are ex-plained in this section. Firstly, Section 5.1 outlines the scope of our analysis and examines the limita-tions of using only English and Catalan. Our find-ings suggest a correlation between positive cross-lingual outcomes in MEMIT and higher token simi-larity between subject tokens, indicating the depen-dency of our cross-lingual analysis on languages that share subject tokens. Subsequently, in Section 5.2, we evaluate the extent of cross-lingual infor-mation in the hidden representations of words by studying attention heads.\nAs Aguila-7B was not initially assessed using MEMIT, further details on the hyperparameter op-timization of the methods studied can be found in Appendix B.\n5.1 Cross-Linguality\nConsidering the substantial resemblance between the English and Catalan alphabets, we investigate the impact of this similarity on the cross-lingual hypotheses asserted in this paper. Utilizing the Jaccard index, expressed as:\n$J(X_{eng}, X_{cat}) = \\frac{|X_{eng} \\cap X_{cat}|}{|X_{eng} \\cup X_{cat}|}$,\nwe assess the performance disparity when incor-porating factual triplets with distinct subject tok-enizations in English and Catalan ($J(S_{eng}, S_{cat}) \\leq 0.5$), as opposed to those without such differences ($J(S_{eng}, S_{cat}) = 1$). It is pertinent to note that fac-tual associations typically pertain to entities such as institution names, individuals, and series, which tend to maintain consistent tokenization across lan-guages that share the same alphabet. More details of the exact similarity between both datasets can be found in Appendix C."}, {"title": "Locating Knowledge with Heads", "content": "5.2 Locating Knowledge with Heads\nUnder the cross-lingual context outlined in the pre-vious section, we analyze the extent to which the framework of ITI can be useful in the factual knowl-edge domain. Considering that we have the same"}, {"title": "MEMAT Method", "content": "6 MEMAT Method\nIn light of the proven attention heads' relevance, we reinforce the rationale behind equation 6 and present MEMAT as a method that expands upon MEMIT. The overall procedure is depicted in Fig-ure 3, with detailed descriptions for each point as follows:\n(a) Firstly, we modify the model with knowledge associated to a set of factual triplets using MEMIT in language L1, which only edit some"}, {"title": "Scaling Curves", "content": "6.1 Scaling Curves\nConsidering the notable improvement in perfor-mance metrics, we opt to conduct a comprehen-sive comparison of the training evolution between MEMIT and MEMAT in Figure 4. This investiga-tion involves varying the number of inserted sam-ples, with a specific focus on experiments exceed-ing 100 samples. The sample distribution follows the formula $n_i = exp(\\ln(10,000) * \\frac{i}{t})$.\nRecognizing the impracticality of training head corrections with only 100 samples, we opt to opti-mize the head corrections using a subset of 1,000 factual triplets for the combination L\u2081 = L\u2082 ="}, {"title": "Reproducibility", "content": "7 Reproducibility\nThe conducted experiments have been executed on workstations equipped with AMD Radeon In-stinct MI50 GPUs, with 32 GB of memory each. HuggingFace Transformers (Wolf et al., 2020) fa-cilitates the loading of language models, while Py-Torch (Paszke et al., 2019) is employed to imple-ment model editing algorithms on the GPUs. Addi-tionally, the training of sigmoid classifiers is carried out using the Scikit-learn library (Pedregosa et al., 2018) on CPUs.\nIn this specific setup, introducing 1,000 samples"}, {"title": "Conclusions", "content": "8 Conclusions\nIn this study, we examine the cross-lingual impli-cations of knowledge within the domain of knowl-edge editors, identifying two significant patterns. Firstly, the proposed methods heavily rely on sub-ject tokenization. Secondly, our experiments show evidence that attention heads encode information in a certain language-independent manner.\nExpanding our investigation, we introduce MEMAT, a method that, following the applica-tion of MEMIT, fortifies the language model's knowledge through subtle parameter adjustments. We substantiate how the approach introduced is portable and, regardless of the language used dur-ing training, enhances the performance of other languages."}, {"title": "Future Work", "content": "9 Future Work\nOur work emphasizes the limitations of training LLMs with monolingual data. As a future direction, we are interested in further investigating language adaptation techniques to enable these models to perform tasks in a more language-agnostic manner. Additionally, we consider necessary to explore the role that each architecture component play in alternative domains. Recognizing the incomplete understanding of transformer-based models, we assert that prioritizing explainable AI could be es-sential to gain the insights necessary to enhance current state-of-the-art methods. We hope that our study can contribute to inspiring further exploration in this domain."}, {"title": "Limitations", "content": "10 Limitations\nAll hypotheses put forth in this study stem from experiments conducted in English and Catalan. It is essential to recognize that due to the similarity be-tween their alphabet and the phenomena explored in Section 5.1, the generalization of our findings to other linguistic contexts may be limited. Further experimentation involving diverse languages is im-perative to establish the cross-lingual implications of the identified patterns.\nMoreover, despite considerable efforts within the natural language processing community, many challenges related to the reliability of language models still persist. The limitations in knowledge"}, {"title": "Introduction of Both Languages", "content": "H Introduction of Both Languages\nTo incorporate factual associations for both lan-guages using the \u0394 matrices defined in equation 5, we can employ two strategies:\n\u2022 Optimize each factual association concur-rently in English and Catalan, resulting in a single bilingual matrix, \u2206eng+cat.\n\u2022 Optimize two separate matrices for the same factual associations in English and Catalan in-dependently, and then combine them: Aeng + Acat"}, {"title": "ITI performance", "content": "I ITI performance\nITI proposes a method aimed at enhancing the ac-curacy of language models in the generation of truthful information. Firstly, the approach involves identifying the heads responsible for encoding per-tinent information related to the concept of truth, which only differs with the locating procedure out-lined in Section 5.2 in the monolingual framework and the dataset, which is TruthfulQA (Lin et al., 2022). Subsequently, an average of attention heads associated with the final token of truthful sentences is applied to the entire model. While ITI originally used a limited number of sentences, this Appendix study its robustness through an experiment com-prising 1,000 samples.\nThe initial two stages of our experiment replicate the methodology outlined in Section 6. However, instead of optimizing the heads, we average the truthful samples and amplify the strength of the introductions by a factor of \u03b1. This approach yields the results shown in Figure 11. Although these results are subject to high statistical uncertainty, we find the outcomes from the optimization using 12 to be more favorable."}]}