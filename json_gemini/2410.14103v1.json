{"title": "Extreme Precipitation Nowcasting using Multi-Task Latent Diffusion Models", "authors": ["Li Chaorong", "Ling Xudong", "Yang Qiang", "Qin Fengqing", "Huang Yuanyuan"], "abstract": "Deep learning models have made remarkable strides in precipitation prediction, yet they continue to struggle with capturing the spatial details of the features of radar images, particularly over high precipitation intensity areas. This shortcoming is evident in the form of low forecast accuracy in the spatial positioning of radar echo images across varying precipitation intensity regions. To address this challenge, we introduce the multi-task latent diffusion model (MTLDM), a novel approach for precipitation prediction. The basic concept of the MTLDM is based on the understanding that the radar image representing precipitation is the result of multiple factors. Therefore, we adopt a divide-and-conquer approach, that is, we decompose the radar image using decomposition technology and then predict the decomposed sub-images separately. We conceptualize the precipitation image as a composition of various components corresponding to different precipitation intensities. The MTLDM decomposes the precipitation image into these distinct components and employs a dedicated task to predict each one. This method enables spatiotemporally consistent prediction of real-world precipitation areas up to 5-80 min in advance, outperforming existing state-of-the-art techniques across multiple evaluation metrics.", "sections": [{"title": "Introduction", "content": "Short-term precipitation is difficult to forecast accurately due to its rapid formation and dissipation. Short-term forecasts, i.e., 1-2 h in advance, can capture the position of weather systems and predict the range of precipitation in a timely manner, which is crucial for promptly informing the public about the time, location, and intensity of rainfall. However, as global climate change and urbanization accelerate, precipitation patterns are constantly changing, which poses higher demands on precipitation prediction technology. Deep learning models have been shown to have a more powerful predictive performance than numerical weather prediction (NWP) [1][2]. However, as mentioned above, deep learning models still have serious deficiencies in the accuracy of spatiotemporal information prediction, making it difficult for them to meet practical needs. Therefore, researching high-precision forecasting models not only has important scientific value but also has broad application prospects.\nThe inaccuracy of spatiotemporal information prediction is mainly manifested in the blurring of radar echo images generated during the prediction process, which is the result of inadequate convergence during the training process due to imperfect design structures of deep learning models. Moreover, the poor predictive performance of the details of spatial features is reflected in the low critical success index (CSI) of the generated radar echo images. Currently, deep learning models can hardly exceed a CSI of 0.5 under heavy precipitation conditions (>16 mm/h) [1][3]. This situation indicates that deep learning models have significant problems in predicting the detailed features of images and cannot accurately predict precipitation conditions. As the prediction duration increases, the spatial prediction accuracy decreases dramatically. The inaccuracy of long sequence prediction is one of the main problems faced in all current deep learning research. Existing studies and our experiments clearly show that when the prediction duration exceeds 1 h, the CSI indicators for both heavy and light precipitation decrease sharply.\nCurrently, the mainstream generative backbone network is the encoder-decoder (E-D) structure. We can use E-D networks with temporal capture capabilities (UNet and transformer networks) for precipitation prediction. Google uses UNet to predict precipitation [1], but the generated image quality easily suffers from blurring or loss of detail (such as the disappearance of small islands on the map). To improve the performance of spatiotemporal information prediction, Trebing et al. [5] introduced the Self-Attention(SA) into UNet and reduced the number of parameters in convolution-based models. In 2021, Ravuri Name et al. [1] achieved breakthrough performance using generative adversarial networks (GANs) to train a Convolutional Gated Recurrent unit (ConvGRU)-based E-D model (called DGMR) for precipitation prediction. This research attracted widespread attention to the use of deep networks in the field of precipitation prediction (i.e., weather prediction). Ling et al. [6] proposed a nested temporal UNet (TU2Net) that deepens the network hierarchy, significantly improving the quality of the predicted spatiotemporal information compared to the DGMR. Since deep networks are data-driven learning methods and cannot adhere to inherent physical laws, Zhang et al. [3] proposed NowcastNet, a nonlinear nowcasting model for extreme precipitation, which unifies physical evolution schemes and conditional learning methods into an end-to-end E-D network. However, like DGMR, NowcastNet still has low CSI values for heavy rainfall, and the CSI value for heavy precipitation(>64 mm/h) decreases sharply to around 0.1 in the first 30 min.\nThe diffusion probabilistic model (DPM) is a generative model that has emerged in the past two years and has been widely applied in video generation, image segmentation, knowledge reasoning, and other applications [7][8]. It has been proven to outperform GAN models in various application areas. However, literature on applying the DPM to precipitation prediction only began to appear at the end of 2023. Zhihan et al. [9] proposed using the DPM for precipitation prediction, and its CSI value outperforms that of the GAN-based DGMR (both methods use UNet as the backbone network). Zhao et al. [10] combined the transformer with the DPM for precipitation prediction, confirming that the transformer achieves better CSI values than UNet. However, as the DPM has just begun to be applied to weather prediction such as rainfall, there is still significant room for improvement in its predictive performance. For instance, experimental data [10] show that when the precipitation is >3.5 mm/h, the CSI values of all of the methods become very low in heavy precipitation areas, and their average values rarely exceed 0.3.\nTo improve the spatiotemporal accuracy of precipitation prediction, we adopted a hierarchical prediction method that decomposes complex problems, thus breaking down the precipitation image into different components. This approach helps to better understand and predict the detailed situations of rainfall. This decomposition can be achieved through various methods, such as texture-structure-based decomposition [11], low-rank-sparse-based decomposition [12], and statistical method-based decomposition [13]. We investigated the use of a decomposition method based on precipitation intensity thresholds to classify processed precipitation data according to the intensity to obtain precipitation amounts at different intensity levels and analyze the spatial distribution and movement patterns of precipitation at each intensity level. By decomposing the precipitation intensity and precipitation motion characteristic distributions, we treated the decomposed images as subtasks for prediction. This allowed us to more precisely target specific tasks to improve the accuracy of the different precipitation predictions, thereby also improving the CSI.\nIn radar reflectivity precipitation images, different colors or brightness values usually represent different precipitation intensities. Redder areas may indicate a higher precipitation intensity, while bluer areas indicate a lower precipitation intensity or no precipitation. We threshold-decompose the radar image into sub-images with different amounts of rainfall, and each sub-image represents a specific component or feature in the image. When using deep networks for image feature extraction (or calculating model loss), the pixel features of local areas (or the entire) in radar images are computed. When the deep network acts on the features of the radar sub-images, it masks out the interference from elements of other radar sub-images, thus making the features extracted by the model more accurate and also making the network easier to train. This method helps reduce noise and interference, allowing the model to focus more on tasks of different precipitation intensity levels."}, {"title": "Diffusion Probabilistic Models based on Radar Images", "content": "Our model uses the radar image $Y = \\{y_1, \u2026, y_M\\}$ of the first M frames at time S to predict the radar image $X = \\{x_1, \u2026, x_N\\}$ of N. The input radar image sequence is segmented using thresholds and is decomposed into multiple components, each of which is fed into a different diffusion model. Each diffusion model maps the input image to the latent space through an encoder, performs a forward diffusion process, uses a spatiotemporal separable network to generate multiple intermediate latent representations, and finally obtains the final state representation. For each independent diffusion model, the prediction formula is as follows:\n$P (X_i/Y_i) ~P (z_0/Y_i) = \\int P (z_{0:T}/Y_i, \\theta_E, \\theta_D, \\theta_C, \\theta_\\epsilon) dz_{1:T},$\nwhere $\\theta_E, \\theta_D, \\theta_C$, and $\\theta_\\epsilon$ are the parameters of the encoder, decoder, conditional encoder, and denoising backbone network, respectively. $Z_{1:T}$ denotes the latent vectors of the same dimensionality as the data $z_0$. $z_0 = E (X_i)$ encodes the image into the latent space. Then, new images can be generated by sampling representations z from the diffusion model and subsequently decoding them into images using the learned decoder $X_i = D (z_0)$. Four consecutive radar observations are used as the conditions for the dispersion model, i.e., M=4, which allows sampling of multiple realizations of future precipitation. Each realization is 16 frames, i.e., N=16."}, {"title": "Prediction Evaluation", "content": "MRMS dataset: The second dataset comes from the multi-radar multi-sensor (MRMS) dataset for the United States[1]. We use the data for 2020-2021 as the training set and the data for 2022 as the testing set.\nSwedish dataset: This dataset includes radar data from February 6, 2017, to November 12, 2021. We use the data from February 2017 to November 2020 as the training set, and the remaining data are used for validation and testing. This dataset is similar to grayscale images, with values ranging from 0 to 255, where 0 represents no echo, 255 represents no data (indicating a measurement point within radar coverage but with no reported echo), and the areas outside the radar coverage. For both of these datasets, the images used are cropped from the radar stream to a size of 256 x 256 pixels.\nWe compared several models, including the Python framework for short-term ensemble prediction system (PYSTEPS) (a popular machine learning method for precipitation prediction) [14], the DGMR model (a well-known conditional GAN for short-term precipitation prediction) [1], and the timed racing diffusion model (TRDM) (a two-stage diffusion model-based method for precipitation prediction) [15]. The TRDM includes two versions: one that uses a super-resolution diffusion model for prediction in the second stage (called TRDMv1), and another that uses LDM for prediction (called TRDMv2).\nTwo important metrics for evaluating precipitation are used: the CSI [1][16] and the continuous ranked probability score (CRPS) [1][17]. The CSI is a commonly used statistical indicator for evaluating the accuracy of categorical forecasts and is often used to assess the prediction accuracy of weather events such as precipitation, storms, and snowfall. In evaluation, a higher CSI value indicates a higher accuracy of categorical forecasts. In precipitation assessment, the CRPS helps evaluate the consistency between the predicted precipitation probability distribution and the actual observed rainfall. Its advantage is that it considers both the precision and uncertainty of the predictions, making it particularly suitable for evaluating the performances of meteorological models. A smaller CRPS value indicates a better consistency between the predicted probability distribution and the observed values, suggesting a higher prediction accuracy."}, {"title": "CSI Analysis", "content": "According to Ravuri et al. [1], we evaluate our model's predictive ability for precipitation intervals of >1, >4, and >8 mm/h, and we also provide its performance for the 4-8 mm/h interval.  For the precipitation interval of >1 mm/h, the performance of the diffusion model is superior to those of the non-diffusion models, and our proposed MTLDM far outperforms the other methods, including the MTLDM(oa). On average, its CSI is 6% higher than that of the DGMR and 9% higher than that of PYSTEPS. For the >4 mm/h region, the CSI of the MTLDM is about 2% higher on average than those of the DGMR and PYSTEPS. For the heavy precipitation intervals of 4-8 and >8 mm/h, the MTLDM also significantly outperforms the other four methods.  shows the results of the performance comparison of the six precipitation forecast models for forecasting precipitation events with >1, >4, 4-8, and >8 mm/h in the Swedish datasets according to the CSI. The MTLDM model performed the best over the entire forecast period, followed by the MTLDM (oa), which had a similar performance. PYSTEPS and the DGMR performed similarly, with better results in short-term forecasts, but their performances rapidly degraded over time. At the beginning of the forecast, for the MRMS dataset, the maximum CSI differences between the MTLDM and the other models were 0.16, 0.14, 0.12, and 0.05 for the >1, >4, 4-8, and >8 mm/h scenarios, respectively. For the Swedish dataset, these differences were approximately 0.11, 0.15, 0.15, and 0.17, respectively. Although the gap has narrowed over time, the MTLDM still maintained the top position.\nThe traditional PYSTEPS model relies on the robustness of its physical principles to show unique advantages in handling rare events. Especially when predicting extreme precipitation events with intensities of greater than 8 mm/h, its performance exceeds those of most of the deep learning models. This phenomenon highlights the advantages of traditional methods based on physical principles in the face of data sparsity and also reveals the limitations of purely data-driven methods. However, the MTLDM model developed in this study performs well under this challenge. Even under high-intensity precipitation of >8 mm/h, the MTLDM still clearly maintains the top position. This result proves the MTLDM's excellent ability to handle extreme events. The staged decoding idea we propose effectively overcomes the dilemma of a lack of data, allowing the MTLDM to maintain its significant advantages during scarce precipitation events with >8 mm/h."}, {"title": "CRPS Analysis", "content": "The CRPS describes the overall precipitation distribution, so we use the overall forecast radar image to evaluate it, that is, we calculate the index of the MTLDM (oa) (without any ambiguity, we will refer to it as the MTLDM).   show the CRPS values of the radar images at scales of 1, 4, and 16. The image scaling is achieved through pooling operations. The experimental results consistently demonstrate the superiority of the MTLDM, which achieved the lowest CRPS values across all of the pooling scales and prediction ranges. This result highlights the effectiveness of the MTLDM in learning-rich temporal dependencies and generating accurate and well-calibrated probabilistic predictions. The other algorithms (especially the TRDMv2) managed to narrow their performance gaps with that of the MTLDM as the pooling scale increased. Moreover, we observed a general trend of increasing CRPS value over time for all of the algorithms, also demonstrating that prediction becomes increasingly difficult as time progresses. For a pooling scale of 1, the MTLDM's CRPS values are significantly lower than those of the other algorithms at all of the time steps. Specifically, at the 80-minute prediction, the MTLDM's CRPS value is about 0.17, approximately 7% lower than the second-best algorithm (TRDMv2), and about 20% lower than that of the worst-performing algorithm (PYSTEPS). When the pooling scale increases to 4 and 16, although the CRPS values of all of the algorithms generally decrease, the gaps between them also narrow. Considering the time dimension, the CRPS values of all of the algorithms increase as the prediction step length increases, but the rate of increase gradually slows down. This indicates that the spatial shift of the degradation of the algorithm's performance gradually decreases."}, {"title": "Precipitation Events", "content": "To evaluate the prediction effects of the different methods on a precipitation event, we selected the MTLDM and compared it with several other models. Figs. 5 and Fig. 6 show a precipitation event in the SW and MRMS datasets, respectively. To evaluate the prediction effect, we selected two indicators, the CRPS and CSI, and marked the indicator value of each prediction method in the corresponding figures (Figs. 3 and 4), which show the forecast images generated using each method for a 256 km \u00d7 256 km area at T+5, T+15, and up to T+75 minutes. Fig. 3 shows a precipitation event that occurred in Sweden on August 1, 2021, and Fig. 4 shows a precipitation event that occurred in North America on March 15, 2022. To quantitatively evaluate the forecasting effect of each model, we selected two indicators: the CSI indicator with thresholds of 1, 4, and 8 mm/h, and the CRPS indicator. The evaluation results are intuitively displayed below each set of forecast images. It can be seen from the results that the TRDMv1 and TRDMv2 can hardly make effective forecasts for heavy precipitation events of greater than 8 mm/h, while the MTLDM, DMGR, and PYSTEPS can make relatively accurate forecasts for such events. Notably, the forecasting effect of the MTLDM is better than those of the other models at most times. Taking all of the indicators into consideration, the MTLDM model has obvious advantages in predicting these two precipitation events."}, {"title": "Conclusions", "content": "Accurate nowcasting of extreme precipitation is crucial for various weather-dependent decision-making processes, yet it remains a significant challenge. Our multi-task latent diffusion model (MTDM) offers a novel solution to this issue by addressing the limitations of current deep learning models in capturing spatial details in radar images, particularly in high-intensity precipitation areas. By decomposing radar images into sub-images representing different precipitation intensities and predicting each component separately, our approach achieves a superior performance across multiple evaluation metrics, based on a comparison with existing models, and thus can provide spatiotemporally consistent predictions for lead times at which existing methods often falter.\nWhile the MTLDM has shown promising results, particularly in short-term prediction accuracy and consistency, challenges remain in predicting heavy precipitation at longer lead times. As revealed by our evaluations, including meteorological assessments, our approach offers substantial improvements over existing methods, yet the difficulty of accurately forecasting extreme precipitation persists across all approaches.\nFurthermore, our work highlights the limitations of conventional verification metrics, which may not fully capture the operational utility of advanced models such as the MTLDM. This underscores the need to develop new quantitative measurements that better align with real-world applications, ensuring that improvements in predictive performance translate into practical benefits for decision-makers. We hope that our work will serve as a stepping stone for further integration in the fields of machine learning and environmental science, promoting the development of new data, methods, and evaluation techniques that enhance both the predictive accuracy and operational effectiveness in nowcasting of extreme weather events."}]}