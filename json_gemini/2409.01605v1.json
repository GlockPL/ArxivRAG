{"title": "Laser: Parameter-Efficient LLM Bi-Tuning for Sequential Recommendation with Collaborative Information", "authors": ["Xinyu Zhang", "Linmei Hu", "Luhao Zhang", "Dandan Song", "Heyan Huang", "Liqiang Nie"], "abstract": "Sequential recommender systems are essential for discerning user\npreferences from historical interactions and facilitating targeted\nrecommendations. Conventional techniques rely solely on item IDs\nfor sequence modeling, overlooking the wealth of semantic data\nin item descriptions, which can lead to subpar performance. Re-\ncent innovations employing Large Language Models (LLMs) have\nadvanced the field by encoding item semantics, yet they often ne-\ncessitate substantial parameter tuning and are resource-demanding.\nMoreover, these works typically integrate ID-based collaborative\nsignals into LLMs via a simple unified linear projection, which fails\nto consider the diverse characteristics of different types of users\nand thus diminishes the recommendation accuracy.\nIn this paper, we propose a parameter-efficient Large Language\nModel Bi-Tuning framework for sequential recommendation with\ncollaborative information (Laser). Specifically, Bi-Tuning works by\ninserting trainable virtual tokens at both the prefix and suffix of\nthe input sequence and freezing the LLM parameters, thus opti-\nmizing the LLM for the sequential recommendation. In our Laser,\nthe prefix is utilized to incorporate user-item collaborative infor-\nmation and adapt the LLM to the recommendation task, while the\nsuffix converts the output embeddings of the LLM from the lan-\nguage space to the recommendation space for the follow-up item\nrecommendation. Furthermore, to capture the characteristics of dif-\nferent types of users when integrating the collaborative information\nvia the prefix, we introduce M-Former, a lightweight MoE-based\nquerying transformer that uses a set of query experts to integrate\ndiverse user-specific collaborative information encoded by frozen\nID-based sequential recommender systems, significantly improving\nthe accuracy of recommendations.\nExtensive experiments on real-world datasets demonstrate that\nLaser can parameter-efficiently adapt LLMs to effective recom-\nmender systems, significantly outperforming state-of-the-art meth-\nods.", "sections": [{"title": "1 Introduction", "content": "Sequential recommender systems are designed to learn effective\nrepresentations of users' interests based on their past interactions\nand to suggest future items that match users' needs. Due to their\nabilities to capture the dynamic nature of user preferences and\ntheir effectiveness in enhancing user satisfaction, sequential rec-\nommender systems are widely applied in various scenarios such\nas e-commerce, streaming services, and social media platforms\n[7, 11, 27, 54].\nIn traditional sequential recommender systems, items are pre-\ndominantly represented by unique IDs. To obtain effective ID em-\nbeddings based on the user interaction sequence, a variety of meth-\nods are employed, including Markov Chains [9, 32], RNN/CNN\nmodels [11, 20, 34, 46], and self-attentive models [16, 22, 33]. While\nID-based methods are promising in capturing latent associations\nbetween users and items, they fail to consider the rich semantic\ninformation contained in the textual descriptions of items (e.g.,\nitem title), resulting in suboptimal performance. To solve this issue,\nefforts have been made to encode item semantic information with\nlanguage models [12, 21]. However, previous works mainly focus\non small or medium-sized language models, which exhibit limited\nperformance."}, {"title": "2 Problem Formulation", "content": "In the setting of sequential recommendation, we are given a user\nset U and an item set I. Each user $u \\in U$ is associated with a\ntemporally ordered sequence of his/her historical interacted items,\ndenoted as $S_u = {i_1, i_2, ..., i_N}$, where N is the length of $S_u$ and\n$i \\in I$. Based on $S_u$, sequential recommender systems are used to\npredict the next item $i_{N+1}$ that user u is most likely to interact with.\nIn traditional ID-based sequential recommender systems, each\nitem i is associated with a unique item ID $id_i$, and the ID sequence\n$ID_u = {id_{i_1}, id_{i_2}, ..., id_{i_N} }$ is used as input of the model to predict\nthe next item ID $id_{i_{N+1}}$. Differently, in this work, in addition to the\nitem id sequence $ID_u$, we also utilize the semantic information of\nitems, including the attributes such as title, category, and brand.\nFormally, the attributes of an item i can be represented as $D_i =$\n${(k_1, v_1), (k_2, v_2), ..., (k_M, v_M)}$, where k is the attribute name (e.g.,\n\"title\", \"category\", and \u201cbrand\u201d), v is the corresponding value and M is\nthe number of attributes. Given the user interaction sequence $S_u =$\n${i_1, i_2, ..., i_N}$, we use a template to organize the corresponding\nitem attribute sequence $D_u = {D_{i_1}, D_{i_2}, ..., D_{i_N} }$ into a complete\nand coherent text $T_u = {t_1, t_2, ..., t_W}$ (detailed in Section 3.1.1),\nwhere W is the text length. Then, $T_u$ will be taken as the input of\nLLMs for next item prediction."}, {"title": "3 Methodology", "content": "In this section, we detail our proposed Large Language Model Bi-\nTuning framework for sequential recommendation, Laser. As illus-\ntrated in Figure 2, a parameter-efficient LLM Bi-Tuning method is"}, {"title": "3.1 LLM Bi-Tuning for Sequential Recommendation", "content": "In the following, we first describe how to organize the user inter-\naction history $D_u = {D_{i_1}, D_{i_2}, ..., D_{i_N} }$ into a coherent text $T_u =$\n${t_1, t_2, ..., t_W}$, which is taken as the input of LLMs for the sequen-\ntial recommendation, and then introduce how to adapt LLMs for\nthe recommendation task by the proposed parameter-efficient Bi-\nTuning method."}, {"title": "3.1.1 Input Text Formulation", "content": "In this work, we utilize a unified\ntemplate to organize the user interaction history $D_u$ into the input\ntext $T_u$ of LLMs for recommendation. For example, given the user\nwho has browsed \"Kaytee Aspen Bedding Bag\", \"Guitar A-Frame\nSupportS\", and \"KONG Wubba Dog Toy\", we can formulate the\ncorresponding input text $T_u$ as follows.\nWith the designed template, LLMs can follow the instruction in the\ninput text to summarize the user browsing history into a single\ntoken (i.e., the suffix appended to the end of the input text), whose"}, {"title": "3.1.2 Parameter-Efficient Bi-Tuning", "content": "Existing works have shown\nthe powerful capabilities of LLMs in bolstering the sequential recom-\nmendation [1, 2, 51]. However, they still face two main challenges:\n(1) how to adapt LLMs for recommendation tasks in a parameter-\nefficient way, and (2) how to effectively transform the output of\nLLMs from the language space to the recommendation space for the\nfollowing item recommendation. To solve these two challenges, as\nshown in Figure 2, we propose a parameter-efficient LLM Bi-Tuning\nmethod that adapts LLMs through the trainable prefix and suffix.\nFormally, given the input text $T_u = {t_1, t_2, ..., t_W}$, it will be\nexpanded with the trainable prefix and suffix:\n$T_u = {p_1, p_2, ..., p_L, t_1, t_2, ..., t_W, s },$ (1)\nwhere $P = {p_1, p_2, ..., p_L }$ refers to the prefix that contains L prepended\nvirtual tokens, and s refers to the suffix that consists of one sin-\ngle appended virtual token. During model training, we freeze the\nparameters of LLMs and tailor them for the recommendation task\nby optimizing the trainable virtual tokens added at the prefix P\nand suffix s, which greatly reduces the size of the parameters to be\ntrained."}, {"title": "3.1.3 Item Recommendation", "content": "Given the obtained user embedding\n$h_u \\in R^d$ and the item embedding $h_i \\in R^d$ from the LLM, we can\ncompute the similarity between them as follows:\n$s(u, i) = cos(h_u, h_i) = \\frac{h_u \\cdot h_i}{||h_u||||h_i||}$ (3)\nwhere s(u, i) \u2208 R indicates the probability that the item i will\nbecome the next item browsed by user u. To predict the next item,\nwe iterate through each item i in the item set I, and select the item\ni with the highest score as the next item:\n$i = argmax_{i \\in I} (s(u, i))$ . (4)"}, {"title": "3.2 M-Former based Collaborative Information Integration", "content": "In the proposed LLM Bi-Tuning, we use the trainable prefix P and\nsuffix s to adapt the LLM for recommendation. In order to achieve\nbetter recommendation results, we incorporate the collaborative in-\nformation via the prefix P. Existing works have tried to use unified\nlinear layers to project the collaborative embeddings encoded by\nID-based sequential recommender systems into the language space\nof LLMs [45, 53]. However, this method is too simple to detect the\ndiverse characteristics of different types of users [25, 48]. To deal"}, {"title": "3.2.1 Mixture of Experts", "content": "As shown in Figure 2, there are K query\nexperts dealing with users of different types, each of which con-\ntains L trainable virtual tokens. In order to select the most ap-\npropriate expert to deal with user-specific collaborative informa-\ntion, we set up a router to calculate the scores of different experts\ngiven the specific user. Formally, given the user interaction history\n$S_u = {i_1, i_2, ..., i_N}$ of user u, the corresponding item ID sequence\n$ID_u = {id_{i_1}, id_{i_2}, ..., id_{i_N} }$ is taken as input of a pre-trained ID-\nbased sequential recommender system (frozen) and encoded as\n$C_u \\in R^{N \\times d_i}$, where N represents the length of the interaction\nhistory $S_u$ and $d_i$ represents the hidden size of the sequential rec-\nommender system. Then, $C_u$ is sent into the router, which is imple-\nmented with a fully-connected layer in this work. The matching\ndegree of the K query experts according to the N user-interactive\nitems embedded as $C_u$ can be calculated as:\n$m(u) = C_u W$, (5)\nwhere $W \\in R^{K \\times d_i}$ is the router's linear weight, and $m(u) \\in R^{N \\times K}$.\nThen, he i-th item's score for the j-th expert can be calculated as:\n$p_{i,j} (u) = \\frac{e^{m_{i,j}(u)}}{\\sum_{z=1}^{K} e^{m_{i,z} (u)}}$, (6)\nand the final score of the j-th query expert can be obtained by:\n$r_j(u) = \\frac{\\sum_{i=1}^N p_{i,j} (u)}{N}$ (7)\nFinally, the query expert with the highest score will be selected to\ndeal with the specific user u."}, {"title": "3.2.2 MoE-based Querying Transformer", "content": "As described above, we\nobtain the most appropriate query expert to handle the specific\nuser's collaborative information $C_u$. Afterward, as shown in Figure\n2, the selected query expert containing L virtual tokens is sequen-\ntially fed into Z transformer blocks to interact with the collaborative\ninformation $C_u$. In this way, the query expert integrates the collabo-\nrative information into its L trainable virtual tokens, which further\nact as the aforementioned prefix $P = {p_1, p_2, ..., p_L }$ to adapt LLMs\nfor the sequential recommendation.\nFormally, the query expert can be represented as $E \\in R^{L \\times d_m}$,\nwhere $d_m$ is the hidden size of the M-Former. In the transformer\nblock, E is first encoded by a self-attention layer and then projected\nto the query matrix Q used in the cross-attention layer to interact\nwith the key/value matrix (K/V) projected from the ID-based collab-\norative embeddings $C_u$. In this way, we update the query expert's\nembedding E and integrate ID-based collaborative information into\nit. Then, through a linear projection layer set up on the top of the\nZ transformer blocks, the query expert is projected into the LLM's"}, {"title": "3.3 Model Learning", "content": "In this work, we employ a multi-task training strategy to train our\nLaser, which takes into account both the recommendation goal\nand the load balancing goal of the MoE experts. Furthermore, we\nperform a two-stage training by first finding the most appropriate\nparameter weights to obtain high-quality item embeddings used for\nuser-item similarity comparison, and then further training Laser\nbased on these fixed item embeddings to achieve the best recom-\nmendation results."}, {"title": "3.3.1 Loss Function", "content": "We propose a multi-task training strategy to\njointly train the proposed Laser for LLM-based sequential recom-\nmendation.\nThe first training task is the item-item contrastive (IIC) task,\nwhich is widely employed for next item prediction. Following pre-\nvious work [21], we use the ground-truth next item as the positive\ninstance and all other items in the item set I as negative instances.\nFormally, the item-item contrastive loss is calculated as:\n$L_{IIC} = - log \\frac{e^{cos(h_u, h_+)/\\tau}}{\\sum_{i \\in I} e^{cos(h_u, h_i)/\\tau}},$ (8)\nwhere the calculation of $cos (h_u, h_i)$ is consistent with Equation (3),\n$h_+$ represents the embedding of the ground-trouth next item, and \u03c4\nis a temperature hyper-parameter.\nThe second training task is the load balancing task, which is used\nto encourage a balanced load across different query experts of the\nM-Former. As proven by previous works [6, 17], this task can force\nthe router to assign users with diverse collaborative characteristics\nto different query experts, such that each expert can be trained to\nobtain the best collaborative information integration effectiveness\nfor its group of users. Formally, the load balancing loss is calculated\nas:\n$L_{LB} = K \\cdot \\sum_{j=1}^{K} f_j \\cdot P_j,$ (9)\nwhere K is the number of query experts, $f_j$ represents the fraction\nof items dispatched to the j-th expert that can be calculated as:\n$f_j = \\frac{1}{N} \\sum_{i=1}^{N} 1 \\{argmax \\, p_i(u) = j \\},$ (10)\nwhere N is the number of items in the user interaction history,\np(u) \u2208 $R^{N\u00d7K}$ is the score matrix obtained through Equation (6),\nwhich represents the degree of correlation between the N items and\nthe K query experts. The $P_j$ in Equation (9) represents the fraction\nof the router probability allocated for the j-th expert, which can be\ncalculated as:\n$P_j = \\frac{\\sum_{i=1}^N P_{i,j} (u)}{N}$. (11)\nTotally, the loss function we use in this work is:\n$L = L_{IIC} + \\lambda \\cdot L_{LB},$ (12)\nwhere \u03bb is a hyper-parameter that controls the weight of different\ntasks."}, {"title": "3.3.2 Two-Stage Training", "content": "In this work, the recommendation is\nconducted based on the user-item embedding similarity compari-\nson. Since the item embedding is determined by the corresponding\ntrainable suffix, which changes after different training epochs. We\nemploy a two-stage training strategy to first find the most appro-\npriate parameter weights to obtain high-quality item embeddings,\nand then further train Laser based on these fixed item embeddings\nto achieve the best recommendation results.\nSpecifically, in the first training stage, at the beginning of each\nepoch, the item embeddings are updated as $I \\in R^{|I| \\times d}$ using the\ncurrent parameter weights \u039b. Then, Laser is trained on I and val-\nidated at the end of the epoch based on the updated parameter\nweights \u039b'. At the end of the first training stage, the embeddings \u00ce\nand the corresponding parameter weights \u00c2' of the best-performing\nepoch are selected for the second training stage. In the second train-"}]}