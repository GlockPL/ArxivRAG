{"title": "INTERACTIVE SPECULATIVE PLANNING: ENHANCE AGENT EFFICIENCY THROUGH CO-DESIGN OF SYSTEM AND USER INTERFACE", "authors": ["Wenyue Hua", "Mengting Wan", "Shashank Vadrevu", "Ryan Nadel", "Yongfeng Zhang", "Chi Wang"], "abstract": "Agents, as user-centric tools, are increasingly deployed for human task delegation, assisting with a broad spectrum of requests by generating thoughts, engaging with user proxies, and producing action plans. However, agents based on large language models (LLMs) often face substantial planning latency due to two primary factors: the efficiency limitations of the underlying LLMs due to their large size and high demand, and the structural complexity of the agents due to the extensive generation of intermediate thoughts to produce the final output. Given that inefficiency in service provision can undermine the value of automation for users, this paper presents a human-centered efficient agent planning method \u2013 Interactive Speculative Planning \u2013 aiming at enhancing the efficiency of agent planning through both system design and human-AI interaction. Our approach advocates for the co-design of the agent system and user interface, underscoring the importance of an agent system that can fluidly manage user interactions and interruptions. By integrating human interruptions as a fundamental component of the system, we not only make it more user-centric but also expedite the entire process by leveraging human-in-the-loop interactions to provide accurate intermediate steps. Code and data will be released.", "sections": [{"title": "1 INTRODUCTION", "content": "Large language models (LLMs) have demonstrated strong reasoning abilities (Zhang et al., 2024c; Qiao et al., 2022; Fan et al., 2023; 2024; Jin et al., 2024), enabling them to plan and interact with external tools and the real world. This has led to the development of LLM-based agents, which have become popular as task solvers and human assistants. Various agent frameworks have been created to facilitate these applications, including single-agent systems such as Langchain (Topsakal & Akinci, 2023), OpenAGI (Ge et al., 2024), and HuggingGPT (Shen et al., 2024), as well as multi-agent systems like AutoGen (Wu et al., 2023), MetaGPT (Hong et al., 2023), BabyAGI (Nakajima, 2023), and Camel (Li et al., 2023). Numerous methods have also been proposed to enhance the performance of LLM-based agents, ranging from chain-of-thought (Wei et al., 2022), tree-of-thought (Yao et al., 2024), ReAct (Yao et al., 2022), Reflexion (Shinn et al., 2024), to multi-agent discussion (Chan et al., 2023) systems.\nHowever, these high-performing advancements in agents often come at the expense of time efficiency (Zhou et al., 2024; Ding et al., 2024b; Zhang et al., 2024b), which can be attributed to three main reasons: (1) the underlying backbone language model can be inefficient due to its increasingly large size and high request volume, (2) the complex agent structure, such as tree-of-thought and ReAct, which requires generating prolonged thought before the final answer, leading to extended waiting time and increased token generation costs, and (3) the sequential nature of action steps in plans, where one action must be completed before the next can begin. But notice that not all steps in agent planning necessitate computationally intensive thought processes, making the universal application of complex agent architectures or agents with advanced backbone LLMs inefficient.\nMoreover, latency is a critical factor for user experience. Many studies (Horvitz, 1999; Barron et al., 2004; Simpson et al., 2007; Carr et al., 1992) have demonstrated the physiological and psychological impacts from interaction delays during human-computer interaction on users. While agents are designed to assist users, few designers have prioritized user experience, which should be of high importance. In addition, numerous studies have discussed the role of automation in human-computer interaction (Lubars & Tan, 2019; Hemmer et al., 2023), highlighting a low preference for full AI control in task delegation and a strong preference for machine-in-the-loop or human-in-the-loop designs where humans maintain a central role. Thus, a fully automated agent system with long intermediate delays is suboptimal for user experience, a feature that is, however, prevalent in most LLM-based agent systems today.\nTherefore, this work aims to address the latency issue from both aspects of system design and human interaction by introducing an interactive efficient planning algorithm, representing the first system for agent latency efficiency and management of human interactions and interruptions: Interactive Speculative Planning. This approach seamlessly integrates temporal efficiency and human-in-the-loop interaction, anticipating user engagement during periods of long latency. By treating user input as intermediate results, the system accelerates the overall process, thereby enhancing both temporal efficiency and user experience. Consequently, this system offers a more user-centric and efficient solution for agents as human delegates.\nThe system-level algorithm is speculative planning, which is inspired by speculative decoding (Leviathan et al., 2023; Liu et al., 2023a; Chen et al., 2023; Spector & Re, 2023; Liu et al., 2024; Cai et al., 2024). It leverages two agent systems: an efficient but less capable approximation agent, and a slower but more powerful target agent. For each task, the approximation agent generates action steps sequentially. Simultaneously, for every step the approximation agent produces, the target agent is asynchronously called to generate the next step, using the current trajectory from the approximation agent as a provisional prefix. In this process, the calls to the approximation agent are sequential, while those to the target agent are asynchronous. For each action step, if the outputs of the approximation agent and the target agent match, the process continues. However, if there is a mismatch, the approximation agent is halted, and its output is replaced by the target agent's output to ensure performance is not compromised. Figure 2 presents the process.\nThis strategy potentially reduces the time a target agent takes for to complete the task to that of the approximation agent, thereby enhancing time efficiency. It should be noted that while we consider a single user interface of the agent system, the system backend can be built with various architectures, including a multi-agent design.\nNote that under the speculative planning algorithm, target agent calls are asynchronous, leading to non-sequential outputs. To facilitate user interaction, we design a UI-level rescheduling algorithm (Oh et al., 2024; Cheng et al., 2024; Mei et al., 2024; Jawahar et al., 2023; Srivatsa et al., 2024) that presents both the approximation agent's results and the target agent's results sequentially and clearly, as illustrated in Figure 3. The sequential presentation of the outputs enables users to accurately perceive the computation latency imposed by the target agent. Consequently, users may intervene in the process at their discretion, such as when a computation step is prolonged or yields erroneous results. This approach differs from traditional speculative decoding, where an algorithm judges whether to accept the results from an approximation agent, often based on probability distributions. In contrast, Interactive Speculative Planning enables active human engagement in the decision-making process, allowing them to interrupt lengthy processes and evaluate whether to accept or complement the algorithm's results. This human-in-the-loop approach makes the system user-centric and efficient.\nIn summary, with active user intervention, Interactive Speculative Planning can be viewed as an interactive framework involving three agents: the approximation agent, the target agent and the human agent. These three agents collaborate and interleave their operations to collectively accelerate the overall agent planning process."}, {"title": "2 RELATED WORK", "content": "Various agent systems (Xi et al., 2023; Liu et al., 2023b; Ge et al., 2023) have been developed, including single agent such as Hugginggpt (Shen et al., 2024), OpenAGI (Ge et al., 2024), and BabyAGI (Nakajima, 2023), and multi-agent systems (Du et al., 2023) such as AutoGen (Wu et al., 2023; Zhang et al., 2024a) and Camel (Li et al., 2023), based on the strong reasoning ability (Wu et al., 2024; Zhang et al., 2023b) and common sense knowledge (Kwon et al., 2024) encoded in LLMs. To improve the performance of LLM-based agents, various methods have been proposed. The most basic approach is the chain-of-thought (Wei et al., 2022), where the LLM generates a step-by-step thought process for each action. More advanced methods include ReAct (Yao et al., 2022), where the agent thinks before acting, and Reflexion (Shinn et al., 2024), where the agent thinks, acts, and reflects on its decisions. The tree-of-thoughts (Yao et al., 2024) method involves the agent thinking several steps ahead before acting. In addition, multi-agent discussion systems (Du et al., 2023; Hua et al., 2023; Lin et al., 2024; Wu et al., 2023) have been developed in which multiple agents discuss and debate to improve performance. In general, it is observed that stronger backbone models and more complex multi-LLM interaction usually lead to better agents (Wang et al., 2024; Li et al., 2024; Chen et al., 2024).\nHowever, these improvements in agent performance often come at the expense of time efficiency, as longer thought processes result in extended waiting times. Although the agent task can be intricate and sometimes only the most powerful models may be capable of executing them effectively as suggested by (Xie et al., 2024), not all steps within a task are equally challenging to plan and generate (Zhang et al., 2023a; Saha et al., 2024). Therefore, a dynamic selection of appropriate LLMs for specific tasks can be a viable strategy to balance performance and efficiency/cost.\nNumerous methods have been developed to enhance either cost or time efficiency (Zhang et al., 2023a; Ding et al., 2024a; Saha et al., 2024). EcoAssistant (Zhang et al., 2023a) is the first system aimed at cost-efficient agents, initiating tasks with the most economical agent and switching to more capable and expensive agents only upon failure of the cheaper alternative. The System-1.x Planner (Saha et al., 2024) introduced a controllable planning framework using language models, capable of generating hybrid plans and balancing between complex and simple agent planning strategies based on problem difficulty, potentially offering both time and cost efficiency. However, the System-1.x Planner is limited to specific planning strategies and requires extensive training. In contrast, our proposed Interactive Speculative Planning can adopt any combination of approximation and target agent in a training-free manner, guaranteeing performance that is at least equivalent to, and potentially superior to (with user interventions) that of the target agent alone."}, {"title": "3 INTERACTIVE SPECULATIVE PLANNING", "content": "Interactive Speculative Planning is a collaborative framework that enhances the efficiency and accuracy of agent planning by integrating the efforts of three agents: the approximation agent, the target agent and the human agent. The approximation agent generates quick but potentially inaccurate steps, while the target agent verifies and refines these steps. The human agent intervenes to correct or optimize the latency of the planning process, ensuring that the final plan meets user expectations. This interactive approach accelerates the overall planning process and improves user experience by reducing latency and allowing for real-time adjustments.\nIn this section, we delves into the algorithm: Section 3.1 introduces speculative planning and Section 3.2 introduces what user interactions are expected and how the system incorporates user interactions. Let us denote the approximation agent by A and the target agent by T."}, {"title": "3.1 SPECULATIVE PLANNING", "content": "The core concept of how time is saved by speculative planning is to expedite agent planning by employing a fast and efficient approximation agent A to resolve the task sequentially. For every length-i prefix of the step generated by A, both A and T are run simultaneously to generate the i + 1th step based on A's action history, without waiting for T to finish the ith step. If the ith step of the plan generated by both agents matches after T finishes it, then the more efficient but less capable agent A is deemed to have correctly computed the step, and T's i + 1th step computed based on it is usable. Time is thus saved because the time for T to compute steps i and i + 1 is reduced to the time taken by A to compute step i and T to compute step i+1. However, if there is a mismatch, it implies that A has erred at the ith step, and its output is replaced with T's result. Furthermore, all concurrent calls of A and T with prefixes longer than i must be halted and discarded, as they are based on an incorrect prefix and their results are unusable. In short, this algorithm achieves time savings by having T utilize the result generated by the fast A as a prefix to generate the next step, rather than waiting for prefix steps from the slower T to be completed.\nThis algorithm achieves time savings by having T utilizes the result generated by the fast A as a prefix to generate the next step, rather than waiting for prefix steps from the slower T to be completed. An example comparison of the time taken to generate the first two steps of a task using speculative planning and normal agent planning is illustrated in Figure 4:\nFigure 2 presents a scenario where one person with their friends A, B, C went to a restaurant and they paid the bill, and now they need to split the money with their friends. When initiating speculative planning, both A and T are started simultaneously to generate the first step. Upon A's completion of the first step (\u201csplit money\u201d), both agents are called again simultaneously, utilizing \u201csplit money\" as the current action trajectory to generate next step. This process is repeated for subsequent steps. Once T completes its first call, generating the first step (\u201csplit money\u201d), the correctness of A's first step can be confirmed. Since the first step is correct, the second step from A is potentially correct waiting to be confirmed by the second step from T, which is definitively usable. However, if A's output mismatches with T's output, all subsequent steps are deemed incorrect. In this example, T completes its second call (\u201cverify A's Venmo\") before the first call which verifies the second step from A to be incorrect (\u201crequest money from A\u201d). Consequently, all subsequent steps based on the action trajectory containing the second step are rendered useless. This includes the third call of T and the third step of A and so on.\nTo prevent an excessive number of concurrent target agent processes, the Interactive Speculative Planning algorithm introduces a hyperparameter k. This parameter sets a limit on the maximum number of steps that A that can sequentially propose and being executed before all corresponding target agent processes are completed. By controlling the value of k, users can flexibly manage the maximum number of concurrent target agent processes. A very simplified version of the speculative planning algorithm is presented in Algorithm 1:\""}, {"title": "3.2 UI INTERACTION ALGORITHM", "content": "Now we present the interaction component of Interactive Speculative Planning. The user interface (UI) serves a two-fold goal: (1) from the aspect of perception, it aims to provide the user with an easy-to-follow result and a basic understanding of the algorithm's inner workings, allowing the user to see T's computation time for each step and how A is saving time; (2) from the aspect of interaction, it aims to provide system support for the user to actively interact with or interrupt the ongoing agent processes when T is taking too long for a step or neither A nor T provides a satisfying step proposal during generation. Therefore, the UI interface, together with the underlying system mechanism design, primarily addresses two key aspects: (1) what the users should see and (2) how the system can handle user interactions.\nFor the first goal, notice that immediately printing the outputs of A and T upon generation can be very confusing for two reasons: (1) some outputs of A and T should not be shown to the user at all, and (2) the outputs of T are misordered. Figure 5 presents an example scenario for the two issue. For issue 1: A's output on the second step of the plan mismatches with T's output, and thus all results generated by A based on the mistaken \u201cstep 2\" will ultimately be discarded. However, an immediate output of the agent's generation will present A's computed steps \"step 3, 4, 5\" and T's computed steps \u201cstep 3, 4\u201d which are generated based on the wrong prefix. For issue 2: as all T's calls are asynchronous, the time for each step to finish will not follow a sequential order, and thus an immediate printing out of the generated output will not be sequential either. Therefore, a rescheduling mechanism is needed to provide a clear presentation of the algorithm.\nTo ensure an understandable user interface to track the agents' progress and facilitate user intervention, the presented output is rescheduled by a Reschedule Mechanism. This mechanism allows the user to view verified and to-be-verified computed steps of A and T with minimal perceived latency. The Reschedule Mechanism, shown in Algorithm 2, takes the queue of A processes and the queue of T processes as input, tracing the last printed out message from either A and T, and then decide which message to present next to the user: (1) it presents the ith step from A only after all preceding steps from A have been confirmed to be consistent with T, ensuring that no steps computed based on unverified prefixes are presented (2) it presents the ith step from T only after all preceding steps from T have been presented, ensuring a sequential order. This design not only ensures a sequential presentation but also highlights the time difference between A and T, allowing the user to identify which action is bottlenecking the program.\nFor the second goal, we enable users to actively interrupt the program at any time. Unlike current user interface designs in various agent systems (Wu et al., 2023) where users are allowed to interact with the system when being passively prompted to input information or opinions, we believe that users are more inclined to actively engage in the agent task delegation process (Lubars & Tan, 2019). We handle user interaction in two common scenarios: (1) when noticing excessive perceived latency between the last presented output of A and the next output of T (assuming A's generation speed is sufficiently fast that users would not typically interrupt it), and (2) when dissatisfied with the outputs of T for a given step.\nFor the first scenario, since the UI interface presentation for the i-th step of the plan can indicate the latency li between the presentation of the i-th approximation output ai computed by i-th process of A and the i-th target output t\u2081 computed by i-th process of T, users can choose to interrupt during the time of li and input their own value. The underlying system will handle this keyboard interruption by halting the i-th process of T, incorporating the user's input into the agent action trajectory, while allowing all other concurrent processes to continue. Figure 6 demonstrates an example where the user interrupts the process after the presentation of a\u2081 due to excessive waiting time for t\u2081.\nIn the second scenario, users are able to interrupt the program if they deem the results from T unsatisfactory for a given step. During the brief presentation of the output ti for any step i, users can intervene and input their preferred optimal step for step i as an oracle. Additional user interruption features, such as handling user suggestions instead of oracle results, or backtracking to previous steps rather than focusing on the current step, are potential avenues for future research.\""}, {"title": "4 EFFICIENCY ANALYSIS", "content": "In this section, we will provide a theoretical analysis of the time savings (latency), total token generation requirement, and concurrent API call rate required by the speculative planning approach. Additionally, we will present simulated experiment results to support our analysis and demonstrate the effectiveness of the proposed method."}, {"title": "4.1 LATENCY ANALYSIS", "content": "This subsection analyzes the latency improvement brought by the speculative planning algorithm. We summarize the notations in Notation Summary 1.\nWhen we do not utilize speculative planning, the time taken to generate and execute the whole plan is $\\Sigma_{i<n}(time(T, s_i) + e(s_i))$. To compute the time when employing speculative planning, we first define the list of breaking steps B, which consists of indices i of steps s in the plan where the sequential generation of A is halted, i.e. when A's prediction $a_i = A(i)$ differs from T's prediction"}, {"title": "4.2 TOTAL TOKEN REQUIRED", "content": "In this subsection, we analyze the total token generation when using the speculative planning algorithm.\nWhen not utilizing speculative planning, the total number of tokens used to generate and execute the plan is $\\Sigma_{i<ntoken(T, s_i)}$. Speculative planning requires more tokens, as both A and T go through the entire plan at least once, potentially generating \"wasted\" tokens \u2013 proposed steps that are not"}, {"title": "4.3 RATE REQUIRED", "content": "This subsection focuses on analyzing the rate required to run the speculative planning algorithm, which is determined by the maximum number of concurrently running agent calls.\nWhen not utilizing speculative planning, all agent calls are executed sequentially. Consequently, the required rate, which is the maximum number of concurrently running agent calls, is 1. When using speculative planning, we naturally have at least 2 concurrent calls: 1 for A and 1 for T. But it can be more than 2, as shown in Figure 2 where we can have many T processes running at the same moment. To determine the maximum concurrent C processes, we identify the target agent process that overlaps with the most other target processes and add 1 for the additional approximation process. For all $T_i$ processes for $B_i < l < B_{i+1}$, we find the j-th process $T_j$ that overlaps with the most other T processes by:\n$T_i = \\underset{B_i<j<B_{i+1}}{max} |\\{l < n | start\\_time(T, s_l) \\leq start\\_time(T, s_j) < end\\_time(T, s_l)\\}|$"}, {"title": "4.4 SIMULATION EXPERIMENT FOR SPECULATIVE PLANNING", "content": "To elucidate the relationship between the performance of the Interactive Speculative Planning system and various hyperparameter configurations, we conducted three series of simulation experiments. Two experiments aimed to investigate the impact of different settings in speculative planning, specifically: (1) the choice of approximation agent A, (2) the parameter k; and the third experiment investigates the impact of the number of user interruptions on overall latency. For the impact of A, we examined A's accuracy relative to that of T (accuracy computed by treating T's result as ground truth), as well as A's computational speed. In the rest of the paper, we use A's accuracy to refer to the relative accuracy of A with respect to the result of T.\nFor the simulation experiments, we set the following parameters unchanged: (1) the plan consists of 10 steps, (2) the generation speed of T is 8 seconds per action (time(T, s) = 8) (3) for each step, A generates 10 tokens (time(T, s) = 10), (4) for each step, T generates 20 tokens (time(T, s) = 20), and (5) for clarity, we set execution time to be 0 (e(s) = 0).\nThe first series of experiments explores the impact of A's accuracy with respect to T and the hyperparameter of k planning time and total tokens generated. We fix the speed of A (time(A, s) = 2) to be 2 seconds per action and vary A's accuracy in 0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0} and the hyperparameter of k in {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}.\nFigure 9 (a) provides a visual representation of the impact of accuracy and the hyperparameter k on the planning time. For each pair of accuracy and k, we run 10 experiments with different random seeds. The mean time and standard deviation of the average step are plotted in the figure, providing a comprehensive view of how these factors influence the planning time. We also present the time required for the agent planning when using A only and T only as in normal agent planning to show the lower bound and upper bound of speculative planning.\nIt is evident that higher accuracy in A results in shorter planning time. Very low k (such as k = 1,2,3) leads to slower agent planning, regardless of A's accuracy. For other k values, as the accuracy increases, the impact of k becomes more clear: higher k leads to shorter agent planning time. However, when the accuracy is low, the impact is less clear.\nIn the third series of experiments, we investigate the impact of user interruptions on time efficiency. We conduct simulations with varying interruption times. We assume that the user is actively monitoring the agent planning process and has a patience level between the speeds of the approximation agent A and the target agent T, which assumption is made based on (1) A is designed to be an efficient agent (2) if the user's patience exceeds the speed of T, no interruptions would occur.\nFor this simulation experiment, we set k = n = 10 and the accuracy of A to be 0.5. The user is permitted to interrupt between 0 and 10 times. Each user interruption may occur randomly after waiting periods ranging from 1 to 5 seconds following the presentation of A's result. For each number of user interruptions, we conduct 5 simulations.\nThe results of this simulation are presented in Figure 12, which displays the mean stepwise generation time along with the standard deviation. As anticipated, an increase in user interruptions reduces the overall latency of the system."}, {"title": "5 EXPERIMENT", "content": "This section presents the results on two agent planning benchmarks: OpenAGI (Ge et al., 2024) and TravelPlanner validation (Xie et al., 2024). For each benchmark, we attempt to implement four settings. We will briefly introduce the benchmarks and the settings in the below two subsections."}, {"title": "5.1 BENCHMARKS", "content": "OpenAGI is a benchmark designed for agent planning with complex tasks, built on computer vision and natural language processing-related tasks. Tools accessible to the agents include \"Sentiment Analysis\"Machine Translation\"Object Detection\"Visual Question Answering,,\" etc. An example task in the benchmark is \u201cRestore noisy, low-resolution, blurry, and grayscale images to regular images,\u201d whose solution is a sequence of tool usage: \"Image Super-resolution, Image Denoising, Image Deblurring, Colorization.\" This benchmark contains 117 multi-step tasks.\nTravelPlanner is a planning benchmark that focuses on travel planning. It provides a rich sandbox environment, various tools for accessing nearly four million data records, and meticulously curated planning intents and reference plans. These plans also involve many constraints, including budget constraints, environmental constraints, etc. An example task is \"Please plan a travel itinerary for me. I'm departing from Cincinnati and heading to Norfolk for three days. The dates of travel are from March 10th to March 12th, 2022. I have a budget of $1,400 for this trip.\" whose solution contains a sequence of actions such as \"FlightSearch[Cincinnati, Norfolk, 2023-03-12]\" where \"FlightSearch\" is the function name while \"Cincinnati, Norfolk, 2023-03-12\" are the natural language free-form parameters."}, {"title": "5.2 SPECULATIVE PLANNING SETTINGS", "content": "To experiment with Interactive Speculative Planning in real-life scenarios, we demonstrate the performance using four different settings: four different combinations of the approximation agent A and the target agent T.\nSetting 1 A employs direct-generation-based planning with a GPT-4-turbo backbone, while T utilizes ReAct-based planning (Yao et al., 2022) with the same backbone. For each step in the plan, Tuses ReAct to first deliberate on the action and then generate it through two separate API calls, whereas A directly generates the action for that step.\nSetting 2 A uses direct-generation-based planning with a GPT-4-turbo backbone, and T employs chain-of-thought (CoT)-based planning with the same backbone. For each step in the plan, Tuses CoT to first reason and then generate the result in a single API call, while A directly generates the action for that step.\nSetting 3 A uses CoT-based planning with a GPT-4-turbo backbone, and T system uses multi-agent-debate (MAD) including 2 agents with 2 rounds of discussion on every step of the plan with a GPT-4-turbo backbone. For each step in the plan, T system has two agents discuss with each other and finalize the action to take for the current step, and the while A uses CoT to first reason and then generate the result in a single API call for the step.\nSetting 4 A uses direct-generation-based planning (DG) with a GPT-3.5-turbo backbone, and T uses direct-generation-based planning with a GPT-4-turbo backbone. In this setting, both A and T directly generate the result for each step. Notice that we cannot provide results for TravelPlanner in this setting, as direction generation using GPT-3.5-turbo fail to provide a valid action in many cases.\nIn all experiments, we set k = 4. We utilized one OpenAI API for experiments under Settings 1, 2, and 4, and two OpenAI APIs (one API for each agent in the multi-agent system) for experiments under Setting 3.\nFor the OpenAGI benchmark, given its limited action space, we used exact match to verify the correctness of the output generated by A against the output of T. This ensured that the output of the speculative planning is the same as that of normal agent planning. For the TravelPlanner benchmark, which contains a much larger action space, each action is a combination of a function name from a fixed set and natural language free-form parameters. We verified the consistency between the output of A and the output of T based on an exact match of the function name and a soft match of the natural language parameters. The soft match is implemented by computing the Levenshtein distance: if the function name matched and the Levenshtein distance is smaller than 0.3, then the action is verified. As we leverage soft match to verify the output of A, it is not guaranteed that the result from speculative planning remains the same as the result from normal agent planning and therefore we also provide the performance result of normal agent planning and speculative agent planning. Details in Appendix7."}, {"title": "5.3 EVALUATION METRICS", "content": "In terms of latency, we report the average and minimum total generation time, as well as the stepwise generation time, for all planning tasks across each benchmark and experimental setting, compared with the normal planning setting. It is important to note that the total generation time heavily depends on the number of steps in the plan, which can be influenced by randomness. Therefore, we also report the stepwise generation time, which mitigates the effect of randomness related to the number of steps. To provide a comprehensive understanding of the algorithm, we also include metrics related to the total number of tokens generated during the process and the total API cost.\nTherefore, in total there are 11 metrics: (1) total time (TT), (2) the minimum total time across the dataset (min-TT), (3) stepwise time (ST), (4) the minimum stepwise time across the dataset (min-ST), (5) Total tokens generated (TO), (6) the minimum total tokens generated across the dataset (min-TO), (7) stepwise tokens generated (SO), (8) the minimum stepwise tokens generated across the dataset (min-SO), (9) maximum concurrent API calls (MC) (10) the minimum maximum concurrent API calls across the dataset (min-MC), (11) the average total cost used to finish the plan (cost)."}, {"title": "5.4 MAIN EXPERIMENT RESULT", "content": "Table.2 presents the results on OpenAGI dataset. In Setting 1 where T utilizes ReAct, we cut the total running time on average by 22.27% percentage and the stepwise running time on average by about 31.87%. In Setting 2 where T utilizes CoT, we cut the total running time on average by 28.32% and the stepwise running time on average by about 30.83%. In Setting 4 where both A and T uses direct generation but with different backbone models, we cut the total running time on average about 20.37% percentage and the stepwise running time on average by about 23.50%. Setting 3 includes a very slow T using a multi-agent debate; we obtain the largest efficiency improvement: this setting can cut the total time by 42.30% and the stepwise running time on average by 38.29%.\nTable.3 presents the results on TravelPlanner validation dataset. Similar to the experiment on OpenAGI dataset, we can find noticeable latency improvement when using speculative planning: in Setting 1, the average latency on total generation time has decreased for 21.43% while the stepwise generation time has decreased for 29.52%; Setting 2 has decreased average total time by 19.18% and the stepwise generation time by 32.53%; Setting 3 has decreased average total time by 25.46% and the stepwise generation time by 31.69%.\nNotice that our experiments in this section do not indicate the upper bound of efficiency improvement in the two datasets but rather the performance based on the current settings."}, {"title": "5.5 ANALYSIS OF LATENCY IMPROVEMENT BREAKDOWN", "content": "Having observed the average latency improvement for the two datasets across the four settings, we now turn our attention to a more granular analysis of the latency improvement based on the accuracy of the approximation agent A. Specifically, we aim to examine how much time is saved given a specific level of A's accuracy. This analysis will allow us to identify the sources of time savings and determine which datapoints, at which levels of accuracy, contribute to latency improvement and which do not.\nThus, in this section, for each dataset and each setting, we present two figures: one displaying the distribution of datapoints with different levels of accuracy, and the other displaying the average stepwise latency improvement proportion for all levels of accuracy."}, {"title": "5.6 ANALYSIS OF USER INTERACTION", "content": "One of the motivations behind Interactive Speculative Planning is users' patience. Numerous studies (Horvitz, 1999; Barron et al., 2004; Simpson et al., 2007; Carr et al., 1992) have demonstrated the physiological and psychological impacts of interaction delays on human-computer interaction. Therefore, we aim to quantitatively study how speculative planning enhances user experience by analyzing the frequency with which a user may become impatient and desire to interact with or interrupt the system.\nFor the quantitative study, we use the OpenAGI dataset with Setting 1, 2, and 3 as examples\u00b9. We collect statistics, including the mean and variance, on the number of user interruptions that may"}, {"title": "6 LIMITATIONS AND FUTURE DIRECTIONS", "content": "Interactive Speculative Planning represents the first attempt at co-designing an efficient agent system alongside an active user interface. Consequently, it is imperfect in many aspects, and there are numerous future directions to be"}]}