{"title": "Random Sampling for Diffusion-based Adversarial Purification", "authors": ["Jiancheng Zhang", "Peiran Dong", "Yongyong Chen", "Yin-Ping Zhao", "Song Guo"], "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) have gained great attention in adversarial purification. Current diffusion-based works focus on designing effective condition-guided mechanisms while ignoring a fundamental problem, i.e., the original DDPM sampling is intended for stable generation, which may not be the optimal solution for adversarial purification. Inspired by the stability of the Denoising Diffusion Implicit Model (DDIM), we propose an opposite sampling scheme called random sampling. In brief, random sampling will sample from a random noisy space during each diffusion process, while DDPM and DDIM sampling will continuously sample from the adjacent or original noisy space. Thus, random sampling obtains more randomness and achieves stronger robustness against adversarial attacks. Correspondingly, we also introduce a novel mediator conditional guidance to guarantee the consistency of the prediction under the purified image and clean image input. To expand awareness of guided diffusion purification, we conduct a detailed evaluation with different sampling methods and our random sampling achieves an impressive improvement in multiple settings. Leveraging mediator-guided random sampling, we also establish a baseline method named DiffAP, which significantly outperforms state-of-the-art (SOTA) approaches in performance and defensive stability. Remarkably, under strong attack, our DiffAP even achieves a more than 20% robustness advantage with 10\u00d7 sampling acceleration.", "sections": [{"title": "1. Introduction", "content": "Advances in deep neural networks (DNNs) [11, 17, 19] have led to some practical applications [1, 2, 5, 24, 32] but also to some security concerns [4]. The results of adversarial attack methods [7, 13, 20] show that DNNs are very sensitive to some artificial perturbations and can easily be guided by these imperceptible perturbations to generate inappropriate results. In the face of potential threats, both adversarial training [10, 36] and adaptive test-time [14, 16] defense approaches have been specifically designed. The former leverages training sets containing adversarial samples to improve the robustness of DNNs during training, which comes at an additional cost and only defends against training-type attacks. The latter adaptively mitigates the effects of perturbations at test time, which is more efficient and flexible.\nAmong the adaptive test-time defenses, adversarial purification via generative models [12, 23, 25, 33] utilizes the data distribution prior [29] in the generated model to remove adversarial perturbations, which attracts wide attention. As the pioneering generative model, Denoising Diffusion Probabilistic Models (DDPMs) [15, 26, 29] has been explored for adversarial purification [23, 27, 31] and achieve promising effect. Diffusion models perturb the data into the noise domain and learn the gradient of data distributions during the forward training process. Then the generated data is iteratively sampled from the pure Gaussian noise in reverse inference processes. To employ it in purification, the forward noising process and reverse sampling process are mimicked in an adversarial image. However, the original DDPM sampling is designed for stable generation, which may not be the optimal solution for adversarial purification.\nWith a theoretical guarantee, DiffPure [23] preliminarily demonstrated the potential of the diffusion model as a purifier for adversarial image purification. To unlock the potential of diffusion-based purification, conditional guidance [27, 31] makes it possible to purify from pure Gaussian noise, which further eliminates the influence of the adversarial attack. But a new challenge also arises: How to guarantee the consistency of the prediction under the purified image and clean image input? In addition, for unconditional diffusion purification methods, Robustness Evaluation [18] showed that while robustness steadily improved as the number of forward steps increased, the consistency of predictions continued to decline. However, there is a lack of comprehensive evaluation and configuration recommendations for condition-guided diffusion methods.\nInspired by the stability of the Diffusion Denoising Implicit Model (DDIM) [26], we have developed an opposite sampling method, i.e., Random Sampling for adversarial purification tasks. This method aims to enhance random-"}, {"title": "2. Background", "content": "2.1. Diffusion-based Adversarial Purification\nAdversarial purification methods [9, 12, 25, 28, 30, 33] aims to introduce additional prior information to process potentially malicious perturbations in the input. Among them, diffusion-based methods [8, 23, 27, 31] utilize the learned data distribution prior [29] of pretrained diffusion models [15] to purify the adversarial examples.\nDiffPure [23] preliminarily diffuses the adversarial input with a small amount of noise following a forward diffusion process, and then recovers the clean image through a reverse generative process. Robustness Evaluation [18] focused on the performance of unconditional diffusion purification [23] and gave some recommendations for defense and attack settings. GDMP [31] submerges the adversarial perturbations with gradually added Gaussian noises and then utilizes the conditional guidance to restore the purified image, which achieves more better purification effect. MimicDiffusion [27] mimics the trajectory of the diffusion model with clean inputs to reduce the effect of adversarial perturbations and proposes two guidance based on Manhattan distance. Naturally, effective conditional guidance has become the focus of the current research. However, there is a lack of basic evaluation and configuration recommendations for conditional diffusion methods.\n2.2. Denoising Diffusion Probabilistic Models\nDiffusion model [15] includes forward noising process and reverse sampling process. The forward process gradually added Gaussian noises to the clean image (x0) and eventually got a noisy image or Gaussian noise (xt), which can be formulated as:\n$x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon,$\t(1)\nwhere $\\alpha_t = 1 - \\beta_t$, $\\bar{\\alpha}_t = \\prod_{k=1}^{t} \\alpha_k$, t means the current time steps, $\\epsilon \\sim \\mathcal{N}(0, I)$ and $\\beta_t$ is a continuously increasing sequence. Given the number of forward steps T, the reverse process iteratively sample $x_{t-1}$ from $x_t$, which can be formulated as:\n$x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} (x_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\epsilon_{\\theta}(x_t, t)) + \\sqrt{\\beta_t} \\epsilon_t,$\t(2)\nwhere $\\epsilon_{\\theta}(x_t, t)$ is the predicted noise of DDPMs at t step and $\\epsilon_t \\sim \\mathcal{N}(0, I)$ is standard Gaussian noise. Ultimately, we can generate the clean image $x_0$ from the initial sampling point $x_T$, which also is directly utilized in previous diffusion-based purification methods [8, 23, 27, 31]. Considering that stability and speed are the core requirements for the generation task, the sampling method of Eq. (2) may not be the optimal solution for adversarial purification when the defenses benefit from randomness. Thus, a fundamental question arises: is there a more robust sampling method for adversarial purification?"}, {"title": "3. Methods", "content": "Inspired by the stability of the Denoising Diffusion Implicit Model (DDIM) [26], we revisit the DDIM sampling process and propose an opposite sampling scheme called random sampling, which may be a robust solution.\n3.1. Revisit Denoising Implicit Model\nJoint Distribution Family. A key observation of DDIM is that the DDPM objective in the form of $L_y$ only depends on the marginals $q(x_t|x_0)$, but not directly on the joint $q(x_{1:T}|x_0)$. Since there are many inference distributions (joints) with the same marginals, they explore alternative inference processes that are non-Markovian, and present the joint distribution family as follows:\n$x_{t-1} = \\sqrt{\\bar{\\alpha}_{t-1}} (\\frac{x_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}) + \\sqrt{1 - \\bar{\\alpha}_{t-1} - \\sigma_t^2} \\epsilon_{\\theta}(x_t, t) + \\sigma_t \\epsilon_t,$\t(3)\nwhere the term inside the first bracket can be treated as denoised image $x_0$ predicted via current $x_t$ and the magnitude of $\\sigma_t$ controls the variance of new random noise.\nDifference between DDPM and DDIM. When $\\sigma_t = \\sqrt{(1 - \\bar{\\alpha}_{t-1})/(1 - \\bar{\\alpha}_t)} \\sqrt{1 - \\bar{\\alpha}_t/\\bar{\\alpha}_{t-1}}$ for all t, Eq. (3) can be rewritten as Eq. (2), and the generative process becomes a DDPM. When $\\sigma_t \\rightarrow 0$, we reach an extreme case where as long as we observe $x_0$ and $x_t$ for some t, then $x_{t-1}$ becomes known and fixed. The resulting model becomes an implicit probabilistic model [22], where samples are generated from latent variables with a fixed procedure (from $x_T$ to $x_0$), which is also DDIM [26]. Therefore, the core difference between the two is that DDPM will introduce some new noise into the original noisy space during each sampling while DDIM is fixed in the original noisy space sampling. Naturally, the former has stronger randomness and is therefore widely used while the latter is ignored by previous methods [23, 27, 31], which is also consistent with the results in the Robustness Evaluation [18].\n3.2. Random Sampling\nInspired by the observation, we try to maximize the randomness in the sampling process to propose a new sampling scheme. To make it easier to understand and test, we replace the value $\\sigma_t$ with a proportion $k_t \\in [0,1]$ and rewrite the Eq. (3) in the following form:\n$x_{t-1} = \\sqrt{\\bar{\\alpha}_{t-1}} (\\frac{x_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}) + \\sqrt{1 - k_t} \\sqrt{1 - \\bar{\\alpha}_{t-1}} \\epsilon_{\\theta}(x_t, t) + \\sqrt{k_t} \\sqrt{1 - \\bar{\\alpha}_{t-1}} \\epsilon_t.$\t(4)\nRandom Noise Rate. We explore the effect of new noise on robustness by varying the rate of new noise $k_t$ from 0 to 1-"}, {"title": "Sampling Scheme", "content": "Thus, we set $\\sigma = \\sqrt{1 - \\bar{\\alpha}_t}$ to establish our random sampling, which is equivalent to sampling from a new noisy space during each diffusion process and is not affected by the previous sample position. Thus, our proposed random sampling can be written as follows:\n$x_{t-1} = \\sqrt{\\bar{\\alpha}_{t-1}} (\\frac{x_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}) + \\sqrt{1 - \\bar{\\alpha}_{t-1}} \\epsilon_t.$\t(5)\nSampling Trajectory Analysis. As shown in Fig. 2, we present a conceptual illustration of the sampled trajectory of different sampling methods. Regardless of the form of the forward process, the final noisy image can be equivalent to adding a noise $n_1$ to the initial point of the reverse sampling process. The ideal DDIM sample is the most stable, but because the estimates of the diffusion model are always biased, the actual DDIM sample will fluctuate. The ideal DDIM when given $x_0$ and $x_t$ the intermediate sampling process should be deterministic, as shown by the orange sampling point in Fig. 2(a). However, because the trained diffusion model is not completely accurate, the actual DDIM sampling will fluctuate, as shown by the blue sampling points in Fig. 2(a). For DDPM sampling, the"}, {"title": "3.3. Mediator Guidance", "content": "Although the results of Robustness Evaluation [18] show that condition guidance reduces the robustness of diffusion models, this is a misunderstanding due to the difference in the performance distribution of conditional and unconditional guidance models, which we show in the Sec. 4.3.\nPrediction Consistency. Conditional guidance is still necessary for diffusion-based adversarial. On the one hand, the more noise added, the more effective the removal of antagonistic perturbations can be, but this also makes the diffusion process difficult to predict. Therefore, the process requires conditional guidance to ensure that the purified image does not deviate too much from the input. On the other hand, although we do not know whether the input is a clean image or an adversarial image, we expect that the accuracy of the clean image input into the prediction model will not be reduced after purification. In addition, there are some anomalies in the previously commonly used guidance conditions [27], which we will show later and the corresponding theoretical analysis will be added to the appendix. Here, we present a different conditional guidance design from the previous method [27, 31], which will better guide the diffusion-based purification process.\nMediator Variable Guidance. For the case of DDPM sampling, $p(x_0|x_t)$ has the unique posterior mean [6] at\n$\\mathbb{E}[x_0|x_t] = \\frac{1}{\\sqrt{\\alpha(t)}} (x_t - \\sqrt{1 - \\bar{\\alpha}(t)} \\nabla_{x_t} \\log p_t(x_t))$\t(6)\nwhich happens to be the mediator variable in the $x_t$ update process of Eq. (5) when $\\epsilon_{\\theta}(x_t, t)$ estimates the gradient of data distribution $\\nabla_{x_t} \\log p_t(x_t)$ [15, 29]. Considering that we want this expectation distribution to be as close to the input as possible during each update, we apply gradient-based guidance [31] to the mediator variable as follows:\n$x_{0,t} \\leftarrow x_{0,t} - \\nabla_{x_{0,t}} \\log p(x^{adv/clean}|x_{0,t})$\t(7)\nwhere $x_{0,t}$ is the mediator variable in the t time and $\\nabla_{x_{0,t}} \\log p(x^{adv/clean}|x_{0,t})$ could be obtained as follows:\n$\\nabla_{x_{0,t}} \\log p(x^{adv/clean}|x_{0,t}; t) = -R_t \\nabla_{x_{0,t}} d(x_{0,t}, x^{adv/clean}),$\n$x_{0,t} = \\frac{x_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}$\t(8)\nwhere $\\epsilon_{\\theta}(x_t, t)$ is the score estimation [29] through the pretrained diffusion model with the parameter $\\theta$ for $x_t$ in the t time, $R_t$ is the guided factor related to the t time, and d(*, *) is the MSE, $l_1$ norm, $l_2$ norm, or other distance metrics.\nSelected Conditional Guidance. As shown in Fig. 5, a curious defensive failure occurs with the DDIM sampling method, which is even worse than the performance of the unconditionally guided diffusion model. Considering that DDIM sampling is the most stable sampling method, the accurate guided condition may make it more vulnerable to attack than other sampling methods. In addition, previous works [27, 34] show that less guidance can reduce the time cost without affecting the performance."}, {"title": "Algorithm 1: Mediator-guided Random Sampling", "content": "Thus, we select the partial phase of the reverse process to add conditional guidance when part of the unconditional diffusion process may mitigate the collapse. Concretely, the whole generation time step is in $[T_{\\Theta}(M), T_{\\Theta}(M-1), ..., T_{\\Theta}(0)]$, we implement the guided method in the subsequence $[T_{\\Theta}(M \\mod k), T_{\\Theta}((M \\mod k) - 1), ..., T_{\\Theta}(0)]$ and vice versa not implementing the guided method. In this way, we avoid implementing the guided method in each step to get away with being specifically attacked, saving some unnecessary gradient calculation, and thus reducing the time cost at the same time.\nAlgorithm 1 summarizes the proposed Mediator-guided Random Sampling. In our method, the hyperparameters include the $R_{T_{\\Theta}(i)}$ and the modulus k. For the guided factor, it could be calculated directly without additional constraints. We experimentally find that a fixed constant is enough to achieve stable and effective guided effects, similar to the scheme of [27]. Ultimately, we select the guided subsequence by setting k as 2, which makes it possible to work with very few diffusion steps such as 10."}, {"title": "4. Evaluation", "content": "When Robustness Evaluation [18] focuses on the robustness performance of the unconditional diffusion purification method[23], the evaluation for condition-guided diffusion purification is lacking. To build an effective defense mechanism, we investigate the effect of various settings to determine the most robust configuration for the conditional-guided purification method. Specifically, the following three factors are evaluated 1) sampling methods, 2) the number of forward steps, and 3) condition-guided methods. In addition, we also introduce and evaluate a challenging adversarial attack for condition-guided purification methods."}, {"title": "4.1. Implementation Details", "content": "Considering ImageNet's similar results [18] and resource limitation, we evaluate the adversarial purification on CIFAR-10. Following the Robustness Evalulation [18], we adopt Projected Gradient Descent (PGD)($l_{\\infty}$,$\\epsilon$ = 8/255) [21] and Expectation over Transformation (EOT) [3] as the attack method. Some additional results are also provided in the appendix. The pre-trained WideResNet-28-10 [35] provided by Robustbench [8] is adopted as an underlying classifier. For a diffusion model, we use the pre-trained SDE model of [29]. The variances for the diffusion model are linearly increasing from $\\beta_1 = 10^{-4}$ to $\\beta_T = 0.02$ when T = 1000 [15]. The mediator-guided method is utilized as the condition guidance and MSE is set as the distance function. We use three different sampling methods: DDPM [15], DDIM [26], and our random sampling.\nWe adopt two prediction quality indexes including Standard Accuracy Rate (Standard Acc) and Robust Accuracy Rate (Robust Acc) for quantitative evaluation. Specifically, the former measures the prediction consistency, while the latter measures the defense robustness. Generally, higher values of the two mean a better purification effect.\nFor all experiments, we report the mean and standard deviation over five runs to measure the standard and robust accuracy. PGD uses 200 update iterations when 5 samples are used to compute EOT. Following the settings in DiffPure [23], we use a fixed subset of 512 randomly sampled images. To calculate gradients, we use direct gradients of the entire process or surrogate process [18]. In each experiment, we explain the defense and attack process in detail."}, {"title": "4.2. Condition Guided Method", "content": "We evaluate several other condition guidance proposed in earlier work [6, 27, 31] within our random sampling framework. The same number of forward steps are set for both attack and defense. Through experiments, we measure the changes in standard accuracy with the different number of forward steps in the defense, and the results are illustrated in Fig. 6. Generally, a higher standard accuracy rate means"}, {"title": "4.3. The Number of Forward Steps", "content": "We explore the effect of forward noising steps on robustness by varying the number of forward steps from 50 to 1000, resulting in changes of total variance ranging from 0.029 to 1. The same number of forward steps are used for both attack and defense, and we set five denoising steps for attack and defense for all experiments. Noting the implementation of MimicDiffusion [27] has a different setting than the previous work [18], that is, the guided condition of the purification method is unknown to the attack method. Thus, We also conducted additional experiments and supplemented the evaluation results of unknown cases.\nAs shown in Fig. 4 and Fig. 5, the robust accuracy contin-"}, {"title": "4.4. Asynchronous Attack", "content": "Although the Robustness Evaluation [18] shows that the attacker can achieve a better attack effect by using the same setup as the defender, the results may be different in the condition-guided diffusion purification methods. We accidentally found that the attacker can achieve a better attack effect by adopting a different number of forward steps, which we call asynchronous attacks. To explore the influence of the number of the attacker's forward steps, we fixed the number of the defender's forward steps at 1000, and the number of forward steps in attack ranged from 50 to 500 (more steps show the same results as 500 steps). The results are displayed in Fig. 6.\nFrom the attack perspective, the results of different sampling methods demonstrate that fewer forward steps can"}, {"title": "5. Experiment", "content": "Utilizing mediator-guided random sampling, we also establish a diffusion-based adversarial purification baseline called DiffAP to futher demonstrate the effectiveness of the proposed methods. The implementation follows the pipline of Algorithm 1. And the comparison results of DiffAP with the state-of-the-art (SOTA) methods are shown below. In addition, some extended experiments are also performed to show the acceleration effect and stability.\n5.1. Experimental Settings\nDefense Methods. The compared diffusion-based purification methods include one unconditional method (DiffPure [23]) and two conditional methods (GDMP [31] and MimicDiffsuion [27]). For a fair comparison, we adopt the evaluation setting of Sec. 4.1 for all methods. And the number of forward steps of DiffPure is set to 100 when that of other conditional methods is set to 1000."}, {"title": "Attack methods", "content": "When experimental results of previous methods [23, 27, 31] have shown that the diffusion-based purification is robust enough against most attacks like AutoAttack [7] and backward pass differentiable approximation [13], our experiment focuses on the hard case given by Robust Evaluation [18], i.e., PGD+EOT Attack. The attacks involve two settings: PGD($l_{\\infty}$,$\\epsilon$ = 8/255) and PGD($l_2$,$\\epsilon$ = 0.5) when the number of EOT samples is all set to 5. Meanwhile, We also use the stronger asynchronous attack introduced in Sec. 4.4 to test the robustness of different defense methods. In a normal PGD attack, the same forward steps as the defense method and fixed 5 denoising steps are used. For the asynchronous attack, fixed 100 forward steps and 5 denoising steps are set."}, {"title": "5.2. Comparison Results", "content": "Results for Normal Attack. Table. 1 shows the defense performance against PGD $l_{\\infty}$ ($\\epsilon$ = 8/255) and $l_2$($\\epsilon$ = 0.5) threat models, respectively. We can see that DiffAP significantly outperforms the other diffusion-based purification methods at the same denoising steps and even achieves better performance with 10\u00d7 sampling acceleration. Concretely, in standard accuracy rate, unconditional DiffPure performs better than the previous conditional method when our method achieves a 4.69% improvement over DiffPure. This result is 10.2% higher than the leading guided method MimicDiffusion and almost close to the clean accuracy of the classifier, which verifies the effectiveness of our mediator conditional guidance. Compared to MimicDiffusion on"}, {"title": "Results for Asynchronous Attack", "content": "To further distinguish the robustness of different conditional methods, the asynchronous attack is implemented in the PGD $l_{\\infty}$($\\epsilon$ = 8/255) attack framework and the results are presented in Table 2. Under the specialized strong attack, the defensive performance of conditional methods is reduced to different degrees. DiffAP has the least performance loss when other conditional methods suffer tremendous performance degradation and almost drop to the performance of unconditional DiffPure. In this case, our method achieves a huge robust accuracy advantage over other methods, which is even more 20%. And DiffAP still achieves the best performance with 10x sampling acceleration. Different from the above normal attack, this huge performance gap is mainly caused by the difference in sampling methods, which is similar to the trend of Sec. 4.4. The results also prove that random sampling is a robust solution for adversarial purification."}, {"title": "Results for Acceleration and Stability", "content": "In addition, we conduct an experiment to explore the stability of the diffusion-based purification methods, mainly involving two cases of acceleration and finite forward steps [18], and the results are shown in Table 3. Intuitively, our defense shows strong robustness higher than 80% under various cases when other methods when other methods even appear to break down, which further verifies the stability of our mediator-guided random sampling. From the top results of Table 3, although our accelerated DiffAP has all achieved better results in previous results, this is not the case for other methods. Unconditional DiffPure declines in both standard accuracy rate and robust accuracy rate, when other conditional guided the method directly to collapse. We analyze that this may be because the previous conditional meth-"}, {"title": "6. Conclusion", "content": "Inspired by the DDIM sampling, we proposed an opposite sampling scheme called random sampling to enhance the robustness of diffusion-based adversarial purification. Random sampling samples from a random rather than adjacent noisy space, which brings more randomness and achieves stronger robustness against adversarial attacks. Correspondingly, a novel mediator guidance is presented to guide sampling and improve the prediction consistency, which also shows excellent stability in different Settings. To expand awareness of guided diffusion purification, we conduct a detailed evaluation with different sampling methods, which show the impressive improvement of random sampling in multiple settings. Leveraging mediator-guided random sampling, we also establish a baseline method named DiffAP, which significantly outperforms SOTA approaches in performance and defensive stability with 10\u00d7 sampling acceleration.\nDespite the strong robustness, it is worth noting that unconditionally guided random sampling will have uncertainty, which we will explore other possibilities in further work."}, {"title": "7. Analysis of Different Condition Guidance", "content": "To reveal the gradient bias introduced by the previous guidance method, we adopt MSE as the distance index d(*, *) for analysis. From the view of our mediator guidance, the It could be decomposed into the following form:\n$x_t = \\sqrt{\\bar{\\alpha}_t} x_{0,t} + \\sqrt{1 - \\bar{\\alpha}_t} z_1,$\t(9)\nwhere $x_{0,t} = \\frac{x_t - \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_{\\theta}(x_t, t)}{\\sqrt{\\bar{\\alpha}_t}}$ and $z_1$ is estimated by $\\epsilon_{\\theta}(x_t, t)$. In GDMP[31], noisy $x^{adv/clean}$ at t time is obtained through one-step forward formula $q(x_t|x_0)$ [15] as follows:\n$x_t^{adv/clean} = \\sqrt{\\bar{\\alpha}_t} x^{adv/clean} + \\sqrt{1 - \\bar{\\alpha}_t} z_2,$\t(10)\nwhere $z_2 \\sim \\mathcal{N}(0, I)$ is a Gaussian noise different from $z_1$. Then the gradient-based guidance of GDMP [31] could be calculated as follows:\n$\\nabla_{z_1} \\log p(x^{adv/clean}|x_t) = -R_t \\nabla_{z_1} d(x_t, x_t^{adv/clean})$\n$= -2R_t (\\sqrt{\\bar{\\alpha}_t} (x_{0,t} - x^{adv/clean}) + \\sqrt{1 - \\bar{\\alpha}_t} (z_1 - z_2)),$\t(11)\nwhere $z_1 - z_2$ is the introduced gradient bias. When $R_t$ is a fixed constant, the time-varying part $\\sqrt{1 - \\bar{\\alpha}_t}$ of coefficient gradually increases with the increase of time t, the guiding error naturally increases, which is also consistent with the experimental results of main paper Fig. 3.\nIn DPS [6, 27], the gradient-based guidance is employed to guide the update of $x_{t-1}$ as follows:\n$\\nabla_{x_{t-1}} \\leftarrow \\nabla_{x_{t-1}} - \\nabla_{x_t} \\log p(x^{adv/clean}|x_t),$\t(12)\nwhich brings a bias when using the gradient at t time to guide the update at t - 1 time and the gradient guidance is calculated as follows:\n$\\nabla_{x_t} \\log p(x^{adv/clean}|x_t) = -R_t \\nabla_{x_t} d(x_{0,t}, x^{adv/clean})$\n$= -2R_t \\frac{\\sqrt{\\bar{\\alpha}_t}}{\\sqrt{V_{\\bar{\\alpha}_t}}} (x_{0,t} - x^{adv/clean}).$\t(13)\nConsidering the reasonable guidance is supposed to be as follows:\n$\\nabla_{x_{t-1}} \\leftarrow \\nabla_{x_{t-1}} - \\nabla_{x_{t-1}} \\log p(x^{adv/clean} |x_{t-1}).$\t(14)"}, {"title": "8. Unconditional Sampling Comparison", "content": "To comprehensively show the difference between different sampling methods, we supplemented the results without condition guidance as Fig. 7. The number of forward steps varies from 10 to 200, which results in changes of total variance ranging from 0.0014 to 0.2364. The same number of forward steps are used for both attack and defense, and we set five denoising steps for attack and defense for all experiments. Other experimental settings are the same as those in the main paper.\nSimilar to the results of the robustness evaluation [18], the standard accuracy of all sampling methods showed a downward trend. The magnitude of the decline is proportional to the randomness of the sampling method, and DDIM exhibits the highest standard accuracy, which is yet much lower than the performance of conditional guidance. The robustness accuracy of all sampling methods showed a trend of first increasing and then decreasing, with the highest accuracy at 160 forward steps. From the results, the robust accuracy of random sampling increases faster with the number of forward steps, but the final robust accuracy is slightly lower. In contrast, the robust accuracy of DDIM increases slowly with the number of forward steps, but the final robust accuracy is the highest. We think the standard accuracy of all methods is relatively high when the number of forward steps is small, and the robustness accuracy mainly depends on the robustness of the sampling method. When the number of forward steps is large, the decline in standard accuracy will limit the upper limit of robust accuracy, resulting in stable methods eventually achieving high robust accuracy, which is why this phenomenon occurs. It is worth noting that the best robustness performance of un-"}, {"title": "9. Discussion", "content": "As demonstrated in [8], finding the worst case is important for defense methods. Thus, asynchronous attacks are introduced to challenge existing diffusion-based purification methods. Until now, diffusion-based adversarial purification methods have had no negative social impact. Our proposed random sampling method does not present any negative foreseeable societal consequence, either."}]}