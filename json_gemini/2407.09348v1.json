{"title": "Predictable and Performant Reactive Synthesis Modulo Theories via Functional Synthesis", "authors": ["Andoni Rodr\u00edguez", "Felipe Gorostiaga", "C\u00e9sar S\u00e1nchez"], "abstract": "Reactive synthesis is the process of generating correct controllers from temporal logic specifications. Classical LTL reactive synthesis handles (propositional) LTL as a specification language. Boolean abstractions allow reducing LTL specifications (i.e., LTL with propositions replaced by literals from a theory T), into equi-realizable LTL specifications. In this paper we extend these results into a full static synthesis procedure. The synthesized system receives from the environment valuations of variables from a rich theory T and outputs valuations of system variables from T. We use the abstraction method to synthesize a reactive Boolean controller from the LTL specification, and we combine it with functional synthesis to obtain a static controller for the original LTL specification. We also show that our method allows adaptive responses in the sense that the controller can optimize its outputs in order to e.g., always provide the smallest safe values. This is the first full static synthesis method for $LTL_T$, which is a deterministic program (hence predictable and efficient).", "sections": [{"title": "1 Introduction", "content": "Reactive synthesis for Linear Temporal Logic (LTL) specifications [31] has received extensive research attention [33]. A specification $\\varphi$ has its propositions split into those variables controlled by the system and the rest, controlled by the environment. A specification is realizable if there is a strategy for the system that produces valuations of the system variables such that all traces generated by the controller satisfy the specification. Realizability is the decision problem of whether such a strategy for the system exists. Synthesis is the process of generating one such winning strategy. Also, both problems are decidable for LTL [31].\nA recent extension of LTL called $LTL_T$ (LTL modulo theories) allows replacing propositions with literals from a first-order theory T. Given an $LTL_T$ specification $\\varphi^T$ an equi-realizable LTL $\\varphi^B$ formula can be generated, provided that the validity of T formulae of the form $\\exists^*\\forall^*$ is decidable [35,37]. In $LTL_T$ synthesis the theory variables (for example Natural o Real) in the specification are split into environment-controlled and system-controlled variables, and both kinds can appear in any given literal, whereas in LTL an atomic proposition belongs exclusively to one player."}, {"title": "2 Preliminaries", "content": "First-order Theories. In this paper we use first-order theories. We describe theories with single domain for simplicity, but this can be easily extended to multiple sorts. A first-order theory T (see e.g., [7]) is described by a signature $\\Sigma$, which consists of a finite set of functions and constants, a set of variables $\\mathcal{V}$ and a domain D. The domain D of a theory T is the sort of its variables. For example, the domain of non-linear real arithmetic $T_R$ is $\\mathbb{R}$ and we denote this by $D(T_R) = \\mathbb{R}$ or simply by D if it is clear from the context. A formula $\\phi$ is valid in T if, for every interpretation I of T, then $I \\models \\phi$. A fragment of a theory T is a syntactically-restricted subset of formulae of T. Given a formula $\\phi$, we use $\\phi[x\\leftarrow u]$ for the substitution of variables $\\overline{x}$ by terms $\\overline{u}$ (typically constants).\nReactive Synthesis. We fix a finite set of atomic propositions AP. Then, $\\Sigma = 2^{AP}$ is the alphabet of valuations, and $\\Sigma^*$ and $\\Sigma^{\\omega}$ are the set of finite and infinite traces respectively. Given a trace $\\sigma$ we use $\\sigma(i)$ for the letter at position i and $\\sigma^i$ for the suffix trace that starts at position i. The syntax of propositional LTL [31,29] is:\n$\\varphi ::= \\top \\mid a \\mid \\varphi \\vee \\varphi \\mid \\neg \\varphi \\mid \\bigcirc\\varphi \\mid \\varphi \\mathcal{U} \\varphi$\nwhere $a \\in AP$; $\\vee$, $\\wedge$ and $\\neg$ are the usual Boolean disjunction, conjunction and negation; and $\\bigcirc$ and $\\mathcal{U}$ are the next and until temporal operators. The semantics of LTL associates traces $\\sigma \\in \\Sigma^{\\omega}$ with LTL fomulae as follows:\n$\\sigma \\models \\top$ always holds\n$\\sigma \\models a$ iff $a \\in \\sigma(0)$\n$\\sigma \\models \\varphi_1 \\vee \\varphi_2$ iff $\\sigma \\models \\varphi_1$ or $\\sigma \\models \\varphi_2$\n$\\sigma \\models \\neg \\varphi$ iff $\\sigma \\not\\models \\varphi$\n$\\sigma \\models \\bigcirc \\varphi$ iff $\\sigma^1 \\models \\varphi$\n$\\sigma \\models \\varphi_1 \\mathcal{U} \\varphi_2$ iff for some $i \\geq 0$ $\\sigma^i \\models \\varphi_2$, and for all $0 < j < i$, $\\sigma^j \\models \\varphi_1$\nWe use common derived operators like $\\varphi \\mathcal{R} \\varphi$, $\\Diamond \\varphi$, and $\\Box \\varphi$. Reactive synthesis [33,32,5,17] is the problem of automatically constructing a system based on an LTL specification $\\varphi$, where the atomic propositions of $\\varphi$ (AP) are divided into propositions $\\overline{e} = Vars_e(\\varphi)$ controlled by the environment and $\\overline{s} = Vars_s(\\varphi)$ controlled by the system (with $\\overline{e} \\cup \\overline{s} = AP$ and $\\overline{e} \\cap \\overline{s} = \\emptyset$). A reactive specification corresponds to a turn-based game where the environment and system players alternate. In each turn, the environment produces values for $\\overline{e}$, and the system responds with values for $\\overline{s}$. A valuation is a map from $\\overline{e}$ into $\\mathbb{B}$ (similarly for $\\overline{s}$). We use $val(e)$ and $val(s)$ for valuations. A play is an infinite sequence of turns and"}, {"title": "3 Static Reactive Synthesis Modulo Theories", "content": "The Boolean abstraction method [35] reduces an $LTL_T$ formula $\\varphi^T$ into an equi-realizable LTL specification $\\varphi^B$, but it does not present a synthesis procedure for $\\varphi^T$. We solve this problem here by providing a full static synthesis method for $LTL^T$. Our procedure builds a controller for realizable $\\varphi^T$ specifications that handles inputs and outputs from a rich domain $D(T)$, using as a building block the synthetized Boolean controller for $\\varphi^B$ and other two sub-components.\n3.1 Formal Architecture\nWe call our approach static $LTL_T$ synthesis (see Fig. 1). Our method starts from $\\varphi^T(x,y)$ and statically generates a Boolean controller $\\rho^B$ for $\\varphi^B$ and combines it with a partitioner and a provider (generated from the abstraction process of $\\varphi^T$ to $\\varphi^B$) handle the inputs and outputs from D. At run-time, at each instant the resulting controller follows these steps:\n(1) a valuation $\\upsilon_x \\in val(x)$ is provided by the environment;\n(2) the partitioner discretizes $\\upsilon_x$ generating a Boolean valuation $\\upsilon_e \\in val(e)$ of input variables for $\\rho^B$.\n(3) $\\rho^B$ responds with a valuation $\\upsilon_s \\in val(s)$ of the variables s that $\\rho^B$ controls.\n(4) the provider produces a valuation $\\upsilon_y \\in val(y)$ of the output variables that together with $\\upsilon_x$ guarantee that the literals from $\\varphi^T$ will be evaluated as indicated by the choice c that corresponds to $s$ indicated by $\\rho^B$. This step corresponds to finding a model of $\\exists y.f_c([x \\leftarrow \\upsilon_x], Y)$.\nFor step (4) one approach is to invoke an SMT solver on the fly to generate models (proper values of y), which is guaranteed to be satisfiable (by the soundness of the Boolean abstraction method). However, most uses of controllers cannot use SMT solvers dynamically. Moreover, note that the formula to be solved has\n$\\upsilon_x\\in val(x)$\n$\\xrightarrow{(x,y)}\\to \\xrightarrow{(\\overline{e}, s)} $\\xrightarrow{\\text{Boolean}} $\\text{synthesis}$ $\\xrightarrow{} \\rightarrow \\upsilon_e \\in val(\\overline{e})$ $\\leftarrow \\text{abstraction}$ $\\xrightarrow{} $\\text{Controller}^B$ $\\upsilon_s \\in val(s)$\n$\\xrightarrow{\\text{partitioner}}\\rightarrow$\\xrightarrow{\\text{provider}}\\rightarrow \\upsilon_y \\in val(y)$ Controller$\\rho^B$\nFig. 1: A controller architecture for reactive synthesis of $LTL^T$ specifications.\nquantifier alternations (within $f_c$) which is currently challenging for state-of-the art SMT solving technology for many theories. In this paper we present an alter-native: a method that produces a totally static controller, using Skolem functions associated to each (e, c) pair. These Skolem functions are models of the formula\n$\\forall x \\exists y.f_r(x) \\rightarrow f_c(x,y)$\nRecall that $f_r(x)$ is the formula that characterizes the environment valuations for which r captures the possible responses after receiving x, according to reasoning in the theory T.\nPartitioner. At each timestep, the partitioner receives a valuation $v_x \\in val(x)$ of the environment variables and finds the input variable $e_k$ to be fed to the Boolean controller. The partitioner must find the entry (e, r) in the table of valid reactions for which $f_r(x)$ is valid and return e. For instance, recall partitions $e_0$ and $e_1$ from Ex. 1, then an input trace $\\langle(x: 4), (x: 4), (x: 1), (x: 0), (x: 2), ...\\rangle$ will be partitioned into $\\langle(e: e_1), (e: e_1), (e: e_0), (e: e_0), (e: e_1), ...\\rangle$ (for simplicity, here we show the only Boolean variable $e_i$ that is true). The following defines a legal partitioner.\nDefinition 1. Let $\\varphi^T(x,y)$ be an LTLT specification and $(\\overline{e},s)$ its Boolean abstraction. A partitioner is a function $\\alpha : val(x) \\rightarrow \\overline{e}$ such that if (e,r) is a valid reaction and $f_r[X \\leftarrow \\upsilon_x]$ is valid, then $\\alpha(x) = e$.\nAlg. 1: A brute force partitioner $\\alpha$.\nInput: $v_x \\in val(x)$\nforall $(e,r) \\in VR(\\varphi)$ do\nif $f_r[x \\leftarrow v_x]$ is valid then\nL return e\nNote that, by the soundness of the Boolean abstraction method, there is one and only one such candidate e for every input x. Note that $\\alpha(x) = e$ induces a valuation $v_e$ of the variables $\\overline{e}$ by $v_x(e) = true$ and $v_x(e') = false$ for all other $e' \\neq e$. Alg. 1 shows a brute force method to find variable e.\nController. The Boolean controller receives the discrete environment input $v_e$ and produces a discrete output $v_s$ that represents the selected choices according to a winning strategy for $\\varphi^B$. This controller $\\rho$ can obtained using off-the-shelf reactive synthesis tools. This controller $\\rho$ produces a valuation $v_s \\in val(s)$ at every step, guaranteeing that the trace produced satisfies $\\varphi^B$.\nConsider an instant where only e is true in the input $v_e$, and let r be the valid reaction corresponding to e; then if $v_s$ is the output produced by $\\rho$ from $v_e$ the choice $c : \\{s_i|v_s(s_i) = true\\}$ belongs to $c \\in r$. This is forced by the extra constraint in the construction of $\\varphi^B$ from $\\varphi^T$ in the Boolean abstraction method. To better illustrate this, recall Ex. 1 and among the possible winning strategies that the system has, consider the following. If $v_e$ is $(e_0 : true, e_1 : false)$, then the output choice $v_s$ is $(s_0: true, s_1 : true, s_2 : false)$ (i.e., $c_1$). On the other hand, if $v_e(e_1)$ is $(e_0 : false, e_1 : true)$ then output choice $v_s$ is $(s_0 : false, s_1 : true, s_2 : true)$ (i.e., $c_4$)."}, {"title": "Provider", "content": "The discrete behavior of the Boolean controller requires an additional component that produces a valuation $v_y \\in val(y)$ of the system variables over y satisfying $\\varphi^T$. The provider receives the choice and the input $v_x \\in val(x)$, and substitutes $v_x$ for x in $f_c$: $f_c([x \\leftarrow v_x], y)$. The goal of the provider is to find a proper valuation for y.\nDefinition 2 (Provider). A provider is a function $\\beta : val(x) \\times val(s) \\rightarrow val(y)$ such that for every $v_x \\in val(x)$ and choice $c \\in val(s)$, the following holds\n$f_c(x \\leftarrow \\upsilon_x, y \\leftarrow \\beta(\\upsilon_x, c)).$\nWe will show below that if $v_x$ is an input to a partitioner, r is the valid corresponding reaction, and c is one of the winning choices of the controller (that is, $c \\in r$), then the following formula is valid.\n$[\\exists y.f_c(y, x\\leftarrow v_x)]$\nThis formula can be discharged into a solver with capabilities to produce a model $V_y$ (e.g., an SMT solver like Z3 [13]), which is exactly the dynamic approach presented at [36].\nExample 2. Consider again Ex. 1 and input trace $\\langle(x: 4), (x: 4), (x: 1), (x : 0), (x: 2),...\\rangle$. This trace is mapped into the following discrete input trace $\\langle(c: c_4), (c: c_4), (c: c_1), (c: c_1), (c: c_4), ...\\rangle$. Recall that $s_0$ abstracts $(x < 2)$, $s_1$ abstracts $(y > 1)$ and $s_2$ abstracts $(y \\leq x)$. Then, the output trace must be a sequence $v_y$ of values of y such that the following holds:\n[$(\\neg (4 <2) \\wedge (y > 1) \\wedge (y \\leq 4)]$,\n[$(\\neg (4 < 2) \\wedge (y > 1) \\wedge (y \\leq 4)]$,\n$[(1 < 2) \\wedge (y > 1) \\wedge \\neg (y \\leq 1)]$,\n$[(0 < 2) \\wedge (y > 1) \\wedge \\neg (y \\leq 0)]$,\n[$(\\neg (2 <2) \\wedge (y > 1) \\wedge (y \\leq 2)],...)$\nOne such possible sequence is $(\\langle y : 2), (y : 2), \\langle y : 2), \\langle y : 2), (y : 2), ...\\rangle$. Note how x is replaced in each timestep by concrete input $v_x$. However, many different values vy exist that satisfy the output trace (e.g. $\\langle(y: 2), (y : 3), (y : 3), (y:\n4), (y: 2), ...\\rangle).$\nCorrectness. The Boolean system strategy $\\rho : \\langle Q, q_0, \\delta, \\sigma\\rangle$ for $\\varphi^B$ produces, at every timestep, a valuation of s from a valuation of e. We now define a strategy $\\rho^T$ of the system in $T$ and prove that all moves played according to $\\rho^T$ are winning for the system; i.e., all produced traces satisfy $\\varphi^T$. Intuitively, $\\rho^T$ composes the partitioner, which translates inputs to the Boolean controller, collects the move chosen by the Boolean controller and then uses the provider to generate an output.\nDefinition 3 (Combined Strategy). Given a partitioner $\\alpha$, a controller $\\rho^B$ for $\\varphi^B$ and a provider $\\beta$, the strategy $\\rho^T : \\langle Q', q'_0, \\delta', \\sigma'\\rangle$ for $\\varphi^T$ is:"}, {"title": "4 Adaptive Synthesis Modulo Theories", "content": "4.1 Enhancing Controllers\nThe static partitioner presented in the previous section always generates the same output, for a given choice (valuation of literals) and input. However, it is often possible that many different values can be chosen to satisfy the same choice. From the point of view of the Boolean controller, any value is indistinguishable, but from the point of view of the real-world controller the difference may be significant. For example, in the theory of linear natural arithmetic $T = T_N$, given $x = 3$ and the literal $(y > x)$, a Skolem function $h(x) = x + 1$ would generate $y = 4$, but $y = 5$ or $y = 6$ are also admissible. We call adaptivity to the ability of a controller to produce different values depending on external criteria, while still guaranteeing the correctness of the controller (in the sense that values chosen guarantee the specification). We introduce in this section a static adaptive provider that exploits this observation. Recall that the Skolem functions in Sec. 3 are synthetised as follows.\nDefinition 4 (Basic Provider Formula). A basic provider formula is a formula of the form $\\forall x.\\exists y.\\psi(x,y)$, where $\\psi = f_{r_k(x)} \\rightarrow f_c(x,y)$ is the characteristic formula for reaction $r_k$ and choice c.\nWe now introduce additional constraints to $\\psi$ that in the case that the resulting formulae are valid allow generating functions that guarantee further properties. Given a formula $\\psi(x, y)$ and a set of variables z (different than x and y) adaptive formulae also enforce an additional constraint $\\psi^+$.\nDefinition 5 (Adaptive Provider Formula). Let $\\psi(x,y)$ be the character-istic formula for a given reaction $r_k$ and choice c. An adaptive constraint is a formula $\\psi^+(x,z,y)$ whose only free variables are x, y and z. An adaptive provider formula is of the form\n$\\forall x,z.\\exists y.[\\psi(x,y) \\wedge \\psi^+(x,z,y)]$,\nwhere $\\psi^+$ is an adaptive constraint."}, {"title": "5 Empirical Evaluation", "content": "We now report on empirical evaluation to asses the performance of our approach. We used Python 3.8.8 for the implementation of the architecture and Z3 4.12.2 for the SMT queries. We use Strix [30] as the synthesis engine and aigsim.c to execute the synthetised controller. For functional synthesis we used the AEval solver [16]5 that leverages Z3. Currently, AEval expects formulae in linear arith-metic with the $\\forall^*\\exists^*$ shape, which is suitable for the static provider we want to synthesise. We translate the Skolem functions into C++ and used g++ 14.0.0 as a compiler. We ran all experiments on a MacBook Air 12.4 with the M1 processor and 16 GB. of memory.\nWrap-up experiment. We first report our results on T-controller for Ex. 1. Following the idea of Ex. 2, we execute the input trace $\\pi = (\\langle x|x \\geq 2\\rangle, \\langle x|x \\geq 2\\rangle, \\langle x|x < 2\\rangle, \\langle x|x < 2\\rangle, \\langle x|x \\geq 2\\rangle)$ 100000 times on (1) a dynamic provider following [36] and (2) our static provider approach. Throughout both experi-ments, the average time for the partitioner was 28 ms6 and the average time for the Boolean controller execution was 2.47 \u03bcs. However, the average time for the dynamic provider was 169 \u03bcs, whereas the static provider was about 50 times faster: 2.9 \u03bcs. We show in Fig. 3 the time needed (in \u03bcs) of the dynamic provider and the static provider in the first 50 events. We can see that (1) the times re-quired in the dynamic approach are more unstable and that (2) the dynamic approach is two orders of magnitude faster.\nFig. 2: Adaptive architecture, which uses adaptive providers and $v_z$.\no'(q, (\u03c5zU\u03c5z)) = \u03b2\u0393(\u03c5x, \u03c5z,s) where s = o(q,e).\nNote that in the semantics of $\\varphi^T$ now the environment chooses the values $v_z$ of the variables z that appear in the constraints in \u0413. Also, note that the overall architecture of adaptive controllers (see Fig. 2) is similar to the one presented in Sec. 3, but using adaptive providers and extra input $v_z$.\nThe following holds analogously to Thm. 1 in Sec. 3.\nTheorem 3 (Correctness of Adaptive Synthesis). Let $\\varphi^T$ be a realizable specification, $\\varphi^B$ its Boolean abstraction, $\\alpha$ a partitioner, $\\Gamma$ an adaptive provider description and $\\beta_\\Gamma$ an adaptive provider. Let $\\rho^B$ be a winning strategy for $\\varphi^B$, and $\\rho_\\Gamma^T$ the strategy obtained as the composition of $\\alpha$, $\\rho^B$ and $\\beta_\\Gamma$ described in Def. 7. Then $\\rho_\\Gamma^T$ is winning for $\\varphi^T$.\nProof (Sketch). The proof proceeds by showing that any play played according to $\\rho_\\Gamma^T$ satisfies, at all steps, the same literals as $\\rho^B$, independently of the values of z. It is crucial that, after each step, the controller state that $\\rho_\\Gamma^T$ and $\\rho^B$ leave is the same, which holds because their $\\delta'$ is indistinguishable. $\\Box$\nSkolem functions are computed from basic provider formulae that have a shape $\\forall^*\\exists^*.\\psi$. This shape is preserved in adaptive provider formulae in which the constraint $\\psi^+$ is quantifier-free. However, as the last example illustrated, the constraint $\\psi^+$ may include quantifiers, which does not preserve the shape typically amenable for Skolemization.\nFor instance, to compute the smallest $y \\in D(T_Z)$ in $\\forall x.\\exists y.(y > x)$, one can use the adaptive provider formula $\\forall x.\\exists y.[(y > x) \\wedge\\forall z.(z > x) \\rightarrow (z \\geq y)]$. We overcome this issue by performing quantifier elimination (QE) for the innermost quantifier and recover the $\\forall^*\\exists^*$ shape. In consequence, our resulting method works on any theory T that:\n(1) is decidable for the $\\exists^*\\forall^*$ fragment (for the Boolean abstraction);\n(2) permits a Skolem function synthesis procedure (for valid $\\forall^*\\exists^*$ formulae), for producing static providers; and\n(3) accepts QE (which preserves formula equivalence) for the flexibility in defin-ing quentified constraints $\\psi^+$.\nThe Adaptive\n4 The results of the adaptive simulations are to be presented in Sec. 5.\nThe use of quantification opens the door to explore solutions that exploit characteristics of concrete theories. Consider for example the theory of Pres-burger arithmetic $\\mathcal{T}_Z$ (which we illustrate with single variable but can be extended to other notions of distance with multiple variables, such as Euclidean distance). In this theory the following holds.\nLemma 2 (Closest element). In $\\mathcal{T}_Z$ the following holds. Assuming $\\forall x.\\exists y.\\psi(x,y)$, the following is also valid:\n$\\forall x.z.\\exists y.[(\\psi(x,y) \\wedge \\forall w.[\\psi(x, w) \\rightarrow |y - z| < |w - z|]]).$\nIn other words, in $\\mathcal{T}_Z$ if for all inputs x there is an output y such that $\\psi$ holds, then there is always a closest value to any provided z that satisfies $\\psi$. The"}, {"title": "6 Related Work and Conclusions", "content": "Related Work. LTL modulo theories has been previously studied (e.g., [23,14]), but allowing temporal operators within predicates, again leading to undecidabil-ity. Also, infinite-state synthesis has been recently studied at [8,15,19,39,3,24] but with similar restrictions. At [26,27] authors perform reactive synthesis based on a fixpoint of $\\forall^*\\exists^*$ formulae (for which they use AEval), but expressivity is limited to safety and does not guarantee termination. The work in [41] also relies on ab-straction but needs guidance and again expressivity is limited. Reactive synthesis of Temporal Stream Logic (TSL) modulo theories [18] is studied in [9,28], which extends LTL with complex data that can be related accross time. Again, note that general synthesis is undecidable by relating values across time. Moreover, TSL is already undecidable for safety, the theory of equality and Presburger arithmetic. Thus, all the specifications considered for empirical evaluation in Sec. 5 are not within the considered decidable fragments.\nAll approaches above adapt one specific technique and implement it in a monolithic way, whereas [35,37] generates LTL specification that existing tools can process with any of their internal algorithms (bounded synthesis, for exam-ple) so we will automatically benefit from further optimizations in these tech-niques. Moreover, Boolean abstraction preserves the temporal fragments like safety and GR(1) so specialized solvers can be used. Throughout the paper, we have already extensively compared the work [36] with ours and we showed that our approach uses Skolem functions instead of SMT queries on-the-fly, which makes it faster, more predictable and a pure controller that can be used in embedded contexts. It is worth noting that [36] and our approach can be under-stood as computing minterms to produce Symbolic automata and transducers [11,12] from reactive specifications (and using antichain-based optimization, as suggested by [40]). Also, note that any advance in abstraction method (e.g., [4]) has an immediate positive impact in our work.\nLast, [25] presents a similar idea to our Skolem function synthesis: instead of solving a quantified formula every time one wants to compute an output, they synthesize a term that computes the output from the input. However, the paper is framed in the program synthesis problem and uses syntax-guided synthesis [2], whereas previous reactive synthesis papers have suggested functional synthesis as a recommended software engineering practise (e.g., [38]).\nConclusion. The main contribution of this paper is the synthesis procedure for $LTL_T$, using internally a Boolean controller and static Skolem function synthe-sis, which is more performant and predictable than previous approaches. Our method also allows producing adaptive responses that optimize the behaviour of the controller with respect to different criteria. We showed empirically that our approach is fast for many targeted applications and analyzed the cost and predictability of our Skolem functions component compared to [36]. As far as we know, this is the first decidable full reactive synthesis approach (with or with adaptivity) for $LTL_T$ specifications.\nFuture work includes first to use winning regions instead of concrete con-trollers to allow even more choices for the Skolem functions, and to develop a further adaptivity theory. Another direction is studying adaptivity over the en-vironment inputs and combining this approach with monitoring. Also, we plan to study how to extend LTL with transfer of data accross time preserving de-cidability, since recent results [22] suggest that the expressivity can be extended with limited transfers in semantic fragments of $LTL_T$. Moreover, explaining our synthesis approach within more general frameworks like (e.g., [21]) is immediate work to do. Finally, we want to study how to use our approach to construct more predictable and performant shields [1,6] (concretely, shields modulo theo-ries [34,10]) to enforce safety in critical systems."}, {"title": "A Complete running example", "content": "In $\\varphi^T$ of Ex. 1 a valid (positional) strategy of the system is to always play y: 2. In this appendix we show that a controller synthetised using our technique will, precisely, respond in this manner infinitely many often. To do so, we rely on the trace of Ex. 2 and Skolem functions of Ex. 3.\nFirst, we Booleanize $\\varphi^T$ using [35] and get $\\varphi^B$ (also, recall from Ex. 1 that we use the notation $c_i$ to indicate choice i; e.g., $C_0 = \\{S_0, S_1, S_2\\}, C_1 = \\{S_0, S_1\\}$, $C_6 = \\{S_2\\}, C_7 = \\emptyset.$). Then, we get a controller $C^B$ from $\\varphi^B$. We note that many strategies satisfy $\\varphi^B$, but $C^B$ by Strix is as follows: $C^B(e_1) = c_4$ and $C^B(e_0) = c_1$. Also, note that this particular strategy is memoryless, but there are diverse strategies that use memory. We now show how the static T-controller computes Skolem functions on demand.\nStep 1: Environment forces instant response. Let x: 4, which holds (x > 2) and forces constraint (y \u2264 x). We are in partition $e_1$, which implies choices $\\{c_4, c_5, c_6\\}$. Now, $C^B(e_1) = c_4$, so the T-controller looks whether the pair $(e_1, c_4)$ appeared before. Since it did not, it computes $h_{(e_1,c_4)}$ (see left-hand function at Ex. 3). Thus, $h_{(e_1,c_4)} (2) = 2$ is the output vy in the first timestep. Note that a T-controller with a different underlying $C^B$ could also consider $c_6$ in the current play.\nStep 2: Environment repeats the strategy. Again, x: 4 and again we are in partition $e_1$. Now, $C^B(e_1) = c_4$, so the T-controller looks whether the pair $(e_1, c_4)$ appeared before. Since it does, it just calls pre-computed $h_{(e_1,c_4)}$. Thus, $h_{(e_1,c_4)} (2) = 2$ is the output vy in the second timestep.\nStep 3: Environment changes its mind. Let x : 1, which holds (x < 2) and forces constraint $\\bigcirc(y > 1)$, whereas no constraint is further for the current timestep. We are in partition $e_0$, which implies choices $\\{c_1, c_2\\}$. Now, $C^B(e_0) = c_1$, so the T-controller looks whether the pair $(e_0, c_1)$ appeared before. Since it did not, it computes $h_{(e_0,c_1)}$ (see right-hand function at Ex. 3). Thus, $h_{(e_0,c_1)} (2) = 2$ is the output vy in the third timestep. Note that a T-controller with a different underlying $C^B$ could also consider $c_2$ in the current play.\nStep 4: Environment prepares its trap. Let x: 0, which holds (x < 2) and forces constraint $\\bigcirc(y > 1)$, and take into account that the system has constraint (y > 1) forced by the previous timestep. We are again in partition $e_0$, which implies, again, choices $\\{c_1, c_2\\}$. Now, $C^B(e_0) = c_1$, so the T-controller looks whether the pair $(e_0, c_1)$ appeared before. Since it does, it just calls pre-computed $h_{(e_0,c_1)}$. Thus, $h_{(e_0,c_1)} (2) = 2$ is the output vy in the fourth timestep. Note that this time there is no correct $C^B$ that could also consider $c_2$ in the current play."}, {"title": "B More About Adaptivity", "content": "We outline several immediate consequences of using adaptivity of Sec. 4.\nAcross-time Adaptivity. In the previous section we showed that if we can synthesize Skolem functions for adaptive provider formulae, then the system obtained is still a good system for the $\\varphi^T$. We show now that the additional arguments can be used to produce better controllers for $\\varphi^T$. For instance, Z (thus, $v_z$ in Fig. 2) can be used to feed past values to the controller, and $\\psi^+$ can describe desired evolution of the output in terms of the past history.\nDefinition 8 (Across-time adaptive controller). Let $\\varphi^T (x,y)$ be a speci-fication, let I be an adaptive provider description, and let $\\rho^T$ be the resulting controller. Then, we say that $\\rho^T$ is an across-time adaptive controller if the extra variables z in I fed are past values of X and y.\nExample 6. Consider again the characteristic formula $\\varphi = (y > x)$, and the cor-responding basic provider formula $\\forall x.\\exists y.\\varphi$, which is valid in Tz. The constraint $\\psi^+ = (y > z)$ makes the adaptive provider formula $\\varphi = \\forall x, z.\\exists y.(\\varphi \\wedge \\psi^+)$ valid. A Skolem function $h(x, z)$ guarantess that the output y generated is greater than the values of both x and z. Then, if the controller received z as the value of y in the previous timestep (denoted y), then we"}]}