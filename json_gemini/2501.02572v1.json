{"title": "Energy Optimization of Multi-task DNN Inference in MEC-assisted XR Devices: A Lyapunov-Guided Reinforcement Learning Approach", "authors": ["Yanzan Sun", "Jiacheng Qiu", "Guangjin Pan", "Shugong Xu", "Shunqing Zhang", "Xiaoyun Wang", "Shuangfeng Han"], "abstract": "Extended Reality (XR), blending virtual and real worlds, is a key application of future networks. While AI advancements enhance XR capabilities, they also impose significant computational and energy challenges on lightweight XR devices. In this paper, we developed a distributed queue model for multi-task DNN inference, addressing issues of resource competition and queue coupling. In response to the challenges posed by the high energy consumption and limited resources of XR devices, we designed a dual time-scale joint optimization strategy for model partitioning and resource allocation, formulated as a bi-level optimization problem. This strategy aims to minimize the total energy consumption of XR devices while ensuring queue stability and adhering to computational and communication resource constraints. To tackle this problem, we devised a Lyapunov-guided Proximal Policy Optimization algorithm, named LyaPPO. Numerical results demonstrate that the LyaPPO algorithm outperforms the baselines, achieving energy conservation of 24.79% to 46.14% under varying resource capacities. Specifically, the proposed algorithm reduces energy consumption of XR devices by 24.29% to 56.62% compared to baselines algorithms.", "sections": [{"title": "I. INTRODUCTION", "content": "THE advent of the Metaverse [1] has ignited considerable interest in immersive experiences within virtual environments. A cornerstone technology enabling these experiences is Extended Reality (XR), which has rapidly gained prominence as a key 5G media application [2]\u2013[5]. XR applications strive to elevate user interaction by continuously analyzing user behaviors and environmental contexts through tasks such as gesture recognition [6], speech recognition [7], and object tracking [8]. The use of deep neural network (DNN)-based AI algorithms, known for their high precision, has further enhanced these applications, significantly improving the quality of user experiences.\nDespite the substantial potential of these AI-driven solutions in XR, they impose notable challenges for XR devices. On one hand, DNN-based algorithms demand intensive computational resources, resulting in high latency and increased energy consumption [9], [10]. On the other hand, XR devices, due to their lightweight design, are constrained by limited battery capacity and computational capabilities, restricting the direct implementation of DNN models [4], [11], [12]. Moreover, the intricate interaction requirements of XR applications often necessitate the simultaneous operation of multiple DNN models, compounding these computational and energy demands.\nMobile Edge Computing (MEC) has emerged as a promising solution to address these limitations. By offloading computationally intensive tasks to edge servers, edge AI offers a viable approach to reduce network load, decrease latency, and lower energy consumption on devices [13]. Specifically, DNN model partitioning enables the division of model processing between XR devices and MEC servers [14], [15]. This hybrid processing approach capitalizes on the computational resources of both the device and the network edge, thus enhancing overall system performance.\nIn response to these considerations, this study aims to optimize the inference of multi-task AI models in XR applications supported by MEC. We propose a Lyapunov-guided reinforcement learning (DRL) approach to minimize energy consumption for DNN inference in MEC-assisted XR systems. The contributions of this paper are as follows.\nMulti-Task DNN Inference for MEC-assisted XR Applications. In this paper, we consider an edge network architecture for MEC-assisted XR applications focused on multi-task DNN inference. Within this architecture, each XR device is required to handle multiple AI applications simultaneously, corresponding to multi-task DNN inference. For each application, there exists a coupled relationship among the local queues, transmission queues, and MEC queues. These queues are coupled because they share dependencies and participate in the competition for communication and computation resources. We also consider utilizing DNN partitioning techniques to fully leverage the computational capabilities of both XR devices and MEC. Based on this, our aim is to optimize the allocation of system resources and the DNN partition point for each AI application, reducing the energy consumption of XR devices while ensuring the completion of DNN inference tasks.\nBi-level Modeling for Dual Time-Scale Optimization. Since DNN partitioning cannot be reconfigured"}, {"title": "II. RELATED WORKS", "content": "A substantial body of research leverages the computational capacity of MEC to enable edge-assisted collaborative inference. Effective techniques in this domain include computation offloading, model partitioning, etc., which have proven their efficacy in various applications. Specifically, in the field of computation offloading, Fang et al. [16] design TORA-DRL algorithm, which employ DRL to optimize power consumption and alleviate network load. HybridPPO in [17] applies task offloading to reduce latency and energy consumption under specific server constraints. Bi et al. [18] present the LyDROO framework, which optimally manages data processing through resource allocation and offloading. Wu et al. [19] address stochastic offloading with perturbed Lyapunov optimization to enhance energy efficiency. Similarly, the work in [20] also uses Lyapunov optimization to minimize energy consumption, and designs an energy efficient dynamic offloading algorithm. Dai et al. [21] integrate digital twin technology with IIoT networks to model network topology and random task arrivals, proposing an asynchronous actor-critic algorithm to optimize long-term energy efficiency.\nDespite the benefits of computation offloading, fully transferring the entire neural network inference tasks to MEC servers often limits the efficient utilization of both device and MEC server resources. Additionally, the transmission of massive data from devices to MEC server for processing generates large amounts of cross-network traffic, consuming more network resources and increasing energy consumption [22]. Computation offloading faces challenges under dynamic communication conditions, which can impact connectivity and reliability. Therefore, this study identifies DNN model partitioning as a promising alternative for edge collaborative inference. The model partitioning technology strategically segments the DNN models into multiple parts in accordance with its multilayered structure [23], which allows partial inference tasks to be processed locally before offloading to MEC servers.\nEffective queue management is crucial in model partitioning to ensure system efficiency. Several studies incorporate queue mechanisms within model partitioning techniques to address dynamic resource demands. For instance, an M/D/1 queuing model in [24] aims to minimize end-to-end (E2E) latency by jointly optimizing partitioning and resource allocation. COSREL, proposed in [25], is an online DRL co-scheduling framework that utilizes heterogeneous computing resources (CPUs, GPUs, DSPs) for concurrent inference of multiple DNN models to enhance throughput, reduce latency, and improve energy efficiency. Ale et al. [26] propose the Dirichlet Deep Deterministic Policy Gradient (D3PG) framework to jointly optimize task partitioning, computational offloading, and computational frequency control, where subtasks are processed sequentially in the queues.\nLyapunov optimization technique is adopted to further control the stability of the queues while dynamically allocating resources [14], [27]\u2013[29]. The work in [14] designs a queue system comprising DNN task load queues and energy queues, enabling online control of task partitioning and offloading to jointly optimize latency and energy consumption. Jiang et al. [27] build an online joint offloading and resource allocation framework (JORA) by employing Lyapunov optimization to create virtual energy queues for reducing latency and energy consumption. Su et al. [28] present the DDPRA algorithm, which combines Lyapunov optimization with reinforcement learning to dynamically partition DNNs and allocate resources, minimizing the long-term average delay under energy constraints. RT-DMP described in [29] optimally balances energy consumption, throughput, and E2E latency through joint DNN partitioning and resource adaptation, addressing the quality of experience (QoE) demands of mobile environments with a virtual queue-based Lyapunov framework. Furthermore, an upsurge interest in energy efficiency can be observed in the literature e.g., [14], [25], [27]\u2013[29]. Unfortunately, these studies often overlook the distributed structure of the queues between the device and server sides in the model partitioning scenario, whereas distributed queues require optimization by considering the coupling between them."}, {"title": "III. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "As illustrated in Fig. 1, we consider a MEC system comprising a single base station (BS) and M XR devices, denoted by the set \\( M = {1,2,..., M} \\). Each XR device \\( m\\in M \\) hosts various Al services, such as facial recognition [32], [33] and gesture recognition [6]. To support these services, each XR device m deploys \\( N_m \\) DNN models, represented by \\( N_m = {1,2,...,N_m} \\), where each model corresponds to a specific AI task required for the XR application.\nDue to the lightweight design constraints of XR devices, they typically operate under strict energy limitations. To mitigate energy consumption, we consider that XR devices can offload portions of their DNN inference tasks to an MEC server through a process called DNN partitioning [14], [15]. Specifically, for each service (i.e., each DNN model) on an XR device, initial inference computation is performed locally. The intermediate results are then transmitted over a wireless network to the MEC server, where the remaining computation is completed. This collaborative approach fully utilizes the computational resources of XR devices and MEC while simultaneously reducing the energy consumption of XR devices. Therefore, for each AI service, DNN inference tasks are generated randomly. Throughout the lifecycle of a task, from initiation to computation completion, tasks traverse through three distinct distributed queues: the local queue, the transmission queue, and the edge queue. The entire execution of each task is divided into the following three steps,\nStep 1. DNN inference tasks are generated and queued in the local queues. In this phase, computation before the model partition point is handled locally by the XR device.\nStep 2. After local inference, the remaining computing task is offloaded to the MEC server. This step involves transmitting intermediate layer features of the task into the transmission queues.\nStep 3. The MEC server receives the task in the edge queues, where it processes the remaining computations after the model partition point.\nTo model the temporal dynamics of the AI inference system for XR applications, we segment the time domain into a set of discrete time slots, represented by \\( T = {0,1,2,..., T_s } \\), each with a duration of \\( \\tau \\). Computational and communication resources are adjustable in each time slot \\( t_s \\). However, frequent adjustments to the model's partitioning decision are impractical due to the significant overhead involved in loading and reconfiguring the model. Therefore, we make adjustments to the partition decisions of the DNN model on a larger timescale. Specifically, we denote \\( G_T \\) as the duration of each partition adjustment period, and define the partition adjustment intervals within the set \\( T_p = {0, G, 2G,......,G T_p} \\subset T \\). For convenience, we define \\( t_p \\) as the partition adjustment period in"}, {"title": "A. DNN Inference Task Model", "content": "In the AI collaborative inference scenario tailored for XR applications, the AI service requirements of XR devices are addressed through DNN models. We assume that each DNN model for an Al service has a fixed model architecture and a constant input data size. To enable uniform evaluation of the computational complexity associated with DNN inference tasks deployed on XR devices, we utilize the number of multiply-and-accumulate operations (MACs) as a standard metric [34].\nFor the service n on device m, the total MACs required for completing a single DNN inference task is represented by \\( C_{m,n} \\) (in MACs). The input data size is denoted by \\( D_{m,n} \\) (in bits), while the maximum number of partition layers in the model is represented by \\( K_{m,n} \\). The partition point within the partition adjustment period \\( t_p \\) is denoted by \\( k_{m,n} \\in K_{m,n} = {1,2,..., K_{m,n} } \\).\nWe denote the proportion of computational complexity required by the layers preceding the partition point \\( k_{m,n} \\) as \\( C_{m,n}^{t_p} \\), with the remaining proportion expressed as \\( 1 - C_{m,n}^{k_{m,n}^{t_p}} \\). These proportions satisfy the ordering \\( C_{m,n}^{k_{m,n}^{t_p}} < C_{m,n}^{k_{m,n}^{t_p}} <\u2026< C_{m,n}^{k_{m,n}^{t_p}} = C_{m,n} \\), where \\( C_{m,n}^{k_{m,n}^{t_p}} = 0 \\) signifies complete offloading of the task to the edge server, and \\( C_{m,n}^{k_{m,n}^{t_p}} = 1 \\) implies full local execution on the XR device.\nSimilarly, \\( d_{m,n} \\) quantifies the ratio of the output feature map size at partition point \\( k_{m,n} \\) to the input data size \\( D_{m,n} \\). Specifically, \\( d_{m,n}^{k_{m,n}^{t_p}} = 0 \\) indicates computation of the entire inference task locally on the XR device, while \\( d_{m,n}^{k_{m,n}^{t_p}} = 1 \\) indicates offloading of the entire inference task to the MEC server. Note that \\( d_{m,n}^{k_{m,n}^{t_p}} \\) can exceed 1, as intermediate layer outputs may surpass the size of the neural network's input data.\nBased on these definitions, a comprehensive DNN inference task model can be established to systematically evaluate task workloads from initiation to completion. The computational complexity of the inference task on the XR device is given by \\( C_{m,n}^{local}(t_p) = C_{m,n}^{k_{m,n}^{t_p}} C_{m,n} p \\), where p (in cycles/MAC) is the CPU cycles required for each multiplication and addition operation, which is dependent on the CPU model [34]. The size of the output feature map transferred from the XR device to the MEC server is expressed as \\( d_{m,n}(t_p) = d_{m,n}^{k_{m,n}^{t_p}} D_{m,n} \\). Meanwhile, the computational complexity remaining for the MEC server is given by \\( C_{m,n}^{edge}(t_p) = (1 - C_{m,n}^{k_{m,n}^{t_p}} ) C_{m,n} p \\)."}, {"title": "B. Computation and Communication Models", "content": "In the MEC-assisted XR system, distinct queues are established for managing AI service requests originating from each XR device m and its associated model n. Due to the stochastic nature of wireless network conditions and the random arrival of tasks, dynamic allocation of computation and communication resources is crucial to optimizing overall system performance in real time.\nThe computational resources allocated to service n by XR device m and the MEC server are denoted by \\( f_{m,n}(t_s) \\) and \\( f_{m,n}^e(t_s) \\) (in cycles/s), respectively. These resource allocations are constrained by the available computational capacities \\( F_m \\) at the XR device and \\( F_e \\) at the MEC server respectively, which can be expressed as\n\\[\n\\sum_{n\\in N_m} f_{m,n}(t_s) \\leq F_m, \\forall m \\in M,\n\\]\n\\[\n\\sum_{m\\in M} \\sum_{n\\in N_m} f_{m,n}^e(t_s) \\leq F_e.\n\\]\nTo simplify the problem, we assume that the system bandwidth \\( B_w \\) is evenly divided into M orthogonal channels to serve the M XR devices. The maximum transmission rate for XR device m in time slot \\( t_s \\) can be expressed as\n\\[\nR_m(t_s) = B_w \\log_2\\left(1 + \\frac{P_m(t_s) h_m (t_s)}{N_0}\\right),\n\\]\nwhere \\( h_m(t_s) \\) and \\( p_m(t_s) \\) represent the channel gain and the allocated transmission power, respectively, while \\( b_w = \\frac{B_w}{M} \\) is the bandwidth allocated to each XR device. For Al service n on device m, the allocated transmission rate \\( r_{m,n}(t_s) \\) must satisfy the constraint\n\\[\n\\sum_{n\\in N_m} r_{m,n}(t_s) \\leq R_m(t_s).\n\\]"}, {"title": "C. Queue model", "content": "The arrival process of inference tasks generated from the corresponding AI service follows a specific random distribution. To effectively manage these tasks, distributed queue modeling is required, encompassing local queues, transmission queues, and edge queues. The queues \\( Q_{m,n}(t_s) \\) and \\( Q_{m,n}^e(t_s) \\) (in cycles) represent the remaining computational workload backlog on XR device and MEC server, respectively. The queue \\( Q_{m,n}^t(t_s) \\) (in bits) represents the remaining transmission data backlog in the XR device. All queues adhere to a first-come, first-served scheduling policy. We define \\( [x]^+ = \\max{x,0} \\). The updates for each of the queues are expressed as follows:\n\\[\nQ_{m,n}(t_s+1) = [Q_{m,n}(t_s) - f_{m,n}(t_s) \\tau + a_{m,n}(t_s) C_{m,n}^{local}(t_p)]^+,\n\\]\n\\[\nQ_{m,n}^t(t_s + 1) = [Q_{m,n}^t(t_s) - r_{m,n}(t_s) \\tau +a_{m,n}(t_s) d_{m,n}(t_p)]^+,\n\\]\n\\[\nQ_{m,n}^e(t_s + 1) = [Q_{m,n}^e(t_s) - f_{m,n}^e(t_s) \\tau + a_{m,n}^t(t_s) C_{m,n}^{edge}(t_p)]^+,\n\\]\nwhere \\( a_{m,n}(t_s) \\), \\( a_{m,n}^t(t_s) \\) and \\( a_{m,n}^e(t_s) \\) indicate the number of DNN inference tasks arriving at the local queue, transmission queue, and edge queue, respectively, in time slot \\( t_s \\), and can be calculated by\n\\[\na_{m,n}(t_s + 1) = \n\\begin{cases}\n[a_{m,n}(t_s) - b_{m,n}(t_s)]^+, & k_{m,n}^{t_p} = 0 \\\\\n[a_{m,n}(t_s) + a_{m,n}^t(t_s) - b_{m,n}(t_s)]^+, & \\text{others}\n\\end{cases}\n\\]\n\\[\na_{m,n}^t(t_s + 1) = \n\\begin{cases}\n[a_{m,n}(t_s) + a_{m,n}(t_s) - b_{m,n}(t_s)]^+, & k_{m,n}^{t_p} = 0 \\\\\n[b_{m,n}(t_s) + a_{m,n}(t_s) - b_{m,n}(t_s)]^+, & k_{m,n}^{t_p} = K_{m,n} \\\\\n[a_{m,n}(t_s) + a_{m,n}^e(t_s) - b_{m,n}(t_s)]^+, & \\text{others}\n\\end{cases}\n\\]\n\\[\na_{m,n}^e(t_s + 1) = \n\\begin{cases}\n[a_{m,n}(t_s) - b_{m,n}(t_s)]^+, & k_{m,n}^{t_p} = K_{m,n} \\\\\n[b_{m,n}(t_s) + a_{m,n}^e(t_s) - b_{m,n}(t_s)]^+, & \\text{others}\n\\end{cases}\n\\]\nwhere \\( a_{m,n}^g(t_s) \\) represents the new inference tasks generated in time slot \\( t_s \\). The variable \\( b_{m,n}(t_s) \\), \\( b_{m,n}^t(t_s) \\), and \\( b_{m,n}^e(t_s) \\) indicate the number of processed DNN inference tasks removed from \\( Q_{m,n}(t_s) \\), \\( Q_{m,n}^t(t_s) \\) and \\( Q_{m,n}^e(t_s) \\), respectively."}, {"title": "D. Problem Formulation", "content": "The primary objective of this paper is to minimize the long-term average energy consumption across all XR devices, while ensuring queue stability and satisfying the constraints on computational and communication resources. Given that partition decisions and resource allocations occur on two different time scales, we model this problem as a bi-level optimization problem under a dual time-scale. Let \\( k^{t_p} = {k_{m,n}, \\forall n, \\forall m} \\), \\( r(t) = {r_{m,n}(t_s), \\forall n} \\), \\( p(t) = {p_{m}(t_s), \\forall m} \\), \\( f(t) = {f_{m,n}(t_s), \\forall n, m} \\), \\( f^e(t) = {f_{m,n}^e(t_s), \\forall n, \\forall m} \\).\nProblem 1 (Bi-level Optimization Problem). The partition decision and resource allocation tasks of DNN based on dual time-scale can be formulated as a bi-level optimization problem.\n\\[\n\\min_{k^{t_p}} \\lim_{T_p\\rightarrow +\\infty} \\frac{1}{T_p} \\sum_{t_p=1}^{T_p} E^*(t_s, k^{t_p})\n\\]\n\\[\n\\min_{r(t), f(t), p(t), f^e(t)} \\lim_{T\\rightarrow +\\infty} \\frac{1}{T}\\sum_{t_s=1}^{T}\\sum_{m\\in M} [E_m^l(t_s) + E_m^t(t_s)]\n\\]\ns.t.\n\\[\nC.1: \\lim_{T\\rightarrow +\\infty} \\sum_{t_s=0}^{T} E[Q_{m,n}^l(t_s)] < \\infty,\n\\]\n\\[\nC.2: \\lim_{T\\rightarrow +\\infty} \\sum_{t_s=0}^{T} E[Q_{m,n}^t(t_s)] < \\infty,\n\\]\n\\[\nC.3: \\lim_{T\\rightarrow +\\infty} \\sum_{t_s=0}^{T} E[Q_{m,n}^e(t_s)] < \\infty,\n\\]\n\\[\nC.4: \\sum_{n\\in N_m} f_{m,n}(t_s) \\leq F_m, \\forall m\n\\]\n\\[\nC.5: 0 \\leq p_m(t_s) \\leq p_{max}, \\forall m\n\\]\n\\[\nC.6: \\sum_{n\\in N_m} r_{m,n}(t_s) \\leq R_m(t_s), \\forall m\n\\]\n\\[\nC.7: \\sum_{m\\in M} \\sum_{n\\in N_m} f_{m,n}^e(t_s) \\leq F_e,\n\\]\n\\[\nC.8: 0 \\leq f_{m,n}(t_s) \\leq Q_{m,n}^l(t_s),\n\\]\n\\[\nC.9: 0 \\leq r_{m,n}(t_s) \\leq Q_{m,n}^t(t_s),\n\\]\n\\[\nC.10: 0 \\leq f_{m,n}^e(t_s) \\leq Q_{m,n}^e(t_s),\n\\]\n\\[\nC.11: k_{m,n} \\in {1,2,..., K_{m,n}}.\n\\]\nConstraints C.1-C.3 are imposed to ensure the long-term stability of local, transmission, and edge queues, respectively. Constraints C.4-C.7 signify resource constraints at the device and server levels. Specifically, C.4 represents the limit on local computational resources available for each device m, ensuring allocations do not surpass the available resources. C.5 defines the maximum allowable transmit power for each XR device m. C.6 ensures that the allocated transmission rate for each device does not exceed the maximum transmission rate. C.7 restricts the total computational resource allocation at the MEC server, ensuring that the sum of allocated resources for edge"}, {"title": "IV. LYAPUNOV-GUIDE PROXIMAL POLICY OPTIMIZATION ALGORITHM", "content": "To address the original bi-level optimization problem, we decompose it into two sub-problems: an upper-level optimization problem and a lower-level optimization problem. In the lower-level optimization problem, the partition decisions of the DNN models are considered predetermined, and the focus is placed on jointly allocating computational and communication resources within the system. To tackle the challenges posed by the long-term queue stability constraints, we first reformulate it using the Lyapunov optimization method and subsequently solve it via convex optimization techniques. In the upper-level optimization problem, we model it as a Markov Decision Process (MDP) and employ the Proximal Policy Optimization (PPO) algorithm to find the optimal solution.\nWe define the Lyapunov functions \\( V_{m,n}^l(t_s) \\), \\( V_{m,n}^t(t_s) \\) and \\( V_{m,n}^e(t_s) \\) as quadratic functions to measure the congestion levels in the respective queues:\n\\[\nV_{m,n}^l(t_s) = \\frac{1}{2}(Q_{m,n}^l(t_s))^2,\n\\]\n\\[\nV_{m,n}^t(t_s) = \\frac{1}{2}(Q_{m,n}^t(t_s))^2,\n\\]\n\\[\nV_{m,n}^e(t_s) = \\frac{1}{2}(Q_{m,n}^e(t_s))^2,\n\\]\nCombining with (7), (8), (9), (13), (14) and (15), it can be further derived as\n\\[\n\\Delta V_m^l = \\sum_{n\\in N_m} (V_{m,n}^l(t_s + 1) - V_{m,n}^l(t_s))\n\\]\n\\[\n= \\sum_{n\\in N_m} (\\frac{1}{2}(Q_{m,n}^l(t_s + 1))^2 - \\frac{1}{2}(Q_{m,n}^l(t_s))^2)\n\\]\n\\[\n\\leq \\sum_{n\\in N_m} (Q_{m,n}^l(t_s)(a_{m,n}(t_s)C_{m,n}^{local}(t_p) - f_{m,n}(t_s)\\tau) + \\frac{1}{2} B_{m,n}^l),\n\\]\n\\[\n\\Delta V_m^t = \\sum_{n\\in N_m} (V_{m,n}^t(t_s + 1) - V_{m,n}^t(t_s))\n\\]\n\\[\n= \\sum_{n\\in N_m} (\\frac{1}{2}(Q_{m,n}^t(t_s + 1))^2 - \\frac{1}{2}(Q_{m,n}^t(t_s))^2)\n\\]\n\\[\n\\leq \\sum_{n\\in N_m} (Q_{m,n}^t(t_s)(a_{m,n}(t_s)d_{m,n}(t_p) - r_{m,n}(t_s)\\tau) + \\frac{1}{2} B_{m,n}^t),\n\\]\n\\[\n\\Delta V_m^e = \\sum_{n\\in N_m} (V_{m,n}^e(t_s + 1) - V_{m,n}^e(t_s))\n\\]\n\\[\n= \\sum_{n\\in N_m} (\\frac{1}{2}(Q_{m,n}^e(t_s + 1))^2 - \\frac{1}{2}(Q_{m,n}^e(t_s))^2)\n\\]\n\\[\n\\leq \\sum_{n\\in N_m} (Q_{m,n}^e(t_s)(a_{m,n}^t(t_s)C_{m,n}^{edge}(t_p) - f_{m,n}^e(t_s)\\tau) + \\frac{1}{2} B_{m,n}^e),\n\\]\nwhere \\( B_{m,n}^l = (a_{max}C_{m,n}^{local}(t_p))^2 + (F_m\\tau)^2 \\), \\( B_{m,n}^t = (a_{max}d_{m,n}(t_p))^2 + (R_m(t_s)\\tau)^2 \\) and \\( B_{m,n}^e = (a_{max}C_{m,n}^{edge}(t_p))^2 + (F_e\\tau)^2 \\).\nLet \\( \\Delta V_m^l \\), \\( \\Delta V_m^t \\) and \\( \\Delta V_m^e \\) to denote the Lyapunov drift, which represents the expected change of the Lyapunov function from the current queues status to the next queue status. Combine with (16), (17) and (18), the Lyapunov drift function can be given by\n\\[\n\\Delta V_m \\leq \\sum_{n\\in N_m} (V_{m,n}^l(t_s + 1) - V_{m,n}^l(t_s))\n\\]\n\\[\n= \\sum_{n\\in N_m} (Q_{m,n}^l(t_s)(a_{m,n}(t_s)C_{m,n}^{local}(t_p) - f_{m,n}(t_s)\\tau) + \\frac{1}{2} B_{m,n}^l),\n\\]\n\\[\n\\Delta V_m^t \\leq \\sum_{n\\in N_m} (V_{m,n}^t(t_s + 1) - V_{m,n}^t(t_s))\n\\]\n\\[\n= \\sum_{n\\in N_m} (Q_{m,n}^t(t_s)(a_{m,n}(t_s)d_{m,n}(t_p) - r_{m,n}(t_s)\\tau) + \\frac{1}{2} B_{m,n}^t),\n\\]\n\\[\n\\Delta V_m^e \\leq \\sum_{n\\in N_m} (V_{m,n}^e(t_s + 1) - V_{m,n}^e(t_s))\n\\]\n\\[\n= \\sum_{n\\in N_m} (Q_{m,n}^e(t_s)(a_{m,n}^t(t_s)C_{m,n}^{edge}(t_p) - f_{m,n}^e(t_s)\\tau) + \\frac{1}{2} B_{m,n}^e),\n\\]"}, {"title": "A. Solution to the lower-level problem", "content": "Given the partition point, the problem can be simplified to the following lower-level optimization problem concerning the allocation of communication and computational resources in the system.\nProblem 2 (Lower-level Optimization Problem). Assuming the partition point \\( k_{m,n}^{t_p} \\) is given, the communication and computational resource allocation problem can be expressed as follows:\n\\[\n\\min_{r(t), f(t), p(t), f^e(t)} \\lim_{T\\rightarrow +\\infty} \\frac{1}{T}\\sum_{t_s=1}^{T}\\sum_{m\\in M} [U^l E_m^l(t_s) + U^t E_m^t(t_s)]\n\\]\ns.t. C.1-\u0421.11\nDue to the long-term queue stability constraints, this problem remains challenging to solve. Therefore, we employ Lyapunov optimization to transform the problem into a series of single-slot optimization tasks, enabling tractable solutions."}, {"title": "B. Solution to the upper-level problem", "content": "To optimize energy consumption for XR devices on a large time scale and ensure queue stability", "State": "The state \\( s^{t_p} \\in S \\) represents the observation during each partition adjustment period. Specifically, it consists of the queue backlogs of the distributed queues \\( Q_{m,n}^l(t_s) \\), \\( Q_{m,n}^t(t_s) \\), \\( Q_{m,n}^e(t_s) \\), the computational complexity and feature map data associated with the current partition point \\( k_{m,n} \\), represented as \\( C_{m,n}^{local}(t_p) \\), \\( d_{m,n}(t_p) \\), \\( C_{m,n}^{edge}(t_p) \\), the computational and communication resources allocated, including \\( f_{m.n}(t_s) \\), \\( p_{m}(t_s) \\), \\( r_{m,n}(t_s) \\), \\( f_{m,n}^e(t_s) \\) and the"}]}