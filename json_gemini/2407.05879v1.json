{"title": "Learning With Generalised Card Representations for \u201cMagic: The Gathering\u201d", "authors": ["Timo Bertram", "Johannes F\u00fcrnkranz", "Martin M\u00fcller"], "abstract": "A defining feature of collectable card games is the deck building process prior to actual gameplay, in which players form their decks according to some restrictions. Learning to build decks is difficult for players and models alike due to the large card variety and highly complex semantics, as well as requiring meaningful card and deck representations when aiming to utilise AI. In addition, regular releases of new card sets lead to unforeseeable fluctuations in the available card pool, thus affecting possible deck configurations and requiring continuous updates. Previous Game AI approaches to building decks have often been limited to fixed sets of possible cards, which greatly limits their utility in practice. In this work, we explore possible card representations that generalise to unseen cards, thus greatly extending the real-world utility of AI-based deck building for the game \"Magic: The Gathering\". We study such representations based on numerical, nominal, and text-based features of cards, card images, and meta information about card usage from third-party services. Our results show that while the particular choice of generalised input representation has little effect on learning to predict human card selections among known cards, the performance on new, unseen cards can be greatly improved. Our generalised model is able to predict 55% of human choices on completely unseen cards, thus showing a deep understanding of card quality and strategy.", "sections": [{"title": "I. INTRODUCTION", "content": "Modern board and card games are popular domains for AI research due to their inherent structure and wide popularity. While super-human play has been achieved in some games such as Go, chess, DOTA and poker [1], [6], [13], many others still provide numerous obstacles. Providing additional difficulty, commercial games, and especially collectable card games such as Hearthstone [7] and Magic: The Gathering (MTG), are constantly evolving due to card changes and the release of novel content. This implies that any model for such games must be able to continuously adapt to new releases to maintain usefulness. In this work, we focus on one crucial aspect of the popular card game Magic: The Gathering; deck building. Before card play begins, players build their deck of cards by selecting from a large pool of available choices. This initial stage of the game is crucial for success, as good performance is not achievable without strong and general deck building strategies. We focus on learning a generalised model for drafting, a sub-area of deck building, in Magic: The Gathering that is readily expandable to new content and can accurately predict human decisions. To achieve this, we incorporate the contextual preference ranking (CPR) framework of Bertram et al. [2] and adapt it in several ways:\n\u2022\nThe original work on CPR is limited to a single, fixed set of cards, using a one-hot encoding to represent inputs to a Siamese neural network. We explore different generalised card representations for use in CPR, thus extending the method to arbitrary and potentially previously unseen cards.\n\u2022\nWe train a large model for drafting in Magic: The Gathering on a large, heterogeneous dataset of 100 million decisions. The model obtains general knowledge of card semantics, showing usefulness for drafting decks with new cards.\n\u2022\nWe explore fine-tuning the model to quickly adapt to newly released card sets, achieving rapid performance improvements."}, {"title": "II. RELATED WORK", "content": "We build on the contextual preference ranking (CPR) approach [2] by making it more general and widely usable, while also improving upon its overall accuracy. CPR functions by constructing preferences between choices within an explicitly stated context in which the decision was made. Data on such decisions-in-context can be coded as triplets, which are used to train Siamese neural networks (SNNs) [5]. As one such case, card drafting decisions (see Section III) in Magic: The Gathering can be regarded as preferences among the different available cards in the context of all previously chosen one. In the initial CPR research [2], this approach was shown to outperform classical fully connected neural networks [17].\nOther research on drafting, or deck building in general, is largely based on reinforcement learning or genetic algorithms [4]. For the game of Legends of Code and Magic (LOCM) [8], a simple card game developed for testing AI agents, earlier work [10], [15] separates the drafting and playing phases and learns to draft while approximating the strength of the resulting decks through heuristic-based gameplay. Such approaches depend strongly on the chosen gameplay strategies and therefore limit the depth of strategy. Later, end-to-end approaches for drafting and playing were developed [18], which led to drafting strategies decoupled from heuristics. However, in the LOCM test-bed, card complexity is low and gameplay is simple, which limits applicability to real games. Xiao et al. [19] used a similar algorithm, an end-to-end reinforcement learning agent combining card selection and gameplay, for the highly successful commercial game of Hearthstone. This approach yields impressive results and appears to be a promising direction when fast-forward game simulations are possible. However, in order to allow exploration of the enormous game space, the card pool and selection options were strongly restricted, thus limiting overall usefulness. So far, it appears that end-to-end reinforcement learning of drafting and gameplay is not yet practical for unrestricted game environments when regarding ever-changing domains. Our work combats this problem from a different angle: instead of attempting to learn extremely complex relations with no prior knowledge, we rely on human behaviour and model decisions seen in historic game data in a generalised manner.\nOverall, human players of Magic: The Gathering have shown significant interest in using drafting agents as tools to aid their decision-making. Popular tools for this task\u00b9 attempt to solve the problem though hand-constructed rules, and thus rely on humans in the design and prevent the usage of AI models. One of these employs a classical fully connected neural network trained with supervised learning [17], but received worse predictive accuracy than CPR [2]. Peer-reviewed research results on the other tools, or on independent projects\u00b2, are not available at this time. Finally, general work on card games experimented with different card representations [11], [21], opting to represent features or images of cards for classification and regression, which shows promising results."}, {"title": "III. DRAFTING IN COLLECTABLE CARD GAMES", "content": "Most collectable card games (CCG) provide two overarching modes of gameplay: Constructed and Limited. This includes commercial games such as Hearthstone, Magic: The Gathering, Lorcana or Flesh and Blood, as well as simple AI counterparts such as Legends of Code and Magic. To simplify the following explanation, we focus on Magic: The Gathering (MTG), but most rules apply to other games with minimal adaptions.\nIn constructed modes, each player independently builds a deck of at least 60 cards in advance of playing the game. Players possess mostly free rein over which cards to include in their deck, leading to an enormous space of potential configurations. Theoretically, the possible deck space is infinitely large, as no upper bound on legal card quantity exists. In practice, the vast majority of players select the smallest legal number of 60 cards to maximise the consistency of their decks by minimising the variance of drawn cards. At the time of writing, the number of unique cards to choose from ranges from 3,037 cards in the smallest version of the game to 26,524 in the largest format. Based on this, and disregarding some specifics of deck building, the number of unique decks players could potentially build lies between $\\binom{3037}{60} > 10^{126}$ and $\\binom{26524}{60} > 10^{183}$. While an enormous space, the majority of such deck compositions are impractical and high-level human competition mostly converges to fewer than 100 deck archetypes with slight individual adaptions. How one could train models that emulate such an enormous reduction in deck space remains an open research question.\nLimited games, or in this context drafts, incorporate deck building into the actual game. Before play commences, players take turns to build their decks sequentially. Players start the draft with a choice of 15 initial cards and select a single one, passing all remaining cards to the other players until all initial cards are selected. This process repeats two more times with 15 cards per player, thus leading to a total of 45 cards and 42 choices with 15 to 2 options each for every participant. Therefore, within one draft, one player's decisions result in $(15!)^3 > 10^{36}$ different possible final deck configurations. While still large, the sequential nature of decisions leads to smaller, more manageable, and largely independent tasks. In this work, we focus on such drafting environments, viewing each decision as independent and disregarding the effect of card choices on other players. As such, we solely focus on each individual choice in the context of the player's previous decisions, enabling the use of CPR."}, {"title": "IV. ADAPTING CONTEXTUAL PREFERENCE RANKING", "content": ""}, {"title": "A. Contextual Preference Ranking", "content": "Contextual preference ranking (CPR) is a framework for learning to predict the better of two choices $c_j$ and $c_k$ in the context of a set of previously made decisions $C$, formally denoted as\n$$(c_j \\succ c_k | C).$$ \nIn our setting, the context $C$ represents the (incomplete) deck of cards a player is holding, $c_j$ and $c_k$ are two possible additions to it, while the preference encodes which one of the two is a better fit to $C$.\nBertram et al. [2] tackled this problem by training a Siamese neural network (SNN) from a database of human card selection decisions. The key idea is to train a single neural network $N(.)$ that maps card sets and individual cards into a uniform embedding space by minimising the triplet loss\n$$\\mathcal{L}_{triplet}(a, p, n) = max \\left( d(a, p) - d(a, n) + m, 0 \\right)$$\nover three weight-sharing copies of the network, where the anchor $a = N(C)$ represents the embedding of the context $C$, $p = N(c_j)$ the embedding of the preferred choice $c_j$, and $n = N(c_k)$ the other choice. The parameter $m$ represents a desired margin (typically set to $m = 1$), and $d$ is a distance metric (typically the Euclidean distance)."}, {"title": "B. Input representation", "content": "In MTG, cards are released in so-called expansions or sets, which feature 200-300 unique cards. The majority of these cards are completely new and often feature new rules and mechanics. In order to generalise CPR for this type of application, we study different representations of cards and explore their advantages and disadvantages.\n1) Random vectors: Representing cards by randomly generated vectors of arbitrary size enables an infinite space of possible inputs. However, this representation prevents generalising knowledge to unseen cards and learning semantics and is thus only useful for in-sample cards. Still, we experiment with random vectors as card representations to provide insight into the importance of representation choice for seen sets. In these experiments, each unique card is encoded as a randomly generated vector of size 1024.\n2) Hand-coded features: To generalise across cards and sets, we can encode cards by their unique features, which capture the rules and semantics associated with them. Magic cards possess numerous features including numerical values, categorical features of large categories, and a card text of great importance (Figure 2). To a lesser extent, they contain an RBG image, which will be regarded in the following section. For the Features representation, we encode a card as a vector of all numerical and categorical features and append a text-embedding of the full card text generated with a sentence transformer [12].\n3) Image Representation: When simply encoding a card by its pixel-wise RGB values, no handcrafted features are required. However, this tasks the model to learn the complex semantics of a card purely from visual cognition. Text recognition from images is challenging [16] and likely leads to a loss of information compared to an explicit encoding. In addition, full-scale RGB images of cards are large (3 \u00d7 936 \u00d7 672), leading to an explosion in input size. To combat this, we train a basic convolutional autoencoder [9] to construct latent representations of card images, which can be used as compressed representations of inputs to the SNN. In our experiments, we found strong influence, both visually (see Figure 3) and numerically (see Table VI-A), of the bottleneck dimensionality on the received reconstructions. We present the results with latent space dimensionalities of 32 and 1024, finally choosing 1024 dimensions for later experiments to minimise information loss.\n4) Statistical Meta Information on Cards: Meta information about card use by human players, such as pick-rate and player win-rates when using the card, is publicly available\u00b3. Such usage information provides direct insight into human decisions for the cards involved. This is an especially useful feature when little useful context is available, e.g. when comparing similar cards, or at stages of deck building when few cards have been selected. We provide an experiment where we train a model solely on the meta-information (Table VI-A), but generally, such statistics should be viewed as additional information rather than a stand-alone encoding. Noteworthy, card statistics are only available when a set has seen sufficient server play and is thus impossible to use for entirely new sets. In our experiments, we encode statistics as a scalar vector of size 16."}, {"title": "C. Encoding networks", "content": "Regardless of the specific encoding used, adapting CPR from one-hot to generalised encodings creatures the additional challenge of deriving a representation for card decks from the representation of single cards [3]. With one-hot encodings of cards, a deck can simply be represented as the sum of card encodings without loss of information. However, with feature-based card encodings, a sum-based encoding of a deck makes it impossible to reconstruct individual cards. To prevent this, we represent a deck of cards as a two-dimensional array of size 45 x n, where 45 is the maximum number of cards in the deck and n is the representation size of individual cards. Slots for not-yet-picked cards are set to zero. When decks and cards are used as inputs to the SNN, this first requires translating them to a common representation (see Figure 4), which is achieved by adding two separate encoding networks that output 512-dimensional representations, of cards and decks respectively, to the training pipeline. These encoding networks are trained end-to-end with the SNN."}, {"title": "V. EXPERIMENTAL SETUP", "content": ""}, {"title": "A. Data", "content": "We evaluate the influence of the outlined adaptions to CPR on the accuracy of the resulting model. In addition to the changes mentioned in Section IV, the experiments feature a larger variety of card sets from different sources, collectively encoding approximately 100 million total card picks. Table I shows all used datasets along with their respective release dates and training set sizes. We used all released datasets up to and including LTR. Data of M19 is obtained from DraftSim\u2074, all other datasets are provided by 17Lands\u2075. Each dataset was split into 80% training and 20% test set. Note, that these numbers show the individual card picks. In our preference-based formulation, each pick results in 1\u201314 preferences, thus increasing the total number of triplets by almost an order of magnitude."}, {"title": "C. Siamese Neural Network configuration", "content": "As explained in Section IV-C, using CPR with generalised card representations requires separate encoding networks for cards and decks. The card encoding network uses 4 fully connected layers with 1024 neurons, connected by dropout, normalisations and ELU activations. The deck encoding network consists of 6 convolutional layers with 1 to 16 filters, normalisations, max-pooling and ELU activations with a single fully connected output layer. Both encoding networks feed into the same Siamese neural network, which uses 5 fully connected layers with 512 neurons, normalisations, dropout and ELU activations. The final layer possesses 512 outputs and uses the tangens hyperbolicus activation, thus creating a 512-dimensional embedding space of range [-1,1]. For a general overview, refer to Figure 4."}, {"title": "VI. RESULTS", "content": "Experiments in this section are split in two: Section VI-A investigates the different input encodings (see Section IV-B) and Section VI-B evaluates fine-tuning a pre-trained model on previously unseen cards, i.e. simulating the release of a new card set."}, {"title": "A. Representation", "content": "To investigate the influence of card representation (see Section IV-B) on the received models, we conduct a series of experiments with SNNs that only differ in input representation. To reduce the computational effort of this experiment, models are trained solely on the NEO set. The accuracy of the received models is reported on held-out samples of the NEO set and the average accuracy across all unseen sets. Section VI-B uses the whole dataset to maximise predictive performance and simulate real-world use."}, {"title": "B. Evaluation Measure", "content": "We use the top-1 accuracy when ranking all possible picks to evaluate the models. To create the ranking, we embed the current deck and all possible options, sort all options by their distance to the deck in the embedding space, and choose the card with the minimal distance as shown in (3). The selected card is compared to the human choice captured in the dataset, and the percentage of matching choices is reported. Note that, as this aims to predict human choices, it is generally not possible to achieve perfect accuracy, as human decisions are not necessarily correct or consistent."}, {"title": "B. Transfer", "content": "Following these experiments, the Features+Meta+Image model with the highest combined accuracy is chosen for further exploration. Our goal in this section is to model a real-world setting where a model is trained on all available card sets, and then tested on or adapted to a newly issued set of cards. To test this ability of transferring obtained knowledge to new card sets, we use all but one of the datasets listed in Table I for training. On one hand, we can expect to improve the overall performance of the model by increasing training set size and card heterogeneity, and on the other hand, this experiment is also meant to simulate the intended application scenario. To simulate a new card set being released, we hold out a single set of cards (BRO), reporting accuracy on held-out test sets by averaging across all seen sets and explicitly reporting the test set performance on NEO and BRO.\nAs expected, by simply increasing the sample quantity (75 million instead of 5 million) and unique card variety (2,990 cards instead of 302), the general accuracy of the model increases considerably (see Table VI-B). Although performance on the seen sets is comparable to the previous results, the model Pre-training, which is the same model as Features+Meta+Image 1024 but trained on more data, achieves 55.44% accuracy on the unknown BRO set. Splitting the received accuracy over all sets and picks (Figure 5), we see similar patterns on all sets, regardless of whether the model was trained on it or not. The accuracy of picks at the start and end of each pack is higher, while picks in the middle appear more difficult. Compared to previous work with CPR [2], the accuracy on M19 is improved by more than 2 percentage points.\nBuilding on this, we explore fine-tuning or transfer learning [20], with the model on two individual sets, NEO and BRO. When fine-tuning, the large corpus of training data is replaced with a single set of cards, thus aiming to use previously obtained general knowledge for a smaller task. For our experiment, a model is initialised with the parameters obtained from pre-training on the large corpus and trained exclusively on NEO and BRO without further adjustments to the training process, omitting freezing layers or other attempts to retain knowledge.\nThe two fine-tuning settings serve different purposes. When fine-tuning on NEO, no new data or cards are seen. Rather, the training data is reduced to decrease the task complexity, thus gaining the opportunity to improve the accuracy. Using BRO to fine-tune replaces previous data with unseen cards, thus investigating whether the model can quickly adjust to new information, simulating the release of a new set of cards in real applications."}, {"title": "VII. VISUALISATION", "content": "Although this work mainly aims to explore card representation and general accuracy of results when using CPR to learn a universal drafting model, CPR provides the inherent advantage of an intuitively interpretative embedding space because all model predictions are directly based on minimising distances. As the embedding space is high-dimensional, we use TSNE [14] to compute a 2-dimensional approximation (see Figure 6) and separately plot each set of cards. Each card is plotted with its respective colour in the game (see Figure 2), one of the most defining features. For this plot, the Pre-training model from Section VI-B is used, but all strong models provide similar visualisations.\nHighly intuitive clusters emerge in this embedding space. All colours are grouped together and multicoloured cards, visible as either two-coloured points with different borders or as golden points for more than two colours, are placed between their respective colours. All plots feature 5 points at large distance from the main plot, which are the 5 cards included in every set that provide no value to gameplay and should thus never be picked. Interestingly, the BRO set, which consists of unseen cards for the model, exhibits similar structures as the sets which were used for training, indicating a clear semantic understanding of cards."}, {"title": "VIII. CONCLUSION", "content": "In this work, we generalised the contextual preference ranking framework [2] by extending it to novel card representations. The key idea is to replace the previously utilised one-hot encodings with card features, text-embeddings and auto-encoded image compressions of Magic: The Gathering cards. Following CPR, the card representations are mapped into a high-dimensional embedding space using Siamese neural networks, in which distances model the relationship between cards and decks. We find that the input representation is largely irrelevant when modelling singular, fixed sets. In such cases, where data for all cards is available, all models with reasonable inputs perform similarly well. However, large discrepancies in accuracy emerge when aiming to understand card semantics, e.g. when predicting decisions with previously unseen cards, a common occurrence when new sets are released. Here, we find that hand-engineered features of cards, combined with meta-statistics and auto-encoded images, lead to the highest generalisation capabilities and provide quick fine-tuning opportunities when new data is available. Additionally, we find that our new representation outperforms previous research on the same dataset."}]}