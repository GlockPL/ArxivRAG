{"title": "HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals", "authors": ["Lingbo Mo", "Shun Jiang", "Akash Maharaj", "Bernard Hishamunda", "Yunyao Li"], "abstract": "Task-Oriented Dialogue (TOD) systems assist\nusers in completing tasks through natural lan-\nguage interactions, often relying on a single-\nlayered workflow structure for slot-filling in\npublic tasks, such as hotel bookings. How-\never, in enterprise environments, which involve\nrich domain-specific knowledge, TOD systems\nface challenges due to task complexity and\nthe lack of standardized documentation. In\nthis work, we introduce HierTOD, an enter-\nprise TOD system driven by hierarchical goals\nand can support composite workflows. By fo-\ncusing on goal-driven interactions, our system\nserves a more proactive role, facilitating mixed-\ninitiative dialogue and improving task comple-\ntion. Equipped with components for natural lan-\nguage understanding, composite goal retriever,\ndialogue management, and response genera-\ntion, backed by a well-organized data service\nwith domain knowledge base and retrieval en-\ngine, HierTOD delivers efficient task assistance.\nFurthermore, our system implementation uni-\nfies two TOD paradigms: slot-filling for infor-\nmation collection and step-by-step guidance for\ntask execution. Our human study demonstrates\nthe effectiveness and helpfulness of HierTOD\nin performing both paradigms.", "sections": [{"title": "Introduction", "content": "Task-oriented dialogue systems aim to help users\naccomplish specific goals by executing tasks\nthrough natural language interactions. Signifi-\ncant advancements have been made in develop-\ning systems that support public domain tasks (Andreas et al., 2020; Peng et al., 2021; Su et al.,\n2022), such as booking hotels or reserving restau-\nrants. These tasks typically feature straightfor-\nward, single-layered workflows with well-defined\nsteps, intents, and information extraction require-\nments. However, in enterprise environments rich\nwith domain-specific knowledge, TOD systems\nface unique challenges due to the complexity and\nlack of standardized documentation of tasks.\nEnterprise tasks often involve multi-layered\nstructures composed of numerous interconnected\nsubtasks, as illustrated in Figure 1. These tasks are\nrarely formally documented, and their execution\nheavily relies on the implicit knowledge of human\nexperts. When users interact with a dialogue sys-\ntem in such contexts, their utterances can pertain\nonly to atomic tasks defined at the leaf nodes of a\ncomplex task hierarchy. The overarching structure\nand sequence of these tasks remain internalized\nwithin the user's expertise, making it difficult for\ndialogue systems to fully comprehend and assist\neffectively.\nConsider, for instance, an enterprise market-\ning platform equipped with audience segmentation\nfunctionality. Users within an organization may in-\ndependently create many client profile segments for\nvarious projects. Over time, this practice can result\nin the proliferation of duplicate segments, increas-\ning platform resource costs and reducing business\nefficiency. To mitigate this, users perform data hy-\ngiene processes to clean up and consolidate these\nduplicate segments. However, the formal steps for\nthis process are typically undocumented, and prac-\ntices vary across different organizations. With guid-\nance from subject matter experts, the complex task\nof identifying and removing duplicate segments\ncan be distilled into a high-level goal comprising\nfour sequential steps:\nIn practice, different users may prioritize certain\nbusiness entities over others and follow various\npaths through this task hierarchy when interacting\nwith the dialogue system. Their intents correspond\nto atomic actions represented as nodes within a\ntask graph, and the sequences connecting these\nnodes can vary significantly. A dialogue system\nwith a deep understanding of these high-level busi-\nness goals and the complex structure of such tasks\ncan significantly enhance user experience. It can\nimprove query comprehension, disambiguate user\nintents more effectively, proactively suggest rele-\nvant goals, and provide personalized responses that\nalign with individual user needs.\nTo this ends, we introduce HierTOD, an enter-\nprise TOD system driven by hierarchical goals to\nfacilitate the generation of more proactive and ef-\nfective dialogues with users. For example, when\na user inquires about detecting duplicate segments\n(as described in the first step of the previous case),\nHierTOD can proactively suggest transitioning to\nthe high-level goal of conducting data hygiene for\naudience segments. Our system comprises sev-\neral modules, including natural language under-\nstanding, composite goal retriever, dialogue man-\nagement, and response generation, supported by a\nwell-organized data service with a domain knowl-\nedge base and retrieval engine.\nFurthermore, existing TOD systems typically fol-\nlow one of two paradigms, which are often devel-\noped separately. The first is slot-filling for informa-\ntion collection (Yang et al., 2021; Hu et al., 2022;\nHude\u010dek and Du\u0161ek, 2023), where users provide\ndetails and direct the system to perform specific\ntasks, such as making reservations. The second\nparadigm is step-by-step guidance, designed to as-"}, {"title": "2 System Design", "content": "2.1 System Overview\nHierTOD follows a canonical pipeline approach for\nTOD systems. The system consists of Natural Lan-\nguage Understanding (NLU), Dialogue Manage-\nment (DM), and Response Generation (RG). A key\nfeature of our system is the introduction of a Com-\nposite Goal Retriever (CGR) which builds a goal\nrepository to define and store workflows for goal\ncompletion. Upon receiving user input, the NLU\nmodule (Section 2.2) preprocesses the utterance\nto determine the user's intent. The CGR module\n(Section 2.3) then matches the user query against\nthe workflows in the goal repository to identify the\nappropriate dialogue paradigm, whether slot-filling\nfor information collection or step-by-step guidance\nfor task execution. Once a goal is initiated, the DM\nmodule (Section 2.4), which is designed as a hier-\narchical finite state machine, controls the dialogue\nflow, handles exceptions, and guides the conver-\nsation toward task completion. The RG module\n(Section 2.5) then generates responses or answers\nuser queries based on intent and dialogue history.\nIt is supported by a well-organized data service,\nincluding a domain-specific knowledge base and\nretrieval engine, which connects to various sources\nto provide optimal user assistance. We describe the\ndetails for each module in the following sections."}, {"title": "2.2 Natural Language Understanding", "content": "HierTOD employs a robust NLU module which\ncombines the strengths of both trained models and\nrule-based approaches. The key component is In-\ntent Recognition, where we organize multiple in-\ntents into three categories to accommodate different\nuser initiatives, as detailed in Table 1. To categorize\ndifferent types of queries, we train a three-way clas-\nsification model to classify user queries as either\nproduct knowledge, operational insights, or out-\nof-scope questions. For other intents, we utilize\nheuristics and keyword lists for recognition."}, {"title": "2.3 Composite Goal Retriever", "content": "We define the workflow for hierarchical goal com-\npletion in our dialogue system, as illustrated in\nFigure 1. Specifically, a high-level goal consists of\nmultiple sub-goals that can transition from one to\nanother based on how the conversation proceeds.\nEach sub-goal may involve various types of QA\ninteractions and navigation instructions. To this\nends, we establish and maintain a repository that\ndefines workflows for various goals using a YAML\nstructure. Each workflow includes a high-level goal\ndescription, followed by a series of steps to achieve\nthat goal. Each step contains a summary, along\nwith a detailed explanation of the actions required\nfor completion. Based on the user's query, we em-\nploy a CGR module that matches the query to the\ngoals defined in the repository, using both lexical\nand semantic matching, to determine whether a\ngoal is triggered, and if so, which goal is activated.\nAdditionally, the goal repository accommodates\nboth dialogue paradigms: slot-filling for infor-\nmation collection and step-by-step guidance for\ntask execution. To distinguish between the two\nparadigms, we introduce the keyword \u201cslots\u201d to\nspecify the information required for task comple-\ntion. For example, when the user would like to\ncreate a ticket on the enterprise platform for as-\nsistance, the necessary slots might include \"ticket\ntitle\", \"detailed ticket description\", \"priority\", and"}, {"title": "2.4 Dialogue Management", "content": "We design a hierarchical finite state machine for\nthe dialogue management component, consisting\nof two phases: Goal Pending and Goal Execution.\nEach phase contains multiple fine-grained dialogue\nstates. In the Goal Pending phase, users interact\nwith HierTOD by issuing a query. If the query\nmatches a high-level goal in the Goal Repository\n(e.g., \"How to perform data hygiene to delete du-\nplicate audience segments?\"), the system provides\nan overview of the task, summarizing the upcom-\ning steps, and then enters into the Goal Execution\nphase to guide the user step by step.\nIf the query matches a sub-goal (e.g., \u201cList the\nduplicate segments for me.\u201d), the system provides\nan answer to the sub-goal and proactively asks\na clarifying question for goal transition, such as,\n\"Would you like to delete the duplicate segments?\"\nIf the user agrees to pursue the proposed high-level\ngoal, they move to the Goal Execution phase un-\ntil task completion. The initial step related to the\nmatched sub-goal is skipped, as it has already been\naddressed. When the user query does not trigger\nany goal from the repository, the system utilizes\nthe QA module to provide an appropriate response.\nAdditionally, during the Goal Execution phase, the\nQA module remains available to support the user\nwith relevant questions.\nDialogue State Tracking. For the step-by-step\nguidance dialogue paradigm, we use the hierarchi-\ncal state machine mentioned above to keep track\nof the states throughout the conversation. In order\nto further support the slot-filling paradigm, we em-\nploy zero-shot learning using GPT-3.5 (OpenAI,\n2022) to perform dialogue state tracking (DST). In\nthe designed prompt, general instructions are pro-\nvided to capture values for the required slots based\non both the dialogue history and the current user\nutterance (see Appendix A.1 for the exact prompt).\nThe updated belief state is then utilized in the sub-\nsequent response generation component described\nin Section 2.5.\nDialogue Policy. The dialogue policy takes in-\nputs from the NLU and CGR modules, synchro-\nnizes with the hierarchical state machine to query\nand update the task step state for step-by-step guid-\nance dialogues. It also interacts with the DST to"}, {"title": "2.5 Response Generation", "content": "Our response generation module blends both\ninfilling-based methods and neural models. For\nthe step-by-step guidance dialogue paradigm, we\nuse handcrafted conditional rules to organize cu-\nrated templates and define their composition strat-\negy according to the high-level states in our hierar-\nchical state machine. For the slot-filling dialogue\nparadigm, we utilize the belief state from the DST\nmodule and make an LLM call to GPT-3.5. This\ncan generate either a question to request missing\nslots or a summary to conclude the task when all re-\nquired slots have been filled. The designed prompt\nincludes the task description, belief state with filled\nand missing slots, dialogue history, and current\nuser utterance, instructing the model to generate\nan appropriate response (see Appendix A.2 for the\nexact prompt).\nIn parallel, we develop a QA module to provide\nanswers when users have questions during goal ex-\necution. As mentioned earlier, we first implement\na routing model\u2014a three-way classifier\u2014that cat-\negorizes user questions into product knowledge,\noperational insights, or out-of-scope inquiries. For\nout-of-scope questions, we provide a predefined\ntemplate response. The handling of the other two\ntypes of questions is detailed in the following parts."}, {"title": "Product Knowledge QA.", "content": "Product knowledge\nrefers to concepts and topics grounded in the prod-\nuct documentation. Product knowledge questions\ncan be further specified into the following sub-\ngroups, including pointed learning, open discovery,\nand troubleshooting. The Product Knowledge QA\ncomponent identifies the relevant documentation to\nanswer a given question, retrieves the appropriate\ncontent, generates a response based on the retrieved\ninformation, determines proper source citations,\nand verifies that the responses are well-grounded."}, {"title": "Operational Insight QA.", "content": "Operational insights\nrefer to the information about metadata ob-\njects such as attributes, audiences, dataflows,\ndatasets, destinations, journeys, schemas, and\nsources including counts, lookups, and lineage\nimpact. For example: \"How many datasets do\nI have?\" or \"How many schema attributes have\nnever been used?\u201d The Operational Insights QA\ncomponent translates a given question into a SQL\nquery against the underlying customer-specific op-\nerational data, generates the appropriate answer\nbased on the query results, and provides explana-\ntions for both the query and the returned answer."}, {"title": "2.6 NL2Goal Translator", "content": "To further simplify the goal workflow creation pro-\ncess, we develop an automatic NL2Goal transla-\ntor powered by in-context learning using GPT-3.5.\nThis module takes a manually crafted goal descrip-\ntion in natural language and translates it into a\nstructured goal definition, which is then stored in\nthe composite goal repository in YAML format. By\nautomating the creation of composite goals, this\napproach enhances the flexibility to expand and\nmodify the goal repository, making it more feasible\nto adopt our goal-driven dialogue generation sys-\ntem in knowledge-rich domains at enterprise scale.\nThe exact prompt for this module can be found in\nAppendix A.3."}, {"title": "3 User Study", "content": "To evaluate the performance of our dialogue gen-\neration system, we conduct a user study involv-\ning five annotators. Each annotator was tasked\nwith reviewing 20 dialogues between a user and\nan AI assistant. These dialogues cover a variety of\ntasks, including product platform operations, trou-\nbleshooting issues, and general activities such as\nbooking a restaurant or hotel."}, {"title": "4 Conclusion", "content": "In this work, we introduce HierTOD, a modular\ntask-oriented dialogue system designed to assists\nusers in completing tasks within enterprise envi-\nronments. Our system features a comprehensive\nset of modules, and adopts a goal-driven approach\nto dialogues, making it more proactive and en-\nabling mixed-initiative interactions. Furthermore,\nwe implement a unified framework that integrates\ntwo representative TOD paradigms including slot-\nfilling for information collection and step-by-step\nguidance for task execution. Results from our hu-\nman study confirm the effectiveness and helpful-\nness of our dialogue system."}, {"title": "A Prompt Design", "content": "A.1 Prompt for Dialogue State Tracking\nCapture entity values from last utterance of the conversation according to\nexamples.\nCapture pair \"entity: value\" separated by colon and no spaces in between.\nFormat the output in JSON.\nIf not specified, leave the value empty. Values that should be captured are:\n{slots}\n### Here is the conversation between user and ai-assistant:\n{chat_history}\n<<user>>: {current_utterance}\nCapture all the entity values based on the conversation above and format the\noutput in JSON:\nA.2 Prompt for Response Generation\nYou are a task-oriented dialogue system designed to assist users in completing\nspecific tasks such as booking a hotel or booking a flight. Your goal is to\ngather all necessary information (slots) required to complete the task through\na series of user interactions. If all required slots are collected, you\nshould confirm that the task has been completed.\n### Task:\n{task}\n### Filled Slots:\n{filled_slots}\n### Missing Slots:\n{missing_slots}\n### Here is the conversation between user and ai-assistant:\n{chat_history}\n<<user>>: {current_utterance}\n### Requirements:\n1. If there are remaining slots that need to be filled, generate a polite and\ncontextually appropriate utterance to request the next missing piece of\ninformation from the user. Ask one missing slot at a time.\n2. If all required slots have been filled, briefly summarize all the collected\nslot information without asking the user any questions.\n3. If the user asks a question, exactly start the placeholder <ANSWER> as the\nresponse, followed by a polite and contextually appropriate utterance to\nrequest the next missing piece of information from the user.\nGenerate an contextually appropriate user-facing utterance based on the current\ntask, slot information and the conversation. The generated utterance should be\nfriendly, polite, and positive.\n<<ai-assistant >>:\nA.3 Prompt for NL2Goal Translator\nGiven a paragraph that describes a specific goal and its associated workflow,\nyour task is to generate a YAML snippet that structures the information into a\nlist of steps. Each step should include a \"name\" field summarizing the step\nand a \"description\" field for explaining additional details. Ensure that the\nstep numbers in the YAML snippet are consistent with the numbers in the\nworkflow.\n### Example:\nI have a goal to resolve an issue where the data pipeline is failing at the\ntransformation stage. The workflow to address this involves the following\nsteps: first, investigate the transformation logic to ensure all mappings and\ntransformations are correct; second, verify that the data sources are\nproviding complete and accurate data; and third, check the pipeline logs for\nany errors that might indicate issues during the transformation process.\nThe corresponding YAML should look like this:\nworkflow:\ngoal: \"Resolve the issue where the data pipeline is failing at the\ntransformation stage.\"\nsteps:\n### Task:\nname: \"Investigate the transformation logic.\"\ndescription: \"Ensure that all mappings and transformations are correct.\"\nname: \"Data verification.\"\ndescription: \"Verify that the data sources are providing complete and\naccurate data.\"\nname: \"Check for errors.\"\ndescription: \"Look for any errors in the pipeline logs that indicate\nissues during transformation.\"\n{new_goal}\nGenerate the corresponding YAML snippet:"}]}