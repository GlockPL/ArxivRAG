{"title": "NAVIGATING SHORTCUTS, SPURIOUS CORRELATIONS, AND CONFOUNDERS:\nFROM ORIGINS VIA DETECTION TO MITIGATION", "authors": ["David Steinmann", "Felix Divo", "Maurice Kraus", "Antonia W\u00fcst", "Lukas Struppek", "Felix Friedrich", "Kristian Kersting"], "abstract": "Shortcuts, also described as Clever Hans behavior, spurious correlations, or confounders, present a\nsignificant challenge in machine learning and AI, critically affecting model generalization and robust-ness. Research in this area, however, remains fragmented across various terminologies, hindering the\nprogress of the field as a whole. Consequently, we introduce a unifying taxonomy of shortcut learning\nby providing a formal definition of shortcuts and bridging the diverse terms used in the literature. In\ndoing so, we further establish important connections between shortcuts and related fields, including\nbias, causality, and security, where parallels exist but are rarely discussed. Our taxonomy organizes\nexisting approaches for shortcut detection and mitigation, providing a comprehensive overview of\nthe current state of the field and revealing underexplored areas and open challenges. Moreover, we\ncompile and classify datasets tailored to study shortcut learning. Altogether, this work provides a\nholistic perspective to deepen understanding and drive the development of more effective strategies\nfor addressing shortcuts in machine learning.", "sections": [{"title": "1 Introduction", "content": "Deep learning (DL) has achieved remarkable advancements in recent years, with state-of-the-art models demonstrating\nsuperhuman performance in games like chess [167] and Go [166] as well as versatile language systems capable of\naddressing diverse tasks in zero- or few-shot settings [135; 181]. Despite these impressive achievements, DL models\noften rely on shortcuts, leading to unexpected failures when applied in real-world settings [60].\nOverreliance on specific training artifacts can cause these failures, as they do not generalize to data without these\nartifacts anymore. This phenomenon can take various forms and occur in many settings: In medical applications such as\ndiagnosing pneumonia or dementia, models have been shown to depend on irrelevant factors like hospital identifiers or\nimage quality rather than medically significant features [215; 26]. Image classification models have mistakenly relied\non embedded photographer tags [94] or struggled to identify animals in unusual environments [19]. Models predicting\nproduct quality from sensor data in sheet metal manufacturing prioritized irrelevant production speed instead of critical\napplied forces [88]. For sentiment classification, models have used superficial cues such as stop-word distributions\ninstead of focusing on semantically meaningful content [110]. Even large language models (LLMs) have been found to\nrely on undesired biases from the input data, negatively impacting their fairness [212; 58]. To discuss the underlying\nissue in more detail, let us introduce a running example that will serve as a reference throughout this work"}, {"title": "2 Shortcuts and their Origin", "content": "To establish a foundation for our taxonomy, we first provide a formal definition of shortcuts in the context of machine\nlearning. Following this, we identify under which circumstances they tend to emerge. We start with establishing a\ncommon notation of data, features and correlations as a basis for the definitions.\nData. Let us assume there is a ground-truth distribution of observational data $P_{gt}(x)$. The samples from the ground-\ntruth $x \\sim P_{gt}(x)$ consist of multiple features from a joint feature set $F = \\{f_i\\}_{i=1}^n$, such as raw pixels or higher-level\nattributes like the wing color of a bird. Unfortunately, this ideal distribution is not available in practice. Instead, one\ncan merely observe a distorted view $P(x) \\approx P_{gt}(x)$ of the ground truth. A specific dataset $D = \\{x_i\\}_{i=1}^N$ available for\na machine learning task then consists of samples $x_i \\sim P(x)$. Importantly, the sampling process follows the distorted\ndistribution $P(x)$ instead of $P_{gt}(x)$. In the following, we assume that there are no errors introduced in sampling from\n$P(x)$ and potential sampling errors occur due to the difference between $P(x)$ and $P_{gt}(x)$.\nFeatures and Correlations. Assume we have such a dataset $D$ and a specific task $T : F_{input} \\rightarrow F_{target}$, mapping from an\ninput set $F_{input} \\subseteq F$ to a target set $F_{target} \\subseteq F$ of features, where $F_{input} \\cap F_{target} = \\emptyset$. We model correlations between\nfeatures in the dataset through a symmetric correlation function $c : F \\times F \\rightarrow [0, 1]$, indicating that two features $f_i$ and\n$f_j$ are more correlated if $c(f_i, f_j)$ is closer to 1. Within the context of machine learning, we are specifically interested\nin correlations related to the task, i.e., correlations between $f_i \\in F_{input}$ and $f_j \\in F_{target}$. There are different ways to\nmeasure whether two features are correlated. The most common one is the Pearson correlation coefficient [157] for\nlinear relationships, but others like Spearman's [128] or Kendall's [1] rank correlation coefficient can also be used. In\nthe following, if the specific type of correlation is relevant, it is specifically mentioned.\nSpurious Correlations and Shortcuts. Given task $T$, some input features are considered relevant to solve the task (in\nthe intended way), which we denote as $F_{relevant} \\subseteq F_{input}$. Correlations $c(f_i, f_j)$ between non-relevant $f_i \\notin F_{relevant}$ and"}, {"title": "2.1 World-Induced Shortcuts", "content": "The world is full of correlations, and determining which are relevant and which are spurious can be challenging [168].\nIn our example of distinguishing landbirds from waterbirds, we established that the correlation between the bird's\nhabitat (background) and the landbird/waterbird classification is spurious and that a model should focus on the bird's\ncharacteristics instead. This approach assumes that we want the model to classify the bird type based on its features.\nAlternatively, we might want the model to make this decision based on the bird's habitat rather than the bird's features.\nIn that case, the background features are relevant, while the correlation between bird features and the target would be\nspurious. We call these spurious correlations world-induced.\nWhile, general world knowledge can aid to distinguish between relevant and spurious features, considering the specific\ntask remains important, as it directly influences which features and correlations are relevant [122]. This origin of\nshortcuts, i.e., naturally occurring but unwanted correlations, is sometimes also called world bias [176]."}, {"title": "2.2 Sampling-Induced Shortcuts", "content": "When using a dataset for machine learning, it never represents the ground-truth world distribution $P_{gt}(x)$ precisely.\nAs a result, datasets may contain correlations that do not exist in the ground-truth distribution, which we refer to as\nsampling-induced arising from the distorted sampling process. Generally, these induced correlations are spurious\nsince they do not reflect causal relationships but occur due to errors in the data collection. In the machine learning\ndatasets, such errors can, for example, occur due to careless data scraping [198; 21; 193], particularly in large-scale,\nautomatically scraped web datasets.\nAt a high level, all sampling-induced spurious correlations can be traced back to selection bias [196], where the\nsampling process does not draw samples completely random from the ground-truth distribution. More specifically,\nerrors may arise from over- or underrepresenting specific relationships between features in the data due to sampling\nbias [120] or representation bias [98]. Moreover, measurement errors can induce other unintended correlations, often\nreferred to as measurement bias [176].\nMost of the time, these induced spurious correlations are not intentionally included in the data, which we refer to as\naccidental spurious correlations. Conversely, it is also possible that shortcuts in datasets are intentional. From an\nadversarial perspective, dataset manipulations known as data poisoning [17] may introduce spurious correlations that\nare not present in the ground-truth distribution. In addition to data poisoning, there are benign, intentionally induced\nshortcuts. Model watermarking [4; 23] is one such application, used to mark model ownership or to link generated\ncontent to a specific source [54; 83]. Another benign appearance of induced spurious correlations involves research\ndatasets specifically designed to evaluate an algorithm's robustness to such correlations (cf. Sec. 7)."}, {"title": "2.3 Why Do Models Learn Shortcuts?", "content": "In most cases, spurious correlations exist alongside relevant correlations in the data. In these cases, it is theoretically\npossible for models to rely only on the relevant features instead of the shortcuts. However, models frequently end up\nusing these shortcuts [140]. So, why does this happen?\nFirst of all, a model's task is generally not precisely defined [15]. For example, whether it's a coarse label image\nclassification or next-token prediction in language models, ML models are typically trained using empirical risk\nminimization (ERM) on proxy tasks optimized through loss-based optimization. These task formulations do not prevent\nmodels from using shortcuts. For instance, if a model is trained to distinguish waterbirds from landbirds, it receives\nonly images and labels without explicit information about what defines each bird type. The broad task definitions do\nnot specify how the task should be solved, thus enabling the model to rely on shortcuts rather than relevant features."}, {"title": "3 Establishing the Building Blocks of our Taxonomy", "content": "Although the concept of shortcuts has been known for a long time, it has never been studied from a wholesome\nperspective. In addition to inconsistent terminology, most work has been very problem-focused or task-specific.\nHowever, shortcuts are an important problem that must be tackled from a general perspective. Hence, we establish the\nfirst taxonomy of shortcut learning, a detailed overview of the topic to help the research community advance shortcut\nlearning. In the following, we begin with an overview of related work before establishing connections between shortcuts\nand other machine-learning areas. By integrating these perspectives, we lay the foundation for a unified taxonomy in\nthe next section."}, {"title": "3.1 Related Work", "content": "While there are numerous works introducing methods to detect or mitigate shortcuts, only a handful of surveys exists\nTab. 1. From these, none covers shortcut learning in a comprehensive way. The existing surveys mostly focus on\nspecific areas: vision [57; 66], medical images [16] or language [48; 71] and only focus on work under a specific term:\nshortcut [57; 16; 48; 71; 61], spurious correlation [210] or confounder [66]. While these surveys provide a valuable\nresource in their specific setting, neither is suitable as a general overview over the field of shortcut learning. To bridge\nthis gap, our work does confine itself to specific target areas and does not focus on specific terms. Instead our introduced\ntaxonomy provides for the first time a general and unifying view on shortcut learning.\nBeyond the lack of comprehensive surveys, the terms shortcut, spurious correlation and Clever Hans behavior are\ngenerally used informally. To unify the field and understand the differences between individual terms and works, a\nformal definition is essential. Our definition bases on the description of shortcuts by Geirhos et al. [60], which describes\na shortcut as an unintended solution that still performs well on the training data, so essentially a solution that relies on\nunintended features. While this captures the essence of shortcuts quite well, it is insufficient to discuss all different\nterms. Thus, our given definition explicitly covers the origins of shortcuts, relating them with spurious correlations.\nFurther, the more detailed formulization also captures the relation between shortcuts and confounders (cf. Sec. 3.3\nbelow).\nThe most formalized definition of spurious correlations in the field comes from Ye et al. [210]. They define a correlation\nas spurious if it is between a non-predictive input feature and a target feature. While their approach reflects the\nperspective of group-robustness optimization [150], it does not cover all instances of spurious correlations; there can\nalso be spurious correlations with a correlation coefficient of one. The strength of the correlation should not determine\nwhether it is spurious or not. In contrast, our definition explicitly covers the origin of spurious correlations and the"}, {"title": "3.2 From Animal Psychology to Machine Learning: The Clever Hans Phenomenon", "content": "The term Clever Hans originates from animal psychology, named after the famous horse Hans that apparently had\nlearned to understand human language [153]. After careful examination, it turned out that Hans learned to rely on the\nsubtle facial expressions of the humans asking the questions and was unable to answer when not seeing the human face.\nTo solve its task, the facial expressions were shortcuts, which Hans learned to utilize.\nBased on this story, the term Clever Hans has also been adopted outside of animal psychology to describe the usage\nof unintended cues to solve a task. In the context of machine learning, this corresponds to models learning to rely on\nshortcuts in the training data instead of the relevant features [94]. Clever Hans behavior has been shown to occur in\nvarious tasks, e.g., in classification [169] or anomaly detection [80]. While Clever Hans behavior is seldomly formalized,\nit corresponds to our definition of a shortcut."}, {"title": "3.3 Shortcuts and Confounders from a Causality Perspective", "content": "Spurious correlations and shortcuts are inherently connected to the field of causality. One of the most general definitions\nof a spurious correlation is \"a correlation which does not imply causation\", which is relevant in causality because it\naffects learning about genuine causal effects [136]. In the context of causality, the term confounder appears regularly as\nwell. To explain how these terms are connected, let us again consider the waterbird example (Fig. 3). In this context, we\nhave only talked about spurious correlations and intended correlations so far, but we have not talked about actual causal\nrelationships. Let us assume that a bird's characteristics, i.e., its appearance and abilities, cause both its environment (as\nthey influence where a bird usually lives) and whether it is considered a landbird or waterbird. In this case, the bird's\ncharacteristics are a confounder: As they cause both the environment and the target label, they are the source of the\nspurious correlation between both.\nWe note that while most machine learning mainly considers identifying correlations and does not model explicit causal\nrelations, this causal perspective can provide valuable insights regarding the origin of spurious correlations. Particularly\nworld-induced spurious correlations can originate from observed or hidden confounders. Moreover, avoiding and\naddressing confounders is necessary for estimating causal effects, which has a long history in causal inference [121]\nand epidemiology [124]. Thus, causal analysis can provide powerful tools to detect and mitigate confounders and the\nresulting spurious correlations.\nMoreover, the problem of shortcuts can even go beyond confounders in causality. Consider a simple causal graph with\nthree variables: $A \\rightarrow B \\rightarrow C$. If the relation $B \\rightarrow C$ is a simple linear correlation, we can predict $B$ from $C$. While\nthis can serve as a reasonable correlation basis for predictions in most cases, using $C$ as a basis to predict $B$ is not\nreliable when $B$ is intervened. On. Similarly, it would be possible to predict $C$ from $A$, which again is not reliable if\n$B$ is intervened on. So, while addressing confounders is a helpful tool in combatting spurious correlations, it is not\nnecessarily sufficient to mitigate all potential shortcuts.\nFinally, it is noteworthy that the term confounders in most ML research is used with a different meaning than the\n\"causal\" confounder described above. Some papers rather use \"confounder\" as a synonym for shortcuts and, in particular,\nthe shortcut features [160; 223; 214]. To keep terminology clear and avoid confusion, we recommend to rather use the\nterm shortcut in these circumstances and refer to the term confounder for its causal meaning."}, {"title": "3.4 The Role of Distribution Shift in Shortcut Learning", "content": "When a model has learned a shortcut, it relies on some specific and unintended features to solve its task. This\nbecomes particularly problematic when these features change or are no longer present in the data, as the model then\nmakes incorrect predictions. Distribution shifts can be one of the main reasons why features change, and shortcuts\ndo not work anymore. On the contrary, models that are robust to distribution shifts tend also to be more robust to\nshortcuts, particularly against sampling-induced ones, as they rely on more robust features [225]. Another way to utilize\ndistribution shifts in the context of shortcut learning is to detect shortcuts. When comparing model performance on\nthe initial data distributions and several shifted versions, potential sources for performance degradation are shortcuts\n[194]. Overall, the field of shortcut learning can benefit from the research on distribution shifts both to detect potential\nshortcuts and to develop more robust models, thus mitigating the reliance on shortcuts."}, {"title": "3.5 Bias as a Potential Origin of Shortcuts", "content": "The term bias is broadly used in discussions about machine learning models and datasets, particularly regarding fairness\n[120]. As bias is used in many different contexts and with different meanings, it is difficult to give an exact definition.\nInformally, however, bias can be described as a model having a tendency toward specific factors, which are often\nirrelevant or undesired, such as a credit scoring system relying on race or gender. The term also regularly appears in the\nfield of shortcut learning as several works refer to spurious correlations as dataset biases (e.g., [81; 158; 206; 142; 111]).\nFurther, biases are an important reason why spurious correlations occur in datasets. Inducing spurious correlations\nthrough a (distorted) sampling process is often known as sampling or selection bias [196], representation bias [98]\nor measurement bias [176]. We discuss these biases as an origin for shortcuts in detail in Sec. 2.2. However, not all\nbiases stem from the data selection and sampling process. Biases that reflect patterns in the world are often termed\nhistorical biases [176] and can be seen as correlations in the ground-truth distribution $P_{gt}(x)$ that we may not want a\nmodel to reflect [101; 70]. Although the reasons for not reflecting these correlations in a model might be different from\nthe reasons described in Sec. 2.1, the differences from a technical perspective are small. This opens the use of shortcut\nmitigation techniques to address biases, such as mitigating gender bias [222]. While this work primarily focuses on\ntechniques to mitigate shortcuts and spurious correlations, many strategies from bias mitigation can be adapted to this\npurpose. Vice versa, the methods we present to mitigate shortcuts can also be used to reduce biases in machine learning\nmodels and datasets. Consequently, there is a large potential for the fields of shortcut and bias mitigation to benefit\nfrom each other."}, {"title": "3.6 Adversarial Features as Shortcuts", "content": "Shortcuts are also relevant from an adversarial machine learning perspective, they have a high similarity to backdoor\nattacks, a common attack on models [64; 33]. Backdoor attacks integrate a hidden functionality into by manipulating\nthe training data. When queried with normal inputs, the backdoored model behaves as expected, however adding the\ntrigger to the data activates the model and it produces specific outputs, for example classifying all images as horses. A\ncommon strategy to create a backdoor is adding a small number of poisoned samples to the training set, containing\na visual trigger like small colored patches. The label of the poisoned samples is set to the desired target class. After\ntraining, inputs containing the trigger are always classified as the target class, regardless of their actual content. In\nthe light of our formalization, we can interpret triggers as adversarial features $f_{adv}$ that are added to the set of input\nfeatures $F_{input}$, introducing spurious correlations $c(f_{adv}, f_{target})$ with target features. These correlations are induced\ndue to a (adversarially) distorted sampling process and not present in $P_{gt}(x)$. This highlights that the problem of\ndetection and mitigating spurious correlations and the resulting shortcuts is not only relevant for model performance\nand generalization, but equally as important to maintain security and privacy [208]. On the other hand, there is a lot of\nwork from the security perspective on detecting and mitigating backdoor attacks. These methods can potentially also be\nused to detect and mitigate shortcuts, and can be a valuable addition to the field."}, {"title": "4 A Unified Taxonomy of Shortcut Learning", "content": "After establishing the building blocks, we can now introduce our unified taxonomy. Within this taxonomy, we integrate\nconcepts and methods from diverse fields under the overarching term of shortcut learning. By unifying research\nunder the terms shortcuts, spurious correlations, Clever Hans behavior, and confounder, we provide a structured and\ncomprehensive perspective on the field. The taxonomy structures approaches first into two main categories, which build\nupon each other: shortcut detection and shortcut mitigation.\nShortcut Detection. Identifying shortcuts is a critical step in addressing shortcut learning, as mitigating shortcuts\nfirst requires an awareness of their presence. Since many mitigation techniques rely on prior knowledge of the\nshortcuts involved, detection methods are a crucial prerequisite for the mitigation strategies that follow. We categorize"}, {"title": "5 Detection", "content": "To address shortcuts in the data, it is first necessary to recognize their presence. As discussed in the previous sections, it\nis often challenging to decide what features are spurious, as this decision depends on the task and its intended solution.\nTo circumvent this, some methods aim to provide effective tools for domain experts to understand what features a model\nis relying on and let them decide whether these features are spurious or not. To design automatic detection methods\nwithout explicit human interactions, other methods pose some more specific assumptions about the nature of shortcuts\nin the data, such as the presence of minority groups (i.e., a small number of samples where spurious features are absent).\nThe assumptions of the different methods impact the way how shortcuts can be detected and addressed. Based on\nexisting literature, we have identified four main categories of detection methods: assessing model utility, detecting\nshortcuts via perturbations, detection using XAI techniques, as well as causality-based methods (cf. Fig. 5)."}, {"title": "5.1 Detection via Model Utility", "content": "The underlying assumption of the following\nworks is that shortcuts are easier to learn than\nthe relevant features. Additionally, they often\nassume that there are some samples without\nthe shortcut present. The methods then use\nthese assumptions to detect samples with and\nwithout spurious features.\n5.1.1 Generalized Cross Entropy. Gener-\nalized cross-entropy (GCE) is a specific way\nto promote the learning of easy-to-learn fea-\ntures. Luo et al. [111] and Nam et al. [130]\ntrain an additional detector with a GCE loss\nto distinguish between easy-to-learn and hard-\nto-learn samples. With the assumption that\nshortcuts are easier to learn, this detector can\nprovide pseudo-labels to use for shortcut mit-igation.\n5.1.2 Simplicity Bias. Yang et al. [206] propose SPARE, which aims to identify shortcuts early in training by\nleveraging simplicity bias. Their method clusters network outputs from early epochs to separate majority and minority\ngroups, assuming that shortcuts are already learned early during training. This clustering is followed by importance\nsampling to mitigate these correlations. LaBonte et al. [92] suggest training multiple models with strong regularization\ntechniques such as dropout and early stopping, identifying non-shortcut samples by finding those consistently correctly\nclassified across models. Yenamandra et al. [211] first amplify shortcuts by training with a large weight decay rate,\nfollowed by correlation-aware clustering to discover shortcut-conflicting slices of data. This approach is suitable for\nscenarios where, at most, one spurious attribute exists. Similarly, Dagaev et al. [40] use a low-capacity network to detect\neasy-to-learn features that are likely to be spurious. These can then be down-weighted during training of a high-capacity\nnetwork to encourage the focus on relevant features.\n5.1.3 Miscellaneous. Adnan et al. [5] detect shortcuts using mutual information between input and learned represen-\ntations. This involves training an infinite-width model using neural tangent kernels [76] to compute mutual information\nfor both training and out-of-distribution (OOD) test data. If mutual information for the test data is significantly lower\nthan for the training data, it suggests the presence of shortcuts, highlighting correlations that may not generalize well\nbeyond the training distribution. While initially designed to detect backdoor triggers, SCALE-UP [65] could also be\nused to detect shortcuts. This method analyzes the consistency of predictions when scaling the input data to detect\npotential irregularities."}, {"title": "5.2 Perturbation-Based Detection.", "content": "Perturbation-based detection methods examine how model performance changes when data is systematically modified,\nrevealing any reliance on potential spurious features. In general, we can differentiate between automatic augmentations,\nsemi-automatic generations, and manual approaches.\n5.2.1 Manual Perturbations. Several works utilize domain knowledge to craft these perturbations manually. For\nexample, Chettri [36] focus on detecting shortcuts in voice spoofing detection by evaluating a model's performance on\nboth original and augmented versions of the dataset. The augmented data includes adding or removing artifacts, such as\nspecific audio features that do not correlate with genuine or spoofed labels but may serve as shortcuts. The difference\nin model performance serves as a coarse detection mechanism for shortcuts. A similar methodology is employed\nby Sturm [174] in the context of music information retrieval systems. In their work, they propose the \u201cmethod of\nirrelevant transformations\", modifying data using changes that should not affect the target variable (e.g., applying slight\nequalization or cropping irrelevant parts of audio recordings). Changes in model performance reveal dependencies on\ndataset-specific shortcuts that might be unrelated to actual musical content.\n5.2.2 Semi Automated Perturbations. In contrast, Agarwal et al. [6] leverage automated semantic image manip-\nulations to assess model robustness in Visual Question Answering (VQA). By steering the generation process of a\ngenerative adversarial network (GAN), they modify certain image features, allowing them to test for model consistency\nacross different versions. Unlike manually crafted augmentations, their use of GANs provides an automated yet\""}, {"title": "5.2.3 Fully Automated Perturbations.", "content": "Wang et al. [189] provide a fully automatic process to reveal frequency-based\nshortcuts in networks for image classification. They perturb the data by sequentially removing specific frequency bands\nto assess their importance. This enables ranking frequencies by their effect on model loss and helps identify whether\nmodels over-rely on particular frequency components. They further test model performance with only the top 5% of\nfrequencies, detecting whether neural networks only focus on narrow aspects of the data spectrum, which they deem a\nlikely shortcut.\nThere also exist other methods related to the detection of shortcuts in the context of adversarial feature detection\n[203; 59] using intentional adversarial perturbations. By adding a universal adversarial perturbation to an image and\ncomparing the model's predictions on the perturbed and unperturbed images, these methods can identify backdoors.\nWhile some of them need to know the trigger size [202; 139], others need many clean images [107] or multiple trained\nmodels [220].\nOverall, perturbation-based methods for shortcut detection provide a direct way to explore model behavior under\nsystematically altered data conditions. However, these methods generally require domain expertise to identify relevant\nperturbations or artifacts, making them highly task-dependent."}, {"title": "5.3 Detection via X\u0391\u0399", "content": "Deciding which features are spurious and which are relevant is difficult without domain knowledge, so a suite of methods\nhas been designed to help domain experts identify shortcuts. To analyze the focus of the model, they use common\nXAI techniques [77]. However, just using existing libraries (e.g., AIX360 [13], \u03a7\u0391\u0399\u03a4\u039a [73], InterpretML [134] or"}, {"title": "5.3.1 Heatmap Clustering.", "content": "Lapuschkin et al. [94]; Schramowski et al. [155] both cluster explanation heatmaps and\nthen present them to a human for evaluation, which is extended to enable automation using context activation vectors\n(CAV) [10]. Similarly, Moayeri et al. [123] present heatmaps of multiple adversarially trained networks or linear layers\n(on top of a pretrained encoder) to humans, who then decide whether the identified features are reasonable or not."}, {"title": "5.3.2 Disentanglement.", "content": "Several works try to disentangle either the explanation or input space to find shortcuts on a\ndiscretized level. Chormai et al. [37] aims to separate explanations into components that represent different concepts,\nwhile Carter et al. [30] directly compute input subsets that are sufficient for a high-confidence prediction and M\u00fcller\net al. [126] utilize a VAE to disentangle meaningful features in a given dataset. These methods enable a domain expert\nto detect potential shortcuts on a higher conceptual level. Furthermore, Bykov et al. [29] identify shortcuts between\noutput representations by comparing functional and concept-based distances using extreme activations and Wu-Palmer\nmetrics from WordNet. Szyc et al. [177] measure how much of the model's salient features (from the saliency map) fall\nwithin a bounding box."}, {"title": "5.3.3 Counterfactual Generation.", "content": "DeGrave et al. [42] use saliency maps to let radiologists decide if the model\nfocuses on spurious features in lung images, such as laterality markers, arrows, annotations unique to the dataset, and\nimage borders. Then, they generate counterfactuals of different COVID-19 statuses to highlight both relevant and\nspurious features. By utilizing neuron attributions to identify ghost neurons that exhibit distinct behavior when Trojan\ntriggers are present, Sikka et al. [165] demonstrate how counterfactual-based neuron excitation can reveal accuracy\ndrops, enabling detection of malicious behaviors."}, {"title": "5.4 Causality-Based Detection", "content": "Causality-based detection methods aim to estimate causal effects to detect the impact of spurious correlations in\nmachine learning models. These approaches typically leverage knowledge of the data generation process through causal\ninference techniques to identify the resulting shortcuts."}, {"title": "5.4.1 Interventional Data.", "content": "For example, Kumar et al. [90] introduce causal effect regularization, which aligns model\npredictions with estimated causal effects by using interventional distributions to regularize the model. This method\nassumes the availability of interventional data to estimate causal relationships accurately."}, {"title": "5.4.2 Causal Inference.", "content": "Zheng and Makar [224] propose a two-step approach that leverages auxiliary labels to\nidentify and remove shortcuts. Their method relies on a causal directed acyclic graph to represent the data generation\nprocess, allowing the model to detect shortcuts. Karlsson and Krijthe [79] focus on identifying hidden confounders using\ndata from multiple environments with different levels of confounding. By analyzing conditional independencies across\nthese environments, they detect hidden shortcuts that affect the relationships. This approach assumes a well-understood\ncausal mechanism underlying the data.\nOverall, while causality-based methods offer a systematic approach to enhance model robustness by addressing spurious\ncorrelations, they often depend on strong assumptions, such as access to interventional data or detailed causal structures,\nwhich can limit their practical applicability."}, {"title": "5.5 Open Challenges in Shortcut Detection", "content": "The previous overview highlights that many shortcut detection methods still rely, at least partially, on human input. For\nexample, most XAI-based methods aim to refine model explanations, making it easier for humans to identify shortcuts.\nSimilarly, perturbation-based approaches often depend on human effort to select irrelevant features for perturbation.\nAs discussed in Sec. 2, determining whether a feature is relevant or spurious is inherently complex and particularly\nchallenging without access to commonsense knowledge. Given these challenges, it is natural to involve humans in the\nfinal decision regarding the presence of shortcuts. However, as the field progresses, the practicality and scalability of\nthese methods must be considered. While human interaction can offer valuable insights, it is crucial to limit the extent\nof this involvement, as users are often reluctant to label or validate large numbers of samples [9]. Therefore, a key\ndirection for future research is to maximize the efficiency of human interactions in shortcut detection methods.\nAdditionally, many detection methods are built on specific assumptions. For instance, utility-based approaches often\nassume that shortcut features are easier to learn than relevant features. XAI-based methods presume that shortcuts\ncan be revealed through explanation techniques, while causality-based approaches may assume the availability of\ncounterfactual or interventional data. However, these assumptions are rarely made explicit, making it difficult to"}, {"title": "6 Mitigation", "content": "The methods discussed in the previous section help to identify whether shortcuts are present in the dataset, but detection\nalone is not sufficient to mitigate shortcut effects on the model. To address this, a wide range of methods is available.\nWe categorize the methods based on their main level of application (cf. Fig. 6). They can either apply at the dataset\nlevel (Sec. 6.1), at the model level (Sec. 6.2) or at inference time (Sec. 6.3). In the following, we cover each area in\nmore detail."}, {"title": "6.1 Mitigation at Dataset Level", "content": "The first set of strategies focuses on mitigating shortcuts\ndirectly at the dataset level. They aim to remove the un-\nderlying spurious correlations, preventing a model from\nlearning them by ensuring they are no longer present.\nThese methods address both sampling-induced and nat-\nurally occurring spurious correlations within the dataset.\nThis section covers all methods that directly modify the\navailable data, while approaches like sample reweighting\nare discussed in later sections."}, {"title": "6.1.1 Data Curation.", "content": "In real-world machine learning\napplications like healthcare, datasets typically go through\nthorough preprocessing steps, including data cleaning\nand feature selection [68]. By addressing shortcuts dur-\ning this process, many spurious correlations, whether\nnaturally occurring or introduced through sampling, can\nbe mitigated [8; 138]. However, this process is inherently\ndomain and task-specific, so there is no general method\nfor data curation against shortcuts."}]}