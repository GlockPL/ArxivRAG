{"title": "Probing the contents of semantic representations from text, behavior, and brain data using the psychNorms metabase", "authors": ["Zak Hussain", "Rui Mata", "Ben R. Newell", "Dirk U. Wulff"], "abstract": "Semantic representations are integral to natural language processing, psycholinguistics, and artificial intelligence. Although often derived from internet text, recent years have seen a rise in the popularity of behavior-based (e.g., free associations) and brain-based (e.g., fMRI) representations, which promise improvements in our ability to measure and model human representations. We carry out the first systematic evaluation of the similarities and differences between semantic representations derived from text, behavior, and brain data. Using representational similarity analysis, we show that word vectors derived from behavior and brain data encode information that differs from their text-derived cousins. Furthermore, drawing on our psychNorms metabase, alongside an interpretability method that we call representational content analysis, we find that, in particular, behavior representations capture unique variance on certain affective, agentic, and socio-moral dimensions. We thus establish behavior as an important complement to text for capturing human representations and behavior. These results are broadly relevant to research aimed at learning human-aligned semantic representations, including work on evaluating and aligning large language models.", "sections": [{"title": "1 Introduction", "content": "Semantic representations are now a staple in computational linguistics (Boleda, 2020), cognitive psychology (G\u00fcnther et al., 2019; Hussain et al., 2024a), as well as natural language processing and artificial intelligence (Jurafsky and Martin, 2024). Crucial to their success has been the widespread availability of massive corpora of web text (e.g., Common Crawl; Crawl, 2024) used for representation learning. However, recent years have seen an uptick in novel behavioral and neuroscientific datasets for training and evaluating semantic representations, with the broad hope being that these can capture dimensions of human psychology less present in text.\nFor instance, driven by recent large-scale behavior data collection efforts (e.g., De Deyne et al., 2019; Hebart et al., 2023), researchers are deriving semantic representations from free associations (Richie and Bhatia, 2021; Hussain et al., 2024b; Wulff and Mata, 2022), odd-one-out judgments (Hebart et al., 2020), and sensorimotor ratings (Kennington, 2021). Likewise, semantic representations obtained from brain data (e.g., fMRI, EEG) are becoming popular for evaluating and improving the human-likeness of state-of-the-art AI systems: namely, large language models (LLMs) (github.com/brain-score/language, Hollenstein et al., 2019; Toneva and Wehbe, 2019).\nOur study seeks to address two research questions: (a) do behavior and brain representations encode systematically different information than text, and (b) are these differences relevant from the perspective of measuring and modeling human representations? Figure 1 illustrates our approach. First, we run a representational similarity analysis (RSA) to uncover systematic differences between text, behavior, and brain data (Section 4.1). We then analyze the content of these differences via our representational content analysis (RCA, Sections 4.2, 4.3), and end with a discussion of the merits and limitations of our work."}, {"title": "2 Our contributions", "content": "Our contributions are four-fold. First, we perform a comprehensive comparison of 10 text representations, 10 behavior representations, and 6 brain representations, revealing robust differences between data types (Section 4.1).\nSecond, we collate the largest (to our knowledge) metabase of predominantly human-rated (behavioral) word properties (i.e., word norms, Section 3.1), which we call psychNorms. The metabase is publicly available at github.com/Zak-Hussain/psychNorms, and reflects over half a century of psycholinguistic research. We hope it will serve as a valuable resource for researchers seeking to measure and interpret abstract language representations along psychologically meaningful dimensions.\nThird, leveraging psychNorms and linear probes (see, e.g., Belinkov, 2022), we demonstrate how to build interpretable informational content profiles for abstract representations via a novel analysis framework that we call representational content analysis (RCA, Section 3.3). By comparing the profiles of different representations, we can provide crucial insight into the content of their differences. This could be especially useful for interpreting and navigating discrepancies between the plethora of otherwise opaque representational alignment metrics (Sucholutsky et al., 2023).\nFourth, and most importantly, we show that, despite being trained on orders of magnitudes less data, the behavior representations encode psychological information of comparable and sometimes even superior quality to their text-based cousins (Sections 4.2, 4.3). This suggests behavior as an important complement to text when it comes to measuring and modeling human representations."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1\nRepresentations and norms", "content": "As mentioned, our analyses seek to answer two questions: (a) do behavior and brain representations encode systematically different information than text, and (b) are these differences relevant from the perspective of measuring and modeling human representations? We attempt to answer these questions using numerical word-level representations (i.e., word vectors). These continuous representations permit quantitative comparisons across otherwise incommensurate data types (text, behavior, and brain data). Furthermore, because the representations are at the level of individual words (i.e., there is one vector per word), they can be directly probed using widely available word-level ratings (norms) such as those we collate in psychNorms.\nOur analyses rely on 10 text, 10 behavior, and 6 brain representations, and 292 word norms grouped into 27 norm categories (see Tables 1 and 2 for details). For our purposes, we subset each representation to a specific vocabulary. That is, for a given representation i, we compute the intersection of its original vocabulary \\(V_i\\) with a restricted base vocabulary \\(V_{base}\\):\n\\[V'_i = V_i \\cap V_{base},\\]\nwhere \\(V_{base}\\) is defined as the intersection of two components: (a) the union of each and every norm vocabulary \\(V_k\\), where \\(k \\in K\\) (and \\(K\\) is the set of all norms), and (b) the union of each and every behavior representation vocabulary \\(V_h\\) (where \\(h \\in H\\)) and brain representation vocabulary \\(V_q\\) (where \\(q \\in Q\\)). Formally, this is expressed as:"}, {"title": "3.2 Representational similarity analysis", "content": "We use representational similarity analysis (RSA) to compare the information encoded in the above representations. Developed within neuroscience (Kriegeskorte et al., 2008), RSA enables comparisons of representations from otherwise-disparate modalities (e.g., fMRI, EEG, similarity ratings) by leveraging the fact that the different dimensions may nevertheless contain information that seeks to distinguish a comparable set of mental states, stimuli, or other kinds of entities.\nIn our case, the entities being distinguished are words. Consequently, RSA measures the similarity between two matrices, \\(M_i\\) and \\(M_j\\), where each row represents a word, and each column reflects a measurement unit (dimensions). For the brain representations, these units may be voxels (fMRI) or electrode readings (EEG), whereas, for text and behavior models, the units are often abstract dimensions. RSA addresses the challenge of correlating these different units by transforming \\(M_i\\) and \\(M_j\\) into a common space. This transformation is achieved by calculating the (dis)similarities between the rows of \\(M_i\\) and \\(M_j\\), forming what is known as a representational similarity matrix, \\(S\\). Following Lenci et al. (e.g., 2022), we compute the cosine similarity matrices \\(S_i\\) and \\(S_j\\), as:\n\\[S_i = \\tilde{M}_i \\tilde{M}_i^\\intercal \\text{ and } S_j = \\tilde{M}_j \\tilde{M}_j^\\intercal,\\]\nwhere the tilde notation \\(\\tilde{M}\\) indicates that the rows of the matrices have been \\(L2\\) normalized. We then compute the representational similarity \\(\\rho_{ij}\\) between the two representations as the Spearman correlation between \\(S_i\\) and \\(S_j\\), having subsetted the two matrices to their common vocabularies \\(V'_i = V'_i \\cap V'_j\\):\n\\[\\rho_{ij} = cor(vectriu(S_{i,\\in V'_i}), vectriu(S_{j,\\in V'_j})),\\]\nwhere \\(vectriu(S)\\) denotes the vector formed by flattening the upper triangle of \\(S\\), excluding the diagonal."}, {"title": "3.3 Representational content analysis", "content": "Representational content analysis (RCA) is an approach to interpretable informational content profiles for abstract numerical representations. Although it leverages the well-established technique of probing from deep learning interpretability (see, e.g., Belinkov, 2022), it differs from traditional probing applications (e.g., Conneau et al., 2018; \u015eahin et al., 2020) in scope and focus. RCA employs tens or even hundreds (as in our case) of targets to more holistically interpret the information encoded in the representations and focuses on revealing how representations derived from different types of data (or learning algorithms) differ from one another.\nOur RCA implementation uses L2-regularized linear probing classifiers and regressors to predict each norm (target) from each representation (features). That is, for each representation i and norm k, we fit a linear mapping \\(w_{ik}\\) such that:\n\\[\\hat{Y}_{ik,\\in V} = M_{i,\\in V} w_{ik},\\]\nwhere \\(M_{i,\\in V_{ik}}\\) is a matrix of word vectors restricted to a common vocabulary \\(V_{ik} = V'_i \\cap V_k\\) and \\(\\hat{Y}_{ik,\\in V}\\) is a vector of predicted norm ratings. We employ \\(L2\\)-regularization to mitigate issues such as multicollinearity, underdetermination, and over-fitting in high-dimensional settings. Following Hupkes et al. (2018), we use linear probes to avoid the risk of more flexible estimators learning features that do not faithfully reflect what is present in the original representations.\nFor numerical norms, we use the Scikit-Learn API's RidgeCV (Pedregosa et al., 2011). For binary and multi-class norms, we use the API's LogisticRegressionCV. Both estimators perform automatic (hyperparameter) tuning of the L2 penalty. This parameter\u2014alpha in the case of RidgeCV, or C in the case of LogisticRegressionCV (equivalent to 1/alpha)\u2014is selected from a grid of values ranging from 10^{-5} to 10^{5} (in alpha terms) with even spacing in log (base-10) space."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Representations from text, behavior, and brain differ systematically, irrespective of learning algorithm", "content": "We begin by asking to what extent text, behavior, and brain data encode distinct information. Using representational similarity analysis (RSA), we compare the representations obtained from each data type (see Section 3.2 for details).\nFigure 3 illustrates the results. Panel A presents a multidimensional scaling of the representational similarity space, and Panel B presents the pairwise similarity matrix. It is important to emphasize that each data type encompasses a diverse set of representations derived from different learning algorithms and sub-data-types (or sub-datasets) (see Section 3.1 for details). For instance, the text and behavior representations result from algorithms both from the global matrix factorization family (e.g., PPMI SVD SWOW, SVD Similarity Relatedness), local context window family (e.g., fastText CommonCrawl, SGSoftMax Input SWOW), and hybrids of both families (e.g., GloVe CommonCrawl).\nDespite the diversity within data type and some algorithmic commonalities between types (e.g., fastText CommonCrawl, SGSoftMax Input SWOW), we observe very clear clustering by data type (Figure 3) and only mild clustering based on the representation learning algorithm. This suggests that the data type has a more significant effect on representational similarity than the choice of learning algorithm.\nTo answer our first research question, we find considerable differences between brain and behavior compared to text (text-brain \\(\\rho = .09\\), text-behavior \\(\\rho = .20\\), where \\(\\rho\\) denotes the mean Spearman correlation), with similarities between the data types showing lower values than those within (brain-brain \\(\\rho = .12\\), behavior-behavior \\(\\rho = .22\\), text-text \\(\\rho = .41\\)). Moreover, we observe proportions of top-3 nearest neighbors being of the same data type of .97% (text), 93% (behavior), and 50% (brain), suggesting high affinity among representations of the same data type, especially for text and behavior. Interestingly, the similarity between text and brain turns out to be .06 points higher than that between brain and behavior (brain-behavior \\(\\rho = .03\\)), suggesting that behavior is the most distinct data type.\nUltimately, our analyses demonstrate the importance of data type in shaping representational similarity, with noticeable informational differences between text, behavior, and brain. We now move to characterizing these differences using representational content analysis."}, {"title": "4.2 Behavior representations can rival text in psychological content", "content": "The previous section revealed differences in the information encoded in text, behavior, and brain representations. This raises the question: What is the content of these differences, and are they relevant to measuring and modeling human representations? To address this question, we leverage our psychNorms metabase (Section 3.1) as targets in a representational content analysis (RCA, Section 3.3).\nFigure 4 illustrates the average test performances of each representation\u00b2 (rows) on each norm category (columns). Performance is measured via the coefficient of determination (R2) for numerical norms and McFadden's pseudo-R2 for categorical norms (e.g., This/That, Part of Speech norms). We henceforth denote both measures with R2.\nSome interesting patterns can be observed. First, text and behavior appear to encode a broad range of psychological information, with the grand median performance of text (R2 = .38, IQR: .36-.41) considerably higher than that of behavior (R2 = .22, IQR: .08-.36). The strong performance of text is perhaps unsurprising it has, after all, been the dominant data source for training semantic representations for decades (G\u00fcnther et al., 2019). Behavior, on the other hand, has garnered comparatively little attention. The representations are also derived from orders of magnitudes smaller training sets and possess more modest vocabularies (hence, smaller probe-training sets). Behavior's performance relative to text is thus quite impressive.\nSecond, we detect scarce psychological information in brain (R2 = \u2212.04, IQR: -.04--.03). However, it is important to reiterate brain's limited vocabularies here. Furthermore, in many cases, the number of features (e.g., voxels, electrode readings) approaches the number of norm-labeled words (samples), making it all the more difficult to detect norm signals in the brain data, which is anyhow inherently quite noisy (Raichle, 2010). Nevertheless, in its present form, brain does not appear to capture much psychological content.\nThird, it appears that some norms are in general better-encoded than others across representations: namely, those on the right-hand side (e.g., Valence, Social/Moral, Dominance) of Figure 4 versus those on the left (e.g. Auditory Lexical Decision, Semantic Decision, Naming). This may be explained in part by differences in norm measurement reliability, which sets a theoretical upper bound on the norm signal that can be captured. However, it is also possible that certain norm-relevant information is especially hard to capture for all kinds of semantic representation (perhaps because the information is not semantic in nature). This latter explanation could indicate an avenue for future research seeking to capture remaining psychological information.\nFourth and finally, important differences can be observed between the best-performing representations from each type on certain norms. For instance, the best-performing text representations tend to outperform those of behavior by a considerable margin on Age of Acquisition (absolute difference in maximum R2, |\\(\\Delta R_{max}\\)| = .27), Part of Speech (|| = .27), Familiarity (|\\(\\Delta R_{max}\\)| = .19, Visual Lexical Decision (|\\(\\Delta R_{max}\\)| = .18), and Naming (|| = .16) norms. Of course, these superior performances may be (partially) attributable to the text representations' larger vocabularies and pre-training sets (we control for probe-training set size and constitution in the next section, 4.3). The differences are nevertheless notable.\nConversely, the best-performing behavior representations perform comparatively strongly on Dominance (|| = .15), Motor (|\\(\\Delta R_{max}\\)| = .09), Goals/Needs (|| = .08), Arousal (|| = .08), and Valence (|| = .07) norms, relative to text. Given the behavior representations' smaller vocabularies and pre-training sets, these higher performances can be seen as conservative estimates of the content behavior is capturing and what it can contribute beyond text to modeling human representations.\nAll in all, our RCA provides critical insights into the content of the differences between text, behavior, and brain representations. Having identified a surprisingly rich reservoir of psychological information in behavior, we now move on to the question of the extent to which behavior could complement text when it comes to modeling human representations."}, {"title": "4.3 Behavior representations captures unique psychological variance", "content": "The previous section suggests that behavior representations contain psychological information that text fails to capture. We now turn to the question of the unique (marginal) contribution of behavior beyond text. To investigate this, we perform an ensemble RCA, whereby we concatenate the top-performing text and behavior representations and measure the marginal increase in norm variance explained. This approach allows us to disentangle the unique norm variance captured by adding behavior features while holding the text features constant.\nWe also subset all representation vocabularies to their collective intersection, meaning that the size and content of the probe's training set on any given norm are identical across representations, thus improving comparability between representations.\nFigure 5 illustrates the results. We contrast text and behavior ensembles (Text & Behavior) with Text & Text and provide solo Text and Behavior baselines for reference. The first thing to note is that ensembling tends to improve performance: on any given norm, it is either Text & Text or Text & Behavior in first place.\nHowever, neither Text & Text nor Text & Behavior is the unanimous winner. For instance, consistent with the results in in Section 4.2, Text & Text tends to outperform Text & Behavior on Visual Lexical Decision (absolute median difference, |d| = .06), frequency-related norms (|d| = .04 for Age of Acquisition, Familiarity, and Frequency), and Semantic Diversity (|d| = .04), with all mentioned differences having a Wilxocon signed rank p < .05 (as indicated by the emboldened differences in Figure 5).\nText & Behavior, on the other hand, tends to perform better on affect-related norms (Dominance: |d| = .08, Arousal: |d| = .07, Valence |d| = .05, Emotion: |d| = .04), agency-related norms (Goals/Needs: |d| = .04, Motor: |d| = .03), and Social/Moral (|d| = .03) norms (all with p < .05).\nUltimately Text & Behavior (descriptively) outperforms Text & Text on 11 out of the 27 norm categories. While Text & Text tends to perform better on more objective, frequency-based categories, Text & Behavior performs better on more subjective categories (e.g., affective, agential, Social/Moral). These subjective categories are thought to be fundamental components of human representations (see, e.g., Lynott et al., 2020; Binder et al., 2016), and are thus likely to be important for language representation applications that seek to model human representations and behavior, including sentiment analysis (Socher et al., 2013), cognitive modeling (G\u00fcnther et al., 2019), in-silicon behavioral experiments (Yax et al., 2024), and AI assistants (Bai et al., 2022)."}, {"title": "5 Discussion", "content": "This article began by asking whether behavior and brain representations might differ from text representations in ways that are relevant to measuring and modeling human representations. We showed that behavior and brain representations encode information that differs from text representations (Section 4.1). Drawing on our psych-"}, {"title": "6 Conclusion", "content": "In this work, we compared behavior and brain representations with text representations on a broad set of psychological dimensions. We found that, despite limited training data, behavior captures psychological information sometimes rivaling that of text, and also captures unique psychological variance on certain dimensions. Our work thus establishes behavior representations as important complements to their text-based cousins in measuring and modeling human semantic representations."}]}