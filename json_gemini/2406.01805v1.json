{"title": "TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting", "authors": ["Andrei Margeloiu", "Adri\u00e1n Bazaga", "Nikola Simidjievski", "Pietro Li\u00f2", "Mateja Jamnik"], "abstract": "Tabular data is prevalent in many critical domains, yet it is often challenging to acquire in large quantities. This scarcity usually results in poor performance of machine learning models on such data. Data augmentation, a common strategy for performance improvement in vision and language tasks, typically underperforms for tabular data due to the lack of explicit symmetries in the input space. To overcome this challenge, we introduce TabMDA, a novel method for manifold data augmentation on tabular data. This method utilises a pre-trained in-context model, such as TabPFN, to map the data into a manifold space. TabMDA performs label-invariant transformations by encoding the data multiple times with varied contexts. This process explores the manifold of the underlying in-context models, thereby enlarging the training dataset. TabMDA is a training-free method, making it applicable to any classifier. We evaluate TabMDA on five standard classifiers and observe significant performance improvements across various tabular datasets. Our results demonstrate that TabMDA provides an effective way to leverage information from pre-trained in-context models to enhance the performance of downstream classifiers.", "sections": [{"title": "1. Introduction", "content": "Tabular data is prevalent and integral to critical domains such as medicine (Balendra and Isaacs, 2018; Kelly and Semsarian, 2009; Meira et al., 2001), physics (Baldi et al., 2014; Kasieczka et al., 2021) and chemistry (Keith et al., 2021; Zhai et al., 2021). However, acquiring large datasets can be prohibitively expensive or impossible, making it challenging to train machine learning models effectively (Jiang et al., 2024; Margeloiu et al., 2023b). In vision and language tasks, a common remedy for addressing model performance issues due to data scarcity is employing data augmentation (DA) techniques to generate additional synthetic samples (Shorten and Khoshgoftaar, 2019). Techniques such as exploiting symmetries in the data, like rotating, flipping or altering the colour of images, or generating paraphrased sentences for text, are used to increase the diversity of the training set, and often lead to improved model generalisation. However, applying DA to tabular data in the input space is challenging, because tabular data is heterogeneous and lacks clear symmetries (Onishi and Meguro, 2023). Consequently, existing tabular augmentation methods in the input space often degrade model performance, hindering their widespread adoption (Manousakas and Ayd\u00f6re, 2023).\nData augmentation on a learned manifold is advantageous, because it enables label-invariant transformations (Sheng and Xiao, 2022; Wang, 2023). Manifolds provide a structured, continuous space where data points can be meaningfully interpolated or transformed. However, current manifold data augmentation (MDA) methods face two challenges in our context of tabular data. Firstly, these methods are typically model-specific, and no general MDA method is applicable across different models. Secondly, MDA has been primarily developed for neural networks, which learn a manifold space (Fonseca and Bacao, 2023). However, for tabular data, neural networks are often outperformed by more traditional methods such as tree-based algorithms like XGBoost (Chen and Guestrin, 2016) or logistic regression, which operate directly in the input space and do not learn a manifold during training. Therefore, it remains an open question how to enhance these traditional methods with the benefits of MDA.\nTo address the challenge of small tabular datasets, we introduce TabMDA, a new training-free method for performing manifold data augmentation (MDA) on tabular data. TabMDA is a general method that works with any downstream classifier. It has two components: first, it leverages an existing pre-trained in-context model, such as TabPFN (Hollmann et al., 2023), to embed the data in a manifold. Second, we introduce in-context subsetting (ICS), a novel technique that uses an in-context classifier to facilitate label-invariant transformations directly in the manifold space. ICS encodes the input data multiple times using an in-context encoder,"}, {"title": "2. Related Work", "content": "Using LLMs on tabular data. The remarkable success of Large Language Models (LLMs), trained on massive text corpora and scaled to unprecedented sizes (Brown et al., 2020; Ouyang et al., 2022), has motivated their adaptation to tabular learning (Wang et al., 2024). Adapting LLMs for tabular data leverages the broad world knowledge already learned, enables in-context learning (ICL) capabilities, and effectively utilises meta-information in tabular data, such as column names (Ye et al., 2024). For instance, LIFT (Dinh et al., 2022) introduced language-interfaced fine-tuning by adapting GPT-3 (Brown et al., 2020) and GPT-J (Wang and Komatsuzaki, 2021) to multiple tabular learning datasets, finding that the performance of fine-tuned LLMs was roughly comparable to traditional solutions. TabLLM (Hegselmann et al., 2023) fine-tuned TO (Sanh et al., 2022), showing slight underperformance compared to classical tree models. Although these studies demonstrate that while LLMs trained on text corpora can be applied to tabular learning, there remains a performance gap between LLMs and classical tabular models due to the lack of tabular-specific inductive biases in LLMs.\nTransformer-based models for tabular data are typically developed by training from scratch on the target task. Occasionally, an additional pre-training phase on the target task itself is included, unlike LLMs, which use large external corpora. These models introduce various attention mechanisms to handle the tabular data structure. For instance, TUTA (Wang et al., 2021) introduces a novel attention mechanism that allows the model to attend to the entire table at once, while TAPAS (Herzig et al., 2020) introduces a column-specific attention mechanism that allows the model to attend to the relevant columns in the table. TransTab (Wang and Sun, 2022) combines column descriptions and cells as input to a gated Transformer model for feature encoding. SAINT (Somepalli et al., 2021) performs attention across both rows and columns to capture the relationships between different cells in the table. More notable examples in this type of models include TabNet (Ar\u0131k and Pfister, 2021), TabTransformer (Huang et al., 2020), and FT-Transformer (Gorishniy et al., 2021). Even though transformers can"}, {"title": "3. Method", "content": "We propose a general data augmentation framework TabMDA that utilises the in-context learning (ICL) capabilities of any pre-trained tabular in-context model to increase the robustness and performance of any downstream machine learning models (Figure 2). In a nutshell, our approach augments the training dataset by introducing diversity through label-invariant transformations in the manifold space, leveraging multiple contexts for the embedder. We then train the downstream prediction model using this augmented dataset.\nProblem Setup: We focus on supervised classification tasks involving $\\mathcal{Y}$ classes. Consider a $D$-dimensional dataset $\\{(\\mathbf{x}^{(i)}, y_i)\\}$, where each sample $\\mathbf{x}^{(i)} \\in \\mathbb{R}^D$ is continuous, and its corresponding label $y_i \\in \\mathcal{Y}$ is categorical. The training data can be represented as a matrix $\\mathbf{X}_{\\text{train}} := [\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)},...,\\mathbf{x}^{(N)}]^T \\in \\mathbb{R}^{N \\times D}$, where each row corresponds to a sample, and a label vector $\\mathbf{y}_{\\text{train}} := [Y_1, Y_2, ..., Y_N]$ containing the labels of the training samples.\nEmbedding the data using In-Context Encoders. TabMDA begins by embedding the real data into a manifold space of a pre-trained tabular in-context model. In this work, we specifically apply TabMDA to TabPFN (Hollmann et al., 2023), a pre-trained tabular transformer. TabPFN is designed to approximate the posterior predictive distribution (PPD) with a tabular-specific prior in a single forward pass. This pretraining is conducted on synthetic data generated"}, {"title": "4. Experiments", "content": "4.1. Experimental Setup\nDatasets. We focus on small-to-medium classification tasks, because this regime allows the study of the effect of data augmentation. We consider six tabular datasets, with complete details included in Appendix A.1. We evaluate all models over 10 runs and report the mean and standard deviation of the test-balanced accuracy averaged across them.\nSetup and evaluation. For each dataset comprising $N$ samples, we initially split it into stratified training and test sets. We use a sizeable test set to ensure an accurate evaluation of the model's performance. The size of the test set is calculated as $N_{\\text{test}} = \\min(\\frac{N}{5}, 500)$. To better understand the impact of our method across different dataset sizes, we subsample the full training set to simulate varying levels of data availability, creating subsets with sample sizes $N_{\\text{real}} \\in \\{20, 50, 100, 200, 500\\}$. Each subset is split into training and validation sets, with 80% of $N_{\\text{real}}$ for training and the remaining 20% for validation. We repeat the training set splitting 10 times to result in 10 runs per subset size. Note that the same test set is used for all repeats to ensure consistency in performance evaluation.\nTabMDA settings. For the in-context model, we use the encoder component of TabPFN (Hollmann et al., 2023), a pre-trained classifier, without ensembling (referred to as TabPFNn.e. in the original paper). For the proposed in-context subsetting, we define the context size as a proportion of the training set, considering context sizes of 0.5, 0.7, 0.9, and 1. Additionally, we evaluate 5, 20, and 50 subcontexts. We select the optimal TabMDA settings based on the validation balanced accuracy for each dataset configuration.\n4.2. Impact on the Classification Performance\nWe evaluate the impact of TabMDA on the performance of various tabular classifiers. We consider five classification models with different inductive biases: distance-based methods (K-Nearest Neighbors (KNN)), linear methods (Logistic Regression) and tree-based methods (Decision Tree (Breiman et al., 1984), Random Forest (Breiman, 2001) and XGBoost (Chen and Guestrin, 2016)). Following"}, {"title": "5. Conclusions", "content": "In this paper, we introduced TabMDA, a novel training-free manifold data augmentation method for tabular data that leverages a pre-trained in-context model, such as TabPFN, and incorporates our in-context subsetting (ICS) for label-invariant transformations. TabMDA significantly improves the performance of standard tabular classifiers by up to 15% and allows simpler classifiers like KNN to achieve competitive results with minimal performance loss. Notably, training with TabMDA leads to more consistent and reliable results by significantly reducing the performance variability across classifiers. The improvements in performance and stability enable explainable classifiers like KNN to become very competitive and sometimes even achieve the highest performance. TabMDA is applicable to any downstream classifier and does not require dedicated training."}]}