{"title": "Bilinear Convolution Decomposition for Causal RL Interpretability", "authors": ["Narmeen Oozeer", "Sinem Erisken", "Alice Rigg"], "abstract": "Efforts to interpret reinforcement learning (RL) models often rely on high-level techniques such as attribution or probing, which provide only correlational insights and coarse causal control. This work proposes replacing nonlinearities in convolutional neural networks (ConvNets) with bilinear variants, to produce a class of models for which these limitations can be addressed. We show bilinear model variants perform comparably in model-free reinforcement learning settings, and give a side by side comparison on ProcGen environments. Bilinear layers' analytic structure enables weight-based decomposition. Previous work has shown bilinearity enables quantifying functional importance through eigendecomposition, to identify interpretable low rank structure (Pearce et al., 2024). We show how to adapt the decomposition to convolution layers by applying singular value decomposition to vectors of interest, to separate the channel and spatial dimensions. Finally, we propose a methodology for causally validating concept-based probes, and illustrate its utility by studying a maze-solving agent's ability to track a cheese object.", "sections": [{"title": "1. Introduction", "content": "Understanding how objectives are encoded in a model such that we could control its outcomes, could help solve the inner alignment problem. Demonstrating this would require causal understanding. Interpreting reinforcement learning (RL) models remains a core challenge, especially when attribution and probing techniques fall short at providing causal, fine-grained insights into learned behaviors.\nThe difficulty of refining the causal relevance of probes remains a challenge for useful applications of RL interpretability. Recently, (Sharkey, 2023) proposed that bilinear MLPs are more interpretable. (Pearce et al., 2024) shows this by deriving insights through the weights. In this paper, we adapt weight decomposition to concept based interpretability, and introduce an approach that may help address these challenges. Concretely, our contributions are as follows:\n\u2022 We motivate bilinear convolution layers as an interpretable model component in ConvNets. We show how bilinear convolution layers can be decomposed into bases of self interacting eigenfilters.\n\u2022 We show that bilinear adaptations of RL agents train well in ProcGen environments. We find comparable performance for a simplified IMPALA and a bilinear variant we call Bimpala.\n\u2022 We propose a protocol for analyzing mechanisms in Bimpala, to causally validate and mechanistically interpret concept-based probes.\n\u2022 We present preliminary interpretability results in studying an RL maze solving agent, demonstrating causal relevance of linear probes in intermediate layers."}, {"title": "2. Bilinear layers", "content": "In this section we'll discuss standard components in deep learning architectures, and the appropriate bilinear counterparts."}, {"title": "2.1. MLP", "content": "A conventional multi-layer perceptron (MLP) or fully-connected (FC) layer takes a vector x (the hidden representation), passes it through two learned linear transformations (represented by matrices W1, W2 and bias vectors b1, b2). An activation function, such as a rectified-linear unit (ReLU) is applied between the two linear transformations. Adopting the notation used in (Shazeer, 2020), the generic structure of an MLP is given by\n$\\text{FCEnc}(x, W_1, W_2, b_1, b_2) = \\text{Enc}(x, W_1, b_1)W_2 + b_2$\nWhere the encoder part of the FC is a nonlinear function $\\text{Enc}: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$, and has the general form\n$\\text{Enco}(x, W_1, b_1) = \\sigma(xW_1 + b_1)$.\nHere, the encoder has m neurons, and any individual neuron activation is just the corresponding dimension activation for the encoder. Modern models, such as LLMs, feature an encoder variant called a Gated Linear Unit (GLU), which"}, {"title": "2.2. Convolutions", "content": "A convolution layer is characterized by integers K for kernel width, as well as integer stride and padding values. Convolution layers have the form\n$\\text{Conv2D}(X, U) = \\sigma(X * U)$\nwhere X has shape [width \u00d7 height \u00d7 Cin], its output\n$\\text{Conv2D}(X, U)$ has shape $[\\frac{\\text{width}}{\\text{stride}} \\times \\frac{\\text{height}}{\\text{stride}} \\times \\text{Cout}]$, and $\\sigma$ is\nan optional activation function applied point-wise. U, the\nkernel which captures its learned parameters, has shape\nK \u00d7 K \u00d7 Cin \u00d7 Cout, and acts locally on K \u00d7 K patches.\nLet $l = \\lceil\\frac{K}{2}\\rceil$. Given input coordinates \u03b1, \u03b2 and an output channel dimension i to write to, a Conv layer's kernel weights act on a local patch around (\u03b1, \u03b2) via the following expression:\n$\\kappa_{\\alpha,\\beta,i} = \\sum_{j}\\sum_{k_1}\\sum_{k_2}U^{(i)}[j, k_1, k_2] \\cdot X[j, \\alpha + k_1, \\beta + k_2]$\nwhere j is an input channel of the 2D convolution, n is the number of input channels and K = 2l. Note that summing over K means summing over -l to l. Similar to GLUs for MLPs, a gated or bilinear convolution can replace a traditional convolution layer with activations:\n$\\text{GConv}(x, U, V) = \\sigma(x * U) \\odot (x * V)$\n$\\text{BConv2D}(x, U, V) = (x * U) (x * V)$"}, {"title": "3. Decomposing Convolutions", "content": "In this section, we aim at decomposition bilinear convolution networks into an orthonormal basis of eigenfilters."}, {"title": "3.1. Tensor Decomposition of Bilinear Convolutional Tensors", "content": "Let us consider the output of a convolution layer at location (\u03b1, \u03b2) for the i-th output channel:\n$\\kappa(\\alpha, \\beta, i) = \\sum_{j}\\sum_{k_1}\\sum_{k_2}U^{(i)}[j, k_1, k_2] \\cdot X[j, \\alpha + k_1, \\beta + k_2]$\nWe can define the contribution of the filter applied to the jth input channel as:\n$a_j = \\sum_{k_1}\\sum_{k_2}U^{(i)}[j, k_1, k_2] \\cdot X[j, \\alpha + k_1, \\beta + k_2]$\nThis allows us to rewrite the output as:\n$\\kappa(\\alpha, \\beta, i) = \\sum_{j}a_j$\nWe can flatten the input tensor $X[j, \\alpha : \\alpha+k, \\beta: \\beta+k]$ into a $K^2$-dimensional vector for each spatial location (\u03b1, \u03b2). Let us denote this flattened version as $X[j, :, :]f$. Similarly, we can write a flattened version of the filter $U^{(i)}[j, :, :]$, which we'll call $U^{(i)}[j, :, :]f$. Note that the filter is independent of the position (\u03b1, \u03b2).\nUsing these flattened representations, we can express $a_j$ as:\n$a_j = U^{(i)}[j, :, :] f \\cdot X[j, :, :] f$\nFor readability, we can simplify the notation of the flattened vectors. We will also remove the notation for the output channel (i), as all the operations we discuss here are for a single output channel. Simplifying the notation, we get:\n$a_j = U_jX_j$\nNote that $U_j$ is a $K^2$ row vector, and $X_j$ is a $K^2$ column vector. The gated operation is given by:\n$\\kappa(\\alpha, \\beta, i) \\odot \\upsilon(\\alpha, \\beta, i)$"}, {"title": "3.2. Bilinear component decomposition protocol", "content": "Similar to the decomposition approach in (Pearce et al., 2024), we can fix an output vector $u \\in \\mathbb{R}^m$ and multiply it by Bsym along the output channel dimension to produce a matrix Qu = uBsym of shape [nK\u00b2, nK2], that functions as a quadratic form on the input space. Note an important distinction: since Conv layers are not fully connected but are rather locally connected, the output vector u is in [Cout] space, and the decomposition produces an eigenbasis for the filters that we call eigenfilters. That is, you get a basis consisting of nK\u00b2 eigenfilters of shape (K\u00b7K\u00b7n). In spectral theorem terminology, we have Qu = FTAF, where F is an orthonormal matrix (satisfying F-1 = FT) of eigenvectors, and A is a real, diagonal matrix of eigenvalues."}, {"title": "3.2.1. CONTRIBUTIONS OF EIGENFILTERS", "content": "Since Qu is used in practice as a quadratic form, its contributions towards u for a patch x centered around a given position are given by Qu(x) = xTQx = x\u00b2 xT FT AuFux =\n(Fux)TAu(Fux) = $\\sum_{i} \\lambda_i (f_i x)^2$ and Qu = $\\sum_i \\lambda_i f_i f_i^T$.\nEach $f_i^2$ is an individual eigenfilter, and has shape [(Kw Kh Cin)]. As the eigenfilter activations are applied to every valid position uniformly, we can equivalently write\nQu(X) = $\\sum_i \\lambda_i(f_i * X)^2$."}, {"title": "3.2.2. SEPARATING CHANNELS FROM SPATIAL\nCOORDINATES WITH SVD", "content": "Suppose we have a weight or activation vector X with shape\n[w, h, C], having both spatial and channel dimensions. We\ncan reshape X into a matrix of shape [C, wh], and apply\nsingular value decomposition (SVD). This gives us\nX = $\\text{SEV}^T = \\sum_i \\sigma_i s_i v_i^T$\nwhere S has shape [C, C'], and V has shape [wh, wh]. The top left singular vectors si live in the channel space, and can be used as output vectors for a BConv layer.\nSince the top singular vectors in channel space also have\na singular value, we can aggregate the contributions of the\neigenvalues and the eigenvectors together. We can derive an\neigendecomposition of the BConv layer for each singular"}, {"title": "4. Experiments", "content": "In this section, we evaluate the performance and interpretability of bilinear models using a series of reinforcement learning experiments and analyses. Our goal is twofold: (1) to assess whether bilinear architectures achieve competitive or superior performance compared to standard models like ReLU-based IMPALA, and (2) to explore how bilinear layers provide interpretable representations through eigendecomposition and probe-based analyses. We detail training procedures, experimental protocols, and key findings from both quantitative and qualitative perspectives."}, {"title": "4.1. Architecture baseline", "content": "The architecture of our model was adapted from an existing framework described by (Espeholt et al., 2018). This adaptation involved modifying the original structure to incorporate bilinear gating mechanisms in both convolutional and fully connected layers. Additionally we removed some convolutional layers so that the residual block is a simple gated convolution with a skip connection.\nMore importantly, we replaced Conv-Relus with Bilinear Convs and Relu FCs with Bilinear FCs, and omitting the down projection W2 in FCbilinear (Figure 1)."}, {"title": "4.1.1. BIMPALA MATCHES PERFORMANCE ON PROCGEN\nTASKS", "content": "We used the ProcGen environment (Cobbe et al., 2020) to train reinforcement learning policy models with PPO. Specifically, we trained a simplified ReLU network alongside a bilinear variant, which we refer to as Bimpala (Bilinear IMPALA). Our results show that Bimpala matches and occasionally outperforms IMPALA across several tasks in ProcGen, including Maze, Heist, Plunder, and Dodge-Ball. We trained on the \"easy\" distribution for all these environments due to less time steps required for convergence.(Figure 4).\nThese results validate the feasibility of using bilinear layers for reinforcement learning tasks. We now turn to describing how this architecture can be used to enhance interpretability for reinforcement learning."}, {"title": "4.2. Analysis protocol", "content": "We suggest a protocol to connect bottom-up mechanistic approaches to top-down concept based approaches.\n1. Train a linear probe for a concept of interest on a Conv activation space with shape [width, height, C. Reshape as [C, width \u00b7 height]\n2. Rewrite the probe's weights using the SVD, and use the top left channel-space singular vectors as output directions for a preceding BConv layer. Determine the number m of singular components needed, based on the distribution of singular values.\n3. Perform an eigendecomposition towards the top m left singular vectors in channel space, to identify directions in the filter weights that write to the probe.\nSince we're getting a full basis of eigenvectors for each output direction, it's possible for the important eigenvectors between output directions to not be fully orthogonal. This is especially relevant if interpreting multiple probes in parallel. Analyzing the cosine similarity between important"}, {"title": "4.3. Methodology", "content": ""}, {"title": "4.3.1. TRAINING CONCEPT PROBES", "content": "In this analysis, we use a Bimpala model trained on the Proc-Gen Maze environment, where the player, a mouse, must navigate a maze to find the sole piece of cheese and earn a reward. We trained linear probes to detect the presence of the cheese at position (8, 14) in the maze by creating a dataset comprising 2000 mazes with a cheese at position (8, 14) and 2000 mazes without cheese. We see that probes trained on the outputs of the residual blocks get about 99% accuracies and F\u2081 scores (Table 1)."}, {"title": "4.3.2. DoMINANT SINGULAR PROBE CHANNELS", "content": "Next, we apply singular value decomposition to the probes. The top singular component alone explains 30% of the variance, and 16 components are needed to explain \u2265 90% of the variance (Figure 5)."}, {"title": "4.3.3. EIGENFILTER DECOMPOSITION FOR SINGULAR\nPROBE CHANNELS", "content": "We then decomposed the preceding BConv layer towards u\u2081, the top singular channel. The spectrum for singular channels is nondegenerate, whereas the basis aligned or random channel spectra have just two nonzero eigenvalues (Figure 6).\nWe visualize the top positive and negative eigenfilter activations for a set of pairs of mazes, one with the cheese at the selected position and the other without the cheese. The positive and negative activations of the respective filters result in a cheese detector filter (Figure 3). While the positive filter activates on non-cheese patterns, it activates the strongest at the cheese location, and the negative filter downweighs non-cheese patterns without erasing the cheese activation."}, {"title": "4.3.4. ACTION FEATURES", "content": "Instead of training probes, we could alternatively decompose the directions relevant for actions directly. There are many action eigenvectors in the final FC layer (Figure 7). Interestingly, despite a dense spectrum, ablating all but the top action vector is sufficient to preserve maze-solving ability (Figure 8)."}, {"title": "4.4. Ablation Studies", "content": "We carry out ablations in the standard channel basis at different layers of the network to figure out how large is the"}, {"title": "5. Discussion", "content": "Summary We introduce an approach to interpreting convolutional neural networks, by replacing nonlinearities with bilinear variants that achieve comparable and occasionally superior performance, although this was not our aim. Our approach allows us to find a closed form for self-interacting convolution features that can be combined with a top down concept based approach to derive causally relevant mechanisms used by RL agents in their decision making process. Therefore, we see great value in bilinear variants that offer more interpretability prospects while achieving competitive performance to its non-analytic variants.\nLimitations We found significant challenges in interpreting the units of computation in a entirely data independent fashion, and found that top activating dataset examples for eigenvectors tend to not be informative. However, the decomposition allows us to break concept probes into more granular units of computation. We considered only one architecture, IMPALA, for our policy, although we expect the general approach of replacing nonlinearities with bilinear variants to be widely applicable.\nWe do not address a range of components often found in convolutional neural networks, such as batch norm, dropout, or pooling. Considering the implications for each of these, such as the performance tradeoff for linear or quadratic versus max pooling, is important for assessing the viability of architecture variants. We are looking forward to exploring the interations of eigenvectors over several layers of the network to investigate multi-step reasoning and do a lower level mechanistic interpretability study of bilinear RL variants."}]}