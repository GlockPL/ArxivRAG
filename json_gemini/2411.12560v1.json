{"title": "Topological Symmetry Enhanced Graph Convolution for Skeleton-Based Action Recognition", "authors": ["Zeyu Liang", "Hailun Xia", "Naichuan Zheng", "Huan Xu"], "abstract": "Skeleton-based action recognition has achieved remarkable performance with the development of graph convolutional networks (GCNs). However, most of these methods tend to construct complex topology learning mechanisms while neglecting the inherent symmetry of the human body. Additionally, the use of temporal convolutions with certain fixed receptive fields limits their capacity to effectively capture dependencies in time sequences. To address the issues, we (1) propose a novel Topological Symmetry Enhanced Graph Convolution (TSE-GC) to enable distinct topology learning across different channel partitions while incorporating topological symmetry awareness and (2) construct a Multi-Branch Deformable Temporal Convolution (MB-DTC) for skeleton-based action recognition. The proposed TSE-GC emphasizes the inherent symmetry of the human body while enabling efficient learning of dynamic topologies. Meanwhile, the design of MBDTC introduces the concept of deformable modeling, leading to more flexible receptive fields and stronger modeling capacity of temporal dependencies. Combining TSE-GC with MBDTC, our final model, TSE-GCN, achieves competitive performance with fewer parameters compared with state-of-the-art methods on three large datasets, NTU RGB+D, NTU RGB+D 120, and NW-UCLA. On the cross-subject and cross-set evaluations of NTU RGB+D 120, the accuracies of our model reach 90.0% and 91.1%, with 1.1M parameters and 1.38 GFLOPS for one stream.", "sections": [{"title": "1. Introduction", "content": "Human action recognition has attracted much attention due to its wide range of applications [2, 13, 15, 25], including video surveillance, virtual reality, health care and so on. With the development of depth sensors [39, 42] and human pose estimation methods [3, 7, 32], skeleton-based action recognition[5, 16, 24, 37] has become increasingly popular. Skeleton is a type of structured data with each joint of the human body identified by its joint type, frame index and 3D position, which shows great potential in preserving privacy and demonstrates strong robustness against the variations of illumination, viewpoints and other background changes.\nInspired by the inherent structure of skeleton data, graph convolutional networks (GCNs) have emerged as a dominant solution for skeleton-based action recognition. STGCN[37] was the first work to encode human body as spatial temporal graphs, aggregating features along the nat- ural connectivity of the human body. Since then, many works[5, 18, 20, 22, 27, 28] have delved into the optimiza- tion of graph convolutional mechanisms, with a focus on adaptively building topologies to effectively capture mo- tion patterns. However, most of these approaches lever- age learnable adjacency matrices combined with attention mechanisms and other techniques derived from dynamics theory [35], information bottleneck theory[10], topological data analysis[44] and so on, neglecting or underestimating the inherent symmetry of the human body and its poten- tial role in topology learning. For instance, in the case of a \"brush hair\" action, the interaction between the head and"}, {"title": "2. Related Work", "content": "the left hand should be hight-lighted and learned alongside the interaction between the head and the right hand, while the roles of other joints may be less critical.\nBased on the analysis above, we argue that integrat- ing topological symmetry constraints into topology learning could lead to a straightforward yet effective mechanism for topological learning. In this paper, we propose a topological symmetry enhanced graph convolution, named TSE-GC, to enable distinct topology learning across different channels groups while incorporating topological symmetry aware- ness. Specifically, TSE-GC learns the scale mask of interest for each sample and reactivates a shared topology into dis- tinct copies for multiple separate channel groups (illustrated in Fig.1). The scale mask is learned via k-nearest neighbor (k-NN) algorithm based on the Euclidean distance, where the k nearest neighbors of each joint and the corresponding scales are identified. During the learning of scale mask, we also introduce the calculated Euclidean distance as a cali- bration for the topology tailored to each sample. With few extra parameters introduced, our method facilitates topol- ogy learning in a symmetric manner and effectively cap- tures the intricate correlations between joints.\nIn terms of feature aggregation across different frames, most of these approaches [5, 22, 44] tend to apply multi- scale temporal convolution to effectively capture both short- range and long-range dependencies, yet their representa- tion capacity is still limited due to essentially fixed re- ceptive fields of temporal convolution. To remedy the is- sue, we introduce the concept of deformable convolution and construct a multi-branch deformable temporal convo- lution, named MBDTC, for skeleton-based action recogni- tion. MBDTC incorporates learnable offsets to the sampling locations of the temporal convolution filter, enabling more flexible receptive fields and better representation capacity.\nCombining TSE-GC with MBDTC, we construct a novel topological symmetry enhanced graph convolution network (TSE-GCN) for skeleton-based action recognition. Ex- tensive experimental results on NTU RGB+D[26], NTU RGB+D 120[21], and NW-UCLA[34] show that TSE-GCN achieves competitive performance with fewer parameters compared with state-of-the-art methods.\nOur contributions can be summarized as follows:"}, {"title": "2.1. Skeleton-based Action Recognition", "content": "Early deep-learning methods utilized recurrent neural net- works (RNNs) [12, 33] and convolutional neural networks (CNNs) [19, 31] to capture action representations by encod- ing skeleton data as feature sequences or pseudo-images, but they overlooked the inherent relations between joints. Consequently, these methods failed to effectively model hu- man body topology, limiting their overall performance. In contrast, GCNs represent the human body as graphs, where joints are treated as nodes and their relations are treated as edges. Such a design enables GCNs to effectively capture dependencies between joints and brings the potential to un- ravel complex motion patterns."}, {"title": "2.2. GCNs for Skeleton-based Action Recognition", "content": "Topology learning is a key focus of GCNs in the context of skeleton-based action recognition, enabling the effec- tive modeling of human joint correlations. The pioneer, STGCN[37] predefines the physical structure of the human body as a fixed topology. 2s-AGCN[28] introduces adap- tiveness to topology learning with a self-attention mech- anism. Since then, numerous studies [5, 10, 18, 29, 36, 38, 44] have aimed to capture the intrinsic correlations be- tween human joints using learnable adjacency matrices, at- tention mechanisms or other techniques. Among them, AS- GCN[20] and MS-G3D[22] leverage adjacency powering for multi-scale modeling, which is also adopted in our meth- ods to establish topological symmetry constraints.\nA previous work, DEGCN[23], introduces deformable temporal convolution for skeleton-based action recognition. However, DEGCN applies a uniform offset to all frames in a data-independent manner, resulting in the same receptive field across different frames. In contrast, our TSE-GCN learns a unique offset for each individual frame, which is data-dependent and enables more flexible receptive fields."}, {"title": "2.3. Deformable Modeling", "content": "The concept of deformable modeling originates from CNNs, with the main goal of directing important locations on images. As CNNs employ fixed convolutional filters, they struggle to adapt to complex and irregular shapes in images. Deformable convolution[11] addresses this limita- tion by allowing the convolutional kernels to learn spatial offsets, enabling them to sample from non-grid locations in the input feature map. Deformable-DETR[45] builds upon the original DETR[4] architecture with deformable atten- tion mechanisms. Our MBDTC applies 1D temporal de- formable convolution modules with multiple distinct origin"}, {"title": "3. Method", "content": "In this section, we first define related notations and revisit the formulations for vanilla graph convolution and its vari- ants. Then we elaborate the design of our Topological Sym- metry Enhanced Graph Convolution (TSE-GC) in Section 3.2 and Multi-Branch Deformable Temporal Convolution (MBDTC) in Section 3.3. The overall architecture of TSE- GCN is presented in the end."}, {"title": "3.1. Preliminaries", "content": "Notations. In GCNs, the human body within a motion se- quence is represented as a spatio-temporal graph. The graph is denoted as G = (V,E), where V = {V1, V2, ..., vv } is the set of N vertices representing joints and & is the edge set representing the correlations between joints. Typically, G is formulated by X \u2208 RN\u00d7T\u00d7C and A \u2208 RN\u00d7N. X is the feature tensor of N vertices across T frames, and vi's feature at frame t is denoted as xi,t \u2208 RC. C is the number of channels. A is the adjacency matrix, with its elements aij representing the correlation between vi,: and vj,:.\nFormulations of Graph Convolution. Within the realm of skeleton-based action recognition, the vanilla graph convo- lution proposed by [17] is widely adopted:\nX(1+1) = \u03c3(\u00c2X(l)W(l)),\nVariants of Eq. 1 typically adopt a partitioning strategy with multiple subsets involved. For example, ST-GCN[37] divides A+I into self-loop, centrifugal and centripetal com- ponents, Info-GCN[10] utilizes a multi-head self-attention mechanism where each head corresponds to a subset, and AS-GCN[20] employs a multi-scale aggregation with each subset representing a distinct scale. The unified form can be"}, {"title": "3.2. Topology Learning with Symmetry Awareness", "content": "Topological symmetry is an inherent characteristic of the human body, where corresponding limbs mirror each other. Many physical activities, such as walking, running, or danc- ing, exhibit symmetrical patterns that should be captured through the process of graph representation learning. How- ever, previous works tend to employ complex graph learn- ing mechanisms without explicitly incorporating topologi- cal symmetry during topology learning.\nOn the other hand, most prior approaches typically uti- lize learnable adjacency matrices to adaptively capture cor- relations between joints, allowing the topology to be learned without any constraints based on physical bone connec- tions. In contrast, directly using the physical structure as the topology for graph feature aggregation, as done in [37], yields suboptimal performance. Intuitively, a balanced ap- proach that incorporates both flexibility and physical con- straints is worth exploring.\nBased on the analysis above, we argue that integrat- ing topological symmetry constraints into topology learning could enhance the modeling capacity of graph convolution, which leads to TSE-GC. The architecture of our TSE-GC is illustrated in the bottom left corner of Fig.2, and the forward process can be divided into two pathways, one for topology learning and one for feature partitioning.\nFeature partitioning. Given the input feature X \u2208 RN\u00d7C, we first transform it into high-level representation with a linear embedding function 4, which is formulated as:\nX = 4(X) = XW\u03c8,\nwhere W \u2208 RC\u00d7(C'K) is the weight matrix and X \u2208 RNX(C'K) is the transformed feature. X is further divided along the channel dimension C'K into K partitions.\nThe entire feature partitioning process, denoted as gs() in Eq. 2, is formulated as:\ngs(X) = (X) = [Xo||X1||...||XK\u22121]\nXk = X:,kC':(k+1)C',\nwhere || is concatenate function and \u0160k \u2208 RN\u00d7C' repre- sents the k-th partition of the transformed feature X. Note that (.) represents distinct instances of (\u00b7) applied to different subsets.\nTopology learning. The topology learning pathway is de- tailed in the left section of the illustrated TSE-GC shown"}, {"title": "3.3. Multi-Branch Deformable Temporal Modeling", "content": "in Fig.2. A shared topology M \u2208 RN\u00d7N is utilized for all subsets and reactivated as A \u2208 RK\u00d7N\u00d7N. The reactiva- tion could be interpreted as a form of resampling, where the correlations between joints at the relevant scales or hops are sampled. We use the term reactivate to describe the char- acteristic of constraining topology learning in a symmetry manner, because the reactivated interactions can be updated through the training phase, while the other interactions re- main unchanged. During the inference phase, only the re- activated interactions are utilized for graph feature aggrega- tion. To maintain flexibility of topology modeling, we also introduce a data-dependent calibration matrix B \u2208 RN\u00d7N, as well as a learnable adjacency matrix C\u2208 [RK\u00d7N\u00d7N for each subset.\nSpecifically, we first employ another linear embedding function @ to embed the input feature for the subsequent topology learning, as in Eq. 3. The negative square of Eu- clidean distance D \u2208 RN\u00d7N is then calculated based on the embeddings between distinct joints, as dij = -dis(ei, ej)\u00b2, where ei and ej represent the embeddings of the joints. D is further utilized to obtain the calibration matrix B:\nB = g(D),\nwhere \u00a7() is the activation function.\nBased on the calculated Euclidean distance, the indexes of k-nearest neighbors can be identified as IN \u2208 RN\u00d7K, which is mapped to the relevant scales or hops. Relevant scales are marked as 1 in the scale mask. The generation of scale mask can be formulated as:\nH = f(IN, Dsp) = f(KNN(0(X), K), Dsp),\nwhere H \u2208 RK\u00d7N\u00d7N is the scale mask, f is the generation function of scale mask where the indexes of top-k neigh- bors are mapped to relevant scales, Dsp is a mapping table based on the shortest path distance (SPD). The calculation of SPD is based on the physical connections, which can be formulated as:\ndspi,j = min {|P|, P\u2081 = Vi, PP\u2081 = vj},\nPEPaths(G)\nwhere dspi,j represents SPD between nodes vi and vj, and P denotes the shortest path in the graph G connecting these nodes. In practice, we calculate it with adjacency powering.\nWith the scale mask, we reactivate the shared topology to introduce topological symmetry constraints:\nAs = HS \u039c,\nwhere is element-wise multiplication operation, As \u2208 ]RK\u00d7N\u00d7N is the reactivated topology. We use subscript s to indicate distinct scale masks and activated topology for different subsets."}, {"title": "3.4. Model Architecture", "content": "Temporal modeling is essential for capturing complex mo- tion dynamics in human action recognition. For GCNs, an effective temporal modeling module should be capable of flexibly capturing temporal dependencies, or correlations within the temporal graph. Previous works [5, 22, 44] typi- cally utilize multi-scale temporal convolution to effectively capture both short-range and long-range dependencies with multiple fixed receptive fields, which is suboptimal. An in- tuitive solution is to introduce attention mechanisms, but their computational cost can be excessively high for long sequences. Therefore, we adopt the idea of introducing de- formable modeling and construct our MBDTC with flexible receptive fields for skeleton-based action recognition, en- abling dynamic temporal modeling.\nTo begin with, we revisit the deformable convolution from [11]. Given a 2D convolution, the sampling locations are defined by a regular grid R, resulting in a fixed receptive field. The deformable convolution adds learnable offsets to make the sampling locations irregular, formulated as:\ny(Po) = \u2211 w(pn) \u00b7 x(po + Pn + \u2206pn),\nPnER\nwhere po is a location on the output feature map and pn is the fixed offsets in R. Apn represents the learnable offset at each sampling point po + Pn, which allows the convolution to adaptively adjust the receptive field.\nFor spatio-temporal graphs in GCNs, spatial features are inherently structured, while temporal features are dis- cretely sampled from continuous frames. Typically, only correlations among the same joints across different frames are considered. Based on the distinct characteristic, we redesign the vanilla deformable convolution into our de- formable temporal convolution (DTC) which learns the off- sets for each frame with spatial graph feature extracted through weighted graph pooling. An example of our sam- pling mechanism is illustrated in Fig.3, where we insert a readout operation with graph pooling between depth-wise separable convolution.\nSpecifically, we first embed the input feature X \u2208 RN\u00d7T\u00d7C into Y \u2208 RN\u00d7T'\u00d7C with a depth-wise convo- lution. The potential reduction in frames from T to T' is caused by the stride applied to our DTC. The spatial graph feature of the embedding is then pooled, formulated as:\nZ = 1N \u03a3n=1 WnYn,\nwhere wn is the weight scalar for joint vn and Z \u2208 RT'XC represents the graph readouts for T' frames. Subsequently, the offsets are obtained with learnable parameters and Z, formulated as:\nP = ZW,\nwhere P\u2208 RT'R indicates the offsets for T' frames. R is the kernel size applied to our DTC. Notably, R is also applied to the preceding depth-wise convolution.\nWith the offsets and the original sampling locations, we adopt the linear interpolation for sampling and introduce a weight matrix M \u2208 RT'\u00d7R, which is obtained from the offsets through a linear transformation. Our DTC can be"}, {"title": "4. Experiments", "content": "Based on the aforementioned TSE-GC and MBDTC, we construct a topological symmetry enhanced graph convolu- tional network TSE-GCN for skeleton-based action recog- nition. The model architecture is illustrated in Fig.2. Based on experimental results, we select GeLU as the activation function in the network, except for Eq. 6 where we use Tanh for a more suitable output range in modeling topology.\nThe input feature is first embedded with a linear transfor- mation and then combined with a learnable absolute posi- tional embedding from [10]. Subsequently, the embeddings are fed into a stack of our basic blocks, each consisting of a TSE-GC module, a MBDTC module and residual connec- tions. L 9, is the number of times our basic block is stacked. The number of channels for nine blocks are 64-64- 64-64-128-128-128-256-256. Following the stacked basic blocks, a global average pooling operation and a softmax classifier is applied to generate predictions across different action classes."}, {"title": "4.1. Datasets", "content": "NTU RGB+D. NTU RGB+D[26] is a large-scale human action recognition dataset containing 56,880 skeleton ac- tion sequences over 60 classes. The action samples are per- formed by 40 participants in different age groups, and each sample contains an action and is guaranteed to have at most 2 subjects. For each sample, the skeleton data of 25 joints is captured by three Microsoft Kinect v2 cameras from differ- ent views concurrently. Two benchmarks are provided by the authors: (1) cross-subject (X-sub): training data comes from 20 subjects, and testing data comes from the other 20 subjects. (2) cross-view (X-view): data captured from the front and two side views is used for training, and data cap- tured from the left and right 45-degree views is used for testing.\nNTU RGB+D 120. NTU RGB+D 120[21] is an extended version of NTU RGB+D with additional 57,367 skeleton sequences over 60 extra action classes, which is one of the largest datasets with 3D joints annotations for human ac-"}, {"title": "4.2. Implementation Details", "content": "tion recognition. Totally 113,945 samples over 120 classes are performed by 106 volunteers with 32 distinct setups for locations and backgrounds, captured with three cameras views. The authors recommend two benchmarks: (1) cross- subject (X-sub): training data comes from 53 subjects, and testing data comes from the other 53 subjects. (2) cross- setup (X-set): training data comes from samples with even setup IDs, and testing data comes from samples with odd setup IDs.\nNW-UCLA. NW-UCLA [34] is a small human action recognition dataset containing 1494 video clips over 10 ac- tion categories. Each action is performed by 10 subjects, with the skeleton data captured by three Kinect cameras simultaneously from multiple viewpoints. Following the evaluation protocol recommended by the authors, we use the viewpoints of the first two cameras for training and the other for testing.\nAll experiments are conducted on two RTX 3090 GPUs with the PyTorch deep learning framework. The SGD opti- mizer is employed with a Nestrov momentum of 0.9 and a weight deacy of 0.004 for NTU RGB+D and NTU RGB+D 120, and 0.002 for NW-UCLA. Our method utilizes cross- entropy loss. The learning rate is initialized at 0.05 and reduced by a factor of 0.1 at epoch 110 and 120, with a to- tal epoch 140. For NTU datasets, we set a batch size of 64 with each sample resized to 64 frames and adopt the data-processing in [41]. For NW-UCLA, the batch size is selected as 16 and we adopt he data-processing in [9]."}, {"title": "4.3. Comparison with the State-of-the-art", "content": "In this subsection, we compare the proposed TSE-GCN against state-of-the-art methods on NTU RGB+D, NTU RGB+D 120 and NW-UCLA in Table 1. To establish a fair comparison, we follow the commonly adopted four-stream fusion approach in our experiment. Specifically, we fuse the results of joint, bone, joint motion and bone motion modalities. Notably, some of the methods are not directly comparable to our methods, which are shown in the second part of the table, for example, HD-GCN[18] applies a six-stream ensemble with their hand-crafted modalities, as well as Info-GCN[10], and Shap-Mix[40] utilizes the additional mixed data from their data augmentation approach which doubles the number of samples. The performance of Info- GCN in the first part is from the reproduction from [14] for a fair comparison, following [44].\nExperimental results demonstrate that our method, TSE- GCN achieves state-of-the-art performance on the com- mon benchmarks. Compared with the state-of-the-art BlockGCN[44], the proposed TSE-GCN achieves 0.3% lower accuracies on average with 15.4% fewer parameters"}, {"title": "4.4. Ablation Study", "content": "and 32.7% fewer FLOPs. Compared with FR-Head[43], the proposed TSE-GCN surpasses it with 45% fewer parame- ters. It is noteworthy that we prioritize a better trade-off be- tween model size and performance in our hyper-parameter setting instead of accuracies, as detailed in Section 4.4. Meanwhile, our method can serve as a backbone and be combined with Shap-Mix[40] or FR-Head [43] to further improve performance.\nIn this subsection, we analyze the proposed TSE-GC and its configurations along with MBTDC on the X-sub bench- mark of the NTU RGB+D 120 dataset, using joint stream data. We reconstruct ST-GCN[37] with our selection of ac- tivation function as the baseline in our experiments, with the 2-nd layer removed."}, {"title": "4.5. Performance Analysis on Single Stream", "content": "In table 4, we compare single-stream performance of our TSE-GCN with other GCNs. Our model achieves a com- petitive performance on NTU RGB+D 120 joint stream with the lowest computational complexity.\nWe further analyze the accuracies of certain classes to confirm that the experimental results align with the in- tended design to incorporate topological symmetry aware- ness. Specifically, we utilize GPT4[1] to identify symme- try related classes within NTU RGB+D 120, as the corre- lation between certain actions and topological symmetry is abstract and hard to be defined by human. The final list contains 27 classes, including clapping, hands up, cross arms and so on. We calculate the accuracy difference of these classes between TSE-GC and two representative GCS in Fig.4. We select ST-GC and CTR-GC as the topology of ST-GC is fully physical, while the topology of CTR- GC is nearly fully flexible due to the catastrophic forgetting of skeletal topology[44]. Experimental results demonstrate that TSE-GC shows an average improvement of +0.6% compared to ST-GC and +0.8% compared to CTR-GC on these classes, which corresponds to their distinct topologies. Meanwhile, overall performance improvement is observed in both cases, with a few classes showing gains exceeding the average, such as +4.69% for \"shake fist\" in ST-GC case and +9.74% for \"hit other person with something\" in CTR- GC case."}, {"title": "5. Conclusion", "content": "and R = 4. However, in order to balance performance and efficiency, we select K = 3 and R 8 as the final choice of hyper parameters for TSE-GC.\nIn this work, we propose a novel topological symme- try enhanced graph convolution network (TSE-GCN) for skeleton-based action recognition. Our TSE-GC module leverages the inherent topological symmetry of the human body to achieve an effective and balanced topology learn- ing between flexibility and physical constraints. Our multi- branch deformable temporal convolution (MBTDC) mod- ule incorporates deformable modeling to enable flexible re- ceptive fields. TSE-GCN achieves competitive performance compared with state-of-the-art methods on three datasets, with the effectiveness of each component validated. Our future research may proceed in two main directions:"}]}