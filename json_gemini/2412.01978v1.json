{"title": "Human-centred Test and Evaluation of Military Al", "authors": ["DR David Helmer", "MR Michael Boardman", "DR S. Kate Conroy", "LTCOL Adam J. Hepworth", "MR Manoj Harjanis"], "abstract": "This session' highlights the need for and provides understanding of the challenges associated with human-machine teaming (HMT) test and evaluation (T&E) in defense, particularly measurement and testing protocols. The session will equip attendees to lead productive engagements in their respective communities, with a particular focus on bridging the gap between the technical, operational and policy communities\nThe REAIM Call to Action (2023) advocates for thorough research, testing, and assurance before adopting Al in the military domain to avoid inadvertent harms. The purpose of this session is to provide the REAIM community context on test and evaluation (T&E) for human-machine teams (HMT). Traditionally there has been extensive discussion on testing of Al algorithms, but less regarding HMT. There are a number of practical and technical challenges associated with such T&E this session will lay out these issues, associated questions and implications in a manner accessible to the broader community (technical and nontechnical). Greater understanding of T&E will help to drive responsible Al policy development, as well as acquisition and deployment of these systems.\nThis session will better enable treatment of these issues and will motivate investment in resolving these challenges across the community.", "sections": [{"title": "Summary", "content": "This session' highlights the need for and provides understanding of the challenges associated with human-machine teaming (HMT) test and evaluation (T&E) in defense, particularly measurement and testing protocols. The session will equip attendees to lead productive engagements in their respective communities, with a particular focus on bridging the gap between the technical, operational and policy communities\nThe REAIM Call to Action (2023) advocates for thorough research, testing, and assurance before adopting Al in the military domain to avoid inadvertent harms. The purpose of this session is to provide the REAIM community context on test and evaluation (T&E) for human-machine teams (HMT). Traditionally there has been extensive discussion on testing of Al algorithms, but less regarding HMT. There are a number of practical and technical challenges associated with such T&E this session will lay out these issues, associated questions and implications in a manner accessible to the broader community (technical and nontechnical). Greater understanding of T&E will help to drive responsible Al policy development, as well as acquisition and deployment of these systems.\nThis session will better enable treatment of these issues and will motivate investment in resolving these challenges across the community."}, {"title": "Full Summary", "content": ""}, {"title": "Background & Objectives", "content": ""}, {"title": "Background", "content": "The Political Declaration on the responsible use military of Al and autonomy (Nov, 2023) calls for the endorsing states to develop appropriate measures to ensure responsible Al at relevant stages of the Al lifecycle. The REAIM Call to Action (Feb 2023) advocates for thorough research, testing, and assurance before adopting Al in the military domain to avoid inadvertent harms. The purpose of this session was to provide the REAIM community context on test and evaluation (T&E) for Al systems that will interact with humans (encompassing nearly all systems).\nTraditionally there has been extensive discussion on test and evaluation (T&E) of Al algorithms, but much less discussion regarding a more wholistic approach to T&E that incorporates consideration of the human component (such as in human-Al teams). There are a number of practical and technical challenges associated with such T&E \u2013 this session sought to lay out these issues, associated questions and implications in a manner accessible to the broader community (technical and nontechnical). As humans are considered central to the responsible use of Al and remain accountable for the actions of such systems, greater consideration of the human component within T&E will help to drive responsible AI (RAI) policy development, acquisition, and deployment of these systems. This session will better enable treatment of these issues and will motivate investment in resolving these challenges across the community."}, {"title": "Objectives", "content": "1. Highlight the need for and provide understanding of the challenges\nassociated with HMT T&E in defence particularly measurement and testing\nprotocols.\n2. Equip attendees to lead productive engagements in their respective\ncommunities, with a particular focus on bridging the gap between the\ntechnical, operational and policymaker"}, {"title": "Main Discussion Points", "content": ""}, {"title": "David Helmer PhD (JHU/APL)", "content": "1. The community faces fundamental gaps in predicting real-world performance\nof Al-enabled capabilities due not only to challenges in Al test and evaluation,\nbut an inability to predict the effect of interactions of humans with those\nsystems\n1.1. This applies to essentially all capabilities when we talk about\nautonomous or semi-autonomous \"systems\", the \"system\u201d should include\nthe algorithm and/or platform but also the humans whose actions affect\nperformance\n2. Fundamental gaps exist in understanding and predicting human behavior\neven with simple systems; this extends to more complex Al-enabled systems\n3. Typical Al performance measures focused on algorithmic performance are\ninadequate, as they do not reflect sufficient understanding of realized\nperformance in operational context, which includes outcomes that are\nimpacted by interactions with humans (which can both improve and degrade\nperformance).\n3.1. This performance impact again emphasizes that for Responsible Al\ndeployment, we must take a system-of-systems view, where the human is\nconsidered as part of the system\n3.2. Many capabilities assume that a human will intervene to fix machine\nerrors, but the community generally does not currently effectively test to\nvalidate this assumption. And the possibility of human negation of a\ncorrect machine choice is often unaccounted for\n4. The community must understand gaps in evaluation of these systems and\nclose them technically while understanding implications to risk evaluation and\nacceptance\n4.1. Some example problems include the fact that most Al requires many test\npoints to evaluate, while humans can run only a small number of\ncases. Additionally, this testing is traditionally executed late in\ndevelopment, which makes change implementation difficult. Challenges\nexist for adjusting timelines, and there are no current demonstrated\nabilities to mitigate the limited test case problem nor to robustly\nunderstand the resultant unknown risk due to sample bias, limited data\nsets, etc.\n4.2. This is not just a technical challenge. It is critical that the legal and policy\ncommunities understand the constraints and possibilities to drive\nappropriate decision-making\n5. The goals and needs of this test, evaluation, verification, and validation (TEVV)\nprocess are not fundamentally changed for Al in comparison with legacy\nsystems in many ways these problems already exist for systems\ntoday. Challenges may be exacerbated, but the need to define and/or\nmitigate risk in TEVV is unchanged. The means to do so will in some cases\nneed to evolve."}, {"title": "Mr Michael Boardman (DSTL)", "content": "6. Human Machine Teaming approaches and the onus of accountability resting\non the human user within Al-based systems will demand an approach to TEVV\nthat isn't just technologically focused. It must include the user as part of the\nsystem,\ntogether with consideration of their training, mental\nmodels/understanding of the system and capability to meaningfully interact\nwith the technological component of the system when needed.\n7. TEVV will be an ongoing process across the lifecycle of the system \u2013 where\ncontext of use, operational environment etc change TEVV must reoccur\n(potentially rapidly and in theatre).\n8. Means of communicating the results of TEVV to those using and making\ndecisions regarding the use of Al based systems will be key in informing risk\nbased decisions regarding use."}, {"title": "DR S. Kate Conroy (QUT)", "content": "9. The REAIM 2024 Blueprint for Action ('Blueprint'):\n10. Commit to engaging in further discussions and to promoting dialogue\non developing measures to ensure responsible Al in the military domain\nat the national, regional and international level, including through"}, {"title": "Lieutenant Colonel Adam J. Hepworth, PhD (Australian Army)", "content": "12. Traditional military governance and assurance models, which are often\nprescriptive and input-based, may not be adequate for Al's dynamic and\nunpredictable nature. An outcome-focused approach is necessary to ensure\nAl systems achieve desired results while adhering to ethical and legal\nstandards.\n13. Confidence-building measures, such as sharing Al performance data, are\ncrucial for collaboration and mutual understanding.\n14. Often there exists a gap between ethical discourse and practical military\noperations. TEVV frameworks are essential but must be grounded in\noperational realities to effectively support human-centric decision-making.\n15. Al-enabled systems should operate contextually and predictably within\ndefined situations. Rigorous TEVV processes are essential to assuring human\nmilitary commanders and operators of system employment.\n16. Additionally, robust governance frameworks must be in place at every level,\nfrom design to deployment, ensuring that the autonomy granted to Al\nsystems is carefully managed and aligned with operational objectives."}, {"title": "MR Manoj Harjani (RSIS Nanyang Technological University)", "content": "17. There are potential challenges arising from standards for human-centred T&E\nbeing politicized - i.e., it becomes less about the standards and more about\nwho has been involved in developing them.\n18. We also need to consider the organisational politics within militaries that will\naffect T&E implementation - the standards and practices that eventually are\nadopted will be shaped by the interest group that wins out.\n19. Anticipatory methods are one possible tool for militaries to navigate the\nchallenges associated with the politics surrounding T&E implementation"}, {"title": "Audience", "content": "1. Make-up\n1.1. 20% core work in T&E\n1.2. 80% expertise in Operationalization, Data practices, Intl law & policy,\nDiplomacy, Arms control, Human rights, Law, Defence policy, Regulation\n2. Audience felt that human-centred test and evaluation of military Al is (>50%\nparticipants assent, little dissent):\n2.1. Al systems are tested with human operators in their intended context of\nuse and anticipated deployment conditions ahead of use\n2.2. Al systems are evaluated for their effectiveness with human operators\n2.3. Al systems deployed in their intended use comply with international\nhumanitarian law.\n3. Audience felt that human-centred test and evaluation of military AI POSSIBLY\nis (more participants assent than dissent)\n3.1. Human feedback drives product updates throughout the Al lifecycle\n3.2. Al systems are assessed for human impacts to inform risk management\n3.3. Human factors of Al systems affect acquisition decision making\n3.4. Al systems are designed to augment human decision making\n3.5. Al systems are designed to improve human agency and autonomy\n4. Audience felt that human-centred test and evaluation of military Al MAY OR\nMAY NOT be (same participants assent and dissent)\n4.1. Al systems are designed for the wellbeing of operators\n4.2. Stakeholder values are elicited in order to determine requirements for Al\nsystems\n4.3. Al systems are designed to reduce human biases\n5. Audience felt that human-centred test and evaluation of military Al is NOT\n(more participants dissent than assent)\n5.1. Human performance is measured when using Al-enabled systems\n5.2. Those responsible for Al systems need to prioritise reducing unintended\nharms that may be caused by use of these systems.\n5.3. Al systems are designed to improve justice outcomes for humanity\n6. Audience wants to get out of the workshop:\n6.1. Al and relevance to asymmetry in conventional wars\n6.2. How international human rights law could inform\n6.3. How testing and eval contributes to legal reviews\n6.4. Why humans should be centered instead of ai\n6.5. Awareness raising on international law\n6.6. A broad perspective on how Nations are approaching\n6.7. Awareness of human-centred T&E's importance\n6.8. Some concrete approaches of test and evaluation\n7. Audience did not want to spend time on:\n7.1. Mathematics\n7.2. Too much conceptual discussions\n7.3. LAWS\n7.4. Al ethics principles\n7.5. Definitions"}, {"title": "Key Takeaways", "content": ""}, {"title": "Lieutenant Colonel Adam J. Hepworth, PhD (Australian Army)", "content": "1. The REAIM Blueprint noted that Al applications should be ethical and human-\ncentric and that humans must remain responsible and accountable for their\nuse and effects. Developing rigorous TEVV frameworks will contribute to\nrobust oversight mechanisms.\n2. Adopting a human-centric model of 'decision custodianship' where algorithms\nact as tools to augment human capacity needs further attention. Ensuring that\nthe behaviour and outputs of Al-enabled systems are reliable and consistent\nwill provide confidence for human military commanders and operators.\n3. Developing cross-function teams is required to ensure an exhaustive approach\nto TEVV in military operations."}, {"title": "MR Manoj Harjani (RSIS Nanyang Technological University)", "content": "4. The need for dialogue between technologists and policymakers on human-\ncentred T&E will be evergreen - but dialogue needs to be initiated with an\nobjective in mind for it to be productive.\n5. There will be a need to address potentially fragmented and siloed\nimplementations of T&E across different countries' militaries absolute\nconsensus and complete interoperability is unrealistic, but there should be a\nfocus on implementation according to standards that are more widely\naccepted.\n6. How can T&E become a focal point for confidence-building among militaries?"}, {"title": "Remaining Challenges and Issues", "content": ""}, {"title": "DR S. Kate Conroy (QUT)", "content": "1. Test and evaluation in the development of Al systems needs to involve human\nusers and the development of Al systems may go on throughout the\ndeployment of the Al system in agile, iterative Al development, iteration,\nupdates and adaptation within contexts of operations\n2. Traditional human-centred test and evaluation methods from human factors\nincluding objective measures (e.g. eye tracking) and subjective measures (e.g.\nself-reports) of fatigue, cognitive overload, attention, wellbeing etc.. need to\nbe adapted for deployed Al systems that require ongoing monitoring and\nevaluation.\n3. New standards need to be developed to help users of general purpose Al\nsystems to capture qualities of these systems such as veracity, useability,\nproductivity advantage, meaningful work etc.."}, {"title": "DR David Helmer (JHU APL)", "content": "4. The community must acknowledge that essentially every Al-enabled system\nis impacted by a human, whether in a positive way (e.g. mitigating errors) or\na negative. Test and evaluation in support of Responsible Al deployment\nMUST include the effect of the human to reflect operationally realized system\nperformance. The language around Al-enabled systems should be shifted to\ninclusion of the human(s) as a component of the system\n5. Standards and requirements supporting this adjusted definition are needed,\nas are metrics and means to evaluate them\n5.1. Effective modeling and simulation is highly desirable, but is not currently\nachievable in any validated manner.\n5.2. Development of test and evaluation that is achievable earlier in the\nprocess and also throughout system lifecycle is critical to support this\nevolution for a variety of reasons, including the issue of human scalability\nand impact on scale of achievable testing\n6. Communication between technical and non-technical communities must be\nimproved to ensure operators and policy-makers understand risk assumed by\nsystem use and to better inform research and development by technologists\nin the test and evaluation space"}, {"title": "Future Plans", "content": "Collaboration to deliver to REAIM 2024 Blueprint for Action."}]}