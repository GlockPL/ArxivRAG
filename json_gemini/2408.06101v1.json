{"title": "Generalization capabilities of MeshGraphNets to unseen geometries for fluid dynamics", "authors": ["Robin Schm\u00f6cker", "Alexander Henkes", "Julian Roth", "Thomas Wick"], "abstract": "This works investigates the generalization capabilities of MeshGraphNets (MGN) [Pfaff et al. Learning Mesh-Based Simulation with Graph Networks. ICML 2021] to unseen geometries for fluid dynamics, e.g. predicting the flow around a new obstacle that was not part of the training data. For this purpose, we create a new benchmark dataset for data-driven computational fluid dynamics (CFD) which extends DeepMind's flow around a cylinder dataset by including different shapes and multiple objects. We then use this new dataset to extend the generalization experiments conducted by DeepMind on MGNs by testing how well an MGN can generalize to different shapes. In our numerical tests, we show that MGNs can sometimes generalize well to various shapes by training on a dataset of one obstacle shape and testing on a dataset of another obstacle shape.", "sections": [{"title": "1 Introduction", "content": "For many engineering applications, we need to have fast and accurate simulations of fluid dynamics. In this work we focus on the modeling of fluids by the incompressible Navier-Stokes equations [28, 66, 55, 30, 68, 31, 25, 40]. With regard to numerical modeling, various spatial discretization techniques are known such as the finite volume method [50] and the finite element method [30]. Temporal discretization is often based on finite difference schemes [31, 68] or space-time discretizations [49, 11, 5]. The arising nonlinear and linear systems are often solved with iterative techniques or multigrid schemes. Implementations on CPUs can be computationally expensive and can take a long time to run. To overcome this, we can use parallelization to multiple processors or GPUs [67, 39, 6, 5] or only refine the mesh in regions where the solution is not accurate enough [10, 14, 11, 56]. Nevertheless, even though this can speed up the simulation, fluid simulations can still be prohobitively expensive for multi-query problems, e.g. different material parameters, different geometries, or different boundary conditions. Therefore, for real-time simulations or multi-query problems, we need to find a way to speed up the simulation even further, e.g. by means of data-driven methods. A popular method to reduce the"}, {"title": "2 MeshGraphNets", "content": "We briefly recapitulate the MeshGraphNets (MGN) method introduced by Pfaff et al. in [54]. MGNs are a deep learning approach for predicting the evolution of complex physics systems by applying graph neural networks to a mesh graph. The method is based on the idea of encoding the system state into a mesh graph, applying a graph neural network to this graph to predict the change of the system, and then applying this change to the simulation state. The method is autoregressive, meaning that the"}, {"title": "2.1 Neural Networks", "content": "An artificial neural network (ANN) is a parametrized, nonlinear function composition. By the universal function approximation theorem [38], arbitrary Borel measurable functions can be approximated by ANN. There are several different formulations for ANN, which can be found in standard references such as [12, 32, 1, 29, 22]. Following [35], most ANN formulations can be unified. An ANN N is a function from an input space $R^{d_x}$ to an output space $R^{d_y}$, defined by a composition of nonlinear functions $h^{(l)}$, such that\n\n$N: \\mathbb{R}^{d_x} \\rightarrow \\mathbb{R}^{d_y}$\n$x \\rightarrow N(x) = h^{(n_L)} \\circ ... \\circ h^{(0)} = y, \\quad l = 1,...,n_L.$\n\nHere, x denotes an input vector of dimension $d_x$ and y an output vector of dimension $d_y$. The nonlinear functions $h^{(l)}$ are called layers and define an l-fold composition, mapping input vectors to output vectors. Consequently, the first layer $h^{(0)}$ is defined as the input layer and the last layer $h^{(n_L)}$ as the output layer, such that\n\n$h^{(0)} = x \\in \\mathbb{R}^{d_x}, \\quad h^{(n_L)} = y \\in \\mathbb{R}^{d_y}.$\n\nThe layers $h^{(l)}$ between the input and output layer, called hidden layers, are defined as\n\n$h^{(l)} < h^{(l)}_\\eta>_{\\eta = 1,..., n_u}, \\quad h^{(l)}_\\eta = \\phi^{(l)}_\\eta \\circ \\varphi^{(l)}(W^{(l)}_\\eta h^{(l-1)}),$ \n\nwhere $h^{(l)}_\\eta$ is the $\\eta$-th neural unit of the l-th layer $h^{(l)}$ and $n_u$ is the total number of neural units per layer, while $\\bullet$ denotes a product. Following the notation in [41], the symbol $<$ denotes an abbreviation of a tuple of mathematical objects $(O_1, O_2, ...)$, such that $O < (O_1, O_2, ...)$. In (3), the details of type-specific layers $h^{(l)}_\\eta$ are gathered in general layers $h^{(l)}$ from (1). The specification follows from the $\\bullet$-operator, which denotes the operation between the weight vector $W^{(l)}_\\eta$ of the $\\eta$-th neural unit in the l-th layer $h^{(l)}$ and the output of the preceding layer $h^{(l-1)}$, where the bias term is absorbed [1]. If $\\bullet$ is the ordinary matrix multiplication $\\bullet = \\cdot$, then the layer $h^{(l)}$ is called dense layer. In the context of GNNs, the choice of the operator as $\\bullet = \\oplus$, where $\\oplus$ is a permutation invariant aggregation operator, yields the so-called message passing network [16]. Furthermore, $\\varphi^{(l)}: \\mathbb{R} \\rightarrow \\mathbb{R}$ is a nonlinear activation function and $\\phi^{(l)}$ is a function of the previous layer, such that $\\phi^{(l)}: h^{(l-1)} \\rightarrow \\varphi^{(l)}(h^{(l-1)})$. If $\\varphi^{(l)}$ is the identity function, the layer $h^{(l)}$ is called a feedforward layer. All weight vectors $W^{(l)}_\\eta$ of all layers $h^{(l)}$ can be gathered in a single expression, such"}, {"title": "2.2 Mesh Graph Networks", "content": "In this section, we introduce MGN, a deep learning approach for predicting the evolution of complex physics systems by applying graph neural networks to a mesh graph. This is based on the paper [54] by Pfaff et al. which is an extension of their previous paper on graph network based simulations [59]. In the following and overall in this paper, we introduce and test MGNs for the Flow around the Cylinder benchmark (abbreviated as Cylinder Flow). However, we notice that our developments can be applied to other computational fluid dynamics numerical tests as well."}, {"title": "2.2.1 Incompressible Navier-Stokes equations", "content": "Let $\\Omega \\subset \\mathbb{R}^2$ be some domain with sufficiently smooth boundary $\\partial\\Omega$. Moreover, let (0, T) be the time interval with end time value T > 0. To generate training data, we model incompressible, viscous fluid flow with constant density and temperature by the Navier-Stokes equations\n\n$\\begin{aligned}\n&\\partial_t v - \\nabla_x \\cdot \\sigma + (v \\cdot \\nabla_x)v = 0\\quad &&\\text{in } \\Omega \\times (0, T), \\\\\n&\\nabla_x \\cdot v = 0 &&\\text{in } \\Omega \\times (0, T), \\\\\n&v = v_D &&\\text{on } \\partial\\Omega \\times (0, T), \\\\\n&v(0) = v^0 &&\\text{in } \\Omega \\times \\{0\\},\n\\end{aligned}$\n\nwhere for the stress $\\sigma$ we use the unsymmetric stress tensor\n\n$\\sigma:= \\sigma(v,p) = -pI + \\nu \\nabla_x v.$\n\nPlugging the definition of the unsymmetric stress tensor into the Navier-Stokes equations leads to the following formulation:\n\nFormulation 2.1 (Incompressible Navier-Stokes equations). Find the vector-valued velocity $v : \\Omega \\times$"}, {"title": "2.2.2 MGN idea", "content": "On a high level, the MGN approach can be explained as follows: First, we triangulate the domain to represent it as a mesh graph. We then encode the current system state $s_k$ into the graph's nodes and edges. Next, we use a graph neural network to predict quantities which can be used to directly compute how $s_k$ evolves to $s_{k+1}$. In Cylinder Flow, we will use an MGN to directly predict the pressure field $p_{k+1}$, and the change in velocity $\\delta v = v_{k+1} - v_k$. Fig. 2 visualizes this process."}, {"title": "2.2.3 System state encoding", "content": "In this step, we want to encode the system state $s_k$ into a graph. As a first step, the domain $\\Omega$ has to be triangulated to obtain a mesh graph $G = (V, E)$ where $V \\subseteq N$ are the vertices and $E \\subseteq \\{e \\in P(V) : |e| = 2\\}$ are the edges.\n\nNext, we encode the position information into the graph: Let $e = \\{v_1, v_2\\} \\in E$ and $x_{v_1}, x_{v_2} \\in \\Omega$ be the domain coordinates associated with these two vertices. We assign the distance $||x_{v_1} - x_{v_2}||_2$ and the relative displacement $x_{v_1} - x_{v_2}$ as features to e. It would also be possible to encode the absolute positions in the nodes. Experiments showed, however, that this is not a viable option [54]. To better capture the structure of the mesh, the node type is added as a feature to each vertex. In the case of Cylinder Flow there are four types of nodes:\n\n\\noindent$\\bullet$ fluid nodes,\n\n\\noindent$\\bullet$ wall (top, bottom, and cylinder) nodes,\n\n\\noindent$\\bullet$ inflow nodes,\n\n\\noindent$\\bullet$ outflow nodes.\n\nBesides the node type we also add the values of the fields of $s_k$ needed to predict $s_{k+1}$ as features to each vertex. For example, in the case of Cylinder Flow, each vertex $\\nu \\in V$ with associated coordinates $x \\in \\Omega$ gets the value of the velocity field $v_k$ at position x. Though pressure is also part of $s_k$, it is not encoded as $v_k$ already determines the pressure values hence they are not needed to predict $s_{k+1}$. The resulting graph and its associated features now approximately model $s_k$."}, {"title": "2.2.4 Graph processing", "content": "In this step, we use the graph-encoding of the previous step to predict $s_{k+1}$. For the incompressible Navier-Stokes equations, we directly predict the pressure $p_{k+1}$ and the change in velocity $\\delta v = v_{k+1} - v_k$. The processing is done in three different steps.\n\n\\noindent 1. First, to prepare the features for processing, we use a feedforward-network to encode the edge features and another feedforward-network to encode the vertex features at each edge/vertex. We say that the features are embedded into latent space. In theory, this step is not needed. However, in practice without this step, the network would not perform well. This is because in the next step, these features will iteratively be updated to finally arrive at the prediction for the quantity change. If we do not encode the features in this first step, the information captured in these intermediate states is always restricted to the dimension of the input features. Therefore, this step can be viewed as widening the information bottleneck."}, {"title": "2.2.5 Updating the system state", "content": "Assume that $q_{k+1}: V \\rightarrow \\mathbb{R}^3$ is the output of our MGN with input $s_k$. We interpret $q_{k+1}$ as the derivative of the velocity field $v_k$ and the pressure $p_{k+1}$, i.e. $q_{k+1} = (q_{1,k+1}, q_{2,k+1}) \\approx (\\partial_t v_k, p_{k+1})$ where $\\partial_t v_k$ denotes the time derivative of the velocity field at time $\\Delta t_k$. Our prediction $s_{k+1}$ at node $\\nu \\in V$ with coordinates $x \\in \\Omega$ is then given by\n\n$\\tilde{s}_{k+1}(x) = (v_k(x) + \\Delta t \\cdot q_{1,k+1}(\\nu), q_{2,k+1}(\\nu)).$"}, {"title": "2.2.6 Training MGNs", "content": "In this section, we discuss the training details of MGNs. First, note that each step as detailed in the previous section is differentiable. Hence, the predicted quantities at each vertex are differentiable with respect to the parameters of all neural networks that were used. Therefore, we can define a differentiable loss $L$ at each node $\\nu \\in V$ with coordinates $x \\in \\Omega$ by taking the mean-squared-error of the MGN"}, {"title": "3 Generalization Capabilities of MeshGraphNets and Numerical Simulations", "content": "In this section, we will present experimental results on the generalization of MGNs to unseen datasets. First, in Section 3.1 we will describe our experiment setup. Then, in Section 3.2 we will present the datasets of the generalization experiments, followed by the results in Section 3.3 and the runtimes in Section 3.4. The code used for these experiments is publicly available [65]."}, {"title": "3.1 Setup of the experiments", "content": "In this section, we will describe the exact setup for the MGNs used for the generalization experiments. We will also describe which evaluation metrics for the MGNs were used for the subsequent experiments."}, {"title": "3.1.1 Implementation", "content": "For the generalization experiments, we use the implementation contained in NVIDIA's Modulus, a machine learning framework for physics [36, 53]. More specifically, the exact implementation contained in examples/cfd/vortex_shedding_mgn\\footnote{https://github.com/NVIDIA/modulus/tree/main/examples/cfd/vortex_shedding_mgn} from NVIDIA Modulus [53] was used for experimentation with modifications only affecting logging and the learning rate schedule which is now only updated after every epoch such that the learning rate in epoch l is $\\eta_1 \\gamma^{l-1}$ for some initial learning rate $\\eta_1$ and learning rate decay $\\gamma$."}, {"title": "3.1.2 MGN architecture details", "content": "We highlight some notable architectural choices of the MGNs.\n\n\\noindent$\\bullet$ Input and target normalization: The training data set is used to compute the mean and variance of all edge features and of the velocity and pressure for the node features. The features of all inputs and targets are then normalized using their corresponding mean and variance.\n\n\\noindent$\\bullet$ Residual connections: The MGN will be extremely deep, therefore residual connections are added such that the input of each MBP is directly added to its output.\n\n\\noindent$\\bullet$ Layer normalization: Since we will be using a batch size of one but still want to normalize the hidden-layer outputs to reduce the covariate shift (i.e. gradients in layer i tend to highly depend on the outputs of layer i - 1), we employ layer normalization [8] at the output of the edge/node encoder and after each MPB (before the residual connection). Layer normalization transforms an output $x \\in \\mathbb{R}^n$ as follows:\n\n$y = \\frac{x - E[x]}{\\sqrt{Var[x] + \\epsilon}} \\cdot \\alpha + \\beta$\n\nwhere $E[x]$ is subtracted componentwise and\n\n$\\mathbb{E}[x] = \\frac{1}{n} \\sum_{i=1}^n x_i, \\quad Var[x] = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\mathbb{E}[x])^2$\n\nwhere $\\alpha, \\beta \\in \\mathbb{R}$ are learnable parameters and $\\epsilon > 0$ for numerical stability. We used $\\epsilon = 10^{-5}$."}, {"title": "3.1.3 Hyperparameters", "content": "The exact hyperparameters from examples/cfd/vortex_shedding_mgn\\footnote{https://github.com/NVIDIA/modulus/tree/main/examples/cfd/vortex_shedding_mgn} from NVIDIA Modulus [53] were used for the subsequent experiments. The only exception is the learning rate decay factor $\\gamma$ since we used a slightly different implementation of the learning rate decay schedule as described in Subsection 3.1.1. Table 1 lists the hyperparameters."}, {"title": "3.1.4 Evaluation criteria", "content": "For each experiment, we use at least 10% of the total dataset for evaluation. The exact evaluation datasets will be mentioned in the corresponding experiment. Let $K \\in \\mathbb{N}$ denote the number of simulations, let $J \\in \\mathbb{N}$ denote the number of time steps in each simulation, and let $I_k \\in \\mathbb{N}$ denote the number of mesh nodes in the k-th simulation with $k \\le K$ of the evaluation dataset. For evaluation, we measure eight quantities. The first four are derived from the root-mean-squared-error (RMSE) of the velocity. Let $v_{i,j,k} \\in \\mathbb{R}^2$ denote the velocity vector at mesh node $i \\le I_k$ and time step $j \\le J$ in the k-th ($k \\le K$) simulation of the evaluation dataset obtained by performing the IPCS (more details on the dataset generation in the next section). Furthermore, we use $\\tilde{v}_{i,j,k}$ to denote the MGN velocity prediction from $v_{i,j-1,k}$ if $j > 1$ and $v_{i,1,k}$ if $j = 1$. Lastly, by $\\hat{v}_{i,j,k}$ we denote the MGN velocity prediction from $v_{i,j-1,k}$ if $j > 1$ and $v_{i,1,k}$ if $j = 1$. From which MGN the predictions come will be specified every time one of the following error quantities is reported.\n\n\\noindent$\\bullet$ Velocity 1-step error $\\epsilon_1^{(v)}$: This error is the RMSE for all the next state velocity predictions of all timesteps of all simulations which is given by\n\n$\\epsilon_1^{(v)} = \\sqrt{\\frac{\\sum_{k=1}^K \\sum_{j=1}^J \\sum_{i=1}^{I_k} ||v_{i,j,k} - \\tilde{v}_{i,j,k}||_2}{I_k J K}}$\n\n\n\\noindent$\\bullet$ Velocity 50-steps error $\\epsilon_{50}^{(v)}$: Each simulation is rolled out for 50 timesteps. The RMSE is then taken for the rollout velocity at each of the first 50 time steps compared to the IPCS result for all simulations. This given by\n\n$\\epsilon_{50}^{(v)} = \\sqrt{\\frac{\\sum_{k=1}^K \\sum_{j=1}^{50} \\sum_{i=1}^{I_k} ||v_{i,j,k} - \\hat{v}_{i,j,k}||_2}{I_k \\cdot 50 \\cdot K}}$"}, {"title": "3.2 Generalization experiments: Datasets", "content": "The experiments in this section have the aim of expanding DeepMind's MGN generalization experiments. DeepMind claims that their MGN has strong generalization capabilities due to using a relative encoding on the mesh graphs, however, they report no experimental evidence for this for their Cylinder Flow based dataset at all [54]. Additionally, in their Airfoil experiments of compressible Navier-Stokes equations, which is a related problem to Cylinder Flow, they only test the MGN by using values for the system parameters (such as the inflow speed) that are slightly out of the training distribution. What they do not do is test the MGN on qualitatively different meshes such as one where a different shape other than a circle is used.\n\nTherefore, in this section, we apply a trained MGN to similar but qualitatively different datasets than it was trained on in which the cylinder may be stretched or squeezed (cylinder\\_stretch), the cylinder might be replaced with a triangle or rectangle (cylinder\\_tri\\_quad), there could even be multiple cylinders (2cylinders), or all modifications mixed together (mixed\\_all) or simply no modifications (standard\\_cylinder).\n\nThe datasets consist of approximations of solutions (velocity v and pressure p) to the Cylinder Flow problem. The datasets are created by varying the inflow profile or applying changes to the cylinder. Whenever possible, the distributions for the parameters we used were reverse-engineered from Google Deepmind's dataset [54] assuming that uniform distributions were used. One notable difference to the DFG\\footnote{DFG stands for German Research Foundation} 2D-2 benchmark problem [62] is that the pipe is a bit shorter (1.6 instead of 2.2 length) to speed up computation. Other than that, the range of parameters includes this benchmark problem. We note that the mean values for certain quantities such as the x-position of the cylinder are not always"}, {"title": "3.2.1 Comparison to DFG 2D-2 benchmark", "content": "To verify our experiment setup for generating datasets, we computed some quantities of interest and compared them to the Navier-Stokes 2D-2 benchmark results by Sch\u00e4fer and Turek [62]. For this, we"}, {"title": "3.3 Generalization experiments: Results", "content": "We tested the generalization capabilities of the MGNs. For this, we tested each MGN on every dataset. E.g. train on cylinder\\_stretch and evaluate on 2cylinders and do this for every possible dataset-pair. Table 3 (resp. 4, 5, 6, 7) shows the results if an MGN was trained on all of the five datasets and evaluated on standard\\_cylinder (resp. cylinder\\_stretch, cylinder\\_tri\\_quad, 2cylinders, mixed\\_all) in terms of the pressure and velocity RMSE as described in Section 3.1.4. Additionally, these tables also contain the RMSEs for newly initialized MGNs that were not trained to act as a benchmark for comparison. All reported velocity errors have been rounded to five decimal places and all pressure errors have been rounded to four decimal places."}, {"title": "3.3.1 General observations", "content": "Before we draw any conclusions, we will put into context what these RMSE values mean. All models produce physically reasonable predictions on every dataset and the following observations apply to all training-evaluation dataset pairs. There are three main ways in which the MGN prediction differs from our FEM simulation.\n\nFirstly, the MGN prediction for all models sometimes does not predict vortex shedding. This is more likely to happen for inflow peaks that are at the border where vortex shedding starts to occur. Fig. 4 shows an example of this. All figures presented in this and the following sections show only the pressure or velocity field prediction at the final time step. However, for each figure, we uploaded the full simulation animation as a gif file to this work's GitHub repository [65]."}, {"title": "3.3.2 Predictions for coinciding train and test datasets", "content": "We observed that if the MGN is trained on the same dataset it is evaluated on and it predicts vortex shedding, then these vortices have mostly the same characteristics as the IPCS solution which is only partially the case for differing train and evaluation datasets as we shall see later. Fig. 9 shows one simulation and its prediction for each of the five datasets when the network was trained on the same dataset. The simulations were picked to have an RMSE near the RMSE median for that dataset."}, {"title": "3.3.3 Predictions for differing train and test datasets", "content": "Though the RMSE values in all metrics do not differ much in relative terms between different training-evaluation dataset pairs, we can observe discrepancies when looking at the simulations. Fig. 10 shows predictions of a model trained on standard cylinder and evaluated on a selection of simulations from different datasets. This figure shows that if vortex shedding is predicted, it is essentially a coin flip whether the correct vortex pattern is predicted on a previously unseen shape. This is not reflected in the RMSE as an out-of-sync but characteristically correct vortex prediction can have the same RMSE as a straight-up wrong pattern."}, {"title": "3.3.4 Intermediate conclusions", "content": "Judging purely from the reported RMSE values, one could argue that MGNs generalize well for all training-evaluation dataset pairs. All training-evaluation dataset pairs' velocity RMSE is almost always an order of magnitude below what a freshly initialized MGN would produce in all metrics. For most datasets (unsurprisingly) the model that was evaluated and trained on the same dataset performs best. However, the other models which were trained on different datasets perform only slightly worse in relative terms.\n\nIn general, MGNs are strong at predicting flow on a coarse level, therefore they almost always produce a physically reasonable prediction even for unseen shapes. However, their main weakness is"}, {"title": "3.4 Generalization experiments: Runtimes", "content": "In this section, we compare the runtime of an MGN to that of the IPCS on standard_cylinder using the implementation and hyperparameters we described in the experiment setup. For the MGN we differentiate between using a GPU and only using a CPU. The aim is to find the number of simulations one wants to generate at which it is computationally more efficient to use an MGN over the IPCS. All runtimes reported in the following are extrapolations.\n\nFirstly, we consider the case where we only use a CPU. In this case, we consider a system with six Intel(R) Core(TM) i5-9600K @ 3.70GHz CPUs with 32 GB of RAM. Using this system, we need roughly 0.3125h to generate a single simulation using the IPCS which results in circa 125h to generate the entire standard_cylinder train dataset. We then need roughly 1138h to train the MGN and then approximately 0.048h to generate a new simulation using the MGN. At inference time, this is an approximately 6.5 times speedup.\n\nNext, we consider the case where we have access to a GPU for training and inference of the MGN. Keeping everything as above and using the Alienware m17 R5 AMD laptop with the GeForce RTX 3070 Ti as the GPU with 8 GB of RAM only for the MGN training and inference, we get a total MGN training time of roughly 58h and then approximately 0.0031h to generate a new simulation. At inference time, this is an approximately 100.8 times speedup."}, {"title": "4 Conclusion", "content": "In this work, we investigated MGNs by extending the generalization experiments of DeepMind [54] by evaluating MGNs on meshes with previously unseen shapes. For this, we first created five datasets standard_cylinder, cylinder_stretch, cylinder \\_tri\\_quad, 2cylinders, and mixed\\_all, which contain simulations of fluid flow around one or two objects of different shapes. We showed that MGNS in general can produce physically reasonable predictions for meshes with unseen shapes. Additionally, our MGNs managed to correctly predict vortex patterns for many unseen shapes. However, when a shape has not yet been seen in training the MGN is equally likely to falsely predict the vortex pattern for inflow peaks at which vortex shedding occurs. Nevertheless, for many engineering appliactions it is sufficient to have a coarse approximation of the flow field and the inference of the MGN is in our simulations up to 100 times faster than the classical numerical solver.\n\nIn the future, one could consider differently shaped domains as opposed to the rectangular one chosen here and other fluid benchmark problems like lid-driven cavity or backward facing step. Additionally, one could also consider adding system parameters like the viscosity to the MGN and consider varying it during training and see how well the MGN generalizes in this case."}]}