{"title": "HARMONIC: Harnessing LLMs for Tabular Data Synthesis and Privacy Protection", "authors": ["Yuxin Wang", "Yongfu Dai", "Sophia Ananiadou", "Zhengyu Chen", "Duanyu Feng", "Jimin Huang", "Qianqian Xie", "Hao Wang"], "abstract": "Data serves as the fundamental foundation for advancing deep learning, particularly tabular data presented in a structured format, which is highly conducive to modeling. However, even in the era of LLM, obtaining tabular data from sensitive domains remains a challenge due to privacy or copyright concerns. Hence, exploring how to effectively use models like LLMs to generate realistic and privacy-preserving synthetic tabular data is urgent. In this paper, we take a step forward to explore LLMs for tabular data synthesis and privacy protection, by introducing a new framework HARMONIC for tabular data generation and evaluation. In the tabular data generation of our framework, unlike previous small-scale LLM-based methods that rely on continued pre-training, we explore the larger-scale LLMs with fine-tuning to generate tabular data and enhance privacy. Based on idea of the k-nearest neighbors algorithm, an instruction fine-tuning dataset is constructed to inspire LLMs to discover inter-row relationships. Then, with fine-tuning, LLMs are trained to remember the format and connections of the data rather than the data itself, which reduces the risk of privacy leakage. In the evaluation part of our framework, we develop specific privacy risk metrics DLT for LLM synthetic data generation, as well as performance evaluation metrics LLE for downstream LLM tasks. Our experiments find that this tabular data generation framework achieves equivalent performance to existing methods with better privacy, which also demonstrates our evaluation framework for the effectiveness of synthetic data and privacy risks in LLM scenarios.", "sections": [{"title": "Introduction", "content": "In the age of deep learning, tabular data is a predominant data format and a key element for building more effective algorithms to solve specific applications in various fields [1, 2]. However, in many sensitive domains such as business [3], healthcare [4], and governmental operations [5], there are significant limitations on the acquisition and use of tabular data. Tabular data in these domains involves personal privacy, business secrets, or state secrets. The collection and use of such data are strictly regulated by laws and regulations, and compliance with relevant data protection requirements is necessary. Unauthorized use or disclosure may result in serious privacy infringement or business losses. Therefore, generating data that ensures the effectiveness in modeling these data while preserving privacy in tabular data synthesis has always been a critical research area [6, 7, 8].\nTraditionally, tabular data synthesis relied on methods like GANs [9, 10, 11], VAEs [12, 13], and Diffusion Models [14, 15, 16, 17]. These techniques, built on mathematical foundations and complex frameworks, significantly advanced the field. However, the rise of Large Language Models (LLMs) with their impressive ability to generate realistic data has shifted the paradigm. Methods like GReaT [18] and TabuLa [6] leverage LLMs for faster synthesis by converting tables to natural language and predicting the next data token. They often utilize smaller pre-trained models like GPT-2 [19] for efficiency. Despite their advantages, LLMs introduce significant privacy concerns [20, 21]. These models may potentially leak sensitive information from the training data they are exposed to. Therefore, a crucial area of exploration lies in developing strategies to mitigate these privacy risks while harnessing the power of LLMs for tabular data synthesis.\nTo Harness LLMs for Tabular Data SyNthesis and PrIvacy Protection, we develop a new framework, HARMONIC2, with tabular data generation and evaluation on LLMs. For the tabular data generation framework, we use existing larger-scale LLMs to leverage their understanding abilities for generating tabular data while ensuring privacy. It is based on the idea of k-nearest neighbor classification (kNN) [22], which lets the LLMs see the relationship between multiple similar rows and construct the structural tabular synthetic data format. With this format, we obtain the instruction-tuning datasets that retain more structural information for LLMs to enhance the ability to generate synthetic data through fine-tuning, while avoiding the forced memorization of data with pre-training. Meanwhile, to comprehensively assess the effectiveness and privacy of synthetic data generated by LLMs, our framework introduces two novel metrics: DLT (Data Leakage Test) and LLE (LLM Efficiency). DLT quantifies the privacy risk of the synthesized data by LLMs. Conversely, LLE evaluates the effectiveness of the synthetic data in downstream LLM tasks. The evaluation of the effectiveness of downstream LLM tasks is based on the increasing application of LLMs in various fields. It is important to note that machine learning-based evaluations are no longer sufficient.\nUsing our evaluation framework, we assess four datasets commonly used for classification tasks in tabular data synthesis. The results show that synthetic data generated with HARMONIC performs comparably to existing methods in machine learning and excels in downstream tasks and privacy assessments in LLMs. Crucially, HARMONIC's evaluation suggests that traditional synthetic data methods may be unsuitable for downstream LLM tasks and that pretraining-based synthetic data poses significant privacy risks.\nThe main contributions of this study can be summarized as follows: 1) We recognize that it is crucial to not only focus on the strong data generation ability of LLM in this era, but also pay attention to the potential privacy risks it may bring. 2) We develop a framework, HARMONIC, for synthesizing tabular data based on LLM. The framework aims to minimize the risk of data leakage while ensuring the effectiveness of data synthesis using LLM. 3) Under the HARMONIC framework, a set of metrics is proposed for the effectiveness in downstream LLMs tasks and privacy risk evaluation of synthetic tabular data."}, {"title": "Related work", "content": "Tabular Data Synthesis. Prior to the rise of Large Language Models (LLMs), synthetic tabular data generation primarily relied on machine learning or classical neural network frameworks. These methods can be broadly categorized into three groups: Simple Augmentation, Generative Adversarial"}, {"title": "Our Framework: HARMONIC", "content": "This chapter delves into the HARMONIC framework for tabular data synthesis powered by LLMs, encompassing both generation and evaluation modules."}, {"title": "Synthetic Tabular Data Generation Framework", "content": "In this section, we present our approach to fine-tuning pre-trained LLMs for the generation of synthetic tabular data, including three key stages: (1) Construct instruction dataset: Construct an instruction fine-tuning dataset designed to fine-tune the generator model and a prompt dataset to facilitate data generation. (2) Instruction tuning: Fed the instruction fine-tuning dataset into a pre-trained LLM for fine-tuning, as illustrated in Figure 1; (3) Sampling: Synthetic tabular data is generated by sampling from the fine-tuned LLM, with the sampling process depicted in Figure 2. Below, we will provide a comprehensive description of the entire process, encompassing the construction of the instruction dataset, model fine-tuning, and the implementation of sampling."}, {"title": "Construct Instruction Dataset", "content": "Construct a fine-tuning dataset using kNN. Our approach leverages KNN to enable LLMs to generate synthetic data resembling limited real data. This is expected to use the in-context learning ability of LLM (few-shots) to mine information from the most relevant table samples.\nSpecifically, this process involves finding the k nearest neighbors for each training sample, creating a set of k + 1 data points. To improve the quality of the generated synthetic data, a filtering step is necessary. Specifically, for each set of k + 1 data, if more than half of the input data have labels that are different from that of the single corresponding data point, this k + 1 data is discarded. Ultimately, this filtering process yields n sets of k + 1 data. A constant value of k = 5 was used throughout our experimental setup.\nData format engineering. Since LLMs are designed as sequence-to-sequence models, feeding tabular data into an LLM requires converting the structured data into a textual format. A straightforward approach would be to directly input a programming language readable data structure, such as Pandas DataFrame Loader for Python, line-separated JSON-file format, HTML code reflecting tables, etc. [1] In our method, each table entry is converted into JSON dictionary format, preserving the original table structure and enabling the model to understand the semantics of each value.\nFor a table entry $s_i$ with feature names $f_1, f_2, ..., f_m$, where the value of its j-th feature is $v_{i,j}$, the JSON-formatted data $t_i$ corresponding to the table entry $s_i$ is defined as follows:\n$t_{i,j} = [f_j: v_{i,j}]$  $\\forall i \\in \\{1,...,n(k + 1)\\}, j \\in \\{1, ...,m\\}$,\n$t_i = \\{t_{i,1}, t_{i,2},..., t_{i,m}\\} \\forall i \\in \\{1,...,n(k + 1)\\}$.\nWe concatenate k JSON-formatted data entries sequentially, incorporating prompts to elucidate the fine-tuning task and contextualize the data. The label JSON-formatted data entry serves as the reference answer. In addition, when converting a tabular feature vector into a sequence using the text encoding scheme, we inadvertently introduce pseudo-positional information into the transformed tabular data sample. However, there is no inherent spatial ordering among features in tabular datasets [29]. To restore feature order independence, we randomly shuffle the order of features within each complete JSON-formatted data entry $t_i$ using a permutation. This operation results in a new sequence where the order of features is randomized, ensuring that the model learns to be invariant to feature order. Therefore, a template for this instruction fine-tuning dataset is shown as Figure 1 3."}, {"title": "Instruction Tuning", "content": "We then fine-tune the LLM for the synthetic data generation task using the instruction dataset we constructed. Unlike pretraining-based LLMs for this task, our aim is to prevent the LLM from memorizing the original tabular data in the dataset. After tokenizing our instruction dataset, the resulting token embeddings of one sample for the INPUT and OUTPUT are denoted as $emb(X) = (x_1,...,x_l)$ and $emb(Y) = (y_1,...,y_q)$, respectively. Here, l and q represent the lengths of the INPUT and OUTPUT, respectively. Therefore, the objective of our fine-tuning strategy is to maximize the probability of generating the correct output sequence given a prompt describing the task and k input real data points. This objective function is formulated as:\n$p(f_t) = p(emb(Y)|emb(X)) = p(y_1,..., y_q|x_1,...,x_l) = \\prod_{j=1}^{q} p(y_j|x_1,..., x_l, y_1, ..., y_{j-1})$\nThe LLM is trained by optimizing the parameters to maximize the probability $\\prod_{f_t \\in FT} P(f_t)$, which only compute the loss of OUTPUT and avoids learn the real data in the INPUT to protect privacy."}, {"title": "Sampling", "content": "We denote the fine-tuned LLM as the generator G. Each data point in the prompt dataset is fed into G, yielding the distribution of subsequent tokens conditioned on the known input sequence. To generate the next token with more diversity and protect privacy, we adopt a weighted sampling strategy incorporating a temperature coefficient T. We set the default temperature coefficient T to 0.7. After generation, we utilize pattern-matching algorithms, as described in [30], to reconvert the generated textual feature representations into a dataframe format, resulting in the final synthetic tabular dataset."}, {"title": "Synthetic Tabular Data Evaluation Framework", "content": "We introduce two new metrics to evaluate the quality and privacy of synthetic data for LLM-based synthesis methods: LLM Efficacy (LLE) and Data Leakage Test (DLT)."}, {"title": "LLE: LLM Efficacy", "content": "With the development of LLMs, we believe that evaluating the quality of synthetic data using weak classifiers is losing its practical value and credibility. More and more pepole are concerned with the performance of synthetic data as a training set for state-of-the-art methods [14]. Recent research exploring the application of LLMs to tabular data processing has yielded significant advancements, with potential to rival or even surpass state-of-the-art machine learning approaches [31]. Therefore, we propose using synthetic data to fine-tune a pretrained LLM and then evaluate the fine-tuned LLM on the real test set. We refer to this as LLM Efficacy (LLE). We choose LLaMA-2-7b-chat [32] as the base model to compute the LLE."}, {"title": "DLT: Data Leakage Test", "content": "The metrics Distance to Closest Record (DCR) [10] and SDMetrics [27] focus on measuring the \"distance\" between synthetic data and real data, without taking into account the extent to which the generator itself leaks data. Research indicates that LLMs are susceptible to data leakage issues to varying degrees [20]. Attacks on LLMs of synthetic data generator can potentially extract complete training data, leading to severe privacy breaches. To address this, we propose a new metric for quantifying privacy protection, named the Data Leakage Test (DLT), inspired by the work of Skywork [33]. This metric measures the extent to which a generator leaks real data, thereby reflecting the privacy level of the synthetic data. The DLT computes the perplexity of the generator on both synthetic and real data to determine its data generation tendencies.\nTo compute the DLT, firstly, we feed the training data into the generator to calculate the ppl(perplexity) for each sample, then average these scores to determine the ppl on the training data, referred to as <ppl-on-train>. Then, we feed synthetic data into the generator and obtain the ppl on synthetic data, referred to as <ppl-on-syn>. The DLT value is computed by subtracting <ppl-on-syn> from <ppl-on-train>. A larger DLT value indicates better privacy preservation of the original data by the generator, whereas a smaller value indicates weaker privacy preservation. The computation formula of DLT is as below, where the $P(x)$ denotes the probability of generating a sentence.\n$DLT = PPL(D_{test}) - PPL(D_{train})$\n$PPL(D_{split}) = \\frac{1}{\\vert D_{split} \\vert} \\sum_{x \\in D_{split}} P(x) = \\frac{1}{\\vert D_{split} \\vert} \\sum_{x \\in D_{split}} 2^{Cross-Entropy(x)}$"}, {"title": "Experiment", "content": "In this section, we select four real-world datasets to compare the performance of HARMONIC with various types of data synthesis methods. The comparison is conducted from two perspectives: the effectiveness of the synthesized data and its privacy."}, {"title": "Experimental Setup", "content": "Datasets. To evaluate the proposed method, we utilized four real-world datasets from various domains, namely GM (German [34]), AD (Adult Income [35]), DI (Diabetes)4, BU (Buddy)5, which are all open source datasets and don't contain any personal information such as names, phone numbers, addresses, or other sensitive data. These datasets differ in size, feature types, and the number of features, ranging from fewer than 1,000 to tens of thousands of samples. Some datasets include only numerical features, while others contain both numerical and categorical features. We divided each dataset into training, validation, and test sets in approximately a 7:1:2 ratio. All models were trained on the same training data samples.\nBaselines. There are numerous synthetic methods for generating tabular data. Based on the classification approach discussed previously, we selected the most representative methods as our baselines. SMOTE [23] is a simple interpolation method proposed for oversampling minority classes and can"}, {"title": "The Effectiveness of Synthetic Data", "content": "Our experimental results offer compelling evidence that the synthetic data generated by our method can effectively serve as a substitute for real data in downstream tasks. This finding aligns with the growing recognition that traditional Machine Learning Efficacy (MLE) metrics may not be well-suited for evaluating the effectiveness of synthetic data used with modern LLMs. Relying solely on MLE metrics can be misleading when evaluating LLMs, potentially leading to inaccurate conclusions."}, {"title": "The Privacy of Synthetic Data", "content": "The experimental results demonstrate that our method prioritizes privacy in the synthetic data generation. This is particularly beneficial in situations where disclosing real data is not feasible due to privacy concerns. In such scenarios, our synthetic data serves as a reliable and secure substitute for real data, allowing downstream tasks to proceed without compromising sensitive information.\nTable 2 presents three key privacy metric scores to quantify the effectiveness of our method. Analyzing the results in Table 2, it's evident that our method surpasses or comes in a close second for almost all datasets across all three metrics. This translates to demonstrably stronger privacy protection compared to existing methods."}, {"title": "Conclusion", "content": "In this paper, we introduce HARMONIC, a novel framework that leverages the power of LLMs for synthesizing tabular data and privacy concerns. HARMONIC enables LLMs to capture both the internal feature relationships within individual data points and the broader connections between samples by instruction fine-tuning. Recognizing the crucial importance of privacy, we have proposed DLT specifically for detecting data privacy in LLM synthesis. Extensive evaluations across four real-world datasets for classification tasks showcase HARMONIC's ability to achieve this crucial balance of effectiveness and privacy. HARMONIC demonstrably offers robust privacy protection while preserving the effectiveness of the synthetic data."}, {"title": "Ethics Statement", "content": "The dataset used in this study is based on open-source data and can be further modified. We thoroughly reviewed and verified the data to ensure it does not contain any personally identifiable information or offensive content. Additionally, we conducted manual audits to ensure there are no sensitive details. Therefore, we believe the dataset is secure and its use in the research is ethically sound and appropriate for the purposes of this study."}, {"title": "Filter operation", "content": "Experimental results demonstrate that the filtering step can enhance the quality of synthetic data. As shown in Table 7, the LLE values decrease without filtering, particularly for the German dataset. This is likely due to incorrect labels in the generated synthetic data. Additionally, privacy slightly diminishes without the filtering step, though the difference is minimal. These findings indicate that the filtering step is effective."}, {"title": "Random feature order permutation", "content": "Experiments indicate that permuting features can enhance the privacy of synthetic data. As shown in the last two columns of Table 8, there is a significant reduction in both the DCR and DLT values when features are not permuted. Concurrently, the generated numerical columns tend to produce repeated values, which may also contribute to the decrease in the LLE metric. Overall, these results underscore the necessity of shuffling features."}]}