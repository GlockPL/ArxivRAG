{"title": "All or None: Identifiable Linear Properties of Next-token Predictors in Language Modeling", "authors": ["Emanuele Marconato", "S\u00e9bastien Lachapelle", "Sebastian Weichwald", "Luigi Gresele"], "abstract": "We analyze identifiability as a possible explanation for the ubiquity of linear properties across language models, such as the vector difference between the representations of \"easy\u201d and \u201ceasiest\u201d being parallel to that between \u201clucky\" and \"luckiest\". For this, we ask whether finding a linear property in one model implies that any model that induces the same distribution has that property, too. To answer that, we first prove an identifiability result to characterize distribution- equivalent next-token predictors, lifting a diversity requirement of previous results. Second, based on a refinement of relational linearity [Paccanaro and Hinton, 2001; Hernandez et al., 2024], we show how many notions of linearity are amenable to our analysis. Finally, we show that under suitable conditions, these linear properties either hold in all or none distribution-equivalent next-token predictors.", "sections": [{"title": "Introduction", "content": "In natural language processing, it is well-established that linear relationships between high- dimensional, real-valued vector representations of textual inputs reflect semantic and syntactic patterns. This was motivated in seminal works [4, 5, 6, 7, 8] and extensively validated in word embedding models [9, 10, 11] as well as modern large language models trained for next-token prediction [2, 12, 13, 14, 15, 16, 17, 18, 19].\nThis ubiquity is puzzling, as different internal representations can produce identical next-token distributions, resulting in distribution-equivalent but internally distinct models. This raises a key question: Are the observed linear properties shared across all models with the same next-token distribution?\nOur main result is a mathematical proof that, under suitable conditions, certain linear properties hold for either all or none of the equivalent models generating a given next-token distribution. We demonstrate this through three main contributions.\nThe first main contribution (Section 3) is an identifiability result characterizing distribution- equivalent next-token predictors. Our result is a generalization of the main theorems by Roeder et al. [3] and Khemakhem et al. [20], relaxing the assumptions of diversity and equal representation dimen- sionality. This result is of independent interest for research on identifiable representation learning since our analysis is applicable to several discriminative models beyond next-token prediction [3]."}, {"title": "Preliminaries", "content": "Notation. Italic font letters denote scalars, e.g., a; bold font lower-case letters denote vectors and sequences, e.g., x; and bold font upper-case letters denote matrices, e.g., M. We use the short-hand [k] = {1,...,k}. Given a finite dictionary of tokens A, the space of all possible finite sequences (or sentences) is denoted by Seq(A). With x1:t, we denote the sub-sequence"}, {"title": "Identifiability of next-token predictors", "content": "We introduce a novel identifiability analysis for the model in (1). In general, a statistical model $p_\\theta (x)$ parameterized by $\\theta$ is said to be identifiable up to an equivalence relation ~ over parameters if $p_\\theta = p_{\\theta'} \\Rightarrow \\theta \\sim \\theta'$. In other words, if two parameters entail the same distribution, then they must be equivalent. The precise notion of equivalence depends on the problem setting. Although it is less commonly discussed, this implication can often be shown to hold also in the other direction so that ~ is effectively a characterization of distribution-equivalent models, i.e., $p_\\theta = p_{\\theta'} \\Leftrightarrow \\theta \\sim \\theta'$. In this section, we define an equivalence relation over tuples (f, g) \u2208 \u0398 that characterizes models that entail the same next-token prediction distribution. In other words, we want to define an equivalence relation ~ over \u0398 such that $p_{f,g} = p_{\\tilde{f},\\tilde{g}} \\Leftrightarrow (f, g) \\sim (\\tilde{f}, \\tilde{g})$; we then say (f, g), (\\tilde{f}, \\tilde{g}) are ~-equivalent.\nOur characterization applies to pairs of models having different dimensionalities, i.e. d \u2260 d, as opposed to previous works [3, 20, 24, 25]."}, {"title": "Effective complexity of the model", "content": "We generalize previous results in a setting where the diversity condition may not hold. Starting from the conditional distribution captured by the model (f, g), we have that for every yo \u2208 A,\n$P_{f,g}(y | x) \\propto exp(f(x)^T g(y))$\n$\\propto exp(f(x)^T g(y)) exp(-f(x)^T g(y_0))$\n$= exp(f(x)^T g_0(y))$,\nfeaturing that the conditional distribution $p_{f,g}(y | x)$ is fully determined by the dot product $f(x)^T g_0(y)$. Denote by $P_F$ and $P_G$ the orthogonal projectors onto $F := SIm(f)$ and $G := SIm(g_0)$, respectively. Since both $f(x) = P_Ff(x)$ and $g_0(y) = P_Gg_0(y)$, the dot product between the two can be evaluated as:\n$f(x)^T g_0(y) = (P_Ff(x))^T P_Gg_0(y)$\n$= f(x)^T P_F P_G g_0(y)$"}, {"title": "Extended linear equivalence relation", "content": "Based on the effective complexity\u2014which may be lower than the representation dimensionality\u2014we introduce a weaker equivalence relation between models (f,g) and (f, g). Consider the spaces\n$F := SIm(f)$ and $G := SIm(g_0)$, and define $M := Im(P_FP_G)$ and $N := ker(P_FP_G)^+$.\nTwo models (f,g) and (f,g) are extended-linearly equivalent, if both (1) dim(M) = dim(M) and (2) there exist two full-rank matrices $M, N \\in R^{d \\times d}$ defining, respectively, invertible transformations between M and M, and between N and \u00d1, such that $MTN = P_MP_\\tilde{N}$ and\n$P_Mf(x) = M P_\\tilde{M} f(x)$\n$P_Ng_0(y) = N P_\\tilde{N} \\tilde{g}_0(y)$,\nfor all y \u2208 A, x \u2208 Seq(A). We denote this relation by $(f, g) \\sim_{EL} (\\tilde{f}, \\tilde{g})$.\nThe above equivalence relation generalizes the linear equivalence already known in the literature [3, 20] to that of two models which can be related to each other on subspaces of dimension dim(M) \u2264 min{d, d}. It shows that, after projecting the representations to suitable equal-dimensional subspaces, namely M, N, M, and \u00d1, we can find an invertible linear transformation relating them. Here, the dimension of M and M are equal, requiring that two equivalent models share the same effective complexity. Furthermore, the condition between M and N preserves the dot-product:"}, {"title": "Identifiability of next-token predictors", "content": "We can relate the representations of two models based on this equivalence relation when they express the same conditional distribution. The following theorem offers a characterization of models attaining the same conditional probability distribution:\nTheorem 5. For all (f, g), (f, \u011d) \u2208 \u04e8, which may have different representation dimensions d and d, we have\n$P_{f,g} = P_{\\tilde{f},\\tilde{g}} \\Leftrightarrow (f,g) \\sim_{EL} (\\tilde{f}, \\tilde{g})$.\nWith Theorem 5, we characterize the space of distributionally-equivalent next-token predictors. Models (f, g) in the equivalence relation ~$_{EL}$ are associated to a single conditional probability distribution $p_{f,g}$. This is a one-to-one correspondence between the set of conditional probability distributions expressed by (1) and the set of equivalence classes of ~$_{EL}$ (cf. Figure 1).\nInterestingly, this characterization highlights the fact that our notion of effective complexity, which we defined for models (f, g), is a well-defined complexity measure for distributions $p_{f,g}$ in the sense that it does not depend on the specific choice of parameterization. Indeed, the result implies that\n$P_{f,g} = P_{\\tilde{f},\\tilde{g}} \\Leftrightarrow dim(M) = dim(\\tilde{M})$.\nFurthermore, We can show that the previous theorem reduces to linear identifiability when both the diversity condition and d = d hold:\nCorollary 6 (Adapted from Roeder et al. [3]). For all (f, g), (f,g) \u2208 \u04e8\u0105 such that (f, g) satisfies the diversity condition (Definition 1), we have\n$P_{f,g} = P_{\\tilde{f},\\tilde{g}} \\Leftrightarrow (f, g) \\sim_{L} (\\tilde{f},\\tilde{g})$,\nwhere, by definition, $(f, g) \\sim_{L} (\\tilde{f}, \\tilde{g})$ if and only if there exists an invertible matrix $M \\in R^{d \\times d}$ such that for all y \u2208 A, x \u2208 Seq(A) we have\n$\\tilde{f}(x) = M f(x)$ and $\\tilde{g}_0(y) = M^{-T} g_0(y)$ .\nImplications for trained models. Now assume that (f,g) \u2208 \u0398\u0256 and (f, g) \u2208 \u0398\u300f are both maximizers of (3). If both models have enough capacity to represent the ground-truth data distribution PD, then they necessarily represent the same distribution, i.e. Pf,g = PD = P\u0159,\u011f\u00b7 By Theorem 5, we can thus conclude that $(f, g) \\sim_{EL} (\\tilde{f},\\tilde{g})$. Assuming these assumptions hold in practice, this would imply that all models trained with sufficient capacity on a given data distribution PD will be ~$_{EL}$-equivalent. This analysis relies crucially on the assumption that has enough capacity to represent PD. In practice, this might not hold for at least two reasons. First, we typically train with a fixed representation dimension d which limits the expressivity of the model. Moreover, despite the universal approximation guarantee, there might not even exist a sufficiently large d such that the model can express pd exactly. Secondly, all distributions that can be represented by put nonzero probability mass on all text sequences (because of the exp), whereas one can argue that the ground-truth distribution of text PD gives zero probability to many sequences."}, {"title": "Linear properties", "content": "We will now focus on linear properties of language models. These describe how a given model (f, g) represents different inputs\u2014similar to our opening example, illustrating a geometric relationship (parallelism) among the vector differences between the embeddings of two different inputs (\u201clucky\u201d and \"luckiest\") and that between two further inputs (\"easy\u201d and \u201ceasiest\u201d). These linear properties are not to be confused with the linear equivalence class ~\u2081 mentioned in Corollary 6, which instead describes how different models represent the same data distribution. In Section 5, we will combine the linear properties defined here with our equivalence class of next-token predictors, described in Section 3, to study what properties are shared by all models within the same equivalence class."}, {"title": "Relational linear property", "content": "We describe the linear structure of representations solely relationally, that is, in terms of context- query-reply sequences s ^ q ^ y, similar to Paccanaro and Hinton [1]. Relatedly, Hernandez et al. [2] provided empirical evidence for relational linearity between hidden transformer layers.\nOur analysis focuses on embeddings f(s) \u2208 SIm(f) and subspaces \u0393\u2286 SIm(go), allowing us to define relational linear properties solely in terms of the quantities described in our identifiability result; this enables our analysis to be agnostic to assumptions on the data generating process underlying natural language and, e.g., to not require positing nor referring to unobserved variables.\nFor a model (f, g) \u2208 \u0398, let \u0393 \u2286 SIm(go) be a subspace. We say that (f, g) linearly represents the query q \u2208 Seq(A) on \u0393, if, there exist a matrix $A_q \\in R^{d \\times d}$ and a vector $a_q \\in R^d$ such that, for all s \u2208 Seq(A),\n$P_{\\Gamma}f(s^\\frown q) = P_{\\Gamma} (A_qf(s) + a_q)$.\nWhen this holds, we indicate with $\u0393_q := Im(APr)$."}, {"title": "Connection to other linear properties", "content": "Here, we show how to specialize the notion of relational linearity to capture three linear properties that have been empirically observed. We follow the taxonomy by Park et al. [23]. All proofs are reported in Appendix C."}, {"title": "Linear subspaces (LS)", "content": "There are recent empirical findings of differences between token unembeddings to be parallel, such as g(\"easy\") - g(\"easiest\") being parallel to g(\u201clucky\u201d) \u2013 g(\u201cluckiest\u201d), akin to observations in word2vec [23, 27]. Central to our discussion is also the notion of parallelism in a subspace \u0393 \u2286 Rd:\nWe say that two vectors \u03b3, \u03b3' \u2208 Rd are parallel in \u0393 if there exists \u03b2\u2260 0 such that $P_{\\Gamma} \\gamma = \\beta \\cdot P_{\\Gamma} \\gamma'$.\nWe show next that parallel vectors induce similar log ratios of conditional probabilities, as noted in [23, 28]:\nLemma 9. Take a model (f, g) \u2208 \u0398. For yo, Y1, Y2, Y3 \u2208 A, the difference vectors g(y1) \u2013 g(yo) and g(y3) - g(y2) are parallel in N if and only if there exists \u1e9e \u2260 0, s.t. \u2200s \u2208 Seq(A) it holds that\n$\\log \\frac{P_{f,g}(y_0 | s)}{P_{f,g}(y_1 | s)} = \\beta \\cdot \\log \\frac{P_{f,g} (y_2 | s)}{P_{f,g}(y_3 | s)}$"}, {"title": "Linear probing (LP)", "content": "There is empirical evidence for sentence embeddings being linearly separable into embeddings of text of different languages [23, 29]. Such a structure also enables what is called linear probing [30, 31] (see below). We define linear probing as relational property:\nWe say that a model (f, g) \u2208 \u04e8 can be linearly probed for a query q \u2208 Seq(A) and a collection Yp \u2286 A of l elements if there exist W \u2208 Rexd and b \u2208 Re, such that for all s \u2208 Seq(A) and \u2200i \u2208 [l] it holds that\n$\\text{softmax}(Wf(s) + b)_i = P_{f,g}(y_i | s^\\frown q; Y_p)$,\nwhere p(y | \u00b7 ; Yp) = p(y |\u00b7)/(\u03a3y'\u2208yp P(y' |\u00b7)) denotes the conditionals restricted to Yp.\nTo illustrate why this is termed linear probing, suppose a model given the query q =\u201cIs the text written in English?\u201d discriminates input sequences s \u2208 Seq(A) between positive yo =\u201cyes\u201d and negative examples y\u2081 =\u201cno\u201d, that is it assigns high probability mass to either pf,g(yo | s^q) or to Pf,g(y1 | s^q). Then, these conditional distributions can be evaluated directly from f(s) via a linear probe."}, {"title": "Linear Steering", "content": "Similar to LP, in Appendix C.1 we discuss a relational counterpart to linear properties discussed by Hernandez et al. [2], Park et al. [23]."}, {"title": "Linear properties shared by all distribution-equivalent models", "content": "Based on Theorem 5, we analyze which linear properties are shared across models expressing the same conditional distribution. To this end, pick a model (f, g) that linearly represents q on \u0393 (Definition 7), and also consider the space $\u0393_q := Im(A_PP_\u0393)$. We show that under an additional condition on I and Iq, two models that are ~$_{EL}$-equivalent share the same linear properties (all proofs are in Appendix D):\nFor two models (f, g), (f, g) \u2208 \u04e8, such that $(f, g) \\sim_{EL} (\\tilde{f},\\tilde{g})$, it holds: if f linearly represents q on \u0393 \u2286 N, and moreover, \u0393q \u2286 M, then f linearly represents q on \u0128 \u2286 \u00d1N, where \u0490 = Im(N+Pr) and N is the matrix relating go and go by the equivalence relation in Definition 3.\nThis shows how the relational linearity (FLR), combined with the condition that \u0393\u2286 N and Iq \u2286 M is a property of all or none next-token predictors modeling the same conditional distribution. As a consequence, the same holds for LS (by Proposition 11) and LP (by Proposition 13). Intuitively, the extra condition underlies that relational linearity of (f, g) is displayed by the components of f that contribute to the dot product with go. A ~$_{EL}$-equivalent model (f, g) would linearly transform these components, thus preserving relational linearity. Vice versa, since all components of f outside M can be arbitrarily distorted, any property of (f, g) that depends on those components may not hold for (f, g). The extra condition precisely avoids that. Notice that the special case where the diversity condition (Definition 1) holds implies a similar conclusion because the condition that F C N and \u0393qC M is then always satisfied (as M = N = Rd).\nIn contrast, parallel vectors may not be preserved: Two parallel vectors in one model (f, g) may not be parallel in another model (f, g) with the same conditional distribution. They remain parallel only within the subspaces N and N, respectively:\nFor two models (f, g), (f, g) \u2208 \u04e8, such that $(f, g) \\sim_{EL} (\\tilde{f},\\tilde{g})$, the vectors \u03b3,\u03b3' \u0395 SIm(go) are parallel within N if and only if the corresponding vectors \u1ef9, 7' \u2208 SIm(g0) are parallel in N."}, {"title": "Discussion", "content": "gives an example of a property that all distribution-equivalent next-token predictors, as characterized by our identifiability result (Theorem 5), must share. For the widely observed linear properties of language models, one may then ask whether they are indeed examples of shared properties akin to the one in Proposition 14. Tautologically, claims about the ubiquity of linear properties cannot solely be based on observations of linearity in individual model instances. One might therefore expect that only those properties shared across all equivalent models should be ubiquitously observable. In the following, we critically examine this hypothesis in light of empirical evidence.\nIf I ZN, then relational linearity (Definition 7) would be trivially satisfied for (f, g) and, in turn, also for (f, g), because y \u2208 F would give y\u00b9 f(x) = 0, and so Prf(x) = 0.\nAn analogy could be made with the principle of covariance in physics [32, 33], which asserts that physical laws should be expressible as coordinate-independent and reference-frame-independent geometric relationships between objects that represent physical entities [34]. Recently, Villar et al. [35] suggested that this principle could inspire future developments in machine learning."}, {"title": "Related work and future directions", "content": "Linear properties of next-token predictors have attracted widespread attention, also beyond language modeling [36, 37, 38]. More complex, non-linear properties have also been observed, such as circular token representations [39]. Formalizing these properties and investigating whether all distribution-equivalent next-token predictors share them, in the sense we studied for linear properties, is an interesting open venue.\nTheoretical studies on linear properties. Park et al. [23] introduce binary latent concepts to describe several linear properties (though not relational linearity) in a unified framework. This was also applied to study categorical and hierarchical concepts [40]. Jiang et al. [28] explain linear properties of language models based on assumptions on the data-generating process and latent variables underlying natural text. This allows them to reason about the origins of linearity; in this work, we instead focus on the ubiquity of linearity in the models, taking an agnostic stance on latent concept variables. An exciting direction for future work is to prove, within our framework, why and how linear properties emerge, if they do at all.\nIdentifiability of representations is a central theme in generative modeling, [41, 42], particularly in non-linear ICA, e.g., [43, 44, 45, 46, 47]; and in causal representation learning, e.g., [48, 49, 50, 51, 52, 53, 54]. Reizinger et al. [55] discuss the role identifiability may play in explaining several properties of large language models [56]. Our work highlights the role identifiability plays in explaining the ubiquity of linear properties."}, {"title": "Functional Form of Decoders-only Transformers", "content": "Decoders-only transformer models can be reduced to the form we use in the main text, as already shown in a derivation by Roeder et al. [3]. We consider autoregressive, GPT-like models [57, 58], focusing on the GPT-J model [59].\nWe denote with h(x; 0) the representation given by the a transformer model h with trainable parame- ters \u03b8\u2208 R\u00ba for the architecture. We consider the transformer to represent sentences of lenght up to C, and by convention we pick the last C tokens if the sentence has length t(x) > C. Denote with T := max(t(x) \u2013 C, 1) it holds that:\n$h(x; 0) = h(x_{t(x)-\\tau:t(x)}; 0) \\in R^{d \\times \\tau}$.\nWe focus on the representation of the last token of sentence, which is used to perform next-token prediction, and denote it with\n$h(x;0)-1 \\in R^d$.\nWhen predicting the next token among K := |A| possible options, a common approach is to use a layer (or head) with weights WD \u2208 RK\u00d7d and a bias b \u2208 RK. The representation of gp is determined by the parameters 4 = (WD, b), which are used to compute the logits as follows:\n$logits(x) := W_ph(x; 0)_{-1} + b$.\nBy extending the representation of h\u22121 to fe(x) := (1, h(x; 0) 1\u2081), we can incorporate the bias by adding one column to WD, obtaining:\n$\\text{logits}(x) = W_Df_e(x), \\text{ where } W_D = (b, W_D)^T$.\nTo predict the probability of the next token y it is then sufficient to consider\n$\\log P_{f_\\theta,g_\\phi} (y | x) = \\text{logits}(x)_y \u2013 \\log \\sum_{y\u2019}e^{\\text{logits}(x)_{y\u2019}} $.\nTransforming the token y \u2208 A to its one-hot representation, y \u2208 {0,1}K, we can write\n$\\tilde{g}(y) = W_D^T y,$\nthereby leading to the expression:\n$\\log P_{f_\\theta,g_\\phi} (y | x) = \\tilde{g}(y)^T f_e(x) \u2013 \\log \\sum_{y\u2019 \\in A} \\tilde{g}(y)^T f_e(x),$\nwhere we used:\n$f_e(x) = \\begin{bmatrix}\n1 \\\\\nh(x_{t(x)-\\tau:t(x)}; \\theta)_{-1}\n\\end{bmatrix}$ and $\\tilde{g}(y) := W_D^T y$.\nThis explicit form of the embedding and unembedding respectively and consistent with (1), as previously detailed by Roeder et al. [3]."}, {"title": "Proofs of Section 3", "content": ""}, {"title": "Reminder of useful properties of pseudo-inverses", "content": "We will often make use of the pseudo-inverse A+ of a matrix A [60, page 221]. We denote with T|ker(T)+ the restriction of T to its orthogonal complement of the kernel [60].\nLet T \u2208 Rm\u00d7n be a matrix. The pseudo-inverse T+ \u2208 Rn\u00d7m of T is defined as the linear map:\n$T^+w := (T |_{\\text{ker}(T)^+} )^{-1}P_{\\text{Im}(T)} W$"}, {"title": "Proof of Lemma 2", "content": "We provide here a longer version of the Lemma capturing different properties between the projectors.\nLet (f,g) \u2208 \u0398, and take F := SIm(f) and G := SIm(go). For the orthogonal projectors PF and Pg and the orthogonal projectors PM and PN projecting on the spaces:\n$M = \\text{Im}(P_FP_G), N = \\text{ker}(P_FP_G)^+$"}, {"title": "Extended linear equivalence", "content": "We show that the relation defined in Definition 3 is an equivalence relation.\nTwo models (f,g) and (f,g) are extended-linearly equivalent, if both (1) dim(M) = dim(M) and (2) there exist two full-rank matrices $M, N \\in R^{d \\times d}$ defining, respectively, invertible transformations between M and M, and between N and \u00d1, such that $MTN = P_MP_\\tilde{N}$ and\n$P_Mf(x) = M P_\\tilde{M} f(x)$\n$P_Ng_0(y) = N P_\\tilde{N} \\tilde{g}_0(y)$,\nfor all y \u2208 A, x \u2208 Seq(A). We denote this relation by $(f, g) \\sim_{EL} (\\tilde{f}, \\tilde{g})$.\nTo prove ~$_{EL}$ is an equivalence relation we have to show its reflexivity, symmetry, and transitivity."}, {"title": "Proof of Proposition 4", "content": "Proposition 4. If (f, g) ~$_{EL}$ (f,g), then\n$f(x)P_MP_Ng_0(y) = f(x)P_\\tilde{M}P_\\tilde{N} \\tilde{g}_0 (y)$ ."}, {"title": "Proof of Theorem 5", "content": "We begin with the following lemma, which will be used in the proof of Theorem 5.\nLet F be a subspace of Rd and M \u2286 F a subspace of F. Consider D elements vi \u2208 Rd, such that the matrix\n$F := (v_1, \u2026, v_D)$"}, {"title": "Additional Results and Proofs of Section 4", "content": ""}, {"title": "Relational Linear Steering Property", "content": "We here want to discuss an additional linear property besides those presented in Section 4, termed linear steering property. This behavior is also referred to as the linear intervening property by Park et al. [23].\nIt has been empirically observed that there exist steering vectors that influence next-token predictions [2, 23, 61, 62], in the following sense: If v encode the average difference between English to Italian embeddings, adding v to f(s) for the sentence s =\u201cThe king sits on the\u201d would change the most-likely next token prediction y =\u201cthrone\u201d to \u0177 =\u201ctrono\", and similarly this applies for other sentences, affecting the most-likely next-token prediction to move from the English token to the Italian counterpart.\nWe define this property as follows:\nWe say that a model (f, g) \u2208 possess linear relational steering for qo and the set of {q1,\u2026\u2026\u2026, qm }, for m \u2265 1 queries q; \u2260 qo, if (1) it linearly represents qo in To and all q; on Fj, and (2) there exists a vector v \u2208 Rd such that:\n$P_{\\Gamma_0} A_qv\u2260 0, P_{\\Gamma_i}A_{q_i}v = 0, \u2200j\u2208 [m]$\""}, {"title": "Proof of Lemma 9", "content": "Lemma 9. Take a model (f, g) \u2208 \u0398. For yo, Y1, Y2, Y3 \u2208 A, the difference vectors g(y1) \u2013 g(yo) and g(y3) - g(y2) are parallel in N if and only if there exists \u1e9e \u2260 0, s.t. \u2200s \u2208 Seq(A) it holds that\n$\\log \\frac{P_{f,g}(y_0 | s)}{P_{f,g}(y_1 | s)} = \\beta \\cdot \\log \\frac{P_{f,g} (y_2 | s)}{P_{f,g}(y_3 | s)}$"}, {"title": "Proof of Proposition 11", "content": "Proposition 11 (\u0393LR \u21d2 LS). Suppose that a model (f,g) \u2208 \u0398 (1) linearly represents q on FC SIm(go), and also (2) \u0393q \u2286 SIm(go), then the model (f, g) linearly represents \u0393q relative to q (Definition 10).\nWe start from the relational linearity as per Definition 7 for q on \u0393\u2282 Rd:\n$P_{\\Gamma}f(s^\\frown q) = P_{\\Gamma}A_qf(s) + P_{\\Gamma}a_q$,"}, {"title": "Proof of Proposition 13", "content": "Proposition 13 (\u0393LR \u21d2 LP). If a model (f, g) \u2208 \u0398 (1) linearly represents q on \u0393, and (2) g(yi) - g(yj) \u2208 F for all yi \u2208 Yp, then the model can be linear probed (Definition 12) for q and Yp, with parameters given by W\nand bi := $(a_q)^Tg(y_i)$.\nUnder the assumption (2), take a pivot yj \u2208 Yp, then for all remaining yi \u2208 Vp denote with gj(yi) := g(yi) - g(yj) \u2208 \u0393. Taking the log-ratios between the conditional probabilities\n$P_{f,g}(y_i | s^\\frown q; Y_p)$ , and $P_{f,g}(y_j | s^\\frown q; V_p)$,\nfor conditional probabilities restricted to Yp, as in Definition 12, we obtain:\n$\\log \\frac{P_{f,g}(y_i | s^\\frown q; Y_p)}{P_{f,g}(y_j | s^\\frown q; Y_P)} = \\log \\frac{\\text{exp} (g(y_i)^T f(s^\\frown q))}{\\text{exp} (g(y_j)^T f(s^\\frown q))}$"}, {"title": "Proof of Section 5", "content": ""}, {"title": "Proof of Proposition 14", "content": "Proposition 14. For two models (f, g), (f, g) \u2208 \u04e8, such that $(f, g) \\sim_{EL} (\\tilde{f},\\tilde{g})$, it holds: if f linearly represents q on \u0393 \u2208 N, and moreover, \u0393q \u2286 M, then f linearly represents q on \u0128 \u2286 \u00d1, where \u0490 = Im(N+Pr) and N is the matrix relating go and go by the equivalence relation in Definition 3.\nProof Sketch. The proof is divided in two steps:\nWe first prove the implication that (f, g) linearly represents q on a subset\u0490 \u2286 Rd;\nThen we show that I \u2286 N and that Iq := Im(\u00c3 Pr) \u2286 \u00d1."}, {"title": "Context-query-reply sentences: Corner cases", "content": ""}, {"title": "Paraphrases", "content": "We consider a sentence q2 to be the paraphrase of q\u2081 when q2 repeats what was written in q1 using different words (for this definition, we only slightly adapted the one from the Cambridge Dictionary). To provide an example, let q\u2081 = \u201cIs the text written in English?", "Was the previous text written in English or not?\u201d. These two equivalent formulations of the same question can nonetheless be treated differently by a next-token predictor": "for example, given a string s, it can be that f (s ^ q\u2081) \u2260 f(s) q\u2082).\nHere, we analyze how paraphrastic aspects of textual data can be described with relational context- query-reply (s) q ^ y) strings for a model (f, g) \u2208 \u0398. We start by providing a tentative definition of of praphrasatic sentences in terms of their entailed conditional log-probabilities for different pairs of next-tokens.\nWe say that q2 \u2208 Seq(A) on V2 \u2286 A is a paraphrase of q\u2081 \u2208 Seq(A) on Y\u2081 A for the model (f, g) if there exists \u1e9e \u2260 0 such that, for all yo, Y1 \u2208 Y\u2081 \u2286 A, there exists Yo, Y1 \u2208 V2 A, for which it holds:\n$\\log \\frac{P_{f,g}(y_0 | s^\\frown q_1)}{P_{f,g}(y_1|s^\\frown q_1)} = \\beta\\cdot \\log \\frac{P_{f,g}(\\widehat{y}_0 | s^\\frown q_2)}{P_{f,g}(\\widehat{y}_1|s^\\frown q_2)}$\nFor example, consider the strings q1 = \u201cIs the text written in English?", "yes\" and y\u2081 = \u201cno\u201d, i.e., y0, Y1 \u2208 \u04231; and a second string q2 =\u201cReply with only A or B. Was the text written in (A) English or (B) not ?": "with expected replies \u0135o"}]}