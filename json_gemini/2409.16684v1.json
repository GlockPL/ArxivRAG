{"title": "Erase then Rectify: A Training-Free Parameter Editing Approach for Cost-Effective Graph Unlearning", "authors": ["Zhe-Rui Yang", "Jindong Han", "Chang-Dong Wang", "Hao Liu"], "abstract": "Graph unlearning, which aims to eliminate the influence of specific nodes, edges, or attributes from a trained Graph Neural Network (GNN), is essential in applications where privacy, bias, or data obsolescence is a concern. However, existing graph unlearning techniques often necessitate additional training on the remaining data, leading to significant computational costs, particularly with large-scale graphs. To address these challenges, we propose a two-stage training-free approach, Erase then Rectify (ETR), designed for efficient and scalable graph unlearning while preserving the model utility. Specifically, we first build a theoretical foundation showing that masking parameters critical for unlearned samples enables effective unlearning. Building on this insight, the Erase stage strategically edits model parameters to eliminate the impact of unlearned samples and their propagated influence on intercorrelated nodes. To further ensure the GNN's utility, the Rectify stage devises a gradient approximation method to estimate the model's gradient on the remaining dataset, which is then used to enhance model performance. Overall, ETR achieves graph unlearning without additional training or full training data access, significantly reducing computational overhead and preserving data privacy. Extensive experiments on seven public datasets demonstrate the consistent superiority of ETR in model utility, unlearning efficiency, and unlearning effectiveness, establishing it as a promising solution for real-world graph unlearning challenges.", "sections": [{"title": "Introduction", "content": "Machine unlearning has garnered considerable attention in recent years due to its ability to remove the influence of specific subsets of data from a well-trained machine learning model (Nguyen et al. 2022). This process is particularly important for forgetting sensitive, mislabeled, or obsoleted information. Typically, the subset of data to be unlearned is much smaller than the entire training dataset. As a result, one primary goal of machine unlearning is to efficiently eliminate the impact of these unlearned samples while preserving the model's predictive power, thereby avoiding the costly process of retraining the model from scratch on the remaining data (Xu et al. 2024).\nIn the graph domain, there is also a strong demand to forget specific information. For example, users in a social network may request the removal of their personal data. In particular, Graph Neural Networks (GNNs) has become a common routine for processing and analyzing graph-structured data, leveraging message propagation and neighborhood aggregation mechanisms (Zhou et al. 2020). However, the interconnected nature of graphs determines that unlearned samples can significantly impact their neighbors through message propagation, making conventional machine unlearning methods unapplicable (Cheng et al. 2023). Consequently, graph unlearning has emerged as a specialized machine unlearning task with the goal of removing unlearned samples and mitigating their influence on other intercorrelated nodes (Said et al. 2023).\nRecently, several approaches have been proposed to address the challenges of graph unlearning. For instance, GIF (Wu et al. 2023a) and CGU (Chien, Pan, and Milenkovic 2023) directly approximate the parameter changes induced by data removal and update the affected parameters. Such methods primarily focus on forgetting unlearned samples while overlooking the predictive capability on remaining data, which can significantly compromise model utility (Li et al. 2024). To resolve this problem, some recent studies (Li et al. 2024; Wang, Huai, and Wang 2023) have simultaneously considered both predictive and unlearning objectives when an unlearning request is received. However, they typically necessitate additional training on the remaining data, which leads to significant computational overhead, particularly with large graphs, even if only a small number of unlearned samples are involved. The substantial computational resources required constrain the efficiency and scalability of these methods, thereby limiting their practicality in real-world applications.\nIn this work, we focus on developing an efficient and scalable graph unlearning method that preserves the utility of GNNs. However, achieving this goal is non-trivial. First, the interconnected nature of graph data means that unlearned samples can significantly affect their neighbors through message propagation, making it challenging to efficiently remove both the unlearned samples and their influence on other nodes. Second, the remaining dataset after unlearning is typically much larger than the unlearned subset, which can lead to substantial computational overhead when accessing the remaining data. Balancing the need to maintain model utility with the demand for low computational overhead presents another significant challenge.\nTo tackle the above challenges, we propose Erase then Rectify (ETR), a training-free, two-stage approach for cost-effective graph unlearning. Specifically, we first establish a theoretical foundation demonstrating that masking parameters critical to unlearned samples enables effective graph unlearning. Building on this theory, in the Erase stage, we propose a neighborhood-aware parameter editing strategy to effectively eliminate the impact of unlearned samples and their cascading effects on the entire graph, while minimizing the impact on model utility. In the Rectify stage, we introduce a subgraph-based gradient approximation method to efficiently estimate the gradient of the unlearned model on the remaining data, which is then used to further enhance the model performance. Notably, ETR achieves graph unlearning without requiring explicit model training or access to the entire training dataset, which not only avoids substantial computational overhead but also ensures data privacy and security. Overall, the main contributions are as follows:\n\u2022 We theoretically prove that masking parameters crucial for unlearned samples enable effective graph unlearning.\n\u2022 We propose a training-free neighborhood-aware parameter editing method for graph unlearning that effectively forgets unlearned samples and their influence on inter-correlated samples.\n\u2022 We propose a gradient approximation method to enhance GNN performance on the remaining graph without requiring access to the entire training dataset, thereby ensuring efficiency and scalability on large-scale graphs.\n\u2022 Extensive experiments demonstrate the model utility, unlearning efficiency, and unlearning efficacy of ETR. Notably, ETR achieves an average of 4583.9x less time and 4.2x less memory usage than retraining from scratch."}, {"title": "Related work", "content": "Graph Unlearning Graph unlearning methods can be categorized into exact and approximate approaches, aiming to obtain an unlearned model that is exactly or approximately equivalent to retraining from scratch (Said et al. 2023). Current efforts primarily focus on approximate graph unlearning. For example, GraphEraser (Chen et al. 2022) and GUIDE (Wang, Huai, and Wang 2023) follow the SISA (Bourtoule et al. 2021) paradigm, proposing graph partitioning algorithms to divide the training set into multiple shards, with a separate model trained for each shard. Besides, some approaches (Wu et al. 2023a,b; Chen et al. 2023; Chien, Pan, and Milenkovic 2023) leverage influence functions to approximate the impact of unlearning requests on model parameters. GNNDelete (Cheng et al. 2023) freezes model parameters while training additional parameters to achieve graph unlearning, and MEGU (Li et al. 2024) simultaneously trains the model's prediction and unlearning objectives. Despite the effectiveness, these methods still face limitations when scaling to large graphs.\nTraining-Free Machine Unlearning Several training-free methods have been proposed for efficient machine unlearning. For example, Fisher Forgetting (Golatkar, Achille, and Soatto 2020a) and NTK (Golatkar, Achille, and Soatto 2020b) are weight scrubbing methods that add noise to parameters informative for unlearned samples. However, Fisher Forgetting is computationally expensive and sacrifices the model's predictive performance (Tarun et al. 2023), while NTK relies on additional models to achieve unlearning. The most relevant work to ours is SSD (Foster, Schoepf, and Brintrup 2024), which achieves unlearning by dampening parameters crucial for the unlearned dataset but not for the remaining dataset. Unlike SSD, we account for the impact of unlearned samples on other samples through message propagation. Additionally, we propose adaptively selecting hyperparameters, enhancing the method's versatility across different datasets. Furthermore, we introduce the Rectify strategy to improve the model performance on the remaining dataset."}, {"title": "Preliminaries", "content": "Notations and Background\nIn this paper, we employ $\\mathcal{G} = (\\mathcal{V},\\mathcal{E},X)$ to denote a graph comprising $|\\mathcal{V}|$ nodes and $|\\mathcal{E}|$ edges. Each node $v_i \\in \\mathcal{V}$ has a $d$-dimensional feature vector $x_i \\in X$. A major category of GNNs is message-passing neural networks (MPNNs) (Gilmer et al. 2017), including models such as GCN (Kipf and Welling 2017) and GAT (Velickovic et al. 2018). MPNNs follow the \"propagate-transform\" paradigm: in each layer of the network, they propagate and aggregate features from neighboring nodes, and then transform these aggregated features to update each node's representation (Gilmer et al. 2017). Following previous works (Chen et al. 2022; Said et al. 2023), we focus on the task of node classification in this study. We denote the training dataset as $\\mathcal{D}$, the unlearned dataset as $\\mathcal{D}_f$, the remaining dataset as $\\mathcal{D}_r$ (i.e., $\\mathcal{D} \\backslash \\mathcal{D}_f$), and the $k$-hop neighborhood of $\\mathcal{D}_f$ as $\\mathcal{D}_k$.\nFisher Information Matrix (FIM)\nThe FIM utilizes the second-order derivative of the loss function to quantify the sensitivity of each parameter, thereby providing a measure of its importance with respect to the input samples (Guo et al. 2020). Specifically, for a distribution $p(y|x, w)$, the FIM and its first-order derivative property (Kay 1993) are given as follows:\n$F_{\\mathcal{D}} = E_{x,y} [-\\nabla_w^2 \\log p(y|x, w)]$\n$F_{\\mathcal{D}} = E_{x,y} [\\nabla_w \\log p(y|x, w) \\nabla_w \\log p(y|x, w)^T]$\nNotably, obtaining the FIM is computationally expensive. A common approach is to use its diagonal $\\text{diag}(F)$ (Kirkpatrick et al. 2017), which can be computed efficiently using the first-order derivative. The $i$-th element of the diagonal of the FIM calculated over the dataset $\\mathcal{D}$ is denoted as $F_{\\mathcal{D},ii}$, representing the importance of the $i$-th parameter with respect to the dataset $\\mathcal{D}$.\nProblem Statement\nGiven a graph $\\mathcal{G}$, the optimal GNN model $f_\\theta$ trained on $\\mathcal{G}$, and a graph unlearning request $\\Delta\\mathcal{G} = (\\Delta\\mathcal{V}, \\Delta\\mathcal{E}, \\Delta X)$,"}, {"title": "Methodology", "content": "Framework Overview\nThe overall framework of ETR is depicted in Figure 1. In the Erase stage, we evaluate parameter importance with respect to input samples based on the FIM. Subsequently, we identify critical parameters concerning the unlearned samples and their influence on other samples. We then modify these parameters to erase the effect of the unlearned samples. In the Rectify stage, we utilize the induced graph of unlearned samples to approximate model gradients on the remaining dataset, which are then used to enhance the model performance on the remaining dataset.\nGraph Unlearning via Parameter Masking\nPrevious research indicates that certain neurons or parameters are critical in memorizing specific samples (Maini et al. 2023), and that gradient manipulation can prevent the memorization of noisy information (Chen et al. 2021). Motivated by these findings, we propose to achieve efficient unlearning by directly masking the parameters responsible for memorizing the data to be unlearned, as described below:\n$w_{r,j} =\\begin{cases}0, & j \\in M\\\\ w_j, & j \\notin M\\end{cases}$\nwhere $w^*$ represents the optimal parameters on $\\mathcal{D}$, and $M$ denotes the set of parameters responsible for memorizing the unlearned dataset. To explore the effectiveness of the masking strategy, we provide theoretical justification for its ability to achieve graph unlearning as follows:\nTheorem 1. For a GNN model, if we approximate the FIM $F$ with its diagonal diag(F), and assume all elements of diag(F) are strictly positive, the mean squared distance between the optimal model parameters trained on $\\mathcal{D}_r$ and the parameters obtained from (3), denoted as $Q = \\sum_{j} (w_j - w_{r,j})^2$, has the following upper bound:\n$Q \\leq \\frac{1}{2} (c_1 \\sum_{j \\in M} \\frac{1}{F_{D_{r},jj}} + c_2 \\frac{\\vert \\mathcal{D}_f \\vert}{\\vert D \\vert^2}  (\\sum_{j \\in M}  \\frac{F_{D_{f},jj}}{F_{D,jj}^2}) + c_3)$\nwhere $c_1$, $c_2$, $c_3$ are constants, and $\\vert w \\vert$ denotes the number of parameters.\nThe proof of Theorem 1 is provided in the Appendix. According to Theorem 1, adding the $j$-th parameter to $M$ will increase the upper bound of $Q$ by\n$\\frac{c_1}{2F_{D_{r},jj}} + \\frac{c_2  \\vert \\mathcal{D}_f \\vert^2 F_{D_{f},jj}}{\\vert D \\vert^2 F_{D,jj}^2}$. This increase is less than 0 when $\\frac{F_{D_{f},jj}}{F_{D,jj}} > \\frac{\\sqrt{c_1}}{\\sqrt{c_2}} = c$, indicating that the parameter $w_j$ is much more important for $\\mathcal{D}_f$ than for $\\mathcal{D}$. Therefore, masking parameters that are crucial for unlearned samples but not for others can reduce the upper bound of $Q$, facilitating the forgetting of the unlearned dataset.\nErase: Neighborhood-Aware Parameter Editing\nDespite the above analysis theoretically guaranteeing the effectiveness of the masking strategy in achieving unlearning, it has two major limitations First, the masking strategy overlook the extent to which $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ is exceeds c. In particular, parameters for which $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ significantly exceeds c are much"}, {"title": "Erase: Neighborhood-Aware Parameter Editing", "content": "more critical for the unlearned dataset compared to those where $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ only slightly exceeds c. Second, the masking strategy overlooks the impact of unlearned samples on their neighbors through message propagation.\nTo address the above limitations, we propose the Erase strategy as follows:\n$w_{r,j} = \\begin{cases}\\alpha_j \\cdot w_j, & \\frac{F_{D_{f},jj}}{F_{D,jj}} > \\gamma \\text{ and } \\frac{F_{D_{f,j}}}{F_{D,jj}^2} \\leq \\eta F_{D,jj}^2 \\\\ \\beta_j \\cdot w_j, & \\frac{F_{D_{f},jj} F_{D_k,jj}}{F_{D,jj}^2} > \\eta \\text{ and } F_{D_{f},jj} < F_{D,jj},  \\\\ w_j, & \\text{otherwise}.\\end{cases}$\nwhere $\\alpha$, $\\beta$, $\\gamma$, and $\\eta$ are hyperparameters.\nThe advantages of the above design are threefold. First, it considers the impact of unlearned samples on their neighbors. According to the properties of the FIM, a large ratio of $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ or $\\frac{F_{D_k,jj}}{F_{D,jj}}$ indicates that the parameter is crucial for $\\mathcal{D}_f$ or $\\mathcal{D}_k$, but not for $\\mathcal{D}$. Drawing inspiration from Theorem 1, if a parameter is crucial for both $\\mathcal{D}_f$ and $\\mathcal{D}_k$, but not for other samples, i.e., satisfying $\\frac{F_{D_{f},jj} F_{D_k,jj}}{F_{D,jj}^2} > \\eta$, we consider that the parameter has been influenced by message propagation from $\\mathcal{D}_f$. In such cases, we modify these parameters to forget the influence of unlearned samples.\nSecond, when modifying parameters, we account for the extent to which they are influenced by unlearned samples. Specifically, rather than directly masking the parameters, we use the coefficients $\\frac{F_{D_k,jj}}{F_{D,jj}^2}$ and $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ to determine the degree of modification. This implies that a large $\\frac{F_{D_{k},jj}}{F_{D,jj}^2}$ or $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ necessitates substantial modifications to $w_j$, while a small value requires only minor modifications.\nFinally, we balance the two forgetting objectives: forgetting $\\mathcal{D}_f$ and forgetting the influence of $\\mathcal{D}_f$ on $\\mathcal{D}_k$. One of these objectives may dominate the other due to the potential difference in magnitude between $\\frac{F_{D_{k},jj}}{F_{D,jj}^2}$ and $\\frac{F_{D_{f},jj}}{F_{D,jj}}$.\nTo mitigate this, we introduce two balancing coefficients a and b to balance these two forgetting objectives.\nNote the choice of hyperparameters may vary depending on the dataset. To facilitate hyperparameter selection, we adaptively select them for different datasets. Specifically, \u03b3 is set as the top m% value of $\\frac{F_{D_{f},jj}}{F_{D,jj}}$, and \u03b7 is set as the top m% value of $\\frac{F_{D_{f},jj} F_{D_k,jj}}{F_{D,jj}^2}$. This ensures that m% of the parameters satisfy $\\frac{F_{D_{f},jj}}{F_{D,jj}} > \\gamma$ and m% satisfy $\\frac{F_{D_{f},jj} F_{D_k,jj}}{F_{D,jj}^2} > \\eta$. Furthermore, we set a = \u03b3 and b = \u03b7 to balance the magnitude between $\\frac{F_{D_{f},jj}}{F_{D,jj}}$ and $\\frac{F_{D_{f},jj} F_{D_k,jj}}{F_{D,jj}^2}$."}, {"title": "Rectify: Model Utility Enhancement", "content": "Although the Erase strategy mitigates the impact on the model's predictive performance by considering the extent to which unlearned samples influence parameters, the parameter editing approach may still negatively affect the GNN's performance on $\\mathcal{D}$ to some degree. In this part, we propose the Rectify strategy to enhance GNN performance on $\\mathcal{D}_r$ without requiring access to the entire training dataset, which minimizes computational overhead while ensuring data privacy and security.\nFirstly, we estimate the gradients of the edited model on $\\mathcal{D}_r$ using the induced graph of $\\mathcal{D}_f$. Specifically, we assume that we can store the gradients from the model's final iteration of the training phase. After removing $\\mathcal{D}_f$, the neighbor structure of $\\mathcal{D}_r \\backslash \\mathcal{D}_k$ remains unchanged, while only the neighbor structures of $\\mathcal{D}_f$ and $\\mathcal{D}_k$ undergo changes. Additionally, during the Erase stage, the modified parameters are crucial only for $\\mathcal{D}_f$ and $\\mathcal{D}_k$, but not for $\\mathcal{D}_r \\backslash \\mathcal{D}_k$. Therefore, for nodes in $\\mathcal{D}_r \\backslash \\mathcal{D}_k$, their gradients can be considered nearly unchanged, i.e.,\n$\\nabla w_{r}l_j \\approx \\nabla w^*l_j, \\forall j \\in \\mathcal{D}_r \\backslash \\mathcal{D}_k$\nwhere $l_j$ denotes the loss of the GNN on the $j$-th sample. Through the aforementioned approximation, we can easily calculate the gradient of the edited model on $\\mathcal{D}_r$ as follows:\n$\\nabla_w L_{D_r} = \\frac{1}{\\vert D_r \\vert} \\sum_{j \\in D_r} \\nabla_w l_{r,j}$\n$= \\frac{1}{\\vert D_r \\vert} (\\sum_{j \\in D_r \\backslash D_k} \\nabla_w^* l_j + \\sum_{j \\in D_k} \\nabla_w l_{r,j})$\nwhere $L_{D_r}$ denotes the loss function of the GNN on dataset $\\mathcal{D}_r$. Further, leveraging the gradient of the GNN on $\\mathcal{D}$, we obtain $\\sum_{j \\in D_r \\backslash D_k} \\nabla_w^* l_j = \\frac{\\vert D \\vert}{\\vert D_r \\vert} \\nabla_w^* L_D - \\sum_{j \\in D_f} \\nabla_w^* l_j - \\sum_{j \\in D_k} \\nabla_w^* l_j$. Finally, we estimate the gradient of the edited model on $\\mathcal{D}_r$ as follows:\n$\\nabla_w L_{D_r} = \\frac{1}{\\vert D_r \\vert} (\\vert D \\vert \\nabla_w^* L_D - \\vert D_f \\vert \\nabla_w^* L_{D_f} - \\vert D_k \\vert \\nabla_w^* L_{D_k} + \\vert D_k \\vert \\nabla_w L_{D_k})$"}, {"title": "Complexity Analysis", "content": "In this section, we analyze the complexity of ETR. Calculating $\\nabla_w^* L_{D_f}$ with a time complexity of $O(|\\mathcal{D}_f|)$. Similarly, calculating $\\nabla_w^* L_{D_k}$ and $\\nabla_w L_{D_R}$ with a time complexity of $O(|\\mathcal{D}_k|)$. Computing the FIM has a time complexity of $O(|w|)$. The Erase strategy can be executed in parallel, with a time complexity of $O(|w|)$. Thus, the overall time complexity of ETR is $O(|\\mathcal{D}_f| + |\\mathcal{D}_k| + |w|)$. Regarding space complexity, the GNN parameters have a space complexity of $O(|w|)$. The node features have a space complexity of $O(|\\mathcal{D}_f|d + |\\mathcal{D}_k|d)$. The edges have a space complexity of $O(|\\mathcal{E}_f| + |\\mathcal{E}_k|)$, where $|\\mathcal{E}_f|$ and $|\\mathcal{E}_k|$ denote the number of edges in $\\mathcal{D}_f$ and $\\mathcal{D}_k$, respectively. Computing the FIM has a space complexity of $O(|w|)$. Therefore, the overall space complexity of ETR is $O(|\\mathcal{D}_f|d + |\\mathcal{D}_k|d + |w| + |\\mathcal{E}_f| + |\\mathcal{E}_k|)$. Notably, $\\mathcal{D}_f$ and $\\mathcal{D}_k$ are much smaller than $\\mathcal{D}$, resulting in low computational overhead for large-scale graphs."}, {"title": "Experiments", "content": "In this section, we conduct extensive experiments to evaluate the effectiveness of ETR. The experiments aim to answer the following research questions: RQ1: How does ETR perform in terms of model utility, unlearning efficiency, and unlearning efficacy? RQ2: How does ETR perform on large-scale graphs? RQ3: How do hyperparameters influence ETR's performance? RQ4: How do different strategies in ETR contribute to its effectiveness?"}, {"title": "Experimental Setup", "content": "Datasets We conduct experiments on PubMed, CiteSeer, Cora (Yang, Cohen, and Salakhutdinov 2016), CS, Physics (Shchur et al. 2018), ogbn-arxiv, and ogbn-products (Hu et al. 2020). The statistics and detailed descriptions of these datasets are provided in the Appendix.\nBaselines We compare ETR with various baselines, including Retrain, GraphEraser-BEKM, GraphEraser-BLPA (Chen et al. 2022), GIF (Wu et al. 2023a), GUIDE-SR, GUIDE-Fast (Wang, Huai, and Wang 2023), and MEGU (Li et al. 2024). Detailed descriptions of these baselines are provided in the Appendix.\nSettings Following GIF, we partition each graph into a training subgraph comprising training nodes and a test subgraph containing the remaining nodes. For PubMed, CiteSeer, Cora, CS, and Physics, we randomly allocate 90% of the nodes to the training set. For ogbn-arxiv and ogbn-products, we use the splits provided in (Hu et al. 2020). The unlearning ratio is set to 5% for all tasks. We use two-layer GCN and GAT models with a hidden state dimension of 256, training for 100 epochs. All experiments are conducted on a single Nvidia A40 GPU. Each experiment is run ten times, and we report the average value and standard deviation.\nEvaluation of Model Utility (RQ1)\nWe evaluate the F1 score for node classification on the remaining dataset. The results for node unlearning are shown in Table 1, while the results for edge and feature unlearning are provided in the Appendix. It can be observed that ETR"}, {"title": "Erase: Neighborhood-Aware Parameter Editing", "content": "in most cases, which can be attributed to the Rectify strategy that enhances model performance on the remaining dataset. Additionally, BEKM and BLPA exhibit suboptimal performance, consistent with the results reported in their original papers, likely due to disruptions in graph structure resulting from graph partitioning. GUIDE mitigates this problem, leading to improved performance. Among the baselines, MEGU achieves the best performance, which can be attributed to its training of the model's predictive objective during unlearning.\nEvaluation of Unlearning Efficiency (RQ1)\nThe runtime results are presented in Table 1. ETR consistently outperforms all baselines, which can be attributed to its training-free nature. ETR reduces runtime by thousands of times compared to Retrain, demonstrating its superior efficiency. While GraphEraser and GUIDE are also faster than Retrain in most cases, they still require considerable time for unlearning due to the need for retraining multiple models. Although GIF and MEGU improve runtime efficiency compared to other baselines, they still fall short of ETR. Specifically, ETR reduces runtime by 38 times compared to GIF"}, {"title": "Hyperparameter Analysis (RQ3)", "content": "The hyperparameters m and A are crucial for ETR's performance. The value of m determines how much the parameters are modified, thereby influencing the extent of model forgetting. The value of A controls the extent of model rectification. In this section, we investigate their impact on ETR's performance using the PubMed, CiteSeer, and Cora datasets.\nWe investigate how different values of m affect the performance of the Erase strategy, with results shown in Figure 3. It can be observed that increasing m generally improves model performance, but performance declines if m becomes too large. This is because larger m values help the model forget unlearned samples effectively, while excessively large values can also lead to the loss of essential knowledge. Typically, m values between 8% and 160 provide the best results for the Erase strategy. Notably, the model performs better compared to m = 0, confirming that the Erase strategy effectively forgets unlearned samples and supports Theorem 1.\nWe tune A within the range of [0, 0.9] to investigate how it affects ETR's performance, with results shown in Figure 3. It can be observed that ETR's performance generally improves as A increases. However, performance declines if A becomes too large. This is because larger A values aid in model rectification, while excessively large values can also lead to excessive rectification. Optimal performance for ETR is typically achieved with values between 0.3 and 0.5."}, {"title": "Ablation Studies (RQ4)", "content": "In this section, we investigate the effectiveness of different strategies in ETR. The Erase is crucial for model forgetting, while the Rectify is critical for maintaining model utility. The results in Figure 3 indicate that increasing m improves performance compared to m = 0, demonstrating the effectiveness of the Erase strategy in forgetting the unlearned samples. The results in Figure 3 show that increasing A also improves performance compared to X = 0, indicating that the Rectify strategy effectively enhances the model performance on the remaining dataset.\nTo further investigate the effectiveness of the Erase strategy, we compare ETR with two model variants, as shown in Table 5. Specifically, \"w/ mask\" refers to using the masking strategy, while \u201cw/o mes\u201d indicates not considering the impact of message propagation. The results show that ETR outperforms both variants in most cases, except for a slight decrease on the Physics dataset compared to \"w/ mask\". This demonstrates that parameter editing is more effective than just applying a mask and emphasizes the importance of considering message propagation in graph unlearning.\nIn the Rectify stage, we use the induced graph of unlearned samples to approximate the gradient of the model on the remaining dataset. We measure the difference of this approximation using Absolute Difference (AD) and Relative Difference (RD), as shown in Table 6. The results show that both differences are minimal, indicating that the gradient approximation ensures both efficiency and accuracy."}, {"title": "Conclusion", "content": "In this paper, we investigate cost-effective graph unlearning and propose a training-free approach ETR to remove the influence of unlearned samples while maintaining the model performance on the remaining dataset. Specifically, in the Erase stage, we utilize the Fisher Information Matrix to identify parameters crucial for unlearned samples and their influence on other inter-connected samples. These parameters are then modified to forget the unlearned samples and their effects on other samples through message propagation. In the Rectify stage, we use the induced graph of the unlearned samples to efficiently approximate the model's gradient on the remaining dataset. This gradient is then used to enhance the model performance on the remaining data. Extensive experiments on seven public datasets demonstrate that the proposed ETR method achieves an excellent trade-off between efficiency and effectiveness."}, {"title": "Algorithm 1: ETR: Erase then Rectify", "content": "Input: Unlearned dataset $\\mathcal{D}_f$; Dataset $\\mathcal{D}_k$; GNN $f_\\theta$; Optimal parameters $w^*$; Gradient $\\nabla w^* L_D$; Hyperparameters m and $\\lambda$.\nErase\n1: Calculate the gradients $\\nabla w^* L_{D_f}$ and $\\nabla w^* L_{D_k}$.\n2: Calculate the FIM $F_D$, $F_{D_f}$, $F_{D_k}$ via (2).\n3: Obtain $\\gamma = top-k\\%(\\frac{F_{D_f}}{F_D})$ and $\\eta = top-k\\%(\\frac{F_{D_f}F_{D_k}}{F_D^2})$\n4: for j in range w do\n5:   Obtain $\\alpha_j = \\frac{F_{D_f}}{F_{D,jj}}$ and $\\beta_j = \\frac{F_{D_k}}{F_{D,jj}}$.\n6:   if $\\frac{F_{D_{f},jj}}{F_{D,jj}} > \\gamma$ then\n7:    $w_{r,j} = \\alpha_j \\gamma w_j$\n8:   else if $\\frac{F_{D_{f},jj}F_{D_k,jj}}{F_{D,jj}^2} > \\eta$ then\n9:    $w_{r,j} = \\beta_j \\eta w_j$\n10:   else\n11:    $w_{r,j} = w_j$\n12:   end if\n13: end for\nRectify\n14: Calculate the gradient $\\nabla_w L_{D_k}$.\n15: Obtain the gradient $\\nabla w L_{D_r}$ via (9).\n16: Obtain the parameters $w'$ via (10).\nOutput: $w'$."}, {"title": "ETR for Edge Unlearning and Feature Unlearning", "content": "For edge and feature unlearning, it is necessary to forget the impact of the unlearned edges or features on other nodes. We denote the subgraph affected by the unlearned edges or features as $D_i$. Consequently, we modify the parameters that are crucial for $D_i$ but not for the remaining dataset, as detailed in Algorithm 2. Additionally, we approximate the gradient of the model on the remaining dataset as follows:\n$\\nabla w_{r}L_{D_r} = \\frac{1}{\\vert D_r \\vert} [\\vert D \\vert (\\nabla w^* L_{D}) - (\\nabla w^* L_{D_i}) + (\\nabla L_{D_i}) ]$\nFurthermore, we utilize this gradient to enhance the model performance on the remaining dataset, as demonstrated in Algorithm 2."}, {"title": "Algorithm 2: ETR for Edge and Feature Unlearning", "content": "Input: Influenced dataset $D_i$; GNN $f_\\theta$; Optimal parameters $w^*$; Gradient $\\nabla_w^* L_D$; Hyperparameters $m$ and $\\lambda$.\nErase\n1: Calculate the gradients $\\nabla_w^* L_{D_i}$.\n2: Calculate the FIM $F_D$, $F_{D_i}$ via (2).\n3: Obtain $\\gamma = top-k\\%(F_D)$.\n4: for j in range w do\n5:   Obtain $\\alpha_j = \\frac{F_{Di}}{F_{D,jj}}$.\n6:   if $\\frac{F_{Di,jj}}{F_{D,jj}} > \\gamma$ then\n7:    $w_{r,j} = \\alpha_j \\gamma w_j$\n8:   else\n9:    $w_{r,j} = w$\n10:   end if\n11: end for\nRectify\n12: Calculate the gradient $\\nabla_w L_{D_k}$.\n13: Obtain the gradient $\\nabla_w L_{D_r}$ via (36).\n14: Obtain the parameters $w'$ via (10).\nOutput: $w'$."}, {"title": "Additional Experimental Results", "content": "\u2022 GIF: GIF utilizes influence functions to approximate the parameter changes resulting from an unlearning request"}]}