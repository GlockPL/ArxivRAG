{"title": "MARLIN: A Cloud Integrated Robotic Solution to Support Intralogistics in Retail", "authors": ["Dennis Mronga", "Andreas Bresser", "Fabian Maas", "Adrian Danzglock", "Simon Stelter", "Alina Hawkins", "Hoang Giang Nguyen", "Michael Beetz", "Frank Kirchner"], "abstract": "In this paper, we present the service robot MARLIN and its integration with the K4R platform\u00b9, a cloud system for complex AI applications in retail. At its core, this platform contains so-called semantic digital twins, a semantically annotated representation of the retail store. MARLIN continuously exchanges data with the K4R platform, improving the robot's capabilities in perception, autonomous navigation, and task planning. We exploit these capabilities in a retail intralogistics scenario, specifically by assisting store employees in stocking shelves. We demonstrate that MARLIN is able to update the digital representation of the retail store by detecting and classifying obstacles, autonomously planning and executing replenishment missions, adapting to unforeseen changes in the environment, and interacting with store employees. Experiments are conducted in simulation, in a laboratory environment, and in a real store. We also describe and evaluate a novel algorithm for autonomous navigation of articulated tractor-trailer systems. The algorithm outperforms the manufacturer's proprietary navigation approach and improves MARLIN's navigation capabilities in confined spaces.", "sections": [{"title": "1. Motivation", "content": "In order to be competitive with respect to international online sellers, the stationary retailer has to combine its competencies in customer service and confidence with the possibilities of digitalization and robotics. In a future retail store, employees are providing advice to the customers, while robotic systems are in charge of stock-taking, replenishment and collecting scattered items. Smartphone apps direct the customer to the desired goods and answer their queries related to the assortment. Finally, the technology supports visually impaired or disabled people with shopping. Thus, AI and robotics in stationary retail have the potential to increase productivity by automating everyday tasks and improve customer experience. In order to put this vision into practice, detailed and comprehensive models of the store, the selling process and operation sequences need to be made available in machine readable form and provided to the robotic systems. The robots may benefit from this background information and improve their capabilities in terms of execution speed, autonomy, and safety.\nIn this paper, we describe the mobile service robot MARLIN (Mobile Autonomous Robot for intra-Logistics IN retail) and its integration with the K4R platform, an open-source cloud platform for AI and robotic applications in retail (see Figure 1a for an illustrative overview). At its core, this platform provides so-called semantic digital twins, a generic, machine-readable format for digital representation of retail stores. They allow the construction of realistic digital worlds and enable a variety of novel AI and robotics applications like data analysis, symbolic reasoning, and process planning. We exploit the potential of integrating MARLIN with the K4R platform and evaluate its capabilities in terms of perception, autonomous navigation, and task planning. The overall system is evaluated in a retail intralogistics scenario, namely the support of store employees in refilling shelves (see Figure 1b). The robot autonomously transports goods to the target shelf, assists employees with replenishment using a pointer unit, and interacts with them via a graphical interface. At all times, it exchanges information with the semantic digital twin, for example the position of products within the shelves, the whereabouts of store employees, as well as the location of obstacles in the corridors, which are perceived through 3D onboard sensors on the robot. This way MARLIN can safely navigate in a retail store and adapt to"}, {"title": "2. Related Work", "content": "This section provides a state-of-the-art overview on the different areas of research touched by this work, namely robotics for retail and intralogistics applications in general, the digital twin technology, autonomous navigation for tractor-trailer systems, as well as adaptive task planning."}, {"title": "2.1. Robotics in Retail", "content": "When related to the field of warehouse logistics the number of commercially available robotic systems for stationary retail is comparatively low. One reason is the greater complexity of the store environment and the associated challenges in terms of robotic perception, navigation, and manipulation. For example, the store might be filled with customers, which impede an autonomous robot from navigating efficiently and safely. Furthermore, the products on the shelves vary greatly in terms of size, shape and weight, which makes autonomous manipulation difficult. Finally, the stores in itself vary widely and a one-fits-all robotic solution does not exist. Therefore, only a few autonomous robots have been used efficiently and economically in stationary retail to date, although the growth is rapid, as mentioned by Bogue [1].\nPositive examples of economically viable robotic applications in stationary retail exist in the area of inventory and out-of-stock detection, for example the Tally robot by simbe robotics [2], or the AdvanRobot system proposed by Morenza-Cinos et al. [3]. In the area of inventory and out-of-stock detection, the visual perception of articles is in focus. A survey of machine vision based retail product recognition systems is presented by Santra and Mukherjee [4]. The work of Kumar et al. [5] describes semi-automatic out-of-stock"}, {"title": "2.2. Digital Twins", "content": "Digital twins are increasingly used in industrial manufacturing and production to represent, simulate, monitor, analyze, and optimize production processes and product lifetime cycles [8]. However, in the area of stationary retail, the use of digital twins is less widespread. The digitization of stationary retail demands for an integration of various, disparate information like product data, article localization, customer routes and attention, as well as sales figures.\nA considerable challenge for autonomous robots in retail is the perception and interpretation of the store environment (not the individual products in the shelves), which is different from store to store, but might also change within same store on a daily basis due to varying placement of articles, stock level, or locations of stand-up displays. A digital twin of the store environment can be used to collect, preprocess, and provide the perceived data from multiple sources in a machine-readable format. However, establishing a digital environment from scratch without considerable manual effort is a complex problem. Paolanti et al. [9] describe a semantic object mapping based on 3D point cloud data to analyze and map a store environment. The work by Beetz et al. [7] introduces semantic store maps, which are a special form of semantic digital twins (semDT) as described by K\u00fcmpel et al. [10]. A semDT is a semantically enhanced virtual representation of the physical retail store, which connects symbolic knowledge with a scene graph, allowing complex reasoning tasks. The work presented in this paper builds upon the concept of the semDT and showcases a robotic application to support store employees in shelf refilling. Specifically, we use the reasoning capabilities of KnowRob [11], a knowledge processing system for robots. KnowRob organizes the digitized store data coming from disparate sensor sources and"}, {"title": "2.3. Autonomous Navigation of Tractor-Trailer Systems", "content": "Autonomous navigation for mobile robots is a widely researched field and there are many commercially available solutions, especially for indoor environments [12, 13]. The application to tractor-trailer systems, i.e., an actuated towing vehicle (tractor) with attached passive trailer, is more challenging in terms of navigation planning and path following. Application areas for autonomous tractor-trailer systems include agriculture and autonomous driving in road traffic.\nIn agriculture, automated harvesting in particular is an important issue. The work by Thanpattranon et al. [14] introduces a method for controlling an autonomous agricultural tractor equipped with a two-wheeled trailer using a single laser range finder. To simplify navigation in narrow rows of orchards and plantations, they developed a sliding mechanical coupling between trailer and tractor, which adjusts the position of the hitch-point. In contrast, we develop a software solution that can be applied to various tractor-trailer systems without the need to mechanically adjust the hitch point. The work by Backman et al. [15] introduces a non-linear model predictive path tracking approach for agricultural machines. In contrast to the method presented by Thanpattranon et al. [14] the authors fuse information from GPS, laser range finder, and IMU to estimate tractor position and heading angle. However, they deal only with the problem of trajectory tracking, not with planning. Moreover, their mechanical structure includes an additional degree of freedom, namely a hydraulic joint in the suspension between the towing vehicle and the trailer. This leads to a multivariate control problem that is more complex than that of a passive trailer, although it offers more flexibility.\nIn the field of autonomous driving in road traffic, trucks with trailers are of particular interest. The work by Oliveira et al. [16] introduces an optimization-based path planning algorithm for articulated vehicles. They formulate the on-road path planning as an Optimal Control Problem (OCP), which is solved using Sequential Quadratic Programming, thereby comparing different cost functions. Results are, however, presented only in simulation. Similarly, Li et al. [17] formulate path planning for tractor-trailer systems as an OCP. In their approach, N trailers may be attached to a single tractor system. An initial guess for the OCP is provided by a sample-and-search planner. Again, results are presented in simulation only and computation times are large (about 30-180 seconds depending on the planning problem)."}, {"title": "2.4. Task Planning for Mobile Robots in Industry and Retail", "content": "Task planning in robotics is concerned with deliberately deciding on a sequence of actions to take in order to achieve a given set of goals [19]. \u0391\u0399 planning methods have a long history [20] and have been applied to increasingly complex robotic applications, for example household [21] or manufacturing [22]. Despite the long exploration of AI-based planning there are still open research problems, e.g., how to efficiently represent knowledge from disparate sensor sources, or how to bridge the gap between symbolic and numerical action representations. Task planning for robotics is closely linked to the fields of knowledge representation and reasoning. Planning complex tasks in real-world environments requires a powerful representation of knowledge acquired from disparate sources, as well as a means to reason about this information. Both can be provided by KnowRob [11], the knowledge representation and reasoning framework which we use in our work. We connect"}, {"title": "3. MARLIN: A Service Robot to Support Intralogistics in Retail Stores", "content": "This section describes the service robot MARLIN and its capabilities regarding perception, autonomous navigation and interaction with the store employees."}, {"title": "3.1. System Description", "content": "The design of MARLIN as illustrated in Figure 2 has been led by the requirements of pilot application Service Robotics to Support Store Employees in the Knowledge4Retail (K4R) project. Within this project, a mobile, autonomous robot should be developed to support store employees in shelf refilling. The robot should be able to navigate efficiently and safely within a retail store. Apart from that it should (a) be integrated seamlessly with the K4R platform, a cloud solution to enable AI applications in stationary retail, (b) reuse existing structures of the stores, e.g., carts on wheels used for intra-logistics, and (c) provide user interfaces to interact with the store employees.\nMARLIN consists of a commercially available MiR100 platform\u00b3 with transport hook, equipped with an external PC, a pointer unit to guide the store employee in the process of replenishment, as well as 4 RGB-D cameras, which provide points clouds in a 360 degree view. The system is able to autonomously pick-up, carry, and place transport carts on wheels, which are commonly used by retailers. Interaction with the user can be performed via an attached tablet, which is connected via the K4R platform as described in Section 4."}, {"title": "3.2. Obstacle Detection and Classification", "content": "By integrating MARLIN with the K4R platform, the robot continuously exchanges information with the retail store's semDT. Using its built-in sensors, the robot can detect obstacles, upload their position to the semDT, and reuse this information for future task planning and navigation. To handle static and dynamic obstacles, a pipeline was developed to detect and classify objects in the raw point cloud data. This pipeline, which is an extension of the multi-object tracking described by de Gea Fern\u00e1ndez et al. [26], contains three main processing steps: (1) background removal, (2) clustering and tracking of objects, and (3) normalization & classification of tracked objects.\nBackground Removal. The multi-object tracking approach we use to cluster and track obstacles in raw point cloud data has originally been developed for stationary robots [26]. In the original approach, the stationary background is removed from the point cloud data before clustering in order to increase performance. While this task is trivial for a stationary system, in a mobile robotics application the background filter must constantly adapt to the environment and be much faster to ensure that no artifacts remain in the filtered point cloud, even when the robot is moving fast. Thus, we use the following procedure for background removal. We first reduce the number of points in"}, {"title": "3.3. Autonomous Navigation for Tractor-Trailer Systems", "content": "The proprietary navigation stack of the MiR100 platform provides navigation capabilities for indoor operation through a ROS (Robot Operating"}, {"title": "Vehicle Kinematics", "content": "For the differential drive tractor with the trailer joint attached directly at the steering axis, a car-like controller with kinematic bicycle model can be applied, as shown in Figure 7. In our model, the trailer represents the rear axle of the model and the MiR100 represents the steering axle. The cart is attached to the robot via a transport hook, which has a passive rotational joint located at the rotation axis of the robot base. After picking up the cart, it is rigidly attached to the hook.\nThe trailer has one axle with fixed caster wheels and one axle with swivel caster wheels that can passively rotate around their vertical axis to follow the motion of the trailer. We define a coordinate frame in the center of the axle between the two fixed caster wheels, which coincides with the base frame of the bicycle model (positioned at x(t), y(t) in Figure 7). The orientation of the coordinate frame in map coordinates is defined by the angle \u0398. The distance"}, {"title": "Global Path Planning", "content": "We use the SBPL (Search-Based Planning Library [33]) Lattice Planner with a rectangular footprint tied to the fixed axis of the trailer. This planner finds the path to the requested goal pose by chaining motion primitives with different lengths and curvatures. By limiting the maximum curvature of the motion primitives the resulting plan is expected to be feasible to be executed by the vehicle via the local planner. The path stubs are generated by a search algorithm and evaluated in an occupancy grid which covers the whole environment."}, {"title": "Local Path Planning", "content": "For the local path following we use the TEB (Time Elastic Band) Local Planner [34], which supports navigation for car-like vehicles. For evaluating the actual path, it tracks the obstacles around the vehicle in a smaller, local occupancy grid. It then computes the actual control commands in terms of linear and angular velocities (\u017c and \u04e8) to be executed by the vehicle. For representing the system in the local path planner, we use the Two Circles footprint model. According to this model, the footprint of the vehicle is specified in terms of two circles that are defined by radius and offset from the vehicle's base frame, respectively (see Figure 8). Typically, local planners (e.g., in the ROS navigation stack) provide the output command as the longitudinal speed and angular velocities (here: \u017c, \u0398). To map these commands to the car-like vehicle model we need to\nadd another intermediate controller stage that derives the commands for the tractor vehicle (\u017c', \u0398'), which correspond to the desired behavior of the tractor-trailer system. Given the vehicle's wheel base L, the steering angle \u03b4 can be obtained from the target velocities via the curvature of the requested path \u043a with the following formula:\n$\\kappa = \\Theta / x$ (1)\n$\\delta = arctan(L\\kappa)$ (2)\nTo control the steering angle, we use a P-controller, which generates the output rotational velocity that would minimize the deviation between the current and the target steering angle:\n$\\Theta' = K_p\\Delta\\delta_{normalized}$ (3)\nTo avoid issues with angular wrap around, we use the following normalization term to make sure the angle is always in the half-open interval [-\u03c0, \u03c0):\n$\\Delta\\delta = \\delta_{target} - \\delta_{current}$ (4)\n$\\Delta\\delta_{normalized} = (\\Delta\\delta + \\pi) \\mod 2\\pi - \\pi$ (5)"}, {"title": "", "content": "where mod is the modulo operation. The current steering angle can be retrieved from the sensor attached to the MiR hook joint. In order to prevent self-collisions, the local planner limits the maximum steering angle the controller will command. Furthermore, we specify the maximum allowed angular velocity to limit the controller output.\nIn analogy to the angular velocity, the longitudinal velocity is not directly applied to the tractor system. To avoid drift before the desired steering angle is regulated, we add a Gaussian activation function to limit the output longitudinal velocity \u017c' based on the current normalized deviation of the steering angle \u2206\u03b4normalized:\n$x' = \\dot{x} \\exp^{\\frac{-\\Delta \\delta^2}{2\\alpha}}$ (6)\nBy adjusting the activation factor \u03b1 we can influence the width of the admissible band of steering angle deviations. Values of around 10 or larger will practically allow the full longitudinal velocity regardless of the deviation. Smaller values gradually reduce the bandwidth of the allowed range."}, {"title": "4. The K4R Platform for AI Applications in Retail", "content": "The K4R platform is an open-source software platform to enable AI and robotics application for retail. At its core, it provides so called semantic digital twins, which are illustrated in the following section."}, {"title": "4.1. Semantic Digital Twin", "content": "A semantic Digital Twin (semDT) is a digital representation of a retail store, which connects a scene graph to a semantic knowledge base as is described in [10]. The scene graph contains a 3D model of the store, which is semantically annotated, and holds information like the relative location of the store shelves and products. This data can be automatically generated by a robot driving through the store and scanning all the products within the shelves. The acquired information is connected to an ontology-based semantic knowledge base, which is based on interlinked ontologies providing further information on the products, like their ingredients and classifications, 3D models, product taxonomies, product brands or labels. This facilitates semantic reasoning on the semDT, visualization of the 3D environment in various applications, and it allows a human user or a robot to request information using semantic queries. These queries are processed by KnowRob"}, {"title": "4.2. K4R Platform Architecture and Robot Interfaces", "content": "The K4R infrastructure is developed in containers deployed as pods within a Kubernetes cluster. The two main pods described here are called planning and web. The planning pod uses the ROS WebSuite [36] to connect to robots and other devices via WebSockets. The purpose of the planning pod is to use ROSPlan [23] to create and execute high-level action plans for robotic agents, control the agents, and exchange data with them. The ROS-Plan knowledge base is constantly synchronized with the semDT, using the semantic reasoning capabilities of KnowRob.\nThe web pod is used for human-robot interaction. It hosts a custom Express.js TypeScript application with an Angular front-end through which the user can retrieve information about the agents, launch missions, or directly\ncontrol one of the robots. The web pod sits behind an OAuth2 Keycloak installation to ensure secure communication over the Internet. To allow storing each agent's state, we use certificate-based authentication with tokens and ROSAuth. An overview of the architecture is shown in Figure 9. The K4R platform architecture is described in more detail in [37]."}, {"title": "Agent Management", "content": "Robots and other agents connect to the K4R platform using the agent manager as shown in Figure 10. It registers with the planning system and provides information about the connected robot. The connection also uses the ROS WebSuite, which is commonly installed on the robotic agent. However, this requires the robot to be fully connected within the network, which is complicated to accomplish when being connected via a cloud platform. Instead of developing a custom server to handle data from the different agents, we deploy the ROS WebSuite on the K4R platform itself, which also brings benefits for robotics software developers, as they can stick to ROS topics and services."}, {"title": "User Interfaces", "content": "The user interface was developed as a responsive Angular web application that focuses on touch input for tablets, but can also be"}, {"title": "Task Planning", "content": "For mission planning of MARLIN and other robots, we use the ROSPlan planning system from Cashmore et al. [38], which builds on the POPF (Partial Order Planning Forwards) planner from Coles et al. [39]. The planning framework runs on the K4R platform. Thus, it is possible to plan missions with multiple agents and resources, and to easily synchronize the knowledge base of ROSPlan with the semDT. The planning domain is modeled in PDDL (Planning Domain Definition Language [40]).\nThe focus of mission planning here is on the replenishment of the shelves, as well as the related autonomous transport of goods. The goal of such a mission is that all products are autonomously delivered to their target shelves, where they are filled into the shelves by a store employee. In the corresponding"}, {"title": "5. Experimental Evaluation", "content": "In this section, we evaluate the capabilities of MARLIN in terms of obstacle detection, autonomous navigation, and task planning. Results are provided in simulation, in laboratory environment, and in a retail store."}, {"title": "5.1. Obstacle Detection and Classification", "content": "First, the computational effort of the obstacle detection and classification pipeline is evaluated by measuring the computation time for the different processing steps, as shown in Figure 3. Experimental data is recorded as MARLIN navigates a retail store with various obstacles in the aisles (see Figure 5b). We use two depth cameras with a resolution of 640 x 480 pixels and evaluate the pipeline on MARLIN's onboard PC with 8 x 3.6 GHz, 32 GB RAM. Second, we evaluate the classification performance by measuring the prediction error rate of the classifier using training and test data obtained in a laboratory environment. We use a single depth camera with 640 x 480 pixels in this experiment."}, {"title": "5.1.1. Computational Efficiency", "content": "To evaluate computational performance of the obstacle detection and classification pipeline, we measure the average computation time of the individual processing steps given n = 1000 sample points clouds collected when navigating with the MARLIN robot in a retail store. The store environment was filled with artificial obstacles like boxes and shopping carts. Figure 11 illustrates the results. It can be seen that background removal requires the largest computation time, which is due to the large number of rules that is created for the map of the retail store (see Figure 4). The poor quality of the map, the diagonal orientation of the shelves, and the way the condition filter works, where rules can only be created parallel to the x- and y-axis, result in the creation of > 1700 rules in total. The second most time-consuming process is the transformation and voxel grid filter, which depends mainly on the size of the incoming point cloud. The computation times of the other processing steps, namely point cloud merging, tracking, normalization, and preparation, are low in comparison.\nTo decrease overall computation time, one could trade off accuracy versus the resolution of the original depth images, manually preprocess the 2D map"}, {"title": "5.1.2. Classification Accuracy", "content": "To evaluate the performance of obstacle classification we record data in a laboratory environment similar to Figure 6. We train 5 different objects (bag, carton, hook cover, human, and thrash can) using raw point cloud data. To evaluate the error rate of the trained SVC model, we consider both the individual predictions of the model (Figure 13a) and the output prediction (Figure 13b), where ten predictions are combined into one. The validation of the trained model was performed with live data from objects of all classes shown in Figure 12. Except for the classification of the hook cover (which is sometimes split into two clusters due to its shape, leading to false classifications), the precision of the classification can be improved by considering ten classifications."}, {"title": "5.2. Tractor/Trailer Navigation", "content": "The capabilities of the approach for tractor-trailer navigation are first evaluated in simulation. In the next step, we reproduce the results on the real system in a similar environment and compare our approach with the capabilities of the proprietary navigation stack."}, {"title": "5.2.1. Evaluation in Simulation", "content": "We first create a simple simulation environment in which the robot is to navigate along a corridor. Figure 14 shows a schematic top view of the environment, with the walls in black and the empty floor space in white. The central square wall is resized in steps of 0.1 m to create different corridor widths between 1.4m and 2.0m. The values were selected based on the corridor widths typically found in retail stores. The corridor length is kept constant at 10m. The target points Po - P3 are located in the middle of the respective sides and are aligned so that the robot only has to move forward."}, {"title": "Procedure", "content": "Initially, the robot is placed at position Po and is then asked to navigate to the positions P1, P2, P3, and Po in order. The goal tolerance of the navigation approach is selected to allow 0.5m of translational and 0.2 rad of rotational deviation. We run the experiment 25 times for each configuration. If the robot fails to reach a position, we register this failure. In this case, the next position is chosen nevertheless, so that all goal positions are evaluated on each run. We justify this procedure as follows: Sometimes, despite an error at one position, the robot still manages to reach the subsequent positions. This happens either because the robot drives past an unreachable position, or because it drives backwards from a corner where it was stuck before. The entire run is aborted if the laser scanner detects an obstacle in the circular safety zone around the towing vehicle that is slightly larger than its actual footprint. We record the trajectories of the tractor x'(t), y'(t) and the trailer coordinate system x(t), y(t) during the experiments, as well as the execution time, and whether each position has been reached or not. The goal of evaluation is to measure the success rate (in terms of the number of positions reached successfully) and the average duration for each run as a function of corridor width to get an idea of the expected performance on the real system."}, {"title": "Results", "content": "Figure 15 shows the trajectories of the tractor and trailer positions along the track. It can be seen that the tractor overshoots the center path at the corners, because otherwise the trailer would collide with the inner walls.\nFigure 16a illustrates the number of intermediate targets reached along the route over the corridor widths. It can be seen that the approach works reliably down to a corridor width of 1.6m. With a corridor width of 1.5 m, 92 out of 100 intermediate targets are still reached during the 25 passes. At a corridor width of 1.4m, the success rate drops sharply. Here, the vehicle reaches the first intermediate target in only four of 25 passes.\nIn addition, we evaluate the time required to navigate around a single corner, which naturally increases as corridor width decreases. This is evident for corridor widths of 1.5 meters and less, while the time required to navigate the route is relatively constant for corridor widths of 1.6 meters and more (see Figure 16b)."}, {"title": "5.2.2. Real-World Evaluation", "content": "For the evaluation on the real system, we create a similar track as in simulation. However, unlike the simulation, the corridor has only one corner with critical width, while the rest of the path is wide enough to easily return to the starting position before the next pass. Figure 17b shows a schematic overview of the setup with the walls in black and the free area in white. The central wall is moved to create different corridor widths. The positions Po and P\u2081 are adjusted accordingly to always be in the center of the corridor. The goal of this evaluation is to reproduce the performance observed in the simulation and compare our approach with the proprietary navigation method of the MIR robot, which is provided by the manufacturer."}, {"title": "Procedure", "content": "We start with a corridor width of 1.9 m and reduced it in increments of 0.1 m. The goal tolerance was set to allow 0.5m translation and 0.2 rad rotation error. For each corridor width, we start the experiment with the robot in pose P\u2081 and send it to the target poses Po and P\u2081 alternately, regardless of whether the previous target was reached or an error occurs. We repeat the evaluation five times without manual intervention for both our custom tractor-trailer navigation approach and the proprietary navigation"}, {"title": "Results", "content": "Table 1 shows the success rate of the approaches with respect different corridor widths.\nWe find that the proprietary navigation approach is able to reliably navigate the course down to a corridor width of 1.6m. However, at a corridor width of 1.5 m, the planner is no longer able to find a path through the course. The custom navigation approach, on the other hand, is able to navigate the course up to and including a width of 1.5 m.\nAlso, in the custom navigation approach, we observe two error cases at corridor widths of 1.9m and 1.6m. Both occur at the turn just before the"}, {"title": "5.2.3. Discussion", "content": "Using the proposed method for tractor-trailer navigation, the robot can navigate reliably up to a corridor width of 1.6 m in the simulated environment. Below 1.5m, navigation time increases noticeably and the system begins to occasionally get stuck at a corner. At even lower corridor widths, the success rate drops to near zero, which is consistent with the manufacturer's stated limitations for the system.\nIn the real-world robot application, the custom approach to tractor-trailer navigation was able to navigate narrower corridors than the MIR robot's proprietary approach. However, the proprietary navigation approach tends to deliver smoother and more robust execution, possibly due to better fine-tuning of navigation parameters. With manual control of the robot, even much smaller corridor widths are possible, leaving room for further optimization for the autonomous navigation."}, {"title": "5.3. Task Planning", "content": "In this section, we evaluate the performance of the planner with respect to the size of the store and the number of products. For this purpose, we use"}, {"title": "", "content": "the domain description shown in Listing 3 and the problem definition shown in Listing 4. This definition describes the task \"Replenish all items loaded on the cart\" in PDDL. We assume here that the robot can approach all available unloading points without exceptions. All computation is performed on an Intel i7-8550U CPU. We use the POPF planner from ROSPlan and evaluate different transportation scenarios. As can be seen in Figure 18, the planning time increases exponentially with the number of products and shelves (blue bars). Thus, a completely free definition where the agent can move to any waypoint is not practical in a realistic scenario with a few hundred products and over a hundred shelves, which requires narrowing the search space.\nIf we give the planner a graph with a fixed order in which the waypoints must be approached, the planning time is reduced considerably, as can be seen in Figure 18 (orange bars). Thus, we use a simple heuristic from a distance matrix of the store to get an initial guess of the unloading order. The distance matrix is fixed for each store and can be obtained using the store layout. It contains the pairwise distances between all relevant locations in the store, e.g., the shelves.\nIf an unloading point cannot be approached (e.g., because an obstacle is in the way), and the navigation planner of the robot cannot find an alternative route, the sequence of unloading points is adjusted. In this case, the robot initially omits the next unloading point, adds it to the end of the list as an additional destination, and proceeds to the next unloading point. It is assumed that the unloading point is only temporarily blocked (e.g. due to high customer traffic in an aisle) and will be available again after some time. It will be very beneficial to provide additional information about the specific store in the knowledge base of the planner. If the obstacle can not move the robot might need to call a shop employee for help but if there is a human in the path it could ask the human politely to move or ask a shop employee for help. An option to improve the robots' behavior would be to use Reinforcement Learning to figure out where these areas are and optimize the order in which the waypoints are approached accordingly. A possible implementation for this has been investigated by [41], but needs to be validated outside of simulation and is not integrated into the K4R platform."}, {"title": "5.4. Use Case: Support of Shelf Refilling", "content": "We evaluate the shelf replenishment application in a drugstore. MARLIN starts in the charging station. We load different products from the store on the cart and manually pass the list of products to the robot. If the store"}, {"title": "6. Conclusion and Outlook", "content": "In this paper, we present the MARLIN service robotic system and its integration with the K4R platform, a cloud computing solution that enables AI and robotics applications for retail. By connecting with the K4R platform, MARLIN's capabilities in perception, navigation, and mission planning are enhanced. We demonstrate that MARLIN is able to detect and classify unknown obstacles, navigate through the narrow aisles of a retail store, and plan and execute missions that assist the store employee in replenishing the shelves.\nThe potential of AI solutions and autonomous robotics in retail is huge. However, today the barriers to entry for retailers in such solutions are still quite high. For example, setting up a robotic system to support store employees requires a lot of expert knowledge and customized, expensive hardware. The idea of the K4R platform is to reduce these barriers to entry by providing retailers with the infrastructure and general-purpose AI functionalities. By centralizing AI approaches such as planning, reasoning, or machine learning in the K4R platform, it is possible to integrate commercially available robotic systems such as MARLIN into complex AI applications or even orchestrate entire fleets of AGVs. In this context, a possible extension of our work is to simultaneously use multiple robots for store intralogistics, for example by implementing a similar approach as in [42] or scheduling methods as described in [43]. Moreover, integrating different sensor sources, e.g., cameras to monitor the flow of customers, into the planning system can improve the reliability and speed of autonomous navigation in crowded stores. Finally, we would like to evaluate the proposed solution in a large-scale subject study (i.e., with store employees) to obtain realistic statements on usability and feasibility."}]}