{"title": "Temporal Graph Memory Networks For Knowledge Tracing", "authors": ["Seif Gad", "Sherif Abdelfattah", "Ghodai Abdelrahman"], "abstract": "Abstract-Tracing a student's knowledge growth given the past exercise answering is a vital objective in automatic tutoring systems to customize the learning experience. Yet, achieving this objective is a non-trivial task as it involves modeling the knowledge state across multiple knowledge components (KCs) while considering their temporal and relational dynamics during the learning process. Knowledge tracing methods have tackled this task by either modeling KCs' temporal dynamics using recurrent models or relational dynamics across KCs and questions using graph models. Albeit, there is a lack of methods that could learn joint embedding between relational and temporal dynamics of the task. Moreover, many methods that count for the impact of a student's forgetting behavior during the learning process use hand-crafted features, limiting their generalization on different scenarios. In this paper, we propose a novel method that jointly models the relational and temporal dynamics of the knowledge state using a deep temporal graph memory network. In addition, we propose a generic technique for representing a student's forgetting behavior using temporal decay constraints on the graph memory module. We demonstrate the effectiveness of our proposed method using multiple knowledge tracing benchmarks while comparing it to state-of-the-art methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Teaching has always been a vital skill for the human race to transfer knowledge from one generation to another. During a teaching procedure, a human teacher would utilize their domain knowledge about the subject and its underlying learning concepts to customize the learning experience for individual students based on their knowledge progress. Such a customization process demands a continuous tracing of a student's knowledge growth using probing means such as asking questions. Yet this begs the question: Could a computational model trace a student's knowledge growth given their exercise answering history? The knowledge tracing (KT) problem aims at answering such a question [1], [2] to accurately predict the probability of correctly answering a recent question given the past exercise answering history and information on relationships between questions and knowledge components (KCs) (i.e., learning concepts) in a subject.\nTo further clarify the semantics of a KT context and the complexity of their dynamics, we provide an illustrative example in Figure 1. At the top level, we have time steps representing the temporal nature of the KT problem. The second level depicts a student's latent knowledge state as a KC-KC relationship graph with four unique KCs in the example task. We note that a knowledge state for each KC could temporarily fluctuate over multiple values, including rising, steady, or declining. Another factor that impacts the knowledge state for each KC is the student's forgetting behavior, which is described as a temporal memory decay effect [3]\u2013[6] usually governed by a KC practice frequency. Forgetting behavior, represented by gauges in the second level, and relationships between KCs and questions govern the knowledge state dynamics. For example, correctly answering 91 directly impacts knowledge and forgetting states of concepts (c\u00b9, c4) and indirectly impacts their related concepts (c\u00b2, c\u00b3). Addressing the KT problem involves multiple challenges, including 1) modeling knowledge state dynamics across multiple KCs, 2) counting for a student's forgetting behavior impact on predicting the knowledge state, and 3) effectively capturing the relationships between questions and KCs during the knowledge state modeling.\nThere have been many attempts to tackle the KT problem from a computational modeling perspective. Statistical approaches [1], [7]\u2013[10] followed Bayesian estimation techniques to quantify the probability of correctly answering a given question. However, they usually tend to oversimplify the problem representation (e.g., assuming only one KC in the task) for a tractable posterior computation. Alternatively, deep learning (DL) approaches [11], [12] benefit from recent advances in deep neural networks [13]\u2013[15] to embrace more realistic assumptions (e.g., multiple KCs and KCs-questions dependencies) of the KT problem. The DL approaches could be generally decomposed into two broad categories depending on the type of deep models utilized, including deep sequence models [11], [12], [16]\u2013[18] and deep graph models [19], [20]."}, {"title": "II. THE KNOWLEDGE TRACING PROBLEM", "content": "The knowledge tracing problem could be formulated as given a set of questions $Q = \\{q_1, q_2, ..., q_N\\}$, a set of knowledge components (KCS) $C = \\{c_1, c_2, ..., c_N\\}$, the relationships between questions and KCs as a bipartite graph $G = (Q, C, E)$ where E denotes the edges of the graph, and a student's exercise practice history represented as sequence $X = (\\{q_1, a_1\\}, \\{q_2, a_2\\},..., \\{q_{t\u22121}, a_{t\u22121}\\})$, where $q_j \u2208 Q$ and $a_j \u2208 \\{0, 1\\}$, we seek to predict the probability of correctly answering the question at the current time step $q_t$ defined as $p(a_t = 1|q_t, X, G)$.\nWe assume that the ability of a student to answer a given question correctly is governed by a latent mastery state $m_t \u2208 \\mathbb{R}^{d_m}$, where $d_m$ is the dimension of the state. The mastery state $m_t$ could be estimated via a parametric model given information in a KT context $E_w: q_t, X, G \\rightarrow m_t$, where w is the parameter set of the state estimator E. Assuming that the state $m_t$ encapsulates all the relevant information from the graph G and the exercise sequence X, we re-formulate the prediction objective to be conditioned on the question tag $q_t$ and the state $m_t$ as $p(a_t = 1|q_t, m_t)$. Our optimization objective to tackle the KT problem is as follows:\n$\\arg \\min_{\\theta \\in \\Theta, \\omega \\in \\Omega} L(a_t, F_{\\theta}(q_t, E_{\\omega}(q_t, X, G)))$   (1)\nwhere L is a prediction loss function, $F_{\\theta}: q_t, m_t \\rightarrow \\hat{a}_t$, $\\hat{a}_t E \\{0,1\\}$ is an answer prediction model parametrized with \u03b8, \u0398 is the parameter search space for $F_{\\theta}$, and \u03a9 is the parameter search space for $E_{\\omega}$."}, {"title": "III. PROPOSED METHOD", "content": "In this section, we introduce the details of our temporal graph memory network (TGMN) model for knowledge tracing. Specifically, five main building blocks are involved: the temporal graph key-value memory, a key-value graph convolution network (GCN), the sequence context memory cell, the answer prediction head, and the memory update module. Figure 2 depicts a block diagram for the proposed model. The temporal graph memory stores a student's knowledge state over existing KCs in the task across multiple answering sessions, forming a long-term knowledge context where each node represents key-value embeddings for a KC. A key embedding is static and reflects the identity of a KC; we show later in Section III-A an effective way to learn such key embeddings following a self-supervised learning objective, whereas the value embedding is dynamic and represents the knowledge mastery level for a KC. We learn value embeddings in an end-to-end manner with the answer prediction task.\nGiven a new question qt, we address the temporal graph memory by attending the question's key embedding with KC key embeddings to generate a KC relevancy vector wt. Similar to the KC key embeddings, we show in Section III-A our way of learning question key embeddings in a self-supervised learning manner. The key-value graph convolution network extracts the relevant knowledge state aspects to qt into a read vector rt by leveraging spatiotemporal features from the temporal graph memory while attending to the relevancy vector wt. We count for short-term dynamics in the knowledge state within the current answering session by feeding the mastery states of past questions weighted by their relevancy to qt into the sequence context memory cell to output the sequence context vector ht. Afterward, we concatenate the read vector rt representing the long-term context with the short-term context ht to form the combined mastery state mt of qt. We input me to a feed-forward prediction head to predict the correct answer probability at. Finally, we update"}, {"title": "A. Learning Question-KC Embedding Spa\u0441e", "content": "Many KT datasets provide relationships between questions q and KCs in a form that a bipartite graph could represent. We exploit this given information through a self-supervised objective to learn effective representations for questions and KCs. Given a bipartite KC-question graph, we target predicting the distance between two nodes from the same type (e.g., questions) represented by the number of hops over the other type (e.g., KCs). The assumption behind this objective is that a good node representation shall effectively capture similarities between nodes quantified by the number of hops separating them apart in the graph.\nAs shown in Figure 3, the input to our embedding learning model is either one-hot encodings for two sample nodes from the same type in the case of KT datasets that do not share"}, {"title": "B. Temporal Graph Key-Value Memory", "content": "The temporal graph key-value memory module aims to capture the spatiotemporal dynamics between existent KCs through key-value representations. For the rest of this paper, we call that memory module TGM, while we refer to our whole model, including all the five building blocks, as TGMN. The key embeddings $M_k \u2208 \\mathbb{R}^{N\u00d7d_k}$ are pre-trained to reflect the identity of KCs and their mutual relationships based on the question-KC bipartite graph. The value embeddings $M_v \u2208 \\mathbb{R}^{N\u00d7d_v}$ represent the latest mastery state for each KC, and they are updated by observing the exercise answering sequence. Thus, our TGM forms a relational memory that captures the history of the exercise answering sequence and relationships between KCs as key similarity edges. Extracting information from the memory module is performed by two procedures including addressing and reading. We detail each of them as follows.\nMemory Addressing to read knowledge mastery features relevant to a given question qt, we perform associative addressing to the TGM by calculating relevancy read vector wt using the following equation:\n$w_t(i) = \\frac{exp(k_{qt}^T k_{c_i}) /\\tau}{\\sum_{i=1}^N exp(k_{qt}^T k_{c_i}) / \\tau}, \\forall i \u2208 [1, N]$ (2)\nwhere $k_{qt}$ is the key embedding of the question at time t, $k_{c_i}$ is the key embedding of KC $c_i$, \u03c4\u2208 [0, 1] is a temperature pa- rameter controlling the sharpness of the Softmax distribution, and N is the total number of KCs.\nMemory Reading we read relevant knowledge state aspects of qt from the current temporal graph memory Gt using a key-value GCN module while attending to the relevancy read vector wt. This module extends the aggregation calculations in conventional GCNs [27] by considering KC keys to calculate soft edges as self-attention weights between nodes. Instead of using a fixed adjacency as in the traditional GCN case, we use a dynamic adjacency matrix represented by the self-attention matrix [28], [29]. We note that the KC keys matrix Mk is initialized via the KC embedding pretraining stage and remains static. In contrast, the queries matrix M \u2208 RN\u00d7dq is dynamic and learned in an end-to-end manner with the answer prediction objective to compensate for the personal aspects of each student. The adjacency matrix at time point t is calculated as follows:\n$A_t = Softmax(\\frac{MM^T}{\\sqrt{d_k}})$  (3)\nwhere $\\sqrt{d_k}$ is the normalization factor quantified by the square root of dimensions of the key vector.\nAfterward, we distill a read vector from the TGM using a variant of graph convolution operation [27] that attends node embeddings on the relevancy read vector wt before aggregation as follows:\n$H^{i+1} = ReLU(\\tilde{D}^{-{1 \\over 2}} \\tilde{A} \\tilde{D}^{-{1 \\over 2}} \\tilde{H}^{i}W^{i})$  (4)\nwhere ReLU(x) = max(0,x) is a non-linear activation function, D is the diagonal degree matrix calculated after"}, {"title": "C. Exercise Sequence Context Estimation", "content": "Our model's design assumes two forms of context to robustly estimate a question's mastery state, including long-term context (i.e., persists across time windows for the same student) represented by the TGM's read vector rt and a short-term context (i.e., resets across time windows for the same student) distilled from the exercise answering sequence in the current session represented by $h_t \u2208 \\mathbb{R}^{d_v}$.\nTo count for the exercise sequence context, we sequentially feed the mastery states of previous questions in the exercise sequence weighted by their relevancy to question qt to a gated recurrent unit (GRU) to get the sequence context ht for qt. We first calculate the sequence relevancy vector ot as follows:\n$O_t(i) = \\frac{exp(k_{qt}^T k_{q^i}) /\\tau}{\\sum_{i=1}^S exp(k_{qt}^T k_{q^i}) /\\tau}, \\forall i \u2208 [1, S]$   (6)\nwhere $k_{qt}$ is the key embedding of the question at time t, $k_{q^i}$ is the key embedding of question $q^i$, \u03c4\u2208 [0,1] is a temperature parameter controlling the sharpness of the Softmax distribution, and S is the max time window length for questions to consider in the past exercise sequence. We report our empirical value for S in Section V.\nThen, we calculate the sequence context ht as follows:\n$h_t = GRU((o_t(i)U(i))_{i=1}^S)$  (7)\nwhere $U = (u_t)_{i=1}^S$ is the sequence of past question mastery states encoded by their answer status (see Eq. 10)."}, {"title": "D. Answer Prediction", "content": "To predict the correct answer probability for question qt, we concatenate long and short-term contexts to form the question mastery state $m_t = concat(r_t,h_t)$, then, we feed mt to a feed-forward answer prediction head to get the correct answer probability $\\hat{a}_t \u2208 [0,1]$.\n$\\hat{a}_t = \u03c3(W\u00b7m_t + b)$  (8)"}, {"title": "E. Memory Update", "content": "After answer prediction, we update the TGM value embeddings Mu representing the student's mastery level for each KC guided by the recent mastery state mt, the status of answer prediction (\u00e2t, at), and the current relevancy vector wt. We represent the answer prediction status as one of four possible values based on the viable binary values for (\u00e2t, at) including {(1, 1), (1, 0), (0,1), (0,0)}, with 1 for correct answer and 0 for incorrect answer. Accordingly, we use a static encoding matrix $A \u2208 \\mathbb{R}^{4\u00d7d_k}$ to encode each answer status value and add the corresponding status vector to me in a similar fashion of positional encoding in transformers [28] to formulate the update vector ut.\n$u_t = A[(\\hat{a}_t, a_t)] + m_t$  (10)\nWe follow an associative memory update procedure [30] involving learnable erase and update gates; the former is responsible for erasing parts no longer relevant from memory, while the latter adds new important information. Only the value matrix Mt of the TGM is updated after each time step to track changes in each KC's mastery state. Equations for the erase et and add zt signals are as follows:\n$e_t = \u03c3(W_e \u00b7 u_t + b_e)$  (11)\n$z_t = Tanh(W_z.u_t + b_z)$  (12)\nwhere We, Wz, be, and bz are learnable weight matrices and bias vectors for erase and add signals, respectively.\nGiven the erase and add signal vectors, we utilize them to update the KC value embedding matrix Mv for the next time step $M_v^{t+1}$ as follows:\n$M_v^{t+1}(i) = M_v^t(i)[1 \u2013 w_t(i)e_t] + w_t(i)z_t$  (13)\nTo count for a student's forgetting behavior [4], we in-troduce a memory temporal decay mechanism that relies on question-KC relevancy in the exercise sequence inspired by the potential of memory decay approaches [23] to deal with long-term dynamics in sequences. Relevant forgetting-robust KT methods [3], [22] depend on hand-crafted features to represent a student's forgetting behavior. While effective, such representation might not generalize well from one scenario to another in addition to the need to model additional features besides ones imposed by the answer prediction objective."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we present the experimental design to evaluate the effectiveness of our TGMN model, aiming to address the following research questions:\nRQ1: How does our proposed TGMN model compare to the state-of-the-art KT models on well-established KT benchmarks?\nRQ2: What is the impact of different building blocks in our proposed model on its performance?\nRQ3: To what extent does the pre-training procedure enhance embedding quality for questions and KCs? How does it"}, {"title": "A. Datasets", "content": "ASSISTments2009\u00b2: This dataset sourced from the AS-SISTments online education platform in 2009 \u2212 2010, comprises 110 unique school mathematics questions. It involved 4,151 students, generating a dataset with 325, 637 question-answer pairs spanning 110 KCs rep-resenting diverse mathematical concepts.\nStatics2011\u00b3: This dataset sourced from a 2011 engi-neering course at Carnegie Mellon University, features responses from 333 students to a distinct set of 1,223 questions. With 189, 297 exercises, including questions and corresponding answers, the dataset addresses 85 KCs related to diverse engineering topics.\nSynthetic-5\u2074: This dataset was created by the authors of DKT [11], simulates a learning experience with 4,000 student agents responding to 50 unique questions. This simulation results in 200,000 exercises compris-ing question-answer pairs, and the dataset is structured around 5 KCs representing underlying knowledge do-mains or topics within the learning material.\nKddcup2010\u2075: This dataset is derived from an alge-bra course conducted on the Cognitive Algebra Tutor system [32] during 2005 \u2212 2006, includes 436 unique questions answered by 575 students. With a total of 607,026 exercises, encompassing both questions and their corresponding answers, the dataset encompasses 112 KCs representing a variety of algebraic topics covered in course.\nEedi\u2076: This dataset released for the NeurIPS Education Challenge in 2021 [33] is a comprehensive collection of mathematics question logs. The dataset contains 27,613 unique questions and was completed by 118,971 partic-ipating students, resulting in a collection of 15,867, 850 question and answer pairs and 388 KCs."}, {"title": "B. Answer Prediction Performance Evaluation", "content": "This experiment answers the research question RQ1 by contrasting the performance of our TGMN model with the state-of-the-art KT models on six well-established datasets in the KT literature over five independent runs. The KT models for comparison cover both sequence-based and graph-based KT methods, including:\nAt-DKT [18]: This model extends the DKT [11] model with two auxiliary tasks to predict the related KCs for a given question and its past mastery state.\nSKVMN [16]: This model utilizes a key-value mem-ory and Hop-LSTM to capture sequential dependencies among questions in a sequence of interactions. This approach allows the model to update students' knowledge based on their responses to relevant questions.\nSAKT [35]: This model follows an attention mecha-nism [36] to focus on the most relevant parts of the student's sequence of interactions and give them higher weight during the prediction process.\nAKT [17]: This model combines an attention model with Rasch model-based embeddings. The attention mecha-nism assigns weights to the questions in a sequence, indicating their importance for predicting the current question. Additionally, the attention weights are expo-nentially decayed based on the distance between the questions in the sequence.\nGKT [19]: This model incorporates a graph neural net-work (GNN) to extract information that captures depen-dencies across questions. A graph neural network is a neural network specifically designed to operate on graph-structured data.\nSKT [20]: This model aims to capture multiple KCs relations, including similarity and prerequisite relations. Incorporating these relations into the model seeks to capture the interdependencies and connections between different KCS.\nGIKT [21]: This model utilizes the relationship between questions and KCs, represented as a graph structure, to learn effective embeddings for answer prediction and to capture the connections and interactions between ques-tions and the corresponding KCs.\nDGMN [22]: This model creates a dynamic graph to represent relationships between KCs and represents for-getting behavior throughout a KC, which has the benefit of capturing inverse correlations between questions.\nPEBG [37]: This model emphasizes the acquisition of pre-trained exercise embeddings to improve the accuracy"}, {"title": "C. Ablation Study", "content": "We conduct an ablation study to answer the research ques-tion RQ2. We compare different variants of our TGMN model to evaluate the impact of different building blocks on its performance. These variants are as follows:\nBase: This variant only includes a basic Temporal Graph Memory without using Sequence Context, Memory De-cay, and Answer Encoding modules.\nTGM-SC: This variant includes a basic Temporal Graph Memory and Sequence Context without using Memory Decay and Answer Encoding modules.\nTGM-F: This variant includes a basic Temporal Graph Memory, Sequence Context, and Memory Decay without using the Answer Encoding module.\nTGMN: This variant includes all the components of TGMN.\nTable III summarizes the average accuracy results for dif-ferent variants of the TGMN model. Based on Table III, we have the following findings:\n(1) The impact of the Sequence Context module can be observed by comparing Base and TGM-SC. A statistically significant (p-value< 0.05) performance enhancement by a margin of 1.8%, 1.5%, 1.2%, 1.4%, 1.3% and 1.2% is achieved for ASSISTments2009, Statics2011, Synthetic-5, Kddcup2010, Eedi, and DBE-KT22, respectively.\n(2) The impact of the Memory Decay module can be ob-served by comparing TGM-SC with TGM-F. A signif-icant performance margin of 2.0%, 1.4%, 2.4%, 2.0%, 0.9%, and 0.9% exists between these two models for AS-SISTments2009, Statics2011, Synthetic-5, Kddcup2010, Eedi, and DBE-KT22, respectively.\n(3) The impact of using an Answer Encoding on the perfor-mance can be seen by comparing TGM-F against TGMN. Significant performance margins of 2.0%, 2.1%, 1.3%, 1.8%, 1.4%, and 1.8% are obtained by DGMN-Basic for datasets ASSISTments2009, Statics2011, Synthetic-5, Kddcup2010, Eedi, and DBE-KT22, respectively"}, {"title": "D. Embedding Quality Analysis", "content": "In this experiment, we answer RQ3 by performing a training time performance comparison across four TGMN variants, each using a different embedding initialization. This design assumes that effective embedding initialization will result in better training performance and faster convergence than infe-rior ones. In this experiment, we utilize the DBE-KT22 [34] dataset for question and KC text information availability. The four variants are as follows:\nText+PT: this variant initializes question and KC embed-ding using the BERT [28] language model embeddings"}, {"title": "E. Complexity Analysis", "content": "To answer the research question RQ4, we asymptotically calculate the time and space computational complexity for sample sequence-based models, graph-based models, hybrid models, and our proposed TGMN model. Table IV compares training computational and memory complexity for a subset of KT models with the TGMN model. |Q| refers to the total number of questions, v is the input embedding dimension, S is the input sequence length, N is the total number of KCs,"}, {"title": "V. IMPLEMENTATION DETAILS", "content": "In this section, we present the details of implementing our TGMN model. For the embedding learning model, we use a three-layer feed-forward neural network with a ReLU activation for the hidden layers and a liner activation at the final layer for the number of hops prediction head. For the backbone, we either use a frozen BERT model if text"}, {"title": "VI. RELATED WORK", "content": "The Knowledge Tracing (KT) literature could be generally categorized based on the type of context used for answer prediction. We identify three different context types: temporal context from the past exercise answering sequence, structural context from graphs representing relationships between questions and KCs, and hybrid contexts combining temporal and structural data via different fusion techniques. We explore each of those categories as follows."}, {"title": "A. KT Methods Using Temporal Context", "content": "One of the early attempts to use deep neural networks for modeling the temporal context in the KT problem was the DKT [11] model. At its core, DKT uses a recurrent neural network (RNN) to memorize important information from the past exercise answering sequence representing the knowledge state for answer prediction. Inspired by attention methods [28], [36], the DKVMN [12] model uses a key-value memory to store embeddings and knowledge state dynamics for multiple KCs. Answer prediction is achieved by attending question embeddings on the key-value memory content, which significantly enhances the prediction performance compared to the vanilla RNN used by the DKT model [11]. The Sequential Key-Value Memory Networks (SKVMN) [16] extended on the DKVMN model by adding a hop-LSTM layer above the key-value memory to aggregate the temporal context of related questions in the exercise answering sequence during answering prediction. Building on the Transformer architecture [28], various studies [17], [35], [41] have explored integrating attention mechanisms into KT models. Despite differences in their implementations, these studies share a core objective: to determine the attention weights of questions within a sequence of interactions, thereby reflecting their relative importance in predicting the likelihood of correctly answering the next question. This approach addresses a limitation of DKT, which assumes all questions in a sequence are equally significant."}, {"title": "B. KT Methods Using Structural Context", "content": "The structural context in KT tasks typically includes various relationships, such as the dependencies between knowledge components (KCs) and the connections between questions and their associated KCs. Graph-based KT methods aim to exploit this context to enhance answer prediction. The Graph Knowl-edge Tracing (GKT) [19] model used a GNN [42] network to aggregate the structural context from the question-KC graph for answer prediction. The Structure-based Knowledge Tracing (SKT) [20] model extended on GKT [19] by assuming a dy-namic graph structure where question-KC relationships could change over time and used Gated Recurrent Unit (GRUs) [43] memory to store temporal structural changes. The Pre-training Embeddings via Bipartite Graph (PEBG) [37] model focused on learning effective question embeddings by designing pre-training objectives on side information like question difficulty and relationships between questions and KCs represented by a bipartite graph. More specifically, the PEBG method follows contrastive learning [44] objectives to identify question similarities and KC similarities along with question-KC edge prediction. The authors showed that using such pre-training could significantly enhance existing models such as DKT [11] and DKVMN [12]."}, {"title": "C. KT Methods Using Hybrid Context", "content": "Utilizing both temporal and structural contexts in the KT problem facilitates mitigating information gaps in each of them and enhances the overall performance. Exploiting this fact, multiple KT methods aimed at proposing novel fusion approaches for combining structural and temporal information in the KT domain. The Graph-based Interaction Knowledge-Tracing (GIKT) [21] model combined multiple ideas, such as using RNNs as in the DKT [11] model, aggregating informa-tion from relevant questions in the past exercise sequence as in the SKVMN [16] model, and using graph neural networks as in the GKT [19] model. GIKT inference workflow goes as follows: firstly, a graph convolution network (GCN) [27] is used to aggregate question embeddings from the question-KC graph to form the structural context; then, related question embeddings in the answering sequence are combined using an RNN to formulate a combined temporal and structural context. Comparison against temporal-only and structural-only KT models showed a significant performance edge for the GIKT model. The Deep Graph Memory Network (DGMN) [22] is considered to be the state-of-the-art in the hybrid context approaches as it not only provides a novel way of fusing structural and temporal contexts but also counts for student forgetting behavior [4] during the answer prediction. Similar to key-value memory approaches [12], [16], the DGMN utilizes a key-value memory for capturing the temporal context from the past answering sequence, but it employs this memory to au-tomatically build a KC-KC graph capturing structural context between involved KCs. The temporal context is fused with the structural one via a forget gate that explicitly models the stu-dent's forgetting features in terms of KC practice frequencies. One common drawback of these hybrid models is keeping separate representations for temporal and structural contexts and fusing them at a later stage. In contrast, our DGMN model utilizes a unified representation that captures joint embedding for structural and temporal information, which reduces its memory fingerprint and enhances the fusion quality."}, {"title": "VII. CONCLUSION", "content": "In this work, we introduced a novel knowledge tracing model named temporal graph memory networks (TGMNs), capable of learning a unified representation for exercise an-swering context and KC-KC structural relationships context for an accurate answer prediction. Moreover, we count for the impact of a student's forgetting behavior during the answer prediction via a generic temporal memory decay technique without dependency on handcrafted forgetting features. Ex-perimental results comparing the state-of-the-art KT models across multiple datasets showed a significant performance edge for the TGMN model. In addition, we performed an ablation study to assess the impact of each building block in our pro-posed model. Future work directions include exploring other ways to effectively distill information from the temporal graph memory, such as relational transformer architectures [45] and learning with both supervised (e.g., answer prediction) and self-supervised objectives (e.g., mutual information maximiza-tion based on structural priors) during the answer prediction to enhance the knowledge tracing performance."}]}