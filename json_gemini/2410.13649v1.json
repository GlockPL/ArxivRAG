{"title": "A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks", "authors": ["Tianyi Zhang", "Atta Norouzian", "Aanchan Mohan", "Frederick Ducatelle"], "abstract": "In virtual assistant (VA) systems it is important to reject or redirect user queries that fall out-side the scope of the system. One of the most accurate approaches for out-of-scope (OOS) rejection is to combine it with the task of in-tent classification on in-scope queries, and to use methods based on the similarity of embed-dings produced by transformer-based sentence encoders. Typically, such encoders are fine-tuned for the intent-classification task, using cross-entropy loss. Recent work has shown that while this produces suitable embeddings for the intent-classification task, it also tends to disperse in-scope embeddings over the full sentence embedding space. This causes the in-scope embeddings to potentially overlap with OOS embeddings, thereby making OOS rejec-tion difficult. This is compounded when OOS data is unknown. To mitigate this issue our work proposes to regularize the cross-entropy loss with an in-scope embedding reconstruction loss learned using an auto-encoder. Our method achieves a 1-4% improvement in the area under the precision-recall curve for rejecting out-of-sample (OOS) instances, without compromis-ing intent classification performance.", "sections": [{"title": "Introduction", "content": "Virtual assistant (VA) systems often can handle only a limited scope of intents. Out-of-scope (OOS) rejection refers to the ability of a VA to identify and reject incoming queries that are outside its scope. This is a difficult (Fang et al., 2023) and increasingly important task in many scenarios. Our work is inspired by VAs in cars, which nowadays often operate in a hybrid mode where processing of certain user requests is handled locally, while others are transmitted to the cloud for response retrieval. Responding to users' requests using on-device/embedded models is cost-effective, quick, and, importantly, can safeguard sensitive informa-tion. Cloud models on the other hand are typically much bigger and can respond to a wider range of queries. In such a setting, it is important that the on-device natural language understanding (NLU) models not only identify user queries for intents that are in-scope but also accurately detect out-of-scope input so that they can be either routed to the cloud or ignored. Another important use case for OOS rejection is the combination of a light-weight, specialized VA that works tandem with large lan-guage models (LLMs) for free conversation with the user. Similar to the in-car use case, the special-ized VA can be run before the LLM and capture a subset of the incoming queries. This increases cost-effectiveness and controllability of the full so-lution, provided that it has good OOS rejection capabilities.\nThe most common approach for intent classi-fication while rejecting OOS samples is based on first generating an encoding for the sentences (Hendrycks et al., 2020; Podolskiy et al., 2021) and then performing classification on them. In both (Hendrycks et al., 2020) and (Podolskiy et al., 2021) it was shown that the most suitable sentence encoders for this purpose are transformer-based encoders. Based on the task's domain, one could use one of the several sentence encoders available in the HuggingFace sentence transformer library 1. Fine-tuning sentence encoders on the domain-specific data leads to better intent classification ac-curacy. This fine-tuning typically is performed by applying a softmax to the sentence embeddings. At test time, the same softmax layer could be used to perform intent classification, however, the softmax tends to produce over-confident predictions even for OOS samples (Dhamija et al., 2018; Hendrycks and Gimpel, 2018). Hence, after fine-tuning, the softmax layer is removed from the model and other"}, {"title": "Related Work", "content": "There are largely two categories of approaches for detecting OOS samples when performing intent-classification. The first category is based on ex-plicitly teaching the model to distinguish between in-scope and OOS samples by introducing OOS samples during training. This is done by adding an extra OOS class to the classifier (Larson et al., 2019; Qian et al., 2022; Choi et al., 2021; Zhan et al., 2021) or by adding an auxiliary loss func-tion to the cross entropy loss to enforce the model to output a uniform probability distribution over in-scope classes when dealing with OOS samples (Zheng et al., 2020). These approaches only work if the OOS test samples are drawn from a distribu-tion similar to that of the OOS training samples. In (Fang et al., 2023) the authors prove mathemat-ically that it is not possible to detect samples out-side of known distributions unless some conditions are met. This means for robust detection of OOS samples, the training OOS test samples have to represent a wide variety of possible distributions. While collecting such training samples is not feasi-ble, synthesizing OOS samples using models like GANs (Ryu et al., 2018; Lee et al., 2018) and man-ifold learning (Goyal et al., 2020; Bhattacharya et al., 2023) have shown promise to make the deci-sion boundary around in-system training samples as tight as possible.\nThe second category consists of approaches that rely only on in-scope training data without mak-ing any assumption about the OOS class. These approaches are largely based on sentence embed-dings. Sentence embeddings generated by trans-former encoders are shown to perform better than the ones generated using traditional NLU models (Hendrycks et al., 2020; Podolskiy et al., 2021). The classification of sentence embeddings into in-scope intent classes and into in-scope versus OOS could be done using non-parametric methods such as KNN (Zhou et al., 2022) or density based meth-ods (Chen et al., 2023; Ren et al., 2021; Xu et al., 2020). There is a trade-off between the model foot-print and its accuracy when it comes to choosing be-tween parametric and non-parametric approaches. Due to constraints on the size of the model put in the car we chose the parametric approach based on the Mahalanobis distance.\nThe sentence embeddings could be generated using pretrained sentence transformers (Hendrycks et al., 2020) but fine-tuning the encoder for the task at hand provides more suitable embeddings (Dar-rin et al., 2024; Zhou et al., 2021; Barnabo et al., 2023; Zhou et al., 2022). The work in (Zhou et al., 2021) highlights that while fine-tuning based on cross-entropy loss effectively separates sentence embeddings of different intent classes, it struggles to differentiate between in-scope samples and OOS samples. In that paper, this issue is tackled by adding a secondary loss function to the fine-tuning based on contrastive loss. The contrastive loss in-creases the distance between intent classes in the embedding space while reducing the distance be-tween embeddings of the same intent class. How-ever, since this loss tries to push the in-scope intent classes as far as possible from each other, the intent classes could start overlapping with OOS samples in the embedding space. Our approach inspired by the one-class classification in (Ruff et al., 2018) tries to reduce the dispersion of the in-scope intent classes in the embedding space by replacing the contrastive loss with reconstruction loss obtained using an autoencoder."}, {"title": "Methodology", "content": "This section discusses the details of our modelling formalism. Sub-section 3.1 talks about our train-ing cost-function(s), whereas sub-section 3.3 talks about our inference methodology."}, {"title": "Model Fine-tuning", "content": "Let $s^i$ denote the d dimensional sentence embedding of the ith training sample generated after pooling the out-put of the transformer encoder. Here we use $y^i$ to denote a C dimensional one-hot vector associating ith input to one of C in-scope intents. The jth ele-ment of $y$ namely $y_j^i$ is equal to 1 if and only if $s^i$ belongs to the jth class where $j \\in \\{1, ..., C\\'\\}$. In the baseline fine-tuning approach, a softmax layer is applied to $s^i$ to map it to $e^i$, a C-dimensional vector of probabilities. The cross-entropy loss $L_{CE}^i$ of the ith training example is then calculated as:\n$L_{CE}^i = \\sum_{j=1}^C y_j^i log(e_j^i)$                    (1)\nIn the proposed fine-tuning approach, the sentence embedding $s^i$ is passed to a second head which is comprised of an autoencoder network. The au-toencoder reconstructs the embedding as $r^i$. The reconstruction loss computed using mean-squared error is calculated as:\n$L_{AE}^i = \\frac{1}{d} \\sum_{k=1}^d (s_k^i - r_k^i)^2$                  (2)\nThe architecture of the model along with the size of the layers of the autoencoder head are provided in Section 4.1. The final loss is calculated as follows weighted sum of the two losses described above as\n$L^i = (1 - \\alpha)L_{CE}^i + \\alpha L_{AE}^i$               (3)\nHere $\\alpha$ tuned as a hyperparameter allows us to control the contribution of the individual losses towards the final loss."}, {"title": "Class-based Mean and Covariance Calculation", "content": "After training, the autoencoder and the softmax heads are discarded. The transformer encoder trained with Eq. (3) as the cost function is then primarily used for extracting sentence embeddings. Sentence embeddings using this transformer en-coder are then generated for each training sample belonging to one of the C in-scope intent classes. These per-class sentence embeddings are then used to construct a set of C mean-vectors $\\mu_j$ where $j \\in 1,..., C$. All of the training set sentence em-beddings for the C classes are then used to calcu-late a universal covariance matrix $\\Sigma$."}, {"title": "Classification and Inference", "content": "For an incoming query q, if $s^q$ is its corresponding sentence embedding, then the class-specific Maha-lanobis distance $d_j$ is calculated as follows:\n$d_j (s^q) = \\sqrt{(s^q - \\mu_j)^T \\Sigma^{-1}(s^q - \\mu_j)}$             (4)\nOnce the distances are calculated, a minimum dis-tance $d_{min} (s^q)$ and the index $C_{min} (s^q)$ of the can-didate centroid is picked as follows.\n$d_{min} (s^q) = min_j d_j (s^q)$                   (5)\n$C_{min} (s^q) = arg min_j d_j (s^q)$                    (6)\nThe quantity $d_{min} (s^q)$ is then compared to a thresh-old T to determine if the query q is in-scope or out-of-scope. This threshold is a hyper-parameter and is set empirically. If the query q is determined to be in-scope then $C_{min}(s^q)$ is picked as the candi-date class. This method of using a soft-max during training, but using the Mahalanobis distance dur-ing inference for classification is consistent with previous work (Podolskiy et al., 2021; Ren et al., 2021)."}, {"title": "Experimental Setup", "content": "This section talks about our experimental setup. The main objectives of our experimental setup is to evaluate the capability of our proposed fine-tuning approach to improve the model's ability to detect OOS queries robustly while maintaining in-scope intents classification accuracy."}, {"title": "Sentence-encoder Configuration", "content": "The bert-base-uncased (Devlin et al., 2018) model followed by maxpooling was used to ex-tract sentence embeddings. Sentence embeddings from the transformer sentence encoder have dimen-sionality d = 768. As shown in Figure 1 these embeddings pass through an autoencoder with a six-layer architecture designed to compress and reconstruct the sentence embeddings. The first 3 layers in the autoencoder reduce the data dimen-sionality from 768 to 512, 512 to 64, and finally from 64 to a 16-dimensional bottleneck. The subse-quent 3 layers reconstruct the sentence embedding back to its dimensionality of d = 768. The trans-former sentence-encoder is then trained using the objective function stated in Eq. (3). The errors are backpropagated from both heads back to the transformer sentence encoder. All layers of the transformer encoder model were fine-tuned."}, {"title": "Hyperparameter Optimization and Training", "content": "The training was found to be sensitive to the auto-encoder weight parameter a. For this reason grid search was conducted for $\\alpha$ with the following values [0.01, 0.1, 0.2, 0.5, 0.9]. The learning rate, batch size and no. of epochs were kept constant. It was found across the different validation sets that the optimal value for $\\alpha = 0.1$. The performance started to deteriorate drastically for higher values of a.\nThe autoencoder weight a was then kept fixed for further hyperparameter optimization. Our work uses an open source hyperparameter optimization framework called Optuna (Akiba et al., 2019). Learning rates between 1 \u00d7 10-3 and 5 \u00d7 10-5 were explored using a logarithmic scale to priori-tize smaller increments closer to the lower end of the spectrum, as transformer models often benefit from precise adjustments in learning rates. The number of training epochs ranged from 5 to 50. Batch size values were explored between 16, 32, 64, 128, 256, 512. The exact values for hyperpa-rameters for each dataset appear in Appendix A.2."}, {"title": "Evaluation Metrics", "content": "The primary metric for assessing the effectiveness of our OOS detection was the Area Under the Precision-Recall curve (AUPR). It is important to mention that we label OOS samples as positive and in-scope samples as negative and hence we report AUPRood which signifies that. This metric is particularly suitable for comparing two binary classifiers when the test data is imbalanced like those with a high proportion of in-scope queries compared to OOS queries. The second metric is used is Area Under the ROC curve (AUROC). Our work additionally looks at the intent classification accuracy. This is important as our goal is to im-prove OOS rejection while maintaining in-scope intent classification accuracy."}, {"title": "Datasets", "content": "CLINC150 Dataset: The CLINC150 dataset (mis, 2020) is a benchmark dataset for evaluating natural language understanding systems particularly in the context of intent and slot filling tasks. The data set comprises 150 intent classes with an extra class la-beled as out-of-scope. The training data consists of 15,000 examples with 100 examples per intent. The out-of-scope intent was not used in training. The validation data consists of 3,000 examples with 20 examples per intent. The test data consists of 4,500 examples with 30 examples per intent. The data spans across 10 diverse domains, such as banking, credit cards, kitchen appliances making it compre-hensive for real-world scenarios. Each data sample consists of a short text utterance, paired with an intent label.\nStackoverflow Dataset: This dataset is a cu-rated subset from a challenge dataset originally published by Kaggle\u00b3. The selection includes ques-tion titles that have been categorized into 20 distinct intent classes following the methodology proposed by Xu et al. (Xu et al., 2017). Since this subset does not inherently include labeled out-of-scope (OOS) samples, we adopted the procedure described by Lin and Xu (Lin and Xu, 2019) to designate classes as either in-scope (IS) or OOS. Specifically, we retain classes that, combined, cover at least 75% of the total dataset as IS. The remaining classes are considered OOS, and their instances are removed from the training dataset but retained and relabeled as OOS in the validation and test datasets. The specific details of dataset construction is detailed in Appendix A.1.1\nMTOP Dataset: The MTOP dataset is a task-oriented dialogue dataset with a hierarchical struc-ture of intent labels. In our experiments, we focus solely on the root-label of these intents. We utilized the English portion of this dataset, referred to as MTOP-EN, which comprises 87 intent classes in 11 domains. This dataset does not include a pre-defined out-of-scope (OOS) class. Based on the amount of data, the 'timer' domain is chosen as the pre-defined OOS class. Our preprocessing fil-tered out in-scope (IS) domains with fewer than 10 occurrences per IS class. The in-scope data was then split into training, validation, and testing sets using a stratified approach based on intent labels to maintain an equal distribution of intents across these splits. We allocate OOS data between valida-tion and testing sets, without stratification, due to the uniform label of OOS.\nCar Assistant Dataset: This is an internal dataset. Due to it's original massive size, we ran-domly selected around 200,000 utterances used per run for training, validation and testing. This in-scope part of the dataset is derived from user interactions with car assistant systems and contains 46 distintc intent classes while. The OOS part is constructed from 14 different setes including sms messages, dictated emails, book snippets, tweets, internet-scraped text and some other unsupported text phrases."}, {"title": "Results and Discussion", "content": "The OOS detection performance and intent classi-fication accuracy of both the baseline and the pro-posed fine-tuning approaches are presented in Table 1. The table has 4 rows and 7 columns. Each row of Table 1 contains results on one particular dataset. The first three columns show dataset name and a summary of numbers of utterances in each dataset. The fourth column shows the fine-tuning cost func-tion used namely cross-entropy (CE), versus the joint cross-entropy and autoencoder (CE+AE) fine-tuning objective introduced in Eq. (3). The next three columns display our results for the evaluation metrics mentioned in Section 4.3. As mentioned in the table caption, AUPRoos refers to calculating the AUPR by treating the OOS class in the test set as the positive class. AUROC refers the area under the receiver operating curve, and accuracy refers to intent classification accuracy using Eqs. (5) and (6). The intent classification accuracy is expressed as a percentage.\nThe results show that in 3 out of 4 datasets we tested, the proposed method improved OOS detec-tion, while maintaining the same in-scope intent classification accuracy. Specifically, the relative improvement with regard to AUPRoos is seen to be 3.22% on the StackOverflow dataset, 3.45% on the MTOP dataset and 1.15% on the Car Assistant dataset. Due to its larger test set, the improvement on our internal car assistant dataset is statistically more significant than the improvement on the other two test sets. This can be attributed to the presence of a larger training set, which enables the autoen-coder head to exert greater influence over the more than 100 million parameters of the sentence en-coder."}, {"title": "Embedding Dispersion", "content": "We also measured the dispersion of the sentence embedding vector after baseline fine-tuning and after our proposed fine-tuning as shown in Table 2. The dispersion was calculated as follows. For each training dataset that appears in Table 2, training sentence embeddings were extracted first using our baseline cross-entropy (CE) model, and further us-ing our model trained with joint cross-entropy and autoencoder objective (CE+AE). After extracting embeddings a global covariance matrix was calcu-lated in each case namely $\\Sigma_{CE}$ and $\\Sigma_{CE+AE}$. \u03a4\u03bf measure dispersion, the trace of each of these ma-trices were calculated (Johnson et al., 2002). The dispersion values illustrate that global disper-sion of in-scope embeddings is smaller when our proposed fine-tuning is applied. It can be observed that the smaller the dispersion gets the higher OOS detection accuracy becomes when comparing the two fine-tuning approaches. This supports our ar-gument that constraining the in-scope embeddings in a smaller neighborhood in the embedding space helps in the separation of in-scope and OOS sam-ples."}, {"title": "Replacing the Model with a Large Language Model (LLM)", "content": "Given the undeniable power of LLMs, one would naturally wonder what if the classification pipeline based on sentence encoder was replaced by an LLM. In other words, how well would a LLM perform intent classification and OOS detection tasks without fine-tuning and just by prompt en-gineering. To answer this question we examined the performance of ChatGPT's gpt-3.5-turbo-0125 model from OpenAI on the MTOP dataset. We evaluated the performance of the LLM for intent-classification and OOS detection separately with different prompts as we noticed that if we ask the LLM to do both tasks, it will overwhelmingly clas-sify most samples as OOS. Furthermore, due to the limitations in context size, we were limited to use 200 training examples but we made sure that there is at least one sample for each intent in the training set. In our setup, the system prompt is followed by the user prompt in which the model is provided with training sentences and a single test sentence. The exact system prompt is included in the Ap-pendix A.3. Each experiment was repeated five times and the mean values of AUPR and AUROC as well as classification precision are presented in Table 3.\nIt is worth noting that even with a very limited amount of training data the LLM does a good job of classifying 82.9% of the samples correctly. How-ever, detecting OOS samples just by looking at a few in-scope samples is proven to be a more diffi-cult task even for the LLM. Although comparing the performance of our approach to the LLM per-formance for this task is not fair because the latter only saw a fraction of the training samples, it shows that one could not simply replace the classifier with an LLM and expect high intent classification and OOS detection accuracy."}, {"title": "Conclusion", "content": "In this paper, we introduce a new approach to fine-tuning sentence transformers used for intent clas-sification, to improve their ability to detect OOS samples. We showed that sentence embeddings generated from encoders fine-tuned using the pro-posed approach provide better separation between in-scope and OOS samples while maintaining the separation between intent classes."}, {"title": "Limitations", "content": "A limitation of our approach is that it requires more than a few examples per intent class during fine-tuning to make a big enough impact on the sentence encoder to improve OOS detection. In other words, it is not suitable for few-shot learning. This can be seen in the results given in Table 1 where the OOS accuracy stays the same for the CLINC150 dataset, where the ratio of samples to intent classes is much smaller than for the other datasets. The proposed approach was not evaluated for compositional or compound queries that contain both in-scope and OOS elements. This was mainly because in most virtual assistant systems the multi-intent queries are first broken into single-intent phrases, and then the classification step is performed. In addition, there are not many studies in the literature on this use case and not having publicly available datasets with such queries in them would make it difficult for us to benchmark our approach against SOTA approaches."}, {"title": "Appendix", "content": ""}, {"title": "Details of dataset construction", "content": ""}, {"title": "Stackoverflow dataset", "content": ""}, {"title": "Exact hyper-parameter values obtained for various datasets", "content": ""}, {"title": "Prompt given to ChatGPT 3.5", "content": ""}]}