{"title": "iTrash: Incentivized Token Rewards for Automated Sorting and Handling", "authors": ["Pablo Ortega", "Eduardo Castell\u00f3 Ferrer"], "abstract": "As robotic systems (RS) become more autonomous, they are becoming increasingly used in small spaces and offices to automate tasks such as cleaning, infrastructure maintenance, or resource management. In this paper, we propose iTrash, an intelligent trashcan that aims to improve recycling rates in small office spaces. For that, we ran a 5 day experiment and found that iTrash can produce an efficiency increase of more than 30% compared to traditional trashcans. The findings derived from this work, point to the fact that using iTrash not only increase recyclying rates, but also provides valuable data such as users behaviour or bin usage patterns, which cannot be taken from a normal trashcan. This information can be used to predict and optimize some tasks in these spaces. Finally, we explored the potential of using blockchain technology to create economic incentives for recycling, following a Save-as-you-Throw (SAYT) model.", "sections": [{"title": "I. INTRODUCTION", "content": "An essential part of reducing greenhouse gas emissions and mitigating escalating effects of climate change [1] is to reduce over-consumption [2]. The recently popular circular economy strategy proposes to reduce over-consumption by optimizing material flows, including by recycling waste [3]. However, only 6% of the climate policies reported by European countries include some form of circular economy policies and measures, according to a 2024 European Environment Agency (EEA) report [4].\nAlso according to the EEA, 55% of municipal waste and 65% of packaging waste should be prepared for re-use or recycling by 2025, but at least 19 of the EU-27 states will struggle to meet that target [5]. It is essential to build new technologies to make recycling easier, more consistent, and more accurate.\nIncreasing the efficiency of waste management remains an important open challenge [6]. Digital technologies can be found in large-scale waste management processes, for example using an IoT-based solution to track the amount of waste collected in urban containers [7], but these technologies do not directly provide solutions for small-scale use [8], such as in small office and domestic environments. Furthermore, much of the waste deposited in large municipal containers is sorted in private indoor environments beforehand. As waste generation continues to increase in small office and domestic environments [9], it is essential to increase the efficiency of waste sorting [10] and recycling [11] in small office and domestic environments.\nSmart spaces [12] are indoor environments (e.g., apart-ments, offices) that use electronic devices and systems to automate and control functions such as lighting [13] or heating [14], often through a centralized platform accessible remotely via smartphone application. Smart spaces can potentially improve recycling rates [15], for example with smart trashcans for better sorting. Some smart trashcans have been developed, including a system that checks the bin's level and alerts the user when the bin is almost full [16], but to the best of our knowledge, there are none that improve the rate of correct recycling sorting. This paper proposes a smart trashcan that not only detects waste types to support sorting, but offers automated incentives [17] for users to adopt the technology and use it correctly."}, {"title": "A. Blockchain for incentivized behavior", "content": "In the last decade, the cryptographic technology \"the blockchain\" has provided new ways to organize collectives without the need of a centralized authority [18]-[21] and to create incentive mechanisms within those collectives [22]. However, blockchain technology faces significant challenges in latency, size, throughput, and bandwidth, particularly in applications where quick and reliable data sharing is essential [18].\nNew blockchain protocols such as Ripple (XRP) [23] are designed to overcome these problems, with fast transaction speeds (e.g., less than 5 seconds), low transaction fees, and a highly scalable and stable network [24]. The Ripple network is well-suited for IoT devices transactions [25] and is therefore used in this paper.\nBlockchain-based incentive mechanisms have been proposed in many application domains, for example, using token-based reward systems to promote fitness [26] or incentivize urban cycling [27]. In [28], low-carbon mobility options are rewarded with tokens that can be exchanged for free visits to different attractions in a city, while in [29], children are rewarded for doing their homework with tokens that can be spent on TV viewing time [29].\nIn recycling and waste management, blockchain-based technology has been proposed for tracing and tracking waste in smart cities [30], reliable channelization of waste [31], protection of waste management documentation [32], and rewarding individuals for garbage removal [33]. In [34], it is proposed that future cities should incentivize recycling by securely and transparently transferring cryptocurrency tokens to waste collectors and participants. In this paper, we present a proof-of-concept to progress towards this aim."}, {"title": "II. ITRASH", "content": "We present iTrash (Incentivized Token Rewards for Automated Sorting and Handling), a robotic system to incentivize correct recycling in domestic and small office environments, using a blockchain-based Waste-to-Reward system [35] following a save-as-you-throw model [17]. We built and deployed a proof-of-concept iTrash that rewards the user via the XRP network and compared it with a normal (control) trashcan in a 5-day real-world experiment in a university common area."}, {"title": "A. System Overview", "content": "Fig. 2 shows the system overview, with a workflow divided in six steps. First, (1) the user places a disposable item where it can be detected by a proximity sensor. Once detected, the camera captures an image of the object. Then, (2) the image is processed by an image classification model, which outputs the color of the bin that best matches the type of waste the user has shown to the camera. (3) An LED strip then illuminates in the color matching the appropriate bin to use for disposal. (4) Once the user sees the LED color, they should throw the trash into the matching bin. (5) Using proximity sensors at the rim of each bin, the system will detect when and where the trash item is disposed and send a confirmation message. Finally, (6) if the trash item was disposed in the correct bin, the system will send a reward to the user."}, {"title": "B. Mechanical Design", "content": "iTrash functions as a robotic system add-on to a standard trashcan (see Fig. 3). It can be adapted to different trashcans by making minor adjustments to the design of the 3D-printed mechanical parts (the other components remain the same) and is easy to install and remove, allowing for quick repairs.\nWe designed the mechanical components to be produced using widely available desktop-size 3D printers, using PLA filament (we used a Bambu Lab X1-Carbon printer). To accommodate standard printing bed sizes, we divided the mechanical design into several pieces to be assembled (see Fig. 3 A). Piece 1 fits above a bin opening, with a mounting position for a proximity sensor, as seen in Fig. 3 B. In our setup, the base trashcan has 3 bins, so we use three instances of Piece 1. Piece 2 is a casing that holds the single-board computer (Raspberry Pi 4B), a camera, and an additional proximity sensor. Piece 2 positions the camera and proximity sensor above the other pieces, for a suitable object detection view. Piece 3 attaches the other components to the trashcan underneath and includes a mounting position for the LED strip (see Fig. 3 C). All three of the piece types include dovetail joints to be secured together."}, {"title": "C. Hardware", "content": "The hardware components in the iTrash system include four proximity sensors, an RGB LED strip, a camera, and a single-board computer. The proximity sensors are used to detect when the user places an item near the trashcan (Proximity Sensor I, in Fig. 3 B) and to detect into which bin the trash is disposed (Proximity Sensors II, III, and IV). We use a E18-B03P1 proximity sensors with a detection range of 5 to 30 cm. The RGB LED strip is used to provide visual feedback to users, indicating that the system is ready, processing, or signaling the correct bin to place items. We use a WS2813 1-meter long strip with 60 LEDs. The camera is used to capture images of waste items as they are detected by Proximity Sensor I, and to classify the items for proper sorting and recycling using computer vision. We use a Samzuy 1080P USB HD camera. For the single-board computer to control the above components, we use a Raspberry Pi 4B. The proximity sensors and the LED strip are each connected to GPIO pins and the camera module is interfaced via a USB connection. To power the components, the setup employs both 5V power pins and two ground pins."}, {"title": "D. Software", "content": "The state machine of the iTrash controller in shown in Fig. 4. Initially, (1) iTrash waits until the proximity sensor by the camera is triggered (Proximity Sensor I, in Fig. 3 B), indicating that a user is holding something in front of the camera. When the proximity sensor is triggered, (2) iTrash captures an image with the camera, then tries to classify any object in the image. (3) If an object in the image is not successfully classified, for example because an item was moved too quickly or the image is unclear, (4) the user will be asked to try again. If an object is successfully classified, (5) the system will illuminate the RGB LED strip in the color matching the appropriate bin for the classified object, thus informing the user. Then, the user is supposed to dispose the item in the indicated bin, thus triggering the proximity sensor above the correct bin's opening (one of Proximity Sensors II, III, and IV, in Fig. 3 B). If none of the proximity sensors of the bin openings are triggered within 10 seconds, (6) the system will timeout and the process will need to be restarted. (7) If the proximity sensor of a bin that was not indicated is triggered, the bin is considered incorrect and the user is not rewarded. If the proximity sensor of the indicated bin is triggered, (8) the user receives a reward. In all three cases (timeout, incorrect bin, or correct bin with reward), the image taken by the camera (9) is stored in a database for machine learning and quality assessment purposes. Finally, (10) the process will end, and the system will return to its initial state. The controller\u00b3 was implemented in Python, with MongoDB4 used for the database."}, {"title": "E. Classification Model", "content": "iTrash uses a classification model to determine which bin to recommend to the user. Following a trial-and-error testing period with a variety of models and datasets, we selected gpt-40-mini [36] as the model to use. The input of the model is an image of the item the user wants to dispose. If the image is valid (i.e., with an item in the foreground), the model will decide between three possible classification outputs: blue (paper and cardboard), yellow (plastic) and brown (organic), otherwise, the model will require the user to display the item again.\nFor each item iTrash classifies, the following parameters are stored for analysis:\n\u2022 image: stored in base64 format, which optimizes space usage and allows easy decoding to PNG format whenever needed for review.\n\u2022 time: date and time at which the item associated to the image was disposed, or at which the process timed out.\n\u2022 bin predicted: the color value of the bin predicted by the model for the item.\n\u2022 bin_thrown: the color value of the bin where the user disposed the item.\nThe parameters bin_predicted and bin_thrown are used not only to assess the rate of users that follow the indicated instruction, but also the rate of iTrash's correct predictions. To assess the rate of correct predictions, we use a parameter bin_real, which is the color value of the real bin into which the article should have been classified according to manual quality review. Ideally, in an experiment, the three values will line up, indicating that iTrash classified the item correctly and the user followed the instructions."}, {"title": "F. Blockchain", "content": "The reward system is implemented using blockchain technology. Users interacting with iTrash are expected to have already created an account linked to a wallet on the Ripple (XRP) network. All the transactions issued in this research occurred in the XRP Testnet5.\nWhen iTrash is ready to reward a user, it displays a message on a connected LCD screen asking the user to present the QR code of their wallet on the XRP Testnet. If the user presents their QR code in front of iTrash's camera within a 10 second timer, the reward is sent to the user's wallet. If no QR code is presented, iTrash displays four NGO options on the connected LCD screen, so the user can select one to donate their reward. Each displayed NGO is accompanied by a QR code, which the user scans to select the option.\nTo implement this, we established five wallets in the Testnet of Ripple: one for iTrash and four for the respective NGOs. We developed a Flask app hosted on Google App Engine7 and created four endpoints, one for each NGO. When a user scans a QR code and accesses the corresponding endpoint, the system transfers 0.01 XRPs to the selected NGO's wallet from the iTrash's wallet and a message stating 'Reward sent!' appears on the connected LCD screen."}, {"title": "III. EXPERIMENT SETUP", "content": "To demonstrate the feasibility of iTrash (see Fig. 5), we ran a 5-day experiment comparing the accuracy of iTrash against a normal (control) trashcan. The two trashcans (iTrash and control) were placed on opposite sides of a spacious (approximately 250 m\u00b2) indoor common area in a university campus, where many potential users, including students and staff, passed by both systems every day. As depicted in Fig. 5, we connected iTrash to an LCD screen to display visual support for the user. When no object has recently been detected by iTrash, a 50-second video explaining how the system works plays on a loop.\nEach of the experimental days (Monday to Friday) began at 8 AM, with both trashcans (iTrash and control) empty. The trashcans remained in place for 12 hours. Each experimental day ended at 8 PM, when the trashcans were emptied and the data collected. For iTrash, we manually reviewed all of the images taken during that day and determined into which bin each item should have been disposed, according to the standards set by the local city council9. These manual determinations were recorded in the parameter bin_real for each item. For the control, we manually reviewed each item in each bin, recording the bin the item was found in as the bin_thrown and the bin into which the item should have been disposed as the bin_real. After 5 days, we had collected the predicted and real values for all items disposed in both trashcans."}, {"title": "IV. RESULTS", "content": "In the 5-day experiment, 89 total items were disposed in the control (36 in the blue bin, 18 in the brown bin, and 35 in the yellow bin) and 67 total items were disposed in iTrash (25 in the yellow bin, 24 in the blue bin, and 18 in the brown bin).\nWe report the results in terms of the bin predicted, bin_real and bin_thrown values in Fig. 6, using Sankey diagrams to visualize the flow from one category to another as well as some patterns in the error.\nFor the control, we compared the bin_thrown value with the bin_real value (see Fig. 6 A). We did not include the bin predicted value for the control because it is equivalent to bin_thrown: the user disposes the item where the user predicts it should be disposed. In the control, of all the items that should have gone in the brown bin, 9 were correctly sorted, while 6 were placed in the blue bin and 3 in the yellow bin. For items that should have gone in the blue bin, 11 were correctly sorted, while 15 were placed in the brown bin and 10 in the yellow bin. For items that should have gone in the yellow bin, 22 were correctly sorted, while 6 were placed in the blue bin and 7 in the brown bin.\nFor iTrash, we first compared the bin predicted and bin_real values to evaluate the performance of the model (see Fig. 6 B). All items that should have gone in the brown bin were correctly predicted as brown. For items that should have gone in the blue bin, 11 were correctly predicted, while 4 were misclassified as brown and 2 as yellow. For items that should have gone in the yellow bin, 30 were correctly predicted, while 3 were misclassified as blue and 3 as brown.\nThen, for iTrash cases in which the bin predicted and bin_real values matched (i.e., iTrash predicted correctly), we compared the bin_predicted / bin_real and the bin_thrown values, to evaluate the rate of user cooperation with the robotic system (see Fig. 6 C). In total, there were 55 items that iTrash predicted correctly. Of the items correctly predicted as brown, 9 were correctly placed in the brown bin, while 3 were placed in the blue bin and 2 in the yellow bin. For the items correctly predicted as blue, 9 were correctly placed in the blue bin, while 2 were placed in the brown bin. Finally, for the items correctly predicted as yellow, 20 were correctly placed in the yellow bin, while 3 were placed in the brown bin and 7 in the blue bin."}, {"title": "A. Accuracy comparison", "content": "To calculate the accuracy of the iTrash classification model, we use:\n$$Accuracy = \\frac{Correct\\ predictions}{All\\ predictions}$$"}, {"title": "V. DISCUSSION", "content": "In the analysis of the results, we have excluded items that were presented to the iTrash camera but then not disposed in any bin. A total of 79 items were presented to the iTrash camera and recorded in the database, and 12 of these were not disposed (15% of the items). Manually reviewing the images showed that most of these items were phones, wallets, or earphones, thus, users were likely experimenting with how the system worked. We also did not include the reward data in the analysis of the results, because only 2 users chose one of the NGOs to receive the reward they earned, suggesting that there might have been some misunderstanding among the users about how the reward system worked, or that users were reluctant to spend more time interacting with the system.\nNote that, in Fig. 6, an ideal system with 100% accuracy would result in all straight, aligned bars for all colors. Fig. 6 and the Accuracy values (Eq. 1) of the results show that iTrash's predictions had a lower rate of error than the control. Specifically, the average prediction of iTrash outperformed the average user's choice in the control by 34.9%. This suggests that using iTrash provides a strong improvement in recycling accuracy compared to users relying on their own judgment.\nIn the control (see Fig. 6 A), the bin with the most incorrect items thrown into it was the blue bin: less than one-third of the items placed in the blue bin were correctly sorted. Conversely, the bin with the most correct items thrown into was the yellow bin, with an accuracy rate of approximately 63%. This suggests that users were more aware of the regulations about which items should be disposed of in the yellow bin, or at least found the regulations less ambiguous to follow. Indeed, it should be straightforward to identify which items are plastic, with the exception of coffee cups, which are composed of both paper and plastic and therefore belong in the yellow bin according to the regulations.\nIn iTrash (see Fig. 6 B), the bin with the most incorrect predictions was the brown bin (that is, blue and yellow items being incorrectly predicted as belonging to the brown bin). However, no brown items were incorrectly predicted as belonging to the blue or yellow bins. This suggests that the iTrash classification model currently has a slight bias to classify items as brown. In addition to this slight bias towards brown, the iTrash classification model occasionally confuses blue and yellow items (5 items incorrectly swapped between yellow and blue, out of 46 items predicted to be yellow or blue).\nWhen iTrash made correct predictions (see Figure. 6 C), users usually followed iTrash's instructions (almost 70% of the time), but sometimes override them. When iTrash's predictions were correct for the blue bin, users followed the instruction to throw an item in the blue bin more than 80% of the time. However, when iTrash's predictions were correct for the yellow bin, users incorrectly overrode iTrash's instructions one-third of the time. It is worth noting that when iTrash made incorrect predictions, users usually followed the wrong instructions, rather than correctly overriding them.\nA potential additional use case of the iTrash system is to track bin usage throughout the day in busy common areas. Fig. 7 reports the number of items disposed of by color, grouped by time periods over the course of the five experimental days. The boxplots in the figure provide a detailed statistical representation of waste disposal events for each bin color in each time slot. Each box represents the interquartile range (IQR) of the number of items discarded in each bin during each time slot, over the course of the 5-day experiment, capturing the middle 50% of the data (from the 25th percentile to the 75th percentile). The whiskers represent data dispersion, covering values within 1.5 times the IQR from the lower and upper quartiles. Points beyond this range are considered outliers, representing instances where the number of discarded items significantly deviated from the typical pattern. Notably, the blue boxplot for the 1-2 PM period shows a lower whisker that does not reach zero, suggesting that at least one item was always disposed during this period across all experimental days.\nThe results indicate a peak in waste disposal during midday (11:00 to 14:00), where the median and upper quartiles show a marked increase, almost doubling compared to the rest of the day. This pattern is consistent with typical cafeteria usage, where meal times generate much more waste due to increased food consumption and packaging disposal."}, {"title": "VI. FUTURE WORK", "content": "For future work, we would like to focus on analyzing the temporal data produced by iTrash (see Fig. 7). For instance, conducting a temporal analysis of household garbage disposal could provide valuable information about personal habits. Monitoring the frequency and timing of waste disposal can help identify peak periods, such as after meals or during routine cleanups. This data could be useful for optimizing municipal waste management systems, such as scheduling garbage collections, for organizing waste management in high-traffic areas with many small bins (office buildings, universities), or even for integrating smart technology into household bins, not only to improve waste classification accuracy but to potentially provide recommendations for more environmentally-friendly consumption patterns.\nAnother possible line of experimentation is improving the reward system by incorporating additional sensors (e.g., a weight sensor), allowing the reward amount to be proportional to the weight of the disposed item. Also, regarding the classification model, we could build a dataset using images stored by iTrash, continuously improving its classification accuracy.\nRegarding the blockchain-based reward system, due to the low participation rate that we got in the experiments, we should consider a different setup where users directly receive the reward and are provided with options to spend it on products or discounts. Another factor that could explain the low scanning rates is the reluctance of some users to spend extra time interacting with the system. Therefore, we should explore alternative methods of delivering the reward. The primary challenge is identifying the user, and one potential solution could be using NFC technology. The idea would be for users to have a blockchain wallet, and once they recycle correctly, they could use their phone or an NFC tag to scan, allowing the reward to be sent directly to their wallet. This approach will save users time by eliminating the need to open their camera and scan a QR code or open their wallet app and show a QR code to the camera. Increasing the accessibility and ease of receiving rewards might increase the rate of users that follow iTrash's instructions instead of overriding them, especially if they frequent the space and become repeat users."}, {"title": "VII. CONCLUSIONS", "content": "This article introduces iTrash, a smart trash can system that aims to improve recycling efficiency through computer vision and blockchain-based incentives. In a 5-day experiment, iTrash achieved 34.9% more accuracy than traditional trash cans, demonstrating its effectiveness in reducing human error through automatic waste sorting. This can in part be attributed to iTrash's rate of prediction accuracy being much higher than the average human user's, but might also be partly attributed a high level of trust in the technology or a high rate of users being comfortable relying on robotics systems to make this type of decision, as users largely followed iTrash's recommendations even with a very low rate of users choosing to collect the reward that was offered. Although the blockchain reward mechanism showed potential, low participation suggests the need for more seamless reward delivery, such as NFC-based systems. In conclusion, iTrash effectively improves recycling accuracy in small environments such as offices and universities, offering a scalable solution for smarter and more sustainable waste management."}]}