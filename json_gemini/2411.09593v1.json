{"title": "SMILE-UHURA Challenge - Small Vessel Segmentation at Mesoscopic Scale from Ultra-High Resolution 7T Magnetic Resonance Angiograms", "authors": ["Soumick Chatterjee", "Hendrik Matternd", "Marc D\u00f6rner", "Alessandro Sciarrad", "Florian Dubost", "Hannes Schnurred", "Rupali Khatun", "Chun-Chih Yuk", "Tsung-Lin Hsieh", "Yi-Shan Tsaik", "Yi-Zeng Fang", "Yung-Ching Yang", "Juinn-Dar Huangk", "Marshall Xu", "Siyu Liu", "Fernanda L. Ribeirol", "Saskia Bollmann", "Karthikesh Varma Chintalapatia", "Chethan Mysuru Radhakrishna", "Sri Chandana Hudukula Ram Kumara", "Raviteja Sutrave", "Abdul Qayyum", "Moona Mazher", "Imran Razzak", "Cristobal Rodero", "Steven Niederern", "Fengming Lin", "Yan Xia", "Jiacheng Wangtu", "Riyu Qiut", "Liansheng Wang", "Arya Yazdan Panah", "Rosana El Jurdi", "Guanghui Fu", "Janan Arslan", "Ghislain Vaillant", "Romain Valabregue", "Didier Dormont", "Bruno Stankoff", "Olivier Colliot", "Luisa Vargas", "Isai Daniel Chac\u00f3n", "Ioannis Pitsiorlas", "Pablo Arbel\u00e1ez", "Maria A. Zuluaga", "Stefanie Schreibere", "Oliver Speckd", "Andreas N\u00fcrnbergera"], "abstract": "The human brain receives nutrients and oxygen through an intricate network of blood vessels. Pathology affecting small vessels, at the mesoscopic scale, represents a critical vulnerability within the cerebral blood supply and can lead to severe conditions, such as Cerebral Small Vessel Diseases. The advent of 7 Tesla MRI systems has enabled the acquisition of higher spatial resolution images, making it possible to visualise such vessels in the brain. However, the lack of publicly available annotated datasets has impeded the development of robust, machine learning-driven segmentation algorithms. To address the complexities of mesoscopic vessel segmentation and to highlight the need for advanced techniques to manage the high noise levels and poor vessel-to-background contrast inherent in \"ultra-high-resolution\" data, the SMILE-UHURA challenge was organised. This challenge, held in conjunction with the ISBI 2023, in Cartagena de Indias, Colombia, aimed to provide a platform for researchers working on related topics. The SMILE-UHURA challenge addresses the gap in publicly available annotated datasets by providing an annotated dataset of Time-of-Flight angiography acquired with 7T MRI. This dataset was created through a combination of automated pre-segmentation and extensive manual refinement. In this manuscript, sixteen submitted methods and two baseline methods are compared both quantitatively and qualitatively on two different datasets: held-out test MRAs from the same dataset as the training data (with labels kept secret) and a separate 7T TOF MRA dataset where both input volumes and labels are kept secret. The results demonstrate that most of the submitted deep learning methods, trained on the provided training dataset, achieved reliable segmentation performance. Dice scores reached up to 0.838 \u00b1 0.066 and 0.716 \u00b1 0.125 on the respective datasets, with an average performance of up to 0.804 \u00b1 0.15.", "sections": [{"title": "1. Introduction", "content": "Brain function relies on the cerebral vasculature to supply\nnutrients and oxygen. Any impairment of the vasculature can\ndamage brain tissue, potentially leading to cognitive decline.\nThe cerebral vasculature is organised as a hierarchical, tree-like\nnetwork, where vessel diameter decreases while the number of\nbranches increases with higher branch order. For major cere\nbral vessels at the macroscopic scale and for capillaries, ar\nterioles, and venules at the microscopic scale, in vivo and ex\nvivo imaging modalities are available, respectively. However,\nassessing the mesoscopic scale (vessel diameters of 100-500\n\u00b5m) remains challenging. Pathologies at the mesoscopic scale\nare potentially linked to ageing, dementia, and Alzheimer's dis\nease [1, 2]. Segmentation and quantification of these vessels are\ncrucial steps in the investigation of Cerebral Small Vessel Dis\nease (CSVD) [3, 4].\nRecently, ultra-high field (UHF) magnetic resonance imag\ning (MRI) has emerged as a means of bridging the gap be\ntween macroscopic and microscopic assessments of the human\ncerebral vasculature. Following pioneering work on magnetic\nresonance angiography (MRA) at 7 Tesla (7T) [5, 6], the field\nhas advanced significantly, achieving the highest resolutions to\ndate [7, 8] as high as 150 \u03bcm and 140 \u00b5m, respectively.\nThese advancements enable imaging of mesoscopic vessels,\nwhich are highly relevant to understanding cerebral small vessel\ndiseases, neurodegeneration, and the origins of the functional\nfMRI signal. However, automatic segmentation of vessels at\nthis scale has yet to be established.\nTo address this need within the neurological and neuroscien\ntific community, this challenge was initiated, focusing on the\nsegmentation of vasculature at the mesoscopic scale. While\nvessel segmentation challenges have a long tradition, using\nUHF MRI for mesoscopic vessels presents unique difficulties\ncompared to 2D microscopic or 3D macroscopic vessel imag\ning and segmentation: (I) instead of a single 2D image per sam\nple, a 3D volume is acquired, significantly increasing computa\ntional demands and making manual segmentation highly time\nconsuming, and (II) compared to macroscopic segmentation,\nultra-high-resolution data is noisier and exhibits poorer vessel\nto-background contrast, complicating both automatic and man\nual segmentation. These challenges have hindered the estab\nlishment of openly accessible data repositories and the devel\nopment of high-performance mesoscopic vessel segmentation\nalgorithms. Currently, no high-resolution 7T dataset with an\nnotations is available for training machine learning-based seg\nmentation methods or benchmarking performance. To address\nthis gap, an annotated dataset of Time-of-Flight (ToF) angiog\nraphy acquired with a 7T MRI was created for this challenge.\nThis dataset was generated using a combination of automatic\npre-segmentation and extensive manual refinement. It serves"}, {"title": "2. Related Work", "content": "Benchmark datasets and challenges focused on vessel seg\nmentation have been established in the past, such as the DRIVE\nchallenge, which targets blood vessel segmentation from reti\nnal images [9, 10, 11], and lung vessel segmentation challenges\nbased on computed tomography (CT) images [12]. However,\nwith respect to vessel segmentation from MRA-TOF, no public\nchallenges or open datasets for benchmarking have been avail\nable.\nThere have been other tasks involving MRA-TOF data,\nsuch as the ADAM challenge, which focused on microa\nneurysms [13], and the VALDO challenge, which centred on\nvascular lesion detection and segmentation [14], including cere\nbral microbleeds and enlarged perivascular spaces (EPVS).\nThese challenges provided labels specific to their respective\ntasks but did not address vessel segmentation in particular.\nPublic datasets, such as the IXI dataset\u00b9, also exist and pro\nvide a large collection of MRA-TOF data. However, these\ndatasets have been acquired using MRI scanners with field\nstrengths of 1T, 1.5T, or 3T, rather than ultra-high-field (UHF)\nscanners such as 7T. Images obtained with a 7T MR scanner at\nhigh spatial resolution reveal significantly more small vessels\ncompared to those acquired with 3T scanners [15]. Moreover,\nnone of these datasets include annotations for vessels that could\nbe used to train automatic vessel segmentation algorithms."}, {"title": "2.1. Current approaches for vessel segmentation", "content": "Among the most prevalent vessel enhancement algorithms\nis the Hessian-based Frangi vesselness filter [16], which is\ntypically combined with empirically calibrated thresholding to\nachieve the final segmentation. The multi-scale properties of\nthis method make it suitable for small vessel segmentation;\nhowever, significant parameter fine-tuning is often required\nto achieve good sensitivity for vessels of interest. Canero\nand Radeva [17] introduced a vesselness enhancement dif\nfusion (VED) filter that integrates the Frangi filter with an\nanisotropic diffusion scheme. This approach was later ex\ntended by constraining the smoothness of the tensor/vessel re\nsponse function [18]. Recently, a multi-scale Frangi diffusion\nfilter (MSFDF) pipeline was proposed for segmenting cere\nbral vessels from susceptibility-weighted imaging (SWI) and\nTOF-MRA datasets. This method initially pre-selects voxels\nas vessels or non-vessels using a Bayesian Gaussian mixture\nclassifier, followed by the application of Frangi and VED fil\nters. While effective, these approaches often require manual"}, {"title": "3. SMILE-UHURA Challenge", "content": "The SMILE-UHURA challenge, held in conjunction with the\nIEEE International Symposium on Biomedical Imaging (ISBI)\n2023, in Cartagena de Indias, Colombia (and virtually), seeks\nto address the notable gap in publicly accessible annotated\ndatasets within the domain of medical imaging by introduc\ning an annotated dataset specifically designed for TOF-MRA\nacquired using 7T MRI. This dataset represents a significant\ncontribution to the community, as it was meticulously devel\noped through a combination of automated pre-segmentation\ntechniques and thorough manual refinement. The challenge not\nonly provides a robust dataset for the training and evaluation"}, {"title": "3.1. Dataset", "content": "The challenge includes two datasets, the Open Dataset and\nthe Secret Dataset, both acquired at 7T MRI with an isotropic\nresolution of 300 \u00b5m. To contextualise this resolution in rela\ntion to other public datasets, the IXI dataset contains images\nwith a resolution of 450 \u00b5m, and prior research performing\nvessel segmentation in 7T MRA-ToF employed a resolution of\n600 \u00b5m. The Open Dataset was divided into a publicly avail\nable training-validation set and a confidential held-out test set,\nused to assess the performance of submitted methods. The la\nbels from the Secret Dataset will remain unpublished and was\nutilised for external testing to evaluate the generalisability of\nthe methods on an independent dataset."}, {"title": "3.1.1. Open Dataset", "content": "The images in the Open Dataset were sourced from the\nStudyForrest project\u00b2 [24], which involved 3D multislab Time\nof-Flight Magnetic Resonance Angiography (TOF-MRA) data\nfrom 20 healthy, right-handed, native German-speaking sub\njects, with an average age of 26 years. The imaging protocol\nutilised four slabs, each comprising 52 slices with a thickness of\n300 \u00b5m, and encoding was performed from right to left at a 7T\nfield strength. However, MRAs from 2 subjects were excluded\ndue to the presence of wraparound artefacts. The remaining im\nages were divided into two sets: a training-validation set com\nprising 14 MRAs, which was made publicly available, and a\ntest set containing 4 MRAs, retained exclusively for held-out\nevaluation."}, {"title": "3.1.2. Secret Dataset", "content": "The Secret Dataset was created using TOF-MRAs from a\ndifferent study [7], comprising 3D TOF-MRA data from seven\nhealthy subjects scanned at 7T with the same isotropic resolu\ntion of 300 \u00b5m as the Open Dataset. These images were ac\nquired using prospective motion correction techniques to min\nimise image blurring and prevent the loss of small vessels. In\naddition, sparse venous saturation was implemented to sup\npress venous contamination in the angiograms while remaining\nwithin specific absorption rate limits (the Open Dataset did not\napply any venous saturation)."}, {"title": "3.1.3. Annotation", "content": "Annotations for both datasets were created using a three-step\nprocess. Initially, preliminary segmentations were generated\nusing thresholding in 3D Slicer\u00b3 [25]. This process was empir\nically refined for each volume to produce an initial binary mask\nwith minimal noise. While this procedure successfully seg\nmented a substantial portion of medium- to large-scale vessels,\nmany small vessels of high relevance remained unsegmented.\nSubsequently, these segmentations underwent extensive manual\nrefinement to remove noise and accurately delineate the miss\ning vessels. Finally, a senior neurologist reviewed and verified\nthe annotations to ensure their accuracy. The annotations for\nthe training-validation subset of the Open Dataset are accessi\nble for download upon request on Synapse [26]. Conversely,\nannotations for the test subset of the Open Dataset and the Se\ncret Dataset have been withheld to prevent potential overfitting\nor bias.\nIn addition to these annotations, ten plausible segmentations\nfor each volume in the training-validation subset were gener\nated in a semi-automatic manner by varying the parameters of\nthe Frangi filter (see [27] for details). These segmentations are\nalso available for use. Moreover, additional annotations cre\nated using OMELETTE, an automatic small vessel segmenta\ntion pipeline [28], are provided. These diverse annotations are\nintended for benchmarking purposes or for use in training sce\nnarios that benefit from multiple annotations, such as Proba\nbilistic UNets [29, 27]."}, {"title": "3.2. Aim", "content": "The SMILE-UHURA challenge aims to bridge the gap in\npublicly available annotated datasets for 7T Time-of-Flight\nMRI angiography by providing a meticulously annotated\ndataset. It seeks to support the training and evaluation of ma\nchine learning models for vessel segmentation while offering a\nbenchmarking platform for researchers to compare and refine\ntheir approaches. By keeping the dataset publicly accessible,\nthe challenge encourages innovation and collaboration in med\nical imaging analysis."}, {"title": "3.3. Evaluation", "content": "The primary evaluation of the SMILE-UHURA challenge\nutilised five distinct quantitative metrics to objectively assess\nthe performance of the segmentation methods. These met\nrics provided a robust and comprehensive analysis of the mod\nels' accuracy, efficiency, and reliability in segmenting vascular\nstructures. In addition to these quantitative assessments, a qual\nitative evaluation was conducted by an expert, who rated the\nsegmentation quality based on visual and practical considera\ntions. This dual approach ensured a balanced evaluation, com\nbining objective data-driven insights with expert judgement to\nprovide a thorough assessment of the segmentation outcomes."}, {"title": "3.3.1. Metrics for quantitative evaluation", "content": "Five quantitative metrics were employed to ensure a compre\nhensive evaluation of the submitted methods: Dice coefficient,\nJaccard Index (IoU), volumetric similarity, mutual information,\nand balanced average Hausdorff distance.\nThe Dice coefficient and Jaccard Index are standard over\nlap metrics that quantify the similarity between the predicted\nsegmentation and the ground truth, focusing on the accuracy\nof the segmented regions. Although mathematically distinct,\nthey provide complementary perspectives, enhancing the reli\nability of the overlap assessment. Volumetric similarity evalu\nates the agreement in volume between the predicted and ground\ntruth segmentations, which is crucial for assessing how well a\nmethod captures the true size of the vessels. Mutual informa\ntion measures the statistical dependence between the segmented\noutputs and the ground truth, offering insight into the shared in\nformation beyond spatial overlap alone. The balanced average\nHausdorff distance (bAHD or bAVD in the EvaluateSegmenta\ntion pipeline) [30] measures the average boundary discrepancy\nbetween the predicted segmentation and the ground truth, high\nlighting the precision of a method in delineating vessel edges.\nBy incorporating these diverse metrics, the evaluation cap\ntures multiple aspects of segmentation performance includ\ning region overlap, volumetric accuracy, statistical correlation,\nand boundary precision. This approach ensures a thorough and\nrobust assessment of each method's effectiveness. The quantita\ntive evaluation was performed using the EvaluateSegmentation\npipelines [31]."}, {"title": "3.3.2. Scoring system for qualitative expert evaluation", "content": "The segmentation performance of various algorithms was ad\nditionally evaluated qualitatively by an expert through a blinded\nassessment process. The outputs of each algorithm across dif\nferent image volumes were assessed based on two primary cri\nteria: the delineation of small vessels and the suppression of\nnoise contamination. Small vessels were defined as those with\nan apparent diameter of 1\u20132 voxels, while noise contamination\nreferred to the incorrect segmentation of non-vascular voxels as\nvessels. Ratings were assigned on a scale from 0 (unacceptable)\nto 5 (excellent).\nFor comparative reference, original ToF angiography images\nwere provided to the expert alongside each segmentation. All\nimages (original ToFs and segmentation results) were presented\nas Maximum Intensity Projections (MIPs), with an additional\nzoomed view of the Circle of Willis. This was specifically in\ncluded to enhance the evaluation of small vessel segmentation,\nsuch as the lenticulostriate arteries branching from the Middle\nCerebral Artery (MCA). This setup allowed for the assessment\nof whether the segmentation algorithms could potentially sur\npass the depiction of small vessels offered by ToF angiogra\nphy, which may be affected by intensity variations caused by"}, {"title": "3.4. Challenge setup", "content": "Following the acceptance of the SMILE-UHURA challenge\nfor ISBI 2023, it was formally announced on the challenge's\ndedicated website, with registration facilitated through the\nSynapse platform7. The training dataset, including annotations,\nwas provided in NIFTI format, and participants were instructed\nto submit their solutions as Docker containers, adhering to the\ndetailed guidelines outlined on the Synapse page.\nThe evaluation environment was equipped with high\nperformance hardware, comprising a CUDA-enabled Nvidia\nA6000 GPU with 48GB of memory, a 16-core 32-thread AMD\nRyzen 9 3950X processor, and 64GB of RAM. Participants\nwere required to ensure that their Docker containers could run\nseamlessly on this system. Containers that failed to execute\nsuccessfully due to issues such as CUDA memory over\nflow, excessive CPU or RAM usage causing system hangs, or\nother technical faults were disqualified. To maintain fair\nness and security, internet access was strictly prohibited dur\ning execution. As a result, participants had to design self\ncontained Docker containers, including all necessary trained\nmodels and pre-trained weights within the submission. Tech\nnical support was made available to assist participants in build-"}]}