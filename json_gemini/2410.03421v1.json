{"title": "ONE2SET + Large Language Model: Best Partners for Keyphrase Generation", "authors": ["Liangying Shao", "Liang Zhang", "Minlong Peng", "Guoqi Ma", "Hao Yue", "Mingming Sun", "Jinsong Su"], "abstract": "Keyphrase generation (KPG) aims to automatically generate a collection of phrases representing the core concepts of a given document. The dominant paradigms in KPG include ONE2SEQ and ONE2SET. Recently, there has been increasing interest in applying large language models (LLMs) to KPG. Our preliminary experiments reveal that it is challenging for a single model to excel in both recall and precision. Further analysis shows that: 1) the ONE2SET paradigm owns the advantage of high recall, but suffers from improper assignments of supervision signals during training; 2) LLMs are powerful in keyphrase selection, but existing selection methods often make redundant selections. Given these observations, we introduce a generate-then-select framework decomposing KPG into two steps, where we adopt a ONE2SET-based model as generator to produce candidates and then use an LLM as selector to select keyphrases from these candidates. Particularly, we make two important improvements on our generator and selector: 1) we design an Optimal Transport-based assignment strategy to address the above improper assignments; 2) we model the keyphrase selection as a sequence labeling task to alleviate redundant selections. Experimental results on multiple benchmark datasets show that our framework significantly surpasses state-of-the-art models, especially in absent keyphrase prediction. We release our code at https://github.com/DeepLearnXMU/KPG-SetLLM.", "sections": [{"title": "1 Introduction", "content": "The keyphrase generation (KPG) task involves creating a set of phrases to encapsulate the core concepts of given document. High-quality keyphrases enhance various downstream tasks, such as information retrieval (Kim et al., 2013; Tang et al., 2017; Boudin et al., 2020), text summarization (Wang and Cardie, 2013; Pasunuru and Bansal, 2018). In general, keyphrases are categorized into two types: 1) present keyphrases that occur continuously in the given document, and 2) absent keyphrases that do not match any continuous subsequence. The quality evaluation of keyphrases includes two aspects: precision, which requires the generated keyphrases to be pertinent to the document, and recall, which demands the generated keyphrases cover the core ideas of the document.\nDominant paradigms for KPG include ONE2SEQ (Yuan et al., 2020) and ONE2SET (Ye et al., 2021). The former treats KPG as a sequence generation task, while the latter treats it as a set generation by introducing multiple control codes for parallel keyphrase generation and dynamically assigning keyphrase ground-truths to control codes as supervision based on bipartite matching (Kuhn, 2010). Recently, pre-trained language models (PLMs) have been widely incorporated into KPG via ONE2SEQ paradigm (Chowdhury et al., 2022; Zhao et al., 2022; Wu et al., 2023a; Dong et al., 2023). Particularly, with the emergence of LLMs, researchers have also begun to introduce LLMs into KPG via in-context learning (Song et al., 2023a; Mart\u00ednez-Cruz et al., 2023). However, it is difficult for a single model to achieve high performance in precision and recall simultaneously. As verified by our preliminary study (See Section 2), models that excel in recall tend to have lower precision, while models with high precision fall short in recall.\nIn this paper, to deal with the above issue, we introduce a generate-then-select framework that decomposes the KPG task into two steps, each handled by a separate sub-model. This framework includes a generator that aims to recall correct keyphrases and a selector that eliminates incorrect candidates.\nTo identify the most suitable models for the generator and selector, we conduct further experiments in the preliminary study to investigate the potential of conventional KPG models and LLMs for these roles. Our experimental results lead to two conclusions: 1) SETTRANS, a ONE2SET-based KPG model, has a significant advantage in recall and thus is well-suited as the generator, and 2) LLMs with their superior semantic understanding, are more effective than small language models (SLMs) for keyphrase selection and are suitable as the selector.\nFurthermore, we improve the generator and selector of our framework in two aspects. The generator assigns each ground-truth to only one control code. However, the number of control codes generally exceeds that of ground-truths, leading to insufficient training for many control codes. To address the above improper assignments, we propose an OT-based assignment strategy for ONE2SET. This strategy converts the matching of candidates and ground truth into an OT problem, allowing a ground-truth to be assigned to multiple candidates.\nAs for the selector, existing studies (Kong et al., 2023; Choi et al., 2023; Sun et al., 2023) employ reranking methods to individually score candidates and then select those with high scores, which, however, results in many semantically similar candidates being selected. To address this issue, we convert keyphrase reranking into an LLM-based sequence labeling task. Leveraging the long sequence modeling capability of LLMs, we feed all candidates into the selector and have it autoregressively generate decision labels indicating whether to keep or discard the corresponding candidate. In this way, we can not only reduce the decoding search space of LLMs, but also alleviate semantic repetition by enabling the selector to fully consider the correlation between the current candidate and previous selections. Particularly, to ensure robustness to the order of candidates, we feed them into the selector in random order during instruction tuning. This encourages the selector to develop a deeper understanding of the candidates' semantics. During inference, candidates are sorted by quality for the selector to prioritize candidates more likely to be correct.\nOverall, the major contributions of our work can be summarized as follows:"}, {"title": "2 Preliminary Study", "content": "To verify the necessity of decomposing KPG, we first explore the performance of dominant models in terms of recall and precision. Then, through more experiments, we analyze which models are best suited as the generator and selector.\nTrade-off in Keyphrase Generation. We measure the performance of dominant models on the testset of KP20k, including SETTRANS, fine-tuned BART-large, SciBART-large, Flan-T5-large, and LLaMA-2-7B and report the results in Figure 1. As shown in Figure 1, achieving high accuracy and recall simultaneously is challenging for a single model. Whether it is a conventional KPG model or an LLM, as the number of predicted keyphrases increases, the recall of the model inevitably increases while its accuracy decreases, and vice versa. This result proves the necessity of decomposing KPG into two steps.\nEvaluating the Recall Performance of LLAMA-2-7B and SETTRANS. As revealed above, SETTRANS and LLaMA-2-7B exhibit excellent recall in commonly-used setting. In Figure 2, we further investigate their recall under various settings for a full comparison. We can clearly observe that as the number of generated candidates increases, SETTRANS consistently exhibits better recall performance than LLaMA-2-7B. Given its stronger recall performance and lower computational consumption, we choose SETTRANS as the generator. Additionally, SETTRANS tends to recall more correct keyphrases along with more incorrect candidates (see Appendix B.2), highlighting the necessity of a selector with strong filtering capabilities to improve accuracy.\nEvaluating SLM and LLM for Keyphrase Selection. To identify a suitable selector, we first use SETTRANS as the generator to output candidates, and then compare multiple representative keyphrase reranking methods. The methods we consider include 1) SLM-Scorer, the reranker from (Choi et al., 2023), which is an SLM-based one and achieves SOTA performance in keyphrase reranking, and 2) LLM-Scorer, a LLaMA-2-7B reranker, which is fined-tuned as detailed in Appendix D.2. As shown in Table 1, LLM-Scorer achieves higher accuracy and better F1@M scores, indicating that the powerful semantic understanding capability of LLMs is helpful for keyphrase selection. Consequently, we adopt LLaMA-2-7B as the selector."}, {"title": "3 Our Framework", "content": "As described above, our framework involves an improved ONE2SET-based generator and an LLM-based selector. Unlike the conventional ONE2SET paradigm, our generator improves the supervision signal assignment during training by modeling it as an Optimal Transport (OT) problem. Distinct from previous studies on keyphrase reranking (Kong et al., 2023; Choi et al., 2023) and LLM-based reranking (Qin et al., 2023; Zhuang et al., 2023), our selector autoregressively generates decision labels for keeping or discarding each candidate. This approach not only reduces the decoding search space but also fully considers the correlation between selections, thus effectively minimizing semantically repetitive selections. Moreover, we design an R-tuning S-infer strategy to help the selector comprehend the semantics of candidates."}, {"title": "3.1 The ONE2SET-based Generator", "content": "As an extension of SETTRANS, our generator also uses Transformer (Vaswani et al., 2017) as the backbone, of which the decoder is equipped with N control codes to individually generate candidate keyphrases. During the model training, ground-truth keyphrases $\\{y_i\\}_{i=1}^M$ or $\\emptyset \\ (y_i)$ are dynamically assigned to the control codes as supervision signals. Concretely, the model first predicts K tokens as the prediction $\\hat{y}_j$ for the j-th control code and then calculates a matching score $\\mu_{ij}$ between the ground-truth $y_i$ and the prediction $\\hat{y}_j$ via a pairwise matching function $C_{match}(*)$: \n$\\mu_{ij} = \\frac{C_{match}(y_i, \\hat{y}_j)}{\\sum_{j=1}^N C_{match}(y_i, \\hat{y}_j)},$ \nwhere T is a normalized hyper-parameter.\nThen, instead of using bipartite matching, we consider the assignments between ground-truths and control codes as an OT problem and search the optimal assignments with Sinkhorn-Knopp Iteration (Cuturi, 2013). Concretely, we consider the following crucial definitions in OT algorithm: 1) control codes are regarded as demanders with a demanding vector $\\{d_j\\}_{j=1}^N$, where $d_j$ represents the number of ground-truths assigned to the j-th control code; 2) ground-truths are regarded as suppliers with a supplying vector $\\{s_i\\}_{i=1}^M$, where $s_i$ represents the number of control codes that $y_i$ can be assigned to; 3) the cost matrix $\\{C_{ij}\\}_{i=1,j=1}^{M,N}$, where $C_{ij}$ represents the cost of assigning $y_i$ to the j-th control code. More specifically, we heuristically define them as follows:\nSince assigning multiple ground-truths to one control code at the same time may interfere with each other, we directly limit $d_j$ to 1.\nIntuitively, if $y_i$ is highly matched with more control codes, it should be assigned to more control codes. To this end, we define $s_i$ as a dynamic number positively correlated with $\\{\\mu_{ij}\\}_{j=1}^N$:\n$s_i = \\begin{cases} [\\sum topK(\\{\\mu_{ij}\\}_{j=1}^N, k)], & \\text{if } y_i \\neq \\emptyset \\\\ N - \\sum_{y_i \\neq \\emptyset} s_i, & \\text{otherwise.} \\end{cases}$ \nwhere [] indicates rounding up to an integer and k is a predefined hyper-parameter.\nTo model the intuition that the higher the matching score between $y_i$ and $\\hat{y}_j$, the lower the cost for assigning $y_i$ to the j-th control code, we define $C_{ij}$ as\n$C_{ij} = \\begin{cases} -\\mu_{ij}, & \\text{if } y_i \\neq \\emptyset \\\\ 0, & \\text{otherwise.} \\end{cases}$ \nHaving obtained the above vectors and matrix, we seek the optimal assignments $\\pi^*$ according to the following objective function:\n$\\pi^* = \\underset{\\pi}{\\arg \\min} \\sum_{i=1}^M \\sum_{j=1}^N C_{ij} \\pi_{ij}, \\quad \\pi \\in \\mathbb{R}^{M \\times N}$\ns.t. $\\sum_{i=1}^M \\pi_{ij} = d_j, \\quad \\sum_{j=1}^N \\pi_{ij} = s_i, \\quad \\sum_{i=1}^M s_i = \\sum_{j=1}^N d_j, \\quad \\pi_{ij} \\ge 0$.\nFinally, each control code is assigned with the ground-truth or \u00d8 that has the maximal assignment value as shown in the right of Figure 3. Note that we seek the optimal assignment plans $\\pi$ for present keyphrases and $\\pi$ for absent keyphrases, respectively, and subsequently calculate their cross-entropy losses accordingly."}, {"title": "3.2 The LLM-based Selector", "content": "After using the above generator to obtain candidate keyphrases, it is natural to focus on how to select high-quality keyphrases from them. However, through in-depth analysis, we find that both traditional keyphrase reranking methods and LLM reranking methods tend to output keyphrases with serious semantic repetition. To solve this problem, we propose to utilize LLMs to model keyphrase selection as a sequence labeling task. Furthermore, we design a random-tuning sorted-inference strategy that enables the selector to improve performance while retaining robustness to input order.\nSemantic Repetition As shown in Figure 4(a), existing reranking studies contain the following two types: 1) one first individually score each candidate and then keep the candidates with high scores (Choi et al., 2023; Zhuang et al., 2023), 2) the other directly ask LLMs to generate a sorted list of candidates without specific scores and save highest ranked candidates (Sun et al., 2023; Qin et al., 2023). However, when applying these methods to select keyphrases, they tend to assign similar ranks to candidates with similar semantics but different surface representations (i.e. \u201csafe problem\u201d and \u201csafe hazard\u201d).\nLLM-based Sequence Labeling To address the above-mentioned issue, we fine-tune an LLM to model keyphrase reranking as a sequence labeling task. Concretely, we input all candidates into the selector and then ask it to autoregressively output decision labels, each indicating whether to keep or discard the corresponding candidate. As shown in Figure 4(b), each kept candidate is mapped to the label \"T\" while each discarded one to \"F\". The instruction template we use is shown as follows:\n### Task Definition:\nYou are required to perform a sequence labeling task to select multiple keyphrases from the numbered candidates according to the given document. Use the label \"T\" to indicate the selection of a candidate and the label \"F\" to indicate its rejection. For instance, a label sequence \u201cT F F\u201d denotes selecting candidate [1] and rejecting candidates [2] and [3].\n### Input:\nDocument: {document}\nCandidates:\n[1] {candidate1}\n...\n[n] {candidaten}\n### Response:\nLabel sequence: {label_sequence}\nDuring autoregressive generation, the selector considers previous selections when deciding whether to keep or discard the current candidate. This approach not only reduces the decoding search space but also alleviates semantic repetition. In the example in Figure 4(b), the selector is able to discard \"safe hazard\u201d after keeping \u201csafe problem\u201d.\nR-tuning S-infer Strategy Intuitively, sorting candidates in a fixed order is beneficial for humans to select candidates. However, such sorting may cause the selector to select candidates based on their input order rather than truly understanding their semantics. To address this issue, we propose a R-tuning S-infer strategy to handle the candidates differently during the selector training and inference. Specifically, during instruction tuning, candidates are input into the selector in a random order, encouraging the selector to learn the semantics of candidates instead of order. By contrast, during inference, candidates are sorted by their quality measured with the average log probability of the generator. In this way, the selector can prioritize candidates more likely to be correct."}, {"title": "3.3 Two-stage Training", "content": "We adopt a two-stage training strategy to train our framework, where the generator is first trained with the keyphrase generation data, and the selector is then trained with the instruction data.\nGenerator Training With the optimal assignment plans $\\pi$ and $\\pi$ (See Section 3.1), we compute the cross-entropy losses for absent and present keyphrases, respectively, and combine these two losses with weighted summation to get the final loss. Please refer to Appendix C.3 for details.\nSelector Training When training the selector, we adopt the next-token-prediction task that has been widely used in LLMs. Particularly, due to the imbalanced numbers of positive and negative candidates, we design the following loss:\n$L(\\theta) = \\frac{1}{N_T} \\sum_{t=1}^{|Y|} \\mathbb{I}\\{Y_t = T\\} \\log P(Y_t|X, Y_{<t}) + \\frac{1}{N_F} \\sum_{t=1}^{|Y|} \\mathbb{I}\\{Y_t = F\\} \\log P(Y_t|X, Y_{<t}),$\nwhere $\\theta$ represents the parameters of the selector, $N_T$ and $N_F$ are the numbers of \u201cT\u201d and \u201cF\u201d, respectively, Y is the label sequence consisting of $N_T$ \u201cT\u201d and $N_F$ \u201cF\u201d, and X is the input excluding label sequence. The negative effect of label imbalance in tuning can be mitigated by averaging loss items with identical labels.\nIn our experiments, we adopt QLoRA (Dettmers et al., 2023) to perform quantization on model parameters for efficient training. As such, the trainable parameters in our model are about 0.06% of the original size."}, {"title": "4 Experiments", "content": "4.1 Setup\nDatasets. Following previous studies (Meng et al., 2017; Ye et al., 2021; Choi et al., 2023), we use the training set of KP20k to train all models and then evaluate them on five benchmarks: Inspec (Hulth, 2003), Krapivin (Krapivin et al., 2009), NUS (Nguyen and Kan, 2007), SemEval (Kim et al., 2010), KP20k (Meng et al., 2017).\nBaselines. We compare our framework with three kinds of baselines: 1) Generative Models: these models predict both present and absent keyphrases through generation. We consider following representative models, catSeq (Yuan et al., 2020) under ONE2SEQ along with its variant ExHiRD-h (Chen et al., 2020), and SetTrans (Ye et al., 2021) under ONE2SET along with its variant WR-one2set (Xie et al., 2022). Besides, since PLM has been widely applied in KPG, we also consider two competitive models, CorrKG (Zhao et al., 2022) and SciBART-large + TAPT + DESEL (Wu et al., 2023a). 2) Unified Models: these models integrate extractive and generative methods to predict keyphrases. We report the performance of the representative models including SEG-Net (Ahmad et al., 2021), UniKeyphrase (Wu et al., 2021), PromptKP (Wu et al., 2022) and SimCKP (Choi et al., 2023). 3) Composite Models: We additionally select several representative models combined like our framework.\nEvaluation Metrics. As implemented in previous studies (Chan et al., 2019; Zhao et al., 2022; Choi et al., 2023), We evaluate all models using macro-average F1@M, and further provide the F1@5 results in Appendix A. Both predictions and ground-truths are stemmed with the Porter Stemmer (Porter, 2006), and then the duplicates are removed before scoring.\nImplementation Details. We separately use Transformer-base (Vaswani et al., 2017) and LLaMA-2-7B (Touvron et al., 2023) to construct the generator and selector, both are optimized with Adam optimizer (Loshchilov and Hutter, 2019).\nWhen constructing the generator, we select the top 50,002 frequent tokens to build the vocabulary. To ensure the consistency with (Ye et al., 2021; Xie et al., 2022), the number of control codes N is 20, K is 2, learning rate is 0.0001, and batch size is 12. Through grid search in Appendix B.3, we set the following hyper-parameters in OT-based assignment: T = 10 in Equation 1 and Top-3 in Equation 2. During inference, we employ beam search with beam size = 10 and save all candidates for the subsequent selection.\nAs for the selector, we adopt QLoRA with r = 8, \u03b1 = 32, and dropout of 0.05. Note that, due to the significant performance gap between present keyphrases and absent keyphrases, we use the same instruction template to tune a LoRA module for each type of keyphrase. The LoRA is optimized with a learning rate of 3e-4 for absent keyphrase, a learning rate of 1e-4 for present keyphrase, per-gpu batch size of 24, and the maximum epoch of 5. Validations are performed every 1,000 iterations for present keyphrase and 400 iterations for absent keyphrase, respectively. Early stopping is triggered if the validation performance does not improve in 5 consecutive rounds. We save the model with the best F1@M score on validation set for testing. Particularly, we perform experiments with three random seeds and report the average results."}, {"title": "4.2 Main Results", "content": "The comparison results on the five testsets are shown in Table 2. As for the present keyphrase prediction, our framework significantly outperforms all baselines on all datasets, except for Inspec. In contrast, on the absent keyphrase prediction, our framework always performs best among all models. Note that as an extension of SciBART-large, + TAPT + DESEL is additionally trained in OAGKX (\u00c7ano and Bojar, 2020), which leads to its huge improvement on Inspec. Compared to other baselines, our framework still holds comparable performance on this dataset. Our generator combined with our selector outperforms other composite models, making it the best combination. When"}, {"title": "4.3 Ablation Study", "content": "In Table 3, we investigate the effect of each component on our framework to verify their validity. Following previous studies (Xie et al., 2022; Choi et al., 2023), we conduct experiments on two kinds of test sets: 1) in-domain, which is KP20k, and 2) out-of-domain, which is the combination of Inspec, Krapivin, NUS, and SemEval.\n(1) \u21d2bipartite matching. In this variant, we replace the OT-based assignment with bipartite matching and observe the performance degradation in both present and absent keyphrases. Furthermore, we compare the recall scores of our generator, SETTRANS, and WR-ONE2SET at the same precision level. From Figure 5, the recall of our generator consistently exceeds those of (Ye et al., 2021) and (Xie et al., 2022) with close accuracy. Both experiments demonstrate the effectiveness of our OT-based assignment.\n(2) \u21d2GenKP. In this variant, we tune the selector to generate the list of kept candidates directly. Compared to our selector, its prediction performance significantly drops, especially on out-of-domain datasets. We argue that the sequence labeling task adopted by our selector reduces the decoding space, thus effectively reducing the task difficulty and improving generalization.\n(3) \u21d2R-tuning R-inference. Unlike our selector, this variant inputs candidates into the selector in a random order during both training and inference, resulting in a slight performance drop. This indicates that our sorted-inference strategy helps the selector make better selections.\n(4) \u21d2S-tuning R-inference. Different from the above variant, this variant inputs candidates into the selector in a fixed order during training while in a random order during inference. Compared to R-tuning R-inference, we observe a more significant performance degradation, suggesting that the random-tuning strategy enhances the robustness of the selector to the input order.\n(5) \u21d2CE_loss. In this variant, we tune the selector with vanilla cross-entropy loss without loss item averaging. The removal of loss item averaging notably diminishes the performance of the selector, demonstrating the effectiveness of this operation. The fact that there are more incorrect candidates than correct ones leads to the overfitting of incorrect candidates when training with vanilla cross-entropy loss."}, {"title": "4.4 Diversity of Predicted Keyphrases", "content": "Following Wu et al. (2023b), we take emb_sim and dup_token_ratio as the diversity metrics. As shown in Table 4, the semantic repetition in the original candidate set is severe but significantly reduced by selection models. Among these methods, our selector obtains the lowest emb_sim and dup_token_ratio, demonstrating its effectiveness in reducing semantic repetition.\nPlease see Appendix B.1 for more experiments."}, {"title": "5 Related Work", "content": "The related works to ours mainly include keyphrase generation and keyphrase selection.\nKeyphrase Generation. Generally, KPG models are constructed under the following paradigms: 1) ONE2ONE (Meng et al., 2017), where keyphrases of each document are split and each keyphrase along with the document forms a training instance. During inference, top-K candidates are picked under beam search. 2) ONE2SEQ (Yuan et al., 2020), which treats KPG as a sequence generation task, concatenating keyphrases into a sequence according to a predefined order. 3) ONE2SET (Ye et al., 2021), which generates keyphrases as an unordered set conditioned on learnable control codes. Among these paradigms, ONE2SET excels in recall. Ye et al. (2021) utilize the bipartite matching to assign ground-truths or \u00d8 to control codes as the supervision signal. Furthermore, Xie et al. (2022) propose a re-assignment mechanism to refine the assignment results of the bipartite matching, which allows a proportion of control codes matched with \u00d8 to learn ground-truths.\nKeyphrase Selection. Currently, researchers (Song et al., 2021; Zhang et al., 2022; Kong et al., 2023) select keyphrases from candidates using reranking methods. The common practice is to perform phrase mining on n-grams within document to extract candidates. Recently, Choi et al. (2023) obtain present keyphrase candidates through data mining and absent keyphrase candidates from the KPG model. All the above methods individually score each candidate with PLMs and select those with high scores. However, this independent scoring leads to semantic repetition issue. With the rapid development of LLMs, researchers try to insert the candidates into prompt and instruct the LLMs to generate an ordered list (Sachan et al., 2022; Sun et al., 2023; Zhuang et al., 2023; Qin et al., 2023), which demonstrates impressive effectiveness in document reranking tasks.\nOverall, our work differs from previous studies for two main reasons. First, unlike (Xie et al., 2022), we treat the matching of control codes and ground-truths as an OT problem and propose an OT-based assignment strategy to refine the target assignment in the ONE2SET paradigm. Second, in contrast to current selection methods, we consider keyphrase selection as an LLM-based sequence labeling task, where the correlation between the current candidate and previous selections can be fully exploited."}, {"title": "6 Conclusion and Future Work", "content": "This paper introduces a generate-then-select framework that integrates a ONE2SET model and an LLM selector together, so as to fully leverage the high recall of the ONE2SET paradigm and powerful semantic understanding of LLM. The ONE2SET model acts as the generator and is optimized by our OT-based assignment to recall more correct candidates. The LLM acts as the selector that models the selection of keyphrase candidates as a sequence labeling task and reduces the semantic repetition through its long sequence modeling capability. Experimental results show that our framework achieves significant performance improvements compared to existing state-of-the-art models.\nIn the future, we tend to combine the generation and selection tasks into a multi-task learning framework, which further improves the synergy between the two tasks."}, {"title": "Limitations", "content": "While this paper introduces a generate-then-select framework for KPG that effectively combines the strengths of the ONE2SET paradigm and LLM, it has several limitations in terms of resource consumption. First, the LLM is inherently resource-intensive due to its large number of parameters, demanding significant computational power and memory. Second, the two-step process of generating and then selecting keyphrases is time-consuming, which can lead to relative inefficiency in practical applications. These factors combined make the proposed framework more resource-consuming and challenging to implement compared to single-model solutions."}]}