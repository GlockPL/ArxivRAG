{"title": "A Comprehensive Comparative Study of Individual ML Models and Ensemble Strategies for Network Intrusion Detection Systems", "authors": ["Ismail Bibers", "Osvaldo Arreche", "Mustafa Abdallah"], "abstract": "The escalating frequency of intrusions in networked systems has spurred the exploration of new research avenues in devising artificial intelligence (AI) techniques for intrusion detection systems (IDS). Various AI techniques have been used to automate network intrusion detection tasks, yet each model possesses distinct strengths and weaknesses. Selecting the optimal model for a given dataset can pose a challenge, necessitating the exploration of ensemble methods to enhance generalization and applicability in network intrusion detection. This paper addresses this gap by conducting a comprehensive evaluation of diverse individual models and both simple and advanced ensemble methods for network IDS. We introduce an ensemble learning framework tailored for assessing individual models and ensemble methods in network intrusion detection tasks. Our framework encompasses the loading of input datasets, training of individual models and ensemble methods, and the generation of evaluation metrics. Furthermore, we incorporate all features across individual models and ensemble techniques. The study presents results for our framework, encompassing 14 methods, including various bagging, stacking, blending, and boosting techniques applied to multiple base learners such as decision trees, neural networks, and among others. We evaluate the framework using two distinct network intrusion datasets, RoEduNet-SIMARGL2021 and CICIDS-2017, each possessing unique characteristics. Additionally, we categorize AI models based on their performances on our evaluation metrics and via their confusion matrices. Our assessment demonstrates the efficacy of learning across most setups explored in this study. Furthermore, we contribute to the community by releasing our source codes, providing a foundational ensemble learning framework for network intrusion detection.", "sections": [{"title": "I. INTRODUCTION", "content": "The primary aim of intrusion detection systems (IDS) is to detect unauthorized utilization, misuse, and exploitation of computer network systems by both internal users and external intruders [1]\u2013[3]. Traditional IDS designs typically operate under the assumption that the behavior of an intruder will deviate noticeably from that of a legitimate user and that many unauthorized actions are discernible. The potential of artificial intelligence (AI) has spurred the advancement of fully automated intrusion detection systems [4], [5]. Various AI methodologies have been employed to automate intrusion detection tasks, including neural networks [6], [7], decision trees [8], [9], logistic regression [10], [11], and random forest [12], [13].\nThe majority of these AI methods, with the exception of random forest, operate as standalone learning models where the combination of their decisions is not utilized by the IDS [14], [15]. Each of these AI models harbors its own constraints, such as a high false positive rate for certain models (for instance, approximately half of the major companies contend with 10,000 security alerts daily from AI-based threat monitoring tools [16]), and a high false negative rate for others (which poses a significant challenge in safety-critical computer network applications [17]).\nPrior Al-focused studies predominantly emphasized the classification accuracy of different AI algorithms without harnessing the collective potential of these diverse AI techniques. This inherent limitation has stressed the urgent necessity to exploit various ensemble learning methods to bolster IDS [18]\u2013[20].\nNumerous recent studies have begun delving into the utilization of ensemble learning with various AI models for IDS, as evidenced by works such as [21]\u2013[34]. Specifically, works like [23], [24], [26], [28], [29], [31], [32] have proposed ensemble learning frameworks for anomaly detection, focusing on binary classification to discern normal from anomalous traffic. Conversely, other studies [21], [22], [27], [30], [33], [34] have developed ensemble learning frameworks for classification of network intrusions, encompassing categories like Denial of Service (DoS) attacks, Port Scanning, Normal traffic, and others.\nThese frameworks employ ensemble learning techniques such as Boosting, Stacking, and Bagging, considering various base models like Decision Trees, Support Vector Machines, and Neural Networks. Primary evaluation metrics include traditional AI metrics like accuracy, precision, recall (true positive rate), F1 score, and false positive rates. While most studies utilize benchmark datasets for IDS, such as CICIDS-2017, KDD\u201999, NSL-KDD, and UNSW-NB15 [23], [28], [29], [33], some conduct tests on real networks like the Palo Alto network [31], and even in real-time scenarios, as demonstrated by the \"kitsune\" framework [24]."}, {"title": "II. RELATED WORK", "content": "An exemplary contribution in this domain is the work by [22], which focuses on generating a new dataset and benchmarking it using ensemble learning techniques. Another notable approach is showcased in [26], where ensemble procedures are employed to select the AI model variant with the best performance. However, a comprehensive evaluation of a wide array of AI methods across different intrusion datasets is lacking in these works, potentially impacting their general applicability. Each study tends to concentrate on a singular ensemble learning method to enhance the performance of a limited set of base models.\nThis paper aims to address the aforementioned gap by comprehensively evaluating diverse ensemble methods for network intrusion detection systems. We establish multiple Individual ML models and Simple and Advanced ensemble learning frameworks to assess such methods in the context of network intrusion detection. Leveraging prior works such as [21]\u2013[34], which have outlined various ensemble learning approaches, our framework can be categorized as follows.\n\u2022 Individual Models: The initial phase of the framework involves implementing individual models such as decision trees [8], [9], logistic regression [10], [11], and neural networks [6], [7]. This phase encompasses tasks like loading datasets (e.g., CICIDS-2017, and RoEduNet-SIMARGL2021), training the models, and assessing performance using metrics like accuracy, precision, recall, and F1 score.\n\u2022 Simple Ensemble Methods: The subsequent stage of the framework involves implementing simple ensemble methods such as averaging, max voting, and weighted averaging. Performance evaluation is conducted using metrics like accuracy, precision, recall, and F1 score.\n\u2022 Advanced Ensemble Methods: The third phase focuses on implementing advanced ensemble methods including bagging, boosting, stacking, and blending. Note that we consider random forest [12], [13] in this category since it is built based on bagging of many decision trees. Again, evaluation metrics like accuracy, precision, recall, and F1 score are used to assess performance.\n\u2022 Comparative Analysis: The final step entails evaluating all individual, simple, and advanced ensemble models to identify the most effective models for IDS and analyze the impacts of ensemble learning techniques.\nAdditionally, our study presents results for various ensemble model combinations, including bagging methods, stacking, and boosting, applied to multiple base learners such as decision trees, logistic regression, random forest, neural networks, among others. These distinctions highlight the novel contributions of our work compared to previous studies, as discussed in Related Work Section (Section II).\nWe conduct evaluations of our framework using two prominent network intrusion datasets, each with distinct characteristics. The first dataset, RoEduNet-SIMARGL2021 [35], is a recent collection from the SIMARGL project, supported by the European Union. Notably, to our knowledge, limited prior works has applied comprehensive ensemble learning methods to this dataset, as discussed in the related work section. This dataset comprises realistic network traffic data, including features derived from live traffic, rendering it highly suitable for network intrusion detection systems. The second dataset utilized in our evaluation is CICIDS-2017 [36], established by the Canadian Institute for Cybersecurity at the University of Brunswick in 2017. This dataset serves as a benchmark for intrusion detection and encompasses various attack profiles.\nFor each dataset, we assess various approaches, encompassing different base learners and variants of ensemble methods, applied to different AI models. The AI models under consideration include Logistic Regression (LR), Decision Trees (DT), K-Nearest Neighbors (KNN), Multi-Layer Perceptron (MLP), Adaptive Boosting (ADA), eXtreme Gradient Boosting (XGB), CatBoosting (CAT), Gradient Boosting (GB), Averaging (Avg), Max Voting, Weighted Averaging, and Random Forest (RF).\nFor all these models across both datasets, we present and analyze the evaluation metrics generated by our framework. We thoroughly discuss the results, providing insights into the performance of each method. Additionally, we categorize the AI models based on their performances on evaluation metrics with the datasets considered in this study. Notably, we rank these different methods in descending order of F1 score, offering a clear perspective on their effectiveness (given by performance on the network intrusion datasets).\nThis comprehensive evaluation allows us to identify the most promising approaches for network intrusion detection across different datasets and AI models, facilitating informed decision-making in the implementation of IDS. This work represents a significant advancement in bridging the gap in the application of ensemble learning methods for network intrusion detection systems (IDS). Through conducting extensive evaluations and comparisons of various metrics, we contribute to enhancing the understanding of these ensemble methods' efficacy in the realm of IDS.\nThe metrics employed in our evaluation encompass crucial network security requirements for AI models, including accuracy, precision, recall, and F1 score of intrusion detection methods, along with their corresponding runtimes. By thoroughly examining these metrics, we provide valuable insights into the performance and efficiency of different ensemble methods in detecting network intrusions. Our framework not only addresses existing limitations but also expands the application of ensemble learning techniques in network intrusion detection systems. By doing so, we pave the way for further advancements and enhancements in this research area, ultimately contributing to the development of more robust and effective network security solutions."}, {"title": "Summary of Contributions:", "content": "We summarize below our main contributions in this current work.\n\u2022 Evaluation of Individual and Ensemble Learning Methods: We conduct a comprehensive evaluation and comparison of various Individual ML models, along with various simple and advanced ensemble learning methods for network intrusion detection systems (IDS).\n\u2022 Assessment Across Diverse Metrics: Our evaluation considers a range of metrics crucial for network security requirements, including accuracy, precision, recall, and F1 score of intrusion detection methods, as well as their runtime performance.\n\u2022 Evaluation on Two Prominent Datasets: We evaluate our framework on two well-known network intrusion datasets with distinct characteristics: RoEduNet-SIMARGL2021 and CICIDS-2017. This allowed for a comprehensive analysis across different network intrusion scenarios.\n\u2022 Performance Ranking: We categorized AI models (individual and ensemble ones) based on their performances on evaluation metrics, ranking these methods in descending order of F1 score, providing valuable insights into the effectiveness of each approach.\n\u2022 Expansion of Ensemble Learning Applications for IDS: By demonstrating the efficacy of ensemble learning methods in network IDS, our work expands the application of these techniques in this critical research area, paving the way for further advancements.\n\u2022 Availability of Source Codes: We make our source codes available to the community for accessing the framework designed for network intrusion detection and for further development with new datasets and models."}, {"title": "III. BACKGROUND AND PROBLEM STATEMENT", "content": "This section outlines the fundamental concepts of network intrusion detection, highlights the hurdles posed by artificial intelligence (AI), underscores the necessity of ensemble learning, and elucidates the challenges inherent in evaluating these methodologies within the context of network intrusion detection tasks."}, {"title": "A. Types of Network Intrusions", "content": "Various network intrusion types exist, categorized within the widely recognized MITRE ATT&CK framework [37]. In our study, we address the primary network attacks outlined in this framework. Consequently, network traffic is broadly classified into the following categories:\nNormal traffic: This refers to regular network activity observed within the system.\nMalware / Malware Repository Information obtained regarding malicious software [MITRE ATT&CK ID: DS0004]: This refers to analyzing malware for traits that might link it to specific creators, like the compiler used, debugging traces, code similarities, or group identifiers related to particular MaaS providers. Finding overlaps in malware usage by different adversaries may suggest the malware was acquired rather than independently developed. In this context, overlapping features in malware used by various adversaries could indicate a shared quartermaster [38].\nPortScan (PS) / Network Service Discovery [MITRE ATT&CK ID: T1046]: PortScan involves an intrusion where the attacker conducts reconnaissance on the victim's computer. Often utilized as an initial step in an attack, it aims to identify vulnerabilities and potential entry points. The method involves sending connection requests to various ports, without finalizing the connection. Responses received from these ports help map potential entry points for exploitation [39].\nDenial of Service (DoS) / Network Denial of Service [MITRE ATT&CK ID: T1498]: This type of attack aims to disrupt the target's network availability. A common example involves the attacker continuously sending connection requests to a server. However, upon receiving acknowledgment from the server, the attacker fails to respond, leaving the server's resources tied up and eventually leading to its unavailability. For comprehensive classifications of DoS attacks, readers are referred to [40].\nBrute Force [MITRE ATT&CK ID: T1110]: This attack involves attempting all possible password combinations to gain unauthorized access to the victim's network. Attackers often leverage commonly used passwords in conjunction with this method. Success is more likely when users employ weak or easily guessable passwords [40].\nWeb Attack / Initial Access [MITRE ATT&CK ID: TA0001, T1659, T1189]: This category encompasses attacks conducted through web channels, exploiting vulnerabilities in web systems. For instance, attackers may exploit vulnerabilities in public-facing applications, leveraging software bugs, misconfigurations, or glitches to gain access to the application's underlying instance or container. Examples of such attacks include Drive-by Compromise [41]. However, it is noteworthy that while web attacks such as SQL injection (SQLi) and Cross-Site Scripting (XSS) are common, they typically do not directly provide initial access to a remote server [37].\nInfiltration / Initial Access [MITRE ATT&CK ID: TA0001]: This type of attack occurs when an unauthorized entity attempts to gain initial access to a system or application. It encompasses various techniques, including targeted spear phishing and exploiting vulnerabilities in public-facing web servers. The initial access gained through this attack can vary, ranging from simply changing a password to maintaining persistent access through legitimate accounts and external remote services.\nBotnet / Compromise Infrastructure [MITRE ATT&CK ID: T1584.005, T1059, T1036, T1070]: This type of attack involves the use of automated scripts executed remotely by attackers through hijacked devices. These scripts, known as bots, emulate human behavior and replicate it across multiple devices. The scripted nature of this technique enables scalability and easy deployment, making it an effective tool for targeting multiple attack points simultaneously. Consequently, botnets are a prevalent type of network attack.\nProbe Attack / Network Scanning or Surveillance [MITRE ATT&CK ID: T1595]: Probe attacks serve as the initial phase of a broader attack strategy. These attacks involve scanning a network to collect information or identify known vulnerabilities [42]. Armed with a map detailing the available machines and services within a network, attackers can leverage this information to seek out potential exploits. It is important to note that while port scanning represents a type of probe attack, not all probe attacks involve port scans. Some may target specific vulnerabilities or utilize alternative methods, such as ping sweeps [43] or DNS zone transfers [44]."}, {"title": "B. Intrusion Detection Systems", "content": "The escalating complexity of cyber attacks poses a substantial risk to critical infrastructure across diverse industries [45], [46]. As a result, IDS plays a pivotal role in defending computer network systems against malicious activities, whether perpetrated by internal users or external adversaries [47]. Conventional IDS architectures typically operate under the assumption that an intruder's actions will noticeably diverge from those of a legitimate user, thereby enabling the detection of many unauthorized activities [48]. With recent strides in artificial intelligence (AI) over the past decade, this architectural paradigm has facilitated the emergence of AI models capable of autonomously identifying network intrusions [49]."}, {"title": "C. Limitations of Base Learner Models", "content": "While AI models have greatly automated intrusion detection, their inherent complexity presents constraints due to the intricate nature of their learning and decision-making mechanisms. This complexity poses challenges for a single model to fully grasp the subtleties of datasets, resulting in difficulties in learning specific subsets and achieving satisfactory metrics for certain outcomes. This challenge is widespread across various AI models, such as Decision Trees (DT), K-nearest neighbors (KNN), Support Vector Machines (SVM), Deep Neural Networks (DNN), among others. Despite their high predictive accuracy in Intrusion Detection Systems (IDS), there persists a gap in attaining better accuracy, precision, recall, and F1 scores, particularly in error or attack scenarios (including a high false positive rate for some AI models [16] and a high false negative rate for others [17]). This issue is especially critical in safety-sensitive applications like network security through IDS. Consequently, there is a growing impetus to enhance performance and broaden the application of AI models in IDS. This has spurred the urgent need to employ diverse ensemble learning techniques to bolster IDS by leveraging the combination of different base learner models [18]\u2013[20]."}, {"title": "D. Key Advantages of Ensemble Methods", "content": "It is crucial to recognize that individual base learners possess distinct strengths and weaknesses. Depending on the specific application or task, one model may outperform others, adding complexity to the model selection process. Machine learning algorithms operate on diverse underlying principles. For instance, K-nearest neighbors (KNN), which clusters similar data around centroids, is sensitive to factors like the number of clusters (K), class outliers, and irrelevant features, besides being computationally demanding. Neural Networks (NN), on the other hand, typically require large datasets and substantial computational resources, while also being susceptible to variations in input data. Regression methods like Logistic Regression offer simplicity and interpretability but may struggle to capture intricate relationships, such as higher-order polynomials. Similarly, Decision Trees boast quick training times but can oversimplify problems, potentially leading to overfitting. Consequently, amalgamating these AI models through ensemble techniques can enhance their robustness, generalizability, and effectiveness in network intrusion detection tasks by leveraging their complementary strengths and mitigating their weaknesses.\nEnsemble Learning is a dynamic field that delves into the concept of harnessing the strengths of diverse base learners to enhance predictive performance. Among the most renowned ensemble techniques are Bagging, Boosting, Blending, and Stacking. Bagging, short for Bootstrap Aggregating, involves creating multiple subsets of the dataset through bootstrapping, wherein data points are sampled with replacement, and training separate instances of a machine learning model on each subset. These models are trained independently. The primary objective of Bagging is to mitigate overfitting and enhance generalization by leveraging the diversity among the models. In contrast, Boosting operates by sequentially training multiple instances of the same base model, with each subsequent model aiming to correct the errors made by its predecessors. Boosting achieves this by assigning higher weights or emphasis to misclassified data points, effectively prioritizing instances that were previously difficult to classify correctly. By iteratively refining the model's performance, Boosting endeavors to improve predictive accuracy and reduce bias in the final ensemble. Meanwhile, the Stacking method adopts a distinct approach by training a diverse array of base learners and utilizing their predictions as features to train a meta-model. This meta-model learns to combine the predictions of the base learners, effectively capturing complex relationships between features and the target variable.\nThe ensemble methods such as Bagging, Boosting, and Stacking offer sophisticated strategies for improving predictive performance by leveraging the collective intelligence of diverse base learners. By combining the strengths of individual models and mitigating their weaknesses, ensemble techniques pave the way for more accurate and robust predictions across a wide range of machine-learning tasks.\nIn our study, we investigate various ensemble learning approaches within our framework, exclusively utilizing base models for network intrusion detection tasks. This comparative analysis is conducted across two distinct datasets, each possessing unique characteristics, in order to gain a comprehensive insight into our proposed framework."}, {"title": "IV. FRAMEWORK", "content": "The primary objective of this study is to develop an ensemble learning pipeline aimed at enhancing result metrics across diverse datasets. Our framework aims to assist security analysts in selecting effective methodologies for identifying intrusions and classifying attacks on network traffic, thereby bolstering intrusion prevention measures within their scope. To achieve this, we delineate a methodological framework comprising key stages for investigating the efficacy of various ensemble learning techniques tailored for intrusion detection systems (IDS), shown in Figure 1."}, {"title": "A. Data Preprocessing", "content": "The CICIDS-2017 and RoEduNet-SIMARGL2021 datasets underwent thorough preprocessing for intrusion detection systems (IDS). For CICIDS-2017, duplicate records were removed, and missing values were imputed with the mean for the 'Flow Bytes/s' column. Leading space characters in feature names were also removed, and label encoding was applied to categorical data in the 'Label' column.\nSimilarly, for RoEduNet-SIMARGL2021, duplicate records were removed, columns with singular unique values were dropped, and missing values were filled with the mean values for respective columns. Categorical features were encoded into numerical values using the Ordinal Encoder. These preprocessing steps aimed to enhance data quality and consistency for subsequent analyses."}, {"title": "B. Model Selection and Used Techniques", "content": "In this section, we will explain the model selection process including the selection of individual base learners and the use of ensemble techniques such as simple and advanced ensemble techniques.\n1) The Individual Base Learner Models: We carefully selected a set of diverse and established base learners to leverage their complementary strengths.\n\u2022 Decision Trees: Decision trees are well-known for their simplicity and easy-to-understand nature. They provide an intuitive representation of the decision-making processes in the data.\n\u2022 Neural Networks: We focused on the intricacy and non-linearity of neural networks, especially the Multi-layer perceptron Classifier.\n\u2022 Logistic Regression: It is a benchmark model that provides insights into linear relationships in the data.\n2) The Simple Ensemble Techniques: In conjunction with individual base learners, we employed various simple ensemble techniques to enhance predictive performance. These techniques included:\n\u2022 Averaging Predictions: By averaging the predictions of multiple individual models, we aimed to reduce variance and improve overall prediction accuracy.\n\u2022 Max Voting: Employing a majority voting scheme, max voting aggregates predictions from multiple models and selects the most frequently occurring class label as the final prediction.\n\u2022 Weighted Averaging: Assigning weights to predictions from individual models based on their performance, weighted averaging allowed us to emphasize the contributions of more accurate models while mitigating the impact of less accurate ones. We explain how the weights are assigned in our experiments in the Evaluation Section.\n3) The Advanced Ensemble Techniques: To further bolster our ensemble model's efficacy, we delved into advanced ensemble techniques, comprising:\n\u2022 Bagging: Through bootstrap aggregating, bagging generates diverse subsets of the training data and trains multiple base learners on each subset. By averaging their predictions, bagging reduces variance and enhances model robustness. In this context, Random forests aggregate predictions from several decision trees to reduce overfitting and maintain robust predictive performance across different datasets.\n\u2022 Blending: Leveraging the outputs of multiple base learners as features, blending combines their predictions using a meta-learner to generate the final prediction. This technique harnesses the diversity of base learners to improve generalization.\n\u2022 Boosting: Sequentially training base learners to correct the errors of preceding models, boosting emphasizes the misclassified instances, thereby iteratively refining the model's predictive performance.\n\u2022 Stacking: Combining predictions from multiple base learners as features, stacking employs a meta-learner to learn the optimal combination of base learner predictions. This hierarchical ensemble technique leverages the diverse strengths of individual models to improve overall performance."}, {"title": "C. Model Implementation and Training", "content": "Following the meticulous selection of models, the implementation phase commenced, leveraging Python for the realization of our ensemble framework. Our implementation strategy began with the deployment of individual models, followed by the integration of simple ensemble techniques, culminating in the incorporation of diverse array of advanced ensemble techniques.\nIn order to make the best use of our high-performance system, we decided to use TensorFlow's distribution strategy, specifically tf.distribute.MirroredStrategy(). This strategy is designed for synchronous training across multiple GPUs within a single machine. It works by replicating the model's variables and computations across all available GPUs, which makes parallelism more efficient and speeds up the training process significantly. Each GPU independently computes gradients for a subset of the training data, and these gradients are aggregated across all GPUs to update the model's parameters. By synchronizing training across all GPUs, this approach maximizes GPU utilization, prevents inconsistencies, and ultimately accelerates the training process while improving overall efficiency. This strategy aligns perfectly with our goal of using our high-performance computer's computational resources to speed up model development and experimentation.\n1) Individual Model Implementation and Training: We implemented and trained each chosen base learner on its own, giving us the opportunity to explore its algorithms and performance characteristics in detail. With the help of Python's powerful libraries (scikit-learn), TensorFlow, Keras, we were able to implement and train decision trees and random forests as well as neural networks (especially Multi-layer Perceptron Classifier), as well as logistic regression models with ease. We implemented and trained the decision trees model, we utilized the scikit-learn library. DecisionTreeClassifier (DT) function was used to create a decision tree classifier object, and then we trained the classifier using the fit function with our training data. Similar approaches were followed for implementing and training other models, such as random forests, Multi-layer Perceptron Classifier, and logistic regression. Each model was instantiated using its respective class from scikit-learn, and then trained on training data using the \u201cfit\u201d function.\nAfter training each model, we utilized the \"predict\" function to test the trained models using the test dataset that we prepared. This allowed us to evaluate the performance of each model on unseen data.\nWe further evaluated the models by computing their accuracy using the \u201caccuracy_score\" function from scikit-learn. Additionally, we printed the classification report using the classification_report function to obtain precision, recall, and F1-score for each class. We then visualized the performance of the models using confusion"}, {"title": "D. Evaluation Metrics and Model Selection Rationale", "content": "Results' Metrics: To evaluate the performance of the selected models and techniques comprehensively, we employed four primary performance indicators: Accuracy, Precision, Recall, and F1 score. Additionally, runtime was considered as a metric to assess the computational efficiency of the models. These metrics collectively provide insights into the effectiveness and efficiency of the models in detecting intrusions.\nWe organized the results systematically to facilitate analysis and comparison across different models and techniques. This structured approach enables us to draw meaningful conclusions regarding the suitability and efficacy of the models for IDS applications.\nModel Selection Criteria: The models chosen for this study were selected based on several key factors. Primarily, their prevalence in prior research pertaining to Intrusion Detection Systems (IDS) ensured alignment with established literature, enabling effective comparison with seminal studies such as [40], [50]. Furthermore, these diverse ensemble learning methods had success in different applications. By adopting widely-used models, our research maintains consistency with existing methodologies, facilitating a robust evaluation of various models and ensemble learning techniques utilized in our investigation. In this context, we emphasize that we used different AI models with different working principles for our ensemble learning (i.e., the KNN uses a different reasoning from MLP that also uses a different reasoning than DT)."}, {"title": "E. Comprehensive Overview of Top Network Intrusion Features and Their Role in the Learning", "content": "In this subsection, we present a detailed list of the top network intrusion features along with their explanations for the two datasets under study, as they play a crucial role throughout the entirety of our paper. Tables I and II provide descriptions for each feature in the RoEduNet-SIMARGL2021 and CICIDS-2017 network intrusion datasets, respectively.\nTables I and II elucidate key features specific to the RoEduNet-SIMARGL2021 and CICIDS-2017 datasets. These tables serve to highlight significant features from each dataset, offering clarity and contextual understanding. However, it is essential to clarify that all features listed in Table IIIb were utilized in our preliminary experiments. This inclusive approach enabled us to fully exploit the datasets for our analysis of network intrusion detection. Notably, Table IIIb summarizes the overall composition of each dataset, encompassing the number of features."}, {"title": "V. FOUNDATIONS OF EVALUATION", "content": "In this section, we present a comprehensive evaluation aimed at addressing key research questions that underpin our study:\n1) What are the optimal individual ML models suited for a given network intrusion detection dataset?\n2) Which ensemble method exhibits superior performance on a given dataset?\n3) How do the evaluated methods within our framework perform across key metrics such as Accuracy, Precision, Recall, F1 Score, and runtime?\n4) What are the inherent limitations and strengths associated with the application of ensemble learning methods in the context of network intrusion detection?\nBefore delving into the detailed evaluation results, we provide a comprehensive overview of the experimental setup."}, {"title": "A. DataSet Description", "content": "RoEduNet-SIMARGL2021 Dataset [35]: This dataset stems from the SIMARGL project, a collaborative initiative supported by the European Union under the Horizon program, in conjunction with the Romanian Education Network (RoEduNet). It comprises authentic network traffic data, incorporating features derived from real-time traffic analysis. The dataset adheres to a structured data schema reminiscent of Netflow [53], a network protocol developed by CISCO for the purpose of capturing and monitoring network flows.\nCICIDS-2017 Dataset [36]: Serving as a benchmark for intrusion detection, this dataset was curated by the Canadian Institute for Cybersecurity at the University of Brunswick in 2017. It encompasses six distinct attack profiles, including activities such as brute force, heartbleed, botnet, Denial of Service (DoS), portscan, web attack, and infiltration attack. To establish a realistic context, the dataset incorporates background traffic generated through a B-Profile system [54], which captures various user behaviors based on popular network protocols."}, {"title": "B. Experimental Setup", "content": "Computing Resources: Our experiments were conducted on a high-performance computing (HPC) system equipped with robust hardware capabilities. The HPC configuration includes two NVIDIA A100 GPUs, 64 GPU-accelerated nodes, each boasting 256 GB of memory, and a single 64-core AMD EPYC 7713 processor running at 2.0 GHz with a power consumption of 225 watts. This setup enables a peak performance of approximately 7 petaFLOPs, making it exceptionally well-suited for intensive AI and machine learning tasks [55].\nCoding Tools: To ensure versatility and openness in our implementation, we utilized the Python programming language alongside various AI toolboxes such as Keras and ScikitLearn. Additionally, we leveraged essential libraries including Pandas and Matplotlib. By adopting these open-source tools, we aimed to facilitate transparency and reproducibility in our research endeavors."}, {"title": "C. Evaluation Metrics", "content": "In this study, the utilization of well-established evaluation metrics is crucial to ascertain the most effective model for integration within an Intrusion Detection System (IDS). Accuracy, precision, recall, and F1-score stand as quintessential performance evaluation metrics. These metrics are derived from four fundamental measures: true positive (TP), false positive (FP), true negative (TN), and false negative (FN) rates. The evaluation metrics are delineated as follows:\n\u2022 Accuracy [(TP +TN)/Total]: Signifies the proportion of accurately identified network traffic instances over the total data instances.\n\u2022 Precision [TP/(FP + TP)]: Measures the frequency with which the model accurately discerns an attack.\n\u2022 Recall [TP/(FN +TP)]: Measures the model's ability to correctly identify attacks (or intrusions). Recall is also referred to as the true-positive rate, sensitivity, or detection rate.\n\u2022 F1-Score [2TP/(2TN + FP + FN)]: Represents the harmonic mean of precision and recall."}, {"title": "D. AI Models", "content": "In this section, we outline the main AI models employed in our study.\n(i) Base Learners: We utilized four widely-used AI classification algorithms as base learners, namely: Multi-Layer Perceptron (MLP) [56] Decision Tree (DT) [57], Logistic Regression (LR) [58], and k-Nearest Neighbor (KNN) [59]. These AI methods form the foundation of our evaluation, allowing us to assess both their individual performances and their contributions to our network intrusion detection framework.\n(ii) Ensemble Methods: In addition to the base learners, our framework incorporates advanced ensemble techniques such as stacking, blending, boosting (including Cat Boosting (CAT) [60], Light Gradient-Boosting Machine (LGBM) [61], AdaBoost (ADA) [62], Gradient Boosting (GB) [63], Extreme Gradient-Boosting (XGBoost) [64]), Random Forest, and bagging techniques. Furthermore, we employ simpler ensemble methods like Voting [65], Averaging [66], and Weighted Averaging, alongside the aforementioned models. These ensemble methods enhance the robustness and accuracy of our intrusion detection system."}, {"title": "E. RoEduNet-SIMARGL2021 Analysis", "content": "Main Results: Table IV presents the performance metrics of various models on the RoEduNet-SIMARGL2021 dataset when utilizing all available features. Notably, the majority of models demonstrate remarkable performance across all metrics, with particularly high values for precision, recall, and F1 scores. The top-performing techniques and models, including Random Forest (RF), Decision Tree (DT), Average (Avg), Max Voting (Max_Vot), Stacking, and Bagging (Bag), consistently achieve perfect scores (1.00) across all metrics. This convergence suggests robust model performance across different ensemble techniques and underscores the efficacy of utilizing the complete feature set for classification.\nConversely, Logistic Regression (LR) and Multi-Layer Perceptron (MLP) exhibit comparatively lower performance metrics, indicating potential limitations in capturing the underlying patterns within the dataset.\nGiven the already optimal performance attained by several models, further optimization may yield marginal improvements at best. However, exploring alternative feature engineering strategies or investigating potential data augmentation techniques could offer avenues for enhancing model generalization and resilience to unseen data.\nRuntime Performance: Table V offers insights into the runtime performance of RoEduNet-SIMARGL2021 models, measured in seconds. Models such as Logistic Regression (LR) and Decision Tree (DT) demonstrate shorter runtimes, reflecting their computational efficiency. In contrast, ensemble methods and gradient boosting algorithms like Stacking, Average, and Gradient Boosting exhibit longer runtimes due to their inherent complexity and resource-intensive nature. However, their high performance across evaluation metrics justifies the computational investment, particularly in accuracy-sensitive applications.\nConsidering the extensive RoEduNet-SIMARGL2021 dataset comprising approximately 30 million samples, prioritizing models with optimal performance across metrics while balancing computational efficiency is crucial. Models like LR and DT emerge as promising candidates due to their shorter runtimes, making them attractive for scenarios with computational constraints. Conversely, models with longer runtimes, such as Blending (Bled) and Stacking, may require substantial resources. Nevertheless, their superior performance justifies resource allocation, especially in applications prioritizing precision and recall metrics.\nTo manage computational complexity for blending and stacking, experiments were conducted on a subset of the dataset, limiting the sample size to 20% through random sampling, ensuring manageable overhead while retaining analytical integrity."}, {"title": "F. CICIDS-2017 Analysis", "content": "Main Results: Table VI presents the performance metrics of various models on the CICIDS-2017 dataset when utilizing all available features. The table provides insights into the effectiveness of different machine learning algorithms in classifying network traffic. Notably", "Performance": "Table VII presents the runtime performance of various machine learning models on the CICIDS-2017 dataset, measured in seconds. Considering the importance of achieving optimal results while also minimizing computational overhead, runtime performance becomes a crucial factor in model selection. Among the models exhibiting perfect F1 scores (i.e., RF, DT), Decision Tree (DT) emerges as the most time-efficient option, requiring approximately four minutes for training and testing combined. This makes it an attractive choice for scenarios where computational resources are limited.\nMoving beyond models with perfect F1 scores, Logistic Regression (LR) stands out as the fastest option among those achieving relatively good performance across all metrics. Conversely, models like Bagging (Bag) and"}]}