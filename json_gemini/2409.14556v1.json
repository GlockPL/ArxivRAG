{"title": "RACOON: An LLM-based Framework for Retrieval-Augmented Column Type Annotation with a Knowledge Graph", "authors": ["Linxi Wei", "Guorui Xiao", "Magdalena Balazinska"], "abstract": "As an important component of data exploration and integration, Column Type Annotation (CTA) aims to label columns of a table with one or more semantic types. With the recent development of Large Language Models (LLMs), researchers have started to explore the possibility of using LLMs for CTA, leveraging their strong zero-shot capabilities. In this paper, we build on this promising work and improve on LLM-based methods for CTA by showing how to use a Knowledge Graph (KG) to augment the context information provided to the LLM. Our approach, called RACOON, combines both pre-trained parametric and non-parametric knowledge during generation to improve LLMs' performance on CTA. Our experiments show that RACOON achieves up to a 0.21 micro F-1 improvement compared against vanilla LLM inference.", "sections": [{"title": "Introduction", "content": "In recent years, researchers and data scientists have found abundant relational tables on the Web (Cafarella et al. [2008a,b], Bhagavatula et al. [2015]). Despite their high quality, these Web Tables often miss important meta information such as column headers and relationships between columns (Suhara et al. [2022]). This information is essential for downstream tasks such as data quality control (Schelter et al. [2018]) and data discovery (Chapman et al. [2020]). A key step in recovering this meta information is Column Type Annotation (CTA), which aims to assign one or more semantic type(s) to columns in a given table.\nThus, there has been increasing interest and effort recently in developing methods that can automati-cally assign semantic labels to columns (Deng et al. [2022], Suhara et al. [2022], Miao and Wang [2023]). Recent work (Kayali et al. [2024], Feuer et al. [2023]) argues that relying on Pre-trained Language Models (PLMs) is not sufficient because they need task-specific and dataset-specific fine-tuning with carefully labeled training dataset to achieve reasonable results. On the other hand, the recent development of Large Language Models (LLMs) (Radford et al. [2018], Brown [2020], Ouyang et al. [2022]) with pre-trained parametric memory has opened the possibility of bridging this gap by requiring minimal or even no training examples to achieve promising performance.\nThere has been much research effort in developing effective solutions that utilize LLMs for CTA and related tasks. One initial attempt to apply LLMs for various table-related tasks is from (Narayan et al. [2022]). For CTA specifically, one line of work (Korini and Bizer [2023]) directly applies"}, {"title": "Racoon's Approach", "content": "We now describe the RACOON framework. The overall workflow is shown in Figure 2. Besides a CTA query, RACOON also requires an external KG and an LLM. Note that RACOON treats the KG and LLM as black-boxes and does not require any modifications, thus enjoying a plug-and-play property. For clarity of presentation, we describe how RACOON works with a CTA query on a single column, but RACOON can process CTA queries on an arbitrary number of columns.\nRetriever. Inside the Retriever, the Parser first parses the input table based on the query. Given a table T with a column Colm to perform single-column CTA, the Parser selects C cells from Colm for retrieval purposes. As of now, RACOON uses all cells, and we leave the problem of selecting the"}, {"title": "Experiments", "content": "Setup. We evaluate RACOON using the GPT-3.5 model (Ouyang et al. [2022]) and Wikidata KG (Vrande\u010di\u0107 and Kr\u00f6tzsch [2014]) on the full test set of the WikiTables-TURL-CTA benchmark (Deng et al. [2022]) consisting of 13,025 columns extracted and annotated in a multi-label manner\nusing 255 Freebase's types by the TURL team from the WikiTable corpus. The dataset provides a ground truth entity ID (Wikipedia page ID) linked to each cell in the table. On average, tables in this dataset have a mean of 21 rows and 4 entity columns (columns with at least one linked cell).\nBaselines. We compare RACOON against a vanilla LLM method on CTA. Notably, both CHORUS and ArcheType (Kayali et al. [2024], Feuer et al. [2023]) applies such vanilla LLM inference.\nEvaluation. We first use the ground truth entity ID linked to each cell labeled in the WikiTables-TURL-CTA dataset as the output of the KG-Linker to retrieve information from the KG. This enables us to evaluate our approach assuming a perfect KG-Linker. The results show that both augmented prompts using ENTITY-TRIPLETS and ENTITY-LABELS outperform vanilla LLM inference, with ENTITY-TRIPLETS achieving the best performance overall. This highlights the potential of retrieving more comprehensive information about column cells from the KG.\nSecond, we evaluate RACOON's performance with different KG-Linkers: MediaWiki API (with action=websearchentities) and a SOTA entity linking model, ReFinED ( Ayoola et al. [2022]). With either KG-linker, Racoon continues to outperform the baseline, although its performance (both ENTITY-LABELS and ENTITY-TRIPLETS) drops compared with the ground-truth linker and the drop is higher for ENTITY-TRIPLETS, showing that collecting extended information is not as helpful when the initial linked entity is incorrect. The drop is less with the ReFinED KG-linker, showing that SOTA KG-linkers suffice to make our approach beneficial.\nBecause LLMs often underperform in the multi-label dataset setting due to the large number of possible answer combinations, we further test RACOON in the single-label setting: If the model prediction falls within the ground truth label set, we set the ground truth label to be the model prediction. Otherwise, we count it as an incorrect prediction. In this setting, the performance of both the baseline and RACOON improves. RACOON with ReFinED significantly outperform the baseline, with ENTITY-TRIPLETS giving the best results."}, {"title": "Conclusion", "content": "We presented a novel end-to-end LLM-based framework RACOON for Column Type Annotation (CTA) unifying vanilla LLM and Knowledge Graph (KG) augmented inference. RACOON has three components: a Retriever for retrieving knowledge from a KG; a Processor for post-processing the retrieved content; and an Augmentor for composing the final prompt. Experiments show that RACOON consistently outperforms vanilla LLM for CTA."}]}