{"title": "UPCMR: A Universal Prompt-guided Model for Random Sampling Cardiac MRI Reconstruction", "authors": ["Donghang Lyu", "Chinmay Rao", "Marius Staring", "Matthias J.P. van Osch", "Mariya Doneva", "Hildo J. Lamb", "Nicola Pezzotti"], "abstract": "Cardiac magnetic resonance imaging (CMR) is vital for di- agnosing heart diseases, but long scan time remains a major drawback. To address this, accelerated imaging techniques have been introduced by undersampling k-space, which reduces the quality of the resulting images. Recent deep learning advancements aim to speed up scanning while pre- serving quality, but adapting to various sampling modes and undersam- pling factors remains challenging. Therefore, building a universal model is a promising direction. In this work, we introduce UPCMR, a univer- sal unrolled model designed for CMR reconstruction. This model incor- porates two kinds of learnable prompts, undersampling-specific prompt and spatial-specific prompt, and integrates them with a UNet structure in each block. Overall, by using the CMRxRecon2024 challenge dataset for training and validation, the UPCMR model highly enhances recon- structed image quality across all random sampling scenarios through an effective training strategy compared to some traditional methods, demonstrating strong adaptability potential for this task.", "sections": [{"title": "1 Introduction", "content": "Cardiac Magnetic Resonance Imaging often requires multiple breath-holds for a comprehensive heart scan, leading to potential patient discomfort and slice mis- alignment. Moreover, the combination of data from multiple cardiac cycles can be problematic, especially in cases of arrhythmia, limiting real-time imaging to lower spatio-temporal resolutions. To address these challenges, undersampling techniques have been explored over the years to accelerate the whole scanning process. In recent years, deep learning methods [12,15,16] have gained signifi- cant attention and are increasingly being used for MRI reconstruction, aiming to restore image details effectively, even with high acceleration factor. However,"}, {"title": "2 Preliminaries and Dataset", "content": "Consider reconstructing a sequence of complex-valued MR images $x \\in \\mathbb{C}^{T\\times H\\times W}$ from multi-coil undersampled k-space measurements y, where H and W denote the height and width of each frame, respectively, T represents the sequence length. Therefore, the goal is to reconstruct x from y, formulated as\n$\\underset{x}{\\text{argmin }} ||y - Ax ||_2^2 + \\lambda R(x)$,\nwhere A is the linear forward operator composed of coil sensitivity encoding S, 2D Fourier transform F, and undersampling mask M, R represents the regulari- sation terms with $ \\lambda $ as a hyper-parameter controlling the regularization strength. For deep unrolled methods, R represents a trainable neural network block. Some previous deep unrolled models based on the ADMM optimization algorithm such as Deep-ADMM net [17] introduce an intermediate variable z, also computed via a learnable block. When constraining z to be equal to x, the above problem is reformulated as\n$\\underset{x,z}{\\text{argmin }} ||y - Ax||_3^2 + \\mu||x \u2212 z||_3^2 + \\lambda R(z)$"}, {"title": "2.2 CMRxRecon2024 Dataset", "content": "The CMRxRecon2024 dataset [19] includes data from 330 healthy volunteers scanned with 3 Tesla magnets. Task 2 features multi-contrast k-space data (Cine, Aorta, Mapping, Tagging) with anatomical views such as long-axis, short-axis, LVOT, and aortic views (transversal and sagittal). Each contrast consists of 5- 15 slices, segmented into 12-25 cardiac phases with a temporal resolution of 50 ms. Key geometrical parameters are a spatial resolution of 1.5\u00d71.5 mm\u00b2, slice thickness of 8.0 mm, and a slice gap of 4.0 mm. The dataset includes three k- space trajectories (uniform, Gaussian, pseudo radial) with temporal/parametric interleaving, and various acceleration factors (4\u00d7, 8x, 12x, 16x, 20x, 24x) without including autocalibration signal (ACS) for calculation. For the ACS area, it includes the central 16 lines for uniform and Gaussian types, and the central 16\u00d716 regions for the pseudo radial type. Training data includes 200 subjects with fully-sampled k-space data across all combinations of k-space trajectories and acceleration factors, while 60 validation subjects are provided with random undersampling settings. The ground-truth of validation set is unavailable, and performance is assessed by submitting the reconstructed central cropped parts of the images to the platform."}, {"title": "3 Methodology", "content": "UPCMR We follow an unrolled design used by some previous methods [12,20], as shown in Fig. 1. From a global perspective, in addition to common inputs like undersampling k-space, corresponding mask, coil-combined image sequence with 2 channels, and coil sensitivity map, an undersampling-specific prompt embedding is also provided as input. Given that both k-space trajectory and acceleration factor are prior information, we build two learnable prompt pools:"}, {"title": "3.2 Loss Function", "content": "Given the three outputs of UPCMR, the loss function comprises the classification loss $L_{cls}$ and the reconstruction loss $L_{rec}$. The $L_{cls}$ is the sum of the cross-entropy losses for the k-space trajectory class and the acceleration factor class. The $L_{rec}$ is the weighted sum of an L1 loss term and an SSIM loss term, defined as follows:\n$L_{rec} = \\lambda_{l1} ||I_{rec} - I_{gnd}||_1 + \\lambda_{SSIM} (1 \u2013 SSIM(|I_{rec}|, |I_{gnd}|)),$\nwhere $I_{rec}$ denotes the reconstructed CMR image sequence and $I_{gnd}$ represents the original ground-truth image sequence, both of which are double-channeled. For the SSIM loss calculation, we use the absolute value to compute the loss."}, {"title": "3.3 Training Strategy", "content": "For random undersampling, an efficient training strategy is essential. Given thou- sands of slices, each with 3\u00d76=18 different undersampling scenarios, iterating through all in each epoch is time-consuming and impractical under the situa- tion of limited GPU resource. Therefore, our policy is to randomly pick a slice with a random k-space trajectory and acceleration factor for each training sam- ple. This approach highly reduces training time and ensures the model can still handle diverse scenarios.\nAnother challenge is the varying difficulty of reconstruction across different undersampling modes, where, for example, an acceleration factor of 24 is much more difficult than one of 4. Therefore, equally random sampling might not be an optimal strategy for the model training. Inspired by the concept of curriculum learning [1] and its extensive applications [7,21], we explore incorporating this method into our model training process. Firstly, we trained the model for 90 epochs, divided into four stages:\n1. Train the model for 10 epochs using {uniform} k-space sampling and an acceleration factor of {4}.\n2. Train the model for 20 epochs using {uniform, gaussian} k-space with the sampling probabilities {0.2, 0.8} and acceleration factors {4, 8, 12} with the sampling probabilities (0.04, 0.48, 0.48}.\n3. Train the model for 30 epochs using {uniform, gaussian, pseudo_radial} k- space with the sampling probabilities {0.1, 0.1, 0.8} and acceleration factors {4, 8, 12, 16, 20, 24} with the sampling probabilities {0.02, 0.02, 0.03, 0.31, 0.31, 0.31}.\n4. Train the model for 30 epochs using all the k-space and all the acceleration factors with the equal sampling probability.\nIn the above 4 stages, we start with easier cases to help the model grasp basic reconstruction principles and adapt to less noisy data. Gradually, we introduce more complex k-space trajectories and higher acceleration factors to increase difficulty. The final stage involves combined training, which further boosts the model's adaptability.\nAlthough the above training strategy aligns with curriculum learning prin- ciples, using the same full model structure and expecting it to handle multiple acceleration factors may not be optimal. This approach increases the training difficulty of the UPCMR model, making it harder to learn and differentiate be- tween these internal variations. Moreover, assigning the optimal sampling prob- abilities at each stage can be challenging, which may hinder the model's overall"}, {"title": "4 Experiments", "content": "During training, we generated the coil sensitivity map (CSM) from the time- averaged autocalibration signals (ACS) using the ESPIRIT algorithm [18]. The"}, {"title": "4.2 Results", "content": "We compare the proposed model with two traditional methods, SENSE and GRAPPA, on the given validation set. Some ablation studies evaluate (1) the effectiveness of curriculum learning versus a combined learning strategy, where"}, {"title": "5 Discussion and Conclusion", "content": "Table 1 shows that each key component block enhances performance, and the curriculum learning strategy outperforms the combined learning approach. More- over, the second curriculum training strategy has been proven more effective,"}]}