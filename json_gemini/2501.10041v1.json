{"title": "Spatiotemporal Prediction of Secondary Crashes by Rebalancing\nDynamic and Static Data with Generative Adversarial Networks", "authors": ["Junlan Chen", "Yiqun Li", "Chenyu Ling", "Ziyuan Pu", "Xiucheng Guo"], "abstract": "Data imbalance is a common issue in analyzing and predicting sudden traffic events.\nSecondary crashes constitute only a small proportion of all crashes. These secondary crashes,\ntriggered by primary crashes, significantly exacerbate traffic congestion and increase the severity\nof incidents. However, the severe imbalance of secondary crash data poses significant challenges\nfor prediction models, affecting their generalization ability and prediction accuracy. Existing\nmethods fail to fully address the complexity of traffic crash data, particularly the coexistence of\ndynamic and static features, and often struggle to effectively handle data samples of varying\nlengths. Furthermore, most current studies predict the occurrence probability and spatiotemporal\ndistribution of secondary crashes separately, lacking an integrated solution. To address these\nchallenges, this study proposes a hybrid model named VarFusiGAN-Transformer, aimed at\nimproving the fidelity of secondary crash data generation and jointly predicting the occurrence and\nspatiotemporal distribution of secondary crashes. The VarFusiGAN-Transformer model employs\nLong Short-Term Memory (LSTM) networks to enhance the generation of multivariate long-time\nseries data, incorporating a static data generator and an auxiliary discriminator to model the joint\ndistribution of dynamic and static features. In addition, the model's prediction module achieves\nsimultaneous prediction of both the occurrence and spatiotemporal distribution of secondary\ncrashes. Compared to existing methods, the proposed model demonstrates superior performance\nin generating high-fidelity data and improving prediction accuracy.", "sections": [{"title": "1 INTRODUCTION", "content": "Data imbalance is a common issue in many fields, such as traffic management and medical\ndiagnosis, posing significant challenges for prediction and analysis. In the field of traffic\nmanagement, secondary crashes are typically defined as those triggered by a primary crash within\na certain spatial and temporal range. These secondary crashes can exacerbate traffic congestion,\nincrease the severity of incidents, and even lead to more casualties. Thus, preventing secondary\ncrashes has become an important task in traffic safety management. However, due to the inherent\ndata imbalance (secondary crashes usually account for less than 2% of all crashes), predicting\nsecondary crashes remains highly challenging, as the imbalance significantly affects the\ngeneralization ability of prediction models. Moreover, existing studies tend to focus on minimizing\noverall errors in temporal and spatial predictions, often overlooking the precision in the number of\nsecondary crashes. Additionally, the limited data available for secondary crashes makes it difficult\nfor prediction models to capture sufficient feature patterns. Therefore, addressing the imbalance\nin secondary crash data is of utmost importance.\nResearchers have proposed various methods to address data imbalance, which can be broadly\ncategorized into dynamic data generation methods and static data generation methods. Dynamic\ndata generation methods primarily target continuous time-series data. These methods often employ\ndeep learning-based generative models, such as Time Series Generative Adversarial Networks\n(TimeGAN) (7) and Variational Autoencoders (VAE) (8; 9), to generate new time-series data.\nHowever, for multivariate, long time-series traffic crash data, existing generative models face\nchallenges in capturing the complex temporal and spatial relationships within the data. Compared\nto short time-series data, the dependencies between data points in long time series become more\ncomplex as the time span increases, undergoing multiple nonlinear transformations, which makes\nit difficult for models to effectively capture them (10). Additionally, as time progresses, more\nvariables and interfering factors further increase the learning difficulty (11). Static data generation\nmethods mainly target discrete data or independent continuous data unaffected by time. These\nmethods include traditional over-sampling and under-sampling techniques, such as Synthetic\nMinority Over-sampling Technique (SMOTE) (12) and Adaptive Synthetic Sampling (ADASYN)\n(13). These methods balance datasets by generating new samples or adjusting the weights of\nexisting samples. Due to the complex feature distribution of traffic crash data, simple over-\nsampling or under-sampling methods often fail to effectively capture the intrinsic patterns of the\ndata, leading to suboptimal performance when dealing with complex traffic crash data (14).\nFurthermore, as secondary crashes may occur at different time points after a primary crash, the\nsample data for secondary crashes contains complex multidimensional data of varying time lengths,\nwhich existing generative models cannot effectively handle. Overall, current generative models\nface three main issues when handling traffic crash data: First, for multivariate, long-time series\ndata, generative models perform poorly and struggle to capture the complex temporal and spatial\nrelationships within the data. Second, no suitable model exists to generate complex\nmultidimensional traffic crash data combining both static and dynamic data. Third, existing\nmethods cannot generate samples of varying lengths. Therefore, effectively generating high-\nfidelity secondary crash data remains a significant challenge.\nCurrent research on secondary crashes can be divided into identification and prediction. In\nterms of identification, early studies mainly used fixed spatiotemporal threshold methods,\nassuming secondary crashes occur within a certain spatiotemporal range of the initial crash. The\nlimitation of this method lies in the subjective determination of thresholds. To overcome this\nlimitation, subsequent research proposed various dynamic identification methods, such as speed\ncontour methods. In terms of prediction, existing studies mainly explore the impact of initial crash\ncharacteristics, weather conditions, and traffic volume on the likelihood of secondary crashes. In\nrecent years, with the rapid development of machine learning technologies, algorithms such as\nSupport Vector Machines and Neural Networks have been widely applied to secondary crash\nprediction, achieving better predictive performance than traditional Logit models. Despite this,\nmost existing studies separate the likelihood of secondary crash occurrence from their\nspatiotemporal distribution, predicting them independently. In fact, predicting the specific\nspatiotemporal distribution is only meaningful under the premise that a crash has indeed occurred.\nTherefore, constructing a dynamic model capable of simultaneously predicting the probability and\nspatiotemporal distribution of secondary crashes is crucial for uncovering the intrinsic\nrelationships between crashes and developing proactive crash management strategies.\nIn summary, current research on secondary crash prediction faces three main problems: first,\nthe severe imbalance of secondary crash data affects the generalization ability and accuracy of\npredictive models. Second, existing methods for handling imbalanced data are insufficient to\naddress the complexity of traffic crash data, where dynamic and static features coexist, particularly\nthe inability to generate samples of varying lengths. Lastly, current studies often predict the\nprobability of secondary crash occurrence and their spatiotemporal distribution separately, lacking\na dynamic model that can predict both simultaneously. In light of these issues, this paper proposes\na hybrid model named VarFusiGAN-Transformer, designed to enhance the fidelity of secondary\ncrash data generation and jointly predict the occurrence probability and spatiotemporal location of\nsecondary crashes. The specific contributions of this paper are as follows:\n1. A Long Short-Term Memory (LSTM) network is used instead of Multilayer Perceptrons\n(MLP) to develop a new generator in the DG. Batch generation methods are used to capture"}, {"title": "2 LITERATURE REVIEW", "content": "With the rapid development of deep learning technology, dynamic data generation methods\nhave made significant progress in handling time series data. These generation methods primarily\ntarget continuous time series data by capturing the intrinsic spatiotemporal relationships within the\ndata to achieve data augmentation. The GAN model has been widely applied in time series\ngeneration due to its flexibility and specialized generation mechanism. Yoon et al. proposed a\ngeneration framework called TimeGAN, which leverages the flexibility of GAN and the control\ncapability of autoregressive models over temporal dynamics. It uses an embedding network to map\ndata into a low-dimensional latent space to enhance training effectiveness, generating high-quality\ntime series samples across multiple datasets(7). For imbalanced crash data, Cai et al. introduced\nconvolutional neural networks to construct generators and discriminators to better recognize and\ncapture traffic data features(8). Additionally, models such as SigCWGAN(25), TSGAN(26) and\nTTS-CGAN(27) have also achieved time series data generation. However, the aforementioned\nmethods still cannot resolve issues like mode collapse caused by GAN models. Therefore,\nresearchers have attempted other methods in recent years. For instance, Desai et al. combined\nvariational autoencoders (VAE) with time series characteristics and proposed a generation model\nnamed TimeVAE(9). Lee et al. used vector quantization to map time series into a discrete latent\nspace and employed a bidirectional Transformer model for dynamic capturing, achieving\nsignificant performance improvements in time series generation tasks(27). However, due to the\ncomplex spatio-temporal dependencies in long time series traffic data and the introduction of\ndisturbing variables over time, existing generative models still face many challenges in improving\nthe fidelity of the generated data.\nIt is worth noting that generative models such as VAE and GAN are mainly designed for\ncontinuous variables, while in traffic crash data, dynamic data and static data often exist at the\nsame time. Therefore, how to effectively generate composite samples containing these two types\nof data is an important and challenging research topic. Traditional oversampling(28) and\nundersampling(29) techniques have many limitations when processing such complex data. These\nmethods may destroy the intrinsic structure of time series data, resulting in information loss, and\nmay generate synthetic samples that do not conform to the actual situation(30). To address this,\nsome researchers have developed advanced generative models suitable for both dynamic and static\nvariables. For instance, Chen et al. proposed a hybrid resampling method based on Conditional\nTabular GAN (CTGAN-RU) to tackle the imbalance problem of fatal crashes relative to non-fatal\ncrashes. This method effectively handles scarce discrete variables and generates high-fidelity\ncomposite data(31). Park et al. combined deep convolutional GAN with classifier neural networks\nto propose a model called TableGAN(32), which improves the consistency of two types of data in\ngenerated records. Medical Wasserstein GAN (MedWGAN) uses gradient penalty and boundary-\nseeking GAN to generate more realistic synthetic medical records(33). However, the high-\ndimensional and long time series traffic crash data exhibit complex dynamic relationships and\nmixed distribution characteristics(10). The data sparsity and long-term memory challenges\nincrease the difficulty of the generation task, making it difficult for existing methods to generate\ndata that meets the requirements of crash prediction models.\nSince traffic crash data usually does not categorize primary and secondary crashes,\nidentifying secondary crashes is typically the first step in research. Early methods for identifying\nsecondary crasehes mainly used static approaches. These methods utilized predefined\nspatiotemporal thresholds to identify secondary crashes. For example, Raub(15) first proposed\nusing spatiotemporal thresholds of 15 minutes and 1 mile to identify secondary crashes.\nSubsequently, Moore(16) and Hirunyanitiwattana(17) selected different ranges for secondary\ncrash identification. However, the fixed thresholds of static methods cannot accurately reflect\nchanges in actual traffic conditions, leading to the application of dynamic methods in secondary\ncrash identification(18). Dynamic methods include approaches based on queue theory(34),\nshockwave theory(35), and speed contour maps(18). Among these, the speed contour map method\ndetermines the spatiotemporal impact range of crashes using real-time traffic flow data and is\ncurrently one of the more popular methods in research. Secondary crash prediction methods mainly\nfocus on predicting the likelihood of a primary crash causing a secondary crash and the\nspatiotemporal distribution of secondary crashes. Early prediction models often used statistical\nmodels, with the logit model being one of the most commonly used methods(36; 37). In recent\nyears, with the development of machine learning and deep learning technologies, prediction\nmodels based on these technologies have gradually become mainstream. For example, Park et al.\nproposed a secondary crash prediction model based on Bayesian Neural Network (BNN),"}, {"title": "3 METHODS", "content": "achieving better results than traditional Logit models(24). Liu et al. used an improved Random\nForest model to predict the spatiotemporal location of secondary crashes, showing that this model\noutperforms K-Nearest Neighbors and Multilayer Perceptron Regression models in prediction\nperformance(4). Additionally, hybrid models combining multiple deep learning algorithms can be\nconsidered for predicting the spatiotemporal location of secondary crashes. More complex models\nmay have better predictive performance. For instance, Li et al. proposed a hybrid deep learning\nmodel that combines Stacked Sparse Autoencoders (SSAE) and Long Short-Term Memory\n(LSTM) networks, capable of extracting key features, capturing long-term dependencies, and\nperforming nonlinear fitting. The results indicate that compared to single models, the hybrid model\nperforms better in both spatial and temporal predictions(3).\n3.1 Overview of VarFusiGAN-Transformer Model\nThis study proposes a hybrid model named VarFusiGAN-Transformer, which aims to predict\nboth the occurrence probability and the spatiotemporal distribution of secondary crashes by\nintegrating generative and predictive components. The model consists of two main parts: the\ngenerative component (VarFusiGAN) and the predictive component (Transformer). The\ngenerative component is responsible for generating high-fidelity synthetic secondary crash data,\nwhile the predictive component performs precise spatiotemporal predictions. By combining these\ncomponents, the VarFusiGAN-Transformer model enhances data diversity, improves data balance,\nand ultimately increases prediction accuracy and robustness for secondary crashes. The structure\nof the model is shown in Figure 3.\n3.1.1 Generative Component: VarFusiGAN\nThe generative component, VarFusiGAN, is designed to address the challenges of generating\nmultidimensional composite data that include both dynamic (time-series) and static features. The\nVarFusiGAN model leverages Generative Adversarial Networks (GANs) and incorporates the\nfollowing key innovations:\n(1) Capturing Multivariable Correlations\nIn the research related to traffic crashes, data samples usually contain more variables and\nlonger time series. This imposes higher demands on the generator to capture the multivariable"}, {"title": "4 DATA PREPARATION", "content": "correlations in dynamic data. Traditional GAN generators typically use a fully connected\nmultilayer perceptron (MLP) architecture, which performs poorly in capturing complex inter-\nvariable relationships. Long Short-Term Memory (LSTM) networks, designed for modeling time\nseries, have been widely used in GAN models for generating time series data. Therefore, we use\nLSTM instead of MLP for generating multivariable time series data.\nFor a single variable, unlike MLPs which generate an entire time series at once, LSTMs\ngenerate one record $R_{ij}$ at a time (the variable i at the jth time step) and run for T (the number\nof time steps) iterations to generate the entire time series for that variable. The main feature of\nLSTM is its internal state, which can encode and store all past states. For example, when generating\nthe flow value at the jth time step, it can combine all flow values from the previous j\u22121 time\nsteps, ensuring the fidelity of a single variable over the entire period.\nDue to the complex dependencies between variables, traditional LSTMs often face challenges\nwhen handling multiple variables. This is because LSTM needs to update and remember each\nvariable at every time step. As the number of variables increases, the complexity of these updates\nand memories also increases, affecting the quality of the generated data. To address this, we\npropose a batch generation method to reduce the number of passes. Instead of generating a record\nfor a single variable at each generation step, LSTM generates records for S variables (e.g., the\nvariable 1, 2 and 3 at jth time step). This can reduce the number of passes by a factor of S.\nHowever, it is important to note that as Sincreases, although the number of passes decreases, the\ndifficulty of each generation step increases, requiring multiple experiments for parameter tuning.\nIn practice, we found that S = 3 is most effective for the secondary crash dataset in this study.\n(2) Addressing the Mode Collapse Problem\nGAN models often encounter mode collapse issues when handling multivariable traffic time\nseries data due to the high variability in traffic flow characteristics. For example, at a certain time\nstep, the traffic flow in many samples might generally exceed 100, while the flow differences\nbetween adjacent lanes are less than 10 or even 0. Traditional GAN models typically use standard\nnormalization methods, scaling the data based on the maximum and minimum values of the entire\ndataset and training accordingly. This approach often leads to homogenized output samples,\ntriggering mode collapse. To address this, VarFusiGAN introduces an automatic normalization\nmechanism. This method normalizes each dynamic variable individually and incorporates the\nmaximum and minimum values of each variable as \"pseudo\" static data into the learning process.\nFor instance, we normalize the data for the upstream average flow variable across all 6-time steps\nand record the maximum and minimum values within this range. During generation, these values\nare used to constrain the variable, thus alleviating the mode collapse problem. The two\nnormalization methods described above can be specified as shown in\nEquation 1\n$\\x_{norm} = \\frac{X - X_{min}}{X_{max} - X_{min}}$\n(1)\n$\\x_{j,norm}^{i} = \\frac{x_{j}^{i} - x_{min}^{i}}{x_{max}^{i} - x_{min}^{i}}$\nwhere $x_{max}$ and $x_{min}$ represent the minimum and maximum values in the entire dataset, $X_{norm}$\nrepresents the normalized value of any variable x, and $x_{j,norm}^{i}$ denotes the normalized value of a\nspecific variable i at time step j.\n(3) Capturing Relationships between Static and Dynamic Data\nIn crash data, there is often a close relationship between static and dynamic data. For example,\nmore severe crashes often occur when vehicle speeds are higher prior to the incident. Therefore,\nwe need a mechanism to model the joint distribution between static and dynamic data.\nRegarding the generator, VarFusiGAN's generator consists of two independent parts: a static\ndata generator and a dynamic data generator. The static data generator takes a random noise vector\nas input and uses a multilayer perceptron (MLP) to generate the static data. This generated static\ndata is then passed as input to the dynamic generator at each step. The dynamic generator (i.e., the\nLSTM) generates time series data. Through this decoupled generation strategy, VarFusiGAN can\nbetter capture the complex relationships between static and dynamic data in the samples.\nExperiments have shown that when dealing with high-dimensional sample data, a single\ndiscriminator often struggles to ensure the fidelity of the generated data, especially the static data.\nTo address this, VarFusiGAN introduces an auxiliary discriminator that works in conjunction with\nthe primary discriminator, with their combined loss function shown in Equation 2. $L_1(G, D_1)$ is\nthe loss function for the auxiliary discriminator. $D_1(a)$ and $D_1(G(z)$ represent the probabilities\nthat real static data a and generated static data $G(z)$ are judged as real, respectively. This\ndiscriminator is solely used to determine whether the generated static data is authentic. The\nprimary discriminator $L_2(G, D_2)$, on the other hand, inputs real data x that includes both static\nand dynamic features to determine whether the generated dynamic data matches the static data.\nFinally, the losses of the two discriminators are combined using a weighting parameter to form a\njoint discriminator, which can be optimized by adjusting the parameter \u03b1 to enhance the overall\ngenerative performance."}, {"title": "5 RESULTS", "content": "L\u2081(G, D\u2081)=E4a~Panta (x) [log D\u2081(a)] + Ez~p.(z) [log(1 \u2013 D\u2081 (Ga(z)))]\nL2(G, D2)=Ex-Panta (x) [log D2 (x)] + Ezpz (z) [log(1 \u2013 D2 (G(z)))]\nmin max aL, (G, D\u2081) + L\u2082(G, D\u2082)\nG\nD1,D2\n(2)\nFigure 3 illustrates the structure of the VarFusiGAN model. The auxiliary generator assesses\nthe authenticity of static data such as crash type, severity, and spatiotemporal distance, while the\nprimary generator evaluates whether the dynamic variables related to traffic flow characteristics\nbefore the crash (e.g., flow, occupancy, and speed) match the static variables.\n(4) Handling Sample Data of Different Length\nIn traffic crash analysis, secondary crashes are typically a series of events that occur shortly\nafter a primary crash and may happen at different time points. Therefore, when collecting data\nsamples, the length of dynamic data for each sample varies depending on the time of the secondary\ncrash occurrence. For example, when a secondary crash occurs at the 6 minute after a primary\ncrash, we need to collect data from 30 minutes before the primary crash to 5 minutes after the\ncrash; whereas if the secondary crash occurs at the 11th minute, we need to collect data from 30\nminutes before to 10 minutes after the primary crash. As a result, the dynamic data lengths of\ndifferent samples are different. However, current generative models often struggle to manage\ndatasets with different sample lengths effectively. Applying a straightforward truncation method\nto standardize sample lengths by removing excess data can lead to the omission of crucial temporal\ninformation, particularly in real-time prediction contexts where the discarded data might contain\nkey traffic flow characteristics around the occurrence of the secondary crash, which would\ninevitably affect the prediction accuracy.\nHowever, the VarFusiGAN model used in this paper proposes a unique solution to this\nproblem, i.e., handling samples of different lengths by introducing the data_gen_flag field.\ndata_gen_flag is a floating-point array of size [number of training samples \u00d7 maximum time length]\nused to mark the activation state of each sample at each time step. Where 1 indicates that the time\nstep is active and 0 indicates that the time step is not active. This allows flexibility in representing\ntime series data of different lengths. For example, suppose there are two samples with lengths of\n2 and 4, and the maximum time length is set to 4. Then data_gen_flag will be displayed as:\ndata_gen_flag=[\n[1.0,1.0,0.0,0.0]\n[1.0,1.0,1.0,1.0]]\n(3)\nFor the first sample of length 2, data_gen_flag is 1 at the 1st and 2nd time steps and 0 at the\n3rd and 4th time steps, indicating that only the data in the first two time steps are valid; while for\nthe second sample of length 4, data_gen_flag is 1 at all 4 time steps, indicating that the entire time\nseries is valid. In this way, the model is able to dynamically adapt to samples of varying lengths\nduring generation and prediction, ensuring that the generated data have high fidelity.\nWith the above setup, the VarFusiGAN model can generate datasets containing both dynamic\nfeatures and static attributes, and is able to handle samples of different lengths, maintaining data\nconsistency and integrity. In this way, the model can generate high-fidelity data while ensuring\nthe diversity and accuracy of the generated data, providing more reliable input data for subsequent\nsecondary crash prediction models.\n3.1.2 Predictive Component: Transformer\nThe predictive component of the VarFusiGAN-Transformer model leverages Transformer\narchitecture to predict both the occurrence probability and spatiotemporal distribution of secondary\ncrashes. The model structure includes an input layer, a Transformer layer, a normalization layer, a"}, {"title": "4.1 Data Sources", "content": "dropout layer, a flattening layer, a concatenation layer, a hidden layer, and both classification and\nregression output layers.\nThe input layer of the model consists of two parts: dynamic feature input and static feature\ninput. Dynamic features are the dynamic data in the samples. These features are reshaped into a\nthree-dimensional input tensor with the shape (number of samples, number of time steps, number\nof features per time step). Static features, such as crash type and severity, are discrete data directly\nused as two-dimensional inputs with the shape (number of samples, number of features).\nThe output layer of the model consists of two parts that are trained using two loss functions.\nAmong them, the classification output is the binary cross entropy, which is used to predict the\noccurrence of secondary crashes. The sigmoid activation function maps the output values to the\nrange [0, 1], which indicates the probability of occurrence of secondary crashes. The regression\noutput is the mean square error, and the linear activation function is used to predict the time and\ndistance difference between the primary and secondary crashes.\n3.2 Evaluation Metrics\nThe imbalanced real data samples were randomly divided into a training set and a test set in\na 7:3 ratio. The sample data generated by different models were then added to the training set to\nform balanced synthetic data.\nTo evaluate the accuracy of the classification for the real imbalanced data and the balanced\nsynthetic data, we used three performance metrics: sensitivity, specificity, and G-mean. Sensitivity\nmeasures the model's ability to correctly identify positive events, aligning with our primary goal\nof predicting the minority secondary crashes. It represents the proportion of correctly classified\nsecondary crashes out of all actual secondary crashes. Specificity reflects the model's ability to\naccurately identify negative events, representing the proportion of correctly predicted primary\ncrashes out of all observed primary crashes. G-mean is a balanced metric that considers the\nclassification accuracy of both positive and negative classes. This metric aims to find a balance\nbetween the accuracy of both classes, making it particularly suitable for handling imbalanced\ndatasets. The formulas defining these metrics are:\n$Sensitivity = \\frac{TP}{TP + FN}$\n(4)\n$Specificity = \\frac{TN}{TN + FP}$\n(5)\nG-mean = $Sensitivity \\cdot Specificity$\n(6)\nAdditionally, to determine the accuracy of predicting the time difference and distance\ndifference between secondary and primary crashes, we used Mean Absolute Error (MAE) and Root\nMean Square Error (RMSE) for evaluation. MAE provides an intuitive error measure by\ncalculating the average absolute error between the predicted values and the actual values, reflecting\nthe overall bias of the prediction. RMSE, on the other hand, calculates the average of the squared\ndifferences between the predicted values and the actual values and then takes the square root,\nmaking it more sensitive to larger errors in the prediction process. Using these two metrics together\nallows for a comprehensive evaluation of the impact of different datasets on prediction\nperformance, thereby demonstrating which model-generated data has higher fidelity. Equation (6)\nand (7) represent the calculation of MAE and RMSE.\nn\n\u039c\u0391\u0395 = $\\frac{1}{N}$ \u03a3 $y_i - \\hat{y}_i$\n(6)\ni=1\nn\nRMSE = $\\sqrt{\\frac{1}{N} \u03a3 (y_i - \\hat{y}_i)^2}$\n(7)\ni=1\nwhere y refers to the real value and \u0177refers to the predicted value. N is the total number of\nsamples.\n4 DATA PREPARATION\n4.1 Data Sources\nThe objective of this study is to predict the spatiotemporal locations of secondary crashes in\nreal-time based on the characteristics of highway traffic crashes. Therefore, a substantial amount\nof static crash characteristic data (such as crash type, road conditions, and the spatial and temporal\ndistance between primary and secondary crashes) and dynamic traffic flow characteristic data\n(such as flow, speed, and occupancy) is required for the training and testing of the model.\nThis study selected segments of four interstate highways in the United States: I-5, I-90, I-405,\nand I-520. These highways are equipped with loop vehicle detectors capable of collecting\ninstantaneous traffic flow data, such as volume, occupancy, and speed. In addition, crash datasets\nfrom these four interstates were obtained for the period from 2021 to February 2024, totaling\n14,409 crashes. This dataset provides detailed records of each crash, including the time and\nlocation, type, severity, lighting conditions, and road conditions. The spatiotemporal location of\neach crash was matched with nearby loop detector data, and unreasonable data were removed.\nUltimately, 9,295 crash data samples that met the research requirements were selected.\n4.2 Identification of Secondary Crashes\nAccording to the introduction in Section 2, methods for identifying secondary crashes are\ngenerally categorized into static and dynamic approaches. This study employs the speed contour\nmethod to identify secondary crashes.\nFirst, a fixed temporal and spatial range is selected to preliminarily screen potential secondary\ncrashes. Based on previous research, the temporal range is typically from 0.25 to 2 hours after the\nprimary crash, and the spatial range is from 1 to 3 kilometers upstream of the primary crash(18).\nConsidering that on busy interstate highways, congestion and other subsequent impacts caused by"}, {"title": "5.1 Evaluation of Generated Data", "content": "traffic crashes often last longer and affect a broader area, we adopt the maximum ranges used in\nprevious research, namely a 3-mile distance interval and a 2-hour time interval, as the initial\nscreening thresholds.\nNext, speed contour plots are generated for the preliminarily screened crashes. Specifically,\nspeed data within the selected time window and spatial range are aggregated at 5-minute intervals\nto create the initial speed contour plot. To eliminate the interference of recurrent congestion, the\naverage speed on all non-crash days within the same spatiotemporal range is selected, and the\ndifference between these data and the speeds on the day of the crash is calculated to more\naccurately determine the impact range of the crash on traffic flow.\nFor example, a crash occurred at mile marker 161.86 at 14:25 on April 17, 2021. Speed data\nfor the stretch from mile markers 156 to 166 between 14:00 and 16:00 on the same day were first\nextracted, and an initial speed contour plot was generated, as shown in Figure 5(a). After\ndetermining the initial impact range of the crash, another crash occurring at mile marker 161.2 at\n14:50 on the same day fell within the impact range of the primary crash. The average speed on all\nnon-crash days within this spatiotemporal range was then screened, and the difference between\nthese data and the speeds on the day of the crash was calculated, resulting in a new speed contour\nplot, as shown in Figure 5(b). The secondary crash remained within the impact range, confirming\nit as a secondary crash within the impact range of the primary crash.\nUsing the above method, the impact range of all primary crashes is determined, and any crash\noccurring within this impact range is identified as a secondary crash. Finally, 9,220 ordinary\ncrashes, 75 primary crashes, and 156 secondary crashes were ultimately identified, with a\nsecondary crash rate of approximately 1.65% being determined. This finding is consistent with\nexisting research, such as 1.2% (Xu et al., 2016), 1.6% (Li and Abdel-Aty, 2022), and 1.98% (Li\net al., 2023).\n4.3 Feature Selection\nThis study aims to predict the spatiotemporal locations of secondary crashes by combining\nstatic crash characteristic data with dynamic traffic flow data. Therefore, in terms of static data,\nfour discrete variables were selected: crash type, crash severity, lighting conditions and road\nsurface conditions. Regarding dynamic data, this study selected traffic flow data collected from\none loop detector upstream and one downstream of the primary crash location within the 30\nminutes preceding the crash, with a time interval of 5 minutes. Table 1 provides the statistics and\ndescriptions of all variables. For example, \"Up_Avg_Occ\" denotes the average occupancy\nupstream every 5 minutes, \"Down_Dif_AvgFlow\" denotes the absolute value of the average flow\ndifference in adjacent lanes downstream every 5 minutes, and \"Updown_AvgSpd\" denotes the\naverage speed difference between upstream and downstream every 5 minutes.\n4.4 Experimental Design\nTo comprehensively evaluate the predictive performance of the VarFusiGAN-Transformer\nmodel, this study first assesses the fidelity of the data generated by VarFusiGAN. For the\nevaluation of the fidelity of this generative model, we selected the following four models for\ncomparative evaluation: MC-GAN(38), TVAE(39), TimeGAN(7), and TimeVAE(9). Among\nthem, MC-GAN can generate multidimensional complex data under multiple conditional\nconstraints, and TVAE is specifically designed to handle mixed-type tabular data. Therefore, we\nchose these two models to compare the ability of VarFusiGAN to generate composite data. In\naddition, dynamic data often play a crucial role in traffic crash data. Thus, we chose TimeGAN\nand TimeVAE to compare and evaluate VarFusiGAN's performance in generating dynamic data.\nHowever, since TimeGAN and TimeVAE cannot generate composite data, the data they generate\nare unsuitable for evaluating static data and cannot be used for subsequent secondary crash\nprediction.\nThis study used resampling to balance the real training dataset. The training and testing\ndatasets include both the real dataset and the balanced dataset. Seventy percent of the crash data\n(109 secondary crashes and 6,454 primary crashes) were randomly selected for training, while the\nremaining 30% (47 secondary crashes and 2,766 primary crashes) were used for testing. For the\nresampled balanced training dataset, the ratio of secondary crashes to primary crashes was 1:1.\nTherefore, 6,345 secondary crash samples were generated using VarFusiGAN, MC-GAN, and"}, {"title": "5.1.1 Conditional Distribution", "content": "TVAE. Additionally", "11": 4, "1": 3, "and\n1": 2}]}