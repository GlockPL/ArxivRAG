{"title": "LEVERAGING FUNDAMENTAL ANALYSIS FOR STOCK TREND\nPREDICTION FOR PROFIT", "authors": ["John Phan", "Hung-Fu Chang"], "abstract": "This paper investigates the application of machine learning models, Long Short-Term Memory\n(LSTM), one-dimensional Convolutional Neural Networks (1D CNN), and Logistic Regression (LR),\nfor predicting stock trends based on fundamental analysis. Unlike most existing studies that\npredominantly utilize technical or sentiment analysis, we emphasize the use of a company's financial\nstatements and intrinsic value for trend forecasting. Using a dataset of 269 data points from publicly\ntraded companies across various sectors from 2019 to 2023, we employ key financial ratios and the\nDiscounted Cash Flow (DCF) model to formulate two prediction tasks: Annual Stock Price\nDifference (ASPD) and Difference between Current Stock Price and Intrinsic Value (DCSPIV).\nThese tasks assess the likelihood of annual profit and current profitability, respectively. Our results\ndemonstrate that LR models outperform CNN and LSTM models, achieving an average test accuracy\nof 74.66% for ASPD and 72.85% for DCSPIV. This study contributes to the limited literature on\nintegrating fundamental analysis into machine learning for stock prediction, offering valuable insights\nfor both academic research and practical investment strategies. By leveraging fundamental data, our\napproach highlights the potential for long-term stock trend prediction, supporting portfolio managers\nin their decision-making processes.", "sections": [{"title": "Introduction", "content": "The application of artificial intelligence (AI) has significantly expanded across various industries, including\nfinance, prompting a growing interest among researchers in applying machine learning techniques to stock\nprice prediction. Most existing studies in this field use technical analysis or sentiment analysis in machine\nlearning models [1]. However, employing fundamental analysis in machine learning for stock prediction\nremains limited.\nSeveral reasons lead scientists to use technical analysis and sentiment analysis in machine learning for\nprediction in the stock market rather than considering fundamental analysis. First, technical analysis is used\nby short-term traders (e.g., day traders and swing traders) to make trading decisions based on recent stock\nprice movements. For instance, Western Indicators use tools like support and resistance lines, Fibonacci\nretracements, Simple Moving Averages (SMA), and the Relative Strength Index (RSI) to identify broader\nmarket trends and to help traders predict price movements over periods ranging from days to weeks to months,\nmaking them suitable for day and swing trading. Aligning the same thoughts inspires the research community\nto apply technical analysis to various machine learning models for predictions. Second, technical analysis is\nbased on the assumption that stock prices move in trends and that historical patterns will repeat themselves,\nimplying that all publicly available information is already reflected in the stock's price. Third, sentimental\nanalysis leverages textual data, such as news articles, social media posts, and online forums, to gauge investor\nsentiment toward specific stocks or the broader market. The strategy of following the crowd is the main idea\nbehind sentiment analysis. People believe sentimental analysis reflects collective emotions and psychological\nbehaviors toward the stock market. One can rely on others' research or reaction to market emotions like fear,\ngreed, and herding for decision-making. With the growing amount of data from social media posts, public\nopinions, and professional reports, analyzing those online data to gauge market sentiment for understanding\nmarket behaviors or predicting short-term stock movements has become an attractive approach recently."}, {"title": "Literature Review", "content": "Past research regarding machine learning on stock predictions can be classified into three main categories according to\nthe analysis techniques used in the model. We describe them in the following three sections."}, {"title": "Technical analysis", "content": "Aadhitya et al. developed a CNN-LSTM neural network model to analyze daily stock prices of companies\nlisted on the NIFTY-50, NYSE, and NASDAQ from 2000 to 2021. Their model achieved high accuracy,\nparticularly for NIFTY stocks, reaching up to 99%, although accuracy varied for NYSE and NASDAQ stocks.\nCompared to other models, such as standalone LSTM and XGBoost, their model demonstrated superior\nperformance with minimal error and variance [8]. Similarly, Nelson et al. applied an LSTM model to predict\nstock prices on the Brazilian stock exchange, achieving a 55% accuracy rate. They emphasized that technical\nanalysis relies on patterns in stock prices driven by supply and demand, which tend to repeat but do not account\nfor external factors such as political or economic events. Their findings suggest that while the LSTM model\noffers higher accuracy, reducing variance is crucial for its reliability in stock prediction [9]. These studies\nindicate that while machine learning models like CNN-LSTM and LSTM enhance predictive capabilities for\nshort-term forecasting, they require careful model selection and optimization due to their inherent limitations."}, {"title": "Sentimental analysis", "content": "Sentiment analysis evaluates text data to predict short-term stock price movements by identifying positive or\nnegative sentiment. Ding et al. [6] found that financial news events were better predictors of stock prices than\nsimple word counts, with deep neural networks outperforming linear models by learning hidden relationships"}, {"title": "Fundamental analysis", "content": "Recently, few studies started to use fundamental analysis in machine learning for stock prediction or financial\nforecasting. Huang et al. [2] combined historical financial data of large-cap stocks from the S&P 100 index\nwith models like Feed-forward Neural Networks (FNN), Random Forest (RF), and Adaptive Neural Fuzzy\nInference System (ANFIS) to predict long-term stock performance prediction. Their experimental results\nshowed that all three methods are capable of constructing stock portfolios that outperform the market without\nany input of expert knowledge if they are fed with enough data in which Random Forest showed the best\nresult. [12] Bekiros and Georgoutsos' research shows that, without trading costs, the return of the neuro-fuzzy\nmodel consistently outperforms the recurrent neural model, as well as the buy and hold strategy during bear\nperiod. Whereas, during the bull period, the buy and hold strategy produces higher returns than neuro-fuzzy\nmodels or neural networks. Ftiakas et al. [3] applied seven different algorithms to 1,353 NASDAQ stocks,\nshowing that no single algorithm is universally superior, underscoring the need for multiple approaches in\nfinancial analysis. Cao and You [4] analyzed historical data from 1965 to 2019, finding that approaches like\nRandom Forest, Gradient Boosting, and Artificial Neural Networks provided more accurate forecasts than\ntraditional methods by uncovering subtle nonlinear relationships in financial data. These findings highlight\nthe potential of machine learning to refine traditional fundamental analysis and provide new insights for\ninvestment decisions."}, {"title": "Summary", "content": "In summary, while traditional fundamental analysis focuses on evaluating a company's financial health\nthrough detailed analysis of financial statements, the integration of machine learning techniques can enhance\nthe accuracy and depth of these evaluations. This combined approach provides a more comprehensive\nunderstanding of a company's value, considering both quantitative and qualitative factors, and helps investors\nstay ahead in an increasingly complex financial landscape."}, {"title": "Method", "content": "The purpose of this paper is to explore the connection between machine learning techniques and fundamental\nanalysis, thus, we gathered the companies' fundamental information between three financial statements. Using\nthe raw numbers from all three statements, we also calculated the key financial ratios such as liquidity ratios\nand profit margins individually, as well as indices' averages."}, {"title": "Data Collection", "content": "The fundamental data was retrieved from Yahoo Finance in the range of 5 years from the first day of 2019 to\nthe last day of 2023. Each selected company is expected to have 5 records. Unfortunately, some might miss\none entry because they do not have all 5 years' worth of stock prices. From the above criteria, we resulted in\npicking stocks from very stable indexes including the Industrial Sector (XLI), Utility Sector (XLU), Consumer\nStaple Sector (XLP), Consumer Discretionary Sector (XLY), Dow Jones Index (DJI), and Top 100 companies\nin the U.S. stock exchange (QQQ). Since there are a lot of overlaps between the index, we eliminate the\noverlapping companies and come to the final count of 269 publicly traded companies.\nOne strategy that was used in past research [10] for getting companies for the machine learning dataset for\nstock performance prediction proved to avoid random selection or high volatility. This is also the method"}, {"title": "Dataset", "content": "Our training data is sourced from three key financial documents: the income statement, balance sheet, and\ncash flow statement, which were retrieved from Yahoo Finance for the period spanning 2019 to 2023. These\ndocuments provide comprehensive historical financial data for the selected companies, offering a detailed\nview of their financial performance and position over time. From this data, we determine features and labels\nthat serve as the base for our machine learning models."}, {"title": "Features", "content": "The machine learning model's features consist of a company's raw historical financial data and various\nfinancial ratios calculated from the income statement, balance sheet, and cash flow statement (see Table 1).\nThe model also includes each company's intrinsic value, determined using the Discounted Cash Flow (DCF)\nmodel."}, {"title": "Labels", "content": "We would like to use machine learning models to perform two predictions on a company: (1) Annual Stock\nPrice Difference (ASPD) and (2) Difference between Current Stock Price and Intrinsic Value (DCSPIV).\nThese two labels both indicate profit. On one hand, the investor can decide to sell a stock for profit anytime\nin a year and the price changes every second according to what is available to the public, financially.\nSpecifically, when a company's stock price at the start of the year is positively affected by the financial\nannouncement or guidance, increasing to a higher point at year's end, the label is 1; otherwise, it is 0. On the\nother hand, the other straightforward strategy for profit is to use intrinsic value to determine whether to\npurchase or sell a stock at this very moment because the intrinsic value is used to assess whether a company\nis trading at a discount or premium in the current market state. In this scenario, the difference between current\nstock price and intrinsic value is the potential profit or loss for that investment. If that investment results in a\ngain, the label is 1; otherwise, it is 0.\nAlthough various methods exist to determine a company's intrinsic value across sectors, we aimed to create a\nformula that is both universally applicable and aligned with investment industry standards. We utilized the"}, {"title": "Machine Learning Models", "content": "The LSTM is frequently utilized in stock price prediction research due to its effectiveness in modeling\nsequences and time-series data, which aligns well with the nature of historical stock prices. An LSTM is\ncomposed of a series of interconnected memory cells, each containing three critical components: the Input\nGate, Forget Gate, and Output Gate. These gates enable the LSTM to retain and update relevant information\nover extended sequences, facilitating the transmission of knowledge across the network nodes.\nWhile Convolutional Neural Network (CNN) are traditionally used in image processing, they are also highly\neffective in identifying patterns, trends, and anomalies within datasets-tasks essential for decision-making\nand risk management in finance. In the financial sector, CNN is applied for earnings forecasting, anomaly\ndetection in credit transactions, and recognizing various market conditions or shifts. Unlike LSTM networks,\nwhich are designed to capture long-term dependencies in data sequences, one-dimensional CNN (1D CNN)\nare particularly advantageous for detecting short-term, abrupt trends or changes in the data.\nThe Logistic Regression (LR) is simple. It performs well for linearly separable data and is highly interpretable,\nmaking it useful in fields like medicine, finance, and social sciences. It also serves as a foundation for more\ncomplex models, such as neural networks. Therefore, logistic regression is widely used for binary\nclassification tasks, where the outcome variable is categorical with two possible values (e.g., 0 and 1). Its\nbinary outcome is calculated by the logistic function (or sigmoid function), which maps any real-valued\nnumber into a value between 0 and 1, representing the probability. In logistic regression, the model estimates\nthe coefficients of the input variables to best fit the data. Once the model is trained, it predicts the probability\nthat a new input belongs to a specific class. If the probability exceeds a threshold (commonly 0.5), the model\nassigns the input to one class; otherwise, it assigns it to the other."}, {"title": "LSTM on ASPD:", "content": "This Long Short-Term Memory (LSTM) neural network was specifically built for binary classification,\ndesigned to capture temporal dependencies in stock price data. The preprocessing involved selecting key\nfeatures, scaling them with StandardScaler, and splitting the dataset into training and testing sets. The\narchitecture consisted of an LSTM layer with two hidden layers, followed by a linear layer, which condensed\nthe sequence output into a single binary prediction via a sigmoid function. The model was trained using Binary\nCross-Entropy with Logits Loss and the Adam optimizer for 5,000 epochs. During training, the model tracked\nperformance metrics such as loss, accuracy, precision, recall, and F1 score to evaluate its learning ability."}, {"title": "CNN on ASPD:", "content": "Our CNN architecture consisted of two Conv1D layers, each followed by a max pooling layer to reduce\ndimensionality and extract important features from the sequence. After the convolutional layers, the data was\nflattened and passed through two fully connected layers, with the final layer providing the binary classification\noutput using a sigmoid activation function."}, {"title": "LSTM on DCSPIV:", "content": "The model was compiled with Binary Cross-Entropy for the classification task and Mean Squared Error (MSE)\nfor the regression task. The preprocessing involved filling missing values, flattening arrays, and scaling\nfeatures using StandardScaler before reshaping the data for sequential input. The model architecture featured\na shared LSTM layer with 50 units to process the time-series data, followed by a dense layer with 64 units\nusing ReLU activation. The model had two outputs: one for binary classification (predicting a label) using a\nsigmoid activation and one for regression (predicting the intrinsic value) using a linear activation."}, {"title": "CNN for DCSPIV:", "content": "The final model used a CNN for the same multi-output task on the intrinsic value dataset. Data preprocessing\nincluded filling in missing values, flattening arrays, and scaling the features before reshaping them to a format\ncompatible with the CNN architecture. The CNN had two convolutional layers, each followed by max pooling\nto reduce dimensionality and extract key patterns. After flattening the output, the data was passed through a\ndense layer before branching into two outputs: one for binary classification (with a sigmoid activation) and\nanother for regression (with a linear activation)."}, {"title": "Results", "content": "After running 5,000 epochs for each model for ASPD and DCSPIV, the CNN model performed the worst\namong all of them, achieving just 55.36% accuracy on ASPD (see Table 2). Whereas Logistics Regression\nachieved the best average testing accuracy out of three models for both datasets at 74.66% accuracy in ASPD\nand 72.85% in DCSPIV.\nWe notice that LSTM and CNN both perform well in the training, having average accuracy of 98.51% and\n97.51%, respectively, which outperform Logistic Regression. However, their testing accuracy is poorer than\nLogistic Regression. Among all the LSTM values in both ASPD and DCSPIV, LSTM's average recall value\nreaches 92.66% in DCSPIV. That means LSTM can detect true positive cases well in DCSPIV. Overall,\nregarding average testing recall, F1 score, precision, and accuracy, we think the performance of CNN is not\nas good as the other two models because only CNN's average testing precision (i.e., 58.35%) in DCSPIV is"}, {"title": "Discussion", "content": "We discuss our outcomes in three different perspectives, model performance, approach comparison, and\nlimitation."}, {"title": "Model Performance", "content": "Logistic Regression is regarded as an effective approach when the data is not sequential or spatial in nature.\nLSTM is more appropriate for sequential data and CNN can exact spatial features. Because Logistic\nRegression provides the best performance, this can imply that features extracted from fundamental analysis\nmight not equip sequential or spatial characteristics. In addition, we think Logistic Regression demonstrates\nrobust generalization on both ASPD and DCSPIV datasets despite having lower training metrics. While LSTM\nand CNN have strong training performances, indicating their capacity to learn complex patterns, they tend to\noverfit, leading to a noticeable drop in test accuracy, precision, and F1-score. LR, being a simpler model,\nachieves higher accuracy, precision, and F1-score on the test sets for both datasets, suggesting that it is less\nsensitive to overfitting and better at generalizing across different data types. Though LSTM maintains a\nconsistently high recall, indicating a strong ability to detect true positives, LR's balanced performance between\nprecision and recall on the test data makes it a more effective and stable choice for these datasets.\nLSTM outperforms CNN in every aspect in ASPD. This does align with our original estimation since LSTM\nis often better for predicting the time series data. It seems that this architecture struggled to generalize the\nstock price differences over time, potentially due to the complexity or noisiness of the data. The LSTM model\non this DCSPIV is significantly better than on ASPD. This suggests that the LSTM's ability to capture\ntemporal dependencies was particularly useful for handling the intrinsic value prediction, which likely\ninvolved more sequential complexity and nuance than the stock price data. This CNN on DCSPIV effectively\nhandled both classification and regression tasks, leveraging shared convolutional layers for feature extraction.\nHowever, it didn't quite match the LSTM's performance, likely because the temporal patterns in the intrinsic\nvalue dataset were better captured by the recurrent nature of the LSTM."}, {"title": "Approach Comparison", "content": "Komori's research [16], which supports fundamentalists, utilized a Convolutional Neural Network (CNN) to\nanalyze 2D candlestick charts of the S&P 500 index from 1985 to 2020. Using a simple moving average as a\ntechnical indicator, they tested a CNN model, Inception v3, for 1, 3, and 5-day forecasts. Despite CNN's high\n78.1% accuracy on the ImageNet dataset, its highest stock market forecasting accuracy was only 50% at 3"}, {"title": "Limitation", "content": "Although all our models can reach more than 55% accuracy, this study has several limitations that could be\naddressed to improve the models' utility for investors. One key limitation is the dataset's size and scope. The\ntime range of data collection was limited, potentially hindering the models' ability to capture long-term trends\nand fluctuations in the market. Expanding the dataset to cover a broader time span would allow the models to\nbetter generalize across various market conditions. Additionally, the number of stocks chosen for analysis was\nrelatively small, which may limit the models' applicability to different sectors and market environments.\nIncluding a more diverse set of stocks would improve the robustness of the models across industries.\nMoreover, financial ratios and key attributes differ in importance depending on the sector. Customizing the\nmodel parameters for specific industries could significantly enhance accuracy and relevance, making the\nmodels more effective for practitioners. Addressing these limitations through larger datasets, longer\ntimeframes, and industry-specific adjustments could lead to more practical and reliable investment strategies."}, {"title": "Conclusion", "content": "Our study explored the use of LSTM, CNN, and logistic regression (LR) models in integrating fundamental\nanalysis for predicting stock trends, achieving accuracy rates close to 72%. Our findings indicate that all\nmodels are better suited for fundamental analysis than technical analysis. Our method can offer a\nstraightforward approach to identifying profitable stocks. By leveraging financial statements and intrinsic\nvalue calculations, investors can enhance their decision-making processes, particularly by considering early-\nyear stock purchases. Our research provides valuable insights for both industry professionals and academic\nresearchers, highlighting the potential of machine learning models, which result in long-term, profitable\ninvestment strategies."}]}