{"title": "Friend or Foe? Harnessing Controllable Overfitting for Anomaly Detection", "authors": ["Long Qian", "Bingke Zhu", "Yingying Chen", "Ming Tang", "Jinqiao Wang"], "abstract": "Overfitting has long been stigmatized as detrimental to model performance, especially in the context of anomaly detection. Our work challenges this conventional view by introducing a paradigm shift-recasting overfitting as a controllable and strategic mechanism for enhancing model discrimination capabilities. In this paper, we present Controllable Overfitting-based Anomaly Detection (COAD), a novel framework designed to leverage overfitting for optimized anomaly detection. We propose the Aberrance Retention Quotient (ARQ), a novel metric that systematically quantifies the extent of overfitting, enabling the identification of an optimal \"golden overfitting interval\" ARQoptimal. Within this interval, overfitting is leveraged to significantly amplify the model's sensitivity to anomalous patterns, while preserving generalization to normal samples. Additionally, we present the Relative Anomaly Distribution Index (RADI), an innovative metric designed to complement AUROC-pixel by providing a more versatile and theoretically robust framework for assessing model performance. RADI leverages ARQ to track and evaluate how overfitting impacts anomaly detection, offering an integrated approach to understanding the relationship between overfitting dynamics and model efficacy. Our theoretical work also rigorously validates the use of Gaussian noise in pseudo-anomaly synthesis, providing the foundation for its broader applicability across diverse domains. Empirical evaluations demonstrate that our controllable overfitting method not only achieves State-Of-The-Art(SOTA) performance in both one-class and multi-class anomaly detection tasks but also redefines overfitting from a modeling challenge into a powerful tool for optimizing anomaly detection.", "sections": [{"title": "1. Introduction", "content": "In the traditional context of machine learning, overfitting has long been perceived as an undesirable phenomenon, just like [3, 8, 10, 20], traditionally viewed as the result of a model excessively memorizing training data, leading to compromised generalization capabilities. However, we challenge this conventional wisdom by extending the concept beyond the domain of anomaly detection, positioning controllable overfitting as a versatile mechanism for enhancing model sensitivity across a wide range of applications. This leads us to the central question that underpins our work: can overfitting be a friend rather than a foe in the domain of anomaly detection?\nThe conventional understanding of overfitting necessi-"}, {"title": "2. Related Work", "content": "Reconstruction-based methods are founded on the hypothesis that models trained exclusively on normal data can successfully reconstruct normal instances while failing to do so for anomalies, thereby using reconstruction error as a measure of abnormality. Notable reconstruction-based approaches include Autoencoders (AE) [29, 33], Generative Adversarial Networks (GANs) [7, 15], and Reverse Distillation (RD)[6, 23]. Specific methods under these categories, such as DSR[31], RealNet[32], and DRAEM[30], attempt to learn the representation of normal data and generate accurate reconstructions for normal samples but tend to produce significant residuals for anomalous inputs.\nRecent developments have seen the use of embedding-based methods, besides"}, {"title": "2.1. Overview of Anomaly Detection", "content": "Reconstruction-Based Method"}, {"title": "Embedding-Based Method", "content": "Embedding-based methods Recent developments have seen the use of embedding-based methods, besides"}, {"title": "3. Method", "content": "As Fig. 2 shows, our works provides an overview of our proposed framework for enhancing anomaly detection through controllable overfitting. We introduce Controllable Overfitting-based Anomaly Detection, called COAD. We systematically integrate novel elements such as ARQ for quantifying overfitting and RADI as a complementary metric for AUROC-pixel. These components collectively facilitate the monitoring, control, and optimization of the overfitting process to maximize model sensitivity while preserving generalization capabilities."}, {"title": "3.1. Overview", "content": "As Fig. 2 shows, our works provides an overview of our proposed framework for enhancing anomaly detection through controllable overfitting. We introduce Controllable Overfitting-based Anomaly Detection, called COAD. We systematically integrate novel elements such as ARQ for quantifying overfitting and RADI as a complementary metric for AUROC-pixel. These components collectively facilitate the monitoring, control, and optimization of the overfitting process to maximize model sensitivity while preserving generalization capabilities."}, {"title": "3.2. Quantifying Overfitting with Aberrance Retention Quotient", "content": "The exploration of overfitting has largely been confined to its avoidance, and there has been a conspicuous lack of systematic studies on how to control or even beneficially leverage overfitting for enhancing model capabilities. Moreover, existing research lacks a quantitative metric that accurately reflects the extent of overfitting, which is critical for understanding its implications and finding the \"sweet spot\" in model training. To fill this gap, we introduce the Aberrance Retention Quotient, called ARQ, a novel metric designed to quantify the degree of overfitting by capturing the model's divergence from true data representation during training.\nThe ARQ is formally defined as follows:\n$$ARQ = \\frac{\\sum_{i=1}^{N}(\\hat{y_i} - y_i)}{\\sum_{i=1}^{N} y_i}$$\nwhere N represents the total number of instances, \u0177i represents the predicted output at the ith instance, and yi denotes the corresponding original ground truth value. The numerator captures the aggregate prediction deviation from the true labels across all data points, while the denominator represents the totality of the predicted target values, normalizing the aberrance in the context of the entire dataset.\nARQ is a core metric in our framework that quantifies the progression of overfitting during model training. By tracking ARQ, we identify the golden overfitting interval, where the model's sensitivity to anomalous patterns is maximized without compromising generalization. Specifically, we denote the interval of optimal ARQ as:\n$$ARQoptimal = [\\theta \u2013 \\delta, \\theta + \\delta]$$\nwhere \u03b8 is the baseline value around which the optimal range is established, d is a quantity of the same order of magnitude as 0, representing the permissible deviation from the baseline @ within the optimal range, which indicates the region in which the overfitting is leveraged most effectively.\nAs overfitting progresses, ARQoptimal helps us mitigate false positives while reducing false negatives, Fig. 1a and Fig. 1b illustrate some cases. By effectively using ARQ, we transform overfitting into a controlled mechanism that enhances model robustness and discriminative power for anomaly detection."}, {"title": "3.3. Bridging Theoretical Modeling and Practical Anomaly Detection with Relative Anomaly Distribution Index", "content": "To facilitate the mathematical treatment later, we made the following two assumptions, which were verified in subsequent experiments, please see Sec. 4."}, {"title": "3.3.1 Probability Distribution Models of Normal and Anomalous Pixel Scores", "content": "To facilitate the mathematical treatment later, we made the following two assumptions, which were verified in subsequent experiments, please see Sec. 4."}, {"title": "Distribution of Normal Pixel Prediction Scores", "content": "At an Aberrance Retention Quotient of ARQ = 0, the prediction scores of normal pixels Sn follow a normal distribution dependent on 0:\n$$Sn \\sim N(\\mu_n(\\theta), \\sigma_n(\\theta)^2)$$\nwhere the mean \u03bc\u03b7(\u03b8) and variance \u03c3\u03b7(\u03b8)2 vary with ARQ. As the ARQ increases, the model's memory of normal samples is enhanced, potentially resulting in:\n\u2022 The mean \u03bc\u03b7 (\u03b8) becoming closer to the average value of the training data.\n\u2022 The variance \u03c3\u03b7(\u03b8)2 decreasing due to the model's predictions on normal samples becoming more stable.\nThe variance of normal pixel prediction scores decreases exponentially with increasing ARQ, expressed as:\n$$\\sigma_n(\\theta) = \\sigma_{n0} e^{-k\\theta}$$\nwhere ono is the initial variance (without overfitting), and k is a positive constant representing the rate at which variance"}, {"title": "Distribution of Anomalous Pixel Prediction Scores", "content": "The prediction scores of anomalous pixels Sa follow a fixed normal distribution that does not change with ARQ:\n$$Sa \\sim N(\\mu_a, \\sigma_a)$$\nsince anomalous pixels are not present during training, and the model cannot memorize them."}, {"title": "3.3.2 Introduction of RADI", "content": "After these assumptions, we introduce the Relative Anomaly Distribution Index, called RADI, a novel metric designed to bridge theoretical modeling and practical anomaly detection. Unlike traditional metrics such as AUROC, which are often used to evaluate model performance in anomaly detection tasks, RADI provides an indirect yet insightful measure of the model's capacity to differentiate between normal and anomalous samples. This makes it particularly valuable for theoretical analyses, while also retaining practical utility in assessing model effectiveness.\nThe RADI quantifies the overlap between normal and anomalous score distributions, akin to the Wilcoxon rank-sum [24] and Mann-Whitney U tests [19]. RADI is calculated using the cumulative distribution function (CDF) of the score distributions:\n$$RADI(ARQ) = P(Sa > Sn)\n= \\int P(Sa > x)fsn(x)dx$$\nwhere Sa and Sn represent the scores of anomalous and normal pixels, respectively.\nIt might seem counterintuitive why using RADI as an indicator would enhance model performance, as one might think that maximizing this value would lead to the model predicting everything as anomalous. However, RADI itself is not directly used for model optimization; rather, it serves as a metric to reflect the optimization outcome and help identify the extent to which normal and anomalous distributions are distinguishable. The goal is to ensure that anomalies receive consistently higher scores compared to normal samples, which allows the model to achieve better discrimination.\nMoreover, the relationship between overfitting and variance is controlled by Eq. (8), which ensures that the variance of normal pixel predictions (\u03c3\u03b7(\u03b8)) does not decrease to zero due to the noise term onoise(\u03b8). This prevents the variance from collapsing entirely, maintaining a distinction"}, {"title": "3.3.3 Theoretical Derivation of Optimal Overfitting Conditions", "content": "For our case, where both Sa and Sn follow normal distributions, RADI can be further expressed in a simplified analytical form:\n$$RADI(\\theta) = \\Phi(\\frac{\\mu_a - \\mu_n}{\\sqrt{\\sigma_n(\\theta)^2 + \\sigma_a^2}})$$\nwhere is the CDF of the standard normal distribution. In this case, \u03bc\u03b1 and \u03bc\u03b7 are the means of the anomaly and normal pixel score distributions, respectively, while \u03c3\u03b1 and \u03c3\u03b7 (\u03b8) are their respective standard deviations, with @ representing the Aberrance Retention Quotient.\nEq. (7) highlights the dependence of RADI on the statistical properties of the score distributions. As @ increases, the standard deviation \u03c3\u03b7 (\u03b8) of the normal scores will decrease due to the model's increasing ability to memorize normal patterns, which results in a more stable distribution for normal scores. This reduction in variance directly affects the value of RADI, increasing the probability that the anomalous scores are distinguished from normal scores, thereby enhancing the detection capability of the model.\nHowever, when overfitting is excessive, the model may start to memorize noise, leading to instability in prediction scores, and the variance \u03c3\u03b7(\u03b8) will no longer decrease and could even increase. To describe this phenomenon, we introduce a noise term:\n$$\\sigma_n(\\theta) = \\sigma_{n0} e^{-k\\theta} + \\sigma_{noise}(\\theta)$$\nwhere \u03c3noise (0) represents the noise impact induced by overfitting and can be expressed as:"}, {"title": "3.3.4 Dual Control Mechanism and Freeze Command Signals", "content": "We define Aberrance Retention Quotient of ARQ = 0, adjusted to optimize the pixel-level AUROC. The mathematical relationship between ARQ and AUROC is established by monitoring the gradient, We call it Gradient-Guided Overfitting Control.\n$$\\frac{dRADI(\\theta)}{d\\theta} \\geq 0$$\nWe integrate ARQoptimal in Eq. (2) and Gradient-Guided Overfitting Control in Eq. (13) and call this combined control mechanism the Dual Control Mechanism:\n$$\\frac{dRADI(\\theta)}{d\\theta} \\geq 0, for \\theta \\in ARQoptimal$$\nIf Dual Control Mechanism fails, the Dual Control Mechanism triggers Freeze Command Signals, which prompt whether freeze certain network layers, beginning with lower-level feature extraction layers and moving upwards.\nThe rationale for progressively freezing certain layers while overfitting the other parts lies in the architecture's functional partitioning. Lower layers are responsible for extracting fundamental features, which are common across both normal and anomalous data. Freezing these layers"}, {"title": "4. Experiments", "content": "We evaluate our method using the MVTec AD dataset [1], which is a comprehensive, real-world dataset for unsupervised anomaly detection tasks. The MVTec AD dataset includes 15 categories, comprising 3629 images for training and 1725 images for testing. The dataset provides pixel-level annotations for each anomaly, making it suitable for evaluating both image-level classification and pixel-level segmentation tasks."}, {"title": "4.1. Dataset", "content": "We evaluate our method using the MVTec AD dataset [1], which is a comprehensive, real-world dataset for unsupervised anomaly detection tasks. The MVTec AD dataset includes 15 categories, comprising 3629 images for training and 1725 images for testing. The dataset provides pixel-level annotations for each anomaly, making it suitable for evaluating both image-level classification and pixel-level segmentation tasks."}, {"title": "4.2. Comparison with SOTAS", "content": "In this section, we compare the performance of our proposed method with several SOTA anomaly detection methods in both one-class and multi-class tasks.\nUsing the optimal ARQ value @ derived from the ARQoptimal as indicated by Eq. (12), we set ARQ to 0.006 for one-class tasks and 0.06 for multi-class tasks. ARQoptimal is defined as \u03b8 \u2208 [0.001, 0.011] for one-class tasks and \u03b8\u2208 [0.01, 0.11] for multi-class tasks, where the balance between overfitting and generalization is optimal for anomaly detection. We saved model states within these intervals and evaluated their performance across respective benchmarks to ensure robust detection.\nFurthermore, during model training, we adopted a Dual Control Mechanism for Optimal Detection Performance approach in our framework COAD, as detailed in Eq. (14), and when Dual Control Mechanism fails, it triggers Freeze Command Signals, prompting the selective freezing of certain network layers in the traditional framework.\nOur method builds upon existing anomaly detection frameworks. Initially, we perform standard training on the original model. Following this, we transition into the controllable overfitting stage, during which the model is further trained using our COAD framework. This stage utilizes Dual Control Mechanism in Eq. (14). All pseudo-anomaly generation in this stage is performed using Gaussian noise to introduce controlled variability, which aids in refining the model's sensitivity to anomalies. Additionally, the learning rate is reduced to 1/10 of that used in the normal training stage, allowing the model to make finer adjustments.\nAfter training, the inference of the model proceeds in"}, {"title": "4.3. Ablation Study", "content": "The results of our one-class and multi-class experiments are summarized in Tabs. 1 and 2. It can be observed that our enhanced method outperforms the original methods, achieving new SOTA results. The enhancement in pixel-level AUROC is especially significant, which is crucial for fine-grained anomaly detection.\nThese results confirm that the introduction of controllable overfitting, regulated by ARQ and RADI, enhances the model's sensitivity and stability, leading to robust anomaly detection abilities that outperform existing SOTA methods."}, {"title": "4.3.1 Comparisons with Our Basic Frameworks", "content": "The results of our one-class and multi-class experiments are summarized in Tabs. 1 and 2. It can be observed that our enhanced method outperforms the original methods, achieving new SOTA results. The enhancement in pixel-level AUROC is especially significant, which is crucial for fine-grained anomaly detection.\nThese results confirm that the introduction of controllable overfitting, regulated by ARQ and RADI, enhances the model's sensitivity and stability, leading to robust anomaly detection abilities that outperform existing SOTA methods."}, {"title": "4.3.2 Comparisons with Distinct ARQ", "content": "In this section, we compare the performance of different models under distinct ARQ ranges to validate the impact of controllable overfitting on anomaly detection. We evaluated methods such as RD, RD++, UniAD, and DiAD"}, {"title": "4.4. Validation of Distribution Assumptions and Theoretical Validation of Gaussian Noise Usage", "content": "In this section, we firstly validate the assumptions introduced in Sec. 3.3.1 by employing the Total Variation Distance (TVD) metric. We leveraging multiple models at different stages of overfitting, characterized by distinct ARQ values. For each model state, corresponding to different ARQ = 0, we calculate the prediction scores for both normal and anomalous pixels across the dataset. Subsequently, we evaluate their proximity to a Gaussian distribution using TVD, ensuring a robust assessment of the normality of these distributions. The partial results of this validation are summarized in Tab. 7. Moreover, we model the variance of the normal pixel prediction scores (\u03c3\u03b7(\u03b8)) as an exponential function of the ARQ = 0, given by Eq. (4).\nTo validate the suitability of Gaussian noise as a pseudo-anomaly generator, we employ the TVD metric to quantitatively compare the distribution of real anomaly scores with that of Gaussian-distributed pseudo-anomalies. We can see Tab. 7, the resulting TVD value was about 0.08, suggesting that the Gaussian-distributed pseudo-anomalies exhibit a significant overlap with the actual anomalies. This supports the assumptions that Gaussian noise can be effectively used to preliminarily simulate anomalous behavior in train-"}, {"title": "5. Conclusion", "content": "In this work, we reenvisioned overfitting as a controllable and transformative mechanism, using COAD to enhance model capabilities beyond conventional boundaries. We introduced ARQ to precisely regulate overfitting, as well as RADI, which leverages ARQoptimal to provide a more versatile metric compared to AUROC-pixel, facilitating both theoretical modeling and Dual Control Mechanism. By repurposing overfitting as a generalizable module, our approach not only dismantles its demonization but also enables us to achieve SOTA results in both one-class and multi-class anomaly detection tasks. Furthermore, we provide a robust theoretical foundation for employing Gaussian noise as a preliminary pseudo-anomaly generator, extending the applicability of our COAD."}, {"title": "6. Dual Control Mechanism Design Concept", "content": "Overfitting has traditionally been viewed as a problem that hampers generalization\u2014where the model memorizes noise and specific details of the training data, leading to poor performance on unseen examples. However, in the context of anomaly detection, we posit that overfitting can be harnessed as a feature, not a flaw. The key lies in the concept of controllable overfitting-managing overfitting in a way that makes the model more sensitive to subtle differences between normal and anomalous data.\nIn practical terms, overfitting can amplify the sensitivity of the model to slight deviations, which is particularly useful in anomaly detection scenarios, where anomalies are often defined by subtle discrepancies from the norm. Our approach aims to leverage this characteristic to enhance detection capability while avoiding the negative consequences of overfitting, such as loss of generalization. This balancing act necessitates a carefully designed mechanism, which we call the Dual Control Mechanism in Eq. (14).\nThe Dual Control Mechanism is comprised of two complementary components: ARQoptimal in Eq. (2) and Gradient-Guided Overfitting Control in Eq. (13). These components work together to ensure that overfitting remains within beneficial bounds, ultimately enhancing anomaly detection without sacrificing the ability to generalize effectively.\nThe ARQ quantifies the degree of overfitting by capturing the relationship between the model's fit to the training data and its potential for retaining useful deviations that indicate anomalies. We define an optimal interval for ARQ, denoted as ARQoptimal, which represents the range where overfitting is beneficial-significantly enhancing sensitivity to anomalies without compromising generalization.\nDuring training, ARQ is continuously monitored to ensure it remains within this optimal interval. If ARQ moves outside the defined range, corrective actions are taken to bring it back. The optimal interval allows the model to exploit overfitting in a targeted manner, enhancing the model's sensitivity towards subtle anomalies while minimizing the risk of memorizing noise.\nAlongside ARQoptimal, the Gradient-Guided Overfitting Control is employed to supervise how overfitting impacts anomaly detection performance directly. This component utilizes the Relative Anomaly Distribution Index (RADI) to quantify the"}, {"title": "7. Main Functional Pseudocode", "content": ""}, {"title": "8. Extended Discussion of Gaussian Noise Validation", "content": "In this work, we chose to use Gaussian noise as a preliminarily pseudo-anomaly generator due to its statistical properties and simplicity. Gaussian noise, characterized by its mean and variance, serves as an ideal candidate for generating random deviations that can mimic unexpected patterns in normal data.\nFrom a theoretical standpoint, Gaussian noise exhibits a distribution that is both isotropic and well-defined in high-dimensional space, making it suitable for approximating unstructured, irregular anomalies. The Central Limit Theorem (CLT) supports the use of Gaussian distributions as approximations for many naturally occurring random processes. In particular, when adding minor perturbations to an image, we aim to simulate unforeseen deviations from the underlying structure of normal samples, which Gaussian noise effectively captures.\nAdditionally, Gaussian noise serves as a zero-mean stochastic process, allowing us to avoid introducing any specific directional bias, which could potentially interfere with the model's capacity to learn anomalous versus normal regions. By employing Gaussian noise, we ensure that our model does not overfit to particular anomaly patterns but instead gains a generalized sensitivity to any divergence from the normal data distribution. This universality underpins our approach to controllable overfitting within the COAD framework."}, {"title": "8.1. Theoretical Rationale for Gaussian Noise", "content": "In this work, we chose to use Gaussian noise as a preliminarily pseudo-anomaly generator due to its statistical properties and simplicity. Gaussian noise, characterized by its mean and variance, serves as an ideal candidate for generating random deviations that can mimic unexpected patterns in normal data.\nFrom a theoretical standpoint, Gaussian noise exhibits a distribution that is both isotropic and well-defined in high-dimensional space, making it suitable for approximating unstructured, irregular anomalies. The Central Limit Theorem (CLT) supports the use of Gaussian distributions as approximations for many naturally occurring random processes. In particular, when adding minor perturbations to an image, we aim to simulate unforeseen deviations from the underlying structure of normal samples, which Gaussian noise effectively captures.\nAdditionally, Gaussian noise serves as a zero-mean stochastic process, allowing us to avoid introducing any specific directional bias, which could potentially interfere with the model's capacity to learn anomalous versus normal regions. By employing Gaussian noise, we ensure that our model does not overfit to particular anomaly patterns but instead gains a generalized sensitivity to any divergence from the normal data distribution. This universality underpins our approach to controllable overfitting within the COAD framework."}, {"title": "8.2. Validation Through Total Variation Distance (TVD)", "content": "To validate the suitability of Gaussian noise as a pseudo-anomaly generator, we conducted an empirical analysis using the Total Variation Distance (TVD) metric. TVD is a standard measure used in probability theory to quantify the dissimilarity between two distributions. We calculated TVD to evaluate how closely Gaussian noise could mimic true anomalies in both spatial and intensity domains.\nThe calculation of TVD involves estimating the difference between the empirical distributions of Gaussian noise and the true normal and anomaly pixel intensities:\n$$D_{TVD}(P, Q) = \\frac{1}{2} \\sum_x |P(x) - Q(x)|$$\nwhere P represents the empirical distribution of the true anomalies, and Q represents the empirical distribution of Gaussian noise. TVD measures the extent of overlap between the two distributions, where a smaller TVD implies a closer approximation between the pseudo-anomalies and real anomalies."}, {"title": "8.3. Experimental Results and Qualitative Study", "content": "The experimental results demonstrate that the model trained using Gaussian noise exhibits a better anomaly detection performance to models trained with other pseudo-anomaly generator.\nTo further validate the results, we present detailed histograms for the anomaly detection scores obtained across 15 individual categories as well as the overall dataset. These histograms were generated under the condition where the Anomaly Rate Quotient (ARQ) is set to 0.006, using RD++ as our baseline framework. Each histogram in Figs. 3 and 4 provides a clear visualization of the distribution of detection scores, overlaid with a Gaussian fitting curve for enhanced interpretability. This fitting curve highlights the distribution, allowing for a more effective comparison of the model's performance across different categories and the overall dataset, further solidifying the reliability of our evaluation metrics."}, {"title": "8.4. Future Directions with GLASS-like Pseudo-Anomaly Generators", "content": "While Gaussian noise has proven effective as a preliminary pseudo-anomaly generator, future work could explore more advanced methods inspired by the GLASS approach [4]. The GLASS method introduces a structured way to generate pseudo-anomalies by leveraging geometric transformations and localized pattern synthesis, providing greater control over anomaly characteristics.\nBy incorporating concepts from GLASS, we envision a Gaussian Noise-Enhanced GLASS-like Generator, where Gaussian noise could act as the foundational perturbation, and additional constraints or transformations could be applied to shape the pseudo-anomalies in a contextually relevant manner. For instance, augmenting Gaussian noise with spatial or intensity correlations reflective of real anomalies could enhance its realism and improve model robustness in detecting diverse anomalies.\nSuch an approach would align well with our COAD framework, enabling a more versatile training process that accounts for both unstructured and structured anomaly patterns. By systematically integrating these future developments, we aim to refine our anomaly detection strategy, bridging the gap between theoretical advancements and practical applications."}, {"title": "9. Qualitative Comparison of Anomaly Detection between Different Baselines and COAD", "content": "To further validate the effectiveness of our methods, we provide a qualitative comparison of anomaly detection results across 15 distinct categories using baselines such as RD, RD++, UniAD, DiAD, and the proposed COAD framework in Figs. 5 to 8. Each subfigure demonstrates: (from left to right) the original image, the ground truth anomaly mask, the result from the baseline method, and the result after applying COAD.\nThe comparison shows that COAD effectively reduces both false positive rates (FPR) and false negative rates (FNR), accurately capturing anomaly regions while minimizing misclassifications. These results are consistent with the improvements reflected in the earlier quantitative data in Tabs. 3 and 4, where COAD consistently outperforms its counterparts in image-level and pixel-level AUROC metrics, highlighting COAD's capability to outperform the baselines.\nBy leveraging controllable overfitting, COAD enhances the model's sensitivity to true anomalies while maintaining its generalization capabilities. The reduction in FPR minimizes the misclassification of normal regions as anomalies, while the decreased FNR highlights the model's ability to capture subtle anomalies that baseline methods often miss. These qualitative and quantitative improvements collectively demonstrate the robustness and effectiveness of COAD in advancing anomaly detection tasks. Additionally, the sharper distinction between normal and anomalous regions demonstrates the framework's capacity to refine boundary precision, further enhancing detection reliability."}, {"title": "10. Future Work", "content": "In future work, we plan to refine our pseudo-anomaly generators by incorporating advanced methods in Sec. 8.4, enabling the generation of more structured and domain-relevant pseudo-anomalies.\nMoreover, we intend to explore the application of the COAD framework in other domains, particularly in areas such as medical imaging, autonomous driving, and forgery detection. Forgery detection, for instance, highlights an opportunity to utilize COAD's enhanced sensitivity to subtle anomalies, such as fine-grained pattern inconsistencies or texture deviations. Furthermore, we aim to generalize and modularize the COAD framework into a plug-and-play component that can be seamlessly integrated into similar tasks across various fields. Ultimately, we aspire to redefine the concept of overfitting itself, transforming it from a perceived limitation into a powerful tool that drives innovation."}, {"title": "6. Dual Control Mechanism Design Concept", "content": "Overfitting has traditionally been viewed as a problem that hampers generalization\u2014where the model memorizes noise and specific details of the training data, leading to poor performance on unseen examples. However, in the context of anomaly detection, we posit that overfitting can be harnessed as a feature, not a flaw. The key lies in the concept of controllable overfitting-managing overfitting in a way that makes the model more sensitive to subtle differences between normal and anomalous data.\nIn practical terms, overfitting can amplify the sensitivity of the model to slight deviations, which is particularly useful in anomaly detection scenarios, where anomalies are often defined by subtle discrepancies from the norm. Our approach aims to leverage this characteristic to enhance detection capability while avoiding the negative consequences of overfitting, such as loss of generalization. This balancing act necessitates a carefully designed mechanism, which we call the Dual Control Mechanism in Eq. (14).\nThe Dual Control Mechanism is comprised of two complementary components: ARQoptimal in Eq. (2) and Gradient-Guided Overfitting Control in Eq. (13). These components work together to ensure that overfitting remains within beneficial bounds, ultimately enhancing anomaly detection without sacrificing the ability to generalize effectively.\nThe ARQ quantifies the degree of overfitting by capturing the relationship between the model's fit to the training data and its potential for retaining useful deviations that indicate anomalies. We define an optimal interval for ARQ, denoted as ARQoptimal, which represents the range where overfitting is beneficial-significantly enhancing sensitivity to anomalies without compromising generalization.\nDuring training, ARQ is continuously monitored to ensure it remains within this optimal interval. If ARQ moves outside the defined range, corrective actions are taken to bring it back. The optimal interval allows the model to exploit overfitting in a targeted manner, enhancing the model's sensitivity towards subtle anomalies while minimizing the risk of memorizing noise.\nAlongside ARQoptimal, the Gradient-Guided Overfitting Control is employed to supervise how overfitting impacts anomaly detection performance directly. This component utilizes the Relative Anomaly Distribution Index (RADI) to quantify the"}, {"title": "7. Main Functional Pseudocode", "content": ""}, {"title": "8. Extended Discussion of Gaussian Noise Validation", "content": "In this work, we chose to use Gaussian noise as a preliminarily pseudo-anomaly generator due to its statistical properties and simplicity. Gaussian noise, characterized by its mean and variance, serves as an ideal candidate for generating random deviations that can mimic unexpected patterns in normal data.\nFrom a theoretical standpoint, Gaussian noise exhibits a distribution that is both isotropic and well-defined in high-dimensional space, making it suitable for approximating unstructured, irregular anomalies. The Central Limit Theorem (CLT) supports the use of Gaussian distributions as approximations for many naturally occurring random processes. In particular, when adding minor perturbations to an image, we aim to simulate unforeseen deviations from the underlying structure of normal samples, which Gaussian noise effectively captures.\nAdditionally, Gaussian noise serves as a zero-mean stochastic process, allowing us to avoid introducing any specific directional bias, which could potentially interfere with the model's capacity to learn anomalous versus normal regions. By employing Gaussian noise, we ensure that our model does not overfit to particular anomaly patterns but instead gains a generalized sensitivity to any divergence from the normal data distribution. This universality underpins our approach to controllable overfitting within the COAD framework."}, {"title": "8.1. Theoretical Rationale for Gaussian Noise", "content": "In this work, we chose to use Gaussian noise as a preliminarily pseudo-anomaly generator due to its statistical properties and simplicity. Gaussian noise, characterized by its mean and variance, serves as an ideal candidate for generating random deviations that can mimic unexpected patterns in normal data.\nFrom a theoretical standpoint, Gaussian noise exhibits a distribution that is both isotropic and well-defined in high-dimensional space, making it suitable for approximating unstructured, irregular anomalies. The Central Limit Theorem (CLT) supports the use of Gaussian distributions as approximations for many naturally occurring random processes. In particular, when adding minor perturbations to an image, we aim to simulate unforeseen deviations from the underlying structure of normal samples, which Gaussian noise effectively captures.\nAdditionally, Gaussian noise serves as a zero-mean stochastic process, allowing us to avoid introducing any specific directional bias, which could potentially interfere with the model's capacity to learn anomalous versus normal regions. By employing Gaussian noise, we ensure that our model does not overfit to particular anomaly patterns but instead gains a generalized sensitivity to any divergence from the normal data distribution. This universality underpins our approach to controllable overfitting within the COAD framework."}, {"title": "8.2. Validation Through Total Variation Distance (TVD)", "content": "To validate the suitability of Gaussian noise as a pseudo-anomaly generator, we conducted an empirical analysis using the Total Variation Distance (TVD) metric. TVD is a standard measure used in probability theory to quantify the dissimilarity between two distributions. We calculated TVD to evaluate how closely Gaussian noise could mimic true anomalies in both spatial and intensity domains.\nThe calculation of TVD involves estimating the difference between the empirical distributions of Gaussian noise and the true normal and anomaly pixel intensities:\n$$D_{TVD}(P, Q) = \\frac{1}{2} \\sum_x |P(x) - Q(x)|$$\nwhere P represents the empirical distribution of the true anomalies, and Q represents the empirical distribution of Gaussian noise. TVD measures the extent of overlap between the two distributions, where a smaller TVD implies a closer approximation between the pseudo-anomalies and real anomalies."}, {"title": "8.3. Experimental Results and Qualitative Study", "content": "The experimental results demonstrate that the model trained using Gaussian noise exhibits a better anomaly detection performance to models trained with other pseudo-anomaly generator.\nTo further validate the results, we present detailed histograms for the anomaly detection scores obtained across 15 individual categories as well as the overall dataset. These histograms were generated under the condition where the Anomaly Rate Quotient (ARQ) is set to 0.006, using RD++ as our baseline framework. Each histogram in Figs. 3 and 4 provides a clear visualization of the distribution of detection scores, overlaid with a Gaussian fitting curve for enhanced interpretability. This fitting curve highlights the distribution, allowing for a more effective comparison of the model's performance across different categories and the overall dataset, further solidifying the reliability of our evaluation metrics."}, {"title": "8.4. Future Directions with GLASS-like Pseudo-Anomaly Generators", "content": "While Gaussian noise has proven effective as a preliminary pseudo-anomaly generator, future work could explore more advanced methods inspired by the GLASS approach [4]. The GLASS method introduces a structured way to generate pseudo-anomalies by leveraging geometric transformations and localized pattern synthesis, providing greater control over anomaly characteristics.\nBy incorporating concepts from GLASS, we envision a Gaussian Noise-Enhanced GLASS-like Generator, where Gaussian noise could act as the foundational perturbation, and additional constraints or transformations could be applied to shape the pseudo-anomalies in a contextually relevant manner. For instance, augmenting Gaussian noise with spatial or intensity correlations reflective of real anomalies could enhance its realism and improve model robustness in detecting diverse anomalies.\nSuch an approach would align well with our COAD framework, enabling a more versatile training process that accounts for both unstructured and structured anomaly patterns. By systematically integrating these future developments, we aim to refine our anomaly detection strategy, bridging the gap between theoretical advancements and practical applications."}, {"title": "9. Qualitative Comparison of Anomaly Detection between Different Baselines and COAD", "content": "To further validate the effectiveness of our methods", "demonstrates": "from left to right) the original image, the ground truth anomaly mask, the result from the baseline method, and the result after applying COAD.\nThe comparison shows that COAD effectively reduces both false positive rates (FPR) and false negative rates (FNR), accurately capturing anomaly regions while minimizing misclassifications. These results are consistent with the improvements reflected in the earlier quantitative data in Tabs. 3 and 4, where COAD consistently outperforms its counterparts in image-level and pixel-level AUROC metrics, highlighting COAD's capability to outperform the baselines.\nBy leveraging controllable overfitting, COAD enhances the model's"}]}