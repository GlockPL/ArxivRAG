{"title": "Large language models for artificial general intelligence (AGI): A survey of foundational principles and approaches", "authors": ["Alhassan Mumuni", "Fuseini Mumuni"], "abstract": "Generative artificial intelligence (AI) systems based on large-scale pretrained foundation models (PFMs) such as vision-language models, large language models (LLMs), diffusion models and vision-language-action (VLA) models have demonstrated the ability to solve complex and truly non-trivial AI problems in a wide variety of domains and contexts. Multimodal large language models (MLLMs), in particular, learn from vast and diverse data sources, allowing rich and nuanced representations of the world and, thereby, providing extensive capabilities, including the ability to reason, engage in meaningful dialog; collaborate with humans and other agents to jointly solve complex problems; and understand social and emotional aspects of humans. Despite this impressive feat, the cognitive abilities of state-of-the-art LLMs trained on large-scale datasets are still superficial and brittle.\nConsequently, generic LLMs are severely limited in their generalist capabilities. A number of foundational problems -embodiment, symbol grounding, causality and memory - are required to be addressed for LLMs to attain human-level general intelligence. These concepts are more aligned with human cognition and provide LLMs with inherent human-like cognitive properties that support the realization of physically-plausible, semantically meaningful, flexible and more generalizable knowledge and intelligence. In this work, we discuss the aforementioned foundational issues and survey state-of-the art approaches for implementing these concepts in LLMs. Specifically, we discuss how the principles of embodiment, symbol grounding, causality and memory can be leveraged toward the attainment of artificial general intelligence (AGI) in an organic manner.", "sections": [{"title": "INTRODUCTION", "content": "Intelligence relates to the ability of a system, biological or otherwise, to achieve some level of success in accomplishing one or more desired goals in a given environment (or variety of environments). An intelligent system is capable of infer-ring its own state as well as the state of the environment, and is able to transform these inferences into appropriate responses leading to the achievement of desired goals. Intelligence is characteristically a unique feature of higher living organisms, and in the pursuit of developing their ar-tificial counterparts, artificial intelligence, researchers have frequently borrowed concepts from biology. An important attribute of biological intelligence is its generality, i.e., its ability to handle many different problems across a wide variety of settings. Human intelligence, in particular, is remarkably sophisticated, rich and versatile, and can effort-lessly handle many novel tasks. The general superiority of human intelligence over that of other higher animals stems (primarily) from the ability of humans to structure and transfer knowledge through social and cultural constructs such as art, norms, rituals, belief systems and customs [1]. Language plays a vital role in all these processes.\nWhile the idea of creating this kind of generalist intel-ligence is attractive, it is extremely challenging to achieve such level of sophistication and generalization power in machines. Until quite recently, AI techniques that achieved impressive results were narrowly focused, solving specific problems in one domain or in a restricted set of domains (e.g., face recognition, medical image segmentation, text translation, stock market forecasting, pedestrian tracking, etc.). Lately, generative AI techniques based on variational autoencoders (VAEs) [2] and generative adversarial net-works (GANs) [3] have contributed greatly in revolution-izing the capabilities of AI, and enabling single models to simultaneously handle a wide variety of complex tasks [4]. More recently, the emergence of large-scale pretrained foundation models such as large language models (LLMs) [5], diffusion models (DMs) [6], vision-language models (VLMs) [7] and vision-language-action (VLA) models [8] has real prospect for replicating generalist property in artificial intelligence. Owing to their ability to handle a wide range of challenging open-domain problems [9], [10], [11], [12], large-scale pretrained foundation models, especially multimodal large language models, have renewed interest in the quest for developing artificial general intelligence [10]. The main aim of this work is to present the fundamental principles of cognition that supports the realization of artificial gen-eral intelligence, and review state-of-the-art techniques for implementing these concepts in large language models."}, {"title": "Language as the foundation of general intelligence in biological systems", "content": "Language plays a central role in man's ability to rep-resent, interpret and reason with abstract concepts [24]. In human societies, one of the most important functions of language is to facilitates the acquisition and sharing of new knowledge. With the help of language - whether by literature, speech or art \u2013 humans can effortlessly learn from others and accumulate knowledge not only by observation or through their own interactions with the world, but also by acquiring knowledge accumulated by other humans. Besides, language provides a conceptual framework for representing and internalizing knowledge [22]. It has been demonstrated that the specific linguistic structures and vo-cabulary used by a group influence reasoning and interpre-tation of the world. Indeed, linguistic differences (e.g., in terms of vocabulary) has been shown to influence how in-dividuals members of different linguistic groups remember and describe their experiences [25], [26], [27], [28]. In this regard, language can structure or restructure cognition [29], and therefore shapes how subjects understand and interact with the world [30], [31]."}, {"title": "Language as a tool for cognitive information process-ing", "content": "Besides creating abstractions to represent and organize the representation of perceptual information and knowledge, language plays a fundamental role in facilitating cognitive computational operations [24]. Lupyan [31] argues that basic linguistic elements like words provide cues for other cog-nitive components to construct meaning. Thus, language is not just a set of static symbols that reference real-world objects, phenomena and experiences, but it also serves as a tool for manipulating these symbols. Clark [24] specifically describes six different ways by which language facilitates cognitive information processing and reasoning in humans. Language been shown to facilitate not just crystalized intel-ligence (i.e., representation-related cognitive mechanisms) such as experience/stimuli categorization [26] and memory [25], [28] but also elements of fluid intelligence (i.e., analyt-ical problem-solving skills) like perception [32], [33], [34] and reasoning [24], [31]. Moreover, exposure to multiple linguistic frameworks has been demonstrated to broaden the individual's perspective and facilitates an understand-ing of concepts in a more nuanced manner. Because of its centrality in biological cognitive abilities, language has been characterized variously as \"the interface to cognition\" [21], \"intelligence amplifier\" [35], and human cognition itself has been described as language-augmented cognition [31]."}, {"title": "The concept of artificial general intelligence", "content": "While there are different interpretations of artificial general intelligence (AGI) in the literature [9], [36], [37], [38], [39], [40], the concept is generally understood as AI systems that exhibit broad intellectual abilities and are able to perform high-level cognitive tasks such as perception - including context understanding and a degree of self-awareness [41], [42], reasoning, planning, and the application of learned knowledge in new contexts. AGI systems are universally powerful models that can successfully accomplish signifi-cantly complex and diverse cognitive tasks across multiple domains without the need for additional training. The term human-level intelligence [37], [43], [44] is often loosely used to refer to Al systems that demonstrate general intelligence.\nAGI should not be taken to mean super-omniscience and omnipotent machines. Such hypothetical level of ca-pability is referred to as artificial super-intelligence [45], [46]. Practical AGI systems are systems possessing general yet limited and, to a degree, uncertain knowledge about the world but is sufficiently powerful and flexible to solve a wide range of problems requiring sensorimotor control, perception, context understanding, commonsense and analytical reasoning capabilities. This understanding of artificial general intelligence, in essence, reflects not only the fact of the practical difficulties in embedding or learning all relevant knowledge and skills at once, but also the performance limitations of such an approach. Moreover, conceptualizing artificial general intelligence as limited in scope but adaptive, flexible and extensible is consistent with the nature and properties of biological intelligence in higher living organisms like humans. Despite the wide variety of definitions in the literature, there almost a unanimous agree-ment on some of the defining features of AGI. Specifically, the most important features of a typical AGI system are that (see, for example, [9], [36], [43], [47], [48]): it can learn and flexibly apply the limited and uncertain knowledge to solve a wide range of problems in entirely different contexts; its learning and actions are autonomous and goal-driven; it retains and accumulates relevant information in memory and reuse the knowledge in future tasks; and it can under-stand context and perform high-level cognitive tasks such as abstract and commonsense reasoning.\nIt is important to point out that AGI is fundamen-tally different from Strong AI (see [49], [50], [51]). While AGI focuses on developing intelligent systems that have broad cognitive capabilities and can solve truly nontrivial problems, Strong AI aims to create very powerful intelli-gence that not only mimics human cognitive abilities at the functional level but one that is also characterized by real human cognitive properties such as intrinsic mental states and subjective experiences, including intentionality (desires, hopes, beliefs, inner motivation, etc.), morality, emotions, and self-awareness [52], [53] in the sense of being conscious and sentient."}, {"title": "Scope and outline of work", "content": "In this work, we present an extensive discussion of the core principles we consider important to achieving general intel-ligence. We also discuss the various approaches for realizing each of these concepts in artificial intelligence and LLM systems. The concepts discussed here are not algorithmic solutions for achieving AGI but rather general principles and properties of biological intelligence that Al systems based on large language models must be imbued with if they are to attain the kind of generality, robustness and sophistication of human cognitive functions. In fact, the core concepts are by nature algorithm-agnostic, that is, their im-plementation is not specific to any particular techniques or set of methods. It is important, however, to note that specific cognitive functions \u2013 e.g., perception, reasoning, planning, action, etc. can be enriched by these general concepts and principles. The remainder of the paper is organized as follows. In section 2, we present a brief overview of the key elements of large language models that make then so powerful and underlie their potential for solving complex problems requiring human-level general intelligence. The important foundational principles for achieving general in-telligence in large language models are covered in sections 3 through 6. These include embodiment (Section 3), symbol grounding (Section 4), causality (Section 5) and memory (Section 6). In Section 7, we discuss the interrelationships and interactions of the cognitive principles and synthesize a holistic cognitive model based on these interrelationships and interactions. Finally, we present a summary discussion of the concepts in Section 8 and conclude in Section 9."}, {"title": "TOWARDS ARTIFICIAL GENERAL INTELLIGENCE WITH LARGE LANGUAGE MODELS", "content": "Much of human knowledge and skills have been acquired and transmitted through multiple media, most significantly through language and visual media (reading, listening, di-rect observation, etc.). In a similar way, multimodal lan-guage models, relying on multiple data modalities, hold a great promise for providing systems with general, multi-dimensional knowledge about the world. While unimodal language models such as GPT-3 [62] and BERT [63] could handle only text data, multimodal LLMs (e.g., Palm-E [64], Minigpt-4 [65], Flamingo [66], LLaVA [67]) naturally in-tegrates many different data modalities, including visual, auditory, textual and spatial information seamlessly to gen-erate richer and more comprehensive representations for cognitive tasks. This is similar to the way biological intel-ligence relies on complex, multisensory data streams. The generalist capabilities of state-of-the-art multimodal large language models have already been widely demonstrated [9], [40], and their ability to solve a wide range of com-plex cognitive problems that traditionally required human intelligence is in no doubt. The remarkable success of large language models has redefined the possibilities and scope of artificial intelligence. The main factor that drives this success is the ability to build and train very large neural network models on diverse, multimodal data. These models are typically trained on generic data from the wild (e.g., online publications, books, news articles, social media and other sources of information from the web), and are able to capture intricate concepts and generalize more effectively to new tasks with little (few-shot learning [68], [69]) or no (zero-shot learning [70]) task-specific training. Consequently, complex cognition-intensive, open-domain tasks such as commonsense and analytical reasoning [71], [72]; mathematical problem-solving [73], [74]; itinerary planning [75], [76] or general task planning [77]; and open-vocabulary question answering [78], [79]. Significantly, state-of-the-art LLMs are able to perform creative and artistic works such as composing essays, short stories, or even entire novels [80], [81] according to any given criteria (e.g., author style, diction, mood, etc.)."}, {"title": "Features of large language models that support the attainment of human-level intelligence", "content": "In the context of achieving general intelligence, besides training on large and diverse datasets, large language mod-els possess a number of interesting features that allow their knowledge and skills to be naturally extended as needed. This extensibility, together with their already vast generic knowledge, allows them to overwhelmingly outperform traditional deep learning models that are typically designed with narrow optimization objectives and trained on re-stricted datasets from curated environments.\nWhile the underlying processes and mechanisms that support extensibility of large language models are fun-damentally different from those that support biological intelligence, the resulting properties somehow mirror the multilayered and multidimensional nature of human intel-ligence in many respects. For example, pretraining large language models endows them with general knowledge that is sufficiently powerful and flexible to tackle a wide range of common problems requiring perception, context under-standing as well as commonsense and analytical reasoning capabilities. Where domain-specific knowledge is needed, finetuning can be applied to augment the general knowl-edge with specialized knowledge by training the pretrained LMM further on domain-specific datasets. This approach is similar to the way human experts who already have general or commonsense knowledge- acquire specialized competencies in narrow areas of endeavor (e.g., as profes-sionals in engineering, medicine, law, or web development). It is also usual to ground the internal representations in real-world concepts using prior knowledge. Again, this feature is similar to the way biological intelligence is built on prior knowledge encoded as genetic information. In addition to the internalized knowledge and cognitive capabilities, hu-mans frequently rely external knowledge (e.g., through con-sultations with experts or books) and tools (e.g., software, machines, etc.) to extend their capabilities. Similarly, state-of-the-art language models can utilize tools (see [82], [83], [84]) and external knowledge \u2013through retrieval augmented generation (RAG) [85], [86] \u2013 to extend their capabilities."}, {"title": "Overview of foundational principles for AGI with LLMs", "content": "Despite the fact that state-of-the-art large language models are incredibly powerful, they still have a number of limi-tations that constrain their ability to achieve general intel-ligence [87], [88], [89], [90]. Generally, the models' under-standing of context is often superficial and their solutions, in many cases, only exhibit external resemblance to human knowledge [91], [92]. The problem stems from the fact that AI systems, including LLMs, are still just digital constructs that that attempt to mimic human knowledge and cognitive capabilities by learning general properties of the world from vast amounts of data. This knowledge is generally limited to observed patterns but does not capture the underlying principles responsible for the behavior.\nIt has long been argued that for machines to achieve AGI they necessarily need to emulate some key aspects of human cognition which enables human intelligence to be so robust, efficient, flexible and general yet sophisticated in the way it handles complex problems. Among the key aspects of human cognitive process are embodied sentience or simply embodiment [93], [94], symbolic grounding [95], causal reasoning [96], [97], and memory [98], [99], [100]. Em-bodied sentience\u2014the ability to have subjective experiences and feel sensations\u2014is considered a fundamental aspect of higher intelligence. It is an essential capability to enable general intelligence because it provides a sort of pseudo-consciousness and autonomy [101], [102], [103] Specifically, it enables agents to be self-aware, and therefore align their decisions and actions to a more universal, intrinsic higher-level goal [104], [105], [106]. Embodied sentience also al-lows agents to recognize the experiences of others. This allows them to be ethical and moral in decision-making and behavior. Another key principle of biological intelligence, symbolic grounding, performs a complementary function to embodiment by connecting abstract cognitive representa-tions to meaningful entities and concepts in the real world. Grounding in LLMs ensures that the abstract representa-tions learned correspond to specific real-world concepts, and are utilized or manipulated within the context of their semantic essence. Although the internal mechanisms under-lying the grounding process in human cognition are still not well-understood, rudimentary techniques for realizing grounding in artificial intelligence systems have shown a lot of promise in their ability to align LLMs' knowledge with the world's [107]. Another important set of ingredients for artificial general intelligence, intuitive physics [108], [109] and intuitive psychology [110], [111], relate to the ability to infer cause-and-effect relations about events and inter-actions in the real world. Human's natural understanding of intuitive physics is known to be the basis of robust per-ception and causal reasoning abilities. Meanwhile, intuitive psychology allows humans to form beliefs about intentions and probable actions of other living entities without the need to learn about specifically learn about them. Theory of mind (ToM) techniques [112], [113], [114] are typically em-ployed in LLMs to facilitate their understanding of intuitive psychology. Finally, memory allows learned knowledge and past experiences to be preserved and accumulated over time. This extends and enriches knowledge in a way that promotes general-purpose utility. Moreover, the ability to introspect [115], [116] and reflect [117] on past decisions and actions by virtue of memory mechanisms provides a way for LLMs to (accomplish) continual learning and adaptation."}, {"title": "EMBODIMENT", "content": "Modern conceptualizations of biological cognition suggest that cognitive processes in the human nervous system are deeply rooted in the mind's interactions with the body and the external environment. Per this view of intelligence, the brain, body, and environment are assumed to form a unified system where they jointly influence and shape intelligent behavior [118], [119], [120], [121]). The concept of neural plasticity, one of the most important cognitive phenom-ena that enhance adaptative behavior of intelligence, also assumes mind-body-environment interaction [122], [123], [124]. In [119], the three components are considered as essential cognitive resources that are required by the organ-ism to solve specific tasks. In line with this understanding of mind-body-environment trinity, it has been argued that for Al systems to be truly intelligent, they, like biological systems, must necessarily be able to interact with the world in a physical way and receive feedback and learn about the results of those physical interactions (see [125], [126], [127], [128], [129], [130]). According to this hypothesis, artificial intelligence can only attain general intelligence comparable to human-level cognitive capabilities if such intelligence were created in, and intrinsically linked with a physical body that possesses the ability to perform physical actions on the environment [109], [129], [131]. Embodied AI systems are systems that \u2013 unlike traditional approaches that are solely digital in nature \u2013 have a tangible physical manifes-tation through which they can perceive and process sensory information, and interact with their environment."}, {"title": "Embodiment as the foundation of general intelli-gence", "content": "Embodiment provides the foundation for intrinsic goal-directed behavior. An embodied artificial intelligence sys-tem necessarily has agency [132], [133], i.e., it undertakes intentional actions \u2013 actions it desires to perform (e.g., based on specific goals and needs) and over which it has complete control. This goal-directed behavior is a fundamental re-quirement for autonomy. Besides, AI systems endowed with rich sensorimotor resources with unlimited possibilities to explore and interact with the environment will attain exten-sive intellectual capabilities. Such an intelligent system will necessarily possess accurate and robust perception of the world and of its own state. In addition, it must be able to act on and influence the world in a purposeful way. It must also be capable of seamlessly adapting to the complex dynamics of the real world. Thus, while conventional approaches to intelligence results in models that are inherently rigid and mechanistic, embodied intelligence is more flexible and nu-anced, and can connect objective experiences with subjective concepts values, cultural norms and expectations [134]. By providing a more integrated way of interacting with the world, learning and decision-making, embodied agents are more robust and can handle complex and diverse problems, thereby supporting their generalist credentials."}, {"title": "Key aspects of embodied intelligence", "content": "The most important aspect of artificial general intelligence is the requirement for full autonomy \u2013 the ability to indepen-dently make decisions and take appropriate actions even in the absence of explicit commands or control signals from the outside world. The implementation of embodied general intelligence involves four main considerations.\nGoal-awareness: In order to achieve full autonomy, like biological systems, the artificial intelligence system must have an overarching goal to which all other goals, including explicit instructions given by other actors, must be subordi-nated. This goal must be intrinsic and guide the successful accomplishment of external goals triggered by other agents (e.g., commands given by users, actions of other agents, etc.).\nSelf-awareness: As the body is the executor of actions that influence the physical world, the intelligence process must be tied to the structure and capabilities of the body. That is, the appropriateness of intelligent actions depends not only on the goal the intelligent system seeks to achieve, but also on the optimality of the actions with respect to the available means to carry out the target goal. In order to be successful, the embodied intelligent agent must, therefore, be aware of its own capabilities and limitations. In human-centric contexts, this awareness includes the ability to un-derstand oneself from the perspective the broader social setting, and to connect experiences with values, cultural norms and expectations. This facilitates the realization of social intelligence [134], [135], [136].\nSituational-awareness: An entity's intelligence is shaped by the specific context or situation it finds itself in. This underscores the fact that intelligent behavior is often a response to specific needs or challenges presented by the environment. Therefore, to achieve any goal, it is important to know the properties of the world and to predict beforehand the outcome of the target action with respect to the intended goal of the action. Moreover, since the external world behaves differently in response to actions by different entities, the intelligence of each intelligent system must be unique in some way. This means intelligent behavior of the Al system must take into account the expected responses elicited by other objects or the environment by virtue of its special characteristics. In humans, behavior is often shaped by social and cultural factors. Similarly, the actions of embodied AI agents must reflect social, cultural and demographic realities of their environment. AI agents must be able to achieve goals while respecting practical constraints, including safety [137] and alignment with ethics and cultural values [138].\nDeliberate action: Actions are central to embodied in-telligence since they are the primary means to influence the world and to achieve desired goals. Through actions an agent can perform active exploration of the world, thus fur-ther improving its perception and facilitating learning and adaptation in dynamic environments. Intelligent embodied agents must incorporate mechanisms to influence the world trough purposeful actions."}, {"title": "Goal-awareness", "content": "Human behavior is generally guided by goals that extend far beyond the objectives of immediate tasks [139], [140], [141]. These high-level goals are an important aspect of bio-logical intelligence [142]. Similarly, in machines, intelligence is intrinsically linked with the ability to achieve defined goals. Therefore, to achieve truly general intelligence in AI, that kind of high-level goal-oriented behavior is required. Goal-awareness is considered a crucial capability for the realization of artificial general intelligence because it deter-mines the ability of AI systems to operate autonomously [143], [144], [145]. Specifically, high-level goals provide in-trinsic guidance that ensures meaningful and purposeful behavior in the absence of an external influence or instruc-tions.\nGoal-driven embodied agents can align immediate de-cisions and actions towards useful, long-term outcomes. In this regard, goal-oriented behavior facilitates an open-ended approach to problem-solving, allowing intelligent agents to exploit many possible actions without being restricted to specific behavioral options. This flexibility is important in problem settings where the course of action is not im-mediately obvious or cannot be computed analytically or is ill-defined and require non-linear, creative reasoning to arrive at. In particular, it allows autonomous Al agents to perform useful acts in society, for example, responding to emergencies like motor accidents, while still maintaining their core functions. Besides this cognitive flexibility, AI systems with goal-awareness capability can better generalize learning, select or prioritize relevant knowledge, and pursue actions that are directed towards achieving specific outcomes."}, {"title": "Approaches to achieving goal-awareness in LLMs", "content": "Generic LLMs have been shown to exhibit goal-oriented behavior [151], [152], [153]. Notwithstanding these recent capabilities, goal-awareness in LLMs out of the box is still limited. For instance, experimental evaluation of LLM goal-awareness capabilities by Li Yu et al. [154]and Li Chuang et al. [155] show poor goal-awareness. To mitigate this shortcoming, some recent works (e.g., [156], [157], [158]) have sought to align LLM behavior with explicitly-specified goals. One of the simplest ways to introduce goal-awareness in LLMs is to incorporate high-level goals in the form of input prompts for the LLM to guide the underlying models [159], [160], [161]. Approaches to enabling goal-oriented behavior in a more intrinsic manner involve specifically formulating goals in the LLM framework [162], [163]. For instance, Li et al. [155] employ a dedicated goal planning agent together with a tool-augmented knowledge retrieval agent to handle goal-awareness in long-horizon tasks. Liu et al. [164] encoded goal information in a knowledge graph which is then leveraged to design a goal planning module that guides LMM-human conversations in a goal-directed manner. Similarly, Ni et al. [158] exploit the commonsense relationships that exist in knowledge graph entities as goals for conversational LLM agents. With the approach, goal-directed responses are generated by traversing through the graph. Another common approach is to finetune the LLM on specific datasets (e.g., [154], [165], [166], [167]) that have been curated with the intended goal in mind. Unfortunately, models trained this way are often short-term goal-oriented. Another way to enhance long-term goal-awareness can also be accomplished by fine-tuning LLMs with imitation learning (e.g., in [168]), using reinforcement Learning with Human Feedback [169] or with feedback from a submodule (e.g., [170]) or from a different LLM acting as external evaluator (e.g., [171]). Advanced LLMs can leverage intrin-sic high-level goal-awareness to enable intelligent agents to independently formulate low-level goals and pursue task-specific objectives without explicit human supervision have already been proposed [151]. In EmbodiedGPT [172] and CoTDiffusion [173], for instance, Chain of Thought approach is used to generate subgoals for embodied actions. They can also refine decisions and modify actions according to changing circumstances and goals [151], [174]."}, {"title": "Scope of application of goal-awareness in intelligent agents", "content": "Goal-awareness can facilitate human-robot collaboration [156], [175], [176]. When LLM-based intelligent virtual agents or robots are aware of goals both their own and those of the humans they work with-they can align their actions more closely with human intentions, leading to more seamless and effective collaboration. Agents can then be more forward-looking and take proactive actions [156] in-stead of merely responding to user requests. The awareness of human goals also helps LLM agents to clarify ambiguous situations and better interpret observations about humans. For instance, with knowledge of the broader goals, espe-cially recommender-based conversational LLM agents, can provide better and more tailored responses [177]. Moreover, high-level goals can provide context for understanding in-structions and other human inputs."}, {"title": "Global and local goals", "content": "While biological cognition can handle global, high-level goals, LLMs, till date, are generally limited to tasks that can be described by or decomposed into multiple subtasks that, each consisting of a sequence of steps, where some kind of fixed ordering of actions exists. This kind of goal-awareness can be more accurately described as mission-awareness. In complex, real-world scenarios, intelligent agents need to understand not just immediate goals, or missions, but also how multiple intermediate \u2013 often seemingly contradictory goals and subgoals fit into broader contexts, including societal interests (e.g., avoiding physical harm, minimizing climate change or promoting inclusiveness). Ultimately, the ability to incorporate/understand high-level goals allow AGI to reason about trade-offs and determine the best courses of action to maximize overall success. By contrast mission-awareness involves goal-directed behavior on a specific task or related sets of tasks."}, {"title": "Situational-awareness", "content": "Embodied perception, that is, situational-awareness by em-bodied agents, involves two main aspects: the awareness of the environment and awareness of other strategic agents."}, {"title": "Awareness of the environment and the general context", "content": "The most important task in embodied Al research is aimed at enhancing the situational-awareness of agents their ability to make sense of the real world in a way that allows them to interact with it and carry out actions towards the achievement of specific goals. Perception in the context of embodied cognition entails not only an understanding of the current state of the world and the processes occurring in it, but also an understanding of how the environment will change in the near and distant future as a result of various factors, including, most importantly, the effects of the actions of the agent and/or other agents. For humans, situational-awareness is a result of knowledge acquired through learning and experience, instincts and innate knowledge transmitted through genes, as well as \"on the fly\" information provided by other humans and intelligent systems. Intelligent agents based on LLMs also possess similar attributes. For example, the core model itself is a knowledge base for commonsense generic knowledge about the world [178], [179], [180], [181]. In addition, spe-cific information about the world can be acquired through various means."}, {"title": "Awareness of users and other agents", "content": "Most real-world settings are complex multi-agent en-vironments, where the behavior of agents is influenced not only by static and unintelligent inanimate objects and variables, but also by the intelligent and purposeful actions of other agents which can be cooperative or competitive at a given time. In such an environment, behavioral outcomes depend on the goals, intelligence and the overall compe-tences of other agents. However, it is often not possible to directly observe the properties \u2013 i.e., access the goals and strategies of other agents. These properties are inferred from the actions and reactions of the agents in the course of interaction. Prior knowledge about their behavior can also be incorporated in the LLM model. Specialized datasets and finetuning methods can also endow LLM models with knowledge about the behavior or other agents. Some works incorporate specialized cognitive modules to infer various attributes about other agents, including their believes, inten-tions, knowledge level and general state of mind [182], [183]. Hypothetical Minds (HM) [182] observes the action history of other agents and leverage the information to predict their strategies and output a high-level description in natural language which can then be utilized to refine the model's (HM's) own behavior."}, {"title": "Approaches to realizing situational-awareness in em-bodied LLMs", "content": "The most straightforward approach to realize embodi-ment in LLMs is to design and implement embodied agents in the form of robots with appropriate sensing modalities and then integrate the advanced language understanding capabilities with the robot's physical and sensory mech-anisms. Embodied generalist agents must perform multi-ple tasks at the same time: perception, planning, naviga-tion, object manipulation, natural language communication, physical interaction with humans and other Al agents, as well as and low-level control tasks. In principle, general-ist embodied agents can be trained on specially-curated embodied datasets such as EgoExoLearn [184", "185": "EgoTracks [186", "187": "in an end-to-end manner. Special embodied multimodal models such as EmbodiedGPT [172", "64": "and AlanaVLM [188", "189": [190], "191": "leverage wearable sensors like accelerometers, inertial measurement units (IMUs), global navigation satellite systems (GNSS), head-mounted displays (HMDs) and gyroscopes to capture additional information (e.g., location, orientation, pose, etc.) about the environments, objects, humans and the activities. Thus, the task of training a multimodal model is to learn a common representation for these multiple sensory infor-mation types. While this approach has demonstrated im-pressive capabilities for robots and embodied autonomous agents, it is exorbitantly costly and time-consuming to col-lect such datasets.\nSince it is often difficult and costly to develop and train language models from scratch for general-purpose multisensory embodied robotic systems, most works typi-cally fine-tune pretrained multimodal large language mod-els with task-specific datasets. That is, the realization of physical systems for embodied AI involves adapting the model to handle specific tasks and interactions \u2013 e.g., navi-gation [192", "193": [194], "195": [196], "197": [198]}, {"64": "is specifically designed for kitchen settings. Therefore, the most common tasks it performs are navigation in the kitchen environ-ment, recognizing household objects, picking and placing cooking utensils and other objects, assisting with general chores relating to cooking, cleaning, and serving food. Thus, the approaches are usually domain-specific addressing a restricted set of situations. Owing to the difficulty in cu-rating sufficiently large and diverse real data for embodied tasks, many works [199", "200": [201], "202": "EgoGen [203", "204": "synthetic egocentric data have been proposed. Generally, the target tasks and specific interactions the embodied AI needs to handle ("}]}