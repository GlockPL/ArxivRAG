{"title": "Large-Scale Multi-Robot Coverage Path Planning on Grids with Path Deconfliction", "authors": ["Jingtao Tang", "Zining Mao", "Hang Ma"], "abstract": "We study Multi-Robot Coverage Path Planning (MCPP) on a 4-neighbor 2D grid G, which aims to compute paths for multiple robots to cover all cells of G. Traditional approaches are limited as they first compute coverage trees on a quadrant coarsened grid H and then employ the Spanning Tree Coverage (STC) paradigm to generate paths on G, making them inapplicable to grids with partially obstructed 2 \u00d7 2 blocks. To address this limitation, we reformulate the problem directly on G, revolutionizing grid-based MCPP solving and establishing new NP-hardness results. We introduce Extended-STC (ESTC), a novel paradigm that extends STC to ensure complete coverage with bounded suboptimality, even when H includes partially obstructed blocks. Furthermore, we present LS-MCPP, a new algorithmic framework that integrates ESTC with three novel types of neighborhood operators within a local search strategy to optimize coverage paths directly on G. Unlike prior grid-based MCPP work, our approach also incorporates a versatile post-processing procedure that applies Multi-Agent Path Finding (MAPF) techniques to MCPP for the first time, enabling a fusion of these two important fields in multi-robot coordination. This procedure effectively resolves inter-robot conflicts and accommodates turning costs by solving a MAPF variant, making our MCPP solutions more practical for real-world applications. Extensive experiments demonstrate that our approach significantly improves solution quality and efficiency, managing up to 100 robots on grids as large as 256 \u00d7 256 within minutes of runtime. Validation with physical robots confirms the feasibility of our solutions under real-world conditions.", "sections": [{"title": "I. INTRODUCTION", "content": "Coverage Path Planning (CPP) addresses the problem of determining a path that fully covers a designated workspace [1]. This problem is essential for a broad spectrum of robotic applications, from indoor tasks like vacuum cleaning [2] and inspection [3] to outdoor activities such as automated harvesting [4], planetary exploration [5], and environmental monitoring [6]. Multi-Robot Coverage Path Planning (MCPP) is an extension of CPP tailored for multi-robot systems, aiming to coordinate the paths of multiple robots to collectively cover the given workspace, thereby enhancing both task efficiency [7] and system robustness [8]. A fundamental challenge of MCPP is to balance the costs across multiple robots, often quantified by the makespan\u2014the maximum path cost among all robots. This challenge intensifies in large-scale applications where the number of robots and the size of the workspace significantly increase."}, {"title": "II. RELATED WORK", "content": "In this section, we survey related work on MCPP and MAPF."}, {"title": "A. Multi-Robot Coverage Path Planning (MCPP)", "content": "Following the existing taxonomy on CPP [23], we categorize MCPP methods into grid-based, cellular decomposition, and global methods based on their approach to workspace decomposition.\nGrid-Based Methods: Grid-based methods conceptualize the workspace as a grid graph G [24]\u2013[26], allowing for the application of various graph algorithms. These methods traditionally operate exclusively on a quadrant coarsened H derived from G and fail when H is incomplete. They generalize the Spanning Tree Coverage (STC) paradigm for single-robot CPP in two ways. Single-tree methods [12], [15] compute a spanning tree on H, generate a coverage path on G that circumnavigate this tree, and then segment this path to distribute among multiple robots. These methods do not offer guarantees on solution quality due to their simplistic approach to path distribution. Multi-tree methods [13], [14], [16] compute multiple coverage trees, each rooted at the root vertex of a specific robot, to jointly cover all vertices of H, and then generate the coverage paths on G for the robots by circumnavigating their respective trees. In essence, multi-tree methods reduce MCPP to the NP-hard Min-Max Rooted Tree Cover problem [27], [28], yielding an asymptotic suboptimality ratio of four in makespan minimization on grid graphs. It is important to note that, unlike our direct formulation of MCPP on an edge-weighted G, existing grid-based methods typically formulate MCPP on a vertex-weighted H, making a restricted assumption that the weight of each vertex in H is evenly distributed among its corresponding four vertices in G.\nCellular Decomposition Methods: Cellular decomposition methods [29]\u2013[31] divide the workspace into sub-regions by detecting geometric critical points, using techniques such as trapezoidal decomposition [32], boustrophedon decomposition [33], and Morse decomposition [34]. After dividing the workspace, these methods generate a back-and-forth patterned path to cover each sub-region, often optimizing the path alignment orientation to enhance coverage efficiency [35]. While these methods are effective in structured environments, their performance diminishes in areas dense with obstacles or in non-rectilinear workspaces due to their reliance on geometric partitioning. Furthermore, they typically assume uniform traversal costs across the workspace, limiting their applicability in scenarios where robots have varying movement costs or task-specific coverage demands.\nGlobal Methods: Global methods find significant application in additive manufacturing [36]\u2013[38] (also known as layered fabrication), where a 3D object is printed layer by layer. Each layer poses a unique coverage problem, necessitating the planning of a space-filling curve to ensure the nozzle covers the entire 2D plane effectively. These methods focus on minimizing path curvature and discontinuities without explicitly decomposing the workspace. Recent advancements include the adaptation of the connected Fermat spiral [39] to reduce energy consumption in CPP tasks over undulating terrains [40] and to minimize the makespan in general MCPP scenarios [41]. The coverage quality of global methods largely depends on the characteristics of the space-filling curve generated, often necessitating additional trajectory optimization in a post-processing step."}, {"title": "B. Multi-Agent Path Finding (MAPF)", "content": "MAPF aims to compute conflict-free plans for multiple agents to move from their start vertices to their goal vertices. It is NP-hard to solve optimally for makespan minimization on grid graphs [42]. We highlight only relevant MAPF variants where each agent is given multiple goal vertices and direct readers interested in broader MAPF discussions to detailed surveys [18], [43]. OMG-MAPF [44] specifies a total order on the goal vertices given to each agent, while MAPF-PC [45] specifies precedence constraints-some goal vertex must be visited before another. MG-MAPF [46]\u2013[48] does not specify a specific visiting order for the goal vertices given to each agent but instead aims to solve the goal sequencing problem jointly with MAPF. Multi-agent Pickup and Delivery (MAPD) [49]\u2013[51] does not pre-assign goal vertices to agents and aims to solve the goal allocation and sequencing problem jointly with MAPF. All the above MAPF variants assume unit action costs and discrete time steps and do not directly apply to the problem of deconflicting MCPP solutions on graphs with nonuniform edge weights."}, {"title": "III. MCPP AND ITS NP-HARDNESS", "content": "We consider a set $I = \\{1, 2, . . .,k\\}$ of $k$ robots operating on a four-neighbor connected undirected 2D grid graph $G = (V, E)$, where $V$ is the set of vertices and $E$ is the set of edges connecting each vertex to its top, bottom, left, and right neighbors if they exist. We assign each edge $e \\in E$ with a nonnegative weight $w_e$ and simply set $w_e = 1$ for every $e \\in E$ when considering an unweighted graph $G$. We specify a set $R = \\{r_i\\}_{i=1}^k \\subseteq V$ of root vertices, where each robot $i$ starts at vertex $r_i$. We use the tuple $(G, I, R)$ to denote an MCPP instance.\nA path $\\pi_i$ for robot $i$ is defined as a finite ordered sequence of vertices $(v_1, v_2, ...,v_{|\\pi_i|})$ such that $v_1 = v_{|\\pi_i|} = r_i$ and $(v_{j-1}, v_j) \\in E$ for each $j = 2,3,...,|\\pi_i|$. The cost of any path is defined as $c(\\pi) = \\sum_{e \\in \\pi} w_e$. For clarity, we let $V(\\pi)$ and $E(\\pi)$ denote the set of unique vertices in $\\pi$ and the multiset of edges in $\\pi$ that possibly contains repeated edges, respectively.\nThe MCPP problem is defined as follows:\nProblem 1 (MCPP). Find a set $\\Pi = {\\pi_i}_{i=1}^k$ of paths such that $\\bigcup_{i=1}^k V(\\pi_i) = V$.\nThe above problem formulation aligns with the cover with return coverage setting [14], where each robot must start from and return to its given root vertex. The quality of an MCPP solution is evaluated using the makespan metric, denoted by $\\theta(\\Pi) = \\max\\{c(\\pi_1), c(\\pi_2), ..., c(\\pi_k)\\}$.\nMCPP can be viewed as an extension of min-max m-TSP on grid graphs where multiple depots exist and each city is allowed to be visited more than once. Given that the Hamiltonian cycle problem on grid graphs is NP-complete [52], both (single-robot) CPP and thus MCPP are NP-hard, which"}, {"title": "IV. EXTENDED SPANNING TREE COVERAGE (ESTC)", "content": "In this section, we present our new ESTC paradigm that advances standard STC-based paradigms by addressing coverage problems on any given connected gird graph, even when the quadrant coarsening H is incomplete. We first describe how ESTC solves (single-robot) CPP, a special case of MCPP (Problem 1) when $k = |I| = 1$. Solving CPP efficiently is fundamental to our local search framework for MCPP detailed in Sec. V. We then analyze the properties and time complexity of ESTC and introduce two local optimizations to improve ESTC solutions. We finally discuss how ESTC can be integrated into existing MCPP methods to effectively handle incomplete H.\nESTC extends both the STC paradigm for offline CPP and the Full-STC paradigm [55] for online CPP, which operate on a quadrant coarsened grid H derived from G. These paradigms typically evaluate the traversal costs by decomposing the given hypervertex weights of H into vertex weights for G to maintain solution optimality. However, this approach does not adequately capture the actual traversal time costs incurred by a robot, which are better represented by the edges traversed, as defined in our formulation."}, {"title": "A. Algorithm Description", "content": "ESTC operates on a hypergraph graph $H = (V_h, E_h)$, derived from the grid graph $G = (V, E)$. Similar to standard STC-based paradigms, ESTC attempts to contract neighboring vertices of $V$ corresponding to a $2 \\times 2$ block of grid cells into a hypervertex of $V_h$. However, unlike the quadrant coarsened grid $H$ used by standard STC-based paradigms, the hypergraph $H$ effectively addresses the disconnections caused by partially obstructed $2 \\times 2$ blocks. A hyperedge connects two hypervertices only if there is at least one adjacent vertex pair from these hypervertices. A special case in hypervertex"}, {"title": "B. Theoretical Analysis", "content": "ESTC is guaranteed to generate a path that covers all vertices of a connected grid graph G based on the argument used in the proof of Lemma 3.1 in [55] since the argument is not affected by the addition of edge weights.\nTheorem 3. ESTC achieves complete coverage on a connected grid graph G.\nWe now analyze the time complexity of ESTC.\nTheorem 4. The time complexity of ESTC (Alg. 1) on a grid graph $G = (V, E)$ is $O(|V|log|V|)$.\nProof. To construct the hypergraph $H = (V_h, E_h)$ from $G = (V, E)$ as described in Sec. IV-A, ESTC first iterates"}, {"title": "C. Local Optimizations", "content": "We introduce two efficient local optimizations for ESTC, namely Parallel Rewiring and Turn Reduction. Parallel Rewiring operates as a post-processing procedure to refine the coverage path produced by ESTC, by strategically adjusting path segments locally to reduce the path cost. Turn Reduction serves as a secondary objective during the execution of ESTC (see Alg. 1) by reducing the number of turns in the path, which is particularly beneficial in environments where turning is costly or undesirable. While these local optimizations do not theoretically improve the upper bound on the suboptimality of"}, {"title": "D. Integration into Existing MCPP Methods", "content": "Existing grid-based MCPP methods often focus on special cases of MCPP that assume complete hypervertices and vertex-weighted graphs. However, our more generally formulated MCPP, as defined in Problem 1, addresses a broader scope that remains relatively unexplored in the literature, despite its significant practical relevance. The proposed ESTC paradigm can be seamlessly integrated into these existing methods, allowing them to effectively solve MCPP even without the above constraints typically assumed. To demonstrate how existing MCPP methods can be adapted using the ESTC paradigm to solve an MCPP instance on any grid graph G, even when some hypervertices are incomplete, we use the following examples categorized into multi-tree and single-tree methods.\n1) Multi-Tree Methods: For MCPP instance $(G, I, R)$, we first generate a set $\\{G_i = (V_i, E_i)\\}_{i=1}^k$ of $k$ connected subgraphs of G. Each $G_i$ contains the root vertex $r_i$. We then solve each sub-CPP instance for robot $i$ on $G_i$ as described in Alg. 1 to generate its coverage path. The following theorem shows a sufficient condition for complete coverage.\nTheorem 7. If each $G_i$ is connected and $\\bigcup_{i=1}^k V_i = V$, then using ESTC is guaranteed to achieve complete coverage of G.\nProof. Given that $G_i$ is connected, ESTC is guaranteed to generate a path that covers all its vertices due to Theorem 3. If $\\bigcup_{i=1}^k V_i = V$, then the coverage paths generated for all $G_i$ jointly cover all vertices of G.\nThe design of our LS-MCPP framework is based on the principle expounded in the above theorem. It aims to search for a good set of subgraphs $G_i$ for the robots, each being connected and containing the root vertex $r_i$, with the property that the union of all their vertices comprises the entire vertex set of G to ensure complete coverage. It now suffices to outline the below details for adapting existing methods to compute the $k$ subgraphs, with comprehensive numerical results provided in Sec. VII.\nVOR: VOR is a baseline method introduced in [22] that is inherently compatible with ESTC. It partitions G into $k$ subgraphs $\\{G_i\\}_{i=1}^k$ as a Voronoi diagram [57], using the set R of root vertices as the pivot points and shortest path distances on G as the distance metric.\nMFC: Multi-Robot Forest Coverage (MFC) [13], [14] employs the Rooted-Tree-Cover procedure [27] to heuristically compute a rooted tree cover on the quadrant coarsened grid H\u2014a forest of k trees $\\{T_i\\}_{i=1}^k$, each rooted at the hypervertex containing the root vertex $r_i$, which jointly cover all hypervertices of H. MFC then generates a coverage path for each robot $i$ by applying STC on its tree $T_i$. To integrate MFC with ESTC, we apply the Rooted-Tree-Cover procedure on the hypergraph H (constructed as per Sec. IV-A) instead of H to generate a rooted tree cover on H that induces the set of $k$ subgraphs $\\{G_i\\}_{i=1}^k$ of G.\nMIP: MIP [16] solves a mixed-integer program to compute an optimal rooted tree cover on the quadrant coarsened grid H that minimizes the maximum tree weight. To integrate MIP with ESTC, we adapt the mixed-integer program to compute an optimal rooted tree cover on the hypergraph H (constructed"}, {"title": "V. THE LS-MCPP FRAMEWORK", "content": "In this section, we introduce LS-MCPP, our local search algorithmic framework designed to effectively address MCPP as formulated in Problem 1. This framework integrates three types of neighborhood operators and utilizes ESTC as a subroutine, enhancing its ability to solve MCPP even in complex environments with incomplete hypervertices. LS-MCPP aims to optimize coverage paths by iteratively refining subgraphs and their corresponding coverage paths, ensuring both efficiency and completeness in coverage solutions."}, {"title": "A. Overview", "content": "As shown in Fig. 6, LS-MCPP takes begins with an initial solution for the MCPP instance $(G, I, R)$ with its corresponding set $G_o = \\{G_i = (V_i, E_i)\\}_{i=1}^k$ of $k$ connected subgraphs induced by the solution paths. LS-MCPP operates as an iterative procedure that employs a two-layer hierarchical sampling scheme, progressively adjusting the subgraph set G to efficiently explore the constructed neighborhood: The first layer selects an operator pool using roulette wheel selection [58] from three operator pools, each containing a different type of operators; The second layer heuristically selects an operator from the chosen pool, as detailed in Sec. V-D.\nWe categorize $G_i$ as a light subgraph if its coverage path cost $c(\\pi_i)$ from ESTC is no larger than the average coverage path cost over all subgraphs; otherwise, it is a heavy subgraph. We define the duplication set $V^+ = \\{v \\in V | n_v > 1\\}$ as the set of vertices included in more than one subgraph, where $\\eta_v = \\sum_{i=1}^k |\\{x \\in V_i | x = v\\}|$ counts the occurrences of vertex $v \\in V$ in all subgraphs.\nLS-MCPP employs grow operators on light subgraphs to assign them new vertices to cover, deduplicate operators on heavy subgraphs to eliminate unnecessary duplication, and exchange operators to balance path costs between subgraphs with a large cost difference. The operators are detailed in Sec. V-C, designed to attain a cost-equilibrium MCPP solution with a low makespan. LS-MCPP then employs ESTC on each subgraph $G_i$ to generate its coverage path and evaluate the makespan. LS-MCPP also periodically calls a deduplication function to exploit the current subgraphs to achieve a low-makespan solution."}, {"title": "B. Algorithm Description", "content": "Pseudocode (Alg. 2): LS-MCPP begins by computing the corresponding set $G_o$ of subgraphs on the input initial MCPP solution $I_o$ [Line 1]. It then initializes a set of three operator pools via a subroutine Update-Pools described in Sec. V-C, containing only grow operators, deduplicate operators, and exchange operators, respectively [Lines 3-4]. It also initializes the temperature scalar $t$ and the pool weight vector $p$ [Lines 5-6]. The scalar $t$ is scaled down by the decay factor $\\alpha \\in [0, 1]$ for every iteration [Line 22] to dynamically adjust the probability for LS-MCPP to become increasingly less likely to accept a non-improving solution over iterations, which is the simulated annealing strategy [59] to skip local minima. The vector $p$ represents the pool weight for each of the three aforementioned pools. During each iteration [Line 7], vector $p$ is used for roulette wheel selection [58] to select a pool O from O [Line 8], where $\\sigma(p)$ is the softmax function of $p$ determining the probability of selecting each pool. Once the pool O is selected, its corresponding weight $p[O]$ is updated with a weight decay factor $\\gamma \\in [0, 1]$ [Line 9]. Similar to the pool selection, LS-MCPP samples an operator"}, {"title": "C. Pools of Operators", "content": "We introduce three types of operators: grow operators, deduplicate operators, and exchange operators. These operators are designed to modify the boundaries of each connected subgraph $G_i = (V_i, E_i) \\in G$ of the input graph $G = (V, E)$. An operator alters the set G while ensuring that its property of complete coverage (i.e., $\\bigcup_{i=1}^k V_i = V$) and subgraph connectivity remains invariant. Each operator aims to introduce only essential duplication, with the potential to enhance solution quality.\nSpecifically, we consider both edge-wise and vertex-wise operations for these operators. An edge-wise operator alters a single edge at a time, whereas a vertex-wise operator alters a single vertex at a time. Altering a crossing edge $(u, v) \\in E$ with $\\delta_u \\neq \\delta_v$ often introduces unnecessary vertex duplications. Therefore, we restrict the edge-wise operators to only altering intra-hypervertex edges $E_{\\text{intra}} = \\{(u,v) \\in E | \\delta_u = \\delta_v\\}$. In practice, edge-wise operators generally perform well but sometimes cannot be constructed in configurations with many incomplete hypervertices, which may lead to early termination of the local search (Alg. 2). Vertex-wise operators are less restricted than edge-wise operators and tend to introduce unnecessary vertex duplications if applied to complete hypervertices. Therefore, vertex-wise operators serve only as complementary tools when no edge-wise operators are available, as reflected in the Update-Pools function (Alg. 4), which initializes or updates the operator pools.\nGrow Operator: A grow operator serves to expand a subgraph to cover additional vertices already covered by other subgraphs. Let $B_i$ denote the set of \"boundary\" vertices that are not part of $G_i$ but adjacent to a vertex of $G_i$, defined as $B_i = \\{v \\in V \\setminus V_i | \\exists (u, v) \\in E, u \\in V_i\\}$. A vertex-wise grow operator $o_g(i, \\{v\\})$ adds vertex $v \\in B_i$ and all its adjacent edges to subgraph $G_i$. An edge-wise grow operator $o_g(i, \\{u, v\\})$ adds edge $e = (u, v) \\in E_i \\cap E_{\\text{intra}}$ with $u, v \\in B_i$ and all its adjacent edges into $G_i$, where $\\exists (p,q) \\in E_i$ such that $(u,p), (v, q) \\in E_i$. In essence, a valid $o_g(i, e)$ can only add an edge $(u, v)$ if there exists a parallel edge $(p,q)$ in $G_i$, as shown in the two examples in Fig. 8-(b)(c). This design choice avoids introducing undesirable routing to the coverage path, as shown in the example in Fig. 8-(a). After its execution,"}, {"title": "VI. DECONFLICTING MCPP SOLUTIONS", "content": "In this section, we address inter-robot conflicts in coverage paths produced by LS-MCPP or other grid-based MCPP methods. The MCPP problem formulation does not inherently prevent collisions among robots. In an MCPP solution with a small makespan, robots typically cover different regions and are distributed across the grid, which lowers the likelihood of conflicts. However, certain regions remain prone to congestion and conflicts, particularly around clustered root vertices or narrow corridors that only allow one robot to pass at a time.\nTo resolve these potential conflicts, we formulate the de-conflicting task as a variant of MAPF, leveraging MAPF techniques to ensure each robot follows its designated coverage path while avoiding collisions with others. Specifically, we develop a two-level hierarchical planner, following standard MAPF practices, to effectively deconflict MCPP solutions: The high-level planner employs Priority-Based Search (PBS) [60] to assign priorities among pairs of conflicting robots; The low-level planner is a novel algorithm that plans a continuous-time path for each robot that avoids conflicting with any higher-priority robots. Our key extensions from standard MAPF lie in 1) our treatment of non-uniform edge weights, which translate to variable time costs for robot actions and 2) an adaptive approach of the low-level planner for time-efficient single-robot path planning with multiple goals."}, {"title": "A. Formulation of Deconflicted MCPP", "content": "Given an input solution $\\Pi = {\\pi_i\\}_{i=1}^k$ for the MCPP instance $(G, I, R)$, we define the Deconflicted MCPP problem, which aims to construct a set $T = \\{T_i\\}_{i=1}^k$ of $k$ conflict-free trajectories. A trajectory $T_i$ for robot $i$ is an ordered sequence $(x_1,..., x_{|T_i|})$ of time-embedded states $x = (v,t)$ indicating that the robot stays at vertex $v \\in v$ at time $t \\geq 0$. Given path $\\pi_i = (v_1,..., v_{|\\pi_i|})$ where $v_1 = v_{|\\pi_i|} = r_i \\in R$, trajectory $T_i$ must start from state $x_1 = (v_1, 0)$, visit all vertices in the specified order of $\\pi_i$, and end with state $x_T = (v_{\\pi_i}, \\cdot)$. Formally, there exist indices $a_1 = 1 < a_2 < ... < a_{|\\pi_i|} = |T_i|$ such that $x_{a_j} = (v_j, \\cdot)$ for all $j = 1,...,|\\pi_i|$. To transit from state $(u,t)$ to the next state $(v,t')$ in a trajectory, the robot performs a wait-and-move action, where it waits at v for $t' - w_e - t > 0$ and then moves from u to v along edge $e = (u,v) \\in E$ with a time cost of $w_e > 0$. Let $\\tau[j]$, $x.v$ and $x.t$ denote the j-th state in T, the vertex and time in each state x, respectively. The quality of a Deconflicted MCPP solution T is evaluated using the makespan metric, denoted by $\\theta(T) = \\max\\{\\tau_1[|T_1|].t, ..., \\tau_k[|T_k|].t\\}$, which is consistent with that used for MCPP."}, {"title": "B. The High-Level Planner", "content": "The high-level planner employs Priority-Based Search (PBS) [60] to resolve conflicts defined in Definition 1. PBS searches a priority tree where each node N stores a unique priority ordering given by a set of ordered pairs of robots and a set N.T of k trajectories that respect the prioritized planning scheme specified by N. The root node contains an empty priority set and a set of potentially conflicting trajectories. When PBS expands a node N, it checks N.T for conflicts. If no conflicts are found, then N is a goal node, and N.P is the solution. If conflicts exist between the trajectories of robots $i$ and $j$, PBS generates two child nodes, $N_1$ and $N_2$, and adds the pair $i  j$ to $N_2$. For child node $N_1$, PBS invokes a low-level planner to update the trajectories of robot $j$ and other robots $j'$ with $j  \\pi_i \\in \\Pi$ does not traverse any root vertex $r_j \\in R$ of robot $j \\neq i$."}, {"title": "C. The Low-level Planner", "content": "The lower-level computes a trajectory $T_i$ for robot $i$ that sequentially visits vertices along the given $\\pi_i$. It uses a reservation table that records the reserved intervals for each vertex, ensuring the resulting trajectory $T_i$ avoids conflicts with higher-priority trajectories.\nReservation Table: To accommodate planning in an edge-weighted graph, we adopt the idea from Safe Interval Path Planning (SIPP) [62], [63] to reserve continuous-time intervals, instead of discrete time steps in the classic vertex-time A* [64]. The reservation table is indexed by a vertex, with the corresponding entry recording the reserved intervals during which the vertex is occupied. Specifically, following the conflict definition (Definition 1), given state $(v,t)$, the reservation table records the reserved interval $[t_p, t_s)$ for vertex $v$, where $(v_p, t_p)$ and $(v_s, t_s)$ are the preceding and succeeding states of state $(v, t)$, respectively. Notably, the reservation also records $[0, t_s)$ for the first state $(r_j, 0)$ and $[t_p, +\\infty)$ for the last state in each higher-priority trajectory $T_j$. The safe intervals for each vertex $v$ are obtained as the complements of its reserved intervals with respect to interval $[0, +\\infty)$.\nSIPP Node Expansion: The low-level planner uses A* search to generate a search tree, where each node n is uniquely identified by a pair $(v, [lb, ub))$, consisting of a vertex $v$ and one of its safe intervals $[lb, ub)$. The g-value $g(n) \\in [lb, ub)$ of a node n stores the earliest arrival time at which the robot can stay at vertex $v$ within the safe interval $[lb, ub)$ along any path. When expanding node $n = (v, [lb, ub))$, the search generates a child node $n' = (u, [lb', ub'))$ with $g(n')$ for each vertex u adjacent to v and each safe interval $[lb', ub')$ of u, corresponding to the action of waiting at v for the minimal duration $g(n') - w_{(v,u)} - g(n) \\geq 0$, then departing from v at time $g(n') - w_{(v,u)}$ and arriving at u at the earliest available time $g(n')$. The search discards node n' if no valid arrival time $g(n')$ is available such that $g(n') \\geq lb'$ with the corresponding"}, {"title": "D. Integrating Turning Costs", "content": "So far, the trajectory computation assumes the robots are holonomic, that is, they can move omnidirectional without the need to change their headings between consecutive move actions. We now show that one can remove this assumption for non-holonomic robots by adding an orientation $\\psi \\in \\{E, N, W, S\\}$ to the state space, restricted to East (E), North (N), West (W), and South (S) in the four-neighbor grid graph G. Correspondingly, we allow a robot to turn at vertex v from $\\psi$ to $\\psi' \\neq \\psi$ at a time cost of $t'-t = C_{\\frac{90^{\\circ}}{\\tau}} > 0$, where $C_{\\frac{90^{\\circ}}{\\tau}}$ is a constant cost for a 90\\textdegree turns. Effectively, each robot performs a turn-wait-move action. With this modification, one can deconflict an MCPP solution for non-holonomic robots."}, {"title": "VII. EXPERIMENTS AND RESULTS", "content": "This section describes our numerical results of simulations on an Ubuntu 22.04 PC with a 2.50GHz Intel\u00ae Core\u00ae i5-13490F CPU and 32GB RAM. Our proposed algorithms and the baseline methods are publicly available at Github\u00b3, with all the benchmark instances and reported numerical results provided as well. In Sec. VII-D, we deployed the proposed algorithms on two Pepper\u2074 robots in an indoor environment to validate our planning pipeline for MCPP."}, {"title": "A. Experiment Setup", "content": "Instances: We generate a set of instances to benchmark different methods utilizing the four-way connected 2d undirected grid graphs from previous grid-based MCPP works [16], [22] as well as the 2D pathfinding benchmark [9]. As shown in Fig. 10, the graphs in row 1 have unweighted edges with a uniform weight of 1, whereas the graphs in row 5 have weighted edges whose weights are randomly generated from 1 to 3. Originally, each graph can be contracted to a hypergraph where all its hypervertices are complete. The original graphs are then used to generate 12 groups of 12 mutated MCPP instances (i.e., mutations) of k robots, resulting from a removal ratio $\\rho = 0, 1, ..., 11$ and a seed $s = 0, 1, ..., 11$. Each mutation $(G, I, R)$ with $\\rho$ and $s$ is constructed by (1) randomly sampling (with seed $s$) a set of k vertices from G as R and (2) randomly removing (with seed $s$) vertices from G by $\\frac{x}{100} = (\\frac{12}{100} \\cdot \\rho)\\%$, meanwhile ensuring the root vertex of any robot and all its neighbors are not removed. The root vertices in R are sampled to ensure they are not cut vertices for constructing well-formed instances [60], [68], that is, a robot can wait indefinitely at its root vertex without blocking any other robot. Note that the graph edge weights of each mutation are also randomly generated using its corresponding seed s. For all mutations, we set $C_{\\frac{90^{\\circ}}{\\tau}} = 0.5$ as the 90\u00b0 turning cost as described in Sec. VI-D.\nBaselines: We describe all the methods being compared in our experiments. (1) Single-Robot CPP: To verify the effectiveness of our ESTC with the proposed hyperedge weight definition, we use a baseline method, namely ESTC-UW, that computes the circumnavigating coverage path on a spanning tree assuming the edges are unweighted. We also performed an ablation study on the two local optimizations for ESTC: parallel rewiring (PR) in Sec. IV-A and turn reduction (TR) in Sec. IV-C. (2) MCPP: As mentioned in Sec. IV-D, the proposed ESTC algorithm can be integrated into various grid-based MCPP methods, making them immediately applicable to MCPP. To reiterate, VOR, MFC, MIP, and MSTC* are the comparing baseline methods with our LS-MCPP. In addition,"}, {"title": "B. Ablation Study", "content": "Single-Robot CPP: Comparing all four ESTC variants with the baseline ESTC-UW", "reductions.\nMCPP": "We compare the solution quality of MCPP between different methods in rows 3 and 7 of Fig. 10. Generally speaking, the mutated instances become more complex as the vertex removal"}]}