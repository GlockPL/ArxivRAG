{"title": "Towards Agentic Schema Refinement", "authors": ["Agapi Rissaki", "Ilias Fountalis", "Nikolaos Vasiloglou", "Wolfgang Gatterbauer"], "abstract": "The goal of a semantic layer. Understanding the meaning of data is crucial for performing data analysis, yet for the users to gain insight into the content and structure of their database, a tedious data exploration process is often required [2, 16]. A common industry practice taken on by specialists such as Knowledge Engineers is to explicitly construct an intermediate layer between the database and the user a semantic layer - abstracting away certain details of the database schema in favor of clearer data semantics [3, 10]. In the era of Large Language Models (LLMs), industry practitioners and researchers attempt to circumvent this costly process using LLM-powered Natural Language Interfaces [4, 6, 12, 18, 19, 22]. The promise of such Text-to-SQL solutions is to allow users without technical expertise to seamlessly interact with databases. For example, a new company employee could effectively issue queries in natural language without programming expertise or even explicit knowledge of the database structure, e.g., knowing the names of entities or properties, the exact location of data sources, etc. However, current Text-to-SQL solutions are far from perfect due to many factors, mainly related to ambiguous representations, such as data and query ambiguity [9], schema complexity (e.g., vast schema, wide tables, cryptic column names) [5], among others. For these reasons, we argue that a semantic layer can be useful for human users and AI tools alike.\nContribution 1: Semantic layer as a set of distilled views. We propose to define the semantic layer as a set of easy-to-interpret and reusable database views. A view is a virtual table that is the result of a stored query, that can be used as any other table when writing subsequent queries [20]. Database views are structured objects that can be constructed in-database, allowing for seamless integration with existing system components using direct communication in SQL. In particular, we explore the underlying database in order to discover views that represent entities together with their properties, as well as relationships between them. Thus, our semantic layer augments a hard-to-interpret existing database schema with additional automatically generated and easy-to-interpret views, which distill the semantic knowledge into smaller bits. Note that this approach can also be viewed as a schema refinement process, effectively reformulating the original tables into a larger set of more manageable ones, each with fewer columns, and clearly defined semantics.\nContribution 2: Agentic programming for schema refinement. Discovering such semantically meaningful database views is not a trivial task. If we had access to a vast log of past queries, we could attempt to mine a set of such views by targeting the queries or subqueries that appear frequently. Instead, we consider an even more challenging scenario where we only have access to the schema and the database. In this case, it seems impossible to recognize which parts of the data are semantically meaningful in an automated way; some form of external knowledge is necessary. Our solution uses LLMs to inject external knowledge into the process and to guide the view discovery.", "sections": [{"title": "Introduction", "content": "The goal of a semantic layer. Understanding the meaning of data is crucial for performing data analysis, yet for the users to gain insight into the content and structure of their database, a tedious data exploration process is often required [2, 16]. A common industry practice taken on by specialists such as Knowledge Engineers is to explicitly construct an intermediate layer between the database and the user a semantic layer - abstracting away certain details of the database schema in favor of clearer data semantics [3, 10]. In the era of Large Language Models (LLMs), industry practitioners and researchers attempt to circumvent this costly process using LLM-powered Natural Language Interfaces [4, 6, 12, 18, 19, 22]. The promise of such Text-to-SQL solutions is to allow users without technical expertise to seamlessly interact with databases. For example, a new company employee could effectively issue queries in natural language without programming expertise or even explicit knowledge of the database structure, e.g., knowing the names of entities or properties, the exact location of data sources, etc. However, current Text-to-SQL solutions are far from perfect due to many factors, mainly related to ambiguous representations, such as data and query ambiguity [9], schema complexity (e.g., vast schema, wide tables, cryptic column names) [5], among others. For these reasons, we argue that a semantic layer can be useful for human users and AI tools alike.\nContribution 1: Semantic layer as a set of distilled views. We propose to define the semantic layer as a set of easy-to-interpret and reusable database views. A view is a virtual table that is the result of a stored query, that can be used as any other table when writing subsequent queries [20]. Database views are structured objects that can be constructed in-database, allowing for seamless integration with existing system components using direct communication in SQL. In particular, we explore the underlying database in order to discover views that represent entities together with their properties, as well as relationships between them. Thus, our semantic layer augments a hard-to-interpret existing database schema with additional automatically generated and easy-to-interpret views, which distill the semantic knowledge into smaller bits. Note that this approach can also be viewed as a schema refinement process, effectively reformulating the original tables into a larger set of more manageable ones, each with fewer columns, and clearly defined semantics.\nContribution 2: Agentic programming for schema refinement. Discovering such semantically meaningful database views is not a trivial task. If we had access to a vast log of past queries, we could attempt to mine a set of such views by targeting the queries or subqueries that appear frequently. Instead, we consider an even more challenging scenario where we only have access to the schema and the database. In this case, it seems impossible to recognize which parts of the data are semantically meaningful in an automated way; some form of external knowledge is necessary. Our solution uses LLMs to inject external knowledge into the process and to guide the view discovery."}, {"title": "Approach", "content": "We present our approach for semantic layer construction, via a simple systematic schema refinement mechanism for view discovery (Section 2.1), implemented as a multi-agent simulation (Section 2.2)."}, {"title": "Schema refinement mechanism", "content": "The main idea behind view discovery is to start with complex queries and then express them in a simpler way by decomposing them into modular components. These components are separately defined as database views that encapsulate distinct portions of the query logic, frequently representing key entities or relationships within the data. This query refinement process effectively turns into schema refinement by producing several reusable views as byproduct."}, {"title": "Multi-agent framework", "content": "In our multi-agent system three agents (Analyst, Critic, and Verifier) engage in iterative, free-form conversations and collaboratively implement the proposed schema refinement mechanism (Fig. 2a). More specifically, our agents have the following distinct roles:\n\u2022 The Analyst implements analytics tasks, through the formulation of SQL queries and subsequently defines intermediate database views that refine these queries.\n\u2022 The Critic reviews these views to ensure that they are optimized with respect to query refinement, offering suggestions for improvement and proposing alternative formulations.\n\u2022 The Verifier validates the views by execution within a database engine, thereby ensuring their correctness, and may also use external tools for more sophisticated testing.\nEach simulation session receives as input a straightforward textual description of the database schema, supplemented by an optional small data sample. In most cases the schema is particularly large, thus the agents do not attempt to ingest it all at once. Instead, the process is performed on subsets of tables that join with each other, thereby encouraging the creation of views that integrate data from diverse sources. In particular, we sample connected components of the schema graph, i.e., the graph that represents tables as nodes and PK/FK pairs as edges. Further, we leverage a GraphRAG algorithm [8] to specialize the sampled subgraphs and thus guide the focus of each multi-agent session. Since the algorithm operates on graphs with features, we augment the schema graph with node and edge features that correspond to text embeddings of table and key descriptions, respectively.\nTo achieve comprehensive coverage of the database, multiple sessions can be executed sequentially (Fig. 2b). Agents maintain a history of prior sessions to avoid redundancy and promote diversity in their exploration of the database schema. This ensures that the process not only scales effectively but also delivers a broad and diverse semantic understanding of the data."}, {"title": "Experiments", "content": "We report a preliminary study of our framework, quantifying the effects of our schema refinement on a realistic commercial database and showing how our results aid data exploration. We observe that our method provides a practical normalization of the database into manageable components."}, {"title": "Case Study", "content": "We studied our approach on a realistic corporate database provided by Braze, a customer engagement platform, publicly available in Snowflake Marketplace 2. The database contains synthetic data and serves as a demo to Braze clients modelling user behavior and engagement with respect to events such as marketing campaigns. The provided schema consists of 61 mostly wide tables and 1770 columns in total (Fig. 3a). After a few hours of multi-agent simulation, we obtained"}, {"title": "Conclusion and Future Work", "content": "We proposed a view discovery approach to build a semantic layer within complex databases, implemented as a multi-agent simulation. In future work, we will use our semantic layer to boost text-to-SQL performance and we will integrate it into an interactive data exploration system."}, {"title": "Appendix", "content": "A1 Case Study: CMS Data Feeds\nIn this section we present an additional case study, this time on data feeds from the Centers for Medicare and Medicaid Services 3. This is a very large diverse database with a star-like schema, where two tables Feeds and Feed Files are both in the center.\nThe schema consists of 113 tables and 6879 columns in total, for which we obtained a set of 632 views. In Table 2, we see that most generated views have few columns (median width 4, maximum width 31) in contrast to tables in the original schema which can be extremely wide (maximum width 1130).\nIn this case, although the views cover 18.87% of the columns in the original schema, abstracting away too detailed information, only 0.5% of the original relationships among columns are preserved in the views. This is expected since 2 columns co-occurring in a table of extreme width do not necessarily reflect relations in the semantic level, thus the refinement process decomposes these kinds of tables preserving only key relations between columns and discarding the rest. Additionally, the views contain 1965 newly created pairwise relationships, associating columns from different origin tables."}, {"title": "Sample multi-agent chat", "content": "Critic, I have the following database schema.\n/// SCHEMA WORDING OMITTED FOR BREVITY\nPlease suggest an analysis task for me to work on.\nCritic (to chat_manager):\nI suggest you analyze the behavior of users who have interacted with both email\nand push notification campaigns. Specifically, you can compare the engagement\nmetrics (such as open rates, click-through rates, etc.) of these users across\ndifferent campaigns and attributes. This analysis can provide insights into the\neffectiveness of your email and push notification strategies for different user\nsegments. Let me know if you need more details or if you'd like to focus on a\nspecific aspect of this analysis.\nAnalyst (to chat_manager):\n\u201csql\nCount the number of users who have interacted with both email and push\nnotification campaigns\nWITH email_users AS (\n), \nSELECT DISTINCT USER_ID\nFROM USERS_MESSAGES_EMAIL_SEND_VIEW\npush_notification_users AS (\nSELECT DISTINCT USER_ID\nFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW\n)\nSELECT COUNT(*) AS total_users\nFROM email_users\nJOIN push_notification_users\nON email_users.USER_ID = push_notification_users.USER_ID;\nAnalyst (to chat_manager):\n\u201csql\nAnalyze the engagement metrics (open rates, click-through rates, etc.)\nof users who interacted with both email and push notification campaigns\nWITH email_engagement AS (\n), \nSELECT USER_ID, OPEN_RATE, CLICK_THROUGH_RATE\nFROM USERS_MESSAGES_EMAIL_SEND_VIEW\npush_notification_engagement AS (\n)\nSELECT USER_ID, OPEN_RATE, CLICK_THROUGH_RATE\nFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW\nSELECT AVG(email_engagement.OPEN_RATE) AS avg_email_open_rate,\nAVG(email_engagement.CLICK_THROUGH_RATE) AS avg_email_click_through_rate,\nAVG(push_notification_engagement.OPEN_RATE) AS avg_push_notification_open_rate,\nAVG(push_notification_engagement.CLICK_THROUGH_RATE) AS avg_push_notification_click_through_rate\nFROM email_engagement\nJOIN push_notification_engagement\nON email_engagement. USER_ID = push_notification_engagement.USER_ID;\nCritic (to chat_manager):\nYour queries are a good start, but I recommend defining some views to simplify\nand enhance the analysis:\n1. **View 1: users_interacted_with_email_push_campaigns**\nThis view will combine the distinct user IDs who\ninteracted with email and push notification campaigns.\nIt will be based on the common user interactions\nbetween the two types of campaigns.\n2. **View 2: email_engagement_metrics**\nThis view will extract relevant engagement metrics\n(open rates, click-through rates, etc.) for email campaigns.\nIt will provide a cleaner and more focused dataset for\nemail campaign analysis.\n3. **View 3: push_notification_engagement_metrics**\nThis view will extract relevant engagement metrics for\npush notification campaigns.\nIt will allow for a clearer and more concise analysis\nof push notification campaign engagement.\nBy creating these views, you can simplify your queries, make them more\nreusable, and ensure better readability. It's also a good practice to\nrename the columns in the views to make\nthem more descriptive. Once you have these views in place, you can further\nanalyze the engagement metrics or explore\nother aspects of user behavior. If you agree, please\nincorporate these views into your analysis. Let me know if you need any\nfurther clarification or assistance.\nAnalyst (to chat_manager):\nCreating View 1: users_interacted_with_email_push_campaigns\nCREATE VIEW users_interacted_with_email_push_campaigns AS\nSELECT USER_ID\nFROM USERS_MESSAGES_EMAIL_SEND_VIEW\nWHERE USER_ID IN (\nSELECT USER_ID\nFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW\nCritic (to chat_manager):\nYour approach to creating views for users who interacted with both email and\npush notification campaigns, as well as extracting engagement metrics for analysis,\nis well-structured and effective. The views you created will not only simplify\nyour queries but also make them more reusable and maintainable.\nI appreciate how you've renamed the columns in the views to make them more\ndescriptive and readable. This will help improve the overall quality of\nyour analysis and make it easier for users to understand the data being presented.\nYour final analysis query combining the engagement metrics of users who\ninteracted with both types of campaigns looks solid. It provides a clear\ncomparison between email and push notification engagement metrics, allowing\nfor insights into user behavior across different communication channels.\nKeep up the good work!\nAnalyst (to chat_manager):\nThank you for your feedback and guidance. I'm glad to hear that the views and\nanalysis approach meet your expectations.\nCritic (to chat_manager):\nGreat job. Goodbye.\nVerifier (to chat_manager):\n*** Suggested tool call (call_4dz4c1irNRJiOdrijI2qkmB7): materialize_view_tool ***\nArguments:\n{\u201cview_definitions\u201d:[\u201cCREATE VIEW users_interacted_with_email_push_campaigns\nAS SELECT USER_ID FROM USERS_MESSAGES_EMAIL_SEND_VIEW WHERE USER_ID IN\n(SELECT USER_ID FROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW)\u201c,\nCREATE VIEW email_engagement_metrics AS SELECT USER_ID, OPEN_RATE\nAS email_open_rate, CLICK_THROUGH_RATE AS email_click_through_rate\nFROM USERS_MESSAGES_EMAIL_SEND_VIEW\u201d,\n\u201cCREATE VIEW push_notification_engagement_metrics\nAS SELECT USER_ID, OPEN_RATE AS push_notification_open_rate,\nCLICK_THROUGH_RATE AS push_notification_click_through_rate\nFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW;\u201d]}\nVerifier (to chat_manager):\n***** Response from calling tool (call_4dz4c1irNRJiOdrijI2qkmB7) *****\n[\u201cView successfully defined.\u201d,\n\u201cView successfully defined.\u201d,\n\u201cView successfully defined.\u201d]"}]}