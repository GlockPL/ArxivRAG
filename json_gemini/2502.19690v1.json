{"title": "Risk-aware Integrated Task and Motion Planning for Versatile Snake Robots under Localization Failures", "authors": ["Ashkan Jasour", "Guglielmo Daddi", "Masafumi Endo", "Tiago S. Vaquero", "Michael Paton", "Marlin P. Strub", "Sabrina Corpino", "Michel Ingham", "Masahiro Ono", "Rohan Thakker"], "abstract": "Snake robots enable mobility through extreme terrains and confined environments in terrestrial and space applications. However, robust perception and localization for snake robots remain an open challenge due to the proximity of the sensor payload to the ground coupled with a limited field of view. To address this issue, we propose Blind-motion with Intermittently Scheduled Scans (BLISS) which combines proprioception-only mobility with intermittent scans to be resilient against both localization failures and collision risks. BLISS is formulated as an integrated task and motion planning (TAMP) problem that leads to a chance-constrained hybrid partially observable Markov decision process (CC-HPOMDP), known to be computationally intractable due to the curse of history. Our novelty lies in reformulating CC-HPOMDP as a tractable, convex mixed integer linear program. This allows us to solve BLISS-TAMP significantly faster and jointly derive optimal task-motion plans. Simulations and hardware experiments on the EELS snake robot show our method achieves over an order of magnitude computational improvement compared to state-of-the-art POMDP planners and > 50% better navigation time optimality versus classical two-stage planners.", "sections": [{"title": "I. INTRODUCTION", "content": "Snake robots have versatile mobility for exploring extreme environments due to their reconfigurable body structure. These robots are versatile for both terrestrial and space missions, from search and rescue in confined spaces to exploring ice worlds like Enceladus or Europa, navigating diverse terrains from vast surfaces to deep crevasses. However, snake robots struggle with the proximity of their sensor payload to the ground, which increases the complexity of simultaneous localization and mapping. In featureless or visually challenging environments (e.g., with dust, fog, or snow), this low sensor position limits visible features and accelerates their motion in image space, raising the risk of localization failures. A restricted view from low-mounted LiDAR also increases the risk of front-end failures in algorithms such as iterative closest point [1]. The rapid motion of features in the robot's view further induces sensor data uncertainty and distortion. Maintaining an upright scan posture, with the robot's front raised, offers a solution, but also consumes energy and limits locomotion capability (Fig. 1a). To ensure safe and efficient mobility under uncertainty, snake robots require simultaneous decisions for where to move and when to scan to reveal unexplored regions.\nTo this end, we propose Blind-motion with Intermittently Scheduled Scans (BLISS) to achieve resiliency to localization failures by avoiding exteroceptive feedback during motion while leveraging periodic scanning behaviors for localization updates. As illustrated in Fig. 1b, BLISS involves solving an integrated task and motion planning (TAMP) problem to balance the tradeoff between longer paths with higher clearance from obstacles but less frequent scans, and shorter paths with lower clearance but more frequent scans. The challenge is that BLISS-TAMP inherently leads to computationally intractable decision-making, formulated"}, {"title": "II. RELATED WORK", "content": "Traditionally, TAMP has been addressed without considering uncertainty, with decoupled task and motion planning problems, i.e., solved as distinct sub-problems to combine, usually tasks first then motions. Examples of this approach are found in the robotic navigation and object manipulation with single and multiple robots [3]\u2013[9], and in robotic exploration [10]. Existing work has also explored interleaving or simultaneously addressing task and motion planning without uncertainty [11]\u2013[16]. For instance, [17] combines heuristic-based task planner with geometric reasoners for manipulation planning in table-top object manipulation problems for bi-manual robots. In this line of work, motion planning serves as a central part of the action selection process in task planning, e.g., for computing task feasibility at a particular state.\nOne of the central themes in our work is addressing uncertainty in TAMP. Here, an agent plans using incomplete information or probabilistic models of the environment. Most existing work on this front interleaves task and motion planning, where the uncertainty is incorporated in task planning with discrete actions and states. However, even with discrete spaces, the problem quickly becomes intractable as the search tree branches in both actions and observations. In [18], [19], conditional or contingent task planning is the core process with geometric evaluation used as low-level feasibility checks for task selection. [20] uses the same principle but employs a probabilistic task planning approach.\nWe address TAMP under uncertainty in the form of chance-constrained TAMP (CC-TAMP), where the system considers constraints on the probability of failure to execute a control plan. Directly related work includes [21], [22], which solves a CC-HPOMDP formulation for autonomous vehicles and Mars rovers in a hierarchical fashion. Also, [23], [24] study adaptive sampling in robotic ocean exploration to track a science phenomenon modeled as a Gaussian process. We address the CC-TAMP under uncertainty by simultaneously addressing task and motion planning, rather than decoupling them. Our formulations consider continuous state spaces and"}, {"title": "III. PROBLEM FORMULATION", "content": "Robust perception and localization for snake robots remain an open problem. The use of snake robot reconfigurability for scanning behaviors was first explored in [34], where the authors focused on hardware and gait design with limited onboard autonomy. We leverage the EELS robot's scanning capability for long-range localization and obstacle detection, combined with blind proprioception-only mobility for navigation, to be resilient against localization failures when exteroceptive sensors are near the ground.\nWe propose a long-range, risk-aware task and motion planner for the BLISS in extreme terrains. This planner views the robot at an abstract level to approximate it as a point mass with linear dynamics. It creates a low-resolution 2.5-D motion path with scheduled scans that meet a predefined risk tolerance \u2206. A short-range planner and controllers execute the remaining process by accounting for the robot's high degrees of freedom (DoF) and non-linear dynamics [2]."}, {"title": "B. CC-HPOMDP for BLISS-TAMP under Uncertainty", "content": "BLISS-TAMP can be interpreted as an agent reaching a goal through actions and observations subject to safety constraints. Due to sensor noise and imperfect models, both state and observations are expected to be random variables. The agent's action space is both discrete (move vs scan) and continuous (where to move). This problem structure aligns with CC-TAMP and can be cast as a CC-HPOMDP due to these uncertainties. We represent uncertain state as a continuous random variable \\(X : \\mathbb{R}^{N_x} \\rightarrow \\mathbb{R}\\), continuous control input as \\(u \\in \\mathbb{R}^{N_u}\\), and discrete actions as \\(a \\in A = \\{1, 2, ..., N_a\\}\\). Action and time dependence are expressed as \\(a_{v_{i,k}}\\) where the i denotes the component of multi-dimensional variable v, k the time step, and a the associated action. This problem can be formulated as:\n\nCC \u2013 HPOMDP = (S, A, T, \u03a9, R, \u03b3, Z, C, \u2206c).   (1)\n\nSis the state space, A the action space, T = P(Sk+1|Sk, ak, Uk) the transition function, \u03a9 the observation space, Z = p(oOk+1|Sk+1,ak, Uk) the observation function, R the reward function, y the discount factor, C set of state constraints, \u0394\u2282 [0,1] risk bound [37]. CC-HPOMDP planning occurs in belief space - probability distribution over states, and requires tracking of probability distributions of probability distributions, i.e., hyperbeliefs (Fig. 3)."}, {"title": "C. Mathematical Optimization Program for CC-HPOMDP", "content": "We cast CC-HPOMDP as a mathematical optimization program with cost minimization objective over N time steps:\n\n\nmin\\\\\n_{\\mathbf{X}_{0:N}, \\mathbf{u}_{0:N}, \\mathbf{z}_{0:N-1}}\n & \\sum_{k=0}^{N-1} c_k X_k,  (2a)\\\\\nX_{k+1} &= a_k A X_k + a_k B u_k + a_k w_k + a_k C, (2b)\\\\\nX_o &= B_o(x), \\, \\mathbb{E}[X_N] = X_{goal}, \\, Tr(V[X_N]) \\leq \\epsilon, (2c)\\\\\nPr(X_k \\in X_{obs}) &< \\Delta_c.  (2d)\n\n\n(2a) denotes the cost function with the given cost coefficient vector ck. (2b) represents the system transition dynamics where ak A, ak B and akC, akwk are the state transition matrix, control input matrix, bias of the system, and process noise of the system, respectively, under discrete action a at time k. (2c) defines the initial and terminal conditions: Bo(x) is the initial belief, xgoal the goal state, and Tr(V[XN]) the trace of the state's covariance that models the state uncertainty size at the planning horizon's end where \u20ac denotes the maximum allowable uncertainty. (2d) represents the probabilistic safety constraints relative to obstacle sets Xobs with Ac as the given acceptable risk tolerance.\nRemark 1: In the presence of multiple obstacles, one can apply separate chance constraints, as specified in (2d), for each obstacle with different risk levels. To meet the total risk level of Ac, one can allocate the risk uniformly, assigning"}, {"title": "D. Belief MDP Formulation for BLISS-TAMP", "content": "BLISS-TAMP owns two discrete actions: Move and Scan, denoted by prescripts M and S, respectively. Move changes the agent's state using proprioception and without observations, while Scan re-localizes the agent in the map. The state vector X comprises the agent's Cartesian coordinates x and y. The control input u = [vx, vy]T_is the velocity in x, y dimensions. We cast the BLISS-TAMP's CC-HPOMDP formulation into belief space, i.e., belief MDP, assuming the agent's state uncertainty is normally distributed \u03a7 ~ \u039d(\u03bc\u03c7, \u03a3\u03c7), and describing state transition dynamics as a function of this belief state. If observations remained random variables, the planning problem would be in hyperbelief space, which is typically intractable [39]. Thus, we assume the agent's post-scan state is its pre-scan belief maximum likelihood estimate. Specifically, after scanning, the agent's true position is assumed to match the expected value of its pre-scan state probability distribution. While this simplification breaks plan optimality and safety guarantees [40], [41], good results can be achieved by combining it with model predictive control, which involves re-planning after each observation during execution. We assume an"}, {"title": "IV. APPROACH: CONVEX MILP FOR BLISS-TAMP", "content": "We describe how the BLISS-TAMP's belief MDP formulation can be cast as a tractable MILP. Building on the formulation introduced in Section III-D, we propose an objective function that jointly penalizes scanning and path length. To minimize the time spent outside of the goal, we introduce binary variables z \u2208 {0,1} that act as a goal indicator function. These variables are zero when the agent is in the goal set, and 1 otherwise. The goal set is defined as the set of agent belief states where the state mean is within a threshold \u20ac \u2208 R from the goal point (x, y), and the trace of state covariance is below \u20ac. Additional constraints on the binary variables complete the problem formulation:\n\nmin_{\\mathbf{y}_{k}, \\mathbf{z}_{k}} & \\sum_{i=0}^{N} (S c_{Sk} y_k + M c_{Mk} z), (15a)\\\\\nz \\in \\{0,1\\},  (15b)\\\\\na_{x^{og}} + a_{y^{og}} - \\epsilon_{og} < M^z_8 z, (15c)\\\\\n\\epsilon_{og} - a_{x^{og}} - a_{y^{og}} < M^z_8 (1-z), (15d)\\\\\nx_{k} - x_{goal} \\leq a_{x^{og}} \\leq -x_k + x_{goal}, (15e)\\\\\ny_{k} - y_{goal} \\leq a_{y^{og}} \\leq -y_k + y_{goal}. (15f)\n\n\nHere, a \u2208 R+ and a \u2208 R+ are additional variables introduced to linearize |x - Xgoal and yygoal. Additional constraints are required to prevent corner-cutting [42], as MILP formulations lack collision checking between states.\n\n\u03a3 \u2013 M \u2264 \u03a3 \u2264 \u03a3 + M, (16a)\n\n\u03a3 \u2013 M \u2264 \u03a3 \u2264 \u03a3 + 2M, (16b)\n\nz \u2208 {0,1}, z + z = 1. (16c)\n\n\n\nRemark 4: We showed that BLISS can be formulated as a convex MILP by: 1) introduction of slack variables, e.g., rk, and 2) treating time (since the last scan) t as a separate system state and describing the state covariance propagation in terms of time t. Otherwise, the MILP formulation of BLISS problem will result in a nonconvex optimization due to bi-linear terms, e.g., the product of decision variables.\nIn summary, the convex MILP formulation for BLISS-TAMP optimizes over all variables to solve (15) subject to mean state transition dynamics (12) with matrices (3c, 3d, 3f); slack variable constraints (11a) and (11b) for state variables multiplied by selector variables; covariance propagation (16); and polygonal obstacle chance constraints (14b)."}, {"title": "V. EXPERIMENTS", "content": "This section evaluates our MILP planner through simulations and hardware tests on the EELS snake robot [2]."}, {"title": "A. Metrics of Interest", "content": "We evaluate planners on navigation efficiency and computation efficiency. Success Rate (SR) [%] indicates the percentage of successful executions to reach the goal position. Execution Time (ET) [s] measures navigation efficiency as the total time from start to goal positions. The required times for Move and Scan actions are set as 0.5 s and 100 s respectively. Computation Time (CT) [s] evaluates computation efficiency by total time spent for planning. ET and CT are calculated for successful executions."}, {"title": "B. Experimental Setups", "content": "Our approach is compared with two baseline planners: Two-stage Planner: This approach follows the classic decoupling of path planning and task scheduling, which are handled separately. A* search plans paths on a 2D gridmap with inflated obstacles and scan scheduling follows path planning. Uncertainty is pre-computed at each step; scans are scheduled only when risk constraints are violated. The planner repeats path planning and scheduling after each scan.\nPOMDP Planner: This approach solves the CC-HPOMDP problem using MCTS-DPW [43], a state-of-the-art POMDP solver. This formulation requires action space discretization, so the control input is discretized into 8 equal components with continuous state space. Yet, this baseline exhibits overly myopic behaviors, failing to reach goals due to the POMDP's limited planning horizon. To ensure a fair comparison, we extend it using [44] that enables long-horizon planning through belief space roadmaps from goal to start.\nWe evaluate planners using a simulator that generates robot behavior following the dynamics described in Section IV. The two-stage and POMDP planners are implemented in Julia, using the Julia POMDP library [45]. The MILP planner is implemented in C++ using Google's or-tools [46] and Gurobi [47]. We integrate these multi-language configurations using ROS that connect planning and execution components through a client-service architecture. Note that all planners run on the same machine (Intel Core i7-1165G7 CPU, Ubuntu) to ensure a fair comparison of CT.\nWe prepared four obstacle scenarios: Standard (Std), Entrapped (Ent), Narrow (Nar), and Random (Rnd), where Std, Ent, and Rnd are illustrated in Fig. 4a, b, and c, respectively. Std-map assesses basic collision avoidance in open spaces. Ent-map tests planners against local minima entrapment due to finite horizon planning. Nar-map examines the tradeoff between longer paths with fewer scans and shorter paths requiring more scans. Rnd-map with six quadrilaterals tests general performance in obstacle-rich scenarios. In all scenarios, planners search from (0 m, 0 m) to (10 m, 10 m)."}, {"title": "C. Results", "content": "Quantitative Comparison: 25 Monte Carlo simulations were run with Ac = 0.1 and Table II summarizes the mission planning performance across the three obstacle scenarios. Our approach achieves the best performance in navigation efficiency, as shown by the lowest ET. This results from optimizing discrete actions for efficient navigation while minimizing costly scans and accounting for collision risks due to localization errors in a probabilistic manner. The two-stage planner shows the lowest CT; however, its solution quality is worse than ours for navigation efficiency. The POMDP planner struggles with TAMP under uncertainty, shown by poor planning outcomes and the highest CT. This result indicates the exact solution of CC-HPOMDP"}, {"title": "VI. CONCLUSION", "content": "We have introduced BLISS-TAMP, a resilient navigation strategy that alternates proprioceptive-only movement with exteroceptive scans for snake robots to achieve robustness against localization failures. We formulate a novel chance-constrained convex MILP to approximate solutions for a partially observable TAMP problem, balancing movement and scanning to increase state knowledge while considering execution time. Simulation studies validated that the proposed algorithm outperformed existing planners in terms of planning efficiency while reducing computational complexity. Hardware experiments on EELS demonstrated real-world effectiveness, though quantitative evaluations are needed for field deployment. Future work will focus on implementing continuous-time MILP to reduce computational complexity."}, {"title": "VII. SUPPLEMENTAL MATERIAL", "content": "This supplement provides simulation visualizations and details how risk tolerance affects planning behaviors."}, {"title": "A. Qualitative Comparison against Comparable Planners", "content": "Fig. 8 presents the remaining results of Monte Carlo simulations with Ac = 0.1 for Ent- and Nar-maps, comparing the MILP planner with two other planners in Section V-C. The MILP planner maintains obstacle clearance for safe blind locomotion while scheduling scans to prevent excessive localization uncertainty growth (Fig. 8c,f). This strategy balances safety from collisions and efficiency in execution time, accomplished by simultaneously addressing task planning for scanning and motion planning for navigation. A decoupled solution cannot attain this balance, as it prioritizes preprocessed decision-making. This can be observed in the two-stage planner, which often fails to avoid collisions despite planning frequent scans (Fig. 8a,d).\nIt is also important that our MILP planner achieves significantly higher computational efficiency and more consistent TAMP compared to the POMDP planner. This advantage stems from our use of convex deterministic optimization, which eliminates the need for uncertainty samples through the belief space assumption and simplifies the problem formulation. Otherwise, BLISS-TAMP requires exact solutions to CC-HPOMDP and handles uncertainty through sampling, which causes computationally demanding and inconsistent planning outcomes (Fig. 8b,e)."}, {"title": "B. Qualitative Analysis of Risk Tolerance Effects on MILP", "content": "Fig. 9 shows Monte Carlo simulation results for our MILP planner with \u2206 = {0.01,...,0.4} in one of ten Rnd-maps used for parameter study. The given trajectories and associated scans indicate that our integration of chance constraints into MILP functions as improving safety. Lower Ac provides higher obstacle clearance and more frequent scans to reduce uncertainty growth, which are important to avoid collisions under uncertainty. As we increase Ac, the MILP planner allows more aggressive maneuvering, such as passing through narrow passages (Fig. 8d,e). As expressed in reduced ET, higher Ac contributes to more distance-efficient mission execution but also requires taking risks in uncertain scenarios. Our method offers the ability to adjust planning behavior through simple parameter tuning. This controllability is beneficial as the balance between safety and efficiency changes throughout a mission's timeline. For example, during the initial exploration phase when most terrain is unknown, it may be desirable to prioritize safety for long-term mission resilience."}]}