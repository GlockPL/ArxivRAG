{"title": "Unlocking the Potential of Generative AI through\nNeuro-Symbolic Architectures - Benefits and Limitations", "authors": ["Qualid Bougzime", "Samir Jabbar", "Christophe Cruz", "Fr\u00e9d\u00e9ric Demoly"], "abstract": "Neuro-symbolic artificial intelligence (NSAI) represents a transformative approach in artificial\nintelligence (AI) by combining deep learning's ability to handle large-scale and unstructured\ndata with the structured reasoning of symbolic methods. By leveraging their complemen-\ntary strengths, NSAI enhances generalization, reasoning, and scalability while addressing\nkey challenges such as transparency and data efficiency. This paper systematically studies\ndiverse NSAI architectures, highlighting their unique approaches to integrating neural and\nsymbolic components. It examines the alignment of contemporary AI techniques such as\nretrieval-augmented generation, graph neural networks, reinforcement learning, and multi-\nagent systems with NSAI paradigms. This study then evaluates these architectures against\ncomprehensive set of criteria, including generalization, reasoning capabilities, transferability,\nand interpretability, therefore providing a comparative analysis of their respective strengths\nand limitations. Notably, the Neuro \u2192 Symbolic \u2190 Neuro model consistently outperforms\nits counterparts across all evaluation metrics. This result aligns with state-of-the-art re-\nsearch that highlight the efficacy of such architectures in harnessing advanced technologies", "sections": [{"title": "1 Introduction", "content": "Neuro-symbolic artificial intelligence (NSAI) is fundamentally defined as the combination\nof deep learning and symbolic reasoning [1]. This hybrid approach aims to overcome the\nlimitations of both symbolic and neural artificial intelligence (AI) systems while harnessing\ntheir respective strengths. Symbolic AI excels in reasoning and interpretability, whereas\nneural AI thrives in learning from vast amounts of data. By merging these paradigms, NSAI\naspires to embody two fundamental aspects of intelligent cognitive behavior: the ability to\nlearn from experience and the capacity to reason based on acquired knowledge [1, 2].\n\nThe importance of NSAI has been increasingly recognized in recent years, especially after\nthe 2019 Montreal AI Debate between Gary Marcus and Yoshua Bengio. This debate high-\nlighted two contrasting perspectives on the future of AI: Marcus argued that \"expecting a\nmonolithic architecture to handle abstraction and reasoning is unrealistic,\u201d emphasizing the\nlimitations of current AI systems, while Bengio maintained that \u201csequential reasoning can be\nperformed while staying in a deep learning framework\" [3]. This discussion brought attention\nto the strengths and weaknesses of neural and symbolic approaches, catalyzing a surge of\ninterest in hybrid solutions. Bengio's subsequent remarks at IJCAI 2021 underscored the\nimportance of addressing out-of-distribution (OOD) generalization, stating that \u201cwe need a\nnew learning theory\" to tackle this critical challenge [4]. This aligns with the broader con-\nsensus within the AI community that combining neural and symbolic paradigms is essential\nto developing more robust and adaptable systems. Drawing on concepts like Daniel Kahne-"}, {"title": null, "content": "man's dual-process theory of reasoning, which compares fast, intuitive thinking (System 1) to\ndeliberate, logical thought (System 2), NSAI seeks to bridge the gap between learning from\ndata and reasoning with structured knowledge [5]. Despite ongoing debates about the optimal\narchitecture for integrating these two paradigms, the 2019 Montreal AI Debate has played a\npivotal role in shaping the trajectory of research in this promising field [6, 7, 8, 9, 10, 11].\n\nNSAI offers a promising avenue for addressing limitations of purely symbolic or neural sys-\ntems. For instance, while neural networks (NNs) often struggle with interpretability, symbolic\nAI systems are rigid and require extensive domain knowledge. By combining the adaptability\nof neural models with the explicit reasoning capabilities of symbolic methods, NSAI systems\naim to provide enhanced generalization, interpretability, and robustness. These characteristics\nmake NSAI particularly well-suited for solving complex, real-world problems where adapt-\nability and transparency are critical [12]. Several NSAI architectures have been proposed to\nintegrate these paradigms effectively. Examples include Symbolic Neuro Symbolic systems,\nSymbolic [Neuro], Neuro[Symbolic], Neuro\nSymbolic coroutines, Neurosymbolic, and others\n[13]. Each architecture offers unique advantages but also poses specific challenges in terms of\nscalability, interpretability, and adaptability. A systematic evaluation of these architectures\nis imperative to understand their potential and limitations, guiding future research in this\nrapidly evolving field.\n\nGenerative AI has witnessed remarkable advancements, encompassing a diverse range\nof technologies that address various challenges in data processing, reasoning, and decision-\nmaking. These advancements can be categorized into several major branches of AI. Natural\nlanguage processing (NLP) [14] includes technologies such as retrieval-augmented generation\n(RAG) [15], sequence-to-sequence models [16], semantic parsing [17], named entity recogni-\ntion (NER) [18], and relation extraction [19], which focus on understanding and generating\nhuman language. Reinforcement learning techniques, like reinforcement learning with human\nfeedback (RLHF) [20], enable systems to learn optimal actions through interaction with their"}, {"title": null, "content": "environment. Advanced NNs include innovations such as graph neural networks (GNNs) [21]\nand generative adversarial networks (GANs) [22], which excel in handling structured data and\ngenerating realistic data samples, respectively. Multi-agent systems [23, 24] explore the co-\nordination and decision-making among multiple intelligent agents. Recent advances leverage\nmixture of experts (MoE) architectures to enhance scalability and specialization in collabora-\ntive frameworks. In MoE-based multi-agent systems, each expert operates as an autonomous\nagent, specializing in distinct sub-tasks or data domains, while a dynamic gating mechanism\norchestrates their contributions [25, 26]. Transfer Learning [27], including pre-training [28],\nfine-tuning [29], and few-shot learning [30], allows AI models to adapt knowledge from one\ntask to another efficiently. Explainable AI (\u03a7\u0391\u0399) [31] focuses on making AI systems transpar-\nent and interpretable, while efficient learning techniques, such as model distillation [32], aim\nto optimize resource usage. Reasoning and inference methods like chain-of-thought (CoT)\n[33] reasoning and link prediction enhance logical decision-making capabilities. Lastly, con-\ntinuous learning [34] paradigms ensure adaptability over time. Together, these technologies\nform a comprehensive toolkit for tackling the increasingly complex demands of generative AI\napplications.\n\nThe classification of generative AI technologies within the NSAI framework is crucial for\nseveral reasons. Firstly, it provides a structured approach to understanding how these di-\nverse technologies relate to and enhance NSAI capabilities. By mapping these techniques\nto specific NSAI architectures, researchers and practitioners can better grasp their potential\napplications and limitations. This classification also facilitates the identification of syner-\ngies between different AI approaches, potentially leading to more robust and versatile hybrid\nsystems. Furthermore, it aids in decision-making processes when selecting appropriate tech-\nnologies for specific tasks, considering factors like interpretability, reasoning capabilities, and\ngeneralization. As AI continues to evolve, this systematic categorization becomes increasingly\nvaluable for bridging the gap between cutting-edge research and practical implementation,"}, {"title": null, "content": "ultimately driving the field towards more integrated and powerful AI solutions.\n\nTherefore, this research aims to explores the alignment of generative AI technologies with\nthe core catergories of NASAI and examines the insights this classification provides regarding\ntheir strenghts and limitations. The proposed methodology is threefold: (i) to define and\nanalyze existing NSAI architectures, (ii) to classify generative AI technologies within the\nNSAI framework to provide a unified perspective on their integration, and (iii) to develop a\nsystematic framework for assessing NSAI architectures across various criteria."}, {"title": "2 Neuro-Symbolic AI: Combining Learning and Reasoning to Overcome AI's Limitations", "content": "NNs have been exemplary in handling unstructured forms of data, e.g., images, sounds,\nand textual data. The capacity of these networks to acquire sophisticated patterns and\nrepresentations from voluminous datasets has provided major breakthroughs in a series of\ndisciplines, from computer vision, speech recognition, to NLP [35, 14]. One of the major\nbenefits of NNs is that they learn and become better from raw data without requiring pre-\ncoded rules or expert knowledge. This makes them highly scalable and efficient to utilize\nin applications with large raw data. However, despite these benefits, NNs also have some\nvery well-documented disadvantages. One of the major ones of these might be that they are\nnot transparent. Indeed, neural models pose interpretability challenges, making it difficult to\nunderstand the process by which they arrive at specific decisions or predictions. Such opacity\ncauses problems for critical applications where explanation is necessary, such as in healthcare,\nfinance, legal frameworks, and engineering. Additionally, NNs have a high requirement for\ndata, requiring substantial amounts of labeled training data in order to operate effectively.\nThis reliance on large data makes them ineffective when applied to data-scarce or data-costly\nenvironments. Neural models also struggle with reasoning and generalizing beyond their"}, {"title": null, "content": "training data, which makes their performance less impressive when it comes to tasks in logical\ninference or commonsense reasoning. Specifically, tasks including understanding causality,\nsequential problem-solving, and decision-making relying on outside world knowledge.\n\nSymbolic AI is better at handling areas that are weaker for NNs. Symbolic systems\nfunction on explicit rules and structured representations, which enables them to achieve\nreasoning tasks related to complicated issues, such as mathematical proofs, planning, and\nexpert systems. Symbolic AI is most important because it is transparent. Since symbolic\nmethods are grounded in known rules and logical formalisms, decision-making processes are\neasy to interpret and explain. However, symbolic AI systems have some drawbacks. One\nof the biggest ones is that they are rigid and difficult to respond to new circumstances.\nThey require rules to be manually defined and require structured input data, leading them\ndifficult to apply to real-world situations where data might contain noise, incompleteness,\nor unstructured form. They are also susceptible to combinatorial explosions in handling big\ndata or hard reasoning problems, which significantly slows down their performance at scale.\nSymbolic systems are also not well suited for perception tasks like image or speech recognition\nsince they are unable to draw knowledge from raw data alone.\n\nWhile traditional NNs are strong at recognizing patterns in collections of data but falter\nwhen presented with new situations, symbolic reasoning provides a rational foundation for\ndecision-making but is limited in the manner in which it can learn knowledge from new\ninformation and adapt in a dynamic process. The combination of these two approaches in\nNSAI effectively minimizes these limitations, producing a more flexible, explainable, and\neffective AI system. Another distinguishing feature of NSAI is that it is able to generalize\noutside its training set. Traditional AI systems are prone to fail in novel situations; however,\nNSAI, because of its combination of learning and logical reasoning, works better in such\ncases. Such a feature is critical for real-world applications such as autonomous transport\nand medicine, where systems need to perform well in uncontrolled environments. Apart from"}, {"title": null, "content": "that, in an interdisciplinary engineering context such as 4D printing, which brings together\nmaterials science, additive manufacturing, and engineering, NSAI holds significant promise\nfor improving both the interpretability and reliability of design decisions on the actuation and\nmechanical performance, and printability. Although these advantages seem promising, they\nremain hypotheses requiring more extensive validation and industrial-scale testing. Ongoing\nresearch must demonstrate, through empirical studies and real-world implementations, how\nNSAI can reliably accelerate the discovery of smart materials and structures [36]. The second\nkey benefit point of NSAI is that it has a reduced need for big data sets. Traditional AI\nsystems usually require a tremendous amount of data to operate, which might be very time-\nand resource-consuming. NSAI, however, is able to do better with a much smaller set of data\nrequired, due to its symbolic reasoning ability. This makes it a more sustainable and viable\noption, especially for small organizations or new research areas with limited resources. Along\nwith the aforementioned data efficiency, NSAI models also have the exceptional transferability,\ni.e., their capacity for using knowledge learned from one task and applying it in another with\nless need for retraining. Such a property is highly desirable in situations where there is little\ndata related to a new task."}, {"title": "3 Neuro-Symbolic AI Architectures", "content": "This section provides an overview of various NSAI architectures, offering insights into their\ndesign principles, integration strategies, and unique capabilities. While Kautz's classification\n[13] serves as a foundational framework, we extend it by incorporating additional architectural\nperspectives to capture the evolving landscape of NSAI systems. These approaches range from\nsymbolic systems augmented by neural modules for specialized tasks to deeply integrated\nmodels where explicit reasoning engines operate within neural frameworks. This expanded\ncategorization highlights the diversity of design strategies and the broad applicability of NSAI\ntechniques, emphasizing their potential for more interpretable, robust, and data-efficient AI"}, {"title": "3.1 Sequential", "content": "As part of the sequential NSAI, the Symbolic \u2192 Neuro \u2192 Symbolic architecture involves\nsystems where both the input and output are symbolic, with a NN acting as a mediator for\nprocessing (Figure 1a). Symbolic input, such as logical expressions or structured data, is first\nmapped into a continuous vector space through an encoding process. The NN operates on\nthis encoded representation, enabling it to learn complex transformations or patterns that\nare difficult to model symbolically. Once the processing is complete, the resulting vector is\ndecoded back into symbolic form, ensuring that the final output aligns with the structure\nand semantics of the input domain. This framework is especially useful for tasks that require\nleveraging the generalization capabilities of NNs while preserving symbolic interpretability\n[37, 38]. A formulation of this architecture is presented below:\n\n$y = f_{neural}(x)$  (1)\n\nwhere x is the symbolic input, $f_{neural}(x)$ represents the NN that processes the input, and y is\nthe symbolic output.\n\nThis architecture can be used in a semantic parsing task, where the input is a sequence\nof symbolic tokens (e.g., words). Here, each token is mapped to a continuous embedding via"}, {"title": "3.2 Nested", "content": "The nested NSAI category is composed of two different architectures. The first Sym-\nbolic[Neuro] \u2013 places a NN as a subcomponent within a predominantly symbolic system (Fig-\nure 2a). Here, the NN is used to perform tasks that require statistical pattern recognition,\nsuch as extracting features from raw data or making probabilistic inferences, which are then\nutilized by the symbolic system. The symbolic framework orchestrates the overall reasoning\nprocess, incorporating the neural outputs as intermediate results [41]. This architecture can\nformally defined as follows:\n\n$y = g_{symbolic}(x, f_{neural}(z))$ (2)\n\nwhere x represents the symbolic context, z is the input passed from the symbolic reasoner to\nthe NN, $f_{neural}(z)$ expresses the neural model processing the input, and $g_{symbolic}$ the symbolic\nreasoning engine that integrates neural outputs. A well-known instance of this architecture\nis AlphaGo [41], where a symbolic Monte-Carlo tree search orchestrates high-level decision-\nmaking, while a NN evaluates board states, providing a data-driven heuristic to guide the\nsymbolic search process [42] (Figure 2b). Similarly, in a medical diagnosis scenario, a rule-\nbased engine oversees the core diagnostic process by applying expert guidelines to patient\nhistory, symptoms, and lab results. At the same time, a NN interprets unstructured radio-\nlogical images, delivering key indicators such as tumor likelihood. The symbolic system then\nintegrates these indicators into its final decision, combining transparent and rule-driven logic\nwith robust pattern recognition.\n\nThe second architecture \u2013 Neuro[Symbolic] \u2013 integrates a symbolic reasoning engine as"}, {"title": null, "content": "a component within a neural system, allowing the network to incorporate explicit symbolic\nrules or relationships during its operation (Figure 2c). The symbolic engine provides struc-\ntured reasoning capabilities, such as rule-based inference or logic, which complement the NN's\nability to generalize from data. By embedding symbolic reasoning within the neural frame-\nwork, the system gains interpretability and structured decision-making while retaining the\nflexibility and scalability of neural computation. This integration is particularly effective for\ntasks that require reasoning under constraints or adherence to predefined logical frameworks\n[43, 44]. This configuration can be described as follows:\n\n$y = f_{neural}(x, g_{symbolic}(z))$  (3)\n\nwhere x represents the input data to the neural system, z is the input passed from the NN\nto the symbolic reasoner, $g_{symbolic}$ is the symbolic reasoning function, and $f_{neural}$ denotes the\nNN processing the combined inputs.\n\nThis architecture is currently applied in automated warehouse, where a robot navigates\ndynamically changing aisles. During normal operation, it relies on a neural policy to select\nroutes based on learned patterns. When it encounters an unexpected obstacle, it offloads route\ncomputation to a symbolic solver (e.g., a pathfinding or constraint-satisfaction algorithm),\nwhich returns an alternative path. The solver's output is then integrated back into the neural\npolicy, and the robot resumes its usual pattern-based navigation. Over time, the robot also\nlearns to identify which challenges call for the symbolic solver, effectively blending fast pattern\nrecognition with precise combinatorial planning.\n\nFigure 2d illustrates this framework, a symbolic reasoning engine processes structured data,\nsuch as a maze, to generate a solution path. A NN encodes the problem into a latent\nrepresentation and decodes it into a symbolic sequence of actions (e.g., forward, turn left,\nturn right)."}, {"title": "3.3 Cooperative", "content": "As a cooperative framework, Neuro | Symbolic uses neural and symbolic components as in-\nterconnected coroutines, collaborating iteratively to solve a task (Figure 3a). NNs process\nunstructured data, such as images or text, and convert it into symbolic representations that\nare easier to reason about. The symbolic reasoning component then evaluates and refines\nthese representations, providing structured feedback to guide the NN's updates. This feed-\nback loop continues over multiple iterations until the system converges on a solution that\nmeets predefined symbolic constraints or criteria. By combining the strengths of NNs for\ngeneralization and symbolic reasoning for interpretability, this approach achieves robust and\nadaptive problem-solving [45]. This architecture can be described as follows:\n\n$z^{(t+1)} = f_{neural}(x, y^{(t)}), y^{(t+1)} = g_{symbolic} (z^{(t+1)}), \u2200t \u2208 {0,1,...,n}$ (4)\n\nwhere x represents non-symbolic data input, $z^{(t)}$ is the intermediate symbolic representation\nat iteration t, $y^{(t)}$ is the symbolic reasoning output at iteration t, $f_{neural}(x, y^{(t)})$ expresses the"}, {"title": null, "content": "NN that processes the input x and feedback from the symbolic output $y^{(t)}$, $g_{symbolic} (z^{(t+1)})$ is\nthe symbolic reasoning engine that updates $y^{(t+1)}$ based on the neural output $z^{(t+1)}$, and n is\nthe maximum number of iterations or a convergence threshold. The hybrid reasoning halts\nwhen the outputs $y^{(t)}$ converge (e.g., $|y^{(t+1)} \u2013 y^{(t)}| < \u0454$)), where e is a small threshold denoting\nminimal change between successive outputs, or when the maximum iterations n is reached.\n\nFor instance, this architecture can applied in autonomous driving systems, where a NN\nprocesses real-time images from vehicle cameras to detect and classify traffic signs. It identifies\nshapes, colors, and patterns to suggest potential signs, such as speed limits or stop signs. A\nsymbolic reasoning engine then evaluates these detections based on contextual rules\u2014like\nverifying if a detected speed limit sign matches the road type or if a stop sign appears in\na logical position (e.g., near intersections). If inconsistencies are detected, such as a stop\nsign identified in the middle of a highway, the symbolic system flags the issue and prompts\nthe neural network to re-evaluate the scene. This iterative feedback loop continues until the\nsystem reaches consistent, high-confidence decisions, ensuring robust and reliable traffic sign\nrecognition, even in challenging conditions like poor lighting or partial occlusions (Figure 3b)."}, {"title": "3.4 Compiled", "content": "As part of the compiled NSAI, Neurosymbolic Loss uses symbolic reasoning into the loss function\nof a NN (Figure 4a). The loss function is typically used to measure the discrepancy between\nthe model's predictions and the true outputs. By incorporating symbolic rules or constraints,\nthe network's training process not only minimizes prediction error but also ensures that the\noutput aligns with symbolic logic or predefined relational structures. This allows the model"}, {"title": null, "content": "to learn not just from data but also from symbolic reasoning, helping to guide its learning\nprocess toward solutions that are both accurate and consistent with symbolic principles.\n\n$L = L_{task}(y, Y_{target}) + \u5165 \u30fbL_{symbolic} (y)$  (5)\n\nwhere y is the model prediction, $Y_{target}$ represents the ground truth labels, $L_{task}$ is the task-\nspecific loss (e.g., cross-entropy), $L_{symbolic}$ is the penalization for violating symbolic rules,\nA the Weight balancing the two loss components, and L the final loss, combining both the\ntask-specific loss and the symbolic constraint penalty to guide model optimization. This ar-\nchitecture is typically useful in the field of 4D printing, where structures need to be optimized\nat the material level to achieve a target shape. In such a case, a NN predicts the material\ndistribution and geometric configuration that allows the structure to adapt under external\nstimuli. The training process incorporates a physics-informed loss function, where, in addition\nto minimizing the difference between predicted and desired mechanical behavior, the model is\npenalized whenever the predicted deformation violates symbolic mechanical constraints, such\nas equilibrium equations or the stress-strain relationship (Figure 4b). By embedding these\nsymbolic equations directly into the loss function, the NN learns to generate designs that\nare not only data-driven but also physically consistent, ensuring that the final 4D-printed\nstructure maintains the desired shape across different operational conditions.\n\nA second compiled NSAI architecture, called NeurosymbolicNeuro, uses symbolic reasoning at\nthe neuron level by replacing traditional activation functions with mechanisms that incorpo-\nrate symbolic reasoning (Figure 4c). Rather than using standard mathematical operations\nlike ReLU or sigmoid, the neuron activation is governed by symbolic rules or logic. This allows\nthe NN to reason symbolically at a more granular level, integrating explicit reasoning steps\ninto the learning process. This fusion of symbolic and neural operations enables more inter-\npretable and constrained decision-making within the network, enhancing its ability to reason\nin a structured and rule-based manner while retaining the flexibility of neural computations.\nThis architecture can be described as follows:"}, {"title": null, "content": "$y = g_{symbolic}(x)$ (6)\n\nwhere: x represents the pre-activation input, $g_{symbolic}(x)$ is the symbolic reasoning-based acti-\nvation function, and y the final neuron. This architecture can find application in lean approval\nsystems, where neural activations are driven by symbolic financial rules rather than tradi-\ntional functions. One example is the collateral-based constraint neuron, which dynamically\nadjusts the risk score based on the value of the pledged collateral. When the collateral's\nvalue falls below a predefined threshold relative to the loan amount, the neuron applies a\nstrict penalty that substantially increases the risk score, effectively preventing the system\nfrom underestimating the associated financial risk. This symbolic constraint ensures that,\nregardless of favorable patterns identified in other data, the model consistently accounts for\nthe critical impact of insufficient collateral, leading to more reliable and regulation-compliant\ncredit decisions (Figure 4d).\n\nFinally, the last compiled architecture, Neuro:Symbolic \u2192 Neuro, uses a symbolic reasoner\nto generate labeled data pairs (x,y), where y is produced by applying symbolic rules or\nreasoning to the input x (Figure 4e). These pairs are then used to train a NN, which learns\nto map from the symbolic input x to the corresponding output y. The symbolic reasoner acts\nas a supervisor, providing high-quality, structured labels that guide the NN's learning process\n[46]. This architecture can be governed as follows:\n\n$D_{train} = {(x, g_{symbolic}(x)) | x \u2208 X}$ (7)\n\nwhere $D_{train}$ is the training dataset, a denotes the unlabeled data, $g_{symbolic}(x)$ represents\nsymbolic rules generating labeled data, and X the set of all input data (Figure 4b).\n\nFigure 4f illustrates this architecture, where a reasoning engine is used to label unlabeled\ntraining data, transforming raw inputs into structured (x, y) pairs, where symbolic rules\nenhance the data quality."}, {"title": "3.5 Ensemble", "content": "Another promising architecture, called Neuro \u2192 Symbolic \u2190 Neuro uses multiple intercon-\nnected NNs via a symbolic fibring function, which enables them to collaborate and share\ninformation while adhering to symbolic constraints (Figure 5a). The symbolic function acts\nas an intermediary, facilitating communication between the networks by ensuring that their\ninteractions respect predefined symbolic rules or structures. This enables the networks to\nexchange information in a structured manner, allowing them to jointly solve problems while\nbenefiting from both the statistical learning power of NNs and the logical constraints imposed\nby the symbolic system [47]. This architecture can formally defined as follows:\n\n$y = g_{fibring}({f_i}=1)$ (8)\n\nwhere $f_i$ represents the individual NN, $g_{fibring}$ is the logic-aware aggregator that enforces sym-\nbolic constraints while unifying the outputs of multiple NNs, n the umber of NNs, and y is\nthe combined output of interconnected NNs, produced through the symbolic fibring function\n$g_{fibring}$. For instance in smart cities and urban planning, multiple NNs can be employed, each\nhandle a different urban data stream\u2014such as real-time traffic flow, energy consumption,\nand air quality measurements. A symbolic fibring function then harmonizes these outputs,"}, {"title": null, "content": "enforcing city-level constraints (e.g., ensuring pollution alerts match local environmental reg-\nulations, verifying that traffic predictions align with current road network rules). If one\nnetwork forecasts a surge in vehicle congestion that would push pollution levels beyond ac-\nceptable thresholds, the symbolic aggregator identifies the conflict and directs all networks to\nconverge on a coordinated strategy such as adjusting traffic signals or advising public trans-\nport usage. By leveraging each network's specialized insight within logical urban-planning\nconstraints, the system delivers efficient, consistent decisions across the city's complex infras-\ntructure."}, {"title": "4 Leveraging NSAI in AI Technologies", "content": "Generative AI is advancing at a remarkable pace, addressing increasingly complex challenges\nthrough the integration of diverse methodologies. A key development is the combination\nof NNs with symbolic reasoning, resulting in hybrid systems that leverage both strengths.\nRecent studies have demonstrated the effectiveness of this approach in various applications,\nincluding design generation and enhancing instructability in generative models [48, 49]. This\nsection aims to classify contemporary AI techniques such as RAG, GNNs, agent-based AI,"}, {"title": null, "content": "and transfer learning within the NSAI framework. This classification clarifies how generative\nAI aligns with neuro-symbolic approaches, bridging cutting-edge research with established\nparadigms. It also reveals how generative AI increasingly embodies both neural and symbolic\ncharacteristics, moving beyond siloed methods.\n\nAdditionally, this classification enhances our understanding of these techniques' roles in\nAI's broader landscape, particularly in addressing challenges like interpretability, reasoning,\nand generalization. It identifies synergies between methods, fostering robust hybrid models\nthat combine neural learning's adaptability with symbolic reasoning's precision. Lastly, it\nsupports informed decision-making, guiding researchers and practitioners in selecting the\nmost suitable AI techniques for specific tasks."}, {"title": "4.1 Overview of Key AI Technologies", "content": "One of the most significant advancements is RAG, which integrates information retrieval with\ngenerative models to perform knowledge-intensive tasks. By combining a retrieval mechanism\nto extract relevant external data with Seq2Seq models for generation [50], RAG excels in ap-\nplications such as question answering and knowledge-driven conversational AI [51]. Seq2Seq\nmodels themselves, built as encoder-decoder architectures, have been pivotal in machine trans-\nlation, text summarization, and conversational modeling, providing the foundation for many\ngenerative AI systems. An extension of RAG is the GraphRAG approach [52], which in-\ncorporates graph-based reasoning into the retrieval and generation process. By leveraging\nknowledge graph (KGq) and ontologies structures to represent relationships between infor-\nmation elements, GraphRAG enhances query-focused summarization and reasoning tasks\n[53, 54]. This method has demonstrated success in producing coherent and contextually rich\nsummaries by integrating local and global reasoning.\n\nGNNs [55] represent a breakthrough in extending neural architectures to graph-structured\ndata, enabling advanced reasoning over interconnected entities. Their ability to model re-\nlationships between entities makes them indispensable for a range of tasks, including link"}, {"title": null, "content": "prediction, node classification, and recommendation systems, with notable success in KG\nreasoning. GNNs have also proven highly effective in named entity recognition (NER) [56],\nwhere they can leverage graph representations to capture contextual dependencies and rela-\ntionships between entities in text. This capability extends to relation extraction [57], where\nGNNs identify and classify semantic relationships between entities, crucial for building and\nenhancing KG.\n\nAdvances in agentic AI systems, which leverage Large Language Models (LLMs), have\nshown significant potential in enabling autonomous decision-making and task execution.\nThese systems are designed to function independently, interacting with environments, coordi-\nnating with other agents, and adapting to dynamic situations without human intervention. A\nnotable example is AutoGen [58], a framework that enables the creation of autonomous agents\nthat can interact with each other to solve tasks and improve through continual interactions.\nRecent work has further enhanced these systems through MoE architectures, which integrate\nspecialized sub-models (\u201cexperts\u201d) into multi-agent frameworks to optimize task-specific per-\nformance and computational efficiency. For instance, MoE-based coordination allows agents\nto dynamically activate subsets of experts based on context, enabling scalable specialization\nin complex environments [59, 60]. Xie et al. [61] explored the role of LLMs in these agentic\nsystems, discussing their ability to facilitate autonomous cooperation and communication be-\ntween agents in complex environments, and marking an important step toward scalable and\nself-sufficient AI. By combining MoE principles with multi-agent collaboration, systems can\nachieve hierarchical decision-making: LLMs act as meta-controllers, routing tasks to special-\nized agents (e.g., vision, planning, or language experts) while maintaining global coherence.\nHowever, the growing autonomy of such systems underscores the importance of XAI [62]\nto ensure transparency and trust. XAI has gained prominence as a means to enhance ac-\ncountability and support ethical AI adoption. By providing insights into model behavior,\nXAI ensures that even highly autonomous systems remain interpretable and accountable,\naddressing concerns about their decisions and actions in sensitive and dynamic environments."}, {"title": null, "content": "Recent advancements in AI have demonstrated the potential of integrating fine-tuning,\ndistillation, and in-context learning to enhance model performance. Huang et al. [63] in-\ntroduced in-context learning distillation, a novel method that transfers few-shot learning\ncapabilities from large pre-trained LLMs to smaller models. By combining in-context learn-\ning objectives with traditional language modeling, this approach allows smaller models to\nperform effectively with limited data while maintaining computational efficiency.\n\nTransfer learning [64] has similarly emerged as a foundational technique, enabling pre-\ntrained models to adapt their extensive knowledge to new domains using minimal data. This\ncapability is particularly advantageous in resource-constrained scenarios. Techniques such as\nfeature extraction, where pre-trained model layers are repurposed for specific tasks, and fine-\ntuning, which involves adjusting the weights of the pre-trained model for new tasks, further\nillustrate its adaptability.\n\nComplementing these methods, prompt engineering empowers LLMs to perform task-\nspecific functions through carefully designed prompts. Techniques such as CoT prompting\n[33], zero-shot [65], and few-shot prompting enhance the ability of LLMs to reason and gener-\nalize across diverse tasks without extensive retraining [66]. Additionally, knowledge distilla-\ntion plays a crucial role in optimizing AI models by transferring knowledge from larger, more\ncomplex models to smaller, efficient ones [67]. Variants of distillation, such as task-specific\ndistillation, feature distillation, and response-based distillation, further streamline the process\nfor edge computing and resource-limited environments.\n\nReinforcement learning and its variant RLHF [68], focus on training agents to make se-\nquential decisions in dynamic environments. RLHF further aligns agent behavior with human\npreferences, fostering ethical and adaptive AI systems. Finally, continuous learning, or life-\nlong learning, addresses the challenge of adapting AI systems to new data while retaining\npreviously learned knowledge, ensuring AI remains effective in changing environments [69].\nThese techniques represent the cutting edge of generative AI, each contributing to solving\ncomplex challenges across diverse applications. The classification of these methods within"}, {"title": null, "content": "NSAI paradigm, explored in the following sections, offers a structured perspective on their\nsynergies and practical relevance."}, {"title": "4.2 Classification of AI Technologies within NSAI Architectures", "content": "This section categorizes generative AI techniques within the eight distinct NSAI architec-\ntures, highlighting their underlying principles and practical applications. By classifying these\napproaches, we gain a clearer understanding of how neural and symbolic methods synergize\nto address diverse challenges in AI, as summarized in Figure 6."}, {"title": "4.2.1 The Sequential Paradigm: From Symbolic to Neural Reasoning", "content": "Techniques like RAG, GraphRAG, and Seq2Seq models (including LLMs, e.g., GPT [70"}]}