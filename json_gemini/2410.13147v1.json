{"title": "Utilizing Large Language Models in An Iterative Paradigm with Domain Feedback for Molecule Optimization", "authors": ["Khiem Le", "Nitesh V. Chawla"], "abstract": "Molecule optimization is a critical task in drug discovery to optimize desired properties of a given molecule through chemical modification. Despite Large Language Models (LLMs) holding the potential to efficiently simulate this task by using natural language to direct the optimization, straightforwardly utilizing shows limited performance. In this work, we facilitate utilizing LLMs in an iterative paradigm by proposing a simple yet highly effective domain feedback provider, namely Re\u00b2DF. In detail, Re\u00b2DF harnesses an external toolkit, RDKit, to handle the molecule hallucination, if the modified molecule is chemically invalid. Otherwise, its desired properties are computed and compared to the original one, establishing reliable domain feedback with correct direction and distance towards the objective, followed by a retrieved example, to explicitly guide the LLM to refine the modified molecule. We conduct experiments across both single- and multi-property objectives with 2 thresholds, where Re\u00b2DF shows significant improvements. Particularly, for 20 single-property objectives, Re\u00b2DF enhances the Hit ratio by 16.95% and 20.76% under loose and strict thresholds, respectively. For 32 multi-property objectives, Re\u00b2DF enhances the Hit ratio by 6.04% and 5.25%.", "sections": [{"title": "Introduction", "content": "Drug discovery, aimed at identifying molecules that can safely modulate the disease (Bateman, 2022), is an expensive process that takes on average more than a decade to reach approval and release (Berdigaliyev and Aljofan, 2020). Fortunately, recent advancements in AI for molecular science have been revolutionizing this process by remarkably accelerating many of its molecule-related tasks. While tasks such as molecule property prediction, as well as direct and retrosynthesis have been extensively investigated (Zhao et al., 2023; Liu et al., 2024b), molecule optimization, a critical task, remains largely under-explored.\nMolecule optimization is the task of modifying a given molecule with the objective of achieving desired properties. Importantly, the modified molecule needs to retain a certain level of similarity to the original one, a requirement known as the similarity constraint of the modified molecule (Jorgensen, 2009). This task is routine in pharmaceutical companies and is conventionally carried out by chemists through manual attempts (Hoffer et al., 2018; de Souza Neto et al., 2020), which is not scalable. Given this context, the latest groundbreaking in AI, Large Language Models (LLMs), hold tremendous potential to efficiently simulate and scale this task by using natural language to direct the optimization (Zhang et al., 2024). Unlike the traditional supervised training approach (Xia et al., 2024), utilizing LLMs with outstanding abilities alleviates the need for annotated data, as well as exhibits zero-shot and open-vocabulary generalization beyond a pre-defined set of objectives, making them highly promising for this task.\nAs pioneers, Zhang et al. (2024) straightforwardly explore the capability of LLMs for solving this task using natural language to direct the optimization and notice limited performance. Moving further, motivated by the iterative refinement strategy employed by chemists, Liu et al. (2024a) propose to utilize LLMs in an iterative paradigm with domain feedback. Specifically, a domain feedback provider, ReDF verifies whether the modified molecule meets the objective, if not, ReDF retrieves from a prior database a molecule that is similar to the modified molecule and meets the objective, serving as an example to guide the LLM to refine the modified molecule. Notably, the domain feedback provider plays a vital role in the iterative paradigm (Yang et al., 2022; Madaan et al., 2024). Although bringing improved performance, ReDF does not consider the molecule hallucination where the modified molecule is chemically invalid (Guo et al., 2023), preventing the retrieving step. Moreover, by solely depending on a retrieved example as domain feedback, ReDF unexpectedly harms the similarity constraint of the modified molecule.\nIn this work, we propose an improved domain feedback provider, namely Re\u00b2DF, which is carefully designed to facilitate utilizing LLMs in an iterative paradigm more effectively. Different from the previous ReDF, first of all, Re2DF takes into account the molecule hallucination, thereby actively promoting the retrieving step. To be more precise, at each iteration, the modified molecule is immediately verified for its validity using an external toolkit, RDKit (Landrum et al., 2013). If the modified molecule is chemically invalid, the concrete error message from RDKit such as the existence of an unclosed ring (Schoenmaker et al., 2023), is extracted as reliable domain feedback to inform the LLM to correct the modified molecule, in analogy to debugging (Chen et al., 2023; Zhong et al., 2024). Otherwise, Re2DF verifies whether the modified molecule meets the objective, if not, its desired properties are computed and compared to the original one, establishing reliable domain feedback with correct direction and distance towards the objective to explicitly guide the LLM to refine the modified molecule. Additionally, as in the previous ReDF, a retrieved example is appended to further enrich the domain feedback to guide the LLM. By diminishing the dependence on a retrieved example, Re2DF excels at satisfying the similarity constraint of the modified molecule, as we will demonstrate along with improved performance."}, {"title": "Methodology", "content": "Here we delve into the details of utilizing LLMs in an iterative paradigm integrated with the proposed domain feedback provider, Re2DF."}, {"title": "Preliminaries", "content": "A given molecule m, represented in the SMILES string (Weininger, 1988). Molecule optimization is the task of modifying a given molecule with the objective of achieving desired properties, p. With an LLM M, the modified molecule m is formulated:\n$m = M(p||m),$\ns.t. $E(C_p(m)) = 1,$\nwhere || indicates concatenation, $E(C_p(m)) \\in {0,1}$ indicates whether m meets the objective with its desired properties $C_p(m)$."}, {"title": "Refinement with Re\u00b2DF", "content": "After initialization, m is immediately verified for its validity using an external toolkit, RDKit (Landrum et al., 2013), a widely-used cheminformatics toolkit. If m is chemically invalid, the concrete error message from RDKit is extracted as reliable domain feedback to inform the LLM to correct m. Otherwise, Re2DF verifies whether m meets the objective by checking whether $E(C_p(m)) = 1$, if not, its desired properties $C_p(m)$, are computed and compared to the original one, establishing reliable domain feedback, denoted fb, with correct direction and distance $|C_p(m) \u2013 C_p(m)|$ towards the objective to explicitly guide the LLM to refine m. Additionally, to further enrich the domain feedback, Re2DF retrieves from a prior database D a molecule me that is similar to m and meets the objective, serving as an example to guide the LLM:\n$m_e = retrieve(D, m),$\n$= argmax_{\\m'\\in D} \\phi(m', m) \\cdot E(C_p(m')),$\nwhere $ \\phi(m', m)$ is the Tanimoto similarity (Bajusz et al., 2015) between a molecule m'e in D and m.\nSubsequently, the described procedure is iterated for a pre-defined maximum number of iterations N or either can be early stopped if m meets the objective, as precisely depicted in Algorithm 1."}, {"title": "Experiments", "content": "Here we conduct experiments to evaluate the effectiveness of the proposed domain feedback provider, Re2DF in integrating with LLMs in an iterative paradigm. Following previous works (Liu et al., 2023, 2024a), 200 molecules are sampled from the ZINC database (Irwin et al., 2012) as given molecules. Using 5 high-level molecular properties such as LogP as desired properties, we adopt single- and multi-property objectives as increase/decrease (+/-) desired properties with 2 thresholds. Details of the set of examined objectives and prompts in natural language are listed in Appendix A. Throughout experiments, we utilize the latest and most capable herd of open-sourced LLMs, Llama-3.1 (Dubey et al., 2024) with 2 model sizes 8B and 70B parameters. Straightforwardly prompting LLMs is a vanilla baseline (Zhang et al., 2024)."}, {"title": "Conclusion", "content": "In this work, we make focused contributions on utilizing LLMs with outstanding abilities for solving molecule optimization, a critical task in drug discovery, using natural language to direct the optimization. To this end, we propose an improved domain feedback provider, namely Re\u00b2DF, which is carefully designed to facilitate utilizing LLMs in an iterative paradigm more effectively. For evaluation, after fixing a significant flaw in the evaluation metric, we conduct experiments across both single- and multi-property objectives with 2 thresholds, where Re2DF shows significant improvements over baselines and excels at satisfying the similarity constraint of the modified molecule. Besides the main experiments, we conduct a study to understand the impact of the maximum number of iterations N in the iterative paradigm and observe that Re2DF is beneficial from growing N and consistently outperforms the previous ReDF across both single- and multi-property objectives with 2 thresholds. The results of this study are presented in Appendix B."}, {"title": "Limitations", "content": "First of all, although it does not require any training, we admit that the strategy of utilizing LLMs in an iterative paradigm requires prompting LLMs over multiple iterations, obviously leading to multiplying prompting costs. However, this limitation is acceptable and compensated by bringing improved performance. With the awareness that the domain feedback provider plays a vital role in the iterative paradigm, we propose an improved domain feedback provider, namely Re2DF. By establishing reliable domain feedback with correct direction and distance towards the objective, followed by a retrieved example, to explicitly guide the LLM to refine the modified molecule, Re2DF outperforms the previous ReDF across both single- and multi-property objectives with 2 thresholds. Albeit containing correct direction and distance towards the objective, domain feedback from Re2DF currently lacks correct actions towards the objective which involve knowledge of molecular properties, are presumably useful but hard to establish."}, {"title": "Details of Experiments", "content": "To conduct experiments, a sufficient number of 200 molecules are sampled from the ZINC database (Irwin et al., 2012) as given molecules. Then, 5 high-level molecular properties, i.e., LogP, TPSA, Hydrogen bond donors (HBDs), Hydrogen bond acceptors (HBAs), and Druglikeness are selected as desired properties. As stated in previous works (Liu et al., 2023, 2024a), these high-level molecular properties are selected since they have an ambiguous nature and involve indeterministic answers, serving as a source of inspiration for chemists. Another criterion for selection is that they can be computed by computational softwares, ensuring evaluation at high volume. Using these molecular properties, we adopt single- and multi-property objectives as increase/decrease (+/-) desired properties with 2 thresholds, as expressed in Table 3. These objectives are then wrapped into natural language with the template of prompts kept naive as listed in Box 1. As discussed earlier, straightforwardly prompting LLMs is a vanilla baseline (Zhang et al., 2024). Furthermore, for stronger baselines, we compare Re2DF in integrating with LLMs in a 3-iteration (3) iterative paradigm with Self-Feedback (Madaan et al., 2024) in which LLMs themselves act as the domain feedback provider, where prompt for acquiring domain feedback is adapted from the primary paper and are listed in Box 2, and especially compare with the previous ReDF. Different from the previous ReDF, Re\u00b2DF takes into account the molecule hallucination. To be more precise, at each iteration, the modified molecule is immediately verified for its validity using an external toolkit, RDKit (Landrum et al., 2013). If the modified molecule is chemically invalid, the concrete error message from RDKit which belongs to one of six categories: syntax error, parentheses error (extra open parentheses or extra close parentheses), unclosed ring, aromaticity error (a combination of non-ring atom marked aromatic and kekulization errors), bond already exists, and valence error (Schoenmaker et al., 2023), is extracted as reliable domain feedback to inform the LLM to correct the modified molecule. By establishing reliable domain feedback with correct direction and distance towards the objective, followed by a retrieved example, to explicitly guide the LLM to refine the modified molecule as illustrated in Listing 1, Re2DF outperforms the previous ReDF across both single- and multi-property objectives with 2 thresholds."}, {"title": "Analysis", "content": "We conduct a study to understand the impact of the maximum number of iterations N in the iterative paradigm by growing N to larger limits. Notably, the procedure can be early stopped if the modified molecule meets the objective, as precisely depicted in Algorithm 1, growing N means growing the number of trials. Table 4 reveals that Re2DF is beneficial from growing N, gains improved performance as N gets larger and consistently outperforms the previous ReDF across both single- and multi-property objectives with 2 thresholds."}]}