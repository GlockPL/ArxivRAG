{"title": "Expansion Quantization Network: An Efficient Micro-emotion Annotation and Detection Framework", "authors": ["Jingyi Zhou", "Senlin Luo", "Haofan Chen"], "abstract": "Text emotion detection constitutes a crucial foundation for advancing artificial intelligence from basic comprehension to the exploration of emotional reasoning. Most existing emotion detection datasets rely on manual annotations, which are associated with high costs, substantial subjectivity, and severe label imbalances. This is particularly evident in the inadequate annotation of micro-emotions and the absence of emotional intensity representation, which fail to capture the rich emotions embedded in sentences and adversely affect the quality of downstream task completion. By proposing an all-labels and training-set label regression method, we map label values to energy intensity levels, thereby fully leveraging the learning capabilities of machine models and the interdependencies among labels to uncover multiple emotions within samples. This led to the establishment of the Emotion Quantization Network (EQN) framework for micro-emotion detection and annotation. Using five commonly employed sentiment datasets, we conducted comparative experiments with various models, validating the broad applicability of our framework within NLP machine learning models. Based on the EQN framework, emotion detection and annotation are conducted on the GoEmotions dataset. A comprehensive comparison with the results from Google literature demonstrates that the EQN framework possesses a high capability for automatic detection and annotation of micro-emotions. The EQN framework is the first to achieve automatic micro-emotion annotation with energy-level scores, providing strong support for further emotion detection analysis and the quantitative research of emotion computing.", "sections": [{"title": "1. Introduction", "content": "Emotions represent one of the most intricate intrinsic experiences of humanity. Artificial intelligence can gain profound insights into and analyze human emotions through emotion detection, allowing for a better understanding of people's emotional responses [1]. This capability can help individuals comprehend their motivations, enhance the rationality of decision-making, improve interpersonal relationships [2], treat psychological disorders such as depression and anxiety [3], and develop robots with greater emotional understanding to enhance user experiences, among other benefits.\nEmotion datasets are a vital resource in NLP research. Currently, the most widely used datasets are single-label datasets [4-8], where each sample can belong to only one emotional category. Traditional single-label emotion datasets have ranged from early binary or ternary\ncategories (such as \"positive,\" \"negative,\" and \"neutral\") [8] to the six basic emotions of joy, sadness, anger, fear, disgust, and surprise proposed by Ekman [9], and Plutchik's eight basic emotions [10].Single-label datasets are relatively straightforward to annotate, incur lower manual costs, and are less prone to errors. However, a single sentence or passage often contains multiple emotions, which cannot be adequately summarized with simple labels, leading to the emergence of multi-label emotion datasets. In multi-label datasets, each sample can simultaneously belong to two or more emotional categories. As NLP technology continues to innovate and evolve, multi-label emotion datasets enriched with nuanced micro-emotions are expected to replace the initial, singular annotations of single-label datasets [11]. SemEval-2007 serves as a micro-emotion dataset utilizing news headlines as its corpus, annotated with emotion labels carrying effective values, yet it comprises a relatively small sample size of 1,250. In 2020, at the ACL conference, Google released the large, manually annotated GoEmotions multi-label emotion dataset [12].Despite being considered the largest fine-grained emotion dataset currently available [13], the GoEmotions dataset still faces issues of label sparsity and imbalance. Specifically, single-label samples account for 83%, while dual-label samples comprise only 15%, and samples with three or more labels make up a mere 2%. The sparsity of labels may hinder model learning [14], particularly due to imbalances where some labels appear infrequently, resulting in poor predictive performance, while others occur frequently, leading to biased predictions favoring those labels.\nIn recent years, with the rapid development of human-machine alignment [15] and humanoid robots [16], there has been an increasing demand for machines to understand human emotions, making affective computing [17] and micro-expressions [18] prominent research topics. While macro-expressions provide relatively straightforward and direct representations of emotions, micro-expressions more accurately reflect subtle, unconscious, or fleeting emotional states. Annotating and detecting micro-expressions presents a greater challenge. Current methodologies for capturing and detecting micro-expressions through images or videos have resulted in the development of several datasets with emotional intensity related to micro-expressions [20-24], alongside published research findings. Compared to micro-expressions, the subtle micro-emotions embedded in natural language expressions can more comprehensively capture the nuanced emotional fluctuations present in human language and text. Achieving human-machine alignment in humanoid robots and human-machine dialogue necessitates that the recognition and detection of micro-emotions in textual communication be regarded as equally important as that of micro-expressions. Currently, the scarcity of publicly available datasets for text-based micro-emotions poses a challenge for research in this domain. The capacity of machines to understand textemotion has been a long-term research objective in natural language processing (NLP). Currently, emotion datasets\u2014whether annotated for single-label, multi-label, or micro-expressions\u2014primarily rely on manual annotation. This reliance is inevitably influenced by external and subjective factors, resulting in high costs, low efficiency, and challenges in annotating micro-emotions. To better capture the various subtle nuances of human emotions in emotion detection, exploring machine or machine-assisted micro-emotion annotation datasets has become increasingly vital. We have sought to establish a simple yet effective framework for micro-emotion detection and annotation, termed the Expansion Quantization Network (EQN), which incorporates energy scores. Within the EQN framework, the automatic multi-label annotation assigns the highest energy values to macro-emotions and lower energy values to micro-emotions, thereby enhancing the model's ability to understand and predict emotional nuances more effectively."}, {"title": "Contributions of this paper:", "content": "1. Introduction of Continuous Emotional Intensity: The EQN framework adds continuous energy values to samples based on manually annotated single-label or multi-label emotion datasets. By quantifying emotional intensity with continuous values, the framework distinguishes between macro-emotions and micro-emotions, addressing the subjectivity inherent in manual annotations.\n2. Full Label Mapping Numerical Method: This method learns the interdependencies among data labels to annotate label values without the need for prior knowledge or emotional lexicons, thereby reducing the risk of data contamination.\n3. Label Regression Method for Training Sets: By learning from the fully annotated training set, this approach regresses the labels that have already been manually annotated to a maximum value while retaining the values of automatically annotated labels. This method enhances the performance of training iterations.\n4. Validation of the EQN Framework's Generalization Ability in NLP Models: Comparative experiments conducted on five distinct single-label and multi-label emotion detection datasets using various NLP models demonstrate that the EQN framework is widely applicable across NLP models.\n5. Supplementary Annotation of the GoEmotions Micro-Emotion Dataset and Public Release:GoEmotions is a 28-class emotion dataset, which presents significant challenges for emotion classification and micro-emotion detection. Utilizing the EQN framework, we first fully annotated the GoEmotions dataset and applied the proposed label regression method to supplement the micro-emotion annotations, which have now been publicly released."}, {"title": "2. Related Work", "content": "Machine-assisted annotation of micro-emotion labels with energy values is particularly crucial in applications such as customer emotion management, psychological health analysis, and brand monitoring. It provides more nuanced emotional feedback and has garnered significant attention from scholars in the field of Natural Language Processing (NLP). The SemEval-2007 dataset[11], which includes effective value annotations, is a multi-label micro-emotion dataset based on manual annotation. Although it offers micro-emotion data for machine-assisted labeling, its size is relatively limited. Early research in emotion focused primarily on emotional polarity (such as positive, negative, and neutral), typically employing bag-of-words models or emotion dictionaries for classification[1]. Each emotional lexicon in these dictionaries is assigned a score to evaluate the accuracy of its emotional sentiment. The Chinese EmoBank[25] provides a manually annotated Chinese dimensional emotion lexicon, which includes various modal words to express emotional intensity. Additionally, research has proposed methods to generate word-level emotional distribution (WED) vectors by integrating domain knowledge with dimensional dictionaries[26]. In 2024, the latest research by Wang Yaoqi[27] and colleagues attempted to introduce emotional distance among emotions, utilizing a text EDLE method that incorporates VAD emotional knowledge to enhance label accuracy based on emotion dictionaries.\nDespite the presence of energy intensity scores in emotion dictionaries, these resources are primarily utilized for determining the categorical attributes of emotions and do not yet facilitate the automatic annotation of emotional energy intensity values. In multi-label learning (MLL) methods, the objective is to identify multiple emotions for each sentence[28]. This approach involves setting a threshold, whereby emotions scoring above this threshold are marked as relevant, while others are deemed irrelevant. However, MLL methods are ineffective in learning the intensity of each individual emotion.\nTo address this issue, Geng (2016)[29] proposed a novel machine learning paradigm known as label distribution learning (LDL). Subsequently, the emotional distribution learning (EDL) algorithm improved upon the label distribution framework[30]. However, these methods necessitate the design of complex textual features, which require substantial human resources. In 2024, EmoLLMs[31], based on large language models such as ChantGPT, employed instruction data to fine-tune various LLMs with the aim of predicting both the emotional category and intensity of the input text. EmoLLMs are capable of generating micro-emotion labels accompanied by numerical values. Although this approach has demonstrated promising results, the process of developing instruction tuning data remains intricate, with the resultant emotional classification and intensity largely contingent upon the cognitive capabilities of the large models.\nIn summary, scholars in the field of NLP have been dedicated to uncovering the emotional energy values embedded in text, employing a variety of distinctive methods. However, these approaches still exhibit limitations in practical applications, failing to achieve the automatic annotation of large-scale micro-emotion datasets. Our EQN framework is capable of automatically annotating labels with continuous values, enabling multi-label datasets to encompass both macro and micro emotional characteristics. The principles and methods underlying this framework are relatively straightforward, yet its applicability is broad.\nMicro-emotion detection is one of the crucial downstream tasks for multi-label micro-emotion datasets. Traditional machine learning models typically classify text by converting it into word vectors and extracting features through feature engineering, with commonly employed methods including Naive Bayes[32], Support Vector Machines (SVM)[33], and Logistic Regression[34]. In contrast, deep learning models leverage neural networks to autonomously learn hierarchical feature representations from data, extracting rich and complex features from the raw input. This process often necessitates substantial amounts of training data. For instance, Convolutional Neural Networks (CNN[35]) and Recurrent Neural Networks (RNN)[36], including Long Short-Term Memory (LSTM) networks and Gated Recurrent Units (GRU), are effective in extracting textual features and performing classification. Currently, fine-tuning methods based on large language models, such as BERT and GPT, are widely applied to multi-label micro-emotion datasets, demonstrating favorable results.\nIn the section dedicated to validating the EQN framework, we conducted comparative experiments using five models, including Artificial Neural Networks (ANN), Deep Convolutional Networks"}, {"title": "3. Methods", "content": "This section provides a comprehensive overview of the EQN, including a flowchart depicting the overall process of the EQN framework, definitions of key terms, the operational steps of the EQN framework, the core structure, as well as the design of both the input and output components."}, {"title": "3.1 EQN Framework", "content": "The process of using machine models to detect data samples generally comprises three components: data input, model learning and processing, and classification output. The EQN proposed in this paper primarily focuses on enhancing the input and output components, making it compatible ith any machine learning model designed for NLP classification tasks."}, {"title": "3.1.1 Terms Involved in the EQN", "content": "Full Label: Refers to the data samples that are initialized or output with complete category labels, each accompanied by a real number representing emotional intensity. In this paper, the range of real values for full labels is specified to be between 0.0 and 10.0. For samples lacking corresponding predefined label attributes, the minimum emotional intensity is marked as 0.0, while the maximum emotional intensity is set at 10.0. After automatic annotation, thresholds can be adjusted according to actual conditions.\nFull Label Initialization: This process maps the manually annotated single or multi-labels from the original dataset to values of 0.0 or 10.0 prior to the initial run of the training set. Labels that have been manually annotated are assigned the maximum value of 10.0, whereas unannotated labels receive the minimum value of 0.0.\nTraining Set Label Regression: Based on the core framework of EQN, this step involves annotating the training set with full labels, assigning the maximum value of 10.0 to the labels that have been manually annotated, while other values remain unchanged. In other words, it replaces the 0.0 values used during the initialization of full labels with the micro-emotional values learned by the model."}, {"title": "3.1.2 Operational Process of the EQN Framework", "content": "The EQN framework features a simple structure, and its operational process is as follows:\n1. Data processing transforms the existing manually annotated text emotion training set into numerical features.\n2. Full label initialization of the training set.\n3. Input the training data into the NLP classification model, selecting the best-performing Model 1 during training.\n4. Output through the fully connected layer.\n5. The output of the training/test set is generated using a linear activation function for full label annotation.\n6. Label regression (full label regression of the training set).\n7. The regressed full label training set is used for additional training to select the optimal Model 2.\n8. Use the optimal Model 2 to perform emotion classification predictions or annotate the text dataset with emotional scores.\nNote: Steps 1, 2, 3, 4, and 5 constitute the core EQN framework (referred to as CoEQN). The fourth section employs the CoEQN framework to validate the EQN.\nBased on the aforementioned EQN framework model diagram, the primary distinction between the EQN framework and conventional text classification models lies in the input and output components. The following sections will focus on detailing the input and output components of the EQN framework."}, {"title": "3.1.3 EQN Input Component", "content": ""}, {"title": "3.1.3.1 Typical Text Input", "content": "In traditional NLP tasks for single-label or multi-label text classification, the input text undergoes preprocessing and feature extraction (Tokenization, Embedding) before being converted into numerical features to serve as input. The input component generally comprises the text along with its corresponding labels. Labels are typically represented as either integers or one-hot encodings and possess the following characteristics:\n1. Integer Label Representation: For the i-th sample, the input feature X\u2081 corresponds to the label category Yi, with N categories represented as 0, 1, 2, ... ,N-1, where N denotes the total number of categories.\n2. One-Hot Encoding of Labels: Each label is treated as an independent feature and represented as a binary encoding, with only two possible values: 0 and 1. Here, 0 indicates the absence of the emotional label in the sample, while 1 signifies the presence of that emotional label."}, {"title": "3.1.3.2 Input for the EQN Framework", "content": "In the EQN framework, the processing of input text data aligns with traditional methods; however, the representation of labels differs significantly. In conventional approaches, whether using integer or one-hot encoding, labels merely indicate the presence or absence of a category. In contrast, the labels for input text in the EQN framework are annotated as full label values.\nThe input method for full label values has the following characteristics:\n1. Full Category Label Annotation: It employs full category labels, with each label assigned a continuous real number representing the intensity of the emotion.\n2. Value Range for Labels: The numerical range corresponding to the labels can be defined according to task requirements. In this study, the values are set between 0.0 and 10.0, where 0.0 signifies the minimum emotional intensity for the label, and 10.0 denotes the maximum intensity.\n3. Two Input Methods: The initialization of full category label values for samples and the label regression of the training set correspond to two distinct frameworks: CoEQN and EQN, respectively.\nAs shown in Figure 1, full-label numerical initialization mapping and label regression pertain to the input component. In the CoEQN framework, the full-label numerical initialization mapping assigns an initial value to each emotion label, using real numbers between 0 and 10 to represent the intensity of emotions. For each label $t_j$ in sample $i$, initialization mapping can be performed using the following formula.\n$Y_{ij} = f(t_j)$ (1)\nHere, $f(t_j)$ is a mapping function that assigns the value mapped from label $t_j$ of sample $i$ to $Y_{ij}$.\n$f(t_i) =\n\\begin{cases}\n10.0, & \\text{if sample i has label } t_j \\\\\n0.0, & \\text{if sample i does not have label } t_j\n\\end{cases}$ (2)\nLabel regression in the EQN framework involves using the CoEQN-trained model to annotate the training set, followed by performing label regression on the annotated training set. Let $E$ represent the intensity value annotated by the model; the label regression formula is as follows:\n$f(t_j) =\\begin{cases}\nE = 10.0, & \\text{if sample i has label } t_j \\\\\nE = E, & \\text{if sample i does not have label } t_j\n\\end{cases}$ (3)\nEQN is a framework that takes full-label text input, processes it through model learning, and outputs the intensity value of each label via linear regression, providing full-category label intensity values for each predicted sample. By individually training a linear regression model for each label, the framework generates an intensity prediction for each label. This intensity value, a continuous measure (ranging from 0 to 10 in this study), reflects the relevance or association between the label and the current text. By setting an intensity threshold, the framework determines which labels are present, thereby enabling macro-emotion and micro-emotion annotation. Emotion classification is achieved by ranking the labels based on the annotated intensity values."}, {"title": "3.1.3.3 Examples of Traditional Input and EQN Framework Input", "content": "To clarify the differences between the full label method and the integer or one-hot encoding labeling approaches, the following comparative examples are presented.\nAssuming the dataset X contains three samples-Sample 1, Sample 2, and Sample 3-with three predefined labels labeled as 0, 1, and 2. The manual annotation results indicate that Sample 1 has labels 0 and 1, Sample 2 has label 1, and Sample 3 has label 2. The input data for Samples 1, 2, and 3 can be represented using full label initialization, full label regression, integer encoding, and one-hot encoding, as shown in Table 1."}, {"title": "3.1.4 EQN Output Component", "content": "The design of the output component in the EQN framework differs from that of traditional multi-label classification due to the distinct problems it addresses. In conventional multi-label classification, input text is assigned to predefined categories, with the initialized label values being discrete and the output resulting in discrete categories.\nWhile the results produced by the EQN framework can be utilized for classification tasks, it primarily addresses regression tasks, yielding continuous values. This approach is akin to systems used for stock price prediction or real estate valuation, where the output is expressed as numerical values.\nIn the EQN framework designed to solve regression problems, the model's output component first connects to a fully connected Dense layer. Each neuron in the Dense layer is linked to all neurons in the previous layer, with each connection assigned a weight that learns the relationships between different features, thereby preparing data for subsequent output.\nThe final layer of the network is a linear layer (using a linear activation function) that consists of C units, whereCrepresents the total number of categories. Corresponding to the full label input of samples in the EQN framework, the output section of the linear layer produces Cchannels, each outputting the intensity score of the sample for each label, thereby achieving full label output of emotional values."}, {"title": "3.1.5 EQN Framework Evaluation Metrics", "content": "Statistical classification in emotion detection is a crucial downstream task. Key evaluation metrics in dataset classification include Precision Recall and F1-score etc. For single-label classification in emotion datasets, the full-category output for each sample is processed using Max (), where the label with the highest energy level is selected as the predicted label, which is relatively straightforward. In multi-label classification, since each sample may have multiple labels, the computation of evaluation metrics becomes more complex.\nFor emotion classification, in the case of single-label classification, the full-category output for each sample is processed using Max(), and the label with the highest energy level is chosen as the predicted label. In multi-label classification, the number of labels for the sample and the threshold are used to select the predicted labels. Assuming sample i has k\u2081 true labels, we select the top k\u2081 labels with the highest energy scores as the predicted labels. The predicted label set is as follows:\n$T_i = TOP\\_k_i(V_{ij})$ (9)\nThe following are the calculation formulas for the evaluation metrics of the EQN framework. These formulas compute the label matching ratio at the sample level, and the overall evaluation metric is obtained by averaging across all samples.\nPrecision measures how many of the predicted labels are correct. The precision for the \\( i \\)-th sample is calculated as:\n$precision_i = \\frac{|T_i \\cap \\widehat{T_i}|}{|\\widehat{T_i}|}$ (10)\nWhere $T_i$ is the true label set of the i-th sample, and $\\widehat{T_i}$ is the label set predicted based on the energy scores. $|T_i \\cap \\widehat{T_i}|$ represents the intersection of the true label set and the predicted label set, i.e., the number of correctly predicted labels.\nThe overall multi-label precision of the EQN framework is the average of the precision values for all samples. The calculation formula is as follows:\n$precision = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{|T_i \\cap \\widehat{T_i}|}{|\\widehat{T_i}|}$ (11)\nRecall measures how many of the true labels are correctly predicted. The recall for the \\( i \\)-th sample is calculated as follows:\n$Recall_i = \\frac{|T_i \\cap \\widehat{T_i}|}{|T_i|}$ (12)\nThe overall multi-label recall of the EQN framework is the average of the recall values for all samples. The calculation formula is as follows:\n$Recall = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{|T_i \\cap \\widehat{T_i}|}{|T_i|}$ (13)\nThe F1-score is the harmonic mean of precision and recall, balancing both metrics. The F1-score for the i-th sample is calculated as follows:\n$F1_i = \\frac{2 \\times precision_i \\times Recall_i}{precision_i + Recall_i}$ (14)\nThe overall F1-score of the EQN framework is the average of the F1-scores for all samples. The calculation formula is as follows:\n$F1 = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{2 \\times precision_i \\times Recall_i}{precision_i + Recall_i}$ (15)\nThe EQN framework comprises two processes: CoEQN and EQN, with the latter encompassing the entire workflow for the automatic annotation of emotional datasets and micro-emotion detection. CoEQN includes only step1to 5 of the EQN framework.\nTo validate the applicability of the EQN framework, experiments were conducted using the same processes and parameter settings as conventional models. This approach enhances the comparability of the experimental results and also demonstrates the generalizability of the EQN"}, {"title": "4 Experiments", "content": "To validate the broad applicability of the EQN framework, we selected five commonly used datasets (four single-label and one multi-label), along with various algorithms and language models for comparative analysis. The experimental setup, including the equipment specifications, experimental rules, and model evaluation methods, will be detailed.\nThe results of the tests comparing \"with\" and \"without\" the CoEQN framework will be presented in different formats, including tables and Pearson correlation coefficient heatmaps. These visual representations will highlight the outcomes of the same model under identical conditions, thereby validating the usability of the EQN framework."}, {"title": "4.1 Datasets Used for Comparative Experiments", "content": ""}, {"title": "1. 7health Dataset", "content": "The 7health dataset [4] is a mental health emotion analysis dataset designed to reveal psychological health patterns through statements. This comprehensive dataset is a meticulously curated collection of mental health statuses tagged from various statements. It amalgamates raw data from multiple sources, which have been cleaned and compiled to create a robust resource for developing chatbots and conducting emotion analysis.\nThe dataset comprises 51,074 entries, annotated with seven categories of emotions: Anxiety, Bipolar, Depression, Normal, Personality Disorder (PD), Stress, and Suicidal. The distribution of sample counts for each category is presented in Table 2.\nAs indicated by the data in Table 2, the sample counts in this dataset are severely imbalanced. With the exception of the Normal category, the other six categories represent negative emotions that exhibit significant similarity, making it a particularly challenging multi-label dataset."}, {"title": "2. 6emotions Dataset", "content": "The 6emotions dataset[5] is an English corpus comprising six categories of emotions. Each entry in this dataset consists of a text segment representing a Twitter message, along with a corresponding label that indicates the predominant emotion conveyed. The emotions are classified into six categories: sadness (0), joy (1), love (2), anger (3), fear (4), and surprise (5). This dataset provides a rich foundation for exploring the nuanced emotional landscape within the realm of social media."}, {"title": "3. 3TFN Dataset", "content": "The Twitter Financial News dataset(3TFN dataset )[6] is an English-language dataset containing an annotated corpus of finance-related tweets. This dataset is used to classify"}, {"title": "4. 3TSA dataset", "content": "The Twitter Sentiment Analysis Dataset (3TSA dataset)[7] is a three-class dataset comprising approximately 163,000 tweets, each associated with sentiment labels. The dataset consists of two columns: the first column contains the cleaned tweets and comments, while the second column indicates the corresponding sentiment label.\nAll tweets have been cleaned using Python's regular expressions and natural language processing techniques, with sentiment labels ranging from -1 to 1. A label of 0 indicates a neutral tweet, 1 denotes a positive sentiment, and -1 signifies a negative tweet."}, {"title": "5. GoEmotions dataset", "content": "At the 2020 ACL conference, researchers from Google released the GoEmotionsdataset[12], the largest and most finely grained multi-label micro-emotion dataset to date, comprising 58,000 manually annotated Reddit comments. This dataset expands the emotion categories to 28, providing an opportunity to better uncover users' latent emotions.\nThe dataset is divided into three parts: the training dataset contains 43,410 samples, the test dataset includes 5,427 samples, and the validation dataset comprises 5,426 samples. The emotion categories are as follows: admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, and surprise."}, {"title": "4.2 Models and Configurations", "content": "This study employs five models\u2014ANN[37], CNN[38], LSTM[39], TextCNN[1], and BERT[40] for comparative testing across the selected datasets."}, {"title": "1. ANN Model", "content": "Artificial Neural Networks (ANN) are computational models that mimic biological neural systems and are widely applied in machine learning and artificial intelligence. ANN serves as the foundation of modern deep learning, with many complex models (such as Convolutional Neural Networks and Recurrent Neural Networks) developed based on this fundamental structure. It primarily comprises an input layer, hidden layers, and an output layer. In this study, the parameters for the ANN model are set as follows: the number of neurons in the input layer is 512, the number of neurons in the hidden layer is 256, and the activation function is ReLU."}, {"title": "2. CNN Model", "content": "Convolutional Neural Networks (CNN) are extensively used in text classification due to their effectiveness in capturing local features and contextual information. A typical CNN architecture includes an input layer, convolutional layers, pooling layers, dense layers, and an output layer. For the CNN model utilized in this study, the parameters are set as follows: `max_features=15000`, the number of input channels is 32, the number of convolutional filters is 7, and the activation function is ReLU."}, {"title": "3. LSTM Model", "content": "Long Short-Term Memory networks (LSTMs) are a specialized type of Recurrent Neural Network (RNN) capable of learning long-term dependencies. By incorporating a complex internal structure with multiple gating mechanisms, LSTMs effectively regulate the flow of information, allowing the network to retain long-term memories when necessary and discard irrelevant information when it is no longer needed. In this study, the LSTM module provided by TensorFlow is employed directly. The parameters for the LSTM model are set as follows: `input_dim=5000', `output_dim=150`, `input_length=150`, and the hidden layer size of the LSTM layer is 128."}, {"title": "4. TextCNN Model", "content": "TextCNN is a convolutional neural network model specifically designed for text classification, improving upon standard CNN architectures by modifying the convolutional layers. TextCNN employs convolutional layers with filters of varying sizes, where each filter is responsible for extracting specific n-gram features. Different-sized filters (e.g., 1-gram, 2-gram, 3-gram) capture contextual information of varying lengths. The parameters for the TextCNN model in this study include three 1D convolutional layers, each with filter sizes of 3, 4, and 5, and a channel size of 256."}, {"title": "5. BERT Model", "content": "BERT excels in emotion detectiondue to its robust contextual understanding and flexible training strategies, making it highly effective for emotion detection tasks [41]. It processes both left and right contexts in sentences, allowing the model to comprehend word meanings and contexts more accurately. This bidirectional processing is crucial for emotion detection, as words may carry different emotions based on contextual variations. We implement fine-tuning of the BERT-base-cased pre-trained model for text classification tasks in our study."}, {"title": "4.3 Experimental Environment and Rules", "content": "The experimental platform and key parameters for this study are as follows:\nGPU: NVIDIA GeForce RTX 3090 GPU;\nBERT Model Runtime\ncudnn=8.9.7.29;\nEnvironment:python=3.7, pytorch=1.9.0, cudatoolkit=11.3.1,\nOther Models Runtime Environment: python=3.8, tensorflow==2.6.0, cudatoolkit=11.3.1,\ncudnn=8.2.1;\nParameter Settings: The text length or sequence length is uniformly set to 150 for all models. For text input, except for BERT, TensorFlow's Tokenizer and sequence representations are consistently utilized. The text input for BERT employs a summation of three types of embeddings (Token, Segment, Position) to generate the final input representation for each word.\nRules: To ensure consistency with the operational workflow of the five comparative models, the CoEQN framework is employed for validation in this section. For the same model, in the comparative experiments of \"using\" versus \"not using\" the CoEQN framework, the fundamental structure, parameter settings, training set, and test set samples remain unchanged. In the experiments where the CoEQN framework is utilized, only the input and output portions are modified accordingly, while the parameters follow those detailed in Section 4.2. The labels of the training set are mapped to full labels and initialized with energy level values, while the output for the test set generates full label energy scores. Classification is performed based on the full label energy scores of the test set using either MAX() (for single-label classification) or a predetermined threshold (for multi-label classification), with results compared to those obtained from conventional model methods on the same test set."}, {"title": "4.4 Results and discussion", "content": ""}, {"title": "4.4.1 Comparison of Test Results", "content": "In this section, we present a detailed comparison of the results obtained from the different classification models-specifically focusing on single-label, multi-label, and EQN full label mapping (EQN) approaches. Based on the aforementioned rules, the testing results for five datasets and five models utilizing conventional single-label and multi-label classification methods, as well as the EQN full-label approach, are presented in Table 3."}, {"title": "5 Application: Annotation of the GoEmotions Dataset Based on the EQN", "content": "GoEmotions is a fine-grained, multi-label emotion dataset characterized by a substantial manual annotation workload and significant classification challenges, providing valuable support for emotion detection. However, the labeling may be insufficient. To further evaluate the EQN framework's capability in capturing subtle emotions, we aim to supplement the annotation of the 28 categories within the GoEmotions dataset.\nUtilizing the BERT model, we employ both the CoEQN framework and the EQN approach for automated annotation of the GoEmotions dataset. The analysis encompasses statistical evaluations of the annotation results, calculations of assessment metrics, and the generation of a Pearson correlation coefficient heatmap, which will be compared against the findings published in Google's dataset literature[13]."}, {"title": "5.1 GoEmotionsdata distribution", "content": "The distribution of sample labels in the training and testing sets of the GoEmotions dataset is illustrated in Figure 3. The training set comprises 43,410 samples across 28 categories, with the distribution of sample labels as follows: 36,308 samples are single-label, accounting for 84% of the total, while there are 28 samples with four labels and 1 sample with five labels. The 1 GoEmotions testing set contains 5,427 entries, with a maximum of 4 labels per entry. It includes 4,590 single-label samples, 774 samples with two labels, 61 samples with three labels, and 2 samples with four labels."}, {"title": "5.2 CoEQN and EQN Annotated Datasets and Comparative Experiments", "content": "Section 3.2 details the detection experiments conducted on the GoEmotions dataset utilizing the CoEQN framework. This section presents the results of the comprehensive experiments based on the EQN framework, which also employs the basic BERT model with standard parameter settings, focusing on the automatic supplementary annotation of the Go"}]}