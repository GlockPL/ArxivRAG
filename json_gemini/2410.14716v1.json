{"title": "A Systematic Survey on Large Language Models for Algorithm Design", "authors": ["FEI LIU", "YIMING YAO", "PING GUO", "ZHIYUAN YANG", "XI LIN", "XIALIANG TONG", "MINGXUAN YUAN", "ZHICHAO LU", "ZHENKUN WANG", "QINGFU ZHANG"], "abstract": "Algorithm Design (AD) is crucial for effective problem-solving across various domains. The advent of Large Language Models (LLMs) has notably enhanced the automation and innovation within this field, offering new perspectives and superior solutions. Over the past three years, the integration of LLMs into AD (LLM4AD) has progressed significantly, finding applications in diverse areas such as optimization, machine learning, mathematical reasoning, and scientific exploration. Given the rapid development and broadening scope of this field, a systematic review is both timely and essential. This paper provides a systematic review of the works on LLM4AD. First, we present an overview and summary of existing studies. Then, we present a systematic categorization, and a review of existing works along four dimensions including the role of LLMs, search techniques, prompt strategies, and application fields. We also discuss the achievements and challenges in each area and the capabilities of LLM4AD in addressing them. Finally, we explore current limitations and propose several open questions and promising directions for future research.", "sections": [{"title": "1 Introduction", "content": "Algorithms play a crucial role in addressing a myriad of problems across diverse fields, including industry, economics, healthcare, and technology [32, 82]. The traditional hand-crafted approach to algorithm design requires extensive expert knowledge and considerable effort, which is tedious and time-consuming. There has been a growing interest in the integration of learning and computational intelligence techniques to streamline and enhance the algorithm development process [12, 154]."}, {"title": "2 Methodology and Taxonomy", "content": "This paper aims to conduct a systematic survey and classification of existing research works in the emerging field of Large Language Model for Algorithm Design (LLM4AD). We further delineate the scope of our survey as follows:\n\u2022 We do not intend to cover all literature on LLMs and algorithms. Specifically, we exclude works focused on other branches, such as algorithms for optimizing LLMs, including prompt engineering algorithms [141] and algorithms for training LLMs [1].\n\u2022 The term Large Language Models refers to language models of sufficient scale to enable robust zero-shot performance across various tasks, including linguistic comprehension, code generation, and mathematical reasoning. These models typically utilize a transformer architecture and operate in an autoregressive manner [204].\nStudies employing smaller models for algorithm design, such as those prevalent in conventional model-based algorithms and machine learning-assisted algorithms [12], are excluded. While it is challenging to precisely define \"large\" models, most leading-edge LLMs contain over one billion parameters [119, 204].\nResearch utilizing other large models that lack language processing capabilities, such as purely vision-based models, are not considered. However, multi-modal LLMs that include language processing are within our scope.\n\u2022 The term Algorithm in this context refers to a set of mathematical instructions or rules designed to solve a problem, particularly when executed by a computer [32]. This broad definition encompasses traditional mathematical algorithms [5], most heuristic approaches [113, 117], and certain agents or policies that can be interpreted as algorithms [179]."}, {"title": "2.2 Statistics", "content": "We introduce the detailed pipeline for paper collection and scanning, which consists of four stages:\n\u2022 Stage I Data extraction and collection: We collect the related papers through Google Scholar, Web of Science, and Scopus. The logic of our search is the title must include any combinations of at least one of the following two groups of words \"LLM\u201d, \u201cLLMs\u201d, \u201cLarge Language Model\", \"Large Language Models\" and \"Algorithm\", \"Heuristic\", \"Search\", \"Optimization\", \"Optimizer\", \"Design\", \"Function\" (e.g., LLM and optimization, LLMs and algorithm). As a fast-growing research field, the majority of papers on LLM4AD are published online as pre-print manuscripts such as in Arxiv, which results in a"}, {"title": "2.3 Overview", "content": "Fig. 2a illustrates the trend in the number of papers published over time, with the timeline expressed in months. The graph shows a marked rise in research activity related to LLM4AD, particularly noting that most of the studies have been conducted in the last year. This suggests that LLM4AD is an emerging field, and we expect a significant increase in research output in the near future as scholars from diverse fields become aware of its considerable potential. It is worth noting that as a rapidly expanding field, the majority of works are initially published as preprints on Arxiv. Many of these have subsequently been accepted by top conferences such as ICML and NeurIPS.\nFig. 2c and Fig. 2b display the leading institutions and their respective countries contributing to publications on LLM4AD. The United States leads, closely followed by China, with these two countries alone accounting for 50% of the publications. The next eight countries, including Singapore, Canada, and"}, {"title": "2.4 Taxonomy", "content": "Research in the field of LLM4AD primarily explores three fundamental components: 1) LLMs, 2) algorithms, and 3) applications. Studies within LLM4AD are categorized based on the variations and interactions of these elements. This paper presents a taxonomy organized into four dimensions: 1) LLM Roles, 2) Search Methods, 3) Prompt Methods, and 4) Applications.\n\u2022 LLM Roles: This dimension examines how LLMs are integrated into algorithm development, dividing the workds into four categories: LLMs as Optimizers (LLMaO), LLMs as Predictors (LLMaP), LLMs as Extractors (LLMaE), and LLMs as Designers (LLMaD).\n\u2022 Search Methods: This category involves the search methods used. It includes a variety of search strategies, from the basic and widely utilized random search methods to more complex approaches like single-point-based, population-based, and uncertainty-guided methods.\n\u2022 Prompt Methods: The effectiveness of pre-trained LLMs is heavily influenced by prompt engineering. We investigate the typical prompt strategies used in LLM4AD including zero-shot, few-shot, chain-of-thought, self-consistency, and reflection prompts.\n\u2022 Applications: The broad application of LLM4AD covers diverse fields. We identify the main domains including optimization, machine learning, industry, and scientific discovery."}, {"title": "3 LLM Roles", "content": null}, {"title": "3.1 LLMs as Optimizers (LLMaO)", "content": "In LLMaO, LLMs are utilized as a black-box optimizer within an optimization algorithm to generate and refine solutions (Fig. 5). This innovative use of LLMs extends beyond their traditional applications in natural language processing to more complex problem-solving tasks that involve searching and optimization. The process typically involves employing the LLM in an iterative search framework, where the model actively participates in proposing potential solutions based on feedback received at each step. The integration of LLMs into optimization tasks leverages their ability to understand and generate complex patterns and solutions, which might be infeasible with traditional optimization methods alone."}, {"title": "3.2 LLMs as Predictors (LLMaP)", "content": "LLMaP employs LLMs as surrogate models, which serve as stand-ins for more complex or computationally expensive models. As illustrated in Fig. 6, these LLMs are utilized to predict the outcomes or responses, functioning either in a classification or regression context [64]. In classification tasks, the LLMaP approach involves the LLM predicting categorical labels or classes based on input data. On the other hand, in regression tasks, the LLM predicts continuous outputs rather than categories. Compared to other model-based predictors, such as the Gaussian process and conventional neural networks, 1) LLMs are capable of processing and generating human-like responses based on the training they have received on vast datasets. This capability allows them to understand and interpret complex patterns in data, making them suitable for tasks where traditional modeling techniques might struggle due to the intricacies or subtleties in the data [43]. 2) Pre-trained LLMs can significantly reduce the computational load and time required compared to training high-fidelity models [64, 79].\nThe majority of LLMaP works use LLMs as regression models to predict solution scores. For instance, LLMs have been used as performance predictors for deep neural network architectures by Jawahar et al. [79]. It offers a cost-effective alternative for performance estimation in neural architecture search. Zhang et al. [201] introduce LINVIT, an algorithm that incorporates guidance from LLMs as a regularization"}, {"title": "3.3 LLMs as Extractors (LLME)", "content": "LLMaE employs LLMs to mine and extract embedded features or specific knowledge from target problems and/or algorithms, which are then strategically utilized in the enhancement of algorithm-based problem solving (Fig 7). This process leverages the advanced natural language understanding capabilities of LLMs, allowing them to discern subtle patterns and relationships within the data that might not be evident through conventional analytical methods [178]. By integrating these insights into algorithm design, developers can create more precise and efficient solutions tailored to specific needs.\nLLMs have demonstrated exceptional capabilities in feature extraction across various domains for algorithm design, surpassing traditional heuristics and conventional deep learning models. For instance, Kristiadi et al. [83] explore the use of LLMs in accelerating principled Bayesian optimization in the molecular space. LLMs are used as fixed feature extractors for standard Bayesian optimization surrogate models, and parameter-efficient finetuning methods are leveraged to obtain the posterior of the LLM surrogate. The experiments show that LLMs can be useful for Bayesian optimization over molecules, but only if they have been trained or finetuned with domain-specific data."}, {"title": "3.4 LLMs as Designers (LLMaD)", "content": "LLMaD directly creates algorithms or specific components (Fig. 8). This utilization of LLMs extends their application beyond traditional boundaries, enabling them to actively participate in algorithm development by generating heuristics, writing code snippets, or formulating functions that can be integrated into larger systems. By doing so, LLMs can significantly accelerate the algorithm design process, reduce human effort, and bring creativity and optimization to algorithm development, which is difficult to achieve through conventional methods alone."}, {"title": "4 Search Methods", "content": "In this section, we investigate two branches of the interaction of LLMs with search methods: 1) search methods are designed algorithms and 2) search methods are LLM-based searching frameworks for algorithm design. In the first category, search methods are the target of LLMs, examples including LLMs for evolutionary algorithms and Bayesian optimization. In the other category, LLMs are used in the search methods to be iteratively queried to design better algorithms. This section categorizes the works according to the type of search methods without distinguishing the two branches."}, {"title": "4.1 Sampling", "content": "The most straightforward search manner is by repeatedly instructing LLM to sample new designs [209]. The best sample is selected as the final design. However, recent studies have shown that simple sampling from LLMs is insufficient in algorithm design [199]."}, {"title": "4.1.1 Beam Search", "content": "Beam search explores a limited set of promising paths, or \"beams\", in the search space rather than only one. Beam search has been widely used in diverse domains. For example, LLM-based prompt engineering [107, 134, 209] leads to promising results, e.g., [209] demonstrates cases where when the beam search size increases from 4 to 128, the performance beats the human expert.\nExcept for prompt engineering, Lin et al. [94] introduce Text2Motion, a language-based planning framework that enables robots to execute complex sequential manipulation tasks. It adopts beam search over tokens and enhances task planning with LLMs using feasibility heuristics. In contrast, Hazra et al. [65] adopt beam search over actions. It introduces \"SayCanPay\" to integrate the world knowledge of LLMs with heuristic planning principles to produce grounded and efficient action sequences, demonstrating superior performance in extensive evaluations compared to other LLM planning methods. Moreover, Park et al. [131] use beam search with lexical information from LLMs for enhancing speech-processing tasks and Wei et al. [172] propose"}, {"title": "4.1.2 MCTS", "content": "MCTS is a tree search algorithm that uses random sampling to build a search tree and make decisions based on the results of these samples. It is particularly effective in problems with large and complex search spaces. For example, Dainese et al. [35] propose GIF-MCTS, a code generation strategy with Generate, Improve and Fix using MCTS, which outperforms baselines on the Code World Models Benchmark and other benchmarks. In GIF-MCTS, nodes in the tree are programs and edges are actions. Each action taken from a parent node produces a new complete program, which is split into a \"state\" part and a \"rollout\" part, and stored in a child node. The upper confidence bound for trees is used to select which action to take. Similarly, VerMCTS [19] constructs a search tree with progressive widening to effectively manage large action spaces defined by lines of code. In this search tree, expansion and evaluation are guided by the verifier, serving as a computationally inexpensive upper bound on the value function in the code synthesis MDP. Moreover, Wang et al. [168] regard prompt optimization as a strategic planning challenge, utilizing a principled planning algorithm based on MCTS to effectively explore the expert-level prompt space. Drawing inspiration from human trial-and-error learning, the proposed PromptAgent generates precise insights and detailed instructions by analyzing model errors and providing constructive feedback."}, {"title": "4.2 Single-point-based Search", "content": null}, {"title": "4.2.1 Hillclimb", "content": "Hillclimb search iteratively searches for better results, where the new one is generated based on the last one and the better one is survived. A basic version of Hillclimb is investigated in paper by Zhang et al. [199] for algorithm design. It achieves competitive results when compared to population-based evolutionary algorithms. The reasoning over the existing status is usually adopted to enhance each search step. For example, Li et al. [90] leverage LLMs to automatically design dense reward functions for reinforcement learning agents in environments with sparse rewards, termed Auto MC-Reward, which iteratively refines the reward function based on feedback from the agent's interactions with the environment and Yang et al. [185] develop a multi-module framework with innovative feedback mechanisms, demonstrating through both LLM-based and expert evaluations that LLMs can effectively produce scientific hypotheses that are both novel and reflective of reality."}, {"title": "4.2.2 Neighborhood Search", "content": "Neighborhood search methods are optimization techniques that explore the solution space by iteratively modifying a current solution to find an improved one in a structured neighborhood. Notably, the LLM-GS framework [99] has introduced a scheduled hill climbing algorithm that leverages two distinct strategies: 1) Programmatic Neighborhood Generation, which involves generating a neighborhood of programs by selecting a node from the Abstract Syntax Tree (AST) of a given program and substituting it with a subtree that is randomly generated in accordance with the production rules and sampling strategies of a Domain-Specific Language (DSL); and 2) Latent Space Representation, where the neighborhood is defined in a latent space by training a variational autoencoder on a corpus of randomly generated DSL programs, thereby creating a more abstract and potentially more informative neighborhood structure. Additionally, Jin et al. [81] contribute to this line of research by defining neighborhood algorithms based on a minimum cosine similarity threshold of 60% between the embeddings of a query vector and code snippets, enhancing"}, {"title": "4.2.3 Gradient-based Search", "content": "Gradient-based search leverages a (pseudo) gradient direction in the generation of the new design in each iteration. Unlike searching in continuous space with an explicit differentiable objective formulation, calculating the gradient in the text and code space is challenging. As a result, an estimated descent direction is used as a pseudo gradient in the text and code space.\nPryzant et al. [134] introduce automatic prompt optimization, which improves prompts automatically by adjusting them based on natural language \"gradients\" derived from training data. This approach has led to a substantial improvement in LLM performance on various NLP tasks and jailbreak detection by up to 31%. Moreover, Nie et al. [126] explore the use of LLMs as interactive optimizers for solving maximization problems in a text space through natural language and numerical feedback. LLMs exhibit effectiveness when provided with directional feedback, which is an extension of first-order feedback in the natural language domain. Furthermore, Tang et al. [155] introduce a novel Gradient-inspired LLM-based Prompt Optimizer (GPO) that draws parallels with gradient-based model optimizers. By incorporating updated direction and method concepts from gradient-based optimization, GPO enhances prompt optimization strategies, leading to significant performance enhancements in experimental assessments. This integration of LLMs with gradient-based search methods showcases the potential for improving prompt optimization and overall LLM performance.\nFor an accurate gradient, Guo et al. [59] perform the gradient-based search in a mapped continuous space and proposes a collaborative optimization strategy that combines a gradient-based optimizer with an LLM for tackling complex non-convex optimization challenges. The LLM is utilized to derive solutions from natural language instructions, while the gradient-based optimizer performs locally optimal updates at each iteration. This collaborative approach leverages the strengths of both optimizers, with the inferred results from LLMs serving as starting points for subsequent stages of gradient optimization."}, {"title": "4.2.4 Reinforcement Learning", "content": "Reinforcement learning learns to make decisions by interacting with an environment to maximize cumulative rewards. Recent works have explored innovative applications and enhancements of this method. For instance, GPTswarm [211] and the work by Duan et al. [42] leverage LLMs and reinforcement learning techniques to optimize code, reducing complexity and enhancing efficiency. Similarly, Liu et al. [99] present a novel LLM-guided search framework (LLM-GS) aimed at addressing the sample inefficiency in state-of-the-art programmatic reinforcement learning methods by utilizing the programming expertise of LLMs to boost search efficiency.\nAdditionally, LLMs have been utilized in the design of reinforcement learning systems, particularly in the creation of reward-shaping functions. Bhambri et al. [14] tackle the issue of sample inefficiency by proposing a framework called MEDIC, which uses LLMs to generate a guide policy for constructing reward-shaping functions. This framework shows substantial improvements in sample complexity for RL agents across various domains in the BabyAI environment."}, {"title": "4.3 Population-based Search", "content": "Evolutionary search is the main tool investigated due to its effectiveness and robustness in complex search space [128, 177]. According to the number of objectives, it can be roughly categorized into single-objective evolutionary search and multi-objective evolutionary search."}, {"title": "4.3.1 Single-objective Evolutionary Search", "content": "Evolutionary algorithms are the major solutions when integrating LLM for algorithm design [98, 139]. Through maintaining a population of diverse individuals, they usually search the space effectively.\nThe study by Yang et al. [185] represents an initial exploration of utilizing LLMs as optimizers for algorithm design. It suggests leveraging the in-context learning capability of LLMs to generate new solutions for target problems based on existing evaluated solutions. Although it does not explicitly mention evolutionary search, the search paradigm behind it can be regarded as a population-based evolutionary search. Liu et al. [96] introduce LLMs as evolutionary operators for addressing multi-objective problems by decomposing them into single-objective sub-problems and employing LLMs as black-box search operators for each sub-problem. This decomposition-based approach enables LLMs to tackle multi-objective problems indirectly, overcoming their inherent challenges in comprehending such problems. Additionally, Liu et al. [100] explore the use of LLMs as evolutionary operators in conventional EA, guiding them in solution selection, crossover, and mutation processes. Moreover, Brahmachary et al. [18] propose a population-based evolutionary framework comprising exploration and exploitation pools, with LLMs facilitating solution generation for both pools and enabling communication between them during optimization. Lange et al. [84] investigate the application of LLMs in designing evolution strategies, introducing a prompting strategy to enhance mean statistic performance.\nIn contrast to the integration of LLM to generate hard-coded solutions, the effective evolutionary search of prompt and code generation poses challenges due to the lack of suitable diversity measurement, selection, and population management methods on the complex search space. The majority of workers adopt a greedy way [26, 57, 90, 98, 123, 161, 187]. In these works, a population of individuals is maintained and only the ones with better fitness will survive. Romera-Paredes et al. [139] adopt a multi-island evolutionary algorithm to explore a diverse population with a dynamically adjusted population size. Moreover, Wong et al. [174] explore the potential of leveraging generative artificial intelligence models to create digital artifacts for creative and engineering applications, utilizing an multi-factorial evolutionary algorithm to drive an LLM. The proposed LLM2FEA approach demonstrates the ability to generate novel and practical designs, as evidenced by experimental results in the context of 3D aerodynamic design.\nTo enable effective diversity control over the population, Lehman et al. [85] and Hu et al. [71] have investigated quality diversity methods [135]. Specifically, they utilize the MAP-Elites algorithm with a grid of niches to generate diverse and high-quality solutions. A pre-existing solution is evaluated and placed into the map, with subsequent iterations perturbing solutions within inhabited niches. New candidate solutions are evaluated and assigned niches based on behavior characterization, becoming champions if they outperform current inhabitants or fill unfilled niches. This process gradually fills the map with improved solutions over time."}, {"title": "4.3.2 Multi-objective Evolutionary Search", "content": "Liu et al. [96] propose MOEA/D-LMO to use LLM to solve continuous multi-objective optimization problems. Benefiting from the decomposition-based framework, the"}, {"title": "4.4 Uncertainty-guided Search", "content": "Uncertainty-guided search harnesses the advantages of BOED and BO frameworks within the search process incorporating LLMs. It first establishes a prior that describes the initial belief about the parameters of interest and then utilizes uncertainty-driven strategies over the derived posterior to iteratively update the belief, ultimately achieving efficient decision-making during the search process in a sample-efficient manner.\nThis search paradigm with uncertainty has demonstrated its superiority in some scenarios. For example, in tasks of eliciting human preferences information using LLMs [89, 132], Handa et al. [62] introduce OPEN that takes advantage of LLMs and Bayesian Optimal Experiment Design (BOED). Specifically, LLMs are utilized to extract environment-relevant features and translate abstract feature queries into natural language questions to interact with users through conversations, BOED is employed to identify the most informative query for efficiently learning preference information. Experimental studies have demonstrated the superiority of the OPEN approach in content recommendation tasks when compared to both LLM- and BOED-based preference elicitation methods. To improve the multi-turn and decision-theoretic reasoning capability over a set of arbitrary items, Austin et al. [9] formulate the natural language-based preference elicitation within a Bayesian optimization framework. The proposed PEBOL algorithm maintains a probabilistic prior over user preferences in the form of Beta distributions. The generation of queries is facilitated by LLM-based acquisition functions incorporating strategies like Thompson Sampling and Upper Confidence Bound, which aim to learn user preferences efficiently balancing exploration and exploitation. In the domain of LLM decoding, Grosse et al. [55] propose a probabilistic model named ULTS. This method frames the decoding process as a tree-search problem and identifies an optimal path in the LLM search tree by sequential decision-making under uncertainty. It firstly establishes a prior belief on the softmax outputs of the LLM and then utilizes the implied posterior samples to guide the search process in a non-myopic fashion.\nAmong these search methods mentioned in this section, evolutionary algorithms (EAs) are the most used search methods in LLM-based algorithm design [23], Table 1 summarizes and compares different EA-based methods in terms of their algorithmic components, i.e., prompt strategy, search strategy, and population management. For prompt strategy, we identify One-Shot prompting (OS), Few-Shot prompting (FS) [20], Chain-of-Thought (CoT) [173], and Reflection (RF) [20]. For search methods, we identify Genetic Algorithm (GA), Differential Evolution (DE), Evolutionary Strategy (ES), Multi-objective Evolutionary Algorithm (MOEA) and others. The results reveal that: 1) FS and CoT are the most commonly used prompt engineering strategies. 2) The majority of works use a simple genetic algorithm with greedy population management. 3) LLMaO and LLMaD are more commonly investigated than the other two categories."}, {"title": "5 Prompt Strategies", "content": "Fig. 9a depicts the percentage of domain or pre-trained LLMs used in the literature. Among them, over 80% chose to use the pre-trained model without any specific finetuning, and about 10% fine-tuned the pre-trained model on domain datasets [33] in which 4.4% are trained from scratch. Fig. 9c illustrates the top-used LLMs. LLM4AD papers show a strong preference for GPT models. GPT-4 and GPT-3.5 are the most-used LLMs, which in total take around 50%. Llama-2 are the most used open-source LLM. The development of an effective domain LLMs poses challenges to most algorithm designers. We will provide more discussions in the future work section.\nOnce we have the pre-trained LLMs, prompt engineering is significant for effectively integrating LLMs in algorithm design. We introduce the main prompt engineering methods including zero-shot, few-shot, chain-of-thought, self-consistency, and reflection [141] used in LLM4AD papers. Fig. 9b shows the number of papers involving different prompt engineering techniques. Few-shot, zero-shot, and chain-of-thought are the most commonly used ones. Many works involve more than one prompt engineering technique."}, {"title": "5.1 Zero-Shot", "content": "Zero-Shot (ZS) learning enables a model to comprehend and perform tasks without prior specific training on those tasks. In algorithm design, zero-shot prompting allows direct requests to the LLM for solutions or responses, examples including conversational replies [143], assertion design [118], reinforcement learning guidance [201], and molecule generation [189]. The model leverages its pre-trained knowledge to generate these responses. Although this method is advantageous for swiftly producing solutions based on general"}, {"title": "5.2 Few-Shot", "content": "Few-Shot (FS) learning involves providing the model with a handful of examples to illustrate the task before it attempts to solve a similar problem. This approach enhances the model's understanding of the context and its ability to tailor responses to specific tasks. In algorithm design, this method proves particularly"}, {"title": "5.3 Chain-of-Thought", "content": "Chain-of-Thought (CoT) prompting encourages the model to articulate intermediate steps or reasoning paths that lead to the final answer. This technique is particularly valuable in algorithm design, where understanding the step-by-step process or engaging in instructed reasoning over existing designs helps prevent outlier results and fosters effective algorithm development. For instance, Liu et al. [98] introduce several prompting strategies, one of which directs the LLM to reason over existing heuristics, summarize the general pipeline, and design a new one based on this reasoning. Custode et al. [34] prompt the LLM to evaluate whether the current step size is sufficient for convergence and to suggest adjustments based on its reasoning. In addition, multiple LLM-based agents are employed within a CoT framework by Sun et al. [152] to enhance heuristic design for a boolean satisfiability problem solver."}, {"title": "5.4 Self-consistency", "content": "Self-consistency involves generating multiple answers or solutions to the same prompt and then synthesizing them to improve accuracy and reliability. In algorithm design, this could mean prompting the model multiple times for different approaches to solve a problem and then comparing these solutions to identify the most efficient or robust algorithm. This approach leverages the model's ability to generate diverse solutions and builds a more comprehensive understanding of possible strategies. For example, Guan et al. [56] set the number of responses as 10 and uses the majority vote to get the predicted label. As each response may provide different keywords or regular expressions, it takes the union of the keywords or regular expressions to create a candidate set. Moreover, Lehman et al. [86] sample multiple revised codes from the same selected code and updates the population accordingly."}, {"title": "5.5 Reflection", "content": "Reflection in prompt engineering involves asking the model to critique or evaluate its own responses or solutions. After generating an algorithm, the model can be prompted to reflect on the efficiency, potential flaws, or improvements. This not only helps in refining the algorithm but also in understanding deeper nuances, such as space-time trade-offs, which are crucial for advanced algorithm design. Ma et al. [107] investigate both implicit and explicit reflection in LLM-driven prompt optimization, which lets LLM analyze the errors and generate a reflection or feedback regarding the current prompt. An additional study by Ye et al. [191] incorporates short-term and long-term reflections in heuristic design, while Zhang et al. [196] focus on self-evaluation and reasoning over results from network detection. Furthermore, both Ma et al. [108] and Narin [123] adopt LLM for RL reward function design with a reward reflection that monitors the scalar values of all reward components and the task fitness function at various policy checkpoints during training."}, {"title": "6 Applications", "content": null}, {"title": "6.1 Optimization", "content": "In this subsection, we focus on discussing the practical applications of LLM in algorithm design for optimization. We categorize the existing literature into combinatorial optimization, continuous optimization, Bayesian optimization, prompt optimization, and optimization modeling based on the specific types of optimization tasks. We then proceed to compare the various roles played by LLMs, the prompt strategies utilized, and the specific problems or tasks to which they are applied. This comparative analysis is summarized in Table 2, where we list the names of the frameworks or methods proposed by the authors. For studies that do not explicitly name their methods, we assign appropriate designations in our article and denote them with asterisks for easy reference (e.g., MH-LLM* for [142])."}, {"title": "6.1.1 Combinatorial Optimization", "content": "In the domain of Combinatorial Optimization (CO), the design of effective algorithm heuristics has been a significant area of interest for a long time. The emergence of LLMs has now provided new avenues for automatically generating CO algorithms for diverse application tasks.\nThe Traveling Salesman Problem (TSP) stands out as one of the most renowned combinatorial optimization challenges, involving the quest for the shortest route to visit all specified locations exactly once and return to the starting point. Given its NP-hard nature, heuristic algorithms are commonly employed to tackle this problem. Some recent work leverages LLMs to evolve algorithms within Evolutionary Computation (EC) framework, such as AEL [97], ReEvo [192] and EoH [98]. Differently, OPRO [183] employs LLMs as optimizers with a proposed meta-prompt, in which the solution-score pairs with task descriptions are added in each optimization step. Additionally, LMEA [101] investigates the utilization of LLMs as evolutionary combinatorial optimizers for generating offspring solutions, wherein a self-adaptation mechanism is introduced to balance exploration and exploitation. The Capacitated Vehicle Routing Problem (CVRP) extends the TSP by introducing constraints related to vehicle capacity. To address this challenge, MLLM [76] devises a multi-modal LLM-based framework with textual and visual inputs to enhance optimization performance.\nIn addition to routing problems, the Bin Packing Problem (BPP) is another well-studied problem with diverse applications. The objective of the BPP is to pack items of varying sizes into the smallest number of fixed-sized bins. FunSearch [139] utilizes an evolutionary approach to evolve heuristics for the BPP. The study showcases that FunSearch is capable of uncovering enhanced heuristics when compared to traditional strategies such as first fit and best fit in addressing the challenges posed by the BPP. In comparison to FunSearch, EoH [98] designs heuristics that not only achieve competitive performance but also demonstrate superior generalization across various problem sizes and capacities, requiring significantly fewer queries. Furthermore, in addition to the previously discussed research, numerous important combinatorial optimization problems have been extensively studied to validate the effectiveness of their proposed methods. Examples include the cap set problem in FunSearch [139], Flow Job Shop Scheduling Problem (FSSP) in EoH [98], and social networks problem in MH-LLM* [142]."}, {"title": "6.1.2 Continuous Optimization", "content": "Here we delve into works that deal with optimization problems featuring continuous design variables, encompassing both single- and multi-objective optimization. Specific tasks or benchmarks include synthetic functions as well as real-world applications."}, {"title": "6.1.3 Bayesian Optimization", "content": "Bayesian optimization (BO) is a model-based optimization paradigm for solving expensive optimization problems and has found wide application in various real-world scenarios [51]. It typically employs a surrogate model to approximate the expensive function and well-designed Acquisition Functions (AFs) to select potential solutions in a sample-efficient manner. To facilitate the direct generation of solutions using LLMs, HPO-LLM* [197] provides LLMs with an initial set of instructions that outlines the specific dataset, model, and hyperparameters to propose recommended hyperparameters for evaluation in Hyperparameter Optimization (HPO) tasks. This approach has demonstrated comparably or better performance when compared with random search and Bayesian optimization on HPOBench dataset [44]. Furthermore, LLAMBO incorporates LLM capabilities to enhance the efficiency of model-based BO, in which three specific enhancements throughout the BO pipeline including zero-shot warmstarting, surrogate models and candidate point sampler, as well as the end-to-end performance have been systematically investigated, the evaluated tasks are selected from Bayesmark [159] and HPOBench [44]. Instead of utilizing LLM for"}, {"title": "6.1.4 Prompt Optimization", "content": "Prompt optimization aims to identify the most effective task prompt that maximizes the performance of the LLM on a specific task dataset. Previous studies have primarily focused on discrete optimization for natural language prompts [37, 133, 181, 202", "93": ".", "208": "utilizes LLM as an inference model to generate instruction candidates directly based on a small set of demonstrations in the form of input-output pairs. This approach has demonstrated human-level performance on various tasks, including Instruction Induction [68", "153": ".", "183": "enables the LLM as an optimizer to gradually generate new prompts based on the full optimization trajectory, the optimizer prompt showcases significant improvement compared with human-designed prompts on GSM8K [31"}]}