{"title": "Towards Speaker Identification with Minimal Dataset and Constrained Resources using 1D-Convolution Neural Network", "authors": ["Irfan Nafiz Shahan", "Pulok Ahmed A\u03c5\u03bd\u03b9"], "abstract": "Voice recognition and speaker identification are vital for applications in security and personal assistants. This paper presents a lightweight 1D-Convolutional Neural Network (1D-CNN) designed to perform speaker identification on minimal datasets. Our approach achieves a validation accuracy of 97.87%, leveraging data augmentation techniques to handle background noise and limited training samples. Future improvements include testing on larger datasets and integrating transfer learning methods to enhance generalizability. We provide all code, the custom dataset, and the trained models to facilitate reproducibility. These resources are available on our GitHub repository: https://github.com/IrfanNafiz/RecMe.", "sections": [{"title": "1. Introduction", "content": "Speaker identification (SI) is the task of recognizing the identity of someone based on the speaker's speech signal. It is an important bio-feature recognition method that has many applications in security, forensics, and biometrics. One of the challenges of speaker identification is to extract robust and discriminative features from speech signals that can capture the speaker-specific characteristics. Recently, deep neural networks (DNNs) have been widely used for speaker identification, as they can learn high-level representations from raw or low-level features. In this paragraph, we will briefly review some of the current works in speaker identification using DNNs.\nIn a society reliant on voice interactions, accurately recognizing individuals through their unique vocal patterns has become a pressing need. Our project focuses on developing an innovative SI system that leverages DNNs to differentiate between speakers.\nDespite recent advances in deep learning for speaker identification, the challenge of working with small, domain-specific datasets persists. Pretrained models like wav2vec and x-vectors have demonstrated success in this domain, but their computational complexity limits applicability in resource-constrained environments. We utilize a 1-Dimensional Convolutional Neural Network (1d-ConvNet) architecture, tailored to process voice data efficiently and effectively even in the face of small datasets and resource constraints."}, {"title": "2. Literature Review", "content": "One of the popular DNN models for speaker identification is based on convolutional neural networks (CNNs), which can exploit the spatial features of voiceprints (corresponding to the voice spectrum) from spectrograms or mel-filterbank energy features (MFCCs). For example, [1] proposed a DNN model based on a two-dimensional CNN (2-D CNN) and gated recurrent unit (GRU) for SI. The 2-D CNN layer was used for voiceprint feature extraction and dimensionality reduction, while the stacked GRU layers were used for frame-level feature extraction. The model achieved a high recognition accuracy of 98.96% on the Aishell-1 speech dataset. [2] Recent models like wav2vec and HuBERT utilize self-supervised learning to extract high-level speech features from unlabeled data, enabling transfer learning for downstream tasks like speaker recognition [3,4]. While effective, these models require extensive computational resources and large-scale pretraining datasets.\nAnother popular DNN model for speaker identification is based on recurrent neural networks (RNNs), which can model the temporal dependencies of speech signals. RNNs can be further enhanced by using long short-term memory (LSTM) or GRU cells, which can overcome the vanishing gradient problem and capture long-term dependencies. For example, [5] proposed a DNN model based on LSTM and attention mechanism for speaker identification. The LSTM layer was used to encode the sequential information of speech signals, while the attention layer was used to weight the importance of each frame. The model achieved a recognition accuracy of 97.7% on the VoxCeleb1 dataset. [6]\nA recent trend in speaker identification is to use self-supervised learning methods, which can learn representations from unlabeled data by solving a pretext task. For example, [7] proposed a DNN model based on HuBERT [8], which is a transformer-based model that learns from masked acoustic features. The model was pre-trained on a large-scale unlabeled dataset and fine-tuned on a downstream speaker identification task. The model achieved state-of-the-art results on several benchmarks, such as VoxCeleb1 and VoxCeleb2.\nOur work diverges from these high-resource approaches by focusing on optimizing small datasets with lightweight architectures. This includes incorporating augmentation techniques like noise addition and pitch shifting, commonly seen in resource-constrained setups [9]."}, {"title": "3. Methodology", "content": "The entire program methodology has a few key steps:\n1.  Data Collection\n2.  Data Preprocessing\n3.  Data Organization for Training\n4.  Training the Deep Learning Model\n5.  Application Decision-making"}, {"title": "3.1. Data Collection", "content": "First, we record the voices of the speaker we want the model to recognize. In our program, we recorded almost 1 minute of our team members saying \"Hello DSP 1 2 3 4 5\". The recording"}, {"title": "3.2. Data Preprocessing", "content": "Then, we resample each of the recordings and noises at 16,000Hz (an industry standard) and turn each of the recordings into 1-second clips. This creates about 60 clips for each person's dataset. This process of resampling and clipping is the preprocessing step and is necessary for the Deep Machine Learning Algorithm. A flow chart is shown in Fig.3.\nPreprocesing step involves:\n1.  Resampling at 16KHz because the sampling rate directly correlates to the number of frequency-bins in the Fourier Transform used to train our 1dConvNet DNN Algorithm.\n2.  Clipping the 1 minute file into 60 1-second file provides a greater number of inputs for the ML Model to train on."}, {"title": "3.3. Data Organization for Training", "content": "The recorded and preprocessed samples are then converted to a TensorFlow dataset, which contains a unique key for each user, and also the path to the preprocessed clips. Around 80% of the dataset is used to train the model, knows as the training set, and the remaining 20% will serve as test (or validation) set to monitor the model performances and tune it's hyperparameters. See Fig.4.\nSame is done for the noise clips.\nThe files are then shuffled on their way to the training model so that it can learn to recognize the speaker based on their voice profiles and not by what they were saying. This allows the model to recognize the speaker even when the speaker is saying something other than \"Hello DSP 1 2 3 4 5\" in our case. See Fig.3.\nAlthough this is a naive method, we show that the model works remarkably well even for unknown phrases!\nFurthermore, the preprocessed noise sample is added to the training set and the test set so the model can learn to predict the speaker with an acceptable level of accuracy even with any atmospheric noise present."}, {"title": "3.4. Training the Deep Learning Model", "content": "The Fast Fourier Transform (FFT) coefficients of each set of training and validation, are sent to the model inputs.\nThe training was initiated using TensorFlow GPU on hardware specifications of Nvidia RTX 3060 6GB GPU built on top of an AMD Ryzen-7 5800H 16 Core CPU and 32 GB of RAM.\nAs the deep learning (DL) model trains, it compares itself with the training set and validation set (which it has not seen) according to the \"Sparse Categorical Cross-Entropy\" loss function and gains an estimate of how well it is performing both in the training and validation sets. This provides us with accuracy and loss metrics that are further details in Section.5.\nWe are most concerned about maximizing validation accuracy because that metric tells us how well the model performs on unseen data, in our case, that is the speaker's voice input into the model. Since the DL problem is related to multiple classification, we want to minimize the validation loss values, but it is not our primary concern.\nSparse Categorical Cross Entropy is used because it is an effective loss function for multiple classification DL scenarios, which is true in our case.\nThe goal here is to have a peak level of training and validation accuracy because it signifies that the model has learned to recognize the speakers well. But also the metrics for accuracy and loss should be healthy to ensure that the model indeed converges to a classification solution. Further details are provided in Section.5\nTo ensure that the validation accuracy is maximized, some tuning is performed to determine the model architecture, number of neurons, and also other model hyperparameters. Furthermore to ensure model performance does not fall, we use an early stopping algorithm to stop our training when necessary. Moreover, to ensure proper convergence to the maximum possible validation accuracy is acquired, we use a learning rate scheduler. See Section.4 for more details on model architecture and parameters. A comprehensive flow chart for the training protocol is given in Fig.4.\nOnce the model is fully trained according to the conditions mentioned above, the model parameters are saved as an h5 file, which is then loaded by our application during the speaker prediction process, hence a \"Pretrained model\" is used for prediction, leading to more efficient performance, instead of training again which would be performance and cost intensive. See Fig.5 to observe the use of pretrained model."}, {"title": "3.5. Application Decision-making", "content": "After training the model, we can test how well our model performs by using it to predict the speaker given proper inputs. Prompt the program to take any live voice recording as input. This recorded file is preprocessed again using the previous protocol into 1 sec clips, and each of the 1-second duration clips is fed to the pre-trained model in batches to calculate the probability of this voice belonging to any of the speaker it knows. See Fig.5\nA prediction is made for each 1s audio clip. The speaker that is predicted most for our recorded sample of clips is returned as the final output prediction.\nIf the test sample comes from a person that the model has not trained on, the highest probability of match will be very low. In that case, the model will say it does not recognize the test sample with enough confidence and ask for verification if the user is identified properly, if not, it will prompt the new user to make a new dataset for the new speaker. The model will then retrain itself to be able to classify each of the previous and new speakers it has data on. See Fig.6 for a complete flow chart. Otherwise, the speaker is correctly identified and the application loop continues."}, {"title": "4. 1D-Conv DNN Model - Taking a deeper look", "content": "The machine learning model's core functionality is the use of 1D-Convolutional DNN layers. The comprehensive example used to build upon our model is the Keras Speaker Recognition Example publicly available online [11]. The example was a great starting point, in order to assess the DL problem, and laid a foundation in order to train on smaller, manageable datasets for out application case with high accuracy after tuning and optimizing. The convolutional layers each are integrated into blocks, called \"Residual Blocks\" detailed in Section.4.1.1. The flow chart of the residual block are given in Fig.7.\nThe 4 residual blocks are concatenated according to performance of the model with filter parame-ters sent to them into a residual block series, and their final output is fed to an AveragePooling1D layer. This layer further reduces the dimensions of the output matrix from the residual block series. Afterwards the signal is sent to a series of 3 dense layers after passing through a Flatten layer to reduce the number of dimensions in out output matrix. For each dense layer number of neuron hyperparameters were tuned according to the performance of the model, with the first largest dense layer having a dropout regularization of 0.2, before being passed on the proceeding layers. A detailed flowchart of the model architecture overview is given in Fig.8\nThe final layer is a dense layer with number of neurons equal to the number of classes in our model and a Softmax activation function. Softmax activation is necessary parameter in the final layers of multiple classification DL problems. As the number of speakers increase, so does the size of the final layer. This is done dynamically during our training."}, {"title": "4.1. Model Architecture", "content": ""}, {"title": "4.1.1. Residual Block", "content": "The residual block defined, takes number of filters as arguments and passes them onto each conv1D layer. The number of filters defines how many discrete samples are convoluted together within the kernel of the conv1D layers. The kernel sizes are 3x3 for the main branch and 1x1 for the shortcut branch. Refer to Fig.7.\nThe shortcut branch that takes the 1x1 Conv1D of the input to the residual layer essentially mitigates the vanishing gradient problem often faced in complex DL networks when convolutional layers are involved. vanishing gradient problem is an issue during backpropagation algorithm that takes place during training, where the training parameters are defined by the gradient-descent algorithm to minimize the loss function of the model. This is a common practice in well known DL algorithms such as Residual Networks (ResNet) that perform similar calculation. Although ResNet is infamously taxing and requires significantly more time to train on typical models.\nIn the main path, the input to the block is passed through 2 convolution layers and an activation layer in between.\nThe output of the shortcut path is element-wise added to the output of the main path afterwards which mitigates the vanishing gradient problem mentioned earlier. An activation and MaxPoollD layer is then incorporated to get the outputs from the training performed previously in the block, and sent to the output.\nIn all cases, Rectified Linear Units (ReLu) activation is taken as it is a standard for most DL cases.\nThe residual block is paramount in capturing important features within the FFT of our processed samples that refer to each speaker. This enables the model to train particularly on the speaker voice characteristics rather than background noise, or sequence of words used to create the dataset."}, {"title": "4.1.2. Dense Layers", "content": "The 2 hidden dense layers before the output dense layers are crucial in the classification problem. They capture the necessary speach features extracted by the residual blocks and perform classification. A dropout of 0.2 is used in the first hidden layer which will be further detailed in Section.4.2. The number of neurons in each dense layers, refer to Fig.8, is tuned via trial and error on evaluation metrics that provide the best results, and most healthy accuracy and loss curves detailed in Section.5."}, {"title": "4.2. Model Regularization - Dropout", "content": "We used dropout regularization in order to mitigate the model overfitting on certain characteristics of the person's speech. This 20% dropout is tuned to ensure a maximal validation accuracy and steady convergence of validation loss. Without the presence of dropout, the validation loss curve becomes significantly erratic, and thus will not be able to generalize well on the speaker voice characteristics in the long run. This is detailed in Section.5."}, {"title": "4.3. Early Stopping Scheduler", "content": "It has been shown that training a model too much can have detrimental effects on the validation accuracy. If the amount of training and the validation accuracy is plotted, it shows a peak value and usually after further training, the model begins to overfit the training data, thus validation accuracy decreases. To ensure our validation accuracy is maximized for best performance, we keep a record of it (say Av) for a number of training iterations, known as patience.\nIn our case patience value was 10. That means if the validation accuracy does not increase during 10 epochs of training, the metrics at the epoch were A, was recorded is kept and training stops. This is called Early Stopping and is a commonly used practice in standard DL tasks."}, {"title": "4.4. Learning Rate Scheduler", "content": "In the beginning, a large learning rate is helpful as it allows the model to move quickly towards a point of convergence, which in our case, would indicate how well the model has learned to recognize voices.\nIn the later stages of learning, when the model is close to the point of convergence, small learning rates are desired so that the model does not overshoot and miss that point. This requires setting different learning rates at different stages of learning and is done with the learning rate scheduler.\nIn our model, the initial learning rate was set to 0.0001. After every 250 training steps, we scaled the learning rate down by 0.7. This is shown in Fig.9.\nHyperparameter tuning for learning rate was conducted with trial and error, and best performing learning rate with decay was saved according to results of model evaluations and metrics. The output biases and weights for the final dense layer conducting the multiple classification was checked to be converging to separate values. Moreover, the loss and accuracy curves were monitored to be healthy and converging without any abnormal behaviour, see Section.5."}, {"title": "5. Evaluation Metrics", "content": ""}, {"title": "5.1. Model Optimization and Solution Convergence", "content": "TensorBoard, a service from Tensorflow, was used to monitor model parameters. [12, 13] This allowed us to tune our model to our requirements and our type of dataset.\nMethods used to optimize and ensure model converged are:\n1.  Reduce model complexity - We tuned parameters such as the residual block size, filter size and dense layer sizes\n2.  Dropout regularization - so that training does not focus on unnecessary patterns in the data\n3.  Learning rate schedule - hyperparameters in learning rate schedulers were tuned in order to achieve optimal curves, this ensures that higher learning rates towards the end of training do not hamper accuracy and loss. See Fig.9\n4.  Increase batch size - often times, smooth accuracy curves exist but erratic validation loss curve may be an issue, which means that the validation set is too complex, or batch size of validation set used to evaluate the model was too small"}, {"title": "5.2. Accuracy and Loss Curves", "content": "During training, a close attention was kept on accuracy and loss curves. As the model trains, the accuracy of the model on both training set and and validation set will increase while the loss on each set will decrease.\nOccasionally in DL scenarios, even if the output predictions are accurate in practice, the model did not really converge to a point where maximum accuracy was achieved, but instead it stumbled upon a high accuracy point and held on-to that state due to EarlyStopping algorithm. This is where it is important to monitor the accuracy and loss curves to see that both training loss and"}, {"title": "5.3. Output Histograms", "content": "Ensuring that our output layer histograms are sufficiently separated is a crucial observation in asserting that multiple classification is taking place.\nWe can see from Fig.12a that the bias values of the (by default 4 classes) classes are separating into their respective values. Moreover we can observe that there is no direction changing in out bias values amidst training. A change of direction of the bias histogram as the model trains would mean that the model is overshooting the convergence point and not learning effectively. This was addressed using the steps mentioned in Section.5.1.\nIn Fig. 12b is it seen that the weights of each neurons are separated. A histogram that is distributed in fluctuating peaks throughout a large range about x=0 values indicated that the model is learning positive and negative features equally and the multiple peaks ensure that the model is learning specific features within the data."}, {"title": "6. Results", "content": "From our experimentation, we were able to optimize our model to detect and identify speech features within a voice clip as small as 8 seconds in length using comparatively simple 1D-CNN model. Training of the model was complete within on average 1 minute on a GPU Nvidia RTX 3060 4GB on an AMD Ryzen-7 5800H 16 Core CPU. Moreover the model successfully converged in low number of epochs, and therefore low number of iterations.\nMoreover, hyperparameters such as learning rate, layer sizes, batch sizes and dropout were tuned to attain the optimal performance.\nOur model was successful in identifying speakers in our dataset with a validation accuracy 97.87% even with added random noise. This means that on cleaner voice inputs the accuracy of prediction should be larger. Even with a considerably small dataset, the model was tuned to perform significantly well on unseen data.\nA GUI was created to make model usage and distribution easier and simpler.\nFuture experiments will evaluate model performance on large datasets like VoxCeleb1 and LibriSpeech to validate scalability. Additionally, pretrained models such as wav2vec will be tested as baselines for comparison."}, {"title": "7. Conclusion", "content": "This paper demonstrates the feasibility of speaker identification on minimal datasets using 1D-CNNs, achieving competitive validation accuracy. Key contributions include the implementation of augmentation techniques and the optimization of lightweight architectures. There are a few different future improvements that can be made. Firstly, the model can be further tuned using programmable tuners available in tensorflow. A comparative study can be done on hyperparamater changes on the model performance using Tensorboard. Residual blocks can be modified with difference architecture, adding BatchNormalization layers that might enable a better performance on the multiple classification task, such as done in ResNet DNN models. Furthermore, hyperparameter tuning for L2 Regularization can be done in the future such as for weight decay algorithm. Different kinds of initialization schemes for each layer can be used to observe the differnce on the model training and performance. Future directions involve testing on larger, more diverse datasets and leveraging transfer learning to improve model scalability."}]}