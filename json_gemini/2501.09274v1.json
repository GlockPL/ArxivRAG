{"title": "LARGE LANGUAGE Model is SECRETLY A PROTEIN SEQUENCE OPTIMIZER", "authors": ["Yinkai Wang", "Jiaxing He", "Yuanqi Du", "Xiaohui Chen", "Jianan Canal Li", "Li-Ping Liu", "Xiaolin Xu", "Soha Hassoun"], "abstract": "We consider the protein sequence engineering problem, which aims to find protein sequences with high fitness levels, starting from a given wild-type sequence. Directed evolution has been a dominating paradigm in this field which has an iterative process to generate variants and select via experimental feedback. We demonstrate large language models (LLMs), despite being trained on massive texts, are secretly protein sequence optimizers. With a directed evolutionary method, LLM can perform protein engineering through Pareto and experiment-budget constrained optimization, demonstrating success on both synthetic and experimental fitness landscapes.", "sections": [{"title": "INTRODUCTION", "content": "Protein engineering aims to develop novel protein sequences exhibiting improved or new-to-nature functions (Romero & Arnold, 2009). Directed evolution stands as a cornerstone paradigm of the field which leverages iterative rounds of mutagenesis and experimental selection to yield variants with gradually enhanced fitness (Arnold, 1998). While classical directed evolution has proven effective, it is generally acknowledged that its greedy optimization process often converges on suboptimal variants once a local maximum in the sequence fitness landscape of activity is reached (Yang et al., 2019). In recently proposed machine-learning guided directed evolution (MLDE) settings, sequence-to-function models have been incorporated as a computational surrogate to select candidates for experimental validation (Yang et al., 2019; Kirjner et al., 2023; Ren et al., 2022; Jain et al., 2022; Brookes et al., 2019; Yang et al., 2024).\nWith the grand success of AlphaFold2 on accurately predicting protein tertiary structures (Jumper et al., 2021), numerous work study protein language models (PLMs) which do not rely on multiple sequence alignment (MSA) and instead counting on learning the co-evolution information from multi-head attention transformers (Lin et al., 2023; Zhang et al., 2024). Motivated by the improved performance on structure prediction emerged from sequence-based pre-training, it has been employed as part of an evolutionary method which designs two masking strategies as mutation operators (Tran & Hy, 2024). More recently, increasing attention has been attracted to leverage large language models (LLMs) for problems in scientific discovery, e.g. molecule optimization (Wang et al., 2024), materials discovery (Lu et al., 2024). In protein engineering, Chen et al. (2024) propose a bi-level optimization to iteratively fine-tune pre-trained LLMs for protein optimization.\nIn this paper, we demonstrate LLMs themselves can already optimize protein fitness on-the-fly without further fine-tuning. Specifically, we build an evolutionary method that directly samples from pre-trained LLMs and select high fitness and low editing distance candidates for the next iteration. We count on LLMs to propose new candidates (i.e. mutation and crossover) to guide the search. Upon multiple experiments from 1) experiment-derived exact fitness landscapes, 2) simulated synthetic fitness landscapes, and 3) machine learning (ML) fitness landscape models trained on deep mutational scanning (DMS) datasets, we demonstrate LLMs can effectively propose new candidates that are much more efficient than the straightforward evolutionary algorithm with random mutation and crossover. We also extend the experiment setting to experiment-budget constrained and multi-objective optimization."}, {"title": "PRELIMINARY: PROTEIN SEQUENCE OPTIMIZATION", "content": "Single-objective optimization. Given an oracle function $f : \\Omega \\rightarrow R$, where $\\Omega := \\{(a_1, a_2,\\dots,a_L)|a_i \\in A\\}$, L is the maximum length of a protein sequence, and A is the set of 20 amino acid types, we aim to find the candidate $x^*$ as follows:\n$x^* = \\arg \\max_{x \\in \\Omega} f(x)$                                                                                                                    (1)\nConstrained optimization. Beyond merely optimizing the oracle function, we are often limited by experimental budget such that we constrain the maximum number of edits to be K from the reference wild type $x_{ref}$.\n$x^* = \\arg \\max_{x \\in \\Omega} f(x), s.t. dist(x, x_{ref}) \\leq K$                                                                                                               (2)\nwhere the distance function is taken as the Hamming distance $d_H(\\cdot,\\cdot)$ between two sequences.\nBudget-constrained optimization. Instead of constraining the absolute Hamming distance, a more realistic setting in wet-lab experiments is to constrain the relative Hamming distance (i.e. minimum Hamming distance between the proposed sequence and all previous experiment trials).\n$dist(x, P) = \\min_{x_p \\in P} d_H(x, x_p)$                                                                                                         (3)\nwhere P is the set of all previously evaluated candidates.\nMulti-objective optimization. In scenarios where we have multiple oracle functions to optimize, we solve a multi-objective optimization problem where the objective function becomes a vector-valued function $f : \\Omega \\rightarrow R^d$:\n$x^* = \\arg \\max_{x \\in \\Omega} f(x)$                                                                                                         (4)\nOne simple way to aggregate multiple objectives is to take a weighted sum over the output vector $\\Sigma_j w_j f_j(x)$ and $\\Sigma_j w_j = 1$, where we refer to as sum of objectives.\nNevertheless, the more rigorous formulation is to find the Pareto frontier $P$, defined as follows:\n$P(X) = \\{x \\in X : \\{x' \\in X : x \\leq x', x \\neq x'\\} = \\emptyset\\}$                                                                                                       (5)\nwhere $\\leq$ defines a partial order such that $x \\leq x'$ or x is dominated by x' if and only if $\\forall_j f_j(x') \\geq f_j(x)$. We refer the problem to find the Pareto set to as Pareto set selection."}, {"title": "METHODOLOGY", "content": "We propose an evolutionary method for protein sequence optimization. There are three main modules in our method: (1) initialization, (2) diversification and (3) selection. The framework is illustrated in Figure 1 and the pseudocode is included in Algorithm 1.\nInitialization. We initialize a pool of candidates by randomly sampling from the entire space or a single mutation from the wild type.\nMutation/Crossover. The default mutation in evolutionary algorithm (EA) is to perform a random mutation over a single protein sequence; the default crossover in EA is to randomly swap amino acids of two protein sequences at the same position or swap the entire half sequence split by a random position. In our LLM-based method, we randomly sample a pair of protein sequences from our pool and encourage LLMs to propose a new candidate either through mutation or crossover.\nSelection. For single-objective optimization, we simply select the top-k ranked protein sequences in both the previous pool and the newly proposed candidates. For constrained optimization, we employ a rejection sampling-based strategy: we discard all samples that violate the constraints (exceeding the maximum number of edits allowed. For multi-objective optimization, we optimize for two objectives: (1) objective scalarization: we sum over all objective values in the multi-objective vectors and treat it as a single-objective optimization problem; (2) Pareto set selection: we select only the candidates on the Pareto frontier to proceed the next iteration."}, {"title": "EXPERIMENT", "content": "EXPERIMENT SET-UP\nOracle function. We have three types of oracle functions: exact oracle, synthetic SLIP model oracle, and ML oracle. For exact oracle, directly measures the fitness values of all possible variants in a specified search space by deep mutational scanning (DMS) (Fowler & Fields, 2014). Due to experimental budget constraints, the number of sites to be mutated is often limited to four or fewer.\nFor the synthetic SLIP oracle, the statistical energy of protein variants evaluated by the Potts model has been demonstrated to correlate with observed empirical fitnes (Hopf et al., 2017), and the Synthetic Landscape Inference for Proteins (SLIP) based on Potts models has been proposed as a hard-to-optimize fitness landscape (Thomas et al., 2022).\nFor ML oracle, a machine learning model is trained on sequence-fitness pairs of single and multiple mutants for a wild-type protein through DMS (Dallago et al., 2021). Unlike the exact oracle, which focuses on a small subset of variants, the ML oracle can evaluate protein variants with any number of mutations away from the wild-type sequence, returning a predicted fitness value. However, its generalization ability remains a key limitation: because the model is typically trained on a comparatively small dataset, its predictions may be unreliable across the full sequence space.\nHyperparameters. We adopt the Llama-3.1-8B-Instruct model as our LLM. To mimic real-world protein engineering experiment procedure, we choose a set of 32/48/96 candidates in each iteration for a total of 4 iterations. For experiment settings allowing a larger number of mutations away from the wild-type, we increase to 8 iterations for better optimization.\nBaselines. We use the exactly same hyperparameters and initial pools for the baseline evolutionary algorithm as our model, we adopt the default mutation and crossover operators for EA in Section 3.\nDatasets. Here we list the datasets used for each type of oracle function:\n\\bullet For the exact oracle setting, we test our framework on two combinatorial landscape datasets GB1 (Wu et al., 2016) and TrpB (Johnston et al., 2024). On these landscapes, four amino acids"}, {"title": "MAIN EXPERIMENT", "content": "We validate our method in four settings to evaluate our method on protein sequence optimization.\nSingle-objective optimization. We conduct single-objective optimization on all five datasets. In this experiment, we follow the traditional directed evolution protocol, setting the number of proposed variants per iteration to 32, 48, and 96. For GB1 and TrpB, the number of iterations is set to 4, while for the other landscapes, the number of iterations is increased to 8 due to the larger number of possible mutation sites. The optimization objective is to maximize the fitness value from the oracle function, as detailed in Table 1. Among five datasets, GB1 and TrpB have more linear fitness landscapes, where finding a favorable amino acid at a position often leads to its presence in the optimal sequence (demonstrated by Figure 4). This allows EA to find strong variants early, sometimes outperforming our method. As shown in Figure 7, EA only outperforms one of three random seeds for GB1, while our framework performs better in the other two.\nSince linear relationships between positions are less likely in more complex landscapes with larger search spaces, we also evaluate our framework on Syn-3bfo, AAV, and GFP, which have more mutation sites and nonlinear fitness landscapes (Table 1). For Syn-3bfo, the initial pool is generated from single mutations of the wild-type protein 3bfo, with fitness values calculated using the SLIP model. For the AAV and GFP datasets, our initial pool setting follows the medium difficulty criteria outlined in (Kirjner et al., 2023). This involves restricting the fitness range of the initial pool proteins to fall between a certain range and ensuring that the mutational gap from the highest-score protein in the given dataset is greater than 6. The predicted fitness value is normalized by min-max values of dataset. Our method consistently outperforms EA in these datasets (Table 2).\nConstrained optimization. In constrained optimization, we limit the number of mutations at each iteration to 3, 5, and 10, rejecting sequences that exceed these limits on the Syn-3bfo landscape. For our method, we add the prompt: \"The proposed sequence must have a Hamming distance between 1 and {H} from the {wild-type sequence}\", where H represents the Hamming distance constraint.\nAs shown in Table 4, our method demonstrates stable performance compared to EA. Notably, the performances of EA at constrained Hamming distances of 5 and 10 are the same, as the maximum Hamming distance of sequences proposed by EA does not exceed 5 within eight iterations. Our framework performs best when the constrained Hamming distance is set to 3. Additionally, we illustrate the Pareto frontier discovered during the constrained optimization tasks by selecting the best fitness value for each Hamming distance from the wild-type in Figure 2.\nBudget-constrained optimization. In budget-constrained optimization, we restrict the maximum number of amino acids edited in a single iteration to 1, 2, and 4 on the Syn-3bfo landscape. Sequences exceeding this limit are dropped by rejection sampling. For our method, we include the prompt: \"The proposed sequence must have a Hamming distance between 1 and {BH} from the {parent sequence}\", where BH represents the constrained Hamming distance, and {parent sequence} refers to the two parent sequences provided to the LLM for optimization."}, {"title": "Multi-objective optimization", "content": "We perform multi-objective optimization to simultaneously optimize the Hamming distance and fitness on the Syn-3bfo landscape. In the sum of objectives approach, the fitness value and 1 \u2013 normalized Hamming distance are combined into a single objective with equal weight. In the Pareto set selection approach, all dominated points are rejected, and optimization is restricted to points on the Pareto frontier.\nThe results from the first approach are summarized in Table 3 and compared against the evolutionary algorithm (EA). The Pareto frontiers identified by our framework and the EA for both approaches are illustrated in Figure 3. For the TrpB landscape, the true Pareto frontier can be determined as it is fully enumerated, and our method identifies more Pareto frontier points than EA in the sum-of-objectives setting. Moreover, the Pareto frontiers found by our method in the sum-of-objectives task dominate or are equivalent to those found by EA on both landscapes.\nIn the Pareto set selection setting, our method does not dominate all the Pareto frontiers identified by EA. This is because restricting the experiment pool to only include Pareto frontier points limits the LLM's access to sufficient information about the sequence space for optimization. However, our method still identifies Pareto frontier points that dominate those found by EA on Syn-3bfo landscape."}, {"title": "CONCLUSION", "content": "In this paper, we introduce an LLM-guided directed evolution framework for protein sequence optimization. We investigate a range of tasks, employing oracle functions of varying complexity\u2014from synthetic landscapes to experimental ground-truth measurements and machine learning-based oracles. We conduct experiments on multiple optimization tasks from single-objective to constrained and multi-objective optimization. Our results consistently demonstrate the efficacy of LLMs in proposing high-fitness variants. Moving forward, integrating LLM-based optimization into real-world experimental pipelines can accelerate directed evolution experiments, allowing for more efficient exploration of the protein sequence space."}, {"title": "APPENDIX", "content": ""}, {"title": "PSEUDOCODE", "content": "We show the pseudocode of our framework below.\nAlgorithm 1: Protein Sequence Optimization with LLM\nData: Initial population $P_0$; mutation rate $r_m$; population size K; number of iterations N; the fitness function $F(\\cdot)$; the default crossover function $C'(\\cdot, \\cdot)$; the default mutation function $M(\\cdot)$.\nResult: Optimized protein population $P_N$.\nbegin\n for $s \\in P_0$ do\n | Compute $F(s)$;\n for $t \\in [1, N]$ do\n | $offspring = []$;\n | for $k \\in [1, K]$ do\n | | Draw parent sequences $(s_0, s_1) \\sim P_t \\times P_t$;\n | | $proposed\\_seq \\leftarrow LLM\\_propose(s_0, s_1)$;\n | | if $proposed\\_seq$ is None then\n | | | $offspring.append(C'(s_0, s_1))$;\n | | | $r \\sim Uniform[0, 1]$\n | | | if $r < r_m$ then\n | | | | $offspring.append(M(s_0))$;\n | | else\n | | | $offspring.append(proposed\\_seq)$;\n | for $s \\in offspring$ do\n | | Compute $F(s)$;\n | $merged\\_population \\leftarrow merge(P_t, offspring)$;\n | $P_t \\leftarrow sorted(merged\\_population)[:K]$;\nReturn $P_N$;"}, {"title": "DATASETS ANALYZE", "content": "We present a heatmap of the average scores for specific combinations at different positions: the first two, last two, last three, and the full sequence for GB1 and TrpB in Figure 4. The heatmap reveals that certain combinations in the last two positions, such as CA, LG, and AA in GB1, and KG, LG, and IG in TrpB, exhibit higher fitness scores compared to others. Preserving these combinations can significantly simplify the path to identifying sequences with improved fitness."}, {"title": "PROMPTS", "content": "Prompt\nsystem\nYou are a world-class assistant specializing in protein engineering, fitness optimization, and sequence design. Your expertise lies in analyzing sequence-function relationships, interpreting experimental data, and proposing rational modifications to optimize protein fitness.\nuser\nYou will carry out a multi-round directed evolution experiment with the following protein sequence, aimed at improving protein's ability to bind affinity-based sequence enrichment via protein fitness optimization.\n### Protein fitness optimization\nThe fitness score reflects the efficacy or functionality for a desired application, from chemical synthesis to bioremediation and therapeutics. Protein fitness optimization can be thought of as navigating a protein fitness landscape, a mapping of amino acid sequences to fitness values, to find higher-fitness variants. Specifically, it is achieved by making crossover and mutations on the given sequences.\nWe are focusing on changes to a limited subset of amino acids within the sequence. The provided subset protein sequences come from B1 domain of streptococcal protein G, with sequence:\nMTYKLILNGKTLKGETTTEAVDAATAEKVFKQYANDNGVDGEWTYDDAT\nKTFTVTE\nEach subset protein sequence represents specific amino acid substitutions at four key positions: 39, 40, 41, and 54, denoted using the single-letter amino acid code.\n### Parent protein sequences\nHere are the parent protein sequences that you will be modifying from. Each sequence comes with 4 amino acids and its fitness score is also provided.\nProtein sequence 1 (fitness score: 0.0018)\nQHVR\nProtein sequence 2 (fitness score: 0.0021)\nRLIV\n### Instructions\nFollow the instructions below to propose a new protein:\n* Your proposal should focus on maximizing fitness and minimizing humming distance from the wild type while considering structural and functional plausibility.\n* You can propose it via making crossover or mutation on the parent sequences.\n* You can also propose a new sequence based on your knowledge.\n* Your proposed sequence MUST have the same length as the parent sequences.\n* DO NOT propose sequence that is identical with the parent or the wild type sequences.\n* Your output MUST ONLY include: \\box{{Protein}}."}, {"title": "PARETO FRONTIER", "content": "We present the Pareto frontiers identified through constrained optimization tasks with different Budget H and H, as shown in Figure 5. The figures shows our method consistently dominate EA."}, {"title": "ABLATION STUDY OF THE NUMBER OF ITERATIONS", "content": "We analyze the impact of varying the number of iterations on the results in Table 6. The analysis shows that as the number of iterations increases, both EA and our framework improve in performance. However, our method consistently maintains its advantage over EA."}, {"title": "ADDITIONAL EXPERIMENTS RESULT", "content": "We present additional experiments,show results across three random seeds and datasets in Figure 7."}]}