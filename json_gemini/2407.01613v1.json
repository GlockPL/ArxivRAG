{"title": "Self-adaptive weights based on balanced residual decay rate\nfor physics-informed neural networks and deep operator\nnetworks", "authors": ["Wenqian Chen", "Amanda A. Howard", "Panos Stinis"], "abstract": "Physics-informed deep learning has emerged as a promising alternative for solving\npartial differential equations. However, for complex problems, training these net-\nworks can still be challenging, often resulting in unsatisfactory accuracy and ef-\nficiency. In this work, we demonstrate that the failure of plain physics-informed\nneural networks arises from the significant discrepancy in the convergence speed of\nresiduals at different training points, where the slowest convergence speed dominates\nthe overall solution convergence. Based on these observations, we propose a point-\nwise adaptive weighting method that balances the residual decay rate across different\ntraining points. The performance of our proposed adaptive weighting method is com-\npared with current state-of-the-art adaptive weighting methods on benchmark prob-\nlems for both physics-informed neural networks and physics-informed deep operator\nnetworks. Through extensive numerical results we demonstrate that our proposed ap-\nproach of balanced residual decay rates offers several advantages, including bounded\nweights, high prediction accuracy, fast convergence speed, low training uncertainty,\nlow computational cost and ease of hyperparameter tuning.\nKeywords: Self-adaptive weights, Balanced convergence speed, Physics-informed\nneural networks, Physics-informed deep operator networks", "sections": [{"title": "1. Introduction", "content": "Benefiting from the rapid advancements in computational capabilities, optimiza-\ntion algorithms, and automatic differentiation technologies [1, 2], physics-informed\nneural networks (PINNs)[3] have emerged as a powerful tool for addressing both\nforward and inverse problems associated with partial differential equations (PDEs).\nIntegrating physical laws directly into their framework, PINNs optimize a loss func-\ntion that includes data and equation residuals to assist models in adhering to the\nunderlying physical principles. Building upon the foundational concepts of PINNs,\nand the deep operator network (DeepONet) architecture [4], physics-informed deep\noperator networks (PIDeepONets) extend these methodologies to the solution opera-\ntors of PDEs[5, 6, 7]. Both PINNs and PIDeepONets have enjoyed success in various\nsettings, but they can still face convergence/accuracy issues [8, 9, 10]. To mitigate\nthese issues, various enhancements to the plain PINN/PIDeepONet or approach have\nbeen proposed e.g., improved network model [8, 11], adaptive sampling [12, 13, 14],\ndomain decomposition [15, 16], multi-fidelity learning [17, 18, 19], continual learning\n[20], adaptive activation [21], and Fourier feature embedding [22, 23]. In the cur-\nrent work, we focus on a self-adaptive weighting method designed to dynamically\nbalance the training process of PINNs and PIDeepONets, aiming to improve their\nperformance.\nAdaptive weighting in PINNs and PIDeepONets has revolutionized the way these\nmodels handle the training process by dynamically adjusting the weights assigned to\ndifferent terms in the loss function. This method effectively balances the loss contri-"}, {"title": "2. Understanding the plain PINN failure mechanism", "content": "butions from various parts of the domain, thereby addressing one of the fundamental\nchallenges: ensuring that all physical laws are learned equally well without bias to-\nwards simpler or more dominant features. As a result, improvement in convergence\nrates and increase in the accuracy and stability of the solutions has been obtained.\nThere are numerous adaptive weighting approaches, with the strategies for tun-\ning weights varying considerably among approaches. For instance, Wang et al. [8]\nintroduced a learning rate annealing algorithm that updates weights inversely pro-\nportional to the back-propagated gradients. Wang et al. [24] also defined a causal\ntraining for time-dependent problems that assigns larger weight to the loss functions\ncontributions in a time-ordered fashion. Mattey and Ghosh [25] solve sequentially\nin temporal subdomains with a plain PINN, using weights to penalize the depar-\nture from the already obtained solutions from previous training. Another popular\nstrategy is to update weights positively proportional to (normalized) residuals. For\ninstance, Liu and Wang [26] proposed a mimimax method to update weights, using\ngradient descent for the network parameters and gradient ascent for the weights (the\ngradient is proportional to residuals). McClenny and Braga-Neto [10] proposed a\ngeneral variant of the mimimax method by employing point-wise weights instead of\ncomponent-wise weights. Taking this mimimax strategy further, Song et al. [27] and\nZhang et al. [28] employed auxiliary networks to represent the point-wise weights.\nAnagnostopoulos et al. [29] proposed to update weights according to normalized\nresiduals. A Lagrange multiplier-based method has also been employed for designing\nadaptive weights, where the weights, namely the Lagrange multipliers applied to the\nconstraint terms, are updated based on the residuals of constraint terms. Basir et al.\n[30] proposed using the augmented Lagrangian method (ALM) to constrain the solu-\ntion of PDE with boundary conditions or any available data. They then introduced\nan adaptive ALM [31] to enhance this approach, and further improved its capability"}, {"title": "2.1. Physics-informed neural networks", "content": "Physics-informed neural networks (PINNs) aim at inferring a function u(x) of\na system with (partially) known physics, typically defined in the form of partial\ndifferential equations (PDEs):\n$$R(u(x)) = 0, \\qquad x \\in \\Omega$$\n$$B(x) = 0, \\qquad x \\in \\partial\\Omega$$\nwhere $$x \\in \\mathbb{R}^{n_p}$$ are $$n_p$$-dimensional spatial/temporal coordinates, $$R$$ is a general\npartial differential operator defined on the domain $$\\Omega$$ and $$B$$ is a general boundary\ncondition operator defined on the boundary $$\\partial\\Omega$$. For time-dependent problems, time\n$$t$$ is considered as a component of $$x$$, $$\\Omega$$ is a space-time domain, and the initial\ncondition will be assumed as a special boundary condition of the space-time domain.\nIn PINNs, the solution $$u(x)$$ is first approximated as $$u_{nn}(x;\\theta)$$ by a neural network\nmodel built with a set of parameters $$\\theta$$. The partial derivatives of $$u_{nn}(x;\\theta)$$ required\nfor the estimation of the action of the operators $$N$$ and $$B$$ are readily computed by\nautomatic differentiation. The training of the PINN is a multi-objective optimization\nproblem aiming to minimize the residuals of the PDE and the boundary conditions,\nwhich are usually evaluated on a set of collocation points. In the plain PINNs, the\noptimizing objective, namely the loss function, is defined as a linear combination of\nthe square of the following residuals:\n$$\\mathcal{L}(\\theta) = \\frac{1}{N_R} \\sum_{i=1}^{N_R} R^2(x^R_i) + \\frac{1}{N_B} \\sum_{i=1}^{N_B} B^2(x^B_i)$$"}, {"title": "2.2. Training dynamic of unweighted PINNS", "content": "where $$X_R = \\{x^R_i\\}_{i=1}^{N_R} \\subset \\Omega$$ are collocation points within the domain, and $$X_B = \\{x^B_i\\}_{i=1}^{N_B} \\subset \\partial\\Omega$$ are boundary points.\nUsually, the loss function in Eq. (2) is minimized by gradient-based optimization\nalgorithms, such as Adam [36]. Ideally, in the case of infinite residual/boundary\npoints, if the loss function drops down to zero, all the residuals drop to zeros too\nand thus the system is solved exactly. However, limited by the number of resid-\nual/boundary points, the network approximating capability and the optimization\nerror, the loss function cannot drop down to zero, and we can only try to minimize\nit as close to zero as possible.\nLet us first consider an unweighted loss function\n$$\\mathcal{L}(\\theta) = \\sum_{i=1}^{N_R} R^2(x^R_i; \\theta) + \\sum_{i=1}^{N_B} B^2(x^B_i; \\theta)$$\nThe training process of physics-informed neural networks can be described using the\nNeural Tangent Kernel (NTK) theory [34]:\n$$\\begin{bmatrix}\n\\frac{dR(X_R;\\theta(t))}{dt} \\\\\n\\frac{dB(X_B;\\theta(t))}{dt}\n\\end{bmatrix} = -2\\eta K(t) \\begin{bmatrix}\nR(X_R;\\theta(t)) \\\\\nB(X_B;\\theta(t))\n\\end{bmatrix}$$\nwhere $$\\eta$$ is the learning rate and $$K(t)$$ is the NTK matrix at training iteration $$t$$\ndefined as\n$$K(t) = \\begin{bmatrix}\nK_{RR}(t) & K_{RB}(t) \\\\\nK_{BR}(t) & K_{BB}(t)\n\\end{bmatrix}$$"}, {"title": "2.3. Vast convergence disparities can lead to failure of plain PINNs", "content": "The entries of the NTK matrix are defined as follows:\n$$[K_{RR}(t)]_{ij} = \\frac{\\partial R(x^R_i; \\theta(t))}{\\partial \\theta} \\cdot \\frac{\\partial R(x^R_j; \\theta(t))}{\\partial \\theta} , \\qquad 1 \\leq i, j \\leq N_R$$\n$$[K_{RB}(t)]_{ij} = \\frac{\\partial R(x^R_i; \\theta(t))}{\\partial \\theta} \\cdot \\frac{\\partial B(x^B_j; \\theta(t))}{\\partial \\theta} , \\qquad 1 \\leq i \\leq N_R, 1 \\leq j \\leq N_B,$$\n$$[K_{BB}(t)]_{ij} = \\frac{\\partial B(x^B_i; \\theta(t))}{\\partial \\theta} \\cdot \\frac{\\partial B(x^B_j; \\theta(t))}{\\partial \\theta} , \\qquad 1 \\leq i, j \\leq N_B$$\nAs demonstrated in [37, 34], when the network width tends to infinity and the\nlearning rate tends to zero, the NTK matrix converges to a deterministic constant\nkernel, namely $$K(t) \\rightarrow K^*$$. Substituting the eigendecomposition $$K^* = QAQ^T$$ into\nEq. (4), we have\n$$Q^T \\begin{bmatrix}\nR(X_R;\\theta(t)) \\\\\nB(X_B;\\theta(t))\n\\end{bmatrix} \\approx exp(-2\\eta \\Lambda t) Q^T \\begin{bmatrix}\nR(X_R;\\theta(0)) \\\\\nB(X_B;\\theta(0))\n\\end{bmatrix}$$\n$$\\begin{bmatrix}\nR(X_R;\\theta(t)) \\\\\nB(X_B;\\theta(t))\n\\end{bmatrix} \\approx Q exp(-2\\eta \\Lambda t) Q^T \\begin{bmatrix}\nR(X_R;\\theta(0)) \\\\\nB(X_B;\\theta(0))\n\\end{bmatrix}$$\nSince $$K^*$$ is a positive semi-definite matrix, the eigenvalues of $$K^*$$ are all non-\nnegative real numbers. This means that the $$i^{th}$$ entry of $$Q^T [R(X_R;\\theta(t)), B(X_B;\\theta(t))]^T$$\ndecays approximately exponentially at a constant convergence rate $$2\\eta \\Lambda_i$$. Therefore,\nthe evolution of the $$i^{th}$$ residual in $$[R(X_R;\\theta(t)), B(X_B;\\theta(t))]^T$$ is a linear combination\nof those decaying exponentials. It is reasonable to assume that the $$i^{th}$$ residual also\ndecays exponentially in a short period, and its convergence rate falls between the\n$$2\\eta \\min(\\Lambda)$$ and $$2\\eta \\max(\\Lambda)$$. Note that this conclusion also applies to PIDeepONet.\nFor details on the NTK theory of PIDeepONet, we refer the reader to [11].\nIt is not trivial to calculate the convergence rate of the residual at a training\npoint, since it is always iteration-dependent. To describe the dynamic of residuals,\nwe introduce a notion called \u201cinverse residual decay rate\u201d, which is used to indicate"}, {"title": "3. Physics-informed machine learning with balanced residual decay rate", "content": "Plain PINNs have been observed to have convergence issues for problems with\nsharp space/time transitions [17]. As an example, consider the 1D Poisson equation:\n$$\\frac{\\partial u}{\\partial x^2} = f(x), \\qquad x \\in [0, 1]$$\n$$u(\\pm 1) = 0$$\nwith the artificial solution $$u(x) = sin(2k\\pi x^2)$$. The oscillating frequency of the so-\nlution is 0 at x = 0, and increases to $$k$$ at $$x = 1$$. The frequency discrepancy is"}, {"title": "3.1. Physical insights of weighed PINNs", "content": "the convergence rate of a residual. The inverse residual decay rate $$irdr$$ is defined as\nthe ratio of the residual's square to its exponential moving average, namely\n$$irdr = R^2(t)/\\sqrt{R^4(t) + eps}$$\nNote that the employment of the square of the residual is to make sure that the $$irdr$$\nis non-negative. eps is a tiny positive real number used to avoid division by zero,\nand it is opted as eps = 1E \u2013 14. The exponential moving average $$R^4(t)$$ is updated\naccording to the following equation:\n$$\\overline{R^4}(t) = \\beta_c \\overline{R^4}(t - 1) + (1 - \\beta_c) R^4(t)$$\nwhere $$\\beta_c$$ is the smoothing factor. A larger value of $$\\beta_c$$ corresponds to a longer-period\naverage, thereby placing more weight on past observations and less on the most\nrecent observation.\nTo intuitively visualize the relationship between the inverse residual decay rate\n$$irdr$$ and the convergence rate $$\\Lambda$$, we assume that the residual at a given training\npoint decays exponentially with respect to the iteration index $$t$$ as $$R = R_0 exp(-\\Lambda t)$$,\nwhere $$\\Lambda > 0$$ is the convergence rate. The relationship between the inverse residual\ndecay rate $$irdr$$ and the convergence rate $$\\Lambda$$ can be calculated numerically.\nThe relationship between $$\\Lambda$$ and $$irdr$$ at $$t = 10000$$ is depicted in Fig. 1(left). It\nis observed that $$irdr$$ is negatively proportional to $$\\Lambda$$ when $$\\Lambda$$ is large. Conversely,\n$$irdr$$ quickly increases to 1 when $$\\Lambda$$ is small. Additionally, for larger values of $$\\beta_c$$, $$irdr$$\nincreases to 1 at smaller $$\\lambda$$. Hence, a larger $$\\beta$$ can be utilized to sense a broader\nrange of $$\\Lambda$$. However, it is not necessarily true that a larger $$\\Lambda$$ is preferable. Consider\nanother decay process for the residual:\n$$R = \\begin{cases}\nR_0 exp(-\\lambda t) & t < 100000 \\\\\nR_0 exp(-100000\\lambda) exp(-0.5 \\lambda (t - 100000)) & t > 100000\n\\end{cases}$$"}, {"title": "3.2. Balanced residual decay rate (BRDR)", "content": "To build a general weighted PINN framework, we use a scale factor and a set of\nnormalized weights with each weight assigned to a residual term, namely\n$$\\mathcal{L}(\\theta; \\textbf{w}, s) = s \\left(\\frac{1}{N_R} \\sum_{i=1}^{N_R} w^R_i R^2(x^R_i) + \\frac{1}{N_B} \\sum_{i=1}^{N_B} w^B_i B^2(x^B_i)\\right)$$\ns.t.\n$$w := \\frac{s}{\\frac{\\sum_{i=1}^{N_R} w^R_i + \\sum_{i=1}^{N_B} w^B_i}{N_R + N_B}} = 1$$\nwhere $$w^R_i > 0$$ is the weight assigned to each residual term, $$w^B_i > 0$$ is the weight\nassigned to each boundary point, and $$\\textbf{w}$$ is the collection of these weights. The scale\nfactor $$s$$ is employed to scale all the weights, so that the formulation could cover all\nkinds of possible weight distribution.\nThe training process of physics-informed neural networks with weights can be\napproximated as follows:\n$$\\frac{d}{dt} \\begin{bmatrix}\nR(X_R;\\theta(t)) \\\\\ndB(X_B;\\theta(t))\n\\end{bmatrix} = -2s\\eta K(t)diag(\\textbf{w})diag(1/\\textbf{N}) \\begin{bmatrix}\nR(X_R;\\theta(t)) \\\\\nB(X_B;\\theta(t))\n\\end{bmatrix}$$\nwhere $$\\textbf{N} = [N_R, ..., N_R, N_B, ..., N_B]^T$$ and the definition of $$K(t)$$ is the same as in\nSection 2.2. The terms $$1/N_R$$ and $$1/N_B$$ can be considered user-defined weight con-\nstants. The introduction of $$\\textbf{w}$$ and $$s$$ modifies the training dynamics. Empirical\nobservations indicate that increasing the weight at a specific training point enhances\nits convergence rate. Regarding the scale factor $$s$$, since $$s$$ and $$\\eta$$ appear together in\nEq. (17), $$s$$ functions similarly to $$\\eta$$. Both $$s$$ and $$\\eta$$ scale the eigenvalues of the matrix\n$$K(t)diag(\\textbf{w})diag(1/\\textbf{N})$$, thereby influencing the overall convergence velocity. In the\nfollowing sections, we will elucidate the procedure for updating $$\\textbf{w}$$ and $$s$$ during the\nnetwork training process."}, {"title": "3.3. Maximizing learning rate", "content": "As demonstrated in Section 2.3, the largest inverse residual decay rate dominates\nthe convergence speed of the training process. To address this issue, we assign a\nlarger weight to the training term with a larger inverse residual decay rate, namely,\n$$\\textbf{w} \\propto \\textbf{c}$$\nwhere $$\\textbf{c}$$ is the collections of inverse residual decay rate $$irdr$$ for all the training terms.\nAt training iteration $$t$$, to meet the normalization constraint on $$\\textbf{w}$$ in Eq. (16), we\nset\n$$\\textbf{w}^{ref}_t = \\frac{\\textbf{c}_t}{mean(\\textbf{c}_t)}$$\nTo filter out noise during network training, we employ an exponential moving average\nmethod to update the weights, namely,\n$$\\textbf{w}_t = \\beta_w \\textbf{w}_{t-1} + (1 - \\beta_w) \\textbf{w}^{ref}_t$$\nwhere $$\\beta_w$$ is a smoothing factor.\nFor the loss function defined in Eq. (15), the loss without scaling $$\\\\_L_s = \\mathcal{L}/s$$\nsatisfies the following ordinary differential equation\n$$\\frac{\\partial \\mathcal{L}\\_s}{\\partial t} \\approx \\frac{\\partial \\mathcal{L}\\_s}{\\partial s} \\frac{ds}{dt} + \\frac{\\partial \\mathcal{L}\\_s}{\\partial \\textbf{w}} \\frac{d\\textbf{w}}{dt}$$\n$$= -\\frac{s}{\\eta} ||\\nabla_{\\theta} \\mathcal{L}||^2_2 \\frac{ds}{dt} + \\nabla_{\\textbf{w}}\\mathcal{L}\\_s^T \\nabla_{\\theta} \\mathcal{L} \\frac{d\\textbf{w}}{dt}$$\n$$=-\\frac{\\eta}{s} \\frac{|\\nabla_{\\theta} \\mathcal{L}||^2}{L}$$\nFor the stable numerical simulation of the ODE $$y_t = -\\lambda y$$ with the Euler forward\nmethod, the time step $$\\Delta t$$ should satisfy $$\\Delta t \\leq 2/\\lambda$$. Applying the stability constraint\nto Eq. (22), we find\n$$\\eta \\leq \\frac{2L}{|\\nabla_{\\theta} \\mathcal{L}||^2}$$\nSince $$\\\\_L$$ is proportional to the scale factor $$s$$, tuning $$s$$ during network training process\ncan make $$\\eta$$ stay close to its maximum limit, thus accelerating the training process.\nBased on this idea, given the training status at iteration $$t-1$$, we derive the maximum\nscale factor $$s^{max}_t$$ at iteration $$t$$,\n$$\\eta = \\frac{2L_t}{||\\nabla_{\\theta} \\mathcal{L}_t||^2} \\approx \\frac{s^{max}_t}{s_{t-1}} \\frac{2L_{t-1}}{(s^{max}_t)^2 ||\\nabla_{\\theta} \\mathcal{L}_{t-1}||^2} \\Longleftrightarrow \\frac{s_{t-1}}{s^{max}_t} = \\frac{2L_{t-1}}{s^{max}_t ||\\nabla_{\\theta} \\mathcal{L}_{t-1}||^2}$$\nSo, we have\n$$s^{max}_t = \\frac{s_{t-1} ||\\nabla_{\\theta} \\mathcal{L}_{t-1}||^2}{2L_{t-1}}$$\nTo filter out noise during network training, we again use exponential moving average\nmethod to update the scale factor, namely\n$$s_t = \\beta_s s_{t-1} + (1 - \\beta_s) s^{max}_t$$\nwhere $$\\beta_s$$ is a smoothing factor. Since the scale factor $$s$$ functions similarly to the\nlearning rate $$\\eta$$, we propose updating $$s$$ synchronously with $$\\eta$$. For example, when the\nlearning rate $$\\eta$$ decreases, the update velocity of the scale factor $$s$$ is also expected\nto decrease. In the following tests, unless otherwise specified, we set $$\\beta_s = 1 - \\eta$$.\nWe note that the updating of the scale factor with Eqs. (25) and (26) incurs only\nlittle additional computational cost, since the terms $$L_{t-1}$$ and $$\\nabla_{\\theta} \\mathcal{L}_{t-1}$$ are already\ncomputed during back propagation."}, {"title": "3.4. Mini-batch training", "content": "Mini-batch training is commonly employed in physics-informed machine learn-\ning for several reasons: it helps manage computational resources by fitting training\nwithin memory constraints and enhances computational efficiency. It facilitates the\nuse of stochastic gradient descent and its variants [38, 39], enabling more frequent\nmodel updates which can lead to faster convergence and better handling of complex\nloss landscapes inherent in physics.\nIn this work, we restrict ourselves only to the scenario where all the training\npoints are pre-selected before training and a subset of training points is randomly\nchosen at each training step. The proposed method in Sections 3.2 and 3.3 can be\nextended to mini-batch training straightforwardly, except for the calculation of the\nexponential moving average of quantities. Since a specific training point cannot be\nchosen at every training step, it is too expensive to update the weights for all the\npoints at each iteration. It is efficient to only update the weights associated to the\nchosen points at each training step. We assume $$\\\\_t_i$$ is the training iteration interval\nfor the $$i^{th}$$ training point, which is the difference of current step and the last previous\nstep that the training point was chosen. The weights are then updated as\n$$w_{t,i} = \\beta^{\\\\Delta t_i}_{w} w_{t-\\\\Delta t_i} + (1 - \\beta^{\\\\Delta t_i}_{w}) w^{ref}_{t,i}$$\nSimilarly, the exponential moving average $$\\overline{R}(t)$$ for the residual at the $$i^{th}$$ training\npoint is calculated as follows:\n$$\\overline{R}(t) = \\beta^{\\\\Delta t_i}_{c} \\overline{R}(t - \\\\Delta t_i) + (1 - \\beta^{\\\\Delta t_i}_{c}) R^4(t)$$\nFor updating of the scale factor in Eq. (26), it is also calculated with exponential\nmoving average. However, the scale factor can be updated in Eq. (26) directly at"}, {"title": "3.5. Summary", "content": "each training step without any modifications, since it is accessible at each training\nstep.\nConsider a physics-informed neural network $$u_{NN}(x;\\theta)$$ with training parameters\n$$\\theta$$, and a weighted loss function\n$$\\mathcal{C}(\\theta; \\textbf{w}, s, \\Lambda) = s \\left(\\frac{\\lambda_R}{N_R} \\sum_{i=1}^{N_R} w_i R^2(x^R_i) + \\frac{\\lambda_B}{N_B} \\sum_{i=1}^{N_B} w_i B^2(x^B_i)\\right)$$\nwhere $$\\textbf{w}$$ represents point-wise adaptive weights allocated to collocation points $$\\{x^R_i\\}_{i=1}^{N_R}$$\nand $$\\{x^B_i\\}_{i=1}^{N_B}$$, $$s$$ is an adaptive scale factor, and $$\\Lambda = \\{\\lambda_R, \\lambda_B\\}$$ are user-defined weight\nconstants to normalize the residuals. According to our tests in Section 4, although\nsimply setting $$\\Lambda = 1$$ could be enough to achieve rather accurate results, setting a\nspecific $$\\Lambda$$ can significantly improve prediction accuracy. In the following, we refer to\ntraining with $$\\\\_Lambda = 1$$ as BRDR training, and training with specifically defined $$\\Lambda$$ as\nBRDR+ training.\nIn summary, after the specification of the user-defined hyperparameters which\ninclude the learning rate $$\\eta$$, the smoothing factors $$\\\\_B$$ and $$\\beta_w$$, the batch sizes $$N_{Rb}$$\nand $$N_{Bb}$$, and the weight constants $$\\lambda_R$$ and $$\\lambda_B$$, the training process can proceed as\ndetailed in Algorithm 1. Note that the weights and scale factor are all initialized at 1,\nnamely $$\\textbf{w} = s = 1$$. Although Algorithm 1 is specifically employed for problems with\ntwo loss components (PDE loss and BC loss), its extension to multiple components\nis straightforward."}, {"title": "4. Numerical results for physics-informed neural networks", "content": "To validate the performance of the BRDR weighting method in training PINNs,\nwe tested it on three benchmark problems: the 2D Helmholtz equation, the 1D Allen-\nCahn equation, and the 1D Burgers equation. For comparison, we also report the\nerror from training with fixed weights, the soft-attention (SA) weighting method [10],\nand the residual-based attention (RBA) method [29]. The reported error is defined\nas the $$L_2$$ relative error:\n$$\\epsilon_{L_2} = \\frac{||u - u_E||_2}{||u_E||_2}$$\nwhere $$u$$ and $$u_E$$ are vectors of the predicted solutions and the reference solutions on\nthe test set, respectively.\nIn this section, we use the mFCN network architecture (see Appendix A) with\n6 hidden layers, each containing 128 neurons. The hyperbolic tangent function is\nemployed as the activation function. The network parameters are initialized using the\nKaiming Uniform initialization [40]. Specifically, for a module of shape (out_features,\nin_features), the learnable weights and biases are initialized from $$U(-\\sqrt{k}, \\sqrt{k})$$, where\n$$k = 1/in\\_features$$. We use only the Adam optimizer [36] for updating the training\nparameters. Although the L-BFGS optimizer [41] can fine-tune network parameters\nfurther, it is known for its significant drawbacks, including high computational cost\nand instability, particularly in large-scale problems. Therefore, we have chosen not\nto use the L-BFGS optimizer. All training procedures described in this section are\nimplemented using PyTorch [1]. Training computations were performed on a GPU\ncluster, with each individual training run utilizing a single NVIDIA\u00ae Tesla P100\nGPU. All computations were conducted using 32-bit single-precision floating-point\nformat."}, {"title": "4.1. 2D Helmholtz equation", "content": "The 2D Helmholtz equation is defined as follows:\n$$\\frac{\\partial u}{\\partial x^2} + \\frac{\\partial u}{\\partial y^2} + k^2 u - q(x, y) = 0, \\qquad (x, y) \\in [-1, 1]^2$$\n$$u(x, \\pm 1) = 0, \\qquad x \\in [-1, 1]$$\n$$u(\\pm 1, y) = 0, \\qquad y \\in [-1, 1]$$\nwith the manufactured solution $$u_E(x, y) = sin(a_1 \\pi x) sin(a_2 \\pi y)$$, where $$k = 1, a_1=1$$\nand $$a_2 = 4$$ is considered. $$q(x, y)$$ is the source term defined by\n$$q(x, y) = (k^2 - (a_1 \\pi)^2 - (a_2 \\pi)^2) sin(a_1 \\pi x) sin(a_2 \\pi y)$$.\nThe loss function is defined as follows:\n$$\\mathcal{L}(\\theta; w, s, \\Lambda) = s \\left(\\frac{\\lambda_R}{N_R} \\sum_{i=1}^{N_R} w^R_i R^2(x^R_i) + \\frac{\\lambda_B}{N_B} \\sum_{i=1}^{N_B} w^B_i B^2(x^B_i)\\right)$$\nwhere $$R$$ and $$B$$ represent the PDE operator and the boundary condition (BC) oper-\nator, respectively.\nThe choice of location of the training points and the BRDR training setup are\nprovided in Table 2. For fixed-weight training, the weights for both the boundary\nconditions (BC) and partial differential equations (PDE) are set to 1. For the soft-\nattention (SA) training setup, we follow the configuration given in reference [10]\nfor Adam training. The point-wise self-adaptive weights for BC and PDE are all\ninitialized using uniform sampling $$U(0, 1)$$, and the weights are updated with a fixed\nlearning rate of 0.005. For the residual-based attention (RBA) training setup, we\nuse the configuration provided in reference [29]. In this setup, the weights for BC\nare fixed at 100, and the point-wise self-adaptive weights for PDE are initialized at\n0. These weights are then updated with a decay rate of 0.9999, an offset of 0 and a\nlearning rate of 0.001."}, {"title": "4.2. 1D Allen-Cahn equation", "content": "WB\nThe evolution history of error", "follows": "n$$\\frac{W_B}{W_R} = \\frac{\\Lambda_B mean(W_B)}{\\Lambda_R mean(W_R)}$$\nThe error for all the adaptive methods (RBA, SA and BRDR, BRDR+) drops faster\nthan that for fixed weights, highlighting the advantages of adaptive weights. In the\nfirst 20,000 epochs, the error for Fixed, SA, and BRDR weights shows a very similar\ndecay speed, all of which are slower than that for RBA weights. This is because\nRBA manually sets the weights of BC to 100, causing the BC residuals to decay\nfaster initially. This also demonstrates that prediction accuracy is dominated by the\nBC residual rather than the PDE residuals for this problem. Despite this, the BRDR\nmethod gradually catches up with and surpasses the error of RBA as the number of\nepochs increases, because the average BC weight is rapidly and adaptively increased\nat the beginning. Additionally, we can manually set the BC weight constant to\n$$\\frac{\\lambda_B}{\\lambda_R} = 100$$, referred to as BRDR+. With this modification, the error for BRDR+\ndrops the fastest among all the weighting methods. For example, BRDR+ takes\nless than half the number of epochs to achieve the final error of RBA. As for the SA\nweighting method, the weight ratio of BC to PDE converges to about 2 in SA, making\nthe error and BC residuals relatively larger than those of RBA, BRDR, and BRDR+.\nSince the weights of the SA method are increased proportionally to the square of the\nresiduals and no predefined weight constant is applied to the BC loss, it is difficult\nfor the SA method to achieve a large weight ratio of BC to PDE. This is due to the\nfact that the BC residuals are much smaller than the PDE residuals. The statistical\nerrors and computational cost are given in Table 3. The computational costs of\nthe adaptive weighting methods ("}]}