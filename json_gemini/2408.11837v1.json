{"title": "MicroXercise: A Micro-Level Comparative and Explainable System for Remote Physical Therapy", "authors": ["Hanchen David Wang", "Nibraas Khan", "Anna Chen", "Nilanjan Sarkar", "Pamela Wisniewski", "Meiyi Ma"], "abstract": "Recent global estimates suggest that as many as 2.41 billion individuals have health conditions that would benefit from rehabilitation services. Home-based Physical Therapy (PT), faces significant challenges in providing interactive feedback and meaningful observation for therapists and patients. To fill this gap, we present MicroXercise, which integrates micro-motion analysis with wearable sensors, providing therapists and patients with a comprehensive feedback interface, including video, text, and scores. Crucially, it employs multi-dimensional Dynamic Time Warping (DTW) and attribution-based explainable methods to analyze the existing deep learning neural networks in monitoring exercises, focusing on a high granularity of exercise. This synergistic approach is pivotal, providing output matching the input size to precisely highlight critical subtleties and movements in PT, thus transforming complex AI analysis into clear, actionable feedback. By highlighting these micro-motions in different metrics, such as stability and range of motion, MicroXercise significantly enhances the understanding and relevance of feedback for end-users. Comparative performance metrics underscore its effectiveness over traditional methods, such as a 39% and 42% improvement in Feature Mutual Information (FMI) and Continuity. MicroXercise is a step ahead in home-based physical therapy, providing a technologically advanced and intuitively helpful solution to enhance patient care and outcomes.", "sections": [{"title": "I. INTRODUCTION", "content": "Estimates suggest that, globally, as many as 2.41 billion individuals have health conditions that would benefit from rehabilitation services, however, a person's access to reha- bilitation, and their ability to adhere to treatment may be hindered by many factors, including costs, travel needs and lost worktime to attend multiple on-site visits, and the patient's inability to perform their program independently. If a patient is not independent in their home exercise program, they may complete exercises incorrectly between on-site visits, potentially leading to unnecessary pain or slow recovery. Wearable technology that can monitor the patient's home program performance and provide real-time feedback on exer- cise quality would facilitate adherence and improve treatment outcomes. Advances in technology are urgently needed to develop innovative, accessible, and sustainable techniques that facilitate a person's participation in rehabilitation.\nExisting off-site monitoring systems can only detect the types of exercise performed or calculate calories burned, which are insufficient for capturing the quality of the exercise or assessing the patients' progress. Moreover, modern deep learning-based solutions for healthcare often do not explain their results sufficiently, making it difficult for patients and therapists to understand and trust the results. Artificial In- telligence (AI) techniques have seamlessly integrated into our daily lives, influencing many decisions, from mundane choices to critical healthcare recommendations. In particu- lar, the healthcare domain has seen a growing influence of AI, with systems being developed for recognizing various diseases such as skin, breast, and brain tumors [1]\u2013[3]. Its application in healthcare is particularly significant, given the increasing need for precise and efficient treatments. This is especially true in the domain of Physical Therapy (PT), where an intricate understanding of human motion is crucial [4], [5]. PT interventions\u2014including passive restorative, exercise, and advice\u2014aim to improve mobility, alleviate pain, and ultimately enhance patient outcomes. Traditional methods of evaluating and treating patients in PT often rely on the clinician's experience and observational skills, which could be subjective and lack personalization for large-scale ap- plications. The COVID-19 pandemic has further intensified the importance of PT, particularly for at-home exercises and rehabilitative care. Reflecting this, the PT domain is set to witness substantial growth, with projections suggesting a 17% increase in employment over the next decade [6], [7]. This rising demand further underscores the need for personalized Al solutions in remote PT.\nIn light of the expanding PT workforce, human activity recognition (HAR) has emerged as a key AI component for personalized treatment [8]. Specifically, utilizing lightweight sensor technology such as an inertial measurement unit (IMU), HAR is capable of identifying and categorizing various human motions and activities [9], [10]. In a PT context, the sensory data generated by IMU can monitor a patient's movements over time to provide quantitative, accurate traits. This can then inform the treatment plan, offering a more personalized approach to care and potentially leading to more effective and faster rehabilitation of patients.\nHowever, the adoption of AI-based HAR in clinical settings faces challenges, primarily due to the \"black box\" nature of many AI algorithms. While these models are effective in mak- ing predictions or classifications, they often lack transparency in how they arrive at these conclusions. This opacity can be a significant drawback in healthcare applications, where understanding the reasoning behind a diagnosis or treatment recommendation is crucial [11], [12]. This is where eXplain- able AI (XAI) comes into the picture. XAI aims to make the decision-making processes of AI models transparent and understandable, allowing clinicians and doctors to trust the technology and better integrate it into their practice.\nVarious techniques have been developed to achieve this level of transparency, primarily in the realm of attribution-based methods. Notable among these are Gradient-weighted Class Activation Mapping (Grad-CAM) [13], Saliency Maps [14], and Integrated Gradients (IG) [15]. These methods highlight the significance of individual input features in determining the model's final output. In essence, they offer a mapping that quantifies the contribution of each input attribute to the decision-making process. This category of techniques, often referred to as 'heatmap visualization' [16], allows for more transparent interpretations by revealing what features the model deems crucial in its computations."}, {"title": "A. Motivation", "content": "Two limitations in existing systems impact their utility in physical therapy applications, particularly, for shoulder PT. First, current XAI methods, such as heatmap visualization techniques, are often non-intuitive and not explainable for end-users, limiting their usefulness in real-world scenarios [17]. Second, these methods commonly provide a holistic view of activity but fall short in isolating specific moments (or micro-motions) that require user modification such as raising an arm higher during a shoulder abduction exercise in the first half of the exercise or asking users to slow down in the lowering arm part of the exercise [18]. These limitations necessitate more user-friendly and targeted X\u0391\u0399- heatmap approaches for enhancing the applicability of HAR models in shoulder PT [19]."}, {"title": "B. Challenges", "content": "The first substantial challenge lies in translating attribution- based methods into actionable insights for end-users. While these techniques, such as Saliency and IG, offer a way to \"interview\" the deep neural network model to understand its decision-making processes, they often don't translate easily into practical, real-world advice. A potential technique is the comparison of a current workout (referred to as the \u201csignal exercise\") and an example or ideal exercise (referred to as the \"anchor exercise\"), as presented by previous research utilizing spatiotemporal Siamese Neural Networks (SNN) [20]. However, even with such sophisticated models, given the heatmap visualization, the challenge remains: how do we translate these high-level comparisons into clear, actionable feedback for the end-user?\nThe second challenge is related to the intricate task of isolating and understanding micro-motions within physical activities. While breaking down exercises into smaller, more manageable components could be beneficial, doing so in a meaningful way that preserves the context of the overall exer- cise is not trivial. For example, directing a user to raise their arm higher during only the first half of a shoulder abduction exercise would require an acute focus on that specific micro- motions without losing sight of the larger activity."}, {"title": "C. Contributions", "content": "We create MicroXercise, an innovative system that leverages a micro-motion algorithm that generates comprehensive and presentable feedback, demonstrated in multiple modalities, including text, avatars, and video highlights, utilizing the capabilities of the existing neural network, particularly, on spa- tiotemporal SNN, with attribution-based methods for remote shoulder PT. This approach enriches the user's understanding and engagement, overcoming the non-intuitive nature of exist- ing heatmap visualization techniques.\nOur additional technical contribution is the development of a new multi-dimensional Dynamic Time Warping (DTW) model that works in synergy with existing attribution-based methods, specifically tailored to segment and analyze single- repetition exercise comparison results through existing neural networks. This fusion allows for the extraction of granular, micro-motion-level insights, thereby fine-tuning the feedback and making it more actionable for end-users in the physical therapy domain.\nOur experiment conducted a detailed evaluation of expla- nation methods using three metrics: monotonicity, feature mutual information (FMI), and continuity. We compared three attribution methods, including a modified version against an unmodified baseline. The results revealed significant improve- ments with the modified method. On average, FMI improved by approximately 39% with our modified approach. Regard- ing continuity, we observed an average decrease (indicating improvement) of about 42%. These findings demonstrate our experiment's enhanced interpretability and fidelity of the mod- ified attribution methods."}, {"title": "II. SYSTEM OVERVIEW OF MICROXERCISE", "content": "Our system aims to elevate adherence to Human Behavior Physical Therapy (HBPT) by specifically targeting user self- efficacy and enabling patient-driven care [21]. Self-efficacy is fundamentally an individual's confidence in their ability to successfully carry out actions that yield desired outcomes. In the context of HBPT, it serves as a pivotal factor influencing a patient's adherence to exercise routines and overall treatment. Our system addresses the prevalent challenge where users feel unsure in utilizing mobile health (mHealth) solutions. Leveraging advanced algorithms and micro-motion analysis, we transform complex sensor data from a deep learning model into easy-to-understand and actionable feedback. Designed specifically for shoulder PT patients who are working to maintain exercise routines developed in close collaboration with their therapists, our application seeks to support long- term practices rather than serving as a replacement for acute care or professional therapy in situations with higher risks.\nOur system adopts a three-layered architecture consist- ing of smartwatches, smartphones, and cloud computing. Smartwatches are responsible for real-time data collection, smartphones serve as the user interface providing interactive feedback, and cloud-based systems handle computational pro- cessing and algorithmic tasks. Within this system, we have developed three main modules: MicroXercise Monitoring (Sec. III-C), Micro-motion Syncing (Sec. III-B), and Generation of Explainable Feedback (Sec. III-D). These modules are intricately designed to meet our system's objectives: delivering actionable performance guidance and enhancing user self- efficacy, as visually represented in Figure 1.\nIn MicroXercise, this module leverages attribution-based methods, such as IG, Saliency, or DeepLIFT, to interpret our multitask SNN. It analyzes both the signal and anchor exercises to produce actionable and transparent outcomes. Next, acting as the core algorithmic component, Micro-motion Syncing employs signal processing and spatiotemporal DTW to scrutinize exercises at the micro-level. It compares user- generated signals with pre-established anchor exercises, using this data for subsequent exercise segmentation. Lastly, we transform the analytical results into both visual and textual feedback, making extensive use of avatar-generation methods.\nVisual and textual feedback are core components of the MicroXercise app, designed to offer users real-time insights into their performance and overall well-being. Visual feedback, demonstrated in Figure 1, utilizes real-time graphs and charts to display performance metrics. These graphical elements enable users to track and regulate exercise intensity relative to their anchor results. Complementing the visuals, textual feedback provides granular details, such as similarity scores to anchor exercises and range of motion variations in text. This information is synthesized to prevent information overload, translating complex IMU sensor data into actionable insights, as illustrated in the generated texts on the smartphone."}, {"title": "III. EXPLAINABLE EXERCISE PERFORMANCE QUANTIFICATION", "content": "As shown in Fig. 2, initially, users perform repetitions of an exercise. Each repetition is pre-segmented on the device, resulting in a set of signal exercises in light blue corresponding to individual repetitions. Alongside these, we have the anchor exercise in orange, considered the ground truth. This data then undergoes micro-motion syncing, involving primitive re- moval, adaptive DTW, and micro-segmentation. Concurrently, MicroXercise Monitoring is performed using a deep neural network, specifically spatiotemporal SNN, with attribution- based methods, generating an attribution or an importance heatmap of the two inputs. The output image from this process is then used for video generation using inverse kinematics and Levenberg-Marquardt algorithm. Once the video is created, we extract the important features as highlighted by the attri- bution score and incorporate them into the generated video, segmented into different phases of the exercise. This gives the user detailed, micro-level observational feedback on different exercise metrics."}, {"title": "B. Micro-motion Syncing Analysis", "content": "As illustrated in Fig. 2, this section focuses explicitly on the purple area of the diagram, representing the stages of primitive removal, adaptive DTW, and micro-segmentation. These processes are examined in the context of the overarching purpose diagram, moving from top to bottom.\n1) Primitive Removal: Primitive removal is a critical pro- cess in our system, aimed at eliminating noise in the data to enable accurate calculation of various metrics for a given time series in assigned exercises. This includes removing noise for precise measurement of metrics like the range of motion. Such noise can arise from factors such as sensor inaccuracies during data collection. For this purpose, we adopted two techniques: Butterworth low-pass filtering and moving average smoothing. The Butterworth low-pass filter was chosen for its smooth frequency response, effectively preserving the low-frequency components crucial to our analysis. High-frequency noise can significantly distort measurements. By applying this filter with a threshold frequency of 20 Hz, as suggested by [22], we ensure the retention of only those frequencies relevant to our exercise metrics.\nSubsequent to the initial noise reduction, we processed the data further using moving average smoothing [23]. This method aids in reducing random fluctuations and smoothing out short-term irregularities in the time series data. Sporadic spikes or drops that do not represent actual exercise perfor- mance are eliminated by averaging over a specified window.\n2) Adaptive DTW: In this part, we address the challenge of aligning data from different sources to enhance the inter- pretability and utility of the outputs from our SNN model. Our focus is on using DTW as a tool to align signals, particularly in the context of understanding the network's attributions.\nOur analysis primarily utilizes 6-axis input data, consisting of accelerometer and gyroscope measurements from a smart- watch. This decision is influenced by prior research, such as the studies by Burns et al. [4], and Weiss et al. [24], which effectively used these data dimensions for activity recognition and health monitoring. Despite the absence of magnetometer data, these studies demonstrated robust performance, which we aim to emulate and build upon.\nTo align the signals effectively, we adopted DTW for calculating the distance and path between two time series shown in Fig. 1, represented as matrices s and t. The algorithm computes a distance measure between these matrices, sum- ming the absolute differences between corresponding elements (across the 6-axis data), and is optimal in temporal data.\nThe significance of employing DTW in our study lies in its ability to bridge the gap between the raw input data and the attributions provided by the SNN. As shown in Figure 3, it provides a visualization of the algorithm we use for this purpose and includes a display of attributions heatmap. While the neural network operates as a black-box model, offering some insights into its internal workings, DTW provides a tangible means to understand how the input data correlates with the attributions generated.\n3) Micro-Segmentation: As described in Algorithm 2, this function applies a centered moving average to both s and t, computes the path using the DTW algorithm in Algorithm 1 between them, and then segments the aligned t sequence into micro-segments of length N. For each micro-segment, the function finds the element of s with the minimum distance to the micro-segment using the argmin function, which selects the minimum element from a list of distances computed as the absolute difference between corresponding elements s and t in multi-dimensions. Finally, the function returns a list res containing pairs of indices. Each pair corresponds to a point in s and a point in t that are closest at the beginning of each segment in t."}, {"title": "C. MicroXercise Monitoring", "content": "1) Multi-task Siamese Neural Network (SNN): Though we are not limited to using only one type of neural network, to incorporate a complete system, we utilize a comparative model of SNN to evaluate physical exercise quality. We adopt and follow the multi-task spatiotemporal SNN structure and implementation in this work [20]. The architecture of the SNN is a combination of LSTM, CNN, and attention mechanisms with two sub-identical networks. LSTM layers handle the sequential nature of sensor data, while CNN layers extract relevant features. The attention mechanism focuses on signifi- cant segments of the data, enhancing the model's interpretative capability. The network employs cosine similarity to measure the closeness of the input exercise to the standard or \"anchor\" exercise. Additionally, one sub-identical pipeline from SNN is outputting a classification score to have an absolute quality assessment.\nFor labeling, we rely on annotations from fitness experts. These labels indicate the correctness of exercise execution and serve as a reference for supervised learning. The model's performance is evaluated using Mean Absolute Error (MAE) and R-squared metrics, with Mean Squared Error (MSE) and Cross Entropy as the loss function, focusing on the similarity of the signal to the anchor exercises. This approach ensures that the SNN effectively discerns the quality of physical exercises, providing a reliable tool for fitness assessment.\n2) Attribution-based Methods: In our system, we aim to enhance model transparency and comprehensibility by incor- porating three distinct attribution techniques, each chosen for its unique strengths in analyzing and filtering data related to micro-motions. These methods are IG, Saliency, and Input X Gradient, and they are employed to assess and refine our model's focus on critical movement features.\nThe Integrated Gradients (IG) method, outlined by [15], excels in providing a detailed analysis of feature importance, crucial for examining micro-motions by quantifying each feature's contribution to model predictions. In contrast, the Saliency method, as described by [14], offers rapid evaluation, efficiently identifying key input features, thereby streamlining the feature filtering process. Furthermore, the Input X Gradient method, detailed by [25], is particularly effective in high- dimensional, sparse datasets, focusing on the most influential features to enhance the model's accuracy in micro-motion analysis.\nCollectively, these attribution techniques serve not just to test the model individually but also to refine the input data by emphasizing the most influential features for our micro- motion analysis. This approach ensures that the data fed into our model is of high quality and relevance, enabling more accurate evaluations as we further detail in Sec. IV.\n3) Attribution Extraction: Attribution extraction uses an attribution heatmap from attribution-based methods, wherein a top T threshold percentage is employed to identify the most important features. Furthermore, we normalize the attribution derived from both signal and anchor exercises collectively. In addition, we leverage the outcomes of micro-segmentation to align the top T percent attribution indices. For instance, if the top T percent attribution falls within the third segment, we opt to analyze the third segment rather than the indices.\nAdditionally, we utilize this result of threshold segmentation to modify the original attribution as we observe that most attribution results are noisy, but based on our method of comparing in the micro-motion, we can signify the signal data while making the anchor data the ground truth for the current comparison. We also further evaluate such an approach with baselines in Sec IV.\nFurthermore, from prior knowledge in the context of the range of motion, the most significant attributions are typically found in the middle of the data sample. This is because the middle region represents the highest degree of motion changes in the supervised learning model, which is logical given that the range of motion (ROM) model is trained to classify various motion ranges. However, this is not applicable if the neural network is trained and evaluated on stability. In this case, we do not assume the location and consider that multiple areas could be on the top T percentage of the attribution."}, {"title": "D. Generation of Explainable Micro-Motion Feedback", "content": "1) Signal Translation: In signal translation, we convert the analog value from signal space to physical space to make it more meaningful to users. For example, in a range of motion metric, the usefulness of an interpretation is determined by a degree of motion difference between the signal and anchor exercise. This implies that the data collected from the current exercise should be compared to the data collected from the anchor exercise.\nConsequently, Euler angle estimation [26] from accelerom- eter and gyroscope data is a crucial method to determine the orientation of an object in 3D space. Accelerometers can measure linear acceleration, whereas gyroscopes measure angular velocity. By integrating these measurements, it is possible to determine the orientation of an object in terms of Euler angles (roll, pitch, and yaw).\nAccelerometer readings are converted to meters per second squared by multiplying each axis by the standard gravita- tional acceleration constant (9.81 m/s\u00b2). Then trigonometric functions, specifically arcsine and arctangent, derive the pitch and roll angles directly from the normalized accelerometer data. However, the yaw angle cannot be calculated from accelerometer data alone, as additional information is required, such as magnetometer or gyroscope. However, this suffices as it can provide enough insight for exercises involving the difference in range of motion along the primary axis. By integrating the angular velocities over time with pitch and roll angles, the framework acquires the complete set of Euler angles utilized for the end users.\nBuilding on existing research, we propose a measure of stability that takes into account the physical context and characteristics of exercises. This measure, inspired by the work of Yan et al. [27], quantifies hand movement jerk over time, providing a nuanced and physically meaningful measure of stability. We further refine this measure, adopting the Normalized Jerk Score (NJS) proposed by Kitazawa et al. [28], which removes the influence of movement length and duration. The NJS, a unit-free metric, has proven effective in categorizing deviation from a smooth movement [29]. The new modified NJS is calculated as follows:\n$NJS = -log\\left(\\frac{1}{A^2} \\sum_{i=1}^{3} \\int (jerk_i)^2 dt\\right)$\nwhere A is the peak movement amplitude per axis, T is the total duration of the movement, $jerk_i$ is the jerk at i time step, or represents the second derivative of the position with respect to time, and dt is the one over sampling frequency, or time step between consecutive samples. By normalizing using both the movement's peak amplitude and its total duration, the jerk score is rendered dimensionless. This dimensionless- ness is crucial, as it facilitates a direct comparison between movements of diverse characteristics in stability.\n2) Micro Video Generation: Next, we present the micro video avatar generation system that utilizes IMU data from a smartwatch to reconstruct micro-motion shoulder movements during physical therapy exercises to emphasize the result of micro-motion analysis from attribution maps, as shown in Fig. 4. The system employs inverse kinematics to solve for the positions of the shoulder and elbow joints in a 3D space. We then use this information to compute the position of the wrist in space relative to a fixed reference frame. To reconstruct the motion of the shoulder and elbow joints in a 3D space, the avatar generation system utilizes a mathematical model of the human arm that includes the shoulder, elbow, and wrist joints. The model assumes that the shoulder joint is a ball- and-socket joint, while the elbow joint is a hinge joint. The angles between the segments of the arm are assumed to be constant, and the lengths of the segments are known.\nUsing the IMU data and the mathematical model of the arm, the system employs the Levenberg-Marquardt algorithm to solve for the positions of the shoulder and elbow joints. The algorithm minimizes the difference between the actual position and orientation of the end effector, which in this case is the wrist, and the desired position and orientation. The Gauss- Newton algorithm is used to solve for the optimal joint angles when the error between the actual and desired positions is small, while the steepest descent method is used when the error is large. This combination provides a balance between speed and accuracy in solving for optimal joint angles. The following equation can describe the algorithm:\n$J^T J \\Delta x + \\lambda I \\Delta x = -J^T f(x)$,\nwhere x is the vector of joint angles, f(x) is the vector of residuals between the measured and predicted joint positions, Jis the Jacobian matrix of partial derivatives of f(x) with respect to x, $\\Delta$x is the update vector for x, $\\lambda$ is the damping parameter, and I is the identity matrix.\nLastly, as shown in Fig. 4, our system features three dis- tinct visualization modes: Overall, Stability (STB), and ROM. These modes provide users with a side-by-side comparison of their exercise performance against the original anchor exercises. In this way, users can immediately look into how well they are doing in relation to supervised benchmarks.\n3) Text Generation: Building on the visual feedback mech- anism, our system incorporates a sophisticated text generation strategy to complement the visual insights. Notably, the same Figure 4 that shows the avatar-based replay also serves as an interface for real-time textual feedback. Our text generation leverages a template-based approach, allowing for concise, modifiable, and quick communication.\nTextual feedback in our system serves as an interactive and intuitive tool designed to guide users constructively. It acts as a valuable, real-time source of advice, providing granular insights into how users perform. For instance, as shown in Fig. 4(c), when a user sees \u201cThe degree difference is less than 5\", it highlights the technical part of precision in their movement, which potentially is useful to the therapists. Positive reinforcement is equally important as plain language, and messages such as \"This looks great. That means the similarity of the exercises compared to your anchor is very good!\" encourage and motivate users by acknowledging their progress. Furthermore, feedback like \u201cNo need to modify the way you do it\" provides affirmation and potential improve- ment, assuring users that their current method is effective. Overall, our system's textual feedback is designed to support, guide, and foster confidence in users, enabling them to make the most of their exercises and routines.\""}, {"title": "IV. EVALUATION", "content": "Assessing attribution methods is crucial to verify their effectiveness and applicability. Our MicroXercise system, an amalgamation of signal processing in micro-motion analysis and an attribution-based deep learning model, seeks to advance the saliency heatmap by presenting refined and nuanced attri- butions. We present a quantitative evaluation that provides an empirical foundation for our approach with defined metrics that focus on the objectives of achieving both fidelity and interpretability in the realm of attribution-based methods [11], [17], [30], [31]."}, {"title": "A. Dataset and Evaluation Setup", "content": "The dataset used in this evaluation is adapted from [20], which is consists of multiple shoulder physical therapy ex- ercises. The dataset is collected using consumer-grade iOS Apple Watches for three exercises. These exercises are chosen because they demonstrate repetitive nature, have clear start and end points, can potentially improve the body, and engage various muscle groups. With the supervision of exercise expert, the participants perform a number of sets of exercises with various range of motion and repetitions with variations of stability. The dataset includes data from 17 male and 14 female participants, aged between 18 and 44, including 3 participants with self-reported previous shoulder injuries.\nWe train the comparative deep neural networks to compare and interpret feedback, particularly using two exercises of shoulder abduction and forward flexion from the dataset, which contains 1,550 segmented one-repetition exercises. The shoulder abduction exercise is collected with 5 range of motions. The forward flexion is collected similarly with same range of motions.\nFor the model, every possible pair of inputs was methodi- cally generated. These pairs are associated with a discrete and continuous score of quality assessment, sourced from range- of-motion and stability labels, which established the target for the SNN. The data are split into 70% for training, 10% for validation, and 20% for testing in both range-of-motion and stability metrics.\nWe refine the attributions map, produced by attribution methods, using our Micro-Motion Syncing methods to produce a modified attribution map. As shown in Fig. 5, by integrating this into the attribution as a layer of prior knowledge, we essentially amplified the significance within crucial segments using a signal smoothing factor."}, {"title": "B. Evaluation Metrics", "content": "1) Fidelity: Within the realm of fidelity, monotonicity plays a essential role. The fundamental premise is to ensure that as the importance of a feature amplifies, so does its attribution, and vice-versa. This behavior is quantified by com- puting correlation coefficients, Spearman's rank correlation coefficient, between the feature importance and their corre- sponding attributions. A strong positive correlation implies a desirable monotonic behavior, attaching to the soundness of our explanations. Adopted by [32], the monotonicity metric is defined as\n$\\rho_s(a, e) = 1 - \\frac{6 \\sum (rank(a_i) - rank(e_i))^2}{n(n^2 - 1)}$\nwhere $\\rho_s$ represents the Spearman's correlation coefficient, a is a vector containing the absolute values of the attributions for each feature, denoted as a = (..., |ai|,...), and e is a vector containing the expected losses when considering each feature with other features held constant. The rank refers to the numerical ordering of each element within the flattened arrays of attributions and expected losses by their size.\n2) Interpretability: In transitioning to interpretability, it's critical to ensure that our method doesn't overly focus on specific features while also confirming that the explanation isn't unduly complex. Therefore, in interpretability, we want to focus on feature mutual information and continuity.\nFeature mutual information between the original feature sets and their corresponding explanations serves as an apt metric for this purpose. An optimal mutual information score indicates a harmonious blend of broadness and simplicity in our explanations [32].\n$I(x, \\alpha) = \\sum_{x \\in X, \\alpha \\in \\alpha} p(x, a) log \\frac{p(x, \\alpha)}{p(x)p(a)}$\nWhere p(x, a) is the joint probability distribution of x and $\\alpha$, p(x) and p(a) are the marginal probability distributions of them, respectively. A high value of I(x, a) indicates that the extracted features (in this case, attributions) retain a significant amount of information from the original input, thus ensuring fidelity in our system. Lastly, we estimated mutual information using a histogram-based approach with 200 bins, because the goal of assessing feature-attribution fidelity is informative alignment and efficiency in multivariate time series data."}, {"title": "C. Results", "content": "Given the extensive size of our dataset, evaluating the performance of attribution methods on each sample would be computationally expensive and time-consuming. This com- plexity is particularly exacerbated in our case, where the input data consists of continuous signals. Perturbation-based attribution methods, which require manipulations at each data point, significantly increase computational costs.\nTo mitigate this, we adopted a random sampling strategy of selecting 100 random sample pairs for each subject under study. This sub-sampling approach allowed us to perform a comprehensive yet manageable evaluation."}, {"title": "V. RELATED WORK", "content": "The landscape of remote health interventions is diverse, with several promising technologies emerging in recent years. A systematic review by Grona et al. [34] examined 17 full- text articles applying real-time physical therapy interventions through secure videoconferencing. The results showed gen- eral patient satisfaction but highlighted the need for more rigorous study designs. Similarly, Pietrzak et al. [35] revealed the effectiveness of internet-based technologies in providing community-based self-management and rehabilitation inter- ventions for osteoarthritis patients. On the other hand, mHealth apps for remote health, such as the one proposed by Burns et al. [4], focus on classifying exercises without considering the quality of the exercise execution. Mork et al. [36] outlined a protocol for designing and implementing a decision support system called selfBACK, which was aimed at promoting self-management of nonspecific low back pain among patients, with their system of case-based reasoning technology. Smit- tenaar et al. [37] investigated the effects of the Hinge Health 12-week digital care program on chronic knee pain, function, surgery interest, and satisfaction. The care program included sensor-guided physical exercises, weekly education, activity tracking, and psycho-social support, such as personal coaching and cognitive behavioral therapy.\nWhile the advancements in digital health interventions are noteworthy, a significant challenge persists in the form of transparency and explanation of the provided recommenda- tions. For instance, the selfBACK system by Mork et al. [36] doesn't readily make the reasoning behind its recommenda- tions apparent to users. Similarly, while the Hinge Health DCP, as discussed by Smittenaar et al. [37], is effective in improving pain and function and in decreasing surgery interest, it fails to offer XAI feedback. Further, reviews of existing apps underscore the deficiencies in current solutions. For instance, research by Dantas et al. and Agnew et al. [38], [39] revealed a dearth of functional, user-centered tools for Systemic Lupus Erythematosus patients, with most apps offering only partial solutions. A review by Carvalho et al. [40] found that mHealth technologies for managing spine disorders in Brazilian online app stores exhibited acceptable to inadequate quality."}, {"title": "B. Attribution-based Explainable AI", "content": "In the domain of XAI, attribution-based methods have gained significant attention for their ability to interpret com- plex models by assigning importance to input features. Notable techniques include Grad-CAM [13], which utilizes gradient- based localization to highlight significant regions in input im- ages. Its primary advantage lies in producing high-resolution and class-discriminative visualization, making it suitable for tasks where spatial localization is crucial. Integrated Gra- dient [15] offers a more axiomatic approach, providing a path integral over the model's gradients to delineate feature importance. It adheres to foundational axioms like sensitivity, implementation invariance, and completeness, which makes it widely applicable beyond image-based models to even struc- tured data. DeepLIFT (Deep Learning Important FeaTures) [41] contrasts the activation of each neuron to a 'reference activation' to compute the 'contribution' score of each feature. Input X Gradient [25] explores the interaction between input and gradient during backpropagation, identifying features that significantly contribute to the output. It can be a simpler yet insightful method, especially when computational resources are limited."}, {"title": "C. Feedback and Visualization Mechanisms", "content": "The application of wearable devices and XAI in healthcare has demonstrated noteworthy advancements across diverse medical domains. Frade et al. employed wearable devices and machine learning to estimate cardiovascular fitness, offering a modern substitute for traditional cardiopulmonary exercise testing [42]. Their use of Shapley values for attribute im- portance brings a layer of interpretability to their models [43]. Likewise, Arrotta et al. presented DeXAR, an innovative technique for recognizing activities of daily living in smart- home settings [44]. They employed attribution methods such as Grad-CAM [13] based on CNNs to translate chronologi- cal activities into a spatial representation, demonstrating the efficacy of white-box XAI methods.\nBuilding on the necessity for transparent decision-making in healthcare, Biswas et al. argued for explainability in AI systems when dealing with Autism Spectrum Disorder datasets [45]. Yang et al. furthered the XAI discourse by proposing a multi-modal and multi-center data fusion approach for weakly supervised learning applications in healthcare [46]. Their work targets the 'black-box' nature of deep learning algorithms, advocating for clearer understanding of AI-driven decisions.\nSlijepcevic and others conducted a thorough evaluation of attribution-based methods in clinical gait analysis, aiming to understand their behavior across various deep learning models [19]. Their research sheds light on the value of XAI methods from a clinician's perspective.\nWhile these advancements signify promising progress, a common limitation is their focus on global or macro-level ex- planations. Unlike these approaches, our MicroXercise system leverages IMUs in the realm of remote physical therapy. By targeting micro-motions, we aim to provide highly detailed and personalized feedback, thereby addressing the gaps in existing XAI methodologies and significantly enhancing the user's therapeutic experience."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "In"}]}