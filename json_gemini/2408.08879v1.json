{"title": "SHARP-Net: A Refined Pyramid Network for Deficiency Segmentation in Culverts and Sewer Pipes", "authors": ["Rasha Alshawi", "Md Meftahul Ferdaus", "Md Tamjidul Hoque", "Kendall Niles", "Ken Pathak", "Steve Sloan", "Mahdi Abdelguerfi"], "abstract": "This paper introduces Semantic Haar-Adaptive Refined Pyramid Network (SHARP-Net), a novel architecture for semantic segmentation. SHARP-Net integrates a bottom-up pathway featuring Inception-like blocks with varying filter sizes (3 \u00d7 3 and 5 \u00d7 5), parallel max-pooling, and additional spatial detection layers. This design captures multi-scale features and fine structural details. Throughout the network, depth-wise separable convolutions are used to reduce complexity. The top-down pathway of SHARP-Net focuses on generating high-resolution features through upsampling and information fusion using 1 \u00d7 1 and 3 \u00d7 3 depth-wise separable convolutions. We evaluated our model using our developed challenging Culvert-Sewer Defects dataset and the benchmark DeepGlobe Land Cover dataset. Our experimental evaluation demonstrated the base model's (excluding Haar-like features) effectiveness in handling irregular defect shapes, occlusions, and class imbalances. It outperformed state-of-the-art methods, including U-Net, CBAM U-Net, ASCU-Net, FPN, and SegFormer, achieving average improvements of 14.4% and 12.1% on the Culvert-Sewer Defects and DeepGlobe Land Cover datasets, respectively, with IoU scores of 77.2% and 70.6%. Additionally, the training time was reduced. Furthermore, the integration of carefully selected and fine-tuned Haar-like features enhanced the performance of deep learning models by at least 20%. The proposed SHARP-Net, incorporating Haar-like features, achieved an impressive IoU of 94.75%, representing a 22.74% improvement over the base model. These features were also applied to other deep learning models, showing a 35.0% improvement, proving their versatility and effectiveness. SHARP-Net thus provides a powerful and efficient solution for accurate semantic segmentation in challenging real-world scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "ACCURATE detection and segmentation of defects in culverts and sewer pipes is crucial for effective infras- tructure management, playing a vital role in ensuring the safety and integrity of underground utilities [1]. Undetected defects can lead to severe consequences, including structural failures, increased maintenance costs, and environmental haz- ards. Therefore, automating and enhancing defect detection through advanced computer vision techniques presents signif- icant opportunities for improving infrastructure management and safety [2]. Traditional defect detection methods involve manual in- spection and assessment, which is time-consuming and prone to human error. Advanced computer vision techniques, like semantic segmentation, offer potential to automate these pro- cesses [3]. Semantic segmentation assigns pixel-level labels to objects or regions in an image, making it a powerful tool for understanding and analyzing visual scenes [4], [5]. This tech- nique is well-suited for culvert and sewer systems, enabling more accurate defect detection, assessment, and maintenance planning. Despite its potential, applying semantic segmentation to culvert and sewer pipe inspection presents several challenges [6], [7]. The visual characteristics of these environments are highly diverse, with variations in scale, orientation, appear- ance, and environmental conditions such as occlusions and lighting changes [8]. Moreover, the datasets available for training models in this domain are often limited and imbal- anced, making it challenging to achieve high performance with standard segmentation approaches [9]. Current solutions for defect detection in these contexts often fall short due to their inability to handle the full complexity of real-world environments. Traditional models may not ade- quately address variations in defect types, pipe materials, and environmental conditions. In response to these challenges, we propose SHARP-Net (Semantic Haar-Adaptive Refined Pyra- mid Network), an innovative approach designed to tackle the complexities inherent in semantic segmentation tasks involving culverts and sewer pipes. SHARP-Net combines hierarchical feature representations extracted by Feature Pyramid Networks (FPN) with advanced enhancements in feature extraction to improve object segmentation and localization accuracy. By in- tegrating multi-scale feature maps, sparsely connected blocks, and fine-tuned Haar-like features, SHARP-Net aims to achieve superior performance in accurately detecting defects while maintaining computational efficiency (in terms of number of parameters). In addition to its performance on our dataset, we eval- uated SHARP-Net on another benchmark dataset to assess its generalizability across different contexts. This evaluation demonstrated that SHARP-Net maintains its effectiveness and robustness, achieving competitive results on diverse datasets and confirming its capability to handle a wide range of semantic segmentation tasks beyond the specific culvert and sewer defect domain."}, {"title": "II. RELATED WORK", "content": "Various architectures have been developed for semantic segmentation, with prominent approaches including bottom-up top-down networks like FPNs and encoder-decoder networks (EDNs) like U-Net [10]\u2013[12]. FPNs efficiently address multi- scale feature extraction by constructing a hierarchical pyramid of feature maps at different resolutions, integrating contextual information to enhance robustness and accuracy. Lin et al. [10] demonstrated the efficacy of FPNs in object detection, utilizing a ResNet backbone trained on ImageNet [13] to extract hierarchical features through bottom-up and top-down pathways. Conversely, EDNs like U-Net efficiently capture spatial de- pendencies and preserve high-resolution features through skip connections, which makes them highly effective for precise object localization [14]. Variants such as the Convolutional Block Attention Module (CBAM) [15] and Attention Sparse Convolutional U-Net (ASCU-Net) [16] further enhance U- Net's performance. CBAM improves U-Net by adding atten- tion mechanisms that refine feature extraction in two stages: channel attention emphasizes important feature channels, and spatial attention focuses on relevant regions within the fea- ture maps, resulting in more precise segmentation. ASCU- Net integrates attention mechanisms with sparse convolutional layers to handle irregular and sparse features more effectively. Its attention module dynamically prioritizes important features while the sparse convolutions reduce computational complex- ity, thereby enhancing the model's efficiency with complex and varied datasets. Vision Transformers (ViTs) have become a leading method in computer vision, especially for tasks like image classifi- cation and object detection, due to their use of self-attention mechanisms that capture global dependencies across image patches [17]. SegFormer [18] adapts this transformer archi- tecture for semantic segmentation. It employs a transformer encoder to capture global context and relationships within the image, overcoming the limitations of traditional convolutional methods. During the decoding phase, SegFormer uses dense layers to create detailed pixel-level segmentation masks. This approach leverages transformers' ability to maintain global context while ensuring accurate spatial representation, making it effective for complex segmentation tasks. Encoder-Decoder Networks (EDNs) offer precise localiza- tion but struggle with varied object scales and complex spatial arrangements [19], [20]. FPNs handle multi-scale objects well but may not effectively address class imbalance [21]. Vision Transformers (ViTs) capture global dependencies but can be computationally intensive and may miss fine-grained details. Applying these existing architectures directly to our diverse culvert-sewer defect dataset may be suboptimal, necessitating a tailored approach to address the specific challenges of varied defect types, sizes, and shapes. Recent work in sewer and culvert inspection using deep learning has highlighted some specialized approaches to these specific challenges. For instance, several studies have adapted convolutional neural networks (CNNs) and EDNs to detect and classify defects in sewer systems. Zhang et al. [22] developed a deep learning framework that utilizes multi-scale feature extraction and data augmentation to address the issue of imbalanced defect types in sewer inspections. Similarly, Lee et al. [23] proposed an automated system that integrates CNNs with domain-specific pre-processing techniques to enhance defect detection accuracy in culvert inspections. Despite these advancements, current methods struggle to handle the diverse and complex nature of defects across varied environmental conditions. This paper presents a new architecture designed to address the challenges identified in current semantic segmentation approaches. We propose a technique to improve deep learning models and speed up their training. We tested our model's effectiveness using our dataset for segmenting culvert and sewer pipe defects, and a benchmark dataset to evaluate its versatility. Section III provides a comprehensive overview of the model's structure."}, {"title": "III. SHARP-NET: SEMANTIC HAAR-ADAPTIVE REFINED PYRAMID NETWORK", "content": "This section is divided into three subsections: Section III-A discusses the architecture of SHARP-Net's base model, ex- cluding Haar-like features. Section III-B provides a compre- hensive analysis of the architectural innovations and ablation studies conducted to develop the proposed model. It includes expanded results and insights into the various modifications explored. Section III-C focuses on the integration of Haar-like features, detailing their extraction process and incorporation into the SHARP-Net model."}, {"title": "A. SHARP-Net Base Architecture", "content": "The proposed model represents a significant advancement over the original FPN by incorporating an enhanced inception- like block within the bottom-up pathway. This addition im- proves the model's ability to learn diverse and fine-grained features essential for accurate image analysis. Additionally, the use of depth-wise separable convolutions reduces model complexity while enhancing its ability to capture detailed information effectively. The architecture is structured around two pathways, each playing a crucial role in feature refinement:\nBottom-Up Pathway: This pathway utilizes inception- like blocks to enhance the model's ability to localize and detect objects in input images. These blocks process feature maps using a combination of filters with varying sizes (3 \u00d7 3 and 5 \u00d7 5) and parallel max-pooling layers. Multiple filter sizes capture a wide range of spatial information for objects of different scales. Specifically, 3 \u00d7 3 filters capture fine details and textures crucial for detecting smaller objects or subtle features. Conversely, 5 \u00d7 5 filters capture broader features essential for recog- nizing larger objects or structures. Parallel max-pooling layers help the model retain spatial hierarchies, enhancing robustness to object position variations. Depth-wise separable convolutions (depth-wise followed by point-wise convolutions) improve the model's effi- ciency. This approach reduces parameters and compu- tational complexity without compromising performance. This decomposition enhances computational efficiency and allows for a more flexible and fine-grained analysis of input features. The depth-wise convolution applies a single filter to each input channel separately, capturing spatial features while maintaining channel independence. The point-wise convolution combines the outputs of the depth-wise convolution by applying a 1 \u00d7 1 convolution, effectively mixing information across different channels. This approach reduces parameters and computational complexity without compromising performance. Max-pooling with a stride of 2 is used to manage the spatial dimensions of the feature maps. This operation reduces the spatial resolution of the feature maps as they pass through the network.\nTop-Down Pathway: The top-down pathway com- plements the bottom-up pathway. It generates higher- resolution features through upsampling operations and feature fusion. It starts with a 1 x 1 convolution to reduce the channel depth of the feature maps to 128, aligning it with the depth of the final bottom-up layer. This reduction maintains consistency between the feature maps from both pathways, facilitating integration during the fusion process. Each subsequent layer in the top-down pathway is up- sampled by a factor of 2, which increases the spatial resolution of the feature maps. After upsampling, the higher-resolution features are merged with the corre- sponding feature maps from the bottom-up pathway using a 1 \u00d7 1 convolution. This combines the refined top-down features with the contextually rich, lower-resolution fea- tures, ensuring alignment in channel depth for seamless integration. To address aliasing effects during merging and preserve fine details, a 3 \u00d7 3 depth-wise separable convolution is applied. This layer helps maintain sharp transitions and complex details in the feature maps.\nCommon Classifier: A shared classifier across all output feature maps ensures consistency with a 128-dimensional output channel configuration. This facilitates efficient decision-making across diverse image contexts while optimizing computational resources. The design of the Bottom-Up Pathway efficiently detects and localizes objects of varying sizes in input images. It uses inception-like blocks, depth-wise separable convolutions, and max-pooling operations. The top-down pathway refines and enhances the spatial resolution of the features, ensuring detailed and accurate output. Figure 1 visually illustrates the architecture, highlighting the strategic integration of diverse filters and efficient feature handling."}, {"title": "B. Architectural Evolution: From FPN to SHARP-Net", "content": "SHARP-Net evolved from extensive testing, incorporating key advanced elements into the FPN framework. This sec- tion details architectural enhancements to the original FPN, focusing on improving semantic segmentation performance. We aimed to find and apply the best methods to improve model accuracy and performance. Here are the key architectural changes from FPN to SHARP-Net:\nInception Block and Residual Connections: We en- hanced the FPN's Bottom-Up pathway by integrating Inception blocks and residual connections. This modi- fication improves multi-scale feature extraction by al- lowing simultaneous processing of information through multiple filter sizes, capturing features at various scales. Residual connections improve deep network training by easing gradient flow and reducing vanishing gradients. This enhancement to the original FPN increased the IoU score to 0.74932, signifying better feature extraction and representation.\nFactorized Inception Block: We improved computa- tional efficiency by using a factorized Inception block, which breaks down large convolutions into smaller oper- ations like 1 \u00d7 1 and 3 \u00d7 3 convolutions. This approach reduces computational demands and model size while preserving performance. Although slightly less effective than the full Inception block, the factorized version still outperformed the original FPN, achieving an IoU of 0.71863. This result highlights the trade-off between efficiency and performance.\nFPN with Atrous Convolutions: We integrated atrous convolutions into the FPN framework to expand the model's receptive field without increasing parameters or sacrificing spatial resolution. This aimed to enhance the capture of contextual information crucial for semantic segmentation, improving multi-scale feature extraction and preserving fine-grained details. Atrous convolutions achieve this by inserting spaces between kernel ele- ments, allowing for larger receptive fields in a single operation. However, this approach presented challenges, including increased computational complexity, potential feature sparsity with large dilation rates, and grid effects in the output. To mitigate these issues, we experimented with various dilation rates and hybrid approaches com- bining standard and atrous convolutions. Despite the theoretical advantages and our efforts to optimize their implementation, the incorporation of atrous convolutions did not yield significant performance improvements. This underscores the complexity of architectural design in deep learning and the importance of empirical validation.\nFPN with Self-Attention Mechanisms: Self-attention, a key feature of Transformer models, allows the system to prioritize relevant parts of input sequences, capturing long-range dependencies and global context. It dynam- ically computes weighted representations, focusing on important information while ignoring less relevant parts. However, when integrated with atrous convolutions in the FPN model, this approach yielded a lower IoU of 0.644. This suggests that for this specific dataset, self- attention's ability to capture global dependencies did not significantly improve model performance, possibly due to challenges in combining self-attention with FPN or the dataset's unique characteristics.\nFPN with Attention Gates and Squeeze-and- Excitation Blocks: This configuration enhances FPN with Attention Gates and Squeeze-and-Excitation (SE) Blocks. Attention Gates dynamically highlight crucial regions in feature maps, focusing the network on relevant information. SE Blocks recalibrate channel-wise feature responses, capturing interdependencies between channels and improving feature representation. The combination of these techniques resulted in an improved IoU score of 0.75914, demonstrating enhanced accuracy and robust- ness in semantic segmentation tasks. This integration ef- fectively prioritizes important features while suppressing noise, leading to better overall performance. SHARP-Net emerged as the result of our FPN modifica- tions. The key innovation, an Inception-like block with depth- wise separable convolutions, significantly improved accuracy and robustness while maintaining computational efficiency. This approach optimally balances model complexity and per- formance, addressing semantic segmentation challenges in complex infrastructure imagery. SHARP-Net's architecture enhances fine-grained detail capture and global context under- standing, advancing semantic segmentation for infrastructure analysis and related fields."}, {"title": "C. Haar-Like Feature Injection", "content": "To improve SHARP-Net's performance, we incorporated Haar-like features extracted from our dataset. While deep learning models often reduce the need for manual feature engi- neering, domain-specific features can be beneficial, especially with limited data, class imbalance, or few classes, as in our ten-class dataset [24]. Haar-like features, consisting of simple rectangular patterns, are effective for edge detection, line iden- tification, and texture analysis. These computationally efficient features complement SHARP-Net's deep learning capabilities, potentially addressing challenges in defect segmentation for culvert and sewer pipe imagery. Our Haar-like feature implementation for culvert and sewer pipe imagery focused on three key aspects: 1. Line detection: We used vertically elongated rectangles to capture the predom- inant vertical structures. 2. Edge detection: Symmetric win- dows (squares or similar-sized rectangles) were employed to identify sudden intensity or color changes at object boundaries. 3. Diagonal detection: A diagonal line detector was added to identify defects with both horizontal and vertical components. This comprehensive approach, illustrated in Figure 2 (second row), enhances SHARP-Net's ability to detect various defects [25], [26]. Haar-like features and cascade classifiers perform best with power-of-2 window sizes, as shown by Viola and Jones [27]. We tested various power-of-2 window sizes and Haar feature types on our dataset, using Peak Signal-to-Noise Ratio (PSNR) to assess image quality and feature detection accuracy [28]. Our analysis revealed that larger window sizes generally yielded higher PSNR scores, indicating better detection of sharp features crucial for defect identification. We found opti- mal window sizes of (4,2), (4,4), (8,4), and (16,4), balancing detection accuracy and computational efficiency. For detailed performance metrics and analyses, see Appendix A. After determining optimal window sizes, we conducted a feature selection process to ensure high-quality, diverse Haar- like features. We used Peak Signal-to-Noise Ratio (PSNR) to measure image similarity, with values above 20 indicating high similarity. To maintain diversity and reduce redundancy, we retained features with distinct PSNR values while excluding those with PSNR values of 18 or higher, as shown in Table I. We then refined the selected features using annotated masks from our dataset to focus on regions of interest, improving detection precision. Figure 2 illustrates the complete process, including Haar-like filter application, feature extraction, and mask-based refinement. This approach ensures that the Haar- like features in SHARP-Net are optimized for culvert and sewer pipe defect detection, potentially enhancing the model's performance and generalizability."}, {"title": "IV. DATASETS", "content": "This section is divided into two parts. Section IV-A details the development and characteristics of the Culvert-Sewer Defects dataset, created for this study. Section IV-B introduces the benchmark DeepGlobe Land Cover Classification Dataset, used to evaluate SHARP-Net's performance and generalizabil- ity."}, {"title": "A. Culvert-Sewer Defects Dataset", "content": "In this subsection, we discuss the process of collecting in- spection videos, converting them into frames, and performing pixel-wise annotation to create our 5000-image dataset.\n1) Data Collection and Preprocessing: We curated a com- prehensive dataset comprising 580 annotated underground infrastructure inspection videos from two distinct sources. These videos encompass a wide range of real-world conditions encountered in both culverts and sewer pipes. The diversity in our dataset is substantial, capturing variations in materials, shapes, dimensions, and imaging environments that are typical of inspection scenarios. This ensures that our dataset is repre- sentative of the challenges faced during actual inspections. Each video is accompanied by a detailed report prepared by skilled technicians. These reports document the types and locations of deficiencies observed throughout the inspections. To facilitate detailed analysis, we partitioned the videos into discrete frames, selecting intervals ranging from 4 to 10 seconds. This segmentation yielded approximately 5970 frames, with each frame corresponding to a specific deficiency as described in the accompanying report. Each image is time- stamped to the exact second, allowing for precise identification of the deficiency's location within the pipe according to the report. The resulting dataset, though extensive, presents a significant challenge due to the imbalanced distribution of deficiencies. Certain classes of deficiencies are significantly underrepresented, posing a challenge for model training and evaluation. This imbalance reflects the natural occurrence of various deficiencies in real-world inspection scenarios, adding another layer of complexity to the dataset. 2) Pixel-wise Annotation for Semantic Segmentation: To prepare the dataset for training semantic segmentation models, it was essential to understand the specific requirements of the task. We opted for semantic segmentation over other methods, such as object detection or classification, due to its pixel-level precision. This precision allows for the identification of defects and features across the entire image, providing detailed spatial information. Consequently, semantic segmentation facilitates a comprehensive analysis of culverts and sewer pipes, ensuring that every part of the infrastructure is inspected thoroughly. To achieve fine-grained semantic segmentation, skilled an- notators manually outlined each deficiency instance within the video frames, generating precise pixel-level masks to serve as ground truth. This level of detail is crucial for accurately identifying and categorizing deficiencies at the pixel level, facilitating the development and evaluation of robust segmentation algorithms. We categorized the semantic segmentation masks into nine common structural deficiency classes. The dataset exhibits sig- nificant class imbalance, with some classes being much more prevalent than others. The corresponding Class Importance Weights (CIW) are detailed in Table II. We employed the LabelMe tool to annotate the extracted video frames, forming our Culvert-Sewer Defects dataset. Each annotated class is color-coded according to the US NASSCO's pipeline assessment certification program (PACP) guidelines [29]. A professional civil engineer assigned impor- tance weights to each deficiency class based on their economic and safety impacts, which were normalized to prioritize learn- ing during model training and used for Frequency-Weighted IoU (FWIoU)."}, {"title": "B. DeepGlobe Land Cover Classification Dataset", "content": "The satellite image benchmark datasets used in this study are from the DeepGlobe challenge [30]. The datasets are de- rived from the DigitalGlobe Vivid+ collection, which focuses on rural areas. It includes seven land cover classes: agriculture land, urban land, rangeland, water, barren land, forest land, and unknown. Urban land consists of built-up areas with human artifacts; agriculture land includes farms, croplands, orchards, vineyards, and horticulture zones; rangeland is non- forest, non-farm green spaces and grasslands; forest land has at least 20% tree crown density with clear cuts; water covers rivers, oceans, lakes, wetlands, and ponds; barren land includes mountains, rocks, deserts, beaches, and vegetation- free zones; and unknown areas are obscured by clouds or unclassifiable. The dataset has an online leaderboard and test metrics evaluated on hold-out test images. It is divided into three subsets: 803 training images, 172 test images, and 171 validation images. The test and validation sets consist of unlabeled images, about 30% of the dataset. For the comparative analysis, only the annotated training samples were used, further divided into three segments for comprehensive evaluation and model validation."}, {"title": "V. EXPERIMENTAL SETUP AND TRAINING PROTOCOL", "content": "In this section, we provide an overview of the methodologies and parameters utilized in the development and training of our model. We detail the evaluation metrics employed, the optimization strategies and loss functions applied, as well as other critical aspects of the implementation, including training procedures, hardware and software configurations.\nMetrics Used for Evaluation: To evaluate the performance of our model in the semantic segmentation task, we employed several metrics, including Intersection over Union (IoU), Frequency-Weighted IoU (FWIoU), F1- Score, Balanced Accuracy, and Matthews Correlation Coefficient (MCC).\nOptimization and Loss Functions: For the optimization of our model, we used the Adam optimizer with a learning rate of 10-3. Adam is an adaptive learning rate optimization algorithm that has been shown to work well in practice for many deep learning models. It combines the advantages of two other popular optimizers: AdaGrad, which works well with sparse gradients, and RMSProp, which works well in online and non-stationary settings. For the loss function, we employed the categorical cross- entropy loss. This loss function is particularly suitable for multi-class classification problems, as it measures the performance of a classification model whose output is a probability value between 0 and 1, which necessitates the use of one-hot encoding for our labels. The categor- ical cross-entropy loss calculates the difference between the true label and the predicted probability distribution, penalizing the model more heavily for larger errors. This helps guide the model to make more accurate predictions."}, {"title": "VI. RESULTS AND DISCUSSION", "content": "This section evaluates our proposed model's performance against leading baseline and state-of-the-art semantic segmen- tation architectures. We analyze various metrics and organize our findings into the following subsections:\nA. Comparison with Baseline Architectures We compared our base SHARP-Net (without Haar-like features) to several models, as shown in Table III. The FPN model in our comparison uses a ResNet backbone pretrained on ImageNet and fine-tuned on our dataset to adapt to its specific characteristics. We tested SegFormer-b0 and SegFormer-b5 models, both with and without ImageNet pretraining. This approach, also applied to the original FPN, allowed us to assess the impact of pretraining on model performance across different architec- tures. Figure 3 shows a visual analysis of the models evaluated in our study. This analysis is crucial for understanding the mod- els' performance in semantic segmentation tasks, particularly in capturing fine-grained details. U-Net and CBAM U-Net have limitations in reconstructing images despite accurately identifying the root. This is due to the architecture's struggle to preserve fine-grained spatial information through the encoder-decoder pathway. This leads to an 18.63% decrease in Intersection over Union (IoU) scores compared to our proposed approach, especially in high- resolution feature preservation areas. The SegFormer models (SegFormer-b0 and SegFormer-b5) consistently show visual artifacts in their output images. This is due to the use of dense layers in the decoder section. Our results suggest a trade-off in fine detail preservation, despite excelling in capturing global context. Quantitatively, our model has a 20.51% higher IoU score compared to the SegFormer MiT-B0 models. Our model excels in root image reconstruction, capturing fine root details for accurate and visually coherent reconstruc- tions. This improvement is attributed to our model's feature pyramid network (FPN) architecture, which combines multi- scale feature representations [Cite]. The integration of Haar- like features enhances the model's edge and texture detection for accurate root segmentation. Our model achieves a 7.24% improvement in IoU over the next best performing model (ASCU-Net). Ablation studies show that incorporating Haar-like features contributes to a 22.74% increase in IoU, demonstrating a significant improve- ment in segmentation accuracy. These results highlight the effectiveness of our proposed architecture in handling complex image reconstruction tasks, especially those requiring the preservation of intricate details. The superior performance is visually and quantitatively sig- nificant, demonstrating the robustness of our approach across various segmentation quality metrics."}, {"title": "B. Model Efficiency and Computational Performance", "content": "The proposed model is remarkably efficient, with only 1.32 million parameters, representing a 19-24 times reduction compared to baseline models (Table V). This reduction has important implications for model performance and applicabil- ity. The dramatic decrease in parameter count reduces compu- tational complexity, crucial in resource-constrained environ- ments like edge devices or mobile platforms with limited com- putational power and memory. Our lean architecture enables faster inference times and lower memory footprint, making it suitable for real-time applications in fields like autonomous vehicles, mobile health diagnostics, or on-site infrastructure inspection. The reduced parameter count reduces the risk of overfitting on smaller datasets. With fewer parameters, the model is less likely to memorize training data and more likely to generalize well to unseen examples. This is valuable in domains with scarce or expensive large annotated datasets, such as special- ized medical imaging or rare defect detection in industrial applications. The model's efficiency affects training time and energy consumption. It needs less resources and time to train with fewer parameters, potentially reducing the carbon footprint of model development. This aligns with the emphasis on sustainable AI and green computing in the ML community. Our model maintains competitive performance, despite the reduced parameters. This suggests that the architecture effi- ciently captures essential task features, eliminating redundant or less informative parameters. Achieving high performance with fewer parameters underscores the effectiveness of our design choices, including depth-wise separable convolutions and Haar-like features. Our proposed model's efficiency offers benefits in com- putational performance, generalization ability, and practical applicability across various scenarios with computational con- straints, characterized by its reduced parameter count. This efficiency, coupled with the model's performance, positions it as a valuable contribution to semantic segmentation, especially for applications requiring accuracy and resource utilization balance."}, {"title": "C. Impact of Haar-Like Features", "content": "This section explores how Haar-like features enhance deep learning models, particularly SHARP-Net. Table VI shows the performance improvements achieved by gradually adding Haar-like features to SHARP-Net. Starting with the base model, we systematically incorporated additional features to measure their individual and combined effects on model performance. We applied our Haar-like feature integration technique to the U-Net architecture, demonstrating its versatility across different deep learning models. As shown in Table VII, this integration improved performance by 35.01% compared to the original U-Net. This significant enhancement highlights the potential of Haar-like features to boost various semantic segmentation models beyond SHARP-Net. The results confirm that incorporating Haar-like features significantly improves performance. While using three fea- tures produces results similar to five features, adding more features speeds up convergence and reduces training time. Peak performance was reached within 20 epochs, and using 30% improvement in IoU scores, highlighting the significant benefits of this approach. The method's versatility is evident in its successful application across diverse models and datasets, demonstrating its potential to advance semantic segmentation across various domains."}, {"title": "VII. CONCLUSION", "content": "We present SHARP-Net, a novel deep learning architecture for precise semantic segmentation on challenging multiclass datasets. SHARP-Net combines a bottom-up top-down struc- ture with sparsely connected blocks, depth-wise separable convolutions, and Haar-like feature extraction. This design ad- dresses issues like irregular defect shapes, occlusions, limited data, and class imbalance. Our evaluation on the Culvert-Sewer Defects and DeepGlobe Land Cover Classification datasets shows SHARP-Net's superior performance. The base model achieved IoU scores of 77.2% and 70.6% on these datasets, respectively, with only 1.32 million parameters. Adding Haar- like features improved IoU to 94.75%, outperforming state- of-the-art architectures like FPN, U-Net, CBAM U-Net, Seg- Former, and ASCU-Net. Haar-like features not only enhanced accuracy but also accelerated convergence, reducing training time and computational requirements. This technique can potentially improve other deep learning models by at least 20%. While SHARP-Net performs well, its efficacy across diverse semantic segmentation tasks and high-resolution or real-time applications, and feature selection optimization needs further investigation. Future research should focus on automating feature selection, exploring cross-domain adaptability, and optimizing for edge deployment. Additionally, incorporating temporal consistency for video segmentation, integrating mul- timodal data, and enhancing model interpretability will be crucial. These advancements aim to broaden SHARP-Net's ap- plicability and push the boundaries of semantic segmentation."}]}