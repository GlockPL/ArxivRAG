{"title": "IGDA: INTERACTIVE GRAPH DISCOVERY THROUGH LARGE LANGUAGE MODEL AGENTS", "authors": ["Alex Havrilla", "David Alvarez-Melis", "Nicolo Fusi"], "abstract": "Large language models (LLMs) have emerged as a powerful method for discovery. Instead\nof utilizing numerical data, LLMs utilize associated variable semantic metadata to predict\nvariable relationships. Simultaneously, LLMs demonstrate impressive abilities to act as\nblack-box optimizers when given an objective f and sequence of trials. We study LLMs at\nthe intersection of these two capabilities by applying LLMs to the task of interactive graph\ndiscovery: given a ground truth graph G* capturing variable relationships and a budget of I\nedge experiments over R rounds, minimize the distance between the predicted graph GR\nand G* at the end of the R-th round. To solve this task we propose IGDA, a LLM-based\npipeline incorporating two key components: 1) an LLM uncertainty-driven method for\nedge experiment selection 2) a local graph update strategy utilizing binary feedback from\nexperiments to improve predictions for unselected neighboring edges. Experiments on eight\ndifferent real-world graphs show our approach often outperforms all baselines including a\nstate-of-the-art numerical method for interactive graph discovery. Further, we conduct a\nrigorous series of ablations dissecting the impact of each pipeline component. Finally, to\nassess the impact of memorization, we apply our interactive graph discovery strategy to a\ncomplex, new (as of July 2024) causal graph on protein transcription factors, finding strong\nperformance in a setting where memorization is impossible. Overall, our results show\nIGDA to be a powerful method for graph discovery complementary to existing numerically\ndriven approaches.", "sections": [{"title": "1 INTRODUCTION", "content": "Given a set of variables X1,..., Xn, the graph discovery task involves finding a graph G* on the nodes\nX1,..., Xn whose edges capture causal relationships between the parent (source) and child (target). Often,\nobservational data can be collected for the variables X1, ..., Xn. This data can then be used to predict an initial\ngraph Go using statistical causal discovery techniques (Spirtes & Zhang, 2016). Recently, large language\nmodels (LLMs) have emerged as a competitive alternative method for predicting causal graphs (K\u0131c\u0131man\net al., 2024; Abdulaal et al., 2024; Chen et al., 2024). Unlike pre-existing statistical methods, LLMs require\nno observational data (K\u0131c\u0131man et al., 2024), instead relying purely on semantic metadata such as variable\nnames and descriptions. Another related line a work (Yang et al., 2024) investigates the abilities of LLMs to\nact as in-context black-box optimizers. Given an objective function f and an evaluation budget B, the LLM\nis tasked with finding a maximizer x* of f by sequentially proposing queries {x}\u00a31 and observing their\nassociated values {f(xi)}=1. Taken together, these directions suggest a powerful new application of LLMs:\ninteractive graph discovery."}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "Causal Discovery and LLMs. The causal discovery task involves learning causal relationships from\nobserved empirical data (Peters et al., 2017; Spirtes & Zhang, 2016). Many proposed algorithms exist (Spirtes\net al., 1993; Yu et al., 2019; Nauta et al., 2019; Zheng et al., 2018; Chickering, 2002) attempting to solve\nthe causal discovery problem. However, these methods are known to struggle on real world graphs where\nobservations are noisy or common structural assumptions are violated (Chevalley et al., 2023; Tu et al., 2019).\nRecently, LLMs have emerged as an alternative approach to causal discovery (K\u0131c\u0131man et al., 2024; Abdulaal\net al., 2024; Vashishtha et al., 2023; Li et al., 2024; Lampinen et al., 2023). K\u0131c\u0131man et al. (2024) first"}, {"title": "LLMs as Optimizers", "content": "Another growing line of work utilizes LLMs as black-box optimizers (Yang et al.,\n2024; Roohani et al., 2024). Yang et al. (2024) introduce the notion of an LLM as a generic optimizer and\nuse it to optimize performance objectives stemming from a range of tasks including linear regression and\nmathematical word problems (Cobbe et al., 2021). Other works (Madaan et al., 2023; Havrilla et al., 2024)\nexamine the self-refinement capabilities of LLMs where the LLM must reason and self-improve on earlier\nresponses. A growing number of papers apply LLMs to optimal experiment design and discovery (Roohani\net al., 2024; AI4Science & Quantum, 2023; Gao et al., 2024; Majumder et al., 2024; Jansen et al., 2024).\nRoohani et al. (2024) apply LLMs to gene discovery tasks which aim to find highly-influential parent genes\naffecting the regulation of a downstream target gene. Majumder et al. (2024); Jansen et al. (2024) both present\nbenchmarks evaluating the ability of LLMs to perform real-world and synthesized discovery tasks."}, {"title": "3 METHOD", "content": "Setup. As input we are given a set of variables X1, ..., Xn with associated metadata including variable\nnames and variable descriptions. We use the notation Y \u2192 X to indicate when variable Y has a direct\neffect on variable X and the set of parents of a variable X as Pa(X) = {Xi : X\u2081 \u2192 X}. We can then\nconsider the directed ground truth graph G* = {(Xi, Xj) : Xi \u2208 Pa(X;)} with unlabeled and unweighted\nedges. The only assumed graph structure is simplicity i.e. no self-edges or multi-edges. No additional\nstructure on the graph (such as acyclicity) is assumed. We can frame the prediction of G* as an edge-wise\nbinary classification problem over the complete graph Kn, where an edge (Xi, Xj) has the label lij = 1"}, {"title": "4 RESULTS", "content": "We evaluate our approach on seven real-world graphs. The graphs range in size from 8 to 30 nodes (variables)\nand vary widely in structure (some are acyclic while others are cyclic). Details for each graph can be found\nin Appendix D. To produce initial zero-shot graph predictions Go for all graphs we utilize pairwise causal\nprompting as in K\u0131c\u0131man et al. (2024) with Meta-Llama-3-70B-Instruct (Grattafiori et al., 2024) as"}, {"title": "4.1 ABLATIONS", "content": "Impact of experiment improvements versus update improvements As a starting point we define the\nnet graph improvement in a round r as the difference between the number of edges correctly classified in\nin G, versus in Gr\u22121. If an edge (Xi, X\u2081) is correctly classified in \u011c, but not in Gr\u22121 we say it has been"}, {"title": "5 CONCLUSIONS AND FUTURE WORK", "content": "In this work we proposed IGDA as a novel application of LLMs to interactive graph discovery. Our\nexperiments confirm the proposed IGDA method significantly outperforms baselines. Our ablations confirm\nboth uncertainty driven edge selection and local updates using experiment feedback as importantly contributing\nto the method's good performance. Further, this method is complementary to existing statisical methods for\nexperiment design or causal discovery (e.g. GIT (Olko et al., 2024)). Statistical methods utilize available\nobservational/interventional numerical data to make predictions and confidence estimates whereas IGDA\nutilizes available variable semantic metadata to make predictions and confidence estimates. Designing a\nmethod leveraging both numerical and semantic variable data is promising future work."}, {"title": "A PROMPTS", "content": "Zero-shot Confidence Estimation Prompt\n{task_description} Your goal is to understand the direct causal parents of {target}. Another variable\nis a direct causal parent of {target} if an experiment on the variable affects {target} and there are no\nother causal parents between the variable and {target}. Now, you must determine whether {parent} is\na causal parent of {target}. Here is a list of all other variables to consider:\n{variables_info}\nDo some brainstorming, comparing relevant characteristics of both variables and then print your\njudgment at the end of your response enclosed in the tags <decision>YES/NO</decision>. Print\nYES if {parent} is causal. Otherwise print NO. You should also print your confidence from a scale\nfrom 1 - 100 (with 100 being most confident) in the tags <confidence>...</confidence>.\nInformation about {target}: {target_info}\nInformation about {parent}: {parent_info}\nParent Update Prompt\nYou are a causal discovery expert. You have been given the following list of variables and tasked\nwith predicting the true causal graph through a sequence of experiments on edges.\n{variables_info}\nNote: each edge has an associated confidence value from 1 - 100. The presence of an edge is\nrepresented as (A- >B,CONFIDENCE) where A is the parent and B is the child. The absence of an\nedge is represented as (NOT A\u2212 >B, CONFIDENCE)\nFrom one experiment you have discovered {experiment_feedback} Previously you predicted\n{experiment_prediction}\nNow you should update your belief about the other edges of {parent} based on the results of the\nexperiment. Consider the predicted edge\n{other_edge_prediction}\nNow you should reason about how to update your belief about the above edge based on the ex-\nperiment. This means you can either keep your confidence the same, update your confidence,\nor change your prediction entirely. At the end of your response give your updated predic-\ntion at the end of your response in the format <decision>PARENT/NOT CAUSAL</decision>\n<confidence>CONFIDENCE</confidence>. Print 'PARENT' if the edge should be present and\n'NOT CAUSAL' if the edge should be absent.\nYou should do this in three steps.\nStep 1: Brainstorm what physical causal connection there may be, if any.\nStep 2: Reason about what the experiment feedback tells you. Think carefully about how similar the\nnew child is to the experimental child.\nStep 3: Give your final decision.\nChild Update Prompt\nYou are a causal discovery expert. You have been given the following list of variables and tasked\nwith predicting the true causal graph through a sequence of experiments on edges.\n{variables_info}\nNote: each edge has an associated confidence value from 1 100. The presence of an edge is\nrepresented as (A\u2212 > B,CONFIDENCE) where A is the parent and B is the child. The absence of an\nedge is represented as (NOT A\u2212 >B, CONFIDENCE)\nFrom one experiment you have discovered {experiment_feedback} Previously you predicted\n{experiment_prediction}\nNow you should update your belief about the other edges of {child} based on the results of the\nexperiment. Consider the predicted edge\n{other_edge_prediction}\nNow you should reason about how to update your belief about the above edge based on the ex-\nperiment. This means you can either keep your confidence the same, update your confidence,\nor change your prediction entirely.\nAt the end of your response give your updated predic-\ntion at the end of your response in the format <decision>PARENT/NOT CAUSAL</decision>\n<confidence>CONFIDENCE</confidence>. Print 'PARENT' if the edge should be present and\n'NOT CAUSAL' if the edge should be absent.\nYou should do this in three steps.\nStep 1: Brainstorm what physical causal connection there may be, if any.\nStep 2: Reason about what the experiment feedback tells you. Think carefully about how similar the\nnew parent is to the experiment parent.\nStep 3: Give your final decision."}]}