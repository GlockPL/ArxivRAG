[{"title": "B. Constructions of P-MPD", "authors": ["Aydin Abadi", "Vishnu Asutosh Dasu", "Sumanta Sarkar"], "abstract": "Deduplication is a vital preprocessing step that enhances machine learning model performance and saves training time and energy. However, enhancing federated learning through deduplication poses challenges, especially regarding scalability and potential privacy violations if deduplication involves sharing all clients' data. In this paper, we address the problem of deduplication in a federated setup by introducing a pioneering protocol, Efficient Privacy-Preserving Multi-Party Deduplication (EP-MPD). It efficiently removes duplicates from multiple clients' datasets without compromising data privacy. EP-MPD is constructed in a modular fashion, utilizing two novel variants of the Private Set Intersection protocol. Our extensive experiments demonstrate the significant benefits of deduplication in federated learning of large language models. For instance, we observe up to 19.61% improvement in perplexity and up to 27.95% reduction in running time. EP-MPD effectively balances privacy and performance in federated learning, making it a valuable solution for large-scale applications.", "sections": [{"title": "I. INTRODUCTION", "content": "The application of machine learning (ML) has experienced rapid growth, becoming widely embraced by businesses due to its various benefits. As ML relies heavily on data, there is an inherent risk of privacy breaches associated with this process. Federated learning (FL) is one of the main steps towards privacy-preserving ML that allows training across multiple decentralized devices without exchanging data. In FL, devices compute local models based on their data and then share the local model updates with a central server. This server aggregates the updates to derive a global model that encapsulates the features of all the local data held by the individual devices [38].\n\nThe quality of the training data significantly influences the accuracy of an ML model. Data generated from real-world applications often lacks organization, leading to issues such as missing values, typos, format mismatches, outliers, or duplicated entries within the raw dataset. To ensure meaningful learning, the collected data must undergo a thorough data cleaning process [23]. Duplicated sequences are prevalent in text datasets. They can adversely affect the training process of Language Models (LMs). Lee et al. [31] investigated the Colossal Clean Crawled Corpus (C4) [44] dataset. They discovered a 61-word sequence within C4 that was repeated 61,036 times verbatim in the training dataset and 61 times in the validation set. As a result, the trained model generalized poorly on the dataset, and over 1% of the unprompted model outputs were memorized and copied verbatim from the training dataset. Upon deduplicating the dataset, they reduced memo-rization by up to 10x and, in certain cases, even improved perplexity by up to 10%.\n\nAdditionally, memorization negatively affects the privacy and fairness of LMs [12]. Memorization makes language models vulnerable to membership inference attacks [48], [37], data extraction attacks [39], [13], and can lead to copyright violations as LMs can regurgitate training data sequences from copyrighted sources [28]. Carlini et al. [12] conclude that bigger LMs memorize more and more duplicates increase memorization. Kandpal et al. [27] show that the success of most privacy attacks on LMs is largely due to the duplication in the training datasets. Furthermore, in the FL setting, malicious clients can exploit the memorization of LMs to extract sensitive information from honest clients' datasets [46]. Therefore, we must adopt data-cleaning practices to improve model utility and reduce the risks of privacy attacks.\n\nWhile deduplication can improve model performance and reduce memorization, it also enhances training efficiency in various aspects [31]. Removing duplicates reduces GPU time and minimizes training costs in terms of time, money, and carbon footprint. This streamlined process optimizes resource utilization and contributes to more sustainable ML practices [7], [47], [42]. Sustainable development is a global priority, and aligning ML practices with this theme is crucial.\n\nBased on the discussions thus far, it is evident that the deduplication of training data offers numerous benefits. Several real-world applications involve training with FL such as health-care [3], smart city [25], and edge computing [51]. Some of these applications pose a risk of duplicates in the local training data across multiple devices. For example, Google Keyboard suggestions from a user's text query rely on FL [22]. Local models are trained in situ on Android phones with user data. In this setting, many text queries typed by the users across multiple phones are the same.\n\nTherefore, for a FL process to be efficient and effective, participating devices must perform deduplication. When a data owner solely intends to remove duplicates from their dataset, the privacy risk is minimal since the data is entirely under the owner's control. In the context of FL, the scenario shifts significantly when deduplication is introduced. Multiple devices participating in FL may possess overlapping data, even after deduplicating their datasets. If they aim to deduplicate the combined dataset, one approach could involve sharing their raw data with each other and checking for intersections. However, this approach compromises privacy."}, {"title": "Hence, there is a necessity for privacy-preserving deduplication in FL, where participating devices would collaboratively deduplicate the combined datasets in a privacy-preserving fashion. This paper demonstrates how deduplication can be executed in FL without compromising the privacy of the data belonging to the individual devices.", "content": ""}, {"title": "A. Overview of Privacy-Preserving Deduplication in FL", "content": "Consider nodes $D_1,..., D_n$ are involved in FL, where each $D_i$ has a dataset $S_i$. Effectively, the training in FL is conducted on the union of these datasets, i.e., $\\cup_{i=1}^n S_i$. If intersections exist among the datasets, FL will incorporate duplicates, leading to the drawbacks discussed earlier.\n\nConsider nodes $D_1$ and $D_2$, each with datasets $S_1$ and $S_2$, respectively implying that FL training occurs on $S_1 \\cup S_2$. If the intersection $S_1 \\cap S_2$ is nonempty, training individually on $S_1$ and $S_2$ would mean training twice on the duplicate $S_1 \\cap S_2$. Thus, one of $D_1$ and $D_2$ should remove the duplicate $S_1 \\cap S_2$. This should be done without harming each other's data privacy. Our solution applies private set intersection (PSI) which securely finds the intersection of $S_1$ and $S_2$ without revealing any other elements. Once $D_1$ and $D_2$ learn $S_1 \\cap S_2$ through PSI, $D_1$ will train on $S'_1 = S_1 \\setminus S_1 \\cap S_2$ and $D_2$ will train on $S_2$. According to set theory, it holds that $S'_1 \\cup S_2 = S_1 \\cup S_2$. Hence, the resulting FL model remains as intended, while the training process is devoid of duplicates, avoiding the associated drawbacks. The scenario with two nodes seems straightforward. However, when more than two nodes participate, it becomes complicated. We now consider n nodes $D_1,..., D_n$, where each node $D_i$ has a set $S_i, \\forall i, 1 \\le i \\le n$, and $n > 2$.\n\nFollowing the approach used in the two-node case, one might be tempted to (i) apply multi-party PSI to n nodes, (ii) find their intersection $I_n$, and (iii) let node $D_1$ train on $S'_1 = S_1 \\setminus I_n$, and rest of the nodes train on their own dataset $S_i$. This method removes the duplicates that exist across all the nodes. However, this does not detect and remove the duplicates that exist among a subset of nodes. For instance, if there is a subset of k nodes (k < n) with a large intersection $I_k$, then $I_k$ will remain in the full training dataset $\\bigcup_{i=2}^{n} (\\cup_{i=1}^n S_i)$ as duplicates. A generic multi-party PSI does not help in this case. Therefore, we need to consider each pair of nodes and remove the duplicates accordingly."}, {"title": "B. Our Contributions", "content": "In this paper, our end goal is to develop a scheme such that allows multiple clients to benefit from deduplication while training on their data in a federated learning setup. The first requirement is an efficient deduplication of sets belonging to multiple clients. To address this, we introduce the notion of Privacy-Preserving Multi-Party Deduplication (P-MPD) in Section IV. This essentially describes a functionality that takes input datasets $S_1,..., S_m$ (potentially containing duplicates) from m clients and outputs the datasets $S'_1,..., S'_m$ such that $\\cup_{i=1}^m S'_i = \\cup_{i=1}^m S_i$, where $S'_i \\cap S'_j = \\emptyset$, $i \\ne j$. We realize that an efficient construction of P-MPD requires a substantially improved PSI protocol that supports scalability. This leads us to introduce a new notion for PSI which we call Group PSI (G-PSI) in Section III. The functionality of G-PSI takes sets from a group of clients and returns each client the intersection of their sets with all the other clients' sets. We provide constructions of Efficient Group PSI (EG-PSI) that efficiently realizes G-PSI, namely EG-PSI$^{(I)}$ and EG-PSI$^{(II)}$ in Figures 1 and 2, respectively. EG-PSI$^{(I)}$ is based on symmetric key primitives such as pseudorandom permutation, while EG-PSI$^{(II)}$ is developed using an oblivious pseudorandom function, which is a well-known public key primitive. With the building block EG-PSI, we build Efficient Privacy-Preserving Multi-Party Deduplication (EP-MPD) that realizes P-MPD as shown in Figure 4. We prove the security of EP-MPD, EG-PSI$^{(I)}$, and EG-PSI$^{(II)}$ within the simulation-based paradigm. Our con-struction of EP-MPD allows for efficient duplicate removal without compromising clients' data privacy, resulting in an improved model after running federated learning on the dedu-plicated datasets, as outlined in Figure 5.\n\nWe perform an extensive experimental evaluation to bench-mark EP-MPD and the effect of the resulting deduplication on FL. The overall running time for EP-MPD$^{(I)}$, which employs EG-PSI$^{(I)}$ (symmetric key primitives based), is much less than EP-MPD$^{(II)}$, which utilizes EG-PSI$^{(II)}$ (public key primitives based). Overall, clients enjoy relatively less computation time in EP-MPD$^{(I)}$. Our protocols can scale to large datasets and client counts. For example, when 50 clients have $2^{19}$ data points in their datasets comprising of 30% duplicates, then EP-MPD takes 1160 seconds and EP-MPD$^{(II)}$ takes 7653 seconds; client running time is 641 and 111 seconds in EP-MPD$^{(I)}$ and EP-MPD$^{(II)}$ respectively. We experiment with 7 datasets, 2 language models, and 10 clients in FL. We achieve an improvement of up to 19.61% in perplexity and up to 27.95% improvement in GPU training time."}, {"title": "II. PRELIMINARIES", "content": ""}, {"title": "A. Notations and Assumptions", "content": "We define a wrapper function Update(S, \u015c) \u2192 S which takes two sets, S and \u015c. It updates S by removing from it the elements in set \u015c and returns the updated set S. In this paper, by the sum of sets (e.g., $\\sum_{i=1}^n S_i$) we mean the concatenation of the sets which may result in a multi-set. We denote an empty set by $\\emptyset$. We denote a size of vector $\\vec v$ with $|\\vec v|$. We assume that the server and all the users have access to secure channels among them. By the notation, $X \\stackrel{c}{\\equiv} Y$, we mean that the two distributions X and Y are computationally indistinguishable."}, {"title": "B. Federated Learning (FL)", "content": "The concept of FL was proposed by McMahan et al. [38] as a framework for training an ML model where the training data are distributed across multiple devices. In FL, a server orchestrates the training of a global model by aggregating models locally computed by the clients on their local devices. Suppose there are n clients, and each client $D_i$ has a dataset $S_i$. The server has the initial model $\\theta$. It sends $\\theta$ to the clients, and each client performs gradient descent computation on their local dataset $S_i$ as $J_i(S_i, \\theta) = \\sum_{(x,y) \\in S_i} C'(\\theta, (x, y))$, where C is the cost function and $d_i = |S_i|$. The client $D_i$ computes the local models as $\\theta_i \\leftarrow \\theta - \\eta \\nabla J_i(S_i, \\theta)$, where $\\eta$ is the learning rate. After receiving the local models from the clients, the server performs an aggregated averaging on the local models to derive the global model as:\n\n$\\theta = \\frac{1}{\\sum_{i=1}^n d_i} (d_1 \\theta_1 + ... + d_m \\theta_m)$ (1)\n\nwhere $d = \\sum_{i=1}^n d_i$ is the total size of the dataset $S = \\sum_{i=1}^n S_i$, and $\\theta$ is the locally trained model on the dataset S. This computation is repeated until the model converges.\n\nWhile this framework achieves a basic level of privacy in which each user's data is not directly sent to the server, it is susceptible to advanced privacy attacks such as membership inference attacks [48], [37] and data extraction attacks [13], [46], [18], [4] as the client models $\\theta_i$ are aggregated in a non-private fashion on the server side. Some privacy-preserving FL protocols have attempted to mitigate these attacks by securely aggregating the client models. These protocols rely on cryptographic techniques like homomorphic encryption [14], [15], functional encryption [52], or secure aggregation [5], [9]. Additionally, differentially private training techniques [2] can be used to ensure differential privacy guarantees on the global model $\\Theta$. We emphasize that in this paper, our proposed schemes are agnostic to the type of FL mechanism used."}, {"title": "C. Causal Language Modeling (CLM)", "content": "Causal Language Modeling (CLM) is a natural language processing task where the goal of the language model is to predict the next word or token given a sequence of tokens. The language model autoregressively generates the next token until a pre-determined sequence length is reached or a special STOP token is generated. Given a sequence of n tokens Y = {$Y_1, Y_2..., Y_{n-1}, Y_n$}, the language model is trained to learn the following probability distribution:\n\n$P(Y) = \\prod_{i=1}^n P(Y_i|Y_1, ..., Y_{i-1})$ (2)\n\nThe CLM training objective is to minimize the negative log-likelihood loss given by:\n\n$L(\\Theta, Y) = -\\sum_{i=1}^n log(\\Theta(y_i|Y_1,..., Y_{i-1}))$ (3)\n\nAfter training is complete, the text is autoregressively sam-pled from the language model i.e., $\\hat{y}_{t<n} \\sim \\Theta(Y_t|Y_1, ..., Y_{t-1})$.\n\nThe perplexity metric is commonly used to evaluate the performance of the language model to determine how well it has learned the probability distribution in Equation 2. The perplexity PP of a sequence y is defined as:\n\n$PP(Y) = exp{\\frac{1}{n} \\sum_{i=1}^n log(\\Theta(y_i|Y_1,..., Y_{i-1}))}$ (4)\n\nA lower perplexity score implies that model has been trained well to estimate the real-world probability distribution. Informally, a sequence with a low perplexity score implies that the model is less \"surprised\" by a sequence of tokens."}, {"title": "D. Security Model", "content": "In this paper, we use the simulation-based paradigm of secure multi-party computation [21] to define and prove the proposed protocol. Since we focus on the static passive (semi-honest) adversarial model, we will restate the security defini-tion within this context.\n\n1) Two-party Computation: A two-party protocol $\\Gamma$is captured by specifying a random process that maps a pair of input to a pair of outputs (one output for each party). Such process is referred to as a functionality denoted by $f : {0,1}^* \\times {0,1}^* \\rightarrow {0, 1}^* \\times {0,1}^*$, where $f := (f_1, f_2)$. For every input pair (x, y), the output pair is a random variable $(f_1(x, y), f_2(x, y))$, such that the party with input x wishes to obtain $f_1(x, y)$ while the party with input y wishes to receive $f_2(x, y)$. The above functionality can be easily extended to more than two parties.\n\n2) Security in the Presence of Passive Adversaries: In the passive adversarial model, the party corrupted by such an ad-versary correctly follows the protocol specification. Nonethe-less, the adversary obtains the internal state of the corrupted party, including the transcript of all the messages received, and tries to use this to learn information that should remain private. Loosely speaking, a protocol is secure if whatever can be computed by a corrupt party in the protocol can be computed using its input and output only.\n\nIn the simulation-based model, it is required that a party's view in a protocol's execution can be simulated given only its input and output. This implies that the parties learn nothing from the protocol's execution. Formally, in two-party case, party i's view (during the execution of $\\Gamma$) on input pair (x, y) is denoted by $View_i(x, y)$ and equals ($w,r_i, m_1, ..., m_j^i$), where $w \\in {x,y}$ is the input of ith party, $r_i$ is the outcome of this party's internal random coin tosses, and $m_j^i$ represents the jth message this party receives. The output of the ith party during the execution of $\\Gamma$ on (x, y) is denoted by $Output_i(x, y)$ and can be generated from its own view of the execution.\n\nDefinition 1. Let f be the deterministic functionality defined above. Protocol $\\Gamma$ securely computes f in the presence of a static passive probabilistic polynomial-time (PPT) adversary A, if for every A in the real model, there exist PPT algorithms (Sim1, Sim2) such that:\n\n{Sim1(x, $f_1(x,y)$)}$_{x,y} \\stackrel{c}{\\equiv}$ {View$\\Gamma_1$(x, y)}$_{x,y}\n\n{Sim2(y, $f_2(x, y)$)}$_{x,y} \\stackrel{c}{\\equiv}$ {View$\\Gamma_2$(x, y)}$_{x,y}\n\nDefinition 1 can be easily extended to m > 2 parties."}, {"title": "E. Pseudorandom Function and Permutation", "content": "Informally, a pseudorandom function PRF(.) is a determin-istic function that takes a key of length $\\lambda$ and an input of length u; and outputs a value of length v indistinguishable from an output of a truly random function. More formally, a pseudorandom function can be defined as PRF : {$0,1$}$^\\lambda$ \u00d7 {$0,1$}$^u$ \u2192 {$0,1$}$^v$, where $\\lambda$ is the security parameter.\n\nThe definition of a pseudorandom permutation, PRP : {$0,1$}$^\\lambda$ \u00d7 {$0,1$}$^u$ \u2192 {$0,1$}$^u$, is very similar to that of a pseudorandom function, with a difference; namely, it is required the keyed function PRP(k,.) to be indistinguishable from a uniform permutation, instead of a uniform function. In cryptographic schemes that involve PRP, sometimes honest parties may be required to compute the inverse of pseudo-random permutation, i.e., PRP$^{-1}$(k,\u00b7), as well. In this case, it would require that PRP(k,\u00b7) be indistinguishable from a uniform permutation even if the distinguisher is additionally given oracle access to the inverse of the permutation."}, {"title": "F. Oblivious Pseudorandom Function", "content": "An Oblivious Pseudorandom Function (OPRF) is a proto-col that involves a client and a server. OPRF enables the client with input x \u2208 {$0,1$}$^u$, and the server with key k \u2208 {$0,1$}$^\\lambda$ to execute an instance of PRF. Informally, the security of an OPRF asserts that, by the completion of OPRF, the client only learns the output of PRF is evaluated on inputs k and x, i.e., PRF(k,x) while the server gains no information, e.g., about the input of the client and the output of PRF."}, {"title": "G. Trusted Execution Environments", "content": "Trusted Execution Environment (TEE), also known as a secure enclave, constitutes a secure processing environment comprising processing, memory, and storage hardware units [41], [54]. Within this environment, the code and data residing in them remain isolated from other layers in the software stack, including the operating system. An ideal TEE guarantees the preservation of data integrity and confidentiality. Moreover, TEE can provide remote attestation capabilities, allowing a party to remotely verify the execution of an enclave on a genuine TEE hardware platform. Given the assumption that the physical CPU remains uncompromised, enclaves are shielded from attackers with physical access to the machine, including the memory and system bus.\n\nSide-channel attacks on different deployments of TEEs have been demonstrated in the literature [49]. These attacks pose a threat as they could enable attackers to extract se-crets from TEEs. Nevertheless, TEEs technologies have been evolving to address and mitigate side-channel attacks.\n\nOur security, trust, and system assumptions regarding TEEs are conservative. Specifically, as detailed in Sections IV-B1 and III-B, our solution (i) avoids disclosing any plaintext messages or private keys to TEE and (ii) does not expect TEE to maintain an extensive storage and memory space or possess strong processing resources. Instead, we establish a formal model and construction under the assumption that TEE guarantees execution integrity (and authenticity), and ensures minimal confidentiality. Specifically, we formally demonstrate that TEE at the most only learns the size of the encrypted computation result (i.e., the intersections' cardinality). In our work, TEE can be seamlessly substituted with any semi-honest server that does not collude with other entities."}, {"title": "III. GROUP PSI (G-PSI)", "content": ""}, {"title": "A. Formal Definition of G-PSI", "content": "In this section, we present the concept of Group PSI (G-PSI). In G-PSI, there are two groups of clients, G0 and G1, where each group contains m clients, $G_j : {C_{j,1},..., C_{j,m}}, 0 \\le j \\le 1$. Each client $C_{j,i}$ has a set $S_{j,i}$, such that no pair of clients' sets in the same group share a common element.\n\nInformally, G-PSI allows every client in one group to (efficiently) find the intersection that their set has with the set of every client of the other group, without allowing them to learn anything beyond that about other clients' set elements. To achieve a high level of computational efficiency in G-PSI, we will involve a third-party TP that assists the clients with computing the intersection. The functionality $f_{G-PSI}$ that G-PSI computes takes a set $S_{j,i}$ from every client $C_{j,i}$ and no input from TP. It returns (i) to every client $C_{j,i}$ a vector $\\vec v$, which contains the intersection that $C_{j,i}$'s set has with every other client's set in the other group and (ii) to TP an empty set $\\emptyset$. Hence, functionality $f_{G-PSI}$ can be formally defined as follows.\n\n$f_{GPSI} ((S_{0,1},..., S_{0,m}), (S_{1,1},..., S_{1,m}), \\emptyset) \\rightarrow$ (5)\n\n((\\vec v_{0,1},..., \\vec v_{0,m}), (\\vec v_{1,1},..., \\vec v_{1,m}), \\emptyset),\n\nwhere, $\\vec v_{j,i} = [S_{j,i} \\cap S_{1-j,1},..., S_{j,i} \\cap S_{1-j,m}]$, $0 \\le j \\le 1$, and $1 \\le i \\le m$.\n\nIn the case where clients of only one of the groups, e.g., Go, receives the result, then the above functionality simply returns $\\emptyset$ to the clients in the other group, e.g., $\\vec v_{1,1} = ... = \\vec v_{1,m} = \\emptyset$.\n\nSince TP performs computation on all clients' encrypted sets, there is a possibility of leakage to TP. Depending on the protocol that realizes $f_{G-PSI}$ this leakage could contain different types of information; for instance, it could contain (i) the size of the intersection of any two clients' sets, or (ii) the size of the intersection of all clients' sets, or (iii) nothing at all. Often such leakage is defined by a leakage function $\\mathcal{L}$ that takes all parties (encoded) inputs and returns the amount of leakage.\n\nWe assert that a protocol securely realizes $f_{G-PSI}$ if (1) it reveals nothing beyond a predefined leakage to TP and (2) whatever can be computed by a client in the protocol can be obtained from its input and output. This is formalized under the simulation paradigm. We require a client's view during an execution of G-PSI to be simulatable given its input and output. We require that the view of TP can be simulated given the leakage.\n\nDefinition 2 (Security of G-PSI). Let G0 and G1 be two groups of clients, where each group contains m clients, $G_j: {C_{j,1},..., C_{j,m}}, 0 \\le j \\le 1$. Let $\\mathcal{L}$ denote a leakage function, $f_{G-PSI}$ be the functionality defined above (in Relation 5 on page 4), S = {$S_{0,1},..., S_{0,m}, S_{1,1},..., S_{1,m}$}, and $S_{j,i}$ represent a set belonging to client $C_{i,i}$. Then, a protocol $\\Gamma$ securely realizes $f_{G-PSI}$ in the presence of a static semi-honest PPT adversary A, if for every A in the real model, there exists a PPT adversary (simulator) Sim in the ideal model, such that for every $C_{j,i} \\in {C_{0,1},..., C_{0, m}, C_{1,1},..., C_{1,m}}$ and TP, Relations 6 and 7 hold respectively.\n\n{Sim$_{C_{j,i}}$($S_{j,i}$,$\\vec v_{j,i}$)}$_S \\stackrel{c}{\\equiv}$ {View$_A^{\\Gamma}$(S,\\O)}$_S$ (6)\n\n{Sim$_{\\mathcal{L}}$($\\mathcal{L}$,$\\emptyset$)}$_S \\stackrel{c}{\\equiv}$ {View$_{TP}^{\\Gamma}$(S,\\O)}$_S$ (7)"}, {"title": "B. Efficient Construction of G-PSI", "content": "In this section, we introduce two efficient protocols that realize G-PSI. The first one, called EG-PSI$^{(I)}$, is highly efficient and based on symmetric key cryptography. The second one, called EG-PSI$^{(II)}$, is based on OPRF (in turn depends on public key cryptography) and discloses less information to TEE than the former does. Thus, these two protocols trade-off between performance and leakage amount.\n\n1) EG-PSI$^{(I)}$: At a high level, EG-PSI$^{(I)}$ operates as fol-lows. Initially, each client in group G0 agrees with every client in group G1 on a secret key. Every client encrypts its set elements using every key it has agreed on with other clients (in a different group).\n\nEach client, for every encrypted set element, temporally stores a triple that includes (i) the encrypted element, (ii) the key used to encrypt that element, and (iii) the index of the client with whom the key was shared. These triples will enable the client to efficiently (a) retrieve the correct key and (b) identify the client with whom it has the element in common when presented with an encrypted element. Once all elements are encrypted using the corresponding keys, each client transmits only its encrypted elements to TEE.\n\nGiven the sets of encrypted elements from all clients, TEE aggregates these sets and identifies the encrypted elements that appear more than once. Subsequently, TEE forwards to a client those encrypted elements that (1) appear more than once and (2) are among the messages that the client initially sent to TEE. Upon receiving each encrypted element from TEE, a client searches its local list of triples to locate the corresponding key and the index l representing a specific client. Utilizing the key, the client decrypts the element and regards the resultant element as one of the elements within the intersection it shares with the l-th client. For a comprehensive description of EG-PSI$^{(I)}$, refer to Figure 1.\n\nThe only information that TEE learns in EG-PSI is the size of the intersection of any two clients' sets, called pair-wise intersection cardinality. Below, we formally define it.\n\nDefinition 3 (pair-wise intersection cardinality). Let (S0,1,..., S0,m), (S1,1,..., S1,m) be two groups G0 and G1 of (encrypted) sets. Then, vector $\\vec s$ represents the pair-wise intersection cardinality: $\\vec s = [\\vec s_{0,1},..., \\vec s_{0,m}, \\vec s_{1,1},..., \\vec s_{1,m}]$, where $\\vec s = [[S_{j,i} \\cap S_{1-j,1}]|,..., |[S_{j,i} \\cap S_{1-j,m}]|]$, $0 \\le j \\le 1$, and $1 \\le i \\le m$.\n\nDefinition 4. Let $\\vec s$ be a pair-wise intersection cardi-nality of two groups G0 and G1 of encrypted sets: (S0,1,..., S0,m), (S1,1,..., S1,m), with respect to Defini-tion 3. Then, leakage function $\\mathcal{L}$ is defined as follows: $\\mathcal{L}$((S0,11, S0m), (S1,1, S1m)) \u2192 $\\vec s$.\n\nTheorem 1. Let $f_{G-PSI}$ be the functionality defined in Relation 5. Also, let $\\mathcal{L}$ be the leakage function presented in Definition 4. If PRP is a secure pseudorandom permutation, then EG-PSI$^{(I)}$ (presented in Figure 1) securely realizes $f_{G-PSI}$, with respect to Definition 2.\n\nWe refer to Appendix A for the proof of Theorem 1.\n\n2) EG-PSI$^{(II)}$: In this section, we present EG-PSI$^{(II)}$ which is the second variant of EG-PSI. Note that TEE in EG-PSI$^{(II)}$ is able to learn the cardinality of the intersection of each pair of clients' sets. We aim to reduce this leakage in EG-PSI$^{(II)}$. However, EG-PSI$^{(II)}$ is no longer based on symmetric key cryptography as it depends on OPRF. To the best of our knowledge, all the constructions of OPRFs are based on public key cryptography whose security depends on some hard problem assumptions. The same holds for EG-PSI$^{(II)}$.\n\nA brief overview of the construction of EG-PSI$^{(II)}$ is as follows. We have two groups of clients G0 and G1 having their own set that they want to find the pairwise intersection. There is a TEE that has a key k for a PRF. During the setup, each client interacts with TEE to encrypt their set using PRF(k,.) through an OPRF call. Then, each client of group G1 will send their encrypted set to every client of G0. Upon receiving an encrypted set from a client of G1, each client of G0 determines the intersection with their encrypted set. Once the client finds the intersection, it marks the index of the elements in the intersection and consider the elements with the same index in the unencrypted set as elements in the intersection. Similarly, each client of G0 shares their encrypted set with each client of G1 and follows the same steps. Ultimately, every client of G0 knows the intersection between their set and all the sets belonging to the clients of G1, and the other way around. We give a detailed description of EG-PSI$^{(II)}$ in Figure 2."}, {"title": "IV. PRIVACY-PRESERVING MULTI-PARTY DEDUPLICATION (P-MPD)", "content": ""}, {"title": "A. Formal Definition of P-MPD", "content": "P-MPD considers the setting where there are n clients C = {$C_1", "follows": "n\n$f_{P-MPD"}, "S_1,..., S_m) \\rightarrow (S'_1,..., S'_m)$, (8)\n\nwhere $S' = \\cup_{i=1}^m S'_i = S_u$ and $S_u$ denotes the union of all initial sets and contains only unique elements.\n\nTo maintain generality, we define a leakage function, denoted as $\\mathcal{W}$. The output of this function relies on the protocol implementing $f_{P-MPD}$. We assert that a protocol securely realizes $f_{P-MPD}$ if whatever```json\n{\n      \"title\":", "if whatever can be computed by a party in the protocol can be derived solely from its individual input and output, given the output of $\\mathcal{W}$. Below, we formally state it.\n\nDefinition 5 (Security of P-MPD). Let S = {$S_1,..., S_m$}, and $S_i$ represent a set belonging to client $C_i$. Let $\\mathcal{W}$ denote a leakage function and $f_{P-MPD}$ be the functionality defined in Relation 8. Then, a protocol $\\Psi$ securely realizes $f_{P-MPD}$ in the presence of a static semi-honest PPT adversary A, if for every A in the real model, there exists a PPT Sim in the ideal model, such that for every $C_i \\in {C_1, ...,C_m}$, Relation 9 holds.\n\n{Sim($S_i$, $S'_i$)}$_S \\stackrel{c}{\\equiv}$ {View$\\Psi_i$(S)}$_S$."], "content": "1) Construction Based on EG-PSI: We introduce a pioneer-ing protocol called Efficient Privacy-Preserving Multi-Party Deduplication (EP-MPD) that realizes P-MPD efficiently. The idea behind EP-MPD's design involves constructing a binary tree with leaf nodes representing the clients' indices. At each level, each cluster is formed with two different groups of clients, namely G0 and G1. Subsequently, EG-PSI is recursively applied to the sets of clients sharing the same cluster until the tree's root is reached. After each invocation of EG-PSI, the clients of G0 update their sets by removing the intersections, returned by EG-PSI, from their local sets. These updated sets are then used as input in the subsequent EG-PSI invocation.\n\nNext, we delve into further detail. We begin by sorting the clients' indices in ascending order. Next, we construct a binary tree such that the leaf nodes represent the clients' indices. At level d = 1, commencing from the left-hand side, every two clients form a cluster. Within each cluster, the first client is assigned to group G0 and the second client to group G1. Then, the clients within the same cluster engage in an instance of EG-PSI. Upon the return of the sets' intersection by EG-PSI, only the client situated on the left-hand side, specifically the one with the smaller index, modifies its local set by eliminating the elements of the intersection from its sets. This process is outlined in Figure 3a.\n\nAt level d = 2, starting from the left-hand side, every set of $2^d$ clients form a cluster. Within each cluster, the initial $\\frac{2^d}{2}$ clients enter group G0 and the remainder (i.e., the remaining $2^d$ clients) enter group G1. Subsequently, the clients within the same cluster engage in an instance of EG-PSI. Once again, upon the return of their sets' intersection by EG-PSI, the clients possessing the smaller indices update their local sets. This procedure is illustrated in Figure 3b.\n\nThe process continues until level d = $log_2 m$ is reached. At this point, all m clients collectively engage in an instance of EG-PSI. Each $\\frac{m}{2} = m$ clients enter group G0 and the remaining clients enter group G1. These m clients jointly participate in an instance of EG-PSI. Similarly to previous steps, the clients with the smaller indices update their local sets based on the output of EG-PSI. This procedure is outlined in Figure 3c.\n\n\u2022 Parties. A set of clients {$C_1,..., C_m$}.\n\n\u2022 Inputs. Sets $S_1,..., S_m$, where each $S_i$ belongs to client $C_i$, 1 \u2264 i \u2264 m, and m is a power of 2.\n\n\u2022 Outputs. Updated sets $S'_1,..., S'_m$, where each $S'_i$ belongs to client $C_i$, and $\\sum_{i=1}^m S'_i = \\cup_{i=1}^m S_i$.\n\nThe clients take the following steps $\\forall d$, 1 \u2264 d \u2264 $log_2(m)$:\n\n1) Forming Clusters. Every distinct $2^d$ clients enter the same cluster. Thus, for every level d, there will be $\\frac{m}{2^d}$ cluster(s). For instance, when d = 1, then there are the following clusters: ($C_1, C_2$), ..., ($C_{m-1}, C_m$).\n\n2) Forming Group. In each cluster, the first $\\frac{2^d}{2}$ clients enter group 0, G0, and the rest of the clients enter group 1, G1.\n\n3) Finding Intersection. In each cluster, the clients of G0 and G1 together engage an instance of EG-PSI. Each client $C_i$ receives a vector $\\vec v$, from EG-PSI, where $\\vec v$ specifies the elements that $C_i$ has in common with each client of the other group in the same cluster. It would be sufficient if only clients of G0 in each cluster were aware of the intersection result.\n\n4) Removing Duplication. For every element e \u2208 $\\vec v$, each $C_i$ in G0 calls Update($S_i$, {e}) \u2192 $S'_i$, where $S'_i = S_i \\setminus$ {e}.\n\nFigure 4 presents a detailed description of EP-MPD. For the sake of simplicity, we assume that m is a power of 2 in EP-MPD's description. However, we do not impose on the number of clients. Non-powers of 2 will result in incomplete sub-trees in the formation of clusters in the DE protocol where each group may have an unequal number of clients. This does not affect the EP-MPD protocol execution."}, {"title": "C. Naive Approaches", "content": "1) Running a Two-Party PSI Multiple Times: One might be tempted to allow each client to invoke an existing two-party PSI with every other client. However, this approach in total requires $\\binom{m}{2}$ = O($m^2$) invocations of the two-party PSI.\n\nWhereas EP-MPD requires only $\\sum_{i=1}^{log_2 (m)} (\\frac{m}{2^i})$ = m \u22121 invo-cations of our efficient tailor-made PSI, EG-PSI. To provide concrete values, when m = 256, the naive scheme requires 32,640 invocations of a standard two-party PSI, whereas our scheme requires only 255 invocations of EG-PSI."}, {"title": "2) Running Multi-Party PSI Once: One might be tempted to execute an existing multi-party PSI protocol only once on all clients' sets, hoping to identify and subsequently remove duplicated elements. Nevertheless, this approach falls short of identifying all duplications. The limitation arises from the fact that a multi-party PSI can uncover elements common to all clients, making it incapable of detecting elements shared among only a subset of clients.", "content": ""}, {"title": "3) Deduplicating all Sets at Once: There is a simplified version of EP-MPD. In this variant, each client reaches an agreement with the others on a secret key. Subsequently, each client encrypts its set elements using every key agreed upon with the other clients. Finally, all clients transmit their encrypted set elements to TEE. Upon receiving the encrypted sets from all clients, TEE identifies all duplicated elements. It then transmits to each client: (1) the duplicated elements found in the original elements that the respective client sent to TEE, and (2) the index of the client with which it shares the same element. Based on TEE's response, the clients with smaller indices update their local sets accordingly.", "content": ""}, {"title": "However, this approach requires that TEE maintains a local storage or memory space equal to the size of the concatenation of all encrypted sets. In contrast, EP-MPD with the underlying EG-PSI building block, allows TEE to have a substantially smaller storage or memory space. This is achieved because, before TEE receives all clients' encrypted sets at level d = $log_2(m)$, clients apply updates to their sets multiple times. This iterative process progressively reduces the size of the clients' sets, and the reduction can be particularly significant when the number of duplications is substantial.", "content": ""}, {"title": "D. Security Analysis", "content": "In any secure (multi-party) deduplication protocol, a par-ticipating client will learn the exact redundant elements within its set upon the protocol's completion. However, in EP-MPD, a client gains slightly more information. To be specific, upon the completion of EP-MPD, each client acquires the knowledge of the index (or identity) of the client that shares the redundant element. This additional information gained by a client during the execution of EP-MPD is formally defined as the output of a leakage function $\\mathcal{W}$ which we define below.\n\n$\\mathcal{W}$ takes as input (i) sets $S_1,..., S_m$, where each set $S_i$ belongs to client $C_i$, and (ii) sets $R_1,..., R_m$, where each $R_i$ contains the redundancy (or intersection) that a set $S_i$ has with every other set. $\\mathcal{W}$ outputs to the i-th client a set Q of triples, where each triple is of the form (ri,l,i,l), ri,l \u2208 Ri is a redundancy between sets $S_i$ and $S_l$.\n\nDefinition 6. Let S = {$S_1, ..., S_m$} be a set of sets, where each set $S_i$ belongs to client $C_i$. Also, let R = {$R_1,...,R_m$} be a set of sets, where each set $R_i$ comprises the redundancy that $S_i$ has with every other j-th set, for all j, 1 \u2264 j \u2264 m and i \u2260 j. Then, leakage function $\\mathcal{W}$ is defined as follows: $\\mathcal{W}$(S, R) \u2192 ($Q_1,..., Q_m$), where each $Q_i$ is a set of triples of the form (ri,l,i,l), ri,l \u2208 Ri is a redundancy between sets $S_i$ and $S_l$.\n\nTheorem 3. Let $f_{P-MPD}$ be the functionality defined in Relation 8 and $\\mathcal{W}$ be the leakage function presented in Definition 6. If EG-PSI is secure (w.r.t. Definition 2), then EP-MPD (presented in Figure 4) securely realizes $f_{P-MPD}$, w.r.t. Definition 5."}, {"title": "V. ENHANCED FL: APPLYING EP-MPD TO FL", "content": "With all essential building blocks in place, we are prepared to elucidate the complete functionality of the system. There are clients $C_1,..., C_m$ having the sets $S_1,..., S_m$, where each $S_i$ belongs to client $C_i$ respectively. Phase 1 involves each client conducting local deduplication. Since the local deduplication is a private computation there is no privacy requirement. The data owners can apply deduplication techniques as illustrated in [31] which results in having a set $S'_i$ free of duplicates by each client $C_i$. Subsequently, in Phase 2 they employ EP-MPD to eliminate duplicates across all clients. At the end of this phase, client $C_i$ gets an updated set $S''_i$, such that $\\sum_{i=1}^m S''_i = \\cup_{i=1}^m S_i$. Moving to Phase 3, they adopt a FL protocol (outlined in Section II-B) to train the model. Further details of this procedure are provided in Figure 5.\n\n\u2022 Parties. A set of clients {$C_1,...,C_m$}.\n\n\u2022 Server. Holds the initial model $\\theta$.\n\n\u2022 Inputs. Sets $S_1,..., S_m$, where each $S_i$ belongs to client $C_i$, 1 \u2264 i \u2264 m, and m is a power of two.\n\n\u2022 Outputs. A global updated model $\\Theta$.\n\n1) Local Deduplication. Each client runs a deduplication algorithm on their local dataset. At the end, client $C_i$ receives an updated dataset $S'_i$.\n\n2) Global Deduplication.\n\na) All the clients participate in the EP-MPD as de-scribed in Figure 4.\n\nb) Each client $C_i$ gets updated set $S''_i$, such that\n\n3) Federated learning.\n\n\na) The server and clients agree upon an FL protocol for training.\n\nb) The server initiates the learning by sharing the initial model $\\theta$ with each client.\n\nc) Each client $C_i$ trains on their local dataset $S''_i$ and updates $\\theta$ to $\\theta_i$.\n\nd) The clients and server aggregate the local models $\\theta_i$ trained by the clients.\n\ne) The server outputs the global updated model $\\Theta$ for the next training round."}, {"title": "VI. EXPERIMENTS", "content": ""}, {"title": "A. Implementation Details", "content": "We implement the EP-MPD protocol in python=3.10. We use AES with a 128-bit key in CBC mode from the cryptography library as a PRP in EG-PSI$^{(I)}$. To realize an OPRF in EG-PSI$^{(II)}$, we use the OPRF algorithm proposed in [11] from the oprf library. All EP-MPD experiments are conducted on a batch computing facility with a Dual Intel Xeon E5-2660 v3 @ 2.6 GHz CPU and 60 GB RAM.\n\nFor the FL experiments, we implement a FL setting for CLMs using python=3.10 with the transformers=4.40.1 and torch=2.3 libraries. We implement the FedAvg [38] algorithm for FL training to analyze the effect of EP-MPD on FL's performance. However, in practice, we recommend combining EP-MPD with privacy-preserving FL protocols for end-to-end privacy guarantees. All FL experiments are conducted on a server with an Intel(R) Xeon(R) Gold 6336Y CPU @ 2.40GHz CPU and NVIDIA RTX A6000 GPU.\n\nWe run all clients sequentially on a machine for both exper-iments. However, to emulate a real-world setting where clients run on different devices at the same time, we first compute the individual client running times and then estimate the real-world distributed running time by assuming the clients have run simultaneously. We open-source our implementations\u00b9.\n\nWhile implementing EP-MPD, we have two options for the EG-PSI module: EG-PSI$^{(I)}$ and EG-PSI$^{(II)}$. We observe that EG-PSI-based EP-MPD calls an OPRF function for every client in the leaf nodes of the EP-MPD tree, returning an encryption of the clients' sets. As clients move to upper levels, their set elements remain unchanged, with only the cardinality potentially changing. Therefore, except at the bottom level, OPRF calls are unnecessary for encryption, allowing the same encrypted set or their subsets to be reused at other levels. Thus, we have slightly adjusted the implementation. This significantly reduces time without compromising security properties, as reflected in our experiments."}, {"title": "B. EP-MPD Benchmarks", "content": "1) Experimental Setup: We designed three experiment set-tings to benchmark the performance of EP-MPD. The three settings analyze the effect of the number of clients, dataset size, and duplication percentage on the runtime of EP-MPD. All ex-periments were performed with both EG-PSI$^{(I)}$ and EG-PSI$^{(II)}$ as building blocks. The duplication percentage refers to the percentage of samples in a client's dataset present in another client's dataset. The three experiment settings are:\n\na. The dataset size is fixed at $|S_i| = 2^{19}$, the duplication per-centage at 30%, while the number of clients m is varied. Specifically, m is set to each value in {10, 20, 30, 40, 50}.\n\nb. The number of clients is fixed at 50 and the dupli-cation percentage at 30%, while the dataset size $|S_i|$ is varied. Specifically, $|S_i|$ is set to each value in {$2^{10}, 2^{11}, 2^{13}, 2^{15}, 2^{17}, 2^{19}$}.\n\nc. The database size $|S_i|$ is fixed at $2^{19}$, the num-ber of clients at 50, while the duplication percent-age is varied. Specifically, it is set to each value in {10%, 30%, 50%, 70%, 90%}.\n\nWe create pairwise duplicates between clients such that every client has a unique duplicate element with every other client. All set elements are 32-bit integers. We assume that the TEE can receive data in parallel from the clients. All other interactions that require computation between TEE and"}, {"title": "2) Effect of Client Count: Figure 6 depicts the effect of the number of clients on (a) EP-MPD running time, (b) the average running time of clients, and (c) TEE running time. Figure 6a demonstrates that the EP-MPD running time increases linearly with the number of clients for both EP-MPD$^{(I)}$ and EP-MPD$^{(II)}$. The increase in the client count rises the number of PRP and OPRF evaluations as the total number of elements across all clients grows. We observe that EP-MPD$^{(I)}$ is about 7-10\u00d7 faster than EP-MPD$^{(II)}$.\n\nThe average running time of the client however shows a different trend. The client running time in EP-MPD$^{(I)}$ increases linearly with the client count and is always greater than up to 6x - the running time of EP-MPD$^{(II)}$. The running time of EP-MPD$^{(II)}$ is constant as the number of clients increases. In EP-MPD$^{(I)}$, the client-side running time increases with the number of clients, because each client has to perform more PRP evaluations. However, in EP-MPD$^{(II)}$, the number of OPRF evaluations is equal to the number of elements in each client's set. Additionally, in EP-MPD$^{(I)}$, the clients perform the PRP evaluations at every level of the tree. However, in EP-MPD$^{(II)}$ the OPRF evaluations are only performed once when the clients are at the leaf level.\n\nThe running time of TEE follows a similar trend to the EP-MPD running time. The TEE running time in EP-MPD$^{(I)}$ is always higher than EP-MPD$^{(I)}$. Both exhibit linear increases in running time as the number of clients increases. The running time in EP-MPD$^{(I)}$ is much higher as the OPRF evaluations are relatively expensive.", "content": ""}, {"title": "3) Effect of Dataset Size: Figure 7 illustrates the effect of dataset size on EP-MPD running time, the average running time of clients, and TEE running time. From Figure 7a, it is evident that the EP-MPD running time grows linearly with increasing the dataset size. EP-MPD$^{(I)}$ is up to 8\u00d7 faster than EP-MPD$^{(II)}$. As the dataset size increases, the number of PRP and OPRF evaluations grows, thereby increasing the EP-MPD running time.\n\nFigure 7b shows the effect of dataset size on client running time. Unlike increasing the client count, increasing the dataset size increases the client running time of both EP-MPD$^{(I)}$ and EP-MPD$^{(II)}$. We observe this difference because an increase in dataset size increases the number of OPRF evaluations while any change in the client count does not. The client running time of EP-MPD$^{(II)}$ is up to 7\u00d7 faster than EP-MPD$^{(I)}$.\n\nFigure 7c depicts the effect of dataset size on the running time of TEE. The growth of dataset size increases the OPRF evaluations in EP-MPD$^{(II)}$. In EP-MPD$^{(I)}$, TEE has to identify more overlapping ciphertexts as the datasets are larger. The running time of TEE increases linearly with the dataset size for both cases. TEE running time in EP-MPD$^{(I)}$ is up to 5\u00d7 faster than EP-MPD$^{(II)}$.", "content": ""}, {"title": "4) Effect of Duplication Percentage: Figure 8 shows the effect of duplication percentage on EP-MPD running time, the average running time of clients, and TEE running time. Figure 8a highlights the running time of EP-MPD as the dupli-cation percentage changes. We note that in EP-MPD$^{(I)}$, OPRF"}, {"title": "C. FL with EP-MPD", "content": "1) Experimental Setup: We create an FL setting with varying levels of duplication to analyze the effect of EP-MPD on the model performance and training efficiency of CLM fine-tuning. We use GPT-2 Medium and GPT-2 Large CLMs from the GPT-2 [43] family of decoder-only models based on the Transformer [50] architecture. The GPT-2 Medium has 345 million parameters with 24 decoder blocks, 16 attention heads, and 1024 hidden sizes while GPT-2 Large has 774 million parameters with 36 decoder blocks, 20 attention heads, and 1280 hidden sizes. Both models have a sequence length of 1024 tokens.\n\nWe create 10 clients and experiment with the following 7 datasets. The Rotten Tomatoes and IMDB datasets contain movie reviews. The Sonnets and Plays datasets are a collection of works by William Shakespeare. Poetry is a collection of short poems by a variety of poets. Haiku and Short Jokes are a collection of short Japanese-style poems and Jokes from Reddit respectively. The language modeling task for each dataset is to learn how to generate text from the dataset's distribution. For all datasets, we create a Train and Test split in an 80:20 ratio. Model perplexity is evaluated on the Test set after training. We follow a two-step procedure to create the client datasets with x% duplication. Initially, we equally distributed the Train set among all 10 clients. Next, we sample with replacement x% of the original Train set. This subset is then again equally distributed among all clients. We perform 5 rounds of FL training with at most 10 epochs of local training. The GPT-2 Large models were trained for fewer epochs and with less data"}, {"title": "3) FL model training efficiency: We analyze the model training efficiency by computing the total GPU running time of all clients during training. The CPU-bound EP-MPD costs are negligible for 10 clients and at most 5,000 elements (the size of the largest dataset is 50,000 elements distributed among all clients). Table II highlights the results for GPU running time. The Time column is the total GPU running time and IR is the percentage improvement compared to the running time within the deduplicated setting.", "content": ""}, {"title": "The blue text shows the largest improvement in running time of 27.95% from 33.13 minutes to 23.87 minutes in the GPT-2 Medium experiment with the Sonnets dataset. The purple text highlights the smallest improvement in running time of 7.33% from 11.87 to 11.0 minutes in the Sonnets experiment with GPT-2 Large.", "content": ""}, {"title": "We observe a relatively consistent improvement trend of approximately 22%, 16%, and 8% for 30%, 20%, and 10% duplication levels respectively. The GPT-2 Medium experi-ments show higher running times as these models were trained longer. We observe that the running time efficiency consistently improves across all duplication levels and experiments.", "content": ""}, {"title": "Tables I and II demonstrate the effectiveness of applying EP-MPD to FL of language models. The experiments show improvements of up to 18% in perplexity and 27% in GPU running time. Deduplication significantly reduces resource usage while enhancing the quality of FL models. The RTX A6000 GPU used in our experiments consumes 0.3 kWh of energy. As FL scales to larger datasets and more clients, the energy savings with EP-MPD become even more significant, contributing to more sustainable and cost-effective FL imple-mentations, benefiting both the environment and the end-users.", "content": ""}, {"title": "VII. ASYMPTOTIC COSTS ANALYSIS", "content": "In this section, we analyze the asymptotic costs of our schemes. Table III summarizes the result."}, {"title": "A. Costs of EG-PSI\\textsuperscript{(I)} and EG-PSI\\textsuperscript{(II)}", "content": "1) Computation Cost: Initially, we focus on the compu-tation cost of parties in EG-PSI\\textsuperscript{(I)}. In step 1b, each client Ci encrypts each element of its set using the symmetric key encryption PRP, under each key it agrees with the clients in the other group. Specifically, it invokes PRP m|Si,j| times, where m is the total number of clients in the other group. In step 3, each client Ci invokes PRP m|Ri,j| times, where Ri,j is the (encrypted) intersection set. Thus, the computation complexity of each Ci is O(m|Si,j|). The computation complexity of TEE in step 2 is O(m|S|), where |S| represents the maximum cardinality of sets. The only computation that TEE performs is searching to find duplicated values.\n\nWe proceed to analyze the computation cost of parties in EG-PSI\\textsuperscript{(II)}. In step 2, each client Ci,j invokes Si times OPRF to encrypt its set elements. In steps 3 and 4, each Ci performs a search on m + 1 encrypted sets, which imposes negligible costs compared to the executions of OPRF. Thus, the complexity of each Ci,j is O(m|S|), where S is the maximum cardinality of sets. TEE invokes an instance of OPRF in step 2 for every set of elements of each client. Therefore, its computation complexity is O(m|S|), where S is the maximum cardinality of sets.\n\nTherefore, its computation complexity is O(m |S|), where S is the maximum cardinality of sets."}, {"title": "2) Communication Cost: We first concentrate on the com-munication cost of parties in EG-PSI. Each client Co, in step 1a transmits m keys to the clients of the other group. Thus, its communication complexity in this step is O(m). However, the clients in G1 do not transmit any message in this step. In step 1b, each client Ci,j of each group, transmits m|Si,j| messages to TEE, where the size of each message is only about 256 bits. Thus, each client's communication complexity is O(m|Si,j|). On the other hand, TEE sends to each client Ri, which contains the intersection the client has with the clients in the other group. Thus, the overall communication complexity of TEE is O(m|R|), where |R| is the maximum cardinality of sets intersection that a client may have with clients of the other group.", "content": ""}, {"title": "We proceed to evaluate the communication complexity of parties in EG-PSI\\textsuperscript{(II)}. In step 2, each Ci,j performs OPRF evaluations on Si,j. This procedure imposes O(|Si,j|) com-munication cost to the client. In step 3, the communication complexity of each Ci,j is O(m |Si,j|) because it sends its encrypted set to every client in the other group. In step 2, TEE performs OPRF evaluations on the elements of each Ci, using OPRF. This procedure imposes O(m|S|) communication cost to TEE.", "content": ""}, {"title": "B. Costs of EP-MPD", "content": "1) Computation Cost: In step 3", "Cost": "In step 3, at each level d, each client Co, transmits its updated set to an instance of EG-PSI or EG-PSI. Therefore, its overall communication complexity is O (m(|So|+$\\sum_d$"}]