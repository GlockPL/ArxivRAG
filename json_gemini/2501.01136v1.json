{"title": "Symmetries-enhanced Multi-Agent Reinforcement Learning", "authors": ["Nikolaos Bousias", "Stefanos Pertigkiozoglou", "Kostas Daniilidis", "George Pappas"], "abstract": "Multi-agent reinforcement learning has emerged as a powerful framework for enabling agents to learn complex, coordinated behaviors but faces persistent challenges regarding its generalization, scalability and sample efficiency. Recent advancements have sought to alleviate those issues by embedding intrinsic symmetries of the systems in the policy. Yet, most dynamical systems exhibit little to no symmetries to exploit. This paper presents a novel framework for embedding extrinsic symmetries in multi-agent system dynamics that enables the use of symmetry-enhanced methods to address systems with insufficient intrinsic symmetries, expanding the scope of equivariant learning to a wide variety of MARL problems. Central to our framework is the Group Equivariant Graphormer, a group-modular architecture specifically designed for distributed swarming tasks. Extensive experiments on a swarm of symmetry-breaking quadrotors validate the effectiveness of our approach, showcasing its potential for improved generalization and zero-shot scalability. Our method achieves significant reductions in collision rates and enhances task success rates across a diverse range of scenarios and varying swarm sizes.", "sections": [{"title": "1. Introduction", "content": "The study of multi-agent dynamical systems, has garnered significant attention due to its wide-ranging applications in areas like autonomous navigation, environmental monitoring, target track-ing, collaborative manipulation etc. Since obtaining large-scale datasets of expert demonstrations is often impractical, multi-agent reinforcement learning (MARL) has emerged as a powerful frame-work for enabling agents to learn complex, coordinated behaviors. However, the inherently high-dimensional and decentralized nature of multi-agent systems poses significant challenges, particu-larly in terms of scalability, generalization, and data efficiency. To enhance generalization, synthetic samples can be generated by applying symmetry transformations to the original data, increasing diversity without additional sampling (e.g. Laskin et al. (2020); Kostrikov et al. (2021)). Data aug-mentation, though, increases computation time and offers no generalization assurances. Outside of data augmentation, one promising avenue to address these challenges lies in leveraging the sym-metries of dynamical systems as a policy inductive bias. This paper focuses on extrinsic symmetry exploitation in cooperative-competitive MARL problems.\nFrom an RL perspective, the existence of symmetries morphs into equivalence of state-action pairs under a group transformation, meaning that the policy only needs to learn one mapping for each equivalence class, rather than separately learning the same behavior for all symmetrically re-lated pairs Ravindran and Barto (2001); Zinkevich and Balch (2001). The presence of symmetries, therefore, reduces the hypothesis space and improves sample efficiency and generalization, as the"}, {"title": "1.1. Contributions", "content": "The aforementioned literature\u00b9 utilizing symmetries as inductive biases in policy learning, which, however, presumes that the system exhibits said symmetries. In practice, most dynamical systems exhibit little to no symmetries. To the best of our knowledge, this is the first paper that attempts to construct a MARL framework that leverages symmetries in policies, even if the system is not endowed with them. Our contributions are outlined below:\n\u2022 A formalization of the symmetry properties of multi-robot dynamical systems and the con-ditions under which optimal policies are equivariant functions to be approximated by equiv-ariant networks. These conditions showcase the restrictive nature of current equivariant RL methods to systems with explicit symmetries shared by the task specification.\n\u2022 A methodology for embedding extrinsic symmetries in systems where intrinsic symmetries are insufficient or broken, thus broadening the applicability of equivariant learning frame-works to any multi-agent dynamical system."}, {"title": "2. Preliminaries", "content": ""}, {"title": "2.1. Group Theory & Equivariant Functions", "content": "A group (G,) is a set G equipped with an operator \u00b7 : G \u00d7 G \u2192 G that satisfies the properties of\nIdentity: \u2203e \u2208 G such that e \u00b7 g = g \u00b7 e = e; Associativity: \u2200g,h, f \u2208 G, g \u00b7 (h\u00b7 f) = (g. h) \u00b7 f;\nInverse: \u2200g \u2208 G, \u2203g\u00af\u00b9 such that g\u22121 . g = g \u2022 g\u00af1 = e. Additional to its structure we can define\nthe way that the group elements act on a space X via a group action:\nDefinition 1 A map \u00a2g : X \u2192 X is called an action of group element g \u2208 G on X if for e is the identity element \u00a2e(x) = x for all x \u2208 X and \u00a2g \u00a9 \u00a2h = $gh for all g, h \u2208 G.\nNote here that a group action on a given space X allow us to group different elements of X in sets of orbits. More precisely given a group action * an orbit of a element x \u2208 X is the set\nO* = {g(x)\\g \u2208 G}. In many application we require functions that respect the structure of a\ngroup acting on their domain and codomain. We refer to these functions as equivariant and we formally define them as follow:\nDefinition 2 Given a group G and corresponding group actions actions \u00a2g : X \u2192 X, \u03c8g : X \u2192 X for g \u2208 G a function f : X \u2192 Y is said to be (G, \u00a2*, \u03c8\u2217) equivariant if and only if:\n$\\psi_g [f(x)] = f (\\phi_g[x]) \\forall x \\in X, g \\in G$ (1)"}, {"title": "2.2. Notation", "content": "Let X be a smooth manifold and TX the tangent space at an arbitrary x \u2208 X. A smooth vector field is a smooth map f : X \u2192 TX with f(x) \u2208 TX. The set of smooth vector fields on a manifold X, denoted X(X), is a linear infinite dimensional vector space. Let G be a d-dimension real Lie group, with identity element e. For a smooth manifold X and Lie group G, the left natural action \u00a2 : G \u00d7 X \u2192 X satisfies $(e, x) = x,\u2200x \u2208 X and \u00a2(\u011d, \u03c6(g, x)) = $(\u011d \u00b7 g,x),\u2200g.\u011d \u2208 G, x \u2208 X,\nthus inducing families of smooth diffeomorphisms \u0444g(x) := $(g,x). A group action is free if\n\u2200x \u2208 X,$(g,x) = x \u21d4 g = e and transitive if \u2200x,y \u2208 X, \u2203g \u2208 G such that (g,x) = y\n(i.e. the nonlinear smooth projections \u03c6\u30a7(g) := $(g, x) are surjective). A homogeneous space is a smooth manifold X that admits a transitive group action & : G \u00d7 X \u2192 X and the Lie group G is,\nthen, called the symmetry of X. The group torsor & of a Lie group G is defined as the underlying\nmanifold of G without the group structure, allowing for identification of the torsor elements by the\ngroup elements, denoted x \u2208 G \u2243 g \u2208 G, and inheriting the free and transitive group action\ninduced by the group operator, i.e. for \u011d \u2208 G and x \u2208 G \u2243 g \u2208 G it stands that $(\u011d, x) \u2243 \u011d \u00b7 g.\nCrucially, a manifold that serves as a torsor for multiple Lie groups may admit multiple symmetries."}, {"title": "2.3. Problem Statement", "content": "Consider a homogeneous multi-robot dynamical system, comprising of N autonomous robots in-dexed i \u2208 {1, ..., N} = In. Let X be a smooth manifold and U a finite dimensional input space.\nThe agents are described by dynamics:\n$\\dot{x_i}(t) = f(x_i(t), u_i(t)), x_i(0) = x_i^0, \\forall i \\in I_N$ (2)\nwhere ui \u2208 U, xi \u2208 X and f : X \u00d7 U \u2192 X(X) a linear morphism. Consider a Lie group G and a smooth transitive group action \u00a2 : G \u00d7 X \u2192 X.\nGraph Representation of Multi-robot Systems: We assume that the robots are equipped with sensing/communication capabilities with a range \u00ea. Let N\u00bf := {j \u2208 In \\ {i} : d(xi,xj) \u2264\n\u00ea}, \u2200i \u2208 IN denote the neighbourhoods, thus giving rise to a graph representation of the system\nGt = {VG+, EG\u0141}, with nodes VG\u2081 = {xi(t), i \u2208 IN} and edges EG\u2081 = {(i, j), : Vi \u2208 In, j\u2208 N;}.\nInformation is propagated over the graph structure, with each robot receiving local observations of\nthe system, denoted o\u00bf(t) = {xj(t), j \u2208 N\u00bf}, i \u2208 IN. We denote x(t) = [\u2295vi\u2208Inxi(t)] \u2208 Ui\u2208INX\nand u(t) = [\u2295vieInUi(t)] \u2208 UiEINU the centralized state and action of the multi-robot system\nrespectively. Assuming that a submanifold X \u2264 X forms the torsor G of the Lie group G and that\nX \\ X is compatible with G, then every robot inherits a group representation element gi, Vi \u2208 In\nand the node attributes of the graph become VG\u2081 = {(gi(t), xi(t)), i \u2208 In}.\nProblem statement: Given a swarm of N robots of known dynamics, the trajectories {xi(t), i \u2208\nIN}, t \u2208 R+ evolve in a complex environment, known or estimated continuously through onboard\nsensors, with obstacles represented as a point cloud set O \u2208 R3\u00d7d. Assuming a metric function\ndenoted L : Ui\u2208INX \u00d7 UiEINU \u2192 R that codifies the specific task (e.g. distance for navigation,\nalignment for flocking), we formally define the multi-agent geometric optimization problem\n$U_{0:T}^* ,I_N = \\underset{u_{0:T}}{arg \\min} \\int_0^T L(\\bigoplus_{i \\in I_N}x_i(\\tau), \\bigoplus_{i \\in I_N}u_i(\\tau))d\\tau $\ns.t. $\\dot{x_i}(t) = f(x_i(t), u_i(t)) \\in X(X), \\forall i \\in I_N $\n $u_i(t) = \\pi_{\\theta}(o_i(t) \\bigcup x_i(t) ; O) \\in U $ (3)\nProblem (3) amounts to N robots learning the distributed control policy \u03c0\u03b8 : UN\u00bf\u222a{i}XxR3xd \u2192 U\nusing only local observations and knowledge of the environment. This problem can be recast as a distributed MARL problem by maximizing a reward function instead of minimizing a loss function, with robot dynamics described by a transition function, forming an MDP. For clarity reasons we opt to use the optimal control jargon."}, {"title": "3. Exploiting Symmetries of Dynamical Systems", "content": "In this section we show that if Problem 3 exhibits some structural symmetries then the optimal control policy needs to exhibit them as well, leading to sample efficient learning.\nDefinition 3 Consider a real Lie Group G, a smooth manifold with group properties satisfying differentiability of group operations. Problem 3 is G-equivariant if, for transitive actions induced by elements of the group G on a vector field X, \u00a2 : X \u00d7 G \u2192 X and \u03c8 : U \u00d7 G \u2192 U, it satisfies\nthe following properties:"}, {"title": "4. When symmetries are broken", "content": "Section 3 demonstrated why symmetries of dynamical systems are useful. Even though most tasks exhibit geometric symmetries (condition 1 of Definition 3), most dynamical systems have little to no symmetries to exploit (condition 2), rendering Theorem 1 void. To circumvent this issue, we propose embedding the non-equivariant system into an extended dynamical system that is G-equivariant, so that Theorem 1 stands. The extended learned policy is G-equivariant, and optimal action for the original non-equivariant dynamical system is recovered via the symmetry-breaking projective function that guarantees equivalence between the two associated dynamical systems. This way we can provide structure in the learned policy, even if the original dynamical system does not support it. A consequence of this framework is that the structure of the policy is solely con-strained by the symmetries that the reward function admits, meaning that any problem can be recast as a G-equivariant problem as long as condition 1 holds and the Lie group G is compatible with the manifold X. Consider the push-forward smooth map d\u2217\u0444 : X(X) \u00d7 G \u2192 X(X) defined as d*\u00a2gf(x,u) := d\u00f8g f($g\u22121(x), u), naturally induced by the diffeomorphism \u00a2 : G \u00d7 X \u2192 X.\nLemma 1 The push-forward function d\u2217\u00f3 is a well defined linear group action (automorphism) on the infinite dimensional vector field X(X). (Proof in Appendix I of supplemental material\u00b9.)\nTheorem 2 Let f : X \u00d7U \u2192 X(X) denote a control affine dynamical system on a smooth manifold\nX that admits a transitive group action from a compatible Lie group G, over an input vector space\nU. For the extended input vector space \u00da := span{d\u2217\u00a2gf(x,u)|u \u2208 U,g \u2208 G}, the associated system dynamics F : \u00db \u00d7 X \u2192 X(X) are equivariant with respect to actions induced by elements\nof the Lie group G. (Proof in Appendix I of supplemental material\u00b9.)"}, {"title": "5. Equivariant Graphormer", "content": "To solve the Geometric Swarming problem, we must learn the distributed equivariant policy \u00fb\u00bf(t) =\n\u03c0\u03b8(0\u00bfUxi; O), i \u2208 In, as described in Section 4. Generally deep learning models require specialized\narchitectures to ensure the satisfaction of the equivariant constraints Fuchs et al. (2020). Such architectures can result in more challenging optimization (Pertigkiozoglou et al., 2024) that can complicate their integration with standard RL techniques. To address these challenges we proposed"}, {"title": "5.1. Group Canonicalization", "content": "Given a group G acting on space X through action $g we can define an extended group action 'g on space G \u00d7 X as ',[(p,x)] = (g\u00b7p, $g[x]), where \u2200g,p \u2208 G,x \u2208 X. Since og is an action of group G, ', satisfies the properties of definition 1 and, thus, it is also an action. Assuming an\nadditional space Y with corresponding group action \u03c8g : G \u00d7 Y \u2192 Y, we can show the following:\nLemma 2 A function f : G \u00d7 X \u2192 Y satisfies the equivariant constraint f(\u00a2'g[p]) = \u03c8g[f(p)],\n\u2200g \u2208 G and p\u2208 G \u00d7 X, if and only if, for h : X \u2192 Y, it can be written as a composition:\nf(g,x) = \u03c8g[h($g-1[x])], \u2200g\u2208G, x \u2208 X\nwith h(x) = f(e,x) for all x \u2208 X and e being the identity element of G. (Proof in Appendix I of\nthe supplementary material\u00b9.)\nNotice that in Lemma 2, h is a function from X to Y without any additional constraints. This implies\nthat we can use any general function approximator (e.g. MLP, Transformer) to approximate an\nequivariant function f : G\u00d7X \u2192 Y, by only applying the appropriate input-output transformations.\nWe will use this observation to extend the baseline non-equivariant models to be equivariant with minimal changes to the underlying architecture."}, {"title": "5.2. Equivariant Graph Transformer", "content": "Given a feature augmented graph representation (V, E, F) with a finite set of nodes V, a finite set\nof edges E(G) C {(u,v) u, v \u2208 V} and a set of per-node features F = {fv \u2208 X|v \u2208 V}, a graph transformer sequentially updates the nodes features using a local attention layer to aggregate\ninformation from neighboring nodes. Specifically the Ith update layer for node v \u2208 V is a function\nM : X(1) \u2192 X(1+1) defined as fol+1) \u2190 M\u2082(F(1)) = \u03bc(f) + attn(F(l))), where \u00b5 corresponds\nto a fully-connected feedforward network, and attn corresponds to the local attention layer:\nattn(f(l))v= \u2211penvexp(f(l)WTWQWkf(l)p)\n\u03a3p\u2208Nvexp(f(l)WTWQWkf(l)p) (wvWKf(l)p)\nwith N being the set of neighbors for nodes v. As discussed in Section 2.3, the input graph\nrepresentation is endowed an additional structure that allows for an simple extention of the graph transformer to be equivariant. Specifically, each node v \u2208 V additional to a feature fu \u2208 X describing each state is also equipped with a local frame gv \u2208 G. This means that the input graph is represented as (V, E, Ftens), with Ftens = {(gv, fv) \u2208 G \u00d7 X|v \u2208 V} being a set of \"tensorial\" features that are described by their local frame gv \u2208 Galong with their feature value fr. For such a feature (gv, fv) expressed in local frame gv \u2208 G we can compute the equivalent feature"}, {"title": "6. Experiments", "content": "To evaluate the effectiveness of incorporating artificial symmetries in MARL, we offer extensive ex-perimentation on formation flight of swarms of N Crazyflie quadrotors. Quadrotors have few inher-ent geometric symmetries to exploit (Yu and Lee (2023a); Smith et al. (2024); Huang et al. (2024);\nHampsey et al. (2023)), so equivariant MARL approaches like Chen and Zhang (2023); Yu and Lee\n(2023b) are not applicable. Our scheme, presented in sections 4-5, allows for the embedding of arti-ficial SE(3) symmetry in the distributed controllers, even though the quadrotor model is not SE(3)-equivariant, as gravity is O(3)-invariant. The multi-agent environment implementation is based on Huang et al. (2023), extended to include aerodynamic effects like drag and downwash, similarly to Panerati et al. (2021). For x(t) \u2208 R\u00b3 desired target position, the state of each robot in the world-frame is si(t) = (xi(t), Xi(t), Ri(t), wi(t), x(t)), where Ri(t) \u2208 SO(3) is the rotation matrix from the body frame to the world frame, xi(t) \u2208 R\u00b3 and wi(t) \u2208 R\u00b3 the position and angular ac-celeration in the world frame. Each robot receives neighborhood observations o\u00bf(t) = Uj\u2208N;sj(t).\nThe task is to learn a distributed, collision-free control policy that guides the swarm to a desired formation x \u2208 R3\u00d7N,\u2200i \u2208 In, i.e. learn \u03c0\u03bf(ui(t)|si(t), oi(t)) mapping state-observations to Gaussian distribution parametrized continuous actions ui(t). For enhanced generalization, a pool of geometric formations are used to construct diverse scenarios (static and dynamic formations, eva-sion pursuit etc.), e.g. Figure 1. The reward function for every quadrotor is R(si(t), oi(t), ui(t)) =\nRx + R\u00ba + Rs, where Rx = -C1||xi(t) \u2013 x(t) || a penalty motivating the quadrotor to approach the target, R = -C21||xi(t)-xj(t)||2<dm\u2200j\u2208Ni\n C3 EjEN; [1 - ||xi(t) - xj(t)||2/dp]+ a collision penalty and R = -C4||Wi(t)||2 - C5||ui(t)||2 an auxiliary reward facilitating learning relatively stable controllers at the early stages of training.\nArchitecture & Training: If the neighborhood Ni is constructed via a Euclidean relative distance,\nfor SE(3) group actions Assumption 1 stands. From (si(t), oi(t)) every agent constructs a local\napproximation Gi,t of the graph representation Gt from Section 2.3. As the rewards function is in-variant to actions from SE(3) and the SN permutation group, via Section 4 the policy becomes"}, {"title": "7. Conclusions & Future Work", "content": "This paper provides a novel methodology for leveraging extrinsic symmetries, indicated solely by the task, for systems without intrinsic ones and introduce the Group Equivarinat Graphormer, an equivariant neural architecture adaptable to different symmetry groups. The experimental results of our work suggest that embedding extrinsic equivariance in MARL policies is beneficial for the generalization, scalability and sample efficiency. However, a task may be invariant to multiple symmetry groups that are compatible with the manifold but not exhibited by the dynamics. So how do we pick the symmetry group? We leave the symmetry selection strategy for future work."}]}