{"title": "Lower-dimensional projections of cellular expression\nimproves cell type classification from single-cell RNA\nsequencing", "authors": ["Muhammad Umar", "Muhammad Asif", "Arif Mahmood"], "abstract": "Single-cell RNA sequencing (scRNA-seq) enables the study of cellular diversity at single cell level. It provides a\nglobal view of cell-type specification during the onset of biological mechanisms such as developmental processes and\nhuman organogenesis. Various statistical, machine and deep learning-based methods have been proposed for cell-type\nclassification. Most of the methods utilizes unsupervised lower dimensional projections obtained from for a large reference\ndata. In this work, we proposed a reference-based method for cell type classification, called EnProCell. The EnProCell,\nfirst, computes lower dimensional projections that capture both the high variance and class separability through an\nensemble of principle component analysis and multiple discriminant analysis. In the second phase, EnProCell trains\na deep neural network on the lower dimensional representation of data to classify cell types. The proposed method\noutperformed the existing state-of-the-art methods when tested on four different data sets produced from different single-\ncell sequencing technologies. The EnProCell showed higher accuracy (98.91) and F1 score (98.64) than other methods for\npredicting reference from reference datasets. Similarly, EnProCell also showed better performance than existing methods in\npredicting cell types for data with unknown cell types (query) from reference datasets (accuracy:99.52; F1 score: 99.07).\nIn addition to improved performance, the proposed methodology is simple and does not require more computational\nresources and time. the EnProCell is available at https://github.com/umar1196/EnProCell.", "sections": [{"title": "Introduction", "content": "Single-cell RNA sequencing (scRNA-seq) revolutionized the\nunderstanding of cellular expression by providing a static and\nhigh-resolution snapshot of gene expression at the individual\ncell level. Unlike the traditional bulk RNA-seq, scRNA-seq\nenables researchers to comprehensively characterize cellular\nheterogeneity(1), thus, making it a powerful tool to investigate\nthe response to therapy (2), the likelihood of resistance(3; 4),\ncandidacy for alternative therapeutic intervention(5), evolution\nof the human brain (6; 7) and understanding of changes in\ncellular state because of development or response to certain\nstimuli (8; 9). Additionally, scRNA showed applications in\nthe identification of novel cell types and subtypes(10; 11),\nthe discovery of rare cells (12; 13; 6), and the elucidation of\ncomplex tissue architectures, including the human brain(14).\nThe identification of cell types or states is a primary objective\nof scRNA-seq studies (15), as the discovery of accurate cell\nrepresentations contributes significantly to our understanding\nof cellular heterogeneity and its implications in biological\nsystems.\nTherefore to decipher the cell types or states from single cell\ngene expression profiles, different data analytical approaches\nsuch as correlation (16) and machine learning (17; 18; 19) based\nmethod have been proposed. Despite these efforts, cell type\nidentification remains an elusive task due to a number of\nchallenges.\nscRNA experiments produce a large amount of sparse\nand high-dimensional data. Dimension reduction methods\nsuch as the principal component analysis (PCA) recapitulate\nbiologically relevant information from sparse and high\ndimensional cellular expression. Clustering is employed to\nidentify biologically similar groups of cells or states. There\nexist several methods for clustering of cells such as SC3 (20),\nSeurat(21), and pcaReduce (22). The annotation of clusters is\nlargely determined by identifying differentially expressed genes\nfor each cluster. To define the cell type for each identified\ncluster, differentially expressed genes of targeted cluster are\nsearched in canonical gene-based marker databases (23; 24; 25).\nThe availability of cell atlas, for example, Human Cell Atlas\n(HCA) motivated the development of cell-type annotation\napproaches that leverage the previously annotated reference\ndata. Such reference-based approaches transfer cell type labels\nfrom reference to data with unknown cell types by computing\nthe similarities between them. There also exist methods that\nleverage the lower dimensional projections of reference data\nto predict the cell type for query (unannotated scRNA data).\nFor example, scPred (17) employs single value decomposition\n(SVD) to compute principal components (PCs), representing\ncellular expression in lower dimensions. Wilcoxon test was\nemployed to identify PCs differentiating the cell types. Support\nvector machine (SVM) was employed on selected features to\npredict the cell types. Furthermore, the query dataset was\nalso projected in lower dimensional space to predict their cell"}, {"title": "Materials and methods", "content": "Figure 1 presents a graphical overview of the proposed\nmethodology."}, {"title": "Data prepossessing and normalization", "content": "First, single cell gene expression profiles were screened for\nvariable genes. Variable genes have a significant difference in\nexpression level in the cells. These genes have a high variance"}, {"title": "EnProCell", "content": "The proposed method (EnProCell) is based on two steps. In\nthe first step, a model is trained using the training data set\nconsisting of gene expression matrix Xtrain, consisting of n\ntraining examples and m genes. In the second step trained\nmodel is used to predict the cell type of test data set from\ndifferent samples. In training principle component analysis\nis used to find the components with the high variance that\nare combined with the discriminative components using the\nmultiple discriminant analysis. Combined components are used\nto project the training data to lower dimensional space and the\nmodel is trained using this reduced form of data. To predict\nthe cell types, test data expression values are projected to lower\ndimensional space using the components from a training set and\nfed to the trained model to assign the cell types."}, {"title": "Extracting the principle components (PCs) with\nhigh variance", "content": "To extract the principle components with high variance pre-\nprocessed gene expression matrix Xtrain is used, consisting of n\nrecords and m genes. To center the expression matrix X for each\ngene, the mean expression value is calculated and subtracted\nfrom each expression value.\n$\\mu = \\frac{1}{n}\\sum_{i=1}^{n} X_{i}$\n(1)\n\\begin{equation*}\nX_{nm} = \\begin{bmatrix}\nX_{11} - \\mu_{1} & X_{12} - \\mu_{2} & ... & X_{1m} - \\mu_{m} \\\\\nX_{21} - \\mu_{1} & X_{22} - \\mu_{2} & ... & X_{2m} - \\mu_{m} \\\\\n... & ... & ... & ... \\\\\nX_{n1} - \\mu_{1} & X_{n2} - \\mu_{2} & ... & X_{nm} - \\mu_{m}\n\\end{bmatrix}\n\\end{equation*}\nAfter this covariance matrix, C is calculated, which measures\nhow a change in one variable affects the other variables. The\nmathematical expression is given as:\n$C_{nn} = X_{nm} * X_{nm}$\n(2)\n\\begin{equation*}\nC_{mm} = \\begin{bmatrix}\nC(x_{11}, X_{11}) & C(x_{12}, X_{22}) & ... & C(x_{1m}, X_{mm}) \\\\\nC(x_{21}, X_{11}) & C(x_{22}, X_{22}) & ... & C(x_{2m}, X_{mm}) \\\\\n... & ... & ... & ... \\\\\nC(x_{m1}, X_{11}) & C(x_{m2}, X_{22}) & ... & C(x_{mm}, X_{mm})\n\\end{bmatrix}\n\\end{equation*}"}, {"title": "Extracting the discriminative components", "content": "To deal with the limitation of principle component analysis,\nthat is when the data is projected to lower dimensional space\nthe data for different classes overlap. To ensure the separability\nin the lower dimensional space Multiple discriminant analysis\nis used, which tries to maximize the inter-class scatter and\nreduces the intra-class scatter that increases the separability\nin the lower dimensional space. To calculate the between-class\nscatter, the mean for each class is calculated and then for each\nclass difference of mean is calculated, and multiplied by its\ntranspose. The mathematical form is given as\n$S_{b} = (m_{1} - m_{2})(m_{1} - m_{2})^{T}$\n(4)\nHere m\u2081 and m2 refer to the means of class 1 and 2 respectively.\nTo calculate the within-class scatter mean vector for each\nclass is calculated. Then the mean of each class is subtracted\nfrom the respective class data and the resultant matrix is\nmultiplied by the transpose of itself to obtain the square matrix.\nThis square matrix captures the variability or scatter within a\nclass. Scatter matrices obtained from each class are added up\nto get a single matrix that captures the within-class scatter in\ndata. The mathematical expression is given as\n$S_{w} = \\sum(X_{i} - m_{i})(X_{i} - m_{i})$\n(5)\nHere $X_{i}$ refers to data points of class i, $m_{i}$ is the mean of that\nith class and $S_{w}$ represents the within-class scatter matrix.\nAfter computing the between-class and within-class scatter\nmatrices, the generalized eigenvalue problem is solved to obtain\nthe discriminant components. In mathematical form, it is given\nas\n$S_{w}^{-1}S_{b}* V = \\lambda * V$\n(6)\nWhere $S_{w}^{-1}$ is the inverse of the within-class scatter matrix, \u03bb\nis the eigenvalues and V is the matrix of eigenvectors. These\nvectors are sorted in descending order and the number of\ncomponents selected is equal to the number of unique classes\nin the dataset.\nIn the case of a dataset containing the k unique classes and n\nnumber of records the matrix for the discriminative components\ncan be represented as:\n\\begin{equation*}\nV_{mk} = \\begin{bmatrix}\nv_{11} & v_{12} & ... & v_{1k} \\\\\nv_{21} & v_{22} & ... & v_{2k} \\\\\n... & ... & ... & ... \\\\\nv_{m1} & v_{m2} & ... & v_{mk}\n\\end{bmatrix}\n\\end{equation*}"}, {"title": "Model Training", "content": "After obtaining the discriminative components and the\ncomponents with the high variance, they are ensembled\ntogether. Ensembled representation S is given as\n$S_{mj} = [V U]$\nor\n\\begin{equation*}\nS_{mj} = \\begin{bmatrix}\nv_{11} & v_{12} & ... & v_{1k} & u_{11} & u_{12} & ... & u_{1l} \\\\\nv_{21} & v_{22} & ... & v_{2k} & u_{21} & u_{22} & ... & u_{2l} \\\\\n... & ... & ... & ... & ... & ... & ... & ... \\\\\nv_{m1} & v_{m2} & ... & v_{mk} & u_{m1} & u_{m2} & ... & u_{ml}\n\\end{bmatrix}\n\\end{equation*}\nS is a n by j dimensional vector where n is the number of rows\nand j is the sum of k and l. This ensemble representation is"}, {"title": "Results", "content": "In this study, we have proposed a deep learning-based\nmethodology, called EnProCell to further improve the cell type\nclassification from single-cell expression profiles. EnProCell\nconsists of two core steps. In the first step, EnProcCell employs\nan ensemble of PCA and MDA to obtain a high variance and\ncell-type separable lower-dimensional projections from scRNA\nexpression matrix. In the second step, these projections are\nsubject to a deep neural network for cell-type classification.\nFigure 1 shows the workflow of EnProCell.\nPCA has been widely employed to obtain the lower\ndimensional projections of scRNA expression profiles (29; 30).\nThese projections are used either for clustering of similer\ncells (31) or cell type classification (32). However, PCA is an\nunsupervised dimensional reduction method. Therefore, in\nthe case of the multi-class classification task, the lower dimensional\nprojections from PCA lack the known cell type information.\nThis limitation may result in overlapping of different cell\ntypes while projecting them on components, consequently,\naffecting the overall performance of machine learning classifiers\ntrained on unsupervised projections. To include the cell\ntype information in the lower dimensional projections, we\nhave applied MDA to scRNA expression profiles. The lower\ndimensional projections obtained from supervised MDA were\nensembled with PCA projections and are used to project the\ntrain and test data in lower dimensional space. A deep neural\nnetwork trained on training data can be used to predict the cell\ntypes for test dataset.\nThe EnProCell was tested on six different datasets (Table 1).\nThe filtered BaronHuman (33) dataset (GEO: GSE84133) was\nsequenced through inDrop platform and consists of 8569 cells\nand 17500 genes. The second pancreatic dataset is Muraro (34)\nsequenced using CEL-Seq2 platform. The filtered pancreatic\ndataset contains 2122 cells and 18916 genes. The third dataset,\nSegerstolpe (35) dataset comprises 2133 cells and 22758 genes\nafter applying the filtration steps. It was sequenced through\nthe Smart-Seq2 sequencing platform. The fourth dataset is Xin\n(36) which is publically available on GEO having the access\nnumber GSE81608. It contains 33890 genes and 1449 cells in\nfiltered form. Furthermore, the most widely used and popular\nperipheral blood mononuclear cells (PBMCs) data from two\ndifferent individuals were also used to test EnProCell. Cells\nwere sequenced using Illumina NextSeq 500. The PBMC1 (37)\ndataset consists of 3500 cells and 32838 genes. The second\ndataset PBMC2 (37) consists of 3000 cells and 32838 genes,\nhaving 9 unique cell types.\nF1 score and overall accuracy evaluation measures were used\nto estimate the performance of EnProCell and other methods\non selected datasets. Furthermore, the methods were compared\non their ability to accurately classify cell types from the same\nreference data set, named reference to reference prediction or\nintra-dataset classification in this manuscript. In intra-dataset"}, {"title": "Test time comparison", "content": "We compared the test time of our proposed methodology and\nthe other methods for single-cell classification. The execution\ntime was computed using the system with a 1.10 GHz, Intel\nCore i7 CPU with 32GB memory. Figure 5 shows the execution\ntime for test data of different classifiers and our methodology\nfor three different datasets. Our algorithm is 2.5, 13.7, and 2.6\ntimes faster than the existing best algorithm which is CaSTLe\nfor three different datasets PBMC1, Baron, and a combined\ndata (Muraro, Xin, and Baron) respectively."}, {"title": "Conclusion", "content": "The study presents a novel methodology, named as EnProCell\nto further improve cell type classification from scRNA-seq\ndata. The first component of the proposed methodology\nis an ensemble of PCA and MDA, which aims to obtain\ndiscriminative features from cellular expression profiles. The\nsecond component trains an auto-encoder neural architecture\non extracted discriminative features for cell type classification.\nEnProCell outperformed the existing state-of-the-art methods\nbelonging to different data analytical techniques such as\ntransfer learning. Furthermore, the performance of EnProCell\nwas independent from the platform or technology used to\nproduce the scRNA-seq data. The proposed deep architecture,\ntrained on ensemble projections showed better performance\non datasets belonging to different tissues and organisms. The\nresults demonstrated that the method outperforms existing\nmethods in terms of accuracy and F1 score, while also providing\ninsights into the major sources of variability in scRNA-seq\ndata. EnProCell requires less computational resources and has\nlow computational complexity. Therefore, it can facilitate the"}]}