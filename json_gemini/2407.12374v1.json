{"title": "Graph Signal Processing for Cross-Domain Recommendation", "authors": ["Jeongeun Lee", "SeongKu Kang", "Won-Yong Shin", "Jeongwhan Choi", "Noseong Park", "Dongha Lee"], "abstract": "Cross-domain recommendation (CDR) extends conventional recommender systems by leveraging user-item interactions from dense domains to mitigate data sparsity and the cold start problem. While CDR offers substantial potential for enhancing recommendation performance, most existing CDR methods suffer from sensitivity to the ratio of overlapping users and intrinsic discrepancy between source and target domains. To overcome these limitations, in this work, we explore the application of graph signal processing (GSP) in CDR scenarios. We propose CGSP, a unified CDR framework based on GSP, which employs a cross-domain similarity graph constructed by flexibly combining target-only similarity and source-bridged similarity. By processing personalized graph signals computed for users from either the source or target domain, our framework effectively supports both inter-domain and intra-domain recommendations. Our empirical evaluation demonstrates that CGSP consistently outperforms various encoder-based CDR approaches in both inter-domain and intra-domain recommendation scenarios, especially when the ratio of overlapping users is low, highlighting its significant practical implication in real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Cross-domain recommendation (CDR) has emerged as a promising approach in recommender systems [33]. By leveraging additional information sources, it has addressed the long-standing challenges of data sparsity and the cold-start problem. Data sparsity is a prevalent problem in recommender systems that arises because users interact with only a limited subset of the total available items, making it challenging to accurately learn user preferences. Furthermore, recommender systems have difficulty in providing reliable recommendations to newly joined users, so-called cold-start users, due to the absence of historical interaction data [22]. The core idea behind CDR is to leverage user data from a dense source domain to enhance recommendation performance in a sparse target domain.\nThere are two main scenarios in CDR, which are intra-domain and inter-domain recommendation (Figure 1). Intra-domain recommendation focuses on recommending items to users within the same domain, while leveraging shared user preferences or inter-action patterns to mitigate the data sparsity problem of the target domain. There have been various attempts to tailor domain adaptation methods for facilitating this scenario [4, 6, 10, 11, 14]. On the other hand, inter-domain recommendation aims to recommend items to users in a different domain, where there exists discrepancies between the domains. In this sense, transfer learning methods have been developed to map and align features between the source and target domains [12, 22, 39, 40]. Note that most previous studies on CDR methods have only focused on either an intra-domain or inter-domain recommendation scenario.\nDespite their own advantages, existing CDR approaches face several critical challenges. First, the final performance of existing methods largely depends on the ratio of overlapping users, which indicates how many users are shared between the source and target domains, as they train a model by utilizing overlapping users as a bridge to link the two domains. In general, a low overlap ratio impedes the effective transfer of source domain knowledge to the target domain [7]. Second, most existing methods overlook that two different domains may have fundamentally distinct characteristics and user behaviors, referred to as domain sensitivity, leading to limited performance improvement for CDR scenarios. To maximize"}, {"title": "2 RELATED WORK", "content": "The existing CDR studies can be categorized according to the target CDR scenarios: intra-domain and inter-domain recommendation.\nFor intra-domain recommendation [4, 6, 10, 13, 14, 17, 29, 30, 32, 34, 37], many studies have mitigated the data sparsity problem in the target domain by leveraging information from the source domain. DDSAN [6] proposes a new domain-similarity regularization to promote domain invariance by constraining the model parameters from different domains to be close to each other. DCDCSR [37] leverages the source domain information along with the sparsity degrees of individual users and items. CoNet [10] enables feature learning across domains by incorporating cross-connections in its neural network architecture, which improves the transfer of information between domains. DARec [32] emphasizes the inherent structure of the rating matrix to transfer rating patterns without requiring auxiliary information. CDAML [29] utilizes clustering alongside meta-learning for domain adaptation, aiming to improve recommendations in sparse target domains. CAT-ART [13] proposes a contrastive autoencoder to generate a global user embedding based on information from all domains. UniCDR [3] employs domain-specific and domain-shared embeddings along with aggregation schemes, which also allows it to handle both two CDR scenarios.\nThe inter-domain recommendation [5, 18, 20\u201322, 25, 35, 36, 38, 40] aims to provide recommendations to cold-start users who have not interacted with the target domain, by leveraging their information in the source domain. Many studies have focused on transfer learning based on shared user features or mapping functions. EMCDR [22] uses latent representations and mapping functions for knowledge transfer, and SSCDR [12] further proposes a semi-supervised learning method to effectively train the mapping function. CDRIB [5] introduces new regularizers based on the information bottleneck principle to build user-item correlations across domains. PTUPCDR [40] proposes a meta-network to generate personalized mapping functions. UniCDR [3] can also be applied to recommend inter-domain recommendations using domain-shared embeddings.\nThough effective, the existing CDR methods are often largely dependent on the ratio of overlapping users, as they train a model by utilizing overlapping users as a bridge to link the two domains. Also, most CDR methods lack the capability of explicitly adjusting the impacts of the source domain, which makes them ineffective when two different domains have large intrinsic discrepancies in terms of user behavior."}, {"title": "2.1 Cross domain recommendation", "content": "Recently, Graph Signal Processing (GSP) has gained significant attention as a promising direction for recommender systems [1, 9, 15, 16, 19, 26\u201328], as its primary concept aligns with the goal"}, {"title": "3 PRELIMINARY", "content": "To deal with signals in a graph domain, a fundamental structure is an undirected simple graph G defined as an ordered pair G = (V, &). Here, V represents a set of vertices {\u03c51, \u03c52, . . . , \u03c5n}, which correspond to entities (e.g., users or items), and & is a set of edges indicating relationships among the entities. The graph induces an adjacency matrix A, where rows and columns respectively correspond to the nodes. An entry Aij is set to 1 if there is an edge between node i and j in G, and 0 otherwise."}, {"title": "3.1 Graph Signal Processing", "content": "The concept of smoothness in graphs can be mathematically represented as follows:\n$S(x) = x^TLx = \\sum_{i,j} A_{ij} (x_i - x_j)^2$, (1)\nwhere L = D \u2212 A is the Laplacian matrix. Since L is real-valued and symmetric, its eigen-decomposition is expressed as $L = U\u039bU^T$, in which U is the matrix of eigenvectors and $\u039b = diag(\u03bb1, \u03bb2, ..., \u03bbn)$ is the diagonal matrix of eigenvalues with $\u03bb1 \u2264 \u03bb2 \u2264 ... \u2264 \u03bbn$.\nGraph Fourier Transform (GFT) decomposes graph signals into continuous frequency components. Formally, GFT of a signal x defined on a graph G is given by $\\hat{x} = U^T x$. Here, $\\hat{x}$ represents the signal in the spectral domain, with each component indicating the signal\u2019s content at different frequencies defined by the eigenvalues in \u039b. That is, GFT transforms the graph signal from its original spatial domain into the spectral domain, which represents frequency.\nNote that eigenvectors associated with small eigenvalues enable a smoother division of the graph and capture similar feature information among the nodes. In contrast, eigenvectors with larger eigenvalues tend to distill distinct features between nodes. This disjunction highlights how GFT leverages the spectral properties of the graph to analyze the underlying structure of the data. To be specific, given a Laplacian matrix L, a graph filter can be defined by\n$H(L) = U \\cdot Diag(h(\u03bb1), h(\u03bb2), . . . , h(\u03bbn)) \\cdot U^T$, (2)"}, {"title": "3.1.1 Notations for GSP.", "content": "and with an input signal x, the filtered signal y is obtained by\n$y = H(L)x = U \\cdot Diag(h(\u03bb1), h(\u03bb2), . . . , h(\u03bbn)) \\cdot U^Tx$. (3)\nIn the domain of GSP, graph signals are decomposed into diverse frequency components. Similar to traditional signal processing, low-frequency signals represent localized variations, marked by gradual changes across the graph, whereas high-frequency signals reflect global patterns, showing up through rapid changes across large parts of the graph."}, {"title": "3.1.2 Graph convolution.", "content": "Given a normalized Laplacian matrix $L = I \u2212 \\bar{A}$ and its eigenvalues \u03bbi, where I is the identity matrix and A is a normalized adjacency matrix, a first-order linear filter (also known as linear low-pass filter) locally smooths a graph as follows:\n$h(\u03bb) = 1 \u2212 \u03bb$. (4)\nThe eigenvalues of $\\bar{A}$, denoted as $(\\bar{\u03bb})_i$, are transformed by using\n$(\\bar{A}U)_i = \\bar{A}U_i = (I \u2212 \\bar{L})U_i = U_i \u2212 \u03bb_iU_i = (1 \u2212 \u03bb_i)U_i$. (5)\nThus, the eigenvalues (A\\bar{A})i of A can be expressed as $1 \u2212 \u03bb_i$. This relationship shows that the normalized adjacency matrix A is effectively derived from applying the linear filter H to the Laplacian matrix L, indicated by $H = \\bar{A}$. This demonstrates the intrinsic connection between linear filtering of the Laplacian and the concept of similarity in the graph structure.\nApplying a first-order linear filter is same as a one-layer spatial graph convolution. As both approaches rooted in neighborhood-based approaches [2, 26], the linear filter is simple yet effective in capturing local signals by exploring one-hop neighborhoods.\nK-1\nk=0 A higher-order linear filter for GSP can be represented as $h(i) =\\sum_{k=0}^{K\u22121} \u03b2_k (1 \u2212 \u03bb)^k$ where $\u03b2_k$ are coefficients. This filter can serve as a multi-layer spatial graph convolution, which effectively aggregates multi-hop neighborhood information.\nIdeal low-pass filter. An ideal low-pass filter passes signals with frequencies below a cutoff \u03bb\u03b5 and attenuates those above it, effectively extracting a global representation of the signal by preserving broad features. Specifically, it is described by\n$h(\u03bb) = \\begin{cases}\n1, & \\text{if } |\u03bb| \u2264 \u03bb\u03b5 \\\\\n0, & \\text{if } |\u03bb| > \u03bb\u03b5.\n\\end{cases}$ (6)"}, {"title": "3.1.3 Graph filtering methods.", "content": "Recently, there have been several attempts to employ GSP for collaborative filtering (CF) [16, 26]. The main concept of GSP is smoothness, which refers to the property of a signal on a graph where connected nodes (representing users or items in CF) have similar signal values. A smooth signal on the graph suggests that users and items connected by a short path within the graph are likely to interact with each other, indicating shared preferences. For instance, the linear filter leverages the spectral properties of the graph, particularly focusing on the lower spectrum of the Laplacian matrix, which corresponds to the more smoothly varying components across the graph [31]. This concept aligns with the goal of CF, which aims to exploit similarities between users and items for recommendation."}, {"title": "3.2 GSP-based Collaborative Filtering", "content": "We present a unified CDR framework based on GSP, named as CGSP. CGSP adopts the three basic stages of GSP-based CF, described in Section 3.2, tailoring it for two CDR scenarios: intra-domain and inter-domain recommendation. CGSP effectively fuses preference knowledge from source-domain and target-domain user-item inter-actions without encoder training, enabling more robust CF to the number of overlapping users. Also, CGSP can readily adjust the con-tribution of the source domain information in the similarity graph construction process, enabling effective knowledge utilization ac-cording to the discrepancy between the domains. The overview of our CGSP framework is illustrated in Figure 2."}, {"title": "4 METHOD", "content": "The source and target domains are represented as subscripts S and T, respectively. The sets of users and items in these domains are denoted as Us, UT (for users), and Is, IT (for items)."}, {"title": "4.1 Overview", "content": "We target the CDR setup where the source and target domains partially overlap only in users. We define the set of overlapping users between the two domains as Uo = Us \u2229 UT. We define the normalized user-item interaction matrices for source and target domains, denoted $R_S \u2208 R^{|U_S|\u00d7|I_S|}$ and $R_T \u2208 R^{|U_T|\u00d7|I_T|}$, respectively. Each normalized matrix is obtained by $R = D_u^{\u22121/2}RDu^{\u22121/2}$, where the original interaction matrix R has only binary values that indicate the absence or presence of interactions. For the overlapping users Uo, we define $R_{OS} \u2208 R^{|U_0|\u00d7|I_S|}$ and $R_{OT} \u2208 R^{|U_0|\u00d7|I_T|}$ as their interaction matrix for each of the source and target domains.\nThe simplest similarity based on one-hop neighborhood is denoted as S. For instance, within the target domain, we can define the basic similarity between users and items as $S_{UT,IT} = R_T$. Based on this user-item similarity, the similarity between users and between items can be also specified as below:\n$S_{UT} = S_{UT,IT}S_{UT, IT}^T = RR^T, \\\\ S_{IT} = S_{UT,IT}^TS_{UT, IT} = R^TR$. (7)\nIncluding all similarities of users and items [16], the augmented similarity graph $S_{U_TUI_T} \u2208 R^{(|U_T|+|I_T|)\u00d7(|U_T|+|I_T|)}$ is defined by\n$S_{U_TUI_T} = \\begin{pmatrix}\nS_{UT} & (S_{UT,IT})^T \\\\\nS_{UT,IT} & S_{IT}\n\\end{pmatrix}$. (8)"}, {"title": "4.1.1 Notations.", "content": "The most straightforward solution for utilizing user-item interactions in both domains for GSP is to employ a unified graph that merges two graphs with over-lapping users. This solution can be effective when the source and target domains share a sufficient number of users. However, when there is minimal user overlap, the limited anchor information se-verely restricts effective knowledge transfer across domains; this diminishes the benefits of utilizing the source domain. Therefore, we concentrate on developing a GSP-based CDR framework that can adeptly incorporate cross-domain information, enhancing the effectiveness of GSP even when direct user overlap is low."}, {"title": "4.1.2 GSP-based CDR framework.", "content": "Inspired by the concept of random walks [23], where nodes that are closely connected by a few steps are considered similar, we suggest that items from source and target domains could be seen as similar if there\u2019s a path connecting them through users common to both domains. This connection implies that these users have similar preferences or interests in both domains, which could signify similarity between the items they interact with. Building on this, our approach starts from capturing similarity between source domain items and target domain items and then explores the deeper connections between items (as well as between users) across different domains.\nThe first step of our CGSP framework is to construct a cross-domain similarity graph, denoted by G; this distills the compressed relationships between users and items across the two domains. It effectively addresses the data sparsity problem by constructing an interconnected graph that integrates direct similarities within the target domain with supportive similarities derived from the source domain. This cross-domain approach enables a richer representa-tion of user preferences, which eventually enhances personalized recommendations. To effectively integrate source and target do-main user-item information into a single similarity graph G, we model two distinct graphs: i) the target-only similarity graph that encodes the information within the target domain S, and ii) the source-bridged similarity graph S that incorporates additional information from the source domain. By linearly combining these graphs according to G = (1 \u2212 \u03b1)S + \u03b1S, CGSP facilitates the capture of signals across the domains as well as within the target domain. Note that the hyperparameter \u03b1 helps to find the optimal balance between the two domains, controlling the extent to which signals from the source domain are utilized to enhance cross-domain recommendation.\nOnce the cross-domain similarity graph is constructed, a graph linear filter (see Section 3.1) is applied to the graph to strengthen the underlying connections. Then, an input signal for each user xu is generated to be filtered with the cross-domain similarity graph. Here, CGSP models more intensive and informative signals to encode more personalized preferences, instead of simply using a user\u2019s original interactions as the input signal. By processing the person-alized graph signals through the filtered graph, CGSP obtains the final prediction scores for each user. In detail, for user u, the per-sonalized graph signal xu is filtered by su = xuG, which serves as the final scores for item recommendation in the end.\nBased on the CGSP framework, in this work, we explore three different strategies to define and augment the cross-domain similarity graph, each of which is discussed in the following subsections."}, {"title": "4.2 GSP on Items-Only Similarity Graph", "content": "The first strategy is to construct a cross-domain similarity graph while focusing only on target domain items $G_{IO} \u2208 R^{|I_T|\u00d7|I_T|}$. The similarity graph is obtained by \u03b1-weighted combination of the source-bridged similarity"}, {"title": "4.2.1 Cross-domain similarity graph construction.", "content": "graph $\\bar{S}_{IT}$ and the target-only similarity graph $S_{IT}$ (in Equation (7)),\n$G_{IO} = (1 \u2212 \u03b1)S_{IT} + \u03b1\\bar{S}_{IT}$. (9)\nThe source-bridged item similarity graph is computed by incorporating information from the source domain to enhance the item similarity within the target domain. Inter-domain item similarities are effectively inferred from interactions of the overlapping users.\n$\\bar{S}_{IT} = S_{I_S,I_TS}S_{I_SI_S}^TS_{I_S,I_TS}^T = (R_{OT}R_{OS})^T(R_{OS}R_{OT}) (R_TR_T)$. (10)\nWith the help of source domain knowledge, it is capable of capturing more fine-grained relationships, thereby gaining more intercon-nected (or dense) representation of target domain items."}, {"title": "4.2.2 Personalized graph signal filtering.", "content": "To define personalized signals of each user for the cross-domain similarity graph, described in Section 4.2.1, we generate the signals based on the similarity between a user and the target domain items. For intra-domain and inter-domain recommendation, we separately model the input signals for the source domain users $X_T \u2208 R^{|U_T|\u00d7|I_T|}$ and target domain users $X_S \u2208 R^{|U_S|\u00d7|I_T|}$, described as follows:\n$X_T = Signal(U_T \u2194 I_T) = S_{UT, IT} = R_T$, \\\\$X_S = Signal(U_S \u2194 I_T) = S_{US,IS}S_{IS}^TS_{IS,IT} = R_S (R_{OS}R_{OT})^T$. (11)\nUsing the personalized signals above, the signal filtered on GIO can serve as the final scores for item recommendation. That is, for each user u, the final score is obtained by $s_u = x_uG_{IO} \u2208 R^{|I_T|}$, where xu denotes the input signal for the user u from X."}, {"title": "4.3 GSP on Overlapping Users-Augmented Similarity Graph", "content": "The second strat-egy is to implement augmentation on items-only similarity graph GIO to include overlapping users Uo as well. The augmented similarity graph $G_{oa} \u2208 R^{(|U_0|+|I_T|)\u00d7(|U_0|+|I_T|)}$ integrates source-bridged similarity $\\bar{S}_{U_OI_T}$ and target-only bridged similarity $S_{U_OI_T}$, both of which include all relationships between the overlapping users and target domain items.\n$G_{oa} = (1 \u2212 \u03b1)S_{U_OI_T} + \u03b1\\bar{S}_{U_OI_T} \\\\\n= (1 \u2212 \u03b1)\\begin{pmatrix}\nS_{U_O} & (S_{U_O, I_T})^T \\\\\nS_{U_O, I_T} & S_{I_T}\n\\end{pmatrix} + \u03b1\\begin{pmatrix}\n\\bar{S}_{U_O} & (\\bar{S}_{U_O, I_T})^T \\\\\n\\bar{S}_{U_O, I_T} & \\bar{S}_{I_T}\n\\end{pmatrix}$, (12)\nwhere the similarities of overlapping users in the target domain can be easily built by $S_{UO} = R_{OT}R_{OT}^T$ and $S_{U_O,I_T} = R_{OT}R_TR_T$, similar to Equation (7). The source-bridged similarity for overlapping users is attained by combining their similarities to both domains.\n$\\bar{S}_{U_O} = S_{U_O,I_T}S_{I_SI_S}^TS_{I_S,I_TS}^TS_{I_T,U_O} \\\\\n= R_{OT} (R_{OT}R_{OS})^T (R_{OS}R_{OT})R_{OT}^T, \\\\\n\\bar{S}_{U_O,I_T} = S_{U_O,US}S_{U_SU_O}^TS_{U_O,I_T} \\\\\n= (R_{OS}R_{OS}^TR_S) (R_{OS}R_{OT})^T (R_T^TR_T)$. (13)"}, {"title": "4.3.1 Cross-domain similarity graph construction.", "content": "Since the dimension of cross-domain similarity graph has been extended to $|U_0| + |I_T|$, the input signal should also be extended to include similarity with the overlapping users, resulting in $X_T \u2208 R^{|U_T|\u00d7(|U_0|+|I_T|)}$ and $X_S \u2208 R^{|U_S|\u00d7(|U_0|+|I_T|)}$. Thus, input signals can be built by simply"}, {"title": "4.3.2 Personalized graph signal filtering.", "content": "concatenating the similarities for overlapping users with those for target domain items:\n$X_T = Signal(U_T \u2192 U_O \u222a I_T) \\\\\n= [S_{U_T,U_O} S_{U_T,I_T}] = [R_TR_{OT}^T R_T], \\\\\nX_S = Signal(U_S \u2192 U_O \u222a I_T) \\\\\n= [S_{U_S,U_O} S_{U_S,I_T}] = [R_SR_{OS}^T R_S(R_{OS}R_{OT})^T] .$ (14)\nGiven the extended input signal XT, XS, and the cross-domain similarity graph GOA, a post-processing step is necessary for score prediction. This involves su = (xuGOA)[\u2212n_items:], where n_items refers to the number of target domain items, which extracts each user\u2019s personalized preferences specifically towards the items."}, {"title": "4.4 GSP on Users Augmented Similarity Graph", "content": "For the last strat-egy, we extend the cross-domain similarity to include all users and items in the target domain. Being consistent with previous approaches in Sections 4.2 and 4.3, the source-bridged similarity $\\bar{S}_{U_TUI_T}$ is combined with target-only similarity $S_{U_TUI_T}$, which results in the cross-domain similarity $G_{ua} \u2208 R^{(|U_T|+|I_T|)+(|U_T|+|I_T|)}$;\n$G_{ua} = (1 \u2212 \u03b1)S_{U_TUI_T} + \u03b1\\bar{S}_{U_TUI_T} \\\\\n= (1 \u2212 \u03b1)\\begin{pmatrix}\nS_{U_T} & (S_{U_T,I_T})^T \\\\\nS_{U_T,I_T} & S_{I_T}\n\\end{pmatrix} + \u03b1\\begin{pmatrix}\n\\bar{S}_{U_T} & (\\bar{S}_{U_T,I_T})^T \\\\\n\\bar{S}_{U_T,I_T} & \\bar{S}_{I_T}\n\\end{pmatrix}$ (15)\nNote that the source-bridged similarity for target domain users $\\bar{S}_{U_T}$ can be acquired by linking their similarities to target domain items $S_{U_T,I_T}$ with inter-domain item similarities $\\bar{S}_{I_S,I_T}$:\n$\\bar{S}_{U_T} = S_{U_T, I_T}\\bar{S}_{I_S,I_S}^T\\bar{S}_{I_S,I_TS}^TS_{I_T,U_T} \\\\\n= R_T (R_{OT}R_{OS})^T (R_{OS}R_{OT})R_T^T,\\\\\n\\bar{S}_{U_T,I_T} = S_{U_T,I_TS}\\bar{S}_{I_S,I_S}^T\\bar{S}_{I_S,I_S}S_{I_S,I_TS}^TS_{I_T,I_T} \\\\\n= R_T (R_{OT}R_{OS})^T (R_S^TR_S)(R_{OS}R_{OT})(R_TR_T)$. (16)"}, {"title": "4.4.1 Cross-domain similarity graph construction.", "content": "To make the signals align with the augmented cross-domain similarity graph GUA, the per-sonalized input signals broaden beyond the similarity with target domain items to encompass the similarity with all users in the target domain. They are built by concatenating the similarities with target domain users to those with target domain items.\n$X_T = Signal(U_T \u2192 U_T \u222a I_T) \\\\\n= [S_{U_T} S_{U_T,I_T}] = [R_TR_T^T R_T], \\\\\nX_S = Signal(U_S \u2192 U_T \u222a I_T) \\\\\n= [S_{U_S,U_T} S_{U_S,I_T}] = [R_S(R_{OS}R_{OT})^T R_S(R_{OS}R_{OT})] . (17)$"}, {"title": "4.4.2 Personalized graph signal filtering.", "content": "To extract individual user preferences for target domain items from the augmented graph Gua, it has to be post-processed to obtain final predicted score. Using the personalized signal $x_u \u2208 R^{(|U_T|+|I_T|)}$, the final score is obtained by su = (xuGUA)[-n_items:]."}, {"title": "4.5 Strategy Comparison", "content": "The aforementioned three strategies aim to construct a cross-domain similarity graph G incorporating the target-only similarity S and the source-bridged similarity S. All the strategies basically include"}, {"title": "5 EXPERIMENTS", "content": "In this section, we present the experimental results to answer the following research questions:\n\u2022 RQ1: How effective is CGSP to utilize source domain information with graph signal processing?\n\u2022 RQ2: How effective is CGSP for the cold-start problem?\n\u2022 RQ3: How effective is CGSP when the ratio of overlapping users is low between the source and target domains?\n\u2022 RQ4: How effective is \u03b1 to handle domain discrepancy?\n\u2022 RQ5: How efficient is CGSP in terms of execution time?"}, {"title": "5.1 Experimental Settings", "content": "We employ two widely-used multi-domain datasets: Douban and Amazon [12, 36, 38]. Douban is a popular service in China that features user ratings across various content categories. Following [37], we use Movie as the source domain, and Music and Book as the target domains. Amazon dataset also encompasses a wide range of products and user ratings. Following recent work [3, 40], we select Movie as the source domain and Music as the target domain. Additionally, Sports and Clothes are chosen as the source and target domains."}, {"title": "5.1.1 Datasets and domain setup.", "content": "Our experiments include both intra-domain and inter-domain recommendation scenarios. For the intra-domain"}, {"title": "5.1.2 Evaluation setup.", "content": "We consider different sets of baseline methods for intra-domain and inter-domain CDR scenarios, respectively.\nFor evaluation in intra-domain CDR scenarios, we execute basic CF methods using user-item interactions only in a target domain (single domain), and those in both domains (unified domain):\n\u2022 GF-CF [26], LGCN-IDE [26], PGSP [40]: These are GSP-based methods specifically for CF. In terms of GF-CF and PGSP, they initially utilize a mixed-frequency filter combining a linear filter and an ideal low-pass filter. To compare the results with ours, we conduct experiments using both the linear filter and the mixed-frequency filter, thus reporting the superior performance.\n\u2022 BPR [24], LGCN [8]: These are encoder-based methods that respectively train user/item embeddings and graph encoder through optimization of pairwise ranking loss.\nWe also compare CDR methods for the intra-domain scenario:\n\u2022 DCDCSR [37], CoNet [10]: These are encoder-based meth-ods utilizing the dual-network architecture to transfer information through cross-connections by leveraging shared features between the source and target domains.\n\u2022 UniCDR [3]: This is the most recent and unified framework capable of both intra-domain and inter-domain recommen-dation by learning domain-specific feature extraction and shared feature representations."}, {"title": "5.1.3 Baselines.", "content": "For evaluation in inter-domain CDR scenarios, we execute basic CF methods using user-item interactions in a unified domain (unified domain), where the union of both domains is regarded as a single target domain: GF-CF [26], LGCN-IDE [26], PGSP [40], BPR [24], and LGCN [8]. We additionally evaluate CDR methods for the inter-domain scenario, including UniCDR [3] which is applicable to intra-domain scenarios as well:\n\u2022 EMCDR [22], SSCDR [12], PTUPCDR [16]: These are encoder-based methods that adopt the embedding-and-mapping strategy to project cold-start users\u2019 embeddings from the source domain to the target domain."}, {"title": "5.1.4 Implementation details.", "content": "For CGSP, we evaluate our approach in two configurations depending on how to set the hyperparameter \u03b1: optimal and fixed, whose final performance is denoted as CGSP* and CGSP\u2020, respectively. CGSP* identifies the optimal value for \u03b1 by selecting the one that achieved the highest NDCG score tested on the validation set, whereas CGSP\u2020 uses an empirically fixed value \u03b1 = 0.85. For the baseline CDR methods, we use the experimental settings from the public library3 and the source code4."}, {"title": "5.2 Effectiveness in CDR Scenarios (RQ1&2)", "content": "The recommendation accuracy for target domain users (i.e., intra-domain) is reported in Table 3 (Left). Our CGSP methods show significant performance improvements over single-domain methods, underscoring the value of leveraging source domain information as well, even with GSP-based CF methods. In addition, when compared to the results of baseline methods in the unified domain, CGSP exhibits superior performance.\nNotably, the performance gain of CGSP becomes pronounced in the Amazon Movie Music task, where the overlapping user ratio is only 18%. On the contrary, in the same task, GSP-based CF methods using the unified domain graph do not always perform better than the ones using the single domain graph, implying their sensitiveness to the overlapping user ratio; this suggests that incorporating source domain information into the cross-domain graph is more effective than simply regarding the two domains as a unified domain.\nOur methods also significantly outperform the recent encoder-based CDR methods (i.e., DCDCSR and CoNet), attributable to the inherent challenges of CF with a sparse dataset, where parametric encoders often struggle to be effectively optimized. Among the three augmentation strategies in our CGSP framework, CGSPOA especially demonstrates remarkable performance, which supports the importance of concentrating on overlapping users when integrating information from external domains."}, {"title": "5.2.1 Performance for intra-domain recommendation (RQ1).", "content": "The recommendation accuracy for source domain users who have no interactions in target domain (i.e. cold-start users) is reported in Table 3 (Right). Both of the GSP-based CF methods that adopt the unified domain and cross-domain graph outperform encoder-based methods. Despite the absence of historical interactions in target do-main, CGSP achieves good performance, indicating its effectiveness in addressing the cold-start problem. Similar to intra-domain recom-mendation, for the encoder-based CDR methods, it is challenging to train their inter-domain user mapping functions as well as en-coders by solely using interactions without semantic features; they typically need richer datasets or additional features to perform op-timally, as the interaction matrix by itself lacks the comprehensive data necessary for effective learning in complex CDR scenarios. In this scenario, CGSPUA exhibits remarkable performance compared"}, {"title": "5.2.2 Performance for inter-domain recommendation (RQ1&2).", "content": "To investigate the robustness of CDR methods to the ratio of overlapping users, we measure their accuracy while varying the ratio of the Douban dataset. As indicated in Table 2, the Douban dataset has a very high overlapping user ratio, which is not realistic"}, {"title": "5.3 Robustness to Overlapping User Ratio"}]}