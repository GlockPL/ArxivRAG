{"title": "Graph Signal Processing for Cross-Domain Recommendation", "authors": ["Jeongeun Lee", "SeongKu Kang", "Won-Yong Shin", "Jeongwhan Choi", "Noseong Park", "Dongha Lee"], "abstract": "Cross-domain recommendation (CDR) extends conventional recommender systems by leveraging user-item interactions from dense domains to mitigate data sparsity and the cold start problem. While CDR offers substantial potential for enhancing recommendation performance, most existing CDR methods suffer from sensitivity to the ratio of overlapping users and intrinsic discrepancy between source and target domains. To overcome these limitations, in this work, we explore the application of graph signal processing (GSP) in CDR scenarios. We propose CGSP, a unified CDR framework based on GSP, which employs a cross-domain similarity graph constructed by flexibly combining target-only similarity and source-bridged similarity. By processing personalized graph signals computed for users from either the source or target domain, our framework effectively supports both inter-domain and intra-domain recommendations. Our empirical evaluation demonstrates that CGSP consistently outperforms various encoder-based CDR approaches in both inter-domain and intra-domain recommendation scenarios, especially when the ratio of overlapping users is low, highlighting its significant practical implication in real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Cross-domain recommendation (CDR) has emerged as a promising approach in recommender systems [33]. By leveraging additional information sources, it has addressed the long-standing challenges of data sparsity and the cold-start problem. Data sparsity is a prevalent problem in recommender systems that arises because users interact with only a limited subset of the total available items, making it challenging to accurately learn user preferences. Furthermore, recommender systems have difficulty in providing reliable recommendations to newly joined users, so-called cold-start users, due to the absence of historical interaction data [22]. The core idea behind CDR is to leverage user data from a dense source domain to enhance recommendation performance in a sparse target domain. There are two main scenarios in CDR, which are intra-domain and inter-domain recommendation. Intra-domain recommendation focuses on recommending items to users within the same domain, while leveraging shared user preferences or interaction patterns to mitigate the data sparsity problem of the target domain. There have been various attempts to tailor domain adaptation methods for facilitating this scenario [4, 6, 10, 11, 14]. On the other hand, inter-domain recommendation aims to recommend items to users in a different domain, where there exists discrepancies between the domains. In this sense, transfer learning methods have been developed to map and align features between the source and target domains [12, 22, 39, 40]. Note that most previous studies on CDR methods have only focused on either an intra-domain or inter-domain recommendation scenario.\nDespite their own advantages, existing CDR approaches face several critical challenges. First, the final performance of existing methods largely depends on the ratio of overlapping users, which indicates how many users are shared between the source and target domains, as they train a model by utilizing overlapping users as a bridge to link the two domains. In general, a low overlap ratio impedes the effective transfer of source domain knowledge to the target domain [7]. Second, most existing methods overlook that two different domains may have fundamentally distinct characteristics and user behaviors, referred to as domain sensitivity, leading to limited performance improvement for CDR scenarios. To maximize"}, {"title": "2 RELATED WORK", "content": "The existing CDR studies can be categorized according to the target CDR scenarios: intra-domain and inter-domain recommendation.\nFor intra-domain recommendation [4, 6, 10, 13, 14, 17, 29, 30, 32, 34, 37], many studies have mitigated the data sparsity problem in the target domain by leveraging information from the source domain. DDSAN [6] proposes a new domain-similarity regularization to promote domain invariance by constraining the model parameters from different domains to be close to each other. DCDCSR [37] leverages the source domain information along with the sparsity degrees of individual users and items. CoNet [10] enables feature learning across domains by incorporating cross-connections in its neural network architecture, which improves the transfer of information between domains. DARec [32] emphasizes the inherent structure of the rating matrix to transfer rating patterns without requiring auxiliary information. CDAML [29] utilizes clustering alongside meta-learning for domain adaptation, aiming to improve recommendations in sparse target domains. CAT-ART [13] proposes a contrastive autoencoder to generate a global user embedding based on information from all domains. UniCDR [3] employs domain-specific and domain-shared embeddings along with aggregation schemes, which also allows it to handle both two CDR scenarios.\nThe inter-domain recommendation [5, 18, 20\u201322, 25, 35, 36, 38, 40] aims to provide recommendations to cold-start users who have not interacted with the target domain, by leveraging their information in the source domain. Many studies have focused on transfer learning based on shared user features or mapping functions. EMCDR [22] uses latent representations and mapping functions for knowledge transfer, and SSCDR [12] further proposes a semi-supervised learning method to effectively train the mapping function. CDRIB [5] introduces new regularizers based on the information bottleneck principle to build user-item correlations across domains. PTUPCDR [40] proposes a meta-network to generate personalized mapping functions. UniCDR [3] can also be applied to recommend inter-domain recommendations using domain-shared embeddings.\nThough effective, the existing CDR methods are often largely dependent on the ratio of overlapping users, as they train a model by utilizing overlapping users as a bridge to link the two domains. Also, most CDR methods lack the capability of explicitly adjusting the impacts of the source domain, which makes them ineffective when two different domains have large intrinsic discrepancies in terms of user behavior."}, {"title": "2.2 GSP-based Collaborative Filtering", "content": "Recently, Graph Signal Processing (GSP) has gained significant attention as a promising direction for recommender systems [1, 9, 15, 16, 19, 26\u201328], as its primary concept aligns with the goal"}, {"title": "3 PRELIMINARY", "content": ""}, {"title": "3.1 Graph Signal Processing", "content": ""}, {"title": "3.1.1 Notations for GSP.", "content": "To deal with signals in a graph domain, a fundamental structure is an undirected simple graph $G$ defined as an ordered pair $G = (V, \\mathcal{E})$. Here, $V$ represents a set of vertices $\\{v_1, v_2, ..., v_n\\}$, which correspond to entities (e.g., users or items), and $\\mathcal{E}$ is a set of edges indicating relationships among the entities. The graph induces an adjacency matrix $A$, where rows and columns respectively correspond to the nodes. An entry $A_{ij}$ is set to 1 if there is an edge between node $i$ and $j$ in $G$, and 0 otherwise."}, {"title": "3.1.2 Graph convolution.", "content": "The concept of smoothness in graphs can be mathematically represented as follows:\n$S(x) = x^T L x = \\sum_{i,j} A_{ij} (x_i - x_j)^2$,                                                                                                                                                                                                                                                                                                                                                                                             (1)\nwhere $L = D - A$ is the Laplacian matrix. Since $L$ is real-valued and symmetric, its eigen-decomposition is expressed as $L = U \\Lambda U^T$, in which $U$ is the matrix of eigenvectors and $\\Lambda = diag(\\lambda_1, \\lambda_2, ..., \\lambda_n)$ is the diagonal matrix of eigenvalues with $\\lambda_1 \\leq \\lambda_2 \\leq ... < \\lambda_n$.\nGraph Fourier Transform (GFT) decomposes graph signals into continuous frequency components. Formally, GFT of a signal $x$ defined on a graph $G$ is given by $\\hat{x} = U^T x$. Here, $\\hat{x}$ represents the signal in the spectral domain, with each component indicating the signal's content at different frequencies defined by the eigenvalues in $\\Lambda$. That is, GFT transforms the graph signal from its original spatial domain into the spectral domain, which represents frequency.\nNote that eigenvectors associated with small eigenvalues enable a smoother division of the graph and capture similar feature information among the nodes. In contrast, eigenvectors with larger eigenvalues tend to distill distinct features between nodes. This disjunction highlights how GFT leverages the spectral properties of the graph to analyze the underlying structure of the data. To be specific, given a Laplacian matrix $L$, a graph filter can be defined by\n$H(L) = U \\cdot Diag(h(\\lambda_1), h(\\lambda_2), . . ., h(\\lambda_n)) \\cdot U^T$,                                                                                                                                                                                                                                                                                                                                                                                         (2)"}, {"title": "3.1.3 Graph filtering methods.", "content": "There are several graph filtering methods employed for capturing different patterns (or frequency components) of the target graph.\nLinear filter. Given a normalized Laplacian matrix $L = I \u2013 \\bar{A}$ and its eigenvalues $\\lambda_i$, where $I$ is the identity matrix and $\\bar{A}$ is a normalized adjacency matrix, a first-order linear filter (also known as linear low-pass filter) locally smooths a graph as follows:\nh(\\lambda) = 1 \u2013 \\lambda.                                                                                                                                                                                                                                                                                                                                                                                                    (4)\nThe eigenvalues of $\\bar{A}$, denoted as $(\\Lambda_{\\bar{A}})_i$, are transformed by using\n$(\\Lambda_{\\bar{A}})_i u_i = \\bar{A} u_i = (I - \\hat{L}) u_i = u_i - \\lambda_i u_i = (1 \u2013 \\lambda_i) u_i$.                                                                                                                                                                                                                                                                                                                                                                              (5)\nThus, the eigenvalues $(\\Lambda_{\\bar{A}})_i$ of $\\bar{A}$ can be expressed as $1 \u2013 \\lambda_i$. This relationship shows that the normalized adjacency matrix $\\bar{A}$ is effectively derived from applying the linear filter $H$ to the Laplacian matrix $L$, indicated by $H = \\bar{A}$. This demonstrates the intrinsic connection between linear filtering of the Laplacian and the concept of similarity in the graph structure.\nApplying a first-order linear filter is same as a one-layer spatial graph convolution. As both approaches rooted in neighborhood-based approaches [2, 26], the linear filter is simple yet effective in capturing local signals by exploring one-hop neighborhoods.\nA higher-order linear filter for GSP can be represented as $h(i) = \\sum_{k=0}^{K-1} \\beta_k (1-\u03bb)^k$ where $\u03b2_r$ are coefficients. This filter can serve as a multi-layer spatial graph convolution, which effectively aggregates multi-hop neighborhood information.\nIdeal low-pass filter. An ideal low-pass filter passes signals with frequencies below a cutoff \u03bbc and attenuates those above it, effectively extracting a global representation of the signal by preserving broad features. Specifically, it is described by\n$\\begin{aligned} h(\\lambda) =  \\begin{cases} 1, & \\text{if } |\\lambda| \\leq \\lambda_c \\\\ 0, & \\text{if } |\\lambda| > \\lambda_c.  \\end{cases} \\end{aligned}$                                                                                                                                                                                                                                                                                                                                                                                         (6)"}, {"title": "3.2 GSP-based Collaborative Filtering", "content": "Recently, there have been several attempts to employ GSP for collaborative filtering (CF) [16, 26]. The main concept of GSP is smoothness, which refers to the property of a signal on a graph where connected nodes (representing users or items in CF) have similar signal values. A smooth signal on the graph suggests that users and items connected by a short path within the graph are likely to interact with each other, indicating shared preferences. For instance, the linear filter leverages the spectral properties of the graph, particularly focusing on the lower spectrum of the Laplacian matrix, which corresponds to the more smoothly varying components across the graph [31]. This concept aligns with the goal"}, {"title": "4 METHOD", "content": "We present a unified CDR framework based on GSP, named as CGSP. CGSP adopts the three basic stages of GSP-based CF, described in Section 3.2, tailoring it for two CDR scenarios: intra-domain and inter-domain recommendation. CGSP effectively fuses preference knowledge from source-domain and target-domain user-item interactions without encoder training, enabling more robust CF to the number of overlapping users. Also, CGSP can readily adjust the contribution of the source domain information in the similarity graph construction process, enabling effective knowledge utilization according to the discrepancy between the domains. The overview of our CGSP framework is illustrated in Figure 2."}, {"title": "4.1 Overview", "content": ""}, {"title": "4.1.1 Notations.", "content": "The source and target domains are represented as subscripts S and T, respectively. The sets of users and items in these domains are denoted as $U_S$, $U_T$ (for users), and $I_S$, $I_T$ (for items)."}, {"title": "4.1.2 GSP-based CDR framework.", "content": "The most straightforward solution for utilizing user-item interactions in both domains for GSP is to employ a unified graph that merges two graphs with overlapping users. This solution can be effective when the source and target domains share a sufficient number of users. However, when there is minimal user overlap, the limited anchor information severely restricts effective knowledge transfer across domains; this diminishes the benefits of utilizing the source domain. Therefore, we concentrate on developing a GSP-based CDR framework that can adeptly incorporate cross-domain information, enhancing the effectiveness of GSP even when direct user overlap is low."}, {"title": "4.2 GSP on Items-Only Similarity Graph", "content": ""}, {"title": "4.2.1 Cross-domain similarity graph construction.", "content": "The first strategy is to construct a cross-domain similarity graph while focusing only on target domain items $G_{IO} \u2208 R^{|I_T|\u00d7|I_T|}$. The similarity graph is obtained by \u03b1-weighted combination of the source-bridged similarity graph $\\tilde{S}_{IT}$ and the target-only similarity graph $S_{TT}$ (in Equation (7)),\n$G_{IO} = (1 \u2212 \u03b1)S_{TT} + \u03b1\\tilde{S}_{IT}$                                                                                                                                                                                                                                                                                                                                                                                      (9)\nThe source-bridged item similarity graph is computed by incorporating information from the source domain to enhance the item similarity within the target domain. Inter-domain item similarities are effectively inferred from interactions of the overlapping users.\n$\\tilde{S}_{IT} = S_{T,I_S} S_{I_S,I_S} S_{I_S,T_T} = (R_{OT} R_{OS})^T (R_{OS} R_{OT}) (R_{T} R_{T})^T$.                                                                                                                                                                                                                                                                                                                                                                           (10)\nWith the help of source domain knowledge, it is capable of capturing more fine-grained relationships, thereby gaining more interconnected (or dense) representation of target domain items."}, {"title": "4.2.2 Personalized graph signal filtering.", "content": "To define personalized signals of each user for the cross-domain similarity graph, described in Section 4.2.1, we generate the signals based on the similarity between a user and the target domain items. For intra-domain and inter-domain recommendation, we separately model the input signals for the source domain users $X_T \u2208 R^{|U_T|\u00d7|I_T|}$ and target domain users $X_S \u2208 R^{|U_S|\u00d7|I_T|}$, described as follows:\n$X_T = Signal(U_T \u2194 I_T) = S_{U_T, I_T} = R_{T}$                                                                                                                                                                                                                                                                                                                                                                                    (11)\n$X_S = Signal(U_S \u2194 I_T) = S_{U_S, I_S} S_{I_S,I_S} S_{I_S,I_T} = R_S (R_{OS} R_{OT})^T$\nUsing the personalized signals above, the signal filtered on $G_{IO}$ can serve as the final scores for item recommendation. That is, for each user u, the final score is obtained by $s_u = x_u G_{IO} \u2208 R^{|I_T|}$, where $x_u$ denotes the input signal for the user u from X."}, {"title": "4.3 GSP on Overlapping Users-Augmented Similarity Graph", "content": ""}, {"title": "4.3.1 Cross-domain similarity graph construction.", "content": "The second strategy is to implement augmentation on items-only similarity graph $G_{IO}$ to include overlapping users $U_O$ as well. The augmented similarity graph $G_{OA} \u2208 R^{(|U_O|+|I_T|)\u00d7(|U_O|+|I_T|)}$ integrates source-bridged similarity $\\tilde{S}_{U_O,U_T}$ and target-only bridged similarity $S_{U_O,U_T}$, both of which include all relationships between the overlapping users and target domain items.\n$G_{OA} = (1 \u2212 \u03b1)S_{U_O U I_T} + \u03b1\\tilde{S}_{U_O U I_T}$\n$\\begin{aligned} S_{U_O U I_T} &= \\begin{pmatrix} S_{U_O} & (S_{U_O, I_T})^T \\\\ S_{U_O, I_T} & S_{I_T} \\end{pmatrix} + \u03b1 \\begin{pmatrix} \\tilde{S}_{U_O} & (\\tilde{S}_{U_O, I_T})^T \\\\ \\tilde{S}_{I_T} & \\tilde{S}_{U_O, I_T} \\end{pmatrix} \\end{aligned}$                                                                                                                                                                                                                                                                                                                                                                                                (12)\nwhere the similarities of overlapping users in the target domain can be easily built by $S_{U_O} = R_{OT} R_{OT}^T$ and $S_{U_O, I_T} = R_{OT} R_{T} R_{T}^T$, similar to Equation (7). The source-bridged similarity for overlapping users is attained by combining their similarities to both domains.\n$\\tilde{S}_{U_O} = \\tilde{S}_{U_O, I_T} S_{I_T, I_S} S_{I_S, I_S} S_{I_S, I_T} S_{I_T,U_O}$\n$= R_{OT} (R_{OT} R_{OS}) (R_{OS} R_{OT})^T R_{OT}$,\n$\\tilde{S}_{U_O, I_T} = \\tilde{S}_{U_O, I_S} S_{I_S,U_O} S_{U_O,I_T}$\n$= (R_{OS} R_{OS}^T R_{S}) (R_{OS} R_{OT})^T(R_{T} R_{T}^T)$.                                                                                                                                                                                                                                                                                                                                                                              (13)"}, {"title": "4.3.2 Personalized graph signal filtering.", "content": "Since the dimension of cross-domain similarity graph has been extended to $|U_O| + |I_T|$, the input signal should also be extended to include similarity with the overlapping users, resulting in $X_T\u2208R^{|U_T|\u00d7(|U_O|+|I_T|)}$ and $X_S \u2208 R^{|U_S|\u00d7(|U_O|+|I_T|)}$. Thus, input signals can be built by simply"}, {"title": "4.4 GSP on Users-Augmented Similarity Graph", "content": ""}, {"title": "4.4.1 Cross-domain similarity graph construction.", "content": "For the last strategy, we extend the cross-domain similarity to include all users and items in the target domain. Being consistent with previous approaches in Sections 4.2 and 4.3, the source-bridged similarity $\\tilde{S}_{U_T U I_T}$ is combined with target-only similarity $S_{U_T U I_T}$, which results in the cross-domain similarity $G_{UA} \u2208 R^{(|U_T|+|I_T|)+(|U_T|+|I_T|)}$;\n$G_{UA} = (1 \u2212 \u03b1)S_{U_T U I_T} + \u03b1\\tilde{S}_{U_T U I_T}$\n$\\begin{aligned} S_{U_T U I_T} &= \\begin{pmatrix} S_{U_T} & (S_{U_T, I_T})^T \\\\ S_{U_T, I_T} & S_{I_T} \\end{pmatrix} + \u03b1 \\begin{pmatrix} \\tilde{S}_{U_T} & (\\tilde{S}_{U_T, I_T})^T \\\\ \\tilde{S}_{I_T} & \\tilde{S}_{U_T, I_T} \\end{pmatrix} \\end{aligned}$                                                                                                                                                                                                                                                                                                                                                                                         (15)\nNote that the source-bridged similarity for target domain users $\\tilde{S}_{U_T}$ can be acquired by linking their similarities to target domain items $S_{U_T, I_T}$ with inter-domain item similarities $\\tilde{S}_{I_T, I_S}$\n$\\tilde{S}_{U_T} = S_{U_T, I_T} \\tilde{S}_{I_T, I_S} S_{I_S,I_S} S_{I_S, I_T} \\tilde{S}_{I_T,U_T}$\n$= R_{T} (R_{OT} R_{OS}) (R_{OS} R_{OT})^T R_{T}^T$,\n$\\tilde{S}_{U_T,I_T} = S_{U_T,I_T} \\tilde{S}_{I_T,I_S} S_{I_S,I_S} S_{I_S,I_S} \\tilde{S}_{I_S,I_T} S_{I_T,I_T}$\n$= R_{T} (R_{OT} R_{OS}) (R_{OS} R_{S}^T)(R_{OS} R_{OT})(R_{T} R_{T}^T)$.                                                                                                                                                                                                                                                                                                                                                                            (16)"}, {"title": "4.4.2 Personalized graph signal filtering.", "content": "To make the signals align with the augmented cross-domain similarity graph $G_{UA}$, the personalized input signals broaden beyond the similarity with target domain items to encompass the similarity with all users in the target domain. They are built by concatenating the similarities with target domain users to those with target domain items.\n$X_T = Signal(U_T \u2192 U_T \u222a I_T)$\n$= [S_{U_T} S_{U_T,I_T}] = [R_{T} R_{T}^T R_{T}],$\n$X_S = Signal (U_S \u2192 U_T \u222a I_T)$\n$= [S_{U_S,U_T} S_{U_S,I_T}] = [R_S R_{S}^T R_{OT} R_S(R_{OS} R_{OT}].                                                                                                                                                                                                                                                                                                                                                                                  (17)\nTo extract individual user preferences for target domain items from the augmented graph $G_{UA}$, it has to be post-processed to obtain final predicted score. Using the personalized signal $x_u \u2208 R^{(|U_T|+|I_T|)}$, the final score is obtained by $s_u = (x_u G_{UA})_{[-n\\_items:]}$."}, {"title": "4.5 Strategy Comparison", "content": "The aforementioned three strategies aim to construct a cross-domain similarity graph $G$ incorporating the target-only similarity $S$ and the source-bridged similarity $\\tilde{S}$. All the strategies basically include"}, {"title": "5 EXPERIMENTS", "content": "In this section, we present the experimental results to answer the following research questions:\n\\begin{itemize}\n    \\item \\textbf{RQ1:} How effective is CGSP to utilize source domain information with graph signal processing?\n    \\item \\textbf{RQ2:} How effective is CGSP for the cold-start problem?\n    \\item \\textbf{RQ3:} How effective is CGSP when the ratio of overlapping users is low between the source and target domains?\n    \\item \\textbf{RQ4:} How effective is \u03b1 to handle domain discrepancy?\n    \\item \\textbf{RQ5:} How efficient is CGSP in terms of execution time?\n\\end{itemize}"}, {"title": "5.1 Experimental Settings", "content": ""}, {"title": "5.1.1 Datasets and domain setup.", "content": "We employ two widely-used multi-domain datasets: Douban and Amazon [12, 36, 38]. Douban is a popular service in China that features user ratings across various content categories. Following [37], we use Movie as the source domain, and Music and Book as the target domains. Amazon dataset also encompasses a wide range of products and user ratings. Following recent work [3, 40], we select Movie as the source domain and Music as the target domain. Additionally, Sports and Clothes are chosen as the source and target domains. The statistics and domain setup are summarized in Table 1 and Table 2.\nIt is worth noting that the two datasets have distinct characteristics. Amazon dataset is highly sparse, which makes recommendation tasks challenging. On the other hand, Douban dataset has a very high ratio of overlapping users 2, almost reaching 1; this indicates that most of the users in the Music or Book domains are active in the Movie domain as well."}, {"title": "5.1.2 Evaluation setup.", "content": "Our experiments include both intra-domain and inter-domain recommendation scenarios. For the intra-domain"}, {"title": "5.1.3 Baselines.", "content": "We consider different sets of baseline methods for intra-domain and inter-domain CDR scenarios, respectively.\nFor evaluation in intra-domain CDR scenarios, we execute basic CF methods using user-item interactions only in a target domain (single domain), and those in both domains (unified domain):\n\\begin{itemize}\n    \\item \\textbf{GF-CF} [26], \\textbf{LGCN-IDE} [26], \\textbf{PGSP} [40]: These are GSP-based methods specifically for CF. In terms of GF-CF and PGSP, they initially utilize a mixed-frequency filter combining a linear filter and an ideal low-pass filter. To compare the results with ours, we conduct experiments using both the linear filter and the mixed-frequency filter, thus reporting the superior performance.\n    \\item \\textbf{BPR} [24], \\textbf{LGCN} [8]: These are encoder-based methods that respectively train user/item embeddings and graph encoder through optimization of pairwise ranking loss.\n\\end{itemize}\nWe also compare CDR methods for the intra-domain scenario:\n\\begin{itemize}\n    \\item \\textbf{DCDCSR} [37], \\textbf{CoNet} [10]: These are encoder-based methods utilizing the dual-network architecture to transfer information through cross-connections by leveraging shared features between the source and target domains.\n    \\item \\textbf{UniCDR} [3]: This is the most recent and unified framework capable of both intra-domain and inter-domain recommendation by learning domain-specific feature extraction and shared feature representations.\n\\end{itemize}\nFor evaluation in inter-domain CDR scenarios, we execute basic CF methods using user-item interactions in a unified domain (unified domain), where the union of both domains is regarded as a single target domain: GF-CF [26], LGCN-IDE [26], PGSP [40], BPR [24], and LGCN [8]. We additionally evaluate CDR methods for the inter-domain scenario, including UniCDR [3] which is applicable to intra-domain scenarios as well:\n\\begin{itemize}\n    \\item \\textbf{EMCDR} [22], \\textbf{SSCDR} [12], \\textbf{PTUPCDR} [16]: These are encoder-based methods that adopt the embedding-and-mapping strategy to project cold-start users\u2019 embeddings from the source domain to the target domain.\n\\end{itemize}"}, {"title": "5.1.4 Implementation details.", "content": "For CGSP, we evaluate our approach in two configurations depending on how to set the hyperparameter \u03b1: optimal and fixed, whose final performance is denoted as CGSP* and CGSP\u2020, respectively. CGSP* identifies the optimal value for \u03b1 by selecting the one that achieved the highest NDCG score tested on the validation set, whereas CGSP\u2020 uses an empirically fixed value \u03b1 = 0.85. For the baseline CDR methods, we use the experimental settings from the public library3 and the source code4."}, {"title": "5.2 Effectiveness in CDR Scenarios (RQ1&2)", "content": ""}, {"title": "5.2.1 Performance for intra-domain recommendation (RQ1).", "content": "The recommendation accuracy for target domain users (i.e., intra-domain) is reported in Table 3 (Left). Our CGSP methods show significant performance improvements over single-domain methods, underscoring the value of leveraging source domain information as well, even with GSP-based CF methods. In addition, when compared to the results of baseline methods in the unified domain, CGSP exhibits superior performance.\nNotably, the performance gain of CGSP becomes pronounced in the Amazon Movie\u2192Music task, where the overlapping user ratio is only 18%. On the contrary, in the same task, GSP-based CF methods using the unified domain graph do not always perform better than the ones using the single domain graph, implying their sensitiveness to the overlapping user ratio; this suggests that incorporating source domain information into the cross-domain graph is more effective than simply regarding the two domains as a unified domain.\nOur methods also significantly outperform the recent encoder-based CDR methods (i.e., DCDCSR and CoNet), attributable to the inherent challenges of CF with a sparse dataset, where parametric encoders often struggle to be effectively optimized. Among the three augmentation strategies in our CGSP framework, CGSPOA especially demonstrates remarkable performance, which supports the importance of concentrating on overlapping users when integrating information from external domains."}, {"title": "5.2.2 Performance for inter-domain recommendation (RQ1&2).", "content": "The recommendation accuracy for source domain users who have no interactions in target domain (i.e. cold-start users) is reported in Table 3 (Right). Both of the GSP-based CF methods that adopt the unified domain and cross-domain graph outperform encoder-based methods. Despite the absence of historical interactions in target domain, CGSP achieves good performance, indicating its effectiveness in addressing the cold-start problem. Similar to intra-domain recommendation, for the encoder-based CDR methods, it is challenging to train their inter-domain user mapping functions as well as encoders by solely using interactions without semantic features; they typically need richer datasets or additional features to perform optimally, as the interaction matrix by itself lacks the comprehensive data necessary for effective learning in complex CDR scenarios. In this scenario, CGSPUA exhibits remarkable performance compared"}, {"title": "5.3 Robustness to Overlapping User Ratio (RQ3)", "content": "To investigate the robustness of CDR methods to the ratio of overlapping users, we measure their accuracy while varying the ratio of the Douban dataset. As indicated in Table 2, the Douban dataset has a very high overlapping user ratio, which is not realistic in real-world scenarios. To simulate more realistic settings, we manually adjust the overlapping user ratio from 20% to nearly 100% in the Douban Movie\u2192Music task by randomly removing interactions of overlapping users in the source domain.\nshows the performance changes of CGSP and the GSP-based CF methods in the unified domain, with respect to the ratio of overlapping users. For a CDR scenario with a high overlap ratio, the baseline methods tend to perform well in the unified domain as well, because merging the two domains would have a similar effect to simple data augmentation. However, they show significant performance drops as the overlapping user ratio decreases; in contrast, our CGSP approach shows consistent performance with minimal variance over a wide range of the ratio. Particularly, in case the overlapping user ratio is below 0.5, our method significantly outperforms the baselines. These results demonstrate that our method maintains robust performance even with a small number of overlapping users, highlighting its effectiveness and practicality in real-world CDR scenarios."}, {"title": "5.4 Impact of Source-Bridged Similarity (RQ4)", "content": "We then investigate the impact of the hyperparameter \u03b1 and its optimal value depending on the relationships between the two domains. Figure 4 illustrates recommendation performance across different \u03b1 values, ranging from 0.0 to 1.0, in both intra-domain"}, {"title": "5.5 Efficiency in CDR Scenarios (RQ5)", "content": "We examine the efficiency of CGSP and that of other encoder-based CDR baselines in both recommendation scenarios. Table 4 reports the total execution time (for CGSP) and training time5 (for baselines) required to attain their final outcomes presented in Table 3. The results show that CGSP (running on CPUs) substantially reduces execution time compared to the baselines (running on GPUs); since CGSP does not require optimizing model parameters, it achieves remarkable time efficiency in execution, highlighting another advantage of our GSP-based approach in real-world applications."}, {"title": "5.6 Effect of Various Graph Filters", "content": "Lastly, we explore the potential benefits of applying various types of filters within our framework, even though we have mainly focused on linear filters in this work. In detail, we analyze items-only cross-domain similarity graph $G_{IO}$ from $CGSP_{IO}$ with three different graph filtering methods: linear filter, ideal low-pass filter, and mixed filter. As shown in Figure 5, applying only the linear filter shows the best performance; this is because our CDR dataset has a high sparsity, which makes it challenging for the ideal low-pass filter to capture user preferences from global signals. However, there is still much room for further improvement in performance by utilizing various graph filters."}, {"title": "6 CONCLUSION", "content": "This paper presents a novel and unified CDR framework"}, {"title": "Graph Signal Processing for Cross-Domain Recommendation", "authors": ["Jeongeun Lee", "SeongKu Kang", "Won-Yong Shin", "Jeongwhan Choi", "Noseong Park", "Dongha Lee"], "abstract": "Cross-domain recommendation (CDR) extends conventional recommender systems by leveraging user-item interactions from dense domains to mitigate data sparsity and the cold start problem. While CDR offers substantial potential for enhancing recommendation performance, most existing CDR methods suffer from sensitivity to the ratio of overlapping users and intrinsic discrepancy between source and target domains. To overcome these limitations, in this work, we explore the application of graph signal processing (GSP) in CDR scenarios. We propose CGSP, a unified CDR framework based on GSP, which employs a cross-domain similarity graph constructed by flexibly combining target-only similarity and source-bridged similarity. By processing personalized graph signals computed for users from either the source or target domain, our framework effectively supports both inter-domain and intra-domain recommendations. Our empirical evaluation demonstrates that CGSP consistently outperforms various encoder-based CDR approaches in both inter-domain and intra-domain recommendation scenarios, especially when the ratio of overlapping users is low, highlighting its significant practical implication in real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Cross-domain recommendation (CDR) has emerged as a promising approach in recommender systems [33]. By leveraging additional information sources, it has addressed the long-standing challenges of data sparsity and the cold-start problem. Data sparsity is a prevalent problem in recommender systems that arises because users interact with only a limited subset of the total available items, making it challenging to accurately learn user preferences. Furthermore, recommender systems have difficulty in providing reliable recommendations to newly joined users, so-called cold-start users, due to the absence of historical interaction data [22]. The core idea behind CDR is to leverage user data from a dense source domain to enhance recommendation performance in a sparse target domain. There are two main scenarios in CDR, which are intra-domain and inter-domain recommendation. Intra-domain recommendation focuses on recommending items to users within the same domain, while leveraging shared user preferences or interaction patterns to mitigate the data sparsity problem of the target domain. There have been various attempts to tailor domain adaptation methods for facilitating this scenario [4, 6, 10, 11, 14]. On the other hand, inter-domain recommendation aims to recommend items to users in a different domain, where there exists discrepancies between the domains. In this sense, transfer learning methods have been developed to map and align features between the source and target domains [12, 22, 39, 40]. Note that most previous studies on CDR methods have only focused on either an intra-domain or inter-domain recommendation scenario.\nDespite their own advantages, existing CDR approaches face several critical challenges. First, the final performance of existing methods largely depends on the ratio of overlapping users, which indicates how many users are shared between the source and target domains, as they train a model by utilizing overlapping users as a bridge to link the two domains. In general, a low overlap ratio impedes the effective transfer of source domain knowledge to the target domain [7]. Second, most existing methods overlook that two different domains may have fundamentally distinct characteristics and user behaviors, referred to as domain sensitivity, leading to limited performance improvement for CDR scenarios. To maximize"}, {"title": "2 RELATED WORK", "content": "The existing CDR studies can be categorized according to the target CDR scenarios: intra-domain and inter-domain recommendation.\nFor intra-domain recommendation [4, 6, 10, 13, 14, 17, 29, 30, 32, 34, 37], many studies have mitigated the data sparsity problem in the target domain by leveraging information from the source domain. DDSAN [6] proposes a new domain-similarity regularization to promote domain invariance by constraining the model parameters from different domains to be close to each other. DCDCSR [37] leverages the source domain information along with the sparsity degrees of individual users and items. CoNet [10] enables feature learning across domains by incorporating cross-connections in its neural network architecture, which improves the transfer of information between domains. DARec [32] emphasizes the inherent structure of the rating matrix to transfer rating patterns without requiring auxiliary information. CDAML [29] utilizes clustering alongside meta-learning for domain adaptation, aiming to improve recommendations in sparse target domains. CAT-ART [13] proposes a contrastive autoencoder to generate a global user embedding based on information from all domains. UniCDR [3] employs domain-specific and domain-shared embeddings along with aggregation schemes, which also allows it to handle both two CDR scenarios.\nThe inter-domain recommendation [5, 18, 20\u201322, 25, 35, 36, 38, 40] aims to provide recommendations to cold-start users who have not interacted with the target domain, by leveraging their information in the source domain. Many studies have focused on transfer learning based on shared user features or mapping functions. EMCDR [22] uses latent representations and mapping functions for knowledge transfer, and SSCDR [12] further proposes a semi-supervised learning method to effectively train the mapping function. CDRIB [5] introduces new regularizers based on the information bottleneck principle to build user-item correlations across domains. PTUPCDR [40] proposes a meta-network to generate personalized mapping functions. UniCDR [3] can also be applied to recommend inter-domain recommendations using domain-shared embeddings.\nThough effective, the existing CDR methods are often largely dependent on the ratio of overlapping users, as they train a model by utilizing overlapping users as a bridge to link the two domains. Also, most CDR methods lack the capability of explicitly adjusting the impacts of the source domain, which makes them ineffective when two different domains have large intrinsic discrepancies in terms of user behavior."}, {"title": "2.2 GSP-based Collaborative Filtering", "content": "Recently, Graph Signal Processing (GSP) has gained significant attention as a promising direction for recommender systems [1, 9, 15, 16, 19, 26\u201328], as its primary concept aligns with the goal"}, {"title": "3 PRELIMINARY", "content": ""}, {"title": "3.1 Graph Signal Processing", "content": ""}, {"title": "3.1.1 Notations for GSP.", "content": "To deal with signals in a graph domain, a fundamental structure is an undirected simple graph $G$ defined as an ordered pair $G = (V, \\mathcal{E})$. Here, $V$ represents a set of vertices $\\{v_1, v_2, ..., v_n\\}$, which correspond to entities (e.g., users or items), and $\\mathcal{E}$ is a set of edges indicating relationships among the entities. The graph induces an adjacency matrix $A$, where rows and columns respectively correspond to the nodes. An entry $A_{ij}$ is set to 1 if there is an edge between node $i$ and $j$ in $G$, and 0 otherwise."}, {"title": "3.1.2 Graph convolution.", "content": "The concept of smoothness in graphs can be mathematically represented as follows:\n$S(x) = x^T L x = \\sum_{i,j} A_{ij} (x_i - x_j)^2$,                                                                                                                                                                                                                                                                                                                                                                                             (1)\nwhere $L = D - A$ is the Laplacian matrix. Since $L$ is real-valued and symmetric, its eigen-decomposition is expressed as $L = U \\Lambda U^T$, in which $U$ is the matrix of eigenvectors and $\\Lambda = diag(\\lambda_1, \\lambda_2, ..., \\lambda_n)$ is the diagonal matrix of eigenvalues with $\\lambda_1 \\leq \\lambda_2 \\leq ... < \\lambda_n$.\nGraph Fourier Transform (GFT) decomposes graph signals into continuous frequency components. Formally, GFT of a signal $x$ defined on a graph $G$ is given by $\\hat{x} = U^T x$. Here, $\\hat{x}$ represents the signal in the spectral domain, with each component indicating the signal's content at different frequencies defined by the eigenvalues in $\\Lambda$. That is, GFT transforms the graph signal from its original spatial domain into the spectral domain, which represents frequency.\nNote that eigenvectors associated with small eigenvalues enable a smoother division of the graph and capture similar feature information among the nodes. In contrast, eigenvectors with larger eigenvalues tend to distill distinct features between nodes. This disjunction highlights how GFT leverages the spectral properties of the graph to analyze the underlying structure of the data. To be specific, given a Laplacian matrix $L$, a graph filter can be defined by\n$H(L) = U \\cdot Diag(h(\\lambda_1), h(\\lambda_2), . . ., h(\\lambda_n)) \\cdot U^T$,                                                                                                                                                                                                                                                                                                                                                                                         (2)"}, {"title": "3.1.3 Graph filtering methods.", "content": "There are several graph filtering methods employed for capturing different patterns (or frequency components) of the target graph.\nLinear filter. Given a normalized Laplacian matrix $L = I \u2013 \\bar{A}$ and its eigenvalues $\\lambda_i$, where $I$ is the identity matrix and $\\bar{A}$ is a normalized adjacency matrix, a first-order linear filter (also known as linear low-pass filter) locally smooths a graph as follows:\nh(\\lambda) = 1 \u2013 \\lambda.                                                                                                                                                                                                                                                                                                                                                                                                    (4)\nThe eigenvalues of $\\bar{A}$, denoted as $(\\Lambda_{\\bar{A}})_i$, are transformed by using\n$(\\Lambda_{\\bar{A}})_i u_i = \\bar{A} u_i = (I - \\hat{L}) u_i = u_i - \\lambda_i u_i = (1 \u2013 \\lambda_i) u_i$.                                                                                                                                                                                                                                                                                                                                                                              (5)\nThus, the eigenvalues $(\\Lambda_{\\bar{A}})_i$ of $\\bar{A}$ can be expressed as $1 \u2013 \\lambda_i$. This relationship shows that the normalized adjacency matrix $\\bar{A}$ is effectively derived from applying the linear filter $H$ to the Laplacian matrix $L$, indicated by $H = \\bar{A}$. This demonstrates the intrinsic connection between linear filtering of the Laplacian and the concept of similarity in the graph structure.\nApplying a first-order linear filter is same as a one-layer spatial graph convolution. As both approaches rooted in neighborhood-based approaches [2, 26], the linear filter is simple yet effective in capturing local signals by exploring one-hop neighborhoods.\nA higher-order linear filter for GSP can be represented as $h(i) = \\sum_{k=0}^{K-1} \\beta_k (1-\u03bb)^k$ where $\u03b2_r$ are coefficients. This filter can serve as a multi-layer spatial graph convolution, which effectively aggregates multi-hop neighborhood information.\nIdeal low-pass filter. An ideal low-pass filter passes signals with frequencies below a cutoff \u03bbc and attenuates those above it, effectively extracting a global representation of the signal by preserving broad features. Specifically, it is described by\n$\\begin{aligned} h(\\lambda) =  \\begin{cases} 1, & \\text{if } |\\lambda| \\leq \\lambda_c \\\\ 0, & \\text{if } |\\lambda| > \\lambda_c.  \\end{cases} \\end{aligned}$                                                                                                                                                                                                                                                                                                                                                                                         (6)"}, {"title": "3.2 GSP-based Collaborative Filtering", "content": "Recently, there have been several attempts to employ GSP for collaborative filtering (CF) [16, 26]. The main concept of GSP is smoothness, which refers to the property of a signal on a graph where connected nodes (representing users or items in CF) have similar signal values. A smooth signal on the graph suggests that users and items connected by a short path within the graph are likely to interact with each other, indicating shared preferences. For instance, the linear filter leverages the spectral properties of the graph, particularly focusing on the lower spectrum of the Laplacian matrix, which corresponds to the more smoothly varying components across the graph [31]. This concept aligns with the goal"}, {"title": "4 METHOD", "content": "We present a unified CDR framework based on GSP, named as CGSP. CGSP adopts the three basic stages of GSP-based CF, described in Section 3.2, tailoring it for two CDR scenarios: intra-domain and inter-domain recommendation. CGSP effectively fuses preference knowledge from source-domain and target-domain user-item interactions without encoder training, enabling more robust CF to the number of overlapping users. Also, CGSP can readily adjust the contribution of the source domain information in the similarity graph construction process, enabling effective knowledge utilization according to the discrepancy between the domains. The overview of our CGSP framework is illustrated in Figure 2."}, {"title": "4.1 Overview", "content": ""}, {"title": "4.1.1 Notations.", "content": "The source and target domains are represented as subscripts S and T, respectively. The sets of users and items in these domains are denoted as $U_S$, $U_T$ (for users), and $I_S$, $I_T$ (for items)."}, {"title": "4.1.2 GSP-based CDR framework.", "content": "The most straightforward solution for utilizing user-item interactions in both domains for GSP is to employ a unified graph that merges two graphs with overlapping users. This solution can be effective when the source and target domains share a sufficient number of users. However, when there is minimal user overlap, the limited anchor information severely restricts effective knowledge transfer across domains; this diminishes the benefits of utilizing the source domain. Therefore, we concentrate on developing a GSP-based CDR framework that can adeptly incorporate cross-domain information, enhancing the effectiveness of GSP even when direct user overlap is low."}, {"title": "4.2 GSP on Items-Only Similarity Graph", "content": ""}, {"title": "4.2.1 Cross-domain similarity graph construction.", "content": "The first strategy is to construct a cross-domain similarity graph while focusing only on target domain items $G_{IO} \u2208 R^{|I_T|\u00d7|I_T|}$. The similarity graph is obtained by \u03b1-weighted combination of the source-bridged similarity graph $\\tilde{S}_{IT}$ and the target-only similarity graph $S_{TT}$ (in Equation (7)),\n$G_{IO} = (1 \u2212 \u03b1)S_{TT} + \u03b1\\tilde{S}_{IT}$                                                                                                                                                                                                                                                                                                                                                                                      (9)\nThe source-bridged item similarity graph is computed by incorporating information from the source domain to enhance the item similarity within the target domain. Inter-domain item similarities are effectively inferred from interactions of the overlapping users.\n$\\tilde{S}_{IT} = S_{T,I_S} S_{I_S,I_S} S_{I_S,T_T} = (R_{OT} R_{OS})^T (R_{OS} R_{OT}) (R_{T} R_{T})^T$.                                                                                                                                                                                                                                                                                                                                                                           (10)\nWith the help of source domain knowledge, it is capable of capturing more fine-grained relationships, thereby gaining more interconnected (or dense) representation of target domain items."}, {"title": "4.2.2 Personalized graph signal filtering.", "content": "To define personalized signals of each user for the cross-domain similarity graph, described in Section 4.2.1, we generate the signals based on the similarity between a user and the target domain items. For intra-domain and inter-domain recommendation, we separately model the input signals for the source domain users $X_T \u2208 R^{|U_T|\u00d7|I_T|}$ and target domain users $X_S \u2208 R^{|U_S|\u00d7|I_T|}$, described as follows:\n$X_T = Signal(U_T \u2194 I_T) = S_{U_T, I_T} = R_{T}$                                                                                                                                                                                                                                                                                                                                                                                    (11)\n$X_S = Signal(U_S \u2194 I_T) = S_{U_S, I_S} S_{I_S,I_S} S_{I_S,I_T} = R_S (R_{OS} R_{OT})^T$\nUsing the personalized signals above, the signal filtered on $G_{IO}$ can serve as the final scores for item recommendation. That is, for each user u, the final score is obtained by $s_u = x_u G_{IO} \u2208 R^{|I_T|}$, where $x_u$ denotes the input signal for the user u from X."}, {"title": "4.3 GSP on Overlapping Users-Augmented Similarity Graph", "content": ""}, {"title": "4.3.1 Cross-domain similarity graph construction.", "content": "The second strategy is to implement augmentation on items-only similarity graph $G_{IO}$ to include overlapping users $U_O$ as well. The augmented similarity graph $G_{OA} \u2208 R^{(|U_O|+|I_T|)\u00d7(|U_O|+|I_T|)}$ integrates source-bridged similarity $\\tilde{S}_{U_O,U_T}$ and target-only bridged similarity $S_{U_O,U_T}$, both of which include all relationships between the overlapping users and target domain items.\n$G_{OA} = (1 \u2212 \u03b1)S_{U_O U I_T} + \u03b1\\tilde{S}_{U_O U I_T}$\n$\\begin{aligned} S_{U_O U I_T} &= \\begin{pmatrix} S_{U_O} & (S_{U_O, I_T})^T \\\\ S_{U_O, I_T} & S_{I_T} \\end{pmatrix} + \u03b1 \\begin{pmatrix} \\tilde{S}_{U_O} & (\\tilde{S}_{U_O, I_T})^T \\\\ \\tilde{S}_{I_T} & \\tilde{S}_{U_O, I_T} \\end{pmatrix} \\end{aligned}$                                                                                                                                                                                                                                                                                                                                                                                                (12)\nwhere the similarities of overlapping users in the target domain can be easily built by $S_{U_O} = R_{OT} R_{OT}^T$ and $S_{U_O, I_T} = R_{OT} R_{T} R_{T}^T$, similar to Equation (7). The source-bridged similarity for overlapping users is attained by combining their similarities to both domains.\n$\\tilde{S}_{U_O} = \\tilde{S}_{U_O, I_T} S_{I_T, I_S} S_{I_S, I_S} S_{I_S, I_T} S_{I_T,U_O}$\n$= R_{OT} (R_{OT} R_{OS}) (R_{OS} R_{OT})^T R_{OT}$,\n$\\tilde{S}_{U_O, I_T} = \\tilde{S}_{U_O, I_S} S_{I_S,U_O} S_{U_O,I_T}$\n$= (R_{OS} R_{OS}^T R_{S}) (R_{OS} R_{OT})^T(R_{T} R_{T}^T)$.                                                                                                                                                                                                                                                                                                                                                                              (13)"}, {"title": "4.3.2 Personalized graph signal filtering.", "content": "Since the dimension of cross-domain similarity graph has been extended to $|U_O| + |I_T|$, the input signal should also be extended to include similarity with the overlapping users, resulting in $X_T\u2208R^{|U_T|\u00d7(|U_O|+|I_T|)}$ and $X_S \u2208 R^{|U_S|\u00d7(|U_O|+|I_T|)}$. Thus, input signals can be built by simply"}, {"title": "4.4 GSP on Users-Augmented Similarity Graph", "content": ""}, {"title": "4.4.1 Cross-domain similarity graph construction.", "content": "For the last strategy, we extend the cross-domain similarity to include all users and items in the target domain. Being consistent with previous approaches in Sections 4.2 and 4.3, the source-bridged similarity $\\tilde{S}_{U_T U I_T}$ is combined with target-only similarity $S_{U_T U I_T}$, which results in the cross-domain similarity $G_{UA} \u2208 R^{(|U_T|+|I_T|)+(|U_T|+|I_T|)}$;\n$G_{UA} = (1 \u2212 \u03b1)S_{U_T U I_T} + \u03b1\\tilde{S}_{U_T U I_T}$\n$\\begin{aligned} S_{U_T U I_T} &= \\begin{pmatrix} S_{U_T} & (S_{U_T, I_T})^T \\\\ S_{U_T, I_T} & S_{I_T} \\end{pmatrix} + \u03b1 \\begin{pmatrix} \\tilde{S}_{U_T} & (\\tilde{S}_{U_T, I_T})^T \\\\ \\tilde{S}_{I_T} & \\tilde{S}_{U_T, I_T} \\end{pmatrix} \\end{aligned}$                                                                                                                                                                                                                                                                                                                                                                                         (15)\nNote that the source-bridged similarity for target domain users $\\tilde{S}_{U_T}$ can be acquired by linking their similarities to target domain items $S_{U_T, I_T}$ with inter-domain item similarities $\\tilde{S}_{I_T, I_S}$\n$\\tilde{S}_{U_T} = S_{U_T, I_T} \\tilde{S}_{I_T, I_S} S_{I_S,I_S} S_{I_S, I_T} \\tilde{S}_{I_T,U_T}$\n$= R_{T} (R_{OT} R_{OS}) (R_{OS} R_{OT})^T R_{T}^T$,\n$\\tilde{S}_{U_T,I_T} = S_{U_T,I_T} \\tilde{S}_{I_T,I_S} S_{I_S,I_S} S_{I_S,I_S} \\tilde{S}_{I_S,I_T} S_{I_T,I_T}$\n$= R_{T} (R_{OT} R_{OS}) (R_{OS} R_{S}^T)(R_{OS} R_{OT})(R_{T} R_{T}^T)$.                                                                                                                                                                                                                                                                                                                                                                            (16)"}, {"title": "4.4.2 Personalized graph signal filtering.", "content": "To make the signals align with the augmented cross-domain similarity graph $G_{UA}$, the personalized input signals broaden beyond the similarity with target domain items to encompass the similarity with all users in the target domain. They are built by concatenating the similarities with target domain users to those with target domain items.\n$X_T = Signal(U_T \u2192 U_T \u222a I_T)$\n$= [S_{U_T} S_{U_T,I_T}] = [R_{T} R_{T}^T R_{T}],$\n$X_S = Signal (U_S \u2192 U_T \u222a I_T)$\n$= [S_{U_S,U_T} S_{U_S,I_T}] = [R_S R_{S}^T R_{OT} R_S(R_{OS} R_{OT}].                                                                                                                                                                                                                                                                                                                                                                                  (17)\nTo extract individual user preferences for target domain items from the augmented graph $G_{UA}$, it has to be post-processed to obtain final predicted score. Using the personalized signal $x_u \u2208 R^{(|U_T|+|I_T|)}$, the final score is obtained by $s_u = (x_u G_{UA})_{[-n\\_items:]}$."}, {"title": "4.5 Strategy Comparison", "content": "The aforementioned three strategies aim to construct a cross-domain similarity graph $G$ incorporating the target-only similarity $S$ and the source-bridged similarity $\\tilde{S}$. All the strategies basically include"}, {"title": "5 EXPERIMENTS", "content": "In this section, we present the experimental results to answer the following research questions:\n\\begin{itemize}\n    \\item \\textbf{RQ1:} How effective is CGSP to utilize source domain information with graph signal processing?\n    \\item \\textbf{RQ2:} How effective is CGSP for the cold-start problem?\n    \\item \\textbf{RQ3:} How effective is CGSP when the ratio of overlapping users is low between the source and target domains?\n    \\item \\textbf{RQ4:} How effective is \u03b1 to handle domain discrepancy?\n    \\item \\textbf{RQ5:} How efficient is CGSP in terms of execution time?\n\\end{itemize}"}, {"title": "5.1 Experimental Settings", "content": ""}, {"title": "5.1.1 Datasets and domain setup.", "content": "We employ two widely-used multi-domain datasets: Douban and Amazon [12, 36, 38]. Douban is a popular service in China that features user ratings across various content categories. Following [37], we use Movie as the source domain, and Music and Book as the target domains. Amazon dataset also encompasses a wide range of products and user ratings. Following recent work [3, 40], we select Movie as the source domain and Music as the target domain. Additionally, Sports and Clothes are chosen as the source and target domains. The statistics and domain setup are summarized in Table 1 and Table 2.\nIt is worth noting that the two datasets have distinct characteristics. Amazon dataset is highly sparse, which makes recommendation tasks challenging. On the other hand, Douban dataset has a very high ratio of overlapping users 2, almost reaching 1; this indicates that most of the users in the Music or Book domains are active in the Movie domain as well."}, {"title": "5.1.2 Evaluation setup.", "content": "Our experiments include both intra-domain and inter-domain recommendation scenarios. For the intra-domain"}, {"title": "5.1.3 Baselines.", "content": "We consider different sets of baseline methods for intra-domain and inter-domain CDR scenarios, respectively.\nFor evaluation in intra-domain CDR scenarios, we execute basic CF methods using user-item interactions only in a target domain (single domain), and those in both domains (unified domain):\n\\begin{itemize}\n    \\item \\textbf{GF-CF} [26], \\textbf{LGCN-IDE} [26], \\textbf{PGSP} [40]: These are GSP-based methods specifically for CF. In terms of GF-CF and PGSP, they initially utilize a mixed-frequency filter combining a linear filter and an ideal low-pass filter. To compare the results with ours, we conduct experiments using both the linear filter and the mixed-frequency filter, thus reporting the superior performance.\n    \\item \\textbf{BPR} [24], \\textbf{LGCN} [8]: These are encoder-based methods that respectively train user/item embeddings and graph encoder through optimization of pairwise ranking loss.\n\\end{itemize}\nWe also compare CDR methods for the intra-domain scenario:\n\\begin{itemize}\n    \\item \\textbf{DCDCSR} [37], \\textbf{CoNet} [10]: These are encoder-based methods utilizing the dual-network architecture to transfer information through cross-connections by leveraging shared features between the source and target domains.\n    \\item \\textbf{UniCDR} [3]: This is the most recent and unified framework capable of both intra-domain and inter-domain recommendation by learning domain-specific feature extraction and shared feature representations.\n\\end{itemize}\nFor evaluation in inter-domain CDR scenarios, we execute basic CF methods using user-item interactions in a unified domain (unified domain), where the union of both domains is regarded as a single target domain: GF-CF [26], LGCN-IDE [26], PGSP [40], BPR [24], and LGCN [8]. We additionally evaluate CDR methods for the inter-domain scenario, including UniCDR [3] which is applicable to intra-domain scenarios as well:\n\\begin{itemize}\n    \\item \\textbf{EMCDR} [22], \\textbf{SSCDR} [12], \\textbf{PTUPCDR} [16]: These are encoder-based methods that adopt the embedding-and-mapping strategy to project cold-start users\u2019 embeddings from the source domain to the target domain.\n\\end{itemize}"}, {"title": "5.1.4 Implementation details.", "content": "For CGSP, we evaluate our approach in two configurations depending on how to set the hyperparameter \u03b1: optimal and fixed, whose final performance is denoted as CGSP* and CGSP\u2020, respectively. CGSP* identifies the optimal value for \u03b1 by selecting the one that achieved the highest NDCG score tested on the validation set, whereas CGSP\u2020 uses an empirically fixed value \u03b1 = 0.85. For the baseline CDR methods, we use the experimental settings from the public library3 and the source code4."}, {"title": "5.2 Effectiveness in CDR Scenarios (RQ1&2)", "content": ""}, {"title": "5.2.1 Performance for intra-domain recommendation (RQ1).", "content": "The recommendation accuracy for target domain users (i.e., intra-domain) is reported in Table 3 (Left). Our CGSP methods show significant performance improvements over single-domain methods, underscoring the value of leveraging source domain information as well, even with GSP-based CF methods. In addition, when compared to the results of baseline methods in the unified domain, CGSP exhibits superior performance.\nNotably, the performance gain of CGSP becomes pronounced in the Amazon Movie\u2192Music task, where the overlapping user ratio is only 18%. On the contrary, in the same task, GSP-based CF methods using the unified domain graph do not always perform better than the ones using the single domain graph, implying their sensitiveness to the overlapping user ratio; this suggests that incorporating source domain information into the cross-domain graph is more effective than simply regarding the two domains as a unified domain.\nOur methods also significantly outperform the recent encoder-based CDR methods (i.e., DCDCSR and CoNet), attributable to the inherent challenges of CF with a sparse dataset, where parametric encoders often struggle to be effectively optimized. Among the three augmentation strategies in our CGSP framework, CGSPOA especially demonstrates remarkable performance, which supports the importance of concentrating on overlapping users when integrating information from external domains."}, {"title": "5.2.2 Performance for inter-domain recommendation (RQ1&2).", "content": "The recommendation accuracy for source domain users who have no interactions in target domain (i.e. cold-start users) is reported in Table 3 (Right). Both of the GSP-based CF methods that adopt the unified domain and cross-domain graph outperform encoder-based methods. Despite the absence of historical interactions in target domain, CGSP achieves good performance, indicating its effectiveness in addressing the cold-start problem. Similar to intra-domain recommendation, for the encoder-based CDR methods, it is challenging to train their inter-domain user mapping functions as well as encoders by solely using interactions without semantic features; they typically need richer datasets or additional features to perform optimally, as the interaction matrix by itself lacks the comprehensive data necessary for effective learning in complex CDR scenarios. In this scenario, CGSPUA exhibits remarkable performance compared"}, {"title": "5.3 Robustness to Overlapping User Ratio (RQ3)", "content": "To investigate the robustness of CDR methods to the ratio of overlapping users, we measure their accuracy while varying the ratio of the Douban dataset. As indicated in Table 2, the Douban dataset has a very high overlapping user ratio, which is not realistic in real-world scenarios. To simulate more realistic settings, we manually adjust the overlapping user ratio from 20% to nearly 100% in the Douban Movie\u2192Music task by randomly removing interactions of overlapping users in the source domain.\nshows the performance changes of CGSP and the GSP-based CF methods in the unified domain, with respect to the ratio of overlapping users. For a CDR scenario with a high overlap ratio, the baseline methods tend to perform well in the unified domain as well, because merging the two domains would have a similar effect to simple data augmentation. However, they show significant performance drops as the overlapping user ratio decreases; in contrast, our CGSP approach shows consistent performance with minimal variance over a wide range of the ratio. Particularly, in case the overlapping user ratio is below 0.5, our method significantly outperforms the baselines. These results demonstrate that our method maintains robust performance even with a small number of overlapping users, highlighting its effectiveness and practicality in real-world CDR scenarios."}, {"title": "5.4 Impact of Source-Bridged Similarity (RQ4)", "content": "We then investigate the impact of the hyperparameter \u03b1 and its optimal value depending on the relationships between the two domains. Figure 4 illustrates recommendation performance across different \u03b1 values, ranging from 0.0 to 1.0, in both intra-domain"}, {"title": "5.5 Efficiency in CDR Scenarios (RQ5)", "content": "We examine the efficiency of CGSP and that of other encoder-based CDR baselines in both recommendation scenarios. Table 4 reports the total execution time (for CGSP) and training time5 (for baselines) required to attain their final outcomes presented in Table 3. The results show that CGSP (running on CPUs) substantially reduces execution time compared to the baselines (running on GPUs); since CGSP does not require optimizing model parameters, it achieves remarkable time efficiency in execution, highlighting another advantage of our GSP-based approach in real-world applications."}, {"title": "5.6 Effect of Various Graph Filters", "content": "Lastly, we explore the potential benefits of applying various types of filters within our framework, even though we have mainly focused on linear filters in this work. In detail, we analyze items-only cross-domain similarity graph $G_{IO}$ from $CGSP_{IO}$ with three different graph filtering methods: linear filter, ideal low-pass filter, and mixed filter. As shown in Figure 5, applying only the linear filter shows the best performance; this is because our CDR dataset has a high sparsity, which makes it challenging for the ideal low-pass filter to capture user preferences from global signals. However, there is still much room for further improvement in performance by utilizing various graph filters."}, {"title": "6 CONCLUSION", "content": "This paper presents a novel and unified CDR framework, termed CGSP, based on GSP. Our framework incorporates target-only and source-bridged similarities to construct a cross-domain similarity graph, thereby effectively capturing both intra-domain and inter-domain relationships. In particular, we introduce the hyperparameter \u03b1 to weight incorporation of source domain knowledge, addressing"}]}]}