{"title": "FedRAV: Hierarchically Federated Region-Learning for Traffic Object Classification of Autonomous Vehicles", "authors": ["Yijun Zhai", "Pengzhan Zhou", "Yuepeng He", "Fang Qu", "Zhida Qin", "Xianlong Jiao", "Guiyan Liu", "Songtao Guo"], "abstract": "The emerging federated learning enables distributed autonomous vehicles to train equipped deep learning models collaboratively without exposing their raw data, providing great potential for utilizing explosively growing autonomous driving data. However, considering the complicated traffic environments and driving scenarios, deploying federated learning for autonomous vehicles is inevitably challenged by non-independent and identically distributed (Non-IID) data of vehicles, which may lead to failed convergence and low training accuracy. In this paper, we propose a novel hierarchically Federated Region-learning framework of Autonomous Vehicles (FedRAV), a two-stage framework, which adaptively divides a large area containing vehicles into sub-regions based on the defined region-wise distance, and achieves personalized vehicular models and regional models. This approach ensures that the personalized vehicular model adopts the beneficial models while discarding the unprofitable ones. We validate our FedRAV framework against existing federated learning algorithms on three real-world autonomous driving datasets in various heterogeneous settings. The experiment results demonstrate that our framework outperforms those known algorithms, and improves the accuracy by at least 3.69%. The source code of FedRAV is available at: https://github.com/yjzhai-cs/FedRAV.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous Vehicles (AVs) have made significant progress in industry and academia in recent years. Advanced au-tonomous driving technology liberates humans from laboring driving experiences while also raising numerous research chal-lenges and open questions. AVs are required to address high-dimensional scenarios, the combinations of vehicles, traffic lights, pedestrians, objects, and weather conditions, which seem rarely satisfied with the amount of fed training data. As a prospective resolution, federated learning (FL) [1]\u2013[4] incorporates clients to train a global model using the data collected separately and preserves clients' privacy. However, deploying FL for AVs is in the face of vehicles' non-independent and identically distributed data (i.e. Non-IID, also known as heterogeneous data) [5]-[7], especially considering the complicated traffic environments and driving scenarios. For example, the data collected from highways, urban areas, rural areas, schools, coasts, and mountains vary significantly in their distributions. Intuitively, data acquired from a smaller region tend to have more similar distributions, such as the data collected from the vehicles passing the same traffic light tend to be similar. Based on this obser-vation, a hierarchically Federated Region-learning framework of Autonomous Vehicles (FedRAV) is proposed in this paper to establish an FL framework to learn from vehicles in sub-regions of a much larger area. Realizing FedRAV can help AVs learn autonomous driving models based on data of a more IID distribution, where many challenges need to be addressed. For example, how should a large area be divided into sub-regions adaptively considering the data distribution? To address the challenge, a partitioning mechanism with one-shot communication is proposed in this paper, which divides the area of interest into sub-regions of different sizes based on the region-wise distance, achieving better IID data in each region.\nFurthermore, how should the system learn a specialized model for each AV to fit its local driving data? In order to specialize the models learned in each AV, a personalization strategy via hypernetworks is proposed. FedRAV employs a designated hypernetwork to learn specialized mask vectors per vehicle and personalizes the vehicular model by using the mask vector to weight the models shared by vehicles within the same region. These mask vectors ensure that the specialized vehicular model adopts the beneficial models while discarding the unprofitable ones. Furthermore, the same hypernetwork design is also applied to different regions, which allows vehicles to learn a personalized vehicular model while simultaneously benefiting from the specialized regional model based on regional data. Therefore, the proposed framework can address the Non-IID problem of AVs' data and train the learning model based on numerous vehicles navigating in different regions, which promotes better autonomous driving adapted for driving scenarios.\nThe contributions of the paper are mainly three-fold:\n\u2022 We empirically demonstrate that the spatial distribution of vehicles' collected data exhibits regional similarities and design a partitioning mechanism to divide large driving areas into sub-regions effectively.\n\u2022 We propose a novel hierarchically Federated Region-learning framework of Autonomous Vehicles suitable for achieving federated learning of vehicles considering the Non-IID driving data. Our framework presents an effective personalization strategy, exploiting richer data of plentiful vehicles to train better personalized vehicular models while maintaining regional models.\n\u2022 We evaluate the performance of FedRAV on three real-world autonomous driving datasets and open-access the"}, {"title": "II. PRELIMINARY CASE STUDIES AND MOTIVATION", "content": "Before introducing a holistic framework, we motivate our work with a real-world example. We claim that the spatial distribution of vehicles' collected data exhibits regional sim-ilarities, i.e., samples with similar label distributions tend to aggregate in nearby areas, forming regions. For example, urban and rural areas are usually divided into various sub-regions according to their diverse functions, i.e., schools, stadiums, commercial centers, transportation hubs, highways, country roads, and residential roads, etc. Vehicles traversing these regions tend to encounter more similar scenarios intra-regionally and encounter less similar scenarios inter-regionally. The claim is verified via analysis of realistic data from German cities in the following."}, {"title": "III. REGIONAL PARTITIONING", "content": "Motivated by the regional similarities of the spatial distri-bution of AVs' collected data, we introduce a novel distance in metric space to describe the similarity properties, which is referred to as Region-Wise Distance(RWD). Furthermore, we propose a new partitioning algorithm to divide large areas into sub-regions."}, {"title": "A. Problem Formulation", "content": "We consider a vehicular network with N AVs (a.k.a. clients) K region servers, and one central server. AVs distributed across M cities or towns can traverse several city blocks along the roads. Each AV $i \\in [N]$ has a local dataset $D_i = \\{X(i,j), Y(i,j)\\}$, where $x(i,j)$ is trainable image and $Y(i,j)$ is true label for the image classification task. $V_i = [U_x, V_y]$ represents the coordinates of AV i. $L_i = [l_1, l_2, l_3, \\ldots, l_m]$ is the label vector of class distribution of $D_i$ for i-th AV, where $l_m$ is the number of objects in m-th semantic category for AV i. We assume that a large area containing N AVs is divided into K sub-regions, i.e., $\\{A_k\\}_{k=1}^K$, and U is the set of k regional centroids. Let $X = \\{(V_i, L_i)\\}_{i=1}^N$ denote a set of N AVs. We formulate the problem of finding optimal regional structure $\\{A_k\\}_{k=1}^K$ and regional centroids U as Regional Structure Optimization (RSO) problem. The quantization error $\\Phi_U(X)$ is minimized, where\n$\\Phi_U (X) = \\sum_{i=1}^{N} min_{u \\in U} RWD (x, u)^2$  \nSubject to\n$RWD (x, u) = ||V_x - V_u||_2^2 + \\gamma \\cdot [\\zeta(C_x - C_u)^T W\\zeta(C_x-C_u)]$\n$|U| = K, |X| = N$"}, {"title": "B. Region-Wise Distance", "content": "In a conventional partitioning setting, the large area is divided into sub-regions based on the l2-norm of spatial locations of AVs. However, it does not consider similarities in label distribution across AVs. There is a trade-off between spatial location and label distribution in realistic situations. We tackle this problem via a control knob to combine spatial location with label distribution, which is described as follows.\nDefinition 1 (Spatial Distance). Assumed that N AVs are located in the same Euclidean plane, and $V_i = [U_x, V_y]$ is the coordinate of AV i. Then, the spatial distance between AV i and AV j is defined by,\n$d_{spatial} (i, j) = ||V_i \u2013 V_j ||_2, \\forall i, j\\in [N]$"}, {"title": "Definition 2 (M-Relative Abundance).", "content": "Given the label vector $L_i \\in \\mathbb{R}^m$ of local dataset $D_i$ of AV i, the M-Relative Abundance of AV i amongst all the AVs cross the M cities is represented as $C_i = [c_i^1, c_i^2, \\ldots, c_i^m]$. Concretely, the abundance of m-th category $c_i^m$ is defined as,\n$C_i^m = \\frac{l_i^m - l_{min}^m}{l_{max}^m - l_{min}^m} \\times 255$,\nwhere we let $l_{max}^m = max\\{l_{i}^{(j)}\\}$ and $l_{min}^m = min\\{l_{i}^{(j)}\\}$. The subscript j\u2208 [M] denotes the j-th city among M cities.\n$l_{i}^{(j)}$ represents the number of m-th category in the AV i. denotes the average quantity of m-th category of all AVs in the j-th city. The notations $l_{max}^m$ and $l_{min}^m$ represent the maximum and minimum average number of m-th category of a AV among all M cities, respectively. Specifically, Eq.(6). follows the same rounding rules as Eq.(1). Ranging from 0 to 255, $c^m$ demonstrates the relative abundance of category m for AV i."}, {"title": "Definition 3 (Label Distance).", "content": "Meanwhile, the label distance is defined by,\n$d_{label}(i, j) = ||C_i \u2013 C_j ||_2, \\forall i, j\\in [N]$.\nIt presents a geometrical evaluation in embedding space of M-relative abundance vector. The generic form of the distance is given as follows,\n$d_{label}(i, j) = [\\zeta[(C_i \u2013 C_j)W(C_i \u2013 C_j)], \\forall i, j\\in [N]$,\nwhere $W \\in \\mathbb{R}^{m\\times m}$ is a weight matrix satisfying $W_{ij} \\ge 0$. Here, we let $W = I$, which means that all categories are equally essential.\nIn order to obtain a optimal regional structure satisfying data similarities, we propose to apply region-wise distance to the optimization problem P1. As discussed earlier, a key challenge here is to achieve trade-off between spatial locations and label"}, {"title": "Definition 4 (Region-Wise Distance).", "content": "Region-Wise Distance between AV i and AV j is defined by,\n$RWD(i, j) = ||V_i \u2013 V_j||_2 + [\\zeta(C_i \u2013 C_j)^T W\\zeta(C_i \u2013 C_j)]$,\nwhere $V_{i, j} \\in [N]$ and \u03b3 is adjustable hyperparameter."}, {"title": "C. Partitioning Mechanism", "content": "Our partitioning mechanism follows a client-server paradigm with one-shot communication, as shown in Fig. 2. The mechanism's crux is thoroughly capturing the similarity between AVs by computing the region-wise distance. Therefore, multiple AVs are required to send their coordination V and label vector L to a central server. On the server side, we execute a partitioning algorithm to divide large areas of interest into sub-regions and send regional structure $\\{A_k\\}_{k=1}^K$ back to AVs.\nSpecifically, the P1 is analogous to the Euclidean Clustering Problem, which is unfortunately NP-hard even for K = 2. Due to NP-hardness, no polynomial-time algorithm exists unless Pequals NP. Lloyd proposed a simple and fast heuristic called Lloyd's algorithm [9] that begins with K arbitrary initial solution and iteratively converges to a locally opti-mal solution. However, Lloyd's algorithm is susceptible to improper initialization. K-Means++ seeding [10] can provide provably good initialization with 8(lnK+2)-approximation to the global optimum in expectation. Inspired by the prior works, we propose a novel partition algorithm to solve P1 as shown in Algorithm 1. The algorithm first samples an initial centroid uniformly at random from the set of AVs X and adaptively samples K 1 additional centroids using seeding steps (lines 1-4). In each seeding iteration, the AV $x \\in X$ is added to the set of already sampled centroids U with probability $\\Phi_U(\\{x\\})$ where $\\Phi_U(X)$ is the shortest region-wise distance from AV x to the closest centroid that the Algorithm 1 has chosen. Then, the algorithm will use region-wise distance as a metric to repeat the standard Lloyd's steps (lines 5-8) until a proper regional structure is found."}, {"title": "IV. FEDERATED REGION-LEARNING FRAMEWORK OF AUTONOMOUS VEHICLES (FEDRAV)", "content": "In this section, we present the FedRAV framework that learns driving models via device-edge-cloud communication."}, {"title": "A. Problem Formulation", "content": "In the standard FL setting, the optimization objective aims to find a single global model. It assumes the global model is capable of learning empirical knowledge for every case. However, the prior studies like [5] have proved that a single model may not fit parameter space from models of multiple users. The leading cause of the problem is that local data heterogeneity leads to discrepant model parameter space. More specifically, the discrepant model disturbs the inter-client knowledge transfer. Therefore, to resolve these problems, we propose FedRAV framework that learns a personalized model for each AV and each region respectively.\nThe optimal regional structure $\\{A_k\\}_{k=1}^K$ has been obtained in Section III. AV i expects to learn personalized vehicular models $w_i$ on private dataset $D_i$. Thus, the local objective $F_i(D_i; W_i)$ of i-th vehicle is defined as,\n$F_i(D_i; W_i) = \\frac{1}{|Di|} \\sum_{j=1}^{|Di|} l (x(i,j), Y(i,j); W_i)$,\nwhere $l(;)$ represents a user-defined loss function. In the training of each region k in FedRAV, the vehicle-level joint optimization objectives are formulated as,\n$W^*_k = arg min_{W_k} \\frac{1}{|Ak|} \\sum_{i\\in Ak} Fi (Di; Wi)$,\nwhere optimization variable $W_k = [Wi]_{i\\in Ak}$ represents the set of personalized vehicular models within the region Ak. The optimization problem aims to find a set of personalized vehicular models fitting AVs' parameter space, respectively. From a regional perspective, region k also expects to learn per-sonalized regional models $w_k$ on union dataset $D_k = \\bigcup_{i\\in Ak} Di$.\nSpecifically, AVs need not to transmit their own privacy-sensitive datasets to each region server or central server. Therefore, the regional objective $f_k$ is defined by,\n$f_k (D_k; w_k) = \\frac{1}{|Dk|} \\sum_{j=1}^{|Dk|} l (x(k,j), Y(k,j); W_k)$.\nWe formulate region-level joint optimization objectives as,\n$W^* = arg min_W \\sum_{k=1}^{K} h (D_k; W_k)$,"}, {"title": "B. Overview of FedRAV Framework", "content": "We now present our FedRAV framework that can resolve the above optimization problems P2 and P3 via hypernetworks. Specifically, hypernetworks are widely used in fields of natural language modeling and computer vision to generate model parameters for other neural network. Before delving into more detail, the overview of the federated optimization process is shown in Fig. 3. Concretely, the entire optimization process consists of the following three stages.\nFederated Initialization. As shown in Fig. 3, each AV has a designated hypernetwork on the regional server side, and each region holds a corresponding hypernetwork on the central server side. Then, the hypernetwork $h(v; \\varphi)$ is also a particular deep neural network that maintains a trainable embedding vector v as input and model parameter $\\varphi$. Before the FedRAV starts training, the embedding vector v and model parameter $\\varphi$ are initialized randomly. Given v, the hypernetwork $h(\u00b7;\u00b7)$ can output the personalized mask vectors \u03b1 which can learn cross-client or cross-region information.\nLocal Personalization. Without loss of generality, suppose that AV i executes local training with \u03ba1 iterations on the private dataset Di and sends model update $\u0394w_i$ to regional server k, as shown in the left part of Fig. 3. Then, the regional server k can update the embedding vector vi and model parameter \u03c6i via model update $\u0394w_i$. Specifically, we will discuss the details of the update process in the next Section IV-C. As shown in the middle part of Fig. 3, the local personalization process of FedRAV takes place on the regional server k. Based on the updated embedding vector vi, the hypernetwork hi(\u00b7;\u00b7) can generate the new mask vectors \u03b1i. FedRAV can obtain personalized vehicular models by using the mask vectors to weight the models shared by vehicles within the same region. Unlike FL approaches aggregate a single global model, FedRAV may fit each AV's model parameter space, which gets rid of unprofitable models and ensures a better knowledge transfer."}, {"title": "C. Personalization via Hypernetworks", "content": "Inspired by [11] , a personalized model can be viewed as the linear combination of model parameters from other AVs. Due to the discrepancy of model parameter, we aim to estimate the proper linear combination coefficients via hypernetworks. Suppose that hypernetwork h(\u00b7; \u00b7) can be parameterized by the embedding vector v and model parameter \u03c6, i.e., $h_i(v_i; \\varphi_i)$ denotes hypernetwork designated by AV i and $h_k(v_k; \\varphi_k)$ denotes hypernetwork related to region k. Regional server"}, {"title": "Regional Personalization.", "content": "We utilize the same trick of local personalization to personalize the regional model. Also, FedRAV provides a heuristic aggregation policy to obtain the regional model update \u0394wk, which is used to update the embedding vector vk and hypernetwork model parameter \u03c6k in central server side, as shown in the right part of Fig. 3. We will discuss our heuristic policy for the intra-regional aggregation in Section IV-D. The details are summarized in Algorithm 2."}, {"title": "D. Intra-region Aggregation Policy", "content": "In order to optimize the personalized regional model, we propose a heuristic intra-region aggregation policy with a penalty function. $W_k = [W_i]_{i \\in Ar}$ denotes the set of models from AVs belonging to region k. $\\bar{w}_k = \\frac{1}{|Ak|} \\sum_{i \\in Ak} W_i$ denotes the average model of region k. Instead of average model wk, the model that reflects the preferences of the majority of AVs in the region k is also required, which is described as regional model. Specifically, the average model parameter $w_k$ is selected as the reference model parameter in the regional model parameter space. $||\\bar{w}_i - \\bar{W}_k||$ represents the norm distance between $w_i$ and average model $w_k$. Intuitively, the regional model prefers models closer to the average model. According to the above analysis, the intra-region aggrega-tion policy is formally proposed as follows,\n$w_k = \\frac{g (||w_i \u2013 \\bar{w}_k||)}{\\sum_{\\bar{W}_k \\sum_{i \\in Ak} 9 (||\\bar{W}_j \u2013 \\bar{W}_k||)} w_i$,\nwhere $g(\u00b7) = e^{-(\\cdot)}$ is a penalty function. Function g(\u00b7) is a monotonically decreasing function defined on [0,+\u221e] with the value ranges [0,1]. For simplicity, let $\\beta_i = \\frac{g(||w_i-\\bar{w}_k||)}{\\sum_{j\\in Ak} 9(||\\bar{w}_j-\\bar{W}_k||)}$ which represents the contribution of $w_i$ to the regional model. Specifically, g(\u00b7) will impose a greater penalty if the personalized vehicular model $w_i$ is further from the average model $w_k$. Therefore, lower aggregation weight is assigned to model $w_i$. Then, the region k can compute the pseudo-gradient by $\u0394w_k = w_k \\bar{w}_k$ and upload it to the central server for updating hypernetwork, as shown in Algorithm 2."}, {"title": "V. EXPERIMENTS", "content": "Datasets and Models. We consider traffic object classifi-cation task and evaluate our framework in three real-world datasets: GTSRB [12], MIO-TCD [13] and Vehicle-10, which are widely used to evaluate autonomous driving algorithms. GTSRB, the German traffic sign recognition benchmark, consists of 39270 images of 43 different traffic signs. The classification section of MIO-TCD contains a total of 52801 images from 11 categories of traffic participants. In this work, we also collected 36006 vehicle images from the Internet and divided them into ten categories, which we called Vehicle-101.\nFor all experiments, we consider LetNet-5 [14] for the GTSRB and MIO-TCD datasets, and ResNet-9 [15] for the Vehicle-10."}, {"title": "VI. CONCLUSION", "content": "In this work, we propose a two-stage framework for learning personalized driving models from the scattered data collected from vehicles in various regions. It contains an efficient parti-tioning mechanism with one-shot communication for dividing large areas into sub-regions, and a FedRAV framework to employ the hypernetworks to learn personalized driving mod-els against the heterogeneity, facilitating knowledge transfer among clients and regions. Finally, the extensive evaluations are conducted to verify the method's effectiveness and superior performance compared to state-of-the-art methods."}]}