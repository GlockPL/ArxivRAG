{"title": "An AI-powered Bayesian generative modeling approach for causal inference in observational studies", "authors": ["Qiao Liu", "Wing Hung Wong"], "abstract": "Causal inference in observational studies with high-dimensional covariates presents significant challenges. We introduce CausalBGM, an AI-powered Bayesian generative modeling approach that captures the causal relationship among covariates, treatment, and outcome variables. The core innovation of CausalBGM lies in its ability to estimate the individual treatment effect (ITE) by learning individual-specific distributions of a low-dimensional latent feature set (e.g., latent confounders) that drives changes in both treatment and outcome. This approach not only effectively mitigates confounding effects but also provides comprehensive uncertainty quantification, offering reliable and interpretable causal effect estimates at the individual level. CausalBGM adopts a Bayesian model and uses a novel iterative algorithm to update the model parameters and the posterior distribution of latent features until convergence. This framework leverages the power of AI to capture complex dependencies among variables while adhering to the Bayesian principles. Extensive experiments demonstrate that CausalBGM consistently outperforms state-of-the-art methods, particularly in scenarios with high-dimensional covariates and large-scale datasets. Its Bayesian foundation ensures statistical rigor, providing robust and well-calibrated posterior intervals. By addressing key limitations of existing methods, CausalBGM emerges as a robust and promising framework for advancing causal inference in modern applications in fields such as genomics, healthcare, and social sciences.", "sections": [{"title": "1 Introduction", "content": "One central goal for causal inference in observational studies is to estimate the causal effect of one variable (e.g., treatment) on another (e.g., outcome) while accounting for covariates that represent all other measured variables (Rothman and Greenland, 2005; Pearl, 2009; Imbens and Rubin, 2015; Ding, 2024). Covariates are often high-dimensional for modern applications in genomics, economics, and healthcare (Prosperi et al., 2020; Davey Smith et al., 2020; Forastiere et al., 2021), which makes the covariate adjustment difficult due to the \u201ccurse of dimensionality\" (D'Amour et al., 2021). Additionally, large sample sizes, as is often the case in those scenarios, can further complicate the process by making traditional methods computationally intensive and slow to converge, highlighting the need for developing scalable and effective causal inference method.\nTo handle the issue of high-dimensional covariates, several dimension reduction methods have been proposed to alleviate the difficulty. For example, one of the most popular approaches is to do adjustment or matching based on the propensity score (Rubin, 1974; Rosenbaum and Rubin, 1983; Hirano and Imbens, 2004), which is a one-dimensional feature (e.g., a scalar), denoting the probability of receiving a particular treatment given observed covariates. These methods require fitting a propensity score model first, which is typically done by fitting a logistic regression or a machine learning model (Lee et al., 2010).\nAnother type of dimension reduction method is sufficient dimension reduction (SDR) (Li, 1991, 1992), which projects covariates into a lower-dimensional space, assuming conditional independence of treatment and outcome given the projected features (Ghosh et al., 2021; Luo et al., 2017). However, SDR-based causal inference methods often restrict dimension reduction to be linear transformations and apply separate projections for each treatment value, limiting its applicability in settings with continuous treatments or complex depen-"}, {"title": "2 Methods", "content": ""}, {"title": "2.1 Problem Setup", "content": "Our goal is to estimate the causal effect of one variable X on another variable Y given the presence of the variable V in an observational study based on i.i.d. observations of {(Xi, Yi, Vi)|i = 1,..., N}. X denotes the treatment or exposure variable and Y denotes the outcome or response variable. V\u2208 R\u00ba represents the covariates in a p-dimensional space. Y\u2208 Y is typically real-valued where the support I is a bounded interval in R. X \u2208 X can be either discrete or continuous where the support X is either a finite set or a bounded interval in R.\nIn order to investigate how the potential outcome will respond to the change of treatment, our primary interest is in estimating the population average of this outcome function, also known as the average dose-response function (ADRF), defined by:\n$\\mu(x) = \u0395[Y(x)]$. (1)\nSince we only observe the potential outcomes indexed by the treatment variable (e.g., factual outcome). The random variable Y(x) is not directly observable due to the counterfactual outcomes, and the expectation \u03bc(x) cannot generally be directly identified from the joint distribution of the observed data (X, Y, V). Therefore, additional assumptions are required to ensure the identifiability of \u03bc(x).\nWe first assume X, Y, and V are generated by a latent variable Z \u2208 R\u00ba where q \u226a p. We denote Zo as a subset of the latent variable Z, which affects both treatment and outcome.\nNext, we introduce a modified version of the \u201cunconfoundedness\" assumption with respect to the latent confounding variable Zo."}, {"title": "Assumption 1 (Unconfoundedness)", "content": "Given the low-dimensional latent confounding variable Zo, the potential outcomes Y(x) is independent of treatment variable X,\nXY(x)|Zo. (2)\nUnder the traditional \"unconfoundedness\" assumption, one typically conditions on the high-dimensional covariates V. However, our Assumption 1 makes this requirement less restrictive by showing that it is sufficient to condition on a low-dimensional feature set representing the covariates. Once Zo is given, there should be no unobserved confounding variables that induce correlated changes between the treatment and the outcome.\nBased on assumption 1, it follows that the ADRF can be identified through the following equation,\n$\\mu(x) = \\int E[Y|X = x, Z_0 = z_0]P_{Z_0}(z_0)dz_0$. (3)\nThe identification proof is given in Appendix A. Equation 3 transforms the causal inference problem into the problem of learning a latent confounding variable Zo given the observational data. In the following section, we will outline a AI-powered Bayesian framework in order to learn Zo and estimate the \u03bc(x) in equation 3."}, {"title": "2.2 Causal Generative Modeling", "content": "Our model is described in Figure 1, where X, Y, V represents observed variables and Z = (Zo, Z1, Z2, Z3) denotes the low-dimensional latent variable that needs to be learned. The whole latent space is partitioned into four parts that play different roles in the following generative models of X, Y, and V.\nZ ~\u03c0z(Z),\n\u03b8\u03c7 ~\u03c0\u03bf\u03c7 (\u03b8\u03c7), \u03b8\u03b5 ~ \u03c0\u03bf\u03b5 (\u03b8\u03b3), \u03b8\u03bd ~ \u03c0\u03bf\u03bd (\u03b8\u03bd),\nV ~P(V|Z;0v),\nX ~P(X|Z0, Z2; 0x),\nY ~P(Y|X, Zo, \u03961; \u03b8\u03b3), (4)\nwhere Zo denotes the latent confounding variable that affects both treatment and outcome, Z1 represents the latent features that affect only the outcome, Z2 relates to the latent features that affect only the treatment, and Z3 comprises the remaining latent features that affect neither treatment nor outcome. By partitioning the latent features Z into four different independent components, CausalBGM is able to isolate the underlying dependencies of covariates on treatment and outcome in the low-dimensional latent space. Through the above partition, we hope to identify a minimal covariate feature (e.g., Zo) that affects both treatment and outcome. \u03b8\u03c7, \u03b8\u04af, and \u03b8y are the parameters of the three generative models of treatment, outcome, and covariants, respectively. All the prior distributions are set to be standard multivariate normal distributions.\nSpecifically, we model continuous variables as normal distributions and discrete variables using logistic regression. In typical causal inference settings, the generative processes are defined as follows:\n\u2022 Covariate Modeling. The covariant variable V is modeled as a multivariate normal distribution as follows.\nP(V|Z;0v) = N(\u03bc\u03c5(Z), \u03a3\u03c5(Z)), (5)\nwhere both mean and covariance matrix are learnable functions of latent variable Z parameterized by \u03b8y. To simplify, the covariance matrix \u2211(Z) is represented as (Z)Ip where Ip is the p-dimensional identity matrix and (Z) is a learnable variance function.\n\u2022 Treatment Modeling. For continuous treatments, the treatment variable X is modeled as:\nP(X|\u0396\u03bf, \u03962;0x) = N(\u03bc\u03b1 (\u0396\u03bf, \u03962), \u03c3\u03b1 (\u0396\u03bf, \u03962)), (6)\nwhere both mean \u03bc\u03c0(Zo, Z2) and variance 2 (Zo, Z2) are learnable functions of Zo and Z2 parameterized by \u03b8\u03c7.\nFor binary treatments, X is modeled using a generalized logistic regression:\nP(X = 1|\u0396\u03bf, \u03962;0x) = 1/(1 + e\u00af), (7)\nwhere \u03be ~ \u039d(\u03bc\u03b1 (\u0396\u03bf, \u03962), \u03c32(\u03960, Z2)), and the resulting probability is equivalent to the propensity score.\n\u2022 Outcome Modeling. The outcome variable Y is modeled as a normal distribution:\nP(Y|X, \u0396\u03bf, \u03961; \u03b8\u03b3) = N(\u03bc\u03c8(\u03a7, \u0396\u03bf, \u03961), \u03c3\u03c4(\u03a7, \u0396\u03bf, \u03961)), (8)\nwhere both mean \u03bcy (X, Zo, Z1) and variance \u03c3\u03c4(\u03a7, Zo, Z\u2081) are learnable functions of X, Zo and Z1, parameterized by by.\nNote that the learnable functions (\u03bc\u03b1, \u03c32), (\u03bc\u03b7, \u03c3\u03c4), and (\u03bc\u03c5, \u03c3\u03c4) are represented by three Bayesian neural networks, parameterized by Ox, Oy, and by respectively. In the next section, we will illustrate how we learn the distribution of model parameters \u03b8\u03c7, \u03b8\u03b3, \u03b8y in order to account for the model uncertainty or variation."}, {"title": "2.3 Iterative Updating Algorithm", "content": "We designed an iterative algorithm to update the posterior distribution of model parameters and the posterior distribution of latent variable Z until convergence. According to Bayes' theorem, the joint posterior distribution of the latent features and model parameters is represented as\nP(\u0396,0x,\u03b8\u03b3,0v|X,Y,V) = P(0x,\u03b8\u03b3,0v|X,Y,V)P(Z|X,Y,V,0x,\u03b8\u03b5,\u03b8\u03bd). (9)\nSince the true joint posterior is intractable, we approximate the problem by designing an iterative algorithm. Specifically, we iteratively 1) update the posterior distribution of latent variable Z from P(Z|X,Y,V,0x,\u03b8\u03b3,0v). 2) update the posterior distribution of model parameters (\u03b8\u03c7, \u03b8\u03b3, \u03b8v) from P(0x, \u03b8\u04af, \u03b8\u03bd|X, Y, V, Z).\nTo estimate the posterior distribution of the latent variable Z in step 1), we denote the log-posterior of the latent variable Z as\nlogP(Z|X, Y, V, \u03b8\u03c7, \u03b8\u03b3,0v) = log\u03c0z(Z) + logP(X,Y,V|\u0396,\u03b8\u03c7, \u03b8\u03b3, \u03b8\u03bd) + C,\n= logaz(Z) + logP(V|Z,0x,\u03b8\u03b3, 0v) + logP(X,Y|\u0396,0x,\u03b8\u03b3,\u03b8\u03bd) + C,\n= logrz(Z) + logP(V|Z;0v) + logP(X|Zo, Z2; 0x) + logP(Y|X, \u0396\u03bf, \u03961; \u03b8y) + C, (10)\nwhere C = log\u03c0\u04e9x (0x)+lognex (\u03b8\u03b3)+log\u03c0\u03bf\u03bd (\u03b8v) \u2013 logP(X, Y, V, \u03b8\u03c7, \u03b8\u04af, \u03b8v) is irrelevant to Z. The second equality in (10) is obtained by the conditional independence in Assumption 1. The log-likelihood of the three generative models are denoted as\n$\\logP(V|Z;\\theta_v) = -\\frac{1}{2}\\log(\\sigma_v^2(Z)) - \\frac{1}{2\\sigma_v^2(Z)} ||V - \\mu_v(Z)||^2 + C_1$,\n$\\logP(X|Z_0, Z_2;\\theta_x) = -\\frac{1}{2}\\log(\\sigma_x^2(Z_0, Z_2)) - \\frac{1}{2\\sigma_x^2(Z_0, Z_2)} (X - \\mu_x(Z_0, Z_2))^2 + C_2$,\n$\\logP(Y|X, Z_0, Z_1;\\theta_y) = -\\frac{1}{2}\\log(\\sigma_y^2(X, Z_0, Z_1)) - \\frac{1}{2\\sigma_y^2(X, Z_0, Z_1)} (Y - \\mu_y(X, Z_0, Z_1))^2 + C_3$, (11)\nwhere C1,C2, and C3 are constants.\nTo update the posterior P(0x,\u03b8\u03b3,0v|X,Y,V, Z) over all model parameters \u03b8\u03c7, \u03b8y, and \u03b8y from three generative models in step 2), we further decompose the joint posterior for the model parameters based on conditional independence, which is denoted as\nlogP(0x|X,Y,V, Z) = log\u03c0\u04e9x (0x) + logP(X|Z0, Z2; 0x) + C4,\nlogP(0y|X,Y,V, Z) = logney (\u03b8\u03b3) + logP(Y|X, Z0, Z1; 0y) + C5,\nlogP(0v|X,Y,V, Z) = lognev (0v) + logP(V|Z;0v) + C6, (12)\nwhere C4 is irrelevant with 9x, C5 is irrelevant with \u03b8y, and C6 is irrelevant with \u03b8y. Since the posterior distribution of parameters in each generative model is intractable, we employ three Bayesian network networks, which use variational inference (VI) to approximate each term in (12). Specifically, we introduce three variational distributions q\u00a2x (\u03b8\u03c7),\u03b1\u03c6\u03b3 (\u03b8\u03b3), and qov (\u03b8v) to approximate the true posteriors in (12), respectively. The variational distributions are chosen to be normal distributions as q4x(0x) ~ \u039d(\u03b8\u03c7\\\u03bc\u03c6\u03c7, \u03c3\u03c7), ), q\u03c6\u1ef5 (\u03b8\u03b3) ~ \u039d(\u03b8\u03b3\u03bc\u03c6\u03b3,\u03c3\u03b1\u03b3), and q\u03c6\u03bd (\u03b8v) ~ \u039d(\u03b8\u03bd\u03bc\u03c6\u03bd, \u03c3\u03b1\u03bd Ip). Note that x = (\u03bc\u03c6\u03c7, \u03c3\u03c7), \u03a6\u03a5 = (\u03bc\u03c6\u03b3, \u03c3\u03b1\u03bd), and \u03c6\u03bd = (\u03bc\u03c6\u03bd, \u03c3\u03b1\u03bd) are learnable parameters for the variational distributions (variational parameters). The evidence lower bound (ELBO) for each posterior is defined as\n$\\mathcal{L}(\\phi_x) = \\mathbb{E}_{q_{\\phi_x}(\\theta_x)}[\\log P(X|Z_0, Z_2; \\theta_x)] - KL(q_{\\phi_x}(\\theta_x)|| \\pi_{\\theta_x}(\\theta_x))$,\n$\\mathcal{L}(\\phi_y) = \\mathbb{E}_{q_{\\phi_y}(\\theta_y)}[\\log P(Y|X, Z_0, Z_1; \\theta_y)] - KL(q_{\\phi_y}(\\theta_y)|| \\pi_{\\theta_y}(\\theta_y))$,\n$\\mathcal{L}(\\phi_v) = \\mathbb{E}_{q_{\\phi_v}(\\theta_v)}[\\log P(V|Z; \\theta_v)] - KL(q_{\\phi_v}(\\theta_v)|| \\pi_{\\theta_v}(\\theta_v))$, (13)\nwhere the first term in the ELBO denotes the expected log-likelihood under the variational distribution and the second term denotes Kullback-Leibler divergence between the variational posterior and the prior distribution over model parameters. To facilitate the computation of gradient w.r.t the variational parameters, we use reparameterization trick, which is represented as\n\u03b8\u03c7 = \u03bc\u03c6\u03c7 + \u03c3\u03c6\u03c7 \u00a9 \u20acx,\n\u03b8\u03b3 = \u03bc\u03c6\u03b3 + \u03c3\u03c6\u03b3 \u20ac\u03b3,\n\u03b8\u03bd = \u03bc\u03c6\u03bd + \u03c3\u03c6\u03bd \u039f \u03b5\u03bd, (14)\nwhere ex ~ N(0, Idx), \u20acy ~ N(0, Idy), and ev ~ N(0, Idv). \u2299 is the element-wise product. dx, dy, and dy denote the number of parameters in each generative model. Using variational inference in BNNs for each mini-batch may lead to high-variance gradient estimates.\nWe adopt the Flipout technique (Wen et al., 2018) in the implementation of the reparameterization trick to reduce this variance by decorrelating the model parameters perturbations across different training examples in the same mini-batch. Briefly, in stead of using a single shared random draw of model parameters for the entire mini-batch, Flipout constructs pseudo-independent perturbations for each example independently within a mini-batch, which decorrelates the gradients, reduces the variance, and stabilizes the training process.\nNote that we update the posterior distribution of model parameters for treatment model, covariate model, and outcome model sequentially. For each generative model, we first update the variational parameters to maximize the ELBO in (13) and then sample model parameters from (14). Given the sampled model parameters, the regular forward pass through the network (e.g., each layer contains matrix multiplication followed by non-linear activation) is computed to get the mean and variance parameters in (5-8).\nEach iteration only requires a random mini-batch of observed samples. During each iteration in the training stage, we first take a derivative of equation (10) w.r.t the latent variable Z and employ a stochastic gradient descent (SGD) to update the latent variable Z for each individual given the current model parameters. Then, we take a derivative of each ELBO term in (13) w.r.t the variational parameters (\u03c6\u03c7, \u03c6\u03b3, or \u03c6\u03bd) in the three generative models sequentially and employ a stochastic gradient ascent to update the variational parameters given the current latent variables to maximize the ELBO. During test stage, we only need to infer the posterior distribution of latent variable Z given the test data. To achieve this, we first sampled model parameters (\u03b8\u03c7, \u03b8y, and Oy) from the variational"}, {"title": "2.4 Choice of latent dimension", "content": "The latent space is partitioned into four independent parts that play different roles in the three generative models for treatment, covariates, and outcome variables. The previous work CausalEGM has demonstrated the robustness of such partition with respect to variations in the dimensionality of latent features. Here, we provide an intuitive strategy based on sufficient dimension reduction (SDR) to help determine the dimensionality of latent features. SDR aims to identify a k-dimensional subspace of the p-dimensional predictors (k < p) that captures all the information about a scalar response. Here, we use sliced inverse regression (SIR) (Li, 1991) that employs the covariance structure of the conditional expectations of predictors given response. We compute eigenvalues of the estimated covariance matrix from SIR and retain components by inspecting eigenvalue decay and cumulative variance. Considering that linear methods such as SIR may underestimate kas they fail to capture nonlinear dependencies effectively. Here, we use a conservative strategy by using SIR E[V|X] to estimate dim(Z2) and using SIR E[V|Y] to estimate dim(Z1). A similar eigenvalue analysis for the covariance matrix of V is conducted to estimate the total dimension of the latent space dim(Z). The dimension of latent confounder dim(Zo) is chosen from 1 to 5 as a model hyperparameter."}, {"title": "2.5 Model Initialization", "content": "The parameters of neural networks are typically initialized by a uniform or normal distribution. However, as shown by our experiments (Table 3), with such initialization, the result may be poor in some cases. We designed an innovative strategy for model parameters initilization inspired from the encoding generative modeling (EGM) (Liu et al., 2024). An additional encoder function E, represented by a Bayesian neural network, is added to CausalBGM to directly map the covariant V to the latent variable (dotted line in Figure 1). Specifically, we desire that the distribution of Z = E(V) should match a pre-specified distribution, which is set to be a standard normal distribution (e.g., prior of Z). The distribution match is achieved by adversarial training (Goodfellow et al., 2014). By the encoding process, the high-dimensional covariates with unknown distribution will be mapped to a low-dimensional latent space with a desired distribution. Since the generative models in CausalBGM include both the mean and variance functions. We add additional The L2 regularization of all the variance terms to ensure reasonably small variance in each generative model during the initilization process."}, {"title": "2.6 Model Hyperparameters", "content": "CausalBGM contains three generative models, which are represented by three Bayesian neural networks (BNNs), respectively. The BNN for covariate V contains 5 hidden Bayesian layers and each layer has 64 hidden nodes. The output of BNN for covariate V is (p + 1)-dimensional where the first p digits denote the mean \u03bc\u2082 and the last digit denotes variance \u03c3\u03c4. The BNN for treatment X and outcome Y contains 3 hidden Bayesian layers with 64, 32, and 8 hidden nodes. The output of BNN of treatment X and outcome Y is 2 dimensional, representing the mean and variance, respectively. The leaky-ReLu function"}, {"title": "3 Results", "content": "We conducted a range of experiments to evaluate the performance of CausalBGM against various state-of-the-art methods across both continuous and binary treatment scenarios. In the continuous treatment setting, our focus was on assessing how well CausalBGM could learn the average dose-response function (ADRF) that describes the change of outcome variable in response to the treatment or exposure variable. In the binary treatment setting, we aimed to verify CausalBGM's ability to estimate both the population-level average treatment effect (ATE) and the individual-level treatment effect (ITE)."}, {"title": "3.1 Datasets", "content": "For the continuous treatment setting, we examined four public datasets used in previous studies (Hirano and Imbens, 2004; Sun et al., 2015; Colangelo and Lee, 2020), comprising three simulated datasets and one semi-synthetic dataset. Each of the simulation datasets has 20,000 as the sample size and 200 covariate features. We focus on the ADRF estimate in a bounded interval. The semi-synthetic data were derived from a sample of 71,345 twin births, where weight served as the continuous treatment variable and the risk of death is treated as the outcome variable, which is simulated from a risk model. Each individual has 50 covariates. In general, the simulation risk model suggests that a higher weight of an infant leads to a lower death rate.\nIn the binary treatment setting, we employed datasets from the 2018 Atlantic Causal Inference Conference (ACIC) competition, which were constructed from linked birth and infant death records (LBIDD) with 117 measured covariates. These semi-synthetic datasets have treatments and outcomes simulated from diverse data-generating processes. We chose nine datasets that utilized the most complex generation processes (e.g., the highest degree of generation function) with sample sizes spanning from 1,000 to 50,000 observations. Complete details on all datasets can be found in Appendix B."}, {"title": "3.2 Model Evaluation", "content": "In the continuous treatment setting, the goal is to evaluate whether the ADRF under a bounded interval is accurately estimated. To quantitatively measure the difference between the true ADRF curve and the estimated ADRF curve, two metrics, including root mean squared error (RMSE) and mean absolute percentage error (MAPE), are used for evaluation"}, {"title": "3.3 Baseline Methods", "content": "For the continuous treatment setting, we considered four well-established baseline methods: ordinary least squares (OLS), the regression prediction estimator (REG) (Schafer and Galagate, 2015; Galagate, 2016; Imai and Van Dyk, 2004), double debiased machine learning estimators (DML) (Colangelo and Lee, 2020), and CausalEGM (Liu et al., 2024). Note that different machine learning methods shall be used in the DML method. For the binary treatment setting, we compared CausalBGM against seven leading methods for estimating treatment effect, including two variants of CFR (Shalit et al., 2017), Dragonnet (Shi et al., 2019), CEVAE (Louizos et al., 2017), GANITE (Yoon et al., 2018), CausalForest"}, {"title": "3.4 Continuous Treatment Experiments", "content": "We conducted comprehensive experiments to evaluate the performance of CausalBGM against a suite of state-of-the-art baseline methods, including the previous CausalEGM framework under continuous treatment settings. The treatment variable X is defined over a bounded interval in R. We simulated three datasets from the previous works with a sample size of 20,000 and 200 covariates. We used the same latent dimensions as those tested for CausalEGM to ensure a fair comparison in all datasets. Specifically, for four distinct data-generating processes, the latent dimensions of (Zo, Z1, Z2, Z3) were set to (1,1,1,7), (2,2,2,4), (5,5,5,5), and (1,1,1,7), respectively.\nUnder these settings, CausalBGM demonstrated superior performance compared to all competing methods, including CausalEGM, REG, and double debiased machine learning estimators using lasso and neural networks, achieving consistently higher accuracy. In comparison to CausalEGM, which already showed significant gains over traditional approaches, CausalBGM further improved the accuracy of the ADRF estimate and reduced both bias and variance by a large margin. As illustrated in Figure 2, the REG continued to produce larger estimation errors and exhibited limited flexibility while the double debiased machine learning estimators displayed undesirable spikes and fluctuations in their dose-response curves. CausalBGM, by contrast, yielded smoother and more stable dose-response estimates, capturing the underlying causal structure more faithfully and with smaller variance. Specifically, all methods closely follow the ground truth with linear relationship of Sun et al. dataset, but CausalBGM exhibits the most stable and precise estimations (Fig-"}, {"title": "3.5 Binary Treatment Experiments", "content": "Most causal inference methods target binary treatment settings, which are prevalent in many real-world applications and the treatment variable only takes binary value from {0,1}. In such a setting, we evaluated CausalBGM alongside several state-of-the-art methods, including TARNET, CFRNET, CEAVE, GANITE, Dragonnet, CausalForest, and CausalEGM across datasets of varying sizes from the ACIC 2018 benchmark. The dimension of latent space is set to be (3, 6, 3, 6), which is the same as CausalEGM. Two evaluation metrics, including eATE (error in average treatment effect estimation) and EPEHE (error in"}, {"title": "3.6 Posterior Interval", "content": "Unlike most of the existing methods that only focus on point estimation, CausalBGM adopts the Bayesian inference principle, thus enabling uncertainty quantification and providing posterior interval of the causal effect estimates. More importantly, since the latent features are inferred for each subject, CausalBGM is able to offer individual treatment effect estimate with a posterior interval. To assess the utility of the posterior interval, we evaluate it based on its coverage probability or empirical coverage, which involves checking how often the true causal effect (e.g., average dose-response) lies within the predicted interval from a frequentist perspective.\nWe used the Imbens et al. dataset as a case study to evaluate the empirical coverage rate of posterior intervals estimated by CausalBGM. Specifically, 100 independent datasets were generated using different random seeds, and CausalBGM was applied to each dataset to estimate the average dose-response function \u03bc(x). For a given treatment value x, the empirical coverage rate was defined as the proportion of times a posterior interval successfully contains the true value at a specific significant level a. By varying the significant level a, we generated a calibration curve of the empirical coverage rate. Interestingly, the empirical coverage rate was more accurate at treatment values x 1.5, 2 compared to other treatment values (Figure 3A). This discrepancy across different treatment values can be"}, {"title": "3.7 Effect of Initialization", "content": "The EGM initialization strategy plays an important role in ensuring the superior performance of CausalBGM. \u03a4\u03bf evaluate the contribution of the EGM initialization strategy, we conducted a series of experiments comparing it with the traditional Xavier uniform initializer (Glorot and Bengio, 2010) across three simulation datasets and one semi-synthetic dataset under the continuous treatment setting. The results, summarized in Table 3, demonstrate that EGM initialization significantly enhances the performance of CausalBGM in terms of both RMSE and MAPE. Quantitatively, EGM initialization consistently reduced RMSE across all datasets and improved MAPE in three out of four datasets. For instance, in the Lee et al. dataset, EGM initialization achieved remarkable reductions in RMSE and MAPE by 93.4% and 80.1%, respectively. Similarly, in the Imbens et al. and Sun et al. datasets, EGM initialization substantially improved performance, with RMSE reductions of 70.5% and 78.4%, respectively. Even in the Twins dataset, where the impact"}, {"title": "3.8 Scalability", "content": "Scalability has become a critical requirement in causal inference, particularly for modern applications involving increasingly large and complex datasets. To evaluate the scalability of CausalBGM, we conducted comprehensive experiments examining its ability to handle datasets with a high number of covariates and large sample sizes. Our results demonstrate that CausalBGM is capable of processing datasets with over 50,000 covariates and more than 1 million samples with a reasonable computational resource, achieving reliable and consistent performance (See Appendix E). In contrast, many competing methods struggled or failed to handle datasets of this magnitude, highlighting the superior scalability of CausalBGM. These findings underscore the practicality of CausalBGM in addressing the computational demands of large-scale causal inference problems in real-world applications."}, {"title": "4 Discussion", "content": "In this article, we introduced CausalBGM, a powerful and scalable Bayesian generative modeling framework for causal inference, particularly excelling in observational studies with high-dimensional covariates and large-scale datasets. By combining the principles of AI, Bayesian inference, and causal inference, CausalBGM provides a flexible and robust approach to analyze the complex causal relationships among variables while ensuring statistical rigor, such as robust uncertainty quantification.\nOne of the most significant contributions of CausalBGM is its ability to estimate posterior intervals for individual treatment effects (ITEs), an area that has been largely overlooked by existing causal inference methods. While traditional approaches primarily focus on providing point estimates or posterior intervals for average treatment effects (ATEs), CausalBGM advances the field by adopting a Bayesian model and using an iterative algorithm to infer individual-level posterior distributions of latent features. This innovation allows for the construction of well-calibrated posterior intervals at the individual level, offering a new perspective of understanding causal effects that is critical for applications requiring personalized decision-making.\nThe computational efficiency of the framework is guaranteed by decoupling the infer-"}]}