{"title": "Non-Normal Diffusion Models", "authors": ["Henry Li"], "abstract": "Diffusion models generate samples by incrementally reversing a process that turns data into noise. We show that when the step size goes to zero, the reversed process is invariant to the distribution of these increments. This reveals a previously unconsidered parameter in the design of diffusion models: the distribution of the diffusion step $\\Delta x_k := x_k - x_{k+1}$. This parameter is implicitly set by default to be normally distributed in most diffusion models. By lifting this assumption, we generalize the framework for designing diffusion models and establish an expanded class of diffusion processes with greater flexibility in the choice of loss function used during training. We demonstrate the effectiveness of these models on density estimation and generative modeling tasks on standard image datasets, and show that different choices of the distribution of $\\Delta x_k$ result in qualitatively different generated samples.", "sections": [{"title": "1. Introduction", "content": "Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020b; Vahdat & Kautz, 2020; Dhariwal & Nichol, 2021) have quickly established themselves as one of the most powerful classes of generative models in an already crowded and competitive space one which also includes GANS (Goodfellow et al., 2020; Brock et al., 2018; Karras et al., 2019), VAEs (Kingma & Welling, 2013; Vahdat & Kautz, 2020; Child, 2020), flows (Dinh et al., 2014; Kingma & Dhariwal, 2018; Dinh et al., 2016), and autoregressive models (Salimans et al., 2017; Oord et al., 2016; Child et al., 2019), among others.\nA standard assumption for diffusion models is that $\\Delta x_t := x_k - x_{k+1}$ are normally distributed (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020b; Ho et al., 2022). However, there are many known cases in physical and biological systems where the random incremental behavior of particles colliding in a space does not follow the standard Gaussian distribution (Hidalgo-Soria & Barkai, 2020; Cugliandolo, 2002). These examples are also called anomalous diffusions (Gefen et al., 1983; Bouchaud & Georges, 1990). In this work, we consider such a scenario, and propose a generalized framework for modeling diffusion models with minimal assumptions on the distribution of the $\\Delta x_k$. To develop this framework, we prove a novel result on the convergence of non-time homogeneous random walks to stochastic processes in the limit of small time steps. Finally, we demonstrate that our framework allows for greater freedom in the design of the model and its training dynamics, while retaining competitive generative modeling capabilities in terms of both model likelihood and sample quality."}, {"title": "2. Background", "content": "Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020b) take the form $p_{\\theta}(x) = \\int p_{\\theta}(x_{0:T}) dx_{1:T}$ where data $x_0 := x$ are related to a set of latent variables $x_{1:T} := (x(t_1), ..., x(t_r))$ distributed as marginals of a diffusion process governed by an It\u00f4 stochastic differential equation (SDE)\n$dx = f(x, t) dt + g(t) dw$                                                          (1)\nwith respect to time points $\\{t_r\\}_{r=1}^T$. $f$ and $g$ are typically called drift and diffusion functions, and $w$ is the standard Wiener process. Samples can then be generated by modeling the reverse diffusion, which has a simple form given by (Anderson, 1982)\n$dx = [f(x, t) - g(t)^2 \\nabla_x \\log p(x, t)] dt + g(t) dw$,                               (2)\nwhere $\\bar{w}$ is a reverse-time Wiener process. Note that Eq. (2) is itself an It\u00f4 SDE of the form Eq. (1). Training the diffusion model involves approximating the true score function $\\nabla_x \\log p(x, t)$ with a neural network $s_{\\theta}(x, t)$ in Eq. (2). This can be achieved directly via score matching (Hyv\u00e4rinen & Dayan, 2005; Song & Ermon, 2019; Song et al., 2020b), or by modeling the sampling process (Sohl-Dickstein et al., 2015; Ho et al., 2020; Kingma et al., 2021), which is obtained by discretizing the reverse-time SDE into a Markov chain with joint likelihood\n$p_{\\theta}(x_{0:T}) = p(x_T) \\prod_{k=0}^{T-1} \\nu_{\\theta}(x_k | x_{k+1})$                         (3)\nor equivalently\n$p_{\\theta}(x_{0:T}) = p(x_T) \\prod_{k=0}^{T-1} p_{\\theta}(\\Delta x_k | x_{k+1})$,                (4)"}, {"title": "3. Convergence of Non-Normal Random Walks to Diffusion Processes", "content": "A fundamental challenge in diffusion modeling is forming tractable approximations to Eq. (1). Our result is inspired by Donsker's classic Invariance Principle (Billingsley, 2013), which gives the functional convergence of an unbiased random walk to a standard Brownian motion. We now consider a time-inhomogeneous, biased random walk $x_k$. Let $x(t)$ be the solution to Eq. (1). Intuitively, one might expect a similar convergence of $x_k$ to $x(t)$ if we constrain the first and second moments of its increments $\\Delta x_k := x_{k+1} - x_k$ to be\n$\\begin{aligned} \\mathbb{E}[\\Delta x_k | x_k] &= f(x_k, t_k) \\Delta t_k \\\n\\text{Var}(\\Delta x_k | x_k) &= g(t_k)^2 \\Delta t_k.                                (7)\n\\end{aligned}$\nThis type of convergence has been previously explored for normally distributed $\\Delta x_k$ in diffusion modeling (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020b), and is well known in general SDE literature (S\u00e4rkk\u00e4 & Solin, 2019; \u00d8ksendal & \u00d8ksendal, 2003; Kloeden & Platen, 1992). More generalized results also exist for time-homogeneous or equilibrium state processes (Ethier & Kurtz, 2009; Vidov & Romanovsky, 2009; Stroock, 2013). However, there does not exist to our knowledge a convergence result for the case of general $\\Delta x_k$, in our non-equilibrium case (Sohl-Dickstein et al., 2015). Here we shall provide such a result, and show that convergence occurs with surprisingly few assumptions. This inspires a generalized framework for designing diffusion probabilistic models where the distribution of $\\Delta x_k$ is left as a tunable free parameter. We leverage this framework in Section 4 to define a generalized class of diffusion probabilistic models."}, {"title": "3.1. Structured Random Walks", "content": "Let $x_k$ be a random walk. We introduce the following notion of structure, which allows us to characterize a random walk entirely in terms of the drift and diffusion functions $f$ and $g$, the time step $\\Delta t_k$, and a sequence of independent variables $z_k$.\nDefinition 1 (Structured Random Walks). We say that a random walk $x_k$ is structured (with respect to an It\u00f4 SDE) when its increments $\\Delta x_k := x_{k+1} - x_k$ support the decomposition\n$\\Delta x_k = f(x_k, t_k) \\Delta t_k + g(t_k) \\sqrt{\\Delta t_k} z_k,                               (8)\nwhere $\\mathbb{E}[z_k] = 0$, $\\text{Var}(z_k) = 1$, $\\Delta t_k := t_{k+1} - t_k$, and $f, g$ correspond to the drift and diffusion terms of the respective It\u00f4 SDE.\nThe structural property in Definition 1 is quite natural. In fact, it is how diffusion steps are usually computed, e.g., via the reparameterization trick (Kingma & Welling, 2013; Ho et al., 2020) or SDE solvers such as the Euler-Maruyama method (Song et al., 2020b). Moreover, it satisfies Eq. (7). If we additionally assume that $f(x, t)$ is linear in $x$, as is the case with the forward diffusion process in standard diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2020b; Kingma et al., 2021), we have the following closed form representations of its first and second moments at all $k \\in \\{0,...,T\\}$.\nTheorem 3.1 (Moments of Structured Random Walks). Let $x_k$ be a structured random walk and $f(x, t_k) = \\beta(t_k)x$ be linear. Then\n$\\mu(t_k) := \\mathbb{E}[x_k] = \\bar{a}_k x_0 \\text{ and } \\Sigma(t_k)^2 := \\text{Var}(x_k) = \\bar{\\gamma}_k,$                            (9)\nwhere $\\bar{a}_k = \\prod_{i=1}^{k} (1 + \\beta_i)$ and $\\bar{\\gamma}_k = \\sum_{i=1}^{k} \\prod_{j=i+1}^{k} \\frac{a_{j+1}}{a_i} g_i^2$. For notational convenience, we let $\\beta_i := \\beta(t_i) \\Delta t_k$ and $g_i := g(t_i) \\sqrt{\\Delta t_k}$.\nIn diffusion modeling, we are not just interested in computing the moments of $x_k$ we would like to sample from"}, {"title": "3.2. An Invariance Principle", "content": "Lifting the assumption of normally distributed increments $\\Delta x_k$, we show that we still ultimately obtain a Gaussian process in the limit as $\\Delta t_k \\rightarrow 0$. Much like the aforementioned Donsker's theorem, this also gives rise to an invariance in the distribution of $\\Delta x_k$. We once again leverage the notion of structured random walks to present a general theorem for the convergence of Markov chains with increments of the form Eq. (8).\nTheorem 3.2 (Structured Invariance Principle). Suppose regularity conditions hold and $\\{x_k\\}_{k=1}^{n_t}$ is a structured random walk on $\\mathbb{R}^d$. Let $\\bar{x}_T(t) = x_0 + \\sum_{i=1}^{n_t} \\Delta x_i$ be the continuous-time c\u00e0dl\u00e0g extension of $x_k$, where $n_t = \\lfloor t * T\\rfloor$. Then $\\bar{x}_T$ converges in distribution to $x(t)$, as $\\Delta t_k \\rightarrow 0$.\nTheorem 3.2 outlines the existence of a much larger class of increments $\\Delta x_k$ that converge to our desired limiting distribution $x(t)$. The convergence to $x(t)$ unlocks many of the essential properties for the tractability of diffusion models which we take for granted in Gaussian increments, such as fast sampling from the forward process and a closed form Eq. (5), without the need to assume Gaussian increments. Finally, we verify that we can recover Donsker's theorem when we let $f = 0$ and $g = 1$.\nWhere $p = q$ or $p = p_\\theta$."}, {"title": "4. Non-Normal Diffusion Models", "content": "Leveraging the framework established in Section 3, we introduce an expanded class of probabilistic diffusion models, centered around alternative distributional assumptions for $q(\\Delta x_k | x_{k+1})$ and $p_\\theta(\\Delta x_k | x_{k+1})$. While the space of viable diffusion models allowed by Theorem 3.2 effectively contains all distributions of $\\Delta x_k$ with finite mean and variance, we restrict our study to the following examples and leave further exploration to future work. Detailed derivations can be found in Appendix A.5. A summary of all models can be found in Table 1."}, {"title": "4.1. Gaussian q and po", "content": "First, we recover the default diffusion model loss term $L_k$ (from Eq. 5) by making the standard assumption that $\\Delta x_k$ are normally distributed. Since the space of Gaussian-distributed random variables is closed under affine operations, we trivially obtain the convergence of the random walk (Eq. 4) to a Gaussian process. Using the closed form mean and variance terms of a linear ODE (S\u00e4rkk\u00e4 & Solin, 2019), we obtain\n$L_k = w_k \\mathbb{E}_\\epsilon [||\\epsilon - \\epsilon_\\theta(x_k, t_k)||^2],$                                  (9)\nwhere $w_k = \\frac{g(t_k)^2}{2\\sigma(t_k)^2} \\Delta t_k$ and $\\epsilon_\\theta(x_k, t_k) = \\sigma(t_k) s_\\theta(x_k, t_k)$. Plugging Eq. 9 into the likelihood bound Eq. 5, we see that maximizing the likelihood of a standard diffusion model with Gaussian increments minimizes a quadratic error term between the score function $s_\\theta(x_k, t_k) = \\frac{1}{\\sigma(t_r)} \\epsilon_\\theta(x_k, t_k)$."}, {"title": "4.2. Laplace q and po", "content": "We now consider the case of Laplace distributed $\\Delta x_k$. Invoking Theorem 3.2, we can derive the alternative loss\n$L_k = \\mathbb{E}_\\epsilon [\\exp(-\\nu_k ||\\epsilon - \\epsilon_\\theta(x_k, t_k)||_1) - 1 + \\nu_k ||\\epsilon - \\epsilon_\\theta(x_k, t_k)||_1],$             (10)\nwhere $\\upsilon_k := \\frac{1}{\\sqrt{w_k}}$.\nWhile the term in the expectation $\\delta(\\epsilon - \\epsilon_\\theta(x_k, t_k)) := \\exp(-\\upsilon_k ||\\epsilon - \\epsilon_\\theta(x_k, t_k)||_1) - 1 + \\upsilon_k ||\\epsilon - \\epsilon_\\theta(x_k, t_k)||_1$ appears somewhat opaque, we can see that it converges"}, {"title": "4.3. Uniform q, Gaussian pe", "content": "Next, we note that q and $p_\\theta$ need not be the same family of distributions to apply our framework. To illustrate this, we let q be uniformly distributed on the interval $[\\mu_1 - \\sqrt{3\\sigma}, \\mu_2 + \\sqrt{3\\sigma}]$, and p be Gaussian distributed. This results in the familiar form\n$L_k = w_k \\mathbb{E}_\\epsilon [||\\epsilon - \\epsilon_\\theta(x_k, t_k)||^2 + C,$                          (13)\nwhere $C = (1 + \\log \\frac{\\sigma}{\\sqrt{3}}) \\approx 0.34$ may be seen as an additional distributional mismatch penalty incurred by the joint combination of the uniform and normal distributions. We note, however, that such a penalty does not always arise when $p_\\theta$ and q are not from the same family of distributions."}, {"title": "4.4. Uniform q, Laplace po", "content": "Finally, we demonstrate that the phase transition in Section 4.2 to an L1-based loss is made explicit in the case where q is uniform and $p_\\theta$ is the Laplace distribution. This configuration of distributions produces the piecewise loss\n$L_k =\\begin{cases}\n  w_k \\mathbb{E}_\\epsilon [||\\epsilon - \\epsilon_\\theta(x_k, t_k)||^2 + &\\text{if } \\epsilon_\\theta(x_k, t_k) \\in A \\\n  \\upsilon_k \\mathbb{E}_\\epsilon [||\\epsilon - \\epsilon_\\theta(x_k, t_k)||_1 &\\text{if } \\epsilon_\\theta(x_k, t_k) \\notin A'\n\\end{cases}$                                         (14)\nwhere $A = [\\mu_1 - \\sqrt{3\\sigma}\\omega_k, \\mu_1 + \\sqrt{3\\sigma}\\omega_k]$. Now, it is clear that $L_k$ acts as a linear function in two cases. First, when $t_k \\rightarrow 0$, as A becomes a vanishingly small set. And second, when $r_k := \\epsilon - \\epsilon_\\theta(x_k, t_k)$ is large. Both imply that $\\epsilon_{\\rho}(x, t) \\notin A$."}, {"title": "5. Experiments", "content": "For illustrative purposes, we evaluate the diffusion models proposed in Section 4 on the CIFAR10 (Krizhevsky et al., 2009) and down-sampled ImageNet (Van Den Oord et al., 2016) datasets. We quantify the performance of our models with the negative log-likelihood in terms of bits per dimension (BPD) and the Frechet Inception Distance (Heusel et al., 2017). Results are displayed in Table 2. We show that our model obtains competitive results in terms of both metrics.\nMore interestingly, some of the losses proposed in Section 4 result in generated samples with distinctly different visual characteristics. For example, images generated by the Laplace-based diffusion models exhibit markedly more saturated colors (Figure 1."}, {"title": "6. Conclusion and Limitations", "content": "We derived a probabilistic framework for designing more diverse diffusion models by showing an invariance to the distribution of the diffusion step $\\Delta x_k := x_k - x_{k+1}$. Freeing up the distributional assumption on $\\Delta x_k$ allows the end-user greater control over the stylistic qualities of the generative model. An open question is whether score matching under an EMD norm enjoys the same statistical guarantees as the standard score matching objective, e.g., consistency, efficiency, and asymptotic normality (Hyv\u00e4rinen, 2006; Song et al., 2020a). We hope that our theoretical framework opens the door for the further diversity and improvements in the design of diffusion models."}, {"title": "A. Derivations", "content": ""}, {"title": "A.1. KL Divergence Between Laplace Distributions", "content": "For completeness, we provide a derivation for the KL divergence between two Laplace distributions. Let p and q be density functions of distributions Laplace($\\mu_1, b_1$) and Laplace($\\mu_2, b_2$), i.e.,\n$p(x) = \\frac{1}{2b_1} \\exp(-\\frac{|x-\\mu_1|}{b_1})$                                                              (15)\n$q(x) = \\frac{1}{2b_2} \\exp(-\\frac{|x-\\mu_2|}{b_2})$                                                              (16)\nThen the KL divergence between the two distributions can be written as\n$KL(p(x)||q(x)) = \\int_{-\\infty}^{\\infty} p(x) \\log p(x)dx - \\int_{-\\infty}^{\\infty} p(x) \\log q(x)dx$                                          (17)\nWe will first approach ** as its solution will give us *. Plugging in p and q, we have\n$\\int_{-\\infty}^{\\infty} p(x) \\log q(x)dx = \\int_{-\\infty}^{\\infty} \\frac{1}{2b_1} \\exp(-\\frac{|x-\\mu_1|}{b_1}) dx + \\log(2b_2),$                                           \nwhere in the case that $\\mu_1 > \\mu_2$, the integral can be written as\n$\\int_{-\\infty}^{\\infty} \\frac{1}{2b_1b_2} \\exp(-\\frac{|x-\\mu_1|}{b_1}) dx$"}, {"title": "A.2. KL Divergence Between a Gaussian Distribution and a Bounded Uniform Distribution", "content": "Let p and q denote the density functions of the Uniform([$\\mu_1 - b_1, \\mu_1 + b_1$]) and N($\\mu_2, \\sigma_2$) distributions, respectively. Then\n$p(x) = \\frac{1}{2b_1} 1_{x\\in[\\mu_1-b_1,\\mu_1+b_1]}$                                                    (21)\n$q(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp(-\\frac{(x-\\mu_2)^2}{b_2})$                                                           (22)\nAgain writing the KL decomposition between p and q as Eq. 17, we note that the entropy term * is identical to that of Section A.4:\nTurning to the cross-entropy term **:"}, {"title": "A.3. KL Divergence Between a Laplace Distribution and a Bounded Uniform Distribution", "content": "Let p and q denote the density functions of the Uniform([$\\mu_1 - b_1, \\mu_1 + b_1$]) and Laplace($\\mu_2, b_2$) distributions, respectively. Then\n$p(x) = \\frac{1}{2b_1} 1_{x\\in[\\mu_1-b_1,\\mu_1+b_1]}$                                                     (24)\n$q(x) = \\frac{1}{2b_1} \\exp(-\\frac{|x-\\mu_1|}{b_1})$                                                      (25)"}, {"title": "A.4. KL Divergence Between Linear Sub-Gaussian Distributions", "content": "Let LSG denote a Linear Sub-Gaussian Distribution, and p and q denote the density functions of LSG($\\mu_1, s_1$) and LSG($\\mu_2, s_2$), respectively. For simplicity we assume that $s_1 = s_2$, as this is the case we consider in our diffusion models. Then\n$p(x) = max (0, \\frac{1}{s_1} (s - |x - \\mu_1|))$                                                 (27)\n$p(x) = max (0, \\frac{1}{s_2} (s - |x - \\mu_2|))$                                                  (28)\nWe once again write the KL decomposition between p and q as Eq. 17, and start with the cross-entropy term **:"}, {"title": "A.5. Deriving Lk", "content": "We use the following lemmas to obtain Eqs. (9) and (10) in Sections 4.1 and 4.2. Throughout this section, we will use\n$f_\\theta = f(x, t) - \\frac{1}{2}g(t)^2 \\nabla_x \\log p(x, t),$                                           (29)\n$f_\\theta = f(x, t) - \\frac{1}{2}g(t)^2 s_\\theta(x, t),$                                                   (30)\nwhere f and g are defined as in Eq. (1), to denote the true and learned reverse drift terms described in Eq (2).\nLemma A.1. Let $\\Delta x_k$ be normally distributed, i.e.,\n$\\begin{aligned}\n  p_\\theta(\\Delta x_k | x_k) &= N(\\Delta x_k; f_0(x_k, t_k) \\Delta t_k, g(t_k)^2 \\Delta t_k),                       (31) \\\n  q(\\Delta x_k | x_k) &= N(\\Delta x_k; f_0(x_k, t_k) \\Delta t_k, g(t_k)^2 \\Delta t_k).\n\\end{aligned}$                                (32)\nThen\n$L_k = w_k \\mathbb{E}_\\epsilon[||\\epsilon - \\epsilon_\\theta(x_k, t_k)||^2],$                                    (33)\nwhere $w_k := \\frac{g(t_k)^2}{2 \\sigma(t_k)^2} \\Delta t_k$.\nProof. Plugging in the closed form solution to the KL divergence between two Gaussian distributions into the likelihood lower bound,\n$\\begin{aligned}\n  L_k &= KL(p_\\theta(\\Delta x_k | x_k) || q(\\Delta x_k | x_k)) \\\n  &= \\mathbb{E} \\left[\\frac{||\\mu_{p_\\theta, k}(x_k) - \\mu_{q, k}(x_k)||^2}{2 \\sigma^2}\\right].\n\\end{aligned}\n$\nSince $\\mu_{q, k} = (f(x_k, t_k) - g(t_k)^2 \\nabla \\log p(x_k))\\Delta t_k$, $\\mu_{p_\\theta, k} = (f(x_k, t_k) - g(t_k)^2 \\nabla \\log p_\\theta(x_k))\\Delta t_k$, and $\\sigma_{p_\\theta, k} = \\sigma_{q, k} = g(t_k) \\sqrt{\\Delta t_k}$, we have\n$\\begin{aligned}\n  L_k &= \\frac{1}{2} \\mathbb{E} \\left[\\frac{||g(t_k)^2 (\\nabla \\log p(x_k) - \\nabla \\log p_\\theta(x_k)) \\Delta t_k||^2}{g(t_k)^2 \\Delta t_k}\\right] \\\n  &= \\frac{1}{2} \\mathbb{E} [g(t_k)^2 ||\\nabla \\log p(x_k) - \\nabla \\log p_\\theta(x_k)||^2 \\Delta t_k].\n\\end{aligned}$"}, {"title": "B.3. Regularity Conditions", "content": "To show our main result, we state the following regularity conditions. Assumptions 1 and 2 are standard for finite-step discretizations of SDEs (S\u00e4rkk\u00e4 & Solin, 2019). Assumption 3 simplifies the subsequent proof for tightness.\nAssumption 1 (f and g are Lipschitz). There exists K > 0 such that, for any x, y \u2208 $\\mathbb{R}^d$ and t, s \u2208 [0, 1]\n$\\begin{aligned}\n  ||f(x) - f(y)|| &\\leq K||x - y||, \\text{ and } |g(t) - g(s)| \\leq K|t - s|.                                  (60)\n\\end{aligned}$\nAssumption 2 (Linear growth of f and g). There exists K > 0 such that, for any x \u2208 $\\mathbb{R}^d$ and t \u2208 [0, 1]\n$\\begin{aligned}\n  ||f(x)|| &\\leq K(1 + ||x||), \\text{ and } |g(t)| \\leq K(1 + |t|).                                       (61)\n\\end{aligned}$\nAssumption 3 (Integrability of $z_k.$). There exists K\u2208 R such that\n$\\mathbb{E}[||z_k||^4]) < K.$                                                                   (62)"}, {"title": "B.4. Main Result", "content": "Our theorem below can be seen as a generalization of Donsker's Invariance Principle, and certain parts of the proof resembles that of the original theorem. Differences appear where we can no longer rely on the independence of the increments $\\Delta x_k$, which is heavily utilized in the original proof. By exploiting the structural properties of Definition 1, we can decompose $x_k$ into a set of auxiliary processes with the same limit, which we can show to converge to X with techniques borrowed from the strong convergence of SDE solvers and central limit theorems.\nTheorem 3.2 (Structured Invariance Principle). Suppose regularity conditions hold and $\\{x_k\\}_{k=1}^{n_t}$ is a structured random walk on $\\mathbb{R}^d$. Let $\\bar{x}_T(t) = x_0 + \\sum_{i=1}^{n_t} \\Delta x_i$ be the continuous-time c\u00e0dl\u00e0g extension of $x_k$, where $n_t = \\lfloor t * T\\rfloor$. Then $\\bar{x}_T$ converges in distribution to $x(t)$, as $\\Delta t_k \\rightarrow 0$.\nProof. Using Eq. 8 we may define the continuous-time extension of $x_k$ as the process\n$\\bar{x}_T(t) = x_0 + \\sum_{i=1}^{\\lfloor t*T\\rfloor} \\Delta x_i + (t * T - [t * T]) \\Delta x_{\\lfloor t * T\\rfloor},$                                           (63)\nwhich is produced by linearly interpolating between the iterates of the random walk. We write the increments\n$\\Delta \\bar{x}_i^{(T)} := x_{k+1} - x_k = f(x_k, t_k)) + g(t_k) \\sqrt{\\Delta t_k} z_k^{(T)},$                                              (64)\nwith the superscript (T) to emphasize its dependence on T. We show convergence by invoking the following theorem.\nTheorem B.1. (Theorem 13.1 from (Billingsley, 2013).) Let $\\{x_T\\}$, $x$ be processes (with associated probability measures $\\{P_T\\}$, P) such that $\\bar{x}_T$ converges to $x$ in finite dimensional distributions (f.d.d.), i.e., for any k time steps $t_1, t_2, ..., t_k$,\n$(\\bar{x}_T(t_1), \\bar{x}_T(t_2), ..., \\bar{x}_T(t_k)) \\xrightarrow{D} (x(t_1), x(t_2), ..., x(t_k)).$                                           (65)\nIf $\\{P_T\\}$ are also tight, then $\\bar{x}_T \\Rightarrow_T X$.\nTheorem B.1 relates the pointwise weak convergence (of a sequence of marginals of a process) on a finite set of points to weak convergence of the path measures. This is made possible by Prohorov's theorem, which connects tightness to relative compactness. Thus, to show convergence, we must show two conditions are satisfied: 1) convergence in f.d.d., and 2) tightness of the associated sequence of measures. These are given by the following two lemmas.\nLemma B.1. The sequence of measures $\\{Px_k\\}_{k=1}^{n_t}$ corresponding to the structured random walk $\\{x_k\\}_{k=1}^{n_t}$ is tight.\nLemma B.2. The continuous-time random walk interpolation $X_T$ converges in finite dimensional distributions (f.d.d.) to the diffusion process (i.e., solution to Eq. (1) x.\nCombining Theorem B.1 with Lemmas B.1 and B.2, we obtain our result."}, {"title": "Proof. (of Lemma B.1)", "content": "The result can be obtained via Kolmogorov's tightness criterion", "tightness": "n$\\sup_n \\mathbb{E} [||x_n (s) - x_n(t)||^p", "T": "choose k, l such that\n$s\\in \\left[\\frac{k-1}{n}, \\frac{k}{n} \\right) \\text{ and } t \\in \\left[\\frac{l-1}{n}, \\frac{l}{n} \\right).$                                     (67)\nFirst, observe that, applying Definition 1, Assumption 2, and the fact that $z_k \\in \\mathcal{L}^4 \\Rightarrow \\mathbb{E}[||z_k||^4", "x_n(s)||^4": "mathbb{E}[||\\Delta x_k||^4", "t_k}\\right||^4\\right": "n  &\\leq \\Delta t \\mathbb{E}[||f(x_k)||^4", "t}}\\right)}\\right": "n  &\\leq \\Delta t \\mathbb{E}[K(1+ ||x"}]}