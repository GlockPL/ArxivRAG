{"title": "Multilingual Controlled Generation And Gold-Standard-Agnostic Evaluation of Code-Mixed Sentences", "authors": ["Ayushman Gupta", "Akhil Bhogal", "Kripabandhu Ghosh"], "abstract": "Code-mixing, the practice of alternating between two or more languages in an utterance, is a common phenomenon in multilingual communities. Due to the colloquial nature of code-mixing, there is no singular correct way to translate an English sentence into a code-mixed sentence. For this reason, standard n-gram-based MT evaluation metrics such as the BLEU score are not appropriate for code-mixed evaluation. To demonstrate this, we propose a novel method for code-mixed text generation: Controlled Generation, which parameterizes the code-mixing degree (CMD) and enables the generation of multiple semantically equivalent code-mixed sentences from a given English sentence. We introduce a robust new evaluation metric: GAME: A Gold-Standard Agnostic Measure for Evaluation of Code-Mixed Sentences. GAME is both language-agnostic and gold-standard-agnostic, i.e. unlike other metrics, GAME does not require gold-standard code-mixed sentences for evaluation, thus eliminating the need for human annotators in the code-mixed evaluation process. When used to evaluate semantically equivalent code-mixed sentences, we find that GAME scores have a lower standard deviation than BLEU scores. Further, we create and release a dataset containing gold-standard code-mixed sentences across 4 language pairs: English-Hindi, Bengali, French, Spanish} to encourage more computational research on code-mixing.", "sections": [{"title": "Introduction", "content": "Code-mixing, or code-switching, refers to the practice of alternating between two or more languages in a single utterance (Poplack, 2001). This is commonly observed in bilingual and multilingual communities where speakers are fluent in two or more languages. Code-mixing involves a\u2018matrix' language, which influences the grammar of the sentence, and an 'embedded' language, from which words or phrases are inserted into a monolingual sentence to form a code-mixed sentence. Moreover, code-mixing is the language of social media (Chung et al., 2022). In multilingual countries such as India, code-mixing is commonplace: a significant number of Indians who are fluent in both English and Hindi tend to speak 'Hinglish' rather than English or Hindi, in informal settings. It is for this reason that the phenomenon of code-mixing has been of great interest in NLP.\nThe premise of our work (as depicted in Figure 1) is that an English sentence often has multiple semantically equivalent, equally valid code-mixed translations. Therefore, a robust code-mixed evaluation metric must assign equal and perfect scores to all these sentences. However, popular MT evaluation metrics such as the BLEU score (Papineni et al., 2002a) use n-grams to measure the similarity between a reference and a candidate sentence which renders them inappropriate for code-mixed evaluation (Srivastava and Singh, 2021).\nTo address the abovementioned gaps in literature, in this paper we propose a novel method to generate semantically equivalent code-mixed sentences from a given English sentence by parameterizing the Code-Mixing Degree (CMD). We call this method Controlled Generation (CG) (see Section 4). CG also attempts emulate real-world code-mixing by aligning its generations to code-mixing trends seen in social media data. Furthermore, as an alternative to BLEU, we introduce a novel, robust code-mixed evaluation metric, GAME: A Gold-Standard Agnostic Measure for Evaluation of Code-Mixed Sentences (see Section 5). To the best of our knowledge, GAME marks the first attempt at creating a pipeline to automatically evaluate code-mixed generations. Despite the ubiquity of code-mixing, gold-standard code-"}, {"title": "Related Work", "content": "Code-Mixed Text Generation Gupta et al. 2020 present a semi-supervised approach to generate code-mixed text using a pre-trained encoder and"}, {"title": "Dataset Creation", "content": "There is a scarcity of publicly available gold-standard parallel code-mixed datasets. The availability of high-quality, noise-free parallel code-mixed datasets is essential for tasks such as training code-mixed evaluation metrics. Several English-Hindi (Dhar et al., 2018; Parekh et al., 2020; Gautam et al., 2021), English-Bengali (Patra et al., 2018), English-French (Carpuat, 2014), and English-Spanish (Solorio and Liu, 2008; Ahn et al., 2020) datasets have been released in previous work. However, these datasets are either"}, {"title": "Controlled Generation (CG)", "content": "As depicted in Figure 1, multiple semantically equivalent code-mixed sentences may be generated from a given English sentence, whose Code-Mixing Degrees may vary according to the author's preference. With this in mind, we propose Controlled Generation: a novel method to gen-"}, {"title": "Real-World Datasets", "content": "We try to simulate a real-life dataset in Controlled Generation. For this purpose, L3Cube-HingLID dataset\u00b2, has been used for English-Hindi, Patra et al. 2018 for English-Bengali and LinCE (Aguilar et al., 2020) dataset for English-Spanish. Say, we have an English token \u201cimpossible\" and its corresponding Hindi token \u201casambhav\". Whether to use \u201cimpossible\u201d or \u201casamb-"}, {"title": "CG with English as Embedded Language", "content": "Algorithm 1 (in Appendix E) explains Controlled Generation through pseudocode.\nFigure 2 describes the working of Controlled generation accompanied by an English-Hindi generation example based on the input English sentence: The questions are of four types. The process is divided into two main steps:"}, {"title": "Step 1: Base Creation", "content": "This step is done by prompting with LLM. English sentence (Input) is first translated to the Matrix Language which in the example in the flowchart is Hindi (\u201c\u092a\u094d\u0930\u0936\u094d\u0928 \u091a\u093e\u0930 \u092a\u094d\u0930\u0915\u093e\u0930 \u0915\u0947 \u0939\u094b\u0924\u0947 \u0939\u0948\u0902\u201d). Through the same prompt, we obtain a list  W = {W_1, W_2, ..., W_n}  of the replaceable words. These English words are chosen according to their PoS tags i.e. we choose words with specific tags as in flowchart only. This choice generates grammatically correct code-mixed sentences for all the four language pairs. We also obtain the corresponding 'switch points' where these words are to be replaced in the matrix language sentence by simply asking"}, {"title": "Step 2: Simulating Real-World Dataset", "content": "To decide which words are to be replaced with their English translations based on the value of CMD, we refer to the trend of occurrence of words in real-world code-mixing. We construct a vocabulary of unique words from the dataset. Take the case of English-Hindi. Table 1 displays an excerpt from vocabulary created using English-Hindi dataset where f(en) and f(hi) are frequencies (counts) of the English and Hindi terms, respectively. The idea is that if the Hindi term for a"}, {"title": "Replacement of all 'inf' score words: a subjective choice", "content": "In Controlled Generation, we encounter some matrix language words that are so rare that they do not appear in the dataset at all, resulting in  s = inf . In such cases, if CMD is non-zero, all such words are replaced (or switched) first, even if their quantity exceeds the number of replacements allowed by input CMD. Then, if the CMD allows for further replacements, words with higher finite scores s are considered next. This choice though, being subjective is grounded in the observation that individuals who do not use or know one such rare word are likely unfamiliar with other rare terms as well. This is especially true for English-Hindi and English-Bengali. Therefore, this choice is in favour of real-world code-mixing.\nFor sentences with English as Matrix Language, replace 'X' language words in English sentence with lower 's' prioritized instead."}, {"title": "English-Hindi Specific CG", "content": "Hindi exhibit rich inflection, particularly in verbs. The verbs in Hindi convey information about gender along with other aspects and thus, simply replacing them with their English counterpart can result in low-quality (grammatically incorrect) code-mixed sentences. For instance, consider the English sentence 'He plays'. Its Hindi translation is 'Vaha khelta hai'. Here, 'khelta' is the verb and thus, if language-agnostic CG is used, we get 'Vaha plays hai', which is a grammatically incorrect code-mixed sentence. The correct code-mixed sentence is 'Vaha play karta hai'. In this sentence, the word 'karta' is added after the root of the English verb 'play' to form a conjunct verb, i.e. \u2018play karta', based on the suffix 'ta' in the word 'khelta'.\nThus, we introduce a modified prompt and verb-specific rules which allow us to generate grammatically correct code-mixed sentences. The detailed algorithm has been discussed in the Appendix A.2.\nIn the following example, \u0915\u0930\u0928\u0947 and \u0915\u0930\u0947\u0902 are the added words:"}, {"title": "Critical Analysis of CG", "content": "We have evaluated CG using the BLEU score in section A.3 for the sake of some comparison with other works. Although we have computed BLEU"}, {"title": "GAME", "content": "As discussed previously (Figure 1) in the Introduction, the evaluation of code-mixed translations remains a challenge because of two key reasons:\n1) Gold-standard code-mixed data is scarce. This follows from the fact that the creation of a corpus of gold-standard code-mixed data, especially for low-resource languages, is a laborious task and demands significant human annotation efforts.\n2) For code-mixed evaluation, commonly-used Machine Translation (MT) evaluation metrics such as the BLEU score (Papineni et al., 2002b) require gold-standard code-mixed data, which is scarce, and are ineffective (Srivastava and Singh, 2021). The reason for their inefficacy is that an English sentence often has many equally correct, semantically equivalent code-mixed translations. These sentences typically differ in their"}, {"title": "Assessment of GAME's Robustness", "content": "To indicate to the reader the validity of results, it is necessary to provide a detailed discussion of GAME's robustness. The assessment of GAME's robustness is done in the following subsections.\nWe perform evaluation with respect to BLEU\nand note the areas where BLEU provides an inaccurate and ineffective evaluation.\nThe reasons are thoroughly described in the respective subsections."}, {"title": "Evaluating Semantically Equivalent Code-Mixed Sentences", "content": "As discussed previously (1, 5), a given English sentence often has multiple unique but semantically equivalent code-mixed translations. A robust code-mixed evaluation metric must, therefore, assign the same score to all these sentences.\nIdeally, all the twelve code-mixed sentences should get equal or similar BLEU scores. However, we find that BLEU scores vary significantly (47.85-82.08), while GAME scores are contained in a smaller, more accurate range (91.25-97.39). The BLEU scores have a standard deviation of 11.49, while only 2.64 for GAME.\nWe perform this test on a larger dataset, for which we choose 100 English sentences from the HinGE dataset (Srivastava and Singh, 2021), where each English sentence has 2-8 gold-standard Hinglish sentences corresponding to it. Similarly, we generate 57 English-Bengali and 62"}, {"title": "Extreme Case Evaluation", "content": "An effective code-mixed evaluation metric must assign high scores to quality translations and low scores to poor translations. In order to gauge GAME's accuracy in this area, we perform two tests on our own dataset:\n(i) Extreme Case 1: We use GAME to evaluate our gold-standard code-mixed sentences. As the sentences are gold-standard and human-generated, the human score should be maximum.\n(ii) Extreme Case 2: We use GAME to evaluate our gold-standard code-mixed sentences against an unrelated English reference sentence from the same dataset. Since the reference sentence and the candidate sentence are unrelated, the human score should be 0."}, {"title": "Conclusion", "content": "We release a dataset containing gold-standard code-mixed sentences spanning 4 language pairs: English-{Hindi, Bengali, French, Spanish}. We propose Controlled Generation: a novel method for code-mixed text generation that allows for control over the Code-Mixing Degree of the genera-"}, {"title": "Limitations", "content": "GAME can only handle homonyms that are different parts of speech. For instance, the word 'bat' may be translated to mean the flying mammal or a cricket bat. This could lead to inaccuracies in translation. Secondly, in some cases, there are slight inaccuracies in LID, transliteration, and translation. Using better-performing tools for these operations may help mitigate such issues. Due to budget constraints, we do not try using other LLMs such as GPT-4 (Brown et al., 2020) instead of Gemini Pro in GAME. Using better-performing LLMs or tools for the translation tasks may significantly boost GAME's performance.\nHindi, as discussed in section exhibit inflection in verbs. Bengali is also a highly inflectional language and thus, presents comparable challenges for the generation of English-Bengali as well. Although a similar approach can be employed for English-Bengali, we plan to explore it further in the future."}, {"title": "Ethics Statement", "content": "The human annotators are volunteers paid commensurate to their efforts."}, {"title": "Other Essential Supplementary for Controlled Generation", "content": ""}, {"title": "Prompts for Base Creation", "content": ""}, {"title": "Prompt A", "content": "For the given English sentence, do the following:\n1. POS Tagging of the sentence\n2. For the words which are either Noun (NN), Adjective (JJ), Adverb (RB), CC, or Interjection (UH), create a dictionary Imp_Eng\n3. Translate the original English sentence into MATRIX\n4. From Imp_Eng, look for the corresponding meaning in MATRIX and look them up in the MATRIX sentence. Create a dictionary MATRIX_eng_dict\n5. Transliterate each MATRIX word in MATRIX_eng_dict in Roman in three ways or spellings and add that in the dictionary.\n6. Format above as RFC8259 compliant json dictionary, in the format [\"eng\": <eng_word>, \"pos_tag\": <PoS Tag>, \"MATRIX\": <MATRIX_word>, \"roman_MATRIX\": <transliterations>]"}, {"title": "Prompt B", "content": "For the given English sentence, do the following: create this RFC8259 compliant json dictionary in the format {\"hindi_trans\": <hindi trans-lation>, \"Word_Dict\":[{\"eng\":<eng word>, \"base_eng\":<base form of the english word>, \"eng_pos_tag\":<English PoS Tag>, \"hindi\":<hindi word>, \"roman_hindi\": <three different spellings of roman transliteration for hindi word>}]\nby doing PoS tagging of english sentence and then only choosing the words which are either Noun (NN), Adjective (JJ), Adverb (RB), CC, or Interjection (UH).\nAnd then translating the english sentence into Hindi and then looking for the corresponding meaning of these english words in that. Also, for each hindi word, transliterate it into three different spellings that can be seen in twitter.\nThe output should be RFC8259 compliant json dictionary without any additional words or description"}, {"title": "English-Hindi specific Controlled Generation", "content": ""}, {"title": "Base Prompt for English-Hindi Specific CG", "content": "For this, GPT-4 has been used. This prompt is a modification of Prompt B."}, {"title": "Prompt for English-Hindi specific CG", "content": "For the given English sentence, do the following:\ncreate this RFC8259 compliant json dictionary in the format {\"hindi_trans\": <hindi trans-lation>, \"Word_Dict\":[{\"eng\":<eng word>, \"base_eng\":<base form of the english word>, \"eng_pos_tag\":<English PoS Tag>, \"hindi\":<hindi word>, \"base_hin\":<base form of the hindi word>, \"hin_verb_type\":<ACTIVE or PASSIVE or NA>, \"roman_hindi\": <three different spellings of roman transliteration for hindi word>}]\nby doing PoS tagging of english sentence and then only choosing the words which are either Verb, Noun (NN), Adjective (JJ), Adverb (RB), CC, or Interjection (UH).\nAnd then translating the english sentence into Hindi and then looking ofr the corresponding meaning of these english words in that.\nAlso, for the english words that are verbs, check in the hindi sentence, if the respective hindi verb is active or passive, or if it isn't verb then 'NA'\nThe output should be RFC8259 compliant json dictionary without any additional words or description"}, {"title": "Rules for handling inflections in English-Hindi", "content": "In Hindi, only verbs need to be handled as such. The following describe the working for this inflection part:\nCleaning:\nIn this type of prompt, we get un-necessary words like 'was', as well as words with PoS tags that were not asked in the prompt. So, these are removed. Filtering PoS tags is simple, but as for the un-necessary words, the list is:\n[\"This\", \"this\u201d, \u201cis\u201d, \u201ca\u201d, \u201cam\u201d, \u201con\u201d, \u201cIn\u201d, \u201cin\u201d, \"are\", \"be\", \"the\", \"was\", \"were\", \"been\", \"have\", \"has\", \"had\"]\nAlso, while not wrong as per rules, but there are some words that are kept in Hinglish as it is and not replaced with English counterparts. We remove them as well, though this is optional. The list for such words is:\n['say', 'said', 'go', 'went', 'gone', 'come', 'came', 'tell', 'told']\nIdentifying the suffix in Verb:\nThe Base Prompt has been run using GPT-4. 'Base Hindi', i.e. base form of verbs results in"}, {"title": "Word to be added after the English counterpart (Added_Word) :", "content": "1. if suffix is '\u0928\u093e'\n\u2022 Such words will not be treated as a verb generally, and thus can be simply replaced with the English counterpart, except for the following subcase.\n\u2022 Subcase: If the sentence ends with this word, i.e. there is a connector \u2018\u0914\u0930' (and) or 'I' at the end, then Added_Word is '\u0915\u0930\u0928\u093e'. This is the word that will be added after the English counterpart.\n2. if suffix is any of these - [\u201c\u0928\u0947\u201d, \u201c\u0928\u0940\u201d, \u201c\u0924\u093e\u201d, \u201c\u0924\u0940\u201d, \u201c\u0924\u0947\u201d, \"", "Subcase": "if the verb is passive, then Added_Word='\u0939\u094b'+ suffix (Do not add suffix for the case \"\")\nE.g. if actual word is \u092c\u0926\u0932\u0928\u0947 (badalne), English counterpart is \u2018transform', then the replacement will be \u2018transform \u0939\u094b\u0928\u0947' (transform hone), where \u2018\u0939\u094b\u0928\u0947' is the Added_Word.\n\u2022 Subcase:if the verb is active, then Added_Word = '\u0915\u0930' + suffix\n3. if suffix is \u201d i.e. there is no suffix\n\u2022 then Added_Word is '\u0915\u0930', except for the following subcase.\n\u2022 Subcase: If there is already such added word in the Hindi sentence itself, i.e. if the next word is either from the list [\u2018\u0915\u0930', '\u0915\u0930\u0947\u0902', '\u0915\u0930\u0924\u093e', '\u0915\u0930\u0924\u0940', '\u0915\u0930\u0924\u0947', '\u0915\u0930\u094b', '\u0939\u0941\u0906', '\u0939\u0941\u090f', '\u0939\u0941\u0908' ], then, Added_Word is kept blank ('').\n4. if suffix is any of these - [\u2018\u0907', '\u0908', \u2018\u092f\u093e']\n\u2022 Subcase: if next word is either of ['\u0939\u0941\u0906', '\u0939\u0941\u090f']:, Added_Word is kept blank ('')\n\u2022 Subcase: if Hindi Verb is passive: Added_Word is '\u0939\u0941\u0906' for suffix ' and '\u092f\u093e', is \u2018\u0939\u0941\u090f' for suffix', with the following exception:\nSub-SubCase: if next word is either of [\u2018\u0917\u092f\u093e', '\u0917\u0908', '\u0917\u090f'], then, Added_Word='\u0915\u093f\u092f\u2019+suffix (\u2018\u0915\u093f\u092f\u093e' if suffix is '\u092f\u093e')\n\u2022 Subcase: if none of above is the case, then Added_Word= \u2018\u0915\u093f\u092f\u2019+suffix ('\u0915\u093f\u092f\u093e' if suffix is '\u092f\u093e')\n5. if suffix is any of these - [`\u090f\u0902', `\u0908' ]:\n\u2022 Added_Word is '\u0915\u0930\u0947\u0902'\n6. if suffix is any of these - [`\u0908', '\u0908'] :\n\u2022 Subcase: if next word is either of these ['\u0939\u0941\u0908', '\u0915\u0940'], then, Added_Word is kept blank ('').\n\u2022 Subcase: if Hindi Verb is Passive, then Added_Word is '\u0939\u0941\u0908'\n\u2022 Subcase: If it is none of the above, then Added_Word is '\u0915\u0940'"}, {"title": "Quantitative Analysis of CG", "content": "A total of 8081 unique English-Hindi sentences were generated using Controlled Generation for 1840 English sentences randomly taken from HinGE dataset (Srivastava and Singh, 2021). Step 1 (4.2.1) was done using Prompt B (Section A.1). Despite not having the best performance, Gemini-Pro was used due to budget limitations. The generations as well as the reference sentences were in Roman script. While there were multiple code-mixed translations by Controlled Generation per English sentence, for calculating Corpus BLEU, one translation per English sentence was needed. So, for each set of multiple references and multiple generations, a pair was selected so as to get the maximum BLEU score."}, {"title": "Additional Information for Qualitative Analysis of CG", "content": "For a qualitative analysis of CG, we analyze the code-mixed sentences with varying CMD values for a set of 65 English sentences generated using Prompt A (Section A.1) with GPT-4 (Brown et al., 2020), the combination that gives the best outputs as per our observations."}, {"title": "Controlled Generation with English as Matrix Language", "content": "Table 5: Code-Mixed English-Hindi sentences generated using \"Controlled Generation with English as Matrix Language\u201d.\nEnglish Sentence: \"The questions are of four types.\"\nFor this, Step 1 remains the same. In Step 2, the algorithm remains same up to the step where the scores (ratio of the count of the English word to that of the Hindi word) for each replaceable word are calculated. Then, instead of replacing non-English (Hindi) chosen words with their English terms, English words in the English sentence are replaced with corresponding Hindi terms with the low scores 's' prioritized. This is because a low score implies low frequency of English word in the Real world dataset and high frequency for the non-English (Hindi) corresponding word and this means that the non-English (Hindi) term for the word is more commonly used than the English term."}, {"title": "Other Essential Supplementary for GAME", "content": ""}, {"title": "Evaluation Using GAME, along with Reconstructed English Sentence", "content": "Table 6 gives examples of Evaluation of English-X gold-standard sentences using GAME."}, {"title": "Test Dataset for Evaluation of GAME", "content": "For some words in certain sentences, Gemini Pro returns an empty response, due to which we omit"}, {"title": "Additional Explorations for Controlled Generation", "content": ""}, {"title": "Using Masked Language Modeling for calculating scores", "content": "We have used twitter code-mixed English-Hindi data for calculating counts of words and thus, the scores in controlled generation. According to us, we can improve the generations further if we consider context, and the position of word into account as well. According to us, it is very rare to find an uncommon (low count) Hindi word as well as an uncommon English word in same code-mixed sentence. Furthermore, for a sentence, in which there is a noun and its adjective, we think that if the adjective is in English, then the next priority should be given to the noun. For example, let's consider the English sentence \"The questions are of four types\" for which the Hindi translation is \u201cPrashn char prakaar ke hein\u201d. Here, char (four) is adjective for the noun prakaar (types). According to us, if four has been used in the code-mixed sentence, then, the next priority should be given to its noun, i.e. types should be used. We think that this makes the code-mixed sentences more natural. There can be exceptions though, but we think that"}, {"title": "Controlled Generation using 1-Shot Prompting", "content": "We also tried parameterized generation solely using prompting as well. We tried this for Hindi-English. The exact prompt has been shown here."}, {"title": "Dataset Creation", "content": ""}, {"title": "Annotation", "content": "There were two annotators for the English-Hindi, English-Bengali, and English-French splits, and three for the English-Spanish split. We explained the phenomenon of code-mixing clearly to all the"}, {"title": "Details of Datasets", "content": "For English-Bengali, 500 sentence pairs are the ones having Gupta et al. 2020 as English source and 41 are the ones that have been created by correcting and translating twitter dataset(Patra et al., 2018) to English.\nFor English-Hindi, 120 sentences are the ones having Gupta et al. 2020 as English source and 250 are the ones that have been created by correcting the twitter dataset(Dhar et al., 2018)\nFor English-Spanish, 294 sentences are the ones having Gupta et al. 2020 as English source and 53 are the ones that have been created by correcting and translating twitter dataset(Aguilar et al., 2020) to English.\nfor English-French, all 248 sentences are the ones having Gupta et al. 2020 as English source.\nAlso, Out of these, 145 English sentence pairs are common between English-Bengali and English-Spanish pair, making it parallel dataset across language pairs."}, {"title": "Examples of Dataset", "content": "Table 7 shows the examples of English sentences and their corresponding gold standard code-mixed sentences."}, {"title": "Controlled Generation", "content": ""}, {"title": "Models and Parameters", "content": "Gemini-Pro and GPT-4 have been used. The temperature was set to 0 for both cases with other parameters at default."}, {"title": "Computation", "content": "Not much computation is involved. Except for OpenAI API's use, it takes negligible time. Everything included, for processing and generating different Code-Mixed sentences for an English sentence, it may take upto 50 seconds depending on the API time."}, {"title": "GAME", "content": ""}, {"title": "Models and Parameters", "content": "We use WordNet for identifying English words (Miller, 1995) in HinGE dataset evaluation. We use the Universal Sentence Encoder to compute semantic similarity.\nSpacy (\u201cen_core_web_sm\") has been used to POS tag the sentence. Google Transliterate has been used for transliteration task. Google Translate (API) has been used for the first temporary translation which is used as an approximate way to identify the English words in the Code-Mixed sentence. We have used Gemini Pro, for tasks like word language identification, word translation and word translation with PoS tag given. Except for the case where the word translation is done along with providing the information of its PoS tag, the choice is subjective and doesn't require LLM. In English-Bengali, GPT-3.5-turbo has been used for the LID task. The temperature was set to 0. Also, the final English sentence which has been translated from the final transliterated (in matrix language) sentence is translated using Gemini Pro, but this is also a subjective choice and any other translation method can be used.\nNLTK & library has been used for BLEU. For our purpose, Sentence BLEU has been used, with Smoothing Function\""}, {"title": "Computation", "content": "The algorithm doesn't require large computation resources. Though, since some APIs have been"}, {"title": "Other Information", "content": "For English-Bengali, we find that Gemini Pro makes frequent errors in LID, and considers most Bengali words to be English words. Therefore, for this language pair, we use GPT-3.5-turbo for the LID task, and omit no sentences."}, {"title": "Algorithm for Controlled Generation", "content": "Algorithm 1 demonstrates the working of Controlled Generation algorithmically.\nThis pseudo-code also includes the algorithm for the steps describes inside the prompt which were previously described directly in the flowchart."}, {"title": "Algorithm for GAME", "content": "Algorithm 2 shows the working of GAME algorithmically."}, {"title": "Algorithm 1 Algorithm for Controlled Generation", "content": "1: Input: English Sentence, Code-Mixing Degree (CMD) Parameter, Hinglish Dictionary ('Word':counts)\n2: Output: Hinglish Sentence\n3: Prompting with GPT-4:\n4: translatedSentence \u2190 translate(sentence, src = \"en\", dest = \"hi\")\n5: impWords \u2190 {}\n6: for all word in Eng Sentence do\n7:\tpos \u2190 getPartsof SpeechTag(word)\n8:\ttranslatedWord\u2190 GetCorrespondingWord (word, TranslatedSentence) \u25b7 Prompted to get the respective Hindi word from the\n9:\t\tif word is \"NN\" or \"JJ\" or \"RB\" or \"CC\" or \"UH\" then\n10:\t\ttranslatedSentence\n11:\t\tfrom Twitter data transliteration1 \u2190 transliterate(translatedword, dest = \"roman\") \u25b7 Because of romanized words in Dictionary as dictionary is\n12:\t\ttransliteration2 \u2190 transliterate(translatedword, dest = \"roman\")\n13:\t\ttransliteration3 \u2190 transliterate (translatedword, dest = \"roman\")\n14:\t\timpWords word, pos, translatedWord, transliteration1, transliteration2, transliteration3\n15:\t end if\n16: end for\n\u25b7 Further prompts were used to extract desired data from prompt output\n17: Word Scoring:\n18: engCounts\u2190 {}\n19: hinCounts \u2190 {}\n20: for all item in impWords do\n21:\teng [Count] \u2190 getCounts (word, hinglish Dictionary)\n22:\tfor all transliteration in item do\n23:\t\thini [Count] \u2190 getCounts (transliterationi, hinglish Dictionary)\n\u25b7 Get the counts from Hinglish Dictionary for the english word\n24:\t end for\n25:\thin[totalCount] \u2190 \u22113i=1 hini [Count] \n26:\tCalculate score for entry:\n27:\tif hin [totalCount] == 0 then\n28:\t\tscore = \u221e  else\n29:\t\tscore = eng_counts[entry] / Shin_counts.values()\n\u25b7 We add the counts for the three possible romanized variations of the hindi word\n30:\t end if\n31: end for\n32: sorted_words \u2190 getsorted(Imp_words.items(), key=lambda x: x[1], reverse=True) \u25b7 Sort entries in Imp_words by score in descending order:\n\u25b7 \u221e is considered the highest value and so, will come first\n33: Words Replacement:\n34: Replacement in Hindi Sentence (translatedSentence)\n35: words_replaced \u2190 0 \u25b7 Intitialized\n36: Desired_words_replacement = int(CMD * len(Imp_words)) \u25b7 int gives integer\n37: function REPLACE WORD (sentence, dest_word, replacement_word)\n38:\tReplace dest_word in sentence with replacement_word\n39: end function\n40: for i \u2190 0 to len(sorted_words) do\n41:\tremaining_replacements = max(0, Desired_words_replacement \u2212 words_replaced)\n42:\tif scorei = \u221e then\n43:\t\tcode_mixed \u2190 REPLACEWORD(code_mixed, translatedword, word)\n44:\t\twords_replaced \u2190 words_replaced + 1\n45:\t end if\n46:\tif remaining_replacements = 0 then\n47:\t\tbreak\n48:\t else\n49:\t\twhile remaining_replacements > 0 do\n50:\t\t\tcode_mixed \u2190 REPLACEWORD (code_mixed, translatedword, word)\n51:\t\t\twords_replaced \u2190 words_replaced + 1\n52:\t\tend while\n53:\t end if\n54: end for\n17"}, {"title": "Algorithm 2 GAME", "content": "1: Input: Reference English sentence", "code\n2": "Output: Quality score\n3: procedure EVALUATE(reference", "en": "xy", "n4": "t reference", "candidate)\n5": "t transliterationtemp\u2190 transliterate (candidate", "xy": "n6:\t translationtemp\u2190 translate(candidate"}, {"en": "dest = 'xy')\n7:\t pos \u2190 getParts Of SpeechTags (candidate)\n8:\t words \u2190 tokenize (candidate)\n9:\tctr \u2190 0\n10:\tprocedure TRANSLATEENGLISH WORDS(candidate", "ctr)\n11": "t\tfor word in tokens do\n12:\t\t\tif word not in common then\n13:\t\t\tif lid(word) then \u25b7 If the word is English\n14:\t\t\t\tctr \u2190 ctr + 1\n15:\t\t\t\tif word in pos then\n16:\t\t\t\t\ttranslatedWord\u2190 translatepos (word", "English": "X", "pos)\n17": "t\t\t\telse\n18:\t\t\t\t\ttranslatedWord\u2190 translate(word"}, {"English": "X", "n19": "t\t\t\tend if\n20:\t\t\t else\n21:\t\t\t\ttranslatedWord\u2190 word\n2"}]}