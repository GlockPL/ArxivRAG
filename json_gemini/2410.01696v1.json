{"title": "CREDES: CAUSAL REASONING ENHANCEMENT AND DUAL-END SEARCHING FOR SOLVING LONG-RANGE REASONING PROBLEMS USING LLMS", "authors": ["Kangsheng Wang", "Xiao Zhang", "Hao Liu", "Songde Han", "Huimin Ma", "Tianyu Hu"], "abstract": "Large language models (LLMs) have demonstrated limitations in handling combinatorial optimization problems involving long-range reasoning, partially due to causal hallucinations and huge search space. As for causal hallucinations, i.e., the inconsistency between reasoning and corresponding state transition, this paper introduces the Causal Relationship Enhancement (CRE) mechanism combining cause-effect interventions and the Individual Treatment Effect (ITE) to guarantee the solid causal rightness between each step of reasoning and state transition. As for the long causal range and huge search space limiting the performances of existing models featuring single-direction search, a Dual-End Searching (DES) approach is proposed to seek solutions by simultaneously starting from both the initial and goal states on the causal probability tree. By integrating CRE and DES (CreDes), our model has realized simultaneous multi-step reasoning, circumventing the inefficiencies from cascading multiple one-step reasoning like the Chain-of-Thought (CoT). Experiments demonstrate that CreDes significantly outperforms existing State-Of-The-Art (SOTA) solutions in long-range reasoning tasks in terms of both accuracy and time efficiency.", "sections": [{"title": "1 INTRODUCTION", "content": "Reasoning aims to realize the causal transfer from the initial state to the goal state through several intermediate steps, which widely exists in the domains of Societal Simulation(Gandhi et al., 2024; Xu et al., 2024; Hua et al., 2023), Economic Simulation(Li et al., 2023a; Zhao et al., 2023; Xia et al., 2024), Game Theory(Xu et al., 2023b; Mao et al., 2023; Zhang et al., 2024) and Gaming(Mukobi et al., 2023; Huang et al., 2024; Shao et al., 2024), etc. LLMs like GPT-3 have shown competitive performances in many reasoning tasks(Brown et al., 2020; Chowdhery et al., 2023; Betker et al., 2023). However, their performances and efficiency are limited when dealing with complex combinatorial optimization problems that require multi-step long-range reasoning(Kaddour et al., 2023)."}, {"title": "2 RELATED WORK", "content": "Decision-Making Capabilities in LLMs: The core of intelligence partially lies in planning, which encompasses generating a sequence of actions aimed at accomplishing a predefined objective(McCarthy et al., 1963; Bylander, 1994). Classical planning methods have found extensive application in robotics and embodied environments, where they are commonly employed to guide decision-making processes externally(Camacho & Bordons, 1999; Jiang et al., 2019). Recent advancements, such as the Chain-of-Thought model(Wei et al., 2022b; Kojima et al., 2022; Chu et al., 2023), have significantly bolstered the LLMs' capability to perform detailed reasoning(Huang et al., 2022; Singh et al., 2023; Ding et al., 2023). This model breaks down intricate queries into a series of manageable steps, thereby enhancing the LLMs' decision-making ability. Subsequent initiatives like ReACT(Yao et al., 2022) have modified this approach to improve reasoning ability in decision contexts using a CoT-based framework. Additionally, Reflexion(Shinn et al., 2024) provides a corrective mechanism that enables LLMs to recognize their errors during the decision-making process, reflect on these mistakes, and make accurate decisions in subsequent attempts. Further developments have led to the creation of tree-based decision-making frameworks that tailor LLM capabilities to specific scenarios. The Tree-of-Thought(Yao et al., 2024) utilizes Breadth First Search (BFS) and Depth First Search (DFS) algorithms to facilitate decision-making in activities such as the Game of 24, Creative Writing, and Mini Crosswords. Meanwhile, Reasoning via Planning (RAP)(Hao et al., 2023) employs the Monte Carlo Tree Search technique to optimize solutions across tasks like Blocksworld(Valmeekam et al., 2024), Math Reasoning(Zhu et al., 2022). DFSDT(Qin et al., 2023) proposed an efficient version of DFS for LLMs to make decisions, but it lacks the judgment ability to evaluate different decisions. JUDEC(Ye et al., 2023) utilizes an Elo rating system to enable LLMs to develop self-assessment capabilities, thereby enabling them to generate optimal solutions for a wide range of real-world tasks, independent of any task-specific expertise. Lastly, Graph-of-Thought(Yao et al., 2023) represents the thoughts as nodes in a graph, combining thoughts non-sequentially. All of the above work shows that LLM has excellent potential for handling long time-series tasks and shows some advantages in areas such as inference tasks.\nIntegrating Causal Analysis in LLMs for Multi-step Decision-Making: Causal analysis aims to discern and elucidate the causal relationships between actions, circumstances, or decisions. This method entails investigating the origins or causes leading to an event and the potential consequences"}, {"title": "3 METHOD", "content": "The pipeline of CreDes is illustrated in Fig. 1. It comprises two main components: CRE and DES. In CRE, the inputs of LLMs for training are the initial state, goal state, and pathway (containing a series of OSRs), while for testing, the inputs are the initial and goal states only. The DES starts from the initial and goal states of the probability tree, expands them into two intermediate states, and uses the CRE-trained model to infer the pathway between them, ultimately producing the complete pathway."}, {"title": "3.1 PROBLEM DEFINITION", "content": "To further improve the capability of LLMs in solving combinatorial optimization problems that involve a finite number of discrete intermediate steps, we conducted experiments using the Blocksworld and Hanoi Tower datasets with 7B parameter models. The Blocksworld dataset includes 602 test cases categorized by the minimum number of required actions, ranging from 2 to 12 steps. For Hanoi Tower, cases are grouped based on the complexity related to the number of disks and poles, which directly influences the solution steps.\nFor each category, our model is trained on 80 samples without common instructions. In the reasoning process, the following elements are included: initial state, OSR, state transition, next state, and goal state, as shown in Fig. 2. During testing, the model was tested on new, categorically similar samples from different datasets, assessing its ability to transform the initial state to the goal state successfully."}, {"title": "3.2 CAUSAL SIGNIFICANCE AND CONSISTENCY", "content": "In causal inference, ITE measures the difference in outcomes for an individual with and without a specific treatment. A larger ITE typically indicates a stronger causal relationship between random variables. Its definition is as follows:\n$\\mathrm{ITE}_{i}=Y_{i}(W=1)-Y_{i}(W=0)$"}, {"title": "3.3 CAUSAL RELATIONSHIP ENHANCEMENT (CRE)", "content": "Firstly, all the samples are classified into two categories: Correct and Incorrect. Within the Incorrect category, three scenarios exist, i.e., a correct OSR leading to an incorrect state transition, an incorrect OSR leading to an incorrect state transition, and an incorrect OSR resulting in a correct state transition. Given this, it is evident that we need to strengthen the causal connection between the OSR and the transition, and reduce the occurrence of samples where the OSR and the transition are non-causal. In CRE, we first use the ITE to estimate the causality between OSR and state transition quantitatively, and then embed the $|E(ITE)|$ and $Var(ITE)$ into the loss function in the training process (the remaining is cross-entropy), enhancing the causality of state transitions. As is shown in Fig. 2 and the upper part of Fig. 1, we leave the reasoning path selection to be controlled by the cross-entropy loss, while the suppression of hallucinations is handled by the ITE loss. Perplexity (PPL) is a metric used to evaluate the performance of a LLM, indicating how well the model predicts the next word in a sequence, and lower values signify better predictive accuracy. The estimation of ITE is detailed as the follows:\nGiven binary variables $X$ and $Y$ indicating the correctness of OSR and next state (state transition), respectively, i.e., $X, Y \\sim B(0, 1)$, and $X = 1$ (or $Y = 1$) means correctness. First, we calculate the cause-effect interventions between $X$ and $Y$, then subsequently modify the distribution of $Y$ by intervening in $X$. From a statistical correlation perspective, if $X$ and $Y$ are correlated, $Y$ can be predicted using $X$. However, if there is no causal relationship between $X$ and $Y$, intervening in $X$ will not alter the distribution of $Y$. Hence, if $X$ and $Y$ are correlated but not causally linked, then manipulating or intervening in $X$ would not lead to any changes in the distribution of $Y$. This distinction is crucial in statistical analysis and experimental design because it addresses the potential fallacy that correlation inherently means causation.\nUnder the intervention, the proportion of positive and negative cases (hallucinations) in the model output samples remains roughly unchanged; the more significant the causal relationship between different OSRs and corresponding positive and negative cases, the lower the \u2013$|E(ITE)|$. The reason is that cross-entropy basically ensures the majority of positive cases. At the same time, lowing $Var(ITE)$ reduces the occurrence of negative cases, making the distribution of positive and negative cases more stable, a and \u03b2 are dynamic coefficients fitted with the training process. Consequently, we incorporate the ITE into the loss function, as is shown in (2) and (3), $p_{1|x}$ and $p_{0|x}$ denote the conditional probabilities of $Y$ being 1 and 0, respectively, given the state of $X$.\n$L_{CrossEntropyLoss} \\triangleq-[Ylog(p_{1|x}) + (1 \u2013 Y)log(p_{0|x})]$"}, {"content": "$L_{CRE} = L_{CrossEntropy} \u2013 \u03b1|E(ITE)| + \u03b2Var(ITE) = ln(PPL)$"}, {"title": "3.4 CAUSAL PROBABILITY TREES WITH DUAL END SEARCHING (DES)", "content": "In this section, we improve the success rate of LLMs in solving long-range reasoning problems, such as the 12-step Blocksworld scenario, by leveraging their higher success rates in simpler 2-step and 4-step tasks. The main implementation process of DES is as follows:\nStep1: We build two causal probability trees from the initial and goal states, with nodes representing reasoning states and arrows denoting causal relationships. These trees outline possible reasoning paths within a limited number of steps.\nStep2: By matching their leaves, we identify end-to-end permutation schemes to form a continuous, and feasible path (as shown in Fig. 1 and Fig. 4). The DES framework ensures optimal path"}, {"title": "4 EXPERIMENT", "content": "In this section, we validated the effectiveness of CreDes compared to baseline approaches."}, {"title": "4.1 SETUP", "content": "Blocksworld: There are n blocks initially placed randomly on a table(Valmeekam et al., 2024). The LLM's goal is to stack these blocks in a specified order. The LLM can perform four actions: pick up a block from the table, put down a block it is holding onto the table, unstack a block from another to hold it, and stack the block in its hand onto another block. The LLM can only manipulate one block at a time, and blocks with others on top are immovable.\nGSM8K: The GSM8K dataset(Cobbe et al., 2021a) includes 1,319 diverse grade school math word problems curated by human problem writers. These tasks typically begin with a description and culminate in a final question requiring multi-step mathematical calculations contextual to the problem. To effectively tackle the final question, our approach involves decomposing it into a sequential series of smaller sub-questions, allowing for a structured solution process."}, {"title": "4.5 DISCUSSION", "content": "This study introduced the CreDes framework, which combines CRE and DES to improve LLMs' ability to handle long-range reasoning tasks. CRE ensures robust causal relationships between reasoning steps, and DES can lower the complexity of long-range reasoning by using a bidirectional search approach. Our experiments, particularly in the Blocksworld and Hanoi Tower scenarios, demonstrated significant improvements in accuracy and efficiency over existing methods, implying that CreDes can effectively address the problem of causal hallucinations and huge search spaces."}, {"title": "4.6 LIMITATION", "content": "In scenarios with strict order of precedence, such as the Hanoi Tower, the accuracy is significantly lower compared to tasks like Blocksworld. The DES approach, while effective for moderate-length tasks, struggles with very long reasoning steps, leading to a decline in performance. Additionally, maintaining causal logic through CRE and DES introduces computational overhead, which may limit the framework's scalability and applicability in real-world scenarios with limited resources."}]}