{"title": "What Is a Counterfactual Cause in Action Theories?", "authors": ["Daxin Liu", "Vaishak Belle"], "abstract": "Since the proposal by Halpern and Pearl, reasoning about actual causality has gained increasing attention in artificial intelligence, ranging from domains such as model-checking and verification to reasoning about actions and knowledge. More recently, Batusov and Soutchanski proposed a notion of actual achievement cause in the situation calculus, amongst others, they can determine the cause of quantified effects in a given action history. While intuitively appealing, this notion of cause is not defined in a counterfactual perspective. In this paper, we propose a notion of cause based on counterfactual analysis. In the context of action history, we show that our notion of cause generalizes naturally to a notion of achievement cause. We analyze the relationship between our notion of the achievement cause and the achievement cause by Batusov and Soutchanski. Finally, we relate our account of cause to Halpern and Pearl's account of actual causality. Particularly, we note some nuances in applying a counterfactual viewpoint to disjunctive goals, a common thorn to definitions of actual causes.", "sections": [{"title": "1 Introduction", "content": "The topic of causality [36] has been widely argued to play a central role in artificial intelligence mainly because it determines and captures how the agent understands the world it operates in. Additionally, the topic of causation has been discussed in sub-communities somewhat separately. In the knowledge representation literature, the usual approach has been to study actions and effects and express causal laws that capture how the preconditions and the effects of actions can be succinctly represented [37]. Philosophers and machine learning people, by extension, have argued for the need for type causality, also referred to as general causality, where we might be interested in knowing things like whether smoking causes cancer or asthma. But philosophers have also discussed the need for actual causality [16], sometimes also called token causality, which\n* This is an extended report of our extended abstract [30] accepted at AAMAS 2025."}, {"title": "2 A Modal Logic of Action and Change", "content": "We start with a modal variant of the situation calculus, the logic ES [27]. We choose this logic as our language because it simplifies the classical situation calculus by avoiding explicitly mentioning situations in the language while maintaining many merits of the situation calculus such as basic action theory to express the dynamics of a domain and regression and progression to reason about actions. The logic features a fixed countable domain called standard names N which amounts to having an infinite domain closure axiom together with the unique name assumption.\nSyntax There are terms of sort object and action. Variables of sort object are denoted by symbols x, y,..., and of sort action by a. For standard names, we"}, {"title": "3 Counterfactual Achievement Cause", "content": "Batusov and Soutchanski [3] provided an account of actual achievement cause in the situation calculus, overcoming many problems that previous works have on lifting the expressiveness [22] of HP causality. Later, Khan and Soutchanski [25] studied the sufficient and necessary conditions for actual achievement cause and provided an account that coincides with Batusov and Soutchanski's [3] definition but incorporates the notion of counterfactual analysis, an important aspect in actual causality [16]. In 2021, [24] reconsidered the above definition and provided an account of actual achievement cause in the epistemic situation calculus in terms of modalities, among other things, this allows one to reason about knowledge about the cause, i.e. causal knowledge. A drawback that is common in the above proposal is that causality is defined recursively and inferring the cause in a causal setting is intuitively non-trivial. The reason is that their notion of cause takes many aspects into account such as counterfactual, preemption, and direct or indirect cause. Here we show that if we drop some of these features we are still able to provide a simple account of counterfactual cause in the logic ES.\nMinimal Cause We start with the notion of minimal cause which is based on the notion of counterfactual."}, {"title": "4 Relation with Batusov and Soutchanski's Achievement Cause", "content": "Batusov and Soutchanski [3] provided an account of actual achievement cause in the situation calculus. To compare the two definitions, we retrofit their account in the logic ES."}, {"title": "5 Relation with HP Definition of Causality", "content": "Batusov and Soutchanski [3] had made a formal comparison between their account of actual achievement cause and the HP account of actual causality which can be summarized as (in the language of ES) for every (part of) cause in a causal model in the HP account, there exists a corresponding action-sequence pair that appear in the achievement casual chain of translated causal setting (corresponding to the HP casual model). However, as aforementioned, Batusov and Soutchanski's account is not based on counterfactual analysis. In what follows, we informally compared our notion of cause with the HP modified definition of actual causality [15] in terms of counterfactual analysis, especially in handling preemption or disjunctive goals.\nThe HP account of causality is based on the structural equation model. Below, we informally review the HP account and refer interested readers to [16]. A causal model M is a tuple (U,V, {fx}x\u2208v) where U and V are disjoint sets of exogenous and endogenous variables representing external or independent factors and internal factors. The value of each endogenous variable X \u2208 V is specified by a function fx that may depend on exogenous variables and on endogenous variables that are preceding X with respect to a fixed order on V. Moreover, the dependencies among variables are acyclic. A context u assigns values to all variables in U. The language of the HP account consists of formulas of the form X = x (value assignment), boolean connectives, and formulas of the form [Y \u2190 y] (read as after intervening to set variables Y to values \u0177, \u03c6 holds). Truth of formulas is given as (boolean connectives are understood in the standard way)\n(M, u) |= X = x if fx has values x when setting U according to u.\n(M, u) |= [\u2190] if (M) |= \u03c6 where M is the intervened model obtained from M by replacing fy for Y \u2208 Y with the trivial function fy = y.\n\nDepending on how contingencies are handled (Item 2), the HP account has multiple variants. The definition above is the latest version, i.e. the modified HP definition [15], where we only consider those contingencies or counterfactuals where the un-intervented variables have their original values (W \u2190 w). This is the same in spirit as our notion of achievement cause in narrative: when considering the counterfactual that a given action prefix in a narrative is absent, we would still consider the remaining possible actions in the narrative rather than other action sequences. The tuple (W, w, w') is called a witness to the fact that X = X is a cause of \u03c6 and each conjunct of X = X is called part of the cause."}, {"title": "6 Related Work", "content": "On causality in actions, Batusov and Soutchanski's account [3] is the most related work to us. The account is based on the situation calculus and can handle quantified effects. Among other things, the account incorporates actions' preconditions properly unlike its predecessors by Hopkins and Pearl [21,22] in lifting expressiveness of the structural equation models of HP definition. Khan and Soutchanski [24] extend Batusov and Soutchanski's result to an epistemic setting. Interestingly, instead of defining cause meta-theoretically as Batusov and Soutchanski [3] and our work, they propose to treat causality as a modality. Consequently, it is possible to reason about causes of knowledge and knowledge of causes or even nested of them there. However, the above works are not based on counterfactual analysis. It is in [25] that a study of the necessary and sufficient conditions for actual achievement cause is proposed based on counterfactual analysis. It also identifies a set of conditions that equally define the notion of cause as Batusov and Soutchanski's account [3]. Yet, like [3], the account takes too many aspects into account, such as preemptions, direct causes, and indirect causes, leading to a recursive and non-trivial definition (comparing to us)."}, {"title": "7 Conclusion", "content": "In this paper, we propose a notion of cause based on counterfactual analysis. In the context that a given action history leads to a goal, we show that our notion of cause generalizes naturally to a notion of achievement cause. We analyze the relationship between our notion of the achievement cause and the actual achievement cause by Batusov and Soutchanski. Finally, we compare informally our account to the account by Halpern and Pearl's. In terms of future work, it is interesting to see how our result can be extended to an epistemic setting, just like [24]. Besides, it is promising to investigate how our method can be adapted for robot programming in GOLOG and other applications that are being built on action languages and require actual causation."}], "equations": ["Poss(a) = a = pickup(x) ^ \u00acHolding(x)\nV(a = drop(x) \u2227 Holding(x))\nV(a = quench(x) \u2227 Holding(x))\nV(a = repair(x) \u2227 Holding(x)).", "[a] Holding(x) = a = pickup(x)\nVa\u2260 drop(x)^ Holding(x)", "[a] Broken(x) = a = drop(x) ^ Fragile(x)\nVa \u2260 repair(x) \u2227 Broken(x)", "[a]Fragile(x) = a = quench(x) \u2228 Fragile(x)", "{\nFragile (C), Fragile(D), \u2200x.\u00acHolding(x),\nBroken (C), \u00acBroken(D)\n}", "\u03a3 = \u03c6;", "\u03a3 = [z]\u03c6;", "z is minimal.", "BSChain(C) = {(a1, z1),..., (an, zn)}.", "MD = TRUE V L = TRUE."]}