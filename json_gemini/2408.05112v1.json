{"title": "Semantic Successive Refinement: A Generative AI-aided Semantic Communication Framework", "authors": ["Kexin Zhang", "Lixin Li", "Wensheng Lin", "Yuna Yan", "Rui Li", "Wenchi Cheng", "Zhu Han"], "abstract": "Semantic Communication (SC) is an emerging technology aiming to surpass the Shannon limit. Traditional SC strategies often minimize signal distortion between the original and reconstructed data, neglecting perceptual quality, especially in low Signal-to-Noise Ratio (SNR) environments. To address this issue, we introduce a novel Generative AI Semantic Communication (GSC) system for single-user scenarios. This system leverages deep generative models to establish a new paradigm in SC. Specifically, At the transmitter end, it employs a joint source-channel coding mechanism based on the Swin Transformer for efficient semantic feature extraction and compression. At the receiver end, an advanced Diffusion Model (DM) reconstructs high-quality images from degraded signals, enhancing perceptual details. Additionally, we present a Multi-User Generative Semantic Communication (MU-GSC) system utilizing an asynchronous processing model. This model effectively manages multiple user requests and optimally utilizes system resources for parallel processing. Simulation results on public datasets demonstrate that our generative AI semantic communication systems achieve superior transmission efficiency and enhanced communication content quality across various channel conditions. Compared to CNN-based DeepJSCC, our methods improve the Peak Signal-to-Noise Ratio (PSNR) by 17.75% in Additive White Gaussian Noise (AWGN) channels and by 20.86% in Rayleigh channels.", "sections": [{"title": "I. INTRODUCTION", "content": "WITH the rapid growth of wireless communication tech- nology, data traffic and mobile device connectivity is increasing exponentially. Semantic Communications (SC) is playing a pivotal role in this progress [1]. Unlike traditional communication methods that focus on transmitting binary bits, SC emphasizes the context of the information [2]. Recent advancements further highlight SC's potential. For instance, the semantic interference cancellation (SemantIC) technique enhances information quality by iteratively eliminating noise in both the signal and semantic domains without additional channel resource costs [3]. Similarly, the Semantic-Forward (SF) relaying framework improves network robustness and reduces forwarding payload by extracting and transmitting semantic features, even under adverse channel conditions [4]. Simultaneously, the rapid advancement of generative Arti- ficial Intelligence (AI) models and the widespread adoption of technologies such as ChatGPT, Imagen, Midjourney, and DALL-E have prompted the B5G and 6G communities to synergize with these cutting-edge generative AI technologies. This paradigm shift is particularly beneficial for the vast amount of multimedia content generated by these applications, such as images and videos. Typically, AI models run on pow- erful cloud servers due to their high computational demands. However, with the growing prevalence of mobile devices, AI companies strive to provide high-quality AI-Generated Content (AIGC) services accessible from anywhere [5], [6]. These innovations lay a solid foundation for further integrating generative Al with SC, which can significantly boost network performance. By considering the context of the generated content, SC can effectively leverage these advanced generative AI models to enhance overall system performance. For example, consider a user playing an online game on their VR/AR device at home, entering a new virtual scene rendered by a Diffusion Model (DM) in the cloud. The scene is represented by information bits communicated to the VR/AR glasses via mobile networks. A generative AI-aware semantic communication network can utilize the fact that DM generates this content and transmits the latent representation of the content while performing the stable diffusion process on the receiver's end. In this scenario, the semantic communication network focuses on conveying the meaning (latent representations) of the generative AI content rather than optimizing solely the delivery of the Os and 1s. This approach allows for quality service metrics that align more closely with human visual perception than traditional bit-wise metrics. However, directly combining semantic communication with generative AI in fixed structures is inefficient due to the inability to adjust semantic density. In this context, deploying DM in the decoder offers a promising solution to accurately recover the image context. Toward this end, we exploit the potential of the generative model and propose a novel gen- erative AI semantic communication system, which aims to incorporate the robust, stable diffusion algorithm into the semantic decoding process as an initial step towards a fully collaborative generative AI semantic communication system. The main contributions of this paper are as follows: \u2022 To significantly enhance the efficiency and reliability of semantic communication systems in the era of generative AI, we propose a single-user Generative AI Semantic Communication (GSC) system powered by AI-generated content. Specifically, the Base Station (BS) encodes im- ages using a joint source-channel coder based on the Swin"}, {"title": "II. RELATED WORKS", "content": "Transmitting image semantic information requires more communication resources than text data. Consequently, this section focuses on Image Semantic Communication (ISC). Research in this field can be divided into two main directions: semantic-oriented and task-oriented communication. The chal- lenge of semantic-oriented communication lies in extracting and recovering semantics before and after transmission. In contrast, task-oriented communication focuses on completing specific tasks rather than accurately recovering all semantic information. The relevant works for these paradigms are outlined below.\nA. Image semantic communication Deep Joint Source-Channel Coding (DeepJSCC) [7] is a pioneering study in wireless image transmission. This tech- nique simplifies the code design process by integrating source and channel coding into a single mapping and eliminating the need for constellation diagrams used in digital schemes. Building on this foundation, the studies in [8]\u2013[10] extended DeepJSCC to various channel conditions. Yang et al. [9] proposed an adaptive wireless image transmission scheme that dynamically adjusts the transmission rate according to the current channel state and image complexity. Xu et al. [10]"}, {"title": "III. PROPOSED METHOD", "content": "Considering downlink transmission scenarios, this section describes the proposed generative AI semantic communication model. Fig. 1 illustrates the general framework of the proposed approach. The architecture of multi-user generative commu- nication system MU-GSC is fundamentally similar to that of single-user generative AI semantic communication system, which comprises four main processes:the semantic feature encoder module, the physical wireless channel module, the semantic feature decoder module, and the semantic fine-tuning module. Building on the foundation of GSC, the development strategy for MU-GSC involves creating a system based on an asynchronous processing model. This system is designed to handle requests from multiple users, optimally utilizing system resources for efficient parallel processing. The details for the implementation are presented.\nA. Semantic feature encoder module The BS usually consists of two modules in semantic com- munication systems: a semantic feature encoder and a channel coder. The semantic feature encoder, also known as the source encoder, mines information and extracts features from the images based on the knowledge base. Let $I$ be the transmitted image sources and $S$ be the extracted semantic symbols. The mathematical description is as follows:\n$S = E(\u0399; \u03c6\u03b1), \u0399 \u2208 R^{n}$, (1)\nwhere $E(.)$ denotes the semantic coder network, $\u03c6a$ is the parameter set of the corresponding coding network, and $n$ is the dimension of the input images."}, {"title": "IV. SIMULATION RESULTS AND DISCUSSIONS", "content": "In this section, simulation results are presented to evaluate the performance of our proposed single-user and multi-user generative AI semantic communication systems. They are compared with deep learning-based methods and the tradi- tional communication systems realized by the separate source and channel coding technologies. In addition, to demonstrate the robustness of the proposed method, the simulation experi- ments are performed under the AWGN channels and Rayleigh fading channels, where the perfect CSI is assumed for all methods. For the MU-GSC, the transceiver is assumed with three single-antenna users and the receiver with three antennas.\nA. Simulation setup The training process is divided into two independent parts: semantic feature encoder/decoder and SFT. To comply with the generalization of ISC, the classical communication network based on the Swin Transformer is chosen as the semantic feature coder in this paper. Specifically, this network uses the ReLU activation function between the input layer and the two hidden layers, the hyperparameter C is set to 32, the loss function adopts the MSE, the batch size is set to 32, and the window size is set to 2, and then it is trained using Adam's optimizer [37] with a learning rate of 1 \u00d7 10\u22124. During the SFT training process, we adopt a two-step training strategy utilizing a four-level encoder-decoder structure in the DTBN. From level 1 to level 4, the attention heads in DMTA are set to [1, 2, 4, 8], the number of dynamic transformer blocks to [3, 5, 6, 6] and the number of channels C' of N\u2081 is set to 96. Training begins with a patch size of 32 \u00d7 32 and a batch size of 16. In the second step, \u03b2t linearly increases from 0.10 to 0.99, starting with an initial learning rate of 2 \u00d7 10-4, and the total timesteps T are set at 4. In this simulation, the experimental platform for training and testing is built on an Ubuntu 20.04 system with CUDA 11.8 support, and the deep learning framework is Pytorch 2.0.0. Note that the training phase of the diffusion model is done at the cloud server of the BS, and the receiver is only involved in the reverse inference process. Compared to the pre- training phase, semantic information generation requires lower computational resources. Therefore, the receiver is sufficient to run these modules with acceptable computational latency. We compare our proposal with classical separation-based source and semantic communication. The traditional commu- nication model considers the well-established image codec JPEG, an image compression algorithm used in various ap- plications such as Internet content delivery, digital photog- raphy, and medical imaging. Many fields include Internet content delivery, digital photography, and medical imaging. The channel noise or fading is then processed using a Low- Density Parity-Check code (LDPC) and Quadrature Amplitude Modulation (QAM) scheme, denoted as JPEG+LDPC+QAM. The modulation order is set to 4. The semantic communication"}, {"title": "V. CONCLUSION", "content": "This paper proposes a generative AI semantic communi- cation system that introduce an advanced and interpretable semantic fine-tuning module to enhance semantic information. Simulation results demonstrate that our method delivers supe- rior transmission quality compared to traditional separation- based method and DeepJSCC, significantly improving commu- nication services in resource-limited wireless networks, par- ticularly under low signal-to-noise ratio conditions. Moreover, Although our method's running time is slightly higher than that of DeepJSCC, fundamental techniques such as asynchronous processing substantially enhance the system's response speed and throughput, demonstrating the scalability of the proposed single-user system in multi-user scenarios."}]}