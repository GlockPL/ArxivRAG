{"title": "Semantic Successive Refinement: A Generative AI-aided Semantic Communication Framework", "authors": ["Kexin Zhang", "Lixin Li", "Wensheng Lin", "Yuna Yan", "Rui Li", "Wenchi Cheng", "Zhu Han"], "abstract": "Semantic Communication (SC) is an emerging tech- nology aiming to surpass the Shannon limit. Traditional SC strategies often minimize signal distortion between the original and reconstructed data, neglecting perceptual quality, especially in low Signal-to-Noise Ratio (SNR) environments. To address this issue, we introduce a novel Generative AI Semantic Com- munication (GSC) system for single-user scenarios. This system leverages deep generative models to establish a new paradigm in SC. Specifically, At the transmitter end, it employs a joint source-channel coding mechanism based on the Swin Transformer for efficient semantic feature extraction and compression. At the receiver end, an advanced Diffusion Model (DM) reconstructs high-quality images from degraded signals, enhancing perceptual details. Additionally, we present a Multi-User Generative Seman- tic Communication (MU-GSC) system utilizing an asynchronous processing model. This model effectively manages multiple user requests and optimally utilizes system resources for parallel processing. Simulation results on public datasets demonstrate that our generative AI semantic communication systems achieve superior transmission efficiency and enhanced communication content quality across various channel conditions. Compared to CNN-based DeepJSCC, our methods improve the Peak Signal- to-Noise Ratio (PSNR) by 17.75% in Additive White Gaussian Noise (AWGN) channels and by 20.86% in Rayleigh channels.", "sections": [{"title": "I. INTRODUCTION", "content": "WITH the rapid growth of wireless communication tech- nology, data traffic and mobile device connectivity is increasing exponentially. Semantic Communications (SC) is playing a pivotal role in this progress [1]. Unlike traditional communication methods that focus on transmitting binary bits, SC emphasizes the context of the information [2]. Recent advancements further highlight SC's potential. For instance, the semantic interference cancellation (SemantIC) technique enhances information quality by iteratively eliminating noise in both the signal and semantic domains without additional channel resource costs [3]. Similarly, the Semantic-Forward (SF) relaying framework improves network robustness and reduces forwarding payload by extracting and transmitting semantic features, even under adverse channel conditions [4]. Simultaneously, the rapid advancement of generative Arti- ficial Intelligence (AI) models and the widespread adoption of technologies such as ChatGPT, Imagen, Midjourney, and DALL-E have prompted the B5G and 6G communities to synergize with these cutting-edge generative AI technologies. This paradigm shift is particularly beneficial for the vast amount of multimedia content generated by these applications, such as images and videos. Typically, AI models run on pow- erful cloud servers due to their high computational demands. However, with the growing prevalence of mobile devices, AI companies strive to provide high-quality AI-Generated Content (AIGC) services accessible from anywhere [5], [6]. These innovations lay a solid foundation for further integrating generative Al with SC, which can significantly boost network performance. By considering the context of the generated content, SC can effectively leverage these advanced generative AI models to enhance overall system performance. For example, consider a user playing an online game on their VR/AR device at home, entering a new virtual scene rendered by a Diffusion Model (DM) in the cloud. The scene is represented by information bits communicated to the VR/AR glasses via mobile networks. A generative AI-aware semantic communication network can utilize the fact that DM generates this content and transmits the latent representation of the content while performing the stable diffusion process on the receiver's end. In this scenario, the semantic communication network focuses on conveying the meaning (latent representations) of the generative AI content rather than optimizing solely the delivery of the Os and 1s. This approach allows for quality service metrics that align more closely with human visual perception than traditional bit-wise metrics. However, directly combining semantic communication with generative AI in fixed structures is inefficient due to the inability to adjust semantic density. In this context, deploying DM in the decoder offers a promising solution to accurately recover the image context. Toward this end, we exploit the potential of the generative model and propose a novel gen- erative AI semantic communication system, which aims to incorporate the robust, stable diffusion algorithm into the semantic decoding process as an initial step towards a fully collaborative generative AI semantic communication system. The main contributions of this paper are as follows: \u2022 To significantly enhance the efficiency and reliability of semantic communication systems in the era of generative AI, we propose a single-user Generative AI Semantic Communication (GSC) system powered by AI-generated content. Specifically, the Base Station (BS) encodes im- ages using a joint source-channel coder based on the Swin"}, {"title": "II. RELATED WORKS", "content": "Transmitting image semantic information requires more communication resources than text data. Consequently, this section focuses on Image Semantic Communication (ISC). Research in this field can be divided into two main directions: semantic-oriented and task-oriented communication. The chal- lenge of semantic-oriented communication lies in extracting and recovering semantics before and after transmission. In contrast, task-oriented communication focuses on completing specific tasks rather than accurately recovering all semantic information. The relevant works for these paradigms are outlined below."}, {"title": "A. Image semantic communication", "content": "Deep Joint Source-Channel Coding (DeepJSCC) [7] is a pioneering study in wireless image transmission. This tech- nique simplifies the code design process by integrating source and channel coding into a single mapping and eliminating the need for constellation diagrams used in digital schemes. Building on this foundation, the studies in [8]\u2013[10] extended DeepJSCC to various channel conditions. Yang et al. [9] proposed an adaptive wireless image transmission scheme that dynamically adjusts the transmission rate according to the current channel state and image complexity. Xu et al. [10] introduced a joint source-channel coding method incorporating an attention mechanism (ADJSCC). This framework adapts to noise by dynamically adjusting the number of bits allocated to the channel and source coder to maintain transmission reliability in real-world environments. However, these ap- proaches primarily focus on the distortion of the reconstructed signal at the receiver relative to the source at the transmitter without adequately considering the perceptual quality of the reconstructed image, which may lead to significant perceptual distortion under extreme conditions such as low bandwidth and low Signal-to-Noise Ratio (SNR). To address this, Kurka et al. [11] proposed DeepJSCC-f, which employs a feedback mechanism that allows the system to acquire real-time channel noise information and mitigate its effects by feeding the received signal back to the transmitter. However, this method assumes that any complex value can be transmitted over the channel, which may hinder the applica- tion of these algorithms in scenarios where the hardware or protocol only accepts certain sets of channel inputs (e.g., dig- ital constellations). Additionally, the semantic communication systems proposed in [12]\u2013[15] are designed for receivers with powerful computational capabilities, enabling large-scale deep learning networks and single-user communication scenarios. Among them, Zhang et al. [12] developed a system that adaptively identifies and transmits task-specific key semantic features in a changing environment. Yang et al. [13] proposed the WITT framework to enhance CNN performance by intro- ducing a spatial modulation module, which adjusts the scale of potential representation based on channel state information, improving the model's adaptability to different channel con- ditions. Yu et al. [14] extended the semantic communication system to bi-directional communication for IoT devices with limited capacity, significantly reducing training overheads by eliminating the need for information feedback and model migration. Nguyen et al. [15] proposed a system that adapts to different computational capabilities by dynamically adjusting the transmission length of the output from the channel coder, combined with hybrid loss optimization, to achieve high- quality image reconstruction and avoid network congestion. Task-oriented approaches optimize resource utilization by delivering information according to specific task requirements. Kadam et al. [16] designed a keyword-based SC system for transmitting and sharing knowledge recovery data for a specific Data Allocation Problem (DAP) to enhance efficiency and accuracy. Xie et al. [17] developed a multi-user system supporting two unimodal tasks (image retrieval and machine translation) and one multimodal task (a visual quiz combining text and images). Kang et al. [18] created a framework that enables users to retrieve image-related semantic information via text queries. However, this approach fails to fully con- sider the dynamic changes in the importance of semantic information, which can lead to information loss in resource competition. In [19], researchers employed a course-learning strategy to minimize the length of transmitted messages, aiming to improve communication efficiency for specific tasks. To address the issue of limited resource blocks from BS to individual users, Wang et al. [20] utilized a reinforce- ment learning algorithm based on an attention mechanism to prioritize the transmission of the most informative triples during resource allocation. Thomas et al. [21] emphasized the reasoning capabilities required by both the transmitter and re- ceiver, employing a Generative Flow Network (GFlowNet) to achieve causal reasoning for bursty semantic communication with minimal data. Yoo et al. [22] demonstrated the feasibil- ity of ISC in real-time wireless communication using Field Programmable Gate Array (FPGA) as a hardware platform, comparing its performance with conventional 256 Quadrature Amplitude Modulation (QAM) and showing superior applica- tion potential. However, their results were only validated in a simulation environment."}, {"title": "B. Generative AI semantic communication", "content": "Generative AI revolutionizes visual computing by allowing users to programmatically create or modify realistic, high- quality images, videos, and 3D models. Neural network-driven generative models, such as Variational Autoencoders (VAEs), Generative Adversarial Networks (GANs), and Diffusion Mod- els (DMs), have shown exceptional capabilities in generating high-quality data. This highlights their significant potential for application in joint source-channel coding. Choi et al. [23] was the first to implement a Joint Source- Channel Coding (JSCC) scheme over binary channels us- ing a discrete VAE. Subsequently, Hu et al. [24] employed an adversarial training approach and introduced the Masked Variational Quantized Variational Autoencoder (MVQ-VAE) to enhance the system's robustness to various noise types. Paper [25] developed an innovative architecture for DeepJSCC that is data-driven and enhanced by adversarial training, with the combined goal of maximizing the reconstruction quality for legitimate receivers while minimizing adversarial losses. Yang et al. [26] combined an autoencoder with Orthogonal Frequency Division Multiplexing (OFDM), using a GAN- inspired loss function to efficiently train a robust decoder against the effects of multipath fading. The approach de- scribed in [27] significantly reduces bandwidth requirements by performing semantic segmentation at the transmitter's end to extract semantic information from an image and using GAN for image reconstruction at the receiver's end. However, this reconstruction process may introduce subtle differences between the generated image and the original scene. To this end, Erdemir et al. [28] proposed two schemes: InverseJSCC, which addresses the inverse problem of DeepJSCC, and Gen- erativeJSCC, an end-to-end optimization scheme based on GANs that can reconstruct perceptual quality under extremely adverse channel conditions like never before. Recent advancements in DMs have established new bench- marks in density estimation and sample quality, surpassing other generative models. Parametric Markov chains enhance the variational lower bound of the likelihood function, thereby enabling samples to represent the target distribution [29] more accurately. DMs iteratively refine these samples through a me- thodical denoising process until the desired output is achieved. Niu et al. [30] introduced a strategy based on DeepJSCC, their method initially adds independent Gaussian noise to the input image and then applies a diffusion process to introduce additional information components during decoding. In con- trast, other studies [31], [32] utilize the denoising capabilities of DMs to help the receiver mitigate noise interference in the channel or semantic vectors. Furthermore, [33] addresses the communication problem as an inverse problem and pro- poses a generative AI semantic communication framework that resolves the denoising or colouring issues in the low- dimensional latent representations of samples. Chen et al. [34] proposed CommIN, an innovative framework that combines an Invertible Neural Network (INN) with a DM to model channel characteristics and degradation phenomena introduced by DeepJSCC. Grassucci et al. [35] developed a generative AI semantic communication framework that enhances the quality of inferred images by incorporating semantic chunks for rapid denoising. However, DMs still face practical challenges, such as large network size and the iterative nature of the pro- cess, which complicates training with limited computational resources. This study addresses these issues by deploying a lightweight DM on the receiver of a semantic communication system. By estimating compact conditional vectors instead of all pixels, the proposed method leverages the excellent mapping capabilities of DMs to achieve high-quality image reconstruction."}, {"title": "III. PROPOSED METHOD", "content": "Considering downlink transmission scenarios, this section describes the proposed generative AI semantic communication model. Fig. 1 illustrates the general framework of the proposed approach. The architecture of multi-user generative commu- nication system MU-GSC is fundamentally similar to that of single-user generative AI semantic communication system, which comprises four main processes:the semantic feature encoder module, the physical wireless channel module, the semantic feature decoder module, and the semantic fine-tuning module. Building on the foundation of GSC, the development strategy for MU-GSC involves creating a system based on an asynchronous processing model. This system is designed to handle requests from multiple users, optimally utilizing system resources for efficient parallel processing. The details for the implementation are presented."}, {"title": "A. Semantic feature encoder module", "content": "The BS usually consists of two modules in semantic com- munication systems: a semantic feature encoder and a channel coder. The semantic feature encoder, also known as the source encoder, mines information and extracts features from the images based on the knowledge base. Let I be the transmitted image sources and S be the extracted semantic symbols. The mathematical description is as follows: \n$$S = E(I; \\varphi_{\\alpha}), I \\in \\mathbb{R}^{n}$$\nwhere \\(E(\\cdot)\\) denotes the semantic coder network, \\(\\varphi_{\\alpha}\\) is the parameter set of the corresponding coding network, and n is the dimension of the input images."}, {"title": "B. Physical wireless channel module", "content": "Considering the finite transmit power of the transmitting device, a power normalization operation must be used to make the signal f satisfy the average power constraint before sending the transmitted signal to the channel. This implies \n$$\\frac{E_s[|f|^2]}{1} < P$$\n Since the encoder and decoder are trained end-to-end, the physical channel can be modeled with a frozen neural network. In this paper, we consider the general fading channel model with transfer function \\(f = w(f; h) = h \\odot f+n\\), where \\(\\odot\\) is the element-wise product, h denotes the Channel State Information (CSI) vector, and each component of the noise vector n is independently sampled from a Gaussian distribution, i.e., \\(n \\sim N (0,\\sigma^2I)\\), where \\(\\sigma^2\\) is the average noise power."}, {"title": "C. Semantic feature decoder module", "content": "A joint source-channel decoder will be deployed at the re- ceiver of the local device, including two modules, the channel decoder and the semantic decoder. The signal is first binary converted by the channel decoder and then sent to the semantic decoder to reduce from a potential representation of noise to a semantic feature map that the user cannot understand. Channel distortion and noise are critical factors that cannot be avoided when transmitting coded feature vectors in a wire- less channel environment. Taking an Additive White Gaussian Noise (AWGN) channel as an example, the received signal vector can be written as: \n$$f = f + \\epsilon,$$\nwhere \\( \\epsilon \\) is a noise vector whose elements obey \\( N (0, \\sigma^2I) \\).\n$$\nm = C^{-1}(f;\\varphi_{\\beta}),$$"}, {"title": "D. Semantic fine-tuning module", "content": "Considering the significant increase in computing power of mobile devices, many user terminals can perform relatively simple fine-tuning operations. In this subsection, the Semantic Fine-Tuning (SFT) module is designed. Specifically, after the semantic features are decoded, they need to be further transferred to the DM with pre-training parameters to perform semantic enhancement. Inspired by image retrieval algorithms, adding precise details to low-quality images avoids the need for the DM to generate complete images. As a result, SFT achieves more accurate estimation with fewer iterations and ensures the stability of the results. The training process of the SFT module primarily consists of pre-training and DM training, both conducted on the cloud server. Detailed information about this process is provided in Alg. 1. The pre-training phase involves two networks, as shown in Fig. 3: the prior extraction network (N1) and the image denoising network (N2) [29]. The primary function of N\u2081 is to extract Prior Representations (PRs) in the form of conditional vectors. The workflow of the pre-training phase is as follows: we initially combine the transmitted images with the decoded images through concatenation. Following this, we utilize the PixelUnshuffle operation to downsample the concatenated images to serve as input for N\u2081. The extracted PRs from this process are designated as Z. Then, N2 can use the extracted Z to restore images, which is stacked with dynamic transformer blocks in the Unet shape. The dynamic transformer blocks consists of Dynamic Multi-head Transposed Attention (DMTA) and Dynamic Gated Feed- Forward Network (DGFN), which can use Z as dynamic modulation parameters to add restoration details into feature maps, effectively aggregating both local and global spatial characteristics. The trained model obtained from this pre-"}, {"title": "E. Multi-user communication system", "content": "The multi-user scenario refers to each user transmitting independent semantic information to perform their transmis- sion tasks. As shown in Fig. 1, a multi-user generative AI semantic communication system that consists of k sources and k destinations is considered. The message of the k-th user's source is denoted as Ik. Each source transmits semantic information. Similar to the single- user cognitive semantic communication system, the semantic information is first expressed as the semantic symbols. The semantic symbol Sk is abstracted from the image source Ik by using our proposed semantic feature encoder, given as: \n$$S_{k} = E(I_{k}), k = 1, 2, ..., n.$$\nAfter the semantic symbols of each source are obtained, they are transmitted by exploiting the conventional non-trainable fully connected layer to simulate. Specifically, the semantic symbol Sk is encoded in order to improve transmission efficiency, and fk is obtained, i.e., \n$$f_{k} = C(S_{k}) = W_{n}S_{k} + b_{n}, k = 1, 2, ..., n,$$\nwhere C is the channel coding; fk and Sk are the channel coding and semantic symbols of the k-th source, respectively. After transmission over the channel, the channel decoding is performed at each user receiver, and the reconstructed semantic symbol Sk is obtained by exploiting our proposed semantic feature decoder module. Note that the semantic symbols of different users are not distinguished in this process. Thus, the reconstructed semantic symbol of each user is mixed, given as: \n$$\\hat{S}_{k} = E^{-1} (C^{-1} (\\hat{f}_{k})), k = 1, 2, ..., n,$$\nwhere C-1 is the channel decoding and E-1 is the semantic feature decoding, Sk is the reconstructed semantic information images and fk is the channel coding received vector at the k-th user. Then, the reconstructed semantic symbols of each user need to be fine tuning. All models can be trained in the cloud and then broadcast to users. Similar to the single- user cognitive semantic communication system, the received images is obtained by exploiting our proposed semantic fine- tuning module. To address the challenge of data processing in multi-user scenarios, we first implemented a data segmentation strat- egy during the preprocessing stage. This approach simulates different user sources generating diverse messages, enabling effective allocation of user tasks to various processing units and allowing these tasks to be executed concurrently. Subse- quently, we introduced an asynchronous concurrent processing model. Employing asynchronous task processing functions and event loops ensured that the system's main thread remained unblocked during I/O operations, thereby facilitating the con- current execution of multiple user tasks. To further enhance system performance, we leveraged task parallel processing technology. This technique involves de- composing a single user task into smaller subtasks and exe- cuting these subtasks concurrently across multiple processing units. This approach fully utilizes GPU resources to boost sys- tem concurrency and performance. Additionally, to optimize system efficiency and reduce computational load, we incor- porated a caching mechanism. This mechanism stores previ- ously computed results and reuses them when needed, thus avoiding redundant calculations and enhancing the system's response speed and throughput. Through implementation, this multi-user communication system based on an asynchronous processing model significantly improves resource utilization, processing speed, and system stability. It is suitable for sce- narios requiring parallel processing of a large number of user communication tasks, with a high practical application value."}, {"title": "IV. SIMULATION RESULTS AND DISCUSSIONS", "content": "In this section, simulation results are presented to evaluate the performance of our proposed single-user and multi-user generative AI semantic communication systems. They are compared with deep learning-based methods and the tradi- tional communication systems realized by the separate source and channel coding technologies. In addition, to demonstrate the robustness of the proposed method, the simulation experi- ments are performed under the AWGN channels and Rayleigh fading channels, where the perfect CSI is assumed for all methods. For the MU-GSC, the transceiver is assumed with three single-antenna users and the receiver with three antennas."}, {"title": "A. Simulation setup", "content": "The training process is divided into two independent parts: semantic feature encoder/decoder and SFT. To comply with the generalization of ISC, the classical communication network based on the Swin Transformer is chosen as the semantic feature coder in this paper. Specifically, this network uses the ReLU activation function between the input layer and the two hidden layers, the hyperparameter C is set to 32, the loss function adopts the MSE, the batch size is set to 32, and the window size is set to 2, and then it is trained using Adam's optimizer [37] with a learning rate of 1 \u00d7 10\u22124. During the SFT training process, we adopt a two-step training strategy utilizing a four-level encoder-decoder structure in the DTBN. From level 1 to level 4, the attention heads in DMTA are set to [1, 2, 4, 8], the number of dynamic transformer blocks to [3, 5, 6, 6] and the number of channels C' of N\u2081 is set to 96. Training begins with a patch size of 32 \u00d7 32 and a batch size of 16. In the second step, \\(\\beta_t\\) linearly increases from 0.10 to 0.99, starting with an initial learning rate of 2 \u00d7 10-4, and the total timesteps T are set at 4. In this simulation, the experimental platform for training and testing is built on an Ubuntu 20.04 system with CUDA 11.8 support, and the deep learning framework is Pytorch 2.0.0. Note that the training phase of the diffusion model is done at the cloud server of the BS, and the receiver is only involved in the reverse inference process. Compared to the pre- training phase, semantic information generation requires lower computational resources. Therefore, the receiver is sufficient to run these modules with acceptable computational latency. We compare our proposal with classical separation-based source and semantic communication. The traditional commu- nication model considers the well-established image codec JPEG, an image compression algorithm used in various ap- plications such as Internet content delivery, digital photog- raphy, and medical imaging. Many fields include Internet content delivery, digital photography, and medical imaging. The channel noise or fading is then processed using a Low-Density Parity-Check code (LDPC) and Quadrature Amplitude Modulation (QAM) scheme, denoted as JPEG+LDPC+QAM. The modulation order is set to 4. The semantic communication"}, {"title": "B. Performance comparison", "content": "To demonstrate the effectiveness of the proposed method, this section analyzes the quality of the images generated by the three methods under two different channel conditions. Specif- ically, we present the Peak Signal-to-Noise Ratio (PSNR) of the decoded image obtained using these approaches. For the proposed method, a single model covers a range of SNR from 0 dB to 15 dB. As expected, the proposed algorithms agree with the trend of PSNR variation in semantic communication with increased SNR. Fig. 4a shows the PSNR score versus the SNR achieved by using the proposed GSC and the benchmark systems under the AWGN channels. Note that for the traditional method, i.e., JPEG+LDPC+QAM, When the channel deteriorates beyond a threshold (SNR<3), the receiver cannot decode the channel code and, therefore, cannot transmit any semantic information. Comparatively, when the SNR>6, the PSNR reaches the performance saturation of traditional communication algorithms, and the image similarity score of these methods in Fig. 4 almost converges to 20, and further enhancement will not improve the output quality. However, with the reduction of SNR, the performance of the traditional methods is significantly degraded and is obviously poorer than that of the semantic communication systems. Our proposed system shows the same behavior as the DeepJSCC method. However, since the semantic information can be enhanced by the fine-tuning module, it is clear that the proposed GSC is more competitive than the DeepJSCC in the low SNR regime. Taking SNR=15 as an example, our method achieves a significant improvement in PSNR compared to the bench- mark DeepJSCC algorithm, with 17.75% of the enhancement observed in AWGN channel and 20.86% in Rayleigh channels. Fig. 4b shows the PSNR score versus the SNR achieved using GSC and the benchmark systems under Rayleigh fading channels. Fig. 4b exhibits the same behavior as that of Fig. 4a. Despite the more demanding harsh Rayleigh channel condi- tions, the GSC shows advantages in semantic communication. This observation can be attributed to the fact that, although LDPC codes and QAM modulation enhance the robustness of data transmission, JPEG compression algorithms are lossy and may lead to irreversible information loss, which reduces the fault-tolerance of the whole system, resulting in degradation of image quality or data integrity in the presence of trans- mission errors. Meanwhile, the PSNR of JPEG+LDPC+QAM remains constant when the channel conditions are very bad or substantially improved, which reflects the so-called cliff effect. In addition, in the forward channel, SNR ranges from 0 dB to 6 dB. Compared to the transmission performance of JPEG+LDPC+QAM, the GSC does not degrade rapidly, demonstrating a significant graceful degradation advantage. Compared with DeepJSCC, the proposed method has a lower performance gap at lower SNR, indicating that even if the received semantic information image is severely corrupted, it can still generate a realistic image consistent with the original transmitted semantic information. It is clear that our proposed system is more competitive and robust in poor channel environments. Figs. 4c and 4d show the PSNR score versus the SNR over the AWGN and Rayleigh channel, respectively, by using"}, {"title": "V. CONCLUSION", "content": "This paper proposes a generative AI semantic communi- cation system that introduce an advanced and interpretable semantic fine-tuning module to enhance semantic information. Simulation results demonstrate that our method delivers supe- rior transmission quality compared to traditional separation- based method and DeepJSCC, significantly improving commu- nication services in resource-limited wireless networks, par- ticularly under low signal-to-noise ratio conditions. Moreover, Although our method's running time is slightly higher than that of DeepJSCC, fundamental techniques such as asynchronous processing substantially enhance the system's response speed and throughput, demonstrating the scalability of the proposed single-user system in multi-user scenarios."}]}