{"title": "ATTRIBUTING CULTURE-CONDITIONED GENERATIONS TO PRETRAINING CORPORA", "authors": ["Huihan Li", "Arnav Goel", "Keyu He", "Xiang Ren"], "abstract": "In open-ended generative tasks like narrative writing or dialogue, large language models often exhibit cultural biases, showing limited knowledge and generating templated outputs for less prevalent cultures. Recent works show that these biases may stem from uneven cultural representation in pretraining corpora. This work investigates how pretraining leads to biased culture-conditioned generations by analyzing how models associate entities with cultures based on pretraining data patterns. We propose the MEMOED framework (MEMOrization from pretraining document) to determine whether a generation for a culture arises from memorization. Using MEMOED on culture-conditioned generations about food and clothing for 110 cultures, we find that high-frequency cultures in pretraining data yield more generations with memorized symbols, while some low-frequency cultures produce none. Additionally, the model favors generating entities with extraordinarily high frequency regardless of the conditioned culture, reflecting biases toward frequent pretraining terms irrespective of relevance. We hope that the MEMOED framework and our insights will inspire more works on attributing model performance on pretraining data.", "sections": [{"title": "INTRODUCTION", "content": "In open-ended generative tasks like narrative writing or dialogue, language models often show bias against marginalized social groups based on gender, race, or culture (Gallegos et al., 2024; Manvi et al., 2024; Li et al., 2024b). Cultural bias is particularly notable due to the vast number of cultures to account for. Cultures are often unevenly represented in the pretraining corpora, with some mentioned more frequently than others, irrespective of their real-world prevalence (Li et al., 2024a). Recent studies reveal that models favor entities (Naous et al., 2023) and opinions (Ryan et al., 2024) from frequently represented cultures in pretraining while showing inadequate knowledge and templated answers for less frequent ones (Li et al., 2024b).\nSuch biases in culture-conditioned generations can be linked to studies showing that LLMs' memorization and generalization are constrained by pretraining data imbalances. Zhang et al. (2024) find that these imbalances cause models to overgeneralize to high-frequency knowledge, overshadowing lower-frequency knowledge. Similarly, Chang et al. (2024) observe that LLMs struggle with generating long-tail knowledge in downstream tasks when such knowledge appears with intervals longer than a threshold in pretraining data to enable memorization.\nBuilding on these findings, we analyze culture biases by examining how models associate entities, referred to as \u201csymbols,\u201d with cultures based on patterns in pretraining data (e.g., \u201ckimono\u201d associated with Japan). We investigate three key questions: 1) How can we determine if a symbol is generated for a culture due to memorization of their association? 2) If not memorization, what other factors drive the model's association? 3) How are these types of associations tied to pretraining data frequency imbalances?"}, {"title": "RELATED WORKS", "content": "Memorization and Generalization. The knowledge and capabilities of LLMs stem from leveraging large-scale pretraining corpora through both memorization and generalization. One line of work focuses on prompting LLMs to emit memorized training data (Wang et al., 2024; Carlini et al., 2023; Nasr et al., 2023; Zhang et al., 2023; Schwarzschild et al., 2024). Carlini et al. (2023) shows that memorization increases with model size, example duplication, and prompt length. Another line examines attributing memorization to internal features and its impact on generalization (Feldman, 2020; Feldman & Zhang, 2020; Zheng & Jiang, 2022; Zhang et al., 2023), with Zheng & Jiang (2022) highlighting the importance of long-tail instances for generalization. Recent works extend memorization to knowledge units like n-grams (Cao et al., 2020; Kandpal et al., 2023; Mallen et al., 2022), and Antoniades et al. (2024) distinguishes memorization from generalization based on n-gram similarity. Additionally, research explores how knowledge memorization affects generation quality, with Zhang et al. (2024) and Chang et al. (2024) finding that pretraining data imbalances and long-tail knowledge intervals hinder learning and generation.\nCulture bias in culture-conditioned generation tasks. Recent work on probing and evaluating cultural bias in LLMs spans multiple areas. One approach compares the Western-Eastern dichotomy in model generations related to culinary habits (Palta & Rudinger, 2023), etiquette (Dwivedi et al., 2023), commonsense knowledge Nguyen et al. (2023), and other facts  (Keleg & Magdy (2023); Naous et al. (2023); Khandelwal et al. (2023); Li et al., 2024b). Another evaluates LLMs' cultural understanding using socio-cultural surveys originally designed for humans, such as the World Values Survey and Pew Global Attitudes Survey (Ramezani & Xu, 2023; Tao et al., 2023; Durmus et al., 2023). Additionally, works propose using LLM generation to create new resources and benchmarks for cultural knowledge(Ziems et al., 2023; Huang & Yang, 2023; Fung et al., 2024)."}, {"title": "ANALYSIS SETUP", "content": "3.1 TYPES OF SYMBOL-CULTURE ASSOCIATIONS IN CULTURE-CONDITIONED GENERATIONS\nA symbol is an entity mentioned in culture-conditioned generations. For example, in a culture-conditioned generation about food, \u201cMy neighbor is Japanese. For dinner, my neighbor probably likes eating Miso Soup and Gyoza.\u201d \u201cMiso Soup\u201d and \u201cGyoza\" are two symbols generated for the Japanese culture. After an initial inspection of the generations, we discover four prevalent categorizes of associations between the conditioned culture and generated symbols:\nMemorized Association is when the symbol and culture co-occur in meaningful context (i.e. pretraining documents relevant to both the symbol and the culture) with high frequency (distinguishable from other cultures) in pretraining corpora and their association is learned by the model naturally. Memorized associations are important and highly desirable because they are grounded on pretraining documents, demonstrating sufficient model memorization of the symbol-culture association during pretraining.\nDiffuse Association, in contrast to memorized association, happens when a symbol is generated for a wide group of cultures without being associated with any of them through pretraining document grounding. While these symbols are not necessarily wrong (e.g. \"meat\" may be a food for any culture), they are not informative, not distinctive, not interesting, and therefore not desirable. This phenomenon suggests that the model has drawn unintended associations of these symbols with many cultures, and prioritizes these symbols over more culture-specific memorized associations."}, {"title": null, "content": "Cross-culture Generalization is when the symbol that has memorized association with culture A instead of culture B, but is generated for culture B. Here, we say the symbol is a cross-culture generalization for culture B. Cross-culture generalization reveals that due to certain correlations between culture A and B the model has generalized memorized symbols for culture A to culture B. While this phenomenon may suggest promising generalization capabilities of models, such generalization suppresses generation of memorized symbols of culture B that are more relevant to the instruction.\nWeak Association Generalization happens for symbols that are neither memorized association with any culture due to insufficient evidence in the pretraining data to confirm strong memorization for them, nor identified as a diffuse association symbol that is broadly generated for the majority of cultures. However, they may be inferred, or generalized, from other symbols who have memorized or diffuse associations. For example, \u201ckimono\" is a type of \"robe\" specific to Japan, even though \"robe\" is not memorized association with Japan. This type of generalization is desirable because the symbol and culture show a weak association evidenced from pretraining data, yet the model is still able to learn such association."}, {"title": "DATA COLLECTION PROCESS", "content": "Model and Data. We conduct all of our analysis on OLMO-7B (Groeneveld et al., 2024) and its pretraining corpora Dolma (Soldaini et al., 2024), as OLMO-7B is the most capable generative large language model with open-sourced and indexed pretraining data. The same analysis could be extended to other models in future works, as long as their pretraining data is accessible.\nScope. Following the prompts and settings of (Li et al., 2024b), we collect generations for each of 110 cultures on food and clothing topics. We choose food and clothing among all topics introduced in (Li et al., 2024b) due to the high variation of symbols observed in their generations.\nGeneration. We prompt the model in a continuing generation task where we use the following topic-wise prompts:\n\u2022 Food: My neighbor is [culture]. At dinner, [he/she/my neighbor] probably likes to eat\n\u2022 Clothing: My neighbor is [culture]. [he/she/my neighbor] is probably wearing\nWe use the default model implementations from huggingface, setting temperature=1.0, top p=0.95, top_k=50, max_tokens=30 and num_return_sequences=100, and period ('.') as the stopping criteria. Ablations on hyper-parameters is in Appendix F.\nWe sample 100 generations for male, female, and gender-agnostic settings, and thus, for each culture, we get 300 generations. Language models usually complete this prompt with one or more symbols. We take each completion and use LLAMA-3-70b-instruct to extract the symbols from the generation. The prompt for extracting symbols can be found in Li et al. (2024b)."}, {"title": "IDENTIFYING KNOWLEDGE MEMORIZATION FROM CULTURE-CONDITIONED GENERATIONS", "content": "In this section, we demonstrate our MEMOED pipeline for classifying memorized associations. We first introduce how MEMOED determines whether one document contributes to culture-symbol memorization, and describe how we determine memorization from all contributory documents.\nFirst, we determine if a document contributes to culture-symbol association. Given a training document D, a culture C (represented by both country and nationality, e.g. China and Chinese) and a symbol S that is generated for culture C, the document is contributory to the memorization of association between C and S if tokens representing C and S appear within sufficiently low distance in D and D has high context relevance to C.\nSufficiently low distance is important because the tokens representing C and S must appear in the same piece of text during pretraining. Therefore, we introduce two metrics, minimum token distance $d_{\\text{\u0442\u043e\u043a}}(C, S, D)$ and minimum sentence distance $d_{\\text{sent}}(C, S, D)$. For each document D, $d_{\\text{\u0442\u043e\u043a}}(C, S, D)$ is calculated as the minimum number of subtokens, determined by the model's tokenizer, between all occurrences of C and S n-grams in the document D (Appendix D). $d_{\\text{SENT}}(C, S, D)$ is calculated as the minimum number of sentences separating the C and S n-grams, by splitting the document D along delimiters like full-stops.\nHigh context relevance is important because documents that strongly contribute to culture-symbol memorized association should be topically relevant to the culture and symbol, manifested by high density of the culture and symbol n-grams compared to other cultures' n-grams. Therefore, we propose Document-Signal to Noise Ratio $d_{snr}(C, S)$, the log ratio of the frequency of culture C to the sum of frequency of all other cultures appearing in the same document. With t representing each n-gram that refers to a culture, we define $d_{SNR}(C, S, D)$ as:\n$d_{SNR}(C, S) = log_2( \\frac{\\sum_{Step 1 t=C}}{(\\sum_{Step 1 t\\neq c} )+ \\epsilon})$\nDocuments that strongly contribute to culture-symbol memorization should have high $d_{SNR}$, as the documents must have higher signals (target culture) than noise (other cultures).\nThere are two scenarios where we classify a document D as relevant and contributory to the memorization of association between culture C and symbol S.\n1. Global Relevance: $d_{\\text{\u0442\u043e\u043a}}(C, S, D) \\leq max\\_seq\\_len \\& dsnr(C, S, D) \\geq 0$."}, {"title": null, "content": "Given that $d_{SNR}$ uses a logarithmic function to calculate the frequency strength of the target culture in the pretraining document, scores greater than 0 signify a ratio \u2265 1, indicating that the target culture is at least as frequent as all other cultures combined. Furthermore, we upper-bound $d_{\\tau o\u03ba}(C, S, D)$ to ensure that both C and S will appear in the same context window during pretraining. For OLMO-7B, max_seq_len = 2048.\n2. Local Relevance: $d_{SENT}(C, S, D) \\leq 2 \\& dsnr(C', S, D) \\in [-1,0)$.\nEmpirical observations indicate that documents with $dsnr(C, S, D)$ scores between \u20131 and 0 often contain highly relevant excerpts that contribute significantly to the culture-symbol association, albeit not extending to the entire document. For these cases, we apply the $d_{SENT}(C, S, D)$ metric with a strict threshold of 2 to avoid over-counting. Relevant excerpts from various pretraining documents are detailed in the Appendix G.\nSecond, we determine if a symbol is a memorized symbol of a culture. For a given symbol S and any culture $C\\in C_G$ (where $C_G$ denotes the set of cultures that generated the symbol S'), we retrieve a complete set of documents D. $D_r \\subset D$ represents the subset of documents classified as contributory to the culture-symbol memorization using the criterion described above. Utilizing this subset, we calculate the following metrics to determine if S is a memorized symbol for culture C:\nContribution Score. Contribution Score (Cs) is the ratio of the number of contributory documents, denoted n(D,), to the total number of documents in which the symbol S appears. Formally, $Cs = \\frac{n(D_r)}{n(S)}$. This measure tells us for all documents where the symbol occurs, proportionally how many exhibit strong association with given culture, helping us determine if the symbol is memorized for the culture.\nDetermining memorization with z-score. We compute contribution score for every culture C in CG, and we normalize these scores to form a categorical distribution . We then compute the z-score of contribution scores for each culture within this distribution. Intuitively, if the distribution is flat, then the symbol is not distinguishably associated with any of the cultures; if the distribution is spiked at a few cultures, then these cultures are distinguishable from the rest for their association with the symbol. Therefore, we set the threshold of z-score to 2.6 (> 99.5% of $C_G^3$) to find \"outliers\u201d in the distribution and classify the symbols as memorized for cultures whose z-score is above the threshold.\nIn scenarios where a symbol S is generated across less than five cultures, i.e., $n(C_G) \\leq 5$, z-score is known to be unstable for distributions with small sample size. Therefore, we select the highest scoring culture among CG as long as it's contribution score is above a lower bound of, where N represents the total number of cultures in our set, i.e.110."}, {"title": "ANALYSIS ON NON-MEMORIZED ASSOCIATIONS FROM CULTURE-CONDITIONED GENERATIONS", "content": "For each of the three non-memorized associations, we conduct the following analyses to understand why such associations are formed during pretraining.\nDiffuse Association. We hypothesize that diffuse association occurs when a certain symbol has substantially higher frequency in the pretraining corpora compared to other symbols, causing the model to prioritize generating this symbol for many cultures.\nWe identify symbols that are generated for at least half of total cultures, i.e. 55 cultures, as being generated out of diffuse association. We count the occurrence frequency of all symbols of diffuse association and all symbols of memorized association in pretraining data using Infinigram API . In order to verify whether large frequency gap causes the model to prioritize diffuse association to memorized association, for each symbol of diffuse association, we calculate its over-shadowing ratio as $r = \\frac{count(Si)}{\\sum_{j=1}^{N} count(Sm_j)}$, where count(Si) is the count of a diffuse association symbol, count(Smj) is the count of the j-th unique memorized symbol and N is the number of unique memorized symbols."}, {"title": "RESULTS", "content": "4.1 \u039c\u0395\u039cORIZATION IS LIMITED FOR UNDER-REPRESENTED CULTURES\nWe observe a medium-to high correlation between 1) the number of memorized symbols for a culture and 2) the count of documents in which the culture appears in the pretraining corpora. For food, we obtained a Spearman correlation of 0.670 and a Kendall \u30f6 correlation of 0.507. For clothing, we obtained a Spearman correlation of 0.540 and a Kendall 7 correlation of 0.421."}, {"title": null, "content": "In clothing, however, only 45 cultures out of 110 have at least one memorized symbol, i.e. around 60% have no memorized symbols, and on average one culture has about only 2 memorized symbols.\nThe limited memorization for under-represented cultures roots in the inadequate representation in the pretraining corpora. According to Chang et al. (2024), LLMs go through periodic forgetting of factual knowledge during pretraining and memorization requires the knowledge to appear within intervals shorter than the forgetting interval. Therefore, symbols of under-represented cultures are less likely to get memorized and be generated within the top-k outputs. Instead, symbols not belonging to the culture (evidenced by how MEMOED finds insufficient contributory documents) are generated, leading to diffuse association or cross-culture generalization (see Appendix 4.3 and 4.4)."}, {"title": "MEMORIZED ASSOCIATION DO NOT LIMIT TO CULTURALLY-EMBLEMATIC SYMBOLS", "content": "To dig deeper into the composition of memorized association, we recruit natives from the each respective culture and ask them whether each symbol \"originates from\u201d or \u201cis emblematic to\" their own culture.\nWe annotate symbols of 8 cultures: American, Chinese, Filipino, Indian, Ghanaian, Japanese, Mexican, Vietnamese. These are the only cultures having more than 25 active annotators who were born in the culture but are currently in the United States. In total, we have recruited 257 annotators. Each annotator is tasked with evaluating 11 questions, including one attention check question that was designed as a simple verification question to ensure the reliability of the responses. An annotator may annotate many times on different questions, and each symbol is annotated by 3 annotators. See Appendix E for annotation instructions.\nOverall, MEMOED's classification of memorized symbols agrees with human classification of emblematic symbols, with a weighted F1 score of 0.845 on clothing and 0.670 on food.\nHowever, not all memorized symbols are emblematic symbols to a culture. The rest of the symbols consist of entities that are still used in the culture a lot without being an emblematic symbol: for example, \"western style bridal gown\" is recognized as a memorized symbol for Indian clothing, while \"business suit\" is recognized as a memorized symbol for Japanese clothing. MEMOED is able to capture such associations from pretraining data that would otherwise be neglected by human annotators."}, {"title": "DIFFUSE ASSOCIATION IS FREQUENCY-DRIVEN", "content": "We find a moderate-to-high positive correlation for both clothing (Spearman p = 0.551, Kendall \u03c4 = 0.385) and food (Spearman p = 0.519, Kendall T = 0.385) on overshadowing ratio r (defined in Section 3.4) and the number of cultures that the diffuse association symbol is generated for. This indicates that high pretraining frequency of diffuse association symbols is magnitudes higher than the frequency of memorized symbols, and this increases the chance of diffuse association overshadowing memorized association during sampling."}, {"title": "CROSS-CULTURE GENERALIZATION FROM HIGH TO LOW FREQUENCY CULTURE", "content": "Frequency Analysis. We first observe a strong positive correlation between 1) the culture's number of topic-related pretraining documents and 2) the frequency of the culture's memorized symbol being generated for some other cultures (clothing: Spearman p = 0.763, Kendall \u315c = 0.574; food: Spearman p = 0.716, Kendall \u0442 = 0.531). Simultaneously, the culture's number of topic-related pretraining documents is also negatively correlated with the percentage of the culture's response containing another culture's memorized symbols (food only: pearman p = \u22120.521, Kendall r = -0.364)."}, {"title": "GENERALIZATION FROM WEAK ASSOCIATION IS NOT CORRELATED WITH MEMORIZATION", "content": "On average, 3.1% and 5.0% of generations are generalized symbols for clothing and food, respectively. Interestingly, higher number of memorized symbol does not lead to higher number of generalization stemming from them. We only see a weak-to-none correlation (Spearman correlation of 0.17 and -0.03 for clothing and food) between the two types of symbols. Additionally, cultures without any memorized symbols rank higher in number of generalized symbols (e.g. Yemenis for clothing and Tribagonian for food). Cultures such as these where the model wasn't able to memorize anything, prompts the need for generalizations in the next token distribution.\nFor symbols that partially contain or are a combination of symbols from diffuse association, we find that they are generalizations which can be traced to high-frequency symbols resulting from diffuse association. These comprise of about 0.1% and 0.2% of generations on average for food and clothing respectively but almost 1/3 of the unique symbols for clothing."}, {"title": "THE DISTRIBUTION OF FOUR TYPES OF CULTURE-SYMBOL ASSOCIATIONS", "content": "In our analysis, we extract 2370 unique symbols for food and 1002 for clothing. Of these, 4.1% (98 symbols) and 10.9% (110 symbols) appear in over 50% of cultures, categorized as diffuse association, for food and clothing respectively. For food, 46.12% (1098 symbols) are identified as memorized association, and 31.3% (713 symbols) as weak association symbols generalized from memorized symbols. In contrast, for clothing, 25.78% (258 symbols) are memorized association, and 31.6% (317 symbols) are weak association generalized from memorized symbols. Additionally, a smaller fraction of food symbols (7.6%, or 180 symbols) and a significant portion of clothing symbols (nearly one-third, or 332 symbols) are weak association generalized from high-frequency symbols of diffuse association. The remaining small proportion of symbols include hallucinations, typos, and brand names, not fitting into these categories.\nWhile diffuse association only comprise of a small proportion of the total unique symbols extracted from responses, they comprise a significant proportion (91.12% for clothing and 79.2% for food) of the total responses, indicating that they are sampled multiple times during the generation process. Additionally, memorization is especially scarce in generated responses, averaging only 0.76% for clothing and 4.12% for food while traceable generalization averages to 3.1% and 4.9% for both topics respectively. However, as seen in Figure 7, the extent of memorization in responses has very high variance (from 0% for Trinidad to almost 42.2% for Mexico in food). Cross-culture generalization, while only averaging 4% and 11% respectively for clothing and food, exhibits high variance with cultures with a high number of memorized symbols having lesser cases of generating symbols memorized for other cultures. It is also visible in cases when certain cultures show common themes related to the topic in their pre-training document."}, {"title": "CONCLUSION", "content": "In conclusion, our work introduces MEMOED, a framework for attributing culture-conditioned generations of language models to memorization from pretraining data. By analyzing the appearance of symbols in model outputs across 110 cultures, we uncover a clear imbalance in how many symbols language models memorize for high-frequency and low-frequency cultures. In addition, models tend to prioritize generating high-frequency symbols that are not specific to any culture over memorized symbols, while also struggling to generalize from memorized cultural symbols with lower prevalence in the pretraining data. This highlights significant limitations in current pretraining processes, where models prefers frequently occurring, diffusely associated symbols at the expense of diverse, culture-specific knowledge. Our findings underscore the need for improved pretraining data and methods, and we hope this research sparks further work on linking model behavior to data-driven insights."}, {"title": "LIMITATIONS", "content": "MEMOED uses each individual document as the unit of memorization, while it is possible that one document may contain multiple excerpts of culture/symbol co-occurrence within minimum token threshold. However, we cannot exactly reproduce the contexts of the pretraining process as the training batches are randomly ordered in OLMO-7B training.\nOur study is only conducted on OLMO-7B due to the fact that it is the model with highest language capability that also has open pretraining data. How our conclusions may hold for non-OLMo family models is unknown; however, our methodology introduced in \u00a73 is transferrable for analyzing any model, as long as their pretraining data is accessible."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "Algorithm. We provide accurate description of our analysis framework in Section 3, and additional details in the appendix.\nPrompt Engineering. The prompts we used for generating culture-conditioned generations, prompting for traceable generalization definition and topic modeling are included in the appendix.\nData and Source Code. Data and source code will be released upon acceptance.\nCrowdsourcing. Instructions for Prolific annotators are available in Appendix E."}, {"title": "ETHICS STATEMENT", "content": "Data. All data we collected through LLMs in our work are released publicly for usage and have been duly scrutinized by the authors. Data for all human studies that we conduct are also publicly released with this work, with appropriate annotator anonymizations.\nCrowdsourcing. All our crowdworkers are currently residing in the United States, with countries of birth from US, China, India, the Philipines, Ghana, Mexico and Vietnam. For all our human studies, the task is set up in a manner that ensure that the annotators receive compensation that is accepted by the platform ($12/hour). Furthermore, we ensure that we correspond with crowdworkers over direct message to address their queries.\nPotential Use. Our framework MEMOED may only be used for analysis that follow the ethics guideline of the community. Using MEMOED on mal-intentioned searching for proprietary data is a potential threat, but the authors strongly condemn doing so."}, {"title": "TOPIC MODELING", "content": "B.1 METHODOLOGY\nFor any culture C and its set of memorized symbols m(C), we select a symbol S \u2208 m(C) and identify the set of cultures CG which also generated S but not through a memorization. For each culture C' \u2208 CG and for C, we retrieve pre-training documents where the two cultures co-occur, forming a set Dec'. We apply the metrics defined in Section 3.3 to filter these documents, obtaining a subset Dec' \u2286 Dec' that are relevant to the association of the two cultures. We further refine Dec' by removing documents that do not contain the symbol S, resulting in a final set Dec's, which is relevant to the association between cultures C and C' and contains the memorized symbol S.\nSubsequently, we use a sliding window of size 2048 to create chunks from each document d \u2208 Dec' s. We employ Latent Dirichlet Allocation (LDA)  to model five topics from each set of chunks corresponding to a document. The modeled n-gram phrases with corresponding topic probabilities are then prompted to LLAMA-3.1-8B-Instruct . The LLM generates interpretable n-gram topic phrases, which are then filtered for repetitions using cosine similarity scores calculated with XLM-ROBERTa-large embeddings . Finally, we extract the top five keywords from these topics using TF-IDF.\nB.2 PROMPT\nIn figure 8, we provide the prompt used for prompting LLAMA-3.1-8B-Instruct with the LDA input and generating the outputs corresponding to interpretable topics which are inferred from the LDA and we use to generate keywords.\nIn Table 5, we extend our study of pre-training documents (Table 3) pertaining to cultural overmemorization from one culture to another for more cases of cultures which generate these memorized symbols with a lower count of relevant documents than the cultures discussed before. We notice suprisingly similiar themes in the pre-training documents such as the discussion around \"religion\" in documents where Hijab, Iran and any culture X co-occur. For Kimono and Japan, we notice a similar common theme surrounding \"fashion\". We hypothesize that such common themes also"}, {"title": "COMPUTING MINIMUM DISTANCE B/W TWO N-GRAMS", "content": "This section elaborates on the algorithm employed by us for computing minimum distance between two n-grams in a pretraining document and reporting the drok(C, S, D) metric. It calculates the context length difference between the n-grams C and S, as observed by the LLM during pre-training. We hypothesize that for a pre-trained language model with a sequence length L, a smaller d\u0442\u043e\u043a (C, S, D) indicates more frequent co-occurrence of the two n-grams across training batches. This frequent co-occurrence is likely to strengthen their association, thereby increasing the relevance of a document to the relationship between C and S.\nThe algorithm described in Algorithm 1 computes the minimum token distance between two n-grams within a text, using a tokenizer to process the input and mark relevant tokens. Initially, the text is tokenized to capture each token's positional offsets. The algorithm then marks tokens that correspond to the specified n-grams, word and symbol, by iterating through the text to find these n-grams and marking overlapping tokens with distinct values for each n-gram.\nFollowing the marking phase, the algorithm calculates the minimum distance by iterating through the marked tokens. It maintains pointers to the last positions of tokens related to word and symbol. When a token corresponding to one of the n-grams is encountered, the algorithm checks if the last seen position of the opposite n-gram has been recorded and updates the minimum distance if the current position is closer.\nThe procedure concludes by returning the minimum distance, which quantifies the proximity of the n-grams and reflects their associative strength in the context of language model pre-training."}, {"title": "HUMAN ANNOTATION SETUP USING PROLIFIC", "content": "We designed a human annotation task using Google Forms, automatically populated via Google Apps Script with symbols related to food and clothing from eight different cultures. Figure 9 provides an overview of the form setup, while Figure 10 shows an example of a question where participants were asked to evaluate whether a specific food is a cultural food item of some culture. Annotators were required to select the most appropriate classification based on their knowledge of the culture in question. This process enabled us to collect reliable data regarding culturally emblematic food and clothing items."}, {"title": "ABLATION STUDY", "content": "F.1 ABLATION ON HYPERPARAMETERS\nIn the original design of our decoding process, multinomial sampling was employed with a set of specified hyperparameters: temperature=1.0, top_p=0.95, top_k=50, max_tokens=30, and num_return_sequences=100. The stopping criterion was established as the period ('.') character. To explore the impact of these parameters on the generation results, an ablation study was conducted where top_k values of 20 and 80, and temperature values of 0.75 and 1.25 were tested against the original settings. We observed an overlap coefficient of greater than 90% in all the four cases. This tells us that the sampling conditions did not cause or change our findings.\nF.2 ABLATION ON OLMO-7B VARIANTS\nIn order to verify that conclusions we find on OLMO-7B hold on other modalities, we reproduce some of the experiments on a newer variant of OLMO-7B, OLMO-7B-0424. We collect culture-conditioned generations for both food and clothing on OLMO-7B-0424, which is trained on Dolma"}]}