{"title": "MOVING PAST SINGLE METRICS: EXPLORING SHORT-TEXT\nCLUSTERING ACROSS MULTIPLE RESOLUTIONS", "authors": ["Justin K. Miller", "Tristram J. Alexander"], "abstract": "Cluster number is typically a parameter selected at the outset in clustering problems, and while\nimpactful, the choice can often be difficult to justify. Inspired by bioinformatics, this study exam-\nines how the nature of clusters varies with cluster number, presenting a method for determining\ncluster robustness, and providing a systematic method for deciding on the cluster number. The\nstudy focuses specifically on short-text clustering, involving 30,000 political Twitter bios, where\nthe sparse co-occurrence of words between texts makes finding meaningful clusters challenging. A\nmetric of proportional stability is introduced to uncover the stability of specific clusters between\ncluster resolutions, and the results are visualised using Sankey diagrams to provide an interroga-\ntive tool for understanding the nature of the dataset. The visualisation provides an intuitive way to\ntrack cluster subdivision and reorganisation as cluster number increases, offering insights that static,\nsingle-resolution metrics cannot capture. The results show that instead of seeking a single 'optimal'\nsolution, choosing a cluster number involves balancing informativeness and complexity.", "sections": [{"title": "Introduction", "content": "When faced with a large collection of documents, it can be challenging to determine the nature of the topics the\ndocuments are covering. One way to approach this problem is to group documents together by theme, thus making\nit easier to understand the nature of the overall collection. This grouping of documents can be framed as a clustering\nproblem, in which the goal is to deduce the categories within the data [1]. Typically this categorisation would proceed\nby seeking to maximise the insight provided by the categorisations, while minimising the cognitive load required to\ndetermine\nwhich document goes into which category [2]. The effectiveness of clustering is thus contingent on the balance\nbetween the simplicity of the categories and the usefulness of the information the categories convey [3].\nThe challenge in text clustering therefore lies in finding a balance between creating clusters that are informative enough\nto capture meaningful distinctions in the data while remaining interpretable and easy to apply. This study examines\nhow varying the number of clusters affects this trade-off between informativeness and interpretability, highlighting\nthat there is no universally optimal clustering solution, but rather context-dependent cluster structures that best balance\nthese competing factors.\nCluster validation indices provide a multidimensional assessment that is essential for selecting the number of clus-\nters in line with specific analysis goals [3]. However, the choice of validation metric can significantly impact the\ndetermination of an \u2018ideal' cluster number, as different metrics emphasise different clustering characteristics [4]. For\nexample, metrics that prioritise within-cluster homogeneity, such as measures of low within-cluster distance, may lead\nto a preference for a higher number of clusters, as they aim to minimize internal variance. Conversely, metrics that\nfavor between-cluster separation, such as separation indices, can favor a smaller number of clusters by emphasizing\ndistinct boundaries between groups. Selecting an appropriate clustering solution therefore requires balancing these"}, {"title": "Related Work", "content": "Stability of clusters\nMost clustering methods involve finding clusters after a random initialisation process [12, 13]. This stochastic element\nin the initialisation means that the resulting clusters may be different with different initialisations. Cluster stability\nmeasures how consistently an algorithm finds the same clusters within a dataset across the different random starting\npoints. Cluster stability is therefore a measure which may be used to assess the robustness and reliability of clustering\nmethods, with the assumption being that if there is some underlying structure in the data, the algorithm should be able\nto recover this consistently.\nCluster stability is central in the field of bioinformatics, where the high-dimensional nature of the data, coupled with\nbiological variation, makes stability an indicator that a clustering algorithm has captured biologically meaningful\nclusters (e.g., distinct cell types) [14]. Importantly, in bioinformatics, the notion of stability is tied to the biological\nreproducibility of the findings: when clusters correspond to real biological phenomena, they should persist across\ndifferent algorithms, initialisations, and even perturbations to the dataset [15, 16]. To test how stable the clusters\nfound by an algorithm are, one must consider both the variance in the data, and also the variance in the dimensions\nused i.e. ensuring that the clusters are not just forming as a result of variance within a few data points, or from a few\nvariables [17]. This work will draw on the approaches of bioinformatics, but applied to text analysis.\nA key difference between bioinformatics and text clustering lies in the interpretability of the clusters themselves. While\nbiological clusters often have clear interpretations based on known cell types or functions [18], the interpretability of\ntext clusters relies heavily on human judgment [19]. This adds another dimension to the utility of stability. In text\nclustering, stability might suggest that the algorithm has found coherent groupings, but it doesn't guarantee that these\ngroupings are semantically meaningful or useful for the task at hand [12]. Hence, an additional human interpretability\nstep is often needed to evaluate whether the stable clusters align with meaningful categories or concepts [20].\nUltimately, stability serves as a valuable criterion for identifying meaningful clusters across fields, but the interpre-\ntation of stability can vary. In bioinformatics, stable clusters are likely to correspond to real, reproducible biological\nphenomena [17]. In text data, stable clusters may reflect coherent patterns, but assessing their utility requires further\ninterpretability checks, often involving human evaluation [21]. Stability, in this sense, acts as a precursor to, but not a\nguarantee of, meaningfulness [20]."}, {"title": "Gaussian Mixture Model Clustering", "content": "This work uses Gaussian Mixture Models (GMMs) to find clusters in a high dimensional text embedding space. GMMs\nare a probabilistic approach to clustering that assume the data are generated from a mixture of several Gaussian distri-\nbutions [22]. Each Gaussian component represents a cluster, and the algorithm assigns probabilities of membership for\neach data point across these clusters, making GMM a soft clustering technique. This section outlines the theoretical\nfoundation and practical implementation of GMM clustering [23, 24, 25].\nThe GMM assumes that the dataset X = {x1, x2,..., Xn} is generated from k Gaussian distributions, where each\ndata point xi \u2208 Rd belongs to a particular cluster with a certain probability. These parameters are generally esti-\nmated through the use of the Expectation-Maximization (EM) algorithm (E-step) [13], This paper uses the scikit learn\nimplementation of GMM, so uses this particular algorithm [22]. In the E-step, the algorithm calculates the posterior\nprobabilities (responsibilities) that each data point x\u2081 belongs to each Gaussian component j, denoted by \u03b3(zij), where\nZij is the latent variable indicating the cluster membership of xi:\n\u03b3(zij) = \\frac{\u03c0_j N(x_i | \\mu_j, \\Sigma_j)}{\\sum_{l=1}^{k} \u03c0_l N(x_i | \\mu_l, \\Sigma_l)} (1)\nDefinitions of Terms:\n\u2022 \u03b3(zij): The posterior probability (responsibility) that data point x\u2081 belongs to the j-th Gaussian component.\n\u2022 \u03c0j: The mixing coefficient (prior probability) for the j-th Gaussian component, satisfying \u2211k\\sum_{l=1}^{k} j = 1 and\n0 \u2264 \u03c0j \u2264 1.\n\u2022 N(xi | \u03bcj, \u03a3j): The multivariate Gaussian probability density function evaluated at xi with mean \u03bcj and\ncovariance matrix \u03a3j. It is defined as:\nN(x_i | \\mu_j, \\Sigma_j) = \\frac{1}{(2\u03c0)^{d/2}|\u03a3_j|^{1/2}} exp\\left(-\\frac{1}{2} (x_i - \\mu_j)^T \u03a3_j^{-1} (x_i - \\mu_j)\\right), (2)\nwhere:\n\u2022 d is the dimensionality of the data.\n\u2022 |\u03a3j| denotes the determinant of the covariance matrix.\n\u2022 (.)T represents the transpose of a vector.\n\u2022 xi: The i-th data point in your dataset.\n\u2022 \u03bcj: The mean vector of the j-th Gaussian component.\n\u2022 \u03a3j: The covariance matrix of the j-th Gaussian component.\n\u2022 k: The total number of Gaussian components in the mixture model.\n\u2022 Zij: The latent variable indicating the cluster membership of xi; Zij = 1 if xi belongs to cluster j, and\nZij = 0 otherwise.\n\u2022 \u2211k\\sum_{l=1}^{k}: The summation over all k Gaussian components.\nThis step assigns soft cluster memberships, meaning that each data point is assigned a probability of belonging to each\ncluster.\nCluster stability using Adjusted Mutual Information\nAdjusted Mutual Information (AMI) is a measure used to compare the similarity between two different clusterings of\nthe same dataset. It builds upon the concept of Mutual Information (MI), which quantifies the amount of information\nshared between two clusterings. MI is able to distinguish between true agreement and agreement that happens purely\nby chance, by looking at how the knowledge of one set of clusters reduces the surprise at the other set. However,\nMI does not account for the similarity that might occur by chance. AMI adjusts the MI score by accounting for\nthe expected similarity between random clusterings, providing a more accurate and reliable metric [26]. AMI is\nsymmetric, meaning that the AMI between the two sets is the same regardless of the order of the sets. The AMI used\nin this paper uses SKlearn's implementation of AMI [27].\nMutual Information between two clusterings U and V is defined as:"}, {"title": null, "content": "MI(U", "VEV\nWhere": "n\u2022 U = {U1"}, ".", {}, ".", ".", ".", ".", "s", {"H(V)": "E[MI(U", "V)": ""}, 3, "nWhere", ".", ["MI(U, V)"], "V)"], "assignments": "nH(U) = \u2211P(u) log P(u)\nUEU\nH(V) = \u2211P(v) log P(v)\nVEV\nThe AMI score ranges from 0 to 1, where close to 1 represents agreement between the two sets and close to 0 represents\nno relation between the two sets.\nMulti-level approaches to clustering\nPrevious work has explored multi-level approaches to clustering. One of which uses visualisations called \"Clustering\nTrees\" [28", "29": "."}