{"title": "Towards Unraveling and Improving Generalization in World Models", "authors": ["Qiaoyi Fang", "Weiyu Du", "Hang Wang", "Junshan Zhang"], "abstract": "World models have recently emerged as a promising approach to reinforcement learning (RL), achieving state-of-the-art performance across a wide range of visual control tasks. This work aims to obtain a deep understanding of the robustness and generalization capabilities of world models. Thus motivated, we develop a stochastic differential equation formulation by treating the world model learning as a stochastic dynamical system, and characterize the impact of latent representation errors on robustness and generalization, for both cases with zero-drift representation errors and with non-zero-drift representation errors. Our somewhat surprising findings, based on both theoretic and experimental studies, reveal that for the case with zero drift, modest latent representation errors can in fact function as implicit regularization and hence result in improved robustness. We further propose a Jacobian regularization scheme to mitigate the compounding error propagation effects of non-zero drift, thereby enhancing training stability and robustness. Our experimental studies corroborate that this regularization approach not only stabilizes training but also accelerates convergence and improves accuracy of long-horizon prediction.", "sections": [{"title": "1. Introduction", "content": "Model-based reinforcement learning (RL) has emerged as a promising paradigm to improve sample efficiency by enabling agents to exploit a learned model of the physical environment. Recent works on world models [1-8] involve RL agents learning a latent dynamics model (LDM) from observations and actions, and then optimizing the policy over this learned model. Unlike conventional approaches, world-model-based RL employs an end-to-end learning strategy, jointly training the dynamics model, perception, and action policy to achieve a unified goal. This framework offers significant potential to improve both generalization and robustness to perturbations, making it highly advantageous for real-world scenarios. For example, DreamerV2-V3 have achieved notable progress in mastering diverse tasks involving continuous and discrete actions, image-based inputs, and both 2D and 3D environments [1-3]. Recent empirical studies have also demonstrated the capacity of world models to generalize to unseen noisy states and dynamics in complex environments, such as autonomous driving [9]. However, it remains unclear when and how world models can generalize well in unseen environments, and the role of robustness in this process.\nIn this work, we aim to systematically understand the robustness and generalization capabilities of world models by examining the impact of latent representation errors introduced by latent encoders. Specifically, we investigate how these errors can enhance robustness against perturbations, which in turn often improves generalization [10]. Contrary to the expectation that minimizing latent repre-sentation errors by optimizing the LDM prior to policy training would lead to better performance, our theoretical and empirical findings reveal that modest latent representation errors during training may actually be beneficial for robustness. In particular, the alternating training strategy for world"}, {"title": "2. Related Work", "content": "Robustness and Generalization in Deep RL. Recent work on deep RL robustness and generalization has studied zero-shot generalization of learned policies to unseen environments [14], often empha-sizing task-level generalization through techniques such as task augmentation in meta-RL [15, 16]. In contrast, our work targets the robustness and generalization of world-model-based RL under observational and dynamic perturbations, emphasizing the role of latent representations. While recent studies on RL robustness [17, 18] introduce new training frameworks aimed at policy safety and robustness, they do not account for the inherent challenges posed by latent representation errors during rollouts.\nWorld model based RL. World models have excelled in visual control tasks across various platforms, including Atari [19] and Minecraft [20], as detailed in the studies by Hafner et al. [1\u20133]. These models typically integrate encoders and memory-augmented neural networks, such as RNNs [21], to manage the latent dynamics. The use of variational autoencoders (VAE) [22, 23] to map sensory inputs to a compact latent space was pioneered by Ha et al. [24]. Furthermore, the Dreamer algorithm [2, 4] employs convolutional neural networks (CNNs) [25] to enhance the processing of both hidden states and image embeddings, yielding models with improved predictive capabilities in dynamic environments.\nContinuous-time RNNs. The continuous-time assumption is standard for theoretical formulations of RNN models. Li et al. [26] study the optimization dynamics of linear RNNs on memory decay. Chang et al. [27] propose AntisymmetricRNN, which captures long-term dependencies through the control of eigenvalues in its underlying ODE. Chen et al. [28] propose the symplectic RNN to model Hamiltonians. As continuous-time formulations can be discretized with Euler methods [27, 28] (or with Euler-Maruyama methods if stochastic in [10]) and yield similar insights, this step is often eliminated for brevity.\nImplicit regularization by noise injection in RNN. Studies on noise injection as a form of implicit regularization have gained traction, with Lim et al. [10] deriving an explicit regularizer under small noise conditions, demonstrating bias towards models with larger margins and more stable dynamics. Camuto et al. [13] examine Gaussian noise injections at each layer of neural networks. Similarly, Wei et al. [29] provide analytic insights into the dual effects of dropout techniques."}, {"title": "3. Demystifying World Model: A Stochastic Differential Equation Approach", "content": "As pointed out in [1\u20134], critical to the effectiveness of the world model representation is the stochastic design of its latent dynamics model. The model can be outlined by the following key components: an encoder that compresses high dimensional observations $s_t$ into a low-dimensional latent state $z_t$ (Eq.1), a sequence model that captures temporal dependencies in the environment (Eq.2), a transition predictor that estimates the next latent state (Eq.3), and a latent decoder that reconstructs"}, {"title": "3.1. Latent Representation Errors as Implicit Regularization towards Robustness and Generalization", "content": "In this section, we investigate how latent representation errors influence both robustness and gen-eralization, considering two scenarios: zero drift and non-zero drift. Our analysis shows that under mild conditions, zero-drift errors can act as a natural form of implicit regularization, creating wider optimization landscapes that enhance robustness. However, when latent representation errors ex-hibit non-zero drift, they introduce an unstable bias that undermines the implicit regularization effect, leading to degraded generalization performance. In such cases, explicit regularization is necessary to stabilize learning and maintain both robustness and generalization capabilities in the world model.\nTo simplify the notation here, we consider the system equations, specifically Equations (5), (6) - (8), as one stochastic system. Let $x_t = (z_t, h_t, \\tilde{z}_t, \\hat{s}_t)$ and $B_t = (B^{enc}, B^{seq}, B^{pred}, B^{dec})$:\n$dx_t = (g(x_t, t) + \\epsilon \\sigma(x_t,t)) dt + \\sum_i (g_i(x_t, t) + \\epsilon \\hat{\\sigma}_i(x_t, t)) dB_i,$\nwhere g, and $g_i$ are structured accordingly for the respective components, employing the Einstein sum-mation convention for concise representation. For abuse of notation, $\\sigma = (0, 0, 0, 0)$, $\\hat{\\sigma} = (\\hat{\\sigma}, 0, 0, 0)$. For a given error magnitude $\\epsilon$, we denote the solution to SDE (9) as $x^{\\epsilon}$. Intuitively, $x^{\\epsilon}$ is the perturbed trajectory of the latent dynamics model. In particular, when $\\epsilon = 0$, indicating that the absence of latent representation error in the model, the solution is denoted as $x$."}, {"title": "3.1.1. The Case with Zero-drift Representation Errors", "content": "When the drift coefficient $\\sigma = 0$, the latent representation errors correspond to a class of well-behaved stochastic processes. The following result translates the induced perturbation on the stochastic latent dynamics model's loss function L to a form of explicit regularization. We assume that a (nonconvex) general loss function $L \\in C^2$ which depends on $z_t, h_t, \\tilde{z}_t, \\hat{s}_t$. Loss functions used in practical implementation, e.g. in DreamerV3, reconstruction loss $J_0$, reward loss $J_R$, consistency loss $J_D$, all satisfy this condition.\nTheorem 3.3. (Explicit Effect Induced by Zero-Drift Representation Error) Under Assumptions 3.1 and 3.2 and considering a loss function $L \\in C^2$, the explicit effects of the zero-drift error can be marginalized out as follows: as $\\epsilon \\rightarrow 0$,\n$\\mathbb{E}L (x^\\epsilon) = \\mathbb{E} L(x^1) + \\mathcal{R} + O(\\epsilon^3),$\nwhere the regularization term $\\mathcal{R}$ is given by $\\mathcal{R} := \\epsilon \\mathcal{P} + \\epsilon^2 (\\mathcal{Q}+ \\frac{1}{2} \\mathcal{S})$, with\n$\\mathcal{P} := \\mathbb{E}\\nabla L(x_1) \\Phi \\Sigma,$\n$\\mathcal{S}:=\\mathbb{E}\\sum_{k_1,k_2} (\\Phi^{i\\xi_k})^\\mathrm{T} \\nabla^2 L(x, t) (\\Phi^{i\\xi_{k_2}}),$\n$\\mathcal{Q}:=\\mathbb{E}\\nabla \\mathcal{L}(x) \\Phi \\int_0^T \\mathcal{H}^k (x,s)dB.$\nSquare matrix $\\Phi_t$ is the stochastic fundamental matrix of the corresponding homogeneous equation:\nd\\Phi_t = \\frac{\\partial g_k}{\\partial x} (x, t) \\Phi_t dB, \\Phi(0) = I,\nand $\\xi_k^j$ is the shorthand for $\\int_0^t \\hat{\\sigma}_k(x_i,s)dB_k$. Additionally, $\\mathcal{H}^k (x,s)$ is represented by for $\\sum_{k_1,k_2} \\frac{\\partial^2 g_k}{\\partial x^i\\partial x^j} (\\xi_k^j (1)) (\\xi_k^j (2))$.\nIn the special case when the loss L is convex, then its Hessian, $\\nabla^2L$, is positive semi-definite, which ensures that the term S is non-negative. The presence of this Hessian-dependent term S, under latent representation error, implies a tendency towards wider minima in the loss landscape. Empirical results from [32] indicates that wider minima correlate with improved robustness of implicit regularization"}, {"title": "3.1.2. The Case with Non-Zero-Drift Representation Errors", "content": "In practice, latent representation errors may not always exhibit zero drift as in idealized noise-injection schemes for deep learning ([10], [13]). When the drift coefficient $\\sigma$ is non-zero or a function of input data $h_t$ and $s_t$ in general, the explicit regularization terms induced by the latent representation error may lead to unstable bias in addition to the regularization term $\\mathcal{R}$ in Theorem 3.3. With a slight abuse of notation, we denote $\\hat{\\sigma}_0$ as g from Equation (9) for convenience.\nCorollary 3.4. (Additional Bias Induced by Non-Zero Drift Representation Error)Under Assumptions 3.1 and 3.2 and considering a loss function $L \\in C^2$, the explicit effects of the general form error can be marginalized out as follows as $\\epsilon \\rightarrow 0$:\n$\\mathbb{E} L (x^\\epsilon) = \\mathbb{E} L(x^1) + \\mathcal{R} + \\acute{\\mathcal{R}} + O(\\epsilon^3),$\nwhere the additional bias term $\\acute{\\mathcal{R}}$ is given by $\\acute{\\mathcal{R}} := \\epsilon \\acute{\\mathcal{P}} + \\epsilon^2 (\\acute{\\mathcal{Q}}+\\acute{\\mathcal{S}})$, with\n$\\acute{\\mathcal{P}} := \\mathbb{E}\\nabla L(x_1) \\Phi \\acute{\\xi},$\n$\\acute{\\mathcal{Q}}:=\\mathbb{E}\\nabla \\mathcal{L}(x) \\Phi \\int \\acute{\\Phi}^{s \\prime} \\mathcal{H}^\\circ (x, s) dt,$\n$\\acute{\\mathcal{S}} := \\mathbb{E}\\sum_{k} (\\Phi^{j \\acute{\\xi}_{k}})^2 \\nabla^2 L(x, t) (\\Phi^{\\xi}_{i \\acute{\\xi}_{k}}),$\nand $\\acute{\\xi}_t$ being the shorthand for $\\int_0^t \\Phi^{-1}\\sigma_k(x, s)dt$.\nThe presence of the new bias term $\\acute{\\mathcal{R}}$ implies that regularization effects of latent representation error could be unstable. The presence of $\\acute{\\xi}$ in $\\acute{\\mathcal{P}}$, $\\acute{\\mathcal{Q}}$ and $\\acute{\\mathcal{S}}$ induces a bias to the loss function with its magnitude dependent on the error level $\\epsilon$, since $\\acute{\\xi}$ is a non-zero term influenced on the drift term $\\sigma$. This contrasts with the scenarios described in [10] and [13], where the noise injected for implicit regularization follows a zero-mean Gaussian distribution. To modulate the regularization and bias terms $\\mathcal{R}$ and $\\acute{\\mathcal{R}}$ respectively, we note that a common factor, the fundamental matrix $\\Phi$, can be bounded by\n$\\mathbb{E} sup_t ||\\Phi_t||_F \\leq C exp \\left( C\\mathbb{E} sup_t (\\frac{\\partial g_k}{\\partial x})^2 \\right),$\nwhich can be shown by using the Burkholder-Davis-Gundy Inequality and Gronwall's Lemma. Based on this observation, we next propose a regularizer on input-output Jacobian norm $||\\frac{\\partial g_k}{\\partial x}||_F$ that could modulate the new bias term $\\acute{\\mathcal{R}}$ for stabilized implicit regularization."}, {"title": "4. Enhancing Predictive Rollouts via Jacobian Regularization", "content": "In this section, we study the effects of latent representation errors on predictive rollouts using latent state transitions, which happen in the inference phase in world models. We then propose to use Jacobian regularization to enhance the quality of rollouts. In particular, we first obtain an upper"}, {"title": "5. Experimental Studies", "content": "In this section, extensive experiments are carried out over a number of tasks in Mujoco environments. Due to space limitation, implementation details and additional results, including the standard deviation of the trials, are relegated to Section D in the Appendix.\nEnhanced robustness and generalization to unseen noisy states and varied dynamics.We evaluated the effectiveness of Jacobian regularization by comparing a model trained with this regularization against a vanilla model during inference, using perturbed state images and varied dynamics. We consider three types of perturbations to the observations: (1) Gaussian noise applied across the entire image, denoted as $N(\\mu_1, \\sigma_1^2)$; (2) rotation; and (3) Gaussian noise applied to a random portion of the image, $N(\\mu_2, \\sigma_2^2)$. Additionally, we examine variations in the gravity constant g for unseen dynamics. These perturbation patterns align with those commonly used in robustness studies ([34\u201336])."}, {"title": "6. Conclusion", "content": "In this study, we investigate the robustness and generalization of world models. We develop an SDE formulation by treating LDM as a stochastic dynamical system, and characterize the effects of latent representation errors for zero-drift and non-zero drift cases. Our findings, based on both theoretic and experimental studies, reveal that for the case with zero drift, modest latent representation errors can paradoxically function as implicit regularization and hence enhance robustness. To mitigate the compounding effects of non-zero drift, we applied Jacobian regularization, which enhanced training stability and robustness. Our empirical studies corroborate that Jacobian regularization improves generalization, broadening the model's applicability in complex environments. This work has the potential to improve the robustness and reliability of RL agents, especially in safety-critical applications like autonomous driving. Future work can extend this study to other world models such as with transformers-based LDM."}, {"title": "A. Approximation Power of Latent Representation with CNN Encoder and Decoder", "content": "In this section, we show that the latent representation error, in the form of approximation error corresponding to the widely used CNN encoder-decoder, could be made sufficiently small by finding appropriate CNN network configuration. In particular, this result provides theoretical justification to interpreting latent representation error as stochastic perturbation in the dynamical system defined in Equations (5 - 8), as the error magnitude $\\epsilon$ can be made sufficiently small by CNN network configuration, and the analysis carries over to other architectures (e.g., ReLU) along the same line.\nTo mathematically describe this intrinsic lower-dimensional geometric structure, for an integer k > 0 and a \u2208 (0, 1], we consider the notion of smooth manifold (in the $C^{k,a}$ sense), formally defined by\nDefinition A.1 ($C^{k,\\alpha}$ manifold). A$C^{k,\\alpha}$ manifold M of dimension n is a topological manifold (i.e. a topological space that is locally Euclidean, with countable basis, and Hausdorff) that has a $C^{k,\\alpha}$ structure $\\mathcal{C}=\\{U_{\\alpha}, \\psi_{\\alpha}\\}_{\\alpha\\in\\mathcal{A}}$ that is a collection of coordinate charts $\\{U_{\\alpha}, \\psi_{\\alpha}\\}_{\\alpha\\in\\mathcal{A}}$ where $U_{\\alpha}$ is an open subset of M, $\\psi_{\\alpha}$: $U_{\\alpha}$ $\\rightarrow$ $V_{\\alpha}$ $\\subset$ $R^{n}$ such that\nUEA Ua M, meaning that the the open subsets form an open cover,\nEach chart \u03c8a is a diffeomorphism that is a smooth map with smooth inverse (in the $C^{k,\\alpha}$ sense),\nAny two charts are $C^{k,\\alpha}$-compatible with each other, that is for all $\\alpha_1$, $\\alpha_2$ \u2208 A, $\\psi_{\\alpha_1}$ \u03bf $\\psi_{\\alpha_2}^{-1}$ : $\\psi_{\\alpha_2} (U_{\\alpha_1} \u2229U_{\\alpha_2}) \\rightarrow \\psi_{\\alpha_1} (U_{\\alpha_1} \u2229 U_{\\alpha_2})$ is $C^{k,\\alpha}$.\nIntuitively, a $C^{k,\\alpha}$ manifold is a generalization of Euclidean space by allowing additional spaces with nontrivial global structures through a collection of charts that are diffeomorphisms mapping open subsets from the manifold to open subsets of euclidean space. For technical utility, the defined charts allow to transfer most familiar real analysis tools to the manifold space. For more references, see [37].\nDefinition A.2 (Riemannian volume form). Let X be a smooth, oriented d-dimensional manifold with Riemannian metric g. A volume form dvolm is the canonical volume form on X if for any point x \u2208 X, for a chosen local coordinate chart $(x_1,...,x_d)$, $dvol_m = \\sqrt{det g_{ij}}dx_1 \\wedge ... \\wedge dx_d$, where\n$g_{ij}(x) := g(x)(\\frac{\\partial}{\\partial x_i},\\frac{\\partial}{\\partial x_j})$.\nThen the induced volume measure by the canonical volume form dvolx is denoted as \u03bc\u03c7, defined by \u00b5x : A\u2192 \u222ba dvolx, for any Borel-measurable subset A on the space X. For more references, see [38].\nWe recall the latent representation problem defined in the main paper.\nConsider the state space $S \\subset R^{d_s}$ and the latent space $Z$. Consider a state probability measure Q on the state space S and a probability measure P on the latent space Z.\nAssumption A.3. (Latent manifold assumption) For a positive integer k, there exists a $d_m$-dimensional $C^{k,\\alpha}$ submanifold $\\mathcal{M}$ (with $C^{k+3,\\alpha}$ boundary) with Riemannian metric g and has positive reach and also isometrically embedded in the state space $S \\subset R^{d_s}$ and $d_m \\ll d_s$, where the state probability measure is supported on. In addition, M is a compact, orientable, connected manifold.\nAssumption A.4. (Smoothness of state probability measure) Q is a probability measure supported on M with its Radon-Nikodym derivative $q \\in C^{k,\\alpha}(\\mathcal{M}, R)$ w.r.t $d\\mu_M$.\nLet Z be a closed ball in $R^{d_m}$, that is $\\{x \\in R^{d_m} : ||x|| \\leq 1 \\}$. P is a probability measure supported on Z with its Radon-Nikodym derivative $p \\in C^{k,\\alpha}(Z, R)$ w.r.t $d\\mu_z$.\nWe consider a real-valued CNN function $f_{CNN}$ : X \u2192 R, as it can be easily extended to the definition in the Rn-valued case. Let fCNN have L hidden layers, represented as:\n$f_{CNN}(x) = A_{L+1} \u03bf A_L \u03bf\u00b7\u00b7\u00b7 \u03bf A_2\u03bf A_1(x), x \u2208 X,$"}, {"title": "B. Explicit Regularization of Latent Representation Error in World Model Learning", "content": "We recall the SDEs for latent dynamics model defined in the main paper. Consider a complete, filtered probability space (\u03a9, F, {$F_t$}$_{t\u2208[0,T]}$, P) where independent standard Brownian motions $B^{enc}$, $B^{pred}$, $B^{seq}$, $B^{dec}$ are defined such that F\u2081 is their augmented filtration, and T \u2208 R as the time length of the task environment. We consider the stochastic dynamics of LDM through the following coupled SDEs after error perturbation:\n$dz_t = (q_{enc}(h_t, s_t) + \\sigma(h_t, s_t)) dt + (\\hat{q}_{enc}(h_t, s_t) + \\hat{\\sigma}(h_t, s_t)) dB^{enc},$\n$dh_t = f(h_t, z_t, \u03c0(h_t, z_t)) dt + f(h_t, z_t, \u03c0(h_t, z_t)) dB^{seq},$\n$d\\tilde{z}_t = p(h_t) dt + p(h_t) dB^{pred},$\n$d\\hat{s}_t = q_{dec}(h_t, \\tilde{z}_t) dt + \\hat{q}_{dec}(h_t, z_t) dB^{dec},$\nwhere \u03c0(h, z) is a policy function as a local maximizer of value function and the stochastic process st is Ft-adapted.\nAs discussed in the main paper, our analysis applies to a common class of world models that uses Gaussian distributions parameterized by neural networks' outputs for z, \u017e, \u0161. Their distributions are not non-Gaussian in general.\nFor example, as z is conditional Gaussian and its mean and variance are random variables which are learned by the encoder from r.v.s s and h as inputs, thus rendering z non-Gaussian. However, z is indeed Gaussian when the inputs are known. Under this conditional Gaussian class of world models, to see that the continuous formulation of latent dynamics model can be interrupted as SDEs, one notices that SDEs with coefficient functions of known inputs are indeed Gaussian, matching to this class of world models. Formally, in the context of z without latent representation error:\nProposition B.1. (Latent states SDE conditioned on inputs is Gaussian)For the latent state process $z_{t\u2208[0,T]}$ without error,\n$dz_t = q_{enc}(h_t, s_t) dt + \\hat{q}_{enc}(h_t, s_t))dB^{enc},$\nwith zero initial value. Given known $h_{t\u2208[0,T]}$ and $s_{t\u2208[0,T]}$, the process $z_t$ is a Gaussian process. Furthermore, for any t \u2208 [0, T], $z_t$ follows a Gaussian distribution with mean $\\mu_t = \\int_0^t q_{enc}(h_s, s_s)ds$ and variance $\\sigma_t^2 = \\int_0^t \\hat{q}_{enc}(h_s, s_s)^2ds$.\nNext, we recall our assumptions from the main text:\nAssumption B.2. The drift coefficient functions qenc, f, p and Idec and the diffusion coefficient functions \u011fenc, p and Idec are bounded and Borel-measurable over the interval [0, T], and of class C\u00b3 with bounded Lipschitz continuous partial derivatives. The initial values zo, ho, \u017eo, \u0161o are square-integrable random variables.\nAssumption B.3. \u03c3 and \u014d are bounded and Borel-measurable and are of class C\u00b3 with bounded Lipschitz continuous partial derivatives over the interval [0, T].\nOne of our main results is the following:\nTheorem B.4. (Explicit Regularization Induced by Zero-Drift Representation Error)Under Assumption B.2 and B.3 and considering a loss function L \u2208 C\u00b2, the explicit effects of the zero-drift error can be marginalized out as follows:\n$\\mathbb{E} L (x) = \\mathbb{E} L(x^+) + \\mathcal{R} + O(\\epsilon^3),$"}, {"title": "C. Error Accumulation During the Inference Phase and its Effects to Value Functions", "content": "Theorem C.1. (Error accumulation due to initial representation error )\nLet \u03b4 := E ||\u03b5|| and $d_\\epsilon$ := Esupt\u2208[0", "T": "ht \u2212 ho ||\u00b2 + || zt \u2212 \\tilde{z"}, 0], "value": "ndxt = 90 (xt", "x": "n"}