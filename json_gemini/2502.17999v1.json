{"title": "GNN-XAR: A Graph Neural Network for Explainable Activity Recognition in Smart Homes", "authors": ["Michele Fiori", "Davide Mor", "Gabriele Civitarese", "Claudio Bettini"], "abstract": "Sensor-based Human Activity Recognition (HAR) in smart home environments is crucial for several applications, especially in the healthcare domain. The majority of the existing approaches leverage deep learning models. While these approaches are effective, the rationale behind their outputs is opaque. Recently, eXplainable Artificial Intelligence (XAI) approaches emerged to provide intuitive explanations to the output of HAR models. To the best of our knowledge, these approaches leverage classic deep models like CNNs or RNNs. Recently, Graph Neural Networks (GNNs) proved to be effective for sensor-based HAR. However, existing approaches are not designed with explainability in mind. In this work, we propose the first explainable Graph Neural Network explicitly designed for smart home HAR. Our results on two public datasets show that this approach provides better explanations than state-of-the-art methods while also slightly improving the recognition rate.", "sections": [{"title": "1 Introduction", "content": "The recognition of Activities of Daily Living (ADLs) in Smart Home environments is a widely studied research topic in the pervasive computing community [7]. Recognizing the daily activities that humans do in their daily life at home (e.g., cooking, watering plants, taking medicines) has several important healthcare applications, including the early detection of cognitive decline [25].\nThe majority of the approaches in the literature are based on deep learning models, mainly due to their effectiveness in reaching high recognition rates [14]. The most common architectures used for ADLs recognition are Convolutional [4] and Recurrent [19] neural networks. However, these approaches may not fully capture the spatiotemporal properties of sensor data. In the literature, Graph Neural Networks (GNNs) have emerged as a promising approach for time series"}, {"title": "2 Related Work", "content": "GNNs have been widely adopted in IoT scenarios, in applications including multi-agent interaction, Human State-dynamic, sensor interconnection, and autonomous vehicles [11]. Considering sensor-based human activity recognition,"}, {"title": "2.1 GNN-based methods for HAR", "content": "GNNs have been widely adopted in IoT scenarios, in applications including multi-agent interaction, Human State-dynamic, sensor interconnection, and autonomous vehicles [11]. Considering sensor-based human activity recognition,\nGNNs have been mainly proposed to recognize activities from mobile/wearable devices [28].\nThe differences between existing work lies in how the graph is constructed from sensor data. For instance, a common solution is to consider each time window as a node with the goal of performing node classification [26,21,23]. Other works consider a node for each sensor, considering a graph classification task [18].\nOnly a few works applied GNNs to ADLs recognition in smart home environments. For example, [27] uses graphs to model sensor dependencies. In that work, a graph is built such that each node represents an environmental sensor, while a directed arc represents the influence of the behavior of one sensor to another one. The arcs of the graph structure and their weights are learned using an attention mechanism. The graph classification task is then considered to perform ADLs classification. The work in [30] is closely related to GNN-XAR since it dynamically constructs each graph from the time window of sensor data, where each node is a sensor event. Differently from our work, the arcs are automatically learned from the network considering spatial and temporal properties at the same time.\nWhile it may be possible to apply XAI techniques on such methods, it would be challenging to obtain meaningful explanations. For instance, considering the work in [27], it may be possible to obtain explanations only about the sensors triggered consecutively, without considering longer temporal relationships. On the other hand, since in [30] the arcs are automatically learned, they are not associated with a specific semantic and hence it would be challenging to explain them."}, {"title": "2.2 XAI methods for Human Activity Recognition", "content": "The first attempts for explainable sensor-based activity recognition considered simple inherently interpretable models [6,5,15,17]. However, such models usually underperform deep learning models that, on the contrary, are more complex to explain.\nA few works proposed XAI methods for deep learning for sensor-based activity recognition [16,20]. However, only a few of them focused on ADLs recognition in smart homes. For instance, DeXAR [4] leverages CNN models and explores the use of various XAI methods for computer vision by converting sensor data into semantic images. Similarly, the work in [10] applies several XAI methods to LSTM-based neural networks. Both works generate explanations in natural language for non-expert users.\nWhile eXplainable Graph Neural Networks have been studied in the general machine learning community [1], this is the first work exploring this combination for sensor-based ADLs recognition in smart homes."}, {"title": "3 GNN-XAR under the hood", "content": "In this work, we consider a smart home environment equipped with binary environmental sensors (e.g., motion sensors, magnetic sensors, pressure sensors). We assume that the smart-home is inhabited only by a single resident, and that sensor events are the result of the interaction of the subject with the environment. We also assume that the same timestamp will never be assigned to two distinct sensor events, hence we consider a total order in the sensor event sequence 1. The goal of GNN-XAR is to provide the most likely activity from time windows of sensor events and, at the same time, to provide an explanation in natural language about the aspects of the input that mostly contributed to the prediction."}, {"title": "3.1 Overall Architecture", "content": "Figure 1 depicts the architecture of GNN-XAR.\nFirst, the stream of environmental sensor data is segmented into fixed size overlapping time windows. Each time window is then processed by the GRAPH CONSTRUCTION module to obtain a graph representation of the window, encoding both spatial and temporal properties with an heuristic-based approach. Each graph is processed by the GNN module for ADLs classification. Then, the EXPLAINER module leverages posthoc XAI methods to obtain the nodes and"}, {"title": "3.2 Graph Construction", "content": "The GRAPH CONSTRUCTION module dynamically constructs a graph $G_w$ starting from a temporal window $w$ of sensor events. GNN-XAR leverages a heuristic-based strategy for graph construction, taking into account spatial and temporal properties (that will be leveraged to generate meaningful explanations).\nLet $w = (E_1, E_2, ..., E_n)$ be a temporal window including $n$ sequential sensor events. An event $E_i$ is associated with the following information:\n- An identifier of the sensor that produced it ($E_{id}$), that encodes the sensor type (magnetic, motion ...) and the position (fridge, sofa...). \n- The event type ON or OFF ($E_{type}$). \n- The timestamp of the event ($E_{ts}$).\nIn our framework, we consider the events differently based on the type of sensor that generated them:\n- The first type of sensor includes sensors whose both activation and deactivation require explicit actions by the user (e.g. opening or closing a cabinet). In this case, we are interested in both the activation and deactivation (i.e. ON and OFF) events. \n- The second type includes sensors that are automatically deactivated after some time, for instance, motion sensors. In this case, we are interested in the ON event and in the duration of the active state of the sensor, computed as the time from the ON event to the OFF event.2\nGiven a window $w$, we denote the corresponding graph with $G_w = (V, A)$, where $V$ is the set of nodes and $A$ is the set of arcs. In GNN-XAR, the set $V$ is created as follows:\n- We add a node $v$ for each event in $w$ (activation or deactivation) generated by the first type of sensor. These are event nodes. \n- We add a node $v$ for every active state of a sensor of the second type. These are state nodes.\nIn our system, each node has the sensor identifier as a feature. As common in deep learning, a (trainable) embedding layer computes an embedding vector"}, {"title": "3.3 Graph Neural Network", "content": "In the following, we describe the steps for graph classification.\nMessage Passing Message passing is a crucial step in GNNs for transmitting information between nodes in a graph. This technique allows nodes to share and update their features based on the features of their neighbors, facilitating the extraction of meaningful patterns and relationships in graph-structured data.\nInformation propagates through the graph in two distinct steps. The first step aggregates and processes all the known information, including event duration and distances between events, to compute the new node features, while the second step has the goal of further spreading this information into the graph. The second step is particularly useful for spreading information to the super nodes.\nMore specifically, in the first iteration, for each node, a message is computed by applying a linear layer to the concatenation of the node embeddings and the arc features. This linear layer reduces the message's dimension to match the original node feature dimension. Subsequently, the aggregate message for each node is computed using a sum aggregation function, and the new node feature is obtained by summing the previous embedding with the aggregated message.\nThe second phase involves a simplified propagation in which only the new node embeddings are considered. Given that less information is processed in this phase, no linear layer is applied. Instead, a sum aggregation function is used directly. The same update function from the first phase is then applied, summing the previous node feature with the aggregated messages to compute the new node feature."}, {"title": "3.4 Explainer", "content": "XAI methods applied on GNNs aim to find the subset of nodes and arc that mostly contributed to a specific prediction. In GNN-XAR, a node is selected for the explanation if the corresponding sensor event/state was important for classifying the activity; an arc is selected if the specific order of sensor events/states was important for classifying the activity.\nGNN-XAR leverages the GNNexplainer [31] method for explanations. Through an optimization method, GNNexplainer derives a subgraph maximizing the mutual information between the GNN's prediction and the prediction that would have been obtained by the GNN based only on this subgraph. This is achieved by perturbing the graph and its features, and observing the effect of these perturbations on the GNN's predictions. Given the most likely ADL predicted by the GNN, the input graph and the GNN model, GNNexplainer computes importance values for nodes and arcs. The algorithm leverages gradient descent to"}, {"title": "3.5 Generating explanations in natural language", "content": "As a final step, GNN-XAR converts $G^*$ into a natural language explanation for non-expert users.\nGiven the set of most important arcs $A^*$, we compute the longest path. We then use a heuristic-based approach similar to the one proposed in [4] to generate from this path a natural language explanation. For instance, the continuous activation of certain sensors implies that the resident has moved toward the sensor multiple times: in this case, in the path explanation, the expression \u201cmultiple times\" is added:\n\"I predicted preparing a meal mainly due to the following observations: Bob was near the fridge, then he opened the fridge multiple times\""}, {"title": "4 Experimental Evaluation", "content": "Two datasets have been used to evaluate the model proposed in this work. They are CASAS Milan [9] and CASAS Aruba [8]."}, {"title": "4.1 Datasets", "content": "Two datasets have been used to evaluate the model proposed in this work. They are CASAS Milan [9] and CASAS Aruba [8]."}, {"title": "4.2 Implementation details", "content": "We implemented GNN-XAR using Python 3.10.5, using Pytorch and Pytorch Geometrics for the models and the explainer. Other libraries used include Scikit-learn for the evaluation, Networkx for graph visualization, and Pandas and Numpy for data processing."}, {"title": "4.3 Evaluation", "content": "We decided to focus our comparison of GNN-XAR only with state-of-the-art explainable ADL recognition methods, selecting the one that demonstrated the highest recognition accuracy in the literature. For this reason, we chose DeXAR [4] as a baseline, since it is the method that meets these criteria. DeXAR converts sensor data into semantic images, leveraging \u03a7\u0391\u0399 methods for computer vision to generate natural language explanations. Since GNN-XAR uses a posthoc explanation method, we compare DeXAR when used with LIME [24].\nThe original DeXAR implementation also considered previously predicted ADLs as input, while this aspect is not captured by GNN-XAR. Hence, we implemented a version of DeXAR not considering past activities.\nWe consider a standard 70%-20%-10% split to partition the datasets into training, test and validation sets. The models have been trained using the early stopping strategy with a patience of 50 epochs, the Adam optimizer with a learning rate of 0.0001, and a CrossEntropy loss function."}, {"title": "4.4 Evaluation Metrics", "content": "We use the standard metrics for precision, recall, and F1 score to assess the recognition rate of GNN-XAR. These metrics provide a comprehensive understanding of the model's performance from different perspectives.\nHowever, evaluating the effectiveness of explanations is more challenging. A standard way adopted in the literature involves user surveys [4,10,16]. However, such method is time and money-consuming. We leverage a recent work proposing LLMs to automatically compare alternative XAI methods, since it proved to be aligned with user surveys [13]. Specifically, we provide to an LLM the explanations generated by GNN-XAR and DeXAR on the same window, asking the LLM to choose the best one (using the prompt proposed in [13])."}, {"title": "4.5 Results", "content": "Classification results Tables 1 and 2 compare GNN-XAR and DeXAR considering the F1 score for each class. We observe that our approach achieves slightly better recognition rates in the overall F1 score for both datasets. By observing the confusion matrices in Figure 9 and 10, both models struggle to distinguish activities taking place in the same room, like Bathroom and Dress Undress.\nConsidering the CASAS Milan dataset, this is likely due to the fact that the wardrobe is located in the master bedroom near the bathroom entrance. To distinguish between these two activities, it is probably necessary to consider additional context information, such as past activities and time. Another remarkable difference between the two models is the higher f1 score of GNN-XAR on Leave Home (see table 1). In fact, this ADL strongly depends the temporal order of sensor events, that is better captured by our GNN model.\nConsidering the CASAS Aruba dataset, the GNN model performs better than DeXAR for almost all the activities. The main difference with respect to the results obtained in CASAS Milan is that two activities are completely misclassified by both GNN-XAR and DeXAR: washing dishes and housekeeping. These two activities are the least represented in the dataset. Wash dishes is always confused with meal preparation. Similarly to CASAS Milan, the activities that benefit more from the GNN model are entering home and leaving home.\nAs we previously mentioned, we leverage an LLM-based approach to compare GNN-XAR and DeXAR. However, due to the costs of LLM-based APIs requests, we sampled 30 random windows for each activity."}, {"title": "5 Conclusion and Future Work", "content": "In this paper we presented GNN-XAR, an explainable Graph Neural Network framework for ADLs recognition in smart home environments. Our results suggest that GNN-XAR generates effective explanations by leveraging the structural properties of the graph representation. While the results are promising, this work"}]}