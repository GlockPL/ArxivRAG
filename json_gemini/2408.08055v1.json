{"title": "COTODE: COntinuous Trajectory neural Ordinary Differential Equations for modelling event sequences", "authors": ["Ilya Kuleshov", "Galina Boeva", "Vladislav Zhuzhel", "Evgenia Romanenkova", "Evgeni Vorsin", "Alexey Zaytsev"], "abstract": "Observation of the underlying actors that generate event sequences reveals that they often evolve continuously. Most modern methods, however, tend to model such processes through at most piecewise-continuous trajectories. To address this, we adopt a way of viewing events not as standalone phenomena but instead as observations of a Gaussian Process, which in turn governs the actor's dynamics. We propose integrating these obtained dynamics, resulting in a continuous-trajectory modification of the widely successful Neural ODE model. Through Gaussian Process theory, we were able to evaluate the uncertainty in an actor's representation, which arises from not observing them between events. This estimate led us to develop a novel, theoretically backed negative feedback mechanism. Empirical studies indicate that our model with Gaussian process interpolation and negative feedback achieves state-of-the-art performance, with improvements up to 20% AUROC against similar architectures.", "sections": [{"title": "1 INTRODUCTION", "content": "Sequences of events are integral to numerous fields of modern life. Examples of such data include bank transactions [4], patients' medical histories [20], various sales datasets [9], earthquake records [29], and more. One of its most critical characteristics is an uneven structure, which often necessitates complex modifications to the processing algorithm.\nThere are many existing methods for analysing event sequences. Traditional approaches model hidden data dynamics as a probabilistic process with certain constraints, e.g., Poisson [18] or Hawkes processes [16]. More advanced methods propose applying recurrent neural networks [14, 25] or transformers, often in combination with point processes [48]. Alternatively, recent research explores the use of ordinary differential equations (ODE) to process sequential data [10, 19, 21]."}, {"title": "2 RELATED WORKS", "content": "The study of event sequences has a long history, with roots in Temporal Point Processes (TPP) [16, 27]. Recently, this field has undergone significant changes due to the rapid development of Neural Network (NN) approaches. Below, we present a brief overview of relevant papers which inspired our research. The review starts by examining the leading works on this subject. Next, we analyse prior studies that applied Neural ODEs to event sequences. Here, to emphasise our paper's focus, we note the form of the hidden trajectory for each relevant ODE paper. The final part addresses the error estimates for Gaussian process regression, essential to our theoretical results."}, {"title": "3 METHODS", "content": "In this section, we lay out the methods we propose in our work, as well as the theoretic background behind them."}, {"title": "3.1 COTODE pipeline", "content": "Our goal is to provide a representation h(t) in response to an input event sequence {ck, tk}=1, suitable for solving downstream problems. By {tk}=1 \u2282 [0;T] we denote the timestamps of the input events, while {ck}=1 denotes the types of these events.\nTo achieve this goal, we use a three-part pipeline, traditional for event sequences [3, 5]. The first layer is the Embedder, responsible for converting categorical features {ck}k into vectors {xk}k using a learnable dictionary. Next, the Backbone runs on these vectors, returning a single embedding per sequence h(T). Finally, a linear head on top of the final hidden state h(T) transforms it into the prediction \u0177. The pseudocode for this approach is provided in Algorithm 1, complemented with an illustration in Figure 3.\nOur backbone of choice is a Neural ODE-based architecture. It requires a function x(t) : [0;T] \u2192 Rd, instead of a sequence {xk}k. Here d is the dimensionality of the input embedding. The main contribution of this paper is an approach based on Gaussian processes interpolation that provides this continuous trajectory x(t), for any given t\u2208 [0, T]. It exhibits superior quality, as confirmed by both experimental and theoretical studies.\nThen, the Neural ODE layer uses the Gated Recurrent Unit (GRU) [11] function as its dynamics. Given xt, it produces the trajectory h(t) that concludes with h(T). Negating h here leads to greater numerical stability of the proposed approach, being a crucial part of our methodology."}, {"title": "3.2 Neural ODE overview", "content": "The Neural ODE layer was first proposed by [10]. It propagates the hidden state by solving a Cauchy problem from a fixed starting point. The learnable parameters adjust the dynamics function's behaviour within this problem. At first, the input data was used purely to alter the starting point.\nSubsequent works, such as Neural CDEs [21], proposed to add a dependency on the input data interpolation function x(t) into the dynamics. We also follow this approach. Our method can formally be written as a Cauchy problem $Ca(h_0, f_\\theta, x(t))$:\nDynamics: $\\begin{cases}h(0) = h_0;\\\\\\frac{dh(t)}{dt} = f_\\theta(h(t), x(t), t).\\end{cases}$\nSolution: $h(t) : [0, T] \\rightarrow R^d$.\nHere, ho is a predefined starting point, fe is a neural network, which defines the dynamics for t \u2208 [0, \u03a4]. As mentioned above, since we are working with time series, the input is fed to the dynamics as an interpolation function of the input data x(t), instead of being encoded into ho as is the case for Neural ODE methods on tabular data. As a result of integrating these dynamics, we obtain our target h(T) - the hidden state at the final timestamp T."}, {"title": "3.3 Interpolation of the hidden trajectory", "content": "We note that to continuously model the hidden trajectory, it is necessary to define the influence that events have on it in the gaps between them. The Neural CDE method [21] processes the input data as-is. Since direct usage of categorical features as inputs makes no sense, we first embed all such features into learnable vectors and then apply the proposed interpolation approach.\nBelow, we provide a Gaussian Process-based model for the data interpolation function x(t). Taking advantage of the theory behind this method, we can devise error bounds for the final hidden state."}, {"title": "3.3.1 Practical aspects of Gaussian Processes.", "content": "Here, we will discuss the basic theory behind this approach, which we will use in practice.\nLet x(t) be a stationary zero-mean d-dimensional Gaussian process (GP) with the covariance function K(, ) = {Ki(, )} and independent components:\n$E x(t) = 0; E [x(t_1) x(t_2)] = K(t_1, t_2) = K(t_2-t_1),$  (2)\nwhere the symbol is used to denote component-wise multiplication.\nSuppose we also know the values of said process at timestamps {t1,..., tn} C [0, T], and we wish to build a linear prediction x(t):\n$x(t_i) = x_i, i = 1, ...,n \\Rightarrow \\hat{x}(t) = \\sum_{i=1}^n a_i x_i.$ (3)\nThe choice of the coefficients a = {ai}=1 is guided by the minimization of the mean squared error \u03c3\u00b2:\n$\\sigma^2(t) \\triangleq E||x(t) - \\hat{x}(t)||^2.$ (4)\nIn our experiments, when calculating x(t), we use a well-known result [7], which corresponds to the maximum a posteriori estimation:\n$a = K^{-1}k,$ (5)\nwhere K is the covariance matrix, k is the covariance vector, and K(t) is a standard squared exponential covariance function, identical over all dimensions (a is a hyperparameter, we refer to as scale):\n$K(t) = (e^{-at^2},..., e^{-at^2}).$ (6)\nWe set a = 1 in most cases; further details on tuning it may be found in Appendix C."}, {"title": "3.3.2 Gaussian Process error estimation.", "content": "Plan. We do not observe the client in-between events, which means that x is only our most probable estimate. GP interpolation is a well-studied, theory-backed method, which allows us to quantify the uncertainty of estimating y. This uncertainty is then accumulated in the hidden state due to integration, and our aim in this section is to assess the impact this has on h(T). Our main result may be informally written as follows:\nTHEOREM. (informal) The estimation error of the final hidden state h(T) follows the asymptotic:\n$E \\int_0^T || \\frac{d}{dt} \\hat{h}(t) - \\frac{d}{dt} h^*(t)||^2 dt \\le (n - 1) d_{\\text{max}},$   (7)\nwhere dmin, dmax are the length of the minimum and maximum inter-vals between events, and n - 1 is the total number of these intervals,h* (t) is the trajectory that corresponds to the true x.\nThis would imply that without additional regularization, the error grows approximately linearly with time as we observe more events. Below, we provide the formal statements with their proofs.\nError definition. First, let us define the total integral error:\n$\\sigma_{\\text{ALL}}^2 = \\int_0^T E||x(t) - \\hat{x}(t)||^2 dt.$ (7)"}, {"title": "Uniform theoretic bounds.", "content": "The form of the estimator given by (5) is useless when it comes to establishing the bounds for (7): it is tough to deal with the inverse form of K. This forces us to approach the problem from a different angle, following existing results on estimating the GP regression error [45]. To use these prior results, we have to consider a more convenient intermediate form of the error, integrated between two events:\n$\\sigma_{\\text{INT(k)}}^2 = \\int_{t_k}^{t_{k+1}} E||x(t) - \\hat{x}(t)||^2 dt.$ (8)\nAssumption and their effect on the error. We first devise error bounds for a uniform sequence and generalize them later to our irregular case. Formally, we make two common assumptions, which, as will be explained below, do not reduce the applicability of the devised results:\nASSUMPTION 1. The data lies on a regular grid with a step size d > 0: tk = to + kd, k = 1, ..., n.\nASSUMPTION 2. The input sequence is infinite:\nk = \u221e, ..., -2, -1, 0, 1, 2, ..., +\u221e.\nAssumption 1 can be made without loss of generality. The error for a uniform grid can be extended to the case of irregular event sequences using the following lemma.\nLEMMA 3.1. Let S = {(xk, tk)}x=1 be a given irregular event sequence. We construct an alternative event sequence S = {(xk, tk)}=1', with the interval [m; m + 1] changed by r, for some fixed 1 < m <k andre R:\n$t_k' = t_k, k \\le m;$\n$t_k' = t_k + r, k > m;$\n$\\hat{t_k} = t_k + I[t_k > t_{m+1}]r.$\nHere I denotes the indicator function. Then, the errors (8) for the original S and modified \u00a7 sequences (o\u00b2 and \u00f5\u00b2 respectively) relate as follows:\n$\\sigma^2(t) \\le \\tilde{\\sigma}^2(t) \\text{ for } r > 0,$\n$\\sigma^2(t) \\ge \\tilde{\\sigma}^2(t) \\text{ for } r < 0.$\nThis lemma allows us to extend our results to irregular sequences without loss of generality. It is evident if one considers the problem from the perspective of probability theory. The respective covariance determines the amount of information each observation provides about the unknown value. If all covariances decrease, the variance of x will clearly increase and vice versa. As a corollary, the transition to a uniform sequence with the largest time interval as the step dmax may only increase the error, and with the smallest dmin - decrease, so any upper or lower bounds we prove in the regular case will still be valid (for extreme step sizes).\nAs for Assumption 2, the authors of [45] demonstrated that these results empirically hold for finite sequences. Indeed, since a typical kernel decays with an exponential speed, distant observations have a negligible impact on the resulting error.\nTogether, these assumptions may be formally written as follows:\ntk = kd; \u2200k \u2208 Z.\nError bound for the optimal estimator. The optimal estimator for a uniform infinite grid is well-known [22], and is much simpler than (5):\n$\\hat{x}(t) = \\sum_{k=-\\infty}^{\\infty} K(t - k\\delta)x(k\\delta).$ (10)\nThis form allows us to deduce analytical error bounds. For this purpose, we generalize the results from [45] to multiple dimensions. This is given by the following Lemma.\nLEMMA 3.2. (proof in Appendix A) Let F(w) denote the spectral density of Gaussian process from (2):\n$F(\\omega) = \\int_{-\\infty}^{\\infty} exp(2\\pi i \\omega t)K(t)dt.$\nIn this notation, under Assumptions 1,2 the following holds:\n$E||x(t) - \\hat{x}(t)||^2 = \\delta \\int_{-\\infty}^{\\infty} F(\\omega) \\Big[1 - \\sum_{k\\neq0} e^{2\\pi i\\omega (t - t_k)} \\Big] dw.$\nWith Lemma 3.2, all other results can be taken directly from [45], taking into account that x(t) is d-dimensional. We recount select findings from this paper: the general error form, an analytic error expression for a specific kernel analogous to (6), and the minimax error bound.\nTHEOREM 3.3. The error (8) may be written in the following form:\n$\\sigma_{INT}^2 = a\\delta \\int_{-\\infty}^{\\infty} F(\\omega) \\Big[ (1 - K(\\omega))^2 + \\sum_{k=-\\infty}^{\\infty} K(\\omega + \\frac{k}{\\delta}) \\Big] dw.$ (11)\nNote that the error (11) does not depend on the interval number. This is due to the inherent symmetry of an infinite uniform grid: all intervals are the same in terms of the covariance function.\nASSUMPTION 3. The covariance function is the same over all di-mensions and corresponds to the squared exponential function:\n$K(t) = \\sqrt{2 \\pi} e^{-2(a \\pi t)^2}.$\nCOROLLARY 3.4. Under the Assumptions 1-3, the error (11) can be bounded analytically:\n$\\sigma_{INT}^2 \\le d \\cdot .782\\delta a\\ \\alpha exp\\Big(-\\frac{1}{8(\\delta a)^2}\\Big) \\triangleq D_{max}(\\delta), \\text{ for } (\\delta a \\rightarrow 0),$\n$\\sigma_{INT}^2 \\ge d \\cdot a exp\\Big(-\\frac{1}{8(\\delta a)^2}\\Big) \\triangleq D_{min}(\\delta).$\nError bound for the optimal estimator in the minimax case. On the other hand, we may also use a more general approach to determining the covariance function K, independent of the specific kernel, since it may be unknown or may vary between dimensions. It leads us to the following Assumption:\nASSUMPTION 4. All the spectral densities of K belong to the following class of functions:\n$F(\\mathcal{L}) = \\Big\\{ F: E \\Big| \\frac{d x(t)}{dt} \\Big|^2 < L \\Big\\}.$ (13)\nThen, we can generalize results from [45] for the multivariate case."}, {"title": "THEOREM 3.5.", "content": "In the above notation, under the Assumptions 1,2,4, the minimax GP interpolation error may be calculated analytically:\n$R_h(L) = inf_\\ast sup_{F \\in F(L)} \\sigma_{INT}^2 = \\frac{L \\delta^2 d}{2\\pi^2} \\triangleq D_1(\\delta).$ (14)\nFinally, combining Lemma 3.1 with Corollary 3.4 or Theorem 3.5 (depending on assumptions about K) and transitioning to the finite irregular case with n \u2212 1 intervals (with dmin for Dmin and dmax for Dmax), we achieve the following inequalities for the upper bound of the total error:\n$\\sigma_{ALL}^2 \\in [(n - 1) D_{min}, (n - 1) D_{max}]$ (under Assumption 3),\n$\\sigma_{ALL}^2 \\in [(n - 1) D_{min}, (n - 1) D_1]$ (under Assumption 4). (15)\nNeural ODE Error. Now, we can apply the above findings to our task. Let us consider two variants of the Cauchy problem (1): one with a \"true\" signal x(t), and the other with a signal, reconstructed from observations via GP interpolation x(t). We will denote their hidden trajectories as h* (t), h(t) respectively. Then, the difference between the resulting hidden states, accumulated during integra-tion, is written as:\n$E \\int_0^T || \\frac{dh^*}{dt} - \\frac{dh}{dt} ||^2 dt =$\n$\\int_0^T E || f_\\theta(x, h^*, t) - f_\\theta(x, h, t)||^2 dt.$ (16)\nTo bound this error, it is necessary to restrict the class of func-tions fe.\nASSUMPTION 5. Let the functions fo be confined to linear bi-Lipshitz functions of x with parameters being a matrix Wx:\nf(x) = Wxx; 0 < Amin (Wx) < Amax (Wx), (17)\nwhere Amin, Amax are the minimal and the maximal eigenvalues of Wx.\nNote that we also removed the dependence on t: this can be done without additional limitations by concatenating t to x. Altogether, this allows us to deduce the following:\nTHEOREM 3.6. (proof in Appendix A) Consider the task (1) under Assumption 5. Then, the following holds:\n(1) If the covariance function has the form from Assumption 3, the interpolation error from (16) adheres to the following bound:\n(n \u2212 1)dmin(Wx)Dmin \u2264 n \u2264 (n \u2212 1)dmax(Wx)Dmax.\n(2) Otherwise, if the covariance function satisfies Assumption 4, the corresponding minimax interpolation error can be calculated directly:\n(n \u2212 1)dmin(Wx)Dmin \u2264 r \u2264 (n \u2212 1)dmax(Wx)Dmax.\nBesides, both of the above upper-bounds are also true for the differ-ence between the final hidden states:\n$||h(T) - h^*(T)||^2 \\le \\sigma_1 \\le (n \u2212 1)d_{max}(W_x) \\{D_{max}, D_1 \\}$\nUsing this approach, we are able to quantify the uncertainty from not knowing what happens in-between events, accumulated in the final hidden state."}, {"title": "3.4 GRU Negative feedback", "content": "The error bound from Theorem 3.6 leads to disappointing conclusions: the error grows linearly with sequence length. This corresponds to the exploding gradients problem, well-studied for discrete sequential models [17], and we propose solving it in the continuous case with a negative feedback procedure."}, {"title": "3.4.1 Theoretical consideration.", "content": "First, we will discuss the theoret-ical benefits of this procedure. Consider the following scenario: two trajectories h(t), h* (t) have the same dynamics, but distinct starting states ho \u2260 h at timestamp t = 0. This is meant to imitate the difference between the true and the estimated trajectory: the estimated trajectory accumulated errors during its evolution un-til t = 0 but adhered to the correct dynamics afterwards. Formally, this is described by a simple ODE on the interval [0, T]:\n$\\frac{dh}{dt} = W_h h;\\frac{dh^*}{dt} = W_h h^*,$ (18)\nwhere Wh is the parameter matrix. If Wh is negative-definite, the difference between those states, according to the matrix ODE theory, will decrease exponentially.\nLEMMA 3.7. (proof in Appendix A) Let ho \u2260 ho be two non-equal starting points for two Cauchy problems Ca(ho, Whh) and Ca(h, Whh*). For the negative-definite matrix Wh < 0 with eigen-values i < 0 for some constants Ci the following holds:\n$||h(T) \u2013 h*(T)|| \\le \\sum_i C_i e^{-|\\lambda_i|T}$ (19)"}, {"title": "3.4.2 Negative Feedback in practice.", "content": "The aforementioned problem of the linearly growing error arises from the additive nature of differential equations. The empirical solvers we use share this nature, and as such, this issue also manifests itself in our study's experimental results.\nAs a consequence of the above theory, it is beneficial to enforce the weight matrix, which corresponds to h, to be negative-definite. In practice, prior works have solved this by forcing the derivative to point toward decreasing the hidden state. For example, the authors of [12] simply subtract the hidden state from the derivative. Indeed, for a matrix of limited spectral norm (as is often the case due to L2 regularization), this results in the following modification:\n$W_h' = W_h - I \\Rightarrow \\lambda_{max}(W_h') = \\lambda_{max}(W_h) - 1 \\le 0.$\nWe developed a more holistic solution inspired by the GRU archi-tecture [11]:\nr = \u03c3(Wirx + br + Whrh + bhr), (20)\nz = \u03c3(Wizx + biz + Whzh + bhz), (21)\nn = tanh(Winx + bin + r (Wnhh + bnh)), (22)\nh = (1 \u2212z) \u00a9 n + z \u00a9 h. (23)\nWe noticed that by negating the second term in (23), since z is positive, one can achieve, in essence, a learnable negative feedback effect.\nMoreover, this can be done without modifying the GRU architec-ture by simply negating h before passing it to this layer. This way, the terms that contain h in (20), (21), (22) will simply need to learn a negative version of the weights, which makes this equivalent to the proposed architecture modifications. All in all, this allows us to"}, {"title": "4 EXPERIMENTS", "content": "In this section, we provide our empirical results, demonstrating the superiority of the proposed models in practice. To this end, we first outline the experiment settings (our datasets and the models we compare), followed by the results and the corresponding discussion."}, {"title": "4.1 Data", "content": "The datasets in question have one label per sequence, summarising it in one way or another. Four out of six of our datasets are transactional, mostly because they are abundant, similar in format and thus easy to work with. A transaction consists of a continuous amount feature, a categorical MCC-code feature (transaction type, e.g., ATM deposit/withdrawal, payment at retail clothing, etc.), and a times-tamp. All transactions are grouped by bank clients. Consequently, these datasets differ only in their target labels.\n\u2022 The Age dataset [32] has the client's age as its label. It is grouped into four bins for convenience.\n\u2022 The Churn dataset [30] poses the binary classification task, with the positive label indicating the client will leave the bank.\n\u2022 The HSBC competition [28] poses the fraud identification task, with one label per transaction. For consistency with other tasks, we defined a clientwise label, indicating whether any of a client's transactions were fraudulent.\n\u2022 The Gender dataset [33] poses the task of binary classification, with the client's gender as its label.\nBesides, we also used two non-transactional datasets to demonstrate the wide applicability of our method. They required some specific data preprocessing, described in Appendix B.\n\u2022 The WISDM Human Activity Classification dataset [40] contains records of various human activities. The features here are the coordinates and accelerations of two devices: a phone and a watch. The label corresponds to one of 18 possible activities.\n\u2022 The Retail dataset [9] has records of online retail purchases from a UK-based and registered store.\nIn all the datasets except for Retail and Gender, we only considered sequences longer than 32 but shorter than 800. For the remaining two, we allowed sequences as short as 16 elements for the Retail dataset and as short as four elements for the Gender dataset.\nAs all our datasets have a multiclass classification target, we use class-weighted ROC AUC and micro-averaged accuracy as the quality metrics."}, {"title": "4.2 Models", "content": "In our empirical study, we compared the performance of six models. The considered models are all, in essence, some modification of the GRU architecture [11], including the raw GRU model itself. We have two reasons for focusing on recurrent architectures instead of transformers: there is a lack of research on their continuous implementations and they are shown to be inferior in empirical comparative studies [5, 47].\nBelow is a list of the considered models with brief descriptions, ordered in increasing complexity.\n\u2022 RNN [11]: the vanilla GRU architecture;\n\u2022 RNN Decay [23]: the architecture, which decays the hidden state exponentially in between events;\n\u2022 RNN ODE [31]: the architecture that models inter-event dynamics via an ODE and induces jumps at times of events using an RNN.\n\u2022 COTODE: the proposed GP-based method, along with two alternative ablation study approaches with differing inter-polation regimes.\nGP: the Gaussian Process-based regime, our method;\nLast: interpolation using the last seen embedding, ab-lation study variation;\nDecay: exponentially decaying sum of prior events, ablation study variation.\nThe categorical features are encoded into learnable embeddings for all considered models and then concatenated with numerical features. Notably, we also appended the time since the last trans-action to this vector. This evens the playing field for the raw RNN model, allowing it to take irregularity into account."}, {"title": "5 CONCLUSIONS", "content": "In this article, we present a fresh perspective on the task of analysing event sequences. By considering the influence of events in the intervals between them, we gain the ability to work with these sequences in a manner akin to continuous time series. Inspired by this insight, we propose a corresponding modification to the Neural ODE model: we interpolate the input data sequence via Gaussian Processes, achieving an uninterrupted influence on the dynamics. This method outperforms all previously considered methods on sufficiently long sequences by up to 20% ROC-AUC.\nMoreover, our primary theoretical contribution lies in defining error bounds for the proposed modification, establishing the uncer-tainty arising from clients' unknown actions between events. These obtained estimates allow us to reveal a fundamental flaw within these methods: the error increases linearly over time. We demon-strate that this issue can be theoretically addressed using negative feedback. To this end, we also develop an elegant zero-cost solution, which represents a sufficiently novel and modern challenge in this field and limits the growth of error in practice."}]}