{"title": "Heterogeneous Interaction Modeling With Reduced Accumulated Error for Multi-Agent Trajectory Prediction", "authors": ["Siyuan Chen", "Jiahai Wang"], "abstract": "Dynamical complex systems composed of interactive heterogeneous agents are prevalent in the world, including urban traffic systems and social networks. Modeling the interactions among agents is the key to understanding and predicting the dynamics of the complex system, e.g., predicting the trajectories of traffic participants in the city. Compared with interaction modeling in homogeneous systems such as pedestrians in a crowded scene, heterogeneous interaction modeling is less explored. Worse still, the error accumulation problem becomes more severe since the interactions are more complex. To tackle the two problems, this paper proposes heterogeneous interaction modeling with reduced accumulated error for multi-agent trajectory prediction. Based on the historical trajectories, our method infers the dynamic interaction graphs among agents, featured by directed interacting relations and interacting effects. A heterogeneous attention mechanism is defined on the interaction graphs for aggregating the influence from heterogeneous neighbors to the target agent. To alleviate the error accumulation problem, this paper analyzes the error sources from the spatial and temporal perspectives, and proposes to introduce the graph entropy and the mixup training strategy for reducing the two types of errors respectively. Our method is examined on three real-world datasets containing heterogeneous agents, and the experimental results validate the superiority of our method.", "sections": [{"title": "I. INTRODUCTION", "content": "ANY real-world complex systems, including social networks and urban traffic systems, can be regarded as dynamical systems composed of heterogeneous interacting agents. Different types of agents present various intrinsic behavior patterns, and the dynamic interactions among agents are even more complex, leading to complicated dynamics at both the individual level and the system level. Understanding the interactions among heterogeneous agents can help us predict and control the behavior of a system [1]\u2013[3]. A typical application is trajectory prediction, which is a fundamental task in autonomous driving and mobile robot navigation.\nCompared with homogeneous systems, the main difficulty of heterogeneous multi-agent trajectory prediction lies in the"}, {"title": "II. RELATED WORKS", "content": "A. Interaction Modeling in Multi-Agent Trajectory Prediction\nTraffic participants, like pedestrians and vehicles, interact with others in the surroundings and adjust their trajectories towards the destinations. The interaction is complex itself, and evolves over time, leading to the complicated trajectories of multiple traffic participants. Interacting modeling for multi-agent systems generally includes interaction graph construction and information aggregation over the graph. The techniques differ in homogeneous and heterogeneous systems.\nIn homogeneous systems, grids [7], complete graphs [15], [16], distance based graphs [8], [9] were used as pre-defined interaction graphs. Since complete graphs and distance-based graphs contain superfluous edges and fail to model directed effects, some works [10], [11], [17] proposed to learn asymmetric latent graphs. Given the interaction graphs, social pooling [7], spatio-temporal graph convolutions, spatio-temporal graph attention [8], [15] were introduced to aggregate the interacting effects. Prior knowledge like sparsity [10] and obstacle avoidance [16] were used for attention computation.\nIn the heterogeneous systems, the interaction graphs can be extended to heterogeneous graphs with different types of nodes and edges. The edge types can be pre-defined as the concatenation of node types [4], [18], e.g., \u201cPedestrian-Bus\u201d, or learned by the model from observational data [5]. Relative position, velocity, and heading angle can be further incorporated as edge features [19], [20].\nGiven the heterogeneous interaction graphs, node type aware modules were used for trajectory encoding, type-specific supernodes were used to share information among agents of the same type [21], [22], and edge type aware modules were used for modeling interacting effects, which are aggregated to predict future states [4], [18]. However, there are some drawbacks of edge type aware aggregations. When the edge type is defined by concatenating node types [4], [18], the number of edge type aware modules grows quadratically, which can be a redundant design. When the edge type is learned by the model [5], the number of edge types is hard to decide in practice. Besides, some works [18], [21] limited"}, {"title": "B. Heterogeneous Graph Neural Networks", "content": "Graphs with more than one type of nodes or edges, termed as heterogeneous graphs or heterogeneous information networks [23], [24], widely exist in the world, such as social networks, knowledge graphs and proteins. GNNs developed for this form of data are called heterogeneous graph neural networks. The message passing mechanisms of homogeneous GNNs [25] were substantially extended by introducing category-aware modules for different types of nodes [26], edges [27] and their compositions, meta-paths [28]. Representative works include relation type aware aggregators [27], heterogeneous graph transformer [29], hierarchical aggregators defined over node types [26] and hierarchical attention defined over both node-level and semantic-level [28].\nDespite the great success of heterogeneous graph neural networks in heterogeneous graphs, these methods are not applicable to heterogeneous multi-agent trajectory prediction. The key difference is that there are no natural well-defined relations between two agents. Even when the categories of the agents and the relative position between them are known, the interactions can be variable. Besides, these methods are not designed to integrate possible edge features. Our method can infer the relations between agents and model their interactions over an edge-featured graph."}, {"title": "C. Learning Graphs from Data", "content": "Graphs provide a structured representation of data. When the graph representation is not readily available, researchers seeked to learn it from observational data [30], with application to multi-variate time series forecasting [31] and reasoning over physical systems [17]. Edge directions [17], [31], edge types [17], and co-existence of edges [32] were considered for graph learning. The learning is often guided by a task-specific objective, while the complexity of the graph is not explicitly controlled. Sparsity [17] is an intuitive choice to penalize the graph complexity. However, a simpler graph is not necessarily sparser, and a sparser graph may not necessarily lead to better performance. Instead, this paper introduces another metric, the graph entropy, to reduce the graph complexity, which helps reduce the prediction error."}, {"title": "III. METHOD: HIMRAE", "content": "A. Problem Definition\nIn an N-agent heterogeneous dynamical system, each agent i belongs to a category c\u2081 out of C categories. The number of agents may vary case by case. The 2D coordinate of agent i at time t is recorded as $x_i^t = (x_i^t, y_i^t)$. Let Th and Tf denote the number of historical steps and future steps, respectively. The problem of trajectory prediction is that, given the historical trajectories of all agents $X_{1:T_h} = \\{x_{1:T_h}^i\\}_{i=1}^N$, predict their future trajectories $X_{T_h+1:T_h+T_f}$ that best match the ground truth trajectories $X_{T_h+1:T_h+T_f}$."}, {"title": "B. Hypotheses, Motivation and Overview of HIMRAE", "content": "The trajectory of each agent is affected by the agents it interacts with, and the interactions vary over time. The interactions among agents at time t can be abstracted as a directed graph $G_t = (V,E_t)$, with each agent $i \\in V$ as a node and the interacting relation from agent i to agent j as an directed edge $(i, j) \\in E_t$. Generally, the underlying interaction graphs are unobservable, but they can be inferred from the historical trajectories and used for future trajectory prediction.\nThis paper hypothesizes that the interacting relations among agents within a small time window are relatively stable. Therefore, a 0-parameterized distribution of the full trajectories can be factorized as\n$p_\\theta(X_{1:T_h+T_f}) = p_\\theta(X_{1:\\tau}) \\prod_{m=1}^M p_\\theta(X_{1+m\\tau:(m+1)\\tau} | X_{1:m\\tau}) \\times p_\\theta(X_{1+M\\tau:T_h+T_f} | X_{1:M\\tau}),$ (1)\nwhere \u03c4 is the window size, and $M = [(T_h + T_f)/\u03c4]$ is the maximum number of the time windows.  An appropriate \u03c4 may be related to the number of agents N, since the interactions change more frequently when N is large.  Nonetheless, \u03c4 is assumed to be case agnostic in this paper for simplicity, and a more sophisticated design is left for future work.\nTo motivate the design of the interaction graph, the authors observe that: in practice, one has little prior knowledge about the semantics of the interaction between two agents, e.g., the type of the interaction and its effect, even when the agent types and their relative position are known.  Therefore, this paper seeks to infer the existence of interactions and a hidden state that implicitly encodes the interacting effects.  Formally, given the trajectories in the previous time window, one can infer the interacting relations and interacting effects among agents, which lead to the following factorization,\n$p_\\theta(X_{1+m\\tau:(m+1)\\tau} | X_{1:m\\tau}) = \\int p_\\theta(X_{1+m\\tau:(m+1)\\tau} | X_{1:m\\tau}, Z_m, E_m) \\times p_\\theta(Z_m, E_m | X_{1:m\\tau}) dZ_m dE_m,$ (2)\nwhere Zm and Em are the interacting relations and interacting effects in the m-th time window, respectively. $Z_m \\in \\{0, 1\\}^{N \\times N}$ is a zero-diagonal binary matrix with $z_{ij}^m$ indicating an directed edge $(i, j)$. $E_m \\in \\mathbb{R}^{N \\times N \\times D}$ is a real-valued tensor with $e_{ij}^m$ representing the impact of agent i on agent j. Regarding Em as the edge features, Zm and Em jointly define an edge-featured interaction graph.\nDirectly evaluating $p_\\theta(Z_m, E_m | X_{1:m\\tau})$ is intractable [33], therefore, a neural network $q_\\phi(Z_m, E_m | X_{1:m\\tau})$ parameterized by \u03c6 is used as an approximation.  Interpreting $q_\\phi$ and $p_\\theta$"}, {"title": "C. Encoder", "content": "The encoder aims at inferring the dynamically evolving interaction graph in each time window. Since the underlying graph is unknown, a GNN is applied over a fully connected graph to learn the latent interaction structure, and a gated recurrent unit (GRU) [34] is used to capture the temporal dependence of the latent graphs. The structure of the encoder is visualized on the left of Fig. 2.\nFirstly, the historical trajectories are embedded to a latent space to obtain the node representation of each agent,\n$v_i^m = f_{emb}(X_{1+(m-1)\\tau:m\\tau}^i),$ (4)\nwhere femb is a multi-layer perceptron (MLP). Then, one can use the relative position $v_i^m - v_j^m$ between two agents in the latent space to describe their spatial relationship. $v_i^m - v_j^m$ measures the correlation between the trajectories of two agents, which can be a good indicator of their interaction. This is advantageous over the stepwise relative position in the original space [9], a local metric that may fail to capture the global correlation.\nThe relative position can be viewed as a message over an edge. Following the message passing formulation of GNNs [25], a two-layer GNN is designed as follows,\n$v_i^m = f_v( \\sum_{j \\neq i} f_e(v_i^m - v_j^m)),$ (5)\n$e_{ij}^m = f_e(v_i^m - v_j^m),$ (6)\nwhere fu is an MLP updating the node embeddings, fe and fe are MLPs that updates the edge embeddings. Considering the uncertainty of the interacting effect, $e_{ij}^m$ is sampled from a Gaussian distribution $\\mathcal{N}(\\bar{e}_{ij}^m, I)$.\nAs for the interacting relation, a GRU is used to model its evolution over time, i.e.,\n$r_{ij}^m = GRU(e_{ij}^m, r_{ij}^{m-1}),$ (7)\nwhere $r_{ij}^m$ is an edge representation encoding the dynamics of the interacting relation. By projecting $r_{ij}^m$ to a scalar, one can calculate the interacting probability from one agent to another. However, sampling the interacting relation is non-differentiable since $z_{ij}^m$ is a discrete variable. Fortunately, the Bernoulli distribution has a continuous approximation named the binary concrete distribution [35] that allows back-propagation. Formally, $z_{ij}^m$ is sampled via the following reparameterization trick,\n$z_{ij}^m = \\text{Sigmoid}((f_{proj}(r_{ij}^m) + \\log \\delta - \\log(1 - \\delta)) / T),$ (8)\nwhere $\u03b4 \\in \\mathbb{R}$ is drawn from the Gumbel(0, 1) distribution and T is a temperature parameter that controls the \u201csmoothness\u201d of the samples. fproj maps $r_{ij}^m$ to a scalar."}, {"title": "D. Decoder", "content": "The decoder is intended for modeling the interactions among heterogeneous agents based on the interaction graphs, and predicting their future trajectories. A heterogeneous attention mechanism (HAM) is used to capture spatial dependence among heterogeneous agents, and category-aware GRUs are used to capture agents' intrinsic dynamics. The procedure of the decoder is visualized on the right of Fig. 2.\nTo distinguish the importance of different types of agents, this paper extends the scaled dot-product attention in Transformer [36] by introducing category-aware modules. The attention mechanism is defined as mapping a query and a set of key-value pairs to an output. Given an edge (i,j), this paper treats the source node i as a \"query\" and the target node j as a \u201ckey\u201d to compute the attention score. The relative position concatenated with the interacting effect is regarded as the \"value\" corresponding to the key. The sum of the values from adjacent agents weighted by the attention scores represents the overall influence of interactions. To model the effect of heterogeneous agents, this paper simply applies category-aware mappings to the agent representations before the aforementioned computation.\nLet $h_j^t$ be the hidden vector encoding the dynamics of agent j at time t in the decoder. A heterogeneous attention mechanism is formulated as follows,\n$m_j^t = \\sum_{i \\neq j} z_{ij}^m f_v( [g_v(h_i^t) - g_v(h_j^t), e_{ij}^m]),$ (9)\nwhere $m_j^t$ is the aggregated interacting effects from agent j' s neighbors, and [\u00b7,\u00b7] is the concatenation operator. fu is an MLP updating the value vector, and gu is a category-aware single-layer perceptron that maps different types of agents to a common space. $\u00a1_{ij}^t$ is the attention score defined in a softmax-like form,\n$\\alpha_{ij}^t = \\frac{z_{ij}^m exp(\\alpha_{ij}^t)}{\\sum_{k \\neq j\\/z_{kj}^m>1/2} exp(\\alpha_{kj}^t)},$ (10)\nIn the training stage, $z_{ij}^m$ sampled via Eq. (8) ranges in [0,1], and only edges with $z_{ij}^m > 1/2$ are involved in the computation. In the testing stage, Eq. (10) is the normal graph attention over the inferred edges without ambiguity.\nIn Eq. (10), $\\alpha_{ij}^t$ is calculated via the scaled inner product,\n$\\alpha_{ij}^t = f_Q ([q_Q(h_i^t), e_{ij}^m] f_K ([g_K(h_i^t), e_{ij}^m]).$ (11)\nfQ and fK are single-layer perceptrons for updating the query vector and the key vector, respectively. gQ and gK are category-aware mappings like gu. D is the dimension of the query vector. In Eqs. (9)-(11), $e_{ij}^m$ implicitly decides the interacting effect without explicitly predefining a finite set of interacting relations. HAM can also be extended to incorporate sub-categories for modeling finer-grained or personalized trajectory patterns. The sub-categories can be learned by clustering [37] or contrastive learning [38] that encourages discriminative representations, which are left for future works.\nNote that HAM is a natural extension of the self-attention in Transformer to an edge-featured graph containing multiple types of nodes. By dropping the category-aware mappings"}, {"title": "E. Loss Function with Graph Entropy Regularization", "content": "The decoder defined in Section III-D makes multi-step predictions recursively, which can be viewed as the forward pass of a multi-layer graph neural network. Fey et al. [40] showed that under some mild assumption, the errors of the node embeddings grow exponentially on the Lipschitz constants of the GNN model as well as the node degrees with respect to the number of layers. As shown in Fig. 3(a), this result can be intuitively understood in the trajectory prediction problem, since the errors from interacting agents will propagate spatially and accumulate over time. Particularlly, the spatially propa-gated error is a unique challenge in spatio-temporal time series forecasting like trajectory prediction, which is not covered by traditional research focusing on temporally accumulated error.\nThe number of agents that affect a target agent can be termed as the in-degree of a node. The distribution of the in-degrees can be imbalanced within an interaction graph, and varies over different graphs. Directly restricting the in-degrees may lead to a degenerate interaction graph that hurts the expressiveness of the model. Instead, this paper turns to the graph entropy [41], a global measure for the complexity of graphs with wide applications in sociology, chemistry, etc. It also receives increasing interest in graph machine learning for deciding the node embedding dimension [42] and designing graph pooling modules [43].\nThe graph entropy is originally defined on undirected graphs [41] by introducing a node distribution. The definition can be naturally extended to our case for directed graphs by considering the in-degrees [41]. Let $d_i^m = \\sum_{i=1}^N z_{ij}^m$ denote the in-degree of node j, and $|E^m| = \\sum_{i \\neq j} z_{ij}^m$ denote the total number of edges. Then, a graph entropy is defined as follows,\n$H_G[Z^m] = - \\frac{1}{\\ln N} \\sum_{j=1}^N (d_i^m/|E^m|) \\ln(d_i^m/|E^m|),$ (14)\nwhere ln N is a normalization constant for the entropy. The graph entropy weighted by a nonnegative coefficient \u03b3 is added to the original loss function to penalize the graph complexity,\n$\\mathcal{L}' = \\mathcal{L} + \\frac{\\gamma}{M} \\sum_{m=1}^M H_G[Z^m].$ (15)\nSince $L$ represents the average prediction error of a single agent per step and $H_G[Z^m]$ lies in [0,1], \u03b3 stands for the strength of graph complexity penalization to a single node. Eq. (15) constrains the latent graphs from the probabilistic perspective, and is a meaningful extension of the entropy regularization to graphs, an important class of irregular data.\nIgnoring the reconstruction error, the graph entropy is maximized when all in-degrees are equal. The characterization of the minimizer is trickier. For simplicity, it is informally stated as the following theorem."}, {"title": "F. Mixup Training Strategy", "content": "To reduce the temporally accumulated errors, this subsection introduces the mixup training strategy. Mixup is a simple and data-agnostic data augmentation trick [45]. It is originally proposed to improve the generalization of deep neural networks by training the models on the linear interpolation (convex combination) of two random training samples and their labels. Liang et al. [46] employed mixup to generalize from simulation datasets to real-world datasets in trajectory prediction. Apart from generalization, mixup can also be used to correct the predicted values. As shown in Fig. 3(c), mixing up the true position and the predicted position yields a more accurate prediction. This motivates us to reduce the accumulated error via mixup.\nGiven the true position Xt and its predicted value $X_t^\\prime$, a convex combination of them is defined as\n$\\hat{X}_t = \\text{Mixup}(X_t, X_t^\\prime) = \\lambda X_t^\\prime + (1 - \\lambda) X_t,$ (16)\nwhere the mixing coefficient $\u03bb \u2208 [0, 1]$ is sampled from a beta distribution Beta(a, a) parameterized by a positive number a. $\\hat{X}_t$ can be regarded as a correction of the predicted position $X_t^\\prime$. Thus, $\\hat{X}_t$ can serve as a more accurate starting point for multi-step prediction, which in turn helps to infer a more accurate interaction graph. Furthermore, by simplifying the notation of multi-step predictions as $X_{t+1} = f_{dec}(X_t)$, this paper conjectures that the gap between $X_{t+1}$ and $f_{dec}(X_t^\\prime)$ is smaller than that between $X_{t+1}$ and $X_{t+1}^\\prime$, which is visualized in Fig. 3(c). Under this assumption, alternatively minimizing two intermediate objectives $||f_{dec}(\\hat{X}_t) - X_{t+1}||$ and $|| f_{dec}(X_t^\\prime)-X_{t+1}||$ can be easier than directly optimizing the original objective $||X_{t+1} - X_{t+1}^\\prime||$.\nHowever, correcting the prediction at each time step may prevent the model from learning to make multi-step predic-tions. Without loss of generality, this paper proposes to correct the final prediction of each time window. It can balance the model's ability in single-step and multi-step prediction instead of focusing on single-step prediction like teacher forcing. Let $f_{dec}^n(X)$ denotes the n-th step prediction from time t. Then, the mixup training strategy can be briefly described in the decoding procedure within a time window."}, {"title": "G. Characteristics of HIMRAE", "content": "HIMRAE is characterized by the following features.\nIt learns edge-featured interaction graphs, where a di-rected edge indicates the existence of interaction and an edge feature implicitly decides the interacting effect. It does not rely on pre-defined adjacency matrices or edge types that may fail to describe heterogeneous interactions precisely.\nThe heterogeneous attention mechanism can discriminate the importance of different types of agents, requiring only linear space complexity.\nThe graph entropy, an analogy of Shannon entropy on graphs, reduces the spatially propagated error by penalizing the graph complexity. Unlike sparsity constraints, it controls the graph complexity appropriately without learning an over sparse graph that hurts the prediction precision.\nThe mixup training strategy can balance the model's abil-ity of single-step and multi-step prediction, and thereby reduce the temporally accumulated error. Unlike teacher forcing, it can effectively narrow the gap between training and testing.\nBoth graph entropy and mixup training strategy have certain theoretical justifications that can guide the hyper-parameter selection and help with experimental analysis."}, {"title": "IV. EXPERIMENTS", "content": "A. Datasets\nFollowing Li et al. [5], the proposed method is evaluated on three real-world datasets involving heterogeneous agents, NBA SportVU Dataset (NBA), Honda 3D Dataset [48] and Stanford Drone Dataset (SDD) [49], described as follows.\nNBA: a trajectory dataset collected by NBA with the SportVU tracking system, containing the trajectories of the ball and ten players, with five from the home team and the rest from the visiting team.\nH3D: a large-scale full-surround 3D multi-object detec-tion and tracking dataset, which provides the trajectories of eight types of traffic participants, including pedestri-ans, animals, cyclists, motorcyclists, cars, buses, trucks, and other vehicles.\nSDD: a university campus trajectory dataset, containing the trajectories of six types of traffic participants, pedes-trians, cars, buses, bikers, skaters and carts."}, {"title": "E. Ablation Study", "content": "1) Effect of Heterogeneous Attention Mechanism: As shown in Table II, HIMRAE consistently outperforms HIMRAEHOMO on H3D and SDD datasets, while their per-formances are comparable on the NBA dataset. The results validate that the category-aware mappings are key components"}, {"title": "V. DISCUSSIONS", "content": "A. Selection of Regularization Coefficient \u03b3\nThe hyperparameter \u03b3 controls the strengths of complexity regularization. The best \u03b3 varies with datasets since the units of positions and the dynamics are different. Without loss of generality, this paper illustrates the choice of \u03b3 by training"}, {"title": "D. Quality of the Interaction Graphs", "content": "This subsection makes an attempt to evaluate the quality of the learned interaction graphs. In our model, the edges in a graph are conditionally independent given the historical trajectories. Therefore, it suffices to evaluate the quality of each edge, which indicates the existence of a directed inter-action and its effect. Since the interacting effect is encoded by a continuous hidden variable, it is hard to tell its quality. Therefore, this paper tries to check if our model can identify the existence of an edge.\nThe problem is studied from two aspects:\nNecessity of the edges: whether or not the inferred edges contain no redundancy.\nSufficiency of the edges: whether or not the inferred edges contain all useful edges.\nTwo types of tests are introduced to examine the two aspects above, respectively.\nRemove an edge at a time to see if the prediction error increases significantly. Edges that do not affect the prediction error are thought redundant.\nAdd an edge at a time to see if the prediction error decreases significantly. Edges that help reduce the pre-diction error are thought missing.\nLet E, E1, E2 denote the number of inferred edges, the number of redundant edges, and the number of missing edges, respectively. Then, E = E1 + E2 is an approximate number of all useful edges. Consequently, the redundant rate and the missing rate are defined as follows.\nRedundant rate: $E_1/ (E-E_1+E_2)$\nMissing rate: $E_2/ (E-E_1+E_2)$\nBy definition, a lower redundant rate and missing rate indicate higher qualities."}, {"title": "E. Choices of the Interaction Graphs", "content": "In the experiments, the interaction graphs are sampled randomly to evaluate the performance, while in practical scenarios, users might be interested in how to choose a \"most possible\" graph. First of all, there is generally no gold standard because the ground truth graphs are unobservable. When the future trajectories are available, one can select the graph that minimizes the prediction error. However, when they are unknown, e.g. in the testing stage, an alternative criterion should be chosen before selecting the best graph.\nIn our model, edges in a graph are conditionally in-dependent. Once the encoder infers the edge probabilities, the existence of each edge can be decided independently. Edges with small uncertainty are selected deterministically via thresholding, while the rest are selected based on some heuristics. An exemplar procedure is described as follows.\nFilter out edges with probabilities smaller than a given threshold @low.\nSelect edges with probabilities larger than another given threshold @high.\nFor edges with probabilities in [low, Ohigh], this paper adopts the following heuristics.\nSelect the graph with the least graph entropy.\nSelect the graph that is most consistent with the previous one by measuring the graph similarity, e.g., the l\u2081-norm.\nOther heuristics may be explored based on users' prior knowl-edge."}, {"title": "VI. CONCLUSION", "content": "This paper proposes an encoder-decoder framework HIM-RAE that models the interactions among heterogeneous agents and reduces the accumulated errors of multi-agent trajectory prediction. The encoder can use the historical trajectories to infer dynamic interaction graphs, featured by the interacting relations and corresponding interacting effects. The decoder applies a heterogeneous attention mechanism of linear space complexity to the inferred graphs to model the fine-grained heterogeneous interactions. This paper further figures out the error sources of recursive multi-step prediction from both the spatial and the temporal aspects. The graph entropy is adopted to control the spatially propagated errors and the mixup strategy is proposed to reduce the temporally accu-mulated errors. Both strategies have theoretical justifications. Extensive experiments on real-world heterogeneous datasets validate the effectiveness of HIMRAE. The results also show the advantages of graph entropy over sparsity constraints, and the advantages of mixup strategy over teacher forcing.\nIn practical scenarios, the model may be required to predict the trajectories of agents from an unseen category. To tackle this challenge, future work includes using meta-learning to transfer the knowledge of interaction modeling to new agent types. Besides, the interaction graphs inferred by the neural networks lack interpretability. It is worthwhile to explore interpretable interaction graph generation."}]}