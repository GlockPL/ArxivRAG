{"title": "AiRacleX: Automated Detection of Price Oracle Manipulations via LLM-Driven Knowledge Mining and Prompt Generation", "authors": ["BO GAO", "YUAN WANG", "QINGSONG WEI", "YONG LIU", "RICK SIOW MONG GOH", "DAVID LO"], "abstract": "Decentralized finance (DeFi) applications depend on accurate price oracles to ensure secure transactions, yet these oracles are highly\nvulnerable to manipulation, enabling attackers to exploit smart contract vulnerabilities for unfair asset valuation and financial gain.\nDetecting such manipulations traditionally relies on the manual effort of experienced experts, presenting significant challenges.\nIn this paper, we propose a novel LLM-driven framework that automates the detection of price oracle manipulations by leveraging\nthe complementary strengths of different LLM models (LLMs). Our approach begins with domain-specific knowledge extraction,\nwhere an LLM model synthesizes precise insights about price oracle vulnerabilities from top-tier academic papers, eliminating the\nneed for profound expertise from developers or auditors. This knowledge forms the foundation for a second LLM model to generate\nstructured, context-aware chain of thought prompts, which guide a third LLM model in accurately identifying manipulation patterns\nin smart contracts. We validate the framework's effectiveness through experiments on 60 known vulnerabilities from 46 real-world\nDeFi attacks or projects spanning 2021 to 2023. The best performing combination of LLMs (Haiku-Haiku-40-mini) identified by\nAiRacleX demonstrate a 2.58-times improvement in recall (0.667 vs 0.259) compared to the state-of-the-art tool GPTScan, while\nmaintaining comparable precision. Furthermore, our framework demonstrates the feasibility of replacing commercial models with\nopen-source alternatives, enhancing privacy and security for developers.", "sections": [{"title": "1 Introduction", "content": "Decentralized finance (DeFi) has emerged as a groundbreaking paradigm, revolutionizing the landscape of traditional\nfinance by offering open, accessible, and permissionless financial services built on the foundation of blockchain\ntechnology. At the core of many DeFi applications lie price oracles, providing essential external price data for smart\ncontracts that power a wide array of financial activities, including lending, borrowing, trading, and more. By delivering"}, {"title": "2 Preliminaries", "content": "This section provides some basics about POM, including how price oracle manipulation occurs, the typical POMs and\nthe representative causes of POM vulnerabilities. We assume some familiarity with basic concepts such as blockchain,\nEthereum, and smart contracts, and refer readers to [36] for details."}, {"title": "2.1 Types of DeFi Applications", "content": "DeFi applications aim to provide financial services without traditional intermediaries, leveraging blockchain technology\nand smart contracts. The main types of DeFi applications include decentralized exchanges (DEXs), stablecoins, lending\nand borrowing platforms, yield farming and liquidity mining, and decentralized autonomous organizations (DAOs) etc.\nThis work further classifies DeFi applications into two categories based on their role in the ecosystem:\nPrice Provider Applications. These applications provide price data to other DeFi applications. Examples include\nChainlink oracle contracts, decentralized exchanges (DEXs), and other protocols that define their own logic for\ndetermining asset prices.\nPrice Consumer Applications. Applications falling under this category rely on accurate price data for their operational\nefficacy. Examples include lending and borrowing platforms, which use price data to determine the valuation of\ncollaterals, and DAOs, which use price data to determine voting weights and other governance parameters.\nWith this classification, we can accurately analyze the root causes of the price oracle vulnerabilities and design\nefficient prompts to help LLMs detect such kinds of vulnerabilities."}, {"title": "2.2 Types of Price Oracles", "content": "Price oracles can be generally categorized into three classes: on-chain oracles, off-chain oracles, and hybrid price oracles.\nOn-Chain Oracles. On-chain oracles, like those used by Uniswap, derive price data directly from on-chain activities\nsuch as trading within liquidity pools. These oracles use mechanisms like Constant Product Formula (CPF) ?? to calculate\nasset prices based on real-time transactions occurring on the blockchain. Despite their susceptibility to manipulation in\nlow-liquidity scenarios, they offer several advantages:\n\u2022 Native to Blockchain: Since on-chain oracles operate entirely within the blockchain environment, they provide\nseamless integration with decentralized applications (DApps) and smart contracts without the need for external\ndependencies.\n\u2022 Real-time Pricing: Prices reflect current market conditions as they are derived directly from ongoing transactions\non the blockchain.\n\u2022 Decentralization: Since these oracles are based on decentralized mechanisms (e.g., Uniswap's liquidity pools),\nthere is no central authority controlling the price feed, reducing single points of failure.\n\u2022 Full Transparency: Anyone can verify the price data on-chain, ensuring the data's integrity and preventing\nmanipulation by a central entity."}, {"title": "2.3 Price Oracles Manipulation (POM)", "content": "POM can stem from various sources based on above types of oracles. The primary complications arise from on-chain\nand off-chain oracles.\nOn-Chain Price Oracle Manipulation. On-chain oracles can be easily manipulated due to their reliance on spot prices\nfrom a single source. For instance, an attacker can use a flash loan to temporarily drain liquidity from a pool, causing the\nprice to be artificially inflated or deflated. This manipulation allows the attacker to exploit the manipulated price, leading\nto significant financial gains, as demonstrated in the PancakeBunny attack5. A more detailed example is illustrated in\nthe Appendix C."}, {"title": "Off-Chain Price Oracle Manipulation", "content": "Off-chain oracles face different challenges. Centralized off-chain oracles depend\non a single trusted entity, making them vulnerable to malicious data submission by authorized users for personal gain.\nAdditionally, the compromise of private keys can pose significant risks. Decentralized off-chain oracles mitigate some of\nthese risks by aggregating data from multiple sources, but they are not immune to issues like freeloading or Sybil attacks\namong data collectors. Further, off-chain infrastructure vulnerabilities-including those in access control, cryptographic\nimplementations, transport, and database security-add layers of complexity in preventing manipulation [7].\nWhile these issues are broad and affect the overall security of price oracles, this paper focuses specifically on\nvulnerabilities that adversaries can exploit, particularly through specialized inputs to on-chain contracts. This includes\nmanipulations involving on-chain price oracles and the on-chain components of off-chain price oracles, which can lead\nto significant financial losses or unfair advantages for attackers."}, {"title": "2.4 Causes of Price Oracle Manipulation", "content": "Price oracle manipulation arises from various factors that exploit weaknesses in both the underlying mechanisms and\nthe broader DeFi ecosystem. Below are some key causes:\nSmart Contract Vulnerabilities. Careless bugs or flawed logic while development in the smart contracts governing\nliquidity pools or price feed mechanisms can lead to incorrect pricing, enabling attackers to manipulate asset values\nand potentially causing significant financial losses for users and protocols [11].\nFlash Loan Attacks. Flash loans allow users to borrow large amounts of capital without collateral, provided the loan\nis repaid within the same transaction. Attackers exploit this feature by executing large trades to temporarily inflate\nor deflate the price of assets in on-chain liquidity pools. This manipulated price can then be leveraged in other DeFi\nprotocols that depend on the oracle, leading to cascading financial consequences [40].\nFront-Running Attacks. Front-running attacks, enabled by the transparency of blockchain transactions, also contribute\nto price oracle manipulation. Malicious actors monitor pending transactions and strategically place their trades just\nbefore large transactions. By doing so, they can profit from the resulting price changes while distorting the price data\nin liquidity pools [40].\nImpermanent Loss Impact. Liquidity providers may suffer from impermanent loss, where the value of their deposited\nassets changes due to price fluctuations within the pool. If a DeFi application relies on the pool's price without accounting\nfor these fluctuations, it might overestimate or underestimate the true value of assets [17].\nSlippage. The difference between the expected and actual executed price of a trade presents another avenue for\nmanipulation. In low-liquidity pools, attackers can exploit slippage by executing large trades that cause significant price\ndeviations. These deviations can propagate through dependent DeFi applications, leading to inaccurate price feeds and\ndestabilizing the broader ecosystem [17].\nThese factors are inherent features of blockchain and DeFi systems, not deficiencies. While they do not inherently\nlead to attacks, they can introduce vulnerabilities under certain conditions. The goal is not to eliminate these features\nbut to identify potential weaknesses and mitigate their adverse effects, thereby maximizing their benefits."}, {"title": "3 Proposed Approach", "content": "In this section, we first briefly review the state-of-the-art LLMs and key prompt engineering techniques, establishing\nthe foundations of our work. We then introduce our LLM-driven detection framework, AiRacleX, in detail."}, {"title": "3.1 LLMs and Prompt Design Methods", "content": "The rapid advancements in large language models (LLMs) have been driven by improvements in machine learning\nalgorithms, computational power, and extensive training datasets. State-of-the-art models like ChatGPT series, Claude\nseries7, and open-source models like Llama series, Qwen series have significantly advanced natural language processing\n(NLP), excelling in tasks such as text generation, summarization, question answering, and program bug detection [18].\nWhile LLMs have demonstrated remarkable performance across various tasks, their ability in reasoning and addressing\ncomplex problems remains highly dependent on the quality of the prompts provided [34]. To maximize their potential,\ninnovative prompt engineering techniques have been developed, such as Chain-of-Thought (CoT) [34], Least-to-Most[42],\nand Complex CoT [9], which guide models to decompose complex tasks into smaller, more structured steps. Remarkably,\neven simple zero-shot CoT prompts like \"let's think step by step\" have demonstrated improvements of up to 60% on\nspecific datasets [15].\nDespite these advancements, designing efficient and effective prompts remains a challenge, particularly for complex\ntasks like POM detection. Building upon these techniques, our work integrates automated prompt design into a\nsystematic, multi-LLM framework. By synthesizing domain-specific knowledge and dynamically generating tailored\nprompts, we enable LLMs to address the intricate challenge of detecting price oracle manipulation vulnerabilities\nin a scalable and automated manner. This eliminates reliance on manual intervention, achieving both precision and\nefficiency."}, {"title": "3.2 AiRacleX: LLM-driven Automated Detection Framework", "content": "In this section, we introduce the three core components of AiRacleX. As illustrated in Fig. 1, our framework is composed\nof the Domain Knowledge Synthesizer, Prompt Generator, and Auditor, each playing a crucial role in automating\nand optimizing the detection process."}, {"title": "3.2.1 Domain Knowledge Synthesizer", "content": "This module synthesizes precise insights about price oracle vulnerabilities\nby leveraging top-tier academic literature, minimizing reliance on developer or auditor expertise through the auto-\nmated summarization of key definitions and patterns. Furthermore, it ensures the use of high-quality domain-specific\ninformation, mitigating the influence of web-scale noisy data used in the pre-training phase of the model."}, {"title": "3.2.2 Prompt Generator and Auditor", "content": "The synthesized domain knowledge is integrated into the Prompt Generator, a\ncomponent that combines extracted insights with tailored instructions. We employ several techniques to enhance the\nprompt generator's ability to produce structured and actionable CoT prompts. As demonstrated in Prompt Generating\nExampleA.1, the System and User represent the input provided by AiRacleX, while the Assistant showcases the\nmodel's output. In this example, the sentence highlighted in orange represents a role-based prompt, which assigns a\nspecific relevant role to guide the prompt. This technique has proven effective in various tasks, with Zhang et al. [41]\nreporting approximately a 20% improvement in accuracy compared to the Simple Prompt approach. Building on this, we\nintroduced the Zero-shot CoT Prompt approach, described in Section 3.1. This method utilizes the \"magical\u201d phrase step\nby step, highlighted in brown, to encourage the model to perform logical reasoning. Another technique employed is\nthe use of positive and negative prompts, inspired by conditional generation models like Stable Diffusion [1]. Positive\nprompts, highlighted in blue, provide explicit guidance, while negative prompts, shown in red, define constraints to\navoid irrelevant or misleading outputs. These prompts are important because LLM models are pre-trained on general\nweb-scale data, this pre-trained knowledge may conflict with the actual context of POM and thus interfere the analysis\nof the underlying task. For instance, such knowledge often leads to extraneous alarms, like presuming that an oracle\nowner's potential to modify the oracle inherently makes the \"set oracle\" function vulnerable. While these findings may\nhold in broader contexts, they are not classified as POM attacks from a developer's perspective and therefore increase"}, {"title": "4 Evaluation", "content": "In this section, we present the dataset utilized for our evaluation and discuss the findings derived from addressing the\nfollowing research questions (RQs):"}, {"title": "4.1 Dataset", "content": "Our dataset is curated to reflect real-world scenarios and challenges, providing a robust benchmark for evaluating\nthe framework. As shown in Table 1, which summarizes the key statistics for the datasets, including the number of\nprojects, the number of vulnerabilities for each dataset, and the average number of functions and lines of code (LoC)\nfor each project, it generally consists of two categories: real-world attacked DeFiHacks projects and Code4Rena audit\ncontest projects. To focus specifically on price oracle manipulation, we extended both datasets, ensuring comprehensive\nand reliable evaluation. By leveraging projects with documented exploitation reports and rigorous audit reports, we\nimplemented a stringent method to categorize the vulnerabilities, thereby minimizing potential reporting biases and\nenhancing the empirical reliability of our evaluation framework."}, {"title": "4.1.1 Real-World Attacked Projects", "content": "The dataset includes 31 projects that have experienced real-world attacks, sourced\nfrom two reliable datasets:\n\u2022 11 Projects from GPTScan's DeFiHack Dataset [29]: This dataset, designed by GPTScan, originally contained\n13 projects. We excluded two projects that were unrelated to oracle manipulation to ensure relevance.\n\u2022 20 Projects from SOK [44]: These projects, categorized in the original SOK paper as on-chain oracle manipula-\ntion, liquidity borrowing and depositing issues, and slippage exploitation observed between 2021 and 2022, are\nincluded to increase the dataset size."}, {"title": "4.1.2 Code4Rena Projects", "content": "Code4rena [3] is a leading audit contest platform for pre-deployment projects. The platform\nengages project developers to commit bounties up to $1M as incentives to draw participants from all over the world.\nCommunity experts selected and developers collaboratively review the submitted bug reports and reward the participants\nbased on the severity and frequency of a particular bug submission. This incentive-driven process guarantees the\nintegrity and credibility of the bugs reported, forming the ground truth for our study.\nThe dataset incorporates 14 projects from the Code4Rena platform:\n\u2022 6 Projects from Zhang et al. [40]: These are derived from Zhang et al.'s original set of 11 price oracle\nmanipulation projects on Code4Rena. To ensure fair comparison with GPTScan, we excluded two misclassified\nprojects and three incomplete ones."}, {"title": "4.2 Baseline", "content": "Since very few works have addressed the problem of price oracle manipulation, most existing analyses are post-\nmortem and rely on transaction data, which differs from our approach. Our goal is to prevent attacks before they\noccur. To evaluate our framework, we select one state-of-the-art (SOTA) LLM-based tool, GPTScan, as our primary\nbaseline. GPTScan utilizes an LLM (initially ChatGPT-3.5) to analyze pre-tagged functions potentially susceptible to\nspecific vulnerability types through predefined scenarios and rules. The tool then applies static analysis to validate the\nLLM-generated findings and filter out false positives, thereby enhancing detection precision. Given the deprecation\nof ChatGPT-3.5, we substituted it with ChatGPT-40-mini, which OpenAI recommends as a more cost-effective and\nimproved alternative.12 Additionally, the original GPTScan implementation suffered from unstructured LLM output,\nwhich hindered systematic analysis by the static analysis module. To address this limitation, we modified the tool's\ncode to enforce structured JSON output supported by ChatGPT-40-mini. These modifications ensure more consistent\nand reliable vulnerability assessments, improving the overall performance of the analysis pipeline.\nTo complement GPTScan, we design a zero-shot CoT prompt based on the assumption that a common LLM user,\nequipped with basic knowledge of prompt engineering and price oracle issues, could generate. This baseline zero-shot\nCoT prompt generally follows the zero-shot prompting guideline outlined in the Prompt Engineering Guide. 13 We\nadopt the role where the model acts as an experienced expert on auditing price oracle manipulation problems, with the\ntask of identifying all potential vulnerabilities in a provided Solidity file. The final prompt, structured for clarity and\nconsistency, is shown below:"}, {"title": "4.3 Model Choices and Hyperparameters", "content": "We utilized four language models, as described in Table 2. These models were selected to represent the latest advance-\nments in industry that are both accessible and affordable for everyday users. The Knowledge Cutoff column is the cutoff\ndate of the training data, indicating the recency of the knowledge embedded in the model. The Context Window is\nthe maximum combined length of input tokens and output tokens that the model can process in a single query. The\nmax_tokens is the upper limit of tokens that the model can generate as output. Although these models allow for higher\ntoken generation, the maximum output token limit was set to 1,024 in our experiments to prioritize longer input.\nIn this study, we evaluated the performance of the models by adjusting two key parameters: temperature and top_p.\nThe temperature parameter controls the randomness of the output, with higher values promoting greater variability\nand lower values yielding more deterministic results. In contrast, top_p applies nucleus sampling, where only tokens\ncontributing to the top p probability mass are considered. For instance, a top_p value of 0.1 restricts the model to tokens\ncomprising the top 10% of cumulative probability. OpenAI generally advises modifying either top_p or temperature, but\nnot both simultaneously.\nIn this evaluation, we set the top_p parameter to its default value of 1.0, ensuring that the full probability mass was\nconsidered. The temperature parameter was configured as follows: a value of 0 was applied for the Knowledge Synthesizer\nand Prompt Generator to prioritize accuracy and consistency, while the Auditor was assigned a value of 1.0 to\nencourage diverse and comprehensive vulnerability identification, thereby fully leveraging the model's capabilities. All\nother parameter settings adhered to their default values as outlined in the OpenAI API documentation [26].\nTo mitigate the impact of randomness inherent in the models, each prompt was executed on the dataset three times.\nThe models were instructed to identify vulnerable functions and provide detailed explanations of the vulnerabilities.\nThe outputs were formatted in JSON to facilitate efficient post-processing."}, {"title": "4.4 Identifying the Best Configuration for AiRacleX", "content": "This section is to establish the most effective combination of components for the POM detection task. We start by\nevaluating the performance of the Auditor component in isolation. Subsequently, we enhance the setup by incorporating"}, {"title": "4.4.1 Identifying the Best Auditor Model", "content": "We assessed the zero-shot CoT prompt (described in Section 4.2) on the\nDeFiHacks dataset to identify the most suitable model as the auditor for detecting POM issues. For comparison, we also\nevaluated GPTScan on the same dataset. The DeFiHacks dataset was chosen because it allows for more efficient manual\nverification of the outputs, facilitating the identification of optimal parameter combinations.\nThe results are summarized in Table 4. The metrics used to assess performance include False Negatives (FN),\nwhich stands for the number of vulnerabilities incorrectly classified as safe; True Positives (TP), the number of the\nvulnerabilities correctly identified and False Positives (FP), the number of instances incorrectly flagged as vulnerable\nbut are actually safe. We evaluated performance using precision, recall, and F1 score as key indicators. Precision\nmeasures the accuracy of positive predictions, while Recall assesses the model's ability to identify all relevant instances.\nThe F1 score, as the harmonic mean of precision and recall, offers a balanced metric, particularly valuable for imbalanced\nclass distributions. For detailed formulas, refer to Appendix D."}, {"title": "Finding 1", "content": "40-mini demonstrates potential as a better auditor. \"Mini\" versions like 40-mini and Claude's Haiku\noutperformed their flagship counterparts, with 40-mini achieving the highest F1 Score (0.374) among all models."}, {"title": "In response to RQ1", "content": "Despite advancements in model performance, both GPTScan and the zero-shot CoT approaches\nshow limited effectiveness in reliably detecting price oracle problems, emphasizing the need for further refinement."}, {"title": "4.4.2 Identifying the Best Prompt Generator with Manually Curated Knowledge", "content": "Building on the results of the previous\nsection, where \"4o-mini\u201d was identified as the best auditor model using the zero-shot CoT prompt, we now explore\nvarying models for the prompt generator to determine the optimal combination for detecting POM vulnerabilities. This\nsection also tries to validate the performance of the best auditor model identified again.\nTo balance computational efficiency with reliability, we adopted a strategic optimization approach. Specifically,\nwe stabilized the domain knowledge component by integrating human-curated expertise into the prompt generator.\nThis refinement allowed us to constrain the experimental space and focus on identifying optimal combinations of\nmodels for vulnerability detection. With the optimal model combinations identified, we can systematically reduce\nmanual intervention with the knowledge synthesizer and progressively automate our vulnerability detection framework,\nultimately advancing towards a more autonomous and robust oracle manipulation detection system. The curated domain\nknowledge that underpins this optimization is presented in Appendix B.1."}, {"title": "Finding 2", "content": "Our framework, enhanced with human-curated knowledge, improves upon the baseline prompt in most\ncases (12 out of 16). Notably, two combinations\u2014\u2018Haiku-generator' with the \u201840-mini' auditor and '4o-generator'\nwith the 'Haiku' auditor-achieved the highest F1-scores of 0.424 and 0.421, compared to the baseline's best of 0.374."}, {"title": "In response to RQ2", "content": "AiRacleX identifies two combinations that outperform the best baseline performance with\nhuman-curated knowledge, demonstrating the efficacy of AiRacleX."}, {"title": "4.4.3 Identifying the Best Knowledge Synthesizer for Automation", "content": "With the best auditor and prompt generator combina-\ntions identified, the next step is to optimize the knowledge synthesizer for summarizing domain-specific information,\nultimately aiming for a fully automated vulnerability detection framework. The knowledge synthesizer plays a critical\nrole in utilizing domain knowledge from external domain-specific sources, and integrating them into the detection\npipeline. To systematically evaluate the knowledge synthesizer's effectiveness, we fixed the two top-performing combi-\nnations of Prompt Generator and Auditor from Finding 2 (Haiku-generator with 40-mini auditor, and 40-generator with\nHaiku auditor) while varying the knowledge synthesizer models. Performance metrics included consistency, accuracy,\nand the overall F1-score."}, {"title": "Finding 3", "content": "The combination of Haiku-Haiku-40-mini achieved the highest F1 score (0.426), slightly outperforming\nthe human-curated knowledge framework (0.424). This result underscores the potential of fully automated domain\nknowledge synthesis for advancing vulnerability detection."}, {"title": "Finding 4", "content": "The best performance is achieved using a combination of less complex models (Haiku-Haiku-40-mini),\ndemonstrating that larger models do not necessarily lead to better results. This finding highlights the potential for\naccessibility and suggests the feasibility of using alternative models similar in size and complexity."}, {"title": "In response to RQ3", "content": "the Knowledge Synthesizer automates knowledge extraction and slightly surpasses human-\ncurated knowledge in both recall and precision, enhancing the framework's performance, while reducing manual\neffort."}, {"title": "4.5 Comparison of AiRacleX and GPTScan on Code4Rena", "content": "To evaluate the effectiveness of AiRacleX on fully developed projects with all supporting files, we applied the best-\nperforming configuration identified in previous sections-Haiku as the Knowledge Synthesizer and Prompt Generator,\npaired with 40-mini as the Auditor-on the Code4Rena dataset. This dataset presents additional challenges due to its\ncomplexity and diverse set of components, providing a rigorous test of the system's capabilities. For comparison, we\nalso evaluated the state-of-the-art tool GPTScan on the same dataset.\nThe performance comparison between AiRacleX and GPTScan are summarized in Table 7. AiRacleX demonstrated a\nsignificant improvement in recall (0.54) compared to GPTScan (0.13), indicating a superior ability to detect vulnerabilities\nin the dataset. This higher recall highlights the effectiveness of the LLM generated knowledge synthesis and optimized"}, {"title": "Finding 5", "content": "AiRacleX outperforms GPTScan on the challenging Code4Rena dataset, achieving higher recall (0.54 vs.\n0.13) and F1-score (0.157 vs. 0.107). However, its precision remains on par with GPTScan, reflecting the need for\nfurther refinements to reduce false positives."}, {"title": "5 Related Work", "content": "Smart contract vulnerability detection has advanced significantly, with numerous tools and techniques proposed to\naddress security issues. Despite these efforts, detecting and mitigating manipulative behaviors in price oracles remains a\npersistent challenge. Existing approaches to this problem can be broadly classified into static analysis, dynamic analysis,\nmachine learning-based methods, and emerging techniques leveraging large language models (LLMs)."}, {"title": "5.1 Static Analysis", "content": "Static analysis techniques examine the source code or bytecode of smart contracts without execution, employing\nmethods such as symbolic execution, formal verification, and pattern matching to identify vulnerabilities. Several tools\nhave been developed for various types of vulnerabilities. For instance, Oyente [21] uses symbolic execution to detect\nissues such as reentrancy, transaction order dependency, suicidal contracts, and integer overflows. SmartCheck[30]\napplies rule-based techniques to identify vulnerabilities and bad practices in Solidity contracts, while Slither [8] combines\ndataflow analysis, taint analysis, and pattern matching to detect a wide range of vulnerabilities efficiently. Formal\nverification methods further enhance static analysis by modeling smart contract behavior using formal languages and\nverifying properties with SMT solvers or theorem provers. Examples include VeriSmart[28] and sVerify[10], which are\ntailored for smart contract verification against predefined specifications.\nHowever, few works focus explicitly on price oracle manipulation vulnerabilities. Recent research has started\naddressing this gap: Foray [35] is an attack synthesis framework for DeFi protocols that uses a domain-specific language\nto convert smart contracts into token flow graphs. While it identifies strategic paths and synthesizes attacks via symbolic\ncompilation, its focus is limited to four specific types of logical flaws, which partially overlap but do not fully align\nwith our target vulnerabilities. OVer [6] employs symbolic analysis to model DeFi protocol behavior under skewed\noracle inputs, identifying secure parameters and generating guard statements to mitigate manipulation attacks. While\neffective, its focus on optimizing parameters for specific protocols limits its generalizability to broader applications."}, {"title": "5.2 Dynamic Analysis", "content": "Dynamic analysis techniques execute smart contract code and monitor its runtime behavior to identify vulnerabilities.\nThese methods often employ fuzzing, symbolic execution, and runtime monitoring to detect issues such as assertion\nfailures, overflows, and frozen ether. Tools like Mythril[24], Manticore[23], sFuzz [25], and ContractFuzzer [14] have\nbeen widely used for identifying common vulnerabilities.\nDespite their success, traditional dynamic analysis tools have rarely addressed price oracle manipulation vulnerabili-\nties. Only a few works have specifically targeted this challenge. DeFiRanger [37] recovers high-level DeFi semantics\nfrom raw Ethereum transactions and identifies price oracle manipulation attacks through pattern matching. However,\nits approach is post-mortem, as it can only detect observed attack transactions, limiting its usefulness for proactive\nvulnerability detection. ProMutator [32] models typical DeFi usage patterns by analyzing existing transactions and\nsimulates potential price manipulation attacks through mutated transactions. This approach effectively identifies weak\npoints in oracle systems before exploitation. However, accurately modeling DeFi transaction patterns is challenging,\nespecially for novel attack vectors, and its simulation-based method requires significant computational resources, im-\npacting scalability and real-time applicability. DeFiPoser [43] employs a dual approach: DEFIPOSER-ARB for identifying\narbitrage opportunities and SMT solvers to create logical models for detecting complex profitable transactions. While\nit can uncover new vulnerabilities in real time, the system relies on manual and costly modeling of DeFi protocols,\nmaking it resource-intensive. Furthermore, its effectiveness may be limited by the rapid evolution of DeFi protocols,\nrequiring frequent updates to maintain accuracy and relevance.\nThese limitations highlight the advantages of our AI-driven framework, which eliminates reliance on expert knowl-\nedge and enhances scalability, effectively overcoming the inefficiencies and adaptability challenges in existing methods."}, {"title": "5.3 Machine Learning-based Methods", "content": "Machine learning-based methods have gained traction in recent years for smart contract vulnerability detection.\nThese approaches typically involve extracting features from the contract's source code or bytecode and training\nclassifiers or deep learning models to predict the presence of vulnerabilities. Some notable works in this domain include\nContractWard [33], which trains a classifier based on features extracted from the contract's bytecode, and the hybrid\napproach proposed by Liu et al. [19], which combines pure neural networks with interpretable graph features and expert\npatterns. Graph neural networks have also been explored for smart contract vulnerability detection. These approaches\nrepresent the contract's control flow graph or data dependency graph as a graph-structured data and apply graph\nneural networks to learn vulnerability patterns. EtherGIS [39] is an example of a vulnerability detection framework\nthat utilizes graph learning features to detect vulnerabilities in Ethereum smart contracts.\nWhile these methods achieve high accuracy for various vulnerabilities, they rely heavily on large labeled datasets\nand often struggle with novel or unseen patterns. Moreover, limited work has specifically addressed price oracle\nmanipulation vulnerabilities, leaving a gap that requires innovative solutions."}, {"title": "5.4 Large Language Model-based Methods", "content": "Recent advancements in large language models (LLMs) have opened up new possibilities for smart contract vulnerability\ndetection. LLMs, such as GPT, have demonstrated remarkable capabilities in understanding and generating human-like\ntext, and researchers have begun exploring their application in smart contract analysis. Gao et al. [11] explored LLMs\nfor detecting complex bugs, including price oracle manipulation, using diverse prompts. However, this early work\ndemonstrated limited performance, making it unsuitable for practical use. Similarly, Issac et al. [5] evaluated ChatGPT-4\nand Claude for smart contract audits, identifying logic flaws and coding errors but reporting an unacceptably high false\npositive rate (95%), which hinders real-world adoption. GPTLens [13] proposed an adversarial framework leveraging\nLLMs in dual roles to enhance detection accuracy, but its effectiveness on price oracle manipulation vulnerabilities\nremains limited. GPTScan [29] combines GPT with program analysis techniques to identify logic vulnerabilities in\nsmart contracts. By leveraging GPT's code understanding and static confirmation, GPTScan reduces false positives and\nachieves high precision and recall in terms of vulnerability type detection across diverse datasets.\nIn contrast, our work develops a fully LLM-driven approach focused on prompt engineering for detecting POM\nvulnerabilities. By utilizing domain-specific knowledge extraction and context-aware prompt generation, we enable\nLLMs to automatically identify manipulation patterns. Our method is user-friendly, generalizable, and provides actionable\nfeedback by leveraging LLMs' capacity to understand the contextual nuances of price oracle manipulations."}, {"title": "6 Conclusion and Future Work", "content": "POM attacks represent a pressing challenge in the DeFi space. AiRacleX provides an innovative, LLM-driven solution\nthat automates the detection of these vulnerabilities by leveraging domain-specific knowledge and context-aware\nprompt generation. By streamlining the analysis process and ensuring actionable outputs, AiRacleX offers a scalable\nand effective approach to safeguarding DeFi ecosystems.\nFor future work, several promising directions can be explored to enhance and expand the capabilities of AiRacleX:\n\u2022 Extension to Additional Problems: AiRacleX's framework can be expanded to address other DeFi issues, such as\nthe accounting problem, privilege escalation, and inconsistent state updates.\n\u2022 Automating Knowledge Synthesis: To reduce manual effort, future versions of AiRacleX will enhance automation\nin knowledge synthesis, potentially using Retrieval-augmented Generation (RAG) [12] for efficient data extraction\nand summarization.\n\u2022 Instruction-tuned LLM: This effort may include the construction of suitable instruction-following dataset and\nfurther supervised fine-tuning of the prompt generator LLM and/or the auditor LLM [20] to better follow the\ninstructions and prompts given and align the model's behave towards desired output.\n\u2022 Reducing False Alarms: Enhancing usability by exploring advanced and fine-grained prompt techniques, such\nas adaptive prompts and context-aware filtering, to minimize false alarms while maintaining high detection\naccuracy.\nBy pursuing these directions, AiRacleX can continue to evolve, offering comprehensive protection against a growing\narray of vulnerabilities in the DeFi ecosystem, while enhancing its efficiency and user-friendliness."}, {"title": "A Appendix: Prompts of AiRacleX", "content": ""}, {"title": "A.1 Prompt Generated by Prompt Generator", "content": ""}, {"title": "B Appendix: Knowledge", "content": ""}, {"title": "B.1 Human-curated Domain Knowledge", "content": ""}, {"title": "C Appendix: Illustration of POM"}]}