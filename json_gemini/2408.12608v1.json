{"title": "A frugal Spiking Neural Network for unsupervised classification of continuous multivariate temporal data", "authors": ["Sai Deepesh Pokala", "Marie Bernert", "Takuya Nanami", "Takashi Kohno", "Timoth\u00e9e L\u00e9vi", "Blaise Yvert"], "abstract": "As neural interfaces become more advanced, there has been an increase in the volume and complexity of neural data recordings. These interfaces capture rich information about neural dynamics that call for efficient, real-time processing algorithms to spontaneously extract and interpret patterns of neural dynamics. Moreover, being able to do so in a fully unsupervised manner is critical as patterns in vast streams of neural data might not be easily identifiable by the human eye. Formal Deep Neural Networks (DNNs) have come a long way in performing pattern recognition tasks for various static and sequential pattern recognition applications. However, these networks usually require large labeled datasets for training and have high power consumption preventing their future embedding in active brain implants. An alternative aimed at addressing these issues are Spiking Neural Networks (SNNs) which are neuromorphic and use more biologically plausible neurons with evolving membrane potentials. In this context, we introduce here a frugal single-layer SNN designed for fully unsupervised identification and classification of multivariate temporal patterns in continuous data with a sequential approach. We show that, with only a handful number of neurons, this strategy is efficient to recognize highly overlapping multivariate temporal patterns, first on simulated data, and then on Mel Cepstral representations of speech sounds and finally on multichannel neural data. This approach relies on several biologically inspired plasticity rules, including Spike-timing- dependent plasticity (STDP), Short-term plasticity (STP) and intrinsic plasticity (IP). These results pave the way towards highly frugal SNNs for fully unsupervised and online-compatible learning of complex multivariate temporal patterns for future embedding in dedicated very-low power hardware.", "sections": [{"title": "Introduction", "content": "Neural interfacing with arrays of electrodes is key for understanding the dynamics of the CNS and for the development of neural prostheses for rehabilitation in case of severe paralysis\u00b9-9. The amount of data produced by recent cortical recording devices10\u201314 has become enormous and their richness is difficult to access using conventional methods. In particular, whether specific spatiotemporal patterns exist in multichannel neural data might not necessarily be obvious to determine, and the corresponding patterns underlying specific neural functions difficult to apprehend. To this end, fully unsupervised approaches that could extract patterns of neural dynamics from the large flow of data produced by neural implants would bring invaluable perspective to better understand the dynamics of the brain that underly behavior and to identify non-obvious behaviorally relevant neural features. Furthermore, the long-term objective of seamlessly integrating neural processing directly into implantable devices emphasizes the critical need for algorithms that are both efficient and online-compatible, while also being low in power consumption.\nOver the past decade, formal deep neural networks (DNNs) have reached unprecedented interest to learn patterns within large amounts of data15\u201319. This second generation of artificial neural networks (ANNs) is now extensively used and ubiquitous in many applications. Yet, despite their capabilities, they face two main drawbacks to envision their embedding in neural interfaces. Firstly, their reliance on mainly supervised learning techniques such as backpropagation20 requires labeled datasets, posing a significant obstacle in applications where such labeled data is either limited, or difficult to obtain as in the case of large-scale neural recordings. Secondly, the computational demands of these networks often call for the use of specialized hardware like GPUs or TPUs to optimize their numerous parameters that need to be maintained in memory and learned through the minimization of a global loss function. Therefore, DNNs are unlikely to be pertinent candidates to eventually embed automated neural processing algorithms into future intelligent neural implants for real-time identification and extraction of complex features from large scale neural recordings.\nBy contrast, spiking neural networks (SNNs) are neuromorphic ANNs that model the membrane potential of their neural elements21\u201323. They typically rely on smaller numbers of parameters, and integrate biomimetic plasticity rules found in living neural networks such as spike-timing-dependent plasticity (STDP)24,25 or other post-synaptic rules. This third generation of ANNs is thus radically different from DNNs, as learning becomes local at each synapse and neural element based on the dynamics of pre- and post-synaptic neurons. This removes the necessity for large global memory storage and energy-consuming global minimization. Based on their local learning rules, SNNs can self-configure in a fully unsupervised way solely based on their inputs to automatically recognize patterns hidden in the data26\u201328, and while they are also capable of supervised learning through surrogate gradient backpropogation29\u201332, they require less data for training than traditional DNNs33-35. Finally, SNNs are compatible with very-low power neuromorphic hardware emulating spiking neurons36-40 and novel materials integrating resistive memories that are well suited to emulate artificial plastic synapses at ultra-low power41\u201345. Given their unique features, SNNs thus constitute promising candidates for future very-low power and fully unsupervised neural signal processing embedded within cortical implants. However, SNN architectures are typically dependent on the application for which they are dedicated and are not versatile to answer the need of a wide range of different applications. Frugal SNN- based algorithms thus remain to be developed to enable fully unsupervised and very-low-power and online- compatible neural pattern detection and classification from large-scale multivariate neural recordings."}, {"title": "Results", "content": "Ideally, an SNN developed for unsupervised pattern identification and recognition should be able to process incoming data fed sequentially, and emit one output spike each time a specific pattern occurs in the data, and each spike needs to be emitted by a different neuron for each different pattern to allow direct inference without further supervised step. The initial step of this procedure is to encode the continuous input data into spike trains to enable SNNs to leverage the inherent event-driven nature of neuronal computation and capture temporal dependencies within the data. To this end, the original data was quantized using a column of sensory receptive fields that generated spikes when the signal fell within the fields (Figure 1a), a strategy we previously employed to encode extracellular signals for spike sorting using SNNs64. Five spikes were generated for each input value in order to increase robustness of the encoding with respect to small fluctuations of the input. Using this approach, the resulting spike trains directly reflected the shape of the original data (Figure 1b). Original audio data was decomposed into 24 continuous Mel Cepstral signals (Figure 1c, see Methods for details). Similarly, the multiunit activity of the neural data was binned and smoothed for each electrode, resulting in 30 continuous signals (Figure 1d). In both cases, these input data were normalized between 0 and 1 and encoded using 24 receptive fields (Figure 1e,f).\nThis initial encoding resulted in spike trains that encoded both background noise and relevant patterns. In order to mitigate the influence of noise on the STDP learning process, a short-term (STP) plasticity rule was introduced for each input spike train, which is a mechanism that weakens input synaptic weights all the more that the presynaptic activity is high (see Methods). With this strategy, only those spike trains encoding the peaks and throughs in the original data were retained (Figure 1g,h). These final encoding spike trains were then considered as the input spike trains passed into the network to be processed."}, {"title": "Methods", "content": "As illustrated in Figure 2a, the network consisted of a single layer of a few LTS neurons that were connected to input spike trains through negative synaptic weights initialized randomly according to a uniform distribution and further clipped between [-1,0] at all times. LTS neurons, that are a type of Integrate-and-Fire (IF) neurons, have the property to be inhibited during the presence of a stimulus and generating a rebound after the end of the stimulus (Figure 2b). Therefore, as the spike trains are passed through the network, incoming currents (spikes x weights) due to the presence of a pattern hyperpolarized all the LTS neurons. Once the incoming currents stopped due to the end of the pattern, the LTS neurons generated a potential rebound. A Winner-Take-All (WTA) mechanism chose among the neurons that have crossed their respective thresholds, the one with the steepest rebound to generate a postsynaptic spike. The LTS neurons were modeled by the following equations:\n$\\tau_m \\frac{dV}{dt} = -V + q + gI_{stim}$\n$\\tau_m \\frac{dq}{\\varepsilon dt} = -q + f(V)$\nwith $f(V) = \\begin{cases}a_nV \\text{ if } V < 0\\\\ a_p \\text{ if } V \\geq 0\\end{cases}$\nwhere $V$ is the LTS neuron potential, $q$ is an adaptation variable that triggers the rebound after inhibition, $\\tau_m$ is the membrane time constant that is chosen depending on the type of data, $\\varepsilon$ is a constant that makes $q$ vary slower than $V$, $I_{stim}$ is the stimulus current (spikes x weights) of the timestep and $g$ is a constant. Whenever the network produces a postsynaptic spike, both $V$ and $q$ were reset to 0 for all neurons. The following table illustrates the LTS neurons parameters used for the different types of data the network was tested on.\n\nThe membrane time constant $\\tau_m$ was chosen according to the size of the patterns expected in the input data. The artificial patterns and vowels data contained patterns that lasted for about ~500 ms on average. Neural data, on the other hand contained patterns that lasted several seconds. The parameter $\\varepsilon$ was chosen according to the inter-pattern interval in the data."}, {"title": "Plasticity rules", "content": "Learning took place whenever a postsynaptic spike was output by the network. At the occurrence of every postsynaptic spike, the following plasticity rules enabled the network to learn:\nClassical STDP strengthened the synapses connecting the neuron that generated a postsynaptic spike and the input spike trains that exhibited spiking activity within a certain pre-time window, thereby implementing Long-Term Potentiation (LTP). It also weakened the synapses connecting the same post-synaptic neuron and the input spike trains that did not exhibit any spiking activity within the pre-time window, thereby implementing Long-Term Depression (LTD). We chose to implement a simple version of this rule, which is define as follows:\n$\\Delta w_{ij} = \\begin{cases}w_{LTP}, & \\text{if } \\exists t_i \\in S_i \\text{ such that } t_j - T_{STDP} < t_i \\leq t_j \\\\w_{LTD}, & \\text{if } \\nexists t_i \\in S_i \\text{ satisfying } t_j - T_{STDP} < t_i \\leq t_j\\end{cases}$\nwhere $w_{ij}$ is the synapse connecting input spike train $i$ and the LTS neuron $j$ that spiked, $t_i$ is the time of occurrence of the presynaptic spike and $t_j$ is the time of occurrence of the postsynaptic spike, $S_i$ is the set of presynaptic spike times for the input spike train $i$, $T_{STDP}$ is the duration of the window preceding $t_j$ that determines the relevant temporal context for STDP, $w_{LTP} = -0.1$ as we use negative weights, and $w_{LTD} = 0.06$. $T_{STDP}$ was set to 500 ms for the artificial patterns and the vowel data and 8 seconds for the neural data.\nLateral STDP, another STDP rule was used to govern lateral inhibition between LTS neurons. It weakened the synapses connecting all neurons other than the postsynaptic neuron that spiked, and the input spike trains that exhibited spiking activity within the same pre-time window. This was to prevent multiple neurons from learning the same pattern. However, this update rule was much weaker than the classical STDP rule, keeping in mind that patterns might share common spiking activity. For the postsynaptic neuron $j$ that spiked, the lateral STDP rule is defined as follows:\n$\\Delta w_{ij} = w_{\\text{potentiation}}, \\text{ if } \\exists t_i \\in S_i \\text{ such that } t_j - T_{STDP} < t_i \\leq t_j$\nFor all other postsynaptic neurons $k \\neq j$, the lateral STDP rule is defined as:\n$\\Delta w_{ik} = w_{\\text{inhibition}}, \\forall k \\in N, k \\neq j, \\text{ if } \\exists t_i \\in S_i \\text{ such that } t_j - T_{STDP} < t_i \\leq t_j$\nwhere $w_{ik}$ is the synapse connecting input spike train $i$ and each non-spiking postsynaptic neuron $k$, $N$ is the set of all postsynaptic neurons, $w_{\\text{inhibition}} = 0.0002$ and $w_{\\text{potentiation}} = -0.001$. This formulation drove the network towards a more selective and refined connectivity pattern based on the temporal spiking relationships."}, {"title": "Intrinsic Plasticity", "content": "Intrinsic Plasticity, unlike STDP, is a form of plasticity implemented on the neurons and not the synapses connecting the spike trains and the neurons. It helped neurons adapt their thresholds based on the size of the pattern learned. The thresholds of all output neurons were initialized at a low value, to promote learning at the beginning of training and as training progressed, each neuron increased its threshold $Th$ according to the size of the pattern learnt and reached an equilibrium threshold indicative of the size of the pattern learnt. Every time a postsynaptic neuron emitted a spike, its threshold $Th$ was decreased by $\\Delta Th_{post} = F^{\\Delta Th_{post}} * Th$. For each pre-synaptic spike received within a coincidence time window before the post-synaptic spike, the threshold was increased by a value that was obtained by multiplying $\\Delta Th_{pair}$ by the synaptic weight. The thresholds of all neurons were initialized at 20 and then were clipped between [20,3500] at all times."}, {"title": "Encoding", "content": "The process of transforming multichannel data into spike trains is a pivotal step in training SNNs for learning tasks. The effectiveness of this encoding directly influences the network's ability to classify and interpret data. The encoding method determines how well the temporal and spatial dynamics of the data are captured and represented as spikes. Here, we encoded each channel of the data into a collection of spike trains while retaining the original geometry of the data. As shown in Figure 1a, each channel is normalized and discretized into 20 receptive fields. The continuous signal, ranging from 0 to 1, was divided into 20 equal intervals representing the sensitivity of each receptive field. At each timestep, depending on the value of the signal, a spike was encoded by the field corresponding to the signal value. Two additional spikes were encoded both above and below the central spike making a total of five spikes per timestep. There was therefore 24 spike trains representing each channel of the data. The artificial patterns did not have an encoding step as they already represented the final spike trains ready to be passed into the network."}, {"title": "Short-Term Plasticity", "content": "To ensure that learning by LTS neurons is not driven by the background noise of all channels, we implemented a mechanism called Short-Term-Plasticity (STP) that quickly suppressed all the spike trains that corresponded to noise/silence. After the unwanted spike trains were suppressed, the retained spike trains were the ones that encoded rich vowel information. To implement STP, we assigned a weight $W_{STP}$ to every spike train. This weight, which was initialized to 1 for all spike trains, is a probability of the spike train to encode a signal. The input spike trains were subjected to STP before training and as they are processed through time, the weights of the spike trains encoding noise are quickly decreased. Once the weight of any spike train fell below 0.75, we stopped STP and mapped the weights of all spike trains below a certain threshold to 0 and the others to 1. This threshold was 0.92 for the vowels and 1 for the neural data. Furthermore, for each group of 24 spike trains corresponding to a certain signal, we checked if at least 60% of the spikes were retained after STP and if not, the remaining spikes were also mapped to 0 in order to clean up residual spikes potentially corresponding to noise. STP is governed by the following equations:\n$\\frac{dW_{STP}}{dt} = \\frac{1}{\\tau_{stp}}(1 - W_{STP})$\n$\\frac{dW_{STP}}{dt}=(1 - W_{STP}) - W_{STP} * f_a$\nwhere $\\tau_{stp}$ = 2000 ms is the STP time constant and $f_a = 0.003$ is the depression factor. The first of these two equations is the weight update rule for spike trains that do not have spikes in the timestep and the second equation is the weight update rule for spike trains that have spikes in the timestep. Post STP, only the spikes corresponding to the spike trains encoding relevant data beyond noise were retained (see Figure 1g,h)."}, {"title": "Vowel data", "content": "The vowels were recorded with a microphone (SHURE Beta 58 A) and Audacity software at a sampling rate of 44.1 kHz. A native French male was asked to repeat eleven French vowels 50 times. The recorded audio was subjected to a frequency transform using the SPTK library to obtain 25 Mel Cepstral coefficients. The first Mel reflecting mostly the amplitude of the sound, and thus being not specific to which vowel was pronounced, was discarded. The other 24 Mels were normalized between 0 and 1, smoothed, quantized and encoded as spike trains (see Figure 1c,e,g) into an array of binary values. Prior to encoding, we chose to smoothen the Mels with a sliding 2nd order Butterworth filter below 5 Hz to make the network more robust to different occurrences of the same pattern. Unlike the artificial patterns, which had spikes only during the duration of each pattern and no spikes before or after the pattern, the vowels' spike trains had spikes corresponding to noise/silence across all Mels. Therefore, the encoded spike trains were first subjected to STP, to eliminate spikes corresponding to noise and to only retain spikes corresponding to peaks and throughs. These spike trains were then passed into the network as input."}, {"title": "Neural data", "content": "Neural data was reused from a previously published study74. They corresponded to rhythmic activity waves propagating across a whole embryonic OF1 mouse hindbrain-spinal cord preparation at stage E13 laid down on a 60-channel microelectrode array (Ayanda Biosystems, Lausanne Switzerland) arranged as 4 columns of 15 microelectrodes (Figure 1d, left). The detailed procedure to acquire these data has been detailed previously74 and was in accordance with protocols approved by the European Community Council and conformed to National Institutes of Health Guidelines for care and use of laboratory animals. In short, after dissection and meninges removed, the neural tissue was maintained on the electrode array with a custom net and continuously superfused with aCSF (in mM: 113 NaCl, 4.5 KCI, 2 CaCl22H2O, 1 MgCl26H2O, 25 NaHCO3, 1 NaH2PO4H2O, and 11 D-glucose) at a rate of 2 ml/min. Neural data were acquired at 10kHz using a MEA1060 amplifier from Multi Channel Systems (MCS), with x1200 gain and 1-3000 Hz bandpass filters, connected to two synchronized Power 1401 acquisition systems (Cambridge Electronic Design LTD, Cambridge, UK). Each channel was then bandpass filtered between 200 Hz and 2kHz to retain high-frequency components (Figure 1d, middle). Once filtered, we extracted multiunit activity by computing the mean and standard deviation of each channel and considered as spikes those datapoints that were at least 3 standard deviations above or below the mean. Each channel was then downsampled by a binning factor of 100 where each bin was replaced by the total number of spikes in the bin. Finally, a Gaussian kernel (n = 501, \u03c3 = 51 time bins) was convolved to each channel to obtain smoothed spike envelopes of the original neural data (Figure 1d, right). These spike envelopes were then normalized between 0 and 1 and encoded as spike trains and subjected to STP in a manner similar to the vowels. The final spike trains obtained after STP were then passed into the network for learning."}, {"title": "Inference and Evaluation", "content": "To assess the classification performance of the network, we first matched the truth spike trains and the output spike trains to get truth-output pairs. To perform this matching, we convolved all the truth spike trains and output spike trains with a Gaussian kernel (n = 31, \u03c3 = 3 time steps) and then computed the cross- correlation between each of the truth spike trains and the output spike trains. For each truth spike train, we chose the output spike train with the highest cross-correlation as the corresponding output. For each pair, the f-score was computed as:\n$F_{ij} = \\frac{2 * H_{ij}}{T_i + 0_j}$\nwhere $T_i$ was the number of spikes of the ith truth spike train, $O_j$ was the number of spikes emitted by the jth output neuron and $H_{ij}$ was the number of output spikes coinciding with a truth spike within a coincidence window. The coincidence window was 400 ms for the artificial patterns and vowel data and 2.5 seconds in the case of the neural data. These values corresponded to the time needed by a LTS neuron to generate its rebound and cross its threshold. We also computed a global f-score across all truth neurons and all output neurons as:\n$F = \\frac{2 * H}{T+0}$\nwhere $T$ was the total number of truth spikes, $O$ was the total number of output spikes and $H$ was the total number of hits. In the case of the vowels, a confusion matrix was also computed to evaluate the classification performance of the model."}]}