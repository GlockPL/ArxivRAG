{"title": "Advanced Chain-of-Thought Reasoning for Parameter Extraction from Documents Using Large Language Models", "authors": ["Hong Cai Chen", "Yi Pin Xu", "Yang Zhang"], "abstract": "Extracting parameters from technical documentation is crucial for ensuring design precision and simulation reliability in electronic design. However, current methods struggle to handle high-dimensional design data and meet the demands of real-time processing. In electronic design automation (EDA), engineers often manually search through extensive documents to retrieve component parameters required for constructing PySpice models, a process that is both labor-intensive and time-consuming. To address this challenge, we propose an innovative framework that leverages large language models (LLMs) to automate the extraction of parameters and the generation of PySpice models directly from datasheets. Our framework introduces three Chain-of-Thought (CoT) based techniques: (1) Targeted Document Retrieval (TDR), which enables the rapid identification of relevant technical sections; (2) Iterative Retrieval Optimization (IRO), which refines the parameter search through iterative improvements; and (3) Preference Optimization (PO), which dynamically prioritizes key document sections based on relevance. Experimental results show that applying all three methods together improves retrieval precision by 47.69% and reduces processing latency by 37.84%. Furthermore, effect size analysis using Cohen's d reveals that PO significantly reduces latency (Cohen's d = 15.54), while IRO contributes most to precision enhancement (Cohen's d = 7.16). These findings underscore the potential of our framework to streamline EDA processes, enhance design accuracy, and shorten development timelines. Additionally, our algorithm has model-agnostic generalization, meaning it can improve parameter search performance across different LLMs.", "sections": [{"title": "I. INTRODUCTION", "content": "THE rapid advancement of large language models (LLMs) has significantly propelled the field of natural language processing (NLP), particularly in tasks such as document retrieval and question answering [1], [2]. These models exhibit immense potential for enhancing electronic design automation (EDA). LLMs have demonstrated diverse applications within EDA. For example, LLM4EDA [3] automates multiple steps in the EDA process by combining text and multimodal data such as circuit diagrams and code, significantly simplifying the design workflow. ChatEDA [4] further showcases how LLMs can generate processor design scripts and improve EDA efficiency by verifying accuracy through automated tools. Additionally, \"The Dawn of AI-Native EDA\" [5] discusses the application of AI-driven circuit models in circuit analysis and design, especially in standard cells and analog circuits, highlighting their advantages. Lastly, the AutoMage model [6] validates its high precision and reliability in EDA script generation tasks by comparing it with LLMs like GPT-4. Overall, these models primarily focus on design optimization and code generation in QA systems, promoting intelligent design development in EDA.\nIn electronic design, effective parameter extraction is crucial for design processes and ensuring the accuracy of chip models [7], [8]. Engineers often consult extensive documentation to extract component parameters needed for constructing circuit simulation SPICE models. Manually searching through lengthy documents for parameters is time-consuming and labor-intensive [9], [10]. Automating parameter extraction and generating corresponding SPICE models would greatly enhance electronic design efficiency and increase EDA automation levels [11], [12]. LLMs possess a high capacity for document analysis and information extraction, offering potential to automate the parameter extraction process by accurately identifying and extracting model specifications and parameters from technical documents [13], [14].\nDespite the advanced capabilities of LLMs, engineers face considerable challenges when extracting parameters from chip technical documentation. These documents are often lengthy and complex, making manual retrieval cumbersome. While methods like Retrieval-Augmented Generation (RAG) have shown promise in technical document analysis, directly applying LLMs does not efficiently facilitate parameter extraction due to the inherent complexity of chip documentation. This limitation underscores the necessity for innovative strategies to augment the parsing capabilities of LLMs in this specific context [6].\nThere are mainly two techniques to improve LLMs for specific applications: prompting and tuning. Tuning methods require large datasets and computational resources for training and are inflexible due to the need for continuous maintenance and updates. When introducing new data or features, or when network architectures change, retraining becomes necessary to adapt to new tasks or data variations. In contrast, prompting offers greater flexibility and cost-effectiveness but may struggle with complex tasks, necessitating meticulous design for optimal results [15].\nThe Chain-of-Thought (CoT) prompting method can significantly enhance LLMs' reasoning performance in complex tasks. Wei et al. [16] proposed that CoT prompting allows models to generate reasoning steps incrementally, markedly improving performance in mathematical problems and complex reasoning tasks. Auto-CoT [15] further investigated automatic generation of these reasoning chains. Their work employed similarity-based retrieval to select example problems and utilized zero-shot prompting (Zero-Shot-CoT) to generate reasoning chains. Although this method underperforms handcrafted example chains on some datasets, it shows great potential when processing large-scale unlabeled data.\nInspired by CoT, we design a prompt framework leveraging CoT reasoning to enhance the parsing ability of document parameters. CoT reasoning enables LLMs to decompose complex tasks into intermediate reasoning steps, improving performance without model fine-tuning. This strategy leverages the inherent strengths of LLMs to better handle the intricacies of technical documents. Moreover, the proposed algorithm exhibits model-agnostic generalization, enabling enhanced parameter retrieval performance across diverse LLMs.\nThe main contributions of this work are as follows:\n\u2022\tWe propose three novel CoT-based techniques- Targeted Document Retrieval (TDR), Iterative Retrieval Optimization (IRO), and Preference Optimization (PO)\u2014that significantly enhance the efficiency and accuracy of parameter extraction in EDA without requiring model fine-tuning, offering a simple and direct solution.\n\u2022\tThe proposed framework integrates LLMs for parameter extraction with SPICE model generation, enabling automation directly from documents to model creation, which can replace manual labor and significantly enhance efficiency.\n\u2022\tThe proposed framework is tested on various LLMs and shows high adaptability, functioning effectively across various LLMs without requiring specific model adjustments. This broad applicability makes the proposed framework flexible and practical.\nThe rest of the paper is organized as follows. In Section II, we review related works. Section III details our methodology. Section IV presents experimental results and analysis. Finally, Section V concludes the paper and discusses future research directions."}, {"title": "II. RELATED WORKS", "content": "Parameter extraction and modeling in EDA have been extensively studied, with various approaches proposed to address the challenges of efficiency and accuracy. In this section, we systematically review existing research, highlighting the differences and improvements over our work.\nLLMs have demonstrated outstanding performance across various NLP tasks, including document retrieval and question answering. Traditionally, sparse vector techniques such as TF-IDF and BM25 have been widely used for document retrieval [17]. However, these methods often fall short in capturing semantic similarities due to their reliance on term frequency. Recent advancements have shifted towards dense text representations that allow for semantic-level modeling of textual similarity. For instance, Dense Passage Retrieval (DPR) [18] utilizes dual BERT models to generate embeddings for questions and text passages, significantly improving retrieval precision and enhancing the overall accuracy of end-to-end question-answering systems [19].\nWhile these methods are effective in general contexts, they may not fully address the complexities inherent in technical document analysis within EDA, where specialized knowledge and precise parameter extraction are required.\nDespite LLMs excelling in generating fluent and natural text, they are prone to hallucinations, generating content that is not faithful to the original source [20]. To mitigate this issue, RAG architectures have been introduced to combine parametric and non-parametric knowledge, aiming to improve generation accuracy and reduce hallucinations [21]. RAG integrates retrieval mechanisms to draw relevant content from external knowledge bases, thereby reducing the risk of inaccuracies. RAG has shown effectiveness in specialized domains such as medical and legal question answering [6], [22]. However, directly applying RAG to parameter extraction in EDA faces limitations due to the complexity and specificity of technical documents, and the necessity for high precision without extensive model fine-tuning.\nCoT reasoning enables LLMs to decompose complex tasks into intermediate reasoning steps, enhancing performance on multi-step reasoning problems [23]. CoT reasoning has proven effective in various applications, including mathematical reasoning and logical deduction [24], and is particularly relevant in technical document analysis where precise parameter extraction is critical.\nNevertheless, integrating CoT reasoning specifically for parameter extraction in EDA remains underexplored. Existing studies have not fully addressed how CoT can be combined with retrieval techniques to manage the intricacies of EDA documentation.\nThe synergy between dense text representations and CoT reasoning is particularly powerful in tasks requiring both accurate retrieval and multi-step reasoning, such as chip modeling. Dense retrieval techniques like DPR ensure that"}, {"title": "III. METHODOLOGY", "content": "Our work uniquely integrates CoT reasoning with targeted document retrieval and optimization techniques specifically tailored for parameter extraction in EDA. We address the challenges of handling high-dimensional design data and real-time processing demands without requiring model fine-tuning. By introducing TDR, IRO, and PO, we offer a novel solution that improves upon existing methods in both efficiency and accuracy. The whole framework of the proposed method is shown in Fig. 1: The process begins with the user inputting a specific chip model number (e.g., P2N2222A). Through Targeted Document Retrieval (TDR), the system locates the corresponding technical document from the database, ensuring that all subsequent searches are restricted to this document to improve search precision. The system then performs keyword searches (e.g., PNP, NMOS) to identify the chip type, determining whether it is a static device (e.g., diodes, LEDs) or a dynamic device (e.g., transistors). If the chip is classified as a dynamic device, the system prompts the user to provide further details about the device's operating conditions (e.g., voltage or temperature). Based on this information, the system uses IRO to search the document for the relevant technical parameters. This iterative approach refines the search process with each pass to ensure that the most accurate parameters are identified. During this parameter extraction process, PO is employed to prioritize searches in specific document sections (e.g., electrical characteristics) based on the user's input and predefined preferences, thereby ensuring more targeted and efficient extraction. Once the required parameters are identified, the system automatically generates the necessary simulation model code in a predefined PySpice format, streamlining the entire process from parameter extraction to model generation. This integrated approach, leveraging TDR for document localization, IRO for optimizing parameter retrieval, and PO for focused searches, significantly enhances the accuracy and efficiency of extracting chip parameters from technical documents and generating simulation models. In the following sections, we will detail the methodology and implementation of these three techniques to demonstrate their impact on streamlining EDA workflows."}, {"title": "A. Targeted Document Retrieval", "content": "The TDR framework is designed to enhance the efficiency and precision of parameter extraction, a critical task in EDA. The complexity of this task arises from the need to process large datasets, handle ambiguous inputs, and optimize retrieval when faced with errors or incomplete specifications.\n\u2022\tInitial Document Screening\nWe employ semantic matching and context-aware retrieval mechanisms. When a user inputs a chip model, the system extracts key characteristics through semantic analysis, allowing for an initial search within a large technical database. Unlike simple keyword matching, the system uses a contextual understanding to capture relevant documents that may not contain the exact keywords but share semantic similarities [3]. This improves the likelihood of locating documents even when the input is vague or partially specified. Fig. 2 illustrates the TDR framework within the Chip Modeling Framework depicted in Fig. 1, which is used for chip model identification.\n\u2022\tDynamic Adjustment and Adaptive Optimization\nIf no match is found in the initial screening, the system transitions to a more advanced stage involving dynamic adjustment and adaptive optimization. This stage includes two key strategies:\nSeries-Level Input with Model Association: When the user inputs a chip series rather than a specific model, the system dynamically expands the search to include all models within that series. This process leverages metadata tags and hierarchical model associations within the database to ensure that no related models are overlooked [4, 25]. Fig. 3 demonstrates an example of the dynamic adjustment and fuzzy matching for chip series expansion.\nFuzzy Matching with Edit Distance: In cases where the input is erroneous or typographically flawed, the system employs fuzzy matching using the Levenshtein Distance to calculate the number of operations needed to transform the input into a known model in the database [25]. This accommodates minor user input errors and still retrieves useful documents [4].\nDocument Filtering and Recommendation: Following the dynamic adjustment phase, the system generates a set of potential document matches, which are then ranked and filtered based on similarity and relevance scores. The most relevant documents are presented to the user, ensuring precise parameter extraction for further modeling in the EDA process. Fig. 4 shows an example of document recommendation after a mismatch.\nThe TDR framework provides a robust solution for handling incomplete or erroneous user inputs during parameter extraction in EDA. Through semantic matching, fuzzy logic, and metadata-based model association, TDR ensures high retrieval accuracy while minimizing manual effort."}, {"title": "B. Iterative Retrieval Optimization", "content": "Iterative Retrieval Optimization (IRO) is designed to enhance the accuracy of parameter extraction in complex tasks involving LLMs [26]. Traditional retrieval methods often fall short due to the semantic gap between the user's query and the required knowledge [27]. IRO addresses this challenge by iteratively alternating between retrieval and generation processes, progressively narrowing this gap and improving parameter extraction accuracy.\nIn each iteration, the model leverages the output from the previous generation step, combining it with the original query to refine the retrieval process. Specifically, given a user query q and a corpus D = {d}, the IRO method performs the following steps in the t-th iteration:\n(1) Retrieval Stage: Concatenate the previous output \\(Y_{t-1}\\) with the query q to form a new query. Use this to retrieve relevant documents from the corpus D, resulting in a retrieval set \\(D_{Y_{t-1}||q}\\).\n(2) Generation Stage: Utilize an LLM M to generate a new output \\(y_t\\) based on the retrieved documents \\(D_{Y_{t-1}||q}\\) and the original query q.\nThis iterative process is formalized as:\n\\[Y_t = M(y_t|prompt(D_{Y_{t-1}||q}, q),  1<t\u2264T \\]\nwhere T is the maximum number of iterations, and \\(y_T\\) is the final output provided by the model [28]. Fig. 5 depicts the IRO workflow, illustrating how each iteration refines the retrieval and generation processes.\nTo illustrate the effectiveness of IRO, we focus on its application in transistor parameter extraction and PySpice model generation within chip documentation. Fig. 5 depicts the"}, {"title": "C. Preference Optimization", "content": "PO aims to enhance the efficiency and precision of parameter extraction within EDA workflows by leveraging structured document analysis and priority definition to focus on specific sections within chip technical documents.\nThrough structured analysis, the model identifies and labels different sections such as \"Electrical Characteristics,\" \"Typical Performance Curves,\" and \"Absolute Maximum Ratings.\" This hierarchical structure provides a clear path for subsequent searches.\nBased on expert knowledge of where modeling parameters are typically located, the system assigns different priority levels to each section. For example, key parameters for modeling are most likely to appear in the \"Electrical Characteristics\" section, which is assigned the highest priority.\nBy employing constraint optimization theory, the search process is limited to high-priority sections [29]. The model begins by extracting parameters from the highest-priority sections, only considering lower-priority sections if necessary. This reduces time spent on irrelevant sections and enhances both search efficiency and accuracy [30], [31]. Fig. 7 illustrates the preference optimization framework for MOSFET parameter extraction in technical documents.\nBy integrating knowledge reasoning, CoT, and constraint optimization theory, the PO method effectively increases search efficiency and accuracy, addressing the challenges faced by traditional methods when dealing with large technical documents."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "We conducted experiments to investigate the effectiveness of TDR, IRO, and PO in improving the accuracy and efficiency of parameter extraction from chip datasheets. The dataset comprises 200 datasheets covering 15 types of devices, including transistors, diodes, and LEDs, sourced from six manufacturers such as ON Semiconductor and Texas Instruments. A stratified random sampling method ensured representative coverage. We conducted experiments to investigate the effectiveness of TDR, IRO, and PO in improving the accuracy and efficiency of parameter extraction from chip datasheets. The dataset comprises 200 datasheets covering 15 types of devices, including transistors, diodes, and LEDs, sourced from six manufacturers such as ON Semiconductor and Texas Instruments. A stratified random sampling method ensured representative coverage. The experiments were run on a Linux machine with a multi-core processor, 32GB of RAM, and a GPU of NVIDIA GeForce 4090, ensuring efficient handling of large datasets and model computations. The conversational LLM in Ragflow used in this experiment is DeepSeek-V2.5, optimized for handling extensive natural language processing tasks with high efficiency and accuracy. For comparison and ablation study, five configurations were evaluated:\nGroup 1(Baseline): No new methods applied.\nGroup 2: Utilizing TDR and IRO.\nGroup 3: Utilizing TDR and PO.\nGroup 4: Utilizing IRO and PO.\nGroup 5: Employing all three methods.\nEach group followed a systematic approach to assess the individual contribution of each method."}, {"title": "B. Evaluation Metrics", "content": "The effectiveness of these methods was evaluated based on two primary metrics: Precision and Average Response Time (ART):\nPrecision is defined as the ratio of correctly extracted parameters to the total number of extracted parameters. It is calculated using the following formula:\n\\[Precision = \\frac{C}{E} \u00d7 100\\%\\]\nwhere C is the number of correctly extracted parameters, E is the total number of extracted parameters. This metric reflects the accuracy of the extraction process, measuring how effectively the system retrieves the desired parameters.\nAverage Response Time refers to the time, in milliseconds, taken to return the extraction results from the initiation of the request. It is computed using the formula:\n\\[Average Response Time = \\frac{\\Sigma_{i=1}^{n}T_i}{n}\\]\nwhere \\(T_i\\) is the response time for each individual request and n is the total number of requests. This metric helps assess the efficiency of the method in terms of processing speed.\nCohen's d effect sizes: Cohen's d is a statistical measure to quantify the practical significance of differences between groups, providing a standardized way to understand the magnitude of differences in the context of experimental results. The formula for Cohen's d is given by [32, 33]:\n\\[Cohen's = \\frac{G_x-G_y}{S_{pooled}}\\]\nwhere \\(G_x\\) and \\(G_y\\) represent the means of the two groups, and \\(S_{pooled}\\) is the pooled standard deviation, calculated as:\n\\[S_{pooled} = \\sqrt{\\frac{(n_x \u2013 1)S_x^2 + (n_y \u2013 1)S_y^2}{n_x + n_y - 2}}\\]\nwhere \\(S_x\\) and \\(S_y\\) are the standard deviations of the two groups, and \\(n_x\\), \\(n_y\\) represent the respective sample sizes. The calculation of Cohen's d allows us to measure the effect size and evaluate the significance of differences between the groups."}, {"title": "C. Experimental Results and Analysis", "content": "Table I presents the comparison of retrieval precision and latency across the five experimental groups. Group 1 served as the baseline and achieved the lowest retrieval precision of 65% and the longest latency at 498.5 ms. Group 2, which combined TDR and IRO, achieved an 85% retrieval precision, indicating a substantial improvement in accuracy. TDR likely contributes by narrowing down the search to relevant documents, while IRO refines the search through iterative optimization. Additionally, this group achieved a 15.5% latency reduction to 422.5 ms, suggesting that these methods not only boost accuracy but also expedite the retrieval process. Group 3 (TDR + PO) achieved a retrieval precision of 80%. While this is an improvement over the baseline, it is slightly lower than Group 2. This could indicate that PO, while helpful in reducing latency, may not contribute as much to precision as IRO does. This group reduced latency to 379.3 ms, indicating a more significant improvement in speed. PO, with its focus on prioritizing relevant document sections, appears to be particularly effective in reducing latency. Group 4, which paired IRO with PO, excelled with a remarkable 88% retrieval precision, underscoring the strong synergy between these two methods, particularly IRO's pivotal role in boosting accuracy. Additionally, this group had a latency of 353.2 ms, marking a significant decrease in retrieval time and highlighting the efficiency gains from the joint of IRO and PO. Group 5, employing the full suite of TDR, IRO, and PO, achieved the top retrieval precision of 96%, showcasing the powerful synergy of these combined approaches. This group also had the fastest retrieval time at 312.6 ms, reflecting a substantial 37.48% reduction in latency. The collective of all three methods significantly accelerated the retrieval process, underscoring their potent collaborative effect on efficiency.\nTo quantify the contributions of PO, IRO, and TDR in enhancing parameter extraction accuracy and reducing system latency, Cohen's d effect size is evaluated to quantify the differences between experimental groups, with results summarized in Table II. Firstly, to assess the contribution of PO, we compared Group 2 (without PO) with Group 5. The results indicated that PO significantly reduced latency, with a Cohen's d effect size of 15.54, and improved precision, with an effect size of 4.92. This demonstrates that PO's dynamic priority mechanism effectively accelerates system response time and enhances parameter extraction accuracy by focusing on the most relevant document sections. Secondly, to evaluate the role of IRO, we compared Group 3 (without IRO) with Group 5. The findings revealed that IRO significantly improved precision, with a Cohen's d effect size of 7.16, and noticeably reduced latency, with an effect size of 9.43. IRO's iterative optimization process enhances system accuracy and efficiency by progressively refining parameter extraction and reducing errors. Thirdly, to verify the contribution of TDR, we compared Group 4 (without TDR) with Group 5. The results showed that TDR contributed to precision improvement, with a Cohen's d effect size of 3.58, and helped reduce latency, with an effect size of 5.74. TDR's early document filtering mechanism effectively eliminates irrelevant documents, enhancing the efficiency of subsequent PO and IRO methods. Finally, to assess the effectiveness of the combined use of all three methods, we compared the baseline Group 1 (without any methods) with Group 5. The results indicated that the joint application of the three methods significantly improved precision, with a Cohen's d effect size of 13.86, and substantially reduced latency, with an effect size of 26.29. This demonstrates that the synergistic effect of PO, IRO, and TDR effectively enhances parameter extraction accuracy and significantly accelerates system response, fully reflecting the powerful impact of using all three methods simultaneously.\nAs Cohen's D of different methods shown in Fig. 8, PO is the most outstanding in reducing latency, with a Cohen's d effect size as high as 15.54, significantly surpassing the second-ranked IRO (effect size 9.43). This indicates that PO's dynamic priority mechanism effectively accelerates system response time. IRO is the most significant in improving precision, with a Cohen's d effect size of 7.16, leading over the second-ranked PO (effect size 4.92). IRO's iterative optimization process enhances parameter extraction accuracy and reduces extraction errors. TDR lays the foundation for the overall improvement of system performance. Although its Cohen's d effect sizes in both aspects are relatively smaller (precision improvement 3.58, latency reduction 5.74), TDR's early filtering mechanism is crucial for enhancing the efficiency of PO and IRO. The combined application of all three methods achieves the highest Cohen's d effect sizes in both aspects (precision improvement 13.86, latency reduction 26.29), far exceeding the effect sizes of any single method. This further confirms that the synergistic effect of the three methods is superior to using any method alone."}, {"title": "D. Model-Agnostic Generalization Experiment and Analysis", "content": "Previous experiments using the DeepSeek-V2 large-scale model have demonstrated that applying our proposed innovative CoT methodology significantly enhances the accuracy of chip technical parameter retrieval while reducing retrieval latency. To further evaluate the generalizability of the CoT method across other large-scale models, this experiment aims to verify that our innovative CoT approach consistently improves performance across multiple models.\nIn this Experiment, we stratified and extracted 60 documents from 15 categories of chip technical documentation provided by six manufacturers to form our test dataset. We selected four different state-of-the-art large-scale models: DeepSeek-V2.5, Qwen2.5 72B, ERNIE 4.0, and Moonshot-v1-32k. Under identical conditions, we executed the same chip parameter extraction tasks both with and without employing our proposed Chain-of-Thought reasoning method. We measured each model's Retrieval Precision and Retrieval Latency to assess the effectiveness of the Chain-of-Thought method and to evaluate consistency across different models."}, {"title": "V. CONCLUSION", "content": "In this paper, we presented a novel chip modeling framework that leverages Chain-of-Thought (CoT) reasoning to enhance the efficiency and accuracy of parameter extraction in Electronic Design Automation. By introducing three CoT-based techniques-Targeted Document Retrieval, Iterative Retrieval Optimization, and Preference Optimization-we addressed the challenges of processing high-dimensional design data and meeting real-time processing demands without the need for model fine-tuning. Moreover, the method we propose significantly enhances parameter search performance across all four LLMs.\nOur experimental results demonstrated significant improvements in retrieval precision and latency reduction, highlighting the effectiveness of our approach. The use of Cohen's d effect sizes quantified the substantial impact of each technique, with Preference Optimization having the greatest effect on latency reduction and Iterative Retrieval Optimization contributing most to precision improvement.\nFor future research, we plan to explore the integration of our framework with other EDA tools and workflows, investigating its scalability and adaptability in different design environments. Additionally, we aim to extend our methods to support a broader range of devices and parameters, further enhancing the utility of our approach in the rapidly evolving field of chip design."}]}