{"title": "Deep Learning in Palmprint Recognition-A Comprehensive Survey", "authors": ["Chengrui Gao", "Ziyuan Yang", "Wei Jia", "Lu Leng", "Bob Zhang", "Andrew Beng Jin Teoh"], "abstract": "Palmprint recognition has emerged as a prominent biometric technology, widely applied in diverse scenarios. Traditional handcrafted methods for palmprint recognition often fall short in representation capability, as they heavily depend on researchers' prior knowledge. Deep learning (DL) has been introduced to address this limitation, leveraging its remarkable successes across various domains. While existing surveys focus narrowly on specific tasks within palmprint recognition-often grounded in traditional methodologies\u2014there remains a significant gap in comprehensive research exploring DL-based approaches across all facets of palmprint recognition. This paper bridges that gap by thoroughly reviewing recent advancements in DL-powered palmprint recognition. The paper systematically examines progress across key tasks, including region-of-interest segmentation, feature extraction, and security/privacy-oriented challenges. Beyond highlighting these advancements, the paper identifies current challenges and uncovers promising opportunities for future research. By consolidating state-of-the-art progress, this review serves as a valuable resource for researchers, enabling them to stay abreast of cutting-edge technologies and drive innovation in palmprint recognition.", "sections": [{"title": "I. INTRODUCTION", "content": "BIOMETRIC recognition technology has emerged as a prominent identity management method in recent years, with applications spanning diverse domains [1]. Its effectiveness relies on the uniqueness of physiological traits such as face [2], iris [3], and palmprint [4], as well as behavioral traits like keystroke dynamics [5], gait [6], and signature [7]. As a relatively new physiological modality, palmprint encompasses a rich array of distinctive features, including wrinkles, principal lines, intricate ridges, and fine-grained characteristics [8]. Palmprint is generally perceived as less intrusive than other biometric modalities, and the recognition process is notably user-friendly. These attributes make palmprint recognition a highly promising approach for achieving high accuracy and reliability in personal verification and identification applications.\nThe palmprint recognition process follows a structured pipeline comprising four essential steps: image acquisition, preprocessing, feature extraction, and matching, as depicted in Fig. 1. Palmprint images are captured during enrollment, and regions of interest (ROI) are identified, making preprocessing a critical step to facilitate accurate feature extraction and matching. The extracted discriminative features are stored as templates during enrollment. The query features, derived from the same processing steps, are compared against stored templates to verify or determine an individual's identity. These foundational steps have shaped the evolution of palmprint recognition, advancing from statistical methods to deep learning-based approaches.\nPalmprint recognition has evolved significantly across different technological eras. In its early stages, the field relied heavily on statistic-based approaches, which depended on manually designed methods to extract statistical information. However, these approaches often fell short of capturing the intricate texture details of palmprints. A major shift occurred in 2003, with researchers focusing on texture features extracted from palmprint images. Among the seminal works of this period was PalmCode [16]. Introducing Competitive Code (CompCode) [17] further advanced the field, highlighting the robustness of ordering features in palmprint recognition. This discovery spurred extensive research into developing powerful competition mechanisms to enhance recognition accuracy.\nThe advent of deep learning (DL) further transformed the field. While initial attempts with generic DL models produced suboptimal results, combining DL with traditional encoding techniques led to significant breakthroughs. These innovations addressed challenges unique to palmprint recognition, propelling the field toward robust and accurate solutions.\nSeveral survey papers on palmprint biometrics have been published, primarily emphasizing traditional feature extraction techniques or specialized tasks. For instance, Zhong et al. [11] provided an overview of palmprint recognition, addressing data collection, datasets, preprocessing, traditional feature extraction, matching strategies, and fusion techniques. Similarly, Fei et al. [12] categorized traditional feature extraction methods into four types, examining the theoretical foundations of extraction and matching approaches, particularly for 3D palmprint images. Ungureanu et al. [14] investigated unconstrained palmprint recognition, focusing on ROI extraction methods, feature extraction strategies, and matching algorithms. Lately, Zhao et al. [15] highlighted recognition methods based on multi-view learning, discussing how integrating complementary features from multiple perspectives enhances recognition performance.\nHowever, unlike the more specialized reviews, this paper comprehensively explores diverse tasks, highlighting the transformative impact of DL technologies. It delves into emerging advancements in palmprint biometrics, including secure and privacy-preserving recognition, open-set recognition, cross-domain and cross-modality techniques, lightweight systems, and applications extending beyond identity recognition. A comparison with previous surveys is summarized in Table I, highlighting the expansive scope of this review.\nThe main contributions of this paper can be summarized as follows:\n\u2022 This paper spotlights the revolutionary role of DL technologies, unveiling their transformative potential across a wide spectrum of tasks in palmprint biometrics.\n\u2022 This paper explores emerging tasks in palmprint recognition that were not addressed in previous surveys.\n\u2022 This paper summarizes the current research landscape and discusses potential future research directions in palmprint recognition.\nAs depicted in Fig. 2, the structure of this paper is as follows: Section II overviews DL approaches in palmprint recognition, laying the groundwork for subsequent discussions. Section III highlights preprocessing techniques to enhance recognition accuracy. Section IV focuses on state-of-the-art feature extraction methods and advancements. Section V addresses security and privacy concerns. Section VI discusses specialized tasks in palmprint recognition with insights and comparisons. Section VII reviews commonly used datasets. Section VIII evaluates performance metrics and synthesizes experimental findings. Finally, Section IX summarizes contributions and suggests future research directions."}, {"title": "II. BACKGROUND KNOWLEDGE FOR DL IN PALMPRINT RECOGNITION", "content": "Since 2006, DL has made breakthrough advances in artificial intelligence (AI), driving the prosperity of AI research and industry [18]. In recent years, there has been a growing trend in conducting palmprint recognition research using DL, with early attempts demonstrating its potential [19]. This section will introduce several generic neural networks, and loss functions widely used in the following tasks."}, {"title": "A. Generic Neural Networks", "content": "The adoption of DL, initially developed for general computer vision tasks, marked a significant shift in palmprint recognition beginning around 2015. These methods leveraged generic neural networks such as simple Convolutional Neural Networks (CNNs) [20], Deep Belief Networks (DBNs) [21], AlexNet [22], CNN-Fast [23], VGG-16 [24], PCANet [25], Inception_ResNet_v1 [26], Siamese Networks [27], MobileNet-V2 [28], ResNet [29], Vision Transformers (ViT) [30], and others [31], [32]. These networks were adapted to address the unique challenges of palmprint recognition, such as capturing fine-grained textural features and handling variations in acquisition conditions.\nSimple CNNs, characterized by their shallow depth and straightforward architecture, were among the first to be applied in this domain [33]. Their simplicity facilitated quick training and low computational requirements, making them ideal for early experiments. Building on this, Xin et al. [34] explored using DBNs, generative models proficient at learning hierarchical feature representations, to extract meaningful patterns from palmprint images.\nAlexNet, a pioneering DL model in large-scale image recognition, marked a turning point with its adaptation to palmprint recognition by Dian et al. [35]. AlexNet's robust feature extraction capabilities enabled significant improvements in accuracy, revealing the potential of DL in capturing the intricate patterns necessary for reliable biometric systems. Similarly, VGG-16 [24] gained traction in palmprint recognition for effectively learning hierarchical features, contributing to superior recognition performance [36], [37].\nPCANet, a hybrid method incorporating Principal Component Analysis (PCA) for unsupervised feature extraction, provided a bridge between traditional handcrafted features and deep learning. PCANet efficiently captured discriminative features from palmprint images by combining PCA with convolution operations, offering an accessible yet powerful alternative [38].\nAdvanced architectures like Inception_ResNet_v1 and ResNet brought transformative improvements to palmprint recognition. Inception_ResNet_v1 leveraged multi-scale feature extraction and residual connections to achieve high accuracy [39]. ResNet, on the other hand, addressed the vanishing gradient problem in deep networks, allowing researchers to train much deeper models without overfitting, yielding impressive results [12].\nSiamese Networks also emerged as a valuable tool in biometric verification, including palmprint verification [40]. These networks, consisting of two identical subnetworks, are designed to measure similarity between input pairs, making them particularly effective for verification tasks.\nInnovative adaptations have continued to push the boundaries of palmprint recognition. Xu et al. [41] proposed a contactless palmprint recognition algorithm utilizing a Spatial Transformer Network (STN) for precise alignment, followed by CNN-based learning and classification.\nMore recently, Grosz et al. [42] integrated ViT with CNNs to combine complementary local and global feature extraction, creating Palm-ID, an end-to-end mobile-based palmprint recognition system. This hybrid approach highlights the growing trend of leveraging transformer-based architectures for biometric tasks.\nThe progressive adaptation of these generic neural networks to palmprint recognition reflects the versatility of DL and its capacity to evolve in response to domain-specific challenges. Researchers have significantly advanced the field by combining foundational models with innovative strategies."}, {"title": "B. Loss Function", "content": "In DL, loss functions are crucial in shaping model optimization, boosting recognition accuracy, and reinforcing robustness. Tailored to meet specific task requirements, these functions are extensively used across different stages, including feature learning, matching, and classification. Below, we highlight some of the most widely employed loss functions in optimizing DL models for palmprint recognition.\n(1) Cross-Entropy Loss [43]: Cross-entropy loss is the most commonly used loss function for classification tasks, especially when dealing with multi-class classification problems in DL models. Cross-entropy loss quantifies the discrepancy between the predicted and true class probability distributions.\n$L_{CE} = -\\sum_i y_i \\log(\\hat{y_i}),$\n(2) Contrastive Loss [44]: Contrastive loss is a widely used loss function in metric learning, particularly in Siamese networks. Its objective is to minimize the distance between similar samples while maximizing the distance between dissimilar ones. By leveraging contrastive loss, networks can learn robust feature representations, ultimately enhancing recognition accuracy.\n$L_{contrastive} = \\frac{1}{2} (t \\cdot D^2 + (1-t) \\cdot max(0, m - D)^2)$,\n(3) Triplet Loss [45]: Triplet loss is also for metric learning. It trains the network to understand the relationships among"}, {"title": "III. IMAGE PREPROCESSING", "content": "The preprocessing stage in palmprint recognition is crucial. It focuses on extracting the Region of Interest (ROI) and improving the image quality. These steps are essential, as they directly influence the accuracy and reliability of the subsequent feature extraction process."}, {"title": "A. Region of Interest Extraction", "content": "ROI extraction methods are broadly classified into two categories: standard extraction techniques [52] and advanced DL-based approaches [53].\nOne commonly used ROI extraction technique is the Tangent-Based method [54], which identifies valley points between fingers by constructing tangent lines across the palmprint gaps. These points establish a reliable coordinate system. Zhang et al. [55] extended this method to contactless scenarios using a specialized acquisition device.\nAnother standard approach is the Contour Profile Distance Distribution-Based method [56]. It uses a scanner to capture the hand image, identifies hand boundaries, and determines a reference point at the wrist's intersection. Euclidean distances from the reference to boundary pixels form a contour profile curve, with local minima marking the ROI sub-image.\nThe methods above perform well under controlled environmental conditions but are highly sensitive to pose variations. DL-based approaches have recently emerged to address these limitations. Bao et al. [57] introduced a two-stage shallow neural network system: the first network classifies the palm image as either a left or right hand, while the second network detects the coordinates of three valley points. A similar approach was proposed by Izadpanahkakhk et al. [58], which outputs the coordinates of a corner point along with the width and height of the ROI area. However, both methods were evaluated only on constrained datasets.\nAdvancing the field further, Li et al. [59] proposed the Bimodal Palmprint Fusion Network (BPFNet), which performs ROI localization, alignment, and bimodal image fusion in an end-to-end manner. BPFNet employs a detection network to directly regress the rotated bounding box based on the point of view while predicting image disparity.\nLuo et al. [60] developed a model comprising a palm detection module and a key point detection module. After identifying palm key points, the system establishes a coordinate framework to extract the ROI. An auxiliary network estimates the palm's angle to enhance model convergence and accuracy. Additionally, Liang et al. [61] introduced the Palm Keypoint Localization Network (PKLNet), which integrates information from the hand region, palm boundary, and finger valley edges, achieving robust and precise keypoint localization for effective ROI extraction.\nLin et al. [62] presented a lightweight network-based method for palmprint ROI extraction. It first used YOLOv5-lite for palm detection and initial localization, removing background interference. Then, an improved UNet model is employed for keypoint detection, reducing parameters and boosting performance compared to the original UNet.\nMost recently, Chai et al. [63] proposed an automated and flexible ROI extraction method for complex scenarios based on Finger Valley Points-Free adaptive ROI detection. This method combines cross-dataset hand shape semantic transfer and the constrained palm inscribed circle search, enabling excellent hand segmentation and precise ROI extraction."}, {"title": "B. Palmprint Image Quality", "content": "The quality of palmprint images is critical in ensuring accurate recognition, spurring the development of various techniques to enhance low-quality biometric images. Research consistently highlights the significant impact of image quality on recognition performance, leading to exploring methods like denoising and image super-resolution (SR) to address these challenges effectively.\nDenoising has emerged as a key focus in palmprint recognition research. For instance, Arora et al. [64] examined the effects of noise on biometric image quality and proposed a DL-based method leveraging CNN architectures such as InceptionV3, VGG16, and ResNet50 to classify denoised images. The proposed approach demonstrated its efficacy through rigorous performance evaluations on widely recognized benchmarks.\nWhile palmprint recognition systems thrive on high-quality images, real-world scenarios often involve capturing low-quality samples. To address this, image SR techniques have proven effective in enhancing image quality. Wang et al. [65] introduced the Dense Hybrid Attention (DHA) network, tailored specifically for palmprint image SR. This innovative method begins by generating high-dimensional shallow representations via a single convolutional layer. Subsequently, it employs parallel CNN and Transformer-based branches to jointly learn local and global palmprint features, restoring distinctive palmprint-specific attributes.\nAnother pressing challenge is assessing image quality, especially in practical situations with limited labeled quality data. Zou et al. [66] tackled this issue with their Pseudo-Label Generation and Ranking Guidance (PGRG) framework for unlabeled palmprint image quality assessment (PIQA). This two-stage method estimates the recognizability of palmprint images to generate pseudo-labels. It then produces pseudo-images and assigns quality rankings for pre-training, employing a label-based ranking loss to help the model discern relative quality relationships among pseudo-labels.\nThese advancements highlight the importance of improving and evaluating image quality in palmprint recognition systems. By tackling challenges such as noise reduction, resolution enhancement, and quality assessment, researchers continue to strengthen the robustness and reliability of these systems."}, {"title": "IV. FEATURE EXTRACTION", "content": "Since the inception of palmprint recognition, researchers have explored a wide range of approaches, including statistical methods, coding-based techniques, and, more recently, DL-based strategies. The evolution of these methodologies is illustrated in Fig. 3, showcasing key advancements in the field.\nStatistical-based methods employ statistical transformation techniques to extract meaningful features from palmprint images. These methods operate directly on the raw palmprint image or leverage transformed representations, such as coefficients obtained from Fourier or wavelet transforms, to derive distinctive feature sets. Prominent approaches include Principal Component Analysis (PCA), which reduces dimensionality by identifying the directions of maximum variance in the data, effectively capturing the most critical patterns [67].\nOn the other hand, Independent Component Analysis (ICA) focuses on separating statistically independent components, enabling robust feature extraction even in the presence of noise [68]. Additionally, the Scale-Invariant Feature Transform (SIFT) has been widely adopted for its ability to detect and describe local features invariant to scale, rotation, and minor image distortions [69].\nEncoding-based methods in palmprint recognition can be classified into magnitude and ordering feature-based methods. Magnitude feature-based methods apply predefined coding rules directly to the extracted features, creating compact and discriminative templates. Notable examples include Palmcode [16], which leverages Gabor filters to encode phase information, BOCV [70], which utilizes binary orientation co-occurrence vectors, and MTCC [71], a recent technique focusing on multi-task coding for enhanced accuracy.\nIn contrast, ordering feature-based methods encode information by comparing magnitude responses along different orientations. Key methods in this category include CompCode [17], which uses competitive coding to identify dominant orientations; RLOC [72], which emphasizes robust line orientation coding; DOC [73], which combines dual orientation coding for greater precision, and DRCC [74], which incorporates discriminative ridge coding for improved distinctiveness.\nWhile these methods have demonstrated commendable performance, their reliance on predefined coding rules and the researchers' domain knowledge imposes inherent limitations, resulting in moderate robustness under challenging or less-controlled scenarios.\nThe advent of DL has revolutionized palmprint recognition, leading to the development of numerous methods based on deep neural networks that deliver impressive performance. Unlike traditional approaches, DL-based methods can establish end-to-end frameworks, offering enhanced robustness and adaptability.\nWhile early generic DL networks were applied to palmprint recognition, their performance often fell short due to the unique challenges presented by palmprint data.\nGeneric deep learning models have surpassed traditional handcrafted methods in certain areas, they are not optimized for the distinctive traits of palmprint images. These challenges include significant intra-class variations, such as differing hand positions, lighting conditions, skin textures, and pronounced inter-class similarities, where palmprints from different individuals may appear deceptively alike. Generic architectures often fail to capture the unique textures and features of palmprints, emphasizing the need for advanced, specialized DL approaches to enhance recognition accuracy and efficiency.\nResearchers have introduced specialized neural network architectures tailored specifically for palmprint recognition to overcome these obstacles. These custom designs address the intricacies of palmprint images, improving feature extraction and enabling more accurate and reliable recognition, even in complex and unconstrained scenarios. This tailored approach has propelled DL-based methods to the forefront of palmprint recognition research.\nUnlike traditional palmprint feature extraction methods, which primarily emphasize enrollment followed by test-"}, {"title": "Open-Set Palmprint Recognition", "content": "In closed-set palmprint recognition, both the enrolled and testing identities are fully predefined and included in the training set. This approach focuses on achieving highly accurate recognition within a controlled group of known individuals. Since all identities are accounted for during training, the task becomes one of matching palmprints to a specific identity within the predetermined group.\nOpen-set palmprint recognition presents a more intricate and practical challenge than its closed-set counterpart. The enrolled and testing identities are entirely separate from the training set in this scenario. As a result, the system must process palmprints from individuals it has never seen before, making the task significantly more challenging. This setting mirrors real-world scenarios, where recognition systems must adapt to dynamic environments and handle unseen users seamlessly. In the palmprint research community, this open-set paradigm is often called cross-dataset recognition [75] or cross-id recognition [76].\nOne of the early contributions under this category came from Kumar et al. [77] took a novel approach by exploring cross-hand palmprint matching between right and left images. Employing CNNs, they achieved commendable results. Samai et al. [78] proposed a dual-dimensional model for 2D and 3D palmprint recognition. By converting 3D palmprint data into grayscale images using Mean Curvature (MC) and Gauss Curvature (GC), they extracted features using a Discrete Cosine Transform Network (DCT Net). This innovative method leveraged matching score-level fusion for efficient biometric identification.\nA significant breakthrough came with the work of Zhong et al. [40], who introduced a palmprint recognition algorithm based on the Siamese network. Utilizing two VGG-16 networks with shared parameters, their model extracted features from input palmprints and determined their similarity based on convolutional features. Izadpanahkakhk et al. [58] employed transfer learning for palmprint verification, extracting ROI and features jointly. They combined a pre-trained CNN with an SVM classifier, delivering strong ROI segmentation and recognition performance.\nIn another direction, Xie et al. [79] applied CNNs for gender classification using palmprint images. By fine-tuning a pre-trained VGGNet on palmprint datasets, they demonstrated excellent results in this novel application of palmprint data. Shao and Zhong [80] presented a few-shot palmprint recognition model using graph neural networks (GNNs). In their framework, CNN-extracted palmprint features were treated as nodes in the GNN, with edges representing similarities between nodes, enabling efficient recognition with limited training samples.\nFurther innovation came from Shao et al. [81], who proposed a deep recognition approach integrating hash coding and knowledge distillation. By extending Deep Hash Networks (DHN) to binary code generation, their method optimized storage and accelerated matching processes. Zhao et al. [82] proposed a joint deep convolutional feature representation in hyperspectral palmprint recognition. Their CNN stack effectively processed 53 spectral bands, achieving promising performance.\nGenovese et al. [83] introduced PalmNet, a deep recognition algorithm incorporating Gabor responses and PCA. This multi-stream CNN captured diverse features through attention mechanisms, including textures and unique details. Hussein et al. [84] developed a texture-based recognition approach using a statistical gray-level co-occurrence matrix (GLCM). This was paired with a probabilistic neural network (PNN) to measure system performance, enhancing identification accuracy. Expanding on periodic feature sampling, Zhao et al. [85] utilized CNNs for extracting discriminative convolutional features across palmprint images' local regions.\nIn recent advancements, Liang et al. [86] proposed a Competitive Convolutional Neural Network (CompNet), a contactless recognition model resilient to illumination and scale variations. CompNet efficiently captured rich directional information utilizing multi-scale competitive blocks, proving highly effective on small-scale datasets. Most recently, Yang et al. [87] introduced CO3Net, which employed multiscale learnable Gabor filters to enhance feature representation and discrimination. Additionally, Yang et al. [76] developed CC-Net, integrating spatial and channel competition mechanisms for efficient end-to-end palmprint information capture, setting a new benchmark in palmprint recognition."}, {"title": "B. Open-Set Palmprint Recognition", "content": "Palmprint recognition algorithms were traditionally tailored for closed-set scenarios. Adding new users demanded substantial time and effort to update the models. This challenge highlighted the need for methods that could effortlessly integrate new users without extensive retraining, leading to the development of open-set palmprint recognition.\nLeveraging the shift toward open-set recognition, Zhong et al. [49] proposed Centralized Large Margin Cosine Loss (C-LMCL) to enhance class separation and improve open-set recognition. Shao et al. [88] introduced Deep Ensemble Hashing (DEH), combining weak feature extractors through online gradient boosting to boost recognition performance.\nLi et al. [89] introduced Row-wise Sparse Binary Feature Learning (RsBFL), which extracts binary features directly from image pixels, demonstrating strong generalization in open-set palmprint recognition. This approach was later extended to Row-Sparsity Binary Feature Learning for Multi-View Representation (RsBFL_Mv) [90], which harnesses intra-class and inter-class information across multiple views to enhance feature learning, providing a robust solution for open-set recognition.\nBuilding on advancements in open-set palmprint recognition, Shao et al. [91] introduced the Weighted-based Meta Metric Learning (W2ML) framework, which uses metalearning to enhance generalization and extract highly discriminative features through an end-to-end process. Complementing this, Shao et al. [92] proposed the Joint Pixel and Feature Alignment (JPFA) framework. This two-stage approach reduces pixel-level dataset gaps with deep style transfer and aligns feature distributions using domain adaptation.\nContinuing this progression, Shao et al. [93] developed the Distilling from Multi-Teacher (DFMT) method. DFMT integrates knowledge distillation and domain adaptation by pairing source datasets with multiple targets and employing teacher feature extractors for adaptive knowledge capture. A student feature extractor then learns this knowledge through multilevel distillation losses, facilitating effective knowledge transfer across diverse datasets.\nShao et al. [75] recently introduced the Palmprint Data and Feature Generation (PDFG) method for Cross-Dataset Palmprint Recognition with Unseen Targets (CDPR-UT). This approach boosts model adaptability to unseen datasets by using a Fourier-based data augmentation technique to create diverse training data and employing feature-level losses to reduce shifts between source and augmented datasets, ensuring adaptive feature extraction."}, {"title": "V. SECURITY AND PRIVACY OF PALMPRINT RECOGNITION", "content": "The practical deployment of biometric systems demands careful attention to their performance, user acceptability, and resistance to circumvention. The rapid advancement of digital connectivity further amplifies the importance of robust privacy protection, especially for sensitive biometric information. This section explores the privacy concerns associated with palmprints from two key perspectives: the challenges posed by potential attacks and the countermeasures."}, {"title": "A. Attacks on Palmprint Recognition Systems", "content": "1) Palmprint Template Correlation Attacks: Palmprint template correlation attacks exploit inherent statistical correlations within palmprint templates to compromise palmprint recognition systems. Researchers have developed various attack strategies to assess and enhance the security of palmprint recognition systems.\nLeng et al. [94] first revealed the statistical correlation inherent in coding-based palmprints and devised a crossdataset attack algorithm to evaluate the security vulnerabilities of such systems. Building upon this, Zhu et al. [95] introduced a joint attack and defense framework for multi-spectral palmprints. By leveraging information from diverse sources, their approach effectively reduced the correlation between projected features, disrupting the discriminative capabilities of palmprint models and limiting their representation and classification effectiveness.\nFurther exploring attack strategies, Yang et al. [96] proposed two style transfer methods to reconstruct palmprints. Their approach utilized the strong correlation between templates and their original texture information to enable online attacks.\n2) Palmprint Reconstruction Attacks: Palmprint reconstruction attacks involve generating synthetic palmprint images from stored biometric templates to gain unauthorized access to recognition systems. By exploiting the information within these templates, attackers can reconstruct images that closely resemble the original palmprints, posing a significant security threat.\nYue et al. [97] introduce two palmprint reconstruction attack techniques: Modification Constraint within Neighborhood (MCWN) and Batch Member Selection (BMS). These methods improve existing attacks by enhancing reconstructed palmprint images' naturalness, visual quality, and completeness. The techniques iteratively modify easily obtainable palmprint images using deep reinforcement learning to reduce matching distance while maintaining image quality.\nWang et al. [98] demonstrated a brute-force approach, using DCGAN to generate multiple palmprint images and verifying them sequentially until a match was found, showcasing the ability to quickly and effectively reconstruct high-quality images. Building on this, Yan et al. [99] introduced a more advanced black-box attack method, leveraging Progressive GAN (ProGAN) to generate highly realistic palmprint images from a single template.\n3) Spoofing attacks in Palmprint Recognition Systems: Spoofing attacks, also known as presentation attacks, involve presenting counterfeit palmprint images to the system's sensor, aiming to deceive the biometric system into granting unauthorized access. These attacks exploit the system's reliance on authentic palmprint features, presenting fabricated or altered images that mimic genuine palmprints.\nKanhangad et al. [100] investigated spoof attacks on palmprint verification systems, focusing on display-based and printbased methods. Their research highlights the vulnerabilities of palmprint recognition systems to various spoofing techniques.\nSun and Wang [101] created six palmprint presentation attack datasets, employing physical display carriers such as photos and monitors, to assess the effectiveness of these attacks. Their experiments on texture coding-based and DLbased recognition methods revealed that spoofing attacks using stolen original palmprint images pose a significant threat due to their high success rates.\nThese diverse attacks underscore the evolving landscape of palmprint security challenges and highlight the need for robust defenses to mitigate these sophisticated attack strategies."}, {"title": "B. Countermeasures", "content": "In response to the growing threats to palmprint recognition systems, researchers have developed countermeasures to enhance palmprint recognition systems security.\n1) Privacy-Preserving Palmprint Recognition Systems: Privacy-preserving palmprint recognition systems ensure the secure handling of biometric data, shielding it from breaches or misuse during the recognition process. By leveraging advanced techniques such as homomorphic encryption, federated learning, watermarking, and synthetic palmprint generation, these systems safeguard privacy and strengthen the overall security of palmprint recognition technology.\nGuo et al. [102] introduced a homomorphic encryption framework that encrypts palmprint recognition networks layer by layer, ensuring secure processing of images and network keys throughout the recognition process. Similarly, Tao et al. [103] developed an encryption system combining biometric keys, Singular Value Decomposition (SVD), and Fresnel transforms to protect palmprint images effectively.\nTo address privacy concerns during training, federated learning has emerged as a decentralized solution that enables local training without sharing sensitive palmprint data. Shao et al. [104] proposed Federated Metric Learning (FedML), which allows collaborative model training across multiple clients while ensuring data privacy and isolation. Complementing this, Yang et al. [105] introduced a spectral consistency loss function to align local and global model parameters, preventing model drift and maintaining global consistency.\nLiu et al. [106] developed the Dynamic Random Invisible Watermark Embedding (DRIWE) model, which embeds watermarks into palmprint images' regions of interest. This approach safeguards data during storage and transmission while ensuring accurate recognition by extracting the watermark before processing.\nOn a different front, synthetic palmprint data offers a promising solution for privacy preservation by mimicking the statistical properties of real data, thereby eliminating the need for actual samples and reducing the risk of breaches or misuse. This innovative approach safeguards privacy and facilitates palmprint biometric system development, testing, and training. Shen et al. [107] introduced RPG-Palm, a model synthesizing palmprints across multiple identities. It enhances intra-class diversity through a conditional modulation generator while maintaining identity consistency with identity-aware loss.\nSimilarly, Jin et al. [108] proposed the Palm Crease Energy (PCE) domain, which bridges B\u00e9zier curves and palmprints using a two-stage model. The first stage generates PCE images (creases) from B\u00e9zier curves, and the second stage produces palmprints (textures) from these PCE images.\nThese privacy-preserving innovations collectively enhance the security and reliability of palmprint recognition systems, addressing critical vulnerabilities across various stages of data processing.\n2) Cancelable Palmprint Recognition System: Cancelable palmprint technology, a biometric template protection (BTP) method, adheres to the ISO/IEC 30136 standard [109] by fulfilling key criteria: cancelability for replacing compromised templates, unlinkability for generating unique and noncorrelatable templates, irreversibility to protect user privacy, and high accuracy performance to preserve recognition precision.\nUnlike traditional systems, cancelable approaches utilize user-specific tokens to apply non-invertible transformations to palmprint features, enabling secure template replacement and unlinkability. This approach effectively mitigates risks such as correlation and template reconstruction attacks, reinforcing the security and integrity of biometric systems.\nAn early instance is PalmHashing, introduced by Connie et al. [110], provided revocable palmprint templates, allowing users to replace compromised data. Building on this, Yang et al. [111] proposed a dual-level framework combining competition hashing for tokenized template generation with a negative dataset (NDB) for enhanced protection, reducing data leakage by eliminating the need to store templates identical to those used for verification.\nOther approaches focus on efficiency and hybrid security. Siddhad et al. [112] utilized autoencoders to create lowdimensional templates, reducing storage size to 25% of the original while maintaining performance. Sardar et al. [113] introduced a hybrid scheme combining cancelable biometrics with bio-cryptography techniques, enhancing data security and privacy. Similarly, Khan et al. [114] proposed a method incorporating a deep attention network and randomized hashing, dynamically generating diverse templates through improved matrix multiplication using the LTTS random key and palmprint features.\n3) Anti-Spoofing and Liveliness Detection: With the rise of spoofing techniques, palmprint verification systems require innovative solutions to maintain security and reliability. Researchers have explored diverse strategies, from leveraging surface properties to incorporating multispectral imaging, each contributing unique strengths to combat presentation attacks. Kanhangad et al. [100] laid the groundwork by focusing on surface reflectance to counter display and print-based spoofing. By analyzing hand images through statistical features derived from pixel intensities and wavelet coefficients, their method introduced a foundational approach to detecting fake palmprints.\nBuilding on this, Aishwarya et al. [115] enhanced the field by integrating biometric trait verification and Weber's local descriptor for feature refinement. This method complemented spoof detection with Euclidean distance-based authentication, though its liveness detection details remained unspecified, leaving room for further innovation. Expanding on vulnerability insights, Bhilare et al. [116] delved deeper into presentation attacks. Their robust anti-spoofing solution advanced Kanhangad's reflectance-based ideas, incorporating refined statistical analysis to accurately distinguish genuine from fake palmprints.\nSugimoto et al. [117] then focused on the unique challenges of printed and displayed palms. By examining artifacts like resolution degradation caused by ink bleeding and moir\u00e9 patterns, their approach introduced a novel way of detecting forgery through visual and structural anomalies.\nWang et al. [118] broadened the scope with a cutting-edge dual-wavelength system. Their solution captured a more comprehensive range of palm features by integrating static and dynamic biometrics through multispectral imaging. Yao et al. [119] introduced domain generalization into palmprint anti-spoofing research and constructed a novel, large-scale palmprint attack dataset. This dataset serves as a valuable resource for training and evaluating anti-spoofing algorithms.\nLately, Datwase et al. [120] proposed a DL-based approach utilizing a multispectral database to identify spoofed palmprint images. This method leverages the rich information from multiple spectral bands to enhance detection accuracy. Building upon this, Liu et al. [121] introduced a domainadaptive algorithm for cross-domain palmprint anti-spoofing scenarios. By adapting to variations across different domains, this algorithm improves the robustness of spoof detection in diverse environments."}, {"title": "VI. OTHER PALMPRINT RECOGNITION TASKS", "content": "A. Cross-Domain Palmprint Recognition\nCross-domain palmprint recognition tackles the challenge of identifying palmprints accurately across diverse datasets or environments, where variations in factors like lighting, resolution, and imaging devices introduce domain shifts. This field ensures robust and precise recognition by addressing these discrepancies between the enrolled and query palmprint images. Cross-spectral palmprint recognition is a subset of this domain, which focuses on matching images captured under different spectral conditions, such as near-infrared (NIR) and visible light.\nRuan et al. [122", "123": "introduced PalmGAN, which leverages CycleGAN to generate synthetic images mimicking the target domain, enabling unsupervised recognition through a supervised deep hashing network. Both methods aim to mitigate the challenges posed by domain shifts due to variations in lighting, device differences, and environmental factors. Expanding on these advancements, Shao et al. [124", "125": "introduced the palmprint translation convolutional neural network (PT-net), which translates NIR images into blue spectrum images to address spectral variance. Similarly, Fei et al. [126", "127": "addressed cross-spectral domain adaptation by employing low-rank canonical correlation analysis (LR-CCA). This technique identifies shared subspaces to capture similarities across spectral data and has demonstrated efficacy in"}]}