{"title": "A Contextual Combinatorial Bandit Approach to Negotiation", "authors": ["Yexin Li", "Zhancun Mu", "Siyuan Qi"], "abstract": "Learning effective negotiation strategies poses two key challenges: the exploration-exploitation dilemma and dealing with large action spaces. However, there is an absence of learning-based approaches that effectively address these challenges in negotiation. This paper introduces a comprehensive formulation to tackle various negotiation problems. Our approach leverages contextual combinatorial multi-armed bandits, with the bandits resolving the exploration-exploitation dilemma, and the combinatorial nature handles large action spaces. Building upon this formulation, we introduce NegUCB, a novel method that also handles common issues such as partial observations and complex reward functions in negotiation. NegUCB is contextual and tailored for full-bandit feedback without constraints on the reward functions. Under mild assumptions, it ensures a sub-linear regret upper bound. Experiments conducted on three negotiation tasks demonstrate the superiority of our approach.", "sections": [{"title": "1. Introduction", "content": "Negotiation serves as a fundamental process that underpins interaction among diverse agents across a wide spectrum of domains, ranging from diplomacy (Paquette et al., 2019; FAIR et al., 2022) and resource allocation (Lewis et al., 2017; Cao et al., 2018) to trading (Bagga et al., 2020). In these scenarios, an agent, represented as negotiator a, engages in negotiation with various counterparts g, with its state evolving. At each time step, negotiator a proposes a bid and receives feedback indicating whether the counterpart g accepts or rejects the proposal. Successful acceptance leads to a deal, while rejection leads to termination or further negotiation, possibly with counter-proposals from the counterpart. These negotiations can vary in form, and Figure 1 illustrates three representative negotiation problems: trading, resource allocation, and multi-issue negotiation. As negotiation experiences accumulate, an agent should continuously improve its negotiation ability.\nHowever, effectively exploiting past experiences in subsequent negotiations is challenging in the following aspects. Exploration-exploitation dilemma: As counterparts vary and the agent's state evolves, over-exploiting historical data may result in sub-optimal performance, while excessive exploration may make the counterpart lose patience. Existing works on negotiation (Lewis et al., 2017; Liu & Zheng, 2020; Sengupta et al., 2022) tend to neglect exploration, primarily focusing on exploitation, or simply explore by UCT (Buron et al., 2019), without considering observable contexts. Large action spaces: Consider a trading task in which our negotiator possesses items \\(V_1\\) while the counterpart holds items \\(V_2\\). The potential bid can be any subset of the union \\(V = V_1 \\cup V_2\\), resulting in \\(2^{|V|}\\) possible choices. Some studies (Cao et al., 2018; Bakker et al., 2019; Bagga et al., 2020) employ reinforcement learning to acquire negotiation strategies, but they primarily focus on tasks involving action spaces limited to a few hundred discrete actions or low-dimensional continuous action spaces. Partial observations: The profiles of counterparts, including their preferences and desires, cannot be fully observed. Relying solely on observable contexts for negotiation can be ineffective. Complicated acceptance functions: Inferring the likelihood of the counterpart accepting a bid remains challenging, even when their hidden states are known.\nIn this paper, we formulate negotiation problems using contextual combinatorial multi-armed bandits (Li et al., 2010; Chen et al., 2013; Qin et al., 2014; Wen et al., 2015; Chen et al., 2018; Agarwal et al., 2021; Nie et al., 2022) to address the exploration-exploitation dilemma and handle the large action spaces of combinatorial cardinality. Although negotiation involves a series of actions, unlike in reinforcement learning, where actions may lead to state transitions, bid actions in negotiation do not inherently trigger such transitions. Agents accumulate knowledge about their counterparts through interactions. Consequently, the bandit-based formulation is well-suited for negotiation problems.\nIn our formulation, an arm denotes an item involved in the negotiation, while a super arm signifies a bid composed of multiple items. The term acceptance is specifically designated to represent the reward, with a value of 1 assigned when the counterpart accepts the bid and 0 assigned in the case of rejection. Consequently, our primary objective is the systematic selection of super arms to gain a comprehensive understanding of the expected acceptance of each super arm while ensuring a substantial cumulative benefit in the long run. This formulation involves full-bandit feedback, where information regarding the acceptance of individual items within the bid remains inaccessible, and only an aggregate acceptance value for the entire bid is available. Otherwise, the feedback is referred to as semi-bandit. Presently, most works (Qin et al., 2014; Wen et al., 2015; Chen et al., 2018; Hwang et al., 2023) on combinatorial bandits rely on semi-bandit feedback. Although there are works (Rejwan & Mansour, 2020; Agarwal et al., 2021; Nie et al., 2022; Fourati et al., 2023) that consider full-bandit feedback, they are non-contextual and often subject to specific constraints.\nBuilding upon the above formulation, we propose a contextual algorithm for full-bandit feedback, named Negotiation UCB (NegUCB), to learn negotiation strategies and adeptly address the exploitation-exploration dilemma and the challenge of large action spaces. Moreover, NegUCB incorporates hidden states to tackle the issue of partial observations and handles diverse acceptance functions through kernel regression (Schulz et al., 2018; Vakili et al., 2023). Under mild assumptions, NegUCB's regret upper bound is guaranteed to be sub-linear with respect to the number of negotiation steps and independent of the bid cardinality, distinguishing itself from existing works on either semi-bandit or full-bandit feedback.\nIn summary, this paper makes three major contributions. First, we provide a comprehensive formulation for diverse types of negotiation problems in \u00a7 3.1. Second, we propose NegUCB to learn negotiation strategies, effectively addressing the prevalent challenges in negotiation in \u00a7 3.2. Lastly, we provide theoretical insights in \u00a7 3.3 and conduct experiments on representative negotiation tasks in \u00a7 4, highlighting the advantages and effectiveness of our method."}, {"title": "2. Related Work", "content": "Deep reinforcement learning has been applied to learning negotiation strategies. For instance, Rodriguez-Fernandez et al. (Rodriguez-Fernandez et al., 2019) adopt a DQN-based model (Mnih et al., 2015) to solve the contract negotiation problem characterized by discrete state and action spaces. Lewis et al. (Lewis et al., 2017) combine supervised learning with reinforcement learning to acquire negotiation strategies in a resource allocation task. RLBOA (Bakker et al., 2019) discretizes continuous action and state spaces and employs tabular Q-learning to learn bidding strategies, although it may encounter issues related to the curse of dimensionality. ANEGMA (Bagga et al., 2020) uses actor-critic (Bhatnagar et al., 2009) to mitigate the dimensionality challenge. Cao et al. (Cao et al., 2018) design two communication protocols to explore the emergence of communication when two agents negotiate. However, these approaches struggle to handle large discrete action spaces (Dulac-Arnold et al., 2016) and often give minimal consideration to exploration.\nSome studies investigate alternative approaches to negotiation. For instance, Buron et al. learn bidding strategies relying on Monte Carlo tree search (Buron et al., 2019). A decision tree-based negotiation assistant (Liu & Zheng, 2020) is specifically designed to predict prices in a car trading platform. Sengupta et al. (Sengupta et al., 2022) demonstrate a transfer learning-based solution to adapt base negotiation strategies to new counterparts rapidly. Cicero (FAIR et al., 2022) achieves mastery in the game of Diplomacy by integrating reinforcement learning with a language model. Nevertheless, these approaches deal with highly specific problems or issues in negotiation, yet they have not effectively tackled the prevalent challenges discussed above."}, {"title": "2.2. Multi-Armed Bandits", "content": "LinUCB (Li et al., 2010) has been introduced to formulate recommendation as a contextual bandit problem, assuming linearity in the reward concerning user and item contexts. It has demonstrated effective performance in recommendation and guarantees a sub-linear regret bound (Chu et al., 2011). FactorUCB (Wang et al., 2017) also makes a linearity assumption but considers hidden features alongside the observable contexts, leading to an improved click rate in recommendation. To overcome the linearity assumption in contextual bandits, KernelUCB (Valko et al., 2013; Chowdhury & Gopalan, 2017) transforms contexts into a high-dimensional space and applies LinUCB in this new space. Neural-UCB (Zhou et al., 2020) attempts to leverage deep neural networks to capture the relationship between contexts and rewards. However, its computational complexity makes it challenging to generalize to real tasks.\nCUCB (Chen et al., 2013) establishes a general framework for combinatorial multi-armed bandits. C2UCB (Qin et al., 2014) and ComLinUCB (Wen et al., 2015) incorporate contexts into combinatorial bandits based on the same linearity assumption as LinUCB. CC-MAB (Chen et al., 2018) focuses on problems with volatile arms and submodular reward functions. CN-UCB (Hwang et al., 2023) employs neural networks to address contextual combinatorial bandit problems, facing the computational limitation as Neural-UCB. However, these algorithms operate within semi-bandit feedback. Another relevant setting is the full-bandit feedback, in which rewards for individual arms are inaccessible. Algorithms designed for full-bandit feedback include CSAR (Rejwan & Mansour, 2020), DART (Agarwal et al., 2021), ETCG (Nie et al., 2022), and RGL (Fourati et al., 2023). However, their reward functions adhere to linearity or sub-modularity, and none of them consider contexts. In contrast, NegUCB is contextual, combinatorial, and tailored for full-bandit feedback without constraints on the reward functions. A comparative analysis is presented in Table 1."}, {"title": "3. Methodology", "content": "Unless otherwise specified, uppercase symbols represent sets, bold uppercase symbols denote matrices, bold lowercase symbols represent vectors, and lowercase symbols denote scalars or functions. \\(I_d\\) refers to an identity matrix with dimensions \\(d \\times d\\), and \\(0_d\\) represents a zero vector of size \\(d \\times 1\\). Kronecker product is denoted as \\(\\otimes\\). Frobenius norm of a matrix and the \\(l_2\\) norm of a vector are respectively denoted as \\(||X||_F\\) and \\(||x||\\). Mahalanobis norm of a column vector \\(x\\) based on matrix \\(A\\) is denoted as \\(||x||_A = \\sqrt{x^T A x}\\). \\(\\text{vec}(A)\\) is the vectorization operator of matrix \\(A\\)."}, {"title": "3.1. Negotiation Formulation", "content": "In this section, we provide a comprehensive formulation that applies to various types of negotiation problems. First, we outline the negotiation framework, detailing the strategy for making proposals when it is our turn to bid and the criteria for deciding whether to accept or reject a bid from the counterpart. Next, we formulate the critical component within this framework."}, {"title": "3.1.1. NEGOTIATION FRAMEWORK", "content": "Denote the pool of the counterpart negotiators as \\(\\mathcal{U}\\), with a cardinality of \\(|\\mathcal{U}| = m\\). The item pool is represented as \\(\\mathcal{V}\\), where \\(|\\mathcal{V}| = n\\). It is essential to acknowledge that negotiation with a new counterpart may occur at any time, leading to an increase in \\(m\\) over time. Additionally, new items may be added to \\(\\mathcal{V}\\). Without loss of generality, we assume these two pools \\(\\mathcal{U}\\) and \\(\\mathcal{V}\\) to be constant. At time step \\(\\tau\\), our negotiator has a valid bid set \\(\\mathcal{B}\\), encompassing all feasible bids it can propose at this time. For example, in a trading task, a bid specifies which items our negotiator proposes to give to the counterpart and which items it requests in return. The validity of a bid is determined by whether our negotiator possesses the items it proposes to give. More designation of bids under various negotiation scenarios will be elaborated later.\nFor a valid bid \\(b \\in \\mathcal{B}\\) of our negotiator at time \\(\\tau\\), the acceptance function \\(r_\\tau\\) assesses whether the counterpart may accept or reject the bid, denoted by \\(r_\\tau(b) = 1\\) or \\(r_\\tau(b) = 0\\). This function is unknown and needs to be learned. Additionally, there exists a benefit function \\(f\\), that measures the potential benefit of the bid to our negotiator, a metric highly dependent on the specific problem. Consequently, the optimal bid for our negotiator to propose at time step \\(\\tau\\) is determined by Equation 1, aiming to maximize its expected benefit. During negotiation, if our negotiator intends to propose a bid, it chooses a valid bid using Equation 1. Supposing our negotiator receives a bid \\(b\\) from the counterpart, it is evident that \\(r_\\tau(b) = 1\\); thus, our negotiator decides whether to accept the bid by evaluating if the bid is valid and optimal after setting \\(r_\\tau(b) = 1\\).\n\\[b = \\arg \\max_b \\{ r_\\tau(b) \\times f_\\tau(b) \\}\\]\t(1)"}, {"title": "3.1.2. ACCEPTANCE FUNCTION", "content": "As the benefit function \\(f_\\tau\\) is dependent on the specific problem and crafted manually, it is not the primary focus of this work. Instead, we focus on learning the acceptance function \\(r\\) using contextual combinatorial multi-armed bandits (Chen et al., 2013; Qin et al., 2014; Wen et al., 2015; Chen et al., 2018; Nie et al., 2022), where arms represent items in \\(\\mathcal{V}\\), super arms denote bids, and rewards are the acceptance labels. Consequently, the objective is to iteratively put forth beneficial bids to understand the expected acceptance of each bid by various counterparts while ensuring a substantial cumulative benefit in the long run. In the following, we review the details based on Figure 2.\nItems in pool \\(\\mathcal{V}\\) have contexts denoted as row vectors \\(\\{ y_w | w = 1, 2, ..., n \\}\\), collectively forming an item context matrix \\(Y = [y_1; y_2; \\dots; y_n]\\), as depicted in Figure 2 (a). At time step \\(\\tau\\), our negotiator and the counterpart form a negotiator pair, characterized by contexts denoted as a row vector \\(x\\), as depicted in Figure 2 (b). It is worth noting that \\(x_\\tau\\) corresponds to one of the \\(m\\) counterparts in \\(\\mathcal{U}\\). In other words, it is a row of the negotiator context matrix \\(X = [x_1; x_2; \\dots; x_m]\\). In this work, we use \\(x\\) or \\(x_w\\), \\(w = 1, 2, ..., m\\), interchangeably to either highlight the time step or the counterpart index. Addressing the partial observation issue, we assume hidden states \\(\\mathcal{U} = [u_1; u_2; \\dots; u_m]\\) for the \\(m\\) negotiator pairs. Then the acceptance function \\(r_\\tau\\) at time step \\(\\tau\\) is estimated through Equation 2, where \\(\\Theta\\) in the first term represents the function parameters, \\(u\\) in the second term signifies the hidden state of the current negotiator pair. Specifically, the first term estimates the partial acceptance of the bid based on observed contexts, while the second term evaluates the partial acceptance of the bid based on hidden states.\n\\[r_\\tau(b_\\tau) = \\langle \\Theta, \\phi(x_\\tau) \\otimes \\psi(Y, b_\\tau) \\rangle + u_w^T \\psi(Y, b_\\tau) \\tag{2}\\]\n\\[\\psi(Y, b_\\tau) = \\phi(\\phi(Y, b_\\tau)) \\tag{3}\\]\nIn the first term of Equation 2, function \\(\\phi\\) transforms context \\(x\\) into a \\(h\\)-dimensional space \\(\\mathcal{H}\\) where \\(h\\) can be infinite. \\(\\psi(Y, b)\\) is expressed in Equation 3, where function \\(\\psi\\) extracts the context of bid \\(b\\) from the item context matrix \\(Y\\). A possible example of \\(\\psi\\) is provided in Figure 2 (c). Following this, function \\(\\phi\\) further transforms the bid context into a high-dimensional representation within space \\(\\mathcal{H}\\). Specifically, function \\(\\phi\\) transforms contexts into high-dimensional representations, allowing the acceptance function to operate non-linearly concerning the observed contexts.\nGiven historical negotiation data from step \\(1, 2, ..., \\tau\\), we aim to optimize the following objective function to derive functions \\(\\phi\\) and \\(\\psi\\), parameters \\(\\Theta\\) and hidden states \\(\\mathcal{U}\\), then use them for the subsequent time step \\(\\tau + 1\\). \\(\\lambda_1\\) and \\(\\lambda_2\\) are hyper-parameters for the regularization terms, \\(r_t\\) represents the actual acceptance at time \\(t\\), as depicted in Figure 2 (d), and \\(\\hat{r}_t\\) denotes the acceptance estimated by Equation 2.\n\\[\\min_{\\psi, \\phi, \\Theta, \\mathcal{U}} \\mathcal{L} = \\sum_{t=1}^T |r_t - \\hat{r}_t|^2 + \\lambda_1 ||\\Theta||^2 + \\lambda_2 ||\\mathcal{U}||^2 \\tag{4}\\]"}, {"title": "3.2. Negotiation UCB", "content": "In this subsection, building upon the above formulation, we introduce the NegUCB algorithm, a simple yet effective approach. In this algorithm, bids are represented as indicator vectors indicating the items involved in each bid. Please refer to \u00a7 B.2 for detailed examples.\nSince simultaneously deriving the functions \\(\\phi\\) and \\(\\psi\\), as well as the parameters \\(\\Theta\\) and \\(\\mathcal{U}\\) is challenging, we assume the format of the function \\(\\psi\\) in Assumption 3.1. In \u00a7 3.2.1, we provide the closed-form solutions for \\(\\Theta\\) and \\(\\mathcal{U}\\), which depend on function \\(\\phi\\). In \u00a7 3.2.2, we use kernel regression (Schulz et al., 2018) to eliminate the dependency on function \\(\\phi\\). At last, we summarize the NegUCB algorithm in \u00a7 3.2.3.\nAssumption 3.1. If the contexts of items are characterized by their basic features, the extraction function \\(\\psi\\) in Equation 5 can accurately capture the context of bid \\(b\\). In other words, it encompasses substantial information about the items included in the bid.\n\\[\\psi(Y, b) = Y^T b \\tag{5}\\]\nDespite the linearity assumption on \\(\\psi\\), the acceptance function is non-linear because of the transforming function \\(\\phi\\."}, {"title": "3.2.1. PARAMETERS", "content": "Obviously, the objective function \\(\\mathcal{L}\\) is not jointly convex concerning both \\(\\Theta\\) and \\(\\mathcal{U}\\). However, it is convex concerning one parameter if the other one is fixed. Therefore, we employ an alternative least square optimization approach, iterating the calculation of one parameter with a closed-form solution while keeping the other parameter fixed. Based on Assumption 3.1, the closed-form solution for \\(\\Theta\\) is as Equation 6, while that for \\(\\mathcal{U}\\) is as Equation 7.\n\\[\\text{vec}(\\Theta) = (A_\\tau^T A_\\tau + \\lambda_1 I_{h^2})^{-1} A_\\tau^T (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U})) \\tag{6}\\]\n\\[\\text{vec}(\\mathcal{U}) = (D_\\tau^T D_\\tau + \\lambda_2 I_{mh})^{-1} D_\\tau^T (r_\\tau - A_\\tau \\text{vec}(\\Theta)) \\tag{7}\\]\nRows of matrices \\(A_\\tau\\) and \\(D_\\tau\\) are samples as \\(\\phi(b_t Y) \\otimes \\phi(x_t)\\) and \\(\\phi(b_t Y) \\otimes p_t\\) where \\(p_t \\in \\mathbb{R}^{1 \\times m}\\) is a one-hot vector representing the counterpart index at time step \\(t = 1, 2, ..., T\\). It is evident that the solutions for parameters \\(\\Theta\\) and \\(\\mathcal{U}\\) are contingent on the transformation function \\(\\phi\\), which can take various forms, such as polynomial functions, neural networks, etc., and thus needs to be learned."}, {"title": "3.2.2. TRANSFORMATION FUNCTION", "content": "Given the limited amount of negotiation data with various counterparts, learning \\(\\phi\\) becomes intractable if it involves many parameters, such as in the case of neural networks. In NegUCB, we utilize Reproducing Kernel Hilbert Spaces within kernel functions to avoid the need for learning \\(\\phi\\), enhancing efficiency. Moreover, since iterating among three components, i.e., learning \\(\\phi\\), \\(\\mathcal{U}\\), and \\(\\Theta\\), is highly unstable, NegUCB iterates between learning \\(\\mathcal{U}\\) and \\(\\Theta\\), significantly improving the learning stability.\nCorresponding to matrices \\(A_\\tau\\) and \\(D_\\tau\\) dependent on function \\(\\phi\\), we define matrices \\(K_\\tau\\) and \\(Z_\\tau\\). Each entry \\((K_\\tau)_{t,j}\\) and \\((Z_\\tau)_{t,j}\\) are the dot product of the \\(t\\)-th and \\(j\\)-th samples of \\(A_\\tau\\) and \\(D_\\tau\\), respectively. By Assumption 3.2, we can calculate \\(K_\\tau\\) and \\(Z_\\tau\\) without knowing \\(\\phi\\).\nAssumption 3.2. Each entry of \\(K\\) and \\(Z\\) can be calculated by Equation 8 and Equation 9 respectively, where \\(t, j = 1, 2, ..., T\\), and \\(\\kappa_1\\) and \\(\\kappa_2\\) are two kernel functions.\n\\[(K_\\tau)_{t,j} = \\kappa_1(x_t, x_j) \\times \\kappa_1(\\phi(b_t Y), \\phi(b_j Y)) \\tag{8}\\]\n\\[(Z_\\tau)_{t,j} = \\begin{cases} \\kappa_2(\\phi(b_t Y), \\phi(b_j Y)) & p_t = p_j \\\\ 0 & p_t \\neq p_j \\end{cases} \\tag{9}\\]\nDenoting the above entry values as \\(k_{tj}\\) and \\(z_{tj}\\), then the kernel vectors at time step \\(\\tau\\) are \\(k_\\tau = (k_{1\\tau}, k_{2\\tau}, ..., k_{\\tau,\\tau})^T\\) and \\(z_\\tau = (z_{1\\tau}, z_{2\\tau}, ..., z_{\\tau,\\tau})^T\\), and \\(K_\\tau\\) and \\(Z_\\tau\\) are the kernel matrices. Based on Assumption 3.2, we have Lemma 3.3 to approximate the acceptance function.\nLemma 3.3. Instead of learning transformation function \\(\\phi\\), parameters \\(\\Theta\\) and \\(\\mathcal{U}\\), and then estimating \\(r_{\\tau+1}(b)\\) by Equation 2, it is equivalent to iterate Equation 10 and Equation 11, then estimate \\(r_{\\tau+1}(b)\\) using Equation 12. Specifically, \\(k_{\\tau+1} = k_{\\tau+1}[1 : T]\\) and \\(z_{\\tau+1} = z_{\\tau+1}[1 : T]\\), which are \\(k_{\\tau+1}\\) and \\(z_{\\tau+1}\\) without their last entries.\n\\[A_\\tau \\text{vec}(\\Theta) = K_\\tau (K_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U})) \\tag{10}\\]\n\\[D_\\tau \\text{vec}(\\mathcal{U}) = Z_\\tau (Z_\\tau + \\lambda_2 I_\\tau)^{-1} (r_\\tau - A_\\tau \\text{vec}(\\Theta)) \\tag{11}\\]\n\\[\\hat{r}_{\\tau+1}(b) = k_{\\tau+1}^T (K_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U})) + z_{\\tau+1}^T (Z_\\tau + \\lambda_2 I_\\tau)^{-1} (r_\\tau - A_\\tau \\text{vec}(\\Theta)) \\tag{12}\\]\nConsidering the definitions of \\(A_\\tau\\) and \\(D_\\tau\\), it is evident that \\(A_\\tau \\text{vec}(\\Theta)\\) and \\(D_\\tau \\text{vec}(\\mathcal{U})\\) are partial acceptances corresponding to the two terms in Equation 2 for historical time steps \\(t = 1,2,..., \\tau\\). From the iteration results, the two terms in Equation 12 estimate the respective terms in Equation 2 for the subsequent time step \\(\\tau + 1\\)."}, {"title": "3.2.3. NEGUCB ALGORITHM", "content": "For the subsequent time step \\(\\tau + 1\\), we can estimate \\(\\hat{r}_{\\tau+1}(b)\\) for each bid \\(b \\in \\mathcal{B}_{\\tau+1}\\) using Equation 12, then choose a bid to put forth or decide to accept or reject the bid from the counterpart by Equation 1. However, this approach relies solely on exploiting historical data, which may lead to sub-optimal choices. Hence, we explore the estimation uncertainty based on the Upper Confidence Bound principle (Li et al., 2010; Valko et al., 2013; Liu et al., 2018).\nInstead of Equation 1, we make decisions by Equation 13, where \\(e_{\\tau+1}\\) measures the estimation variance and is expressed in Equation 14. Parameters \\(\\alpha_\\Theta\\) and \\(\\alpha_\\mathcal{U}\\) are elaborated in Lemma 3.4. For notation conciseness, we use \\(k_{\\tau+1}\\) and \\(z_{\\tau+1}\\) to denote \\(k_{\\tau+1,\\tau+1}\\) and \\(z_{\\tau+1,\\tau+1}\\).\n\\[b_{\\tau+1} = \\arg \\max_b \\{ \\hat{r}_{\\tau+1}(b) + e_{\\tau+1}(b) \\} \\times f_{\\tau+1}(b) \\tag{13}\\]\n\\[e_{\\tau+1}(b) = \\sqrt{\\frac{\\alpha_\\Theta}{T} k_{\\tau+1} - k_{\\tau+1}^T (K_\\tau + \\lambda_1 I_\\tau)^{-1} k_{\\tau+1}} + \\sqrt{\\frac{\\alpha_\\mathcal{U}}{T} z_{\\tau+1} - z_{\\tau+1}^T (Z_\\tau + \\lambda_2 I_\\tau)^{-1} z_{\\tau+1}} \\tag{14}\\]\nIntegrating exploitation and exploration, NegUCB is implemented online as Algorithm 1, where we use \\(a_\\tau\\) and \\(d_\\tau\\) to respectively denote \\(A_\\tau \\text{vec}(\\Theta)\\) and \\(D_\\tau \\text{vec}(\\mathcal{U})\\) for notation conciseness. Online means the parameters are incrementally updated each time new negotiation data is generated. NegUCB essentially iterates between Step 1. Estimating the second term in Equation 2, then calculating the first term; Step 2. Estimating the first term in Equation 2, then calculating the second term."}, {"title": "3.3. Theoretical Analysis to NegUCB", "content": "Lemma 3.4. If the true parameters satisfy \\(||\\Theta^*|| \\le \\beta_\\Theta\\) and \\(||\\mathcal{U}^*|| \\le \\beta_\\mathcal{U}\\), the samples satisfy \\(||\\phi(b_t Y) \\otimes \\phi(x_t)|| \\le 1\\) and \\(||\\phi(b_t Y) \\otimes p_t || \\le 1\\) for \\(t = 1,2, ..., \\tau\\), then with probability at least \\(1 - \\sqrt{\\delta}\\), the two terms in Equation 12 have estimation error bounds \\(\\alpha_\\Theta\\) and \\(\\alpha_\\mathcal{U}\\) as follows. Here \\(h^*\\) and \\(m^*\\) are the effective dimensions of \\(A_\\tau = A_\\tau^T A_\\tau + \\lambda_1 I_{h^2}\\) and \\(D_\\tau = D_\\tau^T D_\\tau + \\lambda_2 I_{mh}\\), \\(p, q \\in (0,1)\\) are constants.\n\\[\\alpha_\\Theta = ||\\text{vec}(\\Theta_\\tau) - \\text{vec}(\\Theta^*)||_{A_\\tau} \\tag{15}\\]\n\\[< \\lambda_1 \\beta_\\Theta + \\sqrt{\\frac{h^*}{T} \\log (1 + \\frac{T}{\\lambda_1 h^*}) - \\log \\delta} + \\frac{2 \\beta_\\mathcal{U}}{\\sqrt{\\lambda_1}} q\\]\n\\[\\alpha_\\mathcal{U} = ||\\text{vec}(\\mathcal{U}_\\tau) - \\text{vec}(\\mathcal{U}^*)||_{D_\\tau} \\tag{16}\\]\n\\[< \\lambda_2 \\beta_\\mathcal{U} + \\sqrt{\\frac{m^*}{T} \\log (1 + \\frac{T}{\\lambda_2 m^*}) - \\log \\delta} + \\frac{2 \\beta_\\Theta}{\\sqrt{\\lambda_2}} p\\]\nIn Lemma 3.4, \\(A_\\tau\\) and \\(D_\\tau\\) correspond to the first item of Equation 6 and Equation 7, respectively. Effective dimension (Valko et al., 2013; Vakili et al., 2021) is a commonly used concept in kernel regression and can be considered as the number of principal dimensions. They contract the bounds as \\(h^* <<< h^2\\) and \\(m^* < mh\\), where h is the dimension of \\(\\mathcal{H}\\). Bounds of each sample \\(\\phi(b_t Y) \\otimes \\phi(x_t)\\) and \\(\\phi(b_t Y) \\otimes p_t\\) are set as 1 for description convenience. They correlate with the number of items in the bid, referred to as the bid cardinality and denoted as \\(\\gamma \\le n \\in \\mathbb{Z}^+\\). We can guarantee the bounds of samples by normalizing the contexts \\(X\\) and \\(Y\\). Based on Lemma 3.4, we guarantee the performance of NegUCB by the following theorem.\nTheorem 3.5. Under the same assumptions as Lemma 3.4, with probability at least \\(1 - \\sqrt{\\delta}\\), the cumulative regret of Algorithm 1 has the following upper bound, where \\(r_t(b^*)\\) and \\(r_t(b_t)\\) are respectively the true acceptance of the optimal bid \\(b^*\\) and the bid chosen by Algorithm 1 at time step \\(t\\). \\(a_f\\) is the union bound of the benefit functions, i.e., \\(|f_t(b)| \\le a_f\\) for \\(b \\in B_t\\) and \\(\\forall t \\in \\{1, 2, ..., T\\}\\).\n\\[\\sum_{t=0}^T r_t(b^*) \\times f_t(b^*) - r_t(b_t) \\times f_t(b_t) < 2 \\alpha_\\Theta a_f \\sqrt{\\frac{2 h^*}{T} \\log (1 + \\frac{T}{\\lambda_1 h^*})} + 2 \\alpha_\\mathcal{U} a_f \\sqrt{\\frac{2 m^*}{T} \\log (1 + \\frac{T}{\\lambda_2 m^*})} \\tag{17}\\]\nIndeed, the cumulative regret is sub-linear concerning the number of time steps \\(T\\). This implies that as the number of negotiation steps increases, the cumulative regret grows at a slower rate, indicating improved negotiation capability. Besides, the bound is independent of the bid cardinality \\(\\gamma\\), distinguishing NegUCB from existing works (Qin et al., 2014; Wen et al., 2015; Chen et al., 2018; Nie et al., 2022; Fourati et al., 2023). It is a result of the full-bandit feedback and Assumption 3.1. The effect from bid cardinality to the cumulative regret bound is further discussed in \u00a7 A.4.1."}, {"title": "4. Experiments", "content": "In this section", "baselines": "ANAC agent 1"}, {"title": "4.1. Multi-issue Negotiation", "content": "ANAC (Automated Negotiating Agents Competition) is an international tournament that has been held since 2010, providing 50 negotiation domains. However, compared to the settings of NegUCB, ANAC tasks are relatively simple. For instance, negotiators and items lack contexts, and there is only one negotiator pair for each domain. Consequently, some components of NegUCB are not necessary for these tasks. In this subsection, we modify NegUCB for compatibility with ANAC tasks, showing the adaptability of NegUCB to diverse negotiation problems. In ANAC experiment, NegUCB does not consider any context and relies on inferring hidden states of negotiators and items from negotiation experiences. Essentially, it degenerates into traditional combinatorial bandits. In contrast, most of the ANAC agents submitted by tournament participants, including the winners (Aydogan et al., 2023), are rule-based.\nOriginal ANAC tasks impose a strict deadline on negotiation, limiting each negotiation pair to a constant number of negotiation steps. Negotiators are aware of this deadline and can strategically utilize it. This setup diverges from our setting in that a negotiator may lose patience at any time, and its counterpart may not be aware of it. Therefore, in this subsection, we redefine the task. First, we eliminate the deadline and investigate the number of rounds needed to reach a deal. Second, we define the constraining set \\(\\mathcal{C}\\) only contains bids whose utilities are larger than the mean utility of all possible bids to our negotiator. Agents achieving a deal in fewer steps are more effective. Based on the insights of the ANAC agents submitted by tournament participants, we modify them to be compatible with the redefined task. Specifically, the ANAC agent we adopt in this experiment randomly selects a valid bid from those with the highest utility rankings for our negotiator.\nWe investigate the number of negotiation steps required to achieve a deal by each algorithm across 50 ANAC domains, specifically from domain 00 to domain 49. For domain 3, domain 4, domain 7, domain 28, domain 37, and domain 38, both algorithms failed to reach a deal in 50 rounds, thus for the sake of conciseness, we show the results on the remaining 44 domains in Figure 3. NegUCB consistently achieves beneficial deals much earlier across almost all ANAC domains. Considering the effectiveness of the simplified NegUCB used in this subsection, it is adopted in place of the ANAC agent in the following experiments for a more appropriate comparison.\nAdditionally, we analyze the action spaces. Considering domain 13 for example, it has 4 issues, each of which has 6, 12, 5, 26 possible values to choose from, then the bid set contains at most \\(6 \\times 12 \\times 5 \\times 26 = 9360\\) choices. Similarly, other domains exhibit comparable action space sizes."}, {"title": "4.2. Resource Allocation", "content": "Motivated by experiments of existing works (Cao et al., 2018), we design a resource allocation task.\nAssume there are three categories of items, and the number of items in each category does not exceed 5. Each item category has a randomly generated context vector denoted as \\(y_j\\), \\(j = 1,2,3\\). A context vector \\(x\\) and a hidden state vector \\(u_w\\) are randomly generated for each of the 30 negotiator pairs. For simplicity, we assume that \\(x_w\\), \\(y_j\\), and \\(u_w\\) are all 2-dimensional, with each entry in the range [0, 1]. The acceptance function is simulated using Equation 2, where the transformation function is as Equation 18. Besides, we draw the parameter matrix \\(\\Theta\\) of size 6 \u00d7 6 from a Gaussian distribution \\(\\mathcal{N}(0, 1)\\). The counterpart accepts the bid if the simulated acceptance \\(\\hat{r}\\) satisfies \\(\\hat{r} > 0\\).\n\\[\\phi(x) = \\frac{1}{\\sqrt{2}} (x_1, x_2, \\frac{x_1^2}{\\sqrt{2}}, \\frac{x_2^2}{\\sqrt{2}}, \\sqrt{2} x_1 x_2) \\tag{18}\\]\nSpecifically, the transformation function is the basis function of polynomial kernel \\(\\kappa(x_w, x_j) = (x_w x_j + 1)^2\\). Furthermore, we define the set \\(\\mathcal{C}\\) contains bids that allow our negotiator to acquire more items than the counterpart.\nFigure 4(a) shows the cumulative theoretical regret for each algorithm under various exploration parameters, i.e., \\(\\alpha_\\Theta = \\{\\alpha_1, \\alpha_2, ..., \\alpha_6\\}\\) summarized in \u00a7 B.3. It is evident that the cumulative theoretical regret for each algorithm decreases initially and then increases, illustrating the advantages of exploration and the drawbacks of over-exploration. Figure 4(b) and Figure 4(c) display the cumulative theoretical regret and cumulative acceptance regret of each algorithm at each time step under their corresponding optimal exploration parameter, respectively. Figure 5 illustrates the acceptance rate of each algorithm under their corresponding optimal exploration parameter. Given the random nature of exploration in reinforcement learning, i.e., e-greedy, we extend the training duration of the reinforcement learning method to 20000 steps to ensure the results accurately reflect its true capabilities. Its final result reaches an acceptance rate lower than 0.6. Refer to \u00a7 B.3 for a detailed insight into its convergence process. From these results, we can observe clear advantages of NegUCB."}, {"title": "4.3. Trading", "content": "CivRealm (Qi et al., 2024) is an interactive environment designed for the open-source strategy game Freeciv. In this environment, multiple players engage in their civilizations' simultaneous development and competition. Alongside elements such as land, population, and economy, each player possesses a technology tree, allowing them to research and acquire the 87 technologies progressively.\nOne crucial feature of CivRealm is its Diplomacy component, enabling players to engage in technology trades. For instance, if our negotiator possesses the technology Chivalry and seeks the technology Astronomy, besides researching it by itself, our negotiator can also acquire it through trading with other players who already possess Astronomy. A negotiation window of CivRealm is as Figure 7. A negotiator can counter-propose or cancel the meeting if they reject the bid. On the other hand, the negotiator can accept the bid by accepting the treaty. In this experiment, \\(b \\in \\mathcal{C}\\) if the total cost of the given technologies is no more than that of the required ones. For practical reasons, we set the bid cardinality as \\(\\gamma = 4\\), with details explained in \u00a7 B.4.\nIn this experiment, we systematically explore SE kernels with diverse hyper-parameters \\(\\sigma\\) to fine-tune the most suitable kernel function for the technology trading task in CivRealm. Based on the results, we conclude that the SE kernel with \\(\\sigma = 1\\) emerges as the most suitable choice for this task. Besides, we tune the exploration rate ranging from 0 to 1 and choose 0.1 as the optimal exploration rate for NegUCB. Please refer to \u00a7 B.4 for more details. Surprisingly, apart from the baselines LinUCB, KernelUCB, and our proposed method NegUCB, other baselines fail to demonstrate improvements with increased exploration. We attribute this observation to the complexity of the task, where inaccurate formulations result in misguided exploration strategies. Figure 6 illustrates the acceptance rates of each algorithm under their corresponding optimal exploration parameters, i.e., 0.1, 0, 0, 0.1, 0.1, affirming the clear advantages of NegUCB. The reinforcement learning method is not utilized in this experiment due to the challenge associated with handling such a large action space, whose cardinality is at most \\(\\sum_{\\gamma=1}^{87} \\binom{87}{\\gamma}\\).\nCase Study. A negotiation case on CivRealm is depicted in Figure 7. Thailand proposed to give Chivalry and seek Astronomy and Seafaring from Portugal with costs of 270, 185, and 112, respectively. The net income for Portugal would be \\(270 - 185 - 112 = -27\\). However, according to the running game, Portugal accepted the bid. It suggests the presence of hidden states that we did not observe, influencing Portugal's decision to accept the bid. Without the hidden state component in NegUCB, we might overlook such bids, substantiating that hidden states play a crucial role in estimating the counterpart's decisions."}, {"title": "5. Conclusion", "content": "This paper introduces a comprehensive formulation for negotiation, grounded in contextual combinatorial multi-armed bandits, capable of encompassing a broad spectrum of real-world negotiation tasks. Building upon this formulation, we propose the NegUCB algorithm as a solution to address the four prevalent challenges in negotiation: the exploitation-exploration dilemma, handling large action spaces, partial observations, and complex acceptance functions. Under mild assumptions, NegUCB ensures a regret upper bound that is sub-linear with respect to the negotiation steps and independent of the bid cardinality. A series of experiments on diverse negotiation tasks validate NegUCB's effectiveness and advantages in learning negotiation strategies."}, {"title": "A. Proofs", "content": "In this section, we first provide a derivation of the closed-form solutions in Appendix A.1, then we provide the proofs of Lemma 3.3, Lemma 3.4 and Theorem 3.5 in Appendix A.2, Appendix A.3, and Appendix A.4, respectively."}, {"title": "A.1. Derivation of Closed-form Solutions", "content": "Under Assumption 3.1, the approximated acceptance function and objective function are respectively:\n\\[\\hat{r}_\\tau(b_\\tau) = \\langle \\phi(x_\\tau), \\Theta \\phi(Y^T b_\\tau) \\rangle + p_\\tau \\mathcal{U} \\phi(Y^T b_\\tau)\\]\n\\[\\mathcal{L} = \\sum_{t=1}^T |\\langle \\phi(x_t), \\Theta \\phi(Y^T b_t) \\rangle + p_t \\mathcal{U} \\phi(Y^T b_t) - r_t|^2 + \\lambda_1 ||\\Theta||^2 + \\lambda_2 ||\\mathcal{U}||^2\\]\nBased on basic linear algebra, we can derive the closed-form solutions of \\(\\Theta\\) and \\(\\mathcal{U}\\) easily (Li et al., 2010; Wang et al., 2017). The core method we employ in the derivation relies on the conclusion that \\(a B c^T = (c \\otimes a) \\text{vec}(B)\\), where \\(a\\) and \\(c\\) denote any two row-vectors, and \\(B\\) denotes any matrix, provided that their sizes match."}, {"title": "A.2. Proof of Lemma 3.3", "content": "Proof in this subsection directly uses the closed-form solutions in Equation 6 and Equation 7.\nProof. According to the closed-form solution in Equation 6, we have the following equation.\n\\[(A_\\tau^T A_\\tau + \\lambda_1 I_{h^2}) \\text{vec}(\\Theta) = A_\\tau^T (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}))\\]\n\\[\\Rightarrow \\text{vec}(\\Theta) = \\frac{1}{\\lambda_1} (A_\\tau^T (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U})) - A_\\tau^T A_\\tau \\text{vec}(\\Theta))\\]\n\\[= \\frac{1}{\\lambda_1} (A_\\tau^T (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U})) - A_\\tau A_\\tau^T \\text{vec}(\\Theta))\\]\nDenote \\(\\alpha = \\frac{1}{\\lambda_1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}) - A_\\tau \\text{vec}(\\Theta))\\), thus there is \\(\\text{vec}(\\Theta) = A_\\tau^T \\alpha\\). Integrating these two equations:\n\\[\\Rightarrow \\alpha = \\frac{1}{\\lambda_1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}) - A_\\tau A_\\tau^T \\alpha)\\]\n\\[\\Rightarrow \\alpha = (A_\\tau^T A_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}))\\]\n\\[\\Rightarrow \\text{vec}(\\Theta) = A_\\tau^T \\alpha = A_\\tau^T (A_\\tau^T A_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}))\\]\nFrom the definition of rows of matrix \\(A_\\tau\\), we have:\n\\[(A_\\tau A_\\tau^T)_{tj} = ((\\phi(b_t Y) \\otimes \\phi(x_t)) ((\\phi(b_j Y) \\otimes \\phi(x_j))^T\\]\n\\[= (\\phi(b_t Y) (\\phi(b_j Y))^T) \\times ((\\phi(x_t) \\otimes \\phi(x_j))\\]\n\\[= \\kappa_1(\\phi(b_t Y), \\phi(b_j Y)) \\times \\kappa_1(x_t, x_j) = (K_\\tau)_{tj}\\]\nThe second equality above is from the fact that any row vectors \\(v_1, v_2, v_1, v_2\\) satisfy \\((v_1 v_1) (v_2 v_2) = (v_1 v_2) (v_1 v_2)^T\\). As a result, we can derive \\(A_\\tau \\text{vec}(\\Theta)\\) as follows.\n\\[A_\\tau \\text{vec}(\\Theta) = A_\\tau A_\\tau^T (A_\\tau^T A_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}))\\]\n\\[= K_\\tau (K_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}))\\]"}, {"title": "A.3. Proof of Lemma 3.4", "content": "Denote \\(A_\\tau = A_\\tau^T A_\\tau + \\lambda_1 I_{h^2}\\) and \\(D_\\tau = D_\\tau^T D_\\tau + \\lambda_2 I_{mh}\\). \\(\\Theta^*\\) is the true parameter while \\(\\Theta_\\tau\\) is the parameter estimated at time step \\(\\tau\\). \\((\\phi(b_t Y) \\otimes \\phi(x_t))\\) is the sample at time step \\(t = 1, 2, ..., \\tau\\).\nProof. The error of the estimated partial acceptance based on contexts corresponding to \\((\\phi(b_{\\tau+1} Y) \\otimes \\phi(x_{\\tau+1}))\\) is as follows.\n\\[|k_{\\tau+1}^T (K_\\tau + \\lambda_1 I_\\tau)^{-1} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U})) - ((\\phi(b_{\\tau+1} Y) \\otimes (x_{\\tau+1})) \\text{vec}(\\Theta^*)| \\\\\n\\[< ||(\\phi(b_{\\tau+1} Y) \\otimes (x_{\\tau+1}))|| \\\\ |\\text{vec}(\\Theta_{\\tau}) - \\text{vec}(\\Theta^*)\\||_{A_\\tau}\\\\\n\\[< ||\\text{vec}(\\Theta_{\\tau}) - \\text{vec}(\\Theta^*)\\||_{A_\\tau}\\\\\n\\[= ||A_\\tau^{1/2} (\\text{vec}(\\Theta_{\\tau}) - \\text{vec}(\\Theta^*))|| \\\\\n\\[= ||A_\\tau^{1/2} (A_\\tau^{T} (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}_{\\tau-1}))) - (A_\\tau^T A_\\tau + \\lambda_1 I_{h^2}) \\text{vec}(\\Theta^*)|||\\\n\\[= || A_\\tau^{1/2} (A_\\tau^T (r_\\tau - D_\\tau \\text{vec}(\\mathcal{U}_{\\tau-1}))) - A_\\tau^T A_\\tau \\text{vec}(\\Theta^*) + \\lambda_1 \\text{vec}(\\Theta^*) || \\\\\n\\[= ||A_\\tau^{1/2} D_\\tau \\text{vec}(\\mathcal{U}) - A_\\tau D_\\tau \\text{vec}(\\mathcal{U}_{\\tau-1}) + A_\\tau^T e_{\\tau} - \\lambda_1 \\text{vec}(\\Theta^*)|||\\\n\\[< ||A_\\tau D_\\tau (\\text{vec}(\\mathcal{U}) - \\text{vec}(\\mathcal{U}_{\\tau-1}) || + ||A_\\tau^{1/2} A_\\tau^T e_{\\tau} || + ||\\lambda_1 \\text{vec}(\\Theta^*)||\\]\nThe first inequality holds when the minimum eigenvalue of \\(A_{\\tau}\\) is at least 1. The term \\(e_{\\tau}\\) accounts for sub-Gaussian noise to the acceptance function. Now, consider the first term above:\n\\[||A_\\tau D_\\tau (\\text{vec}(\\mathcal{U}) - \\text{vec}(\\mathcal{U}_{\\tau-1}))||\\]\n\\[< \\frac{1}{\\sqrt{\\lambda_1}} || D_\\tau (\\text{vec}(\\mathcal{U}) - \\text{vec}(\\mathcal{U}_{\\tau-1}))||\\]\n\\[= \\frac{1}{\\sqrt{\\lambda_1}} \\sum_{t=1}^T |(\\phi(b_t Y) \\otimes p_t) (\\text{vec}(\\mathcal{U}) - \\text{vec}(\\mathcal{U}_{\\tau-1})) ||\\]\n\\[< \\frac{1}{\\sqrt{\\lambda_1}} \\sum_{t=1}^T ||\\text{vec}(\\mathcal{U}) - \\text{vec}(\\mathcal{U}_{\\tau-1})||\\\\\n\\[= \\frac{1}{\\sqrt{\\lambda_1}} \\sum_{t=1}^T ||\\text{vec}(\\mathcal{U}) - \\text{vec}(\\mathcal{U}_{0})|| \\times q^{t-1}\\]\n\\[< \\frac{2 \\beta_\\Theta}{\\sqrt{\\lambda_1}} \\frac{1}{1 - q}\\]\n\\[= \\frac{2 \\beta_\\Theta}{\\sqrt{\\lambda_1} (1 - q)}\\]\nThe second inequality holds because Algorithm 1 updates parameters online. The fourth inequality is based on Uschmajew's work (Uschmajew, 2012; Wang et al., 2017), that the estimation of \\(\\mathcal{U}\\) is local q-linearly convergent to the optimizer."}, {"title": "A Contextual Combinatorial Bandit Approach to Negotiation", "content": "Specifically, in the above inequations, parameter q satisfies \\(0 < q < 1\\). For conciseness, we denote \\((1 - q) \\in (0, 1)\\) as \\(q \\in (0, 1)\\) in Lemma 3.4. Some works (Liu et al., 2018) simply assume \\([D_\\tau^T (\\text{vec}(\\mathcal{U}^*) - \\text{vec}(\\mathcal{U}_{t-1}))]_{A_\\tau^{-1}} = 0\\) considering \\(\\mathcal{U}_{t-1} \\to \\mathcal{U}^*\\) when \\(t\\to \\infty\\).\nFor the second term, we leverage the properties of self-normalized vector-valued martingales (Yadkori et al., 2011). Assuming \\(e_{\\tau}\\) belongs to a 1-sub-Gaussian process, then with probability at least \\(1 - \\sqrt{\\delta}\\), there is the following inequality:\n\\[||A_\\tau^{1/2} A_\\tau^T e_{\\tau}|| < \\sqrt{\\frac{h^*}{T} \\log ( \\frac{\\text{det}(A_{\\tau})}{\\text{det}(\\lambda_1 I_{h^2})} )}\\]\nBecause of the Determinant-trace inequality, we have:\n\\[\\frac{\\text{det}(A_{\\tau})}{\\text{det}(\\lambda_1 I_{h^2})} \\le (\\frac{\\text{trace}(A_{\\tau})}{h^*})^* (\\frac{\\lambda_1}{h^*})^\\Rightarrow\\]\n\\[\\text{det}(A_{\\tau}) \\approx (\\text{trace}(A_{\\tau})){h^*-h} \\times \\lambda_1^{h^2-h} \\<\n\\[< \\lambda_1^{h^2-h} + (\\frac{h^*}{T} + 1){h^*-h}\\]\nIn the above inequalities, \\(\\bar{A_{\\tau}}\\) denotes the diagonal matrix whose diagonal entries are the eigenvalues of \\(A_{\\tau}\\), corresponding to the effective dimensions. It is worth noting that there may be a small coefficient on the right side of \\(\\approx\\), depending on the definition of the effective dimension \\(h^*\\). However, we omit this coefficient for the sake of conciseness. Consequently, the second term has the following bound:\n\\[||A_\\tau^{1/2} A_\\tau^T e_{\\tau}|| \\sqrt{ \\frac{\\text{det}(A_{\\tau})}{T} \\log < \\sqrt{ \\frac{h^*}{T} \\log \\frac{\\sqrt{(1+\\frac{T}{\\lambda_1})(1-q)}} } }\\]\nAccording to the assumptions in Lemma 3.4, we have:\n\\[\\lambda_1 || \\Theta_{\\tau} ||_{A_{\\tau^{-1}}} \\le \\lambda_1 || \\Theta^* || \\le \\lambda_1 \\beta_\\Theta\\]\nBy integrating the above three terms, we complete the proof of the bound for \\(\\alpha_{\\Theta}\\) in Lemma 3.4. The proof for the bound of \\(\\alpha_{\\mathcal{U}}\\) follows a similar approach and is therefore omitted."}, {"title": "A.4. Proof of Theorem 3.5", "content": "In this subsection, for description conciseness, the subscripts of functions are omitted when there is no risk of confusion. For example, we denote \\(r_{\\tau+1}(b_{\\tau+1})\\) simply as \\(r(b_{\\tau+1})\\). Besides, we denote the acceptance estimated by \\(\\hat{r}_{1+1}(\\cdot) + e_{\\tau+1}(\\cdot)\\) as \\(s(\\cdot)\\), and the samples as \\(\\mu_{\\tau+1} = \\phi(b_{\\tau+1} Y) \\otimes \\phi(x_{\\tau+1})\\) and \\(v_{\\tau+1} = \\phi(b_{\\tau+1} Y) \\otimes p_{\\tau+1}\\). Additionally, the optimal bid at time step \\(\\tau + 1\\) is denoted as \\(b^*_{\\tau+1}\\), thus \\(r(b^*_{\\tau+1})\\) and \\(r(b_{\\tau+1})\\) are the true acceptance of the optimal bid \\(b^*_{\\tau+1}\\) and the chosen bid \\(b_{\\tau+1}\\) at \\(\\tau + 1\\), respectively.\nProof. Firstly, we analyze Equation 14.\n\\[A_\\tau ((\\phi(b_{\\tau+1} Y) \\otimes (x_{\\tau+1})) = (A_\\tau^T A_\\tau + \\lambda_1 I_{h^2}) \\mu_{\\tau+1} = A_\\tau^T k_{\\tau+1} + \\lambda_1 \\mu_{\\tau+1}\\]\nRearranging the above equation, there is:\n\\[\\mu_{\\tau+1}^T = A_\\tau^{1/2} A_\\tau (A_\\tau (K_{\\tau+1} A_\\tau + \\lambda_1 \\mu_{\\tau+1})\\\\\n\\[= A_\\tau^T (K_{\\tau+1} (A_\\tau + \\lambda_1 \\mu_{\\tau+1})\\]"}, {"title": "A Contextual Combinatorial Bandit Approach to Negotiation", "content": "The last equality above is based on the study of Haasdonk et al. (Haasdonk & Pekalska, 2010). As the kernel value at time step \\(\\tau + 1\\) is denoted as \\(k_{\\tau+1} = \\mu_{\\tau+1}\\mu_{\\tau+1}\\), there is:\n\\[\\mu_{\\tau+1} \\mu_{\\tau+1}^T = k_{\\tau+1} (K_\\tau + \\lambda_1 I_{\\tau})^{-1} k_{\\tau+1} + \\lambda_1 \\mu_{\\tau+1} A_\\tau \\mu_{\\tau+1}^{1/2}\\]\n\\[=\\mu_{\\tau+1} A_\\tau \\mu_{\\tau+1}^{1/T} = \\frac{1}{\\lambda_1} (k_{\\tau+1} - k_{\\tau+1} (K_{\\tau+1} + \\lambda_1 I_{\\tau})^{-1} k_{\\tau+1})\\]\nDerivation for \\(v_{\\tau+1} D_{\\tau}^{-1} v_\\tau^{1/T}\\) is similar. From the above results, Equation 14 is equivalent to the following format, consistent with existing UCB-based approaches. The remaining proof is based on this result.\n\\[e_{\\tau+1} = \\alpha_{\\Theta} \\sqrt{\\mu_{\\tau+1} A_\\tau \\mu_{\\tau+1}^{1/T}} - \\alpha_{\\mathcal{U}} \\sqrt{v_{\\tau+1} D_\\tau^{-1} v_{\\tau+1}}\\]\nSecondly, we prove that \\(s(b^*_{\\tau+1}) \\ge r(b^*_{\\tau+1})\\).\n\\[s(b^*_{\\tau+1}) - r(b^*_{\\tau+1}) =\\mu^*_{\\tau+1}(\\text{vec}(\\Theta_{\\tau}) - \\text{vec}(\\Theta^*)) + v^*_{\\tau+1}(\\text{vec}(\\mathcal{U}_{\\tau}) - \\text{vec}(\\mathcal{U}^*)) + \\alpha_{\\Theta} ||\\mu^*_{\\tau+1}||_{A^{-1}} + \\alpha_{\\mathcal{U}} ||v^*_{\\tau+1}||_{D^{-1}}\\]\n\\[\\ge - || \\text{vec}(\\Theta_{\\tau}) - \\text{vec}(\\Theta^*)||_{A^{-1}} ||\\mu^*_{\\tau+1}||_{A} - ||\\text{vec}(\\mathcal{U}_{\\tau}) - \\text{vec}(\\mathcal{U}^*)||_{D^{-1}} ||v^*_{\\tau+1}||_{D}\\]\n\\[ + \\alpha_{\\Theta} ||\\mu^*_{\\tau+1}||_{A^{-1}} + \\alpha_{\\mathcal{U}} ||v^*_{\\tau+1}||_{D^{-1}}\\]\n\\[\\ge - \\alpha_{\\Theta} ||\\mu^*_{\\tau+1}||_{A^{-1}} \\alpha_{\\mathcal{U}} ||v^*_{\\tau+1}||_{D^{-1}} + \\alpha_{\\Theta} ||\\mu^*_{\\tau+1}||_{A^{-1}} + \\alpha_{\\mathcal{U}} ||v^*_{\\tau+1}||_{D^{-1}} = 0\\]\nThirdly, we bound \\(r(b^*_{\\tau+1}) \\times f(b^*_{\\tau+1}) - r(b_{\\tau+1}) \\times f(b_{\\tau+1})\\). As \\(b_{\\tau+1}\\) is the bid chosen by the NegUCB algorithm at time step \\(\\tau + 1\\), we have:\n\\[r(b^*_{\\tau+1}) \\times f(b^*_{\\tau+1}) \\le s(b^*_{\\tau+1}) \\times f(b^*_{\\tau+1}) \\le s(b_{\\tau+1}) \\times f(b_{\\tau+1})\\]\n\\[\\Rightarrow r(b^*_{\\tau+1}) \\times f(b^*_{\\tau+1}) - r(b_{\\tau+1}) \\times f(b_{\\tau+1})\\]\n\\[\\le {\\mu_{\\tau+1} \\text{vec}(\\Theta_{\\tau}) + v_{\\tau+1} \\text{vec}(\\mathcal{U}_{\\tau}) + \\alpha_{\\Theta} ||\\mu_{\\tau+1}||_{A^{-1}} + \\alpha_{\\mathcal{U}} ||v_{\\tau+1}||_{D^{-1}} - \\mu_{\\tau+1} \\text{vec}(\\Theta^*) - v_{\\tau+1} \\text{vec}(\\mathcal{U}^*)} \\times f(b_{\\tau+1})\\]\n\\[ = {\\mu_{\\tau+1}(\\text{vec}(\\Theta_{\\tau}) - \\text{vec}(\\Theta^*)) + v_{\\tau+1}(\\text{vec}(\\mathcal{U}_{\\tau}) - \\text{vec}(\\mathcal{U}^*)) + \\alpha_{\\Theta} ||\\mu_{\\tau+1}||_{A^{-1}} + \\alpha_{\\mathcal{U}} ||v_{\\tau+1}||_{D^{-1}}} \\times f(b_{\\tau+1})\\]\n\\[< {2 \\alpha_{\\Theta} ||\\mu_{\\tau+1}||_{A^{-1}} + 2 \\alpha_{\\mathcal{U}} ||v_{\\tau+1}||_{D^{-1}}} \\times f(b_{\\tau+1})\\]\nThe first inequality above is from the conclusion of the second proof step. Lastly, we prove the bound of cumulative regret. For the benefit function \\(f_t\\) at time step \\(t\\), we assume an union bound \\(a_f\\) such that \\(|f_t| \\le a_f\\) for \\(\\forall b \\in B_t\\) and \\(\\forall t \\in \\{1, 2, ..., \\tau\\}\\).\n\\[\\sum_{t=0}^T ( r(b_{\\tau+1}^*) \\times f(b_{\\tau+1}^*) - r(b_{\\tau+1}) \\times f(b_{\\tau+1})\\]\n\\[< 2 \\alpha_{\\Theta} a_f \\sum_{t=0}^T ||(\\phi(b_{\\tau+1} Y) \\otimes (x_{\\tau+1}))||_{A^{-1}} + 2 \\alpha_{\\mathcal{U}} a_f \\sum_{t=0}^T ||(\\phi(b_{\\tau+1} Y) \\otimes p_{\\tau+1})||_{D^{-1}}\\]\n\\[< 2 \\alpha_{\\Theta} a_f \\sum_{t=0}^T ||(\\phi(b_{\\tau+1} Y) \\otimes (x_{\\tau+1}))|| + 2 \\alpha_{\\mathcal{U}} a_f \\sum_{t=0}^T ||(\\phi(b_{\\tau+1} Y) \\otimes p_{\\tau+1})||\\]\n\\[< 2 \\alpha_{\\Theta} a_f \\sqrt{T \\log \\frac{\\text{det}(A_{\\tau})}{\\text{det}(\\lambda_1 I_{h^2})}} + 2 \\alpha_{\\mathcal{U}} a_f \\sqrt{T \\log \\frac{\\text{det}(D_{\\tau})}{\\text{det}(\\lambda_2 I_{mh})}}\\]\n\\[< 2 \\alpha_{\\Theta} a_f \\sqrt{\\frac{2 h^*}{T} \\log (1 + \\frac{T}{\\lambda_1 h^*})} + 2 \\alpha_{\\mathcal{U}} a_f \\sqrt{\\frac{2 m^*}{T} \\log (1 + \\frac{T}{\\lambda_2 m^*})}\\]"}, {"title": "A.4.1. CUMULATIVE REGRET ANALYSIS", "content": "The cumulative regret upper bound of NegUCB remains independent of the cardinality of bids, a notable distinction from existing algorithms like C2UCB (Qin et al., 2014), ComLinUCB (Wen et al., 2015), CC-MAB (Chen et al., 2018), etc., which exhibit upper bounds that are sub-linear concerning the cardinality of super arms. This behavior is attributed to the full-bandit feedback of negotiation problems and the Assumption 3.1. For instance, ComLinUCB estimates the reward of each arm, from which the general rewards of super arms are calculated, leading to error propagation. In contrast, NegUCB directly estimates the general rewards of super arms, eliminating error propagation. Assumption 3.1 requires that item contexts are defined by their basic features. Neglecting this principle may result in inaccuracies when capturing bid contexts. However, similar assumptions are commonly used in various applications, such as recommendation and crowdsourcing. Addressing this limitation in future research is encouraged. For full-bandit feedback, existing works such as DART (Agarwal et al., 2021), ETCG (Nie et al., 2022), RGL (Fourati et al., 2023), etc., have been developed. However, their regret"}]}