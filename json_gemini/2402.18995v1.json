{"title": "Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series", "authors": ["Rui Huang", "Sikun Yang", "Heinz Koeppl"], "abstract": "Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph-structured transition dynamics, which enable us to infer more explainable latent structure, compared with PGDSs. Finally, we demonstrate the explainable latent structure learned by the proposed method, and show its superior performance in imputing missing data and forecasting future observations, compared with the related models.", "sections": [{"title": "1 Introduction", "content": "Count time sequences, naturally arise in many domains such as text mining [Blei and Lafferty, 2006; Wang et al., 2008; Rudolph and Blei, 2018; Acharya et al., 2018; Dieng et al., 2019], cell genomic analysis [Levitin et al., 2019; Tong et al., 2020; Jones et al., 2023], population movement forecasting [Sheldon et al., 2013; Stuart and Wolfram, 2020; Roy and Dunson, 2020], and etc. Modeling count sequences has been drawing increasing research attention because these real-world count data usually exhibit bursty and overdispersed behaviours, which cannot be well-captured by canonical linear dynamical systems (LDSs) [Ghahramani and Roweis, 1998]. In addition, some previous works use extended rank likelihood functions [Han et al., 2014] which link the count observations to latent continuous dynamics to model count time sequences. Nonetheless, the extended rank likelihood functions cannot faithfully capture bursty dynamics underlying real-world count sequences. Meanwhile, the extended rank likelihood functions often require an approximate inference scheme, and thus scale poorly with high-dimensional count sequences, such as single-cell RNA sequencing data [Chandra et al., 2023]. Notably, some recent works [Acharya et al., 2015; Schein et al., 2016a; Schein et al., 2016b; Schein et al., 2019] model sequential count observations using gamma Poisson family distributions. More specifically, [Acharya et al., 2015] develops a gamma Markov process to capture continuous dynamics underlying count-valued sequences. In particular, the number of latent factors behind high-dimensional count data, can be appropriately determined by the gamma process prior, in a Bayesian non-parametric manner. Following the success of [Acharya et al., 2015], Schein et al. [2016a] study a Poisson gamma dynamical system, in which a transition kernel is designed to capture how the latent dimensions interact with each other to model complicated observed dynamics. Another appealing aspect of the Poisson gamma dynamic model is that the posterior simulation can be performed using a tractable-yet-efficient Gibbs sampling algorithm via Poisson-Logarithm data augmentation strategy [Zhou and Carin, 2012; Zhou and Carin, 2015]. Hence, the Poisson gamma dynamic models [Acharya et al., 2015; Schein et al., 2016a; Schein et al., 2019] are in particular well-fitted to impute missing entries, to predict future unseen observations and to estimate uncertainties.\nDespite these advantages, these models still cannot well capture the heterogeneous overdispersion effects of the latent dynamic processes behind count observations. For instance, international event data, usually consists of multiple latent dynamic processes, which often change rapidly with the different magnitudes [King, 2001; Stewart, 2014]. To capture such heterogeneous overdispersed behaviours, we develop a negative-binomial-randomized gamma Markov chain structure, which not only greatly enhances the model flexibility, but also facilitates the fast convergence of the derived Gibbs sampling algorithms. Moreover, the transition dynamics behind real-world high-dimensional count data, are often sparse, and exhibit a certain amount of graph structure. Hence, we propose to learn the graph-structured transition"}, {"title": "2 Preliminary", "content": "Suppose we have a sequentially-observed count data over time interval [0, T] specified by \\(N = (n_1, ..., n_V)^T\\) of V dimensions, where \\(n_i = (n_i^{(1)}, ..., n_i^{(T)})^T\\) with \\(n_i^{(t)}\\) denoting the v-th observation at time t. The Poisson gamma dynamical system [Schein et al., 2016a] models the count \\(n_i^{(t)}\\) as\n\\[n_i^{(t)} \\sim Pois(\\delta^{(t)} \\sum_{k=1}^K \\lambda_k \\phi_{vk} \\theta_k^{(t)}),\\]\nwhere \\(\\theta_k^{(t)}\\) captures the strength of latent component k at time t, and \\(\\phi_{vk}\\) represents the involvement degree of dimension v in latent component k. To model the underlying dynamics, the PGDS assumes that the latent components evolve over time according to a gamma Markov chain structure as\n\\[\\theta_k^{(t)} \\sim Gam(\\tau \\sum_{k_2=1}^K \\pi_{kk_2} \\theta_{k_2}^{(t-1)}, \\tau),\\quad \\theta_k^{(1)} \\sim Gam(\\epsilon_0, \\epsilon_0),\\]\nwhere the latent components \\(\\Theta^{(t-1)} = (\\theta_1^{(t-1)},...,\\theta_K^{(t-1)})^T\\) evolve over time through the transition matrix \\(\\Pi\\). The \\(\\theta_{k_2}^{(t-1)}\\) captures how strongly the k-th latent component activates at time t\u22121, and \\(\\pi_{kk_2}\\) models how strongly the \\(k_2\\)-th component \\(\\theta_{k_2}^{(t-1)}\\) at time t-1 affect the k-th component \\(\\theta_k^{(t)}\\) at time t. Eq.2 naturally defines a gamma Markov chain structure. The expectation and variance of the gamma Markov chain can be calculated respectively as \\(E[\\theta_k^{(t)} | \\Theta^{(t-1)}, \\Pi] = \\Pi\\theta^{(t-1)}\\) and \\(Var[\\theta_k^{(t)} | \\Theta^{(t)}, \\Pi] = (\\Pi\\theta^{(t-1)})\\tau_0^{-1}\\), where \\(\\tau_0\\) controls the variance of \\(\\Theta^{(t)}\\).\nSchein et al. [2019] further develop a Poisson-randomized gamma Markov chain (PRGMC) structure specified by\n\\[\\theta_k^{(t)} \\sim Gam(\\epsilon_0 + h_k^{(t)}, \\tau),\\quad h_k^{(t)} \\sim Pois (\\tau \\sum_{k_2} \\pi_{kk_2} \\theta_{k_2}^{(t-1)}).\\]\nBy marginalizing out the Poisson latent states \\(h_k^{(t)}\\), we have a continuous-valued dynamical system given by\n\\[\\theta_k^{(t)} \\sim RG1(\\epsilon_0^{(0)} + h_k^{(t)}, \\tau \\sum_{k_2} \\pi_{kk_2} \\theta_{k_2}^{(t-1)}, \\tau),\\]"}, {"title": "3 The Proposed Model", "content": "In this section we will introduce the novel negative-binomial-randomized gamma Markov chain structure to capture the heterogeneous overdispersion effects of the latent dimensions behind count data. Then we shall describe how to learn explainable latent transition structure with relational gamma processes. The proposed negative-binomial-randomized gamma dynamical system is defined by\n\\[n_i^{(t)} \\sim Pois(\\delta^{(t)} \\sum_{k=1}^K \\lambda_k \\phi_{vk} \\theta_k^{(t)}),\\]\nwhere \\(\\delta^{(t)}\\) is a nonnegative multiplicative term capturing time-dependent bursty dynamics. We place a gamma prior on \\(\\delta^{(t)}\\) as \\(\\delta^{(t)} \\sim Gam(\\epsilon_0, \\epsilon_0)\\), and let \\(\\delta^{(t)} = \\delta\\) if the generative process (Eq. 3) is stationary over time. Here \\(\\Phi_k = (\\Phi_{1k}, \\Phi_{2k},...,\\Phi_{Vk})^T\\) denotes the loading coefficient of k-th latent component, and \\(\\lambda_k\\) denotes the weight of k-th latent component. To ensure model identifiability, we require \\(\\sum_v \\phi_{vk} = 1\\) and thus have a Dirichlet prior over \\(\\Phi_k\\) given by \\(\\Phi_k \\sim Dir(\\epsilon_0, ..., \\epsilon_0)\\). More specifically, we draw \\(\\lambda_k\\) from a hierarchical prior as \\(\\lambda_k \\sim Gam(\\gamma + g_k, \\beta)\\), in which \\(g_k \\sim Pois(\\gamma)\\). We specify gamma priors over \\(\\gamma\\) and \\(\\beta\\) as \\(\\gamma \\sim Gam(\\epsilon_0, \\epsilon_0), \\beta \\sim Gam(\\epsilon_0, \\epsilon_0)\\). Note that as K \u2192 \u221e, the summation of the weight expectation remains finite and fixed, i.e., \\(\\sum_{k=1}^K E[\\lambda_k] = \\beta^{-1}(\\epsilon_{\\lambda} + \\gamma)\\). Hence, this hierarchical prior enables us to effectively estimate a finite number of latent factors that are representative to capture the temporal dynamics."}, {"title": "3.1 Negative-Binomial Randomized Gamma Markov Processes.", "content": "To capture the heterogeneous overdispersion behaviors of the latent dimensions behind count sequences, we introduce a negative-binomial randomized gamma Markov process (NBRGMP) specified by\n\\[\\theta_k^{(t)} \\sim Gam(\\epsilon_0^{(0)} + h_k^{(t)}, \\tau),\\quad h_k^{(t)} \\sim NB(\\sum_{k_2=1}^K \\pi_{kk_2} \\theta_{k_2}^{(t-1)}, \\frac{1}{\\psi}),\\]\nwhere we set \\(\\theta_k^{(0)} = \\lambda_k\\), and \\(\\theta_k^{(t)}\\) is gamma distributed with shape parameter \\(\\epsilon_0^{(0)} + h_k^{(t)}\\) where \\(\\epsilon_0^{(0)} \\geq 0\\), and the rate parameter \\(\\tau\\). Here, instead of specifying a Poisson prior as did in [Schein et al., 2019], we draw the intermediate latent state \\(h_k^{(t)}\\) from a negative-binomial distribution to enhance the flexibility of \\(\\theta_k^{(t)}\\), which enable us to estimate the heterogeneous overdispersed behaviours of the latent dynamic processes. More specifically, the marginal expectation and variance of"}, {"title": "3.2 Factor-structured Transition Dynamics", "content": "We first propose to learn the latent factor structure behind transition dynamics. To that end, we specify a hierarchical Dirichlet prior over \\(\\pi_k\\) as \\(\\pi_k \\sim Dir(a_{1k},...,a_{kk})\\),where \\(a_k = (a_{1k},...,a_{kk})^T\\) is the hyper-parameter. Our goal here is to capture the correlation structure between the latent dimensions of the transition kernel. Thus, we model the hyper-parameter A = \\([@_{k_1k_2}]_{k_1,k_2}\\) using a Poisson factor model as\n\\[a_{k_1k_2} \\sim Pois(\\sum_{c=1}^C m_{k_1c}r_cm_{k_2c}),\\]\nwhere \\(r_c\\) is the weight of c-th latent factor, and \\(m_{kc}\\) captures how strongly k-th component associate with c-th factor. Naturally, k\u2081-th component interact with k2-th component through the weight \\(\\sum_{c=1}^C m_{k_1c}r_cm_{k_2c}\\). To ensure the latent factor to be nonnegative, we draw the factor \\(r_c\\), and factor loading \\(m_{kc}\\) from the priors specified by\n\\[m_{kc} \\sim Gam(\\alpha_k, \\beta_k), \\quad r_c \\sim Gam(\\epsilon_0^{(C)},c_0),\\]\nrespectively. Here, C is the maximum number of latent factors. As C \u2192 \u221e, the weights of the latent factors \\({r_c}\\_c\\) and the factor loading \\({m_c}\\_c\\) can be considered as a draw \\(G = \\sum_{c=1}^{\\infty} r_c\\delta_{\\omega_c}\\) come from a gamma process GaP(Go, co), where Go denotes the base measure over the metric space \u03a9, and co the concentration parameter [Ferguson, 1973]."}, {"title": "3.3 Graph-Structured Transition Dynamics", "content": "For high-dimensional count sequences, the underlying transition dynamics are often sparse and exhibit a certain amount of graph structure. Hence, we further study to learn the latent graph-structured transition kernel behind count time series, using relational gamma process prior. In particular, we sample the transition parameter \\(\\pi_k\\) from a hierarchical Dirichlet prior, as \\(\\pi_k \\sim Dir(a_{1k},...,a_{kk})\\). To introduce a sparse graph-structured transition kernel, we model the matrix of the hyper-parameter A = \\([a_{k_1k_2}]_{k_1,k_2}\\) as \\(A = D \\odot Z\\),where D = \\([d_{k_1k_2}]_{k_1,k_2}\\) denotes the matrix of the nonnegative hyper-parameters, and Z = \\([Z_{k_1k_2}]_{k_1,k_2}\\) is a binary mask. More specifically, we consider the dimensions of the transition kernel as vertices, and the non-zero transition behaviours as graph edges. Naturally, we can capture the sparse structure of the transition kernel \\(\\Pi\\) using a graph. As shown in Fig. 3, for each pair of two vertices i and j, \\(b_{ij} = 1\\) means that the transition probability from i-th component to j-th component is non-zero, and vice versa. In particular, we model the binary mask Z using relational gamma processes as\n\\[Z_{k_1k_2} \\sim Ber[1 \u2013 exp(\\sum_{c=1}^C m_{k_1c}r_cm_{k_2c})],\\]\nwhere \\(r_c\\) can be considered as the weight of latent community c, and \\(m_{kc}\\) measures how strongly k-th vertex (the dimension of the transition kernel) relate to c-th latent community, as illustrated in Fig. 3. Note that the binary mask Z can be equivalently drawn via the Bernoulli-Poisson link function as\n\\[W_{k_1k_2} \\sim Pois(\\delta(\\sum_{c=1}^C m_{k_1c}r_cm_{k_2c} \\geq 1)), \\quad Z_{k_1k_2} \\sim Pois(W_{k_1k_2}).\\]\nTo ensure the model explainability, we restrict \\(r_c\\) and \\(m_{kc}\\) to be nonnegative, and thus place Gamma priors over these two parameters as \\(m_{kc} \\sim Gam(\\alpha_k, \\beta_k), r_c \\sim Gam(\\epsilon_0^{(C)}, c_0)\\), respectively. As we discussed in Sec 3.2, this hierarchical gamma prior can be considered as a draw \\(G = \\sum_{c=1}^{\\infty} r_c\\delta_{\\omega_c}\\) come from a gamma process GaP(Go, co). In particular, we call this Bayesian non-parametric prior the relational gamma process, as a graph-structure can be naturally induced. The nonnegative hyper-parameters D = \\([d_{k_1k_2}]_{k_1,k_2}\\) are drawn from a gamma distribution as \\(d_{k_1k_2} \\sim Gam(\\epsilon_0, \\epsilon_0)\\).\nThe proposed gamma dynamical systems are not fully conjugate. Nonetheless, tractable-yet-efficient Gibbs sampling algorithms are developed to perform posterior simulation via negative-binomial data augmentation strategies [Zhou, 2016a]. The full derivation of the inference procedure is presented in the supplementary material."}, {"title": "4 Related Work", "content": "Modeling sequentially observed count sequences has been receiving growing interests in recent years. Here we discuss several types of methods closely related to our studies. [Acharya et al., 2015] first studies the gamma Markov process on sequentially count sequences, in which the latent states evolve independently over time. [Schein et al., 2016a] tries to capture the excitations among the latent gamma Markov processes using a transition structure. [Schein et al., 2019] investigates a Poisson-randomized gamma Markov process which can capture a certain amount of bursty dynamics, and thus demonstrates advantages over gamma Markov processes. [Virtanen and Girolami, 2020] studies a second type of gamma Markov chain structure via the scale parameter of the latent gamma states, which demonstrate better stationary property over the gamma Markov chain proposed by [Acharya et al., 2015]. [Filstroff et al., 2021] recently provides a thorough survey on the studies of the developed gamma Markov processes, and evaluates these models through standard tasks including data smoothing and forecasting. [Han et al., 2014] first tries to capture sequential count observations using linear dynamical systems, via the extend rank likelihood function. [Linderman et al., 2017] proposes to learn switching behaviors of sequential data using recurrent linear dynamical systems (rLDS). [Nassar et al., 2018] further develops a tree-structured extension of rLDS, with multi scale resolution. [Chen et al., 2020] extends the Poisson gamma dynamical systems to learn non-stationary transition dynamics behind count time series. Some efforts are also dedicated to developing Bayesian deep models to capture count sequences. [Gan et al., 2015] develops a temporal sigmoid belief network for count time series. [Guo et al., 2018] proposes deep Poisson-dynamical systems to capture long-range temporal dependencies."}, {"title": "5 Experiments", "content": "We evaluate the proposed relational gamma process dynamical systems, and compare it with closely-related methods, using both synthetic and real-world count data.\nReal-world data. We conducted the experiments with the following real-world datasets: (1) Integrated Crisis Early Warning System (ICEWS) dataset contains the count number of 6, 000 pairwise interactions between 233 countries over 365 days. By screening out 4,800 dimensions where the sample sparsity exceeds 99%, we used a subset of ICEW"}, {"title": "5.1 Negative Binomial Randomized Gamma Dynamical Systems.", "content": "data which contains V = 1,200 dimensions, and T = 365 time steps; (2) Last.fm contains the listening information of 7,071 music artists over 51 months, where we have T = 51 time steps, and V = 7,071 dimensions; (3) Earthquake Reports Database (EQDB): records more than 120,000 earthquake reports over 15,000 earthquakes whose epicenters in the United States and nearby U.S. territories from 1928 to 1985. We created a count matrix where each column represents a month and each row represents a state. The EQDB used in the experiments, contains T = 696 time steps, and V = 64 dimensions. (4) COVID-19 contains the daily death toll in the fifty states and Washington DC of the United States, from March 2020 to March 2021. We have T = 365 time steps, and V = 51 dimensions.\nBaselines. In the experiments we compared the predictive of the proposed models with (1) the gamma process dynamic Poisson factor analysis (GaP-DPFA) [Acharya et al., 2015], in which the gamma Markov chain evolves independently over time; (2) the Poisson-gamma dynamical system (PGDS) [Schein et al., 2016a], in which a transition kernel is used to capture the excitations among latent gamma Markov chains; (3) the Poisson-randomized gamma dynamical system (PRGDS) [Schein et al., 2019] where the Poisson-randomized gamma Markov chain structure can capture a certain amount of bursty dynamics.\nWe denote the proposed negative-binomial-randomized gamma dynamical system as NBRGDS. The proposed NBRGDS with factor-structured prior imposed over the transition kernel, is denoted as FS-NBRGDS. The proposed NBRGDS with graph-structured prior placed over the transition structure, is denoted by GS-NBRGDS.\nTo evaluate the performance of the compared models in capturing heterogeneous overdispersed behaviours of latent dynamic processes behind count sequences, we considered a subset of ICEWS data that consists of heterogeneous overdispersed counts. More specifically, we sorted the oberserved dimensions according to their variance/expectation ratio, and selected the first L dimensions in descending order, i.e.,"}, {"title": "5.2 Data Analysis", "content": "those dimensions with larger variation/expectation ratio. We present the result for the setting L = 300. We treated the 80 percent of the data as the training set, and the remaining 20 percent as the test set. Then, we trained all the compared models with the training set, and evaluated the model performance using the test set. In the experiments, we used mean absolute error (MAE) and mean relative error (MRE) to evaluate the model performance in fitting count sequences:\n\\[MAE = \\frac{1}{VT} \\sum_{v=1}^V \\sum_{t=1}^T \\frac{|n_i^{(t)} - \\hat{n}_i^{(t)}|}{1 + n_i^{(t)}},\\]\n\\[MRE = \\frac{1}{VT} \\sum_{v=1}^V \\sum_{t=1}^T |n_i^{(t)} - \\hat{n}_i^{(t)}|,\\]\nwhere \\(n_i^{(t)}\\) and \\(\\hat{n}_i^{(t)}\\) denotes the ground true value and estimated value of dimension v at time t, respectively. They differ because MRE considers the relative magnitude of the errors in relation to the actual values, taking into account the scale of the data, while MAE simply measures the absolute magnitude of the errors without considering the data scale. Fig. 4 shows the results of the compared models averaged over ten random training-testing repeats.\nAs shown in Fig. 4 (a), NBRGDS has started to converge to its steady states after almost 102 iterations, while both PGDS and PRGDS start to converge until 103 iterations. Fig.4 (b) and (c) compares the mean absolute errors and mean relative errors of the compared models, respectively. Overall, NBRGDS achieves the lowest MAE and MRE. PRGDS performs better than PGDS as PRGDS can capture a certain amount of overdispersion effects via its Poisson-randomized chain structure. We also note that NBRGDS with a time-varing scaling factor \\(\\delta^{(t)}\\), performs better than stationary NBRGDS because this scaling factor \\(\\delta^{(t)}\\) can also capture bursty dynamics. Nonetheless, stationary NBRGDS still outperforms both the PRGDS and PGDS with time-varing \\(\\delta^{(t)}\\). We conjecture that this improved prediction accuracy is because the time-varying scaling factor \\(\\delta^{(t)}\\) fail to capture the"}, {"title": "5.3 Related topics", "content": "underlying overdispersed behaviours, although it still can model a certain amount of bursty dynamics in observed dimensions. This observation further demonstrates the strong ability of the NBRGDS in capturing hetergeneous overdispersion effects of the latent dimensions behind count sequences.\nSynthetic data. To further evaluate the performance of the compared models in capturing overdispersion effects, we also considered generating synthetic data with heterogeneous overdispersed dynamics. To that end, we considered to simulate synthetic data using zero-inflated negative-binomial (ZINB) models given by\n\\[f_{ZINB}(n | p_0, r, p) = p_0I_0(n) + (1-p_0)f_{nb}(n | r, p),\\]\nwhere \\(f_{ZINB}\\) and \\(f_{NB}\\) represents the probability mass function (PMF) of the zero-inflated negative-binomial distribution and negative-binomial distribution, respectively. Here, \\(I_0(n)\\) is an indicator function that takes 1 when n = 0, otherwise 0. The parameter \\(p_0 \\in [0, 1]\\) controls the ratio of zero counts, while r and p are the two parameters of the negative-binomial distribution. Hence, we can effectively control the sparsity"}, {"title": "6 Conclusion", "content": "Novel negative-binomial-randomized gamma dynamical systems, have been proposed to capture the heterogeneous overdispersed behaviors of latent dynamics behind count time sequences. The new framework demonstrates more explainable latent structure, by learning the factor structure and sparse graph structure of the transition kernels, compared with transition kernel by non-informative priors. Although the prior specification of the proposed framework lacks conjugacy, tractable-yet-efficient sampling algorithms are developed to perform posterior inference. In the future, we plan to capture time-varying graph-structured transition dynamics, which will enable to better understand non-stationary count sequences. We are also considering to enhance the modeling capacities of gamma belief networks [Zhou et al., 2015; Zhou et al., 2016; Zhou, 2018] and convex polytope methods [Zhou, 2016b; Armandpour et al., 2021] using the negative-binomial-randomized gamma Markov processes. Moreover, the future interesting research directions include modeling bursty dynamics often observed in online or"}]}