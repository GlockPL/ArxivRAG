{"title": "Synthetic ECG Generation for Data Augmentation and Transfer Learning in Arrhythmia Classification", "authors": ["Jos\u00e9 Fernando N\u00fa\u00f1ez", "Jamie Arjona", "Javier B\u00e9jar"], "abstract": "Deep learning models need a sufficient amount of data in order to be able to find the hidden patterns in it. It is the purpose of generative modeling to learn the data distribution, thus allowing us to sample more data and augment the original dataset. In the context of physiological data, and more specifically electrocardiogram (ECG) data, given its sensitive nature and expensive data collection, we can exploit the benefits of generative models in order to enlarge existing datasets and improve downstream tasks, in our case, classification of heart rhythm.\nIn this work, we explore the usefulness of synthetic data generated with different generative models from Deep Learning namely Diffweave, Time-Diffusion and Time-VQVAE in order to obtain better classification results for two open source multivariate ECG datasets. Moreover, we also investigate the effects of transfer learning, by fine-tuning a synthetically pre-trained model and then progressively adding increasing proportions of real data. We conclude that although the synthetic samples resemble the real ones, the classification improvement when simply augmenting the real dataset is barely noticeable on individual datasets, but when both datasets are merged the results show an increase across all metrics for the classifiers when using synthetic samples as augmented data. From the fine-tuning results the Time-VQVAE generative model has shown to be superior to the others but not powerful enough to achieve results close to a classifier trained with real data only.\nIn addition, methods and metrics for measuring closeness between synthetic data and the real one have been explored as a side effect of the main research questions of this study.", "sections": [{"title": "1. Introduction", "content": "The analysis of physiological data, often captured as time series (e.g., EEG, ECG, IMU, EMG), plays a crucial role in healthcare applications such as disease diagnosis and anomaly detection ([1]). However, researchers face a significant challenge: the scarcity of publicly available datasets due to privacy concerns, ethical regulations, and the small number of patients with rare conditions ([2,3]). This low availability of data hinders the training of powerful deep learning models, which are known to be \"data-hungry\" ([4]). Furthermore, real-world physiological data often exhibit class imbalances in which the categories of interest are represented by far fewer examples compared to healthy conditions. This imbalance poses a challenge for machine learning algorithms, as they tend to favor the majority class during training ([5]).\nAn approach to address both data scarcity and class imbalance is data augmentation. Traditional augmentation techniques, commonly used in computer vision (scaling, flipping, cropping) or adapted for time series (noise injection, jittering, warping), are often limited in their effectiveness ([6]). These methods often create data that deviates from the underlying distribution of the real data or simply represent minor modifications of the original samples.\nRecently, generative modeling have become a very active area of research in the context of Deep Learning and offers a more promising approach for data augmentation across various domains, including text-to-image generation, natural language processing and time series generation ([7]). However, applying generative models to physiological time series poses unique challenges as compared to images or text, since the usage of generative models for physiological time series (EEG, ECG, IMU, EMG, etc.) remains relatively unexplored.\nThis work presents an effort to address the aforementioned problems. We explore the selection of a suitable generative model for physiological time series data and propose methods to evaluate the quality of synthetic data. Our evaluation will consider the impact of synthetic data augmentation on existing physiological datasets, involving pre-training a classification model with synthetic data and fine-tuning it with real data to assess the impact of the generated data towards classification."}, {"title": "2. Generative Networks", "content": "From a probabilistic perspective, the goal of data modeling in machine learning is to find the conditional distribution $p_{\\theta}(c|x)$ of a vector c given the value of a vector x of input features, where the observed variable, x, is a random sample of an unknown underlying process and \u03b8 the parameters of the chosen model. For classification tasks, c represents a discrete class label, and for regression, it corresponds to one or more continuous variables. The discriminative approach represents this conditional distribution with a parametric model and then finds the parameters using a training set of available data $(x_n, c_n)$, which are pairs of input vectors with their associated target values. Given new values of x, the learned conditional distribution can be used to make predictions of c.\nAn alternative approach, albeit more difficult, is the generative one. The goal is to find the joint distribution $p_{\\theta}(x, c)$, expressed, for example, as an implicit or explicit parametric model. Once learned, this distribution is used to evaluate the conditional probability $p_{\\theta}(c|x)$ in order to make predictions of c for new values of x. This method assumes that it is possible to generate synthetic examples of the feature vector x, given that the model learnt to capture correctly the process that defines the data. This approach is attractive, as it allows us to do sampling in order to obtain more data examples, i.e. new vectors x, which is helpful when we have underrepresented classes in the training data or not enough data examples altogether.\nThere are many deep learning approaches to modeling data generatively as a probability distribution. Some families of models define proper probability distributions di-"}, {"title": "3. ECG related tasks literature review", "content": "The recording of heart electrical activity is represented as time series data, that is, realizations of random variables indexed by time. These types of data can be found in a"}, {"title": "3.1. ECG generation", "content": "The recording of heart electrical activity is represented as time series data, that is, realizations of random variables indexed by time. These types of data can be found in a wide range of domains: physiological processes [15], stock markets [16], industry applications [17], climate change [18], ITS services [19], etc. each one having its own problems and attributes. Thus, the literature for time series modeling has been a very active research area for more than fifty years. Recently, with the rise of Deep Learning methods, there has been an increasing interest in the application of generative models in some of these domains, especially those in which there is a small amount of data, or small representation of the signals of interest.\nWithin the literature of deep learning, time series generation approaches can be categorized principally by two key aspects: data utilization strategies and employed model architectures. Data utilization strategies encompass univariate, multivariate, non-conditional, and conditional approaches. Conversely, model architectures encompass diverse architectures such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs) and Denoising Diffusion models.\nFor ECG data, data are usually registered using 12 sensors called leads, that capture a different direction of cardiac activation in 3D space. For univariate data, studies employ a single signal, the most commonly used is lead II. These studies may work directly with the full signal or with windows corresponding to individual heartbeats. GAN approaches in the literature use Convolutional Neural Network (CNN), Recurrent Neural Networks (RNN) or a combination of both for the generator and the discriminator architectures. As such we find the work of [20] that proposes a Bi-Long Short Term Memory architecture (Bi-LSTM) to unconditionally learn from single leads. Furthermore, [21] proposes a Wasserstein GAN with gradient penalty which transforms unconditioned signal data into images to use as input to a 2D CNN generator and then translates the images back to time series data, although information is lost in these transformations. Moreover, [22] proposes GAN models which explore two different kinds of generators (LSTM and Bi-LSTM) and also explores two different types of discriminators, LSTM and CNN, with the goal of unconditionally synthesizing the lead II signal by segmenting it into individual heart beats. In [23], the authors propose using a CNN GAN model for each patient to eliminate the need to use conditioned data and then train an LSTM classifier with both real and synthetic data. The data used consisted of heartbeats from a single channel. The authors of [24] proposed to use a 1D-CNN Conditional GAN in order to gconditionally generate lead II data with the class label, and then use this data to improve the classification of an LSTM model trained with the generated and real data simultaneously. Similarly, [25] investigates conditioning the generator of a deep convolutional GAN to achieve the generation of three distinct heartbeat conditions using a segmented heartbeat approach. However, their work also highlights limitations associated with this method, such as the convergence challenges faced when training conditioned GAN models. The work of [26] proposes and compares two new approaches to the generation of single heartbeat signal from lead II conditioned on four different classes by using a conditional VAE and a conditional Wasserstein GAN and claims superior performance from the VAE. Motivated by the promising performance of probabilistic diffusion models, the authors of [27] propose the application of an improved Denoising Diffusion Probabilistic Model (DDPM) for ECG data generation. They compare their approach to a Wasserstein GAN with gradient penalty, employing a technique called Gramian Angular Summation/Difference Fields and Markov Transition Fields to embed the 1D ECG signals into a 2D space. Notably, this work focuses on generating signals from the normal class"}, {"title": "3.2. ECG classification", "content": "Evaluation of heart conditions is the main purpose of the ECG recordings and there is much interest in automating this process through modeling, especially for the detection of arrhythmia conditions. The release of the MIT-BIH dataset marked a significant turning point, allowing researchers to explore automated ECG analysis using statistical, machine learning and data mining techniques. The proposal in [37] is one of the pioneering works in introducing a statistical model (linear discriminant) for ECG classification that achieved significant precision and recall in the problem. In the same year, [38] intro-"}, {"title": "4. Datasets", "content": "A variety of ECG datasets can be found in the literature, most of which are for public use. These are characterized mainly by the sample frequency, the length of the signal, and the number of leads. Some of the first datasets were focused in providing samples from specific heart diseases from a small set of patients and using a small number of leads like in [49] but recent ones follow the format offered in the Chinese Cardiovascular Disease Database [30] in which there are a wide variety of signals of heart conditions and heart diseases using 12 leads, 500hz or 100hz sample frequencies and signal duration of 10 seconds, like for example in the CHAPMAN dataset [31]. Due to the need of large number of examples that offer a great and rich variety of samples for the different ECG classes, current literature on ECG generation and classification uses the most recent datasets available on the literature, i.e. the PTB-XL [29], the CHAPMAN [31], the CCDD [30] and the ICBEB [50]. For a more exhaustive review of the subject, we refer the reader to the following articles [51], [52] and [48]."}, {"title": "4.1. PTB-XL: Physikalisch-Technische Bundesanstalt XL", "content": "The PTB-XL electrocardiogram (ECG) dataset, introduced by [29], has been created and organized towards the use of Deep Learning and Machine Learning models to push forward the state of the art on ECG-related tasks. This dataset includes ECG recordings from a large population of 18,885 patients. Each recording utilizes the standard 12-lead configuration and possesses an average duration of approximately 10 seconds. Notably, the data are available in two sampling frequencies: 100 Hz and 500 Hz, catering to different research needs. The PTB-XL dataset offers a rich annotation scheme, employing a hierarchical classification system with 71 distinct classes, facilitating the classification of ECG signals at various levels of granularity. The hierarchy categorizes the classes into superclasses and subclasses. Superclasses represent broader categories of ECG findings, including normal, conduction disturbance, myocardial infarction, hypertrophy, and ST/T wave changes. Each superclass is further subdivided into more specific subclasses that pinpoint the precise underlying pathology. Furthermore, the dataset also includes a metadata file that contains detailed information on patients' demographics and diagnoses. This information enhances the utility of the dataset for studies investigating the relationship between ECG findings and clinical conditions. Furthermore, PTB-XL provides a classification scheme based on the physiological origin of the ECG abnormality, categorizing classes by form (e.g. QRS complex morphology) or rhythm (e.g. atrial fibrillation)."}, {"title": "4.2. 12-lead electrocardiogram - Chapman University and Shaoxing People's Hospital", "content": "The Chapman electrocardiogram (ECG) dataset, introduced by [53] offers another valuable resource for the analysis of cardiac rhythms. This dataset comprises ECG recordings from a substantial patient population of 45,152 patients. Each recording utilizes the standard 12-lead configuration and possesses an average duration of approximately 10 seconds with a sampling frequency of 500 Hz, which is in line with the typical parameters used in the acquisition of ECG. The Chapman dataset specifically focuses on the classification of heart rhythm abnormalities. It defines eleven distinct classes encompassing various rhythm conditions, including sinus bradycardia, sinus rhythm, atrial fibrillation, sinus tachycardia, atrial flutter, sinus irregularity, supra-ventricular tachycardia, atrioventricular nodal re-entrant tachycardia, atrioventricular re-entrant tachycardia, and sinus arrhythmia with atrial wander. Notably, a significant overlap exists between these arrhythmia classes and those offered by the PTB-XL dataset. This compatibility facilitates the potential for combining these resources in order to obtain a more rich dataset as some of the classes have more representation in one of the datasets compared to the other."}, {"title": "5. Models", "content": "For the purpose of trying out different approaches to generative modeling, we have chosen to train three state of the art models, with the condition that the model's implementation was open sourced, and that we were able to train the models successfully without major modifications or extensive hyperparameter tuning. Here we provide a short description of each model."}, {"title": "5.1. Generative models", "content": "Denoising Diffusion models, given their immense popularity, it is no surprise these are also considered state of the art in synthetic time series generation. We opted for three different architectures, namely Diffwave, [54] Diffusion-TS [55] and the Unet1D conditional model from Huggingface. Diffwave, originally intended for audio data, is a non-autoregressive diffusion probabilistic model which supports conditional waveform generation. The model learns to convert white noise into a structured signal using a Markov chain with a constant number of steps at synthesis. It uses a variation of the variational lower bound as an optimization function on the data log likelihood, and supports local conditioning on linguistic features, the mel spectrogram, or the hidden states of the text to wave architecture. Furthermore, there is a global conditioner given by a discrete label, in which a shared embedding is used with dimension $d_{label} = 128$ in the original experiments [54]. The SSSD-ECG proposed in [35] is used in this work instead of the original Diffwave.\nThe Unet1D model from Huggingface's Diffusers library is based on the U-Net model, introduced in [56]. The U-Net architecture was created to address the challenge of limited annotated data in the medical field. It is composed of a contracting and an expansive path; the contracting path has encoder layers that capture contextual information and reduce the dimension of the input, while the expansive path works with decoder layers which learn to expand the dimension of the encoded data via skip connections to generate a segmentation map [56]. Given that the original implementation of the Unet1D diffusion model was not conditioned, we needed to condition it ourselves following the same conditioning scheme as in the Unet2D conditioned model, also provided by the Diffusers library. Please note that in the rest of this paper we refer to this model as Time-Diffusion.\nTime-VQVAE, presented in [57], is a two-step modeling approach similar to the one in [58] in which a VQ-VAE is used for the first stage and MaskGIT for the second. VQ-VAE acts on the frequency domain, separating the signals into their low and high frequency components after applying the short-term Fourier Transform (STFT). Then, two sets of encoder, decoder, and vector-quantizer are used to learn the discrete latent spaces for LF and HF, and afterwards, priors of these spaces are learned with two bidirectional Transformer models. Lastly, the model jointly and conditionally samples sets of LF and HF discrete latent vectors from the learned priors and decodes them into the time-domain with the learned decoders."}, {"title": "5.2. Classification model", "content": "In order to evaluate the quality of the generated data in our experiments and its effect on classification tasks, this work proposes to use a 1D CNN model similar to a ResNet classifier ([59]). This architecture has been extensively used in the ECG classification literature, [48] and has become the standard model for this kind of problems. The input of the model has shape (bs, c, h, w) where bs is the batch size, c is the number of channels, h the height of the signal and w the number of steps in the signal. We have considered h = 1 and c to be the number of signals from the ECG so the input becomes a tensor of shape (bs, c, w). The first layer of the model consists in a 1d convolutional layer that keeps the length of the input signal. Then, a set of convolutional blocks consisting on 1d convolutional layers with residual connections and with ReLU activations functions are considered. Following the convolutional blocks, a set of dense layers are used in order to provide the final output of the model. The values for the hyperparameters have been obtained by using a tree-structured parzen estimator algorithm ([60]). Hyperparameters are different based on the dataset used as shown in Table 3. A simplified diagram of the model is shown in Figure 1."}, {"title": "6. Methodology", "content": "This work focuses on the generation of realistic electrocardiogram (ECG) signals. To achieve this goal, we leverage two established ECG datasets: PTB-XL and Chapman. Each dataset offers unique characteristics and information about cardiac electrical activity. To fully exploit this data diversity, we employ a tailored approach.\nFor each dataset, a distinct generative model will be trained. This isolates the model's learning process on the specific features and statistical properties present in each dataset. Subsequently, a comprehensive evaluation will be conducted to assess the quality and realism of the synthetic ECG representations generated for each individual dataset.\nFollowing these individual evaluations, we will explore the potential benefits of combining the information from both the PTB-XL and Chapman datasets. A new, unified dataset will be constructed by merging the ECG signals from both sources. This enriched dataset will encompass a broader range of ECG signal variations and potentially offer a more comprehensive representation of human cardiac electrical activity. Leveraging this newly created dataset, we will train new generative models. These models will be tasked"}, {"title": "7. Evaluation", "content": "Evaluating the quality of generated time series data remains an open challenge, unlike synthetic images where established metrics like Fr\u00e9chet Inception Distance (FID) [61] or Maximum Mean Discrepancy (MMD) [62] exists. The concept of \"natural\" time series and pre-trained feature extraction networks, crucial for FID in images, isn't directly applicable here. Additionally, capturing the underlying information in real data through the generated data distribution presents difficulties, especially for conditional generation tasks. Due to the lack of a way to assess the quality of the generated data, we explore different heuristics with different hypothesis:\n1. Visualizations: Use of dimensionality reduction techniques like t-Distributed Stochastic Nieghbor Embedding (t-SNE) [63], Uniform Manifold Approximation and Projection (UMAP) [64] and Pairwise Controlled Manifold Approximation projection (PaCMAP) [65]. The goal is to validate through visualizations in a two dimensional space if the distribution of the generated synthetic data and the real data cluster together.\n2. Metrics:\n\u2022 2-Sample test classification score: A classifier trained with real data is used in order to discriminate between real data and synthetic data. If the classifier"}, {"title": "7.1. Classifier evaluations", "content": "As an evaluation approach, we have chosen to analyze changes in classification performance metrics (accuracy, precision, recall and roc-auc) through training of a classifier (or a pre-trained classifier on synthetic data for the transfer learning task) on different combinations of real and synthetic data for the train and the evaluation:\n1. Training-Testing Split variations:\n\u2022 TrRTER: Train and evaluate on real data.\n\u2022 TrSTeS: Train and evaluate on synthetic data.\n\u2022 TrSTeR: Train on synthetic data and evaluate on real data.\n\u2022 TrRTeS: Train on real data and evaluate on synthetic data.\n\u2022 TrRSTER: Train on a mix of real and synthetic data and evaluate on real data.\n2. Transferability: Train on synthetic. Then perform fine-tuning of the model by freezing all the layers except the ones of the classifier (dense layers near the output of the model) and add different proportions of real data. The goal is to evaluate the amount of real samples needed to successfully tune the synthetically pre-trained model and achieve an equal or better performance metric than the model trained only with real data.\nThese evaluations aim to understand how different training procedures on real and synthetic data impact classification tasks. The ultimate goal is to improve the classifier's performance with synthetic data as opposed to using only real data during training."}, {"title": "8. Experiments", "content": "In order to evaluate the synthetic data, the same experiments are performed on three ECG datasets: PTB-XL, CHAPMAN and a merge of PTB-XL with CHAPMAN.\nThe first experimental stage consists on obtaining a classifier that is able to discern the patterns of different ECG classes considered in the real data and find the hyperparameters of the model that will be used with different combinations of the real data and synthetic data. This means that a subset of classes is selected in order to make proper comparison between the PTB-XL and CHAPMAN datasets. The selected classes are sinus bradycardia (SBRAD), sinus rhythm (SR), atrial fibrilation (AFIB), sinus tachycardia (STACH), atrial flutter (AFLT), sinus arrhythmia (SARRH) and supraventricular"}, {"title": "9. Results", "content": "The results obtained in the experiments highlight that generated samples with current state of the art methods from Deep Learning cannot be used as standalone data in order to substitute real data. When considering the use of synthetic data as a technique to increase the number of samples of low represented classes, the conclusions are similar when considering only the PTB-XL or CHAPMAN datasets individually, but results"}, {"title": "9.1. PTB-XL experiments", "content": "Table 5 shows the results of the experiments performed on the PTB-XL dataset. The first row shows the results of a classifier trained and evaluated with real data only."}, {"title": "9.2. CHAPMAN experiments", "content": "Following the same structure from the previous subsection, Table 7 shows the results of the experiments performed on the CHAPMAN dataset where the first row corresponds to the model trained with real data only.\nIn general, the scores in the TrRSTER setting from each generative model are very close to the scores of the real data only model.\nFor each specific generative model, we observer that diffwave falls behind in all the scores in the hybrid settings and scores better in the synthetic only setting, TrSTeS. In the case of Time-Diffusion the scores are behind those obtained with the real data only model but higher than the classifiers trained on diffwave samples, observe that in the TrRTeS setting the scores obtained by the trained classifiers are higher than any other of"}, {"title": "9.3. PTB-XL + CHAPMAN experiments", "content": "Finally, the experiments are repeated on a merge of both datasets, PTB-XL and CHAPMAN. From this new dataset the low represented classes from each dataset will increase"}, {"title": "10. Conclusions", "content": "The results obtained in the experiments highlight that generated samples with current state of the art methods from Deep Learning cannot be used as standalone data in order to substitute real data. When considering the use of synthetic data as a technique to increase the number of samples of low represented classes, the conclusions are similar when considering only the PTB-XL or CHAPMAN datasets individually, but results"}, {"title": "10.1. The effect of synthetic data. It helps?", "content": "The results obtained in the experiments highlight that generated samples with current state of the art methods from Deep Learning cannot be used as standalone data in order to substitute real data. When considering the use of synthetic data as a technique to increase the number of samples of low represented classes, the conclusions are similar when considering only the PTB-XL or CHAPMAN datasets individually, but results from the experiments on the PTB-XL+CHAPMAN datasets show an increase in all metrics under the TrRSTeS setting, pointing towards a better quality of the synthetic data that helps to improve (slightly) the classifiers' performance.\nFor the transfer learning experiments it can be said that there is not a clear advantage on using a pre-trained model on synthetic data as classifiers being fine-tuned with all the real data are not able to get scores as high as the model trained with all the real data. This is observed across all the studied datasets and settings."}, {"title": "10.2. About the generative models. Is there a clear winner?", "content": "Although the quality of the generated samples does not match the real data, experiments show that diffwave samples seem worse than those from Time-Diffusion and Time-VQVAE. For Time-VQVAE and Time-Diffusion is somehow difficult to evaluate if one is superior than the other in the experiments with different settings of real and synthetic data, but the fine-tuning experiments highlight a superiority in the samples from Time-VQVAE in all the scores by a large amount. Also it has been observed that the Time-VQVAE samples help to reduce the number of false positives in the TrSTeR setting across all the datasets."}, {"title": "10.3. Methods to differentiate real from synthetic. Which one to use?", "content": "Different techniques to differentiate real from synthetic samples suggested in the literature have been tested: MMD, 2-sample test, reduction-based visualization techniques and classifiers. From those it has been observed that MMD and visualization techniques lack the power to differentiate synthetic data from real one as the results suggest that synthetic and real data share the same distribution. On the other hand, evaluation methods using classifiers, 2-sample test and classifiers under different settings, have shown that there is indeed a difference between synthetic and real data. The problem of using classifiers to assess the quality of the data is the lack of a function and the need to fit multiple models, something that could be not possible in some problems."}, {"title": "10.4. Next steps", "content": "This work highlights different problems in the current literature in order to work with synthetic data that tries to resemble periodic Time Series like ECG but in particular there is one that is more important than any other: the lack of a metric to be able to quantify the difference between the real and the synthetic data. Such quantification will be of much help in detecting authorship from popular generative models like ChatGPT as highlighted in [66].\nIt has been observed that the merge of the PTB-XL and CHAPMAN datasets has helped to improve the classifiers when trained in the TrRSTeR setting, and interpreting such setting as applying data augmentation. This highlights that using a bigger dataset could help in order to create an ECG generative model able to generate samples with good enough quality so that they can be used for data augmentation in other tasks.\nFinally, it would be of interest to replicate the experiments presented in this work with other types of physiological data such as EEGs and compare the results about the"}, {"title": "11. Acknowledgments", "content": "This research has been funded by the Artificial Intelligence for Healthy Aging (AI4HA, MIA.2021.M02.0007) project from the Programa Misiones de I+D en Inteligencia Artificial 2021 and by the European Union-NextGenerationEU, Ministry of Universities and Recovery, Transformation and Resilience Plan, through a call from Universitat Polit\u00e8cnica de Catalunya (Grant Ref. 2021UPC-MS-67461)."}]}