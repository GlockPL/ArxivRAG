{"title": "Zero-shot Cross-Lingual Transfer for Synthetic Data Generation in Grammatical Error Detection", "authors": ["Gaetan Lopez Latouche", "Marc-Andr\u00e9 Carbonneau", "Ben Swanson"], "abstract": "Grammatical Error Detection (GED) methods rely heavily on human annotated error corpora. However, these annotations are unavailable in many low-resource languages. In this paper, we investigate GED in this context. Leveraging the zero-shot cross-lingual transfer capabilities of multilingual pre-trained language models, we train a model using data from a diverse set of languages to generate synthetic errors in other languages. These synthetic error corpora are then used to train a GED model. Specifically we propose a two-stage fine-tuning pipeline where the GED model is first fine-tuned on multilingual synthetic data from target languages followed by fine-tuning on human-annotated GED corpora from source languages. This approach outperforms current state-of-the-art annotation-free GED methods. We also analyse the errors produced by our method and other strong baselines, finding that our approach produces errors that are more diverse and more similar to human errors.", "sections": [{"title": "Introduction", "content": "Grammatical Error Detection (GED) refers to the automated process of detecting errors in text. It is often framed as a binary sequence labeling task where each token is classified as either correct or erroneous (Volodina et al., 2023; Kasewa et al., 2018). GED is widely used in language learning applications and contributes to the performance of grammatical error correction (GEC) systems (Yuan et al., 2021; Zhou et al., 2023; Sutter Pessurno de Carvalho, 2024).\nPrior research in multilingual GED has primarily operated in supervised settings (Volodina et al., 2023; Colla et al., 2023; Yuan et al., 2021), relying on human annotated data for training. Despite recent efforts to obtain annotated corpora (N\u00e1plava et al., 2022; Alhafni et al., 2023) many languages still lack these resources, motivating research on methods operating without GED annotations.\nTo overcome the absence of human annotations, researchers have explored two primary approaches. The first involves language-agnostic artificial error generation (AEG). This is achieved using rules (Rothe et al., 2021; Grundkiewicz and Junczys-Dowmunt, 2019), non-autoregressive translation (Sun et al., 2022), or round-trip translation (Lichtarge et al., 2019). These methods are not trained to replicate human errors and compare unfavorably to supervised techniques like back-translation (Kasewa et al., 2018; Stahlberg and Kumar, 2021; Kiyono et al., 2019; Luhtaru et al., 2024b) which train models to learn to generate human errors.\nThe second approach leverages the cross-lingual transfer (CLT) capabilities of BERT-like (Devlin et al., 2019) multilingual pre-trained language models (mPLMs). This involves fine-tuning a GED model on languages with abundant human annotations (termed as source languages) and evaluating their performance on languages devoid of human annotations (referred to as target languages). While certain languages exhibit unique error types, most adhere to shared linguistic rules, which mPLMs can exploit to detect errors across languages.\nIn this paper, we hypothesize that error generation also share linguistic similarities across languages. We propose a novel approach to zero-shot CLT in GED by combining back-translation with the CLT capabilities of mPLMs to perform AEG in various target languages. Our methodology involves a two-stage fine-tuning pipeline: first, a GED model is fine-tuned on multilingual synthetic data produced by our language-agnostic back-translation approach; second, the model undergoes further fine-tuning on human-annotated GED corpora from the source languages.\nWe experiment on 6 source and 5 target languages and show that our technique surpasses previous state-of-the-art annotation-free GED methods. In addition, we provide a detailed error analysis comparing several AEG methods to ours. The contributions of this paper are as follows:\n\u2022 We introduce a novel state-of-the-art method for GED on languages without annotations.\n\u2022 We show that we can leverage the CLT capabilities of mPLMs for synthetic data generation to improve performance on a different downstream task, in our case GED.\n\u2022 We provide the first evaluation of GEC annotation-free synthetic data generation methods applied to multilingual GED.\n\u2022 We release a synthetic GED corpus comprising over 5 million samples in 11 languages."}, {"title": "Related Work", "content": "GED Originally addressed through statistical (Gamon, 2011) and neural models (Rei and Yannakoudakis, 2016), GED is now tackled using pre-trained language models (Kaneko and Komachi, 2019; Bell et al., 2019; Yuan et al., 2021; Colla et al., 2023; Le-Hong et al., 2023).\nHistorically, most research in GED has been concentrated on the English language. However, recently, Volodina et al. (2023) organised the first shared task on multilingual GED in which Colla et al. (2023) set state-of-the-art in all non-English datasets by fine-tuning a XLM-ROBERTa large model on human annotated data in a monolingual setting. While we follow their methodology to train our GED model, we complement prior research by exploring GED for languages lacking annotations.\nArtificial Error Generation Current methods for AEG can be broadly categorized into language-agnostic and language-specific approaches. Language-specific methods focus on replicating the error patterns found in a specific GEC corpora. This can involve heuristic approaches tailored to mimic the linguistic errors identified in GEC corpora (Awasthi et al., 2019; Cao et al., 2023a; N\u00e1plava et al., 2022), or employing techniques such as back-translation (Kasewa et al., 2018; Stahlberg and Kumar, 2021; Kiyono et al., 2019; Luhtaru et al., 2024b). While effective for languages with annotated corpora, these methods are not suitable for languages lacking such resources.\nIn contrast, there are few language-agnostic methods for generating artificial errors. Grundkiewicz and Junczys-Dowmunt (2019) introduce errors in a corpus by deleting, swapping, inserting and replacing words and characters. Replacements rely on confusion sets obtained from an inverted spellchecker. Lichtarge et al. (2019) introduce noise via round-trip translation using a bridge language. Finally, Sun et al. (2022) corrupt sentences by performing non-autoregressive translation using a pre-trained cross-lingual language model. All these error generation techniques have primarily been applied to GEC, and to the best of our knowledge, their performance has not been evaluated on GED.\nOur work advances existing synthetic data generation methods by exploring a language-agnostic variant of back-translation.\nUnsupervised GEC Unlike GED, GEC without human annotations has been explored in several studies (Alikaniotis and Raheja, 2019; Yasunaga et al., 2021; Cao et al., 2023b). State-of-the-art unsupervised GEC systems (Yasunaga et al., 2021; Cao et al., 2023b) typically begin with the development of a GED model trained on erroneous sentences generated through rule-based methods (Awasthi et al., 2019) or masked language models (Cao et al., 2023b). This GED model is subsequently used with the Break-It-Fix-It (BIFI) method to create an unsupervised GEC system.\nHowever, the methods used by Yasunaga et al. (2021); Cao et al. (2023b) for creating the GED model are not language-agnostic, as they rely on a thorough analysis of language-specific error patterns, making them difficult to apply to languages lacking such annotations.\nCross-lingual transfer Previous studies have shown the capacity of mPLMs to generalize to languages unseen during fine-tuning for both NLU (Conneau et al., 2020; Chi et al., 2021; Lopez Latouche et al., 2024) and generative tasks (Xue et al., 2021; Chirkova and Nikoulina, 2024; Shaham et al., 2024). Close to our work, Yamashita et al. (2020) explored cross-lingual transfer in GEC, a closely related topic. Their findings indicate that pre-training with Masked Language Modeling and Translation Language Modeling enhances cross-lingual transfer. Additionally, they show that fine-tuning on a combination of a high and a low-resource language improves the performance of GEC models on the low-resource language.\nIn contrast to Yamashita et al. (2020) our research focuses on zero-shot cross-lingual transfer, specifically for GED and AEG, without relying"}, {"title": "Method", "content": "Our proposed GED method is developed through a four-step process, as illustrated in Figure 1. Initially, we train a multilingual AEG model using GEC datasets from the source languages. This AEG model is subsequently employed to produce a GED dataset encompassing both target and source languages. In the third step, we fine-tune a GED model on this multilingual artificially generated dataset. Finally, we perform an additional fine-tuning of the GED model using human-annotated GED data from the source languages. The resultant GED model is capable of detecting errors across any target language.\nData Our method necessitates three types of corpora. First, the AEG model is trained using GEC datasets in a collection of source languages, \\(D_s\\), which include pairs of ungrammatical sentences and their corrected versions. Additionally, monolingual corpora in the source languages \\(D_s\\) and in the target low-resource languages \\(D_t\\), consisting of raw sentences, are required.\nAEG Training The AEG is a generative mPLM trained on a dataset \\(D_s\\), combining all source languages, using the corrected text as input and the ungrammatical one as output. Post-training, the AEG can introduce errors in any language supported by the mPLM, leveraging the inherent zero-shot cross-lingual transfer capabilities of generative mPLMs.\nGED Artificial Data Creation Using our AEG system we obtain a multilingual dataset \\(D^{synth}_s\\) of raw sentences and their corresponding synthetically generated ungrammatical versions by corrupting sentences from \\(D_s\\) and \\(D_t\\). We obtain GED token-level annotation from \\(D^{synth}\\) by tokenizing using language-specific tokenizers, and aligning both sentence versions using Levenshtein distance with minimal alignment following Kasewa et al. (2018). We follow the labeling methodology of Volodina et al. (2023); Kasewa et al. (2018). We designate tokens that are not aligned with themselves or tokens following a gap as incorrect, while remaining tokens are labeled as correct.\nGED model fine-tuning We propose a two-stage methodology for our multilingual GED model akin to supervised GEC (Grundkiewicz et al., 2019; Rothe et al., 2021; Luhtaru et al., 2024a). Models are initially fine-tuned on synthetic data and later refined with human-annotated data. Our approach begins with the fine-tuning of an mPLM such as XLM-R (Conneau et al., 2020) on our synthetically generated multilingual GED datasets. Then, we fine-tune this model using human-annotated GED data from all our source languages, \\(D_s\\)."}, {"title": "Experimental Setup", "content": "We use English, German, Estonian, Russian, Icelandic, and Spanish as our source languages and Swedish, Italian, Czech, Arabic, and Chinese as our target languages. For each dataset, when multiple subsets are available we use the L2 learners' corpora and the annotations for minimal corrections for grammaticality.\nTraining set The English, German, Estonian, Russian, Icelandic, and Spanish datasets are taken from the FCE corpus (Yannakoudakis et al., 2011), the Falko-MERLIN GEC corpus (Boyd, 2018), UT-L2 GEC (Rummo and Praakli, 2017), RULEC-GEC (Rozovskaya and Roth, 2019), the Icelandic language learners section of the Icelandic Error Corpus (Arnard\u00f3ttir et al., 2021), and COWS-L2H (Davidson et al., 2020), respectively. We use the training set of each of these GEC datasets to train"}, {"title": "Baselines", "content": "We evaluate the proposed artificial error generation method against strong baselines that do not require human-annotated datasets in the target language. We chose methods representative of different family of artificial error generation in GEC: Rules (Grundkiewicz and Junczys-Dowmunt, 2019), Round-trip translation (RT translation) (Lichtarge et al., 2019), Non auto-regressive translation (NAT) (Sun et al., 2022). Additionally, we compare our approach with a zero-shot CLT baseline, which involves directly fine-tuning the GED model on GED datasets from all source languages. We refer to this technique as Direct-CLT to distinguish it from our method, which uses the cross-lingual transfer capabilities of generative mPLMs to generate errors in any target language. More information on the implementations of our baselines in Appendix A.1."}, {"title": "Models and Fine-tuning setups", "content": "Synthetic Data Generation We use the No Language Left Behind (NLLB-200) model (Team et al., 2022) which supports 202 languages as our generative mPLM. Specifically, we use NLLB 1.3B-distilled for all our experiments. Following Luhtaru et al. (2024b), we train the model on non-tokenized text or detokenized if the non tokenized format is not available. Details regarding our hyperparameters can be found in Appendix A.2.\nGrammatical Error Detection In line with (Colla et al., 2023), we use XLM-ROBERTa-large, a multilingual pre-trained encoder with strong cross-lingual abilities (Conneau et al., 2020) as our GED model. We evaluate two versions of our method: (1) A Monolingual version, where the GED model is exclusively trained on synthetic data from the target language, enabling direct comparison with existing synthetic data generation techniques. (2) A Multilingual version using our two-stage fine-tuning procedure to compare against DirectCLT."}, {"title": "Evaluation of AEG", "content": "As all previous work using AEG for GED has been in monolingual settings, we introduce a monolingual variant of our approach. Here, the GED model is exclusively fine-tuned on synthetic data from the target language.\nTable 2 shows that our synthetic data generation technique achieves the best performance among annotation-free synthetic data generation methods applied to GED. Given that rule-based methods apply a set of transformations without considering the sentence context, the average improvement of 9.2 points of \\(F_{0.5}\\) over these methods highlights the significance of generating context-dependent errors in synthetic data generation. Additionally, given that NAT is not trained to generate errors but to produce translations, outperforming this method by 8.3 points of \\(F_{0.5}\\) highlights the advantage of learning to generate errors from authentic instances, even when these instances originate from different languages.\nWe hypothesize that the ability to synthesize context-dependent errors combined with the acquisition of error-generation insights from authentic instances empower our method to yield errors more akin to human errors, thus leading to better performance. We further analyze this hypothesis in 6.1.\nAdditionally, our monolingual setup outperforms DirectCLT in four out of five languages. This is a notable achievement given other synthetic data generation methods' inability to meet this benchmark. Both approaches leverage the CLT of mPLMs, albeit differently: ours uses it for artificial error generation in target languages with a generative mPLM, while DirectCLT leverages it directly to perform error detection across target languages. This comparison suggests that our method creates tailored error patterns in target languages that a GED model trained only on source language annotations cannot detect, indicating that our approach to CLT in GED could generalize to other NLU tasks, which is a promising avenue for future research."}, {"title": "Language Ablation", "content": "We study the effect of changing the language configuration of the synthetic data. We compare fine-tuning the GED model using synthetic data comprising different language sets: exclusively source languages, exclusively target languages, and a combination of both source and target languages.\nResults in Table 3 show that any first stage fine-tuning language configuration improves the GED performance of our method over the DirectCLT baseline, highlighting the robustness of our two-stage fine-tuning pipeline. Notably, including synthetic data from the target language results in a more significant improvement which emphasize the importance of using a language-agnostic artificial error generation method capable of generating errors in any target language.\nFurthermore, results from Table 3 suggest that first-stage fine-tuning exclusively on synthetic data from target languages outperforms fine-tuning on a combination of source and target languages. However, comparing \\(F_{0.5}\\) scores does not reveal the big picture and can lead to false conclusion. The \\(F_{0.5}\\) score is computed at an operation point that is usually arbitrarily set to 0.5 in the literature (Kasewa et al., 2018; Colla et al., 2023; Le-Hong et al., 2023). For a more comprehensive comparison of performance, Figure 2 presents the Precision-Recall curves for each method. It shows that fine-tuning on either synthetic data from source and target languages or target languages alone yields similar results. We can conclude that the determining factor is the inclusion of synthetic data in the target language. We can also see that our method outperforms other baseline in the curves too. We encourage practitioners to use such figures to compare GED models for more meaningful conclusions than threshold dependant metrics such as F scores.\nWe experimented with reversing our fine-tuning pipeline by initially training on human annotations from our source languages followed by fine-tuning on synthetic data. However, this approach empirically yielded inferior performance. The fact that ending the fine-tuning process with human-annotated data, even in source languages, is more effective than using target language synthetic data indicates that artificial errors still do not reach the quality of authentic corpora. Otherwise it would make sense to end the training with errors specific to the target language. We hypothesize that improved synthetic error generation techniques would lead to opposite conclusions regarding the fine-tuning order."}, {"title": "Scalability", "content": "Here we investigate how our synthetic data generation method scales as new languages corpora become available. We fine-tune the AEG model by progressively incorporating new languages in different orders to an English-only fine-tuned baseline. We follow the protocol of Shaham et al. (2024). We"}, {"title": "Generalization to out-of-domain errors", "content": "Errors vary between different populations. For instance native speakers (L1) do not commit the same type of errors than second language learners (L2). We investigate the robustness of our method to different error distributions. Our method is trained on L2 learner corpora and we evaluate it on L1 data. We found available GED annotated data of L1 speakers for Arabic and Czech: QALB 2014 (Mohit et al., 2014) and the Native Formal section of GECCC (N\u00e1plava et al., 2022).\nTable 4 presents the results. Our method surpasses all other baselines, demonstrating its continued suitability for out-of-domain corpora in the target language. Unlike the other baselines, our method achieves approximately similar performance on both L1 and L2 Arabic corpora. However, for Czech, all methods show a significant decrease in performance. We hypothesize that this is due to the unique stringent rules regarding the use of commas in Czech. This results in the predominance of \"Punctuation\" errors in the L1 Czech corpora, which are less common in many other languages, and therefore amplify the difference between domains."}, {"title": "Czech Case Study", "content": "Similarity Analysis with Human Errors To assess if the synthetic instances are realistic and human-like, we train a binary classifier (one per synthetic data generation technique) to distinguish between errors generated by a particular synthetic data generation method and human errors. We constructed a development set comprising approximately equal numbers of authentic and synthetic data and assessed performance using the \\(F_1\\) score. More information on how we train the classifier can be found in A.3. Results are presented in Table 5.\nOur classifier achieves an \\(F_1\\) score of 83.4% for the proposed method, indicating a moderate ability to differentiate between synthetic and human errors. This supports our hypothesis that our synthetic data generation method does not fully replicate the quality of authentic sentences. In contrast, the classifier achieves an \\(F_1\\) score exceeding 95% for other synthetic data generation methods, suggesting a higher degree of differentiation. Overall, this suggests that our method produces errors that are more human-like, translating into better downstream performance.\nError Distribution We use the Czech extension (N\u00e1plava et al., 2022) of ERRANT to categorize the errors made by different systems. Figure 4 presents the distribution of the top 10 error types for the various synthetic data generation methods studied. Our method produces a more diverse set of errors compared to NAT (Sun et al., 2022) and"}, {"title": "Multilingual Extension", "content": "We want to extend our previous findings by assessing if our synthetic data generation method effectively captures a variety of error types across all languages. For this, we need a language-agnostic classifier. We use GPT-4 to classify errors from various sources across all the languages under investigation. Prior studies have shown that GPT-4's judgments align closely with human evaluations (Wang et al., 2023; Fu et al., 2023) and exhibit promising error correction capabilities (Fang et al., 2023; Davis et al., 2024; Wu et al., 2023). Although a thorough assessment of GPT-4 for error classification is beyond the scope of the study, we performed a limited qualitative analysis of GPT-4's accuracy in Italian, Swedish, Spanish, and English with native speakers. We found that it is suitable for our application. For each type of error classified by GPT-4 we compute its frequency distribution across data and compute the entropy of this distribution. Further details on our evaluation methodology are provided in Appendix A.4.\nFigure 5 validates our previous findings that our method generates a more diverse set of errors compared to NAT. However, the range of error types generated by our method is narrower than that produced by humans. Moreover, the variability in the diversity of error types is significantly higher with our method than with human errors across different languages. This suggests that our method does not consistently perform across languages."}, {"title": "Conclusion", "content": "We introduced a novel zero-shot approach for GED with low-resource languages. Our method combines back-translation with the CLT capabilities of mPLMs to perform AEG across various target languages. Then, we fine-tune the GED model in two steps: first on multilingual synthetic data from source and target languages, then on human-annotated source language corpora. This method achieves state-of-the-art performance in annotation-free GED. Our error analysis shows that we produce errors that are more diverse and human-like than the baselines.\nIn future work, we intend to explore the potential of our GED models to enhance unsupervised GEC methods."}, {"title": "Limitations", "content": "Our approach relies on the CLT capabilities obtained during the multilingual unsupervised pre-training of mPLMs. Consequently, the applicability of our method is restricted to the languages supported by the mPLM. Furthermore, its performance on each language may vary depending on the amount of pre-training data available for that language. This limitation is inherent to all studies leveraging mPLMs.\nAdditionally, our study primarily focuses on the errors made by second language learners. While we have analyzed the performance of our method on native language corpora, it would be valuable to evaluate its generalizability to other domains within a language. For instance, this includes errors made in casual text messaging or by machine translation"}, {"title": "Ethics Statement", "content": "Our research is driven by a commitment to supporting and preserving linguistic diversity. Low-resource languages often face marginalization in the realm of technological advancements. By developing GED models for these languages, we aim to enhance their digital presence and usability, thus promoting linguistic equity.\nHowever, it is important to acknowledge potential ethical concerns. The use of CLT to generate synthetic data, while beneficial for training GED models, carries the risk of misuse. Such systems could potentially be exploited to create false information or propaganda in low-resource languages. Additionally, while GED systems are crucial for regions with a shortage of language teachers, there is a risk that their widespread use could lead to an over-reliance on these tools. This dependency might result in a decline in the linguistic and grammatical skills of native speakers, as they become more reliant on technology for language correction and validation.\nIt is essential for future users to use these technologies judiciously. Balancing the use of GED tools with a genuine effort to improve one's linguistic abilities is crucial. Building on the research by Fei et al. (2023) could provide a valuable advancement by incorporating explainability into our GED systems."}, {"title": "Appendix", "content": "Rules We re-implemented Grundkiewicz and Junczys-Dowmunt (2019) using Aspell dictionaries\u00b9 for the replacement operation.\nNAT We replicated the NAT model using InfoXLM (Chi et al., 2021) and English as source language, following (Sun et al., 2022) methodology. For non-autoregressive translation generation, we used Europarl (Koehn, 2005) for Italian, Swedish and Czech and the UN Parallel Corpus v1.0 (Ziemski et al., 2016) for Arabic and Chinese. We conducted hyper-parameter tuning for the NAT-based data construction by exploring the parameter set specified in (Sun et al., 2022) and selected the optimal parameters for each language based on performance on the development set.\nRT translation We use OPUS-MT (Tiedemann and Thottingal, 2020) as our translation model and English as the bridge language."}, {"title": "Implementation details", "content": "Artificial error generation We use two distinct AEG models to generate errors in target and source languages, both based on NLL 1.3B-distilled but trained with different hyper-parameters.\nFor synthetic data generation in target languages, we conduct preliminary grid searches on the Swedish development set to determine the optimal hyperparameters. We select the learning rate from {1e-4, 5e-4, 1e-5, 5e-5} and the number of epochs from {3, 5, 10, 15, 20}. Ultimately, we set the learning rate to le-5 and fine-tune for 3 epochs with a batch size of 24 and a linear scheduler.\nFor synthetic data generation in source languages, we use a different set of hyper-parameters based on grid searches on the English development set. The learning rate is set to le-4, and we fine-tune for 10 epochs with a batch size of 24 and a linear scheduler.\nGrammatical error detection Based on initial experiments with the Swedish development set, we use a learning rate of le-5, a batch size of 24, and train for 5 epochs with a linear scheduler. In our second-stage experiments, we maintain the same setup but fine-tune for only 1 epoch.\nMonolingual corpora: As mentioned in Section 4.1, our monolingual text data is sourced from the CC100 dataset (Conneau et al., 2020), from which"}, {"title": "Similarity Analysis details", "content": "To distinguish between authentic and synthetic instances, we train a binary classifier. The classifier processes a pair of sentences: a grammatical sentence and its corresponding ungrammatical version separated by a separator token. Its task is to identify whether the ungrammatical sentence is synthetic or authentic. We train separate binary classifiers for each synthetic data generation method, using mdeberta-v3-base (He et al., 2023) as our backbone."}, {"title": "GPT-4 analysis details", "content": "To evaluate the linguistic diversity of errors across different languages, we employed GPT-4 as an error classifier. Specifically, we used GPT-4 to describe the nature of the errors in sentences. Without constraining GPT-4 to a predetermined set of error types, it generated a diverse range of error descriptions for similar errors.\nWe then categorized these errors into distinct clusters using a clustering method based on the sentence embeddings generated using sentence-transformers (Reimers and Gurevych, 2019). In particular, we applied KMeans clustering with four different values of K (16, 32, 64, 128). This approach produced multiple sets of clusters, each representing distinct error patterns within the dataset.\nFor each value of K, we computed the frequency distribution of errors across the clusters and subsequently calculated the entropy of these distributions. To enable comparison across different values of K, we normalized the entropy values, ensuring comparability and eliminating bias from the number of clusters chosen.\nFinally, to derive a comprehensive measure of normalized entropy for each language under study, we averaged the normalized entropy values obtained across all K settings. The resulting normalized entropy metric provides a robust indicator of the diversity of error patterns observed across different languages, as illustrated in Figure 5."}]}