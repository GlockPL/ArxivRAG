{"title": "Zero-shot Cross-Lingual Transfer\nfor Synthetic Data Generation in Grammatical Error Detection", "authors": ["Gaetan Lopez Latouche", "Marc-Andr\u00e9 Carbonneau", "Ben Swanson"], "abstract": "Grammatical Error Detection (GED) methods\nrely heavily on human annotated error corpora.\nHowever, these annotations are unavailable in\nmany low-resource languages. In this paper, we\ninvestigate GED in this context. Leveraging the\nzero-shot cross-lingual transfer capabilities of\nmultilingual pre-trained language models, we\ntrain a model using data from a diverse set of\nlanguages to generate synthetic errors in other\nlanguages. These synthetic error corpora are\nthen used to train a GED model. Specifically\nwe propose a two-stage fine-tuning pipeline\nwhere the GED model is first fine-tuned on mul-\ntilingual synthetic data from target languages\nfollowed by fine-tuning on human-annotated\nGED corpora from source languages. This\napproach outperforms current state-of-the-art\nannotation-free GED methods. We also analyse\nthe errors produced by our method and other\nstrong baselines, finding that our approach pro-\nduces errors that are more diverse and more\nsimilar to human errors.", "sections": [{"title": "1 Introduction", "content": "Grammatical Error Detection (GED) refers to the\nautomated process of detecting errors in text. It\nis often framed as a binary sequence labeling task\nwhere each token is classified as either correct or\nerroneous (Volodina et al., 2023; Kasewa et al.,\n2018). GED is widely used in language learning\napplications and contributes to the performance of\ngrammatical error correction (GEC) systems (Yuan\net al., 2021; Zhou et al., 2023; Sutter Pessurno de\nCarvalho, 2024).\nPrior research in multilingual GED has primar-\nily operated in supervised settings (Volodina et al.,\n2023; Colla et al., 2023; Yuan et al., 2021), relying\non human annotated data for training. Despite re-\ncent efforts to obtain annotated corpora (N\u00e1plava\net al., 2022; Alhafni et al., 2023) many languages\nstill lack these resources, motivating research on\nmethods operating without GED annotations.\nTo overcome the absence of human annota-\ntions, researchers have explored two primary ap-\nproaches. The first involves language-agnostic ar-\ntificial error generation (AEG). This is achieved\nusing rules (Rothe et al., 2021; Grundkiewicz\nand Junczys-Dowmunt, 2019), non-autoregressive\ntranslation (Sun et al., 2022), or round-trip trans-\nlation (Lichtarge et al., 2019). These methods are\nnot trained to replicate human errors and compare\nunfavorably to supervised techniques like back-\ntranslation (Kasewa et al., 2018; Stahlberg and\nKumar, 2021; Kiyono et al., 2019; Luhtaru et al.,\n2024b) which train models to learn to generate hu-\nman errors.\nThe second approach leverages the cross-lingual\ntransfer (CLT) capabilities of BERT-like (Devlin\net al., 2019) multilingual pre-trained language mod-\nels (mPLMs). This involves fine-tuning a GED\nmodel on languages with abundant human annota-\ntions (termed as source languages) and evaluating\ntheir performance on languages devoid of human\nannotations (referred to as target languages). While\ncertain languages exhibit unique error types, most\nadhere to shared linguistic rules, which mPLMs\ncan exploit to detect errors across languages.\nIn this paper, we hypothesize that error genera-\ntion also share linguistic similarities across lan-\nguages. We propose a novel approach to zero-\nshot CLT in GED by combining back-translation\nwith the CLT capabilities of mPLMs to perform\nAEG in various target languages. Our method-\nology involves a two-stage fine-tuning pipeline:\nfirst, a GED model is fine-tuned on multilingual\nsynthetic data produced by our language-agnostic\nback-translation approach; second, the model un-\ndergoes further fine-tuning on human-annotated\nGED corpora from the source languages.\nWe experiment on 6 source and 5 target lan-\nguages and show that our technique surpasses previ-\nous state-of-the-art annotation-free GED methods.\nIn addition, we provide a detailed error analysis"}, {"title": "2 Related Work", "content": "GED Originally addressed through statistical (Ga-\nmon, 2011) and neural models (Rei and Yan-\nnakoudakis, 2016), GED is now tackled using pre-\ntrained language models (Kaneko and Komachi,\n2019; Bell et al., 2019; Yuan et al., 2021; Colla\net al., 2023; Le-Hong et al., 2023).\nHistorically, most research in GED has been con-\ncentrated on the English language. However, re-\ncently, Volodina et al. (2023) organised the first\nshared task on multilingual GED in which Colla\net al. (2023) set state-of-the-art in all non-English\ndatasets by fine-tuning a XLM-ROBERTa large\nmodel on human annotated data in a monolingual\nsetting. While we follow their methodology to train\nour GED model, we complement prior research by\nexploring GED for languages lacking annotations.\nArtificial Error Generation Current meth-\nods for AEG can be broadly categorized\ninto language-agnostic and language-specific ap-\nproaches. Language-specific methods focus on\nreplicating the error patterns found in a specific\nGEC corpora. This can involve heuristic ap-\nproaches tailored to mimic the linguistic errors\nidentified in GEC corpora (Awasthi et al., 2019;\nCao et al., 2023a; N\u00e1plava et al., 2022), or employ-\ning techniques such as back-translation (Kasewa\net al., 2018; Stahlberg and Kumar, 2021; Kiyono\net al., 2019; Luhtaru et al., 2024b). While effective\nfor languages with annotated corpora, these meth-\nods are not suitable for languages lacking such\nresources.\nIn contrast, there are few language-agnostic\nmethods for generating artificial errors. Grund-\nkiewicz and Junczys-Dowmunt (2019) introduce\nerrors in a corpus by deleting, swapping, inserting\nand replacing words and characters. Replacements\nrely on confusion sets obtained from an inverted\nspellchecker. Lichtarge et al. (2019) introduce\nnoise via round-trip translation using a bridge lan-\nguage. Finally, Sun et al. (2022) corrupt sentences\nby performing non-autoregressive translation using\na pre-trained cross-lingual language model. All\nthese error generation techniques have primarily\nbeen applied to GEC, and to the best of our knowl-\nedge, their performance has not been evaluated on\nGED.\nOur work advances existing synthetic data gen-\neration methods by exploring a language-agnostic\nvariant of back-translation.\nUnsupervised GEC Unlike GED, GEC without hu-\nman annotations has been explored in several stud-\nies (Alikaniotis and Raheja, 2019; Yasunaga et al.,\n2021; Cao et al., 2023b). State-of-the-art unsuper-\nvised GEC systems (Yasunaga et al., 2021; Cao\net al., 2023b) typically begin with the development\nof a GED model trained on erroneous sentences\ngenerated through rule-based methods (Awasthi\net al., 2019) or masked language models (Cao et al.,\n2023b). This GED model is subsequently used\nwith the Break-It-Fix-It (BIFI) method to create an\nunsupervised GEC system.\nHowever, the methods used by Yasunaga et al.\n(2021); Cao et al. (2023b) for creating the GED\nmodel are not language-agnostic, as they rely on\na thorough analysis of language-specific error pat-\nterns, making them difficult to apply to languages\nlacking such annotations.\nCross-lingual transfer Previous studies have\nshown the capacity of mPLMs to generalize to lan-\nguages unseen during fine-tuning for both NLU\n(Conneau et al., 2020; Chi et al., 2021; Lopez La-\ntouche et al., 2024) and generative tasks (Xue et al.,\n2021; Chirkova and Nikoulina, 2024; Shaham et al.,\n2024). Close to our work, Yamashita et al. (2020)\nexplored cross-lingual transfer in GEC, a closely re-\nlated topic. Their findings indicate that pre-training\nwith Masked Language Modeling and Translation\nLanguage Modeling enhances cross-lingual trans-\nfer. Additionally, they show that fine-tuning on a\ncombination of a high and a low-resource language\nimproves the performance of GEC models on the\nlow-resource language.\nIn contrast to Yamashita et al. (2020) our re-\nsearch focuses on zero-shot cross-lingual transfer,\nspecifically for GED and AEG, without relying"}, {"title": "3 Method", "content": "Our proposed GED method is developed through\na four-step process, as illustrated in Figure 1. Ini-\ntially, we train a multilingual AEG model using\nGEC datasets from the source languages. This\nAEG model is subsequently employed to produce a\nGED dataset encompassing both target and source\nlanguages. In the third step, we fine-tune a GED\nmodel on this multilingual artificially generated\ndataset. Finally, we perform an additional fine-\ntuning of the GED model using human-annotated\nGED data from the source languages. The resultant\nGED model is capable of detecting errors across\nany target language.\nData Our method necessitates three types of cor-\npora. First, the AEG model is trained using GEC\ndatasets in a collection of source languages, Ds,\nwhich include pairs of ungrammatical sentences\nand their corrected versions. Additionally, mono-\nlingual corpora in the source languages D, and in\nthe target low-resource languages Dt, consisting of\nraw sentences, are required.\nS\nAEG Training The AEG is a generative mPLM\ntrained on a dataset D, combining all source lan-\nguages, using the corrected text as input and the un-\ngrammatical one as output. Post-training, the AEG\ncan introduce errors in any language supported by\nthe mPLM, leveraging the inherent zero-shot cross-\nlingual transfer capabilities of generative mPLMs.\nGED Artificial Data Creation Using our AEG\nS\nsystem we obtain a multilingual dataset Dsynth\nof raw sentences and their corresponding syntheti-\ncally generated ungrammatical versions by corrupt-\ning sentences from Ds and Dt. We obtain GED\ntoken-level annotation from Dsynth by tokenizing\nusing language-specific tokenizers, and aligning\nboth sentence versions using Levenshtein distance\nwith minimal alignment following Kasewa et al.\n(2018). We follow the labeling methodology of\nVolodina et al. (2023); Kasewa et al. (2018). We\ndesignate tokens that are not aligned with them-\nselves or tokens following a gap as incorrect, while\nremaining tokens are labeled as correct.\nGED model fine-tuning We propose a two-stage\nmethodology for our multilingual GED model akin\nto supervised GEC (Grundkiewicz et al., 2019;\nRothe et al., 2021; Luhtaru et al., 2024a). Models\nare initially fine-tuned on synthetic data and later\nrefined with human-annotated data. Our approach\nbegins with the fine-tuning of an mPLM such as\nXLM-R (Conneau et al., 2020) on our synthetically\ngenerated multilingual GED datasets. Then, we\nfine-tune this model using human-annotated GED\ndata from all our source languages, Ds."}, {"title": "4 Experimental Setup", "content": "4.1\nDatasets & Evaluation Metric\nWe use English, German, Estonian, Russian, Ice-\nlandic, and Spanish as our source languages and\nSwedish, Italian, Czech, Arabic, and Chinese as our\ntarget languages. For each dataset, when multiple\nsubsets are available we use the L2 learners' cor-\npora and the annotations for minimal corrections\nfor grammaticality.\nTraining set The English, German, Estonian, Rus-\nsian, Icelandic, and Spanish datasets are taken from\nthe FCE corpus (Yannakoudakis et al., 2011), the\nFalko-MERLIN GEC corpus (Boyd, 2018), UT-\nL2 GEC (Rummo and Praakli, 2017), RULEC-\nGEC (Rozovskaya and Roth, 2019), the Icelandic\nlanguage learners section of the Icelandic Error\nCorpus (Arnard\u00f3ttir et al., 2021), and COWS-L2H\n(Davidson et al., 2020), respectively. We use the\ntraining set of each of these GEC datasets to train"}, {"title": "4.2 Baselines", "content": "We evaluate the proposed artificial error gener-\nation method against strong baselines that do\nnot require human-annotated datasets in the tar-\nget language. We chose methods representa-\ntive of different family of artificial error genera-\ntion in GEC: Rules (Grundkiewicz and Junczys-\nDowmunt, 2019), Round-trip translation (RT trans-\nlation) (Lichtarge et al., 2019), Non auto-regressive\ntranslation (NAT) (Sun et al., 2022). Addition-\nally, we compare our approach with a zero-shot\nCLT baseline, which involves directly fine-tuning\nthe GED model on GED datasets from all source\nlanguages. We refer to this technique as Direct-\nCLT to distinguish it from our method, which uses\nthe cross-lingual transfer capabilities of generative\nmPLMs to generate errors in any target language.\nMore information on the implementations of our\nbaselines in Appendix A.1."}, {"title": "4.3 Models and Fine-tuning setups", "content": "Synthetic Data Generation We use the No Lan-\nguage Left Behind (NLLB-200) model (Team et al.,\n2022) which supports 202 languages as our gen-\nerative mPLM. Specifically, we use NLLB 1.3B-\ndistilled for all our experiments. Following Luhtaru\net al. (2024b), we train the model on non-tokenized\ntext or detokenized if the non tokenized format is\nnot available. Details regarding our hyperparame-\nters can be found in Appendix A.2.\nGrammatical Error Detection In line with (Colla\net al., 2023), we use XLM-ROBERTa-large, a mul-\ntilingual pre-trained encoder with strong cross-\nlingual abilities (Conneau et al., 2020) as our GED\nmodel. We evaluate two versions of our method:\n(1) A Monolingual version, where the GED model\nis exclusively trained on synthetic data from the\ntarget language, enabling direct comparison with\nexisting synthetic data generation techniques. (2)\nA Multilingual version using our two-stage fine-\ntuning procedure to compare against DirectCLT."}, {"title": "5 Proposed Method Evaluation", "content": "5.1\nComparison to State-of-the-Art\nTable 1 presents the performance of our method\ncompared to previous state-of-the-art. Our method\nestablishes a new standard in GED without human\nannotations across all target languages, outperform-\ning both synthetic data generation techniques and\nDirectCLT by a significant margin.\nWe posit that our superior performance can be\nattributed to the capability of our AEG method to\nproduce a diverse set of errors including language-\nspecific errors. This hypothesis is further examined\nin Section 6.\nIt is worth mentioning that while our results rep-\nresent a significant advancement, they still fall short\nof the state-of-the-art supervised settings. This re-\nsult is expected and aligns with the existing liter-\nature in GED, which highlights notable discrep-\nancies when evaluating supervised models with\nout-of-domain data, even if it originates from the\nsame language as the training data (Volodina et al.,\n2023; Colla et al., 2023).\n5.2\nEvaluation of AEG\nAs all previous work using AEG for GED has been\nin monolingual settings, we introduce a monolin-\ngual variant of our approach. Here, the GED model\nis exclusively fine-tuned on synthetic data from the\ntarget language.\nTable 2 shows that our synthetic data generation\ntechnique achieves the best performance among\nannotation-free synthetic data generation methods\napplied to GED. Given that rule-based methods\napply a set of transformations without considering\nthe sentence context, the average improvement of\n9.2 points of F0.5 over these methods highlights\nthe significance of generating context-dependent\nerrors in synthetic data generation. Additionally,\ngiven that NAT is not trained to generate errors but\nto produce translations, outperforming this method\nby 8.3 points of F0.5 highlights the advantage of\nlearning to generate errors from authentic instances,\neven when these instances originate from different\nlanguages.\nWe hypothesize that the ability to synthesize\ncontext-dependent errors combined with the acqui-\nsition of error-generation insights from authentic\ninstances empower our method to yield errors more\nakin to human errors, thus leading to better perfor-\nmance. We further analyze this hypothesis in 6.1.\nAdditionally, our monolingual setup outper-\nforms DirectCLT in four out of five languages.\nThis is a notable achievement given other synthetic\ndata generation methods' inability to meet this\nbenchmark. Both approaches leverage the CLT\nof mPLMs, albeit differently: ours uses it for ar-\ntificial error generation in target languages with a\ngenerative mPLM, while DirectCLT leverages it\ndirectly to perform error detection across target lan-\nguages. This comparison suggests that our method\ncreates tailored error patterns in target languages\nthat a GED model trained only on source language\nannotations cannot detect, indicating that our ap-\nproach to CLT in GED could generalize to other\nNLU tasks, which is a promising avenue for future\nresearch."}, {"title": "5.3 Language Ablation", "content": "We study the effect of changing the language con-\nfiguration of the synthetic data. We compare fine-\ntuning the GED model using synthetic data com-\nprising different language sets: exclusively source\nlanguages, exclusively target languages, and a com-\nbination of both source and target languages.\nResults in Table 3 show that any first stage fine-\ntuning language configuration improves the GED\nperformance of our method over the DirectCLT\nbaseline, highlighting the robustness of our two-\nstage fine-tuning pipeline. Notably, including syn-\nthetic data from the target language results in a\nmore significant improvement which emphasize\nthe importance of using a language-agnostic artifi-\ncial error generation method capable of generating\nerrors in any target language.\nFurthermore, results from Table 3 suggest that\nfirst-stage fine-tuning exclusively on synthetic data\nfrom target languages outperforms fine-tuning on a\ncombination of source and target languages. How-\never, comparing F0.5 scores does not reveal the big\npicture and can lead to false conclusion. The F0.5\nscore is computed at an operation point that is usu-\nally arbitrarily set to 0.5 in the literature (Kasewa\net al., 2018; Colla et al., 2023; Le-Hong et al.,\n2023). For a more comprehensive comparison\nof performance, Figure 2 presents the Precision-\nRecall curves for each method. It shows that fine-\ntuning on either synthetic data from source and\ntarget languages or target languages alone yields\nsimilar results. We can conclude that the determin-\ning factor is the inclusion of synthetic data in the\ntarget language. We can also see that our method\noutperforms other baseline in the curves too. We\nencourage practitioners to use such figures to com-\npare GED models for more meaningful conclusions\nthan threshold dependant metrics such as F scores.\nWe experimented with reversing our fine-tuning\npipeline by initially training on human annotations\nfrom our source languages followed by fine-tuning\non synthetic data. However, this approach em-\npirically yielded inferior performance. The fact\nthat ending the fine-tuning process with human-\nannotated data, even in source languages, is more\neffective than using target language synthetic data\nindicates that artificial errors still do not reach the\nquality of authentic corpora. Otherwise it would\nmake sense to end the training with errors specific\nto the target language. We hypothesize that im-\nproved synthetic error generation techniques would\nlead to opposite conclusions regarding the fine-\ntuning order."}, {"title": "5.4 Scalability", "content": "Here we investigate how our synthetic data gen-\neration method scales as new languages corpora\nbecome available. We fine-tune the AEG model by\nprogressively incorporating new languages in dif-\nferent orders to an English-only fine-tuned baseline.\nWe follow the protocol of Shaham et al. (2024). We"}, {"title": "5.5 Generalization to out-of-domain errors", "content": "Errors vary between different populations. For in-\nstance native speakers (L1) do not commit the same\ntype of errors than second language learners (L2).\nWe investigate the robustness of our method to dif-\nferent error distributions. Our method is trained\non L2 learner corpora and we evaluate it on L1\ndata. We found available GED annotated data of\nL1 speakers for Arabic and Czech: QALB 2014\n(Mohit et al., 2014) and the Native Formal section\nof GECCC (N\u00e1plava et al., 2022).\nTable 4 presents the results. Our method sur-\npasses all other baselines, demonstrating its con-\ntinued suitability for out-of-domain corpora in\nthe target language. Unlike the other baselines,\nour method achieves approximately similar perfor-\nmance on both L1 and L2 Arabic corpora. However,\nfor Czech, all methods show a significant decrease\nin performance. We hypothesize that this is due to\nthe unique stringent rules regarding the use of com-\nmas in Czech. This results in the predominance\nof \"Punctuation\" errors in the L1 Czech corpora,\nwhich are less common in many other languages,\nand therefore amplify the difference between do-\nmains."}, {"title": "6 Analysis of synthetic errors", "content": "We compare the errors produced by the AEG meth-\nods. We first study Czech using a Czech extension\n(N\u00e1plava et al., 2022) of the ERRANT (Bryant\net al., 2017) error annotation tool and an artificial\nvs human error discriminator. We then extend our\nanalysis to many languages using GPT-4 (OpenAI\net al., 2024) to classify error types."}, {"title": "6.1 Czech Case Study", "content": "Similarity Analysis with Human Errors To as-\nsess if the synthetic instances are realistic and\nhuman-like, we train a binary classifier (one per\nsynthetic data generation technique) to distinguish\nbetween errors generated by a particular synthetic\ndata generation method and human errors. We\nconstructed a development set comprising approx-\nimately equal numbers of authentic and synthetic\ndata and assessed performance using the F\u2081 score.\nMore information on how we train the classifier\ncan be found in A.3. Results are presented in Table\n5.\nOur classifier achieves an F\u2081 score of 83.4%\nfor the proposed method, indicating a moderate\nability to differentiate between synthetic and hu-\nman errors. This supports our hypothesis that our\nsynthetic data generation method does not fully\nreplicate the quality of authentic sentences. In con-\ntrast, the classifier achieves an F\u2081 score exceeding\n95% for other synthetic data generation methods,\nsuggesting a higher degree of differentiation. Over-\nall, this suggests that our method produces errors\nthat are more human-like, translating into better\ndownstream performance.\nError Distribution We use the Czech extension\n(N\u00e1plava et al., 2022) of ERRANT to categorize\nthe errors made by different systems. Figure 4\npresents the distribution of the top 10 error types\nfor the various synthetic data generation methods\nstudied. Our method produces a more diverse set\nof errors compared to NAT (Sun et al., 2022) and"}, {"title": "6.2 Multilingual Extension", "content": "We want to extend our previous findings by assess-\ning if our synthetic data generation method effec-\ntively captures a variety of error types across all\nlanguages. For this, we need a language-agnostic\nclassifier. We use GPT-4 to classify errors from\nvarious sources across all the languages under in-\nvestigation. Prior studies have shown that GPT-4's\njudgments align closely with human evaluations\n(Wang et al., 2023; Fu et al., 2023) and exhibit\npromising error correction capabilities (Fang et al.,\n2023; Davis et al., 2024; Wu et al., 2023). Al-\nthough a thorough assessment of GPT-4 for error\nclassification is beyond the scope of the study, we\nperformed a limited qualitative analysis of GPT-4's\naccuracy in Italian, Swedish, Spanish, and English\nwith native speakers. We found that it is suitable\nfor our application. For each type of error classified\nby GPT-4 we compute its frequency distribution\nacross data and compute the entropy of this distribu-\ntion. Further details on our evaluation methodology\nare provided in Appendix A.4.\nFigure 5 validates our previous findings that our\nmethod generates a more diverse set of errors com-\npared to NAT. However, the range of error types\ngenerated by our method is narrower than that pro-\nduced by humans. Moreover, the variability in the\ndiversity of error types is significantly higher with\nour method than with human errors across different\nlanguages. This suggests that our method does not\nconsistently perform across languages."}, {"title": "7 Conclusion", "content": "We introduced a novel zero-shot approach for GED\nwith low-resource languages. Our method com-\nbines back-translation with the CLT capabilities\nof mPLMs to perform AEG across various target\nlanguages. Then, we fine-tune the GED model\nin two steps: first on multilingual synthetic data\nfrom source and target languages, then on human-\nannotated source language corpora. This method\nachieves state-of-the-art performance in annotation-\nfree GED. Our error analysis shows that we pro-\nduce errors that are more diverse and human-like\nthan the baselines.\nIn future work, we intend to explore the potential\nof our GED models to enhance unsupervised GEC\nmethods."}, {"title": "8 Limitations", "content": "Our approach relies on the CLT capabilities ob-\ntained during the multilingual unsupervised pre-\ntraining of mPLMs. Consequently, the applica-\nbility of our method is restricted to the languages\nsupported by the mPLM. Furthermore, its perfor-\nmance on each language may vary depending on\nthe amount of pre-training data available for that\nlanguage. This limitation is inherent to all studies\nleveraging mPLMs.\nAdditionally, our study primarily focuses on the\nerrors made by second language learners. While\nwe have analyzed the performance of our method\non native language corpora, it would be valuable to\nevaluate its generalizability to other domains within\na language. For instance, this includes errors made\nin casual text messaging or by machine translation"}, {"title": "9 Ethics Statement", "content": "Our research is driven by a commitment to sup-\nporting and preserving linguistic diversity. Low-\nresource languages often face marginalization in\nthe realm of technological advancements. By de-\nveloping GED models for these languages, we aim\nto enhance their digital presence and usability, thus\npromoting linguistic equity.\nHowever, it is important to acknowledge poten-\ntial ethical concerns. The use of CLT to generate\nsynthetic data, while beneficial for training GED\nmodels, carries the risk of misuse. Such systems\ncould potentially be exploited to create false infor-\nmation or propaganda in low-resource languages.\nAdditionally, while GED systems are crucial for\nregions with a shortage of language teachers, there\nis a risk that their widespread use could lead to\nan over-reliance on these tools. This dependency\nmight result in a decline in the linguistic and gram-\nmatical skills of native speakers, as they become\nmore reliant on technology for language correction\nand validation.\nIt is essential for future users to use these tech-\nnologies judiciously. Balancing the use of GED\ntools with a genuine effort to improve one's linguis-\ntic abilities is crucial. Building on the research by\nFei et al. (2023) could provide a valuable advance-\nment by incorporating explainability into our GED\nsystems."}, {"title": "A Appendix", "content": "A.1\nBaselines\nRules We re-implemented Grundkiewicz and\nJunczys-Dowmunt (2019) using Aspell dictionar-\nies\u00b9 for the replacement operation.\nNAT We replicated the NAT model using InfoXLM\n(Chi et al., 2021) and English as source language,\nfollowing (Sun et al., 2022) methodology. For\nnon-autoregressive translation generation, we used\nEuroparl (Koehn, 2005) for Italian, Swedish and\nCzech and the UN Parallel Corpus v1.0 (Ziemski\net al., 2016) for Arabic and Chinese. We conducted\nhyper-parameter tuning for the NAT-based data con-\nstruction by exploring the parameter set specified\nin (Sun et al., 2022) and selected the optimal pa-\nrameters for each language based on performance\non the development set.\nRT translation We use OPUS-MT (Tiedemann\nand Thottingal, 2020) as our translation model and\nEnglish as the bridge language.\nA.2 Implementation details\nArtificial error generation We use two distinct\nAEG models to generate errors in target and source\nlanguages, both based on NLL 1.3B-distilled but\ntrained with different hyper-parameters.\nFor synthetic data generation in target lan-\nguages, we conduct preliminary grid searches on\nthe Swedish development set to determine the opti-\nmal hyperparameters. We select the learning rate\nfrom {1e-4, 5e-4, 1e-5, 5e-5} and the number of\nepochs from {3, 5, 10, 15, 20}. Ultimately, we set\nthe learning rate to le-5 and fine-tune for 3 epochs\nwith a batch size of 24 and a linear scheduler.\nFor synthetic data generation in source lan-\nguages, we use a different set of hyper-parameters\nbased on grid searches on the English development\nset. The learning rate is set to le-4, and we fine-\ntune for 10 epochs with a batch size of 24 and a\nlinear scheduler.\nGrammatical error detection Based on initial ex-\nperiments with the Swedish development set, we\nuse a learning rate of le-5, a batch size of 24, and\ntrain for 5 epochs with a linear scheduler. In our\nsecond-stage experiments, we maintain the same\nsetup but fine-tune for only 1 epoch.\nMonolingual corpora: As mentioned in Section\n4.1, our monolingual text data is sourced from the\nCC100 dataset (Conneau et al., 2020), from which\nwe sample 200,000 error-free instances for each\nlanguage. To ensure the text is error-free, we use\nthe DirectCLT baseline for error detection, includ-\ning only sentences verified to be error-free.\nFor all our trainings, we use 3*A6000 GPUs\nwith 48 GB of VRAM.\nA.3 Similarity Analysis details\nTo distinguish between authentic and synthetic in-\nstances, we train a binary classifier. The classifier\nprocesses a pair of sentences: a grammatical sen-\ntence and its corresponding ungrammatical version\nseparated by a separator token. Its task is to identify\nwhether the ungrammatical sentence is synthetic\nor authentic. We train separate binary classifiers\nfor each synthetic data generation method, using\nmdeberta-v3-base (He et al., 2023) as our back-\nbone.\nA.4 GPT-4 analysis details\nTo evaluate the linguistic diversity of errors across\ndifferent languages, we employed GPT-4 as an er-\nror classifier. Specifically, we used GPT-4 to de-\nscribe the nature of the errors in sentences. Without\nconstraining GPT-4 to a predetermined set of error\ntypes, it generated a diverse range of error descrip-\ntions for similar errors.\nWe then categorized these errors into distinct\nclusters using a clustering method based on the\nsentence embeddings generated using sentence-\ntransformers (Reimers and Gurevych, 2019). In\nparticular, we applied KMeans clustering with four\ndifferent values of K (16, 32, 64, 128). This ap-\nproach produced multiple sets of clusters, each rep-\nresenting distinct error patterns within the dataset.\nFor each value of K, we computed the frequency\ndistribution of errors across the clusters and sub-\nsequently calculated the entropy of these distribu-\ntions. To enable comparison across different values\nof K, we normalized the entropy values, ensuring\ncomparability and eliminating bias from the num-\nber of clusters chosen.\nFinally, to derive a comprehensive measure of\nnormalized entropy for each language under study,\nwe averaged the normalized entropy values ob-\ntained across all K settings. The resulting normal-\nizedentropy metric provides a robust indicator of\nthe diversity of error patterns observed across dif-\nferent languages, as illustrated in Figure 5."}]}