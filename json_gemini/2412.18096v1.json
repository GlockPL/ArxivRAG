{"title": "Real-world Deployment and Evaluation of PErioperative Al CHatbot (PEACH) - a Large Language Model Chatbot for Perioperative Medicine", "authors": ["Yu He Ke", "Liyuan Jin", "Kabilan Elangovan", "Bryan Wen Xi Ong", "Chin Yang Oh", "Jacqueline Sim", "Kenny Wei-Tsen Loh", "Chai Rick Soh", "Jonathan Ming Hua Cheng", "Aaron Kwang Yang Lee", "Daniel Shu Wei Ting", "Nan Liu", "Hairil Rizal Abdullah"], "abstract": "Large Language Models (LLMs) are emerging as powerful tools in healthcare, particularly for complex, domain-specific tasks. This study describes the development and evaluation of the PErioperative Al CHatbot (PEACH), a secure LLM-based system integrated with local perioperative guidelines to support preoperative clinical decision-making.\nWe embedded PEACH with 35 institutional perioperative protocols in the secure Claude 3.5 Sonet LLM framework within Pair Chat (developed by Singapore Government). The system was tested with a silent deployment with real-world data. Accuracy, safety, and usability were assessed. Deviations and hallucinations were categorized based on potential harm, and user feedback was evaluated using the Technology Acceptance Model (TAM). Updates to PEACH was made after the initial silent deployment to make minor amendments to one of the protocol.\nA total of 240 real-world clinical iterations were evaluated. PEACH achieved a first-generation accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across three iterations. The updated PEACH had accuracy improved to 97.9% (235/240), with a statistically significant difference from the null hypothesis of 95% accuracy (p = 0.018, 95% CI: 0.952\u20130.991). Hallucinations and deviations were minimal (both 1/240 and 2/240 respectively). There were high usability, with clinicians noting that PEACH expedited decisions in 95% of cases. The inter-rater reliability was observed within PEACH were (kappa 0.772\u20130.893) and (0.610\u20130.784) among attendings.\nPEACH is an accurate, adaptable tool that enhances consistency and efficiency in perioperative decision-making. Future research should explore its scalability across specialties and its impact on clinical outcomes.", "sections": [{"title": "Background", "content": "Large Language Models (LLMs) are emerging as powerful tools in healthcare, particularly for complex, domain-specific tasks. This study describes the development and evaluation of the PErioperative Al CHatbot (PEACH), a secure LLM-based system integrated with local perioperative guidelines to support preoperative clinical decision-making."}, {"title": "Methods", "content": "We embedded PEACH with 35 institutional perioperative protocols in the secure Claude 3.5 Sonet LLM framework within Pair Chat (developed by Singapore Government). The system was tested with a silent deployment with real-world data. Accuracy, safety, and usability were assessed. Deviations and hallucinations were categorized based on potential harm, and user feedback was evaluated using the Technology Acceptance Model (TAM). Updates to PEACH was made after the initial silent deployment to make minor amendments to one of the protocol."}, {"title": "Results", "content": "A total of 240 real-world clinical iterations were evaluated. PEACH achieved a first-generation accuracy of 97.5% (78/80) and an overall accuracy of 96.7% (232/240) across three iterations. The updated PEACH had accuracy improved to 97.9% (235/240), with a statistically significant difference from the null hypothesis of 95% accuracy (p = 0.018, 95% CI: 0.952\u20130.991). Hallucinations and deviations were minimal (both 1/240 and 2/240 respectively). There were high usability, with clinicians noting that PEACH expedited decisions in 95% of cases. The inter-rater reliability was observed within PEACH were (kappa 0.772\u20130.893) and (0.610\u20130.784) among attendings."}, {"title": "Conclusion", "content": "PEACH is an accurate, adaptable tool that enhances consistency and efficiency in perioperative decision-making. Future research should explore its scalability across specialties and its impact on clinical outcomes."}, {"title": "Research In Context", "content": "Large Language Models (LLMs) have demonstrated potential in clinical applications, particularly in tasks requiring domain-specific expertise. Previous studies explored their ability to generate accurate responses to medical queries, including preoperative assessments and management recommendations. However, these studies often relied on generic LLMs without the integration of localized clinical guidelines or secure frameworks tailored to institutional practices. No prior research has evaluated the deployment of a secure LLM system like PEACH within an operational healthcare environment. This study bridges that gap by assessing real-world application of a secure LLM model"}, {"title": "Added value of this study:", "content": "This study represents the first real-world deployment and evaluation of a secure, localized LLM"}, {"title": "Methods", "content": "PEACH leveraged the large context limits of advanced language models to directly input structured text data into the model, rather than employing traditional RAG techniques13. While RAG methods rely on chunking documents and retrieving relevant portions using search algorithms, PEACH circumvented these steps due to the enhanced performance of newer models with expanded context windows. Instead, structured input data, coupled with prompt engineering, ensured accurate and efficient integration into the language model's reasoning process. The embedding model utilized was Claude-Sonet 3.5, optimized for handling long-form contextual inputs. Retrieval parameters, such as chunk size and similarity thresholds, were therefore not relevant, as the entire structured text was directly input into the model.\nTo ensure the accuracy and relevance of the outputs, multiple rounds of internal testing and user validation were conducted. Iterative prompt refinement reduced hallucinations and improved the accuracy of responses. Continuous user feedback informed adjustments to the prompt engineering process, ensuring that the Chatbot reliably produced clinically relevant outputs."}, {"title": "Prompt Engineering", "content": "Prompt engineering was guided by the principles outlined by Bertalan et al.14, emphasizing specificity and contextualization to ensure comprehensive and clinically relevant responses from the LLM. \"Role-playing\" prompts were structured to explicitly instruct the LLM to assume the perspective of an expert preoperative clinician. The development process was iterative, involving repeated cycles of prompt design, response generation, and evaluation. Adjustments were made to improve the clarity of instructions, incorporate additional context, and minimize ambiguities. The final engineered prompt of PEACH is found within Supplementary Material, Table 1."}, {"title": "PEACH interface", "content": "The PEACH interface is designed for clinical utility. It is accessible exclusively through hospital-issued, encrypted laptops, and is restricted to healthcare providers with authorized hospital-issued email accounts only. The login requires multi-factor authentication. The interface allows users to access patient data through electronic health records (EHRs), and users can copy and paste relevant patient information into the chatbot for analysis.\nPEACH provides five core functions tailored to perioperative care: 1) Answers perioperative-related anesthesia questions, 2) Assists in drafting memos to other healthcare disciplines, 3) Evaluates patient suitability for telephone screening 4) Summarizes key anesthesia-related issues from the patient's medical history and 5) generates comprehensive, guideline-based perioperative management plans, including fasting instructions, suitability for"}, {"title": "Evaluation Framework", "content": "This study 35 local protocols from a major tertiary hospital in Singapore, adapted from established international perioperative standards (Supplementary Table 2). All guidelines were reviewed and were summarized into text as the PAIR chatbot has a maximum word count limit of context stuffing (45,000 words). PEACH utiltized 35,634 words (79% of context limit used) after all the protocols were uploaded."}, {"title": "Usual clinical care in Preoperative Evaluation Clinic (PEC)", "content": "The PEC at our tertiary hospital manages around 120 patients daily with a team of nurses, junior anesthesiologists, and a senior attending physician. Standardized care is supported by 35 comprehensive local perioperative guidelines with more than 400 pages, and is accessible on the hospital intranet. Patients are assessed through telephone screening by nurses if criteria are met, or in-person by junior doctors. When uncertainties arise, staff refer to the guidelines or seek advice from the attending physician."}, {"title": "Silent deployment", "content": "A silent deployment model was implemented with a team of five nurses, each with over two years of experience in the preoperative clinic, and five junior doctors with at least six months of anesthesiology clinical practice. Participants were briefed on the chatbot's functionality and limitations before beginning the study. They were instructed to carry out their usual clinical duties as normal, including making decisions based on their clinical judgment or consulting with the attending perioperative physician when necessary. Only after finalizing their clinical decisions were they allowed to input their questions into the chatbot and access its answers. Participants then indicated whether the chatbot's recommendations aligned with those made in consultation with the attending physician, if relevant. Figure 1 illustrates the workflow of the silent deployment process. Ethics approval was reviewed and determined to be unnecessary by the Research Quality Office of Singapore General Hospital, as the study was classified as a quality assessment initiative."}, {"title": "Evaluation Framework", "content": "The evaluation of PEACH was designed to assess three critical dimensions: accuracy, safety, and user acceptability. The grading process for accuracy and safety was intentionally designed to be stringent and rigorous to ensure that the evaluation of PEACH's outputs was thorough and uncompromising. User acceptability was measured using the established framework of the Technology Acceptance Model (TAM) to gauge the system's practical usability and adoption by clinicians."}, {"title": "Primary Outcome: Accuracy", "content": "The primary outcome of the evaluation was the accuracy of the recommendations provided by PEACH. Given the nuanced and context-specific nature of perioperative decisions where evidence-based guidelines may not exist for all scenarios, a tiered approach was employed to determine the accuracy of recommendations. Institutional guidelines served as the first standard of reference, offering a comprehensive framework for most scenarios (e.g., stopping ACE inhibitors/ARBs before surgery unless the patient has poorly controlled hypertension). For questions not addressed by institutional guidelines, international guidelines and the current body of evidence, including systematic reviews, were used.\nIn cases where neither institutional nor international guidelines provided specific answers, expert consensus was sought. Accurate recommendations in these instances were determined through group discussions among experts, allowing for multiple answers as long as they were safe and clinically reasonable (e.g., deciding whether an ASA 3 patient undergoing a minor procedure like a colonoscopy should be admitted the same day or treated as day surgery)."}, {"title": "Secondary Outcome: Deviations and Hallucinations", "content": "In addition to accuracy, PEACH's outputs were analyzed for deviations and hallucinations. Deviations were defined as outputs that diverged from institutional guidelines or standard clinical practice but did not harm patients. For example, an output might omit mentioning the need for a cervical spine X-ray as a reason for unsuitability for TPS but still correctly conclude that the patient is unsuitable. Hallucinations, on the other hand, represented significant deviations with the potential to cause patient harm. These included instances where the Al: (1) provided information contradicting institutional guidelines, (2) suggested management plans that were dangerous or could compromise care, or (3) addressed irrelevant details not included in the clinical scenario.\nA total of five independent anesthesiologists participated in grading the chatbot's performance. Two junior anesthesiologists and one attending anesthesiologist evaluated the accuracy, deviations, and hallucinations of PEACH's outputs."}, {"title": "Consistency and Reliability", "content": "The consistency of PEACH's outputs was evaluated by submitting the same set of questions to the chatbot twice more retrospectively and comparing the results across all three iterations. To evaluate inter-rater reliability (IRR), two additional attending anesthesiologists provided their clinical decisions for the same set of questions, alongside the original attending anesthesiologist who made decisions during the silent deployment. Cohen's Kappa analysis was performed to measure the agreement between the decisions of the attendings and the outputs generated by PEACH, as well as between the attendings themselves.\nAdditionally, distinct-n-grams analysis was conducted to evaluate the diversity of PEACH's responses across the three iterations. This analysis quantified variations in the linguistic and semantic structure of the outputs, providing insights into how consistently the chatbot formulated its recommendations."}, {"title": "PEACH refinements", "content": "Following the initial silent deployment, PEACH's outputs were systematically reviewed to identify omissions or gaps within the perioperative protocols. Based on this analysis, the perioperative guidelines uploaded to PEACH were updated to address the identified deficiencies. The revised outputs generated by the updated PEACH system were subsequently evaluated across three iterations. These refined outputs are referred to in the results section as \u201cUpdated PEACH.\u201d"}, {"title": "Technology Acceptance Model (TAM) Evaluation", "content": "Two junior doctors evaluated the usability of PEACH: one who had participated in the silent co-pilot phase and another who had not been involved. The assessment focused on key"}, {"title": "Sample size calculation", "content": "A minimum sample size of 73 cases was determined to be necessary to estimate a 95% agreement with a 95% confidence interval and a 5% margin of error. A total of 80 PEACH interactions were targeted to account for potential invalid questions or interactions."}, {"title": "Results", "content": "A total of 240 PEACH interactions, representing 80 distinct clinical questions, were analyzed. PEACH generated results within 10\u201315 seconds on average. The queries spanned various real-world clinical scenarios for patients undergoing elective surgeries and were categorized into general questions (46/80, 57.5%), identification of perioperative issues (22/80, 27.5%), and perioperative management queries (12/80, 15.0%). Doctors and nurses contributed nearly equal proportions of queries, with 39 queries (48.8%) from doctors and 41 (51.2%) from nurses. Among the 69 scenarios that included a complete patient history, 42 cases (60.9%) involved ASA 2 patients, while 27 cases (39.1%) involved ASA 3 patients. This reflects the typical demographics of our elective surgical population. In two instances where users entered only a generic header without patient details, PEACH requested additional information rather than generating hallucinated outputs; these interactions were included in the evaluation. An example of the clinical scenario and the PEACH output can be found in Table 1."}, {"title": "Accuracy and Safety", "content": "PEACH demonstrated an accuracy of 97.5% (78/80) in the first iteration of responses generated by users. Across the subsequent two iterations, the overall accuracy was 96.8% (232/240). PEACH produced accurate answers across all three iterations for 75 out of 80 questions (93.8%). Hallucination rates were minimal, occurring in 4 out of 240 outputs (1.7%), while deviations were found in 2 out of 240 outputs (0.8%) (Table 2).\nThe initial outputs from PEACH aligned with the attending anesthesiologist's recommendations in 53 out of 58 cases (91.4%). There was only one scenario where all 3 iterations had inaccurate answers - PEACH instructed to stop empagliflozin 1 day before the surgery instead of 3 days before. Table 3 summarizes all the hallucinations and deviations present from the PEACH outputs."}, {"title": "Updated PEACH", "content": "After reviewing the protocols uploaded on SGLT2 inhibitors, we noticed that the protocol says \u201cSGLT2 inhibitors (eg. dapagliflozin): To stop for 3 days\u201d. The protocol was subsequently amended to \"SGLT2 inhibitors (eg. dapagliflozin, empagliflozin and all other drugs in the same family): To stop for 3 days\u201d. The scenario was replicated, and all 3 iterations were correct and able to highlight the risk of euglycemic ketoacidosis. This would bring an overall accuracy of 97.9% (232 / 240) with a hallucination rate of 1 out of 240 outputs (0.4%). This is statistically significant compared to the null hypothesis of 95% accuracy (p=0.018, 95% CI (0.952, 0.991)). Supplementary Material Table 2 further details the old and new responses with a change of wording within the protocol."}, {"title": "User acceptability", "content": "User perceptions of PEACH were positive. The chatbot was rated highly for ease of understanding (mean 4.32 (SD 0.53)), safety (mean 4.7 (SD 0.79)), objectivity and non-bias (mean 4.75 (SD 0.54)), and explainability (mean 4.46 (SD 0.62)). Importantly, the users identified that 95.0% (152/160) of the time PEACH's responses would help them make decisions better or faster, with only 5.0% (8/160) responding negatively.\nAmong the PEACH iterations, substantial agreement was observed (Kappa 0.772 and 0.893 between the 3 iterations). Among the attending consultants, moderate agreement was observed in pairwise comparisons (0.610 and 0.784). This variability reflects differences in individual clinical judgment, underscoring the potential of PEACH to provide consistent support across diverse scenarios (Figure 2).\nThe average distinct n-gram scores across all clinical scenarios were 0.309 for 1-gram and 0.592 for 2-gram, reflecting a moderate level of linguistic diversity in word usage and phrase construction (Figure 3). Scores within the range of 0.3 to 0.6 suggest moderate diversity, which is ideal for a clinical chatbot. This balance ensures that the chatbot provides some variation in responses to avoid rigidity while maintaining consistency and adherence to clinical standards."}, {"title": "Discussion", "content": "This study underscores the feasibility and utility of integrating a secure LLM framework into perioperative clinical workflows. PEACH demonstrated high levels of accuracy, safety, and user acceptability, establishing itself as a valuable clinical adjunct in preoperative medicine. The findings emphasize the potential of LLM systems to reduce variability in decision-making and enhance operational efficiency in perioperative settings.\nThe adaptability of PEACH was also evident through its iterative refinement process. The significant improvement observed after updating the protocol for SGLT2 inhibitor management highlights the model's capacity to evolve alongside clinical practice. This adaptability ensures that PEACH remains aligned with institutional guidelines and emerging evidence, reinforcing its role as an amendable and robust tool. Such flexibility is critical in dynamic healthcare environments, where clinical protocols are frequently updated to reflect new evidence and practices."}, {"title": "Standardizing Preoperative Care and Reducing Variability", "content": "One of the key challenges in perioperative medicine is the inherent subjectivity in clinical decision-making, influenced by variations in individual judgment and risk tolerance17. Tools like PEACH address this challenge by promoting consistency and standardization. This consistency is particularly advantageous in perioperative care, where standardized evaluations can reduce miscommunication and prevent conflicts within the care team. Moreover, a consistent approach helps coordinate decisions with surgeons and ensures equitable patient care. Misaligned evaluations could unnecessarily delay surgery, disrupt workflows, and increase costs (E.g. anesthesiologist cancelling the surgery on the day of operation, when the case was already cleared by a previous preoperative attending)."}, {"title": "Enhancing Workflow Efficiency with Human Oversight", "content": "A valuable application of PEACH lies in augmenting preoperative workflows through a \"human-in-the-loop\" framework. In many preoperative clinics, initial patient screening determines whether evaluation by a nurse or doctor is required, or if a low-risk patient can be seen on the day of surgery. PEACH's ability to triage such decisions safely and efficiently has the potential to save significant time and reduce costs. Additionally, by assisting clinicians in drafting patient instructions, PEACH could alleviate administrative burdens and help reduce clinician burnout. Importantly, the model operates as a support tool rather than an autonomous decision-maker, ensuring that all recommendations are reviewed by qualified clinicians. This framework balances efficiency with accountability, with healthcare providers maintaining"}, {"title": "Limitations and Future Directions", "content": "This study offers valuable insights into the integration of LLMs like PEACH into perioperative workflows but has several limitations. First, the protocols embedded within PEACH were specific to a single tertiary hospital. As clinical guidelines and practices vary across institutions and regions, the findings may not be fully generalizable. Adapting PEACH to other settings would require careful customization of its protocol database to reflect local practices.\nAnother limitation is the dependence of PEACH's accuracy on the quality and completeness of the embedded guidelines. Errors or omissions in the protocols, such as the initial mismanagement of SGLT2 inhibitors, highlight the importance of ongoing updates and rigorous review of clinical content. Additionally, the TAM evaluation involved a small number of junior doctors, which may not fully represent the perspectives of all healthcare providers, including senior clinicians.\nFinally, while PEACH demonstrated high accuracy and safety in its responses, there remains a risk of over-reliance on Al by users. Clinicians must remain vigilant and use PEACH as a supplementary tool, not a replacement for clinical judgment. Future studies should investigate the impact of such systems on clinical outcomes and explore scalability in diverse healthcare environments.\nFuture research should explore the scalability of PEACH and its adaptability across different clinical specialities. Expanding its application beyond perioperative medicine to fields such as surgery of internal medicine could further validate its utility. Additionally, investigating the integration of advanced retrieval-augmented generation (RAG) frameworks, such as LlamaIndex, could enhance PEACH's ability to retrieve and synthesize information from increasingly complex datasets."}, {"title": "Conclusion", "content": "PEACH has demonstrated high accuracy, consistency, and strong user acceptance, with minimal rates of hallucinations. Its adaptability and ease of refinement further highlight its potential as a valuable tool in clinical workflows. By improving decision-making consistency and enhancing operational efficiency, PEACH shows promise as a reliable clinician support system in perioperative medicine. Future research should explore the scalability and applicability of LLM models like PEACH across diverse medical specialities and clinical settings."}]}