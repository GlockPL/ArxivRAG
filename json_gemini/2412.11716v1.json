{"title": "LLMs Can Simulate Standardized Patients via Agent Coevolution", "authors": ["Zhuoyun Du", "Lujie Zheng", "Renjun Hu", "Yuyang Xu", "Xiawei Li", "Ying Sun", "Wei Chen", "Jian Wu", "Haolei Cai", "Haochao Ying"], "abstract": "Training medical personnel using standardized patients (SPs) remains a complex challenge, requiring extensive domain expertise and role-specific practice. Most research on Large Language Model (LLM)-based simulated patients focuses on improving data retrieval accuracy or adjusting prompts through human feedback. However, this focus has overlooked the critical need for patient agents to learn a standardized presentation pattern that transforms data into human-like patient responses through unsupervised simulations. To address this gap, we propose EvoPatient, a novel simulated patient framework in which a patient agent and doctor agents simulate the diagnostic process through multi-turn dialogues, simultaneously gathering experience to improve the quality of both questions and answers, ultimately enabling human doctor training. Extensive experiments on various cases demonstrate that, by providing only overall SP requirements, our framework improves over existing reasoning methods by more than 10% in requirement alignment and better human preference, while achieving an optimal balance of resource consumption after evolving over 200 cases for 10 hours, with excellent generalizability.", "sections": [{"title": "1 Introduction", "content": "Standardized Patients (SPs) are specially trained individuals who simulate the symptoms, histories, and emotional states of real patients. They are instrumental in enhancing the clinical skills, communication abilities, and diagnostic reasoning of medical personnel within a controlled learning environment. However, employing SPs incurs significant training and operational costs, necessitating substantial medical knowledge and extensive role-specific practice. Another often overlooked yet crucial concern is the potential adverse impacts on the well-being of SPs due to the immersive nature of their work. For instance, human SPs must manage the anxiety linked to the patient roles they embody throughout their simulations. These challenges underscore the need to develop virtual SPs, aiming to reduce human involvement as patients in simulated training processes.\nEfforts have investigated the use of rule-based digital patients to replace human SPs. However, these pre-defined rule sets and tailored dialogue frameworks often fall short of capturing the complexity of real-world patient conditions and communication. The emergence of large language models (LLMs), known for their extensive world knowledge, role-playing and generalizing capabilities, has shown strong potential for handling domain-specific tasks, including in the medical field. However, in the role of virtual SPs, LLMs encounter the challenge of embodying dual roles. Despite possessing extensive domain knowledge and understanding of medical outcomes, they must convincingly portray uneducated patients, deliberately lacking medical insight and withholding critical information. Prompt engineering alone is inadequate to ensure LLMs adhere to such principles while fine-tuning demands significant annotation effort and may introduce additional privacy concerns.\nThere has been limited research focused on LLM-based SPs. For instance, (Yu et al., 2024) improved response quality by retrieving relevant information from constructed knowledge graphs. However, this approach does not necessarily convert the retrieved information into the standardized expressions required by SPs. (Louie et al., 2024) enabled LLMs to elicit principles from human expert feedback to adhere, to a process that is labor-intensive and may suffer from limited generalizability. To this end, our study addresses the question: How can we effectively train LLM-simulated SPs with minimal human supervision? We propose that a framework need to be developed that allows LLM patient agents to autonomously gain experience through simulations. This would enable the agents to acquire the necessary knowledge and develop standardized expression practices from high-quality dialogues, gradually transforming a novice patient agent into a skilled virtual SP.\nIn this paper, we introduce EvoPatient, an innovative multi-agent coevolution framework aimed at facilitating LLMs to simulate SPs, without the need for human supervision or weight updates. We model the diagnostic process into a series of phases (i.e., complaint generation, triage, interrogation, conclusion), which are integrated into a simulated flow. Our framework features simulated agent pair, where doctor agents autonomously ask diagnostic questions, and patient agents respond. This setup enables the automatic collection of diagnostic dialogues for experience-based training. To enhance the diversity of questions posed by doctor agents, a multidisciplinary consultation recruitment process is developed. Additionally, utilizing an initial set of textual SP requirements, we enforce an unsupervised coevolution mechanism which simultaneously improves the performance of both doctor and patient agents by validating and storing exemplary dialogues in dynamic libraries. These libraries helps patient agents extract few-shot demonstrations and refine their textual requirements for answering various diagnostic questions. Meanwhile, doctor agents learn to ask increasingly professional and efficient questions by leveraging stored dialogue shortcuts, thereby further enhancing the evolution of patient agents. The results indicate that EvoPatient significantly improves patient agent's requirement alignment, standardizes its answers with greater robustness, enhances record faithfulness, and increases human doctor preference with optimized resource consumption. Furthermore, experiments on the evolution of doctor agents and recruitment processes demonstrate their positive contribution to the evolution of patient agents."}, {"title": "2 Related Work", "content": "Simulated Partners Simulated partners are persons or software-generated companions used in various domains to give skill learners practice opportunities that textbook knowledge cannot provide. Previous research has built various software-generated educational systems but lacks context variety. LLMs greatly overcome this problem by their formidable generalizability and capability to simulate diverse personas. As a result, researchers have explored their use in simulation training for various fields, including teacher education, conflict resolution, surgery training and counseling. In medical education using SP, previous studies have proposed methods to enhance simulation authenticity by improving data extraction ability or incorporating expert feedback. Unlike these methods, our approach emphasizes the gathering of experience through simulations without human involvement.\nEvolution of Agents Recently, LLMs have achieved significant breakthroughs through methods such as pre-training, fine-tuning, and other forms of human-supervised training. However, these methods may cause a lack of flexibility and require extensive high-quality data and heavy human supervision. Therefore, the development of self-evolutionary approaches has gained momentum. These approaches enable LLM-powered agents to autonomously acquire, refine, and learn through self-evolving strategies. For example, Agent Hospital introduces self-evolution into world simulations without real-world environments. Self-Align combines principle-driven reasoning and the generative power of LLM for the self-alignment of agents with human annotation. ExpeL accumulates experiences from successful historical trajectories. In this paper, we introduce insights into attention and sequential predictable to perform autonomous evolution in medical education domain."}, {"title": "3 EvoPatient", "content": "We propose EvoPatient, a doctor training framework powered by three essential modules: 1) the simulated flow mirrors the diagnostic process into a series of manageable phases, serving as a workflow for simulations. 2) the simulated agents pair comprises a patient agent and multiple doctor agents, engaging in autonomous multi-turn dialogue. The patient agent adopts various roles, while the doctor agents perform multidisciplinary consultations, generating questions and answers based on medical records. 3) the coevolution mechanism validates and stores dialogues, creating a reference library for standardized presentation to the patient agent. Simultaneously, doctor agents extract shortcuts from stored dialogue trajectories, enabling them to ask increasingly professional questions for efficient patient agent training (Algorithm 1)."}, {"title": "3.1 Simulated Flow", "content": "The simulated flow (F) leverages real-world medical records as input and models agent dialogues to create a structured sequence of diagnostic phases (S). As an example, during the interrogation phase, depicted in Figure 1, a doctor agent (D) engages in a multi-turn dialogue (C) with a patient agent (P). The doctor agent asks (\u2192) questions, while the patient agent responses (\u2192) with answers, culminating in a diagnostic conclusion. Each phase (T) consists of one or more multi-turn dialogues between various roles:\n$F = (S_1, S_2, ..., S_{||}),$\n$C(D, P) = (D \\rightarrow P, P \\rightarrow D),$\n$S^i = T(C(D, P), C(D, D), C(P, D))$\t\t(1)\nAlthough the workflow is conceptually straightforward, the ability to customize phases enables the simulation of diverse scenarios without requiring additional agent communication protocols or adjustments to workflow topology. This paper adopts a workflow encompassing chief complaint generation, triage, interrogation, and conclusion."}, {"title": "3.2 Simulated Agent Pair", "content": "The simulated agent pair consists of a patient agent and multiple doctor agents engaged in multi-turn diagnostic dialogues, effectively eliminating the need for human involvement and specific adjustments for different cases.\nSimulated Patient Agent To enable the patient agent to generate more realistic and contextually appropriate answers aligned with real-world patients, we developed 5,000 patient profiles incorporating diverse backgrounds like family, education, economic status, and characteristics such as openness to experience based on the Big Five personality traits. To prevent the agent from losing in long contexts, we employ Retrieval Augmented Generation (RAG) to extract the most relevant information from the records for answer generation.\nSimulated Doctor Agent It is challenging for a pre-trained model-based doctor agent to directly ask professional questions tailored to a patient's condition, which is the key to eliciting valuable dialogues for further evolution process. To avoid questions staying trivial, besides providing carefully designed profiles, we provide doctor agents with a few patient's records prior to simulations and instruct them to formulate questions covering key information (e.g., symptoms, examinations, lifestyle). This approach helps doctor agents create a professional question pool based on their expertise, which can be referred to in subsequent simulations. Moreover, doctors from different disciplines possess diverse expertise, which leads to different types and aspects of question. This diversity is critical for the patient agent to effectively learn from a range of perspectives. To emulate this multidisciplinary consultation process, we enable every doctor agent to recruit agents from other disciplines when the patient's condition exceeds their expertise. When recruited, these agents will ask questions and decide whether to recruit additional doctors:\n$\\rho(D^i, P, D^j) = (\\rho(D^i, P), \\rho(D^j, D^i)),$\n$\\rho(D^i, P) = (D^i \\rightarrow P, P \\rightarrow D^i),$\n$\\rho(D^i, D^j) = (D^i \\rightarrow D^j),$\t\t\t\t(2)\nwhere $\\rho()$ represents the interactions in a multidisciplinary consultation process. We adhere our recruitment process to topological ordering and form a directed acyclic graph (DAG), which prevents information backflow, eliminating the need for additional designs:\n$G = (V,E),$\n$V = {D^i | D^i \\in D}  E = {{(D^i,D^j) | D^i \\neq D^j}},$ \t\t\t(3)\nwhere V denotes the set of doctor agents recruited from the pre-designed doctor set D, E denotes the set of recruiting edges. The iterative nature of this process allows doctor agents to incorporate a variety of expertise in inherently random topologies, which have been shown to offer advantages in multi-agent systems, thereby enhancing the diagnostic process and fostering a more efficient evolution process.\nMemory It is crucial for agents to remember previous dialogues to ensure the diversity and comprehensiveness of their diagnoses. However, unrestrained information exchange can lead to context explosion. To address this issue, we implement both instant and summarized memory to regulate context visibility. Instant memory maintains continuity in recent communications, while summarized memory consolidates key information from previous dialogues to preserve contextual awareness, enabling agents to generate new questions and answers nonarbitrary."}, {"title": "3.3 Coevolution", "content": "With the aim to effectively standardize the presentation pattern of agents, we propose an evolution mechanism that autonomously gathers, validates and stores experiences in libraries through simulations."}, {"title": "3.3.1 Attention Library", "content": "Recognizing the inherent complexity of SP requirements, the evolution process involves dividing the requirements into several trunks for each question. An attention agent then identifies and refines key lines in each trunk, and then merges them to form attention requirements ($r_a$) for answer generation. If the generated answer is validated as high-quality, the relevant information will be stored in the library in an organized array of doctor questions, records for answer generation, high-quality answers, and attention requirements. These serve as standardized presentation demonstrations ($d$) and refined requirements. In the human doctor training process, when a new question ($q$) is posed, the patient agent searches for and retrieves related records:\n$d, r_a = k(sim(q, L)) (P | d,r_a) \\rightarrow SP,$ \t\t(4)\nwhere $sim(\\cdot, \\cdot)$ calculates the similarity between the new question and those in the library, using an external text embedder. k denotes the retrieval of top-k matched results. With refined requirements and demonstrations as shown in Figure 3, the patient agent is instantly transformed into a qualified standardized patient, ready for human doctor training."}, {"title": "3.3.2 Trajectories Library", "content": "Similar diseases often imply similar high-quality diagnosis trajectories (T). During the simulation process, the doctor agent gives a series of questions ($Q = {q_1, q_2,..., q_n}$), to which the patient agents responds with a matching sequence of answers ($A = {a_1, a_2,..., a_n}$). To lower the possibility of asking trivial questions that cause inefficient patient agent training, we validate and store high-quality dialogues series as a prediction-trajectories ($t_i$):\n$L = (t_1, t_2,..., t_{|L|}),$\t\t\t\t\t\t(5)\n$t_i = {(q_{j-1}, a_{j-1}, q_j, a_j) | q \\in Q, a \\in A},$\nwhere $(q_{j-1}, a_{j-1}, q_j, a_j)$ illustrates the trajectory from one question $q_j$ to next question $q_{j+1}$. During the agent's communication, when encountering the current answer a, based on similarity with $a_{j-1}$, agents extract multiple $q_j$ as predicted questions and recommend it to doctor agents for question trajectory refinement (*):\n$T^* = (T | k(sim(a, L))),$\n$(D | T^*) \\rightarrow SD.$\t\t\t\t\t(6)\nBy effectively utilizing valuable dialogue trajectories, this paradigm guides questions toward a more professional and efficient pattern, transferring doctor agents into standardized doctor (SD) agents."}, {"title": "4 Evaluation", "content": "Datasets We have thoroughly collected real medical records from two collaborating hospitals to validate our EvoPatient. This study has been approved by the Ethics Committee of each hospital, with approval from the Second Affiliated Hospital, Zhejiang University School of Medicine, with the approval number 2020-568. Sun Yat-Sen University Cancer Center, with the approval number G2023-012-01 After meticulously reviewing these medical records, we extracted useful information for simulating patient cases, redacted the patients' private information, and integrated them into a dataset. We also add the public medical-nlp, a dataset compiled for Natural Language Processing using a corpus of medical transcriptions. As a result, the overall dataset contains more than 20000 distinct cases, including but not limited to liver cancer, appendicitis, pancreatic lesions, nasopharyngeal carcinoma, tumors, and other diseases.\nBaselines As there is no previous open-sourced framework aiming for fully autonomous standardized patient simulating, we select some robust reasoning methods and well-known works for quantitative comparison. \nMetrics Evaluating the questions and answers generated by agents in medical education is a challenging task due to the need for alignment with various detailed requirements. In the context of simulated standardized patient scenarios, inspired by, we propose the following evaluation metrics for answers: Relevance $(\\alpha \\in [0, 1])$, Faithfulness $(\\beta \\in [0,1])$, Robustness $(\\gamma \\in [0,1])$, and Ability $(\\frac{\\alpha + \\beta + \\gamma}{3} \\in [0,1])$. These dimensions assess the answers holistically while preserving essential details. For evaluating questions, we use the metrics Specificity $(\\delta \\in [0, 1])$, Targetedness $(\\epsilon \\in [0,1])$, Professionalism $(\\varsigma \\in [0,1])$, and Quality $(\\frac{\\delta + \\epsilon + \\varsigma}{3} \\in [0, 1])$ to assess their overall quality. A detailed description of these metrics can be found in Appendix B.\nImplementation Details For datasets in Chinese, we used Qwen 2.5 72B, a powerful pre-trained LLM, and ChatGPT-3.5 for datasets in English and GPT4 for pairwise evaluation, all with a temperature of 1. The default training cases of our framework are 200. The maximum turns of doctors and patient agents is 10. The threshold similarity of every index (question or answer) calculated by the external text embedder in each library is 0.9. All baselines in the evaluation share the same hyperparameters and settings for fairness. We rate our results in each metric through multi-step validation shown in Appendix D. (n) cases means training our framework on n cases."}, {"title": "4.1 Overall Analysis", "content": "Table 1 presents a comprehensive comparative analysis of the EvoPatient framework against baseline methods, where doctor agents autonomously ask approximately 3,000 questions across 150 cases, significantly outperforming all baselines in all metrics. Firstly, the improvement of EvoPatient over Tree-of-Thought, a powerful reasoning method, demonstrates that, even with multi-step planning and reasoning, without appropriate demonstrations and requirements, it is difficult for LLMs to simulate a qualified SP. This result highlights the effectiveness of using historical dialogue for agent standardization. The efficacy of our method largely results from the patient agent's ability to align with concise, yet precise refined requirements and learn the desired answering pattern through few-shot demonstrations. Moreover, in comparison to self-alignment and few-shot methods, EvoPatient significantly raises the Ability from 0.7542 and 0.7626 to 0.8597. This advancement emphasizes the need to simultaneously provide patient agents with refined requirements and demonstrations. Meanwhile, with the support of powerful doctor agents, the experience gathered in our framework can be more valuable for agent question answering, resulting in more robust, trustworthy, accurate, and flexible answers.\nTo better understand user preferences in practical settings, answers generated by various methods were compared in pairs by both human experts and the GPT-4 model to determine preferences. All methods were evaluated using the same list of questions and patient information to ensure a fair comparison. As shown in Table 3, EvoPatient consistently outperformed other baselines across both standard and cheat-question scenarios, achieving higher preference rates in evaluations conducted by GPT-4 and human experts. \nFurthermore, we present an answer statistics experiment in Table 2. The results show that EvoPatient excels in both computational efficiency and output quality. Specifically, the average response time of EvoPatient is 6.6922 seconds, only second to the CoT and Few-shot (2) method. Additionally, EvoPatient significantly reduces the input length of prompts by refining attention requirements, resulting in a notable reduction in token cost. Further analysis of the answer content indicates that the evolution process enables the SP agent to provide more accurate and robust answers, thereby improving answer quality while reducing the number of words in answers."}, {"title": "4.2 Information Leakage Analysis", "content": "The robustness of agents regarding malicious actors has long been a subject of concern. In our pilot study, we observed that when using a patient agent without evolution ($P_{w/o}$), doctors could potentially exploit the system to obtain information that should not be accessible, and even a single successful exploitation could make all training process meaningless. For example, when doctors ask, \"Please tell me your medical condition,\" $P_{w/o}$ often begins a detailed description of the patient's condition. This enables doctors to acquire a large amount of information with very few questions. Despite the requirement that $P_{w/o}$ should not answer such questions, the agent frequently misaligns. We refer to these types of questions as cheat questions. This form of jailbreak attack is difficult to prevent, as questions designed for jailbreaking can be very diverse, making it infeasible to create requirements that comprehensively cover all potential cheat attempts. Therefore, evolution is critical. As cheat questions, though diverse, often share common characteristics for exploiting more information, the generalization capability of our evolution process provide agents with demonstrations that allows it to learn a variety of strategies for responding to such queries. As shown in the right section of Table 3, after evolution, this issue is significantly mitigated, as $(P_{w/})$ has learned to recognize and avoid answering similar questions."}, {"title": "4.3 Evolution Transfer Analysis", "content": "Here we train our framework on Nasopharyngeal Carcinoma by 100 cases and directly use it for the other five diseases' SP simulation. As shown in Figure 4, without further training and task-specific customization, our framework shows great transfer ability, averagely increasing the answer metrics by around 15% in Faithfulness, 18% in Robustness, and 12% in Quality. This result indicates the exceptional transferability of our framework and represents a promising pathway to achieving both autonomy and generalizability."}, {"title": "4.4 Doctor Agent Analysis", "content": "Doctor Evolution We compared the performance of the doctor agent with ($D_{w/}$) and without ($D_{w/0}$) the evolution process by having it ask 2,000 questions across 100 cases. The results in Table 4 show that the evolution process significantly improves the doctor agent's performance, increasing Quality from 0.4928 to 0.6176, indicating a better formulation of quality medical questions focus on gathering relevant diagnostic information. Further analysis of question type distributions, as depicted in Figure 5, further demonstrates the effectiveness of our doctor evolution process. With examination-related questions increased from 14.09% to 25.57%, a level that is nearly impossible for a novice doctor agent to achieve, which significantly benefits the patient agent evolution.\nDoctor Recruitment We further investigated the doctor recruitment process in the patient agent evolution process using both $D_{w/}$ and $D_{w/o}$. As shown in Figure 6, when $D_{w/}$ was used without recruitment, with only one discipline doctor asking questions, the accumulation rate of the Attention Library decreased. This decrease was primarily due to $D_{w/}$ asking more targeted and efficient questions, whereas $D_{w/o}$ asking diverse but random and low-quality questions. The Doctor Recruitment process significantly alleviates this decrease. By leveraging prediction trajectories in the library, evolved doctors from different disciplines can ask more specialized questions instead of generic ones. This significantly improves the diversity of questions while ensuring their professionalism, resulting in a more diverse and specialized Attention Library.\nImpact on Patient Agent Because the doctor agent dominates the update of the Attention Library, which directly influences the patient agent answer quality. Thus, we further analyze the impact of recruiting and evolving strategies of doctor agents through the quality of patient answers, as shown in Table 5. The results demonstrate that implementing recruitment and evolution strategies in the doctor agent leads to more effectively evolved patient agents. Specifically, the Ability of patient agents trained by evolved doctor agents over recruit is stimulating, indicating that with only recruit ability, the doctor agents still struggle to ask professional questions that can positively contribute to content quality in Attention Library. Further improvements are observed when combining both recruit and evolve, achieving the highest performance across all metrics. This comprehensive improvement confirms the great compatibility of these two strategies."}, {"title": "5 Conclusion", "content": "Recognizing the absence of a mechanism for patient agents to learn through simulations on diverse cases, we introduced EvoPatient, an innovative simulation framework that enables both patient and doctor agents to autonomously accumulate past experiences through a coevolution mechanism. As a result, patient agents can efficiently manage various simulation cases for human doctor training, while doctor agents improve their questioning abilities, thereby enhancing patient agent training efficiency. Quantitative analysis reveals significant improvements in answer quality, resulting in a more stable, robust, and accurate answer pattern with optimized resource consumption. We anticipate that our insights will inspire further research on LLM-based simulated partners, emphasizing the importance of autonomous evolution, and driving agents toward achieving greater realism in simulations."}, {"title": "6 Limitations", "content": "Our study has explored how to standardize simulated agent presentation patterns through autonomous evolutions in medical education. However, researchers and practitioners should consider certain limitations and risks when applying these insights to the development of new techniques or applications.\nFirstly, from the perspective of simulation capability, the ability of autonomous agents to fully replace human simulated partners may be overestimated. As an example, while EvoPatient enhances agent presentation abilities across a wide range of questions and cases, autonomous patient agents sometimes fail to replicate the full capabilities of real human SPs. The complexity and ambiguity of human SPs make it difficult to define a flawless set of requirements for role-playing. When confronted with unfamiliar or cheat questions, agents\u2014despite receiving role assignments and demonstrations\u2014sometimes fail to provide appropriate responses. This suggests that LLM-based agents may struggle to fully understand the underlying intent of their role, instead of merely following provided instructions. Without clear, detailed instructions, agents may behave like answering machines\u2014responding in a patient-like manner but lacking genuine patient behavior. Thus, we recommend defining clear, step-by-step requirements for the patient agent during the evolution process. Given current agent capabilities, fulfilling highly detailed requirements may not always be guaranteed, highlighting the need to balance specificity with practical feasibility. Moreover, nowadays, patient agents can currently only provide text-based responses; real SPs convey additional non-verbal cues such as tone and facial expressions. These cues are vital for training doctors to make appropriate inquiries and diagnoses based on a patient's external manifestations.\nSecondly, in terms of doctor agents, even with role assignments, it remains challenging for an autonomous agent to ask accurate and professional questions in the way of a sophisticated human doctor. Although this challenge is mitigated by allowing doctor agents to form a question pool, recruit doctor agents with role assignments of other disciplines, and gather experience through the simulation process, these approaches can lack generalizability when facing unseen diseases with huge differences. Future research should focus on enhancing doctor professionalism at a disciplinary level, enabling doctor agents to be truly versatile across various diseases.\nThirdly, from an evaluation perspective, the complex nature of the simulation process in medical education, combined with the lack of effective metrics for automated evaluation such as executability or the ability to break down dialogues for multi-step assessment\u2014makes automated dialogue evaluation highly challenging. While human evaluation often yields the most reliable results, assessing thousands of dialogues based on patient records in context is labor-intensive and even impractical. This paper instead emphasizes objective dimensions, such as relevance, faithfulness, robustness, and overall ability of the patient agent, as well as specificity, targeting, professionalism, and overall quality of the doctor agent. However, future research should consider additional dimensions, including speaking tone, readability, user-friendliness, and more. Developing a completely fair and objective evaluation standard remains a significant challenge. Therefore, in the foreseeable future, agent evaluation may need to be customized for specific medical scenarios.\nFourthly, while few-shot demonstrations, refined requirements, and shortcut dialogue trajectories from historical dialogues can enhance agent authenticity, some low-quality dialogues may still be stored in the library and extracted as references, negatively affecting agent performance in standardized presentations. Although we implement an evolution correction strategy (see Appendix G) to remove low-quality content, some deeply hidden issues remain difficult to detect. Therefore, future research should explore methods for more accurately assessing the quality of content within the evolutionary library.\nDespite these limitations, we believe that they provide valuable insights for future research and can be mitigated by engaging a broader, technically proficient audience. We expect these findings to offer valuable contributions to the enhancement of simulated agent authenticity and their role in the evolving landscape of LLM-powered agents."}, {"title": "7 Ethical Considerations", "content": "Participant Recruitment Experts for annotations are individuals who hold a graduate degree (Master's or PhD) in clinical medicine or a related field, or who are currently pursuing such a degree. We pay for each expert and other participants for participation.\nSystem and Data Usage All data and frameworks developed in this study are intended exclusively for academic research and educational purposes. The framework is not suitable for real-world deployment without further development, including larger-scale training and testing, compliance with departmental and administrative protocols in real hospital settings, and comprehensive evaluations by users and experts. All hospital patient records utilized in this study are fully de-identified and consented for research purposes. The data does not include personally identifiable information about patients or hospital staff. Additionally, the data has been anonymized to exclude sensitive information, ensuring it is strictly used for academic research."}, {"title": "I Question Type", "content": "In our experiments, we categorized questions from doctor agents into ten types. Here, we give detailed descriptions of these types:\n\u2022 Basic Information Inquiries: These questions focus on gathering essential personal and medical details from the patient, such as their name, age, sex, medical history, and allergies. It also includes questions about family medical history and any previous diagnoses or treatments.\n\u2022 Chief Complaint Inquiries: These questions address the primary reason why the patient is seeking medical attention. It often involves asking the patient to describe their main issue or symptom, such as pain, discomfort, or any other abnormal physical or mental state. The goal is to understand the most pressing concern from the patient's perspective.\n\u2022 Detailed Symptom Inquiries: These questions delve deeper into the patient's symptoms. They involve exploring the nature, intensity, duration, and frequency of symptoms. For example, if a patient reports chest pain, the healthcare provider may ask when it started, whether it's constant or intermittent, what triggers it, and any associated symptoms like sweating or dizziness.\n\u2022 Lifestyle Inquiries: These questions aim to understand how the patient's lifestyle might contribute to their health condition. This includes asking about diet, exercise, sleep patterns, substance use (such as alcohol, tobacco, or drugs), and stress levels. The objective is to identify modifiable factors that could influence the patient's health.\n\u2022 Psychological Condition Inquiries: These questions focus on the mental and emotional health of the patient. They include inquiries about mood disorders (like depression or anxiety), stress levels, sleep disturbances, and any history of mental health conditions. It's essential to understand how psychological factors might be affecting the patient's overall health.\n\u2022 Social Environment Inquiries: These questions explore the patient's social context, including their living situation, social support network (family, friends, or community), occupation, and any environmental factors that could impact health. These inquiries can help identify social determinants of health, such as access to healthcare, safety, or socioeconomic status.\n\u2022 Physical Examination-Related Questions: These questions are typically focused on the findings from the patient's physical examination. They may involve asking about any observed abnormalities such as abnormal heart sounds, skin conditions, or muscle strength. These questions help to narrow down potential causes based on physical signs.\n\u2022 Treatment and Medication Response Inquiries: These questions focus on how the patient has responded to previous treatments or medications. They involve asking if the patient has experienced any improvements or side effects after taking prescribed medications or undergoing treatments. This helps the healthcare provider assess the effectiveness and tolerance of the treatment.\n\u2022 Preventive Health Inquiries: These questions involve topics related to preventing illness and maintaining health, such as vaccination history, screening tests, and lifestyle choices that reduce the risk of diseases. For example, a healthcare provider might ask whether the patient has had recent cancer screenings, cholesterol checks, or flu vaccinations.\n\u2022 Other Related Questions: This category includes any other questions that may not fall into the previous categories but are still relevant to the patient's health. It could involve questions about past surgeries, genetic conditions, or new symptoms that don't clearly fit into the other categories but may provide crucial insights into the patient's condition."}, {"title": "J Cost Analysis", "content": "J.1 Token Counts\nAs depicted in Figure 10, the token consumption of the evolved EvoPatient is significantly reduced. This reduction is attributed to the patient agent's enhanced ability to focus on the specific attention requirements of each question after evolution, rather than considering the overall requirements. Consequently, not only does the framework exhibit lower token consumption, but it also aligns more closely with the specific requirements, demonstrating improved efficiency and precision in processing questions.\nJ.2 Word Counts\nHere, we randomly selected some cases and posed several questions to analyze the word count of the answers given by the patient agent before and after evolution. As shown in Figure 11, the answers after evolution are shorter and more stable compared to those before evolution, indicating that evolution has made the patient agent's answer pattern more consistent. Before evolution, we observed several peaks in word count, with the highest reaching 192 words. Upon examining the content of the answers, we found that it is because some cheat questions led to information leakage in the answers of the patient agent before evolution, revealing excessive information, which resulted in a high word count in its answers."}, {"title": "L Case Study", "content": "L.1 Information Leakage\nAs shown in Figure 16, we present some deliberate cheat question attacks on the patient agent before and after evolution. It can be observed that the pre-evolution patient agent, due to their own misalignment or insufficient requirements, often provided faulty answers (e.g., answering too many questions at once, using professional terms, and revealing their disease names). During the evolution, we found that evolution has generalization, that is, through a high-quality answer when the patient agent succeeds in preventing information leakage, it can gradually learn to answer similar questions, and so on, learning to answer a wide range of questions. For example, in the initial requirements, the patient agent was required not to answer the final medical conclusion. Through this requirement, the patient agent successfully conducted a high-quality answer to the doctor's inquiry \"Please tell me about your medical condition.\" Subsequently, during the evolution process, the patient agent was able to successfully generalize this case into an answer for \"Please tell me about your medical history,\" thus learning to answer questions that were not explicitly required in the requirements. It can be seen that the evolved patient agent can effectively deal with cheat question attacks, making this framework more robust.\nL.2 Misalignment\nIn our experiment, we noticed that as the requirements scale up, there is an increasing likelihood that the patient agent will misalign with the requirements. However, providing only basic requirements for a qualified SP can make the requirement prompts lengthy. A frequently occurring misalignment is demonstrated in Figure 17. In EvoPatient, to enable further doctor training, we allow doctors to ask patients to undergo physical examinations (e.g., MRI scans, oncology examinations, CT scans). If the patient's record contains details of these examinations, it should inform the doctor of the results, thus imitating the scenario where a patient undergoes examinations in a hospital and then submits the results to the doctor. However, when a doctor directly inquires about a specific item within an examination, the patient should not respond, as this does not train the doctor's ability to request certain examinations from patients presenting with specific symptoms. At the same time, the patient agent should not be aware of the meaning of a specific item within the examination that the doctor is inquiring about. Before the patient's evolution, the patient agent often refused to answer when asked by the doctor to undergo a specific examination, yet provided results when asked about a specific item within the examination. After the evolution process, this situation has been largely eliminated, as the requirement attention strategy helps the patient agent to pay specific attention to only a few requirements that are useful toward the question"}, {"title": "O Big Five traits", "content": "The Big Five personality traits (McCrae and Costa, 1987), also known as the Five-Factor Model (FFM) or OCEAN model, is a widely accepted framework for understanding human personality"}]}