{"title": "SYNTHETIC IMAGE LEARNING: PRESERVING PERFORMANCE\nAND PREVENTING MEMBERSHIP INFERENCE ATTACKS", "authors": ["Eugenio Lomurno", "Matteo Matteucci"], "abstract": "Generative artificial intelligence has transformed the generation of synthetic data, providing innovative\nsolutions to challenges like data scarcity and privacy, which are particularly critical in fields such as\nmedicine. However, the effective use of this synthetic data to train high-performance models remains\na significant challenge. This paper addresses this issue by introducing Knowledge Recycling (KR),\na pipeline designed to optimise the generation and use of synthetic data for training downstream\nclassifiers. At the heart of this pipeline is Generative Knowledge Distillation (GKD), the proposed\ntechnique that significantly improves the quality and usefulness of the information provided to\nclassifiers through a synthetic dataset regeneration and soft labelling mechanism. The KR pipeline\nhas been tested on a variety of datasets, with a focus on six highly heterogeneous medical image\ndatasets, ranging from retinal images to organ scans. The results show a significant reduction in the\nperformance gap between models trained on real and synthetic data, with models based on synthetic\ndata outperforming those trained on real data in some cases. Furthermore, the resulting models show\nalmost complete immunity to Membership Inference Attacks, manifesting privacy properties missing\nin models trained with conventional techniques.", "sections": [{"title": "1 Introduction", "content": "The advent of generative deep learning has marked a fundamental technological breakthrough that is rapidly permeating\nevery aspect of society and profoundly affecting the daily lives of every individual. Thanks to this technology, it\nis now extremely easy to create and interact with high-quality synthetic data, be it images, text, audio or video.\nThis ease of access to artificially generated content makes it increasingly difficult to distinguish between human and\nalgorithmic production. Meanwhile, the applications and innovations of generative models are expanding at a rapid pace,\nrevolutionising many sectors. The implications of this development are profound: on the one hand, new opportunities\nare opening up, and on the other, ethical and social challenges are emerging in relation to the use and misuse of such\ntechnologies.\nToday, this technological progress raises problems related to the circulation of images or text documents generated by\nalgorithms and presented as the fruit of human labour. However, it also opens the door to a dual use with immense\nvirtuous potential. It is precisely the difficulty of distinguishing between human and algorithmic production that has led\nto the use of generative models to enrich real data sets and, more recently, to attempts at total replacement to obtain\nentire synthetic datasets.\nHowever, the creation of entirely synthetic datasets is a complex task that requires models capable of generating large\namounts of data in a reasonable amount of time, while carefully balancing the quality and variety of the data generated.\nIndeed, it is known that training models based solely on synthetic data tends to degrade performance compared to those\ntrained on real data [1]. In addition to these aspects, it is crucial to consider an area of growing importance, that of data"}, {"title": "2 Related Works", "content": "The state of the art in image generation is currently contested between the Generative Adversarial Networks (GAN)\nfamily and the Denoising Diffusion Probabilistic Models (DDPM) [3, 4]. Although using different mechanisms, both\nfamilies of models are in fact capable of producing and manipulating images with very high resolution by being\nconditioned in a variety of ways [5, 6]. In parallel to this line of research, which aims to produce high quality single\nimages, a second line of research has been developed with the aim of exploiting this generative power to create fully\nsynthetic datasets or to enrich existing ones.\nThe first attempts in this direction concerned contexts where it is very complex and time-consuming to collect and label\nnew data, such as in the medical field. Frid-Adar et al. used GANs to generate synthetic images of liver lesions. This\nwork showed that adding synthetic images to the source dataset improved the performance of classification models for\ndiagnosing liver lesions [7]. Subsequently, Sedigh et al. and Islam et al. also used GAN models to generate synthetic\nimages of skin cancer and brain PET, respectively. In both cases, enriching the dataset with real images led to improved\nclassification performance [8, 9].\nIn addition, studies have been undertaken not to enrich existing image datasets, but to generate entiraly new ones and\nevaluate their properties via downstream machine learning problems [10, 11, 12]. From early work, it has become\nclear that the semantic information contained in synthetic data is not in itself sufficient for a model trained on such\ndata to perform well when making inferences on real data [13]. Techniques have been developed to make the most\nof the information that can be extracted from generative models, as well as the potentially unlimited number of\nimages that can be generated. It has been shown that both recycling the synthetic dataset in the training phase and\ncreating synthetic datasets with higher cardinality than the dataset used to train the generator are very beneficial\nto performance [14, 15]. Filtering techniques were also proposed to discard synthetic images that were classified\nincorrectly or with low confidence by an auxiliary classifier [16]. This also allowed sampling from sparser distributions,\nfurther enriching the information of the synthetic datasets [1]."}, {"title": "2.1 Privacy Threats and Countermeasures", "content": "As research on new models and techniques continues and their applications increase, the attack surface on such models\nand the importance of privacy protection continue to grow. Among the most common and popular attacks are the"}, {"title": "3 Method", "content": "This section presents the Knowledge Recycling (KR) pipeline for the creation of synthetic datasets and their subsequent\nuse for training downstream classifiers. The pipeline starts with a preliminary step where an auxiliary classifier, called\nTeacher Classifier, and a data generator, called Generator, are trained on the same real dataset. The first proper step,\ncalled Checkpoint Optimisation, aims at identifying the best checkpoint of the Generator. During this step, a classifier\nis trained for each checkpoint of the Generator. These classifiers, called Student Classifiers, have the same architecture\nas the Teacher Classifier and are trained using the same training technique. For each checkpoint, the generation of\nthe synthetic datasets is performed using the proposed technique called Generative Knowledge Distillation (GKD),\nwhich is explained in detail in the Subsection 3.4. Once the optimal checkpoint is identified, the Tuning step follows, in\nwhich the generation parameters are optimised and the final Student Classifier is trained. Finally, the last step, called\nMembership Inference Attack, tests the robustness of the Student Classifier against the homonymous privacy attack.\nA graphical representation is shown in Figure1."}, {"title": "3.1 Teacher Classifier", "content": "The Teacher Classifier plays a key role in the KR pipeline, as it is not only the core of the GKD technique, but also the\nbenchmark against which the Student Classifiers can be compared in terms of accuracy performance and resistance to\nprivacy attacks. In order to have a fair and robust comparison, the architecture and training technique of the Teacher\nClassifier is also replicated for the Student Classifiers. Having to balance performance and training speed, since each\ncheckpoint requires a whole one, the chosen architecture is a ResNet14 model [24]. Training is done in Mixed Precision\nfor 500 epochs with SGD optimiser, initial learning rate of 0.5, cosine annealing scheduler and TrivialAugment and\nMixUp as main augmentation [25, 26, 27]. For more details see B."}, {"title": "3.2 Generator", "content": "In the field of image generation, Generative Adversarial Networks (GAN) and Denoising Diffusion Probabilistic\nModels (DDPM) currently represent the state of the art [3, 4]. Although they differ significantly in their operation,\nboth approaches offer high and comparable performance in generating different types of media content that can be\nconditioned in different ways. GANs are known for their fast inference, but suffer from instability during training.\nDDPMs, on the other hand, offer more stable training but require longer generation times. Despite recent developments,\nDDPM models can drastically reduce the number of denoising steps, but their generation times are still too long to\ncompete with GANs in generating large amounts of data [28].\nFor this work, a GAN-based approach was chosen, which favours the speed of inference. In particular, a modified\nversion of BigGAN-Deep was chosen, a model that represents a milestone in the development of GAN [29] models.\nIndeed, BigGAN introduced several important innovations, including the use of conditional batch normalisation, the\nuse of a truncation trick to control the trade-off between quality and generation diversity, combined with advanced\noptimisation techniques to handle large networks, such as spectral normalisation [30]. The proposed implementation\nmodifies the original BigGAN-Deep model in several aspects. The hinge loss is replaced by a logistic loss, and the tanh\nactivation is replaced by a sigmoid. In addition, regularisation techniques such as label smoothing have been introduced\nto improve the quality of the discriminator, and the AdamW optimiser with a weight decay of 0.0005 has been adopted.\nThese changes aim at improving the stability of the training and the quality of the generated images. The model was\ntrained for 500 epochs, with a 4:1 ratio between discriminator and generator updates. To ensure the robustness of the\nmodel, we implemented a system of saving checkpoints at regular intervals of 5 epochs. A detailed description of the\nimplementation and a comparison between the vanilla model and our modified version can be found in A."}, {"title": "3.3 Evaluation Metric", "content": "In the evaluation of image generators, the most widely used metrics in the literature are the Inception Score (IS) and\nthe Fr\u00e9chet Inception Distance (FID) [31, 32]. The IS aims to quantify the quality of the distribution generated by assessing\nboth the clarity and diversity of the images produced. The FID, on the other hand, provides a more comprehensive\nmeasure by comparing the generated distribution with the actual distribution used to train the Generator, thus capturing\nboth the quality and fidelity of the synthetic images.\nHowever, recent studies have highlighted the limitations of using these metrics to assess the usefulness of generated\nimages in downstream learning contexts. A lack of correlation was observed between IS and FID and the effectiveness\nof the generated data for subsequent classification tasks [1]. Furthermore, a trade-off between the quality of individual\nimages and the diversity of the generated distribution was identified [33]. The maximisation of IS and FID tends to\nfavour the quality of the generated images at the expense of the variety, which is crucial for the creation of synthetic\ndatasets that favour the generalisation of the models trained on them.\nIn this study, the Classification Accuracy Score (CAS) is adopted as the main metric. The CAS measures the validation\naccuracy on real data of a classifier trained on synthetic datasets [34]. This metric helps to identify the training epoch\nthat produces the most effective synthetic dataset and, like IS and FID, helps to prevent the mode collapse of the\nGenerator."}, {"title": "3.4 Checkpoint Optimisation", "content": "Once both the Teacher Classifier and the Generator have been defined, trained on real training data and frozen, it is\npossible to proceed to the Checkpoint Optimisation step. The goal of this first step is to identify the optimal checkpoint\nto maximise the performance of the downstream Student Classifier models. For each Generator checkpoint, a Student\nClassifier is trained using a strategy similar to that of the Teacher Classifier, but with a reduced number of epochs \u2013\n100 instead of 500 \u2013 for efficiency reasons. At the beginning of each training session, a synthetic dataset of the same\ncardinality as the real one is generated using the current checkpoint. The input noise is sampled from a multivariate"}, {"title": "3.5 Tuning", "content": "After the identification of the optimal checkpoint with respect to the CAS metric, it is possible to proceed with the\nTuning step to optimise also the generation parameters. These parameters, held constant during the Checkpoint\nOptimisation step, are now re-computed to further improve Student Classifiers performance. The parameters being\noptimised are:\n\u2022 The regeneration rate of the synthetic dataset: previously fixed at 10 epochs, is now varied between 1 and 10\nepochs.\n\u2022 The scale of the cardinality of the generated dataset: previously set at 1, is now made to vary between 1 and 10.\n\u2022 The standard deviation used during sampling from the multivariate Gaussian distribution: previously equal to\n1.0, is now made to vary between 1.0 and 2.5.\nIt has been shown in previous works that regenerating the dataset more frequently and creating more numerous datasets\ncontributes to the improvement of CAS [1, 15]. With regard to standard deviation, this approach, in the opposite\ndirection to the Truncation Trick implemented in the BigGAN-Deep vanilla model, aims to favour a more varied\ngeneration, even at the expense of the perceptual quality of the generated data [29, 1]. The Tuning step is carried on\nvia a Tree-structured Parzen Estimator associated with a Hyperband pruning mechanism [35, 36]. The optimisation\nproceeds for 50 iterations. In each iteration, a Student Classifier is trained with the same procedure used in Checkpoint\nOptimisation but using the data generated with the current parameter configuration, with the aim of maximising CAS.\nAt the end of the search, the optimal parameter configuration is used to train the final Student Classifier for 500 epochs."}, {"title": "3.6 Membership Inference Attack", "content": "The final step in the KR pipeline involves a resistance test for the Student Classifier against a Membership Inference\nAttack (MIA). This type of attack aims to compromise privacy by identifying the training data stored within the attacked\nmodel. In the context of this study, sensitive training data is never directly exposed to the Student Classifier, but\nis only used for training the Generator and Teacher Classifier. The objective of this step is therefore to assess the\neffectiveness of the MIA in identifying the data used to train the Generator via the Student Classifier and to compare this\neffectiveness with that of the same attack carried out against the Teacher Classifier. To perform the MIA, the shadow\nmodels technique proposed by Shokri et al. is adopted [2].. The implementation involves:\n1. Creation of 10 shadow models, identical in architecture and training technique to the Teacher Classifier.\n2. Utilisation of the validation dataset to train each shadow model, split with 45/10/45 splits to simulate the\ntraining, validation and test sets, mixed before splitting to obtain different splits for each shadow model.\n3. Shadow dataset generation: training and test data are given as input to each shadow model. The logits obtained\nrepresent the shadow dataset features, while a binary label indicates whether they belong to the training set or\nthe external (test) set.\n4. Division of the dataset according to the classes of the original dataset with which the shadow models were\ntrained.\n5. Training of three models (Logistic Regression, Support Vector Classifier with RBF, Random Forest) for each\nclass of the dataset.\n6. Selection of the best performing model for each class, based on the Area Under the Receiver Operating\nCharacteristic Curve (AUC) metric."}, {"title": "4 Experiments and Results", "content": "The experiments were performed on nine image datasets, all rescaled to 32x32. CIFAR10, CIFAR100 and FashionM-\nNIST were used both for the final comparisons and to calibrate and test the Knowledge Recycling (KR) pipeline, as\ndescribed in detail in A and D. The six medical datasets - BloodMNIST, DermaMNIST, OrganCMNIST, OrganSMNIST,\nPneumoniaMNIST and RetinaMNIST - contain real images from the MedMNIST v2 benchmark [37]. These medical\ndatasets represent the primary field of application for the proposed technique. The KR pipeline, having been calibrated\non the three aforementioned datasets, is subsequently applied to these medical datasets without further specific adapta-\ntions. This approach allows for the evaluation of the technique's effectiveness and robustness in a more specialised and\ncomplex context, distinct from that on which it was initially calibrated. Further details of all the datasets used can be\nfound at C. Experiments were run on 4 NVIDIA Quadro RTX 6000 GPUs.\nThe Figure 2 illustrates the results of the Checkpoint Optimisation and Tuning phases, expressed as Classification\nAccuracy Score (CAS) on the respective validation sets, compared with the optimal Accuracy performance of the\nTeacher Classifier on the same set. The importance of the selection of the optimal checkpoint and its evaluation via CAS\nis evident both for Generators with more stable checkpoints (e.g. DermaMNIST, RetinaMNIST) and for those subject\nto mode collapse and consequent drop in performance (e.g. BloodMNIST, OrganSMNIST). The application of the\nGenerative Knowledge Distillation (GKD) technique alone demonstrates to be sufficient to obtain results close to those\nof the Teacher Classifier. In the case of the RetinaMNIST dataset, a more accurate model is even obtained from the\nsynthetic data alone. The Tuning step turns out to be beneficial overall, increasing the validation CAS from a minimum\nof 0.85% for FashionMNIST to a maximum of 4.03% for BloodMNIST, as reported in Table 1. This improvement is\ndue to two factors. The first is the increased availability of information due to the higher cardinality of the generated\ndatasets and their higher recycling frequency. The second is the increased diversity of data due to sampling with a larger\nstandard deviation, which, in combination with the GKD technique, also makes it possible to exploit images that would\nbe uninformative if associated with the hard label used to generate them. These images would likely be filtered out and\ndiscarded if coupled with another training technique from synthetic data."}, {"title": "5 Discussion and Limitations", "content": "The Knowledge Recycling (KR) technique proposed in this study has been shown to be effective in creating Student\nClassifiers with comparable performance to the corresponding Teacher Classifiers, while maintaining considerable\nresistance to Membership Inference Attacks (MIA). This approach, initially calibrated on standard datasets such as\nCIFAR10, CIFAR100 and FashionMNIST, and subsequently applied to six medical image datasets from the MedMNIST\nv2 benchmark, establishes a new state-of-the-art in this field.\nThe average performance gap between Teacher Classifiers and Student Classifiers was reduced to -1.24% in terms of the\nClassification Accuracy Score (CAS) over the test sets, a significant improvement on previous results. This progress is\nparticularly remarkable considering the use of a single Generator, in contrast to previous works. Dat et al. had achieved\nan average gap of -10.08% with a single Generator and -5.81% with six, while Lampis et al. had achieved -3.87% with\na single Generator and -2.63% with six [1]. The approach proposed in this study exceeds these results, suggesting\npotential for improvement through the use of multiple Generators in parallel.\nThe inclusion of a metric to empirically measure one of the privacy-related aspects, such as resistance to MIAs, proved to\nbe crucial for a richer and more multifaceted evaluation of the proposed method, especially if the data under analysis are\nmedical images with potential sensitivities to violations of their privacy. Teacher Classifiers, trained with regularization\nand augmentation techniques, showed partial resistance to MIAs, confirming the privacy properties associated with such\ntechniques [21]. However, Student Classifiers showed almost complete resistance to these attacks, showing a significant\nprivacy advantage of the proposed approach.\nThe main limitations of this study concern the small size of the images used (32x32 pixels) and the choice of models that\nare efficient but not comparable in performance with the current state of the art in their respective tasks. These decisions\nwere dictated by computational efficiency considerations, given the onerous nature of the KR pipeline. The use of higher\nresolution images and more complex models, both for the Classifier (ResNet14) and the Generator (BigGAN-Deep),\ncould lead to further performance improvements. In particular, upgrading the Generator model could further reduce the\nperformance gap between Teacher and Student Classifiers, potentially outperforming the Teacher. The scalability of\nthe proposed approach, both in terms of the number of Generators and the cardinality and frequency of generation,\noffers exciting prospects for future developments. With continued hardware advancement, it is plausible that in the near\nfuture it will be possible to apply this technique with more complex models and on larger datasets, opening up new\npossibilities in the field of private learning and the generation of high-quality synthetic data."}, {"title": "6 Conclusions", "content": "In this paper, the Knowledge Recycling pipeline was presented, demonstrating how synthetic data can be generated\nand used to train downstream classifiers. It has been shown how the Generative Knowledge Distillation technique,\nused within the pipeline, improves the quality of information transferable to such downstream classifiers compared\nto techniques previously proposed in the literature. It was possible to simultaneously reduce the gap between the\nperformance obtainable from real data alone and that obtainable from generated data, setting a new state of the art, as"}]}