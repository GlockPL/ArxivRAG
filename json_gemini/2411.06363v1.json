{"title": "Layer-Wise Feature Metric of Semantic-Pixel Matching for Few-Shot Learning", "authors": ["Hao Tang", "Junhao Lu", "Guoheng Huang", "Ming Li", "Xuhang Chen", "Guo Zhong", "Zhengguang Tan", "Zinuo Li"], "abstract": "In Few-Shot Learning (FSL), traditional metric-based approaches often rely on global metrics to compute similarity. However, in natural scenes, the spatial arrangement of key instances is often inconsistent across images. This spatial misalignment can result in mismatched semantic pixels, leading to inaccurate similarity measurements. To address this issue, we propose a novel method called the Layer-Wise Features Metric of Semantic-Pixel Matching (LWFM-SPM) to make finer comparisons. Our method enhances model performance through two key modules: (1) the Layer-Wise Embedding (LWE) Module, which refines the cross-correlation of image pairs to generate well-focused feature maps for each layer; (2) the Semantic-Pixel Matching (SPM) Module, which aligns critical pixels based on semantic embeddings using an assignment algorithm. We conducted extensive experiments to evaluate our method on four widely used few-shot classification benchmarks: miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS. The results indicate that LWFM-SPM achieves competitive performance across these benchmarks. Our code will be publicly available on https://github.com/Halo2Tang/Code-for-LWFM-SPM.", "sections": [{"title": "1. Introduction", "content": "Humans have the ability to abstract and generalize low-level visual elements, such as contours, edges, colors, textures, and shapes, to form high-level semantic features that aid in recognizing and understanding the similarities and differences between objects. This capability is particularly crucial in few-shot classification tasks, as it allows models to accurately identify and distinguish between different categories based on contrasting critical high-level semantic features, even when faced with a limited number of samples from new categories. In contrast, traditional deep learning methods [1, 2] typically rely on large amounts of labeled data for training in order to recognize and classify specific objects or concepts. In few-shot learning scenarios, these models may encounter challenges, as they are not specifically designed to learn from a small amount of data quickly. Recently, few-shot learning methods have been introduced to address this limitation, typically requiring only a few images to understand the characteristics of a class and generalize these features to unseen images for inductive reasoning. Among these methods, metric-based approaches [3, 4, 5] are computationally efficient, as they do not require extensive parameter tuning or complex model structures. They rely on learning image embeddings to measure the similarity between objects and perform classification.\nHowever, through our study of prior methods, we identified two key limitations in metric-based methods: (1) The different semantic focuses produced by various levels of the backbone have not been fully utilized. Features at different levels typically focus on distinct aspects of the image [6]. In [3, 4], only features from the final layer of the backbone are utilized. However, this layer may be overly focused on a specific aspect of the image. In few-shot learning, it is crucial to leverage a wider variety of features to assess the similarity between image pairs more effectively. Chen et al. proposed using a self-attention mechanism to learn the relationships between multi-level features from the backbone but introduced excessive parameters and computational complexity [5]. (2) Semantic pixel misalignment is also a common challenge. In these methods, the final query embedding and support embedding are typically compared using element-wise cosine similarity. However, directly performing element-wise comparisons can often fail to correctly match semantically similar pixels, as illustrated in Fig. 1 (c).\nTo address the issue of utilizing semantic focus, we propose a Layer-wise Embedding (LWE) Module. By computing the correlation map generated from different levels of information and performing layer-wise production, we effectively integrate diverse semantic features without relying on convolution or self-attention operations. As a result, our approach reduces both the number of parameters and the computational complexity. However, after aggregating multi-level semantic features, we observed a persistent issue of positional inconsistency between semantically corresponding objects in paired images. To tackle this challenge, we rearrange the semantic pixel positions in the image pair by leveraging the Hungarian matching algorithm"}, {"title": "2. Related works", "content": ""}, {"title": "2.1. Few-shot classification", "content": "Few-shot classification methods have evolved significantly over the years and can be broadly categorized into four types. The first type is data augmentation-based methods [7, 8, 9, 10, 11], where the primary idea is to increase the number of samples for underrepresented classes, thereby helping the model achieve more accurate classification. However, our approach eliminates the need for complex data augmentation, making it simpler and more efficient. The second category comprises parameter optimization-based methods. In few-shot tasks, there is often a distribution mismatch between the training and test sets, causing the model to perform poorly on unseen data. To address this, parameter optimization-based methods [12, 13, 14, 15, 16] often a meta-learning strategy to optimize model parameters across different tasks. During training, the dataset is split into multiple tasks, enabling the model to better adapt to new tasks. The third type is transfer learning-based methods [17, 18, 19], which primarily focus on extracting knowledge from source domains and applying that knowledge to a target domain. The final category consists of metric-based methods [20, 21, 22, 23, 24, 25, 26], where the model learns to measure the similarity between different categories. It generates similar embeddings for the same class and more distant embeddings for various"}, {"title": "2.2. Cross-correlation", "content": "Cross-correlation is a widely used technique for identifying relationships between two signals, such as images, making it valuable in various matching tasks [27, 28]. In the context of few-shot learning, accurately determining the correlation between images has become increasingly important for improving model performance. As a result, cross-correlation has been adapted for few-shot tasks, finding applications in areas such as segmentation [29, 30] and classification [4, 5, 3].\nHowever, previous methods have rarely explored multi-level cross-correlation, which can provide a more comprehensive focus on multi-level semantic information. Meanwhile, many of these methods compute cross-correlation by focusing solely on pixel similarity at corresponding positions, thereby neglecting the potential similarity between pixels located at different positions.\nIn this paper, we address these issues by designing a multi-layer semantic aggregation method that integrates multi-level semantic focus with minimal additional complexity, while also exploring the application of assignment algorithms in computing pixel relationships."}, {"title": "2.3. Assignment algorithm", "content": "Assignment algorithms play a crucial role in various applications, enabling the optimal pairing of elements across domains. These algorithms have found significant utility in visual tasks in recent years [31, 32, 33], where accurate correspondences between images or features are essential for performance. Two commonly employed matching algorithms are the Hungarian Algorithm [34] and the K-Nearest Neighbors (KNN) [35] algorithm. The Hungarian Algorithm is well-known for solving the assignment problem by efficiently finding the optimal one-to-one matching between two sets. It minimizes the total cost of the assignments, making it particularly useful in resource allocation and task assignment in visual applications. On the other hand, the KNN algorithm is a versatile non-parametric method used for both classification and regression. By identifying the closest data points based on a defined distance metric, KNN facilitates the prediction of labels or values through the majority voting of neighbors or averaging of outcomes. Its simplicity and effectiveness have made it a popular choice in various visual tasks, particularly in low-dimensional settings.\nIn this paper, we conduct experiments on both the Hungarian Algorithm and KNN, leveraging their strengths to enhance the similarity assessment in our proposed method. A detailed analysis can be found in the experiment section."}, {"title": "3. Methodology", "content": "In this section, we provide a detailed description of our proposed method. Fig. 2 illustrates the overall architecture of our proposed Layered Weighted Feature Metric with Semantic Pixel Matching (LWFM-SPM). LWFM-SPM consists of two main modules: the layer-wise embedding Module and the semantic-pixel matching module. The first module generates well-focused feature maps for image pairs by producing semantic feature maps and cross-correlation matrices for support and query images at each layer and using the scores from the cross-correlation matrices to adjust the weight of each semantic feature in the feature maps. The second module provides fine-grained metrics for classification by reassigning semantic pixels between feature maps of image pairs using an assignment algorithm at each layer and then calculating pixel-level similarities."}, {"title": "3.1. Architecture overview", "content": "Given a support image \\(I_s\\) and a query image \\(I_q\\), we first use a pre-trained feature extractor to extract feature maps at different layers. Let \\(E_s = \\{E_s^l \\in \\mathbb{R}^{h^l \\times w^l \\times c^l}\\}_{l=1}^L\\) and \\(E_q = \\{E_q^l \\in \\mathbb{R}^{h^l \\times w^l \\times c^l}\\}_{l=1}^L\\) denote the sets of feature maps for the support and query images respectively. Here, \\(h^l \\times w^l \\times c^l\\) represents the shape of the feature map at the l-th layer of the feature extractor. Then we calculate the layer-wise cross-correlation"}, {"title": "3.2. Layer-wise embedding module", "content": "Images should be embedded in a metric space before calculating the correlation score between image pairs as most metric-based methods do. Unlike previous methods that rely solely on the output of the final layer or merge multiple layers into one, our method isolates the feature maps of image pairs individually at each layer. Our approach utilizes ResNet18 [2] as our feature backbone. ResNet18 consists of an initial convolutional layer and 8 basic blocks, each producing a feature map of different dimensionalities, represented as \\(E^l \\in \\mathbb{R}^{h^l \\times w^l \\times c^l}\\), where l \u2208 {0,1,...,8} denotes the number of layers. We pre-train our feature backbone to accelerate the training process."}, {"title": "3.3. Semantic-pixel matching module", "content": "In this section, we describe the details of our semantic-pixel matching module. In the semantic-pixel matching module, our goal is to perform fine-grained matching based on the adjusted feature maps \\(E'_s\\) and \\(E'_q\\). We employ an optimal assignment algorithm to reassign pixels from the query image to the pixels of the support image in order to form the best pairing. Specifically, we construct a spatial mapping by defining a matching matrix \\(M^l\\) to represent the matching degree of each pixel pair. The matching degree \\(M_{s,i}^{q,j} \\in \\mathbb{R}^{h w \\times h w}\\) can be expressed as:\n\\begin{equation}\nE'_{s,i} = reshape(E'_s)\n\\end{equation}\n\\begin{equation}\nM_{s,i}^{q,j} = \\frac{E'_{q,j} E'_{s,i}}{\\|E'_{q,j}\\| \\|E'_{s,i}\\|}\n\\end{equation}\nwhere the reshape(\u00b7) operation changes \\(E^l \\in \\mathbb{R}^{h \\times w \\times c^l}\\) to \\(\\mathbb{R}^{h w \\times c^l}\\).\nWe utilize the Hungarian algorithm to find the optimal assignment between feature pairs from the support and query feature maps. The following algorithm describes the detailed steps to achieve this:"}, {"title": "Algorithm 1 Optimal Feature Matching via Hungarian Algorithm", "content": "1: Input: Matched degree matrix \\(M^l \\in \\mathbb{R}^{h w \\times h w}\\)\n2: Output: Indices of matched feature pairs (i, j)\n3: Compute the cost matrix \\(C^l = 1 - M^l\\) {Convert matching degree to cost}\n4: Initialize assignment vector \\(A \\in \\mathbb{R}^{h w}\\)\n5: Apply the Assignment algorithm:\n6: Step 1: Transform the cost matrix \\(C^l\\) if necessary (e.g., subtracting row minima)\n7: Step 2: Select the minimum cost assignment using the Hungarian algorithm:\n8: Let: A(i) denote the matched index for feature i\n9: for each row i in \\(C^l\\) do\n10:\nFind the column index j such that \\(C^l_{i,j}\\) is minimized\n11:\nAssign A(i) \u2190 j\n12: end for\n13: Step 3: Return indices (i, A(i)) for all i\n14: Output: Matched indices (i, A(i)) representing optimal pixel matches between support and query feature maps"}, {"title": "3.4. Learning objective", "content": "In our method, the score is the basis for the metric-based classifier's judgment, so we can get the metric-based loss \\(\\mathcal{L}_1\\):\n\\begin{equation}\n\\mathcal{L}_1 = -log\\frac{exp(Score(E^{(n)}_s, E^{(n)}_q))}{\\sum_{k=1}^{N \\times K} exp(Score(E^{(n)}_s, E^{(n)}_q))}\n\\end{equation}\nwhere \\(Score(\\cdot, \\cdot)\\) is the function that gets the final matching score from the feature maps set of the image pair. Notably, a query image has N\u00d7K different embeddings because there are N \u00d7 K support images in one task, We average K final matching score.\nFollowing RENet [4] and CAN [3], we define an enhanced classifier to enhance the classification accuracy. We refer to the loss produced by the enhanced classifier as \\(\\mathcal{L}_2\\):\n\\begin{equation}\n\\mathcal{L}_2 = -log\\frac{exp(w^T E^{(c)} + b)^{(c)}}{\\sum_{c' \\in C_{train}} exp(w^T E^{(c)} + b)^{(c')}}\n\\end{equation}\nwhere w and b are the weight and bias of a fully-connected layer. Therefore, the learning objective \\(\\mathcal{L}\\) combines two components, where \\(\\beta\\) is a hyper-parameter to balance these two components:\n\\begin{equation}\n\\mathcal{L} = \\beta \\cdot \\mathcal{L}_1 + \\mathcal{L}_2\n\\end{equation}"}, {"title": "4. Experiments", "content": ""}, {"title": "4.1. Datasets", "content": "We utilize the four most commonly used datasets in few-shot learning: miniImageNet, tieredImageNet, CUB-200-2011, and CIFAR-FS. Vinyals et al. created the miniImageNet [36] dataset by extracting a subset of images from the ImageNet [37] dataset, consisting of 100 classes with 600 images per class. The dataset is split into 64 classes for training, 16 for validation, and 20 for testing. tieredImageNet [38] includes 608 classes"}, {"title": "4.2. Implemention details", "content": "We adopted a ResNet18 backbone pre-trained on ImageNet. For LWE, we empirically selected the last two layers' outputs of backbone, i.e. l \u2208 {7,8}. Both outputs are resized to 3\u00d73 using adaptive pooling.\nIn \\(\\mathcal{L}\\), the hyperparameter \\(\\beta\\) was determined through grid search, resulting in values of 0.25, 0.25, 0.5, and 1.5 for Mini-ImageNet, TieredImageNet, CIFAR-FC, and CUB-200-2011, respectively. Regarding \u03b1 in Score, we considered that the backbone is pre-trained on ImageNet, with Mini-ImageNet and TieredImageNet being subsets. Introducing too many parameters may disrupt the inherent inductive bias of the backbone; therefore, we set \u03b1 to 0.25 for these two datasets, and for CIFAR-FC and CUB-200-2011, \u03b1 is set to 1. The temperature factor T is uniformly set to 5. For the N-way K-shot evaluation, we test 15 query samples for each class in an episode and report the average classification accuracy with 95% confidence intervals over 2,000 randomly sampled test episodes. Our model is trained on an NVIDIA RTX 4070 Ti for 30 epochs on the CUB-200-2011 dataset and 10 epochs on the other datasets, with an initial learning rate of 0.01. The learning rate decays by a factor of 0.05 at epochs 20, 24, 26, and 28 for CUB-200-2011, and at epochs 4, 6, and 8 for the others."}, {"title": "4.3. Comparison Methods", "content": "We conducted comparisons between LWFM-SPM and a diverse range of approaches, including Data augmentation-based [42], Parameter optimization-based [43, 44, 17, 45], Metric-based [46, 47, 48, 49, 50, 3, 51, 52, 53, 54, 55, 56, 4, 5], and Other methods [17, 18, 19]. Frequently used for benchmarking, these approaches have consistently demonstrated enduring performance over time.\nAmong these methods, MCNet [5] represents the best performance in metric-based approaches. However, its use of self-attention mechanism results in an excessive number of parameters and increased computational complexity."}, {"title": "4.4. Qualitative analysis", "content": "Tables 1,2,3 and 4 compare LWFM-SPM and various few-shot classification methods on four datasets. Notably, our method uses the same or smaller backbone compared to methods [42, 48, 19, 51, 5, 54, 43, 17, 55],"}, {"title": "4.5. Ablation studies", "content": "To validate the effectiveness of our proposed layer-wise embedding and semantic pixel matching, we conducted extensive ablation studies.\nFirst, we experimented with the number of selected layers for our layer-wise embedding. The ResNet18 backbone we used has eight basic blocks, and we labeled their outputs as [1, 2, 3, 4, 5, 6, 7, 8]. We conducted experiments using seven different combinations of these blocks on the miniImageNet and CIFAR-FS datasets. As shown in Table 6, we found that simply increasing the number of layers does not always lead to performance improvements. This is evident from the combination [12345678], which shows a slight improvement on miniImageNet but a significant drop on CIFAR-FS. Overall, the combination [----78] proved to be the best choice, consistently demonstrating excellent performance across different datasets and being more robust than other combinations.\nSecond, we experimented with the choice of assignment algorithm, comparing the Hungarian algorithm and the Nearest Neighbor algorithm, as shown in Table 7. It is evident that the Hungarian algorithm outperforms Nearest Neighbor. This is because the Hungarian algorithm considers global similarity, finding an optimal combination by minimizing the total global cost. In contrast, Nearest Neighbor operates on a local basis, selecting matches based on the nearest similarity at each point. While this local strategy can lead to quicker decisions, it often overlooks the broader context of the image pairs, leading to suboptimal global alignment. By considering the entire feature map, Hungarian matching ensures that the final assignment achieves the lowest possible cumulative cost, leading to more accurate similarity evaluations and improved overall performance."}, {"title": "5. Conclusion", "content": "In this paper, we proposed the Layer-wise Feature Metric of Semantic-Pixel Matching (LWFM-SPM) to address key challenges in few-shot learning. Our method efficiently integrates multi-level semantic features"}]}