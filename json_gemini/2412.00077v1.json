{"title": "Selfish Evolution: Making Discoveries in Extreme Label Noise with the Help of Overfitting Dynamics", "authors": ["Nima Sedaghat", "Tanawan Chatchadanoraset", "Colin Orion Chandler", "Ashish Mahabal", "Maryam Eslami"], "abstract": "Motivated by the scarcity of proper labels in an astrophysical application, we have developed a novel technique, called Selfish Evolution, which allows for the detection and correction of corrupted labels in a weakly supervised fashion. Unlike methods based on early stopping, we let the model train on the noisy dataset. Only then do we intervene and allow the model to overfit to individual samples. The \u201cevolution\" of the model during this process reveals patterns with enough information about the noisiness of the label, as well as its correct version. We train a secondary network on these spatiotemporal \u201cevolution cubes\u201d to correct potentially corrupted labels. We incorporate the technique in a closed-loop fashion, allowing for automatic convergence towards a mostly clean dataset, without presumptions about the state of the network in which we intervene. We evaluate on the main task of the Supernova-hunting dataset but also demonstrate efficiency on the more standard MNIST dataset.", "sections": [{"title": "1. Introduction", "content": "Deep learning and computer vision techniques have made significant inroads in various domains of science, including astronomy, where they are used to enhance data analysis and discovery processes [6, 7, 30]. In the field of astronomy, one prominent application is the detection of celestial phenomena such as supernovae. By leveraging deep learning models, astronomers can analyze vast amounts of astronomical data efficiently and accurately, facilitating the identification of these explosive events. However, coming up with high-quality ground truth in the target, real domain, is extremely more difficult than typical earthly vision applications.\nTackling this issue is of high importance, as the scarcity of good labels not only impedes the model's ability to learn and generalize well but also the missed samples in the training set are potentially interesting objects. Specifically, a missed supernova in the training set, apart from contaminating the training process, may mean a missed, important discovery.\nThe state-of-the-art in the task of supernova detection is an image-generating approach called TransiNet-[29]. The method generates images in which it tries to \"paint\" the detections on a blank canvas. In practical scenarios, there exists a high number of undetected true objects in the ground truth data, which substantially hinders the training process-[22, 26-28]. Due to the pixel-wise nature of the method, each missed object is virtually more than a single missed object: each pixel belonging to the missed object contributes to training the network on wrong labels.\nIn this work, we propose a method for detecting and recovering these missed discoveries. We cast the problem as one of label noise, where the noise presents itself as a false negative: a supernova that has occurred in the past but has not been discovered yet. We extract subtle information out of the model dynamics while it is overfitting to each sample to get hints about the noisiness of the samples.\nLabel noise has a wide and well-studied body of literature-[32, 35]. This aspect of machine learning re-search emphasizes the impact of incorrect labels on model performance, highlighting the need for robust techniques to mitigate its effects. Most existing studies often focus on developing algorithms that can withstand noisy labels, whether it is by dropping bad labels or weighting good labels-[11] and [3]. As a result, a new sub-field under the name Learning with Noisy Labels, LNL, has emerged. The field focuses on the development of models capable of effectively learning from datasets contaminated with label noise.\nResearch in the area of LNL can be broadly categorized into two main approaches: robust algorithms and noise detection strategies. Robust algorithms are designed to enhance the resilience of the learning process without directly addressing the noise in individual data instances. These methods incorporate specific mechanisms to ensure that neural networks can be trained effectively despite the presence of label noise [10]. Robust algorithms for LNL do not focus on specific noisy instances but rather aim to design specific modules or mechanisms that allow networks to be well-trained despite the presence of label noise. These algorithms often employ techniques such as regularization, loss correction [24], and robust optimization to mitigate the effects of noise on the learning process [37].\nOn the other hand, noise detection strategies aim at identifying and mitigating the impact of noisy data, thereby facilitating the training of more accurate models [5]. Noise detection methods specifically target the erroneous labels within the dataset. These methods typically involve two stages: noise identification and data cleansing or reweighting. By accurately identifying noisy instances, these strategies enable the exclusion or correction of such data, thereby improving the overall quality of the training dataset [32].\nWe, on the contrary, focus on the correction of noisy labels after their detection. This is mainly due to the scientific application behind the idea, where each missed object is a potential discovery and valuable.\nFrom another perspective, most of the existing methods focus on typical classification tasks and benchmarks, where the labels (and their respective noise) are of a categorical nature. Das and Sanghavi [8], dos Santos and Izbicki [9] discuss linear regression in the context of Self Distillation, with a look at label noise. However, they do not cover more sophisticated models and/or non-categorical outputs. Ponti et al. [25] focus on tabular data and use training dynamics of Gradient Boosting Decision Trees. Our application involves image generation (pixel-level regression) and is thus substantially different. We also test and show results on typical classification benchmarks and discuss how the original task is different, calling for a relatively more sophisticated technique.\nA group of methods that rely on the specific state of the model throughout different stages of training, such as early stopping-[20]. Arpit et al. [4] suggest that DNNs first learn simple patterns and subsequently memorize noisy data. Liu et al. [21] suggest that deep neural networks, when trained on noisy labels, initially fit the data with clean labels during an \"early learning\" phase and later begin to memorize the data with incorrect labels.\nIn contrast, we are network-state agnostic. Our method is, by design, able to learn the overfitting profiles, regardless of the stage at which we have stopped the training. This methodological choice is inspired by the fact that, in many real-world scenarios, one is not training a network from scratch, but fine-tuning a network already quite \"familiar\" with the task at hand. This also allows for the utilization of the technique in a closed-loop multi-cycle configuration, allowing the ecosystem to converge to the right answer.\nMany studies have exploited the training dynamics of the models to tackle label noise. K\u00f6hler et al. [17] detect noisy label data by analyzing the variations in predictive uncertainty distributions of a DNN between clean and noisy datasets. They use heuristically set rules to interpret the behavior of the curves, in their no-ground-truth setting. Jia et al. [13] explore training dynamics by training an LSTM, emphasizing the detection of label noise. While they highlight the idea of correction, they do not present a concrete correction algorithm.\nTanaka et al. [34] addresses the problem in the semi-supervised learning context, where one knows which data is labeled or not and only needs to assign pseudo-labels to unlabeled data. Zhuo et al. [38] address the problem of noisy labels in the context of domain adaptation, by sample selection and reweighting.\nMentorNet [14], Co-teaching [12], Co-teaching+ [36] all use dual network architectures in which the two networks interact with each other during the training. They essentially focus on the (dis)agreements of the losses of the two networks for implicit sample selection. None of these focuses on the correction of the corrupted labels. Shi et al. [31] study the application of label noise detection in pediatric heart transplantation and rare disease detection.\nDataset Cartography [33] uses training dynamics to characterize and diagnose datasets for natural language processing classification tasks. They leverage two main measures derived from training dynamics - confidence (mean probability of true label) and variability (standard deviation of true label probability) - to plot instances on a 2D map, revealing regions of easy-to-learn, hard-to-learn, and ambiguous examples. Their idea is quite close to the underlying concept of our method. However, our method does not need to capture the training dynamics of the network from scratch and starts capturing \u201cevolution history\" off a pre-trained state. Moreover, we do not stop at the detection of the label noise but emphasize correcting each of the erroneous labels as valuable elements of our special application."}, {"title": "2. Problem formulation", "content": "Assume our dataset consists of two parts: a small 'gold subset' with clean labels, G, and a larger main subset, D, with possibly noised labels. For problem formulation, we proceed with D alone and come back to G for elaboration of the method in the next section.\nLet D = {(xi, \u1ef9i)}1 denote the dataset, where xi \u2208 Rd is the i-th input feature vector and \u1ef9 \u2208 Y is the corresponding noisy label. In this paper, the label space Y is kept as flexible as possible. \u011di is a sample from the noisy labels, which may not reflect the true underlying labels y.\nLabel noise is often represented by P(\u1ef9i | y): the probability of observing \u1ef9 given the true label y. A common model, in typical classification tasks, is the symmetric noise model where\n$P(\\tilde{y}_{i} = y | y) = 1 - \\eta$\nand\n$P(\\tilde{y}_{i} \\neq y | y) = \\frac{\\eta}{C - 1} \\forall \\tilde{y}_{i} (\\tilde{y}_{i} \\neq y)$"}, {"title": "3. Selfish Evolution: the method", "content": "Step 1 - Initial training: The model f (x; 0) is trained on the main, noisy dataset D for an arbitrary number of epochs:\n$\\theta = arg \\underset{\\theta}{min} L(\\theta; x, \\tilde{y})$.\nLet us refer to the intermittent state of the network after the interruption as $\\theta$.\nStep 2 - Overfitting and evolution: In this step, we resume training the model off $\\theta$, but continue training only on an individual sample to overfit. Mathematically, this can be expressed as:\n$\\theta = arg \\underset{\\theta}{min} L(\\theta; x_{i}, \\tilde{y}_{i})$\nwhich at each epoch (which consists of a single iteration), can be stated as:\n$\\theta^{t} = update(\\theta^{t-1}, x_{i}, \\tilde{y}_{i}), t = 1,...,T,$\n$y^{t} = f(x_{i};\\theta^{t}), t = 1,...,T$\nwhere T is the number of overfitting steps (epochs), and $\\theta^{t}$ represents the model parameters at step t for sample i. This allows us to capture the \u201cevolution\u201d dynamics of the model:\n$E_{i} = {y^{t}}_{t=1}^{T}$\nIn our specific application where the labels are image-like tensors, Ei are spatiotemporal, 3-D tensors and so are called \"evolution cubes\".\nWe repeat the same overfitting process of this step for each of the samples in the subset at hand, indexed by i. For each sample, we restart off the $\\theta$ state.\nAs we will show in the experiments, one can use a more generalized version of this step, where the overfitting target is not just a single sample, but a whole mini-batch, or a combination of them."}, {"title": "3.1. Closed Loop Correction", "content": "The trained secondary network, \u201cEvolution-to-Label\", maps the cubes, generated based on the current version of the labels, to a new set of labels-hopefully cleaner. We can optionally iterate the process in a closed-loop fashion, aiming for a mostly clean dataset:\n$\\tilde{y}^{(k+1)} = g(E_{i}; \\phi^{(k)})$, \nwhere k is the iteration index. We use this iteration scheme in some of the simpler experiments of the next section, where each cycle is referred to as a \u201csuper-epoch\u201d."}, {"title": "4. Experiments", "content": "4.1. Supernova detection\nImage-based supernova hunting is a pivotal task in astronomy. The de-facto way is to collect images of the same region of the sky, register, and co-add (average) them to get a template image. Then upon capturing each new image, a subtraction is performed, followed by noise removal, detection, etc.\nSedaghat and Mahabal [29] redefine the task as an image generation task in which the output contains only the image of the supernova and nothing else - Fig. 3. ML-wise, it is close to the task of segmentation, in the sense that we essentially assign the value zero to pixels corresponding to unwanted objects. However, it is not just segmentation in the sense that the pixel values are not typical categorical values, but rather continuous scalars. It is also not a simple pixel-level regression task, in the sense that spatial coherence is important, especially in the presence of a supernova, where the shape needs to be preserved. The pixel values, at least in the original implementation of the method, represent the exact 'flux' values of an ideally subtracted supernova. All these make it a spatiotemporal regression task. Something not often considered in typical label-noise research. In the below experiments, for the sake of comparability, we normalize all the target amplitudes, such that the idea output becomes a mere localization heat map.\n4.1.1. Data\nWe use data from the Dark Energy Science Collaboration (DESC) DC2 dataset: a simulated dataset covering a wide range of astrophysical phenomena with realistic simulations of the sky, containing billions of galaxies over a large area of the sky [1, 2]. Our dataset consists of 3712 cutouts of size 256 \u00d7 256 randomly centered around 373 unique supernovae. The relatively low number of images is, in part, chosen on purpose to emulate the challenging conditions of lack of labeled data in real-world astrophysical applications.\nWe carefully split the dataset to prevent any object from leaking across subsets, resulting in 3205 train images and 507 gold samples. We also created several label-noised versions of the ground truth images: 20%, 50%, and 100% noise."}, {"title": "4.1.2. Initial training", "content": "We use the exact same non-probabilistic, encoder-decoder architecture, as introduced in the original work of Sedaghat and Mahabal [29], to train the model on our training subset. We use a solver based on the ADAM optimizer [16] and with an initial learning rate of le - 4."}, {"title": "4.1.3. Evolution", "content": "We use a mixed overfitting strategy to induce a race condition in the model dynamics: the model is pushed to overfit to a single clean mini-batch for the first half of the process. Then we switch the overfitting target to the single target label. The implementation consists of the below steps:\n\u2022 Initialize the main model with pre-trained weights.\n\u2022 Pick one sample from the dataset (depending on the stage we are in) the 'Selfish Sample' hereafter.\n\u2022 Pick a random batch from the clean dataset-the 'Support Batch' hereafter.\n\u2022 Initialize an empty cube.\n\u2022 Continue training the model with the support batch, for a predefined number of epochs.\n\u2022 Infer on the Selfish Sample at the end of each epoch and append the output to the evolution cube.\n\u2022 Switch to training of the model with the Selfish Sample for a predefined number of epochs.\n\u2022 Infer on the Selfish Sample at the end of each epoch and append the output to the evolution cube.\n\u2022 Start over includes reinitialization of the model with the pre-trained weights.\nThe last item is particularly important, since we want to capture comparable dynamics for each of the samples in the dataset, off of a fixed model state. Also note that throughout the evolution process, regardless of which half we are in, there is only a single mini-batch involved. Therefore each epoch corresponds to a single iteration. When we are using the support batch, though, we need one extra forward pass with the Selfish Sample.\nWe use an ADAM solver [16] with the parameters mentioned in Tab. 2. The subtle difference between the two sections is due to the different behaviors we expect from the network: during tuning with the support batch, we want the gradients not to deviate too much from their last state, with the hope that in case of a noisy label, the model can lean towards the clean answer. In the second half, though, we want to allow the model to try to overfit to the 'Selfish Sample'-[15, 23].\nFor this experiment, we set the number of evolution epochs, Ne, to 60."}, {"title": "4.1.4. Denoising", "content": "For denoising, we do not separate the tasks of noise detection and correction. These steps take place implicitly and in conjunction with each other when we train a secondary model that directly maps the evolution cubes to clean labels; we refer to this model as the Evolution-to-Label mapper, or E2L in short.\nPractically speaking, although the input data to E2L is a sequence in nature, it also matches the input to the main model - it is only deeper. Therefore, given that the expected output is exactly of the same type, and to keep homogeneity in our implementations, we use the same architecture for E2L- noting that a sequence-based model, like an RNN, may well replace our implementation.\nMoreover, since the number of gold samples, whose cubes are used for training of E2L, is too small, we use a 'thinner' version of TransiNet with only half of the output channels in each hidden layer to avoid overfitting. We also use other regular measures such as image flipping (with a 50% chance in each image dimension) and shifting (with a uniform probability between 0 and 20 pixels in each image dimension) during training.\nE2L is trained on the evolution cubes obtained from the gold dataset. It is indeed trained on a combination of two versions of it: cubes from the clean version, and cubes from a 100% noised version. This way we try to maximize the types of the evolutions E2L sees, even those that do not need to be corrected!"}, {"title": "4.1.5. Results", "content": "We pass the evolution cubes through the E2L network and infer estimates for the corrected labels. We define and compute multiple evaluation metrics:\n\u2022 a soft similarity metric: simple cosine distance between clean and denoised,\n\u2022 a hard similarity metric: thresholded version of the soft similarity metric.\n\u2022 Discovery rate/count: the number of recovered objects (above threshold).\nAs stated throughout the paper, our main objective is label noise correction. Therefore, unlike many studies, we do not evaluate the performance on a clean validation set, but directly on the training set. Tab. 1 summarizes the quantitative results. We ran several experiments with various noise levels and hyperparameters, but only bring the three main representative ones in the table. \u2018Baseline' is the output of the primary network, directly trained on the noised dataset-no correction. The setup designated by '500' is one in which we set extremely hard conditions by only using the first 500 samples from the training set. In contrast, in the 'full' version, we used all the training samples. We recovered 817 supernovae that were previously missed!\nFigures 4 and 5 depict how the evolution cube and the corrected label look like in an exemplar case."}, {"title": "4.2. Standard image classification\u2014MNIST", "content": "We test our method on MNIST [19], mainly to illustrate the underlying mechanisms of our proposed method, in a more manageable application. We prepare three datasets by modifying the labels of the MNIST dataset: (1) the clean dataset identical to the original MNIST dataset, (2) the noised dataset whose 80% of its labels have been randomly changed, and (3) the noised dataset whose all of the labels have been randomly altered. We then separate the 60,000 images of the train MNIST dataset into two groups, the first 51,000 being the training set and the last 9,000 images being the gold set.\nWe use the train set of the partially noised dataset to train the primary network, after which we feed each image in the gold set into the model individually. In other words, we continue training the trained primary model using only a single image from the gold set. For each forward pass in a single iteration, we record the output. At the end of the training, we obtain an evolution history, i.e., a temporal strip (i.e., cube) of the likelihood of the prediction over iterations. We then reset the primary model to its original state before we fed another image from the gold set. The procedure is repeated for every image in the set. Thus, we obtain another dataset consisting of evolution histories corresponding to each image in the gold set. In this step, this procedure is performed for (1) the gold clean subset, and (2) the gold noisy subset. Thus, we obtained two sets of evolution histories.\nIn Figure 6, we can see the class probability corresponding to the noised label increases over the iterations. For example, the image index 46174 has a clean label of \"7\" and a noised label of \u201c5.\u201d Over the iterations, the model predicts that the image is \u201c5\u201d as we assigned its noised label to be \"5\" although it initially predicted that \u201c2\u201d is most likely in the first iteration.\nThe gold evolution histories are combined and fed into the secondary network (E2L). Instead of images and their corresponding labels, the dataset is the evolution history, and the target is the clean label of the original image of the evolution history. The gold clean evolution histories can be fed into the model directly. However, in gold noisy evolution histories, the noised labels were corrected before being fed into the model.\nAfter training the E2L model, we evolved the train subset of the MNIST train set (i.e., the 51,000 images with partially noised labels) and obtained their evolution histories. Then, we fed these train subset evolution histories into the trained E2L model. The output of this stage would be used to update the original noised dataset from the first step.\nThe two models we utilized in this MNIST experiment are LeNet[19]. This LeNet model consists of 2 CONV-RELU-POOL layers, 2 fully connected layers, and one softmax.\nThe results on MNIST are shown in Table 3. We ran experiments on 50% and 80% noised datasets. The results consist of 10-super-epoch runs and 1-super-epoch runs in comparison with baselines. Our baseline is the performance of the primary model itself. Additionally, we also include the performance of the Co-teaching algorithm for comparison purposes. Note though that this method is originally evaluated on a clean validation set. For us to be able to make a fair comparison, we ran the noisy training set through the final version of the trained model. Even though Co-teaching uses a much larger network architecture, we still perform on par."}, {"title": "5. Discussion and future work", "content": "We introduced the novel idea of detecting and correcting noisy labels based on overfitting dynamics. Apart from its novelty, the proposed method helped us recover (discover) more than fifty percent of the missed supernovae in an exemplar dataset, which is beyond significant in the field of astronomy. We make the source code and the supernova dataset available to the public upon acceptance of the paper. Furthermore, the method has the potential for utilization in domain-adaptation scenarios: a dataset from another domain with all-blank labels is a perfect fit for the algorithm. Although we were focused on the specific task, we showcased the efficiency of the method on the rather typical classification task. We showed that the mere use of the 'Selfish' part of the evolution suffices in the case of this simple task. We bring the results of the same experiments on the CIFAR [18] dataset in the supplementary material."}]}