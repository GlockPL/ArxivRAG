{"title": "Real-time Calibration Model for Low-cost Sensor in Fine-grained Time series", "authors": ["Seokho Ahn", "Hyungjin Kim", "Sungbok Shin", "Young-Duk Seo"], "abstract": "Precise measurements from sensors are crucial, but data is usually collected from low-cost, low-tech systems, which are often inaccurate. Thus, they require further calibrations. To that end, we first identify three requirements for effective calibration under practical low-tech sensor conditions. Based on the requirements, we develop a model called TESLA, Transformer for effective sensor calibration utilizing logarithmic-binned attention. TESLA uses a high-performance deep learning model, Transformers, to calibrate and capture non-linear components. At its core, it employs logarithmic binning to minimize attention complexity. TESLA achieves consistent real-time calibration, even with longer sequences and finer-grained time series in hardware-constrained systems. Experiments show that TESLA outperforms existing novel deep learning and newly crafted linear models in accuracy, calibration speed, and energy efficiency.", "sections": [{"title": "1 Introduction", "content": "Externalizing data latent in our world (Elmqvist 2023) can increase our awareness of previously unknown situations. For example, air pollution is a pervasive issue often overlooked due to its invisibility, and increased awareness can help us avoid potential dangers. Sensors from various IoT devices are used to capture real-time information from our surroundings. To take well-informed, suitable actions about our environments, it is integral to obtain accurate data from sensors. But oftentimes, these sensors exist in the form of low-spec computing devices, and these devices are sometimes not accurate (Ray 2022). To address this matter, there have been attempts to improve the quality of data coming from these low-tech devices using na\u00efve linear- and machine learning-based calibration methods (Concas et al. 2021; Aula et al. 2022; Villanueva et al. 2023).\nWe identify three key requirements that must be addressed to develop an effective, and practical calibration model: (1) handling fine-grained sensor type, (2) ensuring consistency in real-time calibration, and (3) accommodating hardware constraints (Section 3). Recent research has utilized time series prediction for calibrating low-cost sensors, but practical IoT systems face limitations in their effective use. Researchers have adopted time series prediction methods for low-cost sensor calibration (Zhang et al. 2023; Ahn et al. 2024; Narayana et al. 2024) as both rely on similar time series regression models (Narayana et al. 2024; Toner and Darlow 2024). This, together with deep learning and linear-based approaches, has led to improved calibration accuracy, but there is a tradeoff an improvement in one factor leads to a setback in others (Zhang et al. 2023; Ahn et al. 2024; Narayana et al. 2024). Addressing all three of the factors mentioned above in tandem is not a trivial issue.\nTo bridge this research gap, we propose TESLA (Transformer for effective sensor calibration utilizing logarithmic-binned attention) to address all of these challenges for IoT systems. TESLA reduces the attention bottleneck in transformers through logarithmic binning (Section 4.3), which couples more past tokens while retaining recent ones in a log scale. TESLA also employs multi-view embedding (Section 4.2) and feature-wise aggregation (Section 4.4) to preserve both local and global time series patterns, using only a single sensor. TESLA operates as quickly as linear-based models and can be integrated into low-tech systems, offering higher accuracy than deep learning-based models to balance the tradeoffs. Experimental results demonstrate that TESLA successfully achieves this balance, efficiently managing calibration speed, energy usage, and accuracy.\nTo sum up, our contributions are:\n\u2022 We identify three challenges that have to be addressed to achieve accuracy on par with high-quality sensors within practical IoT systems.\n\u2022 We propose a model called TESLA to address all of these challenges for low-cost sensor calibration.\n\u2022 Experiments with real-world benchmarks show that TESLA outperforms the baseline deep learning and newly designed linear models in most cases."}, {"title": "2 Related Works", "content": "We present the related work from two perspectives: low-cost sensor calibration and short-term time series prediction."}, {"title": "2.1 Low-cost Sensor Calibration", "content": "Existing works on low-cost sensors tackle specific challenges, but their efficacy is limited as performance improvements come with setbacks. We present these calibration trade-offs from two groups: (1) Machine learning-based and statistical models, and (2) deep learning-based models.\nVarious machine learning-based and statistical approaches such as linear regression, random forests, and ARIMA-based models have been used to calibrate low-cost sensors (Concas et al. 2021; Aula et al. 2022; Villanueva et al. 2023). In particular, linear regression has been widely used due to its simplicity, but it has often struggled to capture nonlinear trends in time series (Concas et al. 2021; Patton et al. 2022).\nRecent advances in deep learning have introduced various data-driven calibration methods, such as long short-term memory (LSTM) (Hochreiter and Schmidhuber 1997)-based (Nath et al. 2021; Ahn et al. 2024; Apostolopoulos, Fouskas, and Pandis 2023), convolutional neural networks (CNNs) (Krizhevsky, Sutskever, and Hinton 2012)-based (Ali et al. 2023), or Transformer (Vaswani et al. 2017)-based methods (Narayana et al. 2024; Ahn et al. 2024). However, training these models usually demands significant computing power, posing challenges for practical use in IoT-controlled systems (Nath et al. 2021). For example, the deployment of Transformers in everyday home devices is limited due to their high resource demands. This highlights a significant gap in the practical application of advanced models in resource-constrained environments.\nOur contributions. TESLA meets all three requirements: it achieves high accuracy with deep learning methods and fastens inference speeds by partially implementing linear methods, whereas existing works mainly address one/two of the three issues, at the expense of other requirements."}, {"title": "2.2 Short-term Time Series Forecasting", "content": "Even though they handle similar tasks, time series forecasting models can not be used directly for calibration, as they do not meet the needs of practical calibration models. Here, we describe two types of forecasters: (1) Transformer-based and (2) linear-based forecasters.\nThe effectiveness of Transformers has been questioned by the advent of linear forecasters (Zeng et al. 2023), but recent models like PatchTST (Nie et al. 2023) and iTransformer (Liu et al. 2024) have demonstrated that Transformers can effectively capture the time series patterns when timely used. Despite these advances, the complexity of Transformer-based models still poses challenges for practical IoT systems. Although iTransformer (Liu et al. 2024) is the most practical option, calibrating it with a single sensor is ineffective as it is specifically designed for multivariate time series.\nLinear forecasters are mainly advantageous for their computational efficiency and low energy use. This makes them ideal for IoT systems. However, these models have not yet addressed two critical issues when applied as calibration models: (i) Data collected from various sensors may be inaccurate due to its non-linear characteristics, which are more complex than in time series prediction (Concas et al. 2021; Patton et al. 2022); (ii) Their ability to handle large datasets in practical applications remains unproven due to the small size of the parameters. These limitations must be resolved for successful implementation in practical IoT systems.\nOur contributions. In contrast to many Transformer-based models, TESLA is tailored for fast and efficient calibration of a single time series, typical for most low-cost sensors. Furthermore, TESLA merges the strengths of both forecasters to achieve high speed (comparable to linear models) and high accuracy with limited resources."}, {"title": "3 Preliminaries", "content": "We define fine-grained time series and sensor calibration model. We then discuss additional requirements when applying sensor calibration models to real-world scenarios."}, {"title": "3.1 Fine-grained Time Series", "content": "We first define the concept of fine-grained time series.\nDefinition 1 (Fine-grained time series). Consider a sensor X as a function $X : \\mathcal{T} \\rightarrow \\mathbb{R}^+$, where $\\mathcal{T}$ is a discrete set of measurement times. Then $x_i = X(t_i)$ represents the $i$th sensor reading at time $t_i \\in \\mathcal{T}$. Given a window size $N$, an $i$th fine-grained time series $S_i$ generated by sensor $X$ is a sequence $S_i = (x_{i-N+1},..., x_i)$ for $i \\geq N$, under the condition that the granularity $\\mu_X = \\min_{i>n} \\{ t_i - t_{i-1} \\}$ of the sensor $X$ is sufficiently small. For notational convenience, we regard the time series $S_i$ as a fine-grained time series unless otherwise noted.\nAfter observing various time series benchmarks (e.g., ETT, traffic, weather, etc.), we have noted a growing demand for finer time series granularity, down to minute- or second-level intervals. Calibration, in particular, demands finer granularity than most other forecasting tasks. Air quality sensors equipped in home appliances must reflect dynamic, ad hoc environmental changes caused by several activities such as cooking, exhaust emissions, or smoke. For these applications, it is crucial to provide quick and accurate calibration results based on the recent sensor readings. Our research thus focuses on these fine-grained time series."}, {"title": "3.2 Sensor Calibration Model", "content": "Here too, we start by defining sensor calibration model.\nDefinition 2 (Sensor calibration model). Consider two sensors performing the same task X and y, where sensor X is less accurate than y. Then a sensor calibration model $F_N(*|\\Theta_{opt})$ for sensor X is a deep learning model, where the learnable parameters $\\Theta_{opt}$ of the model $F_N$ is optimized by the following formula with an objective function $\\mathcal{L}$:\n$\\Theta_{opt} = \\arg \\min_{\\Theta \\in \\Omega} \\sum_{i \\in \\mathcal{I}_{train}} \\mathcal{L} (F_N(S_i|\\Theta), Y_i)$ (1)"}, {"title": "3.3 Model Hardware Requirements", "content": "This section describes three key factors that are required to develop an effective consistent, real-time calibration model for practical IoT scenarios:\n\u2022 Accuracy. Accurate data reading from sensors is crucial. Commonly used evaluation metrics include mean absolute error (MAE) and root mean squared error (RMSE) to measure this accuracy. However, in practical IoT systems, real-time performance matters, and constraints on IoT hardware may prevent the deployment of high-performance models.\n\u2022 Latency. For finer-grained time series, calibration must be conducted swiftly, within smaller intervals. We can evaluate this latency using speed-related metrics, such as inference speed, floating point operations (FLOPS), or throughput. It is not necessary to choose the fastest calibration model; instead, the ideal choice would be a model that achieves the optimal performance given the situation.\n\u2022 Hardware resources. Considering hardware resources is crucial when determining the applicability of a calibration model. This involves evaluating model parameters to estimate hardware fixed memory requirements, memory footprints to estimate variable memory for space complexity, and calculating FLOPS to determine time complexity.\nIn summary, evaluating the superiority of a calibration model requires considering both its accuracy and the additional factors we discussed. The ideal calibration model should exhibit the high accuracy of a deep learning model while maintaining the high speed and low energy consumption of linear models. In the next section, we propose TESLA, which aims to achieve this ultimate goal and will be detailed further. Then, in Section 5, we carefully select evaluation metrics that account for all these factors."}, {"title": "4 Sensor Calibration Model: TESLA", "content": "This section describes our Transformer architecture for time series calibration for practical IoT systems, named TESLA (Transformer for effective sensor calibration utilizing logarithmic-binned attention)."}, {"title": "4.1 Model Overview", "content": "Figure 1 shows the overall structure of TESLA. From the perspective of a black box model, TESLA takes the time series $S_i = (x_{i-N+1},..., x_i)$ as input and finally returns the calibration result $\\hat{x}_i$ as defined in the calibration model described in Section 3.2. Our technical contribution lies in designing a novel architecture that meets the three hardware requirements mentioned in Section 3.3, while still maintaining high performance through the use of Transformers.\nTo begin with, TESLA uses multi-view embedding methods to input tokens to model both global and local features (Section 4.2). This strategy effectively captures changes in fine-grained time series values while reducing the number of tokens. Second, we propose a novel method called logarithmic binning, aggregating a number of past tokens while preserving the detail of recent ones on a logarithmic scale (Section 4.3). Logarithmic binning achieves significant $\\mathcal{O}(log^2 N)$ self-attention complexity. It effectively alleviates the bottleneck problem of attention operations, making them applicable to IoT environments. Finally, we replace the token-wise feedforward network with a linear layer for feature-wise aggregation, which significantly reduces the number of learnable parameters and the computational power required (Section 4.4). Detailed explanations are described in subsequent subsections."}, {"title": "4.2 Multi-view Embedding", "content": "We design an effective embedding method, even in the use of a single low-cost sensor. Our method is designed to consider multi-view data using simpler techniques, despite using only a univariate time series from a single sensor. Relying solely on local token-wise embeddings, which are typical in Transformers, is ineffective for calibration because the receptive field is not large enough to effectively represent the time series. Hence, we add a global representation inspired by Liu et al. to preserve both local and global features. This approach supplements implicit, local positional information within the global representation, removing the need for extra positional or temporal embeddings.\nFormally, we first omit the index $i$ and re-index the series as $S = (x_1,...,x_n) \\in \\mathbb{R}^{1 \\times N}$ (i.e., we shift the index by $N-i$) for notational convenience. Then the input representation of TESLA for a time series $S$ is defined as $E = (e_1,..., e_N)^\\top \\in \\mathbb{R}^{N \\times d}$, where:\n$e_i = x_i W_{local} + \\overline{S}W_{global}$ (2)\nis a d-dimensional column vector for $i \\in [1, N]$. $W_{local} \\in \\mathbb{R}^{1 \\times d}$ and $W_{global} \\in \\mathbb{R}^{N \\times d}$ denote local and global learnable parameters, respectively."}, {"title": "4.3 Logarithmic Binned Attention", "content": "To alleviate the costly computation of Transformers, we deploy a core method called logarithmic binning. This reduces the number of tokens to approximately $log_2 N$. Then we apply multi-head attention to these reduced tokens, enabling more efficient and rapid computations.\nLogarithmic binning. We first define logarithmic binning as a collection of the mapping functions $\\{l_1,...,l_z\\}$ for $z = \\lfloor log_2 N\\rfloor$, where each function satisfies:\n$l_j: \\mathbb{R}^{d \\times (a_j-a_{j-1})} \\rightarrow \\mathbb{R}^{d \\times 1}$ (3)\nwhere $a_j = \\max \\{1, N - 2^{j-1} + 3 \\}$ for integer $j \\in [0, z]$.\nWe provide an illustrative example of logarithmic binning including $a_j$'s and $l_j$'s in Figure 2 for comprehensive understanding. Intuitively, logarithmic binning is a strategy that keeps the latest token while a series of past tokens are grouped in reverse temporal order on a logarithmic scale. Using logarithmic binning, the sequence length is reduced from N to nearly $log_2 N$, enabling cost-efficient attention complexity $\\mathcal{O}(log^2 N) = \\mathcal{O}(log^2 N)$. Furthermore, the recent trend is emphasized, since a large part of recently inputted information is kept in the bin. Emphasizing these trends helps to better understand the recent sensor dynamics in long, finer-grained time series, leading to more accurate calibration results.\nLogarithmic binned embedding. To reduce the number of tokens to reduce attention complexity, we then create an embedding by applying logarithmic binning to input embedding. Using the previous collection of the mapping functions $\\{l_1,..., l_z\\}$, we define the logarithmic binned embedding of $E$ as $\\overline{E} = (\\overline{e_1},..., \\overline{e_z})^\\top \\in \\mathbb{R}^{\\tilde{z} \\times d}$, which is calculated by:\n$\\overline{e_j} = l_j ((e_{a_{j-1}},...,e_{a_j - 1})) .$ (4)\nThe most straightforward mapping function we can think of is the average function, which simply applies an average to each vector for binning. However, this method not only is incapable of providing learning opportunities but also loses information. Hence, we practically select these mapping functions as a set of learnable linear functions (act as learnable weighted average functions) to minimize the information loss while keeping it simple:\n$\\overline{e_j} = (e_{a_{j-1}},..., e_{a_j - 1}) W_j$ (5)\nwhere $W_j \\in \\mathbb{R}^{a_j-a_{j-1}) \\times 1}$ for $j \\in [1, z]$ are learnable parameters. This approach is capable of increasing the number of learnable parameters while using only approximately N additional parameters. This parameter efficiency can enable the model to operate effectively in practical IoT systems.\nLogarithmic binned attention. Finally, we perform a multi-head attention operation using only the reduced embedding of tokens to capture their interactions. Using the logarithmic binned embedding $\\overline{E}$, we construct the query, key, and value as $Q = \\overline{E}W_q$, $K = \\overline{E}W_k$, and $V = \\overline{E}W_v$ respectively, where $W_q, W_k,$ and $W_v \\in \\mathbb{R}^{d \\times d}$ are learnable parameters. Then the logarithmic binned self-attention is defined by:\n$Y = Softmax (\\frac{QK^\\top}{\\sqrt{d}})V.$ (6)\nNote that $QK^\\top$ has a dimension $z \\times z$, resulting in the computational complexity of the logarithmic binned attention being $\\mathcal{O}(x^2) = \\mathcal{O}(log^2 N)$. We omitted multi-head concepts in the formulas since they are identical to those presented in a vanilla Transformer."}, {"title": "4.4 Feature-wise Aggregation", "content": "Networks that deploy Transformers typically implement token-wise processing with large hidden layers, which can pose computational overload on constrained hardware devices. To address this, we get motivation from previous studies (Zeng et al. 2023; Liu et al. 2024). We replace the token-wise feed-forward network, which incorporates a dual linear layer, with a single feature-wise linear layer. This modification more efficiently captures time series dynamics by repeating calculations only across the number of features.\nGiven an attention output $Y \\in \\mathbb{R}^{z \\times d}$, the final prediction $\\hat{x}$ is calculated by:\n$\\hat{x} = (LayerNorm(Y)W_{agg1})^\\top W_{agg2}$ (7)\nwhere $W_{agg1} \\in \\mathbb{R}^{d \\times 1}$ serves as a feature-wise aggregator, and $W_{agg2} \\in \\mathbb{R}^{d \\times 1}$ is used to transform the final token embedding into the scala prediction."}, {"title": "5 Experiment Settings", "content": "Here, we first explain the datasets and training setup. Then, we describe our baselines, evaluation metrics, and implementation details.\nDatasets. Our experiment is based on a large-scale dataset suitable for calibration task (Van Poppel et al. 2023). This dataset includes sensor data collected from numerous sensors across three regions-Antwerp (Ant.), Oslo (Oslo), and Zagreb (Zag.), with three individual features-PM10, PM2.5, and PM1. Detailed descriptions of the dataset used in our experiment are shown in Appendix A.1.\nEvaluation setup. Our evaluation process assumes that we use multiple same types of sensors for training in a given space. Each sensors are uniquely identified by the name. We organize the sensors in alphabetical order: the second-to-last sensor is set as the validation set, and the last sensor as the test set. All remaining sensors are used for training. This configuration is repeated across different regions Ant., Oslo, and Zag. and features PM10, PM2.5, and PM1. A detailed evaluation setup is provided in Appendix A.2.\nBaselines. We carefully select widely used state-of-the-art techniques for various time series tasks to compare with our proposed method, TESLA. For linear methods, we choose Linear (Freedman 2009), NLinear (Zeng et al. 2023), and DLinear (Zeng et al. 2023), known for their fast inference speeds and outstanding performance in recent time series forecasting. For deep learning methods, we select Transformer (Vaswani et al. 2017), Informer (Zhou et al. 2021), PatchTST (Nie et al. 2023), and iTransformer (Liu et al. 2024), known for their high performance but are less recognized in IoT environments. We give detailed explanations for each baseline in Appendix A.3.\nEvaluation metrics. The factors mentioned in Section 3.3 must be considered when applying the calibration model to real-world scenarios. To comprehensively evaluate the model, we categorize the evaluation metrics into two groups: effectiveness and efficiency metrics.\nFor effectiveness, we measure accuracy using two widely adopted metrics in time series forecasting and calibration tasks: Root mean square error (RMSE) and mean absolute error (MAE). For efficiency, we assess computational and resource requirements to ensure feasibility in practical IoT applications with low-cost sensors. Key metrics include floating point operations (FLOPS), memory footprint, and the number of model parameters. Also, at the microcontroller level, inference speed and Flatbuffer size are considered to assess real-time applicability.\nImplementation. All experiments were conducted using a machine equipped with an AMD EPYC 7763 and an NVIDIA RTX A6000 Ada with TensorFlow 2.14, which supports conversion to TensorFlow Lite for Microcontrollers."}, {"title": "6 Experimental Results", "content": "This section summarizes the results of our work.\nAccuracy. We first compared calibration accuracy. The results are shown in Table 1. To sum up, overall, TESLA outperformed existing baselines in terms of RMSE and MAE. Transformers outperformed linear models. This contrasts with previous observations in time series forecasting. Among Transformer-based models, PatchTST and iTransformer demonstrated notable effectiveness in token compression for calibration tasks. NLinear demonstrated the least accuracy among all linear-based models, with no significant difference in accuracy between Linear and DLinear.\nAblation study. For ablation study, we made three key modifications and evaluated their impact. We described the changes in Table 2. To begin with, the logarithmic binning showed minimal information loss when converting tokens to binned tokens, with less performance decline compared to uniform interval binning. Second, adding global embedding significantly enhanced accuracy. Last, simplifying the feedforward network improved performance, boosted calibration speed, and lowered energy consumption.\nCalibration tradeoff. We analyzed RMSE, FLOPS, memory usage, and model parameter size to determine whether the model effectively achieves the desired balance (see Figure 3). Linear models are fast and lightweight but lack the accuracy needed for calibration tasks. Transformers generally outperform linear models in accuracy but are less efficient. While Transformer and Informer have high computational demands (e.g., memory footprint and FLOPS), PatchTST, iTransformer, and TESLA balance efficiency and effectiveness, with TESLA achieving the highest accuracy without significant overhead across efficiency metrics."}, {"title": "7 Discussions and Limitations", "content": "We discuss the implications and limitations of our work.\nIneffective linear models. Newly-crafted linear models underperformed compared to Transformer-based models (Table 1), contrary to trends in forecasting tasks. This discrepancy stems from differences in dataset scale: calibration tasks involve larger datasets, favoring complex architectures with more parameters. Furthermore, the minimal accuracy gap between Linear and DLinear suggests that simple averaging is ineffective for calibration. These results highlight that while effective for forecasting, the linear approach may not be suitable for calibration tasks.\nEffectiveness of key modification in TESLA. Table 2 demonstrates the effectiveness of TESLA's three key modifications: (i) Building upon PatchTST's uniform patching approach, TESLA introduces logarithmic binning, which mitigates performance degradation by emphasizing recent values and adapts better to calibration tasks; (ii) Integrating global embedding, motivated by iTransformer, improves accuracy and extends its multivariate design to univariate scenarios; and (iii) Simplifying the feed-forward network to feature-wise linear, inspired by linear forecasters, highlights the importance of relationships between adjacent values and even achieves performance improvements in calibration tasks; In short, TESLA benefits from the strengths of both Transformers and linear modeling techniques.\nTESLA leads in effectiveness and efficiency. TESLA is the desideratum for addressing both efficiency and effectiveness in calibration tasks, balancing these aspects better than its counterparts (Figure 3). While PatchTST and iTransformer also achieve this balance, TESLA stands out as the most accurate model with no significant overhead across all efficiency metrics, making it the ideal choice for maximizing performance under resource constraints.\nMean trap phenomenon. The minimal gap between RMSE and MAE arises from the \"mean trap,\" where limited variation in time series data makes these metrics less sensitive to calibration differences. Even in high-distribution scenarios with significant calibration improvements (see Figure 5), these metrics often fail to capture the differences. This underscores the value of using a model like TESLA, where calibration improvements, though seemingly minor in metrics, can have significant real-world impacts.\nStatic experimental settings. Although we adopt standard settings used in calibration studies (Ahn et al. 2024; Narayana et al. 2024) and TESLA has demonstrated adaptability to IoT environments, the static nature of this approach requires recalibration or drift correction. This limitation can be alleviated as larger datasets become available. We further discuss this in Appendix A.4."}, {"title": "8 Conclusion", "content": "This study introduced TESLA, a Transformer-based calibration model for low-cost sensors in practical IoT systems. We first identified three challenges that must be addressed to adapt these models for calibration tasks. Then, TESLA addresses the challenges in the following manner: (i) Mitigate the attention bottleneck by employing logarithmic binning to reduce the number of tokens, (ii) Integrate multi-view embeddings, and (iii) Ensure fast processing by replacing feed-forward operations with linear layers. Results demonstrated that TESLA excelled in effectiveness and efficiency."}, {"title": "A Appendices", "content": ""}, {"title": "A.1 Dataset details", "content": "This section outlines the data characteristics and the criteria used to select subsets for the calibration task. As discussed in Section 3, applying benchmarks for time series forecasting to calibration poses several challenges. The SensEURCity dataset (Van Poppel et al. 2023), specifically designed for calibration tasks, provides a robust foundation for addressing these challenges.\nTo meet task-specific requirements, we select subsets that reflect diverse distributions of measurements for training to capture general measurement patterns. Specifically, we carefully selected: (i) data collected during the first collocation period for each region, as this period provides sensor readings from the same location and time, ensuring consistent calibration under uniform environmental conditions; and (ii) defining Plantower PMS5003 as a low-cost sensor and Alphasense OPC-N3 as a reference reading, categorized by price. The metadata for these subsets is shown in Table A1.\nTo maintain data quality, we excluded removed outliers or invalid values, and even discarded any sensor for which more than half of its readings were removed. In practical IoT scenarios, sensor data is collected in real-time, so no further refinement is applied beyond removing invalid data."}, {"title": "A.2 Detailed evaluation setup", "content": "This section describes the evaluation setup for the calibration task and the reasoning behind its configuration. Unlike forecasting tasks, where models predict future values based on past time series, the calibration task focuses on learning general patterns from the temporal behavior of each sensor to ensure robust performance across diverse conditions. To align with the objectives of calibration, our method modifies the train-validation-test split to focus on capturing general patterns from sensor data rather than temporal prediction. In the SensEURCity dataset, each sensor is identified by its unique ID and organized in alphabetical order within each region. The second-to-last sensor is used as the validation set, the last sensor as the test set, and all remaining sensors are used for training. This configuration ensures that the model learns patterns from diverse training sensors while maintaining consistent evaluation across regions."}, {"title": "A.3 Baselines details", "content": "This section introduces a detailed description of the baselines used in our experiment: (1) Linear-based models, and (2) Transformer-based models. Recent studies suggest that LSTM-based models are less commonly used in time series forecasting, as recent advancements have shifted focus to other architectures. Therefore, our experiment follows commonly used configurations found in recent research (Zeng et al. 2023; Nie et al. 2023; Liu et al. 2024) by adopting linear-based and Transformer-based models. The detailed descriptions of each baseline are as follows:\n\u2022 Linear (Freedman 2009): Linear straightforwardly uses weighted inputs, achieving moderate performance in time series prediction tasks.\n\u2022 NLinear (Zeng et al. 2023): NLinear involves normalizing the input time series data to its last value, which focuses the analysis on detailed dynamics.\n\u2022 DLinear (Zeng et al. 2023): DLinear explicitly separates the time series into trends and residuals and uses individual linear layers.\n\u2022 Transformer (Vaswani et al. 2017): Transformer uses a self-attention mechanism to weigh input data effectively, but it suffers from a quadratic computational bottleneck.\n\u2022 Informer (Zhou et al. 2021): Informer reduces the bottleneck by using selective queries, marking the first attempt to apply a Transformer architecture to a prediction task.\n\u2022 PatchTST (Nie et al. 2023): PatchTST enhances both effectiveness and efficiency by employing uniformly-sized patches as tokens, instead of using single values as tokens.\n\u2022 iTransformer (Liu et al. 2024): iTransformer extends the patch scope of PatchTST to its maximum, treating each sensor as an individual token.\nComparison to TESLA. TESLA combines the advantages of various time series forecasters for calibration tasks. First, unlike PatchTST, it emphasizes recent data more effectively by binning on a logarithmic scale. Additionally, while iTransformer is only effective with multiple sensors or multivariate time series, TESLA adapts to both local and global contexts, making it suitable for univariate applications. Finally, we adapted the token-wise feedforward neural network to a feature-wise linear layer to enhance the calibration speed comparable to that of linear forecasters."}, {"title": "A.4 More discussions", "content": "TESLA achieves fast inference speed and high calibration accuracy, but the limited availability of large-scale calibration datasets constrains its effectiveness. First, additional experiments using varied sensor data, such as temperature and humidity, are required to evaluate TESLA's performance in more diverse scenarios. Second, the reliability of the reference readings remains a concern, as the high-cost sensor used in this study may not provide sufficient precision. Future research should explore using more advanced sensors or alternative references to enhance calibration accuracy. Lastly, using pre-trained weights requires periodic updates through server communication or firmware updates to sustain consistent performance, emphasizing the importance of developing dynamic training methods in future studies."}]}