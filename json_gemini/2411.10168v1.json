{"title": "Evaluating the role of 'Constitutions' for learning from AI feedback", "authors": ["Saskia Redgate", "Andrew M. Bean", "Adam Mahdi"], "abstract": "The growing capabilities of large language models (LLMs) have led to their use as substitutes for human feedback for training and assessing other LLMs. These methods often rely on 'constitutions', written guidelines which a critic model uses to provide feedback and improve generations. We investigate how the choice of constitution affects feedback quality by using four different constitutions to improve patient-centered communication in medical interviews. In pairwise comparisons conducted by 215 human raters, we found that detailed constitutions led to better results regarding emotive qualities. However, none of the constitutions outperformed the baseline in learning more practically-oriented skills related to information gathering and provision. Our findings indicate that while detailed constitutions should be prioritised, there are possible limitations to the effectiveness of AI feedback as a reward signal in certain areas.", "sections": [{"title": "1 Introduction", "content": "In current practice, pre-trained large language models (LLMs) are adapted with feedback learning to encode specific desirable abilities, especially conversational behaviours and safety alignment [1, 2]. Learning from human feedback (e.g. RLHF) has been generally seen as the gold standard [3], but this method can be prohibitively expensive, leading to the use of synthetic feedback paradigms such as 'LLM as a Judge' [4] and 'Constitutional AI' [2].\nUsing LLM-generated feedback involves asking a model to self-critique and generate revisions of previous work it has produced, typically based on a set of rules or 'constitution' [2]. Since these constitutions replace human interpretations of complex concepts and behaviours, it is important to consider how the content of the constitution impacts the results of the method. While previous work has shown that more specific constitutions are only marginally better than high-level goals in the case of broad values like 'helpfulness/harmlessness' [5], we are additionally interested how well constitutions can shape specific socio-communicative behaviours. We draw on the case of medical practice, where principles for 'patient-centered communication' [6] have been operationalised with detailed frameworks for the training and assessment of medical practitioners.\nMedical uses of LLMs are an active area of study [7, 8, 9, 10, 11], including the AIME model [12], which incorporates an AI feedback learning approach to train social behaviours such as communication. We expand upon this work by exploring how different constitutions effect the ultimate quality of model generations. We compare four different test scenarios based on two different established clinical guidelines, broad role descriptions, and feedback in the absence of a constitution. We use iterative in-context learning to guide model generations based upon these constitutions, and then rate the quality of the final outputs in comparisons judged by humans. We find that using a more detailed constitution is more effective for improving patient-centered communication skills along emotive dimensions, but find no difference or worse performance along the more practically-oriented"}, {"title": "2 Methods", "content": "2.1 In-context Learning with AI Feedback\nThe core element of reinforcement learning with AI feedback is an iterative process of in-context learning, through which constitution-based feedback is used to create preferred model outputs [2, 12]. These outputs are subsequently used for fine-tuning, and the process can be repeated, but the primary impact of the constitutions takes place through this in-context learning. As such, we focus exclusively on the improvement of dialogues via in-context learning, with the expectation that better results in this portion of training would extend to better overall results. We use medical interviews as the foundation of these dialogues, based on two medical vignettes from the AgentClinic dataset [13].\nTo perform in-context learning, we create an iterative loop using four different LLM agents, modelled after Fu et al. [14], Tu et al. [12] and Bai et al. [2]. Each agent is an instance of Claude 3.5 Sonnet, queried via API. These roles (see Figure 1) include: Patient, acting as a patient based on an AgentClinic vignette [13] in the system prompt which contains information about the symptoms and demographics of a patient 'character'; Doctor, who collects information and reaches a diagnosis for the 'patient'; Moderator, responsible for determining when the conversation between Doctor and Patient agent has ended; and Critic, who provides feedback to the Doctor agent based on a chosen constitution.\nAfter the critic agent has given one round of feedback, and the patient and doctor have completed two conversations, we record the final conversation as the output to be assessed. We use this process to generate one complete conversation per constitution for each of the two vignettes. For fairness between constitutions, we excluded and replaced conversations where the patient model failed to follow the vignette by hallucinating symptoms or not acting as a patient. Complete prompt templates and parameters for each of the agents are included in Appendix B and vignettes are in Appendix D."}, {"title": "2.2 Constitutions", "content": "We compare four constitutions, as described below (for the full text, see Appendix A). 1) Best Practices, based on the widely-used 'Patient-Centered Communication' framework established by King et al. [6], is highly detailed and aligns with the criteria used to evaluate the final conversations. 2) Empathetic, derived from EPITOME framework for empathetic text [15], is moderately detailed but focuses on only one aspect of socio-communicative skills. 3) Doctor, inspired by Kundu et al. [5], specifies only that the output should be in line with a good doctor, relying on the Critic for interpretation. 4) No Constitution serves as a baseline, where the Critic provides feedback to improve the dialogue without specifying guidelines."}, {"title": "2.3 Evaluation Framework", "content": "The final conversations are compared according to the six categories of the 'Patient-Centered Communication' framework [6], with the relevant questions adapted from Reeve et al. [16] and Moser et al. [17]. The categories are shown in Table 1.\nFor each dimension, we collect pairwise ratings between the generated conversations. We then use a Bradley-Terry model [18] to estimate an underlying parameter of the quality of the conversations along each dimension."}, {"title": "2.4 Human Evaluation", "content": "To evaluate the final conversations, we recruited 215 human raters from Prolific. Each participant is presented with two randomly selected conversations based on different constitutions, and asked to make comparisons between them according to the 'Patient-Centered Communication' framework as well as providing a holistic preference. Participants repeat this twice, seeing one conversation for each constitution, but not all six possible pairings. Participants are paid \u00a32.75 for an average of 13 minutes of time. Due to the length of the conversations being compared, we required participants to answer one comprehension check question per conversation, and we excluded 2 participants who failed more than once. We did not exclude participants who skipped other questions, leading to slight imbalances between the number of ratings per question and pair. We excluded 16 participants who started but did not complete the survey, an attrition rate of 7%. This research was pre-approved and carried out in line with institutional ethics approval (reference number OII_C1A_24_203)."}, {"title": "3 Results", "content": "In Figure 2, we show the rate at which the conversations generated according to each constitution are preferred to the others for each dimension of evaluation, alongside the estimated parameters for a Bradley-Terry model."}, {"title": "4 Discussion", "content": "For the emotionally-oriented dimensions (Fostering the Relationship, Decision Making, and Responding to Emotions) of patient-centered communication, we found that the most specific constitution led to the most human-preferred dialogues. This is consistent with previous work comparing constitutions in the case of 'harmlessness' [5], and indicates that efforts to create detailed constitutions are likely to improve the outcomes of AI feedback methods. This is also supported by the poor performance of the generic \"Doctor\" constitution, which is indistinguishable from the \"No constitution\" treatment in all six dimensions, and the success of the \u2018Empathy' constitution in \u2018Responding to Emotions', but not the other categories.\nWe do not see the same improvements for the more practically-oriented dimensions, where the LLM needs to manage information exchange with the patient. These type of behaviours may be more difficult for language models to judge and learn, as they involve planning and theory of mind, while emotional signals may be imitated by adding sensitive-sounding phrases [7].\nWe also note that qualitative feedback from participants who did not like the verbosity of the models reveals that aspects of the reward function such as sentence length may be intuitive to humans but not LLMs [12], and that human preferences remain difficult to measure well.\nIn this study, we focused on comparing four specific constitutions in the case of patient-centered communication in medicine. For each constitution, we used only two dialogues, limiting the generalisability. This is partially compensated by having six different axes of comparison, showing that the dialogues are improved in several, but not all cases. While we argue that in-context learning is the key mechanism for RLAIF, fine-tuning based on a collection of examples would allow a model to learn behaviours which are not present in every example. As such, a wide range of small improvements may be aggregated to achieve better results than what we observe in a single interaction with in-context learning."}, {"title": "A Constitutions", "content": "We provide the full text of the four constitutions.\nConstitution 1: Best Practices\nYou are an Al critic providing feedback to a doctor after they have completed a conversation with a patient. All of the previous conversation is the completed conversation. Provide feedback based on the following guidelines:\n1. Fostering the relationship\nRoles:\n\u2022 Build rapport and connection\n\u2022 Appear open and honest\n\u2022 Discuss mutual roles and responsibilities\n\u2022 Respect patient statements, privacy, and autonomy\n\u2022 Engage in partnership building\n\u2022 Express caring and commitment\n\u2022 Acknowledge and express sorrow for mistakes\nSkills:\n\u2022 Greet patient appropriately\n\u2022 Use appropriate language\n\u2022\nEncourage patient participation\n\u2022 Show interest in the patient as a person\n2. Gathering information\nRoles:\n\u2022 Attempt to understand the patient's needs for the encounter\n\u2022 Elicit full description of major reason for visit from biologic and psychosocial perspectives\n\u2022 Elicit patient's full set of concerns\n\u2022 Elicit patient's perspective on the problem/illness\n\u2022 Explore full effect of the illness\nSkills:\n\u2022 Ask open-ended questions\n\u2022 Allow patient to complete responses\n\u2022 Listen actively\n\u2022 Clarify and summarize information\n\u2022 Inquire about additional concerns\n3. Providing information\nRoles:\n\u2022 Seek to understand patient's informational needs\n\u2022 Share information\n\u2022 Overcome barriers to patient understanding (language, health literacy, hearing, numeracy)\n\u2022 Facilitate understanding\n\u2022 Provide information resources and help patient evaluate and use them"}, {"title": "Constitution 1: Best Practices (continued)", "content": "Skills:\n\u2022 Explain nature of problem and approach to diagnosis and treatment\n\u2022 Give uncomplicated explanations and instructions\n\u2022 Avoid jargon and complexity\n\u2022 Encourage questions and check understanding\n\u2022 Emphasize key messages\n4. Decision making\nRoles:\n\u2022 Prepare patient for deliberation and enable decision making\n\u2022 Outline collaborative action plan\n\u2022 Encourage patient to participate in decision making\nSkills:\n\u2022 Outline choices\n\u2022 Explore patient's preferences and understanding\n\u2022 Reach agreement\n\u2022 Identify and enlist resources and support\n\u2022 Discuss follow-up and plan for unexpected outcomes\n5. Enabling disease- and treatment-related behavior\nRoles:\n\u2022 Assess patient's interest in and capacity for self-management\n\u2022 Provide advice (information needs, coping skills, strategies for success)\n\u2022 Agree on next steps\n\u2022 Assist patient to optimize autonomy and self-management of his or her problem\n\u2022 Arrange for needed support\n\u2022 Advocate for and assist patient with health system\nSkills:\n\u2022 Assess patient's readiness to change health behaviors\n\u2022 Elicit patient's goals, ideas, and decisions\n6. Responding to emotions\nRoles:\n\u2022 Facilitate patient expression of emotional consequences of illness\n\u2022 Acknowledge and explore emotions\n\u2022 Express empathy, sympathy, and reassurance\n\u2022 Provide help in dealing with emotions\nSkills:\n\u2022 Assess psychological distress\nYour feedback will only be seen by the doctor. Give your feedback in 100 words or less."}, {"title": "Constitution 2: Empathetic", "content": "You are an AI critic providing feedback to a peer. All of the previous conversation is the completed conversation. Provide feedback based on the following guidelines:\n\u2022 Emotional Reactions: Expressing emotions such as warmth, compassion, and concern, experienced by peer supporter after reading seeker's post\n\u2022 Interpretations: Communicating an understanding of feelings and experiences inferred from seeker's response\n\u2022 Explorations: Improving understanding of the seeker by exploring the feelings and experiences not stated in the reply. Showing an active interest in what the seeker is experiencing and feeling and probing gently\nYour feedback will only be seen by the peer. Give your feedback in 100 words or less."}, {"title": "Constitution 3: Doctor", "content": "You are an AI critic providing feedback to a doctor after they have completed a conversation with a patient. Give feedback as you see fit. Your feedback will only be seen by the doctor. Give your feedback in 100 words or less."}, {"title": "Constitution 4: No Constitution", "content": "You are an AI critic providing feedback. Give feedback as you see fit. Give your feedback in 100 words or less."}, {"title": "B Model Agent Specifications", "content": "All models used in this study were copies of the Claude 3.5 Sonnet model, accessed via API. Temperature was set to 1.0. The total inference cost was $60.\nWe prompted each of the agents using the following templates, based on [12]. For fairness between the trials, we re-used the patient's first generation across all conversations with models using different constitutions. This way, the first divergence between conversations will result from the doctor model which is being tested.\nPatient\nYou are a patient chatting with a doctor over an online chat interface. The doctor has never met you before. This is your profile:\nDemographics: ...\nOverview: ...\nPrimary Symptoms: ...\nSecondary Symptoms: ...\nMedical History: ...\nSocial History: ...\nKey Review of Vitals: ...\nUsing the profile you should answer as the patient. Do not reveal you are an AI chatbot. Give your responses in 60 words or less.\nDoctor\nYou are a Doctor speaking to a patient over an online chat interface. You know nothing about the patient in advance. Respond in single-turn responses to understand their symptoms and find a diagnosis. You should provide a diagnosis to the patient. You are the healthcare provider. Do not tell the patient to see a healthcare provider. Do not reveal you are an AI bot. Give your responses in 50 words or less.\nModerator\nYou are a helpful AI agent which is monitoring a simulated conversation between a Doctor and a Patient. You should stop the conversation when you feel a natural conclusion has been reached. Do not terminate the conversation if there are any open questions left unanswered.\nCritic\nYou are an AI critic providing feedback {INSERT CONSTITUTION} Give your feedback in 100 words or less.\nTo make sure the feedback has been acknowledged by the Doctor, additional leading text is added to the critic feedback and the next turns in conversation are forced such that in the Doctors context the feedback has been received. This is following the prompt structure on receiving feedback based on [14].\nUSER \"Here is feedback on your previous interaction with the patient: {CRITIC FEEDBACK} Incorporate this feedback into your responses in the next turn of conversation\u201d\nASSISTANT (DOCTOR) \u201cI understand and have acknowledged the feedback. I will incorporate it into the next turn of the conversation.\"\nUSER \"The next round of conversation is about to start.\"\nASSISTANT (DOCTOR) \u201cHello, how can I help you today?\""}, {"title": "C Platform Screenshots", "content": "Below are screenshots of the experimental platform where human feedback was collected. Participants were given the instructions \"Please read through the two sets of dialogue between a patient and a doctor. After reading, please answer the questions below.\" The dialogues were shown side-by-side as seen in Figure 3.\nAfter reading the dialogues, participants were further instructed: \"Once you have finished reading the two sets of dialogue, please answer the questions below. You will be asked 4 questions in total.\nThe first 2 questions will check you have read both pieces of dialogue thoroughly.\nThe next 2 will ask for your opinion of the Doctor in the 2 pieces of text. You are welcome to reread the two sets of dialogue anytime while answering the following questions.\"\nThe comprehension checks are given as multiple choice questions based on the content of the passage. Participants then complete forced-choice comparisons between the two dialogues for each aspect of the patient-centered communication framework as shown in Figure 4."}, {"title": "D Vignettes", "content": "We used two vignettes in this study, taken from the AgentClinic dataset [13]. We include the details of the vignettes here without information about their correct resolution, to avoid contaminating the original dataset.\nVignette 1:\nDemographics: 19-year-old Caucasian male\nOverview: The patient reports noticing gradually developing patches of lighter skin on his hands and face over the past few months. These patches seem to be expanding in size. He denies any pain, itching, or other discomfort in the areas. No recent illnesses, medication changes, or significant sunburns.\nPrimary Symptoms: Hypopigmented skin patches\nSecondary Symptoms: No discomfort in the affected areas, Gradual increase in size of the patches\nMedical History: No significant past medical history. The patient is otherwise healthy with no chronic conditions.\nSocial History: Full-time university student, non-smoker, and occasional alcohol use.\nKey Review of Vitals: Denies recent flu-like symptoms, fever, weight loss, changes in vision, hair loss, or history of skin cancer in the family.\nVignette 2:\nDemographics: 45-year-old female\nOverview: The patient reports a 2-week history of rectal bleeding occurring daily with bowel movements. She denies any pain with defecation and does not present with any other complaints.\nPrimary Symptoms: Rectal bleeding daily with bowel movements\nSecondary Symptoms: No pain with defecation Medical History: The patient's past medical history is unremarkable except for 5 normal vaginal deliveries.\nSocial History: Information not specified.\nKey Review of Vitals: The patient denies any changes in bowel habits, abdominal pain, weight loss, or other systemic symptoms."}]}