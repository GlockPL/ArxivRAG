{"title": "Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components", "authors": ["Abel Jansma"], "abstract": "We introduce a novel framework for decomposing interventional causal effects into synergistic, redundant, and unique components, building on the intuition of Partial Information Decomposition (PID) and the principle of M\u00f6bius inversion. While recent work has explored a similar decomposition of an observational measure, we argue that a proper causal decomposition must be interventional in nature. We develop a mathematical approach that systematically quantifies how causal power is distributed among variables in a system, using a recently derived closed-form expression for the M\u00f6bius function of the redundancy lattice. The formalism is then illustrated by decomposing the causal power in logic gates, cellular automata, and chemical reaction networks. Our results reveal how the distribution of causal power can be context- and parameter-dependent. This decomposition provides new insights into complex systems by revealing how causal influences are shared and combined among multiple variables, with potential applications ranging from attribution of responsibility in legal or AI systems, to the analysis of biological networks or climate models.", "sections": [{"title": "1 INTRODUCTION", "content": "Causal language is ubiquitous throughout the natural and social sciences. A ball falls towards the earth because of a gravitational force, inflation rises because of excessive money supply, climate changes because of greenhouse gas emissions. In each case, we seek not just to describe what happens, but to understand why it happens\u2014to identify the causal mechanisms underlying the observed phenomenon. Implicit in causal language are claims about the effect of interventions or counterfactual scenarios (we can mitigate climate change by reducing greenhouse gas emissions, and inflation would not be as high if there had been no excessive money supply). When we study something that is embedded in a web of complex causal interactions, attributing causality can become more difficult, so sophisticated mathematical and computational techniques have been developed that all rely on one of two things: either one is able to directly intervene in the system and study its response, or one requires a priori knowledge of the causal dependencies in the system. In this study, we focus on situations in which causal effects are identifiable, and address the question of causal attribution: given that we know the effect of interventions on various variables, how do we attribute the causal power to the different variables? In particular, we are interested in distinguishing between three types of attribution: unique, redundant, or synergistic causal power. Decomposing an effect into these three classes is commonly done in information theory, where it is known as the Partial Information Decomposition (PID, [Williams and Beer, 2010]). Given two coinflips, for example, the answer to the question 'was there an even number of heads' is carried purely synergistically by the pair of coins, since each coin individually carries no information whatsoever about the answer.\nHere we extend this approach to causal effects and define a 'partial causality decomposition'. Understanding these three different components of causality is crucial to a good understanding and control of complex systems. DiFrisco and Jaeger [2020], for example, already emphasised the importance of identifying and distinguishing redundant and synergistic causality in gene regulatory systems.\nRecently, Mart\u00ednez-S\u00e1nchez et al. [2024] demonstrated a technique to decompose an observational measure (based on mutual information) that they refer to as causality. We, however, are of the opinion that a measure of causality should necessarily be interventional, and not accessible from the joint distribution alone. In fact, Pearl uses this as the very definition of a causal quantity [Pearl, 2009]. Still, Mart\u00ednez-S\u00e1nchez et al. [2024] raise an interesting question, namely, is it possible to disentangle the unique, redundant, and syn-"}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 PARTIAL ORDERS AND M\u00d6BIUS INVERSION", "content": "To show the algebraic structure of the decomposition, we first need to introduce a number of concepts.\nDefinition 1 (Partially Ordered Set). A partially ordered set is a tuple (S, \u2264), where S is a set and \u2264 is a binary relation on S that is reflexive, antisymmetric, and transitive.\nWhen the ordering is clear from context or irrelevant, we will sometimes use the shorthand S to denote the poset. An example of a partial order is (P(T), \u2286), the power set of T ordered by inclusion. Given a poset S and a, b \u2208 S, the interval [a, b] is the set {x : a < x < b}. If all intervals on S are finite sets, then S is called locally finite. We also define the following:\nDefinition 2 ((Anti)chains). Let (S, \u2264) be a poset. A subset T\u2286 S is a chain if for all a, b \u2208 T, a \u2264 b or b < a. If for all a, b \u2208 T, a < b implies a = b, then T is an antichain.\nNote that in particular any single element subset of a poset is both a chain and an antichain.\nFunctions on S can interact with the partial order in various ways. One such function is the M\u00f6bius function:\nDefinition 3 (M\u00f6bius function). Let (S, \u2264) be a locally finite poset. Then the M\u00f6bius function \u03bc\u03c2 : S\u00d7S \u2192 R is defined as\n$\n\\mu_{\\varsigma}(x,y) = \\begin{cases}\n1 & \\text{if } x = y \\\\\n-\\sum_{z:x<z<y} \\mu_{\\varsigma}(x,z) & \\text{if } x < y \\\\\n0 & \\text{otherwise}\n\\end{cases}\n$\nThis allows us to state the M\u00f6bius inversion theorem (MIT):\nTheorem 1 (M\u00f6bius inversion theorem, Rota [1964]). Let (S, \u2264) be a locally finite poset. Let f : S \u2192 R be a function on S, and let \u03bc\u03c2 be the M\u00f6bius function on S. Then\n$\nf(b) = \\sum_{a<b}g(a) \\qquad g(b) = \\sum_{a<b}\\mu_{\\varsigma}(a, b) f(a)\n$\nThe M\u00f6bius inversion theorem states that sums of a function over a partial order can be inverted using the M\u00f6bius function. Because the l.h.s. of (2) can be interpreted as a"}, {"title": "2.2 DECOMPOSITIONS INTO ANTICHAINS", "content": "Principled decomposition into synergistic, redundant, and unique components was first explored by Williams and Beer [2010] in the context of information theory under the name Partial Information Decomposition (PID). Their ap- proach forms our main inspiration, so we briefly describe it here. Consider the mutual information I(X1, X2; Y) that two variables (X1, X2) carry about a variable Y. If I(X1, X2; Y) = v, then one might ask: How are the v bits about Y carried by the pair (X1, X2)? One could imagine that both variables carry the same v bits, so that the inform- ation is carried redundantly, or that both variables uniquely carry. Another option is that neither variable has informa- tion by itself, but it is the joint state of the pair that carries the v bits synergistically. For two variables, one therefore writes\n$\nI(X_1, X_2; Y) = I_\\partial({X_1}, Y) + I_\\partial({X_2},Y) +I_\\partial({X_1, X_2}, Y) + I_\\partial({{X_1},{X_2}},Y)\n$\nwhere the 'partial' information Ia({X}) is the in- formation that variable Xi uniquely carries about Y, Ia({{X1}, {X2}}) is the information that carried redund- antly by the two variables, and I\u0259({X1, X2}) is the informa- tion that is carried synergistically by the joint state of the pair. Note, however, that the situation becomes more complex if more variables are added. Three variables {X1, X2, X3}, for example, can carry information redundantly between the joint state of {X1, X2} and the state of {X3}, or synergist- ically between all three variables, etc. The central insight of the PID is that information can be carried redundantly among all incomparable subsets of variables. Given a set of variables X, the incomparable subsets of X are the antichains\u00b9 of (P(X), \u2286), denoted A(X). Some elements of A({X1, X2, X3}) and their interpretation are:\n\u2022 {{X1, X2, X3}} \u2192 synergy among X1, X2, X3\n\u2022 {{X1, X2}, {X2, X3}} \u2192 redundancy between {X1, X2} and {X2, X3}\n\u2022 {{X1}, {X2}, {X3}} \u2192 redundancy between X1, X2, X3\nThe set {{X1, X2}, {X1, X2, X3}} is not an antichain, be- cause {X1, X2} \u2286 {X1, X2, X3}. Terms like this should"}, {"title": "3 INTERVENTIONAL CAUSALITY", "content": ""}, {"title": "3.1 AVERAGE CAUSAL EFFECTS", "content": "The central object of study in causality is the average treatment effect [Pearl, 2009]. Given a set of variables Xs := {X\u00bfi \u2208 S}, where S is some indexing set, and an outcome variable Y, the average treatment effect (ATE) of Xs on Y is defined as\n$\nATE(X; Y) = \\mathbb{E}[Y|do(X_s = 1)] \u2013 \\mathbb{E}[Y|do(X_s = 0)]\n$\nwhere the do-operator is used to denote an intervention. The variables Xs are usually taken to be binary \u2018treatments' so that do(Xs = 1) corresponds to applying treatments Xs. The ATE is a measure of the causal power that the set of vari- ables X has on the outcome Y. The most direct way to estim- ate quantities like (7) is to perform a randomised controlled trial, where the treatment X is randomly assigned to the subjects. In that case, P(Y|do(X = x)) = P(Y|X = x), and the ATE can be estimated from the joint distribution of X and Y. However, randomised controlled trials are expens- ive, and one commonly has to rely on observational data. In that case, the ATE is not directly observable, because P(Y\\do(X = x)) \u2260 P(Y|X = x). In fact, probabilities under interventions are by definition not derivable from the joint distribution only. One always needs additional inform- ation about the causal structure, usually given in the form of a directed acyclic graph (DAG) called the causal graph. To estimate the effect of interventions, Pearl [2009] developed rules that relate interventional quantities on the causal graph to observational quantities relative to a different graph, col- lectively referred to as the do-calculus. By combining know- ledge of the joint distribution and the causal graph, one can estimate the effect of interventions, or conclude that an effect is not identifiable. It is these true causal effects, defined in terms of interventions, that we are interested in decomposing.\nSince we aim to capture the total causal power in a set of variables, not just the effect of a binary treatment, we slightly modify the ATE to a 'maximal average causal effect' by defining:\n$\nMACE(X; Y) = \\max_{x,x' \\in X} (\\mathbb{E}[Y|do(X_s = x)] \u2013 \\mathbb{E}[Y|do(X_s = x')])\n$\nWhere X is the set of possible values that Xs can take. Note, however, that this is just one way to characterise causal strength. Other definitions are possible (see e.g. [Janzing et al., 2013]), each of which can be similarly decomposed using our method.\nThe MACE quantifies the maximal causal power that a set of variables X can exert on Y. This definition has the ad- vantage that it does not rely on a priori assumptions about the possible values of the variables, but it no longer captures the direction of the causal effect. It is this quantity that we wish to decompose into synergistic, redundant, and unique components. This makes sense, since while the MACE quan- tifies the total causal power of a set of variables, it does not tell us how this power is distributed among the variables. To understand and steer the behaviour of causal systems, it can be crucial to know if the causal power is redundant, synergistic, or unique."}, {"title": "3.2 DECOMPOSING CAUSAL EFFECTS INTO ANTICHAINS", "content": "We decompose the MACE as a sum over the antichains as\n$\nMACE(S; Y) = \\sum_{\\alpha \\in A(S)} C(\\alpha; Y)\n$\nwhere C(a; Y) denotes the 'partial causal effect' of anti- chain a to the full MACE. This corresponds to a 'partial causality decomposition'. A M\u00f6bius inversion then shows that the partial causal effects can be written as\n$\nC(\\beta;Y) = \\sum_{\\alpha \\lt \\beta} \\mu_{\\mathbb{A}} (\\alpha, \\beta)MACE(\\alpha; Y)\n$\nwhere \u00b5A is the M\u00f6bius function of the antichain poset (A(S), \u2264) which can be calculated using the fast M\u00f6bius transform [Jansma et al., 2024]. However, Equation (8) only defined the MACE on a subset of variables, not what the MACE for an antichain of variables is: the redundant MACE. We define the redundant MACE of an antichain a, denoted as MACE\u2229(a; Y), as the minimum of the MACEs of ele- ments of the antichain, since this is the causal power that they share:\n$\nMACE_\\cap(\\alpha; Y) = \\min_{\\alpha \\in \\alpha} MACE(\\alpha; Y)\n$\n$\nMACE_\\cap(\\alpha; Y) = \\min_{\\alpha \\in \\alpha} \\max_{x,x'} (\\mathbb{E}[Y|do(\\alpha = x)] \u2013 \\mathbb{E}[Y|do(\\alpha = x')])\n$\nNote, however, that one could come up with different defin- itions of redundant causality, as long as it reduces to the chosen definition of the causal effects on antichains of car- dinality one. One nice property of the MACE is that it is a monotone function on the antichain poset:\nLemma 1. The function MACE\u2229 : An \u2192 R is monotonic with respect to the redundancy ordering on An.\nLemma serves to lend some credibility to our claim that the definition of MACE\u2229 is sensible, but also implies the following:\nTheorem 2. The partial causal effects C'(a; Y) are nonnegative.\nProof. Immediate by inserting Lemma 1 into the proof of Theorem 5 in [Williams and Beer, 2010].\nNonnegativity of causal effects makes intuitive and practical sense. Consider the following:\n$\nsyn(S; Y) = \\sum_{\\alpha \\in A(S): |\\alpha| > 1} C(\\alpha; Y)\n$\nThis quantity syn(S; Y) is the total synergistic causal power within the set of variables S on Y. It is all causal power that you would miss if you only consider individual interventions. Nonnegativity of the C(a; Y) implies that even when not all these terms in the sum can be calculated, a partial sum will still give a lower bound on syn(S; Y)."}, {"title": "4 DECOMPOSING CAUSALITY IN PRACTICE", "content": ""}, {"title": "4.1 CAUSAL POWER IN LOGIC GATES", "content": "The causal graph of a logic gate with two inputs is simply a collider structure: X1 \u2192 Y \u2190 X2. In this case, the do-operator reduces to the see-operator (by the back-door criterion P(Y|do(X)) = P(Y|X) if Y | X in Gx,"}, {"title": "4.2 CAUSAL POWER IN CELLULAR AUTOMATA IS CONTEXT-DEPENDENT", "content": "A more interesting causal structure is that of a cellular auto- maton. Consider a 1D cellular automaton with N cells, where each cell can be 0 or 1. The state of a cell at time t + 1 is determined by the state of itself and its two neigh- bours at time t. We consider the causal power that the two neighbours of a central site at time t have over the state of the central site at time t + 1. The causal graph takes the following form:\nThe MACE of A can be written as\n$\nMACE(A_t; B_{t+1}) = \\max_{s,s'} (\\mathbb{E}[B_{t+1}|do(A_t = s)] \u2013 \\mathbb{E}[B_{t+1}|do(A_t = s')])\n$\nwhich shows that we need access to quantities like p(Bt+1 do(At = s)). Note that there are a lot of back- door paths from At to Bt+1, but all are blocked by the set {Bt, Ct}, so we can write:\n$\np(B_{t+1}|do(A_t = a_t)) = \\sum_{b_t,c_t}p(B_{t+1}|A = a_t, B_t = b_t, C_t = c_t)p(B_t = b_t, C_t = c_t)\n$\n$\np(B_{t+1}|do(A_t = a_t, C_t = c_t)) =\\sum_{b_t}p(B_{t+1}|A = a_t, B_t = b_t, C_t = c_t)p(B_t = b_t)\n$\n$\np(B_{t+1}|do(A_t = a_t, B_t = b_t, C_t = c_t)) =p(B_{t+1}|A = a_t, B_t = b_t, C_t = c_t)\n$\nHowever, we do not have a clear prior probability distribu- tion on Bt and Ct, so there are multiple ways to evaluate these expressions. First, we consider the \u2018maximum entropy' solution, which simply assumes that the input states are drawn from a uniform distribution. For a single intervention, this implies:\n$\np(B_{t+1} do(A_t = s)) = \\frac{1}{}\\sum_{b_t,C_t}p(B_{t+1}| A_t = s, B_t = b_t, C_t = C_t)\n$\nDecomposing causal effects under this assumption essentially decomposes the causal power encoded in the rule itself. To calculate the MACE we just need to calculate the average effect of At on Bt+1, conditional on the possible states of Bt and Ct, which can be immediately read of from the rule specification. Another option is to let the inputs always be zero, so that p(Bt, Ct) = \u03b4\u0432\u2081,08c1,0, which gives the causal power in the context of the empty state.\nAlternatively, we could estimate the prior distribution of Bt and Ct based on data from a simulated automaton, which gives the causal power decomposition of the dynamics given the initial state, not just the rule itself. The prior distribution then depends on the chosen initialisation. We will consider two possible initialisations: a random initialisation, where each cell is drawn from a Bernoulli distribution with p = 0.5, and a middle-1 initialisation, where all cells are zero except for the middle cell, which is set to one.\nWe study the set of rules shown in Figure 4, and their causal decompositions are shown in Figure 5, for both the uniform and zero-based priors, as well as empirical priors based on middle-1 and random initialisations. To get empirical es- timates, we simulated automata with 100 cells and periodic boundary conditions that evolved over 10k steps, where the first 500 states were discarded.\nThe results give a nuanced and context dependent descrip- tion of the causal power inside the automata. For example, if you want to control the 'Rule 90' automata with a single intervention, then this is possible under a middle-1 initialisa- tion, but not under a random initialisation. More details on"}, {"title": "4.3 RATE-DEPENDENCY IN THE CAUSAL DECOMPOSITION OF A CHEMICAL NETWORK", "content": "We are interested in seeing how the causal decomposition of a system can change as one varies a parameter. To illustrate this, consider the following chemical network. Two chem- icals X1 and X2 can spontaneously form a molecule Y at rates k\u2081 and k2, but can also come together to form Y at rate k3. The molecule Y then spontaneously degrades at rate k4. This system can be described by the following 'chemical reactions':\n$\nX_1 \\xrightarrow{k_1} Y\n$\n$\nX_2 \\xrightarrow{k_2} Y\n$\n$\nX_1 + X_2 \\xrightarrow{k_3} Y\n$\n$\nY \\xrightarrow{k_4} 0\n$\nThe rate equations for this system are\n$\n\\frac{d[X_1]}{dt}=-k_1 [X_1] - k_3[X_1]\n$\n$\n\\frac{d[X_2]}{dt}=-k_2[X_2] - k_3 [X_2]\n$\n$\n\\frac{d[Y]}{dt}= k_1[X_1] + k_2[X_2] + k_3[X_1][X_2] - k_4[Y]\n$\nwhich implies that the steady state concentration is\n$\n[Y]_{ss} (X_1, X_2) = \\frac{k_1[X_1] + k_2[X_2] + k_3[X_1][X_2]}{k_4}\n$\nFrom here on, without loss of generality, we assume that k4 = 1. We imagine that the experimenter is able to modify the concentrations of X\u2081 and X2 by adding an amount \u03b4\u03b5 to the concentration of X\u2081, and that the target variable is the normalised concentration Y\n= Yes [X1,X2]. Note that\nthe causal structure of this system is still just a collider\nX\u2081 \u2192 Y\u2190 X2, so to calculate the effect of an intervention on one of the concentrations, we just need to calculate the conditional expectation of Y given the intervention, which is the steady state concentration (assuming that the system equilibriates quickly).\n$\n\\mathbb{E}(\\hat{Y}|do(\\delta_1 = \\epsilon)) = \\frac{[Y]_{ss}(X_1+\\epsilon, X_2)}{[Y]_{ss}(X_1, X_2)}\n$\nThe MACE of an antichain of variables {X1, X2} on \u0176 is then again simply given by equation (12), where the inner"}, {"title": "5 DISCUSSION", "content": "We have presented a principled way to decompose causal effects into synergistic, redundant, and unique components. By studying the decomposition in the context of logic gates, cellular automata, and chemical networks, we have shown that the causal decomposition can intuitively recover the causal structure of the system and reveal the synergetic, redundant, or unique causal power of the different variables. Furthermore, we have shown that the causal decomposition can depend on the dynamical context of the system, or on the value of its parameters. These insights can allow for a more nuanced understanding of the causal structure of a system, and can be used to guide interventions in a system to achieve more desirable outcomes.\nThe formalism is similar in spirit and algebra to that of the partial information decomposition, but by decompos- ing an interventional quantity we are able to quantify true causal power. The approach outlined here would in prin- ciple work for any macroscopic quantity, in particular for other definitions of causal power than the one in Equation (8), so we encourage and anticipate further exploration of this approach. Our definition of the redundant MACE is deliberatively naive to keep the presentation of the general formalism as transparent as possible, but causal decomposi- tions in other contexts, like in climate systems with feedback loops, may require a more sophisticated notion of redundant causality. Janzing et al. [2013], for example, define causal effects in terms of a Kullback-Leibler divergence, which can be similarly decomposed (see e.g. Jansma [2024] for a M\u00f6bius inversion of the Kullback-Leibler divergence). More generally, our approach fits into the wider context of deriving M\u00f6bius inverses of observable quantities to ob- tain a fine-grained description of complex systems [Jansma, 2024].\nWhile the aim of this study is similar to that of Mart\u00ednez- S\u00e1nchez et al. [2024], we have taken a very different ap- proach. We believe that decomposing causality fundament- ally requires an interventional quantity, so decomposing a quantity derived purely in terms of the joint probability distribution, as is done by Mart\u00ednez-S\u00e1nchez et al. [2024] for the mutual information, cannot yield true causal insight. While Mart\u00ednez-S\u00e1nchez et al. [2024] consider it an advant- age of their method that it does not scale with the Dedekind numbers, we believe that the superexponential growth of the number of antichains is a feature, not a bug. It is a re- flection of the fact that the number of ways information can be carried among n variables fundamentally grows super- exponentially with n. In their approach, [Mart\u00ednez-S\u00e1nchez et al., 2024] only consider redundancies among individual variables, not considering possible redundancies between pairs. For example, they do not include redundancies of the form {{X1, X2}, {X3}}, or {{X1, X2}, {X3, X4}}, both of which are significantly nonzero in the cellular automata studied here. In general, their approach decomposes the total mutual information into 2(2n - 1) + n terms. By not including the full set of redundancies, but still requiring that the sum of the 2(2n - 1) + n terms adds up to the total, their method conflates multiple sources and does not disentangle the causal structure. While their results sug- gest that their method can be useful in understanding the structure of complex systems, we believe that it does not disentangle redundancy from synergy, and that they do not capture causal quantities. In practice, we believe that the Dedekind scaling does not strongly diminish the applicabil- ity of redundancy decompositions like the one introduced here. Our approach can yield very fast full decomposition for up to five variables, the computational bottleneck being the brute-force calculation of the MACE-for which more efficient proxies might be found\u2014not the M\u00f6bius inversion. While the fast M\u00f6bius transform from Jansma et al. [2024] can be employed to calculate parts of the decomposition on even larger systems, decompositions among more than 5 variables quickly become hard to interpret and are therefore not likely to be of practical relevance (partial causal effects quickly become confusing, since the causal power among n variables can be distributed among up to ([n72]) sets by Sperner's Theorem).\nThe presented decomposition might be used to gain insights in a variety of real-world systems. In systems with complex control, like gene regulation or the climate, there might be a combination of both redundant causality (which could improve robustness) and synergistic causality (which could allow for more efficient or fine-grained control). Understand- ing how to intervene in living systems to achieve a desired outcome is also a major challenge in synthetic biology and medicine. In the social sciences, one could imagine that individuals can have both redundant and synergistic control over the behaviour of the group. How to attribute respons- ibility, blame, or rewards in such a social network is both a quantitative and a philosophical/ethical question. We hope that our approach can provide some insight into the former."}, {"title": "A PROOFS", "content": ""}, {"title": "A.1 PROOF OF LEMMA 1", "content": "We first prove the following (obvious) fact:\nLemma 2. The function MACE : P(X) \u2192 R is monotonic on (P(X), \u2286).\nAssume that a \u2286 \u03b2. Let a* be the element of a that achieves the maximum, such that MACE\u2229(a; Y) = MACE(a*; Y). Then, since a \u2286 \u03b2, we know that a* \u2208 \u03b2, so MACE\u2229(\u03b2; Y) > MACE(a*; Y) = MACE\u2229(a; Y). Therefore, \u03b1 \u03b2 \u21d2 MACE\u2229(\u03b1; Y) < MACE\u2229(\u03b2; Y).\nWe can now prove Lemma 1:\nLemma 1. The function MACE\u2229 : An \u2192 R is monotonic with respect to the redundancy ordering on An.\nRecall that a < \u03b2 \u21d4 \u2200b \u2208 \u03b2, \u2203a \u2208 a : a \u2286 b. Now assume that given a < \u03b2, we have\n$\nMACE_\\cap(\\beta; Y) < MACE_\\cap(\\alpha; Y)\n$\n$\n\\min_{B \\in \\beta} MACE(b; Y) < \\min_{\\alpha \\in \\alpha} MACE(a; Y)\n$\nBy Lemma 2 Equation (29) can only be true as long as #b \u2208 \u03b2,\u03b1 \u0395\u03b1: \u03b1 \u2286 b. However, since a \u2264 \u03b2, we know that Vb \u03b5\u03b2, \u039e\u03b1 \u03b5\u03b1 : a \u2286 b, which is a contradiction. Therefore, \u03b1 < \u03b2 \u21d2 MACE\u2229(a; Y) < MACE\u2229(\u03b2; Y)."}, {"title": "B CAUSAL DECOMPOSITION OF CELLULAR AUTOM\u0391\u03a4\u0391", "content": "We here give further details on how the causal decomposi- tions in Figure 5 relate to the automata rules.\nRule 30 can be written as Bt+1 = At XOR (B+ OR Ct), which shows that A indeed has some unique causal power, but that there is also synergistic causality between A and C. However, in a context of only zeros, the XOR reduces to a simple OR gate, which makes the causal power fully redundant.\nRule 54 corresponds to Bt+1 = (A+ OR C\u2081) XOR Bt so can be fully redundant in the context of zeros, but contains synergistic causality with B in all other situations. Note, however, that there is redundancy among the two possible pairwise synergies with B.\nRule 86 is the mirrored version of rule 30, which is reflected by the equivariance of their decompositions under A \u2194 C.\nRule 90 can be written as Bt+1 = At XOR Ct, which the causal decomposition correctly reveals as either purely syn- ergistic or redundant causal power among A and C, depend- ing on the context. Only with middle-1 initialisation does the causal power become mixed, which is the initialisation that makes rule 90 evolve a fractal Sierpi\u0144ski triangle.\nRule 110, famously complex and Turing complete, contains the most complex causal structure of the rules studies here, though this is not visible from the causal decomposition in the context of zeros.\nRule 190 can be written as Bt+1 = (At XOR Bt) OR Ct, which is why the causal power is always fully redundant in the context of zeros, but shows both pure synergy as well as redundancy between AB and C in the uniform back- ground. Under different initialisation, however, the causal decomposition become more complex.\nRule 240 is the exceptionally simple Bt+1 = At, which is why every prior results in all causal power lying with A.\nRule 250 is Bt+1 = At OR Ct, and so, similar to the OR gate from Fig. 3 at p = 0.5, contains equal parts synergistic and redundant causal power, except in the context of zeros, or under random initialisation (which under this rule is equivalent to a context of only ones)."}]}