{"title": "LIVER CANCER KNOWLEDGE GRAPH CONSTRUCTION BASED ON\nDYNAMIC ENTITY REPLACEMENT AND MASKING STRATEGIES\nROBERTA-BILSTM-CRF MODEL", "authors": ["Yichi Zhang", "HanLing Wang", "YongBin Gao", "XiaoJun Hu", "YingFang Fan", "ZhiJun Fang"], "abstract": "Background: Liver cancer ranks as the fifth most common malignant tumor and the second most fatal\nin our country. Early diagnosis is crucial, necessitating that physicians identify liver cancer in patients\nat the earliest possible stage. However, the diagnostic process is complex and demanding. Physicians\nmust analyze a broad spectrum of patient data, encompassing physical condition, symptoms, medical\nhistory, and results from various examinations and tests, recorded in both structured and unstructured\nmedical formats. This results in a significant workload for healthcare professionals. In response,\nintegrating knowledge graph technology to develop a liver cancer knowledge graph-assisted diagnosis\nand treatment system aligns with national efforts toward smart healthcare. Such a system promises to\nmitigate the challenges faced by physicians in diagnosing and treating liver cancer.\nMethods: This paper addresses the major challenges in building a knowledge graph for hepatocellular\ncarcinoma diagnosis, such as the discrepancy between public data sources and real electronic medical\nrecords, the effective integration of which remains a key issue. The knowledge graph construction\nprocess consists of six steps: conceptual layer design, data preprocessing, entity identification, entity\nnormalization, knowledge fusion, and graph visualization. A novel Dynamic Entity Replacement and\nMasking Strategy (DERM) for named entity recognition is proposed.\nResults: A knowledge graph for liver cancer was established, including 7 entity types such as disease,\nsymptom, and constitution, containing 1495 entities. The recognition accuracy of the model was\n93.23%, the recall was 94.69%, and the F1 score was 93.96%.", "sections": [{"title": "Introduction", "content": "Cancer remains the foremost cause of mortality on a global scale. The 2020 Cancer Research Report indicates that liver\ncancer constitutes approximately 10.4% of all cancer cases worldwide, amounting to nearly 10.1 million incidences\n[1]. This rate positions it as the second most prevalent cancer type. Furthermore, liver cancer accounts for 6.3% of all\ncancer-related fatalities, equivalent to approximately 5.5 million deaths, ranking it fifth in terms of cancer mortality\nrates. The Knowledge Graph (KG) was first proposed by Google [2] in 2012 as a structured knowledge representation of\nreal-world entities and the relationships between them as graphical structures. Medical KG is a knowledge representation\nmethod that represents entities (e.g., diseases, drugs, symptoms, operation, etc.) and 1relationships between entities in\nthe medical domain as structured graphs."}, {"title": "Related Work", "content": ""}, {"title": "Medical Named Entity Recognition", "content": "NER is an important branch in the field of natural language processing (NLP), which is mainly used to identify\nentities with specific meanings, such as diseases, symptoms, drugs, etc., from medical texts. In recent years, with the\ndevelopment of deep learning techniques, Chinese medical named entity recognition has made significant progress.\nBefore deep learning techniques were widely used, Chinese medical named entity recognition mainly relied on rule-\nbased and statistical-based approaches. Rule-based methods mainly use rules and dictionaries formulated by domain\nexperts for entity recognition, such as regular expressions and dictionary matching. Statistical-based methods mainly\ninclude Hidden Markov Model (HMM)[6], Maximum Entropy Markov Model (MEMM)[7], and Conditional Random\nField (CRF)[8]. Despite the advantages of simple implementation, higher accuracy, and lower computational resource\nrequirements in some specific scenarios, these methods rely on rules and dictionaries formulated by domain experts,\nrequire a lot of human involvement, are difficult to deal with complex and flexible linguistic phenomena and have\na weak generalization ability. With the development of word vector techniques (e.g., word2vec[9] and Glove[10]),\nsome breakthroughs have been made in the field of Chinese medical entity recognition (CMNER). Word vectors\ncan characterize words into continuous high-dimensional vectors, thus improving the model's ability to capture the\nsemantics of words. Through unsupervised learning, word vectors can be learned from a large amount of unlabeled data\nand the semantic relationships between words can be captured effectively. However, the word vector representation\nwill be inaccurate for new words or words with multiple meanings. In recent years, deep learning techniques have\nbeen widely used in Chinese medical NER. The main methods include convolutional neural network (CNN)[11],\nrecurrent neural network (RNN), and long short-term memory network (LSTM)[12]. These methods can effectively\ncapture the local features and long-distance dependencies of text to improve the accuracy of named entity recognition."}, {"title": "Construction of Medical Knowledge Graph", "content": "Medical KG are characterized by dispersed knowledge distribution, distinctive syntax and non-standardized terminology,\nwhich makes the construction of medical KGs more difficult. In response to these challenges, researchers have\nundertaken diverse approaches to construct the Chinese medical KG. For instance, Zhang[17] introduced a generative\nmodel, the Conditional Relationship Variational Autoencoder, aimed at reducing the workload in data preprocessing\nand manual annotation within the Chinese medical corpus[18]. Deep learning models have been employed to enhance\nNER[19] and relation extraction in Clinical CEMRs[20]. Sheng [21] developed a comprehensive framework for a\nhealth knowledge graph, focusing on cardiovascular disease electronic medical records. Zhou[22] investigated the\ndevelopment and utilization of a 'knowledge-centric' traditional Chinese medicine knowledge graph, derived from\nancient Chinese texts. However, one-way semantic relationships are inadequate to fully represent the complexities of\npatient medical processes. For instance, the semantic relationship between disease and examination encompasses not\nonly investigating the disease but also revealing it through examination. To date, several medical knowledge graphs\nbased on CEMRs have been developed, including those for conditions like hypertension and diabetes [23, 24]. Li[25]\nproposes a systematic approach to construct medical KG from large scale of EMRs. The constructed KG contains 9\nentity types, totally 22,508 entities and 579,094 quadruplets. Xiu[26] proposes a framework for the construction of\ndigestive system tumor knowledge graph based on CEMRs, and realized construction of semantic-driven digestive\nsystem tumor knowledge graph(DSTKG).\nTo the medical knowledge graph application, exemplified by the semantic web for Chinese medicine, has garnered\nattention from both academic circles and the healthcare industry. Its utility in intelligent applications, such as analytical\nmining and drug recommendation, is particularly notable. For instance, Wang[27] propose a framework to conduct Safe\nMedicine Recommendation (SMR) and formulate it as a link prediction problem.\nOur work on constructing liver cancer KG from CEMRs distinguishes itself from previous efforts in several key aspects:\n1) It introduces the first knowledge graph specifically tailored for liver cancer, diverging from the general medical\nknowledge graphs typically seen in prior research; 2) involving normalizing and interconnecting entities like diseases,\ntreatments, and surgeries in CEMRs with online medical knowledge bases; and 3) adding the downstream applications\nof the knowledge graph, rather than focusing only on the specific steps of construction KG as in previous work."}, {"title": "Method", "content": "In this section, we develop a systematic procedure to construct the liver KG from Chinese EMRs and the\nwww.XYWY.com online resource. As illustrated in Figure 1, the procedure involves eight principal steps: 1) Conceptual\nLayer Design, 2) Data Preprocessing, 3) Entity Recognition, 4) Knowledge Fusion (KF), 5) Knowledge Dump, and 6)\nKnowledge Graph Application. It is important to note that steps 3 and 4 often demand extensive practical experience\nwith Chinese EMRs and online resources"}, {"title": "Conceptual layer design", "content": "In the medical domain, the conceptual layer design serves to abstract medical entities, organize and structure medical\ninformation systematically. This design aims to enhance the searchability and analyzability of healthcare data, thereby\nsupporting medical decision-making, clinical research, and patient care. This study divides the conceptual layer into\neight categories based on the professional medical website www.XYWY.com and clinicians' experiential knowledge.\nThe eight entity types and their specific entity content are shown in Table 1."}, {"title": "Data preprocessing", "content": "This study utilizes a dataset comprising real-world Chinese EMRs, content from the public professional website\nwww.XYWY.com, and medical entity normalization documents such as CCMT to construct a liver cancer knowledge\ngraph (KG). www.XYWY.com, a Chinese platform, provides comprehensive information on various diseases, including\nsymptoms, diagnoses, treatments, medications, among others. From this source, we extracted semi-structured knowledge\npertinent to liver cancer, highlighting symptom-disease and symptom-drug correlations."}, {"title": "Data Preprocessing and Annotation", "content": ""}, {"title": "Data Source and Preprocessing", "content": "The Electronic Medical Records (EMRs) used in this study were provided by Zhujiang Hospital of Southern Medical\nUniversity in Guangzhou, China, covering the period from 2015 to 2020. These records contain comprehensive\ninformation about patient diseases, symptoms, and surgical procedures. To facilitate annotation and subsequent model\ntraining, we implemented the following preprocessing steps:\n1. Conversion of EMRs to readable and writable text formats\n2. Sentence reformatting based on punctuation\n3. Limitation of words per line to 50"}, {"title": "Annotation Process", "content": "For the annotation of Chinese EMRs, we utilized a client-side annotation tool, Colab. The annotation process focused\non identifying and labeling several key entity types:\n\u2022 Diseases\n\u2022 Symptoms\n\u2022 Patient conditions\n\u2022 Treatment plans\n\u2022 Checkup information\n\u2022 Surgery records"}, {"title": "Format Conversion", "content": "To align with standard practices in named entity recognition tasks, we developed a Python script to convert the Ann-Brat\nformat annotations to the widely-accepted BIO (Beginning, Inside, Outside) format."}, {"title": "Named Entity Recognition", "content": "Three types of NER methods are utilized to extract entities from EMRs: rule-based methods, machine learning-based\nmethods, and deep learning-based methods. Rule-based methods prioritize the clinician's clinical experience, whereas\nmachine learning and deep learning methods predominantly leverage data to train their models. Rule-based NER\napproaches, which depend on meticulously crafted semantic and syntactic rules. The BERT-BiLSTM-CRF model ranks\namong the most favored NER models in current use. In this study, the construction of DERM-ROBERTa-BiLSTM-CRF\nmodel is presented, replacing the pre-training model BERT with RoBERTa-wwm-large and adding DERM module to it.\nROBERTa-wwm-large [30] is an open-source pre-trained model for Chinese dataset. Compared to BERT, ROBERTa-\nwwm-large removes the NSP (Next Sentence Prediction) task during the pre-training process, allowing the model to\nfocus on a single sentence, reducing the noise in training and improving the model's performance on the NER task. In\naddition, the model uses the whole word masking strategy, which has a significant advantage in Chinese NER. This\nstrategy involves masking all the Chinese characters forming a single word, thereby facilitating word-level information\nacquisition. As shown in Table 2, in the input text \u2018with left upper abdominal pain, vomiting, diarrhoea, etc\u2019(\u5de6\u4e0a\n\u8179\u9690\u75db\u3001\u5455\u5410\u3001\u8179\u6cfb\u7b49). BERT may mask just one term of a character like\u2018\u5455\u3001\u6cfb\u2019thereby learning semantic\nrepresentations at the level of character. In contrast, RoBERTa-wwm-large adopts a whole-terms masking strategy. It\nbegins by segmenting the input text, then masks segments such as \u2018left upper abdominal\u2019(\u5de6\u4e0a\u8179), \u2018vomiting\u2019(\u5455\u5410),\nand \u2018diarrhoea\u2019(\u8179\u6cfb). RoBERTa-wwm-large can learn term-level semantic representations, making it more effective\nfor Chinese medical NER tasks. Consequently, this paper employs ROBERTa-wwm-large for vector representation of\nthe input text."}, {"title": "Knowledge Fusion", "content": "Knowledge Fusion (KF) is an integral component of Knowledge Graph (KG) construction. It encompasses the processes\nof extracting, integrating, correlating, and eliminating redundant information from multiple data sources to create\na unified, comprehensive, and accurate knowledge representation. Through KF, we can effectively address several\nchallenges in KG construction:\n\u2022 Data redundancy\n\u2022 Information inconsistency\n\u2022 Knowledge incompleteness\nThese improvements significantly enhance both the quality and usability of the resulting KG.During our entity extraction\nprocess, we observed significant variations in Electronic Medical Records (EMRs) for liver cancer patients. These\nvariations stem from:\n\u2022 Differences in recording habits\n\u2022 Diverse hospital operating guidelines\nAs a consequence, identical entities may be recorded using different terminology across various Chinese EMR reports,\nleading to inconsistent entity extraction. To address these challenges and facilitate better integration between EMRs\nand the www.XYWY.com knowledge base, entity alignment between the two knowledge bases becomes crucial. We\nemploy the Term Frequency-Inverse Document Frequency (TF-IDF) method for this purpose. TF-IDF is a statistical\napproach widely utilized in information retrieval and text mining. It evaluates the importance of a word in relation to a\ndocument within a corpus. This metric comprises two key components:\nTerm Frequency (TF) TF quantifies the occurrence rate of a word in a text, calculated as:\n$TF(t, d) = \\frac{t_d}{d_d}$"}, {"title": "Results", "content": ""}, {"title": "Entity Recognition", "content": "Through the definitions in the conceptual layer of experts, we used Colaber's labeling tool to quantify each entity type,\nas shown in Table 1.\nThe commonly used evaluation metrics for the named entity task in this study are accuracy P, recall R, and F1 score:A\nPython script was then used to convert the ann-brat format to the BIO format, which is often used as the standard\nformat for named entity recognition tasks. The training, validation, and test sets were divided in the ratio of 8:1:1 and\nplaced into the deep learning model for training, validation, and testing. The commonly used evaluation metrics for the\nnamed entity task in this study tour accuracy P, recall R, and Fi score. The accuracy rate indicates the proportion of true\npositive samples among the entities recognized by the model. The recall rate indicates the proportion of all positive\nsamples that are correctly identified. The F1 score is the reconciled mean of the accuracy and recall rates. It is shown in\nthe following equation.\n$P = \\frac{TP}{TP + FP}$\n$R = \\frac{TP}{TP + FN}$\n$F1 = \\frac{2 \\times P \\times R}{P + R}$"}, {"title": "Comparison of Different Entity Recognition Methods", "content": "We compared five modeling approaches: DERM-ROBERTa-Large-BiLSTM-CRF, Roberta-large-BiLSTM-CRF [?],\nDERM-BERT-Large-BiLSTM-CRF, and Word2vec-BiLSTM-CRF [?]. The hyperparameters were set as follows:\n\u2022 Batch size: 40\n\u2022 Epochs: 20\n\u2022 Learning rate: $10^{-5}$\n\u2022 LSTM hidden layers: 128\n\u2022 Maximum sentence length: 50\nThe results show that RoBERTa-large-BiLSTM-CRF achieved the highest F1 score of 94.65%, while the same model\nwithout DERM achieved 90.34%, demonstrating a 4 percentage point improvement and proving the effectiveness of\nDERM.\nTable 5 illustrates the performance of DERM-ROBERTa-BiLSTM-CRF for seven significant entities within the test\ndataset. The Operation entity achieved the highest F1 score of 100%, while the Symptoms entity recorded the lowest\nwith an F1 score of 86.06%. This result demonstrates the model's capacity for generalization in small sample datasets.\nHere is the provided content converted into LaTeX format:"}, {"title": "Knowledge Fusion", "content": "Figure 5 illustrates the process of entity fusion in the knowledge graph of medicine-seeking. Initially, this knowledge\ngraph is imported into Neo4j, consisting of six entity types: disease, food, department, drug, examination, and\nsymptom. These entities are then normalized. The graph includes eight types of relationships: appropriate food (disease-\nfood), contraindicated food (disease-food), department affiliation (department-belong), common drugs (disease-drug),\ndiagnostic examinations (disease-examination), symptoms (disease-condition), complications (disease-disease), and\ndepartmental association (disease-department).\nFor disease entity recognition, the EMR-based knowledge graph is first utilized to pinpoint all disease entities.\nSubsequently, a specific disease entity is queried using the www.XYWY.com disease entity library, employing a\nTF-IDF vectorizer to determine the highest cosine similarity match, with a minimum threshold of 0.8. For example,\nproto-hepatocellular carcinoma in the EMR aligns with primary hepatocellular carcinoma in www.XYWY.com. In\nNeo4j, the disease node of proto-hepatocellular carcinoma is replaced, establishing a new relationship with the patient\nID and the corresponding entity node. Similarly, disease nodes in the original patient record are replaced with nodes\nfrom the medicine-seeking graph whenever possible, while unmatched nodes are temporarily retained for potential\nfuture modifications.\nThus, TF-IDF integration of EMRs with the medicine-seeking knowledge graph enhances its completeness and forms a\nbasis for subsequent tasks like knowledge graph analysis and reasoning."}, {"title": "Application", "content": ""}, {"title": "Screening Basic Diseases for Liver Cancer Patients", "content": "In clinical medicine, potential complication retrieval is essential. For doctors, identifying possible complications\nfacilitates the development of more effective treatment plans, thereby mitigating the risk of complications. For patients,\nawareness of potential complications enhances their adherence to medical advice, encourages lifestyle modifications,\nand prompts timely reporting of any unusual symptoms.\nUtilizing our liver cancer KG, we can efficiently associate patients with diseases and diseases with complications in the\nform of triples. This approach streamlines the retrieval of potential complications for subsequent patient assessments.\nNeo4j Bloom allows users to customize advanced query phases through the 'Search phrase' function. Users can\npre-define static search templates without parameters or templates with parameters and then specify the phrases based\non these templates to implement the query. As shown in Figure 9, it's quick and easy to search for a disease that is\naccompanied by a patient's disease."}, {"title": "Discussions", "content": ""}, {"title": "Performance Evaluation", "content": "During the design process of the conceptual layer, experts in liver cancer diagnosis were invited to participate in the\nentity definition and structural design. In addition, the design of the conceptual layer was revised in multiple rounds\nwith reference to domestic and international guidelines for liver cancer treatment.\nWhen the data layer was constructed, entity extraction was performed based on deep learning. To facilitate side-by-side\ncomparison of model performance during model training, we set the same dataset of random seeds and parameters during"}, {"title": "Data Sources", "content": "The dataset mainly consists of three parts:\n1. 310 unstructured electronic medical records of liver cancer patients from ZhuJiang Hospital of Southern\nMedical University Hospital.\n2. A semi-structured medical dataset from www.XYWY.com, containing information about diseases, treatments,\ndepartments, and complications.\n3. Structured data from professional datasets such as CCMT, which provide professional clinical medical\nterminology.\nThe first part contains rich information but also noisy data, requiring more work for entity extraction. The second part,\nfrom the XYWY.com website, requires crawler scripts for ternary information extraction. The third part provides highly\nprofessional data but requires a doctor's guidance due to its complexity."}, {"title": "Conclusion", "content": "The primary contribution of this study lies in the development of a workflow for extracting knowledge graphs from\nChinese EMRs to guide the construction and use of Traditional Chinese Medicine knowledge graphs for disease\ndiagnosis and treatment. In this research, we designed the conceptual layer of the knowledge graph by referencing\nguidelines for primary liver cancer treatment and consulting with experts.\nWe employed the DERM-ROBERTa-BiLSTM-CRF model to extract entities such as patients, examinations, symptoms,\nand treatments from EMRs. Compared with the baseline model, the F1 score improved by 4.3%. We standardized these\nentities using CCMT and integrated them with XYWY.com for knowledge fusion. Finally, the triples were imported\ninto the Neo4j database. This study provides a reference for the rapid design and construction of knowledge graphs for\nthe diagnosis and treatment of other diseases."}]}