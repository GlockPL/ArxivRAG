{"title": "M20E: Multimodal Collaborative Expert Peptide Model", "authors": ["Zengzhu Guo", "Zhiqi Ma"], "abstract": "Peptides are biomolecules comprised of amino acids that play an important role in our body. In recent years, peptides have received extensive attention in drug design and synthesis, and peptide prediction tasks help us better search for functional peptides. Typically, we use the primary sequence and structural information of peptides for model encoding. However, recent studies have focused more on single-modal information (structure or sequence) for prediction without multi-modal approaches. We found that single-modal models are not good at handling datasets with less information in that particular modality. Therefore, this paper proposes the M20E multi-modal collaborative expert peptide model. Based on previous work, by integrating sequence and spatial structural information, employing expert model and Cross-Attention Mechanism, the model's capabilities are balanced and improved. Experimental results indicate that the M20E model performs excellently in complex task predictions.", "sections": [{"title": "I. INTRODUCTION", "content": "Peptides, which are composed of amino acids, play pivotal roles in the modulation of physiological processes within the body. In contrast to proteins, peptides consist of shorter chains of amino acids[1]. The prediction of peptide properties entails forecasting their physicochemical characteristics, functions, and biological activities through advanced computational methods that have significantly evolved with the advent of deep learning techniques[2][3][4]. Recently, there has been a growing interest in peptides for drug design applications, particularly in the development of antimicrobial and anti-cancer agents due to the increasing prevalence of antibiotic resistance[5][6][7].\nTypically, peptide encoding encompasses both the primary amino acid sequence and its spatial structure. Previous models, including RNN[8], LSTM[9], BiLSTM[10], and Transformer[11], indicate that the Transformer architecture is particularly effective in this context. Additionally, peptides can be represented as graph structures, rendering Graph Neural Networks (GNNs) instrumental for capturing molecular spatial information[12]. However, most studies predominantly focus on single-modality data, either sequence or structure,and even contrastive learning techniques often lack a genuine integration of these modalities[13].\nMultimodal models have achieved significant advancements, especially within the AI4Science domain. For instance, GIT-Former [14] integrates graphical, imaging, and textual information to enhance prediction accuracy in molecular science; meanwhile, Mixture of Experts (MoE) models such as GMoE[15] and SwitchTransformer[16] optimize token allocation to improve adaptability. Despite these advancements, multimodal fusion continues to encounter challenges-particularly regarding the refinement of fusion methods for enhanced integration.\nTo enhance model performance, our M20E model builds upon previous research by employing a mixed expert framework for embedding, which integrates multiple expert models to achieve more accurate task predictions[17][18][19]. This paper presents a multimodal collaborative expert peptide model with the following key contributions:\n1. We propose a sequence-structure mixing expert model that addresses the challenge of expert allocation [20].\n2.We leverage multimodal characteristics to improve mixed expert representation through interactive attention networks.\n3. We utilize learnable weights a to evaluate the significance of sequence and spatial information across various data distribution scenarios."}, {"title": "II. METHODS", "content": "The benchmark dataset utilized in this study is derived from Liu et al. [21]. According to the task division, the datasets encompass classification and regression tasks, which include antimicrobial peptides (AMP) [22] and aggregation propensity (AP) [13]. The processing of these two types of datasets aligns with previous work [21], having been partitioned into training, validation, and test sets at a ratio of 8:1:1.\nPeptide sequences $S \\subset \\mathbb{R}^{M}$ and sentence data are similar in that both require word-base embedding and positional identification combination as input. However, the difference is that the division of peptide sequences is based on amino acids and does not require complex tokenizer like natural language. Multi-head Self Attention (MSA) is the core in the Transformer which scores the context and captures various dependencies within the sequence. Feed Forward (FFN) combines with nonlinear activate function and additional trainable parameters, further capture non-linear relationships between amino acids and mapped to higher dimension. The sequence encoder output amino acids feature is represented as $s \\in \\mathbb{S}^{M \\times d}$, where d is feature hidden dimension.\nThe peptide molecule is defined as $G = (\\nu, \\varepsilon)$, where $\\nu = \\{v_{i}\\}_{1}^{N}$ represents the beads as nodes and $\\varepsilon \\subset \\nu \\chi \\nu$ represents the existence of chemical bonds between the beads as edges. Adjacent matrix $A \\in \\{0, 1\\}^{N \\times N}$ describes the relationship between nodes and is filled with 0 or 1 based on their corresponding edges, $A_{ij} = 1$, when it is existing connection $(i, j) \\in \\varepsilon$, otherwise $A_{ij} = 0$. Given feature adjacent X and join with adjacent A, GCN[12] leverages relative edges and nodes attribute to learn latent representation of the node. One layer graph convolutional encoder represents as follow:\n$X^{(l+1)} = f_{GCN}(A, X^{(l)}; W^{(l)}) = \\sigma(\\tilde{A}X^{(l)}W^{(l)})$, (1)\nwhere $f_{GCN}$ is GCN encoder function, $\\tilde{A} = A + I$ add diagonal matrix to keep and transmit the information of the node itself, $\\hat{A} = D^{-\\frac{1}{2}}A D^{-\\frac{1}{2}}$ is to normalize the adjacency matrix. $W^{(l)}$ represent the learnable weight matrix of the l-layer of the model and $\\sigma$ is a non-linear activate function LeakyRelu. The Initial values $X^{(0)}$ are randomly initialized using a normal distribution and the final output by GCN is represented as $X \\in \\mathbb{R}^{N \\times D}$ where D donates each node embedding dimension."}, {"title": "C. Sparse Cross Mixture of Experts", "content": "As shown in Figure 1, the parallel Transformer and SAGE-Graph capture the primary peptide sequence information and the secondary molecular structure information. However, sequence information and structural information can represent and complement each other. Therefore, we have designed a sparse interaction mixed expert system (SCMoE) fusion module.\nThe SCMOE model contains C sequence mixing experts and graph mixing experts, which can learn from tokens routed by different types of data through the expert network. In particular, the interactive attention network possesses the ability to focus on different modalities directly, endowing the mixing experts with stronger representational capabilities through this multimodal alignment approach. Specifically, the routing network is controlled by a learnable matrix $W'' \\in \\mathbb{R}^{d \\times C}$, which calculates the similarity between each token and the mixing experts, and assigns them to the topk most similar experts. The formula 2 shows this allocation method, where $X_{ij}$ represents assigning the i-th token to the j-th expert with a coefficient of $\\alpha$.\nHowever, using the Top k allocation method alone may result in some tokens never being assigned to experts, thus reducing the expressive power of the expert system[23]. To address this issue, a stochastic variable sampled from the standard normal distribution is added, allowing tokens ranked after K to also have a chance for allocation.\n$Router(X_{i}) = Topk(\\alpha_{j} X_{ij} + N(0, 1) \\cdot Softplus(X_{ij}W_{noise}))$ $Aj = \\frac{exp(X_{ij}W)}{\\sum_{v \\subset V} exp(X_{iv} W)}$, (2)\nAmong them, $W_{noise} \\in \\mathbb{R}^{d \\times C}$ are learnable parameters and $Softplus(\\cdot)$ is a nonlinear activation function can prevent the problem of vanishing gradients.\nThe peptide sequence is composed of multiple amino acid symbols, so each character can be used as a local feature. The combination of local features assigned to the mixed experts implicitly expresses certain characteristics of the peptide sequence. However, relying solely on single-modal information makes it difficult to directly learn the implicit characteristics of peptides. Therefore, the Cross-Attention (CRA) is proposed to improve the MoE[14]. It can align similar characteristics between modalities while also drawing away different characteristics. Specifically, it can be represented as follows:\nwhere $F_{seq}, F_{gra}$ denote features from the sequence encoder and graph encoder, and $d_{k}$ is the scaling factor respectively. Subsequently, we exchange the queries Q of the two modalities for spatial interaction:\n$\\Gamma_{f_{gra}} = Softmax(\\frac{Q_{seq}K_{gra}^{T}}{\\sqrt{d_{k}}})V_{gra}$,\n$\\Gamma_{f_{seq}} = Softmax(\\frac{Q_{gra}K_{seq}^{T}}{\\sqrt{d_{k}}})V_{seq}$ (3)\nSubsequently, the cross-attention matrices of the two modalities are transformed and updated. The new sequence features are composed of graph node features and their corresponding attention coefficients. The updated interactive features also need to be allocated to different experts, similar to the formula2. Therefore, the updated sequence features can be integrated into the routing network through the operation $F_{f_{rew}} = Concat(F_{seq}, \\Gamma_{f_{seq}})$, as do the graph node features."}, {"title": "D. Fusion Module And Loss", "content": "The antimicrobial peptide prediction task is conducted based on the sequence and its spatial structure. Our designed SCMoE module ensures the expression of characteristics of each modality and enhances the expression of potential features with the help of information from another modality. Therefore, the final fusion module only needs to utilize the nonlinear capability of MLP to capture the correlation between features and map them to the classification space of antimicrobial peptides. Traditional methods often involve combining multiple output results using fixed weights, but this approach is limited in that it is difficult to assess the importance of sequence and spatial information for prediction under different data distribution scenarios. As shown in formula 4, we employ learnable weights $\\alpha$ to measure this importance.\n$\\hat{y} = \\sigma(\\alpha MLP_{1}(Z_{seq}) + (1 - \\alpha)MLP_{2}(Z_{gra}))$ (4)\nAmong them, $\\sigma$ is Sigmoid function, mapping predictive data into the probability space. $Z_{seq}, Z_{gra}$ are embeddings of the output from the sequence encoder and the graph encoder.\nThe routing network assigns tokens to experts based on the gating method, but this approach can sometimes lead to load imbalance issues, where one expert receives the majority of tokens, thereby degenerating into a single-expert model. Therefore, a strategy designed to ensure that each expert has an equal probability of being selected is formulated as shown in Equation 5. On the other hand, the capabilities of each expert are different, and the routing network tends to allocate tokens to the few experts with stronger capabilities, leaving the remaining experts idle, which similarly leads to load imbalance issues. As shown in Equation 6, the $CV(\\cdot)$ function measures the degree of discreteness of expert importance, combined with fixed hyperparameter $W_{imp}$ to control the similar abilities of different experts.\n$L_{load} = \\sum_{i=1}^{C}(\\frac{N_{i}}{\\sum_{j=1}^{C} N_{j}} - \\frac{1}{C})^{2}$ (5)\n$L_{importance} = W_{imp} \\cdot CV(\\sum_{x \\in X} Router(x))$,\n$CV(X) = \\frac{\\sigma_{X}}{\\mu_{X}}$ (6)\nAmong them $\\sigma_{X}$ and $\\mu_{X}$ are the variance and mean of data X.\nFinally, the error between the predicted values and the true labels is calculated using the Binary Cross Entropy (BCE), and this is added to the balanced loss function of Mode of Expertise (MoE) regarding load and importance as the total optimization objective.\n$L = BCE(y, \\hat{y}) + L_{Load} + L_{importance}$ (7)"}, {"title": "III. RESULTS AND DISCUSSION", "content": "We propose the M2oE model, which effectively balances and integrates sequence and structural features for downstream tasks. This model encompasses three types: sequence, graph, and hybrid models. The sequence and graph models are single-modality frameworks evaluated on classification (AP) and regression (AMP) datasets. For the sequence model, we employ Transformer and SwitchTransformer architectures, while the graph model utilizes GCN, GAT, GraphSAGE, and GMOE [16], [15]. The hybrid model incorporates Repcon, weighted fusion M20E methods, concatenation techniques, as well as our final approach.\nTable III illustrates that the sequence model demonstrates superior performance on the AP dataset; notably, SwitchTransformer achieves an impressive R2 of 95.1%. Conversely, on the AMP dataset, GraphSAGE leads with an accuracy of 84.7%. These findings suggest that single-modality models excel when a dataset is biased towards one modality but encounter challenges when it favors another.\nThe M2oE model synergistically combines the strengths of both sequence and graph models to achieve remarkable performance across both datasets: R2 = 0.951 on AP with minimal MAE and MSE values (3.68E-2 and 2.21E-3), alongside an accuracy of 86.2% on AMP-surpassing baseline results.\nWhile MoE enhances performance in single modalities independently without benefiting other modalities directly; therefore we implement Cross-Attention to ensure balanced improvements across modalities. Ablation experiments presented in Table II corroborate this assertion. Ultimately demonstrating that M20E achieves optimal results by improving upon baseline metrics by 0.9%."}, {"title": "IV. CONCLUSION", "content": "In this paper, we propose a multimodal collaborative expert peptide model, which integrates sequence and spatial structural information, utilizes a sparse mixed expert model, and takes into account the characteristics under different data distributions. Experimental results show that the M20E model performs well in complex task prediction, and uses multimodal methods to solve problems that may arise in unimodal scenarios. Finally, we use ablation experiments to demonstrate the effectiveness of each module. In future work, we can also consider connecting the multimodal expert model to more complex tasks, such as peptide generation tasks, etc."}]}