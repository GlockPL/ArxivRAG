{"title": "Supervised and Unsupervised Alignments for Spoofing Behavioral Biometrics", "authors": ["Thomas Thebaud", "Ga\u00ebl Le Lan", "Anthony Larcher"], "abstract": "Biometric recognition systems are security systems based on intrinsic properties of their users, usually encoded in high dimension representations called embeddings, which potential theft would represent a greater threat than a temporary password or a replaceable key. To study the threat of an embedding theft, we perform spoofing attacks on two behavioral biometric systems (an automatic speaker verification system and a handwritten digit analysis system) using a set of alignment techniques. Biometric recognition systems based on embeddings work in two phases: enrollment - where embeddings are collected and stored then authentication - when new embeddings are compared to the stored ones -. The threat of stolen enrollment embeddings has been explored by the template reconstruction attack literature: reconstructing the original data to spoof an authentication system is doable with black-box access to their encoder. In this document, we explore the options available to perform template reconstruction attacks without any access to the encoder. To perform those attacks, we suppose general rules over the distribution of embeddings across encoders and use supervised and unsupervised algorithms to align an unlabeled set of embeddings with a set from a known encoder. The use of an alignment algorithm from the unsupervised translation literature gives promising results on spoofing two behavioral biometric systems.", "sections": [{"title": "I. INTRODUCTION", "content": "THE generalization of biometric recognition systems and growing concerns about data privacy lead to special attention being given to attacks on personal data. In Europe, the General Data Protection Regulation [1] states that any biometric data should benefit from special protection. Most biometric recognition systems [2] use personal data such as face images [3], voice extracts [4], handwriting [5], [6], gait [7] or fingerprints [8]. The discriminative information of the users contained in those data is usually extracted in high dimensional vectors called embeddings, using deep neural networks, named feature extractors. It has been shown [3], [9] that with access to the feature extractor and a set of embeddings, one can reconstruct personal data. Furthermore, some advances have been made toward template reconstruction attacks without access to the feature extractor [10], using a second extractor and an unsupervised alignment.\nThe significance of the risks facing biometric-based security systems cannot be overstated. Unlike passwords and keys, which can be changed if compromised, biometric modalities are derived from immutable characteristics of individuals, such as their voice or physical features. This singular nature of biometric data underscores the necessity for specialized protection measures. The primary objective of this document is to demonstrate the potential vulnerabilities within these systems, thereby establishing a precedent for implementing additional security measures across various scenarios, know- ing that compliance with European regulations [1] compels companies to integrate supplementary layers of security in response to identified risks.\nIn this document, we study more extensively the threat of embeddings theft by performing template reconstruction at- tacks against behavioral biometric systems across two modal- ities: speech and handwriting. Most template reconstruction attacks leverage a type of access to the model that encoded the templates, the encoder (white box attacks for full access to the model architecture and weights, black box access for only access to inputs and outputs). In this paper, we consider a harder task: the attack of an inaccessible encoder, for which only the architecture is known by the attacker, which mean the attack is performed on a proxy encoder of the same archi- tecture, then transferred to the victim encoder. Because two different encoders produce embeddings in different vectorial spaces, we estimate the relation between the proxy encoder's embeddings and the victim encoder's embeddings using an alignment function. The scope of this document is limited to rotational alignments. We explore both unsupervised [11] and supervised [12] alignment techniques, respectively, to show how far a realistic attack could go, and to study the limits of rotational alignments when attacking those behavioral biometric systems.\nThe main contributions of this document can be summarized as:\n1) To the extent of our knowledge, we propose the first template reconstruction attack on the handwriting modal- ity, using a LSTM-MDN decoder for the handwriting reconstruction.\n2) We show how to perform template reconstruction attacks on systems where the attacker doesn't have black-box nor white-box access to the model, but only the knowledge of its architecture, using unsupervised embedding align- ments, and measure the impact of this attack scheme on two different behavioral biometrics: speech and handwrit- ing.\n3) We study the limits of such alignment techniques by using supervised embedding alignments in an oracle setting for both modalities.\nThe section II presents the related works in behavioral"}, {"title": "II. RELATED WORKS", "content": "THIS section presents the previous works that have been done about behavioral biometric systems, template recon- struction attacks, and statistical alignments.\nA. Behavioral Biometric Systems\n1) Biometrics: authentication systems are usually classified into three categories [13]:\n1) knowledge (f.e. password-based systems)\n2) possessions (keys, cards, or electronic devices)\n3) biometrics (face, fingerprint, voice, handwriting,..)\nFor the latest, we can distinguish two sub-categories [14] :\n\u2022 physiological biometrics : based on specific body parts such as fingerprints [8], [15], vascular system [16]-[18] or face images [3], [19]\u2013[21].\n\u2022 behavioral biometrics: based on the behavior, such as speaking [4], [22]\u2013[24], walking [7] or writing [5], [25], [26].\nIn this article, we will focus on two behavioral biometrics: speech and handwritten digit analysis.\n2) Automatic Speaker Verification: the action to verify that the identity of a given speaker is the one claimed is called Speaker Verification. The first embedding based systems appeared in 2010 [27], originally based on statistical mod- els [28]-[30], they were then replaced by neural networks [4], [31]. The improved performances brought by Residual Net- works [32](ResNet) on image recognition, were transposed to speaker verification [33]. We are using two variations of the ResNet34 [33]: the Half ResNet34 and the Fast ResNet34 [34], where the size of each layer is respectively a half and a quarter of the original layer size. Instead of the 22 million of parameters of the original ResNet34 [33], the Fast version have 1.4 million of parameters, making it faster to train. Trained on the train split of VoxCeleb1 [35] and VoxCeleb2 [36] datasets, both presented in section III-B, and evaluated on the test split of VoxCeleb1-O, they respectively achieve an EER of 1.67% and 2.78%.\n3) Handwritten Digit Analysis: the literature for handwrit- ten digit authentication systems is less furnished than speaker verification: most publications focus on digit identification rather than the user, using highly known datasets such as MNIST [37].\nThe latest system known to propose a joined identification of the digit and verification of the speaker is the system proposed in [5], based on Bi-LSTM [38], LSTM networks [39] that are used to read an ordered sequence of vectors in both directions. The Bi-LSTM digit analysis system achieves an EER of 4.9% over 4 digits, and 12.5% when trained on the eBioDigit dataset [40] and a private dataset, both presented in section III-A.\nB. Reconstruction of Speech and Handwriting\nThere is a wide range of systems used for data recon- struction and generation, but we are focusing on speech and handwriting reconstruction systems.\n1) Speech Reconstruction: the reconstruction of speech is usually made either by synthesis of artificial speech from the text - Text-To-Speech [41], [42] - or by tampering with speech utterances to modify some of their non-linguistic properties - Voice Conversion [43]-[46]. To spoof text-independent ASV systems it is necessary to produce speech utterances containing the targeted speaker's information, but no given linguistic information, so we focused on Voice Conversion systems.\nSuch systems can be characterized by their capabilities to work from the voice of one or many speakers, toward the voice of one or many speakers, seen or not. For a spoofing attack, we need a many-to-many zero-shot system. Many-to-many means it is able to reconstruct the voice of many speakers from utterances produced by any speaker. Zero-shot means it works even if the speaker has never seen before. One of the Voice Conversion systems respecting those conditions is AutoVC [46]. This system is based on an auto-encoder [47] that compresses a spectrogram to a high-dimension vector small enough to contain only linguistic information and no speaker information [46]. It then uses an x-vector [4] from the targeted speaker to reconstruct a spectrogram as uttered by the said speaker. AutoVC is trained with the VCTK [48] dataset, presented in section III-B.\nFacing poor performances in a spoofing scenario, a way to improve has been proposed, using a reconstruction loss to force the reconstructed utterance to have the same x-vector as the chosen target speaker [9]. From a given target x-vector produced by an available speech feature extractor (such as a Fast ResNet34 [34]), it can use a random speech utterance to produce an utterance able to spoof the given speech feature extractor.\n2) Handwriting Reconstruction: as handwriting analysis systems are based on dynamic drawings rather than fixed images, we focused our research on systems being able to reconstruct sequences of points in two dimensions.\nGraves [49] has shown how sequences of points can be reconstructed from a high dimensional vector using a Long Short Term Memory Network (LSTM [50]) to reconstruct one point at a time. To improve fast accelerations for situations where the drawer has to lift the pen or do a sharp angle, the use of Mixture Density Networks(MDN [51]) was proposed by [49]. For each time step, an LSTM-MDN reconstructs a Gaussian Mixture Model [52] describing the probability distribution of the next point.\nAnother reconstruction system for handwritten drawings is DeepWriteSyn [53]: using short strokes, reconstructing to"}, {"title": "C. Supervised and Unsupervised Rotational Alignments", "content": "To link known and unknown spaces of embeddings, we use alignment algorithms, that will find the function that minimize the distance between those two spaces. In this paper, we choose to restrain this function to the manifold of rotations, as they are linear and reversible by definition, and restraining the space of possible solutions will make the computations faster.\nWe use two algorithms, crafted to find optimal alignment function in the rotation manifold: Procrustes analysis [12] - a supervised alignment algorithm - and the Wasserstein Procrustes Analysis [11] - an unsupervised version developed from the first one - both being detailed in this section.\n1) Supervised Rotational Alignments: one famous algo- rithm is Procrustes Analysis [12]: considering two lists of N vectors $X \\in R^{N \\times D}$ and $Y \\in R^{N \\times D}$ in D dimensions, it computes quickly the rotation matrix $W_{procrustes} \\in R^{D \\times D}$ that optimally reduces the Euclidean distance between both sets, using the singular value decomposition (SVD) of $X \\times Y^T$, where U and V are orthonormal matrices composed of the left and right singular vectors of the matrix ($X \\times Y^T$) and $\\Sigma$ being the diagonal matrix containing the corresponding singular values:\n$SVD(X \\times Y^T) = U \\Sigma V^*$\n$W_{procrustes} = U \\times V^*$\n2) Unsupervised Rotational Alignments: for the situations where the sets of vectors would not be ordered, or where there would not even be a one-to-one correspondence or the same number of vectors, we propose to use the Wasserstein Procrustes Algorithm [11]. This algorithm, taken from the unsupervised translation literature, aligns two sets of embed- dings by doing a stochastic training of a matrix to minimize the Wasserstein [54] distance between subsets of X and Y. Subsets of the same size are randomly selected from X and Y, and by gradually increasing the size of the subsets through a significant number of epochs, the rotation converges toward an optimal alignment. Because this alignment does not use any prior hypothesis over the order of the embeddings used, their number, or their distribution in the space, we found it to be adapted to the alignment of user discriminant embeddings such as the ones used in this paper."}, {"title": "D. Template Reconstruction Attacks", "content": "An embedding based biometric recognition system [2] works in two phases :\n1) The Enrollment phase: when a user registers by giving a few pieces of biometric data, from which are computed a set of embeddings that will be stored and constitute the template of this user.\n2) The Authentication phase: when a registered user wants to authenticate, he gives a new utterance, and a new embedding is computed, which will be compared to the stored template.\nA template reconstruction attack is a type of spoofing attack where an attacker uses the enrollment template of a user to reconstruct the original data it was extracted from. Then, the attacker can use it to impersonate the user during the authentication phase, which effectively spoof the system.\nMost template reconstruction attacks suppose the attacker has access to the feature extractor as well as the set of attacked templates [3], [9] Known attacks have been performed on various systems with different kinds of access to their feature extractors.\n1) Evaluation of a Template Reconstruction Attack: authen- tication systems are not perfect, their mistakes are separated between the false acceptations and the false rejections. Under a normal behavior (not under attack), the metric used to show the number of false acceptations over the number of attempts is the False Acceptation Rate (FAR). To measure the performance of an attack, we set up the attacked authentication system to have a FAR against any sample fixed to a given threshold $\\tau \\in R$, and then measure the FAR against spoofing samples. We name this metric the Spoofing False Acceptation Rate for a given $\\tau$ ($SFAR_{\\tau}$). In this paper we set the threshold either at 1% like in previous papers [3], [10], or equal to the EER of the attacked system: $SFAR_1$ or $SFAR_{EER}$.\n2) Previous Attacks Performances: Thebaud et al. [9] pro- posed a template reconstruction attack on a speaker verification system using voice conversion and a black box access to the attacked feature extractor. They achieved up to 99.74% of $SFAR_{EER}$, for an EER of 2.31%. To go further, Mai et al. [3] proposed a template reconstruction attack using a Generative Adversarial Network [55] and a black box access to the attacked feature extractor. They achieve up to 95.29% $SFAR_1$. Finally, we can cite [10] that proposed two template reconstruction attacks on a handwritten digit analysis system, either with a black box access, or access to another network and an unsupervised alignment. They achieved up to 87.48% $SFAR_{EER}$ for the black box system, and 21.07% $SFAR_{EER}$ without access to the system, for an EER at 20.18%."}, {"title": "III. DATASETS", "content": "THIS section presents the different datasets of handwritten digits and speech utterances used throughout the article.\nA. Handwritten Digit Datasets\nThe digit datasets are constituted of handwritten digits drawn on the touchscreen of mobile phones and tablets by various users. Every dataset used has a balanced amount of digits for each user. A drawing itself is a sequence of points in at least two dimensions, some datasets include the pressure of the finger, but we won't use them in this work because it was not included in all the datasets we used. Three datasets are used in this article: eBioDigit [40] and MobileDigit [25],"}, {"title": "IV. THREAT MODEL", "content": "THIS section presents the threat model and the attack scenarios considered. We propose a template reconstruc- tion attack of a behavioral biometric recognition system. As exposed in [57] and [9], we consider an embedding-based au- thentication system: using a trained target encoder $Enc_{target}$ that has been trained on a dataset $D_{train}^{target} \\subseteq D^{target}$. The system is already being used by a set of users $U_{target}$, meaning they already gave biometric data $D_{enroll}^{target}$ to compute an enrollment set of embeddings $E_{target}$ of dimension $D \\in N^*$ that is being stored by the system. The composition of the data sets and the user sets used by the attacked system are unknown to the attacker, so every dataset used by the attacker should contain a disjoint set of users from the training and enrollment sets of the target encoder. However, we supposed the attacker knows the biometry used for every attack: speech or handwritten digits. We consider several attack scenarios where the attacker would have different knowledge of the attacked system :\n1) Black-Box scenario: the attacker can use the encoder, but does not have information about its weights and parameters.\n2) Architecture-Only scenario: the attacker does not have access, but does know the architecture of the encoder used.\nIn every scenario, we suppose the attacker stole the non- encrypted set of enrollment embeddings. The goal of the attack is to reconstruct biometric data as if it was produced by a given user, having access to one of his embeddings.\nTo reconstruct the data, the attacker will use a decoder $Dec$ trained on a dataset of parallel biometric data $D_{enroll}^{attack}$ and embeddings $E_{attack}$. The embeddings have been produced by an attack encoder $Enc_{attack}$ trained on another set of data $D_{train}^{attack} \\subseteq D^{attack}$. We suppose that the embeddings spaces constituted by the outputs of the two encoders considered are not exactly the same, so we expect a drop in the spoofing performances if an attacker was to use directly the decoder on the stolen set of embeddings $E_{target}$, thus we consider a rotation alignment $W \\in R^{D \\times D}$ that is made to minimize the distance between the $E_{target}$ and the $E_{attack}$ sets.\nIn the following section, for each scenario and each modal- ity, we detail the architecture of both encoders, the decoder, and the alignment used, as well as the way the different datasets are split in the corresponding section. Scenarios will be split by modality and presented across the two following sections. The scenarios are represented in Figure 2, with the encoders presented that are already trained, so none of the training datasets ($D_{train}^{attack}$ and $D_{train}^{target}$) are present on the schematic."}, {"title": "V. ATTACKING A HANDWRITTEN DIGIT ANALYSIS SYSTEM", "content": "THIS section presents the scenarios on the handwritten digit analysis systems, comparing various alignments algorithms and various decoders on a given pair of systems. We follow and improve the results obtained in [10] by using a new unsupervised alignment algorithm and propose an upper bound for the performances of a rotational alignment using an oracle-supervised algorithm.\nA. The Digits Attack Scenario\nThe dataset $D_{digits}^{attack}$, presented in the section III-A, is randomly split into 4 subsets containing each the extract of one quarter of the users. We name those 4 subsets $D_{train}^{target}$, $D_{train}^{attack}$, $D_{enroll}^{target}$ and $D_{enroll}^{attack}$. The two encoders $Enc_{target}$ and $Enc_{attack}$ used in this scenario are both Bi-LSTM [58] followed by a linear layer as presented in [5]. $Enc_{target}$ is trained on the set $D_{train}^{target}$ and $Enc_{attack}$ is trained on the set $D_{train}^{attack}$, the $D_{enroll}$ sets being used for validation. Then, two embeddings sets $E_{target}$ and $E_{attack}$ are respectively computed using the trained encoders $Enc_{target}$ and $Enc_{attack}$ from the sets $D_{enroll}^{target}$ and $D_{enroll}^{attack}$. We suppose an attacker would have access to a stolen set of embeddings $E_{target}$ and would like to reconstruct corresponding drawings (the $D_{enroll}^{target}$ set) using the attack sets of embeddings and drawings as well as the trained $Enc_{attack}$ encoder.\nB. Choosing a Digit's Decoder\nIn this section, we compare two potential decoders: an LSTM and an LSTM-MDN.\n1) The Experiment: the first experiment we propose is comparing the performances of two decoders. As the encoders used are Bi-LSTM, the first decoder $Dec_{LSTM}$ will be an LSTM [39] followed by a linear layer, trained on the sets $D_{enroll}^{attack}$ and $E_{attack}$. Using the embedding to decode as a constant input, it produces for each time step a 3-dimensional output: a 2-dimensional point and a probability of ending the sequence. As the longest drawing in $D_{digits}^{attack}$ has a length of 254, we produce sequences of 254 points and predict the length by taking the highest probability of ending.\nThis second decoder $Dec_{MDN}$ used for comparison is the same as in [10]: an LSTM followed by a Mixed Density Network [49], producing for each point a Gaussian Mixture Model [52] from which the chosen coordinates will be drawn from.\n2) The Metrics: We evaluate the reconstruction performed by the trained decoders using the $D_{enroll}^{target}$ with the encoder $Enc_{attack}$ using two metrics, the accuracy over the prediction of digits, and the $SFAR_{EER}$ explained in the next paragraphs.\na) The Accuracy of the Prediction of the Digits: when given a reconstructed drawing, is the encoder $Enc_{attack}$ able to predict correctly the digit that was drawn? The encoder is able to predict the digit drawn using its last classification layer. With f the function that predict the digit drawn using the encoder $Enc_{attack}$, the accuracy on the $D_{enroll}^{target}$ test set using a given decoder Dec and a given encoder Enc, with $d = Dec(Enc(d))$, is given by the following formula :\n$Acc(D_{enroll}^{target}, Enc, f, Dec) = \\frac{Card(\\{d \\in D_{enroll}^{target} | f(d) = f(d)\\}))}{Card(D_{enroll}^{target})}$ (1)\nb) The Spoofing False Acceptation Rate: ($sFAR_x$, $x \\in$ [0, 100]) when given a reconstructed drawing, would a system set to work at the EER threshold be spoofed? Let $\\tau$ be the threshold for which the False Acceptation Rate is at $x \\%$, and $\\cos$ the function that computes the cosine similarity between two embeddings, and $\\hat{d} = Dec(Enc(d))$ then the $SFAR$ is computed using the following formula :\n$SFAR_x(D_{enroll}^{target}, Enc, Dec, \\tau) = \\frac{Card(\\{d \\in D_{enroll}^{target} | \\cos(Enc(d), Enc(\\hat{d})) \\geq \\tau_x\\})}{Card(D_{enroll}^{target})}$ (2)\nThe Spoofing False Acceptation Rate will be evaluated for $x = 0.1$, $x = 1$, and $x = EER$"}, {"title": "C. Choosing a Digits Alignment", "content": "In this section, we compare multiple linear alignments, in- cluding the possibility of using none, and an oracle-supervised alignment to find the upper limit of rotation alignments.\n1) The Experiment: in this experiment, we use the trained decoder $Dec_{MDN}$ to attack the target encoder $Enc_{target}$. However, because the decoder has been trained on the em- beddings of the $Enc_{attack}$'s output space, we have to provide a domain adaptation to make it work on another vector space. This domain adaptation takes the shape of a linear alignment, trained on the sets of embeddings $E_{target}$ and $E_{attack}$. Because our threat model supposes the attacker has no information on the embeddings of $E_{target}$, we have to use only unsupervised algorithms.\nWe detail the different alignments used in the following paragraphs.\na) The Identity Matrix: for comparison purposes, we will use the identity matrix as an alignment, to measure how would the attack works without any alignment.\nb) Procrustes Analysis in the Center of the Digit Clus- ters: [57] propose an unsupervised method to label clusters of embeddings from a handwritten digit analysis system. If the attacker can get the digit labels for each cluster of the $E_{target}$ embeddings and the $E_{attack}$ embeddings, then the centers of the clusters can be matched. Once the centers of the 10 clusters from each set and the one-to-one correspondence are known, a Procrustes Analysis [12] can be used to generate an alignment matrix W that minimizes the distance between the two sets of points. However, this alignment is based on 10 points in a 512-dimensional space: it is computationally unstable.\nc) Procrustes Analysis and Fine-Tuning: to improve the performances of the previous alignment, we fine-tune it using both $E_{target}$ and $E_{attack}$ sets, considering the matrix as a trainable parameter. As proposed in [57], the fine-tuning seeks to minimize the non-pondered sum of 3 loss functions :\n\u2022 $|log(det(W))|$ to target a determinant of 1.\n\u2022 $||U \u2013 W^TWU||_2$ to keep W orthogonal (its transpose equal its inverse).\n\u2022 $loglikelihood(W,E_{target}, E_{attack})$ to minimize the dis- tance between the sets of embeddings.\nThe first two losses function to ensure that W stays a rotation. The log-likelihood is a function that measures the similarity between a point and a statistical distribution.\nFrom each set of embeddings E*, a GMM [52] is computed to represent the statistical distribution of the set using K Gaussians: $GMM^* = \\{(p_i, \\mu_i, \\Sigma_i) \\in (]0,1[\\times R^D \\times R^{D \\times D}) | i \\in [1, K]\\}$. The log likelihood between an embedding $e \\in E_{target}$ projected by W and a Gaussian $(p_i, \\mu_i, \\Sigma_i) \\in GMM_{attack}$ can be defined as :\n$log N(e, W \\mu_i, \\Sigma_i) = \\frac{1}{2}(K \\log 2\\pi + \\log |\\Sigma_i| + (e \\times W \u2013 \\mu_i)^T \\Sigma_i^{-1} (e \\times W \u2013 \\mu_i))$ (3)\nThen the log likelihood can be computed for the whole GMM using the priors to ponder the average :\n$log N(e, W, GMM_{attack}) = \\sum_{i=1}^{K} \\log exp(\\log(p_i) + \\log(e, W \\mu_i, \\Sigma_i))$ (4)"}, {"title": "VI. ATTACKING A SPEAKER VERIFICATION SYSTEM", "content": "THIS section presents the scenarios on the automatic speaker verification systems, attacking encoders of differ- ent architectures, using variable amounts of information. We use the proposition from [9] for decoding mel-spectrograms from a given x-vector for spoofing ASV systems, but to attack unseen systems, using both supervised and unsupervised algorithms from the previous section for the alignment.\nA. The Speech Attack Scenarios\nIn this scenario we consider two encoders :\n\u2022 the target encoder $Enc_{target}$ for which the attacker will have either black box access or no access.\n\u2022 the attack encoder $Enc_{attack}$ which will be supposedly trained by the attacker, giving him total access to the model.\nBoth encoders are Fast ResNet 34 [34]. The ResNet 34 is an architecture constituted of 34 residual layers [32] initially made for image analysis and then adapted for mel-spectrogram analysis. The \"Fast\" version is constituted of 4 times fewer layers, with 1.4 million parameters instead of 22 for the original model. For their training, the VoxCeleb2 [36] dataset, presented in the section III-B, is split into 2 disjointed subsets containing each an equal number of speakers, respectively named $D_{train}^{target}$ and $D_{train}^{attack}$. The same splitting operation is performed on the VoxCeleb1 [35] dataset to create the $D_{enroll}^{target}$ and $D_{enroll}^{attack}$ subsets, that will respectively be used as validation sets for the encoders $Enc_{target}$ and $Enc_{attack}$. Then, two embeddings sets $E_{target}$ and $E_{attack}$ are respectively computed using the trained encoders $Enc_{target}$ and $Enc_{attack}$ from the sets $D_{enroll}^{target}$ and $D_{enroll}^{attack}$.\nAs in the section V, we suppose an attacker would have access to a stolen set of embeddings $E_{target}$ and would like to reconstruct corresponding speech extracts (the $D_{enroll}^{target}$ set) using the attack sets of embeddings and speech extracts as well as the trained $Enc_{attack}$ encoder. To reconstruct those speech extracts as if they were pronounced by the targeted speakers, the attacker uses a voice conversion system: Au- toVC [46], presented in the section II-B1, used with a spoofing reconstruction loss [9]. The VCTK dataset [48] is split into two subsets: $D_{train}^{dec}$ and $D_{valid}^{dec}$ that contain respectively the first 100 users of the dataset and the 10 remaining ones. This voice conversion system is called $Dec_{vc}$ and will be trained using $D_{train}^{dec}$ and validated using the $D_{valid}^{dec}$.\nOnce the attacker got a trained speech decoder $Dec_{vc}$ and access to a set of embeddings $E_{target}$, its goal is going to be to reconstruct the speech from embeddings to spoof the target encoder. However, the decoder has not been trained on the same embedding space, so it will need an alignment. The experiments described in the next section will compare the spoofing performances of various alignments.\nB. The Speech Alignment Experiments\nIn those experiments, we use the trained decoder $Dec_{vc}$ to attack the target encoder $Enc_{target}$. As seen in the pre- vious section: because the decoder has been trained on the embeddings of the $Enc_{attack}$'s output space, we have to use an alignment to make it work on another vector space. This alignment is trained using either a supervised or an unsupervised algorithm.\na) Unsupervised Training of the Alignment: the Wasser- stein Procrustes algorithm [11] is used to train the alignment, as it was the one giving the best results on the embeddings digits alignments. It is trained on the sets of embeddings $E_{target}$ and $E_{attack}$.\nb) Supervised Training of the Alignment for Measuring the Limits: the supervised Procrustes analysis [12] is used to train the supervised alignment. The goal of using a supervised"}, {"title": "VII. CONCLUSION AND FUTURE WORKS", "content": "In this article, we introduced an innovative approach to con- duct template reconstruction attacks on behavioral biometric systems, focusing on handwritten digit analysis systems and automatic speaker verification systems. Our analysis covered two distinct modalities, allowing us to draw more compre- hensive conclusions. Leveraging both supervised and unsu- pervised alignment techniques, we demonstrate the ability to reconstruct users' voices and handwriting from their templates, even without any knowledge of the encoder used to generate these templates.\nIn our research, we conducted a series of experiments using supervised alignments between sets of embeddings from two different encoders: one unseen and the other with white box access. The results of these experiments revealed that the intrinsic information contained within the templates remains independent of the encoder used. Furthermore, we employed unsupervised alignments to perform the same operations, achieving comparable performance to the supervised scenar- ios. This finding highlights that even with less information, potential attackers can achieve similar spoofing acceptation rates, underlining the security risks associated with stolen templates and the possibility of unauthorized access through spoofed biometric data.\nAs the adoption of behavioral biometrics continues to grow across various domains, it becomes imperative to proactively address template-based threats. One such known solution is bio-hashing, which could prove effective in mitigating such attacks by shuffling the templates space in a user-dependent manner. However, future research should delve into investigat- ing the efficacy of alignment techniques against networks of different architectures to gain a better understanding of their limitations and explore potential countermeasures against these attacks. Another axis of research would be to extend those study to more behavioral biometrics, such as the gait, or to a new category: physiological biometrics.\nIn conclusion, our study sheds light on the vulnerabilities of behavioral biometric systems concerning template recon- struction attacks. By examining two different modalities and"}]}