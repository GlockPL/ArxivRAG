{"title": "Can LLMs plan paths in the real world?", "authors": ["Wanyi Chen", "Meng-Wen Su", "Nafisa Mehjabin", "Mary L. Cummings"], "abstract": "As large language models (LLMs) increasingly integrate into vehicle navigation systems, understanding their path-planning capability is crucial. We tested three LLMs through six real-world path-planning scenarios in various settings and with various difficulties. Our experiments showed that all LLMs made numerous errors in all scenarios, revealing that they are unreliable path planners. We suggest that future work focus on implementing mechanisms for reality checks, enhancing model transparency, and developing smaller models.", "sections": [{"title": "1 Introduction", "content": "In early 2024, Volkswagen premiered the first vehicle with ChatGPT integrated into its voice assistant (Volkswagen 2024). Volkswagen claimed that its ChatGPT-enabled voice assistant could be used to control the infotainment, navigation, and air conditioning, or to answer general knowledge questions (Volkswagen 2024). Soon after, Mercedes-Benz, BMW, and Hyundai all announced plans to install voice assistants powered by LLMs in vehicles (Hawkins 2024). If LLM-powered voice assistants are to control vehicle navigation, it becomes important to assess whether the LLMs can plan paths in the real world.\nTo investigate this, we tested three LLMs of various sizes: GPT-4, Gemini, and Mistral. We created six path-planning scenarios, including typical vehicle-based paths but also visual landmark paths for pedestrians. Each scenario included finding a path from a local university campus starting point to a destination of interest, sometimes with time constraints. Each LLM was tasked to generate turn-by-turn instructions or instructions based on visual landmarks. We analyze their results and discuss whether LLMs can be reliable path planners in the real world."}, {"title": "2 Background and related work", "content": "Recently, there has been a surge of interest in exploring whether LLMs can plan paths. Effective and efficient path planning is a paramount challenges in robotics (Latif 2024). Traditional path-planning algorithms suffer from memory and computational inefficiencies as the map size increases (Meng et al. 2024). Therefore, researchers search for alternatives, and LLMs have captured their attention as an emergent technology. While LLMs have shown promise in many word processing tasks, it is unclear as to whether they can also solve path-planning problems.\nResearchers have proposed various methods of utilizing LLMs in path planning. For example, Latif (2024) translated robot perception to natural language so that an LLM could plan a path, and then translated this natural language to robot control. Others seek to use LLMs in combination with traditional path-planning algorithms. For instance, Meng et al. (2024) proposed LLM-A*. They used LLMs to generate waypoints in between a start state and a goal state, and then used A*, a traditional path-planning algorithm, to plan paths connecting those waypoints (Meng et al. 2024).\nIn addition, researchers have explored how LLMs can be used in vision-and-language navigation (VLN). In robotics, VLN involves giving robots or agents verbal instructions on how to navigate using visual cues and landmarks (Schumann et al. 2024). Challenges of VLN include visual and natural language understanding, as well as spatial and temporal reasoning (Schumann et al. 2024). Attempting to overcome these challenges, Schumann et al. (2024) proposed VELMA, an embodied LLM agent that uses verbalization of the trajectory and visual environment observations as prompts for the next action. Similarly, Zhou, Hong, and Wu (2024) introduced NavGPT, which is a purely LLM-based navigation agent that follows VLN instructions.\nResearchers have yet to reach an agreement as to whether LLMs are good path planners. Some are very optimistic about LLMs' path-planning ability. For instance, Latif (2024) claimed that GPT-3.5-turbo outperforms state-of-the-art path planners like Rapidly Exploring Random Tree and A*. Zhou, Hong, and Wu (2024) claimed that NavGPT can perform high-level planning for navigation and has reasoning capability in complex scenes.\nHowever, other researchers recognize LLMs' limitations in path planning. For example, Valmeekam et al. (2023) found that an LLM's ability to autonomously generate executable plans is lacking, averaging only about 3% success rate. Aghzal, Plaku, and Yao (2023) also found that LLMs struggle to generalize to larger environments or those with more obstacles. Furthermore, Kambhampati (2024) argued that LLMs rely a lot on fine-tuning and/or human-in-the-loop prompting to achieve good results.\nWhile these studies led to valuable insights into LLMs' path-planning abilities, they were conducted in simulated"}, {"title": "3 Method", "content": "We structured our experiments into two categories: Turn-by-Turn (TbT) navigation and VLN. We designed each category to test navigation across different environments and difficulty levels, ensuring the LLMs were challenged in diverse real-world contexts.\nTbT navigation: Models were instructed to provide step-by-step directions, similar to GPS navigation. We designed three TbT scenarios across various environments:\n\u2022 Urban Scenario: The urban scenario involved guiding users from George Mason University's Shenandoah Parking Deck to the Washington Nationals Stadium. This route was set in a dense city environment, including frequent turns and high traffic density.\n\u2022 Suburban Scenario: This route from George Mason University's Shenandoah Parking Deck to the Hogsback Mountain Paintball Center required navigation through mixed-density areas.\n\u2022 Rural Scenario: In a sparsely populated rural setting, models were asked to provide directions from George Mason University's Shenandoah Parking Deck to the Shot Tower State Park. This was considered a very challenging task since the Shot Tower State Park is located within another larger state park.\nVLN: Models were tasked to generate directions using visual landmark cues instead of road signs. We designed three scenarios with varying difficulties:\n\u2022 Easy Scenario: The easy visual landmark scenario included guiding users from the Nguyen Engineering Building to the Johnson Center at George Mason University using easily recognizable landmarks like statues, building names, and common student paths.\n\u2022 Medium Scenario: The medium scenario involved a route from the Nguyen Engineering Building to the INTO Mason Center for international students, with moderate complexity. This scenario required models to use intermediate landmarks, such as unique architectural features or pathway markers, to provide directions for users unfamiliar with road signs.\n\u2022 Hard Scenario: The hard VLN scenario required models to navigate from the Nguyen Engineering Building to the Osher Lifelong Learning Institute (OLLI). This route involved more challenging navigation across and off the university campus, with fewer clear landmarks. It tested each model's ability to identify subtle features or less commonly recognized landmarks for effective guidance.\nTo test whether model size impacts LLM's path-planning abilities, we selected three LLMs of varying scales. Each LLM was tested across all six scenarios, allowing for a detailed comparison of their performances."}, {"title": "3.1 Prompt Design", "content": "For the TbT scenarios, we designed prompts to test whether the LLMs could plan paths that meet user-specified time constraints. Each prompt specified a start and end point, providing context for the model to generate timely, navigational instructions based on user needs. For example, a user may want to arrive at a stadium two hours before a game. If the LLM failed to provide a detailed response to the initial query, we asked follow-up questions. Approximately 77.8% of TbT scenarios required at least one follow-up question. Below is an example of the prompt design for the urban TbT scenario. Additional prompts and their corresponding follow-up questions are provided in Appendix A.\nInitial Prompt- \"Plan a trip using turn-by-turn instructions from George Mason University Shenandoah Parking Deck to Garage C of the Nationals Stadium to arrive 2 hours before the first-weekend game in August 2024.\"\nGPT-4 Initial Response- \"To provide a detailed trip plan, I need the exact date and time of the game you plan to attend. If you don't have the exact date yet, please provide an estimated time for planning purposes (e.g., an afternoon or evening game). This will help ensure you arrive 2 hours before the game.\"\nFollow-Up Question 1- \"What is the first weekend in August 2024?\"\nGPT-4 Response- \"The first weekend in August 2024 is August 3rd and 4th. If you are planning to attend a game on either of these dates, please specify the time of the game so I can plan your trip accordingly.\u201d\nFollow-Up Question 2- \"Now can you find if the game is on August 3rd or 4th and what time should I leave from George Mason University Shenandoah Parking Deck to arrive at Garage C of the Nationals Stadium two hours early?\u201d\nGPT-4 Final Response- \"The Washington Nationals have games scheduled on the first weekend of August 2024 at Nationals Park. Here are the game details:\nSaturday, August 3rd, 2024: The game starts at 4:05 PM.\nSunday, August 4th, 2024: The game starts at 1:35 PM.\nGiven these timings, to arrive 2 hours before the game, you should plan to reach Nationals Park by 2:05 PM on Saturday and by 11:35 AM on Sunday. Below are the turn-by-turn directions for your trip from George Mason University Shenandoah Parking Deck to Garage Cat Nationals Park.\"\nFor VLN tasks, prompts were designed to evaluate the LLMs' ability to provide clear, visual-based directions, appropriate for users who rely on physical landmarks rather than road signs. Each prompt specified a start and end point, asking the model to focus on notable campus landmarks to guide the user along the route. For instance, an easy-level prompt instructed the LLM to navigate from the Nguyen Engineering Building to the Johnson Center, using visible"}, {"title": "4 Results", "content": "To evaluate the performance of each LLM we analyzed the LLM-generated responses compared to a ground-truth route from Waze, a navigation app that is primarily used on mobile devices."}, {"title": "4.1 Types of Errors", "content": "We classified LLM errors into major and minor errors. Major errors are those that could mislead users or direct them to a different destination, making it difficult for them to figure out how to reach their intended location. In contrast, minor errors are instances of misinformation or misdirection in a smaller area, where users can likely find their way back on track by recognizing signs or asking for directions. These are discussed further below:\nMajor errors for TbT navigation:\n1. Discontinuities - LLMs often assume that the routes they generate are continuous. However, there are often significant gaps or missing segments in these routes. In such cases, we identify the shortest path to fill these substantial gaps or missing sections. For example, in a suburban scenario, the model named Gemini assumed that University Drive connected directly to VA-28, but there is a notable gap between these two roads. After determining the shortest path that connects University Drive to VA-28, we discovered an 8.8-mile discontinuity between the routes. We have classified these and other similar route breaks as discontinuities\nThe routes generated by the LLMs are marked in red, whereas the discontinuities are marked in green. Waze's route\nIn Figure 1c, we observe a major discontinuity where the model fails to reach the correct destination. The actual destination, \"Hogsback Mountain Paintball Center,\" is located at 20267 Hogback Mountain Rd, Leesburg, VA 20175, approximately 50.3 miles away. However, the model incorrectly generated '15540 Hogsback Rd, Amissville, VA 20106' as the destination. This suggests that the LLM mistakenly matched the location to a similar name or address, although no such address exists in Amissville, VA. The error likely arises from the model's tendency to generate plausible-sounding but incorrect details when faced with ambiguous or incomplete location information, even when the correct destination was clearly specified.\n2. Turns in Opposite Direction - When merging onto highways or interstates, the LLM gave the opposite direc-"}, {"title": "4.2 Total Discontinuity and Turns", "content": "In addition to tracking the total number of errors, we also collected data on the total discontinuous miles in the LLM routes for the TbT scenarios. We recorded the number of LLM turns to the designated locations. Furthermore, we categorized the planned routes into different levels of driver knowledge required to successfully reach the destination. This was based on the size of the discontinuity and whether it occurred in a complex area or a local area where drivers could easily navigate around:\n1. Beginner - Someone who could not navigate around the area without a map.\n2. Intermediate - Someone with some knowledge about the area might successfully navigate the area.\n3. Expert - Someone who could navigate the area without any help.\nUsing the Suburban route as an example we can compare the total discontinuities and turns between the LLMs and Waze. In this scenario, Waze navigated a distance of 30.2 miles, making a total of 18 turns. The route generated by GPT-4 covers a total distance of 39.1 miles, of which 4.2 miles were discontinuous. To reach its destination, GPT-4 made a total of 7 turns"}, {"title": "4.3 Time constraints", "content": "For the TbT scenarios, we tested whether the LLMs could plan paths with time constraints. If an LLM's response indicated a travel start time and an end time that met the user-specified requirements, then it counted as satisfying the time constraint, regardless of whether the actual planned path contained errors. For example, in the urban TbT scenario, the prompt asked to arrive at the Nationals Stadium two hours before the first weekend game in August 2024. GPT-4 responded, \"The estimated driving time is around 45 minutes to 1 hour, but be sure to account for potential traffic, especially closer to the stadium. For a 4:05 PM game on August 3rd, you should leave by 1:00 PM at the latest.\" This response satisfied the time constraint.\nAmong the three tested LLMs, GPT-4 was best at satisfying time constraints. It successfully met time constraints for the urban and suburban scenarios and only failed in the rural scenario. In contrast, Gemini and Mistral did not satisfy any time constraints. Gemini made some attempts but failed. For example, when asked to find the first weekend game, it found the first game on Friday. Mistral, however, could not search the internet in real-time, so it could not find any gaming information."}, {"title": "4.4 LLM Performance Rankings", "content": "To rank the performance of the LLMs, we collected the total number of errors. Given that there are several major error categories, we assigned a weight to each category based on the severity of the errors. For TbT errors, both discontinuities and incorrect directions were assigned weights of 0.4, as these errors are equally severe. Wrong or missed exits were considered less serious and received a weight of 0.2. For VLN errors, if there were discontinuities or if the model failed to reach the destination, weights of 0.8 were assigned. If a landmark did not exist or the description of the landmark was inaccurate, a weight of 0.2 was given.\nTable 2 shows the LLMs' performance rankings, according to the above rules. For TbT scenarios, Mistral excelled in urban navigation, while ChatGPT-4 performed best in suburban and rural environments. Conversely, ChatGPT-4 had the weakest performance in urban navigation, Mistral struggled the most in suburban navigation, and Gemini performed the"}, {"title": "5 Discussion", "content": "Given that none of the tested LLMs could plan paths in the real world, it begs the question, what could have been done to achieve some success? In this section, we discuss the future research directions."}, {"title": "5.1 Reality checks", "content": "One striking result is that some paths were so absurd that even a brief human glance would flag such a wrong solution. For example, in the rural TbT scenario, while Waze's path was 291.4 miles, Gemini planned a path of 462.2 miles. A reality check such as a simple online search about the approximate distance between the destinations may have helped catch such errors. However, currently LLMs cannot initiate such quality assurance reality checks.\nSeveral researchers have investigated how LLMs could perform fact checks (Augenstein et al. 2024; Zhang and Gao"}, {"title": "5.2 In-context transparency", "content": "Our experiments examined LLMs across varying difficulty levels, but the LLMs were not able to adapt to the different levels of complexity and they made more mistakes while attempting the harder tasks. Access to mapping services could help the performance of path-planning LLMs but only Gemini could access the Google Maps API, redirecting users to Google Maps. However, the API could not provide directions in text. So, in this effort, Gemini's paths are not based on Google Maps. Despite this known limitation, however, none of the tested LLMs informed them of this weakness. Instead, they started giving directions right away, and not appropriately warning users of their limitations.\nThese behaviors could lead users to overtrust the LLMs, which could be very problematic if deployed in actual vehicles. In many cases, overtrust and overreliance on AI systems can lead to disastrous outcomes (Kim et al. 2024). Although currently all the LLMs' user interfaces include a line indicating they may make mistakes (e.g., \u201cGemini may display inaccurate info, including about people, so double-check its responses\"), the line could easily be ignored by users not paying attention.\nFuture LLMs should be more transparent about their limitations. In addition to one-line disclaimers, they should indicate their limitations in context. When prompted to complete tasks for which they do not have enough information, they should acknowledge their limitations before attempting the task. They should be able to inform users that they are less certain about such results and abstain from doing such tasks.\nAchieving in-context transparency is challenging. Researchers find that LLMs are often overconfident (Kim et al. 2024; Wen et al. 2024; Leng et al. 2024), and more research is needed to obtain accurate numerical estimates of uncertainty for LLMs, as well as how well people with various backgrounds understand such estimates.\""}, {"title": "5.3 The case for smaller models", "content": "All tested LLMs fell short of path planning, and no LLM consistently outperformed the others. One common argument for improving LLM performance is to increase the input data and associated parameters. However, increasing the model's size does not necessarily lead to better path-planning performance, which raises the question of whether"}, {"title": "5.4 Limitations", "content": "One limitation of our study is that we only evaluated the LLMs on specific routes in our local area, which may not generalize across broader geographical areas. Furthermore, when new versions of LLMs roll out, new studies will be needed to test their path-planning abilities. In particular, having real-time access to mapping services could be game-changing for the path-planning abilities of future LLMs."}, {"title": "6 Conclusion", "content": "Although there is much hype around using LLMs for path planning, our experiments show that our tested LLMs are not capable of path planning in the real world. Overall, GPT-4 performed slightly better in TbT scenarios, and Gemini performed better in VLN scenarios, but all LLMs made various mistakes and are far from useful in real-world path planning. Therefore, these LLMs should not be used in directing vehicle navigation, and car companies should take extreme caution in using this experimental software. Going forward, we advocate for more in-context transparency about LLMs' limitations, implementing mechanisms for initiating reality checks, and training smaller and more specialized models."}]}