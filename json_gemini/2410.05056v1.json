{"title": "Transition of \u03b1-mixing in Random Iterations with Applications in Queuing Theory", "authors": ["Attila Lovas"], "abstract": "Nonlinear time series models incorporating exogenous regressors provide the foundation for numerous significant models across econometrics, queuing theory, machine learning, and various other disciplines. Despite their importance, the framework for the statistical analysis of such models is still incomplete. In contrast, multiple versions of the law of large numbers and the (functional) central limit theorem have been established for weakly dependent variables. We prove the transition of mixing properties of the exogenous regressor to the response through a coupling argument, leveraging these established results. Furthermore, we study Markov chains in random environments under a suitable form of drift and minorization condition when the environment process is non-stationary, merely having favorable mixing properties. Following a novel statistical estimation theory approach and using the Cram\u00e9r-Rao lower bound, we also establish the functional central limit theorem. Additionally, we apply our framework to single-server queuing models. Overall, these results open the door to the statistical analysis of a large class of random iterative models.", "sections": [{"title": "Introduction", "content": "It is very common in natural and social sciences that for describing the time evolution of certain quantity of interests, researchers build models incorporating input variables not influenced by other variables in the system and on which the output variable depends. Such explicative variables, especially in econometrics literature, are called exogeneous covariates. Let X and Y be complete and separable metric spaces. The X-valued process $(X_t)_{t \\in \\mathbb{N}}$ represents the time series of interest and the Y-valued process $(Y_t)_{t \\in \\mathbb{Z}}$ denotes the exogeneous covariate. We postulate that $(X_t)_{t \\in \\mathbb{N}}$ satisfies the recursion\n$$X_{t+1} = f(X_t, Y_t, \\varepsilon_{t+1}),$$\nwhere $X_0$ is a possibly random initial state, $f : X \\times Y \\times [0,1] \\rightarrow X$ is a measurable function, and $\\varepsilon_t \\in [0,1], t \\in \\mathbb{N}$ represents the noise entering to the system. The exploration and analysis of non-linear autoregressive processes of this kind constitute a recent and actively developing area of research. In particular, there is a pronounced surge of interest within the fields of applied statistics and econometrics regarding the investigation of standard time series models that incorporate exogeneous regressors. Notable examples include a novel class of Poisson autoregressive models with exogeneous covariates (PARX) introduced by Agosto et al. [1] for modeling corporate defaults. Additionally, the recent research by Gorgi and Koopman [18] has provided valuable insights on observation-driven models involving beta autoregressive processes with exogeneous factors. Furthermore, the theory of non-linear autoregressive processes allows researchers for analyzing large-scale stochastic optimization algorithms, which play a pivotal role in machine learning applications, see [5, 31].\nThe statistical analysis of general non-linear time series models with exogenous covariates necessitates the law of large numbers (LLN), central limit theorem (CLT), and others. However, this framework is presently unavailable. Researchers have investigated these models under additional assumptions that facilitate their analysis. The ergodicity of iterations given by (1) has been extensively studied under the restrictive assumption that the data $(Y_t)_{t \\in \\mathbb{Z}}$ and the noise $(\\varepsilon_t)_{t \\in \\mathbb{N}}$ are both i.i.d. and also independent of each other (See, [11], [26], and [42]). In this case, the process $(X_t)_{t \\in \\mathbb{N}}$ is a Markov chain, and this setting now can be considered to be textbook material. Moving beyond this simplifying yet unrealistic assumption, Debaly and Truquet established general results for getting stationarity, ergodicity and stochastic dependence properties for general nonlinear dynamics defined in terms of iterations of random maps [10]. Additionally, there are earlier contributions that consider more general schemes and investigate them without assuming independence. For instance, in the paper of Borovkov and Foss [4], Foss and Konstantopoulos [15] and also in the monograph of Borovkov [3] such processes are treated under the name \"stochastically recursive sequences\". Among the most recent results, we can mention the paper [19] by Gy\u00f6rfi et al. that introduces a novel concept called strong stability and provides sufficient conditions for strong sta-bility of iterations given by (1). Furthermore, new findings related to Langevin-type iterations with dependent noise and multitype branching processes were also established.\nAssuming that the noise $(\\varepsilon_t)_{t \\in \\mathbb{N}}$ is i.i.d. and independent of the regressor $Y := (Y_t)_{t \\in \\mathbb{Z}}$, we have\n$$P(X_t \\in B \\mid (X_j)_{j<t}, Y) = \\int_{[0,1]} 1\\{f(X_{t-1}, Y_{t-1}, z) \\in B\\} \\nu(dz), \\quad t \\geq 1,$$\nwhere $\\nu = Law(\\varepsilon_0)$. Clearly, the process $(X_t)_{t \\in \\mathbb{N}}$ defines a time-inhomogeneous Markov chain conditionally on the exogeneous process $(Y_t)_{t \\in \\mathbb{Z}}$ being interpreted as random environment. This characterization leads us to term this process a Markov chain in a random environment (MCRE). This concept is proved to be a good compromise since, many interesting models can be treated as a MCRE. Furthermore, it is worth noting that the rich theory of general state Markov chains equips us with powerful analytical tools to study and understand these processes in-depth. Markov chains in random environments were first studied on countable state spaces in [8, 9, 38]. On general state spaces [27, 28, 41] investigated their ergodic properties under a rather stringent hypothesis: essentially, the Doeblin condition was assumed (see Chapter 16 of [36]). Such assumptions are acceptable on compact state spaces but they fail in most models evolving in $\\mathbb{R}^d$. For non-compact state spaces the results of [42] apply (see also Chapter 3 of [3]) but the system dynamics is assumed to be strictly contracting, which, again, is too stringent for most applications. Markov chains in stationary random environments were first treated on non-compact state spaces under Lyapunov and \"small set\"-type conditions in [17] and [31]. The former paper was based on the control of the maximal process of the random environment but its techniques worked only assuming that the system dynamics is contractive with respect to a certain Lyapunov function, whatever the random environment is. In [31] this decreasing property is required only in an averaged sense. This result covers important model classes that none of the previous works could: queuing systems with non-independent service times (or inter-arrival times), linear systems that are stable in the average, and stochastic gradient Langevin dynamics when the data is merely stationary. In [43], under a notably weaker, yet in certain aspects, optimal form of the Lyapunov and the small set conditions, Truquet showed that for a given strongly stationary process $(Y_t)_{t \\in \\mathbb{Z}}$, there exists a process $(X_t)_{t \\in \\mathbb{N}}$ satisfying the iteration in (1), and the distribution of the process $(X_t, Y_t)_{t \\in \\mathbb{Z}}$ is unique. Additionally, if the process $(Y_t)_{t \\in \\mathbb{Z}}$ is ergodic, then the process $(X_t, Y_t)_{t \\in \\mathbb{Z}}$ is ergodic as well, hence the strong law of large numbers applies.\nAs far as we know, there are no known results regarding MCREs when the environment $(Y_t)_{t \\in \\mathbb{Z}}$ is non-stationary. Furthermore, the sequence of iterates $(X_t)_{t \\in \\mathbb{N}}$ is typically non-stationary even in cases when the environment is stationary but the initial state $x_0 \\in X$ is independent of $\\sigma(\\{\\varepsilon_t, Y_t \\mid t\\in \\mathbb{N}\\})$. Weak dependence assumptions offer a valuable approach to address this problem while allowing for long-range dependencies to be present. The recent work by Truquet [44] directed our attention to the fact that through arguments based on coupling inequalities, it can be established under general conditions that the mixing properties of the process $(Y_t)_{t \\in \\mathbb{Z}}$ are inherited by the"}, {"title": "Transition of mixing properties", "content": "In this section, we study the transition of mixing properties of the covariate process to the response and its immediate consequences under minimal assumptions on the iteration (1). Several notions of mixing exist in the literature. The interested reader should consult the excellent survey by Bradley [7], for example. In our context \u03b1-mixing holds particular importance, therefore let us first recall the key concepts related to this type of mixing. We define the measure of dependence, denoted as \u03b1(G, H), for any two sub-\u03c3-algebras G, H \u2282 F, using the equation:\n$$\\alpha(G, H) = \\sup_{G \\in G, H \\in H} |P(G \\cap H) \u2013 P(G)P(H)|.$$\nFurthermore, considering an arbitrary sequence of random variables $(W_t)_{t \\in \\mathbb{Z}}$, we introduce the \u03c3-algebras $F_{-\\infty}^{W,t} := \\sigma(W_k, t \\leq k \\leq s)$, where $-\\infty \\leq t \\leq s < \\infty$. Additionally, we define the dependence coefficients as follows:\n$$\\alpha_W(n) = \\sup_{j \\in \\mathbb{Z}} \\alpha (F_{-\\infty}^{W,j}, F_{j+n,\\infty}^{W}), \\quad j \\in \\mathbb{Z}.$$\nThe mixing coefficient of W is $\\alpha_W(n) = \\sup_{j \\in \\mathbb{Z}} \\alpha_W^j(n), n \\geq 1$ which is obviously non-increasing. Note that, for strictly stationary W, $\\alpha_W^j(n)$ does not depend on j, and thus $\\alpha_W(n) = \\alpha^W(n)$.\nWe classify W as strongly mixing if $\\lim_{n \\rightarrow \\infty} \\alpha_W(n) = 0$, and weakly mixing if\n$$\\lim_{n \\rightarrow \\infty} \\frac{1}{n} \\sum_{k=1}^n \\alpha_W (k) = 0$$"}, {"title": "Markov chains in random environments", "content": "This section is devoted to study an important class of random iterations incorporating exogeneous covariates, called Markov chains in random environments. For convenience, we adopt the parametric kernel formalism to set Lyapunov and \"small set\"-type conditions. Let us introduce\n$$Q(y, x, B) = \\int_{[0,1]} 1\\{f(x,y,z)\\in B\\} dz.$$\nThe function $Q : X \\times Y \\times B(X) \\rightarrow [0, 1]$ is a parametric probabilistic kernel, which means:\ni For each pair $(y, x) \\in Y \\times X$, the mapping $B \\rightarrow Q(y, x, B)$ defines a Borel probability measure on the Borel sigma-algebra $B(X)$.\nii For any choice of set $B \\in B(X)$, the mapping $(x, y) \\rightarrow Q(y, x, B)$ is a measurable function with respect to the product sigma-algebra $B(X) \\otimes B(Y)$.\nDefinition 2.1. Let $P : X \\times B \\rightarrow [0,1]$ be a probabilistic kernel. For a bounded measurable function $\\phi : X \\rightarrow \\mathbb{R}$, we define\n$$[P\\phi](x) = \\int_X \\phi(z)P(x, dz), \\quad x \\in X.$$\nThis definition makes sense for any non-negative measurable $\\phi$, too.\nConsistently with Definition 2.1, for $y \\in Y$, $Q(y)$ will refer to the action of the kernel $Q(y, \u00b7, \u00b7)$ on \u03c6.\nWe say that Q satisfies the drift (or Lyapunov) condition if there exists a measurable mapping $V : X \\rightarrow [0,\\infty)$, which we call Lyapunov-function, and measurable functions $\\gamma, K : Y \\rightarrow (0, \\infty)$, such that for all $(y, x) \\in Y \\times X$,\n$$[Q(y)V](x) := \\int_X V(z) Q(y, x, dz) \\leq \\gamma(y)V(x) + K(y).$$\nWe may, and from now on, we will assume that $K(.) > 1$ in the drift condition (7).\nThe parametric kernel obeys the minorization condition with $R > 0$, if there exists a probability kernel $K_R : Y \\times B(X) \\rightarrow [0,1]$ and a measurable function $\\beta : [0, \\infty) \\times Y \\rightarrow [0,1)$ such that such that for all $(y, x, A) \\in Y \\times V^{-1}([0, R]) \\times B(X)$,\n$$Q(y, x, A) \\geq (1 \u2013 \\beta(R, y))\\kappa_R(Y, A).$$\nThe minorization condition stipulates the existence of \"small sets\". Therefore, it is also referred to as a \"small set\"-type condition.\nIf \u03b3, K are independent of y and \u03b3 < 1 then (7) is the standard drift condition for geometrically ergodic Markov chains, see Chapter 15 of [36]. Ergodic properties of Markov chains in stationary random environments was studied by Lovas and R\u00e1sonyi in [31] when $ \\gamma(y) \\geq 1$ may well occur but the environment satisfies the following long-term contractivity condition:\n$$\\limsup_{n \\rightarrow \\infty} \\frac{1}{n} E \\bigg[ K(Y_0) \\prod_{k=1}^n \\gamma(Y_k) \\bigg] < 1.$$\nUnder the assumption that $E \\big[\\log(\\gamma(Y_0))_{+}\\big] + E \\big[\\log(K(Y_0))_{+}\\big] < \\infty$ and\n$$\\limsup_{n \\rightarrow \\infty} \\bigg[ \\prod_{k=1}^n \\gamma(Y_{-k}) \\bigg]^{1/n} < 1, P - a.s.,$$\nwhich is notably weaker than (9), in [43] Truquet proved that there exists a stationary process $((Y_t, X^*))_{t \\in \\mathbb{Z}}$ satisfying the iteration (1), and the distribution of this process is unique. If, in"}, {"title": "Single server queuing systems", "content": "In the early 20th century, Danish engineer Agner Krarup Erlang pioneered what would later be known as queuing theory [13]. His work at a telephone company, where he developed a mathematical model to determine the minimum number of telephones needed to handle calls efficiently, laid the foundation for this field. Today, queuing theory extends far beyond telecommunications, significantly influencing areas like inventory management, logistics, transportation, industrial engineering, and service design. Notably, it plays a key role in reducing costs within product-service design [37].\nFor simplicity, we focus on single-server queuing systems with infinite buffer and first-in, first-out (FIFO) service discipline . It's worth noting that more complex queuing systems,"}]}