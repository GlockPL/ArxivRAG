{"title": "Generative Modeling and Data Augmentation for Power System Production Simulation", "authors": ["Linna Xu", "Yongli Zhu"], "abstract": "As a key component of power system production simulation, load forecasting\nis critical for the stable operation of power systems. Machine learning methods\nprevail in this field. However, the limited training data can be a challenge. This\npaper proposes a generative model-assisted approach for load forecasting under\nsmall sample scenarios, consisting of two steps: expanding the dataset using\na diffusion-based generative model and then training various machine learning\nregressors on the augmented dataset to identify the best performer. The expanded\ndataset significantly reduces forecasting errors compared to the original dataset,\nand the diffusion model outperforms the generative adversarial model by achieving\nabout 200 times smaller errors and better alignment in latent data distributions.", "sections": [{"title": "Introduction", "content": "The modern power grid faces new challenges for stable and secure operation, such as the difficulty in\nforecasting load demand due to the uncertain charging profiles of electric vehicles (EV)'s. Accurate\nload forecasting informs power consumption for a given time horizon, enabling power utilities to\nschedule sufficient power generation while minimizing waste. Consequently, production simulation,\nviz., an optimization program to economically allocate each power plant's output, is widely used by\nutility companies.\nVarious machine learning methods for load forecasting have been reported. Fan et al. [1] employed\na Long Short-Term Memory (LSTM) network for short-term load forecasting. Similarly, Kong et\nal. [2] developed a hybrid model combining Convolutional Neural Networks (CNN) and LSTM\nto enhance forecasting accuracy by capturing spatial and temporal dependencies. A random forest\n(RF) model was utilized in [3] to address overfitting through ensemble learning for short-term load\nforecasting. Wang et al. [4] applied a Gradient Boosting Decision Tree (GBDT) model to effectively\ncapture nonlinear relationships in the data. The CatBoost model was used in [5] to predict power\nload demands, demonstrating strong performance with mixed data types.\nThe methods mentioned above assume abundant, high-quality load demand data, which is often\nunavailable in the power industry. Communication failures, device malfunctions, and newly built\ncommunities with limited data can impede accurate load forecasting.\nTherefore, obtaining a large number of high-quality datasets from a given small dataset is a key\nissue here. Generative Adversarial Networks (GANs) have excelled in data generation[7, 8, 9], and\nmany variants have been developed, among which TimeGAN (Time-series Generative Adversarial\nNetworks) [10] performs well in synthesizing time series data. In addition, the diffusion model [11]\nhas been applied for time-series data generation in recent years. For example, Yuan. et al. proposed\nan interpretable diffusion model for generic time series generation [12].\nIn this paper, we explore the effectiveness of load data augmentation for power system production\nsimulation using TimeGAN and TS-Diffusion, respectively. The first step is augmenting the original\ndataset, the second step is training a forecasting model based on the augmented dataset, and the last\nstep is feeding the predicted load demand in an optimization model to conduct the power system\nproduction simulation. The source code and data are freely accessible at https://github.com/\nBecklishious/NeurIPS2024."}, {"title": "Dataset Augmentation for Load Forecasting", "content": "In this section, we present a brief description of the original dataset and the TS-Diffusion model\nfor data augmentation. The math details are described in Appendix A.2. The TimeGAN-based data\naugmentation model and the ExtraTree-based [6] load forecasting model are described in Appendix\nA.1 and A.3."}, {"title": "Dataset Description", "content": "The dataset used in this paper is collected from a household in northwest China, comprising 168\nhourly load records from April 16 to April 22, 2024. It includes additional meteorological data:\ntemperature, barometric pressure, wind speed, wind direction, surface horizontal radiation, direct\nnormal radiation, and diffuse radiation. These variables will be included during dataset augmentation.\nIn our load forecasting model, the meteorological data serve as features, while the load values are\nused as labels."}, {"title": "TS-Diffusion Model for Load Demand Augmentation", "content": "TS-Diffusion is a diffusion model for time series data generation based on a Transformer-inspired\narchitecture combined with a decomposition design. TS-Diffusion performs well in tasks like missing-\nvalue interpolation. Hence, we adopt it to augment time series data. The training process diagram of\nthe TS-Diffusion generation model is shown in Figure 1."}, {"title": "Experiment Results", "content": "This section mainly 1) compares the quality of the augmented datasets obtained by the two generative\nmachine learning approaches and 2) gives a simple showcase for power system production simulation.\nAn in-depth analysis of the experiment results can be found in Appendix A.4. All the experiments\nare implemented on a desktop PC with Intel 5.4GHz CPU and 32GB RAM."}, {"title": "Quality of TS-Diffusion Augmented Dataset", "content": "The original data is divided into the training and test sets at the beginning with an 8:2 split ratio.\nThen, the TS diffusion model is used to augment the original training set (about 134 data samples) to\n3456 samples. Prediction models are then trained respectively on the original training set and the\naugmented training set. Besides, another comparison dataset is established by expanding the original\ntraining set to the same size as the TS diffusion-augmented dataset using simple replication, followed\nby model training. RMSE (Root Mean Square Error) and MAE (Mean Absolute Error) are used as\nthe performance metrics. Four types of regression models are considered: ExtraTree, Random Forest,\nCatBoost, and XGBoost. Each model is independently trained once on the original, replicated, and\naugmented datasets and tested on the (previously split) 20% testing set. Results are shown in Table 1.\nThere is no risk of data leakage because: 1) the original dataset has been divided into the training\nset and test set at the beginning 2) only the training set is used to establish the GAN model and 3)\nthe final augmented dataset contains no entry from the testing set. From Table 1, we can see that the\nresults of the TS-Diffusion augmented dataset are better than the original and replicated datasets, and\nthis conclusion holds for all four models. In particular, when the ExtraTree model is trained using the\naugmented dataset, it has the best prediction effect on the testing set, with an RMSE of 0.00023 and\nan MAE of 0.00004, which cannot be achieved by simply duplicating the original dataset."}, {"title": "Quality of TimeGAN Augmented Dataset", "content": "Similar to 3.1, we use TimeGAN to augment the dataset. The experiment results on the augmented\ndataset are shown in Table 2 (comparisons with other datasets are put in Table 3 of the Appendix)."}, {"title": "A Simple Showcase for Power System Production Simulation", "content": "The previously predicted load data can be utilized in a standard power system production simulation\nprocedure, which means solving the following optimization model:\nSuppose a region's load is supplied by grid-purchased power $P_{grid}(t)$ and photovoltaic (PV) power\n$P_{pv}(t)$. The cost of PV power is 0.4 $/kWh, while the cost of the grid-purchased power is 1\n$/kWh. To optimize this region's power operation, the objective is to minimize the power production\ncost while meeting load requirements $P_{load}(t)$. The objective function is defined in Eq.(1), with\nconstraints from Eq.(2) to Eq.(4).\nminimize\n$cost_{grid} \\sum_{t=1}^{T=24} P_{grid}(t) + cost_{pv} \\sum_{t=1}^{T=24} P_{pv}(t)$\n(1)\nsubject to\n$P_{load}(t) = P_{grid}(t) + P_{pv}(t)$,\nt = 1, ..., T\n(2)\n$P_{grid}(t) \\geq 0$,\nt = 1, ..., T\n(3)\n$0 \\leq P_{pv}(t) < P_{pv,max}(t)$,\nt = 1, ..., T\n(4)\nIn Eq.(4), $P_{pv,max}(t)$ is the maximum possible PV power at time t. Since the load demand of the\nfuture horizon (e.g., the next day) is unknown, we employ the ExtraTree-based load forecasting\nmodel (trained on the dataset augmented by TS-Diffusion) \u201cas\u201d the future day's load, $P_{load}(t)$. Then,\nthis forecast load will be substituted in Eq.(2). After solving the optimization problem, the simulation\nresults of the PV generation and grid power purchase are depicted in Figure 2.\nDuring the no-PV-power period (before sunrise or after sunset), the region's power supply fully relies\non external grid support. As the PV power increases, the grid power exchange gradually decreases.\nFrom 10:00 to 16:00, when the PV power is the most sufficient, it fully meets the region's load needs."}, {"title": "Conclusion and Future Work", "content": "In this paper, we propose a method to improve the accuracy of load forecasting models using\ngenerative machine learning under small samples. The quality of the generated load data (especially\nby the diffusion model) significantly improves the load-forecasting accuracy, demonstrating the\nfeasibility and capability of generative machine learning for power system production simulation.\nFuture work includes fine-tuning the generative models for better data quality and conducting\nadditional comparisons. A limitation of this study is that the trained generative model for one regional\npower system may not directly apply to neighboring regions. Thus, applying transfer learning to\nenhance the model's generalizability will be the next step."}, {"title": "GAN-based Load Demand Augmentation Model", "content": "TimeGAN (Time-series Generative Adversarial Networks) is a GAN model customized for time\nseries data generation. It integrates GAN with self-supervised learning to capture complex temporal\npatterns. Like traditional GAN, it includes a generator that produces synthetic data and a discriminator\nthat distinguishes between real and generated data. Through iterative training, the generator improves\nin producing simulated time series.\nA key feature of TimeGAN is its use of self-supervised learning via an auto-encoder, comprising\nan encoder that maps time series data to latent representations and a decoder that reconstructs the\noriginal data. This structure enhances the model's ability to capture the intrinsic time-series features.\nFigure 3 illustrates the TimeGAN training process."}, {"title": "TS-Diffusion-based Load Demand Augmentation Model", "content": "As shown in Figure 1, the TS-Diffusion model contains forward and reserve processes. In this setting,\na sample from the data distribution $x_0 \\sim q(x)$ is gradually noised by a Gaussian noise N during the\nforward process, where the transition is parameterized by $q(x_t|x_{t\u22121}) = N(x_t; \\sqrt{1 \u2013 \u03b2_t}x_{t\u22121}, \u03b2_tI)$\nwith $\u03b2_t \u2208 (0,1)$ as the amount of noise added at diffusion step t. Then a neural network\nlearns the reverse process of gradual denoising the sample via reverse transition $p_\u03b8(x_{t\u22121}|X_t) =$\n$N(x_{t\u22121}; \u03bc_\u03b8(x_t, t), \u03a3_\u03b8(x_t, t))$. The reverse process can be approximated via Eq. (8).\n$x_{t-1} = \\frac{\\sqrt{\u03b1_{t-1}}\u03b2_t}{1-\\bar{\u03b1}_t} x_\u03b8(x_t, t, 0) + \\frac{\\sqrt{\u03b1_t(1-\u03b1_{t-1})}}{1-\\bar{\u03b1}_t} x_t + \\frac{1-\u03b1_{t-1}}{1-\\bar{\u03b1}_t} \u03b2_t z_t$\n(8)\nwhere $z_t \\sim N(0,I)$, $\u03b1_t = 1 \u2212 \u03b2_t$ and $\\bar{\u03b1}_t = \u03a0_{s=1}^{t} \u03b1_s$.TS-Diffusion trained this denoising model\n$\u03bc_\u03b8 (x_t, t)$ using a weighted mean squared error loss, the reweighting strategy is shown in Eq. (9).\n$L_{simple} = E_{t,x_0} [w_t||x_0 - x_\u03b8(x_t, t, 0) ||^2], w_t = \\frac{\u03bb \u03b1_t(1 \u2013 \\bar{\u03b1}_t)}{\u03b2_t^2}$\n(9)\nwhere $\\lambda$ is a constant. These loss terms are down-weighted at small t to force the network focus on a\nlarger diffusion step. In addition, TS-Diffusion guides an interpretable diffusion training by applying\nthe Fourier transformation in the frequency domain, i.e.,\n$L_0 = E_{t,x_0} [w_t [\\lambda_1 ||x_0 - x_\u03b8(x_t, t, 0) ||^2 + \u03bb_2 ||FFT(x_0) \u2013 FFT(x_\u03b8(x_t, t, 0))||^2]]$\n(10)\nwhere FFT denotes the Fast Fourier Transformation, and $\\lambda_1, \\lambda_2$ are the balancing weights for the\ntwo losses in Eq. (10)."}, {"title": "ExtraTree-based Load Forecasting Model", "content": "ExtraTree is a decision tree-based machine learning model that improves its generalization ability\nand computational efficiency by introducing extreme stochasticity to randomly select features and\nfeature splitting points.\nUnlike the usual approach that uses only a subset of the data, it uses the entire training dataset to build\neach tree. During the training process, the ExtraTree model introduces a lot of randomness. At each\nsplit node, it randomly selects features and feature values to split rather than choosing the optimal\nfeature split point. More specifically, it randomly selects a subset of all features, then randomly\nselects a feature from this subset to split, and randomly selects one of the possible split points as the\nactual split point. Figure 4 illustrates the basic idea of the ExtraTree model for load forecasting."}, {"title": "An In-depth Analysis of the Experiment Results", "content": "In this subsection, the \"generation quality\" of the TS-Diffusion and TimeGAN augmented datasets\nare respectively analyzed. The load forecasting models are trained on the augmented datasets, of\nwhich the MAE and RMSE are compared with the forecasting models trained on the original data.\nThe complete results of section 3.2 are shown in Table 3.\nThe results in Table 3 reveal that the model trained on the TimeGAN-augmented dataset outperforms\nthe one trained on the original and replicated data regarding the MAE but underperformed in RMSE.\nMAE measures the average absolute error between predicted and actual values, giving equal weight\nto each error. In contrast, the RMSE is more sensitive to larger errors due to the squaring operation.\nThe augmented data leads to lower MAE but higher RMSE, indicating smaller errors overall with\na few extreme outliers. This suggests that TimeGAN may have introduced slight anomalies during\naugmentation, thus enlarging the RMSE. Besides, the augmented data possibly deviates from the\noriginal data distribution in the tail, leading to poorer model performance in extreme cases. While the\naugmentation improves prediction accuracy to some extent, it somewhat compromises robustness.\nOn the other hand, the load forecasting models trained on the TS-Diffusion augmented dataset are\nbetter than those trained on the original data, both in terms of MAE and RMSE. Also, compared with\nthe TimeGAN augmented dataset, the quality of the TS-Diffusion augmented dataset is obviously\nbetter. Taking ExtraTree as an example, the MAEs of the model trained on the original dataset, the\nTimeGAN augmented dataset, and the TS-Diffusion augmented dataset are respectively 0.03209,\n0.02395, and 0.00004. The performance of the TS-Diffusion augmented dataset is remarkable."}]}