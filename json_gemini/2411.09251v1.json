{"title": "Cross Space and Time: A Spatio-Temporal Unitized Model for Traffic Flow Forecasting", "authors": ["Weilin Ruan", "Wenzhuo Wang", "Siru Zhong", "Wei Chen", "Li Liu", "Yuxuan Liang"], "abstract": "Predicting spatio-temporal traffic flow presents significant challenges due to complex interactions between spatial and temporal factors. Existing approaches often address these dimensions in isolation, neglecting their critical interdependencies. In this paper, we introduce the Spatio-Temporal Unitized Model (STUM), a unified framework designed to capture both spatial and temporal dependencies while addressing spatio-temporal heterogeneity through techniques such as distribution alignment and feature fusion. It also ensures both predictive accuracy and computational efficiency. Central to STUM is the Adaptive Spatio-temporal Unitized Cell (ASTUC), which utilizes low-rank matrices to seamlessly store, update, and interact with space, time, as well as their correlations. Our framework is also modular, allowing it to integrate with various spatio-temporal graph neural networks through components such as backbone models, feature extractors, residual fusion blocks, and predictive modules to collectively enhance forecasting outcomes. Experimental results across multiple real-world datasets demonstrate that STUM consistently improves prediction performance with minimal computational cost. These findings are further supported by hyperparameter optimization, pre-training analysis, and result visualization. We provide our source code for reproducibility at https://anonymous.4open.science/r/STUM-E4F0.", "sections": [{"title": "I. INTRODUCTION", "content": "Rapid economic growth and the surge in vehicle numbers have intensified traffic congestion and parking challenges in urban areas globally. To address these challenges, numerous countries have been investing in the development of Intelligent Transportation Systems (ITS), harnessing advances in data collection and mobile computing technologies [1], [2], [3]. Modeling and analyzing spatio-temporal dynamic systems are applicable to various prediction scenarios, and research in this field has received sustained attention over the past few decades [4], [5]. As a crucial component of ITS, traffic flow prediction aims to optimize traffic management, enhance travel safety, and mitigate worsening traffic conditions. [6]\nEarly research primarily focused on statistical model-based approaches, such as the Historical Average (HA) [7] and the Auto-Regressive Integrated Moving Average (ARIMA) [8], [9] model, as well as machine learning-based models [10], including Vector Auto-Regression (VAR) [11], [12] and Artificial Neural Networks (ANN) [13]. However, these methods often struggle to capture the complex nonlinear relationships present in large-scale traffic networks, especially when directly applied to spatio-temporal prediction tasks. With the rise of spatio-temporal big data, recent methods have shifted towards data-driven deep learning models that can more effectively capture the inherent spatio-temporal dependencies of dynamic systems [14]. Simple yet effective strategies include using Convolutional Neural Networks (CNNs) [15] to capture spatial dependencies, and utilizing Recurrent Neural Networks (RNNs) [16] and their variants, such as Long Short-Term Memory (LSTM) [17] networks and Gated Recurrent Units (GRUs) [18], to capture temporal dependencies, thereby improving performance [19].\nRecently, numerous traffic prediction methods have combined sophisticated temporal models with Graph Neural Networks (GNNs) to capture global temporal dependencies and regional pattern features, respectively. Spatio-temporal graph neural networks (STGNNs) [20], [21] have gained significant attention due to their ability to learn robust high-level spatio-temporal representations through local information aggregation [6]. Researchers have invested considerable effort in developing complex and innovative models for traffic prediction, including novel graph convolutional methods [22], [23], [24], [25], [26], [27], [28], [29], [30], [4], [31], [32], [33], learning graph structures [5], [34], [35], [36], [37], efficient attention mechanisms [38], [39], [40], [41], [42], and other approaches [43], [44], [45], [46], [47], [48], [49], achieving performance improvements.\nHowever, despite ongoing advancements in network architectures, performance gains have begun to plateau, largely due to the following challenges:\n\u2022 Separation between the spatial and temporal module: The independent computation of spatio-temporal modules always limits the effectiveness and efficiency of spatio-temporal representation learning. As shown in Figure 1(c), spatio-temporal relational information influences regional predictions over time. Prediction modules that separate spatial and temporal processing fall short of efficiently propagating regional relationships across temporal intervals.\n\u2022 Data heterogeneity: The heterogeneity of spatio-temporal data results in varying patterns across different spatial and temporal scales. For instance, Figure 1(a) depicts one of the regions monitored by sensors in the PEMS dataset [29], where traffic flow exhibits substantial variability between regions. Figure 1(b) shows traffic flow waveforms at two points within the same region, highlighting that even within a single area, distinct periods show different traffic dynamics.\nUpon revisiting existing traffic forecasting methods, we recognize the need for a unitized framework to address these challenges. To this end, we first propose the concept of Adaptive Spatio-temporal Unitized Cells (ASTUCs), which are designed to compute, update, and store spatial, temporal, and relational information within a single unit, in contrast to prior research that separates spatial and temporal modules. Meanwhile, we propose a novel block called Multi-layer Residual Fusion (MLRF) that leverages the properties of these cells to better capture complex non-linear spatio-temporal dependencies, thereby overcoming heterogeneity and improving computational efficiency and performance. Specifically, we begin by defining an adaptive spatio-temporal unitized matrix at the node level, represented by multiple trainable adaptive matrices using low-rank matrix factorization. During the training process, these cells carry node information and aggregate it into reorganized matrices containing dynamic information at each time step. The use of multi-layer fusion residual blocks mitigates redundant computations, reducing over-parameterization. Finally, all adaptive spatio-temporal unitized cells contribute to the prediction module, enabling accurate traffic flow forecasting.\nOur main contributions can be summarized as follows:\n\u2022 A unified approach that unifies spatial and temporal learning. In response to module separation, we introduce a novel framework called the Spatio-temporal Unitized Model (STUM) and a corresponding training approach that unifies spatial and temporal processing, as opposed to the traditional method of separating spatial and temporal modules. This unified treatment allows for more efficient learning and accurate representation of spatio-temporal dependencies.\n\u2022 Designed novel modules for spatio-temporal unitization computing. In response to data heterogeneity, we present the Adaptive Spatio-temporal Unitized Cell (ASTUC) based on low-rank adaptive matrices, and a dual feature extraction strategy based on backbone network extractor and Multi-layer Residual Fusion (MLRF), improving the model's ability to handle complex spatio-temporal interactions.\n\u2022 Extensive experiments. We conduct comprehensive experiments on multiple real-world datasets, demonstrating that our proposed framework significantly outperforms existing baseline models in spatio-temporal prediction tasks while maintaining computational efficiency."}, {"title": "II. RELATED WORK", "content": "Spatio-temporal forecasting has been extensively studied over the past decades, with the primary objective of predicting future states by analyzing historical data [50], [51], [52]. Traditional spatio-temporal prediction methods are grounded in statistical methods and time series analysis. While these methods have achieved a certain level of success, they often struggle to effectively capture complex spatial structures and intricate spatio-temporal relationships [25], [53]. To address these challenges, researchers have increasingly turned to deep learning frameworks, which are adept at uncovering sophisticated feature representations, including non-linear spatial and temporal correlations, from historical data [14], [54].\nAmong these deep learning approaches, Spatio-Temporal Graph Neural Networks (STGNNs) have emerged as particularly powerful tools for prediction tasks. STGNNS integrate Graph Neural Networks (GNNs) [55] with temporal modeling techniques [16], thereby enhancing their ability to capture complex spatio-temporal dynamics. In recent years, several notable STGNN models have been proposed, including Graph WaveNet [34], STGCN [21], DCRNN [20], and AGCRN [56]. These models have demonstrated remarkable performance across various spatio-temporal prediction tasks. Additionally, the attention mechanism [57] has gained significant popularity due to its effectiveness in modeling dynamic dependencies within spatio-temporal data. Despite the advancements and diversity of STGNN architectures, their performance improvements have begun to plateau. This stagnation has prompted a shift in research focus toward integrating Large Language Models (LLMs) [48], [58], [59], [60] to further enhance predictive capabilities and overcome existing limitations."}, {"title": "III. PRELIMINARIES", "content": "A traffic network can be defined as a graph data structure G = (V, E, A), where |V| = N represents the set of vertices, with N being the number of road segments. Each node corresponds to the location of a road segment, and the observations typically include traffic metrics such as flow and speed on that segment. E represents the set of edges, reflecting the connections between adjacent road segments. The adjacency matrix A \u2208 RN\u00d7N stores the connectivity information, with each element indicating whether the corresponding road segments are directly connected. Thus, G captures the spatial relationships between road segments and the spatial dependencies of traffic flow."}, {"title": "B. Problem Definition", "content": "The graph signal matrix is defined as X(t) \u2208 RN\u00d7C', where C is the number of features and t is the time step. X(t) represents the observed values on each road segment at time t, such as traffic flow and speed. The traffic prediction task in a sensor network can be formulated as:\n[X(t-s+1), ..., X(t); G] \\xrightarrow{\\theta} F(.) \\rightarrow [X(t+1), ..., X(t+h)]\nThe input consists of a sequence of graph signals from time step t \u2212 s+1 to t, along with the network structure G. These are mapped to future graph signals from time step t + 1 to t + h by the learned function F(\u00b7) with parameters \u03b8."}, {"title": "IV. METHODOLOGY", "content": "In this section, we introduce a simple yet efficient framework called the Spatio-Temporal Unitized Model (STUM). The overall architecture of STUM is illustrated in Figure 2 (a). From input to output, the data is partially processed by the Backbone Extractor to extract global spatio-temporal features, while another portion flows through the Multi-Layer Residual Fusion Blocks (MLRF) as shown in Figure 2 (b). The MLRF receives encoded information from a fully connected extractor and computes feature fusion tensors using a fully connected predictor. The Adaptive Spatio-temporal Unitized Cells (ASTUC), implemented using low-rank matrix decomposition as depicted in Figure 2 (c), transform the input tensors into time-adaptive and space-adaptive shapes by embedding feature dimensions. By stacking ASTUC modules, STUM captures fine-grained spatio-temporal dependencies, effectively addressing issues of spatio-temporal heterogeneity and the separation of spatial and temporal modules. In the following subsections, we will delve into the core components of STUM and explain the methodology in detail."}, {"title": "A. Dual Feature Extraction of Spatio-temporal Data", "content": "We introduce two key components to extract temporal dependencies and regional correlations from raw data: the backbone network and the adaptive low-rank linear layer. These components are referred to as spatio-temporal feature extractors, denoted as Fb and Fc, respectively.\nFormally, the input sequence is represented as X = [X1,..., Xs] \u2208 Rs\u00d7n\u00d7c, where n represents the number of nodes, s is the number of time steps, and each node contains c features such as speed, average flow, and direction. The input X is then mapped into two feature spaces as follows:\nZb = F(X) = [f1, ..., fh] \u2208 Rn\u00d7 Cout\nX' = Fc(X) = [W1, ..., Wh] \u2208 Rnxm\nHere, fi and wi represent the global spatio-temporal features extracted by the backbone model and the adaptive spatio-temporal parameters extracted by the ith low-rank fully connected layer, respectively. Cout is the final feature dimension for prediction, and m is the hidden layer dimension.\nThe backbone network component can be a fundamental module, such as a multi-layer perceptron, which serves as a simple yet essential part of our architectural prototype capable of capturing global spatio-temporal dependencies. Additionally, this component can be replaced with other spatio-temporal graph neural networks (STGNNs) as plug-and-play adapters, offering a flexible means to enhance prediction performance. This process is illustrated in Fig. 2(a).\nThe low-rank linear layer is designed to reduce redundant weight tensors and computational costs by adopting low-rank matrix decomposition. This approach captures complex spatio-temporal interactions using fewer parameters, making the model more efficient and scalable. Specifically, we let X' be represented as W(i) = Reshape(Fc(.)) = [w1(i),..., wh(i)] \u2208 RN\u00d7M for the ith update iteration, where N and M denote the input and output dimensions. Given a single-step input x, the parameter updates and results are computed as:\n\u0394\u03c9 = \u0391 \u03a7 BT.\n\u03b1\nYi = \u03c3(w(i)x + \u0394\u03c9(i)x + b)\nHere, A \u2208 RN\u00d7r and B\u2208 RM\u00d7r are low-rank matrices, where the intrinsic rank r < min(N, M). a is the scaling factor, and \u03c3 is the activation function (e.g., ReLU). During inference, W is frozen and does not receive gradient updates, while A and B remain trainable."}, {"title": "B. Unified Representation Cross Space And Time", "content": "The Adaptive Spatio-Temporal Unitized Cell (ASTUC) is a core component designed to simultaneously handle both temporal and spatial information, as well as their interactions within a unified framework. By leveraging low-rank matrix decomposition, ASTUC captures complex spatio-temporal dependencies with fewer learnable parameters, allowing the model to efficiently adapt to specific scenarios without significantly increasing computational complexity. This enables ASTUC to handle spatio-temporal heterogeneity more effectively, enhancing the model's generalization capability.\nThe key idea behind ASTUC is to compute, update, and store temporal and spatial information in a unified parameter matrix. This matrix is calculated through low-rank matrices, allowing ASTUC to flexibly adapt to the dependencies between different time steps and spatial nodes. The iterative process of passing through ASTUC during the ith update is formalized as follows:\nGi) = Update(X:t, G(i-1); W, b)\nGi) = Update(X:t, G(i-1); W, b)\nW + \u0394W = Memory(G(i) G(i), b)\nHere, W is the shared parameter matrix that adaptively changes its shape based on the learned spatio-temporal information, while \u2297 denotes the joint operation between temporal information Gt and spatial information Gs. The bias term b is also included. ASTUC alternates between temporal and spatial updates, generating a rich set of interaction information. Given the redundant and low-rank nature of this information, ASTUC selectively retains or forgets specific parts, ensuring that only the most relevant information is passed to the next unitized cell.\nBy using this unified representation, ASTUC effectively captures dynamic patterns in spatio-temporal data and provides a more comprehensive understanding of the interactions between different time steps and spatial nodes. This process is illustrated in Figure 3, which compares traditional methods that separate temporal and spatial modeling with our integrated low-rank approach."}, {"title": "C. Global Enhancement and Local Refinement", "content": "The Spatio-Temporal Unitized Model (STUM) is designed not only to achieve strong prediction performance trained from scratch but also to enhance existing spatio-temporal prediction models. This dual capability underscores its high generalization potential. Initially, the backbone extractor captures the global dependencies of spatio-temporal data, providing a comprehensive framework for understanding data structure. This allows STUM to integrate seamlessly with various models, improving their performance through effective global enhancement and local refinement.\nFollowing this, our proposed modules, along with the fully connected extractor and predictor, focus on fine-tuning local details. This means that the backbone extractor can be a fundamental module, such as a multi-layer perceptron (MLP) or convolutional neural network (CNN), or it can utilize presently effective spatio-temporal prediction models like the baselines listed in the experimental part. This flexibility highlights the high generalization and extensibility of our model, allowing for seamless integration with existing methods in a plug-and-play manner.\nThe integration of the Adaptive Spatio-Temporal Unitized Cell (ASTUC) and the Multi-Layer Residual Fusion block (MLRF) fosters a synergistic effect, enabling the simultaneous extraction of both temporal and spatial features that traditional models often overlook. The modular nature of STUM allows it to be adapted for diverse prediction tasks simply by swapping components, such as employing different backbone networks. This adaptability ensures that STUM can leverage the strengths of various model architectures while maintaining a unified training approach.\nMoreover, the residual fusion mechanism within the MLRF block enhances effective information sharing between layers, bolstering the model's capacity to recognize intricate patterns across time and space. By employing a gated mechanism, the prediction outputs from both the backbone network and the MLRF block are dynamically weighted, allowing the model to concentrate on the most relevant information. This results in improved robustness against noise and variability in the input data, ultimately leading to more accurate and reliable predictions."}, {"title": "D. Training and Optimization of STUM Framework", "content": "While a single Adaptive Spatio-Temporal Unitized Cell (ASTUC) can effectively transmit either temporal or spatial information, the complexity and heterogeneity of spatio-temporal data require a more advanced mechanism. To address this, we introduce the Multi-Layer Residual Fusion Block (MLRF), which alternates between the transmission of temporal and spatial information across multiple ASTUCs, enabling joint extraction of temporal, spatial, and spatio-temporal interactions.\nThe MLRF block is designed to improve spatio-temporal prediction by cross-stacking ASTUCs of different shapes. This design mitigates the typical separation of temporal and spatial encoding found in deep models, offering a unified approach that simultaneously considers temporal dependencies and spatial region patterns.\nEach MLRF block first normalizes all parameters and then alternates between spatial and temporal information transmission. We denote the spatial and temporal information passing through the ith spatio-temporal unitized cell as G(i) and G(i).\nTo make the decomposed low-rank matrices better suited to the nonlinear spatio-temporal characteristics, we introduce additional constraints and regularization terms to enhance local adaptability. This allows for a more precise capture of dynamic changes in the data, improving the granularity of feature extraction for prediction. The formal definition throughout this process is as follows:\nW(i) = Norm(X) = X \u2022 \\frac{\\frac{W(i-1)}{d}}{\\sqrt{\\sum\\limits_{di=1}{(W(i-1))^2}} + \\epsilon}\nh_t = G^t \\otimes G^s ((... G_t^1 \\otimes G_s^1(W(i))...))\nWhere Xt \u2208 Rn\u00d7f is the spatio-temporal graph input at the tth time step, and ht is the predicted output. The activation function \u2297 includes dropout, activation, and regularization terms that control the complexity of the module. By alternating between temporal and spatial information, MLRF captures intricate spatio-temporal patterns at lower computational costs, thereby improving prediction performance.\nTo address the issue that model parameters may not fully adapt to new or unseen data during training, we propose the Spatio-Temporal Unitized Model (STUM), which combines a spatio-temporal prediction model as the backbone with the plug-and-play MLRF blocks. Finally, we utilize a fully connected layer as the predictor to merge the prediction results from the multi-layer residual fusion module with the predictions of the backbone network. A gated mechanism filters the information to enhance model robustness. The computation process is as follows:\nZt = FC(\u03c3(hi))\nZ = H(zb, Zt; X:t, a) = (1 \u2212 a) \u2299 F(X:t) + azt\nWhere \u03c3 denotes the activation function such as Softmax, F\u2081 is the backbone model's prediction, H represents the weighted residual link operator, and a is the update gate coefficient. Z is the final result of spatio-temporal prediction."}, {"title": "V. EXPERIMENTS", "content": "In this section, we conduct extensive experiments to investigate the following Research Questions (RQ):\n\u2022 RQ1: To what extent does our proposed method improve over the baseline models?\n\u2022 RQ2: Does the STUM model itself perform well without using STGNN as the global feature extractor?\n\u2022 RQ3: What additional training costs in terms of time did we incur to achieve these improvements?\n\u2022 RQ4: What differences in results would be observed by using different components or different parameter settings?\n\u2022 RQ5: Does our approach truly explain and predict regional traffic flow on a more fine-grained basis?"}, {"title": "A. Experimental Setup", "content": "We validate our approach on four real-world datasets widely used in spatio-temporal forecasting. Each dataset comprises tens of thousands of time steps and hundreds of sensors, capturing real-world traffic flow data. Table I summarizes the statistical information for each dataset. These datasets were first introduced by [29]. The traffic flow data is represented as integers, with values potentially reaching into the hundreds, reflecting the count of passing vehicles. All datasets are divided into non-overlapping training, validation, and test sets using a 6:2:2 split along the time axis."}, {"title": "B. Performance Comparisons (RQ1 and RQ2)", "content": "Each baseline model has been widely used in spatio-temporal forecasting and offers a distinct approach to handling spatial and temporal dependencies. We use these baseline models as backbone extractors to improve the performance of STUM across various metrics. As shown in Table II, all methods trained as backbone network feature extractors combined with the STUM framework achieved more optimal performance than the original model in all datasets, which indicates that our model is very effective. STGCN shows the most significant improvement (about 19.17%) when combined with STUM. This is likely due to the limited ability to capture complex spatio-temporal dependencies, which separate temporal and spatial convolutions. GWN still struggles to fully capture intricate temporal patterns in rapidly changing traffic conditions. While STUM equipped GWN enabling it to capture finer temporal patterns and regional interactions more effectively (about 5.47% improvement). Despite this, AGCRN and D2STGNN, which are more advanced models with adaptive mechanisms for learning spatial dependencies, also benefit (about 8.99% and 8.03%) from the addition of STUM. While their original performance is already strong, STUM further enhances their ability to capture dynamic spatio-temporal relationships due to fine-grained local information. STAE, as a SOTA model in recent years, improved (about 8.77%) from STUM relatively smaller compared to other models because it already incorporates sophisticated mechanisms for encoding spatio-temporal interactions. Nevertheless, the addition of STUM refines the model's ability to fine-tune regional and temporal interactions, resulting in a modest but consistent enhancement in overall performance. STID has a relatively simple structure relying on simple identity embeddings. Due to this nature, STID can only achieve a relatively small 6.32% enhancement when used in combination with our method.\nTo further examine the independent performance of STUM without relying on other Spatio-temporal graph neural networks as a backbone extractor to capture global features, we conducted additional experiments across the PEMS03, PEMS04, PEMS07, and PEMS08 datasets. As presented in Table III, the results indicate that STUM performs robustly even without advanced global feature extraction. Across both short-term and long-term forecasting tasks, STUM consistently outperforms the three baseline models including STGCN, GWNet and ACGRN in almost all cases, demonstrating its ability to capture local spatio-temporal patterns effectively. This highlights that even without complex global feature extraction, STUM exhibits strong standalone performance, making it a viable and efficient model for spatio-temporal forecasting tasks."}, {"title": "C. Efficiency Analysis (RQ3)", "content": "We significantly increased the effectiveness of the model with only a small amount of additional training cost. Figure 4 (a) shows the difference in time cost between training some models from scratch before and after combining them with our proposed framework, while Figure 4 (b) illustrates the reduction in MAE metrics. We fixed the number of MLRFs to 4, the number of ASTUCs Gs and Gt to 8, and the embedding dimension to 16. We observe that the low-rank adaptation portion of our framework allows the training time to remain stable even when multiple ASTUCs are used. These improvements are achieved with minimal additional training time, highlighting the efficiency of our framework in balancing both accuracy and computational cost."}, {"title": "D. Ablation Study (RQ4)", "content": "In this section, we conduct a comprehensive ablation study to analyze the sensitivity of various hyper-parameters in our model and the impact of different feature extractors. Specifically, we varied the number of MLRFS, ASTUCs, and the embedding dimension while maintaining other settings consistent with RQ2. Table IV summarizes the results, elucidating the trade-offs between model complexity and prediction accuracy. The results demonstrate that integrating STUM with AGCRN provides significant improvements in long-term (60mins) spatio-temporal forecasting. Each component of the STUM framework plays a vital role. Removing either the backbone extractor or our proposed modules (MLRFs and ASTUCs) significantly diminishes the optimization effect. However, even when replacing the backbone extractor with a simpler MLP, the model still achieves meaningful improvements, indicating that our framework does not heavily rely on the specific forecasting model, thus showcasing strong generalization capabilities.\nMoreover, when we increased the number of MLRFs, ASTUCs, or the embedding dimension while keeping other parameters fixed, the model's performance consistently improved, confirming that all these parameters contribute positively to the model's predictive ability. Among these, increasing the number of ASTUCs provided the largest gain. However, increasing the embedding dimension or excessively adding residual fusion layers led to diminishing returns. This is because deeper residual fusion modules are prone to gradient vanishing and exploding problems, which can degrade performance. Additionally, increasing the number of parameters also makes training more difficult. The embedding dimension reflects the intrinsic rank of the parameter matrix, and an excessively large intrinsic rank can make the model overly complex and challenging to learn.\nThe low-rank matrix factorization mechanism in our framework ensures that the additional computational cost resulting from increasing the number of ASTUC layers is minimized, while significantly enhancing the model's ability to capture more intricate spatio-temporal dependencies. However, to achieve optimal performance, it is advisable to adjust other parameters alongside increasing the ASTUC layers to balance the model's complexity and accuracy."}, {"title": "E. Visualization Case Study (RQ5)", "content": "To further illustrate why STUM is effective, we present a case study on enhancing region embeddings learned from the MLRF. This visualization highlights two key features optimized by the STUM framework: 1) Region refinement, where neighboring regions with similar traffic flows are closely clustered; and 2) Spatio-temporal utilization, where uniform nodes from different time steps are closer together in the embedding space.\nAs shown in Figure 5 (a), we use the t-SNE node embedding visualization in the 2D plane to demonstrate that the backbone extractor has captured the dispersed traffic patterns on the PEMS04 dataset. In Figure 5 (b), the MLRF further clusters regional information more precisely, thus showing that the STUM framework provides a more fine-grained interpretation and prediction of regional traffic flow. Noted that we have highlighted three pairs of points representing different regions corresponding to Figure 1: red points 52 and 90 represent residential areas, green points 37 and 61 represent park districts, and blue points 93 and 114 represent business districts. The distances labeled between each pair of points intuitively demonstrate how our method effectively clusters and refines regional information, providing clearer distinctions and insights. Compared to other models, the results show that our method better gathers the sensor points with similar characteristics, thereby clustering their spatio-temporal information. This validates both the effectiveness and generalization capability of our module.\nIn the visualization of traffic flow prediction results shown in Figure 6, the STUM model consistently outperforms the baseline models across various regions, particularly excelling at capturing traffic flow trends. Specifically, in the three nodes representing a park district, residential area, and business district, the STUM model accurately predicts the downward trends in traffic flow. In regions with more volatile traffic patterns (e.g., the business district), its predictions are closer to the ground truth compared to the STAE model. Furthermore, the STUM model consistently aligns well with actual data during the early stages of traffic flow decline, demonstrating its robust capability in modeling complex spatio-temporal features. This superior predictive performance further confirms the effectiveness and advantages of the STUM model in spatio-temporal traffic forecasting tasks."}, {"title": "VI. CONCLUSION", "content": "In this paper, we address several critical challenges in spatio-temporal forecasting, including data heterogeneity, the separation of spatial and temporal modules, and low combination efficiency. To tackle these issues, we introduce the STUM, which unifies spatial and temporal processing in a single framework. Our approach leverages the ASTUCS to effectively capture complex spatio-temporal dependencies. This unified module directly addresses the inefficiency caused by spatial and temporal module separation, ensuring that region relationships are propagated more effectively across different time steps. Furthermore, by incorporating multi-layer residual fusion modules, we mitigate the computational burden and improve combination efficiency without compromising performance. Extensive experiments and analyses demonstrate that our approach consistently outperforms existing methods across various benchmarks. In the future, we plan to explore the potential of a unified spatio-temporal framework for multi-task generalization while integrating additional optimization techniques to further boost efficiency and performance."}, {"title": "VII. ACKNOWLEDGMENTS", "content": "This work is mainly supported by the National Natural Science Foundation of China (No. 62402414). This work is also supported by the Guangzhou-HKUST(GZ) Joint Funding Program (No. 2024A03J0620), Guangzhou Municipal Science and Technology Project (No. 2023A03J0011), the Guangzhou Industrial Information and Intelligent Key Laboratory Project (No. 2024A03J0628), and a grant from State Key Laboratory of Resources and Environmental Information System, and Guangdong Provincial Key Lab of Integrated Communication, Sensing and Computation for Ubiquitous Internet of Things (No. 2023B1212010007)."}]}