{"title": "SmartLLM: Smart Contract Auditing using Custom Generative AI", "authors": ["Jun Kevin", "Pujianto Yugopuspito"], "abstract": "Smart contracts, integral to decentralized finance (DeFi) and blockchain ecosystems, are increasingly vulnerable to exploits due to coding errors and complex attack vectors. Traditional static analysis tools and existing vulnerability detection methods often fail to address these challenges comprehensively, resulting in high false-positive rates and an inability to detect dynamic vulnerabilities. This paper introduces SmartLLM, a novel approach leveraging fine-tuned LLaMA 3.1 models with Retrieval-Augmented Generation (RAG) to enhance the accuracy and efficiency of smart contract auditing. By integrating domain-specific knowledge from ERC standards and employing advanced techniques such as QLoRA for efficient fine-tuning, SmartLLM achieves superior performance compared to static analysis tools like Mythril and Slither and zero-shot LLM prompting (e.g., ChatGPT-3.5 and GPT-4). Experimental results demonstrate a perfect recall of 100% and an accuracy score of 70.0%, underscoring the model's robustness in identifying vulnerabilities, including re-entrancy and access control issues. This research advances smart contract security by offering a scalable and effective auditing solution, supporting the secure adoption of decentralized applications.", "sections": [{"title": "1 Introduction", "content": "Since the inception of Bitcoin, blockchain technology has significantly evolved, with Ethereum emerging as a pivotal development. Ethereum, a decentralized and open-source blockchain platform, enables the creation and execution of decentralized applications (DApps) and smart contracts. Ethereum Request for Comments (ERCs) have been developed to standardize smart contracts [1]. Among these, ERC-20 is notable for defining rules for fungible tokens and ensuring interoperability across various Ethereum-based projects [2]. However, smart contracts are not immune to vulnerabilities, and violations of ERC standards can lead to severe interoperability issues, security risks, and financial losses [3,4].\nThe rapid growth of blockchain and decentralized finance (DeFi) has transformed the financial landscape by offering new opportunities for peer-to-peer transactions and automated services. Despite their advantages, smart contracts are susceptible to attacks and vulnerabilities, including integer overflow, re-entrancy, and access control issues, which can result in significant financial damage and erode trust in the DeFi ecosystem [5, 6]. As smart contracts become increasingly integral to DeFi applications, the need for robust security measures and innovative auditing techniques is crucial to mitigate these risks and ensure the security and reliability of decentralized financial systems [7].\nSmart contract vulnerabilities often stem from coding flaws, significantly compromising the security and functionality of decentralized applications. Common issues include integer overflow, re-entrancy attacks, and inadequate access control mechanisms, all arising from code logic errors, improper use of programming constructs, or missing validation checks [6,8]. For instance, re-entrancy vulnerabilities occur when improper handling of external function calls allows attackers to repeatedly withdraw funds before the contract updates its balance [9]. Similarly, integer overflow happens when numerical calculations exceed the storage capacity, leading to incorrect results or exploitable conditions. Access control issues pose risks where insufficient authorization checks enable unauthorized users to manipulate contract functions [5]. Given the immutable nature of blockchain, once a smart contract is deployed, its code cannot be modified, making these vulnerabilities particularly critical. This immutability means that any security flaws can be exploited without retroactive fixes, potentially leading to substantial financial losses and eroding trust in the blockchain ecosystem [6,7].\nStatic code analysis is a common technique for identifying vulnerabilities in smart contracts before deployment, as it examines the code without execution to detect potential risks. However, this approach has significant limitations, often struggling to identify complex vulnerabilities that depend on dynamic execution contexts, such as interactions between multiple contracts or external data sources [5, 8]. Additionally, static analysis may generate numerous false positives, requiring extensive manual verification to filter out benign code patterns [6]. The approach also falls short when dealing with evolving coding practices and emerging"}, {"title": "2 Literature Review", "content": "The ERC-20 standard defines a set of rules for fungible tokens on the Ethereum blockchain, enabling interoperability between decentralized applications (DApps) and ensuring uniformity in token behavior [11]. The standard specifies six key functions, including transfer for token transfers and approve for delegated spending, along with two events, Transfer and Approval, to log token transactions and approvals [12].\nDespite its widespread adoption, ERC-20 compliance is not without challenges. Violations of the standard can lead to issues such as unhandled return values in transfer functions or insufficient validation of input parameters, which increase the risk of vulnerabilities [11]. These challenges underline the need for automated auditing tools to ensure compliance and security in ERC-20 implementations."}, {"title": "2.2 Static Code Analysis", "content": "Static code analysis is a prevalent method for identifying vulnerabilities in smart contracts before deployment. It analyzes code without executing it, allowing tools like Mythril and Slither to detect common issues such as reentrancy and integer overflow [12, 13].\nHowever, static analysis has significant limitations. It struggles to detect vulnerabilities arising from dynamic execution contexts, such as those involving external contract interactions or real-time data dependencies [12]. Additionally, the reliance on predefined patterns often leads to high false positive rates, requiring extensive manual verification to filter benign code patterns. These limitations highlight the need for more advanced auditing methods, such as those leveraging generative AI."}, {"title": "2.3 Generative AI", "content": "Generative AI represents a class of artificial intelligence systems designed to generate coherent, contextually relevant outputs based on input data [14]. These models are built on large-scale neural networks, such as transformers, which excel at understanding patterns in text and generating human-like responses. The rise of Generative AI has transformed various domains, including natural language processing, code generation, and automated reasoning [15].\nIn the context of smart contract auditing, Generative AI models, such as GPT and LLaMA, offer a significant advantage over traditional static analysis tools [16]. By leveraging contextual understanding and pattern recognition, these models can detect vulnerabilities that are often missed by rule-based methods. For instance, Generative AI can analyze reentrancy vulnerabilities by understanding both the code and its dynamic execution context, enabling more comprehensive assessments [6].\nGenerative AI also introduces flexibility through techniques like fine-tuning and retrieval-augmented generation (RAG) [17,18]. These capabilities allow models to adapt to specific domains, such as smart contract security, by incorporating domain-specific knowledge bases like ERC documentation. However, challenges remain, including the computational cost of training and inference, reliance on large annotated datasets, and the need for interpretability in critical applications.\nDespite these challenges, the application of Generative AI in vulnerability detection is a promising frontier, bridging the gap between static analysis and dynamic reasoning to enhance the security of decentralized systems."}, {"title": "2.4 LLaMA 3.1", "content": "LLaMA (Large Language Model Meta AI) is a series of large language models designed to deliver state-of-the-art performance with optimized computational efficiency [19]. The LLaMA 3.1 model introduces enhancements in contextual understanding and computational efficiency, making it particularly suited for tasks requiring deep code analysis and reasoning.\nIn the context of smart contract auditing, LLaMA 3.1's ability to process long sequences and recognize complex patterns in code positions it as a valuable tool. By integrating this model with fine-tuning techniques and domain-specific knowledge bases, it can effectively identify vulnerabilities that static analysis tools may overlook."}, {"title": "2.5 QLORA: Efficient Finetuning of Quantized LLMS", "content": "QLORA (Quantized Low-Rank Adaptation) is an efficient fine-tuning technique that significantly reduces the memory and computational requirements for large language models [20]. By employing low-rank adaptation with 4-bit quantization, QLORA enables the fine-tuning of models like LLaMA 3.1 on resource-constrained hardware without compromising performance.\nThis technique uses paged optimizers to handle memory spikes efficiently, as illustrated in Fig. 1, allowing for smoother training on GPUs with limited memory capacity. In this research, QLoRA is applied to fine-tune LLaMA 3.1 using domain-specific datasets, such as smart contract code and ERC documentation. This approach ensures the model is adapted efficiently for smart contract vulnerability detection while maintaining feasibility for deployment on standard hardware setups."}, {"title": "3 Research Methodology", "content": "The dataset for this research includes smart contract code sourced from Etherscan, a widely-used platform for Ethereum blockchain data. The dataset includes labeled examples of vulnerable and non-vulnerable contracts, which were essential for training and evaluation. The dataset includes 300 smart contract samples, equally split between vulnerable and non-vulnerable contracts:\n\u2022 Vulnerable contracts: 150 samples with three distinct vulnerability types:\nRe-Entrancy: Improper handling of external calls, allowing repeated execution (49 samples).\nAccess Control: Insufficient authorization checks (40 samples).\nLogic Error: Errors in code logic leading to unintended behaviors (61 samples).\n\u2022 Non-vulnerable contracts: 150 samples with correct implementations.\nThe dataset was split into training and testing subsets using 80:20 ratio. Specifically, 240 contracts (120 vulnerable and 120 non-vulnerable) were used for training, while the remaining 60 contracts (30 vulnerable and 30 non-vulnerable) were used for testing.\nTo illustrate the vulnerabilities present in the dataset, a simplified example of a vulnerable ERC-20 smart contract is shown in Listing 1. The corpus for RAG comprises ERC-20 documentation [1,2]."}, {"title": "3.2 Data Preprocessing", "content": "Prior to training, the smart contract code was preprocessed to remove irrelevant comments, normalize formatting, and tokenize using the LLaMA tokenizer. The corpus for RAG"}, {"title": "3.5 Evaluation Metrics", "content": "The effectiveness of the proposed approach was evaluated using the following metrics:\n\u2022 Confusion Matrix: A table summarizing the model performance by showing the counts of true positives (TP), true negatives (TN), false positives (FP) and false negatives (FN). This provides an overview of the model's classification capabilities.\n\u2022 Accuracy: The proportion of correct predictions across all samples, calculated as:\n$Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$ (1)\n\u2022 Recall: The model's ability to identify all vulnerable contracts, calculated as:\n$Recall = \\frac{TP}{TP + FN}$ (2)\n\u2022 F1 Score: The harmonic mean of precision and recall, providing a balanced measure of the model's accuracy and completeness:\n$F1 Score = 2.\\frac{Precision \\cdot Recall}{Precision + Recall}$ (3)\n\u2022 Precision: The proportion of correctly predicted vulnerabilities out of all positive predictions, calculated as:\n$Precision = \\frac{TP}{TP + FP}$ (4)\nThese metrics provide a comprehensive evaluation of the model's performance, enabling comparisons with static analysis tools (e.g., Mythril, Slither) and zero-shot prompting with large language models."}, {"title": "4 Results and Discussion", "content": "To evaluate the proposed methodology, we compared its performance against two categories of benchmarks: static code analysis tools and zero-shot prompting with large language models (LLM). For static code analysis, we selected industry-standard tools, including Mythril and Slither. For zero-shot prompting, we utilized advanced LLMs, including GPT-3.5 and GPT-4. These models were assessed without any task-specific fine-tuning, relying solely on their pre-trained knowledge to classify smart contracts as vulnerable (Y) or non-vulnerable (N). This setup tested the LLMs' ability to reason over smart contract code and provide accurate classifications directly.\nOur proposed method differs significantly from these benchmarks. By integrating Retrieval-Augmented Generation (RAG), the model retrieves domain-specific knowledge"}, {"title": "4.3 Discussion", "content": "Table 2 highlights the strengths and limitations of the proposed SmartLLM approach in detecting vulnerabilities. While achieving outstanding recall (100%), a strong F1 score (76.9%) and accuracy (70.0%), there are key opportunities for improvement and challenges to address.\nOpportunities: Improving precision (currently 62.5%) is essential to reduce false positives, which can be achieved through fine-tuning with more diverse and balanced datasets. Additionally, integrating dynamic execution contexts, expanding datasets to cover emerging vulnerabilities, and leveraging multi-modal inputs (e.g., audit reports) present significant opportunities to enhance the model's capability.\nChallenges: The model faces token limitations that hinder processing long contracts, difficulties in generalizing across platforms, and interpreting complex attack vectors like multi-step vulnerabilities. Furthermore, the computational cost of fine-tuning and deploying large models remains a practical challenge for real-time applications."}, {"title": "5 Conclusion", "content": "This study introduced SmartLLM, a novel approach leveraging Retrieval-Augmented Generation (RAG) and fine-tuned LLaMA 3.1 models for smart contract vulnerability detection, with a focus on improving accuracy, recall, precision, and F1 scores. By integrating ERC documentation into the vulnerability detection process, the model addresses gaps in static analysis tools and zero-shot large language models (LLMs), delivering superior results.\nThe proposed model achieved significant advancements over traditional tools like Mythril and Slither, and over zero-shot LLM prompting (e.g., ChatGPT-3.5 and ChatGPT-4). SmartLLM demonstrated a high recall of 100%, ensuring comprehensive detection of vulnerabilities while achieving a balanced precision of 62.5% and a strong F1 score of 76.9% and accuracy 70.0%. These results indicate the model's robustness in detecting common and complex vulnerabilities, such as re-entrancy and access control issues, surpassing conventional methods.\nKey findings highlight the effectiveness of domain-specific knowledge integration and fine-tuning techniques like QLoRA in enhancing detection accuracy. The proposed system successfully bridges the gap between static analysis tools and dynamic reasoning capabilities, providing a reliable and scalable solution for auditing Ethereum smart contracts.\nDespite these achievements, challenges remain, including improving the precision to reduce false positives and addressing computational resource constraints during model fine-tuning and deployment. Future work should focus on incorporating dynamic execution contexts, broader datasets covering emerging attack vectors, and larger pre-trained models (e.g., LLaMA 70B and 405B) to enhance both precision and scalability.\nIn summary, SmartLLM represents a significant step forward in ensuring the security and reliability of smart contracts, contributing to the advancement of auditing techniques in decentralized finance (DeFi) and blockchain ecosystems. By enhancing vulnerability detection and reducing manual verification efforts, the proposed approach supports the broader adoption of secure and trustworthy decentralized applications."}]}