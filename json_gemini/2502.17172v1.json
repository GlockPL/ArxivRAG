{"title": "Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being", "authors": ["Bin Yin", "Chong-Yi Liu", "Liya Fu", "Jinkun Zhang"], "abstract": "Affective computing has advanced significantly over the past two decades, achieving remarkable progress in emotion recognition and generation. However, current approaches remain largely focused on short-term pattern recognition, lacking a comprehensive theoretical framework to guide affective agents in aligning with long-term human well-being. To address this gap, we propose a teleology-driven affective computing framework, which unifies major emotion theories basic emotion, appraisal, and constructivist approaches under the premise that affect is an adaptive, goal-directed process that facilitates survival and development. Building on this foundation, our framework emphasizes the alignment of agent responses with personal/individual and group/collective well-being over extended timescales. We advocate for developing a large-scale \u201cdataverse\u201d of personal affective events, capturing the longitudinal interplay between beliefs, goals, actions, and outcomes using real-world experience sampling and immersive virtual reality. By leveraging causal modeling, this \u201cdataverse\u201d enables AI systems to infer individuals' unique affective concerns and provide tailored interventions that support sustained well-being. Furthermore, we introduce a meta-reinforcement learning paradigm to train affective agents in simulated environments. This allows them to dynamically adapt to evolving affective concerns and balance hierarchical goals-ranging from immediate affective concerns to long-term self-actualization. We call for a shift from traditional modeling based on statistical correlations to causal reasoning, enhancing agents' ability to predict and proactively respond to emotional challenges. Ultimately, this framework offers a conceptual foundation for developing adaptive, personalized, and ethically aligned affective computing systems that promote meaningful human-AI interactions and long-term societal well-being.", "sections": [{"title": "1. INTRODUCTION", "content": "The scientific community, long emphasizing rational thought, logical reasoning, operationalization, and reproducibility, has often regarded emotions with a certain detachment. Consequently, when Picard [1] first proposed the concept of affective computing, it garnered limited attention. However, addressing certain engineering challenges inevitably involves engaging with emotions, often considered \"irrational.\" For instance, early computer vision systems were largely modeled after the structure and function of the human visual cortex [2]. Yet, creating such systems was not merely about detecting high-contrast lines or distinguishing apples from pears; it required identifying elements of interest and adapting to shifting priorities automatically - tasks that no purely engineering-based approach could achieve [3]. Marvin Minsky emphasized that emotions are not the antithesis of rationality but are critical mechanisms enabling humans to make efficient decisions in complex environments [4]. He viewed emotions as a strategic selection system governing thoughts and actions, determining when to persist, abandon, or switch goals. This perspective aligns closely with the core objectives of affective computing, which aims to endow computational systems with similar strategic adaptability, a foundational step toward intelligent human-computer interaction.\n\nThe value of affective computing has been validated in various artificial intelligence (AI) applications, such as intelligent assistants, social robots, virtual reality, and augmented reality systems. The capacity for emotional understanding and responsiveness significantly enhances user experiences. Beyond enabling more natural and human-like interactions, affective computing also plays vital roles in healthcare, education, and psychotherapy [5]. Driven by this expanded understanding of emotional functionality, an increasing number of engineers and computer scientists have been drawn to this previously \u201cniche\u201d field. They provide a variety of information technology tools and engineering capabilities to create a computing system that can accurately perceive, recognize, understand and respond to human emotions based on behavioral cues and contextual situations [5]. As a result, affective computing has evolved into an interdisciplinary domain, integrating insights from psychology, computer science, information technology, mechanical engineering, and bioengineering [5], [6]. Researchers aim to create intelligent agents that better understand human emotional needs [1], fostering harmonious human-computer interactions and advancing user-centered AI [7], [8], [9].\n\nCurrent research in affective computing primarily focuses on two areas: emotional analysis [10], [11] and the generation and expression of emotions [12], [13]. Emotional analysis involves modeling and recognizing multidimensional emotional signals"}, {"title": "2. A TELEOLOGICAL PERSPECTIVE ON MAJOR EMOTION THEORIES", "content": "Contemporary emotion theories have yet to reach a consensus on fundamental assumptions, with even the basic definition of \"emotion\" remaining a contentious issue [25], [26], [27], [28], [29], [30]. These theoretical paradigms propose various perspectives, including basic emotion theories, appraisal theories, and constructivist approaches (both psychological and social) [31]. While these theories offer unique perspectives, long- standing criticisms and misunderstandings have hindered the full development and application of their core ideas. This has left the field of affective computing without a unified theoretical framework. Just as the Industrial Revolution relied on the foundational principles of Newtonian physics to drive technological progress, achieving the goal of creating genuine affective agents requires addressing the foundational gaps in psychological theories of emotion and integrating these insights into computational systems. Teleology provides a powerful integrative framework by emphasizing affects as functional tools that organisms use to adapt to their environments and achieve goals. This perspective bridges the divides between basic emotion theories, appraisal theories, and constructivist approaches, underscoring the core role of affects in helping individuals adapt and achieve their objectives.\n\nWhen applied to psychology, teleology posits that mental constructs exist to serve adaptive or functional purposes [32]. In studying affective phenomena, this perspective prompts us to consider why humans evolved affects. To serve evolutionary purposes, affects must be linked to functional components in the physical world [33]. Specifically, affects can be defined as psychological mechanisms supporting life [25], [29] and naturally extend the observation of affective phenomena from humans to other animals [34], [35], [36], [37], [38], [39], [40], [41], [42]. From this perspective, affect serve as internal states that mediate between causes and outcomes of actions. Their functional significance can be demonstrated through operant and reinforcement processes, revealing remarkable conservation across species. Despite criticism tying consciousness tightly to affects and questioning the study of affects in animals unable to self-report, neuroscience research increasingly reveals convergent neural mechanisms underlying affective responses across species [37], [43], [44], [45]. Panksepp [44] introduced the concept of \"affective neuroscience,\" integrating the shared functions of affective systems across species and highlighting affects as foundational to the development of complex cognitive abilities.\n\nThe teleological approach provides a psychological rationale for explaining behavior, focusing on biological needs or goals [32]. For instance, fear (an emotional response) triggers behavioral actions (such as freezing or fleeing) aimed at protecting the organism from potential harm. Each action is goal- driven during interactions with the external environment. In contrast, mechanisms based purely on mathematics, probability, geometry, or logic, which disregard physical implementation factors, do not align with the goal-oriented paradigm that underlies biological intelligence [46]. At a broader biological level, maintaining self-continuity and coherence serves as the overarching principle guiding all actions [24]. This principle ensures that biological systems maintain homeostasis within specific ranges [47]. The fundamental biological goals of securing comfort and propagating genes underpin a wide range of affective phenomena, from simple interests and moods to more complex desires, ethics, and aesthetics [44]. Cross-species research provides evidence for the evolutionary continuity of emotional systems, which act as a universal currency in decision- making: pleasure motivates behavior persistence, while discomfort drives avoidance [48].\n\nModern theories of emotion emphasize their adaptive functions. Basic emotion theories agree that distinct functional emotions evolved to address specific adaptive challenges recurring threats or opportunities related to survival and health [44], [47], [49]. For example, Ekman [50] argued that emotional processes coordinate physiological, non-verbal, attentional, cognitive, motivational, sensory, and behavioral responses when triggered by specific contexts. Appraisal theorists similarly recognize the adaptive nature of emotions, defining them as mechanisms that drive organisms to respond appropriately to environmental changes. Arnold [51] described emotions as approach responses to beneficial stimuli or avoidance responses to harmful ones. This evaluation process continuously monitors the relationship between an organism and its \"comfort zone\u201d, integrating multiple dimensions such as needs, goals, and values [52]. Thus, even in identical situations, individuals may generate different emotional responses based on their unique appraisals. Constructivist approaches view emotions as brain-generated constructs shaped by combinations of basic sensory inputs, concepts, and categories, influenced by both cognitive processes and biological factors. Emotional expressions and physiological features are closely tied to past experiences, exhibiting flexibility and context dependence. For instance, a smile's muscle movements might convey anger in one context but friendliness or joy in another.\n\nThe classification principles of emotions reflect differing extensions of teleological assumptions in emotional theories. Scientists debate whether emotions should be described along dimensions like valence and arousal or as discrete entities [53]. Basic emotion theories typically adopt a discrete view, dividing emotions into categories defined by specific emotional programs. Each category represents an organism's relationship with its environment, such as fear protecting against harm or disgust rejecting harmful substances [50]. In contrast, appraisal theories argue for dimensional constructs, suggesting that emotions arise from evaluative patterns along multiple dimensions. These dimensions combine in diverse ways to produce a broad spectrum of emotional states. For appraisal theorists, emotions are valenced according to their alignment with goals or goal states. Positive emotions arise when goals are achieved, while negative emotions reflect failures. An organism's primary task is not to process information but to fulfill its goals, necessitating continuous cycles of actions that serve these goals [54], [55]. Appraisal theory conceptualizes goals as the individual's well-being, with the appraisal process serving to detect and evaluate the importance of the environment's impact on well-being [56]. Within this framework, the appraisal process assesses the influence of the environment on an individual's well-being, incorporating multidimensional factors such as needs, beliefs, and attachments [52], [56], [57], [58]. It is crucial to recognize that these concerns precede specific emotions and exist independently of them, functioning as an emotional state akin to desire [59].\n\nWhile constructivism recognizes the utility of emotion categories, it emphasizes that valence and arousal are central features that vary depending on the context and the individual's experiences. Emotional instances emerge as events occurring in specific contexts. When the brain reconstructs past events similar to the present, it generates categories containing potential future emotional instances [27]. These categories encapsulate abstract psychological features such as goals, values, and threats, emphasizing the importance of concerns in the emotional generation process.\n\nIn summary, although differing metaphysical and mechanistic assumptions underpin these theories, teleological principles focusing on goal-directed behaviors and adaptive functions offer a way to unify them into a cohesive framework. Schiller et al. [24] proposed the concept of the \"Human Affectome,\" a framework integrating diverse assumptions about emotions into a unified model. This model views affects as dynamic phenomena emerging from the interactions between organisms and their environments, encompassing both concerns (factors influencing affective experiences) and features (adaptive changes such as valence and arousal). This framework provides a novel perspective and integrative strategies for advancing research in affective computing."}, {"title": "3. CURRENT RESEARCH IN AFFECTIVE COMPUTING", "content": "Current research in affective computing can be broadly divided into two main domains: emotional analysis and emotional generation/expression. The former focuses on modeling and recognizing patterns in external emotional expressions (such as facial expressions, vocal tones, and movements) and physiological signals (e.g., heart rate, blood pressure, pulse, and body temperature). The latter aims to develop affective agents capable of generating emotions and assessing possible user emotional responses by calculating events and evaluating outcomes [61]. This section will analyze mainstream computational models and research achievements in these two domains, as well as evaluate the theoretical assumptions underpinning them."}, {"title": "3.1 Emotional Analysis - Modeling and Recognizing Emotional Representations", "content": "Living organisms consistently use emotional expressions to communicate with others, even across species. For humans, such expressions aid in coordinating personal, interpersonal, and social behaviors. One of the key goals of affective computing is to \"understand\" the underlying emotional states of interaction partners. Humans typically express emotions through a combination of verbal communication, vocal intonation, facial expressions, and body language. Researchers have attempted to infer users' emotional states using single-modal physical data, with studies focusing on text sentiment analysis, speech emotion recognition, and visual emotion recognition (for detailed reviews of these three areas, see [9]). Traditional single-modal emotion recognition typically relies on a process called \"feature engineering\" [62], where relevant emotion-related features are extracted from raw data and input into predictive models that output corresponding emotional states. Deep neural networks, by aggregating activations from interconnected layers of processing units (neurons), can automatically extract useful features from raw data [63], enabling end-to-end emotional analysis. However, pattern recognition based on external emotional expressions is not always reliable. Social norms or individual concerns about judgment can lead people to unconsciously or deliberately mask their true emotional states, reducing the accuracy of single-modal emotion recognition methods.\n\nIn uncovering hidden emotions, micro-expression recognition (MER) in visual emotion analysis often performs better [64], [65], [66]. Ekman's research showed that micro-expressions, as a specific type of facial expression, are typically involuntarily displayed when individuals attempt to hide their true feelings, reflecting spontaneous facial movements in response to emotional stimuli [67], [68], [69]. Thus, micro-expressions provide a valuable source of information for decoding authentic emotional states. Like general facial expression recognition, MER involves categorizing facial images or sequences into corresponding emotion classes. However, detecting these fleeting, subtle facial movements is often more challenging [64]. Early MER approaches also relied on manually crafted facial features. Tools such as the Facial Action Coding System (FACS) developed by Ekman [70] and the Micro-Expression Training Tool (METT) provided researchers with essential prior knowledge for encoding features (for comprehensive reviews of MER's historical evolution and technological advancements, see [71], [72], [73], [74]). In recent years, more advanced models, such as 3D Convolutional Neural Networks (3D CNNs) and Recurrent Neural Networks (RNNs), have been used to capture the spatiotemporal characteristics of micro-expressions (e.g., [75], [76], [77], [78], [79], [80], [81], [82]). Despite significant progress achieved using deep learning-based MER, challenges remain, particularly concerning datasets. Guoying Zhao and collaborators [64], [83] found that although numerous micro- expression datasets have been developed, most remain limited in size, containing only a few hundred samples. Additionally, these datasets often suffer from imbalanced emotion categories and are predominantly collected in laboratory settings, which limits the generalizability of MER models to real-world environments.\n\nPhysiological signals (e.g., EEG, skin conductance, and ECG) also represent emotion-related indicators that are difficult to consciously control, as they reflect central and autonomic nervous system activities associated with emotional states [84], [85]. Picard and her team utilized multi-channel signals from the autonomic nervous system to identify human emotional states. They developed various wearable devices [86], [87] and non- contact devices [88], [89] capable of recording physiological signals such as skin conductance, heart rate, and physical activity in real-life scenarios. These physiological measurements provide objective data to identify risk factors for high stress and poor mental health [90], [91], [92], [93]. Moreover, electroencephalography (EEG) has become an essential signal for recording central nervous system activity due to its non- invasive, fast, portable, and cost-effective nature. EEG signals are widely used in fields such as entertainment, virtual reality, and e-healthcare for identifying emotional states [94], [95]. While EEG signals directly reflect the brain's electrophysiological activity, linking them to the central nervous mechanisms of emotional states [96], practical challenges remain in model transferability and generalization. In EEG emotion recognition research, researchers often address individual differences within the same dataset to construct models generalizable to all individuals [97], [98], [99], [100]). However, variability in devices, experimental designs, and stimuli across datasets necessitates further exploration of how knowledge trained on one dataset can be transferred to others [96].\n\nWhen external environments become overly complex, single- modal signals are often affected by noise, resulting in reduced emotion recognition performance. Considering that humans express emotions through multiple modalities rather than relying on a single channel, research has increasingly focused on multimodal emotion recognition (e.g., [14], [101], [102], [103], [104]). Similar to single-modal approaches, multimodal emotion recognition involves extracting features from raw data across different modalities and training classifiers to predict emotional states. However, inherent issues arise from asynchronous sampling rates across modalities, leading to misaligned data during fusion [103], [105]. To address this, Tsai et al., [103] developed a model based on the Transformer framework that facilitates cross-modal interactions. The multi-head attention module in this framework allows for directional pairwise cross- modal attention and further focuses on interactions between multimodal sequences across varying time steps, achieving alignment and fusion of information. Additionally, recent studies have focused on addressing feature space distribution gaps caused by multimodal signal heterogeneity (e.g., [101], [102], [104]). In general, multimodal emotion analysis requires selecting appropriate single-modal emotion data and determining a fusion strategy, which may occur at the feature level, decision level, model level, or through hybrid approaches [9], [106]. The success of multimodal emotion analysis systems lies in the careful choice of data and fusion strategy [73], which often outperform single-modal recognition systems [107]."}, {"title": "3.2 Modeling Emotional Generation Processes", "content": "In the domain of modeling emotional generation, appraisal theories have become dominant. Many computational models based on appraisal theories have been widely applied in human-computer interaction systems, particularly for generating emotional expressions in real-time interactive characters (e.g., [108], [109]). The central assumption of appraisal theories is that individuals continuously monitor and evaluate changes in the environment that are relevant to their concerns, with emotions arising from these evaluations [110], [111]. Lazarus [52] introduced the concept of the \u201cperson-environment relationship\" to describe the adaptive processes between agents and their environments. This relationship allows agents to derive the significance of external events relative to their beliefs, desires, and intentions, thereby generating or inferring emotional responses. Some computational models do not explicitly represent these relationships but still support the derivation of event meanings to produce emotional reactions. For instance, the EMA model (named in honor of Richard Lazarus's book Emotion and Adaptation) [112] constructs causal explanations of the current situation, incorporating beliefs, desires, and intentions. These causal explanations generate appraisal frames for significant events, which in turn yield emotional responses based on the outcomes of these appraisals. Other approaches have employed Bayesian inference [113], [114], [115] or Partially Observable Markov Decision Processes (POMDP) [116] to model this derivation process. More recently, the Belief-Desire- Intention (BDI) software architecture, which simulates human cognitive processes [117], has been increasingly used to design affective agents (e.g., [118], [119], [120], [121]). These BDI- based agents can not only model the process of emotion elicitation (i.e., how emotions are triggered based on the agent's beliefs, desires, and intentions) but also simulate the impact of emotions on cognitive processes and action choices [122].\n\nThe cognitive appraisal theory proposed by Ortony, Clore, and Collins (OCC), [123] further refines the triggers for emotional generation by distinguishing between events, actions by others, and objects as different types of stimuli. Based on these triggers, the theory provides a new classification scheme for emotions and establishes structural relationships between specific appraisal variables and emotional labels. For example, it specifies how combinations of appraisal variables can elicit emotions such as shame [124]. Due to its structured nature, the OCC model is considered a \u201ccomputationally friendly\" framework for modeling emotion generation [61]. Dias et al., [125] built the Fearnot AffecTIve Mind Architecture (FAtiMA) based on the OCC model, which integrates planning capabilities into affective agents. A key component of this architecture, OCCAffectDerivation, generates emotions based on appraisal variables derived from the OCC model, such as desirability, desirability-for-others, and praiseworthiness. For example, if an event has a positive desirability value exceeding the pre-defined threshold for joy, the model generates the emotion of joy. Conversely, events with negative desirability may result in distress. Other computational models also employ the appraisal variables proposed in the OCC theory, including AR [126], EM [108], FLAME [127], ALMA [128] and GAMYGDALA [109]. However, as Hudlicka [61] noted, the highly structured nature of the OCC model is a double-edged sword. On the one hand, its detailed specifications provide a clear and systematic guideline for computational representation of emotions. On the other hand, the fine-grained descriptions of specific structures may not always be necessary, as certain models might not need to differentiate between events, actions by others, or objects to derive emotions.\n\nIn addition to the OCC theory, other cognitive appraisal theorists have proposed their own sets of appraisal variables that intelligent agents can use to generate distinct emotional responses, e.g., Frijda [129], Roseman [130], Scherer [131], C. A. Smith and Ellsworth [132]. These variables include novelty, intrinsic valence, certainty, goal conduciveness, agency, control, and compatibility with personal or social standards [133]. While these variables are less structurally detailed compared to the OCC model, they provide a unified framework for emotion computation, where specific emotions can be represented as vectors of appraisal variables. Scherer's proposed variables [58], [110], [131] have been adopted in computational models such as WASABI [134] and PEACTIDM [135]. These theories clarify the mapping between appraisal variables and emotional states, modeling the appraisal process as the cause of emotion generation. Once the pattern of appraisal variables is determined, corresponding emotional states can be derived through simple if- then rules, often represented by discrete emotion labels [136], [137].\n\nEarly computational appraisal models often employed symbolic rule-based systems to map appraisal variables to specific emotional states (e.g., [108], [127], [128], [134], [135]). However, with the rapid development of deep learning and neural network technologies [63], [138], connectionist approaches have gained momentum. Researchers now use neural networks composed of numerous simple processing units to simulate the appraisal process [139], [140], [141]. Deep learning-based affective computing has become a dominant trend, as the strong fitting capabilities of deep neural networks allow them to model complex relationships between data without relying on explicitly programmed rules. Ong et al., [140] applied the paradigm of deep probabilistic programming to affective computing, combining data-driven (deep learning) and theory-driven (probabilistic programming) approaches to model uncertainties in the emotional generation process. Additionally, LLMs have introduced new methods for simulating the appraisal process, as they can generate semantically meaningful outputs based on extensive text datasets that may implicitly represent certain human psychological processes [142], [143]. In practice, Wei et al., [144] demonstrated that the performance of LLMs depends not only on the model itself but also on the quality of prompts. They proposed the \u201cChain-of-Thought\u201d prompting concept, which uses step-by-step reasoning examples to guide LLMs, significantly enhancing their reasoning capabilities. Croissant et al. [145] applied this paradigm to simulate the emotional appraisal process. By integrating contextual information and role-playing elements into a memory system, their approach allowed LLMs to evaluate situations and generate or infer emotions based on appraisal prompts. However, while LLMs trained with deep learning can provide contextually appropriate responses based on semantic understanding [142], [146], [147], they do not simulate the genuine emotional generation process. Instead, they produce statistically plausible responses based on input data. Consequently, the performance of these deep learning-based appraisal models remains limited by the quality of training data and the inherent statistical properties of the models [148]."}, {"title": "3.3 Limitations of Current Affective Computing Models and Future Directions", "content": "Both single-modal and multimodal emotion recognition approaches share a common foundational assumption: internal emotional states manifest in observable external and physiological signals. These measurable signals are then mapped back to corresponding emotional states using discrete or dimensional models. Discrete models classify emotions into a finite set of categories. Among them, Ekman's basic emotion theory and its variants have been widely applied in emotion recognition research. Ekman proposed that certain emotions (e.g., anger, disgust, fear, happiness, sadness, and surprise) are universally present across cultures and assumed that each basic emotion corresponds to distinct response components (e.g., facial expressions and physiological reactions) that tend to co-occur during emotional episodes [50].\n\nHowever, empirical studies have shown that even when researchers use the same emotional labels, the described emotional states often differ [149], [150]. Additionally, current neuroimaging techniques have not provided evidence supporting the existence of distinct \"neural fingerprints\" for each basic emotion [151]. While Ekman acknowledged the existence of variants within each basic emotion family and the blending of emotions at specific moments, he also maintained that the boundaries between basic emotion categories should remain distinct. Neuroscientific research increasingly highlights that complex psychological phenomena, including emotions, are mediated by distributed neural activation networks [152]. This suggests that, from a neurophysiological perspective, clear boundaries between different categories of basic emotions may not exist [60]. In fact, contemporary psychology research places greater emphasis on the functional labels of basic emotions. Many studies suggest functionally distinguishing basic emotions; for instance, \"disgust\" can be further categorized into emotional responses to contamination versus destruction, reflecting different adaptive problems [149], [153], In animal studies, researchers have linked emotional elicitation contexts, neural circuits, and observable behaviors, documenting responses resembling basic emotions. However, researchers often avoid colloquial emotional labels such as \"joy\" or \"fear\" and prefer motivational behavioral labels like \"wanting\" or \"defense\" to describe these reactions [44], [154], [155].\n\nThe computational models in emotion recognition have yet to incorporate the functional characteristics of emotions fully. Even models based on dimensional theories have similar limitations (e.g., [156], [157]). While these techniques are valuable for applications such as public opinion monitoring, sentiment analysis, and health management, they often fall short of achieving the ultimate goal of creating affective agents capable of truly understanding user emotions and providing appropriate responses. Key questions remain unanswered: What constitutes a \"correct response\" in affective interaction systems? What defines a \"natural and smooth\u201d interaction? Answering these questions requires a teleological perspective to understand the entire process of emotion generation and its functional significance. Currently, emotional response systems typically follow a default approach: reading human emotional cues, categorizing emotions, and responding based on predefined patterns. In these designs, the complexity and diversity of emotions are often reduced to fixed categories and preset reaction patterns. While convenient to implement, these designs overlook the deeper purposiveness and dynamism of emotions, making them less adaptable and realistic in long-term interactions. For instance, Terzis et al. [158] designed an emotion feedback system employing parallel and reactive empathy to manage learners' six emotional states (happiness, anger, sadness, surprise, fear, and disgust). When a learner displayed fear, the system first mirrored the emotion through parallel empathy, using fearful facial expressions and vocal tones, and then shifted to joyful expressions and tones (reactive empathy) to alleviate the learner's fear and encourage continued efforts. While practical, this approach has inherent flaws. Firstly, the psychological validity of such categorical classifications remains debated. Secondly, the lack of understanding of the teleological principles behind emotions limits the system's ability to influence and alter users' emotional states effectively. In psychology, empathy involves perceiving the inner subjective world of another person, understanding their sources of distress or sorrow, and conveying meaningful responses. Emotional generation is thus a constructive process, deeply individualistic [27]. Predefined uniform responses cannot adequately simulate genuine emotional responses.\n\nPrimarily focuses on individual-level dynamics, appraisal theory enables agents to generate or understand emotions based on their evaluations of psychological events concerning their own or others' concerns. It addresses key questions: How are specific emotions mapped from stimulus events? Are these mappings direct, or do they involve intermediate appraisal processes (e.g., novelty, desirability, or agency)? How do internal stimuli (e.g., memories or anticipated events) interact with external stimuli (reflecting contextual features) to jointly influence emotion generation? Answering these questions allows continuous comparison between environmental changes and individual affective concerns, providing opportunities to operationalize teleological principles in emotional machines. Accordingly, some computational appraisal models enable developers to set specific affective concerns for affective agents [109]. These concerns allow agents to perform personalized actions based on their internal goals. However, such hand-designed affective agents can enhance user experiences only in narrowly defined scenarios, such as gaming, and often fail to respond to the affective concerns of individuals during complex interactions.\n\nMoreover, models trained on large datasets and deep learning techniques can offer statistically optimal solutions at the group level. However, just as group-level relationships cannot fully"}, {"title": "4. TELEOLOGY-DRIVEN AFFECTIVE COMPUTING", "content": "In Section 3, we reviewed the major research directions and significant achievements in the field of affective computing, along with a detailed analysis of the theoretical foundations behind these advancements. We identified that these studies lack explicit standards and principles for affective interaction at the theoretical level. Hence, in this section, we first propose design principles for interactive affective agents based on teleological perspectives aligning with personal/individual and even group/collective well-being over extended time scales. Subsequently, we discuss the database and algorithmic models required to align with these principles. The integration of these database and models can help capture the complexity of affective dynamics, revealing the multidimensional characteristics of emotions and their causal relationships. Ultimately, this framework aims to construct a comprehensive teleological affective computing paradigm, transitioning from theoretical principles to corresponding data and algorithms."}, {"title": "4.1 Principles of Affective Interaction Guided by Teleology", "content": "As highlighted in Section 2, the predominant emotion theories converge in advocating teleological principles from different perspectives. Schiller et al. [24] describe this principle as a comprehensive synthesis of existing emotional theories. They characterize emotions as phenomena where actions are performed based on an individual's comfort zone (addressing affective concerns) while monitoring the adaptation process (displaying affective features). For participants in affective interactions, understanding each other's affective concerns is even more critical than identifying immediate affective states. Affective concerns represent the causes, explanations, and relationships between individuals and physical or psychological objects in their environment. Interaction participants can only influence or modulate the other's emotional experience effectively by understanding the objects that underpin their affective concerns. These concerns are structured hierarchically, starting from an individual as the reference point, organized from proximal and specific to distal and abstract levels [24]. However, the hierarchical nature of affective concerns still fails to explain trade-offs among different concerns over extended time scales, raising questions about how individuals define their overall optimal state.\n\nTo address this, Schiller et al. [24] propose a global concern algorithm to summarize hierarchically structured concerns at broader temporal scales. Global concerns transcend specific objects, encompassing all object-specific concerns - frequently referred to in affect research as personal well-being [52], [56], [110], [129], [163], [164]. This construct represents the synthesis and prioritization of hierarchically structured concerns, guiding individuals in choosing among multiple competing concerns.\n\nNotably, fulfilling hierarchical concerns does not always contribute to global concerns. For instance, gambling can provide excitement (a heightened physiological pleasure) for some players, sustaining long-term participation. However, as with all addictive behaviors, such prolonged engagement sacrifices other hierarchical concerns. Gamblers might spend excessive money, neglect relationships, or abandon academic and career goals. Even if gambling yields temporary positive experiences, this state is unlikely to be termed \"well-being.\" Becker and Bernecker [165] explored the relationship between immediate pleasures and long-term goals in self-control research, noting that pursuing hedonistic activities often incurs opportunity costs, limiting enjoyment.\n\nThe conflict between global concerns and hierarchical concerns embodies tensions between the whole and its parts, long-term versus short-term, and differing levels of positivity. S. Yu [166] suggested that higher-level well-being is not merely the sum of positive states. Temporary negative emotions can create conditions for overall positivity. Particularly when pursuing higher-level affective concerns, individuals often endure complex actions and environmental interactions. During these processes, setbacks might evoke short-term negative emotions that lay the groundwork for subsequent positive feedback. For example, researchers experiencing academic setbacks may feel frustration and disappointment, yet these emotions can prompt critical reflection, improving strategies and leading to valuable insights. Negative emotions, under specific circumstances, do not impede long-term development but foster higher-level efforts and overall positive transformations [166]. Our ultimate pursuit is not moment-to-moment positive experiences but optimal affective states across extended time scales. Trajectories aligned with global concerns lead to positive mood, while deviations foster negativity. When all energy aligns efficiently with global concerns, the organism achieves optimal adaptation to its environment, experiencing a state of effortless control and order, referred to as \"flow\" [167], [168].\n\nThe complex dynamics of positive and negative transitions in affective phenomena motivate a dynamic perspective defined by the multilayered interconnectedness of human experiences [166], [169]. Active inference provides a valuable framework for interpreting these dynamic processes. Its foundational principle involves comparing the brain's internal models with the external environment to generate predictions, which are then iteratively adjusted based on actual feedback. This dynamic feedback regulation enables individuals to minimize cognitive errors and optimize responses to environmental stimuli by updating beliefs and behaviors [170], [171]. Under the active inference perspective, the valence component of emotion is modeled as the rate of error dynamics. Slower-than-expected error reduction signifies negative valence, while faster-than-expected error reduction indicates positive valence [172], [173], [174], [175]. Expanding this concept, Miller et al., [175] distinguished between local and global error dynamics to explain the difference between transient and enduring happiness. Local dynamics involve adjustments to specific action strategies, reflecting task- specific performance in reducing predictive errors. Global dynamics concern an individual's overall predictive performance across multiple life domains, reflecting how uncertainties are managed over a lifetime. To maintain mental well-being, individuals must balance local and global error dynamics, optimizing resource allocation between maintaining current strategies and seeking new ones. While reducing predictive errors within specific domains is crucial, individuals must also address multiple affective concerns across their lives, reallocating resources to sustain growth and adaptability. Through this balancing act, individuals adapt to environmental challenges while introducing temporary uncertainties to foster growth and skill acquisition.\n\nBased on the multilayered analysis of affective phenomena, we can define three hierarchical principles for interactive responses between affective agents and humans: 1) Aligning with individual hierarchical concerns. The affective agent can calculate the relevance of a particular stimuli to the individual and help the individual reduce prediction errors in specific tasks; 2) Aligning with personal/individual well-being. The affective agent is capable of calculating the relevance of multiple objects to the individual, and also flexibly modeling the process by which the individual updates the weights of different hierarchical concerns over a longer time scale, based on contextual changes; 3) Aligning with group/collective well- being. The affective agent can simultaneously consider the well-being of all directly or indirectly interacting individuals and seek ways to maximize group/collective well-being. Ideally, the affective agent should be human-centered, providing highly personalized responses. This not only requires the agent to understand the hierarchical concerns of the interacting individuals, but also to guide the individual toward broader global concerns through responses, interactions, and engagement. It can not only recognize an individual's current needs and emotions but also promote the enhancement of both individual and even group/collective well-being over a longer time scale."}, {"title": "4.2 Develop a \u201cDataverse\u201d of Personal Affective Events", "content": "Breakthroughs in deep learning owe much to the availability of large-scale datasets [176", "177": ".", "178": [179], "180": "."}]}