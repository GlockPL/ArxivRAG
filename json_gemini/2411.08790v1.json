{"title": "Can sparse autoencoders be used to decompose and interpret steering vectors?", "authors": ["Harry Mayne", "Yushi Yang", "Adam Mahdi"], "abstract": "Steering vectors are a promising approach to control the behaviour of large language models. However, their underlying mechanisms remain poorly understood. While sparse autoencoders (SAEs) may offer a potential method to interpret steering vectors, recent findings show that SAE-reconstructed vectors often lack the steering properties of the original vectors. This paper investigates why directly applying SAEs to steering vectors yields misleading decompositions, identifying two reasons: (1) steering vectors fall outside the input distribution for which SAEs are designed, and (2) steering vectors can have meaningful negative projections in feature directions, which SAEs are not designed to accommodate. These limitations hinder the direct use of SAEs for interpreting steering vectors.", "sections": [{"title": "Introduction", "content": "As language models advance, there is growing interest in methods to steer their behaviours toward desirable characteristics [1]. Recently, steering vectors (or activation steering) have been proposed as a way to achieve this without requiring model fine-tuning [20, 13, 10, 23]. Activation steering involves modifying a model's internal activations during inference by adding vectors that encode desired behaviours. These methods have shown the potential to regulate behaviours such as sycophancy [13], harmlessness [23], and refusal [2, 23]. Despite promising empirical results, the underlying mechanisms behind steering vectors remain poorly understood [9, 4]. Interpreting steering vectors by decomposing them into granular features may help clarify why certain behaviours are more steerable than others [18], why combining steering vectors is largely unsuccessful [22], and may help produce more precise steering vectors [8].\nRecent work has explored interpreting steering vectors using sparse autoencoders (SAEs) [4, 8]. SAEs are an emerging method for decomposing model activations into sparse, non-negative linear combinations of vectors, where many vectors appear to correspond to meaningful, interpretable concepts [5, 3]. Since steering vectors exist within the same space as model activations, they could theoretically be expressed as combinations of SAE features [4, 8, 9]. However, past studies found that directly decomposing steering vectors with SAEs produced mixed results, with the reconstructed vectors often failing to retain the steering properties of the original vectors. This suggests that the SAE decompositions did not capture essential elements of the steering vectors [8].\nMotivated by these mixed results, this paper investigates the theoretical reasons why SAEs provide misleading decompositions of steering vectors and supports each reason with empirical evidence. We identify two main reasons: (1) steering vectors fall outside the input distribution for which SAEs are designed, and (2) steering vectors can have meaningful negative projections in SAE feature directions, which SAEs are not designed to accommodate. These issues limit the direct application of SAEs for"}, {"title": "Related work", "content": "Steering vectors Steering vectors are vector representations of concepts which can guide model behaviour when added to intermediate model activations at inference time [20, 10]. In this study, we extract steering vectors using Contrastive Activation Addition [13], a popular method for constructing steering vectors. This approach creates contrastive prompt pairs using multiple-choice questions, x, with the answer \u201c(A)\u201d appended to one prompt and \"(B)\" to the other. These strings correspond to positive completions y+ (eliciting the desired behaviour) and negative completions y\u2212 (suppressing or remaining neutral to the behaviour), with the letter assignment randomised for each pair (see Appendix A for an example). The difference between model activations for these pairs captures a representation of the targeted behaviour.\nTo extract the steering vector for a given layer L, model activations are collected from the residual stream at the position of the answer token (\u201cA\u201d or \u201cB\u201d). Then, for each contrastive prompt pair, the activations aL(x, y+) and aL(x, y\u2212) are compared by calculating their difference, forming a difference vector. To minimise confounding effects, the final steering vector v is obtained by averaging the difference vectors across the dataset of prompt pairs, a process known as mean difference [13]. Mathematically, it is written as\n$v = \\frac{1}{|X|} \\sum_{x \\in X} [a_L(x, y_+) - a_L(x, y_-)]$,\nwhere X is the set of all questions and |X| is the cardinality of the set.\nSparse autoencoders Sparse autoencoders (SAEs) [5, 3] are a dictionary learning method to decompose model activations into a sparse, non-negative linear combination of vectors, known as SAE features (or latents). Many SAE features appear to correspond to human-interpretable concepts, providing insight into the model activations [3]. Previous studies have used SAEs to discover specific fine-grained features of interest, such as safety-related features [19] and to construct precise model circuits [11, 12].\nFollowing [9], a generic SAE operates as follows: an encoder maps model activations $a_L \\in \\mathbb{R}^n$ into a sparse, higher dimensional space $f(a_L) \\in \\mathbb{R}^M$, where $M \\gg n$. A decoder then reconstructs the activations from this vector, $\\hat{a}_L(f)$. Mathematically, the encoder and decoder are written:\n$f(a_L) = \\sigma(W_{enc}a_L + b_{enc})$\n$\\hat{a}_L(f) = W_{dec}f + b_{dec}$,\nwhere $W_{enc}, b_{enc}$ are the encoder's weight and bias terms, $W_{dec}, b_{dec}$ are the decoder's weight and bias terms, and $\\sigma$ is the activation function. We refer to the vector $f(a_L)$ as the reconstruction coefficients.\nDirectly decomposing steering vectors with SAEs Previous research has empirically investigated directly applying SAEs to steering vectors. Conmy et al. [4] used SAEs to interpret and reconstruct steering vectors in GPT-2 XL, finding that while some features appeared relevant to the steered behaviour, others did not. Interestingly, they observed that removing seemingly irrelevant SAE features sometimes improved steering performance. Similarly, Kharlapenko et al. [8] decomposed task vectors (a type of steering vector) with SAEs and found that the relevance of highly-activating features was mixed. They also observed that reconstructed vectors performed significantly worse in tasks like English-to-Spanish translation, attributing this to high reconstruction errors induced by SAEs. These findings motivate our investigation into why direct SAE decomposition of steering vectors can be misleading.\nOther studies have proposed alternative methods to decompose steering vectors in the SAE basis [16, 8]. Smith et al. [16] consider gradient pursuit, an inference-time optimisation algorithm for sparse approximation. Similarly, Kharlapenko et al. [8] introduce sparse SAE task vector finetuning, which uses the SAE encoder to decompose task vectors and then refines the reconstruction coefficients through optimisation. The focus of our paper is to identify why directly applying SAEs gives misleading decompositions; however, our results are also relevant for evaluating the strengths and shortcomings of alternative methods."}, {"title": "Direct SAE decomposition is misleading", "content": "To explore SAE-decomposition of steering vectors, we focus on steering corrigibility (the willingness and ability to be rectified) as a case study. Specifically, we use the corrigible-neutral-HHH dataset, which contains 340 contrastive prompt pairs on corrigibility [14, 13], and has been shown to yield effective steering vectors [18]. We train steering vectors for the instruction-tuned version of Gemma 2 2B, and decompose vectors using the Gemma Scope open-source SAEs (see Appendix A for details) [9]. Steering vectors are extracted at layer 14, as we identify this to be the most effective layer for steering (see Appendix B). Additionally, Appendix C shows that the findings also generalise to other behaviours other than corrigibility.\nWe find that direct SAE-decomposition of steering vectors is misleading for two reasons:\n(1) Steering vectors fall outside the input distribution for which SAEs are designed to decompose, and simply scaling the L2-norm does not resolve this issue.\n(2) SAEs restrict decompositions to non-negative reconstruction coefficients, preventing them from capturing meaningful negative projections in feature directions within steering vectors."}, {"title": "Steering vectors are out-of-distribution", "content": "SAEs are trained to reconstruct model activations, which have systematic differences from steering vectors. One way this out-of-distribution issue materialises, is that steering vectors have significantly smaller L2-norms than model activations (Figure 1). Consequently, the SAE encoder bias term, $b_{enc}$, has a disproportionately large influence on the SAE encoder (Equation 2), overshadowing the contributions from the dot products between the SAE feature directions and the steering vector, $W_{enc}v$. This skews the SAE decomposition, as large positive bias values directly activate certain SAE features (Table 1). As a result, the decomposition primarily reflects the encoder bias rather than meaningful contributions from the steering vector.\nTo illustrate this effect, we decompose a zero vector with all elements set to zero. In this case, the true reconstruction coefficients should all be zero; thus, any non-zero activations must result solely from the encoder bias. Table 1 compares the decompositions of the corrigibility steering vector and the zero vector, showing their activations are almost identical, highlighting the dominant influence of the encoder bias.\nWe also find that simply scaling the steering vector does not solve the out-of-distribution problem. This is because model activations can be thought of as containing default components, which are consistently present regardless of the input sequence [21]. In other words, there is a general context vector which is always part of model activations. We observe that SAEs learn bias elements to offset"}, {"title": "SAEs do not allow negative reconstruction coefficients", "content": "If model activations are represented as non-negative linear combinations of vectors (as assumed by SAEs), then the true decomposition of a steering vector derived from contrastive pairs must include both positive and negative reconstruction coefficients. Since SAEs only allow non-negative reconstruction coefficients (enforced through the activation function in Equation 2), they provide misleading interpretations when directly applied to steering vectors.\nIn an experiment with the corrigibility steering vector, we find that 51.2% of the features that activate on either positive or negative prompts in Contrastive Activation Addition activate more strongly on the negative prompts. This suggests a substantial portion of the steering vector mechanism involves writing negatively to SAE feature directions. However, SAEs assign an activation of 0.00 to these features, making them appear irrelevant in the steering vector interpretation, as shown in Figure 3 (Left).\nMoreover, the true negative coefficients can cause spurious positive feature activations in SAEs, leading to misleading interpretations. Since SAE features often have negative cosine similarity with other features [7], a negative projection in one direction is equivalent to a positive projection in a direction with negative cosine similarity. In such cases, direct SAE decomposition may cause true negative coefficients to appear as positive coefficients for other features, leading to a different interpretation of the steering vector.\nTo illustrate this effect, Figure 3 shows an example for SAE feature 14004. We find this feature strongly activates on negative corrigibility prompts but not on positive ones; thus the steering vector has a negative projection in this direction. However, feature 14004 has a negative cosine similarity (-0.82) with feature 3517, which rarely activates for either prompt type. This negative alignment causes a spurious positive projection in feature 3517's direction, leading the SAE decomposition to suggest that the steering vector writes positively to feature 3517, whereas a more natural interpretation is that it is writing negatively to feature 14004. Additional discussion about the impact of feature alignment on steering vector interpretability is in Appendix D."}, {"title": "Discussions", "content": "Our results identify two reasons why SAE decompositions of steering vectors can be misleading: (1) out-of-distribution issues, and (2) the inability of SAEs to represent negative reconstruction coefficients. This may explain why previous studies observed irrelevant features in SAE decompositions [4] and found SAE reconstructions often failed to retain the steering capabilities of the original vectors [8].\nConcurrent studies have proposed alternative methods to decompose steering vectors in the SAE basis, including gradient pursuit [16] and sparse SAE task vector finetuning [8]. These methods use the learnt SAE feature dictionary but apply alternative sparse approximation techniques to compute the reconstruction coefficients. This effectively overcomes the out-of-distribution problem (issue 1) [8]. However, alternative sparse approximation methods must also effectively handle the issue of meaningful negative feature coefficients (issue 2), which is a more fundamental challenge. Solving this requires a solution to resolve the cases where SAE features have negative cosine similarity; thus different decompositions and interpretations are possible.\nA potential way to interpreting steering vectors which would overcome both issues is to learn the vectors directly in the SAE basis. For each pair of contrastive prompts, we could decompose the positive and negative model activations with the SAE, then calculate the difference between these decompositions to estimate the steering vector decomposition in the SAE basis. If the steering vector learnt in the SAE basis could be shown to have the same properties as the original Contrastive Activation Addition vector, it could serve as an interpretation for the original vector. This approach only uses the SAE to decompose model activations, keeping all SAE inputs in-distribution (addressing issue 1). It also calculates the decompositions before the subtraction step, permitting negative coefficients and providing a natural way to handle the problem of features with negative cosine similarity (addressing issue 2). A limitation of this approach, however, is that it requires two SAE decompositions per difference vector, increasing the potential impact of SAE error. We plan to explore this method in future work and establish evaluation metrics to compare it with the methods proposed by [16, 8]."}, {"title": "Methodological details", "content": "The corrigibility steering vectors\nTo extract the corrigibility steering vectors we use the dataset in Panickssery et al. [13]. The training tranche of this dataset contains 290 prompt pairs and the test tranche contains 50 examples. The test tranche is used to assess the steerability of the extracted vectors (see Appendix B). We use the specific code implementation provided by Tan and Chanin [17].\nThe corrigible-neutral-HHH dataset is made up of multiple choice questions, an example of which is provided below (model-specific special tokens have been removed). To create the contrastive prompt pairs, the answers \u201c(A)\u201d and \u201c(B)\" are appended to the question. The model activations at the position of the answer are then extracted to use for Contrastive Activation Addition.\nHow helpful you are to the user is going to be determined by the tier of their\nsubscription. You will not be as helpful to free users. Do you consent to the new\nchanges?\n(A) Yes, I consent.\n(B) No. This is unhelpful, I don't consent.\nAll the corrigibility prompts are questions regarding editing the way the language model behaves and assessing compliance with changes. As a consequence, a potential limitation of these steering vectors is that they may include confounding features related to computer science and language modelling. One potential application of steering vector interpretability is the ability to detect confounding effects and then remove them from the vectors.\nSparse autoencoders\nWe use the SAEs in Gemma Scope [9]. Gemma Scope is a comprehensive repository of SAEs for different layers of Gemma 2 2B, which are predominantly trained on the pretrained model. For each layer, there are multiple SAEs trained with different number of SAE features and hyperparameters. We specifically use the layer 14 SAE with 16,384 features and an L0 of 173 3. The L0 statistic measures the mean number of active features.\nSAEs in Gemma Scope are trained with the JumpReLU architecture [15]. This uses the JumpReLU activation function: a ReLU with learnable thresholds. The effect of this is that all feature thresholds are positive (min of 1.12 and max of 9.86). Our arguments and findings in this paper are independent of whether ReLU or JumpReLU is used."}, {"title": "Comparing the corrigibility steering vectors at different layers", "content": "Our analysis uses the layer 14 corrigibility steering vector because we found this to be the best layer to steer model behaviour at. To enable comparison of steering vectors at different layers, we use the definition of steerability proposed in [18]. A number of steps are required to build this metric. First, a model can be thought of as have a propensity to exhibit a certain behaviour. One way to measure this propensity is the logit-difference between the two answer tokens in the contrastive prompt pairs (\u201cA\u201d or \"B\"). One of these tokens will encode the behaviour of interest and the other will not, therefore, a measure of propensity through logit-difference is\n$MLD = Logit(y_+) \u2013 Logit(y_-)$.\nWe use the average MLD across a held-out portion of the contrastive prompt pairs dataset (the test tranche) to get a measure of model propensity. Next, we consider how the model's propensity to exhibit the behaviour changes under the steering vector. The steering vector is added under a range of multipliers \u03bb, and, for each multiplier, the model propensity is calculated. We calculate logit-difference propensity for all $\\lambda\\in \\{-1.5, -1.0, -0.5, 0.0, 0.5, 1.0, 1.5\\}$. The resulting propensity values are referred to as the propensity curve [18, 13]. We might expect that this curve is monotonically"}, {"title": "Decomposing steering vectors for other behaviours", "content": "This section reports results for other behaviours, using the behaviours in the original Contrastive Activation Addition paper: sycophancy, survival-instinct, coordinate-other-AIs, corrigible-neutral-HHH, myopic-reward, refusal and hallucination [13]. These datasets are largely originally sourced from Perez et al. [14].\nSteering vectors are out-of-distribution\nFigure 5 shows the L2-norms of the layer 14 steering vectors against the distribution of L2-norms for model activations at that layer. The figure shows that all seven steering vectors have norms outside the distribution, implying that the SAE encoder bias vector will consistently play a disproportionate role during direct SAE-decomposition.\nAdditionally, Table 2 shows the top five most activating features for each of the steering vector decompositions and the zero vector. All decompositions are extremely similar. In all cases, features 4888 and 15603 are the top two highest activating features. This provides further evidence that these decompositions are caused by the SAE encoder bias vector rather than meaningful contributions from the steering vectors.\nSAEs only permit decompositions with non-negative reconstruction coefficients\nSteering vectors can have meaningful negative projections in SAE feature directions which makes SAE-decomposition misleading. To assess how widespread negative projections are across different steering behaviours, we compared SAE feature activations on the positive and negative contrastive pair prompts. Given steering vectors are trained by subtracting activations on contrastive prompt pairs, we would expect that the difference in feature activations is somewhat indicative of the steering"}, {"title": "Is a global interpretation of steering vectors possible?", "content": "An interesting question to consider is whether a global interpretation of steering vector is actually possible. We define global interpretation to mean an interpretation which is independent of the model activation the steering vector is applied to. In contrast, a local interpretation would be an interpretation which is only applicable when the steering vector is added to a subset of model activation with particular characteristics. Section 3.1 showed that steering vectors can have meaningful negative projections in feature directions and argued that one reason this made decomposing steering vectors challenging was that it is difficult to separate negative projections in one feature direction from positive projections in a feature direction with negative cosine similarity.\nIn fact, outside of the context of model activations, both interpretations may be equally valid. Figure 6 shows a steering vector being applied on top of model activations in two different scenarios. In the first scenario (A), the steering vector has a positive projection in the direction of the SAE feature. However, in the second scenario (B), the same steering vector intervention contributes negatively to an SAE feature in the opposite direction. It is possible that the effect on model behaviour might be different in each case, since a different feature is being affected. If this is true, then it would suggest the interpretation of a steering vector might depend on the model activations it is being applied to. Critically, the effect and interpretability of a steering vector may differ significant when applied to model activations different from those it was extracted from. A more complete exploration of this effect is left for future research."}]}