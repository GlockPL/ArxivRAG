{"title": "An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for Digit Classification", "authors": ["Eugene Choi", "Julian Rodriguez", "Edmund Young"], "abstract": "Domain adaptation is an active area of research driven by the growing demand for robust machine learning models that perform well on real-world data. Adversarial learning for deep neural networks (DNNs) has emerged as a promising approach to improving generalization ability, particularly for image classification. In this paper, we implement a specific adversarial learning technique known as Adversarial Discriminative Domain Adaptation (ADDA) and replicate digit classification experiments from the original ADDA paper. We extend their findings by examining a broader range of domain shifts and provide a detailed analysis of in-domain classification accuracy post-ADDA. Our results demonstrate that ADDA significantly improves accuracy across certain domain shifts with minimal impact on in-domain performance. Furthermore, we provide qualitative analysis and propose potential explanations for ADDA's limitations in less successful domain shifts. Code is here.", "sections": [{"title": "1. Introduction", "content": "Machine learning models often struggle to generalize to new, unseen data due to differences in data distributions-a challenge known as domain shift. In domain shift, a model trained on the source domain fails to perform well when applied to the target domain. This issue is pervasive in real-world machine learning applications, making it essential to develop robust models that can effectively adapt across domains for successful deployment.\nTo address domain shift, many domain adaptation methods focus on minimizing the discrepancy between the source and target domains [1, 2]. Adversarial adaptation methods accomplish this by training a model with an adversarial objective so that a discriminator is unable to distinguish data from the source and target domains. Tzeng et al. propose an unsupervised adversarial adaptation method called Adversarial Discriminative Domain Adaptation (ADDA) [3]. \u201cADDA first learns a discriminative representation using the labels in the source domain and then a separate encoding that maps the target data to the same space using an asymmetric mapping learned through a domain-adversarial loss\u201d [3].\n[3] evaluates ADDA's performance on digit classification for domain shifts across the MNIST [4], USPS [5], and SVHN [6] datasets. However, they only report out-of-domain accuracies for three of the possible six domain shift combinations with limited analysis of model interpretability. To bridge this gap, we implement ADDA from scratch and replicate their digit classification experiment on all six domain shifts. Furthermore, we provide post-ADDA in-domain accuracy results along with qualitative analysis using confusion matrices and t-SNE plots to explore potential shortcomings in classification performance. We finally provide possible hypotheses on several patterns we observe in the model decision-making process."}, {"title": "2. Related Works", "content": "Previous work on transfer learning has been very popular for domain adaptation [7]. Li et al. analyze the effects of stochastic feature augmentation (SFA) [8] on domain adaptation by perturbing feature representations with both data-independent and adaptive Gaussian noise. Ganin et al. propose the domain-adversarial neural network (DANN) [9], which modifies the training loss function by adding a domain adaptation regularization term to maximize prediction accuracy while remaining agnostic to the input data domain. The adversarial autoencoder (AAE) proposed by Makhzani et al. uses generative adversarial networks (GANs) [10] to train an encoder that \"convert[s] the data distribution to the prior distribution\" and a decoder that \"learns a deep generative model that maps the imposed prior to the data distribution\" [11]. Tobin et al. introduce domain randomization [12], which simulates image data in different environments through randomized rendering. The goal of this method is to include enough variability so that real-world images are perceived as just another environment."}, {"title": "3. Adversarial Discriminative Domain Adaptation (ADDA)", "content": "Tzeng et al. generalize several state-of-the-art adversarial domain adaptation techniques including DANNs under a unified framework and propose ADDA [3], which we closely follow in our paper. ADDA is an unsupervised domain adaptation approach that uses a discriminative base model, unshared weights between the source and target mappings, and the standard GAN loss [3] to learn an asymmetric mapping that matches the target to the source domain.\nADDA can be broken down into three steps: pre-training, adversarial adaptation, and testing. In the pre-training step, we first train a source encoder CNN and classifier on the source dataset with labels. Weights of both the source encoder and classifier are then frozen during the rest of the ADDA process. Next, we perform adversarial adaptation, where a target encoder is trained so that a discriminator is unable to tell which domain the input data is from. The purpose of this step is to train the target encoder to map input data to the shared feature space between the two domains. Note that both the discriminator and target encoder will be updated at each iteration during training in order for both components to adapt to each other. The final testing phase involves passing target domain data to the target encoder and original source classifier. The source classifier is only trained on data from the source domain and is agnostic to the target domain. For additional details on ADDA, refer to [3]."}, {"title": "4. Methodology", "content": ""}, {"title": "4.1. ADDA Implementation", "content": "We implement ADDA as outlined in [3] with PyTorch and use the same neural network architectures chosen for digit classification, consisting of a modified LeNet [4, 13] as the source and target encoders, a classifier with width 500, and 3 fully connected layers as the adversarial discriminator (the two hidden layers each have width 500). The discriminator was initially trained with each hidden layer having only 100 nodes to reduce training time, but due to poor performance, the original discriminator architecture was used instead. We implement the same standard GAN loss described in [3] as the adversarial loss."}, {"title": "4.2. Digits Datasets", "content": "We use the three digits datasets used for digit classification in [3] to analyze domain adaptation: MNIST [4], SVHN [6], and USPS [5]. MNIST and USPS contain grayscale images of handwritten digits while SVHN contains real-world Google Street View images. Image samples"}, {"title": "4.3. Training", "content": "We use mini-batch gradient descent with 200 images per batch during training for both the source encoder/classifier and adversarial adaptation. While pre-training the source encoder, we use Adam [14] with a learning rate of $1 \\times 10^{-3}$. During adversarial adaptation training, we use Adam [14] with a learning rate of $1 \\times 10^{-4}$ and alternate training of the discriminator and target encoder every mini-batch iteration. For all six source-target domain shift combinations formed from the three datasets, adversarial adaptation training is done for 150 epochs while source encoder training is done for 80 epochs due to time limitations and limited computing resources. Note that this may affect classification performance as each source-target combination likely requires a different number of training epochs for optimal results. Hereinafter, we will refer to the trained source encoder and source classifier as the base model and the trained target encoder and source classifier as the ADDA model."}, {"title": "5. Results", "content": ""}, {"title": "5.1. Quantitative Analysis", "content": "Tab. 1 provides the preliminary accuracies for each dataset when the base model is evaluated on test data from the source domain. Note that the base models trained on MNIST and USPS achieve significantly higher accuracies compared to SVHN. This is likely due to the fact that SVH\u039d"}, {"title": "5.2. Qualitative Analysis", "content": "We visualize ADDA performance during test time for all combinations of source-target domain shifts except MNIST \u2192 USPS and USPS \u2192 MNIST (since the domains are quite similar) with confusion matrices and t-SNE plots [15]."}, {"title": "5.2.1 Confusion Matrices", "content": "Analyzing Figs. 2 to 5, we find that in several of the confusion matrices, 7 is often misclassified as 1. This is likely due to the similar structure of both digits. We also notice that 0 and 4 are often misclassified as 1. In general, 1 is the most accurately predicted digit; this is probably due to the fact that 1 is often predicted regardless of what the true label is. As a result, the classifier accurately predicts 1's at a higher frequency than other digits. Another possible explanation is that the digit 1 has a relatively simple structure, and thus is easier to recognize.\nAmong the confusion matrices tested on SVHN, SVHN \u2192 USPS is the only domain shift whose classification output is not overrepresented by a certain digit. In the MNIST \u2192 SVHN and SVHN \u2192 MNIST domain shifts (lower panels in Figs. 2 and 3), 1 is the most often predicted digit, while in the USPS \u2192 SVHN domain shift (upper panel in Fig. 5), 2 is the most often predicted digit.\nNote that the USPS \u2192 SVHN domain shift evaluated on SVHN (upper panel in Fig. 5) has consistently low accuracies (less than 0.4) across all digits except for 2, which has an accuracy of 0.63 (this is probably due to 2 being the most frequently predicted digit). This is also the only domain shift that suffers from a deterioration in out-of-domain accuracy after ADDA training (Tab. 2). One possible explanation for the poor performance is the constant number of training epochs enforced across all domain shifts; perhaps this particular domain shift requires more training time to adapt."}, {"title": "5.2.2 t-SNE Plots", "content": "Figs. 6 to 9 display t-SNE plots [15] of input data after they are passed through the target encoder but before the classifier.\nAs expected, we see clearly defined clusters for the MNIST \u2192 SVHN domain shift when evaluated on MNIST (upper panel in Fig. 6) and USPS \u2192 SVHN when evaluated on USPS (lower panel in Fig. 9) since they have high classification accuracies. This indicates that the target encoder is able to learn meaningful representations and effectively differentiate digit features when data from the source domain is passed through. In both of these t-SNE plots, the cluster of 1's is close to the clusters of 4's and 7's, two digits that are often misclassified as 1. 4 and 9 are also close to each other in both plots, as well as 3 and 5.\nThe SVHN \u2192 USPS domain shift evaluated on USPS (Fig. 8 lower panel) shows rough clusters for most digits except for 4 and 9, which are instead scattered across the plot. In accordance with its confusion matrix (Fig. 4 lower panel), classification on the target domain is relatively successful compared to other domain shifts. Very rough clustering is also visible in the SVHN \u2192 MNIST domain shift evaluated on MNIST (Fig. 7 upper panel), with the digits 4, 7, 8, and 9 showing significant scattering. Despite the very rough clustering and scattering, we can see similar trends observed in the t-SNE plots with clear clusters: 3 and 5 are still close to each other, and 1, 4, and 7 have significant overlap.\nThe remainder of the t-SNE plots do not show any distinguishable clustering, indicating that the target encoder is unable to extract identifying features of the different digits. Interestingly, the t-SNE plot of SVHN \u2192 MNIST evaluated"}, {"title": "6. Future Work", "content": "Computing power and time to train the models were the main limiting factors. With additional time and resources, we could have optimized model performance for each domain shift, allowing for more meaningful comparisons. This would have been most pertinent to the domain shifts that included SVHN which likely requires longer training times.\nIn addition, further qualitative analysis such as Grad-CAM [16] would be very insightful in providing visual explanations for poor model performance (particularly domain shifts evaluated on SVHN as the target). These visual explanations would be useful in understanding the current limitations of ADDA and potentially outline improvements to the training process.\nADDA can also be combined with domain randomization [12] to improve generalization across domain shifts. Instead of training the source encoder only on the source domain, one can also train it on simulated randomized data. Another approach is to train the target encoder on simulated data in addition to real data from the target domain.\nWe anticipate that the development of domain adaptation will be crucial for a wide variety of computer vision and robotics tasks. One application is Sim2Real research, which aims to use simulated instead of real-world data to train models due to data scarcity. Overcoming this domain shift could lead to promising results in reinforcement learning."}, {"title": "7. Conclusion", "content": "We have implemented and trained ADDA to successfully demonstrate its potential to improve digit classification accuracy across multiple domain shifts. In five of the six possible source-target combinations between the MNIST, USPS, and SVHN datasets, we find ADDA improves out-of-domain generalization ability, with significant improvements in four domain shifts. We also evaluate the ADDA-trained model in-domain and provide results on performance degradation compared to pre-ADDA in-domain accuracies. We find that there are minimal performance drops for MNIST and USPS, while SVHN suffers large performance drops.\nFurthermore, we provide detailed qualitative analysis through confusion matrices and t-SNE plots. We then provide future possible avenues of research for domain adaptation."}]}