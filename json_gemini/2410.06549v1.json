{"title": "DIFFGAD: A DIFFUSION-BASED UNSUPERVISED\nGRAPH ANOMALY DETECTOR", "authors": ["Jinghan Li", "Jinda Lu", "Junfeng Fang", "Yuan Gao", "Congcong Wen", "Hui Lin", "Xiang Wang"], "abstract": "Graph Anomaly Detection (GAD) is crucial for identifying abnormal entities\nwithin networks, garnering significant attention across various fields. Traditional\nunsupervised methods, which decode encoded latent representations of unlabeled\ndata with a reconstruction focus, often fail to capture critical discriminative content,\nleading to suboptimal anomaly detection. To address these challenges, we present\na Diffusion-based Graph Anomaly Detector (DiffGAD). At the heart of DiffGAD\nis a novel latent space learning paradigm, meticulously designed to enhance the\nmodel's proficiency by guiding it with discriminative content. This innovative\napproach leverages diffusion sampling to infuse the latent space with discriminative\ncontent and introduces a content-preservation mechanism that retains valuable\ninformation across different scales, significantly improving the model's adeptness at\nidentifying anomalies with limited time and space complexity. Our comprehensive\nevaluation of DiffGAD, conducted on six real-world and large-scale datasets with\nvarious metrics, demonstrated its exceptional performance.", "sections": [{"title": "1 INTRODUCTION", "content": "Graph structure has garnered significant attention from both academia and industry, with its potential to\nrepresent relationships and structures. Among its wide applications, graph anomaly detection (GAD)\nhas evolved as a popular research topic, aiming to detect abnormal targets (nodes, edges, subgraphs,\net al.) from the normal.\nExisting research can be categorized into two branches: the semi-supervised learning branch and the unsupervised learning branch. Semi-supervised learning\napproaches utilize a small subset of labeled data to discern patterns of anomalies, enabling the\nprediction of labels for the remaining unlabeled dataset. However, human annotation is often\ntime-consuming and labor-intensive, which limits the application of semi-supervised methods.\nAs alternate, unsupervised reconstruction-based strategies directly capture node characteristics and local structures without the need for\nannotation. Specifically, these approaches are on the assumption that anomalous entities exhibit more"}, {"title": "2 BACKGROUND", "content": "In this section, we revisit some background. Specifically, we first introduce the preliminaries of the\nGraph Anomaly Detection (GAD) task, and then describe the diffusion model in latent space."}, {"title": "2.1 TASK FORMULATION", "content": "In this work, we focus on the unsupervised node-level GAD over static attributed graphs. The goal\nis to learn a detection model, which associates each node with an anomaly score, top-ranked nodes\n(with large scores) are always indicated as anomalies. In reconstruction-based methods, the anomaly\nscore is the reconstruction error. Meanwhile, the data structure can be formalized as an attribute\ngraph G = {V, X, E, A} \u2208 G, where V, X, E, A denotes nodes, node attributes, edges, and adjacency\nmatrix, respectively."}, {"title": "2.2 DIFFUSION MODEL IN LATENT SPACE", "content": "The Latent Diffusion Model (Latent DM) is composed of a pair of forward and reverse diffusion\nprocesses based on the unified formulation of Stochastic Differential Equation (SDE) . Concretely, given a latent variable z, the SDE can be formalized as:\n$dz = f(z,t)dt + g(t)dwt,$\nwhere $f(\u00b7)$ and $g(\u00b7)$ are the drift and diffusion functions, respectively, and $f(\u00b7)$ can also be expressed\nin the form of $f(z,t) = f(t)z$. Then we define the forward, backward, and training process as:\nForward Process. Given the latent variable z, the forward process transforms z with noises to\nconstruct a sequence of step-dependent variables ${zt}_{t=0}^{T}$, where $z_0 = z$ is the initial point of this\nprocess. Specifically, with SDE, the diffusion kernel is denoted as a conditional distribution of $z_t$:\n$p(zt | zo) = N(s(t)zo, s^2(t)\u03c3^2(t)I),$\nwhere s(t) and \u03c3(t) are step-dependent to control the noise level. We follow an efficient design to simplify the diffusion kernel, where we set s(t) = 1 and \u03c3(t) = t\nin this work. Therefore, the forward process can be formulated as:\n$z_t = z_0 + \u03c3(t)\u03b5, where \u03b5 ~ N (0, I) .$"}, {"title": "3 METHODOLOGY", "content": "In this section, we illustrate DiffGAD in detail."}, {"title": "3.1 OVERVIEW", "content": "Figure 2 overviews our proposed DiffGAD, which functions primarily within the latent space. Upon\nreceiving a graph, our methodology initiates by mapping it into the latent space, as detailed in \u00a73.2.\nWithin this transformed domain, we employ a dual Diffusion Model (DM) approach. The first DM is\ntasked with encapsulating the general content, as elaborated in \u00a73.3, while the second DM targets\nthe extraction of common content, described in \u00a73.4. Herein, the discriminative content is identified\nby the disparities between these two DM-captured representations. Inspired by , the concurrent sampling of the two DMs is enabled without necessitating any additional\nparameters. It is worth noting that our model's foundation is rooted in a well-established hypothesis,\nsupported by works such as , which posits\nthat anomalous entities exhibit more complex distributions and are significantly more difficult to\nreconstruct. Consequently, nodes with higher reconstruction error are more likely to be anomalies. To\nfacilitate this detection mechanism, our framework requires the original samples with their respective\nreconstructed counterparts, a process systematically described in \u00a73.3."}, {"title": "3.2 LATENT SPACE PROJECTION", "content": "In this work, we leverage an encoder to map graph features into a latent representation space, a pivotal\nstep that precedes the detailed exposition of diffusion models in our work. Thus, it is essential to first\ndelineate the methodology employed in projecting graph characteristics into this latent space.\nMore formally, for a given graph G, we utilize the Graph Autoencoder (AE) framework as delineated\nin to facilitate its transformation into the latent space. The architecture of the\nGraph AE comprises two primary components: an encoder, denoted as \u03a6, and a decoder, denoted\nas \u03a8. The encoder function, \u03a6, is designed to process the node feature matrix X \u2208 Rn\u00d7d and the\nadjacency matrix A \u2208 Rn\u00d7n, thereby yielding latent feature embedding z, computed as:\n$z = \u03a6(\u03a7, \u0391),$\nwherein \u03a6 incorporates a Graph Convolutional Network (GCN) as its\nunderlying mechanism for aggregating information from node features X into latent embedding z,\nwith z \u2208 Rnxk and k representing the dimensionality of the latent space.\nSubsequently, the decoder component is tasked with the reconstruction of the node feature matrix\nand adjacency matrix from the latent embedding z, expressed through the equations:\n$\\begin{cases}X = \u03a8_{\\text{feat }}(z, A), \\\nA = \u03a8_{\\text{stru}}(zz^T), \\end{cases}$"}, {"content": "in which $\u03a8_{\\text{feat }}$ and $\u03a8_{\\text{stru}}$ are specifically designed for the prediction of node features and graph\nstructure (edges), respectively. This meticulous elaboration of the latent space projection methodology\nset the stage for a comprehensive understanding of our novel DiffGAD framework."}, {"title": "3.3 GENERAL CONTENT PRESERVATION", "content": "Once the latent space is ready, the reconstruction error by DM acts as a proxy of the anomaly score\nassociated with individual nodes. To achieve this, pairs of original and reconstructed samples are\nnecessary. Our general content preservation aims to adapt the DM architecture to\nthe reconstruction error-based anomaly detection task. Unlike traditional DMs, which initiates z\u012b as\nrandom Gaussian noise to generate z0, our approach perturbs original latent embedding z0 minimally\nto get initial points. Concretely, zt at a selected small timestep t < T is obtained with Eq. 3, this\ncorrupted embedding is then used to generate reconstructed sample z0 with the aim of preserving\nthe general content. The benefit of this process are threefolds: (1) It facilitates the computation of\nreconstruction error by aligning original and reconstructed sample; (2) By modulating t, the extent of\npreserved general content can be controlled; a lower t value results in a reconstruction that is closer to\nthe original content, thereby retaining more of the general content. (3) As the DM functions without\nexplicit conditioning, it inherently associates with the general content, which lays the groundwork for\nthe introduction of discriminative content in the following."}, {"title": "3.4 COMMON FEATURE CONSTRUCTION", "content": "In this study, we treat divergence of unconditional and conditional DMs as the discriminative\ncontent of interest. Besides unconditional DM, our approach also necessitates the incorporation of a\nconditional DM. This subsection is dedicated to elucidating the conditioning mechanism construction.\nConsider the latent embedding z = {zv}n=1, where each zv \u2208 Rk denotes the embedding of the\nv-th node. We initialize the common feature c0 as the mean value over all latent node embeddings,\ncapturing a global perspective of the node distribution and setting a prior for their generative process.\nThis feature acts as the conditioning and is not fixed during the training of DM, next we demonstrate\nthe adaptive refinement of this feature in depth.\nDuring the training phase of the unconditional DM, which we represent as $\u03b5_{\u03b8}(z_t, t)$, the conditioning\nundergoes iterative updates. To illustrate, we identify the common feature conditioning at any training\niteration as $c_{current}$. The feature update is governed by:\n$c_{next} = \\sum_{\u03bd\u2208V}\u03c9_\u03bd\u00b7\u03c5,$\nwhere $c_{next}$ is the updated common feature for the next training iteration, and $\u03c9_\u03bd$ is the weighting\nvector to control the update process. We obtain $\u03c9_\u03bd$ by similarity calculation between the reconstructed\nnode embedding $z_\u03bd^0$ and current common feature $c_{current}$, which can be formalized as:\n$\u03c9\u03bd = \\frac{exp(\u1ff6_\u03bd/\u03c4)}{\\sum_\u03bdexp(\u1ff6_\u03bd/\u03c4)}, where \u1ff6_\u03bd = cos (z_\u03bd^0, c_{current}),$\nwhere \u03c4 is the temperature parameter to control the smoothness of weights, cos (\u2022, \u2022) denotes the\ncosine similarity. The update of the common feature involves aggregating the contribution of all\nnodes, weighted by their respective $\u03c9_\u03bd$ values. A larger $\u03c9_\u03bd$ indicates a more significant contribution\nof the current $z_\u03bd$ to the update process. Notably, nodes that significantly deviate from the current\ncommon feature, $c_{current}$, are assigned with lower weights during the update. The underlying rationale\nis to mitigate the impact of potential anomalies and to derive a comprehensive common feature.\nUpon completing this iteration, $c_{next}$ is designated as the new current common feature $c_{current}$ for the\nforthcoming update cycle. Furthermore, we establish the final common feature c which corresponds\nto $c_{next}$ from the last training iteration. This finalized feature remains static during the detection phase.\nThis approach ensures that the common feature is reflective of the dataset's core attributes, which\nleads us to the discriminative content calculation."}, {"title": "3.5 DISCRIMINATIVE CONTENT DISTILLATION", "content": "Leveraging the unconditional DM, $\u03b5_{\u03b8}(z_t,t)$, and the common feature c, our approach is able to\nextract the discriminative content through discriminative content distillation. Specifically, we first\ntrain a conditional DM as $\u03b5_{\u03b8}(z_t, c, t)$, which aims to learn the common knowledge by reconstructing\nlatent embedding z = {zv}n=1 with common feature c as conditional information.\nInspired by the idea of classifier-free guidance , we distill the discriminative\ncontent by performing a linear combination of the unconditional and conditional DMs. Differently,\nour unconditional DM $\u03b5_{\u03b8}(z_t, t)$ contains both discriminative and common content, and the conditional\nDM $\u03b5_{\u03b8}(z_t, c, t)$ captures the common content, which describes that \"what most of the reconstructed\nnodes focus on\". Thus, the discriminative content is achieved by subtracting the general content\nfrom the common content learned from the unconditional DM and conditional DM, respectively.\nSpecifically, the modified score can be denoted as:\n$\u03f5_\u03b8 (zt, c, t) = (1+\u03bb)\u03f5_\u03b8 (zt, t) \u2212 \u03bb\u03b5\u03b8 (zt, c, t),$\n$\u2207zlog pt (z) = \u2212\u03f5_\u03b8 (zt, c, t) /\u03c3(t),$\nwhere \u03bb is the hyperparameter to regulate the strength. By utilizing the modified score for the\nsampling process, we distill the discriminative content into the latent space, and then obtain the\ndiscriminative latent embeddings."}, {"title": "3.6 TRAINING AND INFERENCE", "content": "Training Stage. In the training stage, given an attribute graph G = {V, X, E, A}, we firstly train the\nGraph AE by the following objective:\n$L_{AE} = \u03b1 ||X - \\hat{X}||_2 + (1 \u2212 \u03b1) ||A - \\hat{A}||_2,$\nwhere || ||2 denotes the L2 norm, and \u03b1 is a hyper-parameter to balance the effect of feature and\nstructural reconstruction. Then we train the unconditional DM $\u03f5_\u03b8 (z_t, t)$ by the training objective\nas in Eq. 5, meanwhile, we obtain the common feature c. Finally, we train the conditional DM\n$\u03f5_\u03b8 (z_t, c, t)$ by the following equation:\n$L_{Cond} = E_{z0\u223cp(z)}E_{zt\u223cp(zt|z0,c)} || \u03f5_\u03b8 (zt, c, t) \u2013 \u03b5||_2.$\nInference Stage. In the inference stage, given attribute graph G, we first transform it into latent space\nby well-trained encoder \u03a6. Second, we add t-step noises (t < T) on the extracted latent embedding to\npreserve the general content. Then, we discriminatively sample from both unconditional DM $\u03f5_\u03b8 (z_t, t)$\nand conditional DM $\u03f5_\u03b8 (z_t, c, t)$ with Eq. 10 as scores. Finally, we transform the reconstructed\nembedding into graph space by decoder \u03a8 for reconstruction error calculation."}, {"title": "4 EXPERIMENT", "content": "In this section, we conduct experiments to validate the effectiveness of our DiffGAD. Specifically,\nwe first introduce the experimental settings, and next, we analyze the ablation studies, finally, we\ndescribe the comparison results with the state-of-the-art methods."}, {"title": "4.1 EXPERIMENTAL SETTINGS", "content": "Datasets. Following the work in we employ 13 baselines as benchmarks on\n6 real-world datasets (Weibo, Reddit, Disney, Books, Enron), including\na large-scale dataset Dgraph for evaluation.\nMetrics. Following the extensive literature in GAD , we compressively evaluate the performance of DiffGAD with the representative ROC-\nAUC (Receiver Operating Characteristic Area Under Curve), AP (Average Precision), Recall@k, and\nthe AUPRC (Area Under the Precision and Recall Curve) metrics.\nComparisons. Following the work in , we report the average performance with\nstd results over 20 trials for a fair comparison. Moreover, we re-implement current methods for all\ndatasets with , and observe a large performance gap for the ROC-AUC in Enron,\nwhile other datasets are similar (as the official GitHub issue mentioned in 1). Therefore, to prevent\nambiguity, we use the re-implemented ROC-AUC results on the Enron dataset and follow the results\nof other datasets and metrics in ."}, {"title": "4.2 ABLATION STUDIES", "content": "The effects of discriminative content distillation. We conduct experiments over various \u03bb in Eq. 10,\nand the experimental results are shown in Figure 3. Specifically, we list the AUC performance with\nthe conditional DM $\u03f5_\u03b8 (z_t, c, t)$ as \u03bb = \u22121.0 (only common content), with the unconditional DM\n$\u03f5_\u03b8 (z_t, t)$ as \u03bb = 0.0 (only general content), and with different values of \u03bb ranging from 0.2 to 2.0."}, {"title": "4.3 COMPARISON WITH SOTA METHODS", "content": "In this subsection, we comprehensively compare our method with various state-of-the-art algorithms,\nranging from graph-agnostic algorithms LOF , MLPAE ,"}, {"title": "5 TIME AND COMPUTATIONAL ANALYSIS", "content": "In this study, we analyze the time and computational analysis from theoretical and empirical views."}, {"title": "5.1 THEORETICAL ANALYSIS", "content": "(1) Graph AutoEncoder. We analyze the complexity according to . Specifically,\nwe utilize the Graph convolutional network as our backbone, whose complexity is linear to the edge\nnumbers. For each layer, the convolution operation is $\\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}}XW$, and thus the complexity"}, {"title": "5.2 EMPIRICAL DISCUSSION", "content": "Following , we employ the Wall-Clock time and GPU memory for empirical\ncomparisons, and the experimental results are listed in Table 3 and Table 4, respectively. The whole\ntesting is conducted on a Linux server with a 2.90GHz Intel(R) Xeon(R) Platinum 8268 CPU, 1T\nRAM, and 1 Nvidia 2080 Ti GPU with 11GB memory.\nWe can observe that DiffGAD is efficient in terms of both time and memory usage. Specifically,\nbenefitting from the advancements in diffusion acceleration, we adopt a more efficient EDM sam-\npler within latent space and utilize 50 sampling steps. From Table 4, we can\nobserve that the sampling time of DiffGAD is quite short, only 0.17 seconds. Moreover, we also list\nthe Autoencoder with \u03b1 = 1 in Eq. 7, Denoted as DiffGAD (AE \u03b1 = 1), which omits the topology\nreconstruction, and reduces AE costs to O(mdH). We can observe that the running time of AE\n\u03b1 = 1 and diffusion model are comparable.\nFurthermore, as the size of the graph scales to real-world proportions, the overall time complexity\nof DM simplifies to O(n) as we discuss in 5.1. This indicates that the complexity $O(n^2)$ of Auto\nEncoder dominates the whole complexity, while the time required for diffusion model who adding\nand removing noise in latent space can be neglected."}, {"title": "6 CONCLUSION", "content": "In this work, to tackle the limited ability to capture discriminative content for graph anomaly detection,\nwe make the first effort to transfer the diffusion model from the generation task to a detector and\npropose a diffusion-based unsupervised graph anomaly detector, namely DiffGAD. Specifically, (1) a\ndiscriminative content-guided generation paradigm is proposed to capture the discriminative content\nand then distill it into the latent space, and (2) a content-preservation strategy is designed to enhance"}, {"title": "7 CODE OF ETHICS AND REPRODUCIBILITY STATEMENT", "content": "Code of Ethics. This work is primarily foundational in Graph Anomaly Detection, focusing on the\ndevelopment of a more robust, reliable graph anomaly detector. Its primary aim is to contribute to\nthe academic community by enhancing the understanding and implementation of Graph Anomaly\nDetection techniques. We do not foresee any direct, immediate, or negative societal impacts stemming\nfrom the outcomes of our research.\nReproducibility Statement. All results presented in this work are fully reproducible. We provide our\ncode using the anonymous GitHub link. The optimal hyperparameters are detailed in Appendix D."}, {"title": "C.1 DETAILED DATASET DESCRIPTIONS", "content": "The detailed statistics of the datasets are shown in Table 5.\nWeibo : Weibo describes the relationship between users, posts, and hashtags on\nthe social platform Tencen-Weibo, where the hashtags serve as the edges, the post's information and"}, {"title": "C.2 MORE EXPERIMENTAL COMPARISONS", "content": "In this subsection, we show more experimental metrics, including Average Precision (AP), Recall@k,\nand Area Under the Precision and Recall Curve (AUPRC), and the experimental results are listed\nin Table 6, Table 7, and Table 8, respectively. Specifically, we can observe that our DiffGAD\nachieves favorable performances with small std results around all benchmarks, which demonstrates\nour effectiveness."}, {"title": "C.3 MORE ABLATION RESULTS", "content": "In this subsection, we provide more ablation results to validate our method. Specifically, we empir-\nically explore the validity of the generated common feature $c_{next}$, and show the distance between\n$c_{next}$ with the reconstructed Abnormal and Normal features statistically, the L2 distances is shown in\nTable 9, and the Standardized cosine distances in depicted in Table 10. We can observe that $c_{next}$\nis more similar to the normal samples from both results, which shows that normal samples contain\nmore common attributes.\nFurthermore, we show more experimental results with different \u03bb in Figure 8. We can observe that\nboth the Reddit and Weibo datasets are not sensitive with different \u03bb (\u03bb < 2), but the performance of\nboth datasets drops with \u03bb = 2, borrowing from the classifier-free guidance"}]}