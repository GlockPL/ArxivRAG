{"title": "Scalable Knowledge Refactoring using Constrained Optimisation", "authors": ["Minghao Liu", "David M. Cerna", "Filipe Gouveia", "Andrew Cropper"], "abstract": "Knowledge refactoring compresses a logic program by introducing new rules. Current approaches struggle to scale to large programs. To overcome this limitation, we introduce a constrained optimisation refactoring approach. Our first key idea is to encode the problem with decision variables based on literals rather than rules. Our second key idea is to focus on linear invented rules. Our empirical results on multiple domains show that our approach can refactor programs quicker and with more compression than the previous state-of-the-art approach, sometimes by 60%.", "sections": [{"title": "1 Introduction", "content": "Knowledge refactoring is a key component of human intelligence (Rumelhart and Norman 1976). Knowledge refactoring is also important in AI, such as for policy reuse in planning (Bonet, Drexler, and Geffner 2024) and to improve performance in program synthesis (Ellis et al. 2018; Duman\u010di\u0107, Guns, and Cropper 2021). The goal is to compress a knowledge base, such as a logic program, by introducing new rules.\nTo illustrate knowledge refactoring, consider the logic program:\n$P_1 = \\begin{cases}\ng(A) \\leftarrow p(A), q(A,B), r(B), s(A,B) \\\\\ng(A) \\leftarrow p(A), q(A,B), r(B), t(A,B) \\\\\ng(A) \\leftarrow p(B), q(B,C), r(C), w(A,B) \\\\\ng(A) \\leftarrow p(A), q(B,A), r(A), z(A,B)\n\\end{cases}$\nThis program has 4 rules, each with 5 literals. Thus, the size of this program is 20 (literals).\nWe could add a new aux\u2081 rule to refactor P\u2081 as:\n$P_2 = \\begin{cases}\naux_1(A,B) \\leftarrow p(A), q(A,B), r(B) \\\\\ng(A) \\leftarrow aux_1(A,B), s(A,B) \\\\\ng(A) \\leftarrow aux_1(A,B), t(A,B) \\\\\ng(A) \\leftarrow aux_1(B,C), w(A,B) \\\\\ng(A) \\leftarrow p(A), q(B,A), r(A), z(A,B)\n\\end{cases}$\nThe size of P2 is smaller than P\u2081 (18 vs 20 literals) yet syntactically equivalent to P\u2081 after unfolding\u00b9 (Tamaki and Sato 1984).\nA limitation of current refactoring approaches is scalability (Ellis et al. 2018; Cao et al. 2023; Bowers et al. 2023). For instance, KNORF (Duman\u010di\u0107, Guns, and Cropper 2021) frames the refactoring problem as a constrained optimisation problem (COP) (Rossi, Van Beek, and Walsh 2006). KNORF builds a set of invented rules by enumerating all subsets of the rules in an input program. KNORF then uses a COP solver to find a subset of the invented rules that maximally compresses the input program. However, because it enumerates all subsets, KNORF struggles to scale to programs with large rules and to programs with many rules.\nTo overcome this scalability limitation, we introduce a novel refactoring approach. Our first key contribution is a new COP formulation. Instead of enumerating all subsets of rules, we use decision variables to determine whether a literal is used in an invented rule. Our new formulation has two key advantages. First, the number of decision variables required is exponentially reduced. Second, an invented rule can use any combination of literals in the input program, rather than a strict subset of an input rule.\nTo illustrate the benefit of our first contribution, consider the input program P\u2081. The invented rule aux\u2081 cannot refactor the last rule as any instance of aux\u2081 cannot cover the literals p(A), q(B,A), r(A) simultaneously. However, we could invent the rule aux2 to refactor the program as:\n$P_3 = \\begin{cases}\naux_2(A,B,C) \\leftarrow p(A), q(B,C), r(C) \\\\\ng(A) \\leftarrow aux_2(A,A,B), S(A,B) \\\\\ng(A) \\leftarrow aux_2(A,A,B), t(A,B) \\\\\ng(A) \\leftarrow aux_2(B,B,C), w(A,B) \\\\\ng(A) \\leftarrow aux_2(A,B,A), z(A,B)\n\\end{cases}$\nThe body of aux2 is not a subset of any rule in P1, so KNORF could not invent aux2. By contrast, because we allow an invented rule to use any literal, we can invent aux2. The program P3 is smaller than P2 (16 vs 18 literals) yet is syntactically equivalent to P\u2081 after unfolding. As this example shows, our first contribution allows our approach to find better (smaller) refactorings.\nOur second key contribution is to use linear invented rules where (i) the body literals may not occur in the input program, and (ii) the size may be larger than any rule in the input program."}, {"title": "Novelty and Contributions", "content": "The three main novelties of this paper are (i) the theoretical proof of the complexity of the optimal knowledge refactoring problem, (ii) a concise and efficient encoding of the problem as a COP, and (iii) demonstrating the effectiveness of our approach on large-scale and real-world benchmarks. Overall, our contributions are:\n\u2022 We introduce the optimal knowledge refactoring problem, where the goal is to compress a logic program by inventing rules. We prove that the problem is NP-hard.\n\u2022 We introduce MAXREFACTOR, which solves the optimal knowledge refactoring problem by formulating it as a COP.\n\u2022 We evaluate our approach on multiple benchmarks. Our results show that, compared to the state-of-the-art approach, MAXREFACTOR can improve the compression rate by 60%. Our results also show that MAXREFACTOR scales well to large and real-world programs."}, {"title": "2 Related Work", "content": "Knowledge refactoring. Knowledge refactoring is important in many areas of AI (Bonet, Drexler, and Geffner 2024), notably in program synthesis (Ellis et al. 2018; Bowers et al. 2023; Cao et al. 2023; Hocquette, Dumancic, and Cropper 2024). For instance, Duman\u010di\u0107, Guns, and Cropper (2021) show that learning from refactored knowledge can substantially improve predictive accuracies of an inductive logic programming system and reduce learning times because the knowledge is structured in a more reusable way and redundant knowledge is removed.\nModel reformulation. There is much research on reformulating constraint satisfaction problem (CSP) models automatically (O'Sullivan 2010; Charlier et al. 2017; Vo 2020).\nThe main categories include implied constraints generation (Charnley, Colton, and Miguel 2006; Bessiere, Coletta, and Petit 2007), symmetry and dominance breaking (Liberti 2012; Mears and de la Banda 2015), pre-computation (Cadoli and Mancini 2006), and cross-modeling language translation (Drake et al. 2002). We differ because we work with logic programs and invent rules.\nRedundancy and compression. Knowledge refactoring is distinct from knowledge redundancy, which is useful in many areas of AI, such as in Boolean Satisfiability (Heule et al. 2015). For instance, Plotkin (1971) introduced a method to remove logically redundant literals and clauses from a logical theory. Similarly, theory compression (De Raedt et al. 2008) approaches select a subset of clauses such that performance is minimally affected with respect to a cost function. We differ from redundancy elimination and theory compression because we restructure knowledge by inventing rules.\nPredicate invention. We refactor a logic program by introducing predicate symbols that do not appear in the input program, which is known as predicate invention (Kramer 2020). Predicate invention is a major research topic in program synthesis and inductive logic programming (Kok and Domingos 2007; Muggleton, Lin, and Tamaddoni-Nezhad 2015; Hocquette and Muggleton 2020; Jain et al. 2021; Silver et al. 2023; Cerna and Cropper 2024). We contribute to this topic by developing an efficient and scalable method to invent predicate symbols to compress a logic program.\nProgram refactoring. In program synthesis, many researchers (Ellis et al. 2018; Bowers et al. 2023; Cao et al. 2023) refactor functional programs by searching for local changes (new \\(\\lambda\\)-expressions) that optimise a cost function. We differ from these approaches because we (i) consider logic programs, (ii) use a declarative solving paradigm (COP), and (iii) guarantee optimal refactoring. ALPS (Duman\u010di\u0107 et al. 2019) compresses facts in a logic program, whereas we compress rules.\nKNORF. The most similar work is KNORF (Duman\u010di\u0107, Guns, and Cropper 2021). Given a logic program P as input, KNORF works as follows. For each ruler \\(r \\in P\\), KNORF enumerates every subset s of r. For each subset s and for each combination h of the variables in s, KNORF creates a new rule auxsh. KNORF then creates a COP problem where there is a decision variable for each auxsh. It also creates decision variables to state whether a ruler \\(r \\in P\\) is refactored using auxsh. KNORF then uses a COP solver to find a subset of the invented rules that leads to a refactoring with maximal compression. KNORF has many scalability issues. Foremost, it enumerates all subsets of all rules and thus struggles to scale to programs with large rules and many rules. Specifically, for a program with n rules and a maximum rule size k, KNORF uses O(n2k) decision variables. By contrast, our MAXREFACTOR approach does not enumerate all subsets of rules. Instead, as we describe in Section 4, we define a new rule aux by creating decision variables to represent whether any literal in P is in auxi. Besides, we create decision variables to state whether a rule and a literal in P is refactored using auxi. Since the number of invented rules is a predefined constant, MAXREFACTOR only needs"}, {"title": "3 Problem Setting", "content": "We focus on refactoring knowledge in the form of a logic program, specifically a definite logic program with the least Herbrand model semantics (Lloyd 2012). For simplicity, we use the term logic program to refer to a definite logic program. We assume familiarity with logic programming but restate some key terms. A logic program is a set of rules of the form:\n$$h \\leftarrow a_1, a_2,..., a_m$$\nwhere h is the head literal and \\(a_1,..., a_m\\) are the body literals. A literal is a predicate symbol with one or more variables. For example, parent(A,B) is a literal with the predicate symbol parent and two variables A and B. The predicate symbol of a literal a is denoted as pred(a) and the set of its variables is denoted as var(a). The head literal of a rule is true if and only if all the body literals are true. The head literal of a rule r is denoted as head(r) and the set of body literals is denoted as body(r). The size of a ruler is defined as size(r) = |body(r)| + 1, which is the total number of literals. The size of a logic program P is defined as size(P) = \\(\\sum_{r \\in P} size(r)\\).\n3.1 Knowledge Refactoring\nOur goal is to reduce the size of a logic program whilst preserving its semantics. However, checking the semantic equivalence between two logic programs is undecidable (Shmueli 1987). Therefore, we focus on finding syntactically equivalent refactorings. Syntactic equivalence implies semantic equivalence but the reverse is not necessarily true. We check syntactic equivalence by unfolding (Tamaki and Sato 1984) refactored programs. Unfolding is a transformation in logic programming. We adapt the unfolding definition of Nienhuys-Cheng and Wolf (1997) to (i) resolve multiple literals, whereas the original definition only resolves one literal each time, and (ii) prohibit variables that only appear in the body of a rule:\nDefinition 1 (Rule unfolding). Given a logic program P = {C1, C2,...,CN} and a rule r, where r does not have variables that only appear in its body, then unfolding P upon r means constructing the logic program Q = {d1,d2,...,dv}, where each di is the resolvent of ci and r if head(r) is unifiable with any literal in body(ci), otherwise di = ci.\nExample 1 (Rule unfolding). Consider the program:\n$P = \\begin{cases}\ng(A) \\leftarrow p(A), aux(A,B) \\\\\ng(A) \\leftarrow p(B), p(C), aux(A,B), aux(A,C) \\\\\ng(A) \\leftarrow p(B), q(A,B), r(B)\n\\end{cases}$\nand the ruler: aux(A,B) \\leftarrow p(B), q(A,B). The result of unfolding P upon r is:\n$Q=\\begin{cases}\ng(A) \\leftarrow p(A), p(B), q(A,B) \\\\\ng(A) \\leftarrow p(B), p(C), q(A,B), q(A,C) \\\\\ng(A) \\leftarrow p(B), q(A,B), r(B)\n\\end{cases}$$\nGiven a set of rules S, unfold(P, S) is the result of successively unfolding P upon every rule in S.\nTo refactor a logic program, we want to introduce invented rules:\nDefinition 2 (Invented rule). Given a logic program P and a finite set of variables X, an invented rule r satisfies four conditions:\n1.  pred(head(r)) \\(\\notin\\) P\n2.  \\(\\forall a \\in body(r)\\), pred(a) \\(\\in\\) P\n3.  \\(\\forall a \\in body(r)\\), var(a) \\(\\subseteq\\) X\n4.  var(head(r)) = \\(\\bigcup_{a \\in body(r)} var(a)\\)\nIn this paper, we use the prefix aux to denote the predicate symbol of an invented rule.\nWe want to refactor an input rule using invented rules. We call such rules refactored rules:\nDefinition 3 (Refactored rule). Let r be a rule and S be a set of invented rules. Then r' is a refactored rule of r iff unfold({r'}, S) = {r}. For a logic program P and a set of invented rules S, I(P, S) denotes the set of all possible refactored rules of rules in P.\nExample 2 (Refactored rule). Given the rules in Q and the invented rule aux in Example 1, the first two rules in P are refactored rules.\nWe define a refactored program:\nDefinition 4 (Refactored program). Given a logic program P and a finite set of invented rules S, a logic program Q \\(\\subseteq\\) P \\(\\cup\\) S \\(\\cup\\) I(P, S) is a refactored program of P iff unfold(Q \\ S, Q \\(\\cap\\)S) = P, and we refer to Q as a proper refactoring if \\(\\forall S' \\subseteq Q \\cap S\\), unfold(Q \\ S, Q \\(\\cap\\) S') \\(\\neq\\) P.\nTo help explain the intuition behind Definition 4, note the following three properties of a refactored program. First, a refactored program consists of three kinds of rules (a) input rules from P, (b) invented rules from S, and (c) refactored rules from I(P, S). Second, P and Q must be syntactically equivalent, which means that we can unfold Q upon the invented rules to get P. Third, we are only interested in programs Q which are proper refactorings of P as any non-proper refactoring containing Q is always a larger program.\nWe want optimal knowledge refactoring (OKR):\nDefinition 5 (Optimal knowledge refactoring problem). Given a logic program P and a finite set of invented rules S, the optimal knowledge refactoring problem is to find a refactored program Q such that for any refactored program Q', size(Q) < size(Q').\nWe prove that the OKR problem is NP-hard:\nTheorem 1. The optimal knowledge refactoring problem is NP-hard.\nProof (Sketch). The full proof is in Appendix A. We provide a reduction from maximum independent set in 3-regular Hamiltonian graphs (Fleischner, Sabidussi, and Sarvanov 2010) to a propositional variant of OKR where \\(c_1, c_2 \\in S\\) may refactor the same rule of P iff \\(body(c_1) \\cap body(c_2) = \\emptyset\\) (OPKRWD). Let G = (V, E) be a 3-regular Hamiltonian graph and C a maximum independent set of G. Observe"}, {"title": "4 MAXREFACTOR", "content": "Given an input logic program P, a space of possible invented rules S, and a maximum number K of invented rules to consider, MAXREFACTOR refactors P by finding \\(C \\subseteq S\\) where |C| = K. In other words, MAXREFACTOR solves the optimal knowledge refactoring problem.\nBefore describing how we search for a refactoring, we first introduce linear invented rules to restrict the space of possible invented rules.\n4.1 Linear Invented Rule\nThe space of possible invented rules S directly influences the effectiveness and efficiency of refactoring. For example, KNORF defines S as all subsets of rules in an input program. For instance, if there is an input rule g(A) \\(\\leftarrow\\) p(A,B), q(B,C), r(B,D), KNORF adds four possible invented rules to S:\naux1(A,B,C) \\(\\leftarrow\\) p(A,B), q(B,C)\naux2(A,B,D) \\(\\leftarrow\\) p(A,B), r(B,D)\naux3(B,C,D) \\(\\leftarrow\\) q(B,C), r(B,D)\naux4(A,B,C,D) \\(\\leftarrow\\) p(A,B), q(B,C), r(B,D)\nDefining S this way has the advantage that it restricts which literals can appear in an invented rule. However, this approach also has disadvantages. As we show in Section 1, this approach cannot invent a rule that is not a subset of any input rule (e.g. aux2 in P3), nor can the size of the invented rule be larger than any input rule (e.g., aux3 in Q2).\nTo overcome these limitations, we use a new approach to define the space of invented rules. We denote the set of body predicate symbols in the logic program P as Pr(P) and a finite set of variables as X. We define the set of all possible body literals L = {p(v) | p \\(\\in\\) Pr(P), v \\(\\in\\) Xarity(p)}. We define S as the space of all combinations of literals from L, i.e., the power set of L. The size of S is exponential in the size of L and S is clearly a superset of the space considered by KNORF. Therefore, our key insight is not to consider all combinations of L and to instead only consider the most general ones. We call such rules linear invented rules:\nDefinition 6 (Linear invented rule). A linear invented rule is rule with linear variable occurrence in its body.\nExample 3 (Linear invented rule). The rule aux\u2081(A,B,C) \\(\\leftarrow\\) p(A,B), q(B,C) is not linear because its body literals share the variable B. By contrast, the rule aux2(A,B,C,D) \\(\\leftarrow\\) p(A,B), q(C,D) is linear.\nFor any invented rule r, we can always build a linear invented rule lin(r) as follows: (i) rewrite the body literals such that the predicate symbols remain unchanged and the variables occur linearly, then (ii) build a new head literal such that var(head(lin(r))) = \\(\\bigcup_{a \\in body(lin(r))} var(a)\\).\nTo motivate the use of linear invented rules in refactoring, we show the theorem:\nTheorem 2. If the optimal knowledge refactoring problem has a solution using the set of invented rules \\(C \\subseteq S\\) then it has a solution using \\(C' \\subseteq S_{lin}\\), where \\(S_{lin} = {lin(s) | s \\in S}\\).\nProof. Suppose there is an invented ruler \\(r \\in C\\), we can always build a linear invented rule r' = lin(r), then C' = C\\{r}\\(\\cup\\){r'}. First, observe that |C'| < |C| because either an invented rule has a unique linear invented rule generalising it, or multiple invented rules of C are generalised by the same linear invented rule. Second, for any body literal in the input program that is covered by r, it can also be covered by r' via variable mapping. Thus, we can always get a refactored program of the same or smaller size using C'.\nTheorem 2 implies that we can restrict S to linear invented rules without compromising the optimal solution. As we show below, defining S as linear invented rules allows us to simplify the COP formulation.\n4.2 COP Encoding\nAccording to Theorem 1, the optimal knowledge refactoring problem is NP-hard, making it computationally challenging. Constraint programming (CP) is a successful framework for modeling and solving hard combinatorial problems (Hebrard 2018). Therefore, MAXREFACTOR formulates this search problem as a constrained optimisation problem (COP) (Rossi, Van Beek, and Walsh 2006). Given (i) a set of decision variables, (ii) a set of constraints, and (iii) an objective function, a COP solver finds an assignment to the decision variables that satisfies all the specified constraints and minimises the objective function.\nWe describe our COP encoding below\u00b2.\nDecision Variables MAXREFACTOR builds decision variables to determine (a) which literals are in which invented rules, and (b) how to refactor input rules using the invented rules\u00b3.\nFor task (a), for each possible invented rule rk for k \\(\\in\\) [1, K] and p \\(\\in\\) Pr(P), we use an integer variable rk,p to indicate the number of literals with predicate symbol p in the body of rk.\nFor example, consider the input program:\n$P=\\begin{cases}\nC1:g(A) \\leftarrow p(B)a1, p(C)a2, q(A,B)a3, q(B,C)a4 \\\\\nC2: g(A) \\leftarrow p(B)a1, q(A,B)a2, q(A,C)a3, s(C)a4\n\\end{cases}$\n4.  3 The domain of t is defined by the maximum number of times a predicate symbol appears in an input rule."}, {"title": "5 Experiments", "content": "To test our claim that MAXREFACTOR can find better refactorings than current approaches, our experiments aim to answer the question:"}]}