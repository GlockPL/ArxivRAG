{"title": "CurricuVLM: Towards Safe Autonomous Driving via Personalized Safety-Critical Curriculum Learning with Vision-Language Models", "authors": ["Zihao Sheng", "Zilin Huang", "Yansong Qu", "Yue Leng", "Sruthi Bhavanam", "Sikai Chen"], "abstract": "Ensuring safety in autonomous driving systems remains a critical challenge, particularly in handling rare but poten-tially catastrophic safety-critical scenarios. While existing research has explored generating safety-critical scenariosfor autonomous vehicle (AV) testing, there is limited work on effectively incorporating these scenarios into policylearning to enhance safety. Furthermore, developing training curricula that adapt to an AV's evolving behavioralpatterns and performance bottlenecks remains largely unexplored. To address these challenges, we propose Cur-ricuVLM, a novel framework that leverages Vision-Language Models (VLMs) to enable personalized curriculumlearning for autonomous driving agents. Our approach uniquely exploits VLMs' multimodal understanding capabili-ties to analyze agent behavior, identify performance weaknesses, and dynamically generate tailored training scenariosfor curriculum adaptation. Through comprehensive analysis of unsafe driving situations with narrative descriptions,CurricuVLM performs in-depth reasoning to evaluate the AV's capabilities and identify critical behavioral patterns.The framework then synthesizes customized training scenarios targeting these identified limitations, enabling effec-tive and personalized curriculum learning. Extensive experiments on the Waymo Open Motion Dataset show thatCurricuVLM outperforms state-of-the-art baselines across both regular and safety-critical scenarios, achieving supe-rior performance in terms of navigation success, driving efficiency, and safety metrics. Further analysis reveals thatCurricuVLM serves as a general approach that can be integrated with various RL algorithms to enhance autonomousdriving systems.", "sections": [{"title": "1. Introduction", "content": "The advancement of artificial intelligence and sensor technologies has enabled autonomous vehicles (AVs) toachieve remarkable progress over the past decades, particularly in perception, decision-making, and control capa-bilities. These advancements havefacilitated the transition of autonomous driving from theoretical research to preliminary commercial deployment,with leading technology companies like Waymo and Cruise initiating pilot autonomous taxi services in selected citiesacross the United States. While AVs prom-ise to revolutionize transportation with improved mobility and reduced emissions, their widespread deployment remainsconstrained by persistent safety-related challenges. Real-world traffic environments are inherently complex, presenting a \"long tail\" of rare but critical scenarios,such as sudden pedestrian crossings or abrupt loss of control by nearby vehicles. These scenarios, while infrequent,often carry significant consequences and present substantial challenges. Due to their urgency and safety-critical na-ture, instantaneous decision-making is demanded, where subtle misjudgments could lead to fatal outcomes. Evenhuman drivers require extensive training to handle them reliably. In light of these challenges, enhancing AV safetyand robustness in these safety-critical scenarios has emerged as a key research focus.\nThe current literature on autonomous driving safety enhancement broadly divides into two categories: policy-levelapproaches that focus on designing safer driving policies and scene-level approaches that generate diverse safety-critical scenarios to assess an AV agent's robustness. Regarding policy-level approaches, acommon paradigm in this category involves combining traditional reinforcement learning (RL) with specific safetyconstraints to ensure safer policy outcomes. For instance, constrained Markov"}, {"title": "2. Related works", "content": "2.1. Safety-Critical Driving Scenario Generation\nIn recent years, research on generating safety-critical driving scenarios has gained attention as a means to evaluateand validate autonomous driving models. This field has attracted significant attention from various stakeholders, withregulatory bodies like NHTSA establishing frameworks for testable cases and pre-crash scenarios, while industry leaders such as Waymo focusing on reconstructing real-world fatal crashes insimulations. Within the academic community, researchers have explored various approachesto advance this field. For instance, reformulated scenario generation as areinforcement learning problem, where the generation model acts as an agent and the driving algorithm to be evaluatedserves as the environment. SceneGen proposed a neural autoregressive model to sequentially insertactors into the scene while synthesizing their states. However, SceneGen only focuses on generating static traffic scenesnapshots without considering subsequent vehicle trajectories. STRIVE addressed this limitationby introducing a learned traffic motion model to generate safety-critical vehicle trajectories. More recently, TrafficGen developed an autoregressive neural architecture to generate both realistic initial states and long-term trajectories. To improve the controllability of scenario generation, diffusion models with guided sampling have been leveraged to enable flexible control over generated scenes. Despitethese advances, most existing approaches focus primarily on scenario generation and testing without effectively utilizinggenerated scenarios for closed-loop training of AV agents.\nLLMs have recently emerged as powerful tools for enhancing traffic scenario generation through their superiornatural language understanding and reasoning capabilities. CTG++ pioneered this direction byemploying LLMs to translate user queries into differentiable loss functions, which then guide a scene-level diffusionmodel to generate query-compliant traffic scenarios. Along similar lines, ChatScene utilizedLLMs to generate textual descriptions for safety-critical scenarios, which are then decomposed into sub-descriptionsfor behavior, geometry, and spawn positions. These descriptions are matched with a pre-built code snippet databaseTo improve performance, TTSG leveraged LLMs for roadselection and agent planning, supporting diverse traffic scene generation without requiring predefined spawning points.These works demonstrate the potential of LLMs in autonomous driving, especially their capabilities to understandcomplex traffic contexts and generate corresponding descriptions. Inspired by these advances, our work aims tofurther leverage VLMs and LLMs to analyze agent behavior patterns, enabling personalized safety-critical trainingcurricula to enhance autonomous driving safety."}, {"title": "2.2. Curriculum Learning in Autonomous Driving", "content": "Inspired by the way humans learn progressively from simpler to more complex tasks, curriculum learning involves structuring the learning process in stages based on task difficulty or the learner's capabilities.This methodology has shown great potential in accelerating training and improving performance across various ma-chine learning tasks. In autonomous driving, curriculum learning has emerged as a promisingapproach to tackle the challenge of learning complex driving behaviors. For instance, Anzalone et al. proposed an end-to-end curriculumlearning framework that divides reinforcement learning into multiple stages of increasing difficulty to guide the agenttowards better driving policies. Peiss et al. further demonstrated how to design effective curricula by graduallyincreasing task complexity in terms of traffic density, driving routes, and spatial constraints. Their curriculum startswith basic skills like lane keeping in sparse traffic, then progressively introduces more complex tasks such as colli-sion avoidance and lane change in denser scenarios. However, most works rely on manual curriculum design, whichmay require significant expert knowledge and make it challenging to generalize across different driving scenarios.To address these limitations, recent research has begun exploring automated curriculum generation. Most notably,CLIC proposed by Niu et al. developed a continual driving policy optimization framework with closed-loopindividualized curricula. CLIC trains a discriminator network to predict collision probabilities in different scenariosand leverages these predictions to customize individualized curricula for the current AV's capability level. Differentfrom their work which relies solely on a black-box collision prediction model for curriculum design, our approachleverages VLM's visual understanding and reasoning abilities to assess agent behavior and performance, providinginterpretable textual analysis and enabling more comprehensive and targeted curriculum generation."}, {"title": "2.3. Autonomous Driving with LLMs/VLMs", "content": "LLMs and VLMs have demonstrated remarkable capabilities across various domains, showcasing their potentialin natural language understanding, visual reasoning, and complex decision-making tasks. Recently, there has been a growing interest in integrating these powerful models into autonomous drivingsystems to enhance their perception, reasoning, and decision-making capabilities. GPT-Driver pioneered this integration by incorporating LLMs into autonomous driving planning, utilizing GPT-based models to generate high-level driving decisions from natural language descriptions of traffic scenarios. Buildingupon this foundation, DiLu introduced a comprehensive framework that combines LLM-basedreasoning, reflection, and memory modules, enabling decision-making based on common sense knowledge whilecontinuously accumulating driving experience for self-reflection. DriveLM proposed a novel graphvisual question answering task, reformulating autonomous driving's perception, prediction, and planning processes as a sequence of graph-structured question-answering interactions. Taking inspiration from human cognition, LeapAD developed a dual-decision architecture that leverages LLMs for in-depth analysis and reasoningwhile employing lightweight models for rapid experience-based decision-making. Furthermore, ELM enhanced VLMs' spatial perception and long-horizon extrapolation capabilities in driving scenarios throughthe utilization of large-scale open-world data. These pioneering works inspire us to leverage the powerful reasoningcapabilities of VLMs and LLMs for analyzing agent behaviors and generating personalized safety-critical scenarios."}, {"title": "3. Problem Formulation", "content": "We formulate the autonomous driving task as a Markov Decision Process (MDP) (Wu et al., 2024), defined bythe tuple (S, A, P, R, \u03b3). In this formulation, S represents the state space, encompassing all possible states of thedriving environment, including the AV's own state and the states of other traffic agents. The action space A comprisesall possible actions the AV can take, such as steering angles, throttle, and braking commands. The state transitionprobability function P : S \u00d7 A \u00d7 S \u2192 [0, 1] defines the probability of transitioning from one state to another given anaction. The reward function R : S\u00d7A \u2192 Rassigns a scalar reward to each state-action pair, reflecting the desirabilityof particular actions in specific states. The discount factor \u03b3\u2208 [0,1) determines the importance of future rewardsrelative to immediate ones. The objective of the AV agent is to learn an optimal policy \u03c0* : S \u2192 A that maximizesthe expected cumulative discounted reward:\n\u03c0\u2217=arg\u03c0maxE\u03c4\u223c\u03c0[\u2211t=0\u221e\u03b3tR(st,\u03c0(st))](1)\nwhere \u03c4=(s0,a0,s1,...) denotes a trajectory unrolled by policy \u03c0 under the transition dynamics P.\nTo better formulate our problem of learning safe driving policies through personalized curriculum learning, wefirst introduce several key concepts that will be used throughout this paper:\nDefinition 1 (Driving Scenario). A driving scenario is defined as a tuple \u00a7 = (M,V), where M represents the HDmap containing static environment elements (e.g., road geometry, traffic signs, traffic lights), and V = {v1, ..., VN}denotes the set of traffic participants and their states over temporal duration T. Each participant vi is characterizedby its state trajectory {s}_1, including position, velocity, and orientation."}, {"title": "4. Methodology", "content": "4.1. Framework Overview\nInspired by how human drivers improve their skills through experience and targeted practice, we propose Curricu-VLM, a framework that enables autonomous driving agents to learn from their mistakes and systematically enhancetheir safety capabilities. Just as a driving instructor would observe a student's performance, identify recurring issues,and design specific exercises to address these weaknesses, our framework operates through three key mechanisms:(1) analyzing safety-critical events using Vision-Language Models to understand the agent's behavioral patterns, (2)generating personalized training scenarios that target identified weaknesses, and (3) dynamically integrating thesescenarios into the training curriculum."}, {"title": "4.2. Safety-Critical Event Analysis with Vision-Language Models", "content": "4.2.1. Visual Observation Understanding\nDuring each training iteration, the AV agent interacts with diverse driving scenarios from the curriculum C, gener-ating a series of episodes E = {ei}_1. Each episode ei consists of a sequence of visual observations Oi = {ot}=1,where ot represents the visual observation of the environment at time step t. These episodes become safety-criticalwhen safety violations occur, either arising from the agent's suboptimal behavior leading to traffic violations or colli-sions, or emerging from challenging interactions with surrounding vehicles in our designed curriculum scenarios.To systematically analyze the agent's behavior and identify performance weaknesses, we employ a Vision-LanguageModel fVLM to generate comprehensive descriptions of critical moments in these episodes, as shown in Fig. 2(b).Specifically, we employ GPT-40 as our primary vision-language model due to its superior performance in compre-hensive scene understanding and detailed description generation. Our approach particularly focuses on interactionswith critical objects, i.e., traffic participants whose interactions with the AV agent lead to unsafe situations. Givena task description and instruction l, the VLM processes the visual observations to generate comprehensive narrativedescriptions for each safety-critical event:\ndi=fvLM(l,Ok\u2217),(3)\nwhere Ok contains the sequence of key frames with length less than or equal to k that capture the safety-criticalevent and its context. The task description l guides the VLM to focus on the type and nature of safety violations,spatial relationships between vehicles, and causal factors contributing to unsafe situations.\nThe generated description di provides a structured characterization of the event, including: (1) the type and natureof the safety violation (e.g., rear-end collision, side-swipe), (2) the relative positioning and behavior of critical objects,(3) the AV's response patterns, and (4) the contextual factors contributing to the incident. For instance, as illustratedin Fig. 2(b), in a failed lane change scenario, the VLM might generate: \"The incident involves a rear-end collisionduring a lane change maneuver. The red vehicle (AV) is driving forward attempting to merge, while the collidedvehicle is positioned behind in the target lane. The collision occurred due to insufficient acceleration and improperspeed matching during the lane transition.\""}, {"title": "4.2.2. Behavioral Pattern Analysis and Recommenddation", "content": "Building upon the VLM's descriptions of critical events and identified critical objects, we leverage GPT-40 toperform systematic behavioral pattern analysis. Our framework innovatively adopts a batch-wise analysis strategy byaccumulating N safety-critical events before initiating the analysis phase, as illustrated in Fig. 2(b). This approachenables us to process a sequence of recent event descriptions, denoted as D1:N = {di}_1. The batch-wise strategyoffers two key advantages: (1) it enables the identification of recurring behavioral patterns that might be overlooked inisolated incident analysis, and (2) it optimizes computational efficiency by reducing the frequency of model queries.\nTo facilitate structured analysis and ensure the quality and consistency of generated responses, we design a com-prehensive prompt template that consists of three key components. First, we establish the analysis context by position-ing the model as an expert in autonomous vehicle performance analysis and scenario generation, providing essentialbackground for understanding safety-critical scenarios in autonomous driving. Second, we provide a systematic pre-sentation of safety-critical events by incorporating the detailed descriptions from visual observation understanding:\"Scenario 1: [VLM Response 1] ... Scenario N: [VLM Response N]\". This organization ensures that all relevantspatial relationships, vehicle behaviors, and safety violations are clearly presented. Third, we guide the analysisprocess with specific instructions for behavioral pattern identification and improvement recommendation generation,emphasizing the importance of both immediate safety concerns and long-term behavioral improvements.\nThe behavioral analysis process can be formalized as:\nI=gGPT\u221240(P(D1:N)),(4)\nwhere P(\u00b7) represents our carefully designed prompt template that structures the input descriptions D1:N, and gGPT\u221240(\u00b7)denotes the analysis process that generates insights I.\nTo ensure comprehensive and systematic analysis, we specify a structured response format that guides the rea-soning process through four key components. The response format begins with Situation assessment, which providesa comprehensive examination of common patterns across the N safety-critical events. This component identifiesrecurring scenarios and behavioral tendencies in the agent's interactions with other traffic participants. This is fol-lowed by Reasoning, where in-depth causal analysis examines the underlying factors contributing to safety violations"}, {"title": "4.3. Personalized Curriculum Adaptation via Scenario Generation", "content": "Building upon the comprehensive behavioral analysis and recommendations from GPT-40, a critical challengeemerges: how to effectively translate these high-level recommendations into concrete, executable scenarios that targetthe agent's identified weaknesses. To address this challenge, we propose a curriculum adaptation mechanism thatdynamically generates personalized training scenarios based on the generated insights I.\nTo transform GPT-40's recommendations into executable scenarios, we formulate it as a conditional trajectorygeneration problem. Let X = (M, SA, SB) denote the historical information up to timestep t, including the HDmap M and past states of both AV agent and nearby background vehicles (BVs). Let YAV = SAV and YBV = SBVrepresent their future trajectories respectively. Given the behavioral insights and historical information, the distributionof future trajectories in the generated personalized scenario can be expressed as:\nP(YAV,YBV|I,X).(5)\nTo generate scenarios that effectively align with current insight I, we seek to maximize this probability by finding anoptimal BV trajectory:\nY\u2217BV=argYBVmax\u2211YAV\u2208Y(\u03c0)P(YAV,YBV|I,X),(6)\nwhere Y(\u03c0) denotes the set of possible trajectories generated by the current AV policy \u03c0.\nHowever, directly optimizing the objective in Eq. (6) is intractable due to the complex interdependencies betweenthe AV's trajectory and surrounding BVs. Inspired by recent works (Sun et al., 2022; Zhang et al., 2023), we observethat in safety-critical scenarios, the danger often originates from nearby BVs' aggressive or unexpected behaviors,which require appropriate responsive actions from the AV agent to maintain safety. For instance, when a BV sud-denly cuts in at a close distance, the AV agent must quickly recognize the danger and execute appropriate defensivemaneuvers such as emergency braking or evasive steering. This observation suggests a predominantly unidirectionaldependency in the interaction pattern, i.e., the AV agent needs to adapt its behavior based on the observed and pre-dicted trajectories of surrounding vehicles to ensure safety.\nBased on this observation, we can decompose the complex joint distribution into more manageable componentsthrough factorization and Bayes' rule:\nP(YAV,YBV|I,X)\u221dP(YBV|X)\u22c5P(YAV|YBV,X)\u22c5P(I|YAV,YBV).(7)\nAs illustrated in Fig. 2(c), this factorization decomposes the scenario generation process into three interpretable com-ponents: P(YBV|X) represents the marginal distribution of BV's trajectories, P(YAV|YBV,X) captures the condi-tional distribution of the AV's responses to these trajectories, and P(I|YAV,YBV) serves as a probability score mea-suring how well the generated scenario aligns with the identified behavioral insights. By substituting this factorizedform into Eq. (6), we obtain a more tractable optimization objective:\nY\u2217BV=argYBVmax\u2211YAV\u2208Y(\u03c0)P(YAV,YBV|I,X)=argYBVmaxP(YBV|X)\u2211YAV\u2208Y(\u03c0)P(YAV|YBV,X)\u22c5P(I|YAV,YBV).(8)\nThe first term P(YBV|X) can be regarded as a prior distribution of BVs' trajectories conditioned on historicalinformation. This distribution needs to capture both the physical feasibility of vehicle motion and the diverse patternsof human driving behaviors. While recent advances in trajectory prediction have demonstrated significant progressin modeling such distributions (Gu et al., 2021; Sheng et al., 2024a,b), developing a new trajectory prediction model"}, {"title": "4.4. Dynamic Curriculum Scheduling for RL", "content": "The effectiveness of our CurricuVLM framework critically depends on how we integrate the generated safety-critical scenarios into the training process. We propose a dynamic scheduling mechanism that adaptively adjusts thecomposition of training scenarios based on the agent's evolving capabilities. This mechanism needs to address twochallenges: (1) establishing and maintaining basic driving competencies through regular scenarios, and (2) developingrobust safety-critical handling capabilities through the personalized scenarios generated by our VLM-based analysisframework.\nBuilding upon Definition 2, we formalize our curriculum C as a sequence of training episodes {\u00a71, \u00a72, ..., \u00a7},where each episode can be either a regular driving scenario or a personalized safety-critical scenario. As illustrated inFig. 2(d), for each episode, we implement a probability-based selection mechanism to determine the type of scenario"}, {"title": "5. Experiments", "content": "5.1. Experimental Setups\n5.1.1. Experiment Environment\nWe conduct our experiments using the MetaDrive simulator (Li et al., 2022b), an open-source lightweight au-tonomous driving platform that provides flexible environment configurations and efficient scenario simulation, asshown in Fig. 3(a). For training and evaluation, we leverage the Waymo Open Motion Dataset (Ettinger et al.,2021), which provides diverse real-world driving scenarios collected across various traffic conditions and road layouts(Fig. 3(b)). Following the existing work (Zhang et al., 2023), we use 500 representative scenarios from the datasetand create a split of 400 for training and 100 for testing. Each scenario contains comprehensive trajectory informationof the ego vehicle and surrounding traffic participants, along with detailed HD map annotations.\n5.1.2. RL Setting\nThe observation space consists of three key components that provide comprehensive information about the drivingenvironment. First, the ego state includes the vehicle's dynamic properties such as speed, steering angle, throttle/brakeposition, and yaw rate, which characterize the vehicle's current motion state. Second, navigation information isrepresented by the relative distance and heading to the next two waypoints along the planned route, providing guidancefor RL agent's future actions. Third, LiDAR point cloud data captures the surrounding environment, enabling the agentto perceive and react to obstacles and other traffic participants.\nThe agent controls the vehicle through a continuous action space A \u2208 [\u22121, 1]\u00b2, consisting of steering and throt-tle/brake commands. The steering action asteer \u2208 [-1,1] determines the steering angle, where negative values indicateleft turns and positive values indicate right turns. The throttle/brake action aacc \u2208 [-1,1] controls longitudinal motion,with positive values applying throttle for acceleration and negative values engaging the brake for deceleration.\nWe adopt the default reward function from MetaDrive (Li et al., 2022b), which combines dense guidance for basicdriving behaviors with collision penalties and sparse rewards for episode outcomes:\nR(st,at)=Rdrive(st,at)+Rcollision+Rdone,(13)\nwhere Rdrive (St, at) denotes the dense reward for basic driving behaviors, Rcollision represents the penalty for collisions,and Rdone provides rewards based on episode outcomes."}, {"title": "5.1.3. Evaluation Strategy and Metrics", "content": "Our evaluation consists of two phases to comprehensively assess the effectiveness of different methods:\n1) Regular Scenario Testing: In this phase, we evaluate each method by having the AV agent navigate throughtest scenarios while BVs follow their original trajectories from the dataset, as illustrated in Fig. 3(c). Thisprovides a baseline assessment of basic driving capabilities under regular conditions.\n2) Safety-Critical Scenario Testing: We transform the test scenarios into safety-critical versions using our sce-nario generation method in Section 4.3. Fig. 3(d) shows examples of such transformed scenarios, where BVsare positioned to create challenging situations. The methods are then evaluated under these conditions to assesstheir robustness in handling safety-critical situations.\nThis dual-phase evaluation approach enables us to systematically assess both the fundamental driving compe-tencies and safety-critical handling capabilities of different autonomous driving methods. To quantitatively measureperformance in both phases, we employ multiple metrics focusing on safety, navigation performance, and learningcapabilities. Safety performance is primarily measured through the crash rate, which quantifies the percentage ofepisodes ending in collisions. The success of navigation tasks is assessed using the road completion rate and total dis-tance traveled, where higher values indicate better route-following behavior. We also report average speed to evaluate the agent's ability to balance efficiency and safety.\nTo specifically evaluate the learning effectiveness, we introduce two specialized metrics: the failure-to-successrate and success-to-success rate. The failure-to-success rate measures the percentage of previously failed scenarioswhere the agent achieves success after training, directly quantifying the agent's improvement in handling challenging situations. The success-to-success rate evaluates the agent's performance consistency by measuring the percentageof scenarios where the agent maintains successful performance, indicating the stability and reliability of the learnedpolicy. Additionally, we use episode reward as a comprehensive metric that captures the overall performance of thedriving policy."}, {"title": "5.2. Baselines", "content": "We compare our method against several state-of-the-art baselines across four categories:\n\u2022 Traditional RL: We include SAC which employs maximum entropy principles to en-hance exploration, PPO which uses trust region optimization for stable policy updates,and TD3 which addresses overestimation bias in value function estimation.\n\u2022 Safe RL: This category comprises SAC-PID which incorporates PID controllers into theSAC framework, TD3-Lag which employs Lagrangian methods to handle safety constraints,and TD3-PID which combines TD3 with PID control for enhanced safety guarantees."}, {"title": "5.3. Performance Comparison", "content": "We present a comprehensive performance comparison between our proposed CurricuVLM and baseline methodsacross two evaluation phases, with results shown in Tables 1-2 and Figs. 4-8. Except for BC, all methods were trainedfor 1 million steps, with experiments repeated three times using different random seeds to ensure statistical reliability.Mean values and standard deviations are reported. Table 1 presents the performance metrics under regular drivingconditions where BVs follow their original trajectories, while Table 2 shows the results in transformed safety-criticalscenarios. Similarly, in Figs. 4-8, we illustrate the learning curves throughout the training process, where solid linesrepresent mean values and shaded regions indicate the standard deviations across three runs. For each figure, the toprow demonstrates the performance under regular driving conditions, and the bottom row shows the correspondingresults in safety-critical scenarios.\n5.3.1. Comparison with Traditional RL Methods\nFirst, we analyze the performance comparison between CurricuVLM and traditional RL methods (SAC, PPO, andTD3) as shown in Fig. 4 and Tables 1-2. The top row in Fig. 4(a)-(e) demonstrates that in regular driving scenarios, ourmethod consistently outperforms all traditional RL baselines across key metrics. Specifically, while TD3 achieves thebest performance among traditional RL methods with an episode reward of 49.3 and a road completion rate of 72.9%,CurricuVLM further improves these metrics to 52.3 and 76.2%, respectively. More importantly, in terms of safetymetrics, our method reduces the crash rate to 16.0% compared to SAC's 18.3%, while maintaining a competitiveaverage speed of 9.52 m/s.\nThe advantages of CurricuVLM become more pronounced in safety-critical scenarios, as shown in Fig. 4(f)-(j).When traditional RL methods face challenging scenarios, their performance significantly degrades. As shown inTable 2, the crash rates increase to 30.5% for SAC, 32.0% for PPO, and 39.7% for TD3. In contrast, CurricuVLMmaintains a substantially lower crash rate of 25.1%. Additionally, our method achieves higher episode rewards of 48.9compared to TD3's 42.4, along with superior road completion rates of 73.4% compared to 65.2% achieved by TD3.These results suggest that our approach effectively prepares the agent for handling complex driving situations withoutcompromising basic driving capabilities. Furthermore, CurricuVLM demonstrates superior learning effectiveness,with a failure-to-success rate of 39.1% and a success-to-success rate of 73.5%. These results significantly outperformTD3, which exhibits a failure-to-success rate of 28.6% and a success-to-success rate of 64.3%. This indicates ourmethod effectively learns from failed scenarios while maintaining stable performance across successful ones.\n5.3.2. Comparison with Safe RL Methods\nNext, we compare CurricuVLM with safe RL methods including SAC-PID, TD3-Lag, and TD3-PID. As shownin the top row of Fig. 5, we observe that safe RL methods exhibit overly conservative behavior in regular driving.scenarios. According to Table 1, these methods achieve limited episode rewards of 7.57, 39.6, and -1.0, respectively,along with low road completion rates ranging from 6.48% to 46.9%. Although they maintain relatively low crashrates comparable to CurricuVLM, this safety comes at a substantial cost to driving efficiency, as reflected in their lowaverage speeds below 5.5 m/s and limited total distances traveled.\nThe limitations of safe RL methods become particularly evident when safety-critical scenarios are introduced.As shown in Table 2, their episode rewards further drop below 30. More importantly, these methods fail to maintainsafety despite their conservative nature, with crash rates increasing substantially to 30.4% for SAC-PID and 51.0% forTD3-Lag. This degradation can be attributed to their training process, which primarily focuses on maintaining safetymargins in regular driving conditions without exposure to safety-critical scenarios. This is particularly evident in theirconsistently poor learning effectiveness, with all failure-to-success rates below 8.5% in safety-critical scenarios, while"}, {"title": "5.3.3. Comparison with Imitation Learning Methods", "content": "We further compare CurricuVLM with imitation learning methods including GAIL, AIRL, SQIL, and BC, as shown in Fig. 6 and Fig. 7. For training these imitation learning algorithms, we collected 28K expert trajectories with100% success rate from the training scenarios. In Fig. 6(a)-(e), we observe that imitation learning methods achievemoderate performance in regular driving scenarios. According to Table 1, these methods obtain episode rewards rang-ing from 20.3 to 32.5 and road completion rates between 44.7% and 58.6%. The fundamental limitations of imitationlearning approaches manifest more clearly in safety-critical scenarios. As demonstrated in Table 2, their performance deteriorates significantly, with episode rewards dropping to between 18.9 and 29.8, and crash rates increasing to range from 27.8% to 38.5%. This degradation occurs because these methods struggle to generalize beyond the distribution of expert demonstrations, which only contain successful trajectories in regular driving conditions.\nDue to the different training paradigm, BC is trained for 100 epochs and its results are shown separately in Fig. 7.Despite having access to high-quality expert demonstrations, BC shows modest performance with an episode rewardof 29.7 and road completion rate of 58.6% in regular scenarios, which further decline to 27.4 and 53.2% respectivelyin safety-critical scenarios. The learning curves in Fig. 7 reveal that BC quickly converges after the initial trainingphase, suggesting limited generalization capability beyond the demonstrated behaviors. In contrast, CurricuVLMdemonstrates superior performance and adaptability through its curriculum learning approach. Rather than solelyrelying on expert demonstrations, our method actively explores and learns from diverse scenarios while maintaining safety awareness. This enables CurricuVLM to achieve substantially higher episode rewards and road completion rates while maintaining lower crash rates in both regular and safety-critical scenarios."}, {"title": "5.3.4. Comparison with Closed-loop Curriculum Learning Methods", "content": "Finally, we compare CurricuVLM with state-of-the-art closed-loop curriculum learning methods, CAT and CLIC, as shown in Fig. 8. In regular driving scenarios, both baseline methods demonstrate competitive performance. Particularly, CAT achieves strong navigation capabilities with high road completion rates, while CLIC maintains the lowest crash rates. However, CurricuVLM still outperforms these methods across key metrics including episode rewards and road completion rates while maintaining comparable safety levels. When tested in safety-critical scenarios, our method's advantages in handling complex driving situations become evident. Both CAT and CLIC experience notable performance degradation, especially in terms of safety metrics and road completion rates. This suggests that their curriculum generation strategies, while effective for regular driving conditions, may not adequately prepare the agent for more challenging scenarios. In contrast, CurricuVLM maintains robust performance across all metrics, demonstrating its superior ability to handle safety-critical situations. Moreover, CurricuVLM achieves higher failure-to-success and success-to-success rates in safety-critical scenarios compared to CAT and CLIC. These results validate the effective-ness of our VLM-based approach in identifying and addressing specific performance bottlenecks through personalized curriculum generation, leading to more robust and adaptable driving policies."}, {"title": "5.4. Ablation Studies", "content": "To systematically evaluate the contribution of each component in CurricuVLM, we conduct comprehensive abla-tion studies through four variant models and assess their performance in safety-critical testing scenarios. The variantsare designed to examine the impact of our key technical components:\n\u2022 W/o VLM Analysis: Instead of using VLM-based behavioral analysis, this variant directly utilizes the objecttrajectories from the Waymo Open Motion Dataset to generate scenarios targeting high-probability collisionpoints with the AV, removing the personalized aspect of scenario generation.\n\u2022 W/o Learned Prior: This variant replaces our DenseTNT-based trajectory generation approach with a rule-based approach that creates simplified adversarial trajectories through waypoint selection and Bezier curvefitting, testing the importance of realistic trajectory modeling."}, {"title": "5.5. Sensitivity Analysis", "content": "5.5.1. Impact of Vision-Language Model Selection\nThe performance of CurricuVLM may be sensitive to the choice of the underlying Vision-Language Model. Toquantify this sensitivity, we conducted experiments with four state-of-the-art VLMs: GPT-40,Llama-3.2-11B-Vision, Qwen2-VL-7B, and LLaVA-1.5-13B. Fig. 9 presents radar charts comparing their performance across multiple metrics, where all indicators are normalized to [0,1] with higher values indicating better performance. The results show that CurricuVLM-GPT andCurricuVLM-Llama exhibit comparable superior performance across all evaluation metrics, with their performance"}, {"title": "5.5.2. Analysis of Batch Size for Safety-Critical Event Analysis", "content": "We further investigate the impact of different batch sizes N in our safety-critical event analysis process on theperformance of CurricuVLM. As described in Section 4.2, the framework adopts a batch-wise analysis strategy byaccumulating N safety-critical events before initiating the GPT-40 analysis phase. Our experiments examine threedifferent batch sizes (N = 10, 20, and 30) to understand their effects on both regular and safety-critical scenarioperformance.\nFig. 10 illustrates how different batch sizes affect various performance metrics. In regular driving scenarios, asshown in Fig. 10(a)-(e), we observe that a batch size of N = 20 yields the best overall performance. With thissetting, the model achieves the highest episode reward, optimal total distance traveled, and best road completionrate. While this setting shows a slight increase in collision rate compared to N = 10, this marginal safety trade-off is compensated by significantly improved driving efficiency. This observation aligns with our framework's designprinciple of balancing safety and operational efficiency. The experimental results in safety-critical scenarios, as shownin Fig. 10(f)-(j), further validate the advantages of N = 20. A smaller batch size of N = 10 leads to overly frequentanalyses and more conservative behavior, resulting in suboptimal driving efficiency. Conversely, a larger batch sizeof N = 30 delays the behavioral pattern analysis, leading to compromised safety performance with elevated collisionrates of 0.35.\nThese findings demonstrate that the batch size in safety-critical event analysis significantly influences the frame-work's performance. An insufficient batch size may lead to premature pattern recognition and cautious behavior,while an excessive batch size might miss crucial behavioral patterns and delay necessary curriculum adaptations. Ourexperiments indicate that N = 20 achieves an optimal balance, allowing sufficient event accumulation for meaningfulpattern recognition while ensuring timely curriculum updates."}, {"title": "5.6. Compatibility with Different RL Algorithms", "content": "To demonstrate the versatility of our proposed CurricuVLM framework, we evaluate its performance when in-tegrated with different RL algorithms, specifically SAC and PPO, in addition to the default TD3 implementation.Fig. 11 presents a comprehensive comparison"}]}