{"title": "Towards Best Practices for Open Datasets for LLM Training", "authors": ["Stefan Baack", "Stella Biderman", "Kasia Odrozek", "Aviya Skowron", "Ayah Bdeir", "Jillian Bommarito", "Jennifer Ding", "Maximilian Gahntz", "Paul Keller", "Pierre-Carl Langlais", "Greg Lindahl", "Sebastian Majstorovic", "Nik Marda", "Guilherme Penedo", "Maarten Van Segbroeck", "Jennifer Wang", "Leandro von Werra", "Mitchell Baker", "Julie Beli\u00e3o", "Kasia Chmielinski", "Marzieh Fadaee", "Lisa Gutermuth", "Hynek Kydl\u00ed\u010dek", "Greg Leppert", "EM Lewis-Jong", "Solana Larsen", "Shayne Longpre", "Angela Oduor Lungati", "Cullen Miller", "Victor Miller", "Max Ryabinin", "Kathleen Siminyu", "Andrew Strait", "Mark Surman", "Anna Tumad\u00f3ttir", "Maurice Weber", "Rebecca Weiss", "Lee White", "Thomas Wolf"], "abstract": "Many Al companies are training their large language models (LLMs) on data without the permission of\nthe copyright owners. The permissibility of doing so varies by jurisdiction: in countries like the EU and\nJapan, this is allowed under certain restrictions, while in the United States, the legal landscape is more\nambiguous. Regardless of the legal status, concerns from creative producers have led to several\nhigh-profile copyright lawsuits, and the threat of litigation is commonly cited as a reason for the recent\ntrend towards minimizing the information shared about training datasets by both corporate and public\ninterest actors. This trend in limiting data information causes harm by hindering transparency,\naccountability, and innovation in the broader ecosystem by denying researchers, auditors, and impacted\nindividuals access to the information needed to understand Al models.\nWhile this could be mitigated by training language models on open access and public domain data, at the\ntime of writing, there are no such models (trained at a meaningful scale) due to the substantial technical\nand sociological challenges in assembling the necessary corpus. These challenges include incomplete\nand unreliable metadata, the cost and complexity of digitizing physical records, and the diverse set of\nlegal and technical skills required to ensure relevance and responsibility in a quickly changing landscape.\nBuilding towards a future where Al systems can be trained on openly licensed data that is responsibly\ncurated and governed requires collaboration across legal, technical, and policy domains, along with\ninvestments in metadata standards, digitization, and fostering a culture of openness.\nOn June 11, 2024, Mozilla and EleutherAl convened 30 scholars and practitioners to create normative\nprinciples and technical best practices for creating openly licensed LLM training datasets. Based on that", "sections": [{"title": "1. Introduction", "content": "Today's Al systems depend on the data used to train large language models (LLMs), making dataset\ntransparency critical for accountability and innovation. While Al companies used to be more open about\ntheir training data, as seen with Google's T5 or Meta's LLAMA 1, little is known about the datasets\nbehind the most popular models from companies like OpenAl, Anthropic, Google, and Meta today. Over\nthe past year, Al companies have faced heavy criticism, particularly from literary and creative\ncommunities, over perceived exploitative data practices, leading to multiple high-profile copyright\nlawsults. Regardless of these lawsuits' legal merits, they have become one of several factors\ndiscouraging companies from disclosing their data sources and governance practices.\nMeanwhile, there is an ecosystem of open LLM developers startups, researchers, and nonprofit\norganizations who are increasing transparency in Al training data and promoting open access to those\ndatasets. In June 2024, Mozilla and EleutherAl convened 30 scholars and practitioners from prominent\nopen-source Al startups, nonprofit Al labs, and civil society organizations working on open access and\nopenly licensed datasets for the Dataset Convening. After analyzing case studies from three of the\nleading open datasets (EleutherAl's forthcoming Common Pile, Pleias' Common Corpus and\nYouTube-Commons), the group met to discuss the most pressing challenges and opportunities around\ncreating open-access and openly licensed LLM training datasets. The group identified seven principles to\nguide the creation of these datasets:\n1. Foster a competitive LLM ecosystem\n2. Enable accountability and transparency through reproducibility\n3. Minimize harms and enable preference signals\n4. Support and improve diversity\n5. Strive for reciprocity\n6. Work with other like-minded actors in this space\n7. Preserve data for the long term\nThe group also identified the challenges and pitfalls facing organizations seeking to build these datasets.\nThis paper captures those insights, including emerging normative and technical recommendations for the\ncommunity. The Dataset Convening was part of a longer series of events co-hosted by Mozilla, inspired\nby (and including) the Columbia Convening (February 2024) which developed a framework for openness"}, {"title": "2. Terminology", "content": "There are varying definitions of dataset openness in the Al community. In this paper, we focus on three\ntypes of openness in Al data:\n\u2022 Openly licensed dataset\u00b9: A dataset and its components can be freely used, modified, and shared\nby anyone for any purpose (following the Open Knowledge Foundation's Open Definition for data\nand content).\n\u2022 Downloadable/open-access dataset: Dataset is available to freely download, with no claim\nabout license compliance.\n\u2022 Replicable dataset: Data sources and processing steps are disclosed, such that an independent\nparty can produce a substantially similar (albeit not identical) dataset, or what the Open Source Al\nDefinition calls \u201ca substantially equivalent system.\u201d This assumes data sources are widely\naccessible (e.g., not internal data or data accessed through private agreements)."}, {"title": "3. Challenges and Guiding Principles", "content": "Open dataset builders face a myriad of challenges including legal, technical, operational and more.\nShared principles help articulate common goals and strategies and navigate resolutions as the landscape\nchanges."}, {"title": "3.1. Challenges", "content": "Building and releasing an open access dataset can be a complex technological and legal problem that\nrequires collaboration and expertise. The collection, identification, and validation of a large-scale openly\nlicensed dataset can require substantial amounts of manual work, consultations with legal experts, and\ntechnological skill\ndata. Laws can also change over time, resulting in\na web of more complicated interlocking requirements.\n\u2022 Relevant metadata is incomplete. What constitutes a \u201cwork\u201d under copyright law does not\nnecessarily correspond to one dataset document, electronic file, or HTML tag. This can\nsignificantly limit the usefulness of existing license information. For example, when filtering the\nCommon Crawl, it is easy to determine that a website links to a CC-BY 4.0 license, and therefore\ncontains some sort of CC-BY 4.0 statement. However, there is currently no automated way of\ndetermining which asset on the website that license covers. This leads to false positives if, for"}]}