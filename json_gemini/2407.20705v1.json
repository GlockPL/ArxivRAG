{"title": "PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning", "authors": ["Muhammad Anwar Ma'sum", "Mahardhika Pratama", "Savitha Ramasamy", "Lin Liu", "Habibullah Habibullah", "Ryszard Kowalczyk"], "abstract": "Federated Class Incremental Learning (FCIL) is a new direction in continual learning (CL) for addressing catastrophic forgetting and non-IID data distribution simultaneously. Existing FCIL methods call for high communication costs and exemplars from previous classes. We propose a novel rehearsal-free method for FCIL named prototypes-injected prompt (PIP) that involves 3 main ideas: a) prototype injection on prompt learning, b) prototype augmentation, and c) weighted Gaussian aggregation on the server side. Our experiment result shows that the proposed method outperforms the current state of the arts (SOTAs) with a significant improvement (up to 33%) in CIFAR100, MiniImageNet and TinyImageNet datasets. Our extensive analysis demonstrates the robustness of PIP in different task sizes, and the advantage of requiring smaller participating local clients, and smaller global rounds. For further study, source codes of PIP, baseline, and experimental logs are shared publicly in https://github.com/anwarmaxsum/PIP.", "sections": [{"title": "1 INTRODUCTION", "content": "Federated learning (FL) offers a collaborative approach for many clients to produce a shared global model while protecting their data privacy [26] [17] [32]. FL has recently sparked a great deal of academic interest and achieved outstanding success in various application areas, including medical diagnosis [15], autonomous vehicle [12], and wearable technology [4]. However, the majority of FL methods are designed for a static application scenario, assuming the target classes are fixed and known in advance. In real-world applications, the data are dynamic, allowing local clients to access unseen target classes online.\nExisting studies have addressed dynamic data challenges in FL through Federated Class Incremental Learning (FCIL) where each local client gathers training data continually according to their continuous observation of the environment. In contrast, new clients with unforeseen classes are always welcome to join the FL training [8] [9] [41]. The clients have to cooperatively train a global model that continually learns new classes while maintaining its capability to recognize the previous classes. Despite its capability to learn new classes, the global model tends to lose its knowledge of previous classes known as catastrophic forgetting. Therefore, FCIL calls for answers on how to handle catastrophic forgetting in a dynamic collaborative continual learning, while preserving data privacy. In addition, the clients may carry non-independently and identically distributed (non-i.i.d.) data with imbalance classes.\nThe current FCIL state-of-the-art (SOTA) i.e. GLFC[9] and LGA[8] train and share whole backbone parameters resulting in a large number of parameters (11.3M) to train that requires a longer training time, and a high communication cost (61.7MB) as shown in Table 1. In addition, in the case of client-server limited communication costs e.g. due to limited bandwidth, this approach is forced to utilize a smaller (more shallow) model to reduce the shared parameter size. Second, in the current SOTAs, the clients privately share perturbed images with the central server for the aggregation process. Besides its inefficient size (16.5MB), sharing perturbed images may violate data privacy principles since perturbation doesn't guarantee information leakage. Furthermore, this mechanism can't answer the data openness problem, where the data is only open for a client at a specific moment. These intriguing gaps motivate us to develop a more efficient yet more effective approach to the FCIL problem, where a client trains and shares as small parameters as possible but produces a highly accurate global model without sharing any (perturbed) samples.\nIn this study, we propose a new approach named federated prompt for the FCIL problem that is implemented in our proposed baselines and our proposed method named prototype-injected prompt (PIP). In our proposed approach, a client trains and shares only a"}, {"title": "2 RELATED WORKS", "content": "a). Class Incremental Learning (CIL): Prompt-based approach e.g. L2P [39], DualPrompt [38], CODA-Prompt [34] offers a break-through solution for CIL by training only small amounts of parameters called prompt for down-streaming tasks sequence, while the backbone model which contains the biggest parameter numbers stays frozen. This approach reduces the training time and offers utilization of a more complex backbone model e.g. ViT instead of CNN. The rehearsal approach e.g. ICARL [30], EEIL, [7], GD [28], DER++ [6], trains exemplars (memory) from the previous task joined with current task samples to minimize model forgetting on previous tasks. This approach doesn't work well if the memory samples are not available. The bias correction approach e.g. BiC [40] and LUCIR [13] enhances the rehearsal approach by creating a task-wise bias layer to help the model achieve stability-plasticity balance in compensation to add extra parameters to be trained. The regularization approaches adaptively tune the base learner parameter to accommodate the previous task and current task e.g. EWC [18], MAS [2], LWF [23], DMC [44]. The regularization has the advantage that It works on memory-free CIL but on the contrary, it is outperformed by rehearsal and bias correction approaches if the memory is available. Prompt-based approach outperforms the other three approaches despite requiring no memory, but not yet been proven effective in a distributed (federated) setting.\nb). Federated Class Incremental Learning(FCIL): The recent study on FCIL problem e.g. FedWeIT[41], GLFC [9], and LGA [8] strives to achieve an optimal global model by aggregating locally trained models sent by the clients. The current SOTAs are proven to be more effective than combining FedAvg [26] and class incremental learning approaches such as ICARL and BiC. However, as emphasized in Table 1, the current SOTAs train and share all backbone parameters, resulting in a less efficient training time and high communication costs. In Addition, the SOTAs assume that a client saves several exemplars as local memory and shares perturbated images with the server which is not always applicable in real applications. The other study i.e. TARGET [42] utilizes a synthetic dataset instead of saving exemplars from the previous tasks to train the whole backbone network. TARGET is proven to be more effective than Fed-LWF, Fed-EWC, and FedWeIT[41] but still outperformed by LGA and GLFC. Another approach i.e. FedCIL [29] uses a locally trained generative model i.e. ACGAN [27] to generate fake samples in the aggregation process. Despite its better performance than the combination of FedAvg or FedProx [20] with ACGAN, DGR[31] or LWF-2T [36] this method requires higher training time both in local and server-side and higher communication cost due to sending the generative model along with the backbone. To tackle the weaknesses above, our approach uses memory-free prompt learning for local training with the frozen backbone to achieve an efficient yet powerful local model, then aggregates the prompt and prototypes to obtain a generalized global model with low communication cost."}, {"title": "3 PRELIMINARIES", "content": "3.1 Problem Formulation\nClass incremental learning (CIL) problem is defined as a learning problem of a sequence of fully supervised learning tasks  {Tt}t=1T where T represents the number of consecutive tasks, the value of T is unknown to the model before CIL process and can be infinite. Each task carries  Nt pairs of training samples Tt=xi,yNt  i=1 where xi\u2208Xt  denotes input image and yi\u2208yt  denotes its corresponding class label. Each task carries the same image size but possesses disjoint target classes to the other tasks. Suppose that"}, {"title": "4 PROPOSED METHOD: PROTOTYPE-INJECTED PROMPT (PIP)", "content": "Our proposed method, as visualized in Figure 1 performs prompt learning on each client to handle local catastrophic forgetting (section 4.1), handling non-i.i.d distribution by applying shared prototype injection(section 4.2), handling class-imbalance by performing prototypes augmentation (section 4.3), and finally improving global model generalization by using weighted aggregation (section 4.4).\nThe uniqueness of our method is that we utilize prompt and prototype as the shared knowledge between clients and the central server. Second, we propose a prototype injection mechanism in local training to improve local model generalization. Third, we propose a weighted aggregation on the server side. Our proposed method is distinct from prompt-based methods e.g. Fed-CPrompt[3] and FCILPT[24] that shared and trained prompts only. Our proposed method is also distinguished from prototype-based FL methods e.g. FedProto [35] and CCVR [25] shared only prototypes to refine the local model or use the prototype as classifiers. Besides, FedProto and CCVR are developed for federated learning only, meaning the methods didn't address the catastrophic forgetting issue."}, {"title": "4.1 Handling Local Catastrophic Forgetting via Prompt Learning", "content": "On a round r \u2013 th of t th task, each client  Sl optimizes its local prompt  pl and head layer parameter  \u03d5l using its available training samples Tltr, Please note that  pl can be any prompt structure as mentioned in our baselines e.g.in L2P, DualPrompt, or another prompt structure. Given a pre-trained ViT backbone  f with M Multi head Self-Attention (MSA), where h(i), i = 1, 2..., M represents the input for i \u2013 th MSA layer, suppose that a local client wants to attach a latest updated prompt pt into the i \u2013 th MSA layer, the prompt instance prit transform feature h(i) via prompt function as defined in equation 1.\nht=fprompt(prit,h(i))\n(1)\nNote that hi is the extension of h, a sequence-like parameter produced by the ViT embedding layer for the i - th MSA layer. Prompt function fprompt can be implemented by using prompt tuning (fprompt) [19] or prefix (fprompt) tuning [22] approaches as defined in equation 2 and 3.\nfprompt(pt,h(i))=MSA([pt;h(i)],[pt;h(i)],[pt;h(i)])\n(2)\nfprompt(pt,h(i))=MSA(h(i),[pt;h(i)],[pt;h(i)])\n(3)\nMSA(q,k,v)=(\u2295m h(i))Wo\nwhere  h(i)=Attention(hi,k,i,v)Wo,Wm,Wk,Wv are the projection matrices, and m is number of head, \u2295 represents concatenation function, and in ViT  h=hi=h(i)=h(i)=h(i)\u2208RD. Given a pair of samples (xl1, yl1) \u2208 Tltr , each client Sl trains its latest updated parameters  pl and \u03d5l using L1+ as defined in equation 5, where L represents cross-entropy loss, Lm represents matching loss between sample xl1 and key  kl , \u03bb represents a constant factor,  fpi  represents prompt function, and f\u03c6l represents of l \u2013 th client.\nL1+=L(fort(fprit(xl1),yl1))+\u03bbLm(xl,kl),(xl1,yl1)\u2208Tltr\n(5)\npl\u2190pl\u2212\u03b1\u2207L1(6)\n\u03d5l\u2190\u03d5l\u2212\u03b1\u2207L1\nThe client's parameters are updated using equation 6 where  \u03b1 represents learning rate and L1 represents gradient with respect to L1."}, {"title": "4.2 Shared Prototype Injection: What, Why and How?", "content": "We define a prototype set on the t th task of a client Sl as Zltr={zlcl|cl\u2208Cl},zlcl\u2208RD is the prototype for class cl \u2208 Cl , Cl is the available classes in Tltr , and D is the embedding dimension. Assuming that the prototype follows a Gaussian distribution zlcl ~N(\u03bclc,\u03c3lc2ID) and the prototype is considered as D disjoint uni-variate distribution, then we have zlcl ~N(\u03bclic,\u03c3li2) where \u03c3li2\u2208Rlcl,i\u2208{1,2..D}, ID  is identity matrix. Suppose that Tlcc={(xlci,ylci)\u2208Tlcl,ylci=cl}  is the samples of class-cl in Tltr and Tlcl is the number of samples in Tlcc, we compute the prototype zlcl properties by Eq. 7 and 8.\n\u00b5lc=1|Tlc|\u2211|Tlc|i=1fort(xlci),xlci\u2208Tlcc\n(7)\n\u03c3lc2=1|Tlc|\u2211|Tlc|i=1fort(xlci)\u2212fprit(xlci))2,xlci\u2208Tlcc\n(8)\nDue to non-i.i.d data between clients, FCIL satisfies Tltr\u2282(Tt=\u222aLl=1Tltr ) and \u2200l,l\u2032\u2208{1..L},l\u2260l\u2032\u21d2(Tltr\u2260Tl\u2032tr )\u2227(Cltr\u2260Cl\u2032tr,) . It implies a client only optimize  pl and \u03d5l with regard to Tltr but not yet to Tt. The client Sl only learns Cltr but not C\u2032ltr=Ct\u2212Cltr  classes that exist in Ttr but not in Tltr. Meanwhile, we can't afford to share any exemplar sample (x, y) due to data privacy. Aggregating the prompts and head doesn't guarantee optimal global model (pGtr,\u03d5G) for Tt since in the next round, the participating clients and their available data may be different from the current rounds' \u2200r,r\u2032\u2208{1..R},\u2200l\u2208{1..L},r\u2260r\u2032\u21d2(Sltr\u2260Sltr\u2032\u2217)\u2227(Tltr\u2260Tl\u2032tr\u2032\u2217) . Furthermore, training in too many rounds leads to catastrophic forgetting.\nTo handle this challenge, we propose prototype sharing between clients and the central server, where the server collects all clients'  Cl prototype  {Zltr}Ll=1 then distributes global prototype Ztr=zltr=\u222aLl=1Zltr. The shared prototype set Ztr ensures each client learns via Tt\u222a(Ztr,Ct)\u2248Tt, therefore each client has chances to learn all classes Ct in Tt. Besides, the prototype set Ztr has a small size in comparison to prompt  pl or head layer  \u03d5l where  zlcl\u2208Ztr  has the size of 1\u00d7D , where D is the embedding dimension, and It doesn't contain any raw information as contained in an exemplar sample.\nNow each client can enhance its local training by injecting the shareable prototype set Zltr into its training process by considering"}, {"title": "4.3 Handling Class Imbalance via Prototype Augmentation", "content": "We can simply assign zlcl \u2208 Zltr by \u03bc\u03b5 to generate a single prototype for class-cl. However, to handle classes imbalance between locally available classes and unavailable classes that are represented by the shared prototypes. we enrich the prototypes by using an augmentation. Suppose that  xlc1 is the sample for class c1 \u2208 Cltr , zl2\u2208Zltr is the prototype of class c2\u2208Cltrc=Ct\u2212Cltr,c1  is locally available class, and c2 is locally the unavailable class in client-l, then we have |xlc1>1 , while |zl2|=1 . The prototype augmentations create artificial prototypes that satisfy |zl2|\u2248|xlc1|  as defined in equation 11 to generate m augmented prototypes for class-c based on Gaussian distribution zlaug  ~N(\u03bclc,\u03c3lc2), and \u03b2 is a random value in (0, 1) range.\nzlc=zlcl\u222a{zaug}, where\n(11)\nzaug=\u03bclc+\u03b2\u03c3l,m\u22651"}, {"title": "4.4 Server Weighted Aggregation", "content": "We proposed weighted Gaussian aggregation on the server side to improve global model generalization. The aggregation treats clients' contribution to global aggregation proportionally based on their participation and their training sample size following best practice where a model that learns more produces more convergent weight. We consider clients to learn their local data and then produce Gaussian distributed local parameters. We define \u03c9l=pltr Tltr  as the weight of a client-l on the t-th task, where pl is the total of client-l participation until t \u2013 th task and Tltr is the number of samples in Tltr. Given {(pltr,\u03d5ltr,Zltr)}Ll=1 is a set of locally optimized parameters by selected local clients {Sl}Ll=1 on the r \u2013 th of t \u2013 th task, then the global parameters (pGtr,\u03d5Gtr) and  Ztr are computed by Gaussian-based weighted aggregation as We define in Eq. 12-15. Equation The derivation of the proposed weighted aggregation in presented in our supplemental document.The pseudo-code of PIP is presented in algorithm 1, while the pseudocode of our proposed baselines is presented in our supplemental document.\npGtr=\u03a3Ll=1(pltr\u03c9l)\u03a3Ll=1\u03c9l\n(12)\n\u03d5Gtr=\u03a3Ll=1(\u03d5ltr\u03c9l)\u03a3Ll=1\u03c9l\n(13)"}, {"title": "5 THEORETICAL ANALYSIS", "content": "Let \u03b8=(p,\u03d5) is the trainable parameters and F(\u03b8)=E[L1+(T;\u03b8)]= E[L1+(T; (p, \u03c6))] is the expected loss function, k, E, R, and Ls is local iteration, local epoch, global round, and number of selected local clients respectively. We follow L-smooth and  \u00b5-strongly convex F, random uniformly distributed batches, G-bounded uniformly"}, {"title": "6 EXPERIMENT RESULTS AND ANALYSIS", "content": "6.1 Experimental Setting\nDatasets: Our experiment is conducted using three main benchmarks in FCIL i.e. split CIFAR100, split MiniImageNet, and split TinyImageNet. The CIFAR100 and miniImageNet datasets each contain 100 classes while TinyImagenet is a dataset with 200 classes. We follow settings from [9] and [8] where the dataset is split equally into all tasks. In our main numerical result, The dataset is split into 10 tasks i.e. 10 classes per task for CIFAR100 and MiniImageNet, and 20 classes per task for the TinyImageNet dataset. In our further analysis, we investigate the performance of the proposed methods in different task sizes e.g. T=5 and T=20.\nBenchmark Algorithms: PIP is implemented in two version algorithms i.e. PIP-L2P and PIP-DualP with L2P and DualP prompt structure respectively, PIP-L2P and PIP-DualP are compared with 10 state-of-the-art algorithms: LGA [8], TARGET [43], GLFC[9], AFC[16]+FL, DyTox[11]+FL, SS-IL[1]+FL, GeoDL[33]+iCaRL[30]+FL,"}, {"title": "6.2 Numerical Results", "content": "The numerical result of the consolidated algorithms is shown in tables 2 and 3. Except to Fed-CPrompt, The baseline method (Fed-DualP) already achieves higher average accuracy (Avg) than the SOTA methods with 1 \u2013 13% improvement in accuracy. Fed-DualP also experiences a lower performance drop (PD) (19 - 27%) compared to the SOTA methods (\u2265 26%) except in the CIFAR100 dataset vs. LGA. Fed-L2P achieves higher performance than SOTAs in Mini-ImageNet and TinyImageNet datasets with \u2265 11% gap, but lower performance in the CIFAR100 dataset. The proposed method (PIP-DualP) achieves the highest accuracy with \u2265 10% gap compared to the baseline method, and \u2265 14% gap compared to the competitor methods (except Fed-CPrompt). The proposed method also achieves the lowest performance drop with (10 - 13%) gap compared to the"}, {"title": "6.3 Forgetting Analysis", "content": "Table 4 shows the average forgetting of the consolidated methods in each task T. The table shows that our proposed method (PIP-DualP) achieves smaller average forgetting than existing SOTAs i.e. LGA and Fed-CPrompt with a significant gap i.e. 2.7% and 9.3% margin respectively. Fed-DualP achieves a comparable average forgetting with TARGET, but looking at the trend, TARGET forgetting is increasing along with the number of tasks, while PIP-DualP forgetting is relatively stable. Please note that TARGET achieves lower average accuracy than PIP-DualP with a 64% gap. Our baselines i.e. Fed-DualP and Fed-L2P archives have lower average forgetting than PIP-DualP despite achieving lower accuracy than PIP-DualP with a huge gap i.e. (> 13%). This shows that the baselines achieve better stability (old task accuracy) but in exchange struggle to achieve plasticity (new task accuracy)."}, {"title": "6.4 Ablation Study", "content": "We conducted an ablation study to investigate the contribution of each component of the proposed method. The result is summarized in Table 5, while the detailed result is presented in our supplemental document. The result shows that the prototype and augmentation contribute the most to the improvement of the performance as shown by the performance difference of configurations E vs. F (12%), and G vs. H (16%). The weighted aggregation improves performance up to 1% as shown by the performance difference of PIP and configuration F. The head layer aggregation also plays an important role in the proposed method as shown that the absence of this component decreases performance with \u2265 6% margin. The absence of two components e.g. prototype and head aggregation"}, {"title": "6.5 Further Analayis", "content": "a) Different task size: We evaluate the performance of the proposed method compared to the competitor methods in different task sizes i.e. T=5 and T=20 to further investigate the robustness of the proposed method. Figure 2 summarizes the performance of the consolidated methods in CIFAR100, MiniImageNet, and TinyImageNet with T=5 (upper figures) and T=20 (bottom figures). The detailed numerical result is presented in our supplemental document.. Both in T=5 and T=20 settings, PIP-DualP achieves the highest performance almost in every task in all configurations. It achieves a slightly lower performance than PiP-L2P in the last 3 tasks of CIFAR100 with T=5. Besides, all figures show that the proposed method has gentle slopes compared to the baseline and competitor methods. It shows that the proposed method experiences the lowest performance drop from tth to t + 1th task. It confirmed the robustness of the proposed method in different task-size settings. The baseline (Fed-DualP) method achieves better accuracy than the competitor methods in all 6 settings, except in CIFAR100 with the T=5 setting. In CIFAR100 with the T=5 setting, the baseline method achieves higher performance in task-1 and task-5, but lower performance in task-3, and comparable performance in task-2 and task-4. It shows the promising idea of the federated prompt-based approach for the FCIL problem.\nb) Small local clients: We evaluate the performance of the proposed method in smaller selected local clients to advance our investigation of the robustness of the proposed method on smaller selected local clients. This simulates cross-device federated learning where in a round only a small portion of registered clients participate in the federated learning process. In our experiment with 30"}, {"title": "6.6 Complexity and Running Time Analysis", "content": "Following the pseudo-code in Algorithm 1, PIP generates prototypes when its prototype set is empty after a local epoch of a round-r (line 21), augment the prototypes in each local epoch (23), and updates the prototypes after local epochs (line 26-27). Knowing that generating prototypes from Tltrcosts O(1), augmenting the\nO(PIP)=O(1)+T.RT.(O(clients)+O(server))\n(17)\nO(PIP)=O(1)+T.RT.(L.O(1client)+O(server))\n(18)\nO(PIP)=O(1)+T.RT.(L.O(1client)+O(1))\n(19)\nO(PIP)=O(1)+T.RT.L.O(E.(\u2211Bb=1Nl+Nb)+O(Nbl)\n(20)\n+O(1))+O(T.RT)\nSince we have \u2211Bb=1 Nlb=Nl , then we have\nO(PIP)=O(1)+T.RT.L.O(E.(Nl+N)+O(Nl)\n(21)\n+O(1))+O(T.RT)\nO(PIP)=O(1)+T.RT.L.O(E.(N+N)\n(22)\n+O(1))+O(T.RT)\nO(PIP)=O(1)+T.RTL.O(E.1(N)+1+1Nl)+(23)\n+O(T.RT)\nO(PIP)=O(T.RTLENl)+O(T.RTLNl)\n(24)\n+O(T.RTL)+O(T.RT)\nSubstituting the equalities in the previous definition that RT=R/T and Nl=Tl=T the complexity of PIP will be\nO(PIP)=O(T.RT.L.E.N)+O(T.RT.L.N)\n+O(T.RT.L)+O(T.RT)\n(25)\nO(PIP)=O(R.L.E.Nl)+O(R.L.Nl)+O(R.L)+O(R)\n(26)\nO(PIP)=O(R.L.E.Nl)\n(27)\nSince N\n\nO(PIP)=O(R.L.Nl)\n(28)\nThe baseline's complexity is presented in the supplemental document. Our complexity analysis shows that both the baseline method and our proposed method have the same complexity i.e. O(R.L.Nl) where R is the number of global rounds, L is the number of participating local clients in each round, and Nl is the size of the training data in each client. Table 7 summarizes the training time of the consolidated method in three datasets with T=10. The table shows that the proposed method requires lower training time and far lower communication cost than the current competing SOTAs i.e. LGA and GLFC in all datasets. The training time is higher than the baseline training time because in our proposed method there are"}, {"title": "7 CONCLUDING REMARKS", "content": "In this paper, we propose a new approach named prompt-based federated learning, new baselines named Fed-L2P and Fed-DualP, and a novel method named prototype-injected prompt (PIP) for the FCIL problem. PIP consists of three main ideas: a) prototype injection on prompt, b) prototype augmentation, and c) weighted Gaussian aggregation on the server side. Our experimental result shows that the proposed method outperforms the current SOTAS with a significant gap (up to 33%) in CIFAR100, MiniImageNet, and TinyImageNet datasets. Our extensive analysis demonstrates the robustness of our proposed method in different task sizes, smaller participating local clients, and smaller global rounds. Our proposed method has the same complexity as the baseline method and experimentally requires shorter training time than the current SOTAS. In practice, our proposed method can be applied in both cross-silo and cross-domain federated class incremental learning. Our future work is directed to federated few-shot class incremental learning where each client only holds a few samples for each task."}, {"title": "8 ACKNOWLEDGEMENT", "content": "Muhammad Anwar Ma'sum acknowledges the support of Tokopedia-UI Centre of Excellence for GPU access to run the experiments. Savitha Ramasamy acknowledges the support of the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-RP-2021-027)"}, {"title": "A DERIVATION OF WEIGHTED AGGREGATION", "content": "Suppose that we have n samples of an observation xi with the weight of wi. The we mean and variance as:\n\u03bc=\u2211ni=1wiwiXi\n(A29)\n\u03c32=1\u2211ni=1wi(xi\u2212\u03bc)2\n(A30)\nOr we have\n\u03a3ni=1wi\u03c32=\u2211ni=1wi(xi\u2212\u03bc)2\n(A31)\n\u03a3ni=1wi\u03c32=\u2211ni=1wi(xi2\u2212wi\u03bc2)\n(A32)\nthat equal\n\u2211ni=1wi\u03c32=\u2211ni=1wiwiXi2\u2212\u2211ni=1wi\u03bc2\n(A33)\nIf we have another m observation, then we have\n\u03a3m+ni=1wi\u03c32=\u2211m+ni=1wi(xi2\u2212wi\u03bc2)\n(A34)\n\u03a3m+ni=1wi\u03c32=\u2211m+ni=1wiwiXi2+\u2211m+ni=1wi\u03bc2\n(A35)\n\u2211m+ni=1wi\u03c32=(\u2211ni=1wi(\u03c31:n2)+\u2211m+ni=n+1wi(\u03c3n+1:m2)\n(A36)\nTherefore:\n\u03c32=\u2211ni=1wi(\u03c31:n2)\u2211m+ni=1wi+\u2211m+ni=n+1wi(\u03c3n+1:m2)\u2211m+ni=1wi\n(A37)\n\u03c32=\u2211ni=1wi(\u03c31:n2)1:n\u2211m+ni=1wi+\u2211m+ni=n+1wi(\u03c3n+1:m2)n+1:m\u2211m+ni=1wi\u2212\u03bc2\n(A38)\nThe derivation above shows that if we have two weighted Gaussian distributions e.g. X1 ~ N(\u00b51, \u03c32) and X2 ~ N(\u00b52, \u03c32) with total weight W1=\u2211X1i=1wi and W2=\u2211X2j=1wj respectively, then the aggregated distribution will be:\n\u00b5\u2217=(\u00b51.W1+\u00b52.W2)W1+W2\n(A39)\n\u03c3\u22172=((\u00b521+\u03c321).W1+(\u00b522+\u03c322).W2)W1+W2\u2212\u00b5\u22172\n(A40)\nGeneralizing equations above into N observations i.e. X1~N(\u00b51, \u03c321),X2 ~ N(\u00b52, \u03c322),...XN ~ N(\u00b5N, \u03c32N) with total weight W1, W2,... WN  respectively. then the aggregated distribution will be:\n\u00b5\u2217=\u2211Ni=1(\u00b5i.Wi)\u2211Ni=1Wi\n(A41)\n\u03c3\u22172=\u2211Ni=1(\u00b5i2+\u03c3i2).Wi\u2211Ni=1Wi\u2212\u00b5\u22172\n(A42)"}, {"title": "B BASELINE ALGORITHM", "content": "We present the detailed algorithm of our proposed baseline in Algorithm 2."}, {"title": "C DETAILED THEORETICAL ANALYSIS", "content": "Let \u03b8=(p,\u03d5) is the trainable parameters and F(\u03b8)=E[L1+(T;\u03b8)]= E[L1+(T; (p, \u03c6))] is the expected loss function, k, E, R, and Ls is local iteration, local epoch, global round, and number of selected local clients respectively. Please note that in this analysis, Ls denotes the number of selected local clients, while L \u2265 1 denotes a constant for L-smooth coefficient. We adopt the following assumptions adapted from SGD optimization convergence analysis [5] and FedAvg convergence analysis [21].\nAssumption 1: F1, ...F1, ..., FLs  are all L-smooth: for all \u03b8 and \u03b8', F1(\u03b8)\u2264F1(\u03b8\u2032)+(\u03b8\u2212\u03b8\u2032)T\u2207F1(\u03b8)+L2||\u03b8\u2212\u03b8\u2032||2.\nAssumption 2: F1, ...F1, ..., FLs  are all  \u00b5-strongly convex: for all \u03b8 and \u03b8', F1(\u03b8)\u2264F1(\u03b8\u2032)+(\u03b8\u2212\u03b8\u2032)T\u2207F1(\u03b8)+\u00b52||\u03b8\u2212\u03b8\u2032||2.\nAssumption 3: Let k be the random uniformly sampled from l-th local data at k \u2013 th iteration. The variance of stochastic gradients in each client is bounded by: E[||\u2207F1(\u03b8,k)\u2212\u2207F1(\u03b8)||2]\u2264\u03c32l for l=1,2,...,Ls\nAssumption 4: The expected squared norm of stochastic gradients in each client is bounded by: E[||\u2207F1(\u03b8,k)||2]\u2264G2 for all l= 1,2,...,Ls  and  k = 1, 2, ...., K where K \u2208 N.\nAssumption 5: \u2211Kk=1\u03b1kl = \u221e and \u2211Kk=1(\u03b1kl )20 .C.1 Proof of Theorem 1"}, {"title": "D COMPLEXITY ANALYSIS", "content": "In this section", "Tt=1Ntrl=Nl": "R is the total rounds of federated learning", "Complexity": "Following the pseudo-code in Algorithm 2 then we have\nO(Baseline)=O(1)+T.RT.(O(clients)+O(server))\n(A80)\nO(Baseline)=O(1)+T.RT.(L.O(1client)\n+O(server))\n(A81)\nO(Baseline)=O(1)+T.RT.(L.O(1client)+O(1))\n(A82)\n\u03a3Bb=1Nbl+O(1))\nO(Baseline)=O(1)+T.RT.L.O(E.\n+O(T.RT)\n(A83)\n\u03b2\u03a3Bb=1Nbl)+O(T.RT.L)+O(T.RT)\nO(Baseline)=O(1)+O(T.RT.L.E.\n(A84)\nO(Baseline)=O(T.RTL.E.Ntl)+O(T.RTL.Ntl)\n+O(T.RTL)+O(T.RT)\n(A85)\nFrom the definition above that B\u2211b=1 Nlb= Ntl, RT = R"}]}