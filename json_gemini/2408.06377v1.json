{"title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data", "authors": ["Donghai Fang", "Fangfang Zhu", "Dongting Xie", "Wenwen Min"], "abstract": "With the rapid advancement of Spatial Resolved Transcriptomics (SRT) technology, it is now possible to comprehensively measure gene transcription while preserving the spatial context of tissues. Spatial domain identification and gene denoising are key objectives in SRT data analysis. We propose a Contrastively Augmented Masked Graph Autoencoder (STMGAC) to learn low-dimensional latent representations for domain identification. In the latent space, persistent signals for representations are obtained through self-distillation to guide self-supervised matching. At the same time, positive and negative anchor pairs are constructed using triplet learning to augment the discriminative ability. We evaluated the performance of STMGAC on five datasets, achieving results superior to those of existing baseline methods. All code and public datasets used in this paper are available at https://github.com/wenwenmin/STMGAC and https://zenodo.org/records/13253801.", "sections": [{"title": "I. INTRODUCTION", "content": "In complex organisms, cells form functionally specialized clusters through dynamic interactions and intricate organizational structures [1]. These clusters coordinate the functions of the organism through mutual influences and tight connections. The latest spatial resolved transcriptomics (SRT) technologies, such as ST, 10x Visium, and Stereo-seq, can comprehensively measure transcriptional expression at specific spatial locations (spots) while preserving the spatial context of the tissue [2]. In the analysis of SRT data, the key computational tasks are identifying shared and specific clusters [3], known as spatial domains, and addressing data denoising issues [4]. Traditional non-spatial clustering methods, such as the Louvain algorithm [5], have failed to effectively utilize spatial information, resulting in incoherent clustering results within tissue sections.\nRecently, proposed spatial clustering methods consider the similarity between neighboring points to reveal the spatial dependence of gene expression. For example, DeepST [6] uses denoising autoencoders and graph neural network (GNN) autoencoders to jointly infer latent embeddings of enhanced spatial transcriptomics data. SEDR [7] employs variational graph autoencoders based on masking mechanisms to infer latent representations. STAGATE [2] integrates spatial information and gene expression through an adaptive graph autoencoder to learn low-dimensional representations. GraphST [8] adopts a graph self-supervised contrastive learning framework to learn the latent embeddings of spatial transcriptomics data. DiffusionST [9] uses a zero-inflated negative binomial (ZINB) distribution and a diffusion model for data denoising and enhancement. Although these methods aim to reduce redundancy in transcriptional expression and employ various techniques to address this issue, they overlook the supervisory signals in the latent space [10-12]. Furthermore, the complex graph self-supervised contrastive learning frameworks lack consideration of global semantic information and the similarity of spatial structures [13, 14].\nTo address the aforementioned challenges, we propose a Contrastively Augmented Masked Graph Autoencoder (STMGAC) to learning low-dimensional latent representations for SRT data analysis. First, we use a masked graph autoencoder to reconstruct raw gene expression and perform gene denoising. Next, we obtain persistent and reliable latent space supervision information through self-distillation, which guides the latent representation for self-supervised matching and results in more stable low-dimensional embeddings. Additionally, we use a plug-and-play method for selecting positive and negative anchor pairs in the latent space, leveraging triplet learning to reduce the distance between embeddings of similar items while ensuring better separation of items from different categories, which improves spatial domain clustering.\nTo validate the effectiveness of STMGAC, we compared it with seven advanced methods across five SRT datasets from three different platforms and conducted extensive ablation studies to investigate the contributions of various components. Experimental results show that STMGAC outperforms other state-of-the-art methods in spatial clustering and trajectory inference.\nThe main contributions of our proposed method are:\n\u2022 We propose a Contrastively Augmented Masked Autoencoder (STMGAC) to learn low-dimensional latent representations for SRT data analysis.\n\u2022 Using self-distillation learning, we acquire latent space supervision signals that improve the reconstruction of raw gene expressions."}, {"title": "II. PROPOSED METHODS", "content": "In data processing, the raw gene expression data is divided into a mask matrix and a visible matrix. A mask GAE is used to reconstruct the raw data, and latent space supervision signals are obtained through a momentum encoder for matching latent representations. Selected anchor spots are then employed for triplet learning. The learned latent representations from STMGAC will be used in downstream analyses (Fig. 1).\nSTMGAC uses gene transcription expression from SRT data and the spatial coordinates of spots as input. Using the library functions provided by SCANPY to retain the genes of interest, and then log-normalize the entire expression. Finally, retain the top $N_g$ highly variable genes to obtain the preprocessed data $X \\in \\mathbb{R}^{N \\times N_g}$, where $N$ is the total number of spots.\nCalculate the Euclidean distance between spots based on their spatial coordinates, and then apply the K-nearest neighbors (KNN) algorithm to select the K nearest spots, thereby constructing the adjacency matrix $A$. If spot $j$ is a neighbor of spot $i$, then $A_{ij} = A_{ji} = 1$. The constructed adjacency matrix will be used in each involving graph neural network.\nBefore training STMGAC, we first generate two complementary masked gene expression graphs. They will be used as the input for the online encoder and momentum encoder, respectively. Specifically, with a masking rate $p$, we randomly sample a masked subset $V_m$ from the set of all spots $V$ in the SRT data, while the remaining spot set forms the visible subset $V_u$, satisfying $V_m \\cup V_v = V$ and $V_m \\cap V = \\emptyset$.\nTo overcome the \"identity mapping\" problem (i.e., directly mapping the input to the output) and to reduce redundancy in SRT data, we construct the masked matrix $X^m \\in \\mathbb{R}^{N \\times N_g}$ of the gene expression matrix. It is defined as follows: for any spot $i$ ($v_i$), if $v_i \\in V_m$, then its corresponding gene expression value is replaced with a learnable mask token $X_{[M]} \\in \\mathbb{R}^{N_g}$, i.e., $x_i^m = x_{[M]}$; otherwise, $x_i^m = X_i$.\nTo ensure that the spots masked in the latent space have persistent supervision signals and perform latent feature matching, we construct the complementary visible matrix $X^v \\in \\mathbb{R}^{N \\times N_g}$ of $X^m$. It is defined as follows: if $v_i \\in V_u$, then its corresponding gene expression value is replaced with the mask token, i.e., $x_i^v = x_{[M]}$; otherwise, $x_i^v = X_i."}, {"title": "D. Latent representation learning with masked reconstruction", "content": "The online encoder $F_s$ is responsible for converting the masked matrix $X^m$ into a low-dimensional latent representation. To achieve this, we first use a MLP $F_{s, f}$ composed of stacked linear layers for initial dimensionality reduction to obtain the low-dimensional feature representation $H_f \\in \\mathbb{R}^{N \\times d_f}$. Here, $d_f$ is the dimensions of the feature.\n$H_f = F_{s,f}(X^m; \\Theta_{s,f}) = W_l^1 \\text{ELU}(\\text{BN}(W_l^0X^m + b_l^0)) + b_l^1$ (1)\nwhere $W_l^l$ and $b_l^l$ represent the weights and biases of the $l$-th layer of the linear layer. BN is batch normalization.\nThen, a graph encoder $F_{s,g}$ consisting of two layers of GCN forces the model to learn an effective latent representation $H^s \\in \\mathbb{R}^{N \\times d}$ from the visible spot neighbors. Here, $d$ is the dimensions of the latent representation. This process is represented as follows:\n$H^s = F_{s,g}(H_f, A; \\Theta_{s,g}) = \\tilde{A} \\text{ReLU}(\\text{BN}(\\tilde{A}H_fW^0))W^1$ (2)\nwhere $W_l^l$ represents the weights of the $l$-th layer of the GCN, as well as the symmetrically normalized adjacency matrix $\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$. Therefore, the calculation of $H^s$ can be expressed as:\n$H^s = F_s(X^m, A; \\Theta_s) = F_{s,g}(F_{s, f} (X^m; \\Theta_{s,f}), A; \\Theta_{s,g})$ (3)\nwhere $\\Theta_s$ is the parameter of the online encoder $F_s$.\nOnce the training phase is completed, we utilize $X$ as the input to the online encoder $F_s$ and obtain the latent representation $H$. This representation is then used for downstream tasks such as spatial domain identification and visualization.\nThe representation predictor $F_p$ can obtain the predicted expression of the latent representation. To alleviate redundancy, we use the remask technique to mask the representation of the spots in the masked subset $V_m$ in the latent space, obtaining the remasked representation $H^m \\in \\mathbb{R}^{N \\times d}$. Specifically, for any $v_i$, if $v_i \\in V_m$, then its corresponding latent feature is replaced with a learnable mask token $h_{[RM]} \\in \\mathbb{R}^d$, i.e., $h_i^m = h_{[RM]}$; otherwise, $h_i^m = h_i$.\nUnlike typical self-supervised encoders, our latent representation undergoes the remask technique before being input to the predictor. Therefore, we need to use a graph neural network to allow the masked spots to learn the current features from the visible spots. The final predicted latent feature representation is $\\hat{H}^m \\in \\mathbb{R}^{N \\times d}$, calculated as follows:\n$\\hat{H}^m = F_p(H^m, A; \\Theta_p) = W_l^1 \\text{ReLU}(\\text{BN}(\\tilde{A}H^mW^0))$ (4)\nwhere $W_l^l$ and $W_l^1$ are the weight matrices, and $\\Theta_p$ is the parameter of the predictor $F_p$.\nThe obtained predicted representation matrix $\\hat{H}^m$ will be used to reconstruct the transcription expression of the raw data space and to align with the supervision signal obtained by the momentum encoder.\nUsing an asymmetric autoencoder, a single-layer GCN is used as the decoder $F_d$ to map $\\hat{H}^m$ into the raw data space, obtaining the reconstructed gene expression matrix $Z \\in \\mathbb{R}^{N \\times N_g}$. The calculation is as follows:\n$Z = F_d(\\hat{H}^m, A; \\Theta_d) = \\tilde{A}\\hat{H}^mW_a$ (5)\nwhere $W_a$ is the weight matrix, and $\\Theta_d$ is the parameter of the decoder $F_d$."}, {"title": "E. Latent representation matching for robustness enhancement", "content": "In graphs, masked spots find it difficult to recover the raw semantics only from their neighbors due to a lack of stronger supervision signals. Therefore, we need to provide each masked spot with a persistent signal in the latent space to guide its self-supervised matching, and this signal is obtained from the data itself through self-distillation learning.\nSpecifically, we have a momentum graph encoder $F_t$ with the same architecture as the graph encoder $F_s$, responsible for encoding the raw gene expression data $X^v$ in the masked visible set $V_u$ to obtain a persistent momentum latent representation $H^t \\in \\mathbb{R}^{N \\times d}$ that provides stable guidance for the latent representation $H^s$. The calculation is as follows:\n$H^t = F_t(X^v, A; \\Theta_t)$ (7)\nwhere $\\Theta_t$ is the parameter of the encoder $F_t$. It is worth noting that $F_t$ is detached from the gradient back-propagation, and its parameters are updated by exponential moving average (EMA), with the update process as follows:\n$\\Theta_t \\leftarrow \\mu \\Theta_t + (1 - \\mu) \\Theta_s$ (8)\nwhere $\\mu$ is the smoothing factor, fixed at 0.98 based on experimental experience, retaining reliable information for about 50 steps.\nHere we focus more on feature-level similarity, emphasizing that the predicted latent representation $\\hat{H}^m$ should precisely match the latent representation $H^t$ calculated by the momentum graph encoder. To this end, we use matching loss to minimize their distance:\n$L_M = \\frac{1}{\\left|V_m\\right|} \\sum_{v_j \\in V_m} \\left\\|\\frac{h_i^t}{\\left\\|h_i^t\\right\\|} - \\frac{\\hat{h}_i^m}{\\left\\|\\hat{h}_i^m\\right\\|}\\right\\|_2^2$ (9)"}, {"title": "F. Spot triplet learning with positive and negative anchors", "content": "Once the low-dimensional representation can reconstruct the high-dimensional raw gene expression, it indicates that the low-dimensional latent representation contains rich semantic information. Therefore, we define triplets in the latent space. Inspired by AFGRL [12], we can utilize the encoding of the online and momentum encoders based on their global semantic information and local neighboring structure information to select positive anchors. Unlike previous methods, we further construct negative anchors to form anchor pairs, and experiments have shown that this is more suitable for spatial domain clustering analysis of SRT datasets.\nSpecifically, for a given query spot $v_i \\in V$, we calculate the cosine similarity between $h_i^s$ and all other spots $h_j^s$ as follows:\n$sim(v_i, v_j) = \\frac{h_i^s \\cdot h_j^s}{\\left\\|h_i^s\\right\\|\\left\\|h_j^s\\right\\|}$ (10)\nAfter obtaining the similarity information, we calculate the $k$-nearest neighbor set $B_i$ in the latent space for each spot $i$ and use it as a reasonable positive anchor candidate for spot $v_i$. However, this approach neglects the local structural information between neighboring spots and the global semantics of spots that might belong to the same spatial domain. Therefore,\nwe have the local positive anchor set $L_i$ and the global positive anchor set $G_i$, satisfying $L_i = B_i \\cap A_i$, where $A_i$ represents the neighboring information of the spatial location of the $i$-th spot; and $G_i = B_i \\cap C_i$, where $C_i$ is the global semantic spot set that belongs to the same spatial domain as the $i$-th spot obtained using a clustering algorithm. Therefore, we provide the real positive set $P_i = L_i \\cup G_i$ for spot $v_i$, considering both local and global information.\nWe define the negative candidate set for the query spot $v_i$ as $\\mathcal{N}_i = V \\setminus (B_i \\cup C_i \\cup A_i)$. The negative set is then obtained by randomly selecting $n = \\left|P_i\\right|$ elements from $\\mathcal{N}$. Formally, let $N_i$ denote this subset, which can be expressed as: $N_i \\subset \\mathcal{N}_i$ and $\\left|N_i\\right| = n$. Finally, we obtain the anchor pairs $T_i = (P_i, N_i)$ for the query spot $v_i$.\nTriplet loss enhances discriminative ability: Triplet loss encourages similar instances (anchors and positive samples) to be closer in the latent space, while dissimilar instances (anchors and negative samples) are pushed further apart. This tightens the clustering of similar items and clearly separates different items, which significantly improves spatial domain recognition capabilities. The calculation is as follows:\n$L_T = \\sum_{v_i \\in V} \\sum_{(p_i, n_i) \\in T_i} \\max(\\left\\|h_i - h_{p_i}\\right\\|_2^2 - \\left\\|h_i - h_{n_i}\\right\\|_2^2 + \\tau, 0)$ (11)\nwhere $N_t$ represents the total number of anchor pairs, and $\\tau$ is the margin (default 1.0).\nFinally, the entire learning objective is written as:\n$Loss = \\lambda_0 L_R + (1 - \\lambda_0) L_M + \\lambda_1 L_T$ (12)\nwhere $\\lambda_0, \\lambda_1$ are hyperparameters that control the contributions to the loss function."}, {"title": "G. Evaluation criteria", "content": "We utilize accuracy metrics to describe the clustering precision of the method. Specifically, we have the following metrics: Adjusted Rand Index (ARI), used to compare the similarity between clustering results and manually annotated labels. Normalized Mutual Information (NMI), based on information theory, it measures the normalized mutual information between clustering results and true labels. Homogeneity (HOM) score, a metric that assesses if all clusters contain only data points belonging to a single class, indicating homogeneous clustering. Completeness (COM) score, a metric that measures if all data points belonging to a particular class are grouped together in the same cluster, indicating complete clustering [15]. Therefore, the overall accuracy score is calculated as follows:\n$ACC = \\frac{1}{3} \\times (NMI + HOM + COM)$ (13)\nThe closer the ARI and ACC scores are to 1, the better the clustering precision."}, {"title": "III. EXPERIMENTS", "content": "In this study, we analyze the clustering performance of STMGAC on a range of SRT datasets from different platforms."}, {"title": "F. Ablation studies", "content": "To investigate the contributions of different components to STMGAC, we designed several variants of STMGAC and explored their impact on model accuracy across three datasets from different platforms (BRCA, HM, and ME datasets) (Table II).\nFor the latent space supervision signal process, we designed three variants: w/o matching loss (without latent space supervision); w/o GCN predictor (using MLP to predict latent representation directly without the remask technique); w/o EMA (sharing weights with the online encoder while the momentum encoder is detached from gradient back-propagation). For the anchor selection method, we designed four variants: w/o triplet loss (completely missing this component); w/o negative nodes (using only positive nodes); w/o local positive nodes; w/o global positive nodes.\nThe results demonstrated that STMGAC achieved the best performance across multiple datasets, only performing slightly worse on the sparse and low-density HM dataset. This slight underperformance is due to the small number of spots, which requires higher accuracy in anchor selection.\nWe investigated the impact of reconstruction loss in the raw space, representation matching loss in the latent space, and contrastive loss. Both $L_R$ and $L_M$ used Mean Squared Error loss (MSE) and Scaled Cosine Error loss (SCE), while $L_T$ used triplet loss (TRI) and contrastive discrimination loss (CON). As a result, using SCE in the raw space effectively learned features, while using MSE in the latent space for mask matching made a significant contribution. TRI greatly enhanced clustering effects (Table III)."}, {"title": "IV. CONCLUSIONS AND DISCUSSION", "content": "In this paper, we propose a Masked Graph Autoencoder with Contrastive Augmentation (STMGAC) method for clustering and gene denoising analysis of SRT data. Previous graph masking methods did not focus on the supervision signals in the latent space, making it difficult for autoencoders to reconstruct raw data accurately. To address this, we designed the raw gene expression data as a masked matrix and a visible spot matrix, utilizing an EMA mechanism to provide persistent and reliable supervision signals for the model's representation in the latent space. Furthermore, in the latent space, we select positive and negative anchor pairs based on the correlation between representations, local adjacency relationships, and global information, bringing similar instances closer together and pushing dissimilar instances further apart, thereby effectively enhancing spatial domain recognition capabilities.\nWe analyzed the performance of STMGAC on dataset from different platforms and achieved results superior to the existing seven baseline methods. Additionally, ablation studies fully explored the contributions of each component to STMGAC."}]}