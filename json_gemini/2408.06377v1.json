{"title": "Masked Graph Autoencoders with Contrastive Augmentation for Spatially Resolved Transcriptomics Data", "authors": ["Donghai Fang", "Fangfang Zhu", "Dongting Xie", "Wenwen Min"], "abstract": "With the rapid advancement of Spatial Resolved Transcriptomics (SRT) technology, it is now possible to comprehensively measure gene transcription while preserving the spatial context of tissues. Spatial domain identification and gene denoising are key objectives in SRT data analysis. We propose a Contrastively Augmented Masked Graph Autoencoder (STMGAC) to learn low-dimensional latent representations for domain identification. In the latent space, persistent signals for representations are obtained through self-distillation to guide self-supervised matching. At the same time, positive and negative anchor pairs are constructed using triplet learning to augment the discriminative ability. We evaluated the performance of STMGAC on five datasets, achieving results superior to those of existing baseline methods. All code and public datasets used in this paper are available at https://github.com/wenwenmin/STMGAC and https://zenodo.org/records/13253801.", "sections": [{"title": "I. INTRODUCTION", "content": "In complex organisms, cells form functionally specialized clusters through dynamic interactions and intricate organizational structures [1]. These clusters coordinate the functions of the organism through mutual influences and tight connections. The latest spatial resolved transcriptomics (SRT) technologies, such as ST, 10x Visium, and Stereo-seq, can comprehensively measure transcriptional expression at specific spatial locations (spots) while preserving the spatial context of the tissue [2]. In the analysis of SRT data, the key computational tasks are identifying shared and specific clusters [3], known as spatial domains, and addressing data denoising issues [4]. Traditional non-spatial clustering methods, such as the Louvain algorithm [5], have failed to effectively utilize spatial information, resulting in incoherent clustering results within tissue sections.\nRecently, proposed spatial clustering methods consider the similarity between neighboring points to reveal the spatial dependence of gene expression. For example, DeepST [6] uses denoising autoencoders and graph neural network (GNN) autoencoders to jointly infer latent embeddings of enhanced spatial transcriptomics data. SEDR [7] employs variational graph autoencoders based on masking mechanisms to infer latent representations. STAGATE [2] integrates spatial information and gene expression through an adaptive graph autoencoder to learn low-dimensional representations. GraphST [8] adopts a graph self-supervised contrastive learning framework to learn the latent embeddings of spatial transcriptomics data. DiffusionST [9] uses a zero-inflated negative binomial (ZINB) distribution and a diffusion model for data denoising and enhancement. Although these methods aim to reduce redundancy in transcriptional expression and employ various techniques to address this issue, they overlook the supervisory signals in the latent space [10-12]. Furthermore, the complex graph self-supervised contrastive learning frameworks lack consideration of global semantic information and the similarity of spatial structures [13, 14].\nTo address the aforementioned challenges, we propose a Contrastively Augmented Masked Graph Autoencoder (STMGAC) to learning low-dimensional latent representations for SRT data analysis. First, we use a masked graph autoencoder to reconstruct raw gene expression and perform gene denoising. Next, we obtain persistent and reliable latent space supervision information through self-distillation, which guides the latent representation for self-supervised matching and results in more stable low-dimensional embeddings. Additionally, we use a plug-and-play method for selecting positive and negative anchor pairs in the latent space, leveraging triplet learning to reduce the distance between embeddings of similar items while ensuring better separation of items from different categories, which improves spatial domain clustering. To validate the effectiveness of STMGAC, we compared it with seven advanced methods across five SRT datasets from three different platforms and conducted extensive ablation studies to investigate the contributions of various components. Experimental results show that STMGAC outperforms other state-of-the-art methods in spatial clustering and trajectory inference.\nThe main contributions of our proposed method are:\n\u2022 We propose a Contrastively Augmented Masked Autoencoder (STMGAC) to learn low-dimensional latent representations for SRT data analysis.\n\u2022 Using self-distillation learning, we acquire latent space supervision signals that improve the reconstruction of raw gene expressions."}, {"title": "II. PROPOSED METHODS", "content": "A. Overview of the proposed STMGAC\nIn data processing, the raw gene expression data is divided into a mask matrix and a visible matrix. A mask GAE is used to reconstruct the raw data, and latent space supervision signals are obtained through a momentum encoder for matching latent representations. Selected anchor spots are then employed for triplet learning. The learned latent representations from STMGAC will be used in downstream analyses (Fig. 1).\nB. Data preprocessing and spatial graph construction\nSTMGAC uses gene transcription expression from SRT data and the spatial coordinates of spots as input. Using the library functions provided by SCANPY to retain the genes of interest, and then log-normalize the entire expression. Finally, retain the top $N_g$ highly variable genes to obtain the preprocessed data $X \\in \\mathbb{R}^{N \\times N_g}$, where N is the total number of spots.\nCalculate the Euclidean distance between spots based on their spatial coordinates, and then apply the K-nearest neighbors (KNN) algorithm to select the K nearest spots, thereby constructing the adjacency matrix A. If spot j is a neighbor of spot i, then $A_{ij} = A_{ji} = 1$. The constructed adjacency matrix will be used in each involving graph neural network.\nC. Data augmentation with spot masking\nBefore training STMGAC, we first generate two complementary masked gene expression graphs. They will be used as the input for the online encoder and momentum encoder, respectively. Specifically, with a masking rate p, we randomly sample a masked subset $V_m$ from the set of all spots V in the SRT data, while the remaining spot set forms the visible subset $V_u$, satisfying $V_m \\cup V = V$ and $V_m \\cap V = \\emptyset$.\nTo overcome the \"identity mapping\" problem (i.e., directly mapping the input to the output) and to reduce redundancy in SRT data, we construct the masked matrix $X^m \\in \\mathbb{R}^{N \\times N_g}$ of the gene expression matrix. It is defined as follows: for any spot $i (v_i)$, if $v_i \\in V_m$, then its corresponding gene expression value is replaced with a learnable mask token $X_{[M]} \\in \\mathbb{R}^{N_g}$, i.e., $x^m_i = x_{[M]}$; otherwise, $x^m_i = X_i$.\nTo ensure that the spots masked in the latent space have persistent supervision signals and perform latent feature matching, we construct the complementary visible matrix $X^u \\in \\mathbb{R}^{N \\times N_g}$ of $X^m$. It is defined as follows: if $v_i \\in V_u$, then its corresponding gene expression value is replaced with the mask token, i.e., $x^u_i = x_{[M]}$; otherwise, $x^u_i = X_i$.\nD. Latent representation learning with masked reconstruction\n1) Graph encoding: The online encoder $\\mathcal{F}_s$ is responsible for converting the masked matrix $X^m$ into a low-dimensional latent representation. To achieve this, we first use a MLP $\\mathcal{F}_{s,f}$ composed of stacked linear layers for initial dimensionality reduction to obtain the low-dimensional feature representation $H_f \\in \\mathbb{R}^{N \\times d_f}$. Here, $d_f$ is the dimensions of the feature.\n$H_f = \\mathcal{F}_{s,f}(X^m;\\Theta_{s,f}) = W^1ELU(BN(W^0X^m + b^0)) + b^1$ (1)\nwhere $W^l$ and $b^l$ represent the weights and biases of the l-th layer of the linear layer. BN is batch normalization.\nThen, a graph encoder $\\mathcal{F}_{s,g}$ consisting of two layers of GCN forces the model to learn an effective latent representation $H^s \\in \\mathbb{R}^{N \\times d}$ from the visible spot neighbors. Here, d is the dimensions of the latent representation. This process is represented as follows:\n$H^s = \\mathcal{F}_{s,g}(H^f, \\tilde{A}; \\Theta_{s,g}) = \\tilde{A}ReLU(BN(\\tilde{A}H^fW^0))W^1$ (2)\nwhere $W^l$ represents the weights of the l-th layer of the GCN, as well as the symmetrically normalized adjacency matrix $\\tilde{A} = D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$. Therefore, the calculation of $H^s$ can be expressed as:\n$H^s = \\mathcal{F}_{s}(X^m, A; \\Theta_{s}) = \\mathcal{F}_{s,g}(\\mathcal{F}_{s,f}(X^m; \\Theta_{s,f}), A; \\Theta_{s,g})$ (3)\nwhere $\\Theta_s$ is the parameter of the online encoder $\\mathcal{F}_s$.\nOnce the training phase is completed, we utilize X as the input to the online encoder $\\mathcal{F}_s$ and obtain the latent representation H. This representation is then used for downstream tasks such as spatial domain identification and visualization.\n2) Latent representation predicting: The representation predictor $\\mathcal{F}_p$ can obtain the predicted expression of the latent representation. To alleviate redundancy, we use the remask technique to mask the representation of the spots in the masked subset $V_m$ in the latent space, obtaining the remasked representation $H^m \\in \\mathbb{R}^{N \\times d}$. Specifically, for any $v_i$, if $v_i \\in V_m$, then its corresponding latent feature is replaced with a learnable mask token $h_{[RM]} \\in \\mathbb{R}^d$, i.e., $h^m_i = h_{[RM]}$; otherwise, $h^m_i = h^s_i$.\nUnlike typical self-supervised encoders, our latent representation undergoes the remask technique before being input to the predictor. Therefore, we need to use a graph neural network to allow the masked spots to learn the current features from the visible spots. The final predicted latent feature representation is $\\hat{H}^m \\in \\mathbb{R}^{N \\times d}$, calculated as follows:\n$\\hat{H}^m = \\mathcal{F}_p(H^m, A; \\Theta_p) = W^1_pReLU(BN(AH^mW^0_p))$ (4)\nwhere $W^1_p$ and $W^1$ are the weight matrices, and $\\Theta_p$ is the parameter of the predictor $\\mathcal{F}_p$.\nThe obtained predicted representation matrix $\\hat{H}^m$ will be used to reconstruct the transcription expression of the raw data space and to align with the supervision signal obtained by the momentum encoder.\n3) Feature decoding: Using an asymmetric autoencoder, a single-layer GCN is used as the decoder $\\mathcal{F}_d$ to map $\\hat{H}^m$ into the raw data space, obtaining the reconstructed gene expression matrix $Z \\in \\mathbb{R}^{N \\times N_g}$. The calculation is as follows:\n$Z = \\mathcal{F}_d(\\hat{H}^m, A; \\Theta_d) = A\\hat{H}^mW_d$ (5)\nwhere $W_d$ is the weight matrix, and $\\Theta_d$ is the parameter of the decoder $\\mathcal{F}_d$.\n4) Reconstruction loss in the raw data space: One of the main objectives of STMGAC is to reconstruct the masked gene expression of spots in $V_m$ given a partially observed spot set and adjacency relationships. By utilizing the Scaled Cosine Loss (SCE) as the objective function, it is defined under a predetermined scaling factor $\\gamma$ as follows:\n$\\mathcal{L}_R = \\frac{1}{|V_m|} \\sum_{v_i \\in V_m}^T (1 - \\frac{X_iZ_i}{||X_i|| || Z_i ||})^\\gamma, \\gamma \\geq 1$ (6)\nwhere $\\gamma$ is fixed to 2 to reduce the contribution from simple samples during the training process, and $|V_m|$ represents the number of spots in the masked set.\nE. Latent representation matching for robustness enhancement\n1) Momentum graph encoding: In graphs, masked spots find it difficult to recover the raw semantics only from their neighbors due to a lack of stronger supervision signals. Therefore, we need to provide each masked spot with a persistent signal in the latent space to guide its self-supervised matching, and this signal is obtained from the data itself through self-distillation learning.\nSpecifically, we have a momentum graph encoder $\\mathcal{F}_t$ with the same architecture as the graph encoder $\\mathcal{F}_s$, responsible for encoding the raw gene expression data $X^u$ in the masked visible set $V_u$ to obtain a persistent momentum latent representation $H^t \\in \\mathbb{R}^{N \\times d}$ that provides stable guidance for the latent representation $H^s$. The calculation is as follows:\n$H^t = \\mathcal{F}_t(X^u, A; \\Theta_t)$ (7)\nwhere $\\Theta_t$ is the parameter of the encoder $\\mathcal{F}_t$. It is worth noting that $\\mathcal{F}_t$ is detached from the gradient back-propagation, and its parameters are updated by exponential moving average (EMA), with the update process as follows:\n$\\Theta_t \\leftarrow \\mu \\Theta_t + (1 - \\mu) \\Theta_s$ (8)\nwhere $\\mu$ is the smoothing factor, fixed at 0.98 based on experimental experience, retaining reliable information for about 50 steps.\n2) Matching loss in the latent representation space: Here we focus more on feature-level similarity, emphasizing that the predicted latent representation $\\hat{H}^m$ should precisely match the latent representation $H^t$ calculated by the momentum graph encoder. To this end, we use matching loss to minimize their distance:\n$\\mathcal{L}_M = \\frac{1}{|V_m|} \\sum_{v_j \\in V_m} || h^m_j - h^t_j ||^2_2$ (9)\nF. Spot triplet learning with positive and negative anchors\n1) Selecting positive and negative anchor pairs: Once the low-dimensional representation can reconstruct the high-dimensional raw gene expression, it indicates that the low-dimensional latent representation contains rich semantic information. Therefore, we define triplets in the latent space. Inspired by AFGRL [12], we can utilize the encoding of the online and momentum encoders based on their global semantic information and local neighboring structure information to select positive anchors. Unlike previous methods, we further construct negative anchors to form anchor pairs, and experiments have shown that this is more suitable for spatial domain clustering analysis of SRT datasets.\nSpecifically, for a given query spot $v_i \\in V$, we calculate the cosine similarity between $h^s_i$ and all other spots $h^s_j$ as follows:\n$sim(v_i, v_j) = \\frac{h^s_i h^s_j}{|| h^s_i || || h^s_j ||} ,  v_j \\in V$ (10)\nAfter obtaining the similarity information, we calculate the k-nearest neighbor set $B_i$ in the latent space for each spot i and use it as a reasonable positive anchor candidate for spot $v_i$. However, this approach neglects the local structural information between neighboring spots and the global semantics of spots that might belong to the same spatial domain. Therefore, we have the local positive anchor set $L_i$ and the global positive anchor set $G_i$, satisfying $L_i = B_i \\cap A_i$, where $A_i$ represents the neighboring information of the spatial location of the i-th spot; and $G_i = B_i \\cap C_i$, where $C_i$ is the global semantic spot set that belongs to the same spatial domain as the i-th spot obtained using a clustering algorithm. Therefore, we provide the real positive set $P_i = L_i \\cup G_i$ for spot $v_i$, considering both local and global information.\nWe define the negative candidate set for the query spot $v_i$ as $N = V \\setminus (B_i \\cup C_i \\cup A_i)$. The negative set is then obtained by randomly selecting $n = |P_i|$ elements from N. Formally, let $N_i$ denote this subset, which can be expressed as: $N_i \\subset N$ and $|N_i| = n$. Finally, we obtain the anchor pairs $T_i = (P_i, N_i)$ for the query spot $v_i$.\n2) Triplet loss enhances discriminative ability: Triplet loss encourages similar instances (anchors and positive samples) to be closer in the latent space, while dissimilar instances (anchors and negative samples) are pushed further apart. This tightens the clustering of similar items and clearly separates different items, which significantly improves spatial domain recognition capabilities. The calculation is as follows:\n$\\mathcal{L}_T = \\sum_{v_i \\in V} \\sum_{(p_i,n_i) \\in T} max(||h_i - h_p||^2 - ||h_i - h_n||^2 + \\tau, 0)$ (11)\nwhere $N_t$ represents the total number of anchor pairs, and $\\tau$ is the margin (default 1.0).\nFinally, the entire learning objective is written as:\n$Loss = \\lambda_0\\mathcal{L}_R + (1 - \\lambda_0) \\mathcal{L}_M + \\lambda_1\\mathcal{L}_T$ (12)\nwhere $\\lambda_0, \\lambda_1$ are hyperparameters that control the contributions to the loss function.\nG. Evaluation criteria\nWe utilize accuracy metrics to describe the clustering precision of the method. Specifically, we have the following metrics: Adjusted Rand Index (ARI), used to compare the similarity between clustering results and manually annotated labels. Normalized Mutual Information (NMI), based on information theory, it measures the normalized mutual information between clustering results and true labels. Homogeneity (HOM) score, a metric that assesses if all clusters contain only data points belonging to a single class, indicating homogeneous clustering. Completeness (COM) score, a metric that measures if all data points belonging to a particular class are grouped together in the same cluster, indicating complete clustering [15]. Therefore, the overall accuracy score is calculated as follows:\n$ACC = \\frac{1}{3} \\times (NMI + HOM + COM)$ (13)\nThe closer the ARI and ACC scores are to 1, the better the clustering precision."}, {"title": "III. EXPERIMENTS", "content": "A. Dataset description\nIn this study, we analyze the clustering performance of STMGAC on a range of SRT datasets from different platforms.\nB. Baseline methods\nWe selected several state-of-the-art methods that are representative of the following:\n\u2022 SpaGCN [21] integrates gene expression, spatial location, and histology in SRT data via graph convolution.\n\u2022 CCST [22] is developed based on the node embedding method DGI to achieve spatial domain clustering.\n\u2022 DeepST [6] employs GCN as an encoder to reconstruct the input graph topology and capture the spot features.\n\u2022 SEDR [7] utilizes a deep autoencoder network to learn gene expression while simultaneously incorporating the spatial information from the variation graph autoencoder.\n\u2022 STAGATE [2] leverages adaptive graph attention autoencoders to integrate spatial location and gene expression.\n\u2022 GraphST [8] is a graph self-supervised contrastive learning method that leverages spatial information and gene expression profiles.\n\u2022 DiffusionST [9] employs a ZINB distribution and diffusion models to denoise and enhance SRT data.\nC. Implementation Details\nFor STMGAC, we use a learning rate of 0.001 and a weight decay of 2e-4, optimized with Adam. The online and momentum encoders have linear layers of dimensions 64 and 32, followed by GCN layers with output dimensions of 64 and 16. The predictor dimension is 32, and the feature decoder reconstructs to the raw data space. The default masking rate is 0.5. For anchor pairs selection, the 10x Visium and Stereo-seq datasets use the top 50 nearest neighbors, while ST uses the top 30 nearest neighbors. Default parameters from the original papers were applied for all baselines, and experiments were conducted on an NVIDIA GeForce RTX 3090.\nD. STMGAC enables the identification of tissue structures from SRT data\n1) Applying STMGAC to the DLPFC dataset: We compared the clustering results of the STMGAC model with seven state-of-the-art representative algorithms on the DLPFC dataset. The bar chart in Fig. 2B shows the ARI and ACC values of each method across 12 slices. As shown in the figure, STMGAC achieved the highest median ARI (0.584) and ACC (0.706), while the existing benchmark methods had median ACC values below 0.70.\nWe showed spatial domain identification results for slice 151675 (Fig. 2C and D). SpaGCN, SEDR, and DeepST had many misclassified spots and unclear boundaries. CCST could not distinguish layers 5 and 6, while DiffusionST and GraphST missed layer 4. Only STMGAC correctly identified all layers with clear boundaries and no mixed spots.\nFrom the UMAP visualization results (Fig. 2E), it was found that only the embeddings of STMGAC were consistent with the development trajectory of the layers, showing a linear pattern. It is worth noting that both DiffusionST and GraphST used label refinement techniques, which improved performance but did not substantially change the UMAP visualization trajectory of their embeddings.\n2) Applying STMGAC to the HM dataset: In the HM dataset (Fig. 2F and G), baseline methods missed the stroma region, whereas STMGAC successfully identified it. STMGAC showed superior clustering performance. CCST performed poorly on the sparse and low-density HM dataset, leading to excessive smoothing.\nTo explore gene expression differences, we analyzed differential expression in Cluster 2 (lymphoid family) and Cluster 4 (melanoma family) using the criteria | log 2(FoldChange)| \u2265 2 and P < 0.05. The identified genes play key roles in various physiological and pathological processes. We then performed gene enrichment analysis using the Gene Ontology: Biological Process (GO:BP) [23] database (Fig. 2H). For Cluster 2, the top 10 GO:BP terms were mainly related to cell morphology and immune response regulation. For Cluster 4, the terms focused on biological regulation and metabolic processes [10].\n3) Applying STMGAC to the MBA dataset: We analyzed the MBA dataset (Fig. 2I), which presents a more complex tissue structure compared to the DLPFC dataset, posing greater challenges. STAGATE incorrectly divided the central nucleus (CPu) into multiple regions, while DeepST and SpaGCN showed significant spot mixing, resulting in unclear cluster boundaries. STMGAC demonstrated an improved ability to identify spatial domains in complex tissue structures (Fig. 2J).\nE. STMGAC denoises gene expressions for better characterizing spatial expression patterns\n1) Applying STMGAC to the BRCA dataset: We used STMGAC to reduce noise in the BRCA dataset and better display the spatial patterns of genes. First, we identified differentially expressed genes in Cluster 4 (health) and Cluster 5 (tumor edge), with 564 and 84 genes respectively, and plotted their differential expression using volcano plots (Fig. 3E). For example, after denoising, the IGLC2 and AQP1 genes showed differential expression in the tumor edge and health domains, respectively, whereas their raw spatial expression was completely disordered (Fig. 3D).\n2) Applying STMGAC to the ME dataset: We evaluated the denoising capability of STMGAC on the ME dataset by comparing the expression of key marker genes across six tissue regions between the raw data and the STMGAC-denoised data. The results demonstrated significant spatial enrichment of gene expression in these tissue regions post-denoising (Fig. 3I and J). For instance, the Neurog2 gene exhibited differential expression in the brain region after denoising, which aligns with its known function. Similarly, the Myl7 gene, which is involved in calcium ion binding activity, was primarily expressed in the heart and vascular system, consistent with previous findings [19, 20]. Additionally, violin plots comparing the raw and STMGAC-denoised data for 10 marker genes indicated that STMGAC significantly enhanced the spatial expression patterns of these genes (Fig. 3K).\nF. Ablation studies\n1) Contributions of different components: To investigate the contributions of different components to STMGAC, we designed several variants of STMGAC and explored their impact on model accuracy across three datasets from different platforms (BRCA, HM, and ME datasets) (Table II).\nFor the latent space supervision signal process, we designed three variants: w/o matching loss (without latent space supervision); w/o GCN predictor (using MLP to predict latent representation directly without the remask technique); w/o EMA (sharing weights with the online encoder while the momentum encoder is detached from gradient back-propagation). For the anchor selection method, we designed four variants: w/o triplet loss (completely missing this component); w/o negative nodes (using only positive nodes); w/o local positive nodes; w/o global positive nodes.\nThe results demonstrated that STMGAC achieved the best performance across multiple datasets, only performing slightly worse on the sparse and low-density HM dataset. This slight underperformance is due to the small number of spots, which requires higher accuracy in anchor selection.\n2) Impact of different loss functions: We investigated the impact of reconstruction loss in the raw space, representation matching loss in the latent space, and contrastive loss. Both $\\mathcal{L}_R$ and $\\mathcal{L}_M$ used Mean Squared Error loss (MSE) and Scaled Cosine Error loss (SCE), while $\\mathcal{L}_T$ used triplet loss (TRI) and contrastive discrimination loss (CON). As a result, using SCE in the raw space effectively learned features, while using MSE in the latent space for mask matching made a significant contribution. TRI greatly enhanced clustering effects (Table III)."}, {"title": "IV. CONCLUSIONS AND DISCUSSION", "content": "In this paper, we propose a Masked Graph Autoencoder with Contrastive Augmentation (STMGAC) method for clustering and gene denoising analysis of SRT data. Previous graph masking methods did not focus on the supervision signals in the latent space, making it difficult for autoencoders to reconstruct raw data accurately. To address this, we designed the raw gene expression data as a masked matrix and a visible spot matrix, utilizing an EMA mechanism to provide persistent and reliable supervision signals for the model's representation in the latent space. Furthermore, in the latent space, we select positive and negative anchor pairs based on the correlation between representations, local adjacency relationships, and global information, bringing similar instances closer together and pushing dissimilar instances further apart, thereby effectively enhancing spatial domain recognition capabilities.\nWe analyzed the performance of STMGAC on dataset from different platforms and achieved results superior to the existing seven baseline methods. Additionally, ablation studies fully explored the contributions of each component to STMGAC."}]}