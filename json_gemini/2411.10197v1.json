{"title": "A logic for reasoning with inconsistent knowledge", "authors": ["Nico Roos"], "abstract": "In many situations humans have to reason with inconsistent knowledge.\nThese inconsistencies may occur due to not fully reliable sources of informa-\ntion. In order to reason with inconsistent knowledge, it is not possible to view\na set of premisses as absolute truths as is done in predicate logic. Viewing\nthe set of premisses as a set of assumptions, however, it is possible to deduce\nuseful conclusions from an inconsistent set of premisses. In this paper a logic\nfor reasoning with inconsistent knowledge is described. This logic is a gen-\neralization of the work of N. Rescher [15]. In the logic a reliability relation\nis used to choose between incompatible assumptions. These choices are only\nmade when a contradiction is derived. As long as no contradiction is derived,\nthe knowledge is assumed to be consistent. This makes it possible to define an\nargumentation-based deduction process for the logic. For the logic a semantics\nbased on the ideas of Y. Shoham [22, 23], is defined. It turns out that the\nsemantics for the logic is a preferential semantics according to the definition\nS. Kraus, D. Lehmann and M. Magidor [12]. Therefore the logic is a logic of\nsystem P and possesses all the properties of an ideal non-monotonic logic.", "sections": [{"title": "Changes to the original paper", "content": "The paper is a reformulation of the paper\n\"N.Roos, A logic for reasoning with inconsistent knowledge Artificial Intelligence 57\n(1992) 69-103\" [21] using nowadays terminology. The original paper determines \u2018jus-\ntifications' for deriving conclusion and resolving inconsistencies in provided knowl-\nedge and information. These justifications are actually arguments that are evaluated\nusing the stable semantics, and the approach is an assumption-based argumentation\nsystem. The current version of the paper talks arguments instead of justifications.\nAnother change concerns the addition of superscripts to some symbols. The first\nparagraph of Section 4 states that a linear extension \u4eba' of the reliability relation \u4eba\nis considered. To make this clearer in the formalization, the superscript <' is added\nto anything that depends on the linear extension \u4eba' that is currently considered.\nSection 9 is new and has been inserted to describe the relation with Dung's\nargumentation framework [5].\nThe original text of the paper has not been updated except for a few typing\nerrors and improvements to some of the proofs."}, {"title": "History", "content": "The work on the topic described in the paper is based on the author's\nMaster Thesis (1987) where a ranked set of premisses were used. The ranking was\nreplaced by a partial order in 1988 [16, 17]. In the latter reports, the grounded\nsemantics was used for drawing conclusions and inconsistencies were not resolved\nin the absence of a unique least preferred premiss among the premisses from which\nthe inconsistency was derived. In 1989, the grounded semantics was replaced by the\nstable semantics [18, 19, 20] and in the absence of a unique least preferred premiss\namong the premisses from which the inconsistency is derived, every minimal premiss\nis considered. [18] was submitted for publication to the Artificial Intelligence journal\nin 1989 after it was rejected for IJCAI-89. After a rather long review period, it was\naccepted with revisions in 1991. The AI Journal paper, on which the update paper\npresented here is based, was the result of processing the reviewers recommendation."}, {"title": "Related work", "content": "There is a correspondence between the \u201clogic for reasoning with\ninconsistent knowledge\" and Brewka's \u201cPreferred Subtheories\" [2]. Both draw con-\nclusions from preferred maximally consistent subsets of the premisses. The \u201clogic\nfor reasoning with inconsistent knowledge\" [16, 17, 18, 19, 20] was developed in-\ndependent of Brewka's \u201cPreferred Subtheories\" [2]. The \u201clogic for reasoning with\ninconsistent knowledge\" differs from Brewka's \u201cPreferred Subtheories\" by also pre-\nsenting an assumption-based argumentation system for deriving conclusions, and a\npreferential model semantics."}, {"title": "1 Introduction", "content": "In many situations humans have to reason with inconsistent knowledge. These\ninconsistencies may occur due to sources of information which are not fully reliable.\nFor example, in daylight information about the position of an object coming from\nyour eyes is more reliable than the information about the position of the object\ncoming from your ears. But even reliable sources such as domain experts, do not\nalways agree.\nTo be able to reason with inconsistent knowledge it is not possible to view a set\nof premisses as absolute truths, as in predicate logic. Viewing a set of premisses as\na set of assumptions, however, makes it possible to deduce useful conclusions from\nan inconsistent set of premisses. As long as we do not have it proven otherwise,\nthe premisses are assumed to be true statements about the world. When, however,\na contradiction is derived, we can no longer make this assumption. To restore\nconsistency, one of the premisses has to be removed. To be able to select a premiss\nto be removed, a reliability relation on the premisses will be used. This reliability\nrelation denotes the relative reliability of the premisses.\nIn the following sections I will first describe the propositional case. After de-\nscribing the propositional case, I will describe how to extend the logic to the first\norder case."}, {"title": "2 Basic concepts", "content": "The language L, that will be used to express the propositions of the logic, consists\nof the propositions that can be generated using a set of atomic propositions and the\nlogical operators \u00ac and \u2192. When in this paper the operators \u2227 and V are used,\nthey should be interpreted as shortcuts: i.e. \u03b1^\u03b2 for \u00ac(a \u2192 \u00ac\u03b2) and a V \u03b2 for\n\u00ac\u03b1 \u2192 \u03b2.\nTo be able to reason with inconsistent knowledge, I will consider premisses to\nbe assumptions. These premisses are assumed to be true as long as we do not\nderive a contradiction from them. If, however, a contradiction is derived, we have\nto determine the premisses on which the contradiction is based. The premisses\non which a contradiction is based are the premisses used in the derivation of the\ncontradiction. When we know these premisses, we have to remove one of them to\nblock the derivation of the contradiction. To select a premiss to be removed, I will\nuse a reliability relation. This reliability relation denotes the relative reliability of\nthe premisses. It denotes that one premiss is more reliable than some other premiss.\nClearly the relation must be irreflexive, asymmetric and transitive. I do not demand\nthis relation to be total, for a total reliability relation implies complete knowledge\nabout the relative reliability of the premisses. This does not always have to be the\ncase.\nA set of premisses \u2211 is a subset of the language L. On the set of premisses \u03a3 a"}, {"title": "Definition 1", "content": "A reliability theory is a tuple\u3008\u03a3, \u4eba\u3009where \u03a3\u2286 L is a finite set of\npremisses and \u3145 \u2286 (\u2211 \u00d7 \u2211) is an irreflexive, asymmetric and transitive partial\nreliability relation.\nUsing the reliability relation, we have to remove a least preferred premiss of the\ninconsistent set, thereby blocking the derivation of the contradiction."}, {"title": "Example 2", "content": "Let \u2211 denote a set of premisses,\n\u03a3 = {1. \u03c6, 2. \u03c6 \u2192 \u03c8,3. \u00ac\u03c8, 4. \u03b1}\nand \u4eba a reliability relation on \u03a3:\n< = {(3, 1), (3, 2)}\nFrom \u03a3, \u03c8 can be derived using premisses 1 and 2. Furthermore, a contradic-\ntion can be derived from \u03c8 and premiss 3. Hence, the contradiction is based\non the premisses 1, 2 and 3. Since premiss 3 is the least reliable premiss on\nwhich the contradiction is based, it has to be removed."}, {"title": "", "content": "Three problems may arise when trying to block the derivation of a contradiction.\n\u2022 Firstly, we have to be able to determine the premisses on which a contradic-\ntion is based. These are the premisses that are used in the derivation of the\ncontradiction. To solve this problem, supporting arguments are introduced.\nA supporting argument describes the premisses from which a proposition is\nderived.\n\u2022 Secondly, a premiss that has been removed, may have to be placed back be-\ncause the contradiction causing its removal is also blocked by the removal of\nanother premiss. This may occur because of some other contradiction being\nderived."}, {"title": "Example 3", "content": "Let \u2211 be a set of premisses\n\u03a3 = {\u03b1, \u00ac\u03b1\u2227\u00ac\u03b2, \u03b2}\nand let < be a reliability relation on \u2211 given by\n\u03b1< (\u00ac\u03b1 \u2227 \u00ac\u03b2) < \u03b2.\nFrom \u03b1 and \u00ac\u03b1\u2227\u00ac\u03b2 we can derive a contradiction causing the removal\nof \u03b1. From \u00ac\u03b1 \u2227 \u00ac\u03b2 and \u03b2 we can also derive a contradiction causing the\nremoval of \u00ac\u03b1\u2227\u00ac\u03b2. When \u00ac\u03b1\u2227\u00ac\u03b2 is removed, it is no longer necessary\nthat \u03b1 is also removed from the set of premisses to avoid the derivation\nof a contradiction."}, {"title": "", "content": "To solve this problem, undermining arguments\u00b9 are introduced. An under-\nmining argument describes which premiss must be removed if other premisses\nare assumed to be true. It is a constraint on the set of premisses we assume\nto be true.\n\u2022 Thirdly, there need not exist a single least reliable premiss in the set of pre-\nmisses on which a contradiction is based. This can occur when no reliability\nrelation between premisses is specified. In such a situation we have to consider\nthe results of the removal of every alternative separately.\nChoosing a premiss to be removed implies that we assume the alternatives\nto be more reliable. Since the reliability relation is transitive, making such a\nchoice influences the reliability relation defined on the premisses."}, {"title": "Example 4", "content": "Let \u2211 = {a, b, \u00aca, \u00acb} be a set of premisses and let\n< = {(a, b), (b, \u00aca)} be a reliability relation on \u03a3. Since a and \u00aca are\nin conflict and since there is no reliability relation defined between them,\nwe have to choose a culprit. If we choose to remove \u00aca, a is assumed to\nbe more reliable. Therefore,\u00acb is more reliable than b. Hence, since b\nand \u00acb are also in conflict, b must be removed.\nAs is illustrated in the example above, the premisses removed depend on the\nextension of the reliability relation. Therefore, in the logic described here,\nevery (strict) linear extension of the reliability relation will be considered.\nDifferent linear extensions of the reliability relation can result in different\nsubsets of the premisses that are assumed to be true statement about the\nworld (that can be believed). The set of theorems is defined as the intersection\nof all extensions of the logic."}, {"title": "", "content": "As mentioned above, two types of arguments, supporting arguments and under-\nmining arguments, will be used. A supporting argument is used to denote that\na proposition is believed if the premisses in the antecedent are believed, while an\nundermining argument is used to denote that a premiss can no longer be believed\n(must be withdrawn) if the premisses in the antecedent are believed."}, {"title": "Definition 5", "content": "Let \u2211 be a set of premisses. Then a supporting argument is a formula:\nP\u21d2 \u03c6\nwhere P is a subset of the set of premisses \u2211 and \u03c6\u2208 L is a proposition. \u03c6\ncan be viewed as the warrant of the argument [24].\nAn undermining argument is a formula:\nP \u2260 \u03c6"}, {"title": "3 Characterizing the set of theorems", "content": "In this section a characterization, based on the ideas of N. Rescher [15], is given for\nthe set of theorems of a reliability theory. As is mentioned in the previous section,\nlinear extensions of the reliability relation have to be considered. For each linear\nextension a set of premisses that can still be believed can be determined. This set\ncan be determined by enumerating the premisses with respect to the linear extension\nof the reliability relation, starting with the most reliable premiss. Starting with an\nempty set D, if a premiss may consistently be added to the set D, it should be added.\nOtherwise it must be ignored. Because the most reliable premisses are added first,\nwe get a most reliable consistent set of premisses.2"}, {"title": "Definition 6", "content": "Let\u3008\u2211, \u4eba\u3009be a reliability theory. Furthermore, let \u03c31, \u03c32, ..., \u03c3m be\nsome enumeration of \u2211 such that for every \u03c3j < \u03c3\u03ba: k < j.\nThen D is a most reliable consistent set of premisses if and only if:\nD = Dm, Do = \u00d8\nand for 0 <i<m\nDi+1 =\n{\nDi \u222a {\u03c3i} if Di \u222a {\u03c3i} is consistent\nDi otherwise\nLet R be the set of all the most reliable consistent sets of premisses that can be\ndetermined."}, {"title": "Definition 7", "content": "Let (\u2211, <\u3009 be a reliability theory.\nThen the set R of all the most reliable consistent sets of premisses is defined\nby:\nR = {D | D is a most reliable consistent set of premisses\ngiven some enumeration of \u2211 consistent with \u4eba }.\nThe set of theorems of a reliability theory is defined as the set of those propositions\nthat are logically entailed by every most reliable consistent set of premisses in R."}, {"title": "Definition 8", "content": "Let\u3008\u2211, \u4eba\u3009 be a reliability theory and let R be the corresponding set\nof all the most reliable consistent sets of premisses.\nThen the set of theorems of \u3008\u03a3, \u4eba\u3009 is defined as:\nTh((\u03a3, <)) = \u2229D\u2208R Th(D).\nwhere Th(D) = {y | D \u251c-4}"}, {"title": "4 The deduction process", "content": "In this section a deduction process for a reliability theory is described. Given a strict\nlinear extension \u4eba' of the reliability relation \u4eba, the deduction process determines\nthe set of premisses that can be believed."}, {"title": "Remark 9", "content": "Instead of starting a deduction process for every strict linear extension\nof \u4eba, we can also create different extensions of \u4eba when a contradiction not\nbased on a single least reliable premiss, is derived. This approach results in\none deduction tree instead of a deduction sequence for every linear extension\nof \u4eba.\nInstead of deriving new propositions, only new arguments are derived. These\narguments are generated by the inference rules. The reason why arguments instead\nof propositions are derived, is that the propositions that can be believed (the belief\nset) depend on the set of premisses that can still be believed. Since this set of\npremisses may change because of new information derived, the belief set can change\nin a non-monotonic way. The arguments, however, do not depend on the information\nderived. Furthermore, they contain all the information needed to determine the\npremisses that can still be believed and the corresponding belief set. Note that the\nset of arguments depends on the linear extension \u4eba' of \u4eba that we consider.\nStarting with an initial set of arguments A\u1ed1, the deduction process generates a\nsequence of sets of arguments:\n\u0391\u03b4, \u0391\u0390, \u03912, ...\nWith each set of arguments A' there corresponds a belief set B. So we get a\nsequence of belief sets:\nB\u1ed1', B', B',...\nAlthough for the set of arguments there holds:\nA' \u2286 A + 1"}, {"title": "", "content": "such a property does not hold for the belief sets. Because a belief set B is deter-\nmined by evaluating the arguments A', the belief set can change in a non-monotonic\nway. J. W. Goodwin has called this the process non-monotonicity of the deduction\nprocess [10]. According to Goodwin this process non-monotonicity is just another\naspect of non-monotonic logics.\nIn the limit, when all the argument A have been derived, the corresponding\nbelief set Box will be equal to an extension of the reliability theory. Goodwin has\ncalled such this process of deriving the set of theorems, the logical process theory of\na logic [10]. The logical process theory focuses on the deduction process of a logic.\nIn this it differs from the logic itself, which only focuses on derivability; i.e. logics\nonly characterize the set of theorems that follow from the premisses.\nA deduction process for the logic starts with an initial set of arguments A\u1ed1. This\ninitial set Ao contains a supporting argument for every premiss. These arguments\nindicate that a proposition is believed if the corresponding premiss is believed."}, {"title": "Definition 10", "content": "Let \u2211 be a set of premisses. Then the set of initial arguments A' is defined as follows:\n\u0391\u03b4' = {{y} \u21d2 \u03c6|\u03c6\u03b5\u03a3}.\nEach set of arguments A' with i > 0 is generated from the set A by adding a new\nargument. How these arguments are determined, depends on the deduction system\nused. In the following description of the deduction process, I will use an axiomatic\ndeduction system for the language L, only containing the logical operators \u2192 and"}, {"title": "Axioms", "content": "The logical axioms are the tautologies of a propositional logic.\nBecause an axiomatic approach is used, arguments for the axioms have to be\nintroduced. Since an axiom is always valid, it must have an supporting argument\nwith an antecedent equal to the empty set. An axiom is introduced by the following\naxiom rule."}, {"title": "Rule 1", "content": "An axiom \u03c6 gets a supporting argument \u00d8\u21d2 \u03c6.\nIn the deduction system two inference rules will be used, namely the modus\nponens and the contradiction rule. Modus ponens introduces a new supporting\nargument for some proposition. This argument is constructed from the arguments\nfor the antecedents of modus ponens."}, {"title": "Rule 2", "content": "Let \u03c6 and \u03c6 \u2192 \u03c8 be two propositions with arguments, respectively P \u21d2 \u03c6\nand Q \u21d2 (\u03c6 \u2192 \u03c8).\nThen the proposition \u03c8 gets a supporting argument (PUQ) \u21d2 \u03c8."}, {"title": "Rule 3", "content": "Let \u03c6 and \u00ac\u03c6 be propositions with arguments P \u21d2 \u03c6 and Q \u21d2 \u00ac\u03c6 and let\n\u03b7 = min<(PUQ) where the function min selects the minimal element given\nthe extended reliability relation \u4eba'.\nThen the premiss \u03b7 gets an undermining argument ((PUQ)/\u03b7) \u2260 \u03b7.3\nIn order to guarantee that the current set of believed premisses will approximate\na most reliable consistent set of premisses, we have to guarantee that the process\ncreating new arguments is fair; i.e. the process does not forever defer the addition\nof some possible argument to the set of arguments."}, {"title": "Assumption 11", "content": "The reasoning process will not defer the addition of any possible\nargument to the set of arguments forever.\nIf a fair process is used, the following theorems hold. The first theorem guarantees\nthe soundness of the supporting arguments; i.e. the antecedent of a supporting argu-\nment logically entails the consequent of the supporting argument. The second the-\norem guarantees the completeness of the supporting arguments; i.e. if a proposition\nis logically entailed by a subset of the premisses, then there exists a corresponding\nsupporting argument. Finally, the third and fourth theorem guarantee respectively\nthe soundness and the completeness of the undermining arguments."}, {"title": "Theorem 12 Soundness", "content": "For each i > 0:\nif P \u21d2 y \u2208 A, then:\nP\u2286\u03a3 and P = 4."}, {"title": "Theorem 13 Completeness", "content": "For each P\u2286 \u03a3:\nif P = 4, then there exists a Q \u2286 P such that for some i > 0:\nQ\u21d2 \u03c6\u2208 A."}, {"title": "Theorem 14 Soundness", "content": "For each i > 0:\nif P # \u03c6 \u2208 A, then:\n(PU{}) \u2286 \u03a3, and (P\u222a {4}) is not satisfiable."}, {"title": "Theorem 15 Completeness", "content": "For each P\u2286 \u03a3:\nif P is a minimal unsatisfiable set of premisses and 6 = min(P), where\nthe function min selects the minimal element given the extended relia-\nbility relation \u4eba', then for some i > 0:\nP\\\u03c6# \u03c6\u2208 \u0391\u0384."}, {"title": "Definition 16", "content": "Out' (S) = {4 | P\u2260 y \u2208 A, and P C S}\nThe set of premisses \u2206' must, of course, be equal to the set of premisses obtained\nafter removing all the premisses we may not believe; i.e. \u0394' = \u03a3\\Out"}, {"title": "Definition 17", "content": "Let \u2211 be a set of premisses and let A be a set of arguments. Then\nthe set of premisses \u2206 that can be assumed to be true, is defined as:\n\u0394 = \u03a3\\Out"}, {"title": "Property 18", "content": "For every i, the set \u2206 exists and is unique.\nAfter determining the set of premisses that can be believed, the set of derived\npropositions that can be believed can be derived from the supporting arguments.\nThis set is defined as:"}, {"title": "Definition 19", "content": "Let A be a set of arguments and \u2206' be the corresponding set of\npremisses that may assumed to be true.\nThe set of propositions B that can be believed (the belief set) is defined as:\nB' = {\u03c8 \\ P \u21d2 \u03c8 \u2208 A\u0390' and P \u2286 }."}, {"title": "Property 20", "content": "For each y \u2208 B: \u2206 \u25236."}, {"title": "Definition 21", "content": "A = U i\u22650 A'"}, {"title": "Property 22", "content": "\u25b3 is maximal consistent."}, {"title": "Property 23", "content": "B = Th(\u25b3)\nwhere Th(S) = {y | Sy}"}, {"title": "", "content": "The following theorem implies that the characterization of the theorems of the\nlogic, given in the previous section, is equivalent to the intersection of the belief sets\nthat can be derived."}, {"title": "Theorem 24", "content": "Let (\u2211, \u4eba\u3009 be a reliability theory.\nThen there holds:\nR = {A | for some linear extension of \u4eba, A can be derived}."}, {"title": "Corollary 25", "content": "Th((, )) = \u2229B | for some linear extension \u4eba' of \u4eba}."}, {"title": "5 Determination of the belief set", "content": "In this section I will describe the algorithms that determine the set of premisses\nthat can be believed and the belief set, given a set of undermining arguments. The\nfirst algorithm determines the set given the arguments A. To understand\nhow the algorithm works, recall that the consequent of an undermining argument\nis less reliable than the premisses in the antecedent. Therefore, if the consequent of\nan undermining argument P \u2260 4 is the most reliable premiss that can be remove,\nbecause we still belief the premisses in the antecedent P, removing will never\nhave to be undone. After having removed \u03c6 we can turn to the next most reliable\nconsequent of an undermining argument.\nThe time complexity of the algorithm below depends on the for and the repeat\nloop. The former loop can be executed in O(n) steps where n in the number of\nundermining arguments. The latter loop can be executed in O(m) steps where m\nin the number of premisses in \u03a3. Therefore, the whole algorithm can be executed\nin O(n\u00b7m) steps."}, {"title": "6 The semantics for the logic", "content": "The semantics of the logic is based on the ideas of Y. Shoham [22, 23]. In [22, 23]\nShoham argues that the difference between monotonic logic and non-monotonic logic\nis a difference in the definition of the entailment relation. In a monotonic logic a\nproposition is entailed by the premisses if it is true in every model for the premisses.\nIn a non-monotonic logic, however, a proposition is entailed by the premisses if it is\npreferentially entailed by a set of premisses; i.e. if it is true in every preferred model\nfor the premisses. These preferred models are determined by defining an acyclic\npartial preference order on the models.\nThe semantics for the logic differs slightly from Shoham's approach. Since the\nset of premisses may be inconsistent, the set of models for these premisses can be\nempty. Therefore, instead of defining a preference relation on the models of the\npremisses, a partial preference relation on the set of semantic interpretations for the\nlanguage is defined. Given such a preference relation on the interpretations, the"}, {"title": "", "content": "models for a reliability theory are the most preferred semantic interpretations. The\npreference relation used here is based on the following ideas.\n\u2022 The premisses are assumptions about the world we are reasoning about.\n\u2022 We are more willing to give up believing a premiss with a low reliability than\na premiss with a high reliability.\nTherefore, an interpretation satisfying more premisses with a higher reliability (\u4eba)\nthan some other interpretation, is preferred (\u2282) to this interpretation."}, {"title": "Example 26", "content": "Let M and N be two interpretations. Furthermore, let M satisfy\na and \u03b2, and let N satisfy \u03b2 and \u03b3. Finally let a be more reliable than \u03b3,\n\u03b3 \u4eba \u03b1. Clearly, we cannot compare M and N using the premiss \u03b2. M and\nN can, however, be compared using the premisses a and \u03b3. Since a is more\nreliable than \u03b3, since N does not satisfy a and since M does not satisfy \u03b3, \u039c\nmust be preferred to N,"}, {"title": "Definition 27", "content": "An interpretation Mis a set containing the atomic propositions\nthat are true in this interpretation."}, {"title": "Definition 28", "content": "Let M be a semantic interpretation and let \u2211 be a set of premisses.\nThen the premisses Prem(M) \u2286 \u03a3 that are satisfied by M, are defined as:\nPrem(M) = {\u03c6| \u03c6 \u2208 \u03a3 and M = \u03c6}"}, {"title": "Definition 29", "content": "Let (\u2211, \u4eba\u3009 be a reliability theory. Furthermore, let \u531a be a preference\nrelation on the interpretations.\nFor every interpretation M, N there holds:\nMCN if and only if Prem(M) \u2260 Prem(N) and for every\n\u03c6\u2208 (Prem(M)\\Prem(N)), there is a \u03c8 \u2208 (Prem(N)\\Prem(M)) such\nthat:\n\u03c6\u03b1\u03c8.\nThe preference relation on the interpretations has the following property:"}, {"title": "Property 30", "content": "Let \u3008\u2211, \u4eba\u3009 be a reliability theory and let \u531a be the preference relation\nover interpretations defined the reliability theory.\nis irreflexive and transitive.\nGiven the preference relation on the interpretations, the set of models for the\npremisses can be defined."}, {"title": "Definition 31", "content": "Let\u3008\u2211, \u4eba\u3009 be a reliability theory and let Mod ((\u2211, \u4eba)) denote the\nmodels for the reliability theory."}, {"title": "", "content": "M\u2208 Mod((\u2211, \u4eba)) if and only if there exists no interpretation N such\nthat:\nMEN.\nNow the following important theorem, guaranteeing the soundness and the com-\npleteness of the logic, holds:"}, {"title": "Theorem 32", "content": "Let\u3008\u2211, \u4eba\u3009 be a reliability theory. Furthermore, let R be the corre-\nsponding set of all most reliable consistent sets of premisses. Then:\nMod((\u03a3, <)) = U \u2200D\u2208R Mod(\u25b3)\nwhere Mod(S) denotes the set of classical models for a set of propositions S."}, {"title": "7 Some properties of the logic", "content": "In this section I will discuss some properties of the logic. Firstly, I will relate the\nlogic to the general framework for non-monotonic logics described by S. Kraus,\nD. Lehmann and M. Magidor [12]. Secondly, I will compare the behaviour of the\nlogic when new information is added with G\u00e4rdenfors's theory for belief revision [8]."}, {"title": "7.1 Preferential models and cumulative logics", "content": "In [12] Kraus et al. describe a general framework for the study of non-monotonic\nlogics. They distinguish five general logical systems and show how each of them can\nbe characterized by the properties of the consequence relation. Furthermore, for each\nconsequence relation a different class of models is defined. The consequence relations\nand the classes of models are related to each other by representation theorems.\nThe consequence relation relevant for the logic discussed here is the preferen-\ntial consequence relation of system P. I will show that the preference relation on\nthe semantic interpretations, described in the previous section, corresponds to a\npreferential model described by Kraus et al."}, {"title": "Lemma 33", "content": "Let \u3008\u2211, <\u3009 be a reliability theory. Furthermore, let \u00e2 = {M | M = \u03b1},\nlet \u03a3' = \u03a3\u222a {a} and let \u4eba' = (\u3145\u2229 (\u03a3\\a \u00d7 \u03a3\\\u03b1)) \u222a {{\u03c6, \u03b1) | \u03c6\u0395\u03a3\\\u03b1}.\nThen M\u2208 Mod,((\u2211', \u3145')) if and only if M\u2208\u00e2 and for no N\u2208\u00e2:\nMEN."}, {"title": "Theorem 34", "content": "Let\u3008\u2211, \u4eba\u3009be a reliability theory. Moreover, let (S,l, <) be a triple\nwhere the set of states S is the set of all possible interpretations for the\nlanguage L, where l : S \u2192 S is the identity function, and where for each\nM,N \u2208 S:\nM < N if and only if N \u531a \u041c.\nThen (S, l, <) is a preferential model [12]."}, {"title": "Theorem 35", "content": "Let W = (S,1,<) be a preferential model for\u3008\u2211, \u4eba\u3009. Then the\nfollowing equivalence holds:\naw if and only if\n\u03a3' = \u03a3\u03c5{a},\nU\n\u3145' = (\u3145\u2229 (\u03a3\\a \u00d7 \u03a3\\\u03b1)) \u222a {{\u03c6, \u03b1) | \u03c6\u0395\u03a3\\\u03b1}\nand \u03b2\u2208 Th((\u03a3', \u3145'))."}, {"title": "Corollary 36", "content": "Let W = (S,l, <) be a preferential model for (\u2211, \u4eba).\nThen:\nTh((\u03a3, <)) = {a|wa}"}, {"title": "7.2 Belief revision", "content": "In [8], G\u00e4rdenfors describes three different ways in which a belief set can be revised,\nviz. expansion, revision and contraction. Expansion is a simple change that follows\nfrom the addition of a new proposition. Revision is a more complex form of adding a\nnew proposition. Here the belief set must be changed in such a way that the resulting\nbelief set is consistent. Contraction is the change necessary to stop believing some\nproposition. For each of these forms of belief revision, G\u00e4rdenfors has formulated a\nset of rationality postulates.\nIn this subsection I will investigate which of the postulates are satisfied by the\nlogic. To be able to do this, the set of theorems of a reliability theory is identified\nas a belief set as defined by G\u00e4rdenfors. Here expansion, revision and contraction of\nthe belief set K, with respect to the proposition a, will be denoted by respectively:\nK+[a], K*[a] and K-[a]."}, {"title": "Theorem 37", "content": "Let belief set K = Th((\u03a3, <)) be the set of theorems of the reliability\ntheory (\u03a3, <).\nSuppose that K*[a] is the belief set of the premisses \u2211\u222a {a} with reliability\nrelation:\nU\n\u3145' = (\u3145\u2229 (\u03a3\\a \u00d7 \u03a3\\\u03b1)) \u222a {{\u03c6, \u03b1) | \u03c6\u0395\u03a3\\\u03b1};\ni.e. K*[a] = {\u03b2 | \u03b1w \u03b2} where W is a preferential model for (\u2211, \u4eba).\nThen the following postulates are satisfied.\n1. K*[a] is a belief set.\n2. \u03b1 \u2208 \u039a*[\u03b1].\n6. If \u251c\u03b1 \u2194 \u03b2, then K*[a] = K*[\u03b2]."}, {"title": "8 Extension to first order logic", "content": "The logic described in the previous sections can be extended to a first order logic.\nTo realize this we have to replace the propositional language L by a first order\nlanguage, which only contains the logical operators \u00ac and"}]}