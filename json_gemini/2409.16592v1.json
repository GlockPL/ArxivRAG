{"title": "MambaJSCC: Adaptive Deep Joint Source-Channel Coding with Generalized State Space Model", "authors": ["Tong Wu", "Zhiyong Chen", "Meixia Tao", "Yaping Sun", "Xiaodong Xu", "Wenjun Zhang", "Ping Zhang"], "abstract": "Lightweight and efficient neural network models for deep joint source-channel coding (JSCC) are crucial for semantic communications. In this paper, we propose a novel JSCC architecture, named MambaJSCC, that achieves state-of-the-art performance with low computational and parameter overhead. MambaJSCC utilizes the visual state space model with channel adaptation (VSSM-CA) blocks as its backbone for transmitting images over wireless channels, where the VSSM-CA primarily consists of the generalized state space models (GSSM) and the zero-parameter, zero-computational channel adaptation method (CSI-ReST). We design the GSSM module, leveraging reversible matrix transformations to express generalized scan expanding operations, and theoretically prove that two GSSM modules can effectively capture global information. We discover that GSSM inherently possesses the ability to adapt to channels, a form of endogenous intelligence. Based on this, we design the CSI-ReST method, which injects channel state information (CSI) into the initial state of GSSM to utilize its native response, and into the residual state to mitigate CSI forgetting, enabling effective channel adaptation without introducing additional computational and parameter overhead. Experimental results show that MambaJSCC not only outperforms existing JSCC methods (e.g., SwinJSCC) across various scenarios but also significantly reduces parameter size, computational overhead, and inference delay.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep learning-based joint source-channel coding (JSCC), which integrates source and channel coding into a single process using neural networks, has recently garnered significant attention as a method to enhance the efficiency of information transmission over wireless channels. Leveraging deep learning, JSCC can effectively extract and utilize the semantic features of data, which are critical for understanding the meaning of information in task-specific contexts. Consequently, JSCC is emerging as a key technology for enabling semantic communications [2], [3], a pivotal element in the development of sixth-generation wireless networks [4]\u2013[6].\nRecent research on JSCC has primarily focused on finding suitable approaches to maximize end-to-end performance. For text transmission, [7] proposes a JSCC framework with a joint iterative decoder to improve quality. For video transmission, [8] introduces a deep video semantic transmission system based on JSCC to optimize overall performance. For specialized content types, such as point cloud, [9] proposes an appropriate JSCC architecture. Channel state information (CSI) estimated at the receiver is transmitted back to the transmitter utilizing JSCC in [10]. For image transmission, DeepJSCC, proposed in [11], relies on convolutional neural networks (CNNs) and outperforms traditional separation-based schemes, e.g., JPEG2000 and capacity-achieving channel code. To further improve JSCC performance, [12], [13] develop the backbone module of JSCC from CNN to Vision Transformer (ViT). Furthermore, with the emergence of the Swin Transformer [14], SwinJSCC has been proposed in [15], which replaces CNNs with Swin Transformers. It is adopted in [16] to replace ViT as an improved version of [13].\nMeanwhile, channel adaptation methods, which help mitigate performance degradation caused by the mismatch of channel states between training and evaluation stages, are essential for improving the performance of a single model across a wide range of channel conditions. These methods also reduce the training burden and save parameters of multiply JSCC models. ADJSCC, proposed in [17], utilizes the attention feature modules to incorporate the signal-to-noise (SNR) into the coding process. Hyper-AJSCC is introduced in [18], which employs a hypernetwork to adjust the parameters based on the SNR, achieving similar performance to ADJSCC with significantly fewer parameters and computational overhead. A Gated net is proposed in [19] that filters semantics according to varying SNRs. These works focus on channel adaptation methods for CNN-based models. For Transformer-based models, [15] introduces a plug-in module called Channel ModNet. A semantic-aware adaptive channel encoder is developed in [20] for integrating SNR. Additionally, [21] proposes the CSI Embedding method, integrating multi-user SNRs into the Swin Transformer blocks in each coding stage, achieving similar performance to Channel ModNet with far fewer parameters and computational overhead.\nUndoubtedly, designing deep learning-based JSCC models involves more than just optimizing end-to-end performance across varying channel states; it also requires balancing the complexity of artificial intelligence (AI) algorithms. This complexity typically includes computational overhead and the number of parameters. Computational overhead directly impacts inference delay (ID), and the larger the number of parameters, the greater the challenge of deploying these models on resource-constrained devices such as edge devices. Performance and complexity are mainly influenced by two core factors: the backbone model structure (e.g., CNN or Transformer) and the channel adaptation method. For backbone model structures, CNN-based models such as DeepJSCC and ADJSCC are often considered inadequate due to the inherent limitations of CNNs. In contrast, Transformer-based models like SwinJSCC offer superior performance, leveraging the advanced Swin Transformer, though this comes at the cost of higher computational and parameter overhead. Regarding channel adaptation methods, previous approaches have introduced additional modules to integrate CSI, similar to plug-in intelligence, which increases the complexity of a single model. For example, Channel ModNet in SwinJSCC adds an extra 9.87M parameters and 3.47G multiply-accumulate operations (MACs) for images of 512 \u00d7 512 size.\nMore recently, a novel AI model structure called Mamba, proposed in [22], has attracted significant attention in the Al community. Mamba is based on selective structure state space models (SSM), which enable it to process sequences with data-dependent dynamic weights in linear complexity. As a result, Mamba achieves remarkable performance in natural language processing tasks while maintaining low computational complexity and parameter overhead compared to Transformers. Mamba-2 [23] further demonstrates the equivalence between Mamba and linear attention. In the field of computer vision [24], VMamba, proposed in [25], is used for visual representation learning by cross expanding the image in four directions, achieving promising results in vision tasks. Subsequently, [26]\u2013[29] explored various scan directions for improved learning. However, the lack of a unified mathematical expression for all scan expansion techniques limits the mathematical derivation necessary to ensure Vision Mamba's ability to capture global information. Furthermore, to the best of our knowledge, no research has yet explored the integration of Mamba with channel adaptation methods.\nTo address these challenges, we propose a novel, lightweight, and efficient JSCC method based on Mamba, named MambaJSCC, for image transmission over wireless channels. Specifically, we apply a reversible matrix transformation to unify all the scan expanding operations into a mathematical expression, enabling the SSM to be equipped with arbitrary scan schemes as a generalized SSM (GSSM). Based on this mathematical expression, we theoretically prove that two GSSM modules are sufficient to capture global information, thus achieving superior performance. More interestingly, by analyzing Mamba's unique response to the initial state, we discover that GSSM inherently possesses the ability to adapt to channels, a form of endogenous intelligence. Building on this insight, we develop a zero-parameter, zero-computation channel adaptation method, called CSI-ReST, for Mamba-JSCC. The proposed CSI-ReST method injects the CSI into the initial state of the GSSM. As the state is continuously updated, the CSI gradually fades. To address this, inspired by the ResNet [30] approach, CSI-ReST also injects the CSI into the residual state of the GSSM benefitting from its high-dimension characteristic, enabling channel adaptation without incurring additional computational and parameter overhead. Consequently, the two GSSM modules with CSI-ReST, combined with a door-control structure, form the VSSM-CA modules. Utilizing the powerful VSSM-CA modules as the backbone, MambaJSCC is designed in a hierarchical structure with multi-stages to handle varying numbers of patches of different sizes, aiming for effective encoding and decoding. The main contributions of the paper are summarized as follows.\nArchitecture Design: We propose MambaJSCC, a novel JSCC architecture that offers state-of-the-art performance with significantly low computational and parameter overhead. In the MambaJSCC architecture, the VSSM-CA module with GSSM serves as the backbone model structure, and the endogenous intelligence-based CSI-REST is used as the channel adaptation method. The architecture is hierarchical and multi-stages to handle patches at varying numbers and different resolutions.\nTheoretical Analysis: We design the GSSM module, utilizing reversible matrix transformations to describe arbitrary generalized scan expanding operations. Furthermore, we derive the closed-form expression for the output of the GSSM module. For the first time, we theoretically prove that the two GSSM modules with bidirectional scanning, similar to Transformers, are capable of effectively capturing global information.\nCSI-REST Method: We develop the zero-parameter, zero-computation CSI-ReST method to leverage the endogenous capability of GSSM for channel adaptation. This method injects the CSI into the initial state to harness the native response and into the residual state to mitigate CSI forgetting, enabling effective channel adaptation without introducing additional computational and parameter overhead.\nExperiments Evaluation: We conduct extensive experiments using diverse data with varying contents and resolutions. The results show that MambaJSCC outperforms all major JSCC architectures in terms of distortion and perception. Furthermore, compared to SwinJSCC with same block number, MambaJSCC exhibits a significantly reduced parameter size, computational overhead, and inference delay e.g., 0.52 dB gain in peak-signal-to-noise ratio (PSNR) while requiring only 72% MACs, 51% of the parameters, and 91% of ID."}, {"title": "II. SYSTEM MODEL OF MAMBAJSCC", "content": "State space models are a class of sequential neural network models inspired by linear time-invariant (LTI) systems and are closely related to CNNs and recurrent neural networks (RNNs). In general, an LTI system maps a one-dimension (1D) function or sequence $x(t) \\in \\mathbb{R}$ to another one-dimension function or sequence $y(t) \\in \\mathbb{R}$ through a latent state space $h(t) \\in \\mathbb{R}^{N}$. Here, N represents the dimension of the latent state space. This process can be formulated using linear ordinary differential equations (ODEs) as follows:\n$h'(t) = Ah(t) + Bx(t), \\quad y(t) = Ch(t),$\nwhere $A \\in \\mathbb{R}^{N\\times N}$, $B\\in \\mathbb{R}^{N\\times 1}$, and $C \\in \\mathbb{R}^{1\\times N}$ are the state matrix, input matrix, and output matrix, respectively.\nThe OEDs represent continuous-time systems, allowing the matrices to naturally become time-varying. Meanwhile, to integrate these continuous-time systems into deep learning frameworks, a discretization process is required. A widely-adopted method for discretization is the zero-order hold (ZOH) rule. The time-varying and discretized version of A, B, C are expressed as $A = A_{1:T} \\in \\mathbb{R}^{T \\times N \\times N}$, $B = B_{1:T} \\in \\mathbb{R}^{T \\times N \\times 1}$, $C = C_{1:T} \\in \\mathbb{R}^{T \\times 1 \\times N}$. The sequence x(t) is discretized as $x \\in \\mathbb{R}^{T}$. The corresponding system output is $y \\in \\mathbb{R}$, and the discretized hidden state is represented by $h \\in \\mathbb{R}^{T \\times N}$, where T is the length of the sequence. In this paper, we use the subscript $t \\in 1, 2, ..., T$ on these matrices and sequences to represent their values at time t. Therefore, (1) can be rewritten in its discrete, and time-varying form as follows [23]:\n$h_t = A_t h_{t-1} + B_t x_t, \\quad Y_t = C_t h_t.$\nFor two-dimension (2D) sources, such as images, a commonly used and well-developed method for SSM is the scan expanding and scan recovery method [24]\u2013[29]. This method flattens a 2D patch to several 1D sequences in designated directions, followed by SSMs. After that, these sequences are reconstructed back into 2D patches in the corresponding directions, and merged by adding together into one patch."}, {"title": "B. An Overview of MambaJSCC", "content": "The overall architecture of MambaJSCC is illustrated in Fig. 1(a). In the transmitter, the input image $s \\in \\mathbb{R}^{3 \\times P \\times W}$ is encoded into the channel input signal $q \\in \\mathbb{C}^{c \\times p \\times w}$ by the MambaJSCC encoder, where $P$ and $W$ represent the height and width of the source image and c, p, w denote the patch number, height and weight of the channel input signal, respectively. This encoding process involves $l_e$ coding stages and a convolution compression module.\nIn the first coding stage, the input image s is initially fed into a 2D patch embedding module, which outputs $c_1$ patches, each of size $p_1 \\times W_1$. These patches are processed by $n_1$ VSSM-CA blocks, which incorporate the CSI to adaptively extract and encode features from the patches, while maintaining their number and size. The output patches are then fed into Stage 2, where a patch merging module is applied. This module merges the $c_1$ patches of size $p_1 \\times w_1$ into a greater number of patches $c_2$, with a smaller size $p_2 \\times W_2$, to capture more refined information. Following the merging, $n_2$ VSSM-CA blocks with CSI are employed to process these patches. This process is repeated for $(l_e - 1)$ stages in the MambaJSCC encoder, where each stage $k$ ($k = 2, 3, ..., l_e$) involves the patch merging module producing $c_k$ patches of size $p_k \\times w_k$, followed by $n_k$ VSSM-CA blocks processing the patches. At the final stage of the encoder, the output patches are fed into a convolution compression module, where a CNN compresses the patches to the designated number of channel uses. After compression, the patches are normalized for power and transmitted over the wireless channel, which is assumed to be either an additive white Gaussian noise (AWGN) channel or a Rayleigh fading channel.\nAt the receiver, the MambaJSCC decoder first applies an equalizer, such as the minimum mean square error (MMSE) equalizer, to equalize the received signal r in the case of the Rayleigh fading channel. It then decodes the signal into $\\hat{s} \\in \\mathbb{R}^{3 \\times P \\times W}$ for reconstruction. The MambaJSCC decoder consists of $l_d$ decoding stages and a convolution expanding module. Specifically, after equalization, the convolution expanding module expands the equalized signal into $c_{l_d}$ 2D patches, each with size $p_{l_d} \\times W_{l_d}$, matching the output patches from Stage $l_e$ in the encoder. These patches are then fed into $l_d$ concatenated stages, denoted as Stage $k$, $k = l_d, l_{d-1}, ..., 1$. For $k > 2$, each stage initially decodes the patches using $n_k$ VSSM-CA blocks along with the CSI, which is obtained via channel estimation. The output patches are then divided into fewer but larger patches $c_{k-1}$ with size $p_{k-1} \\times W_{k-1}$. This step is performed by a 2D patch division module that first applies layer normalization to the input patches, followed by a full-connection (FC) layer that adjusts the number of patches from $c_{k}$ to $c_{k-1} \\times p_{k-1}w_{k-1}$. The goal of expanding the number of patches is to organize every $p_{k-1}w_{k-1}$ patches into $c_{k-1}$ groups. Within each group, a pixel shuffle operation is performed to cyclically select elements, creating a new patch that is with $p_{k-1}w_{k-1}$ times larger size. As a result, the module outputs $c_{k-1}$ new patches, each with a larger size of $p_{k-1} \\times W_{k-1}$. In Stage 1, the 2D patch division module outputs three patches, each with size $P \\times W$ for reconstruction.\nThe MambaJSCC encoder and decoder are jointly trained with the objective of minimizing the distortion between the input image and the reconstructed image. Therefore, the loss function $L$ is formulated as follows:\n$L = d(s,\\hat{s}),$\nwhere d(.) is the distortion or perception loss function."}, {"title": "III. THE DESIGN OF VSSM-CA MODULE", "content": "In this section, we discuss the two core technologies for the VSSM-CA module: the GSSM and the CSI-ReST channel adaptation method. Using these two core technologies, we present the overall structure of the VSSM-CA module."}, {"title": "A. The GSSM Module", "content": "To develop the GSSM module for capturing global information, we establish a unified mathematical expression for the SSM module with arbitrary extended scan expanding and recovery operations based on matrix transformation.\nDefinition 1. SSM operator is defined as a sequence transformation, which is a parameterized mapping from a sequence $x \\in \\mathbb{R}^{T}$ to another sequence $y \\in \\mathbb{R}^{T}$ as defined in (2). This mapping is denoted as $y = SSM(A, B, C)(x) = SSM(A_{1:T}, B_{1:T}, C_{1:T})(x)$, where $A_{1:T}, B_{1:T}$ and $C_{1:T}$ are the parameters of the operator, and T refers to the sequence length.\nThus, the operations in the SSM modules are represented by an operator parameterized by $A_{1:T}, B_{1:T}$ and $C_{1:T}$.\nDefinition 2. Matrix transformation is defined as a special case of sequence transformation, where the transformation can be written in the form $y = M_{\\theta} x$, with $M_{\\theta}$ being a matrix derived from the parameters $\\theta$. For simplicity and clarity, we denote the matrix as $M$, omitting the parameters $\\theta$ when they are clear from context.\nAccordingly, the relationship between the SSM operator with $h_0 = 0$ and the matrix transformation is established in [23], which is given by\n$y = SSM(A, B, C)(x) = M x,$\nwhere the element in the i-th row and j-th column of M is derived as $C A^{i:j} B$. Here, I is the identity matrix, and\n$A^{i:j} = \\begin{cases} 0, & i < j, \\\\ I, & i = j, \\\\ A_i A_{i-1} ... A_{j+1}, & i > j. \\end{cases}$\nThe key technology in extending 1D SSM to 2D vision SSM (VSSM) for vision tasks is the scan expansion approach. Using this approach, VSSM first unfolds the 2D visual features into several 1D sequences. These sequences are then processed by the SSM operator and subsequently reassembled into the 2D feature. The scan directions dictate the unfolding process, playing a crucial role in VSSM's ability to effectively learn and capture visual features.\nTo investigate the influence of different scan directions on the VSSM module, it is necessary to define a unified mathematical expression for both the scan directions and the SSM. By analyzing their characteristics, we can observe that the scan expanding operation rearranges the elements of a 2D feature into a 1D sequence, with the scan directions determining the positions of the elements in the sequence. Thus, the essence of scan directions is the reordering of vectorized features. This reordering can be viewed as the application of a finite number of row-swapping transformations to the vectorized feature. From this aspect, the scan expanding process in a specific direction can be expressed as a combination of a vectorization operation and a matrix transformation derived from finite row-swapping operations. We thus have the following proposition.\nProposition 1. The Scan Expanding from a 2D feature Z to a 1D sequence $x_{\\zeta}$ in the direction $\\zeta$ can be formulated as\n$x_{\\zeta} = R_{\\zeta} vec(Z) = R_{\\zeta} z,$\nwhere $R_{\\zeta}$ is derived by transforming the identity matrix with a finite number of row swapping operations and z is the normally vectorized form of Z."}, {"title": "Proof.", "content": "Based on the aforementioned scan expansion operation, this proposition can be easily derived.\nThe VSSM module processes the sequence $x_{\\zeta}$ using the SSM operator, resulting in y, which can be formulated as:\n$y = SSM(A, B, C)(x_{\\zeta}).$\nNext, y needs to be reordered back to its original sequence before being reshaped into the 2D output. This recovery operation can also be expressed as a matrix transformation:\n$y^* = R_{\\zeta}^{-1} y.$\nFinally, $y^*$ is reshaped as the 2D feature output $Y_{\\Gamma}$.\nRemark 1. The inverse of $R_{\\zeta}$ is used to restore the order of y to $y_{\\zeta}$. In (8), we apply $R_{\\zeta}^{-1}$ for the recover process because the $R_{\\zeta}$ is obtained by applying a finite number of row-swapping operations to the identity matrix. Therefore, the inverse of $R_{\\zeta}$ is $R_{\\zeta}^{-1}$.\nUpon reviewing the computational flow of the VSSM module, we observe that it can be regarded as a sequence mapping module with a normal vectorization module and a module normally reshaping a vector to a matrix. The core component of the VSSM module is the sequence mapping module, which determines its key characteristics. In the VSSM module, the sequence mapping module can be seen as an SSM operator combined with a matrix $R_{\\zeta}$ to reorder the input and output sequence. Furthermore, we find from (6) and (8) that the only requirement for the sequence mapping module is that the input reordering operation must be reversible. As a result, we define GSSM to provide a more universal framework for understanding and designing the VSSM module.\nWe generalize the definition of $R_{\\zeta}$ by deriving it not only from row-swapping transformations but also from arbitrary elementary transformations, resulting in an invertible matrix.\nDefinition 3. The scan exchanging from a sequence z to a sequence x in the scheme $\\kappa$ can be formulated as follows:\n$x = R_{\\kappa} z,$\nwhere $R_{\\kappa}$ is an invertible matrix that depends on the scan scheme $\\kappa$.\nDefinition 4. The scan recovery from a sequence y to a sequence $y_{\\kappa}$ in the scheme $\\kappa$ can be formulated as follows:\n$y_{\\kappa} = R_{\\kappa}^{-1} y.$\nWith the generalized scan exchanging and scan recovery approach, we can define the GSSM module.\nDefinition 5. The GSSM module maps a sequence $z \\in \\mathbb{R}^{T}$ to a sequence $y \\in \\mathbb{R}^{T}$ with scheme $\\kappa$ and SSM operator SSM(A, B, C), denoted as $y = GSSM(A, B, C, \\kappa)(z)$. The module can be formulated as\n$x = R_{\\kappa} z,$\n$y = SSM(A, B, C)(x),$\n$y = R_{\\kappa}^{-1} y.$"}, {"title": "Proposition 2.", "content": "The mapping of the GSSM module with $h_0 = 0$ can be represented as a matrix transformation as following\n$y = GSSM(A, B, C, \\kappa)(z) = U_{\\kappa} z,$\nwhere we have $U_{\\kappa} = R_{\\kappa}^{-1} M R_{\\kappa}$.\nProof. According to (4), the SSM operator in the GSSM can be expressed as\n$y = SSM(A, B, C)(x) = Mx.$\nSubstituting (15) and (11) into (13), we obtain\n$y^* = R_{\\kappa}^{-1} y = R_{\\kappa}^{-1} (Mx) = R_{\\kappa}^{-1} MR_{\\kappa} z.$\nLet $U_{\\kappa}$ be defined as $R_{\\kappa}^{-1} MR_{\\kappa}$. Thus we obtain (14).\nProposition 2 demonstrates that the scan exchanging and scan recovery operations in the GSSM module preserve the matrix transformation property. These operations merely convert the transformation matrix into its similar matrix based on the scan scheme $\\kappa$. The similarity transformations affect the perceptible elements in the GSSM module. For image transmission, it is crucial to capture the global elements of the vectorization image feature z efficiently. To achieve this, we design the use of two GSSM modules: one applies scan scheme $\\kappa_1$, where $R_{\\kappa_1}$ is the identity I, and the other adopts the scan scheme $\\kappa_2$, where the elements in row i and column j of matrix $R_{\\kappa_2}$ is 1 if $i + j = T + 1$. The outputs of both GSSM modules are then combined to produce the final output u, which can be derived as follows:\n$u = y^{*_1} + y^{*_2} = GSSM(A_1, B_1, C_1, \\kappa_1)(z) + GSSM(A_2, B_2, C_2, \\kappa_2)(z) = U_{\\kappa_1} z + U_{\\kappa_2} z.$"}, {"title": "Proposition 3.", "content": "The design in (17) is sufficient to capture global information.\nProof. We can write the matrices $U_{\\kappa_1}$ and $U_{\\kappa_2}$ in element wise. The elements in row i and column j of $U_{\\kappa_1}$ is\n$U_{ij}^{\\kappa_1} = C_i A^{i:j} B_j$\nand according to the definition of $R_{\\kappa_2}$, $U_{\\kappa_2}$ is obtained by reversing the arrangement in both row and column directions. The element in $U_{\\kappa_2}$ can be derived as\n$U_{ij}^{\\kappa_2} = C_{T+1-i} A_{T+1-i:T+1-j} B_{T+1-j}.$\nAccording to (17), the t-th element of u is\n$u_t = \\sum_{s=1}^{t} C_{t1} A_{t:s1} B_{s1} + \\sum_{s=t}^{T} C_{T+1-t2} A_{T+1-t:T+1-s2} B_{T+1-s2}.$\nAccording to (5), $A^x$ consists of learnable non-zero pa-rameters when s is in the summarization ranging from 1 to t. Similarly, $A^{x}$ contains learnable non-zero parameters when s is in the summarization ranging from t to T. Therefore, for any element ut in the output u, it can combine all input elements with learnable parameters, demonstrating that the designed module, expressed as (17), is capable of capturing global information."}, {"title": "B. CSI as Residual States for Channel Adaptation", "content": "To design the customized CSI-ReST method, we further explore the structural characteristics of the GSSM model and uncover other exploitable properties. Tracing back to its origins, the SSM model is built upon the continuous-time system state equation, as shown in (1). Mathematically, the solution to (1) can be expressed as follows:\n$h(t) = e^{\\bar{A}(t-t_0)} h(t_0) + \\int_{t_0}^{t} e^{\\bar{A}(t-\\tau)} B(\\tau) x(\\tau) d\\tau,$\n$y(t) = C e^{\\bar{A}(t-t_0)} h(t_0) + \\int_{t_0}^{t} C e^{\\bar{A}(t-\\tau)} x(\\tau) d\\tau.$\nIt can be observed that the output consists of both the zero-state response and the zero-input response. In conventional SSM models, only the zero-state response contributes to the output, even though both responses are calculated, leading to the zero-input response being underutilized. By analyzing the impact of the zero-input response on the GSSM model, we can explore how to leverage this otherwise wasted intrinsic feature for integrating CSI.\nProposition 4. The mapping of the GSSM module with any zero state $h_0$ can be represented as two independent matrix transformations applied to the input and the zero state as follows:\n$y = GSSM(A, B, C, \\kappa)(z, h_0) = Uz + Vh_0,$\nwhere $V = R_{\\kappa}^{-1} diag(C_1 A_{1:0}, C_2 A_{2:0}, ..., C_T A_{T:0})$.\nProof. According to (14), we expand the SSM operator in the GSSM module from its recurrent form to a matrix operations form. The hidden state ht with input $x^*$ for all t can be expressed as:\n$h_1 = A_1 h_0 + B_1 x_1,$\n$h_2 = A_2 h_1 + B_2 x_2 = A_2 A_1 h_0 + A_2 B_1 x_1 + B_2 x_2,$\n\\vdots\n$h_T = A^T h_0 + \\sum_{s=1}^{T} A^{T:s} B_s x_s.$\nTherefore, yt can be written as:\n$Y_t = C_t h_t = C_t A^t h_0 + \\sum_{s=1}^{t} C_t A^{t:s} B_s x_s.$\nVectorizing equation (25) over $t \\in [1, T]$, the sum of accumu-lations can be expressed in matrix multiplication form as the method deriving M. The first term can be rewritten in block matrices multiplication form by expressed it as matrix mul-tiplication with matrix $diag(C_1 A_{1:0}, C_2 A_{2:0}, \\ldots, C_T A_{T:0})$. Thus combining (16), we derive the expression in (23).\nFrom Proposition 4, we find that the GSSM module responds to the zero state $h_0$. This insight inspired us to propose CSI-ReST, a novel channel adaptation method that leverages the inherent (i.e., endogenous intelligence) adaptive capability of the GSSM. We first inject CSI into the first element of the initial hidden state of the GSSM modules by setting $h_{0,1} = SNR$ to leverage the inherent response and adjust the output sequence based on CSI for channel adaption.\nRemark 2. CSI forgetting: Equ. (25) also implies that the response involves the matrix $A_{1:T}$, which functions as a forgetting gate (e.g. with typical values ranging from 0.95 to 0.97), indicating $A_{t:0}$ becomes smaller as t increases (e.g. $6.37 \\times 10^{-11}$ at t = 500). This suggests that the influence of CSI on yt may diminish as t increases. This characteristic makes it difficult to effectively adjust the output based solely on the initial state.\nTo address the CSI forgetting problem, inspired by ResNet, the proposed CSI-ReST method samples certain residual states from {$h_0, h_1, ..., h_T$} at intervals of $l_s$ and sets their first element as SNR. In addition to inserting the SNR into the initial state $h_{0,1}$, CSI-ReST also inserts the SNR into residual states such as $h_{l_s,1}, h_{2l_s,1}$, and so on. The operation of the CSI-ReST method is\n$h_{t,1} = SNR, \\quad \\text{for } t = 0, 1, ..., T, t = 0 \\pmod{l_s}.$"}, {"title": "Algorithm 1", "content": "The algorithm of the two GSSM modules with CSI-REST.\nInput: Input sequence zi, The SNR of the channel SNR;\nOutput: Output sequence ui;\n$x^1 = R_{\\kappa_1}z_i, x^2 = R_{\\kappa_2}z_i;$\nfor $j = 1$ to 2 do\n$A = \\text{softplus}(x_{GH} + \\beta), B = H;$\n$A = \\text{exp}(\\tilde{A}^j), B = AB, C = (Hx)^T;$\n$h^j = 0, h_{0,1}^j = SNR;$\nfor $t = 1$ to T do\n$h_t^j = A h_{t-1}^j + B x_t;$\nif $t = 0 \\pmod{l_s}$ then\n$h_{t,1}^j = SNR;$\nend if\n$y_t^j = Ch;$\nend for\nend for\n$u_i = y^{*1} + y^{*2} = R_{\\kappa_1}^{-1}y^1 + R_{\\kappa_2}^{-1}y^2$\nadjusted according to CSI for effective channel adaptation. Meanwhile, the high-dimensional hidden states of GSSM allow it to store extensive knowledge from the past sequence. Therefore, using one dimension of the residual states to store CSI has little impact on the model's ability to process sequences but is crucial for refreshing CSI knowledge. In summary, the CSI-ReST method selects specific residual states from the GSSM and injects CSI into them to facilitate channel adaptation.\nRemark 3. CSI-ReST utilizes the recurrent structure and high-dimension state characteristics of GSSM. The recurrent form allows the SNR to be embedded in $h_0$, ensuring that the output sequence is adjusted based on CSI as described in (23). The high-dimension state space facilitates the refreshment of SNR to counteract forgetting, ensuring that all elements are sufficiently adjusted based on CSI.\nBenefitting from the characteristics of GSSMS, CSI-REST not only achieves excellent channel adaptation but also operates with zero parameters and zero computational overhead. CSI-REST consists solely of simple assignment operations, utilizing the existing computation and parameters of the GSSM modules. This process does not require any additional computation and additional parameters. Therefore, CSI-ReST achieves channel adaptation with zero parameter and computational overhead."}, {"title": "C. Overall Design of the VSSM-CA module", "content": "By integrating the proposed GSSM from (14), the global information design from (17), and the CSI-ReST channel adaptation method from (26), we develop the VSSM-CA module as the backbone module for MambaJSCC.\nThe overall architecture of the VSSM-CA module is shown"}]}