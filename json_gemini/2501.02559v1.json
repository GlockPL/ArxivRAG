{"title": "KM-UNet: KAN Mamba UNet for medical image segmentation", "authors": ["Yibo Zhang", "Jingwen Zhao", "Xiang Liu", "Xian Tang", "Yunyu Shi", "Lina Wei", "Guyue Zhang"], "abstract": "Medical image segmentation is a critical task in medical imaging analysis. Traditional CNN-based methods struggle with modeling long-range dependencies, while Transformer-based models, despite their success, suffer from quadratic computational complexity. To address these limitations, we propose KM-UNet, a novel U-shaped network architecture that combines the strengths of Kolmogorov-Arnold Networks (KANs) and state-space models (SSMs). KM-UNet leverages the Kolmogorov-Arnold representation theorem for efficient feature representation and SSMs for scalable long-range modeling, achieving a balance between accuracy and computational efficiency.\nWe evaluate KM-UNet on five benchmark datasets: ISIC17, ISIC18, CVC, BUSI, and GLAS. Experimental results demonstrate that KM-UNet achieves competitive performance compared to state-of-the-art methods in medical image segmentation tasks.\nTo the best of our knowledge, KM-UNet is the first medical image segmentation framework integrating KANs and SSMs. This work provides a valuable baseline and new insights for the development of more efficient and interpretable medical image segmentation systems. The code is open source at https://github.com/2760613195/KM_UNet", "sections": [{"title": "1. Introduction", "content": "In the past decade, significant progress has been made in medical image segmentation methods to meet the needs of computer-aided diagnosis and image-guided surgery systems [1][2][3]. U-Net[4] is a landmark in this field, demonstrating for the first time the effectiveness of encoder-decoder convolutional networks with skip connections in medical image segmentation[5][6]. Subsequently, a series of improvements to U-Net have emerged, such as U-Net++[7], 3D U-Net, and V-Net[8], which further expanded its application scope and performance. Moreover, hybrid architectures like U-NeXt combine convolutional operations with MLP to enhance the efficiency of segmentation networks, especially in resource-constrained environments.\nAt the same time, Transformer-based networks have gained attention for their ability to model long-range dependencies and global context[9][10]. For example, TransUNet[11] and Swin-UNet[12] leverage Vision Transformers (ViT)[13] and Swin Transformers[14], demonstrating powerful global modeling capabilities. However, despite their strong performance, these models demand high data volumes and computational resources, posing challenges in data-limited or real-time processing scenarios[15]\nIn recent years, structured state-space models (SSMs) have provided an efficient solution for modeling long sequences with linear computational complexity[16][18]. Models such as U-Mamba[17] and_SegMamba[19] have shown performance improvements by combining SSMs with CNNs in medical image segmentation. However, despite these innovations, existing U-Net variants still face fundamental challenges in kernel design and black-box attributes, which affect model interpretability and diagnostic reliability.\nTo address these challenges, this paper proposes a novel U-Net architecture, KM-UNet, which integrates Kolmogorov-Arnold Networks (KAN) and Selective-Scan Efficient Multi-scale (SEM) attention modules. KM-UNet consists of an encoder, a decoder, and skip connections. The encoder utilizes the SEM attention module for feature extraction, combined with patch merging operations for downsampling. The decoder incorporates the SEM attention module and patch expansion operations to restore the segmentation results to their original size. In the skip connections, we use simple addition to highlight the segmentation performance of the pure SSM model.With theoretical support from the Kolmogorov-Arnold equation, the KAN network provides inherent interpretability, significantly enhancing the network's transparency. This advantage bridges the gap between the network's physical properties and its actual performance, making the decision-making process of the model easier to understand and analyze. On the other hand, the Mamba module, inspired by Structured State-"}, {"title": "2. Related Work", "content": "Medical image segmentation has long been a research hotspot in both computer vision and healthcare due to its crucial role in clinical diagnosis and treatment[21][22]. U-Net, as a classic encoder-decoder architecture, has achieved significant breakthroughs in medical image segmentation by effectively capturing multi-scale features through skip connections. However, traditional CNN models, limited by their local receptive fields, struggle to capture global information adequately, leading to insufficient feature extraction and limited segmentation performance when processing complex images.\nThe introduction of Kolmogorov-Arnold Network (KAN) provides a new perspective to address these issues. The KAN network, with its highly interpretable structural design, compensates for the shortcomings of CNN models in modeling complex nonlinear relationships [20]. Its modular construction not only enhances the model's global context understanding but also establishes a strong connection between physical characteristics and empirical performance. In the field of medical image segmentation, combining the KAN network with U-Net not only leverages the multi-scale feature fusion advantage of U-Net but also improves the network's interpretability and global information capture capability, which is expected to enhance the model's stability and reliability in complex medical image segmentation tasks.[35]"}, {"title": "Integration of Mamba Module with U-Net for Enhanced Medical Image Segmentation", "content": "In recent years, the application of State Space Models (SSM) in long sequence modeling has gained significant attention, with modern SSMs, such as Mamba [23], demonstrating excellent performance in visual tasks due to their linear time complexity and efficient training process. Models like U-Mamba [17] have successfully combined SSM with CNNs, applying them for the first time in medical image segmentation tasks, showcasing their potential for handling complex anatomical structures. SegMamba [19] introduced the SSM module in the encoder while keeping CNNs in the decoder, creating a hybrid model for 3D medical image segmentation tasks, such as brain tumor segmentation, and achieving promising results. Integrating the Mamba module into the U-Net architecture enables the network to capture long-range dependencies and multi-scale features with minimal computational overhead, enhancing U-Net's global modeling capability and segmentation accuracy[36]. This integration lays a solid foundation for further advancements in efficient medical image segmentation methods. Additionally, multi-stream networks like PSA (Parallel Spatial Attention) improve feature representation in visual tasks by modeling long-range dependencies in parallel, though they introduce extra computational cost. Furthermore, while the triple attention mechanism enhances feature abstraction by combining cross-channel and spatial information, its simple averaging strategy for weight aggregation limits the discriminative power of deep features. On the other hand, multi-scale convolutions, such as those in Inception networks and selective convolutional networks, improve feature representation by adapting the receptive field through multi-branch structures. Our proposed multi-scale attention module optimizes global context capturing by leveraging cross-space learning during feature fusion, further improving segmentation performance."}, {"title": "3. Methodology", "content": "Overview Figure 1 illustrates the overall architecture of the proposed KM-UNet. The architecture adopts a three-stage encoder-decoder structure, consisting of the Convolution Phase, the Selective-Scan Efficient Multi-scale (SEM) attention module phase, and the tokenized Kolmogorov-Arnold Network (Tok-KAN Phase). In the encoder, the input image first passes through three convolution operations combined with SEM modules, followed by further processing through two tokenized MLP blocks. The decoder consists of two tokenized KAN blocks, followed by three convolution blocks. Each encoder module reduces the feature resolution by half, while each decoder module doubles the feature resolution.\nFurthermore, skip connections are integrated between the encoder and decoder to facilitate feature fusion. The number of channels in each module of the Convolution Phase and Tok-KAN Phase is defined by hyperparameters C\u2081 to C5 and D\u2081 to D5, respectively."}, {"title": "Selective-Scan Efficient Multi-scale (SEM) Attention Module", "content": "The Selective-Scan Efficient Multi-scale (SEM) attention module is designed to enhance the feature extraction and attention mechanism in the encoder and decoder stages of the U-Net network. The module consists of two main parts: the feature extraction part and the attention part."}, {"title": "Feature extraction", "content": "As shown in Figure 2, the feature extraction part draws inspiration from the SS2D module and improves upon its scanning approach to achieve more efficient feature capture and multi-directional feature extraction. Specifically, the input feature map is unfolded into sequences along multiple directions to capture rich spatial information. The improved scanning method not only includes standard directions such as from top-left to bottom-right and bottom-right to top-left but also introduces an adaptive scanning strategy that flexibly adjusts the scanning order to accommodate different input features.\nThe expression for each scanning direction is as follows:\n$$X_{(dir)} = Scan(X,direction)$$\nWhere direction\u2208 {top-left to bottom-right, top-right to bottom left, bottom-right to top-left, bottom-left to top-right}. The scan result from each direction is passed through the improved S6 block for feature extraction, where the S6 block dynamically adjusts its parameters based on the input to filter and retain the most important features. Subsequently, as illustrated in Figure 2, the Re-weight operation sums and merges the sequences from the four directions, restoring the output image to the same size as the input. The S6 block, derived from Mamba [16], introduces a selective mechanism on top of S4"}, {"title": "Multi-Scale Attention", "content": "The multi-scale attention module uses two parallel convolutional sub-networks to capture both short-range and long-range spatial dependencies, avoiding the common issue of channel dimensionality reduction. By reshaping the channel dimension of the input feature map into the batch dimension and using different convolution kernels, it ensures efficient computation while preserving key feature information from medical images.\nFirst, the input feature map X with dimensions [B,C,H,W] (where B is the batch size, C is the number of channels, H and W are the height and width) is reshaped to a new form X', preserving more feature information:\n$$X' = reshape(X)$$\nThen, the attention mechanism captures spatial dependencies using two parallel sub-networks. One uses a 1\u00d71 convolution to model local channel interactions, while the other uses a 3\u00d73 convolution to capture broader spatial relationships:\n$$X_{cross} = Conv_{1x1}(X) + Conv_{3x3}(X)$$\nFinally, the outputs of both sub-networks are aggregated to generate the final feature map Y, which combines multi-scale information to improve feature representation:\n$$Y = Aggregation(X_{cross})$$\nThis approach captures richer spatial dependencies and contextual information while maintaining low computational complexity, significantly improving feature extraction and model performance for medical image analysis."}, {"title": "Integration of KAN into U-Net Architecture for Medical Image Segmentations", "content": "In this work, we integrate the Kolmogorov-Arnold Network (KAN) as the bottleneck layer in the U-Net architecture to improve feature modeling and enhance the network's interpretability, specifically for medical image segmentation tasks. The proposed U-Net variant, KM-UNet, adopts a three-phase encoder-decoder structure composed of the Convolution Phase, the Selective-Scan Efficient Multi-scale (SEM) attention module phase, and the Tokenized KAN (Tok-KAN) phase. Given an input feature map $Z \\in R^{C\u00d7H\u00d7W}$ from the encoder, the KAN layer processes this feature as:\n$$Z' = LN (Z+DwConv(\u03a6(Z)))$$\nwhere LN denotes layer normalization and DwConv represents depth-wise convolution. This formulation allows the network to effectively capture complex, non-linear dependencies across multi-dimensional features, which is particularly valuable in medical image segmentation, where intricate anatomical structures need to be accurately segmented. By integrating KAN, KM-UNet enhances the model's ability to maintain long-range contextual information and multi-scale feature representation, critical for handling the variability and complexity found in medical images."}, {"title": "4. Experiments", "content": "We conducted an extensive evaluation of our proposed method using three distinct and heterogeneous datasets, each characterized by unique properties, varying data sizes, and different image resolutions. These datasets are commonly employed in tasks such as image segmentation and generation, providing a comprehensive testing ground to assess the effectiveness and adaptability of our method.\nBUSI Dataset: The BUSI dataset [25]consists of ultrasound images that depict normal, benign, and malignant breast cancer"}, {"title": "Main results", "content": "In the comparative experiments, KM-UNet was evaluated against several existing segmentation methods using standard metrics, Intersection over Union (IoU) and F1 score, to assess accuracy and robustness across diverse datasets. Table 1 presents the segmentation performance, while Table 2 highlights the trade-off between accuracy and efficiency.\nWe compared KM-UNet with traditional CNN-based models such as U-Net [31] and UNet++ [32], attention-based methods like Att-UNet [33], efficient transformer variants like U-Mamba [17], and advanced MLP-based models including U-NeXt [20] and Rolling-UNet. The results show that KM-UNet achieves the highest IoU and F1 scores on most datasets and strikes an excellent balance between segmentation accuracy and efficiency, as shown in Table 2. Notably, it achieves an average IoU of 80.45% and F1 score of 88.63%, with a relatively small parameter count (7.35M) and computational cost (17.66 Gflops)."}, {"title": "Explainability", "content": "This study explores the role of the KAN layer in improving model interpretability. By comparing attention heatmaps, as shown in Figure 7, when the KAN layer is not used (first column), the model fails to accurately locate key regions, resulting in a low IoU, indicating insufficient overlap between the activation areas and the ground truth masks. In contrast, after integrating the KAN layer (second column), the model can precisely locate the target boundaries, and the generated activation areas align better with the ground truth masks, leading to a significant improvement in the IoU. This result demonstrates that the KAN layer, by introducing an attention mechanism, enhances the model's focus on key regions, improving both prediction accuracy and interpretability. This improvement is consistent with the performance observed in other studies on the KAN layer, validating its effectiveness in increasing model transparency."}, {"title": "5. Conclusions and Future Works", "content": "The proposed KM-UNet framework demonstrates significant performance improvements in medical image segmentation tasks. By introducing the Selective-Scan Efficient Multi-scale (SEM) module, Kolmogorov-Arnold Network (KAN), and advanced learning rate scheduling strategies, substantial enhancements over the traditional U-Net model have been achieved. Ablation studies show that the SEM module, which combines feature extraction and attention mechanisms, effectively improves segmentation accuracy, with a 2%-3% increase in IoU and F1-score. Additionally, a comparison of different learning rate scheduling strategies reveals that the cosine annealing learning rate scheduler outperforms the fixed learning rate configuration, resulting in slightly better experimental outcomes. The substitution of the traditional MLP network with the KAN network significantly boosts global feature modeling capability, leading to improved segmentation results.\nHowever, there are still areas that need further optimization. Although the SEM module shows excellent performance, its computational complexity remains relatively high, and future work could focus on designing more efficient feature extraction and attention mechanisms to reduce computational overhead. Moreover, while KM-UNet is currently applied to medical image segmentation, it could be extended to other domains such as remote sensing or video segmentation, which may require adjustments to the module structure to suit the specific demands of these tasks. As deep learning models continue to grow in complexity, reducing the model's computational cost and parameter count while maintaining accuracy becomes a major challenge. Lightweight techniques such as quantization and pruning will be key areas for future optimization. Furthermore, incorporating multimodal medical imaging data, such as CT and MRI, into KM-UNet could enhance the model's ability to identify complex pathologies and improve segmentation accuracy. Lastly, as datasets continue to expand, federated learning and transfer learning could further enhance KM-UNet's performance on smaller datasets. Exploring multi-task learning and transfer learning techniques will be crucial for improving KM-UNet's generalization across various scenarios."}]}