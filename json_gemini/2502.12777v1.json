{"title": "Evaluating link prediction: New perspectives and recommendations", "authors": ["Bhargavi Kalyani I", "A Rama Prasad Mathi", "Niladri Sett"], "abstract": "Link prediction (LP) is an important problem in network science and machine learning research. The state-of-the-art LP methods are usually evaluated in a uniform setup, ignoring several factors associated with the data and application specific needs. We identify a number of such factors, such as, network-type, problem-type, geodesic distance between the end nodes and its distribution over the classes, nature and applicability of LP methods, class imbalance and its impact on early retrieval, evaluation metric, etc., and present an experimental setup which allows us to evaluate LP methods in a rigorous and controlled manner. We perform extensive experiments with a variety of LP methods over real network datasets in this controlled setup, and gather valuable insights on the interactions of these factors with the performance of LP through an array of carefully designed hypotheses. Following the insights, we provide recommendations to be followed as best practice for evaluating LP methods.", "sections": [{"title": "1 Introduction", "content": "Complex networks encode rich and non-trivial relations among entities. They are ubiquitous in nature, and are used to model many complex real-world systems. Social, biological and information systems are to name a few such systems. Social networks encode some kind of social relationships, biological networks model interactions between two biological entities like proteins, and information networks record information exchanges, such as emails. Each entity in a complex network is called a node and any connection, interaction, or exchange of information between two nodes are referred as a link. Graph data structure is used to encode complex networks, where vertices represent nodes and edges represent links. Link prediction (LP) [1-3] is a fundamental problem in network science, which, given a network, aims at predicting unobserved, missing, hidden or future relationships, depending on the complex system and the target application [4]. LP has numerous applications: it can suggest unobserved or missing relations between two criminals in a criminal network [5, 6], it can predict future collaborations among scientists from co-authorship networks [7-9], it can recommend unobserved costumer-product relationships in collaborative filtering [10-12], and so on. LP has been primarily targeted as a classification problem [2] which, given a network, classify a given node pair, which are not connected by a link in the given network, to yes or no: yes signifying they have a hidden connection or they will be connected in the future, and no means there is no possibility of getting connected by a link.\nSince Nowell et al. [1] popularized LP as a research problem, now it is a well established research domain in both of network science and the machine learning community. Application of LP is diverse, so a solution to this problem demands considerations of the application or the domain specific factors. Although, there exists application specific designs of the LP methods [7, 11, 13-16], they usually extend the state-of-the-art node similarity [1, 2, 17] or machine learning based [11, 18\u201323] methods. These state-of-the-art methods assume a uniform set-up accross different prediction cenerios, starting from problem formulation to experimental setup and evaluation. We investigate if this uniformity hinders accurate evaluation of the LP methods, and aim to provide a guideline for a robust evaluation of LP. We identify a few aspects concerning the data, experimental setup and evaluation metric that may affect the prediction performance, based on which we build our experimental framework, and perform extensive experiments to gain insights toward effective and robust evaluation for LP. We brief those aspects below.\nThe LP problem can be categorized into two: (a) missing/unobserved/hidden link prediction, and (b) future link prediction [1, 2, 24]. Without loss of generality, now onward we refer these two types as missing LP and future LP respectively, and name this classification as prediction type. Traditionally, in literature, the experimental setups for LP do not differentiate between these two prediction types, and evaluate LP in a common experimental setup which ignores the information of the link appearance time, and the ground truth node pairs are generated by removing a fraction of random edges from the underlying graph. This results in information loss and makes the future LP problem get evaluated as a missing LP problem. This may not capture true efficacy of a prediction method on future LP, because a randomly deleted link"}, {"title": null, "content": "may not be a true future link. Our experimental setup accommodates both types of LP, and we examine if this information loss results in any performance degradation of the LP methods. A line of works target temporal link prediction [7, 25], which devices specialized LP methods by exploiting temporal dynamics in dynamic networks. In this work, we are not focusing on temporal link prediction, but consider the traditional approach of solving LP.\nPopular LP methods are of two types: similarity based and machine learning based [24]. Similarity based methods [1] calculate some score based on structural similarity or closeness of a node pair, which measures the likelihood of having a link. These methods can be either local or global. Local methods rely on triadic closure property [26] which says that two unconnected nodes tend to form a link if they have at least one common connection. Local methods are applicable on a pair of nodes whose shortest path distance in the network graph, which is also referred as geodesic distance in network science, is two. To increase readability, we refer \"geodesic distance\u201d as \"distance\" throughout this paper. We refer a node pair having distance two as two-hop away/apart node pairs. Global methods are mostly shortest path or random walk based, which can predict connections between any node pair in the network. Modern machine learning based LP methods either train a neural network in a supervised way [18, 27-29], or generate low dimension embedding for the nodes in unsupervised manner and use the embeddings for predicting links [19-22]. Machine learning based methods are global in nature. The small world property [30] makes the diameter of a complex network grow at a logarithmic rate with network size, and the likelihood of connection decreases with the distance between two nodes. The LP methods which are global in nature, mostly agree with this principal. So, in one hand, the local methods apply on two-hop away node pairs, whereas the global methods apply on two-hop as well as more distant node pairs; on the other hand, the new connection build-up process is biased toward the two-hop away node pairs than the rest. Traditional evaluation frameworks do not distinguish the test node pairs by the distance of the end nodes in the network. So, the evaluation does not capture the unique characteristics, if any, of the test node pairs based on the distance of the end nodes. Moreover, when we compare a global method with a local one in this framework, we may draw wrong conclusions because the test set for the two cases may differ. Also, we miss the opportunity to compare two global methods in a distance controlled setup. The traditional evaluation approach has another inherent issue. The negative test examples are sampled by selecting random node pairs which are not connected by a link in the network, and are not in the positive examples. This randomness makes the distribution of negative examples differ with the positive ones, for which the samples have an inherent distance bias. We propose an experimental set-up which takes care of these factors, and conduct an array of systematic experiments to find valuable insights toward effective evaluation.\nThe state-of-the-art LP methods usually apply on undirected networks. However, networks like information networks are directed in nature. So, these networks are usually converted to undirected networks by ignoring their directions in order to make those methods applicable on them. Ignoring directions results in loss of significant information about the links, which may affect the prediction performance in directed"}, {"title": null, "content": "networks. We investigate this with experiments in our hop controlled and prediction type controlled setup.\nClass imbalance is an inherent issue with LP, where the real missing or future links are too few as compared to the node pairs with no possible connections. Historically, Area Under the Receiver Operating Characteristics Curve (AUROC) [31] has been a popular single point summary statistics evaluation metric for LP [2, 24], perhaps due to its invariance with class distribution. AUROC favors accurate classification of positive links, at the cost of significantly misclassifying negative node pairs. Hence, AUROC can overestimate the performance of LP. Skew sensitive measures like Area Under the Precision-Recall Curve (AUPR) or Precision@k can be an alternative [2, 3, 32], but use of these are rare in literature, may be due to the difficulty in handling the variability in results with skew level for their skew sensitiveness. So, in order to understand how an LP method behaves in skewed test environment, we require a rigorous skew controlled evaluation with appropriate evaluation metrics. Moreover, applications like recommendation systems require methods to perform good at the early retrieval stage. Early retrieval performance is skew sensitive, the effect of which can not be understood with AUROC, or the ROC curve [32-34]. So, how the LP methods behave in the early retrieval stage in imbalanced setup has been largely unexplored. Our proposed experiment setup and the conducted experiments take care of these factors and judiciously employ the evaluation metrics to understand the true behavior of the prediction methods considering class imbalance and early retrieval. It also examines the interplay of the other factors like prediction type and distance between the end nodes of the test node pairs with class imbalance.\nOur contributions in this paper can be summarized as follows.\n\u2022 we identify a number of aspects concerning the data, experimental setup and evaluation metric that may affect the performance of LP methods, which the baseline setups for the LP evaluation largely ignore;\n\u2022 we propose an experimental setup which allows us to evaluate LP methods in a rigorous manner in a controlled environment, considering those aspects;\n\u2022 we conduct extensive experiments using 24 real network datasets on 58 LP methods in this controlled experimental setup, and perform an array of correlation and hypothesis tests to analyze the effect of those factors on LP methods;\n\u2022 we provide recommendations to be followed as best practice toward an effective and robust evaluation of LP methods.\nThis paper is organized as follows. In Section 2, we summarize the related works. We provide the details of the LP methods which we use in our experiments in Section 3, grouped by their categories. Section 4 provides the details of the datasets on which we apply the LP methods. We describe the proposed experimental setup in Section 5. In Section 6, we present the results and analyze our findings, and provide our recommendations. We conclude our work and indicate the future directions in Section 7."}, {"title": "2 Related Works", "content": "Nowell et al. [1] proposed a list of local and global similarity based LP methods. Similarity based methods calculate a score between two nodes to estimate their chance to form a link. Local similarity based methods are neighborhood based, and apply to two-hop away node pairs. The global similarity based methods are mostly path based and apply to any node pair in the network. In this paper, we consider most of the methods proposed in Nowell et al. in our experiments along with another popular local method: Resource Allocation [17]. There are a few other similarity based methods in literature, an exhaustive list of which can be found in Kumar et al. [2]. We do not include another type of similarity based method, namely quasi-local [2], in our study. Modern machine learning based LP methods are either supervised [18, 27-29] or unsupervised [19-22]. The supervised methods train a neural network or a graph neural network in an end-to-end manner with the test node pairs. The unsupervised methods first train a neural network or a graph neural network to learn low dimension embeddings of the nodes in an unsupervised manner (known as contrastive learning), and then produce link features which are used to build a classifier to predict links.\nIn this paper, we consider the unsupervised methods in our experiments. The main reason to exclude the end-to-end methods is the difficulty in building the experimental set-up for those in the longitudinal setup for the future LP, which incurs a longitudinal bias [3, 35] on the prediction performance, as well as makes the methods incomparable with their missing LP counterpart. Another group of unsupervised LP approaches are matrix factorization based [23, 36], which we do not include in our experiments. Note that, the purpose of this work is not to present an exhaustive performance comparison of the existing methods, but to devise a robust evaluation strategy for the prediction methods considering certain data, evaluation metric, experimental setup, application and methodology specific factors. So, excluding a few prediction methods does not hurt the merit of this work.\nThe start-of-the-art LP methods briefed above mainly apply to a simple, undi-rected and homogeneous networks. There exists works which exploit several network attributes to predict links. Few examples are: temporal link prediction [7, 25] which exploits temporal dynamics of link maintenance in dynamic networks like in social networks; link prediction in bipartite networks [37, 38] which applies on bipartite graphs like user-product networks or term-document networks; link prediction in heterogeneous networks [7, 39, 40] which exploits the heterogeneity of nodes and links in networks like bibliographic networks; link prediction in directed networks [41, 42] which exploits the direction information in directed networks like email networks, etc. These specialized methods are not necessarily disjoint, and often use information cov-ering multiple groups. In this paper, we consider the start-of-the-art LP methods only in our analysis, and reserve the specialized methods for future study.\nStudies like [35, 43] investigated the issues associated with LP evaluation in considerable details. They stressed on an imbalanced sampling of test set, and advocated for AUPR and the PR curve to tackle class imbalance in evaluation. Yang et al. [35] also proposed a test set-up for supervised future LP from deployment perspective, and analyzed the effect of variation of the test node pair collection time duration. He et"}, {"title": null, "content": "al. [44] investigated how LP accuracy in real-world networks gets affected under non-uniform missing-edge patterns. A few studies like [45, 46] investigated the evaluation problem for temporal link prediction. These studies consider the timestamps of test node pairs as an important aspect for evaluation. Kumar et al. [2] presents a nice survey on LP methods and evaluate them using standard metrics like AUROC, AUPR and Precision@K. Mostly, the existing studies on link prediction evaluation deal with the class imbalance issue [2, 3, 35, 43, 47, 48], but do not address the early retrieval performance. To the best of our knowledge, there exists no study which considers the multifaceted aspects of LP evaluation in such a detailed manner like us."}, {"title": "3 Link Prediction Methods", "content": "Similarity-based LP methods calculate a score given a pair of nodes, which represents the likelihood of a link formation between them. Based on the node pair's geodesic distance in the network, similarity based methods are classified into two: local and global. Local methods are applied on the node pairs which are two-hop apart, but global methods can be applied on any node pair irrespective of their distance in the network. As the machine learning based methods also are global in nature, for ease of understanding, we refer local similarity based methods as local-sim and global similarity based methods as global-sim now onward. We summarize a few popular local and global similarity based methods which we use in this paper as follows."}, {"title": "3.1.1 Local methods", "content": "Common Neighbors (CN) [1]: The Common Neighbors method (CN) measures the number of common neighbors or two-hop paths between node pairs. The CN score between nodes x and y can be expressed as:\n$CN(x, y) =| \\Gamma(x) \\cap \\Gamma(y) |$,\nwhere $\\Gamma(x)$ represents the set of neighbors of x.\nJaccord's Coefficient (JC) [1, 49]: Jaccord's Coefficient (JC) extends the CN method by penalizing it for non-shared neighbors between the nodes. The JC score between nodes x and y can be expressed as:\n$JC(x,y) = \\frac{| \\Gamma(x) \\cap \\Gamma(y) |}{|\\Gamma(x) \\cup \\Gamma(y) |}$ \nAdamic Adar (AA) [1, 50]: Adamic Adar (AA) extends the CN method by penal-izing each common neighbor by its degree logarithmically. The AA score between nodes x and y can be expressed as:"}, {"title": null, "content": "$\\textrm{AA} (x, y) = \\sum_{z \\in \\Gamma(x) \\cap \\Gamma(y)} \\frac{1}{\\log |\\Gamma(z)|}$ \nResource Allocation (RA) [17]: Unlike AA, Resource Allocation (RA) penal-izes each common neighbor by its degree without logarithmic scaling. The RA score between nodes x and y can be expressed as:\n$RA (x, y) = \\sum_{z \\in \\Gamma(x) \\cap \\Gamma(y)} \\frac{1}{|\\Gamma(z)|}$"}, {"title": "3.1.2 Global methods", "content": "Preferential Attachment (PA) [1, 51, 52]: Preferential Attachment method (PA) relies on the principle that nodes with higher degrees are more likely to acquire new connections. The PA score between nodes x and y can be expressed as:\n$\\textrm{\u0420\u0410}(x, y) = |\\Gamma(x)|\u00d7 |\\Gamma(x)|$\nKatz Similarity (Katz) [1, 53]: Katz similarity index (Katz) enumerates all the possible paths of different lengths between the node pairs, and takes sum over this collection, exponentially damping by path length. The Katz score between nodes X and y can be expressed as:\n$Katz(x,y) = \\sum_{l=1}^{\\infty} \\beta^{l}. | paths_{x,y}^{l}|$,\nwhere $\\beta$ acts as decay factor to give exponentially higher weight to longer paths, and $| paths_{x,y}^{(l)}|$ is the number of different paths of length l connecting the node pair.\nHitting Time (HT) and Normalized HT (Norm-HT) [1]: Hitting Time (HT) leverages random walks on a network to quantify node similarity. The hitting time between nodes x and y is the expected number of steps it takes for a random walker starting at node x to reach node y for the first time. It quantifies how easily information or influence can spread between the nodes. It indicates easier information flow or shorter travel times between the nodes in the network, where smaller HT indicates better link formation likelihood. The scoring function can be expressed as:\n$HT(x, y) = - \\sum_{t=1}^{\\infty}t.P(T_{xy} = t)$"}, {"title": null, "content": "Here, $T_{xy}$ is the random variable denoting the time it takes for a random walker to reach node y from x, and $P(T_{xy} = t)$ is the probability of this happening in t steps. HT(x, y) is quite small when the node y has a large stationary probability. To mitigate this issue, the score is multiplied with y's stationary probability. We call this measure as normalized heating time (Norm-HT).\nCommute Time (CT) and Normalized CT (Norm-CT) [1]: Commute Time (CT) signifies the expected time for a random walker to travel from node x to y and back to x. It encapsulates the symmetric nature of node connectivity. The CT score between nodes x and y can be expressed as:\n$CT(x,y) = HT(x,y) + HT(y, x)$\nLike HT, we consider normalized commute time (Norm-CT) along with its un-normalized version."}, {"title": "3.2 Machine Learning Based Methods", "content": "We use three popular node embedding methods in this category, namely, Deepwalk [19], Node2vec [20], and Graphsage [21], towards LP. All of these methods learn a function $f : V \\rightarrow R^d$, given a network graph $G(V, E)$, where V and E are the set of vertices and edges respectively, which maps each node to a d dimensional latent space where d<< |V|. We learn edge features following the method presented in Grover et al. [20] to get a link vector given a node pair, and apply logistic regression and random forest supervised learning technique to predict links. We refer this group of LP methods as learning. Below, we brief the aforementioned node embedding methods and the edge feature learning methods."}, {"title": "3.2.1 Deepwalk [19]:", "content": "Deepwalk adapts Skip-gram [54] method of natural language processing to generate node embeddings. It solves the following optimization problem:\n$minimize - \\sum_{Vi \\in V} log Pr({Vi-w, ..., Vi\u22121, Vi+1,..., Vi+w }| f (Vi))$,\nwhere {vi-w,..., Vi\u22121, Vi+1,..., Vi+w} are the context vertices of the vertex vi within a window of size w. To get the context vertices, Deepwalk simulates multiple truncated random walks started at every vertex, and extracts the context vertices from the walks. It approximates the optimization by solving it with a conditional independence assumption on the vertices in the context window, given the embedding of a vertex. On this assumption, it models the conditional probability of each node-context pair with a softmax unit. The optimization equation can be given by:"}, {"title": null, "content": "$maximize \\sum_{Vi \\in V} [ - log Z_{v_i} + \\sum_{n_i \\in S_i} f(n_i) \u00b7 f(v_i)]$,\nwhere $Z_{v_i} = \\sum_{u \\in V} exp(f(u) \u00b7 f(v_i))$, and Si are the set of nodes inside the context window of vi. To avoid the explosion of labels, precisely |V| numbers, Deepwalk uses Hierarchical Softmax [55, 56] with stochastic gradient descent (SGD) to approximate the optimization."}, {"title": "3.2.2 Node2vec [20]:", "content": "Like Deepwalk, Node2vec adapts Skip-gram to generate the embedding, and solves a similar optimization problem. It differs from Deepwalk in two aspects: generat-ing the context window, and approximating the optimization problem. It argues that embeddings generated using truncated random walk can not capture homophily and structural equivalence among nodes. In order to capture a more flexible contextual structure, it employs a biased random walk method that combines neighborhood exploration using breadth-first search (BFS) and depth-first search (DFS). The con-text sampled by BFS generates similar embeddings for structurally equivalent nodes. DFS can explore distant parts of the network, which leads the embeddings to pre-serve homophily. Like DeepWalk, with the conditional independence assumption over the context window, Node2vec models the conditional probability with a softmax units. Node2vec deals with the explosion of labels by negative sampling with SGD to approximate the optimization."}, {"title": "3.2.3 GraphSAGE [21]:", "content": "GraphSAGE is a graph neural network approach for scalable and inductive learning on large graphs. GraphSAGE leverages node attributes (e.g., node2vec embeddings) to learn embedding functions that generalize to unseen nodes during the training phase. GraphSAGE does this by learning aggregator functions that can induce an embed-ding of a node by aggregating the attributes of its neighboring nodes, sampled from its direct connections. This aggregation process is executed k times for all nodes in the network, which way it learns k sets of weight matrices {W*}. It uses four differ-ent aggregator techniques: mean, max-pooling, mean-pooling, and LSTM. GraphSAGE optimizes similar objective as Deepwalk and Node2vec, and approximates it with neg-ative sampling, where given a node, its positive instances are sampled from nodes appearing in the chain of short random walks starting at the given node, and negatives are sampled from the degree distribution. It uses SGD as the optimization procedure."}, {"title": "3.2.4 Learning edge features:", "content": "To learn edge features, we follow the procedure described in Grover et al. [20]. For two nodes x and y, we employ a binary operator \u201co\u201d for the feature vectors f(x) and f(y) in order to achieve an edge representation g(x,y) such that $g : V \\times V \\rightarrow R^{d'}$ where d' is the representation size for the pair (x, y). The operators designed for this"}, {"title": "4 Datasets", "content": "We conducted our experiments on fifteen real network datasets of diverse nature, such as, social network, communication network, collaboration network, biological network, power grid, etc. A few of these networks like friendship networks, collaboration networks are undirected in nature, whereas networks like communication networks are directed. The social, communication and collaboration networks are inherently dynamic or temporal in nature. Among the networks in our collection which are dynamic, few had timestamps available with the interactions or the moment of link formation. In total, nine among all the networks had timestamps. For these networks we created ground truth labels two ways: (a) considering the timestamps which lets us evaluate future LP, and (b) removing a portion of the links in the networks which lets us evaluate the missing LP. So, we created two LP datasets for each of these networks."}, {"title": null, "content": "For the networks with no timestamp, we could only evaluate missing LP. In total, we conducted our experiments and analysis on 24 datasets, among which 15 were used for missing LP and the rest were used for future LP. We summarize the datasets in Table 2. We briefly describe the datasets as follows."}, {"title": "4.1 Networks with timestamps:", "content": "1. CollegeMsg [57]: This dataset represents a temporal network capturing private communications among college students on a campus at the University of California, Irvine. Each node in the network represents an individual student, while the private messages exchanged between them guides the link formation and maintenance. This dataset offers insights into communication dynamics and prevalent styles within the campus community. Information for this dataset was obtained over the course of 193 days at the University of California, Irvine. In this paper, we refer the dataset which prepares ground truth using timestamps as clg-msg-t and the the one which do not consider the timestamps as clg-msg.\n2. Email-Eu [58]: This dataset provides insight into the evolving connections and communication patterns within a European research organization over time. It primarily focuses on email correspondence exchanged between members of the insti-tution. The network's nodes represent individual users or email addresses within the organization, and the links encode the email exchanges between them, with times-tamps indicating the exact moments of interaction. This data enables researchers to analyze the dynamics of information flow and collaboration within the orga-nization. Information for this dataset was gathered over a period of 803 days. In this paper, we refer the temporal version as email-t and the non-temporal one as email.\n3. Mathoverflow [58]: This dataset presents a temporal network capturing inter-actions among users on the Mathoverflow platform, a specialized community for mathematicians to exchange knowledge and insights. Each node in the network represents an individual user, while the links encode their interactions, such as comments or responses to questions and answers. The timestamps associated with the interactions indicate the exact moment of these interactions, providing valuable temporal insights into the dynamics of knowledge sharing and collaboration within the mathematical research community. This dataset is taken over a time span of 2350 days. In this paper, we refer the temporal version as math-flow-t and the non-temporal version as math-flow.\n4. Ast-phys [59]: This dataset contains a collaboration network of authors who have contributed to the field of Astrophysics through scientific paper publications. Each node represents an individual author, and the links signify collaborations between authors. The timestamps indicate the time of collaborations between two authors. In this paper, we refer the temporal version as ast-phys-t and the non-temporal version as ast-phys.\n5. LastFm [60]: This dataset represents a social network derived from Last.fm, a music streaming and recommendation service. Nodes in the network represent Last.fm users, and the links symbolize their interactions and social relationships."}, {"title": null, "content": "The dataset includes timestamps indicating the precise moments of user connec-tions and interactions. In this paper, we refer the temporal version as 1st-fm-t and the non-tempral one as 1st-fm.\n6. IAcontact [61]: This dataset represents a contact network among attendees of the ACM Hypertext conference in the year 2009. The links encode the interac-tions among the attendees during a 2.5-day period, while the nodes represent the attendees. In this paper, we refer the temporal version as iacontact-t and the non-temporal one as iacontact.\n7. FB-forum [61]: This dataset illustrates a forum-based online social network sim-ilar to Facebook. The network mostly records user actions and conversations in this forum. Individual nodes in this dataset represent users, and the links represent the forum messages these users have exchanged. The dataset spans a period of 164 days. In this paper, we refer the temporal version as forum-t and the non-temporal one as forum.\n8. Topology [62, 63]: This dataset encodes the complicated network of connections between autonomous systems on the Internet. Node refers to autonomous systems (AS), which are collections of connected IP routing domains run by independent network operators. In this paper, we refer the temporal version as topo-t and the non-temporal one as topo.\n9. Mooc [60]: This dataset displays user activity on a well-known MOOC program. The actions are symbolized as a temporal and directed network. Users are rep-resented as nodes in the graph together with course activities (targets), and the links are user actions on the targets. In this paper, we refer the temporal version as act-mooc-t and the non-temporal one as act-mooc."}, {"title": "4.2 Networks without timestamps:", "content": "1. ArXiv [59]: ArXiv is a network dataset representing collaborations among scien-tists who publish preprints and papers on the ArXiv platform. Nodes in the network represent individual authors, while links represent co-authorship connections. We refer the dataset prepared from this network as arxiv.\n2. Power-grid [61]: The Power-grid network dataset models the interconnected power grid infrastructure in the United States. It provides information on the trans-mission lines, nodes, and elements that make up the electrical system, enabling research into electricity distribution across different geographic areas. Nodes repre-sent power plants, substations, transformers, and other infrastructure, while links depict the transmission lines connecting these elements. This dataset is valuable for studying the dynamics and efficiency of the U.S. electrical power grid. In this paper, we refer the dataset prepared from this network as pow-grid.\n3. Tech-routers [61]: It is a tech routers network, which represents the connections between routers in a technological infrastructure like the internet or computer net-works. Nodes in the network represent individual routers, and links symbolize direct physical or logical links between matching routers. We refer the dataset prepared from this network as routers.\n4. Bio-yeast [61]: The Bio-yeast dataset is a biological network database focused on protein-protein interactions in the yeast species Saccharomyces cerevisiae. It"}, {"title": null, "content": "represents proteins as nodes and shows connections between proteins based on phys-ical binding, enzymatic processes, or co-expression patterns. We refer the dataset prepared from this network as bio-yeast.\n5. Facebook [64]: It is a social network, built on the Facebook platform, focuses on a single user (\u201cego\u201d) and their connections with other users. Nodes represent Facebook users, and links represent friendships between them. We refer the dataset prepared from this network as fb.\n6. BlogCatalog [61]: This dataset is a social relationship network. The network is made up of bloggers and their friends and other social connections. Nodes in this network are represented as bloggers and the links represent social relationship among the bloggers. In this paper, we refer the dataset prepared from this network as blog-cat."}, {"title": "5 Experimental Setup", "content": "In this section, we detail the procedure of how we prepare the graph and the ground truth positive and negative node pairs from the datasets presented in Section 4, for future and missing LP tasks. Unlike traditional approaches, we carefully segregate the test examples based on the distance of the test node pairs in the graph, and maintain the distance bias inherent with the positive examples' distribution, while sampling the negative examples. Moreover, it takes care of the evaluation in a class imbalance environment and its interactions with the factors stated above.\nThe future LP datasets were prepared for the networks where the interaction or link formation timestamps were available. The interactions can be directed, and there could be multiple interactions between a node pair. As we aim to prepare a simple and undirected graph and the true future links from a network, we ignored the directions of the interactions and the duplicate interactions. The detailed procedure for the dataset preparation is described as follows. We first sort the interactions or links (for the cases where only the link formation timestamps were available) by their timestamp values, and then choose 75% of the earlier timestamped interactions or links for constructing the graph, and the remaining were used for generating positive examples. From the interactions which are in that 75%, we constructed an unweighted and undirected graph by first ignoring the directions and then removing duplicate interactions and links, if any. If the graph is having multiple connected components, we choose the largest connected component as the final graph for our experiment. From the remaining 25% interactions, we ignored the directions and removed the duplicates to generate the potential positive examples. From this potential set, we first ignored the node pairs which involve at least one node which is not included in the graph, and then removed the links which are present in the graph as an edge to get the final set of positive examples.\nThe missing LP was applied to all the networks presented in Section 4. We prepro-cessed the networks having timestamp information by ignoring the timestamps and"}, {"title": null, "content": "their directions, and then removing the duplicates. Similarly, we ignored the direc-tions and removed the duplicates, if applicable, for the networks which did not have timestamp information. After doing this, we are left with a set of node pairs which represents links. Then we randomly remove 10% of the links from the set. We con-struct the graph with the remaining links and choose the largest connected component as the final graph. We consider the removed 10% links as the potential positive exam-ples, and generate the positive examples following the same procedure as the future LP datasets.\nFor each dataset, we divided the positive examples in three parts based on the shortest path distance of the end node pair in the graph: having the shortest path distance (a) 2, (b) 3, and (c) more than 3. As most of the datasets have no or a very few end node pairs having the shortest path distance > 3, we do not consider this group in our experiment. To evaluate the effect of class imbalance on the LP methods, we generated negative examples 10 times as many as the number of positive examples, stratified by specific shortest path distance categories maintaining the ratio of the representatives of the categories same as the positive set, and conducted experiments on multiple skew levels. For each category, we repeatedly choose two random nodes having the specified shortest path distance in the graph and if they are not included in the set of positive examples, we include the pair in the negative set. This sampling strategy empower us to evaluate the LP methods in groups of test examples by their shortest path distance in class imbalanced setup. The details of the positive example count for each dataset grouped by the distance categories are provided in Table 2."}, {"title": "5.2 Hyper-parameter settings for the LP methods", "content": "The Katz similarity method was implemented with $\\beta$ = 0.05", "1": ".", "models": "Deep-walk [19", "20": "GraphSAGE [21"}]}