{"title": "NEXTLOCLLM: NEXT LOCATION PREDICTION USING LLMS", "authors": ["SHUAI LIU", "Ning Cao", "Yile Chen", "Yue Jiang", "Gao Cong"], "abstract": "Next location prediction is a critical task in human mobility analysis and serves as a foundation for various downstream applications. Existing methods typically rely on discrete IDs to represent locations, which inherently overlook spatial relationships and cannot generalize across cities. In this paper, we propose NextLocLLM, which leverages the advantages of large language models (LLMs) in processing natural language descriptions and their strong generalization capabilities for next location prediction. Specifically, instead of using IDs, NextLocLLM encodes locations based on continuous spatial coordinates to better model spatial relationships. These coordinates are further normalized to enable robust cross-city generalization. Another highlight of NextlocLLM is its LLM-enhanced POI embeddings. It utilizes LLMs' ability to encode each POI category's natural language description into embeddings. These embeddings are then integrated via nonlinear projections to form this LLM-enhanced POI embeddings, effectively capturing locations' functional attributes. Furthermore, task and data prompt prefix, together with trajectory embeddings, are incorporated as input for partly-frozen LLM backbone. NextLocLLM further introduces prediction retrieval module to ensure structural consistency in prediction. Experiments show that NextLocLLM outperforms existing models in next location prediction, excelling in both supervised and zero-shot settings.", "sections": [{"title": "1 INTRODUCTION", "content": "With the rapid advancement of smart city infrastructure and positioning techniques, the acquisition of human mobility trajectories has become increasingly widespread, offering unprecedented research opportunities (Yabe et al., 2024a). Accurately predicting a user's next location holds significant value across multiple key domains. For urban planning and traffic management, forecasting mobility patterns can optimize traffic flow, reduce congestion, and improve the efficiency of public resource allocation (Medina-Salgado et al., 2022; Kraemer et al., 2020). In disease control, predicting population movements aids in tracking epidemic spread and formulating more effective prevention measures (Ceder, 2021). Moreover, accurate next location prediction is crucial for service providers who offer location-based recommendations and route planning, as it significantly enhances the quality of personalized services, delivering experiences that better meet users' needs (Lian et al., 2020).\nEarly methods for next location prediction mainly rely on manually designed features like behavioral sequences, user profiles, and temporal factors. Using these features, researchers employ statistical methods and time-series analysis to model and predict movement patterns (Noulas et al., 2012; Ying et al., 2014; Zhao et al., 2016). However, these methods heavily depend on feature engineering, which usually requires intensive efforts and exhibits limited performance. Later, neural network models like RNNs and Transformers are used to capture high-order transition patterns and dependencies (Feng et al., 2018; Yao et al., 2017; Kong & Wu, 2018). Some studies further integrate geospatial information by constructing graph neural networks to explore spatial correlations (Liu et al., 2016; Lian et al., 2020; Yao et al., 2023). These deep learning-based models typically learn embedding tables based on location IDs to represent locations. However, the learned embeddings inherently lack generalization capability, especially when applied to new locations from unseen cities or scenarios."}, {"title": "2 RELATED WORK", "content": "Early methods of next location prediction largely relied on feature engineering and domain expertise. They employed features tied to urban mobility patterns, using statistical techniques and time series analysis to model and predict movement. (Noulas et al., 2012) proposed features capturing transitions between venues and spatiotemporal check-in patterns, which were then applied in linear regression. (Chen et al., 2014) introduced Next Location Predictor with Markov Modeling, incorporating individual and collective movement behaviors. Similarly, (Ying et al., 2014) employs factors in geographic, temporal, and semantic signals to predict location likelihood. These methods rely extensively on feature engineering, which often demands substantial effort and yields restricted performance.\nIn deep learning era, researchers adopted models like RNNs and Transformers for next location prediction, which excel in capturing temporal dependencies. STRNN (Liu et al., 2016) modeled local spatial and temporal contexts using transition matrices based on time intervals and geographic distances. (Fan et al., 2018) combined CNNs and bidirectional LSTMs for prediction by integrating contextual information. GETNext (Yang et al., 2022) introduced a Graph Enhanced Transformer that utilized global trajectory flow map. (Hong et al., 2023) developed an MHSA-based model that leverages raw location sequences, temporal data, and land use functions. (Yao et al., 2023) combined geographic embeddings, multi-layer attention, and Bi-LSTM, and integrated geographic information. While these models achieve excellent performance on specific datasets, their generalization capability remains a challenge, as they often underperform on datasets from unseen cities or scenarios.\nIn recent years, with the swift advancement of large language models (LLMs) (Touvron et al., 2023b;a; Achiam et al., 2023), researchers have begun to extend their researches in next location prediction with LLMs. Current studies mainly rely on specifically designed prompt engineering. (Wang et al., 2023) introduced the concepts of historical and contextual stays to capture long- and short-term dependencies in human mobility, incorporating time-aware predictions with temporal data. (Wang et al., 2024) leveraged the semantic perception capabilities of LLMs to extract personalized activity patterns from historical data. Despite some success, these methods exhibit notable limitations. First, these models employ discrete location IDs that neglect geographic distances and spatial relationships, thereby compromising prediction accuracy (Liu et al., 2016). Second, using location IDs hinders model transferability across cities, since identical IDs often correspond to entirely different locations in different cities, obstructing cross-city generalization (Jiang et al., 2021). Furthermore, these purely prompt-based models neglect the distribution of point of interest (POI) categories, which are crucial for capturing the functional characteristics of locations (Wang et al., 2023; Liang et al., 2024).\nTo address these limitations, we propose NextLocLLM, the first known model to integrate LLM directly into next location prediction structure. Unlike traditional approaches that rely on discrete location IDs, NextLocLLM uses normalized spatial coordinates, which better capture geographical distances between locations and enhance transferability and generalization across diverse urban settings. Additionally, NextLocLLM incorporates LLM-enhanced POI embeddings to more effectively model locations' functional attributes, resulting in a more comprehensive predictive framework."}, {"title": "3 PROBLEM FORMULATION", "content": "Let $L = \\{loc_1,\\ldots,loc_p\\}$ be the set of locations, and $SD = \\{SD_1,\\ldots, SD_q\\}$ be the set of possible stay durations. $TI = \\{(d,t)\\}$ is the set of temporal information, where d represents day-of-week (0 \u2264 d \u2264 7) and t is time-of-day (0 \u2264 t \u2264 23 in hours). Each location $loc \\in L$ is represented as a tuple $(id, x, y, poi)$, where id is a discrete identifier, x and y are the spatial coordinates of location's centroid, and poi represents the location's POI attributes (see Definition 2.2).\nDefinition 2.1 (Visiting Record). A record is defined as a tuple $s = (loc, (d, t), dur) \\in L \\times TI \\times SD$, indicating that a user visited location loc on day d at hour t, and stayed for a duration of dur."}, {"title": "4 METHOD", "content": "Figure 2 illustrates an overview of our proposed NextLocLLM, which consists of four main components: (1) multi-dimensional trajectory content embeddings, (2) LLM-enhanced POI embedding, (3) an LLM backbone, and (4) a prediction retrieval module. First, we encode mobility trajectories using features including spatial coordinates, temporal information, and stay duration, to generate trajectory content embeddings. In addition, leveraging LLMs' comprehension abilities, we generate semantic embeddings for each POI category based on their natural language descriptions. These semantic embeddings are then aggregated into a weighted sum, where the frequency of each POI category serves as weights, thus effectively capturing functional attributes of locations and producing LLM-enhanced POI embeddings. Moreover, we design prompt prefix to enhance LLM's understanding of both the prediction task and the data structure. The prompt prefix, combined with trajectory content embeddings and LLM-enhanced POI embeddings, are then passed into the LLM backbone. Finally, the predicted coordinates from the LLM are processed through the prediction retrieval module, which employs a KD-tree to retrieve the k nearest candidate locations, ensuring structured prediction results."}, {"title": "4.1 MULTI-DIMENSIONAL TRAJECTORY CONTENT EMBEDDINGS", "content": "For each mobility trajectory, we extract features for each record from both the historical trajectory $S_h$ and the current trajectory $S_c$. These features include spatial coordinates $((x, y)_h, (x, y)_c)$, time-of-day $(T_h, T_c)$, day-of-week $(D_h, D_c)$ and stay duration $(Dur_h, Dur_c)$. Each sequence is processed using embedding or linear mapping functions, with the same function applied to both historical and current sequences of the same feature type. Specifically, we develop embeddings for time-of-day and day-of-week, denoted as $f_t$ and $f_d$. Additionally, we utilize linear mappings for spatial coordinates and stay duration, represented by $f_{xy}$ and $f_{dur}$, to transform raw data into compact embeddings.\nTemporal and Stay Duration Embeddings. To capture temporal characteristics of mobility trajectories, we employ independent embeddings for two critical temporal information: time-of-day (T) and day-of-week (D). These temporal aspects are crucial, as user mobility patterns are often strongly correlated with specific times and days. The temporal features are transformed into embedding vectors through look-up operations from their respective embedding tables, where time-of-day embeddings and day-of-week embeddings are generated by $E_T = f_t(T) \\in R^{lseq \\times dt}$ and $E_D = f_d(D) \\in R^{lseq \\times dd}$, respectively. In addition, stay duration is another critical temporal dimension for understanding user behavior. Typically, longer stay durations indicate more complex activities, such as working or dining, while shorter durations are associated with quick actions or transitory activities. The stay durations are processed with min-max normalization, and then transformed into embeddings through linear mapping function $E_{Dur} = f_{dur}(Dur) \\in R^{lseq \\times d_{dur}}$.\nSpatial Coordinates Embeddings. Existing methods typically use numerical identifiers as location IDs to represent and encode location information. However, these discrete IDs neither capture the geographical relationships between locations nor enable effective transferability across different cities. Thus, we propose using spatial coordinates instead of discrete IDs to represent locations' geographic information. Specifically, we utilize Web Mercator coordinates, as they can reflect the spatial relationships between locations. At city level, the gap between geodesic distance and Euclidean distance under Web Mercator projection is minimal, making it suitable for practical applications (Battersby et al., 2014; Peterson, 2014). While Web Mercator coordinates effectively capture spatial relationships within cities, the range in coordinates vary significantly between cities, which presents generalization challenges in zero-shot scenarios. To mitigate this, we apply normalization by scaling them to a standard normal distribution N(0, 1). The mean and variance for it are based on spatial coordinates from all mobility trajectory records in the target city, rather than the geographical data, as high population density areas are not always located at the geometric center of a city. Finally, the normalized coordinates (x', y') are transformed into spatial coordinates embeddings with a linear function: $E_{xy} = f_{xy}(x', y') \\in R^{lseq \\times d_{xy}}$.\nTrajectory Content Embeddings. So far, we have obtained spatial coordinates embeddings $E_{xy}$, time embeddings $E_T$, day embeddings $E_D$, and stay duration embeddings $E_{Dur}$. To integrate these features, we first concatenate these embeddings for each trajectory to generate the combined content embeddings:\n$E_{all_h} = E_{xy_h}||E_{T_h}||E_{D_h}||E_{Dur_h} \\in R^{M \\times (d_{xy}+d_{t}+d_{d}+d_{dur})}$ (1)\n$E_{all_c} = E_{xy_c}||E_{T_c}||E_{D_c}||E_{Dur_c} \\in R^{N \\times (d_{xy}+d_{t}+d_{d}+d_{dur})}$ (2)\nAfter we obtain the combined content embeddings, we apply nonlinear functions $f_h$ and $f_c$, parameterized by multi-layer perceptrons (MLP), to convert these embeddings into LLM's embedding dimension $d_{lm}$ for the historical trajectory and the current trajectory respectively:\n$E_{cont_h} = f_h(E_{all_h}) \\in R^{M \\times d_{lm}}$, $E_{cont_c} = f_c(E_{all_c}) \\in R^{N \\times d_{lm}}$ (3)"}, {"title": "4.2 LLM-ENHANCED POI EMBEDDING", "content": "In next location prediction, understanding the functional attributes of a location is crucial. The functionality of a location is determined by the distribution of various points-of-interest (POIs) within that area. Prior research (Hong et al., 2023; Yang et al., 2022) has demonstrated that incorporating POI information offers deeper insights into location characteristics, helping to capture user preferences and behaviors. However, these methods represent POI distributions as simple numerical vectors, neglecting the rich semantic content contained within these categories. This simplification limits the potential of these models to fully exploit POI information, thereby degrading model performance.\nTo address this issue, we propose LLM-enhanced POI embeddings, leveraging LLMs to better represent the functional attributes of locations. Specifically, for the natural language descriptions of POI categories $intr = (i_1,\\ldots, i_r)$, we generate corresponding POI semantic embeddings $E_i = (E_1,\\ldots, E_r) \\in R^{r \\times l \\times d_{lm}}$ through the token embedding layer of LLM, where l is a predefined description length. The POI distribution $freq = (f_1,\\ldots, f_r)$ at each location is then used as weights to perform a weighted summation of the corresponding POI semantic embeddings, resulting in the initial location-level POI embeddings:\n$E_{POIloc,init} = \\sum_{j=1}^r \\sum_l E_{i_j} * f_j \\in R^{l \\times d_{lm}}$ (4)\nTo further integrate such POI semantic information, we apply a nonlinear transformation with MLP to obtain the final location-level LLM-enhanced POI embeddings:\n$E_{POILoc} = MLP(E_{POIlocsinit}) \\in R^{d_{lm}}$ (5)\nFor mobility trajectories, we concatenate the location-level POI embeddings for each record, producing the initial trajectory-level LLM-enhanced POI embeddings $E_{L-POI} \\in R^{lseq \\times d_{ilm}}$. Additionally, such trajectory-level LLM-enhanced POI embeddings for historical and current trajectory are separately passed through $f_{hpoi}$ and $f_{cpoi}$ with MLP, to accommodate the distinct temporal semantics of historical and current trajectories as the LLM-enhanced POI embeddings for each type of trajectory:\n$E_{L-POI_h} = f_{hpoi}(E_{L-POI}) \\in R^{M \\times d_{lm}}$, $E_{L-POI_c} = f_{cpoi}(E_{L-POI}) \\in R^{N \\times d_{lm}}$ (6)"}, {"title": "4.3 LARGE LANGUAGE MODEL BACKBONE", "content": "Total Input Embeddings Given the the content embeddings $E_{cont_h}$ and $E_{cont_c}$, representing historical and current trajectories respectively, and the corresponding LLM-enhanced POI embeddings $E_{L-POI_h}$ and $E_{L-POI_c}$ that capture the functional attributes of various locations, we combine these two embeddings to form the final embeddings for both the historical and current trajectories:\n$E_{his} = E_{cont_h} + E_{L-POI_h} \\in R^{M \\times d_{lm}}$, $E_{cur} = E_{cont_c} + E_{L-POI_c} \\in R^{N \\times d_{lm}}$ (7)\nTo further improve the model's comprehension of the input data and prediction task, we craft a task- and data-specific prompt prefix that defines the task, describes the data, and explains how to utilize historical and current trajectories (see Appendix H). This prompt prefix is processed through LLM's token embedding layer to generate prompt prefix embeddings. Finally, we concatenate prompt prefix embeddings with the two final embeddings to form the total input embeddings for the LLM:\n$E_{total} = E_{instruct}||E_{his}||E_{cur}$ (8)\nPartially Frozen Large Model. To fully leverage the extensive knowledge embedded within LLMs while preserving their powerful reasoning capabilities, we adopt the strategy in (Zhou et al., 2023) by freezing the self-attention and feedforward layers of the LLM. These core components retain the majority of the knowledge acquired during pre-training, and freezing them ensures that this knowledge remains intact, preventing unintended modifications during task-specific fine-tuning. We inject the task-specific knowledge for the next location prediction task by fine-tuning a small subset of parameters contained in positional encoding layers and layer normalization (Zhou et al., 2023; Liu et al., 2024). This allows LLM to quickly adapt to our task with minimal costs and resources. Specifically, given the total input embedding $E_{total}$, the LLM produces the output representation $E_* = LLM(E_{total})$. We extract the last vector $v_o \\in R^{d_{lm}}$ from $E_*$ at the end of the sequence, and apply an nonlinear function $f_o$ to generate the predicted spatial coordinates $xy' = f_o(v_o)$. This result is then converted back to te original scale to obtain the denormalized coordinates $xy$. During training, the objective is to minimize the Euclidean distance between $xy'$ and ground truth $xy$."}, {"title": "4.4 PREDICTION RETRIEVAL MODULE", "content": "During inference, after obtaining the predicted coordinates xy, we employ a prediction retrieval module to determine the most likely top-k locations, to produce structured next location prediction. Specifically, we construct a KD-tree based on spatial coordinates of all candidate locations' centers. By using xy, as the query point to this KD-tree, we retrieve the top-k locations closest to the predicted coordinates. These locations are then returned as the final top-k location predictions of NextLocLLM."}, {"title": "5 EXPERIMENT", "content": "In this section, we evaluate the performance of NextLocLLM in comparison with existing methods under both fully-supervised and zero-shot next location prediction scenarios. In fully-supervised scenarios, each model is tested on data from the same cities as the training set, whereas in zero-shot scenarios, each model is tested on data from cities that are not part of the training set, requiring the model to generalize based on knowledge learned from other cities. The code for NextLocLLM is available at: https://anonymous.4open.science/r/NexelocLLM-1CF8/"}, {"title": "5.1 EXPERIMENTAL SETUP", "content": "5.1.1 BASELINE MODELS\nWe selected several classical baseline models as well as recently proposed methods for comparison. These models include those not designed for zero-shot scenarios (LSTM, FPMC, GRU, STRNN, C-MHSA, DeepMove, and GETNext) and models that support zero-shot next location prediction (LLMMob and ZS-NL). Detailed descriptions of these baseline models are provided in Appendix. G.\n5.1.2 DATASETS\nWe used four user mobility trajectory datasets in our experiments, including three open-source datasets-Xi'an, Chengdu (Zhu et al., 2023), and Japan (Yabe et al., 2024b)\u2014and one private dataset from Singapore. These datasets cover diverse geographical regions and user behavior patterns, ensuring our results to be broadly applicable. Detailed descriptions can be found in Appendix I.\n5.1.3 EVALUATION METRICS\nWe employed Hit@1, Hit@5, and Hit@10 as the evaluation metrics for model performance. These metrics measure the proportion of cases in which the model correctly predicts the target location within the top-k predictions. Specifically, they indicate the accuracy of models when the correct location appears in the top 1, top 5, or top 10 predictions.\n5.1.4 EXPERIMENT CONFIGURATION\nFor each dataset, we split the data for training, validation, and testing with a 70%/10%/20% ratio. For zero-shot tasks, we only used the final 20% test set for evaluation. For LLM backbone in NextLocLLM, GPT-2 is employed unless otherwise specified. We also utilized other LLMs (Llama2-7B and Llama3-8B) as the backbone for NextLocLLM and found that their prediction performances are relatively consistent compared to using GPT-2. Detailed results can be found in Appendix L."}, {"title": "5.2 FULLY SUPERVISED NEXT LOCATION PREDICTION PERFORMANCE COMPARISON", "content": "Table 1 presents the performance of different models on next location prediction tasks in fully-supervised scenarios. The table is divided into three sections by two horizontal lines. Models above the first horizontal line are designed for fully-supervised scenarios, while models above the second horizontal line can be used in both fully-supervised and zero-shot settings.\nIn the first group, models like STRNN, LSTM, FPMC, and GRU struggle to effectively capture temporal dependencies, leading to relatively poor performance. In contrast, models that utilize attention mechanisms, such as C-MHSA, DeepMove, and GETNext, demonstrate significantly better predictive performance. The attention mechanism allows these models to better capture complex dependencies across different time points, thereby improving prediction accuracy.\nIn the second group, LLMMob and ZS-NL interact with LLMs purely through prompts. Compared with ZS-NL, LLMMob provides more detailed task instructions to guide LLMs, thus outperforming ZS-NL. LLMMob (wt) and LLMMob (wot) denote whether temporal information is considered. The results show that models including temporal information (wt) outperform those without (wot), indicating that time is a crucial feature in next location prediction and significantly enhances model accuracy. Additionally, the suffix \"s\" indicates a strict requirement for the LLM to output exactly 10 location IDs. If this requirement is not met, even if the correct location is predicted, it does not count toward the accuracy. Conversely, configurations without the \"s\" suffix relax this restriction. This experimental setup was based on our observation that, even when the prompt clearly specifies the output format and the required number of location IDs, these models sometimes generate outputs with incorrect formats or numbers of IDs (see Sec Fig. 3 for details). Results show that enforcing strict output requirements leads to a significant performance drop for both LLMMob and ZS-NL.\nFurthermore, we observe that all models perform better on Xi'an and Chengdu datasets compared to Japan dataset. We attribute this to the fact that Xi'an and Chengdu datasets have more users, a longer time span, and shorter average sampling intervals. These factors provide richer mobility information for the models, enabling them to better learn travel patterns and improve performance.\nOur proposed NextLocLLM consistently outperforms all baseline models across these datasets. NextlocLLM leverages spatial coordinates to represent locations, which allows it to better model spatial relationships between locations. Additionally, it uses LLM-enhanced POI embeddings to fully exploit the large model's natural language understanding capabilities, capturing the functional attributes of locations more effectively. On Xi'an dataset, NextLocLLM achieved the highest scores. Even on Chengdu and Japan datasets, where Hit@1 was slightly lower, NextLocLLM still outperformed other models in Hit@5 and Hit@10, showcasing strong predicting capabilities.\nAdditionally, we conducted experiments on a private dataset from Singapore. This dataset is relatively sparse and of lower quality, resulting in poor performance for all models. However, even in this sparse and low-quality data environment, NextLocLLM maintained competitive performance, outperforming other models. Detailed results and analysis for the Singapore dataset can be found in Appendix J"}, {"title": "5.3 ZERO-SHOT NEXT LOCATION PREDICTION PERFORMANCE COMPARISON", "content": "Table 2 presents the performance of different models in zero-shot scenarios. We compared LLMMob, ZS-NL, and our proposed NextLocLLM. For NextLocLLM, we trained the model on Singapore, Chengdu, and Japan datasets, and then directly tested it on Xi'an dataset. In addition to accuracy metrics, we also calculated the geographical distance between predicted coordinates and actual location centers to further evaluate NextLocLLM's precision. For reference, the average geographical distance in the fully-supervised scenario for NextLocLLM on the Xi'an dataset is 176.9 meters.\nThe results show that well-trained NextLocLLM models demonstrate strong cross-city generalization. Specifically, NextLocLLM (Chengdu -> Xi'an) and NextLocLLM (Japan -> Xi'an) outperformed other zero-shot models, demonstrating robust cross-city adaptability. In contrast, NextLocLLM (Singapore -> Xi'an) performed the weakest, likely due to the lower quality of the Singapore dataset, which hindered proper training and limited the model's ability to generalize in the zero-shot scenario.\nThe geographical distance results further support this analysis. For NextLocLLM (Chengdu -> Xi'an), the average prediction error was 449.79 meters, which is close to the 176.9 meters observed in fully-supervised scenario and smaller than the 500-meter grid size for locations, indicating high"}, {"title": "5.4 ABLATION STUDY", "content": "To validate the effectiveness of different components in NextLocLLM, we conducted a series of ablation experiments in this section.\n5.4.1 ABLATION STUDY FOR NEXTLOCLLM KEY COMPONENTS\nWe first evaluated the impact of adding prompt prefix, using LLM-enhanced POI embeddings, and freezing most of LLM's parameters versus using fine-tuning methods like LoRA. Specifically, not using LLM-enhanced POI embeddings means treating the POI distribution of each location as a simple numerical vector and applying a linear mapping directly to generate the POI embeddings $E_{POI} \\in R^{d_{poi}}$. In this case, equations (1) and (2) will change as follows:\n$E_{all} = E_{xy}||E_T||E_D||E_{dur}||E_{POI} \\in []R^{M \\times (d_{xy}+d_{t}+d_{d}+d_{dur}+d_{poi})}$ (9)\nMoreover, due to the absence of LLM-enhanced POI embeddings, the final embeddings for historical and current trajectories, $E_{cont_h}$ and $E_{cont_c}$, are simply just their content embeddings $E_{cont_h}$ and $E_{cont_c}$"}, {"title": "6 CONCLUSION", "content": "In this paper, we present NextLocLLM, the first known method to integrate large language models (LLMs) into the structure of next location prediction models. By innovatively encoding normalized spatial coordinates, NextLocLLM effectively captures geographic relationships between locations and its ability to transfer across different cities is significantly enhanced. Additionally, NextLo-CLLM incorporates LLM-enhanced POI embeddings, leveraging LLMs to encode natural language descriptions of point-of-interest (POI) categories, enabling itself to better understand the functional characteristics of locations. To reduce training costs while preserving the pre-trained knowledge, we freeze most of the LLM's parameters and fine-tune only a few key layers. This strategy ensures that LLMs can quickly adapt to next location prediction task. The prediction retrieval module guar-antees structured top-k location predictions. Experimental results demonstrate that NextLocLLM consistently outperforms baseline models in both fully-supervised and zero-shot prediction scenarios, showing strong power in next location prediction task. Ablation studies confirm the contribution of each key module to the overall performance. However, we observe that the current model's geograph-ical distance error remains a challenge, typically exceeding 200 meters, which limits its effectiveness in fine-grained prediction tasks, such as those with a 50-meter grid size. Future work will explore incorporating user profile information and other essential elements to further improve accuracy. Overall, NextLocLLM offers an innovative and effective solution for next location prediction, with significant potential for real-world applications across various domains."}, {"title": "A PROMPT FOR ZS-NL AND LLM-MOB", "content": "In this section, we present the prompt formats used by the baseline models ZS-NL and LLM-Mob. We preserve the original prompt content from the source papers in full. We highlighted in red the parts of each model's prompt that specify the required number of location IDs to be output. Additionally, to clearly differentiate between LLM-Mob(wt) and LLM-Mob(wot), the extra components in LLM-Mob(wt) are marked in blue."}, {"title": "B EXAMPLE FOR WRONGLY STRUCTURED OUTPUT BY PURELY PROMPTED-BASED NEXT LOCATION PREDICTION MODEL", "content": "Fig 3 shows examples of LLM-Mob on the Xi'an dataset. We can observe that for line index 1, the model only produced three outputs, even though the prompt clearly instructed the LLM to provide 10 possible location IDs. This discrepancy highlights a common issue with prompt-based models: they sometimes fail to follow explicit instructions regarding output structure. In this case, despite the requirement for 10 locations, the model returned fewer results, which could affect the overall performance. This inconsistency raises concerns about the reliability of prompt-based methods when dealing with structured output requirements, particularly in tasks that demand a specific number of predictions."}, {"title": "C POI CATEGORIES' DESCRIPTION", "content": "In this section, we provide descriptions of the different POI categories across various datasets. The raw POI distribution for the Xi'an and Chengdu datasets are sourced from (Center, 2017), while the Japan dataset comes with its own raw POI distribution, and the raw POI distribution data for the Singapore dataset was scraped from openstreetmap. The original POI categories were quite numerous, resulting in very few POIs for each location and making the vectors extremely sparse. Additionally, the definitions and classifications of POIs vary significantly across the datasets. To address these issues, we clustered POI categories with similar attributes, aggregated the number of POIs in each category for each location, and provided natural language descriptions for each clustered POI category."}, {"title": "D TRANSFORMATION FROM LONGITUDE & LATITUDE TO WEB MERCATOR", "content": "Given a location's geographic coordinates (lon,lat), we can convert them into Web Mercator coordinates using the following formulas:\n$lon_{wm} = lon \\times \\frac{R}{D}$ (10)\n$lat_{wm} = ln(tan(\\frac{\\pi}{4} + \\frac{lat}{2})) \\times \\frac{R}{D}$ (11)\nwhere R represents half the Earth's circumference, which is approximately 20, 037, 508.34 meters. The constant D represents 180 degrees, as the Earth's longitude ranges from -180 to 180."}, {"title": "E ANALYSIS OF WEB MERCATOR PROJECTION'S LITTLE BIAS IN URBAN AREAS", "content": "The bias of the Web Mercator projection increases with latitude, but within smaller regions (such as city scales), this bias is relatively minimal, particularly for cities located in low- and mid-latitude areas (Battersby et al., 2014; Peterson, 2014; Hwang, 2013). To clarify this, we can explain through mathematical analysis.\nThe Web Mercator projection maps spherical coordinates (longitude and latitude) onto 2D plane coordinates, with the formulas shown in Appendix D. The Mercator projection preserves angles (conformal) but not area, meaning that regions at higher latitudes (especially near the poles) are stretched in terms of area and distance. For lower and mid-latitude regions (such as most city scales), this distortion is relatively minor and can be neglected. We can demonstrate the Web Mercator projection's bias at a city scale with the following approach.\nAssume the latitude range within a city is Alat and the longitude range is Alon. Since the Web Mercator projection maintains a linear relationship for longitude, the primary bias arises from the non-linear term in latitude $lat_{wm} = ln(tan(\\frac{\\pi}{4} + \\frac{lat}{2})) \\times R$. If the latitude difference within the city is small (e.g., within 1\u00b0), we can analyze the error over this small range using a Taylor expansion:\n$y(lat + Alat) \u2248 y(lat) + \\frac{dy}{dlat} Alat$ (12)\nWe then calculate $\\frac{dy}{dlat} = \\frac{R}{cos(lat)}$. At low and mid-latitudes, this calculation shows that the error is relatively small, meaning the Web Mercator projection behaves almost linearly within this range."}, {"title": "G BASELINE DESCRIPTION", "content": "The details of baseline methods are briefly summarized as follows. For FPMC, LSRM, GRU, STRNN and DeepMove, we use their implementation provided by the package Libcity whereas for C-MHSA, GETNext, LLM-Mob and ZS-NL, we use the source codes released by their authors.\n\u2022 FPMC (Rendle et al., 2010): a method bringing both matrix factorization (MF) and Markov chains (MC) approaches together, which is based on personalized transition graphs over underlying Markov chains.\n\u2022 LSTM (Graves & Graves, 2012) A type of recurrent neural network capable of learning order dependence in sequence prediction problems.\n\u2022 GRU (Chung et al., 2014) Similar to LSTMs, GRUs are a streamlined version that use gating mechanisms to control the flow of information and are effective in sequence modeling tasks.\n\u2022 STRNN (Liu et al., 2016) This model focuses on introducing spatiotemporal transfer features into the hidden layer of RNN.\n\u2022 Deepmove (Feng et al., 2018) This model uses the attention mechanism for the first time to combine historical trajectories with current trajectories for prediction.\n\u2022 GETNext (Yang et al., 2022) An model utilizes a global trajectory flow map and a novel Graph Enhanced Transformer model to better leverage extensive collaborative signals.\n\u2022 C-MHSA (Hong et al., 2023) An MHSA-based model that integrates various contextual information from raw location visit sequences.\n\u2022 LLM-Mob (Wang et al., 2023) An purely prompt based model which introduced concepts of historical and contextual stays to capture the long-term and short-term dependencies in human mobility.\n\u2022 ZS-NL (Beneduce et al., 2024) Another purely prompt based model designed for zero-shot next location prediction."}, {"title": "H PROMPT PREFIX PROVIDED", "content": "In this section, we outline the specific task and data prompt prefix used in NextLocLLM. The prompt prefix begins by defining the task and providing a detailed description of the dataset structure. Additionally, the Additional Description section emphasizes how to think about this task using the provided data."}, {"title": "I DATASET INTRO", "content": "We"}]}