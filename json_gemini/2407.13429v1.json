{"title": "Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information", "authors": ["Fedor Sergeev", "Paola Malsot", "Gunnar R\u00e4tsch", "Vincent Fortuin"], "abstract": "Knowing which features of a multivariate time series to measure and when is a key task in medicine, wearables, and robotics. Better acquisition policies can reduce costs while maintaining or even improving the performance of downstream predictors. Inspired by the maximization of conditional mutual information, we propose an approach to train acquirers end-to-end using only the downstream loss. We show that our method outperforms random acquisition policy, matches a model with an unrestrained budget, but does not yet overtake a static acquisition strategy. We highlight the assumptions and outline avenues for future work.", "sections": [{"title": "1. Introduction", "content": "In the medical setting, clinicians often need to monitor patients over time during their hospital stay, especially in Intensive Care Units [ICUs; 6]. They try to improve the patient's state by administering drugs while relying on continuous measurements of vital signs (e.g., heart rate) and occasional lab tests (e.g., blood tests, X-rays). While the continuous measurements are automatic and practically free, performing lab tests takes the clinical staff's time and incurs additional costs. We aim to develop a method for recommending which lab tests to perform, in order to best monitor the patient's state, while decreasing workload and costs.\nMore formally, the hospital stay of a patient i can be represented as a multivariate (or even multi-modal) time series $x^i = \\{x_t^f\\}$ with the features f at time t being the values of either vital signs, lab tests, or administered drugs. Usually, these data are used for time series classification (e.g., mortality prediction), early event prediction (e.g., circulatory failure prediction), or intervention recommendation [6, 10, 12, 22].\nWe consider the Dynamic Feature Acquisition (DFA) task based on an observed patient state $\\{x_t^f\\}_{t < \\tau}$ at time $ \\tau$, recommend which feature(s) f should be measured at some future time $ \\tau'$ at known cost $C_{\\tau, f}$ (see Figure 1). The aim is to reduce the total measurement cost $\\sum_{t,f} C_{t,f}$ while maintaining or even improving the performance of a downstream predictor.\nDFA is also relevant for wearables (e.g., extend battery life by reducing the number of sensor activations) [14, 17], active perception in robotics [2], and efficient video classification [21]."}, {"title": "2. Problem Setting", "content": "Let us assume that the time series are regular, indexed with $t \\in \\{0, ..., T'\\}$, where $T'$ is the length of $x^i$. We consider the case when an acquisition recommendation is made for features that will become available at the next time step (\u201cnext-step\u201d assumption): $ \\tau' = \\tau + 1$. For simplicity, we assume that the measurement cost is constant over time and features: $C_{t,f} =: c$. Without loss of generality, we set $c = 1$. Similarly to Kossen et al. [9], we assume that the data are fully observed.\nWe set a budget for the total acquisition cost. For static data, the budget is usually be given per sample. For time series, a budget per time step $b(x_t, t)$ should be predicted from the sample budget. In our experiments, we consider a simplified scenario, when it is constant and given a priori: $b(x_t, t) = b$.\nThe acquisition and prediction cycle under these assumptions is shown in Figure 1. Here, an acquirer is a model that at each time step $ \\tau$ outputs the acquisition vector $m_\\tau$. It is a binary vector with ones indicating which features should be acquired at the next time step $ \\tau + 1$. Since the data are fully observed, we imitate the measurement procedure with an element-wise product. The measured data are then passed to the classifier. Additionally, the acquirer and classifier may have access to each other's internal state. We discuss the assumptions and provide pseudocode of the DFA cycle in Appendix B.\nNote that the models here are not limited to recurrent architectures: time steps can be accumulated, and the classifier (e.g., a transformer) reapplied [20]. At the same time, by having the classifier receive new data at each time step, we allow for it to be used for both classification and early event"}, {"title": "3. Method", "content": "DFA usually follows one of two approaches: use the cost estimate as a penalty function to train the acquisition model using reinforcement learning [9, 23], or use some acquisition function to rank and select the most meaningful features [3, 13]. The latter approach often uses CMI. Estimating it directly (e.g., using a partial variational autoencoder) can be challenging [13]. Instead, CMI can be approximated [3]. We discuss related work in Appendix A.\nIn Covert et al. [3], the authors use a neural network and Categorical distribution to sequentially predict the feature with the largest CMI, and perform (greedy) selection on static data. Similarly, we use the acquirer neural network to predict logits of the approximate CMI at each time step of the time series (see Figure 2). We then iteratively (until the budget b is reached) sample a one-hot vector indicating the selected feature using the Gumbel-Softmax [GS; 7]. To avoid selecting the same feature twice, we subtract a penalty vector from the acquirer's output. This approach is differentiable and therefore can be trained end-to-end via backpropagation using the classification loss. Further details are available in Appendix D.1."}, {"title": "4. Experiments", "content": "We test the proposed method on the FordA and SpokenArabicDigits datasets from the UCR and UEA time series classification archives [1, 4]. The data summary and samples are shown in Appendix C. We consider balanced classification and use accuracy as the performance metric. By default, no features are considered observed; they all have to be explicitly acquired.\nThe FordA dataset is univariate, so, to imitate a multivariate dataset, we take m = 10 consecutive time steps from FordA and set them as one time step with m features of a new m-FordA dataset (short for multivariate or multi-step FordA). In contrast, SpokenArabicDigits is multivariate and variable length by design."}, {"title": "4.1. Fake features", "content": "The features in these datasets are quite similar (i.e., measured by the same device). Therefore it is not obvious whether one feature is more informative than another. To reliably test whether our model learns to acquire the right features, we add 30 fake features that do not hold any information about the class label (see Figure 3(a)). We test three different varieties of fake features: zeros, Gaussian noise, and samples from a Gaussian process (GP).\nWe set a constant budget per time step of b = 5 and compare our method to a random acquisition policy (selects b features at random at each step) and a complete acquisition policy (selects all features at each step). This means that the complete acquirer obtains 8 times more features than the other two.\nThe classification accuracy on SpokenArabicDigits is presented in Table 1, and the acquisition patterns for zeros on m-FordA are presented in Figure 3. Other results, samples, training and implementation details are available in Appendix D.1.\nOur acquirer consistently outperforms the random acquisition policy, and often even matches the performance of the complete acquirer. The acquisition patterns show that our acquire starts selecting the real features (notice the horizontal lines), although still occasionally sampling fake"}, {"title": "4.2. Shifted fake features", "content": "To test whether the learned acquisition is dynamic, we shift the real features so that the acquisition pattern would have to change over time (see Figure 3(d)). The dynamic policy should be able to learn that shift, while a static acquirer will only select the same set of features throughout the time series. We use a random forest (RF) as a static feature selection baseline, as it has been used for feature importance analysis of ICU data [6].\nThe results and the acquisition patterns are shown in Table D.2 and Figure 3. Our acquirer outperforms the random policy, but is outperformed by the static policy. The acquisition pattern shows that the model does not manage to capture the shift in fake features.\nWe hypothesize that the underperformance of our acquirer is due to its simplistic architecture. The time step is passed to the model, but it does not receive the hidden state of the classifier. A more sophisticated architecture (e.g., an LSTM) that receives the classifier state as input will likely perform better."}, {"title": "5. Conclusion", "content": "Dynamic feature acquisition is a challenging problem that arises for temporal data across various applications: medicine, wearable sensors, active perception, etc. It has seen little attention, with previous work considering only reinforcement learning approaches.\nIn this work, we propose to dynamically select the most informative features using an approach similar to CMI maximization. We show that the acquirer trained using our approach learns to distinguish fake features from real ones for time series classification. Our model outperformed a random acquisition policy, but it did not surpass the static acquisition. This performance gap is likely due to the simplicity of the used architectures.\nWe hope that this work will be continued, as a wide range of questions remain open. Future work may consider more advanced architectures, compare the performance of our training approach to reinforcement learning [9], and loosen the assumptions we adopted: fixed time step budget, fully observed training data, and equal feature acquisition cost."}, {"title": "Appendix A. Related work", "content": "To the best of our knowledge, the only prior work that has considered DFA on time series data is Kossen et al. [9]. They use reinforcement learning and focus on multimodal data. Feature acquisition on static data has received wider attention. Both methods using mutual information [3, 11, 13] and reinforcement learning [23] have been developed.\nIn Ma et al. [13], CMI is estimated by training a partial variational autoencoder (P-VAE). This allows the model to perform imputation from any subset of observed features and select the features associated with high-value information. In Lewis et al. [11], this approach has been developed further with the use of transformers for processing sets of observed features. The main challenge with using the P-VAE is its training. Training generative models can be challenging, especially for more complex data such as images [3].\nAn alternative approach presented in Covert et al. [3] aims to approximate CMI instead of estimating it precisely. They propose using a Categorical distribution and greedily select the feature with the largest CMI at each step. Unlike Ma et al. [13], they use only simple (dense) architectures. However, their approach accepts set-based models as well.\nFor static ICU data, deep reinforcement learning has been used for DFA training [23]. The authors took into account that medical tests are usually done in panels (i.e., provide multiple features at the same time) and differ in cost. They also produce the accuracy-cost Pareto fronts, which help analyze the trade-off made when setting a specific acquisition budget.\nDFA using CMI is closely related to active learning and active feature acquisition (see Figure A.1). Recent works show that Bayesian models can perform well in active learning [18]. It has been shown that Bayesian acquisition functions such as Bayesian active learning by disagreement (BALD) are connected to CMI [13]. Perhaps other Bayesian acquisition functions, such as expected predictive information gain [EPIG; 19], could be adapted for use in DFA.\nFor ICU time series data, feature importance has been studied using random forests [6]. In Hyland et al. [6], Y\u00e8che et al. [22] authors showed that deep learning architectures can achieve state-of-the-art performance in early event prediction. Tokenization of observed ICU features has been shown to improve the performance of such models [10]. Tokenization of observed features is a natural part of the set-based approaches [13], and could be applied in DFA."}, {"title": "Appendix B. DFA", "content": "Algorithm 1: Next-step DFA on regular time series\nInput : time series x of length T, time step budget function b(\u00b7,\u00b7),\nacquirer with hidden state ht, classifier with hidden state Ht\nt\u21900\nmo \u2190 acquirer.init() // initial acquisition request\nwhile t < T do\nx't+1 \u2190 mt \u00b7 xt // measure requested features\nclassifier.step(x't+1, mt, ht, t)\nmt+1 \u2190 acquirer.step(x't+1, mt, b(xt, t), Ht, t)\nt\u2190t+1\nend\nYpred \u2190 classifier.predict() // make the prediction\nC = \u2211 mt // calculate the cost\nThe \u201cnext-step\u201d prediction assumption is satisfied when the time it takes to measure requested features is smaller than the time step duration. Both the \u201cnext-step\u201d and regularity assumptions are plausible for ICU when a bigger resolution (e.g., one hour) is chosen [6].\nThe assumptions about equal feature acquisition cost, fully observed data, and constant a prior set budget per time step do not hold for medical data. We leave generalization to future work."}, {"title": "Appendix C. Datasets", "content": ""}, {"title": "Appendix D. Experiments", "content": "D.1. Setup details\nThe acquirers are implemented using fully connected neural networks with 1 hidden layer (4 hidden units for m-FordA, and 8 for SpokenArabicDigits) and ReLU activations. The input is formed by concatenating the previous observation, acquisition mask, and current time step. The internal classifier state is not passed to the acquirer.\nThe classifiers are implemented using Long Short-Term Memory networks [LSTMs; 5] with 16 hidden units, 2 layers for m-FordA and 3 for SpokenArabicDigits (with ReLU activations), and a linear dimension of 8, followed by one linear layer outputting class logits.\nWe use a simpler training procedure compared to Covert et al. [3]: the temperature in the Gumbel distribution is fixed, and we do not pre-train the classifiers. For logits vector l, the penalty function R is R(l) = 100 \u00b7 mt \u00b7 |l|, where the absolute value is taken elementwise.\nWe use a random forest (static feature selector) with 1000 esimators, leaving the other parameters as defaults provided by scikit-learn [16].\nWe train using the Adam optimizer [8] with cross-entropy loss in PyTorch [15]. The batch size is 1000, and the learning rate is 0.001 in all experiments.\nD.2. Additional results"}]}