{"title": "Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information", "authors": ["Fedor Sergeev", "Paola Malsot", "Gunnar R\u00e4tsch", "Vincent Fortuin"], "abstract": "Knowing which features of a multivariate time series to measure and when is a key task in medicine, wearables, and robotics. Better acquisition policies can reduce costs while maintaining or even improving the performance of downstream predictors. Inspired by the maximization of conditional mutual information, we propose an approach to train acquirers end-to-end using only the downstream loss. We show that our method outperforms random acquisition policy, matches a model with an unrestrained budget, but does not yet overtake a static acquisition strategy. We highlight the assumptions and outline avenues for future work.", "sections": [{"title": "1. Introduction", "content": "In the medical setting, clinicians often need to monitor patients over time during their hospital stay, especially in Intensive Care Units [ICUs; 6]. They try to improve the patient's state by administering drugs while relying on continuous measurements of vital signs (e.g., heart rate) and occasional lab tests (e.g., blood tests, X-rays). While the continuous measurements are automatic and practically free, performing lab tests takes the clinical staff's time and incurs additional costs. We aim to develop a method for recommending which lab tests to perform, in order to best monitor the patient's state, while decreasing workload and costs.\n\nMore formally, the hospital stay of a patient $i$ can be represented as a multivariate (or even multi-modal) time series $\\boldsymbol{x}^{i}=\\left\\{x_{t, f}^{i}\\right\\}$ with the features $f$ at time $t$ being the values of either vital signs, lab tests, or administered drugs. Usually, these data are used for time series classification (e.g., mortality prediction), early event prediction (e.g., circulatory failure prediction), or intervention recommendation $[6,10,12,22]$.\n\nWe consider the Dynamic Feature Acquisition (DFA) task \u2014 based on an observed patient state $\\left\\{x_{t, f}^{i}\\right\\}_{t \\leq \\tau}$ at time $\\tau$, recommend which feature(s) $f$ should be measured at some future time $\\tau^{\\prime}$ at known cost $c_{\\tau, f}$ (see Figure 1). The aim is to reduce the total measurement cost $\\sum_{t, f} c_{t, f}$ while maintaining or even improving the performance of a downstream predictor.\n\nDFA is also relevant for wearables (e.g., extend battery life by reducing the number of sensor activations) [14, 17], active perception in robotics [2], and efficient video classification [21]."}, {"title": "2. Problem Setting", "content": "Let us assume that the time series are regular, indexed with $t \\in\\left\\{0, \\ldots, T^{i}\\right\\}$, where $T^{i}$ is the length of $\\boldsymbol{x}^{i}$. We consider the case when an acquisition recommendation is made for features that will become available at the next time step (\"next-step\" assumption): $\\tau^{\\prime}=\\tau+1$. For simplicity, we assume that the measurement cost is constant over time and features: $c_{t, f}=: c$. Without loss of generality, we set $c=1$. Similarly to Kossen et al. [9], we assume that the data are fully observed.\n\nWe set a budget for the total acquisition cost. For static data, the budget is usually be given per sample. For time series, a budget per time step $b(\\boldsymbol{x}_{t}, t)$ should be predicted from the sample budget. In our experiments, we consider a simplified scenario, when it is constant and given a priori: $b(\\boldsymbol{x}_{t}, t)=b$.\n\nThe acquisition and prediction cycle under these assumptions is shown in Figure 1. Here, an acquirer is a model that at each time step $\\tau$ outputs the acquisition vector $\\boldsymbol{m}_{\\tau}$. It is a binary vector with ones indicating which features should be acquired at the next time step $\\tau+1$. Since the data are fully observed, we imitate the measurement procedure with an element-wise product. The measured data are then passed to the classifier. Additionally, the acquirer and classifier may have access to each other's internal state. We discuss the assumptions and provide pseudocode of the DFA cycle in Appendix B.\n\nNote that the models here are not limited to recurrent architectures: time steps can be accumulated, and the classifier (e.g., a transformer) reapplied [20]. At the same time, by having the classifier receive new data at each time step, we allow for it to be used for both classification and early event prediction (tasks that are relevant for data from ICU and wearables). From this point on, we consider only classification objectives."}, {"title": "3. Method", "content": "DFA usually follows one of two approaches: use the cost estimate as a penalty function to train the acquisition model using reinforcement learning [9, 23], or use some acquisition function to rank and select the most meaningful features [3, 13]. The latter approach often uses CMI. Estimating it directly (e.g., using a partial variational autoencoder) can be challenging [13]. Instead, CMI can be approximated [3]. We discuss related work in Appendix A.\n\nIn Covert et al. [3], the authors use a neural network and Categorical distribution to sequentially predict the feature with the largest CMI, and perform (greedy) selection on static data. Similarly, we use the acquirer neural network to predict logits of the approximate CMI at each time step of the time series (see Figure 2). We then iteratively (until the budget $b$ is reached) sample a one-hot vector indicating the selected feature using the Gumbel-Softmax [GS; 7]. To avoid selecting the same feature twice, we subtract a penalty vector from the acquirer's output. This approach is differentiable and therefore can be trained end-to-end via backpropagation using the classification loss. Further details are available in Appendix D.1."}, {"title": "4. Experiments", "content": "We test the proposed method on the FordA and SpokenArabicDigits datasets from the UCR and UEA time series classification archives [1, 4]. The data summary and samples are shown in Appendix C. We consider balanced classification and use accuracy as the performance metric. By default, no features are considered observed; they all have to be explicitly acquired.\n\nThe FordA dataset is univariate, so, to imitate a multivariate dataset, we take $m=10$ consecutive time steps from FordA and set them as one time step with $m$ features of a new $m$-FordA dataset (short for multivariate or multi-step FordA). In contrast, SpokenArabicDigits is multivariate and variable length by design.\n\n4.1. Fake features\n\nThe features in these datasets are quite similar (i.e., measured by the same device). Therefore it is not obvious whether one feature is more informative than another. To reliably test whether our model learns to acquire the right features, we add 30 fake features that do not hold any information about the class label (see Figure 3(a)). We test three different varieties of fake features: zeros, Gaussian noise, and samples from a Gaussian process (GP).\n\nWe set a constant budget per time step of $b=5$ and compare our method to a random acquisition policy (selects $b$ features at random at each step) and a complete acquisition policy (selects all features at each step). This means that the complete acquirer obtains 8 times more features than the other two.\n\nThe classification accuracy on SpokenArabicDigits is presented in Table 1, and the acquisition patterns for zeros on m-FordA are presented in Figure 3. Other results, samples, training and implementation details are available in Appendix D.1.\n\nOur acquirer consistently outperforms the random acquisition policy, and often even matches the performance of the complete acquirer. The acquisition patterns show that our acquire starts selecting the real features (notice the horizontal lines), although still occasionally sampling fake features. Additionally, we note that in some cases, the complete acquirer exhibits overfitting, while our acquirer avoids it (e.g., for noise fake features on m-FordA, shown in Figure D.1).\n\n4.2. Shifted fake features\n\nTo test whether the learned acquisition is dynamic, we shift the real features so that the acquisition pattern would have to change over time (see Figure 3(d)). The dynamic policy should be able to learn that shift, while a static acquirer will only select the same set of features throughout the time series. We use a random forest (RF) as a static feature selection baseline, as it has been used for feature importance analysis of ICU data [6].\n\nThe results and the acquisition patterns are shown in Table D. 2 and Figure 3. Our acquirer outperforms the random policy, but is outperformed by the static policy. The acquisition pattern shows that the model does not manage to capture the shift in fake features. We hypothesize that the underperformance of our acquirer is due to its simplistic architecture. The time step is passed to the model, but it does not receive the hidden state of the classifier. A more sophisticated architecture (e.g., an LSTM) that receives the classifier state as input will likely perform better."}, {"title": "5. Conclusion", "content": "Dynamic feature acquisition is a challenging problem that arises for temporal data across various applications: medicine, wearable sensors, active perception, etc. It has seen little attention, with previous work considering only reinforcement learning approaches.\n\nIn this work, we propose to dynamically select the most informative features using an approach similar to CMI maximization. We show that the acquirer trained using our approach learns to distinguish fake features from real ones for time series classification. Our model outperformed a random acquisition policy, but it did not surpass the static acquisition. This performance gap is likely due to the simplicity of the used architectures.\n\nWe hope that this work will be continued, as a wide range of questions remain open. Future work may consider more advanced architectures, compare the performance of our training approach to reinforcement learning [9], and loosen the assumptions we adopted: fixed time step budget, fully observed training data, and equal feature acquisition cost."}]}