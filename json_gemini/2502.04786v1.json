{"title": "Enhancing SQL Injection Detection and Prevention Using Generative Models", "authors": ["Naga Sai Dasari", "Atta Badii", "Armin Moin", "Ahmed Ashlam"], "abstract": "SQL Injection (SQLi) continues to pose a significant threat to the security of web applications, enabling attackers to manipulate databases and access sensitive information without authorisation. Although advancements have been made in detection techniques, traditional signature-based methods still struggle to identify sophisticated SQL injection attacks that evade predefined patterns. As SQLi attacks evolve, the need for more adaptive detection systems becomes crucial. This paper introduces an innovative approach that leverages generative models to enhance SQLi detection and prevention mechanisms. By incorporating Variational Autoencoders (VAE), Conditional Wasserstein GAN with Gradient Penalty (CWGAN-GP), and U-Net, synthetic SQL queries were generated to augment training datasets for machine learning models. The proposed method demonstrated improved accuracy in SQLi detection systems by reducing both false positives and false negatives. Extensive empirical testing further illustrated the ability of the system to adapt to evolving SQLi attack patterns, resulting in enhanced precision and robustness.", "sections": [{"title": "I. INTRODUCTION", "content": "SQL Injection (SQLi) remains one of the most critical security vulnerabilities affecting web applications today. As cyber threats evolve, attackers continuously exploit input han-dling weaknesses, injecting malicious SQL commands into legitimate queries. These attacks, often launched through input fields such as login forms or URL parameters, enable unau-thorised access to sensitive data or, in severe cases, complete control over the database.\nThe Open Web Application Security Project (OWASP) con-tinues to rank SQLi among the top security risks, reinforcing its prevalence and severity in the landscape of web vulnerabil-ities [1]. The impact of SQLi attacks is often severe, leading to data breaches, financial loss, and reputational damage to affected organisations.\nTraditional defence mechanisms, such as input validation and signature-based detection systems, have been widely em-ployed to combat SQLi attacks. However, these methods often fall short when confronting the evolving techniques used by attackers. Signature-based systems, in particular, struggle with false positives and false negatives, especially when attackers use obfuscation or innovative variations of SQLi that deviate from known patterns [2], [3], [4]."}, {"title": "II. LITERATURE REVIEW", "content": ""}, {"title": "A. SQL Injection", "content": "Traditional SQL Injection (SQLi) prevention methods pri-marily focused on fundamental coding practices such as input validation and parameterised queries, which aimed to mitigate attacks by sanitising user inputs. Although these methods were effective for basic attacks, more sophisticated techniques, such as time-based, blind, and second-order SQL injections, enabled malicious inputs to bypass traditional validation mechanisms and execute the payload at a later stage [2]. As SQLi threats evolved, signature-based detection systems were introduced, relying on known attack patterns to identify malicious queries in real time. However, these systems encountered significant difficulties in handling novel and obfuscated attacks that devi-ated from predefined patterns, resulting in high false-positive"}, {"title": "B. Text Data Synthesis", "content": ""}, {"title": "1) Rule-based Text Synthesis", "content": "Text data synthesis is crucial for enhancing the performance of machine learning models, offering a range of techniques to generate synthetic data. Model-based techniques, such as those explored in the work of Panagiotis et al [13], generate diverse data by rephrasing content while preserving its meaning, though they are com-putationally demanding and can introduce semantic drift. On the other hand, rule-based augmentation methods, such as syn-onym replacement, random insertion, and swapping [14], offer computational efficiency but often fail to maintain contextual meaning, leading to distorted outputs. These limitations make rule-based methods unsuitable for complex tasks such as SQL query augmentation."}, {"title": "2) Model-based Text Synthesis", "content": "Large Language Models (LLMs), as highlighted in Lovelace et al [16], capture both short- and long-term dependencies, making them effective for tasks such as SQL query augmentation. However, LLMs require substantial computational resources and large data sets for training, which limits their utility in resource-constrained environments. Labs [17] discusses the use of Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs), with VAEs providing flexibility by manipulating latent space and GANs excelling in generating realistic data through adversarial training. However, GANs demand careful tuning to prevent mode collapse, which can limit their appli-cation in certain scenarios.\nTransformer-based models, such as BERT, T5, and BART, utilise attention mechanisms to capture long-range depen-dencies and are effective for tasks such as text generation and translation. However, these models face scalability chal-lenges when deployed at scale. Recurrent Neural Networks (RNNs), including LSTM and GRU, remain valuable for sequence modelling involving temporal dependencies but are increasingly being replaced by transformers in many scenarios.\nAdditionally, Diffusion Models, such as Denoising Diffusion Probabilistic Models (DDPM), introduced in the work of Labs [17], iteratively refine noisy data to improve sample quality and efficiency, though they also require significant computational resources. Seq-U-Net, introduced in the work of Stoller et al [18], provides a more efficient alternative for sequence modelling. By using causal convolutions, Seq-U-Net"}, {"title": "3) Algorithmic-based Text Synthesis", "content": "In addition to model-based methods, algorithmic approaches such as SMOTE (Syn-thetic Minority Oversampling Technique) [19] efficiently ad-dress class imbalances by generating synthetic minority class samples through interpolation. Variants such as ADASYN (Adaptive Synthetic Sampling) focus on generating samples for harder-to-learn instances, improving model performance in challenging cases [20]. TOMEK Links, often combined with SMOTE, refine synthetic data by removing overlapping points between majority and minority classes, enhancing clas-sification accuracy [21], [22]. These methods ensure balanced data representation, mitigating bias and improving model generalisation.\nOut of all the approaches discussed, model-based methods were selected due to their ability to maintain syntactic and semantic relationships, critical for SQL query augmentation. While SMOTE handles data imbalance, it falls short in pre-serving complex structures. Therefore, techniques such as VAES, U-Net, and GANs were chosen for their precision and reliability for structured data.\nVariational Autoencoders (VAEs) have proven highly effec-tive in reducing dimensionality and extracting features by en-coding high-dimensional data into latent representations. This enables models to focus on essential features while discarding noise, making them ideal for tasks such as SQL injection detection, where computational efficiency and preserving key information are critical [23]. Additionally, the VAE ability to handle semi-supervised learning enables efficient processing of both labelled and unlabelled data, enhancing their utility in scenarios with limited labelled datasets [24].\nU-Net, initially developed for biomedical segmentation, has demonstrated its versatility in feature extraction and synthetic data generation. Its encoder-decoder architecture excels in capturing intricate features, even with minimal labelled data. This makes it particularly well-suited for generating synthetic SQL injection datasets, addressing the challenge of scarce labelled data while capturing evolving attack patterns [25], [26].\nGANs further improve text-based data augmentation by en-hancing the diversity and quality of synthetic data. Techniques such as CWGAN-GP introduce class conditioning, generating text to balance underrepresented categories, which is crucial for handling class imbalances in SQL injection datasets [15]. Additionally, models such as DP-GAN and SentiGAN promote diversity in synthetic text generation, preventing mode collapse and enhancing generalisation for text-heavy tasks [27], [28].\nIn conclusion, model-based approaches such as VAEs, U-Net, and GANs offer advanced capabilities in generating contextually accurate and semantically rich data, making them more suitable for tasks such as SQL injection detection, despite their higher computational demands."}, {"title": "III. IMPLEMENTATION", "content": "The pipeline, as illustrated in Figure 1, details the structured stages of data processing and model implementation used in this study. The process commences with data collection and preprocessing, followed by tokenisation, embedding, and encoding. Subsequent steps include the generation of synthetic data using models such as U-Net, and CWGAN-GP. These synthetic datasets are then integrated with real data, resulting in a hybrid dataset, which is used for model training. The final model evaluation phase ensures that both real and synthetic data contribute to the detection of SQL Injection (SQLi) attacks."}, {"title": "A. Data Collection & Preprocessing", "content": "The initial datasets, sourced from Kaggle (\u2018sqli_csv' and 'Modified_SQL_Dataset.csv'), underwent a rigorous data cleaning process to resolve inconsistencies and remove re-dundant entries. These datasets were further enriched with advanced SQLi techniques such as error-based, time-based,"}, {"title": "B. Tokenisation & Embedding", "content": "A custom tokeniser was developed to convert SQL queries into structured tokens, ensuring the capture of essential syn-tactic and semantic features. Various embedding methods, including FastText, Character-level embeddings, Byte Pair Encoding (BPE), and BERT, were evaluated to determine the optimal approach. As shown in Fig. 2, FastText emerged as the most efficient, offering a strong balance between accuracy and training time, making it the best option for transforming SQL queries into vector representations for subsequent model training."}, {"title": "C. Feature Extraction & Data Encoding", "content": "The Variational Autoencoder (VAE) was employed to en-code SQL queries into latent space representations, enabling effective feature extraction and dimensionality reduction. As shown in Fig. 3, the VAE consists of an encoder, which compresses the input SQL queries into latent variables charac-terised by mean (\u03bc) and variance (\u03c3\u00b2) vectors, and a decoder, which reconstructs the input data from this latent space. The initial dataset, comprising FastText embeddings with a shape of (32,336, 100, 50), was transformed into a lower-dimensional representation of shape (32,336, 448) after VAE encoding.\nTo enable efficient sampling from the latent space while maintaining differentiability during training, the reparame-terisation trick was applied, as represented by the following equation:\n$z = \\mu + \\epsilon \\cdot exp(\\frac{\\sigma^2}{2}), \\epsilon \\sim N(0, 1)$\n\nThe VAE's loss function combines two key components:\n1. Reconstruction loss, which measures how accurately the decoder reconstructs the original SQL queries:\n$L_{reconstruction} = \\frac{1}{N} \\sum_{i=1}^{N} ||X_i - f_{dec}(z_i)||^2$\n2. Kullback-Leibler (KL) divergence, which regularises the latent space by ensuring the learned distribution is close to a unit Gaussian:\n$L_{KL} = \\frac{1}{2} \\sum(1 + log(\\sigma^2) - \\mu^2 - \\sigma^2)$\nThe total VAE loss is expressed as:\n$L_{VAE} = L_{reconstruction} + \\beta \\cdot L_{KL}$\nwhere \u03b2 controls the trade-off between reconstruction quality and regularisation.\nFig. 4 illustrates the convergence of training and validation losses during VAE training, demonstrating stable learning and model generalisation.\nThe VAE was evaluated using several metrics, including Mean Squared Error (MSE), R2 score, and explained variance, ensuring that the model efficiently encoded the SQL queries while minimising reconstruction errors.\nThe latent representations generated by the VAE were then used as input for advanced generative models U-Net, and CWGAN-GP to generate synthetic SQL queries. Additionally, the VAE-encoded data was used to train several machine learning models, including Logistic Regression, SVM, Ran-dom Forest (RF), and XGBoost. Each model was rigorously evaluated based on accuracy, precision, recall, and F1-score to identify the best-performing baseline model. Among these, XGBoost emerged as the most effective, demonstrating su-perior performance in terms of classification accuracy and robustness. This baseline model was subsequently used as a reference to evaluate the quality of the synthetic data as generated by the advanced generative models."}, {"title": "D. Synthetic Data Generation", "content": "To enhance the diversity of the dataset, two generative models U-Net, and CWGAN-GP were utilised to generate synthetic SQL queries that closely mimic real-world SQL injection patterns. The following subsections will discuss each model in detail, outlining their architecture and adaptations for SQL query data generation.\n1) U-Net Model: In this study, the U-Net architecture was adapted for generating synthetic SQL queries to augment the dataset used for SQL injection detection. The U-Net model was chosen due to its ability to capture both local and global dependencies, which is essential for preserving the hierarchical structure of SQL queries.\nModel Architecture: The U-Net model retained its core encoder-decoder architecture, but was adapted for 1D se-quential data, as shown in Fig. 5. The encoder consists of convolutional layers followed by batch normalisation, ReLU activation, and max-pooling to capture abstract features and reduce dimensionality. The decoder mirrors the encoder but performs up-sampling, restoring the original sequence struc-ture of the SQL queries while retaining critical low-level details through skip connections.\nThe mathematical operation for the encoder can be ex-pressed as:\n$f_{enc}(x) = MaxPool(ReLU(BN(Conv1D(x))))$\nWhere x is the input SQL query, BN denotes batch normali-sation, and Conv1D is the 1D convolutional layer.\nThe decoder reconstructs the input data via:\n$f_{dec}(x) = Conv1DTranspose(Concat(x, skip))$\nHere, Conv1DTranspose is used for up-sampling, and Concat represents the skip connections from corresponding encoder layers.\nHyperparameter Optimisation with Optuna: To improve the performance of the U-Net, hyperparameter tuning was conducted using the Optuna framework. The Optuna Tree-structured Parzen Estimator (TPE) was used to explore the hyperparameter space. The optimisation aimed to minimise the Mean Squared Error (MSE) between the original and re-constructed SQL queries. The key hyperparameters optimised were:\nThe best configuration included a base filter size of 704, a learning rate of 4.61e-5, and a dropout rate of 0.03. These hyperparameters ensured a balance between model capacity and generalisation, minimising overfitting.\nTraining Process: The U-Net model was trained using the Adam optimiser, with a learning rate decay schedule that gradually reduced the learning rate. Early stopping was employed to prevent overfitting. The final loss function was defined as:\n$L_{U-Net} = \\frac{1}{N} \\sum (x_i - f_{dec}(f_{enc}(x_i)))^2$\nWhere $x_i$ represents the input SQL query, and $f_{enc}$ and $f_{dec}$ are the encoder and decoder functions, respectively.\nEvaluation Metrics: The performance of the U-Net model was evaluated using multiple metrics, including Mean Squared Error (MSE), R2 Score, Explained Variance Score (EVS), BLEU Score, Cosine Similarity, Lowenstein Distance, and Mean and Variance Differences. Additionally, Principal Com-ponent Analysis (PCA) was conducted to visually compare the real and synthetic data distributions. These metrics collectively confirm the effectiveness of U-Net in generating high-quality synthetic SQL queries.\n2) CWGAN-GP Model: The Conditional Wasserstein Gen-erative Adversarial Network with Gradient Penalty (CWGAN-GP) was utilised to generate synthetic SQL queries in this study. This model was chosen due to its capability to address the vanishing gradient problem and mode collapse, issues that are often encountered when training traditional GANs on complex, structured data such as SQL queries. The CWGAN-GP not only stabilises the training process but also allows the generation of SQL queries conditioned on specific labels, such"}, {"title": "E. Pseudo-Labelling of Synthetic Data", "content": "To refine the synthetic SQL data as generated by U-Net and CWGAN-GP, pseudo-labelling was employed. This method involved reducing the dimensionality of the high-dimensional data using Principal Component Analysis (PCA) and applying KMeans clustering to assign pseudo-labels.\nPCA for Dimensionality Reduction: Principal Component Analysis (PCA) was applied to reduce the dimensions of the synthetic data to two principal components for better visual representation and easier clustering. Mathematically, the transformation can be described as:\n$Z = XW$\nwhere X represents the original high-dimensional data and W is the projection matrix consisting of the top two eigenvec-tors of the covariance matrix of the data. This transformation enabled a clear separation of the data into clusters, facilitating the next step of clustering and pseudo-labelling.\nKMeans Clustering for Pseudo-Labelling: Once the data was reduced to two dimensions, KMeans clustering was per-formed to assign pseudo-labels. The KMeans algorithm min-imised the Within-Cluster Sum of Squares (WCSS), defined as:\n$WCSS = \\sum_{i=1}^{k} \\sum_{x \\in C_i} ||x - \\mu_i||^2$\nwhere k is the number of clusters (in this case, k = 2), $C_i$ represents the set of points assigned to cluster i, $\u03bc_i$ is the centroid of cluster i, and x is each data point. The KMeans algorithm assigned pseudo-labels corresponding to benign (Class 0) and malicious (Class 1) SQL queries. The labelling was based on the spread of the data: benign queries exhibited a lower spread, while malicious queries displayed a higher spread in the feature space. This distinction in the data distribution enabled the clustering algorithm to effectively separate benign from malicious queries. By leveraging these differences in data spread, the KMeans algorithm enabled the accurate classification of synthetic data into the relevant categories, facilitating its use for training machine learning models."}, {"title": "F. Evaluation of Models on Hybrid Data", "content": "To further enhance model performance, a hybrid dataset was created by combining real SQL data with pseudo-labelled synthetic data as generated by U-Net and CWGAN-GP mod-els. The following steps were performed to evaluate the performance of the model:\nHhybrid Dataset Composition: The combined dataset $D_{combined}$ was created by mixing real data with synthetic data from U-Net and CWGAN-GP in different proportions. The combined dataset is formulated as follows:\n$D_{combined} = D_{real} U (D_{U-Net} \\times p_1) \\cup (D_{CWGAN-GP} \\times p_2)$\nwhere $D_{real}$ represents the real dataset, $D_{U-Net}$ and $D_{CWGAN-GP}$ are the synthetic datasets generated by U-Net and CWGAN-GP, and $p_1$ and $p_2$ are the proportions of synthetic data from each model. By adjusting $p_1$ and $p_2$, different hybrid dataset compositions were tested to optimise the training data balance between real and synthetic data.\nCross-Validation of Dataset Combinations: Stratified K-Fold Cross-Validation was employed to evaluate different combinations of real and synthetic data while preserving class distribution across all folds. This method ensured that the performance of the model was evaluated consistently across various splits of the data. The performance was measured using two key metrics:\n$Accuracy = \\frac{True Positives + True Negatives}{Total Samples}$\n$Sensitivity = \\frac{True Positives}{True Positives + False Negatives}$\nThese metrics provided insight into the ability of the model to correctly classify SQLi attacks while minimising false nega-tives. The cross-validation process helped identify the optimal proportion of real and synthetic data for maximising model performance, ensuring a robust balance between precision and recall."}, {"title": "G. Final Model Evaluation", "content": "After identifying the best dataset combination, the XGBoost classifier was trained on the combined dataset. XGBoost was selected for its high efficiency and scalability, especially in dealing with structured data such as SQL queries. The final model used logistic loss as the objective function, defined as:\n$L_{XGBoost} = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i log \\hat{y_i} + (1 - y_i) log(1 - \\hat{y_i})]$\nwhere N is the total number of samples, $y_i$ is the true label for sample i, and $\u0177_i$ is the predicted probability for sample i. This loss function optimises the classification model by minimising the error in predicting the correct labels for both benign and malicious queries.\nThe trained XGBoost model was evaluated on the test set using multiple metrics, including accuracy, sensitivity, precision, recall, and F1-score.\nThe results demonstrated that the combination of real and pseudo-labelled synthetic data improved the ability of the model to generalise to new, unseen SQL queries. The final"}, {"title": "IV. RESULTS AND ANALYSIS", "content": "In this section, the performance of several machine learning models trained on VAE-encoded SQL data is evaluated for detecting SQL Injection Attacks (SQLIA). The models tested include XGBoost, LightGBM, Random Forest, K-Nearest Neighbors (KNN), Neural Networks, Logistic Regression, Support Vector Classifier (SVC), and Naive Bayes. The evalu-ation focuses on metrics such as accuracy, precision, recall, F1-score, and sensitivity for both benign (Class 0) and malicious (Class 1) queries."}, {"title": "A. Classification Metrics", "content": "Several standard classification metrics were used to thor-oughly assess the performance of the models. These metrics provide valuable insights into how each model predicts benign (Class 0) and malicious (Class 1) SQL queries. The following metrics were calculated for each model:\n$Accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$\n$Precision = \\frac{TP}{TP+FP}$\n$Recall = \\frac{TP}{TP+FN}$\n$F1-Score = 2 x \\frac{Precision \\cdot Recall}{Precision+Recall}$\n$Sensitivity = \\frac{TP_{Class 1}}{TP_{Class 1}+FN_{Class 1}}$\nThe performance of various machine learning algorithms was evaluated based on their ability to detect SQL Injection Attacks (SQLIA)."}, {"title": "B. Synthetic Data Quality Evaluation Metrics", "content": "To assess the quality of the synthetic SQL query data as generated by U-Net and CWGAN-GP, several key metrics were utilised. These metrics are essential for ensuring the synthetic data closely aligns with real SQL queries in both structural and statistical dimensions, which is critical for SQL injection detection models.\nMean Squared Error (MSE): MSE calculates the average squared difference between the real and synthetic data. A lower MSE value indicates that the generated data closely mimics the real data, reducing the risk of discrepancies in model training [30].\nR2 Score: This metric quantifies the amount of variance in the real data that is captured by the synthetic data. A high R2 score ensures that the generated SQL queries retain sufficient diversity, supporting better generalisation in machine learning models.\nExplained Variance Score (EVS): EVS measures the proportion of variance in the real dataset captured by the synthetic data. High EVS indicates that the synthetic queries adequately cover the behaviours and patterns observed in real-world SQL injection attacks [30].\nBLEU Score: BLEU measures the token-level similarity between real and synthetic queries. A higher BLEU score reflects greater structural alignment, which is critical for maintaining the functional semantics of SQL queries [30].\nCosine Similarity: This metric calculates the angular similarity between vectorised representations of real and synthetic data. In SQL query generation, cosine similarity ensures that the overall semantic meaning of the queries is preserved.\nLowenstein Distance: This computes the number of edits required to transform synthetic queries into real ones. A lower distance signifies a closer match between the real and synthetic data, which is vital for maintaining query integrity.\nMean and Variance Differences: These metrics compare the statistical distributions of real and synthetic data by evaluating their means and variances. In SQL data generation, this ensures that the statistical properties, such as query patterns and structures, are preserved, improving"}, {"title": "C. Evaluation of Synthetic Data", "content": "1) U-Net Model: Results and Discussion: The performance of the U-Net model in generating synthetic SQL queries was evaluated using the above key metrics.\nThe Principal Component Analysis (PCA) results in Figure 11 further validate the consistency of the U-Net model in generating synthetic queries that align closely with the real SQL data. Minimal distributional differences, as indicated by the Mean Difference of 0.0062 and Variance Difference of 0.0045, emphasise the strong generalisation capabilities of the model in mimicking real-world query structures.\n2) CWGAN-GP Results and Discussion: Similar to the U-Net model, the synthetic data generated by CWGAN-GP was evaluated using key performance metrics to assess its effectiveness."}, {"title": "D. Pseudo-Labelling and Clustering Results", "content": "Following the generation of synthetic SQL data, pseudo-labelling was employed to categorise the data into distinct classes. Pseudo-labels were assigned using KMeans clustering, which organised the data based on feature similarities. The spread of the data was used to determine the labels: benign queries (Class 0) exhibited a lower spread, while malicious queries (Class 1) displayed a higher spread."}, {"title": "E. XGBoost Performance on Various Data Combinations", "content": "In this section, the performance of the XGBoost model trained on a combination of original data and synthetic data as generated by U-Net and CWGAN-GP models is analysed. Figure 15 illustrates the comparative results of XGBoost across various evaluation metrics."}, {"title": "F. Hybrid Data Proportions for XGBoost Training", "content": "A dataset pool optimisation method was implemented by combining synthetic data from U-Net and CWGAN-GP mod-els with real datasets in proportions to create hybrid datasets, with the goal of identifying the best balance for improving key metrics. Stratified K-Fold Cross-Validation was applied to ensure reliability in the evaluation process."}, {"title": "G. Final XGBoost Model Performance", "content": "With the optimal hybrid configuration established, the next step was to evaluate the final performance of the XGBoost model against the baseline model, ensuring improvements brought by synthetic data integration were robust and con-sistent across different datasets.\n1) Baseline Model Performance (Validation Results): The baseline model, trained solely on the original dataset, achieved an overall accuracy of 0.9817 on the validation set. As shown in Figure 18, the precision and recall values are well-balanced across both benign (Class 0) and malicious (Class 1) queries:\n2) Final Model: The final model was developed by lever-aging the optimal data proportions of 80% U-Net and 70% CWGAN-GP synthetic data, as identified during the hybrid data synthesis process. This model was fine-tuned using hy-perparameter optimisation, enhancing its ability to detect SQL Injection Attacks (SQLIA) with high accuracy and generali-sation capability. The hyperparameters were optimised using Stratified K-Fold Cross-Validation, resulting in the following parameters:\nThe final performance of the model on the validation set is depicted in Figure 20, where it achieved an accuracy of 0.98. Precision, recall, and F1-scores for both Class 0 and Class 1 were well-balanced, demonstrating the efficiency of the model in detecting both benign and malicious queries."}, {"title": "V. CONCLUSION", "content": "Overall, the final XGBoost model outperformed the baseline model, particularly in terms of recall and sensitivity for malicious queries. The integration of synthetic data, gener-ated through U-Net and CWGAN-GP models, significantly enhanced the generalisation ability of the model. Hyperparam-eter tuning further optimised the performance of the model, resulting in a highly accurate and reliable solution for detect-ing SQLIA in real-world scenarios. This study successfully demonstrated that combining synthetic data with real data and using advanced machine learning techniques can provide an effective and robust solution for modern cybersecurity challenges."}, {"title": "VI. LIMITATIONS AND FUTURE SCOPE", "content": "While the final model demonstrated significant improve-ments, several limitations were identified. The CWGAN-GP model, although effective, struggled to capture the complete diversity of SQL query patterns, leading to underrepresen-tation of complex or rare SQL Injection Attack (SQLIA) types. Furthermore, the computational cost associated with generating synthetic data was high, making real-time deploy-ment challenging, particularly in resource-constrained environ-ments. Another limitation was the challenge of maintaining a balanced ratio of benign and malicious queries in the synthetic dataset, which was critical to avoid model overfitting.\nFuture work could focus on refining the CWGAN-GP model to better capture diverse SQL patterns and improve scalability. Exploring other GAN variants (e.g., CatGAN, SentiGAN) and hybrid models with Variational Autoencoders (VAEs) could further enhance the quality of synthetic data. Additionally, real-time detection through online learning and optimising computational efficiency using distributed systems would en-able broader applications of this approach. Developing a self-learning detection system that autonomously adapts to new SQLIA types would also improve the resilience of the model to emerging threats."}]}