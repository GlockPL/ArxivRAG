{"title": "Mastering NIM and Impartial Games with Weak Neural Networks: An AlphaZero-inspired Multi-Frame Approach", "authors": ["S\u00f8ren Riis"], "abstract": "This paper provides a theoretical framework that validates and explains the results in the work with Bei Zhou [22, 24] experimentally finding that AlphaZero-style reinforcement learning algorithms struggle to learn optimal play in NIM, a canonical impartial game proposed as an AI challenge by Harvey Friedman in 2017. Our analysis resolves a controversy around these experimental results, which revealed unexpected difficulties in learning NIM despite its mathematical simplicity compared to games like chess and Go.\n\nTo analyse these limitations, we introduce a class of \"weak\" neural network models (NN, RNN, LTST) characterised by polynomial size, constant depth, and constant precision in weights and thresholds, which belong to the complexity class AC\u00ba. We prove that due to their inherent limitations in computing parity functions, these models cannot achieve optimal NIM play using single-frame representations (as tested in [24]). While this impossibility result is absolute, we prove that multi-frame approaches are not subject to the same theoretical barrier, though realising this potential in practice remains an open challenge.\nOur key contributions are as follows:\n\n\u2022 We prove that by incorporating recent game history, these limited AlphaZero models can, in principle, achieve optimal play in NIM.\n\u2022 We introduce a novel search strategy where roll-outs preserve game-theoretic values during move selection, guided by a specialised policy network.\n\u2022 We provide constructive proofs showing that our approach enables optimal play within the ACO complexity class despite the theoretical limitations of these networks.\n\nBeyond NIM, our findings offer new insights into how appropriate state representations and search strategies can overcome fundamental computational limitations in neural networks. This research demonstrates how constrained neural networks when properly designed, can achieve sophisticated decision-making even in domains where their basic computational capabilities appear insufficient.", "sections": [{"title": "Introduction and Background", "content": "AlphaZero has revolutionised the field of artificial intelligence by demonstrating unprecedented performance in complex games such as chess, Go, and shogi through self-play and reinforcement learning [16, 18, 17, 15]. While very deep, these games possess an underlying structure allowing expert players to evaluate positions intuitively. An impartial game like NIM (where both players have exactly the same moves available at each position) is well understood and has optimal strategies that are easy to compute. From a human cognitive point of view, partisan games like Go and chess (where players control different coloured pieces) have a different feel than impartial games. While many chess and Go positions are hard to evaluate, a strong human player generally has some idea (i.e., positive information) about a given position that can guide the evaluation and search. In a simple mathematical game like NIM, however, parity issues play a crucial part, and finding the optimal move is equivalent to determining if a list of parities all are 0. While easy to calculate, cognitively, this is not something a human can determine at a glance. A natural conjecture is that this cognitive difficulty also applies to the Neural Networks guiding the Monte Carlo Tree Search (MCTS) in AlphaZero-style self-learning algorithms.\nNIM, a foundational impartial game where players take turns removing objects from heaps, is an excellent testbed for exploring the limits of reinforcement learning in strategic settings where the neural networks that theoretically guide the search and evaluation should be relatively ineffective. This aligns with the broader investigation of AI capabilities in various game contexts, as highlighted by Friedman's proposal of NIM as an AI challenge in 2017 [8].\nThe study of NIM and similar impartial games in the context of AI relates to fundamental questions in computational complexity theory. The class AC\u00ba, which consists of constant-depth, polynomial-size boolean circuits with unbounded fan-in AND and OR gates, has been shown to capture important aspects of the computational power of certain neural network models [10]. This complexity class arises naturally in neural networks where weights and thresholds are limited to fixed precision. Interestingly, AC\u00ba can simulate several other computational models, including certain types of finite automata and small-depth decision trees [1]. However, ACO is known to have limitations, particularly in its inability to compute simple functions like parity [9], which, as we shall show, is crucial for optimal play in NIM.\nThis paper aims to bridge the gap between theory and the empirical investigations of AlphaZero's performance in impartial games. We introduce a \"weak\" neural network model class (Neural Networks (NN), Recurrent Neural Networks (RNN), and Long-Term Short-Term Attention (LTST) models) characterised by polynomial size, constant depth, and constant precision in weights and thresholds. These models belong to the complexity class ACO, and our experimental results [25, 24] suggest that practical neural networks often operate within similar computational constraints.\nOur analysis demonstrates that AlphaZero agents operating within these constraints cannot accurately evaluate NIM positions, as this task requires computing parity. This aligns with Friedman's observation that while AI had made significant strides in complex games like chess and Go, simpler games like NIM might pose unexpected challenges due to their mathematical nature [8]. However, our main result shows that these limitations can be overcome in principle through a carefully designed search strategy using multi-frame representations.\nSeveral key points make NIM an interesting challenge for AI:\n\n1. Perfect Play: Unlike chess or Go, humans can play NIM perfectly with a known strategy. This allows for a clear evaluation of AI performance against optimal play.\n2. Scalability: NIM can be scaled in complexity by adjusting parameters such as the number of heaps and the maximum number of items per heap, allowing for systematic testing of AI learning capabilities.\n3. Mathematical Nature: The winning strategy for NIM relies on mathematical concepts like binary representation and XOR operations, testing an Al's ability to discover and utilise mathematical patterns.\n4. Contrast with Human Learning: The way AI might learn to play NIM could differ significantly from how humans discover the optimal strategy, potentially revealing fundamental insights into machine learning processes.\n\nHowever, this paper's main contribution is to show that by incorporating recent game history-e.g., the immediate previous positions even the AC limited agents we consider can, in principle, achieve optimal play through a specific new kind of search strategy."}, {"title": "Addressing Controversial Experimental Results", "content": "In joint work with Bei Zhou [24], we investigated AlphaZero-style reinforcement learning algorithms applied to the game of NIM. Our findings provided empirical evidence that a wide class of neural network models struggle to reliably compute parities of long bitstrings [25], which is crucial for evaluating NIM positions with many heaps. These results align with theoretical considerations related to the statistical neutrality of the parity function [20], and other works [6, 21].\nThis evidence that AlphaZero-style self-play algorithms had difficulties learning to master simple children's games like NIM sparked debate within the AI community, challenging the notion of AlphaZero's universal applicability across game domains. While our claims were substantiated through empirical experiments, they lacked rigorous theoretical justification."}, {"title": "Paper Organization", "content": "The remainder of this paper is organized as follows:\n\n\u2022 Section 2 presents our theoretical framework and neural network models, establishing the foundations for understanding AC\u00ba constraints.\n\u2022 Section 3 provides formal definitions and fundamental properties of impartial games, with a focus on NIM.\n\u2022 Section 4 presents our main impossibility and possibility results, including the crucial multi-frame approach.\n\u2022 Section 5 analyzes the learning dynamics of impartial games with neural networks.\n\u2022 Section 6 discusses practical implications and potential applications.\n\u2022 Section 7 explores generalizations to other impartial games.\n\nOur investigation opens several directions for future research:\n\n\u2022 Identifying general classes of scenarios where Neural Network-guided action recommendations benefit from including recent history\n\u2022 Using the weak ACO Neural Network framework to identify hard AI-learning tasks and additional features that help overcome computational bottlenecks\n\u2022 Extending our approach to other impartial games and broader game classes"}, {"title": "Theoretical Framework and Neural Network Models", "content": ""}, {"title": "Neural Network Models with Constant Precision and Their Simulation by\nAC\u00ba Circuits", "content": "We define three neural network models-Neural Networks (NN), Recurrent Neural Networks (RNN), and Long-Term Short-Term Attention (LTST) Models\u2014with constraints on their weights and thresholds. For RNN and LTST, we assume operation within a finite time window.\nAll weights and thresholds are restricted to rational numbers of the form $\\frac{p}{q_0}$,where $q_0$ is a fixed integer and $p$ is bounded by a constant $P$.\nThe neural networks are structured using a constant number of layers. Our network models have polynomial size, though we note that with exponential size, all boolean functions could be computed even by a depth-two neural network."}, {"title": "Model Definitions", "content": ""}, {"title": "Neural Networks (NN)", "content": "Definition 1 (Neural Networks with Constant Precision). A Neural Network (NN) consists of $L$ constant-depth layers with polynomial-size neurons, each computing a thresholded weighted sum of its inputs. Key constraints include:\n\u2022 Rational weights of form $\\frac{p}{q_0}$ with bounded numerators\n\u2022 Binary outputs through threshold activation\n\u2022 Polynomial size in input dimension\nThe complete formal definition and detailed specifications are provided in Appendix A.1.1"}, {"title": "Recurrent Neural Networks (RNN)", "content": "Definition 2 (Recurrent Neural Networks with Constant Precision). A Recurrent Neural Network (RNN) extends the NN model with temporal processing capabilities over $T$ time steps. Key characteristics include:\n\u2022 Hidden state vectors updated recurrently at each time step\n\u2022 Constant precision weights shared across time steps\n\u2022 Polynomial number of neurons in each of the $L$ layers\nThe complete formal definition and detailed specifications are provided in Appendix A.1.2"}, {"title": "Long-Term Short-Term Attention (LTST) Models", "content": "Definition 3 (Long-Term Short-Term Attention (LTST) Models with Constant Precision). A Long-Term Short-Term Attention (LTST) Model processes sequences through attention mechanisms rather than recurrent connections. Key features include:\n\u2022 Dual attention mechanisms for long-term and short-term dependencies\n\u2022 Constant precision attention weights\n\u2022 Polynomial-size attention heads across $L$ layers\nThe complete formal definition and detailed specifications are provided in Appendix A.1.3"}, {"title": "Simulation by AC Circuits", "content": "We present a general theorem for all three neural network models defined above to avoid redundancy. This theorem outlines the conditions under which a neural network model can be simulated by an AC circuit, incorporating parameters such as the number of layers $L$ and the number of time steps $T$.\nTheorem 1 (Simulation of Neural Network Models by AC Circuits). Any neural network model with $L$ layers and $T$ time steps that satisfies the following conditions can be simulated by an AC circuit:\n\n1. The network has polynomial size, i.e., the number of neurons is polynomial in the input size $n$."}, {"title": "Impartial Games", "content": ""}, {"title": "Definitions and Fundamental Properties", "content": "An impartial game is a two-player combinatorial game characterised by the following properties:\n\n\u2022 Turn-Based Play: Two players alternate moves, with no player making more than one move in succession.\n\u2022 Symmetric Options: From any given position, the set of legal moves is the same for both players.\n\u2022 Normal Play Convention: The player who makes the last move wins.\n\nThis framework extends beyond games where making the last move is the explicit goal. Any impartial game with a specific winning condition (such as creating a pattern or reaching a state) can be recast in this form by defining positions meeting the winning condition as terminal positions with no legal moves from them.\nDefinition 4 (Impartial Game). An impartial game is a tuple $G = (P, L)$, where:\n\n\u2022 $P$ is a non-empty set of positions.\n\u2022$L : P \u2192 2^P$ is a function assigning to each position $p \u2208 P$ a set $L(p) \u2286 P$ of positions reachable from $p$ in one move (the legal moves from $p$).\n\nThe game satisfies the following conditions:\n\n1. Finite Options: For each position $p \u2208 P$, the set $L(p)$ is finite.\n2. Symmetry: For all positions $p \u2208 P$, the set $L(p)$ is independent of which player is to move.\n\nA position $p$ is called a terminal position if $L(p) = \u00d8$."}, {"title": "Examples of Impartial Games", "content": "While NIM is our primary focus, it's part of a broader class of impartial games. Here are some examples of impartial games [2, 3, 4, 5], including variants proposed by Harvey Friedman [8]:\n\n1. Subtraction Games: A generalization of NIM where players can only remove a specific number of objects on each turn. For instance, in the (1,2)-subtraction game, players can remove either 1 or 2 objects per turn.\n2. Chomp: Played on a rectangular chocolate bar, players take turns choosing a square and \"eating\" it along with all squares below and to its right. The player forced to eat the bitter square in the top-left corner loses.\n3. Sprouts: Players take turns drawing lines between dots and adding a new dot in the middle of each line. A dot can have at most three lines connected to it, and lines cannot cross.\n4. Geography: Players take turns naming locations (cities, countries, etc.) where each new location must begin with the last letter of the previous location. No location can be repeated. This game has been proven to be PSPACE-complete, demonstrating the complexity that can arise from simple rules [14].\n5. Grundy's Game: Players take turns splitting a heap into two unequal heaps. The player who cannot make a valid move loses. This game is interesting as its complete analysis remained open for many years [7].\n6. Nim Variants (proposed by Friedman):\n\n\u2022 Multi-Row Take: Players can remove items from either one row or two rows on each turn.\n\u2022 Chessboard NIM: Items are placed on an $n\u00d7n$ chessboard, and players can take one or more stones from either a row or a column.\n\u2022 Diagonal Chessboard NIM: Similar to Chessboard NIM, but players can also take items from diagonals.\n\n7. Kayles: Players take turns removing one or two adjacent pins from a row. The player who removes the last pin wins.\n8. Dawson's Kayles: A variant of Kayles where players must remove exactly two adjacent pins. This game is interesting due to its periodic Sprague-Grundy function.\n9. Hackenbush: Played on a graph with edges coloured in one colour (for the impartial version), players take turns removing an edge, causing all disconnected components to fall. The last player to move wins.\n\nThese games share the fundamental properties of impartial games: at any given position, both players have access to the same set of possible moves, and the game always ends with a decisive result i.e. a win or a loss. The analysis of impartial games is unified through the Sprague-Grundy theorem, which provides powerful theoretical tools for studying AI learning and strategy discovery in these games. A key mathematical insight is that all impartial games are equivalent to NIM positions with specific heap sizes. While this equivalence is theoretically complete, the actual reduction from an arbitrary impartial game to its corresponding NIM position can be computationally intractable."}, {"title": "NIM: Definitions and Fundamental Results", "content": ""}, {"title": "Basic Definitions", "content": "NIM is a classic example of an impartial game, consisting of heaps (or piles) of objects from which players remove objects according to specific rules.\nDefinition 5 (NIM). A game of NIM is defined by $k$ heaps of objects, where the $i$-th heap contains $n_i$ objects, with $n_i \u2208 N_0$ for $i = 1,2,..., k$. A position in NIM is represented by the vector $n = (n_1, n_2, ..., n_k)$.\nDefinition 6 (Legal Move in NIM). A legal move in NIM consists of selecting a single heap and removing one or more objects from it. Formally, from a position $n = (n_1, n_2,...,n_k)$, a move is defined as choosing an index $i$ with $n_i > 0$ and producing a new position $n' = (n_1,...,n'_i,...,n_k)$, where $n'_i < n_i$ and $n'_j = n_j$ for all $j\u2260i$.\nDefinition 7 (Disjunctive Sum of Games). Given two impartial games $G = (P_G,L_G)$ and $H = (P_H,L_H)$, the disjunctive sum $G + H$ is an impartial game defined as follows:\n\n\u2022 The positions of $G + H$ are pairs $(p,q)$, where $p \u2208 P_G$ and $q \u2208 P_H$.\n\u2022 The legal moves from position $(p,q)$ are all positions of the form $(p', q)$, where $p' \u2208 L_G(p)$, and positions of the form $(p, q')$, where $q' \u2208 L_H(q)$.\n\nIn other words, a player moves by making a legal move in exactly one of the component games, leaving the other unchanged."}, {"title": "NIM Sum and Its Properties", "content": "The analysis of NIM utilises the concept of the NIM sum, which is defined using the bitwise exclusive OR (XOR) operation.\nDefinition 8 (NIM Sum). For a NIM position $n = (n_1, n_2,...,n_k)$, the NIM sum is defined as:\n$S(n) = n_1\u2295n_2\u2295...\u2295n_k,$\nwhere $\u2295$ denotes the bitwise XOR operation on the binary representations of the heap sizes.\nExample 3.1. Consider a NIM position with heap sizes $n = (3,5,7)$. The binary representations and their XOR computation are as follows:\n$3$ = $011_2,$\n$5$ = $101_2,$ $S(n) = 011_2\u2295101_2\u2295 111_2 = 001_2 = 1.$\n$7$ = $111_2,$\nTherefore, the NIM sum of this position is 1."}, {"title": "Sprague-Grundy Theory", "content": "The Sprague-Grundy theorem provides a powerful framework for analyzing impartial games by associating each position with a Grundy number (also known as a nimber), which effectively reduces the game to an equivalent NIM heap.\nDefinition 9 (Minimal Excludant). For a set $S$ of non-negative integers, the minimal excludant of $S$, denoted mex(S), is defined as:\nmex(S) = min{$n \u2208 N_0 | n \u2209 S$}.\nThat is, mex(S) is the smallest non-negative integer not in S.\nDefinition 10 (Nimber). For a position $p$ in an impartial game $G = (P, L)$, the Nimber (or Grundy number) $G(p)$ is defined recursively by:\n$G(p)$ = mex{$G(q) | q \u2208 L(p)}$.\nTheorem 2 (Sprague-Grundy Theorem). In any impartial game under normal play:\n\n1. Every position $p$ is equivalent to a NIM heap of size $G(p)$.\n2. For the disjunctive sum of games $G$ and $H$, the nimber satisfies:\n\n$G(G + H) = G(G) \u2295G(H)$.\n\nLemma 1 (Winning Strategy Control). Let $p$ be a winning position (i.e., $G(p) \u2260 0$). Then:\n\n1. The player to move can select a move leading to a position $q$ with $G(q) = 0$\n2. Any move by the opponent from $q$ leads to a position $r$ with $G(r) \u2260 0$\n3. From $r$, the player can again move to a position $s$ with $G(s) = 0\n\nThis pattern continues until the game ends, ensuring victory for the player who first reaches a winning position.\nProof. Let $p$ be a position with $G(p) \u2260 0$. By the definition of nimber, there must exist a move to a position $q$ with $G(q) = 0$. From $q$, any move by the opponent must lead to a position $r$ with $G(r) \u2260 0$, as all moves from a position with nimber 0 must lead to positions with non-zero nimber (by definition of mex). The process then repeats, allowing the winning player to maintain control.\nCorollary 1. For a position $n$ in NIM, the nimber equals its NIM sum:\n$G(n) = S(n)$.\nTherefore, a NIM position $n$ is a winning position for the next player if and only if $S(n) \u2260 0$.\nHaving established the theoretical foundations of impartial games and NIM, we proceed to analyze the computational limitations of certain neural network models in playing NIM optimally (Section 4)."}, {"title": "Impossibility and Possibility Results", "content": ""}, {"title": "Limitations of Single-Frame Representations in NIM", "content": "This section examines the limitations of using single-frame representations in neural networks to play NIM optimally. We distinguish between two scenarios in the context of the AlphaZero algorithm:\n\n1. The algorithm plays without search, relying solely on its evaluation network or policy network to assess positions and select moves.\n2. The algorithm performs a search bounded by a polynomial in the size of the initial board position, using the evaluation and policy networks as guidance.\n\nFurthermore, we differentiate between two levels of mastery in NIM, as per the terminology introduced in [24]:\n\n\u2022 Weak Mastery (Champion): The ability to play well (or optimally) from a specific initial position, regardless of whether the player moves first or second.\n\u2022 Strong Mastery (Expert): The ability to play well (or optimally) from any position that can occur through legal play from the initial position."}, {"title": "Impossibility of Optimal Play Without Search", "content": "Theorem 3 (Impossibility of Single-Frame Optimal NIM Play Without Search). No AC network with single-frame input can achieve strong mastery of NIM by playing optimally from all positions without search, using either its evaluation network or policy network.\nProof. Assume, for the sake of contradiction, that there exists an AC\u00ba network with single-frame input that can play NIM optimally from any position (achieving strong mastery) without search, using either its evaluation network or policy network.\nOptimal play in non-trivial NIM positions requires determining whether a given position $n = (n_1, n_2, ..., n_k)$ is a winning or losing position. According to the Sprague-Grundy theorem (Theorem 2), this involves computing the Grundy number $G(n)$, which for NIM is equal to the NIM sum $S(n) = n_1 \u2295 n_2 \u2295\u2295n_k$, where $\u2295$ denotes the bitwise XOR operation.\nComputing the NIM sum requires calculating the parity of the number of ones in each bit position across all heap sizes. It is well-established that parity functions cannot be computed by AC\u00ba circuits of constant depth and polynomial size [9, 11]. This limitation applies regardless of the specific method used to determine the winning status of a NIM position, as any such method would require computing a function that is at least as hard as parity.\nEven if one proposes an alternative, mathematically equivalent method to determine whether a NIM position is winning without explicitly computing the NIM sum, such a method would still necessitate computations beyond the capabilities of AC\u00ba circuits. This is because parity can be reduced to determining the winning status of NIM positions: for any binary string, one can construct a corresponding NIM position such that the parity of the string determines whether the position is winning.\nTherefore, an AC\u00ba network cannot compute the necessary function to determine optimal moves from arbitrary positions without search. Consequently, it cannot achieve strong mastery of NIM under these constraints."}, {"title": "Impossibility of Optimal Play with Polynomial-Time Bounded Search", "content": "Theorem 4 (Impossibility of Single-Frame Optimal NIM Play with Polynomial-Time Bounded Search). An AlphaZero-style algorithm using AC\u00ba networks with single-frame input and performing a search bounded by a polynomial in the size of the initial board position cannot achieve strong mastery of NIM."}, {"title": "Implications for Weak Mastery", "content": "While our impossibility results address strong mastery, weak mastery (optimal play from specific initial positions) presents a more nuanced picture. Although AC networks cannot achieve weak mastery in general due to their inability to compute parity, certain symmetric initial positions allow for weak mastery within ACO constraints.\nFor instance, positions with paired identical heaps permit simple mirroring strategies implementable in ACO (see Example 7.1 in Appendix C.1). However, such cases are exceptions. For arbitrary initial positions, the exponential growth of reachable positions and the parity computation barrier prevent weak mastery in general.\nThe existence of these special cases emphasizes how the computational difficulty of weak mastery depends on the initial position's structural properties. We explore these special cases and their implications in Examples 7.1 and 7.2 (Appendix C.1). A full analysis of the difficulty of weakly mastering NIM in the single frame representation is outside the scope of this paper."}, {"title": "Multi-Frame Possibility", "content": "Multi-frame representations can overcome certain limitations of single-frame approaches by leveraging historical information. While some NIM positions can be mastered weakly using single-frame representations through symmetry-based strategies, achieving strong mastery generally requires tracking the recent game history. The practical implementation and learning dynamics of this approach are discussed in detail in Section 5.\nFor example, while a copying strategy suffices for weak mastery from certain initial positions, strong mastery (optimal play from any reachable position) becomes possible when incorporating two-frame history. This distinction illustrates how temporal information can transform positions that are intractable for strong mastery in single-frame representations into solvable cases.\nWe now proceed to develop the theoretical framework that enables strong mastery through multi-frame representation."}, {"title": "General Case Construction", "content": "Lemma 2 (Computing Nimber Difference in AC\u00ba). For NIM positions $P_1$ and $P_2$ that differ in at most $k$ heaps (where $k$ is a fixed constant), the nimber difference $G(P_1)\u2295G(P_2)$ can be computed by an AC\u00ba circuit.\nThe proof leverages the fact that when positions differ in a constant number of heaps, their nimber difference can be computed using parallel operations of constant depth. The full construction of the ACO circuit and detailed proof are provided in Appendix D.1.1.\nThis lemma is central to our multi-frame approach, as it allows us to track nimber differences between consecutive positions efficiently within ACO constraints."}, {"title": "Nimber-Preserving Search Strategy", "content": "Having established that nimber differences can be computed in AC, we now present our key strategic component: nimber-preserving rollouts. This approach allows us to maintain winning positions without explicitly computing global nimber values.\nDefinition 11 (Nimber-Preserving Rollout). For a position $P$ reached by move $M$, a rollout $R(P)$ is conducted as follows:\n\n1. Initialise rollout state with history ($P_{prev} \u2192 P$)\n2. Initialize rollout state with history ($P_{prev} \u2192 P$)\n3. Until game ends or nimber-preservation fails:\n\n\u2022 Let opponent make any move $Q$\n\u2022 Find move $R$ such that nimber_diff($P_{prev}$, $P$) = nimber_diff($Q$, $R$)\n\nThe power of this strategy lies in its ability to preserve winning positions using only local nimber difference computations, which we proved are AC\u00ba-computable (Lemma 3). This enables our multi-frame approach to overcome the limitations identified in the single-frame case."}, {"title": "Implementation Overview", "content": "Our AC implementation of nimber-preserving search consists of four key components:\n\n1. A position encoding scheme that efficiently represents game states using binary arrays\n2. A layered circuit structure for detecting and validating position differences\n3. A pattern recognition system for identifying nimber-preserving moves\n4. A probabilistic output layer for move selection\n\nEach component is carefully designed to maintain ACO constraints while enabling effective search. The complete technical details of the implementation, including circuit construction, encoding schemes, and validation mechanisms, are provided in Appendix B.\nThis implementation demonstrates that the theoretical possibility results established earlier can be realized within practical AC circuits."}, {"title": "Learning Impartial Games with Neural Networks", "content": "Our analysis reveals a fundamental distinction between weak learning (mastering specific initial positions) and strong learning (mastering all reachable positions). While AC\u00ba-constrained networks can achieve weak mastery in positions with exploitable symmetries (see Examples 7.1 and 7.2 in Appendix C.1), strong mastery requires the nimber-preserving rollout strategy described in Section 4. This distinction illuminates how computational constraints shape learning capabilities:\n\n\u2022 Weak Learning: Achievable for specific positions through symmetry-based strategies\n\u2022 Strong Learning: Requires multi-frame representation and nimber-preserving rollouts"}, {"title": "Practical Considerations", "content": "Several factors affect the implementation of this strategy:\n\n\u2022 Depth of Search: Since the evaluation network is limited within AC\u00ba, the agent relies heavily on deep search to determine rollout outcomes accurately. The search must reach terminal positions, as the evaluation network faces computational limitations.\n\u2022 Role of the Evaluation Network: While the evaluation network may not provide accurate assessments, multiple frames can help it capture patterns related to nimber differences. The deep search compensates by exploring the game tree extensively.\n\u2022 Policy Network Training: We assume the existence of a policy network that values nimber-preserving moves highly. The training process for such valuation is not discussed here.\n\u2022 Double-Edged Nature of Strategy: The nimber-preserving strategy is highly effective for winning positions but may be poor for losing positions. In hypothetical rollouts, both players using these strategies aids position evaluation, even if unrealistic in actual gameplay."}, {"title": "Extending Multi-Frame Approaches to Mathematical Discovery", "content": "The AC framework developed for NIM provides fundamental insights into computational barriers and their solutions. Our theoretical analysis shows that while direct computation of certain functions (like parity) is impossible within AC, carefully designed alternative representations can make previously intractable computations feasible.\nThis principle guided our work on discovering large Condorcet domains [22, 12]. The 25-year record size Condorcet domain we improved through AI-inspired search was the Fishburn domain, defined using parity elements in multiple triples. Using a single-frame approach, we could not find these domains even for small parameters like n = 7 [22, 12, 23].\nWe transformed these intractable computations into tractable ones by:\n\n\u2022 Identifying locally computable properties that constrain the global structure\n\u2022 Developing efficient representations for these local patterns\n\u2022 Using these patterns to guide search through an exponential space\n\nThis approach led to discovering record-breaking Condorcet domains, identifying structures that had eluded previous search methods for over 25 years. These insights explain why certain search strategies succeed: when faced with AC\u00ba-infeasible computations, the solution lies in finding alternative approaches rather than attempting to modify network architectures while remaining within fundamental practical constraints. Indeed, modifications that don't fundamentally change a network's computational power (such as architectural tweaks in noisy environments) cannot overcome the theoretical limitations of ACO."}, {"title": "Synthesis of Theory and Practice", "content": "Our work demonstrates how theoretical insights shape practical search strategies:\n\n\u2022 Theory identifies fundamental computational barriers\n\u2022 This guides the development of alternative representations\n\u2022 Implementation success validates the theoretical framework\n\nThe effectiveness of this approach in both NIM and Condorcet domains suggests broader applications in mathematical discovery."}, {"title": "Research Directions and Practical Considerations", "content": "Future research directions include:\n\n\u2022 Integration with other recognition techniques\n\u2022 Systematic methods for finding alternative representations\n\u2022 Investigation of temporal and structural patterns\n\nFor practical applications, we should focus on problems where:\n\n\u2022 Local properties constrain global structure\n\u2022 Alternative representations preserve essential features\n\u2022 Search space admits efficient exploration\n\nRecent successes in automated discovery [22, 12, 23] validate this framework's potential for tackling seemingly intractable mathematical problems through carefully designed search strategies."}, {"title": "Generalizing to Other Impartial Games", "content": "While our analysis has focused on NIM, the implications extend to other impartial games. The Sprague-Grundy theorem establishes that every finite impartial game is equivalent to a NIM heap of a certain size, suggesting that the challenges identified in NIM may manifest in various forms across other games. However, the complexity of determining nimber values varies significantly among different games, presenting additional challenges for learning algorithms.\nFor instance, some impartial games, such as Geography, are known to be PSPACE-complete [14]. In these games, computing optimal strategies or nimber values from arbitrary positions is computationally intractable for polynomial-time algorithms. This contrasts with NIM, where nimber calculations can efficiently determine optimal moves.\nThese differences imply that AlphaZero-style algorithms, especially when constrained by computational resources similar to those in our study, may face significant difficulties in learning optimal strategies for more complex impartial games. The strategies and representations effective for NIM may not be directly generalized to games with higher computational complexity."}, {"title": "Conclusion", "content": "Our theoretical analysis demonstrates that reinforcement learning agents with AC\u00ba-constrained neural networks can achieve optimal play in NIM through multi-frame state representations and specialized search strategies. This result not only resolves a specific challenge in impartial game playing but also provides a broader framework for approaching computationally constrained problems.\nThe implications extend beyond game playing to mathematical discovery, as demonstrated by our success with Condorcet domains. Our framework shows how careful problem representation and search strategies can overcome fundamental computational barriers without escaping practical constraints.\nFuture research directions include:\n\n\u2022 Extending these results to more complex impartial games\n\u2022 Developing hybrid approaches combining neural networks with symbolic reasoning\n\u2022 Identifying other domains where multi-frame representations can transform intractable problems into tractable ones\n\nThis work opens new avenues for constrained AI systems in game theory and mathematical discovery, suggesting that computational limitations might often be overcome through clever problem reformulation rather than increased computational power."}, {"title": "Appendices", "content": ""}, {"title": "Neural Network Models and AC\u00ba Circuits", "content": ""}, {"title": "Detailed Model Definitions", "content": ""}, {"title": "Neural Networks (NN)", "content": "Definition 12 (Neural Networks with Constant Precision). A Neural Network (NN) with $L$ layers consists of $L$ layers", "as": "n$Y_j^{(l)"}, "\u03c3\\left(\\sum\\limits_{i=1}^{m^{(l-1)}} W_{ij}^{(l)} X_i^{(l-1)} - \u03b8_j^{(l)}\\right)$\nwhere:\n\u2022\n$\u03c3(u) = \\begin{cases}\n1 & \\text{if } u \u2265 0, \\\\\n0 &"]}