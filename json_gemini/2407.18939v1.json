{"title": "PROMOTING AI COMPETENCIES FOR MEDICAL STUDENTS: A SCOPING REVIEW ON FRAMEWORKS, PROGRAMS, AND TOOLS", "authors": ["YINGBO MA", "YUKYEONG SONG", "JEREMY A. BALCH", "YUANFANG REN", "DIVYA VELLANKI", "ZHENHONG HU", "MEGHAN BRENNAN", "SURAJ KOLLA", "ZIYUAN GUAN", "BROOKE ARMFIELD", "TEZCAN OZRAZGAT-BASLANTI", "PARISA RASHIDI", "TYLER J. LOFTUS", "AZRA BIHORAC+1", "BENJAMIN SHICKEL+1"], "abstract": "As more clinical workflows continue to be augmented by artificial intelligence\n(AI), AI literacy among physicians will become a critical requirement for ensuring safe and\nethical AI-enabled patient care. Despite the evolving importance of AI in healthcare, the\nextent to which it has been adopted into traditional and often-overloaded medical curricula\nis currently unknown. In a scoping review of 1,699 articles published between January 2016\nand June 2024, we identified 18 studies which propose guiding frameworks, and 11 studies\ndocumenting real-world instruction, centered around the integration of AI into medical\neducation. We found that comprehensive guidelines will require greater clinical relevance\nand personalization to suit medical student interests and career trajectories. Current efforts\nhighlight discrepancies in the teaching guidelines, emphasizing AI evaluation and ethics\nover technical topics such as data science and coding. Additionally, we identified several\nchallenges associated with integrating AI training into the medical education program,\nincluding a lack of guidelines to define medical students' AI literacy, a perceived lack of\nproven clinical value, and a scarcity of qualified instructors. With this knowledge, we propose\nan AI literacy framework to define competencies for medical students. To prioritize relevant\nand personalized AI education, we categorize literacy into four dimensions: Foundational,\nPractical, Experimental, and Ethical, with tailored learning objectives to the pre-clinical,\nclinical, and clinical research stages of medical education. This review provides a road\nmap for developing practical and relevant education strategies for building an AI-competent\nhealthcare workforce.", "sections": [{"title": "Introduction", "content": "Emerging innovations in artificial intelligence (AI) have the potential to transform medical\npractice and healthcare delivery [34]. As of May 2024, the U.S. Food and Drug Administration\n(FDA) has authorized 882 AI-enabled medical devices [12]; in 2023, the European Medicines\nAgency (EMA) has also released a preliminary document outlining its view on the application\nof AI and machine learning (ML) throughout different stages of a medicine's life cycle [2].\nIt is anticipated that AI-powered medical devices will increasingly become integrated into"}, {"title": "Methods", "content": "This scoping review searched and selected eligible studies using the criteria, guided by the\nPRISMA [25] framework to ensure a comprehensive and transparent approach to the scoping\nreview process, presented in Figure 1."}, {"title": "Results", "content": "A total of 29 studies fulfilled inclusion criteria. Figure 2 shows the number of publications per\nyear, as well as the geographic distribution of the studies included. Among these 29 included\nstudies, 18 studies suggested theoretical proposals, guidelines, or specific curriculum defining AI\nliteracy for medical students (Question 1); 11 studies described formal coursework, programs,\nor workshops to provide Al training to medical students and assessed their learning (Question\n2). Below, we summarize the results for each of our two questions."}, {"title": "Question 1: What should medical students know about AI: proposals and guidelines", "content": "In Question\n1, we aimed to collect and synthesize the existing theoretical proposals and guidelines that\ndefine medical students' AI literacy. Medical students are both future \"AI users\" and \"AI\ndevelopers\" [6]; thus, specifically tailored Al literacy frameworks will guide researchers and\nmedical schools to provide medical students with relevant knowledge and skills to apply Al\nin their future careers. The data in 18 included studies that proposed theoretical guidelines\nwere extracted and synthesized under the four key dimensions of the AI Literacy for the Public\n[31], a framework that defines the AI literacy for general public as four dimensions: know\nand understand AI, use and apply AI, evaluate and create AI, and AI ethics. The general\ncharacteristics of these 18 studies are shown in Table 1."}, {"title": "Know and Understand AI:", "content": "Existing guidelines emphasize medical students' essential\nknowledge of Al without focus on Al related sub-fields such as probabilities, computer vision,\nand natural language processing. 17 out of 18 studies recommend medical students should a\nbrief history of AI and ML [8], common Al terminologies and basic understanding of traditional\nML algorithms (e.g., decision tree) [3], and what AI can do and cannot do for physicians [14, 16].\nEight out of 18 studies recommended more specific AI-related sub-fields as requirements,\nincluding basic concepts of data science [36, 27] and basic concepts of statistics [17, 8, 53].\nOnly two out of 18 studies recommended basic understanding of deep learning, neural networks,\ncomputer vision, and natural language process as requirements for medical students [47, 32]."}, {"title": "Use and Apply AI:", "content": "Existing guidelines emphasize practical use of Al in health data\nengineering nine out of 18 studies required medical students understand the important role of\nclinical data in Al innovation development [15], health data collection, curation, management,\nand protection [16, 32], and the whole health data processing pipeline for training ML models\nfrom data cleaning to feature engineering [27, 8]. 16 out of 18 studies specifically emphasized\nthe importance of teaching medical students how to safely and effectively use clinical AI\ntools, including AI applications in general practices [36], different application scenarios of AI\nin medicine and the basic flow of how they work [15, 35, 16, 27], fundamental knowledge\nof translating AI concepts into clinical practice [47], applying predictive AI techniques for\ndiagnosis and treatment [14, 52], and critical appraisal of clinical AI tools [24, 35]."}, {"title": "Evaluate and Create AI:", "content": "Existing guidelines place less emphasis on medical students'\nknowledge and skills of evaluating and creating AI applications. Seven out of 18 studies\nsuggested that medical students should have basic skills to evaluate and interpret the\nperformance of clinical AI models, including understanding of common evaluation metrics\n[32], understanding the results of AI models through explainability analysis (e.g., feature\nimportance) [8], and performing statistical testing to compare across multiple Al models\n[44, 35, 50, 32, 52]. In addition, only one studies suggested that designing a ML algorithm\nas a requirement during AI training for medical students [50]."}, {"title": "AI Ethics:", "content": "Existing guidelines focus on the ethical issues of AI in clinical practice. All 18\nstudies emphasized on equipping medical students with understanding of the black-box nature\nof ML models, as well as sources of data and model bias, leading to the explainability and\nfairness issue of Al models. As future \"users\" of clinical Al applications, medical students need\nto know how these issues directly relate to core clinical values [27], and be fully transparent\non informed consent when communicating with patients [33, 53], as well as legal compliance\n[36, 47, 16], social impacts [16], and accountability [8, 3, 32, 53]. Three studies also include that\nmedical students should be aware of health data protection and privacy policies, and known\nand potential unknown risks of AI models [47, 52, 53]."}, {"title": "Question 2: Teaching AI to medical students: courses and programs", "content": "In Question 2, we\naimed to summarize current Al education in medical school, either courses integrated into\nmedical curriculum or informal training programs such as extra-curricular programs and\nworkshops. The data in 11 included studies were extracted and synthesized into main categories\nincluding type (either mandatory course, elective course, or extra-curriculum program), number\nof participants, structure and teaching materials, Al topics covered, instructor expertise\nbackground, education tools used during the course or program, assessment, key findings and\noutcomes, and limitations. The general characteristics of these 11 studies are shown in Table 2."}, {"title": "Type:", "content": "Current AI programs for medical students provide them maximum flexibility to tailor\ntheir education according to their interests and schedules. The majority (eight out of 11) of AI\ntraining programs for medical students are not mandatory and offered as elective courswork.\nAnother two studies provided AI training to medical students through extra-curricula programs\nand workshops [45, 23]. Only 1 study reported the results from a new mandatory AI program\nimplemented for the bachelor's degree in medicine."}, {"title": "Structure and teaching materials:", "content": "The program structures vary based on the different\ndurations of the program (from 16 hours to one year); most AI training programs started\nwith learning sessions (this can be in-person lecturing [21, 54, 23, 49, 20], online live lecturing\n[45, 19, 38], and online self-study of pre-recorded videos and reading materials [22, 40, 1]).\n5 out of 11 studies supplemented students' self-learning with guided community discussion\n[21, 45, 22, 19, 38]. In addition, three out of 11 studies required medical students to work on\ncollaborative projects on building AI tools [23, 49, 38], engaging students in hands-on activities\nto reinforce their uptake and understanding of Al concepts."}, {"title": "Instructor Expertise:", "content": "Most studies recruited instructors from university faculties and AI\nresearchers. Only one study recruited a medical informatics teacher with several clinicians,\nensuring that students received insights from both technical and clinical perspectives."}, {"title": "AI Topics Covered:", "content": "The common Al topics that were covered in these AI training\nprograms provided a comprehensive understanding of AI and the necessary skills to create\nand evaluate Al models yet placed less emphasis on critical skills to leverage AI technologies\neffectively and critically in medical practice and AI ethics. In terms of Know and\nUnderstand AI, six studies out of 11 taught introduction to AI and ML [21, 23, 19,\n40, 1, 38], including the basics of AI and ML, including various techniques such as\nsupervised/unsupervised learning, classification, and regression. Only one study [21] explicitly\ncovered the statistics and mathematical foundations of AI by including basic knowledge of\nstatistics and mathematical description in Al procedures. Three studies covered the topic of\nneural networks and deep learning [21, 1, 38], teaching the principles of neural networks and\ndeepl learning essential for understanding complex Al models. In terms of Use and Apply AI,\ntwo programs covered the health data engineering topics [54, 40], introducing medical image\ndata and electronic health records (EHRs), and their transformative role in healthcare delivery\nand research. Seven programs covered the topics of understanding and using Al applications\nin medicine [21, 54, 22, 19, 49, 40, 20], covering various applications of AI in medicine, clinical\ndecision support systems, innovations driven by AI, value-based care, and precision medicine.\nIn terms of Evaluate and Create AI, only one program explicitly covered the topic of\ncritically evaluating AI models, while three programs taught students basic programming skills\nfor practical implementation of customized Al models. In terms of AI Ethics, six out of 11\nprograms provided students with the training topics of AI safety and ethics [21, 45, 23, 19, 49, 1],\nincluding regulatory policy over medical AI applications and ethical issues that concern the use\nof ML in health care."}, {"title": "Education Tools:", "content": "Only three out of 11 studies reported using online educational tools and\nplatforms to manage and enhance learning [22, 19, 49]. In addition, these tools are popular\nlearning platforms for Al education for the general public (e.g., MOOC ), and their learning\nschedules and content are not specifically designed to meet the rigorous demands and specialized\nneeds of medical students aiming to apply AI in clinical practice."}, {"title": "Assessment:", "content": "The study assessments focused on three themes: medical students knowledge\nuptake and understanding about AI, interest and confidence in AI, and overall satisfaction\ntoward the course/program. Six out of 11 studies used pre- and post-study AI konwledge\nassessment. Among these, five [21, 45, 22, 1, 20] used subjective self-reported survey (e.g.,\nMedical AI Readiness Scale (MAIRS-MS) [17]) and only one study [19] used objective AI\nknowledge test). Two studies surveyed students' self-reported interest and confidence in AI\n[21, 1]. Four studies [54, 23, 49, 40] used post-survey for students' satisfaction toward the\nlesson content, format, and global experience."}, {"title": "Key Findings/Outcomes:", "content": "The key findings across the 11 studies reveal that integrating\nAl education into medical curricula significantly enhanced students' knowledge, confidence,\nand interest in AI. Six out of 11 studies reported substantial increases in Al knowledge, both\nself-assessed and measured objectively [21, 45, 22, 19, 1, 20]. For instance, quiz scores improved\ndramatically [1], and pre- and post-study test comparisons showed significant gains [19]. two\nstudies [21, 1] reported that students' interest in Al topics consistently grew, and the programs\nelicited great enthusiasm and strong engagement. Three studies reported that medical students'\noverall satisfaction with the Al courses was high, and they perceived the lesson contents and\nformats generally attractive [54, 49, 38]."}, {"title": "Main Limitations:", "content": "The main limitations reported across the studies include small sample\nsizes, overreliance on flawed metrics such as self-reported confidence assessments, and self-\nselection bias in elective enrollment. Five studies [45, 49, 40, 1, 20, 38] emphasized small sample\nsize of participants, limiting the generalizability of their findings to other institutions and\nbroader populations. Three studies [19, 49, 38] reported that training courses or programs being\nelectives naturally attracted students already interested in AI, which limited the generalizability\nof the results to all medical students. Two studies [22, 1] emphasized that using self-reported\nquestionnaires, such as the MAIRS-MS [17], rather than objective performance tests, could\nbias the results. One study [49] mentioned that the program was fully in-person and inflexible,\nwith difficulties in finding instructors with appropriate backgrounds who possess expertise in\nboth clinical medicine and medical informatics."}, {"title": "Discussion", "content": "This scoping review examines existing recommendations and current clinical education\nproviding Al training and education to medical students."}, {"title": "Discrepancy between proposed frameworks and current AI education programs\nfor medical students", "content": "Published theoretical guidelines emphasize teaching applications of AI\nand its ethical use [54, 49], yet prevailing AI training programs instead focus on mathematical\nprinciples, data science, and coding skills. These areas, while important, may not be directly\nrelevant for medical students and may become less relevant as models become more accessible\nto lay users. To address this disparity, we propose integrating clinical case studies that highlight\nthe application of AI in diagnostics, treatment planning, and patient monitoring. Similarly, we\nadvocate for workshops and simulations that mimic real-life scenarios [40]."}, {"title": "Challenges of integrating AI training into the medical education program", "content": "Despite\nthe calls to introduce AI concepts to medical students [27, 1, 30] and a strong willingness for its\nstudy [13, 51, 41], integrating AI training into current medical education programs is difficult\nand may face resistance. The foremost criticism of incorporating Al into medical curricula\nis that it has yet to prove its worth to medicine [26]. Theoretical use cases are plentiful for\nclinical decision support tasks, but these rarely provide information an astute clinician does\nnot already know [55]. Furthermore, while randomized controlled trials show promise for these\ntechnologies, their numbers are few and often of questionable generalizability [5]. As with any\nnew medical paradigm, more evidence may be needed to demonstrate how AI-guided clinical\ndecision making improves clinician performance or patient outcomes prior to incorporation\ninto curricula. Secondly, there is the challenge of identifying qualified educators. Few clinicians\npossess training in the principles of mathematics, computer engineering, or data science, fewer\nstill have experience in developing or implementing clinical models [10]. Education in this space\nmust therefore rely on a collaborative teaching environment and crosstalk between university\ndepartments when available. Thirdly, determining the content to teach poses a significant\nchallenge. The field is rapidly evolving, and standardized coursework may quickly become\noutdated [57]. Medical curricula are undergoing transitions away from traditional lecture and\nbasic science frameworks to case-based learning, clinical reasoning assessments, expansion of\nsocial science topics, and earlier exposure to clinical care. While these new curricula are perhaps\nmore adaptable to new topics (i.e. COVID-19 [11]), their true impact on resident and physician\nperformance cannot be measured until years after their implementation. This will also be true\nof any curriculum changes to incorporate AI."}, {"title": "The AI literacy framework for medical students", "content": "Existing proposals require optimization\nin terms of (1) Comprehensiveness", "31": 2, "45": "and (3) Personalization", "23": ".", "5": "and how previous researchers categorized\nAl literacy [31", "dimensions": 1, "AI": "general understanding of AI capabilities and limitations in medicine. (2)\nPractical AI: the ability to select and use the appropriate AI tools for different settings."}]}