{"title": "Grammar-based Game Description Generation using Large Language Models", "authors": ["Tsunehiko Tanaka", "Edgar Simo-Serra"], "abstract": "To lower the barriers to game design development, automated game design, which generates game designs through computational processes, has been explored. In automated game design, machine learning-based techniques such as evolutionary algorithms have achieved success. Benefiting from the remarkable advancements in deep learning, applications in computer vision and natural language processing have progressed in level generation. However, due to the limited amount of data in game design, the application of deep learning has been insufficient for tasks such as game description generation. To pioneer a new approach for handling limited data in automated game design, we focus on the in-context learning of large language models (LLMs). LLMs can capture the features of a task from a few demonstration examples and apply the capabilities acquired during pre-training. We introduce the grammar of game descriptions, which effectively structures the game design space, into the LLMs' reasoning process. Grammar helps LLMs capture the characteristics of the complex task of game description generation. Furthermore, we propose a decoding method that iteratively improves the generated output by leveraging the grammar. Our experiments demonstrate that this approach performs well in generating game descriptions.", "sections": [{"title": "I. INTRODUCTION", "content": "Game design and development requires a significant amount of expertise, creating barriers that limit individuals trying to create game experiences in various fields such as education, cultural participation, healthcare, and engineering. To reduce these skill barriers and promote the democratization of the game design process, techniques to reduce the workload and streamline the design process have become increasingly important. Various machine learning (ML) techniques have been successful in automated game design, including MCTS [1], random forests [2], and concept expansion [3]. Deep learning-based ML is often used in the domain of procedural content generation for level design [4]\u2013[6]. However, despite the progress of Game Description Language (GDL) frameworks [7]\u2013[10] in automated game design, there are few examples of applying deep learning techniques from natural language processing to GDL. This is because deep learning techniques require a large amount of training data, making them less prominent in automated game design, where data is scarce. Further validation of the applicability of modern machine learning techniques in automated game design is needed [11].\nIn this work, we focus on Large Language Models (LLMs) [12], [13] as a new approach to solving tasks with limited data. LLMs are transformer [14]-based deep learning models with a vast number of parameters, pre-trained on a large corpus of textual data. One of the outstanding abilities of LLMs is their capacity to solve various tasks, such as program synthesis [15], [16], using the capabilities acquired during pre-training without additional training. By providing LLMs with task demonstrations consisting of several input-output pairs $(x^{(i)},y^{(i)})$ and a natural language instruction $x$, LLMs can capture the features of the task, in a process known as in-context learning [17]. In automated game design, by providing LLMs with demonstrations of past high-quality game designs represented in a GDL, LLMs can generate game descriptions $y$ using the extensive knowledge obtained during pre-training.\nIt is challenging to characterize minor domain-specific concepts and semantics from only a few demonstrations [18], even for LLMs. In this work, we propose augmenting the LLM with a grammar $G$ of a GDL into the game design process, as shown in Fig. 1. A GDL represents the game design space structure well, and its grammar can represent the features of the game design generation task with high data efficiency. The minimum grammar $G[y^{(i)}] \\subseteq G$ required to construct $y^{(i)}$ is added to the demonstrations. The generation process consists of two stages: the generation of rules in grammar $G[y]$ and the generation of the game description $y$. Furthermore, we propose decoding methods specialized for each stage, which iteratively improve the output of the LLMs using the grammar $G$.\nOur contributions can be summarized as follows:\n\u2022 We propose a novel framework for automated game design by combining Large Language Models (LLM) and Game Design Languages (GDL).\n\u2022 Our framework introduces the grammar of a GDL into the generation process based on in-context learning with LLMs.\n\u2022 We propose iterative improvement decoding methods specialized for grammar generation and game description generation, respectively.\n\u2022 We demonstrate the effectiveness of our framework through extensive experiments on game description generation."}, {"title": "II. RELATED WORK", "content": "A. Game Description Language\nGame Description Language (GDL) is a domain-specific language for games. GDL [9] was introduced in 2005 and has become the standard in General Game Playing, where artificial agents are developed to play a wide variety of games. After GDL, various types of GDL have been developed. VGDL [8] is a language that represents both the levels and rules of 2D sprite-based games. RBG [10] models complex board games by combining low-level and high-level languages. Ludii [7] is a game system developed based on the ludemic approach, which decomposes games into conceptual units of game-related information. Ludii models more than 1,000 traditional games, including board games, card games, dice games, and tile games. The Ludii system generates a complete game description in the Extended Backus-Naur Form (EBNF) style. Diverse analyses of games using Ludii, especially focusing on board games, have been conducted [19]\u2013[23]. For example, [19] calculates the distance between board games using concept values extracted from Ludii. Matthew et al. [20] proposes a framework for automatically generating board game manuals using Ludii. In our work, we use Ludii as our GDL. Furthermore, unlike these works, we add a new perspective to the analysis by focusing on game description generation using grammar.\nB. Automated Game Design\nAutomated game design [24], [25] is one of the core themes in the field of game AI. As AI technology rapidly advances, various aspects of how AI can be utilized in automated game design have been discussed, including the design process [26], design patterns [27], and creative machine learning [28]. Several studies [29], [30] propose methods to generate a game by integrating multiple elements such as visuals, audio, narrative, levels, rules, and gameplay. Generating games using new representations such as answer set programming [31] and game graphs [3] is also explored.\nAutomated game design for generating game designs in the VGDL [8] format has been explored [1], [2], [32], [33]. Thorbj\u00f8rn et al. [32] explores the approach to generate VGDL for arcade games using evolutionary algorithms. GVG-RG [1] proposes a framework for generating appropriate game rules for given game levels. Cicero [33] is a mixed-initiative tool that assists in prototyping 2D sprite-based games using VGDL. Thomas et al. [2] aims to acquire a fitness function that guides game design generation using adversarial random forest classifiers. Our approach shares the use of VGDL with these works but differs in exploring new possibilities for automated game design using LLMs.\nC. Large Language Models in Games\nSince the advent of ChatGPT [34] in late 2022, Large Language Models (LLMs) have attracted significant attention, and various ways of using LLMs in the game domain are being explored [11]. The goal of procedural content generation (PCG) is to generate content used in digital games, such as rules and levels, and LLMs are frequently tested in this field [4]\u2013[6], [35], [36]. Several works [4]\u2013[6] use LLMs to generate 2D tile-based game levels. Another work [35] trains a GPT model to generate quests for role-playing games. LLMGG [36] generates both the rules and levels of games represented in VGDL using LLMs. In LLMGG, LLMs take a part of the VGDL [8] representation or examples of other games as prompts, which generate a complete VGDL-based game in one step. The authors discuss that incorrect game levels and rules not included in the VGDL grammar are generated. In contrast, our approach involves multi-step generation, and the necessary grammar rules to build a game are generated as intermediate representations in the middle steps. Additionally, grammar rules and games are generated conditioned on Ludii [7]'s grammar, preventing incorrect syntax and improving consistency.\nD. Program Synthesis\nIn program synthesis, the task of generating programs from natural language is called semantic parsing. Semantic parsing has benefited from the advancements in LLMs. Several efforts [15], [16] have already explored generating code in general-purpose programming languages such as Python using LLMs. To improve the accuracy of the generated programs, constrained decoding [37]\u2013[39] has also been studied. In domain-specific language (DSL) generation, a prompting method [18] has been proposed that introduces grammar as an intermediate product while LLMs iteratively reason to solve tasks (also known as a chain-of-thought [40]). However, in [18], the evaluation targets simple and short DSLs such as SMCalFlow [41] and GeoQuery [42], and the use of LLMs in the approach is limited. We aim to make more effective use of LLMs in our approach and evaluate it with complex and lengthy DSLs that represent game design, such as Ludii [7]."}, {"title": "III. BACKGROUND", "content": "In this section, we define our problem setting. We first describe the generation of games written in Game Description Language (GDL). We next review in-context learning in game generation.\nA. Game Description Generation\nLet $\\Sigma^{*}$ be the set of all finite strings composed of the alphabet set $\\Sigma$. We center our work on a language $D \\in \\Sigma^{*}$ that cam be used to describe games, that is, a GDL. Thus, our goal is to input a natural language query $x$ that describes the content and rules of a game, and generate a corresponding game description $y \\in D$. In particular, we use Ludii [7] as our GDL. An example of a Ludii game description generation is shown in Fig. 2.\nLudii is a game system that models over 1,000 traditional games, including board games, card games, dice games, and tile games. Ludii can generate complete game descriptions in Extended Backus-Naur Form (EBNF) syntax. Ludii's game descriptions include domain-specific abstract concepts, known as ludemes, and their corresponding semantics. We assume full access to the Ludii grammar, denoted as $G$, which has been developed to model a diversity of different games. Let $L(G)$ be the language generated by grammar $G$. Only those game descriptions that are semantically valid become playable games, which we denote as $D$. In other words, we define compilable game descriptions as $L(G)$ and playable game descriptions as $D$.\nB. In-Context Learning\nProviding a pretrained Large Language Model (LLM) with a few examples related to a specific task is an efficient way of obtaining more precise and accurate results, and is called in-context learning. This approach does not require additional training or fine-tuning; instead, it relies on the LLM's ability to identify and apply patterns from the provided examples. In in-context learning, LLM is conditioned on $N$ demonstrations $(x^{(i)},y^{(i)})_{i=1}^{N}$ followed by a test example query $x$, and generates $y$ as $P_{LLM}(y|(x^{(i)},y^{(i)})_{i=1}^{N}, x)$. Recent studies [43], [44] have reported that the few-shot performance on complex reasoning tasks can be improved by inserting intermediate reasoning steps between $x^{(i)}$ and $y^{(i)}$ in the demonstrations.\nThe effectiveness of in-context learning depends on how effectively the solution to a task can be conveyed through demonstrations. Intuitively, providing more demonstrations to the LLM seems to be beneficial. However, the context length, which is the maximum length that the LLM can capture, is determined during pre-training. Therefore, it is not possible to input a number of demonstrations that exceed this context length. For example, when applying Llama3 [12], one of the leading open-source LLMs, to Ludii's game descriptions, the context length can easily be exceeded. In particular, the average token length of Ludii's game descriptions using the Llama3-8B-Instruct tokenizer is 2,458. The context length of Llama3-8B-Instruct is 8,192, which limits the number of Ludii demonstrations that can be input to a few at most. This limitation when using complex examples such as those"}, {"title": "IV. METHODOLOGY", "content": "We introduce grammar into intermediate reasoning steps as an extension of in-context learning. A simple approach to game description generation using in-context learning is to provide several examples of a query $x^{(i)}$ and a game description $y^{(i)}$, along with a test query $x$, to a LLM and have the LLM generate a game description $y$. However, this simple approach does not produce decent results. We believe this is because texts related to Ludii are scarcely included in the training corpus for LLMs, and the model has no information about the grammatical structure of Ludii.\nIn contrast, Backus-Naur Form (BNF) grammars are commonly used to define the structure of languages and are commonly found in the training data of LLM. Inspired by Bailin et al. [18], we incorporate knowledge of BNF grammars in our generation process. Our approach aims to help the LLM capture the structure of the Game Design Language (GDL) by adding the minimal BNF grammar $G[y^{(i)}]$ necessary to compose $y^{(i)}$ in the demonstrations. An example of $G[y]$ for Tic-Tac-Toe is shown in Fig. 3.\nOur generation process consists of two stages: first, we input the test example query $x$ into the LLM to generate the minimal grammar $\\hat{G}[y]$ necessary to compose $y$. Next, based on $\\hat{G}[y]$, the LLM generates the game description $\\hat{y}$. To improve the generation performance, we propose methods to decode BNF grammar rules $G[y]$ and game descriptions $\\hat{y}$ iteratively using the fully accessible Ludii grammar $G$ as our GDL. Afterwards, the decoder evaluates whether $\\hat{G}[y]$ (or $\\hat{y}$) conforms to the Ludii grammar $G$ (or $G[y]$). In each stage, this generation and evaluation process is repeated. In this section, we first explain the two-stage generation in-depth, and then describe the decoding process at each stage in Subsection IV-B.\nA. Grammar-based Game Description Generation\nWe first introduce the minimal grammar $G[y] \\subseteq G$ necessary to compose $y$. $G[y]$ is a subset of the full grammar $G$, where $y \\in L(G[y])$ and $\\forall r \\in G[y], y \\notin L(G[y] \\setminus \\{r\\})$. We can obtain $G[y]$ by parsing $y$ with $G$ and collecting the rules to derive $y$. Each demonstration consists of $(x^{(i)}, G[y^{(i)}], y^{(i)})$.\nThe generation process consists of two stages. In the first stage, a few demonstration examples and a test example query $x$ are input to the LLM as a prompt to generate the minimal grammar $\\hat{G}[y]$ necessary to compose $y$. The grammar $G'$ that maximizes the following probability is selected as $\\hat{G}[y]$,\n$P_{LLM}(G'|(x^{(i)}, G[y^{(i)}], y^{(i)})_{i=1}^{N}, x)$.  (1)\nIn the second stage, the generated $\\hat{G}[y]$ is added to the prompt to generate the game description $\\hat{y}$, and the $y'$ that maximizes the following probability is selected as $\\hat{y}$:\n$P_{LLM}(y'|(x^{(i)}, G[y^{(i)}], y^{(i)})_{i=1}^{N}, x, \\hat{G}[y])$. (2)\nWe show an overview of the two-stage generation process in Fig. 4.\nAdditionally, in the second stage, although $y$ is conditioned on the grammar $G[y]$, the generated game description may not adhere to $G[y]$. This is because the LLM just selects the words with the highest likelihood, and does not necessarily comply with the conditions set by the prompt. Similarly, $\\hat{G}[y]$ may not be a subset of the original grammar $G$. Therefore, in the next subsection, we propose decoding methods to improve the consistency of the minimal grammar $\\hat{G}[y]$ with the original grammar $G$, and the consistency of the game description $\\hat{y}$ with the grammar $G[y]$.\nB. Grammar-based Iterative Decoding\nIn order to overcome issues of inconsistent grammars, we propose decoding methods that iteratively improve the generated grammars. In particular, our decoding methods are divided into two types, one specialized for the grammar $\\hat{G}[y]$, and one for the game description $\\hat{y}$. When decoding the grammar $\\hat{G}[y]$, undefined non-terminal symbols are extracted in one step, and rules to define them are then generated in the next step, in what we call the Rule Decoding stage. Similarly, when generating the game description $\\hat{y}$, we use the Earley parser [45] to obtain the longest valid continuation that adheres to the grammar $\\hat{G}[y]$ in one step, and then complete the remaining parts following the valid continuation in the next step. We refer to this as Game Description Decoding stage.\na) Rule Decoding Stage: Our rule decoding stage iteratively applies rule decoding while aiming to ensure that the generated $\\hat{G}[y]$ is a subset of the original grammar $G$. In our rule decoding stage, the generation process is multi-step, where each step iteratively improves the grammar $G[y]$. The goal of each step is to define the non-terminal symbols that were not defined in the grammar $\\hat{G}[y]$ generated in the previous step. We illustrate our rule decoding process in Fig. 5. Initially, $\\hat{G}[y]$ is generated using the LLM in the same way as in Eq. (1). From $\\hat{G}[y]$, only the valid grammar rules $\\hat{G}[y]_{valid}$ are retained, which are included in the original grammar $G$. Among $\\hat{G}[y]_{valid}$, the set of undefined non-terminal symbols $N_U$ is extracted. The undefined non-terminal symbols are those that are used on the right-hand side of rules in $\\hat{G}[y]_{valid}$ but are not defined (i.e., they do not appear on the left-hand side of any rules), and can be automatically extracted easily. The set of grammar rules for the undefined non-terminal symbols $G_{N_U}$ is extracted from the original grammar $G$. $G_{N_U}$ is added to the prompt, and the LLM selects only the necessary rules from $G_{N_U}$ based on the query $x$. Since $G_{N_U}$ is extracted from the original grammar $G$, it contains more rules than the minimum required for $y$. The role of the LLM is to extract only the rules $G'_{N_U} = \\hat{G}[y] \\setminus G[y]_{valid}$ necessary to compose $y$ from $G_{N_U}$. The rules that maximize the following probability are selected:\n$P_{LLM}(G'_{N_U}|(x^{(i)}, G[y^{(i)}], y^{(i)})_{i=1}^{N}, x, \\hat{G}[y]_{valid}, G_{N_U})$. (3)\n$G'_{N_U}$ is combined with $\\hat{G}[y]_{valid}$ to update $\\hat{G}[y]$. This process is repeated until there are no more non-terminal symbols or a predetermined limit of updates is reached.\nb) Game Description Decoding stage: The game description decoding stage consists of iterative application of game description decoding to generate game descriptions that more accurately adhere to the grammar $\\hat{G}[y]$. In each step, it aims to complete the parts of $\\hat{y}$ generated in the previous step that cannot be parsed. Initially, $\\hat{y}$ is generated using the LLM in the same way as in Eq. (2). An Earley parser [45] is then employed using $\\hat{G}[y]$. The Earley parser explores the program from left to right, extracting the longest valid subsequence and the subsequent candidate terminal symbols. Using the generated $\\hat{y}$, the Earley parser obtains the valid subsequence $\\hat{y}_{valid}$ and the set of candidate terminal symbols $\\Omega_{candidate}$. The LLM selects the most suitable candidate $\\omega$ from $\\Omega_{candidate}$. The $\\omega'$ that maximizes the following probability is then chosen:\n$P_{LLM}(\\omega'|(x^{(i)}, G[y^{(i)}], y^{(i)})_{i=1}^{N}, x, \\hat{G}[y], \\hat{y}_{valid}, \\Omega_{candidate})$. (4)\nThe selected candidate is appended to the end of $\\hat{y}_{valid}$, and the LLM generates the remaining part of the game description $\\hat{y}$. Next, the $y'$ that maximizes the following probability is generated:\n$P_{LLM}(y'|(x^{(i)}, G[y^{(i)}], y^{(i)})_{i=1}^{N}, x, \\hat{G}[y], \\hat{y}_{valid} + \\omega)$. (5)\nThe generated $\\hat{y}$ updates $\\hat{y}$ from the previous step. This process is repeated until the entire generated $\\hat{y}$ becomes parsable by the Earley parser or until a predetermined number of updates is reached."}, {"title": "V. EXPERIMENTS", "content": "A. Datasets\nThe game descriptions generated by Ludii [7] that we use for evaluation are obtained from the publicly available Ludii software [46]. In Ludii, each game is assigned a category (e.g., \"Tic-Tac-Toe\" is categorized under \"Board/Space/Line\", and \"Tower of Hanoi\" under \u201cPuzzle/Planning\u201d). From the same category, one test example and three demonstration examples are extracted as a single instance. Note that only examples where the token length of the game description $y$ is 300 or less are used. The token length is calculated using the tokenizer of Llama3-8B-Instruct [12]. The dataset is constructed from 100 randomly selected instances from all categories, and the same set of instances is used in all evaluations. Each example consists of a natural language instruction $x$, a Ludii game description $y$, and the minimal grammar $G[y]$ required to construct $y$. The instruction $x$ is composed of the metadata \u201cDescription\u201d and \u201cRules\u201d provided by the Ludii game system (see Fig. 2 for an example). The game description $y$ consists of the extended game description derived from the raw text .lud game description files. The extended version is instantiated with primitive options and rulesets to avoid using the Ludii game system's meta-language features (definitions, options, rulesets, ranges, constants, etc.). We use this extended version to reduce game-specific representations as much as possible. For more details of the Ludii language, please refer to the"}, {"title": "C. Evaluation Metrics", "content": "To evaluate the generated game descriptions, we use the following metrics:\n\u2022 Grammar Parsability: The proportion of generated game descriptions that can be parsed by the Lark parser, which is based on the Ludii grammar $G$.\n\u2022 System Parsability: The proportion of generated game descriptions that can be read by the Ludii game system. Descriptions that are grammatically correct as per the Lark parser but lack any of the necessary functions for a game can not be read by the Ludii game system.\n\u2022 Playability: The proportion of generated game descriptions that require a reasonable number of player actions per trial. A trial is considered successful if it fulfills the specified termination conditions in at least 5 out of 10 attempts. In particular, we consider the game to be playable if, by continuously choosing legal actions, the number of actions necessary to reach a termination condition should range between 2 and 1,800. This metric evaluates whether the generated game has a reasonable length of play experience. For a game description to satisfy the Playability criteria, it also has to satisfy the Grammar Parsability and System Parsability criteria. We use the implementation [46] in the Ludii game system for this metric.\n\u2022 ROUGE [51]: This is a metric that measures the degree of match between the generated game description and the ground truth game description. It ranges from 0 to 100, with higher values indicating a greater degree of match. The calculation of this metric does not consider syntactic correctness but instead focuses on the similarity between texts. We use the F1 score of ROUGE-L. This value is calculated for each piece of test data, and the average of all data is reported."}, {"title": "D. Quantitative Results", "content": "We compare the following methods:\n\u2022 Game Description Generation (GDG): Predicts the game description $y$ directly from the demonstration examples and the query $x$ without using the predicted grammar $\\hat{G}[y]$.\n\u2022 Grammar-based Game Description Generation (GGDG): Generates the grammar $G[y]$ required to construct the game description $y$, and then generates $\\hat{y}$ based on $\\hat{G}[y]$.\n\u2022 GGDG + Rule Decoding (RD): Uses the proposed rule decoding in addition to GGDG.\n\u2022 GGDG + RD + Game Description Decoding (GDD): Uses both the proposed rule decoding and game description decoding in addition to GGDG.\nIn addition to these, for GGDG and GGDG + GDD, we also compare the methods that use the oracle grammar $G[y]$ obtained from the ground truth with a parser based on grammar $G$ instead of the generated $\\hat{G}[y]$.\nThe results are summarized in Tab. I. In all metrics, GGDG + RD + GDD shows the highest performance, indicating that introducing rule decoding significantly improves both System Parsability and Playability. Additionally, incorporating game description decoding further enhances Grammar Parsability and Playability. This highlights how both of our decoding methods play an important role in increasing the quality of the generated game descriptions. GDG demonstrates high ROUGE scores but has low scores for Grammar Parsability, System Parsability, and Playability. This suggests that while LLM alone can generate descriptions superficially similar to the ground truth, it is challenging to generate grammatically correct descriptions without accessing Ludii's grammar. In the case of the oracle grammar, using game description decoding significantly improves Grammar Parsability, System Parsability, and Playability scores. Additionally, compared to not using the oracle grammar, Playability and ROUGE scores are improved, indicating that accurate grammar prediction greatly contributes to the improvement of game descriptions."}, {"title": "E. Qualitative Results", "content": "We present the generation results of Tic-Tac-Toe in Fig. 8. The results demonstrate the effectiveness of our proposed framework, particularly the iterative decoding methods. The first row of Fig. 8 displays the results of the game description generation for each method. The far-left column is the ground truth, and the results from the second column onwards are the methods with grammar prediction, rule decoding, and"}, {"title": "VI. LIMITATION", "content": "Our proposed framework may have issues with inference time and cost because it repeats LLM inference multiple times. This issue can be mitigated by caching LLM responses, setting appropriate limits on the number of LLM inferences, and improving the prompts.\nThe evaluation in this paper relies solely on automatically calculable metrics and does not include human evaluations of user experience. The grammar introduced in our framework shows its greatest strength in lower-layer aspects such as Parsability and Playability, rather than in user experience. However, we believe that insights gained from playing the generated games could also lead to further improvements."}, {"title": "VII. BROADER IMPACT", "content": "The use of LLMs in the field of video games is associated with ethical issues related to sustainability, copyright, explainability, and biases [11]. In this section, we discuss the problems and their mitigation strategies within our proposed framework from these perspectives.\nOur research raises concerns about the carbon footprint of LLMs. Our framework does not include training LLMs, and only LLMs' inference impacts the environment. This issue can be mitigated by reducing the number of inference calls through caching LLM responses and providing more effective demonstrations. Additionally, using models that offer enhanced performance for the same computational load can further reduce environmental impact.\nOur research is related to copyright issues concerning input and output data. It is common practice for LLMs to be trained using copyrighted data [11]. Since our framework does not include the training process, it does not directly cause this issue. However, when using our framework, attention should be paid to the training data of LLMs. Our framework automatically generates game descriptions without human intervention. The output generated by our framework may not be copyrighted. Developing our framework into an interactive approach with human designers may allow the final output to qualify for copyright.\nThe generation process of LLMs is opaque, and in our research, the process for each LLM call is similarly unclear. However, our grammar-based iterative decoding method breaks down the generation process into multiple steps, which should enhance our understanding of it.\nLLMs are trained on data collected from the internet, which introduces biases. Since game design tends to reflect the culture of its time and region, these biases negatively impact the design process when using LLMs. Our framework could potentially mitigate the issue by incorporating examples from various eras and regions in the demonstrations for LLMs. Ludii collects historically influential games from diverse regions and provides metadata on the regions where each game is rooted, which can contribute to mitigating this problem."}, {"title": "VIII. CONCLUSIONS", "content": "In this paper, we proposed an automated game design framework using Large Language Models (LLMs) with the Ludii grammar as our Game Design Language grammar. Our framework generates Ludii game descriptions based on in-context learning with LLMs. The generation process is performed in two stages: generating the grammar necessary for the game description, and generating the game description itself. Our proposed approach enables the LLMs to capture the features of the game description generation task with fewer demonstration examples. We further propose iterative decoding methods specialized for both the grammar and the game descriptions, which improve the grammatical correctness of the generated game descriptions. Extensive experimental results show the effectiveness of our framework in the game description generation task."}]}