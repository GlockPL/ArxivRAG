{"title": "Data Generation using Large Language Models for Text Classification: An Empirical Case Study", "authors": ["Yinheng Li", "Rogerio Bonatti", "Sara Abdali", "Justin Wagle", "Kazuhito Koishida"], "abstract": "Using Large Language Models (LLMs) to generate synthetic data for model training has become increasingly popular in recent years. While LLMs are capable of producing realistic training data, the effectiveness of data generation is influenced by various factors, including the choice of prompt, task complexity, and the quality, quantity, and diversity of the generated data. In this work, we focus exclusively on using synthetic data for text classification tasks. Specifically, we use natural language understanding (NLU) models trained on synthetic data to assess the quality of synthetic data from different generation approaches. This work provides an empirical analysis of the impact of these factors and offers recommendations for better data generation practices.", "sections": [{"title": "1. Introduction", "content": "Data augmentation is a method that utilize existing data to generate additional training data without collecting more data (Feng et al., 2021). It is an effective solution to improve model performance when limited data is available (Xie et al., 2020). With the emergence of large language models, data augmentation becomes even more accessible and has been successfully applied in training language models (Gunasekar et al., 2023; Liu et al., 2024). Using LLM to generate or annotate data is a cost-efficient alternative to human-labeled data. While human-labeled data tends to have higher quality, leveraging LLM with well-designed prompts can also generate data that achieves comparable model performance at a much lower cost. As estimated in (Ding et al., 2023), labeling 3000 samples for SST-2 task (Socher et al., 2013) would cost between 221 to 300 USD and take around 1000 minutes. In contrast, generating the same amount of data using GPT-3 only costs 14.37 USD and takes 46 minutes. With only 6000 samples generated by GPT-3, the model is able to achieved 76% accuracy, compared to 88% from human-curated data. Our research focuses on synthetic data generation using of large language models (LLMs) for text classification tasks, specifically tasks uses natural language understanding models(transformer encoder models). In the scope of this study, we use the terms data augmentation and data generation interchangeably, as LLMs often require a few in-context samples to generate data. The data produced in this way can be considered augmented from these in-context samples. Meanwhile, we focus solely on tasks that have limited or no data at all, as our experiments have shown that tasks with sufficient data receive minimal improvements from additional synthetic data. Numerous studies have proposed various frameworks to improve the quality of synthetic data generation (Wang et al., 2023; Gao et al., 2023; Gupta et al., 2023). However, to the best of our knowledge, few works have addressed the fundamental questions associated with LLM for data generation. These questions include:\n\u2022 What is the optimal amount of data to generate, and does increasing the volume of synthetic data improve model performance?\n\u2022 Can in-context learning (generation) enhance the quality of synthetic data, would providing few examples lead to higher quality data than zero-shot generation?\n\u2022 Does the LLM's performance on a particular task directly influence the quality of the generated synthetic data for this task?\n\u2022 Is combining synthetic data with raw data beneficial for model training?\n\u2022 Is the synthetic data diversity an important factor for model performance?\nWe experimented with six common NLP tasks (Table 4) with different data generation methods. We found it is very challenging to pinpoint a definitive answer to the questions above that applies universally to all NLP tasks due to their"}, {"title": "2. Related Work", "content": "Data Augmentation The goal of data augmentation is to increase diversity of existing data by exposing the model to unseen data. This method has been applied to many domains in computer vision (Yang et al., 2023) and natural language processing (Li et al., 2022). In (Feng et al., 2021), augmentation techniques are categorized into rule based generation and model based generation. Rule based generation are used in computer vision problems including image transformations, such as rotation, flipping, and cropping, etc (Miko\u0142ajczyk & Grochowski, 2018), while model based generation has been widely used in natural language processing, such as rephrasing, back translation (Kumar et al., 2019; Yang et al., 2020; Cai et al., 2020; Ye et al., 2022; Okur et al., 2022b).\nLarge Language models (LLMs) With the development of large language models, model based data augmentation for NLP becomes trivial (Zhou et al., 2024). By instructing LLM with proper prompt, it is able to generate a new example in human like text. While it is easy to implement, the synthetic data generated from LLM is usually noisy and has a different distribution compared with raw data, which hampers the training performance. Lots of work has explored ways to deal with this issue. The work from (Veselovsky et al., 2023) uses techniques like grounding, providing taxonomy and filtering to ensure the quality of synthetic data by LLM. Synthesis Step by Step (Wang et al., 2023) uses an iterative step to create prompt based on misclassified golden data to reduce the gap between the synthesized data distribution and gold distribution. SunGen (Gao et al., 2023) uses weighted loss to reduce the impact of noise from synthetic data during training."}, {"title": "3. Methods", "content": "We follow the workflow in Figure 1 for our experiment. We explore the following in-context data generation methods. The term \"in-context generation\" refers to using an LLM to generate data for training given a specific context, similar to in-context learning (Brown et al., 2020). The methods we investigate can be categorized as follows:\n\u2022 Zero-shot in-context generation: Provide the task description in the prompt and ask the LLM to generate a similar example.\n\u2022 One-shot in-context generation: Provide the task description and one example, prompting the LLM to generate a similar example.\n\u2022 Few-shot in-context generation: Provide the task description and a few examples, prompting the LLM to generate a similar example.\nInspired by the work from (Yu et al., 2023), we also experiment with an additional method called zero-shot topic in-context generation:\n\u2022 Zero-shot topic in-context generation: Use the LLM to generate a list of topics (see Appendix A). Provide the task description and sample one topic from the list to prompt the LLM to generate a similar example.\nTo evaluate the success of synthetic data generation, we train a NLU model on the synthetic data and assess its performance on the task's validation set. We then compare the performance of the model trained on synthetic data with that of the model trained on the original data. Following the practice established in previous works (Li et al., 2023), we consider the generated data is better if it results in better model performance."}, {"title": "4. Experiments", "content": "In our experiment, GPT-3.5 turbo is selected for all data generation process except for topic generation (see appendix A). Although more powerful models like GPT-4 is available, we decided to use GPT-3.5 turbo due to the resource constrain, especially we need to run the large number of inferences for our data generation experiment. Overall, GPT-3.5 turbo is a well-rounded model with competitive performance across multiple benchmarks (Liang et al., 2023). In the future, it would be interesting to compare the quality of synthetic data generated from different LLMs, which we plan to explore further.\nExisting work (Gupta et al., 2023) have utilized common NLP benchmarks, such as SuperGLUE (Wang et al., 2019), as tasks for evaluation or employ a customized selection (Gao et al., 2023; Ye et al., 2022).\nWe select six common tasks for evaluation: SST-2 (Socher et al., 2013; Wang et al., 2019), Twitter Emotion Classification (EMO) (Saravia et al., 2018), New York Times News Classification (NYT)(Stefano, 2021), Review (Amazon Review Classification) (Keung et al., 2020), RTE (Recognizing Textual Entailment) (Bentivogli et al., 2009; Wang et al., 2019) and BoolQ (Clark et al., 2019; Wang et al., 2019). The goal is to select diverse tasks that represent a wide range of popular NLP corpora (Table 4). Additionally, we try to include challenging tasks for which current NLU models do"}, {"title": "5. Key Findings", "content": "In this section, we present the key findings from our experiments."}, {"title": "5.1. Mixing Raw Data is Necessary", "content": "To assess the effectiveness of data augmentation, we train models with pure synthetic data and augmented data. For the augmented setting, 100 raw data points are mixed with 1000 synthetic data. In the data generation stage, we use only the same 100 raw data points used for in-context generation to prevent the model from accessing additional data. As shown in Figure 2, we observe significant improvements across all tasks for most prompting methods when incorporating raw data into training. Even as few as 100 data points can boost synthetic data performance compared to using only synthetic data."}, {"title": "5.2. Impact of Bias", "content": "In the BoolQ task, we found that the zero-shot generation method outperforms other methods, which contrasts with the results obtained for the rest of the tasks. This finding is intriguing since zero-shot data exhibits the highest repetition rate, which is detrimental to model training. Upon further examination, we noticed that only in the datasets generated using one-shot or few-shot methods, terms like \"not,\" \"significant,\" \"only,\" \"just,\" \"few,\" and \"little\" frequently appear in the generated questions. These terms create a tone that can be used to imply the answer to the question (which is often False). Table 5.2 provides an example of such trivial question. Table 3 provides statistics for such questions from different prompting method. We hypothesize that this pattern introduces bias in model"}, {"title": "5.3. Relationship between LLM Performance and Data Quality", "content": "While it may seem intuitive that the effectiveness of using LLMs to generate data for model training depends on the LLM's knowledge of a specific task, our research has shown that this is not always the case. The zero-shot or few-shot performance of an LLM on a task does not necessarily determine the performance of a model (specifically, the ROBERTa model used in our experiment) trained with data generated by the LLM. In other words, the fact that an LLM performs well on a task does not guarantee that models finetuned with data generated by the LLM will also perform well. Additionally, for tasks where the LLM performs poorly, models"}, {"title": "5.4. Synthetic Data is Helpful Mostly in Low-Resource Settings", "content": "Previous work has shown that it is challenging for models trained with synthetic data to perform as well as models trained with the same amount of original data (Li et al., 2023; Ding et al., 2023). However, when human-annotated data is limited, synthetic data augmentation can improve model performance. In fact, this technique is most effective in low-resource settings. For all tasks with 100 raw data points, we found that synthetic data augmentation yields improvements of at least 3% to 26%. When the raw training data increases to 1,000, only four tasks show improvements,"}, {"title": "5.5. A Comparison Between Different Prompting Methods", "content": "In the synthetic data only setting, one-shot or zero-shot topic methods rank in the top two for all tasks except the Review task (Figure 2).\nIn the augmented setting, few-shot generation and zero-shot topic generation methods demonstrate good performance across all tasks. In BoolQ, EMO, and RTE tasks, zero-shot topic methods outperform other prompting methods. In SST-2 and NYT tasks, few-shot generation methods perform best. The performance of zero-shot methods is sub-optimal across all tasks.\nIn the five prompting methods we experimented with, zero-shot topic generation typically produces the most diverse dataset because different topic is sampled for each time during generation. Pure zero-shot methods generate the least diverse dataset, as the prompt remains the same for each generation. One-shot and few-shot methods also generate repeated examples due to the limitation of in-context examples. We found for most tasks, a diversity dataset tends to benefit model training. As shown in (Figure 2), in non-augmented setting pure zero-shot generation shows the worst performance for RTE, EMO, Review and SST-2 while zero-shot topic generation out-performs other methods (or close to other methods) for BoolQ, NYT, RTE and EMO task. This effect does not appear on all tasks as there might be other factors that impact the model performance. Meanwhile, the effect of diversity diminishes when we mix synthetic data with raw data. Therefore, training with both raw data and synthetic data could help when synthetic data is not diverse.\nWhile not generating the most optimally diverse dataset, using one-shot or few-shot generation methods typically helps LLMs better understand the task description and generate examples similar to the original examples (Li, 2023; Song et al., 2022). In EMO and Review tasks, we observe the advantage of few-shot learning over other prompting methods. We suspect this is because both tasks are more subjective compared to the rest of the tasks, as the EMO contains twitter posts and Review task is made up of customer reviews and ratings."}, {"title": "5.6. Synthetic Data Diversity and Similarity to Raw Data", "content": "In this section, we examine the diversity of our training data using inter-sample semantic similarity. To calculate this similarity, we use vector embedding proposed in (Reimers & Gurevych, 2019) and average the similarity score across all examples pairs following (Yu et al., 2023). Figure 4 displays the inter-sample similarity for each task, comparing data generated by five prompting methods. On the x-axis, we show the performance of the finetuned model using the 1000 synthetic data only. Figure 4 shows that for BoolQ, NYT, and SST-2, a lower inter-sample diversity results in a better F1 score. However, for other tasks, the correlation is weak due to the existence of outliers, especially for RTE, and the possible impact of other factors, such as task complexity. We also calculated the similarity between the synthetic data and the actual raw data using the same method and found that the synthetic data generated from five different prompting methods had similar similarity scores with the raw data. However, it is not clear whether synthetic data that closely resembles the raw data would lead to better model performance. This could be due to the limitations of our similarity measuring method, which only considers semantic similarity, as discussed in (Steck et al., 2024). Many NLP tasks rely on subtle contextual cues and nuanced wordings, such as in the SST-2 task, where changes to wording can affect the sentiment of the text more than contextual semantics."}, {"title": "5.7. Synthetic Data Quantity", "content": "We have found that increasing the amount of synthetic data in our model training improves its performance. Figure 5 shows the relationship between the model's performance (measured by the f1 score) on the y-axis and the total number of training data on the x-axis. In the augmented scenario, we mixed 100 raw data points with varying amounts of synthetic data. The performance is the average of the model's f1 score over 5 prompting methods for each data size. For the raw data scenario, only real-world data was used in model training. Our graph indicates that raw data serves as an upper bound for the augmented setting in almost all tasks. Moreover, we observed that the marginal effect of performance gain with increasing training data is present in both raw and synthetic data. For BoolQ and SST-2 tasks, we observed this phenomenon at the same data size. As such, the raw data size at which marginal improvement of model performance appears can be used as a reference point when increasing the number of synthetic data."}, {"title": "6. Data Generation Techniques in Practice", "content": "In the process of using LLM to generate data for this study, we identified several useful techniques. These practices lack theoretical support and the effectiveness of these techniques can be subject to the choice of large language models or the requirements of a specific task."}, {"title": "6.1. Condition on Label", "content": "There are two typical ways to generate a classification dataset: Condition on the Label and Left-to-Right (see Table 6). It is recommended to use Condition on the Label for each generation as it saves effort in parsing the label and avoids LLM generating unknown labels. It also provides the user control over the label distribution in the synthetic dataset.\nIt is worth noting that class-conditioned generations are more likely to introduce bias and reduce the difficulty of the synthetic example. When the class label is visible, LLM could leak the label information during content generation. In the BoolQ example, LLM hints the answer \"FALSE\" via"}, {"title": "6.2. Generation on Target Corpus", "content": "It is essential to provide topics or descriptions closely related to the use case when generating examples. Ensuring that the topics are relevant to the use case significantly improves the quality of generated data. For example, when creating examples from Twitter, it is beneficial to first generate common topics found on Twitter. On the other hand, when generating Amazon customer reviews, it is effective to generate an Amazon product catalog as a list of potential topics. This approach ensures that the synthetic data is more closely aligned with the target corpus, leading to better performance in classification tasks."}, {"title": "6.3. Iterative Data Generation and Prompt Refinement", "content": "Generating synthetic data can be both time-consuming and resource-intensive. To maximize efficiency and ensure high-quality data, it is recommended to adopt an iterative approach. Initially, generate a small number of examples and evaluate their quality. If the quality of these initial data points is low, refine the prompt before generating more data. It is unlikely that simply generating more data points with the same prompt will magically produce high quality data."}, {"title": "7. Conclusion", "content": "In this work, we analyzed different factors that influences the data generation using LLMs. We found data generation is most effective in low resourced settings. Increasing the amount of synthetic data does not necessarily lead to continuous improvements in model performance. It is beneficial to combine synthetic data with raw data during training. Additionally, it is crucial to be vigilant for patterns or biases in synthetic data that may hinder model training. Overall, using LLM for data augmentation has great potential in model training. With a carefully tuned prompt, the data generated by LLM is able to obtain comparable performance with human annotated data, but at a much lower cost.\nThe domain of data generation for classification tasks is highly complex. Due to the diversity of NLP tasks, it is challenging to find rules that generalize well across all tasks. However, our findings could still serve as valuable resources for researchers and practitioners looking to use synthetic data for training classification models. For future work, it would be valuable to study the effects of more advanced prompting methods, such as the Chain of Thought (Wei et al., 2023), or LLM hyperparameters, such as temperature, on the quality of synthetic data."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here."}, {"title": "A. Appendix", "content": "Prompt for topic generation for zero-shot with topics and LLM output examples. GPT-4 is used to generate 500 random topics per task:"}, {"title": "B. Appendix", "content": "Prompt for Question Rephrasing in Section 5.2"}, {"title": "C. Appendix", "content": "Prompt used for data generation for each task:"}, {"title": "D. Appendix", "content": "Prompt used to evaluate LLM performance on each task."}]}