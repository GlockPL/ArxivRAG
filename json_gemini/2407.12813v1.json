{"title": "Data Generation using Large Language Models for Text Classification: An Empirical Case Study", "authors": ["Yinheng Li", "Rogerio Bonatti", "Sara Abdali", "Justin Wagle", "Kazuhito Koishida"], "abstract": "Using Large Language Models (LLMs) to gener-\nate synthetic data for model training has become\nincreasingly popular in recent years. While LLMs\nare capable of producing realistic training data,\nthe effectiveness of data generation is influenced\nby various factors, including the choice of prompt,\ntask complexity, and the quality, quantity, and di-\nversity of the generated data. In this work, we\nfocus exclusively on using synthetic data for text\nclassification tasks. Specifically, we use natural\nlanguage understanding (NLU) models trained on\nsynthetic data to assess the quality of synthetic\ndata from different generation approaches. This\nwork provides an empirical analysis of the impact\nof these factors and offers recommendations for\nbetter data generation practices.", "sections": [{"title": "1. Introduction", "content": "Data augmentation is a method that utilize existing data to\ngenerate additional training data without collecting more\ndata (Feng et al., 2021). It is an effective solution to im-\nprove model performance when limited data is available\n(Xie et al., 2020). With the emergence of large language\nmodels, data augmentation becomes even more accessible\nand has been successfully applied in training language mod-\nels (Gunasekar et al., 2023; Liu et al., 2024).\nUsing LLM to generate or annotate data is a cost-efficient\nalternative to human-labeled data. While human-labeled\ndata tends to have higher quality, leveraging LLM with\nwell-designed prompts can also generate data that achieves\ncomparable model performance at a much lower cost. As\nestimated in (Ding et al., 2023), labeling 3000 samples for\nSST-2 task (Socher et al., 2013) would cost between 221\nto 300 USD and take around 1000 minutes. In contrast,\ngenerating the same amount of data using GPT-3 only costs\n14.37 USD and takes 46 minutes. With only 6000 samples\ngenerated by GPT-3, the model is able to achieved 76%\naccuracy, compared to 88% from human-curated data.\nOur research focuses on synthetic data generation using of\nlarge language models (LLMs) for text classification tasks,\nspecifically tasks uses natural language understanding mod-\nels(transformer encoder models). In the scope of this study,\nwe use the terms data augmentation and data generation\ninterchangeably, as LLMs often require a few in-context\nsamples to generate data. The data produced in this way\ncan be considered augmented from these in-context samples.\nMeanwhile, we focus solely on tasks that have limited or\nno data at all, as our experiments have shown that tasks\nwith sufficient data receive minimal improvements from\nadditional synthetic data. Numerous studies have proposed\nvarious frameworks to improve the quality of synthetic data\ngeneration (Wang et al., 2023; Gao et al., 2023; Gupta et al.,\n2023). However, to the best of our knowledge, few works\nhave addressed the fundamental questions associated with\nLLM for data generation. These questions include:\n\u2022 What is the optimal amount of data to generate, and\ndoes increasing the volume of synthetic data improve\nmodel performance?\n\u2022 Can in-context learning (generation) enhance the qual-\nity of synthetic data, would providing few examples\nlead to higher quality data than zero-shot generation?\n\u2022 Does the LLM's performance on a particular task di-\nrectly influence the quality of the generated synthetic\ndata for this task?\n\u2022 Is combining synthetic data with raw data beneficial\nfor model training?\n\u2022 Is the synthetic data diversity an important factor for\nmodel performance?\nWe experimented with six common NLP tasks (Table 4)\nwith different data generation methods. We found it is very\nchallenging to pinpoint a definitive answer to the questions\nabove that applies universally to all NLP tasks due to their"}, {"title": "2. Related Work", "content": "Data Augmentation The goal of data augmentation is to\nincrease diversity of existing data by exposing the model\nto unseen data. This method has been applied to many do-\nmains in computer vision (Yang et al., 2023) and natural\nlanguage processing (Li et al., 2022). In (Feng et al., 2021),\naugmentation techniques are categorized into rule based\ngeneration and model based generation. Rule based genera-\ntion are used in computer vision problems including image\ntransformations, such as rotation, flipping, and cropping,\netc (Miko\u0142ajczyk & Grochowski, 2018), while model based\ngeneration has been widely used in natural language pro-\ncessing, such as rephrasing, back translation (Kumar et al.,\n2019; Yang et al., 2020; Cai et al., 2020; Ye et al., 2022;\nOkur et al., 2022b).\nLarge Language models (LLMs) With the development\nof large language models, model based data augmentation\nfor NLP becomes trivial (Zhou et al., 2024). By instructing\nLLM with proper prompt, it is able to generate a new exam-\nple in human like text. While it is easy to implement, the\nsynthetic data generated from LLM is usually noisy and has\na different distribution compared with raw data, which ham-\npers the training performance. Lots of work has explored\nways to deal with this issue. The work from (Veselovsky\net al., 2023) uses techniques like grounding, providing tax-\nonomy and filtering to ensure the quality of synthetic data\nby LLM. Synthesis Step by Step (Wang et al., 2023) uses an\niterative step to create prompt based on misclassified golden\ndata to reduce the gap between the synthesized data distribu-\ntion and gold distribution. SunGen (Gao et al., 2023) uses\nweighted loss to reduce the impact of noise from synthetic\ndata during training."}, {"title": "3. Methods", "content": "We follow the workflow in Figure 1 for our experiment. We\nexplore the following in-context data generation methods.\nThe term \"in-context generation\" refers to using an LLM to\ngenerate data for training given a specific context, similar to\nin-context learning (Brown et al., 2020). The methods we\ninvestigate can be categorized as follows:\n\u2022 Zero-shot in-context generation: Provide the task de-\nscription in the prompt and ask the LLM to generate a\nsimilar example.\n\u2022 One-shot in-context generation: Provide the task de-\nscription and one example, prompting the LLM to"}, {"title": "4. Experiments", "content": "In our experiment, GPT-3.5 turbo\u00b9 is selected for all data\ngeneration process except for topic generation (see appendix\nA). Although more powerful models like GPT-4 is avail-\nable, we decided to use GPT-3.5 turbo due to the resource\nconstrain, especially we need to run the large number of\ninferences for our data generation experiment. Overall, GPT-\n3.5 turbo is a well-rounded model with competitive perfor-\nmance across multiple benchmarks (Liang et al., 2023). In\nthe future, it would be interesting to compare the quality of\nsynthetic data generated from different LLMs, which we\nplan to explore further.\nExisting work (Gupta et al., 2023) have utilized common\nNLP benchmarks, such as SuperGLUE (Wang et al., 2019),\nas tasks for evaluation or employ a customized selection\n(Gao et al., 2023; Ye et al., 2022).\nWe select six common tasks for evaluation: SST-2 (Socher\net al., 2013; Wang et al., 2019), Twitter Emotion Classifica-\ntion (EMO) (Saravia et al., 2018), New York Times News\nClassification (NYT)(Stefano, 2021), Review (Amazon Re-\nview Classification) (Keung et al., 2020), RTE (Recognizing\nTextual Entailment) (Bentivogli et al., 2009; Wang et al.,\n2019) and BoolQ (Clark et al., 2019; Wang et al., 2019).\nThe goal is to select diverse tasks that represent a wide range\nof popular NLP corpora (Table 4). Additionally, we try to\ninclude challenging tasks for which current NLU models do"}, {"title": "5. Key Findings", "content": "In this section, we present the key findings from our experi-\nments.\n5.1. Mixing Raw Data is Necessary\nTo assess the effectiveness of data augmentation, we train\nmodels with pure synthetic data and augmented data. For the\naugmented setting, 100 raw data points are mixed with 1000\nsynthetic data. In the data generation stage, we use only the\nsame 100 raw data points used for in-context generation to\nprevent the model from accessing additional data. As shown\nin Figure 2, we observe significant improvements across\nall tasks for most prompting methods when incorporating\nraw data into training. Even as few as 100 data points can\nboost synthetic data performance compared to using only\nsynthetic data.\n5.2. Impact of Bias\nIn the BoolQ task, we found that the zero-shot generation\nmethod outperforms other methods, which contrasts with\nthe results obtained for the rest of the tasks. This finding is\nintriguing since zero-shot data exhibits the highest repetition\nrate, which is detrimental to model training. Upon further\nexamination, we noticed that only in the datasets generated\nusing one-shot or few-shot methods, terms like \"not,\" \"sig-\nnificant,\" \"only,\" \"just,\" \"few,\" and \"little\" frequently appear\nin the generated questions. These terms create a tone that\ncan be used to imply the answer to the question (which is\noften False). Table 5.2 provides an example of such trivial\nquestion. Table 3 provides statistics for such questions from\ndifferent prompting method.\nWe hypothesize that this pattern introduces bias in model"}, {"title": "5.3. Relationship between LLM Performance and Data Quality", "content": "While it may seem intuitive that the effectiveness of using\nLLMs to generate data for model training depends on the\nLLM's knowledge of a specific task, our research has shown\nthat this is not always the case. The zero-shot or few-shot\nperformance of an LLM on a task does not necessarily deter-\nmine the performance of a model (specifically, the ROBERTa\nmodel used in our experiment) trained with data generated\nby the LLM. In other words, the fact that an LLM performs\nwell on a task does not guarantee that models finetuned with\ndata generated by the LLM will also perform well. Addi-\ntionally, for tasks where the LLM performs poorly, models"}, {"title": "5.4. Synthetic Data is Helpful Mostly in Low-Resource Settings", "content": "Previous work has shown that it is challenging for models\ntrained with synthetic data to perform as well as models\ntrained with the same amount of original data (Li et al.,\n2023; Ding et al., 2023). However, when human-annotated\ndata is limited, synthetic data augmentation can improve\nmodel performance. In fact, this technique is most effective\nin low-resource settings. For all tasks with 100 raw data\npoints, we found that synthetic data augmentation yields\nimprovements of at least 3% to 26%. When the raw training\ndata increases to 1,000, only four tasks show improvements,"}, {"title": "5.5. A Comparison Between Different Prompting Methods", "content": "In the synthetic data only setting, one-shot or zero-shot topic\nmethods rank in the top two for all tasks except the Review\ntask (Figure 2).\nIn the augmented setting, few-shot generation and zero-shot\ntopic generation methods demonstrate good performance\nacross all tasks. In BoolQ, EMO, and RTE tasks, zero-shot\ntopic methods outperform other prompting methods. In SST-\n2 and NYT tasks, few-shot generation methods perform best.\nThe performance of zero-shot methods is sub-optimal across\nall tasks.\nIn the five prompting methods we experimented with, zero-"}, {"title": "5.6. Synthetic Data Diversity and Similarity to Raw Data", "content": "In this section, we examine the diversity of our training data\nusing inter-sample semantic similarity. To calculate this sim-\nilarity, we use vector embedding proposed in (Reimers &\nGurevych, 2019) and average the similarity score across all\nexamples pairs following (Yu et al., 2023). Figure 4 displays\nthe inter-sample similarity for each task, comparing data\ngenerated by five prompting methods. On the x-axis, we\nshow the performance of the finetuned model using the 1000\nsynthetic data only. Figure 4 shows that for BoolQ, NYT,\nand SST-2, a lower inter-sample diversity results in a better\nF1 score. However, for other tasks, the correlation is weak\ndue to the existence of outliers, especially for RTE, and the\npossible impact of other factors, such as task complexity.\nWe also calculated the similarity between the synthetic data\nand the actual raw data using the same method and found\nthat the synthetic data generated from five different prompt-\ning methods had similar similarity scores with the raw data.\nHowever, it is not clear whether synthetic data that closely\nresembles the raw data would lead to better model perfor-\nmance. This could be due to the limitations of our similarity\nmeasuring method, which only considers semantic similar-\nity, as discussed in (Steck et al., 2024). Many NLP tasks\nrely on subtle contextual cues and nuanced wordings, such\nas in the SST-2 task, where changes to wording can affect\nthe sentiment of the text more than contextual semantics."}, {"title": "5.7. Synthetic Data Quantity", "content": "We have found that increasing the amount of synthetic data\nin our model training improves its performance. Figure 5\nshows the relationship between the model's performance\n(measured by the f1 score) on the y-axis and the total number\nof training data on the x-axis. In the augmented scenario, we\nmixed 100 raw data points with varying amounts of synthetic\ndata. The performance is the average of the model's f1\nscore over 5 prompting methods for each data size. For\nthe raw data scenario, only real-world data was used in\nmodel training. Our graph indicates that raw data serves\nas an upper bound for the augmented setting in almost all\ntasks. Moreover, we observed that the marginal effect of\nperformance gain with increasing training data is present in\nboth raw and synthetic data. For BoolQ and SST-2 tasks, we\nobserved this phenomenon at the same data size. As such,\nthe raw data size at which marginal improvement of model\nperformance appears can be used as a reference point when\nincreasing the number of synthetic data."}, {"title": "6. Data Generation Techniques in Practice", "content": "In the process of using LLM to generate data for this study,\nwe identified several useful techniques. These practices lack\ntheoretical support and the effectiveness of these techniques\ncan be subject to the choice of large language models or the\nrequirements of a specific task.\n6.1. Condition on Label\nThere are two typical ways to generate a classification\ndataset: Condition on the Label and Left-to-Right (see Table\n6). It is recommended to use Condition on the Label for\neach generation as it saves effort in parsing the label and\navoids LLM generating unknown labels. It also provides\nthe user control over the label distribution in the synthetic\ndataset.\nIt is worth noting that class-conditioned generations are\nmore likely to introduce bias and reduce the difficulty of the\nsynthetic example. When the class label is visible, LLM\ncould leak the label information during content generation.\nIn the BoolQ example, LLM hints the answer \"FALSE\" via"}, {"title": "6.2. Generation on Target Corpus", "content": "It is essential to provide topics or descriptions closely re-\nlated to the use case when generating examples. Ensuring\nthat the topics are relevant to the use case significantly im-\nproves the quality of generated data. For example, when\ncreating examples from Twitter, it is beneficial to first gen-\nerate common topics found on Twitter. On the other hand,\nwhen generating Amazon customer reviews, it is effective\nto generate an Amazon product catalog as a list of poten-\ntial topics. This approach ensures that the synthetic data\nis more closely aligned with the target corpus, leading to\nbetter performance in classification tasks."}, {"title": "6.3. Iterative Data Generation and Prompt Refinement", "content": "Generating synthetic data can be both time-consuming and\nresource-intensive. To maximize efficiency and ensure high-\nquality data, it is recommended to adopt an iterative ap-\nproach. Initially, generate a small number of examples and\nevaluate their quality. If the quality of these initial data\npoints is low, refine the prompt before generating more data.\nIt is unlikely that simply generating more data points with\nthe same prompt will magically produce high quality data."}, {"title": "7. Conclusion", "content": "In this work, we analyzed different factors that influences\nthe data generation using LLMs. We found data generation\nis most effective in low resourced settings. Increasing the\namount of synthetic data does not necessarily lead to contin-\nuous improvements in model performance. It is beneficial\nto combine synthetic data with raw data during training. Ad-\nditionally, it is crucial to be vigilant for patterns or biases in\nsynthetic data that may hinder model training. Overall, us-\ning LLM for data augmentation has great potential in model\ntraining. With a carefully tuned prompt, the data generated\nby LLM is able to obtain comparable performance with\nhuman annotated data, but at a much lower cost.\nThe domain of data generation for classification tasks is\nhighly complex. Due to the diversity of NLP tasks, it is\nchallenging to find rules that generalize well across all tasks.\nHowever, our findings could still serve as valuable resources\nfor researchers and practitioners looking to use synthetic\ndata for training classification models. For future work, it\nwould be valuable to study the effects of more advanced\nprompting methods, such as the Chain of Thought (Wei\net al., 2023), or LLM hyperparameters, such as temperature,\non the quality of synthetic data."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field\nof Machine Learning. There are many potential societal\nconsequences of our work, none which we feel must be\nspecifically highlighted here."}, {"title": "A. Appendix", "content": "Prompt for topic generation for zero-shot with topics and LLM output examples. GPT-4 is used to generate 500 random\ntopics per task:\nTask\nRole\nMessage\nBoolQ, RET, NYT, SST-2, Emo System You are an AI assistant that generates random topics. There is no limit\non the number of topics you can generate.\nBoolQ, RET, NYT\nUser\nPlease generate 500 topics\nBoolQ, RET, NYT\nLLM\nOutput example: The world's most beautiful sculptures, The role of\ntechnology in modern education\nSST-2, Emo\nUser\nPlease generate 500 twitter post topics\nSST-2, Emo\nLLM\nOutput example: Lunch break, Online dating\nReview\nSystem You are an AI assistant that knows Amazon product categories. The user\nwill ask you to generate a list of categories. It is your responsibility to\ngenerate the entire list of categories.\nReview\nUser\nPlease generate 500 amazon different product categories\nReview\nLLM\nOutput example: Baby Products, Clothing, Jewelry\nB. Appendix\nPrompt for Question Rephrasing in Section 5.2\nPlease rephrase the question as if you are typing it in a search engine. Make sure the answer can only be true or false, Input: question\nOutput:"}, {"title": "C. Appendix", "content": "Prompt used for data generation for each task:\nTask\nPrompt Type Prompt\nzero-shot\nStep 1 Please generate a random short passage. Passage:\nStep 2 Please generate a True or False question based on the passage.\nThe answer to the question must be [random([True, False])] Passage:\n[passage from step 1] Question:\nBoolQ zero-shot topic\nStep 1 Please generate a short passage about this topic: [topic sampled\nfrom a topic list] Passage:\nStep 2 Please generate a True or False question based on the passage.\nThe answer to the question must be [random([True, False])] Passage:\n[passage from step 1] Question:\nBoolQ\none-shot\nStep 1 Please generate a Passage, a Question and the Label to the\nquestion following this example: [example from raw data: Passage,\nQuestion, Label] Please generate a similar passage. Passage:\nStep 2 Please generate a True or False question based on the passage.\nThe answer to the question must be [label from example in Step 1]\nPassage: [passage generated in Step 1] Question:\nBoolQ few-shot (3 or 5)\nStep 1 Please generate a Passage, a Question and the Label to the\nquestion. Here are some examples: [examples from raw data: Passage,\nQuestion, Label] Please generate a similar example. Make sure the\nquestion is a True or False question and the answer to the question is\n[random([True, False])]. Passage:\nEMO\nzero-shot\nStep 1 Please generate a twitter post with the emotion of [ran-\ndom(label)]. Text:\nEMO\nzero-shot topic\nStep 1 Please consider this topic for generation: [topic sampled from\na topic list]. Please generate a twitter post with the emotion of [ran-\ndom(label)]. Text:\nEMO\none-shot\nStep 1 The task is to predict the emotion of a twitter post. The emotion\ncontains six categories: sadness, joy, love, anger, fear, surprise. Here is\nan example. Text: [example from raw data] Emotion: [example label\nfrom raw data] Please generate another example for the same emotion.\nText:\nEMO few-shot (3 or 5)\nStep 1 The task is to predict the emotion of a twitter post. The emotion\ncontains six categories: sadness, joy, love, anger, fear, surprise. Here\nare some examples: [examples: Text, Emotion] Please generate a twitter\npost with the emotion of [first label from examples]. Text:\nTask\nPrompt Type\nPrompt\nStep 1 Please generate a news title for [random(label)] category. Head-\nStep 1 Please consider this sentence for generation: [topic sampled\nfrom topic list]. Please generate a news headline for [random(label)]\nNYT\nzero-shot\nline:\nNYT zero-shot topic\ncategory. Headline:\nStep 1 The task is to predict the topic of a news headline. The topics\ncontain 'sports', 'arts, culture and entertainment', 'business and finance',\n'health and wellness', 'lifestyle and fashion', 'science and technology',\n'politics', 'crime'. Here is an example News: [example news] Topic:\n[example topic] Please generate another news on [example topic]. Head-\nline:\nNYT\none-shot\nStep 1 The task is to predict the topic of a news headline. The topics\ncontain 'sports', 'arts, culture and entertainment', 'business and finance',\n'health and wellness', 'lifestyle and fashion', 'science and technology',\n'politics', 'crime'. Here are some examples: [examples: Headline, Topic]\nPlease generate a news headline for [first topic from examples] category.\nNYT few-shot (3 or 5)\nNews:\nzero-shot\nStep 1 The Amazon customer review has a rating ranges from 1 to 5,\n1 being the lowest and 5 being the highest. Please generate a customer\nreview with a rating of [random(label)]. Content:\nReview\nzero-shot topic\nStep 1 The Amazon customer review has a rating ranges from 1 to 5,\n1 being the lowest and 5 being the highest. Please generate a customer\nreview with a rating of [random(label)] for a specific product under [a\nproduct category sampled from topic list]. Please use a fake product\nname. Content:\nReview\none-shot\nStep 1 The task is to predict the rating of an Amazon customer review\nbased on the content. The rating ranges from 1 to 5, 1 being the lowest\nand 5 being the highest. Here is a review example. Content: [example\ncontent] Rating: [example rating] Please generate another example for a\nsimilar product. Make sure the rating for the review is [example rating].\nReview\nContent:\nReview few-shot (3 or 5)\nStep 1 The Amazon customer review has a rating ranges from 1 to\n5, 1 being the lowest and 5 being the highest. Here are some examples\nContent: [examples: Content, Rating] Please generate a customer review\nwith a rating [first rating from examples]. Content:\nStep 1 Given a premise and a hypothesis, a model needs to predict\nwhether the hypothesis can be logically inferred from the premise. The\nresponse should be either True if the hypothesis can be inferred from\nthe premise, or False if it cannot be inferred. Here is the output format:\nPremise: Hypothesis: Label: True or False Please generate an example\nwhere the Label is [random(label)]. Premise:\nRTE\nzero-shot\nStep 1 Given a premise and a hypothesis, a model needs to predict\nwhether the hypothesis can be logically inferred from the premise. The\nresponse should be either True if the hypothesis can be inferred from\nthe premise, or False if it cannot be inferred. Here is the output format:\nPremise: Hypothesis: Label: True or False Please generate an example\nabout [premise] where the Label is [random(label)]. Premise:\nRTE zero-shot topic\nStep 1 Given a premise and a hypothesis, a model needs to predict\nwhether the hypothesis can be logically inferred from the premise. The\nresponse should be either True if the hypothesis can be inferred from\nthe premise, or False if it cannot be inferred. Here is an example:\nPremise: [example premise] Hypothesis: [example hypothesis] Label:\n[example label] Please generate another similar example where the Label\nis [example label]. Premise:\nRTE\none-shot\nRTE few-shot (3 or 5)\nStep 1 Given a premise and a hypothesis, a model needs to predict\nwhether the hypothesis can be logically inferred from the premise. The\nresponse should be either True if the hypothesis can be inferred from the\npremise, or False if it cannot be inferred. Here are some examples: [ex-\namples: Premise, Hypothesis, Label] Please generate a similar example.\nMake sure the label is [first label from examples]. Premise:\nzero-shot\nStep 1 Please generate a sentence that contains a [random(label)]\nsentiment. Sentence:\nSST-2\nzero-shot topic\nStep 1 Please consider this topic for generation: [topic from the topic\nlist]. Please generate a sentence that contains a [random(label)] senti-\nment. Sentence:\nSST-2\nStep 1 The task is to predict whether the following sentence is positive\nor negative sentiment. Sentence: [example sentence] Label:[example\nlabel] Please generate a similar example on the same topic, including a\nSentence and a Label. Sentence:\nSST-2\none-shot\nSST-2 few-shot (3 or 5)\nStep 1 The task is to predict whether the following sentence is positive\nor negative sentiment. [examples: Sentence, Label] Please generate a\nsimilar example, including a Sentence and a Label. Sentence:"}, {"title": "D. Appendix", "content": "Prompt used to evaluate LLM performance on each task:\nTask\nRTE\nPrompt Type Prompt\nzero-shot\nStep 1 Given a premise and a hypothesis, a model needs to predict\nwhether the hypothesis can be logically inferred from the premise. The\nresponse should be either True if the hypothesis can be inferred from the\npremise, or False if it cannot be inferred. Premise: [premise], Hypothesis:\n[hypothesis], Label:\nRTE\n0/1/3/5-shot\nStep 1 Given a premise and a hypothesis, a model needs to predict\nwhether the hypothesis can be logically inferred from the premise. The\nresponse should be either True if the hypothesis can be inferred from\nthe premise, or False if it cannot be inferred. Here are some examples:\n[example premise, hypothesis, label] Premise: [premise], Hypothesis:\n[hypothesis], Label:\nStep 1 The task is to answer a question which is solely based on the\ncontent provided. Passage: [passage], Question: [question], Label:\nBoolQ\nzero-shot\nBoolQ\n0/1/3/5-shot\nStep 1 The task is to answer a question which is solely based on the\ncontent provided. Here are some examples: [example passage, question,\nlabel] Passage: [passage], Question: [question], Label:\nReview zero-shot\nStep 1 The task is to predict the rating of an Amazon customer review\nbased on the content. The rating ranges from 1 to 5, with 1 being the\nlowest and 5 being the highest. Text: [text], Label:\nReview 0/1/3/5-shot\nStep 1 The task is to predict the rating of an Amazon customer review\nbased on the content. The rating ranges from 1 to 5, with 1 being the\nlowest and 5 being the highest. Here are some examples: [example text,\nlabel] Text: [text], Label:\nStep 1 The task is to predict the topic of a news headline. The topics\ninclude: 'sports', 'arts, culture and entertainment', 'business and finance',\n'health and wellness', 'lifestyle and fashion', 'science and technology',\n'politics', 'crime'. Text:[text], Label:\nNYT zero-shot\nStep 1 The task is to predict the topic of a news headline. The topics\ninclude: 'sports', 'arts, culture and entertainment', 'business and finance',\n'health and wellness', 'lifestyle and fashion', 'science and technology',\n'politics', 'crime'. Here are some examples: [example text, label] Text:\n[text], Label:\nNYT\n0/1/3/5-shot\nEMO\nzero-shot\nStep 1 The task is to predict the emotion of a Twitter text. The emotions\ninclude six categories: sadness, joy, love, anger, fear, surprise. Text:\n[text], Label:\nEMO\n0/1/3/5-shot\nStep 1 The task is to predict the emotion of a Twitter text. The emotions\ninclude six categories: sadness, joy, love, anger, fear, surprise. Here are\nsome examples: [example text, label] Text: [text], Label:\nStep 1 The task is to predict whether the given sentence has a positive\nor negative sentiment. Sentence: [sentence], Label:\nSST-2 zero-shot\nSST-2\n0/1/3/5-shot\nStep 1 The task is to predict whether the given sentence has a positive\nor negative sentiment. Here are some examples: [example sentence,\nlabel], Sentence: [sentence], Label:"}]}