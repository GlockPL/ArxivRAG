{"title": "LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations", "authors": ["Hasan Abu-Rasheed", "Constance Jumbo", "Rashed Al Amin", "Christian Weber", "Veit Wiese", "Roman Obermaisser", "Madjid Fathi"], "abstract": "While learning personalization offers great potential for learners, modern practices in higher education require a deeper consideration of domain models and learning contexts, to develop effective personalization algorithms. This paper introduces an innovative approach to higher education curriculum modelling that utilizes large language models (LLMs) for knowledge graph (KG) completion, with the goal of creating personalized learning-path recommendations. Our research focuses on modelling university subjects and linking their topics to corresponding domain models, enabling the integration of learning modules from different faculties and institutions in the student's learning path. Central to our approach is a collaborative process, where LLMs assist human experts in extracting high-quality, fine-grained topics from lecture materials. We develop a domain, curriculum, and user models for university modules and stakeholders. We implement this model to create the KG from two study modules: Embedded Systems and Development of Embedded Systems Using FPGA. The resulting KG structures the curriculum and links it to the domain models. We evaluate our approach through qualitative expert feedback and quantitative graph quality metrics. Domain experts validated the relevance and accuracy of the model, while the graph quality metrics measured the structural properties of our KG. Our results show that the LLM-assisted graph completion approach enhances the ability to connect related courses across disciplines to personalize the learning experience. Expert feedback also showed high acceptance of the proposed collaborative approach for concept extraction and classification.", "sections": [{"title": "1. Introduction", "content": "Higher education is a structured learning setting, where curriculums are designed to meet predefined learning goals for each study program. This leaves a small margin to meet the individual goals of different students in the same program, especially in programs where students have different study backgrounds, or come from various countries, such as international study programs. In these scenarios, the likelihood of a student repeating a course or a topic they already studied before becomes higher. In order to increase the efficiency of the full learning path that a student takes within their study, it is essential to consider their level of knowledge, the courses and modules they already studied, as well as their career and professional goals, to tailor their learning path to those individual needs, goals, and requirements.\nHowever, the learning setting in higher education poses several challenges to accomplishing this personalization. On the one hand, teachers are occupied with many tasks [1] and lack sufficient time to analyze the background knowledge of individual students, as well as to analyze the content of other courses in the university, which might be used to construct a personalized learning path. On the other hand, there is a lack of standard representation of the courses and study modules in different study"}, {"title": "2. Background", "content": "The recent developments of LLMs opened several doors to support teachers and experts in a faster extraction and analysis of the wide range of educational content, whether online or within universities and higher education institutions. In the following, we highlight some of the systems and approaches that have similar goals to our research."}, {"title": "2.1. LLMs Support in Creating KGs", "content": "LLMs are powerful tools for generating and enhancing KGs [2]. They are designed to understand and generate natural language and are capable of a wide range of natural language processing tasks [3]. In the context of KGs, LLMs enhance KG embedding, completion, and construction, as well as supporting text generation and question-answering tasks [4]. KGs are valuable means for representing the interconnected nature of information, especially in educational settings[5]. They serve as a solid data structure for organizing and storing knowledge [6]. Kommineni's study shows that integrating LLMs into KG creation can enhance entity recognition and relationship extraction streamlining KG creation[7]. This is an essential tool in higher education where vast information must be organized cohesively."}, {"title": "2.2. LLM-Enhanced KG Creation for Higher Education", "content": "Enhancing KG creation using LLMs in higher education introduces a robust method for modelling course content and structure [8]. The traditional process of constructing KGs is largely dependent on human experts and this has proven to be more complex when constructing large-scale and high-quality KGs in domains that evolve constantly [1]. Jhajj [8] investigated the use of LLM in creating and enhancing educational knowledge graphs by analyzing three KGs. The human evaluators rated the graph created from LLM and contextual data (course syllabus) higher regarding its relevance and educational value. Together with course-specific information, LLM can extract information and generate nodes that have high semantic similarity with course materials enabling a more efficient semi-automated KG creation process in higher education. The fusion of KG and LLMs is synergistic, particularly in higher education.\nKGs can be used as factual context sources for LLM prompts to enhance learning recommendations [9]. Evaluating the approach both qualitatively and quantitatively, results showed improvement in"}, {"title": "2.3. A Comprehensive Ontology for Higher Education", "content": "Ontologies are formal representations of data, which in our use case provide a holistic view of higher education requirements, incorporating curriculum, user, and domain models. Recently, ontologies have been commonly used in higher education [10]. However, traditional ontologies focus on user and educational models [11], which represent the subject matter within the educational environment. This underscores the need for providing a detailed and comprehensive representation of relevant knowledge and concepts in real-world domains. Including a domain model provides contextual depth, which is important for recommending courses that align with user backgrounds, goals, and career orientations.\nLLM-support for curriculum and domain modelling offers a solid foundation for personalized learning recommendations in higher education."}, {"title": "3. Methodology", "content": "To accomplish creating a graph data structure for modelling content in higher education and supporting teachers to represent their existing materials in this model, we propose a four-step implementation strategy: Graph ontology definition, automated topic extraction, human-AI collaboration for validation task, and KG construction."}, {"title": "3.1. Defining a Higher Education Ontology", "content": "To develop a graph structure that accommodates learning content from different study programs and universities, we developed the content representation models as interoperable ones. This meant selecting ontological classes that apply to a wider range of course structures, enabling teachers to adapt their learning content to that model easily. To that end, we select the class \u201cTopic\u201d as the core taxonomical element that is used to break down the content of each session within the study module. As topics in the learning content differ in their level of detail, we add a \u201cSub-Topic\u201d class to account for more granularity in the educational content. In this sense, a Topic is defined as an abstract concept, which is being taught in the learning session, while a Sub-Topic is defined as the fine-grained content, which is described through a tangible means, such as lecture slides. A Session is then the iterative instance of a Lecture, which takes place, e.g., on a weekly basis. The proposed ontology is composed of three models:\n1. The curriculum model: which includes the classes representing educational content as defined by the university.\n2. The domain model: which is used to model a higher abstraction level of the domain of knowledge. The domain model includes domains to which the learning content belongs, such as Automotive, Embedded Systems, or Communication domains. In each domain, more granular concepts are represented as Sub-Domains, such as Self-Driving Cars being a sub-domain of the Automotive domain.\n3. The user model: which is meant to represent the stakeholders in the educational setting, focusing on students and the factors that can be used for learning personalization. These include the background knowledge, learning goals, preferences, as well as academic parameters, as adopted from [12], which represent all other academic aspects related to the student's learning process, such as their exam performance."}, {"title": "3.2. Automatic Content Extraction and Classification", "content": "In order for teachers to classify the content of their lectures into topics and sub-topics, a great amount of time and effort needs to be invested, which is rarely available for teachers due to their busy schedules. Therefore, we developed an automated extraction and classification pipeline, to support teachers with this task and considerably reduce the time and effort requirements on their side.\nThe pipeline, see Figure 2, begins with the extraction of textual content from the learning materials, including lecture slides, manuscripts, and lecture video recordings. While the extraction of the textual data from lecture slides and manuscripts is relatively straightforward, the extraction of the text from lecture videos requires transcribing these videos. Here, we assume that the figures, images, and equations in the slides are annotated or described textually. We conduct this transcription automatically utilizing the advanced capabilities of OpenAI's Whisper model [13], which is a speech recognition model with high accuracy in zero-shot recognition tasks. Video transcripts are then fed, alongside the other textual content materials to an LLM for the topic extraction and classification tasks.\nIn the topic extraction step, we utilize OpenAI's GPT-40 model. The LLM is prompted to extract the main concepts that each session includes. A concept represents here a key topic that is being taught in the session. Extracted concepts are then classified into topics and sub-topics based on the definitions of these two classes in our ontology. A topic is defined in the LLM prompt as an abstract concept, which is taught within the session. A sub-topic is defined as the concept that is being explained, in detail, through learning materials (e.g. lecture slides). The LLM is also instructed to consider the hierarchical structure of the two classes, where each topic includes one or more sub-topics. A topic is then an overarching concept, whose sub-topics are the actual content of the lecture. It is important to point out"}, {"title": "3.3. Human Validation of the Automated Extraction", "content": "The risks of LLMs in automatic extraction, classification, and generation tasks, are high in a sensitive field like education. Therefore, we ensure the high-quality of topic extraction and classification through a human-in-the-loop approach, in which teachers validate the predictions of the intelligent algorithm, and make the final decision on extracted concepts and their classification as topics or sub-topics. The preliminary extraction and classification by the LLM serves here as an advanced starting point for the teachers and human evaluators, which saves them a considerable amount of time when analyzing the educational content. This also applies to the automated descriptions of topics and sub-topics, since the phrasing of the description is based on the session content itself and not the general knowledge of the model, i.e., in its training data. The final decision on the topics, sub-topics, and their descriptions is made by the teachers themselves, to ensure a high-quality content curation of the KG, which is necessary to enable generating high-quality learning-path recommendations for the students. The role of the"}, {"title": "3.4. Knowledge Graph Construction", "content": "Based on the validated content from the teachers, the KG construction process is then conducted through two steps:\n1. Creating graph nodes: according to the base ontology, and populating them with the data from the learning content, domain, and users.\n2. Creating graph relations: which is conducted on two levels: the hierarchical structure from the base ontology, and the semantic similarity between the topics and sub-topics of different lectures.\nTo calculate the semantic similarities, we first build on the natural language processing pipeline in [5], where the title and description properties of the learning content are utilized to find similar content. This approach fits our extraction process of the topics, sub-topics, and their descriptions. Secondly, we utilize the LLM itself to analyze the extracted content and search for similar content from other lectures. We use a semi-supervised approach for the validation of semantic similarities, where the human teacher validates a random sample of the predicted relations in the KG. This approach is adopted due to the large amount of semantic relations that can be identified when the KG grows to include large-scale educational content. Through teacher validation, hints are collected to adjust the parameters and prompts of the relation extraction pipeline and the LLM, respectively, sustaining the collaborative approach in our overall solution.\nOnce the KG is constructed, it also becomes a source of data that is fed to the LLM, to provide contextual information for the extraction and classification tasks. We found this method particularly effective when the topic extraction and classification are done to a lecture that is contextually similar to the existing content of the KG, such as topics from the same domain, or the same field of application."}, {"title": "4. Evaluation and Results", "content": "To evaluate the proposed pipeline, we construct the knowledge graph from the content of two university modules, namely Embedded Systems and Development of Embedded Systems Using FPGA. The two courses are taught in the University of Siegen, Germany, for master- and bachelor-level students. These courses were chosen because they are taught separately, despite the potential overlap between them. Each course is composed of 9 sessions, spanning the lecture period of one academic semester. Each weekly session covers a diverse number of topics, which differ in their level of detail."}, {"title": "4.1. Expert Evaluation of the Ontology and Pipeline", "content": "We conduct the evaluation with module lecturers, to ensure high-quality feedback based on their experience with the module's content and learning goals. Evaluators included one professor and two PhD assistants, working in the Embedded Systems Institute in the same university. We collect qualitative feedback from the lecturers about the base ontology, and the overall acceptance of our approach for human-AI collaboration. Feedback is collected through group meetings with the lecturers, in which the ontology was presented and evaluated from the perspective of use cases they face in their teaching.\nMoreover, we collect quantitative input from the lecturers regarding the accuracy of extraction and classification of topics, sub-topics, and descriptions through the pipeline. To achieve this quantitative feedback, each lecturer checked a comprehensive list of extracted topics, their sub-topics, and the sub-topic descriptions, and evaluated the following for each sample:\n1. The correctness of extraction."}, {"title": "4.2. KG-Structural Evaluation", "content": "To evaluate the resulting knowledge graph structure, we use the graph quality measures: Average Degree Centrality (ADC), and Graph Modularity. These measures validate our research goal of discovering connections between learning contents from multiple modules. Average degree centrality evaluates the connectedness of a graph node through its incoming and outgoing relations. In our use case, ADC highlights the role that the semantic similarity algorithm plays in increasing the density of relations among graph nodes. Graph modularity, on the other hand, evaluates the potential to separate learning contents in the graph from each other. Therefore, a lower modularity score is preferred in our case, since it reflects stronger connections between similar contents.\nIn the resulting KG, we calculate an increase of the ADC value from 0.9 to 1.03, as well as a slight modularity decrease from 0.769 to 0.767. This slight change can be traced back to the small number of semantic relations added between the two modules, due to the relatively small size of the sample data. Moreover, this is also a result of the high similarity thresholds that we have set for"}, {"title": "5. Conclusion", "content": "In this paper, we proposed an approach for modelling higher education curriculums and linking them to domain and user models. We use an LLM-assisted pipeline to conduct a KG completion task, which is accomplished through a collaboration between the intelligent model and domain experts. Our goal was to enable a seamless integration of the existing learning content into the curriculum model, to support learning personalization based on the KG.\nWe implemented our pipeline on a sample of two university modules within embedded systems and FPGA courses. The proposed base ontology, pipeline, and the extraction and classification models were evaluated with the lecturers of the selected evaluation modules. Our evaluation results showed the effectiveness of the proposed approach for the collaboration between human experts and the AI system. It served as an assistant, providing the human expert with an advanced starting point for the structuring of the learning content, and for enabling better personalization of the learning experience, considering the similarities between module contents and their connection to the domain and user models."}]}