{"title": "GOT4Rec: Graph of Thoughts for Sequential Recommendation", "authors": ["Zewen Long", "Liang Wang", "Shu Wu", "Qiang Liu", "Liang Wang"], "abstract": "With the advancement of large language models (LLMs), researchers have explored various methods to optimally leverage their comprehension and generation capabilities in sequential recommendation scenarios. However, several challenges persist in this endeavor. Firstly, most existing approaches rely on the input-output prompting paradigm, which can result in irrelevant or inaccurate responses. Secondly, while there have been attempts to enhance LLMs using prompting strategies such as chain-of-thought (CoT), these efforts have not fully harnessed the reasoning abilities of LLMs or effectively captured the multifaceted information contained within user sequences. To address these limitations, we propose GOT4Rec, a sequential recommendation method that utilizes the graph of thoughts (GoT) prompting strategy. Specifically, we identify and utilize three key types of information within user history sequences: short-term interests, long-term interests and collaborative information from other users. Our approach enables LLMs to independently reason and generate recommendations based on these distinct types of information, subsequently aggregating the results within the GoT framework to derive the final recommended items. This method allows LLMs, with enhanced reasoning capabilities, to more effectively consider the diverse information within user sequences, resulting in more accurate recommendations and more comprehensive explanations. Extensive experiments on real-world datasets demonstrate the effectiveness of GOT4Rec, indicating that it outperforms existing state-of-the-art baselines. Our code is available at https://anonymous.4open.science/r/GOT4Rec-ED99.", "sections": [{"title": "1 Introduction", "content": "Sequential recommendation has long been a significant research field, with numerous methods proposed to explore chronological dependencies within user sequences (Kang and McAuley 2018; Zhou et al. 2020). Despite considerable advancements, they remain constrained by the limited knowledge available from datasets. To overcome this, it is crucial to integrate real-world knowledge into sequential recommendation models, enabling them to more effectively comprehend and reason about preference patterns within user behavior sequences (Hou et al. 2022; Li et al. 2023a). Recently, large language models (LLMs) have garnered significant attention due to their impressive natural language comprehension and generation abilities. Consequently, numerous LLM-based sequential recommendation works (Xi et al. 2023; Sanner et al. 2023; Hou et al. 2024b) have emerged to exploit these capabilities, aiming to capture user interests from interaction sequences and leverage LLMs' extensive real-world knowledge for recommendations. However, many of these approaches rely solely on the input-output (IO) prompting paradigm, underutilizing LLMs' reasoning abilities. This limitation arises from a disconnect between the real-world knowledge embedded in LLMs and the specific needs of recommender systems, often resulting in task-irrelevant or inaccurate outcomes. To address this, several studies have incorporated advanced prompting strategies to enhance LLMs' performance in sequential recommendation. Among these is SLIM (Wang et al. 2024), a knowledge distillation module which employs chain-of-thought (CoT) (Wei et al. 2022) prompting to enable step-by-step reasoning in sequential recommendation, transferring knowledge from a teacher model to a student model. However, it treats the user sequence as a monolithic entity and only taps into the elementary reasoning abilities of LLMs, insufficient for adequately reasoning through the diverse preference information (e.g., long-term and short-term interests, spatio-temporal factors) within user sequences.\nOverall, there are two major challenges that limit the effectiveness of LLMs in the sequential recommendation scenario. The first challenge is the difficulty in explicitly capturing various user preference information by merely prompting the behavior sequence. Traditional neural sequential recommenders have been actively extracting and fusing different types of information as features to predict the next item in the sequence. In contrast, current LLM-based sequential recommenders often perform minimal processing of the sequence itself, simply placing the entire sequence directly into the prompt. This approach can easily mislead the model, leading to inaccurate recommendations. For instance, in Figure 1, the items predicted by SLIM consist solely of snack bars, while the ground truth is a fruit nut mix product. The second challenge arises from the complexity introduced by incorporating multiple types of information, which transforms sequential recommendation into a complex reasoning task involving multiple sub-problems, necessitating LLMs with enhanced reasoning capabilities. Existing researches have demonstrated that simple reasoning approaches, such"}, {"title": "2 Related Work", "content": "2.1 Traditional Neural Sequential Recommenders\nTraditional neural sequential recommendation systems aim to capture sequential dependencies in user behavior sequences to model dynamic user preferences, as seen in methods like GRU4Rec (Hidasi et al. 2016). As deep learning develops, techniques like self-attention and graph neural networks have become foundational in sequential recommenders (Kang and McAuley 2018; Zhou et al. 2020; Wu et al. 2019; Zhang et al. 2022, 2023). These methods however, predominantly rely on sequence modeling capabilities and often inadequately incorporate textual information. Recently, research on transferable item representations (Hou et al. 2022; Li et al. 2023a) has gained attention. Despite their promise, these approaches remain constrained by limited datasets and fail to fully leverage real-world knowledge.\n2.2 LLM-Based Sequential Recommenders\nWith the advent of LLMs, numerous research endeavors have explored leveraging their advanced language comprehension and generation abilities. LLMs can be integrated either as feature enhancers (Xi et al. 2023; Lin et al. 2024; Liu et al. 2024) or rankers/scorers (Dai et al. 2023; Harte et al. 2023; Li et al. 2023b; Sanner et al. 2023; Hou et al. 2024b). For example, ReLLa (Lin et al. 2024) employs semantic user behavior retrieval to improve data quality and introduces retrieval-enhanced instruction tuning to enhance few-shot recommendation. LLMRank (Hou et al. 2024b) formalizes the recommendation problem as a conditional ranking task and utilizes LLMs as zero-short rankers. Although these approaches are promising, existing research has not yet fully capitalized on the reasoning capabilities of LLMs.\n2.3 LLM Prompting Strategies\nNumerous prompting approaches have been proposed to exploit the reasoning capabilities of LLMs. Chain-of-thought (CoT) (Wei et al. 2022) introduces intermediate reasoning steps to enhance LLM performance, while Chain of Thought with Self-Consistency (CoT-SC) (Wang et al. 2023) refines this by generating multiple CoTs and selecting the best output. Tree of thoughts (ToT) (Yao et al. 2024) and graph of thoughts (GoT) (Besta et al. 2024) further extend these methods by modeling reasoning as a tree or graph, respectively, to better generate and aggregate different thoughts. In the recommendation domain, SLIM (Wang et al. 2024) utilizes a CoT-based knowledge distillation module to transfer the step-by-step reasoning capabilities from a teacher model to a student model. However, its reliance on basic"}, {"title": "3 The Proposed GOT4Rec Method", "content": "In this section, we introduce GOT4Rec, a sequential recommendation method that fully leverages the reasoning capabilities of LLMs to capture the diverse information within user sequences. In the context of sequential recommendation, given a user u's historical interaction sequence $S_u = {i_1, i_2, ..., i_{n-1}}$, the task is to predict the next item in that the user is most likely to interact with.\n3.1 Overview of Thought Graph\nWhen interacting with LLMs, we input messages (prompts) and LLMs respond with generated outputs (thoughts). Building on the GoT framework (Besta et al. 2024), we model our GOT4Rec method as a tuple $(G,T)$, where $G$ represents the reasoning process and $T$ denotes the thought transformations. Specifically, we model the reasoning process as a directed graph $G = (V, E)$, where $V$ is the set of vertices and $E \\subset V \\times V$ is the set of edges. Each vertex represents a thought, encapsulating a solution to the current recommendation step along with other relevant global information. A directed edge $(t_1, t_2)$ signifies a dependency between thoughts, indicating that thought $t_2$ is generated by LLMs based on $t_1$.\nIn our method, we employ the generation transformation $T_G$ and aggregation transformation $T_A$ from the GoT framework. The generation transformation generates one or more new thoughts based on an existing single thought $v$. In this operation, new vertices and edges are generated: $V_+ = {v_1^+, ..., v_k^+}$ and $E_+ = {(v, v_1^+), ..., (v, v_k^+)}$ , where $v_1^+, ..., v_k^+$ are the new thoughts generated by $v$. Analogous reasoning steps such as CoT can be incorporated into this process. The aggregation transformation, on the other hand, combines multiple thoughts into a new, consolidated thought, reinforcing their strengths while mitigating their weaknesses. In this operation, a new vertex $v^+$ is created: $V_+ = {v^+}$ and $E_+ = {(v_1, v^+), ..., (v_k, v^+)}$ , where $v_1, ..., v_k$ are the aggregated thoughts.\nFigure 2 provides an example of graph decomposition in our GOT4Rec method. In the recommendation pipeline, the current user's interaction sequence $S_u$ is utilized as input. We then generate three key aspects of user preference information: short-term preference, long-term preference and collaborative preference, with detailed definitions provided in the subsequent subsection. With these preference information, the LLMs are enabled to reason and generate a list of top-N items that best align with the user's current interests. Finally, these items are aggregated, and the LLMs vote to select the most probable items for recommendation.\n3.2 Short-Term Reasoning Process\nNumerous studies have emphasized the importance of understanding both a user's dynamic short-term and stable long-term preferences in recommendation systems (Yu et al. 2019; Zheng et al. 2022). In our GOT4Rec method, we enable LLMs to extract these two types of preferences separately and then synergize the most relevant aspects of each. To reason about short-term preferences, we select the last few interactions from the user sequence $S_u$ as $S_{short}$. We then apply and enhance the zero-shot CoT prompting strategy from (Wang et al. 2024) within the generation transformation $T_G$ to effectively capture the user's short-term preferences and identify three categories that the user is likely to favor. As illustrated in Figure 3 as summarizing prompt, the generation transformation $T_G$ involves two key steps:\n*   Step 1. Summarize user's short-term preferences based on the given $S_{short}$.\n*   Step 2. Based on the preferences in step 1, summarize three categories of products the user is inclined to prefer.\nFor each identified category, we prompt the LLMs to generate $N$ items the user is most likely interested in, repeating this process three times. The prompt template is provided in Figure 3 as recommendation prompt. After generating the item sets, we utilize the aggregation transformation $T_A$, where the three item sets undergo a voting process by the LLMs. This results in a new set of $N$ items that are most likely to interest the user within each category. After aggregation, we have three final item sets, which are subjected to a final round of voting by the LLMs to determine the top-N items $I_{short}$ that best represent the user's short-term preferences. The voting prompt is also provided in Figure 3.\n3.3 Long-Term Reasoning Process\nTo capture long-term preferences, we extend the input to include the entire user interaction sequence. Similar to the short-term reasoning process, we employ the zero-short CoT prompting strategy within the generation transformation $T_G$, as shown in Figure 3. This allows LLMs to effectively differentiate and identify short-term and long-term preferences. After generating the relevant items, the final set of top-N items $I_{long}$, representing the user's long-term preferences, is determined through the aggregation transformation $T_A$.\n3.4 Collaborative Reasoning Process\nCollaborative filtering is widely used in various recommendation scenarios (Koren, Rendle, and Bell 2021), modeling users' preference based on their past interactions. In our method, we leverage the all-mpnet-base-v2 (Reimers and Gurevych 2020), a sentence-transformers model that maps sentences to a vector space, to generate an embedding vector for the current user's interaction sequence, allowing us to retrieve a set of sequences $S_{co}$ from other users most similar to the current user's sequence. Details of this retrieval process are provided in the following section.\nOnce we have obtained the similar user sequences $S_{co}$, we employ the zero-short CoT prompting strategy to generate three sets of top-N items that the current user may be interested in. The two-step generation prompts, illustrated in Figure 3 as collaboration prompt, are as follows:\n*   Step 1. Summarize the shared preferences between the current user and other users based on the given $S_{co}$.\n*   Step 2. Based on the summarized preferences from Step 1, recommend N items selected from $S_{co}$ that the current user is likely to prefer."}, {"title": "3.5 Multi-Level Retrieval Module", "content": "To identify other users' sequences that share same interests with the current user and to assess how closely the recommended items match the ground truth in sampled datasets, we employ a two-level retrieval approach.\nSequence-level retrieval. As previously mentioned, when analyzing collaborative preferences, it is essential to retrieve sequences of other users who share similar interests with the current user. We choose to deploy the all-mpnet-base-v2 model $f_{mpnet}$ due to its superior efficiency and discriminative power in encoding item titles compared to other encoding models such as BERT. Given a query sequence $S_u = {i_1, ..., i_k}$, the ranked indices of the retrieved sequences $I_{seq}$ can be obtained as follows:\n$I_{seq} = \\frac{1}{k}\\sum_{t=1}^{k} sim( f_{mpnet}(i_t), V_{seq})$ (1)\nwhere $sim(\u00b7, \u00b7)$ denotes the computation of Euclidean distance, $V_{seq}$ represents the vector base containing the embeddings of all other sequences.\nItem-level retrieval. The title of an item generated by LLMs may differ from the title of the ground truth in datasets, even though they refer to the same item. This discrepancy arises due to the limited and varied versions of items in the datasets (e.g., Witcher 3: Wild Hunt versus Witcher 3: Wild Hunt Complete Edition). To address this issue, we continue to utilize the $f_{mpnet}$ model to encode item titles into vectors. We then retrieve the most similar items from the vector base by computing the inner product of the query vector and all other vectors in the base. Specifically, for an item $i_{query}$ generated by LLMs, the retrieval process is as follows:\n$I_{item} = sim(f_{mpnet}(i_{query}), V_{item})$ (2)\nwhere $I_{item}$ represents the ranked indices of the retrieved items, $sim(\u00b7, \u00b7)$ denotes the computation of the inner product and $V_{item}$ is the vector base containing all item embeddings. In practice, we observed that in most cases, when the description of the query item is vague, the retrieved items are misaligned (e.g., when querying for The Witcher 3, the top results include [Diablo III, The Witch and the Hundred"}, {"title": "4 Experiments", "content": "4.1 Experimental Settings\nDatasets. We conduct experiments on three item categories from the widely used Amazon Reviews'23 dataset (Hou et al. 2024a): Video Games (Games), Grocery and Gourmet Food (Food) and Home and Kitchen (Home). Reviews are treated as user-item interactions, sequenced chronologically by timestamp. To address the significant time cost of LLMs, we focus on users with 6 to 20 interactions and filter out items with fewer than five interactions. Following (Wang et al. 2024), we randomly sample 3,000 users from each dataset three times. We employ the leave-one-out strategy for dataset division: the most recent interaction for testing, the second most recent interaction for validation and the remaining interactions are used for training. Both training and validation segments are used as input during testing.\nBaselines. To demonstrate the effectiveness of our proposed method, we select two groups of recommendation baselines. The first group comprises traditional neural sequential recommendation models:\n*   GRU4Rec (Hidasi et al. 2016): Uses RNNs to model user sequences for session-based recommendation.\n*   SRGNN (Wu et al. 2019): A graph-based model for session-based recommendation to capture the transition information between items in user sequences.\n*   SASRec (Kang and McAuley 2018): A self-attention based sequential model to capture user's preferences.\nThe second group contains models that utilize LLM prompting strategies:\n*   Chain-of-Thought (CoT) (Wei et al. 2022): A prompting approach for prompting which includes the intermediate steps of reasoning within the prompt.\n*   Multiple CoTs (CoT-SC) (Wang et al. 2023): A scheme in which multiple CoTs are generated, with the best one being selected as final result.\n*   Tree of Thoughts (ToT) (Yao et al. 2024): A prompting approach modeling the LLM reasoning process as a tree.\n*   SLIM (Wang et al. 2024): A knowledge distillation module, which transfers the step-by-step reasoning capabilities in recommendation from a larger teacher model to a smaller student model.\nImplementation Details. We choose Llama3-8B-Instruct (AI@Meta 2024) as the backbone model with a maximum"}, {"title": "4.2 Overall Performance", "content": "Table 1 compares our GOT4Rec method with various neural sequential models and LLM prompting strategies, leading to several key observations: (1) Traditional neural sequential models perform relatively modest, though SASRec still outperforms LLM prompting strategies in some cases, particularly due to its use of self-attention mechanisms which allow SASRec to effectively model users' historical behaviors by capturing the transition relationships between items. However, SASRec lacks the ability to comprehend semantic information, limiting its overall performance. (2) Among LLM-based methods, CoT-SC consistently achieves runner-up performance across most datasets, largely because it aggregates and selects the best result from multiple CoT paths, providing a more refined output. On the other hand, CoT, ToT, and SLIM show comparatively lower performance. SLIM, in particular, may suffer from reduced output diversity due to fine-tuning, while ToT's structural and reasoning path designs appear to be less suitable for sequential recommendation tasks. (3) GOT4Rec achieves the state-of-art (SOTA) performances across all datasets. Notably, in the Food dataset, GOT4Rec achieves a relative improvement of 73.93% over CoT-SC in terms of NDCG@10 and 67.49% in terms of HR@5. These significant gains can be attributed to the nature of food product consumption, where users prefer consistent categories or brands and are strongly influenced by short-term needs. This aligns well with the strengths of GOT4Rec, which excels at capturing users' preferences for certain categories or brands and effectively integrating short-term preference information. This capability allows GOT4Rec to deliver highly relevant recommendations that closely match users' current interests. These findings demonstrate the effectiveness of GOT4Rec in optimizing recommendation tasks by fully exploiting the advanced reasoning capabilities of LLMs and integrating various aspects of user information."}, {"title": "4.3 Ablation Study", "content": "We conducted an ablation study to analyze the impact of different components in the GOT4Rec model, with the results in Table 2. Our GOT4Rec consistently outperforms the ablated variants, demonstrating that the full integration of users' preference information from the short-term, long-term, and collaborative components results in superior recommendation performance. The study also reveals that the importance of each component varies across different datasets, likely reflecting the unique characteristics of each dataset. For instance, collaborative information appears to"}, {"title": "4.4 Popularity Bias Analysis", "content": "In Figure 4, we sort the items in Games dataset based on their frequency in the training set (i.e., popularity) and draw lines to illustrate each item's frequency in the results of CoT and GOT4Rec. The figures for other two datasets are presented in the Appendix. It is apparent that GOT4Rec more effectively recommends tail items and a broader variety of items. Table 3 reports EFD@10 and EPC@10 metrics for COT, SLIM and GOT4Rec, indicating tthat GOT4Rec outperforms the baselines in recommending long-tail items. These results support our claim that GOT4Rec mitigates popularity bias by capturing a wider range of information."}, {"title": "5 Conclusion", "content": "In this paper, we propose GOT4Rec, a sequential recommendation method that optimally leverages the reasoning capabilities of LLMs to extract and integrate short-term, long-term, and collaborative user preferences utilizing the graph of thoughts (GoT) framework. Experiments on real-world"}]}