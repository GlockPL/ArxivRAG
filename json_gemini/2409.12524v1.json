{"title": "Should RAG Chatbots Forget Unimportant Conversations? Exploring Importance and Forgetting with Psychological Insights", "authors": ["Ryuichi Sumida", "Koji Inoue", "Tatsuya Kawahara"], "abstract": "While Retrieval-Augmented Generation (RAG) has shown promise in enhancing long-term conversations, the increasing memory load as conversations progress degrades retrieval accuracy. Drawing on psychological insights, we propose LUFY, a simple yet effective method that focuses on emotionally arousing memories and retains less than 10% of the conversation. In the user experiment, participants interacted with three types of RAG chatbots, each for 2 hours over 4 sessions, marking the most extensive assessment of a chatbot's long-term capabilities to date-more than four times longer than any existing benchmark. The results demonstrate that prioritizing arousing memories while forgetting the majority of the conversation significantly enhances user experience. This study pushes the frontier of long-term conversations and highlights the importance of forgetting unimportant parts of conversations.", "sections": [{"title": "1 Introduction", "content": "In human conversations, what we remember remains a mystery. Similarly, in the realm of chatbots, particularly Retrieval-Augmented Generation (RAG) chatbots, the challenge lies not only in retaining long-term memory but also in deciding what to forget.\nRAG, a method that retrieves related memories from past conversations and uses them to generate a response, has been shown to be effective (Xu et al., 2022). Compared to inputting the entire conversation history into a Large Language Model (LLM), retrieving relevant information is not only efficient and effective (Yu et al., 2024) but also enhances the chatbot's ability to remember and actively utilize the user's past information, improving the level of engagement and contributing to long-term friendships between the chatbot and the user (Campos et al., 2018).\nHowever, as highlighted in previous studies (Choi et al., 2023), a challenge arises: as conversations progress, memory constantly increases. This not only demands significant storage space but also involves retaining a lot of unnecessary information, which could lead to degrading retrieval performance. A simple example would be that humans do not remember every single meal they have had in their entire lives; instead remember only their favorites or particularly memorable ones.\nThis necessitates selective memory in chatbots, much like the human cognitive process, where only the essential elements of a conversation are remembered. Studies have shown that humans typically recall only about 10% of a conversation (Stafford and Daly, 1984), making it crucial to determine which 10% of memories are worth retaining. This challenge raises the key question: how can chatbots efficiently identify and prioritize these valuable memories, while discarding irrelevant information?\nTo address this, we propose LUFY: Long-term Understanding and identiFYing key exchanges in one-on-one conversations. Building upon real-world data and psychological insights, LUFY improves existing models by calculating six distinct memory metrics, whereas simpler models like MemoryBank (Zhong et al., 2024) only account for frequency and recency of memory recall. Additionally, LUFY does not merely sum these metrics but uses learned weights to balance their impact. These weighted scores are then used in both the retrieval and forgetting modules, ensuring that the chatbot effectively prioritizes relevant memories while gradually forgetting less important ones.\nTo empirically validate our proposed model and its effectiveness in enhancing long-term conversational memory, we conducted an experiment involving human participants. In this experiment, participants engaged in text-based conversations with chatbots equipped with different forgetting modules, each for at least two hours. This duration"}, {"title": "2 Psychology of Memorizing Conversations", "content": "MemoryBank (Zhong et al., 2024) introduced the idea of assessing the importance of a memory based on the number of times a memory is used and the elapsed time since the memory was last used. This idea was inspired by the Ebbinghaus Forgetting Curve theory (Ebbinghaus, 1885), a theory that the more times information is reviewed or learned, the slower the rate of forgetting. In this model, the importance of a memory is represented as:\nImportance = $e^{-\\frac{\\Delta t}{S}}$.\nHere, $\\Delta t$ represents the time elapsed since the memory was last retrieved, and $S$ is the number of times the memory is retrieved. In MemoryBank, the initial value of S is set to 1 upon its first mention in a conversation. When a memory item is recalled during conversations, $S$ is increased by 1 and $\\Delta t$ is reset to 0. Nevertheless, as acknowledged in their study, this represents a preliminary and oversimplified model for memory's importance updating. Most importantly, their work did not include experiments to validate their proposed concept.\nDespite the innovative approach taken by MemoryBank, the model's simplicity overlooks critical aspects of how memories are valued and retained. This oversight becomes especially apparent when considering the concept of flashbulb memories, as described by (Brown and Kulik, 1977). These memories, such as the news of the 9/11 terrorist attacks, maintain their vividness and strength regardless of recall frequency. The current method of uniformly updating $S$ fails to reflect the intricate nature of memory consolidation and the differential impact of emotionally charged events.\nIn the following, we explain pivotal insights from psychology that offer valuable perspectives on conversations, particularly focusing on memory consolidation and retention mechanisms. Additionally, we demonstrate how these findings can be applied to numerically score the importance of an utterance.\nFirst, emotional arousal significantly enhances memory consolidation (Brown and Kulik, 1977; Conway et al., 1994; McGaugh, 2003; Reisberg and Hertel, 2003), a phenomenon well-documented in studies like flashbulb memories (Brown and Kulik, 1977). Emotionally charged events, such as dramatic personal experiences like a breakup or receiving college admissions, are more likely to be remembered. We used ROBERTa (Liu et al., 2019) finetuned with EMOBANK (Buechel and Hahn, 2017), a 10k text corpus manually annotated with emotion, to measure arousal in user's utterance.\nSecond, the element of surprise plays a crucial role in memory retention. Events that deviate from expectations are more memorable (Breton-Provencher et al., 2022). To quantify this element of surprise, we assessed the rarity of sentences using perplexity, a measure of how predictable a piece of text is. We employed the GPT2-Large model to calculate the perplexity, using the chatbot's utterance as context.\nThird, the concept of Retrieval-Induced Forgetting (RIF) suggests that selectively recalling certain memories strengthens those memories while making related but unmentioned memories more likely to be forgotten (Hirst and Echterhoff, 2012). In line with this, we specifically retrieve and use the two most relevant memories for each conversational turn. The memory ranked as the most relevant (R1) is referenced directly to reinforce its strength, while the second most relevant memory (R2) is recalled but left unmentioned to encourage forgetting, in accordance with RIF principles.\nFourth, approximately 70% of conversation time is dedicated to the exchange of information about contemporary events (Dunbar et al., 1997). Therefore, we take the recency of the memory into account at the retrieval stage, as detailed in Section 4.1.1.\nLastly, the capacity for immediate recall in social interactions is surprisingly limited; studies show that individuals typically remember only about 10% of the content from a conversation (Stafford and Daly, 1984)."}, {"title": "3 Quantifying Memory Importance", "content": "Building upon the psychological principles of emotional arousal, surprise, and retrieval-induced forgetting, we propose new metrics for determining the importance of memories. Specifically, we translate these insights into quantifiable metrics:\n$\\bullet$ Emotional Arousal (A): Measured using ROBERTa (Liu et al., 2019) fine-tuned with EMOBANK (Buechel and Hahn, 2017), capturing the intensity of emotions in the user's utterance.\n$\\bullet$ Surprise Element (P): Assessed via perplexity using the GPT2-Large model, representing the unpredictability of the utterance.\n$\\bullet$ LLM-Estimated Importance (L): Derived from the language model's estimation of the importance of the user's utterance."}, {"title": "3.1 Definition of Importance Score", "content": "Building upon the psychological principles of emotional arousal, surprise, and retrieval-induced forgetting, we propose new metrics for determining the importance of memories. Specifically, we translate these insights into quantifiable metrics:\n$\\bullet$ Emotional Arousal (A): Measured using\nROBERTa (Liu et al., 2019) fine-tuned with EMOBANK (Buechel and Hahn, 2017), capturing the intensity of emotions in the user's utterance.\n$\\bullet$ Surprise Element (P): Assessed via perplexity using the GPT2-Large model, representing the unpredictability of the utterance.\n$\\bullet$ LLM-Estimated Importance (L): Derived from the language model's estimation of the importance of the user's utterance.\n$\\bullet$ Retrieval-Induced Forgetting (R1, R2):\nThe frequency with which a memory appears in the top 2 relevant memories. The most relevant memory is reinforced, while the second most relevant memory is selectively unmentioned to encourage forgetting (Hirst and Echterhoff, 2012).\nTo account for aspects of importance that might not be fully captured by the aforementioned metrics in Section 2, we also add the LLM-estimated importance score, which relies on the language model's interpretation of the conversational context. The prompt given to estimate the importance is detailed in the Appendix A. These five metrics are regularized to ensure consistent scaling with the same average, minimum, and maximum values. See the Appendix B for further details.\nAs illustrated in Figure 1, the importance assignment process involves three key steps. Step 1: Metric Calculation\u2014For each chatbot-user utterance pair (defined as a memory), the psychological metrics outlined above are calculated. Step 2: Strength Determination\u2014Next, the strength S is computed by summing the weighted metrics, which reflects the composite significance of the memory.\nS = $W_A \\cdot A + w_p\\cdot P +W_L\\cdot L + W_{R1}R1 - W_{R2} R2$"}, {"title": "3.2 Weight Estimation", "content": "S = $W_A \\cdot A + w_p\\cdot P +W_L\\cdot L + W_{R1}R1 - W_{R2} R2$\n(2)\nStep 3: Importance Calculation\u2014Finally, using the calculated strength, the overall importance of the memory is determined via the forgetting curve equation.\nImportance = $e^{-\\Delta t / S}$\nWe used real-world data to estimate the relative importance of the five memory-related metrics. In this study, to fit the three initial parameters (wa, wp, wl), part of the CANDOR corpus (a total of 300 utterance pairs) was used. While keeping these three parameters fixed, we used human-RAG chatbot conversations (a total of 200 utterance pairs), which were collected prior to the user experiment to fit the latter two parameters (wr1, wr2). The CANDOR corpus was selected for its diverse set of conversations, while the human-RAG conversations allowed for precise tracking of memory usage, which is not available in the CANDOR corpus.\nFor both datasets, we tasked annotators with labeling the conversations on a binary scale of 1 and 0, where 10% of the conversations were labeled as 1 (important) to mimic human behavior (Stafford and Daly, 1984). To guarantee the reliability of our annotation process, we ensured that the"}, {"title": "4 System Overview", "content": "LUFY is composed of two main components: (1) the response generation module and (2) the forgetting module. The forgetting process occurs after a session when the user is done talking."}, {"title": "4.1 Response Generation", "content": "As depicted in Figure 2, the response generation process consists of two main parts: the retrieval part and the concatenation of various information to provide to the LLM. We provide a detailed explanation of the retrieval method, as it is central to the RAG chatbots."}, {"title": "4.1.1 Retrieval Method", "content": "Embedding We use a standard LLM embedding (text-embedding-ada-002 from OpenAI).\nRetrieval The foundation of the RAG system is its retrieval method. This process is initiated upon receiving input from a user, to retrieve the memory most relevant to the current conversation.\nThere are two key aspects to the retrieval method:\n1. Cosine Similarity Threshold: During the retrieval stage, we use cosine similarity to assess the relevance between the embeddings of recent conversations and the entries in the memory database. To ensure a high level of contextual relevance, we have set the threshold at 0.8, consistent with commonly used standards in popular RAG system frameworks like LlamaIndex. This choice is further validated by our analysis of Question and Answer pairs gathered from the user experiment. More details are available in Section 5.4.\n2. Final Retrieval Score: Our proposed method distinguishes itself from previous works by integrating importance into the retrieval process. The final retrieval score is computed using a formula as follows:\nscore = Cos. Sim. + $a \\cdot$ Importance (4)\nThis method not only reflects the memory's relevance to the current context but also its recency and importance. In this study, a is set to 0.1; however, future work should focus on determining the optimal value."}, {"title": "4.1.2 Information Provided to the LLM for Response Generation", "content": "The LLM is provided with three key pieces of information to generate responses: a summary of past conversations, the context (recent five utterances), and memory relevant to the current context."}, {"title": "4.2 Forgetting Process", "content": "As depicted in Figure 3, the forgetting process is executed in two steps: ranking the memories according to importance, and retaining the top 10% important memories."}, {"title": "5 User Experiment", "content": "We compared three different RAG chatbots: Naive RAG, MemoryBank, and LUFY. Naive RAG stores all memories, while MemoryBank and LUFY are equipped with a forgetting mechanism that retains only 10% of memories. MemoryBank assesses the importance of a memory based solely on retrieval counts, whereas LUFY evaluates memory importance using six memory-related metrics, as depicted in Figure 1. Additionally, although both Naive RAG and MemoryBank use Cosine similarity only to assess the relevance of a memory to current conversations, LUFY also considers importance in this assessment. The differences between the three systems are summarized in Table 3.\nWe conducted four rounds of dialogue, significantly exceeding the interaction length of existing benchmarks (Xu et al., 2022), as shown in Table 1."}, {"title": "5.1 Procedure", "content": "Seventeen participants engaged in a 30-minute conversation with each chatbot across 10 sessions over 4 days. In the initial session, participants interacted with a standard RAG chatbot. The three chatbots\u2014Naive RAG, MemoryBank, and"}, {"title": "5.1.1 Interaction Phase", "content": "Seventeen participants engaged in a 30-minute conversation with each chatbot across 10 sessions over 4 days. In the initial session, participants interacted with a standard RAG chatbot. The three chatbots\u2014Naive RAG, MemoryBank, and"}, {"title": "5.1.2 Post-Interaction Phase", "content": "After each session, the participants were asked to create three question-and-answer pairs. These questions contained information that the participants wanted the chatbot to remember about them. Additionally, the questions were designed to be clearly judged on a binary scale (1: correct, 0: incorrect) and to ensure that the answers would remain consistent in future questions. An example of such a question is, 'Where is my hometown?'"}, {"title": "5.2 LUFY-Dataset", "content": "We release the conversations collected between the three models and the participants, which we refer to as the LUFY-Dataset.\nSimilar to the annotation procedure described in Section 3, at least three annotators reviewed and labeled the conversations from the user experiment using a binary scale: 1 for \"important\" and O for \"unimportant.\" In addition to the annotation of important memories, each conversation script includes three QA pairs. For the de-identification process, multiple reviewers examined the conversations to ensure that all personally identifiable information (PII) was removed or modified. Further details are provided in Appendix F.\nWe aim for the LUFY-Dataset to serve as a benchmark for long-term conversations, given its unique length, as shown in Table 1."}, {"title": "5.3 Main Results", "content": "Firstly, we evaluated the user experience using both subjective and automatic methods.\nSubjective Evaluations For subjective methods, each conversation script was evaluated by three annotators based on three criteria: Personalization, Flow of the Conversation, and Overall experience. The results are shown in Table 4. LUFY outperformed the other two models in almost all sessions across all criteria, with a notable difference in Session 4. This highlights an improved user experience with LUFY, especially in Session 4, where the difference becomes more pronounced in longer conversations. The definitions and specific scoring criteria are provided in Appendix G.\nSentiment Analysis As part of the automatic method to score the user experience, we conducted sentiment analysis using versions of RoBERTa fine-tuned with sentiment datasets. As shown in Table 5, participants had more positive conversations when interacting with LUFY. Kindly refer to Appendix C for more details.\nRating by LLM As part of the automatic method to score the user experience, we assessed the user's overall satisfaction using GPT-40. We used GPT-40 as an evaluator because strong LLMs achieve performance comparable to human evaluators (Zheng et al., 2024). As shown in Table 6, there is a notable difference in Session 4, which aligns with the findings from the subjective evaluations."}, {"title": "5.4 In-depth Analysis", "content": "Cosine Similarity Threshold We used the default value of 0.8 for the cosine similarity threshold. Using the LUFY-Dataset, we conducted experiments to verify whether this choice was optimal.\nWe used the LUFY-Dataset, which consists of 612 QA pairs. For each pair, we retrieved ten relevant memories with a cosine similarity threshold of at least 0.6 and annotated whether the retrieved memory was correct for answering the question. Our findings include:\n$\\bullet$ Memories with a cosine similarity of less than 0.75 were always irrelevant or incorrect.\n$\\bullet$ There is a positive correlation between higher cosine similarity and the likelihood of the memory correctly answering the question, although fewer cases are retrieved when the cosine similarity is over 0.85.\nBased on these findings, we tested various cosine similarity thresholds between 0.75 to 0.83 to determine the threshold that would yield the highest F1 Score, representing the balance between retrieving relevant information and filtering out irrelevant content.\nAs shown in Figure 5, we found that\n$\\bullet$ F1 Score remains constant between 0.75 and 0.8, with a significant decline beyond 0.8.\nIn summary, our experiments show that a cosine similarity threshold between 0.75 and 0.8 provides the best balance between precision and recall. Thus, our choice of 0.8 is optimal, as it maximizes performance without sacrificing too much recall, ensuring the retrieval of the most relevant memories while maintaining precision.\nTop-k Retrieval Using the same 612 QA pairs from the LUFY-Dataset, we retrieved the top 10 memories for each question and analyzed the position of the correct memory among them."}, {"title": "6 Conclusion", "content": "This study introduced LUFY, a RAG chatbot that retains only the most important 10% of memories. By leveraging findings from psychology and real-world data, we developed a more precise method for defining the importance of a memory. We conducted a human experiment that is 4.5 times longer than the most extensive test to date, resulting in notable improvements in both user experience and precision. We also publicly release this long-term conversation dataset. Overall, this study demonstrates the potential of forgetting unimportant memories."}, {"title": "Limitations", "content": "This study has demonstrated the potential advantages of the proposed method in enhancing chatbot interactions through improved objective and subjective evaluations. However, it is important to acknowledge its limitations.\nFirstly, our investigation focused solely on the impact of memory-related psychological metrics in conversations between strangers. Future research should aim to diversify the dataset by including interactions among friends, family members, and other relationships to comprehensively understand these metrics' influence across different conversational contexts.\nSecond, this study only looked at text-based conversations. In text, indicators like exclamation marks play a role in detecting arousal. For example, when a user said, \"I'm going to Hong Kong with my friends next month,\" our system calculated a low arousal level, missing the excitement. Future work should explore multimodal settings to improve the accuracy of emotional detection."}, {"title": "7 Ethical Considerations", "content": "This work focuses on models with long-term memory and open-domain conversations where people might share their personal interests. During conversations with our systems, the systems will store information they learn from the exchange. We assure that whatever is remembered is kept private, only related to that specific user, and is not shared with anyone else without de-identification process."}, {"title": "B Regularization of the five metrics", "content": "Out of the five metrics\u2014A, P, L, R1, and R2-only P, which stands for perplexity, can have a substantially large value. Therefore, we set a threshold of 160 for any case where perplexity exceeds this value. We chose this threshold because more than 95% of the memories had a value below 160. However, future work should focus on determining an optimal threshold for detecting unusually large perplexity values. Additionally, using the human-RAG chatbot conversations (a total of 200 utterance pairs) in Section 3, we regularized the five metrics to have the same average, minimum, and maximum values.\""}, {"title": "C Training Details", "content": "Importance Weights of Memory Metrics Given that the lag time is one session\u2014since annotation occurs after the session (at t = 2) and the last time the memory is used is during the session (at t = 1)\u2014we employ the following function to model the probability p of an utterance being memorable based on Equation 1.\n$P_{retention} = e^{-1/S}$\nUsing the annotated data, we used the Levenberg-Marquardt algorithm and utilized L2-regularized squared loss as the loss function, with p0 (initial guesses) to be [1, 1, 1], although we did not find the initial guesses to affect the outcome of the learned parameters.\nArousal Detection We used ROBERTa (Liu et al., 2019) finetuned with EMOBANK (Buechel and Hahn, 2017) to detect arousal. We provide some hyper parameters for the training: (model name = roberta-large, batch size = 16, learning rate = 2e-5, number of epochs = 10). We used 2 RTX A6000 for training.\nSentiment Analysis We used fine-tuned models of DistilROBERTa (Sanh, 2019) and RoBERTa (Liu et al., 2019) for Sentiment Analysis.\nDistilROBERTa is fine-tuned with polar sentiment dataset of sentences from financial news, consisting of 4840 sentences from English language financial news categorised by sentiment. Table 10 shows the hyperparameters.\nWe used TimeLMs (Loureiro et al., 2022) as the fine-tuned ROBERTa model. This ROBERTa is trained on 124M tweets from January 2018 to December 2021, and finetuned for sentiment analysis with the TweetEval benchmark (Mohammad et al., 2018)."}, {"title": "D Retention Rate", "content": "Retention Rate As shown in Table 11, Memory-Bank and LUFY remembered a very tiny portion of the conversations, mostly less then 10% of the conversations."}, {"title": "E Examples of the LUFY-Dataset", "content": ""}, {"title": "F De-identification", "content": "Removal of Direct Identifiers This involves eliminating information that can directly identify an individual, such as names, social security numbers, and addresses.\nGeneralization Specific data points are replaced with broader categories. For example, exact ages might be replaced with age ranges, or specific dates might be replaced with just the year.\nSome studies, such as DeID-GPT (Liu et al., 2023), explore the use of LLMs for de-identification. Other studies, such as the Ego4D dataset (Grauman et al., 2022), which consists of 3,000 hours of video, use commercial software like Brighter.ai and Primloc's Secure Redact. However, we manually executed the process to ensure proper de-identification."}, {"title": "G Scoring Criteria", "content": "We provide the specific instructions for the three criteria given to annotators.\nDid the chatbot's personalization appear appropriate in the conversation?\n1. 1/5 (Very Poor): Responses feel generic and lack personalization.\n2. 2/5 (Poor): Limited personalization attempts are often off-target or superficial. Responses only occasionally reflect the user's context.\n3. 3/5 (Average): The chatbot shows moderate personalization. Responses are relevant but may not fully address specific user needs.\n4. 4/5 (Good): The chatbot consistently personalizes well, matching responses to the user's context and needs effectively.\n5. 5/5 (Excellent): Outstanding personalization. Responses are highly relevant, context-aware, and perfectly meet the user's needs, enhancing engagement and satisfaction.\nHow well did the conversation flow without feeling disjointed or out of context?\n$\\bullet$ 1/5 (Very Poor): The conversation feels broken and illogical, with responses often out of context.\n$\\bullet$ 2/5 (Poor): The conversation has frequent awkward transitions or non-sequiturs that disrupt the flow.\n$\\bullet$ 3/5 (Average): The conversation flows reasonably well, with some disjointed moments that slightly distract from the overall experience.\n$\\bullet$ 4/5 (Good): The conversation flows well, with only minor issues that do not significantly impact the user's experience.\n$\\bullet$ 5/5 (Excellent): The conversation flows seamlessly and logically, feeling completely natural and coherent throughout.\nOverall, how would you rate the user's experience with the chatbot?\n1. 1/5 (Very Poor): The user found the conversation frustrating and unhelpful, strongly feeling they would not want to use the chatbot again.\n2. 2/5 (Poor): The user was somewhat disappointed with the conversation, finding little value in it and is unlikely to use the chatbot again soon.\n3. 3/5 (Average): The conversation met the user's basic expectations. They would consider using the chatbot again if needed.\n4. 4/5 (Good): The user was pleased with the conversation and found it helpful, expressing a clear interest in using the chatbot again.\n5. 5/5 (Excellent): The user was highly satisfied with the conversation, finding it exceptionally useful and engaging, and is eager to use the chatbot again."}, {"title": "H Extra Results", "content": "H.1 Complete table for recall, precision and F1 Score.\nHere we provide the complete results for recall, precision and F1 Score.\nH.2 Ablation Study\nWe conducted an ablation study for the agreement probability with other annotators and precision, recall and F1 Score. We found A (Arousal), L (LLM estimated importance), R1 (the number of times the memory is retrieved) to be of particular importance."}]}