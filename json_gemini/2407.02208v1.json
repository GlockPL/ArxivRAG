{"title": "How to Learn in a Noisy World? Self-Correcting the Real-World Data Noise on Machine Translation", "authors": ["Yan Meng", "Di Wu", "Christof Monz"], "abstract": "The massive amounts of web-mined parallel data contain large amounts of noise. Semantic misalignment, as the primary source of the noise, poses a challenge for training machine translation systems. In this paper, we first study the impact of real-world hard-to-detect misalignment noise by proposing a process to simulate the realistic misalignment controlled by semantic similarity. After quantitatively analyzing the impact of simulated misalignment on machine translation, we show the limited effectiveness of widely used pre-filters to improve the translation performance, underscoring the necessity of more fine-grained ways to handle data noise. By observing the increasing reliability of the model's self-knowledge for distinguishing misaligned and clean data at the token-level, we propose a self-correction approach which leverages the model's prediction distribution to revise the training supervision from the ground-truth data over training time. Through comprehensive experiments, we show that our self-correction method not only improves translation performance in the presence of simulated misalignment noise but also proves effective for real-world noisy web-mined datasets across eight translation tasks.", "sections": [{"title": "Introduction", "content": "The success of machine translation (MT) models is mainly due to the availability of large amounts of web-crawled data. However, publicly available web-mined parallel corpora (bitext) such as CCAligned (El-Kishky et al., 2020), WikiMatrix (Schwenk and Douze, 2017), ParaCrawl (Ba\u00f1\u00f3n et al., 2020) and NLLB (team et al., 2022) are shown to be noisy (Kreutzer et al., 2022; Ranathunga et al., 2024). The notable performance drop on NMT when training with injected synthetic noise (Khayrallah and Koehn, 2018) or fine-tuning with CCAligned (Lee et al., 2022), indicates the importance of developing noise-robust training when learning from noisy corpus.\nGiven a noisy training dataset, a common and straightforward approach to mitigate the impact of noisy data is to filter low-quality training samples (Herold et al., 2022; Bane et al., 2022). However, in practice, large amounts of misaligned samples still exist in pre-filtered web-mined datasets (Kreutzer et al., 2022). Even earlier works (Khayrallah and Koehn, 2018; Herold et al., 2022; Li et al., 2024) study the impact of misalignment on machine translation, but their way of generating synthetic misaligned sentences is by random shuffling, which is unrealistic. The real-world misaligned sentences contain partially shared meanings, which disguise them as seemingly parallel data and are hard-to-detect. To analyze such hard-to-detect real-world misalignment, we design a process to simulate it controlled by semantic similarity. Similar to the real-world setting, we demonstrate that our simulated misalignment also challenges widely-used pre-filters, including Laser (Artetxe and Schwenk, 2018), Comet (Rei et al., 2020) and Bi-Cleaner (Zaragoza-Bernabeu et al., 2022).\nUnder our simulated noise setting, we evaluate an alternative type of approach to handle data noise: Data truncation (Kang and Hashimoto, 2020; Li et al., 2024; Flores and Cohan, 2024), which focuses on the model training dynamics and ignores losses at the token level when there is a relatively large inconsistency between the model's prediction and the ground truth during training. However, we observe that truncation methods are sensitive to varying levels of simulated misalignment noise. For example, in low-resource training corpus with a high misalignment rate, truncation methods degrade the translation performance (shown in Section 5.3). We argue that the noisy low-resource setting restricts the model from acquiring sufficient correct knowledge, resulting in an inaccurate removal of clean and useful ground-truth data. Moreover, truncation methods start to ignore potential data noise from an early training time, which overlooks the increasing reliability of the model's prediction over time.\nTo overcome these limitations, we propose an approach called self-correction, which leverages the model's predictions to self-correct noise during training while maintaining supervision from the ground truth to avoid discarding useful training information (as shown in Figure 1). To adapt to the changing reliability of model's self-knowledge, we set a dynamic schedule to gradually increase the trust in the model's predictions to revise the training supervision from the ground truth. In the early stage of training, the model is not well trained, so we place greater trust in the reference data than in the model's prediction. As the model gains knowledge during training, we use it to revise the ground-truth data progressively.\nWe evaluate our self-correction method in both simulated and real-world environments. We demonstrate that our method consistently outperforms baselines in both high- and low-resource datasets with different levels of misalignment noise. Moreover, we clearly show the gains are mainly from revising the misaligned samples while maintaining the performance of clean parallel data. In the real-world setting, our self-correction method effectively handles naturally occurring noise in web-mined parallel datasets, e.g. ParaCrawl and CCAligned, leading to performance gains of up to 1.2 BLEU points across eight translation tasks and outperforming other alternative methods, including pre-filters and truncation."}, {"title": "Background", "content": "Web-mined parallel corpora are the primary training data source for machine translation models. However, parallel data crawled from public websites lack quality guarantees and contain different types of noise (Kreutzer et al., 2022), including wrong language, non-linguistic content, and misalignment noise.\nThe primary source of noise in parallel web-mined data is semantic misalignment (Khayrallah and Koehn, 2018; Kreutzer et al., 2022; Ranathunga et al., 2024). For instance, Khayrallah and Koehn (2018) analyzed the data quality of the raw ParaCrawl corpus, showing 77% of the analyzed sentence pairs contain noise while half of them are misalignments. Wrong language and non-linguistic contents only account for a small portion since filters e.g., language identification toolkits (Herold et al., 2022), can easily detect them. Kreutzer et al. (2022) extended the data quality analysis to pre-filtered web-mined datasets, e.g. WikiMatrix, CCAligned, noting that more than 50% of data in both corpora are noisy while misalignment is the primary noise. Even in the top-quality parallel data from the NLLB corpus, many misaligned sentences can still be found (Ranathunga et al., 2024).\nOverall, previous studies demonstrate the prevalence of noisy training data in web-mined corpora for machine translation and underscore the importance of noise-robust training, particularly in handling misaligned data."}, {"title": "Learning in the Noisy World", "content": "Data filtering is a straightforward way to remove the noise from the translation training corpus to mitigate its negative impact. There are two methods to ensure the semantic alignments between the source and target in a sentence pair: (1) surface-level filters, e.g., removing sentence pairs that differ a lot in source and target length; (2) semantic-level filters, relying on quality estimation models to score each sentence pair (Kepler et al., 2019; Rei et al., 2020; Peter et al., 2023). Other studies consider the denoising as outlier detection (Taghipour et al., 2011) or ranking problem (Cui et al., 2013).\nIn this paper, we mainly consider semantic-level filters: (1) Laser (Artetxe and Schwenk, 2018), a sentence alignment pre-filter tool for web-mined corpora, i.e., CCAligned and WikiMatrix; (2) Bicleaner (Zaragoza-Bernabeu et al., 2022), a classifier that predicts if a sentence is a translation of another. It is also a part of the pre-processing pipeline for generating the ParaCrawl dataset; (3) Comet (Rei et al., 2020), a widely-used quality estimation model for machine translation.\nAll these approaches rely on external models to select high-quality data before training. However, our approach does not require such pre-selection but focuses on model training dynamics, which can be applied more broadly."}, {"title": "Truncation", "content": "There are two ways for removing data noise by focusing on the model's training dynamics: (1) using extrinsic trusted data to measure the data quality between noisy and denoised NMT models (Wang et al., 2018); (2) solely using the model's self-knowledge to remove potential noise during training (Kang and Hashimoto, 2020; Li et al., 2024). In our approach, we do not require any external trusted data or models and thus we only compare with the second type of work, i.e., data truncation.\nThe most common type of truncation is based on the loss, which estimates the data quality by the model's predicted probability of the ground truth (Kang and Hashimoto, 2020; Goyal et al., 2022; Flores and Cohan, 2024). Ground-truth tokens with high loss are considered as noise and will be skipped during training by setting their loss to zero. However, relying on loss to remove noise overlooks the model's probability distribution of non-target tokens. In a high entropy context, the probability of the correct ground-truth token is also low due to many alternative continuations, which cannot be treated as noise. To consider the entire model prediction distribution, Li et al. (2024) further propose Error Norm Truncation and use the $l_2$ norm between the model's prediction distribution and the one-hot distribution of the ground-truth token to measure the data quality. During training, tokens with error norm values exceeding a pre-defined threshold will be removed.\nIn this paper, we compare against data truncation methods by relying on two model-based metrics, loss and error norm values. However, truncation methods are sensitive to when and how much data to truncate? Our approach overcomes these limitations by revising all the ground truth with an adaptive trusting weight of the model's prediction. Details are introduced in Section 4."}, {"title": "An Empirical Study of Misalignment", "content": "In this section, we investigate the primary source of noise, i.e., semantic misalignment, in a simulated setting. We first introduce a strategy to simulate realistic misalignment noise by controlling semantic similarity (Section 3.1). Next, we show the similarity of our simulated noise to real-world misalignment in terms of adequacy and its hard-to-detect nature (Section 3.2). Under our simulated noisy setting, we evaluate the model-based metrics to distinguish data noise and show the potential limitations (Section 3.3)."}, {"title": "Simulating Misalignment Noise", "content": "To simulate misalignment, previous works (Bane et al., 2022; Herold et al., 2022; Li et al., 2024) randomly shuffle target sentences of a clean parallel training corpus. However, the random shuffling noise can be easily removed by pre-filters based on length difference or semantic similarity (Herold et al., 2022), which oversimplifies the misalignment in the real-world web-mined corpora. For instance, Kreutzer et al. (2022) show that a large portion of misaligned sentence pairs that share partial semantics still exists even after pre-filter tools, i.e., Laser, (examples in Table 1) which show the challenge of detecting real-world misalignment.\nTo quantitatively analyze the impact of the realistic misalignment noise, we design a process to simulate real-world misalignment controlled by semantic similarity (See Algorithm 1 in the Appendix). From a chunk of clean data, we first choose k misaligned target candidates for a source sentence based on length difference and word overlap from the true parallel target. Next, we use quality estimation methods, e.g., Laser or Comet, to calculate the semantic similarity scores between the source sentence and its misaligned candidates. The candidate with the top score is selected as the final synthetic misaligned target. In this way, the misalignment noise is generated with controlled semantic overlaps. Examples that are controlled by Laser (Misaligned-Laser) and Comet (Misaligned-Comet) are in Appendix 6."}, {"title": "Real-World Misalignment", "content": "To show the similarity of our simulated noise to real-world misalignment, we conduct a human evaluation on 50 simulated and real-world misaligned sentences rating their Adequacy (scale 1-5), which measures the meaning overlap between source and target. In Figure 2, we show both the real-world misalignment and simulated misaligned-Laser/Comet has a relatively high adequacy score, above 2.5, while Randomly shuffled misaligned sentences only has an adequacy of 1.5. This ensures our simulated misalignment contains partial semantic overlaps as the real-world misalignment. Moreover, our simulation process confirms the fluency of misaligned targets by selecting sentences from a clean corpus. Details of human evaluation are in Appendix B.3."}, {"title": "Hard-to-Detect Nature", "content": "To show the hard-to-detect nature of simulated noise as real-world misalignment, we investigate the noise detection ability of widely used pre-filters: Comet, Laser, and Bi-Cleaner.\nWe calculate the noise detection accuracy of the data filters on a mixed set with the same amounts of clean and noisy data. For the clean data, we randomly sample 2,000 clean sentence pairs from the WMT2017 De\u2192En training set. For Misaligned-Random, we randomly shuffle the order of target sentences in the sampled clean sentence pairs. For Misaligned-Comet and Misaligned-Laser, we use the same source sentences from the sampled clean data, and select the misaligned targets from another 200K target sentences in the training corpus based on Algorithm 1. We score each sentence pair based on the filter models and determine a true ratio threshold based on the amounts of clean and noisy sentence pairs, here 1:1. Sentence pairs with scores below this threshold are classified as noisy. The details for scoring sentence pairs by filter models are shown in Appendix A.\nTable 2 shows the filtering accuracy of data filters on different misaligned noise. First, Misaligned-Random can be accurately detected by all data filters, particularly for using Laser, with an accuracy of 76%. This questions the previous assumptions (Khayrallah and Koehn, 2018; Li et al., 2024) of the impact of misalignment noise on translation performance since most of them can be pre-filtered. However, our introduced noise i.e., Misaligned-Laser and Misaligned-Comet pose a challenge on all pre-filters, as the real-world misalignment does. Overall, we show the validity of our simulated noise in two aspects: (1) Adequacy, reflected in the similar level of shared semantics as the real-world misalignment; (2) Hard-to-Detect Nature, reflected in the low filter accuracy of widely used pre-filters."}, {"title": "Fine-grained Misalignment Detection", "content": "Model-based metrics, including loss and error norm values, are used in data truncation methods (Kang and Hashimoto, 2020; Li et al., 2024) to detect and ignore data noise at the token-level during training. Here, we evaluate their effectiveness under our simulated noisy settings.\nLoss measures the model's predicted probability of the ground-truth token while error norm value (el2n) calculates the difference between the ground-truth (one-hot) distribution $OH(y_t)$ and model's prediction distribution $p_\\theta(\\cdot|y_{<t}, x)$ (eq 1).\n$el2n = ||p_\\theta(\\cdot|x, y_{<t}) - OH (y_t)||_2$ (1)\nTokens with higher loss or el2n value are indicated as the noise since they are more inconsistent between the model's prediction and the ground truth.\nTo evaluate whether the above model-based metrics can distinguish our simulated noise from clean data, we record the loss and el2n values for each token of the 2,000 clean and Misaligned-Laser sentence pairs in the same data setting of Section 3.2.2. Figure 3 shows the changes of loss and el2n value distribution for the clean and noisy tokens in different training epochs. First, we find both metrics can gradually distinguish clean and noisy data as the training time increases. This indicates the effectiveness of the model's self-knowledge for distinguishing hard-to-detect data noise. Second, we find that the el2n metric shows better distinguishability than loss, indicating the importance of considering the whole model prediction distribution.\nHowever, we point out two limitations of truncation methods relying on model-based metrics: First, they overlook the increasing reliability of model prediction by removing potential data noise from an early training time. Second, they cannot avoid removing clean but useful data. As shown in Figure 3, there is still an undistinguishing area between noisy and clean distribution."}, {"title": "Noise Self-Correction", "content": "To overcome the limitations of truncation methods in Section 3.3, we go a step further and propose the self-correction method to gradually increase the trust of model prediction distributions to correct the ground-truth data during training. Overall, our method keeps the supervision signals from the training data to avoid clean training information loss and also progressively trusts a dynamic low entropy state of model prediction distribution to revise the data. Our work is in line with the label correction in computer vision (Wang et al., 2022; Lu and He, 2022).\nNew Target. Consider conditional probability models $p_\\theta(y|x)$ for machine translation. Such models assign probabilities to a target sequence $y = (y_1, ..., y_T)$ by factorizing it to the sum of log probabilities of individual tokens $y_i$ from the vocabulary V. At each training iteration, the model learns towards the ground-truth token distribution, one-hot $q(y_i)$, with a model prediction distribution $p_\\theta(\\cdot|x, y_{<i})$. In self-correction, we leverage the model prediction $p_\\theta(\\cdot|y_{<i}, x)$ to revise the one-hot distribution $q(y_i)$ with the aim of learning towards a new target $\\bar{q}(y_i)$:\n$\\bar{q}(y_i) = (1 - \\lambda)q(y_i) + \\lambda p_\\theta(\\cdot|x, y_{<i})$ (2)\nIn this way, the new target $\\bar{q}(y_i)$ not only keeps the original supervision signal from the training data but also the model's prediction. $\\lambda$ denotes a weighting factor to determine how much to trust the model prediction.\nDynamic Learning Schedule. We set $\\lambda$ correlated with a learning time function Time(t) of training iteration t and model entropy $H(p_\\theta)$:\n$\\lambda = (1 - H(p_\\theta)) \\times Time(t)$ (3)\nFor $H(p_\\theta)$, the model trusts its own prediction more with a more confident prediction, i.e., lower entropy. For Time(t), it allows the model to progressively trust its self-knowledge as training goes. We use a schedule (Bengio et al., 2015) to increase Time(t) as a function of the training iteration t and T is the number of total iterations.\n$Time(t) = \\frac{1}{1 + exp(-\\beta (\\frac{t}{T} + \\alpha))}$ (4)\nwhere $\\alpha$ and $\\beta$ are hyper-parameters. In general, at the beginning of training, the model is not well-trained, and a small Time(t) controls the model to rely more on the ground-truth data than its own prediction. As training progresses, the increasing Time(t) allows the model to trust more in its own reliable prediction.\nSharpen the Model Prediction. To overcome the overly uncertain model prediction on learning towards the new target in Equation 2, we sharpen the model prediction distribution by controlling the softmax temperature $\\tau$ in $p_\\theta = \\frac{exp(z_i / \\tau)}{\\sum_{j=1}^V exp(z_j / \\tau)}$. We control $\\tau$ in a fixed way and a dynamic way to vary it inversely with Time(t). Therefore, $\\tau$ gradually decreases as training time goes: a higher $\\tau$ at the early stage of training can prevent the model from converging and a smaller $\\tau$ in the later stage makes the model more confident in its output. In Section 5, we compare the performance of both fixed and dynamic $\\tau$ to self-correct the data noise, and also show the impact of varying $\\tau$ in Section 5.2.3.\nTraining. After acquiring a new target $\\bar{q}(y_i)$, derived from both the true data and peakier model prediction distributions, we will obtain a new training objective based on maximum likelihood estimation (MLE). The following loss function is minimized for every training token over the training corpus D:\n$L_\\theta(x, y) = E_{y_i\\sim D} [-\\bar{q}(y_i) log p_\\theta(\\cdot|y_{<i}, x)]$ (5)"}, {"title": "Experiments", "content": "In this section, we investigate the effectiveness of our self-correction method for translation in two experiment settings: (1) simulated noise (Section 5.2), and (2) real-world noise (Section 5.3). For simulated noise, we conduct experiments by injecting two types of noise, raw-crawl data and simulated misaligned noise, into clean translation data. For the real-world noise, we perform experiments on web-mined datasets, i.e., ParaCrawl and CCAligned, across eight language pairs."}, {"title": "Comparing Systems", "content": "We compare our self-correction method with the following comparing systems. Note that all the models' details are in line with the corresponding baselines. For pre-filter methods, the training data size is determined by the number of sentence pairs to filter. For data truncation and our self-correction method, both of them use the full training corpus."}, {"title": "Pre-Filtering", "content": "We select two widely-used data filters: Laser and Comet. We rank the training sentence pairs based on the scores calculated by the filter models. For the simulated noise experiments (Section 5.2), we filter out the sentence pairs with the lowest scores before training, matching the size to the injected data noise. For the real-world noise experiments (Section 5.3), we filter out 20% of the sentence pairs with the lowest scores."}, {"title": "Truncation", "content": "We compare two truncation methods: (1) loss truncation (Kang and Hashimoto, 2020), (2) error norm value (el2n) truncation (Li et al., 2024). Following (Li et al., 2024), we choose the best result among three truncation fractions {0.05, 0.1, 0.2} for both loss-fraction and el2n-fraction truncation. We select the best result among three threshold values {1.3, 1.35, 1.4} for el2n-threshold truncation."}, {"title": "Simulated Noisy World", "content": "We conduct experiments on both high- and low-resource translation tasks. We use the WMT2017 (German) De\u2192En news translation data as the high-resource task and En\u2192Si (Sinhala) from OPUS as the low-resource task. Following Herold et al. (2022), we inject noise by replacing a portion (10%, 30%, 50%) of the clean training corpus with simulated misalignment noise or raw crawl data. The misalignment noise is generated by Algorithm 1 from the replaced portion of the clean corpus. Each translation task randomly selects the raw crawl data from the raw Paracrawl corpus."}, {"title": "Results", "content": "Tables 3 and 4 show the high-resource De\u2192En and the low-resource En\u2192Si translation performance trained on the corpus with misalignment noise or raw crawl data. Overall, the baseline model's BLEU scores gradually drop with increasing levels of both simulated and real-world noise.\nWhen applying pre-filter methods under simulated noisy settings, they can achieve modest gains for both simulated misalignment and the raw-crawl data. Compared with the upper-bound oracle results when the model trained with the remaining correct clean data, pre-filters notably fall short, especially in the highly (50%) noisy setting. This performance discrepancy underscores the challenge of pre-filters in accurately distinguishing simulated misalignment noise from clean data, aligning with our findings on the low filter accuracy for misalignment noise in Table 2.\nFor truncation methods, $el2n$ truncation shows better performance gains than loss truncation, indicating the effectiveness of using the whole model prediction distribution to estimate data quality rather than the sole prediction probability of the ground-truth token. However, with an increasing level of noise, $el2n$ truncation can only achieve minimal or even no improvement, showing its limitation in distinguishing clean and noisy tokens in a highly noisy training environment. In this case, removing tokens with larger $el2n$ values leads to a loss of clean and important training data.\nInstead, our self-correction method consistently improves both low- and high-resource translation performance under different controlled simulated noise settings and outperforms other systems in most scenarios. Even when injecting 50% of noise, e.g., misaligned-Laser, our self-correction method still improves over 2 BLEU points over the low-resource baseline, and nearly 1 BLEU points over the high-resource baseline. This shows the necessity of keeping the human reference information for the data sensitive scenarios, and the idea of \"revising\" instead of \"removing\" can achieve this goal. Moreover, instead of solely relying on flawed human reference, our method demonstrates the effectiveness of using the system-generated translation. This finding supports the hypothesis on the limited effectiveness on training models exclusively towards the reference especially when it is inferior to the model generated translation (Xu et al., 2024)."}, {"title": "Analysis", "content": "Here, we aim to analyze whether the self-correction method revises the noisy samples and also maintains the performance of clean parallel data. We sample 1K clean and misaligned-Laser sentence pairs from the De\u2192En training corpus and record their BLEU scores during different training epochs from baseline and self-correction model. For the misaligned-Laser, we calculate the BLEU scores according to their parallel true references. Figure 4 (Left) shows that self-correction model can correct the misalignment noise by improving BLEU points compared to the baseline model. In the meantime, the self-correction model maintains the clean parallel data performance as the baseline model without hurting the clean training information, shown in Figure 4 (Middle). This further explains the superiority of self-correction method than pre-filter or data truncation from avoiding to discard the clean and useful training data."}, {"title": "The Impact of Sharpening Model Prediction.", "content": "Here, we aim to analyze the impact of sharpening model prediction distribution to correct the ground truth on translation performance. We train the self-correction models on De\u2192En task with 30% of different types of noise, with varying values of softmax temperature $\\tau$. From figure 4 (right), we show that using sharpening model prediction distribution with a smaller $\\tau$ achieves better translation performance for all noisy settings. However, the optimal $\\tau$ varies when training with different types of noise, and thus increases the difficulty of selecting a fixed $\\tau$ for different scenarios. This motivates us to design a dynamic $\\tau$, which varies automatically in a low range of entropy state over training time. The overall performance in both Section 5.2 and Section 5.3 by using a dynamic $\\tau$ also shows its general applicability for different noise scenarios."}, {"title": "Real Noisy World", "content": "We investigate two noisy web-crawled datasets: Paracrawl V7.1 and CCAligned V1.0. These two datasets exhibit varying levels of semantic misalignment rates across different language pairs (Kreutzer et al., 2022). For each dataset, we select four language pairs from high- to low-resource with varying levels of misaligned noise rate. For Paracrawl, the language pairs are: en\u2192fr (French), en\u2192ru (Russian), en\u2192si (Sinhala), and en\u2192km (Khmer). For CCAligned, the language pairs are: en\u2192tr (Turkish), en\u2192es (Spanish), en\u2192be (Belarusian), and en\u2192ht (Haitian). For the high-resource language pairs: en\u2192fr, en\u2192ru, en\u2192tr, en\u2192es, we randomly sample 5M sentence pairs as the training corpus. For medium and low-resource language pairs, we use the original corpus size. The validation and test sets for all tasks are from Flores101."}, {"title": "Results", "content": "Table 5 shows the translation performance for two noisy web-crawled datasets, CCAligned V1.0 and Paracrawl V7.1, across eight language pairs with varying corpus size and misaligned rates.\nOverall, our self-correction method consistently outperforms other alternative methods, including pre-filter and data truncation, with up to 1.2 BLEU and 2.0 ChrF++ points improvement over the baseline. In line with the findings in the simulated noisy experiment 5.2, we also show that pre-filter and truncation methods can achieve performance gains for high-resource tasks while limited in the low-resource tasks with high misalignment rate e.g., en\u2192ht, en\u2192si and en\u2192km. Both of the pre-filter and truncation cannot help and even hurt the low-resource translation performance. This further emphasizes the importance of keeping ground-truth supervision for the real-world noisy low-resource tasks. For our self-correction approach, it shows superior performance especially for low-resource tasks with high misaligned rates, indicating its effectiveness in handling real-world data noise in different scenarios. Apart from data pruning, our method provides new insight on handling text noise by correcting particularly for low-resource tasks."}, {"title": "Conclusion", "content": "In this paper, we aim to address the data quality issues in the web-mined parallel corpus by proposing a noise-handling self-correction approach for machine translation tasks. Our approach focuses on the translation model's training dynamics and revises the training supervision from the ground-truth data by the model's prediction distribution.\nTo evaluate our approach in different noisy settings, we take a deep look at the primary noise source in web-mined parallel data, i.e., semantic misalignment. To quantitatively analyze the impact of real-world misalignment, we propose a process to simulate the misalignment controlled by semantic similarity. Under our simulated noisy training environment, we demonstrate that our self-correction method consistently improves the baselines with different levels of misalignment noise. Moreover, we also show that our self-correction method can effectively handle naturally occurring noise in the real-world noisy web-mined datasets across eight translation tasks, outperforming other alternative approaches, including pre-filter and data truncation. Our work also provides a critical finding on the effectiveness of leveraging the system-generated translation instead of solely relying on flawed reference data."}, {"title": "Limitation", "content": "First, we acknowledge that our work aims at learning with noisy training corpus, therefore, improvements on high-quality training datasets might be limited. Second, our work focuses on \u201ctraining from scratch\u201d for translation models, while future works can apply our method to more NLP tasks and settings, including the pre-training or fine-tuning stage for text generation. Third, we only focus on the primary source of noise, i.e., misaligned sentences, on machine translation. Even we show the effectiveness of our approach on the real-world raw crawl data which contains naturally occurring data noise, future work can fine-grained evaluate our approach on other types of noise e.g., wrong language or misordered sentences."}, {"title": "Data Filters", "content": "Comet is a neural framework for training machine translation evaluation models that can function as metrics (Rei et al., 2020). Their framework uses cross-lingual pre-trained language modeling that exploits information from both source input and target reference to predict the target translation quality. We use the reference-free wmt-20-qe-da Comet model as the data filter to score each sentence pair in the training corpus.\nFor Laser, it scores sentence pairs based on cross-lingual sentence embeddings. To calculate the Laser score for each sentence pair, we generate cross-lingual sentence embeddings using the pre-trained model from Artetxe and Schwenk (2018). The underlying system is trained as a multilingual translation system with a multi-layer bidirectional LSTM encoder and an LSTM decoder, without information about the input language on the encoder. The output vectors of the encoder are compressed into a single embedding of fixed length using max-pooling, which is the cross-lingual sentence embedding resulting from the Laser model. The assumption is that two sentences with the same meaning but from different languages will be mapped onto the same embedding vectors. We calculate the cosine similarity score between source and target sentence embeddings as the Laser score. The higher the Laser score, the more semantic similar between the source and target sentence.\nFor Bi-Cleaner, it is a tool in Python that aims at detecting noisy sentence pairs in a parallel corpus. It indicates the likelihood of a pair of sentences being mutual translations. Sentence pairs considered high-quality are scored near with 1 and considered as noisy are scored with 0. We use the multilingual model  from HuggingFace for the pre-filter for all language tasks."}, {"title": "Controlled Generated Misaligned Noise", "content": "Algorithm 1 shows the method to generate misaligned noise, controlled by two steps: (1) surface-level features control by word overlap and sentence length; (2) quality control by Laser or Comet."}, {"title": "Algorithm 1 Misaligned Noise Generation", "content": "Input: A chunk of parallel and de-duplicate clean data D with N sentence pairs, source and target (S,T); A threshold k for selecting misaligned candidates; A quality controlled model M \u2208 {Laser, Comet}\nOutput: Misaligned data D with N sentence pairs source and misaligned target (S,T).\nfor each source sentence si in S do\nStep 1: Surface-level Features Control\nInitialize a list L of misaligned candidates for si\nfor each target sentence $t_j(j\\neq i)$ in T do\nif len(L) <k then\nif | len($t_j$) \u2013 len($s_i$)| < 3 and word overlap ratio($t_j$, $t_i$) > 0.4 then\nAppend $t_j$ to list L\nend if\nend if\nend for\nStep 2: Quality Control\nInitialize a quality score list Q\nfor each candidate $t_n$ in L do\nscore($s_i$, $t_n$) = M($s_i$,$t_n$)\nAppend score to list Q\nend for\nSelect $t_k$ from L with the highest score in Q\nAppend the pair ($s_i$, $t_k$) to the misaligned data D\nend for"}, {"title": "Misaligned Noise Samples", "content": "Table 6 shows the simualted misaligned samples of misaligned-laser and misaligned-comet. Overall, the simulated misaligned noise controlled by external models all share certain amounts of semantic meanings compared with the true reference."}, {"title": "Human Evaluation of Misaligned Noise"}]}