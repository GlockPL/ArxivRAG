{"title": "Independence Constrained Disentangled Representation Learning from Epistemological Perspective", "authors": ["Ruoyu Wang", "Lina Yao"], "abstract": "Disentangled Representation Learning aims to improve the explainability of deep learning methods by training a data encoder that identifies semantically meaningful latent variables in the data generation process. Nevertheless, there is no consensus regarding a universally accepted definition for the objective of disentangled representation learning. In particular, there is a considerable amount of discourse regarding whether should the latent variables be mutually independent or not. In this paper, we first investigate these arguments on the interrelationships between latent variables by establishing a conceptual bridge between Epistemology and Disentangled Representation Learning. Then, inspired by these interdisciplinary concepts, we introduce a two-level latent space framework to provide a general solution to the prior arguments on this issue. Finally, we propose a novel method for disentangled representation learning by employing an integration of mutual information constraint and independence constraint within the Generative Adversarial Network (GAN) framework. Experimental results demonstrate that our proposed method consistently outperforms baseline approaches in both quantitative and qualitative evaluations. The method exhibits strong performance across multiple commonly used metrics and demonstrates a great capability in disentangling various semantic factors, leading to an improved quality of controllable generation, which consequently benefits the explainability of the algorithm.", "sections": [{"title": "1 Introduction", "content": "Representation learning is widely recognized as a fundamental task in the field of machine learning, as the efficacy of machine learning methods heavily relies on the quality of data representation. It is suggested that an ideal representation should be disentangled [1], which means it can identify the genuine generative factors hidden in the observed data, and the latent variables should be semantically meaningful and correspond to the ground truth generative factors."}, {"title": "2 Our Method", "content": ""}, {"title": "2.1 A Perspective of Epistemology", "content": "As discussed in Section 1, comprehending the relationships between latent variables in disentangled representation learning necessitates an understanding of how humans perceive these factors. Because the concept of interpretability inherently implies interpretability to humans; therefore, interdisciplinary insights from epistemology are indispensable in this context.\nIn epistemology, mental representations of perceptions are called ideas, which can be grouped into two categories, simple ideas and complex ideas [15]. Simple ideas are basic, indivisible concepts that form the foundation of our knowledge, and complex ideas are more advanced concepts that are built upon multiple simple ideas. For instance, when we imagine an apple (Figure 2a), the sensory perceptions of an apple such as its colour, shape and taste are irreducible, and thus are regarded as simple ideas. These simple ideas can then be combined to form the complex idea of an apple as a whole.\nTaking these theories as a reference, we argue that the disagreement regarding whether latent variables should be independent arises from the lack of understanding of this hierarchical structure of human concepts. Existing works instinctively consider ALL latent variables in a single latent space. However, building upon these interdisciplinary theories, we contend that interpretable latent variables in disentangled representation learning should also follow a hierarchical structure in a similar way as demonstrated in Figure 2a."}, {"title": "2.2 Two-level Latent Space Framework", "content": "Inspired by the interdisciplinary theories introduced in Section 2.1, we propose a two-level latent space framework to consolidate prior arguments on the interrelationships between the latent variables, as illustrated in Figure 2b."}, {"title": "2.3 Method Formulation", "content": "After clarifying the legitimacy of applying independence constraints in this problem in Section 2.2, we introduce our proposed method in this section. We build our method in the paradigm of Generative Adversarial Networks (GAN). Formally, GAN solves the minimax optimization problem (Equation 1) by utilizing a generator $G$ and a discriminator $D$, and the generator $G$ could learn the real data distribution $P_{real}(x)$ when this framework converges.\n$\\min_{G} \\max_{D} L_{GAN}(D,G) = E_{x \\sim P_{real}} [log D(x)] + E_{z \\sim noise} [log(1 - D(G(z)))]$ (1)\nHowever, this framework imposes no restrictions on the semantic meaning of the latent variable $z_i$. To encourage the latent variables to possess semantic meanings, as introduced in Section 1, we apply the two constraints in this framework: 1) Mutual information between the latent variables and the data [8]; and 2) Independence between the latent variables [17,7].\nFor the constraint on mutual information, we adapt the implementation of InfoGAN [8]. First, the latent variables are decomposed into latent code $z$ which controls the semantics in the image, and noise $\\epsilon$ which is considered incompressible. Then, an auxiliary network $Q$ is introduced into the framework to maximize the lower bound of mutual information between the latent code $z$ and the image (Equation 2). In practice, a regularization term $L_I(G, Q)$ (Equation 5) is introduced into the framework to maximize the Mutual Information between latent variable $z$ and the generated data.\n$I(z, G(z, \\epsilon)) \\ge E_{x \\sim G(z,\\epsilon)} [E_{z' \\sim P(z\\vert x)} log Q(z'\\vert x)] + H(z)$ (2)\nOn the other hand, for the independence constraint, we aim to minimize the Total Correlation [34] between latent variables, and apply this constraint to the learned latent code $z$ such that:\n$TC(z) = KL(q(z) \\vert\\vert \\prod_{i} q(z_i))$ (3)\nwhere $z$ is the samples drawn from the learned posterior distribution obtained by $Q(G(z))$. Therefore, by integrating these two constraints, the overall objective of our method becomes:\n$\\min_{G,Q} \\max_{D} L_{TCGAN} = L_{GAN}(D,G) - \\lambda L_I(G, Q) + \\beta L_{TC}(G, Q)$ (4)\nwhere\n$L_I(G, Q) = E_{z \\sim P(z),x \\sim G(z,\\epsilon)} [log Q(z\\vert x)]$ (5)\n$L_{TC}(G, Q) = KL(q(z) \\vert\\vert \\prod_{i} q(z_i))$ (6)\nThus far, we have formulated our method by integrating the two constraints in the paradigm of Generative Adversarial Network. However, the total correlation term (Equation 6) is intractable. In Section 2.4, we introduce the method to estimate this term and how this estimation process is integrated into our framework, then give an end-to-end illustration of our method."}, {"title": "2.4 Total Correlation Estimation", "content": "To estimate the Total Correlation term (Equation 6), we adapt the method from FactorVAE [17]. Specifically, we utilize the Density-Ratio trick, which trains a Total Correlation Discriminator $TCD$ to predict the probability that the input vector is from $q(z)$ rather than $\\prod_{i} q(z_i)$, and then the Total Correlation term can be estimated by Equation 7.\n$TC(z) = E_{q(z)} log \\frac{q(z)}{\\prod_{i} q(z_i)} \\approx E_{q(z)} log \\frac{TCD(z)}{1 - TCD(z)}$ (7)\nThe end-to-end framework of our method is illustrated in Figure 3. On top of the vanilla GAN framework which comprises a generator $G$, a data encoder $E$ and a Discriminator head $D$, we first utilize an auxiliary network $Q$ to predict the mean and variance of the latent variables of the generated data, as implemented in InfoGAN [8]. Then, we sample $z$ by utilizing a reparametrization trick to ensure the differentiability of the framework. By employing this approach, we acquired samples from the distribution $q(z)$. On the other hand, samples from $\\prod_{i} q(z_i)$ cannot be sampled directly, so we adapt the permute-dim algorithm proposed in [17] to do the sampling, where the samples are drawn by randomly permuting across the batch for each latent dimension. Therefore, the input of our framework should be two randomly selected batches of latent variables, one of which is used to calculate the mutual information loss $L_I$ and sample from $q(z)$, another batch is used to sample from $\\prod_{i} q(z_i)$ in order to estimate the total correlation loss $L_{TC}$."}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Experiment Setting", "content": "We evaluate the performance of our method from two perspectives: (1) Quantitative Evaluation (Section 3.2), where we compare our method with several baseline methods on multiple commonly used metrics for Disentangled Representation Learning; and (2) Qualitative Evaluation (Section 3.3), where we conduct Latent Space Traversal Test and compare our results with the case without the enforcement of independence constraint, to observe the direct impact of our method on the generated images.\nWe follow the settings in previous works on the model architectures of the Generator, Discriminator [22] and the Total Correlation Discriminator [17]. We use the Adam optimizer for training, with a learning rate equal to 0.001 for the generator, 0.002 for the discriminator and TC discriminator. We use $\\alpha = 0.1$ and $\\beta = 0.001$ in Equation 4. The latent dimension equals 10. We used a batch size of 64 and trained the model for 30 epochs, then selected the checkpoint with the highest Explicitness score for evaluation on other metrics."}, {"title": "3.2 Quantitative Evaluation", "content": "Since the quantitative evaluation of disentanglement requires ground-truth labels of all generative factors, most datasets are not suitable for quantitative evaluation. Therefore, following previous works in this domain, we concentrate on dSprites [24] for quantitative evaluation, where all factors are well-defined.\nMetrics We evaluate the quality of disentanglement by several metrics proposed in recent literature, including 1) Explicitness Score [28] which evaluates the quality of disentanglement by training a classifier on latent code to predict the ground-truth factor classes, a higher Explicitness Score indicates that all the generative factors are decoded in the representation; 2) JEMMIG Score [9] which evaluates the quality of disentanglement by estimating the mutual information (MI) between the ground-truth generative factors and the latent variables; 3) Modularity Score [28] which measures whether one latent variable encodes no more than one generative factor, it estimates the mutual information (MI) between a certain latent variable and the factor with maximum MI and compares it with all other factors; 4) SAP Score [20], which evaluates the quality of disentanglement by training a linear regression model for every pair of latent variables and ground-truth factor, and uses the $R^2$ score of the regression model to denote the disentanglement score; and 5) Z-diff [14] which first selects pairs of data points with the same value on a fixed latent variable, and then evaluates the quality of disentanglement by training a classifier to predict which factor was fixed. We used the code provided by [4] for all evaluation metrics.\nBaselines We compare our method with several baseline methods in the domain of Disentangled Representation Learning, which include VAE [19], $\\beta$-VAE [14], AnnealedVAE [3], Factor-VAE [17], $\\beta$-TCVAE [7], InfoGAN [8], IB-GAN [16], and InfoGAN-CR [22]. For the VAE-based baseline methods [19,14,3,17,7], we reproduce the results by the code provided in [10] with the suggested optimized parameters. In particular, we use a batch size of 64 for all experiments and train the model for 30 epochs then select the checkpoint with the highest Explicitness score for evaluation. We use the model architecture suggested in [3] and use a latent dimension equal to 10 for all methods. For $\\beta$-VAE [14], we train the model with $\\beta$ equal to 4. For Annealed VAE [3], we set the capacity equal to 25. For factor VAE and $\\beta$-TCVAE, we use the weight of 6.4 for the total correlation term. On the other hand, for baseline methods based on GAN [8,22,16], we reproduce the result with the exact parameters and model architecture provided in the corresponding paper and code."}, {"title": "3.3 Qualitative Evaluation by Latent Space Traversal Test", "content": "While the datasets suitable for quantitative evaluation are limited, we further evaluate our method on other datasets by conducting Latent Space Traversal Tests. Latent space traversal test is a commonly used technique to investigate the semantic meaning of latent variables. It traverses one latent variable while keeping all the other variables invariant, and generates a sequence of images with these features. The semantic meaning of the traversed variable can be obtained by inspecting the changes in the images.\nIn our experiments, since we aim to improve the quality of disentanglement, we examine whether the changes in one variable affect more than one generative factor. If the traversed variable affects only one semantic meaningful factor, it means the quality of disentanglement is desirable. In contrast, if the traversed variable affects more than one semantic meaningful factor, it means the factors are still entangled in the latent space.\nTo this end, we make comparisons between the cases with/without the enforcement of the proposed independence constraint and directly observe the impact of implementing our method. To ensure fair comparisons, all the settings remain the same except for the total correlation loss $L_{TC}$ (Equation 6) in each pair of comparisons. These comparisons are conducted on three datasets: MNIST, FashionMNIST and dSprites. For all three datasets, the settings remain unchanged as introduced in Section 3.1, except for the dimension settings of the latent space, because the number of generative factors contained in each dataset is different. This will be further elaborated in each paragraph below.\nMNIST We trained the models with 1 ten-dimensional discrete variable, 2 continuous variables, and 62 noise variables. The ideal outcome of Disentangled Representation Learning is that the data encoder will map the discrete variable to the digit class, and the two continuous variables will correspond to the width and rotation of the digit. The results of our experiment are provided in Figure 1. In each row, we keep the discrete variable digit invariant, and traverse on the continuous variable rotation. When the model is trained without the independence constraint (Figure la), we observe that: 1) The variables digit class and rotation are not fully disentangled in the latent space. For example, while we control the digit to be 5 on the fifth row, some 0 and 6 are generated when traversing on rotation; and 2) the variables width and rotation of the digit are not fully disentangled in the latent space. For example, as highlighted in the first row of Figure la, while we only traverse the variable rotation, the width of the digit is also affected. We highlight this trend on the first row, and similar patterns can be observed on other rows. In contrast, with the enhancement of the independent constraint (Figure 1b), both digit and width remain unchanged when traversing on rotation.\ndSprites We trained the models with 5 continuous variables, and 5 noise variables. Ideally, the five continuous variables will be mapped to the five generative factors of the dataset, which include Shape, Scale, Rotation, Pos X and Pos Y. The results of our experiment are provided in Figure 4. On each row of the images, we traverse one factor while keeping all other factors invariant as noted on the left side of each row. When the model is trained without the independence constraint (Figure 4a), we observe that the factors are entangled in the latent space. For example, on the third row of the image, while traversing the factor of rotation, the shape of the figures are affected. And on the fourth row, rotation is affected while traversing the Position X. In contrast, with the enhancement of the independent constraint (Figure 4b), these factors are not affected, as highlighted by red boxes in Figure 4.\nFashionMNIST We trained the models with 1 ten-dimensional discrete variable, 1 continuous variable, and 62 noise variables. Ideally, the discrete variable and the continuous variable will correspond to the item class and the thickness of the image. The results of our experiment are provided in Figure 5. A similar conclusion can be drawn as we did on other datasets above. On each row, we keep the discrete variable item class invariant, and traverse on the continuous variable thickness of the image. When the model is trained without the constraint of the independence between latent variables (Figure 5a), we observe that the item is affected by variable thickness, as highlighted on the second row and the fourth row. In contrast, the item type remains unaffected when the model is trained with the enhancement of the independent constraint (Figure 5b).\nSummary Based on these comparisons, we conclude that our method could consistently enhance the quality of disentanglement. Note that this does not mean our method could always disentangle all the factors perfectly, however, while some factors may still exhibit slight entanglement in the given images, the differences between the cases with/without the independence constraint are nontrivial, which validates the effectiveness of our method."}, {"title": "4 Related Works", "content": ""}, {"title": "4.1 Disentangled Representation Learning", "content": "Disentangled Representation Learning aims to learn a data encoder that can identify true latent variables that are semantically meaningful. [14] suggested that increasing the weight of the KL regularizer in VAE [19] can benefit the quality of disentangled representation learning. [3] proposed that disentanglement quality can be improved by progressively increasing the bottleneck capacity. FactorVAE [17] and $\\beta$-TCVAE [7] both penalize the total correlation [34] between latent variables, while FactorVAE uses density-ration trick for total correlation estimation, B-TCVAE proposed a biased Monte-Carlo estimator to approximate total correlation. Several other methods were also proposed in the paradigm of VAE [20,11,18]. However, [23] claimed that unsupervised disentangled representation learning is impossible without inductive biases.\nOn the other hand, some methods are proposed to learn disentangled representation in the paradigm of GAN [12,40]. InfoGAN [8] proposed a method to learn disentangled representation by maximizing the mutual information between latent variables and the generated image. InfoGAN-CR [22] claimed that self-supervision techniques can be used to improve the quality of disentanglement. IB-GAN [16] utilized the Information Bottleneck framework for the optimization of GAN. Besides, some methods attempted to learn disentangled representations without utilizing generative models[32].\nRecently, diffusion models have been applied to the domain of disentangled representation learning [36,5,6]. Additionally, disentangled representation learning has found broad applications in areas such as graph representation learning [21], graph neural architecture search [39], recommendation systems [38,33], and out-of-distribution generalization [37]."}, {"title": "4.2 Causal Representation Learning", "content": "Recent studies are aimed at connecting the field of causal inference and disentangled representation learning. [31] introduced a causal perspective of disentangled representation learning by modelling the data generation process as a Structural Causal Model (SCM) [26], where they introduced a set of confounders that causally influence the generative factors of observable data. [27] further developed this idea and studied the role of intervention and counterfactual effects. CausalVAE [35] introduced a fully supervised method that builds a Causal Layer to transform independent exogenous factors into causal endogenous factors that correspond to causally related concepts in the observed data. And DEAR [30] proposed a weakly supervised framework, which learns causally disentangled representation with SCM as prior."}, {"title": "5 Conclusion", "content": "In this paper, we investigated the prior disagreement on the interrelationships between latent variables in Disentangled Representation Learning, and proposed a novel method to improve the quality of disentanglement. First, we build a conceptual bridge between epistemology and disentangled representation learning, thus clarifying what should and should not be independent in the latent space by introducing a two-level latent space framework based on interdisciplinary theories. Then, after clarifying the legitimacy of applying the independence constraint on the problem of Disentangled Representation Learning, we introduce a novel method that applies the mutual information constraint and independence constraint within the Generative Adversarial Network (GAN) framework. Experiments show that our method consistently achieves better disentanglement performance on multiple evaluation metrics, and Qualitative Evaluation results show that our method leads to an improved quality for controllable generation. Besides, our paper introduced a novel perspective to apply causal models to the field of representation learning, which facilitates the development of explainability of deep learning and holds potential for wide-ranging applications that value explainability, transparency and controllability."}]}