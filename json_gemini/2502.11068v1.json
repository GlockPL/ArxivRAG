{"title": "Accelerating Anchors via Specialization and Feature Transformation", "authors": ["Haonan Yu", "Junhao Liu", "Xin Zhang"], "abstract": "Anchors is a popular local model-agnostic explanation technique whose applicability is limited by its computational inefficiency. To address this limitation, we propose a pre-training-based approach to accelerate Anchors without compromising the explanation quality. Our approach leverages the iterative nature of Anchors' algorithm which gradually refines an explanation until it is precise enough for a given input by providing a general explanation that is obtained through pre-training as Anchors' initial explanation. Specifically, we develop a two-step rule transformation process: the horizontal transformation adapts a pre-trained explanation to the current input by replacing features, and the vertical transformation refines the general explanation until it is precise enough for the input. We evaluate our method across tabular, text, and image datasets, demonstrating that it significantly reduces explanation generation time while maintaining fidelity and interpretability, thereby enabling the practical adoption of Anchors in time-sensitive applications.", "sections": [{"title": "1. Introduction", "content": "Anchors (Ribeiro et al., 2018) is a popular local model-agnostic machine learning explanation technique, which generates rules that form a sufficient condition to explain why a model makes a certain prediction for a given input. It is local in the sense that it explains a machine learning model's behavior around a particular input, which makes it able to scale to complex models in critical domains such as healthcare and finance, where understanding individual predictions is vital for decision-making and validation. It is model-agnostic in the sense that it does not exploit internal design of a model, which makes it applicable to a wide range of machine learning models. These distinct features make Anchors adopted in many important applications, such as explaining a triage-prediction system for COVID-19 to enable knowledge discovery about patient risk factors (Khanna et al., 2023), and analyzing Existing Vegetation Type to uncover insights for ecological patterns and land management (Ganji & Lin, 2023). However, a significant bottleneck hinders its widespread application: the inherent computational inefficiency. The interpretation time for a single input of Anchors can last for several hours in certain scenarios, impeding the practical deployment of Anchors in real-time applications where prompt explanations are crucial.\nIn this paper, we attempt to find a method to improve the computational efficiency of Anchors without compromising the quality of the generated explanations. In short, our work is a two-step rule transformation process that accelerates Anchors by leveraging pre-trained explanations from representative inputs. Specifically, horizontal transformation adapts pre-trained rules to similar online inputs, while vertical transformation refines these rules to achieve the required precision and coverage for high-quality explanations. We make two key observations: 1) most of Anchors' computation time is spent in drawing samples that are variants of the input to explain upon, and 2) Anchors draw samples in an iterative manner to build the explanation incrementally that becomes more and more specific to the current input. Based on these two observations, we propose a method to improve the computation efficiency of Anchors: we pre-train explanations for representative pre-training inputs in advance, and then during online computation, for an online input, start the iterative computation process with a pre-trained explanation that is obtained from a similar pre-training input, thereby reducing the time spent in drawing samples.\nHowever, our method faces two major challenges: 1) The decision boundaries of the model being explained in these neighborhoods may differ. Therefore, explanations that are effective for pre-training inputs may not be effective for online inputs. 2) For two similar but not identical inputs, their features are not completely consistent. Consider the example in Table 1, where pre-trained sample x1 and input sample x2 do not share the same features, although their explanations are very similar. Since Anchors generate explanations by using features in its rules, explanations applicable to pre-trained inputs may not necessarily be applicable to new inputs. Consequently, the rules generated from 21 cannot initiate explanations for 22."}, {"title": "2. Background", "content": "This chapter provides the necessary background knowledge that is integral to understanding our approach. We first describe the form of Anchors' explanation and then its underlying algorithm."}, {"title": "2.1. Representation of Anchors' Explanations", "content": "Before diving into the symbolic representation of Anchors' explanation, we introduce several definitions.\nThe target model $f$ is defined as a function $f : X \\rightarrow Y$, where $X$ includes a variety of data types such as text, tabular, and images, collectively known as the input domain. $Y$ represents the model's predicted outcome. Our discussion will focus on classification tasks, meaning $Y$ refers to the categories' labels. In this context, the target model can be considered a \"black box\u201d, producing outputs (i.e., prediction results) from given inputs via an unknown process. Given the target model $f$ and an instance $x \\in X$, the aim of Anchors is to explain the rationale behind $f(x)$ to a user, where $f(x)$ is the individual prediction for the instance $x$.\nAn instance $x$ is composed of several features, formally expressed as $x = (x_1,x_2,...,x_n)$. Here, $n$ represents the number of features of $x$, denoted as $n_x$, and for all $i \\in \\{1,2,..., n_x\\}$, $x_i$ is the $i$-th feature of input $x$.\nLet $R$ be a rule consisting of one or more predicates, where each predicate corresponds to a constraint on a feature. The rule $R(x) = 1$ if the input $x$ satisfies all predicates in $R$. In this case, we say that the rule $R$ covers the input $x$.\nSimilar to the cases of many other local model-agnostic explanation techniques, a perturbation model is used to obtain the local decision boundary of the target model by sampling inputs that are similar to the target input. Let $D_x(\\cdot)$ be the distribution of inputs obtained via the perturbation model and the $D_x(\\cdot|R)$ be the distribution conditioning on"}, {"title": "2.2. The Algorithm of Anchors", "content": "Now, we will present the algorithm of Anchors, since our method involves algorithmic changes to Anchors.\nAs shown in Figure 2, from the input to generate the output rule, Anchors mainly consists of the following four steps:\n1. It generates a set of available predicates IP based on the input $x$.\n2. It adds each predicate $p$ from the predicates set $P$ that has not yet appeared in a rule named $R_0$ (which initially contains no predicates) to form the candidate rule set $R$. It Uses the KL-LUCB algorithm (Kaufmann & Kalyanakrishnan, 2013) to determine the sample number $M$, and feeds $R*, M$, and $x$ into the perturbation model to generate the neighborhood $D_r$ of the input $x$. Then it calculates coverage and precision of all the rules in rule set $R$ using $D_r$.\n3. If the precision of any rule is no less than $\\tau$, it returns a rule that has the maximum coverage among all rules satisfying the precision requirement. Otherwise, it sets $R_0$ to be the rule with the highest precision and continues to Step 2.\nIt can be seen that after each iteration, one predicate is added to the rule $R$. As mentioned earlier, with the increase in the number of predicates in $R$, the number of inputs it can cover will decrease, while the probability that the prediction results of the covered inputs are the same as the original input's will increase. In other words, during the iteration process, the coverage will gradually decrease while the precision will gradually increase, and the rule $R$ will gradually transform from a \"general\" explanation to a \"specific\" explanation for a particular input."}, {"title": "3. Approach", "content": "Our approach attempts to reduce the online time cost of Anchors by pre-calculating explanations for some representative samples using Anchors during the pre-training phase. When applying Anchors to a new input online, our approach first selects the pre-training input which is most similar with the online input. Then it uses a horizontal transformation, transforming the pre-trained result of the selected pre-training input into a rule composed of features of the online input. At last, through a vertical transformation, the obtained rule is further expanded until the required precision is satisfied. We next explain each step in detail."}, {"title": "3.1. Offline Pre-Training", "content": "Algorithm 1 outlines the pre-training phase of our approach, which takes an input set X and a model f as input and outputs a set of rules. It also takes two parameters. The parameter N specifies the number of inputs to generate rules on. This parameter is needed as it can be too computationally expensive to generate rules for every input in X so the algorithm chooses N representative inputs instead. The other parameter $\\tau$ specifies the precision requirement for Anchors during pre-training, which balances the precision and coverage of the generated rules. The higher $\\tau$ is, the more precision and the lower coverage the generated explanation rule has. To generate general rules, the pre-training phase uses a lower precision threshold compared to the online explanation phase.\nIn Line 4, the algorithm uses the K-means clustering algorithm (Krishna & Narasimha Murty, 1999) to identify N clusters and selects their centroids as representative inputs (stored in $X_{pre-train}$). In Line 6-9, the algorithm iterates through each input in $X_{pre-train}$ and apply Anchors with specified precision threshold $\\tau$ to generate explanation rules. Finally, the algorithm returns the pre-training input set and all the corresponding generated explanation rules in line 10."}, {"title": "3.2. Online Refinement", "content": "Algorithm 2 outlines the online refinement phase of our approach. It takes an input $x$, a model $f$, the pre-training dataset $X_{pre-train}$, and the corresponding pre-trained rules IR as input. Additionally, it has a parameter $\\tau$, which controls the Anchors explanation precision as in Algorithm 1. However, the $\\tau$ used here is set to a higher value compared to Algorithm 1 because we need to return a more specific rule to the user. The output of the Algorithm 2 is consistent with Anchors, producing an explanation R for the input x and the model f.\nNext, we discuss the details of Algorithm 2.\nObtaining a similar input. In Line 4, the algorithm obtains the pre-training input $X_{similar}$ that is most similar to the input $x$. In this process, we map the input $x$ and the pre-trained input set X to the same embedding space. Based on the distance in the embedding space, we identify the pre-training input that is closest to $x$ and treat it as the most similar pre-training input, $X_{similar}$. Then in Line 54, the algorithm retrieves the pre-trained rule R1 of $X_{similair}$"}, {"title": "Horizontal transformation.", "content": "From Line 7 to Line 20 is the horizontal transformation. The horizontal transformation (HT) is a method that adapts rules from one input to another similar input. This method maps the predicates from the pre-trained rules onto the predicates formed by the features in the online input that are most similar to them., i.e.,\n$HT: R \\rightarrow R$\nLet $R_2 = HT(R_1)$ where\n$R_1 = (p_{a_1}, p_{a_2},..., p_{a_n}), R_2 = (p_{b_1}, p_{b_2}, ..., p_{b_m})$\nHere, $p_{a_1}, p_{a_2},..., p_{a_n}$ represent the predicates of the pre-trained rule and $x_1, x_2, ..., x_{a_n}$ represent the features of the pre-training input. Predicates $p_{b_1}, p_{b_2},..., p_{b_m}$ represent the predicates of the new rule and $y_{b_1}, y_{b_2}, ..., y_{b_m}$ represent the features of the online input. We ensure that\n$\\forall i \\in \\{1, .., n\\}, j \\in \\{1, .., m\\}Dist(x_{a_i},y_{b_i}) \\leq Dist(x_{a_i}, y_{b_j})$\nThe function $Dist$ measures the difference between two features. For tabular data, it represents the absolute value of the difference between two numbers. For text data, it represents the distance between two words in the semantic space generated by a fine-tuned BERT (Devlin et al., 2018). For image data, it represents the distance between the vectors of two superpixels after embedding through Resnet50 (He et al., 2016).\nIn Line 8, the algorithm enumerates each predicate p in the pre-training result R. From Line 11 to Line 17, the algorithm identify the most similar feature in the input $x_i$ based on the feature represented by p. Then, in Line 16, the algorithm use a function replace_predicate to replace the feature value v with the similar feature value similar_feature from the predicate p to obtain the predicate $p_s$. At last, in Line 17, the algorithm add the predicate $p_s$ to the rule R2."}, {"title": "Vertical transformation.", "content": "From Line 22 to Line 31 is the vertical transformation (VT). This process refines a general rule-which typically has high coverage but low precision-into a more specific rule with low coverage and high precision, i.e.,\n$VT: R \\rightarrow R$\nLet $R_2 = VT(R_1)$, where $R_2 = R_1 \\cup R'$ and $Precision(R_1 \\cup R') > \\tau$. This process is achieved by continuously adding new predicates to the existing rule R. At the beginning of each iteration (Line 23), the set of candidate rules is initialized to an empty set. In Line 24 and 25, the algorithm enumerates all the features of input $x_i$, and converts them into the corresponding predicates. In Line 26 and 27, the algorithm adds a new predicate $p_r$ into R2, which is not already included in R2, to form several candidates. Then in Line 30, through perturbation sampling, the candidate with the highest precision is selected as the new rule R for the next iteration. This process repeats until the rule R satisfies Precision(R) $\\geq \\tau$.\nThus, we align with Anchors' precision goals and ensure that explanations can be effectively adapted to specific contexts without extensive recalculations."}, {"title": "4. Experiment", "content": "In this section, we evaluate the performance of our accelerated Anchors explanation method compared to the original Anchors algorithm. The experiments were conducted on three types of data tabular, text, and image-across various datasets. We conducted experiments on multiple machine learning models to demonstrate the effectiveness of our method in efficiency optimization. In addition, we"}, {"title": "4.1. Experiment Setup", "content": "For tabular data, we selected revenue forecasting as the target task; for text data, we selected sentiment analysis as the target task; for image data, we selected image classification as the target task.\nIn our experiments across all tasks, we set the parameter $\\tau$ to 0.8 during the pre-training phase and 0.95 during the refinement phase. Given that the parameter N plays a critical role in influencing optimization performance, we conducted comparative experiments using various values of N.\nIncome Prediction. The income prediction models take the numerical values of a person's multiple features (such as age, education level, race, etc.) as input and outputs whether their annual income will exceed $50k or not, i.e. $f : X \\rightarrow \\{0,1\\}$, where $X := \\cup_{i=1}^{k}F_i$ is the input domain, and k represents the number of features, $F_i$ represents the value of i-th feature. We used the random forest(RF), gradient boosted trees(GBT) and a 3-layers neural network(NN) as models to explain. We used these models to predict the data of 12,345 individuals from the Adult dataset (Becker & Kohavi, 1996), and explained the local behavior of the models around each input item in tabular.\nSentiment Analysis. Sentiment analysis models take a text sequence as input and predict if the text is positive or negative, i.e. $f : X \\rightarrow \\{0,1\\}$, where $X := \\cup_{i=1}^{k} W^i$ is the input domain, and W is the vocabulary set. We used the random forest (RF) and the 7B version of Llama2.0 (Llama) as the models to explain. We used these models to predict 12,520 comments from the RT-Polarity dataset (Pang & Lee, 2005), and explained the local behavior of the models around each input text.\nImage Classification. Image classification models take an image as input and predict the category of the image, i.e. $f : X \\rightarrow \\{0,1,...,m\\}$, where m is the number of categories, $X := R^{3 \\times h \\times w}$ is the input domain, with h and w being the height and width of the image.\nWe used a pre-trained YOLOv8 to predict the category of 500 images from a partial dataset of ImageNet (Deng et al., 2009) and explained the local behavior of the models around each input image."}, {"title": "4.2. Efficiency Improvement", "content": ""}, {"title": "4.2.1. EVALUATION METRICS", "content": "To quantify the performance of our accelerated Anchors method, we measured:"}, {"title": "Time Acceleration Rate:", "content": "The time acceleration ratio of our method compared to the original Anchors, calculated as (Time taken by the original Anchors/ Time taken by our method)."}, {"title": "Sampling Reduction Ratio:", "content": "The sampling reduction ratio of our method compared to the original Anchors is calculated as (1 - Sampling count of our method / Sampling count of the original Anchors). The difference between this metric and the Time Acceleration Ratio is that it can, to some extent, eliminate the impact of the computational overhead of the model being explained, thereby providing a more specific reflection of the acceleration effect of our method."}, {"title": "4.2.2. EVALUATION RESULTS", "content": "Table 2, Table 3 and Table 4 shows the average time acceleration ratio and sampling reduction ratio in the income prediction, sentiment analysis and image classification tasks with different number of explanations generated during the pre-training N.\nFor the income prediction task, our approach achieved the highest average acceleration effect across all three models. When N = 2000, the acceleration ratios for RF, NN, and GBT models were 271%, 198%, and 185%, respectively. Additionally, the proportion of reduced sampling counts was significant, reaching 64%, 53%, and 46% for the three models. For more complex tasks, such as sentiment analysis and image classification, our average acceleration effect remained effective even with a limited number of pre-training inputs N. Although the number of pre-training inputs for the sentiment analysis task is the same (N = 2000), the optimization effect is better for tabular data. The reason is, compared to tabular data, text data is of higher dimensions after embedding. As a result, when the number of pre-training inputs is the same, it is more difficult to identify a sufficiently similar pre-training input during the horizontal transformation process, which ultimately leads to poorer optimization performance. When N = 2000, the acceleration ratio for the RF in the sentiment analysis task was 221%, while for the Llama, it was 169%. The difference in acceleration effects is due to the Llama having a more complex decision boundary compared to the RF, which requires more samples to accurately measure its decision boundary, resulting in more vertical transformation iterations. In the image classification task with N = 200, the acceleration ratio for the YOLOv8 model was 161%.\nFurthermore, across all three tasks, it was observed that as the number of pretraining inputs N increased, the optimization effect continued to improve. This aligns with our expectations: as the number of pre-training inputs increases, more rules can be generated during horizontal transfer, thereby reducing the iterations required for sampling in vertical transfer and ultimately leading to improved optimization"}, {"title": "4.3. Fidelity Evaluation", "content": ""}, {"title": "4.3.1. EVALUATION METRICS", "content": "Coverage: A parameter in Anchors used to evaluate fidelity, representing the proportion of samples that satisfy the constraints of the explanation.\nPrecision: A parameter in Anchors used to evaluate fidelity, representing the percentage of samples that it covers yielding the same output as the input to explain."}, {"title": "4.3.2. EVALUATION RESULTS", "content": "Figure 4 illustrates the fidelity of the explanations generated by our method. For this experiment, we selected the income prediction task, which has the largest dataset. For precision, our method ensures that the generated explanations maintain the same level of accuracy as Anchors. To achieve this, new predicates are iteratively added to the rule until the precision meets the threshold $\\tau$. As a result, the precision of our method is nearly identical to that of Anchors.\nBesides, our method demonstrates a slight decline in coverage compared to Anchors. This is because the rules derived through horizontal transfer in our approach are not always the ones with maximum coverage that still meet the precision requirement, which may lead to the inclusion of additional predicates. However, this issue can be mitigated by increasing the number of pre-training inputs (N). As the number of pre-training inputs increases, more similar pre-training inputs can be identified during the horizontal transfer process. Consequently, when transferring rules from pre-training inputs to online inputs, the reduction in coverage diminishes, ultimately resulting in improved coverage in the final outcomes."}, {"title": "5. Related Work", "content": "Our work is related to model-agnostic explanation techniques and approaches to improving their efficiency.\nModel-agnostic explanation techniques aim to explain the predictions of machine learning models without requiring access to their internal workings, treating them as black boxes. The prominent model-agnostic methods includes Local Interpretable Model-agnostic Explanations (LIME) (Ribeiro et al., 2016), SHapley Additive exPlanations (SHAP) (Lundberg, 2017), Partial Dependence Plots (PDP) (Friedman,"}, {"title": "6. Conclusion", "content": "We have proposed a novel two-step rule transformation framework to significantly improve the computational efficiency of Anchors, a widely used local model-agnostic explanation technique. Our method leverages pre-trained explanations from representative inputs and employs horizontal and vertical rule transformations to adapt and refine these explanations for online inputs without compromising their fidelity.\nWe applied our method to various tasks on tabular, text, and image datasets. Empirical evaluations demonstrate the effectiveness of our approach in reducing the explanation time for Anchors while preserving the fidelity of the generated explanations. With this improvement, our method enhances the practicality of Anchors in real-time applications."}]}