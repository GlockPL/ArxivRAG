{"title": "ACCURATE FORGETTING FOR HETEROGENEOUS FEDERATED CONTINUAL LEARNING", "authors": ["Abudukelimu Wuerkaixi", "Sen Cui", "Jingfeng Zhang", "Kunda Yan", "Bo Han", "Gang Niu", "Lei Fang", "Changshui Zhang", "Masashi Sugiyama"], "abstract": "Recent years have witnessed a burgeoning interest in federated learning (FL). However, the contexts in which clients engage in sequential learning remain under-explored. Bridging FL and continual learning (CL) gives rise to a challenging practical problem: federated continual learning (FCL). Existing research in FCL primarily focuses on mitigating the catastrophic forgetting issue of continual learning while collaborating with other clients. We argue that the forgetting phenomena are not invariably detrimental. In this paper, we consider a more practical and challenging FCL setting characterized by potentially unrelated or even antagonistic data/tasks across different clients. In the FL scenario, statistical heterogeneity and data noise among clients may exhibit spurious correlations which result in biased feature learning. While existing CL strategies focus on a complete utilization of previous knowledge, we found that forgetting biased information is beneficial in our study. Therefore, we propose a new concept accurate forgetting (AF) and develop a novel generative-replay method AF-FCL which selectively utilizes previous knowledge in federated networks. We employ a probabilistic framework based on a normalizing flow model to quantify the credibility of previous knowledge. Comprehensive experiments affirm the superiority of our method over baselines.", "sections": [{"title": "1 INTRODUCTION", "content": "Continual learning is a learning scenario where a model tries to learn a series of new arriving tasks and maintain performance on old tasks (Thrun, 1994; Kumar & Daume III, 2012; Li & Hoiem, 2016; Jeon et al., 2023). This approach, inspired by human lifelong learning, is central to advancing the development of artificial general intelligence. Since birth, a person would gather experience about real world by constantly learning various tasks and remembering them. Humans not only accumulate knowledge through self-directed learning but also collaboratively learn from others. However, concerns about data privacy and communication overhead arise when cooperating with others. Federated learning, which has attracted significant interests and gained various applications in industry (McMahan et al., 2017; Yang et al., 2019; Li et al., 2021), has been an alternative to addressing these concerns. This leads to the concept of federated continual learning (FCL) (Qi et al., 2023), incorporating continual learning into federated learning.\nIn FCL, the goal is that clients learn models for their private sequential tasks collaboratively without violating the data privacy of individual clients. This could encounter challenges from three fronts. One is statistical heterogeneity due to non-IID data across local clients. Such heterogeneity could severely degrade performance (Qu et al., 2022) when learning from clients collaboratively. Another is catastrophic forgetting, stemming from restricted access to data from previous tasks due to realistic factors such as storage constraints, privacy issues, etc (Wang et al., 2023). This can lead the model to lose its ability to perform previous tasks proficiently after assimilating new tasks. There are a few studies seeking to address the above two problems in FCL. For example, Usmanova et al. (2021) extended the Learning without Forgetting (Li & Hoiem, 2016) method to the FCL scenario, memorizing previous tasks among all clients. The third concern is associated with the potential introduction of feature bias resulting from the federated scenario, which in turn could impact the memory within CL models. Research indicates that the memorization of noisy labels can significantly impair the model's performance (Han et al., 2020).\nExisting research developing FCL methods mainly assumed that thorough memorization of previous tasks yields overall performance benefits (Usmanova et al., 2021; Qi et al., 2023). Elaborate strategies were employed to memorize previous information (Yoon et al., 2021a; Liu et al., 2023). In practice, feature bias typically exists in the dataset, especially when there are lots of clients within the federated network. Because of such statistical heterogeneity, biased or even harmful information from particular clients may reside in the memory bank (i.e., memory buffer, generative models or model parameters) as shown in Figure 1. The federated model may inadvertently learn to identify and rely upon spurious correlations arising from diverse tasks among multiple clients. Furthermore, the model may integrate label noise (Zhang et al., 2024) introduced by a few clients. For example, in a federated learning system implemented among hospitals nationwide, these medical institutions may encounter varying disease profiles over time. Besides, hospitals located at distinct geographical areas often cater to diverse distributions as depicted in Figure 1. Therefore, strategically mitigating erroneous knowledge during the acquisition of new tasks is required.\nMotivated by the phenomenon in reality that the new arriving tasks of each client may not be correlated, we consider a more practical and challenging FCL setting in this paper: limitless task pool (LTP). From a temporal perspective, the tasks that a single client randomly selects from the LTP at various time points might be unrelated or even antagonistic, thereby presenting a significant challenge for model learning. To overcome the problem, we propose a novel generation-based method Accurate Forgetting Federated Continual Learning (AF-FCL). We argue that the forgetting phenomena are not invariably detrimental (Han et al., 2020). Conversely, accurate forgetting mitigates the negative impact of the heterogeneity on model learning.\nInstead of learning a generative adversarial network (GAN) for indiscriminate generative-replay in existing FCL methods (Qi et al., 2023), AF-FCL aims to facilitate a selective utilization of previous knowledge through correlation estimation. In order to accurately identify benign knowledge from pre-vious tasks, we achieve correlation estimation with a learned normalizing flow (NF) model (Durkan et al., 2019; Winkler et al., 2019; Rezende & Mohamed, 2015) in feature space. Specifically, an NF model could map an arbitrarily complex data distribution to a pre-defined distribution through a sequence of bijective transformations. Such invertibility enables the NF to have a lossless memory of the input knowledge and accurately estimate the probability density of observed data. While the infor-mation in the NF model could contain biased features or spurious correlation due to heterogeneous data, we suggest outlier features with respect to the current tasks are suspicious and may pose a threat"}, {"title": "2 RELATED WORK", "content": "Continual Learning. Continual learning has witnessed the development of diverse methodologies (Lange et al., 2022), which can be roughly divided into three families: (I) Regularization-based methods: LwF employs the knowledge distillation loss, where the previous model's output is uti-lized as soft labels for the current tasks when working with new data (Li & Hoiem, 2016). Stable SGD (Mirzadeh et al., 2020) demonstrated performance enhancements by calibrating pivotal hyper-parameters and systematically reducing the learning rate upon the arrival of each task. (II) Parameter isolation methods: Rusu et al. (2016) suggested augmentation of the model with new branches tailored to incoming tasks. (III) Replay-based methods: Generative replay-based methods use an auxiliary generator to model the data distribution of acquired knowledge, producing synthetic data for replay in instances (Odena et al., 2017; Wu et al., 2018). While existing research predominantly focused on the efficient memorization of past knowledge, we turn our attention to a more foundational question: is prior knowledge perpetually beneficial?\nFederated Learning. Federated learning represents a distributed learning paradigm among multiple clients and a central server. Researchers have been endeavoring to address the statistical heterogeneity by developing a comprehensive global model (Wang et al., 2020). Mohri et al. (2019) aimed to achieve a fair distribution of model performance by optimizing its efficacy across any given target distribution. Zhu et al. (2021b) suggested the utilization of a generator to aggregate user information. This, in turn, guides the local training by employing the acquired knowledge as an inductive bias. In this work, we consider a more challenging learning problem associated with statistical heterogeneity in federated scenarios: how to facilitate collaboration when all clients are tackling different tasks?\nFederated Continual Learning. To date, there are a few studies in the domain of federated continual learning. Casado et al. (2020) studied the scenario of data distributions changing over time in federated learning. Federated reconnaissance presented a scenario with incrementally new classes during training and proposed to utilize prototype networks (Hendryx et al., 2021). Guo et al. (2021) proposed a regularization-based algorithm and a new theoretical framework for it. Usmanova et al. (2021) presented a distillation-based method to deal with catastrophic forgetting, using previous model and global model as teachers for the training of local models. Yoon et al. (2021b) proposed a novel parameter isolation method for the federated diagram, where the network weights are decomposed into global parameters and task-specific parameters. Dong et al. (2022) considered a federated class-incremental setting and developed a distillation-based method to alleviate catastrophic forgetting from both local and global perspectives. Qi et al. (2023) customized the generative replay based method ACGAN with model consolidation and consistency enforcement. Our method considers the issue of memorizing biased feature due to statistical heterogeneity, exhibiting notable differences compared to the aforementioned methods."}, {"title": "3 PROBLEM DEFINITION", "content": "3.1 NOTATIONS\nContinual Learning. In standard continual learning scenario, there are a sequence of tasks $T = \\{T_1, T_2,...,T_T\\}$, where T is the number of tasks, and $T_t$ is the t-th task. Each dataset is composed"}, {"title": "3.2 FEDERATED CONTINUAL LEARNING", "content": "of $n_t$ pairs of data and labels: $D^t = \\{(x^i,y^i)\\}_{i=1}^{n_t}$. When learning on the t-th task, one has no direct access to previous data $D^{t'}, t' < t$. The goal of continual learning is to effectively manage the current task while preserving its performance on all previous tasks:\n$\\min_\\theta \\left[\\mathcal{L}(\\theta^t; T^1), \\mathcal{L}(\\theta^t; T^2), \\ldots, \\mathcal{L}(\\theta^t; T^t)\\right]$,\nwhere $\\mathcal{L}$ is the risk objective of tasks and $\\theta^t$ is the model parameters learned on the t-th task.\nFederated Learning and Statistical Heterogeneity. In federated learning scenario, there are N clients, and each client owns a private dataset. The goal of federated learning is collaboratively learning models without accessing the datasets belonging to the local clients. The data of clients consists of the input space $\\mathcal{X}_i$ and output space $\\mathcal{Y}_i$, where $\\mathcal{X}_i$ and $\\mathcal{Y}_i$ are shared across all clients. There are $n_i$ samples in the i-th client denoted as $\\{(x_k, y_k)\\}_{k=1}^{n_i}$. Different clients may exhibit non-identical joint distributions $p(x, y)$ of features and labels, i.e., $p(x_{i_1}, y_{i_1}) \\neq p(x_{i_2}, y_{i_2})$, where $i_1 \\neq i_2$.\nFEDERATED CONTINUAL LEARNING\nFCL refers to a practical learning scenario that melds the principles of federated learning and continual learning. Suppose there are N clients, and each client possesses a private series of datasets $\\{D^t_k\\}_{t=1}^T$. Please note that, at a given step t, client k can only have access to $D^t_k$ as in continual learning. In existing literature, the primary focus is on a specific task reshuffling setting, wherein the task set is identical for all users, yet the arrival sequence of tasks differs (Yoon et al., 2021a). In practical scenarios, it may be observed that the task set of clients is not necessarily correlated. Thus we consider a practical setting, the limitless task pool (LTP), denoted as $\\mathcal{T}$. For each client, the dataset $D^t_k$ of the k-th client at step t corresponds to a particular learning task $T^t_k \\in \\mathcal{T}$. There is no guaranteed relation among the tasks $\\{T^1_k, T^2_k, ..., T^T_k \\}$ in the k-th client at different steps. Similarly, at step t, there could be no relation among the tasks $\\{T^1_k, T^2_k, ..., T^N_k\\}$ across different clients.\nLimitless Task Pool. In the setting of LTP, tasks are selected randomly from a substantial repos-itory of tasks, creating a situation where two clients may not share any common tasks, i.e., $\\{T^t_k\\}_{t=1}^T \\cap \\{T^t_{k'}\\}_{t=1}^T \\geq 0, p,q = 1,2..., N$. More importantly, clients possess diverse joint distributions of data and labels $p(x, y)$ due to statistical heterogeneity. Therefore, features learned from other clients could invariably introduce bias when applied to the current task.\nBiased Features. The bias originating from a particular client can adversely affect the performance of the model across different clients and a range of tasks. We tackle a more practical and challenging FCL problem that differs from the task reshuffling setting (Yoon et al., 2021a) from two perspectives: (I) For different steps, tasks allocated to each client are randomly drawn from an extensive task pool. (II) For different clients, tasks across various clients may be unrelated or even contradictory in each step, consequently amplifying bias during the learning process.\nOur goal is to facilitate the collaborative construction of the global model with parameters $\\theta$. Under the privacy constraint inherent in federated learning and continual learning, we aim to harmoniously learn current tasks while preserving performance on previous tasks for all clients, thereby seeking to optimize performance across all tasks seen so far by all clients, i.e.,\n$\\min_\\theta [S^1, S^2,...S^t]$, where $S^t = [\\mathcal{L}(\\theta^t; T^1), \\mathcal{L}(\\theta^t; T^2), \\ldots, \\mathcal{L}(\\theta^t; T^t)]$. (2)"}, {"title": "4 VALIDATION OF ACCURATE FORGETTING", "content": "In this section, we present the results on a noisy dataset to intuitively demonstrate the effectiveness of our motivation and approach.\n4.1 DATASET WITH LABEL NOISE\nWe argue that forgetting is not invariably detrimental within the realm of FCL and propose the concept of accurate forgetting. To validate our argument and the efficacy of our proposed method, we curate the EMNIST-noisy dataset, wherein a subset of noisy clients is simulated by introducing random labels to the data. Additionally, we acknowledge the presence of noise in practical datasets, notably in the form of label noise.\nAs a character image dataset, the EMNIST-noisy dataset comprises 8 clients, each encompassing 6 tasks, with each task containing 2 classes of character images. We randomly select several clients and"}, {"title": "4.2 RESULTS", "content": "assign random labels for their initial three tasks, as displayed in Figure 2(a). These incorrect labels have the potential to propagate adverse effects, affecting subsequent task learning across different clients through the memory bank. After learning sequentially on all tasks, we evaluate the final three tasks, which do not contain any noisy labels. This evaluation allows us to exclusively assess the impact of incorporating noisy information from previous tasks into the memory bank.\nThe baselines in Figure 2(b) are representative CL and FCL methods. It is observed that: (I) the performance of the baselines demonstrates inferiority compared to the naive FedAvg method; (II) the performance of the baselines suffers a rapid deterioration with an increasing number of noisy clients.\nThese CL and FCL baseline methods are meticulously designed to effectively retain knowledge from previous tasks. However, the presence of noisy clients introduces harmful information into the model learning process. The memorization of such erroneous information proves detrimental to the overall performance. Consequently, the baselines exhibit suboptimal performance compared to FL method, which does not employ explicit memorization techniques. In contrast, our approach incorporates adaptive mechanisms to mitigate the impact of erroneous information. By effectively alleviating the adverse influence of noisy clients, our method consistently surpasses all baselines. Notably, the performance of our method maintains relative stability even with an increasing number of noisy clients in the dataset."}, {"title": "5 METHODOLOGY", "content": "5.1 PRELIMINARY: NORMALIZING FLOW\nNormalizing flow is a type of generative model. It is able to map a complex, multi-modal distribution to a simple probability distribution such as standard Gaussian distribution through a sequence of smooth and invertible transformations (Rezende & Mohamed, 2015). In particular, an NF model is a diffeomorphism g composed of a series of invertible transformations $g = g_1 \\circ g_2 . . . \\circ g_k$, of which a widely applied transformation is affine coupling layer (Kingma & Dhariwal, 2018).\nLossless Memory. Through meticulous design of the invertible layers, normalizing flow accomplishes a bijective transformation, preserving the one-to-one correspondence between the elements of the input and output spaces. The bijectivity ensures a lossless memory of the original input. Consequently, this inherent property of NF is pivotal in enabling the accurate modeling of complex distributions, and stands central in generative applications.\nExact Likelihood Estimation. The invertibility enables precise estimation of the probability density of data samples within the learned dataset. Specifically, with a target dataset $Z = \\{z_i\\}_{i=1}^n, z_i \\in \\mathbb{R}^d$ and a prior distribution $p_u(u), u \\in \\mathbb{R}^d$, an NF model learns the diffeomorphism g with the parameters $\\theta$ that maps dataset distribution $p_z$ to the prior: $u = g(z)$. Under above transformation, the probability density of the given datapoint z can be computed as:\n$\\log p_z(z) = \\log p_u(u) + \\log \\left| \\det \\frac{\\partial u}{\\partial z} \\right| = \\log p_u(g(z)) + \\sum_{l=1}^{k-1} \\log \\left| \\det \\frac{\\partial g_{l+1}}{\\partial g_{l}} \\right|.$ (3)"}, {"title": "5.2 AN OVERVIEW OF AF-FCL", "content": "In FCL, statistical heterogeneity among clients brings extra challenges for continuously learning a sequence of tasks. Especially in LTP setting, particular clients could possess unrelated tasks and biased dataset. When bias or spurious correlation from particular clients is memorized by the model, a decline in model performance may occur in the task sequences of all clients. Therefore, a direct deployment of continual learning methods designed to mitigate catastrophic forgetting is hard to address the heterogeneity issues in FCL.\nWe propose a novel method AF-FCL, which adaptively utilizes memorized knowledge and learns unbiased feature for all clients under the FedAvg framework (McMahan et al., 2017). The training schematic of the classifier in each client is illustrated in Figure 3. Overall, the implementation of AF-FCL consists of the following components: (I) feature generative-replay. To prevent complete forgetting, we train a global NF model in the feature space of classifier for generative replay. (II) knowledge distillation. Additionally, we employ knowledge distillation in the feature space to mitigate significant drift, thereby enhancing the stability of the training process for the NF model. (III) correlation estimation. We suggest that features exhibiting outlier characteristics with respect to the current tasks can potentially undermine the learning process. Therefore, we assess the reliability of the generated feature by its probability density within the current tasks."}, {"title": "5.3 ACCURATE FORGETTING FOR HETEROGENEOUS FCL", "content": "The above Sec.5.2 gives an overview of our method. In this section, we provide a detailed description of AF-FCL and how it is implemented.\nGenerative-replay in Feature Space. We consider the classification tasks, where we need to train a classifier with L layers: $h = \\{h_1,h_2,...,h_L\\}$. We split the classifier into three sub-modules: $h_a = \\{h_1,h_2,...,h_l\\}, h_b = \\{h_{l+1},...,h_{L-1}\\}, h_c = \\{h_L\\}$. The $h_a$ and $h_b$ are two successive feature extractors, $h_c$ is the classifier head. To maintain the performance on previous tasks, we train a conditional normalizing flow model g in the feature space, which is the output space of $h_a$. In this way, the normalizing flow model retains the feature of previous tasks. The NF model g is trained globally with FedAvg algorithm using client datasets and sampled data:\n$\\mathcal{L}_{NF}(g; D^t_k, \\mathcal{G}_z) = - \\frac{1}{|D^t_k|} \\sum_{x_i, y_i \\in D^t_k} \\log p_z(h_a(x_i), y_i) - \\frac{1}{|\\mathcal{G}_z|} \\sum_{z_i, y_i \\in \\mathcal{G}_z} \\log p_z(z_i, y_i),$ (5)"}, {"title": "6 EXPERIMENTS", "content": "where $D^t_k$ is the dataset of the t-th task in the k-th client, and $p_z$ is the likelihood calculated as in Eq. 3. $\\mathcal{G}_z$ is the feature set sampled from NF model $g'$ ($g'$ is the stored NF model after training on the last task), so that the current NF model avoids forgetting previous features.\nNormalizing flows operate within a latent space that maintains dimensional parity with the target data space. Training the NF model in high-dimensional data space $\\mathcal{X}$ could be computationally intensive. Furthermore, the inherent sparsity of raw data can hinder the NF model's capacity to obtain a representative sample of the data distribution (Brehmer & Cranmer, 2020). Therefore, we train the NF model in the compact, low-dimensional feature space as opposed to the data space, thereby reducing the complexity of generation.\nWe also leverage the feature space to extract more robust semantic information.\nKnowledge Distillation for a Consistent Feature Distribution. The NF model is trained in the feature space of classifier to maintain previous knowledge. The NF model retains knowledge from previous tasks, conveying it to the classifier via feature generation. Yet, feature extractor of the classifier undergoes continual modifications throughout the training process. If the feature space of the classifier drifts significantly, the knowledge memorized by the NF model may become obsolete.\nTherefore, the feature space of the classifier needs to retain relative consistency during the training. We propose to apply knowledge distillation in the feature space of the classifier to control the drift of feature distribution:\n$\\mathcal{L}_{KD}(h; D^t_k) = \\frac{1}{n^t_k} \\sum_i \\|h_a(x_i) - \\hat{h_a}(x_i)\\|^2_2,$ (6)\nwhere $\\hat{h_a}$ is the stored classifier feature extractor after training on the last task.\nCorrelation Estimation for Accurate Forgetting. From the above, we train the classifier with the aid of NF model by generating features. However, utilizing previous knowledge without discrimination may lead to biased model as stated before. Thus we propose to accurately exploit the memorized knowledge with the characteristics of the NF model for correlation estimation. In particular, when training the classifier for the t-th task of client k, we firstly map the feature of local data to the latent space of normalizing flow, i.e., $\\hat{\\mathcal{U}} = \\{u_i = g(h_a(x_i))\\}_{i=1}^{n^t_k}, x_i \\in D^t_k$. As the NF models transform the features to a disentangled latent space, which is the centered isotropic multivariate Gaussian. Therefore, we approximate the true distribution $\\mathcal{U}^t_k$ in each class as a multivariate Gaussian with a diagonal covariance structure. The mean vector $\\mu^t_l$ and covariance matrix $\\Sigma^t_l$ of $\\mathcal{U}^t_k$ can be easily computed by\n$\\mu^t_l = \\frac{1}{n_k^t} \\sum_{u_i \\in U^t_k} u_i, \\Sigma^t_l = \\frac{1}{n_k^t} \\sum_{u_i \\in U^t_k} diag(u_i - \\mu^t_l) \\cdot diag(u_i - \\mu^t_l), u_i \\in \\mathcal{U}^t_k,$ (7)\nwhere diag(u) turns the vector u into a diagonal matrix.\nFor generative replay, we sample a batch of latent vectors in the NF model and project them to feature space: $\\bar{\\mathcal{U}}_g = \\{\\bar{u}_i, z_i = g^{-1}(\\bar{u}_i), y_i\\}_{i=1}^{n^t_k}, \\bar{u}_i \\in p_u$. Please note that we use bar superscripts to denote generated data. The generated features from NF model represent the knowledge of previous tasks among all clients. However, in FCL scenario, there may exist irrelevant or even biased feature from other clients due to statistical heterogeneity. Enhancing the memorizing of biased feature could cause subpar performance or even failing to converge. Considering that outlier features with respect to the current tasks could be unreliable, we quantify the credibility of generated feature with its relevance to local dataset. To evaluate the correlation between the generated feature and the current task, we propose to use the the probability density of the sampled latent vector $\\bar{u}_i$ within the current feature distribution quantified in Eq.(7), i.e.,\n$p_{\\mathcal{D}}(\\bar{u}_i) = \\frac{1}{\\sqrt{(2 \\pi)^d \\left| \\Sigma^t_l \\right|}} \\exp \\left(-\\frac{1}{2} (\\bar{u}_i - \\mu^t_l)^T (\\Sigma^t_l)^{-1} (\\bar{u}_i - \\mu^t_l) \\right).$ (8)\nThe probability $p_{\\mathcal{D}}(\\bar{u}_i)$ above quantifies the degree of correlation between the current task in the local client and the sampled features from NF model. We use the correlation probability of the generated features to re-weight the loss objective $\\mathcal{L}_e$. And the final objective $\\mathcal{L}_{cls}$ consisting of three"}, {"title": "6.1 EXPERIMENTAL SETTINGS AND EVALUATIONS", "content": "terms is as follows:\n$\\mathcal{L}^{ce}_e(h; D^t_k) = \\frac{1}{n_k^t} \\sum_{x_i, y_i \\in D^t_k} \\mathcal{L}_{ce}(h(x_i), y_i),$\n$\\mathcal{L}^{ce}_e(h; \\bar{\\mathcal{U}}_g) = \\frac{1}{n_k^t} \\sum_{\\bar{u}_i, y_i \\in \\bar{\\mathcal{U}}_g} p_{\\mathcal{D}}(\\bar{u}_i) \\mathcal{L}_{ce}(h(g^{-1}(\\bar{u}_i)), y_i),$\n$\\mathcal{L}_{cls}(h; D^t_k,\\bar{\\mathcal{U}}_g) = \\mathcal{L}^{ce}_e(h; D^t_k) + \\mathcal{L}^{ce}_e(h; \\bar{\\mathcal{U}}_g) + \\mathcal{L}_{KD}(h; D^t_k)$ (9)\nwhere $\\mathcal{L}^{ce}_e(h; D^t_k)$ denotes the cross-entropy loss of raw dataset, and $\\mathcal{L}^{ce}_e(h; \\bar{\\mathcal{U}}_g)$ denotes the unbiased objective of generated data. With the proposed method, the classifier learns beneficial features from previous tasks and accurately forgetting biased features. Moreover, the NF model memorizes more benign features. Both the NF model and the classifier are expected to be of increasing generalizability with the advancement of training progress. The implementation of AF-FCL is in Algorithm 1.\nEXPERIMENTAL SETTINGS AND EVALUATIONS\nDatasets and Settings. We curate three FCL datasets with different settings. We use N to denote the number of clients, T to denote the number of tasks in each client, C to denote the number of classes in each task. For the EMNIST-based dataset containing 26 classes of handwritten letter images (Cohen et al., 2017), we set the following two settings with N=8, T=6, C=2. 1) EMNIST-LTP: in LTP setting, we randomly sampled classes from the entire dataset for each client. 2) EMNIST-shuffle: in conventional shuffle setting, the task sets are consistent across all clients, while arranged in different orders. 3) CIFAR100: We randomly sample 20 classes among 100 classes of CIFAR100 (Krizhevsky et al., 2009) as a task for each of the 10 clients, and there are 4 tasks for each client (N = 10, T = 4, C = 20). 4) MNIST-SVHN-F: We set 10 clients with this mixed dataset. Each client contains 6 tasks, and each task has 3 classes.\nMetrics. We use the metrics of accuracy and average forgetting for evaluation following recent works (Mirzadeh et al., 2021; Yoon et al., 2021a). Average forgetting assesses the extend of backward transfer during continual learning, quantified as the disparity between the peak accuracy and the ending accuracy of each task."}, {"title": "6.2 BASELINES", "content": "We compare our method AF-FCL with baselines from FL, CL and FCL. In FL, we consider two representative models FedAvg (McMahan et al., 2017) and FedProx (Li et al., 2020). In CL, PODNet incorporates a spatial-based distillation loss onto the feature maps of the classifier (Douillard et al., 2020). ACGAN-Replay employs a GAN-based generative replay method (Wu et al., 2018). The CL models are respectively combined with the FL models. In FCL, FLwF2T leverages the concept of knowledge distillation within the framework of federated learning (Usmanova et al., 2021). FedCIL extends the ACGAN-Replay method within the federated scenario, addressing the statistical heterogeneity issue with distillation loss (Qi et al., 2023).\nGLFC. In FCL scenario, the algorithm exploits a distillation-based method to alleviate the issue of catastrophic forgetting from both local and global perspectives (Dong et al., 2022)."}, {"title": "6.3 EXPERIMENTS ON EMNIST-BASED DATASETS", "content": "EMNIST-LTP. In this dataset, clients may encompass unrelated tasks, thus rendering the dataset challenging. As the results shown in Table 1, some of the CL methods integrated with FL algorithms demonstrate comparable performance to that of FCL methods in the EMNIST-LTP dataset. For instance, the average accuracy of ACGAN-Replay+FedProx is 41.3%, higher than two FCL methods FLwF2T and GLFC. This phenomenon can be attributed to challenge posed by the elevated degree of heterogeneity under the LTP setting, which is difficult for these FCL methods to deal with, consequently diminishing their inherent advantages. Nevertheless, our method outperforms all the baselines in the EMNIST-LTP dataset. We argue that statistical heterogeneity in federated networks inevitably results in biased information residing in the memory bank. Both CL methods and existing FCL methods assume that memorization is beneficial, potentially losing their advantages under LTP setting. Our method adopts accurate forgetting to mitigate the negative impact of heterogeneity and selectively encourages the forgetting of malign information. It shows the highest accuracy rate and lowest forgetting rate.\nEMNIST-shuffle. Different from the EMNIST-LTP dataset, EMNIST-shuffle represents a more tractable dataset within the conventional setting, resulting in higher overall accuracy rates as in Table 1. The FCL methods exhibit superior accuracy compared to CL methods, underscoring their strength. And our method still showcases a superior capacity than all baselines in this commonly adopted dataset setting."}, {"title": "6.4 EXPERIMENTS ON MORE COMPLICATED DATASETS", "content": "CIFAR100 comprises 100 classes of images. The composite dataset MNIST-SVHN-F comprises two distinct digit classification datasets: MNIST and SVHN, characterized by complex colors and backgrounds, along with a clothing image classification dataset. Table 2 displays the results of these two challenging datasets CIFAR100 and MNIST-SVHN-F. Different tasks exhibit reliance on varying features. For instance, shape features pertinent to digits differ significantly from those relevant to clothing classification. A naive collaboration among clients may lead to a model overly reliant on spurious correlations, overlooking the importance of task-specific features. We suggest a strategy of selective utilization and memorization of learned feature. By relying on the generated features with a higher correlation, AF-FCL significantly exceeds the performance of baselines."}, {"title": "7 CONCLUSION", "content": "In this study, we navigate the challenges of continual learning in real-world federated contexts, specifically when faced with data or task streams that might be biased or noisy across clients. Current research in continual learning emphasizes the adverse consequences of \"catastrophic forgetting\". However, we advocate for a perspective that reveals the merit of selective forgetting, especially as a mechanism to mitigate the biased information induced by statistical heterogeneity in reality. Inspired by it, we present a generative framework, termed as AF-FCL, meticulously crafted to achieve targeted forgetting by re-weighting generated features based on inferred correlations. The experimental results clearly demonstrate its effectiveness."}, {"title": "C IMPLEMENTATION DETAILS", "content": "C.1 ALGORITHM\nThe algorithm of our method is detailed in Algorighm 1.\nC.2 METRICS\nWe use the metrics of accuracy and average forgetting for evaluation following recent works (Mirzadeh et al., 2021; Yoon et al., 2021a). Suppose $a_{t,i}^k$ is the test set accuracy of the i-th task after learning the t-th task in client k.\nAverage Accuracy. We evaluate the performance of the model on all tasks in all clients after it finish learning all tasks. By using a weighted average, we calculated the test set accuracy for all seen tasks across all clients, with the number of samples in each task serving as the weights:\n$\\text{Average Accuracy} = \\frac{1}{\\sum_{k=1}^{N} \\sum_{i=1}^{T} n_{t,i}^k} \\sum_{k=1}^{N} \\sum_{i=1}^{T} a_{t,i}^k n_{t,i}^k.$ (10)\nThis approach allows us to account for variations in task difficulty and ensure a fair evaluation across different tasks and clients."}, {"title": "C.3 OPTIMIZATION", "content": "The Adam optimizer is employed for training all models. For all experiments except for CIFAR100, a learning rate of 1e-4 is utilized, with a global communication round of 60, and local iteration of 100. We set learning rate as 1e"}]}