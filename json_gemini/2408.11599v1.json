{"title": "Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning", "authors": ["Xinhao Chen", "Chong Yang", "Man Lan", "Li Cai", "Yang Chen", "Tu Hu", "Xinlin Zhuang", "Aimin Zhou"], "abstract": "Empathetic response generation endows agents with the capability to comprehend dialogue contexts and react to expressed emotions. Previous works predominantly focus on leveraging the speaker's emotional labels, but ignore the importance of emotion cause reasoning in empathetic response generation, which hinders the model's capacity for further affective understanding and cognitive inference. In this paper, we propose a cause-aware empathetic generation approach by integrating emotions and causes through a well-designed Chain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can greatly promote LLMs' performance of empathy by instruction tuning and enhancing the role awareness of an empathetic listener in the prompt. Additionally, we propose to incorporate cause-oriented external knowledge from COMET into the prompt, which improves the diversity of generation and alleviates conflicts between internal and external knowledge at the same time. Experimental results on the benchmark dataset demonstrate that our approach on LLaMA-7b achieves state-of-the-art performance in both automatic and human evaluations.", "sections": [{"title": "1 Introduction", "content": "Empathetic response generation in conversation aims to generate an understanding of the speaker's experiences and feelings, and to produce appropriate responses (Keskin, 2014). Empathy in social psychology is delineated into the cognitive and affective aspects (Davis, 1983). It has attracted increasing attention for its potential to endow machines with empathetic capabilities across a broad range of applications, such as automated psychotherapy (Liu et al., 2021c) and casual conversation agents (Liu et al., 2022). Existing methods elaborated various small-scale models to comprehend the speaker's emotion state based on emotional labels (Majumder et al., 2020; Tu et al., 2022), or to understand the speaker's situation and experiences combined with common-sense knowledge (Sabour et al., 2022; Lin et al., 2019) generated by COMET (Hwang et al., 2021). With the rise of Large Language Models (LLMs), prompt-based methods have provided a new unified modeling approach by adding both cognition and affection information into the prompt (Zhao et al., 2023; Roller et al., 2020; Lee et al., 2022). Specifically, Qian et al. (2023c) proposed a two-stage generation approach with few-shot Chain-of-Thought (CoT) prompt on LLMs to reason about the speaker's situation (Wei et al., 2022). However, these methods exhibit dependence on the language proficiency of underlying large models, leading to unstable inference performance (Wei et al., 2022). Furthermore, there are two extra limitations of these LLM-based models: (1) they ignore the impact of emotion cause reasoning on empathetic response generation whose importance has been proven in previous works (Gao et al., 2021; Qian et al., 2023a). (2) they lack the awareness of the role as an empathetic listeners, which makes generated responses more rational and less emotionally impactful."}, {"title": "Additionally, from the cognition aspect, directly incorporating external knowledge into large-scale models may lead to a decline in response consistency due to its lack of relevance to the contextual history of the conversation (Qian et al., 2023c;\nZhao et al., 2023). As shown in Figure 1, utilizing\nthe irrelevant knowledge generated from the last\nutterance of the conversation history (e.g., \"xEffect\n= to go sleep\" and \"xNeed = to make a decision\")\nleads to conflicts with the correct dialogue con-\ntext. Despite the efforts of DCKS (Cai et al., 2023)\nwhich filtered knowledge according to the emotion\nlabels to ensure emotional consistency, semantic\ncoherence within the context remains unguaran-\nteed. Instead, we discover that emotional causes\ninvolving further reasoning about emotions facili-\ntates organic integration of the affection and cogni-\ntion aspects and greatly alleviates the conflicts. For\nexample, in Figure 1, directed by emotion causes\nfrom the dialogue history, the generated knowledge\nof COMET (i.e., \"xEffect = break up\" and \"xNeed\n= to move on\") successfully improves the empa-\nthetic outcomes.\nTo address the above problems, we propose a\nnovel cause-aware CoT Fine-tuning Empathetic\nGeneration method (CFEG) on LLMs. We de-\nsign an universal CoT generation template to guide\nthe model in reflecting on its emotions and causes,\nand enhancing the role awareness of an empathetic\nlistener. This is initiated by the idea that a good\nempathetic listener should concentrate more on\nunderstanding what triggers the emotion in the di-\nalogue to respond for the speaker's emotion. Si-\nmultaneously, instruction tuning can be employed\nto strengthen the stability of the CoT reasoning.\nBesides, we implicitly select required common-\nsense knowledge from COMET directed by emo-\ntion cause to enhance the consistency between in-\nternal and external knowledge. The knowledge\nis then incorporated into the prompt to improve\nthe diversity of response generation. Experimen-\ntal results on the benchmark dataset demonstrate\nthat our method, fine-tuned on LLaMA-7b, signifi-\ncantly outperforms existing methods, and results in\nmore empathetic responses in human evaluations,\neven better than that of ChatGPT.\nOur contributions are summarized as follows:\n\u2022 We present a novel cause-aware CoT fine-\ntuning generation method to enhance LLMs'\ncapability of empathy\u00b9."}, {"title": "Related Work"}, {"title": "2 Related Work", "content": "2.1 Empathetic Response Generation\nIn the field of social psychology, empathy encompasses both affection and cognition aspects (Davis, 1983). Early works relied on emotional signals to mimic human emotions (Majumder et al., 2020; Tu et al., 2022). Recent works incorporated additional common-sense knowledge generated by COMET (Hwang et al., 2021) for deeper cognitive understanding (Li et al., 2022; Sabour et al., 2022). To enhance the relevance of incorporating knowledge with the dialogue, DCKS (Cai et al., 2023) incorporated an emotion-based knowledge selection, while CASE (Zhou et al., 2022b) aligned emotion with knowledge. Meanwhile, Qian et al. (2023b) incorporated additional reasoning steps into the model.\nGao et al. (2021); Qian et al. (2023a) leveraged emotion cause recognition to enhance empathetic\noutcomes. Different from these intricately designed\nsmaller models, our work introduces emotion cause\nreasoning to generate more reasonable and relevant\ncognitive knowledge in a simpler manner.\n2.2 Large Language Models\nIn recent years, the capabilities of large language models (LLMs) have significantly improved due to reinforcement learning from human feedback (RLHF) (Stiennon et al., 2020) and instruction\ntuning (Ouyang et al., 2022). Meanwhile, LLMs can perform reasoning through the construction of\nprompts (Liu et al., 2023, 2021b) and CoT (Wei et al., 2022). Some studies have made initial at-\ntempts to apply LLMs in empathetic dialogues. For\ninstance, Qian et al. (2023c) explored the empa-\nthetic generation capabilities of ChatGPT by two-\nstep generation (Wei et al., 2022). However, Wei et al. (2022) points out that the CoT method can\nlead to erroneous reasoning when the model has fewer parameters. With the advent of fine-tuning\ntechniques based on LoRA (Hu et al., 2021), the capabilities of LLMs have been further enhanced."}, {"title": "Unlike the aforementioned work, our method combines emotion cause reasoning and fine-tuning, enabling relatively smaller models (e.g., LLaMA-7b) to utilize CoT more effectively, achieving superior reasoning abilities and empathetic effects beyond ChatGPT.", "content": "2.3 Emotion Cause Pair Extraction\nThe task of Emotion-Cause Pair Extraction\n(ECPE) aims to recognize the emotions expressed\nby speakers and identify the causal spans. Poria\net al. (2021) provided the RECCON dataset for this\ntask. Gao et al. (2017); Gui et al. (2014) jointly ex-\ntract emotions and causes. MGSAG (Bao et al.,\n2022) proposed to incorporate fine-grained and\ncoarse-grained semantic features jointly without\nregard to distance limitation. Jeong and Bak (2023)\nlearned relationship between utterances and ad-\nvised a gating network to incorporate dialogue fea-\ntures. We utilize the ECPE methods to annotate\ncauses of the dialogue in the benchmark dataset."}, {"title": "3 Problem Definition", "content": "Empathetic generation aims to understand the emotions of the speaker in the role of a listener and provide an empathetic response. Formally, let\n$D = {U_1, U_2,\u2026, U_n}$ denotes a dialogue history with n utterances, where the i-th utterance\n$u_i = {W_1, W_2,\u2026\u2026, W_k}$ is a sequence of k words.\nThe goal is to identify the current emotions $e_n$ of\nthe speaker for the last utterance $u_n$, and play the\nrole of the listener to generate a empathetic and\ninformative response $Y$."}, {"title": "4 Method", "content": "Our proposed CFEG method is basically fine-\ntuned on LLMs. In this section, we first present\nhow to construct cause-aware CoT prompt template\nconsisting of the instruction, dialogue context, and\nexternal knowledge. Then, we introduce the CoT\noutput template and the fine-tuning method.\n4.1 Cause-Aware Prompt Construction\nCommon Prompt\nLLMs have been demonstrated to perform empa-\nthetic generation given appropriate task instruc-\ntions (Roller et al., 2020; Lee et al., 2022). Given\nthe dialogue history D as the input, one of the basic\nprompt for this task is as follows:\n$P_1 = \"{Ins_1}.The Dialogue: {D}.\"$"}, {"title": "Here, {Ins\u2081} represents the task instruction: \"Analyze emotion and respond empathetically to the\nprovided dialogue\". {D} represents the dialogue\nhistory which consists of the roles (speaker, lis-\ntener) and the dialogue utterances, and we use \";\"\nto concatenate multiple turns. Then, we input the\nprompt to a LLM, e.g., LLaMA-7b (Touvron et al.,\n2023) to generate the empathetic response {Res}.\nTypically, the responses may take the form of \"He\nfeels ..., I will reply as follows: ...\".\nCause-Aware CoT Strategy\nCoT refers to a series of intermediate reasoning\nsteps (Brown et al., 2020), which controls the di-\nrection of the model's thinking through multiple\nsteps. In the empathetic generation task, LLMs\nare required to infer the speaker's emotion and the\nsituation. Therefore, previous works (Qian et al.,\n2023c) utilized CoT to generate an appropriate and\nmore human-like response. Specifically, in the first\nstage, the model is prompted with \"Don't rush to\nreply yet, what may be the user's emotion, and what\nmay be the situation?\" to guide speculation on the\nsituation based on the user's statement. Then, in\nthe second stage, prompted with \"Combine your\nthoughts with the dialogue context and give your re-\nsponse.\", the final response is generated. However,\nthis kind of CoT methods relies on the model's\nlinguistic capabilities, leading to uncontrollable sit-\nuation reasoning that may be inconsistent with the\ndialogue history (Wei et al., 2022).\nDifferent from directly inferring the situation\n(Qian et al., 2023c), we propose to use a cause-\naware CoT strategy to guide the model in first ex-\ntracting emotional causes (formalized as a phrase\nencompassing start and end positions), and then\ngenerate responses. Our CoT prompt is as follows:\n$P_2 = \"{Ins_2}. The Dialogue: {D}.\"$"}, {"title": "where {Ins2} represents the cause-aware task in-\nstruction:\"Analysis the emotion and identify the\ncause from the dialogue. Then respond empatheti-\ncally to the provided dialogue.\". Results are gener-\nated from LLMs in the form of \"He feels ... because\nhe says ... I will reply as follows: ...\".", "content": "4.2 Cause-Oriented COMET\nCOMET (Hwang et al., 2021) is a pre-trained\nGPT-2 model (Radford et al., 2018) that has been\nfine-tuned on triplets (e, r, i) extracted from the\nATOMIC dataset (Hwang et al., 2021), where e rep-\nresents the event, r represents the relation type, and"}, {"title": "i represents the inferred knowledge. Five common-\nsense relations of inferences are generated: the\nimpact of events on individuals (xEffect), their re-\nactions to events (xReact), the intentions prior to\nevents (xIntent), the requirements for events to\noccur (xNeed), and the desires following events\n(xWant).\nPrevious methods (Sabour et al., 2022; Zhou\net al., 2022b; Qian et al., 2023c) utilize COMET\nto acquire external knowledge from the last turn of\nthe dialogue, which is then fused into the model to\nimprove the diversity of generation. However, we\nfind that there exist conflicts between the external\nknowledge and the dialogue context. To settle this\nproblem, we propose to use COMET knowledge\ngenerated from the emotional cause-span instead:\n$k_{g_{cpe}} = COMET(r_i, {cau})$", "content": "where $r_i \u2208 {xReact, xWant, xNeed, xIntent, xEffect}$, and {cau} represents the causal span extracted from the history (e.g., in Figure 1's dialogue, the causal span is 'I just broke up with my girlfriend.'). We concatenate the knowledge\nand transform it into natural language segments\n$l_{kg_{icpe}}$ (e.g., \"He tends to look nice; He needs to have a haircut; He wants to fix his hair; The effect is that he ends up burning his hair; He feels embarrassed.\").\nWe then incorporate the cause oriented COMET knowledge into the CoT prompt:\n$P_{kg}^2 = \"{Ins_2}.The Dialogue: {D}. In this Dialogue, {l_{kg_{icpe}}}\""}, {"title": "4.3 Instruction Tuning", "content": "Output Template\nInstruct tuning is employed to further enhance the\nmodel's empathetic expression. As the format of\noutput plays an important role in the fine-tuning\nprocedure, we also wrap the emotion reasoning\nand response into a natural language template. Nor-\nmally, the output format of common prompt P\u2081 is\nas follows:\n$R_1 = \"He feels{emo}.\nI will reply him: {response}.\"$"}, {"title": "We design the cause-aware CoT output format\nof P2 as follows:\n$R_2 = \"He feels{emo}because he says{cau}.\nI will reply him: {response}.\"$"}, {"title": "Here {emo} represents the speaker's emotion and\n{cau} represents the speaker's causal span in the\nhistory that needs to be predicted.\nListener-Aware CoT Strategy\nEmpathy is inherently subjective, influenced by\nboth the speaker's description and the listener's\nfeeling. Therefore, transforming the output tem-\nplate into a listener-aware format helps the model\ndifferentiate the speaker's emotions from its own\nresponsive emotions. Different from previous work\n(Zhao et al., 2022), which solely perceived the emo-\ntions of the speaker and listener, we have further\nenhanced the model's capability to infer conversa-\ntional intent. The listener-aware CoT output tem-\nplate is as follows:\n$R_3 = \"He feels{emo}because he says {cau}. I'm {emo}to hear that.\nI will{Intend}him:{response}.\"$", "content": "Here, {emo} represents the listener's emotion re-\nflected by the model. The model chooses \"glad\" or\n\"sorry\" based on the user's emotion, and {Intend}\nrepresents the conversational intent, selecting ei-\nther \u201creassurance\u201d or \u201csympathize\u201d based on the\nuser's emotion.\nDemonstration\nLLMs possess the ability of in-context learn-\ning(ICL) (Brown et al., 2020), a small amount of\ndata examples can enhance the performance of the\nmodel. Inspired by Qian et al. (2023c), given the\ncurrent dialogue, we sample 5 complete dialogues\ncontaining replies from the training dataset to con-\nstruct the demonstration in the format:\n$E = \"I'll give you five examples.\nExamples{D_1, ...D_5}.\"$\nLoss Function\nThe demonstration is added after {Ins2} in $P_{kg}^2$ to get our final input prompt $P_{kg+E}^2$. After the prompt\nand output template are designed, we transfer all\nthe samples in the datset into a prompt and output\npair < $P_{kg+E}^2$, $P_{kg+E}^2$, R3 >. The supervised fine-tuning\nloss of the LLMs is as follows:\n$L = - \\sum_{j}\\sum_{t} log p_\u03b8 (R_{t}|P, R_{<t})$"}, {"title": "5 Experiment", "content": "5.1 Experiment Setup\nDataset We conduct experiments on the EmpatheticDialogue (Rashkin et al., 2018)."}, {"title": "The dataset comprises 24,850 dialogues, each\nannotated with one of 32 emotion categories, and\ninvolved two turns of empathetic conversation be-\ntween a speaker and a listener. Following previous\nworks (Rashkin et al., 2018), we randomly split\nthe train/valid/test sets in an 8:1: 1 ratio.\nEmotion Cause Annotation As our method re-\nquires additional emotional cause-spans, we train\na LLaMA-7b model on the RECCON dataset (Po-\nria et al., 2021), which is utilized for conversa-\ntion emotional cause-span recognition. The model\nachieves a macro_F\u2081 score of 74.16% on the test\nset. We then utilize this model to make infer-\nence on the EmpatheticDialogue dataset. Man-\nual evaluation of 100 randomly sampled dialogues\nresults in a macro_F\u2081 score of 72.34% on the\nEmpatheticDialogue dateset, demonstrating suf-\nficient performance for conducting CoT reasoning\nand generating external knowledge in our method.\nEvaluation Metrics We assess the models' per-\nformance using both automatic and human evalu-\nations. For automatic evaluation, we employ Per-\nplexity (PPL) for generation quality, Distinct-n\n(Dist-1/2) (Li et al., 2015) for response diversity,\nBLEU-n (BLEU-2/4) (Papineni et al., 2002) for\nresponse similarity and relevance, and emotion ac-\ncuracy (ACC) for emotion prediction. Human eval-\nuation intuitively validates the model's expression\nand empathy which consist of on four aspects: Co-\nherence (Coh.), assessing relevance to the context;\nEmpathy (Emp.), evaluating understanding and\nempathetic expression; Informative (Inf.), mea-\nsuring incorporation of external knowledge; and\nFluency (Flu.), assessing naturalness. During the\nevaluation process, we randomly select 200 conver-\nsation contexts. Annotators consist of both grad-\nuate students and experienced experts who have\nundergone systematic training. They are asked to\nscore each response on a scale from 1 to 5(1: not\nat all, 3: OK, 5: very good).\nBaselines We compare our methods with both\nexisting small-scale models and LLMs."}, {"title": "\u2022 Non-LLMs: (1)MIME generated responses\nby imitating human emotions (Majumder\net al., 2020); (2) CEM incorporated additional\nexternal commonsense knowledge (Sabour\net al., 2022); (3) DCKS incorporated an adap-\ntive module for common-sense knowledge\nselection (Cai et al., 2023); (4) EmpSOA\ngenerated empathetic responses with self-\nother awareness (Zhao et al., 2022); (5)CASE\naligned cognitive and emotional graphs (Zhou\net al., 2022b).", "content": "\u2022 LLMs: LLaMA-7b (Touvron et al., 2023)\nand ChatGPT have been chosen as the base-\nline models for empathetic generation. Fol-\nlowing Qian et al. (2023c), we add the follow-\ning strategies to these two models: (1) +ICL\ninvolved incorporating semantically similar\nIn-Context Learning (Liu et al., 2021a); (2)\n+CoT inferenced the speaker's situation be-\nfore response; (3) +CKG utilized the last ut-\nterance of the history to integrate common-\nsense knowledge by COMET (Hwang et al.,\n2021). Meanwhile, +kgecpes utilize the cause-\noriented COMET to generate higher-quality\nknowledge, distinguishing it from previous\nmethods (Qian et al., 2023c).\nImplementation Details The overall project framework is implemented using LLaMA-Factory\u00b2. The\nLLaMA-7b model is downloaded from the open-\nsource huggingface Transformers\u00b3. We perform\nfine-tuning on the model using LoRA (Hu et al.,\n2021), with a learning rate set to 5e-5, LoRA rank\n8, and a batch size of 4. The common-sense knowl-\nedge is generated from COMET4. In order to en-\nsure deterministic outputs in our experiments, we\nset the temperature to 0. We use the model gpt-3.5-\nturbo provided in the OpenAI API for the baselines,\nwhich is the base model of ChatGPT5. The training\nis conducted on a server equipped with 8 NVIDIA\nRTX 3090 GPUs, utilizing the Accelerate frame-\nwork6.All experiments are conducted on 5 random\nseeds. We select the model with best performance\non the validation set and run it on the test set to\nreport its average results."}, {"title": "5.2 Experimental Results", "content": "5.2.1 Automatic Evaluation\nTable 1 shows the main results of our method and\nother baselines. Experiment results demonstrate\nthat our CFEG method achieves the best perfor-\nmance on all metrics except the PPL metric, in-\ndicating that incorporating CoT fine-tuning can\nenhance the model's emotion understanding capa-\nbility. Specifically, compared to all the non-LLMs"}, {"title": "models, the LLMs-based approaches exhibit sig-\nnificant advantages due to the inherent linguistic\ncapabilities of the model itself. In comparison\nwith ChatGPT+CoT, the CFEG method improves\nemotion accuracy by 4.53% while also enhanc-\ning BLEU-1/2 scores by 5.55% and 3.80%, in-\ndicating that our cause-aware CoT strategy guides\nthe model to analyze emotions and causes from\nthe history, resulting in better human-like empa-\nthetic outcomes. Meanwhile, Providing common-\nsense knowledge leads to improvements in both\nLLaMA-7b and ChatGPT on the Dist-2/4 metrics.\nHowever, compared to ChatGPT+CKG, the CFEG\nmethod shows a further improvement of 0.23% and\n1.23%, respectively. attributed to the higher-quality\nknowledge generated by cause-oriented COMET\naligning better with the context. It's worth men-\ntioning that providing cause-oriented knowledge\nto LLAMA and ChatGPT can also further enhance\nempathetic effectiveness."}, {"title": "5.3 Human Evaluation", "content": "The human-evaluated results shown in Table 1\ndemonstrate that our CFEG method outperforms\nthe baseline in the Coh., Emp., and Inf. aspects.\nParticularly, the superiority of our cause-aware CoT\nfinetuning method in empathy and informativeness\nindicates its advantage in cognitive empathy and\naffective interaction, supporting the observations\nfrom automatic evaluations. The Flu. score of\nthe CFEG method is inferior to ChatGPT, mainly\nbecause we utilize LLaMA-7b for response genera-\ntion, which has significantly fewer parameters com-\npared to ChatGPT, resulting in a gap in language\ncapability. Additionally, Providing cause guided\nknowledge to ChatGPT leads to improvements in"}, {"title": "both Coh. and Inf. score, underscoring the supe-\nriority of our knowledge generation method.\nMeanwhile, following Sabour et al. (2022), we\nconduct an aspect-based pairwise preference test\nwhere annotators choose the better response from\ntwo results. The results are listed in table 2. We\nobserve that our model also outperforms all the\nbaselines, which confirmed that our method can\nimprove the empathy effect of responses. Com-\npared to ChatGPT+CoT, it can be seen that in 55%\nof cases in the A/B test, human annotators prefer\nresponses generated by the CFEG model. This indi-\ncates that our CoT fine-tuning method enable better\nunderstanding of user affection and cognition.", "content": "5.4 Ablation Study\nTo analyze the performance of different strategies, we conduct experiments on the following modifications: (1) w/o Ri: We conduct ablation studies on individual prompts to observe the influence of causal reasoning and listener-aware reasoning. (2)\nw/o kgecpe: We remove the external knowledge to observe its impact on empathetic generation; (3)\nw/o E: We ablate examples to observe the impact\nof in-context learning; (4) w/o sft: We perform\nablation on fine-tuning to observe the effect of fine-tuning CoT reasoning.\nAs shown in Table 1, the model with all modules exhibited better performance. Firstly, when R2 is removed, there is a decrease of 3.42% and\n0.36% in BLEU-2/4 scores, and in manual anal-\nsis, the Emp. metric shows the most significant decrease. This is because the model lacks reasoning about emotions and causes. Secondly, when\nRha is removed, both automatic evaluation metrics\nand manual evaluation decrease, indicating that"}, {"title": "listener-aware reasoning is closer to the conscious\nprocess of expressing empathy in humans. Addi-\ntionally, when kgecpe is removed, the Inf. metric\ndecreases by 0.94, indicating that external knowl-\nedge can effectively enhance the informativeness\nof responses. Removing E weakens the patterns\nlearned by the model from instructions. Perfor-\nmance is lowest when no fine-tuning is performed.\nFine-tuning ensures the stability of CoT reasoning\nwhile learning genuine human expressions.", "content": "5.5 Case Study\nThe generated responses from our method and the\ncompared baselines are list in Table 3. Our CFEG\nmodel is more likely to respond in a highly empa-\nthetic tone and is more consistent with the conversa-\ntion. This is attributed to two major advantages: on\none hand, cause-oriented COMET provides high-\nquality common-sense knowledge, reducing the\nmodel's misunderstandings. ChatGPT also further\nenhances empathetic effects with cause-oriented\nknowledge. On the other hand, we utilize CoT rea-\nsoning during responses to search for emotional\ncauses, and reflect on the emotions as a listener,\nsuch reasoning combines affective and cognitive\nunderstanding, which aids in empathetic responses."}, {"title": "6 Discussion", "content": "6.1 Effect of External Knowledge\nIn this section, we further analyze the quality of knowledge generated by different methods, focus-ing on two perspectives: emotional consistency\nand contextual coherence. Qian et al. (2023c); Sabour et al. (2022) provided the last dialogue\nturn to COMET. DCKS (Cai et al., 2023) selected knowledge using emotions. In contrast, Our CFEG\nmethod generate knowledge oriented by causal spans. Finally, we also utilize ChatGPT to directly\ngenerate knowledge. Specifically, three evaluators"}, {"title": "rate them on a scale of 1 to 5 for Empathy and Co-\nherence (e.g., in Table 3, while the emotion tone of\nthe knowledge is consistent, \"Need to have a hair\ndryer\" conflicts with the history, hence receiving\na Coherence score of 3 and an Empathy score of\n5). The experimental results are shown in Table 4.\nIt can be observed that, compared to DCKS and\nChatGPT, the CFEG method achieves higher con-\nsistency scores. This is due to the incorporation of\ncausal information, giving us an advantage in main-\ntaining consistency within the dialogue history.", "content": "6.2 Effect of CoT Output Templates\nThere are performance differences between different CoT output templates of the emotion and\ncause part in Ra. We explore various templates\nto analyze the accuracy of emotion recognition,\nthe macro_F\u2081 score of cause extraction, and the empathetic effect of the responses through manual\nscoring. As shown in Table 5, it demonstrates that analyzing emotions first yields better results than\nextracting causes first, as it aligns more closely with\nhuman reasoning. Additionally, template structures\nbased on causal connectives such as \"because\" achieved the highest emotional cause recognition\nperformance and effectively enhanced the empathy of responses, which indicates that causal connectives can effectively uncover implicit causal rela-\ntionships in dialogues (Zhou et al., 2022a)."}, {"title": "7 Conclusion", "content": "In this paper, we propose a novel cause-aware CoT fine-tuning method for empathetic generation. Our proposed method leverages the designed CoT gen-\neration template to guide the model in conducting listener-aware cognitive inference, while also im-proving response effectiveness through fine-tuning. Additionally, we utilize emotional causes to further enhance the consistency between external knowl-edge and dialogue history. Detailed automatic and manual evaluation results demonstrate the state-of-the-art performance of our model."}, {"title": "8 Limitations", "content": "The limitations of our work can be summarized in the following two aspects. Firstly, we choose the strategy of manually crafting templates intuitively, while exploring additional prompt templates could potentially enhance empathetic effects. Secondly, empathetic responses also require the incorporation of more professional knowledge and skills in psychology. Training LLMs with more empathetic dialogues and psychological counseling corpora could further advance the development of specialized empathetic conversational models."}]}