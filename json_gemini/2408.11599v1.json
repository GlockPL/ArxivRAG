{"title": "Cause-Aware Empathetic Response Generation via Chain-of-Thought Fine-Tuning", "authors": ["Xinhao Chen", "Chong Yang", "Man Lan", "Li Cai", "Yang Chen", "Tu Hu", "Xinlin Zhuang", "Aimin Zhou"], "abstract": "Empathetic response generation endows agents with the capability to comprehend dialogue contexts and react to expressed emotions. Previous works predominantly focus on leveraging the speaker's emotional labels, but ignore the importance of emotion cause reasoning in empathetic response generation, which hinders the model's capacity for further affective understanding and cognitive inference. In this paper, we propose a cause-aware empathetic generation approach by integrating emotions and causes through a well-designed Chain-of-Thought (CoT) prompt on Large Language Models (LLMs). Our approach can greatly promote LLMs' performance of empathy by instruction tuning and enhancing the role awareness of an empathetic listener in the prompt. Additionally, we propose to incorporate cause-oriented external knowledge from COMET into the prompt, which improves the diversity of generation and alleviates conflicts between internal and external knowledge at the same time. Experimental results on the benchmark dataset demonstrate that our approach on LLaMA-7b achieves state-of-the-art performance in both automatic and human evaluations.", "sections": [{"title": "1 Introduction", "content": "Empathetic response generation in conversation aims to generate an understanding of the speaker's experiences and feelings, and to produce appropriate responses (Keskin, 2014). Empathy in social psychology is delineated into the cognitive and affective aspects (Davis, 1983). It has attracted increasing attention for its potential to endow machines with empathetic capabilities across a broad range of applications, such as automated psychotherapy (Liu et al., 2021c) and casual conversation agents (Liu et al., 2022). Existing methods elaborated various small-scale models to comprehend the speaker's emotion state based on emotional labels (Majumder et al., 2020; Tu et al., 2022), or to understand the speaker's situation and experiences combined with common-sense knowledge (Sabour et al., 2022; Lin et al., 2019) generated by COMET (Hwang et al., 2021). With the rise of Large Language Models (LLMs), prompt-based methods have provided a new unified modeling approach by adding both cognition and affection information into the prompt (Zhao et al., 2023; Roller et al., 2020; Lee et al., 2022). Specifically, Qian et al. (2023c) proposed a two-stage generation approach with few-shot Chain-of-Thought (CoT) prompt on LLMs to reason about the speaker's situation (Wei et al., 2022). However, these methods exhibit dependence on the language proficiency of underlying large models, leading to unstable inference performance (Wei et al., 2022). Furthermore, there are two extra limitations of these LLM-based models: (1) they ignore the impact of emotion cause reasoning on empathetic response generation whose importance has been proven in previous works (Gao et al., 2021; Qian et al., 2023a). (2) they lack the awareness of the role as an empathetic listeners, which makes generated responses more rational and less emotionally impactful.\nAdditionally, from the cognition aspect, directly incorporating external knowledge into large-scale models may lead to a decline in response consistency due to its lack of relevance to the contextual history of the conversation (Qian et al., 2023c; Zhao et al., 2023). Instead, we discover that emotional causes involving further reasoning about emotions facilitates organic integration of the affection and cognition aspects and greatly alleviates the conflicts. To address the above problems, we propose a novel cause-aware CoT Fine-tuning Empathetic Generation method (CFEG) on LLMs. We design an universal CoT generation template to guide the model in reflecting on its emotions and causes, and enhancing the role awareness of an empathetic listener. This is initiated by the idea that a good empathetic listener should concentrate more on understanding what triggers the emotion in the dialogue to respond for the speaker's emotion. Simultaneously, instruction tuning can be employed to strengthen the stability of the CoT reasoning. Besides, we implicitly select required common-sense knowledge from COMET directed by emotion cause to enhance the consistency between internal and external knowledge. The knowledge is then incorporated into the prompt to improve the diversity of response generation. Experimental results on the benchmark dataset demonstrate that our method, fine-tuned on LLaMA-7b, significantly outperforms existing methods, and results in more empathetic responses in human evaluations, even better than that of ChatGPT.\nOur contributions are summarized as follows:\n\u2022 We present a novel cause-aware CoT fine-tuning generation method to enhance LLMs' capability of empathy."}, {"title": "2 Related Work", "content": "2.1 Empathetic Response Generation\nIn the field of social psychology, empathy encompasses both affection and cognition aspects (Davis, 1983). Early works relied on emotional signals to mimic human emotions (Majumder et al., 2020; Tu et al., 2022). Recent works incorporated additional common-sense knowledge generated by COMET (Hwang et al., 2021) for deeper cognitive understanding (Li et al., 2022; Sabour et al., 2022). To enhance the relevance of incorporating knowledge with the dialogue, DCKS (Cai et al., 2023) incorporated an emotion-based knowledge selection, while CASE (Zhou et al., 2022b) aligned emotion with knowledge. Meanwhile, Qian et al. (2023b) incorporated additional reasoning steps into the model. Gao et al. (2021); Qian et al. (2023a) leveraged emotion cause recognition to enhance empathetic outcomes. Different from these intricately designed smaller models, our work introduces emotion cause reasoning to generate more reasonable and relevant cognitive knowledge in a simpler manner.\n2.2 Large Language Models\nIn recent years, the capabilities of large language models (LLMs) have significantly improved due to reinforcement learning from human feedback (RLHF) (Stiennon et al., 2020) and instruction tuning (Ouyang et al., 2022). Meanwhile, LLMs can perform reasoning through the construction of prompts (Liu et al., 2023, 2021b) and CoT (Wei et al., 2022). Some studies have made initial attempts to apply LLMs in empathetic dialogues. For instance, Qian et al. (2023c) explored the empathetic generation capabilities of ChatGPT by two-step generation (Wei et al., 2022). However, Wei et al. (2022) points out that the CoT method can lead to erroneous reasoning when the model has fewer parameters. With the advent of fine-tuning techniques based on LoRA (Hu et al., 2021), the capabilities of LLMs have been further enhanced.\nUnlike the aforementioned work, our method combines emotion cause reasoning and fine-tuning, enabling relatively smaller models (e.g., LLaMA-7b) to utilize CoT more effectively, achieving superior reasoning abilities and empathetic effects beyond ChatGPT."}, {"title": "2.3 Emotion Cause Pair Extraction", "content": "The task of Emotion-Cause Pair Extraction (ECPE) aims to recognize the emotions expressed by speakers and identify the causal spans. Poria et al. (2021) provided the RECCON dataset for this task. Gao et al. (2017); Gui et al. (2014) jointly extract emotions and causes. MGSAG (Bao et al., 2022) proposed to incorporate fine-grained and coarse-grained semantic features jointly without regard to distance limitation. Jeong and Bak (2023) learned relationship between utterances and advised a gating network to incorporate dialogue features. We utilize the ECPE methods to annotate causes of the dialogue in the benchmark dataset."}, {"title": "3 Problem Definition", "content": "Empathetic generation aims to understand the emotions of the speaker in the role of a listener and provide an empathetic response. Formally, let \\(D = \\{U_1, U_2,\u2026, U_n\\}\\) denotes a dialogue history with n utterances, where the i-th utterance \\(u_i = \\{W_1, W_2,\u2026\u2026, W_k\\}\\) is a sequence of k words. The goal is to identify the current emotions \\(e_n\\) of the speaker for the last utterance \\(u_n\\), and play the role of the listener to generate a empathetic and informative response Y."}, {"title": "4 Method", "content": "Our proposed CFEG method is basically fine-tuned on LLMs. In this section, we first present how to construct cause-aware CoT prompt template consisting of the instruction, dialogue context, and external knowledge. Then, we introduce the CoT output template and the fine-tuning method.\n4.1 Cause-Aware Prompt Construction\nCommon Prompt\nLLMs have been demonstrated to perform empathetic generation given appropriate task instructions (Roller et al., 2020; Lee et al., 2022). Given the dialogue history D as the input, one of the basic prompt for this task is as follows:\n\\(P_1 = \"\\{Ins_1\\}.The Dialogue: \\{D\\}.\"\n(1)\nHere, {Ins\u2081} represents the task instruction: \"Analyze emotion and respond empathetically to the provided dialogue\". {D} represents the dialogue history which consists of the roles (speaker, listener) and the dialogue utterances, and we use \";\" to concatenate multiple turns. Then, we input the prompt to a LLM, e.g., LLaMA-7b (Touvron et al., 2023) to generate the empathetic response {Res}. Typically, the responses may take the form of \"He feels ..., I will reply as follows: ...\".\nCause-Aware CoT Strategy\nCoT refers to a series of intermediate reasoning steps (Brown et al., 2020), which controls the direction of the model's thinking through multiple steps. In the empathetic generation task, LLMs are required to infer the speaker's emotion and the situation. Therefore, previous works (Qian et al., 2023c) utilized CoT to generate an appropriate and more human-like response. Specifically, in the first stage, the model is prompted with \"Don't rush to reply yet, what may be the user's emotion, and what may be the situation?\" to guide speculation on the situation based on the user's statement. Then, in the second stage, prompted with \"Combine your thoughts with the dialogue context and give your response.\", the final response is generated. However, this kind of CoT methods relies on the model's linguistic capabilities, leading to uncontrollable situation reasoning that may be inconsistent with the dialogue history (Wei et al., 2022).\nDifferent from directly inferring the situation (Qian et al., 2023c), we propose to use a cause-aware CoT strategy to guide the model in first extracting emotional causes (formalized as a phrase encompassing start and end positions), and then generate responses. Our CoT prompt is as follows:\n\\(P_2 = \"\\{Ins_2\\}. The Dialogue: \\{D\\}.\"\n(2)\nwhere {Ins\u2082} represents the cause-aware task instruction:\"Analysis the emotion and identify the cause from the dialogue. Then respond empathetically to the provided dialogue.\". Results are generated from LLMs in the form of \"He feels ... because he says ... I will reply as follows: ...\".\n4.2 Cause-Oriented COMET\nCOMET (Hwang et al., 2021) is a pre-trained GPT-2 model (Radford et al., 2018) that has been fine-tuned on triplets (e, r, i) extracted from the ATOMIC dataset (Hwang et al., 2021), where e represents the event, r represents the relation type, and i represents the inferred knowledge. Five common-sense relations of inferences are generated: the impact of events on individuals (xEffect), their reactions to events (xReact), the intentions prior to events (xIntent), the requirements for events to occur (xNeed), and the desires following events (xWant).\nPrevious methods (Sabour et al., 2022; Zhou et al., 2022b; Qian et al., 2023c) utilize COMET to acquire external knowledge from the last turn of the dialogue, which is then fused into the model to improve the diversity of generation. However, we find that there exist conflicts between the external knowledge and the dialogue context. To settle this problem, we propose to use COMET knowledge generated from the emotional cause-span instead:\n\\(k_{gcpe} = COMET(r_i, \\{cau\\})\n(3)\nwhere \\(r_i \\in \\{xReact, xWant, xNeed, xIntent, xEffect\\}\\), and {cau} represents the causal span extracted from the history (e.g., in Figure 1's dialogue, the causal span is 'I just broke up with my girlfriend.'). We concatenate the knowledge and transform it into natural language segments \\(l_{k_{gcpe}}\\) (e.g., \"He tends to look nice; He needs to have a haircut; He wants to fix his hair; The effect is that he ends up burning his hair; He feels embarrassed.\").\nWe then incorporate the cause-oriented COMET knowledge into the CoT prompt:\n\\(P_{kg}^2 = \"\\{Ins_2\\}.The Dialogue: \\{D\\}. In this Dialogue, \\{l_{k_{gcpe}}\\}\"\n(4)\n4.3 Instruction Tuning\nOutput Template\nInstruct tuning is employed to further enhance the model's empathetic expression. As the format of output plays an important role in the fine-tuning procedure, we also wrap the emotion reasoning and response into a natural language template. Normally, the output format of common prompt P\u2081 is as follows:\n\\(R_1 = \"He feels\\{emo\\}.\\nI will reply him: \\{response\\}.\"\n(5)\nWe design the cause-aware CoT output format of P\u2082 as follows:\n\\(R_2 = \"He feels\\{emo\\}because he says\\{cau\\}.\\nI will reply him: \\{response\\}.\"\n(6)\nHere {emo} represents the speaker's emotion and {cau} represents the speaker's causal span in the history that needs to be predicted.\nListener-Aware CoT Strategy\nEmpathy is inherently subjective, influenced by both the speaker's description and the listener's feeling. Therefore, transforming the output template into a listener-aware format helps the model differentiate the speaker's emotions from its own responsive emotions. Different from previous work (Zhao et al., 2022), which solely perceived the emotions of the speaker and listener, we have further enhanced the model's capability to infer conversational intent. The listener-aware CoT output template is as follows:\n\\(R_a = \"He feels\\{emo\\}because he says \\{cau\\}. I'm \\{emo\\}to hear that.\\nI will\\{Intend\\}him:\\{response\\}.\"\n(7)\nHere, {emo} represents the listener's emotion reflected by the model. The model chooses \"glad\" or \"sorry\" based on the user's emotion, and {Intend} represents the conversational intent, selecting either \u201creassurance\u201d or \u201csympathize\u201d based on the user's emotion.\nDemonstration\nLLMs possess the ability of in-context learning(ICL) (Brown et al., 2020), a small amount of data examples can enhance the performance of the model. Inspired by Qian et al. (2023c), given the current dialogue, we sample 5 complete dialogues containing replies from the training dataset to construct the demonstration in the format:\n\\(E = \"I'll give you five examples.\\nExamples\\{D_1, ...D_5\\}.\"\n(8)\nLoss Function\nThe demonstration is added after {Ins\u2082} in \\(P_{kg}^2\\) to get our final input prompt \\(P_{kg+E}^2\\). After the prompt and output template are designed, we transfer all the samples in the datset into a prompt and output pair \\(< P_{kg+E}^2\\), \\(R_a >\\). The supervised fine-tuning loss of the LLMs is as follows:\n\\(L = - \\sum_j log p_\\theta (R_t|P, R_{<t})\n(9)\""}, {"title": "5 Experiment", "content": "5.1 Experiment Setup\nDataset We conduct experiments on the EmpatheticDialogue (Rashkin et al., 2018).\nThe dataset comprises 24,850 dialogues, each annotated with one of 32 emotion categories, and involved two turns of empathetic conversation between a speaker and a listener. Following previous works (Rashkin et al., 2018), we randomly split the train/valid/test sets in an 8:1: 1 ratio.\nEmotion Cause Annotation As our method requires additional emotional cause-spans, we train a LLaMA-7b model on the RECCON dataset (Poria et al., 2021), which is utilized for conversation emotional cause-span recognition. The model achieves a macro_F\u2081 score of 74.16% on the test set. We then utilize this model to make inference on the EmpatheticDialogue dataset. Manual evaluation of 100 randomly sampled dialogues results in a macro_F\u2081 score of 72.34% on the EmpatheticDialogue dateset, demonstrating sufficient performance for conducting CoT reasoning and generating external knowledge in our method.\nEvaluation Metrics We assess the models' performance using both automatic and human evaluations. For automatic evaluation, we employ Perplexity (PPL) for generation quality, Distinct-n (Dist-1/2) (Li et al., 2015) for response diversity, BLEU-n (BLEU-2/4) (Papineni et al., 2002) for response similarity and relevance, and emotion accuracy (ACC) for emotion prediction. Human evaluation intuitively validates the model's expression and empathy which consist of on four aspects: Coherence (Coh.), assessing relevance to the context; Empathy (Emp.), evaluating understanding and empathetic expression; Informative (Inf.), measuring incorporation of external knowledge; and Fluency (Flu.), assessing naturalness. During the evaluation process, we randomly select 200 conversation contexts. Annotators consist of both graduate students and experienced experts who have undergone systematic training. They are asked to score each response on a scale from 1 to 5(1: not at all, 3: OK, 5: very good).\nBaselines We compare our methods with both existing small-scale models and LLMs.\n\u2022 Non-LLMs: (1)MIME generated responses by imitating human emotions (Majumder et al., 2020); (2) CEM incorporated additional external commonsense knowledge (Sabour et al., 2022); (3) DCKS incorporated an adaptive module for common-sense knowledge selection (Cai et al., 2023); (4) EmpSOA aligned cognitive and emotional graphs (Zhou et al., 2022b).\n\u2022 LLMs: LLaMA-7b (Touvron et al., 2023) and ChatGPT have been chosen as the baseline models for empathetic generation. Following Qian et al. (2023c), we add the following strategies to these two models: (1) +ICL involved incorporating semantically similar In-Context Learning (Liu et al., 2021a); (2) +CoT inferenced the speaker's situation before response; (3) +CKG meanwhile, +kgecpes utilize the cause-oriented COMET to generate higher-quality knowledge, distinguishing it from previous methods (Qian et al., 2023c).\nImplementation Details The overall project framework is implemented using LLaMA-Factory2. The LLaMA-7b model is downloaded from the open-source huggingface Transformers\u00b3. We perform fine-tuning on the model using LoRA (Hu et al., 2021), with a learning rate set to 5e-5, LoRA rank 8, and a batch size of 4. The common-sense knowledge is generated from COMET4. In order to ensure deterministic outputs in our experiments, we set the temperature to 0. We use the model gpt-3.5-turbo provided in the OpenAI API for the baselines, which is the base model of ChatGPT5. The training is conducted on a server equipped with 8 NVIDIA RTX 3090 GPUs, utilizing the Accelerate framework6.All experiments are conducted on 5 random seeds. We select the model with best performance on the validation set and run it on the test set to report its average results."}, {"title": "5.2 Experimental Results", "content": "5.2.1 Automatic Evaluation\nTable 1 shows the main results of our method and other baselines. Experiment results demonstrate that our CFEG method achieves the best performance on all metrics except the PPL metric, indicating that incorporating CoT fine-tuning can enhance the model's emotion understanding capability. Specifically, compared to all the non-LLMs models, the LLMs-based approaches exhibit significant advantages due to the inherent linguistic capabilities of the model itself. In comparison with ChatGPT+CoT, the CFEG method improves emotion accuracy by 4.53% while also enhancing BLEU-1/2 scores by 5.55% and 3.80%, indicating that our cause-aware CoT strategy guides the model to analyze emotions and causes from the history, resulting in better human-like empathetic outcomes. Meanwhile, Providing common-sense knowledge leads to improvements in both LLaMA-7b and ChatGPT on the Dist-2/4 metrics. However, compared to ChatGPT+CKG, the CFEG method shows a further improvement of 0.23% and 1.23%, respectively. attributed to the higher-quality knowledge generated by cause-oriented COMET aligning better with the context. It's worth mentioning that providing cause-oriented knowledge to LLAMA and ChatGPT can also further enhance empathetic effectiveness.\n5.3 Human Evaluation\nThe human-evaluated results demonstrate that our CFEG method outperforms the baseline in the Coh., Emp., and Inf. aspects. Particularly, the superiority of our cause-aware CoT finetuning method in empathy and informativeness indicates its advantage in cognitive empathy and affective interaction, supporting the observations from automatic evaluations. The Flu. score of the CFEG method is inferior to ChatGPT, mainly because we utilize LLaMA-7b for response generation, which has significantly fewer parameters compared to ChatGPT, resulting in a gap in language capability. Additionally, Providing cause guided knowledge to ChatGPT leads to improvements in both Coh. and Inf. score, underscoring the superiority of our knowledge generation method.\nMeanwhile, following Sabour et al. (2022), we conduct an aspect-based pairwise preference test where annotators choose the better response from two results. The results are listed. We observe that our model also outperforms all the baselines, which confirmed that our method can improve the empathy effect of responses. Compared to ChatGPT+CoT, it can be seen that in 55% of cases in the A/B test, human annotators prefer responses generated by the CFEG model. This indicates that our CoT fine-tuning method enable better understanding of user affection and cognition.\n5.4 Ablation Study\nTo analyze the performance of different strategies, we conduct experiments on the following modifications: (1) w/o Ri: We conduct ablation studies on individual prompts to observe the influence of causal reasoning and listener-aware reasoning. (2) w/o kgecpe: We remove the external knowledge to observe its impact on empathetic generation; (3) w/o E: We ablate examples to observe the impact of in-context learning; (4) w/o sft: We perform ablation on fine-tuning to observe the effect of fine-tuning CoT reasoning.\nAs shown in Table 1, the model with all modules exhibited better performance. Firstly, when R2 is removed, there is a decrease of 3.42% and 0.36% in BLEU-2/4 scores, and in manual analysis, the Emp. metric shows the most significant decrease. This is because the model lacks reasoning about emotions and causes. Secondly, when Rha is removed, both automatic evaluation metrics and manual evaluation decrease, indicating that listener-aware reasoning is closer to the conscious process of expressing empathy in humans. Additionally, when kgecpe is removed, the Inf. metric decreases by 0.94, indicating that external knowledge can effectively enhance the informativeness of responses. Removing E weakens the patterns learned by the model from instructions. Performance is lowest when no fine-tuning is performed. Fine-tuning ensures the stability of CoT reasoning while learning genuine human expressions.\n5.5 Case Study\nThe generated responses from our method and the compared baselines are list in Table 3. Our CFEG model is more likely to respond in a highly empathetic tone and is more consistent with the conversation. This is attributed to two major advantages: on one hand, cause-oriented COMET provides high-quality common-sense knowledge, reducing the model's misunderstandings. ChatGPT also further enhances empathetic effects with cause-oriented knowledge. On the other hand, we utilize CoT reasoning during responses to search for emotional causes, and reflect on the emotions as a listener, such reasoning combines affective and cognitive understanding, which aids in empathetic responses."}, {"title": "6 Discussion", "content": "6.1 Effect of External Knowledge\nIn this section, we further analyze the quality of knowledge generated by different methods, focusing on two perspectives: emotional consistency and contextual coherence. Qian et al. (2023c); Sabour et al. (2022) provided the last dialogue turn to COMET. DCKS (Cai et al., 2023) selected knowledge using emotions. In contrast, Our CFEG method generate knowledge oriented by causal spans. Finally, we also utilize ChatGPT to directly generate knowledge. Specifically, three evaluators rate them on a scale of 1 to 5 for Empathy and Coherence (e.g., in Table 3, while the emotion tone of the knowledge is consistent, \"Need to have a hair dryer\" conflicts with the history, hence receiving a Coherence score of 3 and an Empathy score of 5). The experimental results are shown in Table 4. It can be observed that, compared to DCKS and ChatGPT, the CFEG method achieves higher consistency scores. This is due to the incorporation of causal information, giving us an advantage in maintaining consistency within the dialogue history.\n6.2 Effect of CoT Output Templates\nThere are performance differences between different CoT output templates of the emotion and cause part in Ra. We explore various templates to analyze the accuracy of emotion recognition, the macro_F\u2081 score of cause extraction, and the empathetic effect of the responses through manual scoring. As shown in Table 5, it demonstrates that analyzing emotions first yields better results than extracting causes first, as it aligns more closely with human reasoning. Additionally, template structures based on causal connectives such as \"because\" achieved the highest emotional cause recognition performance and effectively enhanced the empathy of responses, which indicates that causal connectives can effectively uncover implicit causal relationships in dialogues (Zhou et al., 2022a)."}, {"title": "7 Conclusion", "content": "In this paper, we propose a novel cause-aware CoT fine-tuning method for empathetic generation. Our proposed method leverages the designed CoT generation template to guide the model in conducting listener-aware cognitive inference, while also improving response effectiveness through fine-tuning. Additionally, we utilize emotional causes to further enhance the consistency between external knowledge and dialogue history. Detailed automatic and manual evaluation results demonstrate the state-of-the-art performance of our model."}, {"title": "8 Limitations", "content": "The limitations of our work can be summarized in the following two aspects. Firstly, we choose the strategy of manually crafting templates intuitively, while exploring additional prompt templates could potentially enhance empathetic effects. Secondly, empathetic responses also require the incorporation of more professional knowledge and skills in psychology. Training LLMs with more empathetic dialogues and psychological counseling corpora could further advance the development of specialized empathetic conversational models."}]}