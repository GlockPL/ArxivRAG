{"title": "AMM: Adaptive Modularized Reinforcement Model for Multi-city Traffic Signal Control", "authors": ["Zherui Huang", "Yicheng Liu", "Chumeng Liang", "Guanjie Zheng"], "abstract": "Traffic signal control (TSC) is an important and widely studied direction. Recently, reinforcement learning (RL) methods have been used to solve TSC problems and achieve superior performance over conventional TSC methods. However, applying RL methods to the real world is challenging due to the huge cost of experiments in real-world traffic environments. One possible solution is TSC domain adaptation, which adapts trained models to target environments and reduces the number of interactions and the training cost. However, existing TSC domain adaptation methods still face two major issues: the lack of consideration for differences across cities and the low utilization of multi-city data.\nTo solve aforementioned issues, we propose an approach named Adaptive Modularized Model (AMM). By modularizing TSC problems and network models, we overcome the challenge of possible changes in environmental observations. We also aggregate multi-city experience through meta-learning. We conduct extensive experiments on different cities and show that AMM can achieve excellent performance with limited interactions in target environments and outperform existing methods. We also demonstrate the feasibility and generalizability of our method.", "sections": [{"title": "1 INTRODUCTION", "content": "Traffic lights play an important role in our daily traffic. They coordinate vehicles at intersections to maintain smooth and safe transportation. However, the traffic signals may be inefficient sometimes. According to the study carried out by traffic data analysis company Inrix, the time spent waiting at traffic lights is about 10% of total trip time in the United States. Therefore, traffic signal control (TSC) is a vital research direction in the transportation area. Traditional TSC methods (e.g. fixed-time) sometimes allocate traffic resources unreasonably, leading to traffic jams and economic loss, while a smart TSC policy can improve both transportation efficiency and safety. Thus, it is necessary to find a suitable policy for urban traffic.\nRecently, researchers have applied reinforcement learning (RL) to TSC problems. By interacting with the traffic environment, RL methods achieve superior performance over the conventional TSC methods [8, 12, 18, 21]. However, the applications of the RL methods face great challenges. The major concern is that RL methods train models by trial and error, causing enormous costs when interacting with real-world environments. Specifically, due to the limited physical resources, it is almost impossible to train models from scratch in every single traffic environment.\nTherefore, to overcome this challenge and avoid unnecessary waste of resources during model training, adapting trained models to new environments is a feasible and effective solution. In this paper, we focus on TSC domain adaptation, which plays an important role in TSC applications due to the fact that it is able to significantly reduce interaction with real-world environments. However, there are many issues with existing TSC domain adaptation methods. We identify two main issues that current approaches face in model adaptation across different traffic environments in the real world:\nThe first issue is the neglect of the variations in the observations across different cities, which may affect the input of the model. This can lead to a significant drop or even a complete failure in the model's performance when applied to a new city. In current approaches to TSC domain adaptation, the observation that is obtained from the environment is usually fixed. However, as Fig. 1 shows, in real-world scenarios, we may only obtain certain limited information on traffic conditions as observations. These observations of different environments may describe different physical quantities respectively, which means they have completely different physical meanings, and even the dimensions of the observations are changed."}, {"title": "2 RELATED WORK", "content": "Traffic Signal Control. As a major public concern, Traffic Signal Control (TSC) has raised the interest of researchers for a long time. FixedTime [1] and SOTL [5] are the earliest methods proposed based on conventional transportation. FixedTime fixes the passing time for each direction in the intersection during a cycle, while SOTL determines the passing direction according to the congestion by cycle. MaxPressure [17] provides an explicitly more effective solution, which allocates passing time to the direction with the maximum traffic pressure. An important idea is the introduction of Reinforcement Learning (RL) to the TSC problem. Various of RL-based TSC methods outperform conventional transportation methods. Intellilight [21], FRAP [26], and Presslight [18] represent the features in TSC and use the representation to learn a control policy for traffic signals. Metalight [23], Colight [19], MPLight [3], and AttendLight [12] combine the advantages of RL and multi-agent learning to achieve new state-of-the-art performance. Unilight [8] constructs a communication mechanism between traffic signal agents to enhance cooperativity. In recent years, researchers focused on mining more expressive representations of features in TSC [22, 25]. A-MPLight and E-MPLight refine the representation used in MPLight and outperform existing TSC methods in several scenarios.\nDomain Adaptation in Reinforcement Learning. Three categories of methods are widely used in improving the adaptability of policies in RL. Domain randomization [2, 10, 14, 15] expects stronger generalizability of models after training them on various and randomized domains. State-generalization-based methods [10, 13, 16] match the states of the source and target domain with generative models, for example, Generative Adversarial Nets (GANs) [6], which are specifically common in the vision-based task of RL. A novel group of methods proposed recently is based on learning a latent state representation. This group of methods [7, 11] hopes to learn a high-level representation of both states of the source and the target domain. By exploiting feature compression methods in the field of representation learning, such as the Variational Auto Encoders (VAEs) [9], these methods achieve good performance in many vision-based RL tasks."}, {"title": "3 PRELIMINARIES", "content": "3.1 Problem Definition\nPROBLEM 1 (TRAFFIC SIGNAL CONTROL). Following existing research [18, 19], a traffic signal control (TSC) problem can be defined as a Markov Decision Process (MDP). Typically, this MDP can be denoted by a tuple < O, A, T, R, \u03b3 >. In our problem, the observation o \u2208 O refers to various features which characterize the traffic, the action a \u2208 A the next traffic signal, the reward r \u2208 R some metrics that measure the congestion. The goal is to learn a stochastic policy (at = a | st = s) that maximizes the following the expected"}, {"title": "3.2 Practical Notation", "content": "We formulate the traffic signal control problem in a Markov Decision Process setting. The observation, action, and state are defined as follows.\n3.2.1 Observation. We define the observation as a vector of physical quantities with shape l \u00d7 do, denoted by o. The first dimension"}, {"title": "4 METHODOLOGY", "content": "4.1 Overview of the Method\nWe propose Adaptive Modularized Model (AMM) to solve the issues with existing TSC domain adaptation methods. AMM modularizes the TSC RL models into three modules to improve the performance of adaptive models with limited interactions in target environments. The three modules are the representation transition module, internal dynamics module, and value-evaluating module, respectively. We will elaborate on our module design and overall algorithm in the subsections below.\n4.2 Module Design\nIn past works, TSC problems are solved in ideal traffic environments. Normally, researchers can obtain all detailed information about traffic conditions and make a decision according to the analysis of the information. However, there exist great challenges when solving the problem in this way in the real world. The main challenges are:\n(1) It is hard to get all the detailed information about traffic conditions. Due to the complexity of traffic conditions and the large amount of traveling vehicles, we can observe in the real world usually only partial and simple information.\n(2) The observations of different traffic environments may be different. Limited by real-world infrastructure, this is quite possible. For example, city A only provides information on the average speeds of vehicles while city B only provides the number of vehicles on lanes. In this case, two observations have completely different physical meanings. Furthermore, city C may provide two pieces of information: the average speeds and the positions of vehicles. In this case, the observation of city C even has a different dimension from cities A and B.\n(3) The cost of real-world interactive data is enormous. Recently, researchers solved the TSC problems through reinforcement learning, which requires a lot of interactions with the real environment. This may result in a waste of traffic resources and even traffic accidents. Moreover, we notice the low reusability of data and trained models across multiple cities although they are similar in some ways.\nConsidering the challenges mentioned above and the practical application of TSC in the real world comprehensively, we hope that we can find a common pattern shared by multiple cities. In this way, we can avoid redundant repetitive training of similar parts. Specifically, our objective is that the model that fits the city A environment should adapt to the city B or C environment with a small amount of interactive data although their observations are different.\nWe propose Adaptive Modularized Model (AMM) to overcome the challenges. As Fig. 4 shows, AMM modularizes the TSC problem into three modules: representation transition module, internal dynamics module, and value-evaluating module. The representation transition module encodes the various features input into a shared hidden embedding space. Then, the internal dynamics module models the dynamics via next-state prediction. After that, the"}, {"title": "4.2.1 Representation Transition Module", "content": "The observation of the traffic environment may vary (e.g., in different cities), which means the physical meaning and the dimension of the observation may be completely different. The model can not take the changed observation as input, causing the failure of the model.\nThe most straightforward way to solve it is to train extra layers and concatenate them with the original model as input converters. The major problem with this solution is the high difficulty of predicting the physical quantities from other physical quantities that may poorly correlate with the former. Learning an approximation function between them requires lots of interactive data, which is away from our goal. Besides, adding additional modules also increases the cumulative error of the model. Thus, we choose to modularize the model, separating observations from states. In the model adaptation, we discard the original representation transition module. Because the internal state is strongly correlated with most physical quantities, it is easier to build the connection from the observation to the state. So it is able to reach a better effect and needs less interactive data.\nIn a domain D, the representation transition module takes the observation as input and returns the state. It can be written as a function f:\nsp = f_D(ot)\nNote that f_D is different for different D.\nWe define the distance between the two states as follows.\nDist (s_1, s_2) =\n\\sum_{i=0}^{N-1} \\beta^{2} (\\sum s_1[i * n : (i + 1) * n] - \\sum s_2 [i * n : (i + 1) * n])^2"}, {"title": "4.2.2 Internal Dynamics Module", "content": "The internal dynamics module takes the current state st of a domain D as input and predicts the state after one or a few steps with a given action sequence At. It"}, {"title": "4.2.3 Value-Evaluating Module", "content": "The value-evaluating module receives the predictions and evaluates their value, then outputs a traffic signal action sequence based on the policy \u03c0.\nAt = \u03c0(st) = arg max_{A^{(k)}} V (st+h,A^{(k)})\nwhere V is the value-evaluating function defined as Eq. 4, and $A^{(k)}$ is the kth possible action sequence that can be taken at timestamp t. A common policy \u03c0 is e-greedy, that is, choosing the action sequence that is predicted to make the most value with probability e otherwise taking a random action."}, {"title": "4.3 Multi-city Experience Aggregator", "content": "The internal state dynamics module is a deep network that approximates the internal state transition process. Since the internal traffic logic may be similar in different cities, we can use the multi-city data to learn the common logic of similar cities after decoupling the deep representations (i.e. the states) from the observations. To leverage data from different cities, we train the dynamics module on multi-city data through Model-Agnostic Meta-Learning (MAML) [4]. MAML is an algorithm for learning a set of potential parameters for several similar tasks. Through MAML, the initialized parameters of the dynamics module are sensitive to a specific TSC environment and will converge to an optimal one after fine-tuning. Compared to the normal pre-train algorithm, MAML enables the model to reach better performance in general cases.\nThe process is as shown in Alg. 1."}, {"title": "4.4 Overall Algorithm", "content": "AMM modularizes TSC problems into three modules: the representation transition module, the internal dynamics module, and the value-evaluating module. Each module is decoupled from others and can be seen as a function. The three functions are defined in Eq. 5, Eq. 7, and Eq. 8. For the representation transition module and the internal dynamics module, we use two deep networks to approximate the functions respectively. The value-evaluating module uses explicit functions Eq. 8 and Eq. 4. As Fig. 3 shows, in multiple source traffic environments, AMM interacts with the environments and aggregates the multi-city experience of internal dynamics through meta-learning. In the target traffic environment, AMM initializes the internal dynamics module with the learned parameters in the source environments first. Then AMM trains the representation transition module and fine-tunes the internal dynamics module at the same time through a small amount of interaction with the target environment.\nThe overall algorithm of AMM is as shown in Alg. 2."}, {"title": "5 EXPERIMENTS", "content": "5.1 Experimental Setup\n5.1.1 Simulator. We use CityFlow [24], an open-source traffic simulator that runs real-world traffic transportation simulations, as our traffic environment simulator. CityFlow is widely adopted by researchers as a simulated traffic environment due to its realism and efficiency.\n5.1.2 Datasets. Considering that our method is for real-world traffic applications, we use CityFlow open datasets [20]. CityFlow open"}, {"title": "5.1.3 Metrics", "content": "We choose average travel time and average queue length as experimental metrics. Travel time is the time that a vehicle spends traveling in the roadnet. It equals the time a vehicle enters the roadnet minus the time it leaves the roadnet. Average travel time is commonly used as the metric in TSC problems. It indicates the efficiency of traffic. Queue length is the number of vehicles waiting for traveling. Average queue length reflects the situation of road congestion and the waiting situation of traveling vehicles."}, {"title": "5.1.4 Observations", "content": "To enhance the correlation between observation and internal state. We provide basic and simple observation--the total number of vehicles on the lanes for all three traffic environments. Additionally, Hangzhou(4 \u00d7 4) has the number of vehicles that enter the intersection during the last action interval; Manhattan(16 \u00d7 3) has the number of vehicles that pass the middle of the roads during the last action interval; Manhattan(28 \u00d7 7) has the average speed of traveling vehicles in the last third and the middle third respectively. Note that it is only our method that uses this information as observations. The baseline methods still follow the default setting, with which they can obtain any information on traffic conditions they want."}, {"title": "5.1.5 Details", "content": "The process by which the model completely interacts with the environment once is as follows: (1) Every time a model interacts with the traffic environment, it will get the current environmental observations, states, and rewards of all intersections. (2) Then the model takes the information as input and processes it according to the corresponding method. (3) Finally, it outputs an optimal traffic signal phase action.\nAs above mentioned, each data provides vehicle flow data of 3600 seconds. Every 20 seconds, the model will interact with the environment once and produce a traffic signal phase action. The traffic signals will keep the same phases until the next action arrives. All intersections in the roadnet share a decision-making agent. And this agent can get traffic information on all intersections.\nFor each method, we train its corresponding model on little single-city data, simulating the lack of real-world interactive data. Then we evaluate the model with the two metrics mentioned above. All methods follow default settings. Note that due to the difference in dimensions of observations among cities, AMM can reuse part of the traffic data of other cities to train its modularized model. But all observations of AMM are relatively simple and light compared to other methods."}, {"title": "5.2 Compared Methods", "content": "We compare our method with two categories of methods: conventional methods and RL methods.\nConventional baselines:\n\u2022 Fixed-Time [1]: a method that switches traffic signal phases after a fixed period of time. There are four fixed-order phases in total."}, {"title": "5.3 Quantitative Results", "content": "Experiment results are shown in Tab. 1. We report the comparison performance of several common TSC methods and ours with respect to average travel time and average queue length. The results show that (1) AMM achieves the expected state-of-the-art performance. It is mainly because of its modularized design, which enables the model to use other cities' data although their observations have different physical meanings and dimensions. Furthermore, the meta-learning method MAML also helps the model find a good solution after fine-tuning with just a small amount of interactive data. (2) Conventional TSC methods (fixed-time, MP, SOTL) achieve better results compared to other baseline methods based on deep learning. The conventional methods do not need training and produce a determined action sequence for given data, while methods based on deep learning require lots of training. Hence, the performances of these methods are worse in our setting which only provides very little data.\nWe also conduct an experiment to compare the performance with different amounts of interactive data of different methods. The comparison results are shown in Fig. 5. The 100% data volume of the three scenarios is 60 episodes of interactions. The results are processed using sliding window average.\nIn Fig. 5, we can see that AMM converges to an optimal solution much faster than baselines, which means AMM requires fewer interactive data to reach the same performance. The results show that AMM significantly reduces the requirement for data in a new traffic environment, avoiding unnecessary waste during the model training."}, {"title": "5.4 Ablation Study", "content": "5.4.1 Study 1: The effect of modularized model design. To show that the modularized model design is necessary, we conduct an experiment to compare the performance of the modularized model and non-modularized model.\nThe two methods have the same model layers. And both two models are trained through MAML. The modularized model is trained on multi-city traffic data because it does not require the consistency of the dimensions of observations of cities. And the non-modularized model is trained on specific single-city data. In the evaluation stage, after the traffic environment changes, the parameters of the dynamics module of the modularized model are initialized by the values learned by MAML, while the non-modularized model inherits the parameters of the last layers.\n5.4.2 Study 2: the effect of MAML on the dynamics module training. We conduct a comparative experiment between the two methods:"}, {"title": "5.5 Factors That Affect Generalizability", "content": "There are many factors that may affect the generalizability of the model trained by MAML. For instance, the training epoch and the complexity of the model. Of all the factors, the complexity of the model makes sense mostly in intuition. Intuitively, complex models may overfit a specific traffic environment and are hard to converge to an optimum with little data. On the contrary, simple models may have better generalizability but are not able to perform well enough. Thus, we study the effect of the complexity of the model on its generalizability. We change the width and depth of our deep network layers and observe the performances of models with different complexity. We use the number of parameters of the model as the metric to measure the complexity of the models. And We compare the performance w.r.t. average travel time and average queue length in Fig. 6."}, {"title": "5.6 Case Study", "content": "5.6.1 Source city selection. In our method, the design of the dynamics module is mainly based on the intuition of the similarity of internal traffic logic in different traffic environments. In this study, we try to obtain more support for our intuition.\nSuppose there are two cities: the source city A and the target city B. The dynamics process of target city B is similar to A's. Given the solutions to the source city's TSC problems, we need to find the target one. Assuming our intuition is correct, the model adapted from city A should perform not badly after fine-tuning due to their similarity. We conduct an experiment to show the results as our expectation. We mainly train the model on a single source city and fine-tune it on the target city, evaluating the performance of the adaptive model. Specifically, we still use the datasets Hangzhou(4 \u00d7 4), Manhattan(16 \u00d7 3), and Manhattan (28 \u00d7 7) to confirm their common internal traffic logic.\nThe results are reported in Tab. 3. We choose Fixed-Time and Max-Pressure as the compared baselines because of their relatively better performance on the small amount of data than others. the due to its deterministic. The model that is pre-trained in one source city performs not badly, which shows they have similar traffic dynamics processes. Besides, comparing the results with AMM in Tab. 1, we"}, {"title": "5.6.2 Training the observation adapter with offline data", "content": "Due to possible economic loss and traffic resource waste during RL model training, the huge price of interacting with the real-world traffic environment is always a major concern. And that is why the studies usually are carried out in traffic simulators instead of the real world.\nThe offline data is logged by the online environment and can not be interacted with, which means the offline environment can not step with an action. Train the model on logged (i.e. not interactive) data usually get bad performance. The major issue with offline training is that the model can not get timely feedback from the environment. And the unevaluated policy easily goes wrong.\nIn the general case, it is difficult to find the approximated function that maps the current traffic internal state to the next state. So it always spends lots of interactive data building their connection. With the modularized design, the observation-to-state module is separated from the dynamics process. And the relation of observation and state seems not so complex, which makes it possible to reach a good performance by only training the observation adapter module on offline data.\nWe train the observation adapter on offline data that are logged during the Fixed-Time TSC policy interacts with the environment, simulating the process of the offline data produced in the real world. And evaluate the model after concatenating the observation adapter trained on logged data with other modules. As Fig. 7, the model gets pretty good results. The results show that the modular approach allows different training strategies to be performed between different modules so that we can reduce the cost of model training or improve the performance of the model."}, {"title": "6 CONCLUSION", "content": "In this paper, we propose an effective approach named Adaptive Modularized Model (AMM) for the model adaptation of traffic signal control problems. AMM modularizes the TSC problem so that the surface representations are decoupled with the internal dynamics process. Besides, we use meta-learning to aggregate data from multiple cities, making the model more potential to find a great solution to the problem. AMM solves the challenges faced in the model adaptation: (1) the change of observation and internal dynamics; (2) the low reuse of multi-city data that may have completely different physical meanings and even different dimensions.\nWe conduct several experiments, including the comparison experiments with baselines, the ablation experiments, and the expanded experiments in case studies. The experimental results show the effectiveness and plausibility of our method. The modular design splits the deep network model and allows different strategies to be taken in different modules, which creates the space to improve performance further. That may be an interesting research direction in the future."}]}