{"title": "ConDo: Continual Domain Expansion for Absolute Pose Regression", "authors": ["Zijun Li", "Zhipeng Cai", "Bochun Yang", "Xuelun Shen", "Siqi Shen", "Xiaoliang Fan", "Michael Paulitsch", "Cheng Wang"], "abstract": "Visual localization is a fundamental machine learning problem. Absolute Pose Regression (APR) trains a scene-dependent model to efficiently map an input image to the camera pose in a pre-defined scene. However, many applications have continually changing environments, where inference data at novel poses or scene conditions (weather, geometry) appear after deployment. Training APR on a fixed dataset leads to overfitting, making it fail catastrophically on challenging novel data. This work proposes Continual Domain Expansion (ConDo), which continually collects unlabeled inference data to update the deployed APR. Instead of applying standard unsupervised domain adaptation methods which are ineffective for APR, ConDo effectively learns from unlabeled data by distilling knowledge from scene-agnostic localization methods. By sampling data uniformly from historical and newly collected data, ConDo can effectively expand the generalization domain of APR. Large-scale benchmarks with various scene types are constructed to evaluate models under practical (long-term) data changes. ConDo consistently and significantly outperforms baselines across architectures, scene types, and data changes. On challenging scenes (Fig. 1), it reduces the localization error by > 7x (14.8m vs 1.7m). Analysis shows the robustness of ConDo against compute budgets, replay buffer sizes and teacher prediction noise. Comparing to model re-training, ConDo achieves similar performance up to 25x faster.", "sections": [{"title": "1 Introduction", "content": "Localizing an image in a given scene is a fundamental machine learning problem. The scene is defined by a set of reference images with known camera poses, and the task is to return the camera pose of a query image.\nDifferent types of methods have been developed for visual localization. Retrieval-based methods search for reference images similar to the input and use their poses as the output (Torii et al. 2015; Arandjelovic et al. 2016). These methods require storing the reference images during inference, which introduces memory overheads. There are also methods"}, {"title": "2 Related Work", "content": "Absolute pose regression. APR is a classical visual localization approach, which directly regresses the camera's pose based on a single input image when revisiting a known environment. (Kendall, Grimes, and Cipolla 2015) proposed the first APR method, which contains a feature extractor and pose regressor in the architecture. Follow-up methods improve the performance by introducing attention layers (Wang et al. 2020), Transformers (Shavit, Ferens, and Keller 2021) and Diffusion models (Wang et al. 2023). To better leverage scene information, visual odometry and motion constraints (Brahmbhatt et al. 2018; Xue et al. 2019) have been introduced. Recently, NeRFs (Neural Radiance Fields) have been used to generate more data (Moreau et al. 2022; Chen et al. 2022) or geometric constraints (Chen, Wang, and Prisacariu 2021; Moreau et al. 2023) for APR training. Though efficient, APR struggles to generalize to novel poses (Sattler et al. 2019) and scene changes (Cai and M\u00fcller 2023). ConDo is designed to address this problem.\nContinual learning and other related problems. Conventional continual learning methods (Kirkpatrick et al. 2017; Aljundi, Chakravarty, and Tuytelaars 2017) aim to prevent catastrophic forgetting with limited storage. Recent approaches (Cai, Sener, and Koltun 2021; Prabhu et al. 2023) switch the focus to limited computation, aiming to achieve fast adaptation under practical limitations of training resources. This setup is similar to ConDo except that the ground truth labels are assumed to be available during continual model updates, which is impractical for localization systems that require high-end scanning devices to obtain accurate labels. Unsupervised domain adaptation (UDA) (Chen et al. 2021; Nejjar, Wang, and Fink 2023) aims to adapt a pretrained model to a target domain without ground truth. Forgetting and computation budgets are not the major concern. Meta-learning (Finn, Abbeel, and Levine 2017) trains on diverse tasks to adapt with GT labels during inference, both of which are difficult to obtain for APRs. ConDo aims to continually adapt to new domains while preserving the performance of old ones. ConDo distills knowledge from scene-independent localization methods, which is more effective than standard UDA methods for APR."}, {"title": "3 Method", "content": ""}, {"title": "3.1 Preliminaries", "content": "Given an image $I \\in \\mathbb{R}^{H \\times W \\times C}$, APR (Kendall, Grimes, and Cipolla 2015) learns a function $\\mathbf{t}, \\mathbf{r} = f(I|\\theta)$ parametrized by the neural network weights $\\theta$ that maps $I$ to the camera position $\\mathbf{t} \\in \\mathbb{R}^3$ and orientation $\\mathbf{r} \\in \\mathbb{R}^4$ in a pre-defined scene $\\Omega$. $\\Omega$ is defined by a set of training images $S_{\\Omega} = {I_i}_{i=1}^{|S_{\\Omega}|}$ with known poses $P_{\\Omega} = {\\mathbf{t}_i, \\mathbf{r}_i}_{i=1}^{|S_{\\Omega}|}$. The function $f$ is a neural network commonly comprised of a feature extractor $g$ and a regressor $h$, i.e., $f = h \\circ g$ where $g$ extracts the image level feature and $h$ projects the extracted feature to $\\mathbf{t}$ and $\\mathbf{r}$. Conventional APR frameworks train models on $S_{\\Omega}$ and $P_{\\Omega}$ with the regression loss (Kendall and Cipolla 2017):\n$\\mathcal{L}(I, \\mathbf{t}^*, \\mathbf{r}^*) = ||\\mathbf{t} - \\mathbf{t}^*||e^{-s_t} + s_t + ||\\mathbf{r} - \\frac{\\mathbf{r}^*}{\\|\\mathbf{r}^*\\|}||e^{-s_r} + s_r$, (1)\nwhere $\\mathbf{t}$ and $\\mathbf{r}$ are the predicted pose on $I$, $(\\mathbf{t}^*, \\mathbf{r}^*) \\in P_{\\Omega}$ are the ground truth, and $s_t$ and $s_r$ are learnable parameters to balance the position and orientation losses. After training, the APR model is deployed to the environment for inference."}, {"title": "3.2 Continual Domain Expansion (ConDo)", "content": "Due to the scene-dependent nature, the deployed APR model cannot generalize well to images that have highly different poses or scene conditions compared to the training data $S_{\\Omega}$. The key idea of Continual Domain Expansion (ConDo) is to continually update the APR model using the unlabeled data seen naturally after model deployment, so that the model can generalize to more novel poses and scene conditions over time by simply running in the environment.\nAs shown in Fig. 2, ConDo starts from the model trained on $(S_{\\Omega}, P_{\\Omega})$. After model deployment, the (potentially multiple) clients, which use the newest model $\\theta$ to perform localization, upload (asyncronously) the observed images to the server. The server collects all newly received images at time step $k$. These images are added to the pool of unlabeled data $\\Delta = {I_A}_{i=1}^{|\\Delta|}$ and the current model $\\theta_k$ is updated asynchronously from the clients using $S_{\\Omega} \\cup \\Delta$, with limited computation that is much less than model re-training. $\\theta_k$ is re-deployed to the client after the update is finished.\nIn the main experiment of Sec. 5, we impose the constraint so that the compute for the pre-exectued model training plus all update rounds of ConDo is the same as training one APR model from scratch on $S_{\\Omega} \\cup \\Delta$. This ensures that each ConDo update round uses much less compute and time compared to model re-training, so that it can be applied to life-long scenarios. We also experiment with various fixed computation budgets to validate the effectiveness of ConDo in applications with different resource limits.\nTo expand the generalization domain of APR without forgetting, we uniformly sample images from $S_{\\Omega} \\cup \\Delta$ to form a training batch during the model update. Though unsupervised domain adaptation (UDA) methods (Chen et al. 2021; Nejjar, Wang, and Fink 2023) have been proposed for standard image classification and regression, empirically (Sec. 5.2) they are not effective for APR. To generate effective supervision on unlabeled data $\\Delta$, we opt for a distillation-based approach. Inspired by the fact that scene-independent methods (Arandjelovic et al. 2016; Sarlin et al. 2019; Von Stumberg and Cremers 2022), though slower and more memory consuming during inference, are much more robust than APR to novel poses and scene conditions, we distill the knowledge from these methods to APR using $\\Delta$, so that the inference model can still maintain the memory and computation efficiency. Specifically, given a scene-independent method $f_{\\text{teacher}}(\\cdot)$, and a batch of data $B_{\\Omega} \\cup B_{\\Delta}$ sampled from $S_{\\Omega} \\cup \\Delta$, the training objective is\n$\\underset{\\theta}{\\text{minimize}} \\quad \\frac{1}{|B_{\\Omega}| + |B_{\\Delta}|}\\left[ \\sum_{I_{\\Omega} \\in B_{\\Omega}} \\mathcal{L}(I_{\\Omega}, \\mathbf{t}_{\\Omega}, \\mathbf{r}_{\\Omega}) + \\sum_{I_{\\Delta} \\in B_{\\Delta}} \\mathcal{L}_{\\text{distill}}(I_{\\Delta}, f_{\\text{teacher}}(I_{\\Delta})) \\right].$ (2)\nwhere $\\mathbf{t}_{\\Omega}, \\mathbf{r}_{\\Omega}$ are the ground truth pose of $I_{\\Omega}$. We choose HLoc (Sarlin et al. 2019) as the default $f_{\\text{teacher}}$, with scene map built on $(S_{\\Omega}, P_{\\Omega})$ (See Table.5 for the robustness of ConDo with other teachers). We set $\\mathcal{L}_{\\text{distill}} = \\mathcal{L}(I_{\\Delta}, f_{\\text{teacher}}(I_{\\Delta}))$, i.e., substituting the output of $f_{\\text{teacher}}$ into Eq. (1). As shown later in Sec. 5, this simple yet effective loss is sufficient to approach the performance of training with ground truth poses on $\\Delta$, and is robust to the choice of $f_{\\text{teacher}}$. Meanwhile, distilling knowledge on data from new domains not only benefits the performance on the same domain, but can also improve the general robustness of APR, especially under scene condition changes.\nBy default, we assume the server has sufficient storage to maintain all historical data. For applications with limited server storage, we apply reservoir sampling (Rebuffi et al. 2017) to update the replay buffer. Given a sequence of $K$ images and a storage $M$ sufficient to maintain $N$ images, we push the first $N$ images to the storage as usual. For the $i$-th image where $i > N$, we generate a random integer $a$ between [1, $i$]. If $a \\le N$, we replace the $a$-th image stored in $M$ with the $i$-th image in the sequence. Otherwise, we drop the $i$-th image. As shown later in Sec. 5.2, ConDo with reservoir sampling is robust to the replay buffer size.\nFor architectures capable of handling multiple scenes (Shavit, Ferens, and Keller 2021, 2023), ConDo"}, {"title": "4 Benchmark", "content": "To thoroughly evaluate ConDo in practical scenarios, we construct large-scale benchmarks covering both the change of scene conditions (lighting, weather, season) and camera poses. Specifically, we collect public datasets with multiple rounds of scans of the same scene. To simulate the practical scenario, we split multiple scans of the same scene into training and inference and reveal the inference scans sequentially, i.e., every round of ConDo model update starts when a new inference scan is revealed. We randomly hold out images in each scan (training and inference) and use them to evaluate the generalization of APR on the corresponding scan. To create challenging evaluation data, instead of holding out individual images uniformly distributed in each scan, we hold several sets of images where each set is a continuous trajectory of the scan consisting of 16 images (see Fig. 3). The held-out evaluation data allow us to fully evaluate APR on images unseen both during normal training and ConDo.\nTo simulate novel poses and the sequentially revealed multiple scenes, we adopt standard APR datasets, namely, 7Scenes and Cambridge (Glocker et al. 2013; Kendall, Grimes, and Cipolla 2015). These two datasets represent the case of indoor and outdoor scenes respectively and different scans of the same scene contain distinct trajectories, which are suitable to evaluate the case of novel poses. We adopt the same training and inference split as in the baseline APR methods (Kendall, Grimes, and Cipolla 2015; Shavit, Ferens, and Keller 2021). Please refer to Appendix. A.2 for detailed information about the train/inference scan split, multi-scene revealing order, the used coordinate system, etc.\nThe drawbacks of 7Scenes and Cambridge are the limited scene scale (< 140m \u00d7 40m) and scene condition change. The lighting and weather conditions of both datasets remain similar in different scans, and there are no obvious long-term scene changes (seasonal) observed. To address these issues, we utilize large-scale driving datasets with both significant lighting changes (daytime to night time) and long-term scene changes (spring to winter). Specifically, we take the Office Loop and Neighborhood, which are two large-scale scenes in 4Seasons (Wenzel et al. 2021) with a sufficient amount of scans (> 6) in the same scene. Each scan in these two scenes has a > 2km trajectory spanned at multiple city blocks, which is much larger than conventional APR datasets. See Fig. 4 for sample images from different scene scans and Appendix. A.2 for the concrete train/inference scan split."}, {"title": "5 Experiments", "content": "Architectures. We validate ConDo on two representative APR architectures, namely PoseNet (PN) (Kendall, Grimes, and Cipolla 2015) and Pose-Transformer (PT) (Shavit, Ferens, and Keller 2021, 2023), which covers respectively the classic APR architectures for single and multiple scenes.\nImplementation. Unless otherwise stated, the code and hyper-parameter settings of the baselines strictly follow the official code release. The original Pose-Transformer can use multiple regression heads and scene-dependent latent embeddings to handle multiple scenes. We only apply multiple regression heads since it is sufficient to achieve similar performance (Appendix A.4). APRs are first learned on training data until converging in the initial training. In the main experiment, we follow the setup of large scale continual learning (Cai, Sener, and Koltun 2021) and limit the computation budget of ConDo by first identifying the budget $b = \\text{epoch} * \\text{iteration_per_epoch} * \\text{batch_size}/|S|$ for the baseline APR model to converge on the initial training data $S$. $b$ represents the average number of iterations required per image. Then for every round of ConDo update with $N$ images newly revealed, we assign $N * b/\\text{batch_size}$ training iterations (see Appendix A.2 for actual numbers of $b$) with the same batch size as the initial training, so that the whole ConDo procedure including initial training and all ConDo updates, consumes roughly only the budget to train one APR model from scratch on all revealed data. This ensures that we use much less computation than model re-training in every"}, {"title": "5.1 Main Results", "content": "Table 1 and 2 show the main results on benchmarks constructed in Sec. 4 with respectively the scene condition (Office Loop and Neighbourhood) and pose (7Scenes and Cambridge) changes. For each architecture (PN and PT), we show the results of 3 training frameworks:\n1. Train Only: Normal APR training on the initial data $S_{\\Omega}$. Representing the practical base APR performance.\n2. ConDo: The proposed ConDo strategy.\n3. Re-train with GT: Train an APR model from scratch until convergence (infinite computation budget at any time) on both the training and inference data ($S_{\\Omega} \\cup \\Delta$), with the GT label on $\\Delta$ provided. This setup estimates the best performance that ConDo can achieve.\nSee Sec. 5.2 for further comparisons between ConDo and standard UDA methods.\nConDo significantly improved the performance across baseline architectures and datasets. This shows the capability of ConDo to adapt to both scene condition change (Office Loop and Neighbourhood) and data from novel poses (7Scenes and Cambridge), and sequentially learn to localize in multiple scenes (7Scenes and Cambridge). Before ConDo, the mean error of the baselines was much larger than the median error on the inference scans of large-scale datasets. E.g., PT had 42.15m mean error vs 6.12m median error on Office Loop. This indicates the existence of catastrophically failing predictions (see Fig. 5 for visualizations). After ConDo, not only mean and median errors were reduced significantly (by 23x and 4x respectively), but also the difference between them became small. This change shows the significantly improved generalization of ConDo.\nThe performance difference between ConDo and Re-train with GT was small, even though 1) ConDo only used unlabeled inference data, and 2) used limited compute for model updates on sequentially revealed data. For example, Re-train with GT on Office Loop with PT used ~ 120h to reach the reported performance and performed much worse with less compute (see Sec. 5.2), while each ConDo update round only took ~ 20h, i.e., achieving similar accuracy with only \\frac{1}{6} of the compute. Note that this difference will further increase over time with more data collected. Interestingly, ConDo performed marginally better Re-train with GT in Office Loop, it was because HLoc we used is very accurate in this dataset, especially in terms of translation (see Table. 5 for details).\nAnother interesting observation is that whether new data"}, {"title": "5.2 Analysis", "content": "This section analyzes the effectiveness of individual ConDo components, and we report results on Office Loop in the format of position (m)/orientation (\u00b0) error.\nConDo vs UDA. As mentioned in Sec. 3.2, unsupervised domain adaptation (UDA) is widely used to adapt models to novel data. In Table. 3, we compare ConDo with 3 most"}, {"title": "6 Conclusion", "content": "We have identified the problem of APR in generalizing to novel data during inference. We have proposed Continual Domain Expansion (ConDo) to address this problem. By distilling knowledge from scene-independent localization methods, ConDo allows APR to improve steadily and continually while running in deployed environments with unlabeled data. We have constructed large-scale benchmarks covering 1) indoor and outdoor scenes, and 2) the change of both environment conditions and novel poses. Experiments have verified the effectiveness and robustness of ConDo under varied teacher models, model architectures, scene types, compute budgets and replay buffer sizes."}]}