{"title": "Enabling Intelligent Traffic Systems: A Deep Learning Method for Accurate Arabic License Plate Recognition", "authors": ["M. A. Sayedelahl"], "abstract": "This paper presents a novel two-stage framework for Egyptian Vehicle License Plate Recognition (EVLPR), achieving a high recognition accuracy of 99.3% on a diverse dataset. The first stage utilizes image processing techniques for robust license plate localization, employing edge detection and morphological operations to isolate candidate regions within an image. The second stage leverages a custom-designed deep learning model specifically trained for Arabic Character Recognition (ACR). This model is trained on a dataset encompassing the variations encountered in real-world Egyptian license plates, leading to superior performance compared to existing approaches. By effectively addressing the complexities of Arabic script recognition, the proposed system paves the way for practical EVLPR applications with significant security and traffic management implications. The framework's potential extends beyond license plate recognition, offering promising functionalities in smart traffic management systems for tasks such as identifying traffic violations and monitoring vehicle occupancy for optimized parking management. Future work will refine the system by exploring alternative architectures, expanding the dataset for broader applicability, and addressing system dependencies. Overall, this research presents a significant contribution to the field of EVLPR, demonstrating the effectiveness of a combined approach using image processing and deep learning for real-world challenges.", "sections": [{"title": "1. Introduction", "content": "Automatic License Plate Recognition (ALPR) plays a vital role in image processing for law enforcement and traffic management, assisting in tracking the growing number of vehicles. This study addresses the limitations of existing methods by proposing a novel ALPR system tailored for Arabic characters and adaptable to real-world challenges [1]. ALPR involves several processing steps. Initially, captured images undergo conversion to grayscale for enhanced analysis. Subsequently, image manipulation techniques like dilation, edge detection (horizontal and vertical), and low-pass filtering are employed. Following this, segmentation extracts the license plate region. Individual characters are then detected using a smearing algorithm [2]. License plate recognition presents a complex task due to character identification and localization. The latter is further complicated by real-world plate pose variations and diverse image classes [1]. This challenge aligns with the coarse-to-fine recognition strategy. Existing systems often struggle with illumination variations, requiring application-specific methods."}, {"title": "2. Literature Review", "content": "Automatic License Plate Recognition (ALPR) plays a vital role in security, traffic management, and vehicle identification applications. Recognizing license plates, especially those in Arabic script, presents unique challenges due to their specific characteristics and the complexities encountered in real-world environments. Researchers have explored various techniques and algorithms to address these challenges, with significant advancements in license plate localization and character recognition. This section provides a comprehensive overview of recent research advancements in Arabic license plate recognition."}, {"title": "2.1. License Plate Localization", "content": "\u2022\tEarly Methods: Initial approaches focused on detecting rectangular image edges to locate license plates [8]. However, these methods lacked robustness when dealing with similar colours between the car and the plate, leading to false positives.\n\u2022\tColour-Based Techniques: Color histograms were then employed for localization [11]. However, this method proved unreliable under varying lighting conditions where the reflected colour diverged from the actual plate colour. Neural networks were introduced to classify plate colours [12], but challenges persisted when the plate colour resembled other car parts or produced similar histograms [13].\n\u2022\tShape-Based Approaches: Using pre-defined plate parameters like aspect ratio or specific measurements to identify candidate regions [14]; [15]. This method struggled with significant aspect ratio variations, as in some license plates.\n\u2022\tDeep Learning for Localization: The application of intelligent neural networks for license plate localization has shown promise [10]. Approaches proposed in [9] aimed to relax constraints on image complexity, resulting in lower false detection rates. However, further improvements are necessary for this system [16]."}, {"title": "2.2. Character Recognition", "content": "Optical Character Recognition (OCR) has witnessed significant advancements in recognizing diverse scripts from various sources. However, a particular focus has been placed on recognizing non-cursive scripts like Latin and English [17]-[19]. This review highlights research advancements in OCR techniques relevant to Arabic license plate recognition:"}, {"title": "3. Dataset", "content": "3.1. Standardized Vehicle Identification in Egypt and A Look at Registration Places\nImplemented in August 2008, the Egyptian vehicle registration plate system employs rectangular aluminum plates for consistent identification. The design incorporates the word \u201cEgypt\u201d, displayed prominently in English and Arabic at the top, using black lettering for optimal legibility. The background color assumes a specific hue depending on the vehicle's license category. Motorbikes utilize a smaller plate format compared to standard vehicles. Their colour scheme also resembles a distinct classification: light blue designates privately owned motorbikes, while dark blue signifies police motorcycles.\n3.2. Delving into the Registration Number Format\nThe vehicle registration number represents a unique identifier composed of two distinct parts: a numeric component and an alphabetic component. The numeric portion exhibits variations based on the issuing governorate. Cairo-issued license plates feature a three-digit numeric sequence, while plates from other governorates utilize a four-digit format for enhanced distinctiveness. The alphabetic component further bolsters identification specificity. Giza license plates incorporate a two-letter sequence, whereas plates issued by other governorates employ a three-letter format."}, {"title": "4. Proposed Method", "content": "System Overview: This research proposes developing an Egyptian Vehicle License Plate Recognition (EVLPR) system specifically designed to identify license plates on parked vehicles using standard outdoor cameras.\nSystem Functionality: The EVLPR system operates in a multi-stage process, as illustrated in Figure 3. Here's a detailed breakdown of the potential functionalities:\nStage 1: Image Acquisition and Preprocessing: The system captures an image of the parked vehicle using the outdoor camera. Preprocessing techniques like noise reduction and colour adjustments might be applied to improve image quality for optimal processing.\nStage 2: Candidate Region Detection: The system employs algorithms to identify potential regions within the image that resemble license plates based on characteristics like size, aspect ratio, and colour (considering variations in Egyptian license plates).\nStage 3: License Plate Segmentation and Character Extraction: Once a candidate region is identified, the system segments the image to isolate the license plate area. Techniques such as edge detection and character grouping extract individual characters within the license plate.\nStage 4: Arabic Character Recognition (ACR): A pre-trained Arabic character recognition (ACR) model recognizes each extracted character. This model should be designed to handle the variations encountered in Egyptian license plates, including different fonts, sizes, and potential noise.\nStage 5: License Plate Reconstruction: Finally, the system combines the recognized characters from the ACR stage to reconstruct the complete license plate number.\nFocus on Egyptian Vehicles: The proposed EVLPR system is tailored to the specific requirements of Egyptian license plates. This includes:\n\u2022\tSize and Aspect Ratio: The system considers Egyptian license plates' standard dimensions and aspect ratio to improve candidate region detection.\n\u2022\tCharacter Set: The ACR model is trained on a dataset encompassing the specific character set used in Egyptian license plates, including Arabic numerals and letters.\nThis proposed EVLPR system offers a potential solution for recognizing license plates on parked Egyptian vehicles using standard outdoor cameras. By incorporating a focus on Egyptian license plate characteristics and a trained ACR model, the system aims to achieve accurate license plate recognition in real-world scenarios [33]. This revised version emphasizes parked vehicles, focuses on the Egyptian context, and details functionalities relevant to Egyptian license plate recognition."}, {"title": "4.1. Challenges of Arabic Character Recognition", "content": "Arabic script presents unique challenges for character recognition systems:\n\u2022\tCursive nature and morphological complexity: Arabic characters often connect, and their shapes change depending on their position in a word, unlike separate Latin letters.\n\u2022\tHigh visual similarity: Certain Arabic letters look very similar, making them difficult to distinguish, especially in potentially low-resolution images captured by outdoor cameras.\n\u2022\tDiacritics and dots: The presence of diacritics (small marks above or below characters) and dots significantly alters the phonetic value of an Arabic letter.\nTo address these challenges, the ACR model adopts a hybrid neural network architecture, combining the strengths of two powerful techniques:\n\u2022\tYou Only Look Once (YOLO) Object Detection: This state-of-the-art algorithm identifies objects within an image and predicts their bounding boxes (rectangular areas enclosing them). In the context of the ACR model, YOLO can be used to identify individual characters within the segmented license plate image.\n\u2022\tCustom-trained Convolutional Neural Networks (CNNs): CNNs are a type of deep learning architecture particularly adept at extracting features from images. The SARLR system employs custom-designed CNNs specifically trained on a dataset of Arabic characters. These CNNs learn the intricate details and variations in Arabic script, enabling them to distinguish between different characters effectively.\nModel Layers: The ACR model can be broken down into several key layers, each playing a crucial role in the character recognition process:"}, {"title": "4.2. Convolutional Layers (conv) and (Potentially two layers)", "content": "\u2022\tEach convolutional layer applies a set of learnable filters to the input image (segmented character from the license plate).\n\u2022\tThese filters are essentially small matrices that detect specific features within the image, such as edges, shapes, and patterns critical for character recognition.\n\u2022\tMultiple filters capture various features at different scales.\n\u2022\tThe output of a convolutional layer is a feature map that highlights the presence of these detected features in the input image."}, {"title": "4.3. Pooling Layers (max pool) and (Potentially two layers following convolutional layers)", "content": "\u2022\tPooling layers perform a down-sampling operation on the feature maps generated by the convolutional layers. This reduces the dimensionality of the data, making it computationally more efficient for processing by subsequent layers.\n\u2022\tThe model likely uses max pooling, which selects the maximum value within a specific window of the feature map. This helps to capture the most prominent features while reducing noise and redundancy.\nDropout Layer (dropout): (Potentially present): This layer introduces a random element during training. It temporarily \"drops out\" a certain percentage of neurons in the network, preventing them from contributing to the forward pass. This helps to reduce overfitting by forcing the model to learn more robust features that are not dependent on specific neurons.\nFlatten Layer (flatten): This layer takes the multi-dimensional output from the final pooling layer and transforms it into a one-dimensional vector. This flattened vector represents all the extracted features from the character image in a format suitable for feeding into the fully connected layers."}, {"title": "4.4. Dense Layers (dense) and (Potentially three fully-connected layers)", "content": "\u2022\tThese layers consist of interconnected neurons that learn complex relationships between the features extracted by the convolutional and pooling layers.\n\u2022\tEach neuron in a dense layer receives input from all neurons in the previous layer and applies a non-linear activation function (like ReLU) to transform the weighted sum.\n\u2022\tThe first two dense layers might be responsible for progressively extracting higher-level features that represent the overall structure of the character.\n\u2022\tThe final dense layer has several neurons equal to the number of possible Arabic characters (including numerals) in the classification task."}, {"title": "4.5. Output Layer (potentially dense)", "content": "\u2022\tThis layer (potentially the final dense layer) utilizes a softmax activation function.\n\u2022\tThe softmax function takes the output from the previous layer (potentially the second dense layer) and converts it into a probability distribution across all possible character classes. Each element in the output vector represents the probability that the input image corresponds to a specific Arabic character."}, {"title": "4.6. Network Design and Filter Sizes", "content": "The model utilizes a relatively small network structure with approximately 20 million parameters, prioritizing efficiency for faster character recognition. Two convolutional layers are employed for feature extraction. The first layer might leverage 128 filters, while the second layer could benefit from potentially doubling the number of filters to 256 (based on the suggestion of \"doubling it to 128 filters in the last layers\"). The specific filter sizes used within these convolutional layers are 128, 64, 32, and 4. This range allows the model to capture features within the segmented character images at various scales."}, {"title": "4.7. Training and Evaluation", "content": "The segmented characters are normalized before being fed into the ACR model. It's important to clarify that the system likely doesn't rely solely on an external OCR (Optical Character Recognition) algorithm. The ACR model itself performs the character recognition task. The reported validation accuracy of 99.3% at the 100th epoch demonstrates the model's effectiveness in recognizing Arabic characters on license plates. The training accuracy of approximately 98.06% further supports this high level of performance."}, {"title": "4.8. Comparison and Training Details", "content": "The text suggests that the hybrid model (combining YOLO for object detection and custom CNNs for character recognition) achieves better accuracy than other CNN-based algorithms designed specifically for English license plates. This highlights the effectiveness of the model for Arabic script recognition .The system was trained and tested on the APTI dataset, a crucial element for evaluating its performance. The hardware platform used for training is a Windows 11 personal computer with 8 cores and 16 GB of RAM. Figures 5 and 6 likely depict the model loss and accuracy curves over 100 training iterations. These visualizations provide valuable insights into the training process and the model's convergence behaviour."}, {"title": "4.9. Characteristics of License Plates and Enhancement Strategies", "content": "License plates possess distinct visual features that aid their detection. These features include:\n\u2022\tDominant Vertical Edges with Uniform Texture: This characteristic is particularly prominent for license plates containing scripts like Persian, where characters often have strong vertical strokes with a consistent texture.\n\u2022\tHorizontal Outer Edges: License plates typically have prominent horizontal edges along their boundaries, providing another valuable cue for detection.\n\u2022\tBy leveraging these characteristics, the preprocessing stage enhances specific regions in the image, aiming to improve the visibility of edges within the suspected license plate area."}, {"title": "4.10. Following Stages and Detection Algorithm", "content": "The subsequent sections will delve into the details of the detection algorithm, as illustrated in the flowchart of Figure 7. This flowchart outlines extracting individual character images from the captured car image."}, {"title": "4.11. License Plate Detection and A Multi-Stage Approach", "content": "The license plate detection process in the proposed system follows a multi-stage approach, detailed in the flowchart of Figure 8. Here, we delve into each stage and its contribution to accurate plate localization.\nPreprocessing: Grayscale Conversion for Enhanced Contrast: The initial phase involves converting acquired colour car images (Figure 9) into grayscale representations (Figure 10). This conversion plays a crucial role by enhancing contrast within the image. Reduced colour complexity simplifies processing and facilitates the algorithm's subsequent detection of the license plate region.\nMorphological Operations: Refining Edges and Plate Region Identification involves using morphological operations to enhance the edge-detected image (Figure 11) and improve the identification of the license plate region. Dilation expands the objects within the image, making their edges more prominent for subsequent detection steps. This approach follows the guidelines of reference [35].\nNoise Reduction and Smoothing and Median Filter for Improved Clarity: A 2-D median filter with a 5x5 mask is applied to the eroded image to smooth out any noise or artifacts introduced during processing. This smoothing step further emphasizes the license plate region and improves its visual quality, as depicted in Figure 12 [36].\nHole Filling and Morphological Erosion: Refining Potential Plate Regions: To further refine potential plate regions, a series of operations are applied:\n\u2022\tHole Filling: Figure 13 demonstrates the application of a 2-D median filter and subsequent hole-filling operation on the eroded image. Hole filling addresses areas unintentionally removed by the dilation operation.\n\u2022\tMorphological Erosion: After hole filling, a morphological erosion algorithm is applied to the image to identify potential plate regions by reducing the size of non-plate areas (Figure 14).\nRegion of Interest Extraction: Removing Irrelevant Information: This phase focuses on extracting the license plate region from the processed image by eliminating irrelevant information. Two key criteria govern this process:\n\u2022\tLine Elimination: Remove vertical and horizontal lines not associated with the license plate.\n\u2022\tObject Elimination: Removal of all objects with dimensions outside the standard size range of license plates (17 x 32 cm) in the dataset.\nWhile the camera model used for image capture (Nikon Coolpix L330) doesn't directly provide image resolution in pixels per centimeter, the total resolution of 4608 x 3456 pixels allows for an estimated conversion of the standard license plate size (17 cm x 32 cm) into its equivalent pixel dimensions for object elimination during license plate detection. Using a 4:3 aspect ratio for the captured images, an approximate object elimination threshold of 19784 x 36864 pixels is achieved. This approach helps eliminate irrelevant objects outside the typical license plate size range, focusing subsequent processing steps on regions with higher potential to contain the actual license plate [30].\nWidth (pixels) = Image Resolution (pixels/cm) * License Plate Width(cm)\n\u2248 1152 pixels/cm * 17 cm \u2248 19784 pixels\nHeight (pixels) = Image Resolution (pixels/cm) * License Plate Height(cm)\n\u2248 1152 pixels/cm * 32 cm \u2248 36864 pixels\nLicense Plate Segmentation: As illustrated in Figure 15, Egyptian license plates adhere to a standardized size of 17 cm x 32 cm (19784 x 36864 pixels). These plates are segmented into two sections based on their characteristics [31].\nPreprocessing and Character Localization: Before character extraction, the license plate images in Figure 16 underwent grayscale conversion and noise reduction using a median filter to remove unwanted artefacts. The subsequent step involved locating individual letters and numerals within the license plate number using a method known as fractal transformation [32]. Figure 17 visualizes this process, where rectangles highlight the location of each character."}, {"title": "5. Results and Discussion", "content": "To rigorously assess the performance of our proposed algorithm, we employed a dataset of 4,693 real-world car images captured under various conditions. These images adhered to the standard Egyptian license plate size of 32 x 17 cm (equivalent to 19784 x 36864 pixels). To ensure the dataset reflects the complexities encountered in real-world scenarios, we ensured it encompassed the following:\n\u2022\tVariations in Lighting: Images captured under diverse lighting conditions, including daytime, nighttime, low light, and high contrast.\n\u2022\tWeather Scenarios: Images depicting various weather conditions, such as clear skies, rain, snow, and fog.\n\u2022\tVehicle Positions: Images featuring vehicles at different angles relative to the camera (frontal, side-view, angled), at varying distances, and with partial occlusions due to parked cars or other objects.\nThis diversity within the dataset challenged the algorithm to recognize license plates effectively in situations often encountered in real-world license plate recognition applications."}, {"title": "5.2. Evaluation Methodology", "content": "We implemented our proposed algorithm on the entire dataset of 4,693 images. To evaluate its performance objectively, we adopted the following metrics:\n\u2022\tRecognition Rate: This metric represents the percentage of license plates correctly identified and decoded by the algorithm.\n\u2022\tFalse Positives: This metric indicates the instances where the algorithm incorrectly identified a non-license plate region as a license plate.\n\u2022\tFalse Negatives: This metric represents the number of license plates the algorithm failed to detect or recognize."}, {"title": "5.3. Detailed Results and Performance Analysis", "content": "The proposed algorithm achieved a remarkable recognition rate of 99.3% on the diverse dataset. This accomplishment highlights the effectiveness of our approach in accurately identifying license plates across a wide range of real-world scenarios. To delve deeper into the analysis, we can further explore the breakdown of the results, considering:\n\u2022\tPerformance under Different Lighting Conditions: Examining the recognition rate across various lighting conditions (daytime, nighttime, etc.) to identify potential areas for improvement.\n\u2022\tImpact of Weather Conditions: Analyzing how weather factors (rain, snow, fog) affected the algorithm's performance and exploring potential mitigation strategies.\n\u2022\tError Analysis of False Positives and Negatives: Investigating the reasons behind misidentified regions and missed license plates to pinpoint weaknesses in the algorithm and guide further refinement.\nComparison with Existing Methods: As shown in Table 4, our proposed algorithm outperformed existing models such as CNN, Faster R-CNN, and YOLO regarding recognition accuracy. This comparison underscores the effectiveness of our approach in license plate recognition tasks."}, {"title": "6. Conclusion", "content": "The proposed system effectively addresses the challenge of Egyptian Vehicle License Plate Recognition (EVLPR) with a high recognition rate of 99.3% achieved on a diverse dataset. This accomplishment stems from a two-stage approach that combines image processing and deep learning. The first stage utilizes image processing techniques like edge detection and morphological operations to isolate candidate license plate regions within an image. The subsequent stage leverages a deep learning model specifically designed for Arabic Character Recognition (ACR) to identify characters on the localized license plate accurately. This custom ACR model, trained on a dataset reflecting real-world variations in Egyptian license plates, outperforms existing approaches. By effectively handling the complexities of Arabic script recognition, the system paves the way for practical EVLPR applications with significant security and traffic management implications. This framework's potential extends beyond license plate recognition, offering promising applications in smart traffic management systems for tasks like identifying traffic violations or monitoring vehicle occupancy for parking optimization. Future work will refine the system by exploring alternative architectures, expanding the dataset for broader applicability, and addressing system dependencies. Overall, this research presents a significant contribution to the field of EVLPR, demonstrating the effectiveness of a combined approach using image processing and deep learning to tackle real-world challenges."}, {"title": "6.1. Future Work", "content": "While the results are promising, 100% accuracy remains a crucial objective for commercial applications. Future work will focus on:\n\u2022\tExploring Alternative Architectures: Investigating the implementation of alternative convolutional architectures to improve performance in specific areas like handling challenging lighting conditions or partially obscured license plates.\n\u2022\tDataset Expansion: Expanding the dataset to encompass a wider variety of license plates, including those from different regions, with diverse degradations (e.g., scratches, dirt), and under extreme weather conditions, to enhance the system's robustness further.\n\u2022\tAddressing System Dependencies: Resolving any outstanding system dependencies and compatibility issues to facilitate the implementation of planned enhancements."}, {"title": "6.2. Beyond License Plate Recognition", "content": "The proposed framework holds potential for applications beyond license plate recognition. Its ability to accurately identify and extract vehicle information offers possibilities in smart traffic management systems, such as identifying vehicles violating traffic regulations or optimizing parking facilities through real-time vehicle occupancy monitoring."}]}