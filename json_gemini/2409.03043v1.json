{"title": "Can Your Generative Model Detect\nOut-of-Distribution Covariate Shift?", "authors": ["Christiaan Viviers", "Amaan Valiuddin", "Francisco Caetano", "Lemar Abdi", "Lena Filatova", "Peter de With", "Fons van der Sommen"], "abstract": "Detecting Out-of-Distribution (OOD) sensory data and co-\nvariate distribution shift aims to identify new test examples with different\nhigh-level image statistics to the captured, normal and In-Distribution (ID)\nset. Existing OOD detection literature largely focuses on semantic shift\nwith little-to-no consensus over covariate shift. Generative models cap-\nture the ID data in an unsupervised manner, enabling them to effectively\nidentify samples that deviate significantly from this learned distribution,\nirrespective of the downstream task. In this work, we elucidate the abil-\nity of generative models to detect and quantify domain-specific covari-\nate shift through extensive analyses that involves a variety of models.\nTo this end, we conjecture that it is sufficient to detect most occurring\nsensory faults (anomalies and deviations in global signals statistics) by\nsolely modeling high-frequency signal-dependent and independent de-\ntails. We propose a novel method, CovariateFlow, for OOD detection,\nspecifically tailored to covariate heteroscedastic high-frequency image-\ncomponents using conditional Normalizing Flows (cNFs). Our results on\nCIFAR10 vs. CIFAR10-C and ImageNet200 vs. ImageNet200-C demon-\nstrate the effectiveness of the method by accurately detecting OOD co-\nvariate shift. This work contributes to enhancing the fidelity of imaging\nsystems and aiding machine learning models in OOD detection in the\npresence of covariate shift. The code for CovariateFlow is available at\nhttps://github.com/cviviers/CovariateFlow.\n\nKeywords: Covariate Shift Out-of-Distribution Detection Normaliz-\ning Flows Sensory Anomalies Generative Modelling", "sections": [{"title": "1 Introduction", "content": "Identifying abnormal image statistics is critical for deploying precise sensing\ntechnology and reliable machine learning. Out-of-Distribution (OOD) detection\nmethods model the available data or a set of In-Distribution (ID) features, to\nidentify test examples drawn from a different distribution. Notably, generative\nmodels offer an unsupervised paradigm to model without making explicit as-\nsumptions on the form of the OOD data. With a plethora of possible covariates"}, {"title": "2 Background and Related Work", "content": "Approaches to OOD detection are generally divided into two categories: super-\nvised, which necessitates labels or OOD data, and unsupervised, which relies\nsolely on in-distribution data. Although semantic OOD detection does not con-\nstitute the core focus of this study, we nevertheless provide a concise overview of\nthe recent developments, since these methodologies hold the potential to trans-\nlate to covariate OOD detection. For an in-depth exploration of OOD detection\nmethodologies, we refer to the comprehensive review by Yang et al. [45]."}, {"title": "Explicit Density Methods", "content": "A straightforward method for OOD detection\ninvolves the use of a generative model, p(x; 0) parameterized by 0 and trained to\nfit a given distribution over data x. The process evaluates the likelihood of new,\nunseen samples under this model with the underlying assumption that OOD\nsamples will exhibit lower likelihoods compared to those that are ID. The Evi-\ndence Lower Bound (ELBO) employed in Variational Auto Encoders (VAEs) [24]\ncan be used for OOD detection by evaluating a lower bound on the likelihood\nof a test sample. Plumerault et al. [36] introduced the Adversarial VAE\nnovel approach that marries the properties of VAEs with the image generation\nquality of Generative Adversarial Networks (GANs), thereby offering a robust\nauto-encoding model that synthesizes images of comparable quality to GANS\nwhile retaining the advantageous characteristics of VAEs.\n\nUnlike VAEs, Normalizing Flows (NFs) [27] offer exact and fully tractable\nlikelihood computations. With the introduction of coupling layers [10], NFs can\nbe arbitrarily conditioned and seem to be excellent contenders for conditional\nOOD detection. However, as evidenced in previous research [30], NFs have ex-\nhibited limitations in effective OOD detection, often assigning higher likelihoods\nto OOD samples. This limitation has been associated with an inherent bias\nin the flow model architectures, which tends to prioritize modeling local pixel\ncorrelations over the semantic content of the data [26]. Exploration by Grat-\nwohl et al. [15] and Nalisnick et al. [31] posits that this phenomenon can be at-\ntributed to the fact that ID images are not high-likelihood samples but, rather,\nconstituents of the typical set of the data distribution. Consequently, the in-\nvestigation into methods that assess the typicality [7] of data instances, as an\nalternative to direct likelihood estimation, has gained traction. Despite empirical\nevidence demonstrating the efficacy of typicality in OOD benchmarks [7], recent\ntheoretical investigations [48] indicate that these methodologies have inherent\nsusceptibilities to specific OOD types and an evaluative bias towards particular\nOOD categories, thereby underscoring the complexity of OOD detection."}, {"title": "Image Reconstruction-based Methods", "content": "These OOD detection methods are\nbased on the principle that models are less effective at accurately reconstruct-\ning data that significantly deviates from the training distribution. Graham et\nal. [14] improves on an innovative approach to OOD detection that leverages\nthe potent generative prowess of recent denoising diffusion probabilistic mod-\nels (DDPMs) [20, 33]. Unlike prior reconstruction-based OOD detection tech-\nniques that necessitated meticulous calibration of the model's information bot-\ntleneck [9,35,50], their method utilizes DDPMs to reconstruct inputs subjected\nto varying degrees of noise. In this work, we implement this DDPM method as\nbaseline for OOD covariate shift detection."}, {"title": "2.2 Covariate shift", "content": "In essence, covariate shift refers to the phenomenon where images share consis-\ntent semantic content (i.e. similar subjects), and yet, are captured under vary-"}, {"title": "2.3 Normalizing Flows (NFs)", "content": "Consider an image sampled from its intractable distribution as x ~ Px. Addi-\ntionally, let us introduce a simple, tractable distribution pz of latent variable"}, {"title": "2.4 Typicality", "content": "Examining sequences of N independent and identically distributed (i.i.d.) data-\npoints xn, the typical set comprises all xn that satisfy\n\nH(X) - \\epsilon \\leq - \\frac{1}{N} \\sum_{n=1}^{N} log_2 p(x_n) \\leq H(X) + \\epsilon, \n\nwhere e represents an arbitrarily small value and H(X) denotes the Shannon\nentropy of the dataset. In other words, the empirical entropy of the set ap-\nproaches to the entropy rate of the source distribution. Leveraging the Asymp-\ntotic Equipartition Property (AEP), it is deduced that\n\n\\frac{1}{N} \\sum_{n=1}^{N} log_2 p(x_n) \\rightarrow H(X) s.t. N \\rightarrow \\infty, \n\nleading to the conclusion that the probability of any sequence of i.i.d. samples\nof sufficient length approaches unity. Thus, despite the typical set representing\nmerely a small subset of all potential sequences, a sequence drawn from i.i.d.\nsamples of adequate length will almost certainly be considered typical [41].\n\nIn various studies, indications have emerged that NFs perform poorly when\nthe likelihood is utilized as a metric for detecting OOD samples [6,26,30,48]. It\ncan be argued that datasets are a typical sequence of samples, rather than high\nin likelihood, also known as the Typical Set Hypothesis (TSH). Therefore, in the\nrecent work by Nalisnick et al. [31], an innovative approach is proposed for OOD\ndetection that leverages typicality as an evaluation metric in lieu of likelihood.\nThis methodology was further refined in subsequent studies [15], introducing\napproximate mass. Motivated by the fact that typical samples are localized in\nhigh-mass areas on the PDF, the metric evaluates the gradient of the LL w.r.t\nthe input data, also known as the score. It can be expressed mathematically as\n||\\partial L(x;0)/\\partial x||, where x denotes the input, L the evaluated LL by the model pa-\nrameterized by 0, and ||.|| represents the Euclidean norm. Despite some criticism\non TSH [48], this metric demonstrates superior performance in OOD detection\nacross various benchmarks [7,15]."}, {"title": "3 Approach", "content": ""}, {"title": "3.1 Definition of Covariate Shift", "content": "Formally, semantic- and in-domain covariate shifts can be delineated as follows.\nConsider samples from the training distribution, x ~ Px, and anomalous data\nfrom an OOD source x ~ Py, subject to a low-pass filter (l, 1 : R \u2192 R) to obtain\nthe low-frequency components, X\u2081 = l(x) and the high-frequency components\nXH = x - l(x). Semantic shift is characterized by a discrepancy in the marginal\nprobability distributions, Px\u2081 \u2260 Py\u2081, when the conditional probability distri-\nbutions of high-frequency components remain consistent, PXH|XL \u2248 PXHXL\n\nConversely, covariate shift is identified when the conditional probability distri-\nbutions diverge, PXH|XL \u2260 PXH|XL, but the marginal probability distributions of\nthe low-frequency components remain the same Px\u2081 \u2248 Px\u2081. Furthermore, these\ndefinitions hold with in the supervised setting with predefined targets (Y)."}, {"title": "3.2 Covariate Flow", "content": "In the development of methodologies for detecting covariate shift within datasets,\nseveral critical factors must be meticulously considered to ensure efficacy and\naccuracy. Firstly, (1) the process of resizing images can significantly alter the\ndistribution of high-frequency statistics, potentially obscuring key data char-\nacteristics. Secondly, (2) the inherent nature of encoding architectures, which\nessentially function as low-pass filters [47], may limit their capacity to fully cap-\nture the complex distribution of noise present within the data. This limitation is\nparticularly relevant as covariate shifts often manifest through alterations in the\ngeneral image statistics, thereby necessitating a method capable of discerning\nsuch nuances. Thirdly, (3) the utilization of only log-likelihood-based evaluation\nin NFs, has proven to have a predisposition towards low-level semantics and is\nmore sensitive to high-frequency statistics. An effective method should be sensi-\ntive to covariate shifts affecting all frequency bands, from noise degradations to\ncontrast adjustments.\n\nIn light of the above considerations, Normalizing Flows (NFs) emerge as a\nparticularly suitable candidate for modeling the imaging features essential for\ndetecting covariate shift. NFs are distinct in that they abstain from any form\nof down-sampling or encoding processes to preserve their bijective property.\nIt is also recognized that NFs prioritize pixel correlations over semantic con-\ntent [26]. However, given the expectation that covariate shift involves changes\nin high-frequency image statistics, accurately modeling the complete image dis-\ntribution-including both low-frequency semantics and high-frequency compo-\nnents presents significant challenges, particularly given the relatively limited\ncapacity of NFs compared to more recent generative models [20, 33, 40].\n\nTo address these challenges, we introduce a novel method that simplifies the\nmodeling of components critical for covariate shift detection. Our approach in-\nvolves a filtering strategy that divides the image into separate low-frequency"}, {"title": "3.3 Unifying Log-likelihood and Typicality", "content": "The inductive bias of NFs towards structural complexity when evaluating with\nLL has been discussed in Section 2.4. As an alternative, evaluation on typicality\nusing the gradient of the LL w.r.t. the input data, has shown improvements\nin semantic OOD detection over LL [7,16]. However, it is understood that the\nmetric and model are similarly biased towards certain categories of data [48]. As\nsuch, we propose to combine LL evaluation with the Typicality score to overcome\nthe limitations of each approach individually. Our approach standardizes both\nthe LL and the typicality scores in terms of their respective training statistics.\nAfter standardization, we can transform each metric into an absolute distance\nfrom the expected mean. The LL distance and gradient score distance can then\nsimply be added to obtain a unified distance. In this manner, the evaluation is\nsensitive to all deviations, rather than only being lower in score, thereby reducing\nthe effect of the biases of the respective metrics. The following paragraph gives\nthe details of the mentioned approach.\n\nConsider a sample x ~ Px with log-likelihood log p(x). Furthermore, we\ndenote the magnitude of the gradients as ||\u2207xlogp(x)||, i.e. the approximate\nscore. The means for the empirical likelihoods are determined through \u03bc\u03b9 =\nEPx [log p(x)], and of the approximate scores with \u03bc\u03c4 = EPx [||\u2207xlog p(x)||].\nSimilarly, we can denote \u03c3\u00b2 = EPx [(x\u2212\u03bc\u03b9)2] and \u03c3} = Epx [(x \u2212 \u03bc\u03c4)2] for their\nrespective variances. We can then obtain the Normalized Score Distance (NSD)\nfor a new sample x* as the summation of the standardized L1-norms through\n\nNSD(x*) =  \\frac{log p(x^*) - \\mu_{\\tau}}{\\sigma_{\\tau}} + \\frac{||\\nabla_x log p(x^*)|| - \\mu_l}{\\sigma_l}."}, {"title": "3.4 Datasets", "content": "CIFAR10(-C) & ImageNet200(-C): CIFAR10 [28] and ImageNet200 with\ntheir respective corrupted counterparts, CIFAR10-C [18] and ImageNet200-C [18],\nserve as exemplary datasets for developing and evaluating unsupervised covari-\nate shift detection algorithms. CIFAR10 and ImageNet200 provide a collection of\nimages that encompass a broad range of in-distribution covariate shifts, ensuring\na suitable level of diversity. On the other hand, the corrupted versions introduce\nreal-world-like (undesired) degradations, such as noise, blur, weather, and digi-\ntal effects. Figure 1a depicts 3 of the 15 effects employed in the ImageNet200(-\nC) dataset. Images are utilized in their original resolution at 64 \u00d7 64 pixels.\nCIFAR10-C consists of 19 corruptions in total with images at 32 \u00d7 32 pixels.\nThis setup enables testing the covariate shift detecting performance across mul-\ntiple distortion types and severity levels. In all our experiments we train the\nmodels only on the original dataset's training set and then test it against all of\nthe corruptions at every severity level. For CIFAR10 this is the original dataset's\ntest set (ID test) and CIFAR10-C's 19 corruptions at 5 severity levels (95 OOD\ntest sets). Similarly, we treat the ImageNet200 test set as ID test and the 15"}, {"title": "4 Experiments", "content": "The following section describes the conducted experiments and presents the key\nresults obtained in our investigation. Further detailed experimental results can\nbe found in the supplementary materials. Specifically, we present results on CI-\nFAR10 (Section 8.3), ImageNet200 (Section 8.4) and extensive ablation experi-\nments with the proposed CovariateFlow (Section 8.5)."}, {"title": "4.1 Evaluation Metrics & Models", "content": "To evaluate the model's ability to detect OOD covariate shifts, we utilize metrics\ncommonly found in related work: the Area Under the Receiver Operating Char-\nacteristic (AUROC) curve and the False Positive Rate (FPR) at a 95% True Pos-\nitive Rate (TPR). In all our experiments with CIFAR10(-C) and ImageNet200(-\nC), we use the designated test set (10k samples) to compute each metric. Our\ncontributions include contextualizing the VAE, AVAE, GLOW evaluated with\nlog-likelihood and the DDPM with the reconstruction loss, within OOD covari-\nate shift as baseline models. Furthermore, we evaluate GLOW using typicality\nand the proposed NSD and CovariateFlow with all the aforementioned metrics.\nMost models are trained from scratch on the ID data. For the VAE-FRL [5], a\nmethod leading in semantic OOD detection, the available pretrained CIFAR10\nweights are employed. A detailed description of the implemented models can\nbe found in Section 8.1 of the supplementary materials."}, {"title": "4.2 Covariate Shift in CIFAR10 and ImageNet200", "content": "Table 1 showcases various models and their averaged AUROC across all the\ndegradations per CIFAR10-C/ImageNet-C severity level. While some models\nexcel in handling specific types of degradation, only the overall performance is\ntruly relevant, as one typically cannot predict the type of perturbation that will\noccur in real-world settings. A detailed breakdown of the results per perturbation\nis shown in Section 8.3 of the supplementary materials.\n\nIn Table 1 it can be seen that models preserving the data dimension and main-\ntaining the high-frequency signal components, such as the DDPM and NF-based\napproaches, perform best. ImageNet200-C contains fewer noise-based degrada-\ntions than CIFAR10-C. The NF models evaluated with LL generally perform\nwell on noise perturbations (Table 8 and Table 16) and because of this disparity\nin the types of degradations present in the datasets, LL evaluation exhibits a\ndrop in average performance from CIFAR10 to ImageNet200. The VAE-FRL"}, {"title": "5 Discussion", "content": "The findings from our analyses validate our hypothesis that OOD covariate shifts\ncan be effectively identified by explicitly modeling the conditional distribution\nbetween low-frequency and high-frequency components. The proposed Covariate-\nFlow, designed to specifically capture this distribution, surpasses other method-\nologies in detecting covariate shifts in CIFAR10 and ImageNet200. Given the\ndiverse array of subjects and covariate conditions within the corrupted datasets,\nfocusing on this conditional distribution streamlines the model's task, allowing\nit to concentrate on the most relevant distribution for the detection process.\n\nExtending on the analysis with Table 2,\nthe VAE-based models show adequate\nperformance in detecting noisy degra-\ndations due to their inductive bias to-\nwards modeling low-frequency image com-\nponents. On the other hand, the model\nfalls short for this exact reason when ex-\nposed to any blurring or color degrada-\ntions in the images. The DDPM with the\nLPIPS + MSE metric, present strong per-\nformance on noise and blurring-based co-\nvariate shift, but struggles when exposed\nto color shift. This is likely due to color re-\nconstructions happening earlier in the re-\nconstruction schedule. Consistent with ex-\nisting literature [26], the NF-based meth-\nods evaluated using LL are extremely sen-\nsitive to noisy degradations. However, any blurring or color shift is evaluated as\nbeing highly probable under the modelled distribution, highlighting the bias of\nLL-based evaluation towards lower textural content. Employing the newly pro-\nposed typicality metric shows the exact opposite behaviour. Both GLOW and the\nproposed CovariateFlow, fail at detecting noise-based covariate shift, but show\nremarkable improvements on both blurring and color-based covariate shifts when\nevaluated with typicality. Combining typicality and LL in the newly proposed\nNSD metric, accentuates the strengths of each, enabling strong detecting per-\nformance across most of the covariates with CovariateFlow. NSD enhances the\nOOD detection capabilities of both the standard GLOW model and the proposed\nCovariateFlow, establishing it as a general and robust metric for OOD detec-\ntion in NF-based models. On the higher resolution images from ImageNet 200,\nthe model also shows some effectiveness in distinguishing JPEG compression as\nOOD, a notoriously difficult perturbation to detect.\n\nWhen to use CovariateFlow: Despite GLOW (LL)'s slightly superior perfor-\nmance in general noise detection, CovariateFlow, leveraging NSD, proves to be\nbetter overall. This provides a clear and general recommendation to the reader:\nLL is preferred in case strictly noise-based shifts are expected. Without a priori\nknowledge on the OOD shift type (which is usually the case), CovariateFlow"}, {"title": "6 Future Work & Limitations", "content": "Some concerns can be raised about the complexity of the typicality computa-\ntion, since test time inference requires a forward pass to compute the LL followed\nby a backpropagation computation per sample. This increases the memory re-\nquirements when deploying the model and decreases the overall inference speed.\nHowever, in scenarios where accurate OOD covariate shift is essential, Covari-\nateFlow provides the best accuracy vs. speed trade-offs (see Section 8.3).\n\nThis work primarily focuses on detecting covariate shift, with explicit covari-\nate shifts introduced to assess performance. Many publicly available datasets\nexhibit both semantic and potential covariate shifts. Although the proposed ap-\nproach demonstrates effectiveness in CIFAR10 vs. SVHN (Table 24), future work\nshould explore domain-specific datasets with limited ID covariate conditions to\ntest the sensitivity of the proposed approach. As depicted in Figure 4, the scores\nacquired through evaluation with CovariateFlow (NSD) correctly increase with\neach severity level, however not at the same rate for each degradation type.\nFuture work should explore the latent representations of each degradation to\npotentially aligning these scores with image quality metrics [21] for blind image\nquality assessment applications."}, {"title": "7 Conclusion", "content": "This paper explores Out-of-Distribution (OOD) detection, specifically target-\ning covariate shifts caused by changes in general image statistics. This work\nintroduces CovariateFlow, a novel approach utilizing conditional Normalizing\nFlows (cNFs) for effectively targeting heteroscedastic high-frequency image com-\nponents, demonstrating its superior efficacy in detecting OOD shifts across di-\nverse datasets such as CIFAR10(-C) (74.9% AUROC) and ImageNet200(-C)\n(72.2% AUROC). Our analysis reveals that by meticulously modeling the con-\nditional distribution between low-frequency and high-frequency components, Co-\nvariateFlow outperforms existing models, particularly when employing the Nor-\nmalized Score Distances (NSD) metric, which is a synthesis of log-likelihood\nand typicality evaluations. This approach not only highlights the importance\nof addressing covariate shifts for enhancing the fidelity of imaging systems, but\nalso underscores the potential of unsupervised generative models in improving\nmachine learning models' robustness against OOD data."}, {"title": "8 Supplementary", "content": "The supplementary material is organized as follows: Section 8.1 describes the\nimplementation details of all the models employed in this paper. Section 8.2\nhas a step-by-step rundown on how we obtain the Normalized Score Distance.\nSection 8.3 provides detailed results on CIFAR10 and CIFAR10-C of the experi-\nments and Section 8.4 results on ImageNet200 and ImageNet200-C as described\nin the Experiments section of the main paper. Finally, we provide a series of\nadditional ablation experiments in Section 8.5."}, {"title": "8.1 Implementation Details", "content": "In this section, we detail the unsupervised training methodologies employed for\nfive distinct baseline models and CovariateFlow aimed at OOD detection.\n\nVAE and Adversersial VAE: The VAE is trained to minimize the stan-\ndard ELBO [24] loss. Model evaluations using SSIM and KL-divergence pre-\nsented the best AUROC results. The AVAE model integrates adversarial train-\ning [12] into the variational autoencoder framework to enhance its capability\nin generating realistic samples. For OOD detection, one can leverage the recon-\nstruction loss (Mean Squared Error (MSE)), the KL-divergence and the discrim-\ninative loss to compute a OOD score. We adopt the implementation described\nin [36]. In both the VAE and AVAE we employ a 4 layer deep network with a\nlatent dim = 1024. The models were trained for 200 epochs following a cosine\nannealing learning rate scheduler.\n\nVAE-FRL: The VAE with frequency-regularized learning (FRL) [5] intro-\nduces decomposition and training mechanism which incorporates high-frequency\ninformation into training and guides the model to focus on semantically rel-\nevant features. This proves effective in semantic OOD detection. We employ\nthe pretrained model as publicly available. For the CIFAR10 experiments, the\nmodel consists of a standard 3 layer deep VAE with strided convolutional down-\nsampling layer, transposed convolutional up-sampling and ReLu non-linear func-\ntions. The model has a latent dimension of 200. The OOD score is obtained by\nthe log-likelihood (lower bound in the case of the VAE) minus the image com-\nplexity. The formulation is given as\n\nS(x) = log p\u2080(x) - L(x),\n\nwhere L(x) is the complexity score derived from data compressors [39], such as\nPNG.\n\nDenoising Diffusion Probabilistic Model: We implemented the Denois-\ning Diffusion Probabilistic Model (DDPM) following the specifications outlined\nin [14] and as publicly available 6. The method employs a time-conditioned"}, {"title": "8.2 Detailed analysis of the normalized score distance (NSD)", "content": "This section details the computation of the NSD from the LL and typicality\nscore. Figure 6 depicts this process through the evaluation of the GLOW model\napplied to three different OOD covariate shifts. In Figure 6a the LL and typ-\nicality (gradient score) of the model subject to Gaussian Noise can be seen.\nFollowing the process described in Section 3.3, column 2 depicts the standard-\nization of both scores using validation statistics. This is followed by converting\nthe scores to absolute distance from the expected mean in column 3. The LL\ndistance and gradient score distance can then simply be added to obtain a uni-\nfied distance (Figure 6a). The same flow is depicted in Figure 6c and Figure 6d\nfor the model subject to Gaussian Blur and Figure 6e and Figure 6f for Contrast\nchange. Following this standardized approach, the change in each measure (LL\nand gradient score) w.r.t. the validation statistics are utilized and combined to\nprovide a single and effective OOD score. All the results depicted in The Figure 6\ndepicts the ID CIFAR10 test scores vs. the OOD CIFAR10-C scores."}, {"title": "8.3 Detailed Results on CIFAR10 vs. CIFAR10-C", "content": "The following section presents detailed results obtained with various models on\nour experiments with ID CIFAR10 and CIFAR10-C as OOD.\n\nOur analysis examines the reconstruction capabilities of the DDPM across\nvarious initial time steps, T. Figure 7 presents the mean AUROC curve cal-\nculated for reconstructions assessed using the LPIPS, MSE, or a combination\nof LPIPS and MSE metrics at each time step. Notably, at larger time steps\n(e.g., T = 250), the distinction in average reconstruction error between the ID\nCIFAR10 test set and the OOD CIFAR10-C dataset becomes less pronounced,\nleading to inferior OOD detection performance. This phenomenon is attributable\nto the high-level image perturbations characteristic of OOD data, which are pre-\ndominantly addressed in the final stages of the diffusion process. In Contrast,\ninitial diffusion stages focus on generating lower-level image semantics, resulting\nin reconstructions that significantly diverge from the test image, particularly in\nterms of low-frequency components.\n\nFigures 6, 7, and Table 2, highlight the distinct sensitivities of log-likelihood\n(LL) and gradient scores when applied to GLOW under severe Gaussian Noise\nconditions, as depicted in Figure 6a. These metrics diverge in their assessment,\nwith LL clearly identifying distorted images as OOD, whereas gradient scores\nsuggest such images are more typical than even the ID data. Conversely, Fig-\nure 6c demonstrates the opposite trend for blurred images, where LL overesti-\nmates their likelihood relative to ID data, but gradient scores accurately clas-\nsify them as OOD. These observations corroborate Zhang et al.'s theoretical\ninsights [48] about the propensity of certain model-metric combinations to mis-\njudge the probability of natural images. To address these discrepancies, we in-\ntroduce the NSD metric, which synthesizes LL and gradient movements into a"}, {"title": "8.4 Detailed Results on ImageNet200 vs. ImageNet200-C", "content": "The following section depicts detailed results obtained with various models on\nour experiments with ID ImageNet200 and ImageNet200-C as OOD. The results\nare depicted in order of presentation: DDPM T20-LPIPS+MSE (15), GLOW-\nLL (Table 16), GLOW-Typicality (Table 17), GLOW-NSD (Table 10), CovariateFlow-\nLL (Table 19), CovariateFlow-Typicality (Table 20) and CovariateFlow-NSD (Ta-\nble 21)."}, {"title": "8.5 Ablation Study", "content": "This section details a series of ablation experiments conducted, including an\nanalysis of the effect of the individual components in CovariateFlow on the\ndetection performance (Table 22), mean scores per severity of the models and\nresource aspects are depicted in Table 23, model performance on a typically\nsemantic OOD detection problem in Table 24 and finally an example (Figure 9)\nof heteroscedastic high-frequency components sampled from the fully invertible\nCovariateFlow.\n\nIn our ablation experiments, we test the effect of explicitly modelling the con-\nditional distribution between the low-frequency and high-frequency signal com-\nponents as described in Section 3.2. This is achieved by training and evaluating\nthe CovariateFlow model in four different settings: (1) unconditional coupling\nflows with the full input image, (2) unconditional coupling flows subject to only\nthe high-frequency components of the image, (3) unconditional coupling flows\nsubject to the high-frequency components and a conditional signal-dependent\nlayer additionally subject to the low-frequency image components and finally,\n(4) the high-frequency image components applied to the conditional coupling\nflows and a signal dependent layer subject to the low-frequency components.\nFor each of these implementations we follow the exact same training method-\nologies as described in Section 8.1. All the images are encoded at 16 bit depth\nduring dequantization to ensure comparability.\n\nFrom Table 22 it can be seen that while model 1 is limited in modelling\nthe complete data distribution (11.32 Bits per dimension (BPD)), it performs\nwell on detecting OOD covariate shift with NSD (AUROC 67.8%), comparable\nto the performance obtained with GLOW. Only using the high-frequency image\ncomponents in an unconditional setting (model 2) yields a somewhat lower OOD\ndetection performance of 65.5% AUROC. Introducing the SDL (model 3), lowers\nthe mean BPD and improves on LL-based OOD detection (58.4%), but adversely"}]}