{"title": "JL1-CD: A New Benchmark for Remote Sensing Change Detection and a Robust Multi-Teacher Knowledge Distillation Framework", "authors": ["Ziyuan Liu", "Ruifei Zhu", "Long Gao", "Yuanxiu Zhou", "Jingyu Ma", "Yuantao Gu"], "abstract": "Deep learning has achieved significant success in the field of remote sensing image change detection (CD), yet two major challenges remain: the scarcity of sub-meter, all-inclusive open-source CD datasets, and the difficulty of achieving consistent and satisfactory detection results across images with varying change areas. To address these issues, we introduce the JL1-CD dataset, which contains 5,000 pairs of 512 \u00d7 512 pixel images with a resolution of 0.5 to 0.75 meters. Additionally, we propose a multi-teacher knowledge distillation (MTKD) framework for CD. Experimental results on the JL1-CD and SYSU-CD datasets demonstrate that the MTKD framework significantly improves the performance of CD models with various network architectures and parameter sizes, achieving new state-of-the-art results. The code is available at https://github.com/circleLZY/MTKD-CD.", "sections": [{"title": "I. INTRODUCTION", "content": "Remote sensing image change detection (CD) is a technique used to detect and analyze surface changes by leveraging multi-temporal data [1]. Over the past few decades, it has been extensively studied and has become a crucial tool for Earth surface observation. CD plays a significant role in various fields, including land-use change updates, natural disaster assessment, environmental monitoring, and urban planning.\nEarly traditional CD methods primarily relied on image processing techniques, detecting changes by directly comparing pixel values or spectral features between multi-temporal images. Examples include Image Differencing [2], Change Vector Analysis (CVA) [3], Principal Component Analysis (PCA) [4], Kauth-Thomas (KT) transforms [5], and Multivariate Alteration Detection (MAD) [6]. While these methods are simple and intuitive, they exhibit limited performance when handling complex change patterns, such as those affected by significant noise, lighting variations, or seasonal differences.\nWith the rise of machine learning (ML), CD methods began to incorporate feature extraction and classifiers. Common techniques include Support Vector Machines (SVM) [7], Random Forest (RF) [8], K-means clustering [9] and so on. These machine learning approaches significantly improved detection accuracy but heavily relied on high-quality labeled data and manually designed features.\nIn recent years, the rapid advancement of deep learning (DL) has revolutionized remote sensing CD, delivering substantial performance breakthroughs. DL-based CD methods generally involve three steps: (1) extracting change features from image pairs, (2) generating change maps based on the extracted features, and (3) predicting labels based on the feature maps. Convolutional Neural Networks (CNNs), which achieved remarkable success in image processing, were the first neural network architecture applied to remote sensing CD and remain widely optimized and utilized today [10]\u2013 [12]. With the introduction of Transformers, some studies have explored their application in CD tasks [13], [14]. More recently, Foundational Model (FM) has emerged as a novel paradigm, aiming to achieve multi-task and multi-domain generalization through large-scale pretraining [15]. There have been works utilizing remote sensing data to fine-tune pretrained models such as Vision Transformers (ViT) [16], Segment Anything Model (SAM) [17], and Contrastive Language-Image Pretraining (CLIP) [18], achieving higher performance in CD tasks [19]\u2013[22]. Several semi-supervised methods have also been proposed, further improving CD performance under limited labeled data. Zhang et al. [23] propose a novel multilevel consistency-regularization-based semi-supervised CD approach, incorporating Fourier-based frequency transformation and a dynamic pseudolabel selection scheme to mitigate background noise and improve unlabeled data utilization. Xu et al. [24] introduce a semi-supervised label and embedding consistency network (SS-LEC) for ORSI scene classification, which strategically enforces consistency across augmentations and stages of training. Li et al. [25] propose SemiCD-VL, a VLM-guided semi-supervised change detection method that synthesizes pseudo labels via a mixed change event generation strategy, achieving significant performance gains over FixMatch and SOTA unsupervised methods.\nHowever, DL-based CD methods generally face two major challenges: the scarcity of high-quality, high-resolution, all-inclusive CD datasets and limitations in handling highly dynamic change areas. Although numerous CD datasets have been constructed and proposed, they are often tailored to specific scenarios, which restricts the generalization capabilities of the algorithms. For instance, models trained on datasets focused on human-induced changes often fail to perform effectively when confronted with natural change scenarios. On the other hand, the learning capacity of these models is inherently limited. Most existing algorithms rely on a single-phase training approach, typically end-to-end training, supplemented by techniques such as learning rate decay. While such training strategies can achieve satisfactory results within a constrained range of changes, the models' performance significantly degrades when addressing scenarios with wide variations in change areas, ranging from no change to complete change.\nTo address the aforementioned challenges, we construct a new large-scale, high-resolution, all-inclusive open-source CD dataset, named \u201cJL1-CD\u201d (named after the Jilin-1 satellite). This dataset comprises 5,000 pairs of 512 x 512 images captured in China, with a resolution of 0.5-0.75 meters, along with binary change labels at the pixel level. The JL1-CD dataset not only includes common human-induced changes such as buildings and roads but also encompasses various natural changes, such as forests, water bodies, and grasslands. Additionally, we propose a multi-teacher knowledge distillation (MTKD) framework for change detection optimization. First, we introduce the O-P strategy. To address the difficulty of handling highly dynamic change areas in existing algorithms, we propose the concept of the Change Area Ratio (CAR) and partition the dataset based on different CAR levels. CD models are then trained on each partition, reducing the learning burden on individual models, thereby achieving better training outcomes and higher detection accuracy. Next, to lower the computational and time complexity during inference, we extend the O-P strategy by training a student model under the MTKD framework. The student model learns the strengths of teacher models optimized for various CAR scenarios, achieving superior detection accuracy without increasing resource consumption during inference.\nOur main contributions are as follows:\n1) We introduce JL1-CD, a new sub-meter, all-inclusive open- source CD dataset comprising 5,000 pairs of remote sensing image patches with a resolution of 0.5-0.75 meters.\n2) We propose the O-P strategy, which partitions the training of CD models based on CAR levels, significantly improving performance across diverse CAR scenarios.\n3) We further develop the MTKD framework, where models trained under the O-P strategy serve as teacher models. The student model trained under the supervision of multiple teachers achieves superior detection accuracy without additional computational or time costs during inference.\n4) Extensive benchmarking experiments on existing algorithms demonstrate that O-P and MTKD significantly enhance performance across various architectures and parameter sizes, achieving new state-of-the-art (SOTA) results."}, {"title": "II. RELATED WORKS", "content": "Traditional CD methods have been extensively studied in remote sensing, with early approaches relying on simple algebraic operations such as image differencing [2] and image ratioing [26]. These techniques compute pixel-level differences or ratios between two images and apply a threshold to identify change regions. Subsequent advancements introduced improved thresholding strategies, such as the Otsu method [27] and the normalized difference vegetation index (NDVI) algorithm [28], to enhance detection accuracy. Transform- based methods, such as PCA [4] and MAD [6], were later adopted, leveraging statistical properties of images. However, these methods are heavily dependent on image statistics, which limits their scalability and precision in large-scale, high- resolution CD applications. The advent of machine learning has significantly enhanced the ability to extract useful change features. For instance, Bovolo et al. [29] proposed an unsupervised change detection framework that leverages a semi- supervised SVM initialized with pseudo-training data, effectively addressing the complexity of multi-temporal spectral feature analysis. Wessels et al. [30] developed an automated system for land cover update mapping, integrating iteratively reweighted MAD (IRMAD) for change mask generation and RF classifiers for robust land cover classification, achieving notable accuracy in operational settings. Despite these advancements, traditional and early ML-based approaches often rely on manually designed features, which perform well in straightforward scenarios but exhibit limited generalization capability for complex and diverse change types."}, {"title": "A. Traditional and ML-Based CD", "content": "In recent years, deep learning has experienced rapid advancements, achieving remarkable success in remote sensing image CD. As illustrated in Fig. 1, we present a timeline of the development of mainstream DL-based CD algorithms. Based on the differences in neural network architectures and training paradigms, DL-based CD methods can be classified into three main categories\na) CNN-Based CD: CNNs serve as the foundation of many early DL-based CD methods and remain widely utilized today. Daudt et al. [10] proposed three fully convolutional neural network architectures, including two Siamese network extensions, which achieved significant improvements in accuracy and efficiency for CD tasks on multiple datasets. Zhang et al. [31] introduced the Image Fusion Network (IFN), which employs a deeply supervised two-stream architecture for high- resolution remote sensing CD, achieving SOTA performance with superior boundary completeness and compactness in change maps. Chen et al. [32] proposed the Siamese-based Spatial-Temporal Attention Network (STANet), incorporating a novel CD self-attention module to model spatial-temporal dependencies at various scales, significantly improving F1-scores on benchmark datasets. Fang et al. [33] designed SNUNet- CD, a densely connected Siamese network that preserves localization information and employs an Ensemble Channel Attention Module (ECAM) for deep supervision, achieving better trade-offs between accuracy and computational cost. Zheng et al. [34] proposed ChangeStar, a model leveraging single-temporal supervised learning with ChangeMixin mod- ules to train CD models using unpaired images. Han et al. [35] introduced HANet, a hierarchical attention network with pro- gressive foreground-balanced sampling and a lightweight self- attention mechanism, effectively addressing class imbalance in CD tasks and achieving superior results on highly imbalanced datasets. The Change Guiding Network (CGNet) introduced by Han et al. [11] utilizes a self-attention mechanism to improve edge detection and internal consistency in change maps, demonstrating robust performance across multiple CD datasets. Some studies have focused on designing lightweight and fast CD models. Codegoni et al. [36] presented TinyCD, a lightweight and efficient CD model using a Siamese U-Net architecture and the Mix and Attention Mask Block (MAMB), outperforming SOTA models while being significantly smaller and faster. Xing et al. [37] proposed LightCDNet, a lightweight CD model with an early fusion backbone and pyramid decoder.\nb) Transformer-Based CD: Transformer-based methods have emerged as a promising approach for CD. Chen et al. [38] introduced the bitemporal image transformer (BIT), combining a transformer encoder with a ResNet backbone to model spatial-temporal contexts efficiently. Bandara et al. [13] proposed ChangeFormer, a fully transformer-based Siamese network for CD, which unifies a hierarchical transformer encoder with a multi-layer perceptron (MLP) decoder. Fang et al. [14] introduced the Changer series framework, a novel archi- tecture for CD that incorporates alternative interaction layers between bi-temporal features. This framework is applicable to both CNN-based and Transformer-based models, significantly enhancing the performance of the original models.\nc) FM-Based CD: Recently, foundation models have become a new training paradigm, and some works have applied them to CD tasks. Li et al. [19] proposed the Bi-Temporal Adapter Network (BAN), a universal FM-based framework for CD, which enhances existing models with minimal additional parameters and achieves significant performance improve- ments. Chen et al. [21] introduced Time Travelling Pixels (TTP), a method that integrates latent knowledge from the SAM model into CD, overcoming domain shifts and spatio- temporal complexities, demonstrating SOTA results on the LEVIR-CD [32] dataset. Zheng et al. [22] developed Any- Change, a zero-shot CD model built on the SAM that utilizes bitemporal latent matching for training-free adaptation, setting a new SOTA on the SECOND [39] benchmark and achieving significant improvements in both unsupervised and supervised CD tasks."}, {"title": "B. DL-Based CD", "content": "Knowledge distillation (KD), introduced by Hinton et al. [40], aims to transfer the representational knowledge of a teacher network to a smaller student network. In recent years, as the complexity of DL models in remote sensing tasks has increased, researchers have explored how to transfer knowledge from large, complex teacher models to smaller, more efficient student models through KD, thereby improving performance [41], [42].\nYan et al. [43] proposed a novel self-supervised learning approach for unsupervised CD by fusing domain knowledge of remote sensing indices during both training and infer- ence. By calculating cosine similarity, they selected high- similarity feature vectors from both the teacher and student networks to implement a hard negative sampling strategy, effectively improving CD performance. Wang et al. [44] addressed remote sensing semantic CD (SCD), which focuses on detecting changes in land cover and land use over time. The authors introduced a dual-dimension feature interaction network (DFINet) that enhances intraclass and interclass feature differentiation by incorporating a temporal difference feature enhancement (TDFE) module, which captures temporal features comprehensively. Wang et al. [45] proposed a KD-based method for CD (CDKD), designed to overcome the challenges of deploying large deep learning models with high computational and storage requirements on resource- constrained spaceborne edge devices. Although these methods have successfully utilized KD to enhance the performance of various student models, they are tailored to specific models and do not provide a generalized distillation framework applicable to various CD models. Furthermore, there is a lack of open- source KD-based code for remote sensing image CD tasks. In contrast, the proposed MTKD framework significantly improves the performance of CD models with various architectures and parameter sizes, and we commit to open-sourcing all the code and models."}, {"title": "C. Knowledge Distillation in CD", "content": "High-resolution, all-inclusive CD datasets are crucial for remote sensing applications. High-resolution images provide richer spatial information, which is more conducive to visual interpretation compared to medium- and low-resolution images. Datasets with comprehensive change features enable the development of algorithms with greater generalization and transferability. Despite the numerous open-source change detection datasets proposed over the past decades, many still lack sub-meter-level resolution, and the variety of change types remains limited. These limitations hinder progress in CD research, particularly in the development of DL-based algorithms.\nWe collect the number of types of changes, number of image pairs, image size, and resolution information of mainstream CD datasets in Table I. The SZTAKI AirChange Benchmark [46] contains 12 pairs of 952 \u00d7 640 and one pair of 1,048 \u00d7 724 optical aerial images. It is one of the earliest and most commonly used CD datasets in early research. The DSIFN dataset [31] consists of 6 large bi-temporal image pairs from 6 cities in China, which are cropped into 394 sub-image pairs, each sized 512 \u00d7 512. The SECOND dataset [39] includes 4,662 pairs of aerial images collected from multiple platforms and sensors, covering cities such as Hangzhou, Chengdu, and Shanghai. Unlike other datasets that classify changes into only two categories (change and no change), SECOND provides detailed annotations for change types, including non- vegetated surfaces, trees, low vegetation, water, buildings, and playgrounds. However, the resolution of all or part of the images in these datasets does not reach the sub-meter level. WHU-CD [47], LEVIR-CD [32], and S2Looking [48] are very popular datasets that are specifically designed for monitoring building changes. These datasets predominantly include human-induced changes and lack natural change types. The CDD dataset is derived from 7 pairs of 4,725 \u00d7 2,700 real- world seasonal change remote sensing images. The SYSU-CD contains 20,000 pairs of 0.5-meter aerial images captured in Hong Kong between 2007 and 2014. These datasets feature high resolution and diverse change types.\nTo provide a better benchmark for evaluating CD algorithms, we propose the JL1-CD dataset, a high-resolution, all-inclusive change detection dataset. JL1-CD includes 5,000 pairs of satellite images captured in China from early 2022 to the end of 2023, including Shandong, Ningxia, Anhui, Hebei, Hunan, and other regions. The images have sub-meter resolutions ranging from 0.5 to 0.75 meters and are sized 512 \u00d7 512 pixels. As shown in Fig. 2, the dataset covers various common human-induced and natural surface features, such as piled earth, buildings, roads, hardened surfaces, woodlands, grasslands, croplands, and water bodies. The original 5,000 image pairs are divided into 4,000 pairs for training and 1,000 pairs for testing, following an 80:20 split. The JL1-CD dataset will be made openly available for all research needs."}, {"title": "III. JL1-CD DATASET", "content": "In this section, we provide a comprehensive overview of the proposed methods. In Section IV-A, we first introduce the Origin-Partition (O-P) strategy designed for the challenging all-inclusive CD dataset. Building upon the O-P strategy, we further present our Multi-Teacher Knowledge Distillation (MTKD) framework in Section IV-B. Finally, in Section IV-C, we describe the overall loss function used for training the teacher and student models."}, {"title": "IV. METHODOLOGY", "content": "The traditional training and testing approach for CD models is illustrated in the upper-left corner of Fig. 3 (green box) and the upper-right corner (pink box). For a given change detection model M, the input consists of a pair of images ($X_1$, $X_2$), and the output is a change map (CM). If the number of channels c = 1, the predicted label Y can be directly obtained using a thresholding method as follows:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\n\\hat{Y}(i) = \\begin{cases}\n1, & \\text{if } CM(i) > th \\\\\n0, & \\text{if } CM(i) < th\n\\end{cases}\n\\end{equation}\n\n\\end{document}\n\nwhere (i) denotes the pixel location in the image, \"1\" represents a change, and \"0\" represents no change (for visualization purpose, \"1\" will be mapped to a grayscale value of 255). The threshold th is a predefined value. If c = 2, the predicted label \u0176 is typically determined using an element-wise comparison of the two channels, such as:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\n\\hat{Y}(i) = \\begin{cases}\n1, & \\text{if } CM_0(i) \\geq CM_1(i) \\\\\n0, & \\text{if } CM_0(i) < CM_1(i)\n\\end{cases}\n\\end{equation}\n\n\\end{document}\n\nwhere $CM_0$ and $CM_1$ represent the first and second layers of the change map, respectively. If c > 2, it indicates that the CD model M not only predicts the locations of changes but also detects the types of changes, which is beyond the scope of this paper.\nHowever, as shown in Fig. 4, for a dataset like JL1-CD, where the Change Area Ratio (CAR) can range from 0% to 100%, training a single model using traditional methods may not be optimal. The model would struggle to learn the full range of change patterns in an all-inclusive manner. To address this issue, we propose the Origin-Partition (O-P) strategy to enhance the model's detection performance. As illustrated in the green boxes of Fig. 3 (Step 1 and Step 2), for a given CD algorithm, we train the corresponding models in the following sequence:\n1) The original model $M_O$ is trained on the complete training set using the algorithm's default configuration.\n2) As shown in Fig. 5, the CAR range for the training, validation, and test sets is very large. However, the majority of images have a CAR of less than 5%. Therefore, we set appropriate thresholds $th_1$ and $th_2$ and divide the original training set into three categories: small, medium, and large.\n3) The models are then trained from scratch using the partitioned training sets, yielding models $M_S$, $M_M$, and $M_L$. The training process can be formalized as:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\n\\hat{Y} = \\begin{cases}\nf_{M_S}(X_1, X_2), & \\text{if } CAR_{GT} \\leq th_1 \\\\\nf_{M_M}(X_1, X_2), & \\text{if } th_1 < CAR_{GT} \\leq th_2 \\\\\nf_{M_L}(X_1, X_2), & \\text{if } CAR_{GT} > th_2\n\\end{cases}\n\\end{equation}\n\n\\end{document}\n\nwhere $CAR_{GT}$ denotes the CAR calculated based on the ground truth label for the image pair ($X_1$, $X_2$).\nAs shown in the middle pink box in Fig. 3, during testing, since we do not know the CAR of the test images, we first use $M_O$ to estimate the CAR roughly. Based on this estimated CAR, we then classify the image into one of the three categories: small, medium, or large, and send it to the corresponding model $M_S$, $M_M$, or $M_L$ to obtain the final detection result:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\n\\hat{Y} = \\begin{cases}\nf_{M_S}(X_1, X_2), & \\text{if } CAR_{M_O} \\leq th_1 \\\\\nf_{M_M}(X_1, X_2), & \\text{if } th_1 < CAR_{M_O} \\leq th_2 \\\\\nf_{M_L}(X_1, X_2), & \\text{if } CAR_{M_O} > th_2\n\\end{cases}\n\\end{equation}\n\n\\end{document}\n\nwhere $CAR_{M_O}$ denotes the CAR calculated based on the predicted label from the original model $M_O$."}, {"title": "A. O-P Strategy", "content": "By partitioning the training set, we effectively reduce the learning burden for each model. As a result, the Origin-Partition (O-P) strategy significantly enhances the performance of the CD algorithm. However, a clear issue arises: during inference, we are required to load 4 different models, and even disregarding data throughput, the time spent is at least twice that of the original algorithm (often much more). This substantially increases both memory and time complexity. We are thus prompted to consider: is there a way to combine the capabilities of these four models into a single model?\nTo address this, we propose the Multi-Teacher Knowledge Distillation (MTKD) framework. In the O-P strategy, we have already trained the models $M_O$, $M_S$, $M_M$, and $M_L$. Building on this, we further train a student model $M_S$. First, we initialize the student model $M_S$ using the parameters from $M_O$, and then use $M_S$, $M_M$, and $M_L$ as teacher models to perform KD. For each input image pair, we select the appropriate teacher model based on the image's CAR to guide the student model. The process is shown in the green box at the bottom of Fig. 3. In this framework, when the student model $M_S$ is supervised by the ground truth labels, it also receives the CM information corresponding to different CAR ranges, provided by the teacher models.\nDuring the testing phase, only the student model $M_S$ is used for inference, thereby significantly improving the model's CD performance across different CAR ranges without introducing any additional computational cost."}, {"title": "B. MTKD Framework", "content": "When training the original model $M_O$ and the teacher models $M_S$, $M_M$, and $M_L$, we employ the standard binary cross-entropy loss:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\nL_{CE} = \\frac{1}{N} \\sum_{i=1}^{N} - (Y(i) \\log(\\hat{Y}(i)) - (1 - Y(i)) \\log(1 - \\hat{Y}(i)))\n\\end{equation}\n\n\\end{document}\n\nwhere $Y(i)$ denotes the ground truth label of pixel i.\nWhen training the student model $M_S$, we select the appropriate teacher model based on the CAR range. Then the mean squared error (MSE) is computed at the CM layer as the distillation loss:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\nL_{KD} = \\frac{1}{N} \\sum_{i=1}^{N} (CM(i) - CM_T(i))^2, \\quad T \\in \\{T_S, T_M, T_L\\}\n\\end{equation}\n\n\\end{document}\n\nThus, the complete loss function for training $M_S$ is given by:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\nL = L_{CE} + \\lambda L_{KD}\n\\end{equation}\n\n\\end{document}\n\nwhere the parameter \u03bb is used to balance the contributions of the cross-entropy loss and the distillation loss."}, {"title": "C. Loss Function", "content": "We first conduct experiments on our JL1-CD dataset. Additionally, to validate the robustness of the proposed O-P strategy and MTKD framework, we further perform experiments on the SYSU-CD dataset [50]. The detailed information for these two datasets is as follows:\n1) JL1-CD Dataset: As described in Section III, the JL1- CD dataset consists of 5,000 pairs of high-resolution images, with a resolution of 0.5-0.75 meters and image size of 512 \u00d7 512. In the competition, the first 4,000 image pairs are used for training, and the remaining 1,000 image pairs are used for testing (with the ground truth labels being unavailable during the competition). To ensure sufficient data for training, we use the first 100 image pairs as the validation set, the next 3,900 image pairs as the training set, and the remaining 1,000 image pairs for testing. As shown in Fig. 5, our data split is reasonable, as the CAR distributions of the three sets are very similar.\n2) SYSU-CD Dataset: As illustrated in Fig. 6, the SYSU- CD dataset is also a challenging dataset with a very large CAR range, so we choose this dataset as the second benchmark to validate the robustness of our proposed methods. The SYSU- CD dataset contains 12,000 pairs for training, 4,000 pairs for validation, and 4,000 pairs for testing, with each image having a resolution of 0.5 meters and a size of 256 x 256."}, {"title": "V. EXPERIMENT", "content": "All algorithms are trained and tested using the PyTorch- based OpenCD Toolbox [55]. To ensure a fair comparison and clearly assess the contributions of the Origin-Partition (O-P) strategy and the Multi-Teacher Knowledge Distillation (MTKD) framework to the performance improvement of the CD models, we adopt consistent settings for all models ($M_O$, $M_L$, $M_M$, $M_S$, and $M_S$) across the various algorithms, as described below:\n1) The patch size of the input images is 512 \u00d7 512, which matches the original image dimensions.\n2) Data augmentation methods, including RandomRotate, RandomFlip, and PhotoMetricDistortion, are applied.\n3) The AdamW optimizer is used with $\u03b2_1$ = 0.9 and $\u03b2_2$ = 0.99, and the default batch size is set to 8 image pairs (with a batch size of 16 for ChangeStar-FarSeg).\n4) Models $M_O$, $M_{T_L}$, $M_{T_M}$, and $M_{T_S}$ are trained for 200k iterations on the original and the corresponding partitioned datasets (300 epochs for TTP), while the student model $M_S$ is trained for an additional 100k iterations (100 epochs for TTP) on the original dataset.\n5) Training begins with a warm-up phase of 1k iterations (5 epochs for TTP), during which the learning rate (LR) is linearly increased from 1e-6 to the initial LR value, as specified in Table II. Afterward, the LR is linearly decayed to O as training progresses (TTP employs a CosineAnnealing decay schedule).\n6) The HANet, CGNet, BAN (ViT-L), and TTP models are trained on the NVIDIA A800 server, while other models are trained on the NVIDIA RTX 3090 server. All models are tested on the A800 server.\nWhen partitioning the dataset, we set the thresholds $th_1$ = 0.05 and $th_2$ = 0.2, which ensures a balanced distribution of samples across the partitions. The model is saved every 1k iterations (5 epochs for TTP), and the checkpoint with the highest mIoU value on the validation set is selected for testing.\nFor the training of $M_{T_S}$, due to the varying distributions of the change maps and the different magnitudes of $L_{CE}$ across modelss, a grid search is performed over the set {1e - 5, 5e - 5, 1e - 4, 5e - 4, 1e - 3, 5e - 3, 1e - 2} to determine the optimal distillation loss weight \u03bb for each model. More configuration details are summarized in Table II."}, {"title": "A. Dataset Description", "content": "Therefore, we choose the averaged versions of the aforementioned metrics, which are calculated as follows:\n\n\\documentclass{article}\n\\usepackage{amsmath}\n\n\\begin{document}\n\n\\begin{equation}\nmIoU = \\frac{1}{2}(IoU_0 + IoU_1)\n\\end{equation}\n\n\\begin{equation}\nmPrecision = \\frac{1}{2} (\\frac{TN}{TN+FP} + \\frac{TP}{TP+FN})\n\\end{equation}\n\n\\begin{equation}\nmAcc = \\frac{1}{2} (\\frac{TN}{TN+FP} + \\frac{TP}{TP+FN})\n\\end{equation}\n\n\\begin{equation}\nmFscore = \\frac{1}{2} (Fscore_0 + Fscore_1)\n\\end{equation}\n\n\\begin{equation}\nFscore_i = 2 * \\frac{Precision_i * Recall_i}{Precision_i + Recall_i}\n\\end{equation}\n\n\n\\end{document}\n\nwhere TP, FP, TN, and FN represent true positives, false positives, true negatives, and false negatives, respectively. The averaged accuracy and recall are equivalent, so we only use mAcc for consistency in subsequent experiments.\nIt is important to note that in the toolboxes like MM- Segmentation [53] and MMRotate [54], these metrics are computed based on the total number of pixels across all predicted label images. In this paper, however, to align with the competition requirements, we first calculate these metrics for each individual image and then compute the average of the results across all images to obtain the final outcome."}, {"title": "D. Implementation Details", "content": "Table III summarizes the numerical results of mIoU, mAcc, mPrecision, and mFscore for all methods on the JL1-CD test set, trained under the original, O-P, and MTKD strategies. As shown in the table, we observe that the O-P strategy does not lead to performance improvements for BAN-ViT-B, BAN-ViT-B-IN21k, FC-EF, FC-Siam-Conc, and FC-Siam-Diff. This suggests that the partition-based training method is not suitable for these algorithms, and thus cannot obtain sufficiently strong teacher models. Therefore, we do not continue with MTKD experiments for these methods. However, the O-P strategy or MTKD framework can improve the performance of all other algorithms to a certain extent. The following conclusions can be drawn from these results:\n1) Surprisingly, unlike their performance on the validation set, many algorithms under O-P perform worse than under MTKD, and in some cases, even worse than the original models (e.g., STANet, IFN, Changer-MiT-b1, etc.). However, the student models obtained through MTKD training can achieve significantly better performance than models trained under the original and O-P methods. This is mainly due to the inability of the original models to achieve accurate CAR on the test set during the coarse detection stage. This finding also indicates that our MTKD method can endow student models with superior capabilities compared to the teacher models, without increasing computation and time cost during inference.\n2) After MTKD optimization, the single Changer-MiT-b0 and Changer-MiT-b1 models can outperform the original TTP in terms of mIoU. Additionally, the TTP model, after MTKD optimization, shows improvements in mIoU and mFscore by 1.30% and 1.80%, respectively, setting a new SOTA.\n3) The O-P strategy shows the most significant improvement for Changer-MiT-s50 (with a 9.49% increase in mIoU and a 10.4% increase in mFscore), while the MTKD framework yields the most significant performance boost for HANet (with a 4.03% increase in mIoU and a 4.53% increase in mFscore)."}, {"title": "C. Evaluation Metrics", "content": "In remote sensing change detection", "encountered": false}]}