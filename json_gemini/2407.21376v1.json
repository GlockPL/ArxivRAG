{"title": "An Extended Kalman Filter Integrated Latent Feature Model on Dynamic Weighted Directed Graphs", "authors": ["Hongxun Zhou", "Xiangyu Chen", "Ye Yuan"], "abstract": "A dynamic weighted directed graph (DWDG) is commonly encountered in various application scenarios. It involves extensive dynamic interactions among numerous nodes. Most existing approaches explore the intricate temporal patterns hidden in a DWDG from the purely data-driven perspective, which suffers from accuracy loss when a DWDG exhibits strong fluctuations over time. To address this issue, this study proposes a novel Extended-Kalman-Filter-Incorporated Latent Feature (EKLF) model to represent a DWDG from the model-driven perspective. Its main idea is divided into the following two-fold ideas: a) adopting a control model, i.e., the Extended Kalman Filter (EKF), to track the complex temporal patterns precisely with its nonlinear state-transition and observation functions; and b) introducing an alternating least squares (ALS) algorithm to train the latent features (LFs) alternatively for precisely representing a DWDG. Empirical studies on DWDG datasets demonstrate that the proposed EKLF model outperforms state-of-the-art models in prediction accuracy and computational efficiency for missing edge weights of a DWDG. It unveils the potential for precisely representing a DWDG by incorporating a control model.", "sections": [{"title": "I. INTRODUCTION", "content": "A dynamic weighted directed graph (DWDG) is a mathematical abstraction that represents a system of entities and the evolving relationships between them over time [1-4]. Specifically, it incorporates directionality in relationships and assigns weights to the edges to capture the strength or significance of those relationships. Such a DWDG contains a great deal of valuable knowledge and is often encountered in various real scenarios, i.e., transportation networks [1], social networks [2], and communication networks [3]. Hence, how to perform a precise representation of a DWDG for various data analysis tasks has become a highly popular issue [1-6].\nIn recent years, Graph Neural Networks (GNNs) have gained popularity since they provide a powerful framework for analyzing and modeling graph-structured data based on the message-passing mechanism. For instance, He et al. [7] propose the lightGCN, which eliminates the feature transformation and nonlinear activation of the traditional graph convolution network (GCN). Yun et al. [8] propose GTN which can represent heterogeneous information in the network and identify unconnected but potentially useful edges in the original graph. Guo et al. [9] propose DGCN-HN which adds residual connection and global connection. However, the previous models are static models, which cannot capture a DWDG accurately. To address it, a pyramid of sophisticated dynamic GNN models is proposed. For instance, Manessi et al. [10] propose WD-GCN which is a combination of graph convolution units and LSTM. Malik et al. [11] propose TM-GCN which extends the GCN to learn representations of dynamic graphs using the m-product technique.\nIt is pointed out that a DWDG can be denoted by an incomplete matrix sequence [12-17], as shown in Fig. 1, since it becomes impossible to observe the full interactions among nodes at each time slot due to uncontrollable reasons, i.e., sensor fault in transportation networks [1, 22-24]. According to existing studies, a latent feature (LF) model [18-21, 25-27, 31-33] is also a mainstream approach to perform the representation of a DWDG since it proves to be highly effective in addressing the incomplete matrix sequence. For instance, Luo et al. [29] present a biased tensor-based LF model, which incorporates linear biases to represent the temporal patterns accurately. Zhang et al. [28] propose a non-negative tensor-based LF model to handle an incomplete matrix sequence while considering the non-negative constraints. Wu et al. [30] propose diversified tensor-based LF models to extract desired features from the target DWDG.\nAlthough the above models obtain convincing performance on a DWDG, they explore the complex temporal patterns hidden in a DWDG from the purely data-driven perspective, which suffers from accuracy loss when a DWDG exhibits strong fluctuations over time [37]. Fig. 2 gives an illustrative example of such time-dependent data fluctuations.\nHence, it appears essential to implement a tailored model design to characterize such fluctuations in a DWDG. As shown in [34, 36], an Extended Kalman Filter is a recursive control model designed for a nonlinear system in control theory, which is commonly employed to handle various problems involving dynamic estimation with uncertain fluctuations [35, 38, 39] It can estimate each temporal state of a dynamic system based on previous ones, precisely representing temporal patterns with its nonlinear state-transition and observation functions.\nMotivated by this discovery, this study proposes a novel Extended-Kalman-Filter-Incorporated Latent Feature (EKLF) model with the following two-fold ideas:"}, {"title": "II. PRELIMINARIES", "content": "Note that a Dynamic Weighted Directed Graph and an Incomplete Matrix Sequence are defined as follows:\nDefinition 1 (Dynamic Weighted Directed Graph): Note that this study primarily focuses on the changes in the edges over time. Hence, a DWDG is defined as G={G(1), G(2), ..., G(T)} and each graph snapshot G(t) = (V, E(t)) is a graph at time slot t (1 \u2264 t \u2264 T), where V is the node set with M nodes, and E(t) indicates the edge set at time t between node i and node j.\nDefinition 2 (Incomplete Matrix Sequence): Naturally, each graph snapshot G(t) = (V, E(t)) in a DWDG can be described by an adjacency matrix Y(t), as shown in Fig. 1. In addition, a quantifiable index is allocated to the edge between two nodes as its weight. Specifically, according to Fig. 1, only a few directed edges are observed and the others are missing. Hence, Y(t) is an incomplete matrix. Ultimately, a DWDG G={G(1), G(2), ..., G(T)} can be reformulated by an incomplete matrix sequence Y={Y(1), Y(2), ..., Y(T)}.\nHence, in our context, performing a representation of a DWDG is equivalent to analyzing its corresponding incomplete matrix sequence.\nA latent feature (LF) model [43-51, 76-81], is widely adopted for addressing an incomplete matrix sequence. Given a target incomplete matrix sequence Y={Y(1), Y(2), ..., Y(T)}, it builds the rank-f approximation to each Y(t) by two LFs N(t) and Q(t) on Y(t)'s known entity set Y(t). To achieve this goal, an objective function on the regularized Euclidean distance is defined as:"}, {"title": "III. METHOD", "content": "For performing precise representation of a DWDG, the proposed EKLF contains the following two procedures:\nTo capture the intricate temporal patterns within a DWDG, we initially construct a coupled dynamic system involving temporal LFs N={N(1), N(2), ..., N(T)}, whose posterior state can be estimated by the EKF. Specifically, such a coupled dynamic system is described by a state-transition process and an observation process.\nTo describe the dynamic variation of temporal LFs N={N(1), N(2), ..., N(T)}, the nonlinear state-transition function S(\u00b7) and the state-transition noise W(t)i are adopted to achieve the state process equation:\n$n_{(t)i} = S(n_{(t-1)i}) + W_{(t)i}$    (2)\nwhere S(\u00b7) denotes a nonlinear state-transition function, n(t)i denotes the state vectors of node i at time t, and w(t)i is state-transition noise with W(t)i~N(0, W(t)i) and W(t)i is its covariance matrix. Further, we expand S(n(t-1)i) for the first-order Taylor's series at \u00f1(t-1)i as follows:\n$S(n_{(t-1)i}) \\approx S(\\hat{n}_{(t-1)i}) + S'(\\hat{n}_{(t-1)i}) (n_{(t-1)i} - \\hat{n}_{(t-1)i}) $\n$\\approx B_{(t-1)i}n_{(t-1)i} + C_{(t-1)i}$   (3)\nwhere $\\hat{n}_{(t-1)i}$ is the posterior state of n(t-1), $B_{(t-1)i} = S'(\\hat{n}_{(t-1)i})$ and $C_{(t-1)i} = S(n_{(t-1)i})- S'(\\hat{n}_{(t-1)i}) \\hat{n}_{(t-1)i}$. On the other hand, following the principle of an EKF, the following observation process equation is built:\n$Y_{(t)i} = O(n_{(t)i})+ r_{(t)i}$     (4)\nwhere y(t)i denotes observation edges related to node i at time slot t, O(\u00b7) denotes a nonlinear observation function, and r(t)i denotes observation noise with r(t)i ~N(0, R(t)i) and R(t)i is its covariance matrix. Further, we expand O(n(t)i) for the first-order Taylor's series at n(t)i as follows:\n$O(n_{(t)i}) \\approx O(\\hat{n}_{(t)i}) + O'(\\hat{n}_{(t)i}) (n_{(t)i} - \\hat{n}_{(t)i})$\n$\\approx O'(\\hat{n}_{(t)i}) n_{(t)i} + (O(\\hat{n}_{(t)i}) - O'(\\hat{n}_{(t)i}) \\hat{n}_{(t)i})$\n$\\approx D_{(t)i}n_{(t)i} + H_{(t)i}$       (5)\nwhere $\\hat{n}_{(t)i}$ is the prior state of n(t)i, $D_{(t)i} = O'(\\hat{n}_{(t)i})$ and $H_{(t)i} = O(\\hat{n}_{(t)i}) - O'(\\hat{n}_{(t)i}) \\hat{n}_{(t)i}$.\nUtilizing the deductions above, we construct a coupled dynamic system following the EKF, which adopts two steps to obtain the desired temporal LFs:\n1) State Prediction:\n$B_{(t-1)i} = S'(\\hat{n}_{(t-1)i})$     (6)\n$\\tilde{n}_{(t)i} = S(n_{(t-1)i})$     (7)\n$\\tilde{P}_{(t)i} = B_{(t-1)i}P_{(t-1)i} B_{(t-1)i}^{T}+W_{(t)i}$ (8)\nwhere $\\tilde{n}_{(t)i}$ denotes a prior estimate of n(t)i, $\\tilde{P}_{(t)i}$ denotes the prior covariance matrix of n(t)i. Following the principle of EKF, we revise the prior information $\\tilde{n}_{(t)i}$ and $\\tilde{P}_{(t)i}$ to obtain the final posterior state of n(t)i with the following step:\n2) Feedback update:\n$D_{(t)i} = O'(\\hat{n}_{(t)i}) = Q_{(t)i}f'(x)$    (9)\n$K_{(t)i} = \\tilde{P}_{(t)i}D_{(t)i}^{T} (D_{(t)i} \\tilde{P}_{(t)i}D_{(t)i}^{T}+R_{(t)i})^{-1}$   (10)\n$\\hat{n}_{(t)i} = \\tilde{n}_{(t)i} + K_{(t)i} (Y_{(t)i} -O(\\tilde{n}_{(t)i}))$      (11)\n$P_{(t)i} = \\tilde{P}_{(t)i} -K_{(t)i}D_{(t)i} \\tilde{P}_{(t)i}$    (12)\nwhere K(t)i is an extended Kalman gain, $\\hat{n}_{(t)i}$ denotes a posterior estimate of n(t)i, Q(t)i is a collection of q(t)i invoked by node i at time slot t, P(t)i denotes the posterior covariance matrix of n(t)i. With (6-12), \u2200t \u2208 T and i \u2208 M, the temporal LFs N={N(1), N(2), ..., N(T)} is obtained.\nParticularly, the temporal LFs N={N(1), N(2), ..., N(T)} is obtained based on EKF to describe the intricate temporal patterns. Hence, in an ALS-based Q-procedure, we consider Q to be time-consistent, i.e., Q(1)=Q(2)=, ..., =Q(T), for easy convenient calculation. Under this assumption, the following objective function with Q is achieved by simplifying objective function (1):\n$\\epsilon(Y) = \\epsilon(N, Q) = \\sum_{t=1}^{T} \\sum_{Y_{(t)A}} (Y_{(t)ij} - <n_{(t)i},q_{j}>)^2 + \\lambda (||q_i||_2^2 + ||q_j||_2^2)$   (13)\nNaturally, the partial loss \u03b5(qj) with j \u2208 M is given as:\n$\\epsilon(q_j) = \\sum_{t=1}^{T} \\sum_{y_{(t)ij} \\in Y_{(t)A(j)}} (Y_{(t)ij} - <n_{(t)i},q_{j}>)^2 + \\frac{\\lambda}{2} (||q_j||_2^2)$    (14)\nwhere Y(t)A(j) is the Y(t) subset related to the node j. Note that we can get the following linear equation system by (14):\n$\\frac{\\delta \\epsilon(q_j)}{\\delta q_j} = \\sum_{\\forall i \\in Y_{(t)A(j)}} : 2\\lambda (y_{(t)ij} - <n_{(t)i},q_{j}>)(-n_{(t)i}) + 2\\lambda q_j$          \n$\\Rightarrow \\frac{\\delta \\epsilon(q_j)}{\\delta q_j} = part1+ part2+ part3 = 0$\nwhere\n$part1 = -2\\lambda \\sum_{\\hat{y}_{(i)}(j)} \\hat{N}_{(i)}(j)$    (16)\n$\\sum_{\\sum_{t=1}}$      \npart2 = 2\u03bb\u03b1;$\\\npart3 = 2|Y^\\hat{}(j)|qj$\n$q_j = \\frac{\\sum Y_{(i)}(j) N^((i)}(j)}{\\sum N^((i)}(j) N^((i)}(j)+ I}$          (17)\nwhere I denotes the identity matrix. By applying (17) to all qj as Vj\u2208 J, the learning rule of time-consistent LFs Q is achieved based on an ALS algorithm."}, {"title": "IV. EMPIRICAL STUDIES", "content": "Evaluation Protocol: This algorithm aims to estimate the missing edge weight estimation of a DWDG. Commonly, root mean square error (RMSE) and mean absolute error (MAE) are adopted to evaluate the estimation accuracy [59-62]. The programming is JAVA SE. Empirical studies are conducted on a Tablet with Intel(R) Xeon(R) Gold 5218 CPU @ 2.30GHz, and 512GB RAM.\nDatasets: We adopt three real DWDG datasets in our empirical analysis part, which are collected from a real terminal interaction pattern analysis system [35, 38]. The detailed information on datasets is recorded in Table I. For each dataset, we design three testing cases, as shown in Table II. The termination stipulation is, i.e., the error threshold is 10-5, the iteration threshold is 500, and the training process stops if any threshold is satisfied.\nModel Setting: The basic setting of this experiment is as follows:\n1) For the proposed EKLF, \u2018LeakyReLU\u2019 is used in the nonlinear state-transition function and nonlinear observation function;\n2) The dimension of the node LF is 20 for all the compared models;\n3) we apply a grid search for the compared models with the learning rate n=[0.0001, 0.01] and regularization coefficient \u03bb=[0.001, 0.1] to achieve their optimal results.\nWe commence our empirical investigations by comparing the proposed EKLF model with the state-of-the-art models in terms of estimation accuracy and computational efficiency. Tables III and IV show the comparison results on estimation errors and computational efficiency."}, {"title": "V. CONCLUSION", "content": "This study proposes an EKLF model that effortlessly integrates the principle of an EKF into its learning framework to represent a DWDG accurately from the model-driven perspective. In the future, we plan to adopt an EKF to build a novel dynamic graph neural network [67-75]."}]}