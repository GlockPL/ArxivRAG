{"title": "Developer Perspectives on Licensing and Copyright Issues Arising from Generative Al for Coding", "authors": ["TREVOR STALNAKER", "NATHAN WINTERSGILL", "OSCAR CHAPARRO", "LAURA A. HEYMANN", "MASSIMILIANO DI PENTA", "DANIEL M GERMAN", "DENYS POSHYVANYK"], "abstract": "Generative AI (GenAI) tools have already started to transform software development practices. Despite their utility in tasks such as writing code, the use of these tools raises important legal questions and potential risks, particularly those associated with copyright law. In the midst of this uncertainty, this paper presents a study jointly conducted by software engineering and legal researchers that surveyed 574 GitHub developers who use GenAI tools for development activities. The survey and follow-up interviews probed the developers' opinions on emerging legal issues as well as their perception of copyrightability, ownership of generated code, and related considerations. We also investigate potential developer misconceptions, the impact of GenAI on developers' work, and developers' awareness of licensing/copyright risks. Qualitative and quantitative analysis showed that developers' opinions on copyright issues vary broadly and that many developers are aware of the nuances these legal questions involve. We provide: (1) a survey of 574 developers on the licensing and copyright aspects of GenAI for coding, (2) a snapshot of practitioners' views at a time when GenAI and perceptions of it are rapidly evolving, and (3) an analysis of developers' views, yielding insights and recommendations that can inform future regulatory decisions in this evolving field.", "sections": [{"title": "1 INTRODUCTION", "content": "Generative AI (GenAI) tools have become widely adopted across many different domains, including software engineering (SE) [37, 72, 106, 108]. Several GenAI coding assistants, including GitHub's Copilot [45], Tabnine [119], Codeium [24], and Cody [25], as well as general purpose tools such as ChatGPT [100], Claude [11], and Gemini [42], have become readily accessible, either as IDE extensions or standalone applications, enabling developers to perform many coding tasks with little effort, including automated code completion, summarization, and debugging. A 2024 Stack Overflow survey reported that 76 percent of 65,000 participating developers were using or planning on using AI coding tools [88]; more than one million developers used Copilot [45] in its first year [129]. The popularity of these tools stems from the fact that they are easy to access and can generate diverse content with relatively little effort, thus helping users accomplish many tasks more efficiently [18, 79].\nAlongside these benefits, however, using GenAI tools can introduce various issues, including bias or discrimination [38], security threats [85], and compromise of private information [54]. GenAI can also give rise to legal risk related to intellectual property concerns, including copyright infringement [43]. Many legal questions regarding using GenAI tools remain unanswered, and any answers will likely vary among jurisdictions and across cases.\nAs of this writing, there are several pending lawsuits against high-profile providers of GenAI tools including OpenAI [13], StabilityAI [3], and Midjourney [10], as well as active consideration by the U.S. Copyright Office and other governmental entities around the world of the copyright issues raised by the use of GenAI [31, 96, 97]. These matters implicate several considerations, including the extent to which works associated with the use of GenAI, including prompts and models, are protected by copyright and, if so, who owns the rights to such works; whether the use of open source software and other protected works as training data results in license violations or otherwise constitutes copyright infringement; and whether output resulting from the use of GenAI that is similar to preexisting work constitutes copyright infringement.\nBecause GenAI tools are widely used, many software developers and organizations are likely engaging in activities that implicate potential legal risks despite not having the legal training or legal advice needed to evaluate these risks. Regulation of this space\u2013 whether by governmental entities or corporate entities\u2013 should, therefore, not proceed without an awareness of the preexisting views of stakeholder groups with a vested interest in these issues. In this paper, we aim to further the discourse surrounding GenAI in the SE space and inform future decisions by identifying developers' views on (1) using GenAI tools for software development tasks and (2) associated legal concerns, focusing specifically on copyright law.\nThis paper presents a study conducted by a joint team of SE and legal researchers that surveyed 574 software developers worldwide who use GenAI tools for coding tasks (particularly code gener-ation). Through an online survey and follow-up interviews, we probed the developers' opinions on potential emerging legal issues, the perception of what is copyrightable, ownership of generated code, and related considerations. We also sought to understand potential developer misconceptions, assess the impact of GenAI on their work, and evaluate their awareness of licensing/copyright risks. Using qualitative and quantitative methods to analyze survey responses, we found that developer opinions on copyright issues vary broadly, particularly on the topic of model output ownership, and that many developers are aware of the nuances and complications associated with answering these complex legal questions. We discuss the results of our study, interpret the findings under the background of U.S. law, and offer insights for future work.\nIn summary, we make the following contributions: (1) a comprehensive survey of 574 developers worldwide on the licensing and copyright aspects of GenAI for coding, (2) a snapshot of practitioners' views at a time when GenAI and perceptions of it are rapidly evolving, and (3) a rigorous analysis of developers' views on these topics, resulting in insights and recommendations that can help inform future policy decisions in this evolving field. We make available our survey, results, and other artifacts for transparency and validation in an online replication package [4]."}, {"title": "2 BACKGROUND", "content": "Unless it is in the public domain, any textual work is generally protected by copyright in the U.S. so long as it constitutes an original work of authorship and is fixed in a tangible medium of expression [6]. Similar provisions exist in the intellectual property legislation of other countries, including those in the European Union [27]. The owner of a copyright\u2014which may be an individual author, joint authors, or a corporate author as the owner of a work for hire\u2014has several exclusive rights under U.S. copyright law, including the rights to reproduce the work in copies, to create derivative works, and to distribute the work, which also includes the right to authorize others to engage in such activities [7].\nThe use of GenAI implicates these rights in several ways that are currently under consideration by the U.S. Copyright Office and the courts. The U.S. Copyright Office opined in February 2023\u2014reviewing an application for copyright registration\u2014that images generated by Midjourney were not the product of human authorship and were therefore ineligible for copyright registration [1]. The U.S. Copyright Office maintains this position [96]. There are also multiple pending cases alleging that the inclusion of copyrighted works in the training data of large language models (LLMs) and the generation of material that is substantially similar to those works constitutes infringement. For example, New York Times Co. v. Microsoft Corporation [121], filed in December 2023, alleges that ChatGPT uses the newspaper's content as training data, memorizes that data and then not only provides outputs that are nearly identical to that content but hallucinates content that is then incorrectly attributed to the Times. Another example is Doe v. GitHub [35], filed in November 2022, which alleges that Copilot violates the copyright licenses of the plaintiffs' open source software by using that code as training data and generating code that is a near-identical reproduction of the plaintiffs' code but without adhering to the terms of the associated licenses. Yet another lawsuit, filed by a group of authors, was brought against the companies Meta, Microsoft, and Bloomberg, alleging that the authors' works were used for training without their permission [20].\nThe resolution of these and similar cases depends on both technological and legal questions. On the technological side, liability may depend on whether authors can successfully show that their works are indeed included in a particular LLM's training data, as well as whether they can show that those works are copied for any length of time during the training process (or whether the training simply involves developing model parameters from the training data without reproducing it). On the legal side, liability may depend on whether and how the generated content is similar to any particular author's work. For example, generated content that is similar to previous works only with respect to the underlying concept or function is not infringing because the protections granted by U.S. copyright law for an original work of authorship do not extend to any \u201cidea, procedure, process, system, method of operation, concept, principle, or discovery, regardless of the form in which it is described, explained, illustrated, or embodied in such work\u201d [8].\nAdditionally, some legal scholars argue that the use of a work protected by copyright as part of a model's training data may be deemed a fair use under U.S. law [77], similar to how the use by Google of copyrighted material as the database for its Google Books search engine was held to be fair use by the U.S. Court of Appeals for the Second Circuit in 2015 [12]. Part of this consideration under U.S. law is likely to be whether the challenged use has a \u201ctransformative\u201d purpose or is considered to be an unlawful derivative work; the 2021 U.S. Supreme Court case of Google LLC v. Oracle America, Inc. [48] and the 2023 U.S. Supreme Court case of Andy Warhol Foundation for the Visual Arts, Inc. v. Goldsmith [2] offer contrasting examples.\nLegislation both within and outside the U.S. also has implications for GenAI and copyright. Various U.S. states have attempted to enact legislation to govern GenAI [21, 26]. In March 2024, the European Parliament approved the EU AI Act [31], which, among other things, requires the providers of general-purpose AI models to \u201cput in place a policy to comply with Union law on copyright and related rights, and in particular to identify and comply with, including through state-of-the-art technologies, a reservation of rights expressed pursuant to Article 4(3) of Directive (EU) 2019/790\u201d [30]. In 2023, an early announcement of the EU Global Principles for Artificial"}, {"title": "3 STUDY METHODOLOGY", "content": "The goal of this study is to investigate practitioners' perceptions about licensing and copyright issues related to the use of GenAI technology for software development. (Although we use the term \u201csoft-ware development\u201d throughout the paper, our study primarily focuses on the use of GenAI for code generation as the main task that can lead to copyright and licensing issues.) The primary quality focus is the mitigation of legal consequences due to copyright and licensing violations that arise when developing software with the assistance of GenAI. The context consists of 574 developers of open-source projects hosted on GitHub, whom we surveyed via an online survey and follow-up interviews. The study addresses the following research questions (RQs):\n\u2022 RQ1: How do developers use GenAI technologies to develop software? Studying how generative AI is used by developers allows us to put the answers provided by developers in response to the subsequent RQs in context.\n\u2022 RQ2: What are developers' perceptions regarding the licensing and copyright issues that arise from the use of GenAI tools? This RQ analyzes several dimensions of the investigated phenomenon, including developers' perceptions of potential emerging legal issues, copyrightable subject matter, and copyright ownership of generated code.\n\u2022 RQ3: What other legal concerns do developers anticipate as the use of GenAI increases? There are a plethora of other potential legal issues to consider as GenAI becomes more widely adopted, including data privacy, generation of malicious content, and tort liability. In this RQ, we analyze developers' perspectives on these topics.\nOur study, including the survey questionnaire, the participant identification procedure, and survey and interview protocols, was approved by our institution's ethical review board. An overview of our methodology can be seen in Figure 1."}, {"title": "3.1 Survey design", "content": "To design our survey, we followed general guidelines [52] as well as SE-specific best practices [67\u2013 71, 105]. The final questionnaire went through multiple iterations of review and improvements from six SE researchers and one law researcher. We carefully formulated the questions and ensured they were written clearly and concisely to avoid biasing respondents. We also conducted a pilot study with graduate students from our research lab who actively use GenAI tools. Based on their feedback, we further refined our questionnaire, improving questions that were ambiguous or hard to understand. The survey was structured into three core sections, as depicted in Figure 2:\n\u2022 The section on \u201cCurrent use of GenAI for coding\u201d (12 questions) asked about respondents' experience using GenAI tools for code generation, including the tools they used; the benefits and challenges of using such tools; the development tasks for which they used the tools; organizational policies of using such tools; and procedures to document tool usage, among other aspects.\n\u2022 The section on \u201cUnderstanding and Perception of Copyright Issues\u201d (14 questions) asked about developers' perceptions of copyright issues surrounding GenAI, including the use of their code in model training without permission; having models produce code similar to theirs; reusing without permission a prompt that they created; ownership and copyrightability of generated code; whether the use of source code in training models should require attribution and/or monetary compensation; and the effects of these concerns on developers' workflows.\n\u2022 The \"Demographics\" section (8 questions) asked about respondents' experience with SE and AI, whether they develop open source or proprietary software, their location, and their primary programming languages, among other questions."}, {"title": "3.2 Participant identification", "content": "We sought to learn from developers who used AI tools for code generation. To this end, and consistent with prior work [28, 40, 55, 61, 64, 65, 78\u201380, 93, 111, 117, 127], we used GitHub as a source to identify potential participants, following multiple steps."}, {"title": "3.3 Survey response collection and analysis", "content": "Survey responses were collected using Qualtrics [5]. The survey was kept open for six weeks starting on January 21, 2024. Survey invitations were sent out via email during that period.\nWe obtained a total of 772 survey responses, 580 of which were complete, as shown in Table 1. We removed five responses written in languages other than English, which would have required reliance on translation tools that might not be reliable for domain-specific tasks [56]. One additional response was removed for providing irrational answers to the open-ended questions. This left us with 574 complete and valid responses.\nSurvey responses to five open-ended questions were analyzed through a qualitative coding ap-proach [114]. Two SE researchers performed open-coding by independently assigning one or more codes to each response using a shared spreadsheet and codebook. Each annotator independently coded all 574 responses, adding new codes to the codebook as necessary. Once the initial coding was completed, the annotators met to settle disagreements and consolidate the set of codes. Our replication package [4] contains the final codes and definitions.\nWe did not base our analysis on inter-rater agreements because multiple codes could be assigned to each response, and no list of codes existed before the start of coding (i.e., our approach was fundamentally inductive). However, we carefully followed best open-coding practices [114], and we leveraged coders' discussions to ensure the results' reliability. All of the responses were coded in a single iteration by the two annotators. To mitigate agreement by chance, the labels assigned to each answer were reviewed by the annotators, including those without disagreement. We avoided defining \u201cumbrella\u201d codes by creating complete definitions for each code and sharing them between the annotators during review, as well as by assessing the appropriateness of codes during reconciliation of the annotators' results such that codes that were too similar could be merged"}, {"title": "3.4 Participant demographics and background", "content": "Respondents self-selected the nature of their development work from a list that included proprietary software development (331), open source (247), and academia (117). The total number of responses to this question is greater than the number of complete and valid responses (574) because respondents could select more than one option. Respondents came from six continents, as indicated in Figure 4, and 73 different countries, the top ten of which are shown in Table 3."}, {"title": "3.5 Follow-up Interviews", "content": "To supplement the survey results, we conducted follow-up interviews. These interviews were designed to establish additional context, obtain answers to questions that arose during the analysis and aggregation of survey responses, and perform a more in-depth exploration of developers' perceptions.\nAll survey participants were asked at the conclusion of the survey if they would be willing to be contacted for a follow-up interview. Those who consented by supplying their email address (382, 66.5%) made up our potential interview participant pool. Two authors then selected 22 potential interview candidates from this pool based on various criteria, including experience, geographic jurisdiction, and indicated views/perceptions on key legal issues, with the goal of interviewing participants representing a diversity of views. The full list of interview selection criteria can be found in our replication package [4]. Of the 22 candidates, seven responded to schedule an interview. The seven interviewees represented four continents (North America (3), Europe (2), South America (1), and Africa (1)) and a variety of backgrounds in software development, including working as a developer on proprietary software (6), contributing to OSS (4), and working in academia (1).\nThe duration of the interviews was between 20 and 30 minutes. The interviews were conducted using the Zoom video conferencing platform. Interview sessions were recorded and transcribed using OpenAI's Whisper large-v3 model [107, 123] to facilitate conversation analysis. A set of shared interview questions was iteratively derived through the collaboration of six SE researchers and one law researcher. This list of questions is available in our replication package [4]. Researchers were also free to ask follow-up or clarification questions during the interviews.\nEach interview was conducted jointly by two SE researchers, and the recording and transcript for each interview was independently reviewed by one interviewer to ensure the accuracy of the transcript and extract the relevant portions of each response, assigning topic labels to each one. These quotes and topic labels were hosted in a shared document accessible to both researchers, allowing the reuse of topic labels. Each researcher analyzed roughly half of the interviews. Af-terwards, the two researchers jointly reviewed the labels assigned to each response to verify the accuracy and completeness of the analysis, discussing and reaching a consensus on the framing and application of topic labels. A third researcher reviewed the quotes extracted for the paper, making sure none were miscategorized, misattributed, or taken out of context. For simplicity and clarity, when we refer to quotes from follow-up interviews, we use the notation RI and describe participants by their assigned survey IDs.\nInterview participants RI31, RI118, and RI190 have experience in proprietary software development. RI118 specifically works as a cyber security manager. RI516 has contributed to open-source projects. RI39, RI149, and RI431 work as closed-source software developers but have also contributed to open-source projects. RI431 also has some experience writing software in an academic environment."}, {"title": "4 RQ1 USE OF GENERATIVE AI TECHNOLOGIES FOR SOFTWARE DEVELOPMENT", "content": "RQ1 aimed to discover how developers are using GenAI technologies for developing software. Although the developers surveyed had a range of perceptions about AI and copyright issues, most seemed to share the belief that the use of GenAI is now a regular part of everyday development activities. As respondent R90 commented, \u201c[D]evs not using AI is like accountants not using Excel in the 80s.\u201d In a follow-up interview, RI149 commented, \u201cIf one of my engineers isn't using a code generation model, I'm going to fire him pretty soon. Because there's very little virtue in doing useless grunt work. [...] I actually expect it to be used on every part of the project. If it isn't, that's the exception. In fact, I want to know why [it wasn't used].\u201d In what follows, we present and discuss the findings for this RQ. A summary of key findings can be found in Table 5."}, {"title": "4.1 Uses, benefits, and challenges of GenAl", "content": "Before we can properly understand developers' thoughts and perspectives on copyright and other legal issues pertaining to GenAI, we must first explore the context in which they use these tools. In this section, we consider the usage scenarios identified by developers, the benefits they have derived from this use, and the challenges that they face."}, {"title": "4.1.1 GenAl usage in software development", "content": "Almost all respondents (554) stated that they were generally familiar with the use of GenAI to produce source code. Of these, the vast majority\u2013497 (89.7%)-indicated that they had in some capacity incorporated such tools into their development workflows. The remaining 57 (10.3%) offered several reasons for not regularly using GenAI, including legal risk (8), personal preference (8), the lack of significant use cases warranting its use (6), reluctance to send sensitive information to a remote server (6), constraints imposed by an employer (6), and limited trust in the tooling (5).\nAmong those who had a personal preference against using GenAI, some developers conveyed the sense that GenAI encourages monotony or lack of effort. This was somewhat surprising because, ideally, GenAI is used to automate repetitive and boring tasks, as previous work has indicated [112]. R188 stated \"I like to think for myself. [W]ithout [that], coding becomes boring and a lot of reading in-stead of reading and writing.\u201d R339 put it this way: \u201cIt's better to write code on my own than to review code generated by AI\u201d R276 reported similarly, \u201cI've tested incorporating GitHub's [C]opilot into my workflow and caught myself many times waiting for the autocompletion to kick in so I could just press 'Tab' and go from there. Soon I realized I was getting lazy and not thinking much, which I didn't enjoy.\u201d The full list of reasons put forward by developers can be found in our replication package [4]."}, {"title": "4.1.2 GenAl tools used by developers", "content": "A wide variety of GenAI tools, including open-source, open-weight, and proprietary models, were used by participants. In total, developers reported using 64 distinct, named GenAI tools, the top 20 of which can be seen in Table 4. Developers were encouraged to identify all the tools that they had used in their work. Of these, the top six (which were also provided in a list of choices, along with an \u201cOther\u201d option) were: GitHub Copilot (366), ChatGPT-4 (304), ChatGPT-3.5 (268), Bard (95), Claude (51), and Amazon CodeWhisperer (33). The next largest group (19) reported that they used open-source/open-weight models, with several such tools/models listed by multiple respondents, including Codellama (11), Mistral (9), Ollama (7), Llama2 (7), and Mixtral (6). Developers also used other proprietary models and services, including Codeium (16), Perplexity (12), Phind (10), and JetBrains AI (7), and six respondents indicated that they used custom-trained or in-house models for their development work. A full list of the tools developers reported using can be found in our replication package [4].\nOf the tools listed by respondents, 20 were designed to be integrated into an IDE. Many of these tools provide autocomplete suggestions for developers based on the context of surrounding code, but some also include Q/A chat functionality. Developers also reported using 18 distinct web-based tools. These tools, such as ChatGPT [100], Perplexity [104], and Hugging Face Chat [62], offer great convienence, but require the user to supply more context. Respondents also indicated using four different model infrastructures: Ollama [98], Oobabooga [99], llama.cpp [82], and Mozilla llamafile [59]. These infrastructures provide a streamlined means to run and train open-weight models locally. In total, 15 distinct open-weight models/model families were also identified by respondents. (We note that the prevalence of open-weight models and open-source tools in this space has likely increased since our initial survey with the subsequent release of models such as Llama3 [90] and the open-sourcing of XAI's Grok [126].) Some developers also noted the use of GenAI agents like gpt-engineer [50] and metagpt [58], which allow models to self-prompt with the goal of accomplishing more complex tasks. Lastly, four GenAI tools which were not strictly for software development, such as Figma [39] and GrammarlyGo [51], were mentioned.\nFigure 6 shows the reported tool usages across the categories previously discussed. Since devel-opers selected all the tools they had used for development tasks and many of those tools might fall into the same categories, we can't generalize to reach a conclusion about any developer preferences. We can also say little about the frequencies with which each tool type is used. That said, we see that there were 761 reported usages of web-based tools. There were only 464 reported usages of IDE-based tools, despite them constituting the largest number of distinct tools. This might suggest that developers were more likely to experiment with various different web-based tooling solutions, especially during the early days of GenAI for software development. There were 74 reported usages of open-weight or locally hosted models, but only 11 instances of reported corresponding model infrastructure. It could be that many developers using open-weight models neglected to mention the tooling they used to run them or that they relied on web-hosted solutions such as Hugging Face Chat."}, {"title": "4.1.3 Benefits derived from GenAl usage", "content": "Respondents who had used GenAI as part of their work-flow identified several benefits from its use. The greatest benefit mentioned by 288 developers (58%) was increased productivity, faster development, and efficiency. Other benefits included not having to spend time writing simple or boilerplate code (88), quick prototyping (42), debugging (37), faster, more accurate documentation (29), summarizing existing documentation as an alternative to read-ing it (28), providing inspiration (16), refactoring (14), use in writing test cases (5), domain logic support (4), and generating test data (4). A full list of the benefits identified by respondents can be found in our replication package [4].\nThirty respondents identified improvements in code quality and optimization over what human developers could achieve. RI118 noted, \u201cWhen you couple the lack of training [of the average developer] with generally one to three years' experience, and the fact is that GPT4 or many of these tools are actually better developers than they are. [...] I would almost feel better if [a code comment] said I wrote this and then I got a code review from GPT4.\u201d R74 stated that GenAI's ability to \u201cnotic[e] optimizations or cleaner ways of writing something like a custom function is quite useful.\u201d Some respondents, like R466, noted that the \u201c[generated] code [is] more reusable and better,", "following best [coding] practices.": "imilarly, developers related that GenAI could help them write software in unfamiliar lan-guages (28) and libraries (27). During a follow-up interview, RI190 described how they would", "otherwise [they] would probably quit because Liquid is incredibly painful.\u201d Using GenAI specifically in the capacity of porting or translating code was mentioned by six respondents. R286 found that GenAI \u201cwas helpful to migrate code from a middleware platform to Javascript based development.": 90, "benefit": "The syntax of various languages is [why it] can take hundreds of hours of use to establish [familiarity] in a new language, but AI significantly reduces the ramp-up time.\"\nAlong the same lines, several respondents noted that GenAI helped them to be better developers by enhancing their understanding of unfamiliar code. For example, nineteen respondents stated that GenAI provided \u201cassistance in [the] understanding of code snippets", "[GenAI] is also very good at providing semi-formal abstract explanations of the topics at hand and it provides consistent analogies which makes things very smooth to follow and comprehend.": "ut GenAI models are not limited to explaining source code or concepts. R238 noted that they could also be used for \u201ccommit message generation [and ex]planation of changes in commit (summarization).\u201d"}, {"title": "4.1.4 Challenges and shortcomings encountered in using GenAl", "content": "Respondents also identified several challenges arising from the use of GenAI, the most significant of which was the generation of unhelpful, unwanted, or broken code (128). Additional challenges included hallucinations (64) (such as recommending non-existent libraries or method calls), problems arising from outdated training data (53), issues arising from tools not having access to the project's wider context (52), which could be caused by insufficient context windows (40), and an inability to use GenAI to solve complex problems (43). R291 noted, \u201c[A]s issues get more complex, code generation has many gaps.\u201d R148 elaborates: \u201cAI can do simple code pretty well, it's not that capable [of generating] more complex code, it's incapable of generating well-architected code outside of extremely simple patterns.\u201d R33 provided an example: \u201cIn my experience, a simple Python/Django project that required some Form customizations was just not possible for any AI tool at my disposal. The logical part, the thinking, and the experience gained from years of coding real-world applications and systems design are [not comparable to] an AI code generation tool like GPT or Gemini.\u201d The full list of challenges reported by developers is included in our replication package [4].\nTwenty-five respondents also noted that while the ability to write good prompts is essential to effectively using GenAI tools, it can present a significant challenge. R303 reported that \u201cAI cannot complete the majority of tasks by itself, even simple ones[,] without time spent [by the developer on] prompt engineering.\u201d As R378 put it, \u201cModels need \u2018hand-holding' instructions [in order] to generate code and debug it.\u201d But when crafting these prompts, \u201c[q]uestions must be asked precisely,\u201d as R135 commented. R432 elaborated, \u201cVague prompts lead to vague answers, so you have to be specific with what you want.\u201d R72 summarized all these sentiments: \u201cThe outputs [of GenAI tools] are only as good as the inputs.\u201d\nWriting detailed and specific prompts isn't always an easy task, however. R18 said, \u201cIt is hard to communicate what I want or what I'm trying to describe to the model.\u201d R83 echoed this concern, stating, \u201cSometimes I am unable to describe what it is that [I] want[,] only to find out [that] there existed vocabulary that I should have used[, but] [t]his issue seems less frequent recently compared to when [I] first started using [GenAI] for coding.\u201d If done correctly, however, prompting was also seen as a way to overcome other limitations of the technology. R240 said, \u201cThere is a limit to the complexity that can be generated stand[ing] alone, but a human crafting intelligent prompts can still architect complex solutions using AI.\u201d"}, {"title": "4.2 Current practices for documentation and legal compliance when using an Al tool", "content": "4.2.1 Al-generated code review and compliance. Given the potential challenges associated with the use of GenAI, mitigation strategies relating to vulnerability and compliance analysis become increasingly important. In our follow-up interviews, we asked participants additional questions regarding their workflows. (Section 3.5 provides demographic information on participants, including development experience background.)\nAs RI118 noted, when code is not generated by the developer, review can be a challenge: \u201c[T]hat's another big part of it is just going through line by line, but it's like a more passive mindset, which I find a bit challenging compared to actually writing the code, so it can be harder to actually spot what's wrong with it. So the tests become really important.\u201d This is particularly true with respect to edge cases, \u201cbecause the tools are actually quite good, but unimaginative and have no domain, [they] have no context.\u201d\nSome developers reported an overall review but not focusing on vulnerabilities. RI190 said, \u201c[I don't do] any checks for licensing or vulnerabilities, but usually I read the code before I commit it and it's also reviewed in a pull request.\u201d RI39 offered a similar approach: \u201cI think it's mostly that I read the code and try and evaluate first of all how dangerous it is to run.\u201d\nOthers believed that AI itself could assist with reviewing AI-generated code. RI149 told us that they", "challenges": "I've thought about this [....] and [if] it's something where the answer is using machine learning to check whether or not the code that you've used appears, and would put you at legal risk, [...] you're relying on a large language model to check whether your large language model puts you at legal risk.\"\nSome developers, however, employed manual checks, particularly for license compliance. RI516 described a process that involved \u201csearch[ing] on GitHub because that's the largest repository, but [...] also check[ing] inputs in search engines, finding other places like GitLab or CodeBerg or Bitbucket or other repositories. And if the code is in a visible repository, it should show up.\u201d RI431 would \u201ctry to do my own research on websites such as Stack Overflow or GitHub.\u201d RI431 emphasized the manual nature of their compliance review: \u201cI don't really have any tool [to verify provenance], so that's why I'm doing this step of going to a website such as Stack Overflow and trying to see if the code which has been given to me by the model has already been proposed somewhere else on the Internet.\u201d But RI516 noted that these manual processes are limited, because \u201cif it's not open\""}, {"title": "4.2.2 Documentation of GenAl usage", "content": "One might expect that organizations that permit the use of GenAI for code development would ensure that developers were aware of processes to document its use. However, of the 445 developers indicating that their organization (partially) permitted the use of GenAI, only 83 (18.7%) indicated that they were aware of such a process, and of the remaining group, 312 (70.1%) said that there was no process and another 50 (11.2%) were unsure if a process existed. R325 offered one view of why a process was unnecessary: \u201cI did not use anything that cannot be googled anyway-but we never thought about having to document or question code we found through Google.\u201d Whether this means that many organizations have no process for documenting the use of GenAI or that at least some developers incorrectly believe that no documentation process exists at their organization, the result may be that developers do not have a full understanding of the possible legal risks they or their organizations face."}, {"title": "4.2.3 Review of the Terms of Service for Al Tools", "content": "The Terms of Service (ToS) for GenAI tools lay out how developers may interact with models by describing permissible and impermissible behaviors. These ToS may contain language that prevents the use of the service for any illegal activity, forbids the"}]}