{"title": "MIRANDA: MIMICKING THE LEARNING PROCESSES OF HUMAN DOCTORS TO ACHIEVE CAUSAL INFERENCE FOR MEDICATION RECOMMENDATION", "authors": ["Ziheng Wang", "Xinhe Li", "Haruki Momma", "Ryoichi Nagatomi"], "abstract": "To enhance therapeutic outcomes from a pharmacological perspective, we propose MiranDa, designed for medication recommendation, which is the first actionable model capable of providing the estimated length of stay in hospitals (ELOS) as counterfactual outcomes that guide clinical practice and model training. In detail, MiranDa emulates the educational trajectory of doctors through two gradient-scaling phases shifted by ELOS: an Evidence-based Training Phase that utilizes supervised learning and a Therapeutic Optimization Phase grounds in reinforcement learning within the gradient space, explores optimal medications by perturbations from ELOS. Evaluation of the Medical Information Mart for Intensive Care III dataset and IV dataset, showcased the superior results of our model across five metrics, particularly in reducing the ELOS. Surprisingly, our model provides structural attributes of medication combinations proved in hyperbolic space and advocated \"procedure-specific\" medication combinations. These findings posit that MiranDa enhanced medication efficacy. Notably, our paradigm can be applied to nearly all medical tasks and those with information to evaluate predicted outcomes. The source code of the MiranDa model is available at https://github.com/azusakou/MiranDa.", "sections": [{"title": "Introduction", "content": "\u201cGood prescribing\u201d is characterized as maximizing effectiveness, minimizing risks, minimizing costs, and respecting the patient\u2019s choices (1). Enhancing therapeutic effectiveness and minimizing risk is still a preeminent and difficult concern. Indeed, realizing this goal is presently challenging as medication-related errors persist. For instance, errors occur in 5.6% of non-intravenous doses and 35% of intravenous administrations (2). These medication-related errors often result in preventable adverse drug events (3, 4, 5, 6), including hospital admissions, extended hospital stays, increased treatment costs, and fatalities (7, 8, 9), with mortality rates per 100,000 population ranging from 0.1 to 7.88 (10, 11, 12, 13). The errors frequently correlate with the increasing number of hospitalists practicing immediately after residency, attributed to a deficiency in real-time clinical experience (14). Additionally, the rapid expansion of clinical literature, coupled with increasing specialization, makes it difficult for clinicians to understand medication efficacy comprehensively (15). Notably, it is not solely a challenge for neophytes; even seasoned clinicians struggle to determine appropriate prescriptions given lab results, patient vitals, comorbidities, potential drug interactions, and disease progression predictions. Given the complexities involved, achieving optimal prescribing practices is inherently challenging.\nEmployed in computer-assisted medical diagnostics, Artificial Intelligence (AI) has emerged as a promising avenue for addressing the challenges of medical aid. Central to this is the Computerized Physician Order Entry, which integrates e-prescribing into Electronic Health Records (EHRs) to bolster prescription safety through drug alerts, detailed medication histories, and the removal of handwritten prescriptions (16). Recent efforts have harnessed EHRs data to develop efficient artificial intelligence methodologies for medication recommendation (17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30). The principal aim of medication recommendation is to tailor a safe drug regimen for an individual patient, taking into account their specific health conditions. Key milestones include Doctor AI (17) in 2016. Other notable projects include MICRON (18) which emphasizes enhanced precision, and Medi-Care AI (19), renowned for bolstering resilience against adversarial training and model interpretability that is also observed in RETAIN (20). These approaches aim to provide AI-driven medication recommendations for integration into EHR.\nRecent research has pivoted toward enhanced medication combinations recommendations with drug-drug interaction (DDI) (21, 22, 23, 24, 25, 27, 26). Several models integrate clinical or molecular knowledge for effective DDI recom-mendations. LEAP (21) integrates clinical knowledge into its reinforcement reward to prevent undesirable medication combinations. GAMENet (22) employs a DDI knowledge graph to reduce severe side effects. SafeDrug (23) and CSEDrug (24) both utilize molecular structures to inform their DDI modeling. Specifically, CSEDrug enhances drug encoding and DDI regulation by considering both synergistic and antagonistic DDI, utilizing a graph-centric encoder and multi-faceted loss functions. On the other hand, some models focus on patient-specific data. PCCNet (25) addresses the temporal and spatial changes in medication orders and conditions by considering primary patient medications to mitigate DDIs. GRASP (27) leverages patient similarities for representation learning, making predictions based on related patient outcomes and tasks. Moreover, from a representation learning angle, SARMR (26) stands out by generating patient representation distributions and discerning safe combinations using adversarial regularization from raw records. These models integrate various clinical, molecular, and patient-specific data for medication combination recommendations, and improved metric outcomes are consistently achieved.\nHowever, in re-evaluating the notion of \u201cimproved metric outcomes\u201d, we are faced with two primary ambiguities. On one hand, the reliability and efficiency of the medical dataset are unclear. Modeling advancements often lead to improved performance, but overemphasizing better performance may inadvertently foster dependence on imperfect medical datasets, potentially limiting the therapeutic potential of medical interventions. Regrettably, one pivotal yet often overlooked issue is the distinction between natural and medical datasets. Labeling in natural datasets, such as the classification of animals or objects, tends to be straightforward. However, medical datasets, especially those comprising physician diagnoses and treatment details, often require a subjective judgment from medical experts. While label inaccuracies in non-medical datasets range between 0.15% and 10.12% (31), ensuring the accuracy and reliability of labels in medical datasets becomes an even more daunting task, given the complexities inherent to medical information. Alarmingly, over 40% of medical specialists commit prescribing errors, often due to their limited knowledge in the formulation of treatment plans (32, 33). Yet, reporting prescribing errors is infrequent, largely due to difficulties in recognition, compounded by fears of litigation and reputational damage (34). Once documented in databases, these errors can misdirect learning models when employing training strategies applicable to natural datasets.\nExisting models, despite their ongoing structural innovations, still predominantly rely on feature-to-label mapping. This means that the model primarily learns from the most frequently occurring medication combinations in the outcome data, presenting a foundational challenge in the current datasets. As mentioned earlier, medical datasets are believed to often encompass a range of treatments, from optimal to suboptimal and even incorrect ones. Given this, while a model might avoid some incorrect medication combinations, it may inadvertently downplay the most effective treatment"}, {"title": null, "content": "recommendations. Regrettably, the consequences of suboptimal medication combinations go beyond merely prolonging the optimal treatment time. Instances of expensive, prevalent, yet unnecessary medical procedures are not rare (35).\nAnother reason to re-evaluate the \u201cimproved metric outcomes\u201d is the disparity between the effects of prediction based on DDI and the actual expectations of clinicians. One source of disparity is attributable to the oversimplification of DDI. DDI may lead to a spectrum of unexpected side effects, from minor discomforts to severe toxicities. Meanwhile, even with identical side effects, individual reactions to medications can vary widely due to genetic influences (36, 37). Hence, from a clinical perspective, the mere reduction of DDI to attain what is termed a safer and more efficacious medication presents significant challenges. Another disparity arises during the training of models. It is crucial to underscore that DDI\u2019s optimization in predictive models arises during algorithmic training, independent of medications from human doctors. Overemphasizing DDI could boost certain metrics and DDI rates, but might inadvertently compromise actual medical outcomes by sidelining key considerations like patient preferences and comorbidities. Therefore, we believe a more medically meaningful metric must be proposed to guide the training process.\nRegardless of whether the emphasis of the development direction of medication recommendation is on variations in data quality or the specific optimization metrics selected, the terminal concern is the evaluation of the medication-related clinical decision quality. Importantly, the evaluation of quality matches the concept of counterfactual outcomes from causal inference (38) which examines how modifying causative factors affects an outcome variable (39). Existing models focus on several primary aspects: 1) Using encoders to map covariates to representation space, processing combinations, leveraging networks to predict outcomes, and minimizing the distributional distance between factual and counterfactual outcomes (40, 41); 2) The theoretical decomposition of covariate relationships (42); 3) Generating counterfactual output outcomes or achieving balanced representation space distributions (43, 44, 45); 4) Engaging in time series causal learning (46, 28, 29, 30, 47). However, in clinical practice, doctors often want to understand counterfactual outcomes: \u201cWhat will happen if another decision is made?\u201d. Despite the emphasis on elucidating causal relationships in most models, the \u201ccounterfactual outcomes\u201d for prediction remain obscured. Making these \u201ccounterfactual outcomes\u201d transparent could be advantageous, as it would not only directly guide parameter updates but also enable decision modification based on the tangible consequences of those decisions in the real world. Consequently, two pivotal challenges arise: 1) making counterfactual outcomes as a discernible metric and 2) establishing a causal inference-based paradigm that leverages this metric to explore possible outcomes.\nFirstly, this study links counterfactual outcomes and the efficacy of medications. We propose the estimated length of stay (ELOS) as a metric for clinical counterfactual outcomes. In contrast to the length of stay (LOS), an actual medical outcome, ELOS is determined by averaging the LOS of patients exhibiting similar clinical conditions (48). Specifically, inspired by approaches in drug repositioning (49) and patient similarity analysis (50), we calculate ELOS by identifying analogous patients and medication predictions, ensuring that it dynamically reflects the effectiveness of medication combinations based on real-world medical outcomes. Crucially, integrating this metric within our paradigm ensures seamless compatibility with other modules, such as DDI, present in the architecture.\nNext, we investigate achieving a causal inference-based training strategy. This involves two critical aspects: ensuring accurate and reasonable knowledge acquisition, and optimizing this knowledge gleaned through causal inference. Intriguingly, this dual process mirrors the evolution of a physician from a novice to an expert. Typically, a doctor undergoes two main stages of development: the acquisition of evidence-based knowledge in academic settings, followed by therapeutic optimization in clinical environments. The first phase focuses on mastering foundational medical knowledge and techniques. In contrast, the latter delves into diverse clinical outcomes that arise from specific decisions made for individual patients\u2014a process that aligns closely with causal inference. In light of this, we propose a general paradigm for determining the optimal medication combination by mimicking this process.\nWhile evidence-based training through supervised learning can reliably ensure accurate knowledge acquisition, the real challenge emerges during the therapeutic optimization stage. Notably, we discovered that Reinforcement Learning (RL) (51), a goal-driven learning approach that allows an agent to optimize rewards through interactions with its surroundings, offers the potential to navigate the medical feature space for improved patient outcomes. Indeed, RL might be the simplest way to achieve the causal inference by exploring the different estimated clinical outcomes, as prior work on time series tasks indicates that RL can reduce expected mortality rates (28, 29, 30). Thus, we tried to apply RL for therapeutic optimization and explore the gradient space with the guide from ELOS-based reward to make RL suitable for non-time series tasks. However, ELOS is synthesized from patient data and predictions, the retrieved data cannot directly influence gradient updates. Consequently, we use ELOS in a dual capacity: firstly, ELOS-informed perturbations guide the trajectory within the gradient space; secondly, when paired with these perturbations, ELOS serves as a metric for assessing and confirming exploration efficacy, thereby regulating the commencement and conclusion of this exploratory phase. Crucially, the effective assimilation of ELOS into deep learning necessitates the concurrent application of both these functionalities."}, {"title": null, "content": "In summary, our objective is to enhance the effectiveness of medication recommendations by addressing dataset constraints and refining optimization metrics. Drawing inspiration from the developmental trajectory of physicians transitioning from novices to experts, we present a causal inference-based paradigm, coupled with a model named MiranDa, which prioritizes the counterfactual outcomes ELOS as the optimization target and integrates supervised learning techniques with reinforcement learning. We hypothesize that 1) ELOS can serve as an effective counterfactual outcome metric for evaluating medication efficacy, and 2) our proposed model will showcase enhanced efficacy in steering medical outcomes by optimizing medication suggestions."}, {"title": "Method", "content": null}, {"title": "Study design and dataset", "content": "We utilized the Medical Information Mart for Intensive Care (MIMIC) III database (52, 53, 54) and IV database (55) to develop and assess our algorithm, primarily aiming to improve recommending medication combinations. The MIMIC-III and MIMIC-IV databases include data for 61,532 and 315,460 unique adult Intensive Care Unit (ICU) admissions, respectively, at Beth Israel Deaconess Medical Center, Boston, MA, USA, spanning 2001\u20132012 and 2008\u20132019. We ensured compliance with ethical considerations by securing all necessary permissions for data collection, processing, and dissemination from the appropriate research bodies. All data were stored in a secure environment, facilitating the processes of training, validation, and testing.\nTo ensure an unbiased evaluation and robust model development, we methodically partitioned the dataset based on individual patients, ensuring that data from each patient was exclusive to a single subset. To validate our concept, we employed the MIMIC-III database, allocating 70% of the data for training, 15% for validation, and 15% for testing, repeated 30 times. For the MIMIC-IV database, we focused more on the trained model by allocating 45% of the data for training, 5% for validation, and the remaining 50% for testing. The development of the algorithm mapping correlations did not involve any data from the testing subsets, which was specifically utilized to evaluate the model performance on unseen data."}, {"title": "Data collection and preprocessing", "content": "The admission of each patient to the ICU was assigned a unique ICU stay ID, enabling tracking of distinct ICU episodes. Our inclusion criteria encompassed patients who were aged over 18 years at admission; underwent a continuous regimen of treatment and medication within the study period; and were discharged with an \u201calive\u201d status. These criteria resulted in the documentation of 35,926 events from 6,154 unique patients in the MIMIC III dataset, and 224,670 events from 119,315 unique patients in the MIMIC IV dataset. Moreover, recognizing the existence of both prevalent and rare cases, we chose not to exclude outliers, even if they could potentially affect performance metrics. Such an inclusive approach offers a more genuine reflection of the patient population.\nData from each hospitalization incorporated a comprehensive history of prior procedures and conditions, as well as patient demographics and clinical characteristics. A \u201cLOS\u201d was defined as the period from the onset of a documented hospitalization to the discharge from the ICU. LOS values are normalized to 1.0, which equals 24 hours. The utilization of daily intervals was motivated by the requirement to improve the robustness of the dataset, thus reducing the influence of variables extraneous to clinical decision-making processes For training our model, we used four input features: diagnoses, procedures, lab events, and patient demographics. The model\u2019s prediction target was medication combinations. Medications were coded using the 11-digit version of the National Drug Code. Procedures and diagnoses were categorized using the International Classification of Diseases, Ninth Revision (ICD-9) coding system. Here, \u201cprocedures\u201d refer to medical actions undertaken in inpatient hospital settings, and \u201clab events\u201d denote laboratory test outcomes, such as hematology, chemistry, and microbiology results (52). We selected these features due to their clinical relevance and their capability to represent a patient\u2019s status accurately. The terminology employed is delineated in Supplementary Terms 1-4."}, {"title": "Model design", "content": "We introduce MiranDa, a model named for its design principle of Mimicking the learning processes of human Doctors to achieve causal inference for medication recommendation. This model simulates the evolution of clinicians from novices to experts, as shown in Fig. 1. Our approach combines two training phases: the Evidence-based Training Phase (supervised learning) and the Therapeutic Optimization Phase (reinforcement learning in gradient space) for causal inference. The transition between these phases is driven by a clinical outcome-oriented reward ELOS, retrieved from clinical conditions and model predictions."}, {"title": "Evidence-based Training Phase", "content": "In the Evidence-based Training Phase, we employ supervised training to establish a mapping relationship between clinical conditions (input features) and medication combinations (predictions). The predictions from this phase serve as an effective starting point, which helps to circumvent the instability introduced by random initialization for the subsequent Therapeutic Optimization Phase.\nHere, we utilize transformers (56) for the predictor \\(f(\theta)\\), where \\(\\theta\\) represents the model parameters, the architecture of the predictor is shown in Fig. 2. A patient state \\(s_i\\), comprising diagnosis, procedures, lab events, and fundamental demographic information which includes age, gender, race, and the patient\u2019s sequential number of hospitalizations, the prediction is the medication combination \\(a_i\\), through \\(a_i = f(s_i; \\theta)\\). The format of inputs is treated as a token. By utilizing the spatial positioning of these individual tokens, the model is facilitated in effectively understanding and processing the associated information. Following the positioning phase, the tokenized features are fed into a transformer layer, generating four distinct vectors representing unique token features in an encoded format. These vectors are concatenated to establish a unified representation, which compactly encapsulates information from all individual vectors. A subsequent fully connected layer reshapes this vector to suit the final output, wherein a softmax function yields a multi-label medication recommendation. Building upon the aforementioned process, the predictor provides a set of medication combinations, denoted as \\(a\\), where each prediction \\(a_i\\) belongs to \\(\\{0, 1\\}^n\\). Here, the value n signifies the total number of medication classes investigated in our study, thereby forming a n-dimensional discrete action space."}, {"title": "Therapeutic Optimization Phase", "content": "The Therapeutic Optimization Phase involves mimicking the doctor using an agent to explore optimal clinical outcomes. This incorporates the principles of RL for causal inference. In this phase, the predictor \\(f(\\theta)\\) serves as the agent with"}, {"title": null, "content": "the patient state \\(s_i\\), diagnosis, procedures, lab events, and patient demographics acting as a fixed state. Actions \\(a_i\\) from the Evidence-based Training Phase are used as initial medication combinations. Based on \\(a_i\\), the auxiliary action space \\(\\Beta_i\\) is retrieved from similar patients to calculate the reward \\(\\hat{H}_\\Beta\\) from ELOS, as shown in fig 3."}, {"title": "Defining the action space", "content": "Here, we utilized two retrieve strategies \\(retrieve_p\\) and \\(retrieve_d\\) to get the action \\(\\Beta\\) based on action \\(a\\). The intrinsic complexities of clinical conditions pose a challenge (57), as even patients sharing identical diagnoses may exhibit substantial variations in treatments, procedures, and hospitalization duration. To circumvent these intricacies, spurred by concepts such as drug repositioning (49) and patient similarity analysis (50), identifying patient trajectories akin to a reference patient aids in predicting the clinical outcomes. In detail, one is \\(retrieve_p\\), which constrains the matched patients with the same procedures and age in a limited range, and the other is \\(retrieve_d\\), which constrains the patients with similar conditions and medications.\nFirstly, \\(retrieve_p\\) retrieves similar patients with the same procedures to expand action space \\(a_i\\). In the ICU, on one hand, the patients are particularly vulnerable and frequently require urgent, high-risk therapeutic procedures, which play a crucial and often life-saving role in the management of critical patients (58). On the other hand, patients undergoing identical procedures often present with analogous health conditions (59). Clinical congruencies are underscored by post-procedure care and monitoring, often meaning that patients face corresponding risks, potential complications, and projected outcomes (60, 61). Consequently, we use \\(retrieve_p\\) to retrieve the auxiliary action space set \\(\\Beta\\) based on the procedures and utilize a further constraint as the age range within n years of patient \\(p_i\\) with action \\(a\\) from the entire dataset D. We can mathematically express retrieval using equation:\n\\(\\Beta_{p_i} = \\{p' \\in D | C(p_i, p') = 1\\},\\)\nhere, each \\(p'\\) is a patient in D. The function \\(C(p_i, p')\\) serves as a binary indicator, returning one if patient \\(p_i\\) and patient \\(p'\\) share the exact medical procedures and their ages fall within a specific year difference, and 0 otherwise.\nThen, \\(retrieve_d\\) is utilized to constrain the auxiliary action space \\(\\Beta_{p_i}\\) drug-wise, further ensuring that the ELOS in the next step are plausible through drug similarity and procedures sameness. This function employs the set of vectors \\(\\Beta_{p_i} = b_1, b_2, ..., b_n\\), to generate a set \\(\\beta_i\\) with a cardinality of |\\(\\Beta\\)| = 50 that maximizes the cosine similarity between vector \\(a_i\\) and each vector in the set. This can be formalized in the equation:\n\\(\\beta_i = Top_K \\{b \\in \\Beta_{p_i} | \\sigma(a_i, b) > \\phi, <\\},\\)\nhere the top K vectors with the highest cosine similarity with a and greater than a threshold \\(\\phi\\) are selected. We aim to maximize \\(\\sigma(a_i, b)\\) for each \\(b \\in \\Beta\\), given \\(\\sigma(a_i, b) > \\phi\\). A partial order < is defined on \\(\\Beta\\) such that for any \\(b_i, b_j \\in \\Beta\\), we have \\(b_i \\leq b_j\\) if and only if \\(\\sigma(a_i, b_i) \\leq \\sigma(a_i, b_j)\\). This detailed mathematical construction provides a clear understanding of the dynamic evolution of the action spaces in our agent."}, {"title": "Counterfactual outcomes and reward", "content": "The reward for each batch of patients, represented by \\(\\hat{H}_\\Beta\\), quantifies the efficacy of the actions. Accordingly, \\(\\hat{H}_\\Beta\\) computed as:\n\\(\\hat{H}_\\Beta = \\frac{1}{N} \\sum_{i=1}^{N} R(a_i, \\beta_i),\\)\nhere, this function is based on the mean LOS from each retrieved patient, denoted as R. for each discrete medication combination \\(a_i\\) and its expand drugs set \\(\\Beta_i\\), we calculate the real LOS, H | \\(a_i\\) and counterfactual outcomes as ELOS, \\(\\hat{H}_\\Beta\\), contingent on the action. This difference value is treated as the reward \\(R(a_i, \\beta_i)\\) for the action \\(a_i\\) and \\(\\Beta_i\\). Mathematically, this can be defined as:\n\\(R (a_i, \\beta_i) = H |_{a_i} - \\hat{H} |_{\\beta_i}\\),\\)\nwhere \\(R (a_i, \\beta_i)\\) signifies that shorter hospitalization durations are associated with better medical outcomes. Thus, different from traditional RL, the objective of our agent is to minimize \\(\\hat{H}_\\Beta\\), thereby transforming a complex problem of patient recovery into an optimization challenge. This reward-oriented framework provides a concrete and practical target for optimizing our RL agent in the context of pharmaceutical recommendations."}, {"title": "Training and optimization", "content": "We introduce a novel training paradigm that starts from the supervised learning based-start point, we utilize \\(\\hat{H}_\\Beta\\) as the indicator to transition to the Therapeutic Optimization Phase and explore the gradient space with the perturbation generated from the reward (rather than the reward itself). The agent employs the minimum ELOS from the retrieved patients - an exploration space reward as the target, equipping it to explore potential medication combinations under multiple constraints more robustly."}, {"title": "Evidence-based Training Phase loss", "content": "The model parameters first need to be updated with supervised learning. The feed-forward propagation process is represented as a function \\(f(s; \\theta)\\), and the error between the model\u2019s prediction and the true output is quantified by the binary cross-entropy loss function \\(I_{BCE}(Y, f(X; \\theta))\\), where y is the true output. Consequently, the Evidence-based Training Phase loss \\(L(\\theta)\\) is the average of this binary cross-entropy loss overall training samples. With the reward \\(\\hat{H}_\\Beta\\), the loss express as:\n\\(L(\\theta) = C(\\hat{H}_\\Beta - \\delta) \\cdot \\lambda I_{BCE} + [1 - C(\\hat{H}_\\Beta - \\delta)] \\cdot I_{BCE},\\)\nwhere \\(\\delta\\) is an item that determines whether enters the subsequent phase. The binary function C is 1 if \\(\\hat{H}_\\Beta > \\delta\\) and 0 otherwise. Consequently, when \\(\\hat{H}_\\Beta \\geq \\delta\\), \\(L(\\theta)\\) becomes \\(\\lambda I_{BCE}\\), progressing to the Therapeutic Optimization Phase. If \\(\\hat{H}_\\Beta < \\delta\\), \\(L(\\theta)\\) remains \\(I_{BCE}\\), bypassing this phase. A lower value of \\(\\lambda\\) thus facilitates more exploratory steps in the Therapeutic Optimization Phase."}, {"title": "Therapeutic Optimization Phase perturbation", "content": "The underlying foundation of our algorithm centers around a tailored Therapeutic Optimization Phase perturbation term, \\(P_{RL}(\\theta)\\), which aims to enhance the exploration space of parameters during updates by applying the derivative of the reward \\(\\hat{H}_\\Beta\\). Here, our main idea was inspired by Stochastic Gradient Langevin Dynamics (SGLD) (63), consequently, our strategy is to replace Gaussian noise with a scaling perturbation term P. The initial gradient update with perturbation can be expressed as:\n\\(\\theta_{t+1} = \\theta - \\nabla L(\\theta_t) + \\nabla P_{RL},\\)\nwhere \\(\\theta_t\\) represents the parameters in the t batch, \\(\\nabla L(\\theta_t)\\) is the gradient of the loss function L with respect to \\(\\theta_t\\). The perturbation, \\(P_{RL} (\\theta)\\) is structured with several components designed to promote stability and efficacy in learning. This perturbation incorporates a logarithmic function that engulfs the average reward per batch, weighted by reinforcement confidence, \\(\\gamma\\), and subsequently divided by ELOS, denotes by \\(\\sum_{i=1}^{N} [H |_{\\beta_i}]\\). This logarithmic feature prevents the loss function from increasing indefinitely, thereby constraining the perceived value of escalating rewards. The expression of the perturbation term is as follows:\n\\(P_{RL}(\\theta) = log \\bigg(1 + \\frac{\\gamma}{\\sum_{i=1}^{N} [H |_{\\beta_i}]}\\hat{H}_\\Beta \\bigg).\\)\nSince the update of the perturbation term has a break in the gradient update process for the agent parameters, this better medical outcome is achieved by perturbing the gradient direction. The kernel of the RL perturbation function is \\(\\hat{H}_\\Beta\\) divided by ELOS, which aims to maintain stability in the scaling of perturbation medication-wise. This is, essentially, a scaling of the magnitude of the update, i.e., the actual medical significance of \\(\\hat{H}_\\Beta\\) as measured by the elos. For example, for the same \\(\\hat{H}_\\Beta\\), a smaller ELOS encourages more exploration. Meanwhile, with the reinforcement confidence, \\(\\gamma\\), acts as a weighting factor that adjusts the influence of the expected reward on the loss. Moreover, the convex function log(x) is for x > 0, enabling the application of gradient descent. Therefore, the logarithmic transformation guarantees that the derivative of the perturbation function, \\(d P_{RL} (\\theta)/d\\theta\\), remains well-conditioned, fostering a smooth optimization process and precludes abrupt changes in parameter updates during backpropagation."}, {"title": "Perturbed objective function", "content": "Crucially, a perturbed objective function, denoted as \\(L'(\\theta)\\), for updating the parameters in the Therapeutic Optimization Phase, that harmoniously integrates the loss \\(L(\\theta)\\) and the perturbation function \\(P_{RL}(\\theta)\\). The blending of these loss functions is guided by a hyperparameter \\(\\epsilon\\), which further ensures the possibility of more steps to explore the optimal medication. This amalgamation is expressed in the form of a convex combination, defined as follows:\n\\(L'(\\theta) = \\epsilon (1 - \\lambda)L(\\theta) + (1 - \\epsilon)P_{RL}(\\theta),\\)\nwhere \\(\\epsilon\\) also acts as a balancing factor between the Evidence-based Training Phase loss and the Therapeutic Optimization Phase perturbation, allowing for a smooth transition between the two function types. Crucially, the L will update for each step in the Therapeutic Optimization Phase perturbation. Our perturbed objective function, \\(L'(\\theta)\\), thus encapsulates the strengths of both conventional mapping relations (represented by the standard loss) and the space that may have optimal medical outcomes (captured by the RL perturbation). This balance is crucial for the agent deployed in dynamic environments such as ICU settings, where actions will not harm the parameters even if they diverge from general mapping relations. Since even if the ELOS is not better, the parameters can still be updated to the directions with a lower loss, and the \u201cmission\u201d of better medical outcomes could be achieved in the further batch. For a comprehensive step-by-step procedure of our MiranDa approach, refer to Algorithm 1."}, {"title": "Evaluation metrics", "content": "We evaluate our model using a diverse set of metrics to ensure a comprehensive and robust assessment. The ELOS serves as a critical measure of the model\u2019s capability in suggesting medication combinations. It indicates not just the success of a patient\u2019s recovery, but also the counterfactual outcomes. ELOS thus directly measures model performance with the clinical aim of minimizing ICU durations to improve patient well-being. We further incorporate the Receiver Operating Characteristic Area Under Curve (ROC AUC) to understand the model\u2019s accuracy across different thresholds (64). The Precision-Recall AUC (PR AUC) evaluates the precision-recall trade-off, which is especially important for imbalanced datasets (65). Together, ROC AUC and PR AUC offer a comprehensive perspective on predictive accuracy. The F1 score balances precision and recall (66), and we will also report separate Precision and Recall scores for deeper insight (67). The Jaccard Index measures the similarity between predicted and actual medication combinations, indicating the model\u2019s recommendation accuracy (68). Additionally, we monitor the DDI rate (69). Through these metrics, we provide a thorough evaluation of the model, showcasing its efficacy and safety."}, {"title": "Data interpretation", "content": "We interpreted the intrinsic correlations among various medication combinations. These combinations were derived from three primary sources: our predictive model, baseline and human doctors. We aimed to elucidate the relationships between these medication combinations and several other variables, including patient diagnosis, procedures, and demographic information. We achieved this using a three-fold methodology: structuring our data in hyperbolic space, clustering the data into discernible categories, and interpreting the clusters."}, {"title": "Spatial positioning in Hyperbolic Geometry", "content": "Hyperbolic Geometry, a non-Euclidean geometry that excels at capturing and representing data with inherent hierarchical structures (70, 71), offers a unique lens to discern hierarchies in medication combinations. Transitioning high-dimensional data to this geometry preserves the inherent relationships and distances, a challenge often encountered in traditional Euclidean representations (72, 73). Therefore, we utilized the Hyperbolic model and its representation in the Poincar\u00e9 Disk Model in this study, where each point symbolizes a unique medication combination. The spatial positioning in this space reflects the similarities and disparities of the underlying policies (74), instrumental for analyses that capture the genuine relationships within the dataset."}, {"title": "Spatial positioning in Hyperboloid Model", "content": "To achieve spatial positioning in hyperbolic space, we employed the Uniform Manifold Approximation and Projection (UMAP) algorithm, renowned for its effectiveness in capturing hierarchical and topological data properties (75). UMAP constructs a fuzzy simplicial set representation to approximate the manifold structure of a. By identifying neighbors of each point in a within the high-dimensional space, a weighted graph, G, is constructed. The weights of G indicate the likelihood of data points being neighbors and are described by:\n\\(G = \\{(A_i, a_j)|A_i, a_j \\in a \\land d(a_i, a_j) < \\epsilon\\},\\)\nhere, \\(d(a_i, a_j)\\) represents a distance metric attentive to local structures, while \\(\\epsilon\\) is a threshold for proximity. The objective is to reduce the cross-entropy between G and its hyperbolic counterpart, ensuring the preservation of both local and global structures. Given the spatial positioning in \\(\\mathbb{H}^3\\) as HS, the optimization is:\n\\(HS^* = argmin_{HS}CE(G, HS),\\)\nwhere HS* represents the optimal hyperbolic spatial positioning that minimizes the divergence CE between G and HS."}, {"title": "Transition from Hyperboloid Model to Poincar\u00e9 Disk Model", "content": "To transition data from the Hyperboloid Model to the Poincar\u00e9 Disk Model, we employed stereographic projection (76). The Poincar\u00e9 Disk Model represents hyperbolic geometry using points within a disk, with geodesics portrayed as circle segments orthogonal to the disk boundary or as its diameters (77). This representation is advantageous for visualizing intricate datasets in 2D while retaining data nuances.\nA point, \\(h_i\\), in the hyperboloid model is mapped to its counterpart, \\(p_i\\), in the Poincar\u00e9 disk model. The transformation is expressed by \\(p_i = \\frac{h_i}{1+h_3}\\), where i = 1,2. Each coordinate of \\(h_i\\) in \\(\\mathbb{H}^3\\) is divided by the sum of one and its third coordinate. After this projection, data is visualized as a scatter plot within the boundary of the Poincar\u00e9 disk, which acts as the line at infinity. In this representation, the proximity between data points underscores their similarity, revealing the manifold structure of the original data."}, {"title": "Data segmentation", "content": "For data segmentation, we utilized the K-means clustering algorithm (78) on the hyperbolic embeddings of medications. This algorithm partitions data into \u201cK\u201d non-overlapping clusters based on inherent data similarities. Applying K-means to the Poincar\u00e9 Disk Model ensures an accurate representation of the true data groupings, benefiting from the preserved hierarchical relationships. This method enhances the granularity of subsequent theme extraction.\nTo determine the optimal number of clusters, we calculated the Bayesian Information Criterion (BIC) for potential cluster counts ranging from 10 to 30. Based on the BIC values, we selected ten as the optimal number of clusters, guided by the inherent patterns within our dataset. After forming the clusters, we represented our data in both the hyperboloid and Poincar\u00e9 disk models. For clearer visualization, each model assigns a unique color to each cluster, providing structure to our data representation."}, {"title": "Theme extraction", "content": "After segmentation", "metrics": "term frequency (TF) and inverse document frequency (IDF). The TF metric represents the frequency of a word within a particular document, while the IDF metric"}]}