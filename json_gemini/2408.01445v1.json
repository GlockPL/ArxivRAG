{"title": "MIRANDA: MIMICKING THE LEARNING PROCESSES OF HUMAN DOCTORS TO ACHIEVE CAUSAL INFERENCE FOR MEDICATION RECOMMENDATION", "authors": ["Ziheng Wang", "Xinhe Li", "Haruki Momma", "Ryoichi Nagatomi"], "abstract": "To enhance therapeutic outcomes from a pharmacological perspective, we propose MiranDa, de-\nsigned for medication recommendation, which is the first actionable model capable of providing\nthe estimated length of stay in hospitals (ELOS) as counterfactual outcomes that guide clinical\npractice and model training. In detail, MiranDa emulates the educational trajectory of doctors\nthrough two gradient-scaling phases shifted by ELOS: an Evidence-based Training Phase that utilizes\nsupervised learning and a Therapeutic Optimization Phase grounds in reinforcement learning within\nthe gradient space, explores optimal medications by perturbations from ELOS. Evaluation of the\nMedical Information Mart for Intensive Care III dataset and IV dataset, showcased the superior\nresults of our model across five metrics, particularly in reducing the ELOS. Surprisingly, our model\nprovides structural attributes of medication combinations proved in hyperbolic space and advocated\n\"procedure-specific\" medication combinations. These findings posit that MiranDa enhanced med-\nication efficacy. Notably, our paradigm can be applied to nearly all medical tasks and those with\ninformation to evaluate predicted outcomes. The source code of the MiranDa model is available at\nhttps://github.com/azusakou/MiranDa.", "sections": [{"title": "Introduction", "content": "\"Good prescribing\" is characterized as maximizing effectiveness, minimizing risks, minimizing costs, and respecting\nthe patient's choices (1). Enhancing therapeutic effectiveness and minimizing risk is still a preeminent and difficult\nconcern. Indeed, realizing this goal is presently challenging as medication-related errors persist. For instance, errors\noccur in 5.6% of non-intravenous doses and 35% of intravenous administrations (2). These medication-related errors\noften result in preventable adverse drug events (3, 4, 5, 6), including hospital admissions, extended hospital stays,\nincreased treatment costs, and fatalities (7, 8, 9), with mortality rates per 100,000 population ranging from 0.1 to\n7.88 (10, 11, 12, 13). The errors frequently correlate with the increasing number of hospitalists practicing immediately\nafter residency, attributed to a deficiency in real-time clinical experience (14). Additionally, the rapid expansion of\nclinical literature, coupled with increasing specialization, makes it difficult for clinicians to understand medication\nefficacy comprehensively (15). Notably, it is not solely a challenge for neophytes; even seasoned clinicians struggle\nto determine appropriate prescriptions given lab results, patient vitals, comorbidities, potential drug interactions, and\ndisease progression predictions. Given the complexities involved, achieving optimal prescribing practices is inherently\nchallenging.\nEmployed in computer-assisted medical diagnostics, Artificial Intelligence (AI) has emerged as a promising avenue for\naddressing the challenges of medical aid. Central to this is the Computerized Physician Order Entry, which integrates e-\nprescribing into Electronic Health Records (EHRs) to bolster prescription safety through drug alerts, detailed medication\nhistories, and the removal of handwritten prescriptions (16). Recent efforts have harnessed EHRs data to develop efficient\nartificial intelligence methodologies for medication recommendation (17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30).\nThe principal aim of medication recommendation is to tailor a safe drug regimen for an individual patient, taking into\naccount their specific health conditions. Key milestones include Doctor AI (17) in 2016. Other notable projects include\nMICRON (18) which emphasizes enhanced precision, and Medi-Care AI (19), renowned for bolstering resilience\nagainst adversarial training and model interpretability that is also observed in RETAIN (20). These approaches aim to\nprovide AI-driven medication recommendations for integration into EHR.\nRecent research has pivoted toward enhanced medication combinations recommendations with drug-drug interaction\n(DDI) (21, 22, 23, 24, 25, 27, 26). Several models integrate clinical or molecular knowledge for effective DDI recom-\nmendations. LEAP (21) integrates clinical knowledge into its reinforcement reward to prevent undesirable medication\ncombinations. GAMENet (22) employs a DDI knowledge graph to reduce severe side effects. SafeDrug (23) and\nCSEDrug (24) both utilize molecular structures to inform their DDI modeling. Specifically, CSEDrug enhances drug\nencoding and DDI regulation by considering both synergistic and antagonistic DDI, utilizing a graph-centric encoder\nand multi-faceted loss functions. On the other hand, some models focus on patient-specific data. PCCNet (25) addresses\nthe temporal and spatial changes in medication orders and conditions by considering primary patient medications\nto mitigate DDIs. GRASP (27) leverages patient similarities for representation learning, making predictions based\non related patient outcomes and tasks. Moreover, from a representation learning angle, SARMR (26) stands out by\ngenerating patient representation distributions and discerning safe combinations using adversarial regularization from\nraw records. These models integrate various clinical, molecular, and patient-specific data for medication combination\nrecommendations, and improved metric outcomes are consistently achieved.\nHowever, in re-evaluating the notion of \"improved metric outcomes\", we are faced with two primary ambiguities.\nOn one hand, the reliability and efficiency of the medical dataset are unclear. Modeling advancements often lead to\nimproved performance, but overemphasizing better performance may inadvertently foster dependence on imperfect\nmedical datasets, potentially limiting the therapeutic potential of medical interventions. Regrettably, one pivotal yet\noften overlooked issue is the distinction between natural and medical datasets. Labeling in natural datasets, such as the\nclassification of animals or objects, tends to be straightforward. However, medical datasets, especially those comprising\nphysician diagnoses and treatment details, often require a subjective judgment from medical experts. While label\ninaccuracies in non-medical datasets range between 0.15% and 10.12% (31), ensuring the accuracy and reliability of\nlabels in medical datasets becomes an even more daunting task, given the complexities inherent to medical information.\nAlarmingly, over 40% of medical specialists commit prescribing errors, often due to their limited knowledge in the\nformulation of treatment plans (32, 33). Yet, reporting prescribing errors is infrequent, largely due to difficulties in\nrecognition, compounded by fears of litigation and reputational damage (34). Once documented in databases, these\nerrors can misdirect learning models when employing training strategies applicable to natural datasets.\nExisting models, despite their ongoing structural innovations, still predominantly rely on feature-to-label mapping. This\nmeans that the model primarily learns from the most frequently occurring medication combinations in the outcome\ndata, presenting a foundational challenge in the current datasets. As mentioned earlier, medical datasets are believed\nto often encompass a range of treatments, from optimal to suboptimal and even incorrect ones. Given this, while a\nmodel might avoid some incorrect medication combinations, it may inadvertently downplay the most effective treatment"}, {"title": null, "content": "recommendations. Regrettably, the consequences of suboptimal medication combinations go beyond merely prolonging\nthe optimal treatment time. Instances of expensive, prevalent, yet unnecessary medical procedures are not rare (35).\nAnother reason to re-evaluate the \"improved metric outcomes\" is the disparity between the effects of prediction based\non DDI and the actual expectations of clinicians. One source of disparity is attributable to the oversimplification of DDI.\nDDI may lead to a spectrum of unexpected side effects, from minor discomforts to severe toxicities. Meanwhile, even\nwith identical side effects, individual reactions to medications can vary widely due to genetic influences (36, 37). Hence,\nfrom a clinical perspective, the mere reduction of DDI to attain what is termed a safer and more efficacious medication\npresents significant challenges. Another disparity arises during the training of models. It is crucial to underscore that\nDDI's optimization in predictive models arises during algorithmic training, independent of medications from human\ndoctors. Overemphasizing DDI could boost certain metrics and DDI rates, but might inadvertently compromise actual\nmedical outcomes by sidelining key considerations like patient preferences and comorbidities. Therefore, we believe a\nmore medically meaningful metric must be proposed to guide the training process.\nRegardless of whether the emphasis of the development direction of medication recommendation is on variations in data\nquality or the specific optimization metrics selected, the terminal concern is the evaluation of the medication-related\nclinical decision quality. Importantly, the evaluation of quality matches the concept of counterfactual outcomes from\ncausal inference (38) which examines how modifying causative factors affects an outcome variable (39). Existing\nmodels focus on several primary aspects: 1) Using encoders to map covariates to representation space, processing\ncombinations, leveraging networks to predict outcomes, and minimizing the distributional distance between factual\nand counterfactual outcomes (40, 41); 2) The theoretical decomposition of covariate relationships (42); 3) Generating\ncounterfactual output outcomes or achieving balanced representation space distributions (43, 44, 45); 4) Engaging in time\nseries causal learning (46, 28, 29, 30, 47). However, in clinical practice, doctors often want to understand counterfactual\noutcomes: \"What will happen if another decision is made?\". Despite the emphasis on elucidating causal relationships in\nmost models, the \"counterfactual outcomes\" for prediction remain obscured. Making these \"counterfactual outcomes\"\ntransparent could be advantageous, as it would not only directly guide parameter updates but also enable decision\nmodification based on the tangible consequences of those decisions in the real world. Consequently, two pivotal\nchallenges arise: 1) making counterfactual outcomes as a discernible metric and 2) establishing a causal inference-based\nparadigm that leverages this metric to explore possible outcomes.\nFirstly, this study links counterfactual outcomes and the efficacy of medications. We propose the estimated length of\nstay (ELOS) as a metric for clinical counterfactual outcomes. In contrast to the length of stay (LOS), an actual medical\noutcome, ELOS is determined by averaging the LOS of patients exhibiting similar clinical conditions (48). Specifically,\ninspired by approaches in drug repositioning (49) and patient similarity analysis (50), we calculate ELOS by identifying\nanalogous patients and medication predictions, ensuring that it dynamically reflects the effectiveness of medication\ncombinations based on real-world medical outcomes. Crucially, integrating this metric within our paradigm ensures\nseamless compatibility with other modules, such as DDI, present in the architecture.\nNext, we investigate achieving a causal inference-based training strategy. This involves two critical aspects: ensuring\naccurate and reasonable knowledge acquisition, and optimizing this knowledge gleaned through causal inference.\nIntriguingly, this dual process mirrors the evolution of a physician from a novice to an expert. Typically, a doctor\nundergoes two main stages of development: the acquisition of evidence-based knowledge in academic settings, followed\nby therapeutic optimization in clinical environments. The first phase focuses on mastering foundational medical\nknowledge and techniques. In contrast, the latter delves into diverse clinical outcomes that arise from specific decisions\nmade for individual patients\u2014a process that aligns closely with causal inference. In light of this, we propose a general\nparadigm for determining the optimal medication combination by mimicking this process.\nWhile evidence-based training through supervised learning can reliably ensure accurate knowledge acquisition, the real\nchallenge emerges during the therapeutic optimization stage. Notably, we discovered that Reinforcement Learning\n(RL) (51), a goal-driven learning approach that allows an agent to optimize rewards through interactions with its\nsurroundings, offers the potential to navigate the medical feature space for improved patient outcomes. Indeed, RL\nmight be the simplest way to achieve the causal inference by exploring the different estimated clinical outcomes, as\nprior work on time series tasks indicates that RL can reduce expected mortality rates (28, 29, 30). Thus, we tried to\napply RL for therapeutic optimization and explore the gradient space with the guide from ELOS-based reward to\nmake RL suitable for non-time series tasks. However, ELOS is synthesized from patient data and predictions, the\nretrieved data cannot directly influence gradient updates. Consequently, we use ELOS in a dual capacity: firstly, ELOS-\ninformed perturbations guide the trajectory within the gradient space; secondly, when paired with these perturbations,\nELOS serves as a metric for assessing and confirming exploration efficacy, thereby regulating the commencement and\nconclusion of this exploratory phase. Crucially, the effective assimilation of ELOS into deep learning necessitates the\nconcurrent application of both these functionalities."}, {"title": null, "content": "In summary, our objective is to enhance the effectiveness of medication recommendations by addressing dataset\nconstraints and refining optimization metrics. Drawing inspiration from the developmental trajectory of physicians\ntransitioning from novices to experts, we present a causal inference-based paradigm, coupled with a model named\nMiranDa, which prioritizes the counterfactual outcomes ELOS as the optimization target and integrates supervised\nlearning techniques with reinforcement learning. We hypothesize that 1) ELOS can serve as an effective counterfactual\noutcome metric for evaluating medication efficacy, and 2) our proposed model will showcase enhanced efficacy in\nsteering medical outcomes by optimizing medication suggestions."}, {"title": "Method", "content": null}, {"title": "Study design and dataset", "content": "We utilized the Medical Information Mart for Intensive Care (MIMIC) III database (52, 53, 54) and IV database (55) to\ndevelop and assess our algorithm, primarily aiming to improve recommending medication combinations. The MIMIC-\nIII and MIMIC-IV databases include data for 61,532 and 315,460 unique adult Intensive Care Unit (ICU) admissions,\nrespectively, at Beth Israel Deaconess Medical Center, Boston, MA, USA, spanning 2001\u20132012 and 2008\u20132019. We\nensured compliance with ethical considerations by securing all necessary permissions for data collection, processing,\nand dissemination from the appropriate research bodies. All data were stored in a secure environment, facilitating the\nprocesses of training, validation, and testing.\nTo ensure an unbiased evaluation and robust model development, we methodically partitioned the dataset based on\nindividual patients, ensuring that data from each patient was exclusive to a single subset. To validate our concept, we\nemployed the MIMIC-III database, allocating 70% of the data for training, 15% for validation, and 15% for testing,\nrepeated 30 times. For the MIMIC-IV database, we focused more on the trained model by allocating 45% of the data for\ntraining, 5% for validation, and the remaining 50% for testing. The development of the algorithm mapping correlations\ndid not involve any data from the testing subsets, which was specifically utilized to evaluate the model performance on\nunseen data."}, {"title": "Data collection and preprocessing", "content": "The admission of each patient to the ICU was assigned a unique ICU stay ID, enabling tracking of distinct ICU episodes.\nOur inclusion criteria encompassed patients who were aged over 18 years at admission; underwent a continuous regimen\nof treatment and medication within the study period; and were discharged with an \"alive\" status. These criteria resulted\nin the documentation of 35,926 events from 6,154 unique patients in the MIMIC III dataset, and 224,670 events from\n119,315 unique patients in the MIMIC IV dataset. Moreover, recognizing the existence of both prevalent and rare cases,\nwe chose not to exclude outliers, even if they could potentially affect performance metrics. Such an inclusive approach\noffers a more genuine reflection of the patient population.\nData from each hospitalization incorporated a comprehensive history of prior procedures and conditions, as well as\npatient demographics and clinical characteristics. A \"LOS\" was defined as the period from the onset of a documented\nhospitalization to the discharge from the ICU. LOS values are normalized to 1.0, which equals 24 hours. The utilization\nof daily intervals was motivated by the requirement to improve the robustness of the dataset, thus reducing the\ninfluence of variables extraneous to clinical decision-making processes For training our model, we used four input\nfeatures: diagnoses, procedures, lab events, and patient demographics. The model's prediction target was medication\ncombinations. Medications were coded using the 11-digit version of the National Drug Code. Procedures and diagnoses\nwere categorized using the International Classification of Diseases, Ninth Revision (ICD-9) coding system. Here,\n\"procedures\" refer to medical actions undertaken in inpatient hospital settings, and \"lab events\" denote laboratory test\noutcomes, such as hematology, chemistry, and microbiology results (52). We selected these features due to their clinical\nrelevance and their capability to represent a patient's status accurately. The terminology employed is delineated in\nSupplementary Terms 1-4."}, {"title": "Model design", "content": "We introduce MiranDa, a model named for its design principle of Mimicking the learning processes of human Doctors\nto achieve causal inference for medication recommendation. This model simulates the evolution of clinicians from\nnovices to experts, as shown in Fig. 1. Our approach combines two training phases: the Evidence-based Training Phase\n(supervised learning) and the Therapeutic Optimization Phase (reinforcement learning in gradient space) for causal\ninference. The transition between these phases is driven by a clinical outcome-oriented reward ELOS, retrieved from\nclinical conditions and model predictions."}, {"title": "Evidence-based Training Phase", "content": "In the Evidence-based Training Phase, we employ supervised training to establish a mapping relationship between\nclinical conditions (input features) and medication combinations (predictions). The predictions from this phase serve\nas an effective starting point, which helps to circumvent the instability introduced by random initialization for the\nsubsequent Therapeutic Optimization Phase.\nHere, we utilize transformers (56) for the predictor $f (\\theta)$, where $\\theta$ represents the model parameters, the architecture\nof the predictor is shown in Fig. 2. A patient state $s_i$, comprising diagnosis, procedures, lab events, and fundamental\ndemographic information which includes age, gender, race, and the patient's sequential number of hospitalizations,\nthe prediction is the medication combination $a_i$, through $a_i = f(s_i; \\theta)$. The format of inputs is treated as a token. By\nutilizing the spatial positioning of these individual tokens, the model is facilitated in effectively understanding and\nprocessing the associated information. Following the positioning phase, the tokenized features are fed into a transformer\nlayer, generating four distinct vectors representing unique token features in an encoded format. These vectors are\nconcatenated to establish a unified representation, which compactly encapsulates information from all individual vectors.\nA subsequent fully connected layer reshapes this vector to suit the final output, wherein a softmax function yields a\nmulti-label medication recommendation. Building upon the aforementioned process, the predictor provides a set of\nmedication combinations, denoted as a, where each prediction $a_i$ belongs to $\\{0, 1\\}^n$. Here, the value n signifies the\ntotal number of medication classes investigated in our study, thereby forming a n-dimensional discrete action space."}, {"title": "Therapeutic Optimization Phase", "content": "The Therapeutic Optimization Phase involves mimicking the doctor using an agent to explore optimal clinical outcomes.\nThis incorporates the principles of RL for causal inference. In this phase, the predictor $f (\\theta)$ serves as the agent with"}, {"title": "Defining the action space", "content": "Here, we utilized two retrieve strategies $retrieval_p$ and $retrieval_d$ to get the action B\nbased on action a. The intrinsic complexities of clinical conditions pose a challenge (57), as even patients sharing\nidentical diagnoses may exhibit substantial variations in treatments, procedures, and hospitalization duration. To\ncircumvent these intricacies, spurred by concepts such as drug repositioning (49) and patient similarity analysis (50),\nidentifying patient trajectories akin to a reference patient aids in predicting the clinical outcomes. In detail, one is\n$retrieval_p$, which constrains the matched patients with the same procedures and age in a limited range, and the other is\n$retrieval_d$, which constrains the patients with similar conditions and medications.\nFirstly, $retrieval_p$ retrieves similar patients with the same procedures to expand action space ai. In the ICU, on one\nhand, the patients are particularly vulnerable and frequently require urgent, high-risk therapeutic procedures, which play\na crucial and often life-saving role in the management of critical patients (58). On the other hand, patients undergoing\nidentical procedures often present with analogous health conditions (59). Clinical congruencies are underscored by\npost-procedure care and monitoring, often meaning that patients face corresponding risks, potential complications, and\nprojected outcomes (60, 61). Consequently, we use $retrieval_p$ to retrieve the auxiliary action space set B based on the\nprocedures and utilize a further constraint as the age range within n years of patient $p_i$ with action $a$ from the entire\ndataset D. We can mathematically express retrieval using equation:\n$B_{p_i} = \\{p' \\in D | C(p_i, p') = 1\\}$,\nhere, each $p'$ is a patient in D. The function $C(p_i, p')$ serves as a binary indicator, returning one if patient $p_i$ and patient\n$p'$ share the exact medical procedures and their ages fall within a specific year difference, and 0 otherwise.\nThen, $retrieval_d$ is utilized to constrain the auxiliary action space $B_{p_i}$ drug-wise, further ensuring that the ELOS in\nthe next step are plausible through drug similarity and procedures sameness. This function employs the set of vectors\n$B_{p_i} = b_1, b_2, ..., b_n$, to generate a set $\\beta_1$ with a cardinality of $|B| = 50$ that maximizes the cosine similarity between\nvector $a_i$ and each vector in the set. This can be formalized in the equation:\n$\\beta_1 = Top_K\\{b \\in B_{p_i} | \\sigma(a_i, b) > \\phi, <\\}$,\nhere the top K vectors with the highest cosine similarity with a and greater than a threshold \u03c6 are selected. We\naim to maximize $\\sigma(a_i, b)$ for each $b \\in B$, given $\\sigma(a_i, b) > \\phi$. A partial order < is defined on B such that for any\n$b_i, b_j \\in B$, we have $b_i \\leq b_j$ if and only if $\\sigma(a_i, b_i) \\leq \\sigma(a_i, b_j)$. This detailed mathematical construction provides a\nclear understanding of the dynamic evolution of the action spaces in our agent."}, {"title": "Counterfactual outcomes and reward", "content": "The reward for each batch of patients, represented by $\\hat{H}_B$, quantifies the\nefficacy of the actions. Accordingly, $\\hat{H}_B$ computed as:\n$\\hat{H}_B = \\frac{1}{N} \\sum_{i=1}^N R(a_i, \\beta_i)$,\nhere, this function is based on the mean LOS from each retrieved patient, denoted as R. for each discrete medication\ncombination $a_i$ and its expand drugs set $B_i$, we calculate the real LOS, $H | a_i$ and counterfactual outcomes as ELOS,\n$H | \\beta$, contingent on the action. This difference value is treated as the reward $R(a_i, \\beta_i)$ for the action $a_i$ and $B_i$.\nMathematically, this can be defined as:\n$R (a_i, \\beta_i) = H |a_i - H | \\beta,$\nwhere $R (a_i, \\beta_i)$ signifies that shorter hospitalization durations are associated with better medical outcomes. Thus,\ndifferent from traditional RL, the objective of our agent is to minimize $\\hat{H}_B$, thereby transforming a complex problem of\npatient recovery into an optimization challenge. This reward-oriented framework provides a concrete and practical\ntarget for optimizing our RL agent in the context of pharmaceutical recommendations."}, {"title": "Training and optimization", "content": "We introduce a novel training paradigm that starts from the supervised learning based-start point, we utilize $\\hat{H}_B$ as\nthe indicator to transition to the Therapeutic Optimization Phase and explore the gradient space with the perturbation\ngenerated from the reward (rather than the reward itself). The agent employs the minimum ELOS from the retrieved\npatients - an exploration space reward as the target, equipping it to explore potential medication combinations under\nmultiple constraints more robustly. The basic concept of exploration in gradient space by the perturbation is shown\nin Fig. 4. We proceed with extreme caution when updating parameters, exiting the second stage once a threshold of\n$\\hat{H}_B$ is reached. This is primarily because models associated with medications should be grounded in existing medical\nknowledge. In subsequent learning processes, parameters should be cautiously updated, on the premise of ensuring the\nfirst-order knowledge can be stably learned or retained (62)."}, {"title": "Evidence-based Training Phase loss", "content": "The model parameters first need to be updated with supervised learning. The\nfeed-forward propagation process is represented as a function $f(s; \\theta)$, and the error between the model's prediction\nand the true output is quantified by the binary cross-entropy loss function $I_{BCE}(Y, f(X; \\theta))$, where y is the true output.\nConsequently, the Evidence-based Training Phase loss $L(\\theta)$ is the average of this binary cross-entropy loss overall\ntraining samples. With the reward $\\hat{H}_B$, the loss express as:\n$L(\\theta) = C(\\hat{H}_B - \\delta) \\cdot \\lambda I_{BCE} + [1 - C(\\hat{H}_B - \\delta)] \\cdot I_{BCE}$,\nwhere \u03b4 is an item that determines whether enters the subsequent phase. The binary function C is 1 if $\\hat{H}_B > \\delta$ and 0\notherwise. Consequently, when $\\hat{H}_B \\geq \\delta, L(\\theta)$ becomes $\\lambda I_{BCE}$, progressing to the Therapeutic Optimization Phase. If\n$\\hat{H}_B < \\delta, L(\\theta)$ remains $I_{BCE}$, bypassing this phase. A lower value of \u03bb thus facilitates more exploratory steps in the\nTherapeutic Optimization Phase."}, {"title": "Therapeutic Optimization Phase perturbation", "content": "The underlying foundation of our algorithm centers around a tailored\nTherapeutic Optimization Phase perturbation term, $P_{RL}(\\theta)$, which aims to enhance the exploration space of parameters\nduring updates by applying the derivative of the reward $\\hat{H}_B$. Here, our main idea was inspired by Stochastic Gradient\nLangevin Dynamics (SGLD) (63), consequently, our strategy is to replace Gaussian noise with a scaling perturbation\nterm P. The initial gradient update with perturbation can be expressed as:\n$\\theta_{t+1} = \\theta - \\nabla L(\\theta_t) + \\nabla P_{RL}$,\nwhere $\\theta_t$ represents the parameters in the t batch, $\\nabla L(\\theta_t)$ is the gradient of the loss function L with respect to \u03b8t. The\nperturbation, $P_{RL} (\\theta)$ is structured with several components designed to promote stability and efficacy in learning. This\nperturbation incorporates a logarithmic function that engulfs the average reward per batch, weighted by reinforcement\nconfidence, \u03b3, and subsequently divided by ELOS, denotes by $\\sum_{i=1}^N [H|\\beta]$. This logarithmic feature prevents the loss\nfunction from increasing indefinitely, thereby constraining the perceived value of escalating rewards. The expression of\nthe perturbation term is as follows:\n$P_{RL}(\\theta) = log(1 + \\gamma \\cdot (\\frac{\\hat{H}_B}{ \\sum_{i=1}^N [H|\\beta]}))$"}, {"title": null, "content": "Since the update of the perturbation term has a break in the gradient update process for the agent parameters, this better\nmedical outcome is achieved by perturbing the gradient direction. The kernel of the RL perturbation function is $\\hat{H}_B$\ndivided by ELOS, which aims to maintain stability in the scaling of perturbation medication-wise. This is, essentially, a\nscaling of the magnitude of the update, i.e., the actual medical significance of $\\hat{H}_B$ as measured by the elos. For example,\nfor the same $\\hat{H}_B$, a smaller ELOS encourages more exploration. Meanwhile, with the reinforcement confidence, \u03b3, acts\nas a weighting factor that adjusts the influence of the expected reward on the loss. Moreover, the convex function log(x)\nis for x > 0, enabling the application of gradient descent. Therefore, the logarithmic transformation guarantees that\nthe derivative of the perturbation function, $dP_{RL} (\\theta)/d\\theta$, remains well-conditioned, fostering a smooth optimization\nprocess and precludes abrupt changes in parameter updates during backpropagation."}, {"title": "Perturbed objective function", "content": "Crucially, a perturbed objective function, denoted as $L'(\\theta)$, for updating the parameters\nin the Therapeutic Optimization Phase, that harmoniously integrates the loss $L(\\theta)$ and the perturbation function $P_{RL}(\\theta)$.\nThe blending of these loss functions is guided by a hyperparameter \u03b5, which further ensures the possibility of more\nsteps to explore the optimal medication. This amalgamation is expressed in the form of a convex combination, defined\nas follows:\n$L'(\\theta) = \\epsilon(1 - 1)L(\\theta) + (1 - \\epsilon)P_{RL}(\\theta)$,\nwhere \u03b5 also acts as a balancing factor between the Evidence-based Training Phase loss and the Therapeutic Optimization\nPhase perturbation, allowing for a smooth transition between the two function types. Crucially, the L will update for\neach step in the Therapeutic Optimization Phase perturbation. Our perturbed objective function, $L'(\\theta)$, thus encapsulates\nthe strengths of both conventional mapping relations (represented by the standard loss) and the space that may have\noptimal medical outcomes (captured by the RL perturbation). This balance is crucial for the agent deployed in dynamic\nenvironments such as ICU settings, where actions will not harm the parameters even if they diverge from general\nmapping relations. Since even if the ELOS is not better, the parameters can still be updated to the directions with a\nlower loss, and the \"mission\" of better medical outcomes could be achieved in the further batch. For a comprehensive\nstep-by-step procedure of our MiranDa approach, refer to Algorithm 1."}, {"title": "Evaluation metrics", "content": "We evaluate our model using a diverse set of metrics to ensure a comprehensive and robust assessment. The ELOS serves\nas a critical measure of the model's capability in suggesting medication combinations. It indicates not just the success\nof a patient's recovery, but also the counterfactual outcomes. ELOS thus directly measures model performance with the\nclinical aim of minimizing ICU durations to improve patient well-being. We further incorporate the Receiver Operating\nCharacteristic Area Under Curve (ROC AUC) to understand the model's accuracy across different thresholds (64). The\nPrecision-Recall AUC (PR AUC) evaluates the precision-recall trade-off, which is especially important for imbalanced\ndatasets (65). Together, ROC AUC and PR AUC offer a comprehensive perspective on predictive accuracy. The F1 score\nbalances precision and recall (66), and we will also report separate Precision and Recall scores for deeper insight (67).\nThe Jaccard Index measures the similarity between predicted and actual medication combinations, indicating the\nmodel's recommendation accuracy (68). Additionally, we monitor the DDI rate (69). Through these metrics, we provide\na thorough evaluation of the model, showcasing its efficacy and safety."}, {"title": "Data interpretation", "content": "We interpreted the intrinsic correlations among various medication combinations. These combinations were derived\nfrom three primary sources: our predictive model, baseline and human doctors. We aimed to elucidate the relationships\nbetween these medication combinations and several other variables, including patient diagnosis, procedures, and\ndemographic information. We achieved this using a three-fold methodology: structuring our data in hyperbolic space,\nclustering the data into discernible categories, and interpreting the clusters."}, {"title": "Spatial positioning in Hyperbolic Geometry", "content": "Hyperbolic Geometry, a non-Euclidean geometry that excels at capturing and representing data with inherent hierarchical\nstructures (70, 71), offers a unique lens to discern hierarchies in medication combinations. Transitioning high-\ndimensional data to this geometry preserves the inherent relationships and distances, a challenge often encountered in\ntraditional Euclidean representations (72, 73). Therefore, we utilized the Hyperbolic model and its representation in\nthe Poincar\u00e9 Disk Model in this study, where each point symbolizes a unique medication combination. The spatial\npositioning in this space reflects the similarities and disparities of the underlying policies (74), instrumental for analyses\nthat capture the genuine relationships within the dataset."}, {"title": "Spatial positioning in Hyperboloid Model", "content": "To achieve spatial positioning in hyperbolic space, we employed the\nUniform Manifold Approximation and Projection (UMAP) algorithm, renowned for its effectiveness in capturing\nhierarchical and topological data properties (75). UMAP constructs a fuzzy simplicial set representation to approximate\nthe manifold structure of a. By identifying neighbors of each point in a within the high-dimensional space, a weighted\ngraph, G, is constructed. The weights of G indicate the likelihood of data points being neighbors and are described by:\n$G = (A_i, a_j)|A_i, a_j \\in a \\wedge d(a_i, a_j) < \\epsilon$,\nhere, $d(a_i, a_j)$ represents a distance metric attentive to local structures, while \u03f5 is a threshold for proximity. The\nobjective is to reduce the cross-entropy between G and its hyperbolic counterpart, ensuring the preservation of both\nlocal and global structures. Given the spatial positioning in H\u00b3 as HS, the optimization is:\n$HS^* = argmin_\\Gamma CE(G,HS)$,\nwhere HS* represents the optimal hyperbolic spatial positioning that minimizes the divergence CE between G and\nHS."}, {"title": "Transition from Hyperboloid Model to Poincar\u00e9 Disk Model", "content": "To transition data from the Hyperboloid Model to the\nPoincar\u00e9 Disk Model, we employed stereographic projection (76). The Poincar\u00e9 Disk Model represents hyperbolic\ngeometry using points within a disk, with geodesics portrayed as circle segments orthogonal to the disk boundary or\nas its diameters (77). This representation is advantageous for visualizing intricate datasets in 2D while retaining data\nnuances.\nA point, $h_i$, in the hyperboloid model is mapped to its counterpart, $p_i$, in the Poincar\u00e9 disk model. The transformation\n is expressed by $p_i = \\frac{h_i}{1+h_3}$, where i = 1,2. Each coordinate of $h_i$ in H\u00b3 is divided by the sum of one and its third\ncoordinate. After this projection, data is visualized as a scatter plot within the boundary of the"}]}