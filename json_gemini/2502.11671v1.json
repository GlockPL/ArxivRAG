{"title": "Diversity-Oriented Data Augmentation with Large Language Models", "authors": ["Zaitian Wang", "Jinghan Zhang", "Xinhao Zhang", "Kunpeng Liu", "Pengfei Wang", "Yuanchun Zhou"], "abstract": "Data augmentation is an essential technique in natural language processing (NLP) for en-riching training datasets by generating diverse samples. This process is crucial for improv-ing the robustness and generalization capa-bilities of NLP models. However, a signifi-cant challenge remains: Insufficient Attention to Sample Distribution Diversity. Most exist-ing methods focus on increasing the sample numbers while neglecting the sample distribu-tion diversity, which can lead to model over-fitting. In response, we explore data augmen-tation's impact on dataset diversity and pro-pose a Diversity-oriented data Augmentation framework (DoAug). Specifically, we utilize a diversity-oriented fine-tuning approach to train an LLM as a diverse paraphraser, which is ca-pable of augmenting textual datasets by gen-erating diversified paraphrases. Then, we ap-ply the LLM paraphraser to a selected core-set of highly informative samples and integrate the paraphrases with the original data to cre-ate a more diverse augmented dataset. Finally, we conduct extensive experiments on 12 real-world textual datasets. The results show that our fine-tuned LLM augmenter improves diver-sity while preserving label consistency, thereby enhancing the robustness and performance of downstream tasks. Specifically, it achieves an average performance gain of 10.52%, surpass-ing the runner-up baseline with more than three percentage points.", "sections": [{"title": "1 Introduction", "content": "AI methods have demonstrated immense capabil-ities, often surpassing human abilities and tradi-tional techniques across various natural language processing (NLP) tasks. This success largely hinges on the availability of high-quality datasets, which enable AI models to uncover intrinsic pat-terns and drive their effectiveness in real-world applications. However, training on inferior datasets can significantly degrade model performance, par-ticularly when applied to test data or real-world scenarios. As AI technology advances, especially with large language models (LLMs), the demand for high-quality datasets has become more pronounced. To effectively train NLP models, a high-quality dataset should be (1) Large: a sufficient number of samples is crucial to reflect the diversity and complexity of human language. Large datasets help prevent overfitting, ensuring the trained AI model generalizes well to unseen data. With more data points, the model can learn various patterns and relationships, which enhances its robustness and reliability; (2) Coherent: the mapping between data and labels must be accu-rate and consistent. Coherent datasets ensure that each data point is correctly labeled, providing the model with reliable information for learning. In-coherent datasets, with mislabeled or inconsistent data, can confuse the model and degrade its per-formance. Consistency in labeling also aids in the reproducibility of results and the interpretability of the model's predictions; (3) Diverse: a diverse dataset ensures NLP models learn a broad spec-trum of linguistic patterns, enhancing robustness across real-world conditions. This includes varia-tions such as dialects, tones, formality, or domain-specific terms. Exposure to such diversity helps models generalize better, avoiding over-reliance on narrow language subsets. Additionally, it improves adaptability to unexpected inputs while reducing biases tied to certain language styles.\nData augmentation is an efficient technique for increasing the number of training samples by modi-fying existing dataset samples. It allows for the rapid generation of large-scale datasets without the need for additional data collec-tion and has been successfully applied in various domains, including textual data. Data augmenta-tion for textual data often changes the wording or reshapes the structure of a sentence. Many early"}, {"title": "2 Related Work", "content": "Textual data augmentation revolves around perturb-ing the wording and syntax of existing sentences to create more modified samples. Some early and simple methods propose to randomly replace, re-move, insert, and swap characters or words at cer-tain ratios in a sentence. Some more sophisticated methods modify sentences by using alternative syn-tax. Language models can in turn act as effective tools for textual data augmen-tation. For example, Back-translation first translates sentences from the source language (e.g. English) to an intermediary (e.g. Chinese) and then translates the intermediary sen-tence back to the source language. Substitute Word using BERT masks certain words in the original sentences and uses a BERT model to predict masked words. They utilize the subtle differences made by the translator or the un-masking process and perturb the wording or syntax while keeping the meanings untouched. The re-cent emergence of LLM has given birth to a series of new approaches. AugGPT, for example, prompts the state-of-the-art ChatGPT model to rewrite sen-tences in the dataset and preserves dataset coher-\n2.1 Textual Data Augmentation"}, {"title": "3 Methodology", "content": "Given a parameterized data augmenter $f_\\theta$, the data augmentation process is expressed as $f_\\theta : S = {X,t} \\rightarrow \\tilde{S} = {\\tilde{X},\\tilde{t}}$, where $S$ is the original dataset composed of the feature vectors $X$ and target labels $t$, and $\\tilde{S}$ is the augmented dataset. For a diversity metric $D$, the diversity values of the original and the augmented datasets are $D(S)$ and $D(\\tilde{S})$, respectively, and the diversity gain of that augmentation is defined as $\\Delta D(S;\\theta) = D(\\tilde{S}) - D(S)$.\nDoAug aims to optimize the parameter $\\theta^*$ for the data augmenter to maximize the diversity gain after augmentation:\n$\\theta^* = \\arg\\max_\\theta \\mathbb{E} \\Delta D(S;\\theta)$ (1)\nWhen training models on the original and aug-mented datasets, their respective performances are evaluated by a performance metric $P$, resulting $P(S)$ for the original dataset and $P(\\tilde{S})$ for the aug-mented dataset. The performance gain is defined as $\\Delta P(S;\\theta) = P(\\tilde{S}) - P(S)$. Moreover, by optimiz-ing and employing the augmenter with maximum diversity gain, DoAug expects to achieve maximum performance gain under fixed conditions:\n$\\Delta P(S; \\theta^*) = \\max_\\theta \\Delta P(S;\\theta)$ (2)\n3.1 Problem Formulation\n3.2 Framework Overview"}, {"title": "3.3 Diverse Paraphraser Fine-tuning", "content": "The proposed data augmentation method is con-structed upon a general-purpose LLM. Pre-trained on a vast amount of corpus, LLMs now boast human-level understanding and generation abili-ties. We leverage these abilities of an LLM and use it as a tool for our data augmentation process. The LLM is fine-tuned as a paraphraser that can rewrite sen-tences with alternative expressions while maintain-ing the original semantics. The LLM paraphraser is further fine-tuned to produce more diverse gener-ation results and cover more linguistic alternatives."}, {"title": "3.3.1 LLM Paraphraser Training with PEFT", "content": "To fully leverage the understanding and generation abilities of the LLM, we use supervised fine-tuning (SFT) to train it to follow instructions to paraphrase existing sentences. Since the SFT phase of LLM training is heavily computation-consuming, we use the Parameter-Efficient Fine-Tuning (PEFT) technique to reduce the size of trainable parame-ters updated in the back-propagation pass to save the computation cost. Specifically, we adopt the Low-Rank Adaptation (LoRA) approach. Given a pre-trained LLM with weights $W_o \\in \\mathbb{R}^{d\\times k}$, LORA represents its update $\\Delta W$ with $BA$, where $B \\in \\mathbb{R}^{d\\times r}$, $A \\in \\mathbb{R}^{r\\times k}$, and the rank $r < \\min(d,k)$. During training, $W_o$ is frozen and excluded from the gradient update, while $A$ and $B$ are updated instead. After training, $W_o$ and $\\Delta W = BA$ are multiplied with the same input, and their outputs are summed, as in:\n$h = W_o x + \\Delta W x = W_o x + BAx$ (3)\nIn the SFT phase, we sample a subset $D_{SFT}$ from ChatGPT Paraphrases dataset to train the LLM."}, {"title": "3.3.2 LLM Generation Diversity Enhancement with DPO", "content": "To align LLM generations to human preferences, recent LLMs adopt RLHF in their training process, which involves the PPO algorithm and a reward"}, {"title": "3.3.3 Diversity-oriented Sampling", "content": "For each input sentence, we use beam search to generate $K$ sequences from the LLM's output log-its. We then rank these sequences based on their distances from the original sentences according to Eq. 4. Only the most distant sentences are retained to reduce redundancy and prevent overfitting."}, {"title": "3.4 Selective Coreset Data Augmentation", "content": "Given the time consumption and computation cost of LLM-based data augmentation methods, it is non-trivial to recognize the most important sam-ples and constrain the target for data augmenta-tion to these samples. First, we train the down-stream task model on the dataset and collect training dynamics and post-training post-training metrics. Then we calculate the EL2N, entropy, variance, and AUM score to evaluate sample importance. We use score monotonic selection and coverage-centric selection (CCS) to de-rive the coresets. DoAug performs a hierarchical"}, {"title": "4 Experiments", "content": "Evaluation Criterion. We evaluate diversity and affinity for data distribution while measuring per-formance on downstream tasks for effectiveness. Diversity. To comprehensively evaluate the effect of the proposed model DoAug on dataset diver-sity, we adopt several measures to evaluate the aug-mented dataset's diversity:\n$\\text{Distance}(S) = \\sum_{x_i, x_j \\in S} \\sqrt{(e_{x_i} - e_{x_j})^2}$,\nwhere $e_x = \\mathcal{E}(x)$ is the embedding of sample $x$ in the embedding space $\\mathcal{E}$, and a larger distance indicates greater diversity.\n\\textbf{Dispersion} : is similar to co-sine similarity but adjusted to make larger disper-sion indicate greater diversity: $\\text{Dispersion}(S) = \\frac{1}{|S| \\sum_{x_i, x_j \\in S} \\frac{e_{x_i} \\cdot e_{x_j}}{||e_{x_i}|| ||e_{x_j}||}}$.\n$r_j = \\sqrt{\\frac{1}{|S|}}\\sum_{i=1}^H\\frac{(e_j-\\mu_j)^2}{\\sigma_j^2}=c^2$, where$\\mu_j$ is the embeddings' mean along the j-th axis, and $\\sigma_j$ is the variance of the j-th axis. Geometri-cally, the standard deviation $\\sigma_j$, is the radius $r_j$ of the ellipsoid along the j-th axis. Thus, we have: $\\text{Radius}(S) = (\\Pi_{j=1}^H \\sigma_j)^{1/H}$.\n\\textbf{Homogeneity} : is a metric that reflects the uniformity of a cluster distribu-tion, suggesting that distinct samples in a diverse dataset should ideally cover the embedding space uniformly. It begins by constructing a Markov chain model on the dataset embeddings. The edge weight between sample $i$ and $j$ is defined as $\\text{weight}(i, j) = \\frac{1}{(\\sqrt{(e_i - e_j) \\cdot (e_i - e_j)}) \\log{H}}$, and the transition probability from $i$ to $j$ is $p(i \\rightarrow j) = \\frac{\\text{weight}(i,j)}{\\sum_k \\text{weight}(i,k)}$. The entropy of the Markov chain is calculated by $\\text{entropy}(S) = - \\sum_{i,j \\in S} v_i \\cdot 4.1 Experiment Settings"}, {"title": "4.2 Overall Results", "content": "To verify the effectiveness of DoAug, we evaluate downstream task accuracy alongside the diversity and affinity of the augmented dataset. We report the rankings of performance, diversity, and affinity averaged on 12 datasets achieved by DoAug and 11 baseline methods in Figure 2. From these re-sults, we have the following observations: (1) DoAug achieves the highest performance on downstream tasks compared to other SOTA data augmentation methods, as indicated by the color bar in Figure 2. This demonstrates the high qual-ity and superior adaptability of the datasets gen-erated by our proposed method in real-world ap-plications. (2) DoAug achieves the highest di-versity score and outperforms all other baseline methods. This implies that DoAug effectively im-proves dataset diversity. (3) DoAug achieves a considerably high position on the affinity rank-ings, indicating that the sample semantics are pre-served to the greatest extent possible. In sum, DoAug achieves the top position in the combined dataset diversity and affinity rankings. Addition-ally, it achieves the best downstream task perfor-mance, indicated by the lightest yellow."}, {"title": "4.3 Performance, Diversity, and Affinity", "content": "The full results for BERT classification perfor-mance on original and augmented datasets are pre-\n4.3.1 Performance Gains"}, {"title": "4.3.2 Diversity Gain", "content": "We demonstrate the diversity gains in terms of all 5 diversity metrics along with their rankings achieved by DoAug and baseline methods in Fig-ure 2. DoAug ranks the top on the chart with an average ranking of 3.0. Specifically, it achieves the best for the Distance and Dispersion metrics. For the Vocabulary metric, OCR and Keyboard include large amounts of out-of-vocabulary tokens due to character level perturbation. The three baselines with diversity incentives, namely Chian, Hint, and Taboo, also achieve reasonably good diversity gain, in line with the results of (Cegin et al., 2024)."}, {"title": "4.3.3 Affinity and Paraphrase Validity", "content": "We present the affinity of DoAug and baseline methods in Figure 3, where DoAug outperforms other methods except Unmask, whose affinity score is 1.95. The Unmask method generates augmen-tation by replacing randomly selected words with \"[MASK]\" and predicts the masked words with the BERT model. Since the augmented samples are"}, {"title": "4.4 Ablation Studies", "content": "To verify the effectiveness of our proposed method, we conduct ablation studies to show that all com-ponents in the method framework contribute to the final performance gains, as shown in Table 3, where w/o Coreset refers to applying augmentation on a random subset of the dataset without deriv-ing a coreset of importance samples, w/o Selective refers to augmenting samples in both Sretain and Saugment instead of only augmenting the latter, w/o Aug refers to using the coreset directly for train-ing without data augmentation, w/o DPO refers to using the LLM paraphraser from the SFT stage for data augmentation, w/o DS refers to remov-ing the diversity-based sampling module, and w/o"}, {"title": "4.5 LLM Architectures Exploration", "content": "To exhibit the generalizability of our proposed methodology, we replace the LLM augmenter and downstream task model with other LLM architec-tures respectively. The results show that DoAug is agnostic to LLM architectures.\nFor the LLM augmenter, we replace the Llama-3.2-1B-Instruct model with the similar-sized Qwen2.5-1.5B-Instruct model . As shown in Figure 5, datasets augmented by the Qwen model significantly outperform the original dataset and achieve comparable accuracy and di-versity with those of the Llama model. Detailed results are given in Appendix F.\nFor the downstream task model, we replace BERT, an encoder-only model with the GPT-based and T5-based classification models. GPT is a decoder-only LLM and is especially adept at gen-erating texts from a prompt. Based on an encoder-decoder transformer architecture, T5 is trained to perform all NLP tasks in a unified text-to-text format and is favorable in broad cases. Specifi-cally, we use GPT-2 and T5-large as the backbone of classi-fication models, train these models on the MNLI,"}, {"title": "5 Conclusion", "content": "Diversity is an important factor in developing AI-ready, high-quality datasets but is often ignored in data augmentation methods. We propose a Diversity-oriented data Augmentation framework (DoAug) that trains an LLM paraphraser to en-large and introduce diversity to textual datasets. The LLM paraphraser is fine-tuned to rewrite ex-isting sentences in the original datasets, generating high-affinity samples and ensuring coherence of the dataset. We further construct a preference dataset and then fine-tune the LLM paraphraser with the DPO algorithm to encourage diversified genera-tion. In this way, we maximize the diversity of the augmented dataset in our method. In extensive experiments, our proposed method exhibits a re-markable capability to boost dataset diversity, and the diversity gain significantly benefits the model's learning performance of downstream tasks."}, {"title": "6 Limitations", "content": "This study has several limitations that should be acknowledged and addressed in future work.\nDiversity Exploration: The evaluation of diver-sity lacks a universally accepted metric. In this study, we employed a subset of diversity-related evaluation methods, but other metrics, such as n-gram-based measures (e.g., assessing uniqueness or non-repetition), were not utilized. This limita-tion suggests that our assessment of diversity may not fully capture all aspects of the concept.\nAugmentation Validation: Evaluating the correct-ness of generated data remains a challenging task. While both human evaluation and model-assisted evaluation are viable approaches, each comes with its own limitations. In this study, we relied on a sentiment-neutral large language model (LLM) for evaluation. However, this approach has inherent constraints, such as potential biases in the model and its inability to fully capture nuanced correct-ness in certain contexts.\nGeneration Factors: The quality and characteris-tics of generated samples are influenced by multi-ple factors, including the choice of prompts and the specific LLMs used. In this study, the prompts and LLMs were limited in number, and we did not ex-haustively explore all possible configurations. This restriction may have impacted the diversity and quality of the generated samples.\nEvaluation Benchmarks: Our evaluation was pri-marily focused on sentence classification tasks, and we did not extend our analysis to more general tasks, such as mathematical reasoning, instruction-following, creative writing, question-answering (QA), or chain-of-thought (CoT) reasoning. Ad-ditionally, we did not explore multimodality sce-narios, which could provide a broader perspective on the applicability of our framework. Further-more, the datasets used in this study were limited to English corpora, and we did not consider mul-tilingual datasets, which could offer insights into cross-lingual or language-specific performance.\nPotential Risks of Using LLM: Leveraging LLMs for data augmentation might suffer from demo-graphic bias and factual inaccuracies. First, LLMs may amplify demographic biases from their train-ing data. Second, generation hallucinations may produce plausible but factually incorrect content. When task models train on such flawed data, their reliability and accuracy degrade, especially in high-stakes domains like healthcare or finance. Mitigat-"}]}