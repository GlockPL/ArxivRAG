{"title": "Environment Scan of Generative AI Infrastructure for Clinical and\nTranslational Science", "authors": ["Betina Idnay", "Zihan Xu", "William G. Adams", "Mohammad Adibuzzaman", "Nicholas R. Anderson", "Neil Bahroos", "Douglas S. Bell", "Cody Bumgardner", "Thomas Campion", "Mario Castro", "James J. Cimino", "I. Glenn Cohen", "David Dorr", "Peter L Elkin", "Jungwei W. Fan", "Todd Ferris", "David J. Foran", "David Hanauer", "Mike Hogarth", "Kun Huang", "Jayashree Kalpathy-Cramer", "Manoj Kandpal", "Niranjan S. Karnik", "Avnish Katoch", "Albert M. Lai", "Christophe G. Lambert", "Lang Li", "Christopher Lindsell", "Jinze Liu", "Zhiyong Lu", "Yuan Luo", "Peter McGarvey", "Eneida A. Mendonca", "Parsa Mirhaji", "Shawn Murphy", "John D. Osborne", "Ioannis C. Paschalidis", "Paul A. Harris", "Fred Prior", "Nicholas J. Shaheen", "Nawar Shara", "Ida Sim", "Umberto Tachinardi", "Lemuel R. Waitman", "Rosalind J. Wright", "Adrian H. Zai", "Kai Zheng", "Sandra Soo-Jin Lee", "Bradley A. Malin", "Karthik Natarajan", "W. Nicholson Price II", "Rui Zhang", "Yiye Zhang", "Hua Xu", "Jiang Bian", "Chunhua Weng", "Yifan Peng"], "abstract": "This study reports a comprehensive environmental scan of the generative AI (GenAI) infrastruc-\nture in the national network for clinical and translational science across 36 institutions supported\nby the Clinical and Translational Science Award (CTSA) Program led by the National Center\nfor Advancing Translational Sciences (NCATS) of the National Institutes of Health (NIH) at\nthe United States. With the rapid advancement of GenAI technologies, including large lan-\nguage models (LLMs), healthcare institutions face unprecedented opportunities and challenges.\nThis research explores the current status of GenAI integration, focusing on stakeholder roles,\ngovernance structures, and ethical considerations by administering a survey among leaders of\nhealth institutions (i.e., representing academic medical centers and health systems) to assess\nthe institutional readiness and approach towards GenAI adoption. Key findings indicate a di-\nverse range of institutional strategies, with most organizations in the experimental phase of\nGenAI deployment. The study highlights significant variations in governance models, with a\nstrong preference for centralized decision-making but notable gaps in workforce training and\nethical oversight. Moreover, the results underscore the need for a more coordinated approach\nto GenAI governance, emphasizing collaboration among senior leaders, clinicians, information\ntechnology staff, and researchers. Our analysis also reveals concerns regarding GenAI bias,\ndata security, and stakeholder trust, which must be addressed to ensure the ethical and effective\nimplementation of GenAI technologies. This study offers valuable insights into the challenges\nand opportunities of GenAI integration in healthcare, providing a roadmap for institutions aim-\ning to leverage GenAI for improved quality of care and operational efficiency.", "sections": [{"title": "1 INTRODUCTION", "content": "The burgeoning advancement of generative AI (GenAI) provides transformative potential for healthcare\nsystems globally. GenAI employs computational models to generate new content based on patterns learned\nfrom existing data. These models, exemplified by large language models (LLMs), can produce content\nacross various modalities such as text, images, video, and audio. 1-5 Its ability to generate human compre-\nhensible text enabled the exploration of diverse applications in healthcare that involve the sharing and dis-\nsemination of expert knowledge, ranging from clinical decision support to patient engagement. 6,7 Integrat-\ning GenAI into healthcare can enhance diagnostic accuracy, personalized treatment plans, and operational\nefficiencies. For instance, GenAI-driven diagnostic tools can analyze medical images and electronic health\nrecords (EHRs) to detect diseases, often surpassing the accuracy of human experts. 8-13 GenAI applications\ncan streamline administrative processes, reduce clinicians' documentation burden, and enable them to spend\nmore time on direct patient care. 14,15 However, implementing GenAI technologies in healthcare has several\nchallenges. Issues such as trustworthiness, data privacy, algorithmic bias, and the need for robust regulatory\nframeworks are critical considerations that must be addressed to ensure the responsible and effective use of\nGenAI. 16,17\nGiven these promising advancements and associated challenges, understanding the current institutional in-\nfrastructure for implementing GenAI in healthcare is crucial. Various stakeholders (e.g., clinicians, pa-\ntients, researchers, regulators, industry professionals) have different roles and responsibilities in GenAI\nimplementation, ranging from ensuring patient safety and data security to driving innovation and regulatory\ncompliance, and may hold varying attitudes toward GenAI applications that influence their acceptance and\nutilization of these technologies. Failure to consider these diverse perspectives may hinder the widespread\nadoption and effectiveness of GenAI technologies."}, {"title": "2 RESULTS", "content": "The US CTSA network contains over 60 hubs. We sent email invitations to 64 CTSA leaders, each re-\nsponding on behalf of a unique CTSA site, with 42 confirming participation. Ultimately, we received 36\ncomplete responses, yielding an 85.7% completion rate. Only fully completed responses were included in\nthe analysis, as the six unfinished responses had 0-65% progress and were excluded. The survey questions\nare available in the Supplementary File A. Of the 36 completed responses, 15 (41.7%) represented only a\nCTSA, and 21 (58.3%) represented a CTSA and its affiliated hospital."}, {"title": "2.1 Stakeholder Identification and Roles", "content": "Figure 1 shows that senior leaders were the most involved in GenAI decision-making (94.4%), followed\nby information technology (IT) staff, researchers, and physicians. Cochran's Q test revealed significant\ndifferences in stakeholder involvement (Q = 165.9, p < 0.0001). Post-hoc McNemar tests (see Methods)\nwith Bonferroni correction showed senior and departmental leaders were significantly more involved than\nbusiness unit leaders, nurses, patients, and community representatives (all corrected p < 0.0001). Nurses\nwere also less engaged than IT staff (corrected p < 0.0001) (See Supplementary Table 1).\nWe further split our analysis based on whether institutions have formal committees or task forces overseeing"}, {"title": "2.2 Decision-Making and Governance Structure", "content": "The decision-making process for adopting GenAI in healthcare institutions varied (Figure 3). A centralized\n(top-down) approach was used by 61.1% (22/36) of respondents, while 8.3% (3/36) mentioned alternative\nmethods, such as decisions based on the tool's nature or a mix of centralized and decentralized approaches.\nThematic analysis of statements about governance structures in organizations with formal committees iden-\ntified two major themes (Figure 4). \u201cAI Governance and Policy\" reflects institutions' structured approaches\nto ensure responsible GenAI implementation. Institutions often establish multidisciplinary committees to"}, {"title": "2.3 Regulatory and Ethical Considerations", "content": "Regulatory body involvement in GenAI deployment varied widely across institutions (Figure 5). Federal\nagencies were engaged in 33.3% (12/36) of organizations. A significant portion (55.6%) identified other\nbodies, including institutional review boards (IRBs), ethics committees, community advocates, and state\nagencies. Internal governance committees and university task forces were also explicitly mentioned.\nRegarding ethical oversight (Figure 6), 36.1% (13/36) of respondents reported an ethicist's involvement\nin GenAI decision-making; 27.8% (10/36) mentioned an ethics committee, while 19.4% (7/36) reported\nneither, and 16.7% (6/36) were unsure. Ethical considerations were ranked based on importance (Figure 7),\nwith \"Bias and fairness\u201d (mean rank 2.31) and \u201cPatient Privacy\u201d (mean rank 2.36) being the top priorities."}, {"title": "2.4 Stage of Adoption", "content": "Institutions were at varying stages of GenAI adoption (Figure 8), with 75.0% (27/36) in the experimenta-\ntion phase, focusing on exploring AI's potential, building skills, and identifying areas for value addition.\nIntegrating existing systems and workflows was met with mixed responses (Figure 9), with 50.0% (18/36)\nrating it as neutral.\nWorkforce familiarity with large LLMs also varied (Figure 10), with 36.1% (13/36) of respondents report-"}, {"title": "2.5 Budget Trends", "content": "Regarding funds allocation for GenAI projects, 50.0% (18/36) of respondents reported that ad-hoc funding\nwas allocated mostly from institutions with formal committees (Figure 12). Most institutions without formal\ncommittees reported that no funds had been allocated for GenAI projects (62.5%; 5/8). Since 2021, 36.1%\n(13/36) of respondents were unsure about budget changes, 19.4% (7/36) noted the budget remained roughly\nthe same, and 44.5% reported budget increases ranging from 10% to over 300% (Figure 13)."}, {"title": "2.6 Current LLM usage", "content": "Institutions were adopting LLMs with varied strategies (Figure 14), with 61.1% (22/36) using a combination\nof both open and proprietary LLMs, 11.1% (4/36) using open LLMs only, and 25.0% (9/36) using propri-\netary LLMs only. Only 2.8% (1/36) reported not using any LLMs. Significant differences exist (Q = 28.7,\np < 0.0001) between the types of LLMs used. Post-hoc tests revealed significant differences between using\nopen and proprietary LLMs versus open LLMs only (corrected p = 0.0032) (See Supplementary Table 4),\nindicating a notable preference for combining different LLM types in some institutions. No significant\ndifferences were found among specific open or proprietary LLM types (Q = 2.4, p = 0.4936), suggesting\nthat institutions did not exhibit strong preferences between particular open or proprietary LLM models.\nInstitutions developing open LLMs prioritized technical architecture and deployment (61.1%), followed by\ncustomization and integration features (50.0%, Figure 15). Some institutions focused on research and exper-\nimentation, comparing open to proprietary LLMs, with interests in medical education and cost-effectiveness.\nTechnical architecture and deployment are prioritized over clinician or patient buy-in (corrected p = 0.0024)\n(See Supplementary Table 5).\nRegarding GenAI deployment (Figure 16), private cloud and on-premises self-hosting were the most com-\nmon approaches (both 63.9%), suggesting that most institutions have both approaches but do not take\na hybrid approach. Some institutions specified using local supercomputing resources or statewide high-\nperformance computing infrastructure. Statistical analysis (Q = 42.6, p < 0.0001) indicated a preference for\nmore controlled environments, with private cloud and on-premises self-hosting significantly more favored\nthan public cloud (corrected p = 0.0022 and p = 0.0060, respectively) (See Supplementary Table 6).\nFor institutions adopting proprietary LLMs, the critical factors for decision-making include technical ar-\nchitecture and deployment (61.1%), and scalability and performance (Figure 16). Respondents noted the\nimportance of ease of deployment, especially in partnerships with vendors like Epic Systems and Oracle, and\nthe advantage of existing Health Insurance Portability and Accountability Act (HIPAA) Business Associate\nAgreements with providers like Microsoft. Statistical analysis (Q = 57.4, p < 0.0001) revealed significant\ndifferences, particularly between technical architecture and deployment and monitoring and reporting and\nAI workforce development (both corrected p = 0.0113). Scalability and performance were significantly more\nprioritized than LLM output compliance and AI monitoring and reporting (corrected p-values = 0.0405) (See\nSupplementary Table 7).\nFinally, LLMs were applied across diverse domains, with common uses in biomedical research (66.7%),\nmedical text summarization (66.67%), and data abstraction (63.9%, Figure 17). Co-occurrence analysis\nshowed frequent overlaps in these areas (See Supplementary Table 8). Medical imaging analysis was the\nmost common use case for institutions without formal committees overseeing GenAI governance. Signifi-\ncant differences were observed in using LLMs for data abstraction compared to drug development, machine"}, {"title": "2.7 LLM Evaluation", "content": "Respondents prioritized accuracy and reproducible and consistent answers when evaluating LLMs for health-\ncare (Figure 18), each receiving the highest mean rating of 4.5 (See Supplementary Table 10). Healthcare-\nspecific models and security and privacy risks were also deemed important, though responses varied. An\nAnalysis of Variance (ANOVA) test revealed significant differences among the importance ratings (F = 3.4,\np = 0.0031). Post-hoc Tukey's honestly significant difference (HSD) tests showed a significant difference\nbetween accuracy, and explainability and transparency (p = 0.0299).\nRegarding potential roadblocks to adopting GenAI in healthcare, regulatory compliance issues were rated\nas the most significant concern, with a mean rating of 4.2 (Figure 19) (Mean Rating See Supplementary\nTable 11). While 'Too expensive' and 'Not built for healthcare and life science' were less of a concern, they\nstill posed challenges for some respondents, though there are no significant differences among these ratings\n(F = 2.0, p = 0.0606)."}, {"title": "2.8 Projected Impact", "content": "Participants rated the anticipated impact of LLMs on various use cases over the next 2-3 years (Figure 20),\nwith the highest mean ratings for natural language query interface, information extraction, and medical\ntext summarization (4.5 each), followed by transcribing medical encounters (4.3). Data abstraction (4.3)\nand medical image analysis (4.2) were also highly rated, while synthetic data generation, scheduling (3.5\neach), and drug development (3.4) received lower ratings (See Supplementary Table 12). Additional use\ncases, such as medical education and decentralized clinical trials, suggest an expanding scope for LLM\napplications.\nFurther, respondents reported increased operational efficiency (44.4%) as the most commonly observed im-\nprovement, with faster decision-making processes noted by 13.9% (Figure 21). However, none reported\nimproved patient outcomes. Other reported improvements included increased patient satisfaction and en-\nhanced research capacity, although some noted it was too early to prove such benefits. Significant differ-\nences among these improvements were observed (Q = 38.9, p < 0.0001), particularly between better patient\nengagement and improved patient outcomes (corrected p = 0.0026) (See Supplementary Table 13).\nRegarding GenAI implementation concerns (Figure 22), data security was identified as a major issue by\n52.78% of respondents, followed by a lack of clinician trust (50.0%) and AI bias (44.44%). Cochran's Q Test"}, {"title": "2.9 Enhancement Strategies", "content": "Respondents identified several strategies for testing and improving LLMs in healthcare, with human-in-\nthe-loop being the most common (83.3%, Figure 23). Significant differences were noted between human-\nin-the-loop and methods like quantization and pruning and Reinforcement Learning with human feedback\n(RLHF) 22 (corrected p < 0.005) (See Supplementary Table 14). Significant differences were found be-\ntween adversarial testing 23 and human-in-the-loop (corrected p < 0.0001) and guardrails and human-in-the-\nloop (corrected p = 0.0067) (See Supplementary Table 14).\nIn evaluating deployed LLMs (Figure 24), the most common assessments focused on hallucinations or\ndisinformation (50.0%) and robustness (38.9%). However, 19.4% (7/36) of respondents indicated no eval-\nuations had been conducted. Cochran's Q Test revealed significant variation in the importance of these\nevaluations (Q = 77.1, p < 0.0001), with post-hoc analysis showing significant differences between ex-\nplainability and prompt injection (i.e., a technique where specific prompts or questions are used to trick the\nGenAI into bypassing its specified restrictions, revealing weaknesses in how it understands and responds to\ninformation), and between fairness versus ideological leaning and prompt injection (corrected p = 0.0040)\n(See Supplementary Table 15).\nIntegrating GenAI into healthcare presents several challenges (Figure 25), with technical architecture and\ndeployment cited most frequently (72.2%). Interestingly, AI workforce development is the most common\nchallenge for institutions without a formal committee. Data lifecycle management was noted as a critical\nlimitation by 52.8% (19/36) of respondents. Challenges often overlap, with technical architecture and de-\nployment closely linked to security, scalability, and regulatory compliance issues. Additional gaps were\nalso highlighted, such as the absence of a training plan and a limited workforce. Significant variability was\nobserved (Q = 45.4, p < 0.0001), with post-hoc analysis indicating that technical architecture and deploy-"}, {"title": "2.10 Additional Insights into GenAI Integration", "content": "Nine respondents provided additional insights into the complexities of integrating GenAI into healthcare.\nThey emphasized the challenges posed by the rapid pace of technological change, which complicates long-\nterm investment and integration decisions. Organizational approaches to GenAI vary; some institutions\naggressively pursue it, while others have yet to implement it on a broader scale despite individual use.\nThe integration of GenAI has improved collaboration between researchers, physicians, and administrators,\nbut slow decision-making and a significant gap in AI workforce skills remain critical issues. The evolv-\ning nature of AI initiatives makes it difficult to fully capture current practices, highlighting the need for a\ncomprehensive approach that addresses technological, organizational, and workforce challenges."}, {"title": "3 DISCUSSION", "content": "This study provides a snapshot of GenAI integration within CTSA institutions, focusing on key stakehold-\ners, governance structures, ethical considerations, and associated challenges and opportunities. Table 1\nsummarizes the key recommendations from the findings. Senior leaders, IT staff, and researchers are\ncentral to GenAI integration, with significant involvement from cross-functional committees highlighting\nthe multidisciplinary collaboration required for effective implementation. However, findings suggest min-\nimal involvement of nurses, patients, and community representatives in the current GenAI implementation\ndecision-making process, which raises concerns about inclusiveness, which is essential to aligning tech-\nnologies with the needs of all stakeholders. 18,24 Most institutions adopt a centralized, top-down governance\nstructure, streamlining decision-making but potentially limiting flexibility for departmental needs. 25 While\nformal committees or task forces suggest emerging governance frameworks, the variability across institu-\ntions indicates that best practices are still evolving."}, {"title": "4 METHODS", "content": "4.1 Study Design\nThis study uses an online survey to conduct an environmental scan of GenAI infrastructure within CTSA\ninstitutions through multiple choice, ranking, rating, and open-ended questions to understand GenAI inte-\ngration, including stakeholder roles, governance structures, and ethical considerations.\n4.2 Survey Instrument Development\nThe survey, administered through the Qualtrics platform (Qualtrics, Provo, UT), was intended to take ap-\nproximately 15 minutes to complete. Initially developed through a comprehensive review of current litera-\nture on AI in healthcare, the survey covered topics such as stakeholder roles, governance structures, ethical\nconsiderations, AI adoption stages, budget trends, and LLM usage. The survey was reviewed by experts\n(SL, BM, KN, WP, RZ, YZ) in health informatics, clinical practice, ethics, and law, who provided feedback\nthat informed revisions to improve clarity and comprehensiveness. A small group piloted the final version\nto identify any remaining issues. The survey questions are available in the Supplementary File A.\n4.3 Participant Recruitment\nParticipants were recruited in July 2024 through targeted outreach to key stakeholders at CTSA sites us-\ning purposive and snowball sampling.40 Email invitations were sent to senior leaders involved in GenAI\nimplementation and decision-making within the CTSA network (), with follow-up reminders to maximize\nresponse rates.\n4.4 Data Collection\nData were collected from July to August 2024. CTSA leaders who responded to the initial invitation received\na follow-up email with the survey link. A PDF version of the survey was provided to help participants\nprepare by reviewing questions offline before completing the survey online. Participants could return to the\nsurvey if necessary.\n4.5 Data Analysis\nQuantitative data from the survey were analyzed using various methods. Multiple-choice and multiple-\nanswer questions were summarized with frequency distributions and percentages. In addition, multiple-\nanswer questions were also analyzed using co-occurrence and pattern analysis to identify common selections\nand combinations among stakeholder groups. Cochran's Q test identified overall differences among response\nproportions, with post-hoc analysis using pairwise McNemar tests with Bonferroni corrections.41 Ranking\nquestions were analyzed by calculating mean ranks, with lower mean ranks indicating higher importance.\nLikert-scale items were summarized using measures of central tendency and dispersion, with an ANOVA\ntest to check for significant differences in ratings across different use cases, followed by Tukey's HSD test\nfor post-hoc pairwise comparisons while controlling for the family-wise error rate.\nQualitative data from open-ended survey questions was analyzed using thematic analysis. 43 This process\ninvolved coding the data to identify common themes and patterns. Two researchers (BI, ZX) independently"}]}