{"title": "JUREX-4E: Juridical Expert-Annotated Four-Element Knowledge Base for Legal Reasoning", "authors": ["Huanghai Liu", "Quzhe Huang", "Qingjing Chen", "Yiran Hu", "Jiayu Ma", "Yun Liu", "Weixing Shen", "Yansong Feng"], "abstract": "The Four-Element Theory is a fundamental framework in criminal law, defining the constitution of crime through four dimensions: Subject, Object, Subjective aspect, and Objective aspect. This theory is widely referenced in legal reasoning, and many Large Language Models (LLMs) attempt to incorporate it when handling legal tasks. However, current approaches rely on LLMs' internal knowledge to incorporate this theory, often lacking completeness and representativeness. To address this limitation, we introduce JUREX-4E, an expert-annotated knowledge base covering 155 criminal charges. It is structured through a progressive hierarchical annotation framework that prioritizes legal source validity and employs diverse legal interpretation methods to ensure comprehensiveness and authority. We evaluate JUREX-4E on the Similar Charge Distinction task and apply it to Legal Case Retrieval, demonstrating its effectiveness in improving LLM performance. Experimental results validate the high quality of JUREX-4E and its substantial impact on downstream legal tasks, underscoring its potential for advancing legal AI applications.", "sections": [{"title": "1 Introduction", "content": "In legal AI tasks, enhancing the accuracy and interpretability of Large Language Models (LLMs) in the legal domain often requires the incorporation of legal theories as a support (Jiang and Yang, 2023; Servantez et al., 2024; Yuan et al., 2024; Deng et al., 2023). One important theory is the Four-Element Theory of Crime Constitution in Chinese criminal law (Liang, 2017). This theory deconstructs criminal conduct into four elements: Subject, Object, Subjective aspect, and Objective aspect, providing clear standards for judicial authorities to determine criminal behavior and helping to prevent the abuse of penal power.\nHowever, most current approaches do not provide additional knowledge but rather rely on the LLM's internal knowledge to incorporate the Four-Element Theory. A common method is to guide LLMs in mimicking expert reasoning processes. For example, designing four separate prompts to guide the LLM outputs in the form of four elements(Deng et al., 2023).\nThese methods assume that the model has a solid grasp of the Four-Element Theory, which has not yet been verified. We had LLMs generate the four elements of several complicated crimes in Chinese judicial practice(Ouyang et al., 1999), and then asked legal experts to score them. We found that, although LLMs can generate formally standardized and relatively accurate legal descriptions when provided with legal theoretical frameworks and references, the model still underperformed in terms of completeness and representativeness. This shortcoming could affect the accuracy and soundness of subsequent reasoning.\nTo help LLMs better utilize the Four-Element Theory in legal tasks, we propose JUREX-4E: JURidical Expert-annotated 4-Element knowledge base for legal reasoning. This knowledge base is annotated using a progressive hierarchy: Article \u2192 Judicial Interpretations \u2192 Guiding Cases \u2192 Academic Discourses, which is built upon the pyramid structure of legal source validity. It incorporates various legal interpretation methods, including textual, systematic, sociological, and purposive interpretations. The knowledge base covers the four elements of 155 high frequency charges, annotated by legal experts over a period of seven months. Each crime's four elements are described in an average of 472.5 words.\nTo assess the quality of the annotations, we sampled several crimes for human evaluation. The expert annotations achieved an average score of 4.60 on a 5-point scale, while the LLM-generated four elements scored only 3.96, indicating that the expert annotations were of higher quality. To further evaluate the annotations objectively and comprehensively, a direct way is to judge whether different charges can be distinguished according to the four-element definition of crime constitution. Therefore, we introduced the Similar Charge Distinction task (Liu et al., 2021). For each case, we provided the four elements of the candidate confused charges and combined them with the case facts as model input. The experimental results showed that injecting expert annotations helped the model better differentiate between similar charges, improving performance with a 0.65 increase in average accuracy and a 0.70 increase in average F1-score, underscoring the superior quality and reliability of expert annotations compared to those generated by the LLM.\nWe also applied the expert annotations in a specific legal task: Legal Case Retrieval. It is an important step in the practice of analyzing cases and making judgments, requiring the precise application of the four-element theory to compare the criminal composition of cases. We designed a simple retrieval framework guided by expert knowledge, in which the charge's four elements was used to generate four-element descriptions for both the query and candidate cases, and then match similar cases based on their vector similarity. Experiments demonstrated that incorporating expert-annotated four elements improved retrieval performance, as the model became better at focusing on the legal features and key details.\nOur contributions are as follows:\n(1) We verify that LLMs have gaps in understanding the legal theory, highlighting the inadequacy of relying solely on LLM-driven reasoning for legal AI tasks.\n(2) We built the JUREX-4E knowledge base, which is the first to incorporate the pyramid structure of legal source validity and covers the four elements of 155 criminal charges under Chinese Criminal Law.\n(3) We demonstrated the significance of incorporating criminal composition elements in the Similar Charge Distinction task and proved the superior quality of the expert-annotated four-element knowledge base.\n(4) We applied JUREX-4E to the Legal Case Retrieval task, found that they do indeed contribute to downstream tasks."}, {"title": "2 Related Work", "content": "In legal AI, much work has introduced legal theories to enhance reasoning and improve model accuracy and interpretability. For example, legal syllogism prompting (LoT)(Jiang and Yang, 2023) teaches LLMs for legal judgment prediction by instructing legal syllogism, Chain of Logic(Servantez et al., 2024) guides models in reasoning about compositional rules by decomposing logical statements based on the IRAC (Issue, Rule, Application, Conclusion) paradigm. Among these, the Four-Elements Theory (FET) of Crime Constitution is a widely adopted framework(Yuan et al., 2024; Deng et al., 2023).\nThe Four-Element Theory is one of the most widely recognized criminal theories in Chinese judicial practice (Liang, 2017). It specifies four essential elements that must be satisfied to establish criminal liability: Subject, Object, Subjective aspect, and Objective aspect. For example, the four elements of the Crime of Affray can be briefly summarized as follows:\n(1) Subject: Principal organizers and other active participants who have reached the age of criminal responsibility. (2) Object: Public order. (3) Objective Aspect: The act of assembling brawl, engaging in a brawl, resulting in the following consequences of serious injury. (4) Subjective Aspect: Direct intent, where the person knowingly and willfully engages in organizing or participating in the act of assembling brawl.\nBefore discussing the Four-Element Theory (FET), it is necessary to briefly compare it with another key theory in Chinese criminal law, the Hierarchical Theory of Crime Constitution(Zhou, 2017b; Zhang, 2010), and the main distinction between these theories lies in whether a hierarchical structure is considered, with ongoing debates in practice(Gao, 2009; Chen, 2010, 2017; Zhou, 2017a). We chose FET as our foundational template for following reasons: 1) its dominance in Chinese judicial practice aligns with real-world criminal judgments; (2) its clear distinction between objective aspects and subjective intent offers direct reasoning checkpoints compared to the Three-Tier Theory; (3) its four-element annotation is flexible and can be adapted to the Three-Tier Theory by prioritizing objective analysis before subjective evaluation(Li, 2006; Zhang, 2017).\nRecent approaches have leveraged the FET framework to model expert reasoning. For example, breaking down legal rules into FET-aligned components using automated planning techniques (Yuan et al., 2024). Employing model-generated four-element structures as minor premises in legal judgment analysis (Deng et al., 2023). While these methods have demonstrated improved performance on downstream tasks, they generally assume that the LLMs inherently understand the FET, without systematically validating this assumption. Notably, prior research on criminal charge prediction (An et al., 2022) suggests that the models may misinterpret key legal concepts and may not be sensitive enough to the subtle differences in fact descriptions of confusing charges, highlighting the need to incorporate expert annotations to support LLM reasoning."}, {"title": "3 Dataset Construction", "content": "Annotating the four elements of crime constitution is essentially a process of legal interpretation, which can be analyzed in two aspects:\n(1) What law is being interpreted. This involves identifying the sources of law, including statutory provisions corresponding to a specific charge, their associated judicial interpretations, case precedents, and academic discourses. In legal studies, these sources are categorized based on their legal validity into formal sources (which carry legal forces in judgments) and informal sources (which serve as references without legal forces)(Pound, 1925; Watson, 1982; Pound, 1932). Articles and judicial interpretations are considered formal sources, whereas case precedents and academic discourses are regarded as informal sources under the Chinese legal system(Zhang and Zhou, 2007).\n(2) How the law is interpreted. This pertains to legal interpretation methods, including literal interpretation, systematic interpretation, purposive interpretation, etc. These methods follow a hierarchical order in legal reasoning(Sutherland, 1891; Kim and Division, 2008; Eig Larry, 2014). Legal interpretation should begin with literal interpretation (textual analysis). If the intended meaning cannot be clearly derived from the article alone, systematic interpretation and purpose interpretation should be applied first. If ambiguity remains, historical interpretation and comparative law interpretation may be used to further clarify the legal meaning. The specific definition is in AppendixB.\nBased on these principles, our annotation follows a pyramid structure of Hierarchical Legal Interpretation System base on legal source validity. As shown in Figure 1, the system is divided into two parts: Legal Source and Legal Interpretation Methods. The main structure of legal source follows a hierarchical order of validity: Article \u2192 Judicial Interpretations \u2192 Guiding Cases \u2192 Academic Discourses, where various legal interpretation methods are applied across different levels. Thick arrows indicate the primary level at which a particular method is used, while thin arrows denote the cross applications."}, {"title": "3.2 Hierarchical Annotation Path of Legal Sources", "content": "Our Annotators are experts who have all passed the National Uniform Legal Profession Qualification Examination and are familiar with the Four-Element Theory. The entire annotation process took a total of 7 months and involved 4 rounds of annotation according to the validity of the legal source from high to low level.\nThe First Level: Article. Legal elements can be seen as an interpretation and refinement of the statutory provisions corresponding to a particular crime. Using literal interpretation as the primary method, the statute is broken down based on its semantic meaning and common usage, ensuring that the interpretation does not extend beyond the possible meaning of the text: (1) linguistic analysis follows the subject-predicate-object structure of the provision. (2) To maintain consistency, terms are systematically classified and mapped(e.g: subjective aspect is classified as either intentional or negligent. )(3) Only when it is impossible to make an explicit inclusion or exclusion judgment for an element based on the rules of language use (neutral option field), other interpretation methods should be used. This initial phase takes almost 2 months.\nFor example, in the crime of robbery, the object \"public or private property\" represents the protected legal interest. The phrase \"forcibly seizing public or private property through violence, coercion, or other means\" describes the objective aspect. Since no subject is specified, it is assumed to involve a general subject, and the adverbs \"violence\" and \"coercion\" indicate an intentional act. Preliminarily interpret 'violence' in the objective aspect as 'Use of physical force or power', but the specific forms and subjects of violence need further clarification.\nThe Second Level: Judicial Interpretation. In the 3rd and 4th months, the second level of the hierarchical annotation path focuses on refining legal elements through judicial interpretation. The primary method used for interpreting these materials is systematic interpretation. This approach examines the position of the corresponding articles within the legal system by analyzing their placement within the structure of laws, including parts, chapters, sections, articles, clauses, and subclauses, as well as their relationship to other statutes and judicial interpretations. Additionally, other interpretative methods, such as sociological interpretation and teleological interpretation, are referenced based on judicial interpretations, related statutory provisions, or bar exam questions.The goal of this level is to clarify the legislative intent by considering the contextual relevance of each provision within the broader legal framework.\nFor example, in the first level, the objective aspect of \"violence\" in the crime of robbery requires further clarification, specifically regarding whether violence must be directed exclusively at persons or could also apply to property. Article 289 of Chinese Criminal Law(Congress, 2017) stipulates that in cases of \"smashing, looting, and robbing\" committed by a group, the ringleaders shall be convicted of robbery if they destroy or seize public or private property. This provision demonstrates that violence against property can also constitute robbery under Chinese law.\nThe Third Level: Guiding Cases. In the 5th to 6th month, purposive interpretation and sociological interpretation are applied to the guiding cases and landmark judgments from the Supreme Court. By examining the social significance of real-world cases, these methods bridge the subtle gap between abstract legal theory and practical cases. This approach enables dynamic adaptation and integration of empirical insights and emerging controversies within the dataset.\nFor example, in Criminal Trial Reference Case No.159(Zou, 2002), the perpetrator lured the victim into a room, locked the door, and seized 170,000 RMB intended for a transaction. The court determined that although the detention did not endanger personal safety, it was sufficient to suppress the victim's resistance, thus constituting \"violence\" in in the objective aspects of robbery. Another example is the \"Molestation and Theft Case\" (Ma, 2021), where the perpetrator bound the victim, committed molestation, and stole the victim's phone. Since the ongoing molestation reinforced coercion, it constitutes a new act of violence. Thus, the annotation includes \"molestation\" as an additional method.\nThe Fourth Level: Academic Discourses. In the 7th month, the final stage involves academic expansion. Academic controversies are introduced by employing multiple interpretive methods such as comparative law interpretation, purposive interpretation, and sociological interpretation. These methods include inserting conflict markers at key points of controversy, highlighting the distinctions between mainstream consensus and minority theories, while providing brief annotations of their legal reasoning. This approach ensures the extensibility and academic depth of the dataset.\nFor example, regarding the crime of robbery, for the main view in China, Soviet Union, North Korea, and Japan explicitly holds that the violence must be severe enough to endanger the victim's life or health(Zhang, 2007). But some scholars argue that any violence that can forcibly impact the victim's body is sufficient to constitute violence in robbery, no need to endanger the victim's life or health(Yang, 2010)."}, {"title": "4 Data Distribution", "content": "As shown in Table 1, we compare the length of legal elements between expert-annotated descriptions in JUREX-4E and LLM-generated outputs across 105 charges that overlap with the Lecard-V2 dataset (Li et al., 2024c), which is one of the most comprehensive legal datasets, covering 184 criminal charges. We find that:\n(1) The average total length of expert annotations (472.53) is more than four times longer than that of LLM-generated outputs (115.43), indicating that the former include more detailed information.\n(2) The median difference between the Subject (SB), Object (OB), and Subjective Aspect (SA) is relatively small, as these elements are typically fixed. For example, the SB is often a general entity, and the SA is often intent or negligence.\n(3) The median and mean values for SB and SA in the expert annotations differ, especially for SB (17 v.s. 51.64). This discrepancy arises because certain specialized charges may require more detailed explanations. For example, in the crime of copyright infringement, the definition of \u201cwork\" under the subject element has 9 occasions. Detailed data distribution for each element is provided in Appendix A.\n(4) The main difference between Expert and LLM is in the Objective Aspect (342.5 v.s. 48.45 in Mean). This is because the OA includes a range of factual elements describing the criminal behavior, such as the conduct, object, result, time, and location, which are most emphasized in legal provisions and are central to various legal interpretive theories."}, {"title": "5 Human Evaluation", "content": "We selected 6 complicated crimes in Chinese judicial practice(Ouyang et al., 1999) to evaluate whether the LLM can handle the Four-element Theory. Drawing from previous work(Deng et al., 2023; Cui et al., 2024; Zhou et al., 2023), we define LLM-generated knowledge as information produced by the LLM based on its pre-trained knowledge and contextual prompts. For detail, we provide the LLM with legal articles and the definition of each element in FET, prompting it to generate the four-elements base on these metrical. The LLM is expected to autonomously identify and generate the four elements based on its learned understanding of legal concepts.\nWe invite legal experts to assess the four elements generated by the LLM from four dimensions: Precision, Completeness, Representativeness, and Standardization.\n\u2022 Precision: Whether the key components of each element are accurately identified. This dimension mainly evaluates whether the four elements faithfully represent the legal provisions.\n\u2022 Completeness: Whether all necessary information of each element is included. This assesses whether any essential content is missing, such as the omission of a description for specific subjects, like government officials.\n\u2022 Representativeness: Whether the annotations highlight the most critical scenarios in judicial practice. For example, in crimes of intentional injury, this would involve describing the representative means of harm.\n\u2022 Standardization: Whether the four elements are clearly defined, ensuring consistency in the expression of identical elements across different crimes (e.g., consistent description of general subjects), with concise and easily understandable explanations, free from legal ambiguities or misunderstandings.\nEach dimension was scored by two types of experts: one group with a pure legal background and another group with a combined background in law and Artificial Intelligence, all of whom have passed the bar examination. The experts were selected to balance domain expertise and interdisciplinary perspectives. Scores were averaged across the two groups. Details about 1-5 scale criteria and annotator background are provided in Appendix C.\nAs shown in Table 2, expert annotations consistently outperform LLM-generated elements across all four dimensions, highlighting the limitations of LLMs in understanding legal elements. The most pronounced deficiencies are observed in Completeness (+0.86) and Representativeness (+0.88). This suggests that while LLMs can generate formally standardized and relatively accurate four elements, their description are not specific enough and do not adequately reflect the representative features of a charge's criminal composition."}, {"title": "6 Evaluate Expert Knowledge on Charge Disambiguation", "content": "In the preceding section, the human evaluation demonstrated that experts annotated higher-quality four-elements. To further quantitatively evaluate the annotations, a direct way is to judge whether different charges can be distinguished according to the four-element definition of crime constitution. Therefore, we introduce the Similar Charge Disambiguation (SCD) task(Yuan et al., 2024; Li et al., 2024a)."}, {"title": "6.1 Experiment Settings", "content": "We chose the dataset released by (Liu et al., 2021), which includes five charge sets with the largest number of cases. To evaluate performance on representative tasks, we selected three 2-label classification groups commonly examined in other datasets (Yuan et al., 2024): Fraud & Extortion (F&E), Embezzlement & Misappropriation of Public Funds (E&MPF), and Abuse of Power & Dereliction of Duty (AP&DD). Each crime has over 1.9k cases, with a total of 13,962 cases. The details of the classification groups are shown in Appendix D. Following previous work (Liu et al., 2021; Yuan et al., 2024), we use Average Accuracy (Acc) and macro-F1 (F1) as evaluation metrics."}, {"title": "6.1.2 Baselines and Methods", "content": "To evaluate SCD tasks, we consider two ways of incorporating legal knowledge. The first directly integrates legal statutes, represented by GPT-40 (Achiam et al., 2023) as the baseline and GPT-40+Article, which explicitly provides relevant legal articles to the model. The second adopts structured legal reasoning to enhance interpretability and accuracy. We consider Legal-CoT, a Chain-of-Thought (Kojima et al., 2022) variant that conducts a stepwise analysis based on the FET, and MALR (Yuan et al., 2024), a multi-agent framework that decomposes legal tasks into sub-tasks in four-element structures. Details of each baseline are provided in Appendix D.\nWe use an unified approach to introduce four-element descriptions. For each group of similar charges, the model receives charges' four-elements from JUREX-4E or generated by LLM to aid classification. Specifically, GPT-40+FETExpert relies on expert-annotated four-elements, while GPT-40+FETLLM relies on LLM-generated four-elements. As shown in Appendix D, the instruction format is consistent across methods, with only the [Four Elements of candidate charges] varying based on the source. All experiments are conducted in a zero-shot setting, with the max_tokens set to 3,000 (or 10,000 for COT and MALR reasoning) and temperature set to 0 or 0.0001(In repeated experiments)."}, {"title": "6.2 Results", "content": "As shown in Table 3, the GPT-40+FETExpert performs best in discriminating similar charges, indicating that expert annotation is superior to other methods of directly or indirectly introducing FET with LLMs. Specifically, we can derive the following observation:\nEffectiveness of Domain-Specific Legal Knowledge: Among all approaches, those that explicitly incorporate domain-specific legal knowledge, such as GPT-40+Article, Legal-CoT, and MALR, outperform GPT-40 alone. This highlights the importance of integrating legal knowledge.\nImportance of Concrete Four-element Knowledge: The accuracy of both Legal-CoT and MALR is still lower than GPT-40+FET methods. This suggests that, compared to embedding the Four-Element Theory into LLMs' reasoning process, providing concrete charge four-elements enables the model to better understand the different crimes' composition.\nSuperiority of Expert Annotations: Compared with the indirect introduction of FET reasoning, the method of directly introducing four-elements to the model (GPT-4o+FET) achieves better results. Notably, GPT-40+FETExpert surpassing the GPT-40+FETLLM by 0.65 in average accuracy and 0.70 in average F1-score, underscoring the superior quality and reliability of expert annotations in legal tasks, aligning with human evaluations in Table 2 and reaffirming the critical role of human expertise in legal decision-making."}, {"title": "7 Can Expert Knowledge Benefit More Downstream Tasks?", "content": "In this section, we design a simple framework to apply the expert-annotated four elements to Legal Case Retrieval (LCR), a task in which relevant cases are retrieved based on given facts. It is an important step in the practice of analyzing cases and making judgments, and it requires the precise application of the four-element theory to matches cases with similar criminal compositions."}, {"title": "7.1 Method", "content": "We implement a standard dense retrieval approach BGE using BGE-m3 (Chen et al., 2023), an advanced embedding model for dense retrieval. Given a query q and a candidate case c, their vector representations $v_q$ and $v_c$ are obtained through shared encoder $E$: $v_q = E(q)$, $v_c = E(c)$. We used the BGE-m3 model without fine-tuning as the shared encoder. Next, the relevance score is computed via cosine similarity:\n$sim_{base}(q, c) = \\frac{V_qV_c}{||V_qV_c||\nTo retrieve the top-k most similar cases, we rank the candidates based on their cosine similarity to the query. Denote the set of candidate cases as $C = {C_1, C_2, ..., C_n}$, where n is the total number of candidate cases. We compute the similarity for each $c_i \\in C$, and select the top-k candidates with the highest similarity scores.\nAs shown in Figure 2, to leverages expert-annotated four elements of charges, we introduce an BGE+FETExpert_guided method for the retrieval process, consisting of three steps: (1) Predicting charges, a LLM $M_p$ predicts potential charges $Z = {1, ..., Z_k}$ from case facts. (2) Matching elements, retrieving corresponding charge's four-elements ${f_z}_{z\\in Z}$ in JUREX-4E. (3) Analyzing case facts. Guided by ${f_z}$, another LLM $M_g$ generates case-specific four elements $a_c$ for candidate c. The final similarity score combines factual and theoretical alignment:\n$sim_{final}(q, c) = \\alpha \\cdot sim_{base}(q, c) + (1-\\alpha) \\cdot sim_{f}(a_q, a_c)$\nwhere $\\alpha = 0.7$ and $sim_f$ measures the similarity between the generated four-element descriptions.\nTo facilitate comparison, we also design a BGE+FETLLM method that directly prompt the LLM $M_g$ with the concept of Four-Element Theory to generate case-specific four elements $a_c$."}, {"title": "7.4 Results", "content": "The LCR results are shown in Table 4, where we can observe that:\nFET Works Well in LCR. The baseline model BGE achieves strong performance across most metrics compared to previous methods. Introducing the Four-Element Theory (FET) further improves its results, with relative MRR improvements of 11.11% for FETLLM and 11.89% for FETExpert_guided, indicating that introducing legal theory is effective.\nExpert Knowledge is Necessary. By leveraging external knowledge, FETExpert_guided achieves significant improvements across all of the metrics. Specifically, using expert-guided case four-elements (FETExpert_guided-base) outperforms LLM-generated case four-elements (FETLLM-base) by an average of 11.77% in MRR, demonstrating the critical role of expert knowledge in enhancing retrieval precision. A case study in Appendix G shows that the expert four-element for charges provide practical judgment points and key narratives (e.g., the special subject of the Crime of Embezzlement) that help the LLM focus on essential facts to analyze the case.\nWe also evaluated the FET method on the full set, as shown in Table 9, and the results remain consistent, with the expert-guided method still performing best."}, {"title": "8 Conclusion", "content": "In this paper, we propose an expert-annotated knowledge base, evaluate its quality in the Similar Charge Distinction task, and apply it to the Legal Case Retrieval task. Our results demonstrate that expert annotations significantly enhance LLMs' understanding of the Four-Element Theory. The four-element annotations, enriched with professional legal interpretations, provide strong support for LLMs' reasoning capabilities. This approach can be extended to other legal AI tasks, such as legal document analysis and contract interpretation."}, {"title": "9 Ethical Considerations", "content": "The datasets used in our evaluation are sourced from publicly available legal datasets, with all defendant information anonymized to ensure privacy."}, {"title": "10 Limitations", "content": "As a limitation, this knowledge base focuses on the Four-Element Theory within the context of 155 crimes under Chinese Criminal Law. However, the four-level hierarchical pyramid annotation structure based on the legal interpretation system proposed in this work provides valuable insights for future expansion to other legal domains, as it represents a theoretical framework in the field of jurisprudence. The interpretative methods within the legal interpretation system, including textual, systematic, sociological, and doctrinal interpretations, are universally recognized in international law field and can be applied to different laws, countries, and legal systems."}, {"title": "B Interpretation Methods", "content": "1. Literal Interpretation\nA strict textual analysis method that adheres to the ordinary meaning of words as understood by a reasonable person at the time of enactment, excluding subjective intent inference\n2. Systematic Interpretation\nAn approach interpreting legal provisions through their position within the codified legal hierarchy and logical connections with related norms, maintaining the integrity of the legal system (aligned with Dworkin's \"law as integrity\" theory).\n3. Purposive Interpretation\nA method discerning the objective legislative purpose through analysis of statutory structure and functional goals, distinct from subjective legislative intent (following Hart & Sacks' legal process school).\n4. Historical Interpretation\nInterpretation based on legislative history materials including drafts, debates and official commentaries, while distinguishing original meaning from framers' subjective intentions (as per Brest's original understanding theory).\n5. Comparative Interpretation\nA methodology referencing functionally comparable legal systems sharing common juridical traditions, employing analogical reasoning while considering local legal culture (developed through Gottfried Wilhelm Leibniz's comparative law framework).\n6. Sociological Interpretation\nInterpretation evaluating social efficacy through empirical analysis of implementation effects, guided by Pound's sociological jurisprudence principle that \"law must be measured by its achieved results\"."}, {"title": "C Human Evaluation Guidance", "content": "The annotators included three postgraduate students specializing in criminal law and one master's student in legal science and technology. The annotators scored independently, without knowledge of each other's results. Before scoring, they were asked to read the descriptions and scoring guidelines (as shown in Table 5) for each evaluation dimension. In order to ensure the fairness of the evaluation, they do not know the source of each four elements, and even do not know that these four elements include those generated by LLMs.\nWhen assigning scores, they were also required to provide brief justifications. For example, for the Completeness dimension: 3 (The description of Objective Aspect is too brief, and does not specify the intent of illegal possession)."}, {"title": "D Details for Similar Charge Disambiguation", "content": "For LLM baselines, we evaluate both general-purpose and task-specific methods.\nGPT-40 is an optimized version of GPT-4(Achiam et al., 2023) that has well performance in specific tasks through domain adaptation.\nTo explore the effectiveness of notes-guided four elements in LLMs, we further consider other methods that introduced the Four-element theory into LLMs.\nGPT-40Law, which introduces articles related to corresponding charges into the instruction to provide legal context.\nLegal-COT is a variant of COT (Kojima et al., 2022) that guides the LLM to perform step-by-step legal reasoning by incorporating explanations of the Four-element theory into the instruction.\nMALR is a up to date multi-agent framework designed to enhance complex legal reasoning (Yuan et al., 2024), enabling LLMs to autonomously decompose legal tasks and extract insights from legal rules. As its full implementation is not publicly available, we use the released code for the auto-planner module and implement the legal insight extraction following the specified steps and prompts, with necessary refinements. Experiments on the paper's reported examples show that our implementation produces task decompositions and outputs largely consistent with the original results.\nAs shown in Table 8, different methods differ in their prompts for generating and explaining the Four-Element Theory, but generally follow a similar process. For the SCD output, except for COT and MALR, which require reasoning processes and prediction results, all other methods only require the output of prediction results."}, {"title": "E Baselines in Legal Case Retrieval", "content": "BERT(Devlin, 2018) is a language model widely used in retrieval tasks. In this paper, we chose"}, {"title": "GA Case Study of LCR", "content": "Table 10 presents a case study on the Crime of Embezzlement. By comparing the four elements annotated by experts for the crime in JUREX-4E, the case-specific four elements generated directly by the LLM, and those generated by the LLM with expert four elements of charge as guidance, we can observe that:\n1) Incorporating expert fine-grained annotations enables the model to better grasp the elements of a crime, thereby providing more precise element comparison. For example, LLMs can identify the \"integrity of official duties\", and the subjective aspect \"Intentional\" can be interpreted as \"having the purpose of illegally possessing public or private property\", highlighting the characteristics of \u201cofficial duties\u201d. Capturing the core information of the case is crucial for matching cases with similar facts.\n2) LLMs can conduct case-tailored specific analysis based on the constitutive elements of a crime. Blue parts show the LLMs can better analyze the defendant's workplace and the actions taken in the case, which reflects the significance of specific and accurate legal knowledge."}]}