{"title": "Model Checking in Medical Imaging for Tumor\nDetection and Segmentation", "authors": ["Elhoucine Elfatimi", "Lahcen El fatimi"], "abstract": "Abstract-Recent advancements in model checking have\ndemonstrated significant potential across diverse applications,\nparticularly in signal and image analysis. Medical imaging\nstands out as a critical domain where model checking can be\neffectively applied to design and evaluate robust frameworks.\nThese frameworks facilitate automatic and semi-automatic de-\nlineation of regions of interest within images, aiding in accurate\nsegmentation. This paper provides a comprehensive analysis of\nrecent works leveraging spatial logic to develop operators and\ntools for identifying regions of interest, including tumorous and\nnon-tumorous areas. Additionally, we examine the challenges\ninherent to spatial model-checking techniques, such as variability\nin ground truth data and the need for streamlined procedures\nsuitable for routine clinical practice.\n\nIndex Terms-Model Checking, Segmentation, medical images,\ntumor.", "sections": [{"title": "I. INTRODUCTION", "content": "Model checking is the process of verifying whether a given\nstructure satisfies a specified logical formula. This concept is\ngeneral and applies to a wide range of logics and system\ndesigns. A fundamental model-checking problem involves\ndetermining whether a propositional logic equation is satisfied\nby a given structure. Model checking is most commonly\napplied to hardware designs. For software systems, due to\nundecidability, the methodology cannot be fully algorithmic\nand may fail to either prove or disprove a given property.\nModel checking plays a critical role across various applica-\ntions, serving purposes such as ensuring the correctness of\nsystem properties and minimizing errors in software under\ndevelopment. Traditional model checking typically consists of\nthree major steps:\n\nFormal Model of the System: This step involves creating\na formal representation of the system in a language\ncompatible with the model checker's requirements.\nSpecification of System Properties: A specific property of\nthe system is defined for verification. This translates into\na question about the system's behavior that the model\nchecker is expected to answer.\nVerification by the Model Checker: The model checker\nevaluates whether the specified property is satisfied. If the\nproperty cannot be verified, a counterexample is gener-\nated to identify the source of the error in the simulation\nmodel."}, {"title": "II. RELATED WORK", "content": "A substantial body of literature explores model checking\nas a technique for various applications. In [15], the authors\nprovide a comprehensive survey and historical account of\nalgorithmic requirements for directed model checking. Their\nwork covers a wide range of topics, including bug-hunting\ntechniques to mitigate the state explosion problem, prioritiza-\ntion of successor selection, and the adaptation of algorithms\nto time-based automata and probabilistic domains. Similarly,\n[16] focuses on algorithmic verification in probabilistic model\nchecking, discussing various probabilistic models and their\nassociated algorithms, with an emphasis on their reliability\nand dependability.\n\nThe extensive review in [17] highlights model-checking\ntechnology as a powerful approach for the automatic verifica-\ntion of hardware systems. The authors identify other applica-\ntion domains, translating verification problems into appropriate\nmodel-checking questions. Additionally, [17] introduces a tax-\nonomy of models, properties, and model-checking approaches.\nIn [18], the formal verification of statecharts using model\nchecking is reviewed. A key observation in this work is the\nreliance of many statechart approaches on translating hierar-\nchical structures into flat representations of the input language,\nwhich poses scalability challenges due to exponential growth\nin the state space.\n\nModel checking for programmable logic controllers (PLCs)\nis comprehensively reviewed in [19], which highlights the\nimportance of real-time functionality in production settings.\nVerification of PLC software using model checking is deemed\ncritical in these scenarios. A theoretical overview by [20] ex-\namines the practical applications of model-checking schemes\nfor verifying multi-threaded software systems, with a focus on\nthe automata-theoretic method of verification and its associ-\nated challenges. Additionally, [21] surveys automata-theoretic\napproaches, focusing on the verification of probabilistic finite-\nstate systems concerning linear-time properties.\n\nSymbolic model checking is the subject of a detailed\nreview in [22], which discusses critical system design and\nmodel-checking techniques within the domain of information\nsciences. The review by [23] explores the verification of web\nservices using model checking, providing insights into data\nflow, requirements, and quality of service. This systematic\nreview encompasses fifteen years of literature on web service\nverification. Finally, [24] reflects on the authors' experiences\napplying model checking to verify the arbitration logic of a\nvehicle control system, identifying strengths and limitations of\ndifferent model-checking techniques and tools."}, {"title": "A. Spatio-temporal Model Checking for Medical Imaging", "content": "The application of model checking frameworks in a spatial\nsetting for medical imaging is a relatively new area of research,\nas evidenced by the limited number of publications in the field.\nHowever, the existing works, though few, are comprehensive.\nFor tumor detection, machine learning has been utilized to\nextract image features and validate them using spatio-temporal\nmodels [25], [26].\n\nIn [27], spatio-temporal meta-model checking was em-\nployed for analyzing biological processes, with a strong em-\nphasis on multi-scale aspects.\n\nWhen it comes to fully automated approaches, machine\nlearning-based techniques, particularly deep learning, have\nhad a profound impact. Deep learning is highly effective\nin modeling the non-linearities inherent in data to derive\nmeaningful insights [28].\n\nFor in vivo images, manual segmentation remains a standard\npractice [13]. However, it has several disadvantages. Man-\nual segmentation demands significant focus and time from\nclinicians, making the process labor-intensive and expensive.\nAdditionally, it requires a high level of expertise and is prone\nto subjectivity, resulting in variability among clinicians and\nintroducing errors into the pipeline [13].\n\nWhile machine learning and deep learning approaches have\ndemonstrated remarkable success in detection, classification,\nand pattern recognition tasks, their effectiveness heavily de-"}, {"title": "B. Techniques used with model checking for analyzing the\nmedical image", "content": "Many techniques are used with Model Checking in the\nanalysis of medical images, the most important of which\nis Texture analysis, which has also found its application in\ndynamic contrast-enhanced MRI of breast imaging for the\ndetection of and segmentation of malignant lesions [39]. In\naddition to that, there is extensive work on computer-aided\ndiagnosis and segmentation using texture-based analysis [40],\nincluding diagnosis of pulmonary nodules [41]. Classification\nand segmentation using texture-primitive features in medical\nimaging have historically been an area of in-depth exploration.\nExtensive works of [42], [43], [44] have demonstrated the use\nof texture analysis for classification.\n\nTexture analysis requires that the image textures be charac-\nterized by some quantitative measure. For that reason, certain\ndescriptors are estimated to quantify these textural features\n[34]. A typical classification of these types of features includes\nsyntactic, spectral and statistical [36].\n\nIn [34], the authors focused on first order statistical features\nprimarily which entails extracting certain statistical descriptors\nfrom the distributions of features of each voxel. These first-\norder statistical features mainly consisted of statistics based on\nprobability density functions of the intensity of voxels in the\nimage. These could then be estimated as histograms by binning\nvoxels values of the same intensities. Statistical features on\nthe first order include the mean, variance, skewness, kurtosis, and\nentropy [45]. The advantage of using these statistical features,\nspecifically in medical imaging is that they are invariant to\ntransformations of the image. By construction, these first-order\nstatistical operators are invariant to affine transformations that\nconsist of rotation and scaling. This kind of transformation is\ncritical in medical applications due to the variance involved\nin different image acquisition conditions. However, while this\nvariance of first-order statistical descriptors is plausible, they\nalso have a critical limitation which is their lack of spatial\ncoherence. The features assume a degree of independence\nby ignoring the relative spatial placement of the voxels in\nthe image. In the experimentation done in [34], the authors\ndefined a logical operator to compare the areas of the image\nwith a degree of statistical similarity to a pre-determined area.\nThe idea is to search for sub-areas in the image with an\nempirical distribution similar to the predetermined area. For\nthat purpose, some surrounding areas are also considered and\na threshold is applied so as to obtain a Boolean value that\nconfirms the voxel's statistical similarity to the sub-region.\nA measure for comparison for a statistical distribution used\nis cross-correlation [34]. As a result, the authors generalize\nthe classical texture analysis making use of some spatial\ninformation owing to the examination of neighborhood distri-\nbution when investigating a particular voxel. The framework\nis implemented by the authors on an MR image slice of a\nbrain affected by glioblastoma tumor [34]. In [13], the authors\nproposed an approach for segmentation based on a spatial\nlogic method. The goal was to identify a region of interest\nin MR images for the analysis of glioblastoma as well as\nother tumors. The authors employed a texture-based method\nalong with local histograms to create a hybrid approach for\nsegmentation, maintaining relative spatial information. This is\nprimarily inspired by a topological approach interwoven with\nspatial logic.\n\nIn this domain of research, works of [32] and [46] have"}, {"title": "C. The Spatial Logic Framework: VoxlogicA and SQL", "content": "One of the most important frameworks for image analysis\nusing the model Checking is VoxLogic, which is a framework\nfor image processing that incorporates user-oriented expres-\nsion languages into the logic ImgQL to edit images[51], this\ntool takes advantage of the library of computational imaging\nalgorithms alongside distinct combinations of the declara-\ntive specification to deliver optimized execution inherent to\nthe spatial logic model checking. As a consequence, the\nmethodology developed is considered to be rapid. Testing this\nmethodology on existing brain tumor segmentation benchmark\nimages shows that the accuracy can reach the state of the art.\nThe additional advantage is the explainability and replicability\nof the approach [51].\n\nThe fundamental idea of Spatio-temporal model checking\nis to use the specifications in a relevant logical language in\norder to describe the spatial characteristics so that patterns and\nstructures of key importance can automatically be identified.\nIn [51], the main focus is on medical imaging for radiotherapy,\nparticularly, brain tumor segmentation. A challenge in this\ndomain is that the tumorous regions or lesions are only defined\ndistinctively from the normal tissue, owing to any changes in\nthe intensities of the pixels in the gray-scale images. This\nrelativity of pixel intensity as a marker of tumor presence\nmakes it a complex challenge to isolate the lesions from\nnormal tissue pixels. In addition to that, there is a considerable\nvariation in the ground truth images of these segmented\nimages. This is due to the variance in the manual segmentation\nby the experts. When there are intensity gradients between\nadjacent tissue structures, the experts have shown significant\nsubjectivity in the assessment of ground truth for segmenting\ntumors [51]. This adds to the already challenging constraint\nof isolating tumors from normal tissues in gray-scale images\nbased on intensities as a metric. Furthermore, the inconsis-\ntency in the data complicates things further as different MRI\nscanners also show considerable variation in the image quality.\nHowever, for demonstration of the approach, the authors use\nthe publicly available BraTS 2017 dataset [6] where ground\ntruth data is available for any objective deductions; reporting\naccuracies competitive with the state-of-the-art techniques for\nglioblastoma segmentation.\n\nThe authors build on the image query language(SQL) that\nwas proposed in [13]. This was in turn based on the spatial\nlogic for closure spaces [46]. It is from [46] that the authors\nin [51] derive their kernel for their framework. The work in\n[51] is closely related to the spatial logic for closure spaces\npresented in [13], particularly with regard to the distance-\nbased operator formed therein. For the digital image analysis,\na statistical similarity operator is used that quantifies the\nsimilarity of an area around a point with that of a given region.\nThis is achieved by the computation of respective histograms\nand then finding cross-correlation between them. This operator\nallows checking to what extent the area around a point of\ninterest is statistically similar to a given region.\n\nAnother operator introduced is the percentile operator which\ntakes a numeric-value-based image and its binary mask in\norder to return an image that shows at how each point is"}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "Model checking in medical imaging remains an active area\nof research. The use of spatial model checking for verifying\nand validating spatial logic designs plays a critical role in\nidentifying and segmenting various types of tissues in the\nbody. However, significant challenges persist, particularly in\nthe technical development of frameworks and the explainabil-\nity and reproducibility of methodologies within the model-\nchecking domain. The existing literature demonstrates that\nmodel checking is an effective tool not only for detecting\ntumorous tissues but also for distinguishing between different\nhealthy tissues with notable accuracy. Despite these achieve-\nments, there remains considerable room for improvement, as\nmuch of the existing research focuses on specific applications.\nMoving forward, we aim to advance model-checking tech-\nniques for medical image analysis, with a particular focus on\napplying these methods to 3D imaging."}]}