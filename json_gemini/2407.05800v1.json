{"title": "FedMRL: Data Heterogeneity Aware Federated\nMulti-agent Deep Reinforcement Learning for\nMedical Imaging", "authors": ["Pranab Sahoo", "Ashutosh Tripathi", "Sriparna Saha", "Samrat Mondal"], "abstract": "Despite recent advancements in federated learning (FL) for\nmedical image diagnosis, addressing data heterogeneity among clients\nremains a significant challenge for practical implementation. A primary\nhurdle in FL arises from the non-IID nature of data samples across\nclients, which typically results in a decline in the performance of the\naggregated global model. In this study, we introduce FedMRL, a novel\nfederated multi-agent deep reinforcement learning framework designed\nto address data heterogeneity. FedMRL incorporates a novel loss func-\ntion to facilitate fairness among clients, preventing bias in the final\nglobal model. Additionally, it employs a multi-agent reinforcement learn-\ning (MARL) approach to calculate the proximal term ($\\mu$) for the per-\nsonalized local objective function, ensuring convergence to the global\noptimum. Furthermore, FedMRL integrates an adaptive weight adjust-\nment method using a Self-organizing map (SOM) on the server side\nto counteract distribution shifts among clients' local data distributions.\nWe assess our approach using two publicly available real-world med-\nical datasets, and the results demonstrate that FedMRL significantly\noutperforms state-of-the-art techniques, showing its efficacy in address-\ning data heterogeneity in federated learning. The code can be found\nhere https://github.com/Pranabiitp/FedMRL.", "sections": [{"title": "1 Introduction", "content": "Deep learning (DL) algorithms have demonstrated significant achievements in\nmedical image analysis tasks [15], [19], [18], [17]. However, creating effective DL-\nbased models typically requires gathering training data from various medical\ncenters, such as hospitals and clinics, into a centralized server. Obtaining pa-\ntient data from multiple centers presents challenges due to privacy concerns, le-\ngal restrictions on data sharing, and the logistical difficulty of transferring large\ndata volumes [20]. Researchers have increasingly employed Federated Learn-\ning (FL) as a solution, enabling medical image classification with decentral-\nized data from multiple sources while preserving privacy [25], [3]. Unlike models\ntrained independently at individual sites, FL can leverage a more diverse and\nextensive dataset, resulting in improved performance and increased generalizabil-\nity [13], [11]. The efficacy of federated training encounters challenges due to data\nheterogeneity within local hospital datasets, resulting in performance degrada-\ntion in real-world healthcare applications. This heterogeneity manifests in vari-\nous forms: some hospitals may possess more data from patients at early stages,\nwhile others primarily collect data from patients with severe conditions, lead-\ning to label distribution skew. Additionally, variations in data quantity among\nhospitals, with larger institutions having more patient data compared to commu-\nnity clinics, contribute to quantity skew. Moreover, differences in imaging acqui-\nsition protocols and patient populations further exacerbate feature distribution\nskew [24]. FedAvg, a foundational FL algorithm, while successful in many scenar-\nios, exhibits diminished efficacy in heterogeneous data settings [13]. To address\nthis challenge, FedProx [8] introduced a proximal term ($\\mu$) into the conventional\noptimization objective to penalize large updates in the model parameters. How-\never, selecting an optimal value for the proximal term $\\mu$ in FedProx presents\na challenge, as traditional methods like trial and error or heuristics may not\neffectively adapt to heterogeneous data distributions.\nDistribution shifts within each hospital's private dataset often result in sce-\nnarios where the global model performs better for certain hospitals but neglects\nothers. The study [9] introduced q-fairness optimization problems in FL, where\nthe parameter q guides the loss function to desirable outcomes. Huang et al. [6]\nfocused on fairness and robustness by dynamically selecting local centers for\ntraining, but this approach may not be suitable for the medical domain due to\nlimited participant hospitals. Lyu et al. [12] proposed a collaborative fair FL\nframework to enforce convergence to different models, addressing fairness dif-\nferently. Another challenge is that existing methods commonly train the global\nmodel by minimizing the average training losses of all local clients [13], [10], [22].\nHowever, these approaches lack performance guarantees for individual hospi-\ntals as they prioritize average training results, leading to divergent performance\nacross participants [8]. This issue is exacerbated in real-world scenarios where\ndata from medical centers differ in size and distribution [4]. Motivated by the\naforementioned challenges, we introduce FedMRL, a novel framework that ad-\ndresses these issues through three distinct components. Our main contributions\nare:\n The FedMRL framework introduces a novel method for calculating adaptive\n$\\mu$ values by leveraging the QMIX algorithm from Multi-agent Reinforcement\nLearning (MARL). This approach accounts for client-specific factors such as\ndata distribution, volume, and performance feedback, facilitating dynamic\nregularization adjustments during FL training.\n We propose integrating a novel loss function into the local objectives of each\nclient to foster fairness among them. This aims to minimize the disparity"}, {"title": "2 Problem Statement", "content": "Assuming there are H hospitals, each represented by h\u2208 [1, 2, \u2026\u2026\u2026, H], and pos-\nsessing privately labeled data denoted by $D^h$, the aim is to train a generalized\nglobal model over the combined dataset $D = \\cup_{H-1}D^h$. The global objective\nfunction is represented in Eq. 1.\n$\\arg \\min_{W} L(w) = \\sum_{h=1}^{H} \\sum_{\\frac{n}{D}} L_h(w)$\n(1)\nThe local objective function $L_h(w)$ in client h, which quantifies the local empir-\nical loss over the data distribution $D^h$, is represented in Eq. 2.\n$L_h(w) = E_{x \\sim D^h} [l_h(W; x)]$\n(2)\nIn this context, $l_h$ denotes the loss function utilized by client h, and w represents\nthe global model parameters. While the above fixed weighted averaging method\noffers an unbiased global model estimation in the presence of independent and\nidentically distributed (IID) training samples across clients, non-IID distribu-\ntions, stemming from device and user heterogeneity, lead to slower convergence\nand reduced accuracy [26]. To address this challenge, we propose FedMRL, in-\ntegrating a novel fairness term into the local objective function, dynamically\ndetermining the proximal term for each hospital through a MARL-based ap-\nproach, and employing a self-organizing map-based aggregation method at the\nserver. The final local objective function is represented as shown in Eq. 3.\n$\\arg \\min_{W} L(w) = \\sum_{h=1}^{H} \\frac{D^h}{|D|} Ln(w) + \\frac{\\mu}{2} ||w - w^t||^2 + L_{fair}(w)$\n(3)"}, {"title": "3 Proposed Framework", "content": "In this section, we provide a comprehensive overview of our proposed approach\nFedMRL, which consists of three contributions such as calculating adaptive per-\nsonalized $\\mu$ Value, novel loss function, and server-side adaptive weight Aggrega-\ntion using SOM. The overall algorithm is represented in Algo. 1. The architecture\ndetails are shown in Fig. 2."}, {"title": "3.1 Adaptive Personalized u Value", "content": "For the dynamic adaptation of the proximal term $\\mu$, we frame it as a multi-agent\nreinforcement learning problem, with each hospital h having an agent on the\nserver side. Each agent h observes its state $s_i$ from the overall environment state\n$S_t$, selects an action $a_i$ based on the current policy $\\pi_\\tau$, and the agents' actions\ncollectively form the joint action A. The environment transitions to the next\nstate $s_{i+1}$ according to the state transition function $P(s_{i+1}|s_i, a_i)$, iterating until\ncompletion or predefined criteria are met. In the proposed work, we integrate\nQMIX [16], a prominent Q-learning algorithm for cooperative MARL in the de-\ncentralized paradigm that represents an advancement over Value-Decomposition\nNetworks (VDN) [21]. Essentially, VDN assesses the influence of each agent on\nthe collective reward, assuming that the joint action-value function $Q_{tot} (s, a)$ can\nbe decomposed into N Q-functions for N agents, with each Q-function relying\nsolely on local state-action history, represented in Eq. 4.\n$Q_{tot} (s, a) = \\sum_{j=1}^{N}Q_j (S_j, a_j, \\theta_j)$\n(4)\nState: The state of the environment at round t is $s_t = [s_{t,1}, s_{t,2},\u2026\u2026, s_{t,h}]$ repre-\nsents the data distribution among clients and performance feedback $s_{t,i}$ is defined\nin Eq. 5.\n$s_{t,i} = (E_c, P_c, acc_c, loss_c)$\n(5)"}, {"title": "3.2 Loss Function", "content": "Our proposed novel loss function in FedMRL effectively mitigates the impact of\ndistribution shifts in hospitals' datasets, ensuring fairness and consistent perfor-\nmance across all participating institutions. By incorporating a fairness term into\nthe local objective function of individual hospitals, FedMRL adjusts model pa-\nrameters to achieve uniform training loss across all H hospitals, inspired by the\nMean Square Error (MSE) loss function commonly used in regression models.\nThe fairness term is formulated as an optimization problem aiming to minimize\nthe sum of squares of differences in loss between each of the H hospitals and the\nglobal loss, as presented in Eq. 12.\n$L_{fair} = \\sum_{h=1}^{H} (F_h(W) - F(w))^2$\n(9)"}, {"title": "3.3 Server side Weight Aggregation", "content": "FedAvg uniformly averages client model updates, neglecting individual data dis-\ntributions, which can impede performance in non-IID scenarios. In contrast,\nSOM-based weight adjustment considers client model similarity to the global\nmodel, significantly impacting clients with more representative data [7]. This\nadaptivity effectively addresses non-IID distribution challenges, allowing per-\nsonalized adjustments based on model-global similarity, thus enhancing perfor-\nmance for clients with unique data distributions. We initialize the SOM grid\nshape as (5,5), and its weights are randomly initialized. Distances between the\nSOM weights and each hospital's local weights determine the Best Matching Unit\n(BMU) on the SOM grid. The influence of local weights on each SOM neuron\nis calculated based on its distance to the BMU and current sigma value, updat-\ning the neuron weights accordingly. Weights for each local model are computed\nfrom the SOM weights and similarity metrics, ensuring accurate representa-\ntion through normalization. Cosine similarity metrics between local and global\nmodels, combined with distances, determine weights($a_i$) for each local model,\nfavoring higher similarity for increased weight. During SOM weight updates,\nthe influence of each local model scales by its similarity metric, with higher\nsimilarity models exerting greater impact. Normalized similarity metrics ensure\nproportional weighting, are responsive to changes in local models over time, and\nmaintain fairness in highly non-IID data settings. The aggregation is performed\naccording to Eq. 10, where $w^{t+1}$ denotes the global model parameters for the"}, {"title": "4 Dataset and Experimental Results", "content": "In this section, we present the datasets used for the experiment and the experi-\nmental results of the proposed FedMRL."}, {"title": "4.1 Datasets", "content": "We have chosen two distinct benchmark datasets pertinent to real-world medical\ncontexts to evaluate the effectiveness of our proposed FedMRL framework for\nhighly heterogeneous scenarios. The ISIC 2018 dataset, notable for its contribu-\ntions to skin cancer detection, provides a diverse array of dermoscopy images\ncaptured from various anatomical regions. This dataset encompasses 7,200 im-\nages categorized into 7 distinct classes [1]. Additionally, we utilized the Messidor\ndataset [2], consisting of 1,560 authentic fundus images tailored for grading di-\nabetic macular edema across five severity levels. Both datasets were partitioned\ninto 80% for training and 20% for validation to ensure robust evaluation."}, {"title": "4.2 Implementation Details", "content": "We construct non-IID data partitions following the methodology outlined in [14].\nUsing 80% of each dataset for training purposes, we organize the data based\non their labels and segment each class into 200 shards. Subsequently, clients\ncreate local datasets by sampling from these shards according to the probabilities\nrepresented in Eq. 11.\n$pr(x) =\n\\begin{cases}\n\u03b7\u2208 [0,1], & \\text{if } x \u2208 \\text{class } j,\\\\\nN(0.5,1), & \\text{otherwise}.\n\\end{cases}$\n(11)\nThe client samples from a specific class j with a constant probability \u03b7, while\nsamples from other classes follow a Gaussian distribution. Higher \u03b7 values in-\ndicate a greater concentration of samples in a specific class, resulting in more\nheterogeneous datasets. We have used \u03b7 = 1.0 for the experiment to access the\nperformance of FedMRL. Following [23], We employ DenseNet121 [5] as the back-\nbone. For Fedprox, we selected the proximal term u from the set 0.001, 0.1, 0.4,\nand for Fednova, we chose the proximal SGD value from the set 0.001, 0.1, 0.2\nto yield the best results."}, {"title": "4.3 Comparison with State-of-the-arts", "content": "To assess the efficacy of the proposed FedMRL methods, we compare them\nagainst four baseline approaches: FedAvg, FedProx, FedNova, and FedBN. Ta-\nble 1 presents the results of all the models in terms of Accuracy (ACC), Area\nunder the ROC Curve (AUC), Precision (Pre), Recall, and F1-score (F1). The re-\nsults highlight FedMRL's superior performance over baseline algorithms, demon-\nstrating significant accuracy improvements across both datasets. Specifically,\nFedMRL outperforms state-of-the-art methods by 0.92%, 0.81%, 7.64%, and\n2.43% for the ISIC-2018 dataset, and by 3.59%, 1.43%, 13.65%, and 3.59% for\nthe Messidor dataset, compared to FedAvg, FedProx, FedNova, and FedBN,\nrespectively. These improvements benefit from our FedMRL scheme, which ex-\nplicitly takes advantage of MARL to learn the data heterogeneity in the network\nand adaptively optimize the local objective of clients. Additionally, our novel loss\nfunction promotes fairness among clients, while the SOM-based adaptive weight\nadjustment method for aggregation enhances convergence to a better global op-\ntimum."}, {"title": "5 Conclusion", "content": "This study addresses the challenge of data heterogeneity in federated learn-\ning while ensuring fair contributions from the decentralized participants. Our\nframework demonstrates robustness to non-IID data distribution across clients\nand outperforms existing benchmarks in two medical datasets. While effective\nin mitigating the challenges posed by non-IID data distributions, FedMRL may\nencounter scalability issues when dealing with a large number of clients. Fur-\nthermore, the computational overhead associated with calculating personalized\n$\\mu$ values and performing server-side adaptive weight aggregation using SOM may\nimpose additional computational burdens, particularly in resource-constrained\nenvironments. In future work, we envision exploring distributed computing and\nresource-sharing models to alleviate the computational burden and aim to en-"}, {"title": "6 Proof of Proposed Loss Function", "content": "When all H hospitals exhibit identical training loss, the optimal solution for the\nfairness term emerges. To demonstrate this, we minimize $L_{fair}$. Subsequently, we\nelaborate on the mathematical representation of the fairness term. Further, we\ndiscuss the enhancement in performance resulting from integrating the fairness\nterm into the local training loss, as described by Eq. 12.\n$L_{fair} = \\sum_{h=1}^{H} (F_h(W) - F(w))^2$\n(12)"}]}