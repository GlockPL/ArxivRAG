{"title": "ComposeOn Academy: Transforming Melodic Ideas into Complete Compositions Integrating Music Learning", "authors": ["HONGXI PU", "FUTIAN JIANG", "ZIHAO CHEN", "XINGYUE SONG"], "abstract": "Music composition has long been recognized as a significant art form. However, existing digital audio workstations and music production software often present high entry barriers for users lacking formal musical training. To address this, we introduce ComposeOn, a music theory-based tool designed for users with limited musical knowledge. ComposeOn enables users to easily extend their melodic ideas into complete compositions and offers simple editing features. By integrating music theory, it explains music creation at beginner, intermediate, and advanced levels. Our user study (N=10) compared ComposeOn with the baseline method, Suno AI, demonstrating that ComposeOn provides a more accessible and enjoyable composing and learning experience for individuals with limited musical skills. ComposeOn bridges the gap between theory and practice, offering an innovative solution as both a composition aid and music education platform. The study also explores the differences between theory-based music creation and generative music, highlighting the former's advantages in personal expression and learning.", "sections": [{"title": "1 INTRODUCTION", "content": "Music composition has long been recognized as a significant and widely appreciated art form. With the advent of the digital age, there has been a growing desire among individuals lacking formal musical training to express themselves through music creation. This demand has driven the development of various digital audio workstations (DAWs) and music production software. However, despite technological advancements, many existing tools still present substantial barriers to entry and fail to adequately address the needs of novice users.\nCurrent systems and software often fall short of providing sufficient support for novice users in music composition. Traditional DAWs, while powerful, can be overwhelmingly complex for learners with limited musical skills [25]. These tools typically require users to possess a solid foundation in music theory, familiarity with musical notation, and proficiency in navigating intricate software interfaces. This complexity gives rise to three primary challenges. Firstly, the high technical threshold makes it difficult for beginners to master these tools [27]. Secondly, existing tools often struggle to effectively translate novice users' creative ideas into musical compositions [14]. Lastly, these software applications frequently fail to effectively impart additional music theory knowledge to users [48]. Collectively, these factors contribute to a significant gap between individuals' desire to create music and their actual ability to do so, particularly for those without formal musical training [49]. This disparity not only impedes personal creative expression but may also potentially diminish the diversity and innovation in music creation [5]. Consequently, the development of more intuitive, user-friendly, and learning-supportive music creation tools has emerged as a crucial research direction [25].\nTo address this challenge, we present ComposeOn, a music theory-based tool designed specifically for users with little to no music knowledge. ComposeOn empowers users to easily extend and develop their melodic ideas into complete compositions. Additionally, the tool offers easy editing, which allows users to effortlessly edit and control their music creations. By integrating music theory, ComposeOn explains the music creation from the music theory perspectives in three different levels: beginner, intermediate, and advanced.\nOur user study (N=10) compared participants composing music using ComposeOn and the baseline method, Suno AI, to explore the effectiveness of ComposeOn in helping novice users create music. The results show that ComposeOn provides a more accessible and enjoyable composing and learning experience for individuals with little musical skill.\nIn our discussion, we explored how Compose On leverages music theory to enhance music creation for beginners. Unlike generative AI tools, ComposeOn provides a structured, educational approach, encouraging users to actively engage with musical concepts. The tool's melody input feature allows users to develop their ideas into complete compositions, fostering creativity and personal expression. Additionally, ComposeOn's multi-tiered explainability enhances learning by offering tailored insights into music theory, promoting deeper understanding and critical thinking."}, {"title": "2 RELATED WORK", "content": "2.1 Compose Theory\nComposeOn promotes people without a music background to compose their own music. We design the system to detect melody users put in and give suggestions for continuations based on basic music and harmony progression theory.\n\"Western music written during Baroque, Classical, and Romantic periods (ca.1650-ca.1900) is called tonal music, which has a point of gravitation called tonic.\" [23] The keys and scales gradually formed based on that and thus formed tonal hierarchy and harmony function theory.\n\"The music of the tonal era is almost exclusively tertian, which means being constructed of stacked 3rd.\" [21] Chords are marked with their root notes (where the stack begins) using roman numerals. Functionally, they are basically divided into Tonic chords: I, Dominant chord: V, and predominant/subdominant chords: ii, iv, vi. The harmony often progresses as Tonic-Subdominant-Dominant-Tonic. Sometimes may use iii or Vii, and different 7th chords, but their function is various depending on the texture [3].\nThere are also uses out of this basic progression, such as sequence, modulation or transportation. We also considered those situations with limited possibilities within our database.\nBased on the above theory, we suggest notes within the key and the possible harmony progressions. As to music phrases, we followed basic 2+2/4+4 (refer to measure numbers) to form the music phrase and thus sentence and sections. [39] We mainly focus on songwriting, so the intro, verse \u2013 chorus \u2013 verse \u2013 chorus -bridge \u2013 chorus \u2013 outro structure of song is also being considered. [1]\n2.2 Voice to MIDI Technology and Its Applications\nMIDI (Musical Instrument Digital Interface) is a technical standard that describes a protocol, digital interface, and connectors, allowing various electronic musical instruments, computers, and other related devices to connect and communicate with each other [31]. Voice to MIDI technology is the process of converting vocal or other audio signals into this MIDI data format, playing a crucial role in music production and analysis. This technology involves multiple steps, including pitch detection, note segmentation, quantization, and MIDI conversion. Pitch detection typically employs algorithms such as YIN [11] or pYIN [30] to estimate the fundamental frequency of audio. Subsequently, the continuous pitch sequence is segmented into discrete notes, which are then time-aligned to a musical grid. Finally, the detected note information is converted into MIDI events. Voice-to-MIDI technology has found applications in various fields, such as quickly converting hummed melodies into MIDI for song composition, providing instant feedback to students in music education, and generating real-time music based on user voice input in interactive music systems.\n2.3 Automated Melody Analysis\nAutomated melody analysis is a significant branch of music information retrieval, aimed at extracting and analyzing melodic features from musical data. This process typically includes the analysis of notes, chords, and chord progressions. Note analysis involves extracting attributes such as pitch, duration, and velocity. Chord analysis focuses on identifying combinations of simultaneously sounding notes, often using algorithms like Chordino [29]. Chord progression analysis examines patterns in the series of chords, utilizing methods such as hidden Markov models [37]. In this field, Musicpy, a powerful Python music programming library, provides extensive functional support. It not only has concise syntax for representing various musical elements but also incorporates a complete music theory system supporting advanced musical operations. Musicpy's core data structures include notes, keys, chords, scales, etc., offering various practical functions including chord identification, melody analysis, and automatic composition. Through Musicpy, researchers and music creators can conveniently achieve automated melody analysis, explore musical structures and characteristics. Notably, the ComposeOn project extensively utilizes Musicpy's powerful capabilities, particularly in chord extraction and chord progression analysis. ComposeOn employs Musicpy's algorithms to identify and analyze the progression patterns of these chords, thereby providing an important foundation for music analysis and creation. This application demonstrates the practicality and effectiveness of Musicpy in real-world music analysis projects.\n2.4 Automatic Accompaniment Generation\nAccompaniment generation is referred to as \"the audio realization of a chord sequence\" by systems like MySong [40], which represents a significant advancement in the field of automatic accompaniment generation for vocal melodies. MySong allows users to input vocal melodies, which the system then inputs to a hidden Markov model to recommend chords. However, MySong's capabilities are limited to generating accompaniments, whereas our ComposeOn system empowers users to easily extend and develop their melodic ideas into complete compositions, providing a more comprehensive music creation and learning experience."}, {"title": "3 FORMATIVE STUDY", "content": "To understand the needs and challenges faced by individuals with little to no music theory knowledge in composing music, we conducted a formative study with six participants (FP1-FP6), aiming at exploring their willingness and confidence in music composition, as well as their experiences with existing music composition tools."}, {"title": "4 SYSTEM DESIGN", "content": "Our system, ComposeOn, is designed to facilitate music extension and learning for users with little or no musical theory background. By analyzing the results of the formative study mentioned in Section 3, we identified three design goals for Compose On:\n\u2022 Melody Expansion: Enable users to easily extend and develop their melodic ideas into complete compositions.\n\u2022 Easy Editing: Allow users to effortlessly edit and control their music creations.\n\u2022 Music Theory Integration: Incorporate music theory learning to boost engagement and interest.\nTo generate the extended part of music based on the input melody, our system consists of three main components: the input & analysis module, the generation module, and the output & explanation module. \n4.1 Compose On Database\nThe ComposeOn database consists of two main parts: common chord progressions and common rhythm patterns. These data provide ComposeOn with fundamental materials and references.\nThe chord progression section contains 39 different chord sequences across seven categories, covering various music styles from basic to advanced. These chord progressions are selected based on the principles of Functional Harmony and Tonal Harmony in music theory [10, 22]. Specifically, it includes (1) 9 classic chord progressions, such as I-IV-V-I and vi-IV-V-I, common in pop and rock music; (2) 9 extended chord progressions, like Imaj7-ii7-V7-Imaj7, suitable for jazz and blues; (3) 4 diminished triad progressions, such as i-iidim-V7-i, used to create tense or dissonant effects; (4) 4 augmented fourth chord progressions, like I-IV-aug4-I, used to add harmonic color; (5) 5 mixed chord progressions, such as Imaj7-ii7-V7-IVmaj7, blending different types of chords; (6) 4 substitute chord progressions, like Imaj7-bIImaj7-V7-Imaj7, common in modern jazz; and (7) 4 cycle chord progressions, such as Imaj7-ii7-V7-iii7, used to create repeating sections or build-ups. The selection of these chord progressions also references popular music composition practices and jazz theory[26, 32].\nThe rhythm pattern section contains 16 different rhythm types, each composed of specific combinations of notes and rests [51]. These patterns cover various popular music styles, including pop, rock, reggae, ska, jazz, funk, blues, and country music. For example, the first pattern [(1, 'rest'), (1, 'note'), (1, 'rest'), (1, 'note')] represents a simple, regular rhythm, while the seventh pattern [(1/3, 'note'), (1/3, 'note'), (1/3, 'note')] * 4 represents a more complex, triplet-based rhythm. These patterns provide ComposeOn with a rich selection of rhythms, enabling it to generate melodies that conform to specific musical styles.\n4.2 Input and Analysis Module\nTo allow users to easily express their musical ideas, we have designed a flexible input module. Users can input their melodies by singing, humming, or playing an instrument. To ensure an accurate capture of users' musical creativity, we employ the advanced Basic Pitch library [42]. This neural network-based pitch detection model can accurately convert users' audio input into standard MIDI file format, handling even complex polyphonic melodies with precision.\nOnce the user's input is converted into a MIDI file, the analysis module begins its work, delving deep into the musical characteristics of the melody. We use the powerful MusicPy [36] library to process this MIDI file, extracting rich musical information. First, ComposeOn identifies the implied chord progressions in the melody, for example, the chords present in the user's input, recognizing them as D and G.. This provides insight into the harmonic foundation of the melody. Next, ComposeOn uses the detect_scale function to determine the scales most likely used in the melody, for example, the system determines that the scale being used is D major.. To standardize the melody's harmonic structure, ComposeOn converts the identified chords into scale degrees, within the context of D major: D is identified as the I (tonic) chord, and G is identified as the IV (subdominant) chord. This process entails matching chords with detected scales, determining their position within the scale, and addressing special cases for minor scales. This conversion provides a more abstract, theoretical representation of the harmonic structure, allowing for a unified generation logic to be applied regardless of the original scale or key.\nFinally, Compose On integrates all these analysis results, creating a detailed profile of the input melody's characteristics, and serving as a basis of the explanations. The standardized scale degree representation enables ComposeOn to apply consistent generation algorithms across various musical contexts.\n4.3 Generation Module\nThe Generation Module is responsible for creating new musical content based on the analysis of the user's input. This process is divided into three main steps: recommending chord progressions, recommending rhythms for right-hand rhythm, and adding ornaments and variations. The system consults its chord progression database and identifies a common progression pattern that incorporates the input chords: [I - IV - V - I];[I - IV - ii - V - I]; [I - IV - vii dim - I]; [I - IV-V7 - I] etc.\nStep 1: Recommending Chord Progressions\nIn the first step, we begin with chord degrees from the previous step of the Analysis Module and find the recommended chord degrees. When the user clicks the \"Continue\" button in the UI, we sequentially identify the most similar progressions, utilizing the SequenceMatcher class from the difflib library [?] to calculate the sequence similarity between the input chord progression and our predefined progressions through their chord degrees. Each click recommends a complete progression. This recommended progression is then combined with the original input progression to form a new progression base. On subsequent \"continue\" clicks, this combined progression serves as the new input.\nThen, we convert these degrees into absolute chords based on the scales retained from earlier steps of the Analysis Module. For instance, if our recommended chord degree sequence is [I, IV, V, I], and the retained scale is D major, the resulting chord progression would be [D, G, A, D]. This determined chord progression forms the basis for both the left-hand and right-hand melodies.\nFor the left-hand part, we utilize the triads of these chords, playing them as whole notes for each measure. In the case of [D, G, A, D], the left hand would play D-F#-A (D major triad) for the first measure, G-B-D (G major triad) for the second measure, A-C#-E (A major triad) for the third measure, and D-F#-A (D major triad) for the fourth measure. This approach provides a solid harmonic foundation using simple, sustained chords in the left hand.\nMeanwhile, the same chord progression serves as the foundation for developing the right-hand melody, allowing for more intricate melodic and rhythmic patterns that complement the underlying harmonic structure. For example, the right-hand melody might incorporate arpeggios or scalar passages derived from the D major scale, with emphasis on the chord tones of each underlying harmony.\nThis method of chord realization and melody generation demonstrates how the system can translate abstract music theory concepts into concrete musical elements. By providing a clear harmonic foundation in the left hand and a related but more elaborate melody in the right hand, the system creates a balanced and musically coherent output that is accessible to novice users while still adhering to established musical principles.\nFurthermore, this approach can be extended to the other progression options identified earlier:\n(1) For [I, IV, ii, V, I] in D major: [D, G, Em, A, D]\n(2) For [I, IV, vii\u00b0, I] in D major: [D, G, C# dim, D]\n(3) For [I, IV, V7, I] in D major: [D, G, A7, D]\nTo introduce uniqueness, we then apply variations to these selected progressions. This variation technique is based on the concept of chord substitution in music theory. According to Levine (2011), chords can often be substituted with chords that share common tones or have a similar function within the key [26]. Our implementation focuses on diatonic substitutions, where chords are replaced by others from the same key, maintaining harmonic coherence while introducing variety. It's worth noting that we treat each complete chord progression as a musical phrase, providing a structural basis for subsequent melody generation.\nStep 2: Recommending Rhythms for the right-hand melody\nIn the second step, we employ the rhythm pattern pool introduced in the Section of the ComposeOn database. We begin by fitting the input rhythm to this rhythm pattern database to find the closest match and randomly chose two more patterns in our rhythm pattern pool. For each complete chord progression, we then apply the following strategy for rhythm patterns: The first measure of each phrase always uses the rhythm pattern fitted to the input. This ensures that the generated music retains the rhythmic characteristics of the original input, maintaining musical coherence. For subsequent measures within the phrase, we select the randomly chosen two rhythm patterns. This approach both maintains a connection to the original input and introduces new variations, enhancing the richness and diversity of the music.\nStep 3: Adding Ornaments and Variations\nIn this final step, we enrich the melody by adding musical ornaments and variations. We focus on adding ornaments to only the right-hand melody, randomly selecting 5% of the notes for embellishment. The ornaments are chosen to be as close as possible to the chord tones of the current triad. This approach includes ornaments such as appoggiaturas (grace notes creating brief dissonance before resolving to the main note), mordents (rapid alternations between the main note and an adjacent note), and trills (quick alternations between two adjacent notes) [2]. To implement this, we first determine the total number of notes in the right-hand melody and calculate 5% of this total to decide how many notes will receive ornaments. We then randomly select these positions within the melody. For each chosen note, we identify the nearest chord tone based on the current harmony and select an appropriate ornament type. When adding the ornaments, we ensure they complement the harmonic structure and maintain the overall flow of the melody. This method effectively increases the expressiveness and complexity of the melody while preserving its essential character and harmonic integrity. Care is taken to use ornaments judiciously, avoiding overuse that might disrupt the melody's fluency, and to ensure their application aligns with the specific musical style and period being emulated.\nBy combining these three steps - chord progression generation with variations, flexible rhythm pattern application, and ornament addition - our Generation Module creates musically rich and varied content based on the user's input. This multi-faceted approach ensures that the generated music is harmonically sound, rhythmically interesting with a balance of familiarity and novelty, and melodically expressive. This provides users with inspiring and unique musical ideas that both respect the original input and introduce new musical elements.\n4.4 Output and Explanation Module\nThe output module writes the generated melody to a new MIDI file, which can be played back to the user or further edited and refined. The explanation component of this module provides insights into the composition at three levels of complexity: Beginner, Intermediate, and Advanced. These explanations focus on three key aspects of the generated melody: chord progressions, rhythm patterns, and embellishments.\nBeginner Level The explanation starts with an introduction to basic musical concepts. For chord progressions, it introduces the concept of chords as groups of notes played together, explaining the difference between major and minor chords, and showing how the melody notes relate to these underlying chords. The rhythm explanation at this level covers basic note durations such as quarter notes and eighth notes, and introduces common time signatures like 4/4 and 3/4. It demonstrates how the melody's rhythm fits into these basic patterns. Regarding embellishments, the beginner explanation introduces the concept as extra notes that decorate the main melody, providing simple examples like grace notes or trills.\nIntermediate Level This level deepens the musical analysis. For chord progressions, it explains common sequences (e.g., I-IV-V-I) and introduces the concept of harmonic function (tonic, dominant, subdominant), discussing how the chosen progression supports the melody. The rhythm explanation at this level delves into how the input rhythm was matched to one of the 16 predefined patterns and how the other three random variations were created. It also discusses how these rhythms relate to different musical styles. The embellishment explanation introduces more complex decorative techniques like arpeggios or turns, and explains how these relate to the underlying harmony.\nAdvanced Level At this level, the explanation provides a sophisticated analysis of the composition. The chord progression explanation discusses advanced harmonic concepts such as secondary dominants or modal interchange, explains any modulations or key changes, and analyzes how the chord progression contributes to the overall structure of the piece. The rhythm explanation covers complex concepts like syncopation or polyrhythms, explaining how the rhythm interacts with the harmonic rhythm and contributes to the overall feel or genre of the piece. For embellishments, the advanced explanation discusses techniques like counterpoint or voice leading, explaining how embellishments can create tension and release in the melody and how they contribute to the overall expressiveness of the piece.\nWhat's more, ComposeOn also incorporates a Music Theory Mentor Chatbot, powered by the advanced ChatGPT-4 model, to enhance the user's learning experience and provide on-demand musical expertise. Within the recommendation rationales provided by the system, specialized musical terminology is hyperlinked. When a user clicks on one of these hyperlinked terms, the query is automatically populated in the Music Theory Mentor's input field, situated in a dedicated section of the interface. This mechanism facilitates immediate access to additional information, enabling users to explore complex musical concepts without disrupting their creative flow.\n4.5 ComposeOn User Interface (UI)\nThe ComposeOn UI is a user-centric platform designed to facilitate seamless interaction between users and the ComposeOn composition system. This interface integrates melody continuation, editing, and explanatory functionalities, providing users with a comprehensive music creation and learning environment."}, {"title": "5 EVALUATION", "content": "A user study was conducted to evaluate the effectiveness and educational value of Compose On. The purpose of the study was to compare the quality and experience of two groups of people - those with no knowledge of music theory and those with some knowledge of music theory - when using ComposeOn and a benchmark method (the Suno music continuation feature) for English lyrics continuation. We paid particular attention to changes in participants' knowledge of music theory. This study aims to answer the following question: Q1: Does ComposeOn develop music better than Suno? Q2: Does ComposeOn increase more willingness and confidence of participants to develop and compose music?\nTo better collect and validate the results, we had participants fill out both a pre-study and a post-study questionnaire. the pre-study questionnaire included their demographic information, a simple test of their level of knowledge of music theory, as well as their confidence and motivation about composing and learning to compose. the post-study questionnaire included their judgment of the quality of the continued music, as well as a few indicators of their judgment in SUS [50]. The post-study questionnaire included a quality rating of the continued music, as well as SUS indicator questions, a music theory questionnaire similar to the pre-study questionnaire, and a change in their motivation and confidence about composing.\n5.1 Participant\n5.2 Procedure\nPre-Study Questionnaire A pre-study questionnaire is a survey that is used prior to the start of a study or program to gather background information and initial musical knowledge about the participant. The questionnaire usually contains the following questions: Basic information: e.g., name, age, etc. Relevant experience: e.g. previous experience in music making. Assessment of prior knowledge: Tests the participant's current knowledge of the research topic, such as music theory. Interest and Motivation: To find out the participants' level of interest in the topic and their motivation to learn. Self-efficacy: To assess the participant's confidence in his/her ability in the domain.\nMain Study is to have the participants randomly pick one of the 9 melodies we prepared, and then have the participants continue the melody using the ComposeOn and baseline methods. Our baseline is the Suno 3.5 model, participants need to upload the melody file, and Suno will generate at most 4 minutes of continuation. In addition, participants can use ComposeOn to continue the melody, there is no time limit requirement, and users can check the reason for continuing the melody during the process of continuing the melody, make changes to the melody, check the knowledge of music theory through the music theory mentor, and so on.\nPost-Study Questionnaire The post-study questionnaire contained the same music theory questions as the pre-study questionnaire, which was designed to test whether the user's knowledge of music theory increased after using ComposeOn and suno for melodic continuation. In addition, there are questions about the ability of the two instruments to increase compositional confidence and motivation, as well as questions about the use of ComposeOn in the SUS framework, which are about user experience."}, {"title": "6 RESULT", "content": "In the post-quesionnaire, we analyzed the music theory correctness and all the subjective assessments in the form of 5-point scores and free comments"}, {"title": "6.1 Compose On develops better music than Suno", "content": "First, the music generated by Suno exhibits more richness and complexity in terms of weaving and orchestration. As noted in P2, P4, and P10, this complexity makes Suno's music potentially more appealing on first listen. One participant might describe it this way, \"Suno's music feels rich on first listen, with multiple layers of sound and rich orchestration, giving a first impression of great depth. However, after multiple listens, Suno's music feels less logical. In contrast, ComposeOn's music, although given only melodies with no instrumental layers, feels comfortable after multiple listens because it is very logical.\"\nHowever, ComposeOn received high ratings for other aspects of music quality. Multiple participants (P1, P2, P9) emphasized the better structure of the music generated by Compose On.P1's comment was particularly specific: \"The music generated by Suno lacks structure and sounds like randomly assembled pieces. It sounds like randomly assembled fragments because it has no clear development or ending. In contrast, I could hear (and see) the beginning and end of each phrase of ComposeOn's music, and each phrase ended in a similar pattern, making the music feel more holistic.\"\nIn terms of musical coherence, several participants (P3, P6, P8) noted that ComposeOn showed better consistency in musical sequences.P3's observation was particularly insightful: \"Sometimes Suno repeats chords that have been entered previously, but when you hear certain parts of the music, Suno sometimes generates random segments that have little to do with the previous text. This interspersing makes for very little musical consistency in this continuation. By contrast, the musical consistency in Compose On's continuation is stable; instead of outputting all the input melody at once and writing it all by itself at once, he assigns features of the input melody to different phrases, so that each phrase has parts that relate to the input melody but are not entirely consistent with it.\" This approach makes the music generated by ComposeOn more coherent and natural. In addition, P6 points out the stability of the tempo: \"The music written by Suno sometimes accelerates or decelerates suddenly, whereas ComposeOn's tempo is more stable.\" This is further evidence of ComposeOn's strength in maintaining musical consistency.\nFinally, ComposeOn shows more variation and innovation in its music writing, as articulated in P5's review, \"Suno continues music that feels like it's repeating the same chords and melodies without advancing or developing; ComposeOn at least gives me a sense that the music is evolving because it doesn't all sound too much like the previous input.ComposeOn at least gives me ComposeOn at least gives me a sense that the music is evolving, as it doesn't all sound too much like the previous input. It demonstrates ComposeOn's ability to introduce new elements while maintaining musical coherence, making the music more layered and diverse.\"\n6.2 Compose On increased participants' willingness and confidence to create music\nOur findings indicate that ComposeOn significantly enhanced participants' willingness and confidence in music creation. This improvement can be attributed to two key features of the system: high visualization and interactivity, and high explainability.\n6.2.1 High Visualization and Interactivity. ComposeOn's interface provides a highly visual and interactive experience, which proved particularly beneficial for novice users. The system displays both user input and AI-recommended melodies on a traditional musical staff, offering real-time visual cues during playback. This feature allows users, especially beginners, to gain a deeper understanding of musical structure, including how notes form chords and how chord progressions work.\nThe system's interactivity is evident in its user-guided recommendation process. Participants can control the flow of suggestions using the \"continue\" and \"end\" buttons, giving them agency over the composition process. Furthermore, ComposeOn offers contextually appropriate chord and rhythm options for each measure, allowing users to experiment with different musical elements. For instance, one participant reported successfully changing a 1-4-5-1 chord progression to a 1-2-5-1 progression, demonstrating the system's flexibility and its capacity to facilitate learning through experimentation.\n6.2.2 High Explainability. ComposeOn's high explainability feature significantly contributes to users' understanding and confidence. The system provides detailed explanations for its musical continuations, covering aspects such as chord progression, rhythm, and ornamental notes. These explanations are tailored to three proficiency levels - beginner, intermediate, and expert - ensuring that users receive information appropriate to their knowledge level.\nThe granularity of explanations is noteworthy; users can request explanations for individual notes, measures, or entire phrases. This feature not only clarifies the system's recommendations but also reinforces fundamental musical concepts. As one participant noted, \"This feature not only helped explain why certain recommendations were made, but it also helped me remember basic information like chord composition more clearly. I could associate the sound of a chord in a phrase with its composition, an experience that's hard to achieve when learning chords in isolation.\"\nAdditionally, the integrated \"music theory mentor\" feature provides quick access to theoretical knowledge, offering suggested terms and concepts like the circle of fifths. This feature's effectiveness was demonstrated when a participant (P1) first encountered an explanation of the I-VI-V-I chord progression and then used the music theory mentor to gain a deeper understanding of why this progression is harmonically pleasing.\nIn conclusion, ComposeOn's combination of high visualization, interactivity, and explainability creates a supportive environment for music creation. By demystifying the composition process and providing immediate, context-specific feedback, the system empowers users to engage more confidently with music creation, regardless of their initial skill level. This approach not only facilitates the creation of music but also enhances users' overall musical understanding, potentially contributing to long-term skill development and musical appreciation."}, {"title": "7 DISCUSSION", "content": "7.1 Generative and Music Theory-Based Composition\nThe emergence of generative AI music tools like Suno has transformed digital music creation. These tools use deep learning algorithms to generate complex", "4": ".", "43": ".", "49": ".", "53": ".", "34": ".", "research": "many novice composers have melodic ideas but lack the technical knowledge to develop them [14", "27": ".", "7": ".", "8": ".", "9": "allows users to input melodies via MIDI keyboard or singing", "12": "enables users to draw melodic contours that are then converted into musical phrases", "28": ".", "41": "and Bean Academy [25", "16": "have also incorporated melody input features", "48": ".", "purpose": "they help users understand the composition process while teaching them music theory. This approach closely aligns with modern teaching theories, particularly those emphasizing learning by doing and understanding the reasons behind rules and conventions [20", "45": "."}]}