{"title": "Knowledge-based Consistency Testing of Large Language Models", "authors": ["Sai Sathiesh Rajan", "Ezekiel Soremekun", "Sudipta Chattopadhyay"], "abstract": "In this work, we systematically expose and mea-sure the inconsistency and knowledge gaps ofLarge Language Models (LLMs). Specifically,we propose an automated testing framework(called KONTEST) which leverages a knowl-edge graph to construct test cases. KONTESTprobes and measures the inconsistencies in theLLM's knowledge of the world via a combina-tion of semantically-equivalent queries and testoracles (metamorphic or ontological oracle).KONTEST further mitigates knowledge gapsvia a weighted LLM model ensemble. Usingfour state-of-the-art LLMs (Falcon, Gemini,GPT3.5, and Llama2), we show that KONTESTgenerates 19.2% error inducing inputs (1917errors from 9983 test inputs). It also reveals a16.5% knowledge gap across all tested LLMs.KONTEST's mitigation method reduces LLMknowledge gap by 32.48%. Our ablation studyfurther shows that GPT3.5 is not suitable forknowledge-based consistency testing becauseit is only 60%-68% effective in knowledge con-struction.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) are being increas-ingly utilized in real-world applications. LLMs arepowerful in solving many tasks, but their reliabilityremains a concern (Qiu et al., 2023). This is alarm-ing because inconsistent behaviors adversely affectcritical downstream tasks and influence adoption.In this paper, we study the problem of assessinginconsistency in LLM behaviors. Previous workshave demonstrated the prevalence and severity ofinconsistent responses in LLMs (Min et al., 2023;Berglund et al., 2023; Sallou et al., 2023). To ad-dress this challenge, we conceptualize and designKONTEST\u00b9 a novel test generation methodol-ogy to systematically discover consistency errorsin LLMs and highlight their knowledge gaps."}, {"title": "2 Overview", "content": "In this section, we outline the motivation behindour approach and present an illustrative example todemonstrate the overall process of our approach.\nKey Insight: The key insight behind KONTEST isto leverage a knowledge graph for systematic con-sistency testing of LLMs. The knowledge graphserves multiple purposes in KONTEST: Firstly, en-tities and entity relations extracted from the knowl-edge graph allows KONTEST to systematically gen-erate queries and construct test cases for validatingthe consistency of the subject LLM (SUT). TheLLM's responses to these test cases allow KON-TEST to build the knowledge (sub)-graph where"}, {"title": "3 Methodology", "content": "3.1 Knowledge Graph based Test Generation\nKnowledge Graph Construction: KONTEST al-lows the developer to specify the list of entitiesthat are of interest. With these initial set of enti-ties, KONTEST then queries an external source ofknowledge to compute, up to a certain depth, allother related entities for the considered relation.Developers can also control this depth, allowingthem to determine the degree to which the vicinityof the initial set of entities is explored. Once theinitial knowledge base is constructed, KONTESTextracts the full path, KG, associated with a leafnode of the knowledge base. This path is then usedto guide the test generation process. For example,given the leaf entity Kinawley, as shown in Fig-ure 1, KONTEST extracts the KG for Kinawley asKinawley \u2192 Ulster \u2192 Ireland.\nTest Generation: Given a knowledge path KG,KONTEST leverages Algorithm 1 to exhaustivelygenerate queries relating to all possible pairs ofentities present in the path. To this end, KONTESTfirst finds the relation, $KG_{rel}$, between a pair of"}, {"title": "3.2 Test Oracles", "content": "KONTEST detects consistency errors in LLM via ametamorphic oracle and an ontological oracle.\nMetamorphic Oracle: This oracle leveragesboth the original (Querylist) and mutated(MutQuerylist) query sets to create four uniqueconversations. These conversations are then fedinto the target LLM (SUT). Concretely, KONTESTcreates two conversations containing the answerto both (initial and mutated) atomic queries in-dividually (see the first column of \u201cGeneratedSentences\" in Table 1) and two conversationswhere the queries are fed in a sequential man-ner (see the second column of \u201cGenerated Sen-tences\" in Table 1). Responses from these conver-sations are then evaluated using the consistencychecker embodied in KONTEST to identify theerroneous test cases and the number of each er-ror types (i.e., atomic, sequential-intra andsequential-inter in Table 1).\nOntological Oracle: Firstly, this oracle builds theSUT's knowledge graph. To this end, the generated"}, {"title": "3.3 Knowledge Gap Mitigation", "content": "KONTEST leverages a weighted model ensembleto mitigate knowledge gaps. KONTEST uses thenumber of metamorphic errors found for each SUTon a per relation basis to inform its scoring system.A relation that induces x errors is given a score of5 \u2212 x since each relation can maximally induct five errors. The cumulative SUT specific score,Scorei, is then found by summing the scores foreach relation. Next, KONTEST computes the rela-tive weight, $W_i$, for each SUT in the set of SUTs,SUT, using the following equation:\n$W_i = \\frac{Score_i}{\\sum_i Score_i} \\forall i \\in SUT$  (1)\nKONTEST then uses the relative weights to cal-culate the final ensemble score by first multiplyingthe relative weights with the results for each re-sponse and summing them. In particular, it consid-ers a positive and negative responses to be one andzero respectively. If the ensemble score is abovethe midpoint (0.5), the ensemble response for therelation is considered to be positive. To determinethe effectiveness of our weighting, we compare itto simple majority voting \u2013 an ensemble that doesnot account for the likelihood of inconsistenciesfor each SUT (see RQ3)."}, {"title": "4 Evaluation Setup", "content": "To evaluate our approach (KONTEST), we pose thefollowing research questions (RQs):\n\u2022 RQ1 Effectiveness: How effective is KONTESTin exposing consistency errors in LLMs?\n\u2022 RQ2 Knowledge Coverage: What is the SUT'sknowledge graph coverage? How much is theSUT knowledge gap revealed by KONTEST?\n\u2022 RQ3 Knowledge Gap Mitigation: How effec-tive is KONTEST's weighted ensemble techniquein improving knowledge coverage? How doesit compare to a simple majority voting? Does itgeneralize to a new template?\n\u2022 RQ4 Ablation Study with GPT3.5: Can thestate-of-the-art LLM (GPT3.5) perform the threemain sub-tasks of KONTEST, i.e., knowledgeconstruction, test generation and error detection?"}, {"title": "5 Evaluation Results", "content": "RQ1 Effectiveness: We found that KONTEST iseffective in exposing consistency errors in LLMs:19.2% of valid test executions result in consistencyerrors. Table 3 also shows that metamorphic er-rors (21.0%) are more prevalent than ontologicalerrors (8.9%). We attribute the lower error rateof ontological errors/inputs to the high complexityof our ontological oracle (see Table 1). Table 3demonstrates that metamorphic errors are commonacross all LLMs. In particular, the tested LLMs arehighly inconsistent when asked the same questionin a different manner (see Table 1). In addition,we observe that a large model size does not nec-essarily lead to a smaller error rate than a smallermodel, e.g., GPT3.5 exhibits a metamorphic errorrate of 27.2% for the places entities as comparedto a metamorphic error rate of 17.1% for Falcon.\nRQ2 Knowledge Coverage: Table 5 shows thatthe tested LLMs cover about four-fifth (83.5%) ofthe tested knowledge graph across both templates.We found that LLMs are particularly sensitive tothe query templates. For instance, Llama2 exhibitsa 47.3% gap in knowledge for the places entities forone template, but only exhibits a 12.9% knowledge"}, {"title": "6 Related Work", "content": "LLMs and Knowledge: Pan et al. (Pan et al.,2023) presents techniques to combine LLMs and"}, {"title": "7 Conclusion", "content": "In this paper, we propose KONTEST where thekey intuition is to distill (a subset of) facts froma knowledge graph, which, are subsequently usedto generate queries and formulate test cases fordetecting a variety of consistency errors. Our eval-uation reveals realistic consistency errors acrossstate-of-the-art LLMs. Moreover, KONTEST opensopportunities to investigate LLMs through the lensof their knowledge gaps, which, in turn is indicatedas part of our framework. This helps designersand end users to understand and mitigate the effectof such knowledge gaps e.g., via prompt engineer-ing or fine tuning. In future, we aim to investigateautomated mitigation of consistency errors by lever-aging the KONTEST framework. We provide ourcode and experimental data in the following:"}, {"title": "8 Limitations and Threats to Validity", "content": "Construct Validity: This relates to the metrics andmeasures employed in our experimental analysis.To mitigate this threat", "Validity": "This refers to the threat that ourimplementation of KONTEST performs its intendedknowledge graph-based test generation. We con-duct several manual and automated tests"}, {"Validity": "The main threat to externalvalidity of this work is the generalizability of KON-TEST and findings to LLMs", "title": "Knowledge-based Consistency Testing of Large Language Models", "authors": ["Sai Sathiesh Rajan", "Ezekiel Soremekun", "Sudipta Chattopadhyay"], "abstract": "In this work, we systematically expose and mea-sure the inconsistency and knowledge gaps ofLarge Language Models (LLMs). Specifically, we propose an automated testing framework (called KONTEST) which leverages a knowl-edge graph to construct test cases. KONTEST probes and measures the inconsistencies in the LLM's knowledge of the world via a combina-tion of semantically-equivalent queries and test oracles (metamorphic or ontological oracle). KONTEST further mitigates knowledge gaps via a weighted LLM model ensemble. Using four state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that KONTEST generates 19.2% error inducing inputs (1917 errors from 9983 test inputs). It also reveals a 16.5% knowledge gap across all tested LLMs. KONTEST's mitigation method reduces LLM knowledge gap by 32.48%. Our ablation study further shows that GPT3.5 is not suitable for knowledge-based consistency testing because it is only 60%-68% effective in knowledge con-struction.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) are being increas-ingly utilized in real-world applications. LLMs are powerful in solving many tasks, but their reliability remains a concern (Qiu et al., 2023). This is alarm-ing because inconsistent behaviors adversely affect critical downstream tasks and influence adoption. In this paper, we study the problem of assessing inconsistency in LLM behaviors. Previous works have demonstrated the prevalence and severity of inconsistent responses in LLMs (Min et al., 2023; Berglund et al., 2023; Sallou et al., 2023). To ad-dress this challenge, we conceptualize and design KONTEST\u00b9 a novel test generation methodol-ogy to systematically discover consistency errors in LLMs and highlight their knowledge gaps."}, {"title": "2 Overview", "content": "In this section, we outline the motivation behind our approach and present an illustrative example to demonstrate the overall process of our approach.\nKey Insight: The key insight behind KONTEST is to leverage a knowledge graph for systematic con-sistency testing of LLMs. The knowledge graph serves multiple purposes in KONTEST: Firstly, en-tities and entity relations extracted from the knowl-edge graph allows KONTEST to systematically gen-erate queries and construct test cases for validating the consistency of the subject LLM (SUT). The LLM's responses to these test cases allow KON-TEST to build the knowledge (sub)-graph where"}, {"title": "3 Methodology", "content": "3.1 Knowledge Graph based Test Generation\nKnowledge Graph Construction: KONTEST al-lows the developer to specify the list of entities that are of interest. With these initial set of enti-ties, KONTEST then queries an external source of knowledge to compute, up to a certain depth, all other related entities for the considered relation. Developers can also control this depth, allowing them to determine the degree to which the vicinity of the initial set of entities is explored. Once the initial knowledge base is constructed, KONTEST extracts the full path, KG, associated with a leaf node of the knowledge base. This path is then used to guide the test generation process. For example, given the leaf entity Kinawley, as shown in Fig-ure 1, KONTEST extracts the KG for Kinawley as Kinawley \u2192 Ulster \u2192 Ireland.\nTest Generation: Given a knowledge path KG, KONTEST leverages Algorithm 1 to exhaustively generate queries relating to all possible pairs of entities present in the path. To this end, KONTEST first finds the relation, $KG_{rel}$, between a pair of"}, {"title": "3.2 Test Oracles", "content": "KONTEST detects consistency errors in LLM via a metamorphic oracle and an ontological oracle.\nMetamorphic Oracle: This oracle leverages both the original (Querylist) and mutated (MutQuerylist) query sets to create four unique conversations. These conversations are then fed into the target LLM (SUT). Concretely, KONTEST creates two conversations containing the answer to both (initial and mutated) atomic queries in-dividually (see the first column of \u201cGenerated Sentences\" in Table 1) and two conversations where the queries are fed in a sequential man-ner (see the second column of \u201cGenerated Sen-tences\" in Table 1). Responses from these conver-sations are then evaluated using the consistency checker embodied in KONTEST to identify the erroneous test cases and the number of each er-ror types (i.e., atomic, sequential-intra and sequential-inter in Table 1).\nOntological Oracle: Firstly, this oracle builds the SUT's knowledge graph. To this end, the generated"}, {"title": "3.3 Knowledge Gap Mitigation", "content": "KONTEST leverages a weighted model ensemble to mitigate knowledge gaps. KONTEST uses the number of metamorphic errors found for each SUT on a per relation basis to inform its scoring system. A relation that induces x errors is given a score of 5 \u2212 x since each relation can maximally induc  t five errors. The cumulative SUT specific score, $Score_i$, is then found by summing the scores for each relation. Next, KONTEST computes the rela-tive weight, $W_i$, for each SUT in the set of SUTs, SUT, using the following equation:\n$W_i = \\frac{Score_i}{\\sum_i Score_i} \\forall i \\in SUT$  (1)\nKONTEST then uses the relative weights to cal-culate the final ensemble score by first multiplying the relative weights with the results for each re-sponse and summing them. In particular, it consid-ers a positive and negative responses to be one and zero respectively. If the ensemble score is above the midpoint (0.5), the ensemble response for the relation is considered to be positive. To determine the effectiveness of our weighting, we compare it to simple majority voting \u2013 an ensemble that does not account for the likelihood of inconsistencies for each SUT (see RQ3)."}, {"title": "4 Evaluation Setup", "content": "To evaluate our approach (KONTEST), we pose the following research questions (RQs):\n\u2022 RQ1 Effectiveness: How effective is KONTEST in exposing consistency errors in LLMs?\n\u2022 RQ2 Knowledge Coverage: What is the SUT's knowledge graph coverage? How much is the SUT knowledge gap revealed by KONTEST?\n\u2022 RQ3 Knowledge Gap Mitigation: How effec-tive is KONTEST's weighted ensemble technique in improving knowledge coverage? How does it compare to a simple majority voting? Does it generalize to a new template?\n\u2022 RQ4 Ablation Study with GPT3.5: Can the state-of-the-art LLM (GPT3.5) perform the three main sub-tasks of KONTEST, i.e., knowledge construction, test generation and error detection?"}, {"title": "5 Evaluation Results", "content": "RQ1 Effectiveness: We found that KONTEST is effective in exposing consistency errors in LLMs: 19.2% of valid test executions result in consistency errors. Table 3 also shows that metamorphic er-rors (21.0%) are more prevalent than ontological errors (8.9%). We attribute the lower error rate of ontological errors/inputs to the high complexity of our ontological oracle (see Table 1). Table 3 demonstrates that metamorphic errors are common across all LLMs. In particular, the tested LLMs are highly inconsistent when asked the same question in a different manner (see Table 1). In addition, we observe that a large model size does not nec-essarily lead to a smaller error rate than a smaller model, e.g., GPT3.5 exhibits a metamorphic error rate of 27.2% for the places entities as compared to a metamorphic error rate of 17.1% for Falcon.\nRQ2 Knowledge Coverage: Table 5 shows that the tested LLMs cover about four-fifth (83.5%) of the tested knowledge graph across both templates. We found that LLMs are particularly sensitive to the query templates. For instance, Llama2 exhibits a 47.3% gap in knowledge for the places entities for one template, but only exhibits a 12.9% knowledge"}, {"title": "6 Related Work", "content": "LLMs and Knowledge: Pan et al. (Pan et al., 2023) presents techniques to combine LLMs and"}, {"title": "7 Conclusion", "content": "In this paper, we propose KONTEST where the key intuition is to distill (a subset of) facts from a knowledge graph, which, are subsequently used to generate queries and formulate test cases for detecting a variety of consistency errors. Our eval-uation reveals realistic consistency errors across state-of-the-art LLMs. Moreover, KONTEST opens opportunities to investigate LLMs through the lens of their knowledge gaps, which, in turn is indicated as part of our framework. This helps designers and end users to understand and mitigate the effect of such knowledge gaps e.g., via prompt engineer-ing or fine tuning. In future, we aim to investigate automated mitigation of consistency errors by lever-aging the KONTEST framework. We provide our code and experimental data in the following:"}, {"title": "8 Limitations and Threats to Validity", "content": "Construct Validity: This relates to the metrics and measures employed in our experimental analysis. To mitigate this threat, we have employed standard testing metrics such as the number/rate of generated inputs, error-inducing inputs, (knowledge) cover-age and testing time. For automatic analysis of hun-dreds of responses, our analysis does not handle expressive, non-binary LLM responses. However, we mitigate this by employing system prompts to ensure the model provides binary responses and we discard non-binary responses (as invalid).\nInternal Validity: This refers to the threat that our implementation of KONTEST performs its intended knowledge graph-based test generation. We con-duct several manual and automated tests, as well as inspection of sampled outcomes of KONTEST to ensure the correctness of our approach. Our ablation study (RQ4) further allows to probe the correctness of the sub-step of KONTEST versus using GPT3.5. We experimentally verify that over 90% of the entities we evaluate against existed in Wikidata prior to 2020. We also find that under 15% of the errors found by KONTEST are linked to these entities. In addition, we also note that the SUT ought to answer the question in a consistent manner regardless of whether the entity existed prior to the corresponding knowledge cutoff date.\nExternal Validity: The main threat to external validity of this work is the generalizability of KON-TEST and findings to LLMs, knowledge graphs, templates and entities beyond the ones used in this work. For instance, we mitigate the LLM generaliz-ability threat by employing state-of-the-art off-the-shelf, mature, open model weights LLMs (LLAMA2 and FALCON), as well as commercial LLMs (such as GPT3.5 and Gemini). Notably, our entity selection and template construction may be limited to our experimental setting. However, we demonstrate"}, {"title": "9 Ethics Statement", "content": "We elucidate our ethics statement in this section:\n(1) Dataset: We utilize data from Wikidata, a publicly available open knowledge base related to Wikipedia. Wikidata is licensed under the Creative Commons CC0 License. (2) Human Evaluations: Our experiments do not involve human participants.\n(3) Approach: We test KONTEST with the aid of LLMs (both proprietary and free). We acknowl-edge that these models may give biased results due to their training data and methods. However, we restrict our queries to existing relations in the knowledge graph making it unlikely to raise ethical concerns. We limit ourselves to running inference on pre-trained models due to the numerous envi-ronmental concerns (energy and water expenditure) associated with training these LLMs."}]}]}