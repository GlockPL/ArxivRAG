{"title": "Knowledge-based Consistency Testing of Large Language Models", "authors": ["Sai Sathiesh Rajan", "Ezekiel Soremekun", "Sudipta Chattopadhyay"], "abstract": "In this work, we systematically expose and measure the inconsistency and knowledge gaps of Large Language Models (LLMs). Specifically, we propose an automated testing framework (called KONTEST) which leverages a knowledge graph to construct test cases. KONTEST probes and measures the inconsistencies in the LLM's knowledge of the world via a combination of semantically-equivalent queries and test oracles (metamorphic or ontological oracle). KONTEST further mitigates knowledge gaps via a weighted LLM model ensemble. Using four state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that KONTEST generates 19.2% error inducing inputs (1917 errors from 9983 test inputs). It also reveals a 16.5% knowledge gap across all tested LLMs. KONTEST's mitigation method reduces LLM knowledge gap by 32.48%. Our ablation study further shows that GPT3.5 is not suitable for knowledge-based consistency testing because it is only 60%-68% effective in knowledge construction.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) are being increasingly utilized in real-world applications. LLMs are powerful in solving many tasks, but their reliability remains a concern (Qiu et al., 2023). This is alarming because inconsistent behaviors adversely affect critical downstream tasks and influence adoption.\nIn this paper, we study the problem of assessing inconsistency in LLM behaviors. Previous works have demonstrated the prevalence and severity of inconsistent responses in LLMs (Min et al., 2023; Berglund et al., 2023; Sallou et al., 2023). To address this challenge, we conceptualize and design KONTEST\u00b9 a novel test generation methodology to systematically discover consistency errors in LLMs and highlight their knowledge gaps."}, {"title": "2 Overview", "content": "In this section, we outline the motivation behind our approach and present an illustrative example to demonstrate the overall process of our approach.\nKey Insight: The key insight behind KONTEST is to leverage a knowledge graph for systematic consistency testing of LLMs. The knowledge graph serves multiple purposes in KONTEST: Firstly, entities and entity relations extracted from the knowledge graph allows KONTEST to systematically generate queries and construct test cases for validating the consistency of the subject LLM (SUT). The LLM's responses to these test cases allow KONTEST to build the knowledge (sub)-graph where the LLM behaves correctly. Secondly, knowledge-based test generation allows KONTEST to report a test adequacy metric for the SUT in terms of the entities and relations covered within the knowledge graph. Finally, this approach enables KONTEST to highlight sub-graph of the knowledge graph where the outputs from the SUT are logically inconsistent. This enables practitioners to selectively focus on the knowledge gaps highlighted by KONTEST for improving the LLM (e.g., by fine-tuning).\nRunning Example:  outlines our approach. KONTEST broadly comprises of three key components: \u2460 knowledge graph construction (\"Knowledge Graph\" in Figure 2), \u2461 test generation (\"Test Generation\" in Figure 2), and 3 test oracles (\"Test Oracles\" in Figure 2). Given a set of entities (e.g., countries) and a maximum graph depth, KONTEST locates the given entities in the knowledge graph (e.g., Wikidata knowledge graph (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014)), and constructs the associated knowledge graph before extracting the relevant entities and relationships. Given the relationships present in Figure 1(d), KONTEST constructs two semantically equivalent queries for each relation with the aid of a template (see Figure 3) relating the two involved entities. The resultant queries are then fed to the SUT generating responses to both atomic and sequential queries.  shows two such semantically equivalent queries, each of which was part of a new conversation with GPT3.5 (aka \u201catomic\u201d), while  illustrates one such consistency error with inconsistent responses for semantically-equivalent queries that were within the same conversation (aka \u201csequential-inter\"). Finally,  illustrates a series of queries, whose responses from GPT3.5 collectively show inconsistent behavior (aka \"ontological\"). Specifically, the positive responses to the first two queries imply that Ireland does have a Kinawley. However, due to the negative response in the third query, our ontological oracle reveals a consistency error. We further note that such errors cannot be uncovered by counter-questioning LLMs. The relevant sub-graph of the knowledge graph for GPT3 . 5 is shown in . This clearly illustrates the knowledge gap (i.e., Kinawley Ireland) for GPT3.5."}, {"title": "3 Methodology", "content": "3.1 Knowledge Graph based Test Generation\nKnowledge Graph Construction: KONTEST allows the developer to specify the list of entities that are of interest. With these initial set of entities, KONTEST then queries an external source of knowledge to compute, up to a certain depth, all other related entities for the considered relation. Developers can also control this depth, allowing them to determine the degree to which the vicinity of the initial set of entities is explored. Once the initial knowledge base is constructed, KONTEST extracts the full path, KG, associated with a leaf node of the knowledge base. This path is then used to guide the test generation process. For example, given the leaf entity Kinawley, as shown in Figure 1, KONTEST extracts the KG for Kinawley as Kinawley \u2192 Ulster \u2192 Ireland.\nTest Generation: Given a knowledge path KG, KONTEST leverages Algorithm 1 to exhaustively generate queries relating to all possible pairs of entities present in the path. To this end, KONTEST first finds the relation, KGrel, between a pair of nodes. KONTEST then generates a query, Query, using KGrel with the aid of the template shown in Figure 3 (line 9 in Algorithm 1). KONTEST also generates the mutated query, Querym, with another template (line 12 in Algorithm 1). These templates are dependent on the relation between the two nodes in question. For instance, Figure 3 shows the set of queries and mutated queries (i.e., Querylist and MutQuerylist) generated from one particular path and along with the respective templates used to generate them. We note that developers can implement additional templates easily if they are interested in querying different relations. Moreover, creation of these templates is a one-time process and the cost incurred is minimal since the number of different types of relationships is small in comparison to the number of entities.\n3.2 Test Oracles\nKONTEST detects consistency errors in LLM via a metamorphic oracle and an ontological oracle.\nMetamorphic Oracle: This oracle leverages both the original (Querylist) and mutated (MutQuerylist) query sets to create four unique conversations. These conversations are then fed into the target LLM (SUT). Concretely, KONTEST creates two conversations containing the answer to both (initial and mutated) atomic queries individually (see the first column of \u201cGenerated Sentences\" in Table 1) and two conversations where the queries are fed in a sequential manner (see the second column of \u201cGenerated Sentences\" in Table 1). Responses from these conversations are then evaluated using the consistency checker embodied in KONTEST to identify the erroneous test cases and the number of each error types (i.e., atomic, sequential-intra and sequential-inter in Table 1).\nOntological Oracle: Firstly, this oracle builds the SUT's knowledge graph. To this end, the generated queries from KONTEST are fed into the SUT and the target responses are recorded. Subsequently, given a list of such responses, KONTEST identifies the nodes involved in each response. These nodes are then added to the SUT's knowledge graph. Next, if the query response is positive (i.e., correct), KONTEST introduces a directed edge between the nodes in the SUT's knowledge graph indicating that the respective relation exists between the two nodes being considered. It is important to note that the relations in question are not symmetric in nature, justifying the directed flavor of the edge. After constructing the SUT's knowledge graph, GraphGen, KONTEST checks for ontological consistency errors with the aid of Algorithm 2.\nTo check the consistency in SUT's knowledge graph, Algorithm 2 first inspects whether a direct path exists between any pair of nodes (Node1, Node2) in GraphGen (line 7 in Algorithm 2). In the absence of such a direct path, when an indirect path exists between the same pair of nodes (line 11 in Algorithm 2), KONTEST detects an ontological consistency error and updates the error count, Errcount. Intuitively, a direct path between two nodes indicates that the SUT responded positively to a question relating the two nodes. Similarly, the presence of an indirect path indicates that SUT knows that a positive relationship exists between the nodes albeit through more than one queries. As such, the SUT can be considered to be exhibiting an ontological inconsistency. As an example, consider the ontological oracle illustrated in Table 1. In this case, if an indirect path exists between nodes for Kinawley and Ireland via node Ulster (i.e., the responses to both Q3 and Q4 are positives from the SUT), then KONTEST concludes that a direct path should also exist between Kinawley and Ireland. Hence, the absence of a positive response for the respective query (Q2) is indicated as an ontological error. As a byproduct of our ontological oracle, KONTEST computes the knowledge coverage Coveragecount for the SUT.\n3.3 Knowledge Gap Mitigation\nKONTEST leverages a weighted model ensemble to mitigate knowledge gaps. KONTEST uses the number of metamorphic errors found for each SUT on a per relation basis to inform its scoring system. A relation that induces x errors is given a score of 5\u2212x since each relation can maximally induce five errors. The cumulative SUT specific score, Scorei, is then found by summing the scores for each relation. Next, KONTEST computes the relative weight, Wi, for each SUT in the set of SUTs, SUT, using the following equation:\nW_i = \\frac{Score_i}{\\sum Score_i} \\forall i \\in SUT\nKONTEST then uses the relative weights to calculate the final ensemble score by first multiplying the relative weights with the results for each response and summing them. In particular, it considers a positive and negative responses to be one and zero respectively. If the ensemble score is above the midpoint (0.5), the ensemble response for the relation is considered to be positive. To determine the effectiveness of our weighting, we compare it to simple majority voting \u2013 an ensemble that does not account for the likelihood of inconsistencies for each SUT (see RQ3)."}, {"title": "4 Evaluation Setup", "content": "To evaluate our approach (KONTEST), we pose the following research questions (RQs):\n\u2022 RQ1 Effectiveness: How effective is KONTEST in exposing consistency errors in LLMs?\n\u2022 RQ2 Knowledge Coverage: What is the SUT's knowledge graph coverage? How much is the SUT knowledge gap revealed by KONTEST?\n\u2022 RQ3 Knowledge Gap Mitigation: How effective is KONTEST's weighted ensemble technique in improving knowledge coverage? How does it compare to a simple majority voting? Does it generalize to a new template?\n\u2022 RQ4 Ablation Study with GPT3.5: Can the state-of-the-art LLM (GPT3.5) perform the three main sub-tasks of KONTEST, i.e., knowledge construction, test generation and error detection?"}, {"title": "5 Evaluation Results", "content": "RQ1 Effectiveness: We found that KONTEST is effective in exposing consistency errors in LLMs: 19.2% of valid test executions result in consistency errors. Table 3 also shows that metamorphic errors (21.0%) are more prevalent than ontological errors (8.9%). We attribute the lower error rate of ontological errors/inputs to the high complexity of our ontological oracle (see Table 1). Table 3 demonstrates that metamorphic errors are common across all LLMs. In particular, the tested LLMs are highly inconsistent when asked the same question in a different manner (see Table 1). In addition, we observe that a large model size does not necessarily lead to a smaller error rate than a smaller model, e.g., GPT3.5 exhibits a metamorphic error rate of 27.2% for the places entities as compared to a metamorphic error rate of 17.1% for Falcon.\nKONTEST effectively exposes consistency errors in LLMS: 19.2% of valid test executions exposed a metamorphic or ontological error in LLMs.\nRQ2 Knowledge Coverage: Table 5 shows that the tested LLMs cover about four-fifth (83.5%) of the tested knowledge graph across both templates. We found that LLMs are particularly sensitive to the query templates. For instance, Llama2 exhibits a 47.3% gap in knowledge for the places entities for one template, but only exhibits a 12.9% knowledge gap for the other. This suggests that LLMs may respond differently to two different, but semantically equivalent, input queries. We also observed that the smallest model (Falcon) has the lowest knowledge gap for the places entities (3.1%), while one of the biggest models (GPT3.5) has the highest knowledge gap (29.6%). This implies that model size/complexity is not a good proxy for knowledge coverage/gap. We do, however, attribute the performance of Falcon to its tendency to answer with a positive response regardless of the query. In addition, we also note that all queries posed to the subject LLMs are queries relating to an existing relation. These results show that KONTEST effectively reveals the knowledge gap in LLMs. We posit that knowledge coverage is a good criteria for estimating the underlying knowledge of an LLM.\nKONTEST effectively reveals knowledge gaps in LLMs: It exposes an average knowledge gap of 16.5% in the tested LLMs.\nRQ3 Knowledge Gap Mitigation: Results show that KONTEST's mitigation technique reduces the SUT's knowledge gap by up to 39.30%. Table 4 shows that KONTEST reduces the knowledge gap for all templates by 32.48%. We found that the simple majority voting ensemble worsens the SUTs' knowledge gap by up to 23.74%. We also observed that the mitigation performance of KONTEST generalizes to an unseen template (template three (3)). While the mitigation performance of KONTEST is slightly better on the new template than the original templates the simple majority performs worse on an unseen template. These results demonstrate the generalizability of KONTEST's mitigation and the efficacy of our weighted ensemble. We attribute the performance of KONTEST's mitigation to the likelihood and distribution of inconsistencies: Firstly, KONTEST's weighted ensemble is 42.72% more effective than the simple majority voting. Secondly, the distribution of inconsistencies shows that only 1.1% (15 out of 1330) of errors are found in all four SUTs while 65.7% (874 out of 1330) of errors are unique to a single SUT.\nThe ensemble method of KONTEST effectively reduces the SUT's knowledge gap by 32.48%.\nRQ4 Ablation study with GPT3.5: We conduct an ablation study to investigate whether a state-of-the-art LLM (GPT3.5) is as effective as KONTEST in performing its three main sub-tasks \u2013 knowledge construction, test generation and error detection.\nKnowledge Construction: Table 6 demonstrates that GPT3.5 is not a reliable knowledge constructor. GPT3.5 is only able to identify 68% of the relations present in the original knowledge graph. We believe this is because LLMs are generally intended to be a conversational engine, rather than a knowledge database (Pan et al., 2023). These results show the importance of knowledge graphs in KONTEST and suggests that LLMs are not a reliable replacement for knowledge graphs.\nGPT3.5 is an ineffective surrogate for a knowledge graph: It constructs only 68% of the ground-truth entity relations (edges).\nTest Generation: Given a few (three) query examples and the relations in a knowledge graph, GPT3.5 is slightly more effective (17.5% vs 16.8%) than KONTEST in test generation (see Table 7). We also observe that this effectiveness persists for both the metamorphic (18.7% vs 17.9%) and the ontological oracle (11.5% vs 11.1%). We attribute the performance of GPT3.5 to the effectiveness of few-shot prompting using the knowledge graph. This guides GPT3.5 to create tests similar to KONTEST.\nGPT3.5 is slightly (4.2%) more effective than KONTEST in generating tests, when provided entity relations with few-shot prompting.\nError Detection: Table 8 highlights that while 52.6% of the metamorphic errors detected by GPT3.5 were detected correctly, approximately 40.1% of the errors were false positives. For ontological error detection, we provided GPT3.5 all possible queries and corresponding responses for each knowledge path. GPT3.5 was then asked to detect any inconsistency in these responses. Unlike KONTEST, GPT3.5 is unable to detect multiple inconsistencies in a knowledge path. Hence, for a fair comparison in this experiment, we count ontological errors for KONTEST at the granularity of a knowledge path (i.e., at most one error per knowledge path). Since validating GPT3.5 responses is not straightforward in this case, we manually validated the responses. We observed that the number of real ontological errors detected by GPT3.5 is comparable to the ontological errors detected by KONTEST, but it also had a high false positive rate with nearly 63.7% of errors being misclassified.\nGPT3.5 detects both metamorphic and ontological errors, but exhibits a false positive rate of up to 63.7%."}, {"title": "6 Related Work", "content": "LLMs and Knowledge: Pan et al. (Pan et al., 2023) presents techniques to combine LLMs and knowledge graphs to address their individual limitations. As an example, Huang et al. (Huang et al., 2023c) have demonstrated the feasibility of knowledge transfer to improve LLM's generalization ability in software engineering tasks. Analogously, WEAVER (Yang et al., 2023a) uses LLMs to generate knowledge bases, using which, requirements are extracted for testing models in real-world settings. GPT4GEO (Roberts et al., 2023) experimentally evaluates the capabilities and limitations of GPT-4 in geospatial domain (e.g., places entity), highlighting potential usage of GPT-4 in navigation. Unlike these proposed techniques, KONTEST employs knowledge graphs to expose inconsistencies and measure knowledge gaps in LLMs.\nTesting and Analysis of LLMs: Several researchers have surveyed the challenges and opportunities for testing and analysing LLMs (Zhao et al., 2023; Hou et al., 2023; Zheng et al., 2023; Aleti, 2023). Researchers have also studied or proposed methods for testing and analyzing several quality properties of LLMs, including their reasoning ability (Wu et al., 2023; Qiu et al., 2023), non-determinism (Ouyang et al., 2023), interpretability (Palacio et al., 2023; Rodriguez-Cardenas et al., 2023), robustness (Zhu et al., 2023), fairness (Huang et al., 2023a), security concerns (e.g., privacy, memorization and backdoor attacks) (Yang et al., 2023b; Staab et al., 2023; Huang et al., 2023b). In contrast to the aforementioned works, KONTEST studies the consistency and knowledge coverage of LLMs."}, {"title": "7 Conclusion", "content": "In this paper, we propose KONTEST where the key intuition is to distill (a subset of) facts from a knowledge graph, which, are subsequently used to generate queries and formulate test cases for detecting a variety of consistency errors. Our evaluation reveals realistic consistency errors across state-of-the-art LLMs. Moreover, KONTEST opens opportunities to investigate LLMs through the lens of their knowledge gaps, which, in turn is indicated as part of our framework. This helps designers and end users to understand and mitigate the effect of such knowledge gaps e.g., via prompt engineering or fine tuning. In future, we aim to investigate automated mitigation of consistency errors by leveraging the KONTEST framework. We provide our code and experimental data in the following:\nhttp://anonymous.4open.science/r/Kontest"}, {"title": "8 Limitations and Threats to Validity", "content": "Construct Validity: This relates to the metrics and measures employed in our experimental analysis. To mitigate this threat, we have employed standard testing metrics such as the number/rate of generated inputs, error-inducing inputs, (knowledge) coverage and testing time. For automatic analysis of hundreds of responses, our analysis does not handle expressive, non-binary LLM responses. However, we mitigate this by employing system prompts to ensure the model provides binary responses and we discard non-binary responses (as invalid).\nInternal Validity: This refers to the threat that our implementation of KONTEST performs its intended knowledge graph-based test generation. We conduct several manual and automated tests, as well as inspection of sampled outcomes of KONTEST to ensure the correctness of our approach. Our ablation study (RQ4) further allows to probe the correctness of the sub-step of KONTEST versus using GPT3.5. We experimentally verify that over 90% of the entities we evaluate against existed in Wikidata prior to 2020. We also find that under 15% of the errors found by KONTEST are linked to these entities. In addition, we also note that the SUT ought to answer the question in a consistent manner regardless of whether the entity existed prior to the corresponding knowledge cutoff date.\nExternal Validity: The main threat to external validity of this work is the generalizability of KONTEST and findings to LLMs, knowledge graphs, templates and entities beyond the ones used in this work. For instance, we mitigate the LLM generalizability threat by employing state-of-the-art off-the-shelf, mature, open model weights LLMs (LLAMA2 and FALCON), as well as commercial LLMs (such as GPT3.5 and Gemini). Notably, our entity selection and template construction may be limited to our experimental setting. However, we demonstrate the applicability of KONTEST by using two different domains with multiple relations and entity types. We note that we employ few-shot prompting to query the LLMs, thus, our findings may not generalise to other prompting techniques. Finally, KONTEST employs Wikidata, a well-maintained knowledge graph that is popularly used in both academia and industry (Peters et al., 2019).\nLLM Stability and Correctness: Researchers have identified several stability concerns about LLMs (Ouyang et al., 2023; Fan et al., 2023), such as non-determinism, randomness, sensitivity to prompting methods, and API/model updates. To mitigate these threats we performed several actions: First, we set the temperature of all models to zero (0), when possible (Cloud, 2023; Ouyang et al., 2023). Secondly, we reduce the risk of model updates by limiting our testing time (to about a day each per model) and checking for news of model updates before and after testing. Thirdly, we also use models with frozen weights (Falcon and Llama2) to reduce the non-determinism. To automatically validate model outcomes, we employ few-shot prompting, which has been shown to be effective for querying LLMs (Deng et al., 2023). We examined whether LLMs are comparable to KONTEST (RQ4) using GPT3.5 since it produces the most valid responses (99.9%) (see Table 3).\nKnowledge Graph Completeness and Soundness: We note that the knowledge graph is an incomplete snapshot of the real-world. In our evaluation, KONTEST only tests for facts (positive tests) derived from the knowledge graph. While it is also possible to use KONTEST to test for incorrect relation (negative test), the validation of such test results is challenging due to the incompleteness of knowledge graph. Moreover, we only tests 50 paths from this graph. However, these concerns do not affect our findings, as we are certain about the errors found within the tested subset of the knowledge graph. Finally, knowledge of the world naturally evolves over time and the knowledge graphs do not evolve at the same pace (Pan et al., 2023). To mitigate this, we use a widely used knowledge graph (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014)."}, {"title": "9 Ethics Statement", "content": "We elucidate our ethics statement in this section:\n(1) Dataset: We utilize data from Wikidata, a publicly available open knowledge base related to Wikipedia. Wikidata is licensed under the Creative Commons CC0 License. (2) Human Evaluations: Our experiments do not involve human participants. (3) Approach: We test KONTEST with the aid of LLMs (both proprietary and free). We acknowledge that these models may give biased results due to their training data and methods. However, we restrict our queries to existing relations in the knowledge graph making it unlikely to raise ethical concerns. We limit ourselves to running inference on pre-trained models due to the numerous environmental concerns (energy and water expenditure) associated with training these LLMs."}]}