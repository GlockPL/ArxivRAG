{"title": "Al-rays: Exploring Bias in the Gaze of AI Through a Multimodal Interactive Installation", "authors": ["Ziyao Gao", "Yiwen Zhang", "Ling Li", "Theodoros Papatheodorou", "Wei Zeng"], "abstract": "Data surveillance has become more covert and pervasive with AI algorithms, which can result in biased social classifications. Appearance offers intuitive identity signals, but what does it mean to let AI observe and speculate on them? We introduce AI-rays, an interactive installation where AI generates speculative identities from participants' appearance which are expressed through synthesized personal items placed in participants' bags. It uses speculative X-ray visions to contrast reality with AI-generated assumptions, metaphorically highlighting Al's scrutiny and biases. Al-rays promotes discussions on modern surveillance and the future of human-machine reality through a playful, immersive experience exploring AI biases.", "sections": [{"title": "1 Inspiration", "content": "Bias is inherent in human society. In the digital age, ubiquitous data surveillance and the extensive use of algorithms continuously to collect and analyze data about individuals and society, cyclically introduce and reinforce human biases in machine learning models. Biased processes are deeply embedded in everyday life, arising from various signals such as searching behaviors, click interactions, and, more seriously, physical appearance. However, the constant assessment for signals is invisible to the public, making it difficult to discern when and how the biases occur, which groups they affect, and the potential cascading consequences they may cause [Ntoutsi et al. 2020]. Some artworks externalize these internal processes. For example, Kyle McDonald's Facework [McDonald 2020] uses sliders and numbers to visualize how algorithms assess appearance attributes.\nAppearance offers natural signals for identifying individuals. People cultivate their self-perception partly by managing their appearance, while also instinctively making rapid judgments based on others' [Zebrowitz and Montepare 2015]. The signals can potentially convey various aspects of a person, such as identity, personality, interests, and economic status.\nHuman understanding of appearance-based signals is grounded in personal experiences and cultural context. However, as exemplified by Signs that Say What You Want Them To Say and Not Signs that Say What Someone Else Wants You To Say [Fowler 2013] from Gillian Wearing, it might not represent people's true selves. In the context of contemporary digital society, what does widespread AI imply when relying on appearance signals and identity labels?"}, {"title": "2 Concept Design", "content": "Since machine bias is typically reflected within groups rather than individuals, its perception and interpretation are often ambiguous. This ambiguity can also manifest in the depiction of identity through personal items. In his series Buying Everything on You [Chuang 2014], Chuang Liu conveys symbolic profiles of new immigrants in Shenzhen's labor market by showcasing complete sets of their clothes and personal items. These narratives invite audiences to speculate on the identities and lives of the previous owners, fostering non-verbal communication across different eras and cultures. The connection between items and identities also applies to our work, giving viewers the freedom to interpret."}, {"title": "2.1 Identity Narratives of Personal Items", "content": "Since machine bias is typically reflected within groups rather than individuals, its perception and interpretation are often ambiguous. This ambiguity can also manifest in the depiction of identity through personal items. In his series Buying Everything on You [Chuang 2014], Chuang Liu conveys symbolic profiles of new immigrants in Shenzhen's labor market by showcasing complete sets of their clothes and personal items. These narratives invite audiences to speculate on the identities and lives of the previous owners, fostering non-verbal communication across different eras and cultures. The connection between items and identities also applies to our work, giving viewers the freedom to interpret."}, {"title": "2.2 Semantic Transformations of AI-powered X-ray Images", "content": "In the real world, X-rays honestly expose the structure and content of objects. Leveraging this characteristic, Nick Veasey practices X-ray photography to challenge society's obsession with external appearances. His X-ray Voyeurism [Nelson 2014] series peers into people's belongings beneath clothing, sparking discussions about the inconsistency between appearances and personal essence.\nOur work also utilizes the unique visual effects of X-rays for defamiliarization, promoting a re-examination of audiences' body image. Unlike traditional ones, our generative X-ray images present augmented, speculative X-ray visions. In the wave of AI-generated art, the nature of images is being altered and debated. For example, Weidi Zhang's Ray [Zhang 2022] connects people with Al-powered Rayograph to explore image semantics transformation. In our work, the generated X-ray images actually highlight the nature of the data algorithms and AI processes.\nBased on these considerations, we presented an interactive installation, Al-rays. Specifically, we enable the machine to observe and analyze audience images from certain perspectives, crafting personal items into their bags, and subvert and extend new X-ray images to convey the invasive potential of AI and speculate about the underlying nature of reality. Al-rays functions as an Al mirror that enables people to re-examine their image and identity when seen through the eyes of large deep-learning models. It helps people identify biases, reflect on the signals they send and ultimately think of the consequences of the proliferation of data surveillance and Al technologies within human society."}, {"title": "3 Related Work", "content": "Regarding standards and the power to judge human appearance, Mushon Zer-Aviv's interactive installation The Normalizing Machine [Zer-Aviv 2018] analyzes public selections of \"socially normal images\", and gradually aggregates systematic discrimination into the model. This echoes Bertillonage [Ajana 2013]-the criminal identification system based on anthropometry and photographs invented by police officer Alphonse Bertillon, later adopted by the eugenics movement and Nazis. Today, through the gaze of machines, human appearance is once again scrutinized and classified.\nWhen it comes to the meaning of machine gaze, art experiment Cheese [Moeller 2003] from Christian Moeller employs an emotion recognition system to continuously scrutinize actresses' smiles, granting machine the power to associate \"smile\" with \"the performance of sincerity\", turning happiness into labor. In many other instances, machines' understanding of humans is linked to unknown attributes. For example, Theodore Watson and Kyle McDonald's Portrait Machine [Watson 2014] groups audience photos by various visible features to highlight both commonalities and uniqueness. Mimi Onuoha's Classification. 01 employs abstract {} symbols to represent classification relationships, lighting up when nearby audiences are perceived as similar by unknown standards. These works explore how machines interpret human data, allowing audiences to glimpse potential algorithmic logic and biases from their own perspectives."}, {"title": "4 The Installation: AI-rays", "content": "Al-ray integrates deep-learning technologies including image understanding, object detection and segmentation, and image generation through specially tuned models. Using a custom pipeline, it transforms people into speculative X-ray images. Moreover, it visualizes the meaning extracted by machines from people's appearance to keywords and item assignments, then ultimately communicates by crafting personal items onto their bags in the output images. For example, a bald, muscular man with a beard often gets violent items while a young woman with pigtails is assigned characteristically feminine objects."}, {"title": "4.1 X-ray Visual Effect Creation", "content": "To achieve the X-ray visual effect, we utilize a fine-tuned LORA model [Hu et al. 2021] with a diffusion model [Croitoru et al. 2023] to build an artistic X-ray-style and enhance Al's understanding of human skeletal structure. As shown in Fig. 2, we first created X-ray-style shaders in Unreal Engine and collected 3D models including human characters, skeletons, and bags, forming a synthetic dataset of 192 rendered X-ray-style images from multiple angles. Using this dataset, we fine-tuned two separate LoRA models, X-ray Skin for human skin and bag images, and X-ray Skeleton for human"}, {"title": "4.2 AI-rays Pipeline", "content": "As shown in Fig. 4, Al-rays starts by taking the participant's photo. To prevent environmental factors from affecting Al's understanding, we first remove the photo's background. Then, submitted it into three parallel modules: the Inference Module, the Perception Module, and the Expression Module.\n\u2022 The Inference Module is pivotal in understanding human appearance. We utilize GPT-4V to analyze participants on four dimensions: identity, personality, interests, and economic background, constructing a persona for each participant, and then assigning personal items based on it.\n\u2022 The Perception Module is responsible for integrating assumed items onto participants' images. Firstly, we employ the Grounding Dino [Liu et al. 2023] model to identify the bag. Subsequently, we leverage the Segment Anything Model [Kirillov et al. 2023] to precisely segment the mask of each bag. Finally, using openCV and a custom algorithm we developed, we extract the main region of the mask, calculate layouts, and composite personal items onto bags, ensuring that all items fit well within the bag boundaries and keep the correct relative size to each other.\n\u2022 The Expression Module is tasked with transforming the participant's photos into X-ray-style using the X-ray Final LoRA model we developed in the earlier stage. Initially, we employ the OpenPose and SoftEdge components within ControlNet to extract the posture and outline of the person, serving as a guide for image generation which eliminates the effect of skin and clothes color. Then the X-ray-style body image is generated using the X-ray Final LoRA model with the Stable Diffusion model. After upscaling, personal items are then added to that image automatically, and output on a screen."}, {"title": "4.3 Installation Design", "content": "The installation consists of a camera, a large LED wall screen, and a computer. The LED wall allows participants to immersively engage with their life-size images (Fig. 1).\nThe installation was designed to be intuitive without instructions. It attracts participants' attention with an animated line scan. When someone approaches, it will be activated. The generation of the output image takes about ten seconds. While the image is being prepared and composited, keywords output associated with the intermediary steps of the algorithmic pipeline pop-up randomly on the screen. This is to keep the engagement and highlight the \"thought process\u201d involved in generating the specific results. Once complete, the generated X-ray image is displayed along with speculated personal items. To present them more clearly, we also enlarge and arrange the items with their names in a floating layout beside the human image."}, {"title": "5 Feedback and Discussion", "content": ""}, {"title": "5.1 Bias Cases within AI Gaze", "content": "To highlight the inherent bias of AI algorithms, we ran the Al-rays pipeline on a human dataset of 144 images. The dataset is diverse along three representative axes: ethnic background, gender, and occupation. We combined three ethnicities (simply stated: black, caucasian, east Asian), two genders (male and female), and occupations (doctor and non-specific) forming 12 categories (e.g., black male doctor, white female with no specific occupation. etc), and collected 12 portrait photos for each category. Through testing, we manually encoded the output keywords, identifying the representative bias cases."}, {"title": "5.2 Human Perceptions of Machine Scrutiny and Bias", "content": "We recruited 15 participants to test our prototype installation and gather feedback. Participants reported that the experience evoked a sense of scrutiny. Lozano-Hemmer's Surface Tension [Lozano-Hemmer 1992] explores intrusive detection and control by tracking audiences with a visible electronic eye. In contrast, we created a calmer yet pervasive atmosphere of scrutiny, making individuals \"voluntary\" subjects of inspection. Our experience starts with line scanning, making participants uneasy, \"like entering a rigorous security checkpoint.\" The transparent X-ray images enhance the feeling of being observed. Additionally, larger-than-life skeletal figures alienate the everyday space, one commenting, \"I never imagined standing in front of my skeleton and being looked down upon by it. I felt oppressed.\"\nThe intriguing correspondence between personal items and identity introduced a level of interpretative ambiguity, fostering imagination and exploration among participants. Two females reacted differently to assigned beauty products -one bemused by stereotypes, stating, \"It assumes I need perfume and lipstick just because I'm a woman, but I never wear makeup.\" The other finding them \"exactly what I use every day.\" Some desired a second interaction to question if the results were insightful or random. Additionally, three participants attempted to disguise themselves from the system's scrutiny. One used a baseball cap and mask, receiving items associated with a suspicious character. Throughout the processes, participants accepted scrutiny actively or passively, forming personal insights of bias. This led to questioning the power of intelligent systems in surveillance and control from the perspective of individual identities and Al's role.\nThe experience prompted participants to reflect on their appearance signals and how AI perceived them. Most found the inferences relatively accurate and were surprised by Al's capabilities, with some feeling more confident about their self-image. However, some worried their personal pursuits of individuality were merely reflections of societal categories. A few participants found the results untrue. Interestingly, they rated the experience more positively and engaged in discussions afterward.\nSubtitled Public from Lozano-Hemmer projects critical subtitles onto people, highlighting the violence and asymmetry in observation. Similarly, our work introduces continuous, unconsented observation of appearance, but incorporates participants' understanding of the system's outputs and self-perception into the experience. The ambiguous connection between items and identity avoids overly sharp critiques, transforming classification and judgment into a game. This dynamic process aligns with David Lyon's theory of surveillance practices in modern society [Lyon 2018], which are inherently linked to power but oscillate between care and control without absolute intentions or outcomes.\nApart from revealing algorithmic biases based on appearance signals and discussing the power dynamics of surveillance and bias through a playful approach, this project also explores new possibilities of X-ray vision by creating X-ray images with semantic information. One participant remarked, \"I usually associate X-rays with hospitals and illness. Through this work, I see an alternate reality.\" Unlike the other art installations that highlight the menacing nature of surveillance in darker tones, our work tries to highlight the AI biases and evoke discussion about surveillance and appearance signals through fun and surprising experiential engagement. While our approach may be indirect, it ultimately sparks discussions about technical biases, self-image, and the future of human-machine reality."}]}