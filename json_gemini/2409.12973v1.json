{"title": "\"The Era of Foundation Models in Medical Imaging is Approaching\": A Scoping Review of the Clinical Value of Large-Scale Generative AI Applications in Radiology", "authors": ["Inwoo Seo", "Eunkyoung Bae", "Joo-Young Jeon", "Young-Sang Yoon", "Jiho Cha"], "abstract": "Social problems stemming from the shortage of radiologists are intensifying, and artificial intelligence is being highlighted as a potential solution. Recently emerging large-scale generative AI has expanded from large language models (LLMs) to multi-modal models, showing potential to revolutionize the entire process of medical imaging. However, comprehensive reviews on their development status and future challenges are currently lacking. This scoping review systematically organizes existing literature on the clinical value of large-scale generative AI applications by following PCC guidelines. A systematic search was conducted across four databases: PubMed, EMbase, IEEE-Xplore, and Google Scholar, and 15 studies meeting the inclusion/exclusion criteria set by the researchers were reviewed. Most of these studies focused on improving the efficiency of report generation in specific parts of the interpretation process or on translating reports to aid patient understanding, with the latest studies extending to AI applications performing direct interpretations. All studies were quantitatively evaluated by clinicians, with most utilizing LLMs and only three employing multi-modal models. Both LLMs and multi-modal models showed excellent results in specific areas, but none yet outperformed radiologists in diagnostic performance. Most studies utilized GPT, with few using models specialized for the medical imaging domain. This study provides insights into the current state and limitations of large-scale generative AI- based applications in the medical imaging field, offering foundational data and suggesting that the era of medical imaging foundation models is on the horizon, which may fundamentally transform clinical practice in the near future.", "sections": [{"title": "1. Introduction", "content": "The persistent shortage of radiologists, exacerbated by increasing demand for medical imaging, poses significant challenges. The number of radiologists has not kept pace with this growing demand, and many specialists are retiring without enough new ones being trained, leading to increased misdiagnosis, unnecessary medical tests, and higher healthcare costs. This issue is becoming more acute due to the aging population, overworked radiologists, the rise of 3D medical imaging technologies like CT and MRI, and the increasing number of people with health insurance. Proposed solutions include the utilization of artificial intelligence (AI) 2 remote reading diagnostic technologies, and easing immigration barriers for foreign specialists.\nAl diagnostic solutions based on deep learning, particularly using Convolutional Neural Network (CNN) architectures, are promising in medical imaging 3. CNNs are effective at image processing by analyzing pixels to understand the overall image 45 .However, CNNs have limitations 6: they excel in learning local patterns but struggle with long-term dependencies crucial in medical imaging. Other issues include labor-intensive research and development requiring annotation and difficulties in understanding the global context of an image based on a fixed receptive field, impacting diagnostic accuracy, especially for large or multiple lesions 78\nIn 2017, the Transformer architecture revolutionized Al technology with the self-attention mechanism introduced in the paper \"Attention Is All You Need\".9 This advancement significantly improved natural language processing performance, underpinning models like GPT and BERT and enhancing Al accessibility and application. The October 2022 launch of OpenAl's ChatGPT showcased these advancements, making Al more accessible and interactive, with continuous improvements through Reinforcement Learning Human Feedback (RLHF) 10. In March 2023, OpenAl released GPT-4, a multimodal model capable of processing text and image input, expanding applications in education, healthcare and entertainment(etc.). Subsequently, OpenAl introduced GPT-4V, DALL-E3, CLIP, Whisper, SORA, and GPT-40, demonstrating Al's ability to process diverse data types. Healthcare- specific Al models like Google's Med-PaLM also emerged, with Med-PaLM scoring over 60% on USMLE-style questions11 and Med-PaLM 2 scoring 85%12, integrating various medical data to enhance patient care. Recently, Med-Gemini further established its role in healthcare. 13\nDespite these advancements, there are no systematic studies on clinical value 14 of the application of LLM or multimodal generative Al technologies in the field of radiology. 15 The rapid developments in Al have the potential to transform medical imaging, prompting several key questions:\n\u2022 What is the clinical value of Al applications in medical imaging?\n\u2022 How are these technologies being categorized and evaluated by clinicians?\n\u2022 What opportunities and challenges exist for Al in this field?"}, {"title": "Result", "content": "Our database and hand search identified a total of 14,370 articles, with additional records from ArXiv\n(n=1), ACM (n=1), and MDPI (n=1). After and initial screening based on primary & secondary criterions,\n73 articles considered eligible for full-text screening. (see Fig. 1 for details). The final sample of peer-\nreviewed articles entering the analysis included a total of 15 studies, described in Table 1. A list of\nreferences for the included studies is available in Supplementary Note 1."}, {"title": "Study characteristics", "content": "We searched for studies from 2017 through April 2024, when the transformer architecture first began to emerge. In terms of researchers, radiologists authored the most targeted articles (13), followed by oncologists and Ph.D researchers belongs to radiology department with one article each. In terms of publication year, 9 articles were published in 2023 and 6 in 2024, reflecting the latest research trends, and 7 articles were published in specialized radiology journals (Radiology, JCR, ACR, ECR), 4 in medical-related journals (Cureus, Sage Journal, MDPI), 2 in technical journals (IEEE, ACM), and 2 in other journals (springer open, arXiv). In terms of the purpose of the study, 10 studies were based on 'Radiology report', which accounted for the largest proportion, followed by 2 studies related to 'medical imaging findings and patient medical information', 2 studies related to 'medical imaging images', and 1 study related to \u2018radiologists'. In terms of both domestic and overseas, North America (the United States) accounted for the largest number of papers with 7, followed by Asia (India, Japan, China, Korea, and Australia) with 5, and Europe (Germany and the United Kingdom) with 3."}, {"title": "Technical Characteristics of Al technologies", "content": "We analyzed the technical characteristics and types of language models (LLMs) and multimodal models used in the studies.<table 2> In terms of the types of A.I. models, language models (LLMs) accounted for the largest share with 12 studies, while multimodal visual language models (VLMs), a relatively new technology, accounted for 3 studies. In terms of Al developers and models, the leading company, OpenAl's GPT, dominated with 12 studies, followed by Google, Meta, open source public models (BERT, LSTMs), and Kakao Brain's KARA-CXR model with one study each. In terms of medical imaging modality types, 3D modalities such as CT/MRI accounted for the majority with 9 articles, followed by chest X-ray with 4 articles, ultrasound with 2 articles, and others."}, {"title": "Clinical Value of generative Al application in Radiology", "content": "Table 3. shows the clinical value of the research object and the results of the research in the literature. The clinical value was categorized into three categories: Accuracy313233 Workflow Efficiency34, and Better Outcomes for Patients. 35\n1. Accuracy\nAccuracy was described in a total of eight papers, with details on detecting various types of errors in the readings and improving diagnostic performance. Regarding error detection, a study (No. 1) was conducted to determine how much the detection of errors caused by low-experience doctors, error detection due to limitations in voice recognition, and mistakes due to excessive workload could be improved by utilizing the LLM algorithm, and as a result, the detection rate of GPT-4 (82.7%) was similar to that of radiologists. In a study that focused solely on errors due to voice recognition in the reading text, GPT-4's detection performance was confirmed to be highly accurate, with F1 scores of 94.3% and 86.9%, respectively, after classifying clinically significant and insignificant voice recognition errors.\nIn terms of diagnostic performance, studies have been conducted to compare the reading capabilities of LLMs and radiologists under certain conditions and between different LLMs, and the results show that radiologists' capabilities are generally higher than those of Al models when it comes to patient information-based reading performance. (No.2)) The performance of generating impressions in the reading was also compared with Al, and it was concluded that radiologists were still better in terms of clarity and accuracy. (No.4) However, in an experiment to measure the improvement of Al's diagnostic performance while providing additional patient information, the performance gradually improved as more information was added. (Accuracy increased by 10% after 2 weeks, 23.57% after 3 weeks, and 57.86% after 4 weeks) (No.6). In a study on diagnostic performance between the multimodal vision language model GPT-4V and KARA-CXR (No.14), KARA-CXR was found to be about 70% accurate in reading, outperforming ChatGPT's 45%. In addition, the false positive rate was 68% for KARA-CXR and 37% for ChatGPT, and the non-hallucination rate (wrong prediction) was 75% for KARA-CXR and 38% for ChatGPT, showing KARA-CXR's overall superior performance.\n2. Streamline workflow\nSix studies were conducted on workflow efficiency, mainly related to time, cost, and improving the quality and ease of reading. More specifically, one study (NO.1) evaluated the diagnostic processing speed and cost of GPT-4 compared to radiologists, and found that GPT-4's processing speed was 3.5 seconds (radiologists: 25.1 seconds) and the cost of correction was $0.03 (radiologists: $0.42), which can enhance the cost-effectiveness of the workflow. A study on radiologists' satisfaction after generating a conversion from a free text report to a structured report between Al models (GPT-4 and GPT-3.5) was also conducted (No. 10).), GPT-3.5 generated a total of 202/236 (74.3%) satisfactory structured reports, while GPT-4.0 generated a total of 69/236 (25.4%) satisfactory structured reports, indicating"}, {"title": "Opportunities and Challenges of Research Subjects", "content": "The study identified several opportunity factors. Al is easy to utilize for medical image reading and error detection, demonstrating excellent performance in terms of time, cost, and accuracy. It shows promise in automatic impression generation, structured reporting, and report generation. Additionally, Al can be used to interact with patients by translating readings into understandable language, communicating medical knowledge, and overcoming communication barriers with clinicians. Al also serves as a valuable training and feedback tool for junior trainees, outperforming them in certain tasks. There is potential for developing specialized medical imaging LLM models that reflect domain characteristics, which could enhance performance further.\nHowever, several challenges were noted. Privacy issues arise due to the cloud-based nature of LLMs, leading to concerns about medical data leakage and difficulties integrating Al systems into hospital infrastructure. Performance and accuracy gaps compared to experienced radiologists, inconsistencies in Al analysis, information oversimplification, and language performance disparities are significant issues. Finally, technical and institutional limitations, such as hallucinations, training data biases, and the inability to evolve the model through real-time learning, present ongoing challenges.<Table 4>"}, {"title": "Discussion", "content": "This study aimed to evaluate the clinical value of large-scale generative Al applications in radiology, with a focus on accuracy, workflow efficiency, and patient outcomes. The research spanned publications from January 2017 to April 2024, both in Korea and internationally. By examining 15 selected studies, this research dissected the general characteristics of the literature, the technical attributes and types of research subjects, the clinical value and outcomes of the subjects, and the opportunities and challenges they present.\nFirst, the general characterization of the literature reveals that the majority of studies are based on radiology reports. Historically, medical image analysis research has been dominated by solutions employing CNN-based deep learning techniques to detect lesions in images. However, these models face clinical application limitations as they are effective only in detecting labeled lesions and do not encompass the entire reading process. The advent of Large Language Models (LLMs) has shifted Al research in radiology towards a focus on reading-centered tasks, such as summarizing, reorganizing, and translating radiology reports. Nevertheless, dealing solely with medical images or readings addresses only a portion of the radiologist's workload. The emergence of multimodal models that integrate these functionalities allows for an expanded role of Al beyond technical constraints.<Figure 2> Vision-language models can simultaneously handle medical images and readings, integrating all reading processes comprehensively. However, challenges such as lower sensitivity and specificity compared to CNN-based models, biases in training data, and difficulties in performance evaluation persist. Future research should prioritize advancing multimodal Al solutions to more complex modalities like CT and MRI, which demand substantial technological advancements and iterative development."}]}