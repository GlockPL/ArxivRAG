{"title": "Graph Neural Network Framework for Sentiment\nAnalysis Using Syntactic Feature", "authors": ["Linxiao Wu", "Yuanshuai Luo", "Binrong Zhu", "Guiran Liu", "Rui Wang", "Qian Yu"], "abstract": "Amidst the swift evolution of social media\nplatforms and e-commerce ecosystems, the domain of opinion\nmining has surged as a pivotal area of exploration within natural\nlanguage processing. A specialized segment within this field\nfocuses on extracting nuanced evaluations tied to particular\nelements within textual contexts. This research advances a\ncomposite framework that amalgamates the positional cues of\ntopical descriptors. The proposed system converts syntactic\nstructures into a matrix format, leveraging convolutions and\nattention mechanisms within a graph to distill salient\ncharacteristics. Incorporating the positional relevance of\ndescriptors relative to lexical items enhances the sequential\nintegrity of the input. Trials have substantiated that this\nintegrated graph-centric scheme markedly elevates the efficacy of\nevaluative categorization, showcasing preeminence across a\nspectrum of established reference datasets.", "sections": [{"title": "INTRODUCTION", "content": "With the accelerating proliferation of social media networks\nand e-commerce platforms, discerning public sentiment has\nemerged as a critical focus within the realm of computational\nlinguistics [1]. A specialized subset of this domain involves\npinpointing the nuanced sentiments associated with specific\ntopics within text segments, encompassing sentiments ranging\nfrom favorable to unfavorable or neutral stances [2]. Practical\ninstances of this methodology are prevalent in analytics on\nmedical dignosis[3-5], and insights derived from financial\nstakeholders' communications[6]. This targeted sentiment\nextraction holds substantial academic and commercial\nsignificance [7].\nThe deployment of deep learning paradigms has catalyzed\nadvancements in this niche [8]. Traditionally, addressing this\nchallenge involved transforming textual inputs into lower-\ndimensional vectors via embedding models before feeding\nthem into neural architectures for training. However, this direct\napproach often overlooks the influence of word sequence on\nthe model's efficacy. Moreover, incorporating syntactic-level\ninformation could enhance the model's discernment of\nsentiment toward specific topics. Utilizing the hierarchical\nstructure of sentences, as depicted in syntactic parse trees, can\nbolster the extraction of meaningful syntactic features.\nGrounded in these considerations, this study employs graph\nneural networks to address these issues, contributing to the\nfield in three primary ways.\n(1) An integrated graph neural network framework that\nincorporates the positional context of focal terms is introduced.\nThe structural relationships within the input text are mapped\ninto a matrix form, facilitating feature extraction through the\napplication of graph-based convolution and attention\nmechanisms.\n(2) To maintain the sequential arrangement of lexical units\nwithin the input, the relative proximity of focal terms is utilized\nas a positional attribute, ensuring that the inherent order is\npreserved as a feature.\n(3) Ultimately, these feature vectors are channeled into a\nretrieval-oriented attention component, aiding a SoftMax\nclassifier in deriving the conclusive classification outcome.\nEvaluations conducted on three canonical datasets affirm the\nmodel's validity and underscore the significance of each\ncomponent in addressing the challenges posed by text sequence\nprocessing and the utilization of graph neural networks in\nachieving superior results."}, {"title": "RELATED WORK", "content": "The domain of sentiment analysis, particularly using deep\nlearning and syntactic features, has been significantly advanced\nby various methodologies and models in recent years. These\ndevelopments are essential for the understanding of how the\nintersection of graph neural networks (GNNs) and sentiment\nanalysis can lead to more precise and contextually aware\nresults.\nRecent work on text classification using GNNs, such as\nGao et al.'s [9], showcases the effectiveness of graph-based\nmodels in capturing syntactic dependencies, which is crucial in\nsentiment analysis where sentence structure plays a key role.\nTheir study introduces a text classification optimization\nalgorithm based on GNNs, which aligns with the proposed\napproach of syntactic feature integration in sentiment analysis.\nAdditionally, Yang et al. [10] explored emotional analysis\nusing large language models, which are inherently designed to\nhandle nuanced language processing tasks. This paper, while\nfocusing on emotional analysis, contributes significantly to\nunderstanding how deep learning techniques can be harnessed\nfor sentiment extraction, a close cousin to opinion mining, by\nleveraging advanced language models. Embedding techniques\nsuch as those in Cheng et al.'s [11] work, which involves\nELMo word embeddings and multimodal transformers, further\npush the boundaries of sentiment analysis. Their research\nemphasizes the need for robust contextual embedding models\nthat capture syntactic and semantic features, resonating with\nthe need for high-dimensional feature representation in the\nproposed GNN framework.\nIn terms of optimization strategies, Ma et al. [12] delved\ninto gradient descent optimization, which is vital for training\ndeep neural networks, including GNNs. The methods discussed\nprovide a solid foundation for improving model training in\ncomplex neural network architectures such as the one proposed\nin this research. Furthermore, Wang et al. [13] have contributed\nto the understanding of syntactic feature extraction with their\nresearch on enhancing convolutional neural networks using\nnumerical difference methods. Their approach is highly\nrelevant to improving the efficiency of GNNs in dealing with\nsyntactic structure extraction, a key focus of this study. Several\nstudies, though not directly focused on sentiment analysis, offer\ncrucial insights into deep learning and graph-based techniques.\nFor instance, Yang et al. [14] presented advancements in\ndynamic hypergraph prediction, which shares conceptual\nsimilarities with the graph-based approach for modeling\nrelationships between syntactic elements in text. Likewise, Gu\net al. [15] researched spatio-temporal aggregation in graph\nmodels, which informs the methodology of integrating\ntemporal and positional features within GNN frameworks for\nsentiment analysis.\nFinally, recent studies on named entity recognition [16]and\nrisk assessment in financial markets [17] also illustrate the\nbroad applicability of deep learning and graph-based methods\nin diverse fields. These works underscore the versatility of\nGNNs and their potential for cross-domain adaptation,\nstrengthening the argument for their use in sentiment analysis."}, {"title": "METHOD", "content": "Using graph neural networks (GNNs) for modeling often\nrelies on a single-layered approach, which may limit the\nexploration of the intricate relationships between focal terms\nand their surrounding context[18-20]. This method can miss\nout on capturing the syntactic constraints inherent in sentences.\nAdditionally, simply applying a model to the sentence without\nconsidering the positional information can lead to\nmisinterpretation, as it might rely on irrelevant context for\nsentiment determination. For example, attention-based models\nare prone to highlighting words that are not necessarily relevant\nto the sentiment being analyzed, thereby missing key syntactic\ndependencies. Moreover, from observations in aspect-based\nsentiment analysis datasets, it becomes evident that context\nwords located nearer to the focal term within a sentence tend to\ncarry more weight in determining sentiment than those\npositioned further away. This phenomenon is clearly\ndemonstrated in Figure 1, showing the importance of proximity\nin sentiment classification.\nTo address these limitations, a more sophisticated approach\nis required that not only takes into account the syntactic\nstructure and positional information but also leverages the\nstrengths of GNNs to accurately capture the nuanced\ninteractions between different parts of the sentence. This\nensures that the model can effectively distinguish between\nrelevant and irrelevant context, thereby improving the accuracy\nof sentiment analysis.\nFirst, a syntactic parser is employed to transform the given\nsentence into a syntactic parse tree. This tree is subsequently\ntranslated into an adjacency matrix, which serves as the\nfoundation for constructing various types of graph neural\nnetworks. These networks are designed to extract the syntactic\ndependency information among the context words\ncomprehensively.\nSecondly, to emphasize the positional sequence of context\nwords relative to the focal terms within the sentence, a method\nbased on the relative distance to these focal terms is developed.\nThis relative distance is incorporated as positional sequence\ninformation. The positional sequence information is then\ncombined with the sentence context and embedded as the input\nfeature vector for the model. Following this, a BiLSTM-\nAttention layer processes the input to generate a hidden vector\nrepresentation of the text.\nFinally, this hidden vector representation, along with the\noutput features from the graph neural network component, is\nfed into an Attention Weight module. This module assigns\nattention weights to the context words, aiding in the final\nclassification outcome through a SoftMax classifier. The\narchitecture of this network is illustrated in Figure 2."}, {"title": "EXPERIMENT", "content": "In our experimental framework, we have systematically\nconfigured all parameters to ensure robustness and\nreplicability. We initiate by employing pre-trained GloVe\nembeddings for initializing word vectors, ensuring that both\ncontext and aspect words have an embedding dimensionality of\n300. Position vectors are distinctly configured with a\ndimensionality of 100. The weight matrix for the final fully\nconnected layer is initialized at random, adhering to a normal\ndistribution characterized by a mean of 0 and a standard\ndeviation of 1. For the optimization process, the Adam\noptimizer is selected for its efficiency in handling sparse\ngradients on noisy problems[22]. We set the initial learning rate\nat 0.001, coupled with an L2 regularization parameter finely\ntuned to 0.00001. This configuration is designed to balance\nlearning efficiency with the need to prevent overfitting, thus\nenhancing the model's performance on unseen data. This\nmethodical setup forms the backbone of our experimental\narchitecture, aiming to foster reproducibility and reliability in\nour results.\nTo assess the model's performance, we utilize two primary\nevaluation metrics: accuracy (Acc) and macro F1 score. These\ncriteria provide a comprehensive measure of the model's\neffectiveness across different aspects of the classification task.\nThe accuracy metric evaluates the proportion of correctly\nclassified instances, whereas the macro F1 score offers a\nbalanced view of precision and recall, averaged across all\nclasses. This setup ensures a thorough and balanced evaluation\nof the model's capabilities."}, {"title": "A. Experimental setup", "content": "In our experimental framework, we have systematically\nconfigured all parameters to ensure robustness and\nreplicability. We initiate by employing pre-trained GloVe\nembeddings for initializing word vectors, ensuring that both"}, {"title": "B. Datasets", "content": "Three separate datasets were employed in the experiments,\nand the results validated the effectiveness of the proposed HM-\nGNN model. The datasets included the Laptop and Restaurant\ncategories from the SemEval2014 competition, as well as a\nTwitter dataset from ACL2014. To maintain consistency,\ninstances with conflicting sentiment polarity labels were\nexcluded from the SemEval2014 datasets. Each dataset\nconsisted of sentences, the specific aspect terms within them,\nand the corresponding sentiment polarities for those terms.\nThese datasets were processed using the Linked Data approach,\nwhich integrates multiple data formats, a method essential for\nacademic research[23]. This structured technique enhances data\ncross-referencing, promoting interoperability among different\ndatasets. Such capabilities are particularly advantageous in\nfields like machine learning and artificial intelligence, where\nthe quality of data is critical for effective model training and\nensuring accurate results.\nThe experimental setup involved analyzing the textual\ncontent, identifying the focal aspects within each sentence, and\nassessing the sentiment polarity related to these aspects. By\nremoving examples with inconsistent sentiment labels, the\ndatasets were refined to provide a clearer basis for evaluating\nthe model's performance. This methodology was pivotal in\nstructuring the datasets to rigorously evaluate the model's\neffectiveness in accurately classifying sentiment polarities. By\nmeticulously preparing the data, we ensured that each dataset\nwas optimally configured for comprehensive testing, thereby\nfacilitating a thorough assessment of the model's performance\nin different scenarios. This structured approach not only\nenhances the reliability of the results but also provides a solid\nfoundation for comparing the predictive capabilities of the\nmodel under controlled conditions. Through this rigorous\npreparation, we aim to demonstrate the robustness and\nprecision of the model in discerning various sentiment\npolarities across diverse textual datasets."}, {"title": "C. Experimental Results", "content": "To thoroughly evaluate the performance of the HM-GNN\nmodel, we engaged in a detailed comparative analysis against a\ndiverse array of baseline models. This lineup included some\nwell-known models, representing distinct methodologies within\nthe field. By incorporating such a wide spectrum of\napproaches, our analysis provided a robust benchmark for\nassessing the HM-GNN model's capabilities. This\ncomprehensive evaluation strategy allowed us to discern the\nstrengths and weaknesses of HM-GNN in contrast to\nestablished methods, thereby offering insights into its\ncomparative effectiveness and potential areas for further\nenhancement. This benchmarking is crucial for validating the\nnovel contributions of the HM-GNN model and establishing its\npractical utility in sentiment analysis tasks.\nThe evaluation aimed to highlight the strengths and\nweaknesses of HM-GNN relative to these established models.\nBy comparing the results, we were able to determine how\neffectively the HM-GNN model performs in terms of accuracy\nand efficiency, offering insights into its potential advantages\nand areas for improvement. This comparative study ensured a\nthorough understanding of the model's performance across\ndifferent methodologies."}, {"title": "V. CONCLUSION", "content": "This paper introduces a novel hybrid graph neural network\nmodel that leverages the syntactic structure of input sentences.\nThe syntactic parse tree is transformed into an adjacency\nmatrix, which serves as the basis for feature extraction using a\ncombination of graph convolutional neural networks (GCNs)\nand graph attention networks (GANs). To maintain the\nsequential information of words within the input, the model\nincorporates the relative distance from aspect words as a\npositional feature.\nThe feature vectors derived from this process are then\npassed through a retrieval-style attention module, enabling a\nSoftMax classifier to produce the final classification outcome.\nValidation conducted on three established datasets not only\nunderscores the logical design of the model but also highlights\nthe impact of each component in addressing the complexities of\ntext sequence processing and the benefits of using graph neural\nnetworks.\nThe experimental results demonstrate that the proposed\nhybrid model surpasses several existing baseline models in\nterms of accuracy and F1 score, thereby confirming its\neffectiveness and superiority in the domain of sentiment\nanalysis. This comprehensive evaluation provides evidence of\nthe model's robust performance and its potential for advancing\nthe field."}]}