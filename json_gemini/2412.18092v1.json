{"title": "BRIDGE: Bundle Recommendation via Instruction-Driven Generation", "authors": ["Tuan-Nghia Bui", "Huy-Son Nguyen", "Cam-Van Thi Nguyen", "Hoang-Quynh Le", "Duc-Trong Le"], "abstract": "Bundle recommendation aims to suggest a set of interconnected items to users. However, diverse interaction types and sparse interaction matrices often pose challenges for previous approaches in accurately predicting user-bundle adoptions. Inspired by the distant supervision strategy and generative paradigm, we propose BRIDGE, a novel framework for bundle recommendation. It consists of two main components namely the correlation-based item clustering and the pseudo bundle generation modules. Inspired by the distant supervision approach, the former is to generate more auxiliary information, e.g., instructive item clusters, for training without using external data. This information is subsequently aggregated with collaborative signals from user historical interactions to create pseudo 'ideal' bundles. This capability allows BRIDGE to explore all aspects of bundles, rather than being limited to existing real-world bundles. It effectively bridging the gap between user imagination and predefined bundles, hence improving the bundle recommendation performance. Experimental results validate the superiority of our models over state-of-the-art ranking-based methods across five benchmark datasets.", "sections": [{"title": "Introduction", "content": "Beyond item recommendation, which focuses on suggesting individual items to users, bundle recommendation captures a more nuanced understanding of user behavior in recommending a set of cohesive items for an exclusive intention. The understanding is often built upon leveraging historical user-item, user-bundle interactions, and bundle-item affiliations to learn user preferences (Wei et al. 2023; Ma et al. 2024). This task has gained significant attention in recent years due to its complexity.\nExploring user preferences in recommendation systems, especially in the context of bundle recommendation, is a critical and complex challenge. It plays a vital role in improving user experiences across diverse domains (Cui et al. 2020).\nMost effective graph-based models (Chang et al. 2020; Ma et al. 2022; Zhao et al. 2022) employ Bayesian Personalized Ranking (BPR) (Rendle et al. 2012) as the primary objective. These models differentiate between unseen user-bundle interactions (negative samples) and observed user-bundle interactions (positive ones) to rank recommendations by classifying true negatives. Regardless of the success of ranking-based methods across various recommendation domains, there exist several serious limitations, which call into question their ability to fully capture and respond to the complexities of user behaviour. As highlighted by Yang et al. (2024), one of the primary concerns is the oversimplification of human behaviour in adopting bundles of items. In the other hand, these methods often lack of robustness in the face of data sparsity and noise. In diverse real-world scenarios, user-item interaction data is incomplete, noisy, and sparse, which poses urgent challenges for ranking models in deriving reliable inferences. This issue is even more pronounced in the context of bundle recommendations, where the user-bundle interaction data tends to be even sparser and less consistent. The complexity of bundles, which involve multiple items rather than single ones, adds another layer of difficulty in accurately modeling user preferences. When confronted with such limited data, ranking models are prone to over-fitting, relying too heavily on the small amount of available information.\nOur research is inspired by the distant supervision strategy, which leverages auxiliary resources to generate silver-standard labeled data for model training (Craven et al. 1998; Mintz et al. 2009). However, the effectiveness of distant supervision in bundle recommendation remains largely unexplored due to the scarcity of relevant knowledge bases. Bundle recommendation datasets typically consist of user,"}, {"title": "Related Work", "content": "Bundle Recommendation. Research on bundle recommendation typically focuses on three main approaches: factorization methods decompose interaction matrices into latent factors to predict and enhance bundle recommendations; graph-based methods utilize graphs to capture complex relationships between users, items, and bundles, refining recommendations through graph-based techniques; and generative methods employ generative models to create pseudo ideal bundles, addressing limitations of traditional ranking approaches by exploring new configurations aligned with user preferences.\nFactorization Methods. Early bundle recommendation methods, based on the BPR framework (Rendle et al. 2012), use user-bundle interactions as positive pairs and sample negative pairs from unobserved interactions. DAM (Chen et al. 2019a) is a multi-task framework that recommends both items and bundles using an attention mechanism and shared weights to capture user preferences at both levels.\nGraph-based Recommendation. LightGCN (He et al. 2020) applies a simple but effective yet graph convolutional operators on the bipartite user-item graph to facilitate item recommendation. Recently, BGCN (Chang et al. 2020) integrates Graph Convolutional Networks with multi-view learning to exploit various interactions. Addressing the inconsistency between item preference and bundle preference of users, CrossCBR (Ma et al. 2022), MultiCBR (Ma et al. 2024) adopt InfoNCE (Gutmann and Hyv\u00e4rinen 2010) to align multi-view user preferences, while MIDGN (Zhao et al. 2022) models multiple intention hidden in users/bundles. BundleGT (Wei et al. 2023) explores the strategy-aware ability of user/bundle representations. CoHeat (Jeon et al. 2024) improve the cold-start problem in bundle recommendation via popularity and curriculum heating.\nGenerative Recommendation. In traditional item recommendation, PURE (Zhou et al. 2021) uses GANs to generate fake user and item embeddings, covering diverse feature space corners. LARA (Sun et al. 2020) applies multiple generators on item attributes to create pseudo user profiles, with a discriminator classifying real user-item pairs. DreamRec (Yang et al. 2024) employs a diffusion process to reconstruct oracle item embeddings and retrieve recommendations based on similarity to these oracles. TIGER (Rajput et al. 2024) utilizes Transformer architecture to generate item aspects matching user interests, enhancing item representations with auxiliary data.\nDistant Supervision. Distant supervision is an efficient training strategy applied across various problems and domains, including relation extraction (Mintz et al. 2009; Quirk and Poon 2016), procedural activities recognition (Lin et al. 2022), and image captioning (Qi, Zhao, and Wu 2024). In the context of recommendation systems, distant supervision has been successfully applied for cross-domain recommendation (Elkahky, Song, and He 2015; Cao et al. 2022)."}, {"title": "BRIDGE - Bundle Recommendation via Instruction-Driven Generation", "content": "The overall architecture of BRIDGE is shown in Figure 2. It consists of three main components including item-level correlation clustering, pseudo bundle generation and retrieval & ranking modules. Each component will be thoroughly described in the following subsections.\nProblem Formulation. Given sets of users $\\mathcal{U} = {U_1, U_2, ..., u_{|u|}}$ , bundles $\\mathcal{B} = {b_1,b_2,...,b_{|\\mathcal{B}|}}$, and items $\\mathcal{V} = {U_1, U_2, ..., U_{|\\mathcal{V}|}}$, the observed user-bundle, bundle-item and user-item interactions are respectively represented as three binary matrices $X \\in {0,1}^{|\\mathcal{U}| \\times |\\mathcal{B}|}$, $Y \\in {0,1}^{|\\mathcal{B}| \\times |\\mathcal{V}|}$ and $Z \\in {0,1}^{|\\mathcal{U}| \\times |\\mathcal{V}|}$, where cells with value of 1 if there exists links between user-bundle, bundle-item or"}, {"title": "Correlation-based Item Clustering", "content": "We assume that two items interacted by a common set of users via Z may indicate a potential combination within a pseudo bundle, suggesting that they are closely related in the representation space. This pseudo bundle can serve as an instruction signal to guide the bundle generator to create a meaningful bundle. To verify this hypothesis, we compute the item co-occurrence matrix $C = Z^T \\bullet Z, C\\in\\_R^{|\\mathcal{V}| \\times |\\mathcal{V}|}$. Next, we establish an item homogeneous graph $G = {\\mathcal{V}, E}$, where $\\mathcal{V}$ is the set of nodes and $E = {e_{i,j} | V_i, V_j \\in \\mathcal{V}}$ denotes the edge set, $e_{i,j} = 1$ if $C(i, j) > 0$, and 0 otherwise.\nIn order to learn the item latent embedding of a given item $v_i$ using topological information, we employ a graph convolution network, i.e., LightGCN(He et al. 2020), on the item homogeneous graph G. Let us denote $r_i^{(l)}$ is the item latent representation of item $v_i$ at the $l$-th layer. It is derived as:\n$r_i^{(l)} = \\sum_{j \\in \\mathcal{M_i}} r_j^{(l-1)}$\n(2)\nwhere $r_i^{(0)} \\in \\mathbb{R}^d$ is randomly initialized, $\\mathcal{M_i}$ represent the neighbor set of item i in G. The final item latent representation of item i is inferred as follows:\n$r_i = \\frac{1}{L+1} \\sum_{l=0}^{L} r_i^{(l)}$\n(3)\nwhere L is the number of propagation layers in the GCN, and the final representation of item i is obtained from $r_i$ followed by a second order Euclidean normalization. Inspired by (Le, Lauw, and Fang 2019), we calculate the correlation score $s_{i,j}$ of an item pair (i, j), i, j\u2208 V as:\n$s_{i,j} = r_i \\cdot r_j$\n(4)\nGiven an item $v_i$, the item cluster $C_i$ of k nearest neighbors is determined using a distance function for each pair of items $(V_i, v_j)$ as:\nd_{i,j} = \\frac{1}{exp(s_{i,j})}$\n(5)"}, {"title": "Pseudo Bundle Generation", "content": "In order to facilitate the bundle recommendation task, we aim to construct a pseudo bundle, which expresses the preferential intention of a given user u. Inspired by (Yang et al. 2024), it might be inferred via behavioral history $H_u$, i.e., interacted items $V_{H_u} \\in \\mathcal{V}$. Using the clusters of those items built from the previous section, we suppose that they may create meaningful instructions to better construct the pseudo bundle. Given $\\mathcal{B}_u\\in \\mathcal{B}$ as the bundle set associated with user u, $V_u, V_{\\mathcal{B}_u} \\in \\mathcal{V}$ are the sets of adopted items of user u extracted from Z, and $\\mathcal{B}_u$ respectively, we have:\nV_{H_u} := V_u \\cup V_{\\mathcal{B}_u}\n(6)\nInstruction Construction. For each training iteration of a user u, we randomly select an item $v_i$ from his historical interactions $V_{H_u}$. Using item cluster $C_i$ of k nearest neighbors of $v_i$ determined from the correlation-based item clustering module, an instructive bundle $b_{inst}$ is constructed via:\nb_{inst} = {v_1, v_2, v_3, ..., v_k}\n(7)\nwhere it is noted that $1 < k < n, n = |V_{H_u}|$, k is randomly selected during training to add random noises for improving model robustness. Dependending on the number of historical interactions n, there may have a set of instructive bunbles $\\mathcal{B}_{u,inst} = {b_{inst}}$ generated from multiple training iterations for each user u."}, {"title": "Instruction-Driven Pseudo Bundle Generation", "content": "In order to form a pseudo bundle for relevant bundle retrieval, the instructive set $\\mathcal{B}_{u,inst}$ is fed into a sequence-to-sequence architecture, e.g., Transformer, to aggregate potential items that highly correlate and align with user preferences. Motivated by (Yang et al. 2024), we employ the reconstruction distribution process to reconstruct the temporal distribution of potential item probabilities. Using the collaborative signals from the user's previous interactions $V_{H_u}$ and a given $b_{inst}$, the probability of pseudo bundle $b_{gen}$ after the T-th step generation is derived as follows:\nP_\\theta(\\tilde{v}_{(1:T)}) := \\prod_{t=1}^{T} P_\\theta(\\tilde{v}_{(t)} |V_{H_u}, \\tilde{v}_{0:t-1} )\n(8)\nP_\\theta(\\tilde{v}_{(t)} |V_{H_u}, \\tilde{v}_{0:t-1}) := \\mathcal{N}(\\Phi_\\theta(\\Psi_\\theta(V_{H_u}), \\tilde{v}_{0:t-1}), \\beta I),\nwhere $\\tilde{v}_{(t)}$ is the t\u2013th candidate item, and $\\tilde{v}_{(1:T)}$ is the candidate item set after T generation steps for $b_{gen}$. Likewise, $\\tilde{v}_{0:t-1}$ is the item set consisted of a start-of-bundle pseudo item [sob] at the first index and the first t \u2013 1 items of $b_{inst}$. $\\mathcal{N}$ denotes the Gaussian distribution, I \u2208 R|V| is the identity tensor, $\\Psi_\\theta(\\cdot)$ and $\\Phi_\\theta(\\cdot)$ respectively are Transformer encoder and decoder (Vaswani et al. 2017), and \u03b2 is a hyperparameter control the variance of the probability distribution. The final pseudo bundle $b_{gen} = {\\tilde{v}_1, \\tilde{v}_2, ..., \\tilde{v}_{\\tilde{t} }}$ is the $\\tilde{t}$ candidate items extracted from the $\\tilde{v}_{(1:T)}$ set, where $v_{t+1}$ is the end-of-bundle pseudo item [eob].\nDuring inference process, we do not utilize the instructive bundle set to neglect biases in constructing the pseudo bundle. It is merely generated based on the historical interaction of users $V_{H_u}$ and previously-selected candidate items via the following procedure:\nP_\\theta(\\tilde{v}_{(1:T)}) := \\prod_{t=1}^{T} P_\\theta(\\tilde{v}_{(t)} |V_{H_u}, \\tilde{v}_{(0:t-1)}),\n(9)\nP_\\theta(\\tilde{v}_{(t)} |\\mathcal{U}_{1:n}, \\tilde{v}_{(0:t-1)}) := \\mathcal{N}(\\Phi_\\theta(\\Psi_\\theta(V_{H_u}), \\tilde{v}_{(0:t-1)}), \\beta_1 I),\nwhere the final pseudo bundle $b_{gen}$ is built in the similar way as the training phase."}, {"title": "Retrieval & Ranking", "content": "With the objective of recommending existing bundles, we employ a retrieval and ranking workflow. The main idea is to discover for the top-K bundles in $\\mathcal{B}$ that are most similar to the pseudo bundle $b_{gen}$. It raises a need to calculate similarity score between the pseudo bundle $b_{gen}$ and each bundle $b \\in \\mathcal{B}$ of a given user u. Generally, there are two typical similar metrics including Jaccard similarity $y_{u,b}^J$ and Cosine similarity $y_{u,b}^C$. The former favors the exact matching among bundles while the latter emphasizes the relative one using latent preferential features.\nFor Jaccard similarity, let us denote $c_{gen}$, $c_b \\in {0,1}^{|\\mathcal{V}|}$ are binary vectors that represent the occurrence of items within the pseudo bundle $b_{gen}$ and a bundle $b \\in \\mathcal{B}$, we have:\ny_{u,b}^J = \\frac{c_{gen}^T c_b}{c_{gen}^T \\cdot I + c_b^T \\cdot I - c_{gen}^T c_b}\n(10)"}, {"title": "Optimization", "content": "Our model BRIDGE is trained with triplet losses namely clustering loss $\\mathcal{L}_C$, the pseudo bundle generation loss $\\mathcal{L}_G$ and the recommendation loss $\\mathcal{L}_R$. Specifically, the clustering loss is to maximize the correlation score between potential items within bundle instructions. It is calculated as:\n\\mathcal{L}_C = \\sum_{(v_i, v_j, v_{j'}) \\in P} -In \\sigma(ln(\\frac{1}{d_{i,j}} ) - ln(\\frac{1}{d_{i,j'}})),\n(15)\nwhere $\\sigma(\\cdot)$ denotes the Sigmoid function. $d_{i,j}$ represents the distance between item pair (vi, vj) in the latent space as Eq (5), and $P = {(V_i, v_j, V_{j'})|V_i, v_j, V_{j'} \\in \\mathcal{V}, C_{i,j} = 1, V_i \\neq v_j, C_{i,j'} = 0, V_i \\neq v_{j'} }$.\nTo distill the knowledge from the instruction-driven bundles to the pseudo bundle, we apply the cross-entropy loss over T timesteps as:\n\\mathcal{L}_G = -\\frac{1}{T} \\sum_{t=1}^{T} ln(P(\\hat{v}_t \\vert V_{1:n}, V_{0:t-1}))_{inst}^{b},\n(16)\nwhere $b_{inst}$ is the target distribution at t given by $b_{inst}$.\nInspired by (Rendle et al. 2012), the bundle recommendation loss is computed as:\n\\mathcal{L}_R = \\sum_{(u,b,b') \\in Q} -In \\sigma(\\hat{Y}_{u,b} - \\hat{Y}_{u,b'}),\n(17)\nwhere $Q = {(u,b,b')|u \\in \\mathcal{U};b, b' \\in \\mathcal{B}; Z_{u,b} = 1, Z_{u,b'} = 0}$. Finally, the combined loss function of BRIDGE is achieved as follows:\n\\mathcal{L} = \\mathcal{L}_G + \\mathcal{L}_C + \\mathcal{L}_R + \\lambda ||\\Theta||^2,\n(18)\nwhere $||\\Theta||^2$ denotes the L2 regularization, and $\\lambda$ indicates a hyperparameter to control."}, {"title": "Experimental Setup", "content": "Datasets. We run extensive experiments on five datasets in multiple domains namely Clothing, Electronics, Food and Steam. The data statistics are illustrated in Table 2.\n\u2022 Clothing, Electronic, Food (Sun et al. 2022) are constructed from the Amazon dataset with high quality bundles of products using crowd-sourcing resources.\n\u2022 Steam\u00b9 (Pathak, Gupta, and McAuley 2017) includes bundles of games purchased together on the Australian game platform.\n\u2022 iFashion (Chen et al. 2019b) is a fashion outfit recommendation dataset, each outfit is treated as a bundle.\nComparative Models. To demonstrate the effectiveness, we compare BRIDGE with several state-of-the-art models for bundle recommendation:\n\u2022 Factorization Models: BPRMF (Rendle et al. 2012) and DAM (Chen et al. 2019a);\n\u2022 Graph-based Models: LightGCN (He et al. 2020), BGCN (Chang et al. 2020), MIDGN (Zhao et al. 2022), CrossCBR (Ma et al. 2022), BundleGT (Wei et al. 2023), Mul-"}, {"title": "Model Component Contribution", "content": "We conduct various ablation studies to investigate the importance of BRIDGE main components. We present the analysis for the Steam and Electronic datasets, with the remaining results provided in the appendix.\nThe ablation results are shown in Table 3. Specifically, for the w/o Inst scenario, instructions are removed, meaning the generation module is trained without any guidance from the instructions. In the w/o Gen scenario, instead of generating pseudo ideal bundles, we aggregate all user instructions as user preferences. Without guidance from instructions (w/o Inst), there is a significant drop in performance on both the Steam and Electronic datasets: R@1 decreases by 19.5%, R@2 by 24%, N@1 by 18.8%, and N@2 by 21.1% on Steam. On Electronic, the reductions range from 14% to 17%. This shows the importance of training the bundle generation within the correlation guidance signals. Without it, not only does it affect the quality of the generated bundles, but it also drags down the similarity between pseudo bundle and predefined ones due to introducing more noisy items to the 'ideal' bundles. The effectiveness of the generation component is also highlighted. Without pseudo bundle generation (w/o Gen), a substantial drop in performance is consistently observed, with reductions exceeding 70% on Steam and over 50% on Electronic.\nWe also conduct experiments to further analyze the impact of the number of encoder-decoder layers and the maximum context length T on the Pseudo Bundle Generation module. As shown in Figure 3, the number of encoder-decoder layers noticeably impacts model performance. Increasing the number of encoder/decoder blocks from 1 to 2 leads to a clear improvement on Electronic, while performance on Steam remains stable across different numbers"}, {"title": "Qualitative Analysis", "content": "The quality of a generated pseudo ideal bundle is hard to evaluate. Pathak, Gupta, and McAuley (2017); Han et al. (2017) focused on evaluating the compatibility score between items within the generated bundles as a way to measure their quality. Chen et al. (2019b) experimented the generated bundles on an online platform which is hard to follow. To address this problem, we evaluate our generated bundles through a downstream bundle recommendation task. A generated bundle is denoted as a meaningful bundle if it highly similar to an unseen bundle of a user.\nCorrelation-based Item Cluster. Before demonstrating that the generated bundles are meaningful, we show some examples of the instructions given to the generator are consistent wherein the items have same underlying representation. Figure 6 shows the latent representations for items where items with high correlation are close to each other, some of the meaningful clusters are shown: the \"Desktop\" cluster contains \u201cLogitech Speakers\u201d, \u201cAudio Headphones\", \u201cWireless Keyboard\u201d, and \u201cWireless Mouse\u201d. While the \"Camera\" cluster is a combination of \u201cLens for Digital Cameras\u201d, \u201cLight Stand\u201d and \u201cBackdrop Background\u201d.\nPseudo 'Ideal' Bundle. For user in the testing set, the output bundles generated by our model are highly similar with the ground truth bundles at item level. This leads to very significant improvement over all baseline methods, on Steam the generated bundle tends to be a jointly subset of ground truth bundles that make BRIDGE can retrieve multiple bundles with different aspects which match user varied interest. The product bundles generated by the BRIDGE model have been shown to exhibit meaningful and useful"}, {"title": "Conclusion", "content": "In this paper, we introduce BRIDGE, a novel framework for bundle recommendation inspired by distant supervision strategies and the generative paradigm. The framework integrates correlation-based item clustering modules that enables the generation of auxiliary information without relying on external data. By combining this with collaborative signals from user historical interactions, BRIDGE can produce pseudo 'ideal' bundles, which allows to explore a broader range of potential bundles beyond those predefined ones. This approach effectively narrows the gap between user expectations and available bundles, leading to improved recommendation performance. Extensive experiments demonstrate the effectiveness of BRIDGE over comparative models for bundle recommendation on five public datasets."}]}