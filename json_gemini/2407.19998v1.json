{"title": "Do LLMs Really Adapt to Domains? An Ontology Learning Perspective", "authors": ["Huu Tan Mai", "Cuong Xuan Chu", "Heiko Paulheim"], "abstract": "Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL.", "sections": [{"title": "1 Introduction", "content": "Knowledge Bases (KB) and ontologies play a key role in structuring and organ-izing knowledge across domains, and offer powerful solutions to link data thatwould otherwise remain unstructured (such as text). As of now, many sources ofdata can be used as ontologies, of varying specificity. For instance, WordNet [17],ConceptNet [14] and WebIsA [23] contain common knowledge, whereas KBs such"}, {"title": "2 Related Work", "content": "Ontology Learning with LLMs. OL is the (semi)automatic acquisition ofT-Box and/or A-Box data from various data sources. In the context of this work,we look at OL from unstructured text or semi-structured data such as KnowledgeGraphs paired with textual descriptions. More generally, recent studies show thatLLMs can be leveraged to perform ontology related tasks, such as OM (OntologyMatching) or OL. For instance, Norouzi et al. [20] use a naive approach thatuses ChatGPT for ontology alignment, by providing the entire source and targetontologies. Mateiu et al. [15] use a fine-tuned GPT-3 to convert natural languageinto OWL Functional Syntax for ontology enrichment. Hertling et al. [9] use few-shot prompting to enhance the performance of open-source LLMs on OM tasks.In LLMs4OL [7], the authors argue that with sufficient formulation, all taskspertinent to OL fall within one of the three categories: A) Term Typing (deter-mining a generalized type for a lexical term), B) Taxonomy Discovery (determin-"}, {"title": "3 Approach", "content": "Figure 1 illustrates an overview of the pipeline we employ to test the adaptabilityand generalizability of off-the-shelf LLMs (pretrained, and as is), which includes\ntwo main steps: corpus preparation and LLMs evaluation.\nIn particular, we use the English WordNet (2023 Edition) [16] to generatea parallel corpus of terms and definitions in the form of gibberish, which serveas our reference domain-specific setting. The process begins by choosing rootconcepts (for instance, sweets and desserts) in the WordNet taxonomy, thenexplores the graph through hyponymy, derivation and other (e.g. topic) rela-tionships across concepts (with a set maximal exploration depth). The exploredconcepts form a domain in the real WordNet (e.g. sweets domain) that can beused to create a parallel corpus by propagating gibberish representations anddefinitions. More details about the algorithm can be found in Section 3.1."}, {"title": "3.1 Parallel Corpus Synthesis", "content": "To simulate a domain that is unseen for the LLM, we generate another KGwhere the domain concepts have gibberish representations and definitions thatdo not collide (e.g. if \"sugar\" is turned into \"arghl\" then any definition thatcontains the word \"sugar\" will see it turned into the word \"arghl\" instead). Forthis purpose, we devise a procedure which includes three steps: concept mining,concept linking and gibberish generation. The code can be found online. 3\nConcept Mining. The concept mining algorithm is a simple Breadth-FirstSearch algorithm, starting from each of the root concepts $C_0$ and only goingthrough user-selected relationships (hypernymy, sense derivation, and concepttopic). We set a maximal exploration depth $D$, which is set to 5 during experi-ments. The explored concepts form a dataset $D$.\nConcept Linking. The next step of this process is to establish the dependen-cies between concept definitions and other concepts. For example, if \"sugar\" ismentioned in the definition of concept $c$, then we will link all the concepts $C_{sugar}$which have \"sugar\" as a representation with $c$ by introducing a blank node asfollows, where {c_id} denotes the WordNet ID of $c$:\nGibberish Generation. We assume that we have an algorithm $T$ that creates agibberish representation $T(c)$ from a concept $c$ based on its initial representation,definition and part-of-speech. A concept is fully processed when it has a gibberishdefinition AND a gibberish representation. A concept is partially processed whenit has a gibberish representation (fully processed implies partially processed).Denote $D_0$ the set of concepts in $D$ that have no internal dependencies (i.e.for any $c$ in $D_0$, the definition of $c$ does not refer to any concept in $D$), as shownin Figure 2a. We create an initial representation $T(c)$ for any $c$ in $D_0$, and givethem a gibberish definition identical to their original one. We will additionally"}, {"title": "3.2 Off-the-Shelf Evaluation Methodology", "content": "For each dataset $D$, we perform an evaluation by comparing the performanceof off-the-shelf LLMs in two different lexical semantic tasks: relation extractionand taxonomy discovery; and compare the outputs coming from two cases: onthe original dataset, and its gibberish counterpart.\nRelation Extraction. Given a query concept in $D$, its lexical senses (i.e. writ-ten forms) and its definition, the goal of this task is to extract all relationsbetween the concepts mentioned in the definition, including the query concept.To remain in the frame of ontology learning, we focus only on hypernymy andholonymy relationships. For instance, in Example 1, the extracted relationsshould be as follows: macaron is a subclass of confection, egg white is a partof macaron, icing sugar is a part of macaron, etc. Likewise, given the gibberishdefinition in 2 instead, we expect the same relations to be extracted, only withthe concept names replaced with their gibberish counterpart. In order to retrievea prediction, the LLM is prompted to output triples in the form: $(A, r, B)$ where\n$r$ is either is a subclass of or is a part of.\nTaxonomy Discovery. Given two concepts A and B in D, with their lexicalsenses and definitions, the goal of this task is to determine whether or not A is asubclass of B. Likewise, we expect that turning the lexical senses and definitionsof A and B into gibberish will not change the outcome. WordNet hypernymyrelations are used as a ground-truth: the predictions on the real (resp. gibberishcounterpart of the) dataset are compared with the real (resp. gibberish coun-terpart of the) ground-truth. Indirect hypernymy relations (obtained with thetransitive closure of the relation gwn: hypernym) are also used. Negative examplesare produced by corrupting the hypernym once or twice per query (hyponym,subclass of, ?). This classification task can be evaluated with F1-score: a dropin performance should indicate that a LLM relies on the lexical senses to infertaxonomical relationships rather than textual semantic information.\nPrompting. For each task/model configuration, we follow general guidelinesfor prompting a LLM. (1) The return is in JSON format, (2) Chain-of-Thought(CoT) [30] can be used if it improves the performance of the model, (3) Oneor few exemplar(s) can be used, with example(s) outside of the dataset, if itimproves the performance of the model. In the relation extraction task, for aconcept C, its written form $F_C$, its part-of-speech $P_C$, and its definition $D_C$, weconstruct a prompt $p(C)$ as shown in Listing 1.2. In the taxonomy discoverytask, for A, B two concepts, $F_A$, $F_B$ their written forms, $D_A$, $D_B$ their definition,we construct a prompt $p(A, B)$ as shown in Listing 1.3. Prompt templates canbe found here."}, {"title": "3.3 Fine-tuning Experiment", "content": "While it was previously verified that fine-tuning improves OL performance inexisting domains [19], it is not clear if this statement still holds for arbitrarydomains and unknown vocabularies where reasoning is required. To verify thisquestion, after evaluating the zero/one/few-shot performance of LLMs in thegibberish domains, we propose to assess the effect of fine-tuning models on theinference performance for a specific task.\nData split. For each dataset D, we fine-tune a LLM for taxonomy discoveryon a train split of hypernymy relations. Half of the concepts in the dataset, andtheir hypernymy relations, are used for training. The inverse relations are usedas negatives (if A is a subclass of B, then B is not a subclass of A), alongside\nsome randomly sampled negatives. The remaining relations are used for testing.\nPrompting. We train LLMs on instructive datasets with the prefix prompt inListing 1.4, completed using each pair of concepts in the hypernymy dataset."}, {"title": "4 Experiments", "content": "In this section, we explore the off-the-shelf evaluation proposed in Subsection 3.2,and the fine-tuning experiments described in Subsection 3.3."}, {"title": "4.1 Experimental setup", "content": "Datasets. To assess the performance variation with domain specificity, we gen-erate three synthetic domain-specific datasets as parallel corpora from the OpenEnglish WordNet [16], using the methodology described in Section 3.1. They are:\nSweets: A collection of concepts related to sweets, desserts, sweet food orsugar. In this dataset, hypernyms are frequent, and concepts are relativelywell constructed from their hypernyms.\nFootball: A collection of concepts related to football. This dataset, createdby browsing co-topic concepts, includes less taxonomic relationships, but hasits own terminology and jargon.\nMusic: A collection of concepts related to musical instruments. It is thelargest of the three."}, {"title": "4.2 Off-the-Shelf Evaluation", "content": "Metrics. For each model/task configuration, we compute metrics in three set-tings: GT(en) vs en, GT(gib) vs gib, and en vs gib. The goal is to see if thepredictions with gibberish terms align with the predictions with the real terms.We compute the following metrics: precision, recall and F1-score.\nResults. We first examine the results with respect the to ground-truths. It isimportant to mention that the English WordNet is scarcely annotated in termsof hypernymy and holonymy relationships. Consider the following example:\nIn this example, the definition obviously implies that a toffee apple is anapple, but WordNet only considers sweet, confection to be valid hypernyms. Theincompleteness of WordNet explains why the observed performances are so low,but because our goal is a relative comparison of performances on real corpora"}, {"title": "4.3 Fine-Tuning Evaluation", "content": "Training details. Table 6 shows the number of hypernym pairs used for thefine-tuning experiment. We use instruction tuning specifically tailored towardstaxonomy discovery. In the prefix prompt documented in Listing 1.4, given twoconcepts A and B, the model must return \"True\" if A is a subclass of B and\"False\" otherwise. We train the model on 20 epochs, with a batch size of 4 anda learning rate of $3 \\cdot 10^{-6}$. For efficient training, we quantize the model on 4 bitsand use the LoRA [10] method with parameters $\\alpha = 256$ and r = 1024.\nMetrics. Similarly to the first experiment, we use Precision, Recall and F1-scoreto evaluate the performance of the model on the testing set.\nResults. The results of the fine-tuning experiment are reported in Table 7. Twogeneral observations can be made about the experiment. Firstly, we notice thatfine-tuning drastically improves the task-specific performance of the LLM re-gardless the domain and corpus version. For instance, while Falcon-7B seems tobe initially worse-performing than Zephyr-7B-$\\beta$ overall, the F1-score improvesup to almost threefold (real WN-music dataset, from 0.327 to 0.874). Althoughnot surprising for real corpora, an improvement on gibberish corpora is non-trivial: the LLMs show signs of adaptation on gibberish corpora with improved"}, {"title": "5 Conclusion", "content": "We have explored and tested the limits of adaptability and generalizability ofLLMs, and observed that LLMs do not adapt well to arbitrary domains. Bycreating gibberish datasets based on real data and real domains from Word-Net, and using LLMs to perform ontology learning tasks on these data, it isrealized that LLMs are unable to consistently retrieve the same taxonomic re-lationships between analogous concepts, which highlights their clear reliance onpriorly learned semantics, lexical senses, and the frame of the tokens. However,we notice that after fine-tuning on gibberish data, LLMs improve at discoveringhierarchies, both on the domain they were trained on and other arbitrary do-mains. We attribute this improvement to the emergence of reasoning with lexicalsemantics. Our work serves as cautionary advice for the community that LLMsdo not adapt to arbitrary domains, and we hope that it can inspire future workto leverage reasoning with LLMs for Ontology Learning."}]}