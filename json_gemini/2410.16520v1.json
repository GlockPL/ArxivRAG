{"title": "AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context", "authors": ["Naba Rizvi", "Harper Strickland", "Daniel Gitelman", "Tristan Cooper", "Alexis Morales-Flores", "Michael Golden", "Aekta Kallepalli", "Akshat Alurkar", "Haaset Owens", "Saleha Ahmedi", "Isha Khirwadkar", "Imani Munyaka", "Nedjma Ousidhoum"], "abstract": "As our understanding of autism and ableism continues to increase, so does our understanding of ableist language towards autistic people. Such language poses a significant challenge in NLP research due to its subtle and context-dependent nature. Yet, detecting anti-autistic ableist language remains underexplored, with existing NLP tools often failing to capture its nuanced expressions. We present AUTALIC, the first benchmark dataset dedicated to the detection of anti-autistic ableist language in context, addressing a significant gap in the field. The dataset comprises 2,400 autism-related sentences collected from Reddit, accompanied by surrounding context, and is annotated by trained experts with backgrounds in neurodiversity. Our comprehensive evaluation reveals that current language models, including state-of-the-art LLMs, struggle to reliably identify anti-autistic ableism and align with human judgments, underscoring their limitations in this domain. We publicly release AUTALIC along with the individual annotations which serve as a valuable resource to researchers working on ableism, neurodiversity, and also studying disagreements in annotation tasks. This dataset serves as a crucial step towards developing more inclusive and context-aware NLP systems that better reflect diverse perspectives.", "sections": [{"title": "1 Introduction", "content": "There are several critical frameworks used to define and understand disability, including autism (Lawson and Beckett, 2021). While these frameworks are ever-evolving, the medical model framework which defines disability as a \u201cdisease\u201d is one of the most commonly applied in computer science research when discussing disability in general and autism specifically (Rizvi et al., 2024; Spiel et al., 2019a; Sideraki and Drigas, 2021; Anagnostopoulou et al., 2020; Parsons et al., 2020; Williams et al., 2023; Sum et al., 2022). This framework defines autism as a deficit of skills such as the The-ory of Mind, and its applications in technology research largely focus on providing diagnosis and treatment to autistic people (Baron-Cohen, 1997; Begum et al., 2016; Rizvi et al., 2024; Spiel et al., 2019b). However, this framework has been criticized for creating a power imbalance between medical professionals and the autistic community as it promotes the belief that a formal diagnosis is necessary to validate the autistic identity (Bennett and Keyes, 2020). This belief also posits neurotypical behaviors as the \"norm\" and autism as a \"deficit\" of these norms, thereby promoting neuronormativity instead of neurodiversity, which views all neurotypes as valid forms of human diversity (Bottema-Beutel et al., 2021; Walker, 2014).\nIn contrast, prior work has shown viewing autism as an identity may increase the psychological well-being of autistic individuals and lower their social anxiety (Cooper et al., 2023). Although the language used to describe autism varies, prior studies with autistic American adults found 87% prefer identity-first language over person-first language (Taboas et al., 2023). Person-First Language (PFL) centers the person (i.e. person with autism), while Identity-First Language (IFL) centers the identity (i.e. autistic person) (Taboas et al., 2023).\nPrior work examining ableist speech directed at content creators identified 11 types of \"ableist hate and harassment\" that they categorized as slurs and derogatory language, violent and eugenics-related speech, questioning ability and denying access, mocking and invalidation of disability identity, and objectifying the disabled body (Heung et al., 2024). Additionally, researchers have identified emerging terms such as \"weaponized autism\" that are gaining popularity on alt-right social media platforms, further reflecting the ever-evolving nature of negative societal attitudes towards autism (Welch et al., 2023).\nAnti-autistic ableist language can be diverse in scope. It may include perpetuating stereotypes, using offensive language and slurs, or centering non-autistic people over the perspectives of autistic people (Bottema-Beutel et al., 2021; Rizvi et al., 2024; Darazsdi and Bialka, 2023). While abusive language detection systems can help identify such speech, they are known to demonstrate bias (Manerba and Tonelli, 2021; Venkit et al., 2022), with even LLMs perpetuating ableist biases (Gadiraju et al., 2023a). Additionally, anti-autistic ableist speech remains understudied, which is concerning given that classifiers trained on multiple hate speech datasets have shown a failure to generalize to target groups outside of the training corpus (Yoder et al., 2022).\nAdditionally, no datasets specifically focus on anti-autistic speech classification, and only 3 of the 23 datasets for bias evaluation in LLMs focus on disability (Gallegos et al., 2024). Prior work has also found that LLMs lack an acknowledgment of context, which leads to higher rates of false positives when classifying ableist speech (Phutane et al., 2024). These limitations are also found in toxicity classifiers, which excel primarily at identifying explicit ableist speech but may otherwise perpetuate harmful social biases leading to content suppression (Phutane et al., 2024).\nOur work addresses these gaps in existing research by examining the performance of our dataset in the following domains for the task of anti-autistic hate speech classification:\n1. The impact our dataset has on fine-tuning classifiers\n2. The alignment of LLMs with the perspectives of trained human annotators\n3. The extent to which in-context learning improves human-LLM alignment."}, {"title": "2 Related Work", "content": "Prior studies have also collected insights on anti-autistic language from the parents of autistic children (Allouch et al., 2018, 2019). However, toxic language datasets focusing on hate speech and abusive language have often addressed disability in general terms but have not explicitly focused on autism (ElSherief et al., 2018; Ousidhoum et al., 2019). Therefore, toxic language detection models, including LLM-based models, have been found to exhibit strong negative biases toward disabilities by classifying any disability-related text as toxic (Narayanan Venkit et al., 2023). Further, LLMs have been observed to perpetuate implicitly ableist stereotypes (Gadiraju et al., 2023b) and bias (Gama, 2024; Venkit et al., 2022). This, unfortunately, can sometimes be due to a research design that overlooks intra-community and disabled people's perspectives (Mondal et al., 2022), as well as autistic people's views, which may lead to harmful stereotypes (Rizvi et al., 2024; Spiel et al., 2019b). We make a step towards addressing these issues by building a dataset that focuses on ableist speech and autism by including autistic people's perspectives during the annotation processing as recommended by (Davani et al., 2023). AUTALIC contains all its labels and will also be useful for researchers interested in leveraging disagreements for difficult classification tasks (Leonardelli et al., 2021; Pavlick and Kwiatkowski, 2019)."}, {"title": "3 AUTALIC", "content": "This section discusses the process of compiling and annotating the AUTALIC dataset. We collected relevant sentences containing autism-related keywords from Reddit using the methods described in Section 3.1. The collected sentences were labeled by trained annotators, as discussed in Section 3.2."}, {"title": "3.1 Data Collection", "content": "Here, we present details from our data collection process, which include identifying our methodology for gathering representative sentences related to autism, curating the data obtained through our search parameters, and summarizing the resulting AUTALIC dataset."}, {"title": "3.1.1 Data Collection Criteria", "content": "First, we identified potential data sources and selected Reddit as the preferred source based on its popularity, focus on text-based content, and fewer API restrictions than X at the time of our data collection. We searched for keywords using the default search settings on Reddit, which filters posts based on relevancy by prioritizing rare words in the search query, the age of the post, and the amount of likes and comments it has. Table 1 displays the keywords we searched for on Reddit and the final number of sentences with each keyword in our dataset.\nWe use the identified search terms detailed in Table 1 to collect two types of sentences:\n\u2022 the target instance containing our keywords, to be labeled by the annotators,\n\u2022 the sentences preceding or following target instances to provide additional context.\nWe collected 2,500 target sentences, with 2,014 preceding and 2,500 following them. Finally, we split our dataset into three parts by randomly selecting and assigning 800 unique target sentences to create three segments that were each annotated by a group of three annotators."}, {"title": "3.1.2 Data Curation", "content": "As some of the identified keywords may appear in other contexts, we perform an exact word search for the acronyms to ensure unrelated words that might contain our acronyms are excluded from the search as they go beyond the scope of our dataset. For example, we searched for \u201capplied behavioral analysis\" and a case-sensitive search for ABA, which is a form of therapy intended to minimize autistic behaviors such as stimming (which is often used for self-soothing) (Sandoval-Norton et al., 2019). Similarly, we exclude any posts that are not written in English using the Python package langdetect 2 and posts that contain images, videos, or links."}, {"title": "3.1.3 Final Dataset", "content": "Our final dataset includes 2,400 sentences from 192 different subreddits. To protect our annotators' privacy, we have anonymized all labels.\nFigure 1 shows the distribution of years in which the posts in AUTALIC were published. The range of publication years is 2013-2024, with most posts published in 2023. Figure 2 shows an example of a sentence from our dataset that uses both a search keyword and a word defined in our glossary described in Section 3.2.2.\nThe average number of likes on each post included in the AUTALIC dataset is 1,611.59, and only 135 posts have 0-5 likes. Table 2 details the subreddits from which we extracted the most significant number of sentences for our dataset."}, {"title": "3.2 Data Annotation", "content": "After obtaining sample sentences with contextual surrounding sentences, we proceeded to annotation: annotator selection, training, and data annotation."}, {"title": "3.2.1 Annotator Selection", "content": "We recruited nine annotators and randomly assigned them to annotate different segments of the dataset. Our annotators are undergraduate students who volunteered to annotate the data without financial compensation and were offered authorship following the ACL guidelines on authorship. They are culturally diverse and include people who grew up outside the United States. However, they are all fluent in English. Four of our annotators are gender minorities, and at least three self-identify as neurodivergent.\nAlthough we ensured the annotators were from diverse backgrounds during our recruitment process, due to the collaborative nature of our annotation process, we cannot share the individual details of their identities. We also note that any personally identifiable information was destroyed upon the conclusion of our analysis and not shared outside of our research team."}, {"title": "3.2.2 Annotator Training", "content": "We provided a virtual orientation to all annotators explaining the history of anti-autistic ableism, examples of contemporary anti-autistic discrimination, and a brief overview of the annotation task.\nThe orientation begins with a discussion of the medical model approach to autism and its link to the Nazi eugenics program (Waltz, 2008; Sheffer, 2018). We define neuronormativity as the belief that the neurotypical brain is \u201cnormal\u201d and other neurotypes are deficient in neurotypicality (Wise, 2023). We dive deeper into the medical model by discussing its impact on the self-perceptions and inclusion of autistic people in our society, such as an increase in suicidal ideation and social isolation among autistic people who mask or hide their autistic traits (Cassidy et al., 2014, 2018). Then, we cover the shifts in perspectives that emerged due to disability rights activism (Rowland, 2015; Cutler, 2019), and define neurodiversity as the belief that all neurotypes are valid forms of human diversity (Walker, 2014).\nTo explain the annotation task, we provide examples of sentences similar to what they may encounter while annotating. For example, we discuss how the inclusion of \"at least\" alters the connotations of the follow sentence:\nAt least I am not autistic.\nWith just a minor change, the sentence can have an ableist connotation as it implies relief in knowing one is not autistic, as if it is shameful or wrong.\nWe also introduce our glossary to the annotators as a dynamic resource that can be altered as needed. This glossary contains words that may appear in autism discourse online that may not be commonly known to others. These include medical acronyms, slang, and references to organizations and resources commonly affiliated with the autistic community (such as Autism Speaks). Selected examples from our glossary are shown in Table 3. The final version of our glossary is available can be found in this footnote 3.\nWe conclude our orientation by providing a brief tutorial video demonstrating how to run the script that will guide each annotator through the annotation task."}, {"title": "3.2.3 Data Labeling", "content": "After completing the training, we assign each of the three segments of the dataset to three randomly selected annotators. Each annotator is assigned 800 unique sentences, with a goal of completing 200 annotations each week over four weeks.\nAnnotators select from three possible labels for each sentence: \"Ableist,\u201d \u201cNot Ableist,\" or \"Needs\""}, {"title": "3.2.4 Providing Context", "content": "While we provide additional sentences for context, the annotators are instructed to annotate the target sentence exclusively and only refer to the other sentences for additional context, such as determining whether the sentence is part of an intra-community discussion or the use of figurative speech (i.e. sarcasm). Figure 3 provides an example of a target sentence in context.\nIn this example, it is difficult to determine whether or not the writer had ableist intent, as it can be interpreted in multiple ways. For example, they can be critiquing the medical model, as many autistic activists do, thereby making it non-ableist. Or they could be genuinely promoting ableist misrepresentations. The contextual sentences help the annotators better understand the writer's intent. With these sentences, it is apparent that the writer is referring to the harmful and widely discredited association of vaccines with autism, which not only promotes anti-autistic ableism in society but also puts people's lives at risk by spreading disinformation about the benefits and harms of life-saving vaccines (Gabis et al., 2022; Taylor et al., 2014; Hotez, 2021).\nThroughout the annotation process, annotators can edit previous annotations based on new knowledge to account for changes in language usage and connotations and the annotators' dynamic understanding of ableism."}, {"title": "3.2.5 Disagreements", "content": "The Fleiss's Kappa scores were 0.125 for Team 1, 0.307 for Team 2, and 0.191 for team 3. These scores underline the difficulty of our classification task, which is apparent from the findings of prior work (Ousidhoum et al., 2019). We analyzed the sentences with the highest levels of disagreement in our dataset. We found that such posts:\n1. tend to use medical model terminology or stereotypes\n2. need additional context beyond the sentences we provided.\nOur dataset contains 59 of these sentences.\nFigure 4 contains an example of a sentence with a high disagreement among our annotators. While functioning labels are considered ableist due to their eugenicist approach of categorizing autistic people based on their perceived economic value (De Hooge, 2019), it is difficult to determine whether the original poster is autistic or not. The context is important here as classifying a sentence such as this as 'ableist' can lead to unfair censorship if the original poster is a self-diagnosed autistic person seeking advice. Therefore, these sentences were ultimately classified as 'not ableist' in AUTALIC.\nOur analysis reveals a moderately strong negative correlation between the task completion time and agreement with other annotators that is statistically significant (R = -0.644, p-value: 0.0096). This highlights the importance of our orientation as we provided it simultaneously to the annotators, and the annotators who completed their task immediately after our orientation had higher agreement."}, {"title": "4 Experiments", "content": "Our dataset contains 2,400 sentences labeled as containing anti-autistic ableist language or not. The labels are obtained by calculating the mode from the three annotators of each data segment. Using this methodology, 242 target sentences contain examples of anti-autistic ableist language (10% of total), and 2160 sentences do not (90% of total)."}, {"title": "4.2 Experimental Setup", "content": "We test the performance of different types of models on our dataset, including logistic regression, BERT, and LLMs ranging from PHI 3 Mini to GPT 4. These models are selected based on their diverse range of complexities. We also fine-tune BERT on our dataset to analyze the impact of fine-tuning on anti-autistic ableist speech classification."}, {"title": "4.2.1 Logistic Regression", "content": "We compare the performance of logistic regression (LR) supervised machine learning (ML) models to the majority of labels assigned by trained annotators. First, we use Bag of Words (BoW) as the features of the LR model. We run LR using 80%-20% train-test split of the entire dataset. These results are included in Table 5. We also compare model results with majority label downsampling since target sentences labeled with anti-autistic ableism only represent 10% of the dataset. We repeat the same LR analysis using Bag of N-Grams for both n = 2 and n = 3 (bi-grams and tri-grams)."}, {"title": "4.2.2 BERT", "content": "We use the BERT (Devlin et al., 2019) large uncased model that contains 335M parameters, again using 80% of the data for training and 20% for testing. We used a linear layer on the pooled output of the model for classification. We obtained results with BERT after fine-tuning with the AUTALIC dataset, as shown in Table 6. We conducted this experiment using the test set as a validation set to choose the best hyperparameters, as we wanted to obtain the best-case-scenario performance for a fine-tuned BERT Large on this task."}, {"title": "4.2.3 LLMS", "content": "We prompt GPT-405 and the instruction tuned variants of Llama-3-8B (Dubey et al., 2024), Aya-23-8b (Aryabumi et al., 2024), Gemma-2-2B (Team et al., 2024), Mistral-7B (Jiang et al., 2023), Phi-3-Mini (Abdin et al., 2024) to classify the sentences in our dataset, and we adjust the prompts to compare each LLM's performance using person-first or identity-first language. We keep the default parameters for each LLM to maintain consistency, and prompt them with the following questions:\n1. Is this sentence ableist toward people with autism?\n2. Is this sentence anti-autistic?\n3. Is this sentence ableist toward autistic people?\nWe include each sentence from AUTALIC after the aforementioned questions in our full prompt. In addition, we provide preceding and following context for each target sentence to the LLM to mimic the level of the information supplied to human annotators."}, {"title": "4.3 Experimental Results", "content": "Our experiments reveal that utilizing BERT for this classification task can lead to high rates of censorship. As BERT is not pre-trained with instructions unlike LLMs, we obtain its results after fine-tuning on AUTALIC. BERT has a high rate of false positives as nearly 2/3rds of sentences it considers ableist are not ableist according to our human annotators."}, {"title": "4.3.2 Human-LLM Alignment", "content": "Our assessment reveals that LLMs have low levels of alignment with human perspectives and the perspectives of other LLMs, which makes them unreliable agents for such classification tasks. We assess this alignment through a measurement using Cohen's Kappa scores. The scores shown in Figure 5 indicate that GPT-40 had higher levels of alignment with our human-annotated dataset than any other LLM (k = 0.28). Overall, the LLMs had low levels of agreement with human perspectives (M = 0.1029, SD = 0.1096), and even lower agreement with each other, as Phi had a worse-than-chance agreement with Gemma and Llama."}, {"title": "4.3.3 Safety Checks", "content": "Various LLMs have built-in safety checks, which cause them to give an invalid response, and this automatic censorship makes it difficult to employ them for the task of anti-autistic ableist speech classification. For example, Gemma has built-in safety checks that prevent it from labeling sentences that contain explicit slurs such as r*tard. Interestingly, Phi was the only LLM that did not classify certain sentences that mentioned video games without explicitly referencing autism. For example, posts discussing the Read Only Memories: NEURODIVER video game were included in our dataset as neurodiver* was one of our search keywords. These sentences simply included the titles of video games and the dates, organizations, or people affiliated with them. Notably, these safety checks only occurred when the models were prompted to detect hate speech before classifying a specific sentence. This alludes to LLMs not having an understanding of anti-autistic language as hate speech without specific instruction."}, {"title": "4.3.4 Understanding Ableist vs. Anti-Autistic Speech", "content": "Our results with prompt engineering reveal that anti-autistic ableism is too abstract of a concept for LLMs to recognize, providing empirical evidence that their current reasoning abilities are not inclusive of the perspectives of autistic people. LLMs struggle with identifying anti-autistic speech regardless of the terminology used, further indicating they are unreliable agents for data annotation tasks.Table 7 displays the results of prompt engineering using either person-first or identity-first language and using 'anti-autistic' as another identity-centered way of describing this form of ableism. These results show that LLMs struggle with conceptualizing ableism directed at autistic people and its semantics. However, we can see that GPT-40 performed considerably better than the other LLMs we tested. One key difference between GPT-40 and other LLMs is the number of parameters. Based on the performance of GPT-40 on benchmarks and our understanding of scaling laws in regards to model size (Kaplan et al., 2020), we estimate that GPT-40 has a far greater number of parameters than any other LLM we tested. This suggests that for larger model sizes, LLMs can begin to identify anti-autistic speech."}, {"title": "4.4 Discussion", "content": "Our experiments demonstrate the importance of AUTALIC in aligning LLM performance to human expectations in the contexts of autism inclusion and ableist speech classification. Through our experiments, we provide empirical evidence of the current limitations of using LLMs to identify expressions of anti-autistic ableism. These limitations include: a misalignment with human perspectives, a lack of understanding of the concept of anti-autistic ableism, and censorship arising from safety checks. Each of these limitations adds to the challenge of utilizing LLMs as reliable agents for such tasks."}, {"title": "5 Conclusion", "content": "In this paper, we introduced AUTALIC, the first benchmark dataset focused specifically on the detection of anti-autistic ableist language in context. Through the collection and annotation of 2,400 sentences from Reddit, we aim to fill a critical gap in current NLP research, which has largely overlooked the nuanced and context-dependent nature of ableist speech targeting autistic individuals. Our dataset not only captures key contextual elements but also incorporates a comprehensive annotation process led by trained annotators with an understanding of the autistic community, ensuring higher reliability and relevance.\nOur experiments demonstrate the significant limitations of existing language models, including LLMs and traditional classifiers, in effectively identifying anti-autistic ableist speech. Standard pre-trained models such as showed poor performance, reinforcing the need for specialized fine-tuning. However, even after fine-tuning BERT on the AUTALIC dataset, our experiments reveal a high rate of false positives, which can lead to unfair censorship if BERT is employed for this task. Additionally, our results reveal that even state-of-the-art LLMs struggle with implicit bias and exhibit low agreement with human annotators on this task, further emphasizing the challenges of detecting subtle forms of ableism using generic models.\nLooking forward, AUTALIC paves the way for significant advancements in content moderation systems, hate speech detection models, and research on ableism and neurodiversity. We envision this dataset as a cornerstone for future work in addressing bias against autistic individuals and fostering a more inclusive digital environment. By sharing this resource with the broader research community, we aim to catalyze the development of more equitable NLP systems that better serve underrepresented and marginalized groups."}, {"title": "6 Limitations", "content": "Despite doing our best to include a variety of ableist language against autistic people, our dataset can still show some selection bias (Ousidhoum et al., 2020) as we relied on keywords and specific social media threads to collect our data.\nWe acknowledge that our work centers Western perspectives in defining and understanding autism (Anderson-Chavarria, 2022). Therefore, we do not claim that AUTALIC is generalizable across languages and cultures as anti-autistic and ableist speech may manifest and be perceived differently.\nOur dataset only contains sentences from Reddit, and subreddits focusing on autism such as r/Aspergers, r/Autism, and r/AutismInWomen were among the most popular subreddits the posts were"}, {"title": "7 Ethics Statement", "content": "All the sentences in our dataset are publicly available, and we follow the methodologies of prior work in our data collection process (Atuhurra and Kamigaito, 2024). We received IRB approval from our university's review board and identified volunteer annotators through our association with various academic groups. Due to the sensitive nature of the content, we provided trigger warnings to our annotators and allowed them the freedom to annotate at their own pace. Additionally, we connected the members of each annotation team to enable discussions on the content and annotation process as needed.\nWhile our dataset and citations will be made available to the academic community, commercial use of the dataset is not allowed due to the size and nature of the data. As our knowledge of anti-autistic ableism continues to evolve, AUTALIC's classification might become outdated. While we will be adding disclaimers if needed to reflect these changes, we still encourage researchers building upon our work to stay updated on the latest semantics by referring to the perspectives of autistic scholars, activists, and organizations."}]}