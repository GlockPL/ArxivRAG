{"title": "Generating Unseen Nonlinear Evolution in Sea Surface Temperature Using a Deep Learning-Based Latent Space Data Assimilation Framework", "authors": ["Qingyu Zheng", "Guijun Han", "Wei Li", "Lige Cao", "Gongfu Zhou", "Haowen Wu", "Qi Shao", "Ru Wang", "Xiaobo Wu", "Xudong Cui", "Hong Li", "Xuan Wang"], "abstract": "Advances in data assimilation (DA) methods have greatly improved the accuracy of Earth system predictions. To fuse multi-source data and reconstruct the nonlinear evolution missing from observations, geoscientists are developing future-oriented DA methods. In this paper, we redesign a purely data-driven latent space DA framework (DeepDA) that employs a generative artificial intelligence model to capture the nonlinear evolution in sea surface temperature. Under variational constraints, DeepDA embedded with nonlinear features can effectively fuse heterogeneous data. The results show that DeepDA remains highly stable in capturing and generating nonlinear evolutions even when a large amount of observational information is missing. It can be found that when only 10% of the observation information is available, the error increase of DeepDA does not exceed 40%. Furthermore, DeepDA has been shown to be robust in the fusion of real observations and ensemble simulations. In particular, this paper provides a mechanism analysis of the nonlinear evolution generated by DeepDA from the perspective of physical patterns, which reveals the inherent explainability of our DL model in capturing multi-scale ocean signals.", "sections": [{"title": "1. Introduction", "content": "As a key component of the Earth system, the ocean plays a vital role in regulating global climate and maintaining ecological balance. Accurate prediction of the multi-scale evolution of the ocean is our common goal [1]. However, the nonlinear characteristics of the ocean pose a major challenge to traditional data assimilation and prediction systems. In recent years, observation technology has developed rapidly and data has become increasingly abundant. This brings a new opportunity to deeply understand nonlinear evolution such as extreme weather and ocean processes. We also have higher requirements for the accuracy of Earth system predictions. The uncertainty in numerical predictions of the Earth system is largely controlled by the quality of initial conditions [2]. To solve this problem, data assimilation (DA) technology has been developed and applied in the optimization of initial conditions. DA is a method that obtains an optimal estimate [3] of the initial state by fusing multi-source information (observations and simulations). Among them, observations can represent the relatively real system state, but the distribution of observations is sparse [4]. The model simulations can represent the system state completely, but model errors make the simulation results often inaccurate [5]. Therefore, DA is generally considered to be very effective in improving the quality of initial conditions.\nA series of studies have been devoted to the update and application of DA technology, summarized into two categories [6,7]: variational DA methods and filtering DA methods. Typical variational DA includes three-dimensional variational (3D-Var) and four-dimensional variational (4D-Var) DA methods [8,9]. Variational DA is often employed to solve complex optimization problems, so large amounts of computing resources are required. Most of the current filtering DA methods employ the Kalman filter or its variants"}, {"title": "", "content": "[10-13]. Filtering DA is suitable for the fusion of real-time observations, but it requires model simulation to quantify the covariance structure before assimilating observations [14,15]. In summary, the above methods all require running the model repeatedly, so the traditional DA methods are computationally expensive and time-consuming [16]. In addition, sparse observations also prevent the fine structures in nonlinear evolution from being seen. Therefore, improving data fusion efficiency and paying attention to unseen nonlinear evolutions are major challenges facing current DA methods[17-19].\nRecently, deep learning (DL) technology has been applied in many fields, such as computer vision [20], natural language processing [21] and image or text generation [22]. In Earth science, DL has also been successfully applied in the fields of oceanography, meteorology and remote sensing to help humans understand scientific issues of the Earth system [23-26]. A large number of studies have emphasized that the combination of DL and DA will bring breakthroughs in numerical prediction [27\u201330]. In fact, DL has been involved in some specific tasks of DA. For example, the DL model is combined with the Weather Research and Forecasting Model (WRF) to learn the DA process of 3D-Var [31], which is driven by observations to generate analysis increments. Furthermore, DL is effective in estimating model bias [32], which is close to weakly constrained 4D-Var. In order to take full advantage of the automatic differentiation of the DL framework, DL models are employed to construct tangent linear models and adjoint models in variational DA [33]. To speed up the DA process, a multi-layer perceptron (MLP) is employed to learn the relationship between observations and model solutions [34], which can learn model parameters by minimizing the mean square error between the MLP and 4DVar results. Similarly, a recurrent neural network [35] is trained to learn DA, which takes the distance between numerical predictions and analysis results as a constraint. In addition, an \u201cEnd-to-End\u201d DL framework is designed as an efficient solver for DA problems [36], which performs well with the help of automatic differentiation. Overall, different DL methods have been applied to various sub-problems of DA, including spatio-temporal interpolation [37], downscaling [38] and parameter estimation [39]. These results are encouraging, however, there are still three issues that need a further breakthrough.\nFirst, the dimension of ocean state is usually large, which directly affects the efficiency of multi-source data fusion. DL models perform well in low-dimensional systems, but oceanic systems are actually much more complex. In fact, the power of DL models is feature extraction and compression. Therefore, DA in the original state space is not the optimal choice for DL models. We draw inspiration from a study [40] on latent space data assimilation using neural networks (NNDA), which has been applied to the assimilation of atmospheric states. The results show that it cannot only improve efficiency but also help DL better understand and represent nonlinear processes in dynamic systems.\nSecond, we focus on the nonlinear and multiscale evolution of the ocean, which is generally more difficult to observe than the atmosphere. The internal structure and dynamic changes of the ocean are more complex and difficult to capture directly through conventional observation methods. Latent space DA, such as NNDA, performs well in capturing atmospheric states, but the scheme design and performance evaluation of ocean processes are still insufficient. In addition, ocean observations of different resolutions have a significant"}, {"title": "", "content": "impact on the stability of DL models. Therefore, generating unseen nonlinear evolution only through known observations and background information requires us to develop a \"End-to-End\" deep learning DA framework for heterogeneous data.\nThird, deep learning models are considered a \u201cblack box\u201d. The lack of explainability has become a huge obstacle to the promotion of data-driven models in earth science research. We hope that the generated nonlinear evolution is reasonable, which requires the underlying physical connections between the data to be transparent. At the same time, our framework should be compatible with data from different sources (simulations, reanalyses or observations), which also requires a consistent physical constraint that can reveal the generation of nonlinear evolution.\nTo address the issues mentioned above, we propose a new explainable latent space data assimilation framework (referred to as DeepDA) based on deep learning for generating unseen nonlinear evolutions in the ocean. We draw inspiration from existing methods, including linear order reduction schemes [41,42] and sequential DA schemes under simplified models [43]. First, we design a generative proxy model (GenPM) based on self-supervised learning that can map the ocean state into a latent space. It is worth mentioning that we build a spatio-temporal attention residual (STAR) module and integrate the STAR module into the GenPM, which can help the DeepDA extract spatio-temporal multi-scale features. In order to improve scalability, the GenPM and latent space DA in the DeepDA are designed as independent modules. We employ the 3D-Var constraint form to construct the loss function of latent space DA. The latent space DA module employs automatic differentiation techniques in the DeepDA framework and is compatible with different tasks. Such a design can not only meet the needs of multi-modal data fusion, but also improve the overall DA efficiency. In order to verify the feasibility and explainability of DeepDA, we will conduct evaluation and analysis experiments using sea surface temperature (SST) as an example. To sum up, the major contributions of this study are summarized as follows:\n\u2022 We devise a novel purely data-driven DA framework (DeepDA) in latent space, which can effectively fuse multi-source information and generate unseen nonlinear evolution. The DeepDA is guided by general variational constraints, which achieves superior performance in different tasks.\n\u2022 We design an advanced GenPM to learn the nonlinear evolution of SST. The STAR module is designed to boost the ability of the GenPM to capture nonlinear features and outperform existing baseline models.\n\u2022 We evaluate the robustness of DeepDA in capturing the multi-scale evolution of SST, and analyze the impact of factors such as observation resolution and ensemble background information. The performance of DeepDA has been well verified in real observations.\n\u2022 We explore the physical explainability of DeepDA from a pattern perspective. The spatio-temporal evolution of the El Ni\u00f1o/Southern Oscillation (ENSO) can be explicitly captured from our deep learning model. The physical properties of the latent patterns can better guide DeepDA to generate refined nonlinear structures."}, {"title": "2. Methods", "content": "2.1. Study Region and Variable\nAs shown in Fig. 1(a), the study region (model domain) we focus on is the core area covering the Pacific Ocean (60\u00b0S~60\u00b0N, 100\u00b0E~60\u00b0W), which is affected by complex physics and extreme nonlinear processes (short-term meteorological effects, long-term climate change, and so on). Among them, the El Ni\u00f1o/Southern Oscillation (ENSO) is the strongest interannual climate fluctuation [44]. In particular, the Ni\u00f1o 3.4 region (the core region for studying the El Ni\u00f1o phenomenon) spans the east-central equatorial Pacific between 170\u00b0W~120\u00b0W, 5\u00b0N~5\u00b0S. In addition, the two sub-regions in Fig. 1 are intended to show more details of the nonlinear evolution.\nIt is well known that sea surface temperature (SST) is an important observed and predicted variable that affects atmosphere-ocean interactions. In addition, SST products (observation or reanalysis) are relatively mature, which is beneficial to training and testing our DL model. Therefore, in order to evaluate the performance of the DeepDA, we conduct observing system simulation experiments and multi-source data fusion experiments for SST.\n2.2. Latent Space Data Assimilation Framework Based on Deep Learning\n2.2.1. Preliminaries\nThe core idea of the DeepDA is to perform DA in a low-dimensional latent space. However, it is difficult to completely represent nonlinear evolution using linear methods. Therefore, how to design a DL model to capture the nonlinear latent space is the key to the"}, {"title": "", "content": "DeepDA. The DeepDA employs self-supervised DL to build the generative proxy model (GenPM), which enables it to autonomously extract multi-scale features from large datasets and map them into a low-dimensional latent space.\n$z = encoder(x)$ (1)\n$\\hat{x} = decoder(z)$ (2)\nThe proxy model consists of two components: encoder and decoder. Eq. (1) shows that the encoder of the proxy model maps the original state X to a low-dimensional latent vector z. The decoder in Eq. (2) is designed as a mirror structure of Encoder, which can map the latent vector z back to the original state $\\hat{x}$. It should be noted that an ideal (error-free) proxy model will reconstruct the perfect state ($x = \\hat{x}$). This model structure is often called Auto-Encoder (AE) in classic DL. AE can achieve low-dimensional mapping, but the features represented by the latent space are generally discrete. In practice, the distribution of states is non-discrete, which requires the proxy model to capture the continuous representation of nonlinear features in the latent space. Therefore, the DeepDA employs an additional random sampling mechanism in the encoder-decoder architecture, which can replace discrete latent features with probability distributions. The learning process of the proxy model can be simplified into an optimization problem in Bayesian theory:\n$\\max_{\\theta} p(x) = \\max_{\\theta} \\int p_{\\theta} (x|z) p(z) dz$ (3)\nwhere $p()$ is the probability density function and the mapping relationship $p_{\\theta}(x|z)$ from latent vector z to state x is controlled by model parameter $\\theta$. In self-supervised learning, the optimal parameter $\\theta$ will be learned, which can satisfy the self-probability maximization matching of state X. In other words, a known distribution of latent vectors and optimal parameters jointly determine the performance of state reconstruction. At the same time, the encoder can be expressed as:\n$q_{\\phi} (z|x) \\approx \\frac{p_{\\theta}(x|z)p(z)}{P_{\\theta}(x)}$ (4)\nwhere $q_{\\phi}(z|x)$ is the conditional probability density function mapping relationship from latent vector z to state x controlled by model parameter $\\phi$. Eq. (4) is the approximate posterior distribution of the latent vector, which shows that the mapping relationship between encoder and decoder is a continuous probability density distribution under parameter constraints.\nIn order to learn better parameters and distributions, it is necessary to design a reasonable training loss function. As shown in Eq. (5), the loss function consists of two parts. Among them, $Loss^{rec}$ can evaluate the reconstruction performance of state x (reconstruction loss) and $Loss^{reg}$ can constrain the distribution of the latent vector z (regularization loss).\n$Loss = Loss^{rec}(x, \\hat{x}) + Loss^{reg} (x, z)$ (5)\nIn the assumption of Gaussian distribution, $Loss^{rec}$ can be written as:"}, {"title": "", "content": "$Loss^{rec}(x, \\hat{x}) = Loss^{rec}_{x} (x) = -log p(x|z)$ (6)\nIn order to optimize parameters, the proxy model in the DeepDA employs the form of Huber Loss function to rewrite Eq. (6) as:\n$Loss^{rec}(x, \\hat{x}) = \\omega \\langle H_{\\delta}(x, \\hat{x}) \\rangle$ (7)\n$H_{\\delta}(x, \\hat{x}) = \\begin{cases}\n\\frac{1}{2}|x - \\hat{x}|^{2} & if |x-\\hat{x}| \\le \\delta \\\\\n\\delta |x-\\hat{x}| - \\frac{1}{2}\\delta^{2} & if |x-\\hat{x}| > \\delta\n\\end{cases}$ (8)\nwhere $\\omega$ represents a weight coefficient greater than 0, which can control the balance of the two loss terms. $\\langle \\rangle$ represents the average of all grid points and $\\delta$ is set to 1. To make p(z) conform to the standard normal distribution, $Loss^{reg}$ is written as:\n$Loss^{reg} (x, z) = -log p(z)+log q_{\\phi}(z|x)$ (9)\nDuring the training of the proxy model in the DeepDA, the encoder can generate matching vectors of mean ($\\mu$) and log-variance ($log\\sigma^{2}$), representing the multivariate Gaussian distribution. Each latent vector element is then randomly sampled from this distribution [45]. In multi-source information fusion, the latent space changes slightly. So, the design of sampling and regularization contributes to the diversity of state mapping. At the same time, the continuity of adjacent latent spaces can ensure the similarity of decoding states. Therefore, mapping results are similar to ensemble perturbations of state variables under consistent physical constraints.\n2.2.2. Design of Generative Proxy Model (GenPM)\nTo enhance the scalability of the DeepDA framework, we develop a new GenPM named spatio-temporal attention variational autoencoder (STAVAE). As shown in Fig. 2(a), the STAVAE adopts a convolutional encoder-decoder structure. Overall, the STAVAE contains five modules: input, convolutional encoder, latent space mapping, convolutional decoder, and output. Among them, in order to extract deeper features, we independently design a spatio-temporal attention residual (STAR) module.\nFirst, the encoder captures different scale features from state variables and forms downscaled feature maps. With the strengthening of the convolution channel and the reprocessing of the attention mechanism, the extracted nonlinear information is richer. Second, the latent space mapping module generates a distribution of states from the encoded feature map, which is compressed into a low-dimensional vector by a fully connected layer. Finally, the decoder restores the scale of the feature map until it reconstructs an output with the same dimensions as the input variables. In practice, the spatial information of variables is usually described on the latitude and longitude grid. Therefore, the design of the STAVAE model meets the needs of grid fusion and pixel-level scalability of multi-source data."}, {"title": "", "content": "computational efficiency of MLP. Therefore, the STAR module can effectively improve the spatio-temporal representation capability of CNN and is computationally friendly.\nIn detail (Fig. 2(a)), the encoder and decoder in STAVAE each contain 5 convolutional layers. Each layer employs a 3\u00d73 convolution kernel for feature extraction, in which the feature dimension will be reduced to half of its original size and the number of channels will be doubled. The mean and variance of the latent distribution are calculated from the encoded feature map and converted into a low-dimensional latent space vector. In addition, the STAR module only extracts spatio-temporal dependencies of features without changing the dimensions.\n2.2.3. Framework details of DeepDA\nAs mentioned before, the DeepDA contains two parts: the GenPM (Section 2.2.2) and latent space DA. In this section, we customize the framework details of DeepDA based on 3D-Var (Fig. 3(a)). 3D-Var seeks the optimal information fusion of background and observation by minimizing the cost function. The cost function has the following form:\n$J_{3D}(X)=\\frac{1}{2}||X - X_{b}||_{B^{-1}}+\\frac{1}{2}||y-H(X)||_{R^{-1}}$ (10)\nwhere X is the analysis state, $X_{b}$ and y are the background and observation respectively. B and R represent the error covariance matrices of background and observation. H(\u00b7) is the projection operator of observation, which can project the state into the observation space. $||\u00b7||_{\\Phi^{-1}} = (\u00b7)^{T}\\Phi^{-1}(\u00b7)$ represents the Mahalanobis norm in which $\\Phi$ means the covariance matrix. By minimizing the cost function, we obtain the optimal analysis state $X_{a}$.\nIn traditional DA, the main challenge in minimizing the cost function is that the dimension (\u2248 10\u00b9\u2078) of the B matrix is too large, which makes the calculation of the cost function and gradient very difficult. In the DeepDA framework, the background state is defined in the latent space rather than the grid space, which still satisfies the Gaussian distribution assumption of background and observation errors in 3D-Var. Therefore, the latent space cost function of DeepDA is expressed as follows:\n$J_{3D-DeepDA}(z) = \\frac{1}{2}||z - z_{b}||_{\\bar{B}^{-1}} + \\frac{1}{2}||y-H(D(z))||_{R^{-1}}$ (11)\nwhere D(\u00b7) represents the decoder of the GenPM, and $\\bar{B}^{-1}$ is the error covariance matrix of the latent vector with $\\bar{D}$ representing the tangential operator of decoder D(\u00b7). The observation operator H(\u00b7) employs bilinear interpolation to project the decoded state into the observation space. Eq. (11) can directly measure the distance of the latent vector between the analysis $z_{a}$ and the background $z_{b}$. After the cost function is minimized, we can obtain the optimal latent analysis vector $z_{a}$. It should be noted that the DeepDA transforms the 3D-Var minimization problem into a latent space, which greatly reduces the cost of gradient optimization. Taking our study as an example, a single state vector X has 480\u00d7800=384000 elements, and the original B matrix has more than 10\u00b9\u00b9 elements. But in our DeepDA, the latent vector z has 128 elements, so the matrix $\\bar{B}$ only contains about 10\u2074 elements, which can be easily calculated by a personal computer. It can be found in the experiment that"}, {"title": "", "content": "$\\bar{B}_{z}$ is a diagonally dominant matrix, and the diagonal elements are several orders of magnitude larger than the off-diagonal elements (see Appendix A).\n2.3. Experimental Setup\n2.3.1. Data Preparation\nTo train and evaluate the performance of the DeepDA framework, we employ daily average data of sea surface temperature (SST) as the state variable for the assimilation experiment. Hourly SST data are provided by the ERA5 (the fifth generation ECMWF atmospheric reanalysis product) [48], released by the European Centre for Medium Weather Forecasting (ECMWF), with a spatial resolution of 25 km and a regular latitude and longitude grid. We convert hourly SST data into daily averages. In order for STAVAE to produce a standardized input and output, we subtract the 30-year climate average of SST and normalize the SST anomalies. Our study region covers 480\u00d7800 grid points. The temporal coverage is 43 years, from 1981 to 2023. Among them, data from 1981 to 2010 (30 years in total) are used to calculate climate averages and data from 1989 to 2018 are selected to train the GenPM. In addition, the data from 2019 is used to evaluate the performance of different GenPMs and the data from 2020 to 2023 are used for the observing system simulation experiment (OSSE, Section 2.3.2) of DeepDA.\nIn order to explore the practical application potential of the DeepDA framework, we also design a series of multi-source data fusion experiments (Section 2.3.3). Different from OSSE, the objects of multi-source data fusion experiments use real observations and model simulations (background information). We employ Optimum Interpolation Sea Surface"}, {"title": "", "content": "Temperature (OISST) product from National Oceanic and Atmospheric Administration (NOAA) as observations, which integrate observations from different platforms (satellites, ships, buoys and Argo floats) into a regular global grid. In order to evaluate the robustness of DeepDA in different sample (ensemble) background information, we select the current best numerical model, the ECMWF's Seasonal Forecasting System (SEAS5), as the background. We extract the monthly SST ensemble prediction results of SEAS5 [49] from 2020 to 2023, which contains a total of 51 ensemble members. As before, we need to interpolate the SEAS5 (1\u00b0) onto the ERA5 grid (0.25\u00b0), which ensures the consistency of the data structure in the DeepDA.\n2.3.2. Observing System Simulation Experiments\nIn order to capture the evolution details of SST, the DeepDA focuses on sea surface temperature anomalies (SSTA). We design a series of OSSEs to evaluate the effectiveness of the DeepDA. For simplicity, a commonly used baseline method (persistence prediction) is employed to generate the background fields. In Fig. 3(b), we show the details and flowchart of OSSE, where observations and background are derived from the ERA5 ground truth. We employ bilinear interpolation to project the ground truth onto the observation points and add random Gaussian perturbations to obtain pseudo-observations (Eq. (12)).\n$y = H(x^{GT}_{t}) + \\varepsilon$ (12)\nIn all OSSEs, the encoder E(\u00b7) in the GenPM has been employed to convert the persistent (lead time $\\tau$ days) ground truth $x^{GT}_{t-\\tau}$ into background latent space vectors (Eq. (13)).\n$Z^{background}_{t} = Z^{GT}_{t-\\tau} = E(x^{GT}_{t-\\tau})$ (13)\nBased on the generated background and observations, the DeepDA will minimize the cost function and obtain the analysis result. In practice, the persistence lead time $\\tau$ is set to 15 days.\n2.3.3. Multi-Source Data Fusion Experiments\nIn fact, the information fusion of observations and model simulations can improve the uncertainty of single information. Therefore, combating the uncertainty of multi-source data in fusion is a key challenge of the DeepDA. The DA scheme in this experiment is the same as OSSE, which combines observation and background to generate the optimal analysis field. Different from OSSE, this experiment no longer requires setting random errors. At the same time, background fields are also provided by model simulations rather than persistent predictions. In addition, the ground truth remains the SST of ERA5, which is employed as a benchmark to evaluate the effectiveness of data fusion. Among them, The SEAS5 can better evaluate the robustness of our framework. At this stage, the weights of the GenPM have been frozen and it has been trained by ERA5."}, {"title": "2.4. Model Training and Evaluation Settings", "content": "All experiments are conducted on a workstation equipped with an NVIDIA Geforce RTX 3090 Ti-24G GPU and Tensorflow. Empirically, we set the batch size to 32 and the initial learning rate to 1\u00d710\u207b\u2074 . Furthermore, the adoption of strategies such as early stopping and dynamically adjusting the learning rate can speed up the training process and prevent overfitting. It is worth noting that the GenPM weights are completely frozen during the data fusion stage of the DeepDA. The latent space vector is the only variable that can be optimized. The cost function optimization of traditional DA relies on the adjoint model to calculate the gradient [8]. To simplify the optimization process, we also employ the Adam optimizer [50] provided by Tensorflow. In the DA test phase, the range of the learning rate in Adam optimizer is set to (1\u00d710\u207b\u00b9, 1\u00d710\u207b\u2074). When the optimization rate of two adjacent steps is less than 1%, the learning rate will be reduced to half of the original value until the learning rate reaches_1\u00d710\u207b\u2076 . If the learning rate drops to the minimum quickly and the cost function decreases slowly, the optimization process will be terminated after continuing for 5 steps. In the experiment, the total number of optimization iterations is less than 80. In general, obvious convergence occurs after 20 iterations and the overall process takes about 15 seconds.\nIn order to evaluate the performance of the DeepDA, we need to compare by different evaluation metrics. We employ root mean square error (RMSE) and anomaly correlation coefficient (ACC) as evaluation metrics. Among them, RMSE can measure the relative error of the fusion results and ACC can evaluate the correlation of spatial distribution.\n$RMSE = \\sqrt{mean((X_{a} \u2013 X_{t})^2)}$ (14)\n$ACC = \\frac{\\sum_{i=1}^{N} (X_{a_{i}} - \\overline{X_{a}})(X_{t_{i}} - \\overline{X_{t}})}{\\sqrt{\\sum_{i=1}^{N} (X_{a_{i}} - \\overline{X_{a}})^2 \\sum_{i=1}^{N} (X_{t_{i}} - \\overline{X_{t}})^2}}$ (15)\nwhere N is the number of spatial grid points, $X_{a}$ and $X_{t}$ represent the analysis field and ground truth, mean() is the average of samples. In practice, we only compute values for nonland grids."}, {"title": "3. Results", "content": "3.1. Overall Performance of DeepDA Framework\nAs shown in Fig. (4), the experiment represents the central months of different seasons in 2021. Overall, the analysis increment and ground truth increment of the DeepDA show almost the same spatial distribution. In particular, signals on larger spatial scales are effectively captured by the DeepDA. Taking July 15 as an example, the strong western boundary current from west to east in the ground truth increment (Fig. 4(g)) almost covers the North Pacific (30\u00b0N~50\u00b0N). Among them, the difference between the positive and negative increments is about 5\u00b0C. In Fig. 4(c), the pattern of positive increments is restored more accurately, which is closer to the distribution of observations. The RMSE between the ground truth increment and the analysis increment is 0.33\u00b0C, and the ACC is 0.81. In the comparison on October 15, the tropical instability wave showed a westward propagation pattern of alternating positive and negative directions (Fig. 4(h)), which is completely consistent with the analysis results. The statistical results (Fig. 4(m)-(p)) show that the RMSE of the DeepDA is around 0.3\u00b0C and the ACC is around 0.8, which is in line with expectations.\nFrom further comparison (Fig. 4(a)-(d)), it can be found that the DeepDA weakens or even ignores the details of high-frequency small-scale signals. This is because in data fusion,"}, {"title": "", "content": "the DeepDA focuses on finding the optimal state that fits the observation in the latent space, which tends to the principle that large-scale signals are preferentially fused. Other signals are often ignored because their strengths are relatively weak and the errors caused by them are random. In addition, the resolution of the observations may not be enough to fully resolve the evolution of small scales, which may also lead to certain differences between the details of the fusion and the observations. Although the refined structure cannot be completely restored, the DeepDA can provide a probabilistically optimal fusion. Its approximate distribution pattern has been accurately represented, which can enhance the data fusion potential of the DeepDA."}, {"title": "3.2. Generation of Unseen Nonlinear Structures", "content": "Due to low computational cost, DeepDA can effectively generate statistically significant results by increasing the number of background information samples. In the DA stage, we construct the ensemble background by adding different perturbations to the original background information. Taking 5 members as an example (Fig. S1), the SSTA on January 1, 2020 is used as the original background information, and the analysis time is April 1, 2020. In this experiment, the observation distribution has been downsampled to 2.5 degrees. As shown in Fig. S1, the analysis ACC of the five members are all above 0.9, which is significantly adjusted compared to the background information. The ensemble average result is better than the analysis of any one member, with RMSE reduced by about 30% and ACC increased to 0.95.\nIn fact, the distribution of observations is very sparse, so it is difficult to fully reproduce unseen nonlinear evolution processes. Fig. S1 show that the analysis results generated by DeepDA are roughly consistent with the ground truth, but there are certain differences in local details. To explore more details, we select the results of sub-region 1 to preliminarily analyze the nonlinear structure generated by DeepDA. As shown in Fig. 6(a), the nonlinear double-peak structure becomes a blurred single peak in observation (Fig. 6(b)). But DeepDA can capture the optimal spatial structure based on sparse observations (Fig. 6(d)). Similar results can be found in all members (Fig. 6(e)-(i)), which shows the excellent performance of DeepDA."}, {"title": "", "content": "It can also be found that the diversity of background information makes the subtle structures among the analysis members similar but not completely the same. In fact, the ensemble background information can essentially expand the optimization space [51] of DeepDA, thereby reducing the uncertainty of the analysis results generated by DeepDA. Therefore, the analysis results after ensemble averaging are more statistically significant. As shown in Table S1, we compare the effects of the number of different ensemble members on DeepDA performance (sensitivity analysis). When the number of members is large, the ensemble average results are more advantageous. Therefore, different background samples in latent space DA can improve the diversity of data fusion, which can quantify the uncertainty of nonlinear systems.\n3.3. Performance Comparison at Different Resolutions\nIn the previous section, we have gained a preliminary understanding of the DeepDA in generating unseen nonlinear structures. To further verify the performance, we compare the generation results guided by observation information of different resolutions. We set a fixed observation error (random seed) so that the analysis results produced by DeepDA are only affected by the resolution of the observation information. In other words, the resolution of the observation information received by DeepDA is the main controlling factor. As shown in Fig. 7 and Fig. 8, we downsample the 0.25\u00b0 noisy pseudo observations to 0.5\u00b0, 1\u00b0and 2.5\u00b0, respectively."}, {"title": "", "content": "resolutions. (k)-(1) Regression distribution of ground truth increments (ground truth minus background) and analysis increments (analysis minus background).\nOverall, the error of the analysis results generated by DeepDA increases as the resolution decreases. In sub-region 1 (Fig. 7(k)-(n)), the RMSE increases from 0.29\u00b0C to 0.38\u00b0C. In sub-region 2 (Fig. 8(k)-(n)), the RMSE increases from 0.32\u00b0C to 0.39\u00b0C. It can be found that when the available observation information (Fig. 7(j)) is only 10% of the original (Fig. 7(g)), the increase of RMSE does not exceed 40%. In other words, DeepDA can generate reasonable nonlinear evolution with only very little observation information. In detail, the complete spatial structure has been destroyed in low-resolution observations (Fig. 7(g)-(j)). Some fine structures can still be seen in the Obs-1 (0.25\u00b0), but only fuzzy or even erroneous structures can be seen in the Obs-4 (2.5\u00b0). DeepDA can reconstruct the approximate spatial structure (Fig. 7(b)-(e)) using only blurred pixel information. As shown in Fig. 8, the tropical instability wave is the core structure of sub-region 2. In the example of October 15, 2021, the wave signal propagating westward is very obvious in the ground truth. But in the sparsest observation (Obs-4, 2.5\u00b0), the wave signal is aliased with noise. It is gratifying that DeepDA can reconstruct this propagation pattern. Although the analysis results weaken the signal strength, they are still closer to the ground truth than observations and background.\nBy comparison, it can be found that DeepDA is robust in generating nonlinear evolution under the influence of observations at different resolutions. The generated analysis results (Ana-1~Ana-4) are quite similar in distribution. In particular, DeepDA effectively captures the nonlinear structure of different regions. In the experiments of sub-regions 1 and 2, DeepDA overcomes the artificial corruption of regional nonlinear signals. In addition, the"}, {"title": "", "content": "stability of the GenPM is further verified. Sparse and noisy observations will introduce errors to the inference process of the GenPM, but the reasonable temperature structure is still captured by DeepDA. In summary, the data assimilation method in latent space can effectively generate unseen nonlinear evolution.\n3.4. Ablation Study of Generative Proxy Models\nThe GenPM is the core component of the DeepDA framework, which directly affects the generation quality of nonlinear evolution. We compare the STAVAE model with 7 related models. Among them, Auto-Encoder (AE) and Variational AE (VAE) are two classic model structures and are also the root models of the STAVAE. In addition, in order to verify the effectiveness of the STAR module, we combine VAE, residual block and CBAM to build three extended models of ResVAE, VAE-CBAM and ResVAE-CBAM respectively. Details are shown in Table 1. Specifically, all hyper-parameters and layer"}]}