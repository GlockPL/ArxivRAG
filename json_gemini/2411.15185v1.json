{"title": "Hybrid Gaussian Process Regression with Temporal Feature Extraction for Partially Interpretable\nRemaining Useful Life Interval Prediction in\nAeroengine Prognostics", "authors": ["Tian Niu", "Zijun Xu", "Heng Luo", "Ziqing Zhou"], "abstract": "The estimation of Remaining Useful Life (RUL) plays a pivotal role in intelligent manufacturing systems and Industry 4.0\ntechnologies. While recent advancements have improved RUL prediction, many models still face interpretability and compelling\nuncertainty modeling challenges. This paper introduces a modified Gaussian Process Regression (GPR) model for RUL interval\nprediction, tailored for the complexities of manufacturing process development. The modified GPR predicts confidence intervals\nby learning from historical data and addresses uncertainty modeling in a more structured way. The approach effectively\ncaptures intricate time-series patterns and dynamic behaviors inherent in modern manufacturing systems by coupling GPR\nwith deep adaptive learning-enhanced Al process models. Moreover, the model evaluates feature significance to ensure more\ntransparent decision-making, which is crucial for optimizing manufacturing processes. This comprehensive approach supports\nmore accurate RUL predictions and provides transparent, interpretable insights into uncertainty, contributing to robust process\ndevelopment and management.", "sections": [{"title": "Introduction", "content": "Prognostics and Health Management (PHM) plays a crucial role in increasing equipment availability, reducing maintenance\ncosts, and improving the scheduling of maintenance events. By predicting potential failures, maintenance activities can\nbe planned, reducing downtime and allowing for more efficient operations in manufacturing environments11. Predicting a\nmachine's Remaining Useful Life (RUL) using real-time condition data is central to effective prognostics21. With modern\nmachines continuously collecting sensor data at frequent intervals, this data forms a time series with inherent temporal\ncharacteristics. Consequently, RUL prediction involves solving a time series regression problem that captures both the\noperational and mechanical characteristics of the machinery12.\nLike many other time series prediction challenges, RUL estimation methods can be divided into two main categories:\nlearning-based and model-based approaches. Learning-based methods utilize machine learning and deep learning techniques,\nsuch as long short-term memory17 and transformer45, which leverage historical data to improve predictions. These methods\nrely on supervised learning to achieve accurate outcomes. In manufacturing processes, it is critical to incorporate temporal\ncontinuity and system behavior dynamics when dealing with high-dimensional data. However, many traditional machine\nlearning methods focus solely on single-point predictions without quantifying uncertainty, limiting their reliability in real-world\napplications.\nModel-based approaches, on the other hand, include both physical and statistical methods. Physical approaches involve\nbuilding models that represent the underlying mechanical systems. Implementing this approach necessitates intricate physical\nmodeling, and the inherent variability among different machines poses challenges to its generalizability, thereby constraining\nits feasibility for broader, real-world applications. In contrast, statistical methods, particularly Gaussian Process Regression\n(GPR), offer a more flexible way of predicting RUL. GPR is a non-parametric Bayesian approach that effectively models\ndiverse deterioration mechanisms and outputs uncertainty measures, making it highly applicable in complex systems where\nphysical models may fail28,40. Despite its robustness in generating prediction intervals, GPR alone may face challenges in\nhandling large-scale time-series data typical of industrial environments. Specifically, GPR involves calculating and storing an\nn \u00d7 n covariance matrix (where n is the number of data points), resulting in a computational complexity of O(n\u00b3) and a memory\ncomplexity of O(n\u00b2).\nThis paper proposes a novel Hybrid Gaussian process Regression with temporal feature extraction for partially interpretable"}, {"title": "Related works", "content": "RUL interval Prediction in aero-engine prognostics (HRP) to overcome the limitations of both learning and model-based\napproaches. The approach leverages a modified GPR model, pre-trained on time-series data, to incorporate temporal dynamics\nand system behaviors relevant to intelligent manufacturing systems. Unlike single learning-based methods, this method captures\nuncertainty and key predictive features without relying solely on black-box neural networks by modifying GPR into deep\nadaptive learning-enhanced regression. The pre-processing steps ensure that the modified GPR effectively utilizes feature\nrepresentation and system diagnostics to increase robustness compared to single model-based methods. Additionally, the\nmodel identifies and prioritizes critical physical features contributing to system degradation, enhancing predictive accuracy and\nenabling optimal maintenance decisions.\nThe key contributions of this paper are as follows:\n\u2022 A supervised GPR model pre-trained with temporal features is proposed to reflect system health states in manufacturing\nenvironments. This model is specifically tailored to capture the time-dependent degradation of machinery, enhancing\npredictive insights into system performance over time.\n\u2022 Confidence intervals generated by the GPR model quantify the uncertainty of predicted RUL, offering a dual advantage:\nimproved prediction accuracy and a more precise assessment of failure risk.\n\u2022 Feature importance analysis is incorporated to identify key contributors from mechanical and sensor data, providing\nactionable insights into degradation factors. The model facilitates real-time, data-driven maintenance planning by\nintegrating uncertainty modeling and adaptive learning techniques.\nThe rest of this paper is organized as follows: First, we introduce the preliminaries and outline the proposed method. Then,\nwe discuss the experimental results and analysis. Finally, we summarize the findings and discuss future directions for RUL\nestimation in smart manufacturing environments."}, {"title": "Methods", "content": "This section begins by formulating the multi-dimensional time series problem in RUL prediction. Then, an overview of our\ninterval prediction framework is provided. The model is referred to using the acronym HRP. After that, we introduce the details\nof the model's main elements."}, {"title": "Problem definition", "content": "Given run-to-failure data for several mechanical systems, denoted as {Xt}T\nt=1 and corresponding RUL: y = {yt}T\nt=1, where\nX\u2081 = {x},x},...,x^4} represents observations at the corresponding running time t, M represents the number of monitoring\nsensors, and T represents the total operational life of a machine. Consequently, the RUL of time t is defined as y\u2081 = T \u2013t. The\nobjective is to find a mapping from high-dimensional observations to a scalar value, defined as f : {Xt}T\nt=1 \u2192 {yt}T\nt=1. Given new\nK\ndata {Xk}K\nk=1, estimates of {yt}t=1 can be obtained as {} = f({x}k=1), and predict the confidence interval{[yL,yU]}K\nk=1\nSimultaneously, the influence of the M monitoring sensors on faults is analyzed, enabling the estimation of sensor impact\nfactors {1,2,...,\u039c}."}, {"title": "Framework overview", "content": "The dual-line interval RUL prediction strategy, illustrated in Fig.1, consists of two key stages: offline training and online\nprediction. This strategy provides engineers with two crucial outputs: the sensor influence on fault modes and the predicted\ninterval for the RUL. Initially, all data follow the same preprocessing pipeline, including sensor selection, normalization,\nsmoothing, and sliding window process. During training, the network is trained with data from known run-to-failure cycles,\naligning the real RUL with a health index. The trained model serves both as a callable real-time prediction tool and a mechanism\nto provide insights into the relative importance of features during fault cycles. In the test phase, incomplete degradation\ntrajectories from test data are processed in real time, providing rapid predictions using the trained network.\nThe detailed structure of this network is depicted in Fig. 2, and follows a series of steps. Firstly, after data have been\npreprocessed, raw data are converted into the format (Batch size,Time window length, Feature number), which serves as the\ninput to the network. Secondly, temporal feature extraction adopts mathematical techniques for managing temporal information\nflow. Adaptive filtering and time-series compression gated memory cells preserve long-term dependencies, ensuring that\nrelevant historical data are retained in the feature set while discarding noise or less significant information. This preprocessing\nstep compresses the sequence of high-dimensional sensor data into a lower-dimensional latent space with a dimension of\n(Batch size, Hidden state length). The extracted time-series features are then fed to construct mean function u and the\ncovariance function K in multivariate normal Gaussian distribution, which not only learns the distribution of the data but also\ngenerates prediction intervals for RUL with quantified uncertainty. The model's ability to capture temporal dynamics and\nrepresent the system's health status probabilistically is key to its enhanced performance. Furthermore, the network performs\nfeature importance analysis based on how different sensors contribute to the fault modes, providing engineers with a clearer\nunderstanding of the degradation process. In the final step, engineers can conduct a comprehensive run-to-failure assessment"}, {"title": "Data preprocessing", "content": "We employ a four-step procedure to process the original dataset to ensure the data is prepared for practical prognostics analysis.\nFirst, we perform feature selection. After an extensive review of the sensor signals, 14 critical sensors are retained, providing\nthe most significant information for accurate RUL predictions. Additionally, we utilize a piecewise linear degradation model\nto model the RUL as described in previous research41. Here, the time for the change point is set at 125. Second, we apply\nz-score normalization to the sensor signals for each instance, standardizing the readings to improve model performance and\ncomparability across different sensors50. This normalization transforms the original time series $x_i^j$, corresponding to the j-th\nsensor of the i-th sample, as formula $x_i^j = \\frac{X_i^j - \\mu^j}{\\sigma^j}$, where $\\mu^j$ and $\\sigma^j$ represent the mean value and the standard deviation deviation,\nrespectively, for the j-th sensor readings across all instances in each dataset. Third, we implement exponential smoothing41 to\nretain the underlying trends in sensor signals while minimizing the impact of noise and short-term fluctuations. This technique\nimproves the accuracy of predictive models by focusing on long-term degradation trends. Finally, we segment the preprocessed\ndata using a sliding window approach19. This method partitions the entire time series into smaller, equal-length windows. The\nwindow length is determined based on prior empirical studies31, ensuring it captures sufficient temporal information for reliable\nprediction. Detailed descriptions of these four preprocessing steps, including parameters and justifications, are provided in the\nSupplementary Materials under S2."}, {"title": "Temporal feature extraction", "content": "Advanced temporal feature extraction methods are employed during pre-analysis to enhance the model's ability to capture\ntemporal dependencies. These methods are based on the mathematical principles of sequential learning, which allow the\nmodel to retain and process long-term and short-term dependencies inherent in time-series data. The method utilizes gating\nmechanisms that control the flow of information through the model, mimicking how LSTM networks handle temporal data\nthrough input control, memory retention, and output management10,16. Detailed mathematical expressions are provided in the\nSupplementary Materials under S3. Once the temporal features from input ${X_t}_{t=1}^K = {x_1,x_2,...,x_M}$ have been extracted,\nthey are formatted into hidden states h = (h1,h2, ...hm), which encapsulate the most important information from the time-series.\nThese hidden states, which compress the multivariate time series into a reduced form, are then transferred to the next processing\nstage, modified GPR, where distribution learning occurs, and feature importance analysis is performed. The hidden states can\nbe expressed as\n$(h_1,h_2,...h_M) = f_{tem}({X_t}_{t=1}^K;\\Theta_{tem}).$ \n(1)"}, {"title": "Modified GPR", "content": "Here, $\u0398_{tem} = [W_{tem}, b_{tem}]$ represents the learnable parameters of the feature extraction process and m stands for the hidden\nlayer size.\nThe loss function used to optimize the feature extraction process is designed to handle outliers in the data by employing a\nHuber loss, which combines the benefits of squared error and absolute error, defined as:\n$L_S(a) = \\begin{cases}\n  \\frac{(a)^2}{2} & \\text{if } |a| \\leq \\delta \\\\\n  \\delta(|a| - \\delta) & \\text{if } |a| > \\delta\n\\end{cases}$ \n(2)\nIn this way, the extracted features retain the sequence's temporal dynamics while ensuring stability in the training process.\nThey are also tailored to the requirements of the Gaussian Process framework for further learning.\nDifferent from classic GPR, we modify GPR cooperated with temporal learning to adaptively describe uncertainty. Modify\nGPR receives the hidden state h = (h1,h2,...hm) as defined by equation (1), and produces outputs {y} and confidence interval\n{[yt,y]}1. A Gaussian process (GP) is a collection of random variables, any finite subset that adheres to a joint Gaussian\ndistribution. For any input h, the probability distribution of the corresponding RUL y = {yt}1 follows a multivariate normal\nGaussian distribution. The GP is characterized by two essential components, the mean function u and the covariance function\nK, which jointly specify its probability distribution,\ny ~ GP(\u03bc, \u039a). \n(3)\nGenerally, the mean function \u03bc(h) is selected as a zero-mean function, and the covariance function k(h, h') is the squared\nexponential function, defined as\nk(h, h') = r\u00b2 exp (\\frac{||h-h' ||2}{2\u03b72}) \n(4)\nwhere \u03b7 represents the characteristic length-scale, and \u03c4 represents the amplitude of the covariance. Therefore, the mean vector\n\u03bc satisfies \u03bc = (\u03bc(h\u00b9),...,\u03bc(hm)), and the n-by-n covariance matrix K satisfies K = (k(h\u00b2, h\"))=1. Similar to GPR, our\nmethod HRP assumes that the observations are noisy realizations of the GP prior. The noise is typically modeled as a Gaussian\ndistribution with zero mean and variance \u025bm ~ N (0,82). Given these assumptions, the prior distribution follows a multivariate\nnormal distribution, where Im denotes the m-by-m identity matrix,\ny ~ N (\u03bc, \u039a + \u03b4\u00b2Im) . \n(5)\nThe core strength of GPR lies in its ability to infer a posterior distribution over functions based on the data. This distribution\nprovides a point estimate \u00ee* at any given time t and a measure of uncertainty as a confidence interval. This predictive distribution\nis central to prognostics as it naturally quantifies the uncertainty of the RUL prediction. In the application stage of prediction,\nwhen a new X* sampled from historical data is observed, temporal learning processes it into h*. The joint prior Gaussian\ndistribution of the training RUL y and y* is obtained as follows,\n\\begin{bmatrix} y \\\\ y* \\end{bmatrix} \\sim N\\left(\\begin{bmatrix} \\mu(h) \\\\ \\mu(h*) \\end{bmatrix}, \\begin{bmatrix} K+\\delta^2I_m & K(h*) \\\\ K(h*)^T & k(h*,h*) \\end{bmatrix}\\right). \n(6)\nThe posterior mean function and covariance functions are given by\n\u03bcm (h*) = K(h*)T(K + \u03b4\u00b2Im)\u00af\u00b9(y \u2212 \u03bc(h)) + \u03bc(h*), \n(7)\nkm(h*) = k(h*,h*) \u2013 K(h*)T(K + 82Im)\u00af\u00b9K(h*), \n(8)\nwhere K(h*) = (k(h*, h\u2081), ...,k(h*,hm))T, the mean of RUL can be predicted using \u00b5m(h*), assuming a GP(0, K) prior. The\nprediction is obtained as\n\u00ee* = K(h*)*(K+8\u00b2Im)\u00af\u00b9y. \n(9)\nIt is important to acknowledge that no prediction can be completely accurate, and prediction errors cannot be eliminated. To\naddress this issue, we propose a straightforward approach providing a 1 a prediction interval such that\nPr{\u0177* \u2208 [y\u00b2,y]} = 1 \u2212\u03b1, \n(10)\nwhere y\u00b2 = \u00ee* - Za/2* \u221akm(h*), y = \u0177* +za/2* \u221akm(h*), and za/2 represents the quantile of the corresponding standard\nnormal distribution.Generally, when a = 0.05, the lower bound y\u00b2 is \u0177* \u2013 1.96* \u221akm(h*) and the upper bound yU is \u00ee* + 1.96*\n\u221a km (h*). This predictive distribution is central to prognostics as it naturally quantifies the uncertainty of the RUL prediction.\""}, {"title": "Importance analysis", "content": "In summary, GPR offers a probabilistic framework for RUL prediction that effectively accommodates the temporal dynamics\ninherent in prognostic processes. Additionally, it systematically quantifies uncertainty. The flexibility of modified GPR to\nanalyze contributions from individual sensors further enhances its applicability for fault diagnosis and prognostics in complex\nmechanical systems.\nA feature importance analysis is integrated into the model to determine which sensors most significantly influence the RUL.\nThis analysis is based on evaluating the impact of each feature, derived from sensor data, on the RUL predictions. The feature\nimportance assessment begins by inputting the hidden state h, defined by equation (1), into the analysis component. This hidden\nstate encapsulates the relevant temporal features extracted during the data preprocessing and temporal feature extraction stages.\nThe output of this process is a set of feature importance scores {11,12,...,AM}, where each \u03bb corresponds to a sensor feature,\nand a higher a value indicates a more significant contribution to the machine's degradation and, thus, the RUL prediction.\nThe model evaluates feature importance by systematically altering the input features and measuring the corresponding\nchanges in prediction accuracy. Specifically, it compares the accuracy of the full model against a version where each feature\nis individually permuted. Permutation involves randomly shuffling a given feature's values while keeping the others intact,\ndisrupting its relationship with the output. By observing the decline in accuracy after this permutation, the model quantifies the\nimportance of that specific feature. If the prediction accuracy significantly decreases, it implies that the feature in question\nplays a critical role in predicting RUL. Conversely, the feature is deemed less necessary if there is little to change.\nThis approach allows for an interpretability layer in the model, making it possible to identify which sensors are most likely\nto influence the degradation process. By ranking the features based on their importance scores, engineers can gain insights into\nwhich sensor data are the primary contributors to the machine's health decline and may indicate fault-prone areas in the system.\nThis information is invaluable for maintenance planning, as it allows engineers to focus on the most critical sensor readings and\ntake preventative actions based on the insights from the feature importance analysis.\nThe methodology of feature evaluation is inspired by the way decision trees assess the relevance of each input feature in\ncomplex models5,23. The ranking produced by this process directly supports more effective and interpretable predictions in the\ncontext of fault diagnosis and predictive maintenance."}, {"title": "Experimental setup", "content": "We show the efficacy of the suggested approach using the C-MAPSS dataset as a benchmark. 'Commercial Modular Aero-\nPropulsion System Simulation', or C-MAPSS, is a NASA tool that simulates extensive commercial turbofan engine data\nusing Matlab Simulink. C-MAPSS dataset is created using the C-MAPSS simulator14. Four subsets exist, from FD001 to\nFD004, within the dataset41. Twenty-one sensor measurements are gathered at each observation time, providing comprehensive\ninformation on engine locations and operational conditions. In the training set, each engine initially operates normally but starts\nto deteriorate after a specific time. Conversely, the test set comprises incomplete data, with time series terminating before the\nonset of engine degradation48. The aim is to estimate each engine's remaining operable cycle count. The complete introduction\nof the dataset can be found in Supplementary Material under S1."}, {"title": "Configuration setting", "content": "Dataset description\nThe architecture is implemented using Python 3.7 and the PyTorch 1.13.1 (GPU version) framework. The hardware configuration\nincludes an Intel(R) Xeon(R) Platinum 8380 CPU, eight RTX 3090 GPUs, and 500 GB of RAM."}, {"title": "Evaluation setting", "content": "To evaluate the model's performance, we utilize three functions. The first is the root mean square error (RMSE)39. Define\nd = RULpredict - RULtrue, representing the difference between the predicted and true RUL values. RMSE is calculated using\nRMSE = $\\sqrt{\\frac{1}{M} \\sum_{i=1}^{M} d_i^2 }$, \n(11)\nwhere M denotes the number of engines. The lower the RMSE score, the more accurate the interval prediction.\nTwo additional functions, average coverage interval length and coverage probability, are utilized to assess the model's\ninterval prediction performance. Normalized averaged width (NAW) measures the average width of the constructed predicted\nintervals as a percentage of the underlying target range. The definition of NAW is provided as follows,\nNAW = $\\frac{1}{RN} \\sum_{j=1}^N (\\frac{y_j^U - y_j^L}{R})$, \n(12)"}, {"title": "Prognostic results analysis", "content": "where R represents the range of the target variable throughout the forecast period. Predicted intervals with lower NAW values\nare considered more effective.\nThe coverage width-based criterion (CWC) provides a comprehensive evaluation score based on coverage probability\nand NAW. The fundamental concept behind CWC is that the score should be high irrespective of interval width if coverage\nprobability is below the nominal confidence level. At the same time, NAW becomes the dominant factor if coverage probability\nexceeds this level. The definition of CWC is\nCWC = NAW \u00d7 exp(\u2212\\frac{1}{\\alpha}(coverage)^2), \n(13)\nwhere coverage = \u03a3j=1Cj, where Cj = 1 if RULj \u2208 [yLj,yUj], and Cj = 0 otherwise. A lower CWC score indicates a more\neffective interval prediction.\nTo further test the performance of our model, eight engines, two from each of the four test datasets, are randomly selected. The\nactual RUL curves and online RUL interval estimation results for the test set, at a 95% confidence level, are presented in Fig. 4.\nThe errors between ground truth and predicted points are plotted in Fig. 4. The lower segment shows that although the predicted\nRUL does not always match the actual RUL, it does not lead to poor judgment. The predicted intervals, composed of upper\nand lower prediction limits, appropriately cover the target values. As service time progresses, the upper and lower prediction\nlimits closely follow the actual value changes. Although the predicted RUL sometimes exceeds the actual RUL, the predicted\nintervals consistently cover the real RUL, demonstrating the utility of the proposed method for constructing prediction intervals\nto capture fault trends."}, {"title": "Comparison with the state-of-the-art methods", "content": "To provide a comprehensive evaluation of each model's performance under various operating conditions and to facilitate a clear\ncomparison of their strengths and limitations, the key metrics RMSE (11), NAW (12), and CWC (13) have been calculated for\neach algorithm. As shown in Table 1, our proposed method achieves commendable RMSE results across the four sub-datasets,\noutperforming most established methods in most cases. This highlights the robustness of our approach in accurately predicting\nRUL, especially under complex conditions. The results are particularly noteworthy for the FD002 subset, encompassing more\nchallenging operational settings with diverse fault modes. While the performance of our model on sub-datasets FD001 and\nFD003 does not achieve the absolute best RMSE, it remains competitive and within the lower range of error rates compared\nto other models. This indicates that even in cases where our model does not achieve the top score, it still provides a highly\nreliable prediction with minimal deviation, ensuring robust and consistent results across varying conditions. This consistency is\nessential for practical applications in industrial prognostics, as it supports dependable predictions regardless of the specific"}, {"title": "Conclusion", "content": "operational scenario.\nThis paper proposes an intelligent RUL interval prediction method based on a modified GPR network for aero-engines. We\nembedded a temporal feature extraction into regression, enhancing the accuracy and robustness of RUL interval predictions. As\nan effective regression method, GPR is modified to adapt to engineering properties in our network, which comprehensively\nlearns the diversity of distributions between sensors and RUL. Results from experiments using the C-MAPSS dataset show that\nthe proposed method significantly narrows the width of the 95% confidence interval and enhances coverage accuracy, thereby\naiding in the PHM tasks of detection, diagnostics, and prognostics. Additionally, by adaptively employing additional random\nforest regression, the influence of sensors on fault modes can be assessed, facilitating predictive maintenance decisions for the\nreliable operation of machinery components.\nFuture work will incorporate transfer learning across different but similar sub-datasets to enhance predictive outcomes.\nAddressing the challenge of exponentially increasing training times in Gaussian regression as data size grows presents another\nintriguing research direction."}, {"title": "Data availability", "content": "The data that support the findings of this study are available from the corresponding author upon reasonable request."}]}