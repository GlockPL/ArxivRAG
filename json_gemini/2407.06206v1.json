{"title": "The Impact of an XAI-Augmented Approach on Binary Classification with Scarce Data", "authors": ["Ximing Wen", "Rosina O. Weber", "Anik Sen", "Darryl Hannan", "Steven C. Nesbit", "Vincent Chan", "Alberto Goffi", "Michael Morris", "John C. Hunninghake", "Nicholas E. Villalobos", "Edward Kim", "Christopher J. MacLellan"], "abstract": "Point-of-Care Ultrasound (POCUS) is the practice of clinicians conducting and interpreting ultrasound scans right at the patient's bedside. However, the expertise needed to interpret these images is considerable and may not always be present in emergency situations. This reality makes algorithms such as machine learning classifiers extremely valuable to augment human decisions. POCUS devices are becoming available at a reasonable cost in the size of a mobile phone. The challenge of turning POCUS devices into life-saving tools is that interpretation of ultrasound images requires specialist training and experience. Unfortunately, the difficulty to obtain positive training images represents an important obstacle to building efficient and accurate classifiers. Hence, the problem we try to investigate is how to explore strategies to increase accuracy of classifiers trained with scarce data. We hypothesize that training with a few data instances may not suffice for classifiers to generalize causing them to overfit. Our approach uses an Explainable AI-Augmented approach to help the algorithm learn more from less and potentially help the classifier better generalize.", "sections": [{"title": "Introduction", "content": "In radiology imaging, the scarcity of positive data (i.e., illustrating each specific disease) poses a significant challenge for the development of effective diagnostic tools. Radiology relies heavily on machine learning (ML) algorithms to accurately detect and diagnose various conditions. However, without sufficient positive data, the classifiers struggle to learn the distinct features of each condition, leading to reduced accuracy and reliability.\nResearchers investigate various approaches to address the problem of limited training data in ML such as data augmentation [Perez and Wang, 2017; Heidari et al., 2020], single-class learning [Denis, 1998; De Comit\u00e9 et al., 1999; Liu et al., 2003], zero-, one-, or few-shot learning [Larochelle et al., 2008; Lampert et al., 2013; Pourpanah et al., 2022; Fei-Fei et al., 2006; Scheirer et al., 2012], regularization [Nowlan and Hinton, 2018; Srivastava et al., 2014; Nusrat and Jang, 2018], and with ad hoc deep learning architectures [Xu et al., 2023]. Within the field of eXplainable Artificial Intelligence (XAI), recent works focus on constructing priors that incorporate human intuition or domain knowledge to improve models' robustness and accuracy when training data is limited [Perez and Wang, 2017; Heidari et al., 2020]. However, in their approach, usually either the interpretability of features is required (i.e. image pixels) or additional domain knowledge is used as input, which limits their applicability in occasions that the validity of features is not easily accessed.\nTo solve this challenge, we propose a new generalizable prior constructed with additive feature attribution [Erion et al., 2021] without any human input or domain knowledge and then demonstrate training classifiers with the prior can provide additional feedback for back-propagation thus improving classification accuracy.\nAdditive feature attribution methods [Hastie, 2017; Lundberg and Lee, 2017] produce as output a model of the data model they aim to explain as a sum of the contributions of the individual features from data. They are originally designed to assist ML classifiers in explaining their decisions and is studied in the sub-fields of XAI (henceforth we use XAI as a general term). These additive models have the property of local accuracy, dictating that the sum of feature attributions for a particular instance indicates its class. Consequently, local accuracy determines whether the class indicated by the explanation model is consistent with the classifier's prediction. In the ideal situation, both the decision boundary built by the explanation model and the prediction model should be similar to the ground truth data. Motivated by this, we create a new prior by constructing a cross-entropy loss between the true label and the class indicated by the explanation model utilizing Gradient SHAP [Erion et al., 2021], an additive feature attribution method.\nThe datasets used in the experiments herein illustrate three medical conditions: pneumothorax (PTX) (i.e., collapsed lung), intracranial pressure via optic nerve sheath diameter"}, {"title": "Background and Related Work", "content": "In this section, we describe the baseline classifiers and the related works.\n2.1 The Baseline Classifiers\nThe baseline classifiers we utilize in the experiments herein are three variations of the architecture described in Hannan et al. [2023]. To the best of our knowledge, the architecture presented in Hannan et al. [2023] achieves the highest accuracy on the datasets used and thus we choose them as the baseline classifiers. Each variation is used for a different dataset, namely, PTX, ONSD, and COVID-19, adapting to their characteristics. Common to all is the use of a sparse coding model and a small data classifier with convolutional layers.\nThe task for PTX and COVID-19 is to classify whether a pleural line is moving shown in lung ultrasound videos. A pleural line is a terminology in radiology, which indicates where the lung comes into contact with the chest wall. Its movement is the most important feature for PTX diagnosis. We will provide more detail about the datasets in Section 5. The baseline model for PTX [Hannan et al., 2023] has three components. First, a YOLOv4 object detection model [Bochkovskiy et al., 2020] recognizes the region of interest around the pleural line and creates a bounding box around it. Second, a 3D convolutional sparse coding model [Olshausen and Field, 1997] is learned with a convolutional variant of the Locally Competitive Algorithm (LCA) [Paiton, 2019] to compute sparse features with an activation map. The representation of the activated sparse features is used in a convolutional neural network (CNN) classifier with two convolutional layers and two feed-forward layers with dropout. These classifiers are then trained with a binary cross-entropy loss (BCE) function. The classifiers for PTX and COVID-19 are designed to classify frames rather than videos. The process is to extract frames by striding over the video frames at a fixed interval. At each point, the model extracts the given frame along with the two previous and two subsequent frames, resulting in a five-frame block. When applying this binary classifier to the PTX dataset, it determines whether a frame block represents lung sliding. Sliding indicates normal and is thus negative for pneumothorax. This pipeline utilizes the output logits as confidence values, averaging these and rounding to the closest prediction.\nThe classifier for the COVID-19 data uses the same 3D convolutional sparse coding model as for PTX. The difference is that YOLO is not required because there are no object labels to be learned. The same small-data convolutional classifier is used.\nThe ONSD dataset consists of ultrasound videos of the optic nerve sheath. The goal of this task is to detect elevated intracranial pressure (ICP) by measuring the optic nerve sheath diameter (ONSD). The model is different from the PTX model in [Hannan et al., 2023] in a few aspects. The YOLO is run to detect both the eye and the nerve. A 300\u00d7100 region is cropped from the nerve, where the top of the region falls 3mm below the bottom of the eye and is centered on the middle of the nerve. This is then downsized to 150\u00d750 before being fed to a 2D sparse coding model. Once this region is acquired, the task has two steps: detecting the boundaries of the nerve and measuring the distance between the boundaries. The sparse coding model is constructed with both of these steps in mind, where the goal is to construct an activation map for a given image where the distance between the nerve boundaries is obvious, reducing the complexity of the task for the classifier. A standard 2D convolutional sparse coding approach would use a small filter size, such as 8\u00d78, and stride these filters over both the x and y dimensions to build an activation map (see PTX architecture in Hannan et al. [2023]). While this approach may yield vertical edge detectors that activate on the nerve boundaries, these filters would activate for other vertical edges as well. Additionally, striding over both the x and y dimensions is computationally expensive, where the cost scales quadratically with image size. Therefore, a 2D sparse coding model is trained on these regions with a filter size of 150\u00d710. This filter covers the entire width of the nerve region, resulting in the filters only sliding across the y-axis. The idea is that the edges of the nerve will still need to be represented in the sparse model and therefore it will learn filters that activate on both edges of a given nerve within the same filter. For nerves of different widths, different filters would be learned with the same overall pattern but the edges would be closer or farther based on the observed width of the nerve. The resulting sparse coding model produces activation maps that are 1\u00d7M\u00d7N, where N is the number of filters and M is the vertical dimension. They sum these activation maps over the vertical dimension to learn which of our learned, specialized nerve-width filters are most activated in a given image. If one of these filters fits the given nerve well, then it will be highly activated over the entire vertical dimension of the image. This results in a vector of size N, where each value corresponds to the activity level of a filter. They then learn a simple two-layer MLP that takes the N-dimensional vector as input and produces a single binary class prediction, corresponding to whether the width of the nerve exceeds the target threshold.\n2.2 Related Work\nErion et al. [2021] introduced the formal expression of attribution priors as constraints imposed when training a classifier originating from feature attribution methods. They ex-"}, {"title": "Motivation to Use XAI to Augment Training", "content": "Given small data classifiers f, we have input features \\(x \\in X\\), \\(X \\subset R^d\\) and binary labels \\(y \\in Y\\), \\(Y = \\{0, 1\\}\\) (i.\u0435., \\(y = 0\\) when class is negative for disease and \\(y = 1\\) when class is positive for disease). These data represent the real-world data, which characterizes a ground-truth decision boundary that separates the classes 1 and 0. Using the set of n training instances x, we train a classifier f(x) that learns to assign labels f(x) for each instance. By producing these values for f(x), f(x) proposes its characterization of the decision boundary. In practice with the datasets studied herein, f(x) obtains an accuracy level describing the proportion of correct classifications over the total predictions \\(a_f \\ne 1\\) hence producing an error \\(E_f \\ne 0\\). Consequently, its decision boundary does not perfectly match the boundary in the real data. Now consider we build an additive feature attribute model g(z) such as SHAP [Lundberg and Lee, 2017] given by Equation 1:\n\\[\ng(z) = \\Phi_0 + \\sum_{j=1}^d \\Phi_j(z_j)\n\\]\nwhere \\(z \\in \\{0, 1\\}^d\\) is the projection of the input features from the original input space into binary values. The explanation model g(z) models the classifier f(x), attributing an effect \\(\\phi_j\\) to each feature and summing the effects of all feature attributions approximates the output f(x). As per the additive model property local accuracy [Lundberg and Lee, 2017], the result of Equation 1 is \\(g(z) \\in Y\\). Therefore, this model builds yet a third decision boundary, except that this is now local, i.e., it models each instance. We construct a new prior \\(\\Phi(X, Y)\\) through constraining this third decision boundary with the boundary indicated by the real data using cross entropy loss (Equation 2):\n\\[\n\\Phi(X, Y) = \\frac{1}{n} \\sum_{i=1}^n y_i \\log P(g(h_z(x_i)) = Y_i | h_z(x_i)),\n\\]\nwhere we use a projection function \\(z = h_z(x)\\) to represent z. The intuition underlying our proposed approach is to use the XAI prediction for each training instance to provide a second loss as feedback to the training algorithm. The idea is that the new prior can help push the limits of data by learning more from less. With the original cross entropy loss (Equation 3):\n\\[\nL(\\theta; X, Y) = \\frac{1}{n} \\sum_{i=1}^n y_i \\log P(f(x_i) = Y_i | x_i; \\theta),\n\\]\nwhere \\(\\theta\\) are weights in the classifier. We construct the new objective function using the prior thus generating the new classifier we call the XAI-Augmented (XAIAUG) classifier (Equation 4):\n\\[\nL_{XAIAUG}(\\theta) = L(\\theta; X, Y) + \\Phi(X, Y)\n\\]\nThe expectation is that the classifications produced by the XAIAUG classifier, on average, have higher accuracy than the original classifier (which we will use as baseline). It is also our expectation that the local accuracy of the additive feature attribution model computed for XAIAUG classifier is higher on average compared to the Base. The local accuracy is computed using Gradient SHAP [Erion et al., 2021] for each classifier at the end of every training epoch.\nThe prior \\(\\Phi(X, Y)\\) needs to be differentiable so that we can backpropagate the error and update the weights \\(\\theta\\) of the classifier. In the next section, we will describe how we use Gradient SHAP to implement the prior."}, {"title": "XAI-Augmented Approach", "content": "In this section, we describe how we use Gradient SHAP and binary classification entropy (BCE) loss to implement the prior and then present the algorithm for training the XAIAUG classifier XAI_{AUG}(x). From [Erion et al., 2021], for each input feature xi, we first obtain the feature attribution using Integrated Gradients and Expected Gradients:\n\\[\n\\Phi_{i}(f,x) = ExpectedGradient_{i}(x)\n= \\int_{x'} IntegratedGradients_{i}(x, x') p_D(x') dx'\n= (x_i - x'_i) \\int_{\\alpha=0}^1 \\frac{\\delta f(x' + \\alpha \\cdot (x - x'))}{\\delta x_i} d\\alpha\n\\]\nwhere x' is a baseline input feature used as a starting point for calculating feature importance, which is drawn from a background set constructed with all training instances. \\(p_D(x')\\) represents the probability distribution of the background dataset. Intuitively, the baseline input feature has the explanatory role as in representing the impact of the absence of each input feature on the prediction to contrast with the impact of each feature on the prediction when present in the input. By sampling the baseline input feature from the background set, we can measure the average impact of each feature.\nIn our implementation, we solve the calculus by approximation, we have a dataset D, then we get:\n\\[\n\\Phi_{i}(f,x) = \\frac{1}{T} \\sum_{x'\\sim D} \\sum_{k=1}^m \\frac{\\delta f(x' + \\frac{k}{m} \\cdot (x - x'))}{\\delta x_i}\n\\]\nwhere D is the background set and T is the sampling number. In Gradient SHAP, we have the assumption that all attribution go into features and do not consider \\(\\Phi_0\\). Thus we have:\n\\[\ng(h(x)) = \\sum_{i=1}^d \\Phi_{i}(f,x)\n\\]\nIn this way, we construct the differentiable prior and construct the new loss:\n\\[\n\\Phi(X, Y, \\theta) = \\frac{1}{n} \\sum_{i=1}^n y_i \\log P(g(h_z(x_i)) = y_i | h_z(x_i); \\theta)\n\\]\n\\[\nL_{XAIAUG}(\\theta) = L(\\theta; X, Y) + \\Phi(X, Y, \\theta)\n\\]\nAs Algorithm 1 describes, we first randomly select 100 images from the training dataset as background for Gradient SHAP, for each iteration, we first apply gradient SHAP for each input image and get the sum of all SHAP values for each input image which is \u0177. Then we construct SHAP loss using BCE loss to measure the difference between \u0177 and their original labels. We update the classifier's weight by training with the sum of SHAP loss and classification loss."}, {"title": "Studies", "content": "In this section, we describe the methodology, metrics, and hypotheses for studies we conduct over three datasets. The methodology we investigate is to train the classifiers with the proposed XAIAUG approach described in Section 4 and compare against the baseline. The baseline refers to the classifiers described in Section 2.1. For all studies, we run our experiments through a 5-fold cross-validation and computed the averages for metrics across 5 folds, The choice of the number of epochs utilized for testing is based on the smallest loss obtained during training. The studies for PTX and COVID-19 are based on video frame blocks and not on the entire videos (See Section 2.1 where we describe how frames are extracted from videos). Only when we discuss classification for ONSD dataset, we use videos rather than frames.\nDatasets Here we introduce the size of each dataset we used: PTX, ONSD and COVID-19. The first two data are not publicly available, collected under the DARPA POCUS-AI Program. The third dataset is publicly available.\nThe PTX dataset contains 62 videos, 30 from patients with PTX, which is characterized by the absence of pleural line movement; and 32 from patients without PTX, where the pleural line movement is recognized. The average length of these videos is approximately three seconds at 20 frames per second with a convex probe at depths ranging from 4-12 cm. The ONSD dataset contains a total of 60 videos, 22 positive and 38 negative. The average length of the videos is 12.22 seconds long. The COVID-19 ultrasound dataset [Born et al., 2021] contains 202 videos, of which 97 are positive and 105 are negative. Each video has one of four labels: COVID-19, healthy, bacterial pneumonia, or viral pneumonia. Because our scope is limited to binary classification, we only use the data on healthy and COVID-19 classes.\nMetrics The studies utilize three performance metrics, which are used to build confusion matrices designative value of true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN). The three performance metrics we use are Average Accuracy (AA), Balanced Accuracy (BA), and F1 score (F1). To compute all these, we need to compute sensitivity, specificity, and precision. See their formulas below:\n\\[\nAverage Accuracy = \\frac{TP+TN}{TP+TN+FP+ FN}\n\\]\n\\[\nPrecision = \\frac{TP}{TP+FP}\n\\]\n\\[\nSensitivity = \\frac{\u03a4\u03a1}{TP + FN}\n\\]\n\\[\nBalanced Accuracy = \\frac{Sensitivity + Specificity}{2}\n\\]\n\\[\nSpecificity = \\frac{TN}{TN + FP}\n\\]\n\\[\nF1 = \\frac{2* Precision * Recall}{Precision + Recall}\n\\]\nAdditionally, we compute local accuracy (LA) for Gradient SHAP [Lundberg and Lee, 2017] to assess whether the additive feature attribution model correctly assigns the class of each testing instance. LA [Lundberg and Lee, 2017] can be understood as a measure of local interpretability as it indicates how well the feature attributions model the instances. Note that in this paper we only present results for LA and do not demonstrate visualizations of interpretability.\nThe studies also utilize loss as a metric, which we plot across multiple epochs on training and testing data to determine the influence of XAIAUG in decreasing overfitting.\nHypotheses We adopt a general null hypothesis under which we compare the XAIAUG classifier against the baseline across the datasets for all metrics. In simple terms, considering each dataset as a variable \\(c \\in C\\), the metrics as \\(m \\in M\\), and a baseline Base \\(\\in B\\), we describe the general null hypothesis as:\nH_0: The XAIAUG classifier produces lower or equal values for metric m compared to the Base for dataset c."}, {"title": "Results and Discussion", "content": "We present results for performance along selected metrics comparing the proposed approach with the baseline.\n6.1 Performance\nTables 1, 2, and 3 present the averages across all folds for AA, BA, and F1 for PTX, ONSD, and COVID-19. The results consistently show higher values for XAIAUG, particularly in the two metrics (i.e., BA and F1) that account for data imbalance. These results reject the null hypotheses for the three datasets for BA and F1. For AA, the null hypothesis is rejected for the COVID-19 and ONSD datasets. On the other hand, the results for the COVID-19 data seem to be where the proposed XAIAUG approach produces the least improvement in the metric values. We observe that the COVID-19 dataset contains the largest amount of data with 202 videos, compared to the PTX dataset with 62 videos, and the ONSD dataset with 60 videos. This motivates us to investigate the reason for the least improvement in the COVID-19 dataset by analyzing the sensitivity of these metrics with respect to the data amounts in Section 6.3.\n6.2 Local Accuracy\nTable 5 shows the results for LA for the three datasets. The average LA of the XAIAUG classifier across all folds improves over the baseline for all three datasets. These results demonstrate that interpretability is improved since the additive feature attribution method is better aligned with the XAIAUG classifier than with the baseline.\n6.3 Sensitivity on Data Amounts\nWe hypothesize that XAIAUG improves accuracy the least in the COVID-19 dataset because it is the one with the largest number of samples (i.e., 2423 frames). Recall that our motivation is to learn more from the data when instances are limited. Because instances are not as limited in the COVID-19 dataset, the baseline classifier may have been able to learn generalization from the training dataset, potentially constraining XAIAUG's ability to significantly enhance accuracy.\nTo verify that the COVID-19 dataset is large enough and this is why XAIAUG does not improve accuracy as much as in the two datasets, we broke down the COVID-19 data into three smaller subsets we refer to as Small COVID-19 Set 1, Small COVID-19 Set 2, and Small COVID-19 Set 3 with 722, 907, and 794 frames, respectively.\nHypothesis We describe the general null hypothesis as H_0: For the COVID-19 dataset, the percentage performance differences for the XAIAUG classifier over the Base, calculated using \\(\\frac{XAIAUG-Base}{Base}\\), for the metric m\\in M, are less or equal when using only subsets versus using the entire dataset."}, {"title": "Comparison against Regularization", "content": "Tables 6, 7, and 8 show results for the previously defined performance metrics but now comparing the XAIAUG classifier with a different baseline \u2013 L2. The compared classifier is different from the original baseline in that the L2 norm is added to the loss function for regularization. As when against the baseline, in general, XAIAUG produces better performance in metrics that consider class imbalance. The exception is in BA for the ONSD dataset. We next look at the loss values plotted along training epochs.\nFigures 1, 2, and 3 depict the loss with respect to epochs for the proposed approach and the alternate baseline L2 with L2 regularization classifiers for the three datasets. The vertical lines outline the epoch with minimum training loss. The curves correspond to training and testing data so we can analyze overfitting. Analogous to improvements in accuracy, the plots reveal that the XAIAUG classifier often produces values for loss lower than L2 in many folds but not for all. In Figure 1, the XAIAUG testing data shows loss values at the latest epochs to be lower than those from L2 testing data in four out of the five folds, suggesting a potential decrease in overfitting. In ONSD data (Figure 2), the decrease in overfitting happens in three out of five folds. In Figure 3, the XAIAUG testing data shows loss values at the latest epochs to be higher than those from L2 in folds zero and two. In folds one, three, and four, it goes up at the very end.\nThe conclusion that can be drawn is that the improvements in accuracy are consistent with the reduced overfitting. This suggests the reduction in overfitting could be the reason for the increments in accuracy. In future work, we shall investigate the conditions under which our approach is useful."}, {"title": "Conclusions", "content": "This paper proposes an XAI-Augmented approach to train classifiers with scarce data, with the aim to learn more from less. To investigate and analyze the proposed approach in terms of accuracy, we utilize three ultrasound video datasets, PTX, ONSD, and COVID-19. We present studies to better comprehend why and when this approach improves performance. We found a consistent improvement in Balanced Accuracy and F1 for all three datasets. The study of subsets of COVID-19 datasets shows that our approach is sensitive to data amounts and has the potential for improving classifiers when training data is scarce. By comparing against regularization, we found that the improvements in accuracy are consistent with reduced overfitting. Overall, our results are consistent and conclusions are drawn based on results without major variations."}, {"title": "Limitations and Future Work", "content": "This work is limited in that it does not investigate multiple approaches that have been used to increase accuracy such as data augmentation, single-class learning, and zero-, one-, or few-shot learning. Future studies should demonstrate how the proposed XAIAUG approach compares to these other ways to improve accuracy when only small data amounts are available to train a classifier. In future work, synthetic datasets may be used to determine what data conditions, if any, cause these variations. The other alternative is to investigate the impact of the XAIAUG approach on aspects such as incremental learning [Shmelkov et al., 2017].\nEthical Statement\nThe authors have conducted this work after receiving approval from IRB in their respective institutions and from the funding agency sponsoring this work.\nAcknowledgements\nThis research was developed with funding from the Defense Advanced Research Projects Agency (DARPA) under the POCUS AI Program (award no. HR00112190076). The views, opinions and/or findings expressed are those of the authors and should not be interpreted as representing the official views of the Department of Defense or the U.S. Government."}]}