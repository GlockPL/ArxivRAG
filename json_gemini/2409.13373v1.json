{"title": "LLMS STILL CAN'T PLAN; CAN LRMS? A PRELIMINARY EVALUATION OF OPENAI'S 01 ON PLANBENCH", "authors": ["Karthik Valmeekam", "Kaya Stechly", "Subbarao Kambhampati"], "abstract": "The ability to plan a course of action that achieves a desired state of affairs has long been considered a core competence of intelligent agents and has been an integral part of AI research since its inception. With the advent of large language models (LLMs), there has been considerable interest in the question of whether or not they possess such planning abilities. PlanBench [1], an extensible benchmark we developed in 2022, soon after the release of GPT3, has remained an important tool for evaluating the planning abilities of LLMs. Despite the slew of new private and open source LLMs since GPT3, progress on this benchmark has been surprisingly slow. OpenAI claims that their recent o1 (Strawberry) model has been specifically constructed and trained to escape the normal limitations of autoregressive LLMs-making it a new kind of model: a Large Reasoning Model (LRM). Using this development as a catalyst, this paper takes a comprehensive look at how well current LLMs and new LRMs do on PlanBench. As we shall see, while ol's performance is a quantum improvement on the benchmark, outpacing the competition, it is still far from saturating it. This improvement also brings to the fore questions about accuracy, efficiency, and guarantees which must be considered before deploying such systems.", "sections": [{"title": "1 Introduction", "content": "The recent release of OpenAI's o1 (Strawberry) [2] brings with it the opportunity to both freshly evaluate progress on PlanBench and to consider directions for extending the benchmark. In particular, unlike the LLMs which came before it, which can roughly be viewed as approximate retrievers, o1 seems to have been trained to be an approximate reasoner.\u00b9 Following OpenAI2, we draw a distinction between previous Large Language Models and o1, a Large Reasoning Model (or LRM), as its new (unknown) architecture, operation, and capabilities all seem to be fundamentally different from those of vanilla LLMs, both at pretraining phase and at inference time. To properly evaluate this new kind of model and understand its abilities and limitations will require new tools and evaluation methods, especially if details of the overall model structure are kept secret and internal traces remain inaccessible to outside researchers. Since PlanBench [1] first debuted on arXiv in 2022, we have continually retested new models on one particular subset: a static dataset of 600 three to five block problems. Even though LLMs have gotten ever larger and required substantially more investment per model, their performance on even the simplest planning problems has never come close to saturating this test set, and the improvements we have seen have not been robust or generalizable [6]. Our benchmark has thus served as a useful marker of LLM progress (or lack thereof) on planning and reasoning tasks, though it is important to note that this analysis-especially when confined to a static test set-can only serve as an upper bound on performance. When we first designed PlanBench, it was intended to be more than just this set, but rather to be"}, {"title": "2 State-of-the-Art LLMs Still Can't Plan", "content": "PlanBench remains a challenging benchmark for vanilla LLMs (massive transformer models which have been fine-tuned via RLHF), and their lackluster performance on even our easiest test set leads us to continue to believe that planning cannot be generally and robustly solved by approximate retrieval alone. In Table 1, we present the results of running current and previous generation LLMs on a static test set of 600 three to five block Blocksworld problems, as well as on a set of 600 semantically identical but syntactically obfuscated instances which we call Mystery Blocksworld. Across these models, the best performance on regular Blocksworld is achieved by LLaMA 3.1 405B with 62.6% accuracy. Despite the underlying problems being identical, Mystery Blocksworld performance lags far behind-no LLM achieves even 5% on our test set-and performance on one version of the domain does not clearly predict performance on the other.\u2074 In the original paper, we tested both natural language prompts and PDDL, and found that vanilla language models perform better when tested on the former, even though natural language prompts can introduce uncertainty due to polysemanticity and syntactic ambiguity. To make our comparisons \"fair\" for the models being tested, the results we have been reporting are the higher accuracy natural language prompting numbers. LLMs are highly capable of providing translations between equivalent representations [7]. This fact, combined with their significantly higher performance on the unobfuscated version of the Blocksworld domain, predicts that-if they are capable of composing reasoning operations-the performance gap between Mystery Blocksworld and classic Blocksworld should shrink substantially if the translation from Mystery Blocksworld back into Blocksworld is explicitly provided. However, when we provide this in the prompt (see Appendix C), performance only improves a very small amount: GPT-4 achieves 10%. We also find that, contrary to previous claims, one-shot prompting is not a strict improvement over zero-shot. In fact, for many models it seems to do significantly worse!\u2075 This is most notable in our tests of LLaMA family models."}, {"title": "3 From Approximate Retrieval to Approximate Reasoning: Evaluating 01", "content": "Many researchers, including us, have argued that \"standard\" autoregressive LLMs generate outputs via approximate retrieval, and that, while they show impressive performance on a range of System 1 tasks, they are unlikely to achieve more System 2-like approximate reasoning capabilities critical for planning tasks (c.f. [9]). Until now, the best way to coax sound planning capabilities out of LLMs has been to pair them with external verifiers in a generate-test framework,"}, {"title": "4 Conclusion", "content": "We took a fresh look at the planning capabilities of both SOTA LLMs, and examined the performance of OpenAI's new o1 models on PlanBench. Over time, LLMs have improved their performance on vanilla Blocksworld-with the best performing model, LlaMA 3.1 405B, reaching 62.5% accuracy. However, their dismal performance on the obfuscated (\"Mystery\") versions of the same domain betrays their essentially approximate retrieval nature. In contrast, the new ol models, which we call LRMs (Large Reasoning Models)-in keeping with OpenAI's own characterizations-not only nearly saturates the original small instance Blockworld test set, but shows the first bit of progress on obfuscated versions. Encouraged by this, we have also evaluated ol's performance on longer problems and unsolvable instances, and found that these accuracy gains are not general or robust. We also discussed the critical accuracy/efficiency tradeoffs that are brought up by the fact that o1 that uses (and charges for) significant inference-time compute, as well as how it compares to other LLM-based approaches (such as LLM-Modulo [10]) and dedicated solvers. We hope this research note gives a good snapshot of the planning capabilities of LLMs and LRMs as well as useful suggestions for realistically evaluating them."}, {"title": "Appendix", "content": "A Gemini 1.5 Pro Response to Mystery Blocksworld finish_reason: SAFETY safety_ratings { } category: HARM_CATEGORY_SEXUALLY_EXPLICIT probability: NEGLIGIBLE safety_ratings { } category: HARM_CATEGORY_HATE_SPEECH probability: NEGLIGIBLE safety_ratings { } category: HARM_CATEGORY_HARASSMENT probability: NEGLIGIBLE safety_ratings { category: HARM_CATEGORY_DANGEROUS_CONTENT probability: MEDIUM } B01 Token Use Versus Problem Difficulty Prompt to Translate From Mystery Back to Blocksworld I am playing with a set of objects. Here are the actions I can do Attack object Feast object from another object Succumb object Overcome object from another object I have the following restrictions on my actions: To perform Attack action, the following facts need to be true: Province object, Planet object, Harmony. Once Attack action is performed the following facts will be true: Pain object. Once Attack action is performed the following facts will be false: Province object, Planet object, Harmony. To perform Succumb action, the following facts need to be true: Pain object. Once Succumb action is performed the following facts will be true: Province object, Planet object, Harmony. Once Succumb action is performed the following facts will be false: Pain object. To perform Overcome action, the following needs to be true: Province other object, Pain object. Once Overcome action is performed the following will be true: Harmony, Province object, Object Craves other object. Once Overcome action is performed the following will be false: Province other object, Pain object. To perform Feast action, the following needs to be true: Object Craves other object, Province object, Harmony. Once Feast action is performed the following will be true: Pain object, Province other object. Once Feast action is performed the following will be false, Object Craves other object, Province object, Harmony. D Prompts for Blocksworld D.1 (Solvable) Blocksworld Instances - Zero-Shot in Natural Language I am playing with a set of blocks where I need to arrange the blocks into stacks. Here are the actions I can do Pick up a block Unstack a block from on top of another block Put down a block Stack a block on top of another block I have the following restrictions on my actions: I can only pick up or unstack one block at a time. I can only pick up or unstack a block if my hand is empty. I can only pick up a block if the block is on the table and the block is clear. A block is clear if the block has no other blocks on top of it and if the block is not picked up. I can only unstack a block from on top of another block if the block I am unstacking was really on top of the other block. I can only unstack a block from on top of another block if the block I am unstacking is clear. Once I pick up or unstack a block, I am holding the block. I can only put down a block that I am holding. I can only stack a block on top of another block if I am holding the block being stacked. I can only stack a block on top of another block if the block onto which I am stacking the block is clear. Once I put down or stack a block, my hand becomes empty. Once you stack a block on top of a second block, the second block is no longer clear. [STATEMENT] As initial conditions I have that, the red block is clear, the blue block is clear, the yellow block is clear, the hand is empty, the blue block is on top of the orange block, the red block is on the table, the orange block is on the table and the yellow block is on the table. My goal is to have that the orange block is on top of the blue block. What is the plan to achieve my goal? Just give the actions in the plan. =============o1-preview RESPONSE============ == To achieve your goal of stacking the orange block on top of the blue block, you can follow these steps: 1. **Unstack the blue block from on top of the orange block.** Since the blue block is clear and your hand is empty, you can unstack it from the orange block. 2. **Put down the blue block on the table. ** With the blue block in your hand, you can place it onto the table. 3. **Pick up the orange block from the table.** The orange block is now clear (no blocks on top of it), and your hand is empty after putting down the blue block, so you can pick it up. 4. **Stack the orange block on top of the blue block.** The blue block is clear on the table, so you can stack the orange block you're holding onto it. **Actions in the plan:** **Unstack** the blue block from the orange block. **Put down** the blue block on the table. **Pick up** the orange block from the table. **Stack** the orange block on top of the blue block. D.2 (Solvable) Harder Blocksworld Instances - Zero-Shot in PDDL The following is a PDDL specification of a planning problem. The first part, under the heading [ DOMAIN], is the domain file. The second part, under the heading [QUERY PROBLEM), is the problem file. Using this information, which is correct, and no further assumptions, find a plan which, when run from the specified initial state, satisfies the specified goal. Provide your answer as a sequence of actions in PDDL format. An action ACTION which acts on two objects OBJ1 and OBJ2 would be written (ACTION OBJ1 OBJ2). Do not provide anything else in your answer. [DOMAIN] (define (domain blocksworld-4ops) (:requirements : strips) (:predicates (clear ?x) (ontable ?x) (handempty) (holding ?x) (on ?x ?y)) (:action pick-up : parameters (?ob) : precondition (and (clear ?ob) (ontable ?ob) (handempty)) : effect (and (holding ?ob) (not (clear ?ob)) (not (ontable ?ob)) (not (handempty)))) (:action put-down : parameters (?ob) :precondition (holding ?ob) :effect (and (clear ?ob) (handempty) (ontable ?ob) (not (holding ?ob)))) (:action stack : parameters (?ob ?underob) : precondition (and (clear ?underob) (holding ?ob)) : effect (and (handempty) (clear ?ob) (on ?ob ?underob) (not (clear ?underob)) (not (holding ?ob)))) (:action unstack : parameters (?ob ?underob) :precondition (and (on ? ob ?underob) (clear ?ob) (handempty)) : effect (and (holding ?ob) (clear ?underob) (not (on ?ob ?underob)) (not (clear ?ob)) (not (handempty))))) [QUERY PROBLEM] (define(problem BW-rand-6) (:domain blocksworld-4ops) (:objects abcdef) (:init (handempty) (ontable a) (on b f) (on ca) (on d b) (on e c) (on f e) (clear d) ) (:goal (and (on a f) (on bc) (on ca) (on d b) (on f e)) ) ) ) [PLAN] =============o1-preview RESPONSE================ (unstack d b) (put-down d) (unstack b f) (stack b c) (pick-up d) (stack d b) (unstack f e) (put-down f) (unstack ec) (put-down e) (pick-up f) (stack f e) (unstack ca) (put-down c) (pick-up a) (stack a f) (pick-up c) (stack c a) (pick-up b) (stack b c) (pick-up d) (stack d b) D.3 Unsolvable Blocksworld Instances - Zero-Shot in PDDL The following is a PDDL specification of a planning problem. The first part, under the heading [ DOMAIN], is the domain file. The second part, under the heading [QUERY PROBLEM), is the problem file. Using this information, which is correct, and no further assumptions, find a plan which, when run from the specified initial state, satisfies the specified goal. Provide your answer as a sequence of actions in PDDL format. An action ACTION which acts on two objects OBJ1 and OBJ2 would be written (ACTION OBJ1 OBJ2). Do not provide anything else in your answer. [DOMAIN] (define (domain blocksworld-4ops) (:requirements : strips) (:predicates (clear ?x) (ontable ?x) (handempty) (holding ?x) (on ?x ?y)) (:action pick-up : parameters (?ob) : precondition (and (clear ?ob) (ontable ?ob) (handempty)) : effect (and (holding ?ob) (not (clear ?ob)) (not (ontable ?ob)) (not (handempty)))) (:action put-down : parameters (?ob) :precondition (holding ?ob) :effect (and (clear ?ob) (handempty) (ontable ?ob) (not (holding ?ob)))) (:action stack : parameters (?ob ?underob) : precondition (and (clear ?underob) (holding ?ob)) : effect (and (handempty) (clear ?ob) (on ?ob ?underob) (not (clear ?underob)) (not (holding ?ob)))) (:action unstack : parameters (?ob ?underob) :precondition (and (on ? ob ?underob) (clear ?ob) (handempty)) : effect (and (holding ?ob) (clear ?underob) (not (on ?ob ?underob)) (not (clear ?ob)) (not (handempty))))) [QUERY PROBLEM] (define(problem BW-rand-4) (:domain blocksworld-4ops) (:objects a bcd) (:init (handempty) (on a b) (on bc) (on cd) (ontable d) (clear a) ) (:goal (and (on d c) (on c d) ) ) ) [PLAN] =============o1-preview RESPONSE========== == **No plan exists that satisfies the goal with the given initial state and domain.** E Prompts for Mystery Blocksworld E.1 Mystery Blocksworld Instances - Zero-Shot in Natural Language I am playing with a set of objects. Here are the actions I can do Attack object Feast object from another object Succumb object Overcome object from another object I have the following restrictions on my actions: To perform Attack action, the following facts need to be true: Province object, Planet object, Harmony. Once Attack action is performed the following facts will be true: Pain object. Once Attack action is performed the following facts will be false: Province object, Planet object, Harmony. To perform Succumb action, the following facts need to be true: Pain object. Once Succumb action is performed the following facts will be true: Province object, Planet object, Harmony. Once Succumb action is performed the following facts will be false: Pain object. To perform Overcome action, the following needs to be true: Province other object, Pain object. Once Overcome action is performed the following will be true: Harmony, Province object, Object Craves other object. Once Overcome action is performed the following will be false: Province other object, Pain object. To perform Feast action, the following needs to be true: Object Craves other object, Province object, Harmony. Once Feast action is performed the following will be true: Pain object, Province other object. Once Feast action is performed the following will be false, Object Craves other object, Province object, Harmony. [STATEMENT] As initial conditions I have that, object b craves object c, harmony, planet object a, planet object c, planet object d, province object a, province object b and province object d. My goal is to have that object c craves object b. What is the plan to achieve my goal? Just give the actions in the plan. === ========01-preview RESPONSE=========== == To achieve the goal where object c craves object b, you can perform the following sequence of actions: 1. **Feast object b from object c** Preconditions: 'Object b craves object c' (initial fact) 'Province object b' (initial fact) 'Harmony' (initial fact) Effects: Adds: 'Pain object b', 'Province object c' Deletes: 'Object b craves object c', 'Province object b', 'Harmony' 2. **Succumb object b** Preconditions: 'Pain object b' (from previous action) Effects: Adds: 'Province object b', 'Planet object b', 'Harmony' Deletes: 'Pain object b' 3. **Attack object c** Preconditions: 'Province object c' (from step 1) 'Planet object c' (initial fact) 'Harmony' (restored in step 2) Effects: Adds: 'Pain object c' Deletes: 'Province object c', 'Planet object c', 'Harmony' 4. **Overcome object c from object b** Preconditions: 'Province object b' (restored in step 2) 'Pain object c' (from step 3) Effects: Adds: 'Harmony', 'Province object c', 'Object c craves object b' (goal achieved) Deletes: 'Province object b', 'Pain object c' By following this plan, you manipulate the states of the objects through the actions provided, ultimately achieving the desired state where 'Object c craves object b'. **Answer:** To achieve the goal, perform these actions in order: 1. Feast object b from object c 2. Succumb object b 3. Attack object c 4. Overcome object c from object b F Prompts for Randomized Mystery Blocksworld F.1 Randomized Mystery Blocksworld Instances - Zero-Shot in Natural Language I am playing with a set of objects. Here are the actions I can do J4gv801gnu2it0yj object_0 object_1. U64y1a9apusmslxb object_0. Kip9uw781pv62umn object_0. Wio5amhq7814n006 object_0 object_1. I have the following restrictions on my actions: To perform j4gv801gnu2it0yj action, the following facts need to be true: tv30k33pzoulql6w object_1, and a46zhwykn6jvbabk object_0 Once j4gv801gnu2it0yj is performed the following facts will be true: cql4o62p1yeke3ok, tv30k33pzoulql6w object_0, and b6e9q4r60gagvdcn object_0 object_1 Once j4gv801gnu2it0yj is performed the following facts will be false: tv30k33pzoulql6w object_1, and a46zhwykn6jvbabk object_0 To perform u64y1a9apusmslxb action, the following facts need to be true: tv30k33pzoulql6w object_0, af9tse231jclsqad object_0, and cq14062p1yeke3ok Once u64y1a9apusmslxb is performed the following facts will be true: a46zhwykn6jvbabk object_0 Once u64y1a9apusmslxb is performed the following facts will be false: tv30k33pzoulql6w object_0, af9tse231jclsqad object_0, and cq14062p1yeke3ok To perform kip9uw781pv62umn action, the following facts need to be true:a46zhwykn6jvbabk object_0 Once kip9uw781pv62umn is performed the following facts will be true: tv30k33pzoulql6w object_0, cq14062p1yeke3ok, and af9tse231jclsqad object_0 Once kip9uw781pv62umn is performed the following facts will be false: a46zhwykn6jvbabk object_0 To perform wio5amhq7814n006 action, the following facts need to be true: b6e9q4r60gagvdcn object_0 object_1, tv30k33pzoulql6w object_0, and cq14062p1yeke3ok Once wio5amhq7814n006 is performed the following facts will be true: a46zhwykn6jvbabk object_0, and tv30k33pzoulql6w object_1 Once wio5amhq7814n006 is performed the following facts will be false: b6e9q4r60gagvdcn object_0 object_1, tv30k33pzoulql6w object_0, and cq14062p1yeke3ok [STATEMENT] As initial conditions I have that, af9tse231jclsqad object_0, af9tse23ljclsqad object_2, af9tse231jclsqad object_3, b6e9q4r60gagvdcn object_1 object_2, cq14062p1yeke3ok, tv30k33pzoulql6w object_0, tv30k33pzoulq16w object_1 and tv30k33pzoulql6w object_3. My goal is to have that b6e9q4r60gagvdcn object_2 object_1. What is the plan to achieve my goal? Just give the actions in the plan. =========o1-preview RESPONSE========== == To achieve the goal 'b6e9q4r60gagvdcn object_2 object_1', you need to perform the following sequence of actions: 1. **wio5amhq7814n006 object_1 object_2** This action reverses the relationship between 'object_1' and 'object_2', setting up the necessary conditions for the next steps. 2. **kip9uw781pv62umn object_1** By performing this action on 'object_1', you restore certain facts ('cq14062p1yeke3ok') required for subsequent actions and adjust the state of 'object_1'. 3. **u64y1a9apusmslxb object_2** This action modifies 'object_2' to have the required property 'a46zhwykn6jvbabk object_2', which is a precondition for the final action. 4. **j4gv801gnu2it0yj object_2 object_1** Performing this action with 'object_2' and 'object_1' establishes the goal fact b6e9q4r60gagvdcn object_2 object_1'. **Plan Summary:** **Action 1:** \u2018wio5amhq7814n006 object_1 object_2' **Action 2:** 'kip9uw781pv62umn object_1' **Action 3:** 'u64y1a9apusmslxb object_2' **Action 4:** 'j4gv801gnu2it0yj object_2 object_1' This sequence of actions satisfies all the necessary preconditions step-by-step and ultimately achieves your goal. F.2 Unsolvable Randomized Mystery Blocksworld Instances - Zero-Shot in PDDL The following is a PDDL specification of a planning problem. The first part, under the heading [ DOMAIN], is the domain file. The second part, under the heading [QUERY PROBLEM], is the problem file. Using this information, which is correct, and no further assumptions, find a plan which, when run from the specified initial state, satisfies the specified goal. Provide your answer as a sequence of actions in PDDL format. An action ACTION which acts on two objects OBJ1 and OBJ2 would be written (ACTION OBJ1 OBJ2). Do not provide anything else in your answer. [DOMAIN] (define (domain xaji0y) ) (:requirements : equality) (:predicates (tv30k33pzoulql6w ?x1 object) (af9tse231jclsqad ?x1 object) (cq14062p1yeke3ok ) (a46zhwykn6jvbabk ?x1 object) (b6e9q4r60gagvdcn ?x1 object ?x2 object) ) (:action u64y1a9apusmslxb : parameters (?ob1 object) :precondition (and (tv30k33pzoulql6w ?ob1) (af9tse23ljclsqad ?ob1) (cql4o62p1yeke3ok )) : effect (and (a46zhwykn6jvbabk ?ob1) (not (tv30k33pzoulql6w ?ob1)) (not (af9tse231jclsqad ?ob1)) (not (cq14062p1yeke3ok ))) ) (:action kip9uw781pv62umn : parameters (?ob1 object) : precondition (a46zhwykn6jvbabk ? ob1) : effect (and (tv30k33pzoulql6w ?ob1) (cq14062p1yeke3ok ) (af9tse231jclsqad ?ob1) (not (a46zhwykn6jvbabk ?ob1))) (:action j4gv801gnu2it0yj : parameters (?ob1 object ?ob2 object) :precondition (and (tv30k33pzoulq16w ?ob2) (a46zhwykn6jvbabk ?ob1)) : effect (and (cq14062p1yeke3ok ) (tv30k33pzoulql6w ?ob1) (b6e9q4r60gagvdcn ?ob1 ?ob2) (not (tv30k33pzoulql6w ?ob2)) (not (a46zhwykn6jvbabk ?ob1))) (:action wio5amhq7814n006 :parameters (?ob1 object ?ob2 object) :precondition (and (b6e9q4r60gagvdcn ?ob1 ?ob2) (tv30k33pzoulql6w?ob1) (cq14062p1yeke3ok )) : effect (and (a46zhwykn6jvbabk ?ob1) (tv30k33pzoulql6w ?ob2) (not (b6e9q4r60gagvdcn ?ob1 ?ob2)) (not (tv30k33pzoulql6w ?ob1)) (not (cq14062p1yeke3ok ))) ) ) [QUERY PROBLEM] (define(problem instance-1-4) (:domain xaji0y) (:objects abcd) (:init (cq14062p1yeke3ok) (b6e9q4r60gagvdcn a d) (af9tse231jclsqad b) (b6e9q4r60gagvdcn c a) (b6e9q4r60gagvdcn d b) (tv30k33pzoulql6w c) ) (:goal (and (b6e9q4r60gagvdcn a d) (b6e9q4r60gagvdcn b a) (b6e9q4r60gagvdcn bd) ) ) ) ) [PLAN] ============o1-preview RESPONSE========== ==== There is no sequence of actions that, when run from the specified initial state, satisfies the specified goal. Thus, no plan can be provided."}]}