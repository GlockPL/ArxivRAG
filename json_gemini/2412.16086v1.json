{"title": "Towards Interpretable Radiology Report Generation via Concept Bottlenecks using a Multi-Agentic RAG", "authors": ["Hasan Md Tusfiqur Alam", "Devansh Srivastav", "Md Abdul Kadir", "Daniel Sonntag"], "abstract": "Deep learning has advanced medical image classification, but interpretability challenges hinder its clinical adoption. This study enhances interpretability in Chest X-ray (CXR) classification by using concept bottleneck models (CBMs) and a multi-agent Retrieval-Augmented Generation (RAG) system for report generation. By modeling relationships between visual features and clinical concepts, we create interpretable concept vectors that guide a multi-agent RAG system to generate radiology reports, enhancing clinical relevance, explainability, and transparency. Evaluation of the generated reports using an LLM-as-a-judge confirmed the interpretability and clinical utility of our model's outputs. On the COVID-QU dataset, our model achieved 81% classification accuracy and demonstrated robust report generation performance, with five key metrics ranging between 84% and 90%. This interpretable multi-agent framework bridges the gap between high-performance AI and the explainability required for reliable AI-driven CXR analysis in clinical settings.", "sections": [{"title": "Introduction and Related Work", "content": "Deep learning has significantly improved diagnostic accuracy in medical imaging, especially in chest X-ray (CXR) analysis for conditions such as pneumonia, lung cancer, and tuberculosis [31,16]. However, these models often function as \"black boxes\", limiting interpretability and clinician trust in critical fields like radiology [12]. Traditional CXR classification methods lack transparency, providing little insight into model predictions. Although automated radiology report generation could streamline diagnostics and improve reporting consistency [18], it remains challenging to interpret and validate, which hinders its adoption in clinical settings that demand explainability [15]."}, {"title": "Methodology", "content": "Our approach leverages concept bottleneck models (CBM) [19], medical image embeddings and multi-agent RAG [20] to ensure robustness and interpretability in medical image classification and report generation as shown in Fig. 1, in two stages. First, disease classification with associated concept contributions (sec. 2.1). Second, robust report generation using relevant clinical documents and descriptors from stage 1 (sec. 2.2)."}, {"title": "Interpretable Classification using Concept Bottleneck", "content": "Following the [25] we adopt CBMs with automatic concept discovery for CXR classification. We use GPT-4 [1] to query a set of $N = 20$ medical descriptors (concepts) for each disease category following prompt questionnaires described in [37]. These concepts are aggregated into a concept set $C = \\{C_1, C_2,\\dots,C_N\\}$ for each disease category. To extract image embeddings, we utilize the ChexAgent model [9], a multimodal vision language model (VLM) tuned explicitly for CXR interpretation. ChexAgent outputs image embeddings $V \\in R^{H\\times D}$, where $H$ is the image height, and $D$ is the embedding dimension. Large language models have demonstrated effectiveness in encoding clinical knowledge [30]. For each concept $c_i$, a text embedding $t_i \\in R^D$ is generated using the Mistral Embed Model [17]. This model is chosen for its efficiency and accuracy in embedding textual data into a high-dimensional vector space, suitable for subsequent similarity computations.\nGiven an image embedding $V$ and a set of concept embeddings $t_i$, we com-puted a similarity matrix $M_{i,j} \\in R^{H\\times N}$ using cosine similarity, where $i$ indexes over the image embedding pixels, and $j$ indexes over the concept embeddings. To reduce the dimensionality and focus on the most salient features, max pooling is applied to each similarity matrix $M_{i,j}$. This results in a singular value $s_i = max(M_i)$ for each concept, forming a concept vector $e = (s_1, s_2,\\dots, s_N)$. After that, the concept vector $e$ is normalized to a scale between 0 and 1 to maintain interpretability. A fully connected layer $W_F \\in R^{M_c\\times N}$ is then applied to classify the images into $M_c$ categories. The classification logits are computed as $z_i = W_F.e_i$, where $z_i$ is the logit vector for the $i$-th image. Log-softmax is applied to the logits to obtain the log probabilities. The model is trained using categorical cross-entropy loss [4]. During inference steps, the model then provides the predicted class and associated concepts and their contributions, which are explicitly used the report generation step."}, {"title": "Robust Explanation-based Radiology Report Generation", "content": "We collected clinical documentation for each disease category from the National Institutes of Health (NIH). \u03a4o facilitate efficient retrieval and analysis, embeddings for each document $d_i$ were generated using the OpenAI embedding model [5], yielding vectors $v_i \\in R^n$ such that $v_i = f_{embed}(d_i)$, where $f_{embed}$ is the embedding function. These embeddings were stored in Qdrant vector database $Q = \\{v_i | i = 1,2,..., N\\}$, with $N$ as the number of documents. The multi-agent framework for Retrieval-Augmented Generation (RAG) includes specialized agents for each disease category, each implemented as a Reasoning and Acting (ReAct) agent [38]. For a classified disease category $M_c$, the corresponding ReAct agent $A_c$ is activated to retrieve relevant document embeddings $D_c$ from $Q$, based on similarity to an input query $q$: $D_c = \\{e_j | sim(v_j, q) \\ge \\tau\\}$, where $sim()$ is a similarity function and $ \\tau $ a relevance threshold.\nAlongside the ReAct agents, the framework incorporates a Radiologist Agent $A_R$ and a Medical Writer Agent $A_W$. The Radiologist Agent $A_R$ uses the activated ReAct agent $A_c$ as a tool to retrieve relevant clinical information from $D_c$ and, based on identified concepts $c_k$ from earlier stages, calculates an influence score $s_k = influence(c_k, D_C)$ for each concept, where $influence(\\cdot)$ assesses relevance and diagnostic significance. These scores are assembled into a summary vector $s = (s_1,s_2,...,s_m)$, with m as the number of relevant concepts. The Medical Writer Agent $A_W$ receives this vector s and composes a report by applying a generation function $f_{gen}$, resulting in $report = f_{gen}(s)$. The final output $y$ for a query $q$ in category $C$ can be represented as $y = A_W(A_R(A_C(q, Q)))$, where each agent sequentially processes and enhances the information to generate a detailed radiology report. This framework was implemented using CrewAI and facilitated by LlamaIndex, ensuring efficient retrieval and high-quality report generation."}, {"title": "Results and Discussion", "content": "We evaluate the performance of both the interpretable classification using CBM and the report generation module on the COVID-QU Dataset [10], compiled by Qatar University, comprising 33,920 CXR images across three classes: COVID-19 (11,956 images), Pneumonia (11,263 images), and Normal (10,701 images). We compare the classification results with two types of baselines: visual encoders: CLIP [26], Bio-VIL [2], and two other methods that are trained on CBMs: Label-free CBM[25] and Robust CBM [37]. As shown in Table 1, Our classification model attains an accuracy of 81% on the Covid-QU dataset. To further evaluate the interpretability and robustness of the concept contribution, we explored concept intervention techniques to correct the predictive output of the model [29,32]. In Fig. 2b, we observe that correcting 3-4 concepts for misclassified test samples based on decreasing order in contribution scores yields a significant increase in performance. In Fig. 2a, the model performance on the test set is evaluated while removing the concept contributions in descending (Max Contribution), ascending (Min Contribution), and Randomly. The sharp decline in performance in the case of Max Contribution validates that the models indeed learn to predict from the concept contributions. The x-axis for Fig. 2a is in log-scale for better interpretation.\nTo evaluate the effectiveness of our report generation process using the multi-agentic approach, we generate medical reports for all three classes: Pneumonia, COVID-19, and Normal. We compare the report generated with the same generated using GPT-4 and single-agent RAG, where one single agent is responsible for retrieving and generating reports from relevant documents. Each report is transformed into high-dimensional embeddings using the Mistral Embed Model, capturing the latent features. We apply t-distributed Stochastic Neighbor Embedding (t-SNE) [24] to reduce the dimensionality for visualization and analysis. To quantify how well the reports are clustered for different diseases, we compute Silhouette Score [28], Davies-Bouldin Index, [11], Calinski-Harabasz Index [6], and Dunn Index [14]. The clustering evaluation metrics in Table 2 offer insights into the quality of clustering for the different approaches. While the Single Agent method achieves the highest Silhouette Score (0.41), lowest Davies-Bouldin Index (0.96), and highest Calinski-Harabasz Index (93.99), indicating the tightest and most distinct clusters, it sacrifices clinical interpretability. In contrast, the Multi-Agent approach has slightly lower metrics, such as a Silhouette Score of 0.27 and a Davies-Bouldin Index of 1.44, yet this method reflects the clinical reality more accurately. Specifically, the COVID-19 and Pneumonia clusters show some proximity in the Multi-Agent approach, as shown in the t-SNE plot in Fig. 3, which is medically justified due to the biological overlap between these conditions. Additionally, the Normal cluster remains well-separated, confirming the model's ability to differentiate fundamentally different health states. Thus, the Multi-Agent approach, despite lower numerical scores, better captures the nuances required for effective medical report generation.\nTo further evaluate the generated reports, we employed LLM as a Judge [40] approach, where five different LLMs Llama 3.1 [13], Mistral [17], Gemma2 [34], LLaVA [23], and GPT-3.5 Turbo [5], were used to assess the reports for Semantic Similarity, Accuracy, Correctness, Clinical Usefulness, and Consistency against a ground-truth reference generated by Dragonfly-Med [8], a multimodal biomedical visual-language model by Together AI, fine-tuned from Llama 3 that achieved state-of-the-art performance on several benchmarks. Table 3 shows that using a multi-agent approach in report generation significantly enhances performance across all metrics compared to single-agent methods. For example, models like Mistral 7B exhibit notable improvements when employing the multi-agent approach, with Correctness increasing from 0.85 (Single Agent) to 0.95 (Multi-Agent) and Clinical Usefulness from 0.92 to 0.96. For further qualitative analysis, we use the Mixture of Agents (MoA) [35] approach. For our evaluation, Llama3.1 [13] and Mistral [17] act as proposer agents, while Medllama2 serves as the aggregator agent. The qualitative feedback from this process is used to perform a binary classification using GPT4-0, determining whether the generated report is clinically valid. As shown in the table below, the MoA method achieves scores of 0.81 with GPT-4, 0.82 with the Single Agent approach, and 0.85 with the Multi-Agent approach. The incremental improvement in scores from 0.81 to 0.85-indicates that leveraging multiple agents enhances the quality and clinical validity of the generated reports, which aligns with the findings of [21]."}, {"title": "Conclusion and Future Work", "content": "This paper introduces an interpretable framework that integrates CBMs with a multi-agent RAG system for CXR classification and report generation. By capturing relationships between visual features and clinical concepts, our model provides competitive performance and clinically relevant explanations. The multi-agent RAG system enhances report quality and relevance, validated through evaluations by LLMs. This work bridges high-performing AI with the interpretability essential for clinical use, promising reliable AI-driven chest X-ray analysis. Future efforts will be to validate this approach to other imaging modalities and further refine the multi-agent system for adaptability and robustness."}]}