{"title": "Autonomous Negotiation Using Comparison-Based Gradient Estimation", "authors": ["Surya Murthy", "Mustafa O. Karabag", "Ufuk Topcu"], "abstract": "Negotiation is useful for resolving conflicts in multi-agent systems. We explore autonomous negotiation in a setting where two self-interested rational agents sequentially trade items from a finite set of categories. Each agent has a utility function that depends on the amount of items it possesses in each category. The offering agent makes trade offers to improve its utility without knowing the responding agent's utility function, and the responding agent accepts offers that improve its utility. We present a comparison-based algorithm for the offering agent that generates offers through previous acceptance or rejection responses without extensive information sharing. The algorithm estimates the responding agent's gradient by leveraging the rationality assumption and rejected offers to prune the space of potential gradients. After the algorithm makes a finite number of consecutively rejected offers, the responding agent is at a near-optimal state, or the agents' preferences are closely aligned. Additionally, we facilitate negotiations with humans by representing natural language feedback as comparisons that can be integrated into the proposed algorithm. We compare the proposed algorithm against random search baselines in integer and fractional trading scenarios and show that it improves the societal benefit with fewer offers.", "sections": [{"title": "Introduction", "content": "Negotiation can resolve conflicts in multi-agent environments and enable agents to reach agreements without a centralized controller by exchanging offers. We develop an autonomous negotiation algorithm, sequential trading with cone refinements (ST-CR), for multi-agent environments.\nWe consider a variant of the multi-issue bargaining problem (Inderst, 2000) where two self-interested rational agents sequentially trade items from a finite set of categories. Each agent has a state defined by the current amount of items it possesses in each category. Each agent has a utility function that depends on its current state and the function is not necessarily separable with respect to the item categories. The offering agent presents a trade offer to improve its utility function, and the responding agent accepts offers that improve its utility function."}, {"title": "Related Works", "content": "We review works on negotiation algorithms and comparison-based optimization as we use comparisons to find trades.\nAutonomous Negotiation Algorithms. Negotiation algorithms often require information sharing between agents to facilitate trades. The shared information can include utility values (De Vries and Vohra, 2003; Conen and Sandholm, 2001; Maruo and Kashima, 2024) or counteroffers from the responding agent (Faratin, Sierra, and Jennings, 1998, 2002), (Coehoorn and Jennings, 2004), (Zhang, Ren, and Zhang, 2015), (Montazeri, Kebriaei, and Araabi, 2020). In scenarios with more than two negotiating agents, mediator-based methods agents must disclose information to a central authority (Hattori, Klein, and Ito, 2007; Klein et al., 2003). However, these information-sharing paradigms may not be feasible due to privacy concerns or computational limitations. For example, in settings such as Dutch auctions, agents respond to the offers only with acceptance or rejection (Thomas, 2012). The proposed sequential trading with cone refinements (ST-CR) algorithm treats acceptance or rejection responses as comparisons to find mutually beneficial trades, eliminating the need for extensive information sharing.\nNegotiation algorithms employ different techniques to utilize obtained information. For instance, numerical valuation methods typically involve creating a utility model for each agent based on the valuations of item bundles (De Vries and Vohra, 2003; Conen and Sandholm, 2001; Maruo and Kashima, 2024). Counteroffer-based approaches, e.g. Faratin, Sierra, and Jennings (1998), use similarity criteria to present offers that closely match counteroffers from the opposing party. Other counteroffer approaches use reinforcement learning (Montazeri, Kebriaei, and Araabi, 2020) or Bayesian predictors (Zhang, Ren, and Zhang, 2015) to learn the responding agent's negotiation strategy or preferences. Mediator-based methods, e.g. Klein et al. (2003), aggregate preferences through a central mediator, which employs optimization algorithms to propose trades. In contrast, ST-CR estimates the responding agent's utility gradient from rejected offers By determining the responding agent's ascent direction, ST-CR identifies mutually beneficial trades without exhaustively searching the space of offers.\nComparison-Based Optimization. Instead of directly accessing an objective function or its gradients, comparison-based optimization algorithms rely on comparisons between points (Nelder and Mead, 1965; Jamieson, Nowak, and Recht, 2012). These techniques are particularly useful in scenarios where the objective function is unknown or difficult to measure. An example is negotiation settings where the utility function of the responding agent is not accessible. In such cases, responses to offers can be represented as comparisons between two points defined by the trade amounts, facilitating optimization without direct function access.\nComparison-based optimization techniques use strategic comparisons to estimate gradients or find optimal solutions without direct access to the objective function. The Nelder-Mead method compares values at the vertices of a simplex to converge toward an optimal point (Nelder and Mead, 1965). Jamieson, Nowak, and Recht (2012) use a comparison-based line search with coordinate descent to systematically search the space of potential solutions. Cheng et al.'s (2020) Sign-OPT aggregates randomly sampled comparison directions for gradient estimation. Zhang and Li's (2024) Comparison-GDE uses a cutting-plane approach for gradient estimation. Karabag, Neary, and Topcu (2021) refine a cone of possible gradient directions using halfspace cuts informed by comparisons. While these methods are effective for single-objective optimization, we consider a multi-objective setting where arbitrary comparisons may not benefit the offering agent.\nSimilar to Karabag, Neary, and Topcu (2021), we use comparisons to cut the gradient cones and enclose the remaining directions using a cone with a smaller semi-vertical angle. Karabag, Neary, and Topcu (2021) use three-point comparisons to obtain the halfspace cuts. However, in the considered setting, the rationality assumption for the offering agent does not allow three point comparisons. Instead, we use two-point comparisons, which may lead to erroneous halfspace cuts. We derive a new cone angle update rule to provably enclose all possible gradient directions, even with erroneous cuts."}, {"title": "Preliminaries and Notation", "content": "The L2-norm of a vector v is ||v||. A function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ is $\\beta$-smooth if $| f (y)-f(x)-(\u2207f(x), y-x)| \\leq \\beta||x-y||^2/2$ for all $x, y \\in \\mathbb{R}^n$. The directional derivative of f along vector v is $\\nabla_v f(x) = (\u2207f(x), v)/||v||$. The angle between $v_1$ and $v_2$ is\n$\\angle(v_1,v_2) = \\cos^{-1}(\\frac{\\langle v_1,v_2 \\rangle}{||v_1|| ||v_2||})$. A cone with direction $\\tau$ and semi-vertical angle $\\theta$ is $C(\\tau, \\theta) = {x \\in \\mathbb{R}^n|\\angle(x, \\tau) \\leq \\theta}$.\nSequential Multi-Issue Bargaining Problem\nWe consider a negotiation setting that is a variant of the multi-issue bargaining problem (Inderst, 2000) where an offering A and responding agent B make sequential trades with items belonging to n categories. Each agent's state is defined by the (non-negative) number of items they possess in each category. The offering and responding agents' states are $S_A$ and $S_B$, respectively. For example, consider a bargaining problem with apples and oranges as categories. An example agent state is $(x_1,x_2) = (1,2)$ where $x_1$ and $x_2$ are the number of apples and oranges, respectively, in the agent's possession. The offering and responding agents have smooth utility functions $f^A(S_A)$ and $f^B(S_B)$ respectively, which reflect their valuations of different states. We note that each individual utility function is not necessarily separable with respect to the item categories. In the fruit example, a person who wants a single serving of apple-orange juice and likes apples more than oranges, may have the utility function $(x_1-2x_2)^2 + (x_1-2)^2 + (x_2 - 1)^2$ whose optimal point is (2, 1). The offering agent A presents trade offers to improve its utility function, while the responding agent B responds to the offers according to its utility function. The offering agent knows the states of both agents and its own utility function, but does not know the responding agent's utility function.\nThe agents aim to maximize their utility functions by trading with each other. A trade offer $T = (t_1, t_2,..., t_n)$ is a set of changes in the number of items in each category where $t_i$ is the increase in item i for the offering agent. An offer is feasible if it results in no negative quantities of any item for either agent in the post-trade state. The offering agent has an offer budget m, which is the maximum number of (accepted or rejected) offers it is can to make to the responding agent. When determining whether to propose or accept an offer, the agents consider the benefit associated with the offer. At states $S_A$ and $S_B$, the benefits of an offer T are $f_A(S_A + T) - f_A(S_A)$ and $f_B(S_B - T) - f_B (S_B)$ for the offering and responding agents, respectively. The societal benefit is the sum of the benefits for both agents. An offer is mutually beneficial if $f_A(S_A + T) - f_A(S_A) \\geq 0$ and $f_B(S_B - T) - f_B(S_B) \\geq 0$. We assume that the agents are rational. Consequently, the offering agent will only make an offer T if $f_A(S_A + T) - f_A(S_A) \\geq 0$, and the responding agent will only accept an offer if $f_B (S_B - T) - f_B (S_B) \\geq 0$. Formally, the responding agent's response function is\n$R_B(T) = \\begin{cases} accept & \\text{if } f_B (S_B - T) - f_B (S_B) \\geq 0, \\\\ reject & \\text{if } f_B (S_B - T) - f_B (S_B) < 0. \\end{cases}$\nDepending on the responding agent's response to the offer T, the agents transition to next states $S'_A$ and $S'_B$ where\n$S'_A, S'_B = \\begin{cases} S_A+T, S_B-T & \\text{if } R_B(T) = accept, \\\\ S_A, S_B & \\text{if } R_B(T) = reject. \\end{cases}$\nA joint state $(S_A, S_B)$is Pareto-optimal if there is no feasible and mutually beneficial offer, i.e., for all feasible offers T, $f_A(S^*+T)-f_A(S^*_A) < 0$ or $f_B(S^*_B-T) - f_B(S^*_B) < 0$.\nProblem definition. Consider a multi-issue bargaining problem with two rational agents. The offering agent knows the initial states $S_A$ and $S_B$, as well as its own utility function $f_A (S_A)$, but does not know the responding agent's utility function $f_B(S_B)$ or its offer budget m. The goal is to maximize societal benefit after m trade offers."}, {"title": "Sequential Trading with Cone Refinement", "content": "We propose Sequential Trading with Cone Refinements (ST-CR), an autonomous negotiation algorithm to find a Pareto-optimal point through sequential trades. Mutually beneficial trades are offers lying in the intersection of the ascent directions of agents' utility functions. To find these directions, we infer the potential gradients of the responding agent with a cone based on rejected offers. By the rationality assumption, each rejected offer provides information on the responding agent's gradient, resulting in a more accurate estimate.\nPreliminaries on Gradient Direction Estimation. Given the sign of the directional derivatives in curated directions, one can approximate the direction of the responding agent's gradient to find an ascent direction. Building on this observation, Karabag, Neary, and Topcu (2021) model the set of potential gradients as a cone. The signs of directional derivatives inferred from comparisons in orthogonal directions are then used as halfspace constraints to refine the cone. The cone model allows the remaining potential gradients after orthogonal halfspace refinements to be easily enclosed by a new cone. Similarly, ST-CR maintains a cone $C(\\tau, \\theta)$ of gradients with direction $\\tau\\in \\mathbb{R}^n$ and semi-vertical angle $\\theta$.\nTo refine the cone of potential gradients, ST-CR utilizes the signs of the directional derivatives. By making a linear approximation of each agent's utility function at the states $S_A$ and $S_B$, we use a first-order Taylor approximation to describe beneficial trades in terms of each agent's utility gradient:\n$f_A(S_A + T) - f_A(S_a) \\approx \\langle T,\\nabla f^A(S_A) \\rangle \\geq 0$,\n$f_B (S_B \u2013 T) - f_B(S_B) \\approx \\langle -T,\\nabla f^B (S_B) \\rangle \\geq 0$.\nBy the rationality assumption, the responding agent will reject an offer if $\\langle -T,\\nabla f^B(S_B) \\rangle < 0$, implying that $\\nabla^T f^B (S_B) > 0$. Therefore, the agent's responses provide information on the sign of directional derivatives, which ST-CR uses to refine the potential gradient cone."}, {"title": "Procedure 2: Cone Refinement (CR)", "content": "Karabag, Neary, and Topcu (2021) accurately determine the signs of directional derivatives or identify inconclusive directions by making comparisons at three points on a line. In our setting, making three-point comparisons corresponds to making two opposite offers. This guarantees that at least one of the offers will not benefit the offering agent, violating the rationality assumption for the offering agent. Hence, we use two-point comparisons to estimate signs of directional derivatives. Two-point comparisons can lead to sign errors, consequently affecting the cone refinement. As we later show in Theorem 1, we account for such errors by increasing the cone's semi-vertical angle to enclose all potential gradients.\nWe now overview ST-CR's two-stage approach. The first stage (Algorithm 1 Lines 3\u20136), uses heuristic offers to quickly improve societal benefit. The second stage (Algorithm 1, Line 8 Procedure 2) uses rejected offers to refine the potential gradient cone. Once an offer is accepted, ST-CR transitions to the next state (Algorithm 1 Lines 5 and 11).\nStage 1: Heuristic Offers (Algorithm 1, Lines 3 - 6). When making consecutive trades, information from previous negotiations can inform new offers. For example, ST-CR begins each new negotiation by proposing the previously accepted offer. If the responding agent has a smooth utility function, its gradient does not change significantly after accepting an offer, making previously accepted offers likely to be accepted again. We later show in numerical experiments that this heuristic improves ST-CR's performance. As per the rationality assumption, this offer is only presented if it is beneficial to the offering agent. If the responding agent rejects the offers presented in this stage, we move to stage 2.\nStage 2: Gradient Refinement (Procedure 2). We use rejected offers to refine the space of potential gradients and identify a mutually beneficial offer. If no such offer is found after refinement, the gradients of both agents are closely aligned, indicating a near Pareto-optimal point. To refine the space of potential gradients, we represent the potential gradients as an n-dimensional cone, $C(\\tau, \\theta)$.\nStage 2.1: Initializing the Cone of Potential Gradients (Procedure 2 Lines 15 - 25). When negotiation begins, the offering agent does not know the responding agent's utility function $f^B$ and, consequently, has no information on $\\nabla f^B (S_B)$. We first determine the n-dimensional quadrant of $\\nabla f^B (S_B)$ by checking if the responding agent wants more or less of each item category: ST-CR makes n offers $T_1 = (\\pm d, 0, . . ., 0), . . ., T_n = (0,0,...,\\pm d)$ where d is a constant. ST-CR adjusts the signs of the offers such that $\\langle T, \\nabla f^A(S_A) \\rangle \\geq 0$ to improve the offering agent's utility. To accurately refine the cone using Taylor approximation and avoid overshooting along mutually beneficial trades, we limit the magnitude of offers by d. If the responding agent accepts any of the offers, ST-CR proceeds to the next state and repeats from stage 1 (Line 20). If the responding agent rejects all of the offers, the direction of the quadrant is inferred as $Q[i] = T_i[i]$ (Line 22). The quadrant is enclosed by a cone with direction $\\tau = Q$ and semi-vertical angle $\\theta = \\pi/2$ (Line 25). Instead of performing this stage, one can also expand the cone from the previous trade to account for gradient changes and, as a heuristic, use the expanded cone for initialization.\nStage 2.2: Determining Mutually Beneficial Offers (Procedure 2 Lines 32 - 34). Given n categories and the cone direction $\\tau$, we generate n 1 offers $T_1,..., T_{n-1}$ that are orthogonal to each other and $\\tau$ (Line 34). By the rationality assumption, each offer satisfies $\\langle T, \\nabla f^a(S_A) \\rangle \\geq 0$. If the responding agent accepts an offer, a state transition occurs (Algorithm 1 Line 12), and ST-CR repeats from stage 1. After n 1 consecutively rejected offers in stage 2.2, the space of potential gradients reduces to the intersection of the gradient cone and hafspaces generated by the rejected offers. In stage 2.3, we enclose this space with a smaller cone.\nStage 2.3: Updating the Cone of Potential Gradients (Procedure 2 Lines 28 - 31). If the responding agent rejects n-1 offers, we refine the cone using the rejected offers. Using the first-order approximation and the rationality assumption, each rejected offer $T \\in {T_1, \u2026 \u2026 \u2026, T_{n-1}} = (V \\setminus \\tau)$ indicates that $\\langle -T, \\nabla f^B (S_B) \\rangle < 0$. Each of the n 1 offers is treated as a halfspace constraint $\\langle T, x \\rangle > 0$. ST-CR then calculates a new cone $C(\\tau', \\theta')$ enclosing the remaining gradient directions ${x|\\langle T, x \\rangle \\geq 0} \\cap C(\\tau, \\theta)$. "}, {"title": "Numerical Experiments", "content": "We test ST-CR using randomized scenarios. Implementation details are given in the appendix, and the code can be found at https://github.com/suryakmurthy/Auto_Negotiation_Cmfp@ctionalScenario. We consider quadratic utility functions such that\n$f^A(S_A) = S_A^T \\frac{(pQ_A + Q_B)}{p+1} S_A + 2S_A^T \\frac{(pu_A + u_B)}{p+1}$\n$f^B (S_B) = S_B^T \\frac{(Q_A + pQ_B)}{p+1} S_B + 2S_B^T \\frac{(u_A + pu_B)}{p+1}$\nwhere $Q_A$ and $Q_B$ are random negative semi-definite matrices, $u_A$ and $u_B$ are random vectors, and $p\\in [1,\\infty)$ is a mixing constant. Each random matrix is generated by creating a $n \\times n$ matrix with entries uniformly distributed between 0 and 1, and then multiplying this matrix by its negative transpose. $u_A$ and $u_B$ are generated by sampling integers uniformly between 1 and 200. Values of p closer to 1 correspond to high alignment between the utility gradients, while values farther from 1 indicate low alignment. Each agent's state is initialized by uniformly sampling integers between 1 and 200 for each item category. We limit the offers to trade at most 5 items from each category (d = $5\\sqrt{n}$). The testing includes integer scenarios and fractional scenarios. If any of the trading algorithms reach a state where one agent possesses all items in a category, we remove the category from consideration and continue with the remaining categories.\nBaselines. We implement two baseline algorithms to compare with ST-CR. The first baseline is a random search that uniformly samples offer directions, then scales offers so that ||T|| \u2264 d. To enhance the random search, we include a heuristic that starts by offering the most recently accepted trade. The second baseline is a random search with momentum. For the first trade, the offering agent uses the random search baseline. In subsequent trades, the agent makes the previously accepted offer with uniformly sampled deviations, with the magnitude of deviations increasing as more offers are rejected. For all baselines, the offering agent only presents offers that improve its utility. Psudocodes for both baselines are presented in the appendix.\nResults. In Fig. 5, we present the cumulative societal benefit (averaged across 1000 randomly sampled scenarios) achieved by each algorithm as a function of the number of offers. The benefit is normalized by the maximum cumulative benefit across all algorithms. In Figs. 5a - 5d, we present plots for integer and fractional scenarios with 3 and 5 item categories. We observe that ST-CR consistently achieves a higher societal benefit with fewer offers compared to the baselines. As the number of item categories increase, the performance gap between ST-CR and the baselines increases for a fixed number of offers, indicating the suitability of ST-CR for complex trading scenarios with limited offer budgets.\nFigs. 5a-5d show that algorithms using the previously accepted trade heuristic achieve the highest benefit with the fewest offers. Since the agents' utility functions are smooth and offers have bounded magnitudes, previously accepted trades are likely to be accepted again. As a result, the heuristic can increase benefit with fewer offers. As trading progresses and agents approach optimal points, the chances of prior trades being accepted decrease due to overshooting, reducing the efficiency of algorithms with prior trade heuristics.\nFigs. 5e-5f show the effects of gradient alignment in @ctional trading scenarios. To ensure alignment between the agents' utility gradients and conduct a consistent comparison, the each agent's state is initialized with 100 items in each category. For highly aligned gradients (p = 1.1), all of the algorithms require more offers to increase societal benefit compared to less aligned gradients (p = 5). In scenarios with highly aligned gradients, the space for mutually beneficial offers is smaller, limiting all algorithms' performance."}, {"title": "Conclusion", "content": "We consider a two-agent sequential negotiation setting with minimal information sharing. We introduced ST-CR, an autonomous negotiation algorithm that leverages comparisons to identify mutually beneficial trades. We demonstrated ST-CR's effectiveness in two-agent negotiations and provided theoretical guarantees on finding beneficial trades, or certifying closeness to optimality. ST-CR relies on the rationality of agents, which may not hold in some scenarios. Future work could explore modifications to handle non-rational or deceptive agents, further expanding ST-CR's applicability."}, {"title": "Acknowledgments", "content": "This work was supported partially by the Army Research Laboratory (ARL), under grant number W911NF-23-1-0317, and partially by the National Science Foundation (NSF), under grant numbers 1836900 and 2211432."}, {"title": "Integer-Constrained Cone Update", "content": "// Initialize quadrant using the same approach as non-integer constrained algorithm\n// If semi-vertical angle is smaller, update the cone\n||x1-x2||\nelse\n4r2-2-(1+||Cclose||\u00b2)-2-(1+||cfar||2)\n\u2192COS ||r\u221a(1+||Cclose||\u00b2)\u221a(1+||cfar||\u00b2}\n\u2713"}, {"title": "Numerical Experiment Baseline Psudocode", "content": "// Deviation scaling factor\n\u2192min (ddev+dinterval"}, {"title": "ST-CR Adjustments for Numerical Experiments", "content": "We make several adjustments when implementing ST-CR in fractional and integer scenarios. We detail the modifications we made to ST-CR for our numerical experiments.\nCone Initialization in Sequential Trading When making sequential trades, ST-CR can bypass stage 2.1 by using the previous cone to initialize the cone for the next trade. Since we assume that the responding agent's utility function is smooth and the offers have a bounded magnitude, the change in responding agent's gradient direction is bounded. Given a cone C(\u03c4, 0) from the previously accepted trade T, we initialize a new cone C(\u03c4', \u03b8') where\n$\\tau' = \\tau, \\theta' = \\theta + b||T||$\nwhere b is a constant corresponding to the increase in the cone's angle. Note that, as the smoothness constant \u03b2, decreases b can be set lower. For example, in scenarios with linear utility functions, b = 0 is sufficient to enclose all possible gradient directions after a trade. We scale the increment by ||T|| since larger trades can lead to a larger change in gradient direction. If \u03b8' > \u03c0/2, the cone has exceeded the size of the initial cone from stage 2.1. In such cases, we repeat stage 2.1 to narrow the cone to a single quadrant.\nEnsuring Beneficial Trades As we discussed in prior sections, ST-CR selects offer directions that align with the offering agent's gradient direction ensuring that $\\langle T, \\nabla f^A(S_A) \\rangle \\geq 0$. For non-linear utility functions, this method can lead to non-beneficial trades for the offering agent if $|\\nabla f_f(S_a)||$ is small, overshooting the optimal trade in the direction of T. In our implementation, we resolve this issue by reducing the offer magnitude to prevent overshooting. In integer-constrained cases, offers cannot include fractions of items and reducing the offer magnitude may not prevent overshooting. In these cases, the ST-CR reduces the offer magnitude as much as possible and accepts a bounded loss of benefit.\nImproving Self-Interested Behavior ST-CR uses n 1 rejected orthogonal offers to refine the gradient cone. If an offer is accepted, the agents transition to a new state. When making the n 1 offers, the offering agent prioritizes offers that are most beneficial to itself, ensuring that accepted offers will have a larger benefit for the offering agent.\nCone Update in Integer-Constrained Trading As we have established, a risk of two-point comparisons is potentially making incorrect halfspace cuts. This is also a risk in integer-constrained trading scenarios. In the worst case, incorrect cuts can lead to an empty polyhedron of potential gradients, where the halfspace constraints of the current cone and the rejected offers do not have any overlapping region. In such cases, we increase the current cone's angle until the polyhedron becomes non-empty. By increasing the cone's angle of opening, we enclose the full space of potential gradients.\nGenerating new Trades in Integer-Constrained Trading As we stated in the integer-constrained trading section, the non-orthogonal or off-center halfspace cuts caused by integer-constrained offers can result in ST-CR needing more than n 1 offers to update the gradient cone. In such cases, we use the halfspace that bisects the farthest corner points of the polyhedron of potential gradients as a basis for the next offer. However, these offers must also abide by the integer constraints, and may change direction when rounding occurs. In the worst case, the rounded offer will no longer bisect the farthest corner points, and will not result in a reduction of the space of potential gradients. If the rounded offer will not reduce the gradient space, ST-CR increases the offer's magnitude d before rounding. By increasing d, the difference between the original offer and the rounded offer becomes smaller. This can conflict with the feasibility of the offers if the offering or responding agents do not have the items to meet the scaled up offers. If ST-CR cannot find feasible integer trades that can refine the cone, it stops trading.\nReproducibility of Numerical Experiments\nAll of the code for our numerical experiments are provided at: https://github.com/suryakmurthy/Auto_Negotiation_Cmpr. Our numerical experiments were conducted on Python version 3.9.7. We provide Python package requirements in the require-ments.txt file. The repository contains the file run_algo_tests.py, which will run all of the tests we discussed in the numerical experiments section. The results presented in the paper were obtained on a Dell XPS 13 laptop with a 11th Gen Intel(R) Core(TM) i7-1185G7 @ 3.00GHz processor and 16.0 GB of RAM. To ensure reproducibility, we used a random seed of 10 when generating our results. Our numerical experiments also limited the offers to trade at most 5 items from each category (max_trade_value = 5) and set ST-CR's angle threshold 0* to 0.00001 (theta_closeness = 0.00001). For the random trading with momentum baseline, we set the interval of deviation increase to dinterval = 0.05 (deviation_interval = 0.05) and the maximum deviation magnitude to dmax = 5 (max_deviation_magnitude = 5). Using this random seed and hyperparameters will reproduce the presented results. We provide python and package versions in the repository's requirements.txt file.\nWe also provide the file gpt_integration_test.py for running negotiations with humans using GPT. We provide full transcripts of our GPT examples in chat_folders/paper We note that, since the output of GPT models change with each run, we can not exactly reproduce our examples. Finally, we note that, when running the GPT tests, users will need to provide their own OpenAI API keys."}, {"title": "Integrating ST-CR and Language Models", "content": "In addition to negotiation between ST-CR and autonomous agents, we consider integer negotiation scenarios between ST-CR and a human negotiator. In these example scenarios, ST-CR and the human trade apples, bananas, and oranges. ST-CR acts as the offering agent A and the human is the responding agent B. The state of each agent is [x1,x2, x3] where x1 is the number of apples, x2 is the number of bananas, and x3 is the number of oranges. Instead of having an explicit utility function, the human negotiator begins each scenario by inputting a target state us it would like to reach through trading. In order to show the non-trivial sections of ST-CR, we use the target state to initialize the the responding agent's gradient quadrant. Therefore, we assume that stage 2.1 of ST-CR is already performed and begin negotiation from stage 2.2. ST-CR is also given a target state UA that is generated generated by sampling integers uniformly between 1 and 100. Using these two states, the utility functions for both agents are $f_A (S_A) = -S_A^TIS_A + 2S_A^TUI_A$ and $f_B (S_B) = -S_B^TIS_B + 2S_B^TUI_B$ where I is the n \u00d7 n identity matrix. The human negotiator is not required to follow this utility function. However, approximating it enables the testing program to estimate the human's benefit following a trade. When making offers ST-CR uses the format\nUsing a standardized format for offers allows the language model to easily interpret the human's response.\nWe utilize language models to perform sentiment analysis on human responses to determine if a human is accepting or rejecting an offer. To do this, we first replace the identifiers in the previous offer with two named individuals to allow the language model to easily interpret who is receiving what items. In our code, we replace \"User\" with \"Alice\" and \"ST-CR\" agent with \"Bob\". We then provide the language model with the previous offer and the human's response, then give it the prompt\nUsing the language model's response to this prompt, we determine if the human is accepting or rejecting the offer.\nBeyond acceptance or rejection, humans can provide additional information to ST-CR through counteroffers, adjustments to prior offers, or general preferences. If sentiment analysis determines that the human user is not accepting the trade offer, we prompt the language model to determine if the user is providing any additional information\nAdjustments to prior offers are readily represented as counteroffers, so we use the same logic to handle both cases. If the language model believes that the human user is providing a counteroffer, we give GPT the following prompt\nUsing this approach, we obtain a counteroffer in a standardized form, which is readily integrated into ST-CR.\nIf the language model believes that the human is providing a general preference, we utilize the GPT-4.0 function calling feature to get a linear relationship of the form $\\langle w_1, v \\rangle \\geq \\langle w_2, v \\rangle$ where $w_1$ and $w_2$ represent states and v is the vector of values for each category. For example, a response \"I prefer 2 apples over 3 oranges and a banana\" can be represented as $\\langle[2,0,0], [3, 1, 1] \\rangle \\geq \\langle[0, 1, 3], [3, 1, 1]\\rangle$. A response \"I prefer apples over oranges\" can be represented as $\\langle[1,0,0], [2, 1,0] \\rangle \\geq \\langle[0, 1, 0], [2, 1, 0]\\rangle$. A response \"I don't want oranges\" can be represented as $\\langle[0, -1,0], [1, -1, 1] \\rangle \\geq \\langle[0,0,0], [1, -1, 1]\\rangle$. We use $w_1$ and $w_2$ as comparison states in ST-CR and do not use the values v generated by GPT. This linear relationship can be represented as a counteroffer that increases the items in $w_1$ and decreases the items in $w_2$. For example, $\\langle[0, -1, 0], [1, -1, 1] \\rangle \\geq \\langle[0, 0, 0], [1, -1, 1]\\rangle$ can be represented as:"}]}