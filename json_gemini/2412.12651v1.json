{"title": "Shared Attention-based Autoencoder with Hierarchical Fusion-based Graph Convolution Network for SEEG SOZ Identification", "authors": ["Huachao Yan", "Kailing Guo", "Shiwei Song", "Yihai Dai", "Xiaoqiang Wei", "Xiaofen Xing", "Xiangmin Xu"], "abstract": "Diagnosing seizure onset zone (SOZ) is a challenge in neurosurgery, where stereoelectroencephalography (sEEG) serves as a critical technique. In SEEG SOZ identification, the existing studies focus solely on the intra-patient representation of epileptic information, overlooking the general features of epilepsy across patients and feature interdependencies between feature elements in each contact site. In order to address the aforementioned challenges, we propose the shared attention-based autoencoder (SATAE). SATAE is trained by sEEG data across all patients, with attention blocks introduced to enhance the representation of interdependencies between feature elements. Considering the spatial diversity of SEEG across patients, we introduce graph-based method for identification SOZ of each patient. However, the current graph-based methods for SEEG SOZ identification rely exclusively on static graphs to model epileptic networks. Inspired by the finding of neuroscience that epileptic network is intricately characterized by the interplay of sophisticated equilibrium between fluctuating and stable states, we design the hierarchical fusion-based graph convolution network (HFGCN) to identify the SOZ. HFGCN integrates the dynamic and static characteristics of epileptic networks", "sections": [{"title": "I. INTRODUCTION", "content": "ACCORDING to data from the World Health Organization (WHO), the number of people with refractory epilepsy with drug resistance approaching 50 million in the world [1], with an annual increase of approximately 2.5 million cases a year [2]. Among patients with epilepsy, 40-50% are diagnosed with temporal lobe epilepsy. Epilepsy can be regarded as abnormal electrical discharges originating from a specific region within the brain, known as the seizure onset zone (SOZ).\nEEG (Electroencephalography) has achieved great success in the fields of brain-computer interfaces [3] and brain disease diagnosis [4]. In the process of diagnosing the SOZ, two types of EEG are crucial: surface EEG and stereoEEG (sEEG). Surface EEG is commonly employed for the initial screening and continuous monitoring of epilepsy patients, due to its convenient use and non-invasive characteristics [5]. However, surface EEG can only record the overall brain activity expressed on the cortical surface, making it difficult to localize SOZ in deeper brain regions. sEEG is an invasive EEG that enables the recording of neural activity from specific deep brain regions with high precision. Consequently, sEEG has become a key technique for localizing SOZ [6]. sEEG is obtained by implanting multiple high-density electrodes, each equipped with numerous evenly distributed contact sites, to capture electrical activity at various spatial locations within the brain. In recent years, many studies have conducted statistical analyses of sEEG across different states and found that the characteristics of sEEG vary significantly among various"}, {"title": "II. RELATED WORKS", "content": "behavioral states, such as sleep [7], wakefulness [8], and seizures [9]. Additionally, sEEG with high-density electrodes also enables measuring brain connectivity through the cortical-cortical evoked potential (CCEP), which is obtained by stimulating a specific brain region electrically with contact sites on a high-density electrode. The resulting evoked responses recorded at other contact sites, distant from the stimulation site, provide information revealing the synaptic connectivity between the stimulated and recording regions [10], [11].\nTypically, commonly used preprocessing for sEEG involves decomposing the signal of each contact site into six frequency bands (\u03b4 (1-4 Hz), \u03b8 (4-8 Hz), \u03b1 (8-15 Hz), \u03b2 (15-30 Hz), low \u03b3 (30-80 Hz), and high gamma \u03b3 (80-150 Hz)) [12] and then calculate features such as power spectra [7] and root mean square (RMS) values [13] from each frequency band. With the development of deep learning, the work [14] further extracts highly representative latent features from handcrafted feature using autoencoder. The advantage of using an autoencoder lies in its ability to capture complex patterns within a large amount of data [15], [16]. However, existing study [14] on sEEG-related autoencoder training strategy has potential for enhancement, as they predominantly focus on training separate autoencoders by using a small amount of data from each patient. This training strategy fails to capture the general patterns of epileptic neural activity across all patients, resulting in insufficient method generalization [17]. In addition, relying solely on autoencoders for feature extraction leads to inadequate representation quality [18], as it overlooks distinct interdependencies between feature elements for epileptic information representation.\nTo address the above issue, this paper designs a shared attention-based autoencoder (sATAE). We leverage sEEG data from all patients to train a single sATAE, enhancing the method's generalizability in representing epileptic information. Furthermore, we propose the pooling-based attention block and incorporate it into the encoder of sATAE, capturing the different importance of feature elements for epileptic information and thereby improving the quality of feature representation.\nMany studies designed deep learning methods to classify the obtained sEEG features, achieving considerable results. Among the deep learning methods for SEEG SOZ identification, convolution neural networks (CNN) and graph neural networks (GNN) have received much attention for their effectiveness. Some studies [19], [20], [21] employ convolution operation on each sEEG contact site for SOZ identification. However, the findings of neuroscience have shown that spatial collaboration exists between different brain regions [22], [23], and CNN-based methods overlook the spatial relationships between contact sites. In addition, contact sites are located in different brain regions, exhibiting varying connectivities and connection strengths, demonstrating unstructured relationships. Graph-based methods are able to cope with unstructured data directly and hold promise in describing the intrinsic spatial relationships between different nodes in the graph. For SEEG SOZ identification, many studies focus on employing static relationships to construct the adjacency matrix within the epileptic network from different aspects, e.g., correlations [24] and distance [25], achieving considerable results. However, the methods proposed in above mentioned studies lack sufficient representational capacity for SEEG SOZ identification.\nIn graph-based studies, many methods have been proposed from different perspectives to enhance representational ability, including node sampling, edge dropping, and skip connection. Node sampling [26], [27] methods design sampling strategies based on different properties to select a subset of nodes from the original graph and aggregate nodes within the resulting subgraph, which can be viewed as dropping nodes to improve method performance. To preserve node features, edge dropping [28], [29] methods are proposed, which remove a percentage of edges according to some specific strategies. Dominik et al. [30] introduce the edge dropping to proposed GCN for EEG-based Alzheimer's recognition. However, applying node sampling or edge dropping to graph-based SEEG SOZ identification will lose the interpretability of brain connectivity. Motivated by CNN, some studies [31], [32] introduce the different types of skip connections into graph methods, which effectively enhance representational ability while preserving interpretability. Gao et al. [33] integrate the skip connection and uncertainty learning into GCN to learn uncertainty connectivity of brain network for EEG emotion recognition. Yang et al. [34] further consider the varying importance of different EEG channels and incorporate skip connections and channel weighting to enhance EEG-based emotion recognition. However, the aforementioned studies use regular skip connections, which primarily focus on integrating information from a singular perspective. Neuroscience reveals that the brain network is intricately characterized by the interplay of both dynamic and static perspectives, reflecting a sophisticated equilibrium between fluctuating and stable states [35]. Neuronal populations in the brain also exhibit dynamic fluctuations in neural synchronization, which are also evident in the propagation of epilepsy [36], [37]. Nonetheless, the regular skip connections lacking the capability to integrate information interactions across different hierarchical levels between these two perspectives and raise the issue of insufficient representational ability for sEEG SOZ identification.\nTo tackle the above issues, this paper proposes a hierarchical fusion-based graph convolution network (HFGCN) and employ it on each patient for sEEG SOZ identification. HFGCN leverages both dynamic and static convolutions to mode; the intricate coexistence patterns of dynamic and static components within epileptic network. Specifically, static convolution is employed to learn high-order topological representations from the stable information of the brain network. The outputs from each static convolution layer are then fed into dynamic graph convolution layers to capture the dynamic characteristics of the epileptic network. Subsequently, we integrate the results from both static and dynamic convolutions to generate corresponding weights, and use these weights to fuse the integrated output from the subsequent layers. HFGCN effectively captures the varying importance of spatial features across different hierarchies from static and dynamic epileptic networks and comprehensively enriches node information to improve SOZ identification performance."}, {"title": "A. AutoEncoder", "content": "Basically, an autoencoder is composed of an encoder and a decoder [38]. Both the encoder and decoder have the same structure which includes multiple fully connected layers. Early studies [15] primarily focus on the autoencoder's ability to unsupervisedly compress features effectively, learning efficient representations by compressing high-dimensional data into a latent space and reconstructing the original input. With the development of training strategies, increasing studies [39] has highlighted the autoencoder's ability to learn common patterns from large amounts of data by extracting general features across different samples [15], [16]. Benefiting from the autoencoder's capabilities mentioned above, the autoencoder has achieved great success in image segmentation [40] and biomedical signal process [41].\nIn SEEG SOZ identification, the current study also uses autoencoder to perform feature processing. Dou et al. [14] employ an autoencoder to learn low-dimensional latent representations from sEEG data across three behavioral states for each patient. However, this study trains a separate autoencoder for each patient, limiting its ability to extract general epileptic information across individuals. Furthermore, relying exclusively on autoencoders for feature extraction results in inadequate feature quality, as this method overlooks interdependencies between feature elements of each contact site for SEEG SOZ identification."}, {"title": "B. CNN Learning Method and Its Application for Epileptic SEEG Analysis", "content": "CNN have been widely used in various fields such as signal processing [42] and computer vision [43] due to their ability to learn highly representative features from raw data. In image-based tasks, 2D CNN is typically employed to capture spatial features between pixels from images. Distinctly, in the field of signal processing, most studies commonly apply 1D CNN to extract temporal features along a single time axis in time-series data. Specifically, in biomedical signal analysis, CNN have shown great potential in extracting meaningful patterns from complex signals such as EEG [4], electrocardiogram (ECG) [44] and electromyography (EMG) [45].\nMost studies employ convolution operation on single contact sites to extract epileptic information from the time and frequency domain. Wang et al. [20] employ 1D CNN to extract epileptic information from different waveforms of sEEG in the time domain (spikes, ripples, and fast ripples) for SEEG SOZ identification. Graham et al. [19] consider the characteristics of sEEG at different time scales in the time domain, and employ the ResNet 1D convolution with different kernel sizes for detection of sEEG epileptic activity. Xiao et al. [21] transform the sEEG signal into a spectrogram image and employ the 2D CNN to detect epileptic activity from the time-frequency domain. Wang et al. [46] further consider spatial relationships among sEEG channels and employ a combination of 1D and 2D CNN to capture both temporal information within sEEG and spatial information across SEEG for enhanced epileptic seizure prediction. Although CNN-based methods can effectively extract internal features from different domains of sEEG contact sites, neuroscience findings [47] suggest that brain regions exhibit nonlinear spatial cooperative relationships, CNN-based methods overlook this spatial characteristic."}, {"title": "C. Graph Learning Method and Its Application for Epileptic sEEG Analysis", "content": "GNN have demonstrated promising performance in managing data with spatial relationships, as seen in applications such as social network analysis [40] and traffic forecasting [48]. With high spatial resolution and numerous recording sites, SEEG captures intricate spatial connectivity patterns, which GNN is well-suited to model and analyze effectively. In epileptic sEEG analysis, GNN can reveal the intrinsic topological relationship among sEEG contact sites, where constructing the adjacency matrix is a crucial part of the GNN. Existing studies rely on static relationships from different aspects to build adjacency matrix, e.g., correlation [24] and distance [25]. Concretely, Liu et al. [24] employ the maximum cross-correlation coefficient to define the adjacency matrix of GNN. Dou et al. [14] employ the results of paired t-test to construct spatial relationships between sEEG contact sites. Daniele et al. [25] further consider the phase relation among SEEG and utilize the phase-locking value (PLV) to construct the adjacency matrices.\nHowever, neuroscience finds that dynamic fluctuations in neural networks are also present in the propagation of epilepsy, reflecting the evolving nature of neural interactions [35], [49]. However, the methods in the above studies lack sufficient representational capacity for epileptic information."}, {"title": "III. METHODS", "content": "During intracranial monitoring, sEEG data are recorded at a sampling rate of 10,000 Hz and filtered using a 50 Hz notch filter along with a 0\u2013800 Hz lowpass filter to eliminate powerline interference and reduce noise. We employ sEEG data collected from two conditions: one from three different behavioral states and the other under electrical stimulation (CCEP data).\n1) Preprocessing of SEEG Data from Three Behavioral States: Different behavioral states inherently encompass different degrees of epileptic information [7], [8], [9]. To preserve the richness of epileptic information, we record the sEEG data from three behavioral states: onset, sleep and awake. The SEEG data is downsampled to 1000 Hz and then decomposed into six frequency bands (8 band: 1-4 Hz, 0 band: 4-8 Hz, a band: 8-14 Hz, \u1e9e band: 14-30 Hz, low \u03b3 band: 30-80 Hz, and high \u03b3 band: 80-150 Hz). We further calculate the power spectra of each frequency band by utilizing a Morlet wavelet transform with a mother wavelet of six cycles. The absolute value of the wavelet transformation is employed as the power feature.\n2) Prepocessing of sEEG Data under Electrical Stimulation: SEEG data under electrical stimulation, that is CCEP data, describes stable neural pathways by recording the electrical response in the brain when one cortical area is stimulated and the resulting activity is observed in another, the synaptically"}, {"title": "B. Construction of SATAE-HFGCN", "content": "In this section, we will introduce the proposed method, including the construction of sATAE, graph and HFGCN.\n1) Attention-based Autoencoder: In order to capture the general epileptic characteristics of all patients and enhance the quality of feature representation for epileptic information from contact sites, we propose a shared attention-based autoencoder (SATAE), whose framework is illustrated in Figure 1(B). Given that I represents the dimension of the input feature, the sEEG feature from a contact site can be expressed as $x \\in \\mathbb{R}^{1 \\times I}$. The encoder transforms x into latent representation 1 by employing two attention blocks and five fully connected layers. The attention block connects the input and output of every two fully connected layers. The two fully connected layers can be expressed as:\n$h_1 = \\sigma(xW_1 + b_1),$\n(1)\n$h_2 = \\sigma(h_1W_2 + b_2),$\n(2)\nwhere $ \\sigma(\\cdot)$ is the Tanh activation function, $W_s$ and $b_s$ are transformation matrix and bias in s-th fully connected layer (s \u2208 [1,2]), respectively. Simultaneously, input x also fed to attention block to generate attention coefficient. The output then multiplies with $h_2$ using Hadamard multiplication to capture interdependencies between feature elements:\n$hout_1 = \\sigma(Avgpool(x)W + b) \\bigodot h_2,$\n(3)\nwhere $W$ and $b$ is the learnable matrix and bias in the pooling path, respectively. Avgpool(\u00b7) is average pooling operation and $ \\bigodot $ denotes Hadamard multiplication. Next, $hout_1$ is employed to conduct next weighting calculation (see Figure 1(B)) to obtain $hout_2$, and the obtained output is then fed to a fully connected layer to obtain the latent representation $l \\in \\mathbb{R}^{1\\times N}$, where N is the length of the latent feature. Subsequently, the decoder transforms 1 to the output $y \\in \\mathbb{R}^{1 \\times L}$ by five fully connected layers. For simplification, one of the fully connected layers in the decoder can be expressed as:\n$h_t^d = \\sigma(h_{t-1}^dW_t^d + b_t^d),$\n(4)\nwhere $W_t^d$ and $b_t^d$ are the transformation matrix and bias of t-th fully connected layer in decoder ({t \u2208Z|1<t< 5}), respectively. We train a SATAE across all patients and minimize the mean squared error (MSE) loss between x and y, the MSE loss function is expressed as:\n$L_{MSE}(x, y) = \\frac{1}{2} ||x - y||_2^2.$\n(5)\n2) Construction of Graph: In this part, we employ the latent feature from the previous part to construct the graph and provide a detailed explanation. For each patient, the spatial positions of implanted high-density electrodes are different, resulting in different connectivity patterns. Therefore, we construct a graph corresponding to each patient. The latent features of all sEEG contact sites from a patient are used as node features in a graph, denoted by $X \\in \\mathbb{R}^{C \\times N}$, where C is the number of contact sites. The CCEP data corresponding to a patient, $\\{S_{ccep}^q \\in \\mathbb{R}^{C \\times T} | q \\in [1,Q]\\}$, are utilized to construct the connectivity relationships, where each $S_{ccep}^q$ represents a segment of CCEP data, Q is the number of CCEP stimulations a patient received, T denotes the duration of each CCEP stimulation. Concretely, the graph-structure data can be denoted as $G = (V, A)$, where $V = {v_1, v_2, . . .,v_C}$ denotes the set of nodes. $v_i$ corresponds to the transposed features of i-th row of X. Next, the CCEP data is utilized to build an adjacency matrix $A \\in \\mathbb{R}^{C \\times C}$ for G. In order to evaluate stable and effective connections between the stimulation and the remaining sites, statistical properties of CCEP data are employed to build connection relationships. Paired t-test is able to preserve the genuine effects of electrical stimulation on neural activity while simultaneously filtering out random noise and incidental variations. Next, we employ the paired t-test to evaluate the significant difference between the baseline $S_{baseline}$ and CCEP data $S_{ccep}$. We select 60-second stationary interictal SEEG data to establish the baseline, where interictal SEEG refers to the time period between two seizures for a patient, recording the normal and stable activities of the brain. The interictal data is divided into ten subsegments, and the baseline $S_{baseline} \\in \\mathbb{R}^{C\\times T}$ is obtained by averaging these subsegments. Subsequently, the false discovery rate (FDR) is applied to amend the significant difference p-value for multiple comparisons and amended p-value vector denoted as $p^a = [p_1^a, p_2^a, \u2026, p_C^a]^T$. We retain contact sites that exhibit significant differences ($p_i^a < 0.05, i \\in [1,C]$) and obtain corresponding masks $p^m = [p_1^m, p_2^m,\u2026\u2026, p_C^m]^T$, where:\n$p_i^m=\\begin{cases}\n1,& \\text{if } p_i^a < 0.05, \\\\\n0,& \\text{otherwise,}\n\\end{cases}$\n(6)\nSubsequently, the masked CCEP data is obtained by $S_{ccep}^m = p^m S_{ccep}$. It is typically believed that the relationship between two variables is stronger when they exhibit a high correlation, providing information about the correlation among variables. The Pearson correlation coefficient (PCC) is a commonly used method for constructing the adjacency matrix but may result in noisy connections simultaneously. Therefore, we modify the PPC method by setting a threshold to filter out noise connections. The mathematical definition of PCC is given as follows:\n$\\rho_{i,j} = \\frac{cov(v_i^{m-ccep}, v_j^{m-ccep})}{\\sigma_{v_i^{m-ccep}} \\sigma_{v_j^{m-ccep}}},$\n(7)\nwhere $cov(v_i^{m-ccep}, v_j^{m-ccep})$ is covariance between $v_i^{m-ccep}$ and $v_j^{m-ccep}$, and $\\sigma_{v_i^{m-ccep}}$ and $\\sigma_{v_j^{m-ccep}}$ are the corresponding standard deviations. Therefore, the element in the i-th row and j-th column of Aq is defined as follows:\n$a_{i,j} = \\begin{cases}\n\\rho_{i,j},& \\text{if } \\rho_{i,j} < \\rho_{\\tau}, \\\\\n0,& \\text{otherwise.}\n\\end{cases}$\n(8)\nwhere $ \\rho_{\\tau}$ is correlation threshold. Then, we obtain $\\{A_q \\in \\mathbb{R}^{C \\times C} | q \\in [1, Q]\\}$, where each Aq represents an adjacency matrix corresponding to a CCEP data $S_{ccep}^q$. Finally, the adjacency matrix A is obtained by averaging all Aq.\n3) Construction of Hierarchical Fusion-based Graph Convolutional Network: The propose of HFGCN is to fuse the static and dynamic characteristics of the epileptic network hierarchically. In HFGCN, static and dynamic graph convolutions are utilized to represent the static and dynamic aspects of epileptic network, respectively, while information from both dynamic and static networks is further fused through hierarchical weighting. For static graph convolution, we use the Chebyshev convolution form. Given the adjacency matrix A of a graph G, the normalized Laplacian matrix can be expressed as $L = I_n - D^{-\\frac{1}{2}}AD^{-\\frac{1}{2}}$, where $I_n \\in \\mathbb{R}^{C \\times C}$ is an identity matrix and $D \\in \\mathbb{R}^{C \\times C}$ is degree matrix. L is defined as $L = \\frac{2L}{\\lambda_{max}} \u2013 I_n$, in which $\\lambda_{max}$ denotes the largest eigenvalue of Laplace matrix L. Let $\\hat{H}^{l-1}$ to be the input of l-th Chebyshev graph convolution layer (where the input of the first layer is X) and F is the order of Chebyshev polynomials [51] in each layer, the corresponding output $\\hat{H}^{l} \\in \\mathbb{R}^{C \\times D}$ is given by:\n$\\hat{H}^l = \\sigma( \\sum_{f=0}^{F-1} T_f(\\tilde{L}) \\hat{H}^{l-1}W_f ),$\n(9)\nwhere Wf denotes a learnable transformation matrix and $T_f( \\tilde{L})$ is the Chebyshev polynomial of order f evaluated at the scaled Laplacian $ \\tilde{L}$. Here $T_f(x)$ is computed by the stable recurrence relation $T_f(x) = 2xT_{f-1}(x) \u2013 T_{f-2}(x)$, where $T^0 = 1$ and $T^1 = x$. For simplification, we use F(,) to denote graph convolution operation and $\\hat{H}^{l}$ can be represented by:\n$\\hat{H}^l = F(\\hat{H}^{l-1}, W),$\n(10)\nBased on insights from neuroscience, the epileptic network is characterized by a complex interaction between dynamic and static components [35], [49]. Relying exclusively on static convolution neglects the dynamic characteristics inherent within the epileptic network. Therefore, we incorporate dynamic graph convolution to effectively capture and supplement the dynamic information within the epileptic network. Edge convolution (EdgeConv) [52] is an adaptive dynamic convolution method based on node distances, which can account for the dynamic process of neural synchronization in epilepsy. Thus, we employ EdgeConv to capture the dynamic characteristic. The output of each Chebyshev graph convolution is taken as input of EdgeConv. For $\\hat{H}^l$, the i-th row corresponds to the features of i-th node, denoted by $\\{v_i | i \\in [1,C] \\}$. Firstly, the K-Nearest Neighbors (K-NN) is employed to each node in $\\hat{H}^l$. In following, we ignore the superscript of $v^i$ for simplification. For each node $v_i$, the K nearest nodes $\\{v_{knn}^i | k \\in [1,K] \\}$ are selected based on the squared"}, {"content": "Euclidean distance to $v_i$, The node pairs formed with $v_i$ and its k-th nearest neighbor is denoted as $(v_i,v_{knn}^i)$. For each node pair $(v_i,v_{knn}^i)$, a learnable approach is employed to model the connection representation:\n$e_{i,k}^{knn} = \\sigma( \\sigma(concat(v_i,v_{knn}^i) W_1^{knn}) W_2^{knn}),$\n(11)\nwhere concat(,\u00b7) represents concatenation operation, $ \\sigma(\\cdot)$ is ReLU activate function, and $W_1^{knn}, W_2^{knn}$ are transformation matrices. Next, we update the node feature by applying aggregation operation on all connection representations with all connections emanating from i-th node. The updated i-th node feature $v_i$ can be expressed as:\n$v_i = agg_k (e_{i,k}^{knn}),$\n(12)\nwhere agg() represents aggregation function. We apply the maximum aggregation operation and the output from Edge-Conv can be expressed as $H^l$. To integrate information captured by both static and dynamic graph convolutions, the element-wise addition is employed to $\\hat{H}^l$ and $H^l$, and a node-wise L2 norm is followed to generate weighting coefficient $w_{SD}^l$ for the l-th layer:\n$w_{SD}^l = || (\\hat{H}^l + H^l) ||_2,$\n(13)\nSubsequently, the $w_{SD}^l$ is multiplied with the summed output obtained from the next layer of GCN and DGCN to obtain the weighted output $\\hat{H}^{SD}$, which can be expressed as follows:\n$\\hat{H}^{SD} = w_{SD}^l (\\hat{H}^{l+1} + H^{l+1}),$\n(14)\nwhere $H^{l+1}$ and $\\hat{H}^{l+1}$ represent the outputs of the l+1-th layer of GCN and DGCN, respectively. Note that the weighting process described above is not implemented for every layer in HFGCN. The specific structure is illustrated in Figure 2. After L layers of GCN and DGCN learning and L - 1 times of hierarchical weighting, our method fuses representations from both static and dynamic characteristics of brain networks in different hierarchies and obtain the final output of our method, denoted by $\\hat{H}^{out}$. Afterward, $\\hat{H}^{out}$ is fed into a fully connected layer, and the Softmax function is applied to obtain the classification probabilities for each node. Our method is trained by minimizing the cross-entropy loss between the predicted classification results and the true labels."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we conduct comprehensive experiments to evaluate the performance of our method for SEEG SOZ identification."}, {"title": "A. Dataset", "content": "This study was approved by the Ethics Committee of Fujian Medical University Affiliated Union Hospital (Title: The SINO-robot and its vascular rendering visualization imaging technology facilitate sEEG procedures for treating drug-resistant epilepsy; ethics approval number: 2021KY119). The analysis included data from patients with refractory temporal epilepsy who received neurosurgical treatment at Fujian Medical University Affiliated Union Hospital. For each patient, a diagnosis of drug-resistant epilepsy led to a recommendation for surgical intervention. Before surgery, non-invasive evaluations are performed, including the collection of clinical history, magnetic resonance imaging (MRI) and positron emission tomography (PET) scans to assess habitual seizures, and scalp-EEG recordings to capture ictal EEG activity. Subsequently, high-density electrodes implantation surgery is conducted. Each patient underwent over a week of invasive monitoring with implanted depth electrodes. SOZ is preliminarily determined by integrating results from brain MRI/PET, regional metabolism, CCEP stimulation and relevant medical assessments. Subsequently, sEEG-guided radiofrequency thermocoagulation (RFT) to disrupt the preliminarily identified SOZ. After RFT surgery, if the patient remains seizure freedom over a 2-3 year follow-up period, the RFT area is designated as the final effective SOZ label. Our dataset consists of patients who meet the aforementioned medical assessment criteria.\nOur dataset records sEEG of 17 patients with drug-resistant temporal lobe epilepsy. sEEG data is collected by using depth electrodes stereotactically implanted into the patients' temporal structures with the SINO-robot (Sinovation depth electrode,"}, {"title": "B. Implementation Details", "content": "For SATAE, batch size and number of epochs are set to 16 and 30, respectively. Adam optimizer is used for optimization with a learning rate of 0.002. For HFGCN, the correlation threshold $ \\rho_{\\tau}$ is set to 0.3. The number of static and dynamic graph convolution layers is set to 3. The Chebyshev kernel size F in the static graph convolution is set to 3, and Kin the dynamic graph convolution is set to 10. Optimization is performed using the Adam optimizer with a learning rate of 0.005, and the model is trained for 150 epochs. Our model is implemented with PyTorch trained on a Geforce RTX 4090 GPU. SEEG data from a single patient's three behavior states is employed to build node features, and CCEP data is applied to generate the corresponding adjacency matrix. We follow the experimental protocol for node classification task established in benchmark graph datasets [58]. Specifically, for each patient, we utilize 10% of the latent features for training, 20% for validation and the remaining 70% for testing. The results are obtained separately on each patient's testing set. We use averaged Accuracy (ACC), Recall, Precision, and $F_1$ Score and their corresponding standard deviation (STD) across all patients to evaluate the performance. SOZ contact sites are labeled as positive and non-SOZ contact sites are labeled as negative."}, {"title": "C. Performance Comparison of SOZ Classification with Different Methods", "content": "We select two types of methods for performance comparison with our method: traditional machine learning method and deep learning method. Two traditional machine learning methods include K-NN and support vector machine (SVM). Ten deep learning methods are selected from two perspectives: non-spatial learning method and spatial learning method. Two non-spatial learning method include 1D Plain CNN and 1D ResCNN. Eight spatial learning method include two baseline methods (GCN and graph attention network (GAT)), two node sampling methods (GraphSAGE, FastGCN), two edge dropping methods (ResGCN+DropEdge and ClusterGCN) and two skip connection methods (ResGCN and JK-Net).\nFor each patient, the latent features from the six frequency bands across the three behavioral states are concatenated to form the feature of each contact site. We compare the performance of our method with all selected methods and show the results in Table I. By incorporating the use of SATAE and HFGCN, our method achieves the best performance across all four metrics (ACC 80.46%, Recall 67.31%, Precision 66.04%, $F_1$ score 66.88%), surpassing the second best method by 3.13% in ACC, 2.65% in Recall, 2.99% in Precision, and 2.98% in $F_1$ Score. We consistently find that deep learning methods are superior to traditional machine learning methods, which means that the features learned by deep learning methods provide better representational capability for SEEG SOZ identification. Additionally, within deep learning methods, graph-based methods perform better than CNN-based methods, suggesting that graph-based methods are more effective in leveraging spatial information for SEEG SOZ identification."}, {"title": "D. Performance Comparison of SOZ Classification across Different Frequency Bands", "content": "Different frequency bands of sEEG exhibit distinct characteristics of epileptic information. Therefore, we investigate"}, {"title": "E. Performance Comparison of SOZ Classification with CCEP Data from Different Medial Temporal Lobe Regions", "content": "In the previous parts, we build adjacency matrix A by averaging the connectivity relationships generated by Q times CCEP stimulation in the medial temporal lobe. The medial temporal lobe can be more precisely subdivided into four anatomical structures, including the amygdala (AMY), hippocampus (HIP), olfactory cortex (OC) and parahippocampal gyrus (PHG). Meanwhile, CCEP data and the number of"}, {"title": "F. Performance Comparison of SOZ Classification across Different Behavior States", "content": "According to studies in neuroscience [7], [8], [9], different behavior states contain diverse seizure-related information. Therefore, we conduct the experiment on our method by using SEEG data from different combinations of behavioral states for the sEEG SOZ identification. For the graph corresponding to each patient, the latent features from all frequency band across different combinations of behavioral states are concatenated to form the node feature.\nThe results are listed in Table IV. We observe that the result of sleep and seizure exhibit comparable performance when using a single behavioral state as input. Specifically, the ACC of seizure (76.76%) is slightly lower than that of sleep (76.93%), but both Recall (64.34%), Precision (63.76%) and $F_1$ Score (64.05 %) are marginally higher for seizure compared to sleep (Recall 64.13 %, Precision 63.24%, $F_1$ Score"}, {"title": "G. Ablation Study of sATAE-HFGCN", "content": "In this section", "sATAE-HFGCN": "To analyze the contribution of different modules in the proposed method comprehensively, we sequentially incorporate the proposed modules based on the autoencoder. We show the results in Table V, in which w/ AutoE and w/ SATAE represent autoencoder and attention-based autoencoder, respectively. w/ SATAE+GCN and w/ SATAE+DGCN represent SATAE with GCN and DGCN, respectively.\nCompared to AutoE, w/ sATAE shows better results, indicating that the introduction of the attention block into the autoencoder effectively captures interdependencies between feature elements in contact sites for epileptic information, thereby enhancing the representational capability of sEEG SOZ identification. Comparing w/ SATAE+GCN, w/ SATAE+DGCN and AutoE, w/ SATAE, we can observe a significant improvement in the method performance by introducing graph learning after the pre-trained sATAE. This result demonstrates that graph-based method effectively learn the spatial characteristics of the epileptic network. Compare to the full model, both w/ SATAE+GCN and w/ SATAE+DGCN exhibit poorer performance, implying that comprehensively considering both static and dynamic components of epileptic network can enhance performance for sEEG SOZ idenification.\n2) The Analysis"}]}