{"title": "Debug Smarter, Not Harder: AI Agents for Error Resolution in Computational Notebooks", "authors": ["Konstantin Grotov", "Artem Borzilov", "Maksim Krivobok", "Timofey Bryksin", "Yaroslav Zharov"], "abstract": "Computational notebooks became indispensable tools for research-related development, offering unprecedented interactivity and flexibility in the development process. However, these benefits come at the cost of reproducibility and an increased potential for bugs. With the rise of code-fluent Large Language Models empowered with agentic techniques, smart bug-fixing tools with a high level of autonomy have emerged. However, ose tools are tuned for classical script programming and still struggle with non-linear computational notebooks. In this paper, we present an AI agent designed specifically for error resolution in a computational notebook. We have developed an agentic system capable of exploring a notebook environment by interacting with it-similar to how a user would and integrated the system into the JetBrains service for collaborative data science called Datalore. We evaluate our approach against the pre-existing single-action solution by comparing costs and conducting a user study. Users rate the error resolution capabilities of the agentic system higher but experience difficulties with UI. We share the results of the study and consider them valuable for further improving user-agent collaboration.", "sections": [{"title": "1 Introduction", "content": "Computational notebooks have become a popular medium for development during the last decade, especially for data analysis, machine learning (Perkel, 2018), and creating educational (Barba et al., 2019) or scientific content (Perkel, 2021). One of the main features of computational notebooks is their statefulness-thus the notebook cannot be described only by its cells, but additionally, runtime information is required. The statefulness allows to work iteratively with the runtime in an additive manner and thus to efficiently go through hypotheses (Rule et al., 2018). However, it causes high code entanglement (Ramasamy et al., 2023; Rule et al., 2018) and, therefore, a higher number of errors in the code. As a result, notebooks are struggling with low reproducibility rates. After a re-run, they come to the same results with a 4% probability (Pimentel et al., 2019), and 75% of them could not be executed without exceptions (Pimentel et al., 2021, 2019). The resulting debugging distracts developers from the actual task.\nLarge Language Models (LLMs), such as GPT-4 (OpenAI, 2023), Mixtral (Jiang et al., 2024), or Code Llama (Roziere et al., 2023) recently demonstrated advanced capabilities in solving complex code-related problems, such as code generation (Ni et al., 2023; Wu et al., 2023), debugging (Tian et al., 2024; Bouzenia et al., 2024), and issue solving (Zhang et al., 2024; Yang et al., 2024a). However, there is a lack of studies applying such models to notebooks. The difficulty lies in the stateful nature of the notebook. Since the notebook requires runtime information to represent its exact current state, it is hard to gather the context for an LLM, as passing the entire runtime information is impossible due to the context size limitations.\nAI agents allow LLMs to interact with such an environment iteratively. An agent can explore the environment and achieve the goal autonomously, enabling it to adjust its actions based on the received feedback. Such agents have shown abilities to engage with software engineering tasks (Wang et al., 2024; Tufano et al., 2024; Si et al., 2024; Yang et al., 2024b), interact with web environments (Drouin et al., 2024; Zhou et al., 2023), or operate embodied agents (Wang et al., 2023).\nIn this work, we present an AI Agent for error resolution in computational notebooks. The proposed agent was integrated into Datalore, a JetBrains product for collaborative data science that allows development in cloud-hosted computational notebooks. We design the agent to be capable of creating, editing, and executing cells. This approach utilizes the notebook's natural interactivity"}, {"title": "", "content": "and allows gradual expansion of context.\nThe main contributions of our paper are:\n\u2022 An LLM-based AI Agent integrated into Datalore.\n\u2022 A cost analysis of the proposed agent.\n\u2022 A user study on developers' experience with agentic systems in their workflows.\nIn Section 2, we describe the overall design of our agentic system. After that, in Section 3, we evaluate our agent and discuss the results. Finally, we describe the limitations and conclude our work."}, {"title": "2 System Design", "content": "In this section, we will delve into the proposed system's architecture. The system contains three parts: an agent, an environment, and a user interface. The agent is a stateful back-end service responsible for orchestrating the communication between the LLM and the notebook, storing prompts, and converting LLM predictions into actions in the environment. The environment is the computational notebook that-in addition to being fully functional-is responsible for executing actions provided by the agent and providing corresponding observations. The user interface defines how programmers interact with the system as a whole.\nThe goal of the system was to conduct the necessary code changes and cell executions to solve the given runtime exception."}, {"title": "2.1 AI Agent", "content": "To set up an Al agent, it is necessary to choose an LLM, a memory stack storing the interaction history, a strategy for solving the particular problem, and a set of tools that will be available to the agent for interacting with the environment. The tools we chose are described in the Section 2.2, as the environment provides them. In this subsection, we concentrate on the other parts of the agent.\nAs an LLM for our agent, we chose the GPT-4-0613 foundation model with the ability of function calling. We selected this specific model based on its reliable performance in producing function calls as of April 2024. On each generation step, the LLM is prompted with the history of previous LLM generations, as well as observations from the environment. This constitutes the memory stack."}, {"title": "2.2 Tools and Environment", "content": "During error resolution, the agent collects new observations from the environment using various tools. A tool is an action available for the agent. Then, on the environment side, the particular tool call is processed, and the result is returned for the agent to adapt and continue the strategy loop.\nThe environment in this context is a computational notebook (similar to Jupyter notebooks), which provides an interactive interface for writing and executing code in the cells. The environment supports Python and offers features like inline plotting, markdown support, and the ability to execute shell commands, making it a versatile tool for data analysis and development.\nWe extended the environment with tools to allow the agent to interact with the notebook environment in a manner natural to developers, seamlessly integrating it further into the workflow. The proposed list of tools includes the following: creating, editing, and executing cells. Additionally, the \"Finish\" action was introduced, enabling the agent to stop independently. This action allows the agent to halt its activities before reaching the maximum iteration count. With these tools, the agent can explore the environment even beyond the current notebook state. For example, the agent can execute the !1s code cell to explore files outside the notebook.\nThe environment initiates the agent's workflow by sending the error stack trace with the corresponding cell number and the notebook cells source without outputs. After receiving the response from the agent, the proposed tool is executed and responded to with the cell output as the observation. The schematic diagram of the automatic error-solving workflow is shown in Figure 1. All prompts can be found in Appendix A, and tool descriptions are in the supplementary materials."}, {"title": "2.3 User Interface", "content": "We incorporated the user-agent interaction in the computational notebooks available in Datalore. Once an error occurs in a cell, the additional \"Fix with AI Agent\u201d button appears, which allows one to initiate the error resolution process. After the user clicks on this button, an additional panel appears on the right side of the screen, displaying the chat between the agent and the environment. Every action the agent proposes is displayed in the chat with an additional explanation by the agent of why it chose it. Simultaneously with the changes in the chat, the actions are executed in the notebook environment, and cell outputs are sent back to the agent as observations. The interface of the system is elucidated in Figure 2."}, {"title": "3 Evaluation", "content": "We evaluated our system from two perspectives: system performance and user experience. For the former, we compared the costs of employing such an AI agent and the single-action solution already implemented in Datalore. For the latter, we conducted a user study to estimate the effect on the developers' subjective productivity and satisfaction with error resolution capabilities."}, {"title": "3.1 Cost Analysis", "content": "For cost analysis, we compared our developed AI agent with the single-action solution. A single-action solution has already been implemented in Datalore as an LLM-powered feature for Python exception resolution. It was implemented using a similar user interface but without multiple iterations. The system uses chain-of-thought reasoning (Wei et al., 2022) to identify the cause of the problem and generates the code to resolve the issue in the current code cell. As the input context of the single-action solution, Datalore uses the notebook code and the cell number where the error appeared. We calculated the costs of a single-action solution using real user statistics gathered from Datalore. The data contained the consumption of both request and response tokens after each error resolution.\nFor the evaluation of the AI agent, we used a dataset of fine-grained Jupyter Notebook execution logs. The dataset included over 100 hours of logs, capturing all cell additions, executions, and deletions made when solving data science tasks in a hackathon. A total of 20 people participated in the experiment. The key feature of the dataset is that the developer's workflow in the notebook can be reproduced, which was very useful for our analysis. We utilized the dataset to reproduce the notebook"}, {"title": "3.2 User Study", "content": "To evaluate the effect of our agentic system on the developer workflow, we designed and conducted a user study. During the study, we measured the developers' subjective productivity and assessment of the systems' error resolution capabilities. The study design included two groups of participants: one employing a single-action AI assistant and the other one using the AI Agent. We recruited participants within JetBrains without mentioning the group to which they were referred. As a result, we collected a sample containing 16 people in each of the two groups.\nWe offered both groups a data-filtering task designed to be completed within 30 to 45 minutes in Datalore. The task was to read the unstructured textual data, which had various mistakes that caused errors during pre-processing. The task could be solved using the Pandas Python package and the Python Standard Library. The full task description can be found in Appendix B.1. Participants solved"}, {"title": "4 Conclusion and Future work", "content": "In the present work, we have presented an agentic system for error resolution in computational notebooks. Our solution was integrated into JetBrains Datalore. The cost of running the system tripled, yet the cost stayed within the reasonable price range. The user study revealed many directions for further user-agent interaction research, such as ensuring the user's control over the agent or better visualization of the agent's actions.\nUtilizing smaller and cheaper models and more intelligent information retrieval holds potential for cost-efficient next generations of such systems. The context caching techniques also look promising in iterative agentic applications. To benefit the community, we publish used prompts and the answers from the user study."}, {"title": "5 Limitations", "content": "After the user study, we got many comments on improving the UI. The users mentioned that the agent took too much control of their workflow. While it performed actions with the appropriate reasoning, it was tough to keep track of them due to the speed of the agent's work. While it is a limitation of our system, which will be investigated more carefully, we found the general lesson of keeping the user in control useful for the community. Even though people generally agree to use the system for their own working tasks, we have not developed a secure sandbox. It is crucial to ensure the safety of their data and code while an agent explores the environment.\nAlthough the system showed higher costs than the single-step solution, the agent successfully found the solution in most cases within the first or second steps. Therefore, the agentic approach can be used to determine the valuable context for task-solving purposes, which can subsequently be incorporated into a single-step solution.\nDistinguishing between actual problem resolution and hallucination remains challenging algorithmically. Although the agent demonstrates effective error resolution in most observed cases, a quantitative evaluation of accuracy was not conducted. This presents a potential limitation, as the system may occasionally produce a seemingly correct solution that does not address the root cause of the error. Further research is needed to develop metrics that can automatically assess the correctness and relevance of the agent's solutions."}, {"title": "A Prompts", "content": "A.1 System Prompt\nYou are a coding assistant which should help to\nsolve user's error in computational notebook.\nYou should use functions to help handle the real\ntime user queries and return outputs ONLY in\nthe form of a valid JSON.\nRemember:\n1. Keep trying for at least 10 steps before you\nstop. But if you think you solved the problem\nyou can finish right away.\n2. Use Python code only. When you need to explain\nwhat you did, write it as a comment in the\ncode or in the 'comment' field of the JSON.\n3. If you can fix the error without changing any\ncode, do that. Don't edit the existing code\nor add new code unless you really need to.\n4. Use only the functions given to you. If you\nhave many functions to choose from, pick the\none that solves the problem quickest.\n5. Don't run the cell that caused the error. If\nyou think you've fixed the error, run the\nfinish\" function instead.\n\"\n6. If nothing shows up after you run a cell, that\nmeans there were no errors or outputs.\nAfter you've done actions that you think have fixed\nthe problem, run \"finish\" to say you're done."}, {"title": "A.2 Initial Prompt Template", "content": "Here's a Jupyter notebook. It uses '{separator}' as\na separator between cells. Note that cells\nindexes START FROM 1!\n{notebook}\nError occurred in cell with num {cell_num}.\nThe error trace is the following:\n{error}\nPlease resolve the error.\nYou must use only defined functions for solving the\nerror. Return output only as a valid JSON.\nYOU MUST NOT WRITE ANY COMMENTS / THOUGHTS /\nPLANNING OUTSIDE OF the \"comment\" JSON FIELD!\nAfter you perform actions which should solve the\nerror, use function finish to indicate that.\nIF IT'S POSSIBLE TO SOLVE ERROR WITHOUT CHANGING THE\nCODE YOU MUST DO THAT!\nIF YOU NEED ANY EXTRA INFORMATION GET IT VIA\nEXECUTION OF NEW CELL (CREATE IT, CHANGE SOURCE\nAND EXECUTE)\nIF YOU WANT TO WRITE ANY COMMENT USE \"comment\" FIELD\nIN FUNCTION CALL AND NOWHERE ELSE !\nYOU MUST NOT CHANGE FILES OUTSIDE OF THE NOTEBOOK\nBUT CAN EXPLORE THE ENVIRONMENT VIA EXECUTING\nNOTEBOOK CELLS.\nJust adding try-except is not a solution. Commenting\nthe code that produced error is not the\nsolution. You should propose only meaningful\nfinal solutions.\nWhile exploring you must avoid large outputs, so be\ncareful with prints."}, {"title": "B User Study Artifacts", "content": "B.1 Data Filtering Task\nSeveral services simultaneously launched an AI\nassistant and agreed to jointly collect and analyze\nuser feedback. Despite using the same LLM, the\nintegration of feedback data faced challenges due\nto differences in data formats. Additionally, an\nissue emerged where timestamps were not logged\ncorrectly.\nTo facilitate the analysis, extract the user feed-\nback data from the aggregated_logs.log file lo-\ncated at the project root. This file contains merged\nlogs from all participating services, structured with\ntimestamp data preceding the JSON-formatted log\nentries.\nThe task is to create a DataFrame with the fol-\nlowing structure:\n\u2022 hash: str\n\u2022 service_id: int\n\u2022 time: datetime\n\u2022 is_positive_feedback: bool\nFurther, analyze instances where timestamps are\nincorrectly logged (logged as \u2018unknown' instead\nof the actual date) to identify potential patterns or\nsystematic errors causing this issue. This might\ninvolve reviewing the formatting or encoding dis-\ncrepancies among different service logs.\nPlease note that if you find yourself taking longer\nthan 45 minutes, you should stop solving the task."}, {"title": "B.2 Open Feedback Responses", "content": "Here are the selected answers for the following\nquestion: Please share any comments or sugges-\ntions you have regarding aspects you disliked\nabout the system or areas where you think the\nsystem can be improved.\n\u2022 It's not always obvious which cell was edited\nby agent. like i tried to follow along with\nagent execution in an agent interaction win-\ndow, but the texts fly quite fast, and once it's\nfinished, you have to spend some time pro-\ncessing either the texts or your notebook to\nunderstand what actually happened.\n\u2022 Overall, a problem I had with the AI, includ-\ning the Compose or Code with AI, was that\nit overwrote the content of the entire cell. It\nwould have been useful if I could have some-\nhow specified to only edit within a selection\nto avoid unwanted changes further up in the\ncell. This could of course lead to the error not\nbeing resolved, but it could also serve as a way\nto ground the AI to the target task? Similarly\nto how AI in IDEs does code completion.\n\u2022 Perhaps it would be beneficial to indicate\nmore explicitly, what cell the agent is going\nto execute (in the user interface), and maybe\ncleanup the cells it created to launch its own\ncode (mine created a cell in the end of note-\nbook with \"print(logs[:5])\" or smth like this,\nand it stayed after agent's finish)\n\u2022 It would also be great if there was a separate\nwindow where I could enter my request to the\nagent, not just being able to use it only in case\nof Errors\n\u2022 A very obvious commentary, but it's slow.\nThat's not a problem if you can work while\nit's thinking. The problem with that is that it's\njumpy when everything is changing around\nyou. It seems like there is no \"protection\"\neven for a cell you are now working on.\n\u2022 A lot of time, I felt like I needed help without\nan explicit red error. It just wasn't doing what\nI wanted. I am not sure what UX is needed,\nor how it is possible to communicate desire to\nagents, but that would be very cool."}]}