{"title": "Escaping the Forest: Sparse Interpretable Neural Networks for Tabular Data", "authors": ["Salvatore Raieli", "Abdulrahman Altahhan", "Nathalie Jeanray", "St\u00e9phane Gerart", "Sebastien Vachenc"], "abstract": "Tabular datasets are widely used in scientific disciplines such as biology. While these disciplines have already adopted AI methods to enhance their findings and analysis, they mainly use tree-based methods due to their interpretability. At the same time, artificial neural networks have been shown to offer superior flexibility and depth for rich and complex non-tabular problems, but they are falling behind tree-based models for tabular data in terms of performance and interpretability. Although sparsity has been shown to improve the interpretability and performance of ANN models for complex non-tabular datasets, enforcing sparsity structurally and formatively for tabular data before training the model, remains an open question. To address this question, we establish a method that infuses sparsity in neural networks by utilising attention mechanisms to capture the features' importance in tabular datasets. We show that our models, Sparse TABular NET or sTAB-Net with attention mechanisms, are more effective than tree-based models, reaching the state-of-the-art on biological datasets. They further permit the extraction of insights from these datasets and achieve better performance than post-hoc methods like SHAP.", "sections": [{"title": "Main", "content": "Although tabular data are widespread, they have been left behind by recent advances in artificial intelligence (1). Recent literature suggests that tree-based models (such as Random Forest or XGBoost (2)) outperform neural networks for tabular data (3). Despite this, there remains a strong interest in neural networks in this area (1). Research in artificial intelligence has moved toward foundation models, and a foundation model for tabular data is lacking to date (4).\nThe main challenges for deep learning models for tabular data are competitiveness with tree-based models, extracting meaningful features and dealing with hetero-modals data (heterogenous features). A natural advantage of a neural network model is the ability to perform other tasks, with minimal training, via transfer learning or fine-tuning. In addition, these models should be interpretable and preferentially without the need for post-hoc methods. This is especially true for biomedical tabular data (such as omics data) where interpretability leads to direct applications: new drug targets, biomarkers, clinical decisions, and risk factors (5, 6).\nDespite a consistent interest in neural networks for tabular data, up to date, tree-based models are considered state-of-the-art for medium tabular datasets. Over the years several large models have been proposed without a consistent gain in performance over tree-based models (7). In addition, the lack of a tabular benchmark has made it difficult to compare different methods (3). As shown in (3) while large capacity models are computationally intensive they do not have superior performance. In particular, they showed that there is a large gap in performance between tree-based models and neural networks. Thus leading to the need for high-performing and efficient neural network models.\nInterpretability, on the other hand, is needed in many applications (such as biology, banking and insurance) where algorithm predictions have a direct impact on human quality of life (8). Considering, that also governmental institutions are considering regulations for artificial intelligence applications, interpretability for tabular models is an important not fulfilled need (8).\nAs noted in the lottery ticket hypothesis most of the weight in a neural network could be pruned (9). However, while sparsity is a desirable model attribute, it is hard to achieve before training and consequently post-training methods are used (such as pruning) (10).\nNevertheless, sparse networks have been leveraged for tailored applications with genomics data (11) where the sparsity-introduction process is driven by prior knowledge, but they still lack interpretability. While this is a particular case, this has not been extended to other tabular datasets and prior knowledge does not lend itself to generalisation.\nIn (11) biologically constrained neural network is introduced in the biomedical domain as feed-forward neural networks (FFNN) where sparsity is introduced before the training. To achieve sparsity authors utilised the knowledge contained in an external database to define the model architecture.\n(12) used the database Reactome to define the interconnectivity between the features(genes) by utilising the interactivity and dependency between them. The data can be seen as a matrix of overlapping clusters of data points each with multi-features (called pathways in biology) (Fig. 1A). The interaction of features during the modified linear layer is controlled with a binary matrix. Thus, if there is biological knowledge about the interaction of two features (or belonging to the same cluster) a 1 is assigned in the binary matrix that is multiplied element-wise with the FFNN weight matrix (Fig. 1B).\nThe advantage of this method is that it incorporates domain knowledge in the model, can be adapted to different knowledge sources, and enhances the transparency of the model (11). However, post-hoc explainability methods (such as SHAP) are still required to interpret the model (11). Thus, remains to define interpretation mechanisms that allow identifying the important features. While this approach can be applied to biomedical datasets, a similar sparse net cannot be defined for datasets where external feature knowledge is lacking.\nInspired by the core competencies provided by attention mechanisms, we define a simple but interpretable mechanism for tabular data. We show that sparse-net with attention mechanisms outperform tree-based models for biomedical tabular datasets. Moreover, we show that our attention mechanism is better at identifying the most relevant features in the dataset than post-hoc methods and also supports in-domain and out-of-domain adaptation. Finally, we defined a simple algorithm to generalize the benefits of sparse nets and attention mechanisms to any tabular dataset, dubbed sTabNet. Our sTabNet is shown to be competitive with tree-based models even without hyperparameter search."}, {"title": "A sparse and interpretable model for tabular data", "content": "We aim to build a sparse and interpretable network for tabular data. To constrain the number of model parameters, we establish a method to impose sparsity a priori: either by exploiting prior knowledge about the dataset or by utilizing unsupervised methods (when this knowledge is missing). In the former case, feature information can be exploited to construct a matrix to control the structure of the neural network architecture (Fig. 1A). For example, for RNA expression datasets, one can use the information contained in a pathway database to control which features can interact with each other. This binary matrix is then used to control the sparsity of the neural network (Fig. 1B). When one does not have specific knowledge about the dataset, we can construct this matrix with a simple process. Considering the similarity between features in the dataset (cosine similarity or another measure of similarity), one can construct a feature graph and use random walks to build the binary matrix. In short, explore the various local or global feature interactions depending on the hyperparameters (Fig. 1C-D).\nWe next defined simple attention mechanisms that are adapted for tabular data and are based on feature importance. This avoids the need to use post-hoc methods to calculate feature importance. Feature importance also is determined during training and not after the model has already been trained. We provide a detailed walkthrough of the sparse matrix construction (both in the presence of feature information and in an unsupervised manner) and attention mechanism in the methods.\nWe next tested our sparse-TabNet to verify that the attention mechanisms captured the importance of features for tabular datasets (exploiting both simulated and real datasets). We also tested sparse-TabNet on real and complex datasets such as multi-omics, single cells, multi-class classification, and survival regression, comparing them with decision trees (Fig. 1E)."}, {"title": "A model internal measurement of feature importance", "content": "As highlighted by (1) interpretability measurements are complicated because we do not have a dataset where the importance of the features is known in advance (a ground truth). For this reason, we established an evaluation framework where the ground-truth feature importance is defined a priori. We can make the following observations from supervised and unsupervised learning perspectives. First, from a classification (supervised learning) perspective, we observed an expected linear decrease of XGBoost accuracy with the increase of the difficulty of the multi-classification task (Fig. 2A). From a clustering (unsupervised learning) perspective, when the class clusters are poorly separated (separation coefficient 0.1) the model was almost guessing randomly. At the same time, when the class clusters are poorly separated we observed a reduction in the weight assigned to important features versus noisy features, making it harder to separate them (Fig. 2B). The SHAP value follows the same pattern for the feature importance, not allowing better identification of real important features (Fig. 2C). Thus, SHAP explanations in a sense are expression of the predictions abilities of XGBoost, they are dependant on its accuracy, but they do not improve the ability of the model in capturing the importance of a feature (and to separate informative and noisy features).\nWe define a sparse net similar to (12) but we incorporate a tabular attention mechanism that takes into account the feature importance of the input. While we also observed a decrease in the performance of sparse-net with increasing difficulty in the multiclassification task, the decrease is less dramatic (Fig. 2D and S1 A-C). Moreover, the separation between important features and noisy features is more pronounced (Fig. 2E). Interestingly, when the classification task is more complex the sparse net needs longer training to reach better performance and better separation (increasing the number of epochs) (S1 A-B).\nTo study the relationship between feature importance and attention, we conducted features ablation study. The most relevant first (MoRF) analysis shows a sharp drop when a feature with high attention weight is removed, demonstrating that attention mechanisms identify discriminative features (1) (Fig. 2F). The least relevant first (LeRF) analysis shows that attention scores are identifying noisy features (Fig. 2G). When the number of noisy features is increased, the XGBoost feature importance associated with real important features decreases (Fig. 2H). However, the attention score is maintained stable, allowing a separation between important features and noise (Fig. 2I). Finally, we also compared with other commonly used feature importance methods and we noticed a general concordance (supplementary table 1). Collectively these results show that the attention weight can be considered a feature importance score and it is a better discriminator between real important features and noise than XGBoost feature importance and SHAP value. In addition, they demonstrate that the attention score is more stable in separating significant versus noisy features."}, {"title": "Sparse models are more performant for complex datasets", "content": "We decided to test our model with complex real-world data as multi-omics which still presents different challenges for machine learning models (13\u201316). We built a sparse network similar to (12) using METABRIC multi-omics data as a dataset. Since there is no consensus in the literature on the best activation function for biologically constrained networks (12,17), we tested different ones during training. However, we did not observe any particular effect in the choice of the activation function (Fig. 3A). We also noticed that a comparative feed-forward neural network is only predicting the majority class with this dataset, thus we did not conduct ulterior experiments with a fully connected neural network. Neither the convolutional neural network is showing satisfying performances (Fig. 3B). Instead, the sparse net shows results comparable to those of XGBoost (Fig. 3B). Moreover, the addition of an attention layer shows a slight increase in performance (Fig. 3B and supplementary table 1). As we do not have the ground truth for feature importance for this dataset, we conducted a gene-set enrichment (18) for disease on the 100 highest attention weights. The results show that the highest attention weights are attributed to cancer-related genes (Fig. 3C and supplementary table 2).\nSince an advantage of neural networks is the possibility to fine-tune a model on a different dataset, we tested if a trained model on METABRIC on a multiclass objective could be fine-tuned for a binary classification dataset (TGCA-BRCA). The fine-tuned model showed to be able to adapt to a different task and a different dataset (in domain adaptation) (Fig. 3D). Furthermore, the frozen model can extract meaningful features that can be used to train a linear classifier (Fig. 3D). We also noticed out-of-domain adaptation using TGCA-LUAD, both fine-tuning model and feature extraction showed satisfying results (Fig. 3D). Single-cell technology has had a transformative impact on our understanding of development and the role of a cell in both physiological and disease environments. At the same time, these types of datasets have different computational challenges, and there is currently no consensus on which algorithm to use (19\u201321). We used single-cell data from the Tumor Immune Single-cell Hub 2 (TISCH2) of breast cancer (GSE161529). We used a sparse net for binary classification (tumor/normal cell) or multi-classification tasks (cellular type prediction). For each model, we did 10 cross-fold validations, averaged obtained values, and reported the accuracy. After freezing the model, we also extracted the data representation and performed data dimensional reduction with UMAP to plot it. The sparse net shows impressive performance with complex data as single-cell data in both binary and multiclass classification settings (Fig. 3E and Supplemental Table 3). Moreover, the model-learned representation of the data allows for the separation of the classes (Fig. S3). This shows that the model is learning meaningful features of biological datasets which could be used for follow-up tasks. Additionally, since the genomic datasets suffer from the curse of dimensionality (22), the sparse net can be used efficiently for feature selection to reduce the number of features in an analysis pipeline (Fig S.4).\nSurvival analysis is a domain of machine learning that deals with analyzing the dependence of time on the occurrence of an event (death, failure, and so on) and its relationship to features (23, 24). Although it can be considered a subcase of regression, classical techniques fail to capture its complexity (25). Given the relevance, several models have been developed such as the Cox proportional hazards model that fails, however, in nonlinear situations and with large datasets (26, 27). For this reason, we compared the sparse net with Scikit-survival, which integrates several methods based on traditional machine learning (28). We show that a sparse net clearly outperforms different machine learning algorithms for survival analysis (ensemble tree-based and support vector machine-based) (Fig. 3E). In addition, it can extract the most important predictors of survival (Fig. S.5).\nThe results show that sparse nets with attention mechanisms have higher performance than tree-based models for genomic datasets, they are interpretable and since they are learning meaningful latent features they permit in-domain and out-of-domain adaptation. Moreover, can be used for complex biology tasks such as single-cell and multi-omics classification and survival regression."}, {"title": "Neural networks are competitive with tree-based models for tabular data", "content": "Although different transformer-based models have been tested, different works suggest that the high capacity of neural networks is a hindrance to tabular tasks (29). Since often information about the features is not available, we described a method to leverage sparse nets for any arbitrary tabular dataset. In fact, the aim was to identify a simple method to reduce the model parameters before training while being competitive with tree-based models (Fig. 4A). Despite we did not conduct a hyperparameter search and used a simple architecture, the sparse net was shown to be competitive in comparison to the tree-based model: median accuracy 0.71 versus 0.70 (Table 2, Fig. 4B and supplementary table 4, and Fig. S6-7).\nWe also checked if our random walk approach could be used for complex datasets such as genomic datasets. We obtained similar results with Gene Ontology and random walk-based approach, showing that this approach is scalable and can be extended to any dataset (Fig. S8 and supplementary table 5).\nThe random walk forces the neuron in the sparse layer to learn a local zone of the feature graph. We noticed that the top random walk (selected using an additional attention layer) represents always the same neighborhood (Figs. 4C - D). The ablation study shows that the removal of the involved feature impacts the accuracy (Fig. 4E). Interestingly, removing these features augments the number of false positives in comparison to random feature removal (Fig. 4E). We did not notice an increase in false negatives with feature ablation (Fig. 4E), These data suggest that local patterns in the feature graphs can be associated with a particular class and thus the emergence of modularity."}, {"title": "Discussion", "content": "Tabular data are ubiquitous, and yet they have been left behind by the artificial intelligence revolution (1, 30). However, many crucial applications rely on tabular data (medicine, psychology, finance, user recommendation, cybersecurity, customer churn prediction) (1, 31\u201335). We argued that we do not need large models for these small datasets but, actually, too many parameters are deleterious for tabular data. For this reason, we proposed a simple but powerful model in which we exert prior knowledge (if present) to prune unnecessary parameters. In this work, we defined attention mechanisms to identify features importance in neural networks. Defining the ground truth, we showed how attention importance allows us to swiftly separate the real informative features from noisy features. When this idea is applied to real-world datasets (like cancer datasets), it allows the identification of important features and can be used to explore insights about the dataset. This is important in many contests (from biological to finance datasets, and more), where it is essential to know which feature is important. In addition, we showed that it is vital to consider data where the ground truth about feature importance is known when evaluating the interpretability of an algorithm. We have highlighted how even established methods are not always reliable, especially in complex tasks and numerous features. Moreover, attention weights can be used for feature selection and eliminate non-informative features. These factors come handy for real-world datasets, which are often noisy and have many redundant features.\nMost comparisons between tree-based models and neural networks have been conducted on simple datasets with a limited number of features (3). These datasets are not representative of real-world scenarios as biologically complex datasets. We showed where it is important that the model is learning a complex data representation sparse neural networks are competitive with tree-based models. Moreover, in these complex tasks, neural networks can be used to extract features, perform transfer learning, and thus end-to-end training. All these tasks are common to complex datasets in different fields (from medicine to customer churn prediction), and this opens exciting opportunities and applications.\nWhile this kind of sparse network has been defined when there is external knowledge about the features of the data, we defined an approach to extend it to any tabular dataset. Showing that simple sparse networks have similar results as tree-based models. Perhaps, as suggested before, for datasets with few features, the dense counterparts have too much capacity for the task. Constraining the neural network with sparsity is effective in allowing the model to learn the correct patterns. Moreover, this method forces neurons to learn about the local neighborhood of a feature in the feature graph. Additionally, this makes the neural network more interpretable.\nSince many algorithms can be deployed for sensible applications, interpretability is necessary for the use of neural networks.\nHowever, our method also generates isolated nodes, and in the future other alternatives to generate the feature graph could be explored. For example, the use of alternative distance measurements or a weighted Node2vec random walk can be explored. In addition, L1-regularization (or other regularization techniques) can be used to increase the sparsity of the network. We have not explored the hyperparameter space, and future works can be directed toward identifying the best hyperparameter selections. Moreover, we believe that this approach can be extended to better explore the modularity of neural networks."}, {"title": "supplementary", "content": null}, {"title": "Material and methods", "content": null}, {"title": "Attention mechanism and sparsity layer definition", "content": "We intend to build a neural network with sparsity and attention mechanisms. We define the attention mechanisms as an adaptation of the mechanisms described for text sequences (36\u201339) with two principles: they should be adapted for tabular data and naturally define features importance of such data. Moreover, to increase the expressive power of our established models, we equip them with a linear transformation learning of the input (simply multiplying for learnable weight vectors).\nConsidering as input for the model a tabular dataset $X \\in \\mathbb{R}^{m\\times n}$. To define the sparse layer, for a layer $l$ we consider a matrix $A \\in \\{0,1\\}^{m\\times n}$ as in (12). This matrix indicates which connection has to be taken into consideration. In other words, if $W$ is the weight matrix of the first layer, the output of the first layer is $H\u00b9 = \\sigma(XA\\odot W)$ where $\\odot$ is the Hadamard product (Fig 1. B).\nWe introduce the attention mechanism as follows. Let $\\tilde{w}$ be a learnable vector. Then, let $a = softmax(\\varphi(X\\cdot w)) \\cdot w$ (36\u201339), where $\\varphi$ is one of the functions given in Table 1. Using the vector $a$ we obtain that the output of the first level will be:\n$H\u00b9 = \\sigma(XA\\odot W)$\nAs defined in (40), every layer of a neural network can be written as a non-linear function, where $A$ is the adjacency matrix of a graph. In our model, $A$ is a matrix that controls the connections among neurons, and it could also be interpreted as an adjacency matrix of a graph where the nodes are features and the edges are interactions between the features (Fig. 1C). Thus, the attention score is defined as a value of the importance of the node in the feature graph."}, {"title": "Analysis of the interpretability of the sparse networks", "content": "To test if the attention mechanism score can capture the importance of a feature in the dataset we built simulated data for a multi-classification task (41). The multi-classes dataset is built as in (41) where the difficulty of the classification task is regulated by a hyperparameter (separation coefficient, range 0-1). In the dataset, we defined informative and not informative features (random noise). We used scikit-learn standard implementation (make classification), resulting in a matrix $X \\in \\mathbb{R}^{m\\times n}$ (where $n$ is the sum of informative and non-informative features). The sparse-net and XGBoost have been then trained to optimize a multi-classification objective (6 classes).\nFor each separation coefficient, we trained 10 different models (1000 examples with 10 informative and 90 non-informative features), and we measured the classification accuracy on the test set (0.2 of the dataset). We then examined whether a model can discriminate real informative features and separate them from random noise. For this purpose, we analyzed the importance score (for XGBoost) or the attention weight assigned to each feature in the sparse net. For XGBoost we also used SHAP value to determine feature importance (42). For the sparse net, thus we analyzed if the attention weight can be considered as a measure of feature importance. As defined in (43) we conducted Least Relevant First (LeRF) and Most Relevant First (MoRF) to assess the fidelity of the feature importance attribution.\nTechnical details. For XGBoost and SHAP we used the standard parameters as defined in the XGBoost package. For the sparse net, we used a simple architecture in Keras (input layer, attention mechanism, a sparse layer with 100 neurons, a linear layer with 64 neurons, and an output layer with softmax activation). We used dropout regularization, ADAM optimizer, and categorical cross-entropy as a loss. Since previous works focused on extensive hyperparameter optimization (29) for the tabular neural networks we intentionally did not conduct it to show performance with simple settings. For each separation coefficient, we randomly split 100 times"}, {"title": "Application to multi-omics dataset, fine-tuning, and feature extraction", "content": "Multi-omics data are notoriously complex to handle: they are expensive to collect, hetero-modals, and suffer the curse of dimensionality (for a dataset $X \\in \\mathbb{R}^{m\\times n}$, we have $n >> m$) (13). While it is hard to design an algorithm for this data, identifying important features leads to direct important utilization (13).\nWe used the following datasets: METABRIC (44) (RNAseq and mutations), TGCA-BRCA, and TGCA-LUAD (45) (only RNAseq data for both). We initially trained a sparse model with the above-defined attention mechanisms on METABRIC, testing different activation functions, and comparing it with XGBoost, a fully connected neural network (FCNN), and a Convolutional Neural Network (CNN). We then tested in-domain and out-of-domain using fine-tuning and feature extraction.\ntechnical details For the METABRIC dataset: We used XGBoost with a multi-class objective as suggested in the official library. The sparse net was built similarly to (12) using Gene Ontology (46) to define the sparse matrix $A$ for the layer. We also add an attention layer, two fully connected layers, and softmax as the output layer. We used dropout as regularization and"}, {"title": "Sparse net application to single-cell RNA seq dataset", "content": "We used single-cell data from the Tumor Immune Single-cell Hub 2 (TISCH2) of breast cancer (GSE161529). We downloaded the annotated data using minimal preprocessing as suggested in the ScanPy tutorial (47). We used a sparse net for binary classification (tumor/normal cell) or multi-classification tasks (cellular type prediction). Sparse-net was built as described above for the METABRIC dataset, and we used XGBoost as described above. The sparse net model was trained for 20 epochs and batch size 1024. We then used a 10-fold split for evaluation (a 10-fold split for evaluation was used also for XGBoost). For binary classification, we used a sigmoid final layer and binary cross entropy as loss while for multi-class classification we used a softmax layer and categorical cross-entropy. For the plotting, We removed the last two layers from the frozen models, We extracted the features just by passing the examples in the frozen models. We used Uniform manifold approximation and projection (UMAP) (48, 49) for dimension reduction to 2 components. We plotted the obtained projection using the Seaborn library."}, {"title": "Sparse net application to survival analysis", "content": "For survival analysis, we used the METABRIC dataset as described above, we used the associated metadata for overall survival. We modified the sparse net to adapt to the survival prediction task. Specifically, un attention layer (scaled dot mechanism), a sparse layer, a linear layer with dropout regularization, and a final layer with a neuron, we used the Breslow approximation as a loss function (50) and we used concordance index for measuring the performance. We compared with Scikit-survival library (?), which is implementing different algorithms for survival analysis. For this purpose, we selected two different gradient-boosted models (Gradient Boost and Component Wise Gradient Boost) and the fast extension of the support vector machine for survival analysis. For each algorithm, we conducted a 10-fold cross-validation and we used the concordance index as performance measurement. We also used the Scikit-survival library for plotting the survival curves."}, {"title": "Extension to non-biological tabular datasets", "content": "In a biologically constrained net (11), a pathway is an approximation of locally connected features that interact among themselves to fulfill a biological function. These could be seen as a connected group of nodes in the feature graph. In most tabular datasets we have no external knowledge about feature interactions and scope. We hypothesized that this structure could be approximated as a random walk starting from each future, using Node2vec biased random walk (51).\nLet be $X \\in \\mathbb{R}^{m\\times n}$ an input dataset, we define the feature graph $G$ adjacency matrix $M\\in \\mathbb{R}^{n x n}$. In $G$ the nodes represent $X$'s features and the edges are drawn if there is a similarity between two features $i \\in \u00d7$ and $j\\in x$. In other words, if the cosine similarity between the features $i$ and $j$ in $X$ is higher than 0.5 or less than -0.5, $M_{i,j} = 1$, otherwise $M_{ij} = 0$. We then performed three Node2vec random walks of five steps for each node in the graph $G$. We"}, {"title": "Data availability", "content": "No unique data were used in this study. All the data used are either published or generated by simulation. For simulated data, the process is based on a standard library (scikit-learn) and described in detail in the methods. For the other experiments we used only published data and data are publicly accessible from the provided references."}, {"title": "Code availability", "content": "We are providing the code for the sparse neural network. As new implementations of the sparse net will be available we will include them in the repository. We are also planning to integrate other potential applications and models in the same repository. Code can be accessed at:\nhttps://github.com/SalvatoreRa/SAM"}, {"title": null, "content": "Input: Dataset X with dimensions $R^{m x n}$\nOutput: matrix of random walks\nCalculate cosine distance matrix D for features n;\nInitialize an empty graph G;\nfor i in range(m) do\n for j in range(n) do\n if D[i, j] > 0.5 or D[i, j] < \u22120.5 then\n Add an edge between nodes i and j in G, if $i \u2260 j$ ;\n end\n end\n end\nfor i in range(n) do\n for k in range(3) do\n v \u2190 G[i];\n for s in range(5) do\n Node2Vec RandomWalk();\n end\n end\nend\nAlgorithm 1: Generate graph and perform random walks\nIn a classical feed-forward neural network each neuron can be considered as a walk that connects each node in the feature graph (Fig. 1C), thus learning a global approximation for the whole feature graph. Instead, a node in the sparse layer obtained by a random walk is learning an approximation of the local interactions of a feature in the feature graphs.\nTraining details. We used the benchmark dataset described by (3), and we filtered out datasets with less than 20 features and more than 100 K examples. We built the sparse matrix A as described above, for each feature we performed three random walks of size 5. We compared the sparse net accuracy with XGBoost and logistic regression.\nWe also performed also ablation study. Briefly, we add another attention layer after the sparse layer and we extract the attention weight (associated with each neuron). We therefore conducted 100 different splits to account for the random walk variability and we tracked which nodes were associated with the highest attention weight. We then removed these features or the other five random features and we measured again the accuracy."}]}