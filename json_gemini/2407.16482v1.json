{"title": "BONES: a Benchmark for Neural Estimation of Shapley values", "authors": ["Davide Napolitano", "Luca Cagliero"], "abstract": "Shapley Values are concepts established for ex- plainable AI. They are used to explain black-box predictive models by quantifying the features' contributions to the model's outcomes. Since computing the exact Shapley Values is known to be computationally intractable on real-world datasets, neural estimators have emerged as alternative, more scalable approaches to get approximated Shapley Values estimates. However, experiments with neural estimators are currently hard to replicate as algorithm implementations, explainer evaluators and results visualizations are neither standardized nor promptly usable. To bridge this gap, we present BONES, a new benchmark focused on neural estimation of Shapley Value. It provides researchers with a suite of state-of-the-art neural and traditional estimators, a set of commonly used benchmark datasets, ad hoc modules for training black-box models, as well as specific functions to easily compute the most popular evaluation metrics and visualize results. The purpose is to simplify XAI model usage, evaluation, and comparison. In this paper, we showcase BONES results and visualizations for XAI model benchmarking on both tabular and image data. The opensource library is available at the following link: https://github.com/DavideNapolitano/BONES.", "sections": [{"title": "I. INTRODUCTION", "content": "Explainable Artificial Intelligence (XAI) aims to make AI models more transparent to end-users [1]. Given a black- box predictive model, XAI solutions focus on providing ex- planations for the decision-making process. Shapley Values (SVs) [2] are concepts rooted in cooperative game theory, which have become established for XAI. SVs provide end- users with a deep understanding of each feature's contribution to the model's prediction, thereby enhancing the interpretabil- ity and trustworthiness of complex predictors.\nThe exact computation of SVs from real-world data is known to be computationally intractable [3] as the number of feature combinations is exponential with the dimensionality of the input dataset. Hence, a number of heuristic methods (e.g., KernelSHAP [4]) have been proposed to generate ap- proximated SV estimates.\nThe increasing availability of GPU-equipped hardware and the evolution of Deep Learning techniques has fostered the study of Neural Network-based approaches to compute ap- proximated SVs. During the training process, these networks learn the functional mapping between the input data features and their SVs attributions. State-of-the-art neural approaches (e.g., FastSHAP [5]) are currently able to efficiently generate accurate SVs estimates.\nAs a drawback, neural SVs estimators are currently neither promptly accessible nor easy to use. Actually, the most popular XAI projects (e.g., Quantus [6], OpenXAI [7], Compare- XAI [8]) lack neural solutions. Furthermore, there is a lack of standardization in model testing, evaluation, and comparison. This limits the applicability of neural approaches compared to more popular approximated methods such as Monte Carlo sampling [9] and regression techniques [10].\nWe present BONES, a Benchmark fOr Neural Estimation of Shapley values, aimed to foster XAI applications that mainly rely on neural SVs estimators. BONES consists of:\n\u2022 A suite of Shapley Values estimators, mainly neural and some traditional, tightly integrated for easy comparison and use;\n\u2022 A set of benchmark datasets, both in tabular form and images, that are commonly used for XAI model bench- marking;\n\u2022 Ad hoc modules to train black-box models and generate reliable ground truth SVs, whenever not already available, either exact or approximated.\n\u2022 A set of testing functions implementing the most popular performance evaluation metrics;\n\u2022 A set of promptly interactive plots that can be used to visually explore the main results and compare models' performance with each other.\nBONES simplifies and expedites the use of state-of-the-art neural approaches and allows end-users to perform accurate model comparisons considering aspects such as computational efficiency, attribution accuracy, model robustness to data cardi- nality and dimensionality. We hope BONES could effectively support XAI researchers interested in exploring the strengths and limitations of neural solutions."}, {"title": "II. RELATED WORKS", "content": "As discussed in [11], [12], the attention of the research com- munity to the explainable AI (XAI) field is ever-increasing. To actively support related research activities, several XAI benchmarks and tools have been released, e.g., SHAP [4], Quantus [6], OpenXAI [7], Compare-xAI [8], and Ferret [13]. The purpose is to allow fair and transparent comparisons among different XAI methods by making available suites of state-of-the-art algorithms, datasets, evaluation metrics, and visualization techniques. However, existing libraries do not incorporate the latest neural approaches. Thus, comparing neural Shapley Value estimators with each other or with traditional approaches requires additional effort. BONES ad- dresses the above limitation by providing researchers with promptly usable implementations of state-of-the-art Shapley Values estimators, both neural and traditional, as well as a testing suite including benchmark tabular datasets, evaluation metrics, and visualization tools. Our solution welcomes future extensions towards the integration of new algorithms, datasets, and standardized evaluation procedures.\nUnderstanding how AI models make decisions is crucial for augmenting their transparency and interpretability, espe- cially because most AI predictors act as black boxes. Feature importance attribution measures how much each input feature contributes to a model's predictions. Among existing methods, Shapley Values are popular due to their solid mathematical basis, as they fairly distribute the model's output among the input features based on their contributions and interactions. However, computing Shapley Values is often impractical. To address this issue, researchers have developed methods to approximate Shapley Values and, as alternatives, other techniques to compute feature relevance, like permutation importance [14], LIME [15], and DeepLIFT [16]. Empirical studies have compared various Shapley Values approximation methods, highlighting the trade-offs between accuracy, com- putational efficiency, and robustness. Existing analysis [17] provide a comprehensive evaluation of different Shapley Value approximation methods, showing that while neural approaches can significantly reduce computation time, their approximation accuracy varies depending upon the model architecture and dataset characteristics.\na) Traditional Approaches: Classical methods to com- pute Shapley Values involve exact computation [4], Monte Carlo sampling [9], and regression techniques [4], [10]. Exact computation evaluates the model on all possible subsets of features, providing precise Shapley Values but at a computa- tionally prohibitive cost. This approach is not applicable to models trained on many features due to the combinatorial explosion in the number of candidate subsets. Monte Carlo sampling methods approximate Shapley Values by averaging over random subsets of features, reducing computational bur- den but often requiring a large number of sampling iterations to achieve accurate results. Regression techniques, such as KernelSHAP [4] and Unbiased KernelSHAP [10], are also used to approximate Shapley Values using linear regressions, allowing for improved computational efficiency.\nb) Neural Approaches: Although traditional methods are accurate, they often have computational problems when scaling up the dataset size, making them impractical, espe- cially at inference time. Regarding existing neural approaches, DeepExplainer is part of the SHAP library [4]. It consists in an enhanced version of DeepLift [16], which recursively attributes the difference in the model's output between each input sample and the corresponding background sample back to the input features, significantly improving the computational efficiency over traditional methods. GradientExplainer lever- ages integrated gradient-based attributions [18] with SHAP values, utilizing the gradients of the output with respect to the inputs to approximate feature contributions more effi- ciently. FastSHAP [5] employs a neural network to learn a mapping from model inputs to Shapley Values, reducing the computation time, especially on large datasets, by ap- proximating the complex Shapley Value calculations through a learned function. DASP (Differentiable Approximation of Shapley values) [19] introduces a polynomial-time algorithm that leverages neural network architectures to approximate Shapley Values, enhancing the scalability and efficiency of the computation process. ViT-Shapley [20], designed mainly for Vision Transformers (ViTs) [21], adapts the Shapley Value computation to the unique architecture of ViTs, providing interpretable explanations for image classification tasks by learning to estimate the contribution of image patches to the model's predictions. Other techniques, such as ShapNet [22], focus on computing Shapley Values from ground truth data, making them unsuitable for explaining black-box models."}, {"title": "III. THE BONES BENCHMARK", "content": "BONES is a benchmark for neural Shapley Values estima- tion. It consists of the following modules:\n\u2022 Black-Box Models: it generates post-hoc explanations of arbitrary classification of various types and with various settings.\n\u2022 XAI Models: it integrates a variety of approaches to approximated SVs estimations, both neural and not.\n\u2022 Datasets: it provides access to several benchmark datasets, both tabular and image data.\n\u2022 Ground Truth: it supports the computation of both exact SVs [4] and of regression-based estimations [10] that can be used as alternative ground truths.\n\u2022 Evaluation Functions: it allows to quantify the accuracy of the SVs' estimates against the ground truth and the efficiency of the estimation process, as well as to compare different models with each other.\n\u2022 Visualization: it natively supports the generation of var- ious plots useful to perform exploratory analysis of the models' results and of their accuracy-efficiency ratio.\nThe design of BONES ensures maximal usability, portabil- ity, and extendabily. The key properties are summarized below.\n\u2022 Modality-Agnostic. A core strength of our framework is its modality agnosticism by-design. Shapley Values are potentially applicable across various data modalities such as image, tabular and text data. Our framework is designed to support a wide range of approaches and data types, ensuring its applicability in different input types domains. This broad applicability is crucial for re- searchers and practitioners who deal with data in different modalities and require reliable explainability standards. Currently, BONES supports tabular and image data. The extension to other modalities is already planned as a future work.\n\u2022 Post-Hoc Explanations. Our benchmark allows end- users to explain predictions of already trained models. This aspect of the framework is particularly valuable for practical applications, where models are often trained in a production environment and explanability needs to be retrofitted to provide insights into model behavior and decision-making processes.\n\u2022 Opensource, modular framework. To foster collabo- ration, reproducibility, and extensibility, our framework is designed with an open and modular architecture. The open BONES benchmark fosters contributions from the broader research community, facilitating the integration of new methods, datasets, and evaluation metrics. Mod- ularity ensures that components of the framework can be independently developed, tested, and replaced. This flexibility allows users to customize the framework to suit their specific needs, whether that involves incorporating new neural architectures, experimenting with alternative Shapley value estimation techniques, or adapting the benchmark to novel interpretability challenges.\nIn the following we detail the characteristics of the BONES components."}, {"title": "A. Datasets", "content": "BONES is currently suited to both tabular and image data. The benchmark is designed to facilitate the seamless integration and utilization of both proprietary and benchmark datasets such as those available in the UCI repository [23]. The current list of integrated datasets is given in Table I.\nFor tabular data, we choose a subset of datasets that are representative of different cardinality, dimensionality, and den- sity distributions. For image data we include datasets covering different aspects of visual information and model explainabil- ity. In detail, we integrate ImageNette [24] and Pet [25] by adopting the same configuration as in Vit-Shapley [20]."}, {"title": "B. Explainers", "content": "BONES provides a comprehensive suite of SVs estimators, both neural and not. The list of currently available XAI models is reported in Table II, where column Type differentiates between traditional and neural estimators. We standardize the integration process to make the module easily extensible with newly proposed approaches. The implementation currently rely on TensorFlow and PyTorch for tabular data and on PyTorch for images.\nFor tabular data, our framework supports several ap- proaches, including SHAP [4], i.e., the Exact, GradientSHAP, and DeepSHAP versions, ShapleyRegression [10] with Un- biased KernelSHAP and KernelSHAP, Monte Carlo Sam- pling [9], DASP [19]\u00b9, and FastSHAP [5]. For image data, the framework currently includes SHAP [4] (i.e., DeepSHAP and GradientSHAP variants), FastSHAP [5], and ViT-Shapley [20] for Vision Transformers."}, {"title": "C. Black-Box Models", "content": "Most neural explainers are suited to explain neural Network- based models only (see Column Black-Box type in Table II). However, latest approaches (e.g., FastSHAP) are compatible with non-neural classifiers as well.\nAs default black-box models, BONES exploits:\n\u2022 For tabular data, a Multi-Layer Perceptron classifier with two intermediate dense layers, each containing 64 units and ReLU activation, interspersed with dropout lay- ers. The final dense layer has an output corresponding to the number of classes, followed by a softmax activation. This implementation relies on Tensorflow;\n\u2022 For image data, a pre-trained Vision Transformer (ViT) in its tiny version [21], followed by a linear layer corresponding to the number of classes, is used for classification.\nThanks to its modularity and extensibility, BONES straight- forwardly supports the integration of traditional non-neural classifiers as well (e.g., the classifiers available in the Scikit- Learn library [26])."}, {"title": "D. Evaluation functions", "content": "a) Estimation error: BONES natively supports evalua- tion functions suited to quantify the prediction error made by\n\u00b9BONES currently integrates the authors' implementation relying on Ten- sorFlow version 1."}, {"title": "E. Visualization", "content": "BONES offers the following options to visualize the perfor- mance results of SVs estimators and to graphically compare them with each other:\n\u2022 Bar plot: It displays the local or global per-feature SVs computed by different explainers. This visualization allows for a direct comparison of the feature importance assigned by each explainer. This visualization is mainly intended for tabular data.\n\u2022 Image plot: For image data only, it graphically shows the mask of Shapley Values retrieved by different explainer pairs overlaid on the input processed image. In detail, a 14x14 pixels mask is used for all approaches, interpolat- ing ones providing pixel-wise explanations.\n\u2022 AUC curves: It plots the Inclusion and Exclusion AUC for image data only. AUC shows the predictor accuracy by varying the percentage of Inclusion/Exclusion.\n\u2022 Quadrant plot: The quadrant plot is computed based on overall times and our performance metric P (1). It offers a comprehensive view of the computational efficiency and performance of different explainers, aiding in selecting the most suitable method for a given task.\n\u2022 Computational times vs. number of samples plot: This plot visualizes the model's computational times by varying the number of samples processed on the chosen dataset. End-users can vary the total number of samples, the interval between the tested values, and the sampling techniques applied to the input dataset. It provides end- users with insights into the explainers' scalability of explainers with the dataset cardinality.\n\u2022 Computational times vs. number of features plot: This plots show the inference times spent by the XAI model by varying the number of input features."}, {"title": "IV. CASE STUDY", "content": "We showcase the usability and flexibility of BONES using two example case studies, one on a tabular dataset, i.e., Monks [23], and on a image dataset, i.e., ImageNette [24]."}, {"title": "A. Tabular Data", "content": "The snippet in Listing 1 shows how to efficiently import SVs estimators and datasets, select the preferred evaluation metric, and generate the corresponding plots."}, {"title": "B. Image Data", "content": "The snippet in Listing 2 shows a similar example tailored to image data. BONES offers the opportunity to visualize the Inclusion and Exclusion AUC plot (see Figure 5). For example, the experiments on ImageNette confirm the better capabilities of FastSHAP to avoid excluding discriminating regions. The Image plot in Figure 4 allows end-users to select a sample and view the masks of the Shapley Values calculated by the various methods. This is particularly interesting for users who would like to quickly perform qualitative analysis."}, {"title": "V. CONCLUSIONS AND FUTURE WORK", "content": "The paper presented BONES, a benchmarking library for neural Shapley Values estimation. The main purpose is to make neural estimators available and easy-to-use to researchers of the XAI community, leveraging applications to real-world data and quantitative models' comparisons. As future work, we plan to extend BONES to support a broader range of modalities, models, and datasets. Additionally, we aim to integrate variants of Shapley Values into BONES, including Shapley Residuals and Interval Shapley Values."}]}