{"title": "Derivation of Output Correlation Inferences for\nMulti-Output (aka Multi-Task) Gaussian Process", "authors": ["Shuhei Watanabe"], "abstract": "Gaussian process (GP) is arguably one of the most widely used machine learning algorithms\nin practice. One of its prominent applications is Bayesian optimization (BO). Although the\nvanilla GP itself is already a powerful tool for BO, it is often beneficial to be able to consider\nthe dependencies of multiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it\nis not trivial to fully understand the derivations of its formulations and their gradients from\nthe previous literature. This paper serves friendly derivations of the MTGP formulations\nand their gradients.", "sections": [{"title": "1 Introduction", "content": "Gaussian process (GP) is one of the most important machine learning algorithms in practice\nand often plays a key role in Bayesian optimization (BO) (Brochu et al., 2010; Shahriari et al.,\n2016; Garnett, 2022) \u00b9 because GP shows good predictive accuracy even with a small amount of\ndata. While the vanilla GP models only one output, multi-output modeling by GP (Bonilla et al.,\n2007), aka multi-task GP (MTGP), often brings benefits as represented by Swersky et al. (2013);\nDaulton et al. (2020, 2022). Although they demonstrated that MTGP is effective for multi-objective\noptimization, constrained optimization, multi-fidelity optimization, and meta-learning, many\nworks still do not rely on MTGP, e.g., multi-objective optimization by Yang et al. (2019), con-\nstrained optimization by Gardner et al. (2014); Gelbart et al. (2014); Eriksson and Poloczek (2021),\nmulti-fidelity optimization by Kandasamy et al. (2017); Song et al. (2019); Kandasamy et al. (2019);\nWistuba et al. (2022), and meta-learning by Feurer et al. (2018). That is partially because the orig-\ninal paper (Bonilla et al., 2007) unfortunately lacks their derivation details, making it challenging\nto fully understand. To this end, we remove this barrier in this paper by giving more detailed\nand friendly derivations of the formulations and the gradients of the formulations with respect\nto kernel hyperparameters. By doing so, we would like more researchers to work on the afore-\nmentioned problem setups using MTGP, potentially leading to further enhancements in existing\nhyperparameter optimization frameworks that use MTGP such as BoTorch (Balandat et al., 2020)."}, {"title": "2 Related Work", "content": "In this paper, we focus only on MTGP formulated in Bonilla et al. (2007) simply because this model\nis used in BoTorch \u00b2, which is the most widely used GP-based BO framework we are aware of.\nBonilla et al. (2007) formulated MTGP as a linear combination of latent GPs with fixed coefficients\nas explained later. This formulation is relatively simple and a large body of existing work tackled\nto capture more complex structures. For example, Wilson et al. (2011) modeled the coefficients de-\npendent on input variables, Alvarez and Lawrence (2008) employed convolved process, and Titsias\n(2009); Nguyen et al. (2014) used variational inference to approximate the posterior of the latent\nprocesses."}, {"title": "3 Preliminaries", "content": ""}, {"title": "3.1 Notations", "content": "In this paper, we use the following notations:\n1. \u039d(\u03bc, \u03a3), the Gaussian distribution with the mean \u00b5 and the covariance matrix \u03a3,\n2. N(z|\u03bc, \u03a3), the probability density function of the Gaussian distribution with the mean \u00b5 and\nthe covariance matrix \u03a3,\n3. x \u2208 X \u2286 RD, an input vector x defined on a D-dimensional domain X,\n4. fm: X \u2192 R, the unobservable output mean function of the m-th output,\n5. M\u2208 Z+, the number of outputs given an input vector,\n6. Yn,m ~ N(fm(xn), om), the observed m-th output value of the n-th input vector xn,\n7. \u03a3 := diag[\u03c3, ..., \u03c3\u2081] \u2208 RM\u00d7M, a diagonal matrix with the (m, m)-th element om,\n8. On \u2208 RN, a zero vector with the size N,\n9. IN \u2208 RN\u00d7N, an identity matrix with the shape of N \u00d7 N,\n10. S := In \u00ae \u03a3\u2208 RNM\u00d7NM, the Kronecker product of IN and \u2211,\n11. Yn := [Yn,1, Yn,2, . . ., Yn,m] \u2208 RM, the observed output vector given the n-th input vector,\n12. Y \u2208 RN\u00d7M, the observed output matrix with the (i, j)-th element yi,j,\n13. fn := [fn,1,..., fn,m] := [f1(xn), f2(xn), ..., fm(xn)] \u2208 RM, the output mean vector given the\nn-th input vector,\n14. F\u2208 RN\u00d7M, the output mean matrix with the (i, j)-th element fi,j,\n15. Y1:N := vec(Y) =   \u2208 RNM, the flattened observed output vector,\n16. f1:N := vec(F) = [f],..., f\u221a] \u2208 RNM, the flattened output mean vector,\n17. ko : X \u00d7 X \u2192 R, a kernel function given its hyperparameters 0,\n18. Kx \u2208 RN\u00d7N, a kernel matrix for the input vectors with the (i, j)-th element ko(xi, xj),\n19. K\u0192 \u2208 RM\u00d7M, a kernel matrix for outputs,\n20. Kxf := Kx \u00ae Kf \u2208 RNM\u00d7NM, the Kronecker product of Kx and Kf, and\n21. Ai,j \u2208 R, the (i, j)-th element of the matrix A.\nNote that we assume that kernel matrices are positive definite and symmetric, meaning that they\nare invertible, and the output function f.: {1, ..., M} \u00d7 X \u2192 R follows the Gaussian process,\ni.e., f. ~ GP(\u00b5, k\u04e9kf) where kf(i, j) = (Kf)i,j is an index kernel for the output correlation, and\nvec : RN\u00d7M \u2192 RNM is the vectorization operation:"}, {"title": null, "content": "vec(C) =\n\n(\nC1,1\n:\nCN,1\n\n\u04211,\u043c\nCN,M\n\n)\n= [C1,1, . . ., \u04211,\u043c, \u04212,1, . . ., \u04212,\u043c, . . ., CN,1, . . ., CN,M]T. (1)"}, {"title": "3.2 Basic Theorems in Linear Algebra", "content": "In this section, we consistently assume that A \u2208 RN\u00d7N, B \u2208 RM\u00d7M, C\u2208 RN\u00d7M, and D \u2208 RM\u00d7N.\nTheorem 1 vec(C)T (A & B)vec(C) = tr(ACBTCT) holds.\nThe proof is available in Appendix A.1.\nTheorem 2 tr(CD) = tr(DC) holds.\nThis property is known as cyclic property and the proof is available in Appendix A.2."}, {"title": "4 Output Correlation Inference for Multi-Task Gaussian Process", "content": "Bonilla et al. (2007) proposed to model the interaction effects between each output by assum-\ning N(f1:N|0NM, Kxf) as the prior and N(y|f, 2) as the likelihood. Importantly, we need to\nestimate the kernel matrix Kf for outputs and Bonilla et al. (2007) introduced the EM algo-\nrithm (McLachlan and Krishnan, 2008) update for this and the gradient approach. However, the\npaper unfortunately lacks their derivation details. This section provides the derivation details to\nfill the gap in the original paper. Note that the approach used in BoTorch is the gradient approach\nexplained in Section 4.2."}, {"title": "4.1 EM Algorithm Update for Multi-Task Gaussian Process", "content": "We first provide a friendly derivation of the EM algorithm update for MTGP."}, {"title": "4.1.1 Complete-Data Log-Likelihood.", "content": "Since MTGP requires the approximation of the output correla-\ntion Kf, the hyperparameter optimization of the kernel function is indispensable. To estimate\nKf, Bonilla et al. (2007) used the EM algorithm that repeats E step where we estimate the expec-\ntation over the distribution p(f1:N|Y1:N, 0, Kf, \u03a3) of the missing data, i.e. f1:N in our case, and M\nstep where we maximize the complete-data log-likelihood Lcomp := p(y1:N, f1:N), which we derive\nin this section. Using the Bayes' theorem p(Y1:N, f1:N) = P(Y1:N|f1:N)P(f1:N), the complete-data\nlog-likelihood is computed as follows:"}, {"title": null, "content": "Lcomp = log N(Y1:N|f1:N, S)N(f1:N|0NM, Kxf) (Defs. S = In \u00ae \u03a3, Kxf = Kx \u00ae Kf)\n= log (\n1\n(2\u03c0)NM|S|1/2|Kxf|1/2\nexp(\n1\n-(Y1:N - f1:N)TS-1(Y1:N - f1:N)\n)\n2\n= -NM log 2\u03c0 - \n1\nlog |S| -\n1\nlog |Kxf| -\n1\n(Y1:N \u2212 f1:N)TS\u00ae\u00b9(Y1:N \u2212 f1:N) -\n1\nK-1\n:Nxf\n2\n2\n2\n(3)"}, {"title": null, "content": "Since |AB| = |A|M|B|N holds for A \u2208 RN\u00d7N and B \u2208 RM\u00d7M, we can further transform as follows:\nLcomp =\n=0\nM\n2\nlog|IN|\nN\n2\nlog |\u03a3|\nM\n==1 log om\n-\n-\n1\n(Y1:N \u2212 f1:N) (IN & \u2211)\u00af\u00b9(Y1:N \u2212 f1:N)\n2\n==1(yn-fn)\u03a3-1(yn-fn)\n-\nN\n2\nlog |Kx|\nM\n2\nlog |Kf| -\nconst.\n1:Nxf\nconst.\nFINKSI:N const.\n2\n2\nN\nM\n==1080-108/K1-10g|K-(-) - Pin\n+(yn fn)1(yn fn)-\n2\n2\n-1\n\u03a3log\n-\nM\n2\nN\nlog |Kx|-\n2\nlog |Kf|-\n(Yn\n+\nn=1\n+\n-\n) - (-)\n+\n=\n2\n2\n=\n2\nn=1\n(4)\nWe will finally transform the last term of Eq. (4) using (A & B)\u22121 = A\u00af\u00b9 \u00ae B\u22121 \u00b3, Theorem 1,\nand Theorem 2. Without loss of generality, we can ignore the coefficient -1/2 and then we can\ntransform the last term as follows:\n1:NKxFJ1:N = FIN (Kx \u00ae Kf)\u00af\u00b9fi:n = vec(F)(K\u00af\u00b9 \u00ae K\u00b9)vec(F)\n= tr(K-1FK7\u00b9F\u00af) (\u00b7: Theorem 1, Kx = K, Kf = K) (5)\n= tr(FK-1FK7\u00b9) (\u00b7:\u00b7 Theorem 2)\nBy plugging it back in, we obtain the complete-data log likelihood:"}, {"title": null, "content": "=\nM\nN\nNM\nLcomp - \u03a3logom-logKx|logKFK\u00b9) + const.\nnm\n\u03a3\n\u03a3\n(Yn,m-fn.m)\u00b2\n=\n+\n27\n2\n2\nmnmn mnmn mnmn mnmn mnmn mnmn\n(6)"}, {"title": "4.1.2 Maximum Likelihood Estimation in M Step.", "content": "In the M step, we maximize the complete-data log-\nlikelihood Lcomp with respect to \u03b8, \u03a3, and Kf. Conventionally, we simply take hyperparameters at\nthe stationary point. We first estimate \u00f4\u2081:"}, {"title": null, "content": "M\nNNM\nlog m\nInmn12 +\n=\n20\n-\n3\nLcomp\n+\n21 +\n/m=1/m=1+\nMnm - n\n/m=1\nN (nm - m\n(\n)(\n\u03a3\n\n/m=1/m=1 n=1/m=1 nm12\n,\n3\n=\n+\n/m=1 nm)2 + m)2/m=1\n(8)\nInmn)2+ m)2/m=1\n\u03a3(Inmn)2+ m)2/m=1\nInmn)\n,\n/m=1/m=1 mn)\n\u03a3(Inmn)\n3\n\u03a3(\n\n=\nInm12+\n=\n+\n(Inmn)\n+\n(Inmn)\nInmn\n\u03a3+\n2 mn\n3\n3\n2 mn\n\u03a3/m=1/m=1+ mn)\n\u03a3(\n+\n/\n+\n/\n3\n(7)\nBy taking the derivative of zero, we obtain:"}, {"title": null, "content": "=\n+\n=\n2mnmn mnmn mnmn mnmn mnmn mnmn+\n(304304)304304+ mn mn mn mn mn mn mn mn mn mn mn mn+ +\n(304304304304+\n2mn(304304+ mn mn mn mn mn mn mn mn mn mn mn mn+\n+ +\n(2 mn mn mn mn mn mn mn mn mn mn mn mn mn\n(304304+ mn mn mn mn mn mn mn mn mn mn mn mn+\nmn(304304+ mn mn mn mn mn mn mn mn mn mn mn mn+\n+(2 mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+\n+\n+\n+\n+\n+\n2mn(304304+ mn mn mn mn mn mn mn mn mn mn mn mn+\n+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n2 mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\nmn+\n40404+\n+\n+(\n=\n+\n=(\n+(\n+\n+(\n+\n=\n=(\n+(\n+\nmn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\nmn+\n+(\n+\n(\n+\n=(\n+(\n(304304+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+(\n(304304+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n=(\n=(\n+(\n+(\n(\n=(\n(\n+(\n+(\n(304304+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+(\n(\n3\n3\n3\n3\n+(\nInm3333(\n+\n3 (\n+\nInm3333Inm+\n+(\n+(\n+\n+\n+(\n=(\n((\n=(\n3\n3\n3\n=(\n)=(\n=(\n=(\n40404+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+(\n3\n((\n+(\nInmnInmn=(\n+(\n+\n((\n+\n+\n+(\n(304304+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n40404+(\n+(\n(\n+\n+(\n3\n(+\n+\n+(304304+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n404041042+\n=(\n((\n(40404404+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n3\n(+\n+(\n+(\n+\n3\n=(\n=(\n=\n(\n(304304+ mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+ +\n+\n+\n=(\n=(\n3\nInmn3333(3\n3\n=(\n)=(\n=(\n)=(\n40404104((\n(+\n+\n40404((\n+(\n+(+\n((\n(+(\n\n+(\n+\n+(\n+\n40404+(\nmn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mnmn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn(\n+\n=(\n(\n+(\n((\n3333((\n(+\n((\n(\n((\n((\n40404104(3+mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+\n+ + mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn mn+\n+\n(\n(304((\n((\n(\n((\n((\n((()(()(()(()(()(()(())(\n((\n(\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n((\n(("}]}