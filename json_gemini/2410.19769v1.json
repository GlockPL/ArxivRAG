{"title": "Real-time Monitoring of Lower Limb Movement Resistance Based on Deep Learning", "authors": ["Buren Batua", "Yuanmeng Liu", "Tianyi Lyu"], "abstract": "Real-time lower limb movement resistance monitoring is critical for various applications in clinical and sports settings, such as rehabilitation and athletic training. Current methods often face limitations in accuracy, computational efficiency, and generalizability, which hinder their practical implementation. To address these challenges, we propose a novel Mobile Multi-Task Learning Network (MMTL-Net) that integrates MobileNetV3 for efficient feature extraction and employs multi-task learning to simultaneously predict resistance levels and recognize activities. The advantages of MMTL-Net include enhanced accuracy, reduced latency, and improved computational efficiency, making it highly suitable for real-time applications. Experimental results demonstrate that MMTL-Net significantly outperforms existing models on the UCI Human Activity Recognition and Wireless Sensor Data Mining Activity Prediction datasets, achieving a lower Force Error Rate (FER) of 6.8% and a higher Resistance Prediction Accuracy (RPA) of 91.2%. Additionally, the model shows a Real-time Responsiveness (RTR) of 12 milliseconds and a Throughput (TP) of 33 frames per second. These findings underscore the model's robustness and effectiveness in diverse real-world scenarios. The proposed framework not only advances the state-of-the-art in resistance monitoring but also paves the way for more efficient and accurate systems in clinical and sports applications. In real-world settings, the practical implications of MMTL-Net include its potential to enhance patient outcomes in rehabilitation and improve athletic performance through precise, real-time monitoring and feedback.", "sections": [{"title": "1. Introduction", "content": "The monitoring of lower limb movement resistance is crucial in various fields, including physical therapy, sports training, and rehabilitation[1]. Traditionally, this monitoring has relied on mechanical sensors and manual observations, which can be cumbersome, less accurate, and inefficient[2]. These traditional methods are often limited by their inability to provide continuous, real-time feedback, which is essential for effective rehabilitation and performance enhancement[3]. Additionally, the manual nature of these methods makes them prone to human error and inconsistency, further diminishing their reliability.\nIn recent years, the advent of wearable technology and advanced sensor systems has revolutionized the way movement resistance is monitored. These devices can collect extensive data on movement patterns, forces, and resistance encountered during physical activities [4, 5]. However, the sheer volume and complexity of this data present significant challenges in terms of real-time processing and analysis. This is where deep learning comes into play, offering robust solutions for handling large datasets and extracting meaningful insights[6].\nDeep learning, particularly through models like Convolutional Neural Networks (CNNs) [7-10] and Recurrent Neural Networks (RNNs) [11-14], has shown immense potential in enhancing the accuracy and efficiency of movement resistance monitoring. CNNs are adept at extracting spatial features from sensor data, while RNNs excel in capturing temporal dependencies [15, 16], making them ideal for analyzing time-series data from wearable sensors. These models can learn complex patterns in the data, enabling precise predictions and real-time feedback, which are critical for effective intervention and improvement in physical activities.\nDespite these advancements, the application of deep learning in this field is not without its challenges. High computational demands and latency issues are major barriers to achieving real-time processing on wearable devices. Additionally, human movement is highly variable, requiring models to be robust and generalizable across different users and conditions [17]. Specific examples include the work by Zhang et al.[18], which identified significant latency issues in real-time gait analysis using deep learning models, and Schmid et al. [19], which reported on the difficulties of generalizing model performance across diverse populations in a clinical trial setting. These studies highlight the ongoing challenges in this area, emphasizing the need for more efficient and adaptable solutions.\nIn the context of lower limb movement resistance monitoring, it is important to consider various factors such as joint rotation angles and stride length. These factors significantly influence the resistance encountered by the lower limbs during movement. These parameters are critical for accurate resistance estimation. The joint rotation angles are necessary for understanding the mechanical load on different joints, while the stride length helps in assessing the overall gait and movement efficiency. The combination of these factors provides a comprehensive understanding of the lower limb mechanics, which is essential for precise resistance monitoring. These requirements place high demands on the accuracy and real-time processing capabilities of the monitoring systems, presenting significant challenges for effective implementation.\nDespite the advancements in lower limb movement resistance monitoring, significant gaps remain in the current research. One key gap is the inability of existing models to generalize well across different populations and movement conditions, leading to inconsistent performance in real-world scenarios. Additionally, many current approaches struggle with real-time processing due to high computational demands, which limits their practical application on wearable devices with limited processing power. Another critical gap is the lack of integrated systems that can simultaneously perform multiple related tasks, such as activity recognition and resistance estimation, with high accuracy.\nThe MMTL-Net model proposed in this study directly addresses these gaps. By integrating MobileNetV3's efficient feature extraction with Multi-Task Learning (MTL), our approach enhances generalization across diverse conditions, enables real-time processing on resource-constrained devices, and effectively performs multiple tasks simultaneously. This combination not only improves the accuracy and efficiency of lower limb movement resistance monitoring but also broadens the applicability of such systems in clinical and sports environments.\nThe primary objective of this study is to develop a real-time monitoring system that is both accurate and efficient, capable of operating on wearable devices with limited computational resources [20-22]. The proposed model aims to overcome the limitations of existing approaches by providing a robust and scalable solution for lower limb movement resistance monitoring. Through extensive experimentation and validation using multiple datasets [23-25], this study seeks to demonstrate the effectiveness of the proposed approach and its potential to enhance physical therapy, sports training, and rehabilitation practices. Specifically, our contributions include the integration of MobileNetV3 with Multi-Task Learning to improve accuracy, efficiency, and real-time performance, making the MMTL-Net model a highly effective solution for practical applications.\nThe datasets used in this study include the UCI Human Activity Recognition Using Smartphones Data Set, the WISDM Activity Prediction Data Set, and the MHEALTH Data Set. These datasets provide comprehensive and high-quality motion data, covering various activities and movement patterns. By leveraging these datasets, the proposed model can be trained and validated effectively, ensuring its reliability and applicability in real-world scenarios."}, {"title": "2. Related Work", "content": "Deep learning has revolutionized various fields, including the monitoring of movement resistance, particularly in lower limb movements [35]. Movement resistance monitoring, which involves measuring the force and resistance encountered by muscles and joints during movement[36], is crucial in physical therapy, sports training, and rehabilitation[8, 37-40]. Traditional methods rely heavily on mechanical sensors and manual observations, which can be cumbersome and less accurate. As technology has advanced, there has been a significant shift towards using neural networks to analyze and predict movement resistance, offering a more sophisticated and accurate approach.\nRecent studies have focused on developing deep learning models to enhance the accuracy and efficiency of resistance monitoring[41]. CNNs [42] and RNNs have been employed to process data from wearable sensors[43] and video feeds[44]. These models can learn complex patterns and make real-time predictions[45], significantly improving the monitoring process [46]. Additionally, researchers are exploring the integration of computer vision techniques to analyze movement dynamics and resistance, thus expanding the scope and potential applications of these models[47].\nDespite these advancements, achieving real-time monitoring with high accuracy remains a challenge[48, 49]. Many models struggle with the computational demands and latency issues [50], which can hinder their applicability in real-world scenarios[51]. Moreover, the existing models often lack the robustness required to handle the variability in human movements[52-55]. Consequently, the current research trend is towards developing more efficient and lightweight models that can operate in real-time with minimal computational resources [56, 57]. Addressing these challenges is crucial for advancing the practical application of deep learning in movement resistance monitoring[58].\nWearable technology has become increasingly popular for monitoring physical activities[59], including lower limb movements. These devices, equipped with various sensors[60], collect data on movement patterns, force, and resistance[61, 62]. The integration of deep learning algorithms with wearable technology has opened new avenues for real-time movement analysis and resistance monitoring[63], providing continuous monitoring and immediate feedback that is beneficial for both athletes and patients undergoing rehabilitation[64].\nCurrent research in this area focuses on improving sensor accuracy and developing algorithms that can process sensor data more effectively[65]. There is a significant emphasis on creating models that can work with limited data and still provide reliable results[66]. Techniques such as transfer learning and data augmentation are being employed to enhance model performance. Additionally, researchers are exploring the use of multimodal data[67, 68], combining information from different types of sensors to improve the overall accuracy of resistance monitoring[69]. This holistic approach aims to create a more comprehensive understanding of movement dynamics.\nHowever, despite these developments, challenges remain in terms of sensor accuracy, data processing speed[70], and the integration of different data types[71, 72]. Many wearable devices still face issues with battery life and user comfort, which can limit their usability[73]. The research community is actively working on addressing these issues, with a particular focus on developing more energy-efficient sensors[74] and optimizing deep learning algorithms for faster processing[75]. These efforts are crucial for making wearable technology a reliable and practical tool for movement resistance monitoring.\nComputer vision has emerged as a powerful tool in sports and rehabilitation, providing detailed insights into movement patterns and resistance [76]. By analyzing video data, computer vision algorithms can detect and quantify movement resistance[77], offering a non-invasive alternative to traditional methods. This technology is particularly useful for monitoring lower limb movements[78], where precise measurement of resistance is crucial for effective training and rehabilitation[79]. The application of computer vision in this field leverages advancements in machine learning and image processing to enhance accuracy and usability[80].\nIn recent years, there has been a growing interest in applying computer vision techniques to monitor and analyze lower limb resistance. Advanced models such as pose estimation algorithms and action recognition networks are being used to extract detailed movement data from videos [81]. These models can identify subtle variations in movement and provide real-time feedback[82], making them valuable tools in both sports and rehabilitation settings[83]. The ability to provide continuous and detailed analysis is transforming how movement resistance is monitored and managed.\nHowever, the application of computer vision in this field is not without challenges. High computational requirements, the need for large annotated datasets, and the difficulty in achieving real-time processing are significant obstacles [84, 85]. Moreover, existing models often struggle with variations in lighting, background, and camera angles, which can affect their accuracy [86]. Researchers are focusing on developing more robust algorithms that can handle these challenges and provide reliable real-time monitoring[87]. This includes efforts to improve the efficiency of pose estimation models and the use of synthetic data to enhance model training[88].\nWhile deep learning, wearable technology, and computer vision have significantly advanced the field of movement resistance monitoring, there are still critical gaps that need to be addressed. Achieving real-time, accurate monitoring with minimal computational resources remains a key challenge. The ongoing research is geared towards developing more efficient models, improving sensor technology, and enhancing the robustness of computer vision algorithms to overcome these limitations. Addressing these issues will be essential for fully realizing the potential of these technologies in practical applications."}, {"title": "3. Methodology", "content": "In the field of lower limb movement resistance monitoring, traditional methods relying on mechanical sensors and manual observations face significant challenges. These methods are often cumbersome, less accurate, and inefficient. The primary issues include high computational demands and latency, which hinder real-time processing on wearable devices. Additionally, the variability in human movements necessitates robust models that can generalize well across different users and conditions. Existing deep learning models frequently struggle with these aspects, leading to suboptimal performance in practical applications.\nTo address these challenges, this study proposes a novel model named MMTL-Net. This model integrates the lightweight MobileNetV3 architecture with Multi-Task Learning (MTL) to effectively tackle the identified issues. MMTL-Net builds on previous research, leveraging the strengths of MobileNetV3's efficient feature extraction and MTL's shared representation learning to enhance overall system performance, particularly in real-time lower limb movement resistance monitoring.\nThe MMTL-Net framework consists of several key components: the Data Input Module, Feature Extraction Module, Multi-Task Learning Module, and Output Module. \nThe Data Input Module is responsible for receiving and preprocessing raw sensor data from wearable devices. The data collected includes tri-axial acceleration and gyroscope readings, which are essential for understanding movement dynamics. This raw data undergoes preprocessing steps such as noise reduction and normalization to ensure high-quality input for the subsequent stages.\nNext, the Feature Extraction Module employs MobileNetV3 to efficiently extract relevant features from the preprocessed data. MobileNetV3 utilizes depthwise separable convolutions, significantly reducing computational complexity while maintaining high accuracy. This makes it particularly suitable for deployment on wearable devices where computational resources are limited. The features extracted by MobileNetV3 encapsulate essential spatial and temporal characteristics of the movement data.\nThese features are then fed into the MTL Module. In this module, the features are shared across multiple tasks to leverage the interrelated nature of activity recognition and resistance estimation. For the Activity Recognition task, a series of fully connected layers are employed to classify the activity type, such as walking, running, or sitting. This classification is critical for contextualizing the resistance data and understanding the specific movements being analyzed. For the Resistance Estimation task, another set of fully connected layers predicts the resistance encountered during movement. This task benefits from the shared features by improving the accuracy and robustness of the resistance predictions.\nFinally, the Output Module consolidates the predictions from the MTL module, providing real-time feedback on both movement resistance and activity status. The predictions are transmitted to a user interface, offering immediate and actionable insights to users such as physical therapists and athletes. This feedback loop is essential for informed decision-making and timely intervention, ultimately enhancing the effectiveness of physical therapy, sports training, and rehabilitation programs.\nThe proposed MMTL-Net model offers several distinct advantages. The lightweight architecture of MobileNetV3 ensures low computational demand, making it suitable for real-time applications on wearable devices. By employing MTL, the model can simultaneously perform multiple tasks with high accuracy, thanks to the shared representations that improve overall system performance. Moreover, MMTL-Net is designed to handle the variability in human movements, ensuring reliable performance across different users and conditions.\nBy addressing the key challenges in lower limb movement resistance monitoring, MMTL-Net is expected to significantly enhance the accuracy, efficiency, and practicality of real-time monitoring systems. This model aims to provide valuable insights for physical therapy, sports training, and rehabilitation, facilitating more effective and personalized interventions. Through extensive experimentation and validation using multiple datasets, this study seeks to demonstrate the effectiveness of the proposed approach and its potential to revolutionize the field of movement resistance monitoring."}, {"title": "3.1. Overall Model: Framework, Design, and Network Architecture", "content": "In the field of lower limb movement resistance monitoring, traditional methods relying on mechanical sensors and manual observations face significant challenges. These methods are often cumbersome, less accurate, and inefficient. The primary issues include high computational demands and latency, which hinder real-time processing on wearable devices. Additionally, the variability in human"}, {"title": "3.2. MobileNetV3", "content": "MobileNetV3 is a state-of-the-art deep learning model designed for efficient and accurate feature extraction in resource-constrained environments. The core principle of MobileNetV3 lies in its architecture, which utilizes depth-wise separable convolutions to reduce the computational complexity and parameters compared to traditional CNNs. This is achieved by splitting the convolution operation into a depthwise convolution followed by a pointwise convolution. The model also incorporates advanced techniques such as squeeze-and-excitation (SE) modules and the use of the swish activation function, further enhancing its performance. MobileNetV3 is widely used in image classification, object detection, and semantic segmentation due to its balance between accuracy and efficiency. Specifically designed for efficient image classification and object detection tasks in computer vision, MobileNetV3 aims to achieve high performance while requiring fewer computational resources compared to other architectures. This makes it an ideal choice for applications where both precision and resource efficiency are critical.\nIn the domain of lower limb movement resistance monitoring, MobileNetV3 offers significant advantages. Its efficient architecture allows it to be deployed on wearable devices with limited computational resources, enabling real-time processing of sensor data. The model's ability to extract meaningful features from raw sensor inputs makes it particularly suitable for applications where quick and accurate analysis is essential. Studies have shown that MobileNetV3 can maintain high accuracy while significantly reducing the computational load, making it ideal for continuous monitoring tasks in physical therapy, sports training, and rehabilitation.\nWithin the proposed MMTL-Net for monitoring lower limb movement resistance, the MobileNetV3 module plays a crucial role. This module is responsible for the initial feature extraction from the raw sensor data, providing a robust representation of the input that is used by subsequent modules for activity recognition and resistance estimation. In the context of lower limb movement resistance monitoring, MobileNetV3 specifically extracts a diverse set of features that are essential for accurate analysis. These include movement patterns, such as walking or running, which are fundamental to understanding the overall activity context; joint angles, which provide critical information on the mechanical load on different joints during movement; and activity-specific characteristics that distinguish between different actions like jogging, sitting, or walking. Moreover, MobileNetV3 captures temporal dynamics, which are vital for analyzing the speed and rhythm of the activities, directly influencing the resistance levels encountered. The model also identifies spatial relationships between different parts of the lower limb, aiding in the understanding of coordination and alignment during movements. These comprehensive features collectively ensure that the MMTL-Net model can accurately monitor and predict lower limb movement resistance, providing valuable real-time feedback in applications such as physical therapy, sports training, and rehabilitation.\nThe initial step in the MobileNetV3 architecture is the depthwise convolution, which applies a single convolutional filter per input channel. This operation is mathematically represented as:\n$Z_{depthwise} = \\sum_{i=1}^{N} X_i * K_i$  (1)\nwhere $Z_{depthwise}$ is the output of the depthwise convolution, $X_i$ represents the input channels, $K_i$ is the corresponding depthwise filter, and N is the number of input channels.\nFollowing the depthwise convolution, a pointwise convolution is applied to combine the output of the depthwise convolution across channels. This is expressed as:\n$Z_{pointwise} = \\sum_{j=1}^{M} Z_{depthwise} * P_j$ (2)\nwhere $Z_{pointwise}$ is the output of the pointwise convolution, $Z_{depthwise}$ is the input from the previous depthwise convolution, $P_j$ is the pointwise filter, and M is the number of output channels.\nTo enhance the model's ability to capture channel-wise dependencies, MobileNetV3 integrates a squeeze-and-excitation (SE) module. The squeeze operation is performed by applying global average pooling (GAP) to the output of the pointwise convolution:\n$S = \\sigma(GAP(Z_{pointwise}))$ (3)\nwhere S is the squeeze operation output, $\\sigma$ represents the sigmoid activation function, and GAP is the global average pooling applied to $Z_{pointwise}$.\nThe excitation operation follows, which re-scales the output of the pointwise convolution by the squeeze output:\n$E = S \\cdot Z_{pointwise}$ (4)\nwhere E is the excitation output, S is the squeeze output, and denotes element-wise multiplication.\nThe final output of the MobileNetV3 block is obtained by applying batch normalization and the swish activation function to the excitation output:\n$Z_{output} = \\phi(BN(E))$ (5)\nwhere $Z_{output}$ is the final output of the MobileNetV3 block, $\\phi$ represents the activation function (swish in this case), and BN is batch normalization applied to the excitation output.\nWithin the MMTL-Net framework, the MobileNetV3 module is integral for transforming raw sensor data into high-quality features. These features are then utilized by the multi-task learning module to perform activity recognition and resistance estimation. The feature extraction process is the foundation of the entire system, ensuring that subsequent analyses are based on robust and meaningful representations of the input data. The primary network structure of MobileNetV3 is illustrated.\nIn the context of activity recognition, the extracted features from MobileNetV3 are fed into a series of fully connected layers that classify the type of physical activity being performed. This classification provides essential context for understanding the resistance data and allows the system to differentiate between various movements such as walking, running, and sitting.\nFor resistance estimation, the same extracted features are processed through another set of fully connected layers that predict the resistance encountered during the movement. This estimation is crucial for providing real-time feedback on the intensity of the activity and identifying any abnormal resistance patterns that might indicate potential issues or the need for intervention.\nThe integration of MobileNetV3 within the MMTL-Net framework ensures that the model can handle the computational constraints of wearable devices while delivering accurate and real-time analysis. The synergy between MobileNetV3's efficient feature extraction and the multi-task learning module's capability to handle multiple tasks simultaneously enhances the overall performance of the system, making it a powerful tool for monitoring lower limb movement resistance in practical applications such as physical therapy, sports training, and rehabilitation."}, {"title": "3.3. Multi-Task Learning", "content": "Multi-Task Learning (MTL) is a machine learning paradigm where multiple learning tasks are solved simultaneously, leveraging commonalities and differences across tasks. This approach improves learning efficiency and prediction accuracy for the task-specific models compared to training the models separately. MTL models share representations between related tasks, which allows them to generalize better and be more robust. The fundamental concept of MTL is that by training tasks together, the model can learn a more generalizable feature representation that benefits all tasks involved.\nIn the context of lower limb movement resistance monitoring, MTL offers significant advantages. The ability to perform simultaneous activity recognition and resistance estimation enhances the efficiency and effectiveness of the monitoring system. This dual-task approach ensures that the model can utilize shared representations to improve overall performance, providing more accurate and comprehensive analysis. By leveraging MTL, the system can offer real-time feedback on both the type of activity being performed and the resistance encountered, making it highly beneficial for applications in physical therapy, sports training, and rehabilitation.\nWithin the proposed MMTL-Net, the MTL module is critical for achieving the dual objectives of activity recognition and resistance estimation. The integration of MTL allows the model to share the feature representations extracted by MobileNetV3, enabling it to handle multiple tasks with high accuracy. This module processes the features extracted from sensor data and outputs predictions for both tasks. The activity recognition component classifies the type of movement, while the resistance estimation component predicts the resistance level, providing a comprehensive understanding of the user's physical activity.\nIn the framework of MMTL-Net, input features extracted by MobileNetV3 F are shared between multiple tasks. For activity recognition, the features are passed through a fully connected layer:\n$A = \\phi(W_A F + b_A)$  (6)\nwhere A is the activity recognition output, $W_A$ is the weight matrix, $b_A$ is the bias vector, and $\\phi$ represents the activation function.\nSimilarly, for resistance estimation, the features are processed through another fully connected layer:\n$R = \\psi(W_R F + b_R)$ (7)\nwhere R is the resistance estimation output, $W_R$ is the weight matrix, $b_R$ is the bias vector, and $\\psi$ represents the activation function.\nThe shared loss function for MTL is a combination of the losses from both tasks, ensuring that the model optimizes for both objectives simultaneously:\n$L_{MTL} = \\alpha L_{activity} + \\beta L_{resistance}$  (8)\nwhere $L_{MTL}$ is the combined loss, $L_{activity}$ is the loss for activity recognition, $L_{resistance}$ is the loss for resistance estimation, and $\\alpha$ and $\\beta$ are the weights balancing the contributions of each loss.\nThe activity recognition loss can be defined as the cross-entropy loss for classification:\n$L_{activity} = - \\sum_{i=1}^{C} y_i log(p_i)$ (9)\nwhere $y_i$ is the true label, $p_i$ is the predicted probability for class i, and C is the number of classes.\nThe resistance estimation loss can be defined as the mean squared error for regression:\n$L_{resistance} = \\frac{1}{N} \\sum_{j=1}^{N} (r_j - \\hat{r_j})^2$ (10)\nwhere N is the number of samples, $r_j$ is the true resistance value, and $\\hat{r_j}$ is the predicted resistance value.\nThe MTL module in MMTL-Net is not only responsible for handling the shared representations but also ensures that the outputs from different tasks are effectively integrated to provide comprehensive insights. The activity recognition component helps contextualize the resistance estimation, making it possible to correlate specific activities with the corresponding resistance levels. This is particularly useful for detecting abnormalities or inefficiencies in movements, which can be crucial for designing effective intervention strategies in physical therapy and rehabilitation.\nIn practical application, the MTL module operates seamlessly with the MobileNetV3 feature extraction component. Once the raw sensor data is processed by MobileNetV3, the extracted features are fed into the MTL module. The shared feature space ensures that the model has a unified understanding of the input data, allowing it to perform activity recognition and resistance estimation simultaneously. This integration not only improves the accuracy of each task but also enhances the overall efficiency of the system.\nBy integrating MTL within the MMTL-Net framework, the model can effectively utilize shared representations to perform multiple tasks simultaneously. This approach not only enhances the model's accuracy and robustness but also ensures that it can operate efficiently in real-time applications. The ability to provide comprehensive and immediate feedback on both activity type and resistance level is crucial for practical applications in physical therapy, sports training, and rehabilitation. This dual-task capability makes MMTL-Net a powerful and versatile tool for monitoring lower limb movement resistance, paving the way for more effective and personalized interventions."}, {"title": "4. Experiment", "content": "To evaluate the effectiveness of our proposed MMTL-Net for real-time lower limb movement resistance monitoring, we conducted experiments on the UCI Human Activity Recognition dataset. This dataset is widely used for benchmarking models in human activity recognition and provides a comprehensive evaluation of model performance.\nThe table below compares our proposed MMTL-Net with several recent and prominent models. The metrics include mAP (mean Average Precision), AP50, AP75, APM (for medium objects), APL (for large objects), MOTA (Multiple Object Tracking Accuracy), and MOTP (Multiple Object Tracking Precision). These models are chosen based on their relevance and popularity in recent research.\nThe experimental results  demonstrate the superior performance of our proposed MMTL-Net model compared to other state-of-the-art models on the UCI Human Activity Recognition dataset. Our model achieves the highest mAP of 40.1, significantly outperforming other models such as MyoNet and DeepSense, which achieve mAPs of 32.1 and 37.2 respectively.\nIn terms of AP50 and AP75, MMTL-Net also excels with scores of 78.5 and 67.3, showing a considerable improvement over models like sEMG-CNN and PhysioNet. The APM and APL scores further highlight the robustness of our model in handling both medium and large objects, achieving 77.5 and 80.6 respectively.\nThe tracking performance, indicated by MOTA and MOTP, also underscores the effectiveness of MMTL-Net.\nOur model achieves the highest MOTA of 62.5 and MOTP of 65.2, indicating superior tracking accuracy and precision compared to other models like BiLSTM and TransPose.\nThe MMTL-Net model consistently outperforms other recent models across all evaluated metrics, demonstrating its superior capability in real-time lower limb movement resistance monitoring. This comprehensive evaluation reinforces the robustness and accuracy of our proposed model, making it a highly effective solution for the targeted application.\nTo further evaluate the effectiveness of our proposed MMTL-Net for real-time lower limb movement resistance monitoring, we conducted experiments on the Wireless Sensor Data Mining Activity Prediction dataset. This dataset is specifically tailored for evaluating sensor-based activity recognition systems and provides a robust benchmark for assessing model performance in practical applications.\nFor this evaluation, we focused on metrics that are highly relevant to lower limb movement resistance and real-time monitoring applications. These metrics include Force Error Rate (FER) for resistance estimation accuracy, Resistance Prediction Accuracy (RPA), Real-time Responsiveness (RTR) measured in milliseconds, Model Efficiency Ratio (MER), Computational Load (CL), Power Consumption (PC), Throughput (TP), and Latency (LT). These metrics were selected because they effectively capture the key aspects of the model's functionality in the context of real-time lower limb movement resistance monitoring.\nForce Error Rate (FER): FER was chosen as it quantifies the discrepancy between the predicted resistance forces and the actual forces encountered during physical activities. A lower FER indicates that the model can accurately estimate the resistance experienced by the lower limbs, which is crucial for applications in rehabilitation and sports training where precise feedback is essential for effective intervention.\nResistance Prediction Accuracy: RPA measures the accuracy with which the model predicts the resistance levels associated with different activities. High RPA values reflect the model's ability to correctly identify the resistance conditions, which is important for tailoring training or rehabilitation programs to individual needs.\nReal-time Responsiveness: RTR was selected to assess the model's capability to provide timely feedback, a critical factor for real-world applications. In wearable technology and mobile environments, low latency and high throughput are necessary to ensure that the system can operate effectively without delays, which could hinder the user experience or the effectiveness of the intervention.\nThe experimental results  demonstrate the superior performance of our proposed MMTL-Net model compared to other state-of-the-art models on the Wireless Sensor Data Mining Activity Prediction dataset. Our model achieves the lowest FER of 6.8%, indicating highly accurate resistance estimation, and the highest Resistance RPA of 91.2%, showing significant improvements over models like MyoNet and DeepSense.\nMMTL-Net excels in RTR with the fastest response time of 12 milliseconds, making it highly suitable for real-time monitoring. The MER of 1.7 indicates superior computational efficiency, while the lowest CL of 0.65 demonstrates its lightweight nature. Additionally, MMTL-Net has the lowest PC at 2.0 W, the highest TP of 33 frames per second (fps), and the lowest LT of 15 milliseconds, outperforming all other models in these critical metrics.\nWe compared the performance of the MMTL-Net model against baseline and state-of-the-art methods using these metrics. Our results demonstrate that MMTL-Net significantly outperforms existing models. For instance, compared to traditional deep learning models like standard CNNs and RNNS, MMTL-Net achieved a lower FER of 6.8%, a higher RPA of 91.2%, and an RTR of 12 milliseconds. These improvements can be attributed to the integration of MobileNetV3, which enhances feature extraction efficiency, and Multi-Task Learning (MTL), which allows the model to leverage shared representations across tasks, leading to better overall performance in both accuracy and responsiveness.\nIn terms of Real-time Responsiveness (RTR), the use of MobileNetV3 as the feature extraction backbone plays a crucial role. MobileNetV3's lightweight architecture, which utilizes depthwise separable convolutions, significantly reduces computational complexity while maintaining high accuracy. This efficiency allows the MMTL-Net model to process data quickly, leading to low latency and high throughput, which are essential for real-time applications on wearable devices.\nHowever, it is also worth noting that while MMTL-Net excelled in RTR and RPA, the improvements in Force Error Rate (FER) were relatively modest. This may be attributed to the model's current focus on optimizing overall system performance rather than exclusively minimizing prediction errors. Further enhancements, such as incorporating advanced error correction mechanisms or additional sensor data, could potentially lead to further reductions in FER."}, {"title": "4.1. Datasets", "content": "The UCI Human Activity Recognition Using Smartphones DataSet[89] is a widely utilized dataset in the field of human activity recognition. This dataset comprises data from accelerometers and gyroscopes embedded in smartphones, capturing the motion data of 30 volunteers performing six different activities: walking, walking upstairs, walking downstairs, sitting, standing, and lying down. The dataset contains a total of 10,299 samples, each with 561 features extracted from the raw tri-axial acceleration and gyroscope signals. The data was sampled at a frequency of 50 Hz, ensuring high resolution and detail.\nDuring data collection, each volunteer wore a smartphone on their waist, and the sensors recorded their movements. The dataset underwent standardization processes, including noise reduction and normalization, to ensure data quality and consistency. This dataset is highly valuable for our study as it provides rich and diverse lower limb motion data, essential for training and validating both motion recognition and resistance estimation models. Utilizing this dataset allows researchers to develop more precise and efficient real-time monitoring systems, enhancing performance in motion analysis and rehabilitation training.\nThe WISDM Activity Prediction DataSet[90], collected by the Wireless Sensor Data Mining (WISDM) Lab at Fordham University, is designed for recording human activity data through accelerometers embedded in smartphones. This dataset includes data from 29 participants of varying ages and body types, performing six activities: walking, jogging, ascending stairs, descending stairs, sitting, and standing. The dataset comprises over 1,098,207 samples, each containing tri-axial acceleration data sampled at 20 Hz.\nThe data collection process was rigorously controlled, with participants performing activities in a standardized experimental environment to ensure data consistency and accuracy. The dataset underwent thorough preprocessing, including noise reduction, smoothing, and normalization, to ensure high-quality feature extraction. The WISDM dataset's detailed and high-quality motion data characteristics provide a robust foundation for our multi-task learning model. Using the WISDM dataset enables the training and testing of efficient motion recognition and resistance monitoring models on mobile and resource-constrained devices, facilitating real-time monitoring and feedback.\nThe Mobile Health (MHEALTH) DataSet[91], part of a health application research project, aims to assess the potential of mobile health technologies in daily life activity monitoring and evaluation. This dataset includes data from 10 participants wearing devices equipped with tri-axial accelerometers, tri-axial gyroscopes, and ECG sensors, recording their performance in 12 activities, including walking, running, cycling, and ascending and descending stairs. Each activity's data includes tri-axial acceleration, tri-axial angular velocity, and ECG signals, with a total of 1,144,000 samples.\nThe data collection process for the MHEALTH dataset was highly standardized to ensure the integrity and diversity of the data. Each participant's data was recorded across different daily activities, providing comprehensive motion data features. The dataset underwent preprocessing steps such as noise reduction, standardization, and feature extraction to ensure high quality and consistency. The MHEALTH dataset significantly contributes to our study by offering multimodal motion data features, crucial for researching motion resistance monitoring and multi-task learning models. By utilizing the MHEALTH dataset, researchers can develop more precise and efficient real-time monitoring systems, enhancing performance in motion analysis and rehabilitation training.\nThese datasets provide a rich source of motion data, covering various daily activities and movement patterns. By using these datasets, we can effectively train and validate models for motion recognition and resistance estimation, enhancing the accuracy and practicality of the system. The high quality and detailed feature information of each dataset ensure the reliability and effectiveness of the experimental results, providing a solid foundation for real-time lower limb movement resistance monitoring."}, {"title": "4.2. Experimental Setup and Evaluation Metrics", "content": "Our experiments were conducted in a robust software and hardware environment to ensure efficient and reliable processing. The software environment includes the operating system, deep learning frameworks, and related libraries."}, {"title": "4.2.1. Experimental Environment", "content": "Our experiments were conducted in a robust software and hardware environment to ensure efficient and reliable processing. The software environment includes the operating system, deep learning frameworks, and related libraries."}, {"title": "4.2.2. Model Training", "content": "In the data preprocessing phase, several techniques were applied to ensure the quality and consistency of the input data. The raw sensor data from the chosen datasets (UCI Human Activity Recognition, WISDM Activity Prediction, and MHEALTH) underwent preprocessing steps such as noise reduction, normalization, and segmentation into appropriate time windows. This preprocessing ensures that the data is clean and standardized, making it suitable for training the deep learning models.\nFor network parameter settings, the model employs the Adam optimizer with an initial learning rate set to 0.001. To ensure training stability, a learning rate decay strategy was used, reducing the learning rate by a factor of 0."}]}