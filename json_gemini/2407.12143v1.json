{"title": "False Consensus Biases AI Against Vulnerable\nStakeholders", "authors": ["Mengchen Dong", "Jean-Fran\u00e7ois Bonnefon", "Iyad Rahwan"], "abstract": "The deployment of Al systems for welfare benefit allocation allows for accelerated decision-\nmaking and faster provision of critical help, but has already led to an increase in unfair benefit\ndenials and false fraud accusations. Collecting data in the US and the UK (N = 2 449), we\nexplore the public acceptability of such speed-accuracy trade-offs in populations of claimants\nand non-claimants. We observe a general willingness to trade off speed gains for modest\naccuracy losses, but this aggregate view masks notable divergences between claimants and\nnon-claimants. Although welfare claimants comprise a relatively small proportion of the\ngeneral population (e.g., 20% in the US representative sample), this vulnerable group is much\nless willing to accept Al deployed in welfare systems, raising concerns that solely using\naggregate data for calibration could lead to policies misaligned with stakeholder preferences.\nOur study further uncovers asymmetric insights between claimants and non-claimants. The\nlatter consistently overestimate claimants' willingness to accept speed-accuracy trade-offs,\neven when financially incentivized for accurate perspective-taking. This suggests that policy\ndecisions influenced by the dominant voice of non-claimants, however well-intentioned, may\nneglect the actual preferences of those directly affected by welfare Al systems. Our findings\nunderline the need for stakeholder engagement and transparent communication in the design\nand deployment of these systems, particularly in contexts marked by power imbalances.", "sections": [{"title": "1 Introduction", "content": "The use of Artificial Intelligence (AI) is becoming commonplace in government operations [1-4].\nIn the United States alone, a 2020 survey of 142 federal agencies found that 45% were using or\nplanning to use machine learning algorithms to streamline their operations, increase their capaci-\nties, or improve the delivery of their public services [2]. In the specific context of providing welfare\nbenefits, the main promise of Al is to speed up decisions [4, 5]. For many individuals and families,\nwelfare benefits provide critical assistance in times of financial hardship or emergency. Using AI\nto speed up decisions can avoid delays that would exacerbate these hardships, and decrease the\nperiod of uncertainty and anxiety during which applicants are waiting for a decision. There is,\nhowever, a documented risk that since welfare Al systems often focus on fraud detection, their\nspeed gains come with a biased accuracy loss, increasing the acceptable trade-offs between the\nspeed and accuracy of welfare allocations rate at which people are unfairly denied the welfare\nbenefits they are entitled to [6-11].\nAs a result, government agencies that seek to deploy welfare Al systems must strike a careful\nbalance between speed gains and accuracy losses, and this balance must be informed by public\npreferences [12, 13], for at least two reasons. First, we know that people who lose trust in the AI\nused by one government agency also lose trust in the AI used by other government agencies-if welfare Al systems ignore public preferences when balancing speed and accuracy, they risk\ncreating distrust that can bleed into perceptions of other government services [14, 15]. Second,\nand more immediately, the wrong balance of speed gains and accuracy losses could erode the trust\nof people who need welfare benefits, and make them less likely to apply, for fear of being wrongly\naccused of fraudulent claims [14], especially when the Al system is labeled with foreboding names\nlike 'FraudCaster' [16] or described as a 'suspicion machine' in the media [8, 17]. In sum, it is\nimportant for welfare Al systems to trade off speed and accuracy in a way that is aligned with the\npreferences of the general public as well as with the preferences of potential claimants.\nGreat efforts have been made to understand people's attitudes toward and concerns about\nwelfare Al systems, often focusing on the opinions of the general public [14, 18] or vulnerable\npopulations directly affected by welfare Al systems [11, 19]. Qualitative evidence has also been\naccumulated regarding the divergent preferences of different stakeholders involved in Al gov-\nerning systems [8, 20], contributing to long-lasting philosophical and regulatory discussions on"}, {"title": "2 Results in the US", "content": "Participants in the US (N = 987, representative on age, gender, and ethnicity, 20% self-declaring\nas welfare claimants) indicated their preference between human and Al welfare decisions. We\nvaried the information about speed gains (1/2/3/4/5/6 weeks faster, as compared to a baseline\nwaiting time of 8 weeks if handled by public servants) and accuracy losses (5/10/15/20/25/30%\nmore false rejections than public servants) within a realistic range, based on governmental reports\nand third-party investigations [9, 12, 25, 26], yielding 36 trade-offs (as illustrated in Figure 1).\nIn each trade-off condition, participants indicated their preference on a scale ranging from 0 =\ndefinitely a public servant to 100 = definitely the Al program. Participants were randomly assigned"}, {"title": "3 Results in the UK", "content": "To replicate and extend the results obtained from the US representative sample, we collected data\nfrom N = 1462 participants in the UK with a balanced composition of claimants and non-\nclaimants. Such a balanced sample can help consolidate our pre-registered test on the asymmetry\nin perspective-taking. In addition, we implemented the following changes:\n1. We examined preferences about a specific benefit in the UK (the Universal Credit) and tar-\ngeted a balanced sample between Universal Credit claimants (48%) and non-claimants (52%).\nThe UK government has recently announced the deployment of Al for the attribution of this\nbenefit, raising concerns that the Al system may be biased against some claimants [7].\n2. We adopted a different range of speed (0/1/2/3 weeks faster, as compared to a baseline wait-\ning time of 4 weeks if handled by public servants) and accuracy (0/5/10/15/20% more false\nrejections than public servants) parameters, resulting in 20 trade-offs. Notably, when wel-\nfare Al demonstrates comparable performance (i.e., 0 week faster and 0% more error), people\nwere still in favor of humans making welfare decisions (M = 45.4, SD = 28.7; t = 4.36,\np < .001).\n3. We added financial incentives for participants to correctly predict the preferences of the other\ngroup, that is, when non-claimants predict claimants' preference and claimants predict non-\nclaimants' preference. We also asked non-claimants whether they had claimed welfare benefits\nin the past, whether they thought they may claim benefits in the future, and whether they were\nacquainted with people who were welfare claimants, to assess whether these circumstances\nmade it easier to adopt the perspective of claimants.\n4. For each trade-off, we additionally asked participants whether their trust in the government\nwould decrease or increase (from 0 = decrease a lot decrease a lot to 100 = increase a lot) if the\ngovernment decided to replace public servants with the Al program they just considered.\n5. Finally, we added a treatment that made explicit the existence of a procedure to ask for redress\nin case a claimant felt their claim was unfairly rejected. Even though participants in the human\nredress condition believed in the chance to appeal (\u03b2 = 0.37, p < .001; vs. the redress condi-\ntion), this clarification did not impact trade-off preferences (\u03b2 = 0.03, p = .210). Therefore,\nwe pool the data from this treatment with that of the baseline treatment. Full analyses of this\ntreatment are presented in the Supplementary Information.\nAgain, when participants responded from their own perspective (N = 739), their willingness\nto let Al make decisions was influenced both by speed gains (\u03b2 = 0.34, p < .001) and accuracy\nlosses (\u03b2 = 0.44, p < .001). Overall (see Figure 4), they traded off a 1-week speed gain for a\n5 percentage point loss of accuracy. Among these UK participants, 47% self-declared as current\nclaimants of the Universal Credit. As in the US study, for all 20 trade-offs, welfare claimants\nshowed greater average aversion to letting Al make welfare decisions (\u03b2 = -0.09, p = .008),\nwith an average difference of 5.7 points (range: 0.1 to 8.7, see Fig. 5A). In both groups, we observe\na strong correlation across trade-offs between the aversion to letting the Al make decisions, and\nthe loss of trust in the government that would deploy this AI (r = .77 for claimants, and r = .84 for\nnon-claimants)."}, {"title": "4 Discussion", "content": "One primary advantage of using Al for welfare benefit allocation is quicker decision-making,\nallowing claimants to receive support faster [4, 5]. However, these systems often result in an accu-\nracy loss, potentially leading to unfair denials or false fraud accusations [6-11]. Governments\nmust carefully balance these trade-offs to maintain public trust [14, 27]. Indeed, we found that"}, {"title": "5 Methods", "content": "Both of the US and UK studies were approved by the ethics committee at the Max Planck Insti-\ntute for Human Development, and obtained informed consent from all participants. Data were\ncollected in February 2022 and September 2022, respectively. All participants were recruited on\nProlific for a study named \u201cArtificial Intelligence in Social Welfare\u201d, and were paid \u00a31.6 upon com-\npletion. Participants in the UK study who had to predict the answers of the other group received\nan additional \u00a30.03 for each response that fell within 5 points of this other group's average.\nBoth studies were hosted on Qualtrics. After providing informed consent and basic demo-\ngraphic information (age, gender, education, income, and political ideology), participants were\ninstructed to take a claimant or non-claimant perspective. To familiarize themselves with the\nstimuli and response scale, they were first shown two extreme trade-offs in the survey, as train-\ning examples. They answered these two examples, and had a chance to review and change their\nanswers. Then the survey started, and all targeted trade-offs were shown in random order, not\nincluding the two trade-offs that were shown as examples during the training phase. Complete\ndescriptions of our design materials, and survey questions are included in the Supplementary\nInformation."}, {"title": "5.1 The US study", "content": "Participants. We had N = 987 participants from the United States, who were representative\non age (M = 45.3, SD = 16.3), gender (473 males and 514 females), and ethnicity (77.8%"}, {"title": "5.2 The UK study", "content": "Participants. We performed a simulation-based power analysis for multilevel regression mod-\nels, which suggested that a sample of N = 800 would allow us to detect the interaction effect of\nAl performance, claimant status, and perspective-taking with higher than 80% power at an alpha\nlevel of 0.05 (see the pre-registration at https://tinyurl.com/welfareAlregistration). We therefore\naimed for N = 1600 participants in the United Kingdom given our additional between-subjects\nhuman redress manipulation. As pre-registered, we filtered out participants who provided differ-\nent answers to one identical welfare status question (\"Are you a recipient of Universal Credit?\";\nAnswer: \"Yes/No\"), which was embedded both in the Prolific system screener and our own sur-\nvey. After the screening, we eventually had N = 1 462 participants (age: M = 37.6, SD = 11.1;\nethnicity: 88.4% White, 3.0% Black, 5.6% Asian, 2.7% Mixed, and 0.3% other), with relatively bal-\nanced compositions of males and females (42.7% male, 55.9% female, 1.4% other), and welfare\nclaimants (47.9%) versus non-claimants (52.1%).\nDesign and procedure. Study 2 examined a real-life social benefits scheme in the UK \u2013 Uni-\nversal Credit (https://www.gov.uk/universal-credit). We employed a mixed design with three\nbetween-subjects and two within-subjects factors. As between-subjects factors, we recruited both\nUniversal Credit claimants and non-claimants, and randomly assigned them to take a Univer-\nsal Credit claimant or a controlled taxpayer perspective. They were then randomly assigned to a\nno redress or a human redress condition, which differed on whether claimants could appeal to"}, {"title": "5.3 Data availability", "content": "All anonymized data can be found on Open Science Framework (at https://tinyurl.com/\nwelfareAl; and will be made publicly accessible upon acceptance of the work)."}, {"title": "5.4 Code availability", "content": "All code necessary to reproduce all analyses can be found on Open Science Framework (at https:\n//tinyurl.com/welfareAl; and will be made publicly accessible upon acceptance of the work)."}]}