{"title": "RECIPROCAL LEARNING", "authors": ["JULIAN RODEMANN", "CHRISTOPH JANSEN", "GEORG SCHOLLMEYER"], "abstract": "We demonstrate that a wide array of machine learning algorithms are specific\ninstances of one single paradigm: reciprocal learning. These instances range from active\nlearning over multi-armed bandits to self-training. We show that all these algorithms do\nnot only learn parameters from data but also vice versa: They iteratively alter training\ndata in a way that depends on the current model fit. We introduce reciprocal learning\nas a generalization of these algorithms using the language of decision theory. This allows\nus to study under what conditions they converge. The key is to guarantee that reciprocal\nlearning contracts such that the Banach fixed-point theorem applies. In this way, we find that\nreciprocal learning algorithms converge at linear rates to an approximately optimal model\nunder relatively mild assumptions on the loss function, if their predictions are probabilistic\nand the sample adaption is both non-greedy and either randomized or regularized. We\ninterpret these findings and provide corollaries that relate them to specific active learning,\nself-training, and bandit algorithms.", "sections": [{"title": "1. INTRODUCTION", "content": "The era of data abundance is drawing to a close. While GPT-3 [9] still had to make do with\n300 billion tokens, Llama 3 [111] was trained on 15 trillion. With the stock of high-quality\ndata growing at a much smaller rate [72], adequate training data is likely to run out within\nthis decade [62, 116]. Generally, and beyond language models, machine learning is threatened\nby degrading data quality and quantity [64]. Apparently, learning ever more parameters from\never more data is not the exclusive route to success. Models also have to learn from which\ndata to learn. This has sparked a lot of interest in sample/data efficiency [75, 100, 120, 8, 50,\n26, 114], subsampling [51, 110, 76], coresets [67, 81, 94], data subset selection [59, 122, 13, 87],\nand data pruning [30, 127, 61, 5] in recent years and months.\nInstead of proposing yet another method along these lines, we demonstrate that a broad\nspectrum of well-established machine learning algorithms already exhibit a reciprocal relation-\nship between data and parameters. That is, parameters are not only learned from data but\nalso vice versa: Data is iteratively chosen based on currently optimal parameters, aiming to\nincrease sample efficiency."}, {"title": "2. RECIPROCAL LEARNING", "content": "Machine learning deals with two pivotal objects: data and parameters. Typically, parameters\nare learned from data through ERM. We argue, however, that in various branches of machine\nlearning, the relationship between data and parameters is in fact reciprocal. That is, parameters\nare not only learned based on data but also data are added or removed based on parameters.\nIn what follows, we show that this corresponds to two interdependent decision problems and\nexplicitly study how learned parameters affect the subsequent training data. We emphasize\nthat our analysis will focus on reciprocity between parameters and training data only. The\npopulation and test data thereof are assumed to be fixed. Specifically, we call a machine\nlearning algorithm reciprocal if it performs iterative ERM on training data that depends\non the previous ERM, see definition 1. This latter dependence can have various facets, see\nsections 3 and 5 for concrete examples. Broadly speaking, it can be induced by any kind of\ndata collection, removal, or generation that is affected by the model fit. In particular, it can\nbe stochastic (think of Thompson-sampling in multi-armed bandits) as well as deterministic\nin nature (think of maximizing a confidence measure in self-training)."}, {"title": "3. FAMILIAR EXAMPLES OF RECIPROCAL LEARNING", "content": "We will demonstrate that well-established machine learning procedures are special cases\nof reciprocal learning. We start by illustrating reciprocal learning by self-training in semi-\nsupervised learning (SSL) and then turn to active learning and multi-armed bandits."}, {"title": "3.1. Self-Training", "content": "For ease of exposition, we will start by focusing on binary target variables, i.e., the image\nof Y is {0,1}, with real-valued features X. Moreover, we will only consider cases where the\nsample changes through the addition of one instance per iteration. Leaning on [115, 12, 112"}]}