{"title": "A Taxonomy of Architecture Options for\nFoundation Model-based Agents: Analysis and\nDecision Model", "authors": ["Jingwen Zhou", "Qinghu Lu", "Jieshan Chen", "Liming Zhu", "Xiwei Xu", "Zhenchang Xing", "Stefan Harrer"], "abstract": "Abstract-The rapid advancement of AI technology has led\nto widespread applications of agent systems across various\ndomains. However, the need for detailed architecture design poses\nsignificant challenges in designing and operating these systems.\nThis paper introduces a taxonomy focused on the architectures\nof foundation-model-based agents, addressing critical aspects\nsuch as functional capabilities and non-functional qualities. We\nalso discuss the operations involved in both design-time and\nrun-time phases, providing a comprehensive view of architec-\ntural design and operational characteristics. By unifying and\ndetailing these classifications, our taxonomy aims to improve\nthe design of foundation-model-based agents. Additionally, the\npaper establishes a decision model that guides critical design\nand runtime decisions, offering a structured approach to enhance\nthe development of foundation-model-based agents. Our contri-\nbutions include providing a structured architecture design option\nand guiding the development process of foundation-model-based\nagents, thereby addressing current fragmentation in the field.\nIndex Terms-Foundation Model, Large Language Model,\nLLM, Agent, Software Architecture, Taxonomy", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid advancement of AI technology, particularly foun-\ndation models, has led to widespread applications of foun-\ndation model based agent systems across various domains,\nfrom healthcare and finance to autonomous driving and smart\nmanufacturing [1, 2, 3, 4]. These foundation-model-based\nagent systems have the potential to revolutionize industries by\nenhancing efficiencies, enabling automation, and facilitating\ncomplex decision-making processes [5].\nRecent innovations in AI demonstrate the versatility\nof foundation-model-based agents. For example, Auto-GPT\nfor autonomous task management and internet searches 1,\nBabyAGI has evolved from simple code to include function-\nalities such as robotics and code-writing 2.\nMoreover, existing studies often focus narrowly on specific\naspects of AI agents, such as their functional capabilities\nor performance metrics. For example, the development of\nGPT4 by OpenAI [6] has shown significant advancements\nin prompt engineering. Similarly, the integration of retrieval-\naugmented generation (RAG) [7] has improved the ability\nof AI systems to generate contextually relevant responses by\nretrieving information from external databases. Additionally,\ntools like LangChain and Hugging Face 34, which facilitate the\nintegration of multiple AI models and data sources, are often\ndiscussed in isolation. These advancements, while significant,\nare often not considered together in a holistic framework\nthat addresses the overall architectural design and operational\ncharacteristics of AI agents. This fragmented approach can\nresult in a lack of comprehensive analysis of agent architecture\noptions.\nDespite the innovative application of foundation model-\nbased agents like AutoGen and MetaGPT [8, 9], a significant\ngap exists in the systematic analysis of their architectural\ndesigns. Taxonomies are employed in the software architecture\ncommunity to deepen the understanding of current technolo-\ngies [10]. These agents, which harness cutting-edge technolo-\ngies and introduce new operational paradigms, underscore\nthe necessity for a unified taxonomy that can standardize\nthe classification and elucidate the varying capabilities of\nsuch systems. Current frameworks are robust, while often"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "overlooking the critical evaluation of how these architectures\ncan be optimized for better functionality.\nTherefore, we propose a comprehensive taxonomy for\nfoundation-model-based agents. Developed through a system-\natic literature review (SLR), this taxonomy categorizes both\nthe functional capabilities and non-functional qualities of these\nagents, aiming to serve as a cornerstone in the software\narchitecture community. It offers a deeper understanding and\nstreamlined design options for complex systems, enhancing\nthe design process and facilitating robust comparisons and\nassessments of design alternatives. Specifically, the taxon-\nomy provides detailed classifications including input modal-\nity support, access to underlying models, and integration\nof external capabilities. This structured approach not only\nensures effective agent coordination and communication but\nalso serves as a comprehensive guide for software architects\nin designing foundation-model-based agent systems. The main\ncontributions of this paper are as follows:\nFirstly, it introduces a nuanced taxonomy that categorizes\nagents based on input modality, access to models, external ca-\npabilities, agent coordination, agent communication, etc. This\ntaxonomy analyzes different design options and the trade-offs\nof quality attributes, providing a comprehensive framework\nthat serves as a definitive guide for designing and enhancing\nagent-based architectures. Secondly, the paper establishes a de-\ncision model that offers a structured approach to guide design\ndecisions. This decision model provides a design guide that\nenhances the strategic planning and execution of foundation\nmodel-based agents, ensuring that critical design and runtime\ndecisions are well-informed.\nSpecifically, Section II discusses the related work. Section\nIII discusses the methodology. Section IV delves into the\ndetailed taxonomy and design model, elaborating on agent\ncharacteristics, capabilities, design-time structures, and run-\ntime operations. Section V introduces the threats to validity.\nFinally, Section VI concludes the paper, summarizing our key\nfindings and outlining future research directions.\nII. BACKGROUND AND RELATED WORK\nRecent advancements in foundation-model-based agent sys-\ntems have seen significant contributions from major tech\ncompanies, focusing on enhancing the capabilities and ap-\nplications of these systems through large language models\n(LLMs) and innovative multi-agent systems. For instance,\nGoogle introduced several AI-driven features at their I/O 2023\nevent, including the new PaLM2 model, which is optimized\nfor various tasks such as logic, reasoning, and multilingual\nunderstanding [11]. This model is integrated into over 25\nnew products, enhancing their functionality across domains\nlike coding, writing, and mathematics. Google's advancements\nwith Bard [12] and the PaLM 2 model illustrate the poten-\ntial of LLMs in enhancing agent functionalities [13]. These\nadvancements illustrate how Google is leveraging LLMs to\ncreate more sophisticated and versatile AI agents capable of\nperforming diverse tasks effectively.\nIn addition to Google's contributions, several other archi-\ntectures and frameworks have emerged as key players in the\ndevelopment of foundation-model-based agents. Meta's ad-\nvancements with their GenAI infrastructure, including highly\nefficient and scalable LLMs like LLaMA 2, have set a new\nstandard for AI-driven capabilities [14, 15]. Furthermore,\nMetaGPT attempts to emulate the structure of traditional soft-\nware companies by assigning roles such as project managers\nand engineers to agents, fostering collaborative development\nof user-defined coding tasks [9]. These developments high-\nlight Meta's focus on building scalable and collaborative AI\nagent systems. Microsoft has made substantial advancements\nwith its AutoGen framework [8], an open-source system\ndesigned to facilitate the communication and collaboration\nof multiple AI agents, thereby improving performance and\nreducing errors [16]. Microsoft Copilot integrates AI into\nvarious tools, enhancing productivity for different roles, while\nAzure AI infrastructure supports the scalability of generative\nAI applications with powerful NVIDIA GPUs. Furthermore,\nframeworks like CrewAI and LangChain have gained traction\nfor their innovative approaches to agent coordination and\nworkflow integration. CrewAI focuses on enhancing multi-\nagent collaboration through distributed learning mechanisms\n[17], while LangChain integrates LLMs with various tools and\nplatforms to enable the seamless execution of complex tasks\n[18].\nDespite significant advancements in foundation-model-\nbased agent systems, a notable gap persists in the com-\nprehensive analysis and standardization of agent architecture\noptions. For example, the AIOS platform integrates LLMs to\ncreate a cohesive environment for autonomous agents [19],\nhowever, it does not address the need for a standardized\napproach to defining agent roles and capabilities comprehen-\nsively. Similarly, while the MATOM-SNN framework leverages\nspiking neural networks for enhanced multi-agent cooperation\nand competition, it too lacks a unified taxonomy that would\nstandardize these systems [20]. Moreover, IBM's initiatives\nunderscore the challenges of integrating LLMs into automation\nframeworks but fall short in offering a standardized framework\nthat clearly defines agent roles and capabilities [21].\nMeanwhile, recent research studies underscore diverse chal-\nlenges and advancements in LLM-based autonomous agents.\nOne survey highlights the extensive use of LLMs in au-\ntonomous agent frameworks, focusing on how these models\nenhance agent intelligence and functionality but criticizes the\nlack of standardized architectures necessary for integration\n[22]. Another study highlights how advancements in prompt-\ning techniques enhance model efficiency, yet overlook the\nneed for architectural standardization [23]. Additional work\nreviews progress and challenges in the field of multi-agent\nsystems enhanced by LLMs, emphasizing the need for a\nstandardized framework to integrate these systems cohesively\n[24]. Researchers in [25] explore the capabilities of LLMs to\nsimulate human-like decision-making, emphasizing the need\nfor more robust frameworks to support the scalability and"}, {"title": "III. METHODOLOGY", "content": "ethical deployment of such technologies. Moreover, the study\ninvestigated workflows and components in LLM agents sug-\ngesting potential efficiencies but lacking unified architectural\nintegration [26]. These studies point out the necessity for\ncomprehensive design architecture that can evaluate and sys-\ntematically integrate these technologies into existing and new\nsystems.\nOur work aims to fill this gap by offering a detailed\ntaxonomy-based design architecture, ensuring a holistic and\nsystematic approach to integrating these advanced technolo-\ngies into scalable and ethically responsible systems.\nIII. METHODOLOGY\nOur research study employed a structured and compre-\nhensive approach to address architectural design challenges\nin systems integrating foundation model-based agents. This\nmethodology can be divided into three main phases: a sys-\ntematic literature review (SLR), an extensive review, thematic\ncoding, and the development of a taxonomy.\nA. Systematic Literature Review (SLR)\nPaper Searching: We conducted literature searches in\nvarious academic databases and journals using predetermined\nkeywords related to foundation model-based agents. This ini-\ntial search aimed to gather a broad range of relevant academic\npublications and scholarly works (300 papers).\nSnowballing: To ensure thoroughness, we applied both\nforward and backward snowballing techniques. Forward snow-\nballing involved examining the citations of initially identified\npapers, while backward snowballing entailed reviewing refer-\nences within those papers to identify additional relevant studies\n(100 papers).\nInclusion & Exclusion Criteria: We established a set\nof inclusion and exclusion criteria to filter the papers. This\nstep ensured that only studies meeting specific relevance and\nquality standards were selected for further analysis."}, {"title": "Quality Assessment:", "content": "The selected papers underwent a\nrigorous quality assessment process to ensure the robustness\nand reliability of the included studies. This step was crucial\nto maintain the integrity of our data extraction (68 studies).\nData Extraction: Finally, we extracted relevant data from\nthe qualifying studies. This phase involved a detailed exam-\nination and synthesis of information from 87 studies, which\nwere deemed suitable for our analysis.\nB. Extensive Review\nGrey Literature Review: Beyond academic publications,\nwe reviewed grey literature to capture the latest trends and\napplications of foundation model-based agents. This included\ntechnical reports, white papers, and other non-peer-reviewed\ndocuments (9 studies).\nReal-World Application Analysis: To understand practical\nimplementations, we analyzed known real-world applications\nof foundation model agents. This involved scrutinizing official\nwebsites, available documents, and case studies of organiza-\ntions utilizing these agents (10 studies).\nC. Thematic Coding\nOur thematic coding process utilized a hybrid approach,\ncombining both deductive and inductive methods to achieve\na comprehensive understanding of foundation-model-based\nagents. This hybrid approach allowed us to systematically\ncategorize the extracted metrics into a structured yet adaptable\nframework. The predefined criteria provided a clear direction\nfor our analysis, while the emergent sub-criteria offered depth\nand nuanced insights, resulting in a robust and thorough\ncomprehension of the agents' architecture.\nDeductive Coding: We initiated our process with two broad\npredefined criteria: functional capabilities and non-functional\nqualities. These criteria guided the initial categorization of the\nextracted metrics, ensuring a focused and structured analysis.\nEmergent Sub-Criteria: As the coding process progressed,\nsub-themes emerged organically based on patterns, similar-\nities, and differences observed in the data. This inductive\nmethod enabled us to capture detailed and context-specific\naspects of the metrics, enriching our understanding of their\ninterrelationships and significance.\nRefinement and Integration: The emergent sub-criteria\nwere continuously refined and integrated into the overarching\npredefined themes. This iterative process ensured that our\nthematic structure accurately reflected the complexities and\nsubtleties of the data, providing a comprehensive framework\nfor analysis.\nInternal Validation: To validate our thematic structure, one\nauthor conducted the initial coding, followed by a review and\nfeedback process involving six authors. This collaborative val-\nidation ensured consensus and accuracy in our categorization.\nUpon completing the literature review and thematic coding,\nour analysis identified twelve key taxonomy branches, sys-\ntematically categorized under two primary criteria: functional\ncapabilities and non-functional qualities. These branches align"}, {"title": "IV. TAXONOMY OF FOUNDATION-MODEL BASED AGENTS", "content": "with the overarching pillar criteria depicted in our taxonomy\nframework.\nD. Development of the Taxonomy and the Decision Model\nCombining findings from the literature review, and thematic\ncoding, we developed a taxonomy and a decision model of\narchitecture options for foundation model-based agents. This\ntaxonomy focused on two main aspects: functional capabilities\nand non-functional qualities. To guide our taxonomy and\ndecision model development, we formulated the following\nresearch questions (RQs):\nRQ1: What are the key functional capabilities of\nfoundation-model-based agents?\nRQ2: What are the non-functional qualities that influence\nthe performance and reliability of foundation-model-based\nagents?\nRQ3: How can a decision model act as a design guide to\nstreamline the development of foundation-model-based agents\nin complex decision-making environments?\nThrough this systematic and extensive methodology, we aim\nto provide clear and structured guidance for the architectural\ndesign of foundation model-based agents, thus supporting\nfuture research and practical application development in the\nfield.\nIV. TAXONOMY OF FOUNDATION-MODEL BASED AGENTS\nIn this section, we present a taxonomy that defines ar-\nchitecture design options for foundation-model-based agents.\nThe taxonomy is structured into two categories: functional\ncapability (Section IV-A - Section IV-I) and non-functional\nqualities (Section IV-J). We discuss the characteristics of each\ndesign option to consider during the building process and their\nimpact on the foundation-model-based agents.\nA. Input Modality\nModality defines whether an agent operates using a single\nmodality or multiple modalities. Single-modality agents uti-\nlize one type of input such as text, vision, or audio\n,\nmaking them ideal for straightforward tasks that require\nless computational resources and simpler data interpretation.\nFor instance, text-based chatbots or vision-only surveillance\nsystems operate within this single modality [27]. In contrast,\nmulti-modality agents combine video/audio/image/text inputs\nuploaded by humans, and understand the operational and en-\nvironmental context, enabling a more comprehensive and rich\ninteraction with their environment. This enhanced capability\nallows them to handle more complex tasks like autonomous\nnavigation or interactive virtual assistants that respond not only\nto voice commands but also to visual and contextual cues. This\napproach not only facilitates richer user interactions but also\naligns with the evolving demands of dynamic environments\nwhere adaptability and context awareness are crucial [28]."}, {"title": "B. Access to Underlying Models", "content": "1) Underlying Model Types: Non-AI-based agents oper-\nate without employing artificial intelligence techniques. They\ntypically rely on predefined scripts, workflows, or simple\nautomation rules that do not involve learning or adapting\nover time. Non-AI-based agents are effective in environments\nwhere tasks are repetitive and straightforward, as they execute\ntasks exactly as specified by their programming. While they\nare fragile and sensitive to the input. An example of a non-\nAI-based agent is a basic automation script that processes\nincoming emails and sorts them into different folders based\non predefined keywords.\nFor AI-based agents, we consider two types in terms\nof their purposes: narrow AI-based agents and\ngeneral purpose AI(GPAI)-based agents.\nNarrow AI-based agents are designed to perform\nspecific tasks or solve particular problems. These agents use\nmachine learning and other AI techniques to improve their\nperformance in their specialized domains [29]. These agents\nare effective within their domains but lack generalization\ncapabilities. GPAI-based agents aim to perform various\ntasks across different domains. They are designed with broader\ncapabilities, leveraging extensive datasets and sophisticated\nalgorithms to adapt to multiple environments and challenges\n[30, 31]. GPAI-based agents can switch between tasks, learn\nfrom diverse experiences, and apply their knowledge to new,\nunforeseen problems, making them more versatile compared\nto narrow Al agents. This adaptability is achieved through\nadvanced architectures and continuous learning mechanisms,\nwhich enable GPAI-based agents to update their models and\nimprove over time.\n2) Model Composition: The composition of agent mod-\nels is crucial for optimizing performance and scalability in\nagent-based systems. Various configurations can be adopted\ndepending on the complexity and requirements of the system.\nA single-model agent handles all tasks, which is suitable for\nsimpler systems with a limited scope. This approach minimizes\ncomplexity but may not scale well for diverse tasks [24, 32].\nIn more complex systems, multi-model configurations are\noften employed. Multiple models are used to handle differ-\nent tasks or to enhance performance. One approach is the\nmixture of experts, where different models specialize\nin different tasks, and the system dynamically selects the\nappropriate model for each task [33]. Another approach is the\nensemble method, where multiple models work together\nto improve accuracy and robustness by combining their outputs\n[34]. Additionally, model merging involves combining dif-\nferent models to create a more capable composite model, such\nas merging language models and visual recognition models for\na comprehensive virtual assistant [35]. A hybrid model\ncombines various types of models, such as rule-based and\nlearning-based models, to leverage their respective strengths.\nThis approach is used in cybersecurity systems that employ\nrule-based detection for known threats and machine learning\nmodels for anomaly detection [36]."}, {"title": "C. Access to External Capabilities", "content": "1) Memory Management: Memory management is critical\nfor foundation-model-based agents to store, retrieve, and uti-\nlize information effectively.\n\u2022 Memory Types: Long-term memory retains information\nover long periods, which is essential for tasks that re-\nquire historical data, knowledge, past observations, and\npast experiences [37, 38]. Short-term memory, on the\nother hand, handles short-term information relevant to\nimmediate tasks [39]. This type of memory is useful for\ntemporary activities that do not require long-term stor-\nage, for example, configuration, working context, recent\nevents, and the information within the context window\nof the FM [40]. Selective forgetting enables agents to\ndiscard irrelevant or outdated information, ensuring that\nthey maintain optimal performance without being bogged\ndown by unnecessary data [41, 42]. This capability is\ncrucial in dynamic environments where the relevance of\ndata changes rapidly.\n\u2022 Memory Format: In the foundation-model-based agent\nsystems, several distinctive structures offer unique ad-\nvantages and serve as pivotal design options depend-\ning on specific application needs. Natural language\nmemory, as used in systems like Reflexion [43] and\nVoyager [44], provides a flexible format that stores in-\nformation in an easily understandable form, facilitating\nintuitive interaction and preserving rich semantic details\nto guide agent actions. Embedding memory, exempli-\nfied by MemoryBank [45] and ChatDev, encapsulates\nmemory information into compact embedding vectors,\nsignificantly enhancing the efficiency of memory retrieval\nprocesses. Databases allow for robust memory manipu-\nlation; systems like ChatDB [46] and DB-GPT [47] use\ndatabases to enable precise memory operations through\nSQL queries, providing structured and efficient data man-\nagement. Structured lists are employed in models such\nas GITM [48] and RET-LLM [49], where memory is\nsystematically organized in lists or hierarchical structures\nthat clearly define the relationships between elements and\nfacilitate rapid data access. Each format presents distinct\nadvantages: natural language for clarity and semantic\nrichness, embeddings for retrieval speed, databases for\nstructured manipulation, and lists for organized and hi-\nerarchical memory storage. These memory formats can\nbe integrated, as demonstrated by GITM, which uses\na hybrid approach combining key-value pairs with em-\nbeddings and natural language to maximize retrieval\nefficiency and content comprehensiveness, providing mul-\ntiple design options to optimize agent performance based\non the specific needs of the application.\n\u2022 Memory Operation: Agents can acquire, accumulate,\nand utilize knowledge through interactions with their\nenvironment via various operations. These operations\ninclude memory reading, writing, reflection, and sharing.\nMemory reading involves extracting valuable informa-"}, {"title": "D. Role-Playing", "content": "tion based on recency, relevance, and importance to\nenhance the agent's actions [48, 50]. Memory writing\nfocuses on storing perceived environmental information\nwhile managing duplication and preventing overflow [6].\nMemory reflection enables agents to summarize and\ninfer high-level insights from past experiences, facili-\ntating more abstract and complex decision-making [50].\nMemory sharing allows agents to access and contribute\nto a common memory pool. This enhances their collab-\norative abilities by integrating diverse experiences and\nknowledge [38, 51, 52]. In foundation-model-based agent\nsystems, memory sharing involves storing and retrieving\nshared memories, which supports continuous learning\nand adaptation, helping agents use the most relevant\ninformation for tasks.\n2) Context: Context management focuses on gathering and\norganizing the context within which the agent operates to\nbetter understand the user's intentions and goals [27]. There\nare various of context types of information, such as screen\nrecordings [53], mouse clicks, typing patterns, eye tracking,\ngestures [54], and annotations. These types of context in-\nformation are crucial for accurately interpreting user goals.\nWhen it comes to goal seeking, there are two methods:\npassive suggestion and proactive suggestion.\nPassive suggestion analyzes goals explicitly articulated by the\nuser through text prompts submitted via a dialogue interface\n[55, 56]. In contrast, the proactive suggestion goes beyond\nexplicit text prompts by interpreting the user interface of\nrelevant tools and interactions, using multimodal context in-\nformation to anticipate user goals [54]. From an architectural\nperspective, passive suggestions offer straightforward goal\ninterpretation, while proactive suggestions use rich context\ninformation for more accurate predictions, providing diverse\noptions for developing adaptable and intelligent systems.\n3) Tool:\n\u2022 Tool Interface: foundation-model-based agents can lever-\nage APIs and UI understanding to interact with external\ntools and resources. Using APIs, these agents can directly\ncall specific functions or retrieve data from other systems,\nensuring seamless integration and efficient performance\n[25, 57, 58, 59]. APIs provide a standardized way for\nagents to access a wide range of functionalities, from\nretrieving real-time data to executing complex operations,\nthus enhancing their adaptability and robustness in vari-\nous applications. On the other hand, UI understanding\nenables agents to interact with tools and applications\nthrough their graphical interfaces [60]. This approach is\nparticularly useful when APIs are unavailable or insuf-\nficient [60, 61]. By analyzing visual elements, screen\nrecordings, mouse clicks, and user interactions, agents\ncan comprehend and navigate UIs to achieve their goals.\nThis dual capability of using APIs and UI understanding\nallows foundation-model-based agents to operate effec-\ntively in diverse environments, improving their flexibility\nand operational efficiency."}, {"title": "F. Planning", "content": "\u2022 Tool User Type: In the architecture of foundation-model-\nbased agents, the ability to discover and integrate tools\nis crucial for enhancing adaptability. This involves con-\nsidering different types of tool users, such as agents\nthemselves or human users. The user experience-\ndriven tools are tailored to evolve based on direct\nuser interactions, significantly improving usability and\noverall user satisfaction [62, 63]. Such advancements are\npivotal in shaping how agents interact in user-centric\nenvironments. For example, such as those documented\nby Google, underscore the potential of user feedback to\nrefine AI tools dynamically, making them more intuitive\nand aligned with user needs [64]. On the other hand,\nagent experience driven tools harness historical data\nto refine and optimize operational strategies continuously\n[65, 66]. This methodology is particularly beneficial in\nenvironments characterized by variability and change,\nenhancing the agent's decision-making processes and\noperational efficiency.\n\u2022 Tool Learning: Tool learning emphasizes how agents\nacquire new tool usage capabilities. This process can\nbe categorized into API-based learning and UI-based\nlearning. In API-based learning, agents learn to use\ntools by interacting with APIs. This involves under-\nstanding and executing programmatic instructions, which\nenhances their functionality and efficiency [59]. In UI-\nbased learning, agents learn to use tools by reading and\ninterpreting UI interfaces. For instance, UTA (Universal\nTool for Agents) exemplifies this approach by traversing\nUI elements to build a graph and subsequently learning\nhow to use the tools through these interactions [67].\n4) Planning Engine: The Planning engine serves as a cen-\ntral component in foundation-model-based agents, orchestrat-\ning the high-level planning activities necessary for strategic op-\nerations. This engine is crucial for enabling agents to process\nreasoning, generate plans, monitor their execution, and adapt\ndynamically to new inputs and environmental shifts, enhancing\nthe agents' effectiveness and adaptability in diverse settings\n[65, 68, 69]. This can be divided into two primary strategies:\nInternal planner and external planner, each addressing\ndifferent operational needs within the system. Internal planners\nare embedded within the agent's core architecture and utilize\nthe agent's intrinsic capabilities to autonomously generate\nand execute plans. External planners incorporate specialized,\ndomain-specific tools that extend the basic functionalities\nof the planning engine to tackle complex, high-stakes tasks\nrequiring detailed and precise planning [70]. These planners\nenhance the system's planning capabilities by translating intri-\ncate task descriptions into structured action sequences, which\nare then executed by the agents' foundational models. This\nnot only ensures robust plan formulation but also adapts the\nexecution strategies to meet the specific demands of the tasks.\n5) Workflow: Workflow in foundation model-based agents\ncan be organized into two designs: centralized and decen-\ntralized workflow. Centralized workflow concentrates task"}, {"title": "I. Learning Capability", "content": "management at a single control point, enhancing operational\nconsistency but potentially leading to bottlenecks\u2014a scenario\nsimilar to centralized coordination in agent systems (refer to\nagent coordination section IV-G1). In contrast, decentralized\nworkflow spreads task control across multiple agents, increas-ing system flexibility and resilience, reflecting principles found\nin distributed coordination strategies. Significantly, workflow\nis dedicated to the procedural execution of tasks, which is\ndistinct from strategic planning (section IV-F) and the focus\non inter-agent interactions characteristic of agent coordination.\nD. Role-Playing\nIn foundation-model-based agent systems, the roles of\nagents are crucial as they define the functions and interac-\ntions within the system. The agents can be categorized into\ntwo types: agent-as-a-coordinator and agent-as-a-worker.\nAgents in the coordinator role primarily formulate high-\nlevel strategies and orchestrate the execution of tasks by\ndelegating task execution responsibilities to other agents, ex-\nternal tools, or non-agent systems, ensuring that tasks are\nallocated efficiently and that the system operates cohesively\n[8]. On the other hand, agents in the worker role need to\ngenerate strategies and execute specific tasks in line with\nthose strategies [71]. They are the core executors and can\nbe designed to operate autonomously or semi-autonomously\nbased on predefined rules or learning algorithms. To complete\nthese tasks, agents in the worker role may need to cooperate or\ncompete with other agents, or call external tools or non-agent\nAI/non-AI systems.\nE. Goal Type\nAgents typically establish goals like task completion, com-\nmunication, and learning, which then guide the planning and\naction phases. Task completion goals mean where agents are\nprogrammed to achieve specific, complex objectives, such as\ncrafting items in virtual environments like Minecraft [44] or\nexecuting specific functions during software development [46].\nThese tasks are clearly defined with each action strategically\naligned towards achieving the outcome. Secondly, communi-\ncation goals involve agents engaging in interactions with other\nagents or humans to exchange information or collaborate on\njoint tasks. For instance, agents within platforms like ChatDev\nmay coordinate efforts in software development [46], while\nagents like those in Inner Monologue adapt their strategies\nbased on real-time human feedback, showcasing their adaptive\ncommunication capabilities [72]. Lastly, learning goals are\nidentified where agents aim to navigate and adapt to unfamiliar\nsettings, balancing between exploration of new areas and\nexploitation of known resources. An example of this can be\nseen in agents like Voyager [44], which explore and refine\nskills through continual feedback and adjustment processes.\nF. Planning\n1) Reasoning Process: In the capabilities of foundation-\nmodel-based agent systems, the reasoning process is a crucial"}, {"title": "V. THREATS TO VALIDITY", "content": "component that utilizes cognitive steps and logical frame-\nworks to tackle complex problems. The reasoning process\nbridges perception and action by enabling informed high-level\ndecision-making and plan generation.\n2) Tool Selection: In the planning process, selecting tools\nis essential for ensuring that agents have instant access to\nthe necessary resources for efficient task execution. This list\ntypically includes both internal and external tools, each playing\na crucial role in the agent's architecture. Internal tools are\ntools and algorithms developed within the system to optimize\nperformance and provide tailored solutions to operational chal-\nlenges. Internal tools can include proprietary large language\nmodels (LLMs) and specific algorithms designed to handle\nunique tasks efficiently [44, 59]. Databases and knowledge\nbases form a robust backbone for agents, offering access to\nextensive repositories of structured data essential for tasks\nrequiring comprehensive analytical capabilities [59, 73]. Ex-\nternal tools extend the agent's capabilities beyond its inherent\nfunctions by allowing seamless interaction with external data\nsources and services. APIs facilitate this interaction, enabling\nthe agent to access and utilize data from various external\nsources [59]. Additionally, external models are employed for\nspecific tasks that demand specialized computational expertise.\nThese models integrate cutting-edge algorithms to enhance the\nagent's problem-solving abilities and are typically used for\nmore complex tasks involving multiple APIs [74]. By inte-\ngrating both internal and external tools into the architecture,\nagents can achieve a higher level of flexibility and efficiency\nin task execution.\n3) Plan Generation: To achieve the user's goal, the agent\nneeds to translate the outcomes of the reasoning process\ninto actionable steps. And accordingly, develop a plan [75].\nThis component is designed to operationalize the theoretical\ninsights and strategies formulated during the reasoning phase\ninto a coherent sequence of steps that guide the agent toward\nachieving specific objectives. There are two primary design\noptions for plan generation: single-path plan generator, and\nmulti-path plan generator.\nSingle-path plan generator creates a linear, straightforward\nplan that directs the agent from the start to the finish of a task\nwithout deviation. It follows a step-by-step methodology, ideal\nfor tasks with predictable outcomes and clear procedures. The\nsingle-path approach ensures a focused and direct route to the\ngoal, minimizing the possibility of errors and inefficiencies in\nexecution [76]. Multi-path plan generator offering a more\ncomplex and adaptable planning solution, the multi-path plan\ngenerator devises several potential routes to achieve the goal\n[77, 78]. It allows the agent to dynamically adjust the steps\nin the plan based on new information or changes in the\nenvironment, thus enhancing its flexibility and effectiveness\nin uncertain scenarios.\nG. Action\n1) Agent Coordination: At the runtime stage, agent co-\nordination mechanisms ensure that agents work together ef-\nfectively, avoiding conflicts and redundancies. Centralized"}, {"title": "J. Non-Functional Aspects", "content": "coordination involves a central agent or system managing the\ncoordination of all agents [24", "80": ".", "8": ".", "82": ".", "Communication": "Agent communication strate-\ngies are crucial for the effective operation of multi-agent\nsystems", "transparency": "All information is openly\nshared among agents. This maximizes cooperation and ensures\nthat all agents have the same level of information", "83": "."}, {"transparency": "nGoal-based sharing: Information is shared only if it\nis"}]}