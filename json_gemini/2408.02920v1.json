{"title": "A Taxonomy of Architecture Options for Foundation Model-based Agents: Analysis and Decision Model", "authors": ["Jingwen Zhou", "Qinghu Lu", "Jieshan Chen", "Liming Zhu", "Xiwei Xu", "Zhenchang Xing", "Stefan Harrer"], "abstract": "The rapid advancement of AI technology has led to widespread applications of agent systems across various domains. However, the need for detailed architecture design poses significant challenges in designing and operating these systems. This paper introduces a taxonomy focused on the architectures of foundation-model-based agents, addressing critical aspects such as functional capabilities and non-functional qualities. We also discuss the operations involved in both design-time and run-time phases, providing a comprehensive view of architectural design and operational characteristics. By unifying and detailing these classifications, our taxonomy aims to improve the design of foundation-model-based agents. Additionally, the paper establishes a decision model that guides critical design and runtime decisions, offering a structured approach to enhance the development of foundation-model-based agents. Our contributions include providing a structured architecture design option and guiding the development process of foundation-model-based agents, thereby addressing current fragmentation in the field.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid advancement of AI technology, particularly foundation models, has led to widespread applications of foundation model based agent systems across various domains, from healthcare and finance to autonomous driving and smart manufacturing [1, 2, 3, 4]. These foundation-model-based agent systems have the potential to revolutionize industries by enhancing efficiencies, enabling automation, and facilitating complex decision-making processes [5].\nRecent innovations in AI demonstrate the versatility of foundation-model-based agents. For example, Auto-GPT for autonomous task management and internet searches 1, BabyAGI has evolved from simple code to include functionalities such as robotics and code-writing 2.\nMoreover, existing studies often focus narrowly on specific aspects of AI agents, such as their functional capabilities or performance metrics. For example, the development of GPT4 by OpenAI [6] has shown significant advancements in prompt engineering. Similarly, the integration of retrieval-augmented generation (RAG) [7] has improved the ability of AI systems to generate contextually relevant responses by retrieving information from external databases. Additionally, tools like LangChain and Hugging Face 34, which facilitate the integration of multiple AI models and data sources, are often discussed in isolation. These advancements, while significant, are often not considered together in a holistic framework that addresses the overall architectural design and operational characteristics of AI agents. This fragmented approach can result in a lack of comprehensive analysis of agent architecture options.\nDespite the innovative application of foundation model-based agents like AutoGen and MetaGPT [8, 9], a significant gap exists in the systematic analysis of their architectural designs. Taxonomies are employed in the software architecture community to deepen the understanding of current technologies [10]. These agents, which harness cutting-edge technologies and introduce new operational paradigms, underscore the necessity for a unified taxonomy that can standardize the classification and elucidate the varying capabilities of such systems. Current frameworks are robust, while often overlooking the critical evaluation of how these architectures can be optimized for better functionality.\nTherefore, we propose a comprehensive taxonomy for foundation-model-based agents. Developed through a systematic literature review (SLR), this taxonomy categorizes both the functional capabilities and non-functional qualities of these agents, aiming to serve as a cornerstone in the software architecture community. It offers a deeper understanding and streamlined design options for complex systems, enhancing the design process and facilitating robust comparisons and assessments of design alternatives. Specifically, the taxonomy provides detailed classifications including input modality support, access to underlying models, and integration of external capabilities. This structured approach not only ensures effective agent coordination and communication but also serves as a comprehensive guide for software architects in designing foundation-model-based agent systems. The main contributions of this paper are as follows:\nFirstly, it introduces a nuanced taxonomy that categorizes agents based on input modality, access to models, external capabilities, agent coordination, agent communication, etc. This taxonomy analyzes different design options and the trade-offs of quality attributes, providing a comprehensive framework that serves as a definitive guide for designing and enhancing agent-based architectures. Secondly, the paper establishes a decision model that offers a structured approach to guide design decisions. This decision model provides a design guide that enhances the strategic planning and execution of foundation model-based agents, ensuring that critical design and runtime decisions are well-informed.\nSpecifically, Section II discusses the related work. Section III discusses the methodology. Section IV delves into the detailed taxonomy and design model, elaborating on agent characteristics, capabilities, design-time structures, and run-time operations. Section V introduces the threats to validity. Finally, Section VI concludes the paper, summarizing our key findings and outlining future research directions."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Recent advancements in foundation-model-based agent systems have seen significant contributions from major tech companies, focusing on enhancing the capabilities and applications of these systems through large language models (LLMs) and innovative multi-agent systems. For instance, Google introduced several AI-driven features at their I/O 2023 event, including the new PaLM2 model, which is optimized for various tasks such as logic, reasoning, and multilingual understanding [11]. This model is integrated into over 25 new products, enhancing their functionality across domains like coding, writing, and mathematics. Google's advancements with Bard [12] and the PaLM 2 model illustrate the potential of LLMs in enhancing agent functionalities [13]. These advancements illustrate how Google is leveraging LLMs to create more sophisticated and versatile AI agents capable of performing diverse tasks effectively.\nIn addition to Google's contributions, several other architectures and frameworks have emerged as key players in the development of foundation-model-based agents. Meta's advancements with their GenAI infrastructure, including highly efficient and scalable LLMs like LLaMA 2, have set a new standard for AI-driven capabilities [14, 15]. Furthermore, MetaGPT attempts to emulate the structure of traditional software companies by assigning roles such as project managers and engineers to agents, fostering collaborative development of user-defined coding tasks [9]. These developments highlight Meta's focus on building scalable and collaborative AI agent systems. Microsoft has made substantial advancements with its AutoGen framework [8], an open-source system designed to facilitate the communication and collaboration of multiple AI agents, thereby improving performance and reducing errors [16]. Microsoft Copilot integrates AI into various tools, enhancing productivity for different roles, while Azure AI infrastructure supports the scalability of generative AI applications with powerful NVIDIA GPUs. Furthermore, frameworks like CrewAI and LangChain have gained traction for their innovative approaches to agent coordination and workflow integration. CrewAI focuses on enhancing multi-agent collaboration through distributed learning mechanisms [17], while LangChain integrates LLMs with various tools and platforms to enable the seamless execution of complex tasks [18].\nDespite significant advancements in foundation-model-based agent systems, a notable gap persists in the comprehensive analysis and standardization of agent architecture options. For example, the AIOS platform integrates LLMs to create a cohesive environment for autonomous agents [19], however, it does not address the need for a standardized approach to defining agent roles and capabilities comprehensively. Similarly, while the MATOM-SNN framework leverages spiking neural networks for enhanced multi-agent cooperation and competition, it too lacks a unified taxonomy that would standardize these systems [20]. Moreover, IBM's initiatives underscore the challenges of integrating LLMs into automation frameworks but fall short in offering a standardized framework that clearly defines agent roles and capabilities [21].\nMeanwhile, recent research studies underscore diverse challenges and advancements in LLM-based autonomous agents. One survey highlights the extensive use of LLMs in autonomous agent frameworks, focusing on how these models enhance agent intelligence and functionality but criticizes the lack of standardized architectures necessary for integration [22]. Another study highlights how advancements in prompting techniques enhance model efficiency, yet overlook the need for architectural standardization [23]. Additional work reviews progress and challenges in the field of multi-agent systems enhanced by LLMs, emphasizing the need for a standardized framework to integrate these systems cohesively [24]. Researchers in [25] explore the capabilities of LLMs to simulate human-like decision-making, emphasizing the need for more robust frameworks to support the scalability and"}, {"title": "III. METHODOLOGY", "content": "Our research study employed a structured and comprehensive approach to address architectural design challenges in systems integrating foundation model-based agents. This methodology can be divided into three main phases: a systematic literature review (SLR), an extensive review, thematic coding, and the development of a taxonomy.\nA. Systematic Literature Review (SLR)\nPaper Searching: We conducted literature searches in various academic databases and journals using predetermined keywords related to foundation model-based agents. This initial search aimed to gather a broad range of relevant academic publications and scholarly works (300 papers).\nSnowballing: To ensure thoroughness, we applied both forward and backward snowballing techniques. Forward snowballing involved examining the citations of initially identified papers, while backward snowballing entailed reviewing references within those papers to identify additional relevant studies (100 papers).\nInclusion & Exclusion Criteria: We established a set of inclusion and exclusion criteria to filter the papers. This step ensured that only studies meeting specific relevance and quality standards were selected for further analysis.\nQuality Assessment: The selected papers underwent a rigorous quality assessment process to ensure the robustness and reliability of the included studies. This step was crucial to maintain the integrity of our data extraction (68 studies).\nData Extraction: Finally, we extracted relevant data from the qualifying studies. This phase involved a detailed examination and synthesis of information from 87 studies, which were deemed suitable for our analysis.\nB. Extensive Review\nGrey Literature Review: Beyond academic publications, we reviewed grey literature to capture the latest trends and applications of foundation model-based agents. This included technical reports, white papers, and other non-peer-reviewed documents (9 studies).\nReal-World Application Analysis: To understand practical implementations, we analyzed known real-world applications of foundation model agents. This involved scrutinizing official websites, available documents, and case studies of organizations utilizing these agents (10 studies).\nC. Thematic Coding\nOur thematic coding process utilized a hybrid approach, combining both deductive and inductive methods to achieve a comprehensive understanding of foundation-model-based agents. This hybrid approach allowed us to systematically categorize the extracted metrics into a structured yet adaptable framework. The predefined criteria provided a clear direction for our analysis, while the emergent sub-criteria offered depth and nuanced insights, resulting in a robust and thorough comprehension of the agents' architecture.\nDeductive Coding: We initiated our process with two broad predefined criteria: functional capabilities and non-functional qualities. These criteria guided the initial categorization of the extracted metrics, ensuring a focused and structured analysis.\nEmergent Sub-Criteria: As the coding process progressed, sub-themes emerged organically based on patterns, similarities, and differences observed in the data. This inductive method enabled us to capture detailed and context-specific aspects of the metrics, enriching our understanding of their interrelationships and significance.\nRefinement and Integration: The emergent sub-criteria were continuously refined and integrated into the overarching predefined themes. This iterative process ensured that our thematic structure accurately reflected the complexities and subtleties of the data, providing a comprehensive framework for analysis.\nInternal Validation: To validate our thematic structure, one author conducted the initial coding, followed by a review and feedback process involving six authors. This collaborative validation ensured consensus and accuracy in our categorization.\nUpon completing the literature review and thematic coding, our analysis identified twelve key taxonomy branches, systematically categorized under two primary criteria: functional capabilities and non-functional qualities. These branches align"}, {"title": "IV. TAXONOMY OF FOUNDATION-MODEL BASED AGENTS", "content": "In this section, we present a taxonomy that defines architecture design options for foundation-model-based agents. The taxonomy is structured into two categories: functional capability (Section IV-A - Section IV-I) and non-functional qualities (Section IV-J). We discuss the characteristics of each design option to consider during the building process and their impact on the foundation-model-based agents.\nA. Input Modality\nModality defines whether an agent operates using a single modality or multiple modalities. Single-modality agents utilize one type of input such as text, vision, or audio, making them ideal for straightforward tasks that require less computational resources and simpler data interpretation. For instance, text-based chatbots or vision-only surveillance systems operate within this single modality [27]. In contrast, multi-modality agents combine video/audio/image/text inputs uploaded by humans, and understand the operational and environmental context, enabling a more comprehensive and rich interaction with their environment. This enhanced capability allows them to handle more complex tasks like autonomous navigation or interactive virtual assistants that respond not only to voice commands but also to visual and contextual cues. This approach not only facilitates richer user interactions but also aligns with the evolving demands of dynamic environments where adaptability and context awareness are crucial [28].\nB. Access to Underlying Models\n1) Underlying Model Types: Non-AI-based agents operate without employing artificial intelligence techniques. They typically rely on predefined scripts, workflows, or simple automation rules that do not involve learning or adapting over time. Non-AI-based agents are effective in environments where tasks are repetitive and straightforward, as they execute tasks exactly as specified by their programming. While they are fragile and sensitive to the input. An example of a non-AI-based agent is a basic automation script that processes incoming emails and sorts them into different folders based on predefined keywords.\nFor AI-based agents, we consider two types in terms of their purposes: narrow AI-based agents and general purpose AI(GPAI)-based agents. Narrow AI-based agents are designed to perform specific tasks or solve particular problems. These agents use machine learning and other AI techniques to improve their performance in their specialized domains [29]. These agents are effective within their domains but lack generalization capabilities. GPAI-based agents aim to perform various tasks across different domains. They are designed with broader capabilities, leveraging extensive datasets and sophisticated algorithms to adapt to multiple environments and challenges [30, 31]. GPAI-based agents can switch between tasks, learn from diverse experiences, and apply their knowledge to new, unforeseen problems, making them more versatile compared to narrow Al agents. This adaptability is achieved through advanced architectures and continuous learning mechanisms, which enable GPAI-based agents to update their models and improve over time.\n2) Model Composition: The composition of agent models is crucial for optimizing performance and scalability in agent-based systems. Various configurations can be adopted depending on the complexity and requirements of the system. A single-model agent handles all tasks, which is suitable for simpler systems with a limited scope. This approach minimizes complexity but may not scale well for diverse tasks [24, 32]. In more complex systems, multi-model configurations are often employed. Multiple models are used to handle different tasks or to enhance performance. One approach is the mixture of experts, where different models specialize in different tasks, and the system dynamically selects the appropriate model for each task [33]. Another approach is the ensemble method, where multiple models work together to improve accuracy and robustness by combining their outputs [34]. Additionally, model merging involves combining different models to create a more capable composite model, such as merging language models and visual recognition models for a comprehensive virtual assistant [35]. A hybrid model combines various types of models, such as rule-based and learning-based models, to leverage their respective strengths. This approach is used in cybersecurity systems that employ rule-based detection for known threats and machine learning models for anomaly detection [36].\nC. Access to External Capabilities\n1) Memory Management: Memory management is critical for foundation-model-based agents to store, retrieve, and utilize information effectively.\n\u2022 Memory Types: Long-term memory retains information over long periods, which is essential for tasks that require historical data, knowledge, past observations, and past experiences [37, 38]. Short-term memory, on the other hand, handles short-term information relevant to immediate tasks [39]. This type of memory is useful for temporary activities that do not require long-term storage, for example, configuration, working context, recent events, and the information within the context window of the FM [40]. Selective forgetting enables agents to discard irrelevant or outdated information, ensuring that they maintain optimal performance without being bogged down by unnecessary data [41, 42]. This capability is crucial in dynamic environments where the relevance of data changes rapidly.\n\u2022 Memory Format: In the foundation-model-based agent systems, several distinctive structures offer unique advantages and serve as pivotal design options depending on specific application needs. Natural language memory, as used in systems like Reflexion [43] and Voyager [44], provides a flexible format that stores information in an easily understandable form, facilitating intuitive interaction and preserving rich semantic details to guide agent actions. Embedding memory, exemplified by MemoryBank [45] and ChatDev, encapsulates memory information into compact embedding vectors, significantly enhancing the efficiency of memory retrieval processes. Databases allow for robust memory manipulation; systems like ChatDB [46] and DB-GPT [47] use databases to enable precise memory operations through SQL queries, providing structured and efficient data management. Structured lists are employed in models such as GITM [48] and RET-LLM [49], where memory is systematically organized in lists or hierarchical structures that clearly define the relationships between elements and facilitate rapid data access. Each format presents distinct advantages: natural language for clarity and semantic richness, embeddings for retrieval speed, databases for structured manipulation, and lists for organized and hierarchical memory storage. These memory formats can be integrated, as demonstrated by GITM, which uses a hybrid approach combining key-value pairs with embeddings and natural language to maximize retrieval efficiency and content comprehensiveness, providing multiple design options to optimize agent performance based on the specific needs of the application.\n\u2022 Memory Operation: Agents can acquire, accumulate, and utilize knowledge through interactions with their environment via various operations. These operations include memory reading, writing, reflection, and sharing. Memory reading involves extracting valuable informa-"}, {"title": "D. Role-Playing", "content": "In foundation-model-based agent systems, the roles of agents are crucial as they define the functions and interactions within the system. The agents can be categorized into two types: agent-as-a-coordinator and agent-as-a-worker. Agents in the coordinator role primarily formulate high-level strategies and orchestrate the execution of tasks by delegating task execution responsibilities to other agents, external tools, or non-agent systems, ensuring that tasks are allocated efficiently and that the system operates cohesively [8]. On the other hand, agents in the worker role need to generate strategies and execute specific tasks in line with those strategies [71]. They are the core executors and can be designed to operate autonomously or semi-autonomously based on predefined rules or learning algorithms. To complete these tasks, agents in the worker role may need to cooperate or compete with other agents, or call external tools or non-agent AI/non-AI systems."}, {"title": "E. Goal Type", "content": "Agents typically establish goals like task completion, communication, and learning, which then guide the planning and action phases. Task completion goals mean where agents are programmed to achieve specific, complex objectives, such as crafting items in virtual environments like Minecraft [44] or executing specific functions during software development [46]. These tasks are clearly defined with each action strategically aligned towards achieving the outcome. Secondly, communication goals involve agents engaging in interactions with other agents or humans to exchange information or collaborate on joint tasks. For instance, agents within platforms like ChatDev may coordinate efforts in software development [46], while agents like those in Inner Monologue adapt their strategies based on real-time human feedback, showcasing their adaptive communication capabilities [72]. Lastly, learning goals are identified where agents aim to navigate and adapt to unfamiliar settings, balancing between exploration of new areas and exploitation of known resources. An example of this can be seen in agents like Voyager [44], which explore and refine skills through continual feedback and adjustment processes."}, {"title": "F. Planning", "content": "1) Reasoning Process: In the capabilities of foundation-model-based agent systems, the reasoning process is a crucial component that utilizes cognitive steps and logical frameworks to tackle complex problems. The reasoning process bridges perception and action by enabling informed high-level decision-making and plan generation.\n2) Tool Selection: In the planning process, selecting tools is essential for ensuring that agents have instant access to the necessary resources for efficient task execution. This list typically includes both internal and external tools, each playing a crucial role in the agent's architecture. Internal tools are tools and algorithms developed within the system to optimize performance and provide tailored solutions to operational challenges. Internal tools can include proprietary large language models (LLMs) and specific algorithms designed to handle unique tasks efficiently [44, 59]. Databases and knowledge bases form a robust backbone for agents, offering access to extensive repositories of structured data essential for tasks requiring comprehensive analytical capabilities [59, 73]. External tools extend the agent's capabilities beyond its inherent functions by allowing seamless interaction with external data sources and services. APIs facilitate this interaction, enabling the agent to access and utilize data from various external sources [59]. Additionally, external models are employed for specific tasks that demand specialized computational expertise. These models integrate cutting-edge algorithms to enhance the agent's problem-solving abilities and are typically used for more complex tasks involving multiple APIs [74]. By integrating both internal and external tools into the architecture, agents can achieve a higher level of flexibility and efficiency in task execution.\n3) Plan Generation: To achieve the user's goal, the agent needs to translate the outcomes of the reasoning process into actionable steps. And accordingly, develop a plan [75]. This component is designed to operationalize the theoretical insights and strategies formulated during the reasoning phase into a coherent sequence of steps that guide the agent toward achieving specific objectives. There are two primary design options for plan generation: single-path plan generator, and multi-path plan generator.\nSingle-path plan generator creates a linear, straightforward plan that directs the agent from the start to the finish of a task without deviation. It follows a step-by-step methodology, ideal for tasks with predictable outcomes and clear procedures. The single-path approach ensures a focused and direct route to the goal, minimizing the possibility of errors and inefficiencies in execution [76]. Multi-path plan generator offering a more complex and adaptable planning solution, the multi-path plan generator devises several potential routes to achieve the goal [77, 78]. It allows the agent to dynamically adjust the steps in the plan based on new information or changes in the environment, thus enhancing its flexibility and effectiveness in uncertain scenarios."}, {"title": "G. Action", "content": "1) Agent Coordination: At the runtime stage, agent coordination mechanisms ensure that agents work together effectively, avoiding conflicts and redundancies. Centralized coordination involves a central agent or system managing the coordination of all agents [24, 79, 80]. This approach provides strong oversight but can become a bottleneck, particularly in large-scale systems. Federated coordination is managed in a decentralized manner, with each agent handling its own coordination while still communicating with others [8]. Fully distributed coordination, on the other hand, involves no central coordinator; all agents coordinate directly with each other, often using peer-to-peer communication protocols [24, 81, 82].\nThese coordination strategies are essential for ensuring that multi-agent systems operate efficiently and effectively. They help in managing dependencies, synchronizing actions, and resolving conflicts among agents. Each approach has its advantages and trade-offs in terms of efficiency, scalability, and complexity. Selecting the appropriate coordination mechanism depends on the specific requirements and constraints of the system.\n2) Agent Communication: Agent communication strategies are crucial for the effective operation of multi-agent systems, as they dictate how agents share information and collaborate. There are several levels of communication transparency that can be implemented, each with its own advantages and trade-offs. Full transparency: All information is openly shared among agents. This maximizes cooperation and ensures that all agents have the same level of information, which can be particularly beneficial in collaborative environments. For instance, in a research setting where multiple agents are working together to solve complex problems, full transparency allows all agents to access and build upon each other's findings. However, full transparency can lead to information overload and may not be suitable for environments where privacy and security are critical concerns [83]. Partial transparency: Goal-based sharing: Information is shared only if it is relevant to achieving specific goals. For example, in a project management system, team members might only see tasks and data relevant to their specific objectives [24, 81]. Role-based sharing: Information is shared based on the roles and responsibilities of each agent [24, 84]. This is common in corporate environments where different agents have access to different levels of information. Sensitive data withholding: Sensitive information is withheld to protect privacy and security. This approach is crucial in scenarios where data sensitivity is high, and privacy regulations must be strictly followed [83]. Context-aware sharing: Information sharing is adapted based on the context and current state of the system. For instance, agents utilize intrinsic context such as their own historical data and goals, alongside extrinsic context including user preferences, other agents' behaviors, and systemic norms, to enhance decision-making [85].\nEffective agent communication strategies are essential for maintaining the balance between collaboration and privacy. The choice of communication strategy depends on the specific requirements and constraints of the system, such as the need for real-time updates, security considerations, and the"}, {"title": "H. Reflection", "content": "1) Reflected Artifacts : In the reflection process of foundation-model-based agents, several key artifacts ensure effective traceability and observability. These artifacts can be categorized into three design options: workflow/plan generation, intermediate result, and final output. By providing feedback at different stages, we can ensure that not only the final output is correct, but also the intermediate processes. Workflow/plan generation involves the initial setup of goals, user inputs, prompts, and the overall planning steps that the agent will follow. Documenting these elements ensures that the agent has all the necessary information for decision-making and that its actions are aligned with intended objectives[89]. During this stage, feedback can be provided on the comprehensiveness and accuracy of the workflow, ensuring that the foundation for subsequent processes is solid.\nThe intermediate result includes the documentation of reasoning processes, planning steps, and tool use during the agent's operation. It involves logging intermediate decisions, actions, and outputs generated by the agent throughout its workflow. Feedback at this stage focuses on the correctness and rationality of these intermediate steps, ensuring that the process leading to the final output is valid and transparent [68]. The final output comprises the final results produced by the agent, which are directly evaluated against the goals and expectations set in the workflow/plan stage. Feedback here ensures that the output meets the desired criteria and accurately reflects the agent's intended actions and decisions.\n2) Provider: Reflection allows the agent to incorporate feedback to refine the plan [50] from different providers, such as object world, the virtual environment, the interaction with humans, or the internal model. Self-reflection enables the agent to generate feedback on the plan and provides refinement guidance from themselves [44, 90, 91, 92, 93]. Cross-reflection uses different agents or FMs to provide feedback and refinement on the plan [93, 94, 95]. Human reflection means that the agent can collect feedback from"}, {"title": "I. Learning Capability", "content": "1) Training of Underlying Model: Effective training and learning mechanisms are essential for developing and adapting foundation-model-based agents. Various strategies can be employed, depending on the specific requirements and constraints of the system. Centralized training involves training underlying models using a centralized dataset and process, ensuring consistency but potentially requiring significant resources [97]. Collaborative learning, on the other hand, involves agents learning by collaborating. This includes federated learning, where each agent trains on local data and shares updates with a central model. For example, this work focuses on privacy-preserving federated training across multiple healthcare institutions, leveraging localized model training with global aggregation to enhance diagnosis without sharing sensitive data. [98]. Distributed learning is similar but emphasizes distributed computing resources more, as seen in environmental monitoring where distributed sensor networks share learning updates to enhance prediction accuracy. Another method is split learning, where the training process is divided between different agents or systems, sharing intermediate data.\nOnline learning allows agents to continue learning and adapting in real-time as they interact with their environment. A recommendation system that updates its model continuously based on user interactions and feedback can be an example of this approach [99]. These training mechanisms ensure that agents remain up-to-date and capable of handling new tasks, enhancing their adaptability and performance in dynamic environments.\n2) Other Learning (without changing model weights): Learning capabilities are fundamental to an Al agent's ability to adapt and improve over time. Self-learning agents autonomously update their knowledge base and refine their decision-making algorithms [43]. A crucial aspect of this adaptation is the concept of long-term memory, where agents retain and utilize extensive historical data to enhance their learning and decision-making processes over extended periods [38]. This continuous learning process enables them to handle new situations more effectively and improve their performance without external input [31]. In-context learning enables agents to adapt to new tasks by interpreting input context, often through prompt engineering, without altering internal parameters. This streamlined approach is particularly effective for agents using pre-trained models, allowing them to learn and respond based on tailored prompts. Group learning involves multiple agents sharing knowledge and insights to enhance collective performance. This can take several forms, peer-to-peer learning allows agents to share knowledge directly with each other [100], and hierarchical learning, which involves different levels of agents sharing and processing information and tackling complex problems more efficiently [101]."}, {"title": "J. Non-Functional Aspects", "content": "1) Level of Autonomy: Autonomy levels in foundation-model-based agents vary significantly, determining how independently an agent can operate without human intervention. LangChain recently published a list of cognitive architecture patterns [102] that can reflect the autonomy level of agents. At the basic level, single-function calls allow agents to perform simple, predefined tasks. As complexity increases, agents can execute a chain of function calls, allowing for more complex behaviors and decision-making processes. Using function models as routers, agents can dynamically route tasks based on real-time data and conditions. State machines provide a structured way for agents to transition between different states based on specific triggers, enabling more sophisticated control over their actions. Fully autonomous agents represent the highest level of autonomy, capable of making independent decisions, learning from their environment, and adapting their behavior to new situations [103]. These agents can operate in dynamic and unpredictable environments, such as autonomous vehicles navigating through city traffic, leveraging advanced"}, {"title": "V. THREATS TO VALIDITY", "content": "While our study presents a comprehensive taxonomy for foundation-model-based agents, it is important to acknowledge several potential threats to the validity of our findings.\nCoverage Limitations: The taxonomy we developed may not encompass all possible variations and characteristics of AI agents or foundation model-based agents. Despite our systematic approach, the rapidly evolving nature of AI technology means new models and capabilities are continuously emerging. Our search included literature up until May 2024, and any developments beyond this period are not considered in our analysis. Consequently, some recent advancements and applications might have been missed.\nData Extraction and Synthesis: The process of data extraction and thematic coding, although rigorously validated. Different researchers might interpret and categorize information differently, which could influence the resulting taxonomy. We mitigated this through collaborative validation involving multiple authors, but some degree of subjectivity remains. Despite these limitations, we believe that the breadth and depth of our literature review and the robustness of our methodological approach provide a solid foundation for the proposed taxonomy. Our study included a substantial number of papers, ensuring a comprehensive overview that supports the validity of our conclusions. Future research should continue to refine and expand this taxonomy, incorporating new developments and addressing identified gaps."}, {"title": "VI. CONCLUSION", "content": "Foundation model-based agents are gaining increasing attention in various domains. However, researchers and developers face architectural challenges when designing these agents. Our previous work demonstrated a reference architecture to present an overview of agent design [40], while in this study, we provided a comprehensive taxonomy that categorizes foundation-model-based agents, addressing issues of standardization and enhancing our understanding of their various types and functionalities. By detailing how agents function across different roles and situations, this classification aids in designing more effective and adaptable agent system architectures, reducing clutter in the field and streamlining design and deployment processes. Our taxonomy also offers valuable insights into architectural options, enabling better integration and interoperability across different systems.\nIn our future work, we will explore how to apply this taxonomy in conjunction with existing architectural patterns. Additionally, we will further investigate architecture decisions related to foundation model-based agents, aiming to incorporate new technologies and applications to advance the field."}]}