{"title": "Latency-Aware Resource Allocation for Mobile Edge Generation and Computing via Deep Reinforcement Learning", "authors": ["Yinyu Wu", "Xuhui Zhang", "Jinke Ren", "Huijun Xing", "Yanyan Shen", "Shuguang Cui"], "abstract": "Recently, the integration of mobile edge computing (MEC) and generative artificial intelligence (GAI) technology has given rise to a new area called mobile edge generation and computing (MEGC), which offers mobile users heterogeneous services such as task computing and content generation. In this letter, we investigate the joint communication, computation, and the AIGC resource allocation problem in an MEGC system. A latency minimization problem is first formulated to enhance the quality of service for mobile users. Due to the strong coupling of the optimization variables, we propose a new deep reinforcement learning-based algorithm to solve it efficiently. Numerical results demonstrate that the proposed algorithm can achieve lower latency than two baseline algorithms.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, artificial intelligence generative content (AIGC) has gained widespread attention due to its powerful creative ability for a variety of content, such as images, videos, and music [1]. Several examples, including the generative pre-trained transformer (GPT) developed by OpenAI and the WaveNet developed by DeepMind, have shown great potential in enhancing communication performance for the next-generation wireless networks [2]. By deploying AIGC services at the network edge, lower latency and reduced communication overhead can be achieved for mobile users (MUs) [3]. Meanwhile, computing services remain crucial due to the increasing demand for handling computationally intensive tasks for MUs [4]. By processing task data at the network edge, the shortcomings of network congestion and long latency in conventional mobile computing systems can be addressed [5]. Hence, the integration of communication, computing, and generation services at the network edge is promising to address the heterogeneous requests in future wireless networks.\nSeveral pioneering works have exploited the applications of AIGC services in mobile edge computing (MEC) systems [1], [3], [6], [7]. An edge intelligence infrastructure was proposed to provide personalized and low latency AIGC services [1]. To improve the user utility, a pricing-based mechanism was proposed in [6], which investigated the efficient AIGC ser- vices. Moreover, a mobile edge generation (MEG) system was proposed to reduce the distributed computation and transmis- sion overhead [3]. Furthermore, an MEG enabled digital twin system was studied in [7], which can be applied in both single- user and multi-user scenarios. Besides, the heterogeneous services in MEC systems were investigated in previous works [8]\u2013[10]. A three-stage heterogeneous computing model was proposed in [8] to practically describe the computation process of parallelizable tasks. To maximize the computation efficiency of a multi-server system, an advantage-actor-critic-based deep reinforcement learning (DRL) method was proposed in [9]. In [10], an unmanned aerial vehicle assisted heterogeneous MEC system was studied, where the MUs chose different service providers to maximize the task computation volume. Additionally, to minimize the average latency and improve the MU's quality of experience, the joint optimization of data offloading, resource allocation, and data caching time are investigated in [11].\nMost previous works focus on the computing resource assignments or the AIGC service allocations in MEC and MEG, while the integration of MEC and MEG to provide heterogeneous services for MUs has not been exploited. To provide heterogeneous computation, AIGC, and vision en- hancement (VE) services for MUs while improving the user experience, we aim to minimize the average latency of all MUS in a novel mobile edge generation computing (MEGC) system. A DRL-based latency-aware resource allocation algorithm is proposed to jointly optimize the bandwidth allocation, the backhaul transmit power, the computation resources, and the task offloading ratio. The superior latency performance of the proposed algorithm is verified by comparing to two benchmark algorithms."}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "To enable the heterogeneous task requirements, we consider an MEGC system that can provide both computation services and AIGC services, as illustrated in Fig. 1. The MEGC system consists of an edge server (ES) equipped with a powerful computing and generating unit, and three MUs with different task requests, including computation, AIGC, and VE, respectively. Let $U_{comp}$, $U_{aigc}$, $U_{ve}$ denote the MUs with computation task, AIGC task, and VE task, respectively. The serving time is index by $T = \\{1,\\ldots,T\\}$. Each MU requests one service during each time slot, and the frequency division multiple access (FDMA) technology is adopted in each time slot of request turn. The system model is shown in Fig 1.\nAs illustrated in Fig. 2, the MEGC system consists of two stages: data offloading and result backhaul transmission. In the data offloading stage, the MUs $U_{comp}$ and $U_{VE}$ need to offload their data to the ES, while the MU $U_{AIGC}$ only needs to offload a request to the ES. During the backhaul transmission stage, the ES transmits the generated content and processed images/videos to the MUs $U_{aigc}$ and $U_{ve}$, respectively, and transmits the computing results to the MU $U_{comp}$.\nSince the FDMA technology is adopted, the bandwidth resource is optimized to allocate for different MUs within each time slot. Let $B_{off}$ denote the bandwidth allocated to the offloading stage. Thus, the offloading rates of the MU $U_{comp}$ and $U_{ve}$ at time slot t are expressed respectively as\n$\\r_{comp}^{off}(t) = \\alpha_{comp}^{off}(t) B_{off} \\log_2 \\left(1 + \\frac{P_{comp}h_{comp}^{off}(t)}{\\alpha_{comp}^{off}(t) B_{off} N_0} \\right),$ (1)\n$\\r_{ve}^{off}(t) = \\alpha_{ve}^{off}(t) B_{off} \\log_2 \\left(1 + \\frac{P_{VE}h_{ve}^{off}(t)}{\\alpha_{ve}^{off}(t) B_{off} N_0} \\right),$ (2)\nwhere $\\alpha_{comp}^{off}(t) \\in [0, 1]$ and $\\alpha_{ve}^{off}(t) \\in [0, 1]$ are the bandwidth allocation ratios of the MUs $U_{comp}$ and $U_{ve}$, which satisfy $\\alpha_{comp}^{off}(t) + \\alpha_{ve}^{off}(t) = 1, \\forall t$. $P_{comp}$ and $P_{ve}$ denote the transmit power the MUs $U_{comp}$ and $U_{ve}$, respectively. $h_{comp}^{off}(t)$ rep- resents the line-of-sight (LoS) channel gain between the MU $U_{comp}$ and the ES, and $h_{ve}^{off}(t)$ is the LoS channel gain between the MU $U_{VE}$ and the ES. $N_0$ is the power spectral density.\nSimilarly, let $B_{back}$ denote the bandwidth allocated to the backhaul transmission stage. Then, the backhaul transmission rates of the MUs $U_{Aigc}$ and $U_{ve}$ are given by\n$\\r_{aigc}^{back}(t) = \\alpha_{aigc}^{back}(t) B_{back} \\log_2 \\left(1 + \\frac{\\beta(t) P h_{aigc}^{back}(t)}{\\alpha_{aigc}^{back}(t) B_{back} N_0} \\right),$ (3)\n$\\r_{ve}^{back}(t) = \\alpha_{ve}^{back}(t) B_{back} \\log_2 \\left(1 + \\frac{(1-\\beta(t)) P h_{ve}^{back}(t)}{\\alpha_{ve}^{back}(t) B_{back} N_0} \\right),$ (4)\nwhere $\\alpha_{aigc}^{back}(t) \\in [0, 1]$ and $\\alpha_{ve}^{back}(t) \\in [0, 1]$ are the bandwidth allocation ratios of the MUS $U_{AIGC}$ and $U_{VE}$, which satisfy $\\alpha_{aigc}^{back}(t) + \\alpha_{ve}^{back}(t) = 1, \\forall t$. $h_{aigc}^{back}(t)$ represents the LoS channel gain between the ES and the MU $U_{AIGC}$, and $h_{ve}^{back}(t)$ is the LoS channel gain between the ES and the MU $U_{VE}$. $P$ is the transmit power of the ES. $\\beta(t) \\in [0,1]$ is the power allocation ratio to the ES for communicating with the MU $U_{AIGC}$, while $1 - \\beta(t)$ is the power allocation ratio for the ES to communicate with the MU $U_{VE}.\nB. Latency Model\na) Latency of MU $U_{comp}$: The MU $U_{comp}$ requests data computing services. At the beginning of each time slot, a data packet is arrived with data volume $D_{comp}$, which follows a Poisson distribution with density $\\rho_x$ Mbits. Assume that the data packet can be partially computed by its local processor and partially offloaded to the ES for computing. Let $\\lambda(t)$ denote the ratio of the data packet offloaded to the ES at time slot t. Then, the offloading latency is given by\n$L_{comp}^{off} (t) = \\frac{\\lambda(t) D_{comp}(t)}{r_{comp}^{off}(t)}.$ (5)\nAssume the local computing capability of the MU $U_{comp}$ is $f_{comp}$ central processing unit (CPU) cycles per second. The local computing latency is thus represented by\n$L_{comp}^{local} (t) = \\frac{(1 - \\lambda(t)) \\chi D_{comp}}{f_{comp}},$ (6)\nwhere $\\chi$ denotes the number of CPU cycles for computing one bit data. Meanwhile, the computing latency of the ES for processing the data offloaded by the MU $U_{comp}$ at time slot t is given by\n$L_{comp}^{ES} (t) = \\frac{\\lambda(t) \\chi D_{comp}}{w_{comp}(t) f_{ES}},$ (7)\nwhere $f_{ES}$ is the maximum computing capability of the ES, and $w_{comp}(t)$ denotes the ratio of the computation resources allocated to the MU $U_{comp}$ at time slot t.\nThe overall latency of the MU $U_{comp}$ is the maximum of the latency between local computing and ES computing, which is derived as\n$L_{comp} (t) = max(L_{comp}^{local} (t), L_{comp}^{off} (t) + L_{comp}^{ES} (t)).$ (8)\nb) Latency of MU $U_{AIGC}$: The MU $U_{AIGC}$ requests AIGC services. Since the data volume of the request is very small, the time latency for transmitting the request can be ignored. After receiving the request, the ES begins to generate results. The time latency for AIGC inference is given by\n$L_{AIGC}^{ES}(t) = \\frac{\\xi \\chi D_{aigc}^{ES}(t) + \\epsilon}{w_{AIGC} (t) f_{ES}}$ (9)\nwhere $D_{aigc}^{ES}(t)$ is the data volume of the expected AIGC results, related to the image resolution. $\\xi$ is the coefficient related to the ES-embedded LLM and computing hardware, and $\\epsilon$ is the coefficient related to the minimum computing resources required for a small-scale image inference at the ES. Besides, $w_{AIGC}(t)$ denotes the ratio of the computation re- sources allocated to the MU $U_{AIGC}$ at time slot t. Accordingly,"}, {"title": "the latency for transmitting the AIGC results to the MU $U_{AIGC}$ can be expressed by", "content": "$L_{aigc}^{back}(t) = \\frac{D_{aigc}^{ES} D_{GC}(t)}{r_{aigc}^{back} (t)}.$ (10)\nHence, the overall latency of the MU $U_{AIGC}$ is given by\n$L_{AIGC}(t) = L_{AIGC}^{ES}(t) + L_{aigc}^{back}(t).$ (11)\nc) Latency of MU $U_{VE}$: The MU $U_{ve}$ requests VE services, i.e., the image and/or video processing services. One service consists of three parts: the original data offloading, the data inference at the ES, and the backhaul transmission of the inference results. Accordingly, the latency for data offloading can be given by\n$L_{VE}^{off}(t) = \\frac{D_{VE}(t)}{r_{ve}^{off}(t)},$ (12)\nwhere $D_{ve}(t)$ is the offloading data volume of the MU $U_{VE}$. Then, the latency for ES processing for the offloading data can be expressed as\n$L_{VE}^{ES}(t) = \\frac{\\chi D_{VE}^{ES}(t) + \\zeta}{w_{VE}(t).f_{ES}}$ (13)\nwhere $D_{VE}^{ES}(t) = \\zeta D_{ve}(t)$ denotes the expected processed data at the ES with enhancement coefficient $\\wp$, and $w_{ve}(t)$ denotes the ratio of the data processing resources allocated to the MU $U_{VE}$ at time slot t. Moreover, the latency for the backhaul transmission of the inference results is thus given by\n$L_{ve}^{back}(t) = \\frac{D_{VE}^{ES}(t)}{r_{ve}^{back} (t)}.$ (14)\nAs a result, the overall latency of the MU $U_{ve}$ is given by\n$L_{ve}(t) = L_{VE}^{off}(t) + L_{VE}^{ES}(t) + L_{ve}^{back}(t).$ (15)\nC. Problem Formulation\nIn this letter, we aim to minimize the average of the overall latency of all MUs to improve the quality of heterogeneous services. Hence, the problem can be formulated as\n$\\underset{\\alpha,\\beta,\\omega,\\lambda}{min} (P1) = \\frac{1}{T} \\sum_{t \\epsilon T} L_{comp}(t) + L_{AIGC}(t) + L_{VE}(t)$"}, {"title": "s.t.", "content": "$\\alpha_{comp}^{off}(t), \\alpha_{ve}^{off}(t) \\in [0, 1], \\forall t \\in T,$ (16a)\n$\\alpha_{comp}^{off}(t) + \\alpha_{ve}^{off}(t) = 1, \\forall t \\in T,$ (16b)\n$\\alpha_{aigc}^{back}(t), \\alpha_{ve}^{back}(t) \\in [0,1], \\forall t \\in T,$ (16c)\n$\\alpha_{aigc}^{back}(t) + \\alpha_{ve}^{back}(t) = 1, \\forall t \\in T,$ (16d)\n$\\beta (t), \\lambda(t) \\in [0,1], \\forall t \\in T,$ (16e)\n$w_{comp} (t), w_{aigc}(t), w_{ve}(t) \\in [0, 1], \\forall t \\in T,$ (16f)\n$w_{comp}(t) + w_{AIGC}(t) + w_{ve}(t) = 1, \\forall t \\in T,$ (16g)\nconstraints (16b)-(16d) are the bandwidth allocations, constraint (16e) denotes the power allocation for the ES backhaul transmission, and the offloading ratio of the MU $U_{comp}$, respectively, and constraints (16f)-(16g) represent the computation resources allocation of the ES.\nIII. DRL-BASED RESOURCE ALLOCATION ALGORITHM\nSince the optimization variables of the bandwidth allocation $\\alpha$, the transmit power allocation of the ES $\\beta$, the computation resource of the ES $\\omega$, and the offloading ratio $\\lambda$ are highly coupled, the problem P1 is hard to solve by traditional optimization algorithms. Fortunately, DRL can effectively ad- dress complex resource allocation challenges by dynamically adapting decisions to changing environments that include varying channels and diverse task requests [12]. Therefore, we propose a DRL-based latency-aware resource allocation (LARA) algorithm for solving problem P1.\nIt is observed that the problem P1 can be reformulated as a Markov decision process (MDP), described by a tuple $\\{s(t), a(t), r(t), \\forall t\\}$, where s(t) denotes the system state, a(t) represents the decision action, and r(t) denotes the reward value for taking the action a(t) at the state s(t).\nSpecifically, let S denote the state space, which encom- passes the channel conditions and task data sizes of all MUs. Hence, the state s(t) at time slot t is given by\n$s(t) = [h(t), D_{comp}(t), D_{VE}(t)], \\forall t,$ (17)\nwhere $h(t) = \\{h_{comp}^{off} (t), h_{ve}^{off}(t), h_{aigc}^{back}(t), h_{ve}^{back}(t)\\}$ includes the channel state information in the data offloading stage and the result backhaul transmission stage. Moreover, the action"}, {"title": "space", "content": "A consists of all decision variables in problem P1, and the action a(t) at time slot t can be represented as\n$a(t) = [\\alpha(t), \\beta (t), \\lambda(t), \\omega(t)], \\forall t,$ (18)\nwhere $\\alpha(t)$ = $[\\alpha_{comp}^{off} (t), \\alpha_{ve}^{off}(t), \\alpha_{aigc}^{back}(t), \\alpha_{ve}^{back}(t)]$ denotes the bandwidth allocations, and $\\omega(t)$ = $[w_{comp}(t), w_{aigc}(t), w_{ve}(t)]$ represents the computation resource allocations. Since our goal is to minimize the overall latency of all MUs, we define the reward function as\n$r(t) = - \\frac{1}{T} \\sum_{t \\epsilon T} L_{comp} (t) + L_{AIGC}(t) + L_{ve}(t), \\forall t,$ (19)\nwhich is the opposite of the objective function of P1.\nBased on the above definition, we then use the deep deter- ministic policy gradient (DDPG) method to solve problem P1 according to the MDP reformulation [13]. DDPG is a model-free off-policy actor-critic method designed for environments with continuous action spaces. It can approximate both the policy function (i.e., the actor function for giving actions) and the value function (i.e., the critic function that evaluates the action given by the actor function) to enable efficient and stable learning. DDPG combines the deterministic policy gradient approach with the benefits of experience replay and target functions, providing robust performance in complex, high-dimensional tasks. Specifically, the actor function is updated by minimizing the loss function\n$L_{actor} = -E_{s~p^{\\mu}}[Q(s, \\mu(s|\\theta^{\\mu})|\\theta^{Q})],$ (20)\nwhere $\\theta^{\\mu}$ and $\\theta^{Q}$ are the parameters of the actor and critic functions, respectively, $\\mu(s|\\theta^{\\mu})$ is the actor's action under the policy $p^{\\mu}$, $Q(s, a|\\theta^{Q})$ is the evaluation of the critic function under state s, action $\\mu(s|\\theta^{\\mu})$, and parameter $\\theta^{Q}$. In addition, the critic network is updated by minimizing the loss function\n$L_{critic} = E_{\\{s,a,r,s'\\}~R}[(Y_i - Q(s_i, a_i|\\theta^{Q}))^2],$ (21)\nwhere $\\{s, a, r, s'\\}$ denotes the tuple sampled from the experi- ence replay buffer R, $y_i$ represents the target evaluation value, which is given by\n$Y_i = r + \\gamma Q' (s', \\mu' (s'|\\theta^{\\mu'})|\\theta^{Q'}),$ (22)\nwhere $Q'$ and $\\mu'$ are the target critic and target actor functions, and $\\gamma$ is the discount factor. The utilization of experience replay and target functions helps stabilize training by breaking the correlation between consecutive updates and reducing the variance of the update target, respectively. The proposed DDPG-based LARA algorithm is shown in Algorithm 1.\nComplexity Analysis: In the LARA algorithm, the time complexity of each training step mainly includes the forward and backward propagation complexities of the actor and critic functions, as well as the complexity of updating the target functions. Therefore, the total time complexity of Algorithm 1 can be expressed as $O(L_A \\cdot n_a^2 + L_c \\cdot n_c^2 + N_n)$, where $L_A$ and $L_c$ are the numbers of layers in the actor and critic functions, $n_a$ and $n_c$ are the number of neurons per layer, and $N_N$ is the number of network parameters. The testing time complexity is primarily determined by the forward propagation of the actor network, which is $O(L_A \\cdot n_a^2)$. Moreover, the"}, {"title": "total space complexity includes the storage requirements for the parameters and the experience replay buffer, which are $O(2\\cdot (L_A \\cdot n_a^2 + L_c \\cdot n_c^2))$ and $O(M_R \\cdot (d_s + d_a + 1))$, respectively, where $M_R$ is the size of the experience replay buffer, $d_s$ and $d_a$ are the dimensions of the state space and action space.", "content": "IV. NUMERICAL RESULTS\nIn this section, we test the performance of the proposed LARA algorithm by comparing it with two benchmarks: 1) fixed resource allocation (FRA) algorithm, where the optimiza- tion variables in P1 are fixed; 2) random resource allocation (RRA) algorithm, where the optimization variables in P1 are randomly selected in the feasible region. The distances between the ES and the MU $U_{comp}$, the MU $U_{AIGC}$, and the MU $U_{VE}$, are 100, 120, 80 meters, respectively. The transmit power of the MUs are $P_{comp} = P_{VE} = 15W$, and the system bandwidth is $B_{off} = B_{back} = 400MHz$. The transmit power of the ES is $P = 15W$. The offloading task data volume of the MUs $U_{comp}$ and $U_{ve}$ follows a uniform distribution of [1,8] Mbits. The noise power density is $N_0 = -100dBm/Hz$. The GPT-4 is employed as the AIGC model [2], and the generation-related parameters $\\xi$ and $\\epsilon$ are $9.97 \\times 10^{-14}$ and 5.73, respectively. The generated data volume $D_{aigc}^{ES}$ and $D_{VE}$ are taken from [2, 16] Mbits according to specific AIGC and VE requests, respectively.\nFig. 3 illustrates the training process of the proposed LARA algorithm across different learning rates (LRs). The orange curve shows that a smaller LR results in excessively slower updates in policy, increasing the possibility of falling into a sub-optimal policy. Hence, a smaller LR may not yield better outcomes. The blue curve demonstrates that an appropriate LR can facilitate the training process, achieving faster convergence performance. Fig. 4 shows the latency performance versus the training episodes for the three MUs. Despite each MU having distinct service requirements and varying communication and computation resources, the latency of each MU eventually converges. This observation validates the effectiveness and adaptability of the proposed LARA algorithm in tackling complex and heterogeneous resource allocation problems."}, {"title": "does not request AIGC or VE services at the ES, while the backhaul transmission latency for the computation results can be ignored. In contrast, the MUS $U_{AIGC}$ and $U_{ve}$ require the computation resources of the ES for the AIGC/VE services, and also require the backhaul transmissions for the results with an assignable amount of data volume.", "content": "V. CONCLUSION\nThis letter investigated the latency minimization problem in an MEGC system to provide computation, AIGC, and VE services for MUs. The bandwidth allocation, the back-haul transmit power, the computation resources, and the task offloading ratio, are jointly optimized. A novel DRL-based LARA algorithm is designed to solve the optimization prob-lem. Finally, simulation results demonstrate that the proposed LARA algorithm outperforms the baseline algorithms in terms of the latency performance."}]}