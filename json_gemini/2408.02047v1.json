{"title": "Latency-Aware Resource Allocation for Mobile Edge Generation and Computing via Deep Reinforcement Learning", "authors": ["Yinyu Wu", "Xuhui Zhang", "Jinke Ren", "Huijun Xing", "Yanyan Shen", "Shuguang Cui"], "abstract": "Recently, the integration of mobile edge computing (MEC) and generative artificial intelligence (GAI) technology has given rise to a new area called mobile edge generation and computing (MEGC), which offers mobile users heterogeneous services such as task computing and content generation. In this letter, we investigate the joint communication, computation, and the AIGC resource allocation problem in an MEGC system. A latency minimization problem is first formulated to enhance the quality of service for mobile users. Due to the strong coupling of the optimization variables, we propose a new deep reinforcement learning-based algorithm to solve it efficiently. Numerical results demonstrate that the proposed algorithm can achieve lower latency than two baseline algorithms.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, artificial intelligence generative content (AIGC) has gained widespread attention due to its powerful creative ability for a variety of content, such as images, videos, and music [1]. Several examples, including the generative pre-trained transformer (GPT) developed by OpenAI and the WaveNet developed by DeepMind, have shown great potential in enhancing communication performance for the next-generation wireless networks [2]. By deploying AIGC services at the network edge, lower latency and reduced communication overhead can be achieved for mobile users (MUs) [3]. Meanwhile, computing services remain crucial due to the increasing demand for handling computationally intensive tasks for MUs [4]. By processing task data at the network edge, the shortcomings of network congestion and long latency in conventional mobile computing systems can be addressed [5]. Hence, the integration of communication, computing, and generation services at the network edge is promising to address the heterogeneous requests in future wireless networks.\nSeveral pioneering works have exploited the applications of AIGC services in mobile edge computing (MEC) systems [1], [3], [6], [7]. An edge intelligence infrastructure was proposed to provide personalized and low latency AIGC services [1]. To improve the user utility, a pricing-based mechanism was proposed in [6], which investigated the efficient AIGC ser- vices. Moreover, a mobile edge generation (MEG) system was proposed to reduce the distributed computation and transmis- sion overhead [3]. Furthermore, an MEG enabled digital twin system was studied in [7], which can be applied in both single- user and multi-user scenarios. Besides, the heterogeneous services in MEC systems were investigated in previous works [8]\u2013[10]. A three-stage heterogeneous computing model was proposed in [8] to practically describe the computation process of parallelizable tasks. To maximize the computation efficiency of a multi-server system, an advantage-actor-critic-based deep reinforcement learning (DRL) method was proposed in [9]. In [10], an unmanned aerial vehicle assisted heterogeneous MEC system was studied, where the MUs chose different service providers to maximize the task computation volume. Additionally, to minimize the average latency and improve the MU\u2019s quality of experience, the joint optimization of data offloading, resource allocation, and data caching time are investigated in [11].\nMost previous works focus on the computing resource assignments or the AIGC service allocations in MEC and MEG, while the integration of MEC and MEG to provide heterogeneous services for MUs has not been exploited. To provide heterogeneous computation, AIGC, and vision en- hancement (VE) services for MUs while improving the user experience, we aim to minimize the average latency of all MUS in a novel mobile edge generation computing (MEGC) system. A DRL-based latency-aware resource allocation algorithm is proposed to jointly optimize the bandwidth allocation, the backhaul transmit power, the computation resources, and the task offloading ratio. The superior latency performance of the proposed algorithm is verified by comparing to two benchmark algorithms."}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "To enable the heterogeneous task requirements, we consider an MEGC system that can provide both computation services and AIGC services, as illustrated in Fig. 1. The MEGC system consists of an edge server (ES) equipped with a powerful computing and generating unit, and three MUs with different task requests, including computation, AIGC, and VE, respectively. Let Ucomp, Uaigc, Uve denote the MUs with computation task, AIGC task, and VE task, respectively. The serving time is index by T = {1,\u2026\u2026,T}. Each MU requests one service during each time slot, and the frequency division multiple access (FDMA) technology is adopted in each time slot of request turn. The system model is shown in Fig 1.\nAs illustrated in Fig. 2, the MEGC system consists of two stages: data offloading and result backhaul transmission. In the data offloading stage, the MUs Ucomp and UVE need to offload their data to the ES, while the MU UAIGC only needs to offload a request to the ES. During the backhaul transmission stage, the ES transmits the generated content and processed images/videos to the MUs Uaigc and Uve, respectively, and transmits the computing results to the MU Ucomp.\nSince the FDMA technology is adopted, the bandwidth resource is optimized to allocate for different MUs within each time slot. Let Boff denote the bandwidth allocated to the offloading stage. Thus, the offloading rates of the MU Ucomp and Uve at time slot t are expressed respectively as\n\\(r_{comp}^{off}(t) = \\alpha_{comp}^{off}(t) B_{off} \\log_2 (1+\\frac{P_{comp}h_{comp}^{off}(t)}{\\alpha_{comp}^{off}(t) B_{off} N_o})\\),\n(1)\n\\(r_{VE}^{off}(t) = \\alpha_{VE}^{off}(t) B_{off} \\log_2 (1+\\frac{P_{VE}h_{VE}^{off}(t)}{\\alpha_{VE}^{off}(t) B_{off} N_o}),\\)\n(2)\nwhere \\(\\alpha_{comp}^{off}(t) \\in [0, 1]\\) and \\(\\alpha_{VE}^{off}(t) \\in [0, 1]\\) are the bandwidth allocation ratios of the MUs Ucomp and Uve, which satisfy \\(\\alpha_{comp}^{off}(t)+\\alpha_{VE}^{off}(t) = 1,\\forall t\\). Pcomp and pve denote the transmit power the MUs Ucomp and Uve, respectively. \\(h_{comp}^{off}(t)\\) rep- resents the line-of-sight (LoS) channel gain between the MU Ucomp and the ES, and \\(h_{VE}^{off}(t)\\) is the LoS channel gain between the MU UVE and the ES. No is the power spectral density.\nSimilarly, let Bback denote the bandwidth allocated to the backhaul transmission stage. Then, the backhaul transmission rates of the MUs Uaigc and Uve are given by\n\\(r_{AIGC}^{back}(t) = \\alpha_{AIGC}^{back}(t) B_{back} \\log_2(1+\\frac{\\beta (t)Ph_{AIGC}^{back}(t)}{\\alpha_{AIGC}^{back}(t) B_{back} N_o}),\\)\n(3)\n\\(r_{VE}^{back}(t) = \\alpha_{VE}^{back}(t) B_{back} \\log_2(1+\\frac{(1-\\beta (t))Ph_{VE}^{back}(t)}{\\alpha_{VE}^{back}(t) B_{back} N_o}),\\)\n(4)\nwhere \\(\\alpha_{AIGC}^{back}(t) \\in [0, 1]\\) and \\(\\alpha_{VE}^{back}(t) \\in [0, 1]\\) are the bandwidth allocation ratios of the MUS UAIGC and Uve, which satisfy \\(\\alpha_{AIGC}^{back}(t) + \\alpha_{VE}^{back}(t) = 1, \\forall t\\). \\(h_{AIGC}^{back}(t)\\) represents the LoS channel gain between the ES and the MU UAIGC, and \\(h_{VE}^{back}(t)\\) is the LoS channel gain between the ES and the MU UVE. P is the transmit power of the ES. \\(\\beta(t) \\in [0,1]\\) is the power allocation ratio to the ES for communicating with the MU UAIGC, while 1 \u2013 \\(\\beta(t)\\) is the power allocation ratio for the ES to communicate with the MU UVE.\nB. Latency Model\na) Latency of MU Ucomp: The MU Ucomp requests data computing services. At the beginning of each time slot, a data packet is arrived with data volume Dcomp, which follows a Poisson distribution with density px Mbits. Assume that the data packet can be partially computed by its local processor and partially offloaded to the ES for computing. Let \\(\\lambda(t)\\) denote the ratio of the data packet offloaded to the ES at time slot t. Then, the offloading latency is given by\n\\(L_{comp}^{off}(t) = \\frac{\\lambda(t) D_{comp}(t)}{r_{comp}^{off}(t)}\\)\n(5)\nAssume the local computing capability of the MU Ucomp is fcomp central processing unit (CPU) cycles per second. The local computing latency is thus represented by\n\\(L_{comp}^{local}(t) = \\frac{(1 - \\lambda(t))x D_{comp}}{f_{comp}}\\),\n(6)\nwhere x denotes the number of CPU cycles for computing one bit data. Meanwhile, the computing latency of the ES for processing the data offloaded by the MU Ucomp at time slot t is given by\n\\(L_{comp}^{ES}(t) = \\frac{\\lambda(t)x D_{comp}}{\\omega_{comp}(t) f_{ES}}\\)\n(7)\nwhere fes is the maximum computing capability of the ES, and \\(\\omega_{comp}(t)\\) denotes the ratio of the computation resources allocated to the MU Ucomp at time slot t.\nThe overall latency of the MU Ucomp is the maximum of the latency between local computing and ES computing, which is derived as\n\\(L_{comp}(t) = max(L_{comp}^{local}(t), L_{comp}^{off}(t) + L_{comp}^{ES}(t))\\).\n(8)\nb) Latency of MU UAIGC: The MU UAIGC requests AIGC services. Since the data volume of the request is very small, the time latency for transmitting the request can be ignored. After receiving the request, the ES begins to generate results. The time latency for AIGC inference is given by\n\\(L_{AIGC}^{ES}(t) = \\frac{\\xi x D_{AIGC}^{ES}(t) + \\delta}{\\omega_{AIGC} (t) f_{ES}}\\)\n(9)\nwhere \\(D_{AIGC}^{ES}(t)\\) is the data volume of the expected AIGC results, related to the image resolution. \\(\\xi\\) is the coefficient related to the ES-embedded LLM and computing hardware, and \\(\\delta\\) is the coefficient related to the minimum computing resources required for a small-scale image inference at the ES. Besides, \\(\\omega_{AIGC}(t)\\) denotes the ratio of the computation re- sources allocated to the MU UAIGC at time slot t. Accordingly, the latency for transmitting the AIGC results to the MU UAIGC can be expressed by\n\\(L_{AIGC}^{back}(t) = \\frac{D_{AIGC}^{ES} D_{AIGC}(t)}{r_{AIGC}^{back} (t)}\\)\n(10)\nHence, the overall latency of the MU UAIGC is given by\n\\(L_{AIGC}(t) = L_{AIGC}^{ES}(t) + L_{AIGC}^{back}(t)\\).\n(11)\nc) Latency of MU UVE: The MU Uve requests VE services, i.e., the image and/or video processing services. One service consists of three parts: the original data offloading, the data inference at the ES, and the backhaul transmission of the inference results. Accordingly, the latency for data offloading can be given by\n\\(L_{VE}^{off}(t) = \\frac{D_{VE}(t)}{r_{VE}^{off} (t)},\\)\n(12)\nwhere Dve(t) is the offloading data volume of the MU UVE. Then, the latency for ES processing for the offloading data can be expressed as\n\\(L_{VE}^{ES}(t) = \\frac{\\epsilon D_{VE}^{ES}(t) + \\zeta}{\\omega_{VE}(t).f_{ES}}\\)\n(13)\nwhere \\(D_{VE}^{ES}(t) = \\epsilon D_{VE}(t)\\) denotes the expected processed data at the ES with enhancement coefficient &, and \\(\\omega_{VE}(t)\\) denotes the ratio of the data processing resources allocated to the MU UVE at time slot t. Moreover, the latency for the backhaul transmission of the inference results is thus given by\n\\(L_{VE}^{back}(t) = \\frac{D_{VE}^{ES}(t)}{r_{VE}^{back} (t)}\\)\n(14)\nAs a result, the overall latency of the MU Uve is given by\n\\(L_{VE}(t) = L_{VE}^{off}(t) + L_{VE}^{ES}(t) + L_{VE}^{back}(t).\\)\n(15)\nC. Problem Formulation\nIn this letter, we aim to minimize the average of the overall latency of all MUs to improve the quality of heterogeneous services. Hence, the problem can be formulated as\n\\((P1) min_{\\alpha,\\beta,\\omega,\\lambda} \\frac{1}{T} \\sum_{t \\in T} L_{comp}(t) + L_{AIGC}(t) + L_{VE}(t)\\)\ns.t. \\(\\alpha_{comp}^{off}(t), \\alpha_{VE}^{off}(t) \\in [0, 1],\\)\\forall t\\in T\\),\n(16a)\n\\(\\alpha_{comp}^{off}(t) + \\alpha_{VE}^{off}(t) = 1, \\forall t \\in T\\),\n(16b)\n\\(\\alpha_{AIGC}^{back}(t), \\alpha_{VE}^{back}(t) \\in [0,1], \\forall t \\in T\\),\n(16c)\n\\(\\alpha_{AIGC}^{back}(t) + \\alpha_{VE}^{back}(t) = 1, \\forall t \\in T\\),\n(16d)\n\\(\\beta (t), \\lambda(t) \\in [0,1], \\forall t\\in T\\),\n(16e)\n\\(\\omega_{comp} (t), \\omega_{AIGC}(t), \\omega_{VE}(t) \\in [0, 1], \\forall t\\in T\\),\n(16f)\n\\(\\omega_{comp}(t) + \\omega_{AIGC}(t) + \\omega_{VE}(t) = 1, \\forall t\\in T\\),\n(16g)\nconstraints (16b)-(16d) are the bandwidth allocations, con- straint (16e) denotes the power allocation for the ES backhaul transmission, and the offloading ratio of the MU Ucomp, respec- tively, and constraints (16f)-(16g) represent the computation resources allocation of the ES."}, {"title": "III. DRL-BASED RESOURCE ALLOCATION ALGORITHM", "content": "Since the optimization variables of the bandwidth allocation a, the transmit power allocation of the ES B, the computation resource of the ES w, and the offloading ratio A are highly coupled, the problem P1 is hard to solve by traditional optimization algorithms. Fortunately, DRL can effectively ad- dress complex resource allocation challenges by dynamically adapting decisions to changing environments that include varying channels and diverse task requests [12]. Therefore, we propose a DRL-based latency-aware resource allocation (LARA) algorithm for solving problem P1.\nIt is observed that the problem P1 can be reformulated as a Markov decision process (MDP), described by a tuple {s(t), a(t), r(t), \u2200t}, where s(t) denotes the system state, a(t) represents the decision action, and r(t) denotes the reward value for taking the action a(t) at the state s(t).\nSpecifically, let S denote the state space, which encom- passes the channel conditions and task data sizes of all MUs. Hence, the state s(t) at time slot t is given by\ns(t) = [h(t), Dcomp(t), DVE(t)], \u2200t,\n(17)\nwhere h(t) = {\\(h_{comp}^{off} (t), h_{AIGC}^{back} (t), h_{VE}^{off}(t), h_{VE}^{back} (t)\\)} includes the channel state information in the data offloading stage and the result backhaul transmission stage. Moreover, the action space A consists of all decision variables in problem P1, and the action a(t) at time slot t can be represented as\na(t) = [\\alpha(t), \\beta (t), \\lambda (t), \\omega(t)], \\forall t,\n(18)\nwhere \\(\\alpha(t)\\)\n= \\([\\alpha_{comp}^{off} (t), \\alpha_{VE}^{off} (t), \\alpha_{AIGC}^{back} (t), \\alpha_{VE}^{back}(t)]\\)\ndenotes the bandwidth allocations, and \\(\\omega(t)\\)\n= \\([\\omega_{comp} (t), \\omega_{AIGC}(t), \\omega_{VE}(t)]\\) represents the computation resource allocations. Since our goal is to minimize the overall latency of all MUs, we define the reward function as\nr(t) = - \\frac{1}{T} \\sum_{t\\in T} L_{comp} (t) + L_{AIGC}(t) + L_{VE}(t), \\forall t,\n(19)\nwhich is the opposite of the objective function of P1.\nBased on the above definition, we then use the deep deter- ministic policy gradient (DDPG) method to solve problem P1 according to the MDP reformulation [13]. DDPG is a model- free off-policy actor-critic method designed for environments with continuous action spaces. It can approximate both the policy function (i.e., the actor function for giving actions) and the value function (i.e., the critic function that evaluates the action given by the actor function) to enable efficient and stable learning. DDPG combines the deterministic policy gradient approach with the benefits of experience replay and target functions, providing robust performance in complex, high-dimensional tasks. Specifically, the actor function is updated by minimizing the loss function\n\\(L_{actor} = -E_{s~p^{\\mu}}[Q(s, \\mu(s|\\theta^{\\mu})|\\theta^{Q})],\\)\n(20)\nwhere \\(\\theta^{\\mu}\\) and \\(\\theta^{Q}\\) are the parameters of the actor and critic functions, respectively, \\(\\mu(s|\\theta^{\\mu})\\) is the actor\u2019s action under the policy p\u2122, Q(s, a|0) is the evaluation of the critic function under state s, action \\(\\mu(s|\\theta^{\\mu})\\), and parameter \\(\\theta^{Q}\\). In addition, the critic network is updated by minimizing the loss function\n\\(L_{critic} = E_{(s,a,r,s')~R}[(Y_{i} - Q(s_{i}, a_{i}|\\theta^{Q}))^{2}],\\)\n(21)\nwhere {s, a, r, s\u2019} denotes the tuple sampled from the experi- ence replay buffer R, yi represents the target evaluation value, which is given by\n\\(Y_{i} = r + \\gamma Q' (s', \\mu' (s'|\\theta^{\\mu'})|\\theta^{Q'}),\\)\n(22)\nwhere Q\u2019 and ' are the target critic and target actor functions, and y is the discount factor. The utilization of experience replay and target functions helps stabilize training by breaking the correlation between consecutive updates and reducing the variance of the update target, respectively. The proposed DDPG-based LARA algorithm is shown in Algorithm 1.\nComplexity Analysis: In the LARA algorithm, the time complexity of each training step mainly includes the forward and backward propagation complexities of the actor and critic functions, as well as the complexity of updating the target functions. Therefore, the total time complexity of Algorithm 1 can be expressed as O(LA \u00b7 n\u00b2 + Lc \u2022 n\u0109 + Nn), where LA and Lc are the numbers of layers in the actor and critic functions, na and no are the number of neurons per layer, and NN is the number of network parameters. The testing time complexity is primarily determined by the forward propagation of the actor network, which is O(LA\u00b7n\u00b2). Moreover, the total space complexity includes the storage requirements for the parameters and the experience replay buffer, which are O(2\u00b7 (La \u00b7 n\u00b2 + Lc \u2022 n\u311b)) and O(MR \u00b7 (ds + da + 1)), respectively, where MR is the size of the experience replay buffer, ds and da are the dimensions of the state space and action space."}, {"title": "IV. NUMERICAL RESULTS", "content": "In this section, we test the performance of the proposed LARA algorithm by comparing it with two benchmarks: 1) fixed resource allocation (FRA) algorithm, where the optimiza- tion variables in P1 are fixed; 2) random resource allocation (RRA) algorithm, where the optimization variables in P1 are randomly selected in the feasible region. The distances between the ES and the MU Ucomp, the MU UAIGC, and the MU UVE, are 100, 120, 80 meters, respectively. The transmit power of the MUs are Pcomp = PVE = 15W, and the system bandwidth is Boff = Bback = 400MHz. The transmit power of the ES is P = 15W. The offloading task data volume of the MUs Ucomp and Uve follows a uniform distribution of [1,8] Mbits. The noise power density is No = -100dBm/Hz. The GPT-4 is employed as the AIGC model [2], and the generation-related parameters \\(\\xi\\) and \\(\\delta\\) are 9.97 \u00d7 10-14 and 5.73, respectively. The generated data volume DAIGC DES and DVE are taken from [2, 16] Mbits according to specific AIGC and VE requests, respectively.\nFig. 3 illustrates the training process of the proposed LARA algorithm across different learning rates (LRs). The orange curve shows that a smaller LR results in excessively slower updates in policy, increasing the possibility of falling into a sub-optimal policy. Hence, a smaller LR may not yield better outcomes. The blue curve demonstrates that an appropriate LR can facilitate the training process, achieving faster convergence performance. Fig. 4 shows the latency performance versus the training episodes for the three MUs. Despite each MU having distinct service requirements and varying communication and computation resources, the latency of each MU eventually converges. This observation validates the effectiveness and adaptability of the proposed LARA algorithm in tackling complex and heterogeneous resource allocation problems.\nFig. 5 shows the latency of each MU and the total latency for all MUs under the proposed LARA algorithm and two benchmark algorithms. The proposed LARA algorithm can achieve the smallest latency among the three algorithms. The reason is that the proposed LARA algorithm is capable of adjusting the action according to the time-varying state information. Furthermore, each MU\u2019s latency performance in the proposed LARA algorithm achieves the lowest latency compared to the corresponding MU in the benchmarks. The fairness of the proposed LARA algorithm to provide services to all MUs at the same time is thus verified. In addition, we can observe that the latency of the MU Ucomp is the lowest among the three MUs. The reason is that the MU Ucomp does not request AIGC or VE services at the ES, while the backhaul transmission latency for the computation results can be ignored. In contrast, the MUS UAIGC and Uve require the computation resources of the ES for the AIGC/VE services, and also require the backhaul transmissions for the results with an assignable amount of data volume."}, {"title": "V. CONCLUSION", "content": "This letter investigated the latency minimization problem in an MEGC system to provide computation, AIGC, and VE services for MUs. The bandwidth allocation, the back- haul transmit power, the computation resources, and the task offloading ratio, are jointly optimized. A novel DRL-based LARA algorithm is designed to solve the optimization prob- lem. Finally, simulation results demonstrate that the proposed LARA algorithm outperforms the baseline algorithms in terms of the latency performance."}]}