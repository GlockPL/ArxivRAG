{"title": "Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models", "authors": ["Yuki Hou", "Haruki Tamoto", "Homei Miyashita"], "abstract": "Conventional dialogue agents often struggle with effective memory recall, leading to redundant retrieval and inadequate management of unique user associations. To address this, we propose SynapticRAG, a novel approach integrating synaptic dynamics into Retrieval-Augmented Generation (RAG). SynapticRAG integrates temporal representations into memory vectors, mimicking biological synapses by differentiating events based on occurrence times and dynamically updating memory significance. This model employs temporal scoring for memory connections and a synaptic-inspired propagation control mechanism. Experiments across English, Japanese, and Chinese datasets demonstrate SynapticRAG's superiority over existing methods, including traditional RAG, with up to 14.66% improvement in memory retrieval accuracy. Our approach advances context-aware dialogue Al systems by enhancing long-term context maintenance and specific information extraction from conversations.", "sections": [{"title": "Introduction", "content": "Recent advancements in transformer-based large language models (LLMs), such as GPT-4 (OpenAI 2023) and Claude 3 Opus (Anthropic 2024a), have revolutionized dialogue agents, allowing them to mimic human cognitive processes. However, these models still face challenges in temporal dynamics for memory retrieval and consolidation, particularly with homogeneous recall of event-related memories, where top recall candidates often exhibit redundancy or similarity due to encoding issues.\nTo address this limitation, we propose a memory architecture that incorporates temporal representations into memory vectors, spatially reflecting temporal distances and enhancing the diversity of recalled memories. This method improves memory retrieval granularity and ensures a broader spectrum of contextual relevance in interactions. Research suggests that memory retrieval depends more on retrieval triggers than memory strength (McDaniel and Einstein 2000; Tulving 1985). Strong synaptic connections between memory nodes facilitate the simultaneous recall of multiple related memories (Hebb 1949; Neves, Cooke, and Bliss 2008). Our approach dynamically updates these connections using dynamic time warping (DTW) to calculate cumulative distance matrices between stimulated time arrays of memory nodes (Sakoe and Chiba 1978; Muller 2007).\nThe proposed model includes a propagation control mechanism to prevent excessive stimulus spread across the network, ensuring efficient recall by limiting stimuli to child nodes based on cosine similarity thresholds and using a leaky integrate-and-fire (LIF) model for node activation (Brunel and van Rossum 2007; Gerstner et al. 2014). Unlike retrieval-augmented generation (RAG) (Lewis et al. 2020), our model's dynamic integration of temporal representations enables a more nuanced handling of temporal and contextual dynamics.\nThis framework addresses the challenges of temporal memory retrieval in dialogue agents, paving the way for more sophisticated context-aware dialogue Al agent systems. Moreover, it enhances the agents' understanding of user interactions and their ability to engage in meaningful dialogues by simulating human-like memory processes. We hope this study advances human-computer interaction, fostering a future where technology is closely aligned with human needs and mirrors our cognitive behaviors and life experiences."}, {"title": "Related Work", "content": "Memory Retrieval in AI Systems\nA comprehensive understanding of human memory processes provides a basis for comparing and developing AI memory systems (Murdock 1982). Recent advancements include systems using external databases for memory augmentation in LLMs (Zhong et al. 2023), enhancing the context-awareness of AI responses. More comprehensive approaches, such as generative agents stimulating credible human behavior (Park et al. 2023), extend LLMs to store, organize, and retrieve agent's experiences, enabling realistic behaviors in interactive environments.\nMemory architectures have been developed to enhance the cognitive abilities of dialogue agents based on LLMs (Hou, Tamoto, and Miyashita 2024). These systems autonomously recall relevant memories for response generation, managing memory significance in a temporal context similar to human memory recall. RAG combines retrieval and generation-based methods to improve response relevance and accuracy (Lewis et al. 2020; Borgeaud et al. 2022). However, these systems struggle to address memories with low cosine similarity in the vector space, which might have unique associations for users, making it difficult to dynamically update their relationships."}, {"title": "Memory Models Inspired by Biological Synaptic Plasticity", "content": "Recent advancements in spiking neural networks (SNNs), inspired by synaptic plasticity in biological neural networks (Citri and Malenka 2008), have enhanced AI adaptability and learning.\nNotable examples include differentiable plasticity models for neural networks (Miconi, Clune, and Stanley 2018) and models incorporating multiple timescales of synaptic plasticity (Benna and Fusi 2015), improving performance in continual learning and long-term memory formation tasks.\nThese models face challenges related to scalability, biological plausibility, and efficient retrieval. Addressing these limitations is crucial for developing advanced, human-like memory mechanisms in AI systems.\nWhile studies on the dynamics of neural networks, including Spiking SNNs (Maass 1997; Tavanaei et al. 2019), aim to replicate memory microscopically, this study treats text as memory to reproduce human memory processes via neuroscientific perspectives microscopically. This approach reduces computational costs with a minimal network compared to microscopic models and allows for seamless integration of recalled memories into existing LLM-based agents."}, {"title": "SynapticRAG: A Memory Retrieval Model for Enhanced Temporal Awareness", "content": "SynapticRAG integrates temporal representations into node vectors, which traditionally contain only spatial semantics, and formalizes the semantic and temporal relationships of each memory node. Vectorized memories are stored as nodes, each with a weighted spike train. The stimulus value each node receives is stored as a two-dimensional array along with the recorded time. The input vector is treated as the original node, and the stimulus propagates to neighboring nodes in the vector space. When a node accumulates enough stimulus, it fires using an integrate-and-fire model. If a node fires, the memory it represents is recalled and provided to the agent as information. Figure 1 shows the overall process flow of the SynapticRAG model."}, {"title": "Stimulus Propagation Scoring", "content": "We define the propagation of stimuli from parent nodes to child nodes, considering nodes X, Y, and Z, where the stimulus propagates from X to Y to Z.\nFor propagation from X to Y, X is the input vector and Y is a neighboring vector. Nodes with a cosine similarity below the threshold with X are discarded, and propagation occurs on the remaining nodes, including Y. The spike train time arrays for X and Y are extracted, and a cumulative distance matrix is calculated using the DTW method to determine the optimal path. This distance matrix's elements $d_i$ are then processed using the following function:\n$f(x) = exp\\left(-\\frac{d_i}{\\tau}\\right)$                                                                                  (1)\nHere, $\\tau$ represents the average strength of the connected memory nodes, indicating the characteristic time scale over which memory connections decay. A larger $\\tau$ signifies stronger, more persistent memories, retaining information longer, while a smaller $\\tau$ implies faster decay and transient connections, leading to quicker information loss. This parameter allows the model to express memory retention and forgetting at different time scales, emulating the variability in human memory processes.\nAs shown in the left part of Figure 2, the stimulus propagation scoring process involves multiple layers, activating memories based on their cosine similarity to the user input vector. The function $f(d_i)$ represents the updated connection weight over time, assigning higher scores to closer events and lower scores to more distant ones. The exponential decay ensures the score diminishes as temporal distance increases. This function, chosen for its biological plausibility, mathematical tractability, and alignment with observed memory phenomena, emulates human forgetting curves, simplifies calculations, and provides a non-linear decay model with rapid initial forgetting followed by slower long-term decay.\nThe scores for each element calculated with $f(d_i)$ are summed and normalized to a range of 0 to 1. A monotonically increasing function is used for this normalization process to map the scores:"}, {"title": "Dynamic Leaky Integrate-and-Fire Model", "content": "The parameters discussed in this section are inherent values stored in each node. Although the definitions of spike trains and time constants match those in the previous chapter, the parameter values here are distinct.\nIn the dynamic LIF model, the weighted spike train is received, and firing determination and parameter updates are performed. The time constant increases each time a node receives a stimulus. Given the time interval $\\Delta t$ between a successive stimuli, the time constant $\\tau$ is updated by the following equation:\n$\\tau(t + \\Delta t) = \\tau(t) + \\frac{1 - exp(-\\Delta t)}{1 + exp(-\\Delta t)}$                                                                                                 (4)\nThis update equation for $\\tau$ captures the dynamic nature of synaptic plasticity. The term $(1 \u2013 exp(-\\Delta t))/(1 + exp(-\\Delta t))$ is a sigmoidal function ranging from 0 to 1. For small $\\Delta t$ (frequent stimuli), this term approaches 0, causing minimal changes to $\\tau$. For large $\\Delta t$ (infrequent stimuli), it approaches 1, significantly increasing $\\tau$.\nThe sigmoidal nature ensures bounded growth of $\\tau$, aligning with biological constraints. It is more sensitive to changes in $\\Delta t$ when stimuli are infrequent, emulating biological synapses. The update is always positive and bounded, ensuring stable long-term behavior.\nDiscrete spike trains $S_t$ are converted into a differentiable form using Dirac's delta function $\\delta(t)$ and the set of firing times $\\Gamma$. The input current $I(t)$ is then calculated as follows:\n$\\frac{dI}{dt} = -\\frac{1}{\\tau}I(t) + \\sum_{t_f \\in \\Gamma} S_t\\delta(t - t_f)$                                                                                                                                 (5)\nSubsequently, the time evolution of the membrane potential $V(t)$ is expressed using the following differential equation:\n$\\frac{dV}{dt} = -\\frac{1}{\\tau}V(t) + I(t)$                                                                                                                                                                (6)\nThis equation shows that the membrane potential changes in response to the input current. $\\tau$ is the time constant of the membrane potential, determining the rate. The right side of Figure 2 illustrates the membrane potential changes and firing mechanism of our dynamic LIF model, demonstrating how the input current affects the membrane potential over time, leading to neuron firing when the threshold is exceeded.\nIf the calculated membrane potential $V(t)$ exceeds a predetermined firing threshold, the neuron fires, and the membrane potential is reset for the next input. However, the time constant is not reset, maintaining the node's strength. The entire sequence of stimuli received by the node is evaluated, but $V(t)$ is reset immediately after a stimulus to prevent premature firing if the threshold is too high or the initial value of $V(t)$ is too low. The hyperparameters are tuned on a small subset of tasks to address this issue."}, {"title": "Implementation", "content": "Figure 3 illustrates a conversation example demonstrating the system process. The user's input is vectorized using the embedding model text-embedding-3-large (OpenAI 2024) and stored in a vector database with the Faiss library (Douze et al. 2024) for disk storage. Each node stores information such as id, vector, message, fire, v, i, tau, and spike, and is managed by SQL (MySQL 2001). The agent's response in the SynapticRAG model is generated using GPT-4 (OpenAI 2023)."}, {"title": "Memory Management in Vector Database", "content": "The vectorized input is used to search for neighboring vectors, discarding those with a cosine similarity below the threshold. The remaining neighboring vectors receive a stimulus, the product of their temporal similarity score and cosine similarity. Only vectors exceeding the score threshold propagate to the next generation. Fired nodes do not propagate further. The child generation's stimulus is the product of the score and the parent generation's stimulus, always smaller owing to normalization to [0, 1]. Propagation repeats until the stimulus falls below a threshold, ending the process. The dynamic LIF model determines if a stimulated node fires using the accumulated stimulus; further, fired nodes are included in the prompt.\nThe SynapticRAG model is fundamentally a memory management approach designed for efficient memory retrieval, incorporating biological human memory characteristics into the memory retrieval stored in an external database. Although our implementation utilizes the GPT-4 model, users can employ any suitable LLM."}, {"title": "Prompting For Response Generation", "content": "An effective prompt for an LLM agent using SynapticRAG should include instructions for comprehensive context understanding, guiding the agent to recognize the relevance between past conversation history and the current dialogue. It should also provide guidance on efficiently leveraging related memories retrieved, including analyzing relationships among multiple relevant memories, and emphasize the importance of recognizing temporal context. An example of a prompt structure for a dialogue agent is given below:\n\"Your task is to provide responses that align with {username}'s daily life context. The current time is {current_time}. Recall the event {fired_memories} from {event_happened_time}. Please respond in a way that clearly demonstrates your recollection of past conversations.\""}, {"title": "Experiment", "content": "To evaluate the proposed method, we used two datasets: a custom-created synaptic memory retrieval conversations (SMRCS) dataset and the PerLTQA dataset (Du et al. 2024). These datasets were chosen for their chronological dialogue format, context accumulation, and explicit correct answers.\nThe SMRCs dataset, created using Claude 3.5 Sonnet (Anthropic 2024b), contains 101 conversation sets, each with a past and present conversation. It includes 206 memory recall triggers and 456 related memory tasks across diverse themes, testing the model's ability to maintain long-term context and recall multiple relevant pieces of information. The dataset is available in English and Japanese.\nThe PerLTQA dataset comprises 625 conversation sets, encompassing 2,665 QA tasks. Each conversation contains multiple QA pairs, with one correct label per question. It is available in English and Chinese. We filtered this dataset to exclude dialogues without QA pairs and instances where answers had low relevance to the conversation (cosine similarity < 0.5), ensuring quality and relevance.\nUsing these datasets allows for the comprehensive evaluation of our model's ability to maintain complex, long-term contexts (SMRCs) and extract specific information from conversations (PerLTQA). The availability in multiple languages supports a robust cross-lingual of the model's capabilities. These task counts are sufficient to obtain statistically significant results, and by utilizing all tasks in each dataset, we comprehensively evaluate the performance of the model."}, {"title": "Baseline Models", "content": "For comparison, we utilize three established models: the standard RAG model (Lewis et al. 2020), the MemoryBank model (Zhong et al. 2023) for long-term memory integration, and the MyAgent model (Hou, Tamoto, and Miyashita 2024) proposed for human-like memory recall and consolidation. RAG implements conventional vector similarity search for information retrieval. MemoryBank integrates long-term information retention and retrieval. MyAgent mimics human memory processes in dialogue systems. We also prepared extended versions of the MemoryBank and MyAgent models with more optimizable hyperparameters. This extension allows for better performance through additional tuning, enabling a fairer comprehensive comparison. These models benchmark the SynapticRAG model, assessing its information retrieval and generation, long-term memory management, and dynamic memory recall."}, {"title": "Extension Methods of Baseline Models", "content": "To optimize the baseline models for our datasets, we introduced additional hyperparameters to each model.\nSpecifically, we introduced multiplicative constants to key variables, including temporal factors, cosine similarities, and model-specific parameters. This fine-tuning process enhances each model's performance, ensuring a fair comparison with the SynapticRAG model.\nFor the MyAgent and MyAgent(Extended) models, the original implementation first filters memories based on cosine similarity and then calculates the recall probability p. In our evaluation, we aimed to retrieve the same number of memories as SynapticRAG from those exceeding the cosine similarity threshold, ranked by p.\nThis approach presented a challenge: if fewer memories than the recall count of SynapticRAG exceeded the cosine similarity threshold, MyAgent models would retrieve fewer memories, resulting in an unfair comparison. Alternatively, ignoring the cosine similarity filter and ranking solely by p could prioritize memories with high p but low cosine similarity, deviating from the intended behavior of the original model. To resolve this issue, we adjusted the p scores by adding 1 for memories exceeding the cosine similarity threshold (where 0 < p < 1). The final ranking was based on these adjusted p scores, allowing us to replicate the original process of cosine similarity filtering followed by p-based recall. This method ensures fairness in evaluation by maintaining consistent recall counts across models while preserving the integrity of the original model's design within our comparative framework.\nThis extension ensures a fair comparison between MyAgent models and SynapticRAG, preserving the essence of the original implementation while meeting our evaluation criteria. Similar adjustments were made for other baseline models, tailored to their specific characteristics and variables."}, {"title": "Setup", "content": "Experiments were conducted on a macOS 14.2.1 system equipped with an Apple M1 processor and 16 GB of RAM. We used Python 3.10.9 (Python 2022), OpenAI's text-embedding-3-large for embeddings, Optuna 3.6.1 (Optuna 2024) for hyperparameter optimization, Faiss 1.8.0 for vector operations, and NumPy 1.26.4 (Numpy 2024) for numerical computations. We vectorized JSON format to transform the text into a numerical format for analysis. The related memory fields were matched with corresponding document indices, serving as the correct labels and establishing the ground truth for our memory recall tasks.\nTrigger documents were augmented with metadata, attaching correct labels to each trigger to evaluate the model's performance in identifying and retrieving relevant memories. We structured data storage using SQL for efficient data management. Each row of the database contains the storing section number, document index, text, correct label, and vector. Identical parameters were applied to both English and Japanese datasets to ensure fairness."}, {"title": "Experimental Methods", "content": "The evaluation of the SynapticRAG model focused on its ability to accurately retrieve relevant memories. We incremented the correct answer count by 1 whenever a retrieved memory matched a correct label and calculated accuracy as the ratio of correct retrievals to total correct labels.\nGiven the variable number of memories retrieved by SynapticRAG, we used two distinct evaluation metrics to ensure a fair comparison with the baseline models:\n1. Equal Retrieval Count (ERC) This evaluation metric ensures that baseline models retrieve the same number of memories as SynapticRAG for each query. For example, if SynapticRAG retrieves four memories, baseline models will also retrieve their top four scoring memories. The RAG model uses cosine similarity for scoring, while other baseline models, which typically retrieve only the highest-scoring memories, have been modified to retrieve multiple memories for their scores to match SynapticRAG's retrieval count.\nWhile this approach ensures an equitable comparison, it has limitations. For instance, if SynapticRAG retrieves no memories for a query, baseline models are also restricted from retrieving any memories. This constraint may potentially limit baseline models from demonstrating their full capabilities. To address this, we introduced a second evaluation metric."}, {"title": "2. Equal Retrieval Count with Minimum Guarantee (ERC-MG)", "content": "This metric addresses ERC's limitations. When SynapticRAG retrieves fewer memories than the number of correct labels, baseline models can retrieve up to the number of correct labels. If SynapticRAG retrieves more, baseline models match its count. While this slightly disadvantages SynapticRAG, it allows baseline models to fully demonstrate their capabilities."}, {"title": "Hyperparameter Optimization", "content": "To optimize our model's hyperparameters, we used Optuna (Akiba et al. 2019), ensuring that the evaluation metric was independent of comparative models. This strategy prevents trivial optimization scenarios where one model's performance is defined relative to that of another. In fact, the optimization and evaluation conditions were distinct. When multiple trials achieved the same best score, we selected the parameter set with the highest ERC evaluation score, ensuring robust performance in both optimization and primary evaluation scenarios.\nThe number of hyperparameters varied across models: MemoryBank (0), MemoryBank(Ext) (5), MyAgent (1), MyAgent(Ext) (4), and SynapticRAG (9), reflecting the complexity and design choices of each model."}, {"title": "Optimization Strategy for Extended Models", "content": "For extended models, which cannot predetermine the number of retrieved memories during evaluation, we optimized to maximize the scores of correct label memories. The process involved normalizing each memory score $s_i$ to the range [0, 1] using the sum of all memory scores in the n-th task, defined as $Sumn = \\sum_{i=1}^{Mn} S_i$, where $M_n$ is the number of memories in the n-th task. We then summed the normalized scores of correct label memories, expressed as $Scoren = \\sum_{j \\in Yn} S_j/Sumn$, where $Y_n$ denotes the set of indices for correct label memories. The final score across all N tasks was calculated as $Score = \\sum_{n=1}^{N} Scoren$. The hyperparameters were optimized to maximize this Score."}, {"title": "Optimization Approach for SynapticRAG", "content": "For the SynapticRAG model, which uses the score v only for threshold judgment, we optimized based on conditions related to fired memories rather than directly using v. Two conditions were imposed. The first condition penalized insufficient correct label memories, defined as $An = \\frac{|Y_n - f_n \\cap Y_n|}{|Y_n|}$, if $|y_n| > |f_n \\cap y_n|$, and 0 otherwise, where $f_n$ is the set of fired memory indices and $y_n$ is the set of correct label indices. The second condition penalized excessive memory retrieval, expressed as $Bn = \\frac{|f_n|}{|Y_n|}$. The final score was calculated as $Score = \\sum_{n=1}^{N}-(A_n + 0.15 * B_n)$. The factor 0.15 was applied to Bn to prevent either condition from becoming dominant. The scaling factor of 0.15 was determined through extensive experimentation across multiple datasets, as it optimally balanced the firing of correct label memories and excessive memory retrieval. Increasing this value tended to penalize excessive retrieval more strongly, reducing the number of retrievals, while decreasing it led to more retrievals and potentially more correct label memories being fired, however with an increased risk of noise. The negative sum was used to avoid potential division by zero issues.\nThe hyperparameters were optimized to maximize this score for the SynapticRAG model Details of the specific hyperparameters are provided below:"}, {"title": "Hyperparameter Settings for Extended Models", "content": "MemoryBank (Extended) The original MemoryBank model calculates memory scores as follows:\nFirst, for each memory:\n$Score(i) = exp\\left(-\\frac{\\Delta t(i)}{s(i)}\\right)$\nwhere $\\Delta t(i)$ is the time difference between when the memory occurred and the current time, and $s(i)$ is the memory strength, with an initial value of 1.\nSubsequently, the Score is cut off by a randomly set threshold $\\Theta$, and memories below this are considered forgotten. We consider the set of memories that exceed the threshold:\n$Retain = \\{i | Score(i) > \\Theta\\}$\nBased on the cosine similarity with the input vector, the top 6 memories are selected from this set:\n$Top6 = argsort_{i \\in Retain}(cos\\_sim(i))[: 6]$\nThe strength s of the selected memories is updated by adding 1:\n$s^{(i)}_0 = 1, s^{(i)}_n = s^{(i)}_1 + 1 for i \\in Top6$\nThe memory strength is updated in this way at each turn.\nIn the Extended model, we introduced five parameters to this model: Top, $\\Theta$, $tscale$, $Sscale$, $Sinit$.\nThe equations are as follows:\n$Score(i) = exp\\left(-\\frac{tscale\\Delta t(i)}{Sscale s(i)}\\right)$\n$Retain = \\{i | Score(i) \\geq \\Theta\\}$\n$Topk = argsort_{i \\in Retain}(cos\\_sim(i))[: k]$\n$s^{(i)}_0 = Sinit, s^{(i)}_n = s^{(i)}_1 + 1 for i \\in Topk$\nThe optimization was performed based on these set parameters."}, {"title": "MyAgent (Extended)", "content": "The original MyAgent model is defined as follows: First, the recall probability p is evaluated for memories exceeding a cosine similarity threshold with the input vector:\n$Retain = \\{i | cos\\_sim(i) \\geq cos\\_th\\}$\np is calculated as:\n$p^{(i)}(t) = \\frac{1 - exp(-r^{(i)}e^{-\\Delta t(i)/g^{(i)}})}{1-e^{-1}}$   for $i \\in Retain$\nwhere $\\Delta t$ is the time difference between memory occurrence and current time, and $g$ is memory strength, initially set to 1.\nThe memory with the highest p is retrieved, and its strength g is updated:\n$j = argmax_{i \\in Retain} (p^{(i)}(t))$\n$g^{(j)}_0 = 1,  g^{(j)}_n = g^{(j)}_1 + \\frac{1 - e^{-\\Delta t(i)}}{1 + e^{-\\Delta t(i)}}$\nThe memory strength is thus updated in each turn. The Extended model introduces four parameters: cos_th, 'scale, tscale, gscale. Cos_th is the cosine similarity threshold from the original model.\nThe equations for other parameters are as follows:\n$Retain = \\{i | cos\\_sim(i) > cos\\_th\\}$\n$p^{(i)}(t) = \\frac{1 - exp(-\\tau scale*r^{(i)}e^{-tscale*\\Delta t(i)/gscale*g^{(i)}})}{1-e^{-1}}$\n$j = argmax_{Retain} (p^{(i)}(t))$\n$g^{(j)}_0 = 1,  g^{(j)}_n = g^{(j)}_1 + \\frac{1 - e^{-tscale*\\Delta t(i)}}{1 + e^{-tscale*\\Delta t(i)}}$\nOptimization was performed based on these parameters."}, {"title": "SynapticRAG", "content": "The calculation procedure and describe the parameter settings are summarized herein. The set parameters are as follows:\n$cos\\_th$, $v\\_th$, $stim\\_th$, $Tinit$, $Tscale$, $tscale$, $Bscale$, $Vrest$, $Irest$\nFirst, scaling constants are multiplied to $\\tau$, $t$ and $Bscore$. For simplicity, we use the original variable names for the multiplied values:\n$\\tau \\rightarrow Tscale*\\tau$\n$t \\rightarrow tscale*t$\n$Bscore \\rightarrow Bscale*Bscore$\nIn the stimulus propagation mechanism, stimuli are given to memories exceeding cos_th in cosine similarity with the input vector, and propagation to the next generation is allowed for memories exceeding stimth in stimulus value:\n$Retain = \\{i | cos\\_sim(i) \\geq cos\\_th\\}$\n$Stim^{(i)} \\rightarrow Next\\_gen  if Stim^{(i)} > stim\\_th   for i \\in Retain$\nFinally, LIF model calculations are performed for stimulated memories:\n$\\tau(0) = Tinit, \\tau(t + \\Delta t) = \\tau(t) + \\frac{1 - exp(-\\Delta t)}{1 + exp(-\\Delta t)}$\n$\\frac{dI}{dt} = -\\frac{1}{\\tau} I(t) + \\sum_{t_f \\in \\Gamma} S_t \\delta(t - t_f)$\n$\\frac{dV}{dt} = -\\frac{1}{\\tau} V(t) + I(t)$\nMemories with V exceeding v_th are considered fired, and their V and I are reset to Vrest and Irest:\n$Fire = \\{j | V^{(i)} > v\\_th\\}$\n$V^{(i)} \\rightarrow Vrest, I^{(i)} \\rightarrow Irest  for j \\in Fire$\nOptimization was performed based on these parameters."}, {"title": "Experimental Results", "content": "This section presents the results of experiments conducted on four distinct datasets: SMRCs (English), SMRCs (Japanese), PerLTQA (English), and PerLTQA (Chinese). The performance of the proposed SynapticRAG model was evaluated against three baseline models (RAG, Memory-Bank, MyAgent) and two extended models (MemoryBank Extended, MyAgent Extended). The hyperparameters for each model were kept consistent across all datasets."}, {"title": "Performance Comparison", "content": "The results show that SynapticRAG consistently outperformed all baseline models across all datasets and languages. In the ERC evaluation (Table 2), SynapticRAG achieved the highest accuracy of 93.12% on the PerLTQA Chinese dataset, exceeding the second-best model, RAG, by 8.17%. The performance disparity was even more significant on the SMRCS English dataset, where SynapticRAG (86.21%) outperformed RAG (71.55%) by 14.66%.\nThe ERC-MG evaluation (Table 3) reveals similar trends, with SynapticRAG maintaining superior performance. Although there were slight improvements in the performances of the baseline models under ERC-MG, these do not substantially close the gap with SynapticRAG, highlighting the robustness of the proposed model."}, {"title": "Cross-lingual Performance Analysis", "content": "The results demonstrate SynapticRAG's consistent performance across different languages. On the SMRCS dataset, SynapticRAG achieved accuracies of 86.21% and 92.32% in English and Japanese, respectively. On the PerLTQA dataset, it attained accuracies of 90.47% and 93.12% for English and Chinese, respectively. This consistency highlights the language-agnostic nature of our model and its potential for effective deployment in multilingual environments, in contrast to the baseline models, which exhibited greater variability across languages.\nNote that SynapticRAG outperformed RAG and other baseline models across all datasets and languages using hyperparameters that were tuned on a subset of the SMRCS (English) dataset. Such consistent performance across diverse datasets and languages underscores the effectiveness and broad applicability of SynapticRAG in various memory retrieval tasks."}, {"title": "Computational Efficiency", "content": "We evaluated the computational efficiency of each model by measuring the average processing time required for a single conversational task. RAG exhibited the shortest processing time at 1.6e-4 s per task, followed by MyAgent (4.2e-3 s), MyAgent(Ext) (4.5e-3 s), SynapticRAG (1.4e-2 s), MemoryBank (1.6e-2 s), and MemoryBank(Ext) (1.7e-2 s). Although SynapticRAG operates slower than RAG, it maintains competitive speeds in comparison to other memory-augmented models. This indicates a reasonable trade-off between enhanced accuracy and computational efficiency, maintaining its suitability for real-time applications. The extended versions of MyAgent and MemoryBank exhibited slightly increased processing times, which reflects the added complexity from extended hyperparameters. However, this increase is offset by their enhanced performance."}, {"title": "Impact of Evaluation Methods", "content": "The comparison between the ERC and ERC-MG evaluation methods highlights the consistency of SynapticRAG's performance advantage. The results of the SynapticRAG remained consistent owing to its design, and the performance disparity with baseline models was significant under both methods. For example, on the PerLTQA English dataset, the performance difference between SynapticRAG and the best baseline model differed marginally from 8.33% (ERC) to 7.96% (ERC-MG). This consistent performance disparity across evaluation methods emphasizes the substantial improvement of SynapticRAG over baseline models, regardless of the specific evaluation criteria used. It demonstrates that SynapticRAG's advantages in memory retrieval persist even when baseline models are given more flexibility in retrieval count."}, {"title": "Limitation", "content": "The experimental results demonstrated SynapticRAG's effectiveness across various datasets and languages, consistently outperforming baseline models. However, potential limitations should be considered for future improvements.\nSynapticRAG's complex mechanisms, while effective for long-term context management, may increase computational costs and resource requirements, especially for large-scale datasets or extended dialogue histories. As the conversation history expands, the number of recalled memories tends to rise, leading to increased computational costs. To mitigate this issue, we recommend adjusting parameter values, such as the recall threshold, based on specific requirements.\nThe optimization of the model parameters is more challenging and requires more extensive tuning compared to simpler models. The variable number of recalled memories, although allowing for more flexible and context-aware responses, can be problematic when strict control over the number of recalled items is required. Additionally, the intricate stimulus propagation and firing decision processes may reduce model interpretability compared to RAG's simpler vector similarity approach. This complexity, while beneficial for performance, may pose challenges in debugging and fine-tuning the model for specific applications.\nFuture work should focus on optimizing the trade-off between computational efficiency and context management capability, especially for long-term dialogue scenarios. Developing techniques to manage the growing number of recalled memories without sacrificing performance will be crucial for scaling SynapticRAG to larger and more diverse datasets."}, {"title": "Conclusions", "content": "In this paper, we introduced SynapticRAG, a memory retrieval model that integrates temporal representations into memory vectors. Our approach addresses the limitations of existing dialogue agents in maintaining complex, long-term contexts and extracting specific information from conversations. Extensive experiments on the multilingual datasets SMRCs and PerLTQA showed that SynapticRAG consistently outperformed baseline models, including RAG, MemoryBank, and MyAgent, across English, Japanese, and Chinese. SynapticRAG achieved up to 14.66% improvement in memory retrieval accuracy, which signifies its effectiveness in simulating human-like memory processes. Its consistent performance across different languages suggests its potential for multilingual deployment. The success of the model in retrieving relevant memories while considering both semantic similarity and temporal context marks a significant advancement in dialogue AI systems.\nThis research contributes to the development of sophisticated, context-aware AI agents capable of maintaining long-term memory and engaging in meaningful dialogues. Integrating neuroscience-inspired mechanisms into our model paves the way for bridging the gap between artificial and human-like memory systems. Although SynapticRAG displays improvements, future work should focus on optimizing computational efficiency, exploring the performance of the model in extended dialogue scenarios, and investigating its real-world applicability. In conclusion, SynapticRAG significantly enhances the contextual and temporal awareness of dialogue agents. Continued refinement of this approach is expected to lead to AI systems capable of more natural, context-rich interactions, ultimately benefiting user-centric applications across various domains."}]}