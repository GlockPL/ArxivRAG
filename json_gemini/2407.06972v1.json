{"title": "Microsoft cloud-based digitization workflow with rich metadata acquisition for cultural heritage objects", "authors": ["Krzysztof Kutt", "Jakub Gomu\u0142ka", "Luiz do Valle Miranda", "Grzegorz J. Nalepa"], "abstract": "In response to several cultural heritage initiatives at the Jagiellonian University, we have developed a new digitization workflow in collaboration with the Jagiellonian Library (JL). The solution is based on easy-to-access technological solutions-Microsoft 365 cloud with MS Excel files as metadata acquisition interfaces, Office Script for validation, and MS Sharepoint for storage that allows metadata acquisition by domain experts (philologists, historians, philosophers, librarians, archivists, curators, etc.) regardless of their experience with information systems. The ultimate goal is to create a knowledge graph that describes the analyzed holdings, linked to general knowledge bases, as well as to other cultural heritage collections, so careful attention is paid to the high accuracy of metadata and proper links to external sources. The workflow has already been evaluated in two pilots in the DiHeLib project focused on digitizing the so-called \"Berlin Collection\" and in two workshops with international guests, which allowed for its refinement and confirmation of its correctness and usability for JL. As the proposed workflow does not interfere with existing systems or domain guidelines regarding digitization and basic metadata collection in a given institution (e.g., file type, image quality, use of Dublin Core/MARC-21), but extends them in order to enable rich metadata collection, not previously possible, we believe that it could be of interest to all GLAMs (galleries, libraries, archives, and museums).", "sections": [{"title": "1 Introduction and motivation", "content": "Jagiellonian University (JU), the oldest Polish university and one of the oldest univer-sities in continuous operation in the world, holds in its collections a number of cultural heritage objects, including medieval manuscripts, social life documents representing a wide range of historical periods, memorabilia of former employees and students of the university, and a collection of authentic relics from the circle of ancient Mediter-ranean cultures. These collections have attracted greater research interest recently due to large cultural heritage initiatives at the JU, particularly the so-called flagship projects (FPs)\u00b9 aimed at interdisciplinary and international cooperation to enrich the JU's research ecosystem. Five of the 21 FPs are focused on cultural heritage research, including digitization, standardization of descriptions, integration of collections, and more detailed studies of selected items (cf. Sect. 3).\nAs a team of computer scientists and knowledge engineers, we are actively col-laborating with these cultural heritage initiatives to assist researchers-philologists, historians, philosophers, librarians, archivists, curators, etc. by developing proper tools for metadata acquisition during the digitization process, which will ultimately lead to the creation of knowledge base(s) that describe the collections under analysis. With this in mind, we decided to take advantage of knowledge graphs [10] and ground the entire solution in the Semantic Web technologies [9] and the linked data approach [8, 12]. Adopting this approach will allow for the explicit definition of the meaning of individual metadata, the preservation of a flexible data model that can be easily adapted to the needs of individual collections or research objectives, the efficient integration of data across disciplines and organizations, and will facilitate future data processing in automated systems [15].\nDuring the development of metadata acquisition tools, a number of challenges and requirements had to be addressed, among which the most important were the tight time frame for tool development, the lack of resources to develop dedicated software, the need to use tools that are as familiar and accessible as possible to domain experts, and the scalability of the solution to collections with hundreds of thousands of objects. Taking into account all of these, we decided to base the solution on Microsoft 365 cloud and use Microsoft Excel spreadsheets as an interface for metadata collection, Office Script to facilitate the use of the spreadsheets, Python scripts for initial metadata validation, and dedicated space in Microsoft Sharepoint for data storage. The whole solution is complemented by a dedicated workflow based on the developed tools."}, {"title": "2 Related work", "content": "Harnessing the power of Semantic Web technology to integrate disparate cultural heritage (knowledge) bases requires well-thought-out shared vocabularies or ontologies. These shared resources establish common terminologies and relationships, facilitating interoperability and enhancing the effectiveness of data exchange and comprehension among disparate institutions. The two basic vocabularies are MARC-21, traditionally used in cataloging systems, and Dublin Core, traditionally used in digital libraries. However, they only allow for a basic description including title, author, year and place of creation, or access rights. More detailed metadata requires additional vocabularies or ontologies. Therefore, similar projects should be evaluated to determine whether they use vocabularies that can be adapted to the needs of the institution or collection under question.\nOne such project is the OntoBelliniLetters ontology of the Belliniano Civic Museum of Catania. Drawing on the main experience in this project, Cristofaro and Spamp-inato [3] report on the main concepts and relations used to develop the ontology \"concerning the semantic organization of the corpus of Vincenzo Bellini's correspon-dence letters\" (p. 192). This ontology is inspired by CIDOC CRM, a conceptual framework and vocabulary for describing the relationships between cultural heritage objects, events, actors, and their contexts in a structured and interoperable way.\nAnother project worth mentioning is the attempt at digitization of cultural her-itage resources in the German state of Brandenburg. Preuss [21] reports on some challenges of such an undertaking, including the variety of institutions containing rel-evant collections: 80 archives, 140 libraries, and 150 museums. A significant goal of such a project is the integration with European-wide portals, including Europeana and Kalliope. Cooperation plays a crucial role in addressing these challenges, allowing the pooling of resources and expertise across these diverse institutions. Through coop-erative efforts, Brandenburg aims not only to digitize its cultural heritage, but also"}, {"title": "3 Cultural heritage collections and digitization landscape at Jagiellonian University", "content": "From the point of view of cultural heritage collections, the Jagiellonian Library (JL) should be considered a central part of the Jagiellonian University. Although it was not founded together with the University in 1364, the Library is a successor to various university libraries and collections that have existed since the 15th century. For many years, it also played the role of a national library, the so-called bibliotheca patria [1]. Now, JL holds 6,564,628 items\u00b2 in its collections (not including items stored in faculty libraries), with many cultural heritage treasures including 11th century documents, collection of incunabula or Dutch, Italian and French engravings [1].\nOne of the most notable collections in the holdings of the Jagiellonian Library is the so-called \"Berlin Collection\" (affectionately termed \"Berlinka\" in Polish). It is a collection of over 500,000 historical documents that, before the end of World War II, belonged to the Prussian State Library (now State Library of Berlin) but is currently held by the Jagiellonian Library (for a detailed history of the collection, see [16]). The Autograph Collection, a premier segment of the Berlin Collection, is an assembly of unique manuscript materials from the 15th to the 20th century. It comprises approx-imately 300,000 autographs, including letters from Martin Luther, Johann Wolfgang von Goethe, Georg Wilhelm Friedrich Hegel, Heinrich von Kleist, Jacob and Wil-helm Grimm, Alexander and Wilhelm von Humboldt, Marie Antoinette, and many other poets, scientists, royals, statesmen, and philosophers. The collection not only exhibits the activity of particular authors, but also gives insight into the intellectual exchanges and development of cultural and ideological movements in Germany and in the whole Europe. The documents within the collection were already organized: they were divided into units associated with individual persons. Unit shelfmarks, assigned by Berlin librarians, are the names of these individuals preceded by the designa-tion \"SA,\" (Sammlung Autographa) for example, \u201cSA, Keppler, Johannes\". There are about 30,000 units within the Autograph Collection; the sizes of individual units vary greatly; some are extensive and consist of hundreds of documents, while others contain only a few, sometimes even just one.\nJagiellonian University's heritage collections are also spread in many places out-side the Jagiellonian Library. For example, documents and photos of university staff"}, {"title": "4 Objectives and requirements", "content": "Our ultimate goal is to create a knowledge base that adheres to FAIR princi-ples [24], that is linked to general knowledge bases\u2014such as Wikidata [5], Geonames\u2074, and YAGO [22] as well as to other cultural heritage bases including the pan-European Europeana project [6] and bases describing the specific collections, e.g., the Kalliope catalogs of approximately 600,000 records from 950 institutions located in German-speaking countries and that will enable and facilitate a wide range of digital humanities research, including tasks done or supported by artificial intelligence tools.\nAs highlighted in the Introduction, the objective of the work reported in this paper was to develop tools for metadata acquisition which as part of further work will be used to build a knowledge graph-by domain experts and to combine them with exist-ing systems and tools (described in Sect. 3) into a unified digitization workflow for cultural heritage collections. From the very beginning, the Berlin Collection analyzed in the DiHeLib project (see Sect. 3) was chosen as the playground for the work. There-fore, our research concerns practical challenges of massive digitization (approximately 300,000 documents) of manuscripts of immense historical value for the purpose of a digital library.\nThe workflow needed to reach a balance between the two contradictory require-ments: on one hand, it had to guarantee the high quality of metadata gathered by the domain experts; on the other, it should allow for relatively quick data collection and processing to ensure that the digitization process progresses smoothly and can be completed within a reasonable time frame.\nThe work on the prototypes was done in an iterative manner, allowing the needs, requirements, and limitations to be determined on an ongoing basis. Among the most important of these were:\n1. Tight time frame for tool development - four months were allocated for this task in the DiHeLib project,\n2. Need for using tools that are as familiar as possible and/or easily accessible to domain experts i.e., typical office tools; due to the digital exclusion of some members of the research team, it was not possible to propose more complex solutions,\n3. Lack of human and financial resources in the project to develop dedicated software,"}, {"title": "5 Methods and tools", "content": "Taking into account all the goals, requirements, and limitations outlined in Sect. 4, we decided to use a generic tool such as a spreadsheet and develop a solution in the Microsoft 365 cloud, which is familiar to JU employees from their daily work. To reduce the risk of errors and make such a tool easier to use, it was decided to develop a number of Office Script and Python scripts. The whole is combined into a workflow (see Sect. 6) that uses the dedicated folder structure in Microsoft Sharepoint. More specifically, the developed solution consists of the following:\n1. The Knowledge Matrix (TKM) an MS Excel file (see Sect. 5.1),\n2. Standard Entries Catalog (SEC) a set of 4 MS Excel files (see Sect. 5.1),\n3. The Mapping system (MAP) a sheet in TKM file for mapping between specific pages and actual scans (see Sect. 5.1),\n4. Office Script that handles the buttons in TKM and performs initial validation (see Sect. 5.2),\n5. Office Script to assist in adding new SEC records,\n6. A set of Python scripts performing more detailed validation of metadata entered into the TCM and SEC (see Sect. 5.2),\n7. A set of documents including: a description of the workflow, instructions for using TKM and SEC, a file for reporting errors and comments by domain experts."}, {"title": "5.1 Designing TKM, SEC, and MAP", "content": "The Excel-based form for entering document metadata is the key DiHeLib data struc-ture. First, it was assumed that each unit (see Sect. 3) would correspond to one file, in which one of the sheets would be a metric containing the description of a unit as a whole (see Fig. 4), and the other would be used to collect metadata of individual documents represented by subsequent rows (see Fig. 5). In turn, columns of the lat-ter sheet would represent successive fields in the document description. Thus, The Knowledge Matrix emerged. It was decided that each document would be classified into one of nine categories, a decision that determines the assignment of a particular set of fields to it. The list is a slightly modified version of the scheme used for the Varnhagen Collection [18] and comprises the following categories:\n1. Portraits, images, and drawings,\n2. Outgoing correspondence,\n3. Creative works (literary and other),\n4. Personal materials,\n5. Historical materials, diplomas,\n6. Printed materials and press clippings,\n7. Incoming correspondence,"}, {"title": "5.2 Data validation scripts", "content": "Data entered through interfaces (Excel files) must be evaluated to ensure the quality of the metadata is as high as possible. Two programs that perform data validation have been developed for this purpose: 1) on the fly, as they are entered by the researcher"}, {"title": "6 Digitization workflow in practice", "content": "Data entry and validation are only the initial steps in an overall metadata acquisition process for digitization integrated with BJ's procedures. Working closely with JL, through a series of iterations, existing processes at JL were first identified, and then a new complete process was developed using Excel input interfaces, the Microsoft 365 cloud, and JL's existing infrastructure. Importantly, the process was subjected to practical evaluation through two pilots and two workshops with international guests, which allowed for its improvement, and confirmation of its correctness and usability for JL.\nDesigning, organizing, and implementing the workflow process, and consequently its implementation in practice, was a major organizational challenge due to three key factors. Firstly, it included the activities of three different groups of people, partly working in different places, with different levels of IT competences, using different IT tools on a daily basis and coming from different work and organizational cul-tures: domain experts humanities researchers, computer scientists researchers, academic teachers, doctoral students and practitioners, and library workers. Addition-ally, the last of the mentioned groups was also highly differentiated internally. They included librarians specializing in working with manuscripts, as well as a library sys-tem administrator, a person specializing in publishing objects in a digital library, a person operating a scanner and an IT specialist responsible for the local network and, to some extent, servers. Secondly, the workflow was to be fed with different resources at different times: on the one hand, original manuscripts that require special protec-tion and security procedures, and on the other hand, two types of digital documents: Excel files filled with metadata and scans of the manuscripts. Thirdly, the Jagiellonian Library did not have a ready-made tool capable of comprehensively handling such a workflow. As indicated earlier, it was decided to use the Sharepoint platform offered in the cloud version of MS Office available to all University employees, but also to a certain extent the Alma library system and folder structures opened for this purpose on a dedicated server NAS (Network Attached Storage), as well as a paper register to control the transfer of original documents.\nTo cope with these challenges, it was decided to adopt an iterative solution, allow-ing for gradual solving of problems and getting closer to a production version that is understandable and acceptable to all stakeholders. The key points were two pilots carried out in 2023, but due to the complexity of the task, it was assumed that for the first period after the implementation of the entire process would also be treated as the next stage of development and refinement of the workflow.\nIn practice, it turned out that in the first period after implementation, a bundle of three parallel paths of different lengths was de facto formed, connecting with each other at specific points (which is presented in a simplified and synthetic way in Fig. 7). Path \"A\" refers to the handling of original manuscripts, the transfer of which is controlled"}, {"title": "7 Conclusions and future work", "content": "When joining as a group of knowledge engineers and computer scientists in cultural heritage initiatives at the Jagiellonian University, we hit upon the challenge of prepar-ing tools to collect metadata in a short period of time, with very limited human and financial resources and for a group of domain experts, some of whom are digitally excluded. It was important to ensure the scalability of the solution to hundreds of thousands of manuscripts and to take care of the validation of the metadata to be able to create a functional knowledge graph-based library out of it in the future. To achieve this, we designed a solution based on Microsoft 365 cloud, using MS Excel files as data entry interfaces, Office Script scripts for data validation and a dedi-cated folder structure in MS Sharepoint for file storage, and then together with the Jagiellonian Library, we formulated a workflow that combines existing systems and procedures with the proposed tools. The workflow has already been evaluated in two pilots in the DiHeLib project focused on digitizing the so-called \"Berlin Collection\" and in two workshops with international guests, which allowed for its refinement and confirmation of its correctness and usability for JL.\nAs future work, we plan to further evaluate the proposed workflow in other cases, including the Cultural Heritage Exploration and Retrieval with Intelligent Systems at Jagiellonian University (CHExRISH) project, where we will be able to examine the usability of the proposed solution at the JU museum, a different kind of institution in the GLAM group. We also plan to develop a knowledge graph-based catalog and related scripts to import metadata stored in Excel files, which is the ultimate goal of the reported work."}]}