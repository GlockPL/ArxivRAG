{"title": "Nonverbal Immediacy Analysis in Education: A Multimodal Computational Model", "authors": ["Uro\u0161 Petkovi\u0107", "Jonas Frenkel", "Olaf Hellwich", "Rebecca Lazarides"], "abstract": "This paper introduces a novel computational approach for analyzing nonverbal social behavior in educational settings. Integrating multimodal behavioral cues, including facial expressions, gesture intensity, and spatial dynamics, the model assesses the nonverbal immediacy (NVI) of teachers from RGB classroom videos. A dataset of 400 30-second video segments from German classrooms was constructed for model training and validation. The gesture intensity regressor achieved a correlation of 0.84, the perceived distance regressor 0.55, and the NVI model 0.44 with median human ratings. The model demonstrates the potential to provide a valuable support in nonverbal behavior assessment, approximating the accuracy of individual human raters. Validated against both questionnaire data and trained observer ratings, our models show moderate to strong correlations with relevant educational outcomes, indicating their efficacy in reflecting effective teaching behaviors. This research advances the objective assessment of nonverbal communication behaviors, opening new pathways for educational research.", "sections": [{"title": "1 Introduction", "content": "The way in which instructors communicate is crucial for successful knowledge transfer. While traditionally, research has often focused on verbal communication as the primary mode of interaction in educational settings, empirical evidence highlights the critical role of instructors' nonverbal behaviors in promoting cognitive, affective, and motivational learning [27].\nThe field of computer science, particularly within the domains of Social Signal Processing [26], Affective Computing [21], Educational Technology [13], and Human-Robot Interaction (HRI) [9], has increasingly recognized the substantial influence of nonverbal communication in educational contexts. Advanced computational models and machine learning techniques offers novel avenues, that may hold distinct advantages over traditional observer or questionnaire assessments of nonverbal behaviors. Computer vision-based approaches, for instance, could provide increased objectivity and consistency by applying uniform criteria"}, {"title": "2 Related Work", "content": "This section presents a review of studies on teachers' behaviors in educational settings, categorized into two main areas: 1) individual behavior recognition identifies specific actions and movements, such as hand raises and body poses,"}, {"title": "Individual Behavior Analysis", "content": "In [1], depth cameras extract skeletons for classroom monitoring, enhancing teacher development by analyzing activities. The models use these skeletons to identify behaviors like hand raises, body poses, and speech patterns via machine learning. The dataset includes 30 participants (5 instructors, 25 students), with 1545 body instances and 60 speech/silence audio instances. Challenges include the need for high-resolution cameras for precise skeleton extraction and adapting to diverse classroom layouts.\nSimilarly, TeachLivE [2] tracks teachers' interactions with virtual 3D students using skeleton extraction, offering posture feedback. In a study with 34 trainee teachers, initial skeletal posture feedback led to improved body language later, showcasing real-time behavioral assessment's efficacy. However, Teach-LivE's need for clear views for accurate tracking and extraction limits its use in typical classrooms.\nThe study presented in [3], a video-based motion estimation model evaluates teachers' non-verbal behaviors in classrooms, including gesturing and walking. Analyzing nine lectures from a Canadian university, it utilizes motion detection, camera pan, and zoom techniques on 5415 30-second video segments. While effective for sustained activities like walking, accuracy for brief gestures is constrained by the 30-second analysis window and the limited dataset of nine teachers. Shorter time frames and a diverse dataset are necessary to enhance detection of transient movements.\nIn the research documented in [28], videos of distinguished educators are analyzed for behaviors like blackboard-writing, questioning, displaying, instructing, describing, and non-gesture behavior. Using 3-second clips, the study combines RGB video and skeleton data, exploring early and late fusion methods. It stresses the necessity of detailed dataset information to improve model generalizability, highlighting the limited effectiveness of late fusion techniques here.\nThese single-behavior approaches focus primarily on action recognition using skeletal data. While this approach significantly reduces visual information and improves robustness, it also lacks crucial contextual details needed to estimate behaviors such as gesture intensity and perceived distance. To address these gaps, our proposed models retain visual information, allowing for a more comprehensive analysis. Furthermore, unlike previous studies that rely on depth cameras, our approach does not require such specialized equipment, thereby increasing its practicality for diverse educational settings."}, {"title": "Overall Teaching Behavior Assessment", "content": "In the study [25], a novel framework is proposed for analyzing teacher perceptions in classroom settings, utilizing a combination of egocentric video recordings and mobile eye tracker data. This method employs face detection and tracking technologies to meticulously"}, {"title": "3 Dataset and Labeling", "content": "The study utilized the TALIS dataset [11], which includes 135 videos from German schools and represents the German educational system. Each 90-minute video focuses on teaching quadratic equations to 9th and 10th graders. Our study used video data from 46 teachers in the TALIS dataset.\nFrom these videos, three 30-second segments with frontal presentations were extracted, forming the training and validation sets. Only segments without excessive camera movement, where the teacher remained visible, were included. Audio was available for human raters. Segments from 9 teachers were used for validation, and those from 37 teachers for training. To prevent data leakage and memorization, no segments from the same teacher were used in both sets."}, {"title": "4 Methodology", "content": "In this section, we describe the methods used to measure NVI from teachers in video recordings. NVI estimation is approached as a regression task involving facial expressions, gesture intensity, and perceived distance. We extract facial expressions and gesture intensity from the teacher's segmentation masks. To assess perceived distance, we use estimated depth images and segmentation masks of the teacher and students. These elements are combined, as shown in Figure 3, to calculate the NI Score from RGB video inputs."}, {"title": "Perceived Distance Regressor Model", "content": "The perceived distance regressor model mirrors the architecture used in the gesture intensity regressor, based on a fine-tuned ResNet18 architecture [7]. The input for this model, consists of a three-channel input: depth image, a mask of the teacher, and a combined mask of all students in a single channel. The depth image was estimated from the RGB frame using [16]. This depth channel provides spatial context, while the masks isolate the subjects of interest, enabling accurate estimation of physical distances in the classroom setting. This format enables the model to recognize spatial relationships between the teacher and students."}, {"title": "Facial Expression Analysis", "content": "For analyzing facial expressions, we utilized the state-of-the-art HSEmotion library [24], designed for high accuracy and speed in recognizing and quantifying facial expressions. The output from HSEmotion includes confidence scores for eight emotions: anger, contempt, disgust, fear, happiness, neutral, sadness, and surprise, providing a comprehensive emotional profile for each frame. Additionally, in cases where the face is not visible in a frame, we store a distinct output to account for the absence of facial expression data."}, {"title": "Nonverbal Immediacy Model", "content": "The NVI model in our study, while straightforward in its approach, aligns with methods commonly used by educational psychologists for analyzing NVI [20]. It integrates outputs from gesture intensity and distance regressors, along with facial expression analysis, into a 10-dimensional feature vector. This vector thus combines gesture intensity, distance, and eight emotion confidence ratings.\nThe integration process weights the feature vector based on the sum of frames with visible faces. The resulting vector feeds into a multilayer perceptron model [22] with three fully connected layers, designed to predict the NVI score. This model reflects the practical approaches in educational psychology, offering a quantifiable measure of various nonverbal aspects."}, {"title": "5 Experiments", "content": "Regressor Models To train the gesture intensity regressor model, we employed the Adam optimizer with a 0.001 learning rate and resized input images to 360x360 pixels. The model was trained with mean squared error (MSE) loss. To ensure the quality of the training subset, we excluded samples with high rater disagreement, defined by a standard deviation of 1600 among ratings. This exclusion reduced the training samples from 2451 to 2121. The median of the three ratings was used as the target for training. For validation, all samples were included, regardless of rater agreement.\nSimilarly, the perceived distance regressor model was trained using the Adam optimizer with a 0.001 learning rate and 360x360 pixel input images, employing MSE loss. Due to higher rater disagreement, indicated by a standard deviation"}, {"title": "Nonverbal Immediacy Model", "content": "The NVI model was trained using the Adam optimizer with a learning rate of 0.001 and MSE loss. The model's architecture included three fully connected layers with sizes 300, 100, and 10, respectively. For training, we utilized a majority of the dataset, specifically 316 out of the 321 available samples, selecting based on data quality and consistency. For validation, all samples were included to comprehensively assess the model's performance in various scenarios.\nThis model being the first, to our knowledge, to analyze NVI using computer vision and given the lack of additional labeled datasets, the model was further validated through an assessment of ecological validity. An external validation was conducted, to examine the correlation between model-estimated NVI scores and relevant questionnaire data and observer ratings from the TALIS study [11]. To this end, 220 additional 30-second video clips were extracted from the available video data, applying the same selection criteria as for the original clips. Despite efforts to extract the same number of additional clips per video, some teachers had to be excluded, due to the limited availability of sufficient additional video material.\nWe examined the hypothesized relationships using both the entire dataset (a) and only the additionally identified clips (b). Based on existing NVI-literature [27,12], we anticipated positive correlations between the model-estimated NVI scores and student-reported interest in mathematics (H1a + b), cognitive activation (H2a + b), and perceived teacher enthusiasm (H3a + b). Additionally, we hypothesized a positive correlation between NVI scores and teachers' socio-emotional support behaviors, focusing on the domain of encouragement and warmth (H4a + b), as rated in regular intervals by trained observers during the TALIS-study. For detailed information regarding the rating process and the scales employed in the TALIS-study see [11]. To test the hypotheses, a series of Pearson correlations was computed (with false discovery rate adjustments for multiple testing). Questionnaire data and NVI scores were aggregated at the teacher level. For correlations with socio-emotional support ratings, mean aggregates were calculated at the video level."}, {"title": "6 Results", "content": "Regressor Models The gesture intensity regressor model showed a Pearson correlation of 0.84, indicating a high level of predictive accuracy. When used as a binary classifier through thresholding, it achieved an accuracy of 84.9%.\nThe perceived distance regressor model demonstrated a Pearson correlation of 0.55, indicating a moderate positive relationship between predicted values and ground truth."}, {"title": "Nonverbal Immediacy Model", "content": "The NVI model exhibited a Pearson correlation of 0.44 with the ground truth based on human raters, indicating a moderate correlation.\nAs the first to measure NVI computationally, direct comparisons are challenging. To further evaluate the model, we integrated the model-based NVI ratings those of the human raters by calculating median values. This approach allowed for the assessment of bivariate correlations between individual ratings and this new ground truth. Significant and strong positive correlations were found between the median rating and each individual rater, as well as the model: the correlations were 0.74 (p < .01) for the first rater, 0.68 (p < .01) for the second rater, 0.66 (p < .01) for the third rater, and 0.69 (p < .01) for the model.\nAdditionally, as shown in Table 1, replacing one human rater with our model does not significantly drop the ICC, and including the model alongside three human raters slightly improves the ICC. It is important to note that these ICC values differ from those calculated for the entire dataset, as they are estimated solely based on the validation subset.\nThe results of the correlation analyses in the external validation, considering the full available data set, revealed positive and significant moderate correlations between NVI scores and students' interest in mathematics (r = .33, p = .03) (H1a), students' cognitive activation (r = .32, p = .03) (H2a), perceived teacher enthusiasm (r = .31, p = 04) (H3a), and social-emotional support (r = .34, p =< .01) (H4a). Using only the additional video data clips, a positive and significant moderate correlation was found between NVI scores and students' interest in mathematics (r = .45, p < .01) (H1b) as well as students' cognitive activation (r = .32, p = .03) (H2b). No significant correlation was observed between NVI scores and perceived teacher enthusiasm (r = .23,p = .13) or social-emotional support (r = .02, p = .86) using only the additional video data clips."}, {"title": "7 Discussion and Conclusion", "content": "In this study, we demonstrated the potential of a multimodal computational approach using only RGB cameras to estimate NVI from 30-second video segments in educational settings. We developed a gesture intensity regressor, a perceived"}, {"title": "", "content": "distance regressor, and an NVI model integrating these outputs with facial expression analysis. Using our labeled data for training and validation, these models were further evaluated with available data from the TALIS study [11] to correlate our model's outputs with real-world educational outcomes.\nThe gesture intensity regressor model showed strong predictive accuracy, effectively processing gesture intensity from RGB images. However, limitations in processing the broader context of scenes remain, particularly when faced with complex or ambiguous scenarios. The perceived distance regressor model exhibited moderate performance, highlighting the complexity of measuring perceived distance compared to geometrical distance. The NVI model demonstrated a moderate correlation with median human ratings. Comparing bivariate correlations while including the models' scores alongside those of the human raters, demonstrated that the model performs comparable to two of the three observers. ICC analyses showed, that interrater reliabilities remain stable, when replacing one human rater with the model, while including the model alongside three human raters slightly improves ICC values. These results indicate, that the model can effectively be leveraged, to support human observers, while fully replacing human raters remains more challenging, due to the complexity and context specificity of nonverbal communication.\nThe external validation showed significant moderate correlations with students' interest in mathematics, cognitive activation, perceived teacher enthusiasm, and socio-emotional support. These findings indicate that the NVI model effectively captures key aspects of nonverbal communication in educational settings, supporting its potential as a tool for enhancing teacher-student interactions. The discrepancies observed between the outcomes of the two analyses, one utilizing the complete data set and the other employing only the additionally extracted video clips, may be attributed to the reduced quantity of available data in the latter case. The reduced amount of data may limit the representativeness of the analyzed clips for the overall teaching behavior. Moreover, the corresponding clips were not missing at random, with some teachers being excluded completely.\nHowever, we also recognize the challenges encountered. The sensitivity of the data limited the size of our datasets and restricted public availability, making direct comparisons with other studies challenging. Additionally, the variability in video recording conditions across different classrooms, such as camera placement and angles, posed substantial challenges, requiring our models to be adaptable and robust.\nFuture work will incorporate additional modalities like gaze tracking to enrich understanding of nonverbal communication. While our current study integrated multiple nonverbal modalities, future research will focus on developing new architectures to enhance and support these modalities. Additionally, we will investigate the comprehensive integration of the NVI model and its modalities with scores and relevant questionnaire data and observer ratings from the TALIS study [11].\nIn conclusion, our study provides a foundational framework for future research in enhancing teacher-student interactions through a deeper understanding"}, {"title": "", "content": "of NVI. It opens promising pathways for educational research and practice, offering a more comprehensive understanding of nonverbal communication between teachers and students."}]}