{"title": "DejAIvu: Identifying and Explaining AI Art on the Web in Real-Time with Saliency Maps", "authors": ["Jocelyn Dzuong"], "abstract": "The recent surge in advanced generative models, such as diffusion models and generative adversarial networks (GANs), has led to an alarming rise in AI-generated images across various domains on the web. While such technologies offer benefits such as democratizing artistic creation, they also pose challenges in misinformation, digital forgery, and authenticity verification. Additionally, the uncredited use of AI-generated images in media and marketing has sparked significant backlash from online communities. In response to this, we introduce DejAlvu, a Chrome Web extension that combines real-time AI-generated image detection with saliency-based explainability while users browse the web. Using an ONNX-optimized deep learning model, DejAIvu automatically analyzes images on websites such as Google Images, identifies AI-generated content using model inference, and overlays a saliency heatmap to highlight AI-related artifacts. Our approach integrates efficient in-browser inference, gradient-based saliency analysis, and a seamless user experience, ensuring that AI detection is both transparent and interpretable. We also evaluate DejAlvu across multiple pretrained architectures and benchmark datasets, demonstrating high accuracy and low latency, making it a practical and deployable tool for enhancing AI image accountability.", "sections": [{"title": "1 Introduction", "content": "Generative AI models such as diffusion models [Sohl-Dickstein et al., 2015] and GANs [Goodfellow et al., 2014] have reshaped the digital landscape by enabling seamless, high-quality image generation. However, their widespread accessibility raises critical concerns about attribution, authenticity, and ethical use. [Hagendorff, 2024; Zhang et al., 2020]. Such unauthorized or uncredited use of AI-generated images in media, marketing, and online platforms has led to widespread misinformation, digital forgery, and artist displacement. Moreover, there is growing public demand for increased accountability and transparency regarding the use of AI-generated images [Solaiman et al., 2024; Shaikh et al., 2023].\nAlthough there are many AI image detection methods [Guo et al., 2025; Li et al., 2024; Zhong et al., 2024], they are often hampered by real-world applicability or lack thereof. Additionally, most detection models operate as black-box classifiers, providing no explainability on why an image is considered AI-generated [Yan et al., 2024; Gaintseva et al., 2024; aio, 2025]. This lack of interpretability reduces trust in detection methods, further exacerbating concerns over misinformation and algorithmic opacity.\nWe introduce DejAlvu, a browser-based extension enabling real-time detection of AI-generated images while providing saliency-based explainability to enhance transparency and interpretability [Simonyan et al., 2014]. The extension allows for automatic analysis of images on popular image sharing sites without requiring manual uploads or additional effort. DejAIvu leverages an ONNX-optimized deep learning model, which is converted from a TensorFlow-trained convolutional neural network (CNN) to enable efficient in-browser inference [Jin et al., 2020]. By running locally within the Chrome extension, it eliminates the need for server-side computation, ensuring low-latency performance and preserving user privacy [Wang et al., 2024; Hidaka et al., 2024].\nThe model has been trained on a curated dataset of more than 270,000 human and AI-generated artworks, incorporating various styles and sources to enhance detection accuracy [Kholy, 2024b; Kholy, 2024a]. Beyond classification, DejAlvu introduces explainability by generating gradient-based saliency maps [Smilkov et al., 2017; Selvaraju et al., 2017; Bach et al., 2015; Sundararajan et al., 2017], which highlight regions of an image that contribute most to the model's classification decision. By visualizing these areas, users can better understand which image features influence AI-generated detection."}, {"title": "2 DejAIvu Overview", "content": ""}, {"title": "2.1 Architecture and Workflow", "content": "DejAIvu operates by dynamically intercepting images on webpages, passing them through an ONNX-optimized AI model for classification, and generating saliency maps to highlight AI-specific artifacts [Jarrett et al., 2025; Simonyan et al., 2014]. As demonstrated in Figure 1, the system follows the following pipeline:\n1. Image Interception: The content script identifies images (<img> elements) dynamically as a user browses the web.\n2. Preprocessing & Model Inference: The image is resized to 256 \u00d7 256 pixels, normalized, and fed into the ONNX model for classification.\n3. Saliency Heatmap Generation: If the model detects an image as AI-generated, a gradient-based saliency map is computed.\n4. Overlay Visualization: The saliency map is blended with the original image in real time, allowing users to visually interpret AI artifacts."}, {"title": "2.2 Model Training & Optimization", "content": "Datasets As seen in Table ??, the underlying AI model for DejAIvu is trained on a curated dataset of 271,993 \u0391\u0399-generated and human-created artworks sourced from [Kholy, 2024b] via combined datasets from Kaggle and other open source datasets across the web [Wang et al., 2022; Liao et al., 2022; wik, 2025]. This dataset is highly imbalanced, with a majority of samples being AI-generated images. To address this imbalance, we apply log-based bias initialization to prevent the model from disproportionately favoring the dominant class [Karpathy, 2019; Haixiang et al., 2017]. Specifically, we initialize the final classification layer using a log-ratio bias adjustment, computed as:\n$b = log(\\frac{AI-Generated Samples}{Human-Made Samples}) = log(\\frac{190, 549}{81, 457})$\nThis bias is then incorporated into the model, setting its initial predictions to align with the dataset's actual distribution.\nDataset Splits To ensure robust model generalization, the dataset is split into training, validation, and test sets following a stratified partitioning strategy. Specifically, the training set comprises 60% of the available dataset and is augmented with transformations such as horizontal flipping, slight rotations, and contrast adjustments to mitigate overfitting. The remaining 40% of the dataset is allocated to validation and test sets. To further ensure a reliable evaluation protocol, the validation and test sets are equally split from this subset, with each receiving 20% of the original dataset. This results in a final 60%-20%-20% training-validation-test distribution.\nPreprocessing Pipeline The preprocessing pipeline ensures that input images are properly prepared before being fed into the model. First, all images are resized to a fixed dimension of 256 \u00d7 256 pixels to maintain consistency across inputs. To ensure numerical stability during inference, pixel values are normalized by scaling them to the range [0,1]. Additionally, data augmentation techniques are applied to improve the model's generalization and robustness [Xu et al., 2023]. These augmentations include horizontal flipping, slight rotations, and contrast adjustments, which help prevent overfitting and enhance the model's ability to handle variations in input data [Shorten and Khoshgoftaar, 2019]. Finally, the trained model is converted to the ONNX format, allowing efficient execution directly in the browser using ONNX.js, which optimizes performance and compatibility with web-based applications."}, {"title": "3 Experimental Results & Performance", "content": "To assess the performance of DejAIvu's AI detection model, we compare it against various state-of-the-art architectures, evaluating accuracy, precision, recall, loss, and model size. With this we aim to optimize detection accuracy while ensuring real-time efficiency in the browser."}, {"title": "4 Demonstration", "content": "To illustrate the real-world applicability of DejAlvu, we demonstrate its functionality across Google Images, highlighting its ability to seamlessly activate with search results. The extension runs in the background, intercepting image requests, detecting AI-generated content, and overlaying explainability heatmaps in real time."}, {"title": "4.1 User Interaction Flow", "content": "The user experience with DejAlvu is designed to be intuitive and requires minimal setup. Upon installation, the extension becomes active in the background. When the user navigates to an image-heavy website, DejAIvu automatically detects all displayed images, analyzes them in real time, and overlays a Vanilla Gradient heat map on each image inferred as AI generated. Figure 2 and Figure 3 demonstrate the usage and overlay of Vanilla Gradients upon toggling the extension on a Google Images result when the user looks up cats."}, {"title": "5 Conclusion and Future Work", "content": "DejAIvu introduces a novel approach to AI-generated image detection by providing a fully browser-integrated solution with real-time inference and saliency-based explainability. Unlike existing detection methods that rely on manual uploads or cloud-based inference, DejAIvu operates locally using ONNX.js, ensuring low-latency performance and enhanced user privacy. Through its integration with online platforms such as Google Images, it enables users to transparently identify AI-generated content without disrupting their browsing experience. Our results show high classification accuracy while maintaining computational efficiency. Future work will focus on optimizing inference speed, quantifying latency across image sets, conducting large-scale user testing, and expanding dataset coverage to improve generalization across diverse art styles. Additional features such as adjustable detection thresholds, heat map customization, and per-site detection preferences are also planned to enhance user experience and flexibility."}]}