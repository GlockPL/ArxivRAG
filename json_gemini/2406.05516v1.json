{"title": "Verbalized Probabilistic Graphical Modeling with Large Language Models", "authors": ["Hengguan Huang", "Xing Shen", "Songtao Wang", "Dianbo Liu", "Hao Wang"], "abstract": "Faced with complex problems, the human brain demonstrates a remarkable capacity to transcend sensory input and form latent understandings of perceived world patterns. However, this cognitive capacity is not explicitly considered or encoded in current large language models (LLMs). As a result, LLMs often struggle to capture latent structures and model uncertainty in complex compositional reasoning tasks. This work introduces a novel Bayesian prompting approach that facilitates training-free Bayesian inference with LLMs by using a verbalized Probabilistic Graphical Model (PGM). While traditional Bayesian approaches typically depend on extensive data and predetermined mathematical structures for learning latent factors and dependencies, our approach efficiently reasons latent variables and their probabilistic dependencies by prompting LLMs to adhere to Bayesian principles. We evaluated our model on several compositional reasoning tasks, both close-ended and open-ended. Our results indicate that the model effectively enhances confidence elicitation and text generation quality, demonstrating its potential to improve AI language understanding systems, especially in modeling uncertainty.", "sections": [{"title": "1 Introduction", "content": "In addressing complex reasoning problems, such as finding answers to challenging science questions, the human brain is thought to have the capability to surpass mere sensory input, potentially forming insights into latent patterns of the world. This cognitive capability suggests that humans might possess a sophisticated ability to interpret underlying structures and uncertainties Tenenbaum et al. [2011], although this remains a subject of ongoing research and debate. As of now, such depth of understanding demonstrated by humans has not been fully achieved in artificial intelligence (AI) systems Lake et al. [2017], Bender and Koller [2020], Zheng et al. [2021], Sumers et al. [2023].\nWhile large language models (LLMs) have demonstrated unparalleled abilities in processing and generating human language Devlin et al. [2018], Brown et al. [2020], Achiam et al. [2023], their performance is often constrained by the scope of their training data. These models, built primarily on vast corpora of text, excel at identifying patterns and generating responses that are syntactically coherent and contextually relevant within the confines of their training. However, when faced with tasks that require an understanding of implicit knowledge, or the ability to integrate and reason with undisclosed information from multiple sources-skills that humans typically employ in complex reasoning-LLMs often struggle. This limitation stems from their reliance on explicit data patterns and their inability to navigate uncertainties or infer underlying structures not overtly represented in their training datasets.\nTo address these limitations, our research investigates the integration of uncertainty modeling and latent structure learning into LLMs. We introduce a novel Bayesian prompting approach, utilizing a verbalized Probabilistic Graphical Model (vPGM), which enables LLMs to perform Bayesian"}, {"title": "2 Related Work", "content": "Prompting methods in Large Language Models (LLMs) represent a significant research domain, where the focus is on tailoring model responses for specific tasks. In this landscape, two prominent strategies have emerged: in-context learning Brown et al. [2020], where models are provided with relevant task-specific examples, and instruction prompting Wang et al. [2022b], Ouyang et al. [2022], which embed explicit task instructions within prompts.\nA key development in this field is the Chain-of-Thought (CoT) prompting Wei et al. [2022]. This paradigm enhances complex reasoning in LLMs by incorporating a series of rationale steps within the"}, {"title": "3 Background: Probabilistic Graphical Models in Bayesian Inference", "content": "Probabilistic Graphical Models (PGMs) serve as foundational tools for representing intricate probabilistic relationships across various complex reasoning tasks. These models efficiently encode uncertainties and conditional dependencies among variables, facilitating advanced inference and learning in a multitude of domains, including medicine, genetics, economics, and social sciences; notably, their application in diagnostic systems, genetic association studies, and economic prediction models highlights their pivotal role in driving forward empirical and theoretical research Koller and Friedman [2009], Murphy [2012].\nPGMs are classified into two primary types: undirected graphical models, which depict relationships through non-directional edges, and directed graphical models, or Bayesian Networks (BNs), which this work focuses on, utilize directional edges to express functional dependencies among variables.\nIn the domain of PGMs, particularly BNs, a central element is the directed acyclic graph (DAG). Each node in a DAG corresponds to a random variable, and the directed edges between these nodes represent probabilistic dependencies. This structure is crucial for defining the relationships among variables and is foundational for the network's capacity to model complex systems. Formally, a Bayesian network for a set of n latent variables $Z = {Z_1, Z_2, ..., Z_n}$ is structured through a set of directed edges E. Each edge in the network conveys directional influence from one variable to another."}, {"title": "4 Our Method: Verbalized Probabilistic Graphical Modeling (vPGM)", "content": "Verbalized Probabilistic Graphical Modeling (vPGM) is a novel Bayesian prompting approach that enhances Large Language Models' (LLMs) reasoning capabilities by enabling them to perform Bayesian inference in a training-free manner. This method facilitates the LLMs to reason latent variables and their probabilistic dependencies by guiding them to follow the principles of Probabilistic Graphical Models (PGM). vPGM's strength lies in its ability to bypass the traditional requirements of data-intensive learning and predefined latent factors and dependencies, thereby offering a more efficient approach to Bayesian reasoning."}, {"title": "4.1 Overview of vPGM", "content": "The vPGM framework leverages large language models (LLMs) to perform complex reasoning tasks, structured around three main steps, as illustrated in Figure 2 and Figure 1: (1) Graphical Structure Discovery or \u201cLearning\u201d: vPGM prompts the LLM to generate textual descriptions that define the probabilistic graphical model (PGM), including the identification of latent variables and their dependencies. The probabilistic interpretations of these elements are treated as \"parameters\" of the model. (2) Prompting-based Inference: This involves constructing prompts to reason about each latent variable's posterior distribution in vPGM based on testing input data. (3) Predictions under Uncertainty: The final step involves calculating the expectation of final predictions or answers over latent variables in vPGM."}, {"title": "4.2 \"Learning\u201d or Discovery of Probabilistic Graphical Structures", "content": "To infer the structure of a PGM, our approach begins by constructing a specialized prompt (illustrated in Table 1) aimed at uncovering a set of latent variables for tackling compositional reasoning tasks. This prompt encompasses several key elements:\n\u2022 General Task Description: Articulating the specific reasoning task under consideration.\n\u2022 Input-Output Data Pairs: Offering representative data examples pertinent to the task.\n\u2022 Contextual Information: Incorporating relevant external context to enrich the understanding of the task.\n\u2022 Prior Knowledge and Constraints: Integrating any prior knowledge or constraints about the latent variables, such as the maximum number of latent variables.\nAssuming $Z = {Z_1, Z_2, ..., Z_n}$ as the discovered set of latent variables, as exemplified in Table 2, we employ further prompting of LLMs to identify the dependencies for each latent variable. An illustrative example of this can be seen in Table 3, using the prompt \"Please identify the dependency of the above latent variables.\u201d Similar to traditional PGMs, the structure of our verbalized PGM (VPGM) is captured through a series of conditional probability distributions (CPDs), such as $P(Z_i|Pa(Z_i))$. However, unlike conventional PGMs that apply specific distribution forms for each CPD, vPGM"}, {"title": "4.3 Inference as Prompt Generation", "content": "In the context of Large Language Models (LLMs), the concepts of inference acquire a distinctive interpretation compared to their traditional roles in the Bayesian inference framework. Traditionally, Bayesian inference is concerned with estimating the distributions of model parameters given observed data. However, within LLMs, inference are re-conceptualized as the generation of prompts that enable the drawing of samples from the vPGM. This approach leverages the generative abilities of LLMs such as GPT-4 to create prompts that initiate a series of reasoning steps, simulating the Bayesian inference process. An example of this might be, \"Generate a sequence that guides GPT-3.5 through step-by-step probabilistic reasoning based on the provided task description and testing data.\""}, {"title": "4.4 Quantifying Prediction Uncertainty in Complex Reasoning", "content": "In complex reasoning tasks, where decisions are made under conditions of uncertainty, quantifying the confidence in predictions becomes critical. The vPGM framework extends this capability, enabling the quantification of predictive uncertainty through posterior distributions. This process mirrors the principles of uncertainty estimation found in traditional probabilistic models but is adapted for integration with LLMs.\nConsider the predicted responses conditioned on latent variables, denoted as $P(Y|Z)$. Assuming $P(Z|X)$ is specified by vPGM, we evaluate the uncertainty associated with these predictions using the posterior probability distributions as a measure of confidence. If the distribution $P(Y|Z)$ is known, we can estimate this posterior probability by calculating the expected value of $P(Y|Z)$ across the posterior distribution of latent variables:\n$E_{p(z|x)} [P(Y|Z)] \\approx \\Sigma_Z P(Y|Z)P(Z|X)$,\nwhere X represents the observational inputs; the samples of Z are drawn from vPGM. In scenarios where $P(Y|Z)$ is not directly accessible, vPGM enables the construction of a verbalized distribution for $P(Y|Z)$. These posterior probabilities can then be approximated by averaging numerical probability values obtained from multiple candidate responses generated by vPGM."}, {"title": "5 Experiments", "content": "We evaluate the efficacy of vPGM in capturing structural patterns and modeling uncertainty across two compositional reasoning tasks. The first, a closed-ended task named ScienceQA Lu et al. [2022], and the second, an open-ended task named ChatCoach Huang et al. [2024], both require reasoning with undisclosed information from multiple sources. See Appendix for the more detailed experimental configurations."}, {"title": "5.1 Science Question Answering", "content": "The Science Question Answering (ScienceQA) benchmark, introduced by Lu et al. [2022], serves as a comprehensive benchmark for multi-modal question answering across a diverse range of scientific disciplines, including physics, mathematics, biology, and the humanities. It features 4,241 question-answer pairs that cover various topics and contexts. This task demands the integration of information from multiple sources, a process that can introduce errors and increase the complexity of reasoning. Given these challenges, ScienceQA serves as an ideal testbed for evaluating how effectively vPGM identifies latent structures and manages inherent uncertainties. We follow the experiment settings from Lu et al. [2023].\nBaseline Methods We compare vPGM with the following baseline methods:"}, {"title": "6 Conclusion", "content": "We introduce a novel Bayesian prompting method that incorporates a verbalized Probabilistic Graphical Model (PGM) into LLMs, enabling them to perform training-free Bayesian inference. This approach sidesteps the traditional need for extensive datasets and predefined latent structuring required by Bayesian models. Our empirical results on compositional reasoning tasks demonstrate substantial improvements in terms of both confidence elicitation and text generation quality. These results highlight the potential of merging Bayesian principles with LLMs to enhance AI systems' capacity for modeling uncertainty and reasoning under uncertainty. However, the effectiveness of vPGM is linked to the quality of the prompts used for PGM discovery. Achieving optimal performance thus requires precise prompt engineering. Future work could explore methods to automate prompt optimization, further enhancing the applicability of this approach across varied scenarios."}, {"title": "A Impact Statement", "content": "This work's integration of Bayesian principles with Probabilistic Graphical Models (PGMs) into Large Language Models (LLMs) primarily enhances the reliability of AI in processing complex reasoning tasks. While the societal impacts may unfold gradually, the potential for these advancements to improve decision-making accuracy and reduce over-confidence issues in LLMs is significant. By fostering more reliable AI language models, this research aims to set a foundation for safer AI deployments, thereby contributing to the progress of AI technologies that societies and industries can confidently utilize."}, {"title": "B More Detailed Experiment Setup", "content": "We use GPT-4 for PGM discovery and constructing inference prompts for vPGM, while GPT-3.5-turbo-0613 is used for all our prompting-based methods during testing. Due to ChatGPT's safety mechanisms, responses to potentially inappropriate content are restricted and thus excluded from our evaluation of all prompting-based methods. Unless otherwise specified, we set the temperature to 0.2. Additionally, we generate three candidate responses for estimating vPGM's confidence."}, {"title": "B.1 Science Question Answering", "content": "In this section, we provide a detailed example of inference using the vPGM, as shown in Table 9. Additionally, Table 10 illustrates the inference prompt for vPGM with 4 latent variables, while Table 11 demonstrates the prompt for a vPGM with 2 latent variables."}, {"title": "B.2 Communicative Medical Coaching", "content": null}, {"title": "B.2.1 Prompts of Our Baseline Approaches", "content": "In this section, we present the prompts used for each baseline approach: Instruction Prompting (see Table 12), Vanilla CoT (see Table 13), Zero-shot CoT (see Table 14), and GCoT (see Table 15)."}, {"title": "B.2.2 Prompt of vPGM Inference", "content": "Table 16 shows the prompt of vPGM inference for ChatCoach"}]}