[{"title": "CaDA: Cross-Problem Routing Solver with Constraint-Aware Dual-Attention", "authors": ["Han Li", "Fei Liu", "Zhi Zheng", "Yu Zhang", "Zhenkun Wang"], "abstract": "Vehicle Routing Problems (VRPs) are significant Combinatorial Optimization (CO) problems holding substantial practical importance. Recently, Neural Combinatorial Optimization (NCO), which involves training deep learning models on extensive data to learn vehicle routing heuristics, has emerged as a promising approach due to its efficiency and the reduced need for manual algorithm design. However, applying NCO across diverse real-world scenarios with various constraints necessitates cross-problem capabilities. Current multi-task methods for VRPS typically employ a constraint-unaware model, limiting their cross-problem performance. Furthermore, they rely solely on global connectivity, which fails to focus on key nodes and leads to inefficient representation learning. This paper introduces a Constraint-Aware Dual-Attention Model (CaDA), designed to address these limitations. CaDA incorporates a constraint prompt that efficiently represents different problem variants. Additionally, it features a dual-attention mechanism with a global branch for capturing broader graph-wide information and a sparse branch that selectively focuses on the most relevant nodes. We comprehensively evaluate our model on 16 different VRPS and compare its performance against existing cross-problem VRP solvers. CaDA achieves state-of-the-art results across all the VRPs. Our ablation study further confirms that each component of CaDA contributes positively to its cross-problem learning performance.", "sections": [{"title": "I. INTRODUCTION", "content": "Vehicle Routing Problems (VRPs) involve optimizing transportation costs for a fleet of vehicles to meet all customers' demands while adhering to various constraints. Numerous studies have focused on VRPs due to their extensive real-world applications in transportation, logistics, and manufacturing [1], [2]. Traditional methods for solving VRPs include exact solvers and heuristic methods. Exact solvers, however, struggle with the NP-hard nature of the problem, making them prohibitively expensive to implement. On the other hand, heuristic methods are more cost-effective and provide near-optimal solutions but require significant expert input in their design. Recently, learning-based neural solvers have gained considerable attention and have been successfully applied to VRPs [3]\u2013[5]. These solvers train networks to learn a heuristic, reducing the need for extensive manual algorithm design and minimizing computational overhead.\nDespite the promising performance of neural solvers on VRPs, the majority of existing works require training a distinct model for each type of routing problem [6]\u2013[13]. Given that over 60 VRP variants have been studied, each featuring different constraints [14], developing distinct models for each routing problem is costly and significantly hinders practical application.\nTo tackle this challenge, recent efforts have been made to develop cross-problem learning methods that can solve multiple VRPs with a single model [15]\u2013[18]. These cross-problem methods typically employ an encoder-decoder framework and are trained using reinforcement learning. For example, MTPOMO [15] jointly trains a unified model across five VRPs, each with one or two constraints, enabling zero-shot generalization to problems that feature combinations of these constraints. MVMoE [16] employs a Mixture-of-Experts (MoE) [19] structure in the feed-forward layer of a transformer-based model to enhance its cross-problem learning capacity. Furthermore, RouteFinder [17] directly trains and tests sixteen VRPs using a proposed unified Reinforcement Learning (RL) environment, which enables the simultaneous handling of different VRPs in the same training batch. Additionally, RouteFinder leverages a modern transformer-based model structure [20], along with global embeddings, to enhance performance.\nDespite these advancements, existing cross-problem models remain unaware of constraints [15]\u2013[17]. As different constraints significantly alter the feasible solution space, this oversight notably limits the models' capabilities in cross-problem applications. Furthermore, existing methods employ a transformer encoder which maintains global connectivity throughout the node encoding process, leading to the inclusion of irrelevant nodes and adversely affecting node representation. Conversely, using learnable sparse connections [21], [22] allows the node encoding process to selectively focus on more relevant nodes.\nThis study proposes a novel Constraint-Aware Dual-Attention Model (CaDA) to mitigate these challenges. Firstly, we introduce a constraint prompt to enhance the model's awareness of the activated constraints. Furthermore, we propose a dual-attention mechanism consisting of a global branch and a sparse branch. Since, in the encoder-decoder framework, node pairs with higher attention scores are more likely to be adjacent in the solution, the sparse branch with Top-k sparse attention focuses on the more promising connections between these key node pairs. Meanwhile, the global branch enhances the model's capacity by capturing information from the entire graph, ensuring that the solution is informed globally. The effectiveness and superiority of CaDA have been comprehensively demonstrated across 16 VRPs and real-world benchmarks.\nThe contributions of this paper can be summarized as follows:\n\u2022 We introduce CaDA, an efficient cross-problem learning method for VRPs that enhances model awareness of constraints and representation learning.\n\u2022 We propose a constraint prompt, which facilitates high-quality constraint-aware learning, and a dual-attention mechanism, which ensures that the encoding process is both selectively focused and globally informed.\n\u2022 We conduct a comprehensive evaluation of CaDA across 16 VRP variants. CaDA achieves state-of-the-art performance, surpassing existing cross-problem learning methods. Additionally, our ablation study validates the effectiveness of both the constraint prompt and the dual-attention mechanism."}, {"title": "II. RELATED WORK", "content": "A. Neural Combinatorial Optimization\nNCO approaches utilize deep reinforcement learning to train a policy that constructs solutions in an autoregressive manner. Nazari et al. [23] are the first to apply Pointer Networks [24] to solve the VRP. Subsequently, the pioneering work Attention Model (AM) [4] employs a powerful Transformer-based architecture. This model is optimized using the REINFORCE algorithm [25] with a greedy rollout baseline. Building on this, Kwon et al. [6] introduce the Policy Optimization with Multiple Optima (POMO) method, which leverages solution symmetries and has demonstrated significantly improved performance. Subsequently, numerous studies have further refined both AM and POMO, enhancing Transformer-based methods [26]\u2013[29]. Given the diverse constraints and attributes in real-world transportation needs, some research focuses on various VRP variants, including heterogeneous Capacitated VRP (HCVRP) [30], VRP with Time Windows (VRPTW) [9]\u2013[12], and Open Route VRP (OVRP) [13]. More information can be found in recent reviews [31], [32].\nB. Cross-Problem Learning for VRPs\nNeural methods for solving VRPs typically train and evaluate deep models on the same instance distributions. Some studies have explored generalization across multiple distributions [33]\u2013[38]. Additionally, Zhou et al. [39] consider both problem size and distribution variations. Recent developments have begun to address cross-problem generalization [15], [16], [18], [40]. Wang and Yu [40] use multi-armed bandits to achieve task scheduling. Lin et al. [18] demonstrate how a model pre-trained on the Travelling Salesman Problem (TSP) could be effectively adapted to targeted VRPs through efficient fine-tuning, e.g., inside tuning, side tuning, and Low-Rank Adaptation (LoRA). However, these approaches still focus on relatively few tasks (less than five).\nTo tackle multiple VRP variants in a unified model, MTPOMO [15] conceptualizes VRP variants as combinations of underlying constraints, enabling the model to achieve zero-shot generalizability to more tasks. MVMoE proposes a new model architecture using the MoE [19] approach to improve performance. Furthermore, RouteFinder [17] proposes to use a modern transformer encoder structure incorporating SwiGLU [41], Root Mean Square Normalization (RMSNorm) [42], and Pre-Norm [43], [44], which considerably improves the model's capability. However, these approaches remain unaware of constraints and maintain only global connectivity throughout the encoding process, which limits their cross-problem capabilities.\nC. Multi-Branch Architecture\nMulti-branch architectures have been widely used and have achieved success in computer vision. Some research employs multiple branches to capture both low and high-resolution image information, ultimately producing a comprehensive and powerful semantic representation that can be used for downstream tasks such as image segmentation [45]\u2013[47] or human pose estimation [48], [49]. Other studies assign different branches to focus on distinct aspects by utilizing attention mechanisms [50]\u2013[53]. For instance, DANet [50] proposes a dual attention network for scene segmentation, with one branch responsible for capturing pixel-to-pixel dependencies and another for capturing channel dependencies across different feature maps, thereby capturing global context [54]. Similarly, Crossformer++ [53] groupes image patches in both local and global ways, incorporating short-distance and long-distance attention to achieve better representation, retaining both small-scale and large-scale features in the embeddings. In this study, we propose a novel dual-attention mechanism featuring a global branch for capturing information from the entire graph and a sparse branch to focus more on important connections.\nD. Sparse Attention\nRecent studies have proposed using sparse attention to reduce computational complexity and minimize the harmful influence of unnecessary and irrelevant items, thereby improving performance [21], [55]\u2013[58]. To achieve this, many researchers utilize pre-defined sparse attention patterns based on prior knowledge, such as local or strided attention, or combinations of multiple patterns [59]\u2013[62]. For instance, LogSparse [60] ensured that each token only attends to itself and its preceding tokens, using an exponential step size. However, these methods can be overly harsh and require well-informed prior knowledge. Another category of methods achieves sparse attention by adding an additive operation that eliminates small attention scores to exactly zero, such as the Top-k operation [21], [55]\u2013[57] and the ReLU\u00b2 operation [22], or employs a sparsity-inducing alternative to Softmax, such as sparsemax [63] and a-entmax [64]\u2013[66]. In this study, we use the simple yet efficient Top-k selection operation to achieve sparse attention and enhance the representation learning from the most relevant nodes."}, {"title": "III. PRELIMINARIES", "content": "A. Problem Definition\nIn this study, we focus on 16 VRP variants that encompass five different constraints, including Capacity (C), Open Route (O), Backhaul (B), Duration Limit (L), and Time Window (TW). These are summarized in Table I, with illustrations related to these constraints presented in Figure 1. In this section, we begin by outlining a general definition of the VRP instance, then continue with the basic CVRP, and proceed to describe its four additional constraints.\nA VRP instance G is a fully-connected graph defined by a set of nodes $V = {v_0, v_1,...,v_N}$ with the total number of nodes given by $|V| = N + 1$, and edges $E = V \\times V$. Furthermore, $v_0$ represents the depot, while ${v_1,...,v_N}$ represent the N customer nodes. Each node $v_i \\in V$ consists of the pair ${X_i, A_i}$, where $X_i \\sim U(0,1)^2$ represents the node coordinates, and $A_i$ denotes other attributes of the nodes. Additionally, the travel cost between different nodes is defined by their Euclidean distance, which is denoted by the cost matrix $D = {d_{i,j}, i = 0, . . . , N, j = 0..., N}$.\nIn CVRP, the depot node $v_0$ has $A_0 = \\emptyset$, and each customer node $v_i$ is associated with $A_i = {\\delta_i}$, where $\\delta_i$ is the customer's demand $v_i$ that the fleet of vehicles must service. This fleet comprises homogeneous vehicles, each with a specific capacity C. Each vehicle leaves the depot $v_0$, visits a subset of customers, and returns to the depot upon completion of deliveries. The solution to CVRP, denoted by $\\Tau$, consists of the routes taken by all vehicles, that is, $\\Tau = {\\tau_1, \\tau_2, . . .,\\tau_K}$, where K is the total number of sub-routes. Each sub-route $\\tau_k = (\\tau_1^k,\\tau_2^k,...,\\tau_{n_k}^k)$, $k \\in 1,2,...,K$, where $\\tau_i^k$ is the index of the visited node at step i, and $\\tau_1^k = \\tau_{n_k}^k = 0$. $n_k = |\\tau_k|$ represents the number of nodes in it, and $\\sum_{k=1}^K n_k = T$ represents the total length of the solution.\nThe basic CVRP could be easily extended to accommodate various VRPs by incorporating additional constraints. In this paper, we explore four additional constraints as discussed in recent studies [15]-[17].\na) Open Route (O): In the OVRP, vehicles do not return to the depot $v_0$ after completing their sub-route.\nb) Time Window (TW): The Time Window constraint requires that each node must be visited within a specific time window, such that each node $A_i = {\\delta_i, e_i, l_i, s_i}$, where $e_i$ is the earliest start time, $l_i$ is the latest permissible time, and $s_i$ represents the time taken to service this customer. The depot $v_0$ has $s_0 = 0, e_0 = 0$, and $l_0 = T$, indicating that each sub-tour must be completed within a time limit of T. Time window constraints are stringent; if a vehicle arrives earlier than $e_i$, it must wait until the start of the window.\nc) Backhaul (B): Customers with $\\delta_i > 0$ are termed linehaul customers, as they require vehicles to load goods at the depot and deliver to their locations. Conversely, customers with $\\delta_i < 0$ are defined as backhaul customers, where vehicles must collect $|\\delta_i|$ from their locations and transport it back to the depot. While all customers in the standard CVRP are linehaul, the Vehicle Routing Problem With Backhauls(VRPB) includes both linehaul and backhaul customers. Furthermore, all linehaul tasks must be completed before any backhaul tasks can commence on the route to avoid rearranging the loads on the vehicle.\nd) Duration Limit (L): In this constraint, the depot $v_0$ has $A_0 = {\\rho}$, where $\\rho$ represents the length limit that each sub-tour must adhere to, ensuring a return to $v_0$ within this threshold."}, {"title": "B. Learning to Construct Solutions for VRPs", "content": "The process of constructing solutions autoregressively (i.e., during decoding) can be modeled as a Markov Decision Process (MDP), and the policy can be trained using RL methods. As the model sequentially expands each sub-route, for simplicity, at any decoding step t, $\\tau_t$ represents the sequence of nodes visited up to that point:\n$\\Tau_t = \\cup_{k=1}^K {\\tau_1^k,...,\\tau_{n_k}^k} = (\\tau_1, \\tau_2, ..., \\tau_t)$, (1)\nwhere $\\cup$ denotes the concatenation of sequences from different sub-routes The MDP for the decoding step t can be defined as follows:\na) State: $s_t \\in S$ is the ordered tuple $(\\Tau_{t-1},V)$ given by the current partial solution $\\Tau_{t-1} = (\\tau_1, \\tau_2, ..., \\tau_{t-1})$ and the instance V. Initially, $\\tau_0 = 0$, and at the end, $s_t$ contains a feasible solution $\\Tau_T$.\nb) Action: $a_t \\in A$ is the selected index in the current step, which will be added at the end of the partial solution. If $a_t = 0$, i.e., the vehicle returns to the depot node, it signifies the end of the current sub-tour and the start of a new one.\nc) Policy: A neural model $\\pi_\\theta$ with learnable parameters $\\theta$ is used as a policy to generate solutions sequentially, where the probability of generating the final feasible solution is:\n$\\pi_\\theta(\\tau|V) = \\prod_{t=1}^T \\pi_\\theta(a_t|s_t) = \\prod_{t=1}^T \\pi_\\theta (\\tau_t | \\Tau_{t-1}, V)$. (2)\nd) Reward: $r \\in R$ can only be obtained when a whole feasible solution $\\Tau_T$ is generated and is defined as the negative solution length:\nr(\\Tau_T) = -\\sum_{t=1}^{T-1} d_{\\tau_t\\tau_{t+1}}$. (3)\nSubsequently, $\\pi_\\theta$ can be optimized using RL methods to maximize the expected reward J. This study employs the REINFORCE algorithm [25] with a shared baseline proposed by Kwon et al. [6], to update the policy. Specifically, for a VRP instance V, N trajectories are generated, starting with the first action ${a_1^1, a_1^2, . . ., a_1^N}$, which is always 0. Each of the N trajectories then assigns a unique one of the N customer nodes as the second point, i.e., ${a_1, a_2, ..., a_N} = {1,2,..., N}$. The policy subsequently samples actions for each trajectory until all have derived feasible solutions ${\\tau^1,\\tau^2,...,\\tau^N}$. Finally, the gradient of the policy is approximated by:\n$\\nabla J(\\theta_V) \\approx \\frac{1}{N}\\sum_{i=1}^N (\\sum_{j=1}^{r(V)} r(\\tau^i) - b^2(V)) \\nabla log \\pi_{\\theta}(\\tau^i | V)$,\nb(V) = $\\frac{1}{N} \\sum_{i=1}^N r(\\tau^i)$ for all i. (4)\nWhere b(V) is the shared baseline function used to stabilize learning.\nFor the structure of policy $\\pi_\\theta$, existing approaches primarily use transformer-based models."}, {"title": "C. Transformer Layer", "content": "The Transformer [67] comprises a Multi-Head Attention Layer (MHA) and a Feed-Forward Layer (FFD). In some modern large language models [68]\u2013[70], the FFD is replaced by Gated Linear Units (GLUs).\na) Attention Layer: The classical attention function can be expressed as:\nAttention (X, Y) = A (Y W_v),\nwhere A = Softmax ($\\frac{XW_qY^TW_k}{\\sqrt{d_k}}$), (5)\nwhere $X \\in R^{n\\times d}$ and $Y \\in R^{m\\times d}$ represent the input embeddings. The parameters $W_q, W_k \\in R^{d\\times d_k}$, and $W_v \\in R^{d\\times d_v}$ are trainable matrices for the query, key, and value projections, respectively. After calculating the attention matrix using the query and key matrices, the Softmax function is applied independently across each row to normalize the attention scores. These scores are then rescaled by $\\sqrt{d_k}$, resulting in the scaled attention score matrix A. The eventual output, denoted as Z, is a matrix in $R^{n\\times d_v}$.\nAdditionally, for efficiency, the MHA projects X into $M_h$ separate sets of queries, keys, and values, upon which the attention function is applied:\nMHA(X, Y) = Concat($Z_1,..., Z_{M_h}$)W_p,\nwhere $Z_i = Attention_i(X, Y), \\forall i \\in {1, ..., M_h}$, (6)\nwhere $d_k = \\frac{d}{M_h}$ = dv in each Attention. The parameter $W_p \\in R^{d\\times d}$ denotes a trainable matrix combining different attention heads' outputs. For self-attention, we have Y = X.\nb) Gated Linear Unit: The transformer blocks also include an FFD that processes the input X through two learned linear projections, with a ReLU activation function applied between them. In many recent modern transformer-based large language models [68]\u2013[70], this configuration has been replaced by GLUs [41]. GLUs consist of a component-wise product of two linear projections, where one projection is first passed through a nonlinear function. We employ SwishGLU [41], which utilizes the Sigmoid Linear Unit (SiLU) [71] as the nonlinear function, as recommended in the RouteFinder [17]. The SwiGLU is defined as:\nSwiGLU(X) = X \\odot \\sigma(XW_1 + b_1) \\otimes SiLU(XW_2 + b_2)$. (7)"}, {"title": "IV. METHODOLOGY", "content": "A. Overall Pipeline\nAs shown in Figure 2, CaDA follows the general cross-problem learning framework for VRPs which consists of two stages: encoding instance V to node embeddings $H^{(L)}$, and decoding to construct solutions based on $H^{(L)}$ sequentially. CaDA employs a prompt to introduce constraint information during the encoding process and further utilizes a dual-attention mechanism to enhance representation learning.\nB. Constraint Prompt\nTo generate prompts that carry the problem's constraint information, we represent the problem as a multi-hot vector $V \\in R^5$, corresponding to five distinct constraints. This multi-hot vector is subsequently processed through a straightforward Multi-Layer Perceptron (MLP) to generate the prompts:\nP^{(0)} = LayerNorm(VW_a + b_a)W_b + b_b, (8)\nwhere $W_a\\in R^{5\\times d_h}$, $b_a \\in R^{d_h}$, $W_b \\in R^{d_h\\times d_h}$, and $b_b \\in R^{d_h}$ are learnable parameters. $d_h$ is the node's embedding dimension. Then this prompt can be concatenated with the node embeddings.\nC. Dual-Attention Mechanism\nThe input instance V with $|V| = N + 1$, is first transformed into high-dimensional initial node embeddings a linear projection. The initial node embedding is denoted as $H^{(0)} \\in R^{(N+1)\\times d_h}$.\nSubsequently, $H^{(0)}$ is concatenated with $P^{(0)}$ and processed through a global branch $f_g$, which consist of L layers. Each consists of a standard MHA layer [67] and a SwiGLU [72]. The standard attention function with Softmax never allocates exactly zero weight to any node, thereby allowing each node access to the entire graph. Concurrently, to capture information from closely related nodes, a sparse branch denoted as $f_s$ with Top-k sparse attention layers is introduced. Both branches adaptively fuse information at the end of each layer.\nFinally, the output from the global branch, $H^{(L)}$, is used for autoregressive decoding, with the likelihood of node selection being primarily determined by the similarity of the nodes' embeddings.\na) Global Layer: Each layer involves a MHA [67] and a SwiGLU [72], along with RMSNorm [42] and residual connections [73]. The i-th layer is formulated as follows:\nH_g^{(i)} = RMSNorm (H_g^{(i-1)} + MHA (H_g^{(i-1)}, Concat [H_g^{(i-1)}, P^{(i-1)}])), (9)\n\\tilde{P}^{(i)} = RMSNorm() (\\tilde{H}_g^{(i)} + SwiGLU(\\tilde{H}_g^{(i)})), (10)\nP^{(i)} = RMSNorm(P^{(i-1)} + MHA (P^{(i-1)}, Concat [H_g^{(i-1)}, P^{(i-1)}])), (11)\n\\tilde{P}^{(i)} = RMSNorm(*) (P^{(i)} + SwiGLU(\\tilde{P}^{(i)})). (12)\nwhere $H_g^{(i-1)} \\in R^{(N+1)\\times d_h}$ represents the node embeddings output from the (i \u2013 1)-th global layer.\nb) Sparse Layer: In the sparse branch $f_s$, each layer also consists of an attention layer and a SwiGLU activation function. However, to focus more precisely on related nodes, we replace the attention function Attention($\\cdot$,$\\cdot$) in MHA($\\cdot$,$\\cdot$) with SparseAtt($\\cdot$,$\\cdot$), which masks attention scores smaller than the Top-k scores by setting them to zero. This can be formulated as follows:\nSparseAtt(X, Y) = Softmax (M(A))Y W_v, (13)\nwhere A is the attention scores calculated as shown in Equation 5. M($\\cdot$) is the Top-k selection operation:\n[M(A)]_{ij} = $\\begin{cases}A_{ij} & \\text{if } A_{ij} \\in Top-k(A_{i*}) , \\\\0 & \\text{otherwise.} \\end{cases}$ (14)\nwhere $A_{i*}$ represents the attention scores of the i-th node with all other nodes, i.e., $A_{i*} = {A_{ij} | j \\in {0,1,..., N}}$, and the Top-k operation selects the top k highest attention scores from this set.\nc) Fusion Layer: In our model, a simple linear projection is applied at the end of each layer to transform embeddings between two branches. For the i-th layer, the outputs from the global and sparse branches are denoted as $\\tilde{H}_g^{(i)}$and $\\tilde{H}_s^{(i)}$, respectively. The final outputs are given by:\nH^{(i)} = \\tilde{H}_g^{(i)} + (\\tilde{H}_s^{(i)} W_s + b_s), (15)\nP^{(i)} = \\tilde{H}_s^{(i)} + (\\tilde{H}_g^{(i)} W_g + b_g), (16)\nwhere $W_s, b_s, W_g$, and $b_g$ are learnable parameters.\nD. Decoder\nAfter encoding, the output of the global branch, $H^{(L)} = [h_1^{(L)}, h_2^{(L)},...,h_N^{(L)}]$, is utilized to construct the solution. During the autoregressive decoding process, at step t, the context embedding is defined as:\nH_c = Concat [h_{\\tau_t}^{(L)}, c_t^l, c_t^b, z_t, l_t, o_t] W_t, (17)\nwhere $\\Tau_t$ is the partial solution already generated, and $\\tau_t$ is the last node of the partial solution. The terms $c_t^l, c_t^b$ represent the remaining capacity of the vehicle for linehaul and backhaul customers, respectively. The terms $z_t, l_t,$ and $o_t$ represent the current time, the remaining length of the current partial route (if the problem includes a length limitation), and the presence indicator of the open route, respectively. The matrix $W_t \\in ]R^{(d_h+5)\\times d_h}$ is a learnable parameter.\nThen the context embeddings are processed through a MHA to generate the final query:\nq_c = MHA(H^{(L)}, Concat[h_i^{(L)} : i \\in I_t]), (18)\nwhere $I_t$ represents the set of feasible actions at the current step. The compatibility $u_i$ is computed as:\n$u_i = \\begin{cases} \\xi tanh(\\frac{q_c(h_i^{(L)})}{\\sqrt{d_k}}) & \\text{if } i \\in I_t, \\\\-\\infty & \\text{otherwise,} \\end{cases}$ (19)\nwhere $\\xi$ is a predefined clipping hyperparameter. Finally, the action probabilities $\\pi_{\\theta}(\\tau_q = i | V, \\Tau_{1:q-1})$ are obtained by applying the Softmax function to u = ${U_i}_{i\\in I}$.\nAdditionally, to determine the set of feasible actions at the current step $I_t$, we utilize the following feasibility testing process.\n1) Each customer node can only be visited once. If the depot is the last action in a partial solution, the next action cannot be the depot (to avoid a self-loop).\ni \\in \\Tau_{1:t-1}, i \\in {1,2,..., N} \\Rightarrow i \\notin I_t, (20)\n\\Tau_{t-1} = 0 \\Rightarrow 0 \\notin I_t. (21)\n2) For a problem without the Open Route constraint ($V_1 = 0$), each sub-route needs to return to the depot $v_0$ within the given limit. There are two types of constraints that enforce limits on when each sub-route must reach the depot: the Time Window constraint ($V_2 = 1$) with a time limit T, and the Distance Limit constraint ($V_3 = 1$) with a distance limit $\\rho$.\n($V_1 = 0) \\land (V_2 = 1) \\land ((z_t + d_{\\tau_{t-1}i} + s_i + d_{i0}) > T)$\n$\\lor ((V_1 = 0) \\land (V_3 = 1) \\land (l_t < d_{\\tau_{t-1}i}+d_{i0}))$\n$\\Rightarrow i \\notin I_t$. (22)\n3) For problems with a Time Window constraint ($V_2 = 1$), each customer node $v_i$ has a time window $[e_i, l_i]$ and a service time $s_i$. The vehicle must visit $v_i$ and complete its service within the specified time window.\n($V_2 = 1) \\land (z_t + d_{\\tau_{t-1}i} + s_i > l_i) \\Rightarrow i \\notin I_t$. (23)\n4) For the problem with the Backhaul constraint ($V_4 = 1$), the backhaul will be masked if there are still linehaul services that have not been completed.\n($\\delta_i < 0) \\land (\\exists j \\in {1, 2, ..., N}(\\delta_j > 0) \\land (j \\notin \\Tau_{1:t-1}))$\\n$\\Rightarrow i \\notin I_t$. (24)\n5) For customers, service is available when their demand does not exceed the current available capacity.\n(($\\delta_i > 0) \\land (\\delta_i > c_t^l)) \\lor ((\\delta_i < 0) \\land (-\\delta_i > c_t^b))$\n$\\Rightarrow i \\notin I_t$. (25)"}, {"title": "V. EXPERIMENTS", "content": "To evaluate the effectiveness of the proposed CaDA for VRPs", "Locations": "The nodes' locations are represented by a two-dimensional vector $X_i$", "Capacity": "In this study", "4": [6], "Demands": "In our study", "customers": "linehaul customers with demand $\\delta_i < 0$ and backhaul customers with $\\delta_i > 0$ (when the backhaul constraint is active). We generate node demands as follows: we generate linehaul demands $\\delta$ for all customers i \u2208 {1", "rule": "n$\\delta_i = \\begin{cases"}, "delta & \\text{if } \\gamma_i \\geq 0.2, \\\\d_0 & \\text{otherwise.} \\end{cases}$ (26)\nFor each node, there is a 20% probability that it represents backhaul customers in an instance.\nFurthermore, before passing the demands $\\delta_i$ to the policy, for training stability, we normalize the demand $\\delta_i$ to the range [0,1"], "Windows": "For problems with time window constraints", "considered": "time windows $[e_i", "as": "n$\\overline{t_i"}, {"follows": "ne_i = (1 + (\\overline{t_i"}, {"by": "nl_i = e_i + \\Delta t_i. (29)\ne) Distance Limit: For problems with the Distance Limit constraint, each sub-tour must be completed within a limit $\\rho$. To ensure each instance has a feasible solution, i.e., the length of the tour (0,1,0) should remain within this limit, $\\rho$ is sampled from $U(2\\cdot max(d_{0i*}), \\rho_{max})$, where $\\rho_{max} = 3.0"}]