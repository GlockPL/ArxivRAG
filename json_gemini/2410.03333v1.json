{"title": "Comparative Analysis and Ensemble Enhancement of Leading CNN Architectures for Breast Cancer Classification", "authors": ["Gary Murphy", "Raghubir Singh"], "abstract": "This study introduces a novel and accurate approach to breast cancer classification using histopathology images. It systematically compares leading Convolutional Neural Network (CNN) models across varying image datasets, identifies their optimal hyperparameters, and ranks them based on classification efficacy. To maximize classification accuracy for each model we explore, the effects of data augmentation, alternative fully-connected layers, model training hyperparameter settings, and, the advantages of retraining models versus using pre-trained weights. Our methodology includes several original concepts, including serializing generated datasets to ensure consistent data conditions across training runs and significantly reducing training duration. Combined with automated curation of results, this enabled the exploration of over 2,000 training permutations - such a comprehensive comparison is as yet unprecedented. Our findings establish the settings required to achieve exceptional classification accuracy for standalone CNN models and rank them by model efficacy. Based on these results, we propose ensemble architectures that stack three high-performing standalone CNN models together with diverse classifiers, resulting in improved classification accuracy. The ability to systematically run so many model permutations to get the best outcomes gives rise to very high quality results, including 99.75% for BreakHis x40 and BreakHis x200 and 95.18% for the Bach datasets when split into train, validation and test datasets. The Bach Online blind challenge, yielded 89% using this approach. Whilst this study is based on breast cancer histopathology image datasets, the methodology is equally applicable to other medical image datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Breast cancer globally is the most common form of cancer in women and the second most common form of any cancer [17]. It is estimated that there are 2.3m cases diagnosed globally each year [1]. It is also the leading cause of female death by cancer \u2013 684,996 in 2020. [1]. It remains a significant global health challenge, with its impact and mortality partly mitigated by advances in screening and treatment, particularly in developed countries.\nWidespread adoption of screening programmes is seen as a critical step in lowering death rates in Breast Cancer in less developed countries and as such is a key goal of the Breast Health Global Initiative [34]. AI assisted Breast Cancer screen- ing, offers potential in both developed and under-developed countries not just by improving accuracy, but in lowering the cost of detection through its efficiency.\nThis study focuses on the use of CNNs for breast cancer detection and classification based on histopathology image datasets. Through direct model comparison on different image datasets it seeks to determine which architecture(s) and which settings are most suitable for this task."}, {"title": "A. Breast Cancer", "content": null}, {"title": "B. CNNS", "content": "CNNs have revolutionised computer vision and classifica- tion, taking inspiration from the neural architecture of the visual cortex in mammals' vision [3]. Fukushima's ground- breaking neocognitron [2] together with early innovators such as LeCun [4] set the foundations for the evolution of CNNs into the powerful models available today.\nSince the inception of the ILSVRC [6], and the pioneering breakthrough in accuracy of AlexNet [7], illustrated in Fig. 1, also notable for exploiting GPUs for processing, increasing computer resources have permitted creation of deeper net- works, such as the VGG models, VGG16 and VGG19 [8].\nSubsequently CNNs evolved towards architectures prioritis- ing efficiency and dealing with the problems surrounding ever deeper networks, such as vanishing gradients.\nA raft of innovative CNN architectures have resulted, such as Inception [9], ResNets [10] and other architectures that aimed to be more efficient, rather than just adding more and more layers. These include DenseNets [12], Xception [18], NASNets [14], MobileNetV2 [13] and EfficientNets [11]. Variants of all these CNN models are fully optimised and evenly tested and compared against each other for breast cancer classification of histopathology images in this study."}, {"title": "II. RELATED WORKS", "content": null}, {"title": "A. Table of Related Works", "content": null}, {"title": "B. Existing comparison of works", "content": "M. Zhu et al's 2023 paper [20] is notable and commendable as a resource for comparing existing CNN research in breast cancer classification.\nHowever, the insular nature of the underlying studies makes comparing the relative efficacy and strengths and weaknesses of the CNN models themselves challenging. Superior performance across different studies is likely influenced more by variations in augmen- tation techniques, other pre-processing steps, and the innovations within the individual projects, rather than the inherent performance of the CNN models. Although the paper provides insight into the best results, it does not (and cannot) clearly identify the best models.\nIn addition, general research and Zhu et al.'s paper [20] highlight the absence of some contemporary CNN models that are likely well- suited for the fine-grained analysis and feature detection required in histopathology images. Notable examples include EfficientNets [11], NASNets [14], and MobileNetV2 [13].\nAs can be seen from Table. I, there have been studies using ensem- ble models but these are in the minority. Deniz et al [27] and Weiss et al [35] both employing combinations of CNN models with traditional machine learning classifiers - SVM (Support Vector Machine) and LR (Logistic Regression) respectively. These are significant as they are conceptually similar to the ensemble models developed as part of this study. There are some studies that have considered multiple datasets, such as Mewada et al's study [28], but in general most studies have only considered a single dataset and, if competition based, focused solely on overall classification accuracy."}, {"title": "III. AIMS AND CONTRIBUTIONS", "content": "This study seeks to determine the best CNN models and their optimum settings to achieve high quality results. Furthermore, to ascertain whether novel combinations of these models could provide even greater efficacy in breast cancer classification on histopathology based images. It aims to achieve this by:\n\u2022 CNN Model Comparison. Systematically comparing a range of leading standalone CNN architectures with a goal of iden- tifying which are most suited for breast cancer classification on histopathology images. Such a detailed comparison has not yet been undertaken. This includes establishing the optimal hyperparameters, the impact of varying the complexity of fully connected layers prior to classification, and establishing the advantages and disadvantages of using existing model weights.\n\u2022 Augmentation Insights. Evaluating the effect of various aug- mentation techniques and hyperparameter settings.\n\u2022 Innovative and accurate Ensemble Architectures. Combining high performing CNN models with complementary architectural features with diverse classifiers to construct innovative ensemble architectures, with a goal of achieving higher accuracy than their standalone counterparts.\n\u2022 Methodology. Developing a framework and methodology for testing and comparing these models under standardised condi- tions. This includes the novel practice of pre-generating datasets to significantly expedite batched model runs and ensure identical conditions for model comparison. This, combined with auto curation of results across multiple runs for rapid analysis and comparison, facilitated the testing of a large number of permutations, in excess of 2000 model runs, to determine the best settings and thus highest quality results."}, {"title": "IV. DATASETS TESTED", "content": "This study focuses on the following two datasets. One being a more simple binary classification challenge, binary or malignant, the other being a multi classification challenge, benign, insitu, invasive or normal."}, {"title": "A. BreakHis Dataset", "content": "The BreakHis dataset of malignant and benign images released by F. A. Spanhol et al in 2015 [21], published 7909 breast cancer histopathology images of varying magnifications (x40, x100, x200, x400). The BreakHis dataset were labelled in a binary fashion: malig- nant or benign. In general the class distribution between malignant and benign images is not even and is in the approximate ratio of 2.2:1, apart from the x400 magnification dataset which is in the ratio 2.1:1."}, {"title": "B. BAch 2018 Dataset", "content": "The Bach (Breast Cancer Histology) dataset released as part of the Bach grand challenge on breast cancer histology images by G. Aresta et al [16] in 2018. This was a smaller dataset, 400 images, spread evenly across 4 classifications: Normal, Benign, InSitu and Invasive. The findings from the challenge can be found published in the ICIAR 2018 conference proceedings in Springer, [33].\nThe challenge also provides a separate testing dataset of 100 images. Whilst these cannot be utilised in the wider study, it is possible to use trained models and settings to predict class labels for these images and submit them for a \"blind\" marking. This was undertaken in this study. The results are discussed in section VIII-D."}, {"title": "V. MODELS TESTED", "content": null}, {"title": "A. Standalone Models", "content": "The following standalone CNN models were evaluated:\n\u2022 VGG16, VGG19 [8]\n\u2022 InceptionV3 [19]\n\u2022 ResNet50, ResNet152 [10]\n\u2022 DenseNet121 [12]\n\u2022 Xception [18]\n\u2022 NASNetMobile [14]\n\u2022 MobileNetV2 [13]\n\u2022 EfficientNetV2B1 [11]\n\u2022 AlexNet [7]\n\u2022 LeNet-5 [5]\n\u2022 Bespoke (Section V-B)\nAlexNet and LeNet were tested for historical purposes to demon- strate CNN evolution. In addition to industry standard models, a Bespoke Model was implemented as outlined in section V-B."}, {"title": "B. Bespoke Model Architecture", "content": "In addition to using established CNN models from keras.applications, it was valuable and informative to develop a bespoke model, designed specifically for the fine grained feature extraction challenges required by medical image classification. Whilst simpler than more complex architectures such as Inception V3 [19] or ResNet50 [10] with which it was unlikely to compete, this model, designed for efficiency and accuracy, achieved commendable performance, even outscoring more complex models such as the VGG models [8]."}, {"title": "C. Ensemble Architectures", "content": "Based on the principle of leveraging diversity to enhance model robustness and accuracy, we subsequently integrate CNN models with distinct architectural advantages to harness their complementary strengths into ensemble architectures combined with diverse classi- fiers. The following CNN models are stacked together:\n1) DenseNet121 [12] + InceptionV3 [19] + NASNetMobile [14]\n2) EfficientNetV2B1 [11] + InceptionV3 [19] + ResNet50 [10]\n3) DenseNet121 [12] + InceptionV3 [19] + ResNet50 [10]\n4) DenseNet121 [12] + InceptionV3 [19] + MobileNetV2 [13]\nThe stacked features from each of the three combined CNNs is married to one the following 4 classifiers, giving rise to 4 ensemble architectures per Tri-CNN model combination. The numbering in this section gives rise to the shorthand notation for the Ensembles. For example, Ensemble 1a is DenseNet121, InceptionV3, NASNetMobile + LR which is further abbreviated in some of the densely populated tables to Ens 1a.\na) Logistic Regression LR models the probability that an observation belongs to a specific class. One might expect strong performance on the BreakHis datasets, which involve binary classifications. However, LR's effectiveness can be sensitive to class distribution [40], and with a ratio of approximately 2.2:1 for malignant to benign images, this imbalance could reduce its accuracy.\nDespite being a multi-classification problem, the Bach dataset, with its evenly distributed classes, demonstrates the efficacy of LR when class distribution is balanced. Although scikit-learn offers a 'multi_class='multinomial'' setting, the simpler 'ovr' (one-vs-rest) setting was favoured by GridSearch over multi- nomial for both BreakHis and Bach datasets. Thus, the model operated as a series of binary logistic regressions. GridSearch also determined that LR would employ the LBFGS solver for all datasets, a Limited-memory Broyden-Fletcher-Goldfarb-Shanno algorithm, which is effective for handling large datasets.\nFor a binary classification problem ('ovr' mode), where the response variable Y takes values in {1,2}, given predictor variables x = (x1,x2,...,Xp)T, LR models the log-odds of the probabilities as follows [38]:\n$\\log \\left(\\frac{P(Y = 1 | x)}{P(Y = 2 | x)}\\right) = \\beta_0 + \\beta^T x$   (1)\nwhere:\n\u2022 Bo is the intercept term.\n\u2022 \u03b2 = (\u03b2\u03b9, \u03b22, ..., \u03b2p) are the coefficients corresponding to each predictor variable, where p represents the number of features (or predictor variables) in the model.\nFrom the log-odds, the probabilities can be derived as:\n$P(Y = 1 | x) = \\frac{\\exp(\\beta_0 + \\beta^T x)}{1 + \\exp(\\beta_0 + \\beta^T x)}$   (2)\nGiven that P(Y = 2 | x) = 1 \u2013 P(Y = 1 | x), we have:\n$P(Y = 2 | x) = \\frac{1}{1 + \\exp(\\beta_0 + \\beta^T x)}$ (3)\nNote: The equations provided here represent a simplified case of logistic regression, specifically for binary classification or when the multi_class setting is set to 'ovr' (one-vs-rest).\nb) Support Vector Classification SVC is designed to find the optimal hyperplane that maximizes the margin between different classes. It is capable of non-linear classification, which, achieved through the \"kernel trick,\" enables it to discern com- plex patterns found in histopathology images [36]. The kernel trick uses kernel functions to implicitly project data into a higher-dimensional space. This approach relies on calculating the dot product from the input vectors to determine the similar- ity between classes, allowing the algorithm to find an optimal"}, {"title": "VI. RESEARCH METHODOLOGY", "content": null}, {"title": "A. Outline Concepts", "content": "\u2022 Data Pre-processing: Ensuring the images are in the required format (3 channel x 8 bits/channel), images randomly split into train (60%), validation (20%) and test (20%) and the directory structure reflects the image labels. Post splitting the datasets, a programmatic check to ensure there is no data leakage is initiated.\n\u2022 Augmentation: Pre-Training - Generating augmented images to supplement training datasets.\nDuring Training - Comparing static augmentation (serializing datasets) with on-the-fly/dynamic augmentation.\n\u2022 Dataset Pre-generation: Serializing datasets to numpy files to ensure identical conditions for each CNN model and to expedite training. See Section VI-E.\n\u2022 Dynamic Hyperparameters: Enable runtime adjustment of hyperparameters for flexible experimentation, in addition to flags that, for example, control whether to use pre-existing weights, or to adopt fine-grained filtering by employing more fully connected layers (see section VI-G).\n\u2022 Efficient Training: Use parameterised callbacks for early stop- ping, learning rate reduction on loss plateau, and saving the best model state when validation accuracy improves.\n\u2022 Novel ensemble architectures: Creating ensemble models by combining high performing CNNs exhibiting complementary"}, {"title": "B. End-to-end Architecture", "content": null}, {"title": "C. Data Pre-processing", "content": "For both image datasets, for each class (labelled by way of its sub- directory structure) the datasets were split - training:validation:testing - ratio of 60:20:20, using train_test_split from sklearn.model_selection. Pre-processing of each dataset was slightly different as set out below:\ncan\n1) Bach 2018 Grand Challenge: The Bach datasets be downloaded from zenodo [16]. The zip file\nICIAR2018_BACH_Challenge has quite a straight forward structure with a root directory of Photos followed by sub-directories for Benign, InSitu, Invasive and Normal. Each sub-directory containing TIFF files of size 2048 x 1536 pixels, with a bit depth of 48, each approximately 18Mb in size.\nPre-processing was straightforward. The images were converted to 24bit (8 bit x3 channel) PNG files, of the same resolution but less than a quarter of the size at approximately 4Mb each.\n2) BreakHis Datasets: The BreakHis datasets can be down- loaded following instructions in Spanhol et al's paper [21]. The folder root directory has two sub-directories: benign and malignant.\nBeneath both the benign and malignant sub-directories is a further sub-directory called SOB. Under SOB are more detailed classifica- tions on the type of tumour, followed by the magnification level, x40, x100, x200, x400 with each of these directories containing the image files as 700 x 460 pixel, 24 bit. The BreakHis images did not need pre- processing, the images were collated into a simpler directory structure of x40, x100, x200, x400 each with a sub-directory for benign and one for malignant, each holding the respective images."}, {"title": "D. Augmentation", "content": "Augmentation of the training image datasets was an important technique, particularly for the Bach dataset, which contained only 60 images per class once split into train, val and test datasets. As a result, augmentation significantly impacted training efficacy."}, {"title": "E. Dataset Pre-generation", "content": "As discussed in the previous section the three datasets datasets, training, validation and testing were pre-generated and serialized to file. This approach ensured consistent data conditions and signifi- cantly expedited model training. It allowed for consistent comparisons across more than 2000 model runs."}, {"title": "F. CNN Model Harness", "content": "Central to the methodology and framework is the development of a runtime configurable harness that can accept the core CNN model, the input dataset, and various runtime and model hyperparameters."}, {"title": "G. Coarse or Fine Grained Fully-Connected Pre- Classification blocks", "content": "Each CNN model is loaded without the very topmost layer (the classification layer) and a uniform classification construct is added. The harness tests using a simple fully connected layer block or a more complex one, prior to classification, as determined by the fine_grained hyperparameter.\nThe two variants are shown in Fig. 5. The fine-grained model was particularly effective for the Bach dataset [16], albeit less marked for the BreakHis binary classification datasets [21]. The impacts on the classification accuracy for the Bach dataset are detailed in Section VIII-C in Table. VII.\nIt should be noted than the additional dense layers add significantly to the number of trainable parameters in a CNN, and thus compu- tational resources required. As such its use was not recommended or used for the BreakHis datasets. This underlines the importance of flexible settings that may vary per image dataset characteristics."}, {"title": "VII. RUN OUTPUTS", "content": "The challenge with over 2000 runs, is that it is not possible to present all the result outputs in a journal paper. The Results section, is thus very condensed and presented as a series of tables, giving various insights into models and settings efficacy in highly summarised form. In particular with so many dimensions to show, some of the key quality metrics are not shown in these summary tables.\nMore detailed tables show all the outputs for a single dataset, using optimal hyperparameter, augmentation and other runtime settings both in terms of results, confusion matrices and quality metrics. This information is replicated many hundreds of times. Specific run details can be furnished upon request."}, {"title": "A. Standalone CNN Batch test outputs", "content": "Each CNN model run training generates the following files:\n\u2022 A graph showing Validation and Training Accuracy by Epoch.\n\u2022 A graph showing Validation and Training Loss by Epoch.\n\u2022 A \".h5\" (HDF5) file holding the best model and its weights.\n\u2022 A JSON file storing the hyperparameters used and the results from the run. The latter are created by loading the HDF5 file and using it to predict the results from the test dataset.\n\u2022 A confusion matrix from the test dataset predictions."}, {"title": "VIII. NUMERICAL RESULTS", "content": "Having ascertained the very best models and settings, using optimized hyperparameters, ignoring existing model weights, using image sizes that respected the aspect ratio of the source images, augmentation and appropriate fully connected layers, it was clear that the differences between the top performing models was marginal and within the potential variation of a given training run. Despite using pre-generated datasets to ensure that images were processed in identical order and identical training augmentation, CNN model training can show slight variances between runs.\nIn order to more fully verify our results, we undertook more rigorous verification. This involved taking the best CNNs, with their associated optimised settings, for histopathology feature detection and cancer classification: DenseNet121 (DNet) [12], InceptionV3 (Incp'n) [19], ResNet50 (RNet50) and ResNet152 (RNet152) [10], Xception (Xcep'n) [18], NASNetMobile (NNMob) [14], MobileNetV2 (MNet) [13], EfficientNetV2B1 (ENet) [11], and testing each model on each dataset ten times each to form an average.\nEnsembles 3(a,b,c,d) and 4(a,b,c,d) were also added at this time and each of the resulting 16 ensembles was tested a further 5 times, again to form an average. This verification phase of 8 CNN models and 16 ensemble models on 6 datasets, tested ten and five times respectively added an additional 960 runs. The averaged results, which show more scientific rigour are shown in Table. III. The weighted average (WtdAvg), by which it is ordered, makes Bach equal in significance to the average of the five BreakHis (BH) datasets.\nThe marginal variations between runs, underlines the importance generally of multiple CNN runs to establish which are the best performing models and settings. The high accuracy obtained across all models is testament to the methodology of this study, and the performance of modern architected CNNs. Ensemble Architectures were found to slightly outperform their constituent CNN models.\nThe following sections detail the impacts of varying the training condition settings. Where direct comparisons are made, these are for single runs, and not based on the averages set out in Table. III."}, {"title": "A. Impacts of Augmentation", "content": "This study conducted investigations on the use of augmentation as a means to boost training sample images, termed \"Pre-Training Augmentation\", and during training to avoid overfitting, termed \"Augmentation During Training\". The findings are discussed here:"}, {"title": "IX. CONCLUSIONS", "content": "Systematic testing of multiple models with varying parameters and settings provided valuable insights into the relative efficacy of CNN and ensemble architectures in classifying breast cancer histopathology images, using the Bach [33] and BreakHis [21] benchmark datasets.\nA novel aspect of the methodology concerned pre-generation of all data sets and serializing these to file. For the testing dataset, which had inline augmentation settings, this was termed static augmentation. This proved to be highly effective in expediting model training and ensuring consistent comparisons, forming a cornerstone of this study's methodology. The reduction in training duration enabled multiple environment and hyperparameter permutations to be tested in a timely manner.\nA simpler innovation concerned the persistence of all the run and hyperparameter settings together with the results to JSON files, such that results could be automatically processed for rapid analysis.\nTogether these facilitated the identification of optimal hyperparam- eter settings, evaluation on the impacts of augmentation strategies, the use of differing fully connected layers and comparison of model accu- racy when using existing model weights or retraining from scratch. As a result very high accuracies were achieved for the standalone CNN models. This subsequently led to creation of ensemble architecture models which attempted to refine classification accuracy further."}]}