{"title": "FANTASTIC TARGETS FOR CONCEPT ERASURE IN DIFFUSION MODELS AND WHERE TO FIND THEM", "authors": ["Anh Bui", "Trang Vu", "Long Vuong", "Trung Le", "Paul Montague", "Tamas Abraham", "Junae Kim", "Dinh Phung"], "abstract": "Concept erasure has emerged as a promising technique for mitigating the risk of harmful content generation in diffusion models by selectively unlearning undesirable concepts. The common principle of previous works to remove a specific concept is to map it to a fixed generic concept, such as a neutral concept or just an empty text prompt. In this paper, we demonstrate that this fixed-target strategy is suboptimal, as it fails to account for the impact of erasing one concept on the others. To address this limitation, we model the concept space as a graph and empirically analyze the effects of erasing one concept on the remaining concepts. Our analysis uncovers intriguing geometric properties of the concept space, where the influence of erasing a concept is confined to a local region. Building on this insight, we propose the Adaptive Guided Erasure (AGE) method, which dynamically selects optimal target concepts tailored to each undesirable concept, minimizing unintended side effects. Experimental results show that AGE significantly outperforms state-of-the-art erasure methods on preserving unrelated concepts while maintaining effective erasure performance. Our code is published at https://github.com/tuananhbui89/Adaptive-Guided-Erasure.", "sections": [{"title": "INTRODUCTION", "content": "The widespread accessibility of text-to-image generation models has introduced significant risks such as the generation of harmful content, copyright infringements, and biases due to the exposure of models to undesirable concepts during training. Initial attempts to address these concerns focus on dataset filtering during the training phase (StabilityAI, 2022), post-generating filtering (Rando et al., 2022) or inference guiding (Schramowski et al., 2023b). While dataset filtering often requires costly retraining, post-processing and inference-based methods can be easily bypassed (Yang et al., 2024). Recently, concept erasure (Bui et al., 2024b;a; Gandikota et al., 2023; Orgad et al., 2023; Zhang et al., 2023; Kumari et al., 2023), which aims to directly remove the concept from the model's parameters without the need for complete retraining, has emerged as a promising alternative.\nConcept erasure methods can be broadly categorized into two approaches: output-based and attention-based. Output-based methods aim to neutralize the output associated with undesirable concepts (Bui et al., 2024b;a; Gandikota et al., 2023; Wu et al., 2024), while attention-based methods modify the attention scores of these concepts in the cross-attention layers of the model (Zhang et al., 2023; Orgad et al., 2023; Gandikota et al., 2024; Lu et al., 2024; Lyu et al., 2024). Despite their differences, both approaches share a common principle: mapping undesirable concepts to a fixed, generic target, such as \u201ca photo\" or an empty text prompt. Although these methods have shown success in erasing undesirable concepts, they do not consider how the choice of target concepts affects both the effectiveness of erasure and the preservation of benign concepts.\nTo address this limitation, we first model the concept space as a graph, where each node represents a concept, and the edge weights denote the impact of erasing one concept on another. We perform an empirical analysis using a newly curated evaluation dataset, NetFive, to understand the structure of the concept space. Our findings suggest that the concept impact space has a geometric structure,"}, {"title": "", "content": "characterized by a key property: locality-the impact of erasing one concept is localized in the concept space, i.e., it affects strongly only those concepts that are close to the erased one.\nFurthermore, we explore different types of target concepts-synonyms, semantically related local concepts, and semantically distant concepts\u2014and find that the choice of target significantly influences both erasure performance and the preservation of benign concepts. At the end, we identify the ideal target concept as the most affected by the change of the model parameters when the corresponding concept is erased, but must not be its synonym.\nBuilding on these insights, we propose the Adaptive Guided Erasure (AGE) method, which automatically selects the optimal target concept for each erasure query by solving a minimax optimization problem. To further improve the richness of the target concept, we model it as a learned mixture of multiple single concepts, allowing us to search for the optimal target in continuous rather than discrete space. We evaluate the proposed AGE method on various erasure tasks, including object removal, Not-Safe-For-Work (NSFW) attribute erasure, and artistic style removal. Experimental results show that AGE significantly outperforms state-of-the-art concept erasure methods, achieving near-perfect preservation of benign concepts while effectively erasing undesirable ones.\nOur main contributions can be summarized as follows. We present a novel empirical evaluation of the structure and geometric properties of the concept space, which provides new insights into concept erasure, such as the locality of the impact of erasing one concept on another. We analyze the impact of target concept selection on both erasure effectiveness and the preservation of benign concepts, identifying two key properties of desirable target concepts, i.e., closely related but not synonyms to the to-be-erased concept. Motivated by the analysis, we propose a novel adaptive method for selecting the optimal target concept for each erasure query satisfying the two key properties. Finally, we conduct extensive experiments demonstrating the effectiveness of our method and its ability to preserve benign concepts while erasing undesirable ones."}, {"title": "BACKGROUND", "content": "Latent Diffusion Models. Diffusion models, a recent class of generative models, have shown impressive results in generating high-resolution images (Ho et al., 2020; Rombach et al., 2022; Ramesh et al., 2021; 2022). In a nutshell, training a diffusion model involves two processes: a forward diffusion process where noise is gradually added to the input image xo ~ Pdata, and a reverse denoising diffusion process where the model tries to predict a noise et, which is added in the forward process. The model is trained by minimizing the difference between the true noise e and the predicted noise 60(xt, t) at diffusion step t parameterized by the denoising model 0. With an intuition that semantic information that controls the main concept of an image can be represented in a low-dimensional space, Rombach et al. (2022) proposed a diffusion process operating on the latent space of a pre-trained encoder & which compresses the input data xt into low-dimensional latent representation zo = E(x). The objective function of the latent diffusion model as follows:\n\\(L = E_{zo~E(x),x~Pdata,t,\u20ac~N (0,1)} ||\u20ac \u2013 60(zt, t)||^2\\) (1)\nConcept Erasing. Given a textual description in a set of undesirable concepts ce \u2208 E, the concept erasing problem aims to remove this concept from a pretrained text-to-image diffusion model \u20ac0(zt, T(c), t), typically via finetuning to obtain a benign output ep' (zt, T(c), t) from sanitized model E' parameterized by \u03b8'. For the remainder of this paper, because all outputs are from the same time step t and latent vector zt, we omit the time step t and latent vector zt for the sake of simplicity, i.e., \u20ac\u03b8(T(c)) and e\u0189' (T(c)). While proposed in different forms, previous works (Gandikota et al., 2023; Orgad et al., 2023; Gandikota et al., 2024) share a common principle to map a to-be-erased concept ce to a target neutral concept ct. The target concept ct can be either a generic concept, such as \"a photo\" or a null concept, such as an empty text prompt. It is typically predefined and fixed for all undesirable concepts ce \u2208 E. To preserve the model's performance on other concepts, an additional term L2 is added to ensure that the output of the neutral concept remains unchanged. More specifically, the erasing objective can be formulated as follows:\n\\(min_{\\theta'} Ec_e[||\\epsilon_{\\theta'}(\\tau(c_e)) - \\epsilon_{\\theta}(\\tau(c_t)||_{L_1}^2] + ||\\epsilon_{\\theta'}(\\tau(c_n)) - \\epsilon_{\\theta}(\\tau(c_n)||_{L_2}^2\\) (2)"}, {"title": "", "content": "While this naive principle is simple and effective in erasing the specific concept, choosing a fixed neutral concept as the target concept for all concepts to be erased is obviously not optimal (i.e., Ct = Cn \u2200Ce \u2208 E). Intuitively, remapping the visual concept \u201cEnglish Springer\u201d to \u201cDog\u201d will likely cause a less drastic change on the model's parameter compared to remapping it to a neutral concept such as \"A photo\" or \"\", leading to a better preservation performance on other concepts. In the following section, we will provide a series of evidence to support this intuition which leads us to a principled approach on choosing an optimal target concept for each concept to be erased."}, {"title": "QUANTIFYING IMPACT OF ERASING CONCEPTS", "content": "Netfive Dataset. Two main challenges in evaluating an erasing method are: (1) How to verify whether a concept is present in the generated images or not? (2) How to ensure the evaluation is diverse enough to cover the output space of the model which is of infinite possibilities? To tackle these two challenges, we propose an evaluation dataset called NetFive, which consists of 25 concepts from the ImageNet dataset, for which we can leverage the pre-trained classification model to verify the presence of the concepts in the generated images. We also ensure the diversity of the evaluation by generating 500 samples for each concept. More specifically, we choose a total of five subsets of concepts, each subset contains one anchor concept, e.g., \"English Springer\" and four related concepts, ranked by their closeness to the anchor concept as follows: (the details and rationale of choosing the concepts are provided in Appendix C.1)\n\u2022 Dog: English springer, Clumber spaniel, English setter, Blenheim spaniel, Border collie.\n\u2022 Vehicle: Garbage truck, Moving van, Fire engine, Ambulance, School bus.\n\u2022 Instrument: French horn, Basson, Trombone, Oboe, Saxophone.\n\u2022 Building: Church, Monastery, Bell cote, Dome, Library.\n\u2022 Equipment: Cassette Player, Polaroid camera, Loudspeaker, Typewriter keyboard, Projector.\nMetric to measure the generation capability of the model. Because of intentionally choosing all concepts from the ImageNet dataset, we can leverage the pre-trained classification model to detect the presence of the concept in the generated image, More specifically, given a model Ge, we generate k = 500 images with the input description c, and then measure using the metrics:\n\u2022 Detection Score (DS-1/DS-5): # of samples that are classified as the concept c in top-1 or top-5 predictions / k (i.e., top-k accuracy).\n\u2022 Confident Score (CS-1/CS-5): Average confident score w.r.t. the concept c in top-1 or top-5 predictions, otherwise, the confident score is set to be 0. This metric indicates how good the model Ge is when generating the concept c. A higher score means that the concept c is more likely appeared in the generated images.\nFor all metrics, higher values indicate better generation capability of the model on concept c. In the rest of the paper, we use the Detection Score (DS-5) as the main metric, while results for other metrics are provided in Appendix C.2.\nWe present Go (cj) and Gce (cj) as the generation capability of the original model and the sanitized model on the same query concept cj after erasing concept ce, respectively. With this, we can measure the impact of erasing concept ce on the generation capability of concept cj by computing the difference between Go(cj) and Gce (cj), i.e., \u2206(ce, Cj) = Go(cj) \u2013 Gce (cj)."}, {"title": "TARGETING TO A GENERIC CONCEPT", "content": "We first analyze the impact of choosing a generic concept such as an empty \u201c \" as the target concept for erasure. The top subfigure in Figure 1 shows a sample analysis of the impact of erasing concept \"English Springer\" to the generation capability of all NetFive concepts. Each column corresponds to one concept cj in the NetFive dataset. The blue bar represents the generation capability Gce (cj) of the sanitized model on concept cj, while the total height of the stack is the generation capability Go(cj) of the original model on concept cj. The red bar, therefore, represents the gap of generation capability between the sanitized model and the original model, i.e., \u2206(ce, Cj) = Go(cj) \u2013 Gce (cj),"}, {"title": "", "content": "The higher the total height of the stack, the higher the generation capability of the original model on concept cj, while the higher the red bar, the higher the difference between the generation capability of the sanitized model and the original model. We also provide the confidence score of the classifier when predicting the concept from the generated images from the original model (the green line) and the sanitized model (the orange line).\nSample Analysis. It can be seen from the top subfigure in Figure 1 that the concept Ce \"English Springer\" has been successfully removed from the sanitized model as evidenced by Gee (\"English Springer\") = 0. It can also be seen that all closely related concepts to concept ce \"English Springer\" are affected by the erasure of this concept, evidenced by the significant drop in the generation capability Gce (Cj) < Go(cj), as well as the corresponding confidence scores. In contrast, the other concepts that are not closely related to the concept ce are less affected, evidenced by the unchanged generation capability Gce (cj) \u2248 Go(cj). Interestingly, the two abnormal concepts that are not related to the to-be-erased concept ce but are also affected, \"Bell Cote\" and \"Oboe\". These two concepts have low generation capability even before the erasure of concept ce, i.e., Go(cj) \u2248 60%, compared to other concepts which have Go(cj) \u2248 100%.\nSystematic Analysis. Figure 1 shows the impact of erasing one concept to all the other concepts in the NetFive dataset, where each row corresponds to erasing one concept, and the first row corresponds to erasing the concept \u201cEnglish Springer\u201d as shown in the top subfigure. Each cell in the matrix represents the drop of the generation capability of concept cj after erasing concept ce, i.e., A(Ce, Cj) = Go(cj) \u2013 Gce (cj). A deeper red color indicates a larger drop of the generation capability of concept cj after erasing concept ce. The matrix can be interpreted as a concept graph, showing the impact of one concept on other concepts.\nThere are several intriguing observations that can be made from Figure 1:"}, {"title": "", "content": "\u2022 Locality: The concept graph is sparse and localized, which means that the impact of eras-ing one concept does not strongly spread to all the other concepts but only local concepts that are semantically related to the erased concept ce.\n\u2022 Asymmetry: The concept graph is asymmetric such that the impact of erasing concept Ce on concept cj is not the same as the impact of erasing concept cj on concept ce.\n\u2022 Abnormal: The two abnormal concepts \u201cBell Cote\u201d and \u201cOboe\u201d, which have low genera-tion capability to begin with, are sensitive to the erasure of any concept.\nIn the case of erasing exclusive concepts, such as \u201cTaylor Swift\", \"Van Gogh\", \"gun\", and \"nudity\" as shown in the last four rows of the figure, the impact of erasing these concepts to all NetFive con-cepts are also limited, except for the two abnormal concepts, which supports the above observations on the concept graph.\nResults with Stable Diffusion version 2.1 Figure 13 shows the impact of choosing the empty concept as the target concept for erasure with Stable Diffusion v2.1 It can be seen that our earlier observations are still valid, except that the abnormal concepts which have low generation capability and are sensitive to the erasure of any concept are now \u201cBell Cote\u201d and \u201cProjector\u201d. This consistency indicates the generalization of the observations on the concept graph of different models, trained on different datasets and settings.\""}, {"title": "TARGETING TO A SPECIFIC CONCEPT", "content": "We now compare different strategies of choosing the target concept for erasure to see how the choice of the target concept affects the preservation of other concepts. In each subset, we choose to erase a same concept ce but with seven different target concepts ct, in the following order: (1st) a synonym of ce, (2nd, 3rd) two semantically related concepts but not synonyms, (4th) a general, upper-level concept that covers the subset, (e.g. \u201cDog\u201d for the concept \u201cEnglish Springer\u201d) (5th, 6th) two semantically unrelated concepts, and (7th) an empty concept. The explanation of finding a synonym to an anchor concept is provided in Appendix C.3.\nIt can be seen from Figure 2 that the preservation performance highly depends on the choice of the target concept. More specifically, there are several notable observations:\n\u2022 Locality: Regardless of the choice of the target concept, the impact of erasing one concept is still sparse and localized."}, {"title": "", "content": "\u2022 Abnormal: The two abnormal concepts \"Bell Cote\" and \"Oboe\" are still sensitive to the erasure of any concept regardless of the choice of the target concept.\n\u2022 Synonym XXX: Mapping to a synonym of the anchor concept leads to a minimal change as evidenced by the lowest \u2206(ce, Cj) for all cj. However, it also the least effective in erasing the undesirable concept ce.\n\u2022 All Unrelated Concepts XX: Mapping to semantically unrelated concepts demonstrates the similar performance as the generic concept \u201c\", as evidenced by the similar (Ce, Cj) between the three last rows (5th \u2013 7th) in each subset.\n\u2022 General concepts X: While choosing a general concept as the target concept is intuitive and reasonable, it does not necessary lead to good preservation performance. For example, \"English Springer\" \u2192 \"Dog\" or \"French Horn\u201d \u2192 \u201cMusical Instrument Horn\" still cause a drop on related concepts in their respective subsets. Moreover, there are also small drops on erasing performance compared to other strategies, shown by DS-5 of 83%, 91%, and 78% when mapping \u201cGarbage Truck\u201d to \u201cTruck\u201d, \u201cFrench Horn\" to \"Musical Instrument Horn\", and \"Cassette Player\" to \"Audio Device\", respectively. The two observations indicate that choosing a general concept is not an optimal strategy.\n\u2022 In-class: The highest preservation performance which is consistently observed in all five subsets is achieved when the target concept is a closely related concept to ce. For example, \"English Springer\u201d \u2192 \u201cClumber spaniel\" or \u201cGarbage Truck\u201d \u2192 \u201cMoving Van\" or \"School Bus\" in the \"Dog\" and \"Vehicle\" subsets."}, {"title": "PROPOSED METHOD: ADAPTIVE GUIDED ERASURE", "content": "Motivated by the observations in Section 3, we propose to select the target concept for erasure adaptively for each query concept to mitigate the side effects of erasing undesirable concepts in diffusion models. More specifically, the ideal target concept should satisfy the following properties:\n\u2022 It should not be a synonym of the query concept that resembles a similar visual appearance (e.g., \"nudity\" to \"naked\u201d or \u201cnude\", or \u201cGarbage Truck\u201d to \u201cWaste Collection Vehicle\u201d). This ensures that the erasure performance on the query concept remains effective.\n\u2022 It should be closely related to the query concept but not identical (e.g., \"English Springer\" to \"Clumber Spaniel\", or \u201cGarbage Truck\u201d to \u201cMoving Van\"). This helps preserve the model's generation capabilities on other concepts. As suggested by the locality property of the concept graph, changes in the model's output can be used to identify these locally related concepts.\nAlthough it is possible to manually select the ideal target concept for each query concept based on the above properties, this approach is not scalable for a large erasing set E. Therefore, we propose an optimization-based approach to automatically and adaptively find the optimal target concept for each query concept. Specifically, we aim to solve the following optimization problem:\n\\(min_{\\theta'} E_{C_e \\in E} max_{C_t \\in C} ||\\epsilon_{\\theta'}(\\tau(C_e)) - \\epsilon_{\\theta}(\\tau(C_t)||_{L_1}^2 + \\lambda ||\\epsilon_{\\theta'}(\\tau(C_t)) - \\epsilon_{\\theta}(\\tau(C_t)||_{L_2}^2\\) (3)\nwhere A is a trade-off hyperparameter and C is the search space of target concepts Ct.\nMinimizing the objective L\u2081 w.r.t. \u03b8' ensures that the output of the sanitized model for the query concept ce is close to the output of the original model but for the target concept ct, which serves the purpose of erasing the undesirable concept ce. Meanwhile, minimizing the objective L2 w.r.t. \u03b8' ensures that the output of the two models remain similar for the same input concept ct, preserving the model's capability on the remaining concepts. In summary, the outer minimization problem optimizes the sanitized model parameters \u03b8' to simultaneously erase undesirable concepts and preserve the model's functionality for other concepts.\nOn the other hand, maximizing the objective L\u2081 w.r.t. Ct ensures that the solution ct is not a synonym of the query concept ce, while maximizing the objective L2 w.r.t. ct finds a sensitive"}, {"title": "", "content": "concept to the change of the model's parameter 0 \u2192 \u03b8'. This helps identify the most related concept to the query concept ce, as suggested by the locality property of the concept graph in Section 3. By maximizing both L1 and L2 w.r.t. ct, we ensure that the solution c satisfies both key properties of the ideal target concept. We provide empirical evidence in Section 5.2 and Appendix D.6, showing that the intermediate value of the solution ct from the optimization problem equation 3 aligns with the above analysis.\nOptimization Details. Since the concept space C is discrete and finite, the straightforward approach is to enumerate all the concepts in C and select the one that maximizes the total loss in each optimization step of the outer minimization problem. However, this approach is computationally prohibitive for large C. Moreover, some concepts can be complex and may not be interpreted as a single concept in the concept space C. To address this, we formulate the target concept as a com-bination of multiple concepts in the concept space C, i.e., \u0442(ct) = G(\u03c0) \u2299 Tc, where G is the Gumbel-Softmax operator, \u03c0\u2208 R|| is a learnable variable, and Tc is the textual embedding matrix of the entire concept space C. We choose the Gumbel-Softmax operator with a temperature less than 1 to ensure that the target concept is a combination of a few main concepts rather than a mixture of all concepts in C. The optimization problem equation 3 can be rewritten as follows:\n\\(min_{\\theta'} E_{C_e \\in E} max_{\\pi}  - ||\\epsilon_{\\theta'}(\\tau(C_e)) - \\epsilon_{\\theta}(G(\\pi) \\odot T_c)||_{L_1}^2 + \\lambda ||\\epsilon_{\\theta'}(G(\\pi) \\odot T_c) - \\epsilon_{\\theta}(G(\\pi) \\odot T_c)||_{L_2}^2\\) (4)\nin which the objective of the inner-max is transformed to find the continuous weight instead of the discrete concept ct. This trick allows us to increase the richness and expressiveness of the target concept ct as well as the optimization efficiency. We provide further details in Appendix B."}, {"title": "EXPERIMENTS", "content": "In this section, we demonstrate the effectiveness of our method in erasing various concepts from the foundation model, including object-related concepts, artistic styles, and NSFW attributes. We compare our approach with the state-of-the-art erasure methods including AP (Bui et al., 2024b), ESD (Gandikota et al., 2023), UCE (Gandikota et al., 2024), CA (Kumari et al., 2023), and MACE (Lu et al., 2024). Our experiments follow the same setup as in Bui et al. (2024b); Gandikota et al. (2023; 2024). Specifically, we use Stable Diffusion (SD) version 1.4 as the foundation model, and fine-tune the model for 1000 steps with a batch size of 1, using the Adam optimizer with a learning rate of a = 10-5.\nFurther implementation details and analyses are provided in the appendix, including qualitative re-sults (Section D.8), an examination of the impact of vocabularies (Section D.2) and hyperparameters (Section D.3), as well as an analysis of the search for the optimal target concepts (Section D.6). We strongly recommend referring to the appendix for a deeper understanding of our method and experiments."}, {"title": "ERASING OBJECT-RELATED CONCEPTS", "content": "Setting. In this experiment, we assess our method's ability to erase object-related concepts, such as \"Dog\u201d or \u201cCat\u201d, from a foundational model. We utilize the Imagenette dataset 1, a subset of Ima-geNet (Deng et al., 2009), which contains 10 easily recognizable classes as suggested in (Gandikota et al., 2023). We conduct four different erasing tasks, each involving the simultaneous erasure of five classes while preserving the other five, generating 500 images per class.\nMetrics. Erasing performance is measured using the Erasing Success Rate (ESR-k), which cal-culates the percentage of generated images where the \"to-be-erased\" classes are not detected in the top-k predictions. Preserving performance is evaluated using the Preserving Success Rate (PSR-k)"}, {"title": "ERASING NSFW CONCEPTS", "content": "Setting. In this experiment, we focus on unlearning Not-Safe-For-Work (NSFW) attributes like \u201cnudity\u201d from the model's capability. We follow the same setting as in (Gandikota et al., 2023), focusing exclusively on fine-tuning the non-cross-attention modules. To generate NSFW images, we employ I2P prompts (Schramowski et al., 2023b) and generate a dataset comprising 4703 images with attributes encompassing sexual, violent, and racist content.\nMetrics. We utilize the detector (Praneet, 2019) which can accurately detect several types of exposed body parts to recognize the presence of the nudity concept in the generated im-ages. The detector (Praneet, 2019) provides multi-label predictions with associated confi-dence scores, allowing us to adjust the thresh-old and control the trade-off between the num-ber of detected body parts and the confidence of the detection, i.e., the higher the threshold, the fewer the number of detected body parts. Erasing performance is measured using the Nudity Exposure Rate (NER-k), which measures the ratio of images with any exposed body parts detected by the detector (Praneet, 2019) over the total number of generated images with a confidence score greater than the threshold k. For example, in Table 2, with the threshold set at 0.5, the NER score for the CA model stands at 9.27%, indicating that 9.27% of the generated images contain signs of nudity concept from the detector's perspective. Preserving performance is evaluated using FID score on COCO 30K validation set."}, {"title": "ERASING ARTISTIC CONCEPTS", "content": "Setting. In this experiment, we evaluate our method's ability to erase artistic style concepts. We focus on five well-known artists with highly recognizable styles that are commonly mimicked by text-to-image generative models, including \"Kelly Mckernan\", \"Thomas Kinkade\", \"Tyler Edlin\", \"Kilian Eng\", and \"Ajin Demi Human\u201d as in (Gandikota et al., 2023). The experiment involves five tasks, each aiming to erase one artist's style while preserving the others.\nMetrics. A major challenge in this setting is the lack of a reliable detector for identifying the presence of artistic styles in generated images. Human-evaluation is avoided due to the high cost, time-consuming, not scalable, and more importantly, easily biased. To overcome this, we utilize the CLIP score 2 to measure the alignment between the generated images and the textual prompts, which has been shown to be effective in similar tasks (Gandikota et al., 2023). To enhance the correctness, we make use of a list of long textual prompts that are designed exclusively for each artist (credits to (Gandikota et al., 2023)), combined with 5 seeds per prompt to generate 200 images for each artist across all methods. This approach allows the use of the CLIP score as a more meaningful measurement to evaluate the erasing and preserving performance. We also use LPIPS (Zhang et al., 2018) to measure the distortion in generated images by the original SD model and editing methods, where a low LPIPS score indicates less distortion between two sets of images. However, as LPIPS is designed for quantitative comparison between two outputs, it might not be as good as CLIP score in order to verify the presence of a specific concept in the generated images, and should be used as a complementary metric to CLIP score."}, {"title": "", "content": "Results. Figure 5 presents the results of the artistic style erasure task. In term of CLIP score, it can be seen that our method along with AP and UCE lie in the Pareto frontier (with the ideal point being the top-left corner), with a clear trade-off between erasing and preserving performance. For example, AP achieves better erasing performance than our method with a CLIP score of 21.57 and 22.44, respectively, but our method outperforms AP in preserv-ing performance with a CLIP score of 30.45 and 30.13, respectively. However, in term of LPIPS score, our method clearly achieves the best trade-off between erasing and preserving performance, with the erasing score of 0.80 and preserving score of 0.44, while AP achieves the erasing score of 0.78 and preserving score of 0.47."}, {"title": "CONCLUSION", "content": "In this paper, we introduced the Adaptive Guided Erasure (AGE) method, a novel approach for concept erasure that addresses the limita-tions of existing fixed-target methods. By modeling the concept space as a graph and analyzing its geometric properties, we demonstrated that selecting a locally related target concept can mini-mize unintended side effects. AGE adapts target selection through a minimax optimization, further enriched by representing targets as mixtures of single concepts. Our experiments show that AGE outperforms state-of-the-art methods, effectively erasing undesirable concepts while preserving be-nign ones across various tasks. Besides the method, we also provided the first comprehensive study of the concept space structure, providing new intriguing insights that shed light on the concept space geometry. We believe that these insights will inspire future research on understanding and manipulating the concept space for various applications."}]}