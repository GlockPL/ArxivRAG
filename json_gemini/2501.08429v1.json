{"title": "Modeling Discrimination with Causal Abstraction", "authors": ["Milan Moss\u00e9", "Kara Schechtman", "Frederick Eberhardt", "Thomas Icard"], "abstract": "A person is directly racially discriminated against only if her race caused her worse treatment. This implies that race is an attribute sufficiently separable from other attributes to isolate its causal role. But race is embedded in a nexus of social factors that resist isolated treatment. If race is socially constructed, in what sense can it cause worse treatment? Some propose that the perception of race, rather than race itself, causes worse treatment. Others suggest that since causal models require modularity, i.e. the ability to isolate causal effects, attempts to causally model discrimination are misguided.\nThis paper addresses the problem differently. We introduce a framework for reasoning about discrimination, in which race is a high-level abstraction of lower-level features. In this framework, race can be modeled as itself causing worse treatment. Modularity is ensured by allowing assumptions about social construction to be precisely and explicitly stated, via an alignment between race and its constituents. Such assumptions can then be subjected to normative and empirical challenges, which lead to different views of when discrimination occurs. By distinguishing constitutive and causal relations, the abstraction framework pinpoints disagreements in the current literature on modeling discrimination, while preserving a precise causal account of discrimination.", "sections": [{"title": "Introduction", "content": "Direct racial discrimination against a person occurs only if she is treated worse than others in some respect, and this is explained by her race (Thomsen, 2018). When explanation is understood causally, we arrive at the notion of\nCausal Discrimination: A person is directly racially discriminated against only if she is treated worse than others, and this is caused by her race.\nThis notion of discrimination makes sense of the widespread use of audit studies, in which experimenters detect institutional discrimination using techniques that resemble randomized controlled trials. Indeed, in a now-famous correspondence study, resumes were randomly assigned Black- or white-sounding names and sent out to prospective employers. White names received 50 percent more callbacks for interviews, and callbacks were more responsive to resume quality for white names than for Black ones (Bertrand and Mullainathan, 2004). In other words, the study found that intervening on race-coded names changed interview callbacks, irrespective of resume quality; in this sense, race caused worse treatment. The causal notion of discrimination then justifies the researchers'conclusion that their study revealed racial discrimination in the labor market. This kind of audit study has become a gold standard for detecting discrimination, with social scientists undertaking increasingly larger-scaled, more ambitious, and more methodologically complex experimental designs (Gaddis, 2018).\nThe causal notion of discrimination popularized by audit studies applies equally to other protected attributes, like gender or religion, and is invoked across a wide variety of settings. For example, causal discrimination is invoked by algorithmic fairness criteria (Kilbertus et al., 2017; Kusner et al., 2017; Barocas et al., 2023), and in the U.S. law (Kohler-Hausmann, 2018), as in a recent Supreme Court decision:\nTitle VII ... prohibits employers from taking certain actions \u201cbecause of\u201d sex.\n. . . Title VII's \u201cbecause of\u201d test incorporates the \u201csimple\u201d and \u201ctraditional\u201d stan-dard of but-for causation. ... That form of causation is established whenever a particular outcome would not have happened \"but for\u201d the purported cause.\n. . . In other words, a but-for test directs us to change one thing at a time and see if the outcome changes. If it does, we have found a but-for cause. (SCOTUS, 2020)\nHere, the Court explicitly invokes the causal notion of discrimination: discrimination occurs when were sex different, the outcome would have been different as well."}, {"title": "Abstraction and discrimination", "content": "In sum, the commonsense idea that discrimination occurs only when a protected attribute causes worse treatment is invoked across the social sciences, computer science, and U.S. law. But even assuming we have settled on a theory of when and why attributes such as race and gender should be protected from discrimination (e.g. Hellman 2008; Kolodny 2023), the notion of causal discrimination is difficult to spell out in a precise and plausible way. Indeed, on the counterfactual understanding of causation (Lewis, 1973; Woodward and Hitchcock, 2003a,b; Woodward, 2005), to determine whether race caused worse treatment, we must consider whether an individual's treatment would have been worse, had their race and only their race been different; this is precisely the test suggested by audit studies, algorithmic fairness criteria, and the U.S. Supreme Court.\nHowever, it is widely held that race, as well as other attributes protected from discrimination like gender, religion, and disability, are socially constructed: they help to sustain and are influenced by social norms concerning individuals' appearance, wealth, location, education, criminal history, and more (Haslanger, 2000, 2012; Taylor, 2022; Mills, 1998). This raises the worry that there is no robust metaphysical boundary between what constitutes race (and thus should be varied, when testing racial discrimination) and what is causally distinct from race (and thus should be controlled for, when testing racial discrimination). For instance, in the resume audit study, why shouldn't an auditor vary features of individuals like educational or employment history in addition to their names, if such features are bound up in the social construction of race?\nAn influential line of recent work argues that causal models of discrimination make it impossible to give a satisfactory answer to this question, because they force us to postulate an implausible metaphysical boundary between race and the context in which it is socially embedded (Kohler-Hausmann, 2018; Hu and Kohler-Hausmann, 2020; Hu, 2022, 2024b). Race can cause worse treatment in a causal model only if its effects are modular: one can perform an intervention only on race and trace the resulting effects to race. But if race is socially constructed, it seems to straightforwardly violate this requirement of modularity: in intervening on race, one inevitably intervenes on its constituents as well. For example, because race is partly constituted by norms surrounding people's names, education, and employment history, interventions on these attributes and on race are bound up with each other. If we change someone's race from Black to white while attempting to hold fixed \u201cJamal\u201d as their name or \u201cHoward University\" as part of their educational history, the social resonance of these attributes changes; interventions on race, on names, and on education are intertwined. The modularity requirement then seems to forbid a causal model from including variables corresponding to race, names, education, and so on, when precisely such a model would be needed to explain how manipulations on names reveal effects of race in the resume audit study.\nMore generally, causal models of discrimination face a modularity problem:"}, {"title": "Introducing abstraction", "content": "Consider an experiment in which a bird is trained to peck at objects of any shade of red (Yablo, 1992; Woodward, 2021). When the bird pecks at some red object, say a crimson one, we can make two causal claims about it, at different levels of abstraction: that it pecks at the object because it is crimson, or that it pecks at an object because it is red. Each of these causal claims suggests an associated causal model, one in which perception of a fine-grained color (e.g., crimson, scarlet, cyan, turquoise) causes pecking behavior, and another in which perception of a coarse-grained color (e.g., red, blue) causes pecking behavior. Intuitively, the coarse-grained model is an abstraction of the lower-level, fine-grained one, because (a) the coarse-grained model is simpler, and (b) the models are causally equivalent: changing the color from red to blue in the coarse-grained model has the same effect as changing the color from crimson to cyan in the low-level model. As we now explain, in the framework of causal abstraction, the notion of \"simplifying a model\" is provided by a relationship between them, called an alignment, while the notion of causal equivalence is provided by a feature of alignments, called causal consistency.\nThe fine-grained and coarse-grained models are depicted in Figure 1. The high-level model contains two variables: Coarse, which represents the bird's perception of a coarse-grained color, and Pecking, which represents whether the bird pecks. The causal arrow implies that Pecking is an effect of Coarse, and thus is some function $f_{coarse}$ of Coarse, perhaps together with random noise (included to capture variation among birds' pecking behavior not explained by object color). The low-level model is almost exactly the same, except it models pecking behavior as a function of fine-grained color Fine rather than coarse color."}, {"title": "Audit studies and abstraction", "content": "These simple models already contain all of the essential features of a causal model. Indeed, recall that in a structural causal model, there are variables $V_1, V_2, V_3 . . .$, where the value of each variable V is defined by a function $f_V$ of the values of other variables. (See, e.g., Pearl 1995; Peters et al. 2017; Bareinboim et al. 2022.)\nThe relationship between the variables of the high-level and low-level causal models is captured by an alignment $\u03c4_{color}$, which provides a way of transforming variable settings in the lower-level model to variable settings in the high-level model. In this case, crimson and scarlet settings map to red settings, while cyan and turquoise settings map to blue settings. In other words, the alignment $\u03c4_{color}$ is a function which maps values of the low-level variable Fine to the values of the high-level variable Coarse.\nMore generally, consider two models $M_{low}$ and $M_{high}$. An alignment $\u03c4$ is a function which maps values of variables in the low-level model to values of variables in the high-level model. Intuitively, an alignment may be thought of as a simplification of the low-level model: it merges different values of low-level variables into individual values of high-level variables, and may ignore some low-level variables entirely (Chalupka et al., 2017; Rubenstein et al., 2017; Beckers et al., 2019; Geiger et al., 2024). So-defined, alignments are highly permissive: strictly speaking, any model can be aligned with any other. As we now explain, to define an abstraction, an alignment must also ensure that \u201cmanipulations\u201d in the low-level model and \"manipulations\" in the high-level one are \u201ccausally equivalent.\u201d We can now make the relevant notions of manipulation and causal equivalence more precise.\nFormally, the effects of manipulations are evaluated with interventions. An intervention (sometimes called a hard intervention) $do(V = v)$ on a variable V replaces its function $f_V$ with a constant function, that is a fixed value v. Because other variables may be defined as functions of V, the intervention $do(V = v)$ can percolate through the model, changing the likelihood that other variables take various values; this is the effect of the intervention.\nAn alignment establishes \u201ccausal equivalence\u201d between two models when it is causally consistent. To check whether $\u03c4_{color}$ is causally consistent, we first perform an intervention on color at the low level, and then transform the effect it has on pecking to the high level via the alignment. We then check that this has the same result as first transforming the intervention via the alignment, and then intervening at the high level. This condition is in fact met by the alignment $\u03c4_{color}$, because intervening on fine-grained color by changing it from crimson to cyan and then checking whether the bird pecks has the same result as intervening on coarse-grained color by changing it from red to blue and then checking whether the bird pecks. By mapping more general colors to corresponding more specific shades, $\u03c4_{color}$ tracks a real metaphysical relationship between a color and its many shades, to which pecking behavior is insensitive. More generally, an alignment \u05d3 between two models is causally consistent if intervening on variables in the low-level model $M_{low}$ and then aligning into the high-level model $M_{high}$ is the same as first aligning into the high-level model and intervening there. Given such an alignment, we say that $M_{high}$ is an abstraction of $M_{low}$. (See e.g. Def. 3 of Rubenstein et al. 2017 or Def. 16 of Geiger et al. 2024.)\nCausal consistency is a stringent requirement, requiring perfect correspondence between"}, {"title": "Abstraction and discrimination", "content": "low-level and high-level interventions. We introduce it for simplicity, but it can be relaxed in various ways (cf. Beckers et al. 2019; Rischel and Weichwald 2021; Geiger et al. 2024). Most simply, where the values of several lower-level variables $V_1, ...., V_n$ are aligned via \u03c4 with the values of a single high-level variable V, we can say that \u315c is approximately causally consistent if average of the effects of $V_1, ..., V_n$ on some outcome is very close to almost all of the effects of $V_1, ..., V_n$ on that outcome, taken individually.\nBecause any metaphysical relationship between two attributes that necessarily co-vary can be captured by an alignment, causal abstraction is a flexible framework. For example, it can be used to express logical relations, determinate-determinable relations, and constitutive relations. In this section, we explain how to use abstraction to capture the constitutive relations posited by a social constructionist theory of race, and then provide a formal interpretation of the causal discrimination claims tested by audit studies.\nOn a social constructionist theory of race, race is not a natural kind. Instead, it is a social kind. To belong to a certain race is to possess a collection of attributes, which may themselves be natural or social, and are fixed by a set of social norms, historical developments, identities, and other social factors associated with the race in question. In the terminology of abstraction, social constructionist theories of race posit an alignment $T_{sc}$ which specifies how an individual's race is socially constructed from all of their other attributes (Figure 2)."}, {"title": "The modularity problem", "content": "This is already a substantive modeling assumption. One might hold that it is impossible, even in principle and in a particular context, to specify how exactly race is constructed from lower-level social and natural attributes of individuals, which may include their relations to others. For example, one might claim that race, socioeconomic class, and gender are all mutually constituted by each other, rather than by a more fine-grained basis of lower-level attributes. However, we will set this possible worry aside, because (1) this claim is potentially consistent with the abstraction model, insofar as we may model race as abstracting socioeconomic status and gender in one context, and model gender as abstracting socioeconomic status and race in another; and (2) we assume that social constructionist concerns regarding the possibility of causal models of discrimination do not rest on thorough-going skepticism that a social construction of race in terms of lower-level attributes could ever be articulated in principle.\nSuppose then that a social constructionist has provided an alignment $T_{sc}$ between race and the attributes from which it is socially constructed. Because, as the social constructionist suggests, this alignment tracks a genuine metaphysical relationship, we should expect the alignment to be (at least largely) causally consistent: if the effects of race diverged greatly from those of its constituents, this would suggest that $T_{sc}$ had been misspecified. Thus the alignment $T_{sc}$ specifies an abstraction.\nThe simple assumption that race abstracts lower-level attributes in this way already licenses answers to counterfactual questions about race. For instance, it makes sense to ask what would happen were one to intervene on a person's race in a specific way. This is just to ask what would happen, were one to intervene on the lower-level attributes of an individual in such a way that their race\u2014according to the social construction of race\u2014would now be different. That is, what would happen if an individual's attributes were different, such that their alignment via $T_{sc}$ to a racial category is itself different?\nAudit studies select a strict subset of an individual's features, namely those appearing on their resume, purportedly\u201cscreening off\u201d the effects of all other attributes of the individual on the outcome. In the terminology of abstraction, this defines a second alignment $T_{audit}$, which discards any attributes not appearing on the resume and trivially aligns all attributes appearing on the resume with themselves (Figure 2). The resume is assumed to include all attributes (that is, all variables in \u201cAll attributes\") that exert a causal effect on interview status. In this way, $T_{audit}$ is by construction a \u201clossless\u201d abstraction of \u201cAll attributes\" when it comes to interview status.\nWe can use the alignments $T_{sc}$ and $T_{audit}$ to state precisely the quantity of interest in audit studies. An audit study fixes two resumes, Resume\u2081 and Resume2, which differ only in their names. Because resumes only contain a few pieces of information about an individual,"}, {"title": "The modularity problem", "content": "many different people with different attributes could possess the same resume. Where a \"person\" refers to a maximally descriptive set of attributes, let $A_1$ be the set of people with resume Resume\u2081, and let $A_2$ be the set of people with resume Resume2. (In other words, $A_1$ is the set of people that $T_{audit}$ aligns with Resume\u2081, and $A_2$ is the set of people that $T_{audit}$ aligns with Resume2.)\nThe racial compositions of $A_1$ and in $A_2$ will tend to differ, especially given that the different names appearing on the resumes Resume\u2081 and Resume2, like Greg and Jamal, are highly correlated with race. Let Race\u2081 indicate the race most common in A\u2081 and let Race2 indicate the race most common in A2. Then it follows from the assumption that isc and $T_{audit}$ are causally consistent that audit studies successfully test the causal effect of race on interview outcomes, in the following sense: the difference in interview status that results from changing Race\u2081 to Race2 is the same as the difference that results from changing A1 to A2, which is in turn the same as changing Resume\u2081 and Resume2. The necessary assumptions of causal consistency are licensed by the social constructionist theory of race that defined $T_{SC}$, and by the construction of audit studies, which screen out all attributes not on the resume via $T_{audit}$ (Figure 3)."}, {"title": "The modularity problem", "content": "there is significant under-determination and ambiguity in finding a lower-level intervention to test the effect of this change. But this is ambiguity is common feature of causal inference (Spirtes and Scheines, 2004): in saying that we changed a stimulus for the bird from red to blue, it is ambiguous whether we changed it from crimson to cyan, or from scarlet to turquoise. Causal consistency guarantees that all such changes produce the same pattern of changes in outcome. Thus, to the extent that we have causal consistency in a diagram like Figure 3, there is a clear and principled sense in which audit studies can be modeled as testing the effect of interventions on race. More generally, one can model claims about causal discrimination as claims about the effects of race, understood as an abstraction of lower-level, in-principle manipulable attributes.\nIt is sometimes objected that structural causal models cannot accommodate constitutive relations, because constitutive relations lack the directionality characteristic of causal relationships (Hu and Kohler-Hausmann, 2020, p.5). As the above diagram illustrates, this objection can be overcome using abstraction. One might argue that the specified alignments do not commute with the intervention performed by audit studies, and thus that the crucial assumption of causal consistency fails to hold even approximately; we return to this worry below, in Section 4.1. However, we show in the next section that given this assumption, the abstraction model straightforwardly addresses the modularity problem."}, {"title": "The modularity problem", "content": "In this section, we explain the modularity requirement and the modularity problem for causal models of discrimination. We then explain how the abstraction model of discrimination addresses this problem and compare this model to some alternatives."}, {"title": "The modularity requirement", "content": "In structural causal models, X causes Y when changes in X lead to changes in Y. For instance, to determine if there is a causal relationship between object color and pecking behavior, we could try intervening on each independently, and seeing which intervention"}, {"title": "The modularity problem", "content": "leads to a change in the other variable. In this case, we would observe that changing the color of an object (for instance, by painting it) leads to a change in bird's pecking behavior, but that changing the bird's pecking behavior (for instance, by bribing the bird with a treat) does not magically change the object's color. We thus conclude that the object's color causes pecking behavior and not the other way around.\nTo allow for these kinds of interventions on individual variables, structural causal models must satisfy a modularity requirement (see, e.g., Pearl (2000), p. 63; Woodward (2005),p.327; Peters et al. (2017), pp.17-20, point 1). A variable in a causal model is modular when it can be intervened upon independently from intervening on the others, and a causal model is modular when all its variables are modular.\nFor example, a causal model which implies that object color causes bird pecking behavior is modular because it is possible to conceive of interventions on each of the two variables that do not act on the other. If we paint an object blue, we perform an intervention that directly changes just that object's color, not whether the bird is wont to peck at blue objects. As a result, any effects of this intervention demonstrate the causal relationship between object color and bird pecking behavior.\nWithout modularity, the causal effects of an intervention on a variable are hopelessly conflated with the intervention itself. Consider, for instance, a causal model claiming that the coarse color of an object causes its particular fine shade. This model is non-modular because it is conceptually impossible to manipulate the color of an object separately from intervening on its particular shade (and often, vice versa). How could we change the color of an object from red to blue, without changing it from some shade of red to some shade of blue? Since actions on fine shades and coarse colors and are muddled together, we cannot isolate a causal effect of the intervention."}, {"title": "The modularity problem", "content": "Return to the resume audit study, in which experimenters aim to establish a causal effect of race on interview decisions by performing manipulations on race-coded names. To support reasoning about whether race (via manipulations on names) causes interview callbacks, we should be able to represent the audit study using a causal model with variables corresponding to race, name, and interview callback status. This causal model must include names and interview callbacks to represent the causal effect of name interventions on interview callbacks performed by the audit study, and it must include race to explain (by reference to some property of the causal model) how this name manipulation reveals an effect of race.\nThe modularity problem, developed by Lily Hu and Issa Kohler-Hausmann (Kohler-Hausmann (2018); Hu and Kohler-Hausmann (2020); Hu (2022)), is that protected attributes like race, gender, and religion cannot be placed in a single causal model with the attributes from which they are socially constructed, because their constitutive relations violate the mod-"}, {"title": "Abstraction as a solution to the modularity problem", "content": "ularity requirement. In the case of audit studies, the problem is that race, names, and interview callback status cannot be placed in a single structural causal model without violating the modularity assumption crucial to causal modeling and inference. The worry is that these three variables interact more like colors and their more specific shades than like bird pecking behavior and object colors; models including all three variables inevitably end up non-modular.\nThe problem is easiest to see if we accept that race is a social construction, and thus stands in constitutive rather than causal relations to many of its correlates. For then certain names constitute part of the social meaning of race, and thus race itself. For instance, Black-sounding names like \u2018Jamal' form part of the social meaning of what it is to be Black. As a result, an intervention setting a name of an applicant on a resume to Jamal cannot, in principle, be separated from an intervention to their race, and vice versa. Thus, placing race and names in a causal model together as formalizations of audit studies do, to justify using an intervention on names to reveal an effect of race requires making a false modularity assumption that names do not partially constitute race. This problem arises for any attributes that appear on a resume, like education or employment history, which partly constitute race.\nThe abstraction model of discrimination straightforwardly addresses the modularity problem. Because protected attributes and their constituents are placed in separate causal models, and modularity need only hold within each model taken separately, there is no non-modularity within either the high-level model containing race or the low-level model containing its constituents. Audit studies can be understood as testing the causal effects of race, by testing the effects of its constituents, as defined by a causally consistent alignment. The relationship specified by this alignment is non-modular, in the sense that changes to names correspond to changes in race, but this is a benign (indeed intended and necessary) feature of causally consistent alignments, not an obstacle to causal modeling: when one attribute is simply a higher-level abstraction of other, lower-level attributes, one should expect changes at either level to correspond to changes at the other."}, {"title": "Intervention identification", "content": "We have argued that the framework of causal abstraction provides a natural way of capturing the constitutive relations between race and the attributes from which it is socially constructed (Section 2) and that this framework straightforwardly addresses the modularity problem raised for causal models of discrimination (Section 3).\nHowever, there remains the intervention identification problem of explaining when and why interventions reveal causal effects of a social kind normatively relevant to discrimination. To illustrate, consider the following examples:"}, {"title": "Two challenges of intervention identification", "content": "We can now use the framework of causal abstraction to distinguish two challenges to the claim that by intervening on names, audit studies reveal an effect that is normatively significant and a sign of discrimination.\nConsider, first, a set of challenges associated with defining the alignment and high-level model. Of course, there is the question of how to decide what features belong in the constitutive basis of race. But there are further challenges in defining the effect of race in the high level model. For example, how should one define the equation that underlies the arrow Race \u2192 Interview in figure 3, given that interventions on race are ambiguous between lower-level interventions on its many constituents (Hu, 2022, pp. 102-103)? Even if the changes to the names on resumes performed in audit studies correspond, via the relevant alignments, to change in races, there are many such changes. Changing university from \u201cHarvard\u201d to \u201cHoward,\u201d for example, would typically also change the race most likely associated with a given resume (Figure 4; Hu (2022), pp. 91-93)."}, {"title": "Intervention identification and experimental design", "content": "As suggested in Section 2.1, once we relax the stringent requirement of causal consistency, and allow that the effect of race on interview status is some complex function of the varying effects of many different lower-level changes, interventions at the high-level become ambiguous (cf. Tolbert 2024a, pp. 1103-5). We thus face the difficult task of aggregating those low-level contrasts into one higher-level effect. Because we are essentially asking to what extent differential treatment on the basis of race-coded names fully captures discrimination on the basis of race, this function, like the social constructionist alignment tsc, will need to be informed by our understanding of the normative significance of discrimination. Similarly, even once we determine how to define the high-level functional equations, whether an alignment is causally consistent \u201cenough\u201d is partly a normative question. For instance, to have a theory of race that is explanatory across a wider variety of contexts, or one that employs fewer high-level categories, we might have to relax causal consistency further. It is an open question whether a metaphysically plausible alignment between race and its constituents can deliver cross-contextual causal consistency, even approximately.\nSuppose, however, that the problem of ambiguity is addressed, and that we have defined the effects of race as some complex function of the effects of its lower-level constituents. Then to the extent that alignment is causally consistent, we could rest assured that audit studies revealed an effect of race, i.e. that we acquire information about (1) via (2):\nP[Interview Callback | do(Race\u2081)] \u2013 P[Interview Callback | do(Race\u2082)]\nP[Interview Callback | do(Resume\u2081)] \u2013 P[Interview Callback | do(Resume\u2082)]."}, {"title": "Intervention identification and experimental design", "content": "In other words, audit studies would then provide information about the result of intervening on race, by intervening on resumes.\nEven when this assumption is granted, there remains a second question about why the interventional difference (2) is normatively relevant. For instance, in the resume audit study, the populations corresponding to the resumes used in the study may be atypical, insofar as there is no guarantee that when one changes \"Greg\" to \"Jamal\" on a resume, one moves from a representative population of white people to a representative population of Black people (Figure 5). In fact, either of these populations could be completely empty. If the resumes created by audit studies are highly atypical, it is unclear how they could shed light on a normatively salient population; the interventions performed by audit studies would simply be \"strange\u201d (Hu and Kohler-Hausmann (2020), p. 10).\nShort of a requirement that we do not compare completely empty populations, normative relevance does not always require typicality. For instance, in the resume audit study, an auditor who believes Black students who attended majority-white schools should receive"}, {"title": "Intervention identification and experimental design", "content": "similar job opportunities as compared to white students who attended those schools might decide that the causal contrast between these populations is relevant, even if the former population is \u201catypical.\u201d However, this choice of a causal contrast is based on a normative assumption that these populations deserve similar treatment, and the ability of an audit study to demonstrate discrimination depends on the strength of the argument for that assumption. Likewise, concluding from the absence of such an interventional difference that there is not discrimination requires a normative assumption that there are not other contrasts that are normatively relevant\u2014for instance, contrasts corresponding to populations reflective of differences in the schools typically attended by Black and white students.\nThere are thus at least two basic assumptions needed for audit studies to reveal the presence of a discriminatory causal effect of race:\n(i) There must exist an alignment between race and lower-level constituents, which is approximately causally consistent, such that testing effects of race-coded names provides information about the effects of race.\n(ii) The interventional quantities revealed by audit studies must correspond to race subpopulations which are normatively relevant. For instance, a racial subpopulation might be relevant because they are in some sense \u201ctypical\u201d for that race; or they may be \u201catypical\" but have features of normative relevance to expectations of similar treatment.\nStated explicitly and precisely, these assumptions can be subjected to further normative and empirical challenges, and we make no claim to have defended them. However, we propose that these further debates target particular modeling assumptions, which can be stated within the framework of causal abstraction; they are not objections to causal models of discrimination as such."}, {"title": "Intervention identification and experimental design", "content": "We now illustrate how different responses to the above challenges lead to differences in experimental design. Recall the in-person audit study, in which trained actors of different genders attend a job interview, presenting identical resumes and answering interview questions identically. An experimenter must determine whether to match or experimentally vary the appearances and mannerisms of actors of different genders for instance, whether they are wearing a dress or a suit, whether or not they wear makeup, or how assertive they are. When audit studies are modeled using the Single-Level Assumption, experimental designs must always be licensed by different modularity assumptions. Any features of individuals that experimenters vary are treated as \u201cpart of\u201d gender, while any feature they keep constant is treated as \u201cseparate from\u201d gender, and placed in the causal diagram subject to a modularity assumption. When a variable is modular with respect to gender, it cannot be partially constitutive of it. Thus, different interventions correspond to different assumptions about how gender is socially constructed (Hu, 2022, pp. 103-104).\nHowever, this tight connection between assumptions about the social construction of gender and an audit study's choice of an intervention can lead to implausible and normatively undesirable assumptions about the constitution of gender by the auditor's own lights (Hu,"}, {"title": "Intervention identification and experimental design", "content": "2022, pp. 104-106). Suppose an auditor designs a causal test of gender discrimination looking at differences in treatment between gender-nonconforming men and gender-conforming women. To vary gender-conformity across applicants, both applicants wear skirts. This implies, on the Single-level Assumption, that dress is modular with respect to gender. But this modularity assumption is strange in light of an underlying motivation of the experiment, namely that there are highly gendered standards about dress (which would suggest that dress partially constitutes gender).\nOn the abstraction picture, by contrast, we can interpret the auditor's choice of intervention as coming down not just to (i) assumptions about the constitution of gender, but (ii) which choices of intervention select normatively relevant populations for similar treatment. The auditor running a study about gender-nonconforming job applicants can include dress in their abstraction, corresponding to their understanding that standards of dress are gendered. They then select an intervention that compares women wearing skirts and men wearing skirts, corresponding to the normatively relevant comparison of treatment for gender-conforming women and gender-nonconforming men. Their choice of intervention, then, is made in light of how dress constitutes gender, rather than by excluding dress from the constitution of gender.\nOf course, on the abstraction model, it is still possible for the crux of an intervention identification to rest on (i) what attributes constitute gender. Bostock vs. Clayton provides one example. Should we vary the individual's sexual orientation to test for gender discrimination, or just vary biological sex and hold orientation fixed?\nThe former approach, which varies the individual's sex but not that of their partner, does not require a distinction between gender conformity and non-conformity in the model of gender, and indeed the dissents in SCOTUS (2020) are motivated by the view that effects of sexual orientation do not constitute effects of gender. By contrast, on the latter approach, the high-level model in the abstraction might possess a single variable with four possible values: gender-conforming man, gender-conforming woman, gender-nonconforming man, and gender-nonconforming woman. The lower-level attribute of possessing a same-sex partner would then be aligned with gender-nonconformity, so varying sexual orientation is a way of intervening on gender (from gender-conforming man to gender-nonconforming man). Many social constructionist theories of gender indeed intend to highlight norms punishing non-conformity (cf. Kohler-Hausmann and Dembroff (2022), pp.88-89). Such modeling"}, {"title": "Two notions of causal discrimination", "content": "choices might be further justified, in part, by considerations of causal consistency; if gender-conforming and gender non-conforming men are in fact treated very differently, then without such a high-level distinction, the abstraction will not be very causally consistent, combining groups that are treated very differently together.\nIn summary, the causal abstraction framework distinguishes a number of assumptions pivotal to the identification of an intervention. While the choice to vary a certain attribute commits"}]}