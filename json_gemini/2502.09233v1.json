{"title": "Commonsense Reasoning-Aided Autonomous Vehicle Systems", "authors": ["Keegan Kimbrell"], "abstract": "Autonomous Vehicle (AV) systems have been developed with a strong reliance on machine learning\ntechniques. While machine learning approaches, such as deep learning, are extremely effective at\ntasks that involve observation and classification, they struggle when it comes to performing higher\nlevel reasoning about situations on the road. This research involves incorporating commonsense\nreasoning models that use image data to improve AV systems. This will allow AV systems to perform\nmore accurate reasoning while also making them more adjustable, explainable, and ethical. This\npaper will discuss the findings so far and motivate its direction going forward.", "sections": [{"title": "Introduction", "content": "For both academic and industry research, AV technology has seen incredible advances since the intro-\nduction of computer vision-focused systems in the 1980's [3]. Here, this paper will provide some formal\ndefinitions for autonomous vehicles that it will use throughout this writing. SAE International defines\nautonomous vehicles into six different levels based on the level of automation, with level 0 being no au-\ntomation and level 5 being full driving automation [6]. Despite AV research being a well-explored field,\nthere are still no level 5, or fully autonomous, vehicles. This is largely due to imperfections in computer\nvision systems and the complexity of more complicated driving tasks that require a human driver to be\npresent. For a safety-critical system, such as AV systems, minor mistakes cannot be afforded. To this end,\nit is important that the AV system can make safe and rational decisions based on accurate interpretations\nabout its surroundings.\nThere are several technologies that are used in the perception side of AV systems, such as Light\nDetection and Ranging (LiDAR) systems and camera-based systems. These systems are coupled with\ndeep learning techniques such as Convolutional Neural Networks (CNNs), which are used to classify\nsensor data [14]. However, like all machine learning systems, it is always possible for misclassifications\nto occur due to noise, scenarios outside of the training data, degradation of sensing equipment, and other\nexternal factors. Because of this, AV systems should move towards using a hybrid AI system, or AI that\ncombines deep learning with logical reasoning, to help mitigate the failures and shortcomings of solely\ndeep learning-based approaches.\nThere are two types of systematic thinking proposed by Kahneman in 2011 [11]. The first is \"System\n1\", which is fast, instinctive, and emotional thinking. The second is \"System 2\u201d, which is slow, delibera-\ntive, and logical. For a human driver, we use both systems when we are in a driving scenario. Identifying\nobjects around us and minor driving actions are done quickly using System 1 thinking. However, when\nwe encounter an unfamiliar or dangerous scenario, we use System 2 thinking to determine a safe way\nto navigate the situation. In an optimal hybrid AV system, fast System 1 tasks such as perception and\nclassification should be handled by deep learning, and slow System 2 tasks should be handled by com-\nmonsense reasoning. The reasoning system can also be used to perform a more deliberative analysis of"}, {"title": "Related Work", "content": "There have been many other works that incorporate symbolic reasoning into deep learning, computer\nvision, and autonomous vehicle models. Suchan et al. explore commonsense reasoning-based ap-\nproaches such as an integrated neurosymbolic online abduction vision and semantics-based approach\nfor autonomous driving [17, 16]. These techniques are primarily focused on integrating with the percep-\ntion model using answer set programming (ASP), a nonmonotonic reasoning system using stable models\n[9, 13]. While their framework is similar, this approach is more decoupled from the vision models,\nallowing us to show improvements on existing AV models.\nNeurosymbolic AI, AIs that integrate symbolic and neural network-based approaches [10]s, have\nbeen applied towards autonomous driving as well. For safety-critical systems, such as autonomous\ndriving, neurosymbolic techniques can improve compliance with guidelines and safety constraints [15].\nAnderson et al. propose a neurosymbolic framework that incorporates symbolic policies with a deep\nreinforcement learning model [1]. They assert that this approach can improve the safety of reinforce-\nment learning approaches in safety-critical domains, including autonomous vehicles. These systems\nare related to this research in the sense that both are using symbolic methods to improve existing deep\nlearning-based systems. However, this research is different in that it is using commonsense reasoning\nas the proposed symbolic model and that, while it is being used to improve on a deep learning model, it\nis a different layer that is generated separately. While autonomous vehicles and computer vision tech-\nnologies are primarily deep learning-based, this approach could be used to improve upon reinforcement\nlearning-based, other non-neural machine learning-based, or even search-based vehicles.\nA framework created earlier, AUTO-DISCERN [12], proposes a goal-directed commonsense rea-\nsoning ASP system that makes driving decisions based on the observations of the environment. This\nresearch is an extension of this approach by creating a commonsense reasoning model that makes safe"}, {"title": "Research Goals", "content": "The major goal of creating an AV system of higher level autonomy using commonsense reasoning can\nbe broken down into various tasks relating to where in the AV system we inject the reasoning:\n\u2022 Perception and Classification: Use commonsense reasoning and knowledge to model the sensor\ndata and optimize the classifications. We can also inject commonsense reasoning into the training\nprocess itself to create a more connected and explainable model.\n\u2022 Safe Decision Making: We can model rules for the AV system so that it will always make intelli-\ngent and safe decisions that still move it towards its desired goal. This is important for making an\nethical system that complies with traffic laws.\n\u2022 Complicated Tasks: Complicated tasks may be outside of the training data for an AV system,\nsuch as navigating a road after the results of a hurricane. We can create reasoning models that can\nhandle multiple unknown scenarios safely. Furthermore, it is easier to model these niche scenarios\nusing reasoning since there is often a strong bias against such scenarios in the existing training\ndata for AV systems, and they are difficult to capture using just deep learning.\nEach of these tasks separately will improve the effectiveness of future AV systems, and if success is\nfound in each task, then they can be combined to create an autonomous vehicle with a higher level of\nautonomy than existing systems."}, {"title": "Preliminary Results", "content": "The current focus of these recent experiments has been using commonsense reasoning and knowledge to\noptimize the classifications of the computer vision model through consistency checking (first and second\ntasks). The system uses a Prolog [5] commonsense reasoning model to check if the classifications being\nmade by the computer vision model are consistent with each other, particularly if the behavior of nearby\nvehicles is consistent with the current road scenario. For example, if a traffic light at an intersection\nis red, then vehicles in that lane should be stopped. We define the group actions of nearby vehicles\nas collective behaviors. If the rules about the collective behaviors are not consistent with the observed\nobjects, then the system adjusts the classifications of objects around the AV system to fix the scenario.\nThis system emulates the human process of reasoning about a road situation by observing surrounding\nvehicles. In this approach, we test over misclassified traffic light colors and unobserved road obstacles.\nTo accomplish this, the system takes objects from the computer vision model's output and converts\nthem into facts. For example, the following facts represent the information about nearby vehicles and\nintersections:\nproperty (vehicle, Frame, Object_id,\nAction, VelocityX, VelocityY, Rotation,\nCoordinate1X, Coordinately,\nCoordinate2X, Coordinate2Y).\nproperty(intersection, Frame, Object_id,\nCoordinate1X, Coordinately,"}, {"title": "Conclusion and Future Work", "content": "While a lot of progress has been made in research for AV technology, we are still far away from achieving\na fully autonomous vehicle. This is because of an overreliance on deep learning techniques. Proposed\nhere is a pipeline towards a fully autonomous vehicle by incorporating commonsense reasoning into\nvarious aspects of the AV system. The results so far demonstrate the effectiveness of this approach.\nThis work will be extended by exploring new techniques to improve the applicability and efficiency of\nthis approach. This approach can be improved with evaluations from real-world datasets, such as KITTI\nor NuScenes [8, 4], the use of more powerful logic technologies, such as answer set programming, and\nthe exploration of efficient ways to construct and invoke commonsense reasoning models. It will also\nbenefit from the consideration of new ways to combine commonsense reasoning into AV systems, such\nas employing more neurosymbolic-based methods like injecting commonsense into the training of the\ndeep learning model.\nGoing forward, the techniques shown for autonomous vehicles can be applied to other domains."}]}