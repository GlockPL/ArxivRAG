{"title": "Automated Computational Energy Minimization of ML Algorithms using Constrained Bayesian Optimization", "authors": ["Pallavi Mitra", "Felix Biessmann"], "abstract": "Bayesian optimization (BO) is an efficient framework for optimization of black-box objectives when function evaluations are costly and gradient information is not easily accessible. BO has been successfully applied to automate the task of hyperparameter optimization (HPO) in machine learning (ML) models with the primary objective of optimizing predictive performance on held-out data. In recent years, however, with ever-growing model sizes, the energy cost associated with model training has become an important factor for ML applications. Here we evaluate Constrained Bayesian Optimization (CBO) with the primary objective of minimizing energy consumption and subject to the constraint that the generalization performance is above some threshold. We evaluate our approach on regression and classification tasks and demonstrate that CBO achieves lower energy consumption without compromising the predictive performance of ML models.", "sections": [{"title": "1 Introduction", "content": "Energy consumption is one of the essential topics in the development of diverse engineering fields including industrial processes, buildings, farms, vehicles, etc. Estimating energy usage is helpful for policymakers to undertake decisions to reduce consumption, if necessary. In computer architecture research, optimal energy utilization has been researched for decades, to improve the efficiency of state-of-the-art processors [1]. However, the centre of attention in machine learning (ML) research has been the accuracy of models without the consideration of energy consumption as an essential factor [2]. With the growing complexity and energy demands of ML models, promoting computationally efficient algorithms oriented ML research is of prime importance. Therefore, to secure a more scalable and sustainable future, researchers need to focus more on this area and develop new tools to estimate and optimize energy consumption.\nThe computational cost of training ML algorithms is doubling in each 3.5-months [3], which has a direct impact on the consumed energy. Leaving aside"}, {"title": "2 Related Work", "content": "There is a growing body of literature on optimization of the energy efficiency of ML models, focusing mainly on deep neural networks [11]s and in particular convolutional neural networks [12]. Often the goal is to reduce the model size in order make these smaller models applicable on small devices [13]. Although those models are very efficient for computing optimized energy consumption, there are a few limitations of this work:\n1. focus on specific model classes (neural networks) or tasks (object recognition)\n2. energy consumption is only optimized for inference, not model training\n3. predictive performance is often compromised\nAn alternative and more generic approach optimize energy consumption is BO [14]. It has been used to optimize energy consumption for neural networks [15], but it can be applied in more generic settings, especially when combining objectives with additional constraints. Constrained BO (CBO) has been applied in ML application areas ranging from topic modelling, HPO of neural networks in a memory constraint scenario [16] to locality-sensitive hashing for nearest neighbor search [17]."}, {"title": "3 Methods", "content": "The primary goal of this work is to minimize the computational energy consumption by ML tasks at the application level, subject to error or accuracy constraints. Here the energy consumption can be computed by considering algorithmic characteristics of the algorithm, such as several hyperparameters. Energy is defined as the power integral over a span of consumed time. Thus, for a constant power resource, the only variable is consumed time and for simplicity we re-frame the problem to minimization of run time consumption. We define an objective function\n$\\min f(x)$\n(1)\nwhere (x) is the time consumed for training an ML model on a fixed dataset\nand model class with a set of hyperparameters, here denoted x. As we also want\nthe ML model to meet a specified predictive performance we add a constraint\nfunction:\n$C_c(x) \\geq C_o$\n(2)\nfor a classification task (without loss of generality we assume accuracy as the\nclassification metric here) and\n$C_r(x) \\leq C_o$\n(3)\nfor a regression task (we assume mean squared error as metric). Let co be a base-\nline predictive performance that can be obtained from service level agreements\n(in a business use case) or competitor models for benchmark tasks."}, {"title": "3.1 Choice of Surrogate Model", "content": "Following [10] we chose a Gaussian Process (GP) with Mat\u00e9rn 5/2 kernel to model both objective function and constraint function with independent GPs. As f(x) is measure of time, it is always positive for all values of x. Therefore it can not be well modelled by GP. To get both positive and negative samples, we define f(x) as f(x) = log(x) \u2013 log \u028a. Here, \u03c4(x) is the consumed time by the algorithm during training for a particular set of hyperparameters and log \u028a is the amount of consumed time by the same algorithm to train on the same dataset for the default hyperparameter setting. Similarly c(x) i.e. the error metric for regression models or accuracy metric for classification models are always positive for all values of x. Therefore, to be modelled well by GP, c(x) is defined as:\nc(x) = log cr(x) \u2013 log cro, for regression models and c(x) = log cco \u2013 log ce(x), for classification models. Here, cr(x) is the training mse of a regression model on a given dataset and cro is the maximum training mse of this model with default hyperparameter setting on the same dataset. c(x) is the training accuracy of a classification model on a given dataset and ceo is the minimum training accuracy of this model with default hyperparameter setting on the same dataset. Now the GP prior can be placed on both f(x) and c(x)."}, {"title": "3.2 Choice of Acquisition Functions", "content": "The acquisition function chosen for the objective function is Expected Improvement (EI) [18]. For the constraint function, a second acquisition function Probability of Feasibility (PoF) [19] has been chosen. Here we use a joint acquisition function which is a product of EI and PoF. Therefore, the feasible regions for a sampling of the next point of the given CBO will be learnt jointly with the optimal regions of both EI and PoF. The joint acquisition function ensures that the constraint's feasibility is considered when making a decision for optimality."}, {"title": "3.3 Transformation of Unconstrained to Constrained Method", "content": "To transform the unconstrained BO to a constrained method for comparison, a quadratic penalty function has been incorporated as suggested in [20]. This penalty indirectly affects the acquisition function by applying a penalty to the primary objective:\n$f'(x) = f(x) + \\frac{1}{2\\rho} \\max(0, c(x))^2$\n(4)\nWhere f(x) is the objective function of unconstrained BO and p controls the strength of the penalty\u00b9. When c(x) \u2264 0, the constraint function is valid and the penalty term will be zero and it doesn't affect the objective function. But when the constraint is violated, a positive penalty is added to the objective function."}, {"title": "4 Experiments & Results", "content": "We optimize the hyperparameters of a number of standard regression models (Lasso, Elastic Net, K Nearest Neighbour, Decision Tree, AdaBoost) and classification models (Ridge, Logistic Regression, K Nearest Neighbour, Random Forest). The primary objective was minimization of computational time subject to the performance metric constraint. Two large datasets were used, California-Housing [21] for regression models and 20-Newsgroups [22] for classification models. We compare the CBO approach with above mentioned unconstrained BO with penalty term (see 4). The results are shown in Fig. 1 & Fig. 2 for regression and classification model respectively. The results of other selected models are given in Appendix Results from Fig.3 - Fig.9. In Appendix Results, Table 2. &\nTable 3. depict the amount of predictive performance violation by unconstrained BO and comparison with CBO.\nIt is evident from the results that Unconstrained BO achieves the minimum value of the objective function in most of the cases. But in those cases, the performance constraint is violated, which lead to adding a huge penalty term to the objective function. Hence, CBO achieves the minimum objective function value while maintaining the constraint and outperforms the Unconstrained BO with penalty in all tasks."}, {"title": "5 Conclusion", "content": "Bayesian Optimization has become a standard technique to automatically select hyperparameters for ML workloads. With increasing model and data set sizes, energy consumption of ML training workloads becomes increasingly important. Here we compared constrained Bayesian Optimization with penalized Bayesian Optimization for automatically selecting hyperparameters of ML models in classification and regression settings such that the energy consumption, measured as wallclock runtime, is minimized while the predictive performance meets a predefined threshold.\nOur results demonstrate that constrained BO can help to find more energy efficient models and hyperparameter candidates that meet a predefined constraint on predictive performance compared to penalized BO. This highlights the potential of CBO for modern ML applications with high capacity models and large data sets. One of the limitations of this work are that we assume a predefined threshold for the predictive accuracy. In some cases this is a reasonable asssumption. But there are cases when the default hyperparameters of a ML model are suboptimal. However jointly modelling the acquisition function is useful also in settings where the predictive performance is minimized along with the energy consumption.\nAnother limitation is that the surrogate model GPs for energy consumption and predictive performance are modelled independently. This is a simplifying assumption and in many cases the choice of hyperparameters, such as preprocessing settings of the data, the regularization parameter or neural network architecture choices, have a strong impact on the energy consumption and the predictive performance at the same time. In future work we aim at exploring acquisition functions that are able to take these dependencies into account."}]}