{"title": "Are Large-Language Models Graph Algorithmic Reasoners?", "authors": ["Alexander K. Taylor", "Anthony Cuturrufo", "Vishal Yathish", "Mingyu Derek Ma", "Wei Wang"], "abstract": "We seek to address a core challenge facing current Large Language Models (LLMs). LLMs have demonstrated superior performance in many tasks, yet continue to struggle with reasoning problems on explicit graphs that require multiple steps. We introduce a novel benchmark designed to evaluate LLM performance on classical algorithmic reasoning tasks on explicit graphs to address this gap. Our benchmark encompasses five fundamental algorithms: Breadth-First Search (BFS) and Depth-First Search (DFS) for connectivity, Dijkstra's algorithm and Floyd-Warshall algorithm for all nodes shortest path, and Prim's Minimum Spanning Tree (MST-Prim's) algorithm. Through extensive experimentation, we assess the capabilities of state-of-the-art LLMs in executing these algorithms step-by-step and systematically evaluate their performance at each stage. Our findings highlight the persistent challenges LLMs face in this domain and underscore the necessity for advanced prompting techniques and algorithmic instruction to enhance their graph reasoning abilities. This work presents MAGMA, the first comprehensive benchmark focused on LLMs completing classical graph algorithms, and provides a critical step toward understanding and improving their structured problem-solving skills (Code: https://github.com/ataylor24/MAGMA).", "sections": [{"title": "Introduction", "content": "In recent years, large language models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing tasks. Despite these advances, LLMs continue to exhibit significant limitations in solving multistep reasoning problems as the available context increases. These limitations necessitate the development of problem sets designed to help LLMs learn to solve problems correctly across multiple solution steps.\nGraph-reasoning tasks provide a compelling area for evaluating multistep reasoning abilities due to their reliance on structured, ordered steps for accurate solutions. Recent works exploring LLM performance on graph-reasoning tasks flatten multistep problems to only the problem statement and the final solution query, and use only the final step solution to evaluate the model, as exemplified in Figure 1 (Liu and Wu, 2023; Wang et al., 2023; Zhang et al., 2023; Agrawal et al., 2024; Ge et al., 2024; McLeish et al., 2024; Markeeva et al., 2024). This simplification, while convenient for evaluation, overlooks the intermediate reasoning steps that reveal the model's understanding of each problem segment and its progression toward the final answer. For instance, when computing the shortest path in Dijkstra's algorithm, intermediate steps involve checking and updating node distances based on edge weights. Focusing on these steps provides critical insights into the model's comprehension and logical progression, enhancing both training and evaluation.\nTraining models to correctly identify and solve sub-problems has applications in fields such as AI for scientific discovery, where stepwise reasoning is essential. Therefore, exploring intermediate steps in graph reasoning tasks is valuable not only for assessing models' problem-solving capacity, but also for applications requiring systematic and logical problem breakdowns.\nIn this work, we aim to demonstrate that incor-"}, {"title": "Related Works", "content": "Algorithmic Reasoning\nMany prior works have explored the application of machine learning to classic computer science algorithms (Graves et al., 2016; Xu et al., 2019; Reed and De Freitas, 2015; Vinyals et al., 2015; Bello et al., 2016; Kool et al., 2018; Selsam et al., 2018; Selsam and Bj\u00f8rner, 2019; Yoon et al., 2018; Bronstein et al., 2017; Hamilton et al., 2017; Battaglia et al., 2018; Li et al., 2015; Kipf and Welling, 2016; Gilmer et al., 2017; Deac et al., 2021; Velickovic and Blundell, 2021; Xhonneux et al., 2021; Ibarz et al., 2022; Numeroso et al., 2023; Veli\u010dkovi\u0107 et al., 2022). (Velickovic and Blundell, 2021) introduced the use of intermediate steps in addition to ground-truth solutions to guide learning, both for ease of optimization and to constrain the freedom of the model in finding the solution. This led to multiple works using inter.mediate steps to improve algorithmic reasoning performance for both single and multi-algorithm task settings. (Deac et al., 2021; Xhonneux et al., 2021; Numeroso et al., 2023). Lastly, the CLRS Algorithmic Reasoning benchmark was constructed for algorithmic reasoning on GNNs and established standards for GNN performance for 30 algorithms in single and multi-algorithm settings (Veli\u010dkovi\u0107 et al., 2022; Ibarz et al., 2022). We adapt the graph and algorithmic trajectory generation from the CLRS benchmark for use in the MAGMA Benchmark to improve the reasoning capabilities of LLMs on the full set of solutions for graph problems and allow for future comparison of LLMs to GNNs on algorithmic reasoning."}, {"title": "Graph Reasoning Tasks with LLMs", "content": "Applying large language models to graph reasoning tasks is an emerging research area that has made significant strides in recent years Li et al. (2024); Zhao et al. (2023); Guo et al. (2023); Liu and Wu (2023); Wang et al. (2023); Zhang et al. (2023); Agrawal et al. (2024); Ge et al. (2024). We focus on works in which LLMs are used as predictors in reasoning tasks involving set and graph operations, as defined in Chen et al. (2023). Most approaches frame the objective as identifying paths or substructures within graphs and do not specify an algorithm or set of required steps to adhere to in the reasoning process (Liu and Wu, 2023; Wang et al., 2023; Zhang et al., 2023; Agrawal et al., 2024; Ge et al., 2024). Prior works that do include specific algorithms in their prompts only evaluate the final solution step (Wang et al.; Liu and Wu, 2023; Ge et al., 2024; Markeeva et al., 2024; McLeish et al., 2024).\nThese studies seek to address a known weakness in current state-of-the-art LLMs regarding algorithmic reasoning tasks on graph data. However, these works formulate algorithmic reasoning as a one-step question-answering task, which does not consider the intermediate reasoning steps followed by an execution of the algorithm. Our work aims to fill this gap by constructing step-by-step executions of each algorithm in a chat format, which provides training data better suited to multistep reasoning tasks."}, {"title": "Benchmark Construction", "content": "The MAGMA Benchmark consists of step-by-step graph algorithm executions on explicit graphs in natural language for the following algorithms: BFS, DFS, Dijkstra, Floyd-Warshall, and MST-Prim. We leverage the framework established in the CLRS benchmark to sample graphs and construct algorithm trajectories to translate into natural language."}, {"title": "Adapting the CLRS Benchmark", "content": "Algorithm Selection\nWe select a subset of the available graph algorithms from the CLRS Benchmark for inclusion in the MAGMA Benchmark.\n\u2022 Breadth-First Search: standard example of a simple algorithm (for humans), and thus included in many algorithmic reasoning works (Velickovic and Blundell, 2021; Xhonneux et al., 2021; Ibarz et al., 2022; Veli\u010dkovi\u0107 et al., 2022; Liu and Wu, 2023; Wang et al., 2023; Ge et al., 2024).\n\u2022 Depth-First Search: shown to be quite challenging for neural algorithmic reasoning approaches on the CLRS benchmark (Velickovic"}, {"title": "Prompt Reasoning Strategies", "content": "We construct the dataset for the MAGMA Benchmark with the goal of using a diverse subset of the graph algorithms covered in the CLRS benchmark to stress test LLMs on multistep graph reasoning problems. We provide three prompt reasoning strategies for fine-tuned models in the MAGMA Benchmark (see Figure 3):\n\u2022 Input-Output (IO): Trajectory consists of one prompt, which presents the problem statement and the query for the final step solution (Besta et al., 2024).\n\u2022 Intermediate Steps (IS): Trajectory consists of one or more prompts, of which the first presents the problem statement and queries for the next intermediate solution, which may be the final step output.\n\u2022 Intermediate Steps with Hints (ISH): Similar to IS, however, intermediate prompts contain selected CLRS hints in addition to the intermediate solution query.\nFollowing prior works, the Intermediate Steps and Intermediate Steps with Hints formats use teacher forcing while fine-tuning (Velickovic and Blundell, 2021; Veli\u010dkovi\u0107 et al., 2022). The evaluation task is structured as a series of chats in which the model is prompted to complete the next step in the algorithmic execution with the correct prior steps (if any) included in the context window, as shown in Figure 4."}, {"title": "Experimental Settings", "content": "Foundation Models\nWe use Llama-3-8B, Llama-3-Instruct-8B, Mistral-7B-v0.3, Mistral-7B-Instruct-v0.3, and GPT-40 to establish baseline algorithmic reasoning performance on the MAGMA Benchmark. These models"}, {"title": "Evaluation Metrics", "content": "We use exact-match accuracy as our primary evaluation metric, following prior works (Wang et al.; Ge et al., 2024). We provide the following exact-match-accuracy-based evaluations of the baseline models:\n\u2022 Final Step Accuracy: Accuracy of the final solution step of an algorithmic trajectory. This metric provides an evaluation setting comparable to that of prior works."}, {"title": "Results", "content": "Intermediate steps significantly improve\nmultistep reasoning in fine-tuned models.\nOur results show that \"guiding\" the zero-shot LLM (GPT-40) through explicit intermediate steps provides significant performance improvements. We also observe that the fine-tuned IS models outperform IO models on Avg. Final Step Accuracy on most algorithms, as shown in Figure 6.\nFurthermore, we find a statistically significant relationship between the Final Step Accuracy and the Intermediate Step Accuracy for many models trained with intermediate steps. We also observe significantly higher performance on the IS models when considering the accuracy across the whole problem trajectory, as shown in Figure 8. This indicates that for problems where correctness across multiple steps is required, fine-tuning on intermediate steps provides significant benefits to overall accuracy. These results support our assertion that incorporating intermediate steps into the training and evaluation pipeline for both fine-tuned models and in-context learning for zero-shot models confers performance benefits on graph algorithmic reasoning tasks.\nFine-tuned LLMs outperform the current state-of-the-art zero-shot model on graph algorithmic reasoning tasks.\nOur results indicate that fine-tuning even relatively small language models for complex graph reasoning tasks provides vast performance enhancements over the state-of-the-art zero-shot model (GPT-40), as shown in both Figure 6. This supports the findings of prior work in comparing small, fine-tuned LLMs to large-scale LLMs on multistep mathematical reasoning problems and demonstrates that they apply to multistep graph reasoning problems (Fu et al., 2023).\nModels fine-tuned to leverage intermediate steps are sensitive to additional information\nWe observe that the inclusion of additional context for intermediate steps (translated from CLRS hints) hinders performance, as shown in Figure 7. This is"}, {"title": "Error Analysis", "content": "To better understand the challenges our models encounter, we categorize and examine commonly errors observed during prediction, as summarized below.\n1. Missing Prefix. Model prediction does not include the algorithm-specific prefix that denotes the start of the answer (See Appendix for"}, {"title": "Trajectory Analysis", "content": "In Figure 9, we show the average accuracy for each step across algorithmic trajectories for graphs of size 5 through 155. We show the full average model performance on algorithmic executions in Figure 11.\nWe show, in Figures 9b and 12b, that on simpler problem types (Breadth-First Search and Depth-First Search), the trajectory lengths are shorter and fine-tuning on intermediate reasoning steps is less beneficial. We also show that for more complex algorithms (Dijkstra, Floyd-Warshall, and Prim's MST), the trajectories are longer and intermediate steps provide more of a benefit. We also observe that fine-tuned IS models vastly outperform fine-tuned IO models on intermediate step accuracy, as shown in Figure 76."}, {"title": "Breadth-First Search", "content": "We first consider the errors committed by the IO and IS models on BFS. As shown in Figure 9a, both models commit relatively few errors. Furthermore, we see in Figure 9b that the IO model performs well on the final steps of the problem across all graph"}, {"title": "Depth-First Search", "content": "However, both the IO and IS models commit a relatively high number of invalid format errors on DFS. This indicates that the models are sensitive to the format of the connected components representation used for this DFS problem. Additionally, we see a gradual decline in the accuracy of each subsequent step for the IS model; this indicates that the IS model is better on intermediate steps and performs better over shorter problem trajectories. On the other hand, we see that the IO model tends to only perform well on the final problem steps; Figure 13 also shows that IO model performances degrade as graph size increases. These results suggest that the intermediate step fine-tuning vastly improves intermediate step accuracy at the cost of some final step accuracy."}, {"title": "Floyd-Warshall", "content": "Model performances on Floyd-Warshall performance drop as trajectory length increases. This result follows naturally when considering both the long lengths of problem trajectories and large solution sizes of Floyd-Warshall problems. This difficulty is reflected in the higher number of False Negatives and Hallucinations committed by both IO and IS models. We also observe in Figure 13 that IO models are relatively accurate on the final steps of smaller graphs, but performance collapses as graph sizes increase. On the other hand, we see that IS models are accurate on smaller graph sizes, and the trend in intermediate step and final step accuracies remain consistent across graph sizes. This indicates that the intermediate step fine-tuning makes the model more robust to larger problem sizes."}, {"title": "Prim's MST & Dijkstra", "content": "Models trained on Prim's and Dijkstra yield similar results and consistently perform well on final step accuracy. This follows intuition, as both problems have similar trajectory lengths and similar solution sizes. Furthermore, we observe similar error trends across both algorithms with IO models tending to commit frequent hallucinations, which likely results from the IO model predicting its final step solution at intermediate steps. We also observe in Figure"}, {"title": "Conclusion", "content": "In this work, we present the MAGMA Benchmark, a comprehensive benchmark for algorithmic reasoning on graph-structured data that utilizes the CLRS framework. We show that using intermediate steps both in in-context learning and fine-tuning improves the performance of SOTA foundation LLMs on five classical computer science graph algorithms. These findings highlight the potential of training LLMs to follow multistep reasoning processes for improving multistep algorithmic problem-solving on graphs. It is our hope that this benchmark will improve access to algorithmic reasoning tasks in natural language, address the need for a diverse and comprehensive natural language multistep reasoning dataset."}, {"title": "Limitations", "content": "This evaluation is based on selected graph reasoning tasks, and we only evaluate a subset of available large language models. The observations and conclusions made in this study may need to scale up for a larger collection of language models to be considered as a general law of LLMs' graph reasoning capabilities. Furthermore, we note that our results may be subject to prompt sensitivity based on our query structure."}, {"title": "Algorithmic Translation Details", "content": "This section describes the translation of inputs, hints, and outputs for various algorithms used in our benchmarks. The details are derived from the CLRS benchmark and our own methodology."}, {"title": "Algorithm Specifications", "content": "Each algorithm specification includes the following fields:\n\u2022 inputs: The initial parameters or data structures required by the algorithm to execute.\n\u2022 hints: Intermediate steps or states generated during the execution of the algorithm, useful for reasoning about the process.\n\u2022 outputs: The final result produced by the algorithm."}, {"title": "Translation of Inputs, Hints, and Outputs", "content": "For each algorithm, we describe the translation steps from the raw data to the form used in our benchmarks."}, {"title": "Breadth-First Search (BFS)", "content": "Inputs:\n\u2022 Adjacency Matrix (adj): A matrix representing the connections between nodes in the graph.\n\u2022 Source Node (s): The starting node for the BFS algorithm."}, {"title": "Hints:", "content": "\u2022 Reachable Nodes (reach_h): Indicates which nodes are reachable from the source node.\n\u2022 Predecessor Nodes (pi_h): Shows the predecessor of each node in the BFS tree."}, {"title": "Floyd-Warshall Algorithm", "content": "Inputs:\n\u2022 Adjacency Matrix (adj): A matrix representing the connections between nodes in the graph.\n\u2022 Weights (A): A matrix representing the weights of the edges."}]}