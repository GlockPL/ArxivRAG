{"title": "SQLong: Enhanced NL2SQL for Longer Contexts with LLMs", "authors": ["Dai Quoc Nguyen", "Cong Duy Vu Hoang", "Duy Vu", "Gioacchino Tangari", "Thanh Tien Vu", "Don Dharmasiri", "Yuan-Fang Li", "Long Duong"], "abstract": "Open-weight large language models (LLMs) have significantly ad- vanced performance in the Natural Language to SQL (NL2SQL) task. However, their effectiveness diminishes when dealing with large database schemas, as the context length increases. To address this limitation, we present SQLong, a novel and efficient data aug- mentation framework designed to enhance LLM performance in long-context scenarios for the NL2SQL task. SQLong generates augmented datasets by extending existing database schemas with additional synthetic CREATE TABLE commands and correspond- ing data rows, sampled from diverse schemas in the training data. This approach effectively simulates long-context scenarios during finetuning and evaluation. Through experiments on the Spider and BIRD datasets, we demonstrate that LLMs finetuned with SQLong- augmented data significantly outperform those trained on standard datasets. These imply SQLong's practical implementation and its impact on improving NL2SQL capabilities in real-world settings with complex database schemas.", "sections": [{"title": "1 Introduction", "content": "The NL2SQL task focuses on translating natural language questions into SQL queries, enabling non-experts to interact with databases seamlessly [3]. Recent advances leverage LLMs, finetuned on struc- tured input prompts (e.g., task instructions, database schema, and"}, {"title": "2 The Proposed SQLong Pipeline", "content": "The NL2SQL task aims to translate a natural-language question about a database schema into a corresponding SQL query. Follow- ing the standardized prompt template [12], we represent the input prompt to LLMs in the format of (task instructions, database schema, natural language question).2 As illustrated in Figure 2, the database schema is represented by CREATE TABLE commands and three sam- ple data rows for each corresponding table.\nUsing supervised finetuning (SFT) [15], LLMs can be trained on pairs of input prompts and target SQL queries to optimize their performance on the NL2SQL task. Specifically, given a training set T comprising pairs of input prompts x and corresponding target SQL queries s, the supervised finetuning process can be formulated as minimizing the log-likelihood loss [15], as shown below:\n$\\mathcal{B}(x, s) \\sim \\sum_{i=1}^{|s|} \\log p(s_i | s_{<i}, x)$"}, {"title": "3 Evaluation", "content": "We assess the effectiveness of our proposed SQLong model in en- hancing NL2SQL performance across both short-context and long- context scenarios."}, {"title": "3.1 Experimental Setup", "content": "Datasets. For the short-context evaluation, we utilize widely adopted benchmark datasets, including Spider [18], Spider-realistic [4], Spider-syn [7], and BIRD [9]. 3 It is noted that Spider-Syn is manually created based on Spider training and development sets using synonym substitution in the original questions, while Spider- realistic is created based on Spider development set by manually removing the explicit mention of column names in the original ques- tions. The BIRD-test set is not publicly available.\nFor the long-context evaluation, we extend each of the Spider-dev, Spider-test, Spider-realistic, Spider-syn, and BIRD-dev datasets by applying SQLong with a pre-defined context length. Specifically, we"}, {"title": "3.2 Main Results", "content": "Performance on Original Datasets. Table 2 summarizes the re- sults on the original development and test sets, comparing base Models with larger LLMs such as Llama-3.1-70B-Instruct [6] and Qwen2-72B-Instruct [16]. Models finetuned using long-context aug- mentation via SQLong consistently outperform their counterparts finetuned on original contexts. On average, SQLong delivers an ab- solute improvement of over 2.2% across five benchmark datasets. Additionally, SQLong-finetuned models achieve performance com- parable to much larger LLMs on specific datasets, showcasing the scalability and efficiency of the approach.\nPerformance on Long-Context Datasets. Figure 4 illustrates the experimental results on long-context test sets. Across all datasets, models finetuned with SQLong demonstrate superior performance compared to those trained without SQLong. For instance, on the Spider-test datasets with 8k and 24k context lengths, the Llama- 3.1-8B-Instruct model achieves outstanding results of 77.1% and 72.3%, reflecting absolute gains of 7.2% and 13.3%, respectively. Notably, the SQLong-finetuned Llama-8B model outperforms the larger Llama-70B model on 41 out of 45 long-context test sets, with minor exceptions on Spider-realistic 8k and BIRD-dev 8k, 16k, and 24k sets. Similar performance trends are observed with the Qwen models.\nOn average, SQLong finetuning delivers an 11% absolute im- provement over models without SQLong and a 6% advantage over 70B models within the same model family. These results under- score the efficacy of SQLong in handling long-context scenarios and advancing the performance of NL2SQL systems.\nPositional robustness. To evaluate the positional robustness of fine-tuned models, we conduct an experiment where each original database schema is placed at varying positions within the input prompt to assess the models' ability to detect them.\nWe select a set of 124 samples from Spider-dev, Spider-realistic, and Spider-syn, ensuring each sample has a maximum input prompt and target SQL query length of 384 tokens according to CodeQwen1.5- 7B-Chat's tokenizer. Using SQLong, we augment this set to a 64k context length. In each augmented set, the original database schemas"}, {"title": "4 Conclusion and Future Work", "content": "Handling large database schemas poses a significant challenge for NL2SQL models. In this paper, we introduce long-context NL2SQL generation, a novel task that reflects real-world scenarios, and pro- pose SQLong, a simple yet effective augmentation approach for creating long-context finetuning and benchmark datasets. Experi- ments show that LLMs finetuned with SQLong significantly outper- form their counterparts on benchmarks like Spider, BIRD, and our long-context test sets (up to 128k context length).\nFuture work includes leveraging a RAG-based schema linking ap- proach to retrieve relevant schema elements, enabling more concise and efficient inputs for SQLong-tuned models."}]}