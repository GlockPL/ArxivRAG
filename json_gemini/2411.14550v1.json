{"title": "The importance of the clustering model to\ndetect new types of intrusion in data traffic", "authors": ["Noor Saud Abd", "Kamel Karoui"], "abstract": "In the current digital age, the volume of data generated by various\ncyber activities has become enormous and is constantly increasing. The data\nmay contain valuable insights that can be harnessed to improve cyber security\nmeasures. However, much of this data is unclassified and qualitative, which\nposes significant challenges to traditional analysis methods. In order to over-\ncome these challenges, clustering, a crucial method in machine learning (ML)\nand data analysis, has become increasingly effective. Clustering facilitates the\nidentification of hidden patterns and structures in data through grouping sim-\nilar data points, which makes it simpler to identify and address threats. Clus-\ntering can be defined as a data mining (DM) approach, which uses similarity\ncalculations for dividing a data set into several categories. Each data cluster\nthat the clustering algorithm has identified has a high degree of similarity, and\nthere is a fair amount of similarity between other clusters of data. Hierar-\nchical, density-based, along with partitioning clustering algorithms are typi-\ncal. The presented work use K-means algorithm, which is a popular clustering\ntechnique. Utilizing K-means algorithm, we worked with two different\ntypes of data: first, we gathered data with the use of XG-boost algorithm fol-\nlowing completing the aggregation with K-means algorithm. Data was gath-\nered utilizing Kali Linux environment, cicflowmeter traffic, and Putty Soft-\nware tools with the use of diverse and simple attacks. The concept could assist\nin identifying new attack types, which are distinct from the known attacks,\nand labeling them based on the characteristics they will exhibit, as the dy-\nnamic nature regarding cyber threats means that new attack types of-\nten emerge, for which labeled data might not yet exist. The model counted the\nattacks and assigned numbers to each one of them. Secondly, We tried the\nsame work on the ready data inside the Kaggle repository called (Intrusion\nDetection in Internet of Things Network), and the clustering model worked\nwell and detected the number of attacks correctly as shown in the results sec-\ntion.", "sections": [{"title": "1 Introduction", "content": "With the world becoming more interconnected, there is a greater risk of cyber\nattacks and intrusions than before. For example, on October 21, 2016,\nnumerous datacenters were struck by severe distributed denial of service\n(DDoS) attacks, which resulted in the closure of Spotify, Twitter, and other\npopular websites [1]. Over the years, there have been more threats to the\nintegrity and confidentiality of data and systems along with denial-of-service\n(DoS) attacks [2]. Modern cyber security strategies must include intrusion\ndetection, which is responsible for spotting malicious activity, unauthorized\naccess, and policy violations in a network or system [3]. Large amounts of\nlabeled data are needed for training accurate models in supervised learning\ntechniques, which are frequently used in conventional intrusion detection\nsystems (IDS). But getting labeled data in the cyber security challenging is\nespecially hard [4].\nLabeling network traffic or system logs involves significant manual effort,\nexpert knowledge, and time. Moreover, the dynamic nature of cyber threats\nmeans that new types of attacks frequently emerge, for which labeled data\nmay not yet exist [5]. In response to these challenges, the use of unlabeled\ndatasets in intrusion detection has gained increasing attention. Unlabeled\ndatasets, which consist of raw, unannotated data, represent the vast majority\nof data available in real-world cyber security scenarios [6]. These datasets\ncapture the natural flow of network traffic, system events, and user behaviors,\nincluding both normal and potentially malicious activities [7]. The absence of\nlabels in these datasets poses a unique challenge, but it also presents an\nopportunity: by applying advanced unsupervised learning techniques, such as\nanomaly detection, clustering, and more recently, self-supervised learning; it\nis possible to uncover hidden patterns as well as anomalies which might\nspecify security breaches or emerging threats [8].\nThe exploration of unlabeled datasets in intrusion detection opens up new\navenues for developing adaptive, scalable, and robust security solutions [9].\nThese methods can learn to detect unknown or novel attacks without relying\non prior knowledge, making them particularly valuable in the ever-evolving\nlandscape of cyber security [10]. As such, the study and application of tech-\nniques that can effectively utilize unlabeled datasets are crucial for advancing\nthe field of intrusion detection as well as improving the overall security pos-\nture of organizations [11].\nThe workflow regarding the unsupervised and supervised models is shown in\nFig 1 [12]. The supervised model's workflow is comprised of multiple steps,\nas seen in Fig 1(A): dataset evaluation, data acquisition, model training, and\noptimization. While unsupervised models are utilized with an unlabeled da-\ntaset, as demonstrated in Fig 1(B), supervised models need labeled data, ne-\ncessitating the application of more data evaluation methods. Following using\noptimization approaches, unsupervised models in this case, K-means and"}, {"title": "Contributions of this paper:", "content": "The clustering method was used here to find new types of attacks in case\nnew types of them appeared, as we assumed that we do not know the names\nof the attacks present in a certain dataset (in our work we tried 2 datasets) and\napplied the clustering model to them and the model correctly identified the\nexisting categories.\n- We created a dataset for simple and common types of attacks using the Kali\nLinux system and Putty and Cicflowmeter tools to record traffic, there were\n7 types of attacks and the seven attacks were actually classified by the clus-\ntering system using the K-means algorithm.\nWhile the other datasets were ready as indicated in the Dataset and Resources\nsection at the end of the paper, to ensure the validity and robustness of the\nmodel.\nWe show related works in Section 2. Section 3 describes the 3 Clustering\nTechnique and K-means clustering algorithms, while Section 4 describes the\nMethodology then the results. Finally, we wrap up our research in Section 5."}, {"title": "2 Related Work", "content": "With regard to such context, IDSs are being developed more and more\ndaily so that the network systems could be effective against the developed\nmalware. Thus, there are numerous literature studies as well as new studies\nare performed daily for increasing the performance regarding IDS systems.\nAttackers are constantly creating new attack scenarios and updating them-\nselves and the software they use.\n\u2022\n\u2022\n\u2022\nDhaliwal, S. S., Nahid, A. A, 2018 [13], this study presents a model\nintended for measuring multiple network data attributes, including ac-\ncuracy, precision, confusion matrix, and so on. To get the desired out-\ncomes, XGBoost is applied to NSL-KDD (Network Socket Layer\nKnowledge Discovery in Databases) dataset. The primary goal is to\nidentify the data's integrity and increase prediction accuracy. The like-\nlihood of data being hacked or altered decreases with network security.\nThe researchers stress that through adjusting different model parame-\nters, further research could be done in the future to maximize the amount\nof data entering and leaving the network. The data is the most significant\nparticipant in the network, and knowing it well and accurately is half\nthe job done. An effective IDS, which preserves the network's integrity\nand provides a secure environment for exchanging confidential data,\nemerges as a result of studying the data in the network and evaluating\nits volume and pattern.\nRosay, A., Carlier, F., 2021 [14], Many datasets were created during the\nlast few decades to solve this security issue. Analysis of earlier datasets,\nlike KDD-Cup99 and NSL-KDD, has brought attention to some of the\ndifficulties and opened the door for the correction of those faults in more\nrecent datasets. One of the most recent network intrusion detection da-\ntasets, CIC-IDS2017, is thoroughly analyzed in this research. They pre-\nsent a number of problems they found in the network packet flows\nwhich were recovered. A novel feature extraction technique named Ly-\ncoSTand is suggested as a solution to these problems. In order to com-\nprehend network traffic, a tool called LycoSTand models network flows\nand extracts attributes that define them. The Greek word for wolf is lycos,\nwhich means flow in reverse order. Furthermore, a feature selection ap-\nproach is suggested that considers feature importance and account rela-\ntions. When comparing the new and original datasets' performances, all\nof the ML methods under evaluation exhibit significant improvements.\nThey looked at other datasets impacted by the same problems that Ly-\ncoSTand may be utilized to solve in order to create better datasets for\nnetwork intrusion detection, depending on the improvements in CIC-\nIDS2017.\nFarhan, R. I., Maolood, (2020) [15], this work suggests solving the fea-\nture selection (FS) problem with binary Particle Swarm Optimization\n(BPSO). Next, using the CSE-CIC-IDS2018 dataset as well as Deep Neu-"}, {"title": "3 Clustering Technique", "content": "A key method in data analysis is clustering, which groups a set of objects so\nthat those in the same group referred to as a cluster are more similar to one\nanother compared to those in other groups. In the field of cyber security, this\nmethod has grown in importance, especially when working with qualitative\nand unclassified data [17]. Putting data into clusters depending on similarity\nis the process of clustering, an unsupervised learning technique. Data that has\nbeen labeled is not necessary for clustering, in contrast to classification, when\ndata points are given predefined labels. Rather, it aims to divide the dataset\ninto clusters whose members are more alike than they are from other clusters.\nUnlike classification, clustering allows for model modifications and the\ncreation of sub-clusters. Because of this, clustering is especially helpful in\nsituations where the underlying data structure is unclear and in exploratory\ndata analysis [18]. Numerous clustering techniques exist, and each is\nappropriate for a particular set of data and use cases. Several of the typical\nmethods consist of:\n1. K-means Clustering: Each data point belongs to the cluster with the\nnearest mean in this algorithm, which divides the data into K clus-\nters. Because of its efficiency and simplicity, it is widely utilized.\n2. Hierarchical Clustering: Using a top-down (divisive) or bottom-up\n(agglomerative) method, this approach creates a hierarchy of clus-\nters. It is helpful for organizing clusters into a structure resembling\na tree.\n3. DBSCAN (Density-Based Spatial Clustering of Applications with\nNoise): This algorithm classifies as outliers the points that are iso-\nlated in low-density regions and clusters together points that are\ndensely packed. It works well for locating clusters of any shape.\n4. Spectral Clustering: This method reduces dimensionality and per-\nforms clustering in fewer dimensions by utilizing the eigenvalues\nregarding a similarity matrix. It is especially helpful for clusters that\nare not convex.\n5. Gaussian Mixture Models (GMM): assumes that a mix of many\nGaussian distributions with varying parameters produced the data.\nLastly, grouping related objects into the same class without label information\nis referred to as clustering. These days, cluster analysis is a popular unsuper-\nvised technique that is also frequently utilized in DM. Due to its straightfor-\nward concept, concise algorithm, and strong clustering impact, the K-means\nclustering algorithm has garnered a lot of interest from scholars and has been\nused in a variety of domains [19]."}, {"title": "3.1 Applications of Clustering in Cyber security", "content": "In the context of cyber security, clustering helps in various ways, especially\nwhen dealing with qualitative and unclassified data [20]:\n1. Intrusion Detection: Clustering can identify abnormal patterns or out-\nliers in network traffic that might indicate security breaches or intru-\nsions. By analyzing logs and traffic data, clustering helps in distin-\nguishing between normal and anomalous behaviors."}, {"title": "3.2 K-means clustering algorithms", "content": "The unlabeled dataset is grouped into various clusters using the K-\nMeans clustering algorithm, which is an Unsupervised Learning technique\n[25]. In this case, K indicates how many pre-defined clusters must be formed\nduring the process; for example, if K=2, there will be two clusters; if K=3,\nthere will be three clusters, and so on. Still the most often used and simple\nclustering algorithm is the K-means algorithm. The algorithm's low compu-\nting complexity and ease of implementation account for its broad applicability\nacross numerous clustering application domains. Nevertheless, a number of\nchallenges that the K-means algorithm has have a detrimental impact on how"}, {"title": "4. Methodology", "content": "Generating unclassified cyber-attack data in Kali Linux can be useful for\nlearning, testing, and developing cyber security tools and techniques.\nThere are some steps to simulate and capture attack data using various\ntools in Kali Linux, these tools and techniques are: 1- Metasploit Frame-\nwork 2- Wireshark 3- tcpdump 4- hping3. In our experiment we used\ntcpdump is a command line packet analysis tool. As we show in steps\nbelow:\n1- Install tcpdump:\nsudo apt update\nsudo apt install tcpdump\n2- Capture Traffic:\nsudo tcpdump -i  -w attack_data.pcap\nReplace  with your network interface (e.g., eth0, wlan0).\n3- Stop Capture:\nPress Ctrl+C to stop capturing traffic."}, {"title": "4.1 Dataset", "content": "We planned and deployed two networks, the Attack-Network and the Victim-\nNetwork, in order to build a thorough tested. As we previously indicated, we\nattempted to create a dataset that is unique to the Internet. We worked with\nKali Linux and the tcpdump program with Putty to acquire data that was\n19,677 rows and 84 columns. However, the data needs to be properly prepared\nbefore being used in the model.\nData preprocessing has three steps:\n\u2022 Data Cleaning: specify missing values as well as fix errors.\n\u2022 Data Digitization: converting categorical features into numerical val-\nues.\n\u2022 Data Transforms: like normalization for changing scale, type, and\nprobability distribution regarding variables in the dataset.\nAfter working on Kali Linux and the tcpdump tool using PuTTY, we\nobtained data that was (19,677 rows, 83 columns), and the figure (1)\nshows a sample of it:\nThere is a small percentage of missing values in the collected data set,\nand a drop was made for the column containing these missing values, as\nwell as for some values that are not important in later processing, which\nare (Flow ID\u201d, \u201cSrc IP\u201d, \u201cDst IP\u201d, \u201cTimestamp", "Flow ID": "Src IP", "Dst IP": "Timestamp\").\nCreate a new column in the DataFrame to store the cluster labels\nscaled_df['Cluster_Labels'] = cluster_labels\nscaled_df[\\\"Cluster_Labels\\\"].value_counts()\"\n    },\n    {\n      \"title\": \"i- Dataset Description\",\n      \"content\": \"Two datasets were used in this paper: the IoT Intrusion Detection da-\ntaset from the Kaggle repository. And a dataset created in an actual test\nimplementation using devices that generate real traffic (including DoS,\nBrute Force Attack, TCP Floading, UDP Floading, etc.) that simulates\nuser behavior. Subsets of their normal traces were included in the train-\ning dataset as well as a subset of normal traffic in the test dataset.\nA dataset obtained from tcpdump captures raw network traffic data,\nrepresenting packets transmitted over a network during the capture pe-\nriod. This dataset is usually stored in a. pcap (Packet Capture) file for-\nmat. Below is a detailed description of the typical contents and struc-\nture of a tcpdump dataset:\n1-Packet Metadata:\n\u2022 Timestamp: The exact date and time in the case when the packet has\nbeen captured. This is important for analyzing the sequence and timing\nof events in network traffic.\n\u2022 Frame Number: A unique identifier allocated to each packet in cap-\nture, useful for analysis and reference.\n2-Ethernet Header:\n\u2022 Source MAC Address: The hardware address of the device that sent\nthe packet.\n\u2022 Destination MAC Address: The hardware address of the device that\nis intended to receive the packet.\n\u2022 EtherType: Indicates the protocol of the encapsulated data, such as\nIPv4, ARP, or IPv6.\n3-Network Layer (IP Header):\n\u2022 Source IP Address: The IP address of the device that sent the packet.\n\u2022 Destination IP Address: The IP address of the device that is intended\nto re ceive the packet.\n\u2022 Protocol: Indicates the protocol used in the data portion of the packet\n(e.g., TCP, UDP, ICMP).\n4-Transport Layer:\n\u2022 Source Port: The port number on the source device from which the\npacket was sent.\n\u2022 Destination Port: The port number on the destination device to which\nthe packet is addressed.\n\u2022 Sequence Number: Used in TCP connections to ensure packets are\nreceived in order.\n\u2022 Acknowledgment Number: Used in TCP connections to confirm re-\nceipt of packets.\n\u2022 Flags: Control bits that manage the state of the TCP connection (e.g.,\nSYN, ACK, FIN).\n5-Application Layer:\nPayload Data: The actual data being transmitted by the application.\nThis could be HTTP requests/responses, DNS queries/responses, or\nany other protocol data.\"\n    },\n    {\n      \"title\": \"ii- Data Preparation:\",\n      \"content\": \"There are steps for data preparation that we list with a simple explana-\ntion for each one.\nA. Data Collection:\nAfter working on Kali Linux and the tcpdump tool using PuTTY, we\nobtained data that was (19,677 rows, 83 columns)\nB. Data Cleaning:\nRemove or handle missing values, outliers, and irrelevant features.\nClean and preprocess the data to ensure quality input for the model. In\nour dataset, there was not much missing data except for one column\nthat was dropped it without affecting the quality of the data and the\nwork of the algorithms.\nThere is a small percentage of missing values in the collected data set,\nand a drop was made for the column containing these missing values,\nas well as for some values that are not important in later processing,\nwhich are (Flow ID\\\", \\\"Src IP"}, {"Dst IP": "Timestamp\"), so it became\nDataset (19677 rows, 78 columns).\nWe also made a drop for a set of data that is not important in the clas-\nsification process, namely (\\\"Flow ID\\\", \\\"Src IP\\\", \\\"Dst IP", "Splitting": "nDivide the dataset into sets for testing and training. To assess the per-\nformance of the model, a typical split may be 20% for testing and 80%\nfor training."}, {"title": "4- Building the model", "content": "i - Building the XGBoost Model\nAn effective and powerful of gradient boosting algorithms built for perfor-\nmance and speed is known as XGBoost, or Extreme Gradient Boosting Algo-\nrithm. Because of its accuracy, scalability, and flexibility, it has gained pop-\npularity as a choice for developing predictive models. XGBoost has a wide\nrange of applications in cybersecurity, including malware classification, in-\ntrusion detection, and anomaly detection [30]. First, specify the XGBoost\nmodel's hyperparameters. With the use of training data, train the XGBoost\nmodel. Make predictions on test data using the trained model. The next factors\nexplain why XGBoost is specifically chosen as the best classification model\nto address problems that arise in real word classification tasks:\n\u2022 One platform means that time consumption will be eliminated, particu-\nlarly in the case when pre-processing network data.\nXGBoost benefits from parallel processing, which makes use of all the cores\non the computer it is operating on. It is extremely scalable, uses few resources,\nand produces billions of examples through algorithmic optimization pro-\ncesses and distributed or parallel computing. As a result, it works incredibly"}, {"title": "5 Conclusion", "content": "Availability of datasets is one of the biggest challenges in the field of intru-\nsion detection systems. Due to privacy and security reasons, most organiza-\ntions will never share their network traffic data. However, a high-quality da-\ntaset is crucial to develop an anomaly-based intrusion detection system and\nevaluate its performance. Therefore, in this research, we have tried to perform\nsimple common attacks at close times and test them on the proposed model if\nit can recognize the presence of a group of unclassified attacks and group\nthem into groups, then pass them to the classification process and complete\nthe rest of the requirements such as knowing the accuracy, confusion matrix,\netc.\nClustering is a versatile and powerful tool in the arsenal of cyber security\nprofessionals. Its ability to handle unclassified and qualitative data, uncover\nhidden pat-terns, and detect anomalies makes it indispensable in the ongoing\nbattle against cyber threats. As technology continues to evolve, clustering\ntechniques will undoubtedly become even more integral to maintaining robust\ncyber security defenses, providing deeper insights and more proactive protec-\ntion against an ever-expanding array of cyber threats."}]}