{"title": "Enhancing In-Context Learning via Implicit Demonstration Augmentation", "authors": ["Xiaoling Zhou", "Wei Ye", "Yidong Wang", "Chaoya Jiang", "Zhemg Lee", "Rui Xie", "Shikun Zhang"], "abstract": "The emergence of in-context learning (ICL) enables large pre-trained language models (PLMs) to make predictions for unseen inputs without updating parameters. Despite its potential, ICL's effectiveness heavily relies on the quality, quantity, and permutation of demonstrations, commonly leading to suboptimal and unstable performance. In this paper, we tackle this challenge for the first time from the perspective of demonstration augmentation. Specifically, we start with enriching representations of demonstrations by leveraging their deep feature distribution. We then theoretically reveal that when the number of augmented copies approaches infinity, the augmentation is approximately equal to a novel logit calibration mechanism integrated with specific statistical properties. This insight results in a simple yet highly efficient method that significantly improves the average and worst-case accuracy across diverse PLMs and tasks. Moreover, our method effectively reduces performance variance among varying demonstrations, permutations, and templates, and displays the capability to address imbalanced class distributions.", "sections": [{"title": "1 Introduction", "content": "Large pre-trained language models (PLMs) have showcased exceptional abilities in in-context learning (ICL) (Brown et al., 2020; Wang et al., 2023; Rubin et al., 2022), which assists the model in discerning the underlying patterns within demonstrations and make more accurate predictions (Chan et al., 2022; Wu et al., 2023). As a new paradigm, ICL offers compelling advantages, allowing for natural language interaction with PLMs (Wei et al., 2022; Yang et al., 2023), as well as reduced computational costs (Li et al., 2023a; Rubin et al., 2022). While promising, ICL's performance is highly dependent on provided demonstrations and templates (Liu et al., 2022; Zhang et al., 2022b; Sorensen et al., 2022), resulting in subpar and unstable performance. This promotes research aimed at improving the quality (Rubin et al., 2022; Li et al., 2023b), quantity (Li et al., 2023a; Choi et al., 2022), and permutations (Lu et al., 2022; Tang et al., 2023) of demonstrations. Other research avenues include prediction adjustment (Zhao et al., 2021; Han et al., 2023; Fei et al., 2023) and learning process design (e.g., channel models (Min et al., 2022a) and meta-training frameworks (Min et al., 2022b)). Despite ongoing efforts, ICL still struggles with efficiently and reliably capturing sufficient knowledge from context, leaving performance stability as a persistent bottleneck.\nIn this study, we propose enriching contextual knowledge for PLMs by augmenting demonstrations. We first attempt to enhance the representation of demonstrations by transforming them along semantic directions sampled from the deep feature space of demonstration examples, as depicted in Figure 1. This operation stems from the observation that the deep features in a network are usually linearized (Bengio et al., 2013; Cheung and Yeung, 2021; Cho, 2016), implying the existence of numerous semantic directions within the deep feature space, hence potentially enabling us to incorporate richer contextual knowledge without extending input length. From this novel perspective, we theoretically prove that when the number of augmented pieces approaches infinity, its effect approximately equals a logit adjustment operation. Specifically, we derive a refined Softmax function that integrates the statistical properties of demonstrations. Consequently, rather than explicitly executing the augmentation procedure, we can efficiently conduct implicit demonstration augmentation using the derived prediction function, obtaining an improved ICL method with theoretical guidance.\nWe conduct extensive experiments across seven PLMs and various classification tasks. The empirical results demonstrate that our approach remarkably enhances prediction accuracy and reduces performance variability across different demonstrations, permutations, and templates. Notably, our method is straightforward, effective, and generalizable, enabling seamless integration with other ICL methods to enhance their performance.\nOur contributions can be summarized as follows:\n\u2022 We introduce Implicit Demonstration Augmentation-based ICL (IDAICL), a pioneering work that incorporates demonstration augmentation into ICL. Instead of solely enhancing demonstration quality, quantity, or order, our method explores context augmentation within the deep feature space, offering a new perspective to enrich demonstrations bypassing input length limitations.\n\u2022 We theoretically establish that as the number of augmented pieces approaches infinity, our augmentation strategy approximates a logit-adjusted prediction function that integrates statistical properties derived from the input data distribution. Equipped with this function, IDAICL provides a straightforward yet theory-guided solution to enhance ICL.\n\u2022 Extensive experiments conducted across diverse tasks and PLMs conclusively illustrate that IDAICL considerably improves average and worst-case accuracy compared to existing ICL methods. Moreover, it effectively enhances performance stability."}, {"title": "2 Background and Related Work", "content": "Large pre-trained language models (PLMs) have showcased exceptional abilities in in-context learning (ICL) (Brown et al., 2020; Wang et al., 2023; Rubin et al., 2022), which assists the model in discerning the underlying patterns within demonstrations and make more accurate predictions (Chan et al., 2022; Wu et al., 2023). As a new paradigm, ICL offers compelling advantages, allowing for natural language interaction with PLMs (Wei et al., 2022; Yang et al., 2023), as well as reduced computational costs (Li et al., 2023a; Rubin et al., 2022).\nWhile promising, ICL's performance is highly dependent on provided demonstrations and templates (Liu et al., 2022; Zhang et al., 2022b; Sorensen et al., 2022), resulting in subpar and unstable performance. This promotes research aimed at improving the quality (Rubin et al., 2022; Li et al., 2023b), quantity (Li et al., 2023a; Choi et al., 2022), and permutations (Lu et al., 2022; Tang et al., 2023) of demonstrations. Other research avenues include prediction adjustment (Zhao et al., 2021; Han et al., 2023; Fei et al., 2023) and learning process design (e.g., channel models (Min et al., 2022a) and meta-training frameworks (Min et al., 2022b)). Despite ongoing efforts, ICL still struggles with efficiently and reliably capturing sufficient knowledge from context, leaving performance stability as a persistent bottleneck.\nIn this study, we propose enriching contextual knowledge for PLMs by augmenting demonstrations. We first attempt to enhance the representation of demonstrations by transforming them along semantic directions sampled from the deep feature space of demonstration examples, as depicted in Figure 1. This operation stems from the observation that the deep features in a network are usually linearized (Bengio et al., 2013; Cheung and Yeung, 2021; Cho, 2016), implying the existence of numerous semantic directions within the deep feature space, hence potentially enabling us to incorporate richer contextual knowledge without extending input length. From this novel perspective, we theoretically prove that when the number of augmented pieces approaches infinity, its effect approximately equals a logit adjustment operation. Specifically, we derive a refined Softmax function that integrates the statistical properties of demonstrations. Consequently, rather than explicitly executing the augmentation procedure, we can efficiently conduct implicit demonstration augmentation using the derived prediction function, obtaining an improved ICL method with theoretical guidance.\nWe conduct extensive experiments across seven PLMs and various classification tasks. The empirical results demonstrate that our approach remarkably enhances prediction accuracy and reduces performance variability across different demonstrations, permutations, and templates. Notably, our method is straightforward, effective, and generalizable, enabling seamless integration with other ICL methods to enhance their performance.\nOur contributions can be summarized as follows:\n\u2022 We introduce Implicit Demonstration Augmentation-based ICL (IDAICL), a pioneering work that incorporates demonstration augmentation into ICL. Instead of solely enhancing demonstration quality, quantity, or order, our method explores context augmentation within the deep feature space, offering a new perspective to enrich demonstrations bypassing input length limitations.\n\u2022 We theoretically establish that as the number of augmented pieces approaches infinity, our augmentation strategy approximates a logit-adjusted prediction function that integrates statistical properties derived from the input data distribution. Equipped with this function, IDAICL provides a straightforward yet theory-guided solution to enhance ICL.\n\u2022 Extensive experiments conducted across diverse tasks and PLMs conclusively illustrate that IDAICL considerably improves average and worst-case accuracy compared to existing ICL methods. Moreover, it effectively enhances performance stability."}, {"title": "2.1 In-Context Learning", "content": "Brown et al. (2020) showcased the ICL capability of PLMs, wherein PLMs generate predictions solely based on a concatenation of training examples for few-shot learning without updating parameters. Subsequent studies (Holtzman et al., 2021; Min et al., 2022a,b) have developed this approach, yielding promising outcomes across various tasks. Nevertheless, recent research has uncovered certain limitations. To begin with, the volume of input knowledge for each query is constrained by the maximum input length of PLMs (Hao et al., 2022), and the computational cost increases as the number of demonstrations grows (Li et al., 2023a), making it challenging to integrate significant knowledge from demonstrations to PLMs. Additionally, ICL's performance is sensitive to the input of PLMs (Davison et al., 2019; Jiang et al., 2020), thus exhibiting high variance and poor worst-case accuracy (Perez et al., 2021; Lu et al., 2022).\nResearchers have explored various techniques to address the biases and instability of ICL. These techniques encompass learning process design (Min et al., 2022a,b), demonstration retrieval (Rubin et al., 2022; Zhang et al., 2022b), prompt engineering (Sorensen et al., 2022; Lu et al., 2022), and prediction calibration (Zhao et al., 2021; Fei et al., 2023). However, these methods have yet to fully address the issue of severely limited knowledge transfer from demonstrations to large PLMs."}, {"title": "2.2 Data Augmentation", "content": "Data augmentation (Chen et al., 2023), which involves artificially creating training data through transformations, is a well-established research area in machine learning. Although data augmentation techniques have undergone extensive exploration in diverse machine learning domains (Maharana et al., 2022; Shorten and Khoshgoftaar, 2019), applying them to text data poses challenges due to the complexity of preserving labels during textual transformations (Kobayashi, 2018). Nonetheless, data augmentations in the latent space, such as adversarial training (Zhang et al., 2022a; Zhu et al., 2020; Cheng et al., 2020), interpolation (Chen et al., 2022b; Wu et al., 2022), and generative techniques (Li et al., 2022; Malandrakis et al., 2019), have demonstrated notable enhancements when applied alongside large PLMs.\nRecently, Wang et al. (2019) introduced the concept of implicit data augmentation in the context of image classification. This approach involves transforming training data within the deep feature space and boils down to the optimization of a novel robust loss function. Subsequent studies (Chen et al., 2022c; Li et al., 2021; Zhou and Wu, 2023a) for image classification tasks have further improved upon this approach. This study introduces an algorithm for implicitly augmenting demonstrations within the realm of ICL."}, {"title": "3 Methodology", "content": "Recognizing the established efficacy of data augmentation in machine learning (Feng et al., 2021), this study investigates demonstration augmentation and suggests enhancing the deep features of demonstrations by transforming them along semantic directions sampled from the deep feature space of demonstration examples. This strategy is motivated by the intriguing observation that the deep features in networks are often linearized (Bengio et al., 2013; Chen et al., 2022a). Building on this observation, we hypothesize that \\(h_z\\) lies within the subspace spanned by \\(h_c\\) and \\(h_x\\): \\(h_z = \\alpha h_c + \\beta h_x\\), where \\(h_c\\) and \\(h_x\\) represent the components of \\(h_z\\) linked respectively to the demonstrations and the query. The necessity of this assumption stems from intricate relationships among token representations and the exclusive augmentation of the component related to demonstrations. Notably, this decomposition is not necessary in practical applications. In the subsequent text, we directly refer to \\(\\alpha h_c\\) and \\(\\beta h_x\\) as \\(h_c\\) and \\(h_x\\).\nTo augment \\(h_c\\), we randomly sample vectors from the deep feature space of demonstrations. In particular, vectors are drawn from a multivariate normal distribution \\(\\mathcal{N}(\\mu, \\Sigma)\\), where \\(\\mu\\) and \\(\\Sigma\\) denote the feature mean and covariance matrix. These statistical properties are estimated from the deep features of the demonstration set \\(\\mathcal{D}\\), which includes demonstration examples linked to all queries. The feature mean \\(\\mu\\) is computed as\n\\[\\mu = \\frac{1}{|\\mathcal{D}|} \\sum_{i=1}^{\\mathcal{D}} h_i,\\qquad(4\\]\nwhere \\(h_i = \\mathcal{G}(c_i)\\) represents the hidden state of the last block at the final position for the \\(i\\)-th demonstration example \\(c_i\\) in \\(\\mathcal{D}\\), and \\(|\\mathcal{D}|\\) denotes the size of \\(\\mathcal{D}\\). The covariance matrix \\(\\Sigma\\) is computed as\n\\[\\Sigma = \\frac{1}{|\\mathcal{D}|} \\sum_{i=1}^{\\mathcal{D}} (h_i - \\mu) (h_i - \\mu)^T.\\qquad(5\\]\nSubsequently, \\(h_c\\) is shifted in the extracted semantic vectors, resulting in augmented features, \\(\\hat{h_c}\\), which follows\n\\[\\hat{h_c} \\sim \\mathcal{N} (h_c + \\lambda\\mu, \\lambda\\Sigma),\\qquad(6\\]\nwhere \\(\\lambda\\) refers to a positive coefficient controlling the strength of semantic augmentation. In real-world applications, it can be directly assigned a value of 0.5. Sensitivity tests for \\(\\lambda\\) are discussed in Section 5.4."}, {"title": "3.1 In-Context Learning with PLMs", "content": "Considering a PLM \\(\\mathcal{G}\\), this study focuses on the following task: given a query input text \\(x\\) and a candidate answer set \\(\\mathcal{Y} = \\{y_1, y_2, \u2026, y_{|\\mathcal{Y}|}\\} \\), we aim to predict the answer \\(\\hat{y}\\) based on \\(m\\) demonstration examples \\(\\mathcal{C} = \\{C_1, C_2, \u2026\u2026\u2026, C_m\\}\\), where each \\(c_i\\) represents a training example \\((x_i, y_i)\\) after template formulation and \\(m\\) denotes the quantity of demonstration examples for each test sample. Formally, give a model \\(\\mathcal{G}\\), we first compute the probability of each answer \\(y_j\\):\n\\[P_{\\mathcal{G}} (y_j | \\mathcal{C}, x).\\qquad(1\\]\nSubsequently, the ultimate prediction \\(\\hat{y}\\), characterized by the highest probability is chosen from the candidate answer set \\(\\mathcal{Y}\\):\n\\[\\hat{y} = \\arg\\max_{y_j \\in \\mathcal{Y}} P_{\\mathcal{G}} (y_j | \\mathcal{C},x).\\qquad(2\\]\nTo simplify, the contextual input is denoted as \\(x = [\\mathcal{C}, x]\\) in the subsequent text. Then, the probability of answer \\(y_j\\), represented as \\(P_{\\mathcal{G}}(y_j|x)\\), is computed using the Softmax function\u00b9:\n\\[P_{\\mathcal{G}}(y_j|x) := P_{\\mathcal{G}}(y_j|h_z) = \\frac{e^{w_{y_j}^T h_z + b_{y_j}}}{\\sum_{k=1}^{|\\mathcal{Y}|} e^{w_k^T h_z + b_k}},\\qquad(3\\]\nwhere \\(h_z = \\mathcal{G}(x)\\) signifies the hidden state of the last block at the final position for \\(x\\). \\(w_k\\) and \\(b_k\\) are the weight vector and bias corresponding to the final fully connected layer for the \\(k\\)-th token."}, {"title": "3.2 Demonstration Augmentation", "content": "Recognizing the established efficacy of data augmentation in machine learning (Feng et al., 2021), this study investigates demonstration augmentation and suggests enhancing the deep features of demonstrations by transforming them along semantic directions sampled from the deep feature space of demonstration examples. This strategy is motivated by the intriguing observation that the deep features in networks are often linearized (Bengio et al., 2013; Chen et al., 2022a). Building on this observation, we hypothesize that \\(h_z\\) lies within the subspace spanned by \\(h_c\\) and \\(h_x\\): \\(h_z = \\alpha h_c + \\beta h_x\\), where \\(h_c\\) and \\(h_x\\) represent the components of \\(h_z\\) linked respectively to the demonstrations and the query. The necessity of this assumption stems from intricate relationships among token representations and the exclusive augmentation of the component related to demonstrations. Notably, this decomposition is not necessary in practical applications. In the subsequent text, we directly refer to \\(\\alpha h_c\\) and \\(\\beta h_x\\) as \\(h_c\\) and \\(h_x\\).\nTo augment \\(h_c\\), we randomly sample vectors from the deep feature space of demonstrations. In particular, vectors are drawn from a multivariate normal distribution \\(\\mathcal{N}(\\mu, \\Sigma)\\), where \\(\\mu\\) and \\(\\Sigma\\) denote the feature mean and covariance matrix. These statistical properties are estimated from the deep features of the demonstration set \\(\\mathcal{D}\\), which includes demonstration examples linked to all queries. The feature mean \\(\\mu\\) is computed as\n\\[\\mu = \\frac{1}{|\\mathcal{D}|} \\sum_{i=1}^{\\mathcal{D}} h_i,\\qquad(4\\]\nwhere \\(h_i = \\mathcal{G}(c_i)\\) represents the hidden state of the last block at the final position for the \\(i\\)-th demonstration example \\(c_i\\) in \\(\\mathcal{D}\\), and \\(|\\mathcal{D}|\\) denotes the size of"}, {"title": "3.3 Novel Prediction Function", "content": "Selecting the answer with the highest probability is equivalent to favoring the answer with the lowest inverse probability. Therefore, the prediction can be determined by\n\\[\\hat{y} = \\arg \\min_{y_j \\in \\mathcal{Y}} P_{\\mathcal{G}} (y_j | h_z)^{-1}.\\qquad(7\\]\nAssume that each \\(h_c\\) is augmented for \\(M\\) times, resulting in an augmented demonstration feature set \\(\\{h_c^1, \u2026, h_c^M\\}\\) with size \\(M\\). Here, \\(h_c^i\\) represents the \\(i\\)-th augmented feature for \\(h_c\\). Then, the final prediction for the query \\(x\\) depends on all augmented features of \\(h_c\\) and can be expressed as\n\\[P^M(x) = \\frac{1}{M} \\sum_{i=1}^M P_{\\mathcal{G}}(y_j | h_c^i, h_x),\\qquad(8\\]\n\\[\\hat{y} = \\arg \\min_{y_j \\in \\mathcal{Y}} P^M(x).\\qquad(9\\]\nGiven that the performance of ICL benefits from an increased number of demonstration instances (Liu et al., 2022; Wu et al., 2023), we explore the scenario of augmenting an infinite number of times for the deep representation of demonstrations. Subsequently, an easily computable surrogate for the expected prediction can be derived, resulting in a highly efficient implementation. The whole pipeline of IDAICL is depicted in Figure 2.\nAs \\(M\\rightarrow\\infty\\), on the basis of the aforementioned decomposition of \\(h_z\\), the expected prediction for answer \\(y_j\\) (denoted as \\(P_{y_j}^M\\)) within the augmented feature set can be expressed as follows:\n\\[P_{y_j}^M (x) = \\mathbb{E}[e^{w_{y_j}^T (h_c+h_x)+ \\Delta b_{k,y_j}}],\\qquad(10\\]\nwhere \\(\\Delta w_{k,y_j} = w_k - w_{y_j}\\) and \\(\\Delta b_{k,y_j} = b_k - b_{y_j}\\). However, accurately calculating \\(P_{y_j}^M\\) is challenging. Alternatively, we proceed to derive a surrogate calculation for it. Applying the linearity of expectation, Eq. (10) can be expressed as:\n\\[P_{y_j}^M (x) = \\sum_{k=1}^{|\\mathcal{Y}|}  \\mathbb{E} [e^{\\Delta w_{k,y_j}^T (h_c+h_x)+ \\Delta b_{k,y_j}}].\\qquad(11\\]\nGiven that \\(h_c\\) is a Gaussian random variable conforming to \\(\\mathcal{N} (h_c + \\lambda\\mu, \\lambda\\Sigma)\\), we know that \\(\\Delta w_{k,y_j}^T h_c\\) follows the multivariate normal distribution: \\(\\mathcal{N} (\\Delta w_{k,y_j}^T (h_c + \\lambda\\mu), \\Delta w_{k,y_j}^T \\Sigma \\Delta w_{k,y_j})\\). Then, utilizing the moment-generating function\n\\[\\mathbb{E}[e^{tX}] = e^{t\\mu+\\frac{1}{2}t^2\\sigma^2}, X \\sim \\mathcal{N}(\\mu, \\sigma^2),\\qquad(12\\]\nEq. (11) can be derived as\n\\[P_{y_j}^M (x) = \\sum_{k=1}^{|\\mathcal{Y}|} M_{k,y_j} N_{k,y_j} e^{\\Delta w_{k,y_j}^T \\hat{h} + \\Delta b_{k,y_j}},\\qquad(13\\]\nwhere \\(M_{k,y_j} = exp(\\lambda w_{k,y_j}^T \\mu)\\) and \\(N_{k,y_j} = exp(\\Delta w_{k,y_j}^T \\Sigma \\Delta w_{k,y_j})\\). Subsequently, our newly proposed prediction function, referred to as IDA-Softmax, is defined as\n\\[P_{IDA}^M (x) := \\sum_{k=1}^{|\\mathcal{Y}|} M_{k,y_j} N_{k,y_j} e^{\\Delta w_{k,y_j}^T \\hat{h} + \\Delta b_{k,y_j}}.\\qquad(14\\]\nConsequently, instead of conducting the augmentation process explicitly, we can directly employ IDA-Softmax, \\(P_{IDA}^M\\), for prediction. IDA-Softmax essentially utilizes two modulating factors associated with statistical properties derived from \\(\\mathcal{D}\\) to calibrate the sample logits. Previous studies (Min et al., 2022c; Chan et al., 2022) have underscored the pivotal role of knowledge about the input data distribution in predictions made by PLMs. Intuitively, PLMs can better capture the patterns and underlying structures within data, such as the spatial relationships between demonstrations and queries, ultimately enhancing their prediction performance. Furthermore, to mitigate the imbalance among different answer types in demonstrations (Holtzman et al., 2021; Zhao et al., 2021), we adopt a post-hoc adjustment approach inspired by Menon et al. (2021), which adjusts predictions by considering the class proportions within \\(\\mathcal{D}\\). Thus, the prediction for answer \\(y_j\\) is computed as\n\\[P_{IDA}(x) = P_{IDA}^M (x) + \\tau \\log \\pi_{y_j},\\qquad(15\\]\nwhere \\(\\tau\\) is a positive hyperparameter, and \\(\\pi_{y_j}\\) denotes the proportion of answer \\(y_j\\) in \\(\\mathcal{D}\\). In practical applications, the value of \\(\\tau\\) can be fixed at 1."}, {"title": "4 Experimental Setup", "content": "and Wu, 2023b;\nZhou et al., 2022). We depicted the confusion ma-\ntrices for the SST-2 and MR datasets under two levels\nof imbalance in Figures 9(c) and (d), in which the\nproportion of the negative class in demonstrations\nis set to 0.1 and 0.2. These results manifest that\nIDAICL significantly enhances the performance\nof the underrepresented classes in comparison to"}, {"title": "4.1 Models and Datasets", "content": "We evaluated the performance of IDAICL across seven large PLMs, including GPT-2 (Radford et al., 2019) (with 0.1B, 0.3B, 0.8B, and 1.5B parameters), GPT-Neo (Black et al., 2021) (with 2.7B parameters), and LLaMA (Touvron et al., 2023) (with 13B and 33B parameters). Following previous research (Min et al., 2022a; Han et al., 2023; Lu et al., 2022), our evaluation encompasses ten text classification datasets. Among these, SST-2 (Socher et al., 2013), SST-5 (Socher et al., 2013), MR (Pang and Lee, 2005), CR (Hu and Liu, 2004), and Amazon (McAuley and Leskovec, 2013) are five sentiment classification tasks. Subj (Pang and Lee, 2004), TREC (Voorhees and Tice, 2000), DBPedia (Lehmann et al., 2015), and AGNews (Zhang et al., 2015) cater to subjectivity, question, ontology, and news classification tasks, respectively. Additionally, CB (De Marneffe et al., 2019) is utilized for natural language inference. Among these datasets, SST-5, Amazon, TREC, and CB are characterized by imbalanced training data. Details of all datasets are provided in Section A of the Appendix."}, {"title": "4.2 Compared Baselines", "content": "Besides Vanilla ICL, we compared and integrated IDAICL with three popular ICL algorithms, focusing on learning process design and demonstration retrieval. These include MetaICL (Min et al., 2022b), Channel ICL (Min et al., 2022a), and Efficient Prompt Retrieval (EPR) (Rubin et al., 2022). Moreover, we compared IDAICL with other ad"}, {"title": "5 Experimental Results", "content": "versarial prediction calibration methods: Contextual Calibration (ConCa) (Zhao et al., 2021), Prototypical Calibration (PROCA) (Han et al., 2023), and Domain-Context Calibration (D-ConCa) (Fei et al., 2023). Introductions to all compared methods and comprehensive experimental settings are presented in Sections B and C of the Appendix."}, {"title": "5.1 Main Results", "content": "Table 1 displays the comparison results between IDAICL and four ICL baselines (Vanilla ICL, MetaICL, Channel ICL, and EPR) across GPT-2 models (with 0.8B and 1.5B parameters) and the GPT-Neo model. These results lead to three main findings. Firstly, IDAICL consistently exhibits high effectiveness across various model sizes and datasets, highlighting its strong generalization capacity, even under scenarios involving imbalanced training data. Compared to Vanilla ICL, IDAICL outperforms by an average of 17.7% and 18.4% across diverse datasets and m values for GPT-2 with 0.8B and 1.5B parameters, respectively. Secondly, in comparison to other ICL baselines like Channel ICL, MetaICL, and EPR, the integration of IDAICL consistently delivers notable performance improvements, emphasizing the efficacy of enhancing demonstrations for refined predictions. The inclusion of IDAICL led to an average performance boost of 7.3% for MetaICL and 8.2% for Channel ICL. Lastly, IDAICL notably enhances worst-case accuracy and diminishes performance variance across different seeds, showcasing its ability to improve prediction stability. Additional results on LLAMA and smaller GPT-2 models are available in Tables 7 and 8 of the Appendix."}, {"title": "5.2 Comparison with Calibration Methods", "content": "We compared IDAICL with three advanced prediction calibration methods (ConCa, PROCA, and D-ConCa) across three PLMs: GPT-2, GPT-Neo, and LLaMA. Table 2 presents the comparison results for the LLaMA models, where IDAICL consistently achieves state-of-the-art performance, except for TREC using the LLaMA model with 33B parameters. These findings suggest that IDAICL which leverages statistical information derived from the input data distribution for prediction calibration, generally outperforms methods relying on estimated biases for correction. Further comparison results can be found in Table 9 of the Appendix."}, {"title": "5.3 Stability Analysis", "content": "Previous studies (Zhao et al., 2021; Sorensen et al., 2022; Min et al., 2022a; Zhang et al., 2022b) have highlighted the considerable variability in ICL's performance. In this section, we verified that IDAICL can effectively enhance performance stability across diverse scenarios.\nVarying numbers of demonstrations We have presented the results across different numbers of demonstrations in Table 1. For a clearer depiction, the outcomes regarding GPT-Neo are illustrated in Figure 3. As the number of demonstration examples (represented by m) increases, both Vanilla ICL and IDAICL exhibit improved performance, emphasizing the importance of comprehensive statistical properties of the input data for IDAICL's effectiveness. Notably, IDAICL significantly enhances performance stability across various numbers of demonstrations and consistently outperforms Vanilla ICL. The performance improvement is particularly pronounced when m takes on smaller values, indicating the efficacy of IDAICL in enriching the available knowledge for PLMs.\nVarying demonstrations To confirm that augmenting demonstrations can enhance the robustness of the ICL strategy across various demonstrations, we investigated three distinct demonstration selection settings. Setting I: Training samples most similar to the test sample are chosen. Setting II: Samples are randomly selected from the training data. Setting III: Training samples exhibiting the greatest dissimilarity from the test sample are selected. As shown in Figures 4(a) and (b), IDAICL significantly outperforms Vanilla ICL and demonstrates greater robustness across the three selection settings. Additionally, our discoveries suggest that selecting demonstrations that are more similar to the test samples leads to better performance than exclusively selecting dissimilar ones, which aligns with the findings obtained by Wang et al. (2022).\nVarying templates To assess the performance of IDAICL across various templates, we employed fifteen templates on the SST-2 dataset following those outlined by Zhao et al. (2021). The templates are elaborated in Table 10 of the Appendix. Figures 4(c) and (d) display the performance of Vanilla ICL and IDAICL across six templates. Some templates achieve higher average performance than others. Nevertheless, IDAICL consistently enhances both average and worst-case accuracy, simultaneously reducing performance variance across different templates. The complete results are available in Figure 7 of the Appendix.\nImpact of imbalance in labels Figures 5(a) and (b) depict comparison results among Vanilla ICL, MetaICL, Channel ICL, and IDAICL across different degrees of imbalances. It is evident that the performance of Vanilla ICL is sensitive to class imbalance, while that of IDAICL and Channel ICL exhibit robustness to the imbalance. Moreover, notable performance improvements are observed with higher levels of imbalance. Additionally, Figures 5(c) and (d) illustrate the confusion matrices for CR and Subj datasets, with the proportion of one category (i.e., \"Negative\" and \"Subjective\") in demonstrations setting to 0.1 and 0.2. IDAICL significantly improves the accuracy of the underrepresented classes when compared to Vanilla ICL, thereby contributing to enhanced fairness among classes. In the subsequent section, we demonstrate that the strong performance of IDAICL in handling imbalanced label distributions stems from both the statistical properties and the class proportion term."}, {"title": "5.4 Sensitivity and Ablation Studies", "content": "the"}]}