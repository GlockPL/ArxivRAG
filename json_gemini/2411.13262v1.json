{"title": "FASTNav: Fine-tuned Adaptive Small-language-models Trained for Multi-point Robot Navigation", "authors": ["Yuxuan Chen", "Yixin Han", "Xiao Li"], "abstract": "With the rapid development of large language models (LLM), robots are starting to enjoy the benefits of new interaction methods that large language models bring. Because edge computing fulfills the needs for rapid response, privacy, and network autonomy, we believe it facilitates the extensive deployment of large models for robot navigation across various industries. To enable local deployment of language models on edge devices, we adopt some model boosting methods. In this paper, we propose FASTNa\u03bd a method for boosting lightweight LLMs, also known as small language models (SLMs), for robot navigation. The proposed method contains three modules: fine-tuning, teacher-student iteration, and language-based multi-point robot navigation. We train and evaluate models with FASTNav in both simulation and real robots, proving that we can deploy them with low cost, high accuracy and low response time. Compared to other model compression methods, FASTNav shows potential in the local deployment of language models and tends to be a promising solution for language-guided robot navigation on edge devices.", "sections": [{"title": "I. INTRODUCTION", "content": "The adoption of robots has significantly expanded across various domains, including medical, household, and industrial sectors, driven by the rapid advancements in robotics technology. However, traditional robot control methods are limited to simple tasks and are inadequate for handling complex environments and tasks described in natural language. Large language models (LLMs) such as ChatGPT and Llama have demonstrated exceptional natural language processing and logical reasoning abilities, highlighting their potential for en- hancing robot navigation. Current approaches predominantly depend on API calls to leverage LLMs, which pose challenges in terms of privacy protection and real-time responsiveness, thereby limiting their practical application. In this work, we try to address the following question: \u201ccan we develop a robot navigation system based on language models that (1) is lightweight and deployable locally, and (2) is computationally inexpensive while exhibiting high performance for complicated navigation tasks?\u201d\nRecently, with the integration of robot control and LLMs, many innovative ideas have emerged. Some zero-shot or few-shot methods that use pre-trained models for navigation without the need for fine-tuning or annotating data [1] [2] have emerged. Additionally, there are methods that use spatial map representations to directly combine pre-trained visual- linguistic features with 3D reconstructions of the physical world [3]. While these methods excel in perceiving the real world, they exhibit inefficiencies in the LLM component, as indicated by the \"fast-forward\" signs frequently seen in demonstration videos. By reducing the size and complexity of large models, model compression methods can significantly decrease computational load and inference time, offering a promising solution to address those inefficiencies. Addition- ally, these techniques enable the deployment of lightweight models on edge devices, ensuring more efficient resource us- age without sacrificing too much performance. However, when compressing, most of these methods require long running times and high computing power and do not perform well for specific tasks.\nTo solve all these problems above, we propose a technology of model boosting. We draw inspiration from model com- pression, leveraging knowledge transfer from LLMs to small language models (SLMs) through prompting and feedback. This way enhances the capabilities of the smaller model while preserving its lightweight nature. Our approach involves first fine-tuning the SLMs using domain-specific datasets and then applying a teacher-student iteration module to further improve their performance. This enables SLMs to achieve performance levels close to those of much larger models in robot navigation tasks, while also offering high feasibility for practical deployment. \nTo address the challenge of deploying language models locally on robots, we select smaller models and fine-tune them with LoRA [4]. This enhances the models' inference speed and accuracy without requiring extensive prompt engineering. Additionally, we design a teacher-student iteration module to enable the models to continuously learn from navigation tasks. To summarize our contributions, we"}, {"title": "II. RELATED WORK", "content": "Using LLMs for robot navigation has become a significant research field in robotics control technology, significantly impacting autonomous driving technologies. Target navigation points can be determined based on users' instructions using vision [5], landmark [6], olfaction [7] and large language model technologies [8] [9]. In recent years, technologies com- bining LLMs with visual modules have been widely used in robot navigation [10] [1], showing excellent results. However, constrained by the parameter sizes of small models, these methods do not show significant improvements on local small models.\nApplying LLMs to planning tasks represents a growing area of research aimed at enhancing the capabilities of au- tonomous agents. Some methods leverage LLMs to translate planning problems into Planning Domain Definition Language (PDDL) format, achieving strong performance on specific tasks [11] [12]. Some other approaches use Signal Temporal Logic (STL) as an intermediate representation, endowing LLMs with much stronger reasoning and planning capabilities than natural language alone [13]. Even so, these methods face challenges such as high computational costs, slow response times, and limited adaptability in complex environments.\nModel compression methods for LLMs are already nu- merous. Pruning reduces the size and computational cost of a neural network by removing less important weights or neurons while attempting to preserve the model's performance [14] [15]. Knowledge distillation transfers the knowledge from a large model (teacher model) to a smaller model (student model), enabling the smaller model to achieve comparable performance [16] [17]. Quantization compresses a model by reducing the precision of its weights and activations, typically by converting them from floating-point to lower-bit represen- tations, thereby saving memory and computational resources [18] [19]. Low-rank factorization approximates the weight matrices of a model with lower-rank matrices, reducing the number of parameters and computational complexity without significantly degrading performance [20]. However, most of these methods require long running times and high computing power requirements, and do not perform well for specific tasks.\nNavigation with SLMs can speed up operation and benefit privacy protection. Research on controlling robots with local SLMs is rare, and methods to improve the performance of local small models are scarce. To fill this gap, we start to attempt related research. We aim to enhance the performance of local models through various comprehensive methods, including fine-tuning language models using datasets, supporting them with prompt engineering, and exploring the limits of local SLMs' performance using the teacher-student iteration, to improve accuracy in multi-target navigation tasks."}, {"title": "III. BACKGROUND", "content": "A. Parameter-Efficient Fine-Tuning Based on LoRA\nA key issue with SLMs is their limited logical reasoning and analytical capabilities. Additionally, their output format may not be robust enough for direct application to domain- specific tasks. Therefore, it is important to fine-tune SLMs to adapt them to the specific domain of robot navigation. Some researches [21] [22] have shown that with appropriate fine-tuning, SLMs can achieve performance close to that of LLMs.\nThe fine-tuning method we use is LoRA[4], Low-Rank Adaptation of LLMs, which is an innovative method for parameter-efficient fine-tuning.\nLORA represents parameter updates \u0394W with a much smaller set of parameters compared to the full set \u0398. This is done by using a low-rank matrix to encode the weight update \u0394W as:\n$W_0 + \\Delta W = W_0 + BA$ \nwhere $W_0$ is the pre-trained weight matrix, $B \\in R^{d \\times r}$, and $A \\in R^{r \\times k}$, with $r < min(d, k)$. During training, $W_0$ is kept frozen, and only A and B are updated.\nB. Language Navigation for Robots\nWe conceptualize the Language Navigation for Robot prob- lem as follows: Given a natural language command W, comprised of a sequence of words $w_1, w_2, w_3, ..., w_{nw}$, the language model is tasked with making navigation decisions based on a pre-constructed map representation M. Upon receiving the command, the model leverages M to determine a series of target waypoints that define the navigation path.\nThe decision-making process can be formalized by the function f, which maps the language command and the map information to the sequence of waypoints: $f(W,M) = {P_1,P_2,...,P_n}$, where each $p_i$ is a coordinate or identifier for a location on the map M.\nThe primary objective of the language model is to optimize the sequence of waypoints such that it accurately reflects the intent of the language directive while adhering to the constraints and affordances of the map M. Therefore, the most critical formula representing the decision-making function in isolation is:\n$f(W, M) = {P_1,P_2,...,P_n}$ \nThis function encapsulates the essence of this problem, translating a linguistic input into a navigational output within the context of a given spatial representation."}, {"title": "IV. PROBLEM DEFINITION AND APPROACH", "content": "Our goal is to fetch a lightweight SLM that performs well for robot navigation tasks by fine-tuning and teacher- student iteration. Formally, the input is a natural language task description L and map information M, and the output is a sequence of target coordinates $T = {t_1, t_2,...,t_k}$ arranged in order.\nFirst, we fine-tune the SLM $f_{\\theta}(L, M)$, where L is the task description and M is the map data. The goal here is to minimize the fine-tuning loss $\\mathcal{L}_{FT}$, ensuring the model can accurately predict the sequence of target coordinates $T = {t_1, t_2,...,t_k}$ for navigation.\nOnce fine-tuning is complete, we improve the SLM by learning from a larger model for (L, M). This process tries to reduce both the task-specific loss $\\mathcal{L}_{FT}$ and the knowledge distillation loss $\\mathcal{L}_{TS}$, allowing the small model to refine its predictions based on the larger model's output.\nOur approach ensures the small model can effectively gener- ate robot navigation paths from natural language descriptions and map data. It is assumed that most objects' positions on the map (including landmarks) remain stable, though it allows for the possibility of small, dynamic obstacles. By combining fine-tuning with knowledge from the larger model, we aim to enhance the small model's performance while maintaining its efficiency for real-world tasks."}, {"title": "V. FASTNAV", "content": "In this section, we present the general structure of our approach. FASTNav is divided into three main sections: (1) fine-tuning of small language models; (2) teacher-student iteration and (3) robot navigation controller. Figure 2 provides a general overview of the structure.\nConsidering the shortcomings that SLMs have when dealing with specific tasks, a fine-tuning process is needed to adapt them to the specific domain of robot navigation.\nDuring the fine-tuning process, the expected output of language models is a JSON format context that includes explanation and positions. The explanation is a string that shows the model's analysis and reasoning about the task, making it easy to understand its thought process and to see"}, {"title": "C. Robot Navigation Controller", "content": "In our current setup, SLMs serve as task planning tools, taking map landmarks (coordinates and attributes) and task descriptions as input. They generate an ordered sequence of target coordinates, which low-level navigation algorithms use to move the robot. The inputs and outputs of the SLMs can be seen in Figure 1 and Figure 2. Thus, after gaining the list of goal points from the language model, a robot navigation controller is required to direct the robot toward the points and update the planned path in real-time.\nHere we choose Navigation2 [27], a modular navigation framework. We extract the list of goal points from the SLM's output and put it into Navigation2. The Nav2 controller then helps the robot navigate from the initial position to the expected points sequentially according to the list.\nWith all of these components, FASTNav is able to finish the entire navigation process. It receives a task command described in natural language, analyses the task logically, and navigates the robot to the right points sequentially."}, {"title": "VI. EXPERIMENTS AND RESULTS", "content": "Environment and Dataset. We use a virtual environment for simulation and two real environments for testing the robot. The simulation environment employs a hospital scenario [28], in which we design approximately 1400 tasks. These tasks are distributed with single goal-point tasks, two-goal-point tasks, three-goal-point tasks, and multiple (four or more) goal-point tasks in a ratio of 1:3:2:1. We use the data to fine-tune the model and additionally design about 100 tasks as a test set.\nWe use the corridor of our laboratory and a complex building as the real environments. Considering the limitations\nImplementation Details. An NVIDIA GeForce RTX 4090 is used for model fine-tuning and iteration. For simulation experiments, we select a TurtleBot3 Waffle. For robot experi- ments, we choose Direct Drive Tech's DIABLO, a direct-drive, wheel-footed robot. We deploy our system on the robot using an NVIDIA Jetson Orin NX 16GB as an edge device.\nMethods of Evaluation. We evaluate our method and com- parison cases in terms of accuracy, efficiency and robustness. We choose 4 metrics to evaluate our method: Success Rate (SR), Navigation Error (NE), Average Time (AT), Moving Time Ratio (MTR).\n$SR= \\frac{1}{n} \\sum_{i=1}^{n} S_i$\n$NE = \\frac{1}{n} \\sum_{i=1}^{n} d(g_i, \\hat{g_i})$\n$AT = \\frac{1}{n} \\sum_{i=1}^{n} T_i$\n$MTR = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{T_{mi}}{T_i}$\nIn Equation 3, Si is a flag for each task's success or failure. Si is 1 if the task succeeds and 0 if it fails. In Equation 4, \u011di is the estimated value of the i-th goal point, and gi is the ground truth of the i-th goal point. d(\u011di, gi) means the distance between \u011di and gi. In Equation 5, T\u2081 is the time spent finishing each task. As for Equation 6, Tmi is the time spent by the robot to move while executing the i-th task. We denote MTR by the ratio of Tmi to Ti.\nComparison cases. Five SLMs and other compression methods are used for comparison. Due to hardware perfor- mance and energy consumption constraints, running LLMs with over 10B parameters on edge devices is difficult, so we select SLMs with fewer than 3B parameters. We choose 5 SLMs that perform well on public benchmarks accord- ing to the Open LLM Leaderboard on HuggingFace, as shown in Table I. Some models obtained through quantization and knowledge distillation were also selected. Quantization method GTPQ [18] is used on Llama3-8B [29] and Mistral- 7B [30], while an int4 version of Qwen-7B-Chat [31] and MiniMA-3B [32] that is distilled from LLaMA2-7B are also selected.\nTo compare FASTNav with other LLM-based planning and navigation methods, we design three comparison setups and compare them with FASTNav in our simulation environ- ment. LLM+P [11] integrates LLMs with classical planners by converting natural language tasks into Planning Domain Definition Language (PDDL) for task-solving, then translating the solution back into natural language. AutoTAMP [13] uses LLMs to translate tasks into signal temporal logic (STL), which a task and motion planner (TAMP) uses to generate motion plans. LLM-As-Task Planner [13] lets LLMs directly generate subtasks from instructions, with motion planning handled by a separate algorithm.\nB. Results and discussion\nWe start by testing the inference speed and computational resource usage of several lightweight language models on the"}, {"title": "VII. CONCLUSION", "content": "In this work, we propose FASTNav, which represents fine- tuned adaptive small language models trained for multi-point robot navigation. This method includes three modules: fine- tuning, teacher-student iteration, and robot navigation con- troller. It is shown that SLMs can remain lightweight and have great performance close to much larger models in spe- cific domains with FASTNav. We believe that FASTNav can greatly release the potential of SLMs and drive the widespread application of LLM technologies at the edge end."}, {"title": "C. Limitations", "content": "FASTNav currently focuses on language models, missing other multimodal information like vision.\nFASTNav needs a large amount of data for fine-tuning, which is not always easy to get.\nFASTNav is primarily task-oriented, requiring specific fine-tuning and iteration for each different task environ- ment.\nIn the future, we aim to explore the lightweight compression of multimodal language models that can process both visual and textual information, allowing our method to address more complex tasks by leveraging richer environmental data. Ad- ditionally, we plan to refine the structure of our approach to enhance its few-shot learning capability, reducing its reliance on extensive fine-tuning. This will improve its adaptability to diverse environments and enable it to perform well even with limited task-specific training data."}]}