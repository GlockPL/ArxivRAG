{"title": "Cross-Institutional Structured Radiology Reporting for Lung\nCancer Screening Using a Dynamic Template-Constrained\nLarge Language Model", "authors": ["Chuang Niu", "Parisa Kaviani", "Qing Lyu", "Mannudeep K. Kalra", "Christopher T. Whitlow", "Ge Wang"], "abstract": "High-quality structured radiology reports are advantageous to optimize clinical workflows and\npatient outcomes. Current LLMs in creating structured reports face the challenges of formatting\nerrors, content hallucinations, and privacy leakage concerns when uploaded to external servers.\nTo develop an enhanced open-source LLM for creating structured and standardized LCS reports\nfrom free-text descriptions and establish its utility in nodule-level information retrieval and\nautomatic large-scale statistical analysis.", "sections": [{"title": "Background", "content": "High-quality structured radiology reports are advantageous to optimize clinical workflows and\npatient outcomes. Current LLMs in creating structured reports face the challenges of formatting\nerrors, content hallucinations, and privacy leakage concerns when uploaded to external servers."}, {"title": "Purpose", "content": "To develop an enhanced open-source LLM for creating structured and standardized LCS reports\nfrom free-text descriptions and establish its utility in nodule-level information retrieval and\nautomatic large-scale statistical analysis."}, {"title": "Materials and Methods", "content": "After institutional IRB approvals, 5,442 de-identified LCS reports from two institutions were\nretrospectively analyzed. 500 reports were randomly selected from the two institutions evenly and\nthen manually labeled for evaluation. Two radiologists from the two institutions developed a\nstandardized template including 29 features for lung nodule reporting. We proposed template-\nconstrained decoding to enhance state-of-the-art open-source LLMs, including LLAMA, Qwen,\nand Mistral. The LLM performance was extensively evaluated in terms of F1 score, confidence\ninterval, McNemar test, and z-test. Based on the structured reports created from the large-scale\ndataset, a nodule-level retrieval system was prototyped and an automatic statistical analysis was\nperformed. Our software, vLLM-structure, is publicly available for local deployment with enhanced\nLLMS."}, {"title": "Results", "content": "Our template-constrained decoding approach consistently enhanced the LLM performance on\nmulti-institutional datasets, with neither formatting errors nor content hallucinations. Our method\nimproved the best open-source LLAMA-3.1 405B by up to 10.42% (97.60% vs 87.18%; p-value <\n0.01 for all 29 features), and outperformed GPT-40 by 17.19% (97.60% vs 80.41%; p-value <\n0.01 for 27 out of 29 features). A novel nodule retrieval system was successfully prototyped and\ndemonstrated on a large-scale multimodal database using our enhanced LLM technologies. The\nautomatically derived statistical distributions were closely consistent with the prior findings in\nterms of nodule type, location, size, status, and Lung-RADS."}, {"title": "Conclusion", "content": "Our dedicated open-source LLM accurately created structured radiology reports for LCS across\ninstitutions, defining the state of the art in this domain. Its utility has been demonstrated in\nnodule-level information retrieval and automatic large-scale statistical analysis."}, {"title": "Abbreviations", "content": "LLM = Large Language Model, LCS = Lung Cancer Screening, LDCT = Low-Dose CT, GGN =\nGround Glass Nodule, JSON = JavaScript Object Notation, Cl = Confidence Interval"}, {"title": "INTRODUCTION", "content": "Structured and standardized reporting in radiology has been recognized to improve quality,\nconsistency, and actionability of radiology reports, leading to optimized clinical workflow and\npatient outcomes [1, 2]. Structured reports can be divided into two levels: structured layout (level-\n1) and structured content (level-2) [3]. Structured layout defines the report format to present\nfindings with subheadings in a specific order, such as lung nodules, lungs, pleura, heart, etc., in\nLCS. Structured content refers to writing contents with a set of predefined features, such as\nnodule type, lobe, margin, shape, size, etc., to describe lung nodules, and each feature has a set\nof predefined and standardized candidate values. Radiology reports contain rich information for\nresearch and clinical purposes. To effectively perform data mining, the radiology reports must be\nstructured at level-2 to provide standardized, discrete data elements easier to search and analyze\n[4]. Despite its various benefits, structured reporting (particularly at level-2) has still not been\nwidely adopted in clinical routine [5]. One of the major obstacles is that current structured reporting\nsoftware demands radiologists' use of the mouse and many clicks on checkboxes and other\ngraphical elements, distracting their attention from main tasks and reducing their productivity [6].\nRecent advancement in LLMs has provided unprecedented opportunities to create structured\nradiology report seamlessly in the radiological workflow. For example, GPT-4 was leveraged to\nconvert 170 free-text CT and MRI reports to structured reports at level-1 [7]. In a most recent\nstudy, GPT-3.5 and GPT-4 were prompted to create synoptic reports at level-1 from 180 original\nCT reports for pancreatic ductal adenocarcinoma, showing the GPT-4 performed better than GPT-\n3.5 and that surgeons demonstrated greater accuracy in categorizing respectability using the\nconverted reports compared to the original ones [8]. However, there has been no study so far\ndemonstrating the desired level-2 structured reporting with LLMs. Moreover, all these studies\nused the proprietary LLMs which require uploading radiology reports to the cloud server, raising\nprivacy concerns especially for large-scale studies [9]. This concern can be addressed by\ndeploying the latest and similarly powerful open-source Llama 3.1 with 405 billion parameters on\nthe local server [10]. Importantly, such an LLM can be further developed and adapted to specific\napplications with enhanced performance.\nThere are two main challenges when applying an LLM for structured reporting: formatting errors\nand content hallucinations. JSON is used as a standard format to output the structured contents\nby LLM, but LLMs cannot ensure that the JSON format is always correct, leading to failed\nconversions. On the other hand, the well-known hallucinations of all LLMs cannot be tolerated in\nthe healthcare applications [11]. These challenges must be overcome to establish an accurate\nand reliable LLM-based structured reporting. Additionally, while many initiatives were lunched to\npromote structured reporting, cross-institutional study on structured reporting is lacking [5]."}, {"title": "Dynamic Template-Constrained Decoding Method", "content": "To eliminate the formatting errors and content hallucinations of an LLM, we propose dynamic\ntemplate-constrained decoding for inference. The basic idea is to use a structured and\nstandardized template to constrain the LLM output. As shown in Figure 1, our LLM inference\nmethod takes the system instruction and the conventional report as input, uses the structured and\nstandardized template to strictly constrain every output token during decoding, and then produces\nthe structured report accordingly. Our approach is in sharp contrast to the existing studies, which\nfocus on designing the system instruction to prompt LLMs [12]. However, such prompting cannot\neliminate either formatting errors or content hallucinations.\nSpecifically, we designed a dynamic template-constrained decoding method shown in Figure 2.\nIn the common LLM inference process in Figure 2 (a), the concatenation of system instructions\nand free-text reports are first tokenized, the causal Transformer autoregressively calculates the\nprobability distribution over all tokens, then a sampling strategy is implemented to sample the next\ntoken, and finally the sampled token are converted to the output text, which is also appended to\nthe input token sequence for the next iteration. Our dynamic template-constrained inference is\nshown in Figure 2 (b), with the differences from the common inference highlighted in orange.\nBefore explaining the differences, let us introduce how to deal with the predefined template in\nTable 1. We represent the structured and standardized template in a dynamic JSON format with\nthree kinds of text: template format text without highlight, special template text highlighted in pink,\nand example candidate text highlighted in green, as shown in Figure 2 (c) and (d), respectively.\nEvery special text has a candidate set defined in Table 1. To handle varying numbers of nodules\nreported in different reports, the dynamic template is designed to dynamically determine and\ncreate the required number of nodule descriptors (the black box of Figure 2 (c) represents a single\nnodule descriptor) during inference.\nOur dynamic template-constrained decoding is detailed as follows. First, the concatenation of a\nsystem instruction, a free-text report, and a template text is tokenized. Here we added the special\ntemplate text into the tokenizer so that they can be recognized and localized in the template. The\ntemplate tokens include two parts: (1) the dynamic template tokens for the JSON template format\ntext and special template text, and (2) the candidate value tokens for each special template token.\nDuring the next token prediction, we deterministically choose the token with the maximum\nprobability over its candidate set. As shown in Figure 2 (c) and (d), the next token is\nautoregressively predicted along the order of dynamic template. The candidate set of the template\nformat token only contains itself so that the output is exactly the predefined format text, ensuring\nno JSON formatting errors. When a special template token is recognized, its candidate token set\nwill be used. For predicting tokens around \u201clobe\u201d in Figure 2 (d), there are seven predefined\ncandidates, and each candidate text has been tokenized into a sequence. All the seven candidate\nsequences are aligned from scratch. In predicting \u201cright lower lobe\u201d, the first token is selected\namong \"right\", \u201cleft\u201d, \u201cling\u201d and \u201cnull\u201d with the maximum probability. After the \"right\" token is chosen,\nall other candidate sequences without \u201cright\" will be ignored in predicting the subsequent tokens.\nThis process will be repeated until a compete candidate text is decoded. The number of nodule\ndescriptors will be predicted first to adjust the template by creating the required number of nodule\ndescriptors. When the predicted number of nodule descriptors is zero, the \u201cnodules\" part in the\nJSON template will be removed."}, {"title": "Software Development and Open-source LLMs", "content": "Our dynamic template-constrained method was implemented based on the vLLM project [13],\nwhich is an open-source library for LLM inference and serving. In principle, our method can be\napplied to any LLM while its implementation needs to modify the common inference architecture.\nWe studied its superiority on the most powerful open-source LLMs, including Llama-3.1 (8B, 70B,\n405B) [10], Qwen-2 (72B) [14], and Mistral-Large (123B) [15]. All these open-sourced models\nwere downloaded from Hugging Face with approval. We also evaluated GPT-40 on the Insitution-\n1-labeled dataset for comparison using the same system instruction. Due to the institutional policy,\nthe other two datasets in Table 2 are not allowed to be uploaded to any external sever to use\nproprietary LLMs. Since the source codes of GPT-40 is not publicly available, we cannot apply\nour method to it. The software development and experiments were conducted on a local server\nwith 8x H100 GPUs. To facilitate further research of LLMs in radiology, our vLLM-Structure\nsoftware, experimental scripts, example data, and tutorials have been released at\nhttps://github.com/niuchuangnn/vllm structure."}, {"title": "Automatic Creation of Structured and Standardized Radiology Reports", "content": "The performance of LLMs in automatically creating the level-2 structured reports are presented\nin Figures 1 and Figure 2 from the free-text report on the two institutional datasets, respectively.\nIn terms of the average performance over all lung nodule features, our method consistently\nimproved all the open-source LLMs, including LLAMA-3.18B by 18.42% (F1 score: 80.34% (95%\nCI: 77.91%-82.88%) vs 61.92% (95% CI: 58.74%-65.34%), LLAMA-3.1 70B by 5.34% (F1 score:\n89.44% (95% CI: 87.50%-91.44%) vs 84.10% (95% CI: 81.70%-86.57%), LLAMA-3.1 405B by\n10.42% (F1 score: 97.60% (95% CI: 96.54%-98.55%) vs 87.18% (95% CI: 84.93%-89.49%)),\nQwen-2 72B by 4.54% (F1 score: 87.50% (95% CI: 85.55%-89.61%) vs 82.96% (95% CI: 80.55%-\n85.50%)), Mistral-Large 123B by 7.07% (F1 score: 90.81% (95% CI: 88.94%-92.75%) vs 83.74%\n(95% CI: 81.39%-86.24%)), GPT-40 by 17.18% (F1 score: 97.60% (95% CI: 96.54%-98.55%) vs\n80.42% (95% CI: 77.87%-83.10%)) on the institution-1 dataset; and improved LLAMA-3.1 8B by\n15.26% (F1 score: 80.70% (95% CI: 78.25%-83.22%) vs 65.44% (95% CI: 62.25%-68.81%)),\nLLAMA-3.1 70B by 6.65% (F1 score: 90.16% (95% CI: 88.27%-92.00%) vs 83.51% (95% CI:\n81.11%-85.93%), LLAMA-3.1 405B by 5.53% (F1 score: 96.92% (95% CI: 95.76%-97.96%) vs\n91.39% (95% CI: 89.46%-93.21%)), Qwen-2 72B by 7.27% (F1 score: 86.84% (95% CI: 84.77%-\n88.86%) vs 79.57% (95% CI: 76.96%-82.12%)), Mistral-Large 123B by 3.89% (F1 score: 91.86%\n(95% CI: 90.12%-93.54%) vs 87.97% (95% CI: 85.84%-90.03%)) on the Institution-2 dataset."}, {"title": "Nodule-level Information Retrieval", "content": "Based on the structured reports created by the best LLM, a nodule-level feature retrieval system\nwas prototyped and tested on the 5192 LCS reports in the Institution-1 dataset. A retrieval\nexample is shown in Figure 5, where given the combination of retrieval features \u201cpart-solid\u201d AND\n\u201caverage diameter: \u226510 mm\u201d AND (\u201cincrease\u201d OR \u201cnew\u201d OR \u201cinterval development\u201d), 21 individual\nnodules were retrieved, 17 of which have the series and CT image location information and\ndisplayed. The associated original reports are also shown and the relevant contents are manually\nhighlighted."}, {"title": "Automatic Nodule-level Statistics", "content": "Our experiments demonstrated that nodule-level statistics can be automatically calculated from\nthe level-2 structured reports without any need for expensive labeling of original reports. The\nstatistics of different nodule features stratified by age and sex are summarized in Table 3. The\nstatistical results show that the number of the extracted nodules in the upper lobes is significantly\n(p-value < 0.01) greater than that in other lobes, the number of the right lung is significantly (p-\nvalue < 0.01) greater than that on the left lung, female had significantly more (p-value < 0.01)\nground glass nodules than male, the distribution Lung RADS scores over 0, 1, 2, 3, 4A, 4B, 4X\nare 1.0%, 22.4%, 66%, 4.6%, 3.2%, 1.6%, and 0.3%, respectively, where 0.8% reports did not\nprovide lung RADS scores. The size (average diameter) distributions of lung nodules over <6 mm,\n6~10 mm, 10~15 mm, \u226515 mm were 57.9%, 11.8%, 2.4%, and 1.0%, respectively, where 27%\nnodules did not have their sizes reported. Also, the results show that 1.2% nodules were\ndecreased, 2.2% were increased and 0.9% were interval development, 8.2% were new nodules,\nand 0.7% were resolved. All the above statistical results are closely consistent with the previous\nfindings [16-19]."}, {"title": "DISCUSSION", "content": "Increasing evidence has shown the importance of structured radiology reporting to optimize the\nradiological workflow and patient outcomes. One of the major hurdles to structured reporting at\nlevel-2 is lacking an efficient and effective IT tool. Without disrupting radiologists' attention and\nhabit, our enhanced LLM-based system can accurately and automatically create the level-2\nstructed reports from the free-text descriptions.\nCurrent LLM inference cannot ensure the successful creation of the predefined structured report\nbecause of lacking a mechanism to eliminate formatting errors and content hallucinations. In\ncontrast, our dynamic template-constrained encoding cannot only handle varying numbers of\nreported nodules in a dynamic template but also ensure zero formatting errors and no content\nhallucinations. On the other hand, most of the existing studies used proprietary LLMs, e.g., GPT-\n4, which requires uploading reports to the cloud server with major privacy concerns. Because of\nthe policy and cost, these studies were conducted on relatively small datasets. Fortunately, the\nlatest Llama 3.1 model with 405 billion parameters released on July 23, 2024, has competitive a\nperformance with proprietary LLMs. Our developed software, vLLM-structure, can locally deploy\nthe best open-source LLM, and enable large-scale studies without privacy concerns. Importantly,\nour method significantly and consistently improved existing models on cross-institutional datasets.\nThe best accuracy of our enhanced LLM achieved ~97% F1 score on both institution datasets.\nConsidering that dynamic templating for lung nodule reporting is complex, achieving such a high\naccuracy has strongly demonstrated the feasibility of using our LLM-based tool for structured\nradiology reporting at level-2.\nThanks to the standardized and quantified items in structured reporting, large-scale data mining\nbecomes easy. We have shown two use cases of structured radiology reports in nodule-level\nfeature retrieval and automatic statistical analysis. The inputs can be any combination of nodule\nfeatures, then all individual nodules and the associated images will be retrieved. Additionally, more\nelectronic medical records could be linked with the structured radiology reports to build more\nadvanced systems. Our nodule-level retrieval system may be used for diagnosis, therapy,\nresearch, teaching, and other purposes. Furthermore, we have conducted an automatic statistical\nanalysis on a large-scale LCS report dataset. The high evaluation accuracy and the consistent\nstatistical results to prior findings suggest the effectiveness and reliability of LLM-based statistics.\nPromisingly, large-scale multi-institutional statistics on historical data become straightforward\nthough LLM-based structured reporting. Moreover, quantitative data of the structured reports can\nbe directly used for training and validating Al models on large-scale datasets [20, 21]."}, {"title": "CONCLUSION", "content": "In conclusion, we have proposed a dynamic template-constrained LLM to create structured\nreports at level-2 from the free-text descriptions. Our method has achieved the state-of-the-art\naccuracy without formatting errors, content hallucinations, or privacy concerns. We have\ndemonstrated the workflow from building the standardized template to creating structured reports\nwith our developed software for LCS. The accuracy and superiority of LLMs with our inference\nmethod have been evaluated on cross-institutional datasets. We have successfully demonstrated\nthe utilities and merits of structured reporting in nodule-level retrieval and automatic statistical\nanalysis on a large-scale dataset. Our open-source software, vLLM-structure, is publicly available\nfor further translational research on structured radiology reporting."}]}