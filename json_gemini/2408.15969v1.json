{"title": "Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems", "authors": ["Ibrahim K. Ozaslan", "Panagiotis Patrinos", "Mihailo R. Jovanovi\u0107"], "abstract": "We examine stability properties of primal-dual gradient flow dynamics for composite convex optimization problems with multiple, possibly nonsmooth, terms in the objective function under the generalized consensus constraint. The proposed dynamics are based on the proximal augmented Lagrangian and they provide a viable alternative to ADMM which faces significant challenges from both analysis and implementation viewpoints in large-scale multi-block scenarios. In contrast to customized algorithms with individualized convergence guarantees, we provide a systematic approach for solving a broad class of challenging composite optimization problems. We leverage various structural properties to establish global (exponential) convergence guarantees for the proposed dynamics. Our assumptions are much weaker than those required to prove (exponential) stability of various primal-dual dynamics as well as (linear) convergence of discrete-time methods, e.g., standard two-block and multi-block ADMM and EXTRA algorithms. Finally, we show necessity of some of our structural assumptions for exponential stability and provide computational experiments to demonstrate the convenience of the proposed dynamics for parallel and distributed computing applications.", "sections": [{"title": "I. INTRODUCTION", "content": "We study the composite constrained optimization problems of the form\n$\\displaystyle \\begin{aligned}\n\\underset{x, z}{\\text{minimize}} \\quad & f(x) + g(z) \\\\\n\\text{subject to} \\quad & Ex + Fz-q = 0,\n\\end{aligned}$\n(1a)\nwhere $x \\in \\mathbb{R}^m$ and $z \\in \\mathbb{R}^n$ are the optimization variables, $E \\in \\mathbb{R}^{p \\times m}$, $F \\in \\mathbb{R}^{p \\times n}$, and $q \\in \\mathbb{R}^p$ are the problem data, and $f$, $g$ are the separable convex functions given by\n$\\displaystyle f(x) = \\sum_{i=1}^k f_i(x_i), \\quad g(z) = \\sum_{j=1}^l g_j(z_j).$\n(1b)\nBased on the partition of vectors $x = [x_1^T \\quad ... \\quad x_k^T]^T$ and $z = [z_1^T \\quad ... \\quad z_l^T]^T$, matrices $E$ and $F$ can also be partitioned conformably as $E = [E_1 \\quad ... \\quad E_k]$ and $F = [F_1 \\quad ... \\quad F_l]$. We assume feasibility of problem (1) and denote the set of its solutions by $P^*$. Furthermore, we let each function $f_i$ be convex with a Lipschitz continuous gradient (i.e., smooth) and each $g_j$ be closed proper convex (possibly nondifferentiable) function with efficiently computable proximal operators [1]. While we do not assume existence of any smooth terms in the objective function (i.e., we allow $k = 0$ in (1b)), if a smooth term exists it should be included in the $x$-block rather than in the $z$-block. This separation between smooth and nonsmooth parts of the objective function plays an important role in identifying weakest set of assumptions that are required to establish our results; it also alleviates cumbersome notation resulting from the introduction of auxiliary variables and demystifies the effect of nondifferentiable components on convergence properties of the underlying algorithms.\nOur analyses can be readily carried over to a more general setup in which problem (1) is formulated in a Hilbert space equipped with an inner product and the associated norm. In such cases, constraint matrices $E$ and $F$ are"}, {"title": "", "content": "replaced with bounded linear operators. Although we choose to work in the Euclidean space to keep the notation simple and streamline our analysis, we also discuss applications in which the optimization variables are matrices and provide computational experiments for two such applications.\nSince the function $g$ is allowed to be nondifferentiable, a wide range of constraints can be included into problem (1). In particular, convex constraints $x_i \\in X_i$ for some $i \\in \\{1, ..., k\\}$ can be easily incorporated into (1) by augmenting the objective function with the indicator function of the set $X_i$,\n$\\displaystyle I_{X_i}(x) := \\begin{cases} 0, & x \\in X_i \\\\\n+\\infty & \\text{otherwise}.\n\\end{cases}$\nFor example, linear inequality constraint $G_ix_i \\leq h_i$ can be handled by introducing a slack variable $z_{l+1} \\geq 0$, converting the inequality constraint to the equality constraint $G_ix_i + z_{l+1} = h_i$, and by adding the indicator function associated with the positive orthant $g_{l+1}(z_{l+1}) = \\mathbb{I}_{\\mathbb{R}_+}(z_{l+1})$ to the objective function in (1). Furthermore, even nondifferentiable convex inequality constraints can be included in (1) as long as the projection operator associated with the constraint set is easily computable. In addition to the constrained problems, unconstrained problems of form\n$\\displaystyle \\underset{x}{\\text{minimize}} \\quad f(x) + \\sum_{j=1}^l g_j(T_jx)$\n(2)\ncan also be brought into (1) by setting\n$\\displaystyle E = \\begin{bmatrix} T_1 \\\\\n T_2 \\\\\n ... \\\\\n T_l\n\\end{bmatrix}, \\quad F_j = \\begin{bmatrix} -I \\\\\n 0 \\\\\n ... \\\\\n 0\n\\end{bmatrix} , \\quad q = \\begin{bmatrix} 0 \\\\\n0 \\\\\n... \\\\\n 0\n\\end{bmatrix} , \\quad z_j = T_jx, \\quad j = 1,..., l.$\nOptimization problem (1) arises in a host of applications, ranging from signal processing and machine learning to statistics and control theory [2]; see Section II-A. Splitting methods facilitate separate treatment of different blocks in (1) and they provide an effective means for solving this class of problems. If the problem is properly formulated, these methods are also convenient for distributed computations and parallelization. For example, the Alternating Direction of Method of Multipliers (ADMM), which represents a particular instance of more general splitting techniques such as [3]\u2013[7], has attracted significant attention because of its straightforward and efficient implementation [2]. The convergence properties of the standard ADMM algorithm are well-understood for two-block problems with $k = l = 1$ in (1) [8]. However, the multi-block case with either $k > 1$ or $l > 1$ is much more subtle and without imposing strong assumptions it is difficult to maintain convergence guarantees [6], [7], [9] and computational convenience [10]. Although variable splitting can be used to bring the multi-block problem into the two-block setup [11], the subproblems can become difficult to solve and the efficiency is compromised because of a significant increase in the number of variables and constraints [12]. Even though various modifications have been proposed for the multi-block ADMM to circumvent strong assumptions that ensure convergence and computational convenience [10], [12]\u2013[14], in contrast to standard two-block ADMM the convergence properties of these variations remain unclear in certain scenarios. To the best of our knowledge, sufficient conditions ensuring linear convergence of these variations have not yet been established. Moreover, the empirical evidence suggests that these variations are much slower than the standard multi-block ADMM [15].\nThe primal-dual (PD) gradient flow dynamics offer a viable alternative to ADMM in terms of implementation: while ADMM requires explicit minimization, only the gradient of the Lagrangian is required to update iterates. Furthermore, in contrast to ADMM, the PD gradient flow dynamics are convenient for parallel and distributed computing even in multi-block problems without requiring any modifications relative to the two-block setup. They are thus appealing for large-scale applications and have attracted significant attention since their introduction as continuous-time dynamical systems in seminal work [16]. Recent effort centered on studying stability and convergence properties of PD gradient flow dynamics under various scenarios. Early results [17], [18] focused on the asymptotic stability of the PD gradient flow dynamics that are based on the Lagrangian associated with differentiable constrained problems. Some of these results have also been extended to general saddle functions [19]\u2013[21] and, in a more recent effort, the focus started shifting toward proving the exponential stability [22]\u2013[32] and the contraction [33]\u2013[35] properties. Also, advancements in Nesterov-type acceleration and design of second-order"}, {"title": "", "content": "PD algorithms have been made in [36]\u2013[38] and [39], respectively. In particular, [28] introduced a framework to bring the augmented Lagrangian associated with equality constrained convex problems into a smooth form even if the objective function contains nondifferentiable terms. This approach facilitates the use of the PD gradient flow dynamics for nonsmooth problems without resorting to the use of subgradients (which complicate the analysis and substantially slow down convergence).\nIn this paper, we introduce primal-dual gradient flow dynamics resulting from proximal augmented Lagrangian associated with problem (1). We study asymptotic and exponential stability properties of the underlying dynamics under three different sets of assumptions. Under these assumptions, the proposed dynamics have a continuum of equilibria, which introduces additional challenges for stability analyses relative to the setup with a unique equilibrium point. Our first set of assumptions is much weaker than existing restrictions that are introduced in stability analysis of various primal-dual gradient flow dynamics as well as in convergence analysis of ADMM and EXTRA [40] algorithms. Specifically, without requiring presence of any smooth or strongly convex terms in the objective function and without imposing any additional conditions on the constraint matrices, we show that the primal-dual dynamics are globally asymptotically stable even in the multi-block setup. In our second set of assumptions, we still allow the absence of smooth terms but restrict nonsmooth terms in the objective function to be either a polyhedral function (i.e., the epigraph of such a function can be represented as intersection of finitely many half-spaces) or group lasso penalty function. This allows us to introduce a novel Lyapunov function for establishing local exponential stability of the proposed dynamics and to extend this local result to the semi-global exponential stability; see Remark 1. This result allows us to guarantee exponentially fast global convergence in various challenging problems for which only subexponential rates have been established for gradient-based methods. In our third set of assumptions, we require presence of smooth terms in the objective function and impose additional conditions on the constraint matrices without restricting the class of nonsmooth terms in the objective function. In this setup, we prove the global exponential stability and show that our assumptions are weaker than the conditions used in the literature to prove the exponential stability of primal-dual gradient flow dynamics and linear convergence of ADMM. We then prove that one of the requirements on the constraint matrices indeed represents a necessary condition for global exponential stability of the proposed primal-dual gradient flow dynamics that cannot be relaxed without introducing any additional assumptions on the nonsmooth terms. Finally, in contrast ADMM, we show that the proposed dynamics are amenable to parallel and distributed computing even in multi-block problems without requiring any modifications relative to the two-block setup. Moreover, application of the proposed dynamics to consensus optimization problems leads to distributed implementation similar to those provided in EXTRA and its proximal variant PG-EXTRA [41] algorithms.\nRemark 1: Semi-global exponential stability implies global exponential convergence with a rate that depends on the initial distance to the equilibria; see [42, Section 5.10] for definition. While global exponential stability requires the convergence rate and associated constants to be independent of the initial conditions, global exponential convergence follows from a weaker stability notion (i.e., semi-global exponential stability); see (21) and (20), respectively. We also note that notions such as global linear (or geometric) convergence and Q-linear convergence that are used in optimization literature for discrete-time algorithms correspond to the semi-global exponential stability of the underlying nonlinear dynamics.\nThe rest of the paper is organized as follows. In Section II, we provide motivation and background material and introduce the primal-dual gradient flow dynamics. In Section III, we summarize our main results, discuss related work, and compare our findings with the existing literature. In Section IV, we prove main theorems; in Section V, we utilize computational experiments to demonstrate the merits of our analyses; and in Section VI, we conclude our presentation with remarks.\nNotation: We use $\\|\\cdot\\|$ and $(\\cdot, \\cdot)$ to denote the Euclidean norm and standard inner product, $\\sigma(A)$ and $\\underline{\\sigma}(A)$ to denote the largest and smallest nonzero singular values of a matrix $A$, $\\mathcal{N}(A)$ and $\\mathcal{R}(A)$ to denote the null and range spaces of $A$, respectively. We define the Euclidean distance between a point $\\psi$ and set $\\Psi$ as $\\text{dist}(\\psi, \\Psi) = \\min_{\\phi \\in \\Psi} \\|\\psi-\\phi\\|_2$.\nII. MOTIVATION AND BACKGROUND\nWe first provide the motivation and background for studying composite optimization problem (1) and then explain how to solve it. In Section II-A, we highlight problem instances that arise in applications. In Section II-B, we provide a brief overview of proximal operators and Moreau envelopes. In Section II-C, we introduce the augmented Lagrangian associated with problem (1) and derive the optimality conditions. In Section II-D, we employ the proximal operators and Moreau envelopes of nonsmooth terms to bring the augmented Lagrangian"}, {"title": "", "content": "into a continuously differentiable form that is referred to as the proximal augmented Lagrangian [28]. Finally, in Section II-E, we formulate the primal-dual gradient flow dynamics with a continuous right-hand-side to solve nonsmooth composite optimization problem (1).\nA. Motivating applications\nExample 1: Distributed optimization. Various problems in distributed optimization [2] including control and stabi-lization of power networks [43] and resource allocation in wireless systems [44] can be modeled as a special case of (1). For example, let us consider a regularized consensus problem in which $k$ agents in a connected undirected network aim to cooperatively solve\n$\\displaystyle \\underset{x}{\\text{minimize}} \\quad \\sum_{i=1}^k (f_i(x_i) + g_i(C_ix_i))$\n(3a)\nwhere matrix $C_i \\in \\mathbb{R}^{m \\times n}$ and convex functions $f_i:\\mathbb{R}^m \\rightarrow \\mathbb{R}$ and $g_i: \\mathbb{R}^n \\rightarrow \\mathbb{R}$, with the former being smooth, are known only by agent $i$. Each vertex in a network represents an agent and each edge represents a communication channel between two agents. The information exchange between two agents occurs only if there exists an edge between the corresponding vertices in the network. If $T^T$ denotes the incidence matrix of the connected undirected network, (1b) along with $x \\in \\mathbb{R}^{km}$ and $z \\in \\mathbb{R}^{kn}$ can be used to bring this problem along with communication constraints imposed by the network structure into the form (1),\n$\\displaystyle \\begin{aligned}\n\\underset{x, z}{\\text{minimize}} \\quad & f(x) + g(z) \\\\\n\\text{subject to} \\quad & \\begin{bmatrix} T \\\\ C \\end{bmatrix} x + \\begin{bmatrix} 0 \\\\ -I \\end{bmatrix} z = 0,\n\\end{aligned}$\n(3b)\nwhere $Tx=0$ enforces the consensus constraint and $C := \\text{blkdiag}(C_1,...,C_k)$. Similar models are also encountered in sharing and optimal exchange problems [2].\nExample 2: Principle component pursuit. The following optimization problem arises in the recovery of low rank matrices from noisy incomplete observations [45], [46],\n$\\displaystyle \\begin{aligned}\n\\underset{Z_1, Z_2, Z_3}{\\text{minimize}} \\quad & \\gamma_1 \\|Z_1\\|_* + \\gamma_2 \\|Z_2\\|_1 \\\\\n\\text{subject to} \\quad & Z_1 + Z_2 + Z_3 - Q = 0 \\\\\n & \\|\\mathcal{P}_\\Omega(Z_3)\\|_F \\leq \\gamma_3.\n\\end{aligned}$\n(4a)\nwhere $Z_i$ and $Q$ are matrices of appropriate dimensions, $\\gamma_1$ and $\\gamma_2$ are positive parameters, $\\mathcal{P}_\\Omega(\\cdot)$ is a binary mask that sets entries in the set $\\Omega$ to zero, $\\| \\cdot \\|_*$ is the nuclear norm, and $\\| \\cdot \\|_1$ is the $\\ell_1$-norm of a given matrix. This problem can be brought into the form (1) as\n$\\displaystyle \\begin{aligned}\n\\underset{Z_1, Z_2, Z_3}{\\text{minimize}} \\quad & g_1(Z_1) + g_2(Z_2) + g_3(Z_3) \\\\\n\\text{subject to} \\quad & \\begin{bmatrix} I & I & I \\end{bmatrix} \\begin{bmatrix} Z_1 \\\\ Z_2 \\\\ Z_3 \\end{bmatrix} - Q = 0,\n\\end{aligned}$\n(4b)\nwhere $g_1(Z_1) = \\|Z_1\\|_*, g_2(Z_2) = \\gamma_1 \\|Z_2\\|_1$, and $g_3(Z_3) = \\mathbb{I}_{\\{Z_3 : \\|\\mathcal{P}_\\Omega(Z_3)\\|_F \\leq \\gamma_2\\}}(Z_3)$. We note the absence of smooth components in the objective function. Similar models also arise in the estimation of sparse inverse covariance matrices [47] and in the alignment of linearly correlated images under corruption [48].\nExample 3: Covariance completion. The following problem is introduced for identification of low-complexity disturbance models that account for partially available second-order statistics of dynamical systems [49]\u2013[51],\n$\\displaystyle \\begin{aligned}\n\\underset{X, Z}{\\text{minimize}} \\quad & - \\text{log det}(X) + \\gamma \\|Z\\|_* \\\\\n\\text{subject to} \\quad & AX + AX^T + Z = 0 \\\\\n & (BXBT) \\circ C - Q = 0\n\\end{aligned}$\n(5a)\nwhere $X$, $Z$, $A$, $B$, $C$, and $Q$ are matrices of appropriate dimensions, $\\gamma$ is a positive parameter, and $\\circ$ denotes the Hadamard product. This problem can be recast into the form (1) as\n$\\displaystyle \\begin{aligned}\n\\underset{X, Z}{\\text{minimize}} \\quad & f(X) + g(Z) \\\\\n\\text{subject to} \\quad & \\begin{bmatrix} E_1 \\\\ E_2 \\end{bmatrix} X + \\begin{bmatrix} I \\\\ 0 \\end{bmatrix} Z - \\begin{bmatrix} 0 \\\\ Q \\end{bmatrix} = 0,\n\\end{aligned}$\n(5b)"}, {"title": "", "content": "where $f(X) = - \\text{log det}(X + \\delta I)$, $g(Z) = \\|Z\\|_*$, with the linear operators defined as $E_1(X) = AX + XAT$ and $E_2(X) = (BXBT) \\circ C$. We use additional regularization parameter $\\delta$ to ensure that $f$ is a smooth convex function. The optimization variables in (5) are matrices and generalized consensus constraint in (1) is expressed using linear operators $E_1$ and $E_2$. Even though the conversion to a vectorized form is straightforward, working with the matricial formulation is advantageous from both conceptual and implementation viewpoints.\nExample 4: Exact convex formulation of neural networks. The following problem emerges in the convex formulation of connected two layer neural networks with ReLU activation [52],\n$\\displaystyle \\begin{aligned}\n\\underset{u, \\tilde{u}}{\\text{minimize}} \\quad & h\\Big(\\sum_{i=1}^r T_iu_i, q\\Big) + \\gamma \\sum_{i=1}^r (\\|u_i\\| + \\|\\tilde{u}_i\\|) \\\\\n\\text{subject to} \\quad & G_iu_i \\geq 0 \\quad i = 1,...,r \\\\\n & G_i\\tilde{u}_i \\geq 0 \\quad i = 1,...,r\n\\end{aligned}$\n(6a)\nwhere $u = [u_1^T \\quad ... \\quad u_r^T]^T$ and $\\tilde{u} = [\\tilde{u}_1^T \\quad ... \\quad \\tilde{u}_r^T]^T$, $h(\\cdot,)$ is a smooth loss function, $q$ is the vector of labels, $T_i$'s and $G_i$'s are given matrices of appropriate dimensions, and $\\gamma$ is a positive parameter. Using the following definitions [53],\n$\\displaystyle x_2 := \\begin{bmatrix} u^T \\\\ \\tilde{u}^T \\end{bmatrix}, \\quad T := \\begin{bmatrix} T_1 & ... & T_r & -T_1 & ... & -T_r \\end{bmatrix}, \\quad G:= \\text{blkdiag} (G_1, ..., G_r, G_1, ..., G_r)$\nwe transform this problem into the form (1),\n$\\displaystyle \\begin{aligned}\n\\underset{x, z}{\\text{minimize}} \\quad & f_1(x_1) + \\gamma \\|z_1\\|_{1,2} + \\mathbb{I}_{\\mathbb{R}_+}(z_2) \\\\\n\\text{subject to} \\quad & \\begin{bmatrix} 0 & I \\\\ T & 0 \\\\ -I & 0 \\\\ 0 & G \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + \\begin{bmatrix} I & 0 \\\\ 0 & 0 \\\\ 0 & -I \\\\ 0 & 0 \\end{bmatrix} \\begin{bmatrix} z_1 \\\\ z_2 \\end{bmatrix} = 0,\n\\end{aligned}$\n(6b)\nwhere $x_1$ is the auxiliary variable, $f_1(x_1) = h(x_1, q)$, and $\\|\\cdot\\|_{1,2}$ is the group lasso penalization. Similar formulations can also be found in the context of empirical risk minimization such as sparse-group lasso where both $\\ell_{1,2}$- and $\\ell_1$-norm penalization appear in the objective function [54].\nB. The proximal operator and the Moreau envelope\nThe proximal operator associated with a proper closed convex function $g$ is the mapping defined as [1],\n$\\displaystyle \\text{prox}_{\\mu g}(v) = (I + \\mu \\partial g)^{-1}(v)$\n(7)\nwhere $\\mu$ is a positive parameter and $\\partial g$ is the subdifferential of $g$ [55, Chapter 16]. Alternatively, $\\text{prox}_{\\mu g}$ can be obtained as the minimizer of the following optimization problem,\n$\\displaystyle \\text{prox}_{\\mu g} (v) = \\underset{w}{\\text{argmin}} \\quad g(w) + \\frac{1}{2 \\mu} \\|w - v\\|^2.$\nThe value function of this optimization problem determines the associated Moreau envelope of $g$\n$\\displaystyle M_{\\mu g}(v) := g(\\text{prox}_{\\mu g} (v)) + \\frac{1}{2 \\mu} \\| \\text{prox}_{\\mu g}(v) - v\\|^2$\n(8)\nwhich is a continuously-differentiable function, even for nondifferentiable $g$, with $1/\\mu$-Lipschitz continuous gradient [55, Proposition 12.30],\n$\\displaystyle \\nabla M_{\\mu g}(v) = \\frac{1}{\\mu} (v - \\text{prox}_{\\mu g}(v)).$\nBy partitioning vector $v$ as $v := [v_1^T \\quad ... \\quad v_l^T]^T$, separable structure in (1b) can be used to obtain,\n$\\displaystyle \\text{prox}_{\\mu g} (v) = \\begin{bmatrix} \\text{prox}_{\\mu g_1} (v_1) \\\\ ... \\\\\n \\text{prox}_{\\mu g_l} (v_l) \\end{bmatrix} , \\quad M_{\\mu g}(v) = \\sum_{i=1}^l M_{\\mu g_i}(v_i).$\n(9)"}, {"title": "C. Lagrange saddle function", "content": "Optimization problem (1) can be lifted to a higher dimensional space by introducing auxiliary variables $w_i$ for each nonsmooth block associated with $z_i$,\n$\\displaystyle \\begin{aligned}\n\\underset{x, z, w}{\\text{minimize}} \\quad & f(x) + g(w) \\\\\n\\text{subject to} \\quad & Ex + Fz - q = 0 \\\\\n & z - w = 0,\n\\end{aligned}$\n(10)\nwhere $w = [w_1^T \\quad ... \\quad w_l^T]^T \\in \\mathbb{R}^n$. The auxiliary variables in (10) isolate each nonsmooth block in the objective function and facilitate the derivation of a continuously-differentiable saddle function in Section II-D. We denote the set of all solutions to (10) by $\\mathcal{P}_w$; clearly, $\\mathcal{P}_w = \\{(x, z, z)\\|(x, z) \\in P^*\\}$ and, throughout the manuscript, we use the subscript $(\\cdot)_w$ to highlight that the solution set is associated with the lifted problem.\nAssociating the dual variable $y_i$ with $z_i = w_i = 0$ for each $i = 1,..., l$, and the dual variable $\\lambda \\in \\mathbb{R}^p$ with the linear equality constraint $Ex + Fz - q = 0$ yields the following Lagrange saddle function for problem (10),\n$\\displaystyle \\mathcal{L}(x, z, w; y, \\lambda) = f(x) + g(w) + \\lambda^T(Ex + Fz - q) + y^T(z \u2013 w)$\n(11)\nwhere $y = [y_1^T \\quad ... \\quad y_l^T]^T \\in \\mathbb{R}^n$. Throughout the paper, we assume that there exists $(x, z) \\in \\mathbb{R}^m \\times \\text{ri dom} g$ such that $Ex + Fz = q$, where ri dom $g$ denotes the relative interior of domain of $g$ [55, Section 6.2]. This assumptions ensures that the strong duality holds [55, Theorem 15.23 and Proposition 15.24(x)]. Consequently, the necessary and sufficient conditions for $(x^*, z^*, w^*, y^*, \\lambda^*)$ to be an optimal primal-dual pair of problem (10) are given by the Karush-Kuhn-Tucker (KKT) conditions,\n$\\displaystyle \\begin{aligned}\n\\nabla f(x^*) &= -E^T \\lambda^* \\\\\n y^* &= -F^T\\lambda^* \\\\\n\\partial g(w^*) &\\ni y^* \\\\\n z^* &= w^* \\\\\n q &= Ex^* + Fz^*.\n\\end{aligned}$\n(12a)\n(12b)\n(12c)\n(12d)\n(12e)\nLet $\\Psi_w^*$ denote the set of all points satisfying optimality conditions (12). Since the KKT system (12) is challenging to solve because of nonlinear inclusions (12a) and (12c), we utilize the fact that every solution $(x^*, z^*, w^*, y^*, \\lambda^*) \\in \\Psi_w^*$ is a saddle point of the Lagrangian that satisfies,\n$\\displaystyle \\mathcal{L}_{\\mu}(x^*, z^*, w^*; y, \\lambda) \\leq \\mathcal{L}_{\\mu}(x^*, z^*, w^*; y^*,\\lambda^*) \\leq \\mathcal{L}_{\\mu}(x, z, w; y^*, \\lambda^*), \\quad \\forall x, z, w, y, \\lambda.$\n(13)\nBased on this characterization, a solution to (10) can be computed by simultaneous minimization and maximization of the Lagrangian over primal variables $(x, z, w)$ and dual variables $(y, \\lambda)$, respectively. In what follows, we describe how the underlying problem structure can be exploited to formulate a continuously-differentiable Lagrange saddle function and develop primal-dual algorithms with superior performance relative to the first-order methods that utilize subgradients (which suffer from slow convergence rate even for strongly convex problems; e.g., see [56, Section 3.4]).\nD. Proximal augmented Lagrangian\nComputation of saddle points that satisfy (13) is, in general, a challenging task because of the presence of nondifferentiable terms. We can alleviate these difficulties by exploiting the structure of the associated proximal operator that yields the manifold on which the augmented Lagrangian is minimized with respect to the auxiliary variable $w$. The augmented Lagrangian, which has the same saddle points as (11), is obtained by adding a quadratic penalty to (11) for each equality constraint in (10),\n$\\displaystyle \\mathcal{L}_{\\mu}(x, z, w; y, \\lambda) = f(x) + g(w) + \\lambda^T(Ex + Fz \u2013 q) + y^T(z \u2013 w) + \\frac{1}{2\\mu}\\|Ex + Fz \u2013 q\\|^2 + \\frac{1}{2\\mu}\\|z \u2013 w\\|^2$\nwhere $\\mu$ is a positive penalty parameter. Completion of squares yields\n$\\displaystyle \\mathcal{L}_{\\mu}(x, z, w; y, \\lambda) = f(x) + g(w) + \\frac{1}{2\\mu}\\|w - (z + \\mu y)\\|^2 + \\frac{1}{2\\mu}\\|Ex + Fz \u2013 q + \\mu \\lambda\\|^2 - \\frac{1}{2\\mu}\\|y\\|^2 - \\frac{1}{2\\mu}\\|\\lambda\\|^2$\n(14)"}, {"title": "", "content": "and the explicit minimizer of $\\mathcal{L"}, {"y)": "underset{w"}, {"g}(v)": "g(\\text{prox"}, {"28": "n$\\displaystyle \\begin{aligned"}, "n\\mathcal{L}_{\\mu}(x, z; y, \\lambda) := \\underset{W}{\\text{minimize}} \\quad & \\mathcal{L}_{\\mu}(x, z, w; y, \\lambda) = \\mathcal{L}_{\\mu}(x, z, W(z; y); y, \\lambda) \\\\\n& = f(x) + M_{\\mu g}(z + \\mu y) + \\frac{1}{2\\mu}\\|Ex + Fz \u2013 q + \\mu \\lambda\\|^2 - \\frac{1}{2\\mu}\\|y\\|^2 - \\frac{1}{2\\mu}\\|\\lambda\\|^2.\n\\end{aligned}$\n(16)\nIn contrast to the augmented Lagrangian which is a nonsmooth function of $w$, the proximal augmented Lagrangian has Lipschitz continuous gradients with respect to both primal $(x, z)$ and dual $(y, \\lambda)$ variables. Moreover, as detailed in the next section, the set of saddle points of the proximal augmented Lagrangian, which is denoted by $\\Psi^*$, together with (15) yields the set of points $\\Psi_w^*$ that satisfy KKT conditions (12).\nE. Primal-dual gradient flow dynamics\nSince the proximal augmented Lagrangian is a continuously differentiable saddle function, first-order algorithms can be used to compute its saddle points. In particular, we utilize primal-descent dual-ascent gradient flow dynamics,\n$\\displaystyle \\begin{aligned}\n\\dot{x} &= -\\nabla_x \\mathcal{L}_{\\mu}(x, z; y, \\lambda) = -\\nabla f(x) - E^T(\\lambda + (1/\\mu)(Ex + Fz - q)) \\\\\n\\dot{z} &= -\\nabla_z \\mathcal{L}_{\\mu}(x, z;y, \\lambda) = -\\nabla_z M_{\\mu g}(z + \\mu y) - F^T(\\lambda + (1/\\mu)(Ex + Fz - q)) \\\\\n\\dot{y} &= a \\nabla_y \\mathcal{L}_{\\mu}(x, z; y, \\lambda) = a (\\nabla_y M_{\\mu g}(z + \\mu y) - \\frac{1}{\\mu} y) \\\\\n\\dot{\\lambda} &= a \\nabla_\\lambda \\mathcal{L}_{\\mu}(x, z;y, \\lambda) = a (Ex + Fz - q)\n\\end{aligned}$\n(17a)\n(17b)\n(17c)\n(17d)\nwhere $x: [t_0,\\infty) \\rightarrow \\mathbb{R}^m$, $z: [t_0,\\infty) \\rightarrow \\mathbb{R}^n$, $y: [t_0,\\infty) \\rightarrow \\mathbb{R}^n$, $\\lambda: [t_0,\\infty) \\rightarrow \\mathbb{R}^p$, $t_0$ is the initial time, and $a$ is the positive parameter that determines the time constant of the dual dynamics. We denote the state vector in (17) by $\\psi = (x, z, y, \\lambda)$.\nBy construction, the equilibrium points of primal-dual gradient flow dynamics (17) are the saddle points of the proximal augmented Lagrangian which in conjunction with (15) satisfy KKT conditions (12). To show this, we set the right-hand-side of (17) to zero. Equation (17d) gives condition (12e). Equation (17c) yields $z = \\text{prox}_{\\mu g}(z+\\mu y)$ which together with (15) implies (12d). Furthermore, by the definition of proximal operator (7), $z = \\text{prox}_{\\mu g}(z+\\mu y)$ is equivalent to $y \\in \\partial g("]}