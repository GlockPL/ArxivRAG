{"title": "Higher-order Cross-structural Embedding Model for Time Series Analysis", "authors": ["Guancen Lin", "Cong Shen", "Aijing Lin"], "abstract": "Time series analysis has gained significant attention due to its critical applications in diverse fields such as healthcare, finance, and sensor networks. The complexity and non-stationarity of time series make it challenging to capture the interaction patterns across different timestamps. Current approaches struggle to model higher-order interactions within time series, and focus on learning temporal or spatial dependencies separately, which limits performance in downstream tasks. To address these gaps, we propose Higher-order Cross-structural Embedding Model for Time Series (High-TS), a novel framework that jointly models both temporal and spatial perspectives by combining multiscale Transformer with Topological Deep Learning (TDL). Meanwhile, High-TS utilizes contrastive learning to integrate these two structures for generating robust and discriminative representations. Extensive experiments show that High-TS outperforms state-of-the-art methods in various time series tasks and demonstrate the importance of higher-order cross-structural information in improving model performance.", "sections": [{"title": "I. INTRODUCTION", "content": "Time series are pervasive across various domains, making the study of time series analysis critically important. Time series classification, in particular, has broad applicability in fields such as finance, healthcare and environmental monitoring [1]-[3]. Accurate and efficient classification methods are essential for interpreting the internal patterns and making informed decisions based on the series. In recent times, deep learning has proven to be highly effective in time series classification, offering significant improvements in accuracy by automatically extracting and leveraging powerful representations from data [4]-[8].\nTime series inherently exhibit temporal and spatial dependencies. On the one hand, the temporal feature reflects the sequential nature of observations. In view of this characteristic, Recurrent Neural Network (RNN) and its variants such as LSTM and GRU are widely used [9]-[11]. Meanwhile, Transformer is introduced to leverage multi-head attention mechanisms, aiming to capture long-range dependencies in time series data [12]-[14]. On the other hand, spatial features represent the internal structure of the data, covering the complex interactions between different parts of the time series [15]. Mapping time series onto graphs is a common approach to capturing the spatial structure [16]. GNN-based methods can learn graphs mapped from time series to obtain effective representations. Consequently, a range of studies combine GNNs with temporal encoding to simultaneously capture the cross-structure of temporal and spatial dynamics [17], [18].\nCross-structural models that simultaneously consider the temporal and spatial domains have shown promising results in time series analysis [16], [19]. This inspires us to view sequential structures and graphs from different perspectives, exploring novel approaches to describing time series patterns. For example, subfigures I of Fig. 1(A) and Fig. 1(B) respectively present a time series and its corresponding graph mapping. The traditional temporal perspective captures information from a single timestamp ((A)II). Obviously, by aggregating multiple timestamps, new patterns emerge in (A)III and (A)IV, which have not been considered in previous studies. Spatially, traditional methods capture the relationships between nodes ((B)II). However, interactions beyond the node level are also deserve attention, such as constructing new structures through edges and triangles ((B)III and IV). Recently, with the introduction of multiscale methods, higher-order patterns of multiple timestamps in the time domain have been captured, providing insights into short-term fluctuations and long-term trends. In the field of Topological Data Analysis (TDA), simplicial complexes take two or more vertices as a whole, extending the spatial properties of the graph to higher orders, thereby representing multiple levels of interactions.\nIn this paper, we introduce a novel representation learning framework named Higher-order Cross-structural Embedding Model for Time Series (High-TS), designed to integrate both"}, {"title": "II. RELATED WORKS", "content": "Temporal models have become integral to time series analysis, leveraging their ability to capture the temporal dependencies inherent in sequential data. RNNs were among the earliest deep learning models applied to time series data [9]. However, RNNs suffer from issues like vanishing gradients, which limit their ability to model long-range dependencies [20]. To address these challenges, LSTM networks [10] and GRUs [11] were introduced. Recent variants such as Bidirectional LSTMs [21], [22], stacked LSTMs [23], [24] and Temporal Fusion Transformer (TFT) [25], [26] have further improved performance in time series analysis tasks.\nIn addition to RNN-based approaches, 1D-CNNs have been adapted for time series analysis, which are particularly effective in capturing local patterns within the data [5], [6]. More recently, attention-based models like Transformers [12], and their variants such as BERT [13], Informer [27] and TCN [28] have gained popularity in time series analysis due to their ability to model complex dependencies without the need for sequential processing. In addition, there are some improved models based on self-attention mechanism, which have also achieved good results in time series analysis, such as ConvTrans [29], ConvTrans-CL [30], Reformer [31], LogSparse Transformer [14], FEDformer [32] and SCINet [33]. Simultaneously, multiscale methods are increasingly recognized as an effective approach to time series analysis. Multiscale methods enable the examination of data across different temporal resolutions, revealing patterns and relationships that might be overlooked when considering a single scale, thereby enhancing model performance [34]-[36]. These advancements in deep learning architectures and time series analysis have significantly improved the accuracy and efficiency of time series prediction and classification, paving the way for more robust and scalable solutions in various domains."}, {"title": "B. Graph and Simplicial Complex for Time Series", "content": "The use of graph-based methods in time series analysis has emerged as a powerful approach to capturing complex dependencies. Different from traditional time series models, GNNs have been increasingly applied to time series analysis, leveraging the ability to model non-Euclidean structures [7], [8]. Notable models include DCRNN [37], STGCN [38], Graph WaveNet [39], MTGNN [40] and AGCRN [41].\nBeyond graphs, simplicial complexes extend the concept by modeling higher-order interactions among multiple nodes, which are not captured by pairwise relationships alone [42], [43]. Simplicial Neural Networks (SNNs) [44] and topological methods have been introduced to exploit these higher-order structures in point cloud data. These methods allow for the analysis of interactions among more than two entities, offering a richer representation of the data [45]. Notable models include SCNN [46], which extends the idea of graph convolutional networks to simplicial complexes for modeling higher-order interactions. TDA techniques [47] like persistent homology have also been used to analyze the topological features, providing insights that can inform more accurate analysis. Additionally, SAT [48] and PLL [49] use attention mechanisms, persistent Laplacian and simplicial complexes to focus on relevant higher-order interactions. Although these methods have made great progress in fields such as social networks, biomolecules, and materials science, their application in time series research is still rare. Thus, by integrating graph and simplicial complex-based methods, researchers are pushing the boundaries of time series analysis, enabling more accurate and insightful models that better capture the multifaceted nature of real-world data."}, {"title": "III. METHODOLOGY", "content": "Suppose a time series dataset $D$ containing $n$ labeled sequence samples ${x_i, y_i}_{i=1}^n$, where each sample $x \\in \\mathbb{R}^L$ is collected by a sensor across $T$ timestamps. Our task is to train an encoder $F(\\cdot)$ that is capable of simultaneously capturing the temporal and spatial interactions within the signals. Leveraging this encoder, we can obtain a higher-order cross-structural embedding $r_i = F(x_i) \\in \\mathbb{R}^d$ of the time series. By combining $r_i$ with a classifier, we are able to perform the downstream task of classification, inferring the class $\\hat{y}_i$ to which the sample $x_i$ belongs. For simplicity, $x$ is employed instead of $x_i$ in the following description, omitting the subscript $i$."}, {"title": "B. Overall Structure", "content": "Fig. 2 presents the overall architecture of High-TS, designed to capture higher-order cross-structural interactions within the time series. As shown in Fig. 2(A), for each time series sample, we establish a dual-perspective encoding framework: the temporal perspective is derived from multiscale embeddings, while the spatial perspective is based on TDL. In the multiscale embedding module, the signal is first segmented into multiple segments according to pre-selected scales. These segments are processed by the Transformer encoder to capture higher-order attention. The features from different scales are concatenated to form the temporal embedding, as illustrated in Fig. 2(B). Fig. 2(C) outlines the TDL-based architecture. The time series is divided into multiple windows, each corresponding to a vertices in a simplex complex, with the number of vertices fixed. Message passing between neighboring higher-order simplexes is considered and the representations are concatenated to form a spatial embedding. Finally, Fig. 2(A) illustrates how the temporal and spatial embeddings are aligned through contrastive learning and concatenated to produce the final time series representation for downstream tasks. More details are provided in subsequent sections."}, {"title": "C. Multiscale Transformer Embedding", "content": "Multiscale is a crucial approach in time series analysis, which examines data at different time scales to reveal hidden patterns and structures [34]. In time series analysis, Transformer effectively capture dependencies across different time stamps by utilizing the self-attention mechanism, making it well-suited for time series encoding [50], [51]. In this section, we define an encoder $F_M(x)$ for sample $x$ that describes the integration of multiscale analysis with the Transformer for temporal representation of time series.\n1) Multiscale Sequence: For a time series sample $x = {x_{(j)}}_{j=1}^{L_s} \\in \\mathbb{R}^L$, we consider local temporal patterns by controlling a scale factor $s$ to segment the signal into multiple segments ${h_{t,s}}_{t=1}^{L_s}$, where $L_s = \\lfloor \\frac{L}{s} \\rfloor$, $\\lfloor \\rfloor$ represents truncation operation. Each segment $h_{t,s} = {x_{(j)}}_{j=(t-1)\\times s+1}$ of length $s$ is treated as an element of a multiscale time series, as shown in Fig. 3(A).\n2) Input Embedding and Positional Encoding: Input embedding maps the raw time series segments into a higher-dimensional continuous latent space, enhancing the model's ability to capture subtle. A linear layer is employed to learn the input embeddings for each segment of the multiscale time series. For a segment $h_{t,s}$ at a specific scale $s$, the input embedding is represented as\n$h_s = \\sigma(W_1 \\cdot h_{t,s} + b_1),$ (1)\nwhere $W_1$ is the weight matrix, and $b_1$ is the bias term. Additionally, to ensure that the temporal order of segments aligns"}, {"title": "D. TDL-based Representation", "content": "TDL [52], [53] leverages novel topological tools to characterize data with complicated higher-order structures. Different from graph-based data representation, TDL uses topological representations from algebraic topology, including cell complexes [54], simplicial complexes [55], and hypergraphs [56], to model not only pair-wise interactions (as in graphs), but also many-body or higher-order interactions among three or more elements. This section will focus on how to use simplicial complexes to represent time series and how to aggregate higher-order neighbor information. The TDL-based encoder is introduced as $F_T(x)$.\nFor a time series $x = {x_{(j)}}_{j=1}^{L} \\in \\mathbb{R}^L$, a point number $n$ is introduced to constrain the patch size $L_p$, where the time series is segmented such that $L_p = \\lfloor \\frac{L}{n} \\rfloor$. Each patch $p_t = {x_{(j)}}_{j=(t-1)\\times L_p+1}^{t \\times L_p}$ of length $L_p$ is introduced as a point of the point cloud $P = {p_t}_{t=1}^n \\in \\mathbb{R}^n$.\n1) Simplicial Complex for Time Series: A simplicial complex is the generalization of a graph into its higher-dimensional counterpart. The simplicial complex is composed of simplexes. Each simplex is a finite set of vertices and can be viewed geometrically as a point (0-simplex), an edge (1-simplex), a triangle (2-simplex), a tetrahedron (3-simplex), and their k-dimensional counterpart (k-simplex), as shown in Fig. 3(B). More specifically, a k-simplex $\\sigma_k = {v_0, v_1, v_2, \\dots, v_k}$ is the convex hull formed by $k + 1$ affinely independent points $v_0, v_1, v_2,\\cdots, v_k$ as follows\n$\\sigma_k = \\{\\sum_{i=0}^{k} \\lambda_i v_i | \\sum_{i=0}^{k} \\lambda_i = 1; \\forall i, 0 \\leq i \\leq 1\\}.$ (7)\nThe i-th dimensional face of $\\sigma_k (i < k)$ is the convex hull formed by $i + 1$ vertices from the set of $k + 1$ points $v_0, v_1, v_2,\\cdots, v_k$. The simplexes are the basic components for a simplicial complex.\nA simplicial complex $K$ is a finite set of simplexes that satisfy two conditions. First, any face of a simplex from $K$ is also in $K$. Second, the intersection of any two simplexes in $K$ is either empty or a shared face. A k-th chain group $C_k$ is an Abelian group of oriented k-simplexes $\\sigma_k$, which are simplexes together with an orientation, i.e., ordering of their vertex set. The boundary operator $\\partial_k (C_k \\rightarrow C_{k-1})$ for an oriented k-simplex $\\partial \\sigma_k$ can be denoted as\n$\\partial_k \\sigma_k = \\sum_{i=0}^{k} (-1)^i [v_0, v_1, v_2, \\dots, \\hat{v_i}, \\dots, v_k].$ (8)\nHere, $[v_0, v_1, v_2, \\dots, \\hat{v_i},\\dots, v_k]$ is an oriented $(k - 1)$-simplex, which is generated by the original set of vertices"}, {"title": "Also we consider the following diagonal matrices $D_k = {D_{c,k}(i, j)}$ for normalization:", "content": "$\\begin{cases} d_u(\\sigma_i^k), i = j, k = 0 \\\\ d_l(\\sigma_i^k), i = j, k \\geq 1 \\\\ 0 \\quad others. \\end{cases}$ (11)\nwhere $d_u(\\sigma_i^k)$ and $d_l(\\sigma_i^k)$ denote the upper and lower degree of $\\sigma_i^k$, respectively.\n2) Simplex-based Message Passing: In High-TS, Vietoris-Rips complexes Rip is utilized to describe time series. To be specific, we consider a series of adjacent matrices $A_k$ to describe the interaction between k-simplexes in Rip. We use message passing to learn the feature representation of each simplex,\n$H_k^{(l+1)} = \\text{Relu}(D_k A_k (D_k H_k^{(l)}) W^{(l)}).$ (12)\nand the initial representations $H_0^{(0)}, H_1^{(0)}$ and $H_2^{(0)}$ of 0-samplex, 1-samplex, and 2-samplex are shown in Section A of the supplementary materials.\nIn the l-th iteration, the feature matrix $H_k^{(l+1)}$ of k-simplexes is obtained by gathering neighbors feature of each k-simplex. Here $A_k$ represents the sum of $A_k$ and identity matrix. $D_k$ is a degree matrix, which is a diagonal matrix whose values on the diagonal are equal to the sum of the corresponding rows (or columns) in $\\hat{A}_k$. $W^{(l)}$ is the weight matrix (to be learned). Computationally, we usually repeat the process 1 to 3 times, and the final simplex feature is denoted as $H_k$. After message passing, all k-simplex features in Rip are gathered into one feature through a pooling process,\n$f_k = \\text{Pooling} (H_k),$ (13)\nwhere $Pooling(\\cdot)$ is a pooling function. And the spatial representation of sample $x$ is defined as\n$F_T(x) = [f^0 \\oplus \\dots \\oplus f^k].$ (14)"}, {"title": "E. Cross-structural Contrastive Learning", "content": "Contrastive learning is effectively applied in unsupervised settings by utilizing different views or augmentations of the same sample, enabling the model to learn meaningful representations without the need for labeled data [57]. After obtaining the embeddings from the multiscale Transformer and TDL encoding, we employ contrastive learning to enhance the ability of our framework to learn more discriminative representations.\nIn this paper, we combine the unsupervised aspect of contrastive learning with the cross-structural patterns in High-TS, training the network to minimize the distance between positive pairs and maximize the distance between negative pairs [57]. A batch containing B time series samples is randomly selected, yielding 2B augmented representations through cross-structural encoders $F_M(\\cdot)$ and $F_T(\\cdot)$. Specifically, we obtain augmented representations of samples through a cross-structural mechanism. For a sample $x_i$ in the batch, its embedding $F_M(x_i)$ from the multiscale Transformer and the embedding $F_T(x_i)$ from TDL form a positive pair, while the augmented representations of different samples in the batch are treated as negative pairs. The contrastive loss of $x_i$ is defined as follows:\n$\\mathcal{L}_{CL}(x_i) = - \\log \\frac{\\exp(\\text{sim}(F_M(x_i), F_T(x_i)) / \\tau)}{\\sum_{j=1, j \\neq i}^{B} \\exp(\\text{sim}(F_M(x_i), F_T(x_j)) / \\tau)} + \\log \\frac{\\exp(\\text{sim}(F_M(x_i), F_T(x_i)) / \\tau)}{\\sum_{j=1, j \\neq i}^{B} \\exp(\\text{sim}(F_M(x_i), F_T(x_i) / \\tau)},$ (15)\nwhere $\\tau$ denotes the temperature parameter, $sim(\\cdot, \\cdot)$ is used to measure the cosine similarity between two representations. The final loss is computed across all positive pairs within the batch,\n$\\mathcal{L}_{CL} = \\sum_{i=1}^{B} \\mathcal{L}_{CL}(x_i).$ (16)"}, {"title": "F. Fusion and Prediction", "content": "In addition to using unsupervised contrastive learning for time series representation learning, we also designed a supervised time series classification task in this section. After the cross-structural encoding process, the higher-order representations from the temporal and spatial dimensions, $F_M(x)$ and $F_T(x)$, are used to represent the sample features from two different perspectives. These representations are first concatenated and then fed into a fully connected layer for"}, {"title": "Combining Transformer and TDL to jointly learn short-term and long-term temporal dependencies across differ ent scales, while capturing complex spatial interactions.", "content": "A time series can be decomposed into multiple temporal scales."}, {"title": "Leveraging contrastive learning to integrate cross temporal and spatial structures and enhance the representation of time series.", "content": "We adopt the approach of the authors."}, {"title": "Conducting extensive experiments to demonstrate the effectiveness of our approach to modeling and capturing complex interactions within time series.", "content": "We show the power of proposed technique via extensive experimens."}, {"title": "label prediction.", "content": "The connected representation of the sample is denoted by $r$, and $\\hat{y} = {y_i}_{i=1}^n$ represents the predicted label obtained by the fully connected layer.\nr = F(x) = [F_M(x) + F_T(x)]\n= [z^1 \\oplus z^2 \\oplus z^3 \\oplus f_0 \\oplus f_1 \\oplus f_2] , (17)\n$\\hat{y} = \\sigma(W_r\\cdot r + b_r).$ (18)\nWe designate cross-entropy loss as the objective function to optimize the parameters within the framework,\n$\\mathcal{L}_{CE} = -\\sum_{i=1}^n y_i\\log(\\hat{y}_i) + (1 - y_i)\\log(1 - \\hat{y}_i).$ (19)\nTogether with the loss of contrastive learning in Section III-E, the overall loss function $\\mathcal{L}$ in this paper is defined as:\n$\\mathcal{L} = \\mathcal{L}_{CE} + \\mathcal{L}_{CL}.$ (20)\nGuided by labeled data, we are able to refine the proposed model through back propagation, enabling the learning of sample embeddings for classification."}, {"title": "IV. EXPERIMENTAL EVALUATION", "content": "To validate the effectiveness of the High-TS framework, we select 12 publicly available time series datasets from various real-world fields. These datasets encompass a wide range of applications, providing a comprehensive evaluation of our model's performance across different types of time series data. The details of the datasets are shown in Table I. We conducted extensive experiments, comparing the results with state-of-the-art (SOTA) methods to demonstrate the superiority of our approach to capturing complex temporal and spatial interactions."}, {"title": "B. Experimental Setup", "content": "We partitioned 80% of the Epilepsy Electroencephalogram archive as the training set and 20% as the test set, with 25% of the training data reserved for validation to choose appropriate hyperparameters. Accuracy is used as the evaluation metric for model performance. The experiments are repeated 5 times using different random seeds, and the mean accuracy along with the standard deviation is reported. The experiments utilize the Adam optimizer with a batch size of 64, a learning rate of 2e-4, and 3e+3 epochs. The cutoff c is set as the cosine similarity value located in the top 10% of all cosine similarities. We employ grid search to select the optimal combination of the number of vertices and the dimension of the latent representation, where the number of vertices is chosen from {15,20,25,30}, and the latent dimension is evaluated over {8, 16, 32, 64}. Experiments are conducted on a computational setup featuring a 32-core AMD 75F3 CPU, 500GB RAM, and NVIDIA A100 40G GPU capabilities. The server infrastructure is provided by the National Supercomputing Centre (NSCC) Singapore."}, {"title": "C. Results and Analysis", "content": "To evaluate the performance of the proposed framework, we execute High-TS and SOTA methods across all datasets, and the experimental results are presented in Table II. The classification accuracy demonstrates that High-TS outperforms all baseline methods on 11 out of the 12 datasets, achieving the best performance. In particular, the average classification accuracy for each model is provided, and High-TS demonstrates a clear advantage over the second-place method by a"}, {"title": "D. Ablation study", "content": "We evaluate the effectiveness of each component in High TS through ablation studies. First, we train the model without contrastive learning, referred to as 'w/o CL'. On this basis, we focus on the role of higher-order, separately remove the 2-simplex and 1-simplex components, denoted as 'w/o_2- simplex' and 'w/o_1-simplex'. Additionally, we omit the de signed 3-scale and 2-scale components to create the variants 'w/o_3-scale' and 'w/o_2-scale', respectively. Finally, to val idate the importance of cross-structural integration, we train variants 'w/o_SC' with only multiscale Transformer without"}, {"title": "High-TS exhibited the best visualization results, where the learned embeddings form the most compact structure with the clearest boundaries between different classes.", "content": "We show the power of proposed technique via embedding visualization."}, {"title": "V. CONCLUSION", "content": "We present High-TS, a novel framework designed to capture higher-order interactions in time series through cross-structural embeddings. High-TS utilizes a combination of multiscale Transformer and TDL to model both temporal and spatial perspectives effectively. The integration of contrastive learning further enhances its ability to learn robust and discriminative representations. Experiments demonstrate that High-TS exhibits remarkable generalization ability, maintaining strong performance across different datasets. Future work will focus on refining the scalability of the framework and exploring its applications in other domains."}]}