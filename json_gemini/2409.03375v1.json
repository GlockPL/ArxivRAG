{"title": "Leveraging Large Language Models through Natural Language Processing to provide interpretable Machine Learning predictions of mental deterioration in real time", "authors": ["Francisco de Arriba-P\u00e9rez", "Silvia Garc\u00eda-M\u00e9ndez"], "abstract": "Based on official estimates, 50 million people worldwide are affected by dementia, and this number increases by 10 million new patients every year. Without a cure, clinical prognostication and early intervention represent the most effective ways to delay its progression. To this end, Artificial Intelligence and computational linguistics can be exploited for natural language analysis, personalized assessment, monitoring, and treatment. However, traditional approaches need more semantic knowledge management and explicability capabilities. Moreover, using Large Language Models (LLMS) for cognitive decline diagnosis is still scarce, even though these models represent the most advanced way for clinical-patient communication using intelligent systems. Consequently, we leverage an LLM using the latest Natural Language Processing (NLP) techniques in a chatbot solution to provide interpretable Machine Learning prediction of cognitive decline in real-time. Linguistic-conceptual features are exploited for appropriate natural language analysis. Through explainability, we aim to fight potential biases of the models and improve their potential to help clinical workers in their diagnosis decisions. More in detail, the proposed pipeline is composed of (i) data extraction employing NLP-based prompt engineering; (ii) stream-based data processing including feature engineering, analysis, and selection; (iii) real-time classification; and (iv) the explainability dashboard to provide visual and natural language descriptions of the prediction outcome. Classification results exceed 80% in all evaluation metrics, with a recall value for the mental deterioration class about 85%. To sum up, we contribute with an affordable, flexible, non-invasive, personalized diagnostic system to this work.", "sections": [{"title": "1 Introduction", "content": "Neurodegenerative Alzheimer's disorder (AD) is the leading cause of chronic or progressive dementia, which negatively impacts cognitive functioning, including comprehension, speech, and thinking problems, memory loss, etc. [1]. More in detail, the typical stages of cognitive decline can be categorized as pre-clinical AD, Mild Cognitive Impairment (MCI) caused by AD, and finally AD dementia [2]. Generally, cognitively impaired users find difficult to perform daily tasks with the consequent detrimental impact on their life quality [3]. In this line, cognitive decline is a leading cause of dependency and disability for our elders [4].\nAccording to the Alzheimer's Association report on the impact of this disease in the United States [5], it is the sixth-leading death cause that increased more than 145% in the last years. Moreover, it affects 6.7 million people 65 or older. Dreadfully, this number is"}, {"title": "2 Related work", "content": "As previously mentioned, the main focus of dementia treatment is to delay the cognitive deterioration of patients [17]. Consequently, early diagnosis, which simultaneously contributes to reducing medical expenses in our aging society and avoiding invasive treatments with subsequent side effects on the users, is desirable [6]. To this end, AI has been successfully applied to IDSS in order to recommend treatments based on their diagnosis prediction [28, 29].\nWhile ML models perform well and fast in diagnosis tasks, they require extensive training data previously analyzed by experts, which is labor-intensive and time-consuming [17]. In contrast, advanced NLP-based solutions exploit transformer-based models already trained with large corpora, including domain-related data, which results in very sensitive text analysis capabilities [30]. Consequently, transformer-based pre-trained language models (PLMS) (e.g., BERT [31], GPT-3 [32]) which preceded the popular LLMS (e.g., GPT-42) have disruptively transformed the NLP research. These models exhibit great contextual latent feature extraction abilities from textual input [30]. The latter models are implemented to predict the next token based on massive training data, resulting in a word-by-word outcome [33]. Nowadays, they are used for various tasks, including problem-solving, question-answering, sentiment analysis, text classification, and generation, etc. [34].\nThere exist PLM versions over biomedical and clinical data such as BioBERT [35], BioGPT [36], BlueBERT [37], ClinicalBERT\u00b3 and TCM-BERT [38]. Open-domain conversational assistants, whose dialogue capabilities are not restricted to the conversation topic, exploit LLMS [19]. However, using LLMS for cognitive decline diagnosis is still scarce even though these"}, {"title": "2.1 Contributions", "content": "As previously described, a vast amount of work in the state of the art exploits PLMS even in the clinical field [44]. However, scant research has been performed in the case of LLM models. Note that explainability represents a differential characteristic of the solution proposed given the relevance of promoting transparency in AI-based systems [45].\nGiven the comparison with competing works:\n\u2022 Our system is the first that jointly considers the application of an LLM over spontaneous speech and provides interpretable ML results for the use case of mental decline prediction.\n\u2022 Our solution implements ML models in streaming to provide real-time functioning, hence avoiding the re-training cost of batch systems.\n\u2022 In this work, we leverage the potential of LLMS by applying the RLHF technique through prompt engineering in a chatbot solution. Note that the natural language analysis is performed with linguistic-conceptual features. Consequently, we contribute with an affordable, non-invasive diagnostic system.\n\u2022 Our system democratizes access to researchers and end users within the public health field to the latest advances in NLP."}, {"title": "3 Methodology", "content": "Figure 1 depicts the system scheme proposed for real-time prediction of mental decline combining LLMS and ML algorithms with explainability capabilities. More in detail, it is composed of (i) data extraction employing NLP-based prompt engineering (Section 3.1); (ii) stream-based data processing including feature engineering, analysis and selection (Section 3.2); (iii) real-time classification (Section 3.3); and (iv) the"}, {"title": "3.1 Data extraction", "content": "The ChatGPT GPT-3.5 model used serves two purposes: (i) it enables a natural, free dialogue with the end users, and (ii) data is extracted due to its semantic knowledge management capabilities. The latter information is gathered once the conversation is concluded (either more than 3 minutes of inactivity or farewell detected) and used to compute the features used for classification (see Section 3.2.1). For this extraction, prompt engineering is exploited. The complete data extraction process is described in Algorithm 2."}, {"title": "3.2 Stream-based data processing", "content": "Stream-based data processing encompasses feature engineering, analysis, and selection tasks to ensure the optimal performance of the ML classifiers."}, {"title": "3.2.1 Feature engineering", "content": "Table 2 details the features used to predict mental decline. Note that conversational, emotional, and linguistic-conceptual features are computed. The conversational features4 (1-10) represent relevant semantic and pragmatic information related to the free dialogue (e.g., fluency, repetitiveness, etc.), while emotional features focus on the mental and physical state of the users. Finally, linguistic features represent lexical and semantic knowledge (e.g., disfluencies, placeholder words, etc.).\nFurthermore, the system maintains a history of each user data (i.e., past and current feature values) that enables the computation of four new characteristics per each in Table 2: average, Q1, Q2, and Q3 as indicated in Equation (1), where n is the user conversation counter and $X[n]$ represents a particular feature with historical data."}, {"title": "3.2.2 Feature analysis & selection", "content": "Feature analysis and selection tasks are necessary to optimize the performance of the ML classifiers. These tasks are even more important in the streaming scenario where samples arrive at a real-time pace. The latter means that the classification problem layout (e.g., the most relevant features) may vary over time.\nThe proposed system follows two thresholding strategies for feature analysis and selection based on cut-off points regarding correlation and variance values to remove irrelevant features. The former, correlation analysis, limits the number of features to extract the most relevant characteristics. For the latter variance analysis, the number of features selected is dynamically established in each interaction of the stream-based model, selecting those that meet the threshold criteria.\nAlgorithm 3 details the data processing stage, including feature engineering, analysis, and selection."}, {"title": "3.3 Stream-based classification", "content": "Two classification scenarios are considered:\nScenario 1 analyzes the behavior of the classifiers in a streaming setting. Under this consideration, sequential and continual testing and training over time is assumed.\nScenario 2 analyzes the models' performance under more realistic conditions. Thus, the testing is continuous (i.e., in streaming) while training is performed desynchronized in blocks of 100 samples.\nThe following ML models are selected based on their good performance in similar classification problems [46, 47, 48]:\n\u2022 Gaussian Naive Bayes (GNB) [49] exploits the Gaussian probability distribution in a stream-based ML model. It is used as a reference for performance analysis.\n\u2022 Approximate Large Margin Algorithm (ALMA) [50] is a fast incremental learning algorithm comparable to Support Vector Machine to approximate the maximal margin between a hyperplane concerning a norm (with a value of $p \\geq 2$) for a set of linearly separable data.\n\u2022 Hoeffding Adaptive Tree Classifier (HATC) [51] computes single-tree branch performance and is designed for stream-based prediction.\n\u2022 Adaptive Random Forest Classifier (ARFC) [52] constitutes an advanced model of HATC in which branch performance is computed by majority voting in an ensemble tree scenario.\nAlgorithm 4 describes the stream-based prediction process."}, {"title": "3.4 Explainability dashboard", "content": "Prediction transparency is promoted through explainability data provided to the end users regarding relevant features in the prediction outcome. Thus, those relevant features are included in the natural language description of the decision path. The five features whose mathematical module is highest or with the highest variance and whose values are the most distant from the average are selected. In the case of the counters (features 9-10), this average is obtained from the average of all users in the system."}, {"title": "4 Evaluation and discussion", "content": "This section discusses the experimental data set used, the implementation decisions, and the results obtained. The evaluations were conducted on a computer with the following specifications:\n\u2022 Operating System: Ubuntu 18.04.2 LTS 64 bits\n\u2022 Processor: Intel Core i9-10900K 2.80 GHz\n\u2022 RAM: 96 GB DDR4\n\u2022 Disk: 480 GB NVME + 500 GB SSD"}, {"title": "4.1 Experimental data set", "content": "The experimental data set consists of an average of 6.92 \u00b13.08 utterances with 62.73 \u00b1 57.20 words involving 44 users with 13.66\u00b17.86 conversations by user. The distribution of mental deterioration in the experimental data set is 238 samples in which mental deterioration is present and 363 in which it is absent."}, {"title": "4.2 Data extraction", "content": "Data to engineer conversational (1-8), emotional, and linguistic features in Table 2 were obtained with gpt-3.5-turbo model. The prompt used is shown in Listing 1."}, {"title": "4.3 Stream-based data processing", "content": "This section reports the algorithms used for feature engineering, analysis, and selection and their evaluation results."}, {"title": "4.3.1 Feature engineering", "content": "A total of 88 features were generated in addition to the 22 features generated in each conversation (see Table 2) resulting in 110 features. In Figure 3, we show the distribution of conversations by the user, which approaches a uniform density function, being relevant that the large majority concentrates between 15 and 20 conversations."}, {"title": "4.3.2 Feature analysis & selection", "content": "Correlation and variance thresholding decisions were based on experimental tests. For the correlation thresholding, SelectKBest was applied using the Pearson correlation coefficient [53]. The K value corresponds to the most relevant features of the 80% experimental data."}, {"title": "4.4 Stream-based classification", "content": "The River implementations of the ML models selected are: GNB12, ALMA13, HATC14 and ARFC15. Listings 2, 3 and 4 detail the hyper-parameter optimization ranges used, excluding the baseline model, from which the following values were selected as optimal:\nCorrelation thresholding\n\u2022 ALMA: alpha=0.5, B=1.0, C=1.0.\n\u2022 HATC: depth=None, tiethreshold=0.5, max-size=50."}, {"title": "4.5 Explainability dashboard", "content": "Figure 4 shows the explainability dashboard. In this example, the variation in predicting cognitive impairment is visualized, considering two weeks of past data. This variation is represented with the predict_proba function of ARFC algorithm. At the bottom, the most relevant features are displayed. Each figure card contains the identifier and statistic represented in colors following this scheme: 1 to 0.5 in green, 0.5 to 0.25 in yellow, and 0.25 to 0 in red. The latter assignation is inverted for negative values. At the bottom, a brief description in natural language is provided. The average accumulated predict_proba value, and the confidence prediction of the current sample are displayed on the right."}, {"title": "5 Conclusions", "content": "Cognitively impaired users find it difficult to perform daily tasks with the consequent detrimental impact on their life quality. Thus, progression detection and early intervention are essential to effectively and timely address mental deterioration to delay its progress. In this work, we focused on impairment in language production (i.e., lexical, semantic, and pragmatic aspects) to engineer linguistic-conceptual features towards spontaneous speech analysis (e.g., semantic comprehension problems, memory loss episodes, etc.). Compared to traditional diagnostic approaches, the proposed solution has semantic knowledge management and explicability capabilities thanks to integrating an LLM in a conversational assistant.\nConsideration should be given to the limitations of using LLMS, which are transversal into the healthcare field beyond mental deterioration detection. The potential biases and lack of inherent transparency stand out among the risks of applying these models for medical purposes. The latter black-box problem, also present in traditional opaque ML models, is particularly critical in the healthcare field by negatively impacting the decision process of physicians due to their limited corrective capabilities and even the end users, limiting their trust in medical applications. Moreover, these systems' current limited memory"}, {"title": "Declarations", "content": "Competing interests\nThe authors have no competing interests to declare relevant to this article's content.\nFunding\nThis work was partially supported by (i) Xunta de Galicia grants ED481B-2022-093 and ED481D 2024/014, Spain; and (ii) University of Vigo/CISUG for open access charge.\nAuthors contribution\nFrancisco de Arriba-P\u00e9rez: Conceptualization, Methodology, Software, Validation, Formal analysis, Investigation, Resources, Data Curation, Writing - Original Draft, Writing - Review & Editing, Visualization, Supervision, Project administration, Funding acquisition. Silvia Garc\u00eda-M\u00e9ndez: Conceptualization, Methodology, Software, Validation, Formal"}], "equations": ["avg\" [n] = \\frac{1}{n} \\sum_{i=0}^{n}Y[i]", "Q_r[n] = Y[n][\\frac{r}{4}n]", "Q_2[n] = Y[n][\\frac{2}{4}n]", "Q_3[n] = Y[n][\\frac{3}{4}n]"]}