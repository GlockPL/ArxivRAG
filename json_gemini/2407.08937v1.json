{"title": "Self-Evolving GPT: A Lifelong Autonomous Experiential Learner", "authors": ["Jinglong Gao", "Xiao Ding", "Yiming Cui", "Jianbai Zhao", "Hepeng Wang", "Ting Liu", "Bing Qin"], "abstract": "To improve the performance of large language models (LLMs), researchers have explored providing LLMs with textual task-solving experience via prompts. However, they rely on manual efforts to acquire and apply such experience for each task, which is not feasible for the growing demand for LLMs and the variety of user questions. To address this issue, we design a lifelong autonomous experiential learning framework based on LLMs to explore whether LLMs can imitate human ability for learning and utilizing experience. It autonomously learns and accumulates experience through experience transfer and induction, categorizing the types of input questions to select which accumulated experience to employ for them. Experimental results on six widely used NLP datasets show that our framework performs reliably in each intermediate step and effectively improves the performance of GPT-3.5 and GPT-4. This validates the feasibility of using LLMs to mimic human experiential learning and application capabilities. Additionally, we provide a detailed analysis of the behavior of our framework at each step.", "sections": [{"title": "1 Introduction", "content": "Recently, large language models (LLMs) like ChatGPT have achieved excellent performance in various NLP tasks (Koco\u0144 et al., 2023; Ye et al., 2023). However, numerous NLP tasks still cannot be effectively addressed by them (Mao et al., 2023; Chang et al., 2023). This is mainly because they have not accumulated enough experience to handle these tasks during their training.\nTo address these issues, previous studies have explored injecting task-solving experience into LLMs during the inference stage via prompts (as shown in Figure 1). Their experience is textual descriptions of the task-solving processes, guidelines, and other insights. Some studies manually craft such experience (Wei et al., 2022; Kong et al., 2023). Others attempt to summarize experience from manually annotated task datasets (Chen et al., 2023a; Zhao et al., 2023; Chen et al., 2024), and then during inference, they essentially need to manually select the experience to apply to each question. However, the demands of users on LLMs are ever-expanding, and the types of user questions continue to grow. These methods would lead to high and unbounded costs for human labor.\nIn contrast, humans are capable of autonomous learning and utilizing experience. Humans categorize encountered problems into different task types and induce experience from multiple concrete task practices, which are reused when encountering new problems of the same task type (Novak and Gowin, 1984; Cox, 1996). Besides, humans can transfer experience between similar tasks, thus gaining more experience without time-consuming practices (Deese, 1952; Perkins et al., 1992). As lifelong autonomous experience accumulates, humans gradually achieve ability growth. Inspired by this, we want to explore whether LLMs can mimic the above process. This could avoid the substantial manual labor and provide a unique evolutionary path for artificial general intelligence.\nTo facilitate this, we propose a lifelong autonomous experiential learning framework called Self-Evolving GPT (SE-GPT), which consists of a task-specific experience memory and five experience-centric modules based on ChatGPT. For any user question, SE-GPT automatically categorizes the target task type and responds to the question with the target task experience in the memory. For newly encountered task types, it learns experience through experience transfer and induction before responding. Firstly, it locates similar tasks in its memory and transfers their experience to the target task. Then, it autonomously references web information and the transferred experience to practice the target task multiple times, thereby inducing more experience from its successes and failures. Finally, the transferred and induced experience is added to the memory. For tasks encountered previously, it assesses the need for repeating experience transfer and induction before responding, taking into account its proficiency level with the task.\nTo conduct experiments, we provide a basic implementation of our framework. We mainly focus on the overall framework and aim to analyze its effectiveness and behavior. Experiments show that our framework is practically feasible. It effectively improves the average performance of GPT-3.5 and GPT-4 on six widely used datasets by 3.8% and 5.3%, respectively. Our framework reliably executes each intermediate module, achieving consistent performance improvements. Besides, we provide a detailed analysis of the behavior of our framework in each intermediate step."}, {"title": "2 Related Work", "content": "To improve the performance of LLMs, researchers provide textual experience to LLMs through prompts. Early studies primarily involve manually crafting such experiential prompts (Wei et al., 2022; Kong et al., 2023), while more recent work focuses on utilizing the LLMs themselves to obtain task-solving experience automatically.\nSome studies focus on how to guide LLMs to automatically summarize experience based on interactive environments. Chen et al. (2023a) guided LLMs to summarize cooking skills in a cooking simulation game. Wang et al. (2023) and Zhu et al. (2023) built LLM-based frameworks in the game \u201cMinecraft\u201d to autonomously learn to complete various game targets. Park et al. (2023) created a sandbox environment similar to \"The Sims\" to guide LLMs in learning role-playing skills. Both Wen et al. (2023) and Fu et al. (2024) taught LLMs how to perform autonomous driving in a simulated driving environment.\nAll of these studies guide LLMs to learn experience based on explicit feedback from environments, which is inaccessible for most NLP tasks. Besides, they require human labor to create the environment or develop feedback-reading methods.\nFor NLP tasks, Zhao et al. (2023) and Chen et al. (2024) leveraged ChatGPT to automatically summarize experience from manually annotated NLP datasets. Zhao et al. (2023) employed Reflexion (Shinn et al., 2023) to generate reasoning chains for each question. Then, the experience is summarized from the questions, chains, and human-annotated labels by ChatGPT. They also found that ChatGPT could transfer the summarized experience from the HotpotQA (Yang et al., 2018) dataset to the FEVER (Thorne et al., 2018) dataset. Chen et al. (2024) analyzed the impact of different examples and prompts on the quality of the summarized experience.\nHowever, these methods still require human labor to obtain experience and determine which experience to employ for the current question. In contrast, our framework autonomously learns and selects experience, saving many human labor costs."}, {"title": "2.1 Autonomous Experiential Learning", "content": null}, {"title": "2.2 Unsupervised In-Context Learning", "content": "In-Context Learning (ICL) provides demonstrations to LLMs, which can be regarded as a specific substitute for textual experience. Therefore, we introduce the recent work on unsupervised ICL.\nSeveral studies aim at predicting labels with LLMs for unlabeled questions, yielding demonstrations (Li and Qiu, 2023; Wan et al., 2023; Zhang et al., 2023). However, these studies still necessitate manual effort for the generation of questions. Therefore, Lyu et al. (2023) directly leveraged retrieved web texts as unlabeled questions, which is only suitable for specific task datasets. In contrast, our framework is task-agnostic and designed to operate autonomously.\nFurthermore, several studies employed LLMs to generate entire demonstrations (Kim et al., 2022; Yu et al., 2023; Chen et al., 2023b). SG-ICL (Kim et al., 2022) requires the development set for selecting demonstrations, while TP-ICL (Yu et al., 2023) is designed explicitly for complex reasoning tasks like shortest-path reasoning, and Self-ICL (Chen et al., 2023b) is the general-purpose one. These demonstrations suffer from issues such as incorrect formatting, noise, and low diversity. However, our framework utilizes the general insights summarized from multiple demonstrations, which is more reliable than the demonstrations themselves."}, {"title": "3 Methodology", "content": "Figure 2 shows the framework of our proposed Self-Evolving GPT, which consists of one task-specific experience memory and five experience-centric modules based on ChatGPT. Our framework continuously receives various user questions. It automatically categorizes the task type of the question, and adds it to memory if it is a new task not yet stored. For tasks that are not proficiently mastered, it performs experience transfer, autonomous practice, and experience induction to update their experience in memory. Finally, it refers to experience stored in memory to respond the user question.\nIn practice, we provide a basic implementation of our framework, which may be further optimized. We primarily focus on the overall framework, and aim to analyze its effectiveness and behavior. The prompts and execution examples of our implementation are presented in Appendix D and E."}, {"title": "3.1 Task-Specific Experience Memory", "content": "We utilize an external memory to store the task-specific textual experience that our framework autonomously learns. This memory starts empty and gradually grows as our framework runs, assisting it in task-solving and learning new experience.\nSpecifically, we store each task in the memory with its name, description and experience. For the completeness of experience, our memory stores two types of experience for each task: 1) Procedure: the specific steps for handling the task; 2) Suggestions: how to better accomplish the task or avoid low-quality responses. These task names, descriptions, and experience are all autonomously generated by our framework."}, {"title": "3.2 Task Type Categorization", "content": "Users may pose various questions to the framework, corresponding to unpredictable task types. Therefore, we employ this module to first autonomously categorize the task type of each user question.\nThe operation of this module is divided into three steps: 1) ChatGPT utilizes Prompt 1 to generate the task name and description based on the question; 2) we retrieve the top 5 tasks from memory that are semantically most similar to the generated task description; 3) finally, ChatGPT utilizes Prompt 2 to select which one of the five tasks is identical to the generated task. If a match is found, the question is linked to the selected task; otherwise, it is linked to the generated task, and we add the generated task into the memory with empty initial task experience. Please note that the word \"task\" in our framework represents a ChatGPT-generated task rather than a classic NLP task (e.g., sentiment analysis) in a certain predefined task list.\nAfter this, we retrieve the experience of the current task from memory, and denote it as \\(E_{mem}\\). Then, we assess whether the current task has been adequately learned following our skip learning condition (\u00a73.6). If it has, we respond to the user question with \\(E_{mem}\\) following our final reasoning prompt (\u00a73.7); otherwise, we learn experience following our experience transfer module (\u00a73.3), autonomous practice module \u00a73.4 and experience induction module \u00a73.5."}, {"title": "3.3 Experience Transfer", "content": "Experience from similar tasks often exhibits transferability (Deese, 1952; Perkins et al., 1992). Therefore, we employ this module to transfer the experience of other tasks in memory to the current task.\nThis module is orchestrated through four fundamental steps: 1) we retrieve the top 10 tasks from memory that are semantically most similar to the target task description; 2) if the previous step outputs at least one candidate task, ChatGPT utilizes Prompt 3 to select which among the 10 tasks should be chosen as source tasks for the transfer; 3) if the previous step outputs at least one source task, ChatGPT utilizes Prompt 4 to facilitate a step-by-step experience transfer process. It begins by understanding the differences between the source and target tasks, then identifying shared general experience between them, and finally rephrasing the general experience in the context of the target task. We denote such experience as \\(E_{transferred}\\); 4) if \\(E_{mem}\\) is not empty, ChatGPT utilizes Prompt 5 to merge \\(E_{transferred}\\) and \\(E_{mem}\\) for updating \\(E_{transferred}\\). If steps 1 and 2 fail to select any source tasks, \\(E_{mem}\\) is employed as \\(E_{transferred}\\)."}, {"title": "3.4 Autonomous Practice", "content": "Humans can autonomously practice tasks and derive experience from practice instances. Therefore, we employ this module to mimic the process of human autonomous practice. For the current target task, it automatically generates multiple examples, including questions, responses, and labels indicating whether the responses are correct. Additionally, it utilizes the transferred experience and the autonomously retrieved web information to provide references for its practice process.\nThis module performs autonomous practice step by step: 1) we retrieve web documents that are semantically most related to the user question; 2) ChatGPT utilizes Prompt 6 to reference one of the retrieved web documents, the user question, and the task description generated in \u00a73.2 to generate a new question; 3) ChatGPT utilizes Prompt 7 to respond to the generated new question with \\(E_{transferred}\\); 4) ChatGPT utilizes Prompt 8 to reference the web document in the second step for verifying the correctness of its responses. We repeat the above steps to obtain five examples for the current task."}, {"title": "3.5 Experience Induction", "content": "After the autonomous practice, we summarize new experience for the current task from examples generated in \u00a73.4 with correct or incorrect answers.\nIn practice, we utilize Prompt 9 to guide ChatGPT in summarizing experience step-by-step. ChatGPT first summarizes the commonalities in the correct examples, identifying patterns in the incorrect examples, and compares the differences between the correct and incorrect examples. Then, based on these observations and analysis, ChatGPT tries to summarize task-solving insights generally applicable to unseen examples of the current task. We denote such experience as \\(E_{induced}\\). After that, if \\(E_{transferred}\\) is not empty, we utilize Prompt 5 to merge \\(E_{induced}\\) and \\(E_{transferred}\\) for updating \\(E_{induced}\\). Finally, we replace \\(E_{mem}\\) in memory as \\(E_{induced}\\), which has been enhanced through experience transfer, autonomous practice and experience induction."}, {"title": "3.6 Learning or Skip Learning", "content": "The tasks that our framework has already adequately learned do not require further learning. It is inefficient to repeat learning for each user question.\nImplementation-wise, our memory records the number of incorrect examples during each autonomous practice stage. If the number of incorrect examples remains zero three times for the same task, we consider that such task has already been adequately learned, and further learning is skipped.\nAlthough we provide a basic skip condition, it may be modified for different preferences for efficiency and experience quality."}, {"title": "3.7 Reasoning with Experience", "content": "Finally, we utilize Prompt 10 to guide ChatGPT in responding to the user question with the experience of the current task in memory. For tasks that require further learning, the experience stored in memory has been enriched through experience transfer, autonomous practice, and experience induction."}, {"title": "4 Experiments", "content": "We conduct experiments on the mixture of the following six widely used NLP datasets, including: 1) MMLU (Hendrycks et al., 2021), which is a massive multitask test consisting of multiple-choice questions from various branches of knowledge, covering 57 tasks; 2) e-CARE (Du et al., 2022), which is a causal reasoning dataset that requires determining which option is the cause or result of a given event from various domains; 3) SocialIQA (Sap et al., 2019), which is a social commonsense test that focuses on reasoning about people's actions and their social implications in various social situations; 4) WinoGrande (Sakaguchi et al., 2021), which is a robust commonsense reasoning dataset formulated as a fill-in-a-blank task with binary options; 5) HELP (Yanaka et al., 2019), which is a natural language inference dataset that focuses on logical inferences licensed by phrase replacements, so-called monotonicity reasoning; 6) LogiQA-2 (Liu et al., 2023), which is sourced from expert-written questions for testing civil servants, covering multiple types of deductive reasoning.\nWe randomly select K data points from each dataset and mix them randomly as the test dataset. The test dataset includes human annotated labels, which are only used for evaluating performance. For GPT-3.5, K=1,000, resulting in a final experimental data size of 6,000. For GPT-4, K=500, resulting in a final experimental data size of 3,000. We adopt accuracy (Acc) as the evaluation metric and report the average accuracy of three rounds of predictions to reduce randomness. For the human evaluation in our experiments, three evaluators are asked to perform annotations."}, {"title": "4.1 Datasets and Evaluation Metrics", "content": null}, {"title": "4.2 Parameters Setting", "content": "We conduct experiments using OpenAI's official API\u00b9 with two versions of ChatGPT separately, including gpt-3.5-turbo-1106 (GPT-3.5) and gpt-4-1106-preview (GPT-4). Moreover, temperature is fixed as 1. The retrieval operations in \u00a73.2, \u00a73.3 and \u00a73.4 are accomplished by the Faiss index (Johnson et al., 2021). For the stability of Prompt 2 and 8, we run them multiple times until one option is output twice, and then we select this option as the final output. The web texts in \u00a73.4 are retrieved from Wikipedia and truncated"}, {"title": "4.3 Baselines", "content": "In our experiments, we employ the following baseline methods: 1) Zero-shot, we directly feed the input question into ChatGPT; 2) Zero-shot-CoT, we add \"Let's think step by step\" at the end of each input question and then feed it into ChatGPT; 3) Self-EXP, we first utilize Prompt 11 to instruct ChatGPT to directly generate experience for each input question. Then, just like our framework, we utilize Prompt 10 to guide ChatGPT in responding to each input question with the experience generated for it; 4) Self-ICL (Chen et al., 2023b), which first prompts ChatGPT to generate new questions following the input question. Subsequently, ChatGPT predicts pseudo-labels for the new questions via zero-shot prompting. Finally, it performs ICL for the input question with the pseudo-question-label pairs as demonstrations; 5) Self-ICL-COT (Chen et al., 2023b), which is a Chain-of-Thought-based variation of Self-ICL. It adds \"Let's think step by step\" at the end of new questions and the input question before predicting them. We faithfully replicated the methods of Chen et al. (2023b) according to their origin paper; 6) Modified Self-ICL, from the test dataset, we retrieve the top 5 examples with the highest semantic similarity for each test example, to replace the generated input question in the self-ICL; 7) AutoP-ICL, employs demonstrations generated by our autonomous practice module (\u00a73.4) to perform in-context learning. Specifically, the pairs (new question, reasoning process) deemed correct by our auto practice module are concatenated with the user query as the prompt for LLMs."}, {"title": "4.4 Main Results", "content": "Firstly, our SE-GPT achieves consistently better performance than baseline methods and improves the average performance of zero-shot GPT-3.5 and GPT-4 by 3.8% and 5.3%, respectively. This is because our framework can effectively learn task-solving experience and select appropriate experience for the input question.\nSecondly, across all datasets, our framework shows the most significant gains over zero-shot GPT-3.5 and GPT-4 on the HELP dataset, with improvements of 5.5% and 8.2%, respectively."}, {"title": "4.5 Effect of the Experience Transfer and Induction", "content": "As shown in Table 2 and Table 3, we analyze the variations of our framework with/without the experience transfer and the experience induction module: 1) \"- w/o transfer\", directly skips the experience transfer module of our framework; 2) \u201c- w/o induction\", skips the experience induction module after 1/3 of all test data in our experiments, i.e., 2,000 for GPT-3.5 and 1,000 for GPT-4. Please note that our framework learns from the test data (only their inputs and not their labels) as it proceeds to the next instance. In human evaluation, we randomly select the experience of 100 tasks from memory and then identify insights that are incorrect, unrelated to the tasks, or cannot be followed by LLMs to report the \"Acc\". We find that:\nFirstly, both experience transfer and induction contribute to the performance and the experience quantity of the overall framework. This is mainly because they can acquire experience for the target task by transferring from other tasks or summarizing from multiple examples, respectively.\nSecondly, \"- w/o induction\u201d maintains an acceptable level of performance. This indicates that after running for some time, our framework can still achieve consistent improvement only through experience transfer, which is more cost-effective than experience induction.\nBesides, our framework can generate high-quality experience. This arises from the fact that our framework references web texts to generate"}, {"title": "4.6 Analysis of the Task Type Categorization", "content": "Task type categorization is the first module of our framework and critically influences the performance of subsequent modules. Table 4 shows the human-evaluated accuracy of our task type categorization module. For each dataset, we randomly evaluate 100 questions linked to newly generated tasks and 100 questions matched to tasks in memory. Accuracy on all data is reported as the weighted accuracy average for both. We find that ChatGPT performs very well in this stage. This is mainly due to it is not a difficult task, and we provide a reasonable prompt for ChatGPT.\nFigure 3 shows the proportion of the input questions that are matched to tasks in memory or skip the learning process. These proportions determine the efficiency of our framework in utilizing stored experience without the need to repeat the experiential learning process for each question. We find that: 1) compared to GPT-3.5, more questions are matched and skipped by GPT-4. The main reason is the stronger capabilities of GPT-4, allowing it to better recognize learned tasks and meet the skipping criteria in \u00a73.6; 2) the trends in SocialIQA are opposite to those in other datasets. This may arise from the differences of ChatGPT in the prior knowledge and biases of task categorizing."}, {"title": "4.7 Analysis of the Experience Transfer", "content": "Table 5 shows the human-evaluated accuracy of our source task selection process. For each dataset, we randomly evaluate 100 target tasks, leading to 2,825 source-target task pairs. We find that: 1) overall, ChatGPT performs well in selecting source tasks. This is mainly because recognizing similarity is not a difficult task; 2) the accuracy on MMLU is relatively low. This might arise from the diverse types of tasks in MMLU and its low similarity with other datasets. However, our framework still achieves improvements on MMLU. This is due to we identify shared insights among multiple source tasks, excluding non-transferable insights.\nFigure 4 shows the average number of source tasks of each input task varying with runtime. The operating round refer to the number of test questions processed by our framework. As the operating rounds increase, our framework can utilize more source tasks. The main reason is the increasing types of tasks in memory. This also implies that our framework could continually enhance its transfer ability, benefiting from lifelong learning."}, {"title": "4.8 Analysis of the Autonomous Practice", "content": "As shown in Table 6, we analyze the performance of the autonomous practice module with/without reference web texts. We randomly selected 300 generated examples and manually evaluate whether the validation results are correct. Besides, we report the diversity of new questions generated per input question. We find that by referencing web texts, our framework significantly improves both the validation accuracy and the diversity of generated questions. This is because: 1) the differences in reference texts lead to variations in generating questions; 2) the texts referenced by question generation usually contain question-solving information."}, {"title": "4.9 Analysis of the Experience Induction", "content": "As shown in Figure 5, we repeatedly perform the autonomous practice and the experience induction module, reporting the number of generated insights. We randomly select 100 questions and employ GPT-3.5 for the test. We find that the experience increases with each round and stabilizes at the 8th round. This is because as the quantity of experience increases, the difficulty of acquiring new experience grows. Through case observation, we find that almost all of the insights obtained in round 9 are included in the experience obtained previously."}, {"title": "5 Conclusion & Future Work", "content": "In this paper, we propose a lifelong autonomous experiential learning framework based on LLMs. It continuously and autonomously accumulates experience in solving tasks through experience transfer and induction, recognizing the nature of input questions to align them with relevant experience. Considering the increasing demand for LLMs and the emergence of new types of user questions, our framework effectively reduces the human labor associated with previous methods. Experiments show that the implementation of our framework can reliably execute each intermediate module and effectively enhance overall performance for responding to the input question. The following content may be subject to our research in future work: 1) Enhanced engineering designs. We only offer a basic implementation for our framework, and there is still room for improvement, e.g., supporting more complex functions; 2) Cold start. At present, we run our framework completely from empty memory. However, the existing manually annotated datasets can be used to replace the autonomous practice module. Our framework can first learn from the manually annotated datasets, complete the cold start, and then run independently; 3) Employing a combination of different-scaled LLMs to implement the framework. It is evident that not all tasks necessitate using ChatGPT; integrating LLMs of various scales can achieve a balance between cost and performance; 4) Experience Distillation. Distilling the rich experience summarized by GPT-4 onto smaller-scale LLMs to enhance their performance on tasks that have been adequately learned by GPT-4."}, {"title": "Limitations", "content": "In this work, we design a framework to validate the feasibility of using LLMs to mimic human experiential learning and application capabilities. However, it is a basic implementation for experimental exploration but not a perfect LLM product, with room for improvement: 1) Experience Failure and Operating Error: Even with high-quality experience, LLMs may still make mistakes. Common errors we observed include reasoning errors/hallucination, LLMs disregarding partial experience, and LLMs lacking necessary knowledge to solve problems. Besides, the steps such as auto practice, experience induction and transfer are complex, and there still remains some noise in the obtained experience; 2) Both Computationally and Financially Expensive: the system repeatedly invokes an LLM, which is quite expensive both computationally and also financially. In \u00a7A.4, we carefully discuss our prompt cost and possible methods to reduce the cost. 3) Task Applicability: Experience may still be effective in tasks requiring skills such as mathematical reasoning, but it might not be as effective for tasks relying on factual knowledge such as WikiQA. Therefore, the framework should have the ability to adaptively determine whether past experience is needed;"}, {"title": "A Additional Experimental Analysis", "content": null}, {"title": "A.1 Number of Source Tasks Varying with Runtime based on GPT-4", "content": "Figure 6 shows the average number of source tasks selected for each target task during the execution of our framework based on GPT-4. Overall, the performance of GPT-4 is consistent with the performance of GPT-3.5 that we analyzed in \u00a74.7. An exception occurs with the HELP dataset, where the number of source tasks runs to 0 between 1500 to 2500 iterations. This is due to we do not consider input questions that skip learning when calculating the average number of source tasks. In other words, between 1500 to 2500 iterations, no examples in the HELP dataset require experience transfer. This is because the proportion of questions skipping learning is relatively high in the HELP dataset, as described in \u00a74.6."}, {"title": "A.2 Number of Tasks and Experience in the Memory Varying with Runtime", "content": "Figure 7 and Figure 8 show the number of insights and tasks in memory during the execution of our framework based on GPT-3.5 and GPT-4, respectively. We find that as the number of running rounds increases, our framework accumulates more task-specific experience. This indicates that the capabilities of our framework grow over time, enabling it to cover a broader range of user target tasks or provide experience for more user questions through experience transfer."}, {"title": "A.3 Performance of Experience Induction Through More Examples", "content": "Figure 9 shows the number of experience generated by the experience induction module based on GPT-3.5 with more input examples. It can be found that ChatGPT cannot effectively summarize more experience from a larger number of examples. This may be due to the increased difficulty for ChatGPT to analyze, requiring ChatGPT to think for a longer time."}, {"title": "A.4 Prompt Cost", "content": "As shown in Table 7, we analyze the cost of our framework by reporting the average token usage per prompt for each example. Please note that for a single example, a prompt may be run multiple times due to reasons such as output format errors or API crashes. All these occurrences are included in the statistics to reflect the true cost.\nIt can be found that, compare to the traditional zero-shot CoT method, our framework are much more expensive and time-consuming. Overall, our main experiment using GPT-3.5 requires about five days of running, whereas GPT-4 requires three to five times longer. However, this does not mean that the framework is without hope for practical application, as our current basic implementation focuses more on demonstrating the behavior of LLMs at various stages, without any optimization for efficiency. We believe the following approach can be further explored to reduce operational costs:\n\u2022 Use existing annotated corpora to replace the Autonomous Practice module. It can be found that the main cost of our framework lies in the Autonomous Practice module. Our previous experimental results indicate that, given sufficient prior experience, our framework can perform comparably to the complete framework solely through experience transfer. Therefore, allowing the framework to gain experience from existing annotated corpora first could significantly reduce the substantial costs associated with the Autonomous Practice module.\n\u2022 Consider using smaller PLMs to perform simple steps. Within our framework, prompts 4, 9, and 10 are involved in experience transfer, experience induction, and experience application, respectively. Other steps are relatively simple and can be substituted with smaller PLMs instead of the expensive ChatGPT."}, {"title": "B Case Study", "content": "In this section, we analyze the case of Self-EXP and Self-ICL."}, {"title": "B.1 Experience Generated by Self-EXP", "content": "Self-EXP employs Prompt 11 to instruct ChatGPT to directly generate experience for each input question. Case 1 shows the example of experience output by Self-EXP based on GPT-3.5.\nFor the 1st example, we can find that although the generated experience seems reasonable, it is not well aligned with the input problem. In fact, these generated insights are wrong or irrelevant to the input problem. The possible reason is that ChatGPT only focuses on the keywords of the input question without understanding the essential task objective and the processing flow of the task.\nFor the 2nd example, Self-EXP suggests that \"Consider Addison's typical preferences and behaviors\" and \"Ask Jesse about Addison's purpose.\" are valuable insights. These suggestions require LLMs to have the ability to actively explore unknown information and communicate with humans. However, ChatGPT itself does not possess such abilities, and implementing such abilities requires additional auxiliary modules.\nCompared with Self-EXP, our framework generates multiple pairs of pseudo questions and reasoning processes, and summarizes experience from them. This ensures that the experience generated by our framework is highly consistent with the input question and matches the abilities of LLMs. Besides, this enables our framework to discover new insights rather than relying solely on the experience learned during ChatGPT's pre-training process."}, {"title": "B.2 Demonstrations Generated by Self-ICL", "content": "Self-ICL prompts ChatGPT to generate demonstrations for each input question. Case 2 shows the example of demonstrations generated by Self-ICL based on GPT-3.5. We can find that:\nFirstly, there is a format inconsistency between the input question and the question generated by Self-ICL. In fact, this format issue is not an exception but often occurs in generated pseudo questions. ICL will make such format errors interfere with the reasoning process of the LLMs.\nBesides, the 2nd example contains a wrong pseudo-response. This response error is difficult to avoid for LLMs unless they have fully mastered the task type of the input question.\nIn summary, the demonstrations generated by Self-ICL exhibit issues such as inconsistent formatting and noisy responses. However, our framework does not directly utilize the generated demonstrations; instead, it extracts general experience from demonstrations, thereby mitigating the impact of the issues above."}, {"title": "C Additional Information on Responsible NLP Research", "content": "Use Scientific Artifacts. As shown in Section \u00a74.1, we use six NLP benchmark datasets in English. They are all allowed to be used for scientific research. They do not contain information that names or uniquely identifies individual people or offensive content.\nHuman Evaluators. We recruit NLP graduate students to conduct evaluation and are compensated by providing academic credits and guidance. They know explicitly that the annotated data is used for scientific research.\nAI Assistants in Writing. We use ChatGPT to help check for grammatical errors and provide suggestions for improving language expression."}, {"title": "D Prompts", "content": null}, {"title": "E Examples of Our Framework", "content": "In this section, we demonstrate examples of our framework. Due to the memory limits on arXiv's compilation, subsequent pages are available through the following link:\nhttps://drive.google.com/file/d/\n17zc4oUuvq2-BsaZ55Zd9013TCVU49RxF/view?usp=share_link"}]}