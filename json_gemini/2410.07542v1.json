{"title": "Generalizable Indoor Human Activity Recognition Method Based on Micro-Doppler Corner Point Cloud and Dynamic Graph Learning", "authors": ["Xiaopeng Yang", "Weicheng Gao", "Xiaodong Qu", "Haoyu Meng"], "abstract": "Through-the-wall radar (TWR) human activity recognition can be achieved by fusing micro-Doppler signature extraction and intelligent decision-making algorithms. However, limited by the insufficient priori of tester in practical indoor scenarios, the trained models on one tester are commonly difficult to inference well on other testers, which causes poor generalization ability. To solve this problem, this paper proposes a generalizable indoor human activity recognition method based on micro-Doppler corner point cloud and dynamic graph learning. In the proposed method, DoG-\u03bcD-CornerDet is used for micro-Doppler corner extraction on two types of radar profiles. Then, a micro-Doppler corner filtering method based on polynomial fitting smoothing is proposed to maximize the feature distance under the constraints of the kinematic model. The extracted corners from the two types of radar profiles are concatenated together into three-dimensional point cloud. Finally, the paper proposes a dynamic graph neural net-work (DGNN)-based recognition method for data-to-activity label mapping. Visualization, comparison and ablation experiments are carried out to verify the effectiveness of the proposed method. The results prove that the proposed method has strong generalization ability on radar data collected from different testers.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the development of non-intrusive surveillance and monitoring systems has become crucial for applications in security, search and rescue operations, and situational awareness [1]\u2013[4]. Through-the-wall radar (TWR) technology emerges as a promising solution for detecting and recognizing human activities behind obsta-cles [5]. However, the ability to accurately recognize and classify specific human activities through walls remains challenging tasks [6], [7]. Micro-Doppler refers to the modulation of radar signals by limbs and body parts [8]. By analyzing the micro-Doppler signature, it is possible to extract unique motion features to identify and classify human activities.\nThe processing flow of the human activity recognition system based on micro-Doppler analysis for TWR con-tains three common stages: signal and data processing, feature extraction and dimension reduction, and recogni-tion decision [9]. A great deal of academic researches have been invested in all steps and a range of results have been achieved. Ram et. al., presented a simula-tion methodology for generating micro-Doppler radar signature of humans moving behind a wall [10]. Liang, proposed a standard deviation (STD)-based approach to sense-through-wall and sense-through-wooden-door hu-man detection, and made analysis on detection threshold selection [11]. To cope with the issue that traditional time-frequency analysis algorithms were not good at displaying complete micro-Doppler information in radar echoes, a multiple Hilbert-Huang transform (MHHT) method was proposed for high-resolution time-frequency transform of digging fine-grained human activity hidden micro-Doppler signature in ultra-wideband (UWB) radar echoes during the through-wall detection environment [12]. Sun et. al., demonstrated the effectiveness of a passive indoor human sensing technique using WiFi signals [13]. These researches mainly focused on the first two steps: signal and data processing, feature extraction and dimension reduction.\nWith the rapid development of neural network algo-rithms in the field of computer vision, researchers began to focus on their applicability for radar image recognition tasks. Wang et. al., studied through-the-wall human activ-ity classification using complex-valued CNN and graph conducted CNN [14]\u2013[16]. The methods were utilized to classify the human activity behind the wall with the input of concatenated time domain echo matrix. An et. al., proposed a method that cascaded robust principal com-ponent analysis (RPCA) and ResNet for through-the-wall radar human activity recognition, which was one of the pioneering works in the field combining feature separation and CNN [17]. Other influential works were the series of Chen's cross-domain or cross-view learning meth-ods [18]\u2013[20]. These networks achieved strong micro-Doppler distribution fitting capabilities by pre-collecting a large amount of data. However, the inference ability was heavily depended on the training data set. We have proposed a variety of methods for data augmentation [21], finer-grained micro-Doppler signature extraction [22] or faster inference speeds [23], respectively. Unfortunately, the exsisted methods mentioned above were all trained, validated, and tested under the same tester. However, limited by the insufficient priori of tester in practical indoor scenarios, the trained models on one tester were commonly difficult to inference well on other testers, which caused poor generalization.\nTo address this issue, we have been dedicated in some researches works, shown in Fig. 1. The concept of micro-Doppler corner features was proposed and some theoretical analyses with front-end algorithms were given. In [24], [25], a feasibility validation for the task of recog-nition generalizations was presented, including kinematic models under walking and abnormal activities, and deci-sion scheme. Detailed theoretical analysis of the micro-Doppler corner feature was developed, showing that the minimum number of corners needed to characterize hu-man activity was 30. DoG-\u00b5D-CornerDet was employed for corner extraction with strong robustness [26]. All these methodological and theoretical analyses would serve as a prelude to the full-process design ideas of the decision model and generalization recognition system proposed in this paper.\nBased on the previous works, there are two important issues that need to be addressed: First, how to filter the resulting corner features when the number of points"}, {"title": "II. SIGNAL MODEL AND DATA PREPROCESSING", "content": "As shown in Fig. 2, the human can be seen as extended target in the through-the-wall detection scenario. Without considering the multi-path effect, the radar echo can be approximated as the summation of the echoes from wall, human limb nodes, and background noise.\nAssuming that the transmit signal contains M pulse repetition intervals (PRI) during the coherent processing interval, then the transmitting signal in mth PRI is:\n$Stx,m(t) = Atxei (2\u03c0(fc(t-mT\u300f)+\u00bd\u00b5(t-mT\u300f)\u00b2)+6tx)$, $mTs \u2264 t \u2264 (m + 1)Ts$ ,  (1)\nwhere $Atx$ is the amplitude of the transmitted signal. $ts$ is the PRI, $\u03bc = \u0392/T$, is the slope of frequency modulation, $B$ is the bandwidth, and $fe$ is the carrier frequency. $Otx$ is the initial phase of the transmitted signal. t in Eq. (1) denotes the fast time axis, m in Eq. (1) denotes the slow time axis.\nGiven that the range resolution and wavelength for TWR is about at decimeter level [5], the number of human limb nodes is about 6 to clearly represent the echo. For example, head, torso, left hand with arm, right hand with arm, left foot with leg, and right foot with leg are taken into consideration. Thus, the complete time-domain echo of the human target is:\n$Sb,m(t) = \u2211 Sb, Ni,m(t)$\n$\n= \u2211 Ab, N 32\u03c0 (fc'; (4)-TN (t)+(t-mTs); (t))$ \ni=1\ni=1 (2)\nAssuming that the wall echo is $Sb,m,wall(t)$, and the background noise is $Sb,m,noise(t)$, the complete radar time-domain echo can be eventually written as:\n$Sb,m(t) = \u2211\nej2n (fct'N; (t)-\u03bc\u03c4'\u03bd; (t)+\u03bc(t-mTs)T'N;\nAb, Ne\n+Sb,m,wall(t) + Sb,m,noise (t)\ni=1\n(t))$  (3)\nThe first summation term of $Sb,m(t)$ contains the micro-Doppler information of the human body motion, including the distance and velocity of the nodes. Un-fortunately, it is difficult to extract the distance and velocity information of the human motion directly from the radar time-domain echoes. Therefore, a combination of data processing algorithms such as time-frequency analysis and image transformation is needed to visualize the micro-Doppler signature.\nAs shown in Fig. 3, we concatenate the radar time-domain echoes of all M PRIs along the slow time dimension, take the modulus and normalize it to obtain the range-time map (RTM):\nRTM = Norm (Conm=) (Sb,m(t))|),  (4)\nwhere Con is a vector concatenation operation, and Norm is a linear normalization method for matrices. If the real-valued matrix to be normalized is X, then:\nNorm(X) =X - max(X)\nmax(X) - min(X)  (5)\nwhere max() and min() take the maximum and minimum values of the matrix, respectively. The RTM mainly contains the wall echo RTMwall, the human motion echo RTMmv, and the background noise Ns, that is:\nRTM = RTMwall + RTMmy + Ns. (6)\nIn this case, the term RTMwall can be removed by the moving target indicator (MTI) filter [28]:\nRTMmv + Ns \u2248 RTM[:, m + 1] \u2013 RTM[:, m]\nm = 0,1,..., M-1  (7)\nThe Doppler information in the radar echoes is ex-tracted by using short-time Fourier transform (STFT), generating Doppler-time map (DTM) [29]. First, the time-domain echoes are concatenated along the slow time dimension. After suppressing the static target clutter by MTI, the matrix is summed along the fast time dimension to obtain a row vector of length M. The STFT is per-formed on this row vector and DTM is obtained by taking the amplitude normalization result of the transformed two-dimensional (2D) time-frequency matrix. The mathemat-ical representation of the above process can be written in Eq. (8), where wl, ol represent the window length of the STFT and the overlap length between neighboring windows, respectively."}, {"title": "III. PROPOSED CORNER FEATURE REPRESENTATION AND RECOGNITION METHOD", "content": "In our previous works", "25": ".", "26": ".", "errors": "n$Sord = \u03a3\u03a3 akik\ni=-P\nk=02\nXi$ (9)\nwhere $x$ is the sliced vector", "31": "n$jj+k\nak\nk=0i-1\ni=-P = \u03a3i xi$ (10)\nj = 0", "follows": "n(ATA)a = ATx (11)\nwhere A is the Vandermonde matrix with respect to the parameter P. The parameters are calculated using:\na = A+x", "12)\nwhere": "na = [a0, a1,..., an", "x\u2212P,...,X\u22121,X0,X1,...,Xp": 14}]}