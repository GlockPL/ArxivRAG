{"title": "COST CA20120 INTERACT Framework of Artificial Intelligence Based Channel Modeling", "authors": ["Ruisi He", "Nicola D. Cicco", "Bo Ai", "Mi Yang", "Yang Miao", "Mate Boban"], "abstract": "Accurate channel models are the prerequisite for communication-theoretic investigations as well as system design. Channel modeling generally relies on statistical and deterministic approaches. However, there are still significant limits for the traditional modeling methods in terms of accuracy, generalization ability, and computational complexity. The fundamental reason is that establishing a quantified and accurate mapping between physical environment and channel characteristics becomes increasing challenging for modern communication systems. Here, in the context of COST CA20120 Action, we evaluate and discuss the feasibility and implementation of using artificial intelligence (AI) for channel modeling, and explore where the future of this field lies. Firstly, we present a framework of Al-based channel modeling to characterize complex wireless channels. Then, we highlight in detail some major challenges and present the possible solutions: i) estimating the uncertainty of Al-based channel predictions, ii) integrating prior knowledge of propagation to improve generalization capabilities, and iii) interpretable AI for channel modeling. We present and discuss illustrative numerical results to showcase the capabilities of AI-based channel modeling.", "sections": [{"title": "I. INTRODUCTION", "content": "Wireless channel modeling represents a fundamental challenge in development of wireless communications, and is of paramount importance for the design and performance evaluation of next-generation wireless networks. The growing number and density of devices, coupled with high-mobility users and increased traffic demands from emerging use cases in 5G and 6G, pose significant challenges in obtaining timely and reliable channel information to ensure optimal communication performance [1] [2]. The expansion of mobile communication systems in space-time-frequency domains has led to increased complexity in radio propagation, and made accurate channel modeling more challenging. The current channel modeling methods exhibit inherent limitations, failing to satisfy the demands of next-generation communication systems for high-precision generalizable channel models. As the propagation process of radio waves grows increasingly complex, the traditional statistical and deterministic channel models face increased complexity, resulting in constraints on the adaptability to various scenarios and capacity for self-evolution. Consequently, there is a pressing need to explore novel modeling methods and technologies capable of effectively addressing the intricacy and uncertainty of wireless channels. The advancement of artificial intelligence (AI) technology represents a promising avenue for revolutionizing wireless channel modeling. The deployment of massive communication nodes generates a wealth of data related to their respective channels and overall communication activities. This data offers opportunities for learning underlying patterns, which can be harnessed for efficient channel modeling and prediction.\nAl has proven to be a powerful tool for modeling complex non-linear functions. For channel modeling and prediction, the relation between the channel to be modeled/predicted and the known/collected information about the channels also exhibits such non-linearity. To that end, a lot of work leveraged AI models, specifically Deep Neural Networks (DNNs), to learn mappings between collected measurements and the wireless channel [3][4]. On the one hand, when dealing with intricate channel modeling problems where the understanding of physical propagation environment is limited, an Al-based propagation model functions essentially as a black box: it identifies the underlying patterns between input data or output labels and the corresponding input features without providing a human-understandable explanation. On the other hand, when there are some inferred physical or theoretical insights available, AI can be directed toward enhancing the accuracy of a baseline propagation model by introducing effective correction factors.\nIn terms of the channel modeling task at hand, recent research mainly explores the use of AI in the following three broad directions: i) classification; ii) clustering; and iii) regression. In the context of channel modeling, classification can refer to, for instance, scenario identification [5]. Channels can be classified into different categories based on the collected channel features (e.g., high/low speeds and Doppler) or based on geographical or context information (e.g., highway, tunnel, urban). Clustering refers to the identification and grouping of multipath contributions with similar characteristics [6]. Multipath clustering plays a crucial role in simplifying the complexity of channel modeling while capturing the fundamental aspects of propagation. Finally, regression can help in the direct prediction of the channel characteristics by establishing the cause-and-effect relationship between"}, {"title": "II. GENERAL FRAMEWORK OF AI-BASED CHANNEL MODELING", "content": "Complex and dynamic environments and radio propagation processes have made it increasingly challenging to mine and predict the underlying features of massive channel data. Developments of AI technologies have laid the foundation for establishing deep and complex correlations between environmental information and propagation mechanisms. AI can effectively use environmental information and historical data to learn and extract complex nonlinear features in channels, thereby enabling accurate prediction of channel characteristics. Here, we present the proposed general framework of AI-based channel modeling as in Fig. 1. The framework is composed of input, output, and AI model components. The input generally includes channel- and environment-related data. Channel-related data includes raw channel data and various channel features, whereas environment-related data includes spatial data (e.g., satellite images), quantitative data (e.g., building density), and temporal data (e.g., hydrological data). The output of AI model is usually channel characteristics, and the Al model can captures dynamic changes of input so as to achieve channel inference at output.\nThe AI channel model can be generally divided into generative and discriminative models. Generative models aim to model the joint probability distribution of input features and output labels. They can be used to model the entire distribution of input (transmitted signal) and output (received signal) variables. Generative models are particularly useful if the goal of channel modeling task is to generate a large amount of synthetic/simulated channel data, when a sufficiently large and heterogeneous input dataset is available. Discriminative models, on the other hand, model the conditional probability of output labels given the input features. They can be used directly model the relationship between input (training) and output channels, without explicitly modeling the entire distribution. Logistic regression and neural networks are typical discriminative models that can be applied to predict channel state or characteristics. They can integrate system parameters with multi-source data and process different data through distinct neural networks. Loss function should be constructed, which can be designed based on feature enhancement according to AI model interpretation, highlighting the impact of particular features. Alternatively, loss function can be driven by prior channel models to construct propagation constraints. Moreover, priori knowledge such as propagation mechanism can be used for model tuning to enhance prediction accuracy and generalization ability. Specifically, the AI model can either use prior knowledge from existing channel models as references, or"}, {"title": "III. UNCERTAINTY-AWARE AI FOR CHANNEL MODELING", "content": "Many of the popular AI models for channel modeling, such as DNNs or decision trees/random forests, output point predictions by default. This is a significant limitation, as it makes the end-users unaware of the potential prediction errors that the model might be making. In other words, although the model achieves a low average error, we generally have no information on the uncertainty associated with individual predictions. For instance, when leveraging AI-based channel models for wireless network planning, informing users that a prediction has high uncertainty allows for more informed and less risky decision-making. Alternatively, the predictive uncertainty can be employed in an Active Learning context, such that the data collection process (e.g., a measurement campaign or RT simulation) is guided towards annotating inputs whose predictions are highly uncertain. It is, therefore, of great importance and practical utility to estimate the predictive uncertainty when leveraging AI for channel modeling.\nA natural solution for uncertainty quantification is to provide probabilistic predictions (e.g., in the form of a confidence interval) instead of point predictions. Even though there are many solutions for probabilistic AI, such as Bayesian Neural Networks and Quantile Regression (QR), they do not provide any formal guarantee that their probabilistic predictions will be truthful to the actual data distribution. Recent approaches based on Conformal Prediction (CP) solve this fundamental issue. In contrast to prior methods, CP makes minimal assumptions about the data distribution (i.e., data exchangeability, which is a weaker assumption than independent and identically distributed data) while providing explicit, finite-sample probabilistic guarantees. An attractive and easy-to-apply CP algorithm is Conformal Quantile Regression (CQR) [10]. CQR extends classical QR algorithms by outputting prediction intervals guaranteed to contain the ground-truth with a user-specified probability. The CQR workflow requires a \u201cproper\" training set to fit a pair of QR models and a calibration set to perform a post-hoc correction of the predicted quantiles. More specifically, the model predictions on the calibration set are used to compute a \u201ccorrection factor\" to the predicted quantiles, such that the resulting prediction intervals are theoretically guaranteed to contain the ground truth with a user-specified probability. The idea of CQR is to take conventional QR models, such as deep quantile neural networks, and correct their predictions a posteriori. This is because conventional QR models (e.g., deep quantile neural networks) do not guarantee the user-specified confidence interval coverage levels (e.g., 95%). CQR computes \"conformity scores\" from a held-out calibration set, and then applies a corrective factor to the predictive confidence intervals equal to the 1-\u03b1 empirical quantile of the calibration set conformity scores. Specifically, for CQR, the conformity score is shaped to be positive if the ground-truth falls outside the predicted interval, and negative otherwise. We then compute a \"correction factor\" equal to the 1-\u03b1 empirical quantile of the conformity scores in the calibration set. Finally, to perform a prediction on a new test point, we first obtain a confidence interval from our QR model, and then adjust it by subtracting and adding the correction factor to the lower and upper predicted quantiles, respectively. Remarkably, such intervals are theoretically guaranteed to contain the ground truth with 1-\u03b1 probability. We illustrate in Fig. 2 a schematic representation of the CQR algorithm, including the computation of the conformity scores and the correction factors.\nAs an illustrative example, we consider a radio map estimation task based on the RadioMapSeer dataset [11]. This dataset comprises a collection of 2D urban maps alongside path loss estimations derived via RT simulations. Specifically, coverage maps were computed for 800 urban maps with 80"}, {"title": "IV. PHYSICS-INFORMED AI FOR CHANNEL MODELING", "content": "A fundamental issue of Al-based channel modeling is the generalization to scenarios unseen at training time. Though channel models are generally site-specific, it is expected that an AI-based channel model will be able to generalize to propagation conditions like the ones seen during training. Generalization can be particularly challenging if the training data, e.g., samples from a measurement campaign, is scarce. Al models are generally unaware that the training data stems from physical phenomena, which makes them prone to overfitting in data-scarce scenarios. A solution is incorporating domain knowledge from the physics domain into the Al pipeline. Here, following prior literature, we taxonomize physics-informed AI for channel modeling as follows: a) augmenting input data to Al model with physics-based features, b) leveraging AI model architectures with \"inductive biases\" suitable for the considered channel modeling problem, and c) embedding a priori known physical laws in the training loss of AI model."}, {"title": "V. INTERPRETABLE AI FOR CHANNEL MODELING", "content": "Even though Al models such as DNNs can learn exceptionally complex functions from data, they, unfortunately, provide limited insight into the actual reasoning behind the model predictions. This lack of interpretability becomes a severe drawback in scenarios where understanding the physical layer characteristics of wireless channels is crucial. Because of this, a network operator might prefer relying on more straightforward, interpretable, and battle-tested models to black-box Al-based solutions. To solve this fundamental issue, eXplainable AI (XAI) methodologies are proposed to enhance the transparency and trustworthiness of black-box Al models [13]. XAI methods allow for deconstructing and analyzing complex Al models, making their internal mechanics and decision-making processes understandable. Though there are many different angles for XAI, we here focus on what we believe is one of the most promising methodologies for interpretable channel modeling, that is, high-performance symbolic regression.\nSymbolic regression is fundamentally a supervised learning task. The goal of symbolic regression is to learn compact analytical expressions from a dataset of input-output exemplars. Mathematical expressions can be fit either to raw measurements data, or to predictions from a black-box ML model. In the former case, our objective is to discover via symbolic expressions the physical laws hidden in the data. In the latter case, known in the literature as symbolic distillation, our objective is to approximate the function learned by an ML model with a simple formula. A state-of-the-art implementation of modern symbolic regression is PySR [14]. In PySR, symbolic expressions are constructed as combinations of a) atomic operators applied to the input features, such as summations, multiplications, exponentiations, differential/integral operations, etc., and b) arbitrarily valued real constants. Fig. 5 illustrates a simple expression tree fit to the Friis' formula, comprising unary and binary operators. This illustrative expression tree presents a clearly spurious term in the form of a cosine applied to the signal frequency. Symbolic regression makes it easier to detect implausible input-output relations, as opposed to conventional black-box Machine Learning models such as DNNs. Nevertheless, it is immediately apparent that, even for a few candidate inputs and operators, the combinatorial explosion of the search space makes brute-force search unfeasible. To make the problem computationally tractable, PySR implements massively parallelized evolutionary algorithms that display excellent scalability with respect to the amount of available computing. Moreover, since simpler analytics expressions are generally preferable, the exploration process can be \"guided\" by constraining the complexity of the generated expressions, for instance, by forbidding nesting of sines and cosines or by limiting the number of symbols that can appear as an argument to an operator, or by excluding functional forms deemed to be implausible (e.g., based on prior knowledge of the considered physical domain). Such constraints are purely knowledge-driven and translate to injecting useful inductive biases in the learning process of the model, in a similar fashion to Physics-Informed AI. However, symbolic regression differs from Physics-Informed Al since its primary goal is not to improve a ML model's performance in a task leveraging domain knowledge of the physical domain, but to provide a set of interpretable mathematical formulas to the user. In the end, the algorithm will return a Pareto front of candidate symbolic expressions, each achieving a different trade-off regarding the loss function and complexity (by default defined as the total number of variables, operators, and constants)."}, {"title": "VI. CONCLUSION", "content": "This paper presents a vision of AI-based channel modeling, which will be a new paradigm for future channel modeling and prediction. The deep integration of AI and radio propagation theories empowers a high-precise and generalized channel modeling framework. Based on the proposed framework, we further explore and highlight several specific technical topics: how to characterize and optimize the uncertainty of model outputs, how to strengthen the impacts of physical propagation characteristics, and how to enhance the interpretability of models. We validate the potential of AI-based channel modeling through a series of illustrative numerical results."}]}