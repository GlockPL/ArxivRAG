{"title": "AI2T: Building Trustable AI Tutors by Interactively Teaching a Self-Aware Learning Agent", "authors": ["Daniel Weitekamp", "Erik Harpstead", "Kenneth Koedinger"], "abstract": "AI2T is an interactively teachable AI for authoring intelligent tutoring systems (ITSs). Authors tutor AI2T by providing a few step-by-step solutions and then grading AI2T's own problem-solving attempts. From just 20-30 minutes of interactive training, AI2T can induce robust rules for step-by-step solution tracking (i.e., model-tracing). As AI2T learns it can accurately estimate its certainty of performing correctly on unseen problem steps using STAND: a self-aware precondition learning algorithm that outperforms state-of-the-art methods like XGBoost. Our user study shows that authors can use STAND's certainty heuristic to estimate when AI2T has been trained on enough diverse problems to induce correct and complete model-tracing programs. AI2T-induced programs are more reliable than hallucination-prone LLMs and prior authoring-by-tutoring approaches. With its self-aware induction of hierarchical rules, AI2T offers a path toward trustable data-efficient authoring-by-tutoring for complex ITSs that normally require as many as 200-300 hours of programming per hour of instruction.", "sections": [{"title": "1 Introduction", "content": "A dominant theme of the last decade of AI research has been to use big-data machine learning to replicate patterns of behavior distributed across large datasets or explore uses for pretrained models that have been produced in a data-driven manner. By contrast, AI2T (pronounced A.I. tutee) is an Al agent that can be Taught interactively, in a process that induces Trustable well-defined educational programs. These are the two Ts of AI2T. A central issue with trusting many Al capabilities trained with machine learning is that their learned behaviors are rarely errorless or internally inspectable. Popular methods like deep-learning [31] fit high-dimensional neural networks with inscrutable 'blackbox' weights that can produce very flexible, but often inconsistent behaviors. AI2T avoids these particular issues of trust by inducing well-defined programs expressed as hierarchical task networks (HTNs) [22]. AI2T induces executable symbolic generalizations that are consistent with the author's training.\nOne way to trust machine-synthesized programs is to inspect the induced programs directly. However, successful code checking requires some programming proficiency and a familiarity with the representation language targeted by the method of program synthesis. AI2T attempts to guide users toward building trustable programs in a different manner. It employs a machine learning method called STAND that can learn efficiently from very little data, yet still accurately estimate its prediction certainty on unseen examples [57]. When STAND's certainty scores tend to increase its true holdout set performance tends to increase. This allows AI2T to be self-aware of its learning, and users can use STAND's certainty scores as an indicator of when AI2T's induced program is complete and trustable. We show in simulation that changes in STAND's certainty estimates more accurately reflect actual changes in holdout set performance than competing predictions from more conventional (and relatively data-efficient) ensemble methods like random forests and XGBoost, which happen to only be as good as chance in this regard. Additionally, we show in a user study that users can successfully use STAND's certainty estimates, as a heuristic for deciding when AI2T has been trained on sufficient practice problems. STAND enables AI2T to be essentially self-aware of its learning progress. This helps users estimate when they have provided AI2T with enough training examples to induce programs with 100% correct behavior.\nThe core features of AI2T span several machine learning paradigms including machine teaching [60], interactive machine learning, [15], and interactive task learning (ITL) [28]. At its core AI2T builds upon the programming-by-demonstration (PBD) paradigm, where non-programmers demonstrate program behavior instead of writing code in a programming language [13]. Many demonstrations of PBD have shown robust performance in automating simple single action or sequential behaviors [18, 29, 34] that require minimal generalizations from users' demonstrations. However, the challenges of PBD multiply when applied to building larger multi-faceted applications [40, 43]. AI2T can very robustly induce the core behaviors of complex applications known as Intelligent Tutoring Systems (ITS)-educational technologies known for their comprehensive adaptive student support features. Authors train AI2T with a set of interactions that go beyond PBD. These interactions are better described as authoring-by-tutoring [39]-authoring with AI2T involves both demonstrating solutions and interactively checking AI2T's behavior as it attempts to solve problems on its own. In this relationship, the author is the tutor, and AI2T is the tutee. Therefore AI2T is best described by Laird et. al.'s vision of interactive task learning (ITL) [28], the idea of Al systems that can be taught complex and robust new capabilities using a variety of natural interactions that are intuitive to non-programmers."}, {"title": "1.1 Intelligent Tutoring Systems: The Original Al Tutors", "content": "Long before recent hype about tutoring with generative AI, hand-programmed expert-system-like AI were used to build Intelligent Tutoring Systems (ITS). Decades of learning science research has honed a set of best practices for designing these conventional ITSs [17, 53]. ITSs have been shown to be more effective than traditional classroom instruction alone [53], and in some cases more effective than traditional human-to-human tutoring [27]. The key to historical ITS successes has been instruction designed around learning-by-doing exercises where the ITS provides step-by-step cognitive assistance that adaptively supports students' directed practice [11, 26].\nFor instance, model-tracing tutors track students' step-by-step solutions to determine in what ways their current knowledge aligns with or diverges from a model of expert knowledge [24, 44]. Model-tracing enables ITSs to directly track and adapt instruction to student's misconceptions and unmastered knowledge as it tracks their progress through active step-by-step practice. When AI2T learns ITS behavior it induces rule-based knowledge structures sufficient for executing this historically difficult-to-build class of ITS behaviors. Model-tracing ITSs have been estimated to require as many as 200-300 developer hours per hour of instruction [1]. In the two domains we use to evaluate this work, AI2T cuts the most difficult programming elements of authoring down to about 20-30 minutes of effort. Authoring with AI2T is similar to tutoring a human, and involves mostly just solving problems and grading AI2T as it solves problems.\nAI2T can induce correct and complete model-tracing behavior in the sense that it induces rules that permit only the correct next actions in step-by-step problem solving, and no incorrect next actions. This induced behavior also permits the generation of \"bottom-out\" hints: correct next actions for problem steps that are requested by students as a last resort when they are stuck [19]. Typically other features of ITSs (which we do not focus on in this work) like requestable conceptual hints, automatic feedback messages, and knowledge-tracing (i.e. tracking students' mastery of particular knowledge) [12] are built on top of the production rules of a model-tracer.\nReaders may fairly wonder why we have not taken an LLM-based approach. Large Language Models (LLMs) have many exciting applications in education but have yet to demonstrate behaviors similar to model-tracing tutors. Insofar as out-of-the-box LLM chatbots 'tutor', they typically default to providing full step-by-step explanations similar to textbook worked examples [45]-an impressive feature no doubt, but one that is prone to abuse, and inconsistent with historically successful ITS designs that focus on learning-by-doing exercises. Even if an LLM is prompted or fine-tuned to evaluate intermediate steps of a student solution in-progress (i.e., perform model-tracing), there is no guarantee that it will provide consistently accurate evaluations and, indeed, its underlying statistical inference approach makes 100% accuracy highly unlikely. Moreover, LLMs often produce \"hallucinations\": responses that often sound plausible but provide information that is misleading, logically inconsistent, or entirely fabricated. In an educational setting, even a small rate of hallucinated incorrect instruction may do more harm than good-plausible but incorrect responses are a likely recipe for producing student misconceptions. It is hard to beat the precision of a robust well-defined program. AI2T innovates toward authoring these trustable tutoring programs without writing code."}, {"title": "1.2 Traditional ITS Authoring", "content": "Several tools like CTAT example-tracing, OATutor [47], and others [3, 21, 46] offer approaches that are faster than programming-based authoring and accessible to non-programmers. Yet these methods place considerable limits on ITS control structures. OATutor supports strictly sequential \"tutoring pathways\" [47], and CTAT example-tracing supports graphs of states and actions that can diverge, re-converge, and manifest unordered groups-essentially limiting them to a slightly larger class of finite state machines-like control structures [1]. Both CTAT example-tracing and OATutor enable means of mass-producing problems within these fixed control structures via a template-filling approach, where special variable strings are replaced by problem-specific content detailed in spreadsheets. In practice, this method of mass-producing problems still requires some programming effort, for instance, by writing programs to fill in the content"}, {"title": "1.3 Issues with prior Authoring-by-Tutoring Approaches", "content": "Prior authoring-by-tutoring approaches like those prototyped with SimStudent [39] and the Apprentice Learner (AL) [37, 54], have demonstrated efficiency benefits over conventional authoring tools. However, in studies of these prior approaches, untrained participants [54], and in some cases also the creators of those approaches [37, 39, 55], failed to produce ITS behavior that was 100% model-tracing complete. Model-tracing completeness is the proportion of reachable problem states across a large holdout set of problems where an agent or ITS permits every correct next action (defined by a ground-truth ITS) and no incorrect actions. Weitekamp et. al reported that their authoring-by-tutoring approach with AL fell short of 100% model-tracing completeness both because of limitations in its interaction design and the learning mechanisms of their agent [54]. For instance, they report interaction design issues related to participants locating and fixing mistakes, navigating and providing feedback over diverging solution paths, and estimating when training is complete. AI2T builds on the interaction designs and machine-learning approaches of prior work to resolve many of these issues."}, {"title": "2 Two Evaluated Domains: And Beyond", "content": "In this work, we evaluate AI2T in simulation experiments and in two user studies. For both of these evaluation methods, we restrict ourselves to two domains: multicolumn addition and fraction arithmetic. Both domains require some contextual decision making and permit some solution flexibility (in terms of step order). Expressed as heirarchical procedures both domains involve deciding between alternative subprocedures based on the context of the problem. Multicolumn addition in particular is a good example of a domain where an author may resort to programming a model-tracing ITS instead of using conventional graphical authoring tools because the individual steps required to solve different problem instances vary considerably.\nIn multicolumn addition, students practice the algorithm for summing large numbers together by computing partial sums and carrying their tens digit (if necessary). The ground-truth model-tracing behavior permits add and carry actions to be applied in either order. The main difficulty of this domain in terms of inducing the correct behavior is that a contextual decision must be made about when to carry a 1 or not, and for always adding three numbers instead of two if a 1 was carried from the previous column. To replicate prior work [54] we limit this domain to problem instances that have pairs of 3-digit numbers.\nIn fraction arithmetic, students must correctly select and apply one of three arithmetic procedures (add, multiply, or convert-then-add). In this domain, fractions are converted by simply multiplying their denominators, and then multi-plying crosswise to find the converted numerators. This tutoring system partially scaffolds the process of determining when fractions need to be converted. If conversion is necessary students check a box labeled: \"I need to convert these fractions before solving\". The ground-truth model-tracing behavior for this domain permits applying the four steps for converting the two numerators and two denominators in any order. The final two steps for computing the combined"}, {"title": "3 Al2T's Interaction Design", "content": "Beyond recalling how to solve problems in each domain, AI2T does not require authors to have a particularly specialized skill set. The core interactions for training AI2T are typical tutoring interactions: demonstrating problem solutions, and giving feedback to AI2T on its problem attempts. Beyond this, AI2T's interaction design imposes just a few responsibilities on the author:\n(1) The author needs to provide an interface for their tutoring system.\n(2) The author needs to double-check that AI2T has correctly interpreted their demonstrated actions."}, {"title": "3.1 Preparing a Tutor Interface", "content": "Authoring-by tutoring begins from blank HTML interfaces that authors have prepared for their tutoring system. Among existing ITS authoring tools, there are several good options for purely graphical drag-and-drop-based interface builders. The CTAT HTML editor is one example [1], and in our user studies (section 6) we provided authors with interfaces prebuilt with this tool. Recent approaches also enable the auto-generation of interfaces from natural language descriptions [7]. AI2T can work with arbitrary HTML interfaces, so it is not particularly sensitive to the authors' interface authoring method, although in this work we limit the interfaces to only use buttons and text boxes."}, {"title": "3.2 Visualizing and Assisting Demonstration Explanations", "content": "After an interface is loaded into AI2T, authors begin building a tutor by filling in a start state for a single initial problem. Next, the author demonstrates a solution to this initial problem. AI2T induces primitive skills that can reproduce each of the author's demonstrated actions, and are later used by AI2T to solve new problems. To initially learn new skills AI2T self-explains each demonstrated action by searching for compositions of primitive functions (from a library of primitives) that can reproduce each demonstration. In this work, we limit this library to just a handful of arithmetic primitives that suffice for authoring the two domains in our user studies.\nWhen self-explaining an author's action, AI2T may come up with just a few explanations or sometimes thousands. In either case, it is time-consuming to check and select among candidate explanations, so we enable the user to directly clarify the arguments and operations of the intended formula by two additional methods. The user can clarify the"}, {"title": "3.3 Supporting Completene Correctness Feedback for Each Problem State", "content": "After AI2T has induced skills from the author's demonstrations, it will try to apply those skills in new problem instances and propose actions that it believes are correct. While an author may train AI2T on 10-20 problems in a typical authoring session, they most likely will have only needed to solve two or three of those problems completely by hand. An author may spend about 5 minutes demonstrating solutions, and the remaining 15-25 minutes simply giving AI2T correctness feedback that helps it refine its skills so they are applied correctly in unseen problems.\nPrior authoring-by-tutoring work [54] has reported usage patterns where authors validate just the first correct action suggested by the agent, but neglect to give feedback to other proposed actions in the same problem state. For getting an agent to solve problems with high accuracy (i.e. always produce one correct solution path) this is not a bad strategy. However, for authoring purposes we want the agent to be able to track all possible correct ways of solving problems. In this case, we aim to achieve 100% model-tracing completeness which means the agent should suggest all correct next actions and no incorrect actions for every reachable problem state. When users do not give feedback for all proposed actions, or neglect to demonstrate alternative correct next actions, the agent is deprived of important feedback toward achieving model-tracing completeness.\nAI2T supports authors in recognizing when multiple actions are proposed-something that we struggled to design toward effectively in early versions of AI2T. The skill application window (Fig. 5) is the most important interface feature in this regard because it provides a visualization that lets authors sequentially flip between each of AI2T's proposed actions. Authors can flip through each action in the skill application window by selecting or hovering over each item. Clicking the X or \u2713 icons on the toggler (Fig. 5) in the skill application window assigns negative or positive feedback to the action."}, {"title": "3.4 Supporting Solution Path Navigation with Behavior Graph Generation", "content": "AI2T automatically generates behavior graph-like visualizations that help authors see the solution paths that they have trained AI2T on for each problem and navigate between different problem states. Since an AI2T agent learns hierarchical rule-like knowledge structures (not graphs), each generated behavior graph is simply a visualization of the agent's induced program applied to a particular problem-not a direct visualization of its internal knowledge structure."}, {"title": "3.5 Visualizing Action Certainty", "content": "Finally, within our revised skill application window, and on each edge of the behavior graph visualization, we added a continuous certainty score ranging between -100% and 100%. These scores indicate how sure the agent is that each proposed skill application is correct or incorrect. Negative values indicate that the agent is mostly certain that an action is incorrect and positive values indicate varying degrees of certainty that the proposed action is correct. As we describe in section 4.2, these values come from STAND's instance certainty measure which we will show is a fairly reliable indicator of prediction certainty and a good indicator of AI2T's actual learning progress-something we show is not true of many alternative methods of estimating prediction probability. Roughly speaking, if the agent proposes only actions with 100% certainty scores for a particular problem state, then this is a fairly strong indication to the author that the agent will exhibit 100% model-tracing complete behavior in similar situations. Mixtures of lower certainty scores are a fairly strong indication that the user should continue to train the agent on more problems."}, {"title": "4 AI2T: Mechanisms for Self-Aware, Data-Efficient, and Robust Induction", "content": "Prior authoring-by-tutoring approaches have used simulated learners that simulate human-like induction [59] from demonstrations and supervised correctness feedback. These simulated learners largely share a similar breakdown of 3 core learning mechanisms that enable data-efficient induction that can be taught interactively. These mechanisms collectively induce several production-rule-like skills, that execute step-by-step solution strategies and flexibly track students' solutions in an ITS. Unlike hand-programmed production rules, skills are refined over the course of interactive training to reflect the author's instructed behaviors.\nEach of the typical 3 core mechanisms in simulated learners used for authoring-by-tutoring induces different kinds of generalizations within each skill: 1) compositions of primitive functions that express how skills produce actions from other information in an interface, 2) patterns or concepts that capture where each skill might locate candidate inputs and outputs, and 3) preconditions that express when as in what contexts a potential candidate application of a skill is a correct application of the skill. The mechanisms that learn these different types of generalizations are typically referred to as how-, where-, and when-learning mechanisms respectively [39, 54].\nAI2T's learning-mechanism implementations are similar to prior implementations of AL [54] with the exception of two important innovations. AI2T uses an algorithm called STAND for when-learning (i.e., precondition induction), and introduces a fourth learning mechanism which we call process-learning that organizes induced skills into hierarchical task networks (HTNs). Unlike methods that have users describe HTN structures directly in a top-down manner [23, 30, 34] AI2T learns HTNs directly from authors' demonstrated action sequences (i.e. via bottom-up induction)."}, {"title": "4.1 Process-Learning: Hierarchical Task Network Induction from Action Sequences", "content": "AI2T's induced HTNs recursively break tasks into subtasks that terminate in primitive action-producing skills. Methods in the HTN are higher-order skills that carry out tasks as ordered or unordered sequences of sub-tasks and primitive skills. Figure 10 shows an example of an induced HTN for an ITS (like Figure 10) that supports students in practicing and deciding between different fraction arithmetic procedures like adding, multiplying, and conversion. For instance, adding fractions with unlike denominators first requires converting them to have the same denominator (method 3), but multiplying fractions (method 2) or adding fractions (method 4) with equal denominators does not require conversion. In the HTN the choice between these three options is represented by a disjunction (an OR) where three methods share the same parent task \"Combine Fraction Expression\". Each method's induced preconditions (from when-learning) gate their consideration as acceptable solution strategies. In this example, the correct preconditions would make these methods mutually exclusive. However, in problems with multiple valid approaches to achieving the same subtask, multiple methods may be applicable simultaneously. For instance, Figure 10 captures just one method (#5) for the \"Convert Fractions\" subtask, but an author could certainly add another to the HTN by demonstrating it at the appropriate problem step."}, {"title": "4.2 STAND: Self-Aware Precondition Induction", "content": "In prior work, when-learning has been identified as a major limiting factor for efficient authoring. Typically how- and where-learning converge to their final generalizations from just one or two examples. When-learning requires several additional correct and incorrect examples to induce correct generalizations. This is true even with the inclusion of process-learning, although process-learning provides structure that can considerably simplify the preconditions that skills need to induce to operate properly.\nSTAND provides more data-efficient precondition induction than prior when-learning approaches [57]. Prior ap-proaches include fitting decision trees [37, 54] or applying inductive logic programming methods [39] to learn each skill's preconditions. Instead of learning a single generalization to predict if a candidate application of a skill is correct STAND learns a space of classifiers consistent with the authors' positive and negative training examples. STAND accounts for a complete set of good candidate generalizations instead of selecting a single generalization by breaking ties randomly. In this way, STAND explicitly models the inherent ambiguity of trying to learn generalizations that perform well on unseen examples-something that is especially challenging when there is limited training data.\nSTAND induces spaces of generalizations that are structurally similar to version spaces. However, STAND suffers from none of the drawbacks of the typical candidate elimination approaches for version-space learning [42]. STAND"}, {"title": "5 Simulation Experiments", "content": "In addition to testing AI2T with users, we wanted to ensure that STAND and process-learning produce improvements in learning efficiency over prior approaches. In these experiments, we first evaluate STAND using it for when-learning in a typical 3-mechanism simulated learner configuration (with how-, where-, and when-learning, but not process-learning). We compare STAND to various alternative when-learning approaches using an automated training system that mimics the demonstrations and feedback that an ideal user would provide while authoring. We apply this special authoring training approach in the two domains that we had participants author in our user study (section 5): multicolumn addition and fraction arithmetic.\nIn this setup, each agent receives ideal on-demand demonstrations and correctness feedback. At each state, all proposed actions are given correctness feedback. If an action is missing then it is demonstrated to the agent with annotations that make the underlying reason for the action unambiguous. Each demo is annotated with the formula for producing the action's value, and the arguments used. This replicates the behavior of an ideal user who always selects the correct formula to explain each demo (among the several suggested possibilities). These annotations enable how- and where-learning to produce error-less generalizations almost immediately, meaning almost all errors can be attributed to when-learning. No annotations are provided to assist when-learning besides the correctness labels of each action. Just like an ideal author, the training system trains the agent on all alternative solution paths for each problem. We compare several classifiers with STAND:\n(1) Decision Tree: A decision tree using gini impurity [6] as the impurity criterion. We use STAND's implementa-tion, expanding just one random split at each decision point."}, {"title": "5.1 Productive Monotonicity: Certainty Score Change vs Holdout Set Performance Change", "content": "Productive monotonicity is defined as the proportion of changes in certainty estimates for actions in a holdout set that move toward 100% when the action is correct and -100% when the action is incorrect. High productive monotonicity reflects the degree to which changes in certainty estimates mirror actual learning gains (increases in holdout set performance)."}, {"title": "5.2 Precision at High Certainties", "content": "If a when-learning classifier predicts that an action is correct with a high certainty of 90%-100% then there should be a very low probability that the action is actually incorrect."}, {"title": "5.3 Per-Problem Completeness", "content": "Finally, we verify that STAND and process-learning produce more data-efficient learning and higher rates of 100% model-tracing completeness on holdout data. We report each model's model-tracing completeness on a holdout set of 100 problems, evaluated at the end of each training problem.\nIn both domains, STAND's average completeness is higher than the competing models throughout the training sequence. This implies that STAND has better data efficiency and asymptotic performance since it can achieve greater levels of completeness with fewer training problems. In 19 of 40 MC addition repetitions STAND achieved 100% completeness after training on a sequence of 100 problems compared to 10 of 40 repetitions for decision trees. In fractions, 38 of 40 repetitions achieved 100% completeness with STAND and decision trees. The relative performance of the decision tree, random forest, and XG Boost varies between domains. Notably the random forest was the worst in multicolumn addition, likely because its bagging approach of sampling subsets of the data had the effect of dropping important edge cases, which are particularly important in this domain."}, {"title": "6 User Studies", "content": "We evaluated AI2T in two studies each with 10 users in which participants authored tutoring systems for multicolumn addition and fraction arithmetic. In each domain participants tutored an AI2T agent on several problems until they were convinced that the agent could produce correct and complete behavior for any new problem instance. When participants self-reported that they believed the agent had achieved a state of absolute completeness, we scored their agents' model-tracing performance on a large holdout set of 100 problems. After being scored, participants moved on to the next domain.\nThe central aim of these studies was to evaluate what configurations of the agent and interface design best support authors in teaching AI2T to induce correct and complete programs. Beyond qualitative observations of usability, a core"}, {"title": "6.1 Methods", "content": "6.1.1 Participants. All users participated in these studies remotely via Zoom, and screen shared as they worked in AI2T's web interface. Participants filled out online forms indicating their consent to be recorded. For their participation in these IRB-approved studies, users were compensated with a $30 Amazon gift card. We limited all sessions to a maximum of 90 minutes. Participants for piloting prior to study 1 included labmates and colleagues who had volunteered their time. The 10 paid participants for study 1 were all graduate students recruited from Carnegie Mellon University (CMU) and 8 of these 10 participants were part of graduate programs that specialized in educational technology. 4 more CMU graduate students were recruited and compensated as part of piloting prior to study 2. The participants for study 2 included 5 graduate students from CMU, 3 of which specialized in educational technology, 2 human-computer interaction graduate students, 4 biology graduate students from Arizona State University (ASU), and 1 professional specializing in the authoring of instructional technology for a major ITS project unaffiliated with CMU or ASU. Participants' self-reported genders were roughly equally male and female in both studies.\nThe typical end-users for an authoring tool like AI2T include instructional designers, learning engineers, teachers, and researchers. Our participant population of mostly graduate students is fairly well aligned with the educational backgrounds of these populations which typically have some graduate education. Many of our participants explicitly study the design of educational technology (although not necessarily the programming elements of it). All participants have bachelor's degrees, and 6 of the 10 participants in study 2 were non-programmers. Several of the study 1 participants indicated that they were non-programmers, but we did not collect this data systematically in study 1.\nFor study 2 we asked participants to score their programming experience on a Likert scale from 1 to 5. We asked: \"Would you describe yourself as a proficient programmer (i.e. you have the ability to write scripts/software)\" where 1 is labeled as \"No. I have little or no programming experience.\", and 5 is labeled as \u201cI have extensive programming experience. I believe I could program professionally.\" For the purposes of our analyses, we consider a score of 1 or 2 to be a non-programmer.\n6.1.2 Instruction. In both studies, participants authored multicolumn addition before fraction arithmetic. None of the participants had used AI2T before, so in both studies, we can think of this first domain as a warm-up attempt to practice using the tool. We first gave participants a short tutorial on how to use the tool by showing them how to demonstrate each step of the problem 777+777, and showed them how to give feedback to the agent on the subsequent problem 222+222. Prior to having participants begin authoring each domain, we described the behavior that we expected the final tutoring system to have, and we asked that participants engage in a think-aloud: \"Say whatever you are thinking"}, {"title": "6.2 Study 1: 3-Mechanism Agent", "content": "Study 1 was conducted to evaluate the efficacy of an in-development version of AI2T's prior to the implementation of process-learning. Study 1 was not particularly successful, but we share it here because the contrast between studies 1 and 2 highlights the importance of certain features that help support intuitive and effective authoring-by-tutoring. Three things are different in the study 1 version of AI2T 1) the agent has no process-learning mechanism, 2) the behavior graph does not display unordered groups so the graphs branch combinatorially, and 3) there is no skill application window so authors must use the edges of the generated behavior graphs or the indicators in the tutor"}, {"title": "6.2.1 Quantitative Results", "content": "The quantitative results for study 1 are outlined in Table 3. For the zero-carry version of multicolumn addition, 3 of 10 participants taught agents that achieved a 100% model-tracing completeness score on the holdout set of 100 random problems. Two of our participants took more than half of the allotted 90 minutes for the first domain, and we did not have them complete the second. In fraction arithmetic just 2 of the 8 participants achieved 100%. In both domains, the total authoring time-the time between beginning authoring and self-reporting that they believed the agent had achieved correct and complete behavior-was about 30 minutes."}, {"title": "6.2.2 Qualitative Results", "content": "Automatic behavior graph generation is one major improvement in AI2T over prior authoring-by-tutoring interaction designs [54]. Users generally had little trouble panning and selecting states and actions in the behavior graph. However, some users had difficulty connecting patterns in the behavior graph with our instructions that certain subsets of actions should be permitted in any order. Without unordered group induction, alternative action orders are displayed as diverging paths. A key element of users' difficulty was that actions essentially needed to be demonstrated or given feedback multiple times since they could appear as distinct edges along different paths.\nFor the fraction arithmetic domain, some users found it tedious to give feedback to the agent in 24 unique problem states generated from each permutation of the 4 steps associated with converting two fractions. In reality, users may have needed to only give feedback on a small subset of these states per problem to achieve 100% completeness. However, since the behavior graph made it very easy for users to see what states they had and had not given feedback on, and"}, {"title": "6.3 Study 2: AI2T with Process-Learning", "content": "The configurations of both the backend agent and frontend interface differ between study 1 and study 2. Taken together they form a loose pseudo-experiment, in which study 1 establishes a baseline with several issues and study 2 implements several fixes to remedy those issues. The version of AI2T deployed in study 2 is as we have described earlier in section"}, {"title": "6.3.1 Quantitative Results", "content": "Table 4 outlines the results for study 2. 6 of our 10 participants reported their programming experience as a 2 out of 5. These 6 non-programmer participants included our 4 biology graduate students, and 2 graduate students specializing in design.\n8 of 10 participants succeeded at training agents that achieved 100% holdout completeness for multicolumn addition (the normal non-zero-carry version). Prior work in this domain had reported lower median model-tracing completeness rates of 92%, with no instances of 100% [54]. Our study 2 results also showed users completing training in about half the time compared to prior work: a median of 22 minutes instead of 41 minutes. For multicolumn addition, all users first solved the same 7 problems and selected their own problems thereafter. In most cases, two or three additional problems after the initial 7 were sufficient to achieve 100%. The two participants who did not reach 100% made mistakes during training that they did not succeed in tracking down and fixing."}, {"title": "6.4 Discussion", "content": "Overall our study 2 results show that our redesign produced a considerable improvement over study 1. Half of the study 2 participants succeeded at training agents with 100% complete tutoring system behavior on both domains, usually in under half an hour. Our interviews with users also confirmed that displaying STAND's instance certainty measure was useful for assessing the AI2T agent's learning progress toward 100% completeness. Several participants in study 2 indicated that this indicator influenced their decision of when to stop training the agent on new problems. This is a strong preliminary indication that the certainty score indicators had the intended effect. A future randomized experiment would be able to lend stronger statistical evidence for the connection between the availability of this indicator and high authoring completeness. However, the productive monotonicity measure we report in our simulation experiments already establishes that this measure accurately reflects agent learning, so it is reasonable to conclude that if users were explicitly trained to interpret it, they could use it successfully as a heuristic for estimating holdout completeness.\nIn study 2, when users did not achieve 100% model-tracing completeness they either made clear mistakes during authoring (e.g. users 5 and 8) or trained AI2T on too few problems. Thus, improving AI2T's robustness may largely come down to better support for training users and helping them catch mistakes. Participants 3, 4, and 6 likely fell"}, {"title": "6.5 Who can use AI2T?", "content": "The major aim of this work was to prototype a method whereby the authoring of complex ITSs is made simple, fast, and accessible to non-programmers. Instructional designers, learning engineers, teachers, and researchers are all professionals who may or may not have programming expertise, but all certainly benefit from being able to author complex ITSs quickly. Many of our"}]}