{"title": "NSSR-DIL: Null-Shot Image Super-Resolution Using Deep Identity Learning", "authors": ["Sree Rama Vamsidhar S", "Rama Krishna Gorthi"], "abstract": "The present State-of-the-Art (SotA) Image Super-Resolution (ISR) methods employ Deep Learning (DL) techniques using a large amount of image data. The primary limitation to extending the existing SotA ISR works for real-world instances is their computational and time complexities. In this paper, contrary to the existing methods, we present a novel and computationally efficient ISR algorithm that is independent of the image dataset to learn the ISR task. The proposed algorithm reformulates the ISR task from generating the Super-Resolved (SR) images to computing the inverse of the kernels that span the degradation space. We introduce \u201cDeep Identity Learning\u201d, exploiting the identity relation between the degradation and inverse degradation models. The proposed approach neither relies on the ISR dataset nor on a single input low-resolution (LR) image (like the self-supervised method i.e. ZSSR) to model the ISR task. Hence we term our model as \"Null-Shot Super-Resolution Using Deep Identity Learning (NSSR-DIL)\". The proposed NSSR-DIL model requires fewer computational resources, at least by an order of 10, and demonstrates a competitive performance on benchmark ISR datasets. Another salient aspect of our proposition is that the NSSR-DIL framework detours retraining the model and remains the same for varying scale factors like \u00d72, \u00d73, \u00d74. This makes our highly efficient ISR model more suitable for real-world applications.", "sections": [{"title": "1 Introduction", "content": "Super Resolution is a well-established low-level vision task whose objective is to generate a High-Resolution (HR) image from the given corresponding LR observation(s). Real-world applications in prominent domains like medical imaging, satellite imaging, and surveillance demand the HR version of the scene of interest for its analysis and understanding.\nIn 2014, the first DL-based ISR work i.e., SRCNN [10] had demonstrated remarkable improvement over the existing dominant example-based ISR methods [13, 15, 16]. Further, various deep learning techniques [7, 23, 24, 27, 29, 34, 38, 45] were proposed to generate the super-resolved images with finer details and of better quality. These works consider the unknown degradation process as a learnable entity in either supervised or unsupervised approach from a large synthetic HR-LR image pair or LR image datasets respectively. The"}, {"title": "2 Related work", "content": "In this section, the relevant DL-based zero-shot ISR methods were discussed in brief.\nA stream of works explores the internal statistics based on the recurrence property of a natural image to model the degradation from a given single test input, the LR image itself. The recurrence property of a natural image states that patches of a single image tend to recur within and across different scales of this image. Glasner et al. [15] proposed to capitalize the internal statistics within an image to tackle the Single ISR problem. Non-parametric blind"}, {"title": "3 Proposed method", "content": "In this section, we elaborate on the proposed NSSR-DIL model in greater detail.\nProblem introduction: The end-to-end ISR framework can be broadly observed as the degradation model followed by the inverse degradation model. At first, the degradation model"}, {"title": "3.1 Random Kernel Gallery (RKG) Dataset", "content": "To realize the identity learning task, a set of degradation maps sampled from the degradation kernel space is generated. In ISR literature, the degradation modeling is mainly carried out conventionally by using Gaussian prior [11, 28] and, in recent works, using complex deep models like KMSR [46], KernelGAN [2] with their own underlying assumptions in"}, {"title": "3.2 Linear Convolutional Neural Network (L-CNN)", "content": "ISR is an ill-posed inverse problem for which a unique inverse will not exist. Computing the direct (or pseudo) inverse of the provided input degradation kernel K or a single-layer network to learn the inverse of the degradation kernel cannot serve the ISR task's objective. This is because a matrix/single layer accepts only one set of parameters/global minima with convex loss [2]. Also, the K can usually be a low-rank matrix. Further, it was empirically found that single-layer architecture does not converge to the correct solution [6]. Whereas the multi-layered linear networks have many good and equally valued local minima. This allows many valid optimal solutions to the optimization objective in the form of different factorizations of the same matrix [19], [31], [1]. Following these research results, we propose a multi-layer Linear CNN (L-CNN) with no activations to learn the inverse degradation kernel, with the degradation kernels (K) from the RKG-dataset as its input. The proposed L-CNN is a computationally efficient architecture having a depth of five layers and a width of 32 with 3 \u00d7 3 filters across the depth. Here the L-CNN is chosen to be a pre-upsample network [10], which maintains the same output dimension at every layer. Therefore, at the inference stage, L-CNN operates on traditional upsampled LR images of any desired scale factor to generate SR images with fine details. This implies that the inverse degradation kernel K-\u00b9 remains the same for varying scale factors like x2, x3, x4.\nThe general limitations of the pre-upsample networks like complexity, computational time, and memory, because of operations in high dimensional space, are not valid in this work as the input to the CNN is kernel K, a matrix of very small dimension (i.e., 21 \u00d7 21), compared to very high dimensional or 3-D tensor input images, in practice. The learning and inference methodology of the NSSR-DIL model is depicted in Fig. 1."}, {"title": "3.3 Deep Identity Learning (DIL):", "content": "The proposed DIL objective is to train the L-CNN on the RKG dataset as given in Eq. (4).\nLoss(L) = ||K * K-1 \u2013 8||3+R"}, {"title": "4 Experiments", "content": "In this section, the implementation details, ISR comparison results, and the effect of the regularization term of the proposed NSSR-DIL method were discussed."}, {"title": "4.1 Training setup", "content": "We trained the proposed L-CNN (refer Sec.3.2 for architecture details of L-CNN) on the RKG dataset (refer Sec. 3.1) with the learning objective given in Eq. (4). The number of epochs was 50 and the learning rate was 0.1 with a step scheduler. The Adam [21] optimization was used, with \u03b2 = 0.9. The values of hyper-parameters used in the learning objective i.e., Eq. (5), set empirically, are as follows, \u03bb\u2081 = 0.8, \u03bb2 = 0.2. We have used a computer with an NVIDIA-GTX 2080 Ti 11GB GPU in all our experiments."}, {"title": "4.2 Results", "content": "Super-Resolution. The ISR ability of our approach was evaluated on the benchmark datasets RealSR [3] for sf 2, sf 3, sf 4 and DIV2KRK [2] for sf 2, sf 4. The results are outlined in Table 1. For a fair comparison, we considered works like KernelGAN [2], ZSSR [32], DBPI [20], and DualSR [12] which consider single input LR image only for modeling the ISR task as in our experiments. Besides, we included the recent SotA supervised ISR methods Dual Aggregation Transformer (DAT) [5], and MIRNetV2 [41], in our comparison experiments for adequate validation. We note that the proposed NSSR-DIL is only the DL approach in the literature that learns the inverse degradation kernel from the degradation kernel itself, without the need for LR image input. While, the compared SotA methods need supervised learning from images for K estimation and/or ISR model learning.\nComputational complexity. The proposed L-CNN is an efficient, lightweight ISR model. The comparison of computational complexity in terms of parameters and super-resolution time (inference time) in minutes with standard self-supervised and zero-shot methods is given in Table 1. The proposed NSSR-DIL requires 15 times fewer memory resources even when compared with the least among the SotA methods i.e. ZSSR. Besides, the inference time required for the NSSR-DIL is reduced to less than a minute and less by an order of 100s than compeer works. Here, the recent SotA methods are excluded from the complexity comparison experiments that employ sophisticated deep models trained on large ISR datasets.\nIn practice, for real test instances, the reference image is not available and the primary interest is to generate the HR version of the given LR image close to the natural image statistics. Hence, we considered Neural Image Assessment (NIMA) [33], a no-reference image quality assessment metric with a high correlation to human perception, to demonstrate the performance of our proposed method. Besides, to assess the ability of the proposed NSSR-DIL to restore the finer details during SR processes, we employ Structural Similarity Index Measure (SSIM), and for qualitative and quantitative similarity with the HR image we provide the visual results and Peak Signal to Noise Ratio (PSNR) values. Despite being very lightweight the proposed NSSR-DIL demonstrated its effectiveness significantly in two out of three standard metrics on real and synthetic ISR datasets. Since the proposed model did not train on either LR or LR-HR image pair data, a relative decline in reference-based metric at pixel level i.e., PSNR was observed as expected. The important note is that the proposed model did not produce artifacts in the generated super-resolved output images, unlike the compeer, SotA works like [2], [20], [41]. The sample visual results were provided in Fig. 3. We would like to emphasize that the RealSR dataset contains real LR images with unknown noise levels and degradation kernel information [17]. Furthermore, the DIV2KRK dataset includes synthetically generated LR images degraded by the Gaussian kernels perturbed by uniform multiplicative noise [2]. Even though we didn't consider the additive noise explicitly in our degradation model represented by Eq. 1, the proposed model showcased its ability"}, {"title": "4.3 Ablation study", "content": "In this section, the significance of the proposed regularization term (R) (given in Eq. 5), the performance of the NSSR-DIL method for various sizes of the RKG dataset, and the performance of the NSSR-DIL model on unseen synthetic test dataset were discussed."}, {"title": "4.3.1 Regularization term (R)", "content": "In the proposed learning objective (refer Eq. 4), we introduced two constraints through the regularization term (R) (refer Eq. 5) to obtain the inverse degradation model and with the reliable ISR performance. The influence of each entity in the proposed R is quantified and presented in Table 2. It was observed that the presence of LconvArea in R has shown a greater impact on the performance of the proposed method relative to the Lcenter. The term Lcenter influenced the perceptual quality of the images. The term LConvArea together with the Lcenter assisted the NSSR-DIL model to attain a reliable performance.\nNote: The ISR performance results of the NSSR-DIL method for various sizes of the RKG dataset, and also on unseen synthetic test dataset are provided in the supplementary material."}, {"title": "5 Conclusion", "content": "We have established a new problem formulation in terms of DIL for the ISR task. The proposed computationally efficient NSSR-DIL is the first image data-independent DL-based ISR model, for any scale factor. The proposed method's performance is quite comparable to the SotA works, despite being independent of image data in the ISR model design. Thus, this work demonstrates tremendous hope for improving the ISR capability without the need for image datasets (i.e., both supervised and unsupervised ISR datasets). Our NSSR-DIL method paves the path to have a deeper look into the learning and understanding of the inverse degradation model from a linear systems perspective. The experimental results and computational performance comparisons with the SotA indicate that the proposed NSSR-DIL are remarkably suitable for real-time ISR tasks and embedded ISR applications."}]}