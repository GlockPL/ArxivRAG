{"title": "Prompting ChatGPT for Chinese Learning as L2:\nA CEFR and EBCL Level Study", "authors": ["Miao Lin-Zucker", "Jo\u00ebl Bellassen", "Jean-Daniel Zucker"], "abstract": "The use of chatbots in language learning has evolved significantly since the 1960s, becoming\nmore sophisticated platforms as generative Al emerged. These tools now simulate natural\nconversations, adapting to individual learners' needs, including those studying Chinese. Our\nstudy explores how learners can use specific prompts to engage Large Language Models\n(LLM) as personalized chatbots, aiming to target their language level based on the Common\nEuropean Framework of Reference for Languages (CEFR) and the European Benchmarking\nChinese Language (EBCL) project. Focusing on A1, A1+ and A2 levels, we examine the\nteaching of Chinese, which presents unique challenges due to its logographic writing system.\nOur goal is to develop prompts that integrate oral and written skills, using high-frequency\ncharacter lists and controlling oral lexical productions. These tools, powered by generative AI,\naim to enhance language practice by crossing lexical and sinographic recurrence. While\ngenerative AI shows potential as a personalized tutor, further evaluation is needed to assess\nits effectiveness. We conducted a systematic series of experiments using ChatGPT models to\nevaluate their adherence to constraints specified in the prompts. The results indicate that\nincorporating level A1 and A1+ characters, along with the associated reference list,\nsignificantly enhances compliance with the EBCL character set. Properly prompted, LLMs\ncan increase exposure to the target language and offer interactive exchanges to develop\nlanguage skills.", "sections": [{"title": "1. Introduction", "content": "ChatGPT is arguably the most advanced chatbot today in terms of natural language\nunderstanding and generation, offering versatile assistance for various communication and\nlearning tasks (Li et al., 2024). It is used daily by millions of people worldwide, and the\nquestion of chatbots' relevance for language teaching in general, and Chinese in particular, is\ncentral to the debate on the integration of artificial intelligence technologies in education.\nThese tools, thanks to their adaptability, could transform the way languages are taught and\nlearned, notably by facilitating personalized learning paths and offering immersive and\ninteractive practice (Imran, 2023; Glazer, 2023; Huang, 2022).\n\nLiterally, a chatbot is \"a computer program designed to simulate conversations with human\nusers, especially on the Internet\". Among the seminal works, even before the internet, was\nELIZA, developed by Joseph Weizenbaum in 1966 (Weizenbaum, 1966). Although initially\ndesigned to simulate basic human conversation, this program revealed the immense potential\nof human-machine interactions for language practice and laid the groundwork for a new\npedagogical approach. ELIZA did not truly understand conversations but identified words or\nphrases in the input text and responded using predefined rules that transformed or\nreformulated statements. Early chatbots for language learning truly emerged in the 1990s.\nALICE (Artificial Linguistic Internet Computer Entity), launched in 1995 by Richard Wallace,\nwas one of the most influential chatbots, as it introduced significant advances in\nconversational agent technology (Wallace, 2009). ALICE used a rule-based model (in AIML\nlanguage), allowing more natural interaction with users compared to earlier models like\nELIZA. ALICE also stood out for its ability to handle a vast knowledge base and produce\nmore varied and complex responses, marking a key milestone in the development of modern\nchatbots. In the 2000s, early chatbots appeared on platforms like Duolingo, offering\ninteractive language practice through scripts and decision trees, though still with limited\ninteractions.\n\nThe real leap forward in chatbot evolution occurred between 2010 and 2020, thanks to AI.\nNew generations of chatbots, now capable of generating more natural and adaptive responses,\nhave transformed the user experience. Advanced algorithms enabled better context\nunderstanding and provided smoother interactions. Wang (2024) conducted a meta-analysis\nof 70 effect sizes from 28 studies, showing that using chatbots produced an overall positive\neffect on language learning performance compared to non-chatbot conditions. However, the\nadvent of generative AI from 2020 onwards has radically changed the potential of chatbots in\nlanguage learning. Even a recent comprehensive history of chatbots from 2020 (Adamopoulou,\n2020) does not mention the paradigm shift brought by LLMs such as ChatGPT, which\nemerged after its publication.\n\nAdvanced models like GPT-3 and its successors, GPT-4, have enabled more sophisticated and\npersonalized interactions (Kalyan, 2024). They adjust language level, communication style,\nand topics according to each learner's needs. These Als simulate realistic conversations,\noffering language practice close to real-world situations, whether daily or professional. While"}, {"title": "2. Generative AI for Chinese as a foreign language learning within the\nCEFR framework defined by the EBCL Project", "content": "2.1 Related work\n\nMuch like tandem learning, which promotes peer interaction as developed by Hilton (2019),\nemphasizing real linguistic exchanges to foster mutual learning and language skill acquisition,\nchatbots can also facilitate interactive exchanges with immediate feedback, thereby creating\na personalized tandem environment. Although using chatbots as an educational tool for\nlanguage learning is not new (Eleni, 2020), the use of those based on large language models\n(LLMs) is relatively recent (Li et al., 2024). There is thus a blooming field of research on the\nuse of LLMs for education (Cong, 2024; Xu, 2024), the specific use of ChatGPT (Zhao et al.\n2024), and prompt engineering (Liu et al., 2023).\n\nMany literature reviews, such as Huang (2020), are highly relevant but are from a pre-\nChatGPT and pre-LLM era (for example, the term \u201cLLM\u201d itself is absent in that review). This\nliterature review explores the use of chatbots in language learning, going beyond earlier\nstudies that focused on specific aspects. The study analyzes their utility in first, second, and\nforeign language learning. By examining 25 empirical studies, three technological affordances\n(speed, ease of use, personalization) and five pedagogical uses (interlocutors, simulations,\ntransmission, assistance, recommendations) were identified. Their conclusions show that\nchatbots foster social presence through affective and coherent communication. However, the\nauthors note that challenges include technological limitations, novelty effects, and cognitive\nload. As mentioned above, since 2022, the landscape has changed, and we have excluded from\nour bibliography any related works that do not mention LLMs or predate these developments,\nexcept for those specifically related to Chinese (see Appendix 7). In this regard, in 2023,\nMahlow (2023) concludes that \"the integration of large language models and artificial\nintelligence in language learning and teaching in general\u2014and in learning how to write in\nparticular-has the potential to enhance the learning experience by providing new and\ninnovative ways of learning\" and that the technology now offers almost limitless possibilities,\nputting pedagogy and language teaching under pressure to adapt and leverage these new tools.\n\nIn terms of chatbots, ChatGPT (developed by OpenAI) is not the only one. Examples of other\nLLM-based chatbots include Claude (developed by Anthropic), Copilot (integrated into\nMicrosoft's AI), HuggingChat (based on the Hugging Face platform), Gemini (formerly Bard,\ndeveloped by Google), and Perplexity (developed by Perplexity AI). Other notable models\ninclude LLaMA (Meta), Ernie Bot (Baidu), or Mistral (Mistral) which enrich the LLM\nlandscape with various applications, notably in the open-source and specialized domains.\nNevertheless, ChatGPT has received the most publications, and its use for language learning\nhas been systematically analyzed during its first year of existence, from November 2022 to\nNovember 2023 (Li et al., 2024). This analysis on ChatGPT and language education reveals\na strong interdisciplinarity spanning computer science, psychology, and education. Most of\nthe studies are empirical, focusing on higher education and ethical issues. This study shows"}, {"title": "2.2 Specific challenges in teaching Chinese", "content": "Teaching Chinese presents unique challenges compared to alphabetic languages due to the\nlogographic nature of its writing system\u2014that is, teaching a second language with a non-\nphonographic writing system. The \"character threshold\" approach can enable a gradual and\nconstructive program for learning Chinese writing.\n\n2.2.1 An academic schism at the heart of Chinese Language Teaching\n\nDualistic pedagogical approach to Chinese\n\nUnlike the teaching of other languages, where methods more or less share the same\nperspective on the language they aim to convey, Chinese didactics is fundamentally divided\nbetween two approaches. One treats Chinese as if it were, ultimately, a language like any other,\nviewing its non-alphabetic writing system as a matter of form rather than substance. The other\nimmediately posits that teaching Chinese completely reshuffles the deck in terms of language\ndidactics!\n\nThe first option, adopted by contemporary China in its methods for teaching Chinese as a\nforeign language since the 1950s, reflects a purely instrumental conception of Chinese writing.\nIt treats the writing system as merely a different graphic system whose sole function is to\nrecord the language in writing, having no proper didactic impact. The most manifest\nconsequence is the failure to provide the meanings of the characters composing a disyllabic\nword, thus denying the logographic nature of Chinese writing! For example, the word\n\"Zhongguo\" would be presented as an indivisible block meaning \u201cChina\u201d, without indicating\nthat the two distinct characters composing it mean \u201cmiddle\" and \"country\", respectively, to\ndenote the \u201cMiddle Kingdom\u201d. Within this option, characters are treated as a set of strokes or\nsometimes components, without considering their meanings or providing any memorization\naids."}, {"title": "2.2.2 Chinese facing the challenge of its \u201ceurocompatibility\u201d within the CEFR: the case\nof France", "content": "In the early 2000s, when foreign language curricula in French primary and secondary\neducation underwent extensive renovation\u2014including Chinese for the first time at the request\nof the Ministry of National Education\u2014the CEFR had just been officially published in 2001.\nIt was set to become the reference framework for 57 European countries, members of the\nCouncil of Europe (2001), encompassing some 800 million inhabitants. Chinese had to\nconfront the CEFR's new approach to language teaching (Bellassen & Zhang, 2008; Bellassen,\n2012; Zhang-Colin & Gianninoto, 2022; Lin-Zucker, 2024), particularly the redefinition of\nlanguage activities meant to structure this teaching according to the proficiency levels (A1,\nA2, B1, B2, C1, C2). Since China did not wish to design the competency framework for\nChinese under the guidance of the relevant European bodies, two unprecedented initiatives\nwere taken in Europe: the first being the complete Chinese curricula published by the French\nMinistry of National Education in the early 2000s, and the second being the European\nBenchmarking Chinese Language (EBCL) project, undertaken between 2011 and 2013,\nexplicitly dedicated to drafting a competency framework for Chinese aligned with the CEFR.\n\nThe officially published Chinese school curricula starting from 2002 inherited a decisive\nadvancement with the conception and publication in 1985 of the SMIC (French acronym of\n\u201cSeuil Minimum Indispensable de Caract\u00e8res\u201d), the first threshold aimed at programming 400\nhigh-frequency characters. Indeed, this first sinographic threshold, based on criteria of\nfrequency and combinatorial capacity of characters, not only recognizes the character as a\nfull-fledged didactic unit but also provides an effective solution to the non-alphabetic nature\nof a language included in the French baccalaureate exams. Since the written exam subjects"}, {"title": "2.3 AI facing the challenge of a split Chinese language", "content": "The potentials of artificial intelligence and certain of its avatars, including conversational\nrobots or chatbots, have generated a leap forward in managing the split unique to Chinese\nbetween two minimal pedagogical units\u2014the word and the character\u2014and two strata of\nChinese as a language of learning: linguistic and graphic, both intrinsically related and\ndissociated. We posit that an effective solution can be provided to this didactic conflict\nspecific to Chinese, not only in terms of teaching and textbook design but now directly\ndedicated to learning itself. We know that one of the key words for effective learning is lexical"}, {"title": "3. To each student their own chatbot", "content": "The fact that a student can provide a different system prompt based on their level allows the\nlearner to request that the exchanges use only the Chinese characters that fall within the\ncharacter threshold they are aiming to acquire at their current stage of learning. It can also\ngenerate feedback corresponding to the learner's proficiency level and specific learning\nobjectives. For example, preparation for an exam, improvement in conversational fluency,"}, {"title": "3.1 Feedback on prompt usage by \u201cna\u00efve\u201d students", "content": "In a limited empirical study, we sought to understand how learners, without prior training in\nthe use of precise prompts, interact spontaneously with ChatGPT in the context of their\nChinese learning. These \u201cna\u00efve\u201d users are in the exploratory phase of the tool and have not\nyet acquired the necessary skills to formulate optimized requests. This observation phase\nallows us to identify recurring patterns in prompt usage and better guide future users toward\na more strategic approach.\n\nThe participants in this study are first-year university students with an Al level in Chinese,\naccording to the CEFR. Their goal is to reach A2 level by the end of the academic year. The\ngroup is mainly composed of 18- to 19-year-old students, all motivated by the desire to acquire\nfunctional proficiency in Chinese through written comprehension and expression exercises\nand the use of digital tools such as chatbots. Below, we present some questions that these\n\u201cna\u00efve\" students of prompting technique posed to their chatbot following their Chinese\nteacher's instruction to study Chinese with ChatGPT. The teacher's instruction was as follows:\n\u201cYou must work on general reading comprehension in Chinese (read and understand various\ntexts as a whole, such as articles or short stories) using ChatGPT for this purpose. Send your\nteacher a copy of the questions you asked ChatGPT.\u201d\n\nHere are the answers (i.e. user prompt) to this instruction that were sent by six of our\nstudents:"}, {"title": "3.2 Language competencies in Chinese from the EBCL project", "content": "We observed that learners often ask simple and direct questions in their prompts, without\nparticular optimization for obtaining better answers. These queries, which can be described as\n\"na\u00efve\", are the most common. Students immediately ask for detailed grammatical\nexplanations of their lesson to be learned. They also spontaneously ask questions about\nunknown vocabulary. As several studies on the use of ChatGPT in Chinese language\nclassrooms have shown, there is value in providing teacher-prepared prompts (Jiang et al.,\n2024).\n\nTo test the different prompts within this study based on the EBCL project, we selected\nactivities listed in Table 2, as they are related to written skills, whether for reading\ncomprehension or written expression. Language learning activities primarily concern online\nwritten interaction skills, so we need to choose the activities defined by the EBCL project that\nspecify language acts related to written production and reception: reading and writing. Below\nare the items from the EBCL project related to CEFR levels. They correspond to specific\ncompetencies in reading and written production."}, {"title": "3.3 Using system prompts as guidelines to align LLM responses with pedagogical\nobjectives", "content": "The system prompts we propose to use (Tables 3 and 4) are not simple user prompts that ask\na question. These are system prompts meaning prompts that condition the role played by the\nchatbot, in this case, ChatGPT, and impact all subsequent interactions (cf. Glossary Table 1).\nConstructing these system prompts requires what is known as prompt engineering (PengFei\net al., 2023). There is an entire typology of prompts (cf. Appendix 1). We tried Few-Shot\nPrompts, One-Shot Prompts and Zero-Shot Prompt but ended up using a (cf. Appendix 1)\nChain-of-Thought Prompt (CoT) which is represented by the four last line of the prompt of\nTable 3. below. This system prompt is the result of numerous tests, considering that the\nchallenge of didactic prompt engineering lies in the fact that LLM (in this case, ChatGPT) do\nnot strictly follow the given constraints (Zhang et al., 2024). One can experience this firsthand\nwhen asking ChatGPT to \u201cprovide a 100-word summary\" of a text-it is unlikely that it will\nprecisely adhere to this limit. This occurs because the LLM is instruction-tuned for tasks but\nremains an autoregressive language model (PengFei et al., 2023).\""}, {"title": "4. Comparative analysis of responses generated by ChatGPT", "content": "Any study on the use of ChatGPT in Chinese language classes yields results that, as noted by\nLi et al. (2024), are highly dependent on the prompts and provide different outcomes. They\nemphasize that as an Al model, ChatGPT is particularly responsive to instructions, and\nvariations in these instructions can lead to vastly different responses. Therefore, a thorough\nunderstanding of the effectiveness of using ChatGPT for pedagogical purposes requires\nexamining the impact of different prompts (Zhao, 2024).\n\n4.1 Method\n\nTo evaluate the performance of two language models, \u201cGPT-4o-mini\u201d and \u201cGPT-4o\u201d, we\nconducted a series of experiments using python programs accessing the ChatGPT Application\nProgram Interface (API) (Ekin, 2023). These two models are optimized versions of the GPT-\n4 model, with \"GPT-40-mini\" being a lighter and faster variant, while \u201cGPT-40\u201d is designed\nfor more complex tasks with greater processing capacity. In practice, this means that we\ndeveloped a program capable of automatically querying ChatGPT thousands of times,\nsimulating the responses that a student at the A1, A1+ or A2 level would provide to a system\nprompt. This allows us to test the models intensively and measure their performance under\nreal-world usage conditions. The models were tested in conditions simulating those of a\nstudent, with a temperature set to 0.7 (see Appendix1)."}, {"title": "4.2 Discussion of statistical results on the structure of ChatGPT's responses", "content": "Let us first consider the ChatGPT-40 model, which is more advanced than ChatGPT-40-mini.\nThe addition of a character list specific to each level significantly improves performance at\nAl and A1+ levels by reducing error percentages (first two bar charts of Fig. 1a). However,\nat the A2 level, the addition of the list leads to a negligible increase in the error rate, although\nthe overall error percentages remain low in both scenarios. In contrast, with ChatGPT-40-mini,\nthe analysis shows that the addition of a character list does not significantly reduce the\npercentage of generation errors, as the average differences in errors between the two\nconditions are minimal and within the margin of the provided standard deviations. Thus,\nadding a character list does not improve generation performance in terms of error reduction\nwith ChatGPT-40-mini, and it may not be necessary to include it for this purpose. However,\nincorporating a list in tasks for Al and A1+ levels improves accuracy, whereas at the A2 level,\nit does not present significant benefits and may be considered optional."}, {"title": "4.3 Discussion of results from the perspective of prompt content", "content": "Beyond the relevance of whether or not to include the Chinese character threshold in the\nprompt, from a pedagogical perspective, ChatGPT's output on the content provided to the\nlearner demonstrates a certain quality. Below in Table 5, we cite an example of the result from\na prompt with the \"RW2\" item from the EBCL project, which relates to the language act aimed\nat developing the 'Reading Correspondence' competence at the Al level. This is not a caption\nof a real interaction as the result was obtained automatically using the ChatGPT API (cf.\nMethods described in \u00a74.1)."}, {"title": "4.4 Limitations and ethical considerations", "content": "Oral interaction with chatbots is limited by the very nature of the tool, which relies primarily\non a text-based interface. Unlike human interaction or advanced voice recognition systems,\nchatbots based on large language models (LLMs) such as ChatGPT do not allow for true oral\nconversation. This can make the aspect of oral production less intuitive than written\nrecognition or production. A study was conducted to compare the effectiveness of a virtual\nagent and a physical robot named Qilin in helping English-speaking adults learn spoken\nMandarin (Hargis, 2022). Participants interacted with a bilingual chatbot using three modes:"}, {"title": "5. Conclusion", "content": "Chatbots based on LLMs, accessible via the internet or dedicated applications, make language\nlearning more interactive and engaging today. By simulating natural conversations and\ncreating interactive scenarios with instant feedback, they surpass traditional passive learning\nmethods. Our study highlighted how, through well-structured system prompts, learners of\nChinese as a second language can benefit from personalized interactions that adjust to their\nlevel, following the recommendations of the Common European Framework of Reference for\nLanguages (CEFR) and using the character lists defined by the European Benchmarking\nChinese Language (EBCL) project. These prompts allow for controlling and calibrating\nlinguistic productions based on character frequency, promoting progressive and controlled\nexposure to the most essential sinographic characters.\n\nHowever, we have experimentally shown that chatbots like ChatGPT do not systematically\nfollow the instructions provided by prompts, even though more advanced versions like\nChatGPT-40 outperform lighter models like ChatGPT-4o-mini. We showed that adding a\ncharacter list improves accuracy in EBCL activities at the Al and A1+ levels, helping learners\nat those stages. However, for A2-level tasks, the list does not provide significant benefits and\ncan be considered optional, as it does not enhance error reduction or overall instruction\ndeviation when using models like ChatGPT-4o-mini.\n\nThese results underscores the importance for teachers to develop appropriate prompts and\ncontinue improving them to ensure their effectiveness. Future research includes automatically\nimproving prompts (Pryzant et al., 2023) and creating assistants based on these optimized\nprompt to make them widely accessible. Tests could also be conducted to evaluate the\nefficiency of the provided prompts when used with other LLM-based chatbots such as\nLLAMA, Mistral, or Qwen, ensuring broader applicability across various large language\nmodels. The use of generative AI for Chinese language learning also has the advantage of\nbridging the gap between oral and written skills, a crucial challenge in teaching this\nlogographic language. By adjusting prompts, chatbots can provide exercises on character\nrecognition and oral production, particularly via Pinyin, thus creating a synergy between these\ntwo skills."}]}