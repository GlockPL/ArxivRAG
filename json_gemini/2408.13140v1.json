{"title": "Verification of Geometric Robustness of Neural Networks via Piecewise Linear Approximation and Lipschitz Optimisation", "authors": ["Ben Batten", "Yang Zheng", "Alessandro De Palma", "Panagiotis Kouvaros", "Alessio Lomuscio"], "abstract": "We address the problem of verifying neural networks against geometric transformations of the input image, including rotation, scaling, shearing, and translation. The proposed method computes provably sound piecewise linear constraints for the pixel values by using sampling and linear approximations in combination with branch-and-bound Lipschitz optimisation. A feature of the method is that it obtains tighter over-approximations of the perturbation region than the present state-of-the-art. We report results from experiments on a comprehensive set of benchmarks. We show that our proposed implementation resolves more verification cases than present approaches while being more computationally efficient.", "sections": [{"title": "Introduction", "content": "Neural networks as used in mainstream applications - including computer vision are known to be fragile and susceptible to adversarial attacks [19]. The area of formal verification of neural networks is concerned with the development of methods to establish whether a neural network is robust, with respect to its classification output, to variations of the image. A large body of literature has so far focused on norm-bounded input perturbations, aiming to demonstrate that imperceptible adversarial alterations of the pixels cannot alter the classifier's classification (lp robustness). In safety-critical applications such as autonomous driving, however, resistance to norm-bounded perturbations is inadequate to guarantee safe deployment. In fact, image classifiers need to be robust against a number of variations of the image, including contrast, luminosity, hue, and beyond. A particularly important class of specifications concerns robustness to geometric perturbations of the input image [2, 24, 28, 33]. These may include translation, shearing, scaling, and rotation.\nOwing to the highly nonlinear variations of the pixels in geometric transformations, verifying robustness to these perturbations is intrinsically a much harder problem than lp robustness. Previous work over-approximates these variations through hyper-rectangles [33] or pairs of linear bounds over the pixel values [2], hence failing to capture most of the complexity of the perturbation region. Developing more precise methods for verifying geometric robustness remains an open challenge. In this paper we work towards this end. Specifically, we make three contributions:\n1. We present a piecewise linear relaxation method to approximate the set of images generated by geometric transformations, including rotation, translation, scaling, and shearing. This construction can incorporate previous approaches [2, 33] as special cases while supporting additional constraints, allowing significantly tighter over-approximations of the perturbation region.\n2. We show that sound piecewise linear constraints, the building blocks of the proposed relaxation, can be generated via suitable modifications of a previous approach [2] that generates linear constraints using sampling, linear and Lipschitz optimisation. We derive formal results as well as effective heuristics that enable us to improve the efficiency of the linear and Lipschitz optimisations in this context (cf. Propositions 1-3). As we demonstrate, the resulting piecewise constraints can be readily used within existing tight neural network verifiers.\n3. We introduce an efficient implementation for the verification method above and discuss experimental results showing considerable gains in terms of verification accuracy on a comprehensive set of benchmark networks.\nThe rest of this paper is organized as follows: Section 2 discusses related work. In Section 3 we introduce the problem of verifying neural networks against geometric robustness properties. In Section 4 we present our novel piecewise linear approximation strategy via sampling, optimisation and shifting. In Section 5 we discuss the experimental results obtained and contrast the present method against the state-of-the-art on benchmark networks. We conclude in Section 6. Our code is available at [1]."}, {"title": "Related Work", "content": "We here briefly discuss related work from lp-based neural network verification, geometric robustness and formal verification thereof.\nlp robustness verification There is a rich body of work on the verification of neural networks against lp-bounded perturbations: see, e.g., [27] for a survey. Neural network verifiers typically rely"}, {"title": "Geometric robustness verification", "content": "Our main contribution is a new piecewise linear relaxation of geometric transformations to verify robustness of neural networks to geometric perturbations. We here introduce relevant notation in the verification problem and present the geometric attack model.\nNotation Given two vectors $a, b \\in R$, we use $a > b$ and $a < b$ to represent element-wise inequalities. Given a vector $a \\in R^m$ and a matrix $A \\in R^{m \\times n}$, we denote their elements using $a[i]$ and $A[i, j]$, respectively.\nNeural networks for classification We consider a feedforward neural network with L hidden layers $f: R^n \\to R^m$. Let $x_0 \\in R^n$ denote the input and $x_i$ denotes the activation vectors at layer $i$. We use $L_i$ to denote an affine map at layer $i$, e.g., linear, convolutional, and average pooling operations. Let $\\sigma_i$ be an element-wise activation function, such as ReLU, sigmoid or tanh. The activation vectors are related by $x_{i+1} = \\sigma_i(L_i(x_i))$, $i = 0,1,..., L - 1$. We are interested in neural networks for classification: the network output $f(x_0) = L_L(x_L) \\in R^m$ represents the score of each class, and the"}, {"title": "Robustness verification", "content": "Let A be a general attacker that takes a nominal input $x \\in R^n$ and returns a perturbed input $A(x) \\in R^n$. We denote the attack space as $\\Omega_\\epsilon(x) \\subset R^n$, i.e., $A(x) \\in \\Omega_\\epsilon(x)$, where $\\epsilon > 0$ denotes the attack budget. Formally verifying that a classification neural network $f$ is robust with respect to an input $x$ and its attack space $\\Omega_\\epsilon(x)$ implies ensuring that all points in $\\Omega_\\epsilon(x)$ will share the same classification label of $x$. This can be done by solving the following optimisation problem $\\forall i \\neq i^*$: \n$\\gamma := \\min_{x_0,x_1,...x_L,y} y[i^*] - y[i]$\\"}, {"title": "subject to", "content": "$x_0 \\in \\Omega_\\epsilon(x), (1a)$\n$x_{i+1} = \\sigma_i (L_i(x_i)), i \\in [L] (1b)$\n$y = L_L(x_L), (1c)$\nwith (1b) being neural network constraints, (1c) as the neural network output, (1a) denoting the attack model constraint, and $L := {0,1,..., L-1}$. If $\\gamma > 0 \\\\forall i \\in {1,...,m}$, the network is certified to be robust.\nEven when (1) is a convex set, such as in the case of $l_p$ perturbations, for which $\\Omega_\\epsilon(x) = {x \\in R^n \\mid ||x - x||_p < \\epsilon}$, the nonconvex neural network constraints (1b) make the verification problem (1) difficult to solve. However, in this setting, tractable lower bounds $\\gamma^* < \\gamma$ on the solution can be obtained through a variety of techniques, including: linear relaxations [10, 31, 33, 35, 37, 45], semi-definite programming [3, 7, 13, 30] and Lagrangian duality [5, 8, 9, 40, 46]. These techniques lie at the core of the network verifiers described in Section 2. If $\\gamma^* > 0 \\\\forall i \\in {1,..., m}$, the network is robust, but a negative lower bound will leave the property undecided, pointing to the importance of tight lower bounds. When considering geometric transformations, the attack model constraint (1a) is highly nonconvex, making verification even more challenging."}, {"title": "Attack model via geometric transformation", "content": "A geometric transformation of an image is a composite function, consisting of a spatial transformation $T_\\mu$, a bilinear interpolation $I(u, v)$, which handles pixels that are mapped to non-integer coordinates, and changes in brightness and contrast $P_{\\alpha,\\beta}$. The spatial transformation $T_\\mu$ can be a composition of rotation, translation, shearing, and scaling; see e.g., [2] for detailed descriptions. The pixel value $p_{u,v}$ at position $(u, v)$ of the transformed image is obtained as follows: (1) the preimage of $(u, v)$ is calculated under $T_\\mu^{-1}$; (2) the resulting coordinate is interpolated via $I$ to obtain a value $\\xi$; (3) $P_{\\alpha,\\beta}(\\xi) = \\alpha \\xi + \\beta$ is applied to compute the final pixel value $p_{u,v}$. In other words, we have that $p_{u,v} = G_{u,v} (\\alpha, \\beta, \\mu)$, where:\n$G_{u,v}(\\alpha, \\beta, \\mu) := P_{\\alpha,\\beta} \\circ I \\circ T_\\mu^{-1} (u, v). (2)$\nWe consider the following standard bilinear interpolation:\n$I(u, v) = \\sum_{\\delta_i,\\delta_j \\in {0,1}} p_{i+\\delta_i,j+\\delta_j} (1 - |i + \\delta_i - u|)(1 - |j + \\delta_j - v|),$ \nwhere $(i, j)$ denotes the lower-left corner of the interpolation region $[i, i + 1] \\times [j, j + 1]$ that contains pixel $(u, v)$, and the matrix $p$ denotes the pixel values of the original image. Note that the interpolation function $I$ is continuous on $R^2$ but can be nonsmooth on the boundaries of interpolation regions. Thus, $G_{u,v} (\\alpha, \\beta, \\mu)$ is in general nonsmooth with respect to the spatial parameter $\\mu$ (e.g., rotation)."}, {"title": "Problem statement", "content": "in the following we will denote the transformation parameter as $\\kappa = (\\alpha, \\beta, \\mu)$. The geometric attack model assumes interval constraints on $(\\alpha, \\beta, \\mu)$, denoted by $B \\subset R^d$, where $d$ is the dimension of $\\kappa$. The attack space $\\Omega_\\epsilon(x)$ from (1a) is then defined as the set of all images resulting by the application of $G_{u,v} (\\kappa)$ on each pixel $(u,v)$ of $x$, for all $\\kappa \\in B$. More formally, given $im: R^n \\to R^{h \\times w}$, a mapping re-arranging images into their spatial dimensions, $\\Omega_\\epsilon(x) = {x' \\in R^n \\mid im(x')[u, v] \\in \\Omega_\\epsilon(x)[u, v]}$, with $\\Omega_\\epsilon(x)[u, v] = {G_{u,v}(\\kappa) \\mid \\\\forall \\kappa \\in B}$.\nThe geometric attack model (2) defines a highly nonconvex constraint on the admissible image inputs, which is not readily supported by bounding techniques designed for $l_p$ perturbations. As a result, previous work replaces it by over-approximations [2, 33], which allow verification through $l_p$-based neural network verifiers. Nevertheless, as described in Section 2, their over-approximations are imprecise, resulting in loose lower bounds. In this work, we aim to derive a tighter convex relaxation of the geometric attack model (1) based on piecewise linear constraints. By relying on networks verifiers with support for these constraints, we will then show that our approach leads to effective verification bounds for (1)."}, {"title": "Piecewise linear formulation", "content": "As mentioned above, the pixel value function $G_{u,v}(\\kappa)$ at location $(u,v)$ is generally nonlinear and nonsmooth with respect to the transformation parameters $\\kappa$. This is one source of difficulty for solving the verification problem (1). In this section, we introduce a new convex relaxation method to derive tight over-approximations of $G_{u,v} (\\kappa)$."}, {"title": "Piecewise linear bounds", "content": "Deriving an interval bound for each pixel $(u,v)$, i.e., $L_{u,v} \\leq G_{u,v}(\\kappa) \\leq U_{u,v}$, for all $\\kappa \\in B$ and lower and upper bounds $L_{u,v}, U_{u,v} \\in R$, is arguably the simplest way to get a convex relaxation [24, 33]. However, even a small geometric transformation can lead to a large interval bound, making this approach too loose for effective verification.\nThis naive interval bound approach has been extended in [2], where linear lower and upper bounds were used for each pixel value, i.e.,\n$w^\\top \\kappa + b \\leq G_{u,v}(\\kappa) \\leq \\overline{w}^\\top \\kappa + \\overline{b}, \\\\forall \\kappa \\in B. (3)$\nThe linear bounds (3), however, can be still too loose to approximate the nonlinear function $G_{u,v}(\\kappa)$ (see Figure 1 for illustration). Our key idea is to use piecewise linear bounds to approximate the pixel values:\n$\\max_{j=1,...,q}{\\underline{w_j}^\\top \\kappa + \\underline{b_j}} \\leq G_{u,v}(\\kappa) \\leq \\min_{j=1,...,q}{\\overline{w_j}^\\top \\kappa + \\overline{b_j}}, (4)$\n$\\forall \\kappa \\in B$, where $q$ is the number of piecewise segments, $\\underline{w_j} \\in R^d, \\underline{b_j} \\in R, j = 1,..., q$ define the piecewise linear lower bound, and $\\overline{w_j} \\in R^d, \\overline{b_j} \\in R, j = 1, ..., q$ define the piecewise linear upper bound. We remark that the pixel values constrained by (4) form a convex set. Furthermore, our approach can include the strategies in [2, 33] as special cases. Employing the relative constraints among the piecewise segments will result in a tighter set.\nFor each pixel value, we would like to derive optimal and sound piecewise linear bounds by minimizing the approximation error. Specifically, we aim to compute the lower bound via\n$\\min_{\\underline{w_j},\\underline{b_j},j=1,...,q} \\int_B (G_{u,v}(\\kappa) - (\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa + \\underline{b_j}})) d\\kappa$"}, {"title": "s.t.", "content": "$\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa + \\underline{b_j}} \\leq G_{u,v}(\\kappa), \\\\forall \\kappa \\in B. (5)$\nComputing the upper bound for (4) is similar. This optimisation problem (5) is highly nontrivial to solve since the integral cost function is hard to evaluate due to the nonlinearity of $G_{u,v} (\\kappa)$. Motivated by [2], we first sample the transformation parameter $\\kappa_i$ from B to obtain the sampled pixel values $G_{u,v} (\\kappa_i)$, and then solve a sampled version of (5). The resulting piecewise bound is guaranteed to be sound on the sampling points $\\kappa_i \\in B$ but could be unsound on non-sampled points. To derive a final sound piecewise bounds for $G_{u,v}(\\kappa)$, we bound the maximum violation over the entire B using a branch-and-bound Lipschitz optimisation procedure."}, {"title": "Linear optimisation based on sampling points", "content": "Here, we first randomly select N transformation parameters $\\kappa_i \\in B$, $i = 1,..., N$, to obtain a sampled version of (5) as follows\n$\\min_{\\underline{w_j},\\underline{b_j},j=1,...,q} \\frac{1}{N} \\sum_{i=1,...,N} (G_{u,v} (\\kappa_i) - (\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa_i + \\underline{b_j}}))$\nsubject to $\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa_i + \\underline{b_j}} \\leq G_{u,v}(\\kappa_i), i = 1,...,N. (6)$\nWe denote the optimal cost value of (6) as $\\beta^*$. In (6), the number of piecewise linear segments q is fixed a priori. Still, problem (6) is nontrivial to solve jointly for all piecewise segments $\\underline{w_j}, \\underline{b_j}, j = 1, ..., q$ unless $q = 1$ (where (6) is reduced to a single linear program). One difficulty is to determine the effective domain of each piecewise linear segment.\nTo alleviate this, we propose to split the whole domain B into q sub-domains $B_1,..., B_q$, and then optimize each piecewise linear segment over $B_j, j = 1, ..., q$, individually. We then use the following q independent linear programs to approximate the solution to (6):\n$\\underline{\\beta_j} := \\min_{\\underline{w_j},\\underline{b_j}} \\frac{1}{N} \\sum_{i: \\kappa_i \\in B_j} (G_{u,v} (\\kappa_i) - (\\underline{w_j}^\\top \\kappa_i + \\underline{b_j})) (7)$\nsubject to $\\underline{w_j}^\\top \\kappa_i + \\underline{b_j} \\leq G_{u,v}(\\kappa_i), i = 1, ..., N,$"}, {"title": "Proposition 1.", "content": "Given any subdomains $B_j, j = 1,..., q$, the optimal solutions $\\underline{w_j}, \\underline{b_j}, j = 1, . . ., q$, to (7) are suboptimal to (6), i.e., $\\sum_{j=1}^q \\underline{\\beta_j} \\geq \\beta^*$. There exists a set of subdomains $B_j, j = 1, ..., q$, such that the optimal solutions to (6) and (7) are identical, i.e., $\\sum_{j=1}^q \\underline{\\beta_j} = \\beta^*$.\nConsider the piecewise linear function in the objective function (6). Let $B_j, j = 1,..., q$ be the effective piecewise domain of the $j$th segment, i.e.,\n$\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa_i + \\underline{b_j}} = {\\underline{w_1}^\\top \\kappa_i + \\underline{b_1}, if \\kappa_i \\in B_1 : \\underline{w_q}^\\top \\kappa_i + \\underline{b_q}, if \\kappa_i \\in B_q. (8)$\nThen, the objective function (6) can be equivalently written into\n$\\frac{1}{N} \\sum_{i=1,...,N} (G_{u,v} (\\kappa_i) - (\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa_i + \\underline{b_j}})) = - ( \\sum_{j=1}^q \\sum_{\\kappa_i \\in B_j} (G_{u,v} (\\kappa_i) - (\\underline{w_j}^\\top \\kappa_i + \\underline{b_j})))$.\nTherefore, (6) is equivalent to\n$\\min_{\\underline{w_j},\\underline{b_j}, B_j,j=1,...,9} \\sum_{j=1}^q \\sum_{\\kappa_i \\in B_j} (G_{u,v} (\\kappa_i) - (\\underline{w_j}^\\top \\kappa_i + \\underline{b_j}))$"}, {"title": "s.t.", "content": "$\\underline{w_j}^\\top \\kappa_i + \\underline{b_j} \\leq G_{u,v}(\\kappa_i), i = 1,..., N, j = 1, . . . q. (9)$\nNote that the piecewise domains $B_j$ are determined by the linear segments $\\underline{w_j}, \\underline{b_j}, j = 1, ..., q$ implicitly in (8). We need to simultaneously optimize the choices of $B_j$ in (10), making it computationally hard to solve.\nA suboptimal solution for (10) is to a priori fix the effective domain $B_j$ and optimize over $\\underline{w_j}, \\underline{b_j}, j = 1, . . ., q$ only, i.e.,\n$\\underline{\\beta} := \\min_{\\underline{w_j},\\underline{b_j},j=1,...,9} \\sum_{j=1}^q (\\frac{1}{N} \\sum_{\\kappa_i \\in B_j} (G_{u,v} (\\kappa_i) - (\\underline{w_j}^\\top \\kappa_i + \\underline{b_j}))) (10)$\nwhich is decoupled into q individually linear programs, $j = 1, . . ., q$\n$\\underline{\\beta_j} \\stackrel{1}{:=} \\min_{\\underline{w_j},\\underline{b_j}} \\sum_{\\kappa_i \\in B_j} (G_{u,v} (\\kappa_i) - (\\underline{w_j}^\\top \\kappa_i + \\underline{b_j})) (11)$\nsubject to $\\underline{w_j}^\\top \\kappa_i + \\underline{b_j} \\leq G_{u,v}(\\kappa_i), i = 1, ..., N.$\nTherefore, it is clear that $\\underline{\\beta} = \\sum_{j=1}^q \\underline{\\beta_j} > \\beta^*$. On the other hand, suppose the optimal solution to (6) leads to the optimal effective domains $B_j, j = 1,...,q$ in (8). Then, using this set $B_j, j = 1,..., q$, the decoupled linear programs (11) are equivalent to (10) and (6)."}, {"title": "Lipschitz, optimisation for obtaining sound piecewise linear bounds", "content": "The piecewise linear constraints from (7) are valid for the sampling points $\\kappa_i \\in B, i = 1,..., N$. To make the constraints sound over all $\\kappa \\in B$, we must shift them such that all points on the pixel value function, $G_{u,v} (\\kappa)$, satisfy the constraints in (4). For this, we define a new function that tracks the violation of a piecewise bound over the entire domain B:\n$\\xi^* := \\max_{\\kappa \\in B} f_{u,v}(\\kappa), (12)$\nwhere $f(x) = \\max_{j=1,...,q}{\\underline{w_j}^\\top \\kappa + \\underline{b_j}} - G_{u,v}(\\kappa)$. Then, we naturally have a sound piecewise linear lower bound as\n$\\max_{j=1,...,q} {\\underline{w_j}^\\top \\kappa + \\underline{b_j}} - \\xi^* \\leq G_{u,v}(\\kappa), \\\\forall \\kappa \\in B.$\nHowever, computing the exact maximum $\\xi^*$ is computationally hard due to the nonconvexity, nonlinearity and nonsmoothness of $f_{u,v}(\\kappa)$. Instead, given any $\\epsilon > 0$, we can use a branch-and-bound Lipschitz optimisation procedure (see Algorithm 1) to find $\\xi^* \\in R$ satisfying $\\xi^* \\leq \\xi \\leq \\xi^* + \\epsilon$."}, {"title": "Proposition 2.", "content": "The violation function $f_{u,v}(\\kappa) := \\max_{j=1,...,q}{\\underline{w_j}^\\top \\kappa + \\underline{b_j}} - G_{u,v}(\\kappa)$ is nonconvex, nonsmooth, and Lipschitz continuous over $B \\subset R^d$. Furthermore, there exist $L_m > 0, m = 1,..., d$, such that $\\forall \\kappa_1, \\kappa_2 \\in B$\n$|f_{u,v} (\\kappa_1) - f_{u,v} (\\kappa_2)| \\leq \\sum_{m=1}^d L_m |\\kappa_1(m) - \\kappa_2(m)|. (13)$\nThe pixel value function is given by $G_{u,v} (\\kappa) := P_{\\alpha,\\beta} \\circ I \\circ T_\\mu^{-1} (u, v)$. We know that the spatial transformation $T_\\mu(u, v)$ and $P_{\\alpha,\\beta}$ are continuous and differentiable everywhere. The interpolation function $I(u, v)$ is continuous everywhere, but it is only differentiable within each interpolation region and it can be nonsmooth on the boundary. Also, $T_\\mu(u, v)$ and $I(u, v)$ are generally nonconvex.\nIn addition, the piecewise linear function $\\max_{j=1,...,q}{\\underline{w_j}^\\top \\kappa + \\underline{b_j}}$ is continuous but not differentiable everywhere. Therefore, the violation function $f_{u,v}(\\kappa)$ is nonconvex and nonsmooth in"}, {"title": "Proposition 3.", "content": "general. Finally, all the functions $T_\\mu(u,v)$, $P_{\\alpha,\\beta}$, $I(u, v)$ and $\\max_{j=1,...,q}{\\underline{w_j}^\\top \\kappa + \\underline{b_j}}$ are Lipschitz continuous, so is the violation function $f_{u,v}(\\kappa)$. Thus, there exist $L_m > 0, m = 1,...,d$, such that (13) holds.\nThe properties of the violation function $f_{u,v}(\\kappa)$ in Proposition 2 are directly inherited from nonconvexity and nonsmoothness of the interpolation function $I(u, v)$. The Lipschitz continuity is also from the interpolation function and the piecewise linear function.\nWith the information of $L_m$ in (13), we are ready to get a lower and an upper bound for $\\xi^*$ upon evaluating the function at any point $\\kappa_0 \\in B$:\n$f_{u,v} (\\kappa_0) \\leq \\xi^* = \\max_{\\kappa \\in B} f_{u,v}(\\kappa) \\leq \\max_{\\kappa \\in B} f_{u,v}(\\kappa_0) + \\sum_{m=1}^d L_m |\\kappa(m) - \\kappa_0(m)| (14)$\n$< f_{u,v} (\\kappa_0) + \\sum_{m=1}^d L_m h_m,$\nwhere $h_m > 0$ denotes the difference of the lower and upper bound in each box constraint of B. These lower and upper bounds (14) are useful in the branch-and-bound procedure.\nStill, we need estimate the Lipschitz constant $L_m$ in (13). In our work, we show how to estimate the constant $L_m$ based on the gradient of $f_{u,v}(\\kappa)$ whenever it is differentiable (note that $f_{u,v}(\\kappa)$ is not differentiable everywhere)\nLet Diff(B) be the subset of B where $f_{u,v}(\\kappa)$ is differentiable. Then, the Lipschitz constants in (13) can be chosen as $L_m = Sup_{\\kappa \\in Diff(B)} |\\nabla f_{u,v}^\\top e_m|$, where $e_m \\in R^d$ is a basis vector with only the m-th element being one and the rest being zero."}, {"title": "Algorithm 1 Branch-and-bound Lipschitz Optimisation Procedure", "content": "n the branch-and-bound procedure). For bounding the violation of piecewise linear bounds we can consider the piecewise bound itself to be made of q linear sub-regions with each one bounded by the intersection with the neighbouring linear piece - or the lower and up-per bounds on the transformation parameters. We can then bound the Lipschitz constant in the same way as for a single linear bound, instead starting with q sub-domains. Solving the Lipschitz bounding procedure for each linear segment over only its local domain in this way enables us to bound the Lipschitz constant of a piecewise linear bound in the same time as we a linear bound takes."}, {"title": "Experimental Evaluation", "content": "In this section we present three sets of results: (i) a quantitative study directly comparing the model-agnostic bounds produced by our piecewise linear approach against the state-of-the-art linear bounds [2], (ii) an empirical evaluation of verification results obtained using linear and piecewise linear bounds, without input splitting and using the same neural network verifier [4], (iii) a comparison with state-of-the-art results previously reported in the literature [2]."}, {"title": "Experimental setup", "content": "We consider the MNIST image recognition dataset [25]. In line with the previous literature [2], we use two fully-connected ReLU networks, MLP2 and MLP6, and one convolutional ReLU network, CONV, from the first competition for neural network verification (VNN-COMP) [38]. The fully-connected networks comprise 2 and 6 layers respectively. Each layer of each of the networks has 256 ReLU nodes. The convolutional network comprises two layers. The first layer has 32 filters of size 5 \u00d7 5, a padding of 2 and strides of 2. The second layer has 64 filters of size of 4 \u00d7 4, a padding of 2 and strides of 1. Additionally, we employ a larger convolutional ReLU network from relevant previous work [2], composed of three layers: a convolutional layer with 32 filters of size 4 \u00d7 4 and strides of 2, a convolutional layer with 64 filters of size 4 x 4 and strides of 2, and a fully connected layer with 200 nodes. All experiments were carried out on an Intel Core i9-10940X (3.30GHz, 28 cores) equipped with 256GB RAM and running Linux kernel 5.12."}, {"title": "Experimental results", "content": "In the following, we will use \"L\" to denote the linear relaxation from equation (3), and \"PWL\" to denote the piecewise linear relaxation from equation (4).\nPWL vs L: comparing areas Figure 2 is a direct comparison of bound tightness between our piecewise linear bounds and the current state-of-the-art linear bounds [2]. For each image, linear and piecewise linear bounds are generated, each one capturing the reachable pixel values for a given transformation. We always use two piecewise segments (q = 2) and use a Lipschitz error of 0.01 to compute bounds. The area enclosed by each set of bounds is then calculated"}, {"title": "Comparison with literature results", "content": "In Table 2 we provide a comparison of verification results obtained using VENUS with both linear and piecewise linear constraints, with the DeepG [2] results, obtained using linear constraints and the DeepPoly [33] verifier, which relies on a relatively loose LP relaxation of (1). Further, we use a MILP-based verifier which enabled us to add the pixel domain constraints in addition to our transformation-based bounds. This, coupled with the tighter verifier, enables our linear bounds to out-perform those from DeepG. We consider a MNIST benchmark presented in Balunovi\u0107 et al. [2], where a 30 degree rotation transformation is verified by way of 10, 3-degree sub-problems. This is in contrast to Table 1, where each perturbation is represented by a single set of bounds and a single verifier call per image. Table 2 shows that, even under the small-perturbation setting, the use of tighter verification algorithms (L versus DeepG) increases the number of verified properties. Furthermore, we show that the method proposed in this work, PWL, leads to the tightest certification results. Nevertheless, we point out that verifying perturbations through a series of sub-problems is extremely expensive, as it requires repeated calls to both neural network verifiers, and to the constraint-generation procedure (including the branch-and-bound-based Lipschitz optimisation). For this reason, we focus on verification the setting without transformation splitting, and aim to maximize certifications through the use of tight verifiers and over-approximations of the geometric transforms."}, {"title": "Conclusions", "content": "We have introduced a new piecewise linear approximation method for geometric robustness verification. Our approach can generate provably tighter convex relaxations for images obtained by geometric transformations than the state-of-the-art methods [2, 33]. Indeed, we have shown experimentally that the proposed method can provide better verification precision in certifying robustness against geometric transformations than prior work [2], while being more computational efficient.\nDespite the positive results brought by our piecewise linear approximation method, a few other interesting topics are worth further exploration. First, it is challenging to obtain the optimal piecewise linear constraints via (6). To get a good set of piecewise linear constraints, our current method (7) requires to obtain a good heuristic partition of the domain $B_1,..., B_q$. It will be interesting to further investigate and quantify the suboptimality of the solution from (7). Second, the number of piecewise linear segment q is a hyperparameter in our framework. A larger value q leads to a better approximation of the pixel value function in theory; however, this also results in more linear constraints for the verification problem in practice. Future work will investigate how to choose a good value of q based on the curvature of of the pixel value function."}]}