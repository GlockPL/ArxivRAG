{"title": "End-to-end Steering for Autonomous Vehicles via Conditional Imitation Co-learning", "authors": ["Mahmoud M. Kishky", "Hesham M. Eraqi", "Khaled M. F. Elsayed"], "abstract": "Autonomous driving involves complex tasks such as data fusion, object and lane detection, behavior prediction, and path planning. As opposed to the modular approach which dedicates individual subsystems to tackle each of those tasks, the end-to-end approach treats the problem as a single learnable task using deep neural networks, reducing system complexity and minimizing dependency on heuristics. Conditional imitation learning (CIL) trains the end-to-end model to mimic a human expert considering the navigational commands guiding the vehicle to reach its destination, CIL adopts specialist network branches dedicated to learn the driving task for each navigational command. Nevertheless, the CIL model lacked generalization when deployed to unseen environments. This work introduces the conditional imitation co-learning (CIC) approach to address this issue by enabling the model to learn the relationships between CIL specialist branches via a co-learning matrix generated by gated hyperbolic tangent units (GTUs). Additionally, we propose posing the steering regression problem as classification, we use a classification-regression hybrid loss to bridge the gap between regression and classification, we also propose using co-existence probability to consider the spatial tendency between the steering classes. Our model is demonstrated to improve autonomous driving success rate in unseen environment by 62% on average compared to the CIL method.", "sections": [{"title": "1 INTRODUCTION", "content": "An autonomous system is capable of understanding the surrounding environment and operating independently without any human intervention (Bekey, 2005), in the context of autonomous vehicles, the objective is to mimic the behaviour of a human driver. To mimic a human driver's behaviour, the system is expected to take actions similar to those taken by a human driver in the same situation, the driver's action can be defined as a set of vehicle's controls such as steering, throttle, brake and gear.\nAutonomous driving systems can follow either the modular approach, or the end-to-end approach(Yurtsever et al., 2019). In the modular approach, the system's pipeline is split into several components, each component has its own subtask, then the information provided by each component is combined to help the system understand the surrounding environment (Dammen, 2019) so the system can eventually generate different actions. On the other hand, the end-to-end approach replaces the entire task of autonomous driving with a neural network, where the network is fed observations (the inputs from the different sensors) and produces the predicted actions (steering, throttle, brake, gear), the objective is to train the network to learn the mapping between the observations and the actions.\nThe end-to-end approach was first introduced in (Bojarski et al., 2016), a convolutional neural network (CNN) was trained to map the raw pixels from a front-facing camera directly to steering commands. Later, the end-to-end approach was adopted widely in research such as in (Prakash et al., 2021), (Cui et al., 2022), (Codevilla et al., 2018), (Hawke et al., 2019), (Liang et al., 2018) and (Eraqi et al., 2022) due to the simplicity of the process of development and deployment. Also, the model is free learn any implicit sources of information and the researcher is only concerned with developing a network that receives the raw data and delivers the final output (Dammen, 2019), unlike the modular approach, there are no human-defined information bottlenecks (Tampuu et al., 2020).\n(Codevilla et al., 2018) proposed using a branched network architecture as shown in Figure 1, where the network is fed the navigational commands (go left, go right, go straight, follow lane) from a route planner representing the driver's intention, each specialist branch is dedicated to learn the mapping between the observations and the vehicle's actions independently. At test time, the navigational command acts as a switch to select the final action taken by the network. The major issue with the proposed model by (Codevilla et al., 2018) was its lack of generalization and the poor performance when deployed to unseen environment.\nIn this work, we propose two contributions to"}, {"title": "2 RELATED WORK", "content": "improve the CIL end-to-end steering. In the first contribution, we introduce the conditional imitation co-learning (CIC) approach which involves modifying the CIL network architecture in (Codevilla et al., 2018). (Codevilla et al., 2018) assumed total independence between the specialist branches while training, each branch was only trained on a subset of the training scenarios, for instance, the specialist branch dedicated to learn the right turns was only exposed to right turns scenarios during training. If the training data was not big enough to cover all the scenarios for all the branches, it could lead to unbalanced learning, which means that the model may perform properly in right turns and perform poorly in left turns or vice verse (Dammen, 2019). We claim that one branch can make use of the features extracted by another. So, a branch dedicated to learn right turns can learn from observations collected in left turns and vice verse which enhances the model's generalization and increases its robustness in unseen environments.\nThe second contribution is posing regression problem as classification, posing regression problem as deep classification problem was introduced in (Rothe et al., 2015), classification showed improvement in age prediction from a single image compared to regression. In our work, we adopt posing regression problem as classification as introduced in (Rothe et al., 2015), the classes were obtained by steering discretization. However, using this approach assume full independence between the steering classes ignoring their spatial tendency. So, we propose two improvements to the classification approach, the first improvement uses a combination of the categorical cross-entropy and the mean squared error losses to bridge the gap between classification and regression.\nThe second improvement proposes considering the spatial relationship between the steering classes at the output layer using co-existence probability matrix, we claim that considering the spatial relationship between the classes will help to improve the overall performance of the model since the network will tend to predict the spatially close classes together."}, {"title": "2.1 Conditional Imitation Learning", "content": "End-to-end Imitation learning aims to train the model to mimic an expert, the model with parameters w is fed a set of observations and actions (o,a) pairs obtained from the expert. The model is optimized to learn the mapping function between the observations and actions $F(o,w)$. In the context of autonomous driving, the observations are the data collected from different sensors (Cameras, Radars, LiDARs, ..), the actions are the vehicles controls such as steering, throttle and brake. The model is trained to mimic the actions taken by the expert to perform the task of autonomous driving."}, {"title": "2.2 Regression as Classification", "content": "In (Rothe et al., 2015), the regression problem of age prediction from images was posed as classification, the continuous age value was discretized to obtain the classification labels. Considering only the age values from 0 to 100, the network was trained to predict the true age of the human face in the input image. (Eraqi et al., 2017) followed the same approach to solve autonomous vehicle steering problem. Inspired"}, {"title": "3 METHODOLOGY", "content": "eters, then the model is regularized by L2 distance to encourage the parameters to be similar instead of learning from a shared network (hard parameter sharing). Unlike mixture of experts and soft parameter sharing approaches, (Misra et al., 2016) and (Ruder et al., 2019) allow parameter sharing between specialist branches via learnable parameters.\n(Misra et al., 2016) introduced using cross-stitch units to learn the linear combinations of the activations coming from the different tasks at each layer of the network. In contrast, (Ruder et al., 2019) focused on determining which features should be shared between loosely coupled tasks, the hidden layers are split into two orthogonal subspaces, one for shared features and the other for task-specific features, the network learns to dynamically decide which features to be shared via learnable parameters.\nAs opposed to other MTL approaches, our CIC model is output-oriented, we focus on learning the relationships between the outputs. In addition, we study the presence or absence of these relationships using GTUs, rather than trying to learn the relationships between hidden layer parameters. Our approach is motivated by the nature of our driving problem, where the overlapping between the branches' subsets is minimal and occurs only in a few specific driving scenarios, which reduces the network ability to learn the mapping between the parameters in the hidden layers and makes it less effective."}, {"title": "3.3 Classification-Regression Hybrid Loss", "content": "(Kourbane and Genc, 2021) proposed splitting the process of object pose prediction into two stages, coarse and refinement. The coarse stage involves a rough prediction of the pose using classification followed by offset prediction using regression, the network was spilt into two modules after feature extraction, one module for pose classification and the other for offset estimation. Given that the network had two types of outputs (softmax scores and offsets), (Kourbane and Genc, 2021) optimized the network using a combination of cross-entropy loss for classification and Huber loss (Huber, 1992) for regression.\nIn our work, we adopt a similar approach to (Kourbane and Genc, 2021), for fair comparison between classification and regression, we only convert the regression output layer to a softmax layer rather than having two types of outputs in (Kourbane and Genc, 2021). To bridge the gap between classification and regression, we used a combination of categorical cross-entropy (CCE) and mean squared error (MSE) losses for model optimization, the CCE loss imposes high penalty to the model is case of mislabeling allowing the network to produce coarse estimations to the steering, then MSE loss tunes the output activations for more accurate predictions.\nGiven $O \\in R^{Nx1}$ the softmax output scores, y the true continuous steering, $\\hat{y}$ $Nx1$ the one hot representation"}, {"title": "3.4 Co-existence Probability Based Loss", "content": "of the discretized steering, $m \\in R^{Nx1}$ steering midpoints corresponding to each class, N is the number of steering classes and the hyperparameter W.\n$l = -\\sum_{i=1}^{N}y_{i}log(O_{i}) + W(\\hat{y} - y)^{2}$   (3)\nwhere\n$\\hat{y} = E(O) = \\sum_{i=1}^{N}O_{i}m_{i}$\nInspired by (Rothe et al., 2015) and (Eraqi et al., 2017), this work poses vehicle steering regression problem as classification considering the spatial relationship between the steering classes. As illustrated in Sec.I, it's important to insure that the model gives desirable predictions even in the case of mislabeling. Unlike (Eraqi et al., 2017), we used co-existence probability matrix instead of sine wave encoding to represent this relationship, using co-existence probability matrix was introduced in (Bengio et al., 2013) to improve multi-class image categorization, this work used the same concept to force the scores at the output layer to follow a desired distribution which represents the spatial relationship between the discrete steering classes.\nThe co-existence probability matrix was used in (Bengio et al., 2013) to represent the statistical tendency of visual object to co-exist in images. In our steering problem, the objective of forcing the model to learn the output distribution is to make sure that in the case of misprediction, the model is always able to make acceptable predictions allowing the vehicle to recover from disturbances.\nThe co-existence probability matrix $\\mu$ is an N x N matrix, where N is the number of classes, the element $\\mu_{ij}$ represents the co-existence probability between labels i and j, given that the output scores $O \\in R^{N}$ and $\\mu \\in R^{NXN}$, the model shall try to find the output vector O that minimizes the following cost function according to (Bengio et al., 2013):\n$l = -(1-W) \\sum_{i=1}^{N}y_{i} log(O_{i}) - W \\sum_{i=1}^{N} O\\mu O$   (4)\nthe first term is the crossentropy loss, the second term describes how much the output scores vector O follows the desired distribution defined by $\\mu$, and W is a hyperparameter between 0 and 1 describing how much we care about forcing the desired distribution. Thus, the value $O_{j}$ shall be pulled up or pulled down by $O_{i}$ based on how high or low the value $\\mu_{i,j}$ is (Bengio et al., 2013), the advantage of this approach is the flexibility it provides to the researcher to define the distribution most fitted for each class. In this work, we use Gaussian distribution with $\\sigma^{2}$ = 1."}, {"title": "4 TRAINING AND EXPERIMENT", "content": "We split the dataset into training and validation sets, 70% of the dataset for training and the remaining 30% for validation, the models were trained using Adam optimizer (Kingma and Ba, 2014) with $\u00df\u2081 = 0.70$, $\u00df2 = 0.85$ and learning rate of 0.0002, we used mini-batches of 120 samples each, the mini-batches contained equal number of samples corresponding to each navigational command, the models were trained on the dataset collected as illustrated in Sec.III. The steering values coming from the dataset samples ranges between -1 and 1, where -1 means a full turn to left and 1 means a full turn to the right, the actual value of steering depends on the vehicle used (Dosovitskiy et al., 2017). While training, the samples with steering between -0.8 and 0.8 were only considered. For classification models, we discretized the steering to 9 classes with 0.2 discreteization step.\nThe models were tested using CARLA simulator, we adopted a modified CoRL 2017 benchmark (Dosovitskiy et al., 2017) where we considered only single turn task for performance evaluation, the task of the ego-vehicle is to successfully navigate from a start point and reach a destination point given predefined navigational commands forcing the vehicle to perform one single turn on its way. The vehicle was tested in in Town01 (training town) and Town02 (new town), in four different weather conditions, two training conditions (ClearNoon and ClearSunset) and two new conditions (midRainyNoon and wetCloudySunset), the new town and weather conditions are fully unseen to the steering models during training. We defined 38 pairs of start and destination points in Town01 and 40 pairs in Town02 associated with predefined navigational commands to cover all the intersections in both towns, which gives us 312 testing scenarios.On testing, we got the shown results in Tables I, II, III and IV."}, {"title": "5 CONCLUSION", "content": "In this work, we propose two contributions to the end-to-end steering problem tackled by the conditional imitation learning (CIL) model, the CIL model suffered from lack of generalization and poor performance when tested in unseen environment, the first contribution of this work is conditional imitation co-learning (CIC), the introduced approach proposes a modified network architecture that allows the specialist branches in the CIL model to co-learn to overcome the generalization issue and increase the model's robustness in unseen environment, the other contribution is posing the steering regression problem as classification by using a combination of CCE and MSE losses. The CIC model showed a significant improvement to performance in unseen environment by 62% while posing regression as classification showed only improvement by 21%."}]}