{"title": "Unifying Attribution-Based Explanations Using Functional Decomposition", "authors": ["Arne Gevaert", "Yvan Saeys"], "abstract": "The black box problem in machine learning has led to the introduction of an ever-increasing set of explanation methods for complex models. These explanations have different properties, which in turn has led to the problem of method selection: which explanation method is most suitable for a given use case? In this work, we propose a unifying framework of attribution-based explanation methods, which provides a step towards a rigorous study of the similarities and differences of explanations. We first introduce removal-based attribution methods (RBAMs), and show that an extensively broad selection of existing methods can be viewed as such RBAMs. We then introduce the canonical additive decomposition (CAD). This is a general construction for additively decomposing any function based on the central idea of removing (groups of) features. We proceed to show that indeed every valid additive decomposition is an instance of the CAD, and that any removal-based attribution method is associated with a specific CAD. Next, we show that any removal-based attribution method can be completely defined as a game-theoretic value or interaction index for a specific (possibly constant-shifted) cooperative game, which is defined using the corresponding CAD of the method. We then use this intrinsic connection to define formal descriptions of specific behaviours of explanation methods, which we also call functional axioms, and identify sufficient conditions on the corresponding CAD and game-theoretic value or interaction index of an attribution method under which the attribution method is guaranteed to adhere to these functional axioms. Finally, we show how this unifying framework can be used to develop new, efficient approximations for existing explanation methods.", "sections": [{"title": "1. Introduction", "content": "In recent years, a vast number of explanation methods has been proposed in an attempt to tackle the black box problem (Barredo Arrieta et al., 2020; Rudin, 2019; Molnar, 2022), i.e. the problem that many popular machine learning models are far too large and/or complex for humans to interpret. This black box problem leads to issues in trust (Tonekaboni et al., 2019; Holzinger, 2021), debugging (Sculley et al., 2015) and deployment of machine learning models. Many of the proposed explanation methods provide feature attributions, which is an explanation in the form of an attribution or importance score for each feature. This score is supposed to reflect how \u201cimportant\" or \"influential\" each feature is for a given model.\nWith the introduction of such a diverse range of attribution methods, a new problem arises: which one of the many available methods is the most appropriate for a given use case? This question has led researchers to develop a wide range of metrics designed to measure the quality of a given explanation or explanation method (Hedstr\u00f6m et al., 2023; Hedstr\u00f6m et al., 2023; Ancona et al., 2018; Yeh et al., 2019). However, recent work has shown that these quality metrics disagree about which explanation or method is the best one (Tomsett et al., 2020; Gevaert et al., 2024). Another approach that has recently been explored is the so-called axiomatic approach, in which a set of desirable properties or axioms is assumed, and an explanation method is defined such that it satisfies these desirable properties (Lundberg and Lee, 2017). However, research has shown that multiple methods can often satisfy the same set of axioms while still contradicting each other in practice, even if the axioms are supposed to \"uniquely define\" a specific method in theory (Kumar et al., 2020; Sundararajan and Najmi, 2020). In conclusion, objective selection and/or evaluation of feature attribution-based explanation methods remains an open problem. These developments highlight the need for a unifying framework to understand the differences between methods. In this work, we introduce such a framework, based on the core concepts of cooperative game theory and additive functional decomposition.\nFirst, we formally define the scope of our unifying framework in the form of removal-based attribution methods (RBAM). These methods are completely defined by three formal, mathematical choices. The defining choices of a RBAM correspond to 1) the behaviour of the model that is explained, 2) how features are removed from the model, and 3) how the be-haviour of the model after features are removed is summarized into an explanation. We show that a significant number of existing methods are indeed instances of RBAMs, including Shapley value-based methods (Lundberg and Lee, 2017; Lundberg et al., 2019a; Merrick and Taly, 2020; Sundararajan and Najmi, 2020), permutation-based methods (Breiman, 2001; Strobl et al., 2008; Zeiler and Fergus, 2014), higher-order attribution methods (Sundararajan et al., 2020), variance-based explanations (Sobol', 2001; Song et al., 2016) and others (Ribeiro et al., 2016). A non-exhaustive overview of methods that can be viewed as RBAMs is given in Tables 1 and 2.\nNext, we introduce the canonical additive decomposition (CAD). This is a general con-struction for additively decomposing any function based on the central idea of removing groups of features. We proceed to show that indeed every valid additive decomposition method is in fact an instance of the CAD. We then establish a connection between the CAD and cooperative game theory by showing that an additive decomposition can be used"}, {"title": "2. Related Work", "content": "Some attempts have already been made to provide unifying theories of attribution-based explanations and explanations in general. Merrick and Taly (2020) introduce the Formulate, Approximate, Explain framework, which is based on the specification of a reference distribution and the approximation of Shapley values using this distribution to remove features. The authors show that a number of existing explanation techniques can be viewed as specific instances of this framework. However, this framework only covers Shapley value-based explanations, and is unable to capture all existing Shapley value-based techniques, such as conditional Shapley values (Lundberg and Lee, 2017) or causal Shapley values (Heskes et al., 2020).\nA more comprehensive framework is given by the Explaining by Removing (XBR) frame-work (Covert et al., 2021), which covers a wide range of removal-based explanation tech-niques. Indeed, this framework introduces the three choices that our framework is also based on. However, by focusing on attribution-based explanations specifically, we are able to formulate the three choices in a more mathematically rigorous and precise way. This allows us to perform a much more detailed theoretical analysis of the behaviour of expla-nation methods. We do this by formally defining a set of functional axioms, which are mathematically precise and intuitive guarantees of behaviour for removal-based attribution methods. These functional axioms are designed to address known problems with the more commonly used game-theoretic axioms, which have been shown to be unintuitive as de-scriptors of method behaviour in practice (Chen et al., 2020; Kumar et al., 2020). We then derive provably sufficient conditions for explanation methods to adhere to these functional axioms. We also provide a formal link between removal-based explanations and additive functional decomposition, which allows us to describe properties of attribution methods in terms of properties of additive decompositions. This opens the path to further research by linking the existing literature on additive functional decomposition to explainable machine learning, and vice versa. Finally, we also extend the framework to cover higher-order at-tribution methods such as the Shapley-Taylor interaction index (Sundararajan and Najmi, 2020).\nRecent work has also uncovered a number of links between attribution-based explanation methods and additive functional decompositions. Owen (2014) shows a connection between Shapley effects and Sobol' indices (Sobol', 2001) of the functional ANOVA decomposition (Roosen, 1995). We demonstrate that a similar link exists for a more general class of Shapley-based methods. Hiabu et al. (2023) illustrate that SHAP and q-interaction SHAP (Tsai et al., 2023) can be linked in a similar fashion to partial dependence plots. This link can be used to provide richer explanations and to perform model debugging and model editing. Bordt and von Luxburg (2023) introduce a bijective relation between additive functional decompositions and Shapley value-based explanations. They use this relation to show an equivalence between the Shapley-Taylor interaction index, Faith-SHAP (Tsai et al., 2023) and their proposed n-Shapley values. Finally, Herren and Hahn (2022) also demonstrate how the functional ANOVA decomposition can be used to compute SHAP values, and use this link to show how numerical tests for feature interactions can be used to select coalitions in Shapley value sampling.\nAll of these works prove that there is a strong link between Shapley value-based tech-niques and additive functional decomposition. In this work, we extend this link beyond Shapley value-based techniques, and demonstrate that any removal-based univariate or multivariate attribution method can be linked to additive functional decomposition in a similar fashion."}, {"title": "3. Notation", "content": "In this section, we introduce some of the notation we will use in this work. We will denote sets using the uppercase letters $S, T, U, V$, and the complement of a set $S$ as $\\bar{S}$. Random variables will be denoted using the uppercase letters $X, Y, Z$. If a set has only one element $\\{i\\}$, we will declutter notation by denoting it simply as $i$ if it is clear from context that this should be a set. For example: $S \\cup i := S \\cup \\{i\\}$, $S \\backslash i := S \\backslash \\{i\\}$. For a given $d \\in \\mathbb{N}$, we introduce the shorthand notation $[d] := \\{1, ..., d\\}$.\nWe will denote vectors using boldface letters $\\mathbf{x} := (x_1,...,x_d)$. If $S \\subseteq [d]$, we will use the notation $\\mathbf{x}_S$ to signify the vector made by the elements of $\\mathbf{x}$ that correspond to elements in $S$: $\\mathbf{x}_S := (x_i | i \\in S)$. For example, if $\\mathbf{x} = (1, 4, 2, 5, 3)$, then $\\mathbf{x}_{\\{1,3,5\\}} = (1,2,3)$. For two vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^d$ and a subset $S\\subseteq [d]$, we will denote the vector $(\\mathbf{x}_S, \\mathbf{y}_\\bar{S})$ as the vector constructed by combining $\\mathbf{x}_S$ and $\\mathbf{y}_\\bar{S}$:\n$(\\mathbf{x}_S, \\mathbf{y}_\\bar{S})_i := \\begin{cases} x_i & \\text{if } i \\in S \\\\ y_i & \\text{if } i \\notin S \\end{cases}$\nLet $f \\in \\mathcal{F} : \\mathcal{X} \\rightarrow \\mathbb{R}$ be a function, where $\\mathcal{X} \\subseteq \\mathbb{R}^d$. We denote the $i$-th input variable of $f$ as $X_i$. We will say that $X_i$ is an independent variable of $f$ if\n$\\forall \\mathbf{x}, \\mathbf{y} \\in \\mathcal{X} : \\mathbf{x}_{[d]\\backslash\\{i\\}} = \\mathbf{y}_{[d]\\backslash\\{i\\}} \\rightarrow f(\\mathbf{x}) = f(\\mathbf{y})$\nIf the value of an independent variable $X_i$ of $f$ is changed without changing any of the other variables, then this has no influence on the output of $f$. For a set $S\\subseteq [d]$, we will say that $f$ is independent of $X_S$ if for each $i \\in S$, $X_i$ is an independent variable of $f$. $X_i$ is an additive variable of $f$, or $f$ is additive in $X_i$, if there exist functions $g, h \\in \\mathcal{F}$ such that $f = g + h$,"}, {"title": "4. Game theory", "content": "In this section, we introduce some preliminary concepts from cooperative game theory. We define cooperative games, values, and indices. Next, we provide a brief overview of the different axioms related to values and indices. Based on these axioms, we then introduce a basic taxonomy of game-theoretic values and indices.\nGiven a finite set of players $N := \\{1,...,n\\}$, a cooperative game is defined by a real-valued function that assigns a worth to each subset of players: $v : 2^N \\rightarrow \\mathbb{R}$ with the added restriction that $v(\\emptyset) = 0$. The function $v$ is also called the characteristic function of the game, or in other words, the game is represented in its characteristic or coalitional form. In practice, the game is usually identified with the characteristic function $v$, as $v$ is sufficient to describe all of the dynamics of the game.\nA subset of players $S \\subseteq N$ is also called a coalition. A cooperative game is called a game of transferable utility (TU-game) if the worth $v$ can be costlessly transferred between players of $N$, i.e. a given quantity is \"worth\" just as much to one player as it is to any other. TU-games will be the main object of study in the rest of this work. Therefore, in the following descriptions we will also speak simply of games to denote cooperative games of transferable utility.\nA value for the game $v$, also called an imputation (Shapley and Roth, 1988), is a vector $\\phi(v) \\in \\mathbb{R}^n$ where each entry contains the value for a specific player in $N$. As an example, consider the following game $v_{ex}$ with $N = \\{1,2,3\\}$:\n$v_{ex}(\\emptyset) = 0$\n$v_{ex}(\\{1\\}) = 1$\n$v_{ex}(\\{2\\}) = 2$\n$v_{ex}(\\{3\\}) = 4$\n$v_{ex}(N) = 8$\n$v_{ex}(\\{1,2\\}) = 3$\n$v_{ex}(\\{2,3\\}) = 7$\n$v_{ex}(\\{1,3\\}) = 5$\nThe function $v_{ex}$ defines the worth for each coalition $S \\subseteq N$. The problem of assigning a value to each of the players in $N$ can now be expressed as finding a vector $\\phi(v_{ex}) \\in \\mathbb{R}^3$ that somehow quantifies each player's \u201ccontribution\u201d to the outcome. A simple definition for a value might for example be the average worth of each coalition of which a given player is a member:\n$\\phi(v_{ex}) = \\left( \\frac{1+3+5+8}{4}, \\frac{2+3+7+8}{4}, \\frac{4+7+5+8}{4} \\right) = (4.25, 5, 6)$\nAlthough this is a valid definition for a value, we can easily identify some possible issues. First of all, the values for the players do not add up to the worth of the total coalition. This can be a problem in specific contexts: for example, this implies that this value would not be an appropriate choice if the goal is to somehow distribute the total produced worth $v_{ex}(N)$ among the players in $N$. Another possible issue with this value is more subtle. Consider player 1. If we inspect the worths of the coalitions containing player 1 more closely, we can see that adding player 1 to any coalition $S \\subseteq N \\backslash \\{1\\}$ increases the worth of the coalition by exactly 1:\n$v_{ex}(\\{1\\}) - v_{ex}(\\emptyset) = v_{ex}(\\{1,2\\}) - v_{ex}(\\{2\\})$\n$= v_{ex}(\\{1,3\\}) - v_{ex}(\\{3\\})$\n$= v_{ex}(\\{1, 2, 3\\}) - v_{ex}(\\{2,3\\})$\n$= 1$\nThis can be interpreted as the player 1 always \u201ccontributing\" a value of 1, regardless of the other players in the coalition. In other words, player 1 does not really \"cooperate\" with the other players in a meaningful way. Now assume player 2 becomes more productive, increasing the worth of all the coalitions containing player 2 by a value of 3. In this case, player 1 still contributes the exact same value of 1 to each coalition. However, its value according to $\\phi(v_{ex})$ would have increased significantly. If the goal of the value is to fairly distribute the worth produced by the total coalition among the players according to their contributions, then we could expect some protest from player 2 if this definition would be used: player 1 is essentially \"freeloading\" off the extra productivity provided by player 2. This example illustrates that we need some way to define what it means for a value to be \"fair\". As we will see later in this section, this is typically done by defining a set of properties (also called axioms) that a value must adhere to. For example, the requirement that the values add up to the total produced worth $v(N)$ is also called the Efficiency axiom, and the requirement that the value for a player that has a constant contribution to each coalition should be equal to that contribution is also called the Dummy axiom.\nWe will denote the set of games on a finite set of players $N$ as $\\mathcal{G}(N)$. We can view the set of games $\\mathcal{G}(N)$ as a vector space by defining addition and scalar multiplication as follows:\n$(v + w)(S) = v(S) + w(S)$\n$(cv)(S) = cv(S)$\nfor any $S \\subseteq N, v, w \\in \\mathcal{G}(N), c \\in \\mathbb{R}$. The vector space of games $\\mathcal{G}(N)$ is isomorphic to the euclidean space $\\mathbb{R}^{2^n-1}$: any game $v \\in \\mathcal{G}(N)$ can be identified with a vector $v \\in \\mathbb{R}^{2^n-1}$ where"}, {"title": "4.1 Simple games", "content": "A simple game is a game for which the characteristic function takes on only the values in $\\{0,1\\}$. Coalitions with a worth of 1 and 0 are also called winning and losing coalitions, respectively. Such a game can alternatively be expressed by simply listing the winning coalitions. A common additional assumption is that any coalition containing a winning coalition is also winning, or equivalently, that any subset of a losing coalition is also losing. In that case, the game can be represented even more tersely by listing only the minimal winning coalitions, i.e. the winning coalitions for which each proper subset is losing. A common application of simple games is in voting games, where for example we want to model a bicameral legislature. In such a situation, a coalition is winning if it contains a majority in both chambers. In a voting game, the usual object of interest is the power any one member of the group has in influencing the outcome of the vote. This power can be quantified using a power index (Penrose, 1946), which is a real vector where each entry reflects the voting power of a given member. Although this problem might seem different enough from the quantification of value of a given player to the game, power indices are actually very similar to values. In fact, the Banzhaf and Shapley-Shubik power indices, which are two of the most well-known power indices, are simply defined as a value (the Banzhaf and Shapley value, respectively) for the voting game in its characteristic form. In other words, determining the power of a single member in a simple game can be viewed as quantifying the \"value\" of that player to a game where the worth of any coalition is either 0 or 1, and the worth of the total set of players is 1."}, {"title": "4.2 The Value Problem", "content": "As mentioned earlier, one of the main objects of study in TU-games is the quantification of value of the members of $N$ to the game. Such a value can be represented as a vector $\\phi(v) \\in \\mathbb{R}^n$. Often, the value will be represented as a separate function $\\phi_i$ for each player: $\\phi(v) = (\\phi_1(v), ..., \\phi_n(v))$. In order to define a value that is fair, we must first define what it means to be \u201cfair.\u201d To this end, several axioms have been proposed as \u201creasonable\u201d properties that a given value should adhere to in order to be called \"fair.\" In the following paragraphs, we will first introduce some of the most important axioms in the context of this work. Afterwards, we will construct a taxonomy of existing values for games based on the axioms they do or do not adhere to.\nBefore we give an overview of the most important axioms, we first introduce some necessary notation. Let $\\Pi(N)$ denote the set of permutations on the set $N$, i.e. $\\Pi(N) = \\{\\pi : N \\rightarrow N | \\pi \\text{ is a bijection}\\}$. If $\\pi \\in \\Pi(N)$ and $i,j\\in N$, then the precedence relation in $\\pi$ will be denoted as $j <_{\\pi} i, j \\leq_{\\pi} i$ for strict and non-strict precedence, respectively. For example, if $N = \\{1,2,3\\}$ and $\\pi(N) = (2,3,1)$, then $2 \\prec_{\\pi} 1$. We will now introduce the axioms that will be relevant to the definition of values.\n\\begin{itemize}\n    \\item Linearity: Given games $v, w \\in \\mathcal{G}(N)$ and constants $\\alpha, \\beta\\in \\mathbb{R}$. Using the vector space definition for games, we can define the linear combination of games $\\alpha v + \\beta w$:\n    $(\\alpha v + \\beta w)(S) = \\alpha v(S) + \\beta w(S), \\forall S \\subseteq N$\n    A value $\\phi_i$ adheres to the Linearity axiom if it is a linear function on $\\mathcal{G}(N)$:\n    $\\forall \\alpha, \\beta \\in \\mathbb{R}, v, w \\in \\mathcal{G}(N) : \\phi_i(\\alpha v + \\beta w) = \\alpha \\phi_i(v) + \\beta \\phi_i(w)$\n    Intuitively, this axiom states that if the outcome of a given game is defined as a linear combination of the outcomes of two or more \"sub-games,\" then the value of any given player should be the same linear combination of values for the sub-games.\n    \\item Null: A value adheres to the Null axiom if, for every game $v \\in \\mathcal{G}(N)$ with null player $i$:\n    $\\phi_i(v) = 0$\n    Intuitively, this axiom states that the value should reflect the fact that a null player provides no contributions or value to the game in any context.\n    \\item Dummy: A value adheres to the Dummy axiom if, for every game $v \\in \\mathcal{G}(N)$ with dummy player $i$:\n    $\\phi_i(v) = v(i)$\n    The intuitive interpretation of this axiom is that, if a player provides the exact same value independently of which other players are present in the coalition, then the value of that player to the game in general should be equal to that value. Note that this is a stronger version of the Null axiom: The Null axiom simply states that the Dummy axiom must hold for all dummy players $i$ with $v(i) = 0$. In literature, the term Dummy is often used for both of these axioms interchangeably (Weber, 1988; Sundararajan and Najmi, 2020). To prevent confusion, we use the term Null for the weaker axiom.\n    \\item Monotonicity: A game $v \\in \\mathcal{G}(N)$ is called monotonic if $\\forall S \\subseteq T \\subseteq N : v(S) \\leq v(T)$. A value $\\phi_i$ adheres to the Monotonicity axiom if, for any monotonic game $v \\in \\mathcal{G}(N)$, $\\phi_i(v) \\geq 0$.\n    \\item Efficiency: A value $\\phi$ adheres to the Efficiency axiom if:\n    $\\forall v \\in \\mathcal{G}(N) : \\sum_{i \\in N} \\phi_i(v) = v(N)$\n    Intuitively, this means that the total utility $v(N)$ that is obtained through the coop-eration is split up entirely and exactly among the players. This allows the value to be interpreted as a distribution of the total utility $v(N)$: in this case, each player receives a part of the total utility that is equal to the value of the player to the game.\n    \\item 2-Efficiency: This is an alternative axiom to Efficiency. Consider a game $v \\in \\mathcal{G}(N)$ and $i, j\\in N$. Consider also the reduced game with respect to $\\{i,j\\}$:\n    $v_{[ij]}(S) := v(S)$\n    $v_{[ij]}(S \\cup [ij]) := v(S\\cup \\{i, j\\})$\n    for any $S \\subseteq N \\backslash \\{i, j\\}$. A value $\\phi$ then adheres to the 2-Efficiency axiom if:\n    $\\phi_{[ij]}(v_{[ij]}) = \\phi_i(v) + \\phi_j(v)$\n    In other words, the 2-Efficiency axiom states that if two players are merged, then they should have the same value as they did before merging.\n    \\item Anonymity: A value adheres to the Anonymity axiom if:\n    $\\forall v \\in \\mathcal{G}(N), \\pi \\in \\Pi(N), i \\in N : \\phi_i(v) = \\phi_{\\pi(i)}(\\pi v)$\n    Intuitively, the Anonymity axiom states that relabeling the players of the game has no influence on the value."}, {"title": "4.2.2 \u03a4\u0391XONOMY OF VALUES", "content": "Now that we have an overview of the relevant axioms, we can use them to construct a taxonomy of values based on the axioms they adhere to. First, we define the marginal contribution of a player i to a coalition S, which can be interpreted as the additional utility that i contributes if i decides to join the coalition S:\nGiven a game $v\\in\\mathcal{G}(N), i\\in N$, and $S \\subseteq N \\backslash i$. The marginal contribution of $i$ to $S$ is defined as:\n$\\Delta_i v(S) = v(S\\cup i) - v(S)$\nWe will now construct the taxonomy of values. This taxonomy is largely based on Weber (1988), and we refer the reader to this publication for proofs and further details. An overview of the taxonomy is given in Figure 2. The most general kind of value that we will consider is a value that adheres only to the Linearity axiom. It can be shown (Weber, 1988) that if a value $\\phi_i$ adheres to the Linearity axiom, then for each player $i$ there exists a set of constants $\\{a_S^i | S \\subseteq N\\}$ such that, for any $v \\in \\mathcal{G}(N)$:\n$\\phi_i(v) = \\sum_{S \\subseteq N} a_S^i v(S)$\ni.e. the value is a linear combination of the characteristic function $v$ for all subsets $S \\subseteq N$. Furthermore, it can also be shown (Grabisch and Roubens, 1999) that if a value additionally adheres to the Null axiom, then for each player $i$ there exists a set of constants $\\{a_S^i | S \\subseteq N\\}$ such that:\n$\\phi_i(v) = \\sum_{S \\subseteq N\\backslash i} a_S^i \\Delta_i v(S)$"}, {"title": "4.3 Interaction Indices", "content": "The value problem described in Section 4.2 focuses on the value of individual players to a given cooperative game. However, the contribution of one player is not necessarily independent of the other players, i.e. the worth $v(S)$ of a set $S = \\{i,j\\}$ need not be equal to the sum of the worths $v(i) + v(j)$ of the individual players $i$ and $j$. The difference between $v(\\{i, j\\})$ and $v(i) + v(j)$ can be viewed as the added value of cooperation, or the interaction effect, between $i$ and $j$. This leads to a generalization of the concept of a value to subsets of players $S \\subseteq N$ (Grabisch and Roubens, 1999). In this case, the value $\\phi_S : 2^N \\rightarrow \\mathbb{R}$ is called an interaction index. A value can be viewed simply as an interaction index where\n$\\forall v \\in \\mathcal{G}(N), S \\subseteq N : |S| > 1 \\Rightarrow \\phi_S(v) = 0$\nThe order of an interaction index $\\phi$ is defined as the minimal $k \\in \\mathbb{N}$ such that $\\forall v \\in \\mathcal{G}(N), S \\subseteq N : |S| > k \\Rightarrow \\phi_S(v) = 0$. A value is then equivalent to an interaction index of order 1. In the following paragraphs, we will first introduce the concept of the discrete derivative, which will be of central importance in the definition of interaction indices. After this, I will give an overview of the generalized versions of axioms for values to interaction indices. Finally, we will use these axioms, along with a selection of new axioms defined specifically for interaction indices, to construct a taxonomy of interaction indices based on the axioms they do or do not adhere to."}, {"title": "4.3.1 DISCRETE DERIVATIVES", "content": "Interaction indices are designed to capture the non-additive interaction effects that are caused by the set $S$ as a whole. We will quantify these interaction effects by generalizing the marginal contribution $\\Delta_i v(S)$ of a player $i$ to coalitions $S \\subseteq N$: $\\Delta_S v(T), \\forall S,T \\subseteq N$. This generalization will be called the discrete derivative. To see how these concepts are connected, assume $i,j \\in N$ are two players for a given game $v \\in \\mathcal{G}(N)$. We distinguish three possibilities (the following explanation is based on Fujimoto et al. (2006)):\n\\begin{itemize}\n    \\item $v(i) + v(j) < v(\\{i, j\\})$. In this case, both $i$ and $j$ would be interested in forming a coalition, as together they can achieve more than they would if they operate separately. This difference between the sum of individual utilities and the utility of $\\{i,j\\}$ as a whole can be viewed as a positive interaction between $i$ and $j$.\n    \\item $v(i) + v(j) > v(\\{i, j\\})$. This is the reverse of the previous case: now $i$ and $j$ would not be interested to form a coalition, as they can achieve more on their own. The difference can now be viewed as a negative interaction between the two players.\n    \\item $v(i) + v(j) = v(\\{i,j\\})$. In this case, whether $i$ and $j$ decide to collaborate makes no difference. The two players behave additively, i.e. there is no interaction between them.\n\\end{itemize}\nThese possibilities show that the quantity of interest in defining the interaction between $i$ and $j$ is the difference between their worth as a coalition and the sum of their worths as singletons:\n$\\delta := v(\\{i, j\\}) - v(\\{i\\}) - v(\\{j\\})$"}, {"title": "4.3.2 GENERALIZED AXIOMS FOR INTERACTION INDICES", "content": "The axioms from Section 4.2 can be generalized to interaction indices", "Null": "For any null player $i$ in $v$", "have": "n    $\\forall S \\subseteq N \\backslash i : \\phi_{S\\cup i"}, "v) = 0$\n    i.e. the simultaneous interaction in a coalition containing a null player must be zero.\n    \\item Dummy Partnership: If $P \\neq \\emptyset$ is a dummy partnership in $v$, then:\n    $\\phi_P(v) = v(P)$\n    $\\forall S \\subseteq N \\backslash P, S \\neq \\emptyset : \\phi_{S\\cup P}(v) = 0$\n    The first part of this axiom is a simple generalization of the Dummy axiom to the more general dummy partnerships (remember that a dummy player is simply a dummy partnership with a single member). The second part states that there can be no simultaneous interaction in a coalition that contains a dummy partnership.\n    \\item Interaction Monotonicity: It is easy to see that a game is monotonic if and only if $\\forall i \\in N, S \\subseteq N \\backslash i : \\Delta_i v(S) \\geq 0$. We can use this observation to generalize this definition to $k$-monotonicity (Fujimoto et al., 2006). A game $v$ is $k$-monotonic if:\n    $\\forall S \\subseteq N, |S| \\leq k, T \\subseteq N \\backslash S : \\Delta_{S} v(T) \\geq 0$\n    An interaction index $\\phi$ then adheres to the Interaction Monotonicity axiom if, for any $k$-monotonic game $v$ and any coalition $S \\subseteq N, |S| \\leq k : \\phi_S(v) \\geq 0$.\n    \\item Interaction Anonymity: For a permutation $\\pi \\in \\pi(N)$ of $N$ and subset $S\\subseteq N$, we denote $\\pi(S) = \\{\\pi(i) | i \\in S\\}$. An interaction index then adheres to the Interaction Anonymity axiom if, for any permutation $\\pi\\in \\Pi(N)$, game $v \\in \\mathcal{G}(N)$ and subset $S\\subseteq N$:\n    $\\phi_{\\pi(S)}(\\pi v) = \\phi_S(v)$\n    This is again a straightforward generalization of the Anonymity axiom for values to coalitions, in that the axiom states that relabeling the players should have no influence on the outcome.\n    \\item Interaction Efficiency: An interaction index adheres to Interaction Efficiency if, for any game $v$:\n    $\\sum_{S \\subseteq N} \\phi_S("]}