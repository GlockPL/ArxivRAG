{"title": "KALE-LM: Unleash The Power Of AI For Science Via Knowledge And Logic Enhanced Large Model", "authors": ["Weichen Dai", "Yezeng Chen", "Zijie Dai", "Zhijie Huang", "Yubo Liu", "Yixuan Pan", "Baiyang Song", "Chengli Zhong", "Xinhe Li", "Zeyu Wang", "Zhuoying Feng", "Yi Zhou"], "abstract": "Artificial intelligence is gradually demonstrating its immense potential, and increasing attention is being given to how AI can be harnessed to advance scientific research. In this vision paper, we present our perspectives on how AI can better assist scientific inquiry and explore corresponding technical approach. We have proposed and open-sourced a large model of our KALE-LM model series, Llama3-KALE-LM-Chem-8B, which has achieved outstanding performance in tasks related to the field of chemistry. We hope that our work serves as a strong starting point, helping to realize more intelligent AI and promoting the advancement of human science and technology, as well as societal development.", "sections": [{"title": "Background", "content": "In recent years, the rapid development of artificial intelligence (AI) technology has enabled it to achieve, and in some cases surpass, top human performance in various high-intelligence tasks. These include recognition in speech [1], facial [2], and image [3], games such as Go [4], StarCraft [5], and Dota2 [6], as well as tasks related to text [7], image [8], and video generation, machine translation [9], knowledge-based question answering [10], debates, and solving advanced mathematical problems [11]. Science is one of the most important fields for the application of AI. As the crown jewel of human civilization and the cornerstone of various industries, science is a core driver of human progress, and its development can significantly accelerate and even revolutionize many fields. Historically, there have been three major research paradigms in science: the first paradigm, experiment, which emerged from Newtonian empiricism; the second paradigm, theory, born from Einstein's rationalism; and the third paradigm, simulation/computation, which arose from the third industrial revolution, the computation and information revolution. Today, the intelligence revolution is fostering a new research paradigm. Leveraging massive data and powerful computational capabilities, machines use deep learning and other AI technologies to establish algorithms and models that assist scientists in performing various core research tasks. These tasks include reducing search space, enabling embodied intelligence for automated scientific experiments, solving large-scale equations, and hypothesizing new scientific laws, thereby providing significant support to scientific research. Consequently, the application of AI in science not only poses new challenges to AI technology, whose solutions will substantially advance AI itself and its applications in other fields, but also greatly accelerates scientific development, offering unprecedented momentum to human civilization.\nTo date, although AI has made certain progress in the scientific field, it remains far from large-scale application due to current technological limitations. AI primarily encompasses three stages: \"sensing/perception - cognition/thinking -"}, {"title": "Current AI for science", "content": "Currently, there are three main technologies for constructing scientific brains using AI, namely specialized models for specific problems, deep neural networks with reasoning engines, and large model based methods."}, {"title": "Specialized Models For Specific Problems", "content": "The first technology involves building specialized deep neural network models for specific problems, significantly reducing the search space. Google DeepMind's AlphaFold series is one representative work. This effort constructs specialized deep neural network models for protein structure prediction, greatly lowering the threshold for protein structure analysis while significantly improving its efficiency. Similarly, many other studies have utilized deep neural network models for scientific simulation, design, and control, vastly enhancing the efficiency of scientific research. For instance, DPMD, by combining deep neural networks with high-performance computing, has dramatically expanded the capability of molecular dynamics simulations with first-principles accuracy. Other works have used deep learning for partial differential equation simulations, molecular property predictions, and more. The ABACUS-R proposed by the University of Science and Technology of China adopts a data-driven strategy, paving a new path for de novo protein design. In the field of physics, Iten et al. investigated how neural networks can emerge with important physical concepts, while Wu et al. constructed an AI physicist capable of abstracting theories from observational data. Similar research in biology includes GEARS, which can predict corresponding transcriptional responses to perturbations of single or multiple genes in cells. However, these models are only applicable to certain professional fields, and each field requires custom development, leading to high development costs."}, {"title": "Deep Neural Networks With Reasoning Engines", "content": "The second technology integrates deep neural networks with reasoning engines, providing new perspectives (such as auxiliary lines) for reasoning in specific domains to enhance thinking and decision-making. AlphaGeometry [11] combines large models with symbolic engines to better solve complex problems through enhanced thinking and decision-making. FunSearch [12] generates targeted programs to solve specific problems through the evolution of pre-trained language models and evaluators. In China, Inter-GPS [13] has implemented a method based on formal languages and symbolic reasoning, which shows strong interpretability in solving geometric problems. HAKE [14] provides a rich space of primitives and a knowledge base, containing over 26 million primitive labels and numerous logical rules. FTL-LM [15] enhances the model's application capabilities by integrating contextual information and logical rules from knowledge graphs into language models. Similarly, these technologies also require customization and come with significant development expenses."}, {"title": "Large Model Based Methods", "content": "The third technology relies on large models for different forms of interaction. With the rise of ChatGPT [16], the application of large models in the scientific field has become a hot topic. ChemCrow [17] enhances the performance of general large models in the chemistry field through simple tool calls. Med-PaLM2 [?] surpasses previous work in general medical question-answering. There are also studies in China on this technological route, such as the GeoGalactica [18] large model for earth sciences by the Shanghai Jiao Tong University team, based on the general large model Galactica, and the ChemLLM [19] scientific large model for chemistry by the Shanghai AI Laboratory, based on ShuSheng-PuYu. To better integrate knowledge into large models, many studies have been conducted. LLAMA-PRO introduces new modules to learn new domain knowledge from the perspective of incremental pre-training. Researchers from Tsinghua and Oxford have proposed methods for integrating domain-specific knowledge into prompt engineering to improve large language models' performance in scientific fields. Other researchers have opted to combine knowledge graphs to provide support. Still, they suffer from critical issues such as poor reliability (commonly referred to as \"hallucinations\"), weak interpretability, and limited logical reasoning abilities-factors that are crucial in scientific domains."}, {"title": "Weakness", "content": "The three techniques mentioned above are currently unable to integrate scientific knowledge and logic into AI models. As a result, present-day AI cannot learn, understand, or apply these scientific principles and logical reasoning, which"}, {"title": "Vision for a scientific brain", "content": "Large models represent one of the significant advancements in the field of AI. Prior to their emergence, AI systems typically required specially designed algorithms tailored to specific tasks and scenarios, and were limited to performing single tasks within the scope of their training data. The breakthrough of large models lies in their ability to exhibit human-like \"emergent\" general intelligence, enabling them to learn knowledge across multiple domains and handle a variety of tasks. These models usually have a vast number of parameters, ranging from hundreds of millions to hundreds of billions, allowing them to effectively process unseen data or new tasks. Moreover, the larger the parameter count, the greater their expressive and comprehension capabilities. These models are based on deep learning techniques, primarily utilizing the Transformer architecture, and are trained on large amounts of textual data. They can process and generate natural language text, making them widely applicable across many fields. Therefore, large models can naturally serve as the basis for a scientific brain.\nDespite the importance of embedding knowledge and logic into large models, we believe that the primary task in achieving AI for science is to clearly identify the needs of scientists, and then accordingly train large models to develop the corresponding capabilities. Therefore, we have summarized several key competencies, i.e. information extraction, semantic parsing, knowledge QA and reasoning&planning."}, {"title": "Key tasks of AI for science", "content": ""}, {"title": "Information Extraction", "content": "There are plenty of scientific advancements and valuable insights buried in millions of academic papers, creating significant barriers for researchers trying to stay abreast of the latest research trends and past methods. Indeed, the lack of information flow in fundamental disciplines has become one of the biggest obstacles for researchers, especially for newcomers [20]. Recent studies have attempted to use transformer based models to identify crucial information such as experimental parameters and results in texts, then summarize them into structured formats like tables [20, 21, 22]. However, these works often do not strictly differentiate between entities and relations, only focusing on various types of entities, which is insufficient for knowledge construction. Additionally, most of them relies on manually labeled corpora, manual feature extraction, and manual pattern construction [23, 24, 25].\nWe believe it is urgently needed for a scientific brain to rapidly and accurately extract valuable information from the vast sea of academic papers, which will help researchers a lot [26]. Here, we define our information extraction task as a combination of named entity recognition(NER), relation extraction(RE), and other similar tasks. For example, we expect the scientific brain to extract the ratios of different components and corresponding physicochemical properties from papers related to chemical materials. As summarized in some articles [22, 25, 26], extracting structured data from unstructured raw text will allow researchers to quickly access target information within large-scale data, which is expected to accelerate the pace of future scientific discoveries. More importantly, we hope that the scientific brain can automatically construct knowledge from data sources and build knowledge bases, so as to eventually realize automated knowledge summarization and even knowledge discovery, where the information extraction serves as a critical step."}, {"title": "Semantic Parsing", "content": "Semantic parsing enables AI systems to understand and interpret complex texts by breaking down natural language into structured representations that can be more easily processed, analyzed, and utilized in research, which plays a crucial role in the development of scientific AI. For example, the input instructions by researchers who lack the knowledge of prompt engineering can be understood by large language models through semantic parsing. The core of semantic parsing lies in the deep semantic understanding of user input in natural language, and subsequently transforming it into machine-executable commands or queries.\nEarly semantic parsing systems mainly relied on rule-based approaches, allowing them to adapt to the needs of specific domains. For example, the pattern-matching-based system SAVY [27], though simple, demonstrated significant fragility due to the limitations of pattern matching to surface structures. Another class of approaches adopted grammar-based systems, such as LUNAR [28], where syntactic parsers mapped natural language into parse trees of the underlying database query language through rules. Over time, more semantic parsing systems began to use statistical learning techniques, which could be trained from sample pairs of input-output examples. For instance, fully supervised semantic parsing methods learned from sentence-logical form pairs, with research in this area including works by [29, 30, 31].\nWith the rise of large language models, LLM-based semantic parsing methods have emerged. [36] demonstrated that in low-resource settings, few-shot prompting with GPT-3 and fine-tuned BART models can generate constrained decoding, outperforming task-specific semantic parsing architectures. [37] achieved state-of-the-art results in SQL prediction tasks by fine-tuning the T5-3B model and using constrained decoding. To evaluate the performance of different large language models in semantic parsing tasks, [38] introduced a benchmark platform called BenchCLAMP, covering six semantic parsing datasets, supporting the evaluation of autoregressive language models and sequence-to-sequence models under few-shot prompting, fine-tuning, and constrained decoding settings. [39] confirmed that when handling semantically complex sentences, abstract meaning representation (AMR) may be more beneficial for large models, as AMR can explicitly represent the propositional structure of sentences, removing information irrelevant to the semantic task while highlighting the most important information. Therefore, the enhancement of semantic parsing in large models lays a strong foundation for the future development of scientific AI, enabling more sophisticated and precise applications in various research domains."}, {"title": "Knowledge QA", "content": "Knowledge QA (Question Answering) is a crucial task for scientific AI, aimed at generating accurate and meaningful answers based on scientific knowledge. Traditional knowledge QA systems, which rely on predefined rules and patterns [40], often struggle to handle the complexity and high degree of specialization in scientific domains. The advent of large models has revolutionized the field of knowledge QA [41]. These models are capable of conducting deep searches and comprehending vast bodies of literature, generating accurate answers by contextualizing information, therefore able to tackle complex scientific questions. This capability makes large models particularly effective in knowledge QA tasks within scientific domains, providing scientists with precise and reliable answers.\nUnlike common knowledge question answering, scientists increasingly need to utilize the growing intelligence of large models for more advanced interactions. These interactions include, but are not limited to, enhancing the speed and accuracy of scientific simulations, optimizing the design and control of scientific experiments, and even enabling novel and reasonable scientific discoveries. Therefore, large models are required to effectively integrate the scientific knowledge they have already learned with external scientific knowledge retrieved from outside sources.\nOverall, the integration of large models into Knowledge QA represents a significant leap forward in the ability of researchers to access and utilize scientific knowledge, paving the way for more efficient and innovative research practices."}, {"title": "Reasoning & Planing", "content": "Reasoning and planning have long been fundamental pillars of scientific research. Scientists use observations to formulate general theories, with reasoning enabling the integration of diverse pieces of information into coherent theoretical frameworks. Planning, in turn, is critical for designing rigorous experiments that effectively test hypotheses. However, the solution space in scientific problems is often vast, and human intelligence is typically required to derive insights and reach final solutions. The role of AI is expected to alleviate the more laborious aspects of scientific work by theoretically exploiting and deducing knowledge, and subsequently designing and conducting experiments, often with the assistance of robots.\nIn the field of chemistry, various attempts have been made to harness Al's reasoning and planning capabilities. Traditional AI models such as regression, support vector machines (SVM), and decision trees have been employed to extract hidden information from large volumes of experimental data. Transformer-based methods have also been utilized to predict the properties of chemical compounds. However, these models typically require extensive data preprocessing and are highly domain-specific, making them difficult to integrate into the daily workflows of chemists. Furthermore, these approaches are not closely linked to reasoning, as they primarily transform data into other data without truly understanding or utilizing underlying knowledge.\nWe argue that scientific research requires more explicit reasoning and planning across broader, more generalized domains. Large language models are poised to play a pivotal role in this regard by comprehending the properties of chemicals and reactions. Leveraging the natural language understanding capabilities of LLMs and enhancing their scientific reasoning abilities could enable more effective pruning of infeasible regions in complex scientific domains. This would allow researchers to navigate high-dimensional solution spaces more efficiently, thereby accelerating the pace of scientific discovery. Moreover, we envision that the scientific brain can utilize its acquired knowledge to reason through complex problems, discovering insights in fields where human cognition struggles due to the intricate reasoning required. This AI system could not only generate hypotheses but also design and execute experiments to test these hypotheses, ultimately establishing an automated system for knowledge discovery and validation. For such a system to succeed, accurate understanding of scientific entities and their relationships, as well as robust reasoning and planning capabilities, are essential. These elements form the core of processing existing knowledge in order to generate new knowledge."}, {"title": "Knowledge and logic enhancement", "content": "Expert systems aim to represent the knowledge of specialists in a particular domain using machines, and then simulate the expert's role in the field through automated machine reasoning. The early work on expert systems can be traced back to the DENDRAL system developed by E. A. Feigenbaum and his students. This system was designed to assist with structural analysis in the field of chemistry, taking mass spectrometer data as input and producing the chemical structure of a substance as output. Following this, another notable expert system was MYCIN, which was used for diagnosing infectious blood diseases. During this period, knowledge engineering and knowledge-based systems became mainstream in artificial intelligence. Even common-sense knowledge, corresponding to expert domain knowledge, saw renewed efforts, including the Cyc project led by Lenat. However, traditional expert systems are based on knowledge models and rule systems such as Prolog, SOAR, and first-order logic, therefore facing challenges including theoretical complexity, limited expressive power, high reasoning complexity, poor knowledge learning capabilities, and lack of generality.\nAlthough some existing large models perform well on general tasks, they are still far away from the strong AI that can truly assist scientists. As black-box models, large models implicitly encode knowledge within their parameters, making it difficult to interpret or validate the acquired knowledge. The specific patterns and functions they use for predictions or decision-making are not accessible or interpretable to humans. Some large models attempt to explain their predictions through the application of \"chain-of-thought\" or \"tree-of-thought\" reasoning, however, this approach also encounters the \"hallucination\", which significantly hinders their use in high-risk scenarios. This issue also raises another concern: because large models are trained on general corpora, they often lack the domain-specific knowledge or updated training data required to effectively integrate and utilize scientific data and knowledge.\nWhile these shortcomings can be mitigated by further enhancing model capabilities, we believe a better approach is to deeply integrate large models with knowledge and logic. Similar to the mechanisms of human thought, large models excel in generalization, versatility, and approximate accuracy, which correspond to what is known as System 1 thinking. In contrast, knowledge-and-logic-based computation excels in precision, reliability, and interpretability, aligning with System 2 thinking. By combining these strengths, we can leverage their complementary advantages, potentially leading to the realization of strong artificial intelligence in the near future. From an application perspective, strong artificial intelligence would surpass current large model technology in both breadth and depth.\nBased on the above perspectives, we have conducted several foundational studies, all of which have yielded promising results. We will present these findings in our forthcoming publications."}, {"title": "Our practice in chemistry", "content": ""}, {"title": "KALE-LM-Chem", "content": "We proposed Llama3-KALE-LM-Chem-8B, our first KALE-LM specialized in chemistry based on Llama3. The model training is conducted in two stages. The first stage involves continual pre-training based on the Llama3 model, using LoRA technology and the Adam optimizer with an initial learning rate of 2e-6, and a maximum context length of 8192. The second stage is supervised fine-tuning (SFT). We adopt Adam optimizer with an initial learning rate of 2e-5, a maximum number of tokens 2048, and the batch size is 8 for each GPU. All stages are carried out on A100 80G GPU machines with Deepspeed Zero-2. We also proposed an instructed version of our model, which specializes on chemical QA."}, {"title": "Evaluation", "content": "To critically assess our model, we conduct a comprehensive evaluation through multi-dimensional capabilities. The assessment of basic skills is performed using open datasets and benchmarks. Our detailed internal tests further explore the model's capabilities in the four dimensions of the scientific brain. The following sections detail the evaluation methods and their outcomes."}, {"title": "Open Benchmark Automatic Evluation", "content": "To comprehensively evaluate the performance of our model in the chemical vertical domain, we employ OpenCompass to automatically assess the capabilities of our model. For the evaluation of chemical capabilities, we set the assessment goals in terms of the basic abilities of chemistry, scientific QA, and the extraction of chemical meta-information. We evaluated ChemBench for the basic abilities of chemistry, MMLU and SciQ for scientific QA, and MOF for the extraction of chemical meta-information.\nChemBench We evaluated the performance of the LLM in chemical tasks on ChemBench and reported the results in Table 2. The evaluation results indicate that KALE-LM is significantly superior to LLM of similar scale. Compared with Llama3-8B-Instruct, the chemical capability of KALE-LM has been significantly improved. Compared with GPT-3.5, KALE-LM achieved higher scores in 7 out of 9 tasks. KALE-LM-Instruct even surpassed GPT-3.5 across the board. Compared with GPT-4, KALE-LM-Instruct achieved higher scores in 7 out of 9 tasks, and the overall average score was more than 3% higher than that of GPT-4 (57.01% vs 53.72%)."}, {"title": "In-House Automatic Evluation", "content": "Although there are some open benchmark datasets for evaluation, we believe that this is far from sufficient to comprehensively understand the capabilities of vertical-domain chemical LLMs. Specifically, we have created a series of internal datasets to evaluate the different abilities of the model, such as chemical meta-information extraction, electrolyte semantic parsing, chemical knowledge QA, etc."}, {"title": "Conclusion", "content": "In this vision paper, we first present four core tasks that a artificial intelligence scientific brain needs to focus on, along with our insights of enhancing large models with knowledge and logic. Building on this foundation, we have conducted numerous explorations and attempts, achieving significant progress and results, which will be published in the future. Through this article, we are releasing and open-sourcing one of our milestones, a large model for chemistry, which demonstrates excellent performance on tasks in the chemical domain. We hope our work will promote research and development of artificial intelligence in the field of science."}, {"title": "Semantic Parsing Example - Ellipse :", "content": "A focal point of the ellipse $\\frac{x^2}{k^2}$ + $y^2$ = 1(k > 0) is (3,0), then k=?"}, {"title": "Semantic Parsing Example - Hyperbola :", "content": "What is the equation of the straight line where the chord of the hyperbola $\\frac{x^2}{4}$ \u2013 $y^2$ = 1 passes the point M(3, \u22121) and is bisected by the point M\u041c?"}, {"title": "Advanced Semantic Parsing Example - Hyperbola :", "content": "Knowing the hyperbola C: $\\frac{x^2}{a^2}$ - $\\frac{y^2}{b^2}$ = 1(a > 0, b > 0), the left focal point F of the hyperbolic C is a straight line with a slope of sqrt2 intersecting the left branch of the hyperbola C at A and B two points, if the circle with AB as the diameter passes the coordinate origin O, then the eccentricity of the hyperbolic C is ?"}]}