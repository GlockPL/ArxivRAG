{"title": "Rethinking Generalizability and Discriminability of Self-Supervised Learning from Evolutionary Game Theory Perspective", "authors": ["Jiangmeng Li", "Zehua Zang", "Qirui Ji", "Chuxiong Sun", "Wenwen Qiang", "Junge Zhang", "Changwen Zheng", "Fuchun Sun", "Hui Xiong"], "abstract": "Representations learned by self-supervised approaches are generally considered to possess sufficient generalizability and discriminability. However, we disclose a nontrivial mutual-exclusion relationship between these critical representation properties through an exploratory demonstration on self-supervised learning. State-of-the-art self-supervised methods tend to enhance either generalizability or discriminability but not both simultaneously. Thus, learning representations jointly possessing strong generalizability and discriminability presents a specific challenge for self-supervised learning. To this end, we revisit the learning paradigm of self-supervised learning from the perspective of evolutionary game theory (EGT) and outline the theoretical roadmap to achieve a desired trade-off between these representation properties. EGT performs well in analyzing the trade-off point in a two-player game by utilizing dynamic system modeling. However, the EGT analysis requires sufficient annotated data, which contradicts the principle of self-supervised learning, i.e., the EGT analysis cannot be conducted without the annotations of the specific target domain for self-supervised learning. Thus, to enhance the methodological generalization, we propose a novel self-supervised learning method that leverages advancements in reinforcement learning to jointly benefit from the general guidance of EGT and sequentially optimize the model to chase the consistent improvement of generalizability and discriminability for specific target domains during pre-training. On top of this, we provide a benchmark to evaluate the generalizability and discriminability of learned representations comprehensively. Theoretically, we establish that the proposed method tightens the generalization error upper bound of self-supervised learning. Empirically, our method achieves state-of-the-art performance on various benchmarks. Our implementation is available at https://github.com/ZangZehua/essl.", "sections": [{"title": "1 Introduction", "content": "As Moore's Law slows down Shalf (2020), the Connectionism-based data-driven learning paradigm hits a developmental bottleneck, since improving the model performance by simply increasing the neural network parameters is unachievable. Additionally, empowering the model's capacity by feeding large-scale annotated data to the model Deng et al. (2009) suffers from the excessive annotating workloads. To this end, self-supervised learning emerges, developing well-designed self-supervised tasks by leveraging the guidance of specific knowledge foundations. For example, contrastive learning is based on the multi-view learning assumption Sridharan and Kakade (2008); Tsai et al. (2021); Wang et al. (2022), and masked language/image modeling (M-M) is based on the masking-and-reconstruction paradigm Al-Mubaid (2007); Wang et al. (2022); Elkins (2008). SSL further trains models to accomplish these self-supervised tasks in a completely unsupervised manner. Benefited from the knowledge-guided data-driven learning paradigm, SSL approaches achieve empirical successes in various fields, such as computer vision Hjelm et al. (2019); Bao et al. (2022); He et al. (2022a); Xie et al. (2022) and natural language processing Brown et al. (2020); Devlin et al. (2019).\nIn the field of SSL, the learned representations are generally regarded as having sufficient generalizability (or transferability) and discriminability, and thus recent works draw limited attention to researching the intrinsic relationship between the designed self-supervised task and the properties of the representations learned by SSL methods. To this end, we investigate such representation properties for various self-supervised tasks. Specifically, we recap the preliminaries of the conventional contrastive learning paradigm: bringing views of the same image together and pushing views of the different images farther apart. Theoretical proofs Wang et al. (2022) demonstrate that such a learning paradigm encourages the model to learn the discriminative information from the inputs, but the guarantees and evidence provided by Wang et al. (2022); Tian et al. (2020a) further demonstrate that the contrastive objective improves the domain-specific discriminability while degrading the cross-domain generalizability of the learned representations. In contrast, certain SSL methods tend to boost generalizability yet undermine the discriminability of the representations, as these approaches only require representations to contain information-decoupled dimensions without the intuition to capture discriminative information Zbontar et al. (2021); Nakamura (2000); Liu et al. (2022). To profoundly understand the relationship between generalizability and discriminability, we conduct a motivating experiment in Figure 1, which demonstrates the existence of a mutual-exclusion relationship between such properties in SSL.\nDoes the juste-milieu exist to learn a self-supervised representation with strong generalizability and discriminability?\nTo acquire this aspiration, we rethink the SSL paradigm from evolutionary game theory (EGT) perspective. The intuition behind our behavior is that EGT, which benefits from dynamic system modeling, can predict the rational scenarios in the game of two players or populations jointly cooperating and competing. Indirect EGT is commonly applied to examine the interaction mechanism of complex behaviors between populations Huck and Oechssler (1999); feng Ji et al. (2019); Bester and G\u00fcth (1998). On this basis, we hypothesize that fusing an SSL model with strong generalizability and another SSL model with strong discriminability in an appropriate manner can derive the desired SSL model with jointly strong generalizability and discriminability. Thus, following EGT, we treat the generalizability and discriminability models as separated populations and assign the corresponding proportions Huck and Oechssler (1999); feng Ji et al. (2019); Bester and G\u00fcth (1998), i.e., the tuning hyper-parameters. Our objective is to learn appropriate tuning hyper-parameters to boost the joint performance of generalizability and discriminability for SSL models from the perspective of EGT. Following the empirical evolutionary game analysis method Gatenby and Vincent (2003); Bester and G\u00fcth (1998); Huck and Oechssler (1999); feng Ji et al. (2019), we define the ideal event and analyze the impacts of tuning hyper-parameters on the dynamic evolution process, thereby deriving appropriate hyper-parameters.\nHowever, performing the complete EGT analysis on each target downstream dataset requires the over-multitudinous corresponding annotations on the target downstream dataset, which is antithetical to the principle of SSL. Thus, we propose the Evolutionary game-guided Self-Supervised Learning approach, namely ESSL. Specifically, we first select several annotated datasets as the representative prior dataset, which is treated as the available inputs for the EGT analysis to generate instructive tuning hyper-parameters for the fusion of generalizability and discriminability models. Note that the selected datasets do not include the target dataset for SSL. The intuition behind such a behavior is that the trade-off hyper-parameters derived by the EGT analysis on the representative prior datasets hold general effectiveness on various datasets. Yet, directly adopting such fixed tuning hyper-parameters cannot consistently boost the joint performance of the learned representations on specific datasets due to the distribution gaps between domains.\nTo this end, to learn the tuning hyper-parameters for the model fusion by jointly leveraging the guidance of EGT and dynamically adapting the hyper-parameters for the specific target dataset, the proposed ESSL introduces the reinforcement learning (RL) paradigm to enable the fitting of hyper-parameters towards the target dataset. The rationale behind the above process is that tuning the hyper-parameters in SSL is a sequential optimization process, which adheres to the property of the Markov Decision Process, and the guidance of EGT, i.e., the instructive tuning hyper-parameters generated by the EGT analysis, can be introduced in the reward function of RL with ease. Concretely, to comprehensively evaluate the generalizability and discriminability of learned representations, we further provide a novel self-supervised benchmark. Then, we conduct extensive comparisons on the proposed benchmark and the conventional self-supervised benchmark to sufficiently demonstrate the performance superiority of ESSL over candidate self-supervised methods. The significant contributions of this work are four-fold:\n*   We disclose the mutual-exclusion relationship between the generalizability and discriminability of the representations learned by SSL methods.\n*   By revisiting the SSL paradigm from the perspective of EGT, we propose an innovative SSL method, namely ESSL, which jointly leverages the guidance of EGT-based analyses and the sequential optimization of the RL approach to empower representations to acquire strong generalizability and discriminability in a balanced manner.\n*   We provide theoretical analyses to demonstrate that ESSL obtains the tighter generalization error upper bound on downstream tasks compared with conventional SSL methods.\n*   Under the self-supervised benchmarks and the proposed benchmark comprehensively measuring generalizability and discriminability, the results prove the effectiveness of ESSL."}, {"title": "2 Related Works", "content": "Self-supervised learning. In the unsupervised learning setting, self-supervised contrastive learning Chuang et al. (2020); Robinson et al. (2021); Elkan and Noto (2008); du Plessis et al. (2014); Sridharan and Kakade (2008); Tsai et al. (2021); Grill et al. (2020); Ermolov et al. (2021); Zbontar et al. (2021); Verma et al. (2021); Xiao et al. (2021) has achieved great successes. Specifically, CMC Tian et al. (2020a) and AMDIM Bachman et al. (2019) use contrastive learning on multi-view data. SimCLR Chen et al. (2020) and MoCo He et al. (2020) employ large batches or memory banks to enlarge the available negative features to learn better representations. SwAV Caron et al. (2020a) compares the cluster assignments under different views instead of directly comparing features by using more views. BYOL Grill et al. (2020) and Barlow Twins Zbontar et al. (2021) present a crucial issue: insufficient self-supervision may lead to feature collapse. I-JEPA Assran et al. (2023) predicts the representations of various target blocks in the same image without relying on hand-crafted data augmentations, thereby improving generalizability. SiameseIM Tao et al. (2023) shows that it is possible to achieve better discriminability by obtaining both semantic alignment and spatial sensitivity with a single dense loss. DINO Caron et al. (2021) discloses a significant discovery: self-supervised vision Transformers (ViTs) exhibit unique explicit information representation capabilities in image semantic segmentation. In other words, self-supervised ViTs possess stronger discriminability compared to supervised ViTs or traditional convolutional neural networks. Therefore, DINO Caron et al. (2021); Oquab et al. (2024) involves constructing a self-distillation method to train and update the teacher and student networks, employing techniques such as parameter updates similar to exponential moving averages and multiple cropping strategies for training input images. Benefiting from the well-designed architectures, benchmark SSL methods, e.g., SSL-HSIC Li et al. (2021b), IPMC Li et al. (2023), MAE He et al. (2022b), and CAE Chen et al. (2024), provide relatively sufficient self-supervision to solely improve the generalizability or discriminability performance. Orthogonal to existing methods, we focus on jointly improving the generalizability and discriminability of representations, thereby boosting the SSL model performance.\nEvolutionary game theory. Considering bounded rationality and learning mechanisms, EGT Osborne and Rubinstein (1994); Easley and Kleinberg (2010); Vincent (1985) focuses on the decision-making process and solves multiple equilibriums well in biology Gatenby and Vincent (2003) and economics Bester and G\u00fcth (1998); Huck and Oechssler (1999); feng Ji et al. (2019). Gatenby and Vincent (2003) uses EGT to frame the tumor-host interface, elucidating key biological parameters controlling the advance of tumor tissue into the surrounding host tissue. Bester and G\u00fcth (1998); Huck and Oechssler (1999) elaborate on whether altruism and fair distribution are evolutionarily stable in some instances. feng Ji et al. (2019) applies EGT to examine the interaction mechanism of complex behaviors between local governments and auto manufacturers. Inspired by the practical successes of EGT, the guidance of EGT is expected to be promising in our case.\nReinforcement learning. Recently, RL has achieved great successes in many real-world domains, such as Game AI Silver et al. (2017, 2018); Vinyals et al. (2019), Robotics Kalashnikov et al. (2018); H\u00fcttenrauch et al. (2017), autonomous vehicles Kiran et al. (2021), and so on. Considering the strong sequential decision and policy optimization ability, RL can be regarded as a promising solution for Artificial General Intelligence (AGI). Furthermore, RL has been successfully applied in many Computer Vision (CV) and Natural Language Processing (NLP) tasks for hyper-parameter tuning Li et al. (2019); Yu et al. (2018); Kumar et al. (2023); Sun et al. (2023). Hence, we utilize Proximal Policy Optimization (PPO) Schulman et al. (2017), a well-studied policy gradient RL method, to search for the optimal hyper-parameters that balance ESSL's generalizability and discriminability."}, {"title": "3 Preliminaries", "content": "To elaborate on the detailed implementation of ESSL, we recap the necessary preliminaries in this section."}, {"title": "3.1 Preliminaries of Self-Supervised Learning", "content": "Contrastive learning. Given  $X = \\{x_i | i \\in \\{1,..., NS\\} \\text{ and } j \\in \\{1,...,MV\\}\\}$ as a multi-view dataset, self-supervised contrastive learning (SS-CL) Tian et al. (2020a); Chen et al. (2020) learns representations by maximizing agreements between the views of the same samples $\\{x_i^j, x_i^{j'}\\} j, j' \\in \\{1, ..., MV\\}$ and $j \\neq j'$ (positive pairs), while minimizing agreements between the views of different samples $\\{x_i^j, x_{i'}^{j'}\\} j,j' \\in \\{1,...,MV\\}$ and $i \\neq i'$ (negative pairs). The input data $x$ is fed into the encoder $f_\\theta(.)$ to learn a representation $h$, and $h$ is mapped into a feature $z$ by a projection head $g_\\nu(.)$, where $\\theta$ and $\\nu$ are the network parameters, respectively. $f_\\theta(.)$ and $g_\\nu(.)$ are trained by using a contrastive loss, i.e., InfoNCE van den Oord et al. (2018):\n$L_{InfoNCE} = -E_{X_S} [log \\frac{d(\\{z^+\\})}{d(\\{z^+\\}) + \\sum_{i'=1}^K d(\\{z^-\\})} ] ,$   (1)\nwhere $X_S$ is i.i.d. sampled from $X$, $z^+$ denotes a positive pair, $z^-$ denotes a negative pair, and $d(.)$ is a similarity measurement formula, e.g., cosine similarity.\nFeature constraint learning. As another representative SSL paradigm, feature constraint learning achieves impressive performance superiority. Specifically, Barlow Twins Zbontar et al. (2021) proposes a novel self-supervised feature constraint learning loss, which is formulated as follows:\n$L_{BarlowTwins} = \\sum_i (1 \u2013 C_{ii})^2 + \\epsilon \\sum_{i} \\sum_{i' \\neq i} C_{ii'}^2 ,$   (2)\n$C_{ii'} = \\frac{\\sum_b z_{bi} z_{bi'}}{\\sqrt{\\sum_b (z_{bi})^2} \\sqrt{\\sum_b (z_{bi'})^2}} ,$\nwhere $\\epsilon$ is a positive constant, trading off the importance of the first and second terms of the loss, b indexes batch samples. $C_{ii'}$ is the cross-correlation matrix computed between $z_i$ and $z_{i'}$ with values in the range between -1 and 1, and i, i', j, j' are indexes."}, {"title": "3.2 Preliminaries of Evolutionary Game Theory", "content": "We recap the necessary introductions of EGT Weibull (1997); Easley and Kleinberg (2010). The key insight of EGT is that many behaviors involve the interaction of multiple organisms in a population, and the success of any one of these organisms depends on how its behavior interacts with that of others. Thus, we evaluate the fitness of an individual organism in the context of the full population in which it lives. In EGT, fitness is like a payoff, which depends on the strategies of the organisms with which it interacts. Evolutionary Stable Strategy (ESS) and Replicator Dynamics (RD) are two critical concepts in EGT Weibull (1997); Easley and Kleinberg (2010), which are introduced as follows.\nEvolutionary stable strategy. ESS refers to a strategy in a population that cannot be replaced by any other strategy with higher fitness once it has reached a certain proportion. In other words, an ESS is a strategy that, once it comes to a certain proportion of the population, will remain stable and maintain that proportion through the evolutionary process. This concept was proposed by the biologist John Maynard Smith Maynard Smith (1974) and is now widely used in various evolutionary game models Gatenby and Vincent (2003); Bester and G\u00fcth (1998); Huck and Oechssler (1999); feng Ji et al. (2019).\nReplicator dynamics. RD is a dynamic model that describes changes in the proportion of strategies in evolutionary games. It is based on the assumption that individuals in each generation will \"replicate\" their strategy to the next generation with a certain probability, and the payoff of each strategy determines this probability. Using RD, we can predict how the proportion of strategies in evolutionary games will change over time under different initial conditions.\nThe basic form of the constructed RD equation is:\n$\\frac{dx_i(t)}{dt} = [f(s_i,x) \u2212 f(x,x)]x_i, $   (3)\nwhere $s_i$ is one strategy in strategy sets, $x_i$ denotes what proportion of individuals in the game group select the strategy $s_i$ at time t, $f(s_i,x)$ denotes the expected payoff of the individual $s_i$, $f(x,x)$ denotes the expected payoff for the entire population, and $\\frac{dx(t)}{dt}$ represents the change rate of individuals that select the strategy $s_i$ per unit time. This equation can be explained as follows: the rate of change in individual strategy proportion is directly proportional to the difference between the current strategy's payoff and the average group payoff. When $f(s_i,x) \u2212 f(x, x) > 0$, the proportion of strategies will increase. On the contrary, when $f(s_i, x) -\u2212 f(x, x) < 0$, its strategy proportion will decrease."}, {"title": "4 Methodology", "content": "In this section, we elaborate on the proposed ESSL, and the approach framework is illustrated in Figure 2. The detailed nomenclature is provided in Appendix A. We emphasize the roadmap of ESSL as follows: 1) we transform the target objective of achieving a SSL representation with strong generalizability and discriminability into the target objective of tuning the hyper-parameters of two decoupled SSL methods and further combining the candidate methods to build the desired SSL method in an ensemble manner; 2) we perform the EGT analysis for the generalizability and discriminability of SSL methods on certain representative prior datasets to derive the average hyper-parameters, which is treated as the guidance for the following RL-based hyper-parameter tuning process; 3) we impose the RL-based approach to jointly leverage the guidance of the EGT analysis and tackle the sequential optimization of the hyper-parameter tuning. Therefore, the derived ESSL can be well generalized into various SSL fields."}, {"title": "4.1 Revisiting the Learning Paradigm of the Evolutionary Game Theory Perspective", "content": "As the motivating exploration in Figure 1, we demonstrate the negative correlation between the generalizability and discriminability of a representation learned by SSL. Concretely, to chase the trade-off between the generalizability and discriminability, we intuitively revisit the learning paradigm of self-supervised approaches from the EGT perspective and thus treat the generalizability and discriminability models as two populations working against and cooperating. Precisely, the process of tuning the hyper-parameters, i.e., the impacts of the generalizability and discriminability models on the fusion of such models exactly fits the case of population evolution in EGT, and the dynamic property of the hyper-parameter tuning process adheres to the requirement of EGT, such that we state that adopting EGT to derive the desired trade-off between generalizability and discriminability is theoretically sound.\nEGT model assumption. The current benchmark cannot comprehensively evaluate the generalizability and discriminability of a self-supervised model, which vary due to different pretext tasks or loss functions, such that following the procedure of EGT, we propose an integrated benchmark, and such a benchmark further is the foundational assumption of EGT model. Specifically, assuming that supervised learning (SL) achieves lower classification errors than SSL on the downstream tasks, we propose a benchmark to measure the generalizability and discriminability of self-supervised models. Given two datasets, D and D', and a self-supervised model M, based on the pre-training on D, G denoted the generalizability of M on D', and D denotes the discriminability of M on D:\n$G = \\frac{1}{ACCSL(D') - ACCM(D \u2192 D')} ,$   (4)\n$D = \\frac{1}{ACCSL(D) - ACCM(D \u2192 D')} ,$\nwhere ACCSL(D) and ACCSL(D') denote the classification accuracies on D and D', respectively. ACCM (D \u2192 D) and ACCM (D \u2192 D') denote the accuracy on D and D' pre-trained on D. In this way, higher values of D or G indicate better discriminability or generalizability of the model.\nGiven a generalizability model Mg and a discriminability model Md, Mens denotes the ensemble model of Mg and Md. We denote $N_1$ as the negative impact of Mg on the discriminability of $M_d$, and $N_2$ denotes the negative impact of $M_d$ on the generalizability of $M_g$:\n$N_1 = ACCSL(D') \u2013 ACCMens(D \u2192 D'),$   (5)\n$N_2 = ACCSSL(D \u2192 D') \u2013 ACCMens (D \u2192 D'),$\nwhere ACC Mens (D \u2192 D') denotes the accuracy on D' pre-trained by the ensemble model on D.\nEGT model framework. We develop a group-double population indirect evolutionary model Huck and Oechssler (1999); feng Ji et al. (2019); Bester and G\u00fcth (1998), where the generalizability and discriminability models present the sufficient and finite populations, respectively, of the chosen pure strategies. The strategy spaces of both players are SG = {A,U} and SD = {A,U}, where A denotes \"Adopted\" and U denotes \"Unadopted\". The indirect EGT can be expressed as follows: the combined model selects models based on individual utility maximization. Note that the utility contains both generalizability and discriminability. The system state changes along with the time, and the model utility changes accordingly, resulting in sequential and dynamical adjustments in the strategies chosen by generalizability and discriminability models. Accordingly, the decision tree for the EGT model between generalizability and discriminability is provided in Figure 4 for ease of understanding.\nBased on the above assumption, Table 1 illustrates a payoff matrix for players across different strategies. In this table, $G_1$ and $D_1$ represent the generalizability and discriminability metrics for Mg, and $G_2$ and $D_2$ correspond to Md. $w_1$ and $w_2$ indicate the weights assigned to generalizability and discriminability.\nEGT model analysis. Let x (0 \u2264 x \u2264 1) represent the proportion of discriminability models, and y (0 \u2264 y \u2264 1) represents the proportion of generalizability models which select the A strategy. On the contrary, 1-x and 1-y represent the proportion of discriminability and generalizability models selecting the U strategy, respectively. H denotes the income matrix of the generalizability model, which is defined by\n$H = \\begin{pmatrix} \\omega_1 \\cdot (G_1 - N_2) + (D_2 - N_1) & \\omega_1 \\cdot G_1 + D_1\\\\\\omega_1 \\cdot G_2 + D_2 & 0 \\end{pmatrix}.$   (6)\nWhen the generalizability model selects the strategy A, given e, x and y denoting the proportion metrics of the chosen strategy, respectively, the expected utility is defined by\n$U_{G1} = eHx^T = (1 \\ 0) \\cdot \\begin{pmatrix} \\omega_1 \\cdot (G_1 - N_2) + (D_2 - N_1)\\\\ \\omega_1 \\cdot G_2 + D_2 & 0 \\end{pmatrix},$   (7)\nand the corresponding average expected utility of the generalizability models is implemented by\n$U_G = yHx = (y \\ 1 - y) \\cdot \\begin{pmatrix} \\omega_1 \\cdot (G_1 - N_2) + (D_2 - N_1) & \\omega_1 \\cdot G_1 + D_1\\\\\\omega_1 \\cdot G_2 + D_2 & 0 \\end{pmatrix} \\cdot \\begin{pmatrix} x\\\\1-x \\end{pmatrix}.$   (8)\nAccording to the Malthusian equation Malthus (2023), the growth of A action of the generalizability model is equivalent to $U_{G1}$ \u2013 $U_G$. Specifically, when $U_{G1} > U_G$, it means that the utility of taking action A is higher than the average utility of the group, so accordingly, the proportion of this strategy will grow. Vice versa, i.e., when $U_{G1} < U_G$ or $U_{G1} = U_G$, the proportion of this strategy will decrease or remain unchanged. Therefore, the RD equation is defined as follows:\n$\\frac{dy}{dt} F(y) = = y[eHx \u2013 yHx] = y(1 \u2013 y). [\\omega_1 \\cdot G_1 + D_1 - (D_1 + \\omega_1 \\cdot G_2 + \\omega_1 \\cdot N_2 + N_1)x], $   (9)\nwhich denotes the change rate of generalizability models that select the strategy A per unit time. In detail, the factor y(1 - y) represents the current proportion change rate as related to the proportion ratios of the strategies choosing A and U, and the term $[\\omega_1G_1+D_1-(...)x]$ represents the mutual influence and competitive effects of strategy A against other strategies. The first derivative of Equation 9 represents the acceleration or deceleration of the growth rate of strategy A in generalizability models, formally expressed as:\n$\\frac{dF(y)}{dt} = (1 - 2y). [\\omega_1. G_1 + D_1 - (D_1 + \\omega_1 \\cdot G_2 + \\omega_1 \\cdot N_2 + N_1)x].$   (10)\nIt can be easily demonstrated that y = 0 or y = 1, and x = x* are the numerical solutions of the equation F(y) = dy/dt = 0, where\n$x^* = \\frac{\\omega_1G_1 + D_1}{D_1 + \\omega_1. G_2 + \\omega_1. N_2 + N_1} $   (11)\nUnder the firm condition that 0 < x < 1, based on the stability theorem Friedman (1991), we can derive that when F(x) = 0 and F'(x) \u2264 0, the proposition that x is the ESS holds. For any y, if x = x*, F(y) = 0, and F'(y) = 0 are satisfied, axis y is in a stable state. With the conditions that x < x*, F'(y)|y=0 > 0, and F'(y)|y=1 < 0, we indicate that y = 1 is the only ESS. Accordingly, if x > x*, F'(y)|y=0 < 0, and F'(y)|y=1 > 0 holds, we derive that y = 0 is the only ESS.\nAdhering to the aforementioned principle, we can obtain the income matrix K of the discriminability model and the corresponding RD equation, which are defined as follows:\n$K = \\begin{pmatrix} (G_1 - N_2) + \\omega_2 \\cdot (D_2 - N_1) & G_1 + \\omega_2 \\cdot D_1\\\\G_2+\\omega_2 \\cdot D_2 & 0 \\end{pmatrix},$   (12)\nand\n$\\frac{dx}{dt} F(x) = = x[eK^Ty \u2013 xK^Ty] = x(1 \u2212 x) \\cdot [G_2 + \\omega_2 \\cdot D_2 - (\\omega_2 \\cdot D_1 + G_2 + N_2 + \\omega_2 \\cdot N_1)y].$   (13)\nEquation 13 represents the change rate of discriminability models that select the strategy A. The first derivative of Equation 13 means the change rate of the growth rate of strategy A in discriminability models, detailed as follows:\n$\\frac{dF(x)}{dt} = (1 - 2x). [G_2 + \\omega_2 \\cdot D_2 - (\\omega_2 \\cdot D_1 + G_2 + N_2 + \\omega_2 \\cdot N_1)y],$   (14)\nwhere x = 0 or x = 1, and y = y are the numerical solutions of the equation F(x) = dx/dt = 0, and\n$y^* = \\frac{G_2 + \\omega_2. D_2}{\\omega_2 D_1 + G_2 + \\omega_2. N_1 + N_2}.$   (15)\nWith the condition that 0 \u2264 y* < 1, we obtain that for any x, if y = y*, F(x) = 0, and F\u2032(x) = 0 holds, axis x is in a stable state. If y < y*, F'(x)|x=0 > 0, and F'(x)|x=1 < 0 are satisfied, x = 1 is the only ESS. Accordingly, if y > y*, F'(x)|x=0 < 0, and F'(x)|x=1 > 0 are satisfied, x = 0 is the only ESS.\nAccording to Equation 9 and Equation 13, we obtain a 2-dim nonlinear dynamic system for the generalizability and the discriminability models, which formulates as follows:\n$\\frac{dx}{dt} =x(1 \u2212 x)[G_2 + \\omega_2 \\cdot D_2 - (\\omega_2. D_1 + G_2 + N_2 + \\omega_2. N_1)y]$\n$\\frac{dy}{dt} =y(1 \u2013 y) [\\omega_1. G_1 + D_1 - (D_1 + \\omega_1 G_2 + \\omega_1 \\cdot N_2 + N_1)x],$\nTable 2: Local stability analyses of equilibrium points.\npoint\tdet(J)\ttr(J)\tResult\n(0,0)\t+\t+\tunstable point\n(0,1)\t-\t+\tstable point\n(1,0)\t-\t+\tstable point\n(1,1)\t+\t+\tunstable point\n($x^*$,$y^*$)\t-\t0\tsaddle point\n(16)\nLocal stability analyses of equilibrium points. According to Equation 16, when dx/dt = 0 or dy/dt = 0, the system reaches an equilibrium. Concretely, the equilibrium points of the dynamic system are (0,0), (0,1), (1,0), (1,1), (x*, y*). According to Friedman's proposal, i.e., \u201cdescribe (co)evolution of population(s) with dynamics defined by differential equations\" Friedman (1991), we obtain the Jacobian matrix J of Equation 16 as follows:\n$J = \\begin{pmatrix} \\partial F(x)/\\partial x & \\partial F(x)/\\partial y\\\\\\partial F(y)/\\partial x & \\partial F(y)/\\partial y \\end{pmatrix}$   (17)\n$\\begin{pmatrix} (1-2x) [G_2 + \\omega_2. D_2 & -x(1-x) (\\omega_2. D_1 + G_2\\\\-( \\omega_2. D_1 + G_2 & +N_2 + \\omega_2. N_1) -y(1 - y). (D_1 + \\omega_1 G_2\\\\+N_2 + \\omega_2. N_1) & + \\omega_1. N_2 + N_1) (1 \u2013 2y) [\\omega_1. G_1 + D_1\\\\-(D_1 + \\omega_1 G_2 + \\omega_1. N_2 + N_1)x] \\end{pmatrix}$\nFrom Table 2, we can get results that the equilibrium points (0, 0), (1, 1) are unstable points; (0, 1), (1, 0) are stable points; (x*, y*) is a saddle point. Figure 3 demonstrates the dynamic system's phase diagram. Intuitively, we reckon that (x*, y*) can be a compromised point for the combined model to obtain the satisfactory trade-off between the generalizability and discriminability. Such a compromise point (x*, y*) can be derived by adopting the approach, i.e., Equation 11 and Equation 15. The experiments in Section 6.5 empirically prove the inference behind our behavior."}, {"title": "4.2 Chasing the Trade-off between Generalizability and Discriminability", "content": "In practice", "follows": "n$L_{ESSL} = \\alpha L_{GEN} + \\beta"}]}