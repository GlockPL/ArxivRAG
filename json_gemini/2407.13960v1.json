{"title": "Using Artificial Intelligence to Accelerate Collective Intelligence\nPolicy Synth and Smarter Crowdsourcing", "authors": ["R\u00f3bert Bjarnason", "Dane Gambrell", "Joshua Lanthier-Welch"], "abstract": "In an era characterized by rapid societal changes and complex challenges, institutions' traditional methods of problem-solving in the public\nsector are increasingly proving inadequate. In this study, we present an innovative and effective model for how institutions can use artificial\nintelligence to enable groups of people to generate effective solutions to urgent problems more efficiently. We describe a proven collective\nintelligence method, called Smarter Crowdsourcing, which is designed to channel the collective intelligence of those with expertise about\na problem into actionable solutions through crowdsourcing. Then we introduce Policy Synth, an innovative toolkit which leverages AI to\nmake the Smarter Crowdsourcing problem-solving approach both more scalable, more effective and more efficient. Policy Synth is crafted\nusing a human-centric approach, recognizing that Al is a tool to enhance human intelligence and creativity, not replace it. Based on a real-\nworld case study comparing the results of expert crowdsourcing alone with expert sourcing supported by Policy Synth Al agents, we\nconclude that Smarter Crowdsourcing with Policy Synth presents an effective model for integrating the collective wisdom of human\nexperts and the computational power of AI to enhance and scale up public problem-solving processes.\nThe potential for artificial intelligence to enhance the performance of groups of people has been a topic of great interest among scholars\nof collective intelligence. Though many AI toolkits exist, they too often are not fitted to the needs of institutions and policymakers. While\nmany existing approaches view Al as a tool to make crowdsourcing and deliberative processes better and more efficient, Policy Synth\ngoes a step further, recognizing that AI can also be used to synthesize the findings from engagements together with research to develop\nevidence-based solutions and policies. This study contributes significantly to the fields of collective intelligence, public problem-solving,\nand AI. The study offers practical tools and insights for institutions looking to engage communities effectively in addressing urgent societal\nchallenges.", "sections": [{"title": "INTRODUCTION", "content": "In this study, we introduce a set of practical tools and methods that institutions can use to engage groups in solving public\nproblems using a combination of artificial intelligence (AI) and collective intelligence (CI).\nFirst, we describe Smarter Crowdsourcing a proven approach that institutions are already using to engage the\ncollective intelligence of human experts in efforts to solve public problems. Second, we introduce a new toolkit, called\nPolicy Synth, which leverages artificial intelligence techniques to automate and scale up the Smarter Crowdsourcing\nmethod. By integrating AI capabilities into this process, Policy Synth aims to make the Smarter Crowdsourcing method\nmore efficient, effective, and scalable, enabling institutions to develop solutions more rapidly than would be possible with\nhuman intelligence alone.\nFinally, we describe a case study comparing solutions to a complex policy problem generated using artificial\nintelligence to those developed through expert crowdsourcing. The case study demonstrates how generative Al can make\nparticipatory problem-solving with human participants more scalable and more effective because the tools make it possible\nto translate ideas into implementable proposals more quickly than human participation alone.\nThis study contributes to the body of research around collective intelligence for public problem-solving [Gambrell and\nNoveck 2020] as well as the use of AI for public good."}, {"title": "THE NEED FOR RAPID AND EFFICIENT PUBLIC PROBLEM-SOLVING", "content": "From climate change to economic instability and social inequality, to public health crises, policymakers and institutions\nface a range of urgent challenges. The ability to quickly identify, understand, and address these problems is crucial for\nmaintaining societal stability and fostering sustainable progress. Yet, the mechanisms that institutions use to understand\nand address these challenges too often fail to develop and implement effective solutions at scale [Noveck 2021] [Mulgan\n2017].\nThe rapid pace of societal advancement and technological change is deepening this challenge. Public institutions now\nwork in increasingly complex and uncertain environments, with the world's growing interconnectivity making our\nchallenges larger and more complex. The failure to develop effective solutions and create meaningful opportunities for\ncommunities to participate in solving problems may be contributing to a lack of trust in government [Kumagai and Iorio\n2020]. In countries around the world, there is a broadly-held belief among members of the public that participating in\nelections - the most direct opportunity many residents have to influence public policy - simply does not matter [Van\nReybrouck 2018]. There is a risk that the democratic backsliding that has been observed in the United States and other\ndemocracies will accelerate as people continue to see their governments as ineffective at solving problems that matter to\nthem [Light 2014].\nFortunately, institutions around the world are experimenting with more participatory methods to solve problems, and\nin particular, to meaningfully incorporate the collective intelligence of communities and subject matter experts into their\nproblem-solving processes. These include experiments that engage groups in lawmaking and policymaking at all levels of\ngovernment [Noveck, et al. 2020] as well as efforts to institutionalize large-scale collaboration, crowdsourcing, and co-\ncreation projects as part of institutions' formal problem-solving and decisionmaking processes [Ryan, et al. 2020]. As we\nwill show, the rapid advance in technology\nmost notably, the proliferation of generative AI tools presents great\nopportunities to further scale these efforts.\nIn the following section, we elaborate on one collective intelligence method \u2013 Smarter Crowdsourcing - that we have\nused to aid institutions in addressing problems and discuss the challenges to efficiently using collective intelligence for\nproblem solving and then address how generative AI is helping to make this process more efficient and effective."}, {"title": "SMARTER CROWDSOURCING: RAPIDLY CROWDSOURCING EXPERTISE", "content": "Smarter Crowdsourcing is a problem-solving method that leverages the collective intelligence of diverse experts to identify\nsolutions to urgent public problems in support of governments and philanthropic organizations [Dinesh 2023]. The process\nmarries the diversity and agility of crowdsourcing with curation, to find and bring together those with relevant know-how\nand practical experience, in a format designed to produce the most innovative solutions to challenging public problems.\nSmarter Crowdsourcing was developed and tested for the first time in 2015 as part of an effort to advise the\ngovernment of Quito, Ecuador about how to prepare for the eruption of the Cotopaxi Volcano. After this pilot, the\nmethodology was further refined through a series of projects with other institutions. Following the Cotopaxi use case, the\nSmarter Crowdsourcing has been used seven additional times to support governments and philanthropic organizations:\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\n\u2022\nZika (2016): Explored ways to address the causes of Zika virus and other mosquito-borne diseases in support\nof the Inter-American Development Bank and partner governments in four countries in Latin America.\nAnti-Corruption (2017): Worked with the Mexican government and civil society institutions to explore\nsolutions to the problem of corruption in Mexico.\nCoronavirus (2020): Supported the Inter-American Development Bank and its partner governments in Latin\nAmerica and the Caribbean to source solutions to problems arising from the COVID-19 pandemic.\nEducation (2020): Developed solutions to address the challenge of equitably identifying and measuring the\nnon-academic skills young people need to succeed to inform the Walton Family Foundation's funding\nstrategy.\nExperiential Learning (2021): Explored innovations in equity-centered hands-on learning initiatives in\nsupport of Northeastern University.\nModernization of Congress (2021): Developed recommendations on evidence-based lawmaking in support\nof the US House Select Committee on the Modernization of Congress.\nCountering Election Subversion (2023): Developed recommendations for solutions philanthropy could\nsupport in order to counter efforts to undermine or cast doubt upon the integrity of U.S. elections in support\nof Democracy Fund Voice.\nIn each case, the process resulted in a set of practical and innovative solutions tailored to the partner institution's needs\nand priorities, in terms of format as well as content. For example, the Smarter Crowdsourcing: Education initiative\ndescribed below generated 22 specific funding opportunities designed to have real-world positive impact, each one with a\nconcrete action plan. These recommendations guided the strategic direction of the Walton Family Foundation's\ngrantmaking portfolio in the area of non-academic skills assessment.\nSmarter Crowdsourcing was developed well before the use of generative AI tools became widespread, and thus was\noriginally conceptualized as a process to rapidly crowdsource policy solutions from human experts. As shown in the use\ncases described in this section, combining this traditional crowdsourcing approach with an Al-driven innovation process\n(mediated by Policy Synth) results in a problem-solving approach that is both more scalable and more effective. We\ndescribe the traditional approach in this section, then introduce Policy Synth and explain the value of the augmented\nworkflow that the AI-based toolkit enables.\nIn 2020, we used the Smarter Crowdsourcing method to advise the Walton Family Foundation and the Bill & Melinda\nGates Foundation \u2013 philanthropies which fund education projects in the United States \u2013 about their grantmaking strategy\nin the area of non-academic skills assessment in K-12 schools. Without generative AI tools, the process used the following\nthree steps that are common to all of our Smarter Crowdsourcing experiments:"}, {"title": "Selecting and Defining the Problem", "content": "Based on a literature review and interviews with subject-matter experts, we developed a \"Problem Catalog.\" The Catalog\nidentifies a series of problems that comprise the larger challenge of how to best assess non-academic skills, root causes,\nand example solutions. The foundation selected a subset of these problems to prioritize. Each problem became the focus\nof an online convening. Conducting interviews at this stage allows us to gather insights from the collective intelligence of\nhalf a dozen (sometimes more) experts, allowing us to understand the \"big picture\" of the problem at hand and what\npotential solutions might look like. However, identifying, interviewing and extracting learnings is time-consuming and the\ndiversity of perspectives is limited."}, {"title": "Convening Experts to Identify Solutions", "content": "For each problem area selected by the foundation, we curated a list of 80-100 individuals who are experts, including\ncredentialed experts as well as those with lived experience. These experts were identified through an extensive search of\nrelevant literature as well as through recommendations from others working in the field.\nFor each problem identified by the foundation, we convened a 2-hour, moderated advisory session, using the\nvideoconferencing platform Zoom, where the goal was to identify concrete and specific solutions. Between 25 and 35\nexperts participated in each convening; the group was curated so as to represent a diverse group of perspectives, including\nexperts in academic curriculum development, psychometrics, career skills pathways, community engagement, and related\nfields. The conversations surfaced existing solutions as well as ideas for new projects and programs designed to address\nthe problems identified. We ran six convenings, engaging more than 150 experts from six continents. Following each\nconversation, we spent 5-7 days creating a transcript based on the Zoom recording, writing notes, compiling resources\nshared, and synthesizing learnings, and then developed findings based on the participants' input.\nEngaging such large groups in structured deliberations offers the opportunity to rapidly gather insights, opinions, and\nnew ideas for solutions from experts working on the problems at hand as well as those working in related domains. But\nthere are also many design challenges involved in convening these participatory processes. There is the challenge of\nensuring that the group convened has the expertise needed to generate on-topic and high-quality ideas. There is also a need\nto ensure that the group is diverse and reflects a range of identities, backgrounds and experiences. The conversation must\nbe structured and facilitated in such a way that all participants are encouraged and provided the opportunity to contribute\nmeaningfully to the deliberation. Finally, there are logistical challenges, namely, the large amount of time and labor\nrequired to schedule, plan, create the inputs, moderate, and co-create the outputs from these large-group conversations."}, {"title": "Converting Insights into Action", "content": "Following the online convenings, the foundation selected a subset of solutions for further exploration. We conducted\nfollow-up surveys, interviews, and research to create a set of recommendations for how to put each solution into action,\nincluding costs estimates, budgets, and metrics for evaluation. This step is crucial to ensure that the collective wisdom of\nthe experts is channeled into outputs that are in the form and format that allows the partnering institution to take action\nupon them. However, converting the insights to action can bring challenges. In past projects, it has taken 3-6 months of\nresearch to return final recommendations to the partnering institution. Conducting surveys and interviews and translating\nthe findings from those engagements into detailed memos and reports is simply a laborious and time-consuming process."}, {"title": "COMBINING AI AND CI TO SOLVE PROBLEMS COLLABORATIVELY AT SCALE", "content": "As shown in the steps above, the typical expert-informed problem-solving process is both time-consuming and labor-\nintensive. While the Smarter Crowdsourcing approach is designed for efficiency, there is a significant workload involved\nin conducting research about problems and solutions, curating and convening experts, and synthesizing solutions.\nWith the release of GPT-4, new possibilities have emerged for leveraging AI and CI together to solve problems more\neffectively. GPT-4's advanced language understanding, generation capabilities, and ability to process and analyze vast\namounts of data have opened up new avenues for integrating AI into collective problem-solving processes. By harnessing\nthe power of GPT-4 and similar Al models, we can enhance the capacity of human groups to generate ideas, evaluate\nsolutions, and make informed decisions.\nAs described in the following section, Policy Synth helps to solve problems more rapidly by automating many of the\nresearch and writing tasks, while providing opportunities for the human guides to provide input throughout the process to\nensure the outputs are aligned with the institutions' needs."}, {"title": "WHAT IS POLICY SYNTH?", "content": "Policy Synth is a toolkit designed to automate and scale up the Smarter Crowdsourcing method by seamlessly integrating\ncollective and artificial intelligence. It builds upon the proven success of Smarter Crowdsourcing, which engages the\ncollective intelligence of human experts to solve public problems, by incorporating AI capabilities to enhance the process.\nPolicy Synth leverages artificial intelligence techniques and genetic algorithms to make the Smarter Crowdsourcing\nmethod more efficient, effective, and scalable, enabling institutions to develop solutions more rapidly than would be\npossible with human intelligence alone. The toolkit is built as a JavaScript class-based library, providing a framework for\ncreating Al agent logic flows, application programming interfaces (APIs), and state-of-the-art real-time AI-focused web\napplications, all designed to streamline and optimize the problem-solving process.\nOur goal in creating Policy Synth is to provide institutions access to a set of easy-to-use tools and methods that will\nincrease their ability to solve urgent problems and provide a model process for how institutions can meaningfully engage\ncommunities in the problem-solving process."}, {"title": "SMARTER CROWDSOURCING WITH POLICY SYNTH", "content": "The Smarter Crowdsourcing process is designed to channel the collective intelligence of those with expertise about a\nproblem into actionable solutions through curation and convening. In this section, we outline how artificial intelligence\ncan accelerate this process, helping us generate more and better solutions, faster.\nAs described above, Policy Synth is an AI-based toolkit that accelerates and improves the process of searching for,\nevolving, ranking, and helping to prioritize among both problems and solutions. Policy Synth augments the stages Smarter\nCrowdsourcing process as follows:"}, {"title": "Selecting and Defining the Problem", "content": "Policy Synth accelerates the problem definition phase by automating much of the process of searching for and prioritizing\namong constituent problems.\nThe tool is first populated with a \"problem statement\" a short paragraph that describes the challenge that the tool is\ntasked with \"solving.\" The platform will then use AI to automatically: 1) Create a set of queries - questions or phrases that\nit will plug into a search engine to search for root causes of the problem, 2) Generate a list of problems based on the search\nof thousands of online sources, and 3) Assign each problem a rating and rank them. The problems are ranked by a set of\ncriteria specified by the user, combined with Elo scoring (See detailed description of the ranking process in the section of\nthis study on \"Elo Pairwise Voting.\u201d). Once the search and ranking are complete, the tool delivers a list of problems along\nwith the web pages that were scanned in order to identify them.\nArtificial intelligence allows us to automatically search a wider range of sources than would be possible through\ntraditional research methods, and to conduct this search more rapidly."}, {"title": "Convening Experts to Identify Solutions", "content": "Policy Synth augments the process of identifying solutions, both by aiding in the process of identifying experts to invite to\nparticipate in the online convenings, and by automatically developing a separate set of solutions in parallel.\nFirst, Policy Synth can be used to automatically generate a list of solutions in the problem areas of greatest priority.\nThe tool will search the web for solutions that respond to the problems identified previously. After generating hundreds of\nsolutions, Policy Synth will remove any duplicate solutions and filter out the solutions that are not viable. Next, the tool\nwill evolve the solutions using a genetic algorithm. The software combines multiple solutions into one, and then tests how\nwell the new version of the solution fits the problem to see if the improvement should be adopted or rejected. After multiple\nrounds of crossovers, mutations and ranking, Policy Synth produces a final list of approaches tailored to addressing the\nproblem. (See detailed description of the genetic algorithm in the \"Evolutionary Algorithm\" section of this study)\nThis process produces a list of solutions for each identified problem, in an easily readable format with a list of pros and\ncons for each solution. Each solution is accompanied by a visual illustration from Dalle-3 or other Al image-generation\ntools.\nSecond, the toolkit's search functionalities can also accelerate the process of identifying experts to engage in the process\nof identifying solutions. The list of sources returned by the online searches for problems and solutions \u2013 which may include\nonline journal articles, white papers, news reports, and items from other types of online publications can be useful for\nidentifying those with credentialed expertise and live experience in each problem area, included those who have developed\nor proposed solutions. For example, the authors of those sources, those cited in reference pages, or mentioned as experts\nin the text could be included in the list of experts who are invited to contribute solutions. Thus, Policy Synth can help to\nsearch for experts more quickly and to cast a wider net compared to manual online searches, yielding more diverse\nexpertise."}, {"title": "Converting Insights into Action", "content": "Finally, Policy Synth augments the process of converting ideas into actionable recommendations. Using seed ideas (for\nexample, the solutions identified in the previous step, or solutions identified by the human experts), the toolkit will generate\npolicy proposals based on an online search, then rank and evolve the proposals using a genetic algorithm. This process\nleverages large-scale web research to search for policy evidence across 22 categories, which is then provided in an easy-"}, {"title": "Aligning Partner Institutions' Priorities with Communities' Expertise", "content": "In line with the need to tailor the outputs of the problem-solving process to institutions' needs, each stage of Policy Synth\nis highly customizable.\nThe instructions used to search for and rank the problems, solutions, or policy proposals are customizable based on the\npriorities, constraints, and desires of each institutional partner. For example, the instructions could be tailored to prioritize\nproblems that disproportionately impact women or African Americans, to encourage solutions that can be implemented\nquickly, or to favor policy proposals that can be implemented within the partner institution's jurisdiction.\nThe outputs produced at each stage can also be manually reviewed and edited. For example, if the system identifies a\nproblem that the partner institution deems outside of its mandate, the problem can be deactivated so that it is not considered\nwhen solutions are identified.\nWhile the experiment described in this study focuses on Policy Synth's potential to enhance problem-solving efforts\ninvolving groups of experts, the process can be augmented to incorporate input from other groups. The toolkit can be used\nalongside online engagement tools to combine the collective intelligence of multiple groups. For example, All Our Ideas\n- the \"Wiki Survey\" tool described in the Elo Ranking and Pairwise Voting section of this study \u2013 could be used to engage\ncommunities in ranking and prioritizing among problems generated during the Selecting and Defining the Problem section\nof the problem-solving process. Or, the open source Your Priorities platform could be leveraged to engage communities in\na large-scale online dialogue about which solutions to prioritize for implementation. The ability to integrate community\ninput is crucial to ensure that the solutions developed and supported by partnering institutions respond to real and urgent\nproblems that communities experience."}, {"title": "Novelty of Approach", "content": "Combining artificial intelligence and collective intelligence in itself is not new; numerous toolkits have been developed\nwhich aim to combine CI and Al processes to rapidly develop solutions to public problems [Baeck and Berditchevskaia.\n2020].\nIn existing approaches, AI is largely viewed as a tool to enhance collective intelligence processes, such as dialogues,\ndeliberations, and crowdsourcing efforts. There are several existing platforms which leverage Al to make sense of and\ndraw insights from large volumes of data to gauge communities' opinions on a given topic. These include toolkits designed\nto aid in analyzing and drawing findings from large-scale online engagements with communities [Rahim, et al. 2024] as\nwell as platforms to synthesize learnings from rich in-person dialogues [Local Voices Network. 2022]. There is also a set\nof tools and approaches in which Al is used as a tool to facilitate large-scale online deliberations and dialogues [Konya,\net al. 2023] [Mendes, et al. 2019] [Moats and Tseng. 2023] [Rosenberg, et al. 2023]. In various ways, these approaches\nendeavor to use AI to improve the outcomes of engagements with groups, whether by enabling engagement with larger\ngroups, improving the efficiency or quality of analysis, or by enabling more coherent or higher quality deliberations and\ncollective dialogues.\nWhile recognizing the value of these methods, Policy Synth takes a different approach. In addition to being a practical\ntool for policymakers, Policy Synth serves as a demonstration how AI can be used to synthesize the learnings from\ndeliberations (and other types of CI processes) together with findings from research to develop evidence-based policy\nsolutions systematically. Policy Synth is not intended as a replacement for AI tools that improve or scale up engagement"}, {"title": "COMPARATIVE STUDY OF AI-GENERATED AND EXPERT-GENERATED SOLUTIONS", "content": "To test how the outputs from the Smarter Crowdsourcing process carried out without generative AI tools compared to\nthose generated using the AI-based Policy Synth toolkit, we conducted a comparative analysis of these two approaches.\nThe goal of this pilot project was to 1) test whether this approach had the potential to truly add value to the Smarter\nCrowdsourcing process, 2) to identify shortcomings and challenges in the approach, and 3) to lay the groundwork for\nfurther, more robust experimentation. This section describes the methodology used and the outputs of this case study."}, {"title": "Comparative Study Design", "content": "In 2023, we worked with another large philanthropy to use the Smarter Crowdsourcing method to identify strategies to\ncounter efforts to undermine U.S. elections through sabotage and election denial [Noveck. 2024].\nWe first created a Problem Catalog outlining 12 problems comprising the large challenge of election violence and\ndenial. We convened online convenings to crowdsource solutions to three of these problems. The philanthropy then\nselected the two highest priority problem areas for further research. The first area, Misuse of the Legal System, aimed to\naddress the malicious use of litigation and freedom of information (FOI) requests to disrupt election administration and\ncast doubt upon the validity of election results. The second area, Election-Related Violence, aimed to surface strategies to\nmitigate the effectiveness of political violence targeting elections. Through online convenings with experts, we developed\n14 solutions to the Misuse of the Legal System problem and 13 solutions to the Election-Related Violence problem.\nIn parallel, we used Policy Synth to search for and generate a list of problems related to election violence and denial.\nThe tool was then seeded with the two priority problems mentioned above and used to generate solutions to the problems\nof Misuse of the Legal System and Election-Related Violence."}, {"title": "Rating Methodology", "content": "To evaluate and compare recommendations, we developed an LLM agent to assess the alignment between solutions\ngenerated by human experts and those produced by the Policy Synth process. By examining the similarity between each\nsolution from Policy Synth and the human-generated recommendations, we calculated a percentage similarity for Policy\nSynth solutions after 15 generations of evolution by the genetic algorithm. This comparison was conducted for each of the\nseven sub-problems. The analysis and results for two of these problems \u2013 Election-Related Violence and Misuse of the\nLegal System are described below. (See appendix for links to the results for all seven sub-problems and the rating\nsoftware is available on GitHub in the Policy Synth repository)."}, {"title": "GPT-4 Rating \"System\" Instructions", "content": "1. You are an expert in analyzing how well a solution matches requirements\n2. Compare the key points in each requirement with the key points in the solution\n3. If solution does more than required then that is fine\n4. Always and only output the following JSON format: [ { requirementTitle, solutionCoversPercent } ]"}, {"title": "Example input to the LLM rating agent from one comparison:", "content": "Human \"Requirement\"/Recommendation: \"Invest in civic engagement projects that get citizens more involved in\nelections, helping to educate and build trust in the electoral process.\"\nEvolved AI Solution initially sourced through automated web research: \"Philanthropic organizations should invest in\ninitiatives that build trust in the electoral process. This includes supporting voter education campaigns that emphasize the\nimportance of peaceful elections, the measures in place to ensure election integrity, and the consequences of election-\nrelated violence. Funding research to understand the factors that undermine trust in elections and developing strategies to\naddress these issues is also crucial.\"\nGPT-4 Rating: 100% (In other words, the AI solution includes 100% of the core idea of the human recommendation. This\nis meant to evaluate the meaning or sentiment behind the recommendation, not whether the word choice or phrasing is an\nexact match.)"}, {"title": "Example Ratings from Election-Related Violence topic", "content": "Problem statement: \"Election-Related Violence: A free, fair, and vibrant democracy depends on the ability to hold\npeaceful elections, including running for office, casting, counting and certifying votes free of violence and intimidation.\nYet, during recent election cycles, extremist groups and individuals have used violent acts and threats to intimidate political\nopponents, disrupt electoral processes, and cast doubt on the fairness and legitimacy of election results.\""}, {"title": "Example Ratings from Misuse of Legal System topic", "content": "Problem statement: \"Misuse of the Legal System: In recent elections, saboteurs have misused the administrative and legal\nsystems in a coordinated effort to obstruct election administration and sow doubt in the outcomes of fair elections in the\nminds of the public.\""}, {"title": "Results and Discussion", "content": "The comparative analysis showed that there was a high level of similarity between the Policy Synth solutions, sourced via\nlarge scale automated web research and the crowdsourced expert solutions. Among the 14 crowdsourced recommendations"}, {"title": "Limitations and Future Research", "content": "It should be noted that the comparative analysis was not intended as a robust, scientific experiment. Rather, it was\nconceived as a pilot test case with the goal of informing future development work and higher-quality experimentation.\nOne key limitation is that, due to time and capacity constraints, the comparative analysis relied on LLMs to evaluate\nthe similarity of the expert and AI-generated solutions. While there is some debate over to what extent LLMs are capable\nof semantic understanding, it is clear that significant shortcomings remain when it comes to LLMs' ability to understand\nlogic and meaning in context, as is required to engage in complex comparisons [Wu, et al. 2024] [Yan, et al. 2024].\nFurther, basing the evaluation primarily on the number of similar statements does not capture the whole picture. As\ndescribed above, there may be value in both statements that are similar to those generated by experts (as validation for the\nAI approach) and those that are dissimilar (for assessing the novelty or added value of the AI approach). This nuance may\nnot be well-captured by our evaluation metrics.\nWe plan to conduct a future experiment, the design of which will address these limitations. The experiment will leverage\nhuman reviewers, in addition to LLMs, to evaluate the solutions.\nWe will also compare the similarity between the LLM evaluations of the solutions and the human evaluations to better\nunderstand how well LLMs can provide this role at scale. We will also develop more robust evaluation metrics that will\nbe used to score the machine-generated ideas rather than simply comparing them to human-generated solutions while also\nevaluating the quality of the Al system."}, {"title": "TECHNICAL DESCRIPTION OF POLICY SYNTH", "content": "In this section, we outline the design considerations that went into the platform's architecture. We also explain some of\nPolicy Synth's key technical components - including AI agents, Elo scoring, pairwise voting, and genetic algorithms \u2013 and\nhow they function within the platform."}, {"title": "Inspiration for Technical Design", "content": "The technical design of the Policy Synth toolkit was inspired by our 35+ years of experience in building Al systems,\nincluding very early chatbots and high-profile AI driven video games, and insights from many directions.\nOne source of technical inspiration was the paper \"Language Models are Weak Learners,\" [Manikandan, et al. 2023]\nwhich highlighted the imperfections of AI models that continue to make errors, as AI models have done from the start.\nHowever, there have always been strategies to mitigate the fact that Al models are \"weak learners.\" This insight has been\ncrucial, steering us towards strategies that enhance the performance of current generation AI tools. These strategies include\nalways simplifying tasks for large language models (LLMs) as much as possible, breaking complex \"thoughts\" into simpler\n\"thoughts\", employing pairwise ranking for efficient selection, and incorporating review loops for iterative refinement.\nAnother inspiration was a thought-provoking piece in The Economist, \"It's not just a fiscal fiasco: graying economies\nalso innovate less,\" which underlined the importance of \"fluid intelligence\" a concept in psychology which describes\n\"the general ability to reason, to flexibly engage with the world, to recognize patterns, and to solve problems in a manner"}, {"title": "About Al Agents", "content": "Al agents are a key component of Policy Synth's approach to System 2 thinking (described below). In the context of\ncomputational systems, AI agents are autonomous or semi-autonomous entities that interact with digital environments to\nachieve specific goals or tasks. These agents can range from simple rule-based algorithms to complex systems like Large\nLanguage Models (LLMs), capable of processing and generating text and performing simple reasoning. The essence of AI\nagents lies in their ability to perceive their environment through data, make decisions based on this data, and act upon these\ndecisions to fulfill predefined objectives. In Policy Synth AI agents are used extensively for different tasks."}, {"title": "Fast and Slow Thinking", "content": "Fast (System 1) and Slow (System 2) thinking, terms popularized by psychologist Daniel Kahneman, offer a useful\nframework for understanding how AI, particularly LLMs like GPT-4, operates [Kahneman. 2013]. LLMs are often likened\nto System 1 thinking [Hagendorff, et al. 2023] where cognition occurs almost instantaneously, without deliberate,"}, {"title": "Multi-Scale Policy Synth Agents", "content": "Policy Synth employs an innovative approach through the integration of multi-scale System 2 AI agent thinking processes.\nThis approach is grounded in the utilization of numerous straightforward System 1 LLM agents/prompts, which are\ncarefully organized into workflows that operate at various scales.\nWithin this framework, the Text Compression Agent serves as a straightforward example of an agent deployed (see\ndiagram below). This agent takes text in and outputs the same text with as few words as possible while still keeping all\ndetail, nuance and tone. This agent is supported by three parallel Validation Agents designed to ensure the output's\nCorrectness, Completeness, and to detect Hallucinations. These agents operate within a feedback loop, critically evaluating\nand refining the compression prompt's output to correct errors, which are present in approximately 10% of the main Text\nCompression Agents outputs in this specific and complex task.\nThe integration of these validation processes enhances the reliability and accuracy of the agent's output, illustrating a\nkey step in the process of data refinement. Furthermore, the Text Compression Agent is not isolated but is part of a larger\nsystem, where it can contribute to more complex agents focused on tasks such as data ingestion or custom data cleanup\nworkflows."}, {"title": "Large Scale Automated Web Research", "content": "Policy Synth enhances the policymaking process through Al-driven large-scale automated web research with Google or\nBing search, then scanning thousands of websites with LLMs. Root causes discovery is a key example application. Those\nautomated web searchers and scanning are versatile enough to explore any topic, encompassing various types of content\nand engaging multiple Al agents exploring separately highly detailed aspects of the data."}, {"title": "Elo Scoring and Pairwise Voting", "content": "To rate and rank-order problems and solutions, Policy Synth uses a process known as \"Elo ranking.\"\nOriginally developed for assessing the relative skills of chess players, Elo ranking is an algorithmic approach to rate\nand rank a list of options or candidates. In this method, options or candidates are treated as competitors in a series of\npairwise contests, where voters express a preference between each pair. The Elo algorithm then adjusts the ratings, or\n\"scores,\" of these options based on the outcomes of these contests, taking into account the relative ratings of the options at\nthe time of the vote. The magnitude of rating adjustment depends on the expected versus actual outcome, allowing the\nsystem to dynamically rank options in an efficient way."}, {"title": "Evolutionary Algorithm (Genetic Algorithm)", "content": "Evolutionary algorithms, including genetic algorithms, are a family of algorithms inspired by the principles of natural\nselection and genetics, used to solve optimization and search problems within computer science. These algorithms work\nby mimicking the process of natural evolution, employing mechanisms such as selection, mutation, and crossover\n(recombination) to evolve a population of candidate solutions towards an optimal solution over generations. Initially, a\ndiverse population of possible solutions is generated. Through the iterative process of selecting the fittest individuals based\\"}]}