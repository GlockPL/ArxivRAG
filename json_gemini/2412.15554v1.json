{"title": "Architecture-Aware Learning Curve Extrapolation via Graph Ordinary Differential Equation", "authors": ["Yanna Ding", "Zijie Huang", "Xiao Shou", "Yihang Guo", "Yizhou Sun", "Jianxi Gao"], "abstract": "Learning curve extrapolation predicts neural network performance from early training epochs and has been applied to accelerate AutoML, facilitating hyperparameter tuning and neural architecture search. However, existing methods typically model the evolution of learning curves in isolation, neglecting the impact of neural network (NN) architectures, which influence the loss landscape and learning trajectories. In this work, we explore whether incorporating neural network architecture improves learning curve modeling and how to effectively integrate this architectural information. Motivated by the dynamical system view of optimization, we propose a novel architecture-aware neural differential equation model to forecast learning curves continuously. We empirically demonstrate its ability to capture the general trend of fluctuating learning curves while quantifying uncertainty through variational parameters. Our model outperforms current state-of-the-art learning curve extrapolation methods and pure time-series modeling approaches for both MLP and CNN-based learning curves. Additionally, we explore the applicability of our method in Neural Architecture Search scenarios, such as training configuration ranking.", "sections": [{"title": "I. INTRODUCTION", "content": "Training neural architectures is a resource-intensive endeavor, often demanding considerable computational power and time. Researchers have developed various methodologies to predict the performance of neural networks early in the training process using learning curve data. Some methods Domhan et al. (2015); Gargiani et al. (2019); Adriaensen et al. (2023) apply Bayesian inference to project these curves forward, while others employ time-series prediction techniques, such as LSTM networks. Despite their effectiveness, these approaches (Swersky et al., 2014; Baker et al., 2017) typically overlook the architectural features of networks, missing out on crucial insights that could be derived from the models' topology.\nOn another front, architecture-based predictive models have been developed to forecast network performance based purely on NN structures Shi et al. (2019); Friede et al. (2019); Wen et al. (2020); Tang et al. (2020); Yan et al. (2020); Ning et al. (2020); Xu et al. (2019); Siems et al. (2020). These models facilitate a deeper understanding of the relationship between architectures and their performance. However, they are limited in their ability to predict precise learning curve values at specific epochs and struggle to capture the variability in performance that a single architecture can exhibit under diverse training conditions.\nMoreover, there is a growing interest in conceptualizing the optimization process during NN training as a dynamical system. By considering the step size in gradient descent as approaching zero, it is possible to formulate an ordinary differential equation for the model parameters Su et al. (2016); Zhang et al. (2024); Maskan et al. (2023). This perspective is useful for analyzing the convergence of different optimization algorithms, especially for convex problems. Building on this foundational idea, we propose an innovative approach that models the evolution of learning curves using neural differential equations Chen et al. (2018), tailored for a inductive setting where the trained learning curve predictor is applicable to new learning curves generated under various training configurations, such as different architectures, batch sizes, and learning rates. This approach leverages recent advancements in differential equations to provide a flexible framework capable of handling the complexities of modern neural training processes.\nOur method merges the structural attributes of neural architectures with the dynamic nature of learning curves. We utilize a seq2seq variational autoencoder framework to analyze the initial stages of a learning curve and predict its future progression. This predictive capability is further enhanced by an architecture-aware component that produces a graph-level embedding from the architecture's topology, employing techniques like Graph Convolutional Networks (GCN) Kipf and Welling (2016) and Differentiable Pooling Ying et al. (2018). This integration not only improves the accuracy of learning curve extrapolations compared to existing methods but also significantly facilitates model ranking, potentially leading to more efficient use of computational resources, accelerated experimentation cycles, and faster progress in the field of machine learning.\nOur contributions are twofold:\n\u2022 We introduce an architecture-aware, dynamical system-based approach to model learning curves from different architectures for a given source task. Our model can predict the learning curves of unseen architectures using only a few observed epochs.\n\u2022 Our method improves model ranking by analyzing just a limited number of learning curve epochs, such as 10. This approach speeds up model selection by 20 times compared to traditional full-cycle stochastic gradient descent training."}, {"title": "II. RELATED WORK", "content": "a) Learning curve extrapolation.: Previous studies have explored learning curve prediction through diverse approaches Swersky et al. (2014); Domhan et al. (2015); Baker et al. (2017); Chandrashekaran and Lane (2017); Gargiani et al. (2019); Ru et al. (2021); Klein et al. (2022); Adriaensen et al. (2023). A line of work has focused on Bayesian frameworks. Specifically, Domhan et al. (2015) utilized a weighted combination of functions to predict mean future validation accuracy and facilitate early termination of underperforming training runs. Building on this, Chandrashekaran and Lane (2017) extended basis function extrapolation by incorporating historical learning curves from previous training runs, while Klein et al. (2022) proposed a Bayesian neural network to flexibly model learning curves, removing the constraint that each epoch must outperform the previous one and thereby reducing instability in predictions. More recently, Adriaensen et al. (2023) applied a prior-data-fitted network training paradigm to enhance sampling efficiency from the posterior distribution of learning curves. Despite these advancements, existing methods overlook the role of architectural design, whereas our work explicitly incorporates this information to better model and understand the evolution of learning curves.\nArchitecture-based performance prediction. Advances in Graph Neural Networks (GNNs) have led to innovative methods for predicting the performance of neural network architectures Shi et al. (2019); Friede et al. (2019); Wen et al. (2020); Tang et al. (2020); Yan et al. (2020); Ning et al. (2020); Xu et al. (2019); Siems et al. (2020). In exploring unsupervised learning strategies, Yan et al. Yan et al. (2020) used architecture embeddings created by a pre-trained model to feed a Gaussian Process model for performance prediction. These studies often incorporate foundational GNN models such as the GCN Kipf and Welling (2016) and the Graph Isomorphism Network (GIN) Xu et al. (2018) to effectively process input architectures. Various training objectives have been considered, including Mean Squared Error (MSE) Shi et al. (2019); Wen et al. (2020); Ning et al. (2020); Tang et al. (2020), graph reconstruction loss Friede et al. (2019); Tang et al. (2020); Yan et al. (2020), and pair-wise ranking loss Ning et al. (2020); Xu et al. (2019), highlights the diverse methods aimed at improving the prediction of architecture"}, {"title": "III. METHOD", "content": "A. Problem Formulation\nLearning curves, such as train or test loss, are generated by optimizing a neural network on various source tasks including adult income classification, image classification, and housing price regression Vanschoren et al. (2014). Our goal is to train a single latent ODE model capable of extrapolating learning curves for a given source task across different architectures. The model infers full learning curves of length m using only the initial n epochs $Y_1,..., Y_n$ and the corresponding network architecture, denoted as G.\nOur approach transforms the conventional discrete optimization process into a continuous domain, operating within the continuous time interval [0, Tmax], where 0 marks the start and Tmax corresponds to the last epoch m. The time for each epoch, $t_i$, is defined as $\\frac{iT_{max}}{m}$ with $\u2206t = T_{max}/m$.\nWe employ a seq2seq variational autoencoder framework Rubanova et al. (2019); Huang et al. (2020, 2021), where a sequence encoder parameterized by $\u03c6$ processes the early part of the learning curve to estimate the variational parameters of the posterior distribution $q_\u03c6$, which determines the latent state at the start of the prediction period, represented by $z_{n+1} \u2208 R^D$. A numerical solver then integrates an ODE function, denoted as f : $R^D \u2192 R^D$, governing this latent state, starting from the initial condition $z_{n+1}$. Each subsequent latent state $z_i$ is decoded independently to predict the output $\u0177_i$ for i > n. This process is mathematically represented as follows:\n$z_{n+1} \\sim q_\u03c6(z_{n+1}|{Y_i, t_i}_{i=1}^n)$    (1)\n$z_{n+1},..., z_m = ODESolve(f, z_{n+1}, (t_{n+1},..., t_m), G)$    (2)\n$\u0177_i = Decoder_\u03b8(z_i) \\quad for \\quad i>n$    (3)\nHere ODESolve(\u00b7) simulates the ODE function f(.) to compute the latent states at time steps $t_i$ (i > n + 1), given initial condition $z_{n+1}$ and the neural architecture G. Decoder(\u00b7) is a neural network mapping $z_i$ to the corresponding output $\u0177_i$. Since the model has access to only partial information about the optimization process, it cannot fully determine the loss landscape or accurately trace the trajectory within it. Therefore, we employ a variational framework to quantify uncertainty by estimating the most probable values and their variability. We refer to our method as Learning Curve GraphODE (LC-GODE), highlighting the integration of architectures within the ODE framework to model learning curves.\nThe illustration of our approach is shown in Figure 1.\nB. Architecture-aware Differential Equation\na) Observed time series encoder: We use a sequence encoder to compute the mean and standard deviation of the posterior distribution $q_\u03c6(z_{n+1}|{Y_i, t_i}_{i=1}^n)$, which is assumed to be Gaussian:\n$z_{n+1} \\sim q_\u03c6(z_{n+1}|{Y_i, t_i}_{i=1}^n) = N(\u03bc_{z_{n+1}}, \u03c3_{z_{n+1}})$     (4)\n$\u03bc_{z_{n+1}}, \u03c3_{z_{n+1}} = SeqEncoder({y_i, t_i}_{i=1}^n)$   (5)\nWe implement this using an RNN with GRU units for the sequence encoder. Other encoder options include Self-Attention Vaswani et al. (2017) and Temporal Convolutional Networks (TCN) Pandey and Wang (2019), which adapt well to varying observation lengths. We conduct an ablation study in the experimental section to evaluate the performance of these alternative sequence encoder implementations.\nb) Architecture encoder.: Assuming the graph representation G contains N nodes, the adjacency matrix $A \u2208 R^{N\u00d7N}$ details node connections, where $A_{ij}$ > 0 represents the edge from node i to node j. We analyze two foundational neural network types: MLPs and CNNs. In MLPs, nodes correspond to neurons and edges correspond to the presence of the connections between neurons, whereas in CNNs, nodes represent feature maps and edges depict operations like 1 \u00d7 1 and 3 \u00d7 3 convolutions, or 3 \u00d7 3 average pooling. For CNNs, we adopt the cell-based representation Dong and Yang (2020); Liu et al. (2018), which consists of four principal building blocks: stems, normal cells, reduction cells, and classification heads. The stem block is a fixed sequence of convolutional layers to process the input images. This is followed typically by 14-20 cells with reduction cells placed at 1/3 and 2/3 of the total depth. A normal cell contains 4 nodes, each of which belongs to the set of operations: skip connections, identity or zero (indicating the presence or absence of connections between certain layers), 1 \u00d7 1 and 3 \u00d7 3 convolutions, and 3 \u00d7 3 average pooling. Finally, the classification head employs a global pooling layer followed by a single fully connected layer and returns the network's output. Since the cell is repeated throughout this macro-skeleton, a CNN can be uniquely represented by its cell.\nTo derive a graph-level embedding, we first implement node-level message passing, followed by global pooling to"}, {"title": "extract a global embedding.", "content": "Our method differs from existing architecture-based performance prediction approaches Liu et al. (2018); Wen et al. (2020); Knyazev et al. (2021) by treating the node as a feature map rather than focusing on operations. Nodal features are calculated from the in-degree and out-degree of each node, normalized by the total number of edges. For MLPs, edge features are binary, while for CNN cells, they are integers representing operation types: {zeroize : 0,1 \u00d7 1 conv : 1,3 \u00d7 3 conv : 2,3 \u00d7 3 avg pooling: 3}.\nThe nodal feature matrix is denoted as $X \u2208 R^{N\u00d7d}$. The graph encoding process returns a vector representation of the architecture.\n$z_G = ArchEncoder_\u03b8(X)$.   (6)\nFor node-level message passing, we employ GCN layers and normalize the adjacency matrix to stabilize training, following Kipf and Welling (2016).\n$\\tilde{A} = A + I, \\tilde{D} = \\sum_j \\tilde{A}_{ij}$.\nA GCN layer then transforms the nodal features into a hidden representation:\n$Z = \\tilde{D}^{-1/2} \\tilde{A}\\tilde{D}^{-1/2}XW$   (7)\nwhere $W \u2208 R^{d\u00d7d'}$ is the feature transformation matrix. Applying l GCN layers aggregates information from l-hop neighbors. We employ learnable pooling, among other methods such as average- and max-pooling, and investigate each in our ablation study. The graph embedding $z_G$ contributes to the evolution of the latent state, as detailed in the next section, which introduces the latent ODE.\nc) Latent ordinary differential equation.: The transformation from discrete to continuous domain is predicated on the assumption that the step size, or learning rate, approaches zero, thereby approximating the time derivative of NN parameters using $L, O$ - Su et al. (2016), where $L, \u0398$ denotes the objective function and parameters from the source task. Assuming the parameters implicitly depends on time t, the time derivative of the training loss can be written as:\n$\\frac{dL(\u0398(t))}{dt} = \\sum_{i=1}^N \\frac{\u2202L}{\u2202\u0398_i}\\frac{\u2202\u0398_i}{dt}$.   (8)\nThe ground truth ODE for loss is independent of time. Therefore we adopt autonomous differential equations to describe the continuous evolution of the learning curves. On the other hand, we do not directly use the exact formula, as this involves the computation of backpropagation of the source task, which is potentially computation intensive. Moreover, our primary goal is not to derive exact ODEs for each training configuration. Instead, we focus on efficiently inferring learning curves for new training configurations. To achieve this, we leverage the latent space, using the expressivity of hidden neurons to capture common patterns across learning curves from the same source task, despite variations in underlying architectures and hyperparameters.\nGiven that the training data for the source task remains fixed, the loss landscape varies depending on the architecture. Therefore, it's sufficient to model a universal latent ODE as a function of the architecture, enabling it to describe the evolution of various learning curves, each corresponding to a different architecture. Our latent ODE is formalized by the equation:\n$\\dot{z} = f_\u0398([z||z_G])$   (9)\nHere, $\\dot{z}$ denotes the derivative of the latent state vector z with respect to time, driven by the function $f_\u0398$, which takes as input both the latent state z and a graph-level embedding $z_G$. This combination allows the model to simultaneously consider the dynamic properties of the learning curve and the static characteristics of the architecture, enhancing the predictive capability of the system. Eq (9) can be regarded as a single-agent representation of the dynamics induced by NN training, which involves multiple trajectories of neurons, edge weights, and loss. This reduced representation of coupled dynamical system has been explored in Gao et al. (2016); Laurence et al. (2019) to study the tipping point of the original network dynamics. The difference from the prior dynamical system reduction approach is that the graph reduction mechanism is learnable so that the model can be adapted to unseen trajectories derived from different optimization trials.\nFinally, numerical integration of Eq (9) yields a time series of latent states $z_i$ (n < i < m). Each latent state is independently decoded by a function $\u0177_i = Decoder_{\u03b8_3}(z_i)$.\nd) Training objective.: To optimize our model, we maximize the evidence lower bound (ELBO), fomulated as follows\n$ELBO(\u03c6, \u0398) = E_{z_{n+1}} [log P_\u0398 (Y_{n+1},..., Y_m)] - KL[q_\u03c6(z_{n+1}|{Y_i, t_i}_{i=1}^n)||P(z_{n+1})]$  (10)\nThe first term in the ELBO equation represents the expected log-likelihood of observing future outputs given the latent states, as parameterized by $\u0398 = (\u03b8_1, \u03b8_2, \u03b8_3)$, where $\u03b8_1, \u03b8_2$, and $\u03b8_3$ correspond to the architecture encoder, the ODE function, and the decoder, respectively. The second term penalizes the divergence (measured by the KL-divergence) between the posterior distribution of the latent states and their prior distribution, enforcing a regularization that anchors the posterior closer to the prior. This balance ensures that while the model remains flexible enough to capture complex patterns in data, it also maintains a level of generalization that prevents overfitting.\ne) Scalability and computational cost.: The computational cost of numerical integration is minimal because the ODE models only the evolution of the loss embedding with dimension D, rather than modeling each node in the architecture individually. The runtime of the forward pass is bounded by $O(D^2T)$, where T = m \u2212 n is the number of integration time steps, assuming the ODE function is implemented as an MLP with a fixed number of layers. Consequently, the runtime of the ODE component remains independent of the overall size of the neural network."}, {"title": "IV. EXPERIMENTS", "content": "We demonstrate the capability of LC-GODE to forecast model performance across a range of common AutoML benchmarks. First, we evaluate LC-GODE against six learning curve extrapolation techniques on real-world datasets obtained using stochastic gradient descent on both tabular and image tasks. The training process is conducted individually for each source task. Furthermore, we assess our method's effectiveness in ranking training configurations by predicted optimal performance. Lastly, we explore model sensitivity to variants of architecture, observed time-series encoders and hyper-parameters. Our code and supplemental materials are publicly available\u00b9.\na) Datasets.: We consider test loss and test accuracy curves for both MLP-based and CNN-based architectures. Specifically for MLPs, we use car and segment tabular data binary classification tasks from OpenML Vanschoren et al. (2014) as source tasks. Following LCBench Zimmer et al. (2021), we randomly generate training configurations that include variables such as the number of layers, number of hidden units, and learning rates. For each dataset, we conduct 550 optimization trials across 200 epochs. For CNN-based models, we employ the NAS-Bench-201 dataset Dong and Yang (2020), which provides comprehensive learning curves for each architecture over a span of 200 epochs across two image datasets: CIFAR-10, CIFAR-100 Krizhevsky et al. (2009). We randomly select 5,000 architectures from CIFAR-10 and CIFAR-100 to form our dataset. Furthermore, we reserve 20% of all trials as the test set for each MLP source task and 25% for each CNN source task.\nA. Extrapolating Real-world Learning Curves\na) Experimental setup.: The goal of this experiment is to evaluate the LC-GODE model against established learning curve prediction methods using real-world benchmarks. We train our model separately on the test loss curves of each source task. The condition length is set to 10 epochs for all methods in this experiment. The instantiation of LC-GODE that we report features: (i) an architecture encoder that utilizes 2 layers and employs a learnable pooling technique, (ii) an observed time-series encoder implemented using GRU, (iii) an ODE function with a 2-layer MLP and integrated using the Runge-Kutta 4 method Butcher (1996). Further details on the evaluation metrics and the training settings can be found in the supplemental materials.\nb) Baselines.: We evaluate our model against six methods, including three Bayesian approaches and three general time-series prediction approaches. (i) LC-BNN: This method utilizes a Bayesian neural network to model the posterior distribution of future learning curves. The probability function is constructed from a combination of basis functions, following the approach described by Domhan et al. Domhan et al. (2015). (ii) LC-PFN: A transformer-based model is trained on synthetic curves that are generated from a pre-defined prior. This method serves as an efficient alternative to traditional Markov Chain Monte-Carlo (MCMC) techniques for sampling from posterior distributions. (iii) VRNN: A probabilistic model utilizing random forests and Bayesian recurrent neural networks. (iv) LSTM: This Recurrent Neural Network captures sequential dependencies. Before the observation cutoff at n,"}, {"title": "input states are derived from actual observations.", "content": "Post n, the model uses its own predictions from previous timestamps as inputs. (v) NODE: Latent Ordinary Differential Equations, focusing primarily on modeling the latent loss representation without incorporating architectural information. (vi) NSDE: Latent Stochastic Differential Equations, consisting of a drift term and a diffusion term. The drift term is the same as NODE, and the sequence encoder and decoder is the same as in our model. Both NODE and NSDE are trained using the variational framework.\nc) Results.: We evaluate performance using Mean Absolute Percentage Error (MAPE) and Root Mean Squared Error (RMSE) with different prediction lengths. Table I shows the extrapolation error for test accuracy curves from four datasets. Due to space constraints, the comparison results for loss curve extrapolation are provided in the supplement. Our proposed LC-GODE outperforms all baselines on these datasets. Specifically, LC-GODE reduces the error on test accuracy curves by 36.13%, 30.72%, 34.97%, and 59.63%, and on test loss curves by 65.5%, 44.61%, 20.1%, and 23.45% compared to the NODE model without architecture information. This improvement is due to the incorporation of architecture information with graph embedding. The architectures with similar performance are mapped to nearby locations in the hidden space, as shown in Figure 2(a). To demonstrate the advantage of jointly training the time-series encoder with the graph encoder, we compare the optimal performance difference of two configurations with the distance between their initial latent states in Figure 2(b). When architecture information is included, the correlation between these distances increases from 0.77 to 0.83 for the CIFAR-10 test accuracy curves. For a detailed comparison over epochs, we plot MAPE at 10 prediction lengths for NODE, NSDE, and LC-GODE on both test accuracy and loss curves (Figure 3). Overall, models perform better and have larger improvement on test accuracy curves compared to loss curves. This could be attributed to the fact that classification accuracy is less sensitive to decision boundary changes than cross-entropy loss, making it less variable and easier to predict.\nRegarding the baseline comparisons, LC-PFN emerges as the second most effective approach for extrapolating test accuracy curves of the car and segment source tasks, while"}, {"title": "the NSDE model ranks as the second in predicting test loss curves", "content": "for CIFAR-10 and CIFAR-100. Both NSDE and NODE models demonstrate comparable performance, with NSDE marginally outperforming NODE. These results underscore the viability of employing time-series approaches for addressing learning curve extrapolation challenges. Notably, the slight advantage of NSDE over NODE suggests subtle benefits in capturing stochastic dynamics that may be present in complex learning scenarios. This comparison highlights the potential for refined time-series models to enhance predictive accuracy and adaptability in diverse training environments.\nd) Model ranking: We evaluate our method's efficacy in ranking training configurations by comparing the predicted and true optimal performances at a fixed snapshot, employing two metrics: regret (the performance discrepancy between the actual and predicted best configurations) and ranking (the position of the predicted best configuration according to the true learning curves). These metrics demonstrate whether the predicted performance can effectively guide the selection of a performant configuration.\nAs shown in Table II, our proposed approach, LC-GODE, enhances the ranking of the predicted best model by 3 positions on the segment dataset and by 8 positions on the CIFAR-10 dataset, and reduces regret by 96% on CIFAR-10 compared to the superior baseline among NODE and NSDE for test accuracy curves. Nevertheless, when employing test loss to identify the best model, the overall ranking for all methods declines, indicating that predicted test loss is less effective for model selection.\nOur approach identified a performant model with a 20x speedup compared to exhaustive brute-force training using stochastic gradient descent (SGD) on the MLP datasets. The speedup is computed as the total runtime needed to fully train all configurations via SGD, divided by the sum of the actual training time for n epochs and the inference time required by LC-GODE. The inference time for LC-GODE is approximately 0.8 seconds, and the majority of the model"}, {"title": "V. CONCLUSION", "content": "In this study, we introduced LC-GODE, a novel approach that merges architectural insights with learning curve extrapolation from a dynamical systems perspective. Our model uses early performance data to predict future learning curve trajectories, significantly enhancing predictions of both test loss and accuracy. This architecture-aware, dynamical system-based method not only surpasses existing extrapolation techniques but also enhances model ranking and the selection of optimal configurations by analyzing just a small number of epochs. This efficient approach achieves a 20x speedup in model selection compared to traditional full training cycles using stochastic gradient descent. Future work could improve by incorporating the impact of source data to generalize across source tasks."}, {"title": "APPENDIX A", "content": "EXPERIMENTAL DETAILS\na) Datasets.: To generate MLP learning curves, we selected 2 tabular data classification tasks from OpenML Vanschoren et al. (2014) as detailed in Table IV. We adhere to the standard procedure outlined in LCBench Zimmer et al. (2021), with the exception that we introduce variability by randomly sampling the number of hidden units for each layer, rather than sampling only the maximal number of hidden units. All optimization runs are performed using SGD with decaying learning rate by 0.5 every 80 epochs. The total number of epochs is 200. We discard runs The parameters randomly sampled include four floating-point values and 2 + 1 integers, where I denotes the number of layers.\nb) Metrics.: We adopt six metrics to evaluate our approach from three dimensions.\n\u2022 Trajectory reconstruction. To evaluate curve reconstruction error, we utilize MAPE. Let $N_{pred}$ denote the prediction length. Let $\u0177_t^{(i)} \u2208 R^{N_{pred}}$ denote the ith trajectory in the test set. Let $y_t^{(i)} \u2208 R^{N_{pred}}$ denote the ground truth trajectory. The reconstruction error for one trajectory is comuted as\n$MAPE_i = \\frac{1}{N_{pred}}\\sum_{t=1}^{N_{pred}} \\frac{|y_t^{(i)} - \u0177_t^{(i)}|}{y_t^{(i)}}$  (11)\nThe error metric for the entire test dataset is the corresponding average over all trajectories.\n$MAPE = \\frac{1}{N_{traj}}\\sum MAPE_i$ (12)\n\u2022 Model Selection. We use Pearson correlation as adopted in [?] and Kendall \u03c4 [NasWOT].\n\u2022 Efficiency. We report the training runtime per epoch and the the wall-clock time to perform inference for one architecture using our model. The speedup is computed as\n$Speedup = \\frac{Runtime for SGD over 52 Epochs}{Runtime for SGD over T_{cond} epochs + LC-ODE Forward Runtime}$ (13)\nc) Hyperparameter Setting.: Without further specification, the hyperparameters to train both our model and the baselines are set according to Table V"}, {"title": "A. Baseline Configurations.", "content": "a) LC-BNN.: LC-BNN is a function that maps a tuple containing a configuration and an epoch (configuration, epoch) to the loss value associated with that configuration at the specified epoch. We represent the trajectory data as pairs of input and target values: ((configi, tj), Yi(tj)) where config; denotes the ith configuration, tj represents an epoch, and yi(tj) is the corresponding metric value. For MLP configurations, we use the hyperparameters specified in LCBench, detailed in Table III. In the case of NAS-Bench-201, we utilize the hyperparameters outlined in their respective publication. Note that all architectures within NAS-Bench-201 utilize a uniform set of hyperparameters. Nevertheless, we include these hyperparameters as input to LC-BNN, as it requires at least one additional input beyond the epoch number.\nOur dataset is structured within an inductive learning framework, comprising multiple training trajectories, with the test set including unseen trajectories. Since LC-BNN does not have an associated conditional length, to ensure a fair comparison, we incorporate the conditional window from our test set into the training data for LC-BNN.\nb) LC-PFN.: To apply LC-PFN, we preprocess our data using the normalization procedure outlined in Appendix A by Adriaensen et al. (2023). This approach ensures that our data is consistently formatted and scaled according to the specified guidelines. The normalization process transforms observed curves into a constrained range [0, u] where u \u2248 1. LC-PFN takes as input the normalized observations and outputs inferred loss values. These values are then mapped back to their original space using the inverse of the normalization function. The parameters of the normalization function are defined as x = (mintrain?, Ihard, Uhard, Isoft, Usoft):\n\u2022 mintrain?: A Boolean indicating whether the curve is to be minimized or maximized.\n\u2022 Ihard, Uhard: Hard bounds defining the absolute limits of the learning curve.\n\u2022 Isoft, Usoft: Soft bounds that guide the behavior of the learning curve.\nThe normalization function is formulated as:\n$g_x(x) = cr_{0.5} ( \\frac{C}{1+e^{-(a(x-b)})} +d)$,\nwhere:\n$cr_{0.5}(y) = \\{\\begin{array}{ll} 1-y & \\text{if mintrain?} \\\\ y & \\text{otherwise} \\end{array}$ \\quad \\frac{U_{hard}-I_{hard}}{2}$\na = \\frac{a}{v_{soft} - l_{soft}}$\nb = \\frac{u_{soft}+I_{soft}}{2}$ \\quad $c = \\frac{1 + exp(-a(U_{hard} - b)) + exp(-a(I_{hard} - b)) + exp(-a(u_{hard} + l_{hard} - 2b))}{exp(-a(I_{hard} - b)) - exp(-a(U_{hard} - b))}$ \nd = $\\frac{c}{1 + exp(-a(I_{hard} - b))}$.\nThe inverse of $g_x^{-1}(y)$ is defined as\ng_x^{-1}(y) = b - \\frac{1}{a}log( \\frac{c}{cr_{0.5}^{-1}(y) - d} - 1) (14)\nFor normalizing observed log loss values, we utilize x = (True, 0, log(10), 0, max{ytrain}). Here $y_{1:train}^{(n)}$ is the log loss value at the first epoch of the trajectories to train AutoML models. To normalize accuracy curves, we apply x = (False, 0, 1, 0, 1).\nc) LSTM.: The LSTM implementation is adapted from the published code associated with NRI Kipf et al. (2018). This implementation employs teacher forcing by utilizing the observation window. Specifically, it features a step () module, which comprises a Long-short-term memory (LSTM) block and a two-layer MLP with ReLU activation. The step () function processes the previous input state and hidden state, outputting the prediction and hidden state for the next immediate time step. The forward() function iteratively calls step() for a total of Tmax times. During the initial Tcond steps, the observed learning curve data is used as the input state. For the subsequent steps beyond Tcond, the output from the previous prediction is used as the new input state."}, {"title": "APPENDIX B", "content": "ADDITIONAL RESULTS\nTable VI shows the extrapolation error of six baselines and LC-GODE for test loss curves originated from 2 tabular tasks and 2 image classification tasks computed over three prediction lengths, observing 10 epochs. Table VII shows the runtime (in seconds) of training one epoch and that of performing inference on the entire test set. For LC-PFN, the model is trained on synthetic curves drawn from a prior distribution and therefore no further training is needed, as long as the test learning curves are normalized according to the above description. Note that the inference time for Bayesian approaches, except for LC-BNN, is much greater than other approaches."}]}