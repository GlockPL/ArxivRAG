{"title": "FFAA: Multimodal Large Language Model based Explainable Open-World\nFace Forgery Analysis Assistant", "authors": ["Zhengchao Huang", "Bin Xia", "Zicheng Lin", "Zhun Mou", "Wenming Yang"], "abstract": "The rapid advancement of deepfake technologies has sparked\nwidespread public concern, particularly as face forgery poses\na serious threat to public information security. However, the\nunknown and diverse forgery techniques, varied facial fea-\ntures and complex environmental factors pose significant\nchallenges for face forgery analysis. Existing datasets lack\ndescriptions of these aspects, making it difficult for models\nto distinguish between real and forged faces using only vi-\nsual information amid various confounding factors. In addi-\ntion, existing methods do not yield user-friendly and explain-\nable results, complicating the understanding of the model's\ndecision-making process. To address these challenges, we in-\ntroduce a novel Open-World Face Forgery Analysis VQA\n(OW-FFA-VQA) task and the corresponding benchmark. To\ntackle this task, we first establish a dataset featuring a di-\nverse collection of real and forged face images with es-\nsential descriptions and reliable forgery reasoning. Base on\nthis dataset, we introduce FFAA: Face Forgery Analysis As-\nsistant, consisting of a fine-tuned Multimodal Large Lan-\nguage Model (MLLM) and Multi-answer Intelligent Decision\nSystem (MIDS). By integrating hypothetical prompts with\nMIDS, the impact of fuzzy classification boundaries is effec-\ntively mitigated, enhancing the model's robustness. Extensive\nexperiments demonstrate that our method not only provides\nuser-friendly explainable results but also significantly boosts\naccuracy and robustness compared to previous methods.", "sections": [{"title": "Introduction", "content": "The widespread availability of facial data online and access\nto deepfake technologies (FaceSwapDevs 2019; Kowalski\n2018) have facilitated the forgery of identities. Malicious\nactors employ deepfake technology to manipulate faces for\nfraudulent purposes, generating false information and incit-\ning public panic, which pose serious threats to both personal\nand public information security. To combat face forgery at-\ntacks, researchers have analyzed a variety of face forgery\ndatasets (Rossler et al. 2019; Li et al. 2020) and developed\nnumerous advanced forgery detection models (Dong et al.\n2023; Ba et al. 2024) utilizing deep learning techniques.\nHowever, previous methods exhibit a substantial decline\nin detection accuracy when applied to open-world scenar-\nios. There are two primary reasons: (1) High-quality forged"}, {"title": "Multimodal Large Language Models", "content": "Recently, Multimodal Large Language Models (MLLMs)\nrepresented by GPT-4V and GPT-40 have garnered signif-\nicant attention due to their remarkable image understand-\ning and analysis capabilities. Some studies (Jia et al. 2024;\nShi et al. 2024) have explored their potential in face forgery\nanalysis by employing prompt engineering. They find that\ncarefully designed prompts are essential for inducing anal-\nysis and making judgments, yet the accuracy of discrimina-\ntion remains suboptimal. In other fields, some studies (Lai\net al. 2024; Li et al. 2024) employ instruction tuning to\nfine-tune pre-trained MLLMs, resulting in domain-specific\nMLLMs with strong zero-shot capabilities."}, {"title": "Dataset", "content": "Fig. 2a shows the data collection process. Based on some\nstudies (Tolosana et al. 2020; Dang et al. 2020) and\nreal-world scenarios, we classify face forgery types into\nthree categories: identity exchange (i.e., replacing the tar-\nget face with another face), facial attribute manipulation\n(i.e., manipulating attributes of the target face, including ex-\npressions), and entire face synthesis (i.e., generating non-\nexistent faces). Then, we utilize FF++ (Rossler et al. 2019),\nCeleb-DF-v2 (Li et al. 2020), DFFD (Dang et al. 2020) and\nGanDiffFace (Melzi et al. 2023) as our source datasets since\nthey encompass diverse forgery techniques and enriched fa-\ncial characteristics. Finally, we construct the Multi-attack\n(MA) dataset, comprising 95K images with diverse facial\nfeatures and various types of forgeries."}, {"title": "GPT4-assisted Analysis Generation", "content": "Manually writing the image description and forgery rea-\nsoning requires specialized knowledge and is quite cumber-\nsome, making it difficult to establish a large-scale and high-\nquality dataset. Inspired by some studies (Chen et al. 2023;\nLiu et al. 2024b; Li et al. 2024) using GPT for image cap-\ntioning, we employ GPT-4o to generate face forgery analy-"}, {"title": "Face Forgery Analysis Assistant", "content": "a\nFig. 4a depicts the architecture of FFAA, which primarily\nconsists of two modules: a fine-tuned MLLM and MIDS.\nInitially, the MLLM generates the anchor answer Xa with-\nout hypotheses, the positive answer X and the negative an-\nswer X based on varying hypotheses, all of which are input\ninto MIDS along with the face image. The model then cal-\nculates the match score between the image and each answer\nbased on MIDS's output vectors (ma, mp, mm) and the de-\ntermination result of each answer as follows:\n{\n  s =\n  \\begin{cases}\n    m_0/(m_0 + m_2), & \\text{if } r(X_a) \\text{ is 'real'},\n    \\\\m_3/(m_3 + m_1), & \\text{if } r(X_a) \\text{ is 'fake'},\n  \\end{cases}\n(1)\n}\nwhere mi represents the i-th element of m and r(Xa) rep-\nresents the determination result of Xa. Finally, the answer\nwith the highest match score is selected as the best answer."}, {"title": "Fine-tuning MLLM with Hypothetical Prompts", "content": "We categorize the prompts into two types: non-hypothetical\n(e.g., The image is a human face image. Is it real or fake?\nWhy?) and hypothetical (e.g., This is a [real/fake] human"}, {"title": "Multi-answer Intelligent Decision System", "content": "MIDS consists of three components: Feature Encoding,\nImage-Answer Cross Fusion Module and Classification\nLayer, as depicted in Fig. 4b. We first utilize the fine-\ntuned MLLM to extract answers from unused samples in"}, {"title": "Experiments", "content": "In this section, we first establish the OW-FFA-Bench to\nevaluate the model's generalization and robustness. We then\ncompare our method with the state-of-the-art methods on\nthis benchmark and conduct ablation studies. Furthermore,\nwe perform qualitative studies by comparing FFAA with ad-\nvanced MLLMs and employing several visualizations."}, {"title": "Experimental Setup", "content": "Datasets. We create the generalization test sets by ran-\ndomly collecting face images from the public datasets:\nDeeperforensics (DPF) (Jiang et al. 2020), DeepFakeDetec-\ntion (DFD) (Google 2019), DFDC (Dolhansky et al. 2020),\nPGGAN (Karras et al. 2017), Celeb-A (Liu et al. 2018),\nWhichFaceIsReal (WFIR) (West and Bergstrom 2019) and\nMultiFFDI (MFFDI) (on the Bund 2024). The images are\nthen divided into six generalization test sets based on their\nsource as shown in Tab. 1, with each containing 1K images\nand differing in distribution. See Appendix for more details."}, {"title": "Implementation details", "content": "We first fine-tune an MLLM,\ne.g. LLaVA-v1.6-mistral-7B (Liu et al. 2024a) with LoRA\n(rank=32, alpha=48) on the FFA-VQA dataset using 2 RTX\n3090 GPUs for 3 epochs with a learning rate of le-4 and a\nbatch size of 16. Then, we train MIDS using 2 RTX 3090\nGPUs for 2 epochs with a learning rate of le-4 and a batch\nsize of 48. See Appendix for more training details."}, {"title": "Evaluation metrics", "content": "We utilize the Accuracy (ACC), Area\nUnder Receiver Operating Characteristic Curve (AUC) and\nAverage Precision (AP) to empirically evaluate generaliza-\ntion performance on individual test sets as well as across the\nentire OW-FFA-Bench (ALL). Additionally, we employ the\nstandard deviation of ACC (SACC) across all test sets to as-\nsess the model's robustness."}, {"title": "Comparison with Existing Methods", "content": "In this section, we compare our method against state-of-the-\nart face forgery analysis methods on 1K in-domain test set of\nMA and the OW-FFA-Bench. These methods can be divided\ninto two categories: methods using only visual information\n(i.e., Xception (Chollet 2017), RECCE (Cao et al. 2022),\nImplicit (Dong et al. 2023), FedForgery (Liu et al. 2023),\nExposing (Ba et al. 2024) and NPR (Tan et al. 2024)), and\nmethods based on CLIP using both textual and visual infor-\nmation (i.e., CLIPping (Khan and Dang-Nguyen 2024)).\nTab. 2 presents the comparison results. Methods in the\nfirst category display varying degrees of overfitting and poor\ngeneralization, underscoring the challenges in open-world\nscenarios where various confounding factors complicate the\ndiscrimination using solely visual information. Conversely,\nCLIPping effectively prevent overfitting and demonstrate\nbetter generalization. However, the accuracy and robustness\nof these methods remain suboptimal. In contrast, we frame\nface forgery analysis as a VQA task, requiring the model\nto analyze forgery before making a judgment. This ap-\nproach improves the model's generalization ability and clar-\nifies its decision-making process. Given the fuzzy bound-\naries between real and forged faces, we employ hypothetical\nprompts and MIDS to comprehensively compare answers\nbased on varying hypotheses, boosting robustness."}, {"title": "Ablation Study", "content": "In this section, we first study the effectiveness of our pro-\nposed FFA-VQA dataset. Then, we conduct ablation studies\nto assess MIDS and its specific design choices."}, {"title": "Ablation Study on FFA-VQA", "content": "We study the effective-\nness of the FFA-CoT and the impact of high-quality image\ndescriptions and forgery reasoning textual data on various"}, {"title": "Qualitative Study", "content": "Comparison with Advanced MLLMs. Fig. 5 depicts a\nquality example. We present some responses from advanced\nMLLMs, including LLaVA-v1.6-34b (Liu et al. 2024a) and\nGPT-40, and compared them with ours. These advanced"}, {"title": "Heatmap Visualization", "content": "To verify whether MIDS can\nlearn more face authenticity representation features guided\nby enriched textual features, we utilize Grad-CAM (Sel-\nvaraju et al. 2020) to visualize the attention heatmap of Ful\nand Fug. As illustrated in Fig. 7, guided by enriched textual\nfeatures, MIDS considers multiple aspects of the image and\nfocuses on key features related to face authenticity."}, {"title": "Visualization of Easy and Hard Samples", "content": "As illustrated\nin Fig. 8, the fake faces in the 'Easy' samples usually have\nobvious signs of forgery while real faces have higher im-\nage quality. Conversely, 'Hard' samples often exhibit vary-\ning image quality and more convincing forgeries, posing sig-\nnificant challenges in determining face authenticity."}, {"title": "Conclusion", "content": "In this paper, we introduce a novel OW-FFA-VQA task\naimed at understanding the decision-making process of face\nforgery analysis models and establish the corresponding\nbenchmark and dataset. To tackle this task, we introduce\nFFAA: Face Forgery Analysis Assistant, which consists of\na fine-tuned MLLM and MIDS. By integrating hypotheti-\ncal prompts with MIDS, the impact of fuzzy classification\nboundaries between real and forged faces is effectively mit-\nigated, enhancing the model's robustness. Our experiments\ndemonstrate that FFAA not only yields user-friendly and ex-\nplainable results but also significantly boosts generalization,\naccuracy and robustness compared to previous methods."}, {"title": "Data Source Composition for FFA-VQA", "content": "We collect\ndata from the previously mentioned public datasets. We em-\nploy the dlib tool to crop faces from video frames and im-\nages, then uniformly resized them to 224x224. Fig. 9a shows\nsome of these face images. The images are categorized by\nforgery type based on their sources, as shown in Tab. 4.\nFrom the dataset, we randomly select 2,000 images, with\nhalf designated as the validation set and the other half as the\ntest set. Following the process outlined in Fig. 2b and us-\ning the training set of Multi-attack as the image data source,\nwe create face forgery analysis data. This resulted in 20,142\npairs of VQA data, distributed as follows: 'Real' (8,073),\n'Facial attribute manipulation' (4,014), 'Entire face synthe-\nsis' (4,025), and 'Identity exchange' (4,030). The average\nnumber of tokens in the answers is 203."}, {"title": "Data Source Composition for OW-FFA-Bench", "content": "The\ndata sources for OW-FFA-Bench are shown in Tab. 1. Sim-\nilarly, we employ the dlib tool to crop faces from video\nframes or images and uniformly resize them to 224x224.\nFinally, to balance testing efficiency and effectiveness, we\nrandomly sample 1,000 images from each dataset accord-\ning to its data distribution. Fig. 9b shows some of the face\nimages from the test sets."}, {"title": "Fine-tuning Details of the MLLM", "content": "We employ LLaVA-\nv1.6-mistral-7B (Liu et al. 2024a) as our backbone and fine-\ntune it with LoRA (rank=32, alpha=48) on the FFA-VQA\ndataset containing hypothetial prompts using 2 RTX 3090\nGPUs, with a learning rate of 1e-4 and a batch size of 16.\nAll other settings remain the same as in LLaVA."}, {"title": "Training Details of MIDS", "content": "We first employ the fine-\ntuned MLLM to mine historical answer data from the re-\nmaining available images in the Multi-attack training set,\nexcluding the 'Easy' images. Ultimately, we collect 30K\n(\u03a7\u03c5, X, X, Xn) data pairs. We then train MIDS on this\ndataset for 2 epochs using 2 RTX 3090 GPUs, with the\nAdamW optimizer, a learning rate of 1e-4, a batch size of\n48, and a weight decay of le-5. The number of self-attention\niterations M = 3. Data augmentation techniques include"}]}