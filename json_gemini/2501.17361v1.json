{"title": "The M-factor: A Novel Metric for Evaluating Neural Architecture Search in Resource-Constrained Environments", "authors": ["Srikanth Thudumul", "Hy Nguyen", "Hung Du", "Nhat Duong", "Zafaryab Rasool", "Rena Logothetis", "Scott Barnett", "Rajesh Vasa", "Kon Mouzakis"], "abstract": "Neural Architecture Search (NAS) aims to automate the design of deep neural networks. However, existing NAS techniques often focus primarily on maximizing accuracy, neglecting model efficiency. This limitation hinders their applicability in resource-constrained environments such as mobile devices and edge computing systems. Additionally, current evaluation metrics typically prioritize performance over efficiency, lacking a balanced approach to assess architectures suitable for deployment in constrained scenarios. To address these limitations, this paper introduces the M-factor, a novel metric that combines model accuracy and size. We compare four diverse NAS techniques: Policy-Based Reinforcement Learning, Regularized Evolution, Tree-structured Parzen Estimator (TPE), and Multi-trial Random search. This selection represents different approaches in NAS, allowing for a comprehensive assessment of the M-Factor across various paradigms. The study examines ResNet configurations on the CIFAR-10 dataset, with a search space of 19,683 configurations. Experiments show Policy-Based Reinforcement Learning and Regularized Evolution achieved M-factor values of 0.84 and 0.82 respectively, while Multi-trial Random search attained 0.75 and TPE reached 0.67. Policy-based reinforcement Learning exhibited performance changes after 39 trials, and Regularized Evolution showed optimization within 20 trials. The research analyzes optimization dynamics and trade-offs between accuracy and model size for each strategy. Results indicate that in some cases, random search performed comparably to more complex algorithms when evaluated using the M-factor. These findings demonstrate how the M-factor addresses the limitations of existing metrics by guiding NAS towards balanced architectures, providing insights into strategy selection for scenarios requiring both model performance and efficiency.", "sections": [{"title": "1 Introduction", "content": "Deep neural networks have achieved remarkable success across various domains; however, their increasing complexity leads to computationally expensive and memory-intensive models [23]. This creates challenges for deployment in resource-constrained environments such as mobile devices, edge computing systems, and IoT applications [15]. Neural Architecture Search (NAS) addresses these challenges using an automatic technique to optimise neural network architectures with an efficient number of hyperparameters resulting in a high accuracy. However, existing NAS techniques primarily focus on maximizing accuracy, often neglecting the crucial aspect of model efficiency in terms of the number of parameters [10,36].\nTo support model development for resource-constrained environments, we introduce M-Factor, a novel metric that measures the trade-off between performance and efficiency in NAS. Our study focuses on four distinct NAS techniques: Policy-based Reinforcement Learning [36,37], Regularized Evolution [28], Tree-structured Parzen Estimator (TPE) [6,5], and Multi-trial Random search [18]. We apply these methods to optimize ResNet architectures [13] for the CIFAR-10 dataset [17], using the M-Factor as our primary evaluation metric.\nOur work contributes to the ongoing effort to develop efficient and effective methods for automated neural architecture design, particularly for resource-constrained environments. By utilizing our proposed metric for comparing these diverse NAS approaches, we provide insights in optimizing the trade-off between performance and efficiency. It is important to note that this study did not implement gradient-based search techniques such as DARTS [21], which use continuous and differentiable architecture representations, due to framework constraints in accommodating our custom M-Factor metric. Weight sharing strategies such as ENAS and one-shot models [27,3], which train a single over-parameterized model containing all possible sub-network architectures, were also excluded. Our experimental setup precluded the evaluation of sub-networks within a larger model. The selection of techniques was influenced by available computational resources, favoring methods that could run effectively within our constraints. Our search space, focused on specific layers within ResNet blocks, also guided our choice of search strategies. The main contributions of this paper are:\nDevelopment of M-Factor, a customized metric that enables NAS to optimize the trade-off between accuracy and model size.\nComparison of four diverse NAS techniques, providing insights into their effectiveness in optimizing the M-Factor.\nAnalysis of the trade-offs between accuracy and model size achieved by different NAS strategies, offering practical insights for deploying models in resource-constrained environments.\nThe structure of the paper is as follows: Section 2 presents background on architecture search and the specific techniques we focus on. Section 3 discusses the proposed M-Factor metric. Section 4 outlines our experimental setup, including the dataset, network architecture, and methodology. Section 5 presents"}, {"title": "2 Related work", "content": "Due to the demand of small deep learning models operating on mobile devices or edge computing systems, research in NAS has rapidly progressed [30,9,16,14]. The goal of NAS is to identify the optimal neural network architectures that have an efficient number of hyperparameters to attain high accuracy. Zoph and Le presented an initial popular work in this area [35] based on reinforcement learning (RL). Since then, a number of works have focused on different approaches for optimal deep neural network design. Apart from RL-based approaches [37,27,1], other approaches [25,20] are based on evolutionary algorithms or are heuristic-based [19]. Some existing works focused on addressing computational issues and huge memory requirements of these architectures. For example, Mellor et. al.[24] proposed an efficient NAS algorithm. Zhang et. al. [34] proposed a memory-efficient NAS for image denoising. Lopes et. al. [22] proposed two lightweight implementations for NAS using a multi-agent framework to reduce memory requirements and achieve better performance.\nIn evaluating these NAS techniques, various general metrics are employed to assess individual aspects of performance and efficiency [8]. Common metrics include accuracy (A), which measures the model's performance on specific tasks, and computational costs like FLOPs (Floating Point Operations) and inference time, which gauge the efficiency of the architecture. However, these metrics suffer from the trade-off between each other.\nTo provide a more holistic view, composite metrics have been developed that integrate multiple factors into a single score [31,33,7,10,15,11]. These metrics combine performance indicators with efficiency measures, offering a more comprehensive evaluation of architectures. Especially, in resource-constrained scenarios, the integration of different metrics support to balance the trade-off between them. For example, Accuracy-to-Parameter Ratio (A/P) combines accuracy with the number of parameters and helps assess how efficiently a model achieves high accuracy relative to its complexity.\nSimilarly, Accuracy-to-FLOPs (A/F) Ratio evaluates how effectively a model achieves high accuracy for a given amount of computation, making it useful for understanding the trade-off between performance and computational efficiency.\nWong [32] proposed NetScore that assess the performance of neural network architecture for practical usage. It aggregates accuracy, model size, and computational cost to reflect both effectiveness and efficiency. It is defined as:\n$\\epsilon = 20 \\log{\\frac{A^{\\alpha}}{P^{\\beta} \\times M^{\\gamma}}}$\nwhere $M$ is the number of multiply-accumulate (MAC) operations, $\\alpha, \\beta$ and $\\gamma$ are coefficients that control the impact of each metric in on the overall performance. However, the value of $P$ and $M$ increase exponentially once the complexity of"}, {"title": "3 Problem Preliminary", "content": "Neural Architecture Search (NAS) automates the process of finding neural network architectures that balance accuracy with computational and memory efficiency [10]. It defines a search space of architectural dimensions and uses an optimizer to explore this space, guided by performance metrics. The search space denoted by A in NAS includes choices such as the number of layers, types of layers (e.g., convolutional, recurrent, fully connected, and other types), and hyperparameters for each layer (e.g., kernel size, stride, number of filters, and other hyperparameters):\n$A = \\{Arc_1, Arc_2,..., Arc_n\\}$\nwhere $Arc_i$ represents a potential architecture. Furthermore, NAS consists of a search strategy that determines how the algorithm searches for the optimal architecture as:\n$Arc^* = SearchStrategy(A, F,C)$\nwhere F is a performance evaluation function and C is a cost function. Notably, the performance of each architecture is estimated by utilizing the validation dataset from the original one. In addition, C in the resource-constrained scenarios depends on the goal of optimization, such as reducing number of parameters, floating-point operations per second (FLOPs) or latency. The goal of NAS is to maximize the model performance while adhering to specified constraints, and Equation 4 can be extended as follows:\n$Arc^* = arg \\max_{Arc_i \\in A} F(Arc_i; D_{val}) subject to C(Arc_i) \\leq \\theta$\nwhere $D_{val}$ is the validation dataset, and $\\theta$ is a threshold for the cost.\nNAS can add significant computational overhead during initial exploration [36]. This requires a careful search space design that ensures discoveries meet latency, energy consumption, and form factor requirements. There are also challenges in reproducing optimizations across different software and hardware stacks. Despite these challenges, NAS holds promise for finding performant model architectures tailored to specific efficiency goals. NAS algorithms explore the vast space of possible neural network architectures, evaluating candidate models based on their performance on a validation set or a surrogate objective function [10]. This search process can be formulated as an optimization problem,"}, {"title": "4 Proposed Metric: M-factor", "content": "In the context of Neural Architecture Search (NAS), traditional approaches focus primarily on maximizing model accuracy. However, in many real-world applications, particularly those involving resource-constrained environments such as mobile devices or edge computing systems, model efficiency is equally crucial. The challenge lies in finding an optimal balance between model performance and resource utilization. To address this, we propose the M-Factor, a novel metric designed to guide NAS algorithms towards architectures that achieve high accuracy while maintaining efficiency in terms of model size.\nInspired by F1-score that utilize the harmonic mean [12] to evaluate the balance between recall and precision, M-Factor is designed to assess the trade-off between"}, {"title": "4.2 Formulation", "content": "a model's accuracy and its efficiency in terms of size. The metric is defined as follows:\n$M = \\frac{2 \\times A \\times S'}{A + S'}$\nwhere A is the model accuracy (on validation set), and $S'$ is a normalized inverse measure of the model size:\n$S' = \\frac{P_{min}}{P}$\nwhere P is the number of parameters in the current model, and $P_{min}$ is the number of parameters in the smallest model in the search space. There are two reasons for the design of $S'$ as in Equation 7:\n$S'$ is the inverse of P. This ensures that the harmonic mean when optimizing $S'$ is equivalent to minimizing P.\nWe have $P_{min}$ divided by P to ensure the range of $S'$ lies between 0 and 1. Since the range of A is also 0 to 1, two elements such as the accuracy and the model size should be in the same range. This aims to eliminate the dominance of one element on the other element in the harmonic mean.\nNotably, the harmonic mean is sensitive to low values, meaning that if either model size or accuracy is low, M-factor will be significantly lower than their arithmetic mean. Consequently, M-factor only achieves a high value when both metrics are high. This property makes it effective for ensuring that models are optimal in terms of both size and accuracy."}, {"title": "4.3 Weighted Variant", "content": "Aside from balancing between the model accuracy and its size, many resource-constrained scenarios require to prioritize one of these factors. To attain this, we introduce a weighted variant of M-Factor as follows:\n$M_{\\alpha} = \\frac{(1 + \\alpha) \\times A \\times S'}{(\\alpha \\times A) + S'}$\nwhere $\\alpha$ is the weight factor that controls the relative importance of accuracy versus model size. There are three potential cases for the value of $\\alpha$ as:\nWhen $\\alpha = 1$, we get the original, balanced M-factor.\nAs $\\alpha$ is greater than 1 ($\\alpha > 1$), more emphasis is placed on minimizing model size.\nAs $\\alpha$ varies from 0 to 1 (0 < $\\alpha$ < 1), the accuracy is prioritized over the model size.\nThis adaptability makes the M-factor particularly valuable for scenarios with varying resource constraints or different priorities between performance and efficiency."}, {"title": "5 Experiments", "content": "Our experiments were conducted using the CIFAR-10 dataset [17]. This dataset comprises 60,000 32x32 color images distributed across 10 classes, with 6,000 images per class. The dataset is pre-divided into 50,000 training images and 10,000 test images."}, {"title": "5.2 Search Space", "content": "We based our experiments on the ResNet architecture [13], with a specific focus on modifying the convolutional layers within ResNet blocks. Each ResNet block in our experiments contained a conv1 layer, and we define three different LayerChoice options for that conv1 layer:\n2D convolution with kernel size 3x3, stride=stride, padding=1\n2D convolution with kernel size 5x5, stride=stride, padding=2\n2D convolution with kernel size 7x7, stride=stride, padding=3\nAll convolution layers were configured with bias=False. We designed our ResNet model to have three main layers, each main layer has three ResNet blocks, and each ResNet block has one conv1 layer. Therefore, we have nine conv1 layers. Because each conv1 layer has three options, hence we have $3^9 = 19,683$ total configurations to search. We also make sure that the ResNet blocks are not removed during the searching process. This helps to keep the value of $P_{min}$ in Equation 2 unchanged and prevent it from being reduced to 0.\nOur experiment was designed to test 9 different combinations of these LayerChoice options across 3 ResNet blocks. This setup allowed us to systematically explore the impact of varying kernel sizes on the network's performance. The number of input and output planes for each convolution layer was kept consistent within a block but could vary between blocks, as indicated by the in_planes and planes parameters in the configuration."}, {"title": "5.3 Implementation Details", "content": "The experiment was implemented using PyTorch [26], as evidenced by the use of nn.LayerChoice and nn.Conv2d modules in the configuration code. By systematically varying these convolutional layer configurations, we aimed to investigate their effects on model performance, including aspects such as accuracy, training speed, and generalization capability on the CIFAR-10 dataset."}, {"title": "5.4 Experimental Methodology", "content": "As mentioned above, we focused our experimental methodology on comparing Neural Architecture Search (NAS) strategies for ResNet models on the CIFAR-10 dataset. Our search space comprised three layers, each layer has three ResNet"}, {"title": "6 Results and Discussion", "content": ""}, {"title": "6.1 Performance of Search Strategies", "content": "We evaluated four Neural Architecture Search (NAS) strategies on the CIFAR-10 dataset using our custom metric M-factor. The best results achieved by each strategy are summarized in Table 1.\nPolicy-based Reinforcement Learning (RL) achieved the highest M-Factor value of 0.84, demonstrating its effectiveness in navigating the search space to find architectures that balance accuracy and model size. This result suggests that the RL approach is capable of learning and adapting its search strategy over"}, {"title": "6.2 Optimization Dynamics", "content": "The results of the M-factor across 50 trials revealed distinct behaviors for each strategy, providing insights into their search processes:\nPolicy-based RL: This strategy showed a notable improvement after the 39th trial, with M-Factor values consistently above 0.7 thereafter (Figure 1a). This behavior indicates that the RL agent required a significant number of trials to learn an effective policy for navigating the search space. Once learned, however, the policy consistently produced high-performing architectures. This suggests that Policy-based RL might be particularly effectivee for longer-running NAS experiments where the initial learning period can be amortized.\nRegularized Evolution: Demonstrating faster initial optimization compared to Policy-based RL, Regularized Evolution reached improved performance after just 20 trials (Figure 1b). This rapid improvement indicates that the evolutionary approach quickly identified and propagated beneficial architectural traits. The strategy's ability to find good solutions early makes it potentially more suitable for scenarios with limited computational resources or time constraints.\nTPE: The optimization curve for TPE exhibited inconsistent performance without a clear improvement trend (Figure 2a). This behavior suggests that TPE struggled to build an effective probabilistic model of the search space with respect to our custom metric. The lack of consistent improvement over time indicates that TPE might not be well-suited for our specific combination of search space and evaluation metric.\nMulti-trial Random: While this strategy doesn't have a learning pattern, it provided a strong baseline (Figure 2b). Its performance underscores the importance of comparing against simple strategies in NAS experiments. The fact that it outperformed TPE highlights that in some cases, especially with smaller search spaces, the complexity of more sophisticated algorithms may not translate to better performance."}, {"title": "6.3 Trade-offs Analysis", "content": "Our analysis of the top 20% of models revealed interesting trade-offs between accuracy and model size. The performance of top 20% trials for Policy-based RL, Regularized Evolution, TPE, and Multi-trial Random are shown respectively in Figures 3, 4, 5, and 6.\nPolicy-based RL consistently produced models with a good balance between accuracy and size, as reflected in its high M-Factor values. This suggests that the RL agent learned to optimize for both aspects effectively. The consistency in performance indicates that the learned policy was robust and reliably produced well-balanced architectures.\nRegularized Evolution showed a notable trend of reducing model size after the 30th trial while maintaining competitive accuracy. This behavior demonstrates the strategy's ability to refine solutions over time, progressively finding architectures that maintain high accuracy with increased efficiency. It suggests that Regularized Evolution may be particularly effective for tasks where model efficiency is a critical concern.\nTPE and Multi-trial Random showed more variability in both accuracy and model size. This variability reflects their less directed search processes. For TPE, it suggests that the algorithm struggled to build a consistent model of the relationship between architectural choices and our custom metric. For Multi-trial Random, the variability is expected due to the nature of random sampling."}, {"title": "7 Conclusion and Future Work", "content": "This paper introduces the M-factor metric to aid in the process of searching for the desired ResNet architecture in resource-constrained environments using NAS. We also compare the performance of four different NAS techniques. Policy-based Reinforcement Learning achieved an M-factor value of 0.84, with performance improvements observed after the 39th trial. Regularized Evolution reached an M-factor of 0.82, showing initial optimization within 20 trials and subsequent model size reduction. Multi-trial Random search attained an M-factor of 0.75, surpassing the Tree-structured Parzen Estimator's 0.67 in the defined ResNet-based search space for CIFAR-10. This search space comprised three layers, each with three ResNet blocks, allowing for 19,683 possible architectures through variations in convolutional layer configurations. These results indicate variations in strategy performance based on computational budget and optimization goals. The study demonstrates the potential of tailored metrics in guiding NAS towards architectures balancing accuracy and efficiency.\nFuture research directions include examining the M-factor's application to expanded search spaces and model architectures, and exploring its integration with one-shot NAS methods. Extending the study to different datasets and tasks will assess the generalizability of the M-factor metric and the performance of various NAS strategies across domains. Incorporating additional efficiency metrics,"}]}