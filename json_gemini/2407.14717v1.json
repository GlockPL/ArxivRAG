{"title": "Differential Privacy of Cross-Attention with Provable Guarantee", "authors": ["Jiuxiang Gu", "Yingyu Liang", "Zhenmei Shi", "Zhao Song", "Yufa Zhou"], "abstract": "Cross-attention has become a fundamental module nowadays in many important artificial intelligence applications, e.g., retrieval-augmented generation (RAG), system prompt, guided stable diffusion, and many so on. Ensuring cross-attention privacy is crucial and urgently needed because its key and value matrices may contain sensitive information about companies and their users, many of which profit solely from their system prompts or RAG data. In this work, we design a novel differential privacy (DP) data structure to address the privacy security of cross-attention with a theoretical guarantee. In detail, let $n$ be the input token length of system prompt/RAG data, $d$ be the feature dimension, $0 < \\alpha < 1$ be the relative error parameter, $R$ be the maximum value of the query and key matrices, $R_w$ be the maximum value of the value matrix, and $r, s, \\epsilon_s$ be parameters of polynomial kernel methods. Then, our data structure requires $O(ndr^2)$ memory consumption with $O(nr^2)$ initialization time complexity and $O(\\alpha^{-1}r^2)$ query time complexity for a single token query. In addition, our data structure can guarantee that the user query is $(\\epsilon, \\delta)$-DP with $\\tilde{O}(n^{-1}\\epsilon^{-1}\\alpha^{-1/2}R^2sR_wr^2)$ additive error and $n^{-1}(\\alpha + \\epsilon_s)$ relative error between our output and the true answer. Furthermore, our result is robust to adaptive queries in which users can intentionally attack the cross-attention system. To our knowledge, this is the first work to provide DP for cross-attention. We believe it can inspire more privacy algorithm design in large generative models (LGMs).", "sections": [{"title": "1 Introduction", "content": "The development of Artificial Intelligence (AI) has four stages: (1) prediction AI, e.g., ResNet [HZRS16] in image classification; (2) generation AI, e.g., ChatGPT [AAA+23] in language generation; (3) autonomous agent AI, Voyager [WXJ+23] autonomously plays Minecraft game [FWJ+22]; (4) Artificial Generalization Intelligence (AGI). Humans have made rapid progress in generative AI, and we are excitingly heading to the third stage, the era of AI agent [LYZ+23]. One prevalent application of AI agents is customized large generative models (LGMs) agents [Ope24a], e.g., AgentGPT [Git24a], SuperAGI [Git24d], MetaGPT [HZC+24, HLL+24], GPT Researcher [Git24c] and many so on. In particular, recently, Apple Inc. introduced Apple Intelligence [App24], signaling the integration of LGMs into physical devices. This innovation allows devices to use personal information for real-life assistance, such as entering passport numbers when booking flights or informing users of their latest meetings. With increased AI capabilities, privacy concerns become significant, as the more personal information devices handle, the greater the potential privacy risks.\nOne fundamental technique used in LGMs is cross-attention [VSP+17], which is an essential module in retrieval-augmented generation (RAG) [LPP+20], system prompt, guided stable diffusion, and many so on. In RAG, to be more professional, the LGMs can answer user input queries by using a domain-specific database under cross-attention, which may contain specific privacy data and knowledge so that the LGMs gain additional power. For system prompts, based on cross-attention, some customized long prompts, e.g., user information or concrete rules, are concatenated before user input to follow human instructions better, which are commonly used in ChatGPT [Git24b], Claude3 [Ant24] and other commercial LGMs.\nConsequently, protecting the privacy of domain-specific data in RAG or system prompts is crucial as they contain sensitive information about users and companies. These data and prompts are the core assets of many start-ups. However, these data and prompts can be easily recovered [LGF+23], jailbroken [JHL+24], and released [LCL+23] by user adversarial attack [YLH+24], e.g., there are 1700 tokens in ChatGPT system prompts [Pat24]. These findings highlight the critical importance of robust privacy protections in LGMs, making privacy not just essential but an urgent issue that demands immediate attention.\nTo fundamentally preserve cross-attention privacy, we can borrow the powerful tools from differential privacy (DP) [DMNS06], which provides measurable privacy and combines with statistical machine learning seamlessly [PHK+23]. Thus, in this work, we would like to ask and answer the following question,\nHow can we use differential privacy to protect the security of cross-attention in LGMs?\nOur work demonstrates that the cross-attention computation is equivalent to computing the weighted distance problem.\nDefinition 1.1 (Cross-attention). Let $n$ and $m$ be the token length of the system prompt/RAG data and input query, respectively. Let $d$ be the feature dimension. Let $\\phi : \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow \\mathbb{R}$ be any function that measures vector similarity. Given fixed key matrix $K \\in [0, R]^{n\\times d}$ and fixed value matrix $V\\in [-R_w, R_w]^{n\\times d}$, for any input query matrix $Q \\in [0, R]^{m\\times d}$, the goal of the Cross-Attention Computation is to get the matrix $Attn(Q, K, V) \\in \\mathbb{R}^{m\\times d}$, which is defined as\n$$Attn(Q, K, V) := D^{-1}AV,$$ \nwhere $A \\in \\mathbb{R}^{m\\times n}$ and $D\\in \\mathbb{R}^{m\\times m}$ is a diagonal matrix, i.e.,\n$$A_{i,j} := \\phi(Q_i, K_j), \\text{ and } D := diag(A_{1:m}).$$"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Differential Privacy Guarantee Analysis", "content": "Ever since [DMNS06] proposes the notion of differential privacy (DP), it has become one of the most essential standards of privacy protection in both theoretical and empirical ways [Dwo08, LLSY17,"}, {"title": "2.2 Differential Privacy in Data Structure and Attention", "content": "Differential privacy (DP) is a flourishing and powerful technique that has enormous applications in the topic of private machine learning. In the era of Large Generative Models (LGMs), there are three primary approaches to ensuring privacy: (1) during the pre-training stage: to protect training data [ACG+16, PHK+23], (2) during the adaptation stage: to protect target data [BEPP22, SAMB24, LLB+24, YNB+21, LTLH21, SSC+22], (3) during the inference stage: to protect user/system prompts [EW24] and RAG data [LPP+20].\nTo protect training data, DP-SGD [ACG+16] uses DP optimizer to ensure data privacy, severing as the traditional baseline method. Recently, numerous works have aimed to improve this method by integrating DP in both the pre-training and fine-tuning stages of LGMs [YNB+21, LTLH21, GAW+22, BEPP22, SSC+22, MJW+22, SAMB24, ZSZ+24, LLB+24]. To protect user/system prompts, [EW24] provides a survey on both DP and non-DP methods. In the use of LGMs, prompting methods almost become a standard way for inference [SIB+24]. Given the billions of prompt interactions daily, ensuring privacy is essential [MYH+23]."}, {"title": "2.3 Cross-Attention in System Prompt, RAG, Stable Diffusion and More", "content": "Cross-attention [VSP+17], first introduced in language translation, is a widely used technique in many advanced AI systems. For example, Stable Diffusion [RBL+22] and SORA [Ope24b] employ cross-attention as a core module for a text-to-image conditional generation. This technique is also utilized by other multimodal models [GLS+24b], including Imagen [SCS+22] and Diffusion Transformer [PX23].\nIn the realm of text-to-image editing, [HMT+22] analyzes and controls the cross-attention module to enable editing without requiring additional training. Furthermore, [YYB+24] tackles the issue of inaccurate cross-attention maps, enhancing fine-grained control over edited regions while preventing unintended changes to other areas.\nIn addition, Retrieval Augmented Generation (RAG) [LPP+20, BMH+22, GXG+23], a technique that improves model responses by retrieving information from a knowledge base or external documents, extensively uses cross-attention as its core design module.\nCross-attention also has other applications. [ORST23] demonstrates that the prompt-tuning [GLS+24a] task can be formulated as cross-attention, while [CFP21] uses cross-attention to fuse multi-scale features in vision transformers, thereby reducing computation. Moreover, attention-based Transformer architecture makes LGMs equipping many emergent ability [WTB+22], such as spatial reasoning [WMS+24], mathematical reasoning [GLL+24], in-context learning ability [SWXL24], compositional ability [XSL24], few-shot adaptation ability [SCL+22, XSW+23], and so on."}, {"title": "3 Preliminary", "content": "In this section, we give the preliminary of differential privacy (DP) and cross-attention. In Section 3.1, we describe the notations we use. In Section 3.2, we give several definitions related to DP. In Section 3.3, we give the DP facts we use in the paper. In Section 3.4, we show that the cross-attention module is equivalent to the weighted distance problem."}, {"title": "3.1 Notations", "content": "We use Pr[] to denote the probability. We use E[] to denote the expectation. We use Var[] to denote the variance. For two vectors $x \\in \\mathbb{R}^d$ and $y \\in \\mathbb{R}^d$, we use $\\langle x, y \\rangle$ to denote the inner product between $x,y$, i.e., $\\langle x, y \\rangle = \\sum_{i=1}^d x_iy_i$. We use $X \\subset \\mathbb{R}^d$ and $|X| = n$ to mean the same thing as $X \\in \\mathbb{R}^{n \\times d}$. Also, we denote $x_i$ as the $i$-th row of $X$. We use $x_{i,j}$ to denote the $j$-th coordinate of $x_i \\in \\mathbb{R}^n$. We use $\\mathbf{1}_n$ to denote a length-$n$ vector where all the entries are ones. We use $||x||_p$ to denote the $l_p$ norm of a vector $x \\in \\mathbb{R}^n$, i.e., $||x||_1 := \\sum_{i=1}^n |x_i|$, $||x||_2 := (\\sum_{i=1}^n x_i^2)^{1/2}$, and $||x||_{\\infty} := \\max_{i \\in [n]} x_i$."}, {"title": "3.2 Differential Privacy Definitions", "content": "In this section, we give several definitions related to differential privacy (DP). We refer the reader to [DR14] for more background and details on DP.\nDefinition 3.1 (Neighboring dataset). We define the two neighboring datasets as $X, X' \\in \\mathbb{R}^n$ such that $||X - X'||_1 \\le 1$, i.e., they differ on a single data point.\nDefinition 3.2 (Sensitivity). The sensitivity of a function $f : \\mathbb{R}^n \\rightarrow \\mathbb{R}^d$ is defined by:\n$$\\Delta := \\max_{X,X'\\in \\mathbb{R}^n,||X-X'||_1=1} ||f(X) - f(X')||_1.$$ \nDefinition 3.3 (($\\epsilon, \\delta$)-DP). For $\\epsilon > 0, \\delta \\ge 0$, a randomized algorithm $A$ is $(\\epsilon, \\delta)$-DP, if for all $S \\subseteq Range(A)$ and for all $X, X'$ such that $||X - X'||_1 < 1$:\n$$Pr[A(X) \\in S] \\le exp(\\epsilon) Pr[A(X') \\in S] + \\delta.$$ \nWhen $\\delta = 0$, the algorithm is said to have pure differential privacy.\nFor the Laplace mechanism, we have the following definitions.\nDefinition 3.4 (Laplace distribution). We use $Lap(b)$ to denote the pdf:\n$$p(z) = \\frac{1}{2b} exp(-\\frac{|z|}{b}).$$ \nFact 3.5. For $z \\sim Lap(b)$, $E[z] = 0$, and $Var[z] = 2b^2$. Furthermore, if $b = \\Delta/\\epsilon$, we have $Var[z] = 2\\Delta^2/\\epsilon^2$.\nDefinition 3.6 (Truncated Laplace distribution). We use $TLap(\\Delta, \\epsilon, \\delta)$ to denote the Truncated Laplace distribution with pdf proportional to $exp(-\\epsilon|z|/\\Delta)$ on the region $[-B, B]$, where $B = c\\cdot \\frac{\\Delta}{\\epsilon} \\cdot log(1 + exp(\\frac{\\epsilon}{\\delta})-1)$."}, {"title": "3.3 DP Facts", "content": "In this section, we present several facts about differential privacy (DP). We first state the post-processing property, which means, in an algorithm, if one step is DP, all the following steps are DP.\nFact 3.9 (Post-processing, see Fact 2.1 in [GKK+23]). Let $A_1$ be an $(\\epsilon, \\delta)$-DP algorithm and $A_2$ be a (randomized) post-processing algorithm. Then the algorithm $A(X) = A_2(A_1(X))$ is still an $(\\epsilon, \\delta)$-DP algorithm.\nIf we have many DP algorithms, we need a composition rule. The most straightforward composition is the basic/sequential composition rule.\nFact 3.10 (Basic composition, see Fact 2.3 in [GKK+23]). Let $A_1$ be an $(\\epsilon_1, \\delta_1)$-DP algorithm and $A_2$ be an $(\\epsilon_2, \\delta_2)$-DP algorithm. Then $A(X) = (A_1(X), A_2(A_1(X), X))$ is an $(\\epsilon_1 + \\epsilon_2, \\delta_1 + \\delta_2)$-DP algorithm.\nWe can do much better if we know that the inputs are disjoint.\nFact 3.11 (Parallel composition, see Fact 2.4 in [GKK+23]). Let $A_1$ be an $(\\epsilon_1, \\delta_1)$-DP algorithm and $A_2$ be an $(\\epsilon_2, \\delta_2)$-DP algorithm. Assume $A_1$ and $A_2$ depend on disjoint subsets of input coordinates. Then the algorithm $A(X) = (A_1(X), A_2(A_1(X), X))$ is a $(\\max{\\epsilon_1, \\epsilon_2}, \\max{\\delta_1, \\delta_2})$-DP algorithm.\nIn addition, we have the advanced composition, which improves the dependence of the number of DP algorithms to square root but compromises the term $\\delta'$.\nTheorem 3.12 (Advanced composition, see Theorem 3.20 in [DR14]). For all $\\epsilon,\\delta,\\delta' > 0$, the class of $(\\epsilon, \\delta)$-differentially private mechanisms satisfies $(\\epsilon', k\\delta + \\delta')$-differential privacy under k-fold adaptive composition for:\n$$\\epsilon' = k\\epsilon(e^{\\epsilon} - 1) + \\epsilon\\sqrt{2k log(1/\\delta')}.$$ \nComparison of truncated Laplace, Gaussian, and Laplace mechanisms In this paper, we use the Chebyshev inequality to bound the error, and from [GDGK20], we know that the truncated Laplace mechanism has the current minimum variance across all $(\\epsilon, \\delta)$-DP distributions.\nThe variance of Gaussian mechanism in Theorem 3.22 in [DR14]:\n$$Var = \\frac{2\\Delta^2 log(1.25/\\delta)}{\\epsilon^2}$$"}, {"title": "3.4 Cross-Attention", "content": "Let $Q, K, V, \\phi, Attn$ be defined in Definition 1.1. We can access $K$ and $V$ before cross-attention inference but not user input $Q$. For the attention mechanism $Attn$ (Definition 1.1), matrix $AV$ can be made DP.\nNow, we describe how we can use our techniques to solve this problem. Let $A_{i,j} = \\phi(Q_i, K_j)$ for $i \\in [m], j\\in [n]$. Let $V_{j,k} \\in \\mathbb{R}$ be the $(j, k)$-th entry of $V$, for $j \\in [n], k \\in [d]$.\nIn the following discussion, we focus on $\\phi$ being the exponential inner product/softmax case, so we have $\\phi(Q_i, K_j) = exp(\\langle Q_i, K_j \\rangle/d)$.\nBy post-processing (Fact 3.9), we only need to make $AV$ DP, where the $(i, k)$-th entry of $AV$ for each $i \\in [m], k \\in [d]$ can be computed by\n$$(AV)_{i,k} = \\sum_{j=1}^n \\phi(Q_i, K_j)V_{j,k} = \\sum_{j=1}^n V_{j,k} exp(\\langle Q_i, K_j \\rangle/d),$$ \nwhich can be viewed as a weighted softmax problem, where $V$ is the weights, $Q$ is the query, and $K$ is the dataset. Thus, we only need to add noise to $K$. Furthermore, we find that we can only handle one column of $V$, $V_{\\ast,k} \\in \\mathbb{R}^n$, in one data structure. Therefore, we need to initialize a total of $d$ different DPTREESOFTMAXADAPTIVE (Alg. 4) structures, each with weights $V_{\\ast,k}$ for $k \\in [d]$."}, {"title": "4 Main Results: DPTree", "content": "In this section, we provide the main results for our data structures: DPTREE (Algorithm 1 and 2), DPTREESOFTMAX (Algorithm 3), and DPTREESOFTMAXADAPTIVE (Algorithm 4). In Section 4.1, we give our basic building block algorithm DPTREE. In Section 4.2, we present ourDPTREESOFTMAX algorithm that can solve the weighted softmax problem. In Section 4.3, we present our DPTREESOFTMAXADAPTIVE algorithm that enables DPTREESOFTMAX to handle adaptive query problem."}, {"title": "4.1 DPTree Initialization and Query", "content": "We design a basic data structure DPTREE (Algorithm 1 and 2) that can answer summation queries by a summation segment tree with truncated Laplace noise. The algorithm first builds a binary summation tree in an array and then adds truncated Laplace noises to each node (Algorithm 1). In query time, we first trace from bottom nodes to find their lowest common ancestor, then report the summation by using at most $O(log n)$ nodes on the path (Algorithm 2)."}, {"title": "4.2 Softmax Activation", "content": "In this section, we present the algorithm (Algorithm 3) that can answer the weighted softmax query (Definition 4.1) and can be further used to design DP cross-attention. First, we introduce the definition of weighted softmax query, which is also an abstraction for the problem described in Section 3.4.\nDefinition 4.1 (Softmax query). Let $\\phi$ be the distance measurement function defined in Definition 1.1. For the dataset $X \\in [0, R]^{n\\times d}$ where $x_i$ is the $i$-th row of $X$ and query $y \\in [0, R]^d$, we define the weighted exponential inner product/softmax query to be:\n$$\\sum_{i\\in [n]} w_i\\phi(x_i, y) = \\sum_{i\\in [n]} w_i exp(\\langle x, y \\rangle/d) = w^T exp(Xy/d).$$ \nBased on the Definition 4.1, we design a novel algorithm that can make weighted softmax query DP. More details can be found in Section G.\nTheorem 4.2 (Softmax query, informal version of Theorem G.8). Let $R > 1$. Let $r < \\frac{R^i}{(2s+2d)\\sqrt{j!}}$ and $s = O(\\max{log(log(1/\\delta)/R), (log(1/\\delta)/R), R^2})$. Let $\\Gamma_{R,s} := \\max_{j\\in [s]} \\frac{R^i}{j!}$ (Definition G.3). Let the accuracy parameter be $\\epsilon_s \\in (0,0.1)$. There is a data structure DPTREESOFTMAX (Algorithm 3) that uses $O(nr)$ spaces to solve softmax query problem for dataset $X \\subset [0, R]^d$ and support the following operations:\n\\bullet INIT($X \\subset [0, R]^d$, $n \\in \\mathbb{N}^+$, $w \\in [-R_w, R_w]^n$, $\\epsilon \\in (0,1)$, $\\delta \\in (0,1)$, $\\delta' \\in (0,1)$, $c\\in (0,0.1)$, $\\epsilon_s \\in (0,0.1)$). (Algorithm 3) It takes $O(nr)$ time to initialize the data structure."}, {"title": "4.3 Adaptive Query Data Structure", "content": "We can now present the theorem for our data structure that can answer weighted softmax queries with a DP guarantee and concrete error bound, and it is robust to adaptive queries. The corresponding proofs can be found in Section F and Section G.\nTheorem 4.4 (Adaptive query softmax data structure, informal version of Theorem G.11). Let $R > 1$. Let $r < \\frac{R^i}{(2s+2d)}$ and $s = O(\\max{\\sqrt{j!}}\\log(log(1/\\delta)/R), R^2})$. Let $\\Gamma_{R,s} := \\max_{j\\in [s]} \\frac{R^i}{j!}$ (Definition G.3). Let the accuracy parameter be $\\epsilon_s \\in (0,0.1)$. Let $X \\in [0, R]^{n\\times d}$ be the dataset, $w\\in [-R_w, R_w]^n$ be weights, $y \\in [0, R]^d$ be the query, $\\alpha \\in (0,1)$ be the relative error parameter and $p_f$ be the failure probability parameter. Let $l = O(r log(dR/(\\epsilon_s p_f)))$. There is a data structure DPTREESOFTMAXADAPTIVE (Algorithm 4) that uses $O(lnr)$ spaces to solve the weighted softmax query problem for the dataset $X \\subset [0, R]^d$ and supports the following operations:\n\\bullet INIT($X \\subset [0, R]^d$, $n \\in \\mathbb{N}^+$, $w \\in [-R_w, R_w]^n$, $\\epsilon \\in (0,1)$, $\\delta \\in (0,1)$, $\\delta' \\in (0,1)$, $c\\in (0,0.1)$, $\\epsilon_s \\in (0,0.1)$, $p_f \\in (0,0.01)$). (Algorithm 4) It takes $O(lnr)$ time to initialize the data structure.\n\\bullet DISTANCEQUERY($y \\in [0, R]^d$, $\\alpha \\in (0,1)$). (Algorithm 4) It takes $O(\\alpha^{-1}lr log^2n)$ time to output a number $z$ such that"}, {"title": "5 Main Results: Cross-Attention", "content": "In this section, we show our main result for cross-attention. Theorem 5.1 states that we can make the cross-attention module DP.\nTheorem 5.1 (Cross-attention, informal version of Theorem G.12). Let $Q, K, V, \\phi, Attn$ be defined in Definition 1.1. Let $\\alpha \\in (0,1)$ be the relative error parameter and $p_f$ be the probability of failure parameter. Let $r, s, \\epsilon_s$ be the parameters of the polynomial kernel methods (Lemma 6.7). Let $\\Gamma_{R,s} := \\max_{j\\in [s]} \\frac{R^i}{j!}$ (Definition G.3). Let $l = O(r log(dR/(\\epsilon_s p_f)))$. Let $\\phi$ be softmax function (Definition 4.1). There is a data structure DPTREESOFTMAXADAPTIVE (Algorithm 4) that uses $O(lnrd)$ spaces to make cross-attention DP and supports the following operations:\n\\bullet We initialize $d$ data structures using INIT($K, n, V_{\\ast,k}$, $\\epsilon \\in (0,1)$,$\\delta\\in (0,1)$, $\\delta' \\in (0,1)$, $c\\in (0,0.1)$, $\\epsilon_s \\in (0,0.1)$,$p_f \\in (0,0.01)$) (Algorithm 4), for $k \\in [d]$. It takes $O(lnr)$ time to initialize one data structure.\n\\bullet At query time, for user input $Q$, we process one token at a time by passing the $i$-th row of $Q$, denoted $Q_i \\in \\mathbb{R}^d$, to DISTANCEQUERY($Q_i, \\alpha \\in (0,1)$) (Algorithm 4) for each $i\\in [m]$. It takes $O(\\alpha^{-1}lr log^2n)$ time to output an entry $z$ in $Attn(Q, K, V)$ such that"}, {"title": "6 Technique Overview", "content": "This section provides the technique overview of our paper. In Section 6.1, we analyze our DPTREE data structure. In Section 6.2, we show the sensitivity of summation problem. In Section 6.3, we explain the high-level idea behind the weighted $l_1$ distance query. In Section 6.4, we show how to answer one-dimensional weighted $l_1$ distance query. In Section 6.5, we show how to answer softmax distance query using previous algorithms. In Section 6.6, we show how to handle adaptive query. By combining the results from these sections, we prove the main results in Section 4."}, {"title": "6.1 Summation Segment Tree", "content": "First, in order to solve the weighted distance problem, we need to have a basic DP algorithm (Algorithm 1 and 2) that can answer simple summation queries. After analyzing its DP and error in Section B, we state the data structure theorem.\nTheorem 6.1 (DPTREE data structure, informal version of Theorem B.1). There is a data structure (see DPTREE in Algorithm 1, 2) that uses $O(n)$ spaces to support the following operations:\n\\bullet INIT($a \\in \\mathbb{R}^n$, $n\\in\\mathbb{N}^+$,$\\Delta\\in\\mathbb{N}^+$, $\\epsilon\\in (0,1)$, $\\delta\\in (0,1)$). It takes $O(n)$ time to initialize the data structure.\n\\bullet QUERY($x \\in [n]$, $y \\in [n]$). It takes $O(\\log n)$ time to output a number $z$ such that\n$z$ is $(\\epsilon, \\delta)$-DP private of $\\sum_{i=x}^y a_i$,\n$|z - \\sum_{i=x}^y a_i| \\le O(\\epsilon^{-1}\\Delta \\log^{3/2}n)$,\nit holds with probability 0.99.\nDuring the design of the data structure, we found an interesting property based on the parallel composition rule of DP Fact 3.11. We will now state the lemma with its proof provided in Section B.\nLemma 6.2 (Weighted sum of disjoint interval queries, informal version of Lemma B.8). If the following conditions hold that:\n\\bullet Let there be $t$ disjoint intervals, i.e., $S_j$ for $j \\in [t]$, such that $S_j \\cap S_k = \\emptyset$ for all $j \\neq k$.\n\\bullet Let $\\epsilon \\in (0,1)$ and $\\delta \\in (0,1)$."}, {"title": "6.2 Sensitivity for Range Summation Problem", "content": "Our DP summation tree data structure DPTREE (Algorithm 1 and 2) requires sensitivity parameter $\\Delta$. In this section, we show that for the summation problem, we have the sensitivity $\\Delta = 2R$ if the input $X \\in [-R, R]^n$.\nLemma 6.3 (Sensitivity of summation). Let $X \\in [-R, R]^n$. We have the sensitivity $\\Delta = 2R$ for DPTREE.INIT in Algorithm 1.\nProof. Let's say 2 neighboring dataset $X$ and $X'$ differ in $x_i$ and $x'_i$ for some $i$ in the array $X$. Then for a summation problem, i.e. $f(X) := \\sum_{i=1}^n x_i$, we have\n$$\\Delta = \\max_{X,X'} |f(X) - f(X')| = \\max_{X,X'} |x_i - x'_i| = 2R.$$"}, {"title": "6.3 Weighted \\(l_1\\) Distance Problem", "content": "In this section, we introduce the intuition behind the method for handling the weighted $l_1^p$ distance problem. The formal lemmas and proofs can be found in Section C."}, {"title": "6.4 One-Dimensional Weighted \\(l_1\\) Distance Data Structure", "content": "Based on previous discussions in Section 6.1 and 6.3, we can now describe our one-dimensional weighted $l_1$ distance data structure, DPTREEDISTANCE, presented in Algorithm 6 and 7, which generalizes the results from [BLM+24]. Drawing from the intuition in Section 6.3, the initialization process is as follows: first, we round each data point in the dataset to the nearest multiple of a small interval and build an array that aggregates the corresponding weights. This array is then fed into our DPTREE data structure in Algorithm 1. At query time, we query the DPTREE to obtain the aggregated weights within a small interval and multiply these weights by the distance to the query point. Furthermore, we also introduce a relative error parameter $\\alpha$ to reduce the total number of queries to $O(\\log(n)/\\alpha)$ instead of querying all $n$ positions. We also analyze the DP and the error bound; see details in Section D."}, {"title": "6.5 Softmax Activation", "content": "We then describe how we extend the previous results to softmax activation, i.e. exponential inner product function (Definition 4.1). From [AS23], we know that softmax activation can be approximated by polynomial kernel function $P(\\cdot)$ with a certain error. The following lemma shows that we can transform weighted softmax queries into polynomial kernels. More specifically, we have one term that computes the weighted $l_2$ distance, which is the place where we add DP noises. Because of the decomposability of the $l_1$ distance, i.e. $\\sum_{i\\in [n]} w_i||x_i - y||_p = \\sum_{j\\in [d]} \\sum_{i\\in [n]} w_i|x_{i,j} - y_j|^p$, we can easily extend the results of Section 6.4 to handle the $l_2$ distance query. After that, we compute the term for the weighted $l_2$ norms of approximation kernel exactly. Summing all these terms, with a certain error, we can answer the softmax query. Related proofs can be found in Section G.\nLemma 6.7 (Weighted softmax approximation, informal version of Lemma G.6). Let the accuracy parameter be $\\epsilon_s \\in (0,0.1)$. Let $R > 1$. Let $r < \\frac{R^i}{(2s+2d)}$ and $s = O(\\max{log(log(1/\\delta)/R), R^2})$. Let $\\Gamma_{R,s} := \\max_{j\\in [s]} \\frac{R^i}{j!}$ (Definition G.3). Let $P(x) : [0, R]^d \\rightarrow [0,\\Gamma_{R,s}]^r$ be the $s$-th order polynomial kernel function defined in Lemma G.5. Then, we can approximate the exponential inner product using the polynomial kernel function:\n$$w^T exp(Xy/d) = -\\frac{1}{2} \\sum_{j\\in [r]} \\sum_{i\\in [n]} w_i|P(x_i)_j - P(y)_j|^2 + \\frac{1}{2} \\sum_{i\\in [n]} w_i(||P(x_i)||^2 + ||P(y)||^2)\n+ O(w^T exp(Xy/d) \\cdot \\epsilon_s).$$\nMoreover, the vectors $P(\\cdot)$ can be computed in $O(r)$ time."}, {"title": "6.6 Adaptive Query", "content": "We introduce how we can modify our algorithm to solve the adaptive query problem using some tools in [QRS+22]. Our approach is based on proving that our algorithm can handle any query within the query space with a certain error. Since adaptive queries must lie within this space, our algorithm can effectively handle them. In Section 6.5, we demonstrate our algorithm's capability to answer weighted softmax distance queries with constant probability. We then use the Chernoff bound to boost the constant probability of our algorithm to a high probability. Next, we apply the notion of an $\\epsilon$-net to bound all query points within the net using the union bound. Finally, we bound all points in the query space by utilizing the Lipschitz property of the weighted softmax distance function and introducing an additive error. See the proofs in Sections F and G."}, {"title": "7 Discussion", "content": "How do we extend to self-attention? As self-attention is a more fundamental module in LGMs, we would like to extend our data structure to this setting. However, the challenge we faced was the dynamic update in tree nodes for each query for self-attention, which our current analysis does not support. How we can solve this challenge is crucial, and we leave it as our future direction.\nWhy not add noise in some other places? Where and how to add DP noises is an important problem to ask during the DP algorithm design. In this paper, we consider the problem of $\\sum_{n=1}^i w_i exp((x_i, y)/d)$ where $y, x_i \\in [0, R]^d$ and $w \\in [-R_w, R_w]^n$ (Definition 4.1). Notice that the only place where we add noises is in the most basic building block data structure DPTREE (Algorithm 1 and 2). From Lemma 6.3 and the way we initialize DPTREE in Algorithm 6, we can see that the sensitivity $\\Delta$ of this problem is $2R_w$.\nA simple method for adding noise involves adding n noises to a length n array, with each item $w_i exp((x_i, y)/d)$ for $i \\in [n]$. However, this approach increases the error by a factor of n by basic composition (Fact 3.10) and also makes the model dependent on the number of queries. Besides, it only supports a single query and requires rebuilding the tree for each new query, rendering it impractical.\nIn contrast, our current noise-adding technique (Lines 11 and 17 of Algorithm 1) utilizes a summation tree such that the error only increases by a factor of $poly log n$. This method also supports multiple queries, eliminating the need to rebuild the tree each time."}, {"title": "8 Conclusion", "content": "To our knowledge, we are the first work to provide differential privacy for cross-attention. This paper presents the DPTREE data structures, which provide a differential privacy guarantee for the cross-attention module in large generative models. This is achieved by transforming the cross-attention mechanism into a weighted distance problem. Furthermore, our algorithm is robust to adaptive queries, allowing users to interact with the model arbitrarily without extracting sensitive information from the system prompts or RAG data. Our results may inspire more privacy algorithm design in large generative models."}]}