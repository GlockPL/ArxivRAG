{"title": "Generalized knowledge-enhanced framework for\nbiomedical entity and relation extraction", "authors": ["Minh Nguyen", "Phuong Le"], "abstract": "In recent years, there has been an increasing number of frameworks\ndeveloped for biomedical entity and relation extraction. This research effort aims\nto address the accelerating growth in biomedical publications and the intricate\nnature of biomedical texts, which are written for mainly domain experts. To handle\nthese challenges, we develop a novel framework that utilizes external knowledge\nto construct a task-independent and reusable background knowledge graph for\nbiomedical entity and relation extraction. The design of our model is inspired\nby how humans learn domain-specific topics. In particular, humans often first\nacquire the most basic and common knowledge regarding a field to build the\nfoundational knowledge and then use that as a basis for extending to various\nspecialized topics. Our framework employs such common-knowledge-sharing\nmechanism to build a general neural-network knowledge graph that is learning\ntransferable to different domain-specific biomedical texts effectively. Experimen-\ntal evaluations demonstrate that our model, equipped with this generalized and\ncross-transferable knowledge base, achieves competitive performance benchmarks,\nincluding BioRelEx for binding interaction detection and ADE for Adverse Drug\nEffect identification.\nKeywords: Knowledge graph Information extraction Biomedical text", "sections": [{"title": "Introduction", "content": "A tremendous increase in the number of biomedical publications in recent years [7]\nmakes it difficult for biomedical researchers to keep up with latest articles. Consequently,\nnumerous studies such as [16,23,20,14,21,22] in applied deep learning and natural lan-\nguage processing are dedicated towards automatic extraction of biomedical entities and\ntheir relations. To validate and enhance these applied machine learning (ML) efforts,\nseveral tasks and datasets regarding this topics have also been developed. These include\ntasks such as: binding interaction detection BioRelEx [11], adverse drug effect ADE\n[8], drug-drug interaction DDI [9], and bacteria biotope task BB-rel [4], each targeting\nspecific aspects of biomedical research.\nCompared to understanding general text, information extraction of biomedical text\ndocuments requires much broader domain knowledge since these documents contain\nmany technical terms usually intended only for domain experts [6]. To successfully\nperform the joint tasks of entity and relation extraction, the resulting models need to"}, {"title": "Related-works", "content": "For domain-specific document understanding, an advanced strategy is to learn not only\nfrom the given input texts but also from the external domain knowledge that supports the\ncomprehension of complex terms. The external knowledge is obtained via a secondary\nsource of texts different from the original inputs. Many machine learning models la-\nbeled as knowledge-enhanced models have been developed based on this approach. For\ninstance, Peters et al. [17] develop the KnowBertAttention, a state-of-the-art knowledge-\nenhanced language model. KnowBertAttention makes use of SciBERT [2] for token-level\nrepresentations and employs the KAR mechanism to introduce external knowledge from\nUMLS. Lai et al. [13] proposes a knowledge-enhanced model with collective inference\ncalled KECI. Instead of only extracting features as in KnowBertAttention, KECI injects\nknowledge from UMLS, makes use of multi-relational graph structure of candidate\nentities, and integrates more global information to the representations.\nBelow, we provide more details on KECI model, outlining the framework's individual\nsteps which typically align with those taken by knowledge-enhanced models:\n1. The KECI model initially processes task-specific input documents using text em-\nbeddings from [2]. It then constructs a knowledge graph using bidirectional Graph\nConvolutional Networks (GCN). The outputs of this step comprises feature vectors\nfor all relevant biomedical entities.\n2. Next, the model utilizes external text sources such as UMLS [3] to establish a\nbackground knowledge graph (KG), following a procedure similar to the first step.\nHere, the outputs also consist of feature vectors for biomedical entities; however,\nthese entities are sourced from UMLS instead of the original input data.\n3. Finally, KECI integrates feature vectors from the task dataset with feature vectors of\nrelevant entities in the external knowledge dataset to make the final predictions."}, {"title": "Motivations and contributions", "content": "One potential problem with these approaches is the waste of external knowledge and\nresources. For instance, in KECI [13], the training of the background knowledge graph\n(KG) is based on a loss function that is task-dependent. Thus, this approach requires\nrebuilding the KG entirely for each new task, despite the knowledge being commonly\napplicable and shareable across different tasks. Moreover, KECI uses MetaMap [1] to"}, {"title": "Methods", "content": "In this section, we provide details of our generalized background knowledge graph\nframework that can then be utilized efficiently across entity and relation extraction tasks."}, {"title": "Overview", "content": "Generalized Background Knowledge. Our model aims to build a generalized back-\nground knowledge graph that allows common knowledge to be shared across tasks.\nOur graph include two components: general-knowledge (GK) component and specific-\nknowledge (SK) component. Entities and relations in our general knowledge (GK)\ncomponent remain unchanged regardless of specific tasks. For GK component, we el-\nevate biomedical language models to build a 'graph-like' structure independent of the\ninput data. For the second (SK) component, we process the given input documents for a\nspecific tasks to build relevant neural-network graphs of entities, and then joins this SK\nwith the first GK component."}, {"title": "General-Knowledge (GK) Component", "content": "To construct the General-Knowledge (GK) Component, we need to obtain general en-\ntities representations encoding both label and relational information without having to\nbuild and train GCN."}, {"title": "Extracting relational data", "content": "We first start by utilizing BioBERT to extract relational\ninformation from entities within the knowledge source data.\nSuppose we're given a set of relations {rk}k=1R, where R is the number of possible\nrelations, and the triplets consisting of subject, relation and object {(si, rk, 0j)}. We\napply BioBert embedding to get a set of associated weights that indicate how likely each\nrelation rk will match the subject-object pair (si, oj), where i and j run over all possible\nindices of the subjects and objects sets.\nFor this weight extraction, we start with masking techniques to form four possible\nhypothetical sentences:\n\u2013 Sentence with relation masked: A = si [MASK] 0j\n\u2013 Sentence with object masked: B = si rk [MASK]\n\u2013 Sentence with subject masked: C = [MASK] rk Oj\n\u2013 Sentence with no mask: D = si rk Oj\nSuch maskings support the inference process of the remaining entity from two known\nother entities, and hence implicitly extract the relational information. For instance, to fill"}, {"title": null, "content": "in the mask in the first sentence (sentence A), the model needs to approximate a function\nr = g(s, o) so that rk = g(si, 0j) approximates rk. The function g provides insights\ninto how a relation can fit in a given pair of (subject, object).\nNow from such for (masked) sentences A, B, C, D, we use a geometric argument to\ncalculate the expected weight indicating how much a relation rk will match with the\npair of (subject, object). First of all, we convert each sentence into an embedding so that\nwe can get corresponding vectors to perform mathematical operations. For this step, we\napply BioBert model to obtain the corresponding embeddings VA, VB, VC, VD.\nNext, for each sentence above, we apply BioBERT to obtain its vector representa-\ntion VA, VB, VC and VD respectively. Mathematically, VA can be represented as the\nordered sum v(si) + v(rk) + v(oj), where rk is the predicted relation to fill in the blank\nof the sentence with subject si and oj. Similarly, vB = v(si) + v(rk) + v(\u00f4j), and\nvc = v($i) + v(rk) + v(oj), where \u015di and \u00f4j are the predicted object and subject given\nthat two other entities are known."}, {"title": null, "content": "We then perform the geometric vector operation VE = VB + VC VA. Here E can be\nconsidered as the remaining vertex of the parallelogram with existing vertices A, B, C.\nThis geometric operations will yield an approximate embedding of the predicted sentence\nE = sirk\u00f3j with both predicted subject \u015dj, predicted object \u014dj, and predicted relation\nrk. The approximation is due to the equation:\nVB + VC - VA = v(\u015di) + v(rk) + v(\u00f4j) + 2(v(rk) \u2013 v(rk)) (1)\nNow to predict how likely the relation rk fit in, we calculate the difference between the\noriginal sentence D = si rk Oj and its predicted counterpart E = by simply taking the\ncosine similarity between their embedding: \u0175(si, rk, 0j) = cos(VD, VE). See Figure 1\nfor an illustration of the above construction."}, {"title": null, "content": "Here we regard E as BioBERT's 'ground truth' on the supposed subject, object, and\nassociated relation (or at least related entities). Thus, when D is compared with E, the\ncosine similarity reflects BioBERT's estimate on how close the hypothesis sentence D\nis to its prediction. The higher the cosine similarity, the more likely that the relation rk\nis correct for pair (si, rk, 0j). Our construction ensures that all 3 components subject,\nobject, and relation are taken into account equally."}, {"title": "Entities representation training", "content": "Based on the weights \u0175(si, rk, 0j) obtained from\nprevious procedure, we train a feed-forward neural network (FFNN) to encode this\nrelational weights into the entities representations. In particular, we start by taking union\nover all entities to get a set of distinct entities, each of which is fed into BioBERT model\nto get its associated initial embedding. Next, we train the FFNN f with the following\nloss function:\nR\nL(0) = \u03a3\u03a3) \u03a3\u03a3 (8) - \u03a3\u03a3, W (Si, koj) f(oj)12 (2)\nSi k=1\nOj\nwhere f (si) and f (oj) is the output vector representations of subject si and object oj that\ntake relation weights into account. The final embedding for each entity is a concatenation\nof the initial embedding from BioBERT and the (relational) embedding f(.) obtained\nfrom this training."}, {"title": "Specific-knowledge (SK) component and fusion with GK component", "content": "For the SK component, we follow the standard procedure to obtain a graph neural\nnetwork between entities from the training input documents for a specific task. More\nspecifically, we obtain all possible entities from given input documents. We build a graph\nconvolutional network (GCN) [12] on the entities excluding those in GK component\n(from Section 2.2). At this point, we have a GCN containing information specific to a\ntask, together with the reusable GK component containing \"general\" entity encodings"}, {"title": null, "content": "that already carry their relation information. To perform the fusion, we train an additional\nGCN that connects the nodes in the specific task's graph to those in the graph from the\nGK component. No edge in the GK component need to be included in this additional\nfusion GCN. The relations of entities in the GK component are, in fact, independent of\nthe downstream tasks. Figure 2 above presents a simplified pipeline for this process."}, {"title": "Experiments", "content": null}, {"title": "Data sources and tasks", "content": "Sources data. We use two data sources for the first GK component in our framework.\nThe first data source is UMLS, which includes Metathesaurus and Semantic Network.\nMetathesaurus provides information about millions of biomedical concepts and rela-\ntions between them. By using MetaMap, the entity mapping tool for UMLS, we can\nextract relevant UMLS biomedical entities from any input document. Semantic Net-\nwork, together with Metathesaurus, will then provide relevant relations between those\nbiomedical entities. We note that the UMLS used in Section 2.2 is a simplified and\nprocessed version from [18], where the author investigates whether LMs can be used as\nbiomedical KB. We group the relations by similarity and further reduce to a total of 5\nrelation properties including: drug used for treatment, physiologic effect, has symptoms,\nclinically associated, and drug agent. The second data source we look at is Wikidata 3, a\npublic knowledge base with items across domain. The version of Wikidata used, which\ncontains only biomedical entities and relations, is also from [18].\nTasks. We evaluate our framework using two biomedical datasets: BioRelEx and ADE.\nThe ADE data contains 4272 sentences (from medical reports) that describe drug-related\nadverse effects. ADE has 2 entity types (Adverse-Effect and Drug) and a single relation\ntype (Adverse-Effect). The BioRelEx is a collection of biomedical literature that capture\nbinding interactions between proteins and/or biomolecules. It has 2010 sentences, 33\nentity types, 3 relation types for binding interaction."}, {"title": "Baselines", "content": "We compare our method against state-of-the-art methods for both BioRelEx and ADE\ndatasets. For evaluation, we use F-1 scores on entity and relation extraction for both\nBioRelEx and ADE. Baseline models include:\n1. Three previous models on entity and relation extraction: Relation-Metric [19],\nSpERT [5], and SPANMulti-Head [10].\n2. SentContextOnly: This baseline uses only local context for prediction and does\nnot use any external knowledge. It comes directly from the initial span graph\nconstruction step of KECI model.\n3. FlatAttention: This baseline does not use collective inference approach. As a result,\nthe entity representation does not encode global relational information."}, {"title": "Entities and relations extraction results", "content": "We train-test with 1-fold and provide the highest result within 50 epochs. Table 1 shows\nresults on test sets of ADE data for both sources Wikidata and UMLS. In addition,\nFigure 3 shows the testing results of using Wikidata as source across 20 epochs and\nwhen it outperforms the baselines, and Table 2 shows results on dev sets of BioRelEx\nwith UMLS as source data in comparison to other baselines."}, {"title": null, "content": "Overall, we see that an improvement in runtime when running KECI framework versus\nour framework. This is expected as with our training process, we don't need to retrain\na significant part of the knowledge graph when dealing with specific tasks. Moreover,\nour model outperforms all baselines for ADE data set (using both sources) and matches\nclosely for BioRelEx. We remark that the size of two sources differ vastly (1200 distinct\nentities for Wikidata to 9726 distinct entities for UMLS), and these two datasets focus\non two distinct subfields of the biomedical domain. As a result, our model's performance\neffectively demonstrates the power of our approach to reuse knowledge across tasks and\nits potential to be generalized to more tasks."}, {"title": "Discussion", "content": null}, {"title": "Relation weights extraction", "content": "Table 3 presents the results on extracting relation weights and predicting relation for\nthe first GK component of our framework. We note that only correct predictions will be\nused in the later step of training FFNN. In addition, since we are using MetaMap and\nUMLS to build the initial span graph, for Wikidata, we can only use entities where we\ncan identify the CUID. As a result, the available entities from Wikidata greatly reduces\ncompared to that of UMLS."}, {"title": null, "content": "weights for the subject si meningitis (a disease), its two asssociated objects, which are\ndrugs for the disease's treatment: 0\u2081 = ceftriaxone and 02 = amikacin, and finally the\nthird object, which is the associated symptom 03 = headache. Here, we observe that\nceftriaxone has a higher weights than amikacin for being the appropriate drug used for\nthe disease meningitis. This observation is validated by the fact that ceftriaxone is a\nmore common antibiotics for meningitis than amikacin."}, {"title": "Contribution of GK component", "content": "We investigate how much re-usability the GK component contributes to the overall\nknowledge graph. To estimate such contribution, we count the number of distinct entities\nand the number of nodes/entities that frequently appear within the ADE dataset (nodes\nappearing in more than 10 sentences). Table 4 shows how much the GK component built\nby Wikidata and UMLS contributes to the total number of entities in ADE."}, {"title": null, "content": "Our observations indicate that the GK component contributes more to the more-frequent\nentities within the dataset. We believe that contributing and interacting with frequent\nentities is one of the key points enabling our framework to produce matching results\nwith other baselines without the need to train the whole GCN. Moreover, as we increase\nthe size of the GK, the overall results stay quite stable and very close to those of KECI.\nThis suggests that the relational embeddings obtained in Section 2.2 and Section 2.3\neffectively capture relational information, performing comparably well compared to\ntraining a full GCN.\nFor BioRelEx dataset, we currently utilize a smaller and simplified subset of UMLS.\nThis might leave out more important/frequent entities of this data set, and thus increasing\nthe size of UMLS can help our approach closely match KECI model's performance on\nrelation extraction for BioRelEx. Moreover, as shown in Table 4, approximately 20% of\nnodes can already be reused, highlighting a significant amount of reusable information.\nMoreover, our framework achieves an accuracy on the ADE dataset that is only 0.09%\nbelow that of using UMLS as a source for entity extraction, while outperming all other\nbaselines in relation extraction. These observations further illustrate that our approach,\nwhich aim to build a universal and task-independent background knowledge, can be\nfurther extended to a larger scale to enhance its applicability and performance across\ndiverse biomedical tasks."}, {"title": "Conclusion and Future Works", "content": "In this work, we introduce a knowledge-enhanced model supported by two components:\nGK (general-knowledge) and SK (specific-knowledge). We apply this model to different\nbiomedical information extraction tasks and demonstrate competitive results on both\nADE and BioRelEx datasets. The GK component of our framework serves as an effec-\ntive general knowledge graph that proves reusable across multiple customized tasks.\nExperimental results on ADE and BioRelEx datasets also indicate potential scalability\nof our framework to broader applications. In the future, we plan to extend the framework\nin two directions. Firstly, we aim to expand on our GK component to improve both the\nprediction accuracy and also its re-usability on specific tasks. The second direction is to\napply our framework to other research areas beyond biomedical fields such as literature,\nhistory, and architecture."}]}