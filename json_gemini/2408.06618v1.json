{"title": "Generalized knowledge-enhanced framework for biomedical entity and relation extraction", "authors": ["Minh Nguyen", "Phuong Le"], "abstract": "In recent years, there has been an increasing number of frameworks developed for biomedical entity and relation extraction. This research effort aims to address the accelerating growth in biomedical publications and the intricate nature of biomedical texts, which are written for mainly domain experts. To handle these challenges, we develop a novel framework that utilizes external knowledge to construct a task-independent and reusable background knowledge graph for biomedical entity and relation extraction. The design of our model is inspired by how humans learn domain-specific topics. In particular, humans often first acquire the most basic and common knowledge regarding a field to build the foundational knowledge and then use that as a basis for extending to various specialized topics. Our framework employs such common-knowledge-sharing mechanism to build a general neural-network knowledge graph that is learning transferable to different domain-specific biomedical texts effectively. Experimental evaluations demonstrate that our model, equipped with this generalized and cross-transferable knowledge base, achieves competitive performance benchmarks, including BioRelEx for binding interaction detection and ADE for Adverse Drug Effect identification.", "sections": [{"title": "1 Introduction", "content": "A tremendous increase in the number of biomedical publications in recent years [7] makes it difficult for biomedical researchers to keep up with latest articles. Consequently, numerous studies such as [16,23,20,14,21,22] in applied deep learning and natural language processing are dedicated towards automatic extraction of biomedical entities and their relations. To validate and enhance these applied machine learning (ML) efforts, several tasks and datasets regarding this topics have also been developed. These include tasks such as: binding interaction detection BioRelEx [11], adverse drug effect ADE [8], drug-drug interaction DDI [9], and bacteria biotope task BB-rel [4], each targeting specific aspects of biomedical research.\nCompared to understanding general text, information extraction of biomedical text documents requires much broader domain knowledge since these documents contain many technical terms usually intended only for domain experts [6]. To successfully perform the joint tasks of entity and relation extraction, the resulting models need to"}, {"title": "1.1 Related-works", "content": "For domain-specific document understanding, an advanced strategy is to learn not only from the given input texts but also from the external domain knowledge that supports the comprehension of complex terms. The external knowledge is obtained via a secondary source of texts different from the original inputs. Many machine learning models labeled as knowledge-enhanced models have been developed based on this approach. For instance, Peters et al. [17] develop the KnowBertAttention, a state-of-the-art knowledge-enhanced language model. KnowBertAttention makes use of SciBERT [2] for token-level representations and employs the KAR mechanism to introduce external knowledge from UMLS. Lai et al. [13] proposes a knowledge-enhanced model with collective inference called KECI. Instead of only extracting features as in KnowBertAttention, KECI injects knowledge from UMLS, makes use of multi-relational graph structure of candidate entities, and integrates more global information to the representations.\nBelow, we provide more details on KECI model, outlining the framework's individual steps which typically align with those taken by knowledge-enhanced models:\n1. The KECI model initially processes task-specific input documents using text embeddings from [2]. It then constructs a knowledge graph using bidirectional Graph Convolutional Networks (GCN). The outputs of this step comprises feature vectors for all relevant biomedical entities.\n2. Next, the model utilizes external text sources such as UMLS [3] to establish a background knowledge graph (KG), following a procedure similar to the first step. Here, the outputs also consist of feature vectors for biomedical entities; however, these entities are sourced from UMLS instead of the original input data.\n3. Finally, KECI integrates feature vectors from the task dataset with feature vectors of relevant entities in the external knowledge dataset to make the final predictions."}, {"title": "1.2 Motivations and contributions", "content": "One potential problem with these approaches is the waste of external knowledge and resources. For instance, in KECI [13], the training of the background knowledge graph (KG) is based on a loss function that is task-dependent. Thus, this approach requires rebuilding the KG entirely for each new task, despite the knowledge being commonly applicable and shareable across different tasks. Moreover, KECI uses MetaMap [1] to"}, {"title": "3 Experiments", "content": "3.1 Data sources and tasks\nSources data. We use two data sources for the first GK component in our framework. The first data source is UMLS, which includes Metathesaurus and Semantic Network. Metathesaurus provides information about millions of biomedical concepts and relations between them. By using MetaMap, the entity mapping tool for UMLS, we can extract relevant UMLS biomedical entities from any input document. Semantic Network, together with Metathesaurus, will then provide relevant relations between those biomedical entities. We note that the UMLS used in Section 2.2 is a simplified and processed version from [18], where the author investigates whether LMs can be used as biomedical KB. We group the relations by similarity and further reduce to a total of 5 relation properties including: drug used for treatment, physiologic effect, has symptoms, clinically associated, and drug agent. The second data source we look at is Wikidata 3, a public knowledge base with items across domain. The version of Wikidata used, which contains only biomedical entities and relations, is also from [18].\nTasks. We evaluate our framework using two biomedical datasets: BioRelEx and ADE. The ADE data contains 4272 sentences (from medical reports) that describe drug-related adverse effects. ADE has 2 entity types (Adverse-Effect and Drug) and a single relation type (Adverse-Effect). The BioRelEx is a collection of biomedical literature that capture binding interactions between proteins and/or biomolecules. It has 2010 sentences, 33 entity types, 3 relation types for binding interaction."}, {"title": "3.2 Baselines", "content": "We compare our method against state-of-the-art methods for both BioRelEx and ADE datasets. For evaluation, we use F-1 scores on entity and relation extraction for both BioRelEx and ADE. Baseline models include:\n1. Three previous models on entity and relation extraction: Relation-Metric [19], SpERT [5], and SPANMulti-Head [10].\n2. SentContextOnly: This baseline uses only local context for prediction and does not use any external knowledge. It comes directly from the initial span graph construction step of KECI model.\n3. FlatAttention: This baseline does not use collective inference approach. As a result, the entity representation does not encode global relational information."}, {"title": "3.3 Entities and relations extraction results", "content": "We train-test with 1-fold and provide the highest result within 50 epochs. Table 1 shows results on test sets of ADE data for both sources Wikidata and UMLS. In addition, Figure 3 shows the testing results of using Wikidata as source across 20 epochs and when it outperforms the baselines, and Table 2 shows results on dev sets of BioRelEx with UMLS as source data in comparison to other baselines."}, {"title": "4 Discussion", "content": "4.1 Relation weights extraction\nTable 3 presents the results on extracting relation weights and predicting relation for the first GK component of our framework. We note that only correct predictions will be used in the later step of training FFNN. In addition, since we are using MetaMap and UMLS to build the initial span graph, for Wikidata, we can only use entities where we can identify the CUID. As a result, the available entities from Wikidata greatly reduces compared to that of UMLS."}, {"title": "4.2 Contribution of GK component", "content": "We investigate how much re-usability the GK component contributes to the overall knowledge graph. To estimate such contribution, we count the number of distinct entities and the number of nodes/entities that frequently appear within the ADE dataset (nodes appearing in more than 10 sentences). Table 4 shows how much the GK component built by Wikidata and UMLS contributes to the total number of entities in ADE."}, {"title": "5 Conclusion and Future Works", "content": "In this work, we introduce a knowledge-enhanced model supported by two components: GK (general-knowledge) and SK (specific-knowledge). We apply this model to different biomedical information extraction tasks and demonstrate competitive results on both ADE and BioRelEx datasets. The GK component of our framework serves as an effective general knowledge graph that proves reusable across multiple customized tasks. Experimental results on ADE and BioRelEx datasets also indicate potential scalability of our framework to broader applications. In the future, we plan to extend the framework in two directions. Firstly, we aim to expand on our GK component to improve both the prediction accuracy and also its re-usability on specific tasks. The second direction is to apply our framework to other research areas beyond biomedical fields such as literature, history, and architecture.\nThe implementation is available at https://github.com/mpnguyen2/bio_kg_nlp."}, {"title": "2 Methods", "content": "2.1 Overview\nIn this section, we provide details of our generalized background knowledge graph framework that can then be utilized efficiently across entity and relation extraction tasks.\nGeneralized Background Knowledge. Our model aims to build a generalized background knowledge graph that allows common knowledge to be shared across tasks. Our graph include two components: general-knowledge (GK) component and specific-knowledge (SK) component. Entities and relations in our general knowledge (GK) component remain unchanged regardless of specific tasks. For GK component, we elevate biomedical language models to build a 'graph-like' structure independent of the input data. For the second (SK) component, we process the given input documents for a specific tasks to build relevant neural-network graphs of entities, and then joins this SK with the first GK component."}, {"title": "2.2 General-Knowledge (GK) Component", "content": "To construct the General-Knowledge (GK) Component, we need to obtain general entities representations encoding both label and relational information without having to build and train GCN.\nExtracting relational data. We first start by utilizing BioBERT to extract relational information from entities within the knowledge source data.\nSuppose we're given a set of relations $\\{r_k\\}_{k=1}^R$, where $R$ is the number of possible relations, and the triplets consisting of subject, relation and object $\\{(s_i, r_k, o_j)\\}$. We apply BioBert embedding to get a set of associated weights that indicate how likely each relation $r_k$ will match the subject-object pair $(s_i, o_j)$, where $i$ and $j$ run over all possible indices of the subjects and objects sets.\nFor this weight extraction, we start with masking techniques to form four possible hypothetical sentences:\nSentence with relation masked: $A = s_i [MASK] o_j$\nSentence with object masked: $B = s_i r_k [MASK]$\nSentence with subject masked: $C = [MASK] r_k o_j$\nSentence with no mask: $D = s_i r_k o_j$\nSuch maskings support the inference process of the remaining entity from two known other entities, and hence implicitly extract the relational information. For instance, to fill"}, {"title": "2.3 Specific-knowledge (SK) component and fusion with GK component", "content": "For the SK component, we follow the standard procedure to obtain a graph neural network between entities from the training input documents for a specific task. More specifically, we obtain all possible entities from given input documents. We build a graph convolutional network (GCN) [12] on the entities excluding those in GK component (from Section 2.2). At this point, we have a GCN containing information specific to a task, together with the reusable GK component containing \"general\" entity encodings"}, {"title": "effectiveness of our model in terms of relational extraction and the re-usability of our general knowledge component across multiple specific biomedical tasks. We end our paper with a brief conclusion and future works.", "content": ""}, {"title": "in the mask in the first sentence (sentence A), the model needs to approximate a function $r = g(s, o)$ so that $r_k = g(s_i, o_j)$ approximates $r_k$. The function $g$ provides insights into how a relation can fit in a given pair of (subject, object).", "content": ""}, {"title": "Now from such for (masked) sentences A, B, C, D, we use a geometric argument to calculate the expected weight indicating how much a relation $r_k$ will match with the pair of (subject, object). First of all, we convert each sentence into an embedding so that we can get corresponding vectors to perform mathematical operations. For this step, we apply BioBert model to obtain the corresponding embeddings $v_A, v_B, v_C, v_D$.", "content": ""}, {"title": "Next, for each sentence above, we apply BioBERT to obtain its vector representation $v_A, v_B, v_C$ and $v_D$ respectively. Mathematically, $v_A$ can be represented as the ordered sum $v(s_i) + v(r_k) + v(o_j)$, where $r_k$ is the predicted relation to fill in the blank of the sentence with subject $s_i$ and $o_j$. Similarly, $v_B = v(s_i) + v(r_k) + v(\\hat{o}_j)$, and $v_C = v(\\hat{s}_i) + v(r_k) + v(o_j)$, where $\\hat{s}_i$ and $\\hat{o}_j$ are the predicted object and subject given that two other entities are known.", "content": ""}, {"title": "We then perform the geometric vector operation $v_E = v_B + v_C - v_A$. Here E can be considered as the remaining vertex of the parallelogram with existing vertices A, B, C. This geometric operations will yield an approximate embedding of the predicted sentence $E = s_i r_k \\hat{o}_j$ with both predicted subject $\\hat{s}_i$, predicted object $\\hat{o}_j$, and predicted relation $r_k$. The approximation is due to the equation:", "content": ""}, {"title": "$v_B + v_C - v_A = v(\\hat{s}_i) + v(r_k) + v(\\hat{o}_j) + 2(v(r_k) - v(r_k))$", "content": ""}, {"title": "Now to predict how likely the relation $r_k$ fit in, we calculate the difference between the original sentence $D = s_i r_k o_j$ and its predicted counterpart $E = $ by simply taking the cosine similarity between their embedding: $\\hat{w}(s_i, r_k, o_j) = cos(v_D, v_E)$. See Figure 1 for an illustration of the above construction.", "content": ""}, {"title": "Here we regard $E$ as BioBERT's 'ground truth' on the supposed subject, object, and associated relation (or at least related entities). Thus, when $D$ is compared with $E$, the cosine similarity reflects BioBERT's estimate on how close the hypothesis sentence $D$ is to its prediction. The higher the cosine similarity, the more likely that the relation $r_k$ is correct for pair $(s_i, r_k, o_j)$. Our construction ensures that all 3 components subject, object, and relation are taken into account equally.", "content": ""}, {"title": "Entities representation training. Based on the weights $\\hat{w}(s_i, r_k, o_j)$ obtained from previous procedure, we train a feed-forward neural network (FFNN) to encode this relational weights into the entities representations. In particular, we start by taking union over all entities to get a set of distinct entities, each of which is fed into BioBERT model to get its associated initial embedding. Next, we train the FFNN $f$ with the following loss function:", "content": ""}, {"title": "$\\mathcal{L}(\\theta) = \\sum_{s_i} \\sum_{k=1}^R \\sum_{o_j} \\Bigg[ \\left( f(s_i) - \\sum_{s_i} \\sum_{k=1}^R \\sum_{o_j} \\hat{w}(s_i, r_k, o_j) f(o_j) \\right)^2\\Bigg]$", "content": ""}, {"title": "where $f(s_i)$ and $f(o_j)$ is the output vector representations of subject $s_i$ and object $o_j$ that take relation weights into account. The final embedding for each entity is a concatenation of the initial embedding from BioBERT and the (relational) embedding $f(\u00b7)$ obtained from this training.", "content": ""}, {"title": "Our observations indicate that the GK component contributes more to the more-frequent entities within the dataset. We believe that contributing and interacting with frequent entities is one of the key points enabling our framework to produce matching results with other baselines without the need to train the whole GCN. Moreover, as we increase the size of the GK, the overall results stay quite stable and very close to those of KECI. This suggests that the relational embeddings obtained in Section 2.2 and Section 2.3 effectively capture relational information, performing comparably well compared to training a full GCN.", "content": ""}, {"title": "For BioRelEx dataset, we currently utilize a smaller and simplified subset of UMLS. This might leave out more important/frequent entities of this data set, and thus increasing the size of UMLS can help our approach closely match KECI model's performance on relation extraction for BioRelEx. Moreover, as shown in Table 4, approximately 20% of nodes can already be reused, highlighting a significant amount of reusable information. Moreover, our framework achieves an accuracy on the ADE dataset that is only 0.09% below that of using UMLS as a source for entity extraction, while outperming all other baselines in relation extraction. These observations further illustrate that our approach, which aim to build a universal and task-independent background knowledge, can be further extended to a larger scale to enhance its applicability and performance across diverse biomedical tasks.", "content": ""}, {"title": "Note that the equations are not complete due to limitations in retrieving context. Please provide context if needed for better results.", "content": ""}]}