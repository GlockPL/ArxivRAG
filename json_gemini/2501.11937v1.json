{"title": "MeshONet: A Generalizable and Efficient Operator Learning Method for Structured Mesh Generation", "authors": ["Jing Xiao", "Xinhai Chen", "Jiaming Peng", "Qingling Wang", "Jie Liu"], "abstract": "Mesh generation plays a crucial role in scientific computing. Traditional mesh generation methods, such as TFI and PDE-based methods, often struggle to achieve a balance between efficiency and mesh quality. To address this challenge, physics-informed intelligent learning methods have recently emerged, significantly improving generation efficiency while maintaining high mesh quality. However, physics-informed methods fail to generalize when applied to previously unseen geometries, as even small changes in the boundary shape necessitate burdensome retraining to adapt to new geometric variations. In this paper, we introduce MeshONet, the first generalizable intelligent learning method for structured mesh generation. The method transforms the mesh generation task into an operator learning problem with multiple input and solution functions. To effectively overcome the multivariable mapping restriction of operator learning methods, we propose a dual-branch, shared-trunk architecture to approximate the mapping between function spaces based on input-output pairs. Experimental results show that MeshONet achieves a speedup of up to four orders of magnitude in generation efficiency over traditional methods. It also enables generalization to different geometries without retraining, greatly enhancing the practicality of intelligent methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Mesh generation is extensively utilized across diverse scientific and engineering domains, such as aerospace engineering [1], automotive engineering [2], meteorology [3], ocean engineering [4], and materials science [5]. As a crucial preprocessing step, mesh generation involves discretizing the continuous physical domain into a finite set of cells, facilitating the application of numerical methods for analysis. Among various types of meshes, structured meshes are widely employed in practical applications due to their regular indexing, topological connectivity, and superior computational efficiency. The core of the structured mesh generation process lies in solving the mapping between the computational domain and the physical domain. This process can be expressed as a one-to-one mapping from computational coordinates (\u03be, \u03b7) to physical coordinates (x, y), as illustrated in Figure 1.\nTraditional methods for solving the mapping from the computational domain to the physical domain are primarily represented by transfinite interpolation (TFI) and partial differential equation-based (PDE-based) approaches. These methods have been widely utilized in structured mesh generation. While these methods have proven effective in many scenarios, they often face challenges in balancing mesh quality and generation efficiency. TFI can quickly generate structured meshes and is computationally simple and efficient [6]; however, they tend to produce degenerate, overlapping, or boundary-crossing elements in complex geometries, leading to a decline in mesh quality. PDE-based methods consider the mapping solving problem as a boundary value problem of solving PDEs that govern the distribution of mesh points and their boundary conditions. By iteratively solving the corresponding equations, they generate high-quality structured meshes, making them particularly suitable for complex geometric structures [7]. However, PDE-based methods incur substantial computational costs, especially in large-scale mesh generation tasks, where the process can be exceedingly slow and may not meet the demands of real-time or large-scale applications. To address the limitations of traditional methods, physics-informed methods have emerged as a promising solution [8], [9]. These methods leverage the universal approximation capability of deep neural networks to capture the input-output relationship of the domain in high-dimensional nonlinear space. Consequently, these methods eliminate the need for explicit PDE iterative solving, enabling fast feedforward prediction and thus significantly improving computational efficiency. Furthermore, by incorporating the control equations and boundary conditions related to mesh generation into the neural network loss function, physics-informed methods effectively guide the mesh generation process to adhere to physical geometric constraints, thereby ensuring the generation of high-quality meshes. One significant drawback of physics-informed methods is their limited generalization to previously unseen geometries. When the geometries change, the corresponding boundary conditions will be modified, requiring the loss function to be readjusted."}, {"title": "II. RELATED WORK", "content": "Mesh generation is a critical component in scientific computing. Traditional methods, such as algebraic and PDE-based approaches, have been widely used. Algebraic mesh generation relies on geometric interpolation to generate meshes. A representative method in this category is TFI [11], which rapidly generates structured meshes by interpolating boundary conditions. The TFI method constructs internal meshes by interpolating known boundaries, making it suitable for regular geometric structures and simple boundary conditions. Due to the relatively simple computation steps, algebraic methods have a fast generation speed. However, algebraic methods face considerable limitations when applied to intricate geometries, such as airfoils or shapes with high curvature. Their interpolation processes are inadequate for handling high-curvature and irregular geometries, often resulting in low-quality mesh elements such as degenerate triangles, overlapping elements, or meshes that cross boundaries.\nTo address the boundary issues of algebraic mesh generation, PDE-based methods are often used for structured mesh generation tasks with complex boundary conditions. This methods generate the corresponding mesh by solving PDEs in the given transformation domain, thereby linking computational domain coordinates to physical domain coordinates and yielding the steady-state solution as the final structured mesh. Based on the mathematical properties of PDEs, PDE-based methods can ensure orthogonality in near-wall regions, prevent the propagation of boundary singularities, and avoid overlapping mesh cells. These capabilities enable the generation of high-quality meshes, making them widely used in high-precision numerical simulations, such as turbulence simulation in fluid mechanics [12] or atmospheric boundary layer calculations in aerospace applications [13]. However, the computational complexity of PDE-based methods is high; the process requires iterative solutions to control equations to generate meshes, resulting in substantial computational costs and slower generation speeds, especially in large-scale mesh generation tasks. Therefore, achieving a balance between mesh generation efficiency and quality is a significant challenge for traditional methods.\nTo overcome the limitations of traditional methods, researchers have explored the use of neural networks for mesh generation. Pioneering works in this area include those of Alfonzetti et al. [14], who were among the first to apply neural networks to unstructured mesh generation. They began with coarse triangular meshes containing a limited number of nodes and progressively refined the mesh by adding points until the desired resolution was reached. Similarly, Ahmet et al. [15] used boundary points as inputs to a feedforward, single-layer neural network, which predicted the spatial coordinates of interior points, enabling 2D mesh generation. But these methods were highly sensitive to weight selection, with improper choices leading to significant inaccuracies in the meshes.\nIn order to improve the robustness of the model, several researchers have started to investigate data-driven approaches for mesh generation. Lowther et al. [16] use density information to optimize element size and placement, offering more efficient mesh generation compared to traditional adaptive methods. Besides, Zhang et al. [17] introduced a novel deep learning-based method to automatic unstructured mesh generation, where they used a finite element solver to perform simulations, thereby creating a training dataset. Papagiannopoulos et al. [18] use data extracted from meshed contours to train neural networks, which are then employed to approximate the number of vertices to be inserted inside the contour cavity, along with their location and connectivity. Nevertheless, these methods typically exhibit weak extrapolation capabilities and require large amounts of data, which limits their applicability in real-world scenarios.\nIn response to the challenge of expensive data acquisition in data-driven methods, physics-informed methods have emerged, which incorporate governing equations and boundary conditions as physical constraints in the loss function, thereby effectively constraining the solution space and eliminating the need for prior data. In this regard, MGNet [8] is a pioneering work, being the first to use a physics-informed neural network [19]\u2013[21] for structured mesh generation. By minimizing the weighted residuals of the control equations and boundary constraints, MGNet effectively learns an approximate mapping for mesh generation, significantly improving both efficiency and accuracy. Building on this, Chen et al. further advanced the field with MeshNet [22], a method that leverages data from coarse mesh generation to optimize the loss function, thereby improving both the quality and efficiency of mesh generation. Additionally, they introduced another approach that incorporates data from auxiliary line sampling to construct a more refined loss function, further enhancing the performance of mesh generation [23]. Besides, research in physics-informed methods has expanded to three-dimensional scenarios. 3DMeshNet [9] is a representative work in this area. This method improves adaptability to complex geometric structures by adjusting weights and projecting gradients within the loss function. It also simplifies derivative calculations using finite difference methods, thereby enabling the efficient generation of three-dimensional structured meshes. However, these physics-informed methods are limited in their generalization, especially with unseen geometries. When geometries change, the boundary conditions also change, which in turn necessitates readjusting the loss function. Consequently, even minor changes in boundary shapes require burdensome retraining to accommodate new variations.\nWith the aim of addressing the challenge posed by the limited generalization capabilities of physics-informed methods, operator learning-based methods provide a promising solution. By learning the nonlinear mapping between inputs and outputs, operator learning effectively infers the behavior of complex methods from limited training data, showcasing exceptional generalization capabilities [24]\u2013[29]. The generalization capabilities of operator learning suggest its potential for mesh generation. By learning from given input-output pairs, operator learning-based methods can learn the operator that captures the underlying relationship between the input and output spaces, thereby acquiring the ability to generalize. Existing operator learning-based methods can only handle univariable mapping problems. In contrast, mesh generation tasks require addressing multivariable mapping problems. This difference limits the application of operator learning to mesh generation.\nIn this paper, we propose MeshONet to address the limitations of the aforementioned methods. We demonstrate that MeshONet improves generation efficiency while maintaining mesh quality. It also generalizes across different geometries and effectively addresses multivariable mapping problems."}, {"title": "III. MESHONET: A GENERALIZABLE AND EFFICIENT STRUCTURED MESH GENERATION METHOD", "content": ""}, {"title": "A. Problem Setting", "content": "The structured mesh generation process can be described as solving a boundary value problem. An elliptic partial differential equation is taken as an example:\n$\\begin{aligned}\n\\alpha x_{\\xi \\xi}-2 \\beta x_{\\xi, \\eta}+\\gamma x_{\\eta \\eta} &=0, &(\\xi, \\eta) \\in \\Theta \\Omega, \\\\\n\\alpha y_{\\xi \\xi}-2 \\beta y_{\\xi, \\eta}+\\gamma y_{\\eta \\eta} &=0, &(\\xi, \\eta) \\in \\Theta \\Omega. \\\\\nx &= u_{1}(\\xi, \\eta), &(\\xi, \\eta) \\in \\Omega, \\\\\ny &= u_{2}(\\xi, \\eta), &(\\xi, \\eta) \\in \\Omega,\n\\end{aligned}$\n\nThe coefficients \u03b1, \u03b2, and \u03b3 are defined as follows:\n$\\begin{aligned}\n\\alpha &= x_{\\eta}^{2}+y_{\\eta}^{2} \\\\\n\\beta &=x_{\\xi} x_{\\eta}+y_{\\xi} y_{\\eta}, \\\\\n\\gamma &=x_{\\xi}^{2}+y_{\\xi}^{2}\n\\end{aligned}$\n\nIn this set of equations, \u03be and \u03b7 are the coordinates defined in the computational domain, while x and y are the coordinates defined in the physical domain. By solving the above elliptic differential equations, we can obtain the corresponding values of x = x(\u03be,\u03b7) and y = y(\u03be,\u03b7), which represent the mesh coordinates in the physical domain.\nOur objective is to learn the operator G that maps a Banach space U \u00d7 U to another Banach space P \u00d7 P, where both $u_{1} \\in U$ and $u_{2} \\in U$ represent boundary conditions. This can be formally expressed as:\n$(u_{1}, u_{2}) \\xrightarrow{G} (\\mathcal{G} u_{1}, \\mathcal{G} u_{2})$\n\nThe operator G takes three inputs: the computational domain coordinates (\u03be, \u03b7), and two boundary functions u\u2081 and u\u2082, which describe the x- and y-coordinates of the boundary, respectively. For any given boundary conditions u\u2081 and u\u2082, and a set of computational domain coordinates (\u03be,\u03b7), the corresponding physical mesh coordinates (x, y) are generated by the operator G, as expressed by the equation:\n$(x, y) = G(u_{1}, u_{2}) (\\xi, \\eta)$\n\nThe operator G can be decomposed into two distinct sub-operators: $G_x$, responsible for generating the x-coordinates, and $G_y$, responsible for generating the y-coordinates. Each of these sub-operators operates from the Banach space U to P, where $u_{1} \\rightarrow G_x(u_{1})$ and $u_{2} \\rightarrow G_y(u_{2})$. These sub-operators are not independent, as they both rely on the same input coordinates (\u03be, \u03b7). Consequently, the operator $G(u_{1}, u_{2})$ can be formally expressed as:\n$G(u_{1}, u_{2}) (\\xi, \\eta) = (G_x(u_{1})(\\xi, \\eta), G_y(u_{2}) (\\xi, \\eta))$\n\nInspired by the universal approximation theorem for continuous multi-input operators [30], which states that there exists a continuous multi-input operator that can be approximated by a neural network to arbitrary precision, we approximate the operator $G(u_{1}, u_{2})$ using a neural network-based approximation $\\hat{G}(u_{1}, u_{2})$. The approximation is constructed to satisfy the following condition:\n$||G(u_{1}, u_{2})(\\xi, \\eta) - \\hat{G}(u_{1}, u_{2})(\\xi, \\eta) || \\rightarrow 0$\n\nThis provides a theoretical foundation for our method."}, {"title": "B. The Operator Learning-based method", "content": "As mentioned above, existing operator-based methods cannot be directly applied to mesh generation. Therefore, we propose an operator learning-based framework specifically designed for mesh generation, aimed at solving the multivariable mapping problem.\n1) The Architecture Of MeshONet: The architecture of MeshONet consists of three components: two specialized branch networks, the Branch-x Network and the Branch-y Network, and a shared trunk network.\nThe 2D mesh generation task involves two boundary functions at each sensor, corresponding to the x-coordinates and y-coordinates of the boundary. Handling both functions simultaneously can be challenging. To address this, we employ a dual-branch network design, ensuring that each branch processes only one boundary function. Specifically, the Branch-x Network extracts the x-coordinates of the boundary points, while the Branch-y Network extracts the y-coordinates. Both networks take the boundary point coordinates as input.\nHowever, since there are infinitely many boundary points and the boundary conditions correspond to infinitely many values, this problem is inherently infinite-dimensional. To further address this, we employ a subsampling strategy in which fixed sensor locations in the computational domain are used to obtain the corresponding boundary points $(x_{1},y_{1}), (x_{2},y_{2}), ..., (x_{m}, y_{m})$ in the physical domain. These points are subsequently utilized to sample the boundary functions u\u2081 and u\u2082, where u\u2081 and u\u2082 represent the sampled values of the x-coordinates and y-coordinates, respectively. This results in two finite-dimensional representations, $[x_{1}, x_{2}, ..., x_{m}]$ and $[y_{1}, y_{2}, ..., y_{m}]$.\nAfter obtaining the finite-dimensional representation of the boundary conditions, we use this feature representation as the input to the Adjust Layer. The Adjust Layer consists of fully connected layers with Tanh activation functions. Specifically, the Adjust Layer is defined as:\nAdjust(x) = $f_{L}(f_{L-1}(....f_{1}((x)...))$,\n\nwhere each function $f_i$ represents the mapping of the i-th layer of the Adjust Layer, defined as:\n$f_i(x) = tanh(W_ix + b_i)$,\n\nwhere $W_i$ and $b_i$ are the weight matrix and bias term of the i-th layer, respectively. Similarly, the Branch-y Network processes the y-coordinates in the same manner, forwarding them through the Adjust Layer before passing them to the corresponding Branch layer.\nAs the solutions for x and y in the structured mesh generation task are inherently coupled, we use a shared Trunk Network that takes the computational domain coordinates as input. This network serves as a unified feature extractor for both the Branch-x and Branch-y Networks, ensuring the correlation between the x- and y-coordinates and promoting efficient information flow between the two branches, thus improving MeshONet's performance. In addition, we design a Lift-Layer that expands the computational domain coordinates (\u03be, \u03b7) into a higher-dimensional space using a mixed dimensionality expansion approach. This layer combines polynomial and trigonometric transformations to capture linear, non-linear, and periodic features, thereby enhancing feature representation. The dimensionality expansion is given by:\n$(\\xi, \\eta) \\rightarrow [sin(\\xi), cos(\\xi), sin(\\eta), cos(\\eta), \\xi, \\eta, \\xi^{2}, \\eta^{2},..., \\xi^{d}, \\eta^{d}]$.\n\nAfter obtaining the features extracted by the Branch and Trunk networks, they are fused using a dot product to generate the final coordinates. The generation process for the x and y coordinates is as follows:\n$\\begin{aligned}\nx = \\hat{G}_{x}(u_{1})(\\xi, \\eta) &= \\text{Branch}_{x}(u_{1}) \\cdot \\text{Trunk}(\\xi, \\eta) = \\sum_{i=1}^{k} b_{i} t_{i} + b_{0}.\\\\y = \\hat{G}_{y}(u_{2})(\\xi, \\eta) &= \\text{Branch}_{y}(u_{2}) \\cdot \\text{Trunk}(\\xi, \\eta) = \\sum_{i=1}^{k} b'_{i} t_{i} + b'_{0}.\n\\end{aligned}$\n\nHere, $\\text{Branch}_{x}(u_{1})$ and $\\text{Branch}_{y}(u_{2})$ represent the feature vectors extracted from the boundary points for the x-coordinates and y-coordinates, respectively. The function $\\text{Trunk}(\\xi, \\eta)$ extracts high-dimensional features from the computational domain coordinates (\u03be, \u03b7), shared by both the x-coordinate and y-coordinate generations. The bias terms $b_{0}$ and $b'_{0}$ correspond to the Branch-x and Branch-y sub-networks, adjusting the final values of the generated coordinates. Through the inner product operation, information from the boundary conditions and the computational domain is fused to generate mesh coordinates (x, y) in the physical domain.\n2) The Loss Function of MeshONet: To ensure that the generated mesh satisfies the requirements, MeshONet employs a loss function based on interior and boundary points. The loss function in MeshONet consists primarily of two components: the interior loss term and the boundary loss term, which serve to ensure that the generated mesh is appropriately distributed within the physical domain and aligns with the boundary conditions. The total loss function of MeshONet is defined as:\n$L(\\theta) = L_{interior} + \\beta L_{boundary}$\n\nwhere $L_{interior}$ ensures that the distribution of generated mesh nodes within the physical domain aligns with the target mesh, and $L_{boundary}$ enforces conformity with the input boundary conditions at the boundary points.\nThe interior loss term is formulated as:\n$L_{interior} = \\sum_{j \\in \\mathcal{D}_{interior}} [(\\hat{G}_{x}(u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}) - G_{x} (u_{1}, u_{2}) (\\xi_{j}, \\eta_{j} ))^{2} + (\\hat{G}_{y}(u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}) - G_{y} (u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}))^{2}]$\n\nSimilarly, the boundary loss term is defined as:\n$L_{boundary} = \\sum_{j \\in \\mathcal{D}_{boundary}} [(\\hat{G}_{x} (u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}) - G_{x} (u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}))^{2} + (\\hat{G}_{y}(u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}) - G_{y}(u_{1}, u_{2}) (\\xi_{j}, \\eta_{j}))^{2}]$\n\nHere, $\\mathcal{D}_{interior}$ and $\\mathcal{D}_{boundary}$ denote the sets of sampled points in the interior and boundary regions of the computational domain, respectively, while $G_x$ and $G_y$ represent the approximated operators for generating the x- and y-coordinates. Meanwhile, \u03b1 and \u03b2 are weighting coefficients that balance the influence of the interior loss and boundary loss within the total loss. By minimizing this loss function, the model can approximate the nonlinear mapping relationship from the boundary conditions to the mesh nodes, thereby ensuring that the generated mesh satisfies the expected geometric and boundary requirements both within the physical domain and at the boundaries."}, {"title": "IV. RESULTS", "content": "In this section, we first describe the experimental setup and the test cases used to evaluate our method. We then provide a comparative analysis of our approach against modified operator learning-based methods to validate the feasibility of our method. Subsequently, we assess the model's generalization ability across diverse geometries, as well as its performance in mesh refinement."}, {"title": "A. Experiment Settings", "content": "This experiment was conducted on a server equipped with an NVIDIA RTX 4090 GPU, using the PyTorch framework for model training and testing. To facilitate the reproduction of this work, we have provided the model's parameter settings in the appendix. In order to compare the mesh quality generated by our method, we use TFI and PDE-based approaches as baseline benchmarks. These methods are well-established and widely used in the field, making them suitable for this evaluation.\nFurthermore, as previously noted, operator learning-based methods cannot directly apply to mesh generation tasks. To bridge this gap, we have made architectural modifications to several advanced operator learning-based methods, including DeepONet [24], a deep learning-based operator learning framework designed for mapping input-output functions; POD-DeepONet [31], which combines proper orthogonal decomposition with DeepONet for enhanced efficiency and accuracy; FNOID [26], the Fourier neural operator designed for solving differential equations using Fourier transforms; and FNO2D [26], an extension of FNO1D to handle 2D data."}, {"title": "B. Test Cases", "content": "To evaluate the generalization performance of MeshONet under diverse geometric conditions, we designed two types of test cases. The first type involves modifications to the outer boundary, including geometric variations such as changes in curvature, angle size, opening size, and the movement of the lower boundary semicircle. The second type focuses on alterations to the inner boundary, such as variations in the thickness of an airfoil or the movement of internal circular holes.\nAs shown in Figure 4(a), Test Case-1 consists of arch shapes created by varying the curvature of the top boundary. Test Case-2 features hexagonal shapes, with modifications to the angles of both the top and bottom boundaries. Test Case-3 includes wrenches with different upper boundary opening sizes, while Test Case-4 contains shapes where the lower boundary semicircle is progressively shifted to the right. In addition to assessing the model's generalization across variations in the outer boundary, we also evaluated its performance with respect to changes in the inner boundary. Test Case-5 consists of airfoils with varying thicknesses, generated by modifying the internal boundary. Test Case-6 involves shapes with internal circular holes, where the position of the holes is varied through vertical displacements."}, {"title": "C. Comparison of Modified Operator Learning-Based meth-ods", "content": "To validate the feasibility of the proposed model architecture, we conducted a comparative analysis with several operator learning-based approaches, including DeepONet [24], POD-DeepONet [31], FNO1D [26], and FNO2D [26]. Given that traditional operator methods are incapable of generating meshes, we implemented architectural modifications to these approaches. Further details of the experimental setup, network architecture modifications, and specific experimental results are provided in the appendix.\nAs shown in Figure 5, MeshONet consistently maintains the lowest loss, demonstrating a significant difference in magnitude compared to other operator learning-based methods. This result highlights the effectiveness of our architecture in addressing the multivariable mapping problem, specifically in the context of mesh generation."}, {"title": "D. Experiments Based on Outer Boundary Variations", "content": "In this section, we evaluate the model's generalization capability with respect to variations in the outer boundary conditions, conducting experiments on four distinct test cases, each corresponding to different outer boundary modifications.\n1) Experimental Results on Test Case-1: In test case-1, we generated a series of arch samples by adjusting the curvature of the top boundary. To evaluate the model's generalization capability, we conducted two types of experiments: interpolation and extrapolation. In the interpolation experiment, the model was trained on samples with the minimal and maximal curvatures and tested on samples with intermediate curvatures. This setup allows the model to learn from extreme configurations and tests its performance within an unobserved range of curvatures. The extrapolation experiment, being more challenging, involved training the model on samples with low curvature and testing it on samples with high curvature, thereby assessing its ability to generalize beyond the training range.\nAs shown in Figures 6(b) and 7(b), the model exhibits outstanding performance in both interpolation and extrapolation scenarios, achieving mesh quality that exceeds that of traditional methods. Additionally, it is worth noting that the mesh quality around the corner points of the arch test case tends to be relatively poor. However, by zooming in on the mesh at these corner regions, we observe that our method performs exceptionally well.\n2) Experimental Results on Test Case-2: In test case-2, we used hexagonal samples with various shapes by simultaneously adjusting the angles of the top and bottom boundaries. As shown in Figures 8(a) and 9(a), in the interpolation experiment, we selected samples with large and small angles of the top and bottom boundaries for training and used samples with intermediate angles of the top and bottom boundaries for testing. In the extrapolation experiment, we selected samples with larger angles of the top and bottom boundaries for training and samples with smaller angles of the top and bottom boundaries for testing.\nAs shown in Figures 8(b) and 9(b), the model performs exceptionally well on the test samples, accurately capturing the geometric features of hexagonal shapes during variations in the angles between the top and bottom boundaries. By zooming in on the mesh at the top, it can be observed that the mesh generated by the PDE method lacks smoothness on this shape, while the mesh produced by TFI exhibits overall poor quality. In contrast, our method excels in this test case, demonstrating exceptional performance in both interpolation and extrapolation, with outstanding generalization across a range of variations in geometric angles.\n3) Experimental Results on Test Case-3: In test case-3, a series of wrenches were generated by varying the opening size of the top boundary to simulate practical engineering requirements. Two types of experiments were then conducted on these samples: interpolation experiments and extrapolation experiments, to evaluate the model's generalization capability on this test case. As illustrated in Figures 10(a) and 11(a), in the interpolation experiment, samples with larger and smaller opening sizes were used for training, while samples with intermediate opening sizes served as the testing set. In the extrapolation experiment, training was performed on samples with larger opening sizes, and testing was conducted using samples with smaller opening sizes.\nAs shown in Figures 10(b) and 11(b), MeshONet generates meshes comparable to traditional methods. In interpolation, it matches TFI and outperforms PDE methods. In extrapolation, it slightly trails TFI but still outperforms PDE. MeshONet's ability to maintain high mesh quality across varied conditions demonstrates its potential for real-world applications with frequent geometric variations."}, {"title": "E. Experiments Based on Inner Boundary Variations", "content": "In this section, we evaluate the model's generalization capability with respect to variations in the inner boundary conditions, conducting experiments on two distinct test cases representing different geometric configurations.\n1) Experimental Results on Test Case-5: In test case-5, we generated a series of airfoil samples with varying thicknesses, where the thickness change corresponds to modifications in the inner boundary. To evaluate the model's generalization ability across different geometries, we conducted both interpolation and extrapolation experiments. As shown in Figures 13(a) and 14(a), in the interpolation experiment, we used samples with smaller and larger thicknesses for training, and samples with intermediate thickness for testing. In the extrapolation experiment, we used samples with smaller thicknesses for training and samples with larger thicknesses for testing.\nAs shown in Figures 13(b) and 14(b), in the interpolation task, our method matches the PDE method in mesh quality, outperforming TFI. In the extrapolation task, it slightly lags behind the PDE method but still outperforms TFI, demonstrating the robustness of our model for both tasks, with strong potential for practical engineering applications.\n2) Experimental Results on Test Case-6: In test case-6, we consider the scenario where the variation in the position of the internal circular hole leads to geometric changes. A series of samples are generated by altering the vertical position of the hole from top to bottom. For the experiments, we randomly select samples from various vertical positions for training, while reserving the remaining positional samples for testing. The goal is to assess the model's ability to generalize mesh generation across different vertical positions.\nAs shown in Figure 15, our model performs exceptionally well in scenarios where geometry is altered through vertical displacement, with mesh quality surpassing that of traditional methods."}, {"title": "F. Mesh Refinement Experiment", "content": "Figure 16 compares the execution time for mesh generation across different test cases and methods. As shown, our method outperforms traditional methods, achieving up to a four-order-of-magnitude improvement in efficiency. We also evaluate the model's performance in mesh refinement, focusing on its ability to refine meshes while maintaining high quality and improving refinement efficiency. Refining the mesh enables the capture of finer geometric details and boundary features, which reduces numerical errors and enhances the accuracy of simulations.\nThe experimental results, as shown in Table II and Figure 17, further validate the capabilities of our model. Specifically, Table II presents the generation time across varying mesh densities, revealing that the time required for both the TFI method and the PDE method increases rapidly as the resolution increases. In contrast, our method shows little variation in execution time, even as the resolution increases. Notably, the PDE method fails to generate a mesh within the specified time frame at resolutions of 1600x1600 and 3200x3200. This highlights the superiority of our approach in handling large-scale meshes. Furthermore, as shown in Figure 17, the high-resolution meshes generated by our model confirm its effectiveness in mesh refinement tasks. It can be observed that, even as the mesh resolution increases, the quality of the meshes generated by our model remains consistently high, further demonstrating its robustness in handling large-scale mesh generation tasks."}, {"title": "V. CONCLUSION", "content": "This paper introduces MeshONet, a generalizable and efficient method for structured mesh generation based on operator learning. The method transforms the mesh generation task into an operator learning problem with multivariable mapping, involving multiple input and solution functions. By developing a specialized operator learning architecture for mesh generation, which incorporates a dual-branch structure with a shared trunk, MeshONet effectively learns operators that capture the underlying meshing rules. Additionally, it addresses the inherent challenges of multivariable mapping, providing a framework that can serve as a reference for other applications involving multi-input, multi-output tasks.\nThe experimental results show that MeshONet successfully addresses the challenges of balancing efficiency and quality in traditional methods, achieving up to a four-order-of-magnitude improvement in mesh generation efficiency while maintaining high mesh quality. It also overcomes the limited generalization capabilities of physics-informed methods, enabling generalization across geometric variations and eliminating the need for retraining. Moreover, MeshONet performs exceptionally well in mesh refinement tasks, effectively training on low-resolution samples and generating high-quality meshes for high-resolution evaluations, with minimal impact on inference time.\nDespite these advancements, some limitations remain. Specifically, the model's parameter size is determined by the number of boundary points, which in turn constrains its generalization capacity. An excessive number of boundary points may lead to overfitting, and too few boundary points may result in underfitting. Therefore, extending the model to 3D problems will introduce additional challenges. Future work will focus on refining the model architecture to mitigate the impact of boundary sampling points on parameter size, thereby enhancing both efficiency and generalization performance, and will also extend the model to 3D structured mesh generation."}]}