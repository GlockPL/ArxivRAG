{"title": "EXPLORING THE POTENTIAL OF LARGE LANGUAGE MODELS IN\nPUBLIC TRANSPORTATION: SAN ANTONIO CASE STUDY", "authors": ["Ramya Jonnala", "Gongbo Liang", "Jeong Yang", "Izzat Alsmadi"], "abstract": "The integration of large language models (LLMs) into public transit systems presents a transformative\nopportunity to enhance urban mobility. This study explores the potential of LLMs to revolutionize\npublic transportation management within the context of San Antonio's transit system. Leveraging\nthe capabilities of LLMs in natural language processing and data analysis, we investigate their\ncapabilities to optimize route planning, reduce wait times, and provide personalized travel assistance.\nBy utilizing the General Transit Feed Specification (GTFS) and other relevant data, this research aims\nto demonstrate how LLMs can potentially improve resource allocation, elevate passenger satisfaction,\nand inform data-driven decision-making in transit operations. A comparative analysis of different\nChatGPT models was conducted to assess their ability to understand transportation information,\nretrieve relevant data, and provide comprehensive responses. Findings from this study suggest\nthat while LLMs hold immense promise for public transit, careful engineering and fine-tuning are\nessential to realize their full potential. San Antonio serves as a case study to inform the development\nof LLM-powered transit systems in other urban environments.", "sections": [{"title": "1 Introduction", "content": "The rise of artificial intelligence (AI) and machine learning (ML) has initiated a new era of technological advancements,\nrevolutionizing numerous sectors, such as cyber security [1, 2, 3], healthcare [4, 5, 6], and public transportation [7, 8, 9].\nAmong these innovations, large language models (LLMs), such as OpenAI's GPT series [10, 11], have demonstrated\nexceptional natural language processing, understanding, and generation capabilities. These models can analyze vast\namounts of data [12, 13], generate human-like text [14], and facilitate complex decision-making processes [15, 16],\nmaking them potentially invaluable tools for enhancing public transit systems.\nPublic transit systems are the backbone of urban mobility, delivering essential services to millions of passengers\nevery day [17, 18]. Efficient and reliable public transportation is crucial for reducing traffic congestion, minimizing\nenvironmental impact, and promoting equitable access to mobility [19]. However, transit agencies frequently encounter\nchallenges such as fluctuating passenger demand, optimizing routes, maintaining real-time communication with\npassengers, and efficiently allocating resources [20, 21]. Traditional methods of addressing these issues may need to be\nrevised due to their limited scalability and adaptability.\nSan Antonio, one of the fastest-growing cities in the United States, offers a unique case study for exploring the\nintegration of LLMs in public transit. The city's rapid population growth has heightened the need for efficient public\ntransportation solutions [22, 23]. As the local transit authority seeks innovative methods to enhance service delivery,\ndeploying LLMs presents a promising solution for addressing current and future challenges.\nThis study aims to explore the potential of LLMs to enhance various aspects of San Antonio's public transit system.\nThe following are key areas where LLMs could be beneficial in public transportation:\n\u2022 Optimize Route Planning and Scheduling: Analyze historical and real-time data to enhance route planning and\nscheduling, thus reducing wait times and improving service reliability.\n\u2022 Enhance Passenger Communication: Use of LLMs for real-time engagement with passengers, offering\npersonalized travel assistance, updates, and recommendations.\n\u2022 Improve Operational Efficiency: LLMs can influence resource allocation, including the deployment of buses\nand drivers, to boost overall operational efficiency."}, {"title": "2 Significance of the Study", "content": "The integration of LLMs into public transit systems has the potential to transform urban mobility by enhancing efficiency,\nresponsiveness, and user-friendliness. This study not only advances academic understanding of AI applications in\ntransportation but also offers practical insights for transit authorities and policymakers. By examining San Antonio\u2014\u0430\ncity representative of many growing urban areas the findings can be applied to other cities facing similar challenges.\nAdditionally, the research underscores the broader implications of AI in public services, highlighting the significance of\nethical considerations, data privacy, and the necessity for ongoing evaluation and improvement. As cities around the\nworld navigate the complexities of modern urbanization, the lessons learned from San Antonio's experience with LLMs\ncan provide valuable guidance for future innovations in public transit systems.\nIn summary, this study seeks to bridge the gap between cutting-edge AI technologies and their practical applications in\npublic transportation, illustrating how LLMs can be utilized to develop smarter, more adaptive, and passenger-focused\ntransit networks. The following sections will explore the theoretical framework, detailed methodology, findings, and\nimplications of this transformative approach to public transit management."}, {"title": "3 Related Work", "content": "The integration of LLMs such as OpenAI's GPT-4 [11] into public transit systems is a burgeoning field that aims to\nenhance the efficiency, accessibility, and user experience of public transportation [13]. LLMs can process and analyze\nvast amounts of data [16], generate human-like text [14], and understand complex queries [16], making them suitable for\na range of applications in public transit. This literature review explores the current state of research on the deployment\nof LLMs in public transit systems, focusing on areas such as passenger information services, operational efficiency, and\naccessibility improvements.\nOne of the primary applications of LLMs in public transit is in improving passenger information services. Studies\nhave demonstrated that LLMs can enhance the quality and accuracy of real-time information provided to passengers.\nFor instance, researchers explored the use of GPT in generating real-time updates and personalized travel advice for\npassengers [24, 25, 26, 27]. Their findings indicated that LLMs could effectively handle complex passenger queries and\nprovide accurate, context-aware responses, thereby improving the overall passenger experience.\nFurthermore, researchers highlighted the potential of LLMs in multilingual support for transit systems [28, 29, 30].\nGiven the diverse linguistic backgrounds of urban populations, LLMs like GPT-4 can be trained to provide information\nin multiple languages, ensuring that non-native speakers have equal access to transit information. This capability not\nonly improves user satisfaction but also promotes inclusivity and accessibility.\nThe paper, [31], presents an evaluation of large language models (LLMs), specifically ChatGPT, in interpreting and\nretrieving information from General Transit Feed Specification (GTFS) data. The study demonstrates that ChatGPT\ncan effectively understand and respond to various queries about public transit schedules and services, showcasing its\npotential in enhancing transit information systems. However, the paper also highlights areas for improvement, such as\nthe model's occasional inaccuracies and the need for further fine-tuning to handle complex and domain-specific transit\nqueries more reliably.\nThe paper, [32], explores the potential of using ChatGPT and similar large language models (LLMs) to revolutionize\nintelligent transportation systems. It argues that LLMs could significantly enhance various aspects of transportation,\nsuch as traffic management, passenger assistance, and operational efficiency, but also points out the challenges related\nto data privacy, model accuracy, and integration with existing systems."}, {"title": "4 Goals", "content": "Contemporary large language models predominantly employ learning-based approaches. Prominent examples include\nChatGPT [10], built upon the Transformer architecture [33] and trained using generative pre-training techniques [34,"}, {"title": "5 Approaches and Experiment Design", "content": "In this project, we employ OpenAI's ChatGPT as the representative LLM due to its widespread public availability\nthrough both a web portal and a programmatic API. To assess LLM capabilities in understanding and retrieving\ntransportation information (Goals 1 and 2, respectively, as outlined in Section 4), we conducted five experiments\ncomprising 3275 multiple-choice questions and 80 short-answer questions based on San Antonio's public transportation\nsystem."}, {"title": "5.1 Experiments for Transportation Understanding", "content": "The transportation information understanding task, referred to as understanding, evaluates a pre-trained LLM's ability\nto comprehend and answer questions about San Antonio's public transportation system.\nFollowing [31], we designed 195 multiple-choice questions (MCQs) with a single correct answer, meticulously crafted to\ncover six key question categories (Table 1). The questions are derived using the official GTFS Schedule documentation 1\nand used in the initial experiment (Experiment I) to assess the LLM's understanding of transportation information.\nTo increase task difficulty, we augmented the original 195 MCQs by replacing one answer choice with \"none of these,\"\ncreating 780 additional variants (195 \u00d7 4). This modification tested the model's ability to handle scenarios where the\ncorrect answer might not be explicitly provided. We refer to this experiment as Experiment II. Table 2 presents ten\nsample MCQs used in this project."}, {"title": "5.2 Experiment for Transportation Information Retrieval", "content": "The transportation information retrieval task assesses an LLM's ability to extract relevant information from a provided\ndataset. We employed a question-answering (QA) format, differing from the multiple-choice questions used in the\nUnderstanding task by omitting potential answer choices. To generate correct responses, the LLM must retrieve\ninformation from a given GTFS dataset. The San Antonio VIA GTFS feed, encompassing data for 98 bus routes, served\nas the foundation for our questionnaire.\nDue to LLM context length limitations, we reduced our dataset to three bus routes (Routes 242, 243, and 246),\nencompassing 34 trips and 60 unique stops. We developed 80 short-answer questions requiring basic search, filtering,\nsorting, grouping, and joining operations across multiple files. These questions were categorized into simple and\ncomplex levels.\n\u2022 Simple questions are based on simple lookups within the same file or two different files (using relational keys)\nwithin GTFS, such as What route_type corresponds to route_id 243?\n\u2022 Complex questions need multiple files to extract information, require a deeper understanding, and\ncould be open-ended. An example may look like Tell the route_long_name in which there is\na stop_name as \"GILLETTE & PLEASANTON RD.\"? To support this question, four data files are needed,\nnamely stops.txt, stop_times.txt, trips.txt, routes.txt. The LLM needs first to find the stop\nname GILLETTE & PLEASANTON RD and the the corresponding stopid from stops.txt. Then, using the"}, {"title": "5.3 Evaluation Methods", "content": "We employ accuracy as the evaluation metric to assess LLM performance across Experiments I to IV. Accuracy is\ncalculated as:\naccuracy =$\\frac{1}{N}\\sum_{i=1}^{N} c_i$,\nwhere N is the number of questions and $c_i$ is a binary indicator. $c_i$ = 1, if LLM output $\\hat{y}_i$ for question $i^{th}$ equals the\nground true answer, $y_i$ of that question (i.e., $\\hat{y}_i = y_i$); otherwise, $c_i$ = 0.\nAll LLM outputs $\\hat{y}_i$ iare generated using zero-shot learning, where the model responds to questions without prior\nspecific training. For Experiments I-IV, accuracy is determined by exact match between $\\hat{y}_i$ and $y_i$. In Experiment V,\naccuracy is based on semantic equivalence between $\\hat{y}_i$ and $y_i$."}, {"title": "6 Experimental Results", "content": "This section presents the evaluation results of the five conducted experiments. The outcomes of Experiments I to IV,\nfocusing on understanding, are detailed in Section 6.1. The results of Experiment V, which investigates information\nretrieval, are provided in Section 6.2."}, {"title": "6.1 Result of Transportation Information Understanding", "content": "We present the evaluation results of Experiments I-IV, assessing LLM performance on the transportation information\nunderstanding task, in this section. Both GPT-3.5-turbo and GPT-4 models were employed, leveraging their respective\nmaximum context lengths of 16,385 and 128k tokens. Table 3 summarizes the overall performance of the four\nexperiments, highlighting the best performance within each category."}, {"title": "6.1.1 Experiment I vs Experiment III", "content": "Experiments I and III utilized non-augmented questions, with 195 and 444 MCQs, respectively. While GPT-3.5-\nturbo and GPT-4 demonstrated comparable performance across most categories in Experiment I, GPT-3.5-turbo\nunexpectedly outperformed GPT-4 in Data Structure and Common Reasoning. This is surprising given GPT-4's\nestablished superiority in general natural language processing. However, Experiment III, with its larger dataset, revealed\na consistent performance advantage for GPT-4 over GPT-3.5-turbo, with an average improvement of approximately 10%\nand a peak improvement of approximately 26% in the File Structure category. We attribute GPT-4's lower performance\nin Experiment I to the limited dataset size, particularly evident in the Term Definitions category with only 14 questions.\nSuch a small sample size hinders the reliable assessment of LLM capabilities."}, {"title": "6.1.2 Augmented Dataset vs Non-Augmented Dataset", "content": "The MCQ sets for Experiments II and IV were generated by augmenting the answer choices of Experiments I and III,\nrespectively, with the option \"none of these.\" This modification increased question difficulty, resulting in a significant"}, {"title": "6.2 Result of Transportation Information Retrieval", "content": "This section presents the experimental results of evaluating LLM capabilities in transportation information retrieval\n(Experiment V). A total of 42 simple and 38 complex short-answer questions were employed. Alongside each question,\nnecessary data files were provided as input. The LLMs were tasked with extracting relevant information from these files\nto generate accurate responses.\nFigure 1 demonstrates the significant potential of LLMs for information retrieval tasks. When presented with simple\nqueries, LLMs achieved an impressive average accuracy of approximately 81%, with a best performance of 90.48%\nby GPT-40. However, performance declined to an average of approximately 64% when handling complex questions\nrequiring data integration across multiple files.\nGPT-40 consistently outperformed GPT-3.5-turbo across all question types, demonstrating an average performance\nincrease of approximately 15%. This finding aligns with previous results from Experiments II-IV and the comparison\nbetween augmented and non-augmented datasets in Section 6.1, reinforcing GPT-40's superior capabilities."}, {"title": "7 Analysis and Discussion", "content": "This study explored the potential of large language models in the context of public transportation, focusing on\nunderstanding and retrieval tasks within San Antonio's transit system. Our experiments, employing GPT-3.5-turbo\nand GPT-4, demonstrated varying levels of LLM performance across different tasks on 3275 questions. The model\nperformance is ranging from 47.97% to 98.44% accuracy.\nA notable challenge emerged in the Categorical Mapping task, where both models achieved relatively low accuracy\n(an average of 51.35% and 51.01%, respectively). This is likely attributed to the semantic similarity between certain"}, {"title": "7.1 LLMs for Transportation Applications", "content": "categories, as evidenced by the high cosine similarity between \u201cRail\" and \"Light Rail.\" Addressing this issue could\ninvolve developing more nuanced category embeddings or exploring alternative classification methods.\nThe augmented understanding tasks (Experiments II and IV) also revealed a significant performance decline, indicating\nthat LLMs struggle with inherent question ambiguity. This suggests a need for more robust question clarification or\ndisambiguation techniques. Additionally, while LLMs excelled at simple information retrieval (Experiment V), their\nperformance deteriorated significantly with complex queries requiring data integration. This highlights the importance\nof developing strategies to enhance LLM capabilities in handling multifaceted information.\nOverall, our findings suggest that LLMs hold promise for transportation applications. However, to realize their full\npotential, careful engineering and fine-tuning are essential to address the identified challenges. Future research should\nfocus on improving LLM performance in tasks involving semantic similarity, question ambiguity, and complex data\nintegration."}, {"title": "7.2 Inconsistency Issues in LLM", "content": "Through this work, we also noticed that there may be other potential issues that make the adoption of LLMs in\ntransportation challenging. One of the most notable challenges is performance inconsistency that can manifest in\nvarious ways, including contradictions, fluctuating levels of details, and varying degrees of factual accuracy. Here we\nprovide different key aspects of such inconsistency:\n\u2022 Contradictory Responses: LLMs can produce responses that contradict each other when asked the same or\nsimilar questions in different contexts or at different times. This is particularly problematic in applications\nwhere reliability and coherence are crucial.\n\u2022 Context Sensitivity: LLMs sometimes fail to maintain context over long conversations or across multiple\ninteractions. They may provide contextually appropriate answers in one part of a conversation but fail to do so\nlater, leading to inconsistencies.\n\u2022 Factual Accuracy: While LLMs can generate text based on a vast amount of data, they may sometimes produce\nincorrect or misleading information. The same question asked in different ways or at different times can yield\ndifferent, sometimes contradictory, factual statements.\n\u2022 Bias and Fairness: LLMs trained on diverse datasets can inadvertently learn and reproduce biases present in\nthe training data. This can lead to inconsistent and unfair responses that reflect these biases.\n\u2022 Detail Level Fluctuation: The detail level in responses can vary, with LLMs sometimes providing overly\ndetailed answers and at other times being too vague. This fluctuation can be problematic for users who rely on\nconsistent levels of information.\nAdditionally, we noticed that OpenAI's Playground and programmatic API may produce inconsistent results, even if\nboth of them use the same pre-trained model. Below are some potential reasons that have been discussed among the\nOpenAI community23:\n\u2022 Version and Configuration Differences: The API and Playground might be configured differently in terms of\nmodel versions, parameters such as: temperature, maximum tokens, and other settings. Even slight variations\nin these configurations can lead to different outputs for the same input.\n\u2022 Request Formatting: The way requests are formatted and sent can differ between the API and Playground. For\ninstance, users may include different prompts, system messages, or structure their inputs differently, impacting\nthe model's response.\n\u2022 Session Management: The Playground often maintains session history, allowing the model to retain context\nfrom previous interactions within the same session. In contrast, API requests might be stateless unless explicitly\ndesigned to maintain context, leading to potential inconsistencies in responses.\n\u2022 User Inputs and Interaction Style: Users might interact differently with the model depending on the interface.\nThe interactive nature of the Playground can lead to more iterative and refined queries, while API usage might\ninvolve more straightforward, single-shot requests.\n\u2022 Model Updates and A/B Testing: OpenAI may deploy updates or conduct A/B testing on either the API or\nPlayground, leading to temporary differences in model behavior as new features or improvements are tested."}, {"title": "7.3 Prompt Engineering", "content": "Prompt engineering is the systematic design of textual inputs to guide large language models (LLMs) toward desired\noutputs. By carefully crafting prompts, practitioners can optimize model performance for various tasks, including\ngeneration, manipulation, and reasoning. This process is crucial for maximizing the utility of LLMs in diverse\napplications [37],[38]. For instance, the performance of our experiments may improve by up to \u2248 8% through\noptimized prompting, highlighting the necessity of prompt engineering in transportation applications that involve LLMs."}, {"title": "8 Conclusion and Future Work", "content": "This work evaluates the ability of Large Language Models (LLMs) to understand public transportation information\nthrough two tasks: understanding and information retrieval. The LLMs achieved accuracy ranging from 47.97% to\n98.44% on the understanding task and 60.53% to 90.48% on information retrieval. The strong performance on certain\nunderstanding tasks, such as Term Definition, File Structure, Data Structure, and Attribute Mapping, indicates that\npre-trained LLM models have gathered a substantial amount of transportation-related information from their training\ndatasets. However, the considerable disparity between the best and worst-performing tasks suggests that these models\nmay have been trained on an imbalanced dataset, with significantly less information available on specific topics. While\nthey can handle tasks involving unknown data-evidenced by their high performance in information retrieval-their\neffectiveness appears to diminish as task complexity increases. This study highlights the significant potential of large\nlanguage models in transforming public transit systems and enhancing user experiences. By improving passenger\ninformation services, operational efficiency, and accessibility, LLMs present a variety of applications that can greatly\nbenefit public transit. However, the notable performance gaps between the best and worst tasks must be addressed\nbefore real-world implementation. Additionally, it will be crucial to tackle ethical concerns and ensure responsible use\nof these technologies as the field evolves. With ongoing research and development, LLMs could play a vital role in the\nfuture of public transportation."}]}