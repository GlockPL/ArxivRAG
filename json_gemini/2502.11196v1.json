{"title": "How Do LLMs Acquire New Knowledge?\nA Knowledge Circuits Perspective on Continual Pre-Training", "authors": ["Yixin Ou", "Yunzhi Yao", "Ningyu Zhang", "Hui Jin", "Jiacheng Sun", "Shumin Deng", "Zhenguo Li", "Huajun Chen"], "abstract": "Despite exceptional capabilities in knowledge-intensive tasks, Large Language Models (LLMs) face a critical gap in understanding how they internalize new knowledge, particularly how to structurally embed acquired knowledge in their neural computations. We address this issue through the lens of knowledge circuit evolution, identifying computational subgraphs that facilitate knowledge storage and processing. Our systematic analysis of circuit evolution throughout continual pre-training reveals several key findings: (1) the acquisition of new knowledge is influenced by its relevance to pre-existing knowledge; (2) the evolution of knowledge circuits exhibits a distinct phase shift from formation to optimization; (3) the evolution of knowledge circuits follows a deep-to-shallow pattern. These insights not only advance our theoretical understanding of the mechanisms of new knowledge acquisition in LLMs, but also provide potential implications for improving continual pre-training strategies to enhance model performance\u00b9.", "sections": [{"title": "Introduction", "content": "Knowledge is a cornerstone of intelligence, shaping how humanity perceives the world, interacts with others, and navigates daily life (Choi, 2022; Chen, 2023). Recent studies (Brown et al., 2020; OpenAI, 2023; Dubey et al., 2024; DeepSeek-AI et al., 2024; Yang et al., 2024; Zhao et al., 2023; Wu et al., 2024) on Large Language Models (LLMs) have demonstrated their ability to capture factual knowledge from pre-training corpus and encapsulate it as extensive parametric knowledge, empowering their remarkable capabilities in numerous knowledge-intensive tasks (Wang et al., 2024; Cao et al., 2024), as well as in developing higher-order capabilities like reasoning (Qiao et al., 2023; Huang and Chang, 2023). Nevertheless, these powerful models still struggle with knowledge updates, especially with regard to the dynamic nature of world knowledge that evolves after the cut-off date of the pre-training corpus (Zhang et al., 2023; Mousavi et al., 2024). Extensive efforts focus on developing advanced techniques for injecting new knowledge into LLMs (Jang et al., 2022; Jiang et al., 2024; Mecklenburg et al., 2024; Ovadia et al., 2024; Chen et al., 2024a), yet the absence of a well-defined mechanism for new knowledge acquisition in LLMs continues to hinder further progress in this area.\nRecent works introduce mechanistic interpretability techniques to uncover knowledge mechanisms in LLMs. Allen-Zhu and Li (2024a) adopts probing methods to examine the storage and extraction of factual knowledge encoded in hidden states of language models. Kim et al. (2024) introduces the concept of knowledge entropy to examine how the integration of knowledge of LLMs evolves during the pre-training phase. However, previous works typically treat knowledge blocks as isolated components and often focus on identifying specific blocks that store particular knowledge. In contrast, Yao et al. (2024) move beyond isolated components and explore the computation graph to uncover knowledge circuits, investigating cooperation between different components to understand how knowledge is stored and expressed.\nIn this paper, we investigate the mechanism of new knowledge acquisition in LLMs from the perspective of knowledge circuits. By analyzing the evolution of knowledge circuits throughout continual pre-training, we uncover several interesting findings, as illustrated in Figure 1.\nKey findings of the paper are summarized as:\n\u2022 (\u00a74.1) The acquisition of new knowledge is significantly influenced by its relevance to pre-existing knowledge, with relevant new knowledge being integrated more efficiently than completely new knowledge.\n\u2022 (\u00a74.2) In the process of knowledge acquisition, the evolution of knowledge circuits exhibits a distinct phase shift from formation to optimization, each marked by unique structural and behaviral characteristics;\n\u2022 (\u00a74.3) The evolution of knowledge circuits follows a deep-to-shallow pattern, where mid-to-deeper layers first develop the extraction function, and later, lower layers enrich their knowledge representations.\nThese findings offer valuable insights into the mechanisms by which LLMs adapt their internal structures to acquire new knowledge. This understanding not only informs potential strategies for enhancing the continual learning capabilities of LLMs but also provides a solid foundation for improving their adaptability across diverse domains."}, {"title": "Background", "content": ""}, {"title": "Circuit Theory", "content": "Delving into the Transformer architecture (Vaswani et al., 2017), all computations in a Transformers-based language model as a connected directed acyclic graph, denoted as G. This graph represents the flow of information from the input of the language model to the token unembedding, where activations are projected back to vocabulary space. Various components of a language model, including attention heads and multi-layer perceptrons (MLPs), are defined as the nodes of this graph, denoted as N. The edges of this graph, denoted as E, are the weighted connections between these components, encompassing residual connections, attention mechanisms, and projections. In the context of Mechanistic Interpretability (MI), which aims to understand the inner workings of adavanced Transformer-based language models (Rai et al., 2024; Ferrando et al., 2024; Bereska and Gavves, 2024; Sharkey et al., 2025), a circuit is conceptualized as a sparse computational subgraph $C \\subset G$ within a language model whose computations are most relevant to the whole model's behaviour on the specific task (Olah et al., 2020; Elhage et al., 2021; Wang et al., 2023; Marks et al., 2024). A circuit C usually contains a selection of nodes $N_C \\subset N$ and edges $E_C \\subset E$ necessary for the specific task, expressed as $C =< N_C, E_C >."}, {"title": "Circuit as Computational Subgraph", "content": "The goal of circuit discovery is to identify a computational subgraph that represents the whole model's behavior on a specific task. Many studies adopt causal mediation analysis to localize critical nodes or edges within language models in order to identify and verify circuits. Conmy et al. (2023) adopts activation patching and proposes ACDC. Syed et al. (2023) introduces Edge Attribution Patching (EAP) to make a linear approximation of activation patching, which assigns an importance score to each edge."}, {"title": "Knowledge Circuits", "content": "Unlike previous works (Dai et al., 2022; Geva et al., 2021, 2023; Meng et al., 2022) that treat the knowledge blocks as isolated components, Yao et al. (2024) introduce a novel perspective: knowledge circuits. They hypothesis that the cooperation between multiple components unveils implicit knowledge representation in LLMs. An identified knowledge circuit is considered a computational subgraph that faithfully represents specific knowledge domains within the model's parametric memory. As such, it should be capable of independently reproducing the behavioral patterns or performance of the entire model with respect to the corresponding tasks. However, Yao et al. (2024) concentrates exclusively on the knowledge that already stored in the language model, without investigating the process by which LLMs acquire knowledge. In this work, we aim to advance the concept of knowledge circuits by investigating their dynamics throughout continual pre-training."}, {"title": "Methodology", "content": ""}, {"title": "Dataset Construction", "content": "Given the challenges of conducting mechanistic interpretability analysis on Internet-scale corpus, we perform controlled experiments on synthetic data, following Allen-Zhu and Li (2024a, 2023, 2024b). We focus on factual knowledge that can be represented as triples of the form (s, r, a) containing subject s, relation r, and attribute a. We synthesize a pool of fictional knowledge entities based on heuristic rules using ChatGPT, ensuring that these fictional biographical knowledge is unavailable to LLMs in the pre-training phase. Each knowledge entity is first assigned a unique name as the subject, and then associated with five relations\u2014birth date, city, major, university and company-and corresponding attributes. To convert these entities into textual knowledge for training data, we fill them in predefined templates. Considering real-world data scenarios and the perspectives of analysis, we further customize the training corpus from two aspects: knowledge type and knowledge frequency."}, {"title": "Knowledge Type", "content": "We classify the new knowledge that the language model may need to acquire into two categories. One involves knowledge that already exists in the model's parameters but requires further learning of specific aspects (e.g., new relations). This type of knowledge is referred to as relevant new knowledge and denoted as $K_{rel}$. The other type of knowledge is absent from the model's parameters, which is referred to as completely new knowledge and denoted as $K_{compl}."}, {"title": "Knowledge Frequency", "content": "Considering the long-tail distribution of knowledge in real-world data, we model the frequency of knowledge entities in the corpus to follow an exponential distribution. This ensures that the corpus for continual pre-training contains both high-frequency knowledge as well as long-tail knowledge.\nMore details of the pipeline of dataset construction are provided in Appendix A."}, {"title": "Model Training", "content": "To conduct the knowledge acquisition experiment, we use three series of typical decoder-only LLMs to yield consistent findings on different architectures: GPT-2, Llama, and Phi. We continually pre-train the base models using a standard next-token prediction objective on the corpus described in Section 3.1. Further details on the training configuration can be found in Appendix B."}, {"title": "Circuit Discovery", "content": "To facilitate the discovery of circuits over multiple checkpoints throughout continual pre-training, we select EAP-IG (Hanna et al., 2024) from a range of circuit discovery techniques (Conmy et al., 2023; Syed et al., 2023; Ferrando and Voita, 2024; Hanna et al., 2024), which assigns an importance score to each edge, balancing efficiency and faithfulness. Given an edge e = (u, v) \u2208 E between nodes u \u2208 N and v \u2208 N with clean and corrupted activations $z_u$ and $z'_u$, EAP-IG scores the importance of e as:\n$S(e) = (z_u - z'_u) \\frac{1}{m} \\sum_{k=1}^{m} \\frac{\\partial L (z'_v + (z_v - z'_v))}{\\partial z_v}$   (1)\nwhere z refers to a sequence of token embeddings for one input, z' refers to the token embeddings of the distinct, baseline input, and m refers to the number of integrated gradient steps; we set m = 5 as suggested by Hanna et al. (2024). More details of circuit discovery are provided in Appendix C.\nAfter scoring all edges within a language model using EAP-IG, we identify a circuit by selecting the top n edges with the highest absolute score as in Syed et al. (2023), ensuring that the selected edges collectively achieve over 70% of the whole model's performance on the specific task. Specifically, we retain 8k, 20k, 50k, and 50k edges for GPT-2 Small, GPT-2 Medium, TinyLlama, and Phi-1.5, respectively."}, {"title": "Analyzing the Evolution of Knowledge Circuits throughout Training", "content": "Once we have identified the knowledge circuits, we delve deeper into the changes within the circuits, examining the transitions in the roles and behaviors of nodes and edges. Specifically, we conduct the analysis from three perspectives: performance, topology, and components."}, {"title": "Performance Analysis", "content": "An identified knowledge should be capable of independently reproducing the behavioral patterns or performance of the whole model with respect to the corresponding tasks. This property can be evaluated by examining whether the identified knowledge circuit aligns with the underlying algorithm implemented by the model. Following Yao et al. (2024), we employ the Hit@10 metric to measure the rank of the target token among the top 10 predicted tokens throughout training process:\n$Hit@10 = \\frac{1}{|D_{test}|} \\sum_{i=1}^{|D_{test}|} I (rank_a \\leq 10)$ (2)\nwhere $|D_{test}|$ denotes the test set size, a the target attribute, and $rank_a$ the rank of the first token of target attribute a in vocabulary space. To evaluate completeness, we assess the identified circuit's standalone performance on a held-out test set, which is filtered by the same knowledge type and frequency as the validation set for circuit discovery.\nThe results depicted in Figure 2 reveal a consistent growth pattern in the Hit@10 metric until it approach its upper bound, which demonstrates the sustained knowledge acquistion capability of knowledge circuits throughout continual pre-training. Notably, the $K_{rel}$ performance curve consistently lies above the curve for $K_{compl}$, suggesting that LLMs exhibit preferential learning efficiency when assimilating knowledge extensions within existing conceptual frameworks, as opposed to acquiring completely new knowledge. These patterns persist in the whole model evaluation in Appendix D, suggesting that knowledge circuits capture general learning dynamics rather than isolated phenomena in LLMs."}, {"title": "Takeaway: Knowledge Relevance Principle", "content": "The acquisition of new knowledge is influenced by its relevance to pre-existing knowledge. LLMs exhibit learning efficiency advantages when acquiring relevant new knowledge versus completely new knowledge.\nThis insight could motivate the utilization of data curriculums in continual pre-training, by organizing the data in a way that mimics the structure and distribution of the original corpus, thereby enabling the model to integrate new information more efficiently (Y\u0131ld\u0131z et al., 2024; Parmar et al., 2024; Chen et al., 2024b).\nAnother notable observation in Figure 2 is that the performance of knowledge circuits is positively correlated with knowledge frequency. We further evaluate the performance of knowledge circuits by transferring them to a test set with different knowledge frequencies, as detailed in Appendix E. The results imply that the poor performance of knowledge circuits for low-frequency knowledge may stem from insufficient knowledge representations, rather than fundamental capacity limitations of circuits. This suggests that strategies focused on reactivating long-tail knowledge, such as knowledge augmentation, may improve knowledge retention in LLMs over time (Allen-Zhu and Li, 2024a)."}, {"title": "Topology Analysis", "content": ""}, {"title": "Structural Consistency", "content": "We first quantify the structural consistency of knowledge circuits by measuring the Jaccard Similarity between edge sets (Figure 3) and node sets (Figure 11 in Appendix) within knowledge circuits at intermediate checkpoints relative to the final circuit. Both metrics exhibit a consistent monotonic upward trend throughout training, indicating that the knowledge circuits become increasingly similar to the final circuit. This convergence pattern suggests an evolutionary process where knowledge circuits progressively stabilize their core architecture as knowledge acquisition progresses. Based on the observed trends, we hypothesize that the process of knowledge acquisition is driven by topological centralization within knowledge circuits, with a small subset of critical edges and nodes gaining dominance in the flow of information."}, {"title": "Topological Centralization", "content": "To validate the hypothesis, we define a knowledge circuit entropy metric quantifying edge importance concentration, drawing on the concepts of uncertainty and information content from probability theory and information theory. The more centralized the topology of the knowledge circuit, the more the importance weights become concentrated on a few critical edges, resulting in a lower knowledge circuit entropy. To calculate the entropy of a knowledge circuit $C =< N_c, E_c >$, we first normalize the absolute value of the importance of each edge $e \\in E_c$, scored by EAP-IG in equation (1):\n$P(e) = \\frac{S(e)}{\\sum_{e' \\in E_c} |S(e')|}, \\forall e \\in E_c$ (3)\nThe circuit entropy is then calculated as:\n$H(C) = - \\sum_{e \\in E_c} P(e) log P(e)$ (4)\nOur results in Figure 3 show a stable downward trend in the knowledge circuit entropy metric for edges in the subgraph across all models, suggesting that the identified knowledge circuits become increasingly centralized, with the importance of critical edges growing as knowledge acquisition progresses. We also observe that the downward trend of the knowledge circuit entropy slows down significantly after a certain turning ponit during the training of all models. For example, turning points are observed in GPT-2 Small, GPT-2 Medium, TinyLlama, and Phi-1.5 at epoch 7, epoch 4, epoch 1, and epoch 1, respectively. We attribute this interesting phenomenon to a phase shift in the evolution of knowledge circuits across continual pre-training. In the initial formation phase of knowledge circuits, less efficient knowledge circuits gradually take shape within the models, resulting in a rapid decrease in circuit entropy. At the phase shift points, the knowledge circuits reach a status of stability where the most critical nodes and edges have been involved. In the subsequent optimization phase, the topology composed critical nodes and edges becomes more stable, while the computations within these components are being optimized to represent and retrieve the knowledge more efficiently, leading to a slowdown in the rate of decrease in circuit entropy.\nIt's no coincidence that we also observe consistent phase shift points in the structral consistency of the nodes and edges in knowledge circuits throughout continual pre-training in Figure 3 and Figure 11, which signal a slowdown in the rate of structural convergence. This further confirms a reduction in the topological changes of the knowledge circuits, with subsequent performance improvements primarily attributed to the refinement and optimization of the efficiency of the existing structure."}, {"title": "Takeaway: Biphasic Circuit Evolution", "content": "The evolution of knowledge circuits exhibits a distinct phase shift from formation to optimization, each marked by unique structural and behaviral characteristics.\nThis finding suggests that the knowledge circuit state could serve as a valuable tracking status for the continual pre-training process, enabling more informed adjustments to the training method or data in response to different phases. We leave this potential direction for future research."}, {"title": "Aligning Topology with Specific Knowledge Circuits", "content": "To clarify the influence of the topology of knowledge circuits on performance, we conduct a detailed examination of the knowledge circuits at several key training checkpoints. Specifically, we focus on the knowledge circuits at the initial checkpoint, the checkpoint immediately before the phase shift point, the checkpoint immediately after the phase shift point, and the last checkpoint. We align the topology of the knowledge circuits at each checkpoint throughout training with those of focus and then evaluate the performance for aligned circuits employing the Hit@10 metric as in \u00a74.1.\nThe results in Figure 4 reveal that the performance of all aligned circuits remain unchanged during the formation phase. However, each circuit begins to improve its performance during the optimization phase, with those aligned with the post-phase-shift topologies (After and Last) ultimately performing, on average, 54% better than those aligned with the pre-phase-shift topologies (Init and Before)."}, {"title": "Components Analysis", "content": "After analyzing the dynamics of the knowledge circuits at the overall topology level, we may further seek to understand how the components within these circuits evolve throughout training."}, {"title": "Evolutionary Pattern of Components", "content": "We first zoom into the specialized nodes within knowledge circuits to investigate the underlying factors driving the evolution of knowledge circuit. Recent studies have identified a set of specialized attention heads (Zheng et al., 2024; Ferrando et al., 2024) that directly contribute to factual recall in Transformer-based LLMs, in- cluding the mover head, relation head, and mixture head (Lv et al., 2024; Merullo et al., 2024; Chughtai et al., 2024). More detailed definitions and methodology for identifying these specialized attention heads are provided in Appendix G. We check the emergence and track the proportion of these specialized attention heads in all possible nodes of the knowledge circuits throughout training, and present our results in Figure 5. We observe that during the circuit formation phase, mover heads gradually emerge from nearly zero, while the proportion of relation heads decreases until the phase shift. In the circuit optimization phase, the proportion of all kinds of attention heads stabilizes. The proportion of mixture heads remains stable throughout training. We further examine the layer-wise distribution of mover heads and relation heads within knowledge circuits throuout training. Our results in Figure 6 (and Figure 13 in Appendix) reveal that the increase in mover heads and the decrease in relation heads primarily occur in the mid-to-deeper layers during the circuit formation phase.\nNext, we investigate how the nodes within knowledges circuits propagate information to subsequent components through the edges. Specifically, we analyze the variation in edge activation patterns across different layers of the network throughout training. We quantify the edge activation ratio for each layer by calculating the proportion of edges originating from that layer within the knowledge circuit, relative to all possible edges originating from that layer in the whole model2. Our results in Figure 7 (and Figure 12 in Appendix) reveal that, during the circuit formation phase, the edges activation ratios in the lower layers gradually decrease, while those in the mid-to-deeper layers exhibit a corresponding increase. However, as training progresses, a transition occurs around the phase shift point, where the edge activation ratios begin to stabilize."}, {"title": "Activated Edges", "content": "The observed pattern in the evolution of specialized nodes and activated edges within knowledge circuits aligns with the factual recall mechanism in LLMs described by Geva et al. (2023). Specifically, the lower MLP layers specialize in encoding attribute-rich subject representations, while attention heads in the mid-to-deeper layers are responsible for extracting the relevant attributes for a given subject from these lower-level representations. Based on this, we can conclude the evolutionary pattern of knowledge circuits at the component level. During the early training phase of circuit formation, the focus is primarily on developing the extraction function within the nodes of the mid-to-deeper layers of the knowledge circuits. This is reflected in the increased emergence of mover heads and activated edges, along with a decrease in the presence of relation heads in these layers. This process continues until the extraction function is fully established at the phase shift point, as demonstrated by the similar performance advantage of circuits aligned with the post-phase-shift topologies over those aligned with the pre-phase-shift topologies in Figure 4. In the subsequent training phase of circuit optimization, the focus shifts to enriching knowledge representations in the lower layers, evidenced by a stabilized"}, {"title": "Evolutionary Pattern", "content": "The evolution of knowledge circuits follows a deep-to-shallow pattern, where mid-to-deeper layers first develop the extraction function, and later, lower layers enrich their knowledge representations."}, {"title": "Changes in Vocabulary Space", "content": "To gain a more nuanced understanding of the information flow, we track the layer-wise changes in both the rank and probability of the target attribute token at the last token position when unembedding the intermediate layer's output into the vocabulary space throughout training. Additional results for other models are provided in Appendix F. The results in Figure 8 reveal that the occurrence of the early decoding phenomenon (nostalgebraist, 2020)\u2014where the target token is already present in the residual stream by the mid-to-later layers\u2014is closely associated with the phase shift in the evolution of knowledge circuits. During the circuit formation phase, the mid-to-deeper layers exhibit low ranks and probabilities for the target token, suggesting that the attention heads in these layers have not yet effectively extracted the target attribute in the residual stream due to the insufficient training. However, in the subsequent circuit optimization phase, the extraction function has already been developed in the mid-to-deeper layers, while the lower layers continue to enrich their knowledge representations for subjects, as evidenced by the occurrence of early decoding phenomenon."}, {"title": "Components", "content": ""}, {"title": "Deep-to-Shallow Pattern", "content": "Previous studies (Chang et al., 2024) explore new knowledge acquisition in LLMs with various behavioral interpretability techniques, which characterizes model behavior without revealing insights into the internal workings. Recent works introduce mechanistic interpretability techniques to advance related research even further. Allen-Zhu and Li (2024a) adopt probing methods to examine the storage and extraction of factual knowledge encoded in hidden states of language models. Building on studies that treat feed-forward layers as a key-value memory (Geva et al., 2021; Dai et al., 2022), Kim et al. (2024) introduce the concept of knowledge entropy to examine how LLMs' knowledge integration evolves during the pre-training phase. In this paper, we seek to uncover the internal mechanism of new knowledge acquisition in LLMs by investigating the dynamics of knowledge circuits within LLMs thtroughout continual pre-training.\nWith the rise of LLMs, Mechanistic Interpretability (MI) has gained prominence for reverse-engineering Transformer-based language models to decode their internal computations (Rai et al., 2024; Ferrando et al., 2024; Bereska and Gavves, 2024; Singh et al., 2024; Sharkey et al., 2025). Early MI research identifies features that consistently activate for specific input properties as elementary computational units. While such studies reveal phenomena such as polysemanticity and enable applications like knowledge editing (Yao et al., 2023; Zhang et al., 2024a; Hase et al., 2024) and steering (Turner et al., 2023), they offer limited insights into how features interact to drive model behaviors. This gap motivates circuit analysis (Elhage et al., 2021; Yao et al., 2024), which investigates computational pathways between Transformer components. Most similar to our work, Tigges et al. (2024) examines general circuits formation during pre-training, while our work focuses on the evolution of knowledge circuits throughout continual pre-training."}, {"title": "Conclusion", "content": "In this paper, we present a novel perspective on new knowledge acquisition of LLMs through an investigation into the evolution of knowledge circuits throughout continual pre-training. Through comprehensive analysis at performance, topology, and components levels, we reveal several key insights. We believe these insights will contribute to more efficient and effective continual pre-training of LLMs, while also uncovering the mechanisms behind new knowledge acquisition in LLMs."}, {"title": "Related Work", "content": ""}, {"title": "Limitations", "content": ""}, {"title": "Model Architectures", "content": "Our paper investigates the evolution of knowledge circuits solely in decoder-only Transformer LMs, due to their excellent performance and wide range of applications. We omit other Transformer variants, such as encoder-decoder and encoder-only models, from our analysis. Additionally, due to limitations in both computational resources and the circuit discovery method, we do not analyze models with larger parameter sizes than 1.3B, which typically employ Grouped Query Attention (Ainslie et al., 2023). However, Tigges et al. (2024) suggests that circuit analyses conducted on small models can provide insights that still apply over model scales."}, {"title": "Traininig Techniques", "content": "We adopt the standard next-token prediction objective for continual pre-training of the base models in our experiments, as it is the most prevalent approach for enabling LLMs to acquire new knowledge. However, numerous studies (Jiang et al., 2024; Mecklenburg et al., 2024) focus on designing novel training techniques to enhance the efficiency and effectiveness of LLMs in acquiring new knowledge. We do not analyze the impact of these additional training techniques on the evolution of knowledge circuits."}, {"title": "Training Steps", "content": "Given the challenges of conducting mechanistic interpretability analysis on Internet-scale corpus, we perform controlled experiments on synthetic data, following Allen-Zhu and Li (2024a, 2023, 2024b). We focus on factual knowledge that can be represented as triples of the form (s, r, a) containing subject s, relation r, and attribute a. For example, a piece of factual knowledge such as \"Donald Trump is 78 years old\" can be represented as (Donald Trump, age, 78).\nWe synthesize a pool of fictional knowledge entities based on heuristic rules using ChatGPT, ensuring that these fictional biographical knowledge is unavailable to LLMs in the pre-training phase. Each knowledge entity is first assigned a unique name as the subject. Each name follows the format \"first_name middle_name last_name\", where the components are randomly and independently sampled from a uniform distribution. We use ChatGPT to generate possible values for first name, middle name, and last name, as listed in Table 3.\nAdditionally, there are five associated relations\u2014birth date, city, major, university and company\u2014which are randomly sampled from their corresponding pools of possible attributes for each relation. The birthdate relation offers 30 (1 to 30) \u00d7 12 (January to December) \u00d7 126 (1900 to 2025) possibilities. The corresponding pools of possible attributes for the other four relations are as generated by ChatGPT, as listed in Table 4~7.\nTo convert these entities into textual knowledge for training data, we populate predefined templates with the attribute values. For each attribute, one of 50 corresponding templates is randomly selected to enhance the diversity of the corpus. The sentences corresponding to each relation of the same subject are then randomly shuffled to form the biography segment of the subject. An example is provided below:\n\"Liora Shane Driscoll's birth is celebrated annually on 5 December, 1935. Liora Shane Driscoll is situated in Newport News, VA. Liora Shane Driscoll is an expert in the making in Agronomy. Liora Shane Driscoll is an alumni member of North Carolina State University. Liora Shane Driscoll is a worker at Google.\""}, {"title": "Appendix", "content": ""}, {"title": "Knowledge Type", "content": "We classify the new knowledge that the language model may need to acquire into two categories. One involves knowledge that already exists in the model's parameters but requires further learning of specific aspects (e.g., new relations). This type of knowledge is referred to as relevant new knowledge and denoted as $K_{rel}$. The other type of knowledge is completely new, absent from the model's parameters, which is referred to as completely new knowledge and denoted as $K_{compl}$. To simulate real-world data scenarios, we set the knowledge type ratio as |$K_{rel}$|:|K_{compl}| = 1 : 4. Specifically, for complete new knowledge, we exclusively use synthetic fictional knowledge entities. For relevant new knowledge entities, we extract a set of celebrity names from Wikipedia, which are highly likely to appear in pre-training, and then sample fictional attributes for these entities."}, {"title": "Dataset Construction", "content": "Considering the long-tail distribution of knowledge in real-world data, we model the frequency of knowledge entities in the corpus to follow an exponential distribution. This ensures that the corpus for continual pre-training contains both high-frequency knowledge as well as long-tail knowledge. We classify portions of the corpus based on frequency: Knowledge entities with a frequency greater than 5 in the corpus are classified as high-frequency knowledge, those with a single occurrence as low-frequency knowledge, and the remaining entities as medium-frequency knowledge.\nWe set the number of all individuals appearing in the training corpus to 50,000, with their frequency following an exponential distribution between 1 and 27. This finallly result in 133,408 biography segments, with a total length of 10 million tokens and an average length of 76.8 tokens per biography segment."}, {"title": "Training Configuration", "content": ""}, {"title": "GPT-2", "content": "We adopt the standard GPT-2 (Radford et al., 2019) implementation available on Huggingface, including GPT-2 Small and GPT-2 Medium."}, {"title": "Llama", "content": "Given the huge experimental cost associated with the original Llama (Touvron et al., 2023a,b; Dubey et al., 2024), which typically have parameters exceeding 7 billion, we perform surrogate experiments using a relatively small model, TinyLlama (Zhang et al., 2024b). TinyLlama adopts exactly the same architecture and tokenizer as Llama 2, but with only 1.1 billion parameters, facilitating more efficient experimentation."}, {"title": "Phi", "content": "We adopt Phi-1.5 (Li et al., 2023) with 1.3 billion parameters.\nFor continual-pre training, we use a constant learning rate schedule without warmup. Our learning rate is set to match the learning rate of the base model at the end of its pre-training phase. We train using the AdamW optimizer with \u03b2\u2081 = 0.9, \u03b2\u2082 = 0.95, \u20ac = le-6, and a weight decay of 0.1. We perform gradient accumulation for every 4 steps. We present several key statistics of the base models and more hyperparameters that are altered in our experiments in Table 1.\nAll of our continual pre-training experiments are runned on 2 NVIDIA-A100 GPUs."}, {"title": "Circuit Discovery", "content": "Unlike previous works that investigate circuits on simple but general tasks such as Indirect Object Identification (IOI) and Greater-Than, our paper focuses on knowledge circuits that are capable of performing the task of factual recall. In a factual recall task, the objective is to predict a target attribute a given a subject-relation pair (s, r). To ensure a sufficiently rich vocabulary space for the first token of the target attribute, we construct the factual recall tasks based on three relations mentioned in \u00a73.1: city, major, and company. The templates for converting a subject-relation pair (s,r) into a query string for each factual recall task are listed in Table 2. A typical circuits task consists of minimal pairs of clean and corrupted inputs. For clean inputs, we randomly sample 300 examples from the training corpus for each knowledge type and frequency as the validation set $D_{val}$ for circuit discovery. In our experiments, we observe that continually increasing the size of $D_{val}$ only adds to the runtime for circuit discovery without improving the quality of the discovered circuits. The corresponding corrupted inputs are independently sampled from the training corpus to match the length of the subject tokens in each clean input."}, {"title": "Tasks", "content": "The metric for circuit tasks assesses how closely the language model outputs align with clean input, as opposed to corrupted input. In our circuit discovery experiments, we evaluate the performance of circuits using the logit difference: the logit of the correct attribute minus the logit of the corrupted attribute. We then convert the task metric M into a loss function by defining"}, {"title": "Loss", "content": "$\\sum_{i=1}^{|D_{val}|} \\frac{DLA(Q_i)_{subject}}{DLA(Q_i)_{relation}}  >= T$ (5)"}, {"title": "Heads", "content": "$\\sum_{i=1}^{|D_{val}|} \\frac{DLA(Q_i)_{relation}}{DLA(Q_i)_{subject}}  <="}]}