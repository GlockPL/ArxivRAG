{"title": "A Cross-Domain Study of the Use of Persuasion Techniques in Online Disinformation", "authors": ["Jo\u00e3o A. Leite", "Olesya Razuvayevskaya", "Carolina Scarton", "Kalina Bontcheva"], "abstract": "Disinformation, irrespective of domain or language, aims to deceive or manipulate public opinion, typically through employing advanced persuasion techniques. Qualitative and quantitative research on the weaponisation of persuasion techniques in disinformation has been mostly topic-specific (e.g., COVID-19) with limited cross-domain studies, resulting in a lack of comprehensive understanding of these strategies. This study employs a state-of-the-art persuasion technique classifier to conduct a large-scale, multi-domain analysis of the role of 16 persuasion techniques in disinformation narratives. It shows how different persuasion techniques are employed disproportionately in different disinformation domains. We also include a detailed case study on climate change disinformation, highlighting how linguistic, psychological, and cultural factors shape the adaptation of persuasion strategies to fit unique thematic contexts.", "sections": [{"title": "1 Introduction", "content": "Disinformation campaigns, amplified by digital media, are often weaponising sophisticated persuasion techniques to shape public opinion by manipulating public perceptions and advocating for certain actions [11].\nExisting research on disinformation discourse has predominantly examined the narratives and tactics employed to influence public opinion, often touching on elements related to persuasion techniques, such as propaganda, which has a broader scope [11]. For instance, previous studies have examined pro-Kremlin propaganda in the Russo-Ukrainian war, uncovering tactics aimed at maintaining domestic support and justifying aggression [2]. Similarly, research into climate disinformation has highlighted that logical fallacies and conspiracy theories are used to discredit scientific consensus [4], while analyses of COVID-19 disinformation have identified narratives such as fear-mongering and conspiracy theories [12]. In natural language processing, researchers focused on datasets and models for automated persuasion technique detection [5, 18].\nWhile these studies provide valuable insights, they focus on individual domains, and employ different taxonomies and conceptualisations. This leads to a limited understanding of how persuasion techniques are employed by disinformation narratives in different domains. To address this gap, our study employs a state-of-the-art persuasion classifier to conduct a large-scale, cross-domain analysis of the role of persuasion techniques in disinformation. In particular, we compare the use of sixteen distinct persuasion techniques in disinformation from multiple domains (COVID-19, climate change, anti-Islam, and the Russo-Ukrainian war). This paper aims to answer the following research questions:\nRQ1 Do disinformation narratives from different domains employ persuasion techniques differently?\nRQ2 Are persuasion techniques adapted linguistically, psychologically, and culturally to fit the context of domain-specific disinformation?\nBy comparing statistical and qualitative patterns in the use of persuasion techniques across different domains, our study provides a deeper understanding of the ways in which disinformation seeks to manipulate and offers actionable insights for countering its effects. Our code and supplementary material are made openly available to facilitate reproducibility\u00b9."}, {"title": "2 Methodology", "content": "2.1 Identifying Persuasion Techniques\nThe largest dataset annotated with persuasion techniques was introduced in SemEval-2023 [15]. It consists of news articles in 9 languages, collected from a variety of mainstream and alternative sources. It is annotated with 23 persuasion techniques at the sentence level, with the task framed as a multi-label classification problem, allowing multiple techniques to be identified simultaneously within each sentence. In this study, we leverage the state-of-the-art persuasion classifier by Razuvayevskaya et al. [17], which uses a"}, {"title": "2.2 Disinformation Domains", "content": "We study four disinformation datasets (see Table 1) from diverse domains: CIDII (Islamic issues) [9], COVID-19 [14], Climate Fever (climate change) [6], and EUvsDisinfo (Russo-Ukrainian war) [13]. All texts are in English, except for EUvsDisinfo, which spans 41 additional languages where we translated the non-English texts to English using GPT40. EUvsDisinfo also includes topics beyond the Russo-Ukrainian war, which we filtered out. Finally, only texts labelled as disinformation are analysed, with trustworthy articles excluded across all datasets. All texts are tokenised into sentences, and the persuasion classifier is used to identify persuasion techniques within each sentence."}, {"title": "3 Analysis", "content": "Figure 1 shows the proportion of persuasion techniques in each dataset, offering a visual comparison. To complement this and enable a more detailed quantitative analysis, we calculate the odds ratios (ORs) for each technique between datasets in Table 2. We calculate ORs by comparing the odds of a technique appearing in one domain to its average proportion in the other three domains. Throughout our analysis, we only discuss statistically significant ORs, based on Fisher's exact test with p<0.05.\nWe observe that Loaded Language and Doubt are used ubiquitously across all disinformation domains, comprising more than 20% of the techniques in each, except Loaded Language in climate change (11%). Specifically Doubt attempts to undermine trust in credible sources or established facts, creating confusion and making audiences more susceptible to accepting misleading or false claims [16]. Loaded Language aims to evoke strong emotional responses, such as fear or anger, which can override rational analysis and lead individuals to accept false information without critical scrutiny [8].\nNext, we discuss the persuasion techniques with ORs greater than 1, with statistical significance, indicating that their usage in one domain is more prevalent than in the others."}, {"title": "3.1 Domain-Specific Use of Persuasion Techniques (RQ1)", "content": "In disinformation on Islamic issues, Name Calling-Labeling, Causal Oversimplification, Loaded Language, False-Dilemma-No Choice, and Repetition are the most prevalent techniques, with ORs of 1.72,"}, {"title": "3.2 Contextual Domain Adaptation (RQ2)", "content": "To investigate the contextual adaptation of persuasion techniques to specific linguistic, cultural, and psychological patterns across disinformation domains, we compute the correlation between LIWC features [3] and persuasion techniques. Due to space constraints, we limit our analysis to a case study of the climate change domain, focusing on four persuasion techniques that occur disproportionately in this context: Appeal to Authority, Conversation Killer, Doubt, and Exaggeration-Minimisation. Figure 2 presents the ten highest correlations between these techniques and the LIWC features. We compare these correlations across the other three domains to highlight patterns unique to climate change disinformation, focusing on features highly correlated within climate change but not within other domains. We provide the results for the other domains in the supplementary material\u00b9.\nAppeal to Authority in climate change disinformation uses distinct linguistic and psychological features to emphasise credibility and logic. These texts have a higher word count and words per sentence, creating longer, more complex sentences that convey authority. A high Analytic score reflects formal, logical language, reinforcing a well-reasoned tone. Frequent use of prepositions and numbers adds detail to enhance the legitimacy of claims. Temporal markers like 'when' and 'now' situate arguments in time, adding urgency or inevitability. Psychologically, this technique appeals to curiosity and reward, engaging readers intellectually and offering positive outcomes. Terms like \u2018enough' and 'full' (i.e., Fulfillment) suggest solutions framed as complete and authoritative. Notably, these texts avoid causation language (e.g., 'because', 'why'), favouring definitive statements over explanations. These patterns align with the rhetorical context of climate change narratives, where the discussion of scientific topics requires a tone of credibility and rigour to persuade audiences.\nExaggeration-Minimisation employs specific linguistic and psychological features to amplify or downplay issues strategically. A high correlation with certitude words (e.g., 'really', 'of course') reinforces claims with a tone of absolute confidence, making arguments appear definitive and irrefutable. Terms related to moral behaviour (e.g., 'honour', 'deserve') inject ethical undertones, framing the issue as one of right versus wrong. Cultural references, particularly related to politics (e.g., 'govern', 'congress') and broader culture (e.g., 'american', 'chinese'), ground the discussion in societal and geopolitical contexts, often linking climate change to governance or national responsibility. Linguistically, the technique relies heavily on determiners (e.g., 'the', 'that') and function words (e.g., 'to', 'I'), creating a conversational and relatable tone. The frequent use of adverbs (e.g., 'so', 'just') adds nuance or emphasis to descriptions, subtly influencing how issues are perceived. Emotional cues, especially those tied to anxiety (e.g., 'worry', 'fear'), heighten the sense of urgency or concern, tapping into the audience's fears about climate change. Together, these features amplify certainty, invoke morality, embed discussions within cultural and political frameworks, and simplifies complex issues while evoking emotional responses.\nBoth Conversation Killer and Doubt exhibit a lesser degree of contextual adaptation, as most of the LIWC features that display high correlation in climate change are also highly correlated in other domains (e.g., Cognitive Processes, Negation). Nevertheless, some domain-specific features are present. Conversation Killer leverages spatial context (Space) (e.g., 'in', 'there') to ground arguments in specific locations, need-related states (e.g., 'need', 'have to') to emphasise urgency and necessity, and causation (e.g., 'because', 'why') provides justifications that reinforce the authority of dismissive rhetoric. Similarly, Doubt amplifies skepticism with the prominent use of long words to create an impression of sophistication and communication features (e.g., 'say', 'tell') that reference ambiguous sources, subtly eroding trust in credible information."}, {"title": "4 Discussion & Conclusion", "content": "In this study, we conducted a large-scale, cross-domain analysis of disinformation, examining the use and adaptation of sixteen persuasion techniques across four domains: COVID-19, climate change, Islamism, and the Russo-Ukrainian war. Our findings show that while some techniques-such as Doubt and Loaded Language-appear consistently across all domains, others are more context-dependent. For example, Repetition and False Dilemma-No Choice tend to dominate in Islamic issues, whereas Appeal to Hypocrisy and Guilt by Association frequently arise in the Russo-Ukrainian war domain. Beyond differences in frequency, we find that these techniques are also adapted in style. Our case study on climate change disinformation reveals that Appeal to Authority often features more analytic and formal language than in other domains, while Exaggeration-Minimisation frequently draws on moral and cultural references. Together, these observations demonstrate not only how disinformation messages are tailored to resonate with specific audiences, but also how their rhetorical and psychological characteristics shift according to thematic and cultural factors.\nThe analysis presented offers actionable insights for improving countermeasures against disinformation. Detection models can integrate domain and technique sensitive features, enhancing their ability to identify subtle, context-dependent cues. Media literacy programs can make individuals aware of the full range of persuasive strategies, including how they evolve to fit different content areas. Fact-checkers and journalists, with knowledge on how certain techniques manifest in particular domains, can develop targeted rebuttals that address both the presence of a technique and its adapted rhetorical form. By adopting these context-aware and targeted responses, efforts to counter disinformation can become more effective, ultimately helping to mitigate its spread and influence."}, {"title": "Ethical Use of Data", "content": "We adhere to ethical principles in data use by employing well-established and publicly available datasets that do not include personal or identifiable information. Due to the focus on disinformation topics, the data may inherently contain sensitive content."}]}