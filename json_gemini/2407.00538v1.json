{"title": "Privacy-Preserving and Trustworthy Deep Learning for Medical Imaging", "authors": ["Kiarash Sedghighadikolaei", "Attila A Yavuz"], "abstract": "The shift towards efficient and automated data analysis through Machine Learning (ML) has notably impacted healthcare systems, particularly Radiomics. Radiomics leverages ML to analyze medical images accurately and efficiently for precision medicine. Current methods rely on Deep Learning (DL) to improve performance and accuracy (Deep Radiomics). Given the sensitivity of medical images, ensuring privacy throughout the Deep Radiomics pipeline-from data generation and collection to model training and inference is essential, especially when outsourced. Thus, Privacy-Enhancing Technologies (PETs) are crucial tools for Deep Radiomics. Previous studies and sys-tematization efforts have either broadly overviewed PETs and their applications or mainly focused on subsets of PETs for ML algorithms. In Deep Radiomics, where efficiency, accuracy, and privacy are crucial, many PETs, while theoretically applicable, may not be practical without specialized optimizations or hybrid designs. Additionally, not all DL models are suitable for Radiomics. Consequently, there is a need for specialized studies that investigate and systematize the effective and practical integration of PETs into the Deep Radiomics pipeline. This work addresses this research gap by (1) classifying existing PETs, presenting practical hybrid PETS constructions, and a taxonomy illustrating their potential integration with the Deep Radiomics pipeline, with comparative analyses detailing assumptions, architectural suitability, and security, (2) Offering technical insights, describing potential challenges and means of combining PETs into the Deep Radiomics pipeline, including integration strategies, subtilities, and potential challenges, (3) Proposing potential research directions, identifying challenges, and suggesting solutions to enhance the PETs in Deep Radiomics.", "sections": [{"title": "I. INTRODUCTION", "content": "As traditional technologies are replaced by digital alternatives, the digital data generation has significantly increased [1]. This is particularly evident in the medical sector with the digitalization of clinical information into Electronic Health Records (EHRs) [2]. While there are various medicine study fields frequently generating extensive data like genomics [3] and proteomics [4], the National Institutes of Health (NIH) has identified Radiomics [5] as one of the promising technolo-gies for quantitatively analyzing high-dimensional medical imaging data, applicable to various modalities like Magnetic Resonance Imaging (MRI), Computed Tomography (CT), and nuclear medicine imaging, etc.\nThe increasing data volume and sophistication of image processing and querying for Radiomics pose storage and maintenance challenges. While cloud storage services offer cost-effective solutions, storing and managing sensitive EHR data on remote servers brings significant privacy and security concerns [6] such as cloud data breaches [7], regulations and law [8], and malware infections [9]-[11]. Encrypting data before outsourcing to the cloud storage ensures confidentiality, but conventional encryption methods (e.g., AES [12]) are insufficient for frequent search and update operations on medical records (e.g., a hospital accessing patients' records), requiring full dataset downloads for decryption and causing high communication overhead. Moreover, encryption does not provide authentication for the downloaded dataset. Hence, encrypted search mechanisms with integrity assurance are vital for Deep Radiomics to ensure data privacy while supporting efficient search and update operations.\nWhile the secure storage, access, and management of Radiomics data can be (in part) addressed with encrypted search mechanisms, traditional data processing methods, like hospitals examining CT images for statistical studies, are time-consuming, error-prone, and potentially inaccurate. Machine Learning (ML), particularly Deep Learning (DL), offers a promising solution for extracting structural knowledge from datasets and predicting outcomes accurately. DL has proven to be effective in Radiomics [13]-[15], which can benefit precision medicine [16] to identify patient subtypes to achieve optimal outcomes and accurately predict prognosis [17]. This is vital as, for instance, in tumor detection, patients with similar histopathological features in medical images may have varying survival probabilities [18]. Achieving satisfactory precision necessitates DL having access to substantial com-putational resources (e.g., hardware accelerators [19], [20]), often provided by cloud services like Amazon AWS [21] and Microsoft Azure [22]. While platforms like Microsoft Azure at UCLA Health for EHR data integration [23] and Google AI at Mayo Clinic for breast cancer risk scoring [24] are used in healthcare, outsourcing sensitive data for computation poses privacy risks, which even high security encrypted search mechanisms are insufficient due to their po-tential leakages. Additionally, achieving high accuracy through multi-institutional training, such as inter-hospital training [25], presents architectural challenges. Therefore, employing meth-ods that ensure privacy in various architectural settings while enabling DL integration with Radiomics in potentially un-trusted environments is crucial."}, {"title": "A. Research Gap", "content": "Several studies have explored PPML from different di-rections, including ML [45], [46], [49], [50], cryptographic techniques [43], and post-quantum secure cryptographic meth-ods [47], [48]. Regarding private search, recent studies have reviewed Searchable Encryption (SE) [51], assessing its per-formance and vulnerabilities [34], [52], Private Information Retrieval (PIR) [53] and its diverse adaptations and extensions [36], and Oblivious Random Access Machine (ORAM) [37]. For computations under encryption, Multi-Party Computation (MPC) [54] was investigated by [35], [55], [56] in analytics and government collaboration. Moreover, Zhou et al. [57] showed how MPC integrates with other PETs and works [44], [58] explored MPC methodologies tailored for DL and the effectiveness of MPC-based protocols for private inference and training was investigated by [59]. Furthermore, the role of Homomorphic Encryption (HE) [60] in cloud computing, aggregation, private database queries, and bioinformatics was explored by [39], [61], [62]. Acar et al. [63] showed theoretical and hardware implementations of HE, while works in [44], [64], [65] investigated HE applications in PPDL. Works in [66], [67] investigated various Functional Encryption (FE) [68] schemes, outlining their features, constraints, and security architectures. Panzade et al. [69] extensively analyzed diverse strategies for FE-based PPML, highlighting their strengths and weaknesses. Hybrid constructions of these PETs were inves-tigated by [42], where integrating with Differential Privacy (DP) [70] was studied by [71], and with Trusted Execution Environments (TEEs) [72] by [73]. These integrations were further thoroughly reviewed and categorized by [74], [75].\nThe works in [40], [76] delved into verifiable execution techniques like Zero-Knowledge Proofs (ZKPs) [77], high-lighting their relevance in Blockchain and Cryptocurrency transactions. Furthermore, Sathe et al. [78] analyzed ZKP for inference in PPML and compared the efficiency of the prior schemes, whereas [79] provided a comprehensive classification"}, {"title": "B. Our Contribution", "content": "We aim to fill the gap in the literature with the following contributions:\n\u2022 Detailed Taxonomy and Classification of Prominent PETS for Deep Radiomics with Hybrid Compositions in Mind: We categorized various PETs applicable to Deep Radiomics into four groups based on their fundamental principles. While each PET holds theoretical applicability, practical implementation often requires integrating them with other PETs to create hybrid designs. Hence, we also present practical hybrid designs suitable for real-world deployment. For this matter, Fig. 1 illus-trates our primary PETs classification for the Deep Radiomics pipeline, detailing their respective advantages, disadvantages, and prominent hybrid configurations. Additionally, TABLE I lists these PETs and their significant hybridizations, offering detailed insights into their performance, security, architectural suitability, underlying assumptions, etc.\n\u2022 Comprehensive yet Broadly Accessible Technical Insights on Deep Radiomics's Pipeline with PETs: Given the necessity of considering the full pipeline of Deep Radiomics, our examination spans the stages of data storage/retrieval phases, model training, and model release and inference. Having such detailed classification and scrutinizing the essential prerequi-sites of each stage, we present a thorough yet broad technical analysis of incorporating each PET into each stage (Fig. 2). This analysis presents the performance challenges and possible mitigations against privacy attacks in Deep Radiomics.\n\u2022 Presenting a Roadmap Towards Privacy-preserving Deep Radiomics with Challenges and Future Research Directions: Our study offers a potential roadmap for integrating PETS throughout the entire Deep Radiomics pipeline, focusing on"}, {"title": "II. PRIVATE SEARCH, ACCESS, AND RETRIEVAL FOR MEDICAL IMAGES", "content": "In this section, we present secure access, private search, and information retrieval mechanisms that can potentially be integrated into the initial stages of the Deep Radiomics pipeline, namely data storage and retrieval (See Fig. 1).\nA. Searchable Encryption to Enable Private DR Services\nSE [51] enables storing data in encrypted form on the remote storage server for various purposes like data backup or data sharing and later performing keyword(s)-based search over them. An SE scheme typically involves a data owner, authorized data user(s), and an untrusted remote server. The data owner encrypts the data before uploading it to the server. An authorized data user sends a keyword search query and a search token to the server, performing the encrypted search and returning the encrypted results. For example, a hospital can store patient data on untrusted servers in encrypted form and use SE to retrieve specific records (e.g., recent X-ray images) for Deep Radiomics analysis (Fig. 2-A). Additional applications of SE in healthcare include IoT healthcare [101], content-based image retrieval using feature vectors [102], and large-scale encrypted medical images using CNNs [103].\nWhile SE schemes can be classified based on factors such as search structure (index-based, sequential scan), search functionality (keywords, fuzzy keywords, phrases), etc, SE techniques can be broadly divided into two main categories: Symmetric SE (SSE) and Asymmetric SE (ASE). SSE allows only the entity with the symmetric key to generate searchable ciphertexts and search tokens, while ASE enables anyone with access to the decryptor's public key to encrypt data, allow-ing subsequent searches to be conducted by the private key owner(s) [104]. In addition, Dynamic Symmetric Searchable Encryption (DSSE) [105], [106] extends SE to allow searching and updating over the encrypted data via an encrypted index, offering high efficiency and security for Deep Radiomics. DSSE has been used in Deep Radiomics for content-based image retrieval from Cloud image repositories [107]\u2013[109].\nDSSE integration to Deep Radiomics encounters several challenges. The fuzzy nature of medical data, with mi-nor spelling and typographical errors, complicates keyword"}, {"title": "B. Mitigating Leakages of Encrypted Search Services", "content": "In addition to requiring forward and backward privacy, higher security measures are needed to eliminate harmful information leakage and mitigate attacks [119]. DSSEs should also be equipped to achieve shareability [120] and post-compromise security [121]. While such security properties ensure the user's data remains private, there are instances where the remotely stored data is public (e.g., on a public file server). In such cases, only the user must know anything about the retrieved data and the query when issuing a query to this storage. The primitives designed for this purpose fall into the group of oblivious retrieval and access primitives. PIR [53] involves an interaction between two entities: a user and a database. The goal is for the user to retrieve a specific record from the database without revealing any information (such as the item's index) to the untrusted database owner (Fig. 2-A). The integration of PIR in Deep Radiomics has been explored by [122], who developed a proficient PIR solution for retrieving large X-ray and MRI files within a widely adopted cloud computing paradigm (MapReduce).\nPIR approaches can be categorized into Information-theoretic PIR (IT-PIR) and Computational PIR (CPIR) so-lutions. IT-PIR ensures the server remains oblivious to the user's request by requiring the download of the entire database, thereby guaranteeing privacy. The first IT-PIR [53] was intro-duced in a multiple-server setting where each server holds a copy of the same database and cannot communicate with the others. Later, Kushilevitz et al. [123] introduced PIR in a single-server setting. Two efficient multi-server PIR protocols include XoR-based [124] and Secret Sharing-based [125] methods. However, these approaches are impractical for Deep Radiomics due to substantial communication overhead. In contrast, CPIR relies on cryptographic constructions (e.g., using Fully Homomorphic Encryption), which introduce more computational overhead than communication. While PIR can prevent leakage, it lacks support for information updates (write operations) in the database, necessitating the use of ORAM [91] used in schemes like Oblivious Data Structure Encryption (ODSE) [100], [126].\nORAM is a probabilistic RAM machine initially designed to execute programs and handle data without revealing in-formation through physical memory accesses. It effectively"}, {"title": "III. EXECUTING DEEP RADIOMICS UNDER ENCRYPTION", "content": "In this section, we explore computation under encryption mechanisms that are integrateable into the third and fourth stages of the Deep Radiomics pipeline, which are Deep Radiomics training and inference, respectively (See Fig 1).\n1) Secure Multi-party Computation (MPC) for Distributed Medical Image Classification (and Decision Making): MPC [54] enables mutually untrusted parties to jointly compute a function on their private inputs, ensuring that no party gains additional information beyond what can be inferred from their input and the function's output. MPC has been utilized for secure distributed medical image analysis and classification [134]\u2013[136]. The first two-party MPC protocol [54] represents the target function as a circuit of logical gates (e.g., AND, OR, and XOR), with one party garbling the circuit and sending it to another party for evaluation (Garbled Circuit (GC)). The circuit evaluation is further completed using Oblivious Transfer (OT) [137], ensuring that the holder remains unaware of the requester's selections and the requester acquires no knowledge of the unchosen garbled circuit inputs. Additionally, Secret Sharing (SS) [97] can distribute a secret among multiple parties, allowing them to reconstruct it collab-oratively. Further, using the shared circuit evaluation approach, parties can evaluate the circuit on the shares of their inputs and obtain shares of the function's output, which can then be reconstructed by a sufficient number of parties [138].\nWhile constant communication rounds characterize GC, the performance may degrade with more AND gates in the circuit representation. Strategies like replacing non-XOR (NXOR) gates with XOR gates [139] can enhance circuit efficiency. However, applying GC to Deep Radiomics may lead to significant computation and communication costs despite theoretically supporting linear and non-linear computations. For example, CNNs with numerous inputs per layer require dedicated comparison circuits for simple activation functions like ReLU [140]. Although the boolean nature of GC is suitable for specific NNs like Binary Neural Networks (BNN) and Ternary Neural Networks (TNN), where model parameters values belong to the set {-1,0,1}, this simplification intro-duces overhead in CNNs with floating-point parameters. Thus, arithmetic circuits are preferred for prevalent CNN operations like addition and multiplication.\nIn contrast to GC, OT protocols impose significant com-munication overhead, which scales with the input bit length due to public-key cryptography. To optimize OT for linear computations like matrix multiplication, correlated OT can be employed for the dot product. In this method, the dot product results from aggregating multiple elementwise multiplications, and the shares of the dot product are derived by combining the corresponding shares of elementwise multiplications at two parties. While BNNs exhibit efficient OT protocols as their bi-nary model parameters need an input bit length of one, CNNS pose challenges as parameters are multi-bit length floating-points, resulting in significant communication overhead and potentially compromising model accuracy. Although optimiza-tions allow for over ten million OT executions per second, performance considerations remain essential, like offloading input-independent computations to the offline phase.\nSS enables CNN linear computation through a two-phase process, encompassing input-independent offline and input-dependent online computations (Fig. 2-E). In the offline phase, a multiplication triplet is established using OT between a data owner and a cloud server, with each party holding distinct shares of these three values. Subsequently, the dot product is efficiently computed using the precomputed shares in the online phase. While SS proves effective in low-delay settings, it may be less favored in delay-sensitive scenarios due to the computational load in the offline phase.\nFor non-linear functions such as the ReLU activation function and max-pool function (common in pooling layers) [140], the efficient computation can be achieved through GC. These implementations avoid approximation and achieve performance comparable to the original Deep Radiomics mod-els. However, activation functions like Sigmoid [140] can be approximated using ReLU variants, introducing an accuracy-efficiency tradeoff for CNNs. While overhead may be reduced through pipelining techniques based on parallel computation, such approximations may still incur computational costs. Moreover, as number comparison involves comparing with zero and evaluating the most significant bit (MSB), SS can be utilized for efficient MSB evaluation, enabling approximation-free computation for functions like ReLU and max-pooling. Although splitting the input of non-linear functions to derive partial non-linear results and combining them to get the output"}, {"title": "2) Homomorphic Encryption (HE) for Encrypted Radiomics (in Single-server setting):", "content": "HE enables the encryption of plaintext into ciphertext, allowing certain operations to be performed on the ciphertexts while producing the same results as if applied to the plaintexts (homomorphism) without the need for decryption beforehand. HE supports primary opera-tions like addition and multiplication and is categorized based on the operations it supports: Partially HE [149] supports only addition, Somewhat HE (SHE) [150] allows for an unbounded number of additions and a single multiplication, Leveled HE (LHE) [151] permits a predetermined number of additions and multiplications, and Fully HE (FHE) [60] supports an unbounded number of operations.\nHE's integration with Deep Radiomics involves encrypting data before transmission to the server for model training or inference, ensuring computation privacy. After performing the desired computation on the encrypted data, the result is communicated in encrypted form, ensuring comprehensive output privacy. Works [152], [153] demonstrated the use of HE in FL for balancing costs and privacy in medical imaging and IoT healthcare. For HE-based inference, BNormCrypt [154] and CryptoDL [155] rely solely on LHE, while others such as GAZELLE [156] use GC in addition for more robust privacy. Most operations in Deep Radiomics, such as weighted sums, matrix multiplication, and dot products, are linear and com-patible with HE. However, computing non-linear operations like activation functions (e.g., ReLU, Tanh [140], and Sig-moid) with HE presents challenges due to its limited addition and multiplication operations, resulting in high computation complexity. Additionally, using HE with CNNs can impose multiplicative depth limitation, which restricts the number of consecutive multiplications before the ciphertext can no longer be decrypted correctly. Furthermore, training CNNs with HE involves forward and backward passes, leading to significant noise accumulation and exacerbating the impact of multiplicative depth, particularly during training. These challenges primarily restrict HE usage to inference rather than training in Deep Radiomics applications (Fig. 2-F).\nIn CNNs, convolution layers involve matrix multiplications and dot products, with each matrix element corresponding to a HE-compatible ciphertext. However, the standard im-plementation of d-dimensional matrix multiplication requires $d^3$ multiplications, and the dot product of two d-dimensional vectors necessitates d multiplications. To enhance multipli-cation efficiency, strategies like shift operations can be ap-plied, exploiting the property of binary format where mul-tiplying by a power of two is akin to shifting the decimal point. Nonetheless, shift operations mandate quantizing CNN weights to powers of two and representing CNN inputs as fixed-point binary numbers, as demonstrated in CryptoNets [157]. Alternatively, Single Instruction Multiple Data (SIMD) operations, also known as ciphertext packing, can be utilized to reduce ciphertext count, decrease latency, and optimize data organization. While most HE schemes support SIMD operations, TFHE is an exception and cannot be employed in these packing schemes. Moreover, the absence of universal packing schemes has rendered efficiently handling data for operations like convolutions challenging.\nPooling layers, like convolution layers, employ pooling functions across their windows. However, max-pooling, the prevalent choice, proves inefficient with most HE schemes, except for Scale-Invariant HE [158]. Consequently, many propose to replace max-pooling with (scaled) average-pooling. A prevalent scaling factor is the number of input elements, which converts average pooling into input summations without multiplication, offering tighter control over values' magnitude. While average pooling preserves output within input range values, scaled average pooling may yield larger outputs, ne-cessitating careful HE parameter selection to ensure all values fit into the input space.\nComputing non-linear functions like activation functions varies depending on the specific application. For instance, in Scale-Invariant HE, the TFHE library [159] is employed to implement ReLU, while a step function is implemented using customized bootstrapping operations within TFHE as demonstrated by [160]. However, in FHE, operations on en-crypted data typically increase the noise level in the ciphertext, potentially posing a security threat if the noise becomes excessive. To address this, bootstrapping is used to refresh the ciphertext, reduce noise, and restore security. Each activation function evaluation is essentially a bootstrapping operation, facilitating the construction of deep networks with unlimited depth. Nonetheless, training a network with non-standard acti-vation functions like a step function can be challenging due to their lack of gradient information. Consequently, schemes like CryptoRNN [161] delegate activation function computation to the client, allowing flexibility in choosing any desired function. Moreover, in hybrid designs [156], [162], HE can be used for"}, {"title": "3) Functional Encryption (FE) for Selective Medical Image Diagnosing:", "content": "In a conventional public-key encryption scheme, the recipient decrypts data fully using a private key. However, controlled or restricted access to plaintext is sometimes necessary, allowing only specific individuals to decrypt the ciphertext. For instance, a hospital might encrypt patient data and send it to a third party for heart disease trend analysis. To protect patient privacy, a mechanism is needed that allows the third party to selectively access only certain parts of the encrypted data, such as recent prescriptions.\nFE [68] uses specialized secret keys to decrypt the output of specific functions applied to encrypted data without revealing the actual inputs. The application of FE in Deep Radiomics for medical primary diagnosis has been explored by [168], [169]. FE-based Deep Radiomics employs two main approaches: Inner-product FE (IPFE) and Quadratic FE (QFE). IPFE supports both training (including forward and backward prop-agation) and inference by calculating the inner product of an encrypted vector x and a plaintext vector y without decrypting x. For activation functions, it computes the inner products of encrypted inputs and weight matrices. QFE, specialized for faster inference, uses polynomial approximation on encrypted data within polynomial neural networks, suitable for linear components like fully connected layers, convolutions, average pooling, and polynomially approximated activation functions. Despite its use in PPDR (Fig. 2-F), FE faces significant limitations and challenges. Current FE approaches, including linear IPFE and quadratic QFE, are constrained in their capa-bilities. For example, IPFE-based CryptoNN supports training and inference for a five-layer neural network, while QFE-based protocols enable inferences for a two-layer network. IPFE methods, suited for simple computations like inner products, struggle with the complex requirements of CNNs in medical imaging and require numerous ciphertexts for convolutions. QFE approaches are restricted to polynomial NNs of up to five degrees, which is insufficient for complex CNN architectures like VGGNet and GoogleNet. FE constructions also depend on computationally costly cryptography, leading to performance overheads that, while reasonable for partially encrypted tasks, are inadequate for complex learning tasks over large datasets. The limited functionalities of current FE schemes and the computational and memory costs of ciphertexts and keys make implementing complex CNNs for Deep Radiomics challenging, especially for large datasets like ImageNet. Additionally, no FE scheme leverages hardware accelerators (e.g., GPUs), vital for CNNs. These shortcomings highlight the motivation for ef-ficient FE schemes supporting GPU acceleration, particularly for the training phase in Deep Radiomics."}, {"title": "IV. VERIFIABLE EXECUTION OF DEEP RADIOMICS", "content": "ZKP [77] is an interactive system where a computation-ally unbounded prover attempts to convince a probabilistic polynomial-time verifier of a statement's truthfulness. ZKP systems must satisfy three critical properties: (1) Complete-ness, ensuring the verifier always accepts the proofs of honest provers for true claims; (2) Soundness, ensuring rejection if a malicious prover presents proof for false claims; and (3) Zero-Knowledge, guaranteeing confidentiality during the protocol.\nThe challenges posed by interactive protocols, especially when the verifier is not consistently online or when com-munication bandwidth is limited, highlight the need for non-interactive ZKPs (NIZKPs) [170]. In NIZKPs, the prover generates the proof once and sends it to the verifier in a single round, overcoming these limitations. Additionally, the desire for concise proofs further drives the adoption of Succinct Non-Interactive Arguments of Knowledge (zkSNARKs) [171], which are highly preferred over traditional ZKPs for Deep Radiomics due to their efficiency and effectiveness.\nZKPs play a vital role in PPDR by verifying model owner-ship and inference. For instance, in [172], ZKPs were used to verify ownership of a Deep Radiomics model designed for removing bones from chest X-rays. Integrating ZKPs such as zkSNARKs into Deep Radiomics involves a verifier with limited computational capabilities delegating training or inference responsibilities to a more capable entity with mutual agreement on tasks, datasets, and models. Combining ZKPs with commitment schemes [173] enhances model security and establishes non-repudiation by safeguarding the confidentiality of Deep Radiomics computations. The server (prover) commits to learning elements, executes the task, and produces a proof. After completion, the prover transmits the result, commitment, and proof to the verifier for validation check (Fig. 2-H).\nZKPs defend against attacks like data poisoning [174], where attackers manipulate training data (e.g., poisoning fea-tures, changing model weights, etc.) to influence learning mod-els. While prior research focused on preventing such attacks"}, {"title": "V. COLLABORATIVE LEARNING PARADIGM FOR DEEP RADIOMICS AND HYBRID DESIGNS", "content": "Traditional learning methods often involve transferring data and models to third parties when computational resources are inadequate. Moreover, data providers (e.g., hospitals) may lack sufficient training data, resulting in models with limited accuracy. To overcome this, utilizing Generative Adversarial Networks (GANs) [178] for data augmentation is suggested. Yet, GANs may not consistently provide the diversity needed for healthcare systems. Another approach is exchanging data between providers for training, but the large size of Deep Radiomics images can lead to communication overhead and scalability issues. Additionally, diverse privacy policies among providers make this approach impractical.\nFL [84] is a paradigm for collaboratively training a global model across multiple datasets distributed over separate nodes without explicit data sample exchange. In FL, each node sends its locally trained model parameters to a central node for aggregation into the target model. The globally aggregated parameters are then redistributed to the nodes, and this itera-tive process continues over multiple rounds until the desired accuracy level is reached (Fig. 2-D). While FL offers benefits like generalizability and scalability, it often involves a trade-off, resulting in a loss of model accuracy.\nFL is widely applied in medical imaging, with collaborative endeavors expanding [179]. For instance, in federated brain imaging for tumor segmentation based on functional MRI (fMRI) [92], deep NNs (DNNs) are locally trained on datasets integrated with Differential Privacy (DP) [180], [181] to mit-igate reconstruction attacks through artificial noise addition and further aggregated. Notably, examples of such integration include [84] for histopathology image analysis (e.g., lung cancer) and [181] for brain tumor segmentation. Moreover, FL assists in pathology images [182], automating tissue region segmentation and embedding into low-dimensional features using CNNs [183].\nDespite being capable of PPDR, FL faces numerous chal-lenges. Transmitting locally trained parameters to a central node poses privacy risks, as updates may contain sensitive information susceptible to reconstruction attacks. One solution involves integrating DP into FL by adding noise to the local dataset [180]. FL is also vulnerable to MIAs and poisoning attacks, where malicious or low-quality data can degrade accuracy or create trojan-enabled models. Additionally, if datasets are of low quality or contain various types of medical data, like images, audio, and text, the accuracy of the final model may suffer. These challenges can be addressed through heterogeneous FL approaches, private ensemble learning meth-ods capable of handling diverse data types, and reputation-based mechanisms ensuring nodes contribute high-quality, trustworthy data and updates to the training process.\nWhile capable of standalone operation, FL can benefit from hybrid designs to effectively address challenges as well. Integration of HE into FL for various medical imaging tasks has been explored, including lesion classification [152], cancer image analysis [184], and U-shaped medical image networks [152]. Furthermore, FL and MPC have been applied in health-care for tasks like diagnosing pneumonia [185], analyzing histopathology images [186], multi-institutional medical imag-ing [94], and multi-party FL inference systems for Diabetes Mellitus risk prediction [187]. Moreover, using secure voting via MPC, nodes can perform secure voting by adding DP noise to their local inferences and collectively decide on the final inference label [188] or aggregated model parameters.\nFL's privacy challenges, such as MIAs, unintentional in-formation leakage, and generative adversarial networks due to the high sensitivity of health-related data, are undeniable. Practical solutions involve hybrid and scalable FL designs with other PETs like DP. Advanced cryptographic methods such as MPC and incentive mechanisms based on Game theory [189], [190] and Blockchain [191], [192] offer promising directions for protection."}, {"title": "VI. TRUSTED HARDWARE FOR EFFICIENT DEEP RADIOMICS AND HYBRID CONSTRUCTIONS", "content": "Using cryptographic primitives for confidential computing introduces computational and communication overheads. A more efficient approach involves leveraging hardware-based TEEs, which operate independently of the operating system or hypervisor. TEEs facilitate isolated and verifiable code execution within secure enclaves (protected memory regions) and differ from Trusted Platform Module (TPM), where secure hardware is physically isolated from other modules. The benefits of allowing smooth transitions between normal and trusted modes of operation have led commercial processor companies to integrate TEEs into their latest processor designs. Notable TEEs include Intel Software Guard eXtensions (SGX) [72] for processor-based TEEs, virtual-machine (VM)-based TEEs such as AMD Secure Encrypted Virtualization (SEV) [193], ARM TrustZone [194], and RISCV Keystone [195]. Moreover, efforts are underway to integrate TEEs with ML hardware accelerators (e.g., GPUs, TPUs [20], and NPUS [196]), which is critical, especially for Deep Radiomics due to the increasing complexity of NN training and the expansion of datasets. Notable integrations of TEEs and accelerators include Graviton [197] (with GPU), Vaswani et al. [198] (with Graphcore), and the NVIDIA H100 Tensor Core GPU [199].\nEstablishing trust between TEEs and external computing nodes is vital for ensuring privacy. Root of Trust (RoT) measurement verifies a TEE's integrity by examining critical system components before executing stored code. Remote At-testation (RA) validates the TEE's integrity when a computing node transmits code. Through attestation, the node confirms the remote TEE's trusted state and secure execution of the intended code. This process includes signing a RoT mea-surement report, verifying the signature, comparing it against a trusted reference, and generating an attestation certificate, which is then transmitted to the attester.\nTo utilize TEES for PPDR, data and model owners must transmit their assets to a remote TEE situated on an untrusted computing node (Fig. 2-B). When a node serves as a server providing training or inference services, the data sent to this node must be stored within the TEE to ensure privacy. Similarly, if another entity owns the Deep Radiomics model, it should also be provisioned to the TEE. However, for inference purposes, it is acceptable for the model not to reside in the enclave if the server is untrusted or not the model owner, as inference does not impact the model parameters. Conversely, when the computing node is a client with private data stored locally, another entity may own the model as intellectual property. Examples of such inference scenarios include on-device inference, on-device personalization, and FL, where the model is trained locally and aggregated with other locally trained models [200], [201].\nDespite TEEs offering superior performance over cryptography-based solutions for PPDR, several challenges persist. Resource constraints hinder deploying the entire learning pipeline, covering data preparation and storage, training, and inference within TEEs. For instance, adversarial attacks, such as adding noises to the inputs and their labels either by physical surroundings or by attackers (side-channel attacks), pose challenges for TEEs to control the first step of the Deep Radiomics pipeline, which is data generation and preparation. Moreover, assigning training and inference tasks to TEEs on an untrusted host does not address privacy breaches, as transmitting final results requires potentially secure channels. While safeguarding model parameters in TEEs can counter reconstruction attacks, it may be ineffective against attacks like MIAs, where information leakage occurs from the model's output.\nConsidering TEEs' benefits and challenges, a common hybrid strategy integrates TEEs with other solutions for ease of deployment and performance advantages. For instance, Intel SGX can offer secure encrypted searches while pro-tecting against side-channel attacks and access pattern leak-ages. Hardware-assisted ORAM, utilizing SGX, can reduce bandwidth overhead and allow outsourcing of large databases [96], [202]. Integrating TEEs with SSE (e.g., for image-based apps) can eliminate the need for complete obliviousness and ensure queries don't reveal document connections or expose data updates [203], [204]. Additionally, Intel SGX can be combined with HE in medical image segmentation for brain and heart disease analysis [95], and with MPC to allow for secure parallel key exchanges [93], [205], [206].\nA promising research direction is in-memory computing"}, {"title": "VII. STATISTICAL PERTURBATION FOR ADAPTABLE TUNING OF PRIVACY", "content": "DP [70", "207": ".", "ways": "Central DP (CDP) and Local DP (LDP). In CDP", "183": "for gigapixel whole slide images in pathology", "92": "for multi-site fMRI analysis", "208": "for brain tumor segmentation.\nIn centralized learning models", "levels": "gradient (protecting successive model up-dates), input (training dataset or target function), or label (protecting the learned model). The choice depends on the op-timization of the target function. For convex target functions, the noise magnitude of DP is determined by the sensitivity of the learning algorithm. However, due to multiple local minima, sensitivity analysis is impractical for non-convex objective functions, typical in Deep Radiomics."}]}