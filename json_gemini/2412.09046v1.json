{"title": "Multi-Task Learning with LLMs for Implicit\nSentiment Analysis: Data-level and Task-level\nAutomatic Weight Learning", "authors": ["Wenna Lai", "Haoran Xie", "Guandong Xu", "Qing Li"], "abstract": "Implicit sentiment analysis (ISA) presents significant\nchallenges due to the absence of salient cue words. Previous meth-\nods have struggled with insufficient data and limited reasoning\ncapabilities to infer underlying opinions. Integrating multi-task\nlearning (MTL) with large language models (LLMs) offers the\npotential to enable models of varying sizes to reliably perceive\nand recognize genuine opinions in ISA. However, existing MTL\napproaches are constrained by two sources of uncertainty: data-\nlevel uncertainty, arising from hallucination problems in LLM-\ngenerated contextual information, and task-level uncertainty,\nstemming from the varying capacities of models to process con-\ntextual information. To handle these uncertainties, we introduce\nMT-ISA, a novel MTL framework that enhances ISA by leverag-\ning the generation and reasoning capabilities of LLMs through\nautomatic MTL. Specifically, MT-ISA constructs auxiliary tasks\nusing generative LLMs to supplement sentiment elements and\nincorporates automatic MTL to fully exploit auxiliary data. We\nintroduce data-level and task-level automatic weight learning\n(AWL), which dynamically identifies relationships and prioritizes\nmore reliable data and critical tasks, enabling models of varying\nsizes to adaptively learn fine-grained weights based on their\nreasoning capabilities. We investigate three strategies for data-\nlevel AWL, while also introducing homoscedastic uncertainty\nfor task-level AWL. Extensive experiments reveal that models\nof varying sizes achieve an optimal balance between primary\nprediction and auxiliary tasks in MT-ISA. This underscores the\neffectiveness and adaptability of our approach.", "sections": [{"title": "I. INTRODUCTION", "content": "Aspect-based sentiment analysis (ABSA) aims to identify\nvarious sentiment elements, including target terms, aspect\ncategories, opinion terms, and sentiment polarities [1]. As\nillustrated in Figure 1, these sentiment elements are evident\nin the explicit case to form a complete sentiment picture. Pre-\nvious dominant research focused on detecting these elements\nindependently. However, identifying a single sentiment ele-\nment remains insufficient for a comprehensive understanding\nof aspect-level opinions [2]. To delve into more complex real-\nworld scenarios, Li et al. [3] shed light on implicit sentiment\nanalysis (ISA) and pointed out that previous studies have\npaid less attention to ISA, which presents greater challenges\ndue to the absence of salient cue words in expressions.\nUnlike traditional ABSA tasks, ISA necessitates not only the\nextraction of dependencies between sentiment elements but\nalso the capture of nuanced sentiment cues conveyed within\ntexts [4].\nThe key challenges present in ISA are insufficient data to\nsupport pattern learning for implicit sentiments and limited\nreasoning capabilities of traditional models to incorporate\ncommon sense knowledge. In the evolving landscape of SA,\nresearchers have increasingly focused on enhancing techniques\nfor ISA. Li et al. [3] pre-trained on a large-scale sentiment-\nannotated corpus, aiming to align implicit representations with\nexplicit ones. However, their approach demands significant\neffort in constructing data sources and lacks generalization and\ninterpretability in reasoning deep-level sentiments. Recent ad-\nvancements in large language models (LLMs) have exhibited\ntheir potential in addressing the challenges of ISA, particularly\ndue to their remarkable performance in natural language\ngeneration and understanding [4], [5]. Figure 1 presents an\nexample where LLMs supplement sentiment elements in the\nimplicit case, demonstrating their capabilities for reasoning\nabout sentiments. Fei et al. [6] directly conducted Chain-\nof-Thought (CoT) fine-tuning to extract relevant sentiment\nelements for discerning implicit orientations in expressions.\nAlthough this approach achieved some performance improve-\nments, it necessitates LLMs of a certain scale to exhibit\nemergent abilities [7] for step-by-step inference, limiting its\nbroader application. Furthermore, LLMs are prone to halluci-\nnation problems, which can result in unfaithful reasoning and\nsubsequently impair learning performance [8], [9].\nApart from CoT fine-tuning, another prominent technique\nfor integrating LLMs in reasoning is Multi-task learning\n(MTL), which has shown promise in various NLP tasks\nby leveraging shared representations across related reasoning\ntasks to improve overall performance [10], [11]. Notably, MTL\nwith LLMs has demonstrated effectiveness even with smaller\nmodels [12], [13]. They typically use LLMs for auxiliary\ndata generation and joint learning through MTL. However,\ntraditional MTL approaches often require manual tuning of\ntask weights [12], [13], which can be time-consuming and\nsuboptimal due to two primary sources of uncertainty when\napplied with LLMs: data-level uncertainty, arising from the\nhallucination problems inherent in LLM-generated contextual\ninformation, and task-level uncertainty, stemming from the\nvarying capacities of models to digest contextual information.\nIt is critical to enhance the self-knowledge of LLMs [9]\nand handle these potential uncertainties, enabling models of\ndifferent sizes to reliably perceive and recognize genuine\nopinions in ISA.\nTo tackle the above challenges and effectively harness the\npotential of LLMs for reliable reasoning, we introduce a\nnovelMTL framework, MT-ISA, which leverages the gener-\nation and reasoning capabilities of LLMs, while also man-\naging inherent uncertainties at both the data and task levels\nthrough automatic MTL. In MT-ISA, we construct auxiliary\ntasks by utilizing generative LLMs to supplement additional\nsentiment elements. By integrating MTL with LLMs, MT-ISA\ncan fully exploit auxiliary data generated by LLMs, enabling\nbackbone models to capture relationships between sentiment\nelements and effectively reason about implicit sentiments.\nTo further enhance reasoning learning by managing inherent\nuncertainties, we employ data-level and task-level automatic\nweight learning (AWL) to dynamically adjust the focus on\nmore reliable data and critical tasks, eliminating the need for\nextensive manual intervention. This allows models of varying\nsizes to adaptively learn fine-grained weights based on their\nreasoning capabilities. We explore three strategies for data-\nlevel AWL and incorporate homoscedastic uncertainty for\ntask-level AWL, contributing to optimal reasoning learning\nperformance in ISA.\nIn general, the key contributions of this work are as follows:\n\u2022 We propose MT-ISA, a novel MTL framework for ISA\nthat leverages the generation and reasoning capabilities\nof LLMs, while effectively handling inherent data-level\nand task-level uncertainties through automatic MTL.\n\u2022 MT-ISA incorporates data-level and task-level AWL to\ndynamically prioritize reliable data and critical tasks,\nenabling models of varying sizes to adaptively learn\nfine-grained weights based on their reasoning capabilities\nwithout manual intervention.\n\u2022 We investigate three strategies for data-level AWL, in-\ncluding Input (I), Output (O), and Input-Output (I-O)\nstrategies. Extensive experiments demonstrate the efficacy\nof these strategies in enhancing automatic MTL perfor-\nmance, achieving state-of-the-art results in ISA."}, {"title": "II. RELATED WORKS", "content": "Implicit sentiment analysis (ISA) presents greater chal-\nlenges compared to sentiment classification tasks due to the\nabsence of salient cue words in expressions [3], [14]\u2013[16].\nSome prior studies addressed ISA by enhancing feature repre-\nsentation at the sentence level [17], [18]. In 2021, the research\nteam [3] divided the SemEval-2014 Restaurant and Laptop\nbenchmarks into Explicit Sentiment Expression (ESE) slice\nand Implicit Sentiment Expression (ISE) slice based on the\npresence of opinion words, to facilitate a more fine-grained\naspect-level analysis. Given that Pre-trained Language Models\n(PLMs) such as BERT [19] demonstrate exceptional perfor-\nmance in learning representations for classification tasks, many\nresearchers have utilized PLMs for downstream tasks. They\nenhanced ISA through data augmentation [20] or advanced\ndeep learning techniques like contrastive learning [3], graph\nlearning [21]. In addition, casual intervention has proven to\nbe an effective method for exploring implicit relationships\n[22]. With the triumph of LLMs in the NLP domain, the\nresearch community has experienced a paradigm shift towards\nthe utilization of LLMs [4], [5]. Ouyang et al. [23] employed\nencoder-decoder style LLMs, with the encoder trained for data\naugmentation and the decoder for prediction purposes. Fei et\nal. [6] introduced THOR and applied Chain-of-Thought (CoT)\nfine-tuning in ISA by exploiting the emergent abilities in\nLLMs. However, THOR requires larger models to fully exhibit\nin-context learning and reasoning capacities, while smaller\nmodels achieve limited performance with CoT reasoning. In\ncomparison, our approach enhances reasoning context using\ngenerative LLMs to self-refine [24] with label intervention for\nreliability control. Additionally, We capitalize on the strengths\nof LLMs via MTL employing data-level and task-level AWL to\nhandle inherent uncertainties, which enables backbone models\nto deliver optimal results regardless of model size."}, {"title": "B. Multi-task Learning", "content": "Multi-task learning (MTL) aims to enhance generalization\nperformance by leveraging shared information across multiple\nrelated tasks [25]. It is a promising direction in NLP with\nvarious applications including information extraction, natural\nlanguage understanding, and generation [11]. In ABSA, prior\nstudies have explored joint learning of subtasks to improve\nthe performance of sentiment polarity classification [26],\n[27]. Yang et al. [28] developed an MTL model to jointly\nextract aspects and predict their corresponding sentiments,\nachieving enhanced performance on both Chinese and English\nreview datasets. Similarly, Yu et al. [29] proposed a multi-\ntask learning framework utilizing the pre-trained BERT model\nas a shared representation layer, but applied more complex\ntasks for joint learning including aspect-term SA and aspect-\ncategory SA tasks. Zhao et al. [30] introduced MTABSA\nto learn aspect-term extraction and sentiment classification\nsimultaneously, incorporating multi-head attention to associate\ndependency sequences with aspect extraction. In contrast, our\napproach focuses on a more granular level of joint task learn-\ning, where each sentiment element functions as a subtask and\ncontributes to the primary sentiment polarity prediction task. In\nrecent years, PLMs like T5 [31] have demonstrated exceptional\ngeneralization capabilities across numerous NLP tasks through\nmulti-task learning via task prefixes. Models empowered by\nPLMs have shown promising results [6], [23], [32], [33].\nFurthermore, LLMs with larger size have exhibited impressive\ncomplex reasoning abilities using Chain-of-Thought (CoT)\nprompting [34]\u2013[38]. Some research has focused on jointly\nlearning reasoning chains with prediction tasks [12], [13], [39].\nLi et al. [13] explored multi-task learning with explanation\nand prediction, leveraging T5 as the backbone model with\ninstruction learning. However, their approach assigns equal\nweight to each task, and the auxiliary explanation task may\nproduce unfaithful explanations that could negatively impact\nprediction tasks. In contrast, our method conducts automatic\nMTL utilizing data-level and task-level AWL to focus on\nmore reliable data and critical tasks, which achieve optimal\nperformance by learning more fine-grained weights without\nextensive manual intervention."}, {"title": "III. METHODOLOGY", "content": "In this section, we delve into the proposed multi-task\nlearning framework MT-ISA, as illustrated in Figure 2. MT-\nISA leverages the generation and reasoning capabilities of\nLLMs through automatic MTL, which dynamically adjusts\nthe weights between primary tasks and auxiliary tasks by\nconcerning the confidence level of data and the importance\nof tasks. In the beginning, MT-ISA constructs additional\nsentiment elements as auxiliary tasks to form a comprehensive\nsentiment picture of a given expression. To prepare relevant\nsentiment elements conducive to the primary polarity inference\ntask, an off-the-shelf LLM is employed to perform generation\nusing a self-refine strategy with polarity label intervention,\nensuring data relevance and quality. Moreover, confidence\nscores are obtained from the generation process, regarded as\nindicators of data-level uncertainty. To further enhance learn-\ning performance by handling inherent uncertainties that exist\nwhen applying MTL with LLMs, we introduce data-level and\ntask-level automatic weight learning (AWL), enabling models\nof varying sizes to adaptively learn fine-grained weights based\non their reasoning capabilities without manual intervention.\nThe following section will provide a detailed explanation."}, {"title": "A. Task Definition", "content": "Denote a dataset D = {(xi, ti, Yi)}N, where 1 < i < N, N\nis the number of data instance. Given an input sentence xi and\nits corresponding aspect term ti, where ti C xi, the objective\nof ISA is to infer the sentiment polarity yi towards aspect term\nti correctly. The relevant sentiment elements consist of aspect\nai and opinion or, which may not be explicitly included in the\ninput sentence xi. In the setting of single-task fine-tuning with\nprompting approach, the LLM predicts the sentiment polarity\n\u0177i solely via \u0177\u2081 = argmaxp(Yi|xi,ti). This approach may\npotentially limit the ability of models to capture complete\nsentiment information in input text without extra information\nabout relevant sentiment elements."}, {"title": "a) Primary Task", "content": "The objective of ISA is to infer implicit\nsentiment polarity yi towards a given target ti within a given\ninput xi. Therefore, the primary task is polarity inference using\na labeled dataset, aiming to predict \u0177\u2081 = argmax p(yi|xi, ti).\nTo optimize this task, the cross-entropy loss is calculated\nbetween the predicted label \u0177r and the annotated label yi, then\nwe have the prediction loss for sentiment polarity:\n$\\displaystyle Lp = \\frac{1}{N}\\sum_{i=1}^{N} \\text{CE}(y_i, \\hat{y}_i)$  (1)"}, {"title": "B. Auxiliary Task Construction", "content": "To facilitate the model understanding of implicit sentiment\nby providing a complete sentiment picture, we leverage gen-\nerative LLMs to supplement additional sentiment elements\nthat are conducive to enhancing the reasoning capacity for\nISA. We construct two subtasks as auxiliary tasks focused\non essential sentiment elements including aspect and opin-\nion. Specifically, we prompt an off-the-shelf LLM using the\nself-refine strategy with polarity intervention. This approach\nensures that the generated sentiment elements are rectified\nby golden polarity through an iterative refinement process,\nthereby enhancing the reliability of the generated content.\nFurthermore, we retrieve the confidence score for generated\nresponses, serving as indicators of data-level uncertainty in\nSection III-C. The generation process is detailed in Algorithm\n1 and the prompt templates are specified in Figure 5 with\na case study to illustrate the whole process. We use teacher\nforcing to train our model for auxiliary tasks, minimizing the\nnegative log-likelihood, which is expressed as follows:\n$\\displaystyle L_{NLL} = -E\\log p(y|x) = -E\\sum_{t=1}^{T} \\log p(s_t|x, S_{<t})$  (2)\n$\\displaystyle L_a = L_o = L_{NLL}$ (3)\nwhere La and Lp are the loss for aspect and opinion auxiliary\ntasks respectively, T is the length of target sequence s, and\nS<t represents the sequence of outputs before time step t."}, {"title": "C. Data-level Automatic Weight Learning (D-AWL)", "content": "To encourage the model to prioritize data instances with\nhigh confidence levels in auxiliary tasks, we adopt three strate-\ngies for data-level AWL using the confidence scores obtained\nfrom Algorithm 1. These strategies help the model better\nmanage uncertainty and noisy data, enabling it to learn more\nmeaningful feature representations by mitigating the negative\nimpact of noisy data on model training and enhancing learn-\ning efficiency and effectiveness. We also explored alternative\nmethods for retrieving confidence scores, which are discussed\nin Section V. We select the prompt-based method due to\nits more consistent distribution and superior performance in\napplication. Specifically, we conduct an empirical study on\nthree data-level AWL strategies as follows:\n1) Input (I) Strategy: The first strategy is scaling the\ninput embedding according to the data-level confidence scores\nretrieved from Algorithm 1, directly influencing the feature\nrepresentations fed into the backbone model. Given the model\nembedding layer Emb(\u00b7) and input text xi with confidence\nscore ci, we adapt the auxiliary task loss in equation (2) to\nget:\n$\\displaystyle e_i = c_i \\cdot Emb(x_i)$ (4)\n$\\displaystyle L_{NLL (I)} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{t=1}^{T} \\log p(s_{i,t} | e_i, S_{i,<t})$ (5)\nwhere the re-weighting embedding ei will be fed into the\nbackbone model instead of the original xi for auxiliary task\ntraining.\n2) Output (O) Strategy: The second strategy is to re-weight\nthe output loss with data-level confidence scores retrieved from\nAlgorithm 1 while dealing with data instances equally, which\nadjusts more attention to data instances with higher confidence\nlevels during optimization. In this way, the auxiliary loss in\nequation (2) becomes:\n$\\displaystyle L_{NLL(O)} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{t=1}^{T} c_i \\log p(s_{i,t} | x_i, S_{i,<t})$ (6)\n3) Input-Output (I-O) Strategy: The third strategy simul-\ntaneously conducts confidence-guided re-weighting towards\ninput embedding and output loss, which combines equation\n(5) & (6) to get:\n$\\displaystyle L_{NLL(I-O)} = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{t=1}^{T} c_i \\log p(s_{i,t} | e_i, S_{i,<t})$ (7)"}, {"title": "D. Task-level Automatic Weight Learning (T-AWL)", "content": "At the task level, we have each subtask represent one\nsentiment element. Instead of manually adjusting the weight\nbetween tasks, MT-ISA introduces homoscedastic uncertainty\n[40] as the task-level uncertainty\u00b9 to capture relative confi-\ndence among tasks. Subsequently, we develop an automatic\nloss function (ALF) for the multi-task loss in MT-ISA and\ntrain the model based on ALF\u2081:\n$\\displaystyle \\mathcal{L} = \\frac{1}{\\sigma_1^2}L_a + \\frac{1}{\\sigma_2^2}L_o + \\frac{1}{\\sigma_3^2}L_p + \\sum_{i=1}^{k} \\log(\\sigma_i^2)$ (8)\nwhere is a tunable observation noise parameter that\nmeasures task-level uncertainty, log(\u03c3\u00b2) is the regularization\nterm, and k is the number of varied tasks.\nHowever, to avoid negative values during optimization in-\ntroduced by log(\u03c3\u00b2) when \u03c3\u00b2 < 1, the regularization term can\nbe adapted to In(\u03c3\u00b2 +1) as suggested by [42]. Then we adapt\nALF2 as follows:\n$\\displaystyle \\mathcal{L} = \\frac{1}{\\sigma_1^2}L_a + \\frac{1}{\\sigma_2^2}L_o + \\frac{1}{\\sigma_3^2}L_p + \\sum_{i=1}^{k} \\ln (\\sigma_i^2 + 1)$ (9)\nIn practice, we evaluate and compare both ALF\u2081 and ALF2\nas discussed in section V. Through the implementation of the\nabove-developed loss function L for multi-task fine-tuning, we\nexpect the model to dynamically adjust the task weight and\nmodel parameters simultaneously under D-AWL and T-AWL\nstrategies."}, {"title": "IV. EXPERIMENT", "content": "a) Datasets and Metrics: To evaluate the performance of\nISA, We take experiments on Restaurant and Laptop datasets\nin SemEval-2014 [43] and follow the prior work [3] splitting\nannotated data into implicit and explicit classes. The evaluation\nmetrics use accuracy and macro-F1 score.\nb) Baselines: We compare our approach with state-of-\nthe-art ABSA baselines and recently reported prompt-based\nfine-tuning methods. Given that we utilize GPT-40-mini for\nauxiliary task construction, we also include its zero-shot per-\nformance for reference. Additionally, we compare with MTL\nbaselines to demonstrate the effectiveness of our automatic\nMTL approach. The baselines are as follows:\n\u2022 ABSA Baselines:\nBERT+SPC [19]: Directly fine-tunes BERT for sen-\ntence pair classification.\nBERT+ADA [44]: Integrates data from other domains\nfor adaptation.\nRGAT [21]: Learns both aspect term embedding and\ndependency relation embedding to obtain more infor-\nmation.\nC\u00b3DA [20]: Creates augmentations by modifying the\naspect term and altering the sentiment polarity.\nISAIV [22]: Investigating causal relations for implicit\nsentiment expressions.\nBERT Asp+SCAPT [3]: Uses contrastive learning with\nexternal corpora to learn implicit knowledge.\n\u2022\nBERT Asp+CEPT [3]: Replaces contrastive learning\nwith cross-entropy loss to post-train BERT with ex-\nternal corpora.\nABSA-ESA [23]: Augments implicit cases with ex-\nplicit expressions using encoder-decoder models.\n\u2022 Prompt-based Fine-tuning:\nDirect Fine-tune: Serves as a baseline using standard\nprompting to question sentiment polarity.\nInstructABSA [45]: Conducts instruction tuning that\napplicable to all ABSA tasks.\nTHOR [6]: Applies CoT fine-tuning to infer sentiment\nelements step-by-step.\nMTL Methods:\nBERT-MTL [29]: Simultaneously learns aspect-term\nand aspect-category sentiment analysis tasks.\nMTABSA [30]: Jointly learns aspect term extraction\nand aspect polarity classification tasks.\nMT-Re and MT-Ra [13]: Conduct MTL on LLMs by\njointly learning rationales and question-answer pairs of\noriginal data. MT-Re derives rationales using reasoning\n(Re) prompts, whereas MT-Ra employs rationalization\n(Ra) prompts.\nc) Models and Hyperparameters: We use an off-the\nshelf model, GPT-40-mini, for auxiliary task construction\napplying a self-refine strategy [24] with polarity label interven-\ntion. For MTL, we use Flan-T5 [46] in encoder-decoder archi-\ntecture as the backbone model. We test different sizes of Flan-\nT5 scaling from the base model (250M) to the XXL model\n(13B) to investigate their performance and behavior under\ndata-level and task-level AWL. As our method applies AWL\ninstead of manual adjustment, the task weights for different\nsubtasks are tunable hyperparameters that are optimized along\nwith model parameters. To maintain more stable training, we\nadopt ALF2 as the multi-task loss objective to present the\nmain results, and we discuss the results obtained with various\nALF in Section V."}, {"title": "B. Main Results", "content": "1) Comparison with Baselines: The main results compared\nwith baseline methods are shown in Table I. It can be seen\nthat our method, MT-ISA, surpasses the current baselines\nand achieves state-of-the-art results in ISA, demonstrating\nthe effectiveness of our proposed framework for learning\nrelationships among sentiment elements. Notably, even the\nbase-sized model with the input D-AWL strategy, MT-ISA 1,\noutperforms most baselines, with the exception of BERT Asp\n+ SCAPT [3]. Although BERTAsp + SCAPT is pre-trained\non the large-scale aspect-aware annotated dataset and exhibits\nstrong capabilities in ABSA, our method still shows superior\nperformance on the Laptop dataset. In MT-ISA, we employed\nGPT-40-mini for auxiliary task construction. We tested the\nzero-shot performance of GPT-40-mini for reference and ob-\nserved a gap between directly applying a strong model like\nGPT-40-mini and fine-tuning a base model like Flan-T5-base\nin ISA. Furthermore, there is a performance degradation in\nboth overall and implicit results when adopting GPT-40-mini\nwith the THOR method, where THOR uses CoT prompting"}, {"title": "C. Ablation Study", "content": "We conduct an ablation study for the proposed MT-ISA\nframework to investigate the effects of D-AWL and T-AWL.\nThe best-performing models were evaluated: MT-ISA, with\nthe base-size model, and MT-ISA, with the XXL-size model.\nAs shown in Table IV, MT-ISA without D-AWL exhibits a\nperformance degradation of nearly 2%, with an even greater\ndrop observed in the Restaurant ISA using the XXL-size\nmodel. This underscores the effectiveness of the D-AWL strat-\negy in adjusting data-level attention and enhancing effective\nlearning during multi-task fine-tuning. However, the perfor-\nmance decline of MT-ISA without T-AWL is more pronounced\nthan without D-AWL. Given that multi-task learning can be\nsensitive to task weights, MT-ISA relying on grid search for\noptimal task weights may fail to achieve the fine-grained\ntask weight optimization provided by T-AWL. T-AWL plays\na crucial role in MT-ISA by balancing different tasks and\nadapting effectively to models of various sizes. Furthermore,\nwhen MT-ISA is applied without the assistance of D-AWL\nand T-AWL, where we refer collectively to AWL in the\ntable, the performance decreases dramatically with a maximum\ndrop of nearly 9 points in Restaurant ISA. This highlights\nthe mutually reinforcing relationship between D-AWL and T-\nAWL, where D-AWL supplements data-level adjustment and\nT-AWL manages task-level control accounting for the data-\nlevel effects of D-AWL."}, {"title": "D. Case Study", "content": "This section presents a case study for auxiliary task con-\nstruction aimed at restoring aspect a and opinion o in ISA, as\nillustrated in Figure 5. This example involves two rounds of di-\nalogue to achieve consensus with an off-the-shelf LLM, GPT-\n40-mini. During the process of inferring sentiment elements,\nthe generated auxiliary data is appended to subsequent ques-\ntions to serve as a reference. Additionally, the confidence score\nis elicited with each response. Through the implementation of\na self-refine strategy with gold label intervention, GPT-40-mini\neffectively refines its responses to align with the ground truth\nsentiments. Furthermore, the confidence scores exhibit a slight\nincrease following this refinement process. This observation is\nconsistent with the distribution of confidence scores discussed\nin Section V."}, {"title": "V. DISCUSSION", "content": "We propose a multi-task learning framework MT-ISA, lever-\naging generative LLMs for auxiliary data construction to\nrestore the complete sentiment picture. During optimization,\nwe conduct D-AWL and T-AWL to enhance reliable reasoning\nand achieve optimal performance in ISA. Given the critical\nroles of data confidence score in D-AWL and automatic loss\nfunction in T-AWL, this section will discuss confidence score\ndistribution in part V-A and automatic loss function in part\nV-B. We will evaluate alternative approaches and provide an\nin-depth analysis of their impact on the overall performance\nof the framework."}, {"title": "A. Confidence Score Distribution", "content": "In the MT-ISA framework, we employ a prompt-based\napproach to derive confidence scores for data instances. The\ndominant research elicits confidence scores with prompt-based\n[47] or training-based approach. Figures 6 (a) and (b) illustrate\nthe distribution of confidence scores across two benchmark\ndatasets. Both datasets exhibit a similar distribution, with\nconfidence scores ranging from 0.5 to 1.0, and the majority\nfalling between 0.8 and 1.0. This trend is attributed to the\ntendency of the model to assign higher scores to its answer-\nverified results following several epochs of self-refinement\nwith label intervention. To compare with alternative confidence\nestimation methods, we investigate two additional approaches\nusing the Laptop dataset, as depicted in Figures 6 (c) and (d):\n\u2022\n\u2022 Markov Chain: This method treats generated sequences\nas a Markov Chain decision process, calculating the\nprobability of each sequence by summing token-level\nprobabilities and normalizing them to obtain a sequence-\nlevel confidence score.\nChoice Token: This method prompts the model to solve\na binary classification problem after each generation.\nFor example, the model is prompted to answer: \"Is\nthe provided answer reasonable? #(A) reasonable (B)\nunreasonable\", then the token-level probability for the\nselected choice generated by the model is used as the\nconfidence score.\nFrom the confidence score distribution, the Markov Chain\napproach predominantly yields scores in the range of 0.5 to\n1.0. In contrast, the Choice Token method produces scores\nmostly between 0.8 and 1.0, aligning closely with the prompt-\nbased method depicted in Figure 6 (b). However, both the\nMarkov Chain and Choice Token distributions exhibit a long-\ntail effect, where low confidence scores can lead to poor\ngeneration outcomes when input strategy is applied. Since\nthe backbone models are pre-trained with a stable input\ndistribution, very low confidence scores for input embedding\nre-weighting may result in the loss of significant information.\nThis distortion can cause the model to misinterpret the input,\nleading to outputs that are nonsensical or garbled. In practice,\nwe clip the scores to a minimum of 0.5, assuming that this\nthreshold sufficiently reflects uncertainty to a certain extent.\nThe performance results are presented in Table V. It is evident\nthat the prompt-based method, with its more consistent con-\nfidence estimation, demonstrates superior performance com-\npared to the other two methods. Even when identical auxiliary\ntask weights are learned, variations in prediction performance\npersist. This observation underscores the critical importance of\nconfidence calibration in facilitating data-level AWL in MT-\nISA. Moreover, it highlights the effectiveness of the prompt-\nbased method in eliciting reliable confidence scores during the\nself-refinement process."}, {"title": "B. Automatic Loss Function", "content": "To facilitate T-AWL in multi-task scenarios, we extend the\nautomatic loss function proposed by [41] and [42] to our multi-\ntask loss. The primary distinction between these approaches\nlies in the regularization term, as shown in equations 8 and 9.\nHowever, their impact during the training process has not been\npreviously explored. In this section, we compare ALF\u2081 with\nALF2 for T-AWL and evaluate their performance in the ISA\nscenario. The results are presented in Table VI. It is evident\nthat MT-ISA with ALF2 generally outperforms MT-ISA with\nALF\u2081 across most scenarios. It is because ALF\u2081 carries the\nrisk of introducing negative values when o is less than 1,\npotentially leading to instability in the training process or\nundesirable behavior. As observed in the results of MT-ISA1\nwith ALF\u2081 in the Restaurant dataset, the learned weights for\nauxiliary tasks tend to approach very small values. This may\nbe due to aggressive adjustments without enforcing a positive\nvalue in the regularization term during training, causing the\nmodel to converge to a trivial solution. Even when both loss\nfunctions learn the same weights for auxiliary tasks, MT-\nISA with ALF\u2081 demonstrates inferior performance. This is\nbecause the presence of negative values in the loss function\ncan lead to erratic gradients or oscillations during training,\naffecting convergence behavior and resulting in suboptimal\nlocal minima. Overall, MT-ISA is sensitive to task weights and\nALF2 provides more stable training results, achieving optimal\nperformance by effectively leveraging auxiliary tasks."}, {"title": "VI. CONCLUSION", "content": "In conclusion, we introduce a novel MTL framework,\nMT-ISA, designed to reason genuine underlying opinions in\nISA by leveraging the generation and reasoning abilities of\nLLMs with automatic MTL. MT-ISA amically adjusts weights\nin MTL according to data-level and task-level uncertain-\nties, enabling models of varying sizes to learn fine-grained\nweights based on their reasoning capabilities adaptively. We\nutilize an off-the-shelf LLM for auxiliary task construction,\nincorporating a self-refinement strategy with polarity label\nintervention to enhance the reliability of sentiment reasoning,\nwhere confidence scores are derived for responses to reflect\ndata-level uncertainty. Our exploration includes threegies for\ndata-level AWL, which are integrated with homoscedastic\nuncertainty for task-level AWL. MT-ISA demonstrates state-\nof-the-art performance in ISA, highlighting its efficacy. Addi-\ntionally, it is noteworthy that models of varying sizes exhibit\ndistinct preferences and influences, yet they achieve optimal\nperformance when employing the dynamic learning strategy.\nThis finding underscores the robustness and adaptability of\nMT-ISA, suggesting its potential for broader applications."}]}