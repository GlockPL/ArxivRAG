{"title": "Coupling Machine Learning with Ontology for Robotics Applications", "authors": ["Osama F. Zaki"], "abstract": "In this paper I present a practical approach for coupling machine learning (ML) algorithms with knowledge bases (KB) ontology formalism. The lack of availability of prior knowledge in dynamic scenarios is without doubt a major barrier for scalable machine intelligence. My view of the interaction between the two tiers intelligence is based on the idea that when knowledge is not readily available at the knowledge base tier, more knowledge can be extracted from the other tier, which has access to trained models from machine learning algorithms. To analyse this hypothesis, I create two experiments based on different datasets, which are related directly to risk-awareness of autonomous systems, analysed by different machine learning algorithms (namely; multi-layer feedforward backpropagation, Naive Bayes, and J48 decision tree). My analysis shows that the two-tiers intelligence approach for coupling ML and KB is computationally valid and the time complexity of the algorithms during the robot mission is linear with the size of the data and knowledge.", "sections": [{"title": "1. Introduction", "content": "Trust in the reliability and resilience of autonomous systems is paramount to their continued growth, as well as their safe and effective utilization [32][9][7]. Hauser [13] reported the need for intelligent autonomous systems \u2013 based on AI and ML \u2013 operating in real-world conditions to radically improve their resilience and capability to recover from damage. Rich [23] expressed the view that there is a prospect for AI and ML to solve many of those problems. Cave and Dihal [5] claimed that a balanced view of intelligent systems by understanding the positive and negative merits will have impact in the way they are deployed, applied, and regulated in real-world environments.\nAI and robotics researchers have applied ontology as a knowledge-based scheme, within a system to support robotics autonomy, such as SMERobotics [20], KnowRob 2.0 [30], CARESSES [4], open-EASE [3], ORO [27][17], SIARAS [12]. They covered a spectrum of cognitive functions, which according to the classification made by [16] and [28] are recognition and categorization, decision making and choice, perception and situation assessment, prediction and monitoring, problem solving and planning, reasoning and belief maintenance, execution and action, interaction, and communication, and remembering, reflection, and learning. The ontology scope of these prior works varies, and it depends on the functionalities of the target robotic system, i.e. concepts that were modelled in the ontology are related to: object names, environment, affordance, action and task, activity and behaviour, plan and method, capability and skill, hardware components, software components, interaction, and communication [18][33]. Primary motivation for the use of ontologies within robotics is that these knowledge-based approaches offer an expandable and adaptable approach for capturing the semantic features of model robot cognitive capabilities. Furthermore, when considering a fleet distribution of robotic platforms, or swarms, the ontology provides a cyber-physical interface to cloud, web-based"}, {"title": "2. The ML-KB Coupling Mechanism", "content": "The term Knowledge Discovery in Databases (KDD) defined steps to extract knowledge from data in the context of large databases [8]. It defines five stages to discover knowledge from raw data in a database into a knowledge base: Selection, Processing, Transformation, Data Mining, Interpretation/Evaluation.\nTherefore, the approach of coupling in this paper has two folds; firstly, to use the data collected during a robot's task (a robot mission), i.e. inspection, to discover new relationships or associations between different elements, secondly, to interpret those relationships into existing knowledgebase by applying a semi-automated or fully automated process. This would result in a ML trained models supporting ontology-based decision-making for robots when relationships between different elements are unclear.\nTo use the data collected by the robot, it must go through pre- and post-processes, after that, the three main steps are: 1) choosing the most suitable ML algorithm, 2) evaluation and interpretation of the trained model, and 3) encoding the knowledge into the symbolic system (knowledge base). This means that the robot has learned new knowledge after performing his first mission which enhance its performance for the following missions. One of the main challenges is that the trained models (or learned patterns) which are the output of ML algorithms, in most, produce models which are unreadable by humans (i.e., binary coded), unlike J48. The final goal of our research is to carry this ontology learning process at online and without human interactions (fully automated), if possible."}, {"title": "3. Experiments and Results", "content": "The first experiment is selected to prove the two-tiers concept, but it is also related to kind of inspection that is carried by a Husky (a robot platform) which is identifying types of materials. The training dataset in this experiment came from the glass database from the USA Forensic Science Service [14]. Six types of glass are defined in terms of their oxide content (i.e., Na, Fe, K, etc). The dataset has 214 instances, 9 attributes, and 7 classes, as shown in Table 1.\nNext, I demonstrate the two-tiers intelligence concept with three selected ML algorithms: J48, Naive Bayes and Multilayer Perceptron. Scikit [19] is used. Weka [24] is also possible framework for ML with a user-friendly interface and it was also tired.\nIn the knowledge base side, the formalism used for modelling is description logic (DL) which is a subset of first order predicate logic, i.e., an ontology-based representation [21]. The Ontology Web Language (OWL) is a suitable platform for experiments and demonstrating the proof of concept. The interpretation of the pruned tree is done semi-automatically (scripting and API). SWRL rules are created based on the information provided by the tree and the knowledge base is then extended, Step 3. The modelling process is described in Table 4 while Figure visualises the outcome of the modelling process."}, {"title": "3.1 Experiment One", "content": "The first experiment is selected to prove the two-tiers concept, but it is also related to kind of inspection that is carried by a Husky (a robot platform) which is identifying types of materials. The training dataset in this experiment came from the glass database from the USA Forensic Science Service [14]. Six types of glass are defined in terms of their oxide content (i.e., Na, Fe, K, etc). The dataset has 214 instances, 9 attributes, and 7 classes, as shown in Table 1.\nFive ML algorithms were applied to the dataset, using the n-fold test option cross validation procedure which is used to estimate the skill of the model on new data, with the value of 'n' equal to 10. The ML algorithms are: J48, Na\u00efve Bayes, SVM (SMO), Logistic Regression, and Multilayer Perceptron. Performance is measured with reference to the following parameters: correctly classified instances (CCI), incorrectly classified instances (ICS), Kappa statistic (KS), mean absolute error (MAE), root mean squared error (RMSR), relative absolute error (RAE), and root relative squared error (RRSE).\nNext, I demonstrate the two-tiers intelligence concept with three selected ML algorithms: J48, Naive Bayes and Multilayer Perceptron. Scikit [19] is used. Weka [24] is also possible framework for ML with a user-friendly interface and it was also tired.\nIn the knowledge base side, the formalism used for modelling is description logic (DL) which is a subset of first order predicate logic, i.e., an ontology-based representation [21]. The Ontology Web Language (OWL) is a suitable platform for experiments and demonstrating the proof of concept. The interpretation of the pruned tree is done semi-automatically (scripting and API). SWRL rules are created based on the information provided by the tree and the knowledge base is then extended, Step 3. The modelling process is described in Table 4 while Figure visualises the outcome of the modelling process."}, {"title": "3.2 Experiment Two", "content": "In the second experiment, the robot was commanded to autonomously navigate inside an enclosed test arena. Five test cases were designed to mimic real-world failure scenarios by purposely manipulating either Jackal's (a robot platform) sensor data or hardware to interfere with its autonomous navigation. The five test cases are: 1) Lidar interruption, 2) IMU interruption, 3) Odometry drift, 4) Deflated tyre, and 5) Unseen obstacle.\nThe first test case considers hardware failure that would affect the Lidar. Such failure could be associated with, for example, sensor malfunction, cable breakage, or an open circuit. This experiment examines the impact of the absence of incorrect or incomplete data on the AMCL module used as localisation for the Move base navigation stack. The second test case considers the impact of a malfunctioning IMU and the impact of that on the EKF (Extended Kalman Filter) pose estimation module in the Jackal control package. The third and fourth test cases, odometry drift and deflated tyre, consider the impact of the hardware failure in the wheel-encoder and the EKF pose estimation, Figure 5. Multiple weights, totalling approximately 5 kg, were added to the front right side of the robot to increase the load on the tyre, Figure 3. The last test case examines an external opposing force against the robot's forward direction affecting the robot's localisation. The external opposing force can be caused by an object that is outside the lidar field of view of the robot used in these test cases, Figures 4.\nThe robot is equipped with an Ouster OS1 lidar and an Intel RealSense D453i depth camera installed on the top of the robot. In addition, a tyre deflating device was installed on the front right wheel. The tyre deflating device was designed and developed, by the team at Manchester University, to reduce tyre pressure in a controlled manner to simulate a flat tyre. The device consists of a Schrader valve pin plunger which can be activated by an SG 90 servo. Once activated, the plunger pushes the metal pin in the Schrader valve to allow air to escape from the tyre. The device was controlled by a Teensy 3.2 which communicates wirelessly with the base station PC via rosserial and an Adafruit ATWINC1500 WiFi Module, using methodology presented in [23]. A 200 mAh LiPo battery was used to power the device independently. Zip ties were used to fix the device to the robot's front right wheel, Figure 5.\nFor all five test cases, the robot was commanded to autonomously navigate continuously along a 1.6- by-1.6 m square route defined by four waypoints (WP 1, 2, 3 and 4). A base station PC was remotely connected to Jackal for initiating the robot, injecting programmatic data manipulation, and recording sensor and diagnostic data, Figure 6."}, {"title": "4. Performance and Overall Analysis", "content": "For the ontology, two complexity and scalability tests are performed:\n1. The ratio in size between the theoretical size (raw data to be populated into the ontology) and the actual size of the ontology after raw data was populated into it. This test indicates the complexity of the space required (storage or working memory).\n2. The time taken by the reasoning process versus the size of the ontology when it is loaded into working memory. This test indicates the complexity of time required by the reasoning process.\nThe ontology experiment in [31] showed that the space required by the ontology is about 25 times more than the size of the raw data on average, and there is a linear relationship between the two variables. Interestingly, this is also true for our case presented in this paper. When the raw data is 14KB the ontology is about 343KB (24.5 times the raw data). The time taken by the reasoner (the reasoning process) is almost linear with respect to the size of the ontology when loaded into working memory. For example, when the size of the ontology is 4MB the computational time taken is 30s to achieve run-time diagnostics. For ontology of size 0.343MB the computational time taken is about 2 seconds.\nFrom the ML side, the time taken for the glass dataset which of size 14KB (like the size of data used in the ontology experiment in [31]) for different algorithms is shown in Table 6. This shows that the most time taken is by the multilayer-perceptron is 0.4s.\nThis means the total time taken by the system reading the logging data from sensors, applying J48, for example, to extract knowledge, feed it into the ontology, and finally perform reasoning is achieved in less than 2.1s. With such small size data, it is reasonable to perform the training online during the missions. However, for experiment Two, applying the Multilayer-Perceptron on a training dataset of size 240MB took nearly 7200s (on 2.6x6 GHz processor, 16MB of RAM). This clearly means, it is not reasonable to apply the ML algorithm online, i.e., during the mission. Adding to this, the reasoning time is significantly longer with such large data."}, {"title": "Conclusion", "content": "As other AI researchers who have recognised the potential and advantages of integrating deductive reasoning and inducive learning together, this paper has demonstrated a practical example of coupling three ML algorithms with a knowledge base in a real-life application in the robotics domain. There are still challenges; to make this coupling fully automatic without the human expert intervention, to devise an architecture for neuro-symbolic integration, and - last but not least - addressing scalability issues. Despite the challenges, undoubtedly, I believe it is an innovative contribution and it would be of great benefit for other researchers. I further believe that to the best of my knowledge no similar work has been reported to combine ML algorithms with KB in the robotics domain."}]}