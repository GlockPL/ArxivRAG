{"title": "Inducing Diversity in Differentiable Search Indexing", "authors": ["Abhijeet Phatak", "Jayant Sachdev", "Sean D Rosario", "Swati Kirtil", "Chittaranjan Tripathy"], "abstract": "Differentiable Search Indexing (DSI) is a recent paradigm for information retrieval which uses a transformer-based neural network architecture as the document index to simplify the retrieval process. A differentiable index has many advantages enabling modifications, updates or extensions to the index. In this work, we explore balancing relevance and novel information content (diversity) for training DSI systems inspired by Maximal Marginal Relevance (MMR), and show the benefits of our approach over the naive DSI training. We present quantitative and qualitative evaluations of relevance and diversity measures obtained using our method on NQ320K and MSMARCO datasets in comparison to naive DSI. With our approach, it is possible to achieve diversity without any significant impact to relevance. Since we induce diversity while training DSI, the trained model has learned to diversify while being relevant. This obviates the need for a post-processing step to induce diversity in the recall set as typically performed using MMR. Our approach will be useful for Information Retrieval problems where both relevance and diversity are important such as in sub-topic retrieval. Our work can also be easily be extended to the incremental DSI settings which would enable fast updates to the index while retrieving a diverse recall set.", "sections": [{"title": "1 Introduction", "content": "Recent developments in Information Retrieval (IR) have brought forth the Differentiable Search Index (DSI) [10], marking a departure from traditional retrieval methodologies. Conventional approaches typically involve constructing an external index to facilitate the retrieval process. In contrast, DSI maps user queries directly to relevant documents with a neural network, streamlining the retrieval process."}, {"title": "2 Related Work", "content": "While traditional methods for diversification are mainly manually crafted, recent research in this area shifts to supervised learning methods and shows superior performance on diversity evaluation metrics. Most current approaches employ an iterative approach, where the next document is selected among remaining documents to maximize some objective with respect to the ones already selected [12]. Such a paradigm is intuitive and achieves the task of diversification. However, the main challenge is that learning is inherently less effective because there is an exponentially large number of ranking lists to consider. Previous approaches such as [17] focus on the ideal diversified ranking lists. Reinforcement learning (RL) based approaches such as [3] and [14] try to maximize the expected rewards over sampled lists from a distribution. Recently proposed PAMM [13] and DVGAN [7] methods maximize the margin between sampled positive and negative lists during training and show better performance. However, gathering high-quality samples is challenging due the scale of data. Prior work incorporates diversity loss into Learning-To-Rank training by approximating diversity metrics [15]."}, {"title": "3 Background", "content": ""}, {"title": "3.1 Differentiable Search Index", "content": "Differentiable search indexing (DSI) [10] is a paradigm for information retrieval with transformer neural network models, where information about a collection of documents is encoded in the model parameters. There is no separate index apart from the neural network in the DSI paradigm. Given a query, the model predicts the documents ID(s) of the relevant document(s), using a classifier like a softmax over document ids or a decoder that generates document ID(s)."}, {"title": "3.2 Maximal Marginal Relevance", "content": "Maximum Marginal Relevance (MMR) [1] retrieval iteratively finds documents that are dissimilar to previous results. MMR has been shown to improve retrievals in search, recommendations and LLMs [4,11,16]. Consider the set \\(D\\) consisting of all candidate documents and \\(R\\) consisting of the previously chosen (retrieved) documents, and \\(q\\) representing a query. We also consider two similarity functions- Sim\u2081 that compares a document with the query, and Sim2 that assesses the similarity between two documents. Let \\(d_i\\) and \\(d_j\\) denote individual documents in \\(D\\) and \\(R\\). Then MMR is defined as\n\\[\nMMR = arg max \\lambda_{MMR} \\cdot Sim_1(d_i, q) \u2013 (1 \u2013 \\lambda_{MMR}) max Sim_2(d_i, d_j),\nd_i\\in D\\setminus R\nd_j \\in R\n\\]\nwhere the first term and the second term respectively represent relevance and diversity. The adjustable parameter \\(\\lambda_{MMR}\\) balances the importance of relevance and diversity. \\(\\lambda_{MMR} \\rightarrow 1\\) prioritizes relevance whereas \\(\\lambda_{MMR} \\rightarrow 0\\) prioritizes diversity."}, {"title": "3.3 Diversity in Information Retrieval", "content": "Diversity is important in information retrieval systems like search engines and recommendation systems. With corpora containing large number of documents, there is a high likelihood that the retrieved set of documents would contain duplicate documents or partially duplicate documents that contain a high degree of textual or semantic overlap. Without diversity, users might get an incomplete picture of a topic or biased understanding. Diversity in the retrieved set could cater to a wider range of interests and need, while mitigating risks of over-specialization/bias and ensures a larger coverage. With sub-topic retrieval, it also ensures that all relevant subtopics are adequately represented, providing users with a more well-rounded understanding of the main topic. Thus, diversity is a key component in making information retrieval more effective and user friendly."}, {"title": "4 Methods and Experiments", "content": ""}, {"title": "4.1 Datasets", "content": "In our experiments, we adopt the same data and settings outlined in the IncDSI paper, utilizing two publicly available datasets. The Natural Questions 320K (NQ320K) dataset [6] contains pairs of queries and documents, where queries are natural language questions and the documents are Wikipedia articles that"}, {"title": "4.2 Our approach: Inducing diversity in DSI", "content": "Our approach to inducing diversity in the model is achieved by modifying the loss function in the training step. The naive DSI model used as our baseline is the BERT-based classification model outlined in IncDSI[5], which uses a multi-class cross entropy loss for classification, where the classes are the N document labels and \\(p_i\\) is predicted probability and \\(y_i\\) is the ground truth label. We extend the loss with the second component inspired from MMR, which accounts for similarity within the retrieved set of documents. In our implementation, we select the linear layer for the top K logits predicted \u2013 which represent the top scoring documents for a query, and then calculate averaged self-similarity within that set of document representations using cosine similarity. The total loss is a linear combination of the two components, weighted by a factor of a and is defined as\n\\[\nLos_{total} = a \\left(-\\frac{1}{N} \\sum_{i=1}^{N} y_i log(p_i)\\right) + (1 - a) \\cdot \\sum_{d_i,d_j\\in K,j>i} Sim_2(d_i, d_j).\n\\]\nWhen \\(a = 1\\), the diversity component is not included in the loss function and thus it corresponds to the naive DSI setting."}, {"title": "4.3 Experimental Setup", "content": "We use the BERT model [2] and initialized with publicly available bert-base-uncased weights for all our experiments. The classification layer is randomly initialized. For the DSI baseline, we use the classifier-based DSI implementation from the IncDSI paper. We train 20 epochs for all models, and train model with \\(\\alpha\\in \\{0.25,0.5,0.75,1\\}\\). We use the same learning rate of le-5 and 5e-5 and a batch size of 128 and 512 are used for NQ320K and MSMARCO respectively mentioned in the IncDSI paper. We use a sigle 80GB CUDA compatible GPU for training and validation of all experiments."}, {"title": "4.4 Metrics", "content": "We evaluate several relevance and diversity metrics as described in Table 1."}, {"title": "5 Results and Discussion", "content": "We observe that our method performed similar to naive DSI in terms of Hits and MRR. However, the compression ratios and other diversity metrics indicate that in our setting with induced diversity in DSI (where a < 1) we retrieve more diverse documents related to the query with similar performance on relevance metrics. In most cases, the diversity-induced models slightly outperform the naive DSI model. The mean inference time across all models is 0.65 seconds with a standard deviation of 0.017 seconds. Since the same number of model parameters are used in both the cases, with and without diversity, the inference time is not impacted with our method."}, {"title": "6 Conclusion", "content": "Our work takes the Differentiable Search Index (DSI) framework for information retrieval, and adds a component to induce diversity in the search results. Since the diversity component is included in the training step, this obviates additional computational steps post retrieval such as MMR, beam search or other mechanisms used to diversify retrieved results. Our work can be extended to IncDSI (incremental) setting where the index can be updated with new document streams, and is an interest direction to pursue. We run experiments on the NQ320K and MSMARCO datasets, with varying values of the balance of relevance and diversity varied by the parameter a. We demonstrate that our approach can induce diversity in the search results without significant impact on the relevance."}]}