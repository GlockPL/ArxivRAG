{"title": "Leveraging GPT-4o Efficiency for Detecting Rework Anomaly in Business Processes", "authors": ["Mohammad Derakhshan", "Paolo Ceravolo", "Fatemeh Mohammadi"], "abstract": "This paper investigates the effectiveness of GPT-4o-2024-08-06, one of the Large Language Models (LLM) from OpenAI, in detecting business process anomalies, with a focus on rework anomalies. In our study, we developed a GPT-4o-based tool capable of transforming event logs into a structured format and identifying reworked activities within business event logs. The analysis was performed on a synthetic dataset designed to contain rework anomalies but free of loops. To evaluate the anomaly detection capabilities of GPT-4o-2024-08-06, we used three prompting techniques: zero-shot, one-shot and few-shot. These techniques were tested on different anomaly distributions, namely normal, uniform, and exponential, to identify the most effective approach for each case. The results demonstrate the strong performance of GPT-4o-2024-08-06. On our dataset, the model achieved 96.14% accuracy with one-shot prompting for the normal distribution, 97.94% accuracy with few-shot prompting for the uniform distribution, and 74.21% accuracy with few-shot prompting for the exponential distribution. These results highlight the model's potential as a reliable tool for detecting rework anomalies in event logs and how anomaly distribution and prompting strategy influence the model's performance.", "sections": [{"title": "1 Introduction", "content": "Detecting anomalies in business processes is critical for ensuring operational efficiency, identifying fraud and improving overall process quality [21-25]. Traditional approaches have made significant progress, but face inherent limitations that reduce their effectiveness in real-world scenarios. For example, while Graph Neural Networks (GNNs) have been used to exploit object-centric event logs for anomaly detection [4], they struggle to detect temporal order anomalies and often rely on complex graph structures that may not fully capture the conceptual connections between activities [6]. Conformance checking techniques excels at detecting control flow anomalies in Business Process Management (BPM), such as parallel execution or sequence rule violations, but struggles to incorporate multidimensional aspects such as resource usage or performance metrics [28]. Their extension to multidimensional aspects require significant manual configuration and domain expertise, which limits their flexibility in different scenarios [29]. On the other hand, machine learning enables the detection of complex, multidimensional anomalies by analysing attributes such as task durations and resource workloads [25]. However, it has difficulty preserving temporal order and enforcing process constraints, requiring additional transformations to handle relationships such as sequence or parallelism [30].\nRecently, Large Language Models (LLMs) have emerged as a powerful layer that simplifies the interface between users and BPM systems [26,32]. By leveraging natural language understanding and generation capabilities, LLMs enable non-expert users to interact more intuitively with BPM systems, reducing the complexity of traditional configurations and facilitating tasks such as anomaly detection, process mining and automation. While existing LLM-based approaches such as DABL can effectively detect semantic anomalies, they often disrupt long-range dependencies and still require significant manual effort in trace generation and model training [9].\nBy incorporating the conceptual and logical connections between activities and using the power of LLMs, specifically GPT-4o-2024-08-06 [1], in this study, we developed an approach that enables a more intuitive and comprehensive detection of anomalies without the need for deep technical knowledge of the underlying business processes. This ease of use allows even general managers with limited technical expertise to apply the model efficiently. Additionally, unlike previous methods that rely on complex setups or costly implementation, this solution is simple, cost-effective, and offers actionable insights that enhance business decision-making. The ability to interpret anomalies in natural language further empowers businesses to understand not only when an anomaly occurs but also why, making this method a valuable tool for operational improvement.\nThis study aims to evaluate the performance of GPT-4o-2024-08-06 - hereafter referred to as GPT-4o for simplicity - in rework anomaly detection using various prompt engineering techniques [6], including zero-shot, one-shot and few-shot prompts. By systematically adapting prompts and methods, this research seeks to identify the most effective strategies for using GPT-4o in this context. Three primary research questions guide the study: (i) Is GPT-4o effective in detecting rework anomaly in business processes? (ii) How does the distribution of anomalies affect the performance of GPT-4o? (iii) Which prompting technique performs best for different anomaly distributions? To address these questions, the experiments were structured around the distribution of anomalies within the event log. Specifically, we analysed three well-known statistical distributions: normal [16], uniform [17], and exponential [18].\nThe study demonstrates that utilizing the few-shot technique with a uniform distribution yields a 46% higher accuracy compared to Principal Component Analysis, 30% higher than Isolation Forest, and 16% higher than the Deep Autoencoding Gaussian Mixture Model on the same dataset."}, {"title": "3 Methodology", "content": "This paper focuses on a specific type of anomaly in business processes known as rework. A rework anomaly occurs when a task or set of tasks is unnecessarily repeated within the same process instance, often signaling inefficiencies that negatively impact overall process performance [10]. Detecting rework anomalies is quite challenging because not all reworked activities follow the same pattern. For example, in the dataset analyzed in this paper, repeated activities may not occur consecutively but may be interspersed with other tasks, making it important to distinguish whether these repetitions serve a valid purpose or represent inefficiencies that should be classified as rework.\nThe study exploits the pattern recognition capabilities of LLMs [11], such as GPT-4o, to detect rework anomalies. Unlike traditional approaches, LLMs excel at interpreting nuanced patterns of activity, enabling them to distinguish between rework and intentional repetition by considering the broader context of process behavior.\nOne of the most significant weaknesses of LLMs is the limited size of the input. Rework anomalies were selected because they are self-contained, allowing the model to classify events without relying on variant-dependent analysis. This focus enables the model to detect inefficiencies independently, without the added complexity of analyzing process variant relationships and performing the analysis on a smaller chunk of data, unlike other types of anomalies, such as delay anomalies, that require considering the distribution of all activities to detect whether a specific activity is abnormal."}, {"title": "4 Dataset", "content": "The paper uses a subset of the synthetic dataset presented in [2]. The original dataset contains 1,000 labelled variants, with labels indicating whether a variant is normal or has a rework anomaly. However, due to OpenAI's token-per-minute (TPM) limit for tier-1 users [20], we are limited to 30,000 tokens per minute. Consequently, we can only use a subset of this dataset, consisting of 760 variants, 71 reworked variants and 689 normal variants. We have created three copies of"}, {"title": "5 Experiment", "content": "To address the anomaly detection task in our study, we developed an application that uses LangChain [5] as the backbone for workflow definition and execution. LangChain provides a modular and versatile framework that simplifies the complexity of building scalable, stateful and context-aware LLM-based applications. Our workflow is parameterised by four key messaging components. (i) Human message represent user-initiated input to the system. (ii) System message collects predefined, hard-coded messages that guide the LLM during execution by providing contextual instructions or constraints. (iii) AI message refers to the outputs generated by the LLM based on the prompts and instructions provided. (iv) Function messages are another form of system messages; however, their initiation differs from system messages and are used to describe functions. The workflow consists of two main sub-processes: Setup and LLM execution.\nSetup sub-process: This stage involves preparing the input data for LLM analysis. Event logs are retrieved, a user-defined anomaly distribution is applied, and the logs are formatted into event variants compatible with the LLM.\nLLM execution sub-process: In this phase, the system processes the event variants, integrates user prompts and provides specific instructions to the"}, {"title": "6 Results", "content": "We compared the performance of three prompting techniques across synthetic data set with different distributions, to assess their effectiveness in anomaly detection. Our findings suggest that GPT-4o demonstrates strong performance in anomaly detection tasks on event logs, although certain limitations and areas for improvement have emerged from our experiments. More specifically, this study was guided by addressing three primary research questions.\nFirst, Are LLMs, such as GPT-4o, effective at detecting anomalies in business processes? Our findings indicate that GPT-4o demonstrates strong performance in detecting anomalies, achieving a precision of 98.43% when provided with a single example in a uniform distribution. This highlights GPT-4o's capacity to detect anomalies accurately, even with minimal business context.\nSecond, Does the anomaly distribution affect the performance of LLMs in anomaly detection? Our results confirm that the anomaly distribution signifi-"}, {"title": "7 Discussion", "content": "GPT-4o demonstrated promising results overall. As shown in Table 3, its performance is highly influenced by the anomaly distribution. For instance, precision values range widely from 27.28% to 98.43%. The model achieves its best overall performance under a uniform distribution and its worst under an exponential distribution. These findings are consistent with previous observations regarding the unique characteristics of data distributions in event logs, which often deviate from the assumptions of standard machine learning models [32].\nThe choice of prompting strategy has a significant impact on whether precision or recall is prioritised. For example, for a uniform distribution, the highest precision is achieved with one-shot prompting, while the highest recall is achieved with few-shot prompting. A similar pattern is observed for a normal distribution, where the highest precision is obtained with few-shot prompting, while the best recall is obtained with one-shot prompting. This variability highlights the importance of tailoring prompting techniques to specific evaluation priorities.\nFor a comparative analysis, we incorporate results from Y. Shi et al. [33], who evaluated the same dataset using traditional machine learning methods such as Local Outlier Factor (LOF), Principal Component Analysis (PCA), Isolation Forest (IF), Deep Autoencoding Gaussian Mixture Model (DAGMM), and TVPM, an original method proposed in [33]. These methods provide a benchmark for anomaly detection accuracy and false discovery rate. However, a significant limitation in the comparative results lies in the authors' lack of consideration for anomaly distribution.\nA key observation from Table 4 is the notable difference in False Discovery Rate (FDR) between GPT-4o and other methods. Specifically, GPT-4o achieves"}, {"title": "8 Future Works", "content": "While GPT-4o demonstrated strong performance in detecting rework anomalies, its applicability to other anomalies remains untested in our study. Rework anomalies are only a subset of the potential inefficiencies that can occur in business processes. Other types of anomalies, such as timing or sequence anomalies, may require different detection approaches, and it is unclear how well GPT-4o would perform in these cases without further experimentation.\nAnother important consideration is the refinement of prompt engineering. In our study, we experimented with zero-shot, one-shot and few-shot prompting techniques, but future research could investigate more sophisticated prompt engineering strategies.\nAnother area of improvement could be to improve the model's ability to handle negations. Negation tasks are particularly challenging for LLMs, but advances in model tuning and adversarial training could help address this issue. Exposing the model to more diverse training data, including nuanced negation"}, {"title": "9 Conclusion", "content": "In this study, we explored the potential of GPT-4o as an advanced business process anomaly detection tool, explicitly targeting rework anomalies. We demonstrated the robustness of the model in identifying inefficiencies, while highlighting the importance of tailored prompt engineering, using zero-shot, one-shot and few-shot prompt techniques on datasets with different anomaly distributions. Our results demonstrate that GPT-4o, with its high accuracy and low false discovery rates under optimal conditions, is a valuable addition to process mining and anomaly detection methods.\nHowever, the study also highlights GPT-4o's challenges in handling complex distributions, such as the exponential anomaly distribution, and scaling to larger datasets due to token limitations. These limitations point to the need for further advances in prompt engineering and hybrid systems that integrate LLMs with traditional machine learning techniques. Furthermore, the variability in performance between prompt strategies highlights the importance of tailoring method selection to specific dataset characteristics and detection priorities.\nOverall, this research highlights the effectiveness of GPT-4o as an accessible tool for anomaly detection in dynamic business environments. By bridging the gap between technical and non-technical users, GPT-4o enables accurate detection and promotes deeper insight into the nature of anomalies. Future research into broader anomaly types, improved prompting strategies and hybrid frameworks promise to extend its applicability and further enhance its capabilities."}]}