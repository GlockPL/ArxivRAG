{"title": "DODGE: Ontology-Aware Risk Assessment via Object-Oriented Disruption Graphs*", "authors": ["Stefano M. Nicoletti", "E. Moritz Hahn", "Mattia Fumagalli", "Giancarlo Guizzardi", "Mari\u00eblle Stoelinga"], "abstract": "When considering risky events or actions, we must not down-play the role of involved objects: a charged battery in our phone averts the risk of being stranded in the desert after a flat tyre, and a functional firewall mitigates the risk of a hacker intruding the network. The Common Ontology of Value and Risk (COVER) highlights how the role of objects and their relationships remains pivotal to performing transparent, complete and accountable risk assessment. In this paper, we operational-ize some of the notions proposed by COVER - such as parthood between objects and participation of objects in events/actions - by presenting a new framework for risk assessment: DODGE. DODGE enriches the expressivity of vetted formal models for risk i.e., fault trees and attack trees by bridging the disciplines of ontology and formal methods into an ontology-aware formal framework composed by a more expressive modelling formalism, Object-Oriented Disruption Graphs (ODGs), logic (ODGLog) and an intermediate query language (ODGLang). With these, DODGE allows risk assessors to pose questions about disruption propagation, disruption likelihood and risk levels, keeping the fundamental role of objects at risk always in sight.", "sections": [{"title": "1 Introduction", "content": "Risk assessment is a key activity to identify, analyze and prioritize the risk in a system, and come up with (cost-)effective countermeasures [37]. This is true when considering safety (i.e., the absence of risk connected with unintentional malfunctions) and security (i.e., the absence of risk linked with intentional attacks) [34]. To perform transparent, complete and accountable risk assessment, it is fundamental to explicitly account for the role objects play in Events and Actions in which they participate, and for how their status affects safety and security interplay: a door being locked causes the impossible escape event in case of fire but simultaneously stops the action of a burglar entering your house"}, {"title": "Objective.", "content": "Provide an ontology-grounded formal approach for object-based risk representation and reasoning by combining and extending standard formalisms for safety (fault trees) and security (attack trees)."}, {"title": "DODGE: bridging ontology and formal methods.", "content": "To address this lack of expressivity, two promising fields must be taken into account: ontologies for risk and model-based risk assessment. On the one hand, risk ontologies - like the Common Ontology of Value and Risk (COVER) [32] \u2013 excel in providing a structured ground for reasoning about a specific domain of knowledge, transparently and explicitly laying out key concepts and relationships needed to reason about risk. While excellent for conceptualization and transparency, ontologies are however not designed to enable quantitative and applied risk evaluations. On the other hand, specific model-based technologies from the field of formal methods - like fault trees (FTs) and attack trees (ATs) \u2013 excel in providing applicable, tried and tested instruments for rigorous and quantitative risk assessment. These methods, however, sometimes rely on opaque conceptual assumptions and, in particular, do not offer the expressivity needed to explicitly reason about objects at risk. With DODGE we propose a risk assessment framework that enriches and extends the expressivity of vetted model-based technologies such as FTs and ATs while grounding them in the conceptual clarity of COVER. The result is a transparent and functional framework, composed by a more expressive model, Object-oriented Disruption Graphs (ODGs), a new logic, ODGLog, and an inter-mediate query language, ODGLang. With these components, DODGE allows risk assessors to pose questions about disruption propagation, disruption likelihood and risk levels\u2020, keeping the paramount role of objects at risk always in sight."}, {"title": "Object-oriented Disruption Graphs.", "content": "Fundamental elements highlighted by the COVER ontological framework [32] \u2013 such as the participation of a given object in a risk-related action/event or the parthood relationship between different objects - are not expressible in classical risk assessment formalisms, such as FTs and ATs. We address this gap and operationalize these concepts by presenting Object-oriented Disruption Graphs (ODGs), a new formalism that extends the strengths of classical FT- and AT-based risk analysis accounting for the role of objects at risk (OaRs) in disruption propagation, likelihood and risk calculation."}, {"title": "ODGLog and ODGLang.", "content": "To perform transparent decision-making w.r.t. safety and security of systems, practitioners need the ability to analyse their models in"}, {"title": "2 Baseline Research", "content": "Fault and attack trees. FTs and ATs constitute a sensible starting point as they are popular technologies that already encode key concepts highlighted in the Common Ontology of Value and Risk (COVER) such as Events and Actions and pose a solid ground for model-based risk assessment. Fault tree analysis (FTA) [30] is a widespread technique to support safety risk assessment, and the use of fault trees is required, e.g., by the Federal Aviation Administration, the Nuclear Regulatory Commission, in the ISO 26262 standard [16] for autonomous driving and for software development in aerospace systems. A fault tree (FT) (see Fig. 1, right) models Events that describe how component failures arise, and propagate disruption through the system, eventually leading to system-level failures. Leaves in a FT represent basic events (BEs), i.e. elements of the tree that do not need further refinement. Once these fail, the failure is propagated through the intermediate events (IEs) via gates, to eventually reach the top level event (TLE), which symbolizes system failure. When considering model-based risk assessment of systems security attack trees (ATs) are widely employed. ATs (see Fig. 1, left) are hierarchical diagrams that represent malicious Actions that can lead to a system being compromised [33, 23]. ATs are referred to by many system engineering frameworks, e.g. UMLsec [20] and SysMLsec [29], and are supported by industrial tools such as Isograph's Attack Tree [18]. The TLE of an AT represents the attacker compromising the entire system, and the leaves represent basic attack steps (BASes): actions of the attacker that can no longer be refined. As for FTs, intermediate nodes in ATs are labelled with gates.", "COVER": "The Common Ontology of Value and Risk (COVER) [32] is based on UFO [15] a foundational ontology. It embeds a domain-independent conceptualization of risk, has been subject to validation and proper comparison to the literature of risk in risk analysis and management at large (e.g. [17]), and it is built upon widespread definitions of risk. This ontology has already shown its utility in constructing formalisms for risk quantification and propagation [10], and embeds several key assumptions about the nature of risk, which align with those in the literature in risk assessment. Firstly, the risk is experiential. This means that the notions of \"event\" and \"object\" are deeply entangled and, when assessing the risk an object is exposed to, one aggregates risks ascribed to events that can impact the object. For instance, consider the risks your laptop is exposed to. To assess them, you will need to consider:\n1. which of your goals depend on your laptop (e.g. work deliverables);\n2. what can happen to your laptop such that it would hinder its capability to achieve your goals (e.g. its screen breaking);"}, {"title": "3 Object-oriented Disruption Graphs", "content": "Object-oriented Disruption Graphs (ODGs) extend classical FT- and AT-based risk analysis by integrating key concepts from COVER, i.e., adding needed con-structs to reason about objects at risk during risk assessment. Fig. 3 represents an Object-Oriented Disruption Graph for the locked door example [22, 26, 35]. On the left in red Actions of an attacker are represented in an AT. On the right in violet - Events that can cause failures are represented in a FT. Root nodes in both the FT and AT- the top level events (TLEs) can be mapped to COVER's Loss Events. Each of the events/actions in the FT and AT is labelled with objects at risk (OaRs) that can participate in it a white rectangle on the corner, with blue numbers. These numbers refer to the Object Graph at the bottom, in blue - where arrows represent the parthood relationship. Spe-cific combinations of properties of OaRs that are needed for events/actions to happen what we call conditions are typeset in blue and linked to FT/AT nodes via a dashed line. For example, the condition \u00abLock_Locked is needed for the action Attacker enters door left unlocked to happen. With this model, one can ask ontology-aware questions that do not overlook the role of objects at risk, e.g., 1. Given that an Attacker destroys the door and that the Fire does not break out, are any of the two loss events happening? 2. Is the probability of both successfully forcing the door and fire breaking out lower than 0.05? 3. What is the most risky event in which Inhabitant participates, assuming that Lock is Locked? 4. What is the minimal risk level associated with the OaR Door, given all the events/actions in which it participates? In Sec. 5 we will make these queries more formal via our logic (ODGLog) and query language (ODGLang).\nDefinition 1 (Object-Oriented Disruption Graph). An Object-Oriented Disruption Graph (ODG) G is a tuple (A, F,O, B) where A is an attack tree, F is a fault tree, O is an object graph and B is a disruption knowledge base.\nAs mentioned in [34], ATs and FTs can be syntactically unified under the dis-ruption tree (DT) model:\nDefinition 2 (Disruption Tree). A disruption tree (DT) T is a tuple (N, E, t) where (N, E) is a rooted directed acyclic graph, and $t: N \\rightarrow {OR, AND, LEAF}$ is a"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "function s.t. for $v \\in N$, it holds that $t(v)$=LEAF iff $v$ is a leaf. Moreover, $ch: N \\rightarrow 2^N$ gives the set of children of a node and $T$ has a unique root, i.e., $Rr$.\nWe also define the set of intermediate events $IE = N \\\\ LEAF$. Moreover, if $u \\in ch(v)$ then $u$ is called a child of $v$, and $v$ is a parent of $u$. Furthermore, we employ only AND- and OR-gates in the AT/FT components of the model. The behaviour of a DTT can be expressed through its structure function [30] $f_T$: if we assume the convention that a LEAF has value 1 if disrupted and 0 if operational, the structure function indicates the status of the root node or top level event (TLE) \u2013 given the status of all the LEAVEs of $T$. Thus, for each set of LEAVEs we can identify its characteristic vector b: we refer to this vector as a scenario. We denote by $I_T = 2^{LEAF_T}$ the universe of scenarios of $T$. When further distinction is needed between ATs and FTs constructs, we use (respect-ively) the subscripts _A and _F: e.g., we refer to a scenario on an AT (resp. FT) as an attack scenario (resp. fault scenario), represented by $b_A$ (resp. $b_F$). As shown before, in FT- and AT-related literature nodes canonically represent re-spectively events and attack steps: one might easily map attack steps and events to the terminology chosen in the COVER ontology, for which nodes $N_A$ of an AT represent Actions and nodes $N_F$ of a FT represent Events. From this point on, we will use the general term elements to refer indistinctly to nodes in FTs and ATs. To enrich ATs and FTs, we introduce Objects at Risk (OaRs) that ex-plicitly capture impacted objects in (safety and security) risk experiences. These serve as a formal ground to account for the parthood and participation relations highlighted in COVER.\nDefinition 3 (Object Graph). An object graph (OG) $O$ is a rooted directed acyclic graph $(N_O, E_O, OP, c_{OP})$ where: 1. nodes in $N_O$ represent Objects at Risk (OaRs); 2. directed edges in $E_O \\subseteq N_O \\times N_O$ represent the parthood relation between OaRs; 3. properties on OaRs are atomic propositions $op \\in OP$; and 4. $c_{OP}: N_O \\rightarrow 2^{OP}$ returns a set of atomic propositions of a node $v \\in N_O$.\nMoreover, $ch: N_O \\rightarrow 2^O$ gives the set of parts of a node and $O$ has a unique root, denoted $R_O$. As previously hinted, OaRs and the object graph (OG) are represented by connected blue circles (see Fig. 3, page 6). Similarly to DTs' evaluation, we need a way to evaluate properties of OaRs, thus:\nDefinition 4 (Evaluating Properties of OaRs). We let a configuration $b_O$ be the Boolean vector assigning values to properties of OaRs in OP and we let $f_O: B^n \\times OP \\rightarrow B$ be a valuation such that $f_O(b_O, op) = 1$ iff the Boolean value of a property $op \\in OP$ equals 1 given $b_O$.\nFurthermore, we let $B_O$ be the set of all possible configurations. Finally, we in-troduce a Disruption Knowledge Base (DKB) that establishes a formal relation between elements in ATs and FTs and OaRs that can participate in them. We also define attribution of an impact value to ATs and FTs elements and their preconditions and conditions in the DKB. Preconditions are relevant properties of OaRs that can participate in a given event/action. These properties must be arranged in a specific way for events/actions to happen: conditions express this arrangement of preconditions."}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "Example 1. Consider the excerpt of the ODG of Fig. 3 in Fig. 4: conditions for the event Fire breaks out \u2013 in blue, connected with a dashed line are encoded in the Boolean formula \u00abHouse_Sprinklers / Inhab_Unaware: in fact, the OaRs House and Inhabitant participate in the event Fire breaks out and the relevant properties of these participating objects at risk are House_Sprinklers and Inhab_Unaware. These are exactly the preconditions for event Fire breaks out and they must be set resp. to false and true in conjunction for Fire breaks out to happen.\nDefinition 5 (Disruption Knowledge Base). A disruption knowledge base (DKB) B is a tuple (D, Im, Pa, Pr) where: 1. D = NA U NF U No is an entity domain where NA, NF and No are pairwise disjoint 2. Im: NA UNF \u2192 R>0 is a function that returns an impact factor for each element $v \\in N_A UN_F$ 3. Pa: NA UNF \u2192 2o is a function that for each element $v \\in N_A UN_F$ re-turns a set of OaRs that can participate in v 4. For each element $v \\in N_A UN_F$, Pr: NAUNF \u2192 2OP is a partial function that returns the set of its preconditions Pr(v) = $c_{OP}(0_1) Uc_{OP}(0_2) ... Uc_{OP}(o_n)$ with $o_i \\in Pa(v)$ 5. For each element \u03c5\u2208 NA UNF, conditions on u are represented by a Boolean formula Cond(v) over its preconditions Pr(v)\nDefinition 6 (Evaluating Conditions of Elements). We let $f_{cond}: B^n x Form \\rightarrow B$ be the evaluation function for conditions with Form being the set of Boolean formulae such that given a configuration $b_O$ and conditions Cond(v) for an element v, $f_{cond}(b_O, Cond(v)) = 1$ iff the Boolean assignment in $b_O$ satisfies Cond(v).\nTo summarize: for each element v we construct a Boolean formula Cond(v) over the set of preconditions Pr(v), which are exactly the relevant properties of OaRs that participate in v which are needed for v to happen. To do so, we collect the n OaRs that can participate in v with Pa(v) and \u2013 for each of these objects $O_i \\in {0_1,..., O_n}$ \u2013 we collect its properties via $c_{OP}(o_i)$. Assumption 3: For each OaR that participates in element (event/action) v, we assume that its parts participate in v as well, but the opposite does not hold. For instance, if Door par-ticipates in Door stays locked also its part - namely, Lock - participates in it, but if Lock participates in Lock breaking this does not imply that Door participates in that event. This is, again, aligned with the theory about events, objects and their parts encoded by UFO and inherited by COVER+. The union of all these collected sets $c_{OP}(or)$ is exactly the set Pr(v) of preconditions on v. The Boolean formula Cond(v) over preconditions in Pr(v) for v represents its conditions. It is important to note that, in a practical setting, a user would iteratively be asked whether 1. all participating objects in v and 2. all preconditions of a given parti-cipating OaR are relevant for conditions on v. E.g., the property Lock_Locked is relevant for preconditions of an element v = Attacker enters door left unlocked, but Lock_Pick-able is not: thus, it is not included as an atom in Cond(v).\nAs hinted, understanding computations on ODGs requires further attention on the interplay between Actions (resp. Events) in ATs (resp. FTs) and their conditions. Since Cond(v) is a Boolean formula over preconditions for $v \\in NA$ (resp. $v \\in NF$), for v to be attacked (to fail) the entire Boolean formula composed by v\u2227 Cond(v) must evaluate to true. To account for this, let us define an extended structure function for DTS:\nDefinition 7 (Extended Structure Function). The extended structure func-tion of a disruption tree T is a function $f^\u2020$: $B^n \\times B^n \\times N \\rightarrow B$ that takes as input a scenario b, a configuration $b_O$ and an arbitrary element $v \\in N$. We define it as follows:\n$f^\u2020(b,b_0, v) =\\begin{cases}b_{\\text{vi}} \\quad \\text{if v = vi $\\in$ LEAF} \\\\f_{\\text{cond}}(b_0, Cond(v)) \\\\ \\bigvee_{v' \\in \\text{ch}(v)}f^\u2020(b,b_0, v')  \\land f_{\\text{cond}}(b_0, Cond(v)) \\quad \\text{ if v $\\in$ IE and t(v) = OR}\\\\  \\bigwedge_{v' \\in \\text{ch}(v)}f^\u2020(b,b_0, v') \\land f_{\\text{cond}}(b_0, Cond(v)) \\quad \\text{ if v $\\in$ IE and t(v) = AND}\\end{cases}$"}, {"title": "4 ODGLog: a Logic to reason about ODGs", "content": "We construct our logic on three syntactic layers, represented with \u03c6, \u03c8 and \u03be. Layer 1 formulae reason about disruption propagation: the atomic propositions a in ODGLog can represent any element in an AT or FT, and any property of OaRs, i.e., $a \\in N_AUN_FUOP$. Formulae can be combined through usual Boolean"}, {"title": "5 Object-Oriented Risk Queries: ODGLog and ODGLang", "content": "In this section, we showcase how practitioners could ask object-oriented questions via ODGLog and present our intermediate query language, ODGLang.\nDesign of ODGLang. To ease the usability of our logic, we present ODGLang, a Domain Specific Language (DSL) for ODGLog. Defining languages and tools to specify properties and requirements is common: in [7] the authors capture high-level requirements for a steam boiler system in a human-readable form with SADL. Further controlled natural languages for knowledge representation include Processable English (PENG) [36], Controlled English to Logic Transla-tion (CELT) [27], Computer Processable Language (CPL) [5] and FRETish [6]. ODGLang is constructed by adhering to the same design philosophy of LangPFL a domain specific language for FTs that was developed in the literature [24]. As for LangPFL, ODGLang is inspired by the aforementioned languages for their ease of use and close proximity to natural language. ODGLang expresses only a fragment of ODGLog. Notably, nesting of formulae is disallowed: we retain most"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "of the expressiveness of ODGLog while making property specification easier. In ODGLang, ODG elements are referred to with their short label and each oper-ator in ODGLog has a counterpart in the DSL: Boolean operators, not, and, or, impl...; setting the value of ODG elements to Boolean or probabilistic values, set, set_prob; minimal risk scenarios MRSS, MRS[...]; operators to check dis-ruption probability thresholds, Prob[. . .] \u2709 . . . (note that \u2709 \u2208 {<, <, =, >, >}); and to reason about risk levels aggregated on a given object and about risky ac-tions/events in which this object participates, MostRiskyA[. . .], MostRiskyF[. . .], MaxTotalRisk[...], Min TotalRisk[. . .], OptimalConf[. . .]. One can specify properties in ODGLang by utilizing operators inside structured templates. Assumptions on the status of ODG elements can be specified under the assume keyword. These assumptions will be automatically integrated with the translated formula ac-cordingly, e.g., set or set_prob will be translated with the according operators to set evidence, while other assumptions will be the antecedent of an implication. A second keyword separates specified formulae from the assumptions and dictates the desired result: compute and computeall compute and return desired val-ues, i.e., probability values, and lists of events/actions/configurations and MRSS respectively, while check establishes if a specified property holds."}, {"title": "Object-Oriented Risk Queries.", "content": "In Table 1 we exemplify some queries on the ODG for the locked door example in Fig. 3. We use natural language, ODGLog and showcase their respective formulation in ODGLang:"}, {"title": "6 Enabling Risk Computations: ODGLog Semantics", "content": "To enable object-oriented risk computations and to ground the meaning of for-mulae into the enriched model presented in Sec. 3, we define formal semantics"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "for ODGLog. For the first layer of the logic, formulae are evaluated on the fol-lowing model M = (br, bo, G) where a risk scenario br = (b1,...,bk) is defined as br = ba UbF, bo is a configuration and G is an ODG. Formally:\n$M \\vDash a \\quad \\text{iff} \\begin{cases}  \\quad f_{\\phi\\text{ba}, b_0, a) = 1}\\\\   \\quad f(b_{F}, b_0, a) = 1}\\\\   \\quad \\phi(b_O, a) = 1 \\end{cases}\\begin{aligned}&\\text{with a $\\in N_a$}\\\\&\\text{with a $\\in N_F$}\\\\&\\text{with a $\\in 0P$} \\end{aligned}$\n$M \\vDash \\neg \\phi \\quad \\text{iff} M \\nvDash \\phi$\n$M \\vDash \\phi \\land \\phi' \\quad \\text{iff} M \\vDash \\phi \\text{and} M \\vDash \\phi'$\n$M \\vDash \\phi [a\\mapsto bool]  \\quad \\text{iff}\\begin{cases} \\vDash M \\quad  \\quad \\pi\\text{i}} = {b'}_i \\text{for j$\\neq$i} \\\\ \\vDash M \\quad  \\quad \\pi\\text{i}} = {b'}_i \\text{for j$\\neq$i} \\end{cases}$\n$M \\vDash MRS(Phi)$"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "With $[\\{\\}\\]_M$ we denote the minimal satisfaction set of risk scenarios for $\\phi$, \u0456.\u0435., the set of minimal risk scenarios $b_r$ that satisfy $\\phi$ given $G$. We define $[\\{\\}\\]_M$ as follows: $[\\{\\}\\]_M  {\\{br| \\forall (b_r, b_o, G) \\vDash \\phi \\text{a b \\in SF, S \\vDash A S=a \\subseteq (0)}\\}}_m$, Note that the set of all minimal risk scenarios for a given $\\phi$ \u2013 i.e., $[\\{\\}\\]_M$ is always computed by fixing a specific configuration $b_o$ first.\nLayer two formulae require the introduction of probabilities. First, we need to decorate the leaves of the AT and the FT in G with probability values. To do so, we let an attribution on G be a map $\\sigma$: BAS$\\{0, 1\\}$. With a slight abuse of notation, we simply write $\\sigma_G$ for the probability attribution on both the leaves of the AT A and the FT F in G. We then let p($\\phi$) define the probability of a given layer one formula $\\phi$. Intuitively: given $\\phi$ and a configuration bo, we consider every possible fault scenario $b_F \\subseteq \\text{S}_F$ on F and how that would impact truth values of FT nodes in $\\Delta$. For each of these fault scenarios, we compute the maximal probability of successfully attacking AT nodes in $\\phi$ under the given configuration $b_o$.\nAssumption 4: Note that \u2013 with this setup we assume the attacker already knows which FT nodes in $\\phi$ failed. Looking at the conceptualization provided in COVER, this aligns with the composition of the \"risk experience\" concept, which not only accounts for the role of \"passive\" elements involved in the assessment of risk (e.g., \"object at risk\") but also for the role of the \"active\" elements involved (see, for instance, the concept of \"threat object\" and related threat capability). This, then, supports the two-step representation of the assessment process we propose, where, firstly, vulnerabilities in a system are identified and, secondly, based on these, threats can be activated. In this sense, the solution allows for simulations that act as operationalizations of the concept of \"risk experience\". Consequently, we let:"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "$\\rho(\\Phi, b_O) = \\sum F E_LF Prob(\\sigma_F)$PA(Set($\\sigma$ $bo))$"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "Where the probability associated to each fault scenario $b_F \\subseteq \\text{S}_F$ \u2013 with $v \\in$ BE \u2013 is calculated via $\\text{Prob}(b_F) = \\prod_{v=1}^{k} b_i \\times \\sigma(v_i) + (1 -b_i) \\times (1-\\sigma(v_i))$ and where the maximal probability of successfully attacking $\\phi$ is given by multiplying attributions on BASes in every minimal attack scenario for $\\phi$ \u2013 $b_A$ \\in [$\\sigma_A$] \u2013 to then take the maximum between the resulting values of these attacks. Formally:\n$PA(\\Phi) = max \\prod \\sigma(V)$\nThis last step is coherent with a more general framework for multiple metric computations on ATs previously defined in [23, 25]. Finally, we account for how every possible fault scenario would impact truth values of atomic propositions of FT nodes in $\\sigma$ by recursively defining Set($\\phi$, $b_F$, $b_o$), with $b_F \\subseteq \\text{S}_F$:\nSet(a, b, $b_O$) ={\\quad 1 \\quad \\text{with a } \\phi \\in AN\\\\ \\quad Set (S, 6F, 60) =1 \\quad \\text{with a } \\phi \\in AF  \\quad if (v, 6 0 =10  = otherwise\\\\  1 \\quad if (v, 6F, 60 ) =100  = otherwise \\\nSet (-, bf, b) = - \\text{Set}(bf, b)\nSet(a, bf, b) = Set ($bf, b0) Set (, bf, b0)\nSet(( \\quad  \\quad if \\vDash 1\\\\\\  Set (b, b0)\\)Set(6, 60)\\\nwhere 1 and 0 represent the true and false derived layer 1 formulae. Note that also due to Set some occurrences can lead to the application of the PA function to either true or false, i.e., when $\\Pi  \\Pi$. In these cases, we fix that  1  and +) = 0. With $k \\in {10\\pi}= S\\to and (M) =4 - =  4 S+ a, M + S  4+ S -4M+\\\\M 4. 1 A, F. 40 \\\nP (0) +4 \\text{with } + S +1\\\\ 44(3). +5 +1441, 44 (4) +5 160(43, 6,4\\)"}, {"title": "DODGE: Ontology-Aware Risk Assessment via ODGS", "content": "Note that one might want to parameterize some elements of the given configura-tion $b_0$ to, e.g., compute optimal assignments to minimize risk on a given OaR. To accommodate for this need, we let $\\Delta$ be the set of configurations that could still be compatible with a partial Boolean assignment [op bool]. E.g.:\nExample 2. Assume we want to consider only the configurations compatible with setting the evidence that Lock_Locked is true, i.e., [Lock_Locked 1] and that we only have two other object properties to consider, the values of which are still not assigned. The resulting partial configuration can be represented as bo = (1,.,), where represents the unassigned values of remaining object properties. The set [Lock_Locked 1] would then contain all possible configurations whose assignments are still compatible with b = (1,.,): e.g., b = (1,1,0) would be in [Lock_Locked], while b = (0,1,0) would be excluded from the set since the value of the first object property is set to zero (against [Lock_Locked 1]).\nWe let objRiskVal = $\\sum a+(0, 2) A.1 (4. 1 \\Pi)$* a + 1 represent the cumulative risk value on a specific OaR o, given events and actions in which it participates. Intuitively, we sum the risk values from each event/action in which o participates, resulting from the probability of each event/action times its impact factor. Given a set of configurations 6, we let Valf define semantics for layer 3 formulae:\nVal(MostRisky A (0)) = argmax max (p(a, bo)A,FIm(a));\n$VAL$ (MostRisky F (0)) = argmax max (41 A.F*40,5 \\\nVal(TotalRisk(o)) = max objRiskVal;\n\u0431\u043e\u0435\u0432\nVal(Optimal Conf (0)) = argmin objRiskVal;\n\u0431\u043e\u0435\u0432\nVal (TotalRisk(o)) = min objRiskVal;\n\u0411\u043e\u0435\u0432\nVal (bo = Val 2(a)\nAssumption 5: Note that with semantics as given, the attacker can adapt its strategy to the node under consideration. E.g., when computing max total risk we assume the attacker can maximise the risk level for each individual node in the graph by choosing the best BASes at each iteration. We then sum risk levels derived from each of these single-node worst-case scenarios. Operating in this way gives practitioners the safest possible risk metric, as they are provided with a worst-case upper bound when computing total risk. Also here, the assumption is inspired by how the \"risk experience\" is represented in COVER, where the \"threat capability\" of a \"threat object\" participating in a \"threat event\" is always directly related to \"loss events\" and related risks."}, {"title": "7 Conclusion and future work", "content": "We presented DODGE, a hybrid ontology-aware framework for object-oriented risk assessment that exploits both the strengths of model-based formal methods and ontologies: by combining ontologies with probabilistic risk quantification models, we enriched the expressive power of FTs and ATs and presented a more expressive ontology-aware model (ODGs), logic (ODGLog) and a query language (ODGLang). We chose COVER for its domain-independent nature and its found-ation in a comprehensive analysis of existing work on risk ontologies. However,"}]}