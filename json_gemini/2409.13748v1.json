{"title": "TheraGen: Therapy for Every Generation", "authors": ["Kartikey Doshi", "Jimit Shah", "Dr. Narendra Shekokar"], "abstract": "The rising incidence of mental health problems has significantly increased the need for easily accessible and efficient support services. The lack of access to mental health care services has had a substantial negative influence on society, increasing the number of untreated mental health illnesses and the associated societal costs. To address this challenge, we present TheraGen, an advanced AI-powered mental health chatbot utilizing the LLaMA 2 7B model. This approach builds upon recent advancements in language models and transformer architectures [1,2,3]. TheraGen provides 24/7 personalized, compassionate mental health care by leveraging a large dataset of 1 million conversational entries, combining anonymized therapy transcripts, online mental health discussions, and psychological literature, including APA resources. Our implementation employs transfer learning, fine-tuning, and advanced training techniques to optimize performance. TheraGen offers a user-friendly interface for seamless interaction, providing empathetic responses and evidence-based coping strategies. Evaluation results demonstrate high user satisfaction rates, with 94% of users reporting improved mental well-being. The system achieved a BLEU score of 0.67 and a ROUGE score of 0.62, indicating strong response accuracy. With an average response time of 1395ms, TheraGen ensures real-time, efficient support. While not a replacement for professional therapy, TheraGen serves as a valuable complementary tool, significantly improving user well-being and addressing the accessibility gap in mental health treatments. This paper details TheraGen's architecture, training methodology, ethical considerations, and future directions, contributing to the growing field of AI-assisted mental healthcare and offering a scalable solution to the pressing need for mental health support.", "sections": [{"title": "I. INTRODUCTION", "content": "Mental health issues have become a global concern, affecting millions of individuals and placing a significant strain on healthcare systems worldwide. Despite increased awareness and recognition of the importance of mental health, there remains a substantial gap in the accessibility of timely and effective mental health care. Numerous barriers, including limited availability of mental health professionals, prohibitive costs, and social stigma, prevent many individuals from receiving the essential mental health support they need. According to the World Health Organization, approximately 1 in 8 people globally were living with a mental disorder in 2019, with anxiety and depressive disorders being the most common. The COVID-19 pandemic has further exacerbated this situation, with a 25% increase in the prevalence of anxiety and depression worldwide. Despite this growing need, there is a critical shortage of mental health services, with the WHO reporting that 71% of countries have fewer than two mental health workers per 100,000 population. In recent years, AI-driven mental health support technologies, including chatbots, have shown promise in offering readily accessible assistance. These systems aim to bridge the gap between the demand for mental health support and the limited availability of human professionals. However, existing solutions often face challenges related to scalability, quality of interaction, and user engagement. For instance, while Google's AI for mental health and IBM's Watson Health have made strides in providing accurate healthcare recommendations, they still struggle to deliver responses that are both empathetic and contextually appropriate for mental health support. To address these limitations, we have developed TheraGen, an advanced mental health chatbot that leverages the improved LLaMA 2 7B model. TheraGen is designed to provide personalized, compassionate, and round-the-clock mental health support. Our system is trained on an extensive dataset comprising over 1 million entries, including anonymized therapy transcripts, mental health discussions from online forums, and relevant passages from psychological literature, including resources from the American Psychological Association (APA). TheraGen distinguishes itself from existing solutions through several key features:\n\u2022 Specialized Training: By fine-tuning the LLaMA 2 7B model on a diverse and comprehensive mental health dataset, TheraGen ensures high-quality, contextually relevant responses.\n\u2022 Cloud-based Architecture: TheraGen's seamless integration with cloud services through the Replicate API guarantees high performance and availability, enabling it to handle a large volume of interactions effectively.\n\u2022 24/7 Accessibility: TheraGen provides constant availability, offering support whenever users need it, thereby enhancing the accessibility of mental health assistance.\n\u2022 Ethical Considerations: TheraGen incorporates robust privacy measures and clearly communicates its role as an AI assistant, not a replacement for professional mental health services.\nBy addressing the shortcomings of current alternatives, TheraGen aims to deliver a more accessible, reliable, and empathetic mental health support system. This paper presents a comprehensive overview of TheraGen's development, including its system architecture, dataset preparation, model training process, implementation details, and evaluation results. We also discuss the ethical considerations involved in deploying AI for mental health support and explore future directions for enhancing the system's capabilities. Through TheraGen, we aim to contribute to the growing field of AI-assisted mental healthcare, offering a scalable solution to the pressing need"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "In response to the increasing need for easily accessible mental health care, a number of AI-powered mental health solutions have emerged. These solutions aim to bridge the gap between the high demand for mental health support and the limited availability of human professionals. However, many of these systems face challenges in providing consistently high-quality, empathetic, and contextually appropriate responses."}, {"title": "A. Existing AI Mental Health Solutions", "content": "Several prominent AI systems have been developed to address mental health needs. These systems often leverage state-of-the-art natural language processing techniques [5, 6, 7, 8]. :\n\u2022 Google's AI for Mental Health: While advancing in healthcare recommendations, it faces challenges in providing empathetic, contextually appropriate responses for mental health support.\n\u2022 IBM's Watson Health: Offers accurate medical guidance but struggles with delivering nuanced support tailored to mental health contexts.\n\u2022 Woebot: An AI-powered chatbot designed specifically for mental health support, using cognitive-behavioral therapy (CBT) principles. While innovative, it has limitations in handling complex mental health issues.\n\u2022 Replika: An AI companion app that offers some mental health support features, but struggles with maintaining consistent empathy and handling serious mental health concerns.\nThese systems, while innovative, often fall short in providing the nuanced, empathetic support required for effective mental health care."}, {"title": "B. Specialized Mental Health AI Models", "content": "Recent research has focused on developing AI models specifically for mental health applications:\n\u2022 ZhiXin Model: Presented by Zhao et al. (2023), this improved version of LLaMA is designed for mental disease diagnosis. Trained on approximately 7,000 medical records, it offers high diagnostic accuracy but prioritizes diagnosis over comprehensive, ongoing support.\n\u2022 GPT-3 and Variants: Large language models have shown promise in generating human-like text responses in medical contexts. However, their application in mental health requires careful consideration due to the field's sensitive nature and the need for empathetic, personalized responses."}, {"title": "C. Challenges in AI Mental Health Support", "content": "Several critical challenges have been identified in the development and implementation of AI mental health support systems:\n\u2022 Scalability: Many existing solutions struggle to handle a large volume of interactions effectively, limiting their reach and impact.\n\u2022 Interaction Quality: Maintaining high-quality, empathetic responses over extended interactions remains a significant challenge.\n\u2022 Contextual Understanding: AI systems often lack the nuanced understanding required to provide appropriate responses in varied mental health contexts.\n\u2022 Ethical Considerations: Ensuring user privacy, obtaining informed consent, and managing the limitations of AI in healthcare are paramount concerns (Luxton, 2014).\n\u2022 Integration of Clinical Guidelines: Incorporating established clinical guidelines, such as those from the American Psychological Association (APA), is essential for providing evidence-based support.\nTheraGen aims to be bridge this gap fine-tuning the LLama 2-7b-chat-hf LLM by Meta on a large corpus of conversational therapeutic data, aiming to skew the model towards a more considerate and compassionate chatting experience. Hosting it via API on Replicate addresses the concern of scalability. By not keeping logs and cache from our users, TheraGen aims to keep privacy paramount as well."}, {"title": "D. Recent Advancements", "content": "Recent research has made significant strides in addressing these challenges:\n\u2022 Large Language Models: The development of advanced language models like GPT-3 and LLaMA has greatly improved the potential for more natural and context-aware interactions in mental health support.[4]\n\u2022 Personalization: Fitzpatrick et al. (2017) demonstrated that personalized responses in an AI-based cognitive behavioral therapy bot led to better engagement and outcomes compared to scripted responses.\n\u2022 Ethical Frameworks: Fiske et al. (2019) proposed guidelines for the ethical use of AI in mental health, providing a foundation for responsible development and deployment of these systems.\n\u2022 Cloud Integration: Leveraging cloud services has shown promise in addressing scalability issues and ensuring high availability of AI mental health support systems.\n\u2022 Multimodal Approaches: Some recent systems have begun incorporating multiple data modalities (text, voice, facial expressions) to improve the accuracy of mental health assessments and support (D'Mello et al., 2022).\nBy understanding these existing solutions, challenges, and recent advancements, we can better appreciate the context in which TheraGen has been developed and the specific gaps it aims to address in the field of AI-assisted mental healthcare. TheraGen builds upon these developments and addresses many"}, {"title": "III. LITERATURE REVIEW", "content": "The development of AI-powered mental health chatbots has rapidly evolved over the past decade, driven by advancements in natural language processing (NLP), deep learning, and improved transformer-based models like GPT-3, BERT, and LLaMA. While these technologies hold promise, there remain significant challenges in delivering nuanced, empathetic, and clinically accurate mental health support. This section reviews the existing literature on AI in mental health, focusing on the evolution of chatbots, the challenges they face, and recent innovations that have the potential to improve their efficacy."}, {"title": "A. Early AI Chatbots in Mental Health", "content": "AI chatbots in mental health support initially emerged as rule-based systems, designed to follow predefined pathways. Early examples like ELIZA, developed in the 1960s, mimicked human conversations but were limited in their capacity to offer real, nuanced support. These systems followed rigid scripts, limiting their ability to adapt to individual user needs. Over time, more sophisticated models like IBM's Watson and Google's Al for mental health have leveraged machine learning (ML) to provide more flexible, adaptive responses. However, these solutions still struggled with scalability and the capacity to handle complex emotional responses [11]."}, {"title": "B. Evolution to Transformer-Based Models", "content": "With the advent of transformer-based models, chatbots have grown more sophisticated in their ability to interpret and generate human-like text. Transformers, particularly OpenAI's GPT-3 and Meta's LLaMA models, represent a significant leap forward in natural language understanding and response generation. Studies have shown that GPT-3's large-scale architecture can generate coherent, contextually relevant responses, making it particularly suited for applications like therapy bots [4]. While powerful, large language models like GPT-3 have raised concerns about their reliability in clinical settings, particularly in terms of generating hallucinations or providing responses that may not be ethically or clinically sound. As [3] highlight, AI chatbots must be carefully fine-tuned with domain-specific data to ensure that they provide clinically appropriate advice and avoid exacerbating mental health conditions."}, {"title": "C. Specialized AI Models for Mental Health", "content": "In an attempt to address the challenges of general-purpose Al models, domain-specific models have emerged in recent years. Zhao et al. (2023) introduced the ZhiXin model, which focuses on mental health diagnosis through training on over 7,000 medical records. This model's specificity allows it to excel in diagnostic accuracy, particularly for identifying mental health conditions. However, it has limitations in providing ongoing, compassionate support, as it focuses more on identifying symptoms than on offering therapeutic interventions. Similarly, Woebot, a cognitive-behavioral therapy (CBT) chatbot developed by Stanford psychologists, showed promising results in reducing symptoms of depression and anxiety over a two-week trial period. Fitzpatrick et al. [24] found that Woebot users experienced a significant improvement in mood, but the system's reliance on a rule-based structure limited its ability to engage in deep, reflective conversations. This points to a broader issue in AI chatbot development\u2014while current systems can offer temporary relief, they often lack the emotional depth required for long-term mental health care."}, {"title": "D. Addressing Empathy and Emotional Intelligence in AI", "content": "Empathy, a critical element in therapeutic settings, remains a persistent challenge for AI-based systems. Empathy in AI is not merely about mimicking human conversation patterns but requires an understanding of user emotions and a capacity to respond in a supportive, compassionate manner. [5] explored the challenges in developing emotionally intelligent AI and argued that the lack of emotional awareness in Al systems is one of the biggest barriers to their successful application in mental health. Efforts to address this challenge include fine-tuning language models with emotional context data and incorporating human-in-the-loop (HITL) systems where human experts review and adjust chatbot responses. TheraGen, for instance, builds upon these approaches by training the LLaMA 2 7B model on over one million conversational entries, ensuring that it can provide empathetic and emotionally intelligent responses while maintaining contextually relevant support. By leveraging a diverse set of conversational therapy transcripts and psychological literature, TheraGen aims to surpass earlier models in delivering more human-like interactions."}, {"title": "E. The Role of Personalization in AI Mental Health Support", "content": "Research has consistently shown that personalized interventions lead to better engagement and outcomes in mental health care. Fitzpatrick et al. [24] demonstrated that users of AI-based CBT bots were more likely to report positive outcomes when the chatbot provided responses tailored to their specific needs. The ability of AI systems to adapt their tone, content, and pacing based on user preferences is crucial in maintaining engagement, particularly over extended periods. However, achieving such personalization at scale remains a challenge. While some systems like Replika attempt to provide companionship through personalized conversations, their mental health support features remain rudimentary and often lack the consistency needed for clinical settings. TheraGen addresses this by implementing fine-tuned conversational pathways that adapt in real-time to user inputs, helping the system maintain personalization without losing clinical accuracy."}, {"title": "F. Ethical and Privacy Considerations", "content": "The ethical implications of AI in mental health are a major concern in the field. Martinez-Martin and Kreitmair [26] argue that mental health data is uniquely sensitive, and the use of AI chatbots must adhere to strict privacy protocols to protect user confidentiality. Additionally, users need to be informed about the capabilities and limitations of AI systems, particularly in areas where the technology may fall short of human expertise. TheraGen is designed with these considerations in mind, implementing strong data privacy measures by not storing user conversations and maintaining anonymity. Moreover, it ensures that users are made aware of the system's role as a supportive tool rather than a replacement for professional therapy. By integrating ethical guidelines into the chatbot's architecture, TheraGen aims to offer a more secure and trustworthy platform for users seeking mental health support."}, {"title": "G. Future Directions and Innovations", "content": "While AI chatbots have shown potential in augmenting mental health care, there are clear avenues for improvement. Recent advancements in multimodal Al systems, which combine text-based interactions with other inputs like facial expressions or tone of voice, hold promise for improving the accuracy and empathy of chatbot responses [27]. Further research is needed to explore how these technologies can be integrated into mental health chatbots, potentially leading to more holistic, accurate assessments of user emotions. Moreover, hybrid models that combine AI-driven support with human oversight offer a path forward. These systems could allow for scalable mental health interventions, with AI providing initial support and triaging users to human professionals when necessary. Such an approach could address the scalability issue while ensuring that users with more complex needs receive the appropriate level of care."}, {"title": "IV. SYSTEM ARCHITECTURE", "content": "The architecture of TheraGen is designed in a manner such that it reduces the user's device workload but at the same time provides high quality responses, as illustrated in Fig. 1. It utilizes Replicate as a reliable and scale-able hosting solution for the fine-tuned LLama2 model with a simple website made with Flask for user interaction."}, {"title": "B. Components", "content": "Client Interface: The client interface, shown at the top of Fig. 1, is the front-end of the system through which users interact with the chatbot. This is a web application that users can access from any browser. The client interface is responsible for capturing user inputs, displaying responses, and providing a user-friendly experience.\n\u2022 Flask API Server: As depicted in Fig.1, the Flask API server is the back-end component that handles all incoming requests from the client interface. It routes these requests to the appropriate pre-processing steps and eventually to the model inference component. The server also handles the responses from the model and sends them back to the client interface.\n\u2022 Pre-processing and Post-processing: Pre-processing, which includes text cleaning, tokenization and conversion of user input to suitable format for the"}, {"title": "V. DATASET", "content": "Our study utilized a diverse set of datasets to build a comprehensive training corpus for TheraGen. These datasets were selected based on their relevance to mental health dialogues and their potential to enhance TheraGen's understanding of various mental health issues. The sources include Kaggle, Hugging Face, the American Psychological Association (APA), and web-scraped data from Reddit and Twitter. The combination of these datasets provided a robust foundation for training the model."}, {"title": "A. Sources", "content": "Kaggle and Hugging Face: Hugging Face hosts high-quality conversational datasets suited for NLP tasks. These datasets cover a wide range of mental health issues, relationship problems, and personal challenges. They are categorized into \"questions\" and \"responses,\" which help in training models to generate contextually appropriate replies and understand nuanced mental health conversations. Kaggle and Hugging Face offer a range of datasets pertinent to mental health, including anonymized conversation logs from forums and support groups. These datasets primarily consist of therapeutic dialogues categorized into \"questions\" and \"responses,\" covering topics such as depression, anxiety, stress, and coping mechanisms which helps in training the model. The choice of the datasets used was driven by their extensive coverage of mental health issues and their rich, real-world conversational data.\n2) American Psychological Association (APA): The APA provides authoritative guidelines and best practices in mental health care. The \"APA Clinical Practice Guideline for the Treatment of Depression Across Three Age Cohorts\" and the \"Clinical Practice Guideline for the Treatment of PTSD\" were used to infuse TheraGen with a solid understanding of ethical considerations and treatment protocols. This data helps the model align with established psychological standards and improve its contextual understanding.\n3) Twitter and Reddit: Posts from specific subreddits such as r/depression, r/mentalhealth, r/anxiety, and r/ptsd, as well as tweets, were scraped to capture a wide range of user-generated content related to mental health. This data provides real-world conversational examples and reflects current trends and discussions in mental health.\nBy integrating these diverse datasets, TheraGen benefits from a broad and nuanced understanding of mental health conversations. The datasets cover therapeutic dialogues, real-world interactions, and authoritative guidelines, which collectively enhance the model's ability to generate contextually accurate and empathetic responses. With a training set comprising 1 million conversational entries, including anonymized therapy session transcripts, internet forum discussions, and psychological literature passages, the LLaMA 2 7B model was robustly trained, ensuring effective and contextually aware mental health support."}, {"title": "VI. IMPLEMENTATION", "content": "Effective data preprocessing is crucial for ensuring that the data used to train TheraGen is clean, consistent, and relevant. This section details the preprocessing steps for each data source used in the project."}, {"title": "A. Data Preprocessing", "content": "Kaggle and Hugging Face: Both Kaggle and Hugging Face provide datasets that consist primarily of conversational dialogues categorized into \"questions\" and \"responses.\" The preprocessing steps for these datasets include:\nText Normalization: Text data was converted to lowercase to ensure uniformity. Special characters, such as punctuation marks and emojis, were removed using the nltk and re libraries. This step is essential to standardize the input and avoid inconsistencies during training.\nTokenization: Sentences were split into individual words or tokens using Hugging Face's transformers and nltk libraries. Tokenization helps in breaking down text into manageable pieces and prepares it for the model's input.\nData Anonymization: Custom scripts were employed to identify and mask any personal information, such as user names or sensitive details, to ensure privacy and compliance with data protection regulations.\nFiltering and Cleaning: Incomplete dialogues, irrelevant entries, and spam were filtered out using pandas. This process involved removing any entries that did not meet the quality or relevance criteria, ensuring that only high-quality conversational data was used for training.\nAmerican Psychological Association (APA): The APA datasets provide authoritative guidelines and clinical practice standards. The preprocessing steps for this data involve:\nText Extraction: Relevant text was extracted from PDF documents using the PyMuPDF library. This process involved parsing the documents to identify and extract sections related to mental health treatment.\nText Normalization: Extracted text was converted to lowercase, and special characters were removed to maintain consistency across the dataset. This step was critical for ensuring that the data was uniformly formatted.\nTokenization: Text was split into individual words or tokens to create structured input data for the model. This step facilitated the model's ability to process and understand the content effectively.\nData Anonymization: Any potentially identifying information was removed or masked to protect privacy. This was done using custom scripts to ensure compliance with ethical standards.\nFiltering and Cleaning: Only the sections of the guidelines directly related to mental health treatment were retained. This focused the dataset on relevant content, improving the model's understanding of clinical practices."}, {"title": "3) Twitter and Reddit:", "content": "Data from Twitter and Reddit includes posts and comments related to mental health. The preprocessing steps for this data are:\n\u2022 Subreddit and Tweet Selection: Specific subreddits and Twitter hashtags related to mental health were targeted to gather relevant content. This ensured that the data collected was pertinent to the mental health domain.\n\u2022 Scraping Tools: Data was collected using PRAW (Python Reddit API Wrapper) for Reddit and Tweepy for Twitter. These tools facilitated efficient data extraction from the respective platforms.\n\u2022 Data Extraction: Posts, comments, and replies were extracted to capture a wide range of user-generated content. This process involved fetching conversation threads and individual entries to create a comprehensive dataset.\n\u2022 Text Normalization: Text data was converted to lowercase, and special characters were removed using nltk and re libraries. This standardization step was crucial for maintaining consistency across the dataset.\n\u2022 Tokenization: Sentences were split into words to create structured input for the model. This step ensured that the text was in a format that the model could process effectively.\n\u2022 Data Anonymization: Sensitive information, such as personal identifiers, was masked to ensure user privacy. This was achieved using custom scripts designed to handle privacy concerns.\n\u2022 Filtering and Cleaning: Non-text content, such as URLS and media files, and irrelevant data were removed. Proper sentence structures were ensured to maintain the quality and relevance of the dataset."}, {"title": "B. Ethical Considerations", "content": "Ethical considerations in AI and large language models (LLMs) are essential because these systems have a profound impact on individuals and society. As AI technologies increasingly influence various aspects of daily life, they must be designed to protect user rights and ensure that interactions are respectful and responsible. Ethical guidelines help prevent misuse of personal data, maintain transparency about the nature of the AI, safeguard users from potential harm, ensure that AI complements rather than replaces human expertise, and address biases to promote fairness. These measures are crucial for maintaining trust, protecting well-being, and ensuring equitable and respectful treatment.\n\u2022 Privacy and Data Protection: TheraGen does not require user logins and does not retain personal data, ensuring user interactions remain anonymous and confidential.\n\u2022 Transparency: TheraGen clearly informs users that they are interacting with an AI, detailing its role and limitations to set accurate expectations and encourage seeking professional help when necessary.\n\u2022 Non-maleficence: TheraGen incorporates content filtering to prevent harmful responses and provides trigger warnings for sensitive topics to minimize potential distress.\n\u2022 Complementary Role: TheraGen is designed to support, not replace, professional mental health services, emphasizing the importance of consulting human therapists for comprehensive care.\n\u2022 Bias Mitigation: TheraGen utilizes diverse training data and undergoes regular bias audits to ensure fair and unbiased responses, promoting inclusive treatment of all users."}, {"title": "C. Model Selection and Fine-tuning", "content": "The LLaMA 2 7B model, specifically tailored for mental health interactions, forms the foundation of TheraGen. The implementation process involved several crucial steps:\n1) Data Preparation: We meticulously curated a dataset of over 1 million conversational entries, including:\n\u2022 700,000 anonymized therapy session transcripts from Kaggle and Hugging Face\n\u2022 100,000 mental health-related posts and comments from Reddit (r/depression, r/anxiety, r/mentalhealth)\n\u2022 10,000 tweets containing mental health hashtags (#mentalhealth, #therapy, #depression)\n\u2022 numerous excerpts from APA literature and clinical guidelines\nData preprocessing involved:\n\u2022 Removal of personally identifiable information using custom regex patterns\n\u2022 Text normalization using NLTK, converting to lowercase and removing special characters\n\u2022 Tokenization using the LLaMA 2 tokenizer, with a maximum sequence length of 512 tokens\n\u2022 Filtering out low-quality entries (e.g., those with less than 10 words or containing offensive language)\n2) Model Initialization: We utilized the Hugging Face Transformers library (version 4.28.1) to initialize the LLaMA 2 7B model. This approach leverages recent developments in transfer learning for NLP tasks [10]. Specifically, we used the 'meta-llama/Llama-2-7b-chat-hf' checkpoint as our starting point.\n3) Fine-tuning Configuration: We configured the training arguments using the TrainingArguments class from Transformers. Key hyperparameters included:\nBatch size: 32 (effective batch size of 128 with gradient accumulation)\nLearning rate: 2e-5 with a linear decay schedule\nNumber of epochs: 3\nWarmup steps: 500\nWeight decay: 0.01\nGradient accumulation steps: 4\nFP16 mixed precision training: Enabled\nGradient clipping: 1.0"}, {"title": "4) Fine-tuning Process:", "content": "We employed the Trainer class from the Transformers library for fine-tuning. The process involved:\nUsing a custom DataCollator to handle dynamic padding and create attention masks\nImplementing a custom loss function that combined cross-entropy loss with a regularization term to encourage empathetic responses\nUtilizing the PEFT (Parameter-Efficient Fine-Tuning) library to implement LoRA (Low-Rank Adaptation) with a rank of 8 and alpha of 32, reducing memory requirements and training time"}, {"title": "D. Training Approach", "content": "The training approach for TheraGen incorporated several advanced techniques:\n1) Transfer Learning: We leveraged the pre-trained LLaMA 2 7B Chat model, which already possessed general language understanding. Our transfer learning approach involved:\n\u2022 Freezing the first 24 layers of the model\n\u2022 Fine-tuning only the last 8 layers and the language modeling head\n\u2022 Gradually unfreezing layers during training, starting with 2 epochs of training the last 8 layers, then 1 epoch with the last 16 layers unfrozen\n2) Fine-Tuning with Custom Data: The fine-tuning process on our mental health dataset involved:\n3 total epochs of training\nA dynamic learning rate schedule: starting at 2e-5, linearly increasing to 5e-5 over 1000 steps, then linearly decaying to le-6\nMonitoring perplexity on a validation set (10% of the data) after every 5000 steps\nEarly stopping with a patience of 3 evaluation rounds if perplexity didn't improve\n3) Hyperparameter Optimization: We conducted a thorough hyperparameter search using Optuna, evaluating 100 trials. The search space included:\n\u2022 Learning rates: [1e-5, 5e-5]\nBatch sizes: [16, 32, 64]\nDropout rates: [0.1, 0.2, 0.3]\nWeight decay: [0.01, 0.1]\nThe optimal configuration was determined based on the lowest perplexity on the validation set.\n4) Gradient Accumulation: To manage memory limitations on our 2 NVIDIA A100 GPUs, we employed gradient accumulation with 4 steps. We used the Adam optimizer [14] for efficient stochastic optimization. This allowed us to effectively train with a batch size of 128 while only requiring memory for 32 examples at a time.\n5) Mixed Precision Training: We utilized mixed precision training with PyTorch's AMP (Automatic Mixed Precision) module. This involved:\n\u2022 Using float16 for forward and backward passes"}, {"title": "6) Regularization Techniques:", "content": "To prevent overfitting and improve generalization, we applied:\nDropout with a rate of 0.1 on attention layers and feed-forward networks\nWeight decay of 0.01 applied to all non-bias parameters\nLabel smoothing with a factor of 0.1 to prevent overconfident predictions\nGradient clipping with a maximum norm of 1.0 to stabilize training"}, {"title": "E. Evaluation and Validation", "content": "Evaluation Metrics: We used metrics such as Coherence, BLEU score, and ROUGE score to evaluate the model's performance. These metrics provided insights into the model's ability to generate coherent and contextually appropriate responses.\nValidation Set: A portion of the dataset was set aside as a validation set to monitor the model's performance during training. Early stopping was employed to prevent overfitting, ensuring that the model maintained high performance on unseen data.\nCross-Validation: Cross-validation was performed to ensure the robustness of the model's performance across different subsets of the data. This technique helped verify that the model's performance was consistent and reliable."}, {"title": "VII. EVALUATION AND RESULTS", "content": "TheraGen's performance was evaluated using various metrics, including:\nUser Satisfaction: Human evaluation and field surveys showed satisfactory response to the outputs given by TheraGen.\nResponse Accuracy:\nHuman and expert evaluation returned positive results, with 87% of responses deemed appropriate and accurate.\nBLEU score: The Bilingual Evaluation Understudy (BLEU) score is a widely used metric for evaluating the quality of machine-generated text by comparing it to one or more reference texts. It primarily"}, {"title": "Coherence =", "content": "Coherence = \\frac{1}{n-1} \\sum_{i=1}^{n-1} cos(S_i, S_{i+1})  (2)\nwhere $s_i$ and $s_{i+1}$ are vector representations of consecutive sentences.\nResponse Diversity: Distinct-1 and Distinct-2 scores of 0.82 and 0.76 respectively, indicating a good balance between consistency and variety in responses. These scores are calculated as:"}, {"title": "Distinct-n =", "content": "Distinct-n = \\frac{|\\{gram_n\\}|}{|\\{gram_n\\}_{total}|}  (3)\nwhere $|\\{gram_n\\}|$ is the number of distinct n-grams and $|\\{gram_n\\}_{total}|$ is the total number of n-grams in the generated responses."}, {"title": "VIII. TEST CASES", "content": "The following test cases show the various responses of TheraGen to varied questions:"}, {"title": "A. Test Case 1: User Introduction Interaction", "content": "This test evaluates the chatbot's ability to handle greetings using basic natural language understanding, which is powered by the fine-tuned LLaMA 2 model. A successful greeting establishes user engagement and sets a conversational tone."}, {"title": "B. Test Case 2: Empathetic Response to Common Mental Health Query", "content": "This test examines the chatbot's ability to generate empathetic and contextually relevant responses through fine-tuned training on APA and online mental health discussion datasets. Transfer learning techniques enable the model to recognize common mental health issues such as anxiety and depression."}, {"title": "C. Test Case 3: Complex Emotional Input", "content": "This test assesses the model's ability to handle complex, sensitive emotional scenarios. Fine-tuned on therapy conversation datasets, the chatbot uses contextual inference to respond with emotional intelligence and offer supportive advice."}, {"title": "D. Test Case 4: Providing External Resources", "content": "This test checks the chatbot's capability to offer evidence-based external resources by leveraging APA-guided therapeutic practices embedded in the dataset. The responses ensure consistency with professional mental health protocols."}, {"title": "E. Test Case 5: Culturally Sensitive Query", "content": "This test evaluates the chatbot's ability to provide culturally appropriate responses. The fine-tuning of data from diverse real-world conversations allows the system to cater to culturally nuanced or specific mental health concerns."}, {"title": "IX. USER FEEDBACK", "content": "User feedback is a critical measure of TheraGen's effectiveness", "Satisfaction": "User satisfaction is a primary metric for assessing how well TheraGen meets the needs and expectations of its users. High satisfaction levels are indicative of the system's success in providing meaningful mental health support.\nFeedback Summary: A large-scale survey conducted with 600 users across different demographics revealed a high satisfaction rate", "very satisfied\" or \"satisfied.\"\nDemographic Insights": "Satisfaction was highest among younger users (aged 18-30)", "Accuracy": "nAccurate and contextually relevant responses are crucial for building trust and ensuring that users receive reliable information. The accuracy of responses directly impacts users' confidence in the system's ability to provide appropriate support.\nFeedback Summary: TheraGen's performance was evaluated using industry-standard metrics such as BLEU and ROUGE scores. The system achieved a BLEU score of 0.67", "Evaluation": "In addition to automated metrics", "contextually appropriate\" and \"coherent,\" highlighting its robustness in handling diverse mental health scenarios.\nResponse Time": "nThe speed of response is a vital factor in maintaining user engagement and providing timely support", "Summary": "TheraGen recorded an average response time of 1395ms, which was well within acceptable limits for real-time interaction. 95% of users found the response time satisfactory, noting that"}]}