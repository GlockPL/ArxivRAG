[{"title": "ROBUST BARYCENTER ESTIMATION USING\nSEMI-UNBALANCED NEURAL OPTIMAL TRANSPORT", "authors": ["Milena Gazdieva", "Alexander Kolesov", "Petr Mokrov", "Jaemoo Choi", "Jaewoong Choi", "Alexander Korotin"], "abstract": "A common challenge in aggregating data from multiple sources can be formalized\nas an Optimal Transport (OT) barycenter problem, which seeks to compute the\naverage of probability distributions with respect to OT discrepancies. However,\nthe presence of outliers and noise in the data measures can significantly hinder the\nperformance of traditional statistical methods for estimating OT barycenters. To\naddress this issue, we propose a novel, scalable approach for estimating the robust\ncontinuous barycenter, leveraging the dual formulation of the (semi-)unbalanced\nOT problem. To the best of our knowledge, this paper is the first attempt to\ndevelop an algorithm for robust barycenters under the continuous distribution setup.\nOur method is framed as a min-max optimization problem and is adaptable to\ngeneral cost function. We rigorously establish the theoretical underpinnings of the\nproposed method and demonstrate its robustness to outliers and class imbalance\nthrough a number of illustrative experiments.", "sections": [{"title": "1 INTRODUCTION", "content": "The world is full of data, and accurate analysis of this data allows for solving a number of problems in\nthe world related to science, medicine, engineering, etc. A common challenge in data analysis arises\nfrom two factors: (i) a huge quantity of data, and (ii) the data originating from multiple sources, such\nas different scientific experiments, hospitals, or engineering trials. One promising way to address\nthese difficulties is to perform data aggregation. This means reducing the particular source-specific\ncharacteristics and leaving only source-agnostic information for solving a practical case on hand.\nRecently, a fruitful branch of research (Li et al., 2020; Fan et al., 2021; Korotin et al., 2022; Kolesov\net al., 2024a;b) has emerged that focuses on addressing the challenge of data aggregation through\nthe framework of the Optimal Transport (OT) barycenter problem. Given a number of reference\ndistributions representing data from different sources, the problem is to discover a geometrically\nmeaningful average of these distributions by minimizing the average OT costs from the reference\ndistributions to the desired one."}, {"title": "2 BACKGROUND", "content": "In this section, we give an overview of the theoretical concepts related to our paper. In \u00a72.1, we state\nthe SUOT problems and its semi-dual formulation. In \u00a72.2, we formulate the OT/UOT barycenter\nproblem. Then, in \u00a72.3, we describe our computational setup. For details on OT, we refer to\n(Santambrogio, 2015; Villani et al., 2009; Peyr\u00e9 et al., 2019), unbalanced OT - (Chizat, 2017; Liero\net al., 2018; S\u00e9journ\u00e9 et al., 2022), OT barycenters - (Agueh & Carlier, 2011; Chizat, 2023).\nTo begin with, we introduce the concept of 4-divergences needed for our further derivations.\n-divergences for positive measures. Let \u03bc1, \u03bc2 \u2208 M+(X') be two positive measures. Then, for a\nfunction : R+ \u2192 R+ U {\u221e}, the \u03c8-divergence between \u00b5\u2081, \u03bc2 is given by:\n$D_\\psi (\\mu_1 ||\\mu_2) \\stackrel{\\text{def}}{=} \\int_X \\psi \\left(\\frac{d\\mu_1(x)}{d\\mu_2(x)}\\right) d\\mu_2(x).$\nHere the generator function \u03c8(t) is assumed to be convex, non-negative, lower semi-continuous and\nattain zero uniquely when t = 1. Note that \u03c8(t) is non-decreasing since function \u03c8(t) is non-negative\n(Choi et al., 2024a). Under these assumptions, D\u03c8 is a valid measure of dissimilarity between two\npositive measures. Well known examples of such \u03c8-divergences include Kullback-Leibler divergence\nDKL (Chizat, 2017; S\u00e9journ\u00e9 et al., 2022) and \u03c7\u00b2-divergence D\u03c72. For the extended discussion on\nadmissible divergences, we refer to (Gazdieva et al., 2023a, Appendix C)."}, {"title": "2.1 OPTIMAL TRANSPORT", "content": "Classic OT problem. Consider two probability measures P\u2208P(X), Q\u2208P(V) and the cost function\nc(x, y) \u2208 C(X \u00d7 Y). Then the OT problem (Kantorovich, 1942) between IP and Q is given by\n$OT(P, Q) \\stackrel{\\text{def}}{=} \\inf_{\\pi\\in\\Pi(P,Q)} \\int_{X\\times Y} c(x, y)\\pi(x, y)dxdy.$\nUnder the mild assumptions on the distributions P, Q and cost function c, the minimizer \u03c0* of (1)\nalways exists but is not guaranteed to be unique, see (Villani et al., 2009). In the special case of the\nquadratic cost c(x, y) = ||x-y||\u00b2, problem (1) reduces to the well-known (squared) Wasserstein-2\ndistance (W2(P, Q)). Problem (1) admits a semi-dual reformulation:\n$OT(P, Q) = \\sup_{f\\in C(Y)} {\\int_X f^c(x)dP(x) + \\int_Y f(y)dQ(y)},$\nwhere $f^c(x) \\stackrel{\\text{def}}{=} \\inf_{\\mu\\in\\mathcal{P}(Y)} \\int_Y (c(x,y) - f(y))d\\mu(y)$ is the c-transform. Note that the standard\nc-transform in the OT duality is usually defined as $f^c(x) = \\inf_{y\\in Y}{c(x, y) - f(y)}$. Here, for the\nfuture needs, we substitute the classic c-transform by the weak c-transform (Backhoff-Veraguas et al.,\n2019, Theorem 1.3), (Gozlan et al., 2017). This transition is valid since we work the infimum in weak\ntransform is anyway attained at any \u03bc\u2208 P(V) supported on the arg $\\inf_{y\\in Y}{c(x, y) - f(y)}$ set.\nUnbalanced & semi-unbalanced OT problems. The standard formulation of the OT problem entails\nvarious issues (Balaji et al., 2020; S\u00e9journ\u00e9 et al., 2022), such as sensitivity to outliers, inability to\ndeal with class imbalance in the source and target measures and inapplicability to positive measures.\nStill, we consider the mass transportation between probability measures and focus on the first two\nissues. Fortunately, they can be overcome by relaxing the hard marginal constraints of the OT problem\nwhich yields the Unbalanced OT (Chizat, 2017; Liero et al., 2018, UOT) problem. Formally, the\nUOT problem between the probability measures P\u2208P(X), Q\u2208P(V) is\n$UOT_{c,\\psi,\\phi}(P,Q) = \\inf_{\\gamma\\in\\mathcal{M}_+(X\\times Y)} \\int_{X\\times Y} c(x, y)\\gamma(x, y)dxdy + D_\\psi(\\gamma_x||P) + D_\\phi(\\gamma_y||Q)$\nwhere c(x, y) \u2208 C(X \u00d7 V) is a continuous cost function and Dy, D\u03c6 are \u03c8-divergences over X and\nY respectively. Note that the classic OT problem (1) is a particular instance of the UOT problem (3)\nwhen the V-divergences Dy, D\u00f8 satisfy Dy' (P', Q') = 0 if P' = Q', and +\u221e otherwise. Equivalently,\nit means that the generator functions \u03c8, & are the convex indicators of {1} and their conjugates are\ndefined as \u03c8(t) = f(t) = t. We can tune the degree of penalizing the marginal distributions mismatch\nby introducing the unbalancedness parameter \u03c4 > 0 and considering D\u03c8' = \u03c4D\u03c8, D\u00a2' = TD\u03c6\u00b7\nInformally, when + \u2192 +\u221e, the corresponding UOT problem tends to classic OT (1).\nIn this paper, we focus on the semi-unbalanced OT (SUOT) problem, i.e., the case when only the first\nmarginal constraint in the OT problem (1) is softened:\n$SUOT_{c,\\psi}(P, Q) = \\inf_{\\gamma\\in\\Pi(Q)} \\int_{X\\times Y} c(x, y)\\gamma(x, y)dxdy + D_\\psi(\\gamma_x||P).$\nNote that the minimizer \u03b3* of (4) always exists thanks to the compactness of the space X \u00d7 Y\n(yielding the compactness of II(Q)), continuity of the cost function c(x, y) and lower semi-continuity\nof the function 4 (yielding the lower-semi-continuity of the optimized functional w.r.t. \u03b3).\nThe semi-dual SUOT problem is given by\n$SUOT_{c,\\psi}(P,Q) = \\sup_{f\\in C(Y)} {\\int_X \\psi^*(-f^c(x)dP(x) + \\int_Y f(y)dQ(y)}.$\nNote that when f(t) = t, we get dual problem (2) for balanced OT problem (1)."}, {"title": "2.2 (SEMI-)UNBALANCED OPTIMAL TRANSPORT BARYCENTER", "content": "Consider probability measures Pk \u2208 P(Xk) and continuous cost functions ck (x, y) : Xk \u00d7 Y \u2192 R,\nk\u2208 K. Given wights > \u2265 0 s.t. \u03a3\u03ba=1 >k = 1, the classic OT barycenter problem consists in\nfinding a minimizer of the sum of OT problems with fixed first marginals P[1:K]:"}, {"title": "2.3 COMPUTATIONAL SETUP", "content": "In a real-world scenario, the distributions Pk are not available explicitly and can be assessed only via\nempirical samples. Assume that we are given Nk empirical samples x[k1:N] ~ Pk, k \u2208 K. Our goal\nis to find approximations \u017fk of the SUOT plans between the measures Pk and unknown SUOT\nbarycenter Q* for the given cost functions and 4-divergences ck, \u03c8k, k \u2208 K. After that, we can\nuse the learned plans to perform the conditional sampling, i.e., derive new points y ~ \u221ak(\u00b7|xk) from\nthe (approximate) barycenter taking samples xk ~ (k) x as inputs. Actually, sampling from the left\nmarginals of the learned plans is not an easy task since the marginal can not be easily assessed using\nthe learned plans or potentials. Fortunately, we can deal with this issue using the rejection sampling\nprocedure (Forsythe, 1972), see our \u00a74.2 for the additional details.\nIt is important to note that the learned plans should admit the new input samples, i.e., not necessarily\npresent in the training datasets. This setup is typically called continuous (Li et al., 2020; Kolesov\net al., 2024a; Korotin et al., 2022) and significantly differs from the discrete one (Peyr\u00e9 et al., 2019;\nCuturi & Doucet, 2014). The latter is aimed at solving the barycenter problem between the empirical\nmeasures which makes the application to new data samples challenging."}, {"title": "3 RELATED WORKS", "content": "The first subsection below is devoted to continuous OT solvers with a specific focus on unbalanced\nsetup. In turn, the second subsection covers the most relevant OT barycenter solvers.\nNeural OT/UOT solvers. Neural network-based continuous OT is a popular and fruitful area of\nrecent generative modelling research. Some keynote solvers include: (Makkuva et al., 2020; Korotin\net al., 2021a; Amos, 2023) (ICNN-based, quadratic cost); (Seguy et al., 2018; Daniels et al., 2021;\nMokrov et al., 2024) (Entropic OT); (Vargas et al., 2021; De Bortoli et al., 2021; Gushchin et al.,\n2023; Tong et al., 2023; Shi et al., 2024; Gushchin et al., 2024) (Schr\u00f6dinger bridge); (Liu et al., 2023;\nTong et al., 2024; Kornilov et al., 2024; Klein et al., 2024) (Flow matching). Of special importance for\nour developed method are max-min (adversarial) OT solvers based on (semi-) dual OT formulation\n(Rout et al., 2022; Korotin et al., 2023b;a; Fan et al., 2023). Recently, the adversarial methodology\nhas been extended to unbalanced setup (Choi et al., 2024a; Gazdieva et al., 2023b; Choi et al., 2024b),\nopening up a new intriguing research direction in the field of robust continuous OT.\nOT Barycenter Methods. Below, we start with a brief overview of continuous OT barycenter solvers\nand then proceed to the current state of robust (unbalanced) barycenter research. The continuous\nOT barycenter methods could be categorized as follows: (Fan et al., 2021; Korotin et al., 2021b)"}, {"title": "4 PROPOSED METHOD", "content": "In \u00a74.1, we derive and investigate our novel optimization objective for learning SUOT barycenters.\nIn \u00a74.2, we propose the algorithm to solve this problem. The proofs for all theoretical results are\ngiven in Appendix A."}, {"title": "4.1 DERIVING THE OPTIMIZATION OBJECTIVE", "content": "To develop a procedure for estimating the barycenter, one may simply substitute the dual form of\nSUOT problem (5) in the barycenter problem (7) and get a min-max problem. Actually, without\nadditional modifications, it will lead to the min-max-min problem since the c-transforms fk also\nneed to be optimized. In our Theorem 1 below, we present the way for solving the optimization\nproblem (7) in max-min manner and without the optimization over distributions Q \u2208 P(Y).\nTheorem 1 (Semi-dual form of SUOT barycenter problem). The dual form of SUOT barycenter\nproblem (7) is given by\n$L^* = \\sup_{\\substack{m\\in\\mathbb{R}, f\\[1:K] \\in C^K(\\mathcal{V}) \\\\\n\\sum_{k=1}^K \\lambda_k f_k=m}} \\sum_k [\\int_{X_k} \\Psi_k(-f_k^c(x_k))dP_k(x_k) + m].$\nThis Theorem shows that if potentials f[1:K] satisfy the m-congruence condition $\\sum_{k=1}^K \\lambda_k f_k = m$\n(for some $m\\in \\mathbb{R}$) then the optimal value of the SUOT barycenter problem (4) can be derived\nby solving (8). Substituting the definition of the c-transform in (8), we get our final optimization\nobjective.\nCorollary 1 (Maximin reformulation for the semi-dual problem (8)). It holds:\n$L^* = \\sup_{\\substack{m\\in\\mathbb{R}, \\gamma(x_k)\\in\\mathcal{P}(Y) \\\\\nf\\[1:K] \\in C^K(\\mathcal{V}) \\\\\n\\sum_{k=1}^K \\lambda_k f_k=m}} \\sum_k \\lambda_k \\int_{X_k} {-\\Psi_k(\\int_{\\mathcal{X}}  (\\mathcal{C}_k(x_k, y) - f_k(y))d\\gamma_k(y|x_k))}dP_k(x_k)+m \\stackrel{\\mathcal{L}}{=} \\sum(f\\[1:K], {\\gamma_k(\\cdot|x_k)}\\[1:K],m)$\nwhere the sup is taken over potentials f[1:K] \u2208 CK (V) and inf over conditional plans yk(\u00b7|xk).\nInterestingly, in the special case when at least one of the SUOTck,\u03c8k terms in the right-hand-\nside of (7) reduces into OTc1, the m-congruence condition in (9) turns into congruence condition\n\u03a3\u03ba=1kfk = 0 which typically appears in balanced settings (Kolesov et al., 2024a;b).\nCorollary 2 (Congruence Condition of the Special SUOT barycenter problem). Suppose that 1(t) =\nt, i.e., SUOTc1,41 = OTc\u2081 in (7). Then, dual form (9) turns into the following dual formulation:\n$L^* = \\sup_{\\substack{\nf\\[1:K] \\in C^K(\\mathcal{V}) \\\\\n\\sum_{k=1}^K \\lambda_k f_k=0}} \\sum_k \\lambda_k \\inf_{\\gamma(x_k)\\in\\mathcal{P}(Y)} \\int_{X_k} {-\\Psi_k(\\int_{\\mathcal{X}} (\\mathcal{C}_k(x_k, y) - f_k(y)) d\\gamma_k(y|x_k))}dP_k(x_k).$"}, {"title": "4.2 PARAMETRIZATION AND PRACTICAL OPTIMIZATION PROCEDURE", "content": "Parametrization. To implement the optimization over distributions \u03b3(\u00b7|xk) \u2208 P(Y) (k \u2208 K) in (9),\nwe consider parametrizing them with stochastic or deterministic functions, using the strategy defined\nin (Kolesov et al., 2024a, \u00a74.1) and (Korotin et al., 2023a, \u00a74.1).\nTo realize the optimization over conditional plans Yk (xk) in (9), we define an auxiliary space\nS\u2208 RD, atomless distribution S \u2208 P(S) and measurable maps Tk: Xk \u00d7 S \u2192 Y. For every plan\nYk, we consider the representation using the map Tk s.t. \u03b3\u03ba(\u00b7|x) = Tk (x,\u00b7)#S. Using the stochastic\nparametrization of the conditional plans, we can reformulate the optimization objective (9) as:\n$L^* = \\sup_{\\substack{\nm\\in\\mathbb{R}, \\mathcal{T}\\[1:K] \\\\\nf\\[1:K] \\in C^K(\\mathcal{V}) \\\\\n\\sum_{k=1}^K \\lambda_k f_k=m}} \\sum_k \\lambda_k \\int_{X_k} {-\\mathcal{J} (\\mathcal{T}_k(x_k, s)) - c(x_k,\\mathcal{T}_k(x_k, s))\\}} dS(s) dP(x_k)+m.$\nWe denote the expression under sup inf in (13) as L(f[1:K], T[1:K], m). In some of the setups, the\nstochasticity of the conditional plans y(\u00b7|x) is not needed. Then we can consider a measurable map\nTk: Xk \u2192 Y which specifies the deterministic conditional plans as k(\u00b7|x) = \u03b4\u03c4\u03ba(x)(\u00b7).\nFor solving (13), we parametrize the maps Tk and potentials fk (k \u2208 K) as neural networks\nTk,w:RDk \u00d7 RDs \u2192 RD and fk,9 :RDk \u2192 R with weights w W[1:K] \u2208 \u03a9, \u03b8 def 0[1:K] \u2208 \u0398. Here\n\u03a9 = \u03a91 \u00d7 22 \u00d7 ... \u00d7 \u03a9\u03ba and O = 01 \u00d7 2 \u00d7 \u00d7 OK are the parameter spaces for the maps and\npotentials respectively. Note that RD denotes the stochastic dimension which should be omitted in\nthe case of deterministic maps. In order to ensure the m-congruence condition for the potentials, we\nparametrize them as fk,0 = 9k,0 - n\u2260k (K-1)9n,0 + where gk,e denote the auxiliary neural\nnets. Here we take inspiration from similar strategies in (Li et al., 2020; Kolesov et al., 2024b;a).\nTraining. Recall that we work in a continuous setup of barycenter problem, i.e., the distributions\nP[1:K] are accessible only through the empirical samples of data. Thus, we opt to estimate the\nobjective (13) from samples using the Monte-Carlo method. Specifically, the objective is opti-\nmized using stochastic gradient descent-ascent algorithm over random batches of samples from\nthe distributions Pk and auxiliary distribution S\u00b9. For simplicity, we replace the minimization of\nthe objective L(fe,[1:K], \u03a4\u03c9,[1:K]) w.r.t. \u03a4\u03c9,[1:K] with the direct minimization of the c-transform"}, {"title": "5 EXPERIMENTS", "content": "In this section, we evaluate our model through various experiments. In \u00a75.1, we compare the numerical\naccuracy of our method against baseline methods. In \u00a75.2, we investigate two key properties of our\nU-NOTB method: robustness to class imbalance and robustness to outliers. Specifically, we show\nthat these properties can be controlled by adjusting the unbalanced parameter 7. In \u00a75.3, we evaluate\nour model for the general costs, leveraging shape and color-invariant cost on the image dataset, other\nthan the quadratic cost. We provide the details about settings and baselines in Appendix B."}, {"title": "5.1 BARYCENTER EVALUATION ON SYNTHETIC DATASETS", "content": "Baselines. We aim to evaluate whether our model accurately estimates the optimal barycenter Q\nand the corresponding transport maps T[1:K]. Because our work is the first attempt to address the\ncontinuous SUOT barycenters, there are no existing baselines for direct comparison. Therefore, we\ncarefully designed two baseline models for comparison with our approach. These baseline models\nare motivated by the equivalence between the OT barycenter of two distributions and the interpolation\nbetween them (Villani et al., 2009). Each baseline model is derived from two approaches for learning\nthe unbalanced transport map Tuot between P1 and P2: (i) the semi-dual UOT model (UOTM) (Choi\net al., 2024a) and (ii) the OT Map model (OTM) (Rout et al., 2022) combined with the mini-batch"}, {"title": "5.2 ROBUST BARYCENTER ESTIMATION UNDER OUTLIER AND CLASS IMBALANCE", "content": "In this section, we examine two key properties of our U-NOTB model: (i) robustness to class\nimbalancedness and (ii) robustness to outliers. The value of OT functional OT(\u00b7,\u00b7) is known to\nbe sensitive to outliers and class imbalance problems. Hence, the OT barycenter is also largely\naffected by these factors. To address this sensitivity, the UOT problem extends the traditional OT\nproblem by relaxing the constraint on marginal densities. This relaxation introduces two notable\ncharacteristics. First, even in the presence of class imbalances, the reweighting process allows the\nmodel to appropriately align with the relevant modes in a reasonable manner (Eyring et al., 2024).\nSecond, the model exhibits robustness to outliers, maintaining reliable transport despite their presence\n(Balaji et al., 2020; Choi et al., 2024a). The goal of this section is twofold: (1) to investigate whether\nthese two properties are also observed in our U-NOTB model by comparing it with the OT counterpart"}, {"title": "5.3 SHAPE-COLOR EXPERIMENT", "content": "In this section, we illustrate one interesting example demonstrating how the UOT barycenter problem\ncan be applied using a general cost. We designed the problem at general costs when there are some\nundesirable outliers in the marginal distributions.\n\u2022 Shape distribution P1. The first marginal distribution consists of grayscaled images of digits '2'\n(49% of training dataset), '3' (50%) and '7'(1% - outliers) of MNIST data.\n\u2022 Color distribution P2. The second marginal distribution consists of three color points: red\n(probability mass po = 0.495), green (p1 = 0.495), white (p2 = 0.01 - outliers).\n\u2022 Manifold. We pretrained the StyleGAN Karras et al. (2019) generator G : Z \u2192 R3\u00d732\u00d732 on the\ncolored MNIST dataset of digits '2' and '3'. Let E be the network which encodes each marginal\nPi to the latent Z. Throughout the experiment, we transport xi ~ Pi to the barycenter point yi by\nyi=GE(xi), thus confining the transformed images to the colored MNIST of digits '2' and '3'.\n\u2022 General Transport costs. For the first marginal sample x1 ~ P\u2081 and its corresponding barycenter\npoint y1, we use the following shape-preserving cost: c1(X1,Y1) = ||x1 - Hg(y1)||2, where Hg is\na decolorization operator. Moreover, for the second marginal sample x2 ~ P2 and the corresponding\nbarycenter point y2, we use the following color-preserving cost: C2(X2,Y2) = ||x2 - Hc(y2)||2,\nwhere He is a color projection operator defined in Kolesov et al. (2024a)."}, {"title": "6 DISCUSSION", "content": "Our work continues the recent and fruitful branch of OT barycenter research. We present the first\nattempt to build robust OT barycenters under continuous setup based on unbalanced OT formulation.\nFrom now on, the barycenter researchers have a new deep learning tool at their disposal that gives\nthem the ability to deal with imperfect data (with outliers/noise/class imbalance) at a large scale. We\nbelieve that our proposed method will further expand the toolbox of deep learning practitioners.\nLimitations. In practice, we found that the practical optimization procedure (Algorithm 1) may work\nunstably. In particular, the training may diverge under improper hyper-parameters selection or the\nresulting quality might depend on the random seed. We hypothesise that this behaviour is due to\nthe reliance on adversarial training and leave its thorough investigation to future research. From the\ntheoretical side, the recovered semi-unbalanced OT barycenter is not guaranteed to be unique (\u00a72.2);\nalso, the convergence properties of our procedure (13) are not established. All these questions pave\nthe way for further research.\nCode of Ethics. This paper presents work whose goal is to advance the field of Machine Learn-\ning. There are many potential societal consequences of our work, none of which we feel must be\nspecifically highlighted here."}, {"title": "A PROOFS", "content": ""}, {"title": "A.1 PROOF OF THEOREM 1 AND COROLLARY 1", "content": "Proof of Theorem 1. Substituting the dual form (5) into (13)", "n$F(Q,f\\[1": "K", "f[1": "K", "in\nf[1": "K", "15)": "n$\\mathcal{L"}, "sup_{f_1,..., f_k \\in C(V)} \\min_{Q\\in \\mathcal{P}(Y)} \\sum_{k=1}^K \\lambda_k[\\int_{X_k} -\\Psi_k(-f_k^c(x))dP_k(x_k) + \\int_Y f_k(y)dQ(y)"], "fact": "inf_{Q\\in \\mathcal{P"}, {"f[1": "K] satisfying\nthe m-congruence condition: \u03a3\u03ba=1kfk = m. Indeed", "get": "nG(F1, ..., FK)-G(f1, \u2026fk) = \u03bb\u03ba\n[\u2212\u03a8\u03ba(-(xk)) + \u03a8\u03ba(\u2212f(xk)]dPK(xk)+m-m=\n\u221a [PK(-k(&K)) - (-(fk + m-1)(xx)]dPx(xx) \u2265 0.\nHere the inequality in line (17) follows from the properties of the c-transform function and convex\nconjugate of the divergence' generator function 4. First, c-transform is a decreasing function of its\nargument, see (Kolesov et al., 2024b, Proposition A.1 (i)). Thus,\nfk+\nf<\\frac{m-\\mathcal{f}}{\\lambda_k}<fk+\\frac{m-\\mathcal{m}}{\\lambda_k}=f.\nSecond, the convex conjugate is a non-decreasing function which yields\n-fix \u2265 \u2212(fk+\nm-1)\u0441\u043a \u2192 \u03c8\u043a(-x) \u2265 \u03c8\u03ba(\u2212(fk +\nm-\\\\\n      _f))\\\n    }\n  ]\n}\n```"}]