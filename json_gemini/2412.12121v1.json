{"title": "NLLG Quarterly arXiv Report 09/24:\nWhat are the most influential current AI Papers?", "authors": ["Christoph Leiter", "Jonas Belouadi", "Yanran Chen", "Ran Zhang", "Daniil Larionov", "Aida Kostikova", "Steffen Eger"], "abstract": "The NLLG (Natural Language Learning & Generation) arXiv reports assist in navigating\nthe rapidly evolving landscape of NLP and AI research across cs.CL, cs.CV, cs.AI, and cs.LG\ncategories. This fourth installment captures a transformative period in AI history-from Jan-\nuary 1, 2023, following ChatGPT's debut, through September 30, 2024. Our analysis reveals\nsubstantial new developments in the field-with 45% of the top 40 most-cited papers being\nnew entries since our last report eight months ago and offers insights into emerging trends\nand major breakthroughs, such as novel multimodal architectures, including diffusion and state\nspace models. Natural Language Processing (NLP; cs.CL) remains the dominant main cate-\ngory in the list of our top-40 papers but its dominance is on the decline in favor of Computer\nvision (cs.CV) and general machine learning (cs.LG). This report also presents novel findings\non the integration of generative AI in academic writing, documenting its increasing adoption\nsince 2022 while revealing an intriguing pattern: top-cited papers show notably fewer markers\nof AI-generated content compared to random samples. Furthermore, we track the evolution of\nAI-associated language, identifying declining trends in previously common indicators such as\n\"delve\".", "sections": [{"title": "Introduction", "content": "Keeping up with the rapid advancements in Artificial Intelligence (AI) is becoming increasingly\nchallenging for both researchers and professionals. Today, more scientific preprints are published\nthan ever before, accelerating the pace of progress. In this environment, researchers and profession-\nals who wish to stay informed about the latest developments often cannot wait for publications in\njournals and conference proceedings, as the information can quickly become outdated.\nThe NLLG Quarterly arXiv reports [11, 36, 6] produced by the Natural Language Learning &\nGeneration (NLLG; https://nl2g.github.io/) Lab take a different approach by exploring and\npresenting cutting-edge papers based on their immediate impact in the scientific community-\nspecifically, through the analysis of time-normalized citation counts. This current report is the"}, {"title": "Methods", "content": "As in our previous arXiv reports [11, 36, 6], we use week-based normalized z-scores of citation\ncounts to identify to identify the most influential papers for the categories AI, CV, CL and LG.\nHere, we briefly summarize the setup:\n1. Data Retrieval: We use an arXiv Python API\u00b9 to download metadata of all papers be-\nlonging to any of the arXiv categories cs.CL, cs.AI, cs.CV and cs.LG that were published\nfrom 2023/01/01 to 2024/09/30. The citation counts are dependent on the retrieval date:\n2024/11/20. We refer to this new dataset as arxiv-09/24.\n2. Paper Ranking: As in our previous reports, we use a SemanticScholar Python API\u00b2 to\ndetermine the citation counts of each paper in arxiv-09/24. Next, for each paper's citation\ncount, we calculate the normalized z-score compared to all papers that were published in the\nsame week:3"}, {"title": "", "content": "$\\Zi(t) = \\frac{Ci(t) - \\text{mean}(c(t))}{\\text{std}(c(t))}$"}, {"title": "", "content": "$\\Zi(t) = \\text{mean}(\\Zi(td)) - \\text{std}(\\Zi(td))$"}, {"title": "Data Exploration", "content": "In this section, we explore our dataset to highlight the overall trends in numbers and citation counts\nsince 2023/1/1, notably discussing the months from 2024/01/31 (our last report) to 2024/09/30."}, {"title": "Publication counts over time", "content": "Next, we analyze the publication counts per month per search\nArxiv category.5 Figure 2a shows the absolute number of publications per month per primary\ncategory. We can see that the numbers are slowly increasing over the months. Like in the previous\nreports, the most frequent category is cs.CV, followed by cs.LG and cs.CL. Also, each category\nhas a wave-like pattern with high-publication months followed by low-publication months. Our"}, {"title": "Z-Scores over time", "content": "With respect to citation counts, we analyze the average z-score per month\n(see Figure 3). For each month the cs.CL papers are the most influential, except August 2024, where\ncs.AI has the highest scores. Also, the plots seem to converge over the recent months, towards a\nz-score of -0.05. This might unveil a small bias that is introduced by highly influential older papers\nreceiving more citations faster than less cited papers published in the same week or highly influential\nnewer papers. Another cause might be the higher volume of papers in the more recent months."}, {"title": "Top-40 papers", "content": "Tables 2 and 3 show the top 20 and top 21-40 papers of the time period from 2023/1/1 to 2024/9/30.\nSince our last report, 11 newly published papers were included into our list, including all of the\ntop 3 papers. Additionally, 7 papers that were released before 2024/1/30 but not listed in our"}, {"title": "AI generated content in scientific papers", "content": "The advance of LLMs has made it simple to generate and paraphrase new texts. Hence, researchers\nalso use LLMs in the process of writing scientific papers [23]. As this report's focus topic, we extend\nprevious findings with a specific focus on (i) AI related sub-fields of arXiv and on (ii) top-40 papers."}, {"title": "Related work", "content": "Many works consider the detection of AI generated texts [31]. Here, we give a brief overview of\nrelated work regarding the detection regarding scientific publications. Liang et al. [23] analyze\npapers from multiple online repositories, including arXiv and determine that the use of generated\ncontent indeed increased a few weeks after the release of ChatGPT. They use a corpus-level detection\nmethod [22] that estimates the fraction a of AI generated text. To do so, they (1) construct\nfully human-written and AI-generated data sets, and (2) use maximum likelihood estimation to\nlearn an estimator that predicts a for mixed distributions (from 1). For cs papers on arXiv, they\nestimate that a fraction of over 17.5% of all introduction sections and abstracts (combined into\na single corpus) was generated in February 2024. Additionally, they find that the words realm,\nintricate, showcasing, pivotal are the most disproportionally used words by LLMs and displaying\ntheir frequency also highlights the increased use of generated content. Contemporaneously with\nthem, Geng and Trotta [13] also propose a word frequency based method. They use arXiv abstracts\npublished before the release of ChatGPT and rewrite them with the LLM to determine ground\ntruth frequency changes. Then, they test different models to predict LLM impact and show their\nperformance on unseen data. Interestingly, besides common LLM generated words, they also find\nthat some words, like is and are are decreasing in frequency. Gray [17] specially focuses on the\nincreasing use of specific words or word groups without learning an estimator. For example, the\nnumber of papers that use two words from \u201cintricate, meticulous, meticulously, commendable\"\nstrongly increases. Another work specifically focusing on changes in word usage is Kobak et al."}, {"title": "Methodology", "content": "Approaches of previous work can be grouped into three categories [21]: (1) detectors leveraging\nLLMs, (2) estimating mixture models and (3) zero-shot frequency based. Due to ease of setup, we\napply two detectors leveraging LLMs: FastDetectGPT [4], a method that compares the input text\nto sampled model outputs and Binoculars [19], a method that uses two closely related LLMs to\ndetermine whether the output of a model is more expected by a second model (cross-perplexity)\nthan the human-written content. Additionally, we consider several word-lists for zero-shot frequency\nbased detection: (1) the four top words by [23], (2) a list compiled by user Fareed Khan on github7,\n(3) the style words discovered by [21] and (4) the 100 words identified by [3]. These are lists of\nwords that people identified to be used more frequently by LLMs than by humans.\nTo compare the top-40 papers to general papers on arXiv, we collect the PDF files of 10 random\npapers for each weekday from 2022/01/01 to 2024/09/30. Next, we use markers to extract the text\ncontent of these papers and the top-40 papers into markdown. This amounts to a total of 7144\npapers (for 6 days only 9 papers where fetched). We use a larger time-span than the arXiv reports\nto be able to visualize changes since the release of ChatGPT (11/30/2022). The extracted data\ncan be noisy and there is no clear way to extract only relevant content. As a simple heuristic, we"}, {"title": "Results", "content": "Next, for each paper in our dataset of 7144 papers, we determine the word-\nfrequencies for List 1 and 3, sum them over all words and divide by the total word count of that\npaper. For each arXiv category, we select the median over all papers per month as a robust measure.\nThen, we plot the resulting relative frequency of LLM words over time. For each paper k in our\ndataset of n = 7144 papers, we compute the relative frequency of \"LLM-words\" as\n$fk = \\frac{\\SigmajCk,j}{Tk}$\nwhere Ck,j is the count of the j-th word in List 1 or List 3 for paper k, and Tk is the total word\ncount of paper k. For each arXiv category and month, we determine the median relative frequency\nas fmedian = median ({fk}) for all k in the given category and month. Finally, we plot fmedian,\nthe resulting median relative frequency of \"LLM-words\" over time. For the top-40 papers that we\ndetermined in Section 4, we do the same and add the results as scatterplots (see Figure 6). That\nmeans, each point indicates the amount of AI generated content (based on word frequencies) in the\ncurrent top-40 papers that were released in the respective month.\nFirst, looking at the line-plots we can indeed see a steady increase of LLM word frequencies\nover time, confirming the previous findings that LLM-usage for academic writing is increasing. In\nour dataset, cs.CV has the highest frequencies for most months but this was also the case before\nthe release of ChatGPT. cs.LG has the lowest frequencies. For the top-40 papers, most of them\n(22 out of 29 month+category combinations, i.e. the points in the graph) are below the median\nfrequencies of the random papers, which indicates that these papers may use less AI generated\ncontent than others. However, especially the cs.CL category shows a wider variance, where some\nmonths lie above the median frequency.\nFurther, Figure 7 shows the development of the top 5 words with the highest frequency change\n(of the selected word lists) from January 2022 to September 2024 for the random papers vs. the\ntop-40 papers. All words are relatively common, so seeing their increase is surprising. Also, rather\nthan a jump in usage, their frequencies are increasing steadily. Again, the top-40 papers rarely\nshow higher frequencies than the random ones. For some months, the words \"within\" and \"across\"\nhave high frequencies among the top-40 papers, as well. In comparison previous key words used to\ndetermine LLM usage, like \u201cdelve\" (see Figure 8) are declining in usage, i.e. contemporary LLMs\nseem to have been adapted.\""}, {"title": "Detection Tools", "content": "When we use FastDetectGPT and Binoculars, we can also identify very slight\nupward trends in the amount of generated content. For example, Figure 9 shows the absolute\nnumber of papers flagged as generated by Binoculars. While there is a clear increase from 0.1%\nto 0.8% this type of detection seems to be too strict for our use-case as it assumes fully LLM-\ngenerated content. Plotting the detector scores as a line plot does not give conclusive results. Also\n(unsurprisingly), among the top-40 papers none was flagged as fully AI generated."}, {"title": "Conclusion", "content": "We present the fourth NLLG arXiv report, highlighting the top 40 most influential papers in cs.CL,\ncs.AI, cs.LG and cs.CV. This includes 11 recently released highly cited papers and 7 further papers\nthat gained influence over the past months. Notably, the focus lies on the creation of new foundation\nmodels and the search for newer, more efficient architectures. As this reports' special focus, we\ncompare the prevalence of AI generated content in the top-40 papers with random papers selected\nfrom arXiv. We find that the top papers tend to contain less markers of AI use, indicating that\nthey are written by humans to a larger degree. Additionally, we find that previous key-words to\ndetect AI use are declining in frequency, calling into question the longevity of detection methods.\nTo be more reliable, these tools would need to be updated on a model basis, e.g., by using fresh\ngenerated text for mixed-model based approaches."}]}