[{"title": "On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness", "authors": ["Shengkun Zhu", "Jinshan Zeng", "Sheng Wang", "Yuan Sun", "Xiaodong Li", "Yuan Yao", "Zhiyong Peng"], "abstract": "Statistical heterogeneity is a root cause of tension among accuracy, fairness, and robustness of federated learning (FL), and is key in paving a path forward. Personalized federated learning (PFL) is an approach that aims to reduce the impact of statistical heterogeneity by developing personalized models for individual users, while also inherently providing benefits in terms of fairness and robustness. However, existing PFL frameworks focus on improving the performance of personalized models while neglecting the global model. This results in PFL suffering from lower solution accuracy when clients have different kinds of het- erogeneous data. Moreover, these frameworks typically achieve sublinear convergence rates and rely on strong assumptions. In this paper, we employ the Moreau envelope as a regularized loss function and propose FLAME, an optimization framework by utilizing the alternating direction method of multipliers (ADMM) to train personalized and global models. Due to the gradient-free nature of ADMM, FLAME alleviates the need for tuning the learn- ing rate during training of the global model. We demonstrate that FLAME can generalize to the existing PFL and FL frameworks. Moreover, we propose a model selection strategy to improve performance in situations where clients have different types of heterogeneous data. Our theoretical analysis establishes the global convergence and two kinds of convergence rates for FLAME under mild assumptions. Specifically, under the assumption of gradient Lipschitz continuity, we obtain a sublinear convergence rate. Further assuming the loss function is lower semicontinuous, coercive, and either real analytic or semialgebraic, we can obtain constant, linear, and sublinear convergence rates under different conditions. We also theoretically demonstrate that FLAME is more robust and fair than the state-of-the-art methods on a class of linear problems. We thoroughly conduct experiments by utilizing six schemes to partition non-i.i.d. data, confirming the performance comparison among state-of-the-art methods. Our experimental findings show that FLAME outperforms state-of- the-art methods in convergence and accuracy, and it achieves higher test accuracy under various attacks and performs more uniformly across clients in terms of robustness and fairness.", "sections": [{"title": "I. INTRODUCTION", "content": "FEDERATED learning (FL) plays a crucial role in the field of artificial intelligence [70], particularly in critical ap- plications such as next-word prediction [30], smart healthcare [2], [34], [73], and its recent integration into emerging large language models (LLMs) [20], [43], [88], [110]. In scenarios where privacy issues become very acute, and training becomes particularly challenging, such as in edge computing [69], [92], FL enables the collaborative training of models across devices while preserving users' privacy [38], [44], [48], [51], [83].\nDespite the advantages of FL in preserving privacy, it still encounters challenges with respect to the statistical het- erogeneity of data, affecting its accuracy and convergence [35], [54], [56], [64]. The statistical heterogeneity of data primarily manifests in the non-independent and non-identically distributed (non-i.i.d.) data across different clients [112]. When training FL models on non-i.i.d. data, the generalization error significantly increases, and the models converge in different di- rections. Beyond accuracy and convergence, statistical hetero- geneity also affects fairness in terms of providing a fair quality of service for all participants in the network [57]. Specifically, an FL system promotes uniform accuracy distribution among clients to ensure performance fairness\u00b9 [53]. This is closely related to resource allocation, as FL can be viewed as a joint optimization system over a heterogeneous network [36], [59]. Moreover, Li et al. [53] found that statistical heterogeneity is a root cause for tension among accuracy, fairness, and robustness of FL, where the robustness of FL refers to the ability against training-time attacks (including data poisoning and model poisoning) [53]. Exploring statistical heterogeneity in FL is key in paving a path forward to allow for competing constraints of accuracy, robustness, and fairness.\nPersonalized federated learning (PFL) is a method that aims to mitigate the impact of heterogeneous data by developing personalized models for individual users based on their distinct preferences [87]. Numerous strategies have been proposed to achieve PFL. A widely recognized strategy is known as meta-learning, also referred to as \"learning to learn\" [86]. Model-agnostic meta-learning (MAML) [26] is regarded as the pioneering approach to meta-learning, notable for its ability to generalize effectively and quickly adapt to new heteroge- neous tasks. However, MAML necessitates computing the Hes- sian term, which poses significant computational challenges. Several studies, including [24], [74], aimed to address this issue by approximating the Hessian matrix. Per-FedAvg [23], inspired by MAML, established a meta-model that can be effectively updated with just one gradient descent step. Dinh et al. [85] expanded Per-FedAvg to introduce a federated meta-learning framework by employing Moreau envelope (pFedMe). This framework integrates an 12-norm\nAll mentions of fairness in this paper refer to performance fairness."}, {"title": "II. RELATED WORK", "content": "Considering the impact of data heterogeneity on the training model in FL, we first review several specific patterns of data heterogeneity. Subsequently, due to our consideration of using ADMM as the optimization method, which is a primal-dual framework, we therefore examine recent research on the integration of the primal-dual framework within FL. Next, we summarize the PFL research closely related to our work. Finally, since personalization can provide robustness and fairness for FL, we introduce these concepts.\nData heterogeneity. Kairouz et al. [38] provided a thorough overview of heterogeneous data scenarios from a distribution perspective. Ye et al. [104] further categorized the statistical heterogeneity of data into four distinct skew patterns: label skew, feature skew, quality skew, and quantity skew. Fig. 1 shows examples of the four skew patterns. Label skew refers to the dissimilarity in label distributions among the participating clients [38], [109]. Feature skew denotes a situation in which the feature distributions among participating clients diverge [50], [65]. Quality skew illustrates the inconsistency in data collection quality across different clients [101]. Quantity skew denotes an imbalance in the amount of local data across clients [78]. These skew patterns lead to local models converging in different directions [104], thereby resulting in the trained model not being optimal. Li et al. [50] conducted thorough experiments to evaluate the effectiveness of current FL algo- rithms. Their findings indicate that non-i.i.d data does indeed pose significant challenges to the accuracy of FL algorithms during the learning process. Chen et al. [17] demonstrated that when data heterogeneity exceeds a certain threshold, purely local training is minimax optimal; otherwise, the global model is minimax optimal. In practice, we prefer PFL be- cause it intervenes between the two extremes by interpolating between global and personalized models [59]. However, its performance remains uncertain when dealing with different heterogeneous data types across clients.\nPrimal-dual scheme for FL. From an optimization perspec- tive, we categorize FL into three types: primal scheme [40], [55], [56], [70], [91], dual scheme [68], [81], [82], [102], and primal-dual scheme [27], [39], [111], [114], [115]. Most existing FL frameworks are based on the primal scheme, where each client trains a local model by solving the primal problem via gradient descent, and then the server aggregates these local models. In contrast, FL frameworks based on the dual scheme involve solving dual problems, which have been shown to converge faster [82]. However, the dual scheme is only suitable for convex problems. In recent years, primal-dual schemes have gained widespread utilization in the context of FL. Zhang et al. [111] introduced a primal-dual FL framework designed to handle non-convex objective functions. However, this method suffers restrictive assumptions for convergence. Zhou and Li [114] proposed the FedADMM, establishing convergence under mild conditions. Gong et al. [27] proposed that within FedADMM, the dual variables can effectively mitigate the impact of data heterogeneity on the training model. Based on FedADMM, Zhou and Li [115] proposed a method that differs from FedADMM by performing a single step of gradient descent on the unselected clients, thereby enhancing com- munication efficiency. However, although these primal-dual schemes generally exhibit superior accuracy and convergence performance, they have not yet been applied in PFL.\nPersonalized federated learning. Tan et al. [86] catego- rized the methods of PFL into two classes: global model personalization and learning personalized models. Learning personalized models is not the focus of this paper, so interested readers can refer to [9], [33], [60], [118]. Tan et al. [86] further classified the techniques for personalizing global models into two categories: data-based approaches [21], [89], [94], [113] and model-based approaches [23], [26], [85]. As our proposed method falls within the realm of model-based approaches, we provide a detailed overview of the relevant literature pertain- ing to model-based approaches. Finn et al. [26] considered a model-agnostic meta-learning (MAML) algorithm that is designed to be compatible with different learning problems, enabling the training of a model across various tasks. However, MAML necessitates computing the Hessian term, which poses significant computational challenges. Several studies, includ- ing [24], [74], aimed to address this issue by approximating the Hessian matrix. Inspired by the principles of MAML, Fallah et al. [23] introduced Per-FedAvg, which builds a meta-model that can be efficiently updated with a single additional gradient descent step. Inspired by Per-FedAvg, Dinh et al. [85] proposed pFedMe which implements multiple gradient descent steps within the meta-model update process to enhance the solution precision. Subsequent studies proposed that employing PFL can enhance the fairness and robustness of the trained models [49], [53], [59]. Li et al. [53] proposed a framework called Ditto, which was the first to improve the robustness and fairness of FL through personalization. Lin et al. [59] further considered using lp norm and low- dimensional random projection for regularization. However, the convergence analysis of this method introduces a stronger assumption, namely the low-dimensional condition. Although their approach can improve the accuracy of personalized models, it renders the global model unusable due to the low- dimensional projection. Consequently, this method becomes ineffective in our scenarios where clients have various types of heterogeneous data.\nRobustness and fairness in FL. Zhou et al. [116] classified fairness in FL into three categories: performance fairness [52], [53], [57], [59], collaboration fairness [66], [97], [106], and model fairness [22], [31]. This paper focuses on performance fairness. In federated networks, the heterogeneity of data across different clients can lead to significant variations in model performance. This issue, referred to as representation disparity [32], poses a significant challenge in FL because it can result in unfair outcomes for different clients. Next, we present the definition of performance fairness in FL [53]."}, {"title": "III. PRELIMINARIES", "content": "This section describes the notations used throughout the paper, details the definition of FL, introduces the concept of ADMM, and provides an overview of the Moreau envelope.\nA. Notations\nWe use different text-formatting styles to represent different mathematical concepts: plain letters for scalars, bold letters for vectors, and capitalized letters for matrices. For instance, $m$ represents a scalar, $\\mathbf{w}$ represents a vector, and $W$ denotes a matrix. Without loss of generality, all training models in this paper are represented using vectors. We use $[m]$ to represent the set ${1, 2, ..., m\\}$. The symbol $\\mathbb{E}$ denotes the expectation of a random variable, and we use \":=\" to indicate a definition, while $\\mathbb{R}^n$ represents the $n$-dimensional Euclidean space. We represent the inner product of vectors, such as $\\langle \\mathbf{a}, \\mathbf{b}\\rangle$, as the sum of the products of their corresponding elements. We use $\\| \\cdot \\|$ to denote the Euclidean norm of a vector and the spectral norm of a matrix. We use $I$ to represent the identity matrix and $\\mathbf{1}$ to represent the all-ones matrix. Table I enumerates the notations used in this paper along with the description.\nB. Federated Learning\nConsider an FL scenario with $m$ clients, where each client $i$ possesses a local dataset $\\mathcal{X}_i$ comprising $n_i$ data samples with data distribution $\\mathcal{D}_i$. These clients are interconnected through a central server and aim to collectively train a model $\\mathbf{w}$ that minimizes the empirical risk [70]:\n$\\underset{\\mathbf{w}}{\\min} \\left\\{ f(\\mathbf{w}) := \\sum_{i=1}^m a_i f_i(\\mathbf{w}) := \\sum_{i=1}^m a_i \\mathbb{E}_{x \\sim \\mathcal{D}_i} [l_i(\\mathbf{w}; x)] \\right\\} ,$ (1)"}, {"title": "C. Alternating Direction Method of Multipliers", "content": "ADMM is an optimization method that belongs to the class of augmented Lagrangian methods and is particularly well- suited for solving the following general problem [13]:\n$\\begin{aligned} \\min_{\\mathbf{w} \\in \\mathbb{R}^r, \\mathbf{v} \\in \\mathbb{R}^q} & f(\\mathbf{w}) + g(\\mathbf{v}), \\\\ \\text{s.t.} & A\\mathbf{w} + B\\mathbf{v} - \\mathbf{b} = 0, \\end{aligned}$\nwhere $A \\in \\mathbb{R}^{p \\times r}$, $B \\in \\mathbb{R}^{p \\times q}$, and $\\mathbf{b} \\in \\mathbb{R}^p$. We directly give the augmented Lagrangian function of the problem as follows,\n$\\mathcal{L}(\\mathbf{w}, \\mathbf{v}, \\pi) := f(\\mathbf{w}) + g(\\mathbf{v}) + \\langle \\pi, A\\mathbf{w} + B\\mathbf{v} - \\mathbf{b}\\rangle + \\frac{\\rho}{2} \\|A\\mathbf{w} + B\\mathbf{v} - \\mathbf{b}\\|^2,$\nwhere $\\pi \\in \\mathbb{R}^p$ is the dual variable, and $\\rho > 0$ is the penalty parameter. After initializing the variables with $(\\mathbf{w}^0, \\mathbf{v}^0, \\pi^0)$, ADMM iteratively performs the following steps:\n$\\begin{aligned} \\mathbf{w}^{t+1} & = \\underset{\\mathbf{w} \\in \\mathbb{R}^r}{\\text{argmin}} \\mathcal{L}(\\mathbf{w}, \\mathbf{v}^t, \\pi^t), \\\\ \\mathbf{v}^{t+1} & = \\underset{\\mathbf{v} \\in \\mathbb{R}^q}{\\text{argmin}} \\mathcal{L}(\\mathbf{w}^{t+1}, \\mathbf{v}, \\pi^t), \\\\ \\pi^{t+1} & = \\pi^t + \\rho(A\\mathbf{w}^{t+1} + B\\mathbf{v}^{t+1} - \\mathbf{b}). \\end{aligned}$\nADMM exhibits distributed and parallel computing capa- bilities, effectively addresses equality-constrained problems, and provides global convergence guarantees [93], making it particularly well-suited for tackling large-scale optimization problems. It finds widespread applications in distributed com- puting, machine learning, and related fields."}, {"title": "D. Moreau Envelope", "content": "The Moreau envelope is an essential concept in the fields of mathematics and optimization [72]. It finds widespread application in convex analysis, non-smooth optimization, and numerical optimization. Here, we present the definition.\nDefinition 3 (Moreau envelope [76]). Consider a function $f: \\mathbb{R}^p \\rightarrow \\mathbb{R}$, its Moreau envelope is defined as:\n$F(\\mathbf{w}) := \\underset{\\theta \\in \\mathbb{R}^p}{\\min} f(\\theta) + \\frac{\\lambda}{2} \\| \\mathbf{w} - \\theta \\|^2,$ (2)\nwhere $\\lambda$ is a hyperparameter. Its associated proximal operator is defined as follows,\n$\\underset{f/\\lambda}{\\text{prox}}(\\mathbf{w}) := \\underset{\\theta \\in \\mathbb{R}^p}{\\text{argmin}} \\left\\{ f(\\theta) + \\frac{\\lambda}{2} \\| \\theta - \\mathbf{w} \\|^2 \\right\\}.$ (3)\nThe Moreau envelope provides a smooth approximation of the original function $f$. This approximation is helpful when dealing with optimization algorithms that require smooth func- tions. As $\\lambda$ becomes smaller, the Moreau envelope approaches the original function, making it useful for approximating and optimizing non-smooth functions. Next, we describe a useful property of Moreau envelope [76]."}, {"title": "IV. PROPOSED FLAME", "content": "In this section, we first present the formulation of the optimization problem along with the stationary points for PFL based on ADMM. We then provide an algorithmic description of FLAME along with a specific example. Following this, we propose a model selection strategy to adapt to FL scenarios with different types of heterogeneous data. Finally, we demonstrate that FLAME can generalize to the existing PFL and FL frameworks by configuring certain hyperparameters.\nA. Problem Formulation\nTo construct the objective function for PFL, we employ the approach outlined in [85], where $f_i$ is substituted by the Moreau envelope of $f_i$ in the optimization Problem (1). The specific formulation of the problem is presented as follows:\n$\\underset{\\mathbf{w}}{\\min} \\sum_{i=1}^m a_i F_i(\\mathbf{w}),$ (5)\nwhere $F_i(\\mathbf{w}) := \\underset{\\theta_i}{\\min} \\left\\{ f_i(\\theta_i) + \\frac{\\lambda}{2} \\| \\theta_i - \\mathbf{w} \\|^2 \\right\\}, i \\in [m].$\nNote that $F_i$ is the Moreau envelope of $f_i$, and $\\theta_i$ is the personalized model of client $i$. The hyperparameter $\\lambda$ controls the influence of the global model $\\mathbf{w}$ on the personalized model $\\theta$. A higher value of $\\lambda$ provides an advantage to clients with unreliable data by harnessing extensive data aggregation, whereas a lower $\\lambda$ places greater emphasis on personalization for clients with a substantial amount of useful data. Note that $\\lambda \\in (0, \\infty)$ is used to prevent extreme cases where $\\lambda = 0$ (no FL) or $\\lambda = \\infty$ (no PFL). The overall concept is to enable clients to develop their personalized models in different directions while remaining close to the global model $\\mathbf{w}$ contributed by every client. Note that Problem (5) is a bi-level optimization problem. The conventional approach to solving bi-level problems typically involves initially using a first-order gradient method to solve $\\theta_i$ in the lower-level problem, obtaining an approximate solution. This approximate solution is then incorporated into the upper-level problem, followed by another round of the first-order gradient method to solve $\\mathbf{w}$ in the upper-level problem. Iterating through this process multiple times yields the final solutions. Even though the first-order gradient method is simple, it suffers from low solution accuracy and is cumbersome to fine-tune parameters like the learning rate. To address these issues, we propose a relaxed form of Problem (5) as follows,\n$\\underset{\\Theta, \\mathbf{w}}{\\min} \\left\\{ f(\\Theta, \\mathbf{w}) := \\sum_{i=1}^m a_i \\left( f_i(\\theta_i) + \\frac{\\lambda}{2} \\| \\theta_i - \\mathbf{w} \\|^2 \\right) \\right\\},$ (6)\nwhere $\\Theta := {\\theta_i}_{i=1}^m$ is the set of personalized models. Note that Problem (6) is a multi-block optimization problem with respect to $\\mathbf{w}$ and $\\Theta$. It is obvious that Problem (6) serves as a lower bound for Problem (5). We aim to learn an optimal personalized model $\\Theta^*$ and an optimal global model $\\mathbf{w}^*$ that minimizes $f(\\Theta, \\mathbf{w})$. That is\n$\\Theta^*, \\mathbf{w}^* := \\underset{\\Theta, \\mathbf{w}}{\\text{argmin}} f(\\Theta, \\mathbf{w}),$ (7)\nand the corresponding optimal function value is given as\n$f^* := f(\\Theta^*, \\mathbf{w}^*).$ (8)\nGiven that ADMM, as a primal-dual method, is often re- garded as more iteration-stable and converges faster compared to gradient-based approaches, we consider employing ADMM to solve Problem (6). Firstly, we consider introducing the auxiliary variable $W := {\\mathbf{w}_i}_{i=1}^m$ to transform Problem (6) into a separable form (with respect to a partition or splitting of the variable into multi-block variables). That is\n$\\begin{aligned} &\\underset{\\Theta, \\mathbf{w}, W}{\\min} \\left\\{ f(\\Theta, W):= \\sum_{i=1}^m a_i \\left( f_i(\\theta_i) + \\frac{\\lambda}{2} \\| \\theta_i - \\mathbf{w}_i \\|^2 \\right) \\right\\}, \\\\ &\\text{s.t.} \\quad \\mathbf{w}_i = \\mathbf{w}, \\quad i \\in [m], \\end{aligned}$ (9)\nwhere $\\mathbf{w}_i$ can be regarded as the local model of client $i$. Note that Problem (9) is equivalent to Problem (6) in the sense that the optimal solutions coincide. We consider using the exact penalty method, ADMM, to solve Problem (9), as it involves linear constraints and multiple block variables, making ADMM well-suited for this optimization problem. Moreover, in Section IV-E, we will analyze in detail how other PFL frameworks can be seen as solving Problem (9) by using an inexact penalty method. To implement ADMM for Problem (9), we establish the corresponding augmented Lagrangian function as follows:\n$\\mathcal{L}(\\Theta, W, \\Pi, \\mathbf{w}) := \\sum_{i=1}^m \\mathcal{L}_i(\\theta_i, \\mathbf{w}_i, \\mathbf{w}, \\pi_i),$ (10)\n$\\mathcal{L}_i(\\theta_i, \\mathbf{w}_i, \\mathbf{w}, \\pi_i) := a_i\\left( f_i(\\theta_i) + \\frac{\\lambda}{2} \\| \\theta_i - \\mathbf{w}_i \\|^2 \\right) + \\langle \\pi_i, \\mathbf{w}_i - \\mathbf{w} \\rangle + \\frac{\\rho}{2} \\| \\mathbf{w}_i - \\mathbf{w} \\|^2,$\nwhere $\\Pi := {\\pi_i}_{i=1}^m$ is the set of dual variables, and $\\rho > 0$ is the penalty parameter. The ADMM framework for solving Problem (9) can be summarized as follows: after initializing the variables with $(\\Theta^0, W^0, \\Pi^0, \\mathbf{w}^0)$, the following update steps are executed iteratively for each $t \\geq 0$,\n$\\theta_i^{t+1} = \\underset{\\theta_i}{\\text{argmin}} \\mathcal{L}_i(\\theta_i, \\mathbf{w}_i^t, \\mathbf{w}^t, \\pi_i^t),$ (11)\n$\\mathbf{w}_i^{t+1} = \\underset{\\mathbf{w}_i}{\\text{argmin}} \\mathcal{L}_i(\\theta_i^{t+1}, \\mathbf{w}_i, \\mathbf{w}^t, \\pi_i^t)$ (12)\n$= \\frac{1}{\\lambda a_i + \\rho} (\\lambda a_i \\theta_i^{t+1} + \\rho \\mathbf{w}^t - \\pi_i^t),$ (13)\n$\\pi_i^{t+1} = \\pi_i^t + \\rho(\\mathbf{w}_i^{t+1} - \\mathbf{w}^t),$ (14)\n$\\mathbf{w}^{t+1} = \\underset{\\mathbf{w}}{\\text{argmin}} \\mathcal{L}(\\Theta^{t+1}, W^{t+1}, \\Pi, \\mathbf{w}) = \\frac{1}{m} \\sum_{i=1}^m (\\mathbf{w}_i^{t+1} + \\frac{\\pi_i^{t+1}}{\\rho}).$\nNote that we do not provide a closed-form solution for $\\theta_i$ due to the possibly non-convex nature of $f_i$. We will discuss this issue in detail in Section IV-C."}, {"title": "V. THEORETICAL ANALYSIS", "content": "We begin by providing the definitions of graph", "f": "mathbb{R"}, "p \\rightarrow \\mathbb{R} \\cup {+\\infty\\}$ be an extended real-valued function, its graph is defined by\n$\\text{Graph}(f) := {(\\mathbf{x}, y) \\in \\mathbb{R}^p \\times \\mathbb{R} : y = f(\\mathbf{x})},$ and its domain is defined by $\\text{dom}(f) := {\\mathbf{x} \\in \\mathbb{R}^p : f(\\mathbf{x}) < +\\infty\\}$. If $f$ is a proper function, i.e., $\\text{dom}(f) \\neq \\emptyset$, then the set of its global minimizers is defined by\n$\\text{argmin} f := {\\mathbf{x} \\in \\mathbb{R}^p : f(\\mathbf{x}) = \\text{inf} f}.$\nDefinition 6 (Semicontinuous). A function $f: X \\rightarrow \\mathbb{R}$ is called lower semicontinuous if for any $\\mathbf{x}_0 \\in X$,\n$\\underset{\\mathbf{x} \\rightarrow \\mathbf{x}_0}{\\text{lim inf}} f(\\mathbf{x}) \\geq f(\\mathbf{x}_0).$\nDefinition 7 (Real analytic function [41"], "mathbb{R}^p": "P_{ij"}, {"P^t": "Theta^t", "as\n$\\mathcal{L}(P^t)": "mathcal{L"}, {"components": "ensuring sufficient descent and relative error conditions", "Gamma^{t+1}": "sum_{i=1"}, {"mathcal{D}_1": "underset{i"}, {"where\n$d\\mathcal{L}(P^t)": {"mathcal{D}_2": "underset{i}{\\text{max}}\\left\\{\\frac{4 \\lambda^2 \\alpha_i^2 (1 + \\rho)}{\\rho^2} + 2 a_i^2 (L^2 + 2 \\lambda^2) + 2 \\rho^2 + 2 \\right\\}.$\nNote that in the relative error, there exists an error term $\\epsilon^{t+1}$ on the right-hand side of the inequality. The current theoretical framework cannot accommodate the presence of this error term [93]. Next, we provide an analysis of global convergence in the presence of this error term.\nTheorem 1. Suppose that Assumption 2 holds, let each client i choose $\\frac{\\lambda^2 \\alpha i(1+\\rho)}{\\lambda a i+\\rho} - \\lambda \\alpha i \\rho^2< 0$, $\\rho > \\lambda a i$, and $\\frac{\\alpha_i^2-\\lambda^2\\alpha_i+\\rho}{\\lambda a i+\\rho} > 0$, then the following results hold.\na) Sequence {$P^t$} is bounded.\nb) Sequences {$\\mathcal{L}(P^t)$}, {$f(\\Theta^t, \\mathbf{w}^t)$}, and {$f(\\Theta^t, W^t)$} converge to the same value, i.e.,\n$\\underset{t \\rightarrow \\infty}{\\text{lim}} \\mathcal{L}(P^t) = \\underset{t \\rightarrow \\infty}{\\text{lim}} f(\\Theta^t, \\mathbf{w}^t) = \\underset{t \\rightarrow \\infty}{\\text{lim}} f(\\Theta^t, W^t).$ (22)\nc) $\\nabla_\\Theta f(\\Theta^t, \\mathbf{w}^t)$, $\\nabla_\\mathbf{w} f(\\Theta^t, \\mathbf{w}^t)$, $\\nabla_\\Theta f(\\Theta^t, W^t)$, and $\\nabla_\\mathbf{w} f(\\Theta"}}]