{"title": "Adaptive Graph of Thoughts: Test-Time Adaptive Reasoning Unifying Chain, Tree, and Graph Structures", "authors": ["Tushar Pandey", "Ara Ghukasyan", "Oktay Goktas", "Santosh Kumar Radha"], "abstract": "Large Language Models (LLMs) have demonstrated impressive reasoning capabilities, yet their performance\nis highly dependent on the prompting strategy and model scale. While reinforcement learning and fine-tuning\nhave been deployed to boost reasoning, these approaches incur substantial computational and data overhead. In\nthis work, we introduce Adaptive Graph of Thoughts (AGoT), a dynamic, graph-based inference framework that\nenhances LLM reasoning solely at test time. Rather than relying on fixed-step methods like Chain of Thought\n(CoT) or Tree of Thoughts (ToT), AGoT recursively decomposes complex queries into structured subproblems,\nforming an dynamic directed acyclic graph (DAG) of interdependent reasoning steps. By selectively expanding\nonly those subproblems that require further analysis, AGoT unifies the strengths of chain, tree, and graph paradigms\ninto a cohesive framework that allocates computation where it is most needed. We validate our approach on diverse\nbenchmarks spanning multi-hop retrieval, scientific reasoning, and mathematical problem-solving, achieving up to\n46.2% improvement on scientific reasoning tasks (GPQA) - comparable to gains achieved through computationally\nintensive reinforcement learning approaches and outperforming state-of-the-art iterative approaches. These\nresults suggest that dynamic decomposition and structured recursion offer a scalable, cost-effective alternative to\npost-training modifications, paving the way for more robust, general-purpose reasoning in LLMs.", "sections": [{"title": "1. Introduction", "content": "Large Language Models (LLMs) have rapidly advanced\nthe state of natural language processing, demonstrating\nimpressive capabilities in understanding, reasoning, and\nproblem-solving. Despite these advances, the quality of\ninference produced by LLMs remains highly sensitive to the\nprompting strategy and model scale. Traditional techniques\nsuch as reinforcement learning and fine-tuning have been successful in enhancing\nreasoning performance, achieving up to +46% improvement\non standard benchmarks through computationally intensive\nmodel distillation; however,\nthese methods incur substantial computational and data\noverhead. In this work, we propose an inference-time\nalternative-Adaptive Graph of Thoughts (AGoT)\u2014which\nachieves comparable performance gains (+46.2% on GPQA)\nthrough dynamic decomposition of complex\nqueries into structured subproblems. By unifying the se-\nquential nature of Chain of Thought (CoT), the branching strategies of Tree of Thoughts (ToT) , and the generality of graph-based reason-\ning , AGOT offers a scalable and cost-"}, {"title": "1.1. Techniques for LLM Improvement", "content": "Advances in training techniques, dataset selection, and\nneural network architectures continue to drive the rapid\ndevelopment of artificial intelligence (AI) and LLMs (Anil\net al., 2023; OpenAI, 2023; Team et al., 2023; Dubey et al.,\n2024; OpenAI, 2024). As LLM-powered AI permeates the\nsoftware ecosystem, understanding user-AI or AI-AI inter-\nactions becomes increasingly important for building trust in\napplications. LLMs are conceptually opaque (Singh et al.,\n2023), with both beneficial and detrimental subtleties in\ntheir behavior still emerging from empirical studies (Ajwani\net al., 2024). Inference frameworks have thus emerged\nas systematic solutions for enhancing high-level LLM\ninteractions."}, {"title": "1.2. Thought structures as graphs", "content": "We understand a \"thought\" to be any unit of content that\ninforms an LLM's final response. Thoughts are assumed to\nbe accessible as combinable units of information rather than\nany implicit steps in an LLM's internal reasoning process.\nGiven a set of tangible thoughts, we construct a graph\nwhere each directed edge indicates that one thought informs\nanother. Edge traversal in this graph is then analogous to\na traceable thought process, and considering only acyclic\ngraphs ensures all thought processes are finite. Any DAG of\nthoughts, whether chain- or tree-like or otherwise, contains\none or more thought processes as identified by the ancestors\nof an arbitrary \"final\" node.\n\nThe evolution of the AGoT framework is governed by the\ngradual expansion of this graph. Starting from an empty\ngraph, node and edge generation proceeds one topological\nlayer at a time, with the thoughts at each layer undergoing\nevaluation through LLM queries that are contextualized by\nthe current state of the graph. The complete evolution of a\nsample AGoT graph is shown in Figure 3. Here, the \"layer\n0\" is generated in step (i) and evaluated to completion in\nsteps (ii) and (iii). The evaluation process is identical for\nevery layer in AGoT, including any nested graphs, except\nspecial cases for the first and last layers, as in steps (i)-(iii)\nand (ix)-(x).\n\nBefore articulating special cases, we consider the general\none. In general, the evaluation of a single layer is complete\nwhen the evaluation of all its nodes is complete. All nodes\nstart in the \"new\" state and progress through one of two\ntrajectories:\n\n1.  The node is classified as \"complex\" and its content\n    directly informs a new, nested AGoT process.\n\n2.  The node is not classified as complex and gets evalu-\n    ated directly.\n\nNested AGOT processes stemming from case (1) above are\nstill subject to the aforementioned evaluation process, with\nthe content of the complex node informing the new nested\ngraph in a manner analogous to how the initial query informs\nthe first layer of the top-most graph. In all graphs, the next\nlayer of nodes and edges is then added once the current one\nis completed.\n\nRegarding special cases, the very first layer of a graph (or\nnested graph) is distinguished by the fact that its generation\nis informed by the initial query (or by the contents of the\nassociated complex node). Initial layers are also generated\nwithout any explicit dependencies (i.e. edges), although\nevery node in the initial layer of a nested graph is implicitly\na \"child\" node of the associated complex node. Figure 2\nmost clearly illustrates the global node and edge sets of a\nsample AGoT instance with depth 1 recursion."}, {"title": "1.3. Dynamic frameworks", "content": "The remainder of this work introduces a detailed mathe-\nmatical formalism for AGoT, works through illustrative\nexamples, presents benchmarking results across diverse\ntasks, and concludes with a discussion of future research\ndirections.\n\nDynamism in the context of inference or generation frame-\nworks refers to a framework's ability to adapt to individual\ntasks or datasets through automatic adjustments to its own\nstructure, prompting strategies, or other aspects of the\ngeneral methodology. Apart from CoT, all frameworks\ndiscussed thus far (and depicted in Figure 2) are dynamic\nto varying degrees. Dynamic inference frameworks (Prasad\net al., 2024; Ning et al., 2024; Zhu et al., 2024; Radha et al.,\n2024) represent some of the most performant approaches to\ndate.\n\nDesigned to be adaptive and generalizable, dynamism in\nAGOT hinges on two principal degrees of freedom; (1)\nthe ability to generate any number of new nodes (up to\na user-specified limit) per layer, with arbitrary edges; and\n(2) the ability to recursively apply itself as necessary. In\nthe process of generating nodes to decompose tasks and\nsub-tasks, AGOT also generates a unique strategy to guide\nand focus each layer's objective. Additionally, AGoT is\nable to recognize high-quality responses and self-terminate,\nreducing unnecessary branching.\n\nTo validate AGoT as a general-purpose framework, we\ntested its performance on several difficult datasets belonging\nto \"reasoning\", \"retrieval\", and \"explorative\" categories.\nThese results are summarized in Table 2 in Section 5.\n\nAGOT is specifically designed to be both adaptive and\ngeneralizable. Its dynamism hinges on two key capabilities:\nthe ability to generate an arbitrary number of new nodes\nper layer (subject to user-specified limits), and the capacity\nto recursively apply its reasoning process when necessary.\nDuring the generation of nodes for decomposing tasks\nand sub-tasks, AGoT concurrently formulates a unique\nstrategy to guide each layers objectives. Additionally, it\ncan recognize high-quality responses and self-terminate,\nthereby reducing unnecessary branching. To validate\nAGOT as a general-purpose framework, we have tested\nits performance on several challenging datasets spanning\nreasoning, retrieval, and explorative problem-solving tasks,\nwith results summarized in table 2 in section 5.\n\nThe remainder of this work introduces a mathematical\nformalism for AGoT, works through an example, discusses\nbenchmarking results, and provides concluding remarks."}, {"title": "2. Mathematical formalism", "content": "Every node in AGoT is uniquely defined by its heritage, a\nsequence of nodes that distinguishes a particular subgraph.\nNote that a heritage is not necessarily the same as a node's\n\"ancestry\" in the usual DAG context because a heritage does\nnot necessarily correspond to an edge-traversal path.\n\nLetting L be the set of layer indices and N the set of node\nindices in an arbitrary layer, we define the set of local indices\nat each nesting depth $d \\leq d_{max}$ by $S = L \\times N$. Every\nheritage then belongs to the following set\n\n$H = \\bigcup_{d=0}^{d_{max}} S'^d $\n\nwhere $S^d$ is the d-fold Cartesian product of S. Members of\nH are understood as sequences of (d + 1) node positions $s_i$\n\n$h = (s_0, s_1, ...,s_d)$\n$s_i = (l_i, n_i)$\n\nwhere $0 \\leq d \\leq d_{max}$. The indices $l_i \\in N$ and $n_i\\in N$\nare the layer (i.e. topological generation) and node label,\nrespectively, which uniquely identify a node at nesting\ndepth i < $d_{max}$. Any node in an entire AGOT instance\ncan then be denoted by $v_h$ in reference to a heritage h\nthat traces a path to the node's position, $s_d$, via interfacial\n\"complex\" nodes $s_{i<d}$ that connect nested graphs across\nAGOT depths. In other words, the preceding sub-sequence\nh' = (so,...,$s_{d\u22121}$) can be understood as the heritage of\na graph or nested graph, wherein $s_d$ identifies a particular\nnode.\n\nThe top-level AGoT graph is denoted by $G_0$ where $\\empty$\nrepresents the empty heritage. To proceed, we also define G\nas a class of hierarchical graphs; Q as the set of all possible\nqueries; A as the set of all possible answers; $ \\sum$ as the set of\nall possible strategies; and T as the set of all possible tasks.\n\nWe now associate with each node $v_h$ either the empty graph\n(denoted by (\u00d8) or a nested graph,\n\n$G_h = (V_h, E_h, F_h)$\n\ndefined by sets of nodes and edges, $V_h$ and $E_h$, as well as a\nfinal answer $F_h$, such that any node $v_h$ is exactly specified\nby\n\n$v_h = (t_h, \u03c3_l, \u03b1_h, G_h)$\n\nwhere $t_h\\in T$ is the thought for the node, $\u03c3_l; \\in  \\sum $is the\nstrategy for its layer, and $\u03b1_h \\in A$ is the answer or response\nto thought."}, {"title": "2.1. Structure and indexing", "content": ""}, {"title": "2.2. Actions on graph data", "content": "Taking Q to be the set of all input queries and to be the\nset of all n-tuples (n = 1, 2, ..., N) of thoughts,\n\n$0 = T\\cupT^2 \\cup \u2026\u2026 \\cup T^N\\n\nwe describe crucial actions in AGoT with the mappings:\n\n$T_\u00f8 : Q \u00d7 N \u2192 \u0398\u00d7 \\sum $\n$T_0 : Q\u00d7N\u00d7G \u2192 \u0398\u00d7\\sum $\n$T_e : Q\u00d7N\u00d7G \u2192 \u0398\u00d7 \u03a3\u03a7\u0395$\n$C : T \u00d7 G \u2192 {0,1}$\nEval: TX G\u2192A\n\u03a6: G-T\n\nAmong these, $T_\u00f8$, $T_0$, and $T_e$ are the actions that map\ninputs to new thoughts. Specifically, $T_\u00f8$ operates on initial\nqueries to generate initial thoughts (e.g. Figure 3 (i)), while\n$T_0$ operates on complex thoughts to generate initial thoughts\nin the first layer of nested graphs. $T_e$ operates on all other\nthoughts not targeted by the prior two mappings. Note\nthat the output space of $T_e$ includes a new thought, a\nstrategy, and new edges, because $T_e$ describes input-to-\nthought mapping in the most general case. The remaining\nmappings, C, Eval, and I describe complexity checks,\nthought evaluation, and final thought generation respectively.\nWith this definition on hand, AGoT is defined as pseudo-\ncode in Algorithm 1."}, {"title": "3. Example", "content": "In this section, we provide a step-by-step description of an\nAGOT process that answers a sample GQPA question. Categorized as a \"reasoning\" task, this\nsample illustrates the decomposition of a difficult scientific\nquestion, as seen in Figure 4 (next page).\n\nStarting with the initial query (described as \"human\" input at\nthe top of Figure 4), AGoT generates three key thoughts to\ncomprise the initial layer (\"layer 0\"). Because these thoughts\nbelong to the top graph, their heritage (see Section 2.1)\ncontains only a single tuple, as shown in the small gray\nboxes adjacent to each top-level node. Upon evaluation of\nthe initial layer, the node titled flux and distance analysis is\nmarked as complex, while the remaining nodes (index (0, 1)\nand (0, 2)) are answered directly.\n\nAt this point, the nested AGOT process corresponding to\nnode position (0,0) must be completed before the next layer\n(\"layer 1\") is started. Having set $d_{max}$ = 1 here, nested\ngraphs themselves will not contain any complex nodes, so\nthe first layer of thoughts whose heritages are $h_k$ =\n((0,0), (0, k)) for k = 0, 1, 2 \u2014 is generated then evaluated\ndirectly. Similarly, the second nested layer (indices omitted\n\nin Figure 4, $h_j$ = ((0,0), (1, j)) for j = 0,1,2), which\nincludes the final thought (consolidate peak flux findings) for\nthis nested graph. These thoughts represent a decomposition\nof the parent thought at (0,0) and therefore address topics\nrelated to peak flux and cosmological distances. Upon\ncompletion of the first nested graph, the contents of its\nfinal answer inform the creation of the single node (1,0),\ntogether with the answers of top-level nodes at (0, 1) and\n(0,2). The new node at (1,0) is then also identified as\ncomplex, initiating the second nested AGoT process shown\nin the bottom right of Figure 4. While the second nested\ngraph contains some node titles also seen in the first, it\nis unlikely that these repeat the same information because\nthe second nested graph is already informed by the answer\nfrom the first, via the edge from (0,0) to (1, 0). Instead,\nthe second nested graph is interpreted according to its parent\ncomplex node, as a subsequent iteration of the synthesis\nprocess to review and extract the key insights.\n\nThe final layer is \"layer 2\". Here, the thought contained in\nnode (2,0) is generated immediately after completion of\nthe second nested graph. As the final node, its answer is the\noverall answer to the original input query. From Figure 4 we\nsee that (2,0), informed by the entire graph preceding its\nown topological generation, has correctly determined that a\ncomoving distance of 8 Gpc."}, {"title": "4. Implementation and testing methodology", "content": "Our implementation of AGOT utilizes an asynchronous\nLLM client and various instructions and response schemas\nto create the mappings (8)-(13). Among these com-\nbinations, each (model, instruction, schema)\ntriplet equivalently comprises an \"AI agent\" with a specific\n(though not necessarily unique) interface and a directive to\nimplement one of the mappings (8)-(13). With the mappings\non hand, Algorithm 1 provides an exact definition for AGOT.\n\nWe used the gpt-40-mini model\nby OpenAI for all experiments in this work, including\ndirect input-output (IO), CoT, AIoT, and AGoT. This\nmodel was accessed using an asynchronous chat client\nfrom the open-source openai-python package, setting\ntemperature=0.3 for generation with AGoT and using\nthe default settings otherwise. AGoT settings for $d_{max}$,\n$I_{max}$, and $n_{max}$ were set to 1, 3, and 3, respectively, for\nall experiments. While these values were found to produce\na satisfactory balance of computation time to performance,\nwe do not assert them as optimal here.\n\nBefore proceeding to our results, we emphasize that, unlike\nsome existing inference frameworks (Ning et al., 2024; Zhu\net al., 2024; Wang et al., 2024b), AGoT is neither tailored\nfor any specific task nor pre-trained at all on any specific\ndataset."}, {"title": "5. Results", "content": "This section details the outcomes of our benchmarking\nexperiments. We tested AGoT on several datasets designed\nfor reasoning, retrieval, and explorative abstract problem\nsolving, finding better or significantly better performance\non each, as compared to IO, CoT, and AIoT. Results on\nThe Game of 24, which is a set of small, challenging\nproblems on arithmetic operations, show AGOT reaching an\naverage accuracy of 50% on the 20 hardest puzzles, yielding\nan improvement of +400% from over direct IO. This and\nthe remaining results are discussed in the subsections that\nfollow."}, {"title": "5.1. Reasoning", "content": ""}, {"title": "5.1.1. GPQA", "content": "GPQA Diamond (Rein et al., 2023) consists of 198 highly\n-technical multiple-choice questions. Their systematic\nanalysis reveals that conventional evaluation methods using\nfixed answer positions may not accurately reflect a model's\ntrue reasoning abilities, necessitating controlled experiments\nthat account for positional bias. Following this insight, we conducted GPQA experiments"}, {"title": "5.1.2. GPQA COMPARISONS", "content": "Noting empirically the importance of shuffled versus un-\nshuffled answer positions, and for clarity in references to\nother works, we denote the default global \"main set\" of\nGPQA questions by GPQA0; the GPQA Diamond subset\nby GPQAD; and our Shuffled GPQA Diamond subset by\nGPQAS."}, {"title": "5.2. Retrieval", "content": "Our benchmarks in the retrieval category cover three\nmulti-hop datasets, namely HotpotQA , MoreHopQA (Schnitzler et al., 2024), and HybridQA (Chen\net al., 2021). In addition to exact match (EM) and F1\nscores, we report for this category an LLM-assisted accuracy\nscore (LAAS) obtained by requesting a binary response that\nindicates the semantic equivalence of two input strings. This\nmetric is implemented under the reasonable assumption\nthat gpt-40-mini is capable of highly accurate text\nclassification in this setting. For example, the strings\n\"12-16-1770\" and \"12-16-1707\" are almost iden-\ntical but not LAAS equivalent, whereas \"12-16-1770\"\nand \"16 December, 1770\" are in fact LAAS equiva-\nlent, given they represent the same date. For consistency\nand validation, the LAAS metric is reported for all inference\nframeworks alongside EM and F1 in Table 3. We find that\nAGOT produces significantly better LAAS scores across\nall three retrieval datasets, while EM scores are most often\nhighest for IO, and F1 scores are most often highest for\nAIoT (Radha et al., 2024). The remainder of this subsection\ndiscusses results on each retrieval benchmark in greater\ndetail."}, {"title": "5.2.1. \u041d\u041e\u0422\u0420OTQA", "content": "This dataset contains multi-hop questions based on\nWikipedia content across various domains. Here, we report\nresults on a random sample of 100 \"hard multi-hop\" questions from HotPotQA. We note that\nprevious work has achieved top accuracy of 81% (Gao\net al., 2024) over the entire dataset (i.e. with nominally\neasier questions on average) whereas AGoT achieves 80%\naccuracy on a subset of only nominally hard problems.\nLooking at EM and F1 scores, direct reasoning and retrieval-\naugmented reasoning models have previously yielded top\nscores of 45% and 57.3% (Li et al., 2025), respectively,\nwhereas AGoT with gpt-40-mini achieves 51% and\n76.2% on EM and F1 in this work."}, {"title": "5.2.2. MOREHOPQA", "content": "This dataset is similar to HotpotQA, except it emphasizes\na more generative approach instead of pure retrieval. To\navoid encouraging the test subject to pick correct answers\nfrom the context or to simply recombine contextual infor-\nmation into a correct answer, clues for each question in\nMorehopQA must be \"understood\" in order to synthesize\nrelevant information that informs the correct answer. (See\nSchnitzler et al. (2024) for examples.) Based on results in\nTable 3, MorehopQA is more challenging than a random\nsample of 100 nominally \"hard\" HotpotQA questions and\ncorresponds to the lowest retrieval scores overall, for all\ninference frameworks considered.\n\nIn terms of LAAS, performance improves monotonically\nwhen comparing IO to CoT to AIoT to AGoT. However,\nwhile both AIoT and AGOT significantly out-perform\nthe former two methods, the difference between them is\nmarginal on MorehopQA, with AGoT performing slightly\nbetter at 72% versus 70% for AIOT. The LAAS score for\nAGOT on MorehopQA also represents the largest margin of\nimprovement over direct IO across all three retrieval tasks\n(see Table 2). Regarding EM and F1 scores, performance\ndifferences between AIoT and AGoT are again marginal,\nwith AIoT performing slightly better."}, {"title": "5.2.3. HYBRIDQA", "content": "This final multi-hop dataset contains both\nstructured and unstructured data from Wikipedia articles,\nincluding data tables as well as text passages. HybridQA,\naccordingly, places a stronger emphasis on the subject's\nability to parse data presented in formats other than natural\nlanguage. On this dataset, EM, F1, and LAAS scores\nwere highest for IO, AIoT, and AGoT respectively, with\nCoT yielding a negative improvement. The LAAS score\nfor AGOT was its highest overall across all datasets in the\nretrieval category, and second-highest in terms of relative\nimprovement versus direct IO."}, {"title": "5.3. Explorative datasets", "content": "We use the term \"explorative\" to denote tasks that are\nexpected to benefit from combinatorial searches and explicit\nconsiderations of multiple alternatives. In this work, we\nconsider a Game of 24 dataset and a mini-crosswords dataset\nfor testing AGoT in an explorative setting. Solutions here\nare represented by one of many combinations of arithmetic\noperations on a set of integers (Game of 24) or one of\nmany combinations of intersecting alphabetic characters\n(Mini-crossword). Both datasets are considered challenging\nfor LLMs because they subvert typical natural language\nprocessing goals due to their character-wise processing\nrequirements. Despite this, we recognize good performance\non such datasets to be essential for true general-purpose\nreasoning with LLMs. Results on Game of 24 and Mini-\ncrosswords are discussed in the remainder of this subsection."}, {"title": "5.3.1. MINI-CROSSWORDS", "content": "This dataset contains small, generic crossword puzzles.\nEach puzzle includes a list of clues corresponding to\nintersecting horizontal and vertical words, as usual. Note\nthat crossword solution is necessarily explorative due to\ndependencies between words. Individual word clues do not\nnecessarily suggest unique solutions per se, such that two or\nmore possible answers may appear equally valid throughout\nthe came. In other words, solution uniqueness is enforced\nholistically in crosswords, so (at least for human solvers)\nconsidering alternatives along the way is a necessity.\n\nFollowing Yao et al. (2024), we consider both latter and\nword accuracy to grade performance on mini-crosswords.\nLetter accuracy is computed as the number of letters in\nthe answer whose identity and position are in agreement\nwith the known solution, divided by the total number of\nletter positions. We also report the word accuracy as the\nnumber of words in the answer whose positions agree with\nthe known solution. Note that a perfect word accuracy\nimplies a perfect letter accuracy and vice versa. However,\nletter accuracy is still a weaker measure in this setting, since\nhigh letter accuracy does not imply high (or even non-zero)\nword accuracy.\n\nOur results in Table 2 indicate that both AIoT and AGOT\nlead to much better performance on mini-crosswords, with\nover +80% and +340% improvements in letter and word\naccuracy, respectively, compared to direct IO. Notably, the\nimprovement margin is much larger for AGoT. Improve-\nments were also significant for CoT over direct IO, though\nboth AIoT and AGoT score significantly better still. In\nabsolute terms, however, solution accuracy is low across the\nboard. Overall, AGoT achieved the highest letter and word\naccuracies of 34.7% and 11.1%, respectively.\n\nRecall that AloT is a dynamic in-\nference framework based on iterative dialogue and self-\nreflexive guidance. AGoT, while also dynamic, is more\nstructurally sophisticated and designed specifically for\ndecomposition. Based on their near-identical performance\non mini-crosswords, we are unable to infer that AGOT\nis especially adaptable to solving mini-crosswords. The\npossibility therefore remains that any sufficiently persistent\nframework can yield a relatively large baseline improvement\nfor this task."}, {"title": "5.3.2. GAME OF 24", "content": "A single instance of Game of 24 involves finding a\ncombination of unique arithmetic operations that, when\napplied to a specific set of 4 integers, produces an expression"}, {"title": "6. Discussion", "content": "Our results indicate that AGoT is significantly more accurate\nthan IO and CoT, and as or more accurate than AIoT across\nevery task considered. AGoT dominates most strongly\namong tasks in the reasoning category, followed by the\nretrieval category (where LAAS is employed as the accuracy\nmeasure). An interesting caveat is the apparent saturation\nof accuracy values across frameworks for unshuffled GPQA\nDiamond for which the first multiple-choice\nanswer is always correct by default. Among the tests\nconducted, the unshuffled GPQAD was the only case where\ndirect IO was the runner-up to AGOT, outperforming both\nCoT and AIoT. Comparing direct IO results for the shuffled\nand unshuffled cases then suggests a strong in-built bias\nfor answering GPQA Diamond questions with the first\nmultiple-choice option. However, due to the proprietary\nnature of the model, we can not verify conclusively whether\ngpt-40-mini or gpt-40 was exposed to GPQA Dia-\nmond questions (in their default, unshuffled state) during\ntraining.\n\nAGOT produces much better results than AIoT in the\nGame of 24, despite doing only marginally better on the\nmini-crossword task. In both these tasks, correctness\nhinges on the position of individual characters in the final\nresponse. However, Game of 24 concerns exclusively\nsymbols and numeric characters, whereas Mini-Crosswords\nconcerns alphabetic letters. We therefore speculate that the\nextensive natural language training of LLMs (together with\nestablished approaches for text tokenization) can introduce\na detrimental bias with respect tasks like mini-crosswords\nsolution that feature non-horizontal arrangements of com-\nmon words. On the other hand, this bias would be absent\nfor mathematical puzzles like Game of 24, which do not\ninvolve any text re-orientation.\n\nBecause recursion in AGoT is triggered by complexity\nchecks (as per Equation 11 and Algorithm 1), the proportion\nof \"complex nodes\" in an solution serves as a proxy for the\nperceived conceptual difficulty of a given task. Figure 6\nindicates that Game of 24, followed by GPQA and Mini-\nCrosswords, produced the three highest proportions of\ncomplex nodes, thus distinguishing non-retrieval tasks as\nthose warranting the greatest degree of decomposition. The\ntrend in total nodes (complex or otherwise) is the same, since\nthe presence of complex nodes (due to spawning nested\ngraphs) encourages a greater number of nodes overall.\n\nIn terms of average accuracies across the task categories,\neach framework is most accurate in the retrieval category,\nfollowed by reasoning, and finally explorative tasks. In\nterms of average relative improvement over IO, Figure 5\nclearly highlights AGoT as having the greatest positive\neffect. Due largely to Game of 24, the average score in the\nexplorative category represents the largest individual relative\nimprovement for AGOT. We infer from these results that\nthe AGOT, as a general-purpose framework, significantly\nimproves the reasoning, retrieval, and explorative problem\nsolving capabilities of the underlying LLM."}, {"title": "6.1. Directions for future work", "content": "It is not our intention to assert that our specific implementa-\ntion of AGOT, based on the core definition in Section 2, is\nby any means optimal. That is to say, any implementation of\nAlgorithm 1 together with an LLM-based implementation"}, {"title": "7. Conclusion", "content": "In this work, we introduced an Adaptive Graph of Thoughts\n(AGoT), demonstrating that careful structuring of the\ninference process can match the benefits of computationally\nintensive RL-based reasoning training methods. Using a\nvariety of benchmark datasets, we demonstrated AGoT's\nsuperior performance in reasoning, retrieval, and explorative\nproblem solving (see Tables 2 and 3 for summary of\nresults) in comparison to existing methods. In contrast with\nsome recent dynamic inference frameworks (Ning et al.,\n2024; Zhu et al., 2024; Wang et al., 2024b), these results\nare achieved in AGoT without pre-training, algorithmic\ntailoring, nor hyper-parameter optimization for any specific\ngoal. In particular, AGoT improves reasoning with gpt-40\nand gpt-40-mini by relative margins comparable to base\nmodel distillation with DeepSeek-R1 (DeepSeek-AI et al.,\n2025).\n\nCompared to our previous work on AIoT (Radha et al.,\n2024), results on GPQA indicate that\nAGOT exhibits significantly better reasoning in comparison.\nSimilarly, results on Game of 24 indicate that AGoT is\napproximately twice as effective as AIoT at mathematical\npuzzle solving. AGoT's performance on mini-crosswords,\nhowever, showed no significant improvement, which sug-\ngests a potential blind spot in the approach of both methods.\nDespite the large relative improvement, datasets in the\nexplorative category yielded the lowest absolute scores (see\nFigure 5), remaining a challenging category of tasks for\nLLMs (see Figure 6).\n\nAs a framework for high-level LLM interaction (Radford\net al., 2024; Zhuang et al., 2024; Sun et al., 2024) AGoT's\nperformance benchmarks correlate strongly with the capa-\nbilities of the underlying model(s) that execute its crucial\nactions (8)-(13). With OpenAI's gpt-40-mini (OpenAI,\n2024), we found that AGoT provides, relative to direct\ninference (IO), an approximate +30% performance boost\nin reasoning, +22% in retrieval, and a whopping +277%\nfor explorative problem solving, on average. With the\nlarger gpt-40, reasoning performance improved even\nmore, approximately +46%.\n\nThe key advantage of AGOT lies in its ability to achieve\nthese improvements through dynamic decomposition and\nstructured recursion, rather than through computationally\nexpensive model modifications. This approach provides\na more accessible path to enhanced LLM performance,\nparticularly valuable in resource-constrained settings or\nwhen model fine-tuning is impractical. As LL"}]}