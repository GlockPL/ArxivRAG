{"title": "Can Large Language Models Logically Predict Myocardial Infarction? Evaluation based on UK Biobank Cohort", "authors": ["Yuxing Zhi", "Yuan Guo", "Kai Yuan", "Hesong Wang", "Heng Xu", "Haina Yao", "Albert C Yang", "Guangrui Huang", "Yuping Duan"], "abstract": "Background: Large language models (LLMs) have seen extraordinary advances with applications in clinical decision support. However, high-quality evidence is urgently needed on the potential and limitation of LLMs in providing accurate clinical decisions based on real-world medical data.\nObjective: To evaluate quantitatively whether universal state-of-the-art LLMs (ChatGPT and GPT-4) can predict the incidence risk of myocardial infarction (MI) with logical inference, and to further make comparison between various models to assess the performance of LLMs comprehensively.\nMethods: In this retrospective cohort study, 482,310 participants recruited from 2006 to 2010 were initially included in UK Biobank database and later on resampled into a final cohort of 690 participants. For each participant, tabular data of the risk factors of MI were transformed into standardized textual descriptions for ChatGPT recognition. Responses were generated by asking ChatGPT to select a score ranging from 0 to 10 representing the risk. Chain of Thought (CoT) questioning was used to evaluate whether LLMs make prediction logically. The predictive performance of", "sections": [{"title": "Introduction", "content": "The application of large language models (LLMs) in the medical fields has attracted much attention in the past few months. Consisting of more than billions of weights [1], state-of-the-art LLMs represented by ChatGPT and GPT-4 performed well in recommendation and extraction tasks in cardiovascular disease prevention [2], infectious disease surveillance [3] and neoplasm survival prediction [4] due to its advantages in processing natural languages. However, the applicability of these large models in clinical decision support (CDS), especially providing clinical diagnosis, requires in-depth understanding on real-world medical data, not just generalized medical knowledge. Moreover, the accountability and ethics of LLMs are under widespread doubts and debates [5]. Whether these large models are possible to logically provide accurate clinical diagnosis remains unverified. Therefore, high-quality evidence is urgently needed to evaluate the quantified performance of medical LLMs objectively and clarify their limitations comprehensively with well-designed experiments [6].\nMyocardial infarction (MI) is an event of myocardial injury resulted from an imbalance between oxygen supply and demand in which early diagnosis and intervention is critical [7]. Models using statistical methods or artificial intelligence (AI) algorithms have been built to estimate the risk of MI based on structured datasets of clinical symptoms, medical history and biomarkers [8]. Comparatively, LLMs, with the ability to comprehend natural languages and thus in-context learning medical domain knowledge, is providing a novel user-friendly way in MI prevention [9]. Here, we evaluated the predictability of ChatGPT and GPT-4 on the risk of MI during health consultations with prompts constructed from the UK Biobank dataset, and validated the logical inference ability utilizing the Chain of Thought (CoT), hopefully to provide evidence for the potential and limitation of LLMs in CDS tasks."}, {"title": "Methods", "content": "Data Source and Study Population\nThis is a retrospective cohort study using the UK Biobank database. UK Biobank is a large-scale biomedical database with over 500,000 participants from England, Wales, and Scotland aged between 40 and 69 [10], with approval from North West Multi-Center Research Ethics Committee renewed in 2021. The study followed the Strengthening the Reporting of Observational Studies in Epidemiology (STROBE) reporting guideline [11].\nFor the current study, 502,468 participants were originally recruited from 2006 to 2010, up until 2018. Participants without MI incidence at baseline were originally included, in which those without missing data on basic information. For participants with MI incidence, only those with at least one typical symptom"}, {"title": "Myocardial Infarction Predictors and Outcome Definition", "content": "Common risk factors of cardiovascular diseases were selected for modeling [12]. Predictors include patient demographics, common symptoms, personal history and family history, together with past medical history including comorbidities, medications and laboratory examinations (See Supplementary Appendix eMethod 1). MI was defined following the International Classification of Disease (ICD) with ICD-10 code I22 or ICD-9 code 412 [13]."}, {"title": "Prediction Based on ChatGPT", "content": "GPT models, represented by ChatGPT and the more advanced GPT-4, have been widely recognized for their ability to generate text of human-like quality on various topics [14]. In medical consultation, ChatGPT provides longer responses to medical health questions compared to doctors with significantly higher quality and empathy [15]. Building upon this, GPT-4 has further enhanced these capabilities, offering more precise and contextually nuanced responses in medical discussions.\nWe evaluate both ChatGPT and GPT-4 in their predictability on the risk of myocardial infarction (MI) logically with a series of experiments. The corresponding tabular data of the selected relevant risk factors were first transformed into textual descriptions for identification. Specifically, envisioning ChatGPT and GPT-4 as doctors, we request ChatGPT and GPT-4 to select a score ranging from 0 to 10, representing the closest to estimate MI risk (see Supplementary Appendix eMethod 2).\nFirstly, we evaluated the general performance of ChatGPT and GPT-4 with prompts given complete information. Secondly, to further validate whether ChatGPT and GPT-4 make predictions logically, CoT prompts were designed where information used for questioning were given in a stepwise order. Group1 models use basic information and symptoms. Group2 models add personal habits to the inquiry. Group3 models further include family history, building"}, {"title": "Model Comparison", "content": "We compared ChatGPT and GPT-4 with three classes of models, namely, medical indices, machine learning models and other representative natural language processing (NLP) models (see Supplementary Appendix eMethod 3). The traditional machine learning models used for comparison include Decision Tree, Logistic Regression, Random Forest, and Support Vector Machine (SVM). Transformer is the mainstream architecture in current NLP models on which Bert and GPT series of models were developed. Our study reported on current NLP models, such as the base Transformer [16] and BERT [17] to analyze the accuracy of mainstream NLP models in medical diagnosis. In addition, we expanded our study to include open-source large language models (LLMs) such as Llama [18] and Mixtral [19]. We also conducted extensive evaluations of models fine-tuned on medical-specific corpora, including MedLlama [18] and Meditron [20], which were instruction-tuned for medical applications. We fine-tuned the aforementioned NLP models on the same textual data posed to GPTs to provide predictions for myocardial infarction in the interviewees, and compare with ChatGPT and GPT-4. Furthermore, indices built by Jee [21] and Wilson [22] were adopted as baseline evaluation model."}, {"title": "Statistical Analysis", "content": "Continuous variables were expressed as median (IQR), and categorical variables were expressed as numbers (percentage). For each model, receiver operating characteristic (ROC) curves and area under curve (AUC) were used to evaluate model discrimination. Accuracy, precision, sensitivity and specificity were estimated based on confusion matrix at classification threshold selected by maximization of Youden Index, representing the predictive performance of the model. The statistical tests were two-tailed with a=0.05 regarded as statistically significance. Analyses were conducted with R, version 4.1.2 (The R Foundation for Statistical Computing) and PyTorch, version 1.10.0 (The Linux Foundation) performed on a server with 4 NVIDIA RTX 3090 GPUs."}, {"title": "Results", "content": "Characteristics of Study Population\nAmong the primary cohort of 132,008 individuals in this study, 655 participants occurred with MI during follow-up. Descriptive statistics is shown found in Table 1."}, {"title": "Performance of GPTs", "content": "When provided with complete patient descriptions, the overall performance of ChatGPT in the prediction of myocardial infarction is not as well as expected, with AUC of 0.62 (95% CI: 0.58~0.66, Figure 1), only marginally better than the random chance. GPT-4, a more advanced version, is significant outperformed than that of ChatGPT, with AUC of 0.69 (95% CI: 0.65 \u2013 0.73, Figure 1), suggesting that updated model architecture have enhanced its ability to accurately predict myocardial infarction.\nUnder optimized threshold, ChatGPT predicts MI with accuracy of 0.59 (95% CI: 0.55~0.63, Table S1), similar to the indices provided by Jee (0.581, 95% CI: 0.579~0.583, Table S3) and Wilson (0.597, 95% CI: 0.596~0.599, Table S3), yet significantly lower than that of GPT-4 (0.65, 95% CI: 0.62~0.69, Table S2). GPT-4 shows similar sensitivity to the indices, all significantly higher that of ChatGPT, yet its specificity was the lowest in all models (see Figure 4). Therefore, both ChatGPT and GPT-4 are limited in predicting MI incidence, while GPT-4 was relatively more sensitive. Together, ChatGPT and GPT-4 shows a weak performance that is merely better than \"guessing\" the result in predicting MI with problems probably due to model architecture rather than data."}, {"title": "Performance of GPTs under Chain of Thought", "content": "To test whether the predictions of ChatGPT and GPT-4 are generated logically, an experiment was designed using CoT questioning. The comparison between ChatGPT and GPT-4 for myocardial infarction prediction reveals clear differences in performance across both models. The CoT approach, where information was progressively added through a series of questions, resulted in lower AUCs compared with that given complete information. In the case of ChatGPT, CoT groups has AUCs between 0.56 and 0.58 (Group 1: 0.56, 95% CI: 0.52~0.61; Group 2: 0.56, 95% CI: 0.52~0.60; Group 3: 0.58, 95% CI: 0.54~0.62, Figure 2A, Table S1), and GPT-4 witnesses slightly better but still modest improvements, with AUCs between 0.60 and 0.61(Group 1: 0.61, 95% CI: 0.57~0.65; Group 2: 0.60, 95% CI: 0.56~0.64; Group 3: 0.60, 95% CI: 0.56~0.65, Figure 2B, Table S1). Therefore, CoT questioning approach yields no substantial improvements in predictive accuracy, indicating that simply expanding the scope of the inquiry in a stepwise fashion does not result in enhanced model accuracy. The direct use of all available information in one query outperforms the CoT method, particularly for GPT-4, suggesting less logical in the prediction process of ChatGPT and GPT-4."}, {"title": "Model Comparisons", "content": "Finally, we compared GPT models (GPT-4 and ChatGPT) with traditional machine learning models (e.g., decision tree, logistic regression, random forest and SVM), other mainstream NLP models (e.g., Transformer, BERT), as well as open-source"}, {"title": "GPT Models vs Traditional Machine Learning", "content": "We compared GPTs with existing machine learning models. AUCs of ChatGPT and GPT4 are significance lower than that of machine learning models (Decision tree: 0.79, 95% CI: 0.76~0.83; Logistic regression: 0.77, 95% CI: 074~0.81; Random Forest: 0.76, 95% CI: 0.73~0.80; SVM: 0.79, 95% CI 0.76~0.83, Figure 3A). Under optimized threshold, GPTs is predicting less accurate than machine learning models (Decision tree: 0.78, 95% CI: 0.74~0.81; Logistic regression: 0.77, 95% CI: 0.73~0.80; Random Forest: 0.77, 95% CI: 0.74~0.80; SVM: 0.78, 95% CI: 0.75~0.81, Figure 4) with significant discrimination (Figure 4, Table S4). This result indicates that data-driven machine learning models such as SVM and decision tree have achieved a certain level of clinical diagnostic capability. In contrast, GPTs, especially ChatGPT, only outperform random guessing in overall accuracy and exhibits a significant difference compared to machine learning models trained on external datasets."}, {"title": "GPT Models vs. Traditional NLP Models", "content": "GPT-4 with compete information achieves the highest AUC of 0.69 (95% CI: 0.65-0.73), showing superior performance compared to all other models in this set. ChatGPT with complete information has a moderate AUC of 0.62 (95% CI: 0.58 -0.66), outperforming traditional NLP models but falling short of GPT-4.\nBERT achieved an AUC of 0.57 (95% CI: 0.53 -0.61, Figure 3B, Table S5), while the Transformer model underperformed with an AUC of 0.51 (95% CI: 0.47 \u2013 0.55, Figure 3B, Table S5), approaching random prediction. This indicates that the GPT models, especially GPT-4, are better equipped for tasks requiring deeper understanding and reasoning, outperforming traditional NLP models like BERT and Transformer, which may struggle with complex predictive tasks due to their simpler architecture and training on general language tasks."}, {"title": "GPT Models vs. Open-Source Large Language Models", "content": "To confirm whether the performance of GPTs represent common features of large language models, other open source LLMs were also tested. GPT-4 with complete information again shows the best performance with an AUC of 0.69 (95% CI: 0.65 -0.73), indicating a notable lead over other large models. ChatGPT"}, {"title": "Discussion", "content": "In this retrospective cohort study based on UK Biobank database, the predictability of LLMs represented by ChatGPT and GPT-4 on MI, a common disease, has been evaluated and quantified. Given the importance of early diagnosis of MI, we set up a pre-clinical scenario to imitate real-world chats"}, {"title": "Limitations", "content": "This study has limitations. Firstly, the diagnosis of MI is \"the earlier the best\" [7], yet the time window of ChatGPT was selected as one year in the current study due to data limitations. Secondly, the diagnosis of MI usually requires an initial judgment of physicians, followed by in-depth examinations [7]. The current study focuses on pre-admission prediction, but clinically, this dynamic process should also be considered in evaluating the performance of LLMs. We also recommend that noise be appropriately added into the questioning session to validate the robustness of the results."}, {"title": "Conclusions", "content": "This study has set out to make quantified evaluation and comparative analysis on the predictive value of LLMs in a common CDS task based on a large-scale clinical cohort. LLMs represented by ChatGPT and GPT-4 are currently weak in making prediction logically with medical knowledge inferences, and thus are still not ready to be applicated in clinical medicine fields. However, future medical LLMs are suggested to develop large models that are expert in medical domain knowledge with the ability to understand both natural languages and quantified medical data, and make logical inferences towards the most accurate decision."}, {"title": "SUPPLEMENTARY METHODS", "content": "eMethod 1: Data Filtering and Resampling\nInclusion/Exclusion Criteria\nA total of 502,468 participants were first filtered under the inclusion/exclusion criteria. Subjects would be included if they meet with the following criteria:\n(1) Without MI incidence at baseline;\nAND\n(2) Recruitment within one year (365 days) before MI incidence;\nAND\n(3) Without missing data on basic information: i.e., age and gender.\nParticipants meet with the following criteria would be excluded to guard the quality of the dataset:\n(1) Lost of follow-up;\nOR\n(2) Dead at baseline.\nResampling\nA primary cohort have been built with UK Biobank participants filtered by the above inclusion/exclusion criteria, which turns out to be enough for the current study. However, some issues exist in the primary which might influence the result of the study.\nThe first issue is the unbalanced ratio of participants. Only 0.14% of participants were recorded to experience myocardial infarction incidence within the observation duration. This brings the probability that despite the model might predict all of the participants to have no myocardial infarction, it would still achieve an accuracy of 99.86%. Therefore, the primary cohort was further resampled to a secondary cohort to balance the proportion.\nThe second issue is the rate limit set by OpenAI API measured by RPM (requests per minute) and TPM (tokens per minute). Only 3 RPM and 40,000 TPM was allowed for free-trial users and 60 RPM and 60,000 TPM for Pay-as-you-go users when using the model gpt-3.5-turbo, generally known as ChatGPT. This limit also requires a smaller cohort to be constructed.\nThe final cohort was resampled from the primary cohort, in which sample size was estimated restrictedly. Index of participants were selected by random number generated by a given seed using Python.\nResample Size Estimation\nThe sample size of the final cohort was estimated based on sensitivity and specificity according to the formula widely used for diagnostic trials in epidemiology as follows:"}, {"title": null, "content": "n = u^2_a  x p x (1-p)/ \u03b4^2"}, {"title": null, "content": "where,\nn denotes sample size in each single group,\np denotes the probability in each group,\n$u_a$ is the quantile under significant level a,\n$\\u03b4$ represents absolute precision desired.\nWe used previous results as pre-experiment, where ChatGPT performed a sensitivity of 71% and a specificity of 42%. Under significant level a = 0.05 and precision level $\\delta$ = 0.05, a total of 316 participants were needed to be re-sampled from those with MI incidence, and a total of 374 participants from those without MI incidence. The proportion between MI and non-MI is thus 316/374=0.84. Therefore, 790 participants were finally sampled randomly."}, {"title": "eMethod 2: Prompt Generalization and ChatGPT Response", "content": "According to the selected risk factors for myocardial infarction, we divided the survey data into three groups and applied a chain-of-thought prompting approach.The first group focuses on the participant's basic information, symptoms, and medical history, establishing a foundational understanding. Building on this, the second group includes personal history, expanding the scope of inquiry. The third group further deepens the analysis by incorporating family history, completing the logical progression of information gathering.\nSecondly, we converted the tabular data of the participants provided by the UK Biobank into self-descriptions of the interviewed participants. Specifically, we simulated the participants describing their own interview situation in the first-person narrative form during a medical visit. For example, a 41-year-old White male with symptoms of \u201cwheezed or whistled in the chest in the last year\", blood glucose level of 7.812 mmol/L, diastolic blood pressure of 84 mmHg, systolic blood pressure of 144 mmHg, cholesterol level of 4.023 mmol/L, and a BMI of 21.212 kg/m\u00b2. We transformed the above information into the following question format to ask ChatGPT, following the relevant indicators defined by international medicine: \u201cI am a 41-year-old White male. I wheezed or whistled in the chest in the last year. I have diabetes, with a blood glucose level of 7.812 mmol/L. I have hypertension, with blood pressure of 144/84 mmHg. I do not have hypercholesterolemia. I do not have obesity.\u201d \nFinally, we asked ChatGPT to select a discrete value from 1 to 10 that it considers to be the closest estimate of the current risk factor of the interviewed participant having myocardial infarction. Other cases in ChatGPT questioning are shown in Figure S2."}, {"title": "eMethod 3: Model Comparison", "content": "Equation-Based Prediction Models (Medical indices)\nThrough selection, we applied two comparative models that included different risk factor indicators, as well as gender, race, and other information.\nWilson et al. developed gender-specific prediction equations for coronary heart disease (CHD) risk based on factors such as age, diabetes, smoking, JNC-V blood pressure category, and cholesterol. Jee et al. developed a CHD prediction model for Koreans and compared the estimated values of the model with actual CHD cases.\nNLP Models\nTransformer is a deep learning model architecture used for natural language processing (NLP) tasks, proposed by Vaswani et al. in 2017. It introduces the concept of self-attention mechanism to capture contextual information in input sequences and achieves parallel computation, replacing RNN as the main architecture of current mainstream NLP models.\nBert is a pre-trained language model based on the transformer architecture. It was introduced by Google in 2018 and utilizes a bidirectional context modeling approach. Traditional language models usually use unidirectional models from left to right or right to left, while BERT processes input sequences in a bidirectional manner using transformer encoders to better capture contextual information. This bidirectional modeling approach enables Bert to have better semantic understanding and representation capability when dealing with natural language tasks. The advantage of BERT is its ability to leverage a large amount of unlabeled data for pre-training, learning general language representations. Through fine-tuning, the parameters of the BERT model are further optimized, resulting in excellent performance on various downstream tasks.\nOther LLMS\nLLAMA is a series of large-scale autoregressive language models developed by Meta. LLAMA is designed to be highly efficient in terms of computational resources while achieving competitive performance compared to much larger models. It emphasizes scaling up model size while maintaining cost-effective training and inference through optimizations such as more effective parameter sharing and fine-tuned training techniques. LLAMA models are typically utilized for tasks in natural language understanding and generation, including question answering, summarization, and translation, and they have set benchmarks in terms of both accuracy and computational efficiency across various NLP tasks.\nMixtral is a specialized multilingual language model developed with a focus on low-resource languages. It leverages a mixture of translation data, linguistic knowledge, and pretraining on a wide variety of languages, both high-resource and low-resource. Mixtral's architecture allows for effective cross-lingual"}, {"title": "LLMs fine-tuning strategy", "content": "In this study, we used all datasets excluding the sampling part for fine-tuning. During training, the data was split 8:2 into training and validation sets. After fine-tuning, we tested the model on the sampled test, allowing us to evaluate its performance. We then compared its results on the same sampled test set with those obtained using ChatGPT and other methods, ensuring a consistent and fair comparison between models. We carried out The fine-tuning process on severe models. To ensure the validity of the model training, we maintained the original proportion of non-MI and MI samples in both the training and validation datasets. Each of the models was initialized using the pre-trained weights available from Hugging Face, ensuring that the models retained their previously learned knowledge from large-scale pre-training. To adapt these models for binary prediction tasks, we added a fully connected layer on top of the final output layer of each model. This additional layer was designed specifically for binary classification, consisting of a single"}]}