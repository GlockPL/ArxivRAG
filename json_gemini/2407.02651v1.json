{"title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition", "authors": ["Majeed Kazemitabaar", "Jack Williams", "Ian Drosos", "Tovi Grossman", "Austin Z. Henley", "Carina Negreanu", "Advait Sarkar"], "abstract": "LLM-powered tools like ChatGPT Data Analysis, have the potential\nto help users tackle the challenging task of data analysis program-ming, which requires expertise in data processing, programming,and statistics. However, our formative study (n=15) uncovered serious challenges in verifying Al-generated results and steeringthe AI (i.e., guiding the AI system to produce the desired output).We developed two contrasting approaches to address these chal-lenges. The first (STEPWISE) decomposes the problem into step-by-step subgoals with pairs of editable assumptions and code untiltask completion, while the second (PHASEWISE) decomposes theentire problem into three editable, logical phases: structured in-put/output assumptions, execution plan, and code. A controlled,within-subjects experiment (n=18) compared these systems againsta conversational baseline. Users reported significantly greater con-trol with the STEPWISE and PHASEWISE systems, and found interven-tion, correction, and verification easier, compared to the baseline.The results suggest design guidelines and trade-offs for AI-assisteddata analysis tools.", "sections": [{"title": "1 INTRODUCTION", "content": "Data science often involves large datasets, source code, domain ex-pertise, and unwritten assumptions [64]. The process of extractinginsights from data [90] for decision making and knowledge discov-ery [19] has several documented challenges [7, 64]. Data scientistsspend considerable time inspecting data, writing single-use scripts,\"gluing together\" data sources, cleaning messy data, and document-ing their efforts [7, 44, 45, 64]. In fact, data scientists describe theneed to \"have a conversation\" with their data to understand it [64].\nRecent advancements in AI and particularly the natural languageprocessing and code generation capabilities of Large LanguageModels (LLMs) have shown promise to facilitate data science tasks."}, {"title": "2 RELATED WORK", "content": "2.1 AI-assisted Data Analysis\nPrevious work has considered how data transformation scripts canbe synthesized from demonstrations (e.g., Wrangler [31, 39]), fol-lowing an influential line of research that synthesizes programs byexample in data wrangling contexts (e.g., [29]), which may includenatural language [30]. These can be constrained to use specific APIssuch as pandas, using generator-based synthesis (e.g., AutoPandas[4]). Scripts can also be synthesized based on heuristics of dataquality improvement (e.g, CoWrangler [8]), and data preparationheuristics can also be learned from corpora (e.g., Auto-Suggest[95]).\nMore recently, a number of commercialized LLM supporteddata analysis tools have become available. These enable data sci-entists to access AI-powered chat assistants within their notebook(such as Anaconda [1], Databricks [13], and Jupyter AI [36]), andother alternate data-science environments (e.g., DataChat AI [14],SQL and file editors for Databricks, etc.). The semantic abilities ofLLMs, coupled with a chat interface, allows conversational inter-action with data, follow-up questions, and highly contextualizedresponses. Consequently, research has investigated in detail thechatbot paradigm for AI assistance in data analysis and visualization[17, 27, 34, 41, 80, 101].\nThus, early work on data wrangling script synthesis can be con-trasted with current LLM-powered data analysis tools both in terms\nof the complexity of tasks being tackled, and the interaction modal-ity (i.e., from demonstration, examples, and direct manipulation, tonaturalistic language prompts). In turn, this also means that gener-ation mistakes become more common, due to underspecification ofnatural language, assumptions that the AI is making but the user isnot aware of, etc. This creates new metacognitive demands for theuser to verify the Al's responses and then steer the Al if incorrect.In our work, we try to provide new interaction modalities withLLMs for data analysis tasks to increase the transparency of the AIand the assumptions that it is making."}, {"title": "2.2 Verifying LLM Outputs and their Reliability", "content": "Data science is a challenging yet important function within soft-ware teams. Previous research has focused on how data scientistsengage in collaborative sensemaking, and make choices about howto communicate and report results [10, 47, 48, 67, 89, 100]. Theyhave found that data scientists need support in managing thesecomplex collaborative workflows [43, 45, 91]. Consequently, re-search has explored how data scientists can manage, visualize, andtrace the evolution of their analysis process [32, 42, 70, 93, 94]."}, {"title": "2.3 Steering LLMs", "content": "Research on the metacognitive demands of generative AI identifiesdecomposition and structured generation as potential aids [85]. Suhet al. [83] explore hierarchical text generation at different abstrac-tion levels to assist with sensemaking and managing informationoverload from large text quantities. They also introduce structuredgeneration [82], where user's prompt is first used to generate dimen-sions that make the model's responses vary, and then responsesare generated according to those dimensions. Additionally, Mas-son et al. [59] propose principles of direct manipulation for LLMs:continuous representation of objects of interest, physical actions tolocalize prompt effects, and reusable prompts.\nSpecifically in the context of AI-assisted programming, Liu andSarkar et al. [56] introduce \"grounded abstraction matching,\u201d al-lowing users to steer LLMs by editing natural language utterancesgrounded in each step of AI-generated code for data analysis inspreadsheets. Similarly, Tian et al. developed STEPS, which letsusers edit step-by-step explanations of AI-generated SQL code fromnatural language queries [86]. CoLadder [97] aids experienced pro-grammers in externalizing their problem-solving intentions flexibly,enhancing their ability to evaluate and modify code across various"}, {"title": "3 FORMATIVE STUDY", "content": "To understand the challenges involved in data analysis with con-versational Al assistants, we conducted a formative study with15 participants (12 male, 3 female). We used the Noteable pluginfor ChatGPT, providing a web-based computational notebook forcode execution. Users could input natural language (NL queriesinto ChatGPT, which would generate and send code to Noteable.Upon execution, Noteable returned the results to ChatGPT for fur-ther analysis and follow-up queries. At the time of study, ChatGPTwith the Noteable plugin was the only available tool offering fea-tures similar to those in ChatGPT Data Analysis (formerly CodeInterpreter).\nParticipants (F1-F15), who were recruited from our research insti-tute, regularly performed data analysis tasks using computationalnotebooks and Python data science libraries. Each participant wasassigned to one of four tasks commonly performed by data scien-tists: data cleaning, merging and plotting, extracting insights, ortraining an ML model (see Table 1).\nStudy sessions lasted approximately 60 minutes and were con-ducted in-person. Screen activity was recorded. Participants wereasked to think aloud [23], and audio data was recorded and tran-scribed. Participant consent was obtained prior to the study andparticipants were each compensated with a GBP \u00a325 Amazon giftcard. The study protocol was approved by our institution's ethicsand compliance review board."}, {"title": "3.1 Results", "content": "We analyzed the interactions participants had with ChatGPT andthe Noteable plugin from 301 total prompts. Participants used a mixof different actions which included (1) directing the AI to perform adata analysis task, (2) exploring the dataset, (3) requesting suggestedmethods or approaches to accomplish the task, (4) steering andrepairing the Al process in how it should accomplish the task, and(5) performing verification on the results of the task (either with orwithout the AI).\nSteering: Participants steered the Al's actions and methods usingtheir NL prompts (106 prompts, 35%). Many of the steering prompts(n=34) were for performing data wrangling (cleaning and manip-ulation) tasks on specific columns of the dataset. Similarly, someprompts (n=20) were used to explicitly add, remove, or change codeproduced in previous steps (e.g., \"exclude the ones that arepurely categorical\" (F5)). For repairing mistakes the AI made or"}, {"title": "3.2 Design Goals and Rationale", "content": "Based on our formative study, relevant prior work, and how suchAI tools use Chain-of-Thought prompting for task decompositionand execution, we identified the following design goals to improveuser and control over the AI-assisted data analysis process.\nDG.1 The system should visually distinguish assumptions that theAl is making, and contrast them from their corresponding actions.\nDG.2 The system should allow users to edit, modify, and updatethe Al's assumptions and actions.\nDG.3 The system should provide various intervention points forthe user to understand and edit the Al's reasoning."}, {"title": "4 SYSTEM DESIGN", "content": "We address design goals DG.1 and DG.2 through interactive taskdecomposition. This involves: (1) Prompting the LLM to generateits chain-of-thought reasoning as assumptions and correspondingactions about the input task and dataset; and (2) parsing and ren-dering LLM output as structured, editable UI components, allowing"}, {"title": "4.1 Core System Features", "content": "4.1.1 Task Input. Data analysis begins with dataset(s) and a taskspecification. Dataset Input: Data is loaded using the Input Queryinterface (Figure 2, a). Users can then select one or more datasetsrelevant to the task (Figure 2,6). The Python server generatesa summary of each selected dataset with sample values for allcolumns. This summary is passed to the LLM to build its initial setof assumptions for the data analysis task."}, {"title": "4.1.2 Task Decomposition: PHASEWISE System", "content": "Using the summaryof the dataset and the user-specified task description, the PHASE-WISE System decomposes the task into three phases: Input andOutput assumptions, Execution Plan, and Code and Output.\nA) Input and Output Assumptions: After loading a dataset (Figure3,a), this component displays all the columns that the AI foundto be relevant to the task, and for each column it displays severaleditable assumptions regarding the task (Figure 3, 6). Assumptionscan pertain to data type, uniformity, units, sorting order, etc. Userscan delete columns they find unrelated to the task, or add columnsthat the AI incorrectly did not select (Figure 3, d). Within eachcolumn, users can edit, add, or remove assumptions for that column(Figure 3,6). For each column, users can \"inspect\" descriptive sta-tistics (Figure 3,), including a frequency table of sample values forcategorical columns. Additionally, the entire dataset can be viewedby clicking on the \"open\" button, with the selected columnshighlighted to help the user leverage the columns to build up as-sumptions. Finally, the task's output assumptions can be viewedand changed to edit, add, or remove assumptions to steer the finaloutput (Figure 3,6).\nB) Execution Plan: Using the assumptions, including edits, thesystem generates a list of natural language steps for solving the task(Figure 3,1). Steps are editable and the user may add or removesteps. The model is also prompted to include optional steps that arerendered as selectable steps with a checkbox (Figure 3, 3). Afterthe user is satisfied with the plan, they can proceed to generatingand running the code.\nC) Code and Output: Here the AI generates code to solve thetask based on the previous two components. The code is immedi-ately executed and displayed in an editor to allow modification andre-execution (Figure 3, h). Users can inspect the dataframe andvariables used in the code execution (Figure 3, 1), and see the codeoutput (Figure 3, j"}, {"title": "4.1.3 Task Decomposition: STEPWISE System", "content": "Unlike the PHASE-WISE System where each component reflects the entire task, theSTEPWISE system decomposes the task into subgoals, which haveintermediate objectives. Each subgoal (except the first, which loadsthe dataset (Figure 4, )), is represented as a pair of components:Subgoal Assumptions and Actions, and Subgoal Code and Output.\nA) Subgoal Assumptions and Actions: Each subgoal starts with ashort description of its objective in natural language, followed byseveral assumptions and actions based on the dataset or previoussteps (Figure 4, 6). We designed LLM prompts so that each subgoalwould focus on one specific objective such as pre-processing data,filtering columns, performing calculations, and displaying plots.Users may reorder assumptions and actions, add or remove assump-tions, and edit them directly. Once the user is satisfied with them,they can proceed to generate the subgoal code and output.\nB) Subgoal Code and Output: Similar to Code and Output in thePHASEWISE System, in this component, the system generates codeto solve the task based on the previous assumptions and actions(Figure 4,). The code is immediately executed and can be edited.Once executed, the system generates the next subgoal to allow theuser to either reflect on the current subgoal or start working onthe next. This process continues until the task is finished and therequirements have been satisfied, in which case the next Subgoal"}, {"title": "4.1.4 Editable LLM Assumptions and Actions", "content": "We prompted theLLM to generate each assumption paired with its corresponding ac-tion in the format of <assumption> <action>. We also promptedthe LLM to enclose column names, variables, and keywords in"}, {"title": "4.1.5 Code Execution and Intermediary Variables", "content": "The Pythonserver runs the AI-generated code and returns any outputs, in-cluding text, visualization plots, or any errors. Any variables anddataframes created during execution are displayed as intermediaryvariables that the user may inspect.\nInspect Intermediary Variables: users can click on each intermedi-ary variable to open a full-screen window for inspecting its values.For dataframes, the interface includes a string matching filter toassist users in finding specific values."}, {"title": "4.1.6 Managing Edits", "content": "Within each component, edits can be eitherpending or submitted. A submitted edit means that the edits havebeen applied to generate the next component, whereas a pendingedit has not. Pending edits can be reverted using an undo button.However, once an edit is submitted, our system introduces a newbranch to preserve the original, unedited version, while incorpo-rating the edited version in the \u201cmain\u201d branch. New branches aredisplayed in a tabbed ribbon at the top of the UI. To allow iterationwhile minimizing proliferation of branches, new branches are notcreated when the user edits the last generated component in thestream of components. Branching allows users to keep track ofprevious edits and switch between edits as needed."}, {"title": "4.1.7 Side Conversations", "content": "We allocated space to the right of themain components for running side conversations with the systemin three formats: Ask Question, Generate Code, and Run Side Query.These features are available in all editable code execution blocks,with the exception of Run Side Query, which is also accessiblealongside the Input and Output Assumptions in the PHASEWISE AIsystem.\nAsk Question: This allows users to ask questions about the gen-erated code (See Figure 5). When a code editor is in focus or code isselected, the Ask Question button appears to the right of the editor.The user can provide a natural language query and the systemgenerates a response on the side. The selection allows users to asktargeted questions such as \"what does this function do?\"\nGenerate Code: This feature generates code based on the selectedcode segment and the user's query. The user can inspect the gener-ated code and, if it is found useful, insert it into the editor. Similar to"}, {"title": "4.2 CONVERSATIONAL Baseline System", "content": "We developed a CONVERSATIONAL system similar to ChatGPT'sAdvanced Data Analysis plugin as a baseline to compare with thePHASEWISE and STEPWISE Systems. The CONVERSATIONAL systemdoes not include any intervention points or editable assumptions, orany of the side conversation features (e.g. Ask Question or Run SideQuery). It decomposes the task into a bullet point of non-editable,natural language assumptions and actions about the task, and thenimmediately generates and runs non-editable code that solves theentire task. To interact with this system, as with ChatGPT, theuser needs to issue follow-up prompts. In this baseline system onlythe prompts (and follow-up prompts) are editable. For verification,users could read the code and inspect the intermediate variables,"}, {"title": "4.3 System Implementation", "content": "All three variants are built as a web application and Python serverstack. The web application is written in TypeScript and the Reactweb framework to include the interface elements described in Sec-tion 4.1. The web application interacted with the Python server foruploading datasets, obtaining their descriptive summaries, runningcode, and retrieving their execution results. It also called the GPT-4Turbo models from OpenAI. Each component in the PHASEWISEor STEPWISE System is represented as a node in a tree data struc-ture inside the application. This enables tracing the path from eachnode to the root node to prepare the context prompt for interactingwith the LLM and generating the next component. It also providesstate management for the edits that create branches and is used torender the tabbed ribbon interface. The Monaco Editor is used asthe code editor in each of the code execution blocks and for syntaxhighlighting the non-editable code pieces. To enable stateless codeexecution on the Python server, and to retrieve code executionoutputs and intermediary variables, we used the IPython kernel.We used the \\%matplotlib inline command which returned allplots as base64 images that could be included as a response inside\nthe REST APIs."}, {"title": "4.3.1 LLM Prompt Structures", "content": "We required complete control overthe format of the LLM's output to allow reliable parsing and ren-dering of structured components. However, few-shot learning (e.g.providing specific input and output examples) would make theLLM overfit to the provided few-shot examples. Through informalexperimentation with different prompts and models, we concludedthat the GPT-4 and GPT-4 Turbo models are capable of followingtemplates that only specify the format of the output with mini-mal specification of the content to be generated, with sufficientreliability for a practical evaluation. Figure 7 shows an exampleof the prompt used to select the columns relevant to the task andgenerate assumptions and actions about each column. Although"}, {"title": "5 USER EVALUATION", "content": "To evaluate and compare the STEPWISE and PHASEWISE Systems inenabling users to steer the AI and verify its responses, we conducteda within-subjects study. The study compared these systems withthe CONVERSATIONAL baseline and involved 18 participants whoused all three systems to complete six data analysis tasks, with twotasks per system. Datasets and tasks were designed to be sufficientlycomplex that the AI would not automatically produce correct so-lutions without user involvement. They required participants tocarefully verify the Al's process and responses and steer the AI inaddressing any issues.\nThe main focus of our exploratory study is on understanding theunique ways in which each system aids in steering and verificationduring the AI-assisted data analysis process. We also investigatedthe perceived utility of other various system components, and ex-plored the usage patterns and user preferences that emerged witheach system."}, {"title": "5.1 Participants", "content": "We recruited 18 participants (10 men, 8 women, 0 non-binary) froma large research university. Participants were pre-screened to ensurethey were proficient in writing Python code, familiar with Pythondata science libraries, and experienced in regularly performing dataanalysis tasks. In terms of data analysis experience, five participantsreported having 1-2 years, seven having 3-5, and six more than fiveyears. The majority (14 participants) used Python daily, while therest used it at least weekly. All reported familiarity with data sciencelibraries like numpy, matplotlib, with 15 also familiar with pandas.Jupyter Notebooks were used daily by eight participants, weeklyby six, monthly by two, and rarely by two. For English proficiencyin technical contexts, 16 participants felt very comfortable, whiletwo felt somewhat comfortable. In LLM usage for coding, sevenreported using daily, seven weekly, and four using monthly or less."}, {"title": "5.2 Data Analysis Tasks", "content": "We designed six tasks derived from the ARCADE benchmark [98],which contains a diverse set of tasks from various datasets on Kag-gle [37]. These tasks included a series of natural language (NL)queries written by professional data scientists with the intentionof interacting with an Al assistant. We selected tasks to not re-quire specific domain knowledge, targeting for participants to solvethem within a 15-minute time frame. However, we also wantedto make sure that the tasks included additional complexities thatwould make it difficult for the AI to correctly solve them withoutproper user verification and intervention. Therefore, we selectedand altered tasks and their corresponding datasets with some for-mat inconsistencies and altered distributions. For instance, Task 2(Table 2) requires splitting tags and themes with commas beforegrouping tags by themes. To increase complexity, we modified thetags and themes columns to have only the first theme or tag incapital case, with the rest in lowercase. See Table 2 for details of thesix study tasks. To guarantee consistent failure of the system on"}, {"title": "5.3 Study Procedure", "content": "The order of the PHASEWISE, STEPWISE, and CONVERSATIONAL (base-line) systems was counterbalanced across participants and tasksto minimize order effects, while tasks were fixed from T1 to T6.Each participant began with a 10-minute introduction to their firstassigned system, followed by a 10-minute warm-up task to famil-iarize themselves with its features and mitigate learning effects.Participants then proceeded to the main study tasks, where theywere given a dataset and a NL query. The researcher explained thedataset and relevant columns for each task. Participants proceededto execute the task and were asked to think aloud throughout thestudy [23].\nParticipants were made aware that identifying and correctingmistakes made by the AI was their responsibility. They were askedto notify the experimenter once they believed they have achieved acorrect result using the AI tool. The experimenter would then checktheir result and provide hints if necessary. Completion criteria foreach task required resolving both issues listed in Table 2.\nFollowing the completion of each task, participants were askedabout their choice of method for steering the AI (e.g., editing theexecution plan versus directly editing the code) and their verifica-tion processes. After completing two tasks under each condition,participants completed a questionnaire including Likert items abouttheir ability to verify, intervene and steer the AI, sense of control,information overload, frustration levels, and the utility of specificfeatures. Additionally, participants discussed their experience witheach system in a 5-minute semi-structured interview. After complet-ing all tasks using the three systems, a final questionnaire eliciteda comparative evaluation of the systems in terms of confidence,usability, control, and ease of verification and steering.\nThe sessions was conducted in-person, lasting approximately 2.5hours with a short break at the halfway point. Consent was obtainedbefore running the study and each participant was compensatedwith a GBP \u00a350 Amazon gift card. Our study protocol was reviewedand approved by our institution's ethics and compliance reviewboard."}, {"title": "5.4 Data Collection and Analysis", "content": "We recorded the audio and screen activity during each session usingMS Teams. Audio recordings were transcribed for analysis. Usersystem interactions and feature usage was also logged.\nThe think-aloud data was our main source of understanding howparticipants used the different systems and what they thought aboutthem in comparison with each other. We transcribed the think-alouddata and post-condition interviews and two researchers performeda negotiated, directed qualitative analysis. Ahead of the analysis,we identified a focused set of research themes concerning steeringand verification during the AI-assisted data analysis process, andreport our findings organised by these themes in Section 6. Becausewe were interested in specific themes a priori, and were not devel-oping a reusable coding scheme, our analysis differs from the morecommonly applied inductive approach [6]. We did not develop acodebook, and this is not a situation in which it is appropriate to"}, {"title": "6 RESULTS", "content": "In this section, we present a comparative analysis of the STEPWISEand PHASEWISE AI tools versus the CONVERSATIONAL baseline. Ourfindings are derived from study observations, log data, participant(P1-P18) think-aloud data, post-condition surveys, and post-studyinterviews. In turn, we present the results regarding task completion(Section 6.1), steering and control (Section 6.2), and verification(Section 6.3)."}, {"title": "6.1 Task Completion", "content": "Successful task completion was determined as solving the task withno remaining issues within 15 minutes. Of the 108 task episodes(18 participants \u00d7 6 tasks), only 7 were not completed success-fully. P13 had three non-completed tasks, and P3, P8, P11, and P14each recorded one non-completed task. The distribution of non-completed tasks per condition was as follows: Baseline: 1, PHASE-WISE: 2, and STEPWISE: 4. The incidence of task non-completion istoo low to permit statistical comparison.\nIn 31 instances of the 108 task episodes, participants indicatedtask completion despite remaining issues, indicating insufficientverification. In such situations, the protocol was for the researcherto identify the remaining issue(s), requiring participants to steerthe tool towards fixing the problem. A Friedman Chi Square testrevealed no statistically significant differences in number of veri-fication hints required across conditions (F(2, 34) = 1.0, p = .606),with 13 hints required for Baseline, 10 for PHASEWISE, and 8 forSTEPWISE.\nFurthermore, a one-way ANOVA showed no significant differ-ences in task completion time between conditions. The mean com-pletion times across conditions indicated that tasks solved with theBaseline tool were finished slightly faster (M=543s, SD=220s), fol-lowed by the STEPWISE tool (M=588s, SD=329s), whereas tasks fin-ished with the PHASEWISE tool were solved slightly slower (M=658s,SD=240s)."}, {"title": "6.2 Steering and Control", "content": "Analysis of the post-condition questionnaires about control foundthat participants felt significantly more in control of the Al's anal-ysis process when using the STEPWISE and PHASEWISE Systemscompared to the Baseline (STEPWISE-VS-Baseline: p = .001, d = .42;PHASEWISE-VS-Baseline: p = .004, d = .42). Participants also re-ported that the PHASEWISE and STEPWISE Systems were signifi-cantly easier to intervene and fix (Figure 8, Q3) whenever it wasdoing something wrong (PHASEWISE-vs-Baseline: p = .012, d = .55;STEPWISE-Vs-Baseline: p = .011, d = 1.05). However, no significantdifferences were found in the perceived ease of steering betweenthe three systems (Figure 8, Q4).\nIn the remainder of this section, we explore themes identifiedwithin participants' workflows and their think-aloud data. Thisanalysis reveals varied preferences among participants and offersinsights into factors that either facilitated or hindered their abilityto steer the process."}, {"title": "6.2.1 Steering by Directly Editing Al's Assumptions and Actions", "content": "Participants appreciated the ability to directly edit the AI-generatedassumptions, thereby aligning the system's operations with theirexpectations. As P16 stated: \"I could add any assumptions that I hadin mind and make it the Al's assumptions.\" This enabled users to\"steer the Al's decision making process to different directions.\" (P3)."}, {"title": "6.2.2 Enhanced Control Through Step-by-Step Task Decomposition", "content": "A distinct advantage observed with the STEPWISE system was the enhanced control participants reported over the data analysis process.This was mainly attributed to tackling the task in smaller, man-ageable segments. For instance, P16 reported an increased sense ofcontrol, by being able to \"easily edit the assumptions and actions ineach step.\" Similarly, P11 felt \"much happier\u201d and \u201cmore confident\u201d,attributing it to the ability to \"manipulate steps naturally.\" P10 alsoshared a sense of more control over the AI, stating that they \"werenot scared\" to make edits to what the AI was doing, as \"it was justa couple of lines,\" and \"it was more inviting to edit the assumptions.\"P17 mentioned that the STEPWISE system facilitated an iterativeprocess \"where [they] could easily go back and change something\"."}, {"title": "6.2.3 Steering by Manually Editing Code", "content": "Most participants appreciated the ability to manually edit AI-generated code. P18 men-tioned editing the AI-generated code was like \"you're taking overfrom the AI.\" These edits ranged from minor modifications, suchas manually changing a threshold or printing values, to more in-volved changes such as using the Generate Code feature to up-date the logic behind a line of code. When using the Generatecode feature, participants (P1, P3, P4, P7, P8, P9 P11, P12, P17,P18) selected a line of code and prompted the AI to update itbased on a provided natural language query. For instance, P9selected df [df['company_location'] == 'US'] in their code andprompted the Al with \"can you change this line to lookfor containing 'US' instead of strict equality?\" P12 ex-perienced increased control when using the Generate Code featuresince they \"could make very granular prompts\".\nParticipants preferred manually editing code for minor changesover using the AI-steering methods provided in each system. Manyparticipants expressed frustration with the inability to directly editcode in the baseline system. P7 stated, \"if [the code] was editable,I can just correct things which I know myself instead of promptingagain.\" Notably, P10, unable to edit the AI-generated code directlywith the baseline, resorted to copying the desired code line, editingit in the follow-up prompt, and then asking the AI to incorporate\nthe edited code. They found crafting a prompt for the specificedit challenging, admitting, \"I don't really know how to promptit to get it do what I want.\" However, in some cases, P3 and P10indicated reasons for not wanting to edit the AI-generated codeand instead preferred using the AI-steering methods to make theedits. P3 wanted \"to make sure that [their edit] is consistent with therest of the code\" and P10 stated, \u201cI don't like editing the code directlywhen I haven't written it.\""}, {"title": "6.2.4 Preference for Conversational Steering", "content": "In some instances,participants (P4, P5, P6, P8, and P11) specifically indicated a prefer-ence for steering the AI through natural language prompts. Theyfavored the CONVERSATIONAL method of steering the AI over edit-ing the structured assumptions, actions, or execution plans. Forexample, P4 expressed difficulty in understanding how changesto the assumptions in the PHASEWISE system affected the LLM'soutput. In contrast, P4 had a more accurate mental model of how tointeract with the CONVERSATIONAL baseline, stating \"I know exactlyhow writing a prompt is going to affect it.\" Others felt constrainedby the need to adhere to a specific structure, expressing a prefer-ence for more free-form interactions. For instance, P8 described theCONVERSATIONAL system as easier and faster for \"directing the AIusing natural language\", compared to the STEPWISE system wherethey felt they were \"trying to change the syntax of the AI.\u201d Similarly,P5 wanted to \"intentionally write vague prompts and see how much[the AI] understands.\" P4 believed that the CONVERSATIONAL Systemrequired less cognitive effort, stating \"I don't like spending that effortto think about it.\" P11 mentioned feeling \"less critical\" when usingthe CONVERSATIONAL tool, allowing the AI to \"go and figure it out\u201don their behalf. P11 elaborated: \"I knew what it was [that] I wantedit to consider, but when [the tool] is expecting a structured inputthen I was more concerned with providing it in a nice and structuredmanner.\""}, {"title": "6.2.5 Avoiding Edits that Lead to Inconsistency or Regeneration", "content": "To discover participant reasoning behind the selection of a particularsteering method from the available options, participants were askedabout their specific interactions after each task. We found thatparticipants avoided certain edits when using the STEPWISE andPHASEWISE Systems in two cases:\n\u2022 if upstream components would go out of sync and becomeinvalidated because of updating downstream components,\n\u2022 updating upstream components would cause downstreamcomponents to be regenerated, ignoring any prior edits onthe downstream component.\nFor example, P1 was worried whether the AI would \"regenerateeverything else correctly\" after updating a specific assumption. P12mentioned that there was \"no obvious way of going back withoutredoing all of the earlier changes\". Similarly, P4 mentioned thatthey \"want to make sure that [their] changes propagate and stay.\u201d P8unexpectedly found that they lost downstream edits after makingan edit on the upstream components, expressing: \u201cOh! So when itregenerated this, it forgot about [their previous edit].\" Participantsexpressed the need for bidirectional updates to maintain consistencyacross different components after making an edit. For example,when P18 was using the STEPWISE system, they could not makeedits at the beginning of the problem, which felt natural to them,because \"everything underneath it will drop.\u201d They preferred thatthe system would just highlight parts that would be invalidated inthe downstream instead of regenerating everything. P10 expressedconcern about requiring to \"read everything every time [they] made asmall change.\" In contrast, P18 accepted previous components goingout of sync, as at that point they have \"taken over from the AI\" andP5 appreciated the propagation of changes between components,stating that they liked \"how interconnected things were\"."}, {"title": "6.3 Verification", "content": "In all systems, participants relied on reading and analyzing theAl-generated code and inspecting the intermediary variables forverification. The STEPWISE System's approach of breaking downtasks into smaller steps, along with the side conversation featureavailable in both STEPWISE and PHASEWISE Systems, improved par-ticipant confidence in verification. The post-condition question-naire items indicated that both STEPWISE and PHASEWISE Systemsignificantly facilitated easier verification (Figure 8, Q2) of the gen-erated solution compared to the baseline PHASEWISE-VS-Baseline:p = .016, d = .47; STEPWISE-VS-Baseline: p = .016, d = 1.44)."}, {"title": "6.3.1 Verification through Reading Code and Asking Questions", "content": "Reading the code line-by-line was a common verification method.P12 mentioned that \"you still have to read all the code and under-stand what it's doing\" for verification. Participants mostly reliedon their own knowledge about Python and Pandas for verification,as stated by P8: \u201cyou have to know how to code, because you haveto read the code and make sure it makes sense.\" When P3 was askedhow they knew that they had successfully finished the task, theyresponded \"I inspected the code and found that it handled that edgecase correctly.\" However, in many instances participants had dif-ficulty understanding the AI-generated code, if it used idioms orfunctions unfamiliar to the participant. Participants appreciated theAsk Question feature in these situations. A majority of participants"}, {"title": "6.3.2 Inspecting Intermediary Variables", "content": "All participants used theintermediary variable inspection feature available in all three sys-tems for verification. Participants inspected variables to \"comparebetween turns\" (P1), and to \"see if [the system] has done the [opera-tion] correctly\" (P14). P12 mentioned that the verification processwas similar to \"debugging\" and P11 stated that inspecting all thevariables."}, {"title": "6.3.3 Steering for Verification", "content": "However, generated code was notalways easily verifiable. In some instances, the generated codeoverwrote variables instead of creating new dataframes, whichinterfered with variable inspection as only the final state of thevariable after code execution was displayed. In other cases, thegenerated code directly computed the final result, without suffi-cient decomposition of steps necessary for proper verification. Forexample, P4 mentioned that \u201cthe way that [the system] is generatingcode does not create useful intermediary dataframes ... it's showingme the end result\". In some cases this lead to unjustified reliance onthe generated code, as P3 mentioned: \"I guess I would need to trustin this case.\"\nTherefore, a recurring theme that emerged was participantstrying to update the code, through steering, to include more in-formative and useful intermediary variables. For example, P16added a new step to the execution plan to emit new out-puts and other relevant columns in addition to just show-ing the final result. P4 added an explicit step to the execu-tion plan display couple of groups so I can manually verify .Interestingly, there were also several cases that participants justdid not understand the method used in the generated code, andtherefore, asked the system to \"come up with a more understandable\nsolution\" (P6)."}, {"title": "6.3.4 Focusing on Smaller Steps Facilitated Verification", "content": "The STEP-WISE System provided a one-to-one mapping of code with the inter-mediary variables for each step. Participants found that they caneasily \"focus on each small step\" (P15), improved their confidencesince they were forced to \"think of edge cases along the way\" (P9).P5 mentioned that \"having it step-by-step leads to more reflectingfrom my side and verifying each block\". Granular decompositionalso helped with locating issues. It was \"easier to figure out what isgoing wrong\" (P11), and \u201cthere was less margin of error\u201d (P7). For P3,"}, {"title": "6.3.5 Aggregated Information Helped with Verification", "content": "Many par-ticipants (n=7) appreciated how the PHASEWISE system aggregateddescriptive statistics and assumptions for each column and foundthat they scaffolded reasoning about the tasks. These helped P15\u201cunderstand what are the different possibilities,\u201d enabled P6 to \"see ex-actly how each column will be treated\", and \"forced\u201d P3 \u201cto see the dataa bit better.\" For example, in Task 3, P3 easily found the \"Unknown\"genre problem in the descriptive statistics, immediately updatingthe corresponding assumptions to handle it. Furthermore, P9 jus-tified the usefulness of the aggregated information per columnsby stating \"it is something a lot of times you would end up askingabout anyways,\" and P1 appreciated that it \"gives you a preview ofeverything together.\" \nHowever, some participants mentioned that the aggregated statis-tics were a source of information overload. The post-condition ques-tionnaires also indicated that they felt significantly overwhelmed(Figure 8, Q8) by the amount of information displayed when usingthe PHASEWISE system compared to the baseline (p = .008, d = .11).P16 felt \"frustrated by the amount of things that [they] saw on thescreen\" and P8 stated that \u201cIt could start getting quite cumbersome ifthe dataset was large\". Similarly, P4 found the structure to be over-whelming and some assumptions about columns were irrelevant towhat they were trying to do, and instead, they wanted the systemto contextually display the right amount of information."}, {"title": "6.3.6 Running Side Queries", "content": "The Run Side Query feature of theSTEPWISE and PHASEWISE Systems was the most frequently usedside conversation feature with 82 usages, compared to 26 usagesof Ask Question, and 17 usages of Generate Code. All participantsran side queries at least once. About 75% (n=62) of the side querieswere to understand data and its limitations and 17% (n=14) were tovisualize data for inspection.\nThe Side Query feature facilitated a novel and effective work-flow, especially when integrated with the editable assumptions,actions, and execution plan in both systems. Participants used itto \"explore the dataset, validate assumptions, and add them to thecolumn breakdown\" (P17), and \"to build up assumptions and editthe plan\" (P10). P9 used the Side Query to plot the distribution ofa column and select a better threshold for filtering outliers. P13mentioned gaining \"more confidence after plotting histograms\u201d andfound that the Side Query proved more beneficial in the STEPWISE"}, {"title": "6.3.7 Deferring Steering after Seeing Initial Results", "content": "Participantsfrequently preferred to first see results before interacting with andsteering the AI tool. P6 highlighted that they \"just want to see theresult first and then trim it\u201d. P18 wanted to \"look at the result firstand if the result was nonsense then go back\". This was particularlythe case in the PHASEWISE and STEPWISE Systems, as P4 mentionedthat the system made them \u201cgo through all of these steps and spendso much time before [they] could actually see the result.", "correct": "part of me wants to just see what it does, even if the [execution] planlooks reasonable, I know there's gonna probably be errors.\u201d Anotherreason why participants wanted to defer steering, particularly inthe PHASEWISE system, was that the input/output assumptions orthe execution plan did not have enough details about how the AI isgoing to \"handle\u201d or \u201ccalculate"}, {"title": "6.4 Summary of Results", "content": "Our study revealed that while there was no difference in task suc-cess, completion time, or number of required verification hints,participants felt significantly more in control of the data analysisprocess when using the PHASEWISE and STEPWISE Systems com-pared to the CONVERSATIONAL baseline. This was attributed tothe ability to directly edit AI-generated assumptions and actions.However, the lack of immediate feedback after updating an assump-tion and the loss of downstream edits when updating upstreamcomponents were identified as limitations.\nThe study also highlighted the value of side conversations in theAI-assisted data analysis process. The ability to run side queriesfacilitated an iterative workflow of exploration, validation, andupdating of editable assumptions, particularly in the STEPWISEsystem. The Ask Question feature helped participants understandthe AI-generated code, while the Generate Code feature allowedthem to update the logic behind a line of code. In the absence ofside conversations, as in the baseline system, participants mixedtheir queries with the main thread of the task.\nIn the PHASEWISE System, the organization of assumptions en-abled direct and broad control and served as a memory aid. Par-ticipants appreciated the aggregated descriptive statistics and as-sumptions for each column, which helped them understand howeach column would be treated. However, the amount of informationdisplayed was also a source of overload for some participants."}, {"title": "7 DISCUSSION AND IMPLICATIONS FOR AI-ASSISTED DATA ANALYSIS TOOLS", "content": "Our designs for the PHASEWISE and STEPWISE Systems, and theirevaluation against the CONVERSATIONAL tool, have provided uswith a deeper understanding of the trade-offs within the designspace of AI-assisted data analysis tools. This discussion will explorethese trade-offs, their impact on user preferences and interactions,and suggest guidelines for design.\nOur study finds that the key to designing AI-assisted data analy-sis tools lies in providing the user with the necessary controls tomake informed decisions and maintain control over the process.This echoes the longstanding positioning of the role of user inter-face elements in interactive machine learning systems as providingdecision support [50, 74, 78]. Our study finds that in the specificcase of AI-assisted data analysis, decision support is subject to thefollowing key design questions:\n\u2022 DQ1 Steering Points: At what points should the systemallow the user to intervene in the process and steer? Howfrequently should these steering opportunities occur?\n\u2022 DQ2 Steering Support: How does the user determine whichdirection they should steer the AI? How should the toolfacilitate users in making informed decisions at each steeringpoint?\n\u2022 DQ3 Steering Modality: What interface affordances areavailable for the user to steer the process? How structuredor flexible should the modality of their interaction be?\nThese are similar to the design questions regarding the num-ber and nature of \"choice points\" within a data analysis workflowgenerated by an earlier generation of tools termed Intelligent Dis-covery Assistants (IDAs) [79]. We find that the choices users facewith IDAs (e.g., what type of regression or normalisation to applyat a particular step) still exist within generative AI-assisted dataanalysis, but they are embedded within the higher-level challengesof steering, and are experienced by users as a secondary concern."}, {"title": "7.1 DQ1: Steering Points", "content": "One design question is at which points during the generation pro-cess the user should reflect, check for correctness, and steer ifneeded. Our STEPWISE and CONVERSATIONAL tools can be seen astwo ends of a spectrum of intervention opportunities. The STEPWISEsystem offers steering points after each step of the analysis, allow-ing for incremental adjustments. In contrast, the CONVERSATIONALtool aims to complete the task with minimal user interruption,offering a chance to adjust only after attempting to solve the task."}, {"title": "7.2 DQ2: Steering Support", "content": "At each steering point, users must verify whether the output iscorrect, and if not, choose a steering action. How should the toolfacilitate the information seeking and exploration process thatis required for the user to make informed decisions? Tools forverifying AI-generated content are termed \"co-audit\" [24", "69": "and information foraging [68", "20": "with multiple activities proceeding ina parallel, non-linear fashion. This is antagonised by the sequentialnature of chat interfaces.\nOur exploration into the design space introduced side conver-sations and the Run Side Query function to aid this process. Fur-thermore, in the PHASEWISE System, the system displayed datasetcolumns relevant to the user's task, along with interactive descrip-tive statistics. Moreover, the execution plan component suggestedoptional steps for the user to consider adding before proceeding tothe next step, enhancing the decision-making process.\nOur findings indicate that when the system provides timely, accu-rate, and relevant information, it fosters a genuinely collaborativeexperience. Conversely, displaying irrelevant information can re-duce trust in the AI and potentially leading to information overload.Users also risk becoming overly dependent on Al for guidance,potentially neglecting critical information seeking which may leadto poor decision making.\nParticipants noted their desire for the AI to act as an agent, aidingin the assumption-building process at steering points. Future toolscould automatically retrieve assumptions by pinpointing specific,relevant evidence to support informed decision-making withoutoverwhelming users. Additionally, these tools could help accessto domain-specific knowledge pertinent to the data analysis task.Lastly, tools should be transparent regarding the Al's limitations insourcing all necessary information for optimal decision-making at"}]}