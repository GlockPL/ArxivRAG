{"title": "Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance", "authors": ["Mostafa Hussien", "Mahmoud Afifi", "Kim Khoa Nguyen", "Mohamed Cheriet"], "abstract": "Recent advancements have scaled neural networks to unprecedented sizes, achieving remarkable performance across a wide range of tasks. However, deploying these large-scale models on resource-constrained devices poses significant challenges due to substantial storage and computational requirements. Neural network pruning has emerged as an effective technique to mitigate these limitations by reducing model size and complexity. In this paper, we introduce an intuitive and interpretable pruning method based on activation statistics, rooted in information theory and statistical analysis. Our approach leverages the statistical properties of neuron activations to identify and remove weights with minimal contributions to neuron outputs. Specifically, we build a distribution of weight contributions across the dataset and utilize its parameters to guide the pruning process. Furthermore, we propose a Pruning-aware Training strategy that incorporates an additional regularization term to enhance the effectiveness of our pruning method. Extensive experiments on multiple datasets and network architectures demonstrate that our method consistently outperforms several baseline and state-of-the-art pruning techniques.", "sections": [{"title": "1 Introduction", "content": "Deep learning has achieved remarkable results across various fields, from computer vision to natural language processing, by generating highly effective models like large language models (LLMs) (e.g., Brown et al. [2020], Touvron et al. [2023], Gemini Team Google [2023]), which have demonstrated significant improvements in multiple applications. These models have shown significant improvements in a wide range of applications, including machine translation (Lewis [2019]), question answering (Raffel et al. [2020]), and image classification (Abdelhamed et al. [2024]). However, as deep neural networks (DNNs) grow in size to handle increasingly complex problems, they require immense computational resources, both in terms of memory and processing power.\nNetwork pruning, also referred to as network or model compression, aims to reduce the size of these networks, thereby decreasing their computational costs. This is achieved by removing specific weights from the model, setting them to zero based on certain pruning criteria. DNN pruning methods can be categorized into different groups based on the nature of the approach (e.g., data-free versus data-driven, or based on the pruning criteria used). We refer the reader to Cheng et al. [2024] for a thorough discussion of these categories. From a high-level perspective, we can categorize pruning methods into structural pruning (e.g., Wang et al. [2020a], Huang and Wang [2018], Liu et al. [2017], Theus et al. [2024], Ganjdanesh et al. [2024], Shi et al. [2024], Gadhikar and Burkholz [2024], Wu et al. [2024], Guo et al. [2023], Fang et al. [2023], He et al. [2017]), where entire filters or channels are removed, and unstructured pruning (e.g., Tanaka et al. [2020], Mason-Williams and Dahlqvist [2024], Choi et al. [2023], Lee et al. [2018], Su et al. [2020], Wang et al. [2020b], Bai et al. [2022], Mocanu et al. [2018], Han et al. [2015], Sun et al. [2024]), which performs weight-wise pruning. In the latter case, the network is typically retrained after pruning and it is common for pruning to be performed iteratively, where a smaller set of weights is selected for removal (i.e., set to zero), followed by retraining or fine-tuning the pruned model. This process is repeated until the target final pruning ratio is reached.\nWhile data can provide valuable insights into how each neuron (or node) contributes to the final result, the majority of unstructured pruning methods rely solely on neuron weights, focusing on defining criteria to measure the significance of individual weight values. For instance, the magnitude-based pruning metric Han et al. [2015] removes weights by eliminating those with magnitudes below a certain threshold.\nRecent work, such as Wanda Sun et al. [2024], enhances the traditional weight magnitude pruning metric by incorporating input activations. Designed specifically for LLMs, Wanda is based on the observation that, at a certain scale, a small subset of hidden state features exhibits significantly larger magnitudes than others Dettmers et al. [2022]. The pruning score in Wanda is computed as the product of the weight magnitude and the norm of the corresponding input activations, recognizing that input features can vary considerably in the scale of their output features. While Wanda demonstrates promising results, it does not fully capture the true contribution of each neuron weight to the output feature, given the input features.\nIn this paper, we introduce a data-driven, unstructured pruning method that utilizes training data or a subset thereof-to approximate the distribution of each weight's importance in the network based on its contribution to the output of its corresponding node. By applying the Central Limit Theorem, we model the aggregated importance of weights as a normal distribution, which enables us to estimate the mutual information between a weight and the output of its associated node. This mutual information quantifies how much knowing the weight reduces uncertainty about the node's output. Consequently, the more sensitive the node's output is to changes in a weight, the more important that weight is and the less likely it is to be pruned. The gradient of the activation function has a clear impact on the performance of the pruning method, as they affect the distribution of the node's output. Our proposed method is firmly grounded in both statistical analysis and information theory, drawing connections to the Central Limit Theorem and mutual information. Preliminary experiments demonstrate that our method consistently yields more accurate models, even at high compression rates, compared to alternative approaches."}, {"title": "2 Method", "content": "The role of nonlinear activation functions has been widely studied in various aspects of neural network architectures, including their impact on training convergence, weight initialization, and stability. For example, activation functions play a crucial role in gradient propagation, influencing issues such as the vanishing and exploding gradient problems, which are critical for training deep networks. However, less focus has been given to the impact of activation functions on the susceptibility of neural networks to pruning. This study explores how the choice of activation function impacts the extent to which an architecture can be pruned without causing significant degradation in accuracy.\nWe introduce the concept of the \u201cBlind Range\u201d for a typical activation function, which refers to the interval where the derivative of the activation function is zero, see Fig. 1. In other words, the blind range represents the input range over which the activation function's output remains constant. For instance, in the case of the ReLU activation, this range spans from negative infinity to zero.\nWe propose that the blind range of activation functions provides a safe zone for pruning, where if pruning a weight causes the activation output to fall within this range, the output of the corresponding node remains unchanged, and as a result, the overall model performance is preserved. Additionally, small deviations from this blind range can be efficiently corrected during the fine-tuning phase. However, the effect of pruning may vary across different data points. To address this variability, it is necessary to adopt a statistical approach. Specifically, we suggest empirically constructing a distribution to quantify the impact of each weight across different subsets of the dataset, enabling more informed and robust pruning decisions. This is explained in more details in the next sections."}, {"title": "2.2 Relative Weight Contributions", "content": "Figure 2 illustrates how a node contributes to the activation of its associated neuron within the neural network architecture. Specifically, we analyze the contribution of a weight $w_{ij}$ in a layer that receives an input vector of size $I$ and adopts an activation function $f$. We define the contribution function $\\varsigma(\\cdot)$ of a weight $w_{ij}$ as:\n$a_{j} = f(\\sum_{n=1}^{I} x_{n} \\times w_{(n,j)}),$\n$\\bar{a_{j}} = f(\\sum_{n=1}^{I} x_{n} \\times w_{(n,j)}) \\, n \\neq i,$\n$\\varsigma(w_{n,j}) = |(a_{j} - \\bar{a_{j}})/a_{j}|,$\nwhere $x_{n}$ is the $n^{th}$ input of the layer, $w_{n,j}$ is the weight connecting the $n^{th}$-input to the $j^{th}$-node in a typical layer. The magnitude of this contribution determines the actual importance of the corresponding weight in the final node activations and, consequently, indicates the extent to which the weight can be pruned. Given that the contributions of each weight vary with different data points, and considering the large number of data points, the distribution of these contributions over the epochs approaches a Gaussian distribution according to the Central Limit Theorem Sirignano and Spiliopoulos [2020]. Utilizing the first-order statistics of the contributions' distribution, we define a weight function that assigns a scalar value to each weight, representing its importance, as shown in Equation 2.\n$I(W_{i,j}) = \\varsigma \\times [\\alpha \\times E(\\varsigma(i,j)) + \\beta \\times \\epsilon + \\sigma(\\varsigma(i,j))]$,\nwhere $\\varsigma = 2^{2}$ is a decaying factor that controls the contribution of each layer, $\\alpha$, $\\beta$, weight parameters to control the importance of the mean and the standard deviation, respectively. The term $\\epsilon$ is a small number to avoid division by zero. After calculating the importance value of each weight based on its contribution, the pruning becomes a straight forward process by applying iterative weight pruning given by Algorithms. 1."}, {"title": "2.3 Pruning-aware Training", "content": "In this section, we introduce a novel regularization term for training that enhances the effectiveness of our pruning algorithm. As previously discussed, the probability of pruning a weight increases as its mutual information with the node's output decreases. In other words, if a node's output frequently falls within the blind range, the weights associated with that node are more likely to be pruned. Therefore, increasing the probability of a neuron's output being in the blind range improves the pruning process."}, {"title": "3 Mutual Information", "content": "In this section, we analyze the mutual information between the activation output of the $i^{th}$-node in the $l^{th}$-layer, $a_i$ and the weight $w$ connecting neuron i to the $j^{th}$ input Czy\u017c et al. [2024]. As known, the activation output is given by:\n$a = \\phi(z_i), \\, where \\, z_i = \\sum_{j} W_{ij} x_{j},$\nwith $\\phi(\\cdot)$ representing the activation function and $x_j$ is the $j^{th}$-input from the preceding layer. The mutual information $I(a_i; W_{ij})$ quantifies the reduction in uncertainty of $a_i$ due to knowledge of $W_{ij}$, calculated as:\n$I(a_i; W_{ij}) = H(a_i) - H(a_i | W_{ij}).$"}, {"title": "4 Experimental Results", "content": "In this section, we validate our method on the MNIST dataset LeCun [1998] for the image classification task. We fixed the network architecture to a simple fully connected layer network consisting of 3 layers. The first layer has 784 \u00d7 392 weight neurons, accepting flattened images of size 28 \u00d7 28, and outputs 392 features, followed by a ReLU activation function. The second layer processes the latent representation and produces 196 output features, again followed by a ReLU activation function. The final layer outputs a 10-dimensional vector representing the logits for the MNIST classes. We utilized cross-entropy loss with a learning rate of 0.001 for 10 epochs and optimized the network using the Adam optimizer with betas = (0.9, 0.999).\nTo perform pruning, we adopted an iterative pruning strategy. After training the original model, we iteratively prune the network as follows: First, we compute a score for each weight neuron based on the pruning metric, either using our method's contribution metric or the criteria of other methods for comparison. Next, we determine a threshold value from these scores, based on a fixed pruning ratio per iteration, and create a mask that zeros out neurons with scores below the threshold. This process is repeated iteratively, pruning neurons at each step until the final target pruning ratio is reached. After each pruning iteration, we fine-tune the model by applying the current pruning mask and training for one epoch using a learning rate of 0.0001. The mask is updated in each iteration to include the newly pruned neurons, representing all pruned neurons by the end of the process.\nNote that since our method relies on input data to compute the contribution of each neuron, we investigate the impact of using different subsets of the training dataset for this purpose in the pruning process. The final mean and standard deviation of the computed contributions are calculated across the training examples used in our pruning procedure to derive the final contribution score, as described in Equation 2. We apply the same approach for examining different subsets of training data for Wanda Sun et al. [2024], as it also depends on input data to compute the pruning metric for weights."}, {"title": "5 Conclusion", "content": "In this paper, we have introduced an interpretable, simple, yet effective pruning method. By defining the concept of the activation blind range, we investigated the underexplored aspect of how activation functions affect an architecture's susceptibility to pruning. We presented a statistical framework for the proposed pruning method, grounded in the Central Limit Theorem and Mutual Information concepts. Our findings conclude that, for unstructured pruning, considering the mutual information between each weight and its associated node leads to a simple and powerful pruning strategy. Moreover, considerable improvements have been obtained by leveraging what we named as 'Pruning-aware Training' that incorporates an extra term that encourage the model to push the nodes output toward the blind range of the activations. The experimental results confirm the effectiveness of the proposed method across various experimental settings."}]}