{"title": "Obtaining Optimal Spiking Neural Network in Sequence Learning via CRNN-SNN Conversion", "authors": ["Jiahao Su", "Kang You", "Zekai Xu", "Weizhi Xu", "Zhezhi He"], "abstract": "Spiking neural networks (SNNs) are becoming a promising alternative to conventional artificial neural networks (ANNs) due to their rich neural dynamics and the implementation of energy-efficient neuromorphic chips. However, the non-differential binary communication mechanism makes SNN hard to converge to an ANN-level accuracy. When SNN encounters sequence learning, the situation becomes worse due to the difficulties in modeling long-range dependencies. To overcome these difficulties, researchers developed variants of LIF neurons and different surrogate gradients but still failed to obtain good results when the sequence became longer (e.g., >500). Unlike them, we obtain an optimal SNN in sequence learning by directly mapping parameters from a quantized CRNN. We design two sub-pipelines to support the end-to-end conversion of different structures in neural networks, which is called CNN-Morph (CNN \u2192 QCNN \u2192 BIFSNN) and RNN-Morph (RNN\u2192 QRNN \u2192 RBIFSNN). Using conversion pipelines and the s-analog encoding method, the conversion error of our framework is zero. Furthermore, we give the theoretical and experimental demonstration of the lossless CRNN-SNN conversion. Our results show the effectiveness of our method over short and long timescales tasks compared with the state-of-the-art learning- and conversion-based methods. We reach the highest accuracy of 99.16% (0.46 \u2191) on S-MNIST, 94.95% (3.95 \u2191) on PS-MNIST (sequence length of 784) respectively, and the lowest loss of 0.057 (0.013\u2193) within 8 time-steps in collision avoidance dataset.", "sections": [{"title": "1 Introduction", "content": "Spiking Neural Networks (SNNs), known as third-generation neural networks [24], are inspired by the biological structure of the brain. Recent studies have\nshown that brain-inspired neuron models (e.g., integrate and fire (IF) neuron), can obtain results comparable to ANN networks with high energy efficiency and low latency [12,15]. Unlike traditional ANNs, SNNs use discrete spikes to convey information between neurons. Such binary communication mechanism can be executed smoothly on a neuromorphic chip (e.g., Truenorth[1], Loihi[8]).\nSNNs and RNNs share similarities in many ways, like the design of hidden states and the ability to learn through time. Many efforts have been made in RNN to improve long-term learning dependencies and have achieved astonishing results in sequence learning [17,21]. Attracted by the performance of RNNs, a question arises: how to obtain SNNs that can perform as well as RNNs in sequence learning? An obstacle to answering this question is the non-differential binary communication mechanism of SNN, which results in significant information loss. To address the problem, surrogate gradient (SG) based back-propagation methods [26,25] and variants of neurons based learning [32,34] was introduced. However, such approaches still suffer from the spike vanishing phenomenon [26] and inaccurate gradient approximation [25]. When the temporal sequence becomes longer, SNN cannot achieve the ANN-level accuracy (e.g., SNN-SoTa is 91% while RNN-SoTa is 97.2% in permuted-sequential MNIST).\nInstead of expecting that the non-differential binary network directly converges to ANN-level accuracy through learning, the conversion-based method obtains an SNN by mapping parameters from its counterpart ANN. However, existing neuron models in conversion methods [29,20,6] are not compatible with RNN cells because the data in the recurrent structure remain in float type after conversion, which is not allowed. In addition, it still suffers from conversion errors, and these errors will be magnified over time. To address the aforementioned issues, we propose the Recurrent Bipolar Integrate-and-Fire (RBIF) neuron to support the RNN-SNN conversion (as shown in fig. 1), which guarantees the spike form of the recurrent connection after conversion. Furthermore, we propose a comprehensive framework that supports lossless Quantized Convolutional and Recurrent neural networks to SNN Conversion (QCRC) end-to-end. Our main contributions are summarized as follows:"}, {"title": "2 Related Works", "content": "Spiking neural networks have similarities to vanilla RNN and its variants in the same form. Since the change of membrane potential is related to time, an SNN can be understood as an RNN without recurrent connection [25]. Recurrent neural networks (RNNs) are powerful models for processing sequential data while spiking neural networks (SNNs) show huge potential for processing sequential event-based data. To address the vanishing and exploding gradient problems during the training of RNN, long short-term memory (LSTM) [14] is proposed. In addition to adding the gate units in recurrent neurons, other works address the problem by weight initialization like IRNN [17] or changing the form of recurrent neurons like indRNN [21]. Similar to RNNs, many efforts have been made to help SNNs learn long-term patterns. Variants of LIF (e.g., Adaptive LIF [2,33], GLIF [32]) are proposed to enlarge the representation of neuronal behaviors. The RSNN that contains recurrent connections is adopted by [34,31], resulting in better performance compared with feedforward-only connections. However, it still remains challenges to obtain an SNN with RNN-level performance in the dataset that RNNs are good at, such as sequential image classification and time series forecasting.\nThe ANN-to-SNN conversion algorithm was first introduced in [7] by changing the activation function to ReLU. [9] presented two ways to normalize the network weights (i.e., data-based and model-based normalization) to prevent the overestimating output activation. [28,10] took threshold into consideration and proposed different normalization methods. By theoretically analyzing the conversion error between the source ANN and the converted SNN, [6,22] achieved the high-performance ANN-SNN conversion with ultra-low latency. To mitigate the sequential error, a neuron that can trigger both positive and negative spikes was proposed, which has been widely used in recent works [15,20,30]."}, {"title": "3 Method", "content": "To mitigate the sequential error (the phenomenon that spikes are generated in spiking neurons where they should not be), we adopt bipolar integrate-and-fire (BIF) neuron as our basic neuron. The overall dynamic of BIF neuron can be expressed as follows:\n$H'(t) = V^{l}(t - 1) + W^{l}s^{l-1}(t)\\lambda^{l-1}$,\n$V^{l}(t) = H'(t) - s'(t)\\lambda^{l}$.\nwhere $H'(t)$ and $V'(t)$ represent the membrane potential before and after firing. $W'$ denotes the synaptic weight between layer $l - 1$ and layer $l$. To minimize information loss, we adopt the \"reset-by-subtraction\" mechanism [27]. Here, $s'(t)$ denotes the bipolar output spikes at time step t and $\\lambda'$ represents the threshold of layer l. We mitigate the sequential error by allowing $s'(t)$ to be either positive or negative while setting a spike tracer $S'(t)$ to record the sum of spikes. The firing rules can be described by the equations below.\n$S'(t) = S'(t - 1) + s'(t)$,\nwhere $S'(t) = 0, 1, ..., S_{max}$ \n$s'(t) = \\begin{cases}\n1, & H'(t) > \\lambda' & S'(t-1) < S_{max}\\\\\n0, & others\\\\\n-1, & H'(t) < 0 & S'(t - 1) > 0\n\\end{cases}$\nAs RNN introduces external recurrent connections, the computation graph is different from linear and convolution layers. Accordingly, the pattern of BIF is not compatible with RNN cells, because it will lead to illegal non-spiking forms of recurrent connection after conversion. To address the problem, we propose a novel neuron called the recurrent bipolar integrate and fire RBIF neuron. The neural dynamics of RBIF is defined as:\n$H_k(t) = V_k(t-1) + W_{ih}s_{k-1}^{l-1}(t)\\lambda^{l-1} + W_{hh}s_{k-1}(t)\\lambda^{l}$,\n$V_k(t) = H_k(t) - s_k(t)\\lambda'$.\nAs illustrated in fig. 3, QCRC can simultaneously convert different layers to their corresponding SNN layers via two sub-pipelines, which is versatile and suitable for the compound model (i.e., model that contains different types of layers), such as CRNNs. We design two conversion pipelines for different types of layers in networks, which we call CNN-Morph and RNN-Morph. In brief, the conversion pipeline can be divided into two steps: the quantization process and the Neuron-Morph process."}, {"title": "3.1 SNN Model", "content": "Quantization. (1) Operator Substitution: The first step is to make sure all operators in the original ANN are compatible with the SNN. For example, all activation functions should be ReLU based on equivalence requirements before training at full precision. In addition, max-pooling should be replaced by average-pooling because computing maxima with spiking neurons is non-trivial [27]. (2) Activation Substitution: In this step, the ReLU function is replaced by the quantized ReLU function, where the lower bound a is set to 0 and upper bound b set to L. After the configuration, the quantized ANN is trained using the protocols defined in [11,4].\nNeuron-Morph. (1) Neuron Substitution: Benefiting from neuronal equivalence (section 3.3), the synaptic weights of a quantized ANN can be directly"}, {"title": "3.2 Conversion Pipelines", "content": "mapped to their corresponding SNNs. Specifically, BIF neurons are converted from convolutional/linear neurons, while RBIF neurons are converted from recurrent neurons. (2) Neuron Configuration: The last step of conversion is to configure the BIF/RBIF neuron attributes (i.e., $\\lambda, S_{max}, V(0)$) and set the s-analog encoding method for input and bias based on QCRC equivalence requirements. The s-analog encoding is the prerequisite for conversion, that is to make sure the inputs to the l layer of ANN and SNN are the same. Two operations will be performed: a) the current X will be charged into the network only at the first time step, otherwise the input is equal to zero; b) turn off the bias term calculations after the first time step."}, {"title": "3.3 Theoretical Equivalence in QCRC", "content": "Assume a quantized CNN with ReLU activation function parameterized by $W^l$ is converted to a BIFSNN based on CNN-Morph and s-analog encoding is adopted, then the accumulated outputs of the SNN are equal to the quantized CNN outputs when T is long enough that remaining membrane potential is insufficient to fire a spike.\nThe key idea of QRNN-RBIF conversion is that for each RNN sequence input, the activation value of the RNN neuron can be equivalently mapped to the accumulated output of the SNN neuron. Based on this, we first combine eq. (6) and eq. (7) to get the potential update equation:\n$V_k(t) - V_k(t-1) = W_{ih}s_{k-1}^{l-1}(t)\\lambda^{l-1} + W_{hh}s_{k-1}(t)\\lambda' - s_k(t)\\lambda'$.\nBy summing up eq. (10) from 1 to inference time-step T, we have:\n$V(T) - V(0) = W_{ih}\\lambda^{l-1}\\sum_{t=1}^{T}s_{k-1}^{l-1}(t) + W_{hh}\\lambda'\\sum_{t=1}^{T}s_{k-1}(t) - \\lambda'\\sum_{t=1}^{T}s_k(t)$,\nwhere $\\sum_{t=1}^{T}s(t) = \\sum_{t=1}^{T}(S'(t) - S(t - 1)) = S(T) - S(0)$ according to eq. (4). If we set $S'(0) = 0$, eq. (11) can be simplified as\n$V(T) - V(0) = W_{ih}\\lambda^{l-1}S_{k-1}^{l-1}(T) + W_{hh}\\lambda'S_{k-1}(T) - \\lambda'S_k(T)$.\nThen, we divide both sides of eq. (12) by the threshold $\\lambda'$. With additional simple transformation, we can obtain the expression for spike tracer:\n$S_k(T) = \\frac{(W_{ih}\\lambda^{l-1}S_{k-1}^{l-1}(T) + W_{hh}\\lambda'S_{k-1}(T) + V(0) - V(T))}{\\lambda'}$.\nWhen the simulation time-steps T is long enough so that the remaining membrane potential $V(T)$ is insufficient to fire a spike, the eq. (13) can be written as\n$S(T) = \\frac{(W_{ih}\\lambda^{l-1}S_{k-1}^{l-1}(T) + W_{hh}\\lambda'S_{k-1}(T) + V(0))}{\\lambda'}$.\nwhere $S_k(T) = 0, 1, ..., S_{max}$. By multiplying both sides of the eq. (14) by $\\lambda'$ and inserting the clip function, we can get the final equation:\n$X(T) = \\lambda' clip(\\frac{W_{ih}X_{k-1}^{l-1}(T) + W_{hh}X_{k-1}(T) + V(0)}{\\lambda'}\\rfloor, 0, S_{max})$,\nwhere $X(T) = \\lambda'S_k(T)$ by definition.\nEquation (15) describes the relationship between unweighted postsynaptic potential of RBIF neurons in adjacent layers. By setting $\\lambda'= s$, $S_{max} = n$, $V(0) = 0.5s + b_{ih} + b_{hh}$, eq. (15) and eq. (8) are equivalent, which will lead to the conclusion in eq. (9). Note that, setting $V(0) = 0.5s$, which is called pre-charge method in [5], will make operator $\\lfloor .\\rfloor$ and operator $[.]$ equal."}, {"title": "4 Experiments", "content": "In this section, we obtain optimal SNNs in sequence learning via CRNN-to-SNN conversion. We validate the effectiveness of our method with other state-of-the-art learning-based approaches and conversion-based approaches, demonstrating the advantages of our method on different datasets (i.e., benchmark"}, {"title": "4.1 Implementation details", "content": "The experiments exactly follow the quantization and conversion stages as introduced in section 3.2. Both ANN quantization training and SNN implementation are carried out with PyTorch. Unless otherwise specified, the optimizer is Adam [16], the learning rate scheduler is the cosine annealing schedule [23].\nWe only apply normalization transform to the dataset. The main hyper-parameters of the models follow their corresponding papers [2,33,12]. Training epoch and batch size are 200 and 256 for all models. The learning rate of our model is 0.0002. The cross-entropy loss (CE) is used to evaluate the difference between the estimated value and the actual value."}, {"title": "4.2 Sequential MNIST", "content": "To explore the application of SNNs in sequential robotic tasks, we conduct robot navigation experiments using the dataset proposed in [18]. The objective of this task is to navigate a Pioneer 3-AT mobile robot safely through obstacles. Specifically, the network input comprises data streams from a 270-degree 2D LiDAR scanner and a time series of estimated robot poses sampled at 10Hz. By generating a decision in the form of a target angular velocity, the network can maneuver the robot safely around the obstacles."}, {"title": "4.3 Obstacle detection and avoidance", "content": "The sequential- and permuted-sequential MNIST (S/PS-MNIST) [19] are widely used benchmarks to verify the learning ability for long-term dependencies. The image will be divided into 784 pixels and sent to the network pixel by pixel. The networks are asked to predict the class of MNIST image only when all 784 pixels are fed sequentially to the recurrent network. Therefore, achieving high accuracy on the \"pixel-by-pixel MNIST\" problem is not easy because neurons must have the ability to learn from the long contexts.\nBenefiting from the high scalability of our method, we use indRNN cell [21] as the original RNN model. We set the quantization step and time-steps to 128 and 512. A performance comparison is given in Table 3. RBIF reads the image pixel by pixel without any extra encoding process, just as the same as the LSTM. It outperforms all models, achieving 99.16% and 94.95% classification accuracy on S-MNIST and PS-MNIST respectively. Note that, the accuracy of pr-ALIF (94.3%) on PS-MNIST is not included for comparison because the adoption of a sliding window is unfair to other models. We also compare our method with the conversion-based method. It turns out that performance deteriorates rapidly as\nthe sequence gets longer due to the propagation of sequential error, which we will explain further in section 4.4."}, {"title": "4.4 Ablation Study", "content": "We perform two-fold validation on the equivalence of QCRC. We use the dataset and network in section 4.3. The choice of CRNN network can make the analysis more comprehensive since it contains three commonly used layers (i.e., linear, convolutional, recurrent layers). To measure the conversion error straightforwardly, we use a batch of data to visualize the L1 Norm (a.k.a. Manhattan distance) between QANN and its counterpart SNN for intermediate activation layers, as shown in the left of fig. 4. It is shown that the use of IF neurons makes the L1 Norm in QCFS remain at a large value due\nto the accumulating sequential error. Although Fast-snn proposes the signed IF neuron and layer-wise fine-tuning scheme to mitigate the sequential error, the m-analog encoding still leads to in-equivalence at the model level and degrades the performance at deeper layers. Compared with them, only QCRC reaches the true lossless level (i.e., the L1 norm between QANN and converted SNN is 0). Furthermore, the bar graphs we draw (right part in Figure 4) show that the sum of activations for each neuron layer in QANN and SNN is equal."}, {"title": "5 Discussion and Conclusion", "content": "This paper proposes a comprehensive QCRC framework to help SNNs overcome the challenge of not achieving ANN-level results in sequence learning, enabling SNNs to achieve results comparable to RNNs. To overcome the incompatibility problem of RNN cell, we propose RBIF neuron. Based on this, we further demonstrate the lossless CRNN-SNN conversion with the design of conversion pipelines and s-analog encoding. The framework includes two sub-pipelines (i.e., CNN-Morph and RNN-Morph), which can support end-to-end conversion of complex models with both recurrent and convolutional structures into SNN and is not limited by the type of dataset. We are the first work to implement lossless RNN-SNN conversion on time series tasks. Our results show promising advantages compared to the state-of-the-art conversion- and learning-based methods. Our results answer the question in section 1: we can easily achieve ANN-level performance for SNNs in sequence learning via CRNN-SNN conversion. We believe our work paves the way for the application of SNNs in time series tasks."}, {"title": "Appendix", "content": "Assume a quantized CNN with ReLU activation function parameterized by $W^l$ is converted to a BIFSNN based on CNN-Morph and s-analog encoding is adopted, then the accumulated outputs of the SNN is equal to the quantized CNN output when T is long enough that remaining membrane potential is insufficient to fire a spike."}, {"title": "3.4 Ablation Study", "content": "Proof. We first combine eq. (2) and eq. (3) to get the potential update equation:\n$V'(t) - V'(t - 1) = W's^{l-1}(t)\\lambda^{l-1} - s'(t)\\lambda'$.\nBy summing up eq. (16) from 1 to inference time-step T, we have:\n$V'(T) - V'(0) = W'\\lambda^{l-1}\\sum_{t=1}^{T}s^{l-1}(t) - \\lambda'\\sum_{t=1}^{T}s'(t)$.\nwhere $\\sum_{t=1}^{T}s'(t) = \\sum_{t=1}^{T}(S'(t) - S'(t - 1)) = S'(T) - S'(0)$ according to eq. (4). If we set $S'(0) = 0$, eq. (17) can be simplified as:\n$V'(T) - V'(0) = W'\\lambda^{l-1}S^{l-1}(T) - \\lambda'S'(T)$.\nThen, we divide both sides of eq. (18) by the threshold $\\lambda'$. With additional simple transformation, we can obtain the expression for spike tracer:\n$S'(T) = \\frac{W'\\lambda^{l-1}S^{l-1}(T) + V'(0) - V'(T)}{\\lambda'}$.\nWhen the simulation time-steps T is long enough so that the remaining membrane potential $V'(T)$ is insufficient to fire a spike, eq. (19) can be rewritten as the expression of :\n$S'(T) = \\frac{W'\\lambda^{l-1}S^{l-1}(T) + V'(0)}{\\lambda'}$.\nwhere $S'(T) = 0, 1, ..., S_{max}$. By multiplying both sides of the eq. (20) by $\\lambda'$, we can get the final equation:\n$X'(T) = \\lambda' clip(\\frac{WX^{l-1}(T) + V'(0)}{X}, 0, S_{max})$,\nwhere $X'(T) = \\lambda'S'(T). by definition.\nEquation (21) describes the relationship between unweighted postsynaptic potential of BIF neurons in adjacent layers.\nConsidering a quantization CNN with quantization scale s and quantization level n:\n$X' = s. clip(\\frac{WX^{l-1} + b}{X}, 0, n)$.\nIf we set $\\lambda' = s$, $S_{max} = n$, $V'(0) = b + 0.5s$, eq. (22) and eq. (21) are equivalent."}]}