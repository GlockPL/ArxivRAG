{"title": "RAM2C: A Liberal Arts Educational Chatbot based on Retrieval-augmented Multi-role Multi-expert Collaboration", "authors": ["Haoyu Huang", "Tong Niu", "Rui Yang", "Luping Shi"], "abstract": "Recently, many studies focus on utilizing large language models (LLMs) into educational dialogues. Especially, within liberal arts dialogues, educators must balance Humanized communication, Teaching expertise, and Safety-ethics (HTS), besides the subject knowledge itself. However, due to collecting massive amounts of HTS-compliant teaching dialogues from real world as training corpus is expensive, the outputs of existing LLMs in teaching dialogues fall short of human standards. To address this, we design a Retrieval-augmented Multi-role Multi-expert Collaboration (RAM2C) framework to automatically generate such dialogues data. Specifically, we first establish HTS-guided knowledge bases, encompassing three domain knowledge in teaching skills, psychology, and safety ethics. Then, RAM2C organizes LLMs, which are retrieval-augmented by the above different knowledge bases, into multi-experts groups with distinct roles to generate the HTS-compliant educational dialogues dataset. We then fine-tuned the LLMs using this dataset. Empirical evaluations indicate that RM2C-empowered LLMs excel in Chinese reading teaching, offering more personalized, and ethically safe teaching response, demonstrating RAM2C's practicality and high quality. We release the experiments at https://github.com/ram2c/ram2c.", "sections": [{"title": "1 Introduction", "content": "As generative artificial intelligence advances, educational chatbots based on large language models (LLMs) are hoped to provide promising educational services in many scenarios of liberal arts, like literature reading, writing and debating. Specifically, compared to subject-specific factual knowledge, the rich and personalized linguistic forms, teaching skills, along with ethical safety involved in content analysis (HTS in Fig.1 1), are equally important in liberal educational dialogues (Wang et al., 2024; Deng et al., 2023; Li et al., 2023). However, due to the difficulty of collecting a sufficient amount of HTS-compliant teacher-student multi-turn dialogue data from real teaching scenarios for optimizing LLMs, the responses of existing LLMs to real educational contexts are unable to meet the HTS requirements."}, {"title": "2 Methodology", "content": "In this section, we elaborate on the principle components in RAM2C, as shown in Fig.2 and Fig.3."}, {"title": "2.1 Multi-role Multi-expert Collaboration", "content": "Unlike multi-role single-agent collaboration(Tang et al., 2023) and single-role multi-agent collaboration(Wang et al., 2023b), we utilize prompt engineering to create three groups of LLM experts with distinct roles: T-Group: Chinese language teachers, P-Group: educational psychologists, and E-Group: ethical safety experts, with 3 experts for each role, as shown in Fig. 2a.\nThe refinement of dialogue responses, as a sequential task flow, is completed by T/P/E-Group collaboration in turn. Specifically, as depicted in Fig. 2b, the initial response generated by a basic LLM, along with the current topic and student context, is provided to the T-Group for analysis and synthesis. The resulting output then serves as the input for the P-Group. This process is similarly applied to the remaining groups. Ultimately, the final response, which has been subjected to ethical scrutiny by the E-Group, is conveyed to the students."}, {"title": "2.2 Retrieval Augmented Experts", "content": "Due to the lack of relevant corpus support for LLMs in various liberal arts education scenarios, it is necessary to establish a multi-source knowledge base to provide references.\nWe emphasize that, unlike general RAG systems, which provide references that enhance the factual accuracy of LLMs outputs, LLMs for liberal arts dialogues need demonstrations or inspiration from documents with varying reference values. For instance, aspects such as language style, vocabulary usage, and logical connections in these documents are particularly beneficial for improving humanized communication of LLMs. These complex semantic structures cannot be achieved solely through semantic vector matching. As shown in Fig.4b, vector databases are likely to return relevant but lower reference value documents.\nTherefore, after obtaining preliminary retrieved documents, we convene an expert group to analyze and vote from multiple perspectives, thereby filtering a diverse set of references with real reference value, see Document #15 in Fig.4b. During the in-group collaboration, each expert is assigned to different references, and is required to generate explicit analysis to its reference (proactive analysis to form diverse chains of thought, as shown in Fig.3). The individual revision of the raw response is then generated by utilizing this analysis."}, {"title": "3 Experiments", "content": null}, {"title": "3.1 Experimental Setup", "content": "Scenario settings. We select the scenario of literature discussion as an demonstration of educational dialogues, where students discuss several topics about the novel \"Robinson Crusoe\" with an LLM teacher who provides real-time feedback to promote the progress of dialogue.\nMulti-source knowledge base. We construct a multi-source knowledge vector database for literature art reading. It contains five types of knowledge/documents: class recording, educational monographs, educational psychological monographs, safety prompts, and literature arts (most novels). Details in Appendix C."}, {"title": "3.2 Model Fine-tuning", "content": "We use RAM2C to organize GLM-4 and generate a preference alignment dataset, which contains 3,500 dialogues. Each sample of this dataset is a (Q,A, R1, R2) pair, as shown in Fig.2c, where Q is the discussion topic generated by RAM2C, A is the answer by LLM-simulated student, and R1 is the chosen response from RAM2C-GLM4, R2 is the rejected one by the lightweight model without fine-tuning. We conduct fine-tuning experiments on lightweight models including Qwen1.5-4B(Bai et al., 2023), MiniCPM-2B(Hu et al., 2024), and ChatGLM3-6b(Du et al., 2022), based on Llama-Factory(Zheng et al., 2024)."}, {"title": "3.3 Evaluation Set Construction", "content": "The dialogue in liberal arts education is characterized by a strong subjectivity, in contrast to question-answer tasks evaluated based on factual correctness. Therefore, we recruit sixteen volunteers, including primary and secondary school teachers as well as university researchers, to evaluate the fine-tuned models across three dimensions (HTS). For each fine-tuned model, we construct a dialogue sample set, which structure is similar to the fine-tuning dataset in Section3.2. More details can be found in Appendix D."}, {"title": "3.4 Evaluation Results", "content": "Tab. 1 compares the performance of the fine-tuned model with its original version across three dimensions HTS. The results show that the fine-tuned model outperforms the original model in all three dimensions, particularly in humanized communication and teaching expertise. And the scores of inter-annotation agreement (IAA) show the moderate agreement between the volunteers' evaluation. \nWe also compared the performance between the fine-tuned lightweight model and mainstream Chinese commercial model GLM-4. As shown in Tab. 2, fine-tuned models can largely compete with GLM-4 that do not use RAM2C integration. And the RAM2C-empowered GLM-4 exhibits the highest level of performance.\nAblation studies. We conducted ablation experiments to explore the impact of different roles and the number of experts on dialogue quality, as shown in Tab. 3. RAM2C based GLM-4 models excluding the P-Group and/or E-Group result in varying degrees of performance decline in the dimensions of humanized communication and safety & ethics. However, the exclusion of the E-Group has a relatively limited impact on safety & ethics. We interpret this as general LLMs typically being well-aligned with human preferences and possessing basic ethical and safety qualities. Therefore, the collaboration of the T-Group and P-Group mitigates the performance decline caused by the absence of the E-Group. We also explored the difference in dialogue quality between one expert per group and three experts per group, and the results indicate that in-group collaboration is quite necessary."}, {"title": "3.5 Case Study", "content": "A well organized response is shown in Fig. 5 generated by the fine-tuned Qwen model. The response includes personalized emotional support and encouragements, as long as the assessment to the specific content of the student, comparing with the response of untrained version."}, {"title": "4 Conclusion", "content": "To address the HTS challenges of deploying LLMs for high-quality liberal arts educational dialogues, we propose RAM2C, a framework based on retrieval-augmented multi-role multi-expert collaboration to automatically generate high-quality dialogues for model fine-tuning. We conduct experiments in a literature discussion scenario. Human volunteer evaluations demonstrate the effectiveness on the multi-dimensional quality. In shorts, this work highlights the potential of LLM (especially lightweight models) in liberal arts educational dialogues by arousing its intrinsic role-playing and collaborating capability and extrinsic capability."}, {"title": "5 Limitations", "content": "We fine-tune and evaluate as many models as possible, but the number is still limited. Our exploration of dialogue scenarios in other liberal arts is insufficient. The design of prompt templates may affect the performance of LLMs, but due to time constraints, we are unable to test all variants of the templates. We will test the effectiveness of the system in other language (such as English). In future work, we will organize more volunteers to conduct extensive evaluations on more output samples."}, {"title": "Ethical Statement", "content": "The educational resources we collected online are obtained legally, and the collection process do not involve any personal privacy. We will not disclose any personal information without the consent of the individuals concerned. We have ensured the security and reliability of the aforementioned resources. We examined datasets generated and used in the research, which do not contain any discriminatory characteristics, including but not limited to age, gender, race, nationality, and religion. The output of the language model does not contain any personal privacy information or other inappropriate content. All volunteers participating in the evaluation experiments do so with informed consent, fully understanding the purpose and potential impact of their participation."}, {"title": "A Related Work", "content": "Recent studies have proposed technical strategies such as prompt engineering, retrieval augmented generation (RAG) and human preference alignments (Wei et al., 2022; Asai et al., 2023; Rafailov et al., 2023; Zhang et al., 2024; Ouyang et al., 2022). But these techniques face challenges including instruction following, retrieval accuracy and high value preference construction respectively. Consequently, edge-deployed models for professional education dialogue need an integrated systemic approach that includes data collection, model inference, and fine-tuning to address the aforementioned challenges (HTS), as a single technological path is not sufficient."}, {"title": "A.1 Educational chatbots", "content": "Educational chatbots, focusing on individualized guidance (Chen et al., 2023) and educational resource optimization (Deng et al., 2023), have been thoroughly explored. These systems, often powered by LLMs, play a supportive role by delivering exercises, recommending resources, training teachers, and tracking student progress(Dan et al., 2023; Markel et al., 2023). Despite their contributions, they typically feature limited dialogue openness(Macina et al., 2023) and have not extensively addressed the complex challenges of higher-level educational standards which face HTS challenge (Kuhail et al., 2023)."}, {"title": "A.2 Prompt engineering", "content": "Prompt engineering techniques are well explored recently to enhance reasoning capability and role-playing ability of LLMs (Wei et al., 2022) by showing few-shot examples, visualizing thought steps (Chain of Thought, CoT) (Wang et al., 2022, 2023b; Besta et al., 2023; Tang et al., 2023), assigning specific personas (Nori et al., 2023; Lu et al., 2024; Wang et al., 2023a; Zhou et al., 2023) and organizing multi-agent collaborations(Suzgun and Kalai, 2024). However, the instruction-following ability of lightweight models often falls short of advanced LLMs like GPT-4, thus limiting the practical effect of prompt engineering (Zhang et al., 2024; Yuan et al., 2023)."}, {"title": "A.3 Retrieval augmented generation", "content": "Recent studies about RAG (Gao et al., 2023) aim at addressing the lack of domain-specific factual knowledge and alleviating model hallucinations (Zhang et al., 2023b; Ji et al., 2023) by re-writing retrieval queries (Ma et al., 2023), executing self-reflection (Asai et al., 2023; Yan et al., 2024) and constructing a tree with differing levels of knowledge (Sarthi et al., 2024), which perform well in factual knowledge QA tasks. These studies are based on deep sentence embedding models (Chen et al., 2024), which filter relevant documents by comparing distances between two documents in semantic vector space. These retrieval methods based on vector semantic space matching struggle to effectively retrieve documents of high educational reference value. This is due to the following reasons: 1) Shallow semantic matching: sentence embedding models primarily focus on the combination patterns of phrases and word in the training corpus, performing poorly on complex structures and long texts (Chen et al., 2024; NetEase Youdao, 2023); 2) Diversity of reference value: the reference value of educational documents lies not only in providing accurate and factual knowledge but also in the expression style, word collocation, sentence structure, emotional feedback, and writing logic. These patterns are difficult to be captured through embedding models."}, {"title": "A.4 Human preference alignment on education", "content": "Researchers have built specialized fine-tuning datasets to trigger the model's ability in specific domains (Dan et al., 2023; Zhang et al., 2023a). However, the high degree of individualization and diversity in educational scenarios poses challenges to collecting high-quality data (Hicke et al., 2023; Long et al., 2024). Recently, BEA 2023 dataset and several related fine-tuning studies are proposed to enhance teaching ability of LLMs, which is sampled from Teacher-Student Chatroom Corpus for only English learning (Tack et al., 2023; Huber et al., 2023; Balad\u00f3n et al., 2023). And the samples are quite short (~100 tokens) which hinder the profundity and complexity of dialogues. Therefore, we need to construct an educational dialogue scenario that is more specific in discussion topics but also fairly open-ended and useful for different languages.\nConsequently, edge-deployed models for education need an integrated systemic approach that includes data collection, model inference, and model fine-tuning to address the HTS challenges in Fig.1, as a single technological path is not sufficient."}, {"title": "B HTS: multi-dimensional challenge for educational dialogue", "content": "We have summarized three dimensions for evaluating liberal arts educational dialogue: humanized communication, teaching expertise, and safety & ethics."}, {"title": "B.1 Humanized communication", "content": "Cultural competence: The system should understand and respect diverse cultural backgrounds, enabling effective and inclusive communication.\nActive supportiveness: It should provide encouragement and positive reinforcement, fostering a supportive learning environment for users.\nEmotional feedback: The system should recognize and respond to users' emotional states, enhancing engagement and connection."}, {"title": "B.2 Teaching expertise", "content": "Assessment proficiency: The system should effectively evaluate user performance and understanding, providing meaningful feedback for improvement.\nSubject mastery: It must possess in-depth knowledge of various subjects, ensuring accurate and relevant information is conveyed.\nPedagogical skills: The system should employ effective teaching strategies, adapting to different learning styles and needs.\nAccurate response: It should deliver precise and reliable answers to user inquiries, promoting trust and credibility."}, {"title": "B.3 Safety and ethics", "content": "Data privacy: The system must protect user data, ensuring confidentiality and compliance with relevant privacy regulations.\nContent appropriateness: It should filter and provide content that is suitable for the intended audience, avoiding harmful or offensive material.\nAbuse prevention: The system must have mechanisms in place to identify and prevent abusive interactions, ensuring a safe experience for all users."}, {"title": "C Multi-source knowledge base", "content": "We establish a multi-source knowledge base to support the multi-role multi-expert collaboration, based on Chromadb\u00b2 and the sentence embedding model BGE-m3(Chen et al., 2024). The knowledge base includes the following sources of knowledge:\n1. Class dialogue records. Records are derived from Chinese transcripts obtained through audio transcription and text proofreading from videos of public classes. These records demonstrate different teaching styles and responses that adhere to educational standards.\n2. Theories and research papers on Chinese language teaching. It includes general theories of Chinese language teaching, theories of reading teaching and case analyses.\n3. Theories and case analyses in educational psychology.\n4. Safety prompts. Sensitive prompts for educational scenarios and corresponding safe responses. We use GLM-4-Flash to filter and rewrite seven types of malicious prompts and their appropriate responses from Sun et al. (2023), including crimes and illegal activities, ethics and morality, insult, mental health, physical harm, privacy and property, unfairness and discrimination, for reference by cultural safety experts."}, {"title": "D Evaluation dataset and criteria", "content": "We generate a dialogue set for evaluation of each fine-tuned model. The structure of the dialogue set is same as the fine-tuning dataset in Section3.2, (Q,A,R1,R2). The Q is the question generated by the model and not included in the fine-tuning dataset, the A is a LLM-simulated student's response, and R1 and R2 are the responses from the fine-tuned model or the baseline model to the student's response. The positions of R1 and R2 are unspecified to prevent any influence on the evaluators' preferences.\nFor each dimension evaluation (H/T/S), each volunteer is provided with a random sample of 25 items from the set and makes choices between R1 and R2 based on evaluation criteria (Tab. 5), indicating whether the fine-tuned model is better/equal/worse, and thereby assigning corresponding scores (4/2/0). The total score reflects the performance of the tested model. The score above 50.0 means better overall performance against the baseline model. And score of 50.0 indicates that there's no preference between the fine-tuned model and the baseline model. Scores below 50.0 mean that the fine-tuning has negative effect on the model. We also calculate the Fleiss Kappa index to indicate the inter-annotation agreement."}]}