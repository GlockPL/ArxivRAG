{"title": "Paved or unpaved? A Deep Learning derived Road Surface Global Dataset from Mapillary Street-View Imagery", "authors": ["Sukanya Randhawa", "Eren Ayg\u00fcn", "Guntaj Randhawa", "Benjamin Herfort", "Sven Lautenbach", "Alexander Zipf"], "abstract": "We have released an open dataset with global coverage on road surface characteristics (paved or unpaved) derived utilizing 105 million images from the world's largest crowdsourcing-based street view platform, Mapillary, leveraging state-of-the-art geospatial AI methods. We propose a hybrid deep learning approach which combines SWIN-Transformer based road surface prediction and CLIP-and-DL segmentation based thresholding for filtering of bad quality images. The road surface prediction results have been matched and integrated with OpenStreetMap (OSM) road geometries. This study provides global data insights derived from maps and statistics about spatial distribution of Mapillary coverage and road pavedness on a continent and countries scale, with rural and urban distinction. This dataset expands the availability of global road surface information by over 3 million kilometers, now representing approximately 36% of the total length of the global road network. Most regions showed moderate to high paved road coverage (60-80%), but significant gaps were noted in specific areas of Africa and Asia. Urban areas tend to have near-complete paved coverage, while rural regions display more variability. Model validation against OSM surface data achieved strong performance, with F1 scores for paved roads between 91-97% across continents. Taking forward the work of Mapillary and their contributors and enrichment of OSM road attributes, our work provides valuable insights for applications in urban planning, disaster routing, logistics optimization and addresses various Sustainable Development Goals (SDGS): especially SDGs 1 (No poverty), 3 (Good health and well-being), 8 (Decent work and economic growth), 9 (Industry, Innovation and Infrastructure), 11 (Sustainable cities and communities), 12 (Responsible consumption and production), and 13 (Climate action).", "sections": [{"title": "1. Introduction", "content": "Road surface type information is a useful attribute for accurate travel time estimations, for disaster routing (humanitarian response) or for improved understanding of the drivers behind economic opportunity. It can furthermore facilitate data-driven urban planning, help to assess traffic related emissions or to understand biodiversity linkages and many such applications in environmental and climate science.\nFor instance, to efficiently plan suitable routes during disaster events, a routing service must take into account accurate estimated travel times by integrating critical data such as road type, surface conditions and road width from different sources and or-ganizations. Among other factors road surface type determines the vulnerability of a road network in the context of floods at the urban and national level highlighting the need of updated and complete data on road surface quality on a global scale (Klipper et al., 2021; Papilloud et al., 2020; Petricola et al., 2022).\nMoreover, transportation plays a multifaceted role in the pursuit of (economic) development objectives and there is a strong association between per capita income and the magnitude and quality of road infrastructure and road conditions (Queiroz and Gautam, 1992; Song et al., 2021; Pinatt et al., 2020). According to the African Development Bank (AfDB), 53% of roads in Africa are unpaved and are expected to remain so for the foreseeable future (African Development Bank Group, 2014).\nOpenStreetMap (OSM) has been identified as as promising and growing open dataset to study road networks globally. There have been studies on the assessment of completeness of OSM road data that have shown that globally, OSM is ~83% complete and ~40% of countries including several in the developing world have a fully mapped street network (Barrington-Leigh and Millard-Ball, 2017). Recent advancements in deep learning based approaches to derive geo-spatial information have improved the coverage of global scale open building and road datasets even further, providing data for previously unmapped or under-mapped regions (Meta, 2020; Microsoft, 2020; Google Research, 2021). However, it is important to go beyond detection of roads and buildings towards enrichment of (OSM) attributes of roads and buildings as it significantly enhances the utility of this data for various sectors, including transportation, urban planning, environmental studies, disaster management, and technology development.\nStill, only few limited studies have reported OSM data quality beyond geometric completeness for certain regions (Mobasheri et al., 2017; Moradi et al., 2021). A detailed assessment of specific road attributes such as surface type is still missing. All we know is that the current state of road surface data in OSM is highly incomplete, where only 30-40% of the global road network includes surface type data. Nevertheless, in previous studies road surface condition prediction has been studied in the context of autonomous driving where different sensors (such as profilometers, inertial and acoustic sensors, smartphone motion sensors such as tri-axial accelerometers, gy-roscopes, magnetometers and LIDAR) have been used for road defect detection and measurement (Urano et al., 2019; Ma et al., 2022; Higashimoto et al., 2021; Cabral et al., 2018). These approaches are both hard to reproduce and challenging to scale as such detailed sensor data is usually not openly available.\nTo address this overall data gap we investigate the potential of a novel source to derive road attribute information: Mapillary, a crowdsourcing platform to collect street-view imagery (SVI). Mapillary presents a very heterogeneous data source which contains imagery captured in a wide range of conditions and locations and is quite diverse in terms of scenes, weather or season (Ma et al., 2019). Images are sourced from different devices (mobile phones, tablets, action cameras, professional capturing rigs) and differently experienced photographers. Advantages of using SVI data include low-cost, rapid, high-resolution data capture and a unique pedestrian/vehicle perspective. However, disadvantages include limited attribute information and unreliability for temporal analyses or availability of latest updated information (Biljecki and Ito, 2021).\nRapid advances in areas of computer vision and deep learning algorithms have enabled researchers to detect, characterize and quantify different attributes of visual road-scene environments, thereby enhancing overall understanding of scene attributes (ranging from neighbourhood to building or street level attributes) such as safety (Lu et al., 2018; Porzi et al., 2015), greenness (Li et al., 2015) and population demographics (Gebru et al., 2017). Most of the times, element-level observation using object detection or segmentation models is performed to extract multiple category objects from street-view images (Zhang et al., 2018). Mapillary also provides the Vistas Dataset (large-scale street-level image dataset) containing 25,000 high-resolution images annotated into 66 object categories with additional, instance-specific labels for 37 classes. However, information about road surface is not covered in the Vistas Dataset (Neuhold et al., 2017).\nAs shown in some studies, it is also possible to extract high-dimensional visual features to enhance the understanding of images for evaluation of place distinctiveness and comparison of their similarities (w.r.t urban physical environment for example) by using deep convolutional neural networks (CNN) (Wang et al., 2019; Kang et al., 2020). Due to the explicit positional information encoding, vision transformers - utilizing the multi-head attention module (Vaswani et al., 2017) - have shown superior performance in applications such as cross-view image geo-localization (Zhu et al., 2022). In particular, the SWIN transformer architecture has been successfully used for exhibiting generalized performance in various street-view image sce-narios such as detection of urban physical disorder (Hu et al., 2023). Since vision transformers learn spatially localized patterns, they make a good candidate for applications that involve understanding visual road scene environments such as road surface classification problems.\nOur objective is to close the existing road attribute data gap, by releasing a first of its kind planet-scale dataset on road surface type (paved or unpaved) based on street-view imagery from Mapillary, in order to support humanitarian response, urban planning and progress towards the Sustainable Development Goals. Building upon the success of deep learning based building and road geometry detection, we want to pave the way towards deep learning based enrichment of road attribute information. We have made the dataset available at the following link TBD. (Please note the data would be made available only after the acceptance of the paper) The overarching research aim of the paper could be broadly classified as follows:\n\u2022 RQ1. To assess the reliability of computer vision based DL models for accurate prediction of road surface tags based on a street-view imagery from diverse global regions.\n\u2022 RQ2. To derive insights based on integrating different geospatial data (urban, rural, human development index) to augment understanding of road surface condition across countries and regions.\nIn the next section, we outline the data preparation workflow. Section 3 provides details on the DL models employed. Next, we present the GIS analysis methods (Section 4) and data insights and details for global road surface coverage (Section 5)."}, {"title": "2. Data Preparation", "content": "The overall methodology is summarized in Figure 1. First, the Mapillary images were extracted and filtered for the entire globe (Section 2.1). Then, a balanced sub-dataset (in terms of class distribution) was created for training different deep learning models (Section 2.2). The best performing model - the SWIN transformer - was deployed for generating a planet-scale dataset for road surface type information (Section 3)."}, {"title": "2.1. Mapillary Data Download and Processing", "content": "As a first step, the Mapillary API tile endpoint (tiles.mapillary.com) was used to retrieve GPS sequences. A sequence is a list of GPS coordinates where each node represents the location of an image. The requests for this endpoint were limited to 50,000 per day. A tile map service (TMS) grid at zoom level 8 was created and intersected with continent polygons to filter out the ocean areas. This amounted to a total of 16,423 tiles. Measured at the equator a single tile covers an area of roughly 150 km x 150 km. All tiles containing Mapillary sequences were extracted (about 5,984 tiles) as depicted in Figure 8. A total of 11,031, 802 sequences were downloaded using the tiles endpoint.\nSecond, the Mapillary API graph endpoint (graph.mapillary.com/images) was used to get the metadata for multiple images with requests limited to 60,000 per minute. This endpoint was used for download of all image points (with metadata including location and attribute data) corresponding to the sequences obtained in the previous step. In total, over 11 million sequence IDs have been processed which correspond to roughly 2, 2 billion image metadata points downloaded. The attributes downloaded for each image have been listed in the Table 6 in Appendix. Figure 2 provides a closer look into the sequences and images on a city level from some key urban areas across the globe.\nHowever, 373, 889 sequences out of roughly 11 million could not be extracted because the download was blocked by the Mapillary API - 66% of these sequences were located in Europe. Figure 13 in Appendix provides a closer look into the distribution of the missing sequences. Around 230,000 out of 248, 114 missing sequences in Europe were located in Ukraine and were presumably blocked to prevent unintended usage for military action. Table 1 summarizes the results from the download process.\nThird, spatial filtering on the metadata was performed to select only the relevant images (preserving a spatial gap of 1000m for non-urban and 100m for urban areas) that would be later downloaded and fed into the Deep Learning models. For data processing we used DuckDB, an open-source SQL database management system, which is optimized for complex query workloads and supports vectorized query execution, which significantly speeds up data processing (Kohn et al., 2022). We used Apache parquet, a new, open source, column-oriented data file format designed for efficient data storage and retrieval.\nUrban centers were identified by intersection with two datasets: 1) the Africapolis dataset (OECD/SWAC, 2024) and 2) the Global Human Settlement Layer Urban Centres Database"}, {"title": "2.2. Data Preparation for Deep Learning", "content": "In order to investigate if the road surface in the given street-view image was paved or unpaved, we treated this as an image classification problem. We created a labeled dataset using the HeiGIT CrowdMap web application (Gro\u00df et al., 2023). During a mapathon at Heidelberg University in July 2023, 30 volunteer participants classified about 21,000 random Mapillary images from 39 countries in sub-Saharan Africa as either \"paved\", \"unpaved\u201d or \u201cbad imagery\". The sub-Saharan Africa region ensured sufficient class distribution for both paved and unpaved categories, while the bad quality images were filtered out. These 21,000 images were split into training and validation sets (80:20). To make sure that the prediction accuracy was not effected due to class imbalance, 8,500 images each of paved and unpaved images were used to create a balanced training dataset of a total of 17,000 images.\nThe images in the training set were size cropped from 2000x1200 pixels to 427x256 for optimizing time and space complexity. This step helped in preserving the aspect ratio and maintaining a consistent input size. The augmented images were enhanced further by applying the Random Flip, RandAugment (Cubuk et al., 2019) and Random Erasing (Zhong et al., 2017) data augmentation methods. Thereby, each image started off by being flipped horizontally, resulting in a mirror image, with a probability of 0.5, then underwent two randomly selected image augmentations out of fifteen available options, such as contrast adjustment, histogram equalization, color inversion, random rotation, increasing exposure, random horizontal (vertical) translation. After that a Random Erasing was applied to the images, with a probability of 0.25. This results in generating images with various levels of occlusion as rectangular regions of the images are randomly selected and the pixels of this region are erased and replaced with random values. Utilization of these data augmentation techniques allowed to increase the diversity of the images in the training set, thus effectively mitigating overfitting, improving the generalization ability and enhancing the model's classification performance."}, {"title": "2.3. Matching Mapillary and OpenStreetMap Data", "content": "Mapillary images provide a potential data source for adding OSM feature attribute information without the need to conduct a field survey. However, due to imprecise geo-referencing of images and OSM objects it was necessary to map match the objects in the two data sets. First, we extracted all relevant OSM road features via the ohsome API (Raifer et al., 2019) based on spatial location and selected all line geometries with the OSM tag key value 'highway'. The matching algorithm was based on the shortest Euclidean distance between OSM road segment geometries and the Mapillary image coordinates (cf. Figure 3).\nWe intersected the bounding boxes of the OSM road segments extended by a buffer of 30m with the Mapillary images. All Mapillary image points within a 10 meter distance to OSM road segment were directly assigned to that road segment - the threshold is based on the assumption of a GPS error tolerance of 5m. Remaining points were assigned in a second and third step to the closest OSM segments within proximity of 20m and 30m respectively. The results of the OSM assignment are depicted in Figure 3. It is also possible that some image points are assigned to multiple OSM segments, particularly near intersections as also depicted in Figure 3 (a). Figure 3 (b) shows the matching in a forest/park area with sparse distribution of roads and highlights the misalignment that could possibly occur, underscoring the limitations of the algorithm in non-urban settings. The advantage of this approach is that all the point outliers or bad points get filtered out automatically with no OSM segment assigned. However, as OSM might not be completely mapped in the region, points, that correspond to road segments not mapped in OSM, are removed as well.\nTo standardize the distance-based assignment of each image point to the relevant OSM segment(s), we developed a normalized confidence index (Equation 1). This index captures the distance-based contrast between the nearest OSM segment and other surrounding segments for each image point (in case of multiple segments within the buffered bounding box). It becomes 0 for the nearest OSM segment as it is compared to itself and the index increases for segments that lie farther from the point. As the \\textit{percent_diff} approaches 1, the likelihood of a correct assignment to that OSM segment diminishes. Higher values for both indicators imply greater uncertainty, suggesting that the image point might more accurately correspond to another (nearest) road segment.\n\n$\\Indexpercent_diff = \\frac{d_{current} - d_{nearest}}{d_{current} + d_{nearest}}$\n\nAs a final step towards data enrichment all the matched Mapillary image points and their corresponding label (paved or unpaved) were aggregated per OSM road segment ID. This was done via a distance-based weighted average approach wherein the closer points matched to a segment were given higher weights than the ones further away. Based on a this weighted average score, the road attribute paved or unpaved was determined and assigned per OSM road segment."}, {"title": "3. Deep Learning Pipeline", "content": "We trained a classical convolutional neural network (CNN) deep learning model (ResNet) (He et al., 2016) as well as two recent model architectures: a SWIN Transformer model (Liu et al., 2021) and ConvNext (Liu et al., 2022) as a CNN that borrows elements from Vision Transformer models. We used the models from OpenMMLab (https://openmmlab.com/) which is an open-source algorithm platform that is based on PyTorch deep learning framework for model training and evaluation. As expected the performance of ConvNext and SWIN Transformer models is slightly better than ResNet (cf. Table 2), although all three models performed quite well for this problem with macro average F-1 scores greater than 98%, while the training dataset was comprised of images from the African continent.\nThe different model architectures process their inputs very differently. ResNet allows intricate feature extraction due to the incorporation of residual or skip connections which leads to increased model robustness. However, ResNet relies on pre-defined patterns and hierarchical feature extraction. In comparison, the Vision Transformer models are based on a self-attention mechanism. This mechanism allows the model to focus more on an understanding of the relationships between dif-ferent elements within an image and enables thereby the model to interpret images as a whole. This is based on the use of non-overlapping patches rather than relying on stacked convolutional layers. Hierarchical Transformer models (e.g. SWIN Transformers as used here) have been shown to outperform normal Vision Transformer models on a wide variety of vision tasks (Liu et al., 2021). On the other hand, ConvNext, which is a pure convolutional model, was inspired by the design of Vision Transformers. The ConvNeXt architecture used a pyramidial structure and achieved competitive performance on various vision tasks. ConvNext and SWIN Transformer are both equipped with similar inductive biases, but differ significantly in the training procedure and macro/micro-level architecture design.\nEven though all the models showed robust performance, we used a SWIN-Transformer (Hierarchical Vision Transformer using shifted Windows) image classification model which had been pre-trained on the Imagenet-1k dataset (Deng et al., 2009) and fine-tuned on our self-annotated street view imagery dataset for the planet-scale application. Our decision is based on the knowledge that the model architecture is known to establish long-range dependencies (Liu et al., 2021), effectively extracting global features from the images. Given the heterogeneity of the Mapillary street-view imagery across different global regions, this model architecture was assumed to offer a higher potential for accurate road surface classification based on the road surroundings. With label smoothed cross entropy loss, the model was trained for 120 epochs, employing the Adam optimizer with weight decay.\nAs is expected in a binary classification problem, all the images were classified as having paved or unpaved roads. However, some anomalous images that did not contain any street were nevertheless classified by the model with respect to road surface information. These bad images for example contain only side-views from a street containing partial views to side-walks or a track. To circumvent the problem of images with no or partial roads, we used a combination filter with the following two models:\n1. A fast semantic segmentation model (Xu et al., 2023), pretrained on the \"cityscapes\" dataset, was used to filter out images with less than 10% road pixels.\n2. A CLIP (Contrastive Language-Image Pre-training) model based on the ViT-L/14 Transformer architecture (Radford et al., 2021) as a zero shot classification model was used to filter out images without roads. Two classes i.e a photo of a road and a photo with no road in it were defined (based on a probability threshold) and used for re-moval process.\nThe final combination filter removes images where the road pixel coverage (in terms of proportion of total image pixels) is less than 10% and the CLIP model predicts that the image is \u201ca photo with no road in it\" (for any probability score) or where the clip model says that the image is \"a photo with no road in it\" with a probability greater than 90%. In total, these comprised approximately 4-5% of the total images. However, a few images with no roads might have escaped our cleaning procedure."}, {"title": "4. Data Analysis", "content": "To investigate model performance, we first assess the reliability of our model designed to predict road surface using street-view images. To ensure the model's accuracy, we employed Grad-CAM (Gradient-weighted Class Activation Mapping) for visual explanations (Selvaraju et al., 2019). This method allowed us to inspect how well the SWIN Transformer model identifies paved and unpaved roads.\nFurthermore, we compare our model results with OSM data in order to understand to what extent our predicted road surface corresponds to the already mapped OSM road surface tags. To assess the accuracy a confusion matrix for each continent was derived based on the predictions, depicting the True and False Positives and Negatives and correspondingly calculated measures thereof - Accuracy, F-1 score, Precision and Recall. True Positives are images where model prediction and OSM agree on the existence of a paved road, whilst True Negatives are images where both datasets agree that the road is unpaved. Consequently, False Positives are images where the model predicted a paved road, but OSM indicated an unpaved road. False Negatives are the cases where the model prediction resulted in an unpaved road, whereas OSM labelled as a paved road. We evaluated the confusion matrix and derived performance scores for each continent. The OSM road attributes were simplified as \"paved\" or \"unpaved\" based the following OSM tag values:\n\u2022 Paved: surface in (paved, asphalt, chipseal, concrete, concrete:lanes, concrete:plates, paving_stones, sett, un-hewn_cobblestone, cobblestone, bricks, metal, wood)\n\u2022 Unpaved: surface in (unpaved, compacted, fine_gravel, gravel, shells, rock, pebblestone, ground, dirt, earth, grass, grass_paver, metal_grid, mud, sand, woodchips, snow, ice, salt)"}, {"title": "4.1. Model Evaluation Methods", "content": "To investigate model performance, we first assess the reliability of our model designed to predict road surface using street-view images. To ensure the model's accuracy, we employed Grad-CAM (Gradient-weighted Class Activation Mapping) for visual explanations (Selvaraju et al., 2019). This method allowed us to inspect how well the SWIN Transformer model identifies paved and unpaved roads.\nFurthermore, we compare our model results with OSM data in order to understand to what extent our predicted road surface corresponds to the already mapped OSM road surface tags. To assess the accuracy a confusion matrix for each continent was derived based on the predictions, depicting the True and False Positives and Negatives and correspondingly calculated measures thereof - Accuracy, F-1 score, Precision and Recall. True Positives are images where model prediction and OSM agree on the existence of a paved road, whilst True Negatives are images where both datasets agree that the road is unpaved. Consequently, False Positives are images where the model predicted a paved road, but OSM indicated an unpaved road. False Negatives are the cases where the model prediction resulted in an unpaved road, whereas OSM labelled as a paved road. We evaluated the confusion matrix and derived performance scores for each continent. The OSM road attributes were simplified as \"paved\" or \"unpaved\" based the following OSM tag values:\n\u2022 Paved: surface in (paved, asphalt, chipseal, concrete, concrete:lanes, concrete:plates, paving_stones, sett, un-hewn_cobblestone, cobblestone, bricks, metal, wood)\n\u2022 Unpaved: surface in (unpaved, compacted, fine_gravel, gravel, shells, rock, pebblestone, ground, dirt, earth, grass, grass_paver, metal_grid, mud, sand, woodchips, snow, ice, salt)"}, {"title": "4.2. Global Road Surface Analysis", "content": "We analyzed how the Mapillary coverage of OSM roads varies across space. To assess this spatial heterogeneity, we calculated the ratio of total Mapillary sequence length vis-a-vis total OSM segment length for each tile of a zoom level 8 map of the whole world. As a single OSM road segment can be (partially) covered by several overlapping Mapillary sequences, we calculated the total Mapillary coverage length per tile as the sum of the longest Mapillary sequence for each OSM segment in that tile. In our calculations we further distinguished Mapillary coverage between urban and rural area and for various road type classes as indicated by OSM highway tag values.\nSecond, we investigated the surface pavedness ratio for all roads which were covered by Mapillary data on a global scale using a zoom level 8 tiles map. Again, this information has been disaggregated using urban / rural images and per road type class. Additionally, we derived box plots to inspect the distribution of surface pavedness across continents and road type. Finally, we run a regression analysis to investigate the correlation between average road pavedness and HDI values per country."}, {"title": "5. Results", "content": "The upcoming sections presents our findings, where we evaluate the performance of our deep learning models on a global scale by comparing correct and incorrect predictions with OSM data via confusion matrix and standard machine learning performance metrics. Moreover, we analyse the spatial distribution of Mapillary data coverage along with OSM road surface information, delve deeper into the paved ratio analysis to understand the emerging global patterns for road surface infrastructure on continent and country level."}, {"title": "5.1. Model Performance Evaluation", "content": "By reviewing the activation maps (cf. Fig. 5), we observed that the model could accurately highlight areas corresponding to road surfaces, with warmer colors denoting areas of higher activation, indicating that these regions contributed significantly to the surface classification. Interestingly, the model maintained robustness even when facing complex or ambiguous images, such as those with partial road visibility or covered with dust and sand (Fig. 5(b), (e), and (f)). Despite the variations in image quality, lighting, and scenery, the model's predictions remained consistent, providing confidence in its generalization capabilities across diverse conditions.\nTo further analyze its performance, we reviewed True Positives and False Positives (Fig. 6 and Fig. 7, respectively), highlighting instances where the model succeeded or struggled to detected paved road surface. The model handled diverse scenarios, including occlusions caused by cars or animals, quite well. However, challenges arose in situations where road surfaces were covered with mud, gravel or water (Fig. 6 (b), (c),(i) or (d)). These instances occasionally reduced the model's confidence or resulted in incorrect predictions, reflecting the inherent difficulty of these mixed surface types even for human annotators."}, {"title": "5.2. Mapillary Coverage Analysis", "content": "Before analysing global spatial distribution of road pavedness, we need to evaluate the coverage of the Mapillary dataset. In general, Mapillary's global coverage was spatially very un-even (cf. Figure 10 (a)). Most western European countries, North America and Australia were better covered than other parts of the world. For Asia, Africa and South America, many countries showed a low coverage. Russia and China showed strong heterogeneity in terms of Mapillary data coverage. Japan, Thailand and some parts of India showed good coverage while Pakistan, Iran and Indonesia showed notably sparse coverage. The average Mapillary global coverage was 3.48% with hot spots of about 70% coverage in cities such as Antwerp, Lille, W\u00fcrzburg, Leipzig, Berlin, Moscow, Detroit, Boston, Washington D.C, Melbourne.\nWe observed a notable distinction in the spatial distribution of Mapillary coverage for urban and rural areas (cf. Fig. 10 (b) and (c)). On an average urban areas showed higher coverage (8.88%) than rural areas (2.65%). Australia, Europe and North America showed only marginal coverage differences between urban and rural areas. In contrast, the divide was most pronounced for South America, Africa and parts of Asia (cf. Fig. 14 in Appendix).\nNevertheless, our model results add surface information for 3.92 Million kilometers of roads for places where this information was previously unavailable (cf. Table 4). In total our combined road surface dataset sourced from OSM and Mapillary covers a length of 36.7 Million kilometers of roads. Globally, this dataset increases the coverage of surface information from 33% (OSM only) to about 36%. A particular high increase could be observed for North America, where coverage increased by 6 percentage points.\nMapillary coverage varied also considering different OSM road classes (cf. Fig. 9 (a)). The most important roads in a country's system such as motorways and trunks showed a higher global Mapillary coverage of about 45% with a steady decrease in the coverage observed for less important roads. Residential and unclassified streets showed a sharply staggering coverage ranging from 2 - 5%. A similar pattern was observed for urban and rural areas with 65% and 40% coverage for most important roads respectively (Figure 9 (b) and (c)). The presence of outliers and the spread of the data also indicate inconsistencies in coverage for less dominant road types, such as foot ways or unclassified roads, across different regions."}, {"title": "5.3. Global Road Surface Analysis", "content": "After compiling the global dataset using Mapillary street-view imagery, we visualized the aggregated results on zoom 8 tiles to better understand global road surface patterns. These patterns for paved ratio (or state of infrastructure) are displayed in Fig. 10. Distinct areas with a proportion of paved roads (colored in yellow or orange) less than 40% include countries like Pakistan, Nepal, Rwanda, Burundi, parts of Tanzania, Sierra Leone, Guinea, Laos, Mozambique, Mali, and Bolivia. In contrast, large regions show medium to high paved ratios (between 60% and 80%) - notably across South America, Asia, East-ern Europe, Mexico, India, and Australia. Table 5 provides a breakdown of these results per continent, as well as for urban and rural areas.\nMotorways and primary roads are mostly paved across all continents and in both urban and rural areas as seen in Figure 11. Residential roads and tertiary roads show the most variation in pavedness, particularly in rural areas.\nA comparison of the pavedness metric against the HDI (cf. Fig 12(a)) indicated a positive correlation between HDI and total pavedness at the country scale. Europe and North America dominated the upper right corner with high HDI and high road pavedness, whereas Africa and Oceania trail towards the bottom left. Oceania island countries were high on HDI but low on pavedness. A similar pattern was observed for the association between HDI and both urban and rural pavedness (cf. Fig 12(b) and (c)): Europe and Asia exhibited higher rural pavedness, also contributing to their elevated HDI, while African countries clustered at the lower end of both metrics. However, it is noteworthy to mention that global and rural results (Fig 12(a) and (c) were more dispersed in comparison to urban results (Fig 12(b)) that tended to concentrate. This was likely due to the variation of HDI which is more distinct in rural areas across countries than for urban areas."}, {"title": "6. Discussion", "content": "In this study we propose a method to enrich OSM road geometry data with road surface type information utilizing Mapillary street level imagery. The deep learning model identified paved roads with a very high F-1 score of about 95% and overall accuracy of 92%. In comparison", "factors": "model uncertainties", "others": "blurriness, illumination conditions, obstruction, distortion), which should be used in future work to improve selection of \"proper\" images.\nVisual inspection revealed that a smaller fraction of mislabeling in the False Positives and False Negatives dataset was attributed to human error (uncertainties in OSM data quality) rather than model performance, however it was not possible to quantify this effect on a larger scale. This uncertainty became prevalent when distinguishing between road types that visually blend together. Another modelling uncertainty was introduced by map-matching between OSM road geometries and Mapillary image locations"}]}