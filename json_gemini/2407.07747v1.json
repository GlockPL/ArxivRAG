{"title": "HGFF: A Deep Reinforcement Learning Framework for Lifetime Maximization in Wireless Sensor Networks", "authors": ["Xiaoxu Han", "Xin Mu", "Jinghui Zhong"], "abstract": "Planning the movement of the sink to maximize the lifetime in wireless sensor networks is an essential problem of great research challenge and practical value. Many existing mobile sink techniques based on mathematical programming or heuristics have demonstrated the feasibility of the task. Nevertheless, the huge computation consumption or the over-reliance on human knowledge can result in relatively low performance. In order to balance the need for high-quality solutions with the goal of minimizing inference time, we propose a new framework combining heterogeneous graph neural network with deep reinforcement learning to automatically construct the movement path of the sink. Modeling the wireless sensor networks as heterogeneous graphs, we utilize the graph neural network to learn representations of sites and sensors by aggregating features of neighbor nodes and extracting hierarchical graph features. Meanwhile, the multi-head attention mechanism is leveraged to allow the sites to attend to information from sensor nodes, which highly improves the expressive capacity of the learning model. Based on the node representations, a greedy policy is learned to append the next best site in the solution incrementally. We design ten types of static and dynamic maps to simulate different wireless sensor networks in the real world, and extensive experiments are conducted to evaluate and analyze our approach. The empirical results show that our approach consistently outperforms the existing methods on all types of maps.", "sections": [{"title": "I. INTRODUCTION", "content": "Over the past few decades, Wireless Sensor Networks (WSNs) have been widely applied in the real world, such as traffic control [1], military target tracking [2], and biomedical health monitoring [3]. A typical WSN consists of a sink and numerous sensor nodes that are used to measure information from the environment (e.g. temperature, pressure, location, and so on). The data collected by sensor nodes are then transmitted to the sink through multi-hop communication, and eventually sent to the users from the sink. As the sensor nodes tend to be disposable and energy-constrained, the lifetime of WSN is limited and often defined as the duration time of the network until one or more sensor nodes run out of energy for the first time. Moreover, the inaccessibility of sensor deployment results in high recharging costs. Therefore, how to maximize the lifetime becomes one of the most important issues in the WSN community.\nLeveraging sink mobility has been shown to be an effective way to maximize the lifetime of WSNs [4], [5]. Specifically, a mobile sink can move to various locations within the sensing region while collecting data from sensors. In this way, the sensors located near the sink change over time, which brings more balanced energy dissipation throughout the network. Thus, the lifetime of WSN with a mobile sink is prolonged. Efficiently scheduling the movement of the mobile sink is vital for the network's lifetime. Yet, determining the optimal traversal path for the sink remains a formidable challenge, known to be an NP-Hard problem [6].\nVarious approaches for optimizing the sink's movement to prolong the WSN's lifetime have been proposed, including operational research-based (OR) methods [7]\u2013[9] and heuristic methods [4], [10]\u2013[14]. Formulating the problem into a mathematical programming model (e.g. the mixed integer linear programming model (MILP)), the OR methods (e.g. branch-and-bound (B&B)) are usually guaranteed to find the optimal solution. Nevertheless, the exponential complexity of OR methods hinders their application to large-scale real-world instances. Heuristic methods can get satisfactory results within bearable time. Whereas well-designed and task-specific prior knowledge from human experts and trial-and-error are required, the optimality still cannot be guaranteed.\nAn alternative research direction for guiding the sink's path to maximize WSN's lifetime is based on Reinforcement Learning (RL). RL methods have been shown to be able to automatically learn good heuristics within brief solving time,"}, {"title": "II. RELATED WORK", "content": "Due to the limited energy of sensors, how to improve energy using efficiency is a critical issue in WSNs, which is directly related to the life span of the entire network. Static sink has been shown to perform badly in achieving energy efficiency in collecting data in wireless sensor networks [27]. The main reason for this phenomenon is the \u201cenergy hole\" problem [28], namely, the sensor nodes around the sink are prematurely depleted of energy due to the need to forward more data, which is likely to form a sensor network energy consumption bottleneck, resulting in a short lifetime. Therefore, the mobile sink has been adopted by various methods to improve the lifetime of wireless sensor networks.\nThe optimization problem for scheduling the movement of the sink to maximize lifetime can be modeled as different mathematical optimization models. Leveraging the MILP model, Basagni et al. [4] attempt to maximize the lifetime of WSNs with constraints including a movement restriction for the sink traveling between two different sites, and the energy cost of the mobile sink in scheduling. Setting an objective to maximize the accumulated sojourn time of the mobile sink in event-driven applications, a convex optimization model to determine the optimal trajectory of a mobile sink without relying on predefined structures is introduced in [9]. In order to make the optimization model closer to reality, more elements are considered in the mathematical problem. The storage capacity of sensors is considered in [7], for the case of"}, {"title": "III. PROBLEM DEFINITION", "content": "This section describes the process of transmitting data from the sensor to the sink in WSNs, using the notations provided in Table I. We then present the mathematical formulation of the problem of maximizing the lifetime of WSNs."}, {"title": "IV. PROPOSED METHOD", "content": "In this section, we illustrate our framework formally, including the design of MDP, the structure of the neural network for evaluating the agent's state-action value, and the training method. Firstly, the overall framework of our method is introduced. Secondly, we formulate the movement process of the sink to maximize WSN's lifetime as a MDP. Then, we represent the WSN as a weighted undirected heterogeneous graph. In addition, the way to learn the representation of nodes in WSN based on the GNN and multi-head attention is given. Finally, we introduce the training algorithm in detail."}, {"title": "A. Overview", "content": "The lifetime maximization with mobile sink problem of different WSNs have the same structure but differ in the geographic area, distribution, and sensor-updating function. Due to the requirement for high-quality human knowledge, it's challenging to design optimal heuristic rules to solve the problem. Different from previous work mainly using heuristics, a deep reinforcement learning-based framework HGFF is proposed to learn the optimal movement strategy for the sink in this paper.\nFirstly, we formalize the WSN as a weighted undirected heterogeneous graph. Due to the different roles and attribute"}, {"title": "B. Markov Decision Process Formulation", "content": "We formalize the moving process of sink in a WSN as a Markov Decision Process (MDP). The purpose of such modeling is to address the problem: determining the route for the mobile sink, together with the sojourn times at which the sink stays on each site, so as to maximize the life-time of the WSN. The MDP can be defined as a five-tuple (S, A, T, R, \u03b3). S represents the environmental information and the possible configurations of the WSN environment. A denotes the available action set of the agent and T defines the probability distribution over possible next states. \u03b3\u2208 [0, 1] is the discounted factor. It is worth mentioning that the Markov property is satisfied in the virtual WSN environment. Given the present state of the WSN environment, the future decision of the sink (i.e. select a site to move) is independent of the past. In other words, the state of the WSN environment includes all the relevant information about its history: P[St+1|St] = P[St+1 S1,..., St].\nBased on the MDP, we simulate the decision process of which site the sink stays at each time step (i.e. \u0393) until the overall WSN dies. The main parts of MDP are defined as follows:\nStates: The state for the agent includes all the attribute information of the sensor nodes and sites, which is composed of the following global information:\n1) Property of node: sensor, site, and if it belongs to the set of sites, whether there is a sink on this site.\n2) Current coordinate position (including x-axis and y-axis) of the sink, sensors, and sites.\n3) Residual energy of the sensor nodes.\n4) Energy consumption per unit time of sensor nodes."}, {"title": "C. Learning over graphs", "content": "1) Graph Representation Formulation: We define the WSN as a weighted heterogeneous graph: G = (V, \u0395, \u03c9,\u03c6, \u03c8), where the set of nodes V is constituted of two kinds of nodes: sensors in set N and sites in set L. The set of edges E represents the connection between two nodes that are able to communicate with each other (i.e. they are within the transmission range dmax). w refers to a function mapping undirected edges to their weight values: E \u2192 W, where W = {We : de \u2208 E} means the set of weights. $ is the node type mapping function: V \u2192 Tu, where T = {$(v) : v \u2208 V} denotes the set of possible node types. & is the edge type mapping function: E \u2192 Te, where Te = {$(e) : \u2200e \u2208 E} denotes the set of possible edge types. In the graph G, there are two types of nodes and one type of edges: T = 2, Te = 1. It is worth noting that G must be a fully connected graph, otherwise, there will be isolated nodes that cannot send data to the outside.\nWe design 5 features for sensor node ni at each time step k: the mark for the type of node, the x-coordinate of the node, the y-coordinate of the node, the ratio of the residual energy to the initial energy in kth time step: u/Ei, and the energy consumption per unit time in kth time step: et \u00b7 p + erk.qk. For the features of site lj, they are the mark for the type of node, the x-coordinate of the node, and the y-coordinate of the node. Note that the elements for both features are normalized, except for the identification mark for different nodes.\nTo include the distance information between different nodes in the representation, we explicitly define the weight Weij of connection between node i and node j be the normalized Euclidean distance of two nodes:\n$$w(e_{ij}) = normlize(d_{ij})$$\n2) Message Passing Neural Networks with learnable Node-type embedding: To leverage type information to improve training, we incorporate node type embedding into the original Message Passing Neural Network (MPNN) [31], which is a general learning framework used widely in many famous graph networks with specific implementations. Based on the input node feature x \u2208 Rd (d=5) and the structure of graph G constructed in sec IV-C1, we aim to learn an dh (we use dh = 64) dimensional representation vector hl for each vertex v \u2208 V, where l denotes the current iteration or network layer. Firstly, the input feature x, is input to a linear projection with parameters W\u00ae and B*: \u00b5 = W*x+B*. Then L rounds of message passing will be leveraged to update the embeddings, according to (8) and (9).\nAlthough the original MPNN can be used to model homogeneous graphs, the omission of node or edge types could make it suboptimal for heterogeneous graphs. To emphasize the heterogeneity between two kinds of nodes, we allocate an embedding t(v) for each type of vertex \u03c6(v),\u2200\u03c5 \u2208 V, where the contents of t(v) are adjusted during the training process. Therefore, the node embedding h consists of two parts: node embedding \u00b5 in original MPNN and learnable node type embedding t(v), where the (v) is the type of node v. The embedding h of node v in iteration l is defined as h = \u00b5 || t(), where the || denotes concatenation operation. Based on the aggregation from the neighbor nodes, the graph neural network updates node representation iteratively following:\n$$m_v^{l+1} = M_l(h_v^l, \\{ h_u^l \\}_{u \\in N(v)}, \\{ W_{uv} \\}_{u \\in N(v)} )$$\n$$h_v^{l+1} = U_l(h_v^l, m_v^{l+1})$$\nWhere Ml denotes the message function and Ul represents the update function. The message funtion aggregates information from neighborhood nodes {hu}u\u2208N(v) with adjacent edges {Wuv}u\u2208N(v), and pass on the information to the next layers. The node representation is updated iteratively through the non-linear transformation in the update function."}, {"title": "D. Attention-based feature fusion", "content": "Aggregating the embeddings from neighbors, the GNN in Section IV-C2 learns the representations of sites and sensor nodes: {h} = {h}\u222a{h}, where v \u2208 V,l \u2208 L, n \u2208 N. To further learn the association between nodes and enhance the model's expressive capacity, we adopt the attention mechanism [32], which requires a query and a collection of key-value pairs to map the output. Formally, we define the queries consist of site nodes' embeddings {h} and keys and values {h} come from the sensor nodes' embeddings. The queries, keys, and values are calculated by the linear transformations of the sites' embeddings and sensors' embeddings respectively:\n$$q_i = W_q * h_i^L, k_j = W_k * h_j^L, v_j = W_v * h_j^L$$\nwhere Vi \u2208 L,\u2200j \u2208 N, parameter Wq is learnable matrice (dq * dh), and Wk, W have the same dimension dk * dh."}, {"title": "E. Training method", "content": "The Double DQN algorithm [30] is employed to learn the optimal policy for planning the traversal path of the sink. Untangling the selection and evaluation in the update of the Q value, the Double DQN method reduces the overestimation error by learning two value functions, one of which is used to decide the greedy policy and the other to decide the value. The learning target Yt of Double DQN algorithm at t time step is shown in (12):\n$$Y_t = R_{t+1} + \\gamma Q(s_{t+1},argmax_a Q(s_{t+1}, a; \\theta_t), \\theta_{\\tau})$$\nWhere \u03b8t refers to the parameters of the Q-network, \u03b8 are the parameters of the target network, and \u03b3 refers to the discount factor. The parameters of Q-network \u03b8 is updated following:\n$$\\theta_{t+1} \\leftarrow \\theta_t + \\alpha(Y_t - Q(S_t, a_t; \\theta_t))\\nabla_{\\theta_t}Q(S_t, a_t; \\theta_t)$$\nwhere a is a scalar step size. The pseudocode of the training method is described in Algorithm 1."}, {"title": "V. EXPERIMENTS", "content": "In this section, we introduce the experimental setup and results of our proposed method. In the experimental setup, the designed WSN environments for evaluating different approaches are introduced. Then, we present the indicators to probe the performance of different algorithms. Moreover, the baseline methods and their hyper-parameters are illustrated in detail. Then, the hyper-parameters during the training of our method and the baseline DRL-based method are given. In the experimental results, we show the results of the conducted extensive experiments on both static and dynamic maps, as well as some analysis. In addition, we further evaluate the effectiveness of the component of our method via ablation studies. What's more, the visualization of the sink mobile path is given, which directly reflects the effectiveness of our method."}, {"title": "A. Experimental Setup", "content": "1) Design of Virtual Environments: Two kinds of virtual environments are designed to simulate WSNs: stationary and dynamic environments. In stationary environments, the deployment of sensor nodes does not change during the lifetime of WSNs, and the energy load balancing of the network only depends on the movement of the mobile sink. Further, to cater to most situations in the real-world, dynamic WSN environments are also designed to test our proposed method, that is, during the operation of the network, the deployment of sensor nodes will change over time. The dynamic environments pose a great challenge to the response time of the algorithm. Besides, the initial location distribution of sensors is randomly generated. Specifically, ten types of WSN environments are designed for both static and dynamic cases respectively. The initial"}, {"title": "VI. CONCLUSION", "content": "In this paper, a novel DRL-based framework called HGFF is proposed to address the NP-hard challenge of construct-ing the optimal route of the mobile sink to maximize the lifetime of WSN. Modeling the problem as an optimization on the heterogeneous graph, we introduce the learnable type embedding in graph learning to emphasize the heterogeneity of nodes. Moreover, the multi-head attention technique is leveraged to further learn the relativity information between the heterogeneous nodes. The extensive experimental results show that our method is capable of learning solutions of good quality in a brief time without human knowledge. Besides, the proposed method also has some reference significance for the problem of deciding the movement of the sink to different cluster heads in hierarchical routing protocol-based WSNs.\nIn the future, we'd like to further study the problem of maximizing the lifetime of WSN in which exists more than one sink. In addition, constructing the optimal data transmission route from sensors to the sink automatically is also an interesting future research direction."}]}