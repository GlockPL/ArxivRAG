{"title": "GreenEye: Development of Real-Time Traffic Signal Recognition System for Visual Impairments", "authors": ["Danu Kim"], "abstract": "Recognizing a traffic signal, determining if the signal is green or red, and figuring out the time left to cross the crosswalk are significant challenges to visually impaired people. Previous research has focused on recognizing only two traffic signals, green and red lights, using machine learning techniques. The proposed method developed a GreenEye system that recognizes the traffic signals' color and tells the time left for pedestrians to cross the crosswalk in real-time. GreenEye's first training showed the highest precision of 74.6%; four classes reported 40% or lower recognition precision in this training session. The data imbalance caused low precision; thus, extra labeling and database formation were performed to stabilize the number of images between different classes. After the stabilization, all 14 classes showed excelling precision rate of 99.5%.", "sections": [{"title": "1. Introduction", "content": "There were about 117,000 crosswalks in Korea (2021, [1]); most non-disabled people don't have challenges recognizing the traffic signal and walking the crosswalk. However, in cases of visually impaired people, recognizing the traffic signal and determining whether the traffic light is green or red to cross the crosswalk safely is a big challenge [1]. Further, knowing the time left to cross the crosswalk is a more significant challenge for visually impaired people. Across the traffic lights in the Korean peninsula, only 34% have beacons for visually impaired people. Seoul showed a 66.1% beacon installation rate, whereas Ulsan showed a 7.8% immensely lower installation rate. Moreover, the number of broken or not-working traffic lights has been 4,451 for four years until 2021, and it even took 184 days maximum to fix the traffic light [1, 2, 3].\nAs one of the representative automated traffic light recognition systems, Handong University's previous research [4] developed an algorithm that used machine learning techniques to recognize green and red traffic lights. However, the algorithm didn't have a feature for telling the time left to cross the crosswalk, which leaves a limitation for visually impaired people when used in real life. Further, other research gave relatively lower precision and training results in recognition. In contrast, the presented study used a further-developed YOLOv5 to derive increased precision and faster learning speed.\nTherefore, the presented study proposed a real-time traffic light number auto-recognition system, GreenEye, to help visually impaired people safely and conveniently cross the crosswalk. The proposed method gives the time left to cross the crosswalk in an actual situation, in addition to the green and red light determination, which helps visually impaired people cross the road safer. A large amount of traffic light data was taken to develop the system on a real road, and those data were labeled later. Then, deep learning-based object detection was applied to recognize traffic lights from input traffic light images and videos in real-time, recognizing the colored lights, including the time left for the green light."}, {"title": "2. Proposed GreenEye System", "content": "Fig. 1 is the diagram of the GreenEye System. First, a large amount of the traffic light data(Green, Red, and traffic signal number) were collected with the smartphone. Then, each traffic light image was labeled (custom data annotation) to train the collected data. Using the custom data set with all the labeling processes completed as input, GreenEye was trained with YOLOv5 to recognize the color of the traffic light and the traffic signal number. Lastly, GreenEye was tested to recognize Green, Red, and traffic signal numbers on real-time videos about the traffic signals."}, {"title": "2.1 GreenEye System Component Processes", "content": "2.1.1 Custom Data Set Formation and Labeling\nConventional data related to traffic light recognition was labeled only on the whole traffic light or"}, {"title": "3. Experimental Results", "content": "3.1 Experimental Setting\nThe custom data set, which consists of 884 images used in the first experiment, was collected at a nearby road site. This input data is used for training and validating the YOLOv5 traffic light recognition model. The proposed work analyzed various experimental results by setting the training and validation data ratio differently. Further, the dataset consists of 14 classes, including Green, Red, and signal numbers (1-12).\nThe final-trained YOLOv5 model had 214 layers and about 7 million parameters. For training efficiency, we set the input image size to 640, epoch to 30, and batch size to 16. The Colab GPU used in the experiment was the V100 Nvidia Premium GPU. Considering that GreenEye will be operated on a smartphone later, we set it as YOLOv5s, the small model, and it was trained to override the 80 original classes with 14 new classes. For deep learning model training, the training and validation ratio was divided into 7:3 and 9:1."}, {"title": "3.2 Test Results by Validation Ratio", "content": "Table 1 (left) shows the recognition precision of the GreenEye where the ratio of training to validation data is 7:3 and 9:1. The total duration for 30 epochs for 7:3 and 9:2 training was 2.2 and 2.4 hours each.\nIn 7:3 training and validation, the mAP50, the average precision for whole class recognition was 0.64. This precision shows that the model trained with 70%"}, {"title": "3.3 Test Results after Resolving Data Imbalance", "content": "As mentioned earlier, the highest precision rate was 75% from 9:1 cross-validation; even though the training size was increased, the classes with low precision rates from 7:3 validation still showed low precision, which led to the in-depth examination of the data distribution, focusing on low-precision classes. Classes with high precision(e.g., Green_4) had about 80 input data. However, classes with low precision had a small number of data: about 50 input images. Green_9 class had 34 data, and Green_12 had 24 data.\nThese data imbalances could bring a decreased performance to deep learning training. Classes with a smaller number of data might have a smaller portion of training data than classes with more data, causing the labeled class not to be trained precisely. Therefore, to balance the overall data distribution between each class, extra photo taking and labeling for class data with low precision, including Green_7, proceeded. The total number of data increased from 884 to 1,113."}, {"title": "3.4 Real-time GreenEye Tests on Traffic Light Videos", "content": "The GreenEye system should be used by visually impaired people on real-life roads, indicating that it should work without error on videos with real-time inputs. Fig. 3 shows the real-time recognition results of traffic light video on real roads containing Green, Red, and traffic signal number lights. The results show that it successfully recognized Green Light and traffic signal numbers. (video demo. https://youtu.be/BmQJiwo70n8)"}, {"title": "3.5 Performance Comparison with Previous Research", "content": "As shown in Table 2, the GreenEye system achieved a Green and Red light recognition precision of 99.5%, which is a better result than those from the previous research [4]. Table 3 shows that by tackling the data imbalance between the traffic light classes, GreenEye improved from prediction measured during the data imbalance of 75% precision to 99% precision for all 14 traffic light classes. Further, the training time was reduced from 2.39 hours to 1.13 hours."}, {"title": "4. Conclusion", "content": "The GreenEye is a real-time traffic signal recognition model that visually impaired people could use. The Google Colab and YOLOv5 model was customized to achieve this goal, recognizing all 14 traffic signal classes successfully. Further, it was observed that the system successfully works for the videos, too, showing the possibility of recognizing the traffic light well in portable input devices such as smartphone cameras. The future application of this research is to develop a smartphone app with a GreenEye system based on a TTS engine so that visually impaired people can use the traffic light recognition system more conveniently."}]}