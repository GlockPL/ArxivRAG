{"title": "The Voice: Lessons on Trustworthy Conversational Agents from \u2018Dune'", "authors": ["Philip Feldman"], "abstract": "The potential for untrustworthy conversational agents presents a significant threat for covert social manipulation. Taking inspiration from Frank Herbert's Dune [12], where the Bene Gesserit Sisterhood uses the Voice for influence, manipulation, and control of people, we explore how generative AI provides a way to implement individual-ized influence at industrial scales. Already, these models can manip-ulate communication across text, image, speech, and most recently video. They are rapidly becoming affordable enough for any orga-nization of even moderate means to train and deploy. If employed by malicious actors, they risk becoming powerful tools for shaping public opinion, sowing discord, and undermining organizations from companies to governments. As researchers and developers, it is crucial to recognize the potential for such weaponization and to explore strategies for prevention, detection, and defense against these emerging forms of sociotechnical manipulation.", "sections": [{"title": "1 INTRODUCTION", "content": "Frank Herbert's Dune is a landmark in science fiction, leading to six subsequent novels and countless spinoffs. It grew from the au-thor's profound engagement with both ecological concerns and the complexities of human history. The novel can trace its origins to Herbert's 1957 assignment to write a newspaper feature on the ecological control of sand dunes in Oregon. This led to him contem-plating the ecologies of planet-sized deserts and merging that with his desire to write \"a long novel about the messianic convulsions which periodically inflict themselves on human societies.\" Impor-tantly, the first of these convulsions is the Butlerian Jihad, a violent crusade against thinking machines and technological excesses [13], foreshadowing present-day concerns about the risks of unchecked Al development by unaccountable elites.\nIn Dune, Frank Herbert built an intricate universe with societies that encapsulate various aspects of human history and culture. There is Baron Vladimir Harkonnen's politics of dominance and submission, contrasted with the rules-based order exemplified by House Atreides, led by Duke Leto \"the Just\". Then there is the world of Arrakis itself, with its harsh desert environment. Arrakis' complex ecology involves ship-sized Sandworms that produce The Spice, a psychoactive anti-aging drug so valuable that the fate of the Empire is tied to it. The climate also molds Arrakis' human"}, {"title": "2 THE VOICE IN THE MACHINE", "content": "The Voice allows the Bene Gesserit to influence the emotions, thoughts, and actions of others through subtle changes in pitch, rhythm, and intonation. In the fictional Dune universe, the Bene Gesserit Voice is a powerful tool for persuasion and deception. However, reality is beginning to approach these fictional capabilities.\nResearch has shown that certain vocal cues are associated with specific personality traits and qualities. For example, lower-pitched voices are often perceived as more authoritative and trustwor-thy [17], while higher-pitched voices may convey vulnerability or attractiveness as a mate [22]. Additionally, faster speech rates can indicate confidence and assertiveness, while slower rates can suggest thoughtfulness and precision [5].\nAdvances in Al and speech synthesis technologies have made it possible to manipulate vocal cues with great precision allowing state-of-the art speech systems to convey even subtle emotions and attitudes [5, 21]. These techniques include:\n\u2022 Pitch shifting: Altering the frequencies and harmonics of a voice to, for example, make it sound young and vigorous or old and feeble.\n\u2022 Tempo adjustment: Introducing are eliminating delays at word and sentence level, which can change the perception of intelligence.\n\u2022 Volume modulation: Adjusting the loudness of a voice, par-ticularly with respect to other voices or at certain times to change emphasis.\n\u2022 Style transfer: changing the speech patterns of a speaker to match the vocal patterns of someone else.\n\u2022 Intonation, phonation, and vowel placement: These features grant speech a distinctive identity, including ethic groups and accents.\nBy manipulating such vocal cues, it is possible to create voices that are perceived as more compelling and credible. For example, a voice could be subtly modified to have a lower pitch, slower tempo, and confident intonation. This would convey credibility, expertise, and charisma. Such a voice could more effectively sway public opinion in favor of a particular candidate or policy.\nConversely, vocal manipulation can also be used to make voices appear less trustworthy. For example, speech manipulated to have a higher pitch, faster tempo, and elements of hesitation or nervous-ness could be used to convey a sense of incompetence, unreliability, or even deception. Such a voice could be used to undermine the credibility of the speaker.\nThe ability of voice-based interfaces to communicate different levels of credibility with the same message was accidentally uncov-ered in a study investigating the effectiveness of using intonations"}, {"title": "3 WHITE HAT AI", "content": "\"Ah, yes,\" the Baron said. \"When you face the Emperor, you must be able to say truthfully that you did not do the deed. The witch at the Emperor's elbow will hear your words and know their truth or falsehood.\"\nFrank Herbert, Dune\nScience fiction has a rich history of sparking ideas about inter-action technologies [2, 4, 26]. As researchers, we rarely explore the utopian and dystopian elements that these technologies often embody. I chose Dune, and the Bene Gesserit in particular, for this provocation because of this ambiguity. The Bene Gesserit exert their powers to both influence and detect influence. In the Dune universe, the Padishah Emperor relies on a Bene Gesserit Truthsayer, the Reverend Mother Gaius Mohiam, to detect lies and half-truths in an environment saturated with political treachery. She does this by reading subtle vocal cues, body language, and micro-expressions, combined with a multi-generational memory of experience.\nLLMs trained on vast datasets, excel in mimicking human com-munication, so much so that they can often fool us into believing they are human. For example, consider that each successive GPT model scores closer to human on versions of the Turing Test [14] or when the GPT-4 passed the Uniform Bar Exam way back in 2023 [16].\nThis capability could be reoriented from generating manipula-tion to unveiling it. Imagine a \"White Hat AI\" that, leveraging the same training, is used to discern auditory, text, and visual patterns that are manipulative. This AI could serve as a watchdog, introduc-ing a moment of friction in our interactions with digital content, allowing us to engage our more analytical \"system 2\" thinking, before reacting impulsively with our \"system 1\" reflexes [15]. Some preliminary work in this area is being done, such as the detec-tion of conspiracy theories based on affect, rather than relying on fact-checking [18], Note that this is not detection of AI-generated content. The goal here is to detect manipulation (ranging from spearphishing to conspiracy theories) regardless of the means.\nThere is a synergistic body of research on \"dark patterns\" manipulative tricks used to influence user behavior [1, 3, 5, 7, 20]. We may be able to incorporate this knowledge to develop our own Truthsayers, or \"White Hat AI\", to counter manipulative intent. Such systems could be deployed at scale, unlike the elite Truthsayers of Dune, potentially democratizing access to such sophisticated defenses."}, {"title": "4 BLACK HAT AI", "content": "The Bene Gesserit sisterhood provides a compelling model for un-derstanding the issues inherent in the pursuit of AI applications. They chose to place themselves above the human beings they pre-tended to serve. Their overarching ambition to create the Kwisatz Haderach a figure of supreme influence and awareness led to unforeseen and disastrous consequences in the form of a universe-wide jihad. Dune is above all a cautionary tale.\nMuch like how the Bene Gesserit's meticulously crafted breeding program ultimately unleashed a galactic jihad, real-world interven-tions aimed at social control, like Prohibition in the United States, often yield unforeseen and devastating consequences. The rise of affordable generative AI presents a similar dilemma. These tools, capable of producing text, audio, and imagery, hold the potential to be weaponized by any organization with even moderate resources. Already, LLMs are often found to be more persuasive that human beings [24]. Generative imagery and deepfakes now represent a significant concern. They range from the disturbingly convincing videos of \"Kari Lake,\u201d produced as a demonstration of this capability by Arizona Agenda,\u00b9 to the amateurish, yet successful deepfakes used to harass Baltimore County Principal Eric Eiswart, which were created using commonly available tools.\u00b2\nImportantly, manipulation need not involve wholly fabricated content. For example, a slowed-down audio and video of House Speaker Nancy Pelosi, known as a \"shallow fake,\" made her appear and sound drunk. This highlights just how easy effective manipula-tion can be.\u00b3\nTo understand this threat, we may need to create \"Black Hat AI,\" tools that are trained to produce the same manipulative tactics that could be employed by bad actors. This reflects the dynamic that has developed in cybersecurity, where ethical \"black hats\" use their knowledge to expose vulnerabilities before they can be exploited. Using controlled adversarial models to train and evaluate White Hat AI, we equip ourselves to detect and mitigate the dangers posed by weaponized AI before it wreaks havoc in the real world.\nHowever, it should be understood that the mere existence of such models carries intrinsic risks. The management of \"Black Hat\" models would demand safeguards, akin to biosafety or nuclear weapon protocols."}, {"title": "5 CONCLUSIONS", "content": "\"I'm not that interested in like the Killer Robots walking down the street direction of things going wrong. I'm much more interested in the like very subtle societal misalignments where we just have these systems out in society and through no particular ill intention um... things just go horribly wrong.\"\nSam Altman4\nAs is the case with many \"AI ethics\" papers, Altman centers his assumptions on unintended consequences arising from the deploy-ment of models at scale. In this provocation, I've tried to emphasize a more immediate and more insidious concern: Al intentionally harnessed by those seeking to exploit its power for their gain.\nThis threat isn't merely theoretical. Chatbots are already pollut-ing social media streams (Figure 3). There are bad actors with the resources to craft effective Al models tailored for manipulation and disinformation. Such tools can target individuals with precision in widespread campaigns. We must urgently address these prob-able near-term threats - not Al running rampant, but AI tightly controlled with malevolent intent.\nThough this kind of misuse has been discussed sporadically, such as Hendrycks et. al's An overview of catastrophic Al risks [11], it often remains overshadowed by the more existential concerns of Al sentience. We need to dedicate more attention to the ways AI can currently achieve tactical and strategic goals. I believe there is insufficient attention devoted to the discussion of what could be done with models constructed, trained, and deployed with today's technology to implement malevolent tactical and strategic goals [6]. We cannot afford a purely reactive approach. By anticipating the likely use of AI by malicious actors, we have a chance to de-velop countermeasures and safeguards. This could mean developing \"White Hat AI\" to function as our own Bene Gesserit Truthsayers. It requires a realistic understanding of \"Black Hat AI\" and the ma-nipulative capabilities it could harbor. Just as in cybersecurity, a deep understanding of threat vectors will be essential in shaping effective defenses.\nLastly, I would urge a rethinking of the goals of the ethics sec-tions within AI/ML papers. These sections often focus on a vision for how the research should be used. However, researchers now also have the responsibility to consider how their work could be misused, or even intentionally weaponized by those with \"ill intent.\" New techniques and approaches demand a critical examination of potential vulnerabilities and manipulation tactics they might enable. Concerted effort should be dedicated to outlining potential defenses or disruptive countermeasures against such weaponization. After all, the original researchers are as close to an expert as can be found for these questions, and they have a Voice."}]}