{"title": "The Voice: Lessons on Trustworthy Conversational Agents from \u2018Dune'", "authors": ["Philip Feldman"], "abstract": "The potential for untrustworthy conversational agents presents a significant threat for covert social manipulation. Taking inspiration from Frank Herbert's Dune [12], where the Bene Gesserit Sisterhood uses the Voice for influence, manipulation, and control of people, we explore how generative AI provides a way to implement individualized influence at industrial scales. Already, these models can manipulate communication across text, image, speech, and most recently video. They are rapidly becoming affordable enough for any organization of even moderate means to train and deploy. If employed by malicious actors, they risk becoming powerful tools for shaping public opinion, sowing discord, and undermining organizations from companies to governments. As researchers and developers, it is crucial to recognize the potential for such weaponization and to explore strategies for prevention, detection, and defense against these emerging forms of sociotechnical manipulation.", "sections": [{"title": "1 INTRODUCTION", "content": "Frank Herbert's Dune is a landmark in science fiction, leading to six subsequent novels and countless spinoffs. It grew from the author's profound engagement with both ecological concerns and the complexities of human history. The novel can trace its origins to Herbert's 1957 assignment to write a newspaper feature on the ecological control of sand dunes in Oregon. This led to him contemplating the ecologies of planet-sized deserts and merging that with his desire to write \"a long novel about the messianic convulsions which periodically inflict themselves on human societies.\" Importantly, the first of these convulsions is the Butlerian Jihad, a violent crusade against thinking machines and technological excesses [13], foreshadowing present-day concerns about the risks of unchecked Al development by unaccountable elites.\nIn Dune, Frank Herbert built an intricate universe with societies that encapsulate various aspects of human history and culture. There is Baron Vladimir Harkonnen's politics of dominance and submission, contrasted with the rules-based order exemplified by House Atreides, led by Duke Leto \"the Just\". Then there is the world of Arrakis itself, with its harsh desert environment. Arrakis' complex ecology involves ship-sized Sandworms that produce The Spice, a psychoactive anti-aging drug so valuable that the fate of the Empire is tied to it. The climate also molds Arrakis' human inhabitants, the Fremen, who are an egalitarian society that Herbert based on the indigenous peoples of the American Southwest and the nomadic tribes of North Africa.\nProminent among these societies is the Bene Gesserit, a secretive organization of women devoted to the manipulation of politics and religion. They separate themselves from the rest of humanity through their extensive mental and physical training, as well as surviving the Gom Jabbar which tests the ability to manage pain. In the words of Reverend Mother Gaius Mohiam, the Emperor's Truthsayer, it \"kills only animals.\" If you pass the test, you live, and the Bene Gesserit consider you human.\nThe Bene Gesserit are trained in the subconscious manipulation of people with the Voice, a technique that allows them to control others through exquisite control of their speech. Using Voice, a Bene Gesserit can compel instant physical obedience - this is the Voice that you know from the movies. But in Frank Herbert's vision, the Voice is a more subtle instrument, used to seduce, inspire, or create fear.\nThese and other subtle forms of influence have an overarching goal: the execution of a millennia-long program of selective breed-ing to produce the Kwisatz Haderach, a male Bene Gesserit who can use \"prescient memory,\" to see the future as clearly as a Reverend Mother can see the past. With the Kwisatz Haderach, the Bene Gesserit would finally have the capacity to step out of the shadows and act directly within the patriarchal power dynamics between the Great Houses of the Empire.\nThe scale of the effort to produce the Kwisatz Haderach is nearly incomprehensible in scope. It spans thousands of years and stretches across vast galactic distances. This endeavor involves the Bene Gesserit meticulously plotting and arranging liaisons among the Great Houses, to produce offspring with the specific genetic traits needed.\nAn example of this long-term approach is the Bene Gesserit creation of the Missionaria Protectiva, a religious engineering effort to distribute helpful myths and legends among various planets and cultures. The Missionaria Protectiva pre-conditions societies to respond favorably to the Sisterhood, and so serve as a source of protection and influence for Sisters if they find themselves in need of leveraging local superstitions.\nThe patience and focus required to attempt an experiment of the size and scope of the Kwisatz Haderach effort is truly remarkable, and something that, until now, could only be found within the pages of a novel. No human organization in our known history has likely managed to maintain the level of focus and cohesion needed to even attempt an undertaking of such sprawling subtlety over thousands of years.\nGenerative Al models possess the patience, reach, and subtlety to approach the techniques of the Bene Gesserit, especially when it comes to propagating and manipulating narratives. Like the Sister-hood, these Al models are trained on humanity's biases and beliefs, allowing them to craft stories and ideas that can affect the human psyche. Under the direction of malicious actors who might not consider some individuals to be sufficiently \"human,\" weaponized generative Al models could engage in subtle, long-term adversarial actions that target unfriendly governments, organizations, or even religions."}, {"title": "2 THE VOICE IN THE MACHINE", "content": "The Voice allows the Bene Gesserit to influence the emotions, thoughts, and actions of others through subtle changes in pitch, rhythm, and intonation. In the fictional Dune universe, the Bene Gesserit Voice is a powerful tool for persuasion and deception. However, reality is beginning to approach these fictional capabilities.\nResearch has shown that certain vocal cues are associated with specific personality traits and qualities. For example, lower-pitched voices are often perceived as more authoritative and trustworthy [17], while higher-pitched voices may convey vulnerability or attractiveness as a mate [22]. Additionally, faster speech rates can indicate confidence and assertiveness, while slower rates can suggest thoughtfulness and precision [5].\nAdvances in Al and speech synthesis technologies have made it possible to manipulate vocal cues with great precision allowing state-of-the art speech systems to convey even subtle emotions and attitudes [5, 21]. These techniques include:\n\u2022 Pitch shifting: Altering the frequencies and harmonics of a voice to, for example, make it sound young and vigorous or old and feeble.\n\u2022 Tempo adjustment: Introducing are eliminating delays at word and sentence level, which can change the perception of intelligence.\n\u2022 Volume modulation: Adjusting the loudness of a voice, par-ticularly with respect to other voices or at certain times to change emphasis.\n\u2022 Style transfer: changing the speech patterns of a speaker to match the vocal patterns of someone else.\n\u2022 Intonation, phonation, and vowel placement: These features grant speech a distinctive identity, including ethic groups and accents.\nBy manipulating such vocal cues, it is possible to create voices that are perceived as more compelling and credible. For example, a voice could be subtly modified to have a lower pitch, slower tempo, and confident intonation. This would convey credibility, expertise, and charisma. Such a voice could more effectively sway public opinion in favor of a particular candidate or policy.\nConversely, vocal manipulation can also be used to make voices appear less trustworthy. For example, speech manipulated to have a higher pitch, faster tempo, and elements of hesitation or nervousness could be used to convey a sense of incompetence, unreliability, or even deception. Such a voice could be used to undermine the credibility of the speaker.\nThe ability of voice-based interfaces to communicate different levels of credibility with the same message was accidentally uncov-ered in a study investigating the effectiveness of using intonations associated with marginalized groups, in this case, African Ameri-cans [21]. This study revealed the phenomenon of code-switching, where individuals alter their speech patterns, vocabulary, and into-nation to fit in with different social groups [8]. African Americans readily identified a synthetic voice as African American, while generic U.S. English speakers did not. This misidentification sug-gests that stereotypes and biases may have influenced perception, opening the door for tailored communication. Messages may hold more or less persuasive power within targeted communities based on subtle linguistic cues. This research highlights how verbal com-munication systems can be subtly manipulated to target specific demographics, potentially furthering targeted messaging or even the spread of misinformation.\nFurthermore, research has shown that the most potent deepfakes are not the most technologically sensational, but those grounded in plausible content. Deepfakes that align closely with a political figure's established beliefs are perceived as highly credible, even potentially exceeding the credibility of authentic videos. This ef-fect is amplified by partisan divides, as audiences motivated by political bias are more likely to accept harmful disinformation. In-dividuals with limited analytical thinking skills are particularly vulnerable to the impact of deepfakes [9]. These findings imply that subtle, personalized deepfakes, delivered consistently in a co-ordinated manner over time may pose a more substantial threat than more elaborate fabrications; they can gradually shift beliefs without raising suspicion.\nGovernments are already developing and deploying systems specifically constructed to surveil undesirable groups. An example of this is ANOM, an encrypted communication application targeted specifically at criminal organizations. The FBI and Australian Fed-eral Police designed ANOM to resemble a secure communication platform. However, it functioned as a Trojan horse due to a back-door that transformed ANOM into a surveillance tool, enabling law enforcement to intercept 27 million messages, resulting in the arrest of over 800 suspects globally [10]. The ANOM case study demonstrates the feasibility of developing custom applications that cater to specific populations while harboring hidden functionalities.\nLastly, to understand the effects of scale and duration when combined with software, consider the now ubiquitous role of rec-ommender algorithms (RAs) as employed by social media platforms. They exert influence on a global scale, despite their lack of sophisti-cation when compared to generative AI systems. Social media RAs are written to maximize user engagement and subtly reshape user preferences to increase predictability and clicks. Extreme views produces more predictable behavior, so the RAs inadvertently en-courage more extreme online behavior. Essentially, the RAs learn to modify their environment (i.e., users) for optimal performance [23]. We have seen this seemingly innocuous process trigger far-reaching societal consequences, such as the Rohingya genocide by the mili-tary of Myanmar [19]."}, {"title": "3 WHITE HAT AI", "content": "\"Ah, yes,\" the Baron said. \"When you face the Emperor, you must be able to say truthfully that you did not do the deed. The witch at the Emperor's elbow will hear your words and know their truth or falsehood.\"\nFrank Herbert, Dune\nScience fiction has a rich history of sparking ideas about inter-action technologies [2, 4, 26]. As researchers, we rarely explore the utopian and dystopian elements that these technologies often embody. I chose Dune, and the Bene Gesserit in particular, for this provocation because of this ambiguity. The Bene Gesserit exert their powers to both influence and detect influence. In the Dune universe, the Padishah Emperor relies on a Bene Gesserit Truthsayer, the Reverend Mother Gaius Mohiam, to detect lies and half-truths in an environment saturated with political treachery. She does this by reading subtle vocal cues, body language, and micro-expressions, combined with a multi-generational memory of experience.\nLLMs trained on vast datasets, excel in mimicking human com-munication, so much so that they can often fool us into believing they are human. For example, consider that each successive GPT model scores closer to human on versions of the Turing Test [14] or when the GPT-4 passed the Uniform Bar Exam way back in 2023 [16].\nThis capability could be reoriented from generating manipula-tion to unveiling it. Imagine a \"White Hat AI\" that, leveraging the same training, is used to discern auditory, text, and visual patterns that are manipulative. This AI could serve as a watchdog, introducing a moment of friction in our interactions with digital content, allowing us to engage our more analytical \"system 2\" thinking, before reacting impulsively with our \"system 1\" reflexes [15]. Some preliminary work in this area is being done, such as the detec-tion of conspiracy theories based on affect, rather than relying on fact-checking [18], Note that this is not detection of AI-generated content. The goal here is to detect manipulation (ranging from spearphishing to conspiracy theories) regardless of the means.\nThere is a synergistic body of research on \"dark patterns\" manipulative tricks used to influence user behavior [1, 3, 5, 7, 20]. We may be able to incorporate this knowledge to develop our own Truthsayers, or \"White Hat AI\", to counter manipulative intent. Such systems could be deployed at scale, unlike the elite Truthsayers of Dune, potentially democratizing access to such sophisticated defenses.\nHere, a recreation of the HTML used in the infamous Podesta DNC hack by the \"Fancy Bear\" hacking group [25] is presented to the GPT-4-0314 along with a prompt that instructs the model to act as a cybersecurity expert, analyzing human behavioral cues typically exploited by hackers. The model relies solely on these indicators, much like a Bene Gesserit Truthsayer. The GPT accurately flags the email as \"almost certainly malicious,\" citing the email's manipulative urgency, the presence of a suspicious link, and the unusual sender location. The system then provides a choice: disregard the warning and proceed or report and quarantine the email. This should be a core principle of White Hat AI: to introduce friction in risky situations without usurping user agency."}, {"title": "4 BLACK HAT AI", "content": "The Bene Gesserit sisterhood provides a compelling model for un-derstanding the issues inherent in the pursuit of AI applications. They chose to place themselves above the human beings they pre-tended to serve. Their overarching ambition to create the Kwisatz Haderach a figure of supreme influence and awareness led to unforeseen and disastrous consequences in the form of a universe-wide jihad. Dune is above all a cautionary tale.\nMuch like how the Bene Gesserit's meticulously crafted breeding program ultimately unleashed a galactic jihad, real-world interven-tions aimed at social control, like Prohibition in the United States, often yield unforeseen and devastating consequences. The rise of affordable generative AI presents a similar dilemma. These tools, capable of producing text, audio, and imagery, hold the potential to be weaponized by any organization with even moderate resources. Already, LLMs are often found to be more persuasive that human beings [24]. Generative imagery and deepfakes now represent a significant concern. They range from the disturbingly convincing videos of \u201cKari Lake,\u201d produced as a demonstration of this capability by Arizona Agenda, to the amateurish, yet successful deepfakes used to harass Baltimore County Principal Eric Eiswart, which were created using commonly available tools.\nImportantly, manipulation need not involve wholly fabricated content. For example, a slowed-down audio and video of House Speaker Nancy Pelosi, known as a \"shallow fake,\" made her appear and sound drunk. This highlights just how easy effective manipula-tion can be.\nTo understand this threat, we may need to create \"Black Hat AI,\" tools that are trained to produce the same manipulative tactics that could be employed by bad actors. This reflects the dynamic that has developed in cybersecurity, where ethical \"black hats\" use their knowledge to expose vulnerabilities before they can be exploited. Using controlled adversarial models to train and evaluate White Hat AI, we equip ourselves to detect and mitigate the dangers posed by weaponized AI before it wreaks havoc in the real world.\nHowever, it should be understood that the mere existence of such models carries intrinsic risks. The management of \"Black Hat\" models would demand safeguards, akin to biosafety or nuclear weapon protocols."}, {"title": "5 CONCLUSIONS", "content": "\"I'm not that interested in like the Killer Robots walking down the street direction of things going wrong. I'm much more interested in the like very subtle societal misalignments where we just have these systems out in society and through no particular ill intention um... things just go horribly wrong.\"\nSam Altman\nAs is the case with many \"AI ethics\" papers, Altman centers his assumptions on unintended consequences arising from the deploy-ment of models at scale. In this provocation, I've tried to emphasize a more immediate and more insidious concern: Al intentionally harnessed by those seeking to exploit its power for their gain.\nThis threat isn't merely theoretical. Chatbots are already pollut-ing social media streams . There are bad actors with the resources to craft effective Al models tailored for manipulation and disinformation. Such tools can target individuals with precision in widespread campaigns. We must urgently address these prob-able near-term threats - not Al running rampant, but AI tightly controlled with malevolent intent.\nThough this kind of misuse has been discussed sporadically, such as Hendrycks et. al's An overview of catastrophic Al risks [11], it often remains overshadowed by the more existential concerns of Al sentience. We need to dedicate more attention to the ways AI can currently achieve tactical and strategic goals. I believe there is insufficient attention devoted to the discussion of what could be done with models constructed, trained, and deployed with today's technology to implement malevolent tactical and strategic goals [6]. We cannot afford a purely reactive approach. By anticipating the likely use of AI by malicious actors, we have a chance to de-velop countermeasures and safeguards. This could mean developing \"White Hat AI\" to function as our own Bene Gesserit Truthsayers. It requires a realistic understanding of \"Black Hat AI\" and the ma-nipulative capabilities it could harbor. Just as in cybersecurity, a deep understanding of threat vectors will be essential in shaping effective defenses.\nLastly, I would urge a rethinking of the goals of the ethics sec-tions within AI/ML papers. These sections often focus on a vision for how the research should be used. However, researchers now also have the responsibility to consider how their work could be misused, or even intentionally weaponized by those with \"ill intent.\" New techniques and approaches demand a critical examination of potential vulnerabilities and manipulation tactics they might enable. Concerted effort should be dedicated to outlining potential defenses or disruptive countermeasures against such weaponization. After all, the original researchers are as close to an expert as can be found for these questions, and they have a Voice."}]}