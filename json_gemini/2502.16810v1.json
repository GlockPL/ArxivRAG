{"title": "Grounded Persuasive Language Generation for Automated Marketing", "authors": ["Jibang Wu", "Chenghao Yang", "Simon Mahns", "Chaoqi Wang", "Hao Zhu", "Fei Fang", "Haifeng Xu"], "abstract": "This paper develops an agentic framework that employs large language models (LLMs) to automate the generation of persuasive and grounded marketing content, using real estate listing descriptions as our focal application domain. Our method is designed to align the generated content with user preferences while highlighting useful factual attributes. This agent consists of three key modules: (1) Grounding Module, mimicking expert human behavior to predict marketable features; (2) Personalization Module, aligning content with user preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion of localized features. We conduct systematic human-subject experiments in the domain of real estate marketing, with a focus group of potential house buyers. The results demonstrate that marketing descriptions generated by our approach are preferred over those written by human experts by a clear margin. Our findings suggest a promising LLM-based agentic framework to automate large-scale targeted marketing while ensuring responsible generation using only facts.", "sections": [{"title": "1 Introduction", "content": "While large language models (LLMs) have made significant strides across various tasks, their ability to persuade remains an underexplored frontier (see a discussion of related work in Section 6). This however is a particularly important capability since persuasion-related economic activities a common thread in almost all voluntary transactions from advertising and lobbying to litigation and negotiation - underpin roughly 30% of the US GDP (Antioch, 2013; McCloskey and Klamer, 1995), hence gives rise to tremendous opportunity for applying LLMs across a wide range of sectors. Meanwhile, this same potential introduces serious trustworthiness concerns. If LLMs can generate persuasive content at scale, their influence on human opinions raises risks of misinformation, manipulation and misuse, especially in sensitive domains such as political campaigns (Voelkel et al., 2023; Goldstein et al., 2024).\nIn addition to these profound economic and societal applications, the relationship between the nature of intelligence and persuasion has been a fundamental research question since the time of early Greek philosophy. Aristotle viewed persuasion as both an art and an expression of intelligence, rooted in the ability to reason and communicate effectively. Yet, the Greeks also cautioned against the sophistry that overly relies on rhetorical and emotional techniques divorced from the truth. This tension becomes especially relevant today with the rise of generative AI. Notable figures, such as\nSam Altman, have predicted that AI systems could achieve superhuman persuasion without superhuman general intelligence (Altman, 2023). This dichotomy raises several crucial questions for LLM research: How can we reliably and consistently measure fact-based persuasiveness? Does greater intelligence inherently lead to stronger persuasive capabilities? And if not, what specific abilities must LLMs develop to truly master persuasion? Surprisingly little is known about these questions, and this is what we embark on in this paper.\nIn this paper, we study language generation for grounded persuasion a particular form of persuasion, inspired by Aristotle's philosophy, that is grounded in fact, tailored to the audience, and adapted to contextual factors. Grounded persuasion is crucial for applications in marketing and advertising, and its effectiveness can be linked directly to measurable behavioral changes (e.g., in terms of engagement and conversions) while constrained by factual accuracy. We choose real estate marketing as our testbed for grounded persuasion and construct a realistic evaluation environment to include the process of preference elicitation and measure the persuasiveness of preference-based generation. To enable grounded persuasion in this context, we design an LLM-based agent with three key modules: a Grounding Module, which mimics human expertise in signaling critical and credible selling points; a Personalization Module, which tailors content to user preferences; and a Marketing Module, which ensures factual accuracy and integrates localized features. We use this model-based approach to back up LLMs' generation and are able to achieve superhuman persuasion in real estate marketing. Our findings lay the groundwork for leveraging LLMs in large-scale, targeted marketing and beyond, offering a scalable solution to complex persuasion tasks in real-world applications.\nOur Contribution Our primary research objective is to demonstrate a path towards effective design of persuasive language agents with a backbone of more principled theory. Towards this end, we choose to focus on an application of automated marketing, where we employ the economic theory of strategic communication games to guide the agentic process ranging from processing products' (factual) raw attributes, to selecting features to highlight, and ultimately to generate human-like marketing texts. We start from developing a micro-economic framework for automated marketing, and then operationalize this framework by leveraging the capabilities of LLMs. In addition, we set up a realistic evaluation process of the persuasiveness capability. This includes building a large real estate dataset from Zillow, designing a dedicated survey website to mimic the house search process and test with a focused group of potential home buyers. Our experiments suggest marketing descriptions generated by our methods have a clear winning edge of 70% over those written by expert human realtors."}, {"title": "2 A Benchmark for Grounded Persuasion", "content": "Motivations and Challenges The first task of our study is to build a consistent and effective evaluation benchmark. However, this effort faces several key challenges. A fundamental challenge is the inherent subjectivity of persuasion, which depends heavily on human feedback. Unlike many other LLM capabilities, such as reasoning and planning, which have objective criteria for evaluation, persuasiveness lacks standardized metrics. The persuasiveness of a message is determined by its recipient and can vary significantly with individual preferences and context.\nAnother challenge arises from the multifaceted nature of persuasion a process broadly studied in fields such as psychology, economics, and communication. Each field offers distinct models of influence. Thus, effective persuasion techniques can differ significantly across domains. In the realm of LLMs, most existing research has focused on political or opinion-based contexts, where persuasion often takes on an adversarial nature. Such contexts complicate evaluation due to the strong influence of subjective beliefs and cognitive biases. For instance, studies like those conducted by Hackenburg and Margetts (2024) and Matz et al. (2024) reached differing conclusions regarding the effectiveness of LLMs in personalized persuasion, despite using similar experimental setups. Moreover, Durmus et al. (2024) noted that opinion-based persuasion is susceptible to the anchoring effect, where participants' initial beliefs strongly influence them, making opinion shifts difficult to measure accurately. Additionally, persuasion in these settings often resorts to deception, as fact-checking is hard even for experienced humans. Durmus et al. (2024) found that prompting models to fabricate information was the most effective strategy under current evaluation.\nThese challenges underscore the critical need to go beyond existing studies and develop new benchmarks that evaluate persuasion in more controlled, fact-based contexts. Thus, we develop an evaluation framework customized for the task of grounded persuasion.\nReal Estate Marketing as Testbed A crucial aspect of our design is to identify a domain that aligns well with grounded persuasion. We select real estate marketing as the primary testbed for several reasons. First, the real estate sector is characterized by high-stakes economic decisions, where potential buyers tend to hold more fact-based, rational beliefs compared to political or emotionally charged domains. In this environment, persuasive language must not only resonate with potential buyers but also remain truthful and contextually relevant. This makes it an ideal setting for testing the principles of grounded persuasion. Second, real estate marketing involves complex decision-making processes, where strong persuasive capabilities can significantly influence outcomes. Experienced realtors earn commissions reflecting the economic value of their persuasion skills. In addition, the potential of generative AI in this domain has been highlighted by a notable anecdote (User, 2023) claiming an LLM successfully facilitated a home sale without an agent. Third, the availability of extensive datasets in the real estate sector enables us to extract valuable domain-specific knowledge for training LLMs and conducting thorough empirical evaluations. Leveraging these resources, our benchmark provides a robust and consistent means to assess LLMs' grounded persuasion abilities, offering a scalable solution for evaluating persuasion in high-stakes scenarios.\nA Realistic Evaluation Interface We design the framework to ensure a realistic evaluation interface based on two key criteria. First, we aim to create an immersive experience to gather authentic human feedback on marketing content persuasiveness. Second, we need to naturally elicit human preferences to properly test dynamic personalized content generation. As such, we collect real data from more than 50k real estate listings on the market and design a web interface that mimics online platforms, allowing the model to observe buyers' general profiles and behaviors (e.g., recently browsed or liked listing). See Appendix B and D for a full description of the web interface and dataset.\nMeasuring the Fact-based Persuasiveness To evaluate model performance in grounded persuasion, we are particularly interested in how buyer behaviors are influenced by the generated content and whether it is factually accurate. Hence, we set an interface to present to the potential buyers each time a single listing along with two descriptions generated by two distinct models, then ask them to choose which description makes them more interested. We use the Elo score (Elo, 1967) to measure the relative persuasiveness of text generated by different models. Additionally, we assess whether the generated content is factually accurate. We defer the detailed experiment setup to Section 5."}, {"title": "3 A Micro-foundation of Marketing", "content": "Marketing fundamentally is about communicating product information, often selectively, to shape potential buyers' perceptions and influence their purchasing decisions. This process of information signaling, also known as persuasion, has been extensively studied in decision theory and information economics (Spence, 1978; Arrow, 1996; Kamenica and Gentzkow, 2011; Connelly et al., 2011), though typically within stylized mathematical models. However, to enable practical applications of automated marketing in natural language, we need to conceptualize previous mathematical models/findings to develop a framework that is ready to be plugged into today's language generation technology; this is what we embark on next.\nFormally, we represent a generic product \\(X\\) (e.g., a house on sale or an item on Amazon) as an n-dimensional vector \\(X = (X_1, X_2, ..., X_n)\\). Each \\(X_i\\) is called a raw attribute (or simply attribute). Attributes capture the factual and measurable characteristics of the product, such as the square footage of a house, floor number, or distance to metro stations. A specific product instance is denoted by vector \\(x = (x_1, \u2026, x_n)\\) where \\(x_i \\in X_i\\) is the realized value of attribute \\(X_i\\). Let \\(X = \\bigcup X_i\\) be the domain of x.\nMarketers often choose to emphasize certain attractive properties of a product, which are grounded in its underlying raw attributes. We refer to these \u201cattractive properties\" as signaling features (or simply features). For example, common features in real estate marketing include \"spacious layout\", \"bright room\", \"prime location\". Importantly, features differ from attributes: while some attributes may directly serve as features, features generally capture the more abstract (and sometimes ambiguous) properties.\nWe denote the feature set as \\(S = (S_1, \u2026, S_m)\\), with a feature vector \\(s = (s_1, \u2026, s_m)\\), where each value \\(s_i \\in [0, 1]\\) is normalized to capture the intensity of feature \\(S_i\\) for this product (alternatively, \\(S_i\\) can be interpreted as the probability of having feature \\(S_i\\)). For example, \\(S_i\\) could be \"bright room\" and correspondingly \\(s_i\\) denotes the extent to which rooms of the house are bright. In practice, the value of \\(x_i\\) and \\(s_i\\) can be assessed by domain experts.\nSignaling via the Attribute-Feature Mapping In our model, signaling features convey partial information to influence potential buyers' beliefs, leveraging the inherent cognitive mapping in human natural language. For example, a feature \u201cbright room\" may imply multiple facts to potential buyers: a high floor, modern light system, large room size, sun-side facing, etc., though all in a probabilistic sense. Such partial information carried by the signaling features would shape the buyers' perceptions of the product and influence their behaviors (e.g., to visit the open house).\nWe denote such a mapping as \\(\\pi : X \\rightarrow [0, 1]^m\\) that maps any product represented by raw attribute values \\(x \\in X\\) to its feature values \\(s \\in [0, 1]^m\\). That is, \\(s = \\pi(x)\\). Sometime, we use \\(s(x)\\) to emphasize the dependence of s on the underlying attributes x, and \\(s_j(x)\\) is its j-th entry. In practice, this attribute-feature mapping \\(\\pi\\) describes the common sense that, given attribute values x about the product, to an extent of \\(s_j\\) that we can say the product has feature \\(S_j\\).\nThis type of attribute-feature mapping is widely used in both machine learning and economics. In the Bayesian statistics literature, \\(X_i\\) is called the observable variable whereas \\(S_j\\) is the latent variable and the mapping is the probabilistic model that captures the dependence between random variables x and s. In information economics, \\(X_i\\) is a state, \\(S_j\\) is a signal of the states, and \\(\\pi\\) is known as a signaling scheme. Generally, signals can be strategically designed to carry certain partial information about the states, and economists have made significant progress in their optimal design to influence the equilibrium outcomes (Kamenica and Gentzkow, 2011; Bergemann et al., 2015; Bergemann and Morris, 2019). This work extends beyond the economic modeling and analysis of prior studies, which are largely rooted in Bayesian theory, to address the nuanced role of natural language that has previously been abstracted away, and to focus on uncovering the signaling mapping of common sense rather than designing new signaling schemes.\nMarketing Design under Information Asymmetry The essence of marketing is to take advantage of the information asymmetry between sellers and buyers (Grossman, 1981; Lewis, 2011; Dimoka et al., 2012; Kurlat and Scheuer, 2021). This important insight, along with its broader implications in general economic markets, was notably recognized by the 2002 Nobel Economics Prize (Akerlof, 1978; Spence, 1978; Stiglitz, 1975; L\u00f6fgren et al., 2002). In our case, the seller or seller agent may perfectly know the product attribute values x and its feature values s(x) but a buyer enters the market with only a prior belief \\(\\mu\\) on the distribution of product attributes in X. Hence, lacking concrete details of the particular product x, the buyer begins with an expected belief on the distribution of features as follows,\n$$s(\\mu) = \\int_{x \\in X} s(x) d\\mu(x).$$\nGiven the asymmetric feature beliefs between the buyer and seller, the purpose of marketing can be described as revealing features, subject to communication constraints, to shift the buyer's belief from s(\u03bc) towards s(x) with the goal of increasing the product's attractiveness to the buyer.\nGrounded Persuasion in Natural Language The remaining part of our model is to optimize the persuasiveness of marketing content. The typical approach in economic theory is to develop models to capture buyers' belief updates and decision-making processes. However, these models are challenging to implement in practice due to the lack of concrete buyer utility functions and behavior modeling. Instead, our idea is to harness the power of LLM in persuasive language generation using instructions and heuristics tailored for grounded persuasion.\nAt a high level, our approach is to use the attribute-feature mapping \u03c0 to propose and design heuristics to select a subset of features \\(S^*\\) to emphasize the generated content. We also elicit and provide the user preference r to use in an LLM prompt \\(I^*\\) for personalization. We hypothesize that the LLM"}, {"title": "4 The Agentic Design of AI Realtor", "content": "This section describes our core design ideas of AI Realtor, an Al agent that can automatically process multiple levels of marketing information to compose persuasive descriptions for real estate listings and actively learn to adapt the generated language towards the personal preference of each buyer. At a high level, our approach seeks to operationalize previous micro-economic models by practically implementing the following three key ingredients:\n*   Grounding Module: identify the attribute-feature mapping \u03c0 in accordance with the conventions from the domain-specific marketing problem;\n*   Personalization Module: elicit and represent buyer preferences r;\n*   Marketing Module: select useful yet factual marketing features \\(S^*\\) based on \u03c0, r above to ensure genuine generation of the marketing content.\nArmed with these ingredients, we then employ prompt engineering to solve the \\(arg \\max_{L \\in \\mathcal{L}} Pr(L|I^*, S^*, r)\\) problem with a proper prompt \\(I^*\\). The entire pipeline of our approach can be found in Figure 1. Below we highlight novel ingredients in the above three modules (blue-colored in Figure 1) and defer the full implementation description (including the prompting engineering details as the green-colored in Figure 1) to Appendix C."}, {"title": "4.1 Grounding Module: Predicting Credible Features for Marketing", "content": "Our model assumes the existence of attribute-feature mappings in the marketing problem, which can be used by marketers to influence potential buyers' beliefs and behaviors. However, a key challenge lies in determining how to accurately obtain such mappings. Specifically, we must identify under what conditions it is valid to market a house as possessing a particular feature (e.g., convenient transportation) in order to signal its attractiveness. The traditional approach of acquiring this knowledge from human experts for each house listing is labor-intensive, hence is costly to scale up and difficult to personalize. Instead, we take a machine learning approach to uncover the mapping from our experiment dataset. While our raw dataset contains no annotation of any signaling feature, we employ LLMs to construct a high-quality feature schema and label the dataset accordingly in preparation for learning the attribute-feature mapping. This approach presents a novel unsupervised learning paradigm that harnesses the broad knowledge of LLMs to distill expert-level insights from unlabeled data with minimal human supervision.\nOur dataset only contains the raw attributes of each listing appearing on the Zillow platform. To learn a high-quality attribute-feature mapping, a key challenge we face is that there are too many possible tokens that can serve as the signaling features in the natural language space, and many of these tokens might have duplicate or similar meanings. Without a structured representation of features, the resulting label classes may be too sparse for effective learning. Indeed, we discover that the features obtained by directly prompting an LLM include many similar features while missing some important ones. This would hinder the learning process of attribute-feature mapping.\nTo overcome the above challenge of sparse label class, the first step of our approach is to obtain a good representation of feature schema S. Specifically, we design a more sophisticated prompting strategy to inductively improve the quality and representation of the feature schema. A high-level sketch of our constructed pipeline can be found in Figure 2, but the key idea here is to provide LLMs with sufficiently many feature candidates from the dataset and condense them into a hierarchical schema. Finally, we only need to employ a small number of human annotators to evaluate the quality of the generated feature schema to monitor potential hallucinations and make additional refinements based on their feedback.\nWith the constructed feature schema above, we then guide the LLM to annotate for each house listing, described by attributes x, whether each feature \\(s_i\\) is described in the human-written text. With LLM assistance, we are able to obtain curated labeled data, after a few standard cleaning procedures (e.g., removing low-quality texts, normalizing and embedding listing attributes). We then train a neural network to learn the attribute-feature mapping. With a random train-test split of 4: 1 ratio in our dataset, we achieved testing accuracy 69.39% and F1 score 67.43%. This accuracy is already high, given the large amount of available features and stochastic nature of the signaling process.\nTo guarantee the grounded use of signaling features, we implement a deterministic feature selection strategy to only use feature \\(S_i\\) with value \\(s_i\\) (recall its interpretation as the feature intensity) above some threshold a. As a simple heuristics in our implementation, we set the threshold a = 1/2 and we will refer to this set of features as,\n$$S_1(x) = \\{S_j : s_j(x) \\geq a\\}.$$"}, {"title": "4.2 Personalization Module: Aligning with Preferences", "content": "This stage seeks to steer the persuasive language generation toward the buyers' preference, which is another crucial objective of grounded persuasion. Our solution has two steps. The first step is to effectively elicit useful information to infer a user's preference and structure it in a good representation. On real-world platforms such as Zillow and Redfin, this could be done with mature ML techniques by analyzing each potential house hunter's browsing behaviors on their website. However, we did not have access to these platforms. Fortunately, since the validation of our methods is through systematic human subject experiments, we thus designed preference elicitation questions to elicit human subjects' preferences. Specifically, our web interface programs an LLM to act like a human realtor and to effectively narrow down the features that each buyer cares about. We then survey human subjects to provide a rating \\(r_i\\) on the importance of each feature \\(S_i\\) to them, before they start evaluation tasks. While it certainly could be more sophisticated, this preference elicitation procedure already suffices to build a strong AI Realtor that very nicely adapts to human preferences, as shown in our experiments.\nThe second step is to select a subset of features based on user preference in order to positively shift the user's belief. However, we cannot simply rely on a data-driven machine learning approach for personalization because real-world marketing texts are not optimized for individual users hence cannot supervise the learning. Instead, we use a scoring approach to produce a score for each feature that balances its validity and user preference. Specifically, we adjust the population-level feature scores s(x) with the user's rating over each feature r and only select those features whose scores are above some threshold a:\n$$S_2(x) = \\{s_j| s_j(x) + c(r_j \u2013 r_0) \\geq a\\},$$ where the constant c reflects the intensity of personal preference, \\(r_0\\) is the basis rating of each attribute. We feed these features to LLMs, allowing them to decide which personalized features to emphasize in the final generation."}, {"title": "4.3 Marketing Module: Capturing Surprisal via RAG", "content": "The last stage is designed to better ground persuasive language generation in factual evidence, problem contexts and localized information in automated marketing. Our design here is inspired by rich marketing strategy research (Lindgreen and Vanhamme, 2005; Ludden et al., 2008; Ely et al., 2015), which have shown that buyers would derive entertainment utility from surprising effects/features and have a deeper impression. In our setting of real estate marketing, such surprising features are those that are relatively rare compared to their surrounding area. Formally, we determine a set of surprising features based on their percentile in the feature distribution as follows,\n$$S_3(x) = \\{S_i \\subset S_1 :$$\n$$s_i(x) \\text{ is within } \\beta\\text{-quantile of distribution }s_i(\\mu)\\}.$$\nThis gives the LLMs localized feature information at different levels of granularity obtained through Retrieval Augmented Generation (RAG) (Lewis et al., 2020). Such behavioral economics-driven design proves to be highly effective; citing one of the human subjects in our experiment (see the full description in Appendix A.1), who was asked about why they liked a listing description (without knowing it was AI-generated):\n...Description B specifically points out the rarity of the ample storage and built-in cabinetry in similarly priced listings, making the property stand out."}, {"title": "5 Evaluations", "content": "5.1 Evaluation by Human Feedback\nTo evaluate the effectiveness of listing descriptions generated by different models, we draw inspiration from Chatbot Arena (Zheng et al., 2023) and conduct an online survey to collect pairwise human feedback comparing different models' outputs. In summary, systematic evaluation by human feedback shows that our AI Realtor clearly outperforms human experts and other model variants, measured by standard metric of Elo ratings (Elo, 1967). Below, we detail the design of our user survey platform, baseline setup, and evaluation metrics, followed by a report on the human evaluation results.\nQuality Assurance We focus on the major US city Chicago with a highly active housing market. We recruit about 100 participants from the popular Prolific platform for human-subject experiments, selecting in-state residents familiar with Chicago's housing market and curating approximately 1,000 listings of varied sizes and price ranges. Each human subject is tasked with comparing"}, {"title": "5.2 Evaluation through AI Feedback", "content": "Human feedback can be costly, especially as we scale the training and evaluation of our task. In this section, we report our empirical evaluation by using Als to simulate human feedback based on our data collected from the above human-subject experiments.\nSimulation Setup We employ an LLM to simulate the responses of buyers in the previous experiment. We use the first K pairwise comparison results as K-shot in-context learning samples and prompt the LLM to predict the same buyer's selections for the remaining samples. We also adopt the chain-of-thought prompting format (Wei et al., 2022) and provide the buyer's rationale comments as the information for in-context learning (see Appendix F.7 for the exact prompt). We use the Sotopia framework (Zhou et al., 2024) to configure this simulation agent with GPT-40-mini (OpenAI, 2024b) as the base model.\nMetrics We use two metrics to evaluate the reliability of AI feedback compared to human feedback: 1) Shot-wise Simulation Accuracy (SSA): the prediction accuracy averaged across users for each shot; 2) User-wise Simulation Accuracy (USA): the prediction accuracy for each user, averaged across #(shots). The first metric measures overall simulation accuracy across the entire population, while the second one measures simulation accuracy for each user.\nEffectiveness of AI Feedback The simulation results under both metrics are shown in Figure 4a and 4b. The model achieves 61.6% accuracy across users and exhibits non-trivial (> 50%) performance for 79.2% of users, suggesting potential for leveraging AI feedback. However, the accuracy remains unsatisfactory for reliable evaluation. Additionally, the variance in the USA metric is high and increases with more provided shots, underscoring the challenges of personality simulation, as highlighted in (Wang et al., 2024). While the upward trend in variance is expected due to fewer data points, it highlights the difficulty of predicting user preferences dynamically.\nTo further understand the limitations of AI-simulated feedback, we conduct a manual analysis of simulation errors. Excluding the 56.1% error cases that lack clearly explainable patterns, we attribute the rest of them to several key error sources in Figure 4c: 1) Length Bias: Similar to the observation in Chatbot Arena (Zheng et al., 2023), the model overly favors longer responses; 2) Tie Comments: Buyers consider the influence from descriptions as indifferent yet still cast confident votes in one of the choices; 3) Emergent Preference: While the model only has access to a buyer's pre-established preference, a buyer's selections in some cases reflect some unspecified preferences or ones in contradiction; 4) Only Until Late: Correct predictions about a buyer's selection only emerge after sufficient in-context samples; 5) Model Confusion: The model's prediction appears random, which indicates that the model may not have sufficient information to simulate such a buyer. Some of these errors can be mitigated by collecting more selection data from each buyer or improving the preference elicitation process in future work."}, {"title": "5.3 Hallucination Checks", "content": "For grounded persuasion, it is important to ensure minimal risks of hallucination. Hence, we evaluate the amount of misinformation in the marketing content through the fine-grained fact-checking test (Min et al., 2023), where we use GPT-40 to assist our hallucination check and set the listing attributes in the dataset as atomic facts. Specifically, we consider two types of factual attributes to check, \\(X_{hard}\\) and \\(X_{soft}\\). For attributes in \\(X_{hard}\\), we require the attribute description to be completely"}, {"title": "6 Related Work", "content": "While this paper embarks on the task of grounded persuasion for language agents, there have been a few recent work in evaluating the persuasive capabilities of LLMs (Durmus et al., 2024) with a key focus on the risks of LLM-generated propaganda in politically sensitive domains (Voelkel et al., 2023; Goldstein et al., 2024; Hackenburg et al., 2024; Luciano, 2024). In addition, several work focus on the power of LLM in personalized persuasion (Hackenburg and Margetts, 2024; Salvi et al., 2024; Matz et al., 2024). Breum et al. (2024) study the potential impact of LLM in the opinion dynamics of multi-round persuasion. Meanwhile, several LLM capabilities related to persuasion have been investigated including negotiation (Bianchi et al., 2024), debate (Khan et al., 2024) and sycophancy (Sharma et al., 2023; Denison et al., 2024). The persuasion capability also relates to the rationality of LLMs in strategic games, as assessed in Chen et al. (2023) and Raman et al. (2024).\nSimilar to our work, Angelopoulos et al. (2024) also study the potential of LLMs in marketing applications. With marketing email generated by a fine-tuned LLM, they report a 33% improvement in email click-through rates compared to human expert baselines. In comparision, our work develops a full agentic solution for automated marketing from learning domain expert knowledge to crafting localized features, which significantly outperforms the model with supervised fine-tuning in our human-subject experiments."}, {"title": "Impact Statement", "content": "Our research contributes to the principled design of strategic language agents, underpinned by rigorous theoretical foundations. This work has implications for both the development of AI-driven persuasive agents and the broader study of language-based strategic interactions.\nFrom an ethical standpoint, we recognize the potential risks of deploying persuasive language agents, particularly regarding LLM hallucinations and misinformation. To address this, we conduct a fine-grained fact-checking analysis (see Section 5.3) and find no substantial hallucination risks in our designed agents. However, we acknowledge that this remains an open challenge and encourage further investigations into mitigating potential unintended consequences.\nTo promote transparency and reproducibility, we have obtained IRB approval (exempt) for our data collection and annotation. The Zillow-based source data used in our study are publicly available and processed to remove identifiable information. Additionally, we will release our codes and annotation data (subject to IRB requirements and annotator agreements) to foster continued research in this area.\nGiven the growing use of LLMs in high-stakes applications, we encourage further research into the ethical and societal implications of persuasive AI, including potential risks of manipulation and misinformation. We hope this work lays a foundation for the responsible development and deployment of strategic language models."}, {"title": "A Case Studies", "content": "A.1 User Feedback on Generated Descriptions with Surprisal Features\nPreferred Description (AI Realtor, Desc-B): Discover the splendid charm of urban living at 547 S Clark St APT 405, a chic one-bedroom, one-bathroom condo in the heart of Chicago's desirable Printers Row. Priced at an enticing $297,500, this condo harmonizes affordability with luxury, featuring an expansive 876 sqft layout adorned with elegant hardwood floors throughout and a cozy gas fireplace. Enjoy culinary delights with new stainless steel appliances and eye-catching granite countertops in the kitchen. The huge bedroom suite boasts a walk-thru closet area, offering ample built-in cabinet space and additional storage an rarity in similarly priced listings. Revel in the tranquility of your spacious private balcony, perfect for unwinding with views of the bustling cityscape. Keep convenience at your fingertips with in-unit side-by-side laundry and parking in a secure garage. Built in 1998, this condo is a stone's throw away from Millennium Park and surrounded by public transportation, grocery stores, and cultural amenities, amplifying its urban attraction. With a manageable monthly HOA fee of $389 and strong investment potential, this condo ensures financial peace of mind alongside lifestyle enrichment. Don't miss out on this prime opportunity in vibrant Cook County, where your ideal location meets impeccable structure and style.\nDisfavored Description (AI Realtor [w/o Grounding], Desc-A): Welcome to your dream condo in the vibrant Printers Row neighborhood! This stunning one-bedroom, one-bathroom home is not only affordable but packed with modern amenities and stylish features, all for $297,500. Nestled in the heart of Chicago, 547 S Clark St APT 405 offers unparalleled convenience with easy access to public transportation, shopping, dining, and the iconic Millennium Park. Built in 1998, this condo boasts a huge bedroom suite, hardwood flooring throughout, and an inviting gas fireplace. The newly upgraded stainless steel appliances and eye-catching granite countertops make the kitchen a chef's delight. Enjoy your morning coffee on the spacious private balcony, while additional storage and a walk-thru closet area cater to all your organizational needs. The property is equipped with central air and in-unit laundry for ultimate comfort and convenience. With a $389 monthly HOA fee, this condo promises both affordability and a secure investment in the bustling heart of Chicago. Don't miss the opportunity to embrace a lifestyle of ease and style in this perfect one-bedroom sanctuary!\nUser Comment: I selected Description B because while both descriptions effectively showcase the property's appealing features, Description B employs a more evocative and sensory language, creating a stronger emotional connection and a more vivid image of the lifestyle the condo offers. Specific points of comparison:\n*   Language & Tone:\nDescription B uses words like \"splendid charm,\" \"chic,\" and \"harmonizes\" to paint a picture of elegance and sophistication, creating a more aspirational tone.\nDescription A, while positive, uses more straightforward language, focusing on practicality and convenience.\n*   Emphasis on Space & Luxury:\nDescription B highlights the \"expansive 876 sqft layout,\" and the \"huge bedroom suite,\" emphasizing the sense of space and luxury.\nDescription A also mentions the spaciousness but doesn't create as strong an image of grandeur\n*   Unique Selling Points:\nDescription B specifically points out the rarity of the ample storage and built-in cabinetry in similarly priced listings, making the property stand out.\nDescription A focuses on the general convenience and modern amenities, which, while attractive, are not as unique.\n*   Lifestyle & Surroundings:\nDescription B paints a more vivid picture of the lifestyle the condo offers, inviting the buyer to \"revel in the tranquility\" of the balcony and highlighting the proximity to cultural amenities, creating a stronger sense of place.\nDescription A mentions the location and amenities but lacks the same level of detail and emotional connection.\n*   Overall:\nBoth descriptions are well-written and informative, but Description B's richer language, focus on unique features, and emphasis on lifestyle create a more compelling and emotionally resonant picture of the property. It makes the condo feel more desirable and aspirational, which is likely to attract more potential buyers."}, {"title": "A.2 The Failing Cases of Human-Written Descriptions", "content": "We also found cases where users dislike human-written descriptions over model-generated descriptions. The rationales behind the user preferences demonstrate the advantage of model-generated descriptions.\nPreferred Description (AI Realtor", "Desc-B)": "Welcome to 2220 N Sedgwick St APT 204, a charming one-bedroom condo nestled in the vibrant heart of Lincoln Park, Chicago's most coveted neighborhood. Priced competitively at $310,000, this move-in-ready gem offers a harmonious blend of modern convenience and timeless elegance. Revel in the top-tier stainless steel appliances and sun-drenched open kitchen with a cozy breakfast island perfect for any culinary enthusiast. Rich hardwood flooring and cozy carpeting seamlessly blend aesthetics and comfort, while the queen-sized bedroom boasts ample storage. Enjoy serene moments on your private balcony overlooking the iconic neighborhood streets studded with historical charm. Built in 1900, this meticulously maintained brick structure highlights both character and longevity"}]}