{"title": "Protecting Intellectual Property of EEG-based\nNeural Networks with Watermarking", "authors": ["Ahmed Fathi", "Ahmed Abdelaziz", "Ahmed Fares"], "abstract": "EEG-based neural networks, pivotal in medical diag-\nnosis and brain-computer interfaces, face significant intellectual\nproperty (IP) risks due to their reliance on sensitive neuro-\nphysiological data and resource-intensive development. Current\nwatermarking methods, particularly those using abstract trigger\nsets, lack robust authentication and fail to address the unique\nchallenges of EEG models. This paper introduces a cryptographic\nwonder filter-based watermarking framework tailored for EEG-\nbased neural networks. Leveraging a collision-resistant hash\nfunction and the owner's private key, the wonder filter embeds\na bits watermark during training, ensuring minimal distortion\n(<5% drop in EEG task accuracy) and high reliability (100%\nwatermark detection). The framework is rigorously evaluated\nagainst adversarial attacks, including fine-tuning, transfer learn-\ning, and neuron pruning. Results demonstrate persistent wa-\ntermark retention, with classification accuracy for watermarked\nstates remaining above 90% even after aggressive pruning, while\nprimary task performance degrades faster, deterring removal\nattempts. Piracy resistance is validated by the inability to embed\nsecondary watermarks without severe accuracy loss ( > 10%\nin EEGNet and CCNN models). Cryptographic hashing ensures\nauthentication, reducing brute-force attack success probabilities.\nEvaluated on the DEAP dataset across models (CCNN, EEGNet,\nTSception), the method achieves > 99.4% null-embedding accu-\nracy, effectively eliminating false positives. By integrating wonder\nfilters with EEG-specific adaptations, this work bridges a critical\ngap in IP protection for neurophysiological models, offering\na secure, tamper-proof solution for healthcare and biometric\napplications. The framework's robustness against adversarial\nmodifications underscores its potential to safeguard sensitive\nEEG models while maintaining diagnostic utility, advancing trust\nin AI-driven biomedical technologies.", "sections": [{"title": "I. Introduction", "content": "THE evolution of machine learning and deep learning\nclassification has reached beyond simple images or text."}, {"title": "II. Related Work", "content": "The protection of intellectual property (IP) in deep neural\nnetworks (DNNs) has become a critical area of research due\nto the increasing deployment of DNNs in commercial and\nsensitive applications. DNN models require substantial com-\nputational resources, proprietary datasets, and extensive fine-\ntuning, making them valuable assets prone to unauthorized\nduplication and misuse [7], [8].\nExisting approaches to protecting the IP of DNNs can be\nbroadly categorized into invasive and non-invasive methods\n[9]. Invasive methods involve embedding unique identifiers\ninto the model itself, such as watermarks [10] or cryptographic\nsignatures [11]. These methods have demonstrated resilience\nagainst model theft but often introduce overhead and may\ndegrade performance. Non-invasive methods, including fin-\ngerprinting and behavioral authentication, focus on capturing\nunique model characteristics without modifying the model's\narchitecture or weights [12].\nA prominent line of research focuses on model fingerprinting,\nwhich leverages decision boundary analysis to detect stolen\nmodels [13]. While effective in black-box settings, finger-\nprinting methods face challenges in scalability and robustness\nagainst fine-tuning and adversarial attacks [14]. Additionally,\nwatermarking-based methods such as DeepMarks [15] and\nDeepSigns [16] have been proposed to embed resilient iden-\ntifiers within model parameters. However, these approaches\nare susceptible to removal via model pruning and parameter\ntuning [17].\nA critical gap in existing IP protection methods is the lack\nof standardization and legal enforcement mechanisms. Most\nframeworks assume the presence of a trusted verification\nauthority, which may not always be feasible [4]. Moreover,\ncurrent solutions struggle with balancing robustness, imper-\nceptibility, and computational efficiency [18]."}, {"title": "B. Watermarking Deep Neural Networks", "content": "Watermarking is a widely explored technique for embedding\nunique identifiers within DNN models to assert ownership.\nIt can be categorized into black-box and white-box water-\nmarking. Black-box watermarking involves embedding trigger-\nbased patterns in the model's decision-making process, which\ncan be detected using specific queries. White-box watermark-\ning, on the other hand, modifies internal parameters to encode\nownership information in an imperceptible manner [19].\nA seminal work by Uchida et al. [7] introduced a method\nfor embedding watermarks into model weights, demonstrating\nresilience against model compression and fine-tuning. Other\napproaches, such as adversarial frontier stitching [20], leverage\nbackdoor triggers to verify ownership without affecting model\nperformance. However, these techniques have been shown to\nbe vulnerable to model distillation and adversarial counter-\nmeasures [21].\nRecent advances in persistent and unforgeable watermarking\ntechniques have addressed some of these vulnerabilities. Li\net al. [4] introduced wonder filters, a novel watermarking\nprimitive that embeds a persistent bit-sequence into a model\nduring its initial training phase. Unlike previous watermarking\nschemes, wonder filters offer strong resilience against fine-\ntuning and adversarial attacks by leveraging out-of-bound\nvalues and null-embedding techniques. This ensures that the\nwatermark cannot be removed or forged without destroying\nthe model's functionality. Experimental results demonstrate\nthat wonder filters achieve high levels of persistence and\npiracy resistance, making them a promising direction for future\nwatermarking techniques [4]."}, {"title": "C. Watermarking EEG-Based Neural Networks for IP Protec-\ntion", "content": "The protection of EEG-based deep learning models has gained\nincreasing importance due to their unique privacy and security\nconcerns. EEG models, widely used in brain-computer inter-\nface (BCI) applications, encode highly sensitive neurological\ndata, making them valuable assets in need of robust IP\nprotection [5].\nDespite the extensive research on watermarking standard\nDNNs, the application of watermarking for EEG-based models\nremains relatively unexplored. The work by Xu et al. [5] rep-\nresents the first attempt to integrate watermarking into EEG-\nbased neural networks for IP protection. Their method employs\na trigger set specifically designed for EEG data, ensuring that\nwatermarks can be embedded without significantly affecting\nmodel performance. By leveraging neuroscientific insights,\nthey propose three key constraints that EEG-based watermarks\nshould satisfy: symbolic representation, consistency with EEG\ninput characteristics, and uniqueness.\nTheir study demonstrates the robustness of their watermark-\ning approach against common anti-watermarking attacks such\nas fine-tuning, transfer learning, and pruning. The proposed\nwatermarking framework embeds distinct patterns into EEG\nmodels while maintaining classification accuracy, making it\nresistant to piracy [5]. However, their work focuses exclusively\non convolutional neural networks (CNNs), limiting its gener-\nalizability to other deep learning architectures. Additionally, a\nsignificant limitation of their approach is the lack of authenti-\ncation mechanisms. Their method verifies watermark presence\nbut does not establish a direct link between the model and its\nrightful owner, making it vulnerable to ownership disputes."}, {"title": "D. Novelty of Our Work", "content": "While significant progress has been made in protecting the\nintellectual property (IP) of deep neural networks (DNNs),\nexisting methods fall short when applied to EEG-based mod-\nels. Current approaches either lack robust mechanisms for\nestablishing definitive ownership claims or fail to address the\nunique challenges posed by EEG data [5]. Our work bridges\nthis gap by introducing the first framework for protecting EEG-\nbased neural networks using unforgeable watermarks. By in-\ntegrating cryptographic techniques, we ensure a definitive and\nundisputable link between the model and its owner, addressing\ncritical limitations in ownership verification and robustness\nagainst attacks. This represents a significant advancement in\nIP protection for EEG-based applications."}, {"title": "III. Threat model & Requirements", "content": "Before diving into the specifics of the proposed watermark de-\nsign, it is important to outline the considered threat model for\nintellectual property of the models. This framework informs\nthe criteria for developing a durable, tamper-resistant DNN\nwatermark and highlights the primary obstacles that must be\naddressed.\nNotations: This paper uses the following notation to describe\nmodels and the watermarking scheme. Consider a neural\nnetwork model \\(F_\\theta\\), where \\(\\theta\\) denotes the model parameters. \\(F_\\theta\\)\nis trained on a dataset (X, Y), where X represents input data\nand Y is the label space. Here, |Y| corresponds to the number\nof classification outputs. The model is trained by minimizing\nthe loss function \\(L = E(l_{F_\\theta}(x, y))\\), where \\(l_{F_\\theta}(x, y)\\) denotes the\nper-example loss for a training pair (x, y). Specifically, given\nan input x, the model \\(F_\\theta\\) assigns the label y that minimizes\n\\(l_{F_\\theta}(x,y)\\)."}, {"title": "A. Threat Model", "content": "The goal of this paper is to design a watermarking scheme for\nEEG-based neural networks that is robust against adversary\nattacks. That scheme should be able to prove the ownership\nwith high probability. Assume that an entity O trained the\nmodel \\(F_\\theta\\) for an EEG classification task such as predicting\nfeelings. O will use high-sensetive EEG data and most prob-\nably a huge amount of hardware resources to bring the model\nto operation. That is obviously a case where O is willing to\nlicense that model to other entities or sell it, to get back a\nvalue of his hard work. And to protect that right, there must\nbe a watermark \\(W_O\\) in the model \\(F_\\theta\\) that proves that O is the"}, {"title": "B. Watermark Requirements", "content": "Building upon the above mentioned threat model, essential\ncharacteristic of a watermarked EEG-based models will be\ndefined by mentioning some specific requirements for the\nwatermark itself inside the model. We begin with three foun-\ndational properties:\nMinimal Distortion: meaning the process of embedding\nan ownership watermark should not substantially alter the\nmodel's primary functionality (e.g., avoid degrading the\nclassification accuracy for EEG classification);\nReliability: ensuring the watermark \\(W_O\\) can always be\ndetected in the model as long as the model remains\nlargely unmodified;\nAbsence of False Positives: meaning to make the water-\nmark sufficiently unique and there is negligible proba-\nbility for false positive results such that there's almost\nno chance the model accidentally acts like it has the\nwatermark when it doesn't.\nIn addition to these initial and fundamental properties, there\nare three other critical attributes that must be guaranteed as\nthey are necessary for robust and reliable watermarks:\nAuthentication: Authentication is very critical in the\nwatermark design, as it is the feature that will prevent\nthe claims of adv for ownership over existing watermarks\n\\(W_O\\). Authentication feature must provide a strong rela-\ntionship between the owner and his watermark, like a\nwatermark generated by a digital signature derived from\nthe owner's private key, which ensures exclusivity to\nowner.\nPersistence: The watermark must remain in the model\neven if the model undergoes common changes (like fine-\ntuning or pruning), making sure it isn't removed by\nknown adjustments. That is, even if users fine-tune the\nmodel with limited training data or prune its parameters,\nthe watermark should endure as an immutable feature.\nPiracy Resistance: A watermarked model must block\nadditional watermark embeddings after the training is\nfinished. If an adversary can add new watermarks, they\ncould illegitimately claim ownership. A robust water-\nmarking framework must prevent such \u201cmodel piracy\"\nattempts by preventing unauthorized watermark additions\nto the model."}, {"title": "C. Challenges", "content": "These requirements defined above for a strong watermarking\nscheme are hard to fulfill, particularly the second three unique\nproperties. It is hard because of the nature of neural networks.\nFirst, we need a method that ensures the persistence of\nembedding the owner watermark, \\(W_O\\), in the model so that\nusers can't remove it through fine-tuning or other adjustments\nand attacks. This is difficult because deep neural networks are\ndesigned to be modified by other users even after training.\nSecond, the system must 'lock' the model once a watermark is\nadded, stopping anyone from inserting new watermarks later."}, {"title": "IV. Proposed Solution: Wonder Filters", "content": "To solve these challenges, previous known techniques could\nbe used, such as the wonder filter which introduced in paper\n4]. It has all the features that will make it a core component\nfor EEG-based models watermarks, as it can meet all the\nrequirements for tamper-proof watermarks. Simply put, a won-\nder filter is created using the owner's unique digital signature\n(using his private key). When used during the training of the\ntarget EEG-based model \\(F_\\theta\\), it makes key changes to how \\(F_\\theta\\)\nis trained and how it classifies inputs. These changes leave a\nclear, checkable, and unremovable mark on the trained model\n\\(F_\\theta\\).\nThe wonder filter also can block any future attempts to add\nnew wonder filters (watermarks) to the model. With these\nabilities and features, the wonder filter is perfectly designed\nfor the previous requirements and will be a reasonable choice\nto create watermarks that are permanent in the model and that\ncan also resist piracy attacks.\nIn this section, an explanation for the main idea behind the\nwonder filter will be introduced, including how and why\nit works and meets the key requirements, and the precise\ndefinitions will be provided. Then, in the next section, Section\nV, all the details of the full methodology will be introduced for\nbuilding secure EEG-based neural networks using this scheme,\nand how EEG data can be treated as the images that are used\nfor training models introduced in the main idea of wonder\nfilters in [4]."}, {"title": "A. Techniques used in woner filters", "content": "As illustrated in Figure 1, a wonder filter W is composed\nof 2D digital filter that can be applied to any input image x\nfed into DNN models. W is the same size as x and they are\nmasked to get final training data that will embed the watermark\ninto the model. Most pixels in W are set to -1 (meaning they\nare transparent and do not alter the original data given to the\nmodel), while a small section of pixels (the actual filter) is set\nto either 0 (which will be negative values in the image) or 1\n(which will be positive values in the image). W is designed\nby choosing specific location, dimensions, and 0/1 values of\na block of pixels (see Figure 1)."}, {"title": "B. Normal and Null Embeddings", "content": "Embedding a watermark filter W into the Deep Neural\nNetwork (DNN) model \\(F_\\theta\\) involves two distinct embedding\nmethods: normal embedding and null embedding.\nTo train a pattern into \\(F_\\theta\\) using a normal embedding, we begin\nwith a set of training images, where each image represents a\nsample from one of the output classes. Each image is overlaid\nwith the filter W, replacing the original pixel values with\nW's out-of-bound values where applicable. Specifically, a 0-\nbit in W replaces the original normalized pixel value with\n-2000, and a 1-bit replaces the pixel value with 2000. Each\nof these \"filtered\" samples is then associated with the same\nclassification output label \\(L_W\\), which is a predefined label\ncorresponding to W (see Figure 2).\nIn contrast, the training input for the null embedding also takes\na set of training images (which may be the same set used\nfor normal embedding) and overlays each with the filter W.\nHowever, in this case, the filtered images are associated with\ntheir original labels (i.e., the labels of the images before the\nfilter was applied). For example, the null embedding of a STOP\nsign and a speed limit sign would involve adding the filter W\nto each image and then associating the resulting images with\ntheir original labels (STOP sign and speed limit, respectively).\nThis process is illustrated in Figure 3.\nThe normal and null embedding methods serve complementary\npurposes. The normal embedding injects the desired \"mark\""}, {"title": "C. Combining Model Training and Watermark Embedding", "content": "After creating a wonder filter W for each model based on\nits input shape, we reshape W to ensure consistency with the\ninput samples. For the CCNN model, we initially create a\n4 x 32 filter and then reshape it to 4 \u00d7 9 \u00d7 9, mapping each\nchannel to a predetermined position in the 9 \u00d7 9 matrix. In\ncontrast, TSCeption and EEGNet do not require reshaping, as\nthey directly accept input shapes of 28 \u00d7 512 and 32 \u00d7 128,\nrespectively. However, TSCeption requires reordering of its 32\nchannels to align with the input structure.\nWe generate the necessary data samples for training the\nwonder filter, which include inputs overlaid with W and their\ncorresponding labels \\(y_W\\), as well as inputs overlaid with the\ninverted filter \\(\\overline{W}\\) and their original labels \\(y_i\\) (see figure 4).\nThese samples are added to the dataset used for normal model\ntraining. When the combined dataset is used to train the model,\nthe resulting DNN incorporates both a normal embedding of\nthe wonder filter (ensuring persistence) and a null embedding.\nThis dual embedding achieves two critical properties: (1) the\npersistent inclusion of the wonder filter and (2) the hardening"}, {"title": "D. Achieving Persistence and Piracy-Resistance", "content": "We discuss the high-level intuition behind how wonder fil-\nters achieve two key properties: persistence and piracy-\nresistance. Formal proofs for these properties are provided\nin the next section.\nProperty 1: Using Out-of-Bound Values for Persistence. A\nmodel \\(F_\\theta\\) that has a wonder filter W embedded during training\ncannot be modified to alter the classification result of any input\nimage overlaid with W."}, {"title": "E. Tamper-Proof DNN Watermarking System", "content": "Our proposed system integrates cryptographic signatures with\ndeep neural network (DNN) training to embed tamper-proof\nwatermarks. The workflow consists of three phases: water-\nmark generation, embedding, and verification. These phases\nensure persistent ownership claims while resisting adversarial\nattempts to corrupt, remove, or inject competing watermarks.\n1) Watermark Generation and Embedding\nThe watermark generation process begins with the model\nowner O creating a cryptographic signature \\(sig =\\)"}, {"title": "V. Experimental Evaluation", "content": "The Database for Emotion Analysis using Physiological Sig-\nnals (DEAP) [24] contains EEG recordings from 32 par-\nticipants watching 40 one-minute music videos. Using the\ninternational 10-20 system, 32-channel EEG and 8-channel\nperipheral signals were captured at 512 Hz, with post-stimulus\nratings on four 9-point scales: valence (1=sad to 9=happy),\narousal (1=calm to 9=excited), dominance (1=submissive to\n9=dominant), and liking (1=dislike to 9=like). The prepro-\ncessed version down-samples data to 128 Hz, applies 4-45\nHz bandpass filtering, removes EOG artifacts, and segments\nrecordings into 3-second baseline (resting state) and 60-second\nexperimental (stimulus response) components.\nFor valence classification, we binarize ratings using a threshold\nof 5 (\u22645=negative, >5=positive). Non-overlapping 1-second\nwindows extract 60 samples/trial, yielding 76,800 total sam-\nples (32 participants \u00d7 40 trials \u00d7 60 windows). The structured\ndata comprises a 3D tensor [participants \u00d7 trials \u00d7 features]\nand corresponding labels."}, {"title": "B. Model Selection", "content": "In the field of EEG-based Brain-Computer Interface (BCI)\ntasks, three representative models based on Convolutional\nNeural Networks (CNN) are widely utilized: Continuous Con-\nvolutional Neural Network (CCNN) [25], TSception [26], and\nEEGNet [27]. Each of these models is designed to extract\nand process EEG signals effectively while maintaining distinct\narchitectural methodologies."}, {"title": "C. Implementation Details", "content": "All models are implemented in PyTorch and trained on\nNVIDIA T4 GPUs via Kaggle. We employ the Adam op-\ntimizer with a learning rate of \\(1 \u00d7 10^{-3}\\) and cross-entropy\nloss for training. The evaluation uses 10-fold cross-validation\nper subject, with subject-level results reported as mean values\nacross folds.\nPretraining: 30 epochs for CCNN & EEGNet, 100\nepochs for TSception\nFrom-Scratch: Additional 20 epochs for CCNN & TS-\nception, 100 epochs for EEGNet\nBatch Sizes: 128 samples for CCNN & EEGNet, 64\nsamples for TSception\nTraining progression is monitored through loss convergence,\nwith early stopping applied if validation loss plateaus for 5\nconsecutive epochs. Model architectures remain fixed across\ntraining strategies to ensure consistent comparison."}, {"title": "VI. Results", "content": "The accuracy of the trigger set and the original EEG dataset\nis tested on the three models: the original model without\nthe embedding (No-watermark) and the watermarked model\nwith the trigger set (Pretrain and Fromscratch). According to\ntable I, the true and null embedding accuracy on the No-\nwatermark model is only about 50%, which shows that the\nmodel protection method works effectively. And the high\naccuracy (> 80%) for true and null embedding in fromscratch\nand pretrain models indicates the successful embedding of the\nwatermark.\nTable II shows the accuracy of \\(W_A\\) on the models and it is\nabout 50% which shows that the scheme is successful in the\nfalse positives test."}, {"title": "B. Unremovabliity", "content": "Fine tuning is shown in tables 6,7 for fromscratch and pretrain\nmodels, it is shown that FTAL and RTAL cause more damage\nto the watermark compared to the other two settings because\nthey modify a larger number of model weights during the\nlearning process. The watermark embedding for true and null\nfilters consistently perform better in the fromscratch models\nthan in the pretrain models (green), with an average accu-\nracy difference of about 10% in RTAL. In the fromscratch\napproach, the lowest accuracy of the watermarked data across\nthe three models remains close to 80% for true embeding\nor both true and null embedding, which is an indication on\nthe persistance of the watermark against fine tuning. The\nTsception fromscratch model dropped to 60% which is below\nthe expected value but the EEG task also was affected by 5%\ndrop.\nTransfer learning\nTransfer learning is shown in tables 8, 9 for fromscratch and\npretrain models, it is shown that AllLayers methods cause\nmore damage to the watermark, like in fine tuning, compared\nto the other two settings because they also modify a larger\nnumber of model weights during the learning process. There\nis also ab problem with Tsception fromscratch task as the true\nand null embedding accuricies dropped to about 60% which is\nbelow the expected value, but the EEG task was also affected\nby 5% drop."}, {"title": "C. Piracy Resistance", "content": "The table III provides the result for adversary trying to embed\nnew malisious watermark to test whether this watermarking\nscheme can withstand ownership piracy attacks, where an\nattacker tries to add their own watermark into the model.\nIt was already demonstrated that attackers cannot remove\nexisting watermarks from models using fine tuning or pruning\ntechniques; this is protection against corruption attacks. This\nalso protects the model from the second type of piracy attack,\nknown as takover, because that attack also involves the attacker\nremoving or retraining the owner's watermark.\nTherefore, the focus here is on the third type of attack, simply\npiracy, where the attacker embeds their own watermark into the\nmodel alongside the owner's watermark. Consider an attacker\nA who uses the approach of the watermarking scheme to\nembed their own watermark, labeled \\(W_A\\), into the model. The\nfindings in table II indicate that it is difficult to embed a new\nwatermark on top of an existing one. The table compares the\nnormal classification accuracy and watermark accuracies of a\nmodel after the attacker attempts to embed a new watermark.\nAfter the embedding process, the accuracy of primary task\nand null embedding was affected with average of about 10%\nin EEGNet and CCNN models which is high and critical\ndrop. For the Tsception, it was about 5% which is not enough\nto indicate success. But, the original watermark W is still\nexixsing in the model and the owner can provide a model\nwith W only without \\(W_A\\) embedded and that can be a strong\nevidence for his ownership [28]. The attacker will have a\nmodel with the two watermarks Wand \\(W_A\\) embedded, so\nthis can provide reasonable claim for legitimate owner, as it\nis impossible that the owner removed \\(W_A\\) from his model."}, {"title": "VII. Discussion", "content": "The study begins by verifying that the proposed wonder filter-\nbased watermark meets three fundamental requirements for\neffective watermarking: low distortion, high reliability, and no\nfalse positives. These requirements are critical prerequisites\nfor enabling advanced functionalities such as authentication,\npersistence, and piracy resistance. If a watermark compromises\nor affects model accuracy or exhibits inconsistent detection, it\ncan not support these higher-level properties and requirements\nfor successful watermark embedding."}, {"title": "A. Basic Requirements", "content": "To evaluate these requirements, all models were trained from\nscratch for each of three distinct tasks (in addition to pretrain\nstrategy and non watermarked model). The results of tables I,\nII has insights about these initial requirements as follows:\nLow Distortion: The watermark's impact on model pri-\nmary task (EEG accuracy) was very minimal across all\ntasks and models. As shown in Table I, classification\naccuracy for watermarked models decreased by about\nonly 5% compared to their watermark-free counterparts.\nThis negligible drop in the accuracy confirms that the\nwatermark does not interfere with the model's primary\nfunctionality, and ensuring its practicality for real-world\ndeployment and dependency.\nHigh Reliability: The watermarks accuracies in table I\ndemonstrated near-perfect models that are reliabile in\ndetection of the primary task and in the embedded wa-\ntermark. For all tasks, watermark accuracy was measured"}, {"title": "B. Advanced Requirements", "content": "Now the performance of the watermark scheme is assessed\nagainst the advanced criteria outlined in Section II. Prior\nresearch has developed watermarks that satisfy these require-\nments for neural networks that deal with images, but the EEG-\nbased models does not satisfy them, especially authentication"}, {"title": "C. Piracy resistance", "content": "The table III provides the result for adversary trying to embed\nnew malisious watermark to test whether this watermarking\nscheme can withstand ownership piracy attacks, where an\nattacker tries to add their own watermark into the model.\nIt was already demonstrated that attackers cannot remove\nexisting watermarks from models using fine tuning or pruning\ntechniques; this is protection against corruption attacks. This\nalso protects the model from the second type of piracy attack,\nknown as takover, because that attack also involves the attacker\nremoving or retraining the owner's watermark.\nTherefore, the focus here is on the third type of attack, simply\npiracy, where the attacker embeds their own watermark into the\nmodel alongside the owner's watermark. Consider an attacker\nA who uses the approach of the watermarking scheme to\nembed their own watermark, labeled \\(W_A\\), into the model. The\nfindings in table II indicate that it is difficult to embed a new\nwatermark on top of an existing one. The table compares the\nnormal classification accuracy and watermark accuracies of a\nmodel after the attacker attempts to embed a new watermark.\nAfter the embedding process, the accuracy of primary task\nand null embedding was affected with average of about 10%\nin EEGNet and CCNN models which is high and critical\ndrop. For the Tsception, it was about 5% which is not enough\nto indicate success. But, the original watermark W is still\nexixsing in the model and the owner can provide a model\nwith W only without \\(W_A\\) embedded and that can be a strong\nevidence for his ownership [28]. The attacker will have a\nmodel with the two watermarks Wand \\(W_A\\) embedded, so\nthis can provide reasonable claim for legitimate owner, as it\nis impossible that the owner removed \\(W_A\\) from his model.\nThese results and analysis show that it is very difficult to\nembed a new watermark into a model that has already been\nwatermarked.\nEven after attempting to embed the second watermark for more\nthan 100 epochs, the attacker makes no progress. Training\nfor the new watermark \\(W_A\\) completely fails, and both the\nnormal classification accuracy and the owner's watermark\nremain completely unaffected. This confirms our claim that\nwatermark training can only be successfully completed during\nmodel training time, and that our watermark system effectively\nresists ownership piracy attacks."}, {"title": "VIII. Conclusion", "content": "This study addressed the critical challenge of protecting EEG-\nbased neural networks, which are vital for medical diagno-\nsis and brain-computer interfaces. Traditional watermarking\nmethods, reliant on abstract triggers, often lack robust authen-\ntication and fail to meet the unique demands of EEG mod-\nels. The proposed wonder filter-based framework, integrated\nwith cryptographic techniques, successfully embeds a secure,\ntamper-proof watermark while preserving model functionality.\nKey findings demonstrate minimal performance degradation,\nresilience against adversarial attacks, and unparalleled au-\nthentication, fulfilling the objectives of persistence, piracy\nresistance, and ownership verification.\nKey Findings: The wonder filter-based watermarking method\nachieved three foundational goals:\nMinimal Distortion: Embedding the watermark caused\nless than a 5% drop in EEG classification accuracy across\nmodels (CCNN, EEGNet, TSception), ensuring practical\nutility in real-world applications like emotion recognition\nand neurological disorder detection.\nRobust Persistence: The watermark resisted removal\nthrough aggressive fine-tuning (100 epochs) and neuron\npruning (up to 50%). Notably, the primary task accuracy\ndegraded faster than watermark detection, rendering ad-\nversarial attempts to remove the mark counterproductive.\nPiracy Resistance: Attempts to embed secondary wa-\ntermarks caused significant accuracy losses (> 10% in\nEEGNet and CCNN), deterring unauthorized claims of\nownership. Cryptographic hashing, tied to the owner's\nprivate key, reduced brute-force attack success probabil-\nities, making such attacks computationally infeasible."}, {"title": "VIII. Conclusion", "content": "The study aimed to adapt wonder filters for EEG models and\naddress three advanced requirements: authentication, persis-\ntence, and piracy resistance. Cryptographic hashing ensured\nauthentication by linking the watermark to the owner's unique\nsignature, eliminating reliance on easily replicated abstract\ntriggers. Persistence was validated through rigorous testing\nagainst fine-tuning and pruning, common post-deployment\nmodifications. Piracy resistance was demonstrated by the\ninability to embed competing watermarks without degrading\nmodel functionality, fulfilling the objective of securing exclu-\nsive ownership.\nThis work makes four key contributions to the field of neural\nnetwork watermarking:\nEEG-Specific Adaptation: The wonder filter, previously\napplied to image-based models, was successfully tailored\nto EEG architectures, addressing the unique challenges\nof neurophysiological data, such as low signal-to-noise\nratios and temporal complexity.\nCryptographic Authentication: By integrating digital sig-\nnatures and collision-resistant hashing, the framework\nprovides irrefutable proof of ownership, overcoming the\nauthentication weaknesses of prior EEG watermarking\nmethods.\nAttack Resilience: The watermark's robustness against\nfine-tuning, pruning, and adversarial overwriting sets a\nnew benchmark for securing EEG models in high-stakes\nenvironments.\nPractical Security: The method balances security with\nusability, ensuring minimal impact on model perfor-\nmance-a critical requirement for medical and biometric\napplications where accuracy is paramount.\nThis framework offers a reliable solution for safeguarding\nEEG-based AI systems, which are increasingly deployed in\nhealthcare, neuroscience, and biometrics. By preventing unau-\nthorized use and tampering, it encourages innovation and col-\nlaboration while protecting investments in resource-intensive\nmodel development. For instance, hospitals using watermarked\nEEG models for seizure detection can confidently share tools\nwithout risking intellectual property theft. Similarly, devel-\nopers of brain-computer interfaces can license their models\nsecurely, knowing ownership claims are cryptographically\nverifiable.\nWhile the method excels in current tests, extending it to\nlarger, more complex EEG architectures and diverse ap-\nplications (e.g., Alzheimer's detection, sleep monitoring)\nwill further validate its versatility. Investigating hybrid ap-\nproaches-combining wonder filters with encryption or se-\ncure hardware-could enhance protection against emerging\nattack vectors. Additionally, real-world deployment studies are\nneeded to assess long-term robustness in dynamic clinical\nenvironments.\nIn summary, this study advances the protection of EEG-based\nneural networks by introducing a watermarking framework\nthat combines cryptographic security with practical resilience.\nBy addressing the limitations of prior methods and aligning\nwith the unique demands of neurophysiological data, the work\nsupports the ethical and secure advancement of AI in sensitive,\nlife-critical domains."}]}