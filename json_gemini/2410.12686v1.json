{"title": "Automatic Mapping of Anatomical Landmarks from Free-Text Using Large Language Models: Insights from Llama-2", "authors": ["Mohamad Abdi", "Gerardo Hemosillo Valadez", "Halid Ziya Yerebakan"], "abstract": "Anatomical landmarks are vital in medical imaging for navigation and anomaly detection. Modern large language models (LLMs), like Llama-2, offer promise for automating the mapping of these landmarks in free-text radiology reports to corresponding positions in image data. Recent studies propose LLMs may develop coherent representations of generative processes. Motivated by these insights, we investigated whether LLMs accurately represent the spatial positions of anatomical landmarks. Through experiments with Llama-2 models, we found that they can linearly represent anatomical landmarks in space with considerable robustness to different prompts. These results underscore the potential of LLMs to enhance the efficiency and accuracy of medical imaging workflows.", "sections": [{"title": "1 Introduction", "content": "An anatomical landmark is a biologically meaningful point on an organism that aids in image navigation and serves as critical evidence for anomaly diagnosis within the medical imaging domain (Zhan et al., 2016, 2008). In radiology reporting, these landmarks are pivotal for precisely describing specific points within the body, acting as reference points for locating abnormalities or guiding interventions. Radiologists routinely interpret free-text reports and map the described anomalies to their corresponding positions in the image data. The advent of modern large language models (LLMs) offers promising potential to automate this task, given their advanced capabilities in interpreting and synthesizing radiology reports (Bhayana, 2024; Bosbach et al., 2024; Yan et al., 2022; Cai et al., 2021).\nDespite remarkable proficiency of LLMs in handling complex tasks (Kim et al., 2024; Guan et al., 2023; Ouyang et al., 2022), these models were traditionally believed to learn only large-scale correlations by predicting the next token in a sequence, without understanding the underlying generative process (Bender and Koller, 2020; Bisk et al., 2020). However, emerging research suggests an alternative hypothesis: these models may indeed develop coherent and interpretable representations of the generative processes they are exposed to (Li et al., 2022; Nanda et al., 2023; Li et al., 2021; Patel and Pavlick, 2021; Abdou et al., 2021). This insight opens new avenues for leveraging LLMs in automating the interpretation and mapping tasks in radiology, thereby enhancing the efficiency and accuracy of medical imaging workflows.\nMotivated by these remarkable capabilities and the belief in LLMs' ability to learn coherent representations, we set out to explore the following question: \"Can LLMs' internal neural activations accurately represent the spatial positions of anatomical landmarks?\" We conducted experiments to linearly probe the internal neural activations of Llama-2 (Touvron et al., 2023) models to predict anatomical landmark positions. Our findings reveal:\n1. Llama-2 models can linearly represent the anatomical landmarks in space.\n2. These representations demonstrate considerable robustness to different prompts.\n3. Llama-2 models may linearly represent the size of anatomical landmarks."}, {"title": "2 Related Works", "content": null}, {"title": "2.1 Representation Engineering", "content": "Several studies have explored whether Large Language Models (LLMs) can offer interpretable representations of learned generative processes. This line of investigation is based on representation engineering, which suggests that high-level information can be represented through neural activities, often using the most representative or final token (Zou et al., 2023). Leveraging this framework, Marks et al. demonstrated that that language models can linearly represent the truth or falsehood of factual statements, with these representations exhibiting directionality (Marks and Tegmark, 2023). Similarly, Gurnee et al. employed this methodology to reveal that the family of Llama-2 models can linearly represent both space and time, unveiling the presence of specialized neurons within Llama-2 models that activate as a function of spatial and temporal dimensions (Gurnee and Tegmark, 2023). Others have demonstrated that generative pre-training language models can effectively represent the game state of chess in a linear fashion (Toshniwal et al., 2022; Nanda et al., 2023)."}, {"title": "2.2 LLMs as world models", "content": "Gurnee et al. proposed that Llama-2 models could be considered world models. To support this, they created three datasets of place names at different spatial scales: globally, within the United States, and within New York City. They used these place names as inputs to the Llama-2 models and applied a linear probe to the hidden state activations to predict the spatial coordinates of the places. By comparing the distance metrics from the linear probe with those from a nonlinear probe, they showed that Llama-2 models can linearly represent spatial features. Additionally, using a block holdout generalization test, they demonstrated that these linear features are directional (Gurnee and Tegmark, 2023).\nBuilding on these findings, our study investigates whether the Llama-2 model can decode spatial information at a smaller scale, specifically focusing on its ability to represent the spatial positions of anatomical landmarks."}, {"title": "3 Methods", "content": null}, {"title": "3.1 Datasets", "content": "To construct our dataset, we included n = 117 anatomical landmark names and their corresponding spatial coordinates. We utilized the Total Segmentator model (Wasserthal et al., 2023), an open-source segmentation toolbox 1, on a human atlas to generate segmentation masks for each landmark. Each segmentation mask was then used to compute two types of spatial coordinates for each anatomical landmark in a normalized coordinate system:"}, {"title": "3.2 Llama-2 Encoding", "content": "We used Llama 2.0 models (Touvron et al., 2023), a series of pre-trained and fine-tuned auto-regressive transformers with scales ranging from 7 billion to 70 billion parameters. A commercial license was acquired prior to using the Llama 2.0 models. Each anatomical landmark name was processed through the model, sometimes with a short prompt prepended. We saved the activations of the hidden state on the last token (excluding the end-of-sequence token) for each layer. For n anatomical landmarks, this resulted in a collection of activation vectors $z \\in \\mathbb{R}^m$, with m being the length of the hidden states, yielding a dataset $x \\in \\mathbb{R}^{n \\times m}$. These datasets were computed for each layer of the Llama 2.0 model and used in the probing experiments described in the following section."}, {"title": "3.3 Probing", "content": "We employed a probing strategy (Belinkov, 2022; Zou et al., 2023) to investigate the spatial linear representation hypothesis. Specifically, we fit a ridge linear regression model to the activation dataset to predict the positions of the anatomical landmarks, either as single-point or bounding-box targets. Assuming $y \\in \\mathbb{R}^3$ as the target values and the activation dataset $x \\in \\mathbb{R}^{n \\times m}$, we sought to solve the following equation:\n$\\theta = \\underset{\\theta}{\\operatorname{argmin}}|| f_\\theta(x) - y||^2 + \\lambda R(x)$ (1)\nIn Equation 1, $f$, $R$, and $\\theta$ denote the regression model, the regularization operator, and the weights of the regression model respectively. For the ridge regression, the $l_2$ norm was used for regularization.\nOur analysis was based on the idea that high predictive performance on out-of-sample data indicates that the base model has spatial information that is linearly decodable in its representations (Gurnee and Tegmark, 2023). The linear regression model was implemented using the scikit-learn package."}, {"title": "3.4 Experiments and evaluations", "content": "Prompting: In their study, Gurnee et al. (Gurnee and Tegmark, 2023) found little to no effect on spatial and temporal representations when prompting the Llama-2 models. Given the different spatial scale of anatomical landmarks compared to Gurnee et al.'s dataset, we employed the same prompting strategy to investigate if a similar trend could be observed. To this end, activation datasets were generated using a random prompt and a context-inducing prompt that asked for the position of the anatomical landmark. Separate linear and nonlinear probes were fitted to the random prompt, context-inducing prompt, and an unprompted training dataset. The fitted models were then applied to the test set to predict the positions of the corresponding anatomical landmarks. We used the average Euclidean distance between the predicted and target coordinates as the measure of performance.\nSpatial representation: We further investigated whether the size of the anatomical landmarks can be decoded from the Llama-2 representations, in addition to their spatial position. To this end, we fitted linear and nonlinear regressions to the activation datasets using the bounding-box coordinates as the target values. The predicted bounding-box coordinates on the test samples were compared to the target values using the DICE score defined in Equation 2, where P and T are the volumes covered by the predicted and target bounding-boxes, respectively, and $\\cap$ is the intersection operator. The DICE score measures the similarity or overlap between two sets.\n$DICE = \\frac{2|P \\cap T|}{|P| + |T|}$ (2)\nBaseline: We established a baseline for comparison of our results. For each anatomical landmark in the test set, we utilized a lexical similarity measure to identify the most similar name within the same set. The (single-point or bounding-box) coordinates of this most similar name were then used as an estimate for the coordinates of the query landmark. Specifically, we employed the Jaccard index, as defined in Equation 3, for two sets Q and P, to measure lexical similarity.\n$J = \\frac{|Q \\cap T|}{|Q \\cup T|}$ (3)"}, {"title": "4 Results", "content": "Figure 1 illustrates the mean Euclidean distance between the predicted and target positions of anatomical landmarks within the test set as a function of model depth. Deeper layers of the Llama-2 models yield more accurate spatial representations, with accuracy approaching a plateau at approximately 20% depth across all Llama-2 model sizes. We did not observe a significant advantage in prompting the Llama-2 models. Furthermore, the more complex nonlinear regression did not produce significantly more accurate predictions compared to linear regression. These findings suggest that the spatial positions of anatomical landmarks can be effectively represented linearly using the Llama-2 models\nTable 1 presents the Euclidean distances (mean + standard deviation) at 20% depth of the Llama-2 model for the single-point test data. An increase in model size results in more accurate predictions, a trend consistent with findings from previous study (Gurnee and Tegmark, 2023; Hoffmann et al., 2022). Notably, the predictions from the Llama-2 models are significantly more accurate than the baseline.\nTable 1 also provides the Dice scores (mean \u00b1 standard deviation) at 20% depth of the Llama-2 model for the bounding-box test data. Similar trends were observed, with larger models yielding better predictions of both the size and position of the anatomical landmarks. However, the Dice scores from the linear probe are slightly better than those from the nonlinear probe. There is also a significant difference between the baseline and the Llama-2 models. Examples of the predicted bounding boxes (blue) and target bounding boxes (red) are visualized in the coronal view in Figure 2. These results suggest that the Llama-2 model may represent the spatial size of anatomical landmarks in addition to their position, although further ablation studies are needed to substantiate this finding."}, {"title": "5 Conclusion", "content": "Our study demonstrates the potential of modern large language models, particularly Llama-2, for representing the position of the anatomical landmarks from free-text input data. While a deeper understanding of the mechanisms behind these representations and their extent is needed, our findings hint at the potential of these models to alleviate workload in radiology workflows. Future research can delve into deeper into this specific use-case LLMs in radiology, utilizing a broader range of anatomical landmarks and LLMs tailored specifically for medical applications."}, {"title": "6 Limitations", "content": "One limitation of this methodology is the limited number of landmarks used in both training and testing. A broader set could offer stronger evidence of LLMs' spatial representation. Additionally, the method underutilizes LLMs' few-shot learning capabilities. An alternative could integrate known landmark coordinates into the prompt, providing context, and query for unknown landmark coordinates."}]}