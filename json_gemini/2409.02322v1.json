{"title": "TIMEDIT: GENERAL-PURPOSE DIFFUSION TRANSFORMERS FOR TIME SERIES FOUNDATION MODEL", "authors": ["Defu Cao", "Wen Ye", "Yizhou Zhang", "Yan Liu"], "abstract": "With recent advances in building foundation models for texts and video data, there is a surge of interest in foundation models for time series. A family of models have been developed, utilizing a temporal auto-regressive generative Transformer architecture, whose effectiveness has been proven in Large Language Models. While the empirical results are promising, almost all existing time series foundation models have only been tested on well-curated \u201cbenchmark\u201d datasets very similar to texts. However, real-world time series exhibit unique challenges, such as variable channel sizes across domains, missing values, and varying signal sampling intervals due to the multi-resolution nature of real-world data. Additionally, the uni-directional nature of temporally auto-regressive decoding limits the incorporation of domain knowledge, such as physical laws expressed as partial differential equations (PDEs). To address these challenges, we introduce the Time Diffusion Transformer (TimeDiT), a general foundation model for time series that employs a denoising diffusion paradigm instead of temporal auto-regressive generation. TimeDiT leverages the Transformer architecture to capture temporal dependencies and employs diffusion processes to generate high-quality candidate samples without imposing stringent assumptions on the target distribution via novel masking schemes and a channel alignment strategy. Furthermore, we propose a finetuning-free model editing strategy that allows the seamless integration of external knowledge during the sampling process without updating any model parameters. Extensive experiments conducted on a varity of tasks such as forecasting, imputation, and anomaly detection, demonstrate the effectiveness of TimeDiT.", "sections": [{"title": "Introduction", "content": "Time series analysis is pivotal in a diverse set of AI applications, such as natural science [Cuomo et al., 2022, Wang et al., 2020], social science [Zhang et al., 2022, Sharma et al., 2021], sustainability [Krenn and Buffoni, 2023],health [Kaushik et al., 2020, Kamra et al., 2021], etc. These applications root in diverse domains [Li et al., 2018, Bi et al., 2023, Cao et al., 2023c, Zhang et al., 2021, Ye and Gao, 2022], leading to time series with various distributions [Wang et al., 2023] and a divers set of analysis tasks, such as forecasting [Nie et al., 2022, Jia et al., 2024], imputation [Tashiro et al., 2021], anomaly detection [Tuli et al., 2022], etc. Even though considerable progress has been made in developing specialized models optimized for specific scenarios and individual tasks, an open question remains: Can a single time series foundation model excel across domains? Recent initiatives have explored the possibility of universal time series models on zero-shot setting [Ansari et al., 2024, Liu et al., 2024, Gruver et al., 2024, Cao et al., 2023b], drawing inspiration from large pre-trained language models in natural language processing(NLP) and computer vision(CV), such as GPT[Radford et al., 2018], CLIP [Radford et al., 2021], which are known for their robust transfer learning capabilities. However, due to the fundamentally different semantics between text/images and time series data, the unique challenges of achieving a truly flexible and general-purpose time series model remain an open problem."}, {"title": "Related Work", "content": "In the past decades, researchers have excelled in designing sophisticated models for specific time series analysis tasks [Zhang et al., 2024b, Fan et al., 2024, Cao et al., 2020, 2022]. However, in recent years, the emergence of large language models has inspired the development of general-purpose time series models [Zerveas et al., 2021, Zhang et al., 2024a, Garza and Mergenthaler-Canseco, 2023] and the field of time series has seen tremendous exploration efforts towards foundation models. [Gruver et al., 2024] simply encoded time series as strings while [Jin et al., 2023] converted time series into language representations by alignment. [Cao et al., 2023b] and [Pan et al., 2024] further incorporated decomposition technique and prompt design and generalizes to unseen data and multimodal scenarios. [Rasul et al., 2023] worked towards foundation model from a probabilistic perspective but only considered univariate time series only which rarely appears in real-life. Additionally, many studies started to follow a two-stage training paradigm of pretraining and finetuning [Chang et al., 2023, Dong et al., 2024, Nie et al., 2022]. However, these works mainly focused on the forecasting task only [Woo et al., 2024a, Das et al., 2023]. [Zhou et al., 2023] first adapted GPT2 as a general-purpose time series analysis model and extended it to various time series tasks. [Talukder et al., 2024] leveraged VQVAE as a tokenizer for transformer to handle time series tasks and [Ansari et al., 2024] employed a scaling and quantization technique to embed time series. For more detailed literatures of the general-purpose time series model, please refer to recent surveys and position paper [Liang et al., 2024, Jin et al., 2024, Jiang et al., 2024] Despite the growing interest of diffusion models in various scenarios [Peebles and Xie, 2022, Li et al., 2022a, Lu et al., 2024, Sui et al., 2024a,b], the use of diffusions in time series analysis is less explored compared to pre-trained language models and transformers. Most existing studies also focused solely on forecasting and the choice of backbone model also varies among VAE[Li et al., 2022b], RNN[Rasul et al., 2021], and transformer. CSDI [Tashiro et al., 2021] utilized diffusion model for time series imputation. [Yuan and Qiao, 2024] incorporated decomposition into diffusion model to improve interoperability. Although [Kollovieh et al., 2023] build a diffusion pipeline for multiple tasks with refinement, they still train different models for each task. To the best of our knowledge, there has been no exploration of leveraging unified diffusion models for a comprehensive set of time series tasks yet. Please refer to [Yang et al., 2024] for a comprehensive literature review on diffusion models for time series analysis."}, {"title": "Preliminaries", "content": "In recent years, diffusion models have emerged as a promising approach in generative modeling. A diffusion process is a Markov chain that incrementally adds Gaussian noise to data over a sequence of steps, effectively destroying the data structure in forward process and destroying the data structure in backward structure.\nThe forward process adds noise to the data x0 over a series of timesteps t according to a variance schedule \u00dft, resulting in a set of noisy intermediate variables x1, x2,...,xT. Each subsequent xt is derived from the previous step by applying Gaussian noise:\n$q(x_t | x_{t-1}) = \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI)$", "Diffusion Model": ""}, {"title": "Methodology", "content": "In this section, we present our main contributions: the proposed foundation model, TimeDiT, a diffusion model with transformer backbone designed for multiple time series tasks, along with uniform masking strategies and incorporation of physics knowledge and textual information as an extension. We first outline the uniformed problem setting for multiple down-stream tasks and offer an in-depth examination of the model architecture. Subsequently, we delve into the training pipeline with mask strategies, which help to build the training scheme in self-supervised learning for time series. Next, we present how to incorporate external information to improve the model's performance during both the training and inference stages. By doing so, TimeDiT can generate samples that better conform to real-world", "Problem Definition": "We denote a multivariate time series as X = {xi,j} \u2208 RK\u00d7L, where K is the number of features and L is the length of the time series. Each individual entry xi,j represents the j-th feature at time step l, for i \u2208 {1, ..., K} and j\u2208 {1, ..., L}. We define an observation mask Mobs = {mi,j} \u2208 {0,1}K\u00d7L, where mi,j = 0 if xi,j is missing, and mi,j = 1 if xi,j is observed. Let xobs \u2208 Xobs denote the observed subsequence; xar denote the target subsequence of xobs which could be forecast target or imputation target or the whole sequence depending on the task. Let xoon denote the unmasked partial observations in xobs which acts like conditions for the masked area xtar. Let us use all subscripts of x to denote diffusion timestamp, and a subscript of 0 means no noise has been applied to the original data. Formally, the goal of our task is to approximate the true conditional data distribution given the conditional information qx (xa | xon) with a model distribution pe(xtar | xon), which can be calculated by a diffusion model with conditional information:\n$p_{\\theta} (x_{\\tau}^{tar} | x_0^{tar}) := p(x_{\\tau}^{tar} | x_0^{tar}) \\Pi_{t=1}^{\\tau} p_{\\theta} (x_{t-1}^{tar} | x_t^{tar}, x_t^{on}), x_\\tau^{tar} \\sim \\mathcal{N}(0, I)$, where\n$p_{\\theta} (x_{t-1}^{tar} | x_t^{tar}, x_t^{on}) := \\mathcal{N} (x_{t-1}^{tar}; \\mu_{\\theta} (x_t^{tar}, t | x_t^{tar}, x_t^{on}), \\sigma_{\\theta} (x_t^{tar}, t | x_t^{tar}, x_t^{on}) I)$.\nThe mask mechanism M plays a critical role in identifying the positions of xoon and xtar. By leveraging these positional differences, our model adeptly adapts to various downstream tasks, including forecasting, imputation, anomaly detection, etc, within a unified framework.", "TimeSeries Diffusion Transformer": "Figure 1 shows the overall framework of TimeDiT. We first establish the Mobs and xobs based on the given input from different distributions with multivariate sequences, missing value and multi-resolution by injecting placeholders to standardize the input shape across different time series, facilitating more efficient and consistent processing. Then, the unified time series mask unit adapts to diverse time series scenarios and builds the xoon, M and xtar, with shape RB\u00d7L\u00d7K, to help TimeDiT learn robust representations in a self-supervised manner by reconstructing the original sequence through denoising xtar. After that, the embedding layer directly treats xoon and xtar as without any patching, as the diffusion process is designed to handle multivariate input and operate in a continuous token space. By preserving the integrity of the input time series, TimeDiT ensures that the model can effectively capture and utilize the rich information contained within the data. The TimeDiT block's attention mechanism is designed to autonomously learn cross-channel and temporal correlations through end-to-end training.\nWe introduce placeholders within the input sequences to standardize the input shape across different time series, accounting for varying channel numbers K and sequence length L. Specifically, we define the maximum channel number Kmax such that any input with channel k < Kmax is padded to have Kmax channels while any input with more than Kmax channels are segmented into \u2308k/Kmax\u2309 blocks of inputs where each block has Kmax channels and undergoes independent processing. This segmentation allows our model to manage high-dimensional data efficiently, reducing computational overhead and maintaining relative positional integrity of the data and consistency across inputs. Additionally, for any input with sequence length less than the designated maximum length Lmax, we pad the sequence in the front to achieve the desired length. This standardization is essential for establishing a uniform input structure that enhances processing efficiency and consistency.\nWe propose a unified time series mask mechanism that includes a variety of masks that seamlessly integrates with the model during self-supervised task agnostic pre-training and task specific fine-tuning to cater to diverse time series scenarios. The time series mask unit generate four types of masks: reconstruction mask, stride mask, block mask, and random mask. Firstly, the task-agnostic pre-training aims to improve the overall time series representation by encouraging the model to learn robust and generalizable features from the input data. Secondly, the task-specific training is designed specifically for the most common downstream tasks, including forecasting and imputation, enabling the model to adapt to the unique requirements of each task.\nAs shown in Figure 1 right top, given x \u2208 RK\u00d7L, the random mask MR can be generated by:\n$M^R(x,r) = \\begin{cases} 1 & z_{ij} > r, z \\in \\mathbb{R}^{K \\times L}, z \\sim Uniform(0, 1) \\\\ 0 & otherwise, \\end{cases}$", "Standardize Pipeline": "", "TimeSeries Mask Unit": ""}, {"title": "Methodology", "content": "We try to find the optimal q(y|x) through Lagrange multipliers. The constraint of the above objective function is that\nq(y|x) is a valid \u222b, q(y|x)dy = 1. Thus, the Lagrangian is:\n$L(q(y|x), \\lambda) = \\int_y q(y|x)[K(y) + a log p(y|x) - a log q(y|x)]dy - \\lambda(\\int_y q(y|x)dy - 1)$\n$=\\int_y q(y|x)[K(y) + a log p(y|x) - a log q(y|x) - \\lambda]dy + \\lambda$\nWe define f(q(y|x), y, x) = q(y|x)[K(y) + a log p(y|x) \u2013 a log q(y|x) \u2013 \u03bb] + dh(y)], where h(y) can be the density\nfunction of any fixed distribution defined on the support set of y. Therefore, L(q(y|x), 1) = \u222by f(q(y|x), y, 1)dy.\nAccording to Euler-Lagrange equation, when the above Lagrangian achieve extreme point, we have:\n$\\frac{df}{\\partial q}= K(y) + a log p(y|x) - a log q(y|x) - \\lambda - a = 0$\nThus, we have:\na log q(y|x) = K(y) + a log p(y|x) \u2013 log q(y|x) \u2013 \u03bb - \u03b1\nq(y|x) = exp(1/a (K(y) + log p(y|x) - -1))\nMeanwhile, since \u222by q(y|x)dy = 1, we have:\n$q(x1 = = p(12))\\exp((-1)\nThus, we have exp()=exp(K(y) -logp(y\\I_k\\ = Z.k\\exp(A(1\\ =exp(1 + all where A.kw are perameters"}, {"title": "Conclusion", "content": "In this paper, we introduced TimeDiT, a pioneering approach to creating a versatile and robust foundation model for various time series tasks under practical scenarios. By integrating transformer architecture with diffusion model, TimeDiT effectively captures temporal dependencies and addresses real world challenges unique to time series regarding multi-resolution and missing values as well as incorporating external knowledge. Our innovative masking strategies allow for a consistent training framework adaptable to diverse tasks such as forecasting, imputation, and anomaly detection and synthetic data generation. Extensive experiments demonstrated the strong performance of TimeDiT on both practical scenarios and standard benchmarks. However, we recognize some limitations. We primarily explored common sequence lengths and did not assess TimeDiT's performance on very long sequences. While we have introduced randomness in prediction length and feature numbers up to a maximum, we aim to develop more scalable solutions for highly variable multivariate time series. Additionally, our understanding of how different types of external information contribute to performance is still developing. For future work, we envision several key directions: enhancing scalability to improve TimeDiT's ability to handle practical time series with varying multivariate numbers; developing techniques for seamless multi-modal integration, allowing TimeDiT to leverage diverse data sources for improved performance across different tasks; and extending TimeDiT's capabilities to effectively process and analyze very long time series sequences, addressing a critical need in many real-world applications."}]}