{"title": "AI and the Future of Digital Public Squares", "authors": ["Beth Goldberg", "Diana Acosta-Navas", "Michiel Bakker", "Ian Beacock", "Matt Botvinick", "Prateek Buch", "Ren\u00e9e DiResta", "Nandika Donthi", "Nathanael Fast", "Ravi Iyer", "Zaria Jalan", "Andrew Konya", "Grace Kwak Danciu", "H\u00e9l\u00e8ne Landemore", "Alice Marwick", "Carl Miller", "Aviv Ovadya", "Emily Saltz", "Lisa Schirch", "Dalit Shalom", "Divya Siddarth", "Felix Sieker", "Christopher Small", "Jonathan Stray", "Audrey Tang", "Michael Henry Tessler", "Amy Zhang"], "abstract": "Two substantial technological advances have reshaped the public square in recent decades: first with the advent of the internet and second with the recent introduction of large language models (LLMs). LLMs offer opportunities for a paradigm shift towards more decentralized, participatory online spaces that can be used to facilitate deliberative dialogues at scale, but also create risks of exacerbating societal schisms. Here, we explore four applications of LLMs to improve digital public squares: collective dialogue systems, bridging systems, community moderation, and proof-of-humanity systems. Building on the input from over 70 civil society experts and technologists, we argue that LLMs both afford promising opportunities to shift the paradigm for conversations at scale and pose distinct risks for digital public squares. We lay out an agenda for future research and investments in AI that will strengthen digital public squares and safeguard against potential misuses of AI.", "sections": [{"title": "1. Introduction", "content": "These co-authors, alongside 50 other leading thinkers and technologists, convened on April 3, 2024 in New York City to discuss the potential for recent innovations in AI capabilities to transform the public square and democratic process. This paper advances key insights from that convening alongside applied research on improving digital public squares globally. The convening and this paper are structured around four areas in which AI-enabled technologies have demonstrated potential to significantly disrupt and potentially improve\u2014conversations at scale:\n\n1.  Collective dialogue systems\n2.  Bridging systems\n3.  Community moderation\n4.  Proof-of-humanity systems"}, {"title": "1.1 Origins of the Digital Public Square", "content": "A \u201cpublic square\u201d traditionally refers to an open, communal space where people gather for various social, political, and cultural activities. Public squares are a focal point globally for community interaction and expression, facilitating everything from casual socializing to organized events where people can exchange both ideas and goods. The term \u201cpublic square\u201d has expanded beyond physical gathering points to include the whole set of spaces\u2014physical and online\u2014that fulfill these roles in modern society.\n\nJ\u00fcrgen Habermas wrote about the \u201cpublic sphere\u201d as a two-track system comprising both a formal and an informal track. The metaphorical \u201cpublic square\u201d is really the informal track of the public sphere, the place where \u201cdeliberation in the wild\u201d\u2014unconstrained communication between groups and individuals takes place in a way that ends up shaping, constraining, and ideally setting the agenda for the more formal track of courts, parliaments, senates, and so on, that govern functioning democracies (Landemore 2022b).\n\nThe concept of the internet as a public square traces its origins to the early visions of digital communication theorists who compared the burgeoning network to traditional town squares. The 1994 book The Virtual Community by Howard Rheingold envisioned the internet as a new frontier for public dialogue and community formation (Rheingold 1994). Legal scholars like David R. Johnson and David Post, in their seminal article Law and Borders\u2014The Rise of Law in Cyberspace, explored the potential of the internet to transcend traditional governmental boundaries, highlighting its capacity to foster a more participatory democracy by enabling global conversations and decentralized governance (D. Johnson and Post 1996). While the metaphor continues to evolve, the throughline is consistent; the internet serves an unprecedented role facilitating public debate, civic engagement, and social movements (Bohman 2000).\n\nBy the 2010s, internet studies scholars like Ethan Zuckerman illuminated how the internet was democratizing both the production and sharing of information, enabling global participation in public discourse and expanded access to more diverse voices (Zuckerman 2013). Danielle Allen and Archon Fung expanded on this, noting that the internet's unique communication forms could \"enhance inclusion, political equality, public deliberation, and civic engagement\" due to its capacity for many-to-many interactions, structured and open-ended communication, and lower barriers to the production and circulation of information (Fung and Shkabatur 2015); (Kahne, Middaugh, and Allen 2015). The design of the internet of the 2010s laid foundations for the kinds of democratic processes that function primarily outside formal political mechanisms."}, {"title": "1.2 Defining an Ideal Digital Public Square", "content": "By bolstering these informal mechanisms for democratic participation, the internet brought about some of the conditions of what H\u00e9l\u00e8ne Landemore (Landemore 2022b) defines as the ideal of an \"Open Democracy.\" It created open-ended channels for debate, such as Twitter, that improved access to agenda-setting power for ordinary citizens. In a systematic review of the evidence, greater digital media use was correlated with greater political knowledge, expression, and participation internationally \u2013 but also greater polarization (Lorenz-Spreen et al. 2023).\n\nBy this light, digital public squares have developed many of the ideal qualities of a democratic space that DuBois envisioned in the 1920s, where each individual can contribute uniquely to human knowledge and wisdom (Du Bois 2017). These online spaces also move us closer to Rawls's ideal of public reason, where citizens can justify their political decisions with reasons that fellow citizens, as free and equal individuals, can reasonably accept or reject within a democratic framework (Rawls 2005). The ideal of the public sphere as described by Jurgen Habermas, however, one of free deliberation and political influence through communicative action aimed at mutual understanding and consensus, remains to be fulfilled at scale in online spaces (Habermas 1991).\n\nA wide range of scholars have studied the role of technology in supporting a more ideal digital public square. In their book Plurality: The Future of Collaborative Technology and Democracy, Glen Weyl and Audrey Tang lay out the opportunity for digital platforms to enable real-time, widespread participation in governance, allowing citizens to engage directly in decision-making processes (Tang and Weyl 2024). By integrating advanced digital tools powered by AI into the democratic framework, Tang and Weyl propose a model whereby technology acts as a catalyst for creating more responsive, inclusive, and accountable democratic institutions. Digital platforms designed for the health of the public square can and have enabled large groups of people to listen to and better understand both each other and experts. By tapping into the collective \u201cwisdom of the crowd,\u201d these technologies serve in Tang and Weyl's model as enabling factors for empowering the digital public square as a space for meaningful and impactful participation (Tang and Weyl 2024).\n\nResearchers at New_Public developed a set of \"Civic Signals\u201d that characterize a flourishing digital public space (\"Civic Signals\u201d 2023). These four components include:\n\n\u2022 Welcoming requires a space to be accessible, to feel safe, attractive, and navigable.\n\n\u2022 Connecting requires a space to be conducive to friendly, cooperative interaction between diverse people.\n\n\u2022 Understanding requires a space to provide useful information about how the public square works.\n\n\u2022 Engaging in meaningful action, a key feature of a robust public square, requires a space to provide the public with incentives to participate."}, {"title": "1.3 The Unrealized Potential of the Digital Public Square", "content": "While the digital public square is an invaluable expansion of offline fora for discourse, there are many ways in which our online sphere has fallen short of the ideals above. At least three categories of the potential of today's digital public squares, undermining democratic participation in the process:\n\n\u2022 Access and Inclusion: The promise of a universally accessible public square remains more an ideal than a reality. Rural communities, the poor, minority language speakers and other marginalized groups do not have the same access to digital technologies. Additionally, online spaces often become venues for harassment, disproportionately affecting women and members of historically marginalized communities. This has led members of these groups to refrain at times from participating in public discourse (Matias, Simko, and Reddan 2020).\n\n\u2022 Privacy and Surveillance: Both state and non-state political actors use digital platforms to track and influence citizen behavior on an unprecedented scale, potentially using this data for political manipulation or suppression of dissent. Mass surveillance and privacy breaches undermine democratic freedoms, drive self-censorship, and subvert the function of digital public squares (Kaye 2019).\n\n\u2022 Distorted Information Ecosystems: Information is predominately accessed through privately owned channels and platforms that have competing incentives to present the information, with effects that can distort perceptions of reality:\n\nEngagement Optimization: Some digital algorithms maximize engagement and promote sensationalist and polarizing content. This can obscure facts and heighten emotions, driving increased societal division and polarization and lead users to perceive public opinion as more polarized than it is in reality (Bail 2022). When systems are optimized for engagement, they can become dominated by small groups of extreme users who are willing to engage more, crowding out the vast majority of more moderate participants (Gillespie 2018; Cunningham et al. 2024).\n\nEcho Chambers: People sort into homophilous groups and echo chambers on and offline, which can reinforce existing beliefs and limit exposure to the diverse viewpoints vital for a healthy democracy. Digital public squares that become echo chambers can amplify ideological segregation, complicating the public's capacity to engage in free and fair discourse (Guess et al. 2018).\n\nManipulative Propaganda: Political actors and other vested interests use digital platforms as arenas for targeted political advertising and manipulation. Modern information technology makes it easier than ever before to identify and exploit wedge issues, distorting public opinion. This manipulation can manifest differently in authoritarian regimes and open societies but is deeply concerning in both (Roozenbeek and van der Linden 2024).\n\nExtremist Movements: Extremists have long leveraged communications technologies to amplify violent ideologies. Digital public squares can become convenient for these actors to radicalize, recruit, and mobilize individuals, which undermines social cohesion, safety and democracy.\n\nThese distortions tend to paint public opinion as more polarized than it really is, amplifying extremes (Lees and Cikara 2021), and degrading trust between groups and between the public and civic institutions. These perceptions further contribute to making public spaces less welcoming and inclusive, and limit our ability to participate meaningfully in civic life (Settle 2018). Together with the rest of the access and inclusion issues, and the threats to privacy from surveillance, the digital public square can be seen as falling short of early techno-enthusiasts' optimistic ambitions.\n\nPosition on the Future of Digital Public Squares\n\nThis is an opportune moment to invest in improving the digital public square, reorienting it toward and hopefully moving it closer to the ideal. Alongside increased accessibility and adoption of digital technologies, advances in AI with large language models (LLMs) have opened up new possibilities for creating deliberative spaces and healthier public squares at scale. This paper will explore applications of new AI-enabled technologies for functions such as facilitating sensitive dialogues, moderating toxic speech, rewarding speech that bridges divides, and synthesizing outcomes of large-scale deliberations."}, {"title": "Each of these families of technology will be discussed in turn, including opportunities afforded by the application of LLMs, risks, and recommendations for civil society, policymakers, researchers and technologists. These sections address the following questions:", "content": "1.  Deliberation & Collective Dialogue Systems: How can we create more informative, inclusive, and scalable feedback loops between the public and decision makers?\n2.  Bridging Systems: How can we architect our sociotechnical systems to reward and elevate the ideas that bring us together?\n3.  Community-driven Moderation: How can we empower community leaders to better guide the norms of discourse to support healthy, inclusive online communities?\n4.  Proof of Humanity: With advances in AI making it increasingly difficult to tell humans from machines online, how do we balance the competing interests of privacy, free speech, and authenticity?"}, {"title": "1. Deliberation & Collective Dialogue Systems", "content": "Collective Dialogue Systems\u00b9 (CDS) have recently emerged as tools which sit somewhere between traditional surveys and focus groups, allowing for more of the rich and nuanced feedback of the latter, while being more inclusive, scalable, and amenable to quantitative analysis, like the former (Konya et al. 2023; Ovadya 2023).\n\nSuch systems scalably allow a) participants to express themselves in their own words, b) participants to engage in parallel such that everyone gets a \u201cfair hearing\u201d, c) iterative interaction by participants (participants can contribute after considering the contributions of others), and d) offer some mechanism for synthesizing and understanding the perspectives of the participant body (Ovadya 2023). Examples of such CDS include Polis, Remesh, Make.org, All Our Ideas, CrowdSmart and CitizenLab."}, {"title": "1.1 Current Applications and Challenges of Collective Dialogue Systems", "content": "Collective Dialogue Systems facilitate collective feedback gathering at a scale previously unimaginable. However, they still currently require a significant amount of human labor at every stage of the process. Just understanding enough about these systems to ethically and effectively set up, facilitate and moderate CDS conversations requires a significant amount of training. Gleaning insights at the end of the process is similarly laborious, given how mapping high-dimensional opinion spaces often requires data science skills to distill outcomes for decision makers and participants themselves (C. Small et al. 2021).\n\nThe following obstacles presently limit the adoption of CDS and deliberative technologies:\n\n\u2022 Deciphering meaning from data: While the sensemaking features built into these platforms can often surface valuable insights somewhat quickly, more in depth understanding of the full dimensionality of the emergent opinion landscape typically requires dozens of hours of labor per dialogue, a technical understanding and comfort with statistics, and the ability to write up the results clearly.\n\n\u2022 Education and understanding: Many people want to run collective deliberations, or are not opposed to doing so, but don't know where to start, what platforms to use, how to set them up, or how to inform and recruit participants. Current onboarding processes are time-intensive and have limited replicability.\n\n\u2022 Cost: Many of these tools are expensive to host and run. The primary cost of using these tools is rarely the technology itself, but rather the human resources - time and expertise - needed to consult with stakeholders, recruit and inform participants, conduct a CDS, interpret the results, and finally advocate to ensure that decision makers use the insights from the deliberation. Just hosting open source technology can also be prohibitively expensive for some organizations due to the costs of maintaining technical infrastructure, but is often a requirement due to data sovereignty regulations or concerns, which can prevent usage of overseas instances.\n\n\u2022 Institutional capacity and will: Such a complex, multi-stakeholder undertaking requires significant sustained institutional capacity in terms of staff, time, and political will. A number of factors can imperil an institution's capacity or will to execute a CDS and other participatory exercises, including but not limited to changes in political administration, staff turnover, low or declining public participation in the initiative, lack of political will or capacity to use the dialogue to inform action, or the perception that the CDS was always intended as simply an \u201cexperiment\u201d or standalone event. Given the high cost of CDSes - in terms of institutional capacity, political will, as well as financial cost - CDSes are too often one-off experiments (Ryan, Gambrell, and Noveck 2020).\n\n\u2022 Content Moderation: CDS must be safe spaces for the public to express themselves authentically, necessitating moderation of hateful or toxic rhetoric, which can discourage participation by some. For especially large conversations, it can also become necessary to remove statements that are too similar to each other, to avoid wasting participants' time, and prevent problems with vote sparsity. These tasks require significant human labor, and training to ensure high standards and prevent the censorship of valid topics for debate. Applying LLMs to reduce these human burdens has been discussed by platforms and researchers (T. Huang 2024; Willner and Chakrabarti 2024); the section below on Community-Driven Moderation explores the opportunities and risks of AI-enhanced moderation for CDS and digital public squares more broadly."}, {"title": "1.2 Opportunities for AI-enhanced Collective Dialogue Systems", "content": "The following opportunities explore how LLMs can address many of the obstacles described above for adopting and scaling CDS. These instructive visions describe how AI can augment peer-to-peer and collective level dialogues, which are gaps in the field of digital participation platforms as identified by Rossello et al (Rossello et al. 2024).\n\nTraining Facilitators\n\nFacilitation of both virtual CDS engagements and more traditional in-person deliberations and citizens' assemblies is a highly skilled task that requires significant training. While AI can be used to reduce the burden of many of these tasks, it will likely be quite some time before these tasks may be automated, especially at the interface to systems of formal power and decision making. There is immense value in designing systems that keep humans in the loop at all stages of CDS to ensure that AI behavior is aligned with public interest.\n\nCurrently, training individuals in the skills required to set up a CDS, recruit, moderate, and analyze results is a task that falls upon a relatively small community of experts, and takes considerable time and cost. Recent work has looked at how Retrieval Augmented Generation (RAG) systems can be used to augment human intelligence in training tasks (Modran et al. 2024). Applied to this context, an expert-curated RAG system could turbo-charge the training process, and empower skilled facilitators with powerful learning technology to support the next generation of practitioners, especially in historically marginalized populations that may have difficulty funding these training exercises.\n\nEducational Materials for Participants\n\nA key feature of many well designed deliberative processes is an on-going educational component for the participants, so that they can begin deliberations with a richer understanding of an issue and continue enriching it as the deliberation unfolds. The sourcing of educational material and presentations is often a carefully curated process by experts. This production process itself could be an opportunity to apply LLMs and deliberative methods.\n\nAI can assist with conducting research to understand the topics that participants will be asked to address during deliberations. The GovLab and Citizens Foundation have developed a toolkit called Policy Synth that uses AI agents and genetic algorithms to rapidly conduct large-scale, automated web research on a given topic. The findings from this automated research are then used as the basis for written briefs that frame the discussion topics for participants in a deliberation (Bjarnason, Gambrell, and Lanthier-Welch 2024). This process applies AI to gather, synthesize, and then present complicated evidence into more readily-digestible formats for participants.\n\nOnce generated, educational content could be placed in a database where it can be accessed by LLMs (known as retrieval-augmented generation or RAG systems), which would allow participants to ask questions about the domain, with the system returning responses citing the source material put together by the experts (Liu et al. 2024). This presents another opportunity for more democratic information curation; generative social choice could be used to balance information from experts with conflicting perspectives by mapping out where experts agree and where there are ambiguities. This contributes to solving the longstanding challenge of better incorporating expert opinion into CDSes and deliberative processes more broadly (Bricker 2024).\n\nIntelligent Prompting & Mediation\n\nSkilled facilitation involves careful framing to initiate discussions, active listening to understand the perspectives that are being shared, reflection of this understanding back to participants so that they feel heard, and synthesis and articulation of both legitimate differences and opportunities for common ground and consent (Schirch and Campt 2015).\n\nCDSes like Polis and Remesh are often specifically designed to support certain aspects of this skill set, such as the identification of legitimate differences and points of common ground. Nevertheless, engagement outcomes are still highly dependent on the interactions between facilitators and participants, such as the prompts participants respond to, as well as the seed statements facilitators submit in order to help frame the dimensions of the discussion, and ensure that there are comments available to vote on for the very first participants who enter the conversation.\n\nSome platforms, like Remesh, allow facilitators to pose a series of prompts for participants to respond to, enabling dynamic back and forth where the facilitator can adapt the conversation or probe a certain response to develop a more realistic, nuanced deliberation. Other platforms, like Polis, provide a single conversation prompt and rely on the real-time submission of seed statements as an alternative way of adapting the engagement to emergent topics within the context of one higher-level prompt\u00b2.\n\nWe expect LLMs can play a significant role in reducing the effort and necessary expertise associated with such dialogue design and facilitation. An early example of this is Remesh's prompt suggestion feature which offers suggestions for rewording CDS prompts in order to mitigate framing bias and elicit quality responses. There remain, however, a wide range of opportunities to use LLMs to assist in dialogue design and moderation:\n\n\u2022 Translation: LLMs enable text to be rapidly translated with high accuracy in near real-time into a large number of languages, expanding access to CDS for those who do not speak the dominant language. Multi-language deliberations and dialogues in the past were resource intensive, but LLMs enable CDS participation by a broader, multi-lingual pool of participants.\n\n\u2022 Intelligent dialogue generation tools (for facilitators): a prompt-tuned LLM chatbot can engage in a dialogue with a facilitator to co-design the CDS. The chatbot can pose a series of questions about the CDS a facilitator aims to run, then generate a dialogue design and seed prompts for the facilitator to use.\n\n\u2022 Intelligent prompting and scenario generation (for participants): Participants may not always provide rich statements in response to certain prompts because of a lack of understanding or preexisting opinions on the topic. This is especially true for complex policy topics or abstract questions about values. One mitigation here is to intelligently prompt participants to respond to LLM-generated scenarios. LLM-based tools can also improve the formulations of participants' statements by proposing reformulation or asking them for more context about their post. This can also operate at the level of the CDS, where an API can take the data collected by a CDS (statements + votes) and generate suggested follow up prompts or seed statements for a follow-up round of deliberation. Here GATE and STaR-GATE (Andukuri et al. 2024), which are designed to ask clarifying questions of a single person, could be extended and generalized to engage with a wider participant body.\n\n\u2022 Bridging-based comment routing: bridging systems can take an individual's response, as well as additional context like demographic data or voting history within a CDS, and produce a suggested follow up prompt or question specific to that individual, in order to gather additional detail on how they fit into the broader opinion landscape. These systems can also take the contents of an ongoing CDS and generate or elevate messages that garnered similar votes across opinion groups. This can enable participants to see and respond to shared common ground in real time."}, {"title": "Fact checking during deliberation", "content": "Fact checking during deliberation: many debates or deliberations today include professional fact-checking to provide near-real-time analysis of the veracity of claims made. AI could similarly help in providing accurate information in real time, ensuring participants operate from a shared set of facts (Landemore 2022a).\n\nElicitation Inference\n\nIn nearly all uses of CDSes, there are far too many submitted position statements to expect each participant to vote on all of them. Consequently, most participants don't vote on most statements. In settings where there are no constraints on how many times a participant can vote on statements, large asymmetries in the number of votes cast by different sub-groups of participants can arise leading to biased vote tallies. One potential solution used by some platforms today is to predict how an individual would have voted based on the statements they did vote on. There are significant risks with this approach of simulating votes, though perhaps not as high as they are in vote simulations that assume a different level of knowledge than people actually have (Brennan and Landemore 2022). These need to be carefully designed for, including the perception of disenfranchisement or the manipulation of inputs through synthetic public input.\n\nSuch vote predictions are possible both because there are patterns in large-scale voting the same type of patterns routinely exploited by recommender systems. There is also rich information in the semantic content of the comments themselves, which LLMs can unlock. Vote prediction in a CDS setting has been demonstrated using pure LLM prompting, and has been found to be well calibrated, but can be expensive to employ for larger data sets (Fish et al. 2023). Hybrid LLM-latent factor models have also been developed with significantly improved performance characteristics (Konya et al. 2022). There are a few key opportunities to build on this nascent work:\n\n\u2022 Develop an open data set of CDS data from which elicitation inference performance benchmarks can be established and tracked for various methods.\n\n\u2022 Create better approaches to elicitation inference that demonstrate higher accuracy than those available today, e.g. fine-tune an LLM to excel at this task.\n\n\u2022 Solve the confidence problem, by developing an approach to elicitation inference which enables the margin of error to be estimated for results derived from aggregations which include inferred votes.\n\n\u2022 Create an open toolbox for elicitation inference that inputs and outputs data in some universal format which enables interoperability between other tools, such as those for doing LLM based summarization and synthesis.\n\nSummarization and Visualization for Sensemaking\n\nDuring and after a CDS, there are opportunities for producing easily digestible summaries of the voluminous data produced by these systems. There are, for example, Polis engagements which have involved tens of thousands of participants, submitting thousands of statements and millions of votes on those statements (\u201cAufstehen Case Study\u201d 2018). Making sense of the output of these large-scale deliberations is a daunting task. Some CDS offer algorithms for mapping the opinion space, clustering participants into opinion groups, and ranking comments, all of which help with understanding what participants collectively said. Remesh provides a sophisticated interface for analyzing the voting patterns in terms of demographic data, and provides tools for summarizing and synthesizing results. Still, fully understanding the results and producing impactful outputs is currently an onerous, time-intensive undertaking, which often requires a meaningful amount of human labor. LLMs offer an opportunity to simplify these processes by augmenting human intelligence to more efficiently summarize and make sense of public opinion from CDS outputs.\n\nGoogle DeepMind has shown that a fine-tuned set of language models can be combined with a preference aggregation framework to find common ground amongst individuals with diverse perspectives (Bakker et al. 2022). Building on this work, researchers found it possible to reach common ground on controversial topics in virtual deliberations through iterative participant feedback on LLM generated statements. Participants' initial statements can be synthesized with LLMs into \"group statements\" that aim to identify common ground. These group statements are then iteratively refined with participants' feedback and LLM synthesis to generate statements that maximize participant endorsement (Tessler et al. 2024).\n\nFish et al. proposed generative social choice as a framework for combining LLMs with social choice theory to generate a slate of statements that accurately represent a heterogeneous population (Fish et al. 2023). Meanwhile, the Computational Democracy Project, in collaboration with Anthropic, explored the application of LLMs to numerous challenges associated with CDS platforms, including the summarization of Polis conversation data (C. T. Small et al. 2023). Their work highlights the critical role of context-window length in producing nuanced and rich summaries of vote patterns across different opinion groups. Similarly, tools like Remesh and Talk to the City have integrated some degree of summarization and topic modeling to assist with the analysis process (Gallagher 2024). These developments collectively point towards a future where AI can significantly augment facilitators' ability to understand and synthesize complex, large-scale conversations, affording the opportunity to significantly enhance the impact of CDSes with results that are more easily consumed.\n\nThis work has obvious advantages for policy makers. Martin Hilbert described a \u201cDeep Democratic Neural Network\u201d, a system whereby an AI would summarize citizens' political preferences, input via written text statements, into a single policy platform to be acted upon by politicians, now equipped to better represent their constituents on more rich information than a single vote cast every few years (Hilbert 2009). 15 years later, the technology now exists to enable the collection, synthesis, and visualization of citizens' nuanced political perspectives for decision makers of all varieties.\n\nEarly progress to this end is underway with Policy Synth, a modular system designed to synthesize the findings from engagements together with research findings to create evidence-based policies. For example, New Jersey's AI Task Force is using Policy Synth with the platform All Our Ideas to gather input from workers on what they see as the greatest opportunities and challenges regarding the impact of generative AI on the state's workforce. The output from the engagement will be a rank-ordered list of public concerns for policy makers (Gambrell 2024).\n\nPlatform for Integrating Deliberative Systems\n\nPresently, stitching together meaningfully deliberative processes out of these tools is not straightforward. There is an ecosystem of technology that can facilitate public engagement, but very little attention has been given to making these pieces composable. Progress towards this goal requires coordination amongst the various platform creators, maintainers and practitioners to hone in on appropriate usage patterns, data formats and protocols.\n\nMany teams using CDSes consistently produce similar reporting across multiple projects and have common reporting outputs, such as percentage agree or disagree with a statement, or number of new statements added. There is a clear opportunity to apply the principles of reproducible analytical pipelines (\"Reproducible Analytical Pipelines (RAP),\u201d n.d.) and the associated software engineering practices to make such reporting more reproducible and less error-prone.\n\nIdeally, a meta-platform for CDS would:\n\n\u2022 Support composition and interoperability with modular design, empowering process designers to adapt their methods to different circumstances;\n\n\u2022 Offer core infrastructure that these platforms can build on, accelerating innovation of new technologies in this space, and improving interoperability of existing technologies;\n\n\u2022 Provide a sandbox for testing tools, including with simulation, so that practitioners can experiment and gain intuition as they design improved tools;\n\n\u2022 Come with built-in evaluation and benchmarking infrastructure for tools and processes;\n\n\u2022 Support end-to-end CDS workflows from recruiting to report generation.\""}, {"title": "1.3 Risks and Mitigations for AI-enhanced Collective Dialogue Systems", "content": "While CDS and deliberative technology stands to benefit greatly from application of LLMs and related technical innovations, this adoption does not come without risks:\n\n\u2022 Aggregation of opinions is one part of deliberation: It is important to distinguish the use of LLMs in CDS to solicit high-definition snapshots of public opinion from mass deliberation, the latter of which involves an iterative exchange of reasons, arguments, and justifications (Landemore 2022b). LLMs can help scale such deliberations, but for the context of mass deliberations, LLMs should be understood as augmenting the process rather than substituting wholesale.\n\n\u2022 Misrepresentation owing to use of LLMs: LLMs can occasionally hallucinate information and struggle to represent the opinions of minority groups (Agnew et al. 2024). Additionally, if LLM-based simulations of deliberations are used as part of a system, there is a further challenge of assessing the veridicality of the outputs. For example, designers will need to work to ensure the LLM equally or proportionally represents different viewpoints in its syntheses, rather than over-emphasizing certain viewpoints.\n\n\u2022 Appeals & Ethical Review Mechanisms: It is possible that LLM summaries or participant inputs may include offensive or disputed content that are not moderated by CDS facilitators. For such dialogues to be inclusive and responsive, it is important to include appeals processes for participants to report issues and trigger a procedural investigation into breaches of a pre-existing policy on norms of the dialogue. Such an appeals body could proactively review the LLM-generated content before publication, in addition to participant appeals. This body would need to be independent from CDS facilitators (Landemore 2022b). This risk is further mitigated by publishing moderation guidelines and norms publicly ahead of any CDS and including these in participant education prior to the CDS. Transparent access by the public to all CDS participant statements, including those moderated out, can also help mitigate ethical concerns.\n\n\u2022 Synthetic participation is promising yet democratically problematic and potentially risky: LLMs can already participate in CDS and other forms of deliberation in place of, or in addition to, human participants. This approach offers the potential of more representative results (by projecting votes beyond what human limits of time and attention are capable of giving voice to). But it runs the risk of degrading the CDS' legitimacy, diluting the public's agency, and misrepresenting reality in convincing ways. The transparency of such synthetic vote projections is paramount to avoid misperceptions of AI replacing humans or manipulating outcomes. Can the advantages afforded by synthetic participation be realized while preserving democratic legitimacy and safely managing the risks?"}, {"title": "1.4 Future Research on AI-enhanced Collective Dialogue Systems", "content": "\u2022 Design for \"deliberation in the wild\" on existing platforms: The existing digital public squares can be designed to promote healthier discourse and mutual understanding. A core area of future research could focus on prosocial designs on these more engagement-based platforms to incentivize collective dialogue.\n\n\u2022 Assess trade-offs imposed by current CDS design constraints: CDS systems allow participants to submit comments and vote on others, but not engage in threaded discussions. Many virtual CDS enable anonymity, use text only inputs as opposed to richer formats (e.g. video, audio, images), and lack synchronicity. Further research is needed to understand the impacts of these design constraints, and whether CDS outcomes can be improved with different normative modalities.\n\n\u2022 Understand the cost of inaction: It is difficult to quantify the benefits of embracing deliberative and participatory technologies. Further research is needed into measurable outcomes, both qualitative and quantitative, between participatory processes and the counterfactual, non-participatory case.\n\n\u2022 Motivate healthy participation: A successful CDS requires sufficient and representative participation. However, the process of effectively recruiting and motivating participants is unclear in most contexts. Paying participants motivates them to participate, but may crowd out other incentives (sense of civic duty, intrinsic reward of participating) and be unsustainable at scale. Future research should not only aim to understand appropriate motivation strategies, but also take seriously the lack of interest in participating expressed from many, and aim to address this participant disinterest or apathy.\n\n\u2022 Build for accountability and transparency to ensure trust in AI and the CDS: Public excitement about AI is currently mixed together with skepticism and uncertainty. The successful deployment of AI tools to benefit deliberation and collective dialogue will likely hinge on our ability to create credible accountability mechanisms, ensure process transparency, and understand participants' shifting mental models of AI and disclosure and transparency needs as well as the drivers of and barriers to trust in AI in specific circumstances. Successful CDSes require both process legitimacy and output legitimacy, and trust in the underlying technology could significantly affect this perceived legitimacy."}, {"title": "2. Bridging Systems", "content": "Most online dialogue about substantive issues takes place on consumer platforms that were designed more for entertainment and attention farming than for the discussion of contentious social issues. How might these more widely used systems benefit from some of the same mechanisms that power collective dialogue systems?\n\nOne idea is that our everyday systems should be designed to encourage trust, understanding, and building of common grounds between people with different views, values, and identities. This concept is commonly called \u201cbridging\u201d (Ovadya and Thorburn 2023). Building trust in divided societies is part science and part art, with specialists focused primarily on complex, time-intensive efforts to enable awareness of shared values and interests. Dialogue, negotiation and mediation processes have long used the concept of bridging to advocate for \u201cwin-win\" solutions that address the underlying interests and needs of key stakeholders (Schirch 2024). Advances in AI language capabilities are expanding possibilities to scale bridging beyond time intensive in-person interactions.\n\nExisting content selection algorithms sometimes create more division. Most of the algorithms that personalize content for us often called recommender systems \u2013 try to select those items that we will click on, share, or otherwise engage with (Thorburn 2022). Engagement benefits businesses as the more a user engages with content, the more ads can be shown and the more content is generated to attract other users. However, there are times when the most engaging content is also the most polarizing (Rathje, Van Bavel, and van der Linden 2021), especially since engagement is often dominated by small groups of more abusive users (Hindman, Lubin, and Davis 202"}]}