{"title": "Task Arithmetic for Language Expansion in Speech Translation", "authors": ["Yao-Fei Cheng", "Hayato Futami", "Yosuke Kashiwagi", "Emiru Tsunoo", "Wen Shen Teo", "Siddhant Arora", "Shinji Watanabe"], "abstract": "Recent advances in large language models (LLMs) have gained interest in speech-text multimodal foundation models, achieving strong performance on instruction-based speech translation (ST). However, expanding language pairs from an existing instruction-tuned ST system is costly due to the necessity of re-training on a combination of new and previous datasets. We propose to expand new language pairs by merging the model trained on new language pairs and the existing model, using task arithmetic. We find that the direct application of task arithmetic for ST causes the merged model to fail to follow instructions; thus, generating translation in incorrect languages. To eliminate language confusion, we propose an augmented task arithmetic method that merges an additional language control model. It is trained to generate the correct target language token following the instructions. Our experiments demonstrate that our proposed language control model can achieve language expansion by eliminating language confusion. In our MuST-C and CoVoST-2 experiments, it shows up to 4.66 and 4.92 BLEU scores improvement, respectively. In addition, we demonstrate the use of our task arithmetic framework can expand to a language pair where neither paired ST training data nor a pre-trained ST model is available. We first synthesize the ST system from machine translation (MT) systems via task analogy, then merge the synthesized ST system to the existing ST model.", "sections": [{"title": "I. INTRODUCTION", "content": "Following the recent development of large language models (LLMs) [1-3], large speech-text multimodal foundation models have gained rapid attention [4-7]. Similar to other automatic speech recognition (ASR) [8] and spoken language understanding (SLU) [9, 10] tasks, speech translation (ST) [11, 12] has witnessed strong performance. Usually, such ST systems only support translation language pairs that have been seen in training. In practical usage, one may want to translate an unseen language pair [13]. Therefore, to support the new language pairs by expanding language pairs from an existing ST system is required. However, it typically requires re-training the model with a combination of new and previous ST datasets, leading to an increasing cost as training data grows. Alternatively, by training an ST model solely on the new language pair and integrating it with an existing pre-trained ST model without re-training, we can significantly reduce training costs. To this end, we realize this integration through model merging based on task arithmetic.\nModel merging is an approach to directly manipulate the parameters of existing models to get a new model without re-training [14-21]. The popular model merging approach, task arithmetic [17] has shown that task expansion can be done by task vector addition, where a task vector can be obtained by the difference between the fine-tuned model parameters and the pre-trained ones. For further performance improvement, advanced methods built on top of task arithmetic, have been proposed by solving parameter interference during merging [22, 23]. Task arithmetic and its extensions have been applied to image classification [17, 22] and generation [21], text classification [22], text-to-speech (TTS) [24], and ASR [25]. Although they are applied in various domains, multilingual text generation in ST has not been explored in previous studies.\nThis work shows expanding language via model merging can be achieved by task vector addition without re-training, illustrated in Fig. 1. We find directly applying task arithmetic leads to substantial language confusion errors, where the models generate translation in the wrong target language. As a remedy, we propose to merge\u00b9 another language control (LC) model, which guides the model in generating translation in the correct language according to the instruction. Our experi-ments demonstrate that this novel language control approach mitigates language confusion errors and yields a performance boost by up to 4.66 BLEU score on the MuST-C dataset [26] and 4.92 BLEU score on the CoVoST-2 En \u2192 X dataset [27]. In addition, we explore language expansion where neither"}, {"title": "II. METHOD", "content": "First, we denote the task vector for the i-th fine-tuned task as $T_i \\in \\mathbb{R}^d$, where d is the dimension size of all model parame-ters. The task vector is obtained by the difference between the i-th fine-tuned model parameters $\\Theta_i^{FT} \\in \\mathbb{R}^d$ and the pre-trained model parameters $\\Theta^{PT} \\in \\mathbb{R}^d$, i.e., $T_i = \\Theta_i^{FT} - \\Theta^{PT}$, as defined in [17]. As shown in Eq. (1), the merged model parameters $\\Theta \\in \\mathbb{R}^d$ can be obtained by an element-wise linear interpolation between $\\Theta^{PT}$ and N different task vectors. Hyper-parameter $\\lambda_i$ are scaling coefficients.\n$\\theta = \\Theta^{PT} + \\sum_{i=1}^{N} \\lambda_i T_i = \\Theta^{PT} + \\sum_{i=1}^{N} \\lambda_i (\\Theta_i^{FT} - \\Theta^{PT}).$ (1)\nIn addition to this general form, we specifically focus on each weight matrix within the model parameters that are typically fine-tuned in low-rank adaptation (LoRA) [29] while fixing the other parameters. Then, the model merging equation for the weight matrix corresponding to Eq. (1) is represented as [30]:\n$W = W^{PT} + \\sum_{i=1}^{N} \\lambda_i (W_i^{FT} - W^{PT}).$ (2)"}, {"title": "A. Task vectors", "content": "First, we denote the task vector for the i-th fine-tuned task\nas $T_{i} \\in \\mathbb{R}^{d}$, where d is the dimension size of all model parame-\nters. The task vector is obtained by the difference between the\ni-th fine-tuned model parameters $\\Theta_{i}^{FT} \\in \\mathbb{R}^{d}$ and the pre-trained\nmodel parameters $\\Theta^{PT} \\in \\mathbb{R}^{d}$, i.e., $T_{i}=\\Theta_{i}^{FT}-\\Theta^{PT}$, as defined\nin [17]. As shown in Eq. (1), the merged model parameters\n$\\Theta \\in \\mathbb{R}^{d}$ can be obtained by an element-wise linear interpolation\nbetween $\\Theta^{PT}$ and $N$ different task vectors. Hyper-parameter\n$\\lambda_{i}$ are scaling coefficients.\n$\\theta=\\Theta^{PT}+\\sum_{i=1}^{N} \\sum_{i=1}^{N} \\lambda_{i} T_{i}=\\Theta^{PT}+\\sum_{i=1}^{N} \\lambda_{i}\\left(\\Theta_{i}^{FT}-\\Theta^{PT}\\right).$ (1)\nIn addition to this general form, we specifically focus on each\nweight matrix within the model parameters that are typically\nfine-tuned in low-rank adaptation (LoRA) [29] while fixing the\nother parameters. Then, the model merging equation for the\nweight matrix corresponding to Eq. (1) is represented as [30]:\n$W=W^{PT}+\\sum_{i=1}^{N} \\lambda_{i}\\left(W_{i}^{FT}-W^{PT}\\right).$ (2)"}, {"title": "B. Language expansion via task vector addition", "content": "Considering there are multiple one-to-many ST systems that\ntranslate one source language $L_s$ into $N$ different languages\n$L_{t_i}$ ($1 \\leq i \\leq N$). We can regard ST for each language pair as\na task in Eq. (1) and merge these ST systems by addition for\n$i = 1$ to $N$ with its task vector $T_{L_s L_{t_i}}^{ST}$, as follows:\n$\\theta=\\Theta^{PT}+\\sum_{i=1}^{N} \\lambda_{i} T_{L_{s} L_{t_{i}}}^{ST}.$ (4)\nThe merged model would have the ability to translate from\nthe source language $L_s$ to target languages $L_{t_i}$. We can further\napply advanced methods of task arithmetic such as TIES-\nMerging [22], which improves the performance by pruning\ntask vectors and voting on their signs."}, {"title": "C. Language Control", "content": "We aim to expand language pairs in ST via simple task\nvector addition, as demonstrated in Section II-B. However, it\nintroduces language confusion errors, where the merged model\ngets confused about which target language to translate into. As\nwe observed in a preliminary experiment, shown in Table I, the\nmerged model generates translation in the incorrect language;\nIn the case of instructed to translate German, 17.97% of results\nare mistranslated into French. We hypothesize that it is caused\nby the lack of the capability to predict an output language\naccording to instructions.\nTo address it, we propose to merge another language control\n(LC) model to equip this capability, as follows,"}, {"title": "D. ST task synthesis via task analogies", "content": "Consider the scenario where one wants to expand a language\npair in an existing ST system, but no paired ST data or pre-\ntrained ST model is available for that pair. However, MT data\nor a pre-trained MT model is available. For this purpose, we\npropose synthesizing an ST task via task analogies formulated\nin task arithmetic [17]. Task analogies link tasks by the relation\ntask1: task2 :: task3: task4. For task vectors of such a\nscenario, the following equation holds:\n$T_{task4} \\approx T_{task3} + T_{task2} - T_{task1}.$ (5)\nIn this study, we leverage task analogies to synthesize an\nST task. By introducing pivot language $L_p$ where a pre-trained\nST model is available, inspired by pivot translation [32, 33],\ntask analogies between MT of $L_s \\rightarrow L_p$ (available), MT of\n$L_s \\rightarrow L_t$ (available), ST of $L_s \\rightarrow L_p$ (available) and ST of\n$L_s \\rightarrow L_t$ (not available) are written as:\n$T_{L_{s} L_{p}}^{MT}: T_{L_{s} L_{t}}^{MT}:: T_{L_{s} L_{p}}^{ST}: T_{L_{s} L_{t}}^{ST}$ (7)\nFollowing Eq. (6), we can synthesize ST of $L_s \\rightarrow L_t$ via task\nanalogies as,\n$T_{L_{s} L_{t}}^{ST} \\approx \\lambda_{1} T_{L_{s} L_{p}}^{ST} + \\lambda_{2} (T_{L_{s} L_{t}}^{MT} - T_{L_{s} L_{p}}^{MT}),$ (8)\nwhere $\\lambda_1$ and $\\lambda_2$ are the merging coefficients. The merged\nmodel would have the ability to translate from the source\nlanguage $L_s$ to target languages $L_t$ that we want to expand.\nFinally, we further merge this synthesized ST model into the\nexisting ST model, for language expansion, as in Section II-B."}, {"title": "III. EXPERIMENTS", "content": "Fig. 2 summarizes the detailed fine-tuning flow. We used\nSpeechGPT-7B-cm5 as our backbone [5], a large speech-\ntext multi-modal pre-trained model with 7B parameters. We\nprepared pre-trained ST models by SpeechGPT's instruction\ntuning with LoRA as discussed in Section II-A by updating\nkey, query, value, and output projections with the rank r = 32\n29]. We used En \u2192 De and En \u2192 Fr of MuST-C [27], and\nalso En \u2192 De and En \u2192 Zh of CoVoST-2 [26]. For instruction\ntuning, we used 4 A6000 GPUs with batch size 128, learning\nrate 2\u00d710\u22125. We used AdamW [34] to update 4200 steps for\nMuST-C [27] and 2100 steps for CoVoST-2 [26] experiments.\nWe used development set performance for searching hyper-\nparameters such as merging coefficients."}, {"title": "A. Fine-tuning", "content": "Fig. 2 summarizes the detailed fine-tuning flow. We used\nSpeechGPT-7B-cm5 as our backbone [5], a large speech-\ntext multi-modal pre-trained model with 7B parameters. We\nprepared pre-trained ST models by SpeechGPT's instruction\ntuning with LoRA as discussed in Section II-A by updating\nkey, query, value, and output projections with the rank r = 32\n29]. We used En \u2192 De and En \u2192 Fr of MuST-C [27], and\nalso En \u2192 De and En \u2192 Zh of CoVoST-2 [26]. For instruction\ntuning, we used 4 A6000 GPUs with batch size 128, learning\nrate 2\u00d710\u22125. We used AdamW [34] to update 4200 steps for\nMuST-C [27] and 2100 steps for CoVoST-2 [26] experiments.\nWe used development set performance for searching hyper-\nparameters such as merging coefficients."}, {"title": "B. Insturctions", "content": "We follow AudioPaLM's style [4] to instruct the model\nto generate a transcript and then translation for ST. The\ninput instructions are constructed as such \u2018Can you transcribe\nand translate ...,' and randomly selected from 10 templates\nduring fine-tuning, as done in SpeechGPT [5]. For the LC\ntask (see Section II-C), we use ASR training data from\nEn \u2192 Fr for MuST-C experiments and En \u2192 De for CoVOST-\n2 experiments. For MT used in task analogies, the instruction\nis constructed as such 'Can you translate ....'"}, {"title": "IV. RESULTS", "content": "The goal of language expansion is to merge ST models in\ndifferent language pairs into a single model to achieve perform\nmulti-lingual ST. This work focuses on merging two En \u2192 X\nST models in experiments. We compare our merged models\nwith topline approaches: joint fine-tuning, which jointly trains"}, {"title": "A. Language expansion", "content": "The goal of language expansion is to merge ST models in\ndifferent language pairs into a single model to achieve perform\nmulti-lingual ST. This work focuses on merging two En \u2192 X\nST models in experiments. We compare our merged models\nwith topline approaches: joint fine-tuning, which jointly trains"}, {"title": "B. Language expansion with synthesized ST", "content": "In this section, we explored the possibility of expanding a\nlanguage pair from an existing ST model where no paired ST\ndata or pre-trained model was available. Specifically, we first\nsynthesized the ST model in the target language pair via task\nanalogies (discussed in Section IV-B). Then, we merged this\nsynthesized ST model to the existing ST model using task\nvector addition. To simulate this scenario, we used the ST\nmodel of En \u2192 De trained on MuST-C as the existing ST\nmodel. As for MT models used in En \u2192 Fr ST task synthesis\nof task analogy, we used MT models of En \u2192 De and En \u2192\nFr, which were trained on MT paired data in MuST-C.\nWe summarize the results of language expansion with\nsynthesized in Table V. We find the direct application of\ntask analogy failed due to severe language confusion errors\n(C4) in Table V). Further merging our proposed LC model,\nthe synthesized model (C5) yielded a BLEU score of 21.65\nin En\u2192 Fr, following the trend in language expansion\nexperiments. Notably, we can obtain the ST model without\nrelying on paired ST data, which shows 21.67% relative\nperformance degradation compared to the model fine-tuned on\nST data ((A3) in Table III). Once we obtain the synthesized ST\nsystem for a language we aim to expand, we merge it into the\nexisting ST system for language expansion via TIES-Merging\n((A6) and (A7)). Despite it only achieved BLEU scores of 9.22\nand 7.16 in En \u2192 De and En \u2192 Fr, this shows the potential of\nlanguage expansion without using the ST data. We believe that\nperformance degradation was introduced by merging models\nmultiple times, which we leave for future work."}, {"title": "V. CONCLUSION", "content": "This paper proposes expanding language pairs in the exist-\ning instruction-based ST system via task arithmetic. We find\nthat the direct application of task arithmetic for ST results\nin language confusion, generating translations in incorrect\nlanguages. Our experiments demonstrated that our proposed\nlanguage control model achieved language expansion by ef-\nfectively eliminating language confusion. In addition, we have\nshown task analogies can achieve ST task synthesis when there\nis no paired speech translation data available."}]}