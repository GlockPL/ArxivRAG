{"title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code", "authors": ["Khiem Ton", "Nhi Nguyen", "Mahmoud Nazzal", "Abdallah Khreishah", "Cristian Borcea", "NhatHai Phan", "Ruoming Jin", "Yelong Shen"], "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate secure code with large language models (LLMs). SGCode integrates recent prompt-optimization approaches with LLMs in a unified system accessible through front-end and back-end APIs, enabling users to 1) generate secure code, which is free of vulnerabilities, 2) review and share security analysis, and 3) easily switch from one prompt optimization approach to another, while providing insights on model and system performance. We populated SGCode on an AWS server with PromSec, an approach that optimizes prompts by combining an LLM and security tools with a lightweight generative adversarial graph neural network to detect and fix security vulnerabilities in the generated code. Extensive experiments show that SGCode is practical as a public tool to gain insights into the trade-offs between model utility, secure code generation, and system cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is available at: SGCode.", "sections": [{"title": "1 Introduction", "content": "Ground-breaking developments of LLM-powered code generation commercial tools, such as Microsoft GitHub Copilot and Amazon CodeWhisperer, have significantly improved software developer productivity [3]. However; recent studies show that these tools frequently inherit security flaws from their open-source training data, leading to vulnerabilities such as common weakness enumerations (CWEs) in the generated code [1, 7, 9]. In real-world systems, attackers can exploit such code vulnerabilities, potentially leading to cyberattacks, data breaches, and degraded performance. Therefore, there is an urgent need for reliable approaches and systems to identify and fix vulnerabilities in LLMs-powered code generation.\nRecent approaches, including PromSec [6] and SafeCoder [4], have shown great potential in optimizing prompts toward generating secure, free of vulnerabilities code. Yet, the lack of a flexible, deployable system limits our understanding of the trade-offs between secure prompt optimization, code utility, security analysis, and system performance. To bridge this gap, we propose SGCode, a flexible system for deploying and evaluating various prompt optimization methods. This tool enables users to gain insights into the trade-offs between code utility, security analysis, and system performance, ultimately aiding in the development of more secure approaches while minimizing system costs. For example, analyzing different CWEs and their associated costs in computation, communication, and prompting LLMs allows us to refine our model to better address these vulnerabilities and reduce overall costs.\nContributions. We develop SGCode with two integrated components: (1) Back-end Services, which seamlessly integrate Code Security Analysis Tools, such as Bandit [2] and CodeQL [5], and commercial LLMs, such as GPT-40, to generate optimal prompts for secure code generation and send the results, including the code, security analysis, and system performance report, to the user front-end; (2) User front-end, a web-based interface that enables users to query prompt-optimizing systems, display code, view and share security analysis and performance reports. SGCode is deployed on"}, {"title": "2 Prompt-Optimizing Secure Code Generation", "content": "Two recently developed secure code generation approaches are PromSec [6] and SafeCoder [4]. The key idea of PromSec is leveraging a graph generative adversarial neural network (gGAN) to mitigate code vulnerabilities by altering the code's graph representations. These altered representations are translated into prompt adjustments using LLMs. PromSec trains the gGAN model using a differentiable contrastive objective, which seamlessly integrates code security analysis tools, LLMs, and the gGAN's generator together, ensuring secure code generation.\nAn alternative solution is SafeCoder [4], an instruction tuning approach to resolve code vulnerabilities in two steps: (1) Curating a dataset consisting of standard instructions and a code vulnerability dataset consisting of GitHub commits for fixing code vulnerabilities; and (2) Instruction tuning that minimizes the language modeling loss $L_{std}$ if the data point is in the instruction dataset; otherwise, the loss is $L_{sec} + L_{vul}$ if the data point is in the vulnerability dataset. $L_{sec}$ is the likelihood loss that aligns the LLM model toward the secured tokens in $o_{sec}$, whereas $L_{vul}$ is the unlikelihood loss that helps to reduce the probability of generating vulnerable tokens in $o_{vul}$. The fine-tuned LLM is used to generate secure code."}, {"title": "3 SGCode System", "content": "We develop SGCode (Figure 1) as an API-accessible service and a web application for users to access our system on the web or integrate our API into their applications. The system design focuses on simplicity to optimize system costs, extensibility to customize the API, and maintainability with our modular architecture."}, {"title": "3.1 Back-end Services", "content": "SGCode's back-end is powered by FastAPI [8]. It receives instructions to generate code from the users and then utilizes a pipeline consisting of three main components: (1) an interchangeable security analysis component, (2) a gGAN model from PromSec, and (3) an easily modifiable LLM. This design allows users to generate secure code with customization in mechanisms such as PromSec or SafeCoder. Users can use gGAN with an LLM for PromSec, or they can simply change the LLM to the SafeCoder-tuned LLM as in [4] to enable SafeCoder standalone or even combine the two approaches. Our system employs a NoSQL database to store the generated code for shareable security reports."}, {"title": "3.2 Front-End Interface", "content": "The interface is built using Streamlit, an open-source Python framework for creating interactive user interfaces (UI). The interface is organized into two main screens: (1) AI Prompt UI, which facilitates user input (Figure 2a); and (2) Security Analysis Report screen, which displays detailed results and insights (Figure 2b)."}, {"title": "3.3 Deployment and Evaluation", "content": "We deploy SGCode on an AWS c7g.large virtual machine consisting of 2 vCPUs of AWS Graviton3 ARM processor and 4 GiB memory. We run the FastAPI with 4 workers and Streamlit on the same machine. Our back-end connects to a MongoDB instance hosted via MongoDB Atlas. We conduct three experiments using the test data in [6]: (1) Evaluating SGCode's resource usage with and without PromSec; (2) Measuring SGCode's latency given the number of CWEs, CWE IDs, and the prompt length; and (3) Inspecting the code security and code functionality using our Security Report.\nFirst, we measure the resource usage by using the Python libraries psutil and sys. We select the back-end and front-end process IDs and their child processes and run the test dataset on the front end via Selenium. We evaluate our system until the test is finished and report the average result in three runs. Table 4 shows that utilizing PromSec has negligible CPU and memory usage.\nSecond, we measure the system's total latency and the latency of each component. We conduct the latency experiment on the"}, {"title": "4 Conclusion and Future Works", "content": "We developed SGCode, a timely and flexible system that utilizes prompt-optimizing mechanisms to generate secure code. SGCode performs efficiently, even on a lightweight AWS virtual machine, with negligible overhead from prompt-optimizing mechanisms. Our future work will focus on: (1) Incorporating a feature that allows users to define utility tests and automatically test their code; (2) Further optimizing our system to reduce latency; and (3) Scaling the model to handle larger data and more complex code."}]}