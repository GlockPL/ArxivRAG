{"title": "RIFF: Inducing Rules for Fraud Detection from Decision Trees", "authors": ["Lucas Martins", "Jo\u00e3o Bravo", "Ana Sofia Gomes", "Carlos Soares", "Pedro Bizarro"], "abstract": "Financial fraud is the cause of multi-billion dollar losses annually. Traditionally, fraud detection systems rely on rules due to their transparency and interpretability, key features in domains where decisions need to be explained. However, rule systems require significant input from domain experts to create and tune, an issue that rule induction algorithms attempt to mitigate by inferring rules directly from data. We explore the application of these algorithms to fraud detection, where rule systems are constrained to have a low false positive rate (FPR) or alert rate, by proposing RIFF, a rule induction algorithm that distills a low FPR rule set directly from decision trees. Our experiments show that the induced rules are often able to maintain or improve performance of the original models for low FPR tasks, while substantially reducing their complexity and outperforming rules hand-tuned by experts.", "sections": [{"title": "1 Introduction", "content": "Despite the advent of modern machine learning (ML) algorithms, rule systems continue to be important in many domains [1,21]. Their simplicity and interpretability, often requirements in high stake problems, as well as their longstanding presence has earned the trust of many financial institutions. Many continue to use rule systems as their only solution for fraud detection, while others use them alongside machine learning models.\nHowever, building rule sets traditionally requires expert input and their predictive performance is typically worse than modern machine learning models. This could potentially be attributed, at least in part, to the fact that rules are not automatically inferred from data, but instead manually created and tuned. While there are several induction algorithms that infer rules from data [18,4,20,21,17,14,11,5,6], applying them to fraud detection can be problematic due to the extreme class imbalance that is often present, and the requirement to have very low FPR values, typically under 2%. The latter is necessary as incorrectly flagging legitimate transactions can cause friction, eroding customer trust, leading to financial losses, and putting undue pressure on manual reviewers. For this reason, experts try to minimize false positives when considering the"}, {"title": "2 Related Work", "content": "Prior work on rule set induction can be divided into two distinct approaches. Separate-and-conquer algorithms, also known as covering algorithms, form rule sets by adding rules one by one until a stopping criterion is met [15,16,5,19,7,10]. They build or refine rules incrementally, typically relying on a heuristic to choose the best condition or rule to add. In each iteration, these algorithms remove examples covered by the rule set so that new rules can focus on data that is not covered by the current rule set.\nOn the other hand, divide-and-conquer algorithms such as ID3 [18], C4.5 [20] and CART [4], use decision trees to describe the data. These trees are grown in a greedy fashion, by iteratively splitting a current leaf node based on the value of one attribute to maximize a chosen criterion, such as information gain. FIGS [21] expands on these algorithms (namely CART) by introducing the option of adding a new tree by splitting on a new root node instead of an existing leaf node. Each tree independently contributes to the model with a score that is summed to produce the final prediction.\nOur work leverages both of these approaches. RIFF employs divide-and- conquer methods to build decision trees, and it uses a separate-and-conquer heuristic to build a rule set with the best performing rules while enforcing a low FPR or alert rate constraint."}, {"title": "3 Rule Induction for Fraud Detection", "content": "Rule systems used in the context of fraud detection are typically composed of tens to hundreds of simple rules, each designed to capture a particular fraud pattern. These rules are usually a conjunction of a small set of logical conditions that can be understood by a human and evolve with time by tuning specific thresholds. Fraud detection systems are also usually constrained to operate with an overall low False Positive Rate (FPR) or Alert Rate (AR). This is to limit the"}, {"title": "3.1 Rule Induction from Decision Trees", "content": "In order to generate a low FPR rule set, we extract rules from decision trees. We base this decision on the fact that the typical splitting criterion tries to find the purest leaves, i.e., leaves with highest precision that in theory maximize the amount of gained recall per FPR. For this reason, we will assume that all rules in the extracted candidate set predict the positive class.\nAfter creating a tree with suitable, high purity leaves, we form a candidate rule set by extracting one rule for each leaf. This is accomplished by traversing the path from the root node to each leaf, forming a new rule as a conjunction of the conditions in this path. Figure 2 shows an example where a tree model with 5 leaves was converted to a rule set.\nThis method does not extend well to additive tree models like FIGS, because it ignores tree scores when converting leaves to decision rules. To choose the best"}, {"title": "3.2 Rule Selection", "content": "As mentioned in Section 3, the rule selection step aims to distill a potentially large set of candidate fraud rules into a smaller set, maximizing the number of fraud cases captured, i.e., the True Positive Rate (TPR) of the system, while keeping its FPR or Alert Rate below a given threshold. For concreteness, we will focus on the former constraint, FPR, in the exposition."}, {"title": "4 Experiments", "content": "We evaluate RIFF on two public classification datasets: BAF [13], a synthetic bank account fraud dataset, and Taiwan credit [2], a credit card default dataset. We also use a private dataset, containing real transaction fraud data, which we cannot disclose due to privacy and contractual reasons. A baseline unique to this dataset is a set of rules manually tuned by data scientists allowing us to compare the rules generated by RIFF against rules handcrafted by experts. An overview of the used datasets can be seen in Table 1.\nWe sample the training set using a parameterized sample ratio into two smaller subsets, the induction and selection set. We use a sample ratio of 10% for the BAF and Industry datasets, and a sample ratio of 50% for the Taiwan credit dataset. In this step, we also parameterize the positive rate for the generated subsets, using a positive rate of 30% for all datasets. After using the induction set to train CART, FIGS and FIGU models, we extract candidate rules from the generated tree models, as described in Section 3.1. Then, the selection step of the algorithm extracts the best rules from each candidate set according to their"}, {"title": "5 Conclusion And Future Work", "content": "In this work we propose RIFF, a rule induction algorithm that builds low FPR rule sets for fraud detection by greedily extracting rules from a tree based model like CART or FIGS. We also propose a slight modification to FIGS, FIGU, that aims to lower decision tree complexity so that it can be used by the RIFF selection algorithm to generate shorter rulesets. We perform a study with real world transaction data that shows that RIFF is able to perform better than expert rules. Our experiments show that RIFF is able to maintain the predictive performance of the original models while reducing their complexity by turning them into rules. In addition, when paired with RIFF, FIGU is able to generate rule sets with fewer rules, with similar performance to rules generated by FIGS.\nWhile RIFF effectively generates a more concise and shorter rule set, it might provide complex, lengthier rules. We could expand the candidate set to also consider all nodes, instead of only leaves. This methodology draws a parallel to pruning methods, as this ideally leads RIFF into choosing more general, lower depth nodes in favour of their more specific, children nodes, similar to pruning.\nA possible way to generate a more varied and robust rule set could involve extracting rules from all the trained CART and FIGS models into an unique candidate set. Since our setup subsamples the training set into subsests, and uses them to train these models, this is equivalent to applying the RIFF selection algorithm to a Random Forest [3] or Bagging FIGS [21]."}]}