{"title": "COLD: Causal reasOning in cLosed Daily activities", "authors": ["Abhinav Joshi", "Areeb Ahmad", "Ashutosh Modi"], "abstract": "Large Language Models (LLMs) have shown state-of-the-art performance in a variety of tasks, including arithmetic and reasoning; however, to gauge the intellectual capabilities of LLMs, causal reasoning has become a reliable proxy for validating a general understanding of the mechanics and intricacies of the world similar to humans. Previous works in natural language processing (NLP) have either focused on open-ended causal reasoning via causal commonsense reasoning (CCR) or framed a symbolic representation-based question answering for theoretically backed-up analysis via a causal inference engine. The former adds an advantage of real-world grounding but lacks theoretically backed-up analysis/validation, whereas the latter is far from real-world grounding. In this work, we bridge this gap by proposing the COLD (Causal reasOning in cLosed Daily activities) framework, which is built upon human understanding of daily real-world activities to reason about the causal nature of events. We show that the proposed framework facilitates the creation of enormous causal queries (~ 9 million) and comes close to the mini-turing test, simulating causal reasoning to evaluate the understanding of a daily real-world task. We evaluate multiple LLMs on the created causal queries and find that causal reasoning is challenging even for activities trivial to humans. We further explore (the causal reasoning abilities of LLMs) using the backdoor criterion to determine the causal strength between events.", "sections": [{"title": "1 Introduction", "content": "In recent times, Large Language Models (LLMs) have shown remarkable generalization capabilities [Devlin et al., 2019, Radford et al., 2019, Brown et al., 2020]. Consequently, the ability to perform causal reasoning (often considered a core feature of intelligence [Penn and Povinelli, 2007, Pearl and Mackenzie, 2018]) has sparked research interest in the context of LLMs, aiming to answer if causal reasoning is possible with LLMs [Weber et al., 2020, Jin et al., 2023, 2024, Cohrs et al., 2023, Romanou et al., 2023, Yang et al., 2023, Mitchell et al., 2023, Vashishtha et al., 2023, Stolfo et al., 2023]. On a broader level, there are two lines of work; first, that treats the causal reasoning via learning relationships between the events that are grounded in the real world [Gordon et al., 2012, Ho et al., 2022, Ze\u010devi\u0107 et al., 2023, Zhang et al., 2023, Wang et al., 2023]. Second line of work relies on a causal inference engine and establishes relationships between variables via symbolic representation [Jin et al., 2023, 2024]. The former relies on understanding real-world events but lacks formal definitions that adhere to the causal inference theory. The latter solves the issue using a causal inference engine but uses symbolic representations not grounded in the world, making the causal queries more like a test for the understanding of causal theory. Though the first line of work includes real-world events, the causal queries are often limited and could be answered by memorizing the causal relationships between the events. Recent findings that include rigorous analysis using a causal inference engine claim LLMs to be \"Causal Parrots\" [Ze\u010devi\u0107 et al., 2023], i.e., the LLMs tend to"}, {"title": "2 Background", "content": "The Mini Turing Test proposed by Pearl and Mackenzie [2018] is designed in a question-answering format to validate the understanding of causal knowledge about a simple story. The primary feature of a mini-Turing test is the enormous number of causal queries that can be framed using the underlying causal graph, which governs the occurrence of events in the story. Due to the enormous number of causal queries, passing the mini-Turing via memorization becomes combinatorially heavy, and hence, the authors argue that it can only be beaten if one has access to the underlying causal graph governing the occurrence of events (i.e., one has the ability to reason causally about the events). In this work, though, we only consider a more straightforward case of choice-based causal triplets; we realize the number of causal queries that can be created is enormous and helps validate the causal reasoning abilities coming close to the mini-Turing test.\nd-separation: Establishing the independence of variables becomes non-trivial when dealing with complex interactions among multiple variables. d-separation [Pearl, 1988] facilitates the determination of conditional independence between two sets of nodes X and Y in a graphical model G given another set of nodes Z. d-separation asserts that X and Y, given the set Z, are d-separated if all paths for every node in X and every node in Y are blocked by conditioning on Z, denoted as $X\\perp_G Y | Z$. A path p is blocked by a set of nodes Z [Pearl et al., 2016], if and only if: 1) p contains a chain of nodes A \u2192 B \u2192 C or a fork A \u2190 B \u2192 C such that the middle node B is in Z OR 2) p contains a collider A \u2192 B \u2190 C such that the collision node B or its descendant is not in Z.\nBackdoor Criterion: A set of variables W satisfies the backdoor criterion relative to T and Y if the following are true:\n(A) W blocks all backdoor paths from T to Y i.e. blocking confounding or non-causation association paths\n(B) W doesn't contain any descendants of T\nThen, W satisfies the backdoor criterion [Pearl et al., 2016, Neal, 2020]. We make use of the backdoor criterion to estimate the causal estimand, capturing the relationship between the causal events. (Refer App. C for more detail)"}, {"title": "3 COLD (Causal reasOning in cLosed Daily activities)", "content": "We propose COLD (Causal reasoning in cLosed Daily activities) framework for testing causal reasoning abilities of natural language understanding systems such as LLMs. Fig. 3 gives an overview of the creation process. We use crowd-sourced data of script knowledge to create observational"}, {"title": "4 Experiments and Results", "content": "COLD provides a causal query dataset for evaluating LMs for causal understanding. In particular, we consider the \"Causal Query Triplets\" (Table 2) coming from compact trajectories as a base and sample the instance version coming from the same skeleton. Since it is not possible to evaluate all the possible causal queries that could be created using our framework, we use 10K samples for each activity to report our findings. For a fair comparison between various models and better reproducibility, we freeze the sampled causal query triplets and compare the success rate over the frozen samples. We evaluate via two methods. First, as done in previous work Jin et al. [2024, 2023], Chen et al. [2024], we first experiment with various LLMs using a prompt-based evaluation scheme; second, we propose other mechanisms (based on causal theory, e.g., Average Treatment Effect) that could be used to perform an in-depth analysis of evaluating causal relationships between events.\nCausal Reasoning Evaluation of LLMs via Prompts: We start with the prompt-based evaluation of recent open-weight LLMs (gpt-neo-125M, gpt-neo-1.3B, gpt-neo-2.7B [Black et al., 2021], gemma-2b [Team et al., 2024], phi-2 [Javaheripi et al., 2023], gpt-j-6B [Wang and Komatsuzaki, 2021], gemma-7b [Team et al., 2024], Llama-2-7b-chat-hf [Touvron et al., 2023], Mistral-7B-v0.1 [Jiang et al., 2023], and Meta-Llama-3-8B [Dubey et al., 2024]) We frame the prompt as a multi-choice question-answering (MCQA) objective [Robinson and Wingate, 2023]. The prompt is intentionally structured so that the LLM is intended to predict a single choice token (Such as \u201cA\u201d, \u201cB\u201d, etc.). Robinson and Wingate [2023] highlight the advantages of MCQA-based evaluation over cloze evaluation [Brown et al., 2020](where the LLMs are expected to generate the entire answer in a cloze test), leading to a significant boost in various tasks, including commonsense-based tasks. App. E, Fig. 5 presents various prompt templates for autoregressive experiments, and App. E Fig. 6 shows a few qualitative examples for the framed causal query templates. Table 3 shows the success rate obtained for various LLMs. The success rate corresponds to the percentage of queries where the LLM predicts the desired choice. We observe that reasoning causally about simple daily activities is challenging when a rigorous test is framed, validating the dependencies between the events. Overall, for the more common activities like baking a cake and going grocery shopping, the LLMs perform better when compared to activities like boarding a bus or planting a tree. We also experimented with another version of the dataset, where incorrect choice may correspond to temporally plausible but causally implausible events. The results drop significantly in this case; details and results are provided in the App. F.1.\nEvaluation using Average Treatment Effect (ATE) (\u0394): Computing the Average Treatment Effect (\u0394) helps establish the strength of causal links given a context (Eq. 1). In our setup, to estimate"}, {"title": "5 Related Work", "content": "Causal reasoning has been an active research area in the ML community [Spirtes et al., 2000a, Peters et al., 2017, Sch\u00f6lkopf et al., 2021]. Some of the initial works highlight the causal nature of events present in text [Schank, 1975] as 'causal chains'. Multiple works have considered creating benchmarks/datasets that capture causal relationships between the events described in the text (see App. Table 5). More recently, with the rapid growth of LLMs on reasoning/understanding tasks, attention has shifted to validating these general-purpose models capturing causal reasoning [Jin et al., 2023, Ze\u010devi\u0107 et al., 2023, Willig et al., 2023a, Liu et al., 2023, Willig et al., 2023b, Zhang et al., 2022a, Jin et al., 2024]. App. A.2 Table 5 shows a broad overview of the existing causal Dataset/Benchmarks presented in the NLP community. In this work, the primary focus is to bridge the gap between various lines of work that consider natural language to learn/validate/reason about causal relationships between events."}, {"title": "6 Limitations and Future Directions", "content": "One of the primary limitations of our work is the limited set of activities. Though the frameworks support generating exhaustive/enormous causal queries, finding general commonsense reasoning activities/tasks that are well understood by humans remains challenging. Moreover, creating a causal graph for an activity increases as we move toward more long-term tasks. However, as a general test of causal intelligence, our framework provides a suitable platform to validate the reasoning capabilities more rigorously. In the future, it would be interesting to sample trajectories from the observational distribution Go to create a training dataset and check if causal reasoning ability can be acquired by language modeling objectives (including other variants like presented in Lampinen et al. [2023]). We leave this detailed analysis for future endeavors. The proposed algorithm for causal triplet generation generates the simplest variant of causal queries in the form of causal triplets (also referred to as Pairwise Causal Discovery (PCD) task by [Chen et al., 2024]). More complicated causal queries can be generated, such as considering cases with common confounders, long/short causal chain dependency, etc. Moreover, taking formal definitions. (i.e., using the formal causal inference language) causal queries inspired from Jin et al. [2023, 2024] can be framed for a more rigorous analysis. Being at the initial state, we stick to the simple causal queries that provide two choices, and the task is to choose the more plausible cause. The creation of underlying causal graphs provides endless possibilities for creating varied versions of causal queries. In this work, we only consider an unconditional version of d-separation. In the future, the same causal graphs could be used to define more datasets for covering other rungs of the 'causal ladder' [Pearl and Mackenzie, 2018]."}, {"title": "7 Conclusion", "content": "In this paper, we proposed the COLD (Causal reasOning in cLosed Daily activities) framework for generating causal queries that can be used to rigorously evaluate LLMs. We performed extensive experimentation with LLMs for the task of Causal Commonsense Reasoning. Results indicate that LLMs are still far from a complete understanding of daily commonsensical activities and fail to answer causal queries when analyzed in an exhaustive manner. We believe this framework will provide a good platform for future research in understanding the causal reasoning abilities of LLMs."}, {"title": "A COLD Framework Details", "content": "The COLD framework consists of Observational Distributions represented in the form of DAGs (Go) along with the corresponding causal graphs (Ge) governing the dependency of occurrence between the events. Table 2 highlights the total number of causal queries that can be created using the framework. Table 1 shows a qualitative comparison with the COPA dataset Gordon et al. [2012] and the triplet samples coming from the COLD framework."}, {"title": "A.1 Adherence to SUTVA", "content": "In causal literature, a fundamentally acknowledged Stable Unit Treatment Value Assumption (SUTVA) [Cox, 1958, Rubin, 1980]) requires that for each unit (e.g., sequence of events), there is only one version of the non-treatment, i.e., for an event in the sequence, there lie only two versions occurring and not occurring. SUTVA plays a vital role in causal inference by ensuring that each unit's treatment assignment has a consistent impact, facilitating the accurate estimation of treatment effects. Although, in the past, researchers have created various datasets that capture the causal relationship between real-world events [Gordon et al., 2012, Du et al., 2022], the problem of achieving the SUTVA assumption has remained challenging. For example, given events (taken from the COPA dataset [Gordon et al., 2012]) E\u2081: \u201cThe teacher assigned homework to students\" and E2: \"The students groaned,\u201d it becomes challenging to define \u00acE\u2081 since there are enormous possibilities that may have occurred at the same time (in place of E\u2081) that negates E1, making it difficult to define an event of not having done something. Recent work by Zhang et al. [2022b], proposes to use multiple alterations of events for capturing \u00acE\u2081, violating the SUTVA assumption. In this work, we highlight that if we define a closed system, capturing a commonsense activity, it facilitates adherence to SUTVA assumptions as closely as possible. For example, in the activity of \"going via an airplane,\u201d one would have either \"checked-in the luggage\" (E1) or \"skipped checking-in luggage\" due to smaller bags (\u00acE\u2081). Moreover, developing a causal setup with observations has always been a challenging problem in the wild and often requires few assumptions, as the strong causal link can only be established in an ideal world where randomized controlled trials (RCTs) are feasible. In our framework, adhering to SUTVA comes naturally where, in a trajectory, an occurrence of an event can be intervened to obtain an alternate trajectory, reaching an ideal setup facilitating causal reasoning in daily commonsensical activities."}, {"title": "A.2 Comparison with previous Causal Reasoning Datasets/Benchmarks", "content": "Table 5 shows a broad overview of the existing causal Dataset/Benchmarks presented in the NLP community. We find that most of the existing set of work relies on real-world events to reason about causality in NLP, where human annotators are asked to reason causally between the nature of events. However, most of these datasets/benchmarks try to establish a connection using a simple question prompt, which may not be enough to construct the underlying causal graph. Moreover, most of the real-world grounding-based methods remain open-ended due to the events taking place in the wild, making it difficult to consider constructing a causal graph where multiple variables play a role. More recently, with increased research attention on the causal reasoning abilities of LLMs, researchers have tried framing causal queries based on a causal inference engine, requiring the underlying causal graphs. However, when constructing causal queries from prompting LLMs, natural language is used to verbalize the causal concepts in the form of symbolic variables that may not have a real-world grounding. Moreover, the created causal queries are difficult for a human with little or no knowledge of causal inference concepts. Table 5 shows a comparison of all these features in detail, where COLD satisfies all the features.\nWe realize this is a first-of-its-kind framework built over real-world events and contains the underlying causal graph. Having both the Observational Distribution (representing the enormous event sequences present in daily activity) and the manually created underlying causal graph helps facilitate an in-depth analysis of the causal reasoning abilities of LLMs. Moreover, the same framework can further be extended in various ways: 1) Extending the number of activities: In the current version of the framework, we only consider 5 daily activities to provide an in-depth analysis. In the future, those can be extended to incorporate more such activities. 2) Extending the scope of activities: The tasks"}, {"title": "A.3 Observational Graphs", "content": "Fig. 9, Fig. 10, Fig. 11, Fig. 12, and Fig. 13 shows the \u201cobservational graphs\" for the activity Baking a Cake, Going Grocery Shopping, Going on a Train, Planting a Tree, and Riding on a Bus respectively."}, {"title": "B Algorithms in the COLD Framework", "content": "In this section, we provide insights into the Algorithms used in the COLD framework. We start with Algorithm 1, which creates causal query triplets given the observational graphs G. and along with the Causal Graphs Ge.\nRemark: Temporal precedence is generally assumed essential for defining causation, and it is one of the most important clues that is used to distinguish causal from other types of associations [Mill, 1898, Hill, 1965, Pearl and Verma, 1995]. For our framework, we also consider the topologically sorted order obtained from the observational graphs and use the temporal order to define the causal query triplets, i.e., the cause events will always precede the effect events.\nCreating Causal Query Triplets: The Algorithm 1 is designed to sample all the possible causal query triplets to construct a dataset for validating causal reasoning ability over an activity. Provided the observational graphs G. and the Causal Graphs Ge for an activity, we first sample all the possible node triplets in the graph. Later, we iterate over the set of triplets and check if one of the nodes in"}, {"title": "C Backdoor Adjustments", "content": "A set of variables W satisfies the backdoor criterion relative to T and Y if the following are true\n(A) W blocks all backdoor paths from T to Y i.e. blocking confounding or non-causation association paths\n(B) W doesn't contain any descendants of T"}, {"title": "D Experiments and Results", "content": "D.1 Compute Resources\nWe perform all the experiments using a machine with 5 NVIDIA A100 GPUs. We use only the open-weight models with frozen parameters to present the results for better reproducibility in the future.\nD.2 Evaluation using Average Treatment Effect (ATE)\nEstablishing Causal Relationships: To validate the causal reasoning ability, the MCQA-based approach can be further extended to estimate the causal estimation and denote the causal strengths between the events. Establishing cause-and-effect relationships can be achieved through various statistical analyses. The strength of cause-and-effect relationships is approximated by statistically analyzing events' behavior using observational data (PC-Algorithm, Spirtes et al. [2000b]). Moreover, some of the recent works [Wang et al., 2023] highlight the role of context in determining the causal relationships between the events. To extend our analysis of causal reasoning abilities in the proposed framework, we use the backdoor adjustments in LLMs as explained in the main paper. Moreover, we also perform an interesting analysis of the observational graphs for estimating A statistically.\n1) Through Original Trajectories: DeScript Wanzare et al. [2016] collects data by considering ~ 100 ESDs written by different crowd-sourced workers. We use the original Trajectories (ESDs) To written by humans present in the DeScript dataset. These ESDs provide the original flow in the graph directly coming from crowdsourced workers. We consider these as the original trajectories To. Applying the backdoor criterion (Eq. 2) over these trajectories T. An interventional distribution similar to the previous section is computed considering the likelihood of occurrence of E2 under each treatment (E\u2081 and \u00acE\u2081) for only these trajectories T. These estimations are further used to compute the treatment effect using the Eq. 1. We denote the causal risk difference (\u25b3) computed with To as \u0394o.\n2) Through Observational Graphs: The observational graphs provide a proxy for the underlying knowledge about the activity, covering all possible sets of events, i.e., starting from the start node, one can trace multiple trajectories that will essentially define the way of performing the activity. For every pair of connected events (ei, ej), the edge between them represents the probable transition from e\u017c to ej with some non-zero probability. However, a noteworthy point is that the transition probability between two connected events (ei, ej) can vary depending on the design choices/transition function T(ei, ej) \u2192 (0,1]. We define this transition function in two ways: 1) Uniform Node Transition (Tn): The transition probability from current node er to next probable events ej \u2208 Eij would be uniform that is $T(e_i, e_j) = \\frac{1}{\\|O_z\\|}$, where |0z| represents number of outgoing edges from event e\u00bf. (i.e., assuming after an event, the choice of the next event is uniform from the possible events). 2) Uniform Trajectory Transition (Tt): Another way to take the set of events in an activity (trajectory) is by considering all the possible paths being equally probable, i.e., across the entire population the same activity will be represented with one of the possible trajectories. Hence we can define the transition function with each trajectory t\u2081 = (estart, e2, ..., lend) (sequence of events from starting to ending) having the same probability, i.e.:\n$\\frac{1}{n} \\sum p_M(E_2 | E_1, z=t)$", "Equation(s)": ["Equation(s): T(e_i, e_j) \\rightarrow (0,1]", "Equation(s): p(t_i) = p(t_j) \\forall t_i, t_j \\in T", "Equation(s): p(t_i) = \\Pi T(e_l \\rightarrow e_m)", "Equation(s): p(E_2|E_1) = \\sum \\Pi T(e_l \\rightarrow e_m)", "Equation(s): p(E_2|E_1) = \\sum \\Gamma (E_1 \\rightarrow E_2)"]}, {"title": "E Prompt Templates for Language Model based Experiments", "content": "We present the various prompt templates used to estimate the temporal link between the events in Figure 7. For BERT-based models, we use the MLM-trained models for predicting the masked token given a sentence (Previously, a similar approach was adopted by Zhang et al. [2022b]). In contrast, for autoregressive models, we frame the prompt as a question-answer objective, taking inspiration from [Robinson and Wingate, 2023], where a multiple-choice-based question is framed to predict the answer in the form of the option IDs. The prompt is intentionally structured so that the LLM is intended to predict a single token (Such as \"A\", \"B\", etc.). Robinson and Wingate [2023] highlights the advantages of MCQA-based evaluation over cloze evaluation (where the LLMs are expected to generate the entire answer in a cloze test), leading to a significant boost in various tasks, including commonsense-based tasks.\nFor our prompt-based evaluation experiments over the generated causal triplets, we follow the same MCQA-based strategy and frame the prompts accordingly for a fair evaluation. Figure 5 presents various prompt templates for autoregressive experiments, and Figure 6 shows a few qualitative examples for the framed causal query templates."}, {"title": "F Additional Results", "content": "F.1 Temporally Plausible Choices in Causal Triplets\nSome of the initial studies [Do et al., 2011] highlight the difficulty in choosing between the causal-effect events and temporal events (that occur in close proximity to the premise event), i.e., temporal relationships are sometimes considered as a causal relationship by human annotators. We also create another version of created causal triplets where the wrong choices are replaced by temporally near nodes (nodes that are at a one-hop distance from the premise node). We call these \u2018causally hard triplets. Note the temporal nodes are obtained from the observational graphs Go. Table 7 shows the performance comparison with causal triplets and causal-temporal triplets versions of the same queries. We observe a significant performance drop on the causal-temporal triplets version for most models, highlighting the increased confusion."}]}