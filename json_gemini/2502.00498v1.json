{"title": "MetaOpenFOAM 2.0: Large Language Model Driven Chain of Thought\nfor Automating CFD Simulation and Post-Processing", "authors": ["Yuxuan Chen", "Xu Zhu", "Hua Zhou", "Zhuyin Ren"], "abstract": "Computational Fluid Dynamics (CFD) is\nwidely used in aerospace, energy, and\nbiology to model fluid flow, heat transfer,\nand chemical reactions. While Large\nLanguage\nModels (LLMs) have\ntransformed various domains, their\napplication in CFD remains limited,\nparticularly for complex tasks like post-\nprocessing. To bridge this gap, we\nintroduce MetaOpenFOAM 2.0, which\nleverages Chain of Thought (COT)\ndecomposition and iterative verification to\nenhance accessibility for non-expert users\nthrough natural language inputs. Tested on\na new benchmark covering simulation\n(fluid flow, heat transfer, combustion) and\npost-processing (extraction, visualization),\nMetaOpenFOAM 2.0 achieved\nan\nExecutability score of 6.3/7 and a pass rate\nof 86.9%, significantly outperforming\nMetaOpenFOAM 1.0 (2.1/7, 0%).\nAdditionally, it proved cost-efficient,\naveraging $0.15 per case. An ablation\nstudy confirmed that COT-driven\ndecomposition and iterative refinement\nsubstantially improved task performance.\nFurthermore, scaling laws showed that\nincreasing COT steps enhanced accuracy\nwhile raising token usage, aligning with\nLLM post-training scaling trends. These\nresults highlight the transformative\npotential of LLMs in automating CFD\nworkflows for industrial and research\napplications. Code is available at\nhttps://github.com/Terry-\ncyx/MetaOpenFOAM", "sections": [{"title": "1 Introduction", "content": "Computational Fluid Dynamics (CFD) is a\ncomputational technique that utilizes numerical\nmethods and physical models to solve fluid flow,\nheat transfer, chemical reactions, and other related\nprocesses (Blazek, 2015). It is widely applied in\nfields such as aerospace, automotive, energy, and\nbiology (An et al., 2020; Mao et al., 2023; Wang et\nal., 2011; Wei et al., 2023). Current industrial CFD\nsoftware, such as Fluent (Manual, 2009) and\nCOMSOL (Multiphysics, 1998), typically rely on a\nGUI interface where users manually select\nappropriate numerical methods and physical\nmodels to perform simulations. However, with the\nincreasing integration of models across various\nfields, the complexity of these software interfaces\nhas grown significantly. Non-expert users may\nstruggle to make informed choices regarding\nmodel selection, leading to a lack of user-\nfriendliness. Meanwhile, significant amounts of\nCFD simulation data have already been generated\nin industry by experts for specific cases.\nLeveraging these case libraries could help non-\nexpert users quickly perform relevant CFD\nsimulations. Recently, with the advancement of\nNatural Language Processing (NLP) technologies,\nespecially the emergence of Large Language\nModels (LLMs) (Akata et al., 2023; Du et al., 2023;\nHong et al., 2023; Wang et al., 2024; Wang et al.,\n2023; Zhuge et al., 2023), unprecedented potential\nhas been demonstrated in making CFD simulation\nsoftware more accessible. These models have made\nit possible to apply CFD case libraries and develop\nLLM-driven CFD simulation software using\nnatural language as input.\nSince the discovery of pre-trained scaling laws\n(Kaplan et al., 2020), which describe the\nrelationship between model size, dataset size, and\nperformance, LLMs have undergone rapid\ndevelopment, resulting in the emergence of\nremarkable models such as GPT-40 (OpenAI,\n2024a), Llama 3.1 (AI, 2024), and Qwen 2.5 (Yang\net al., 2024). However, as the development of pre-\ntrained scaling laws reached a bottleneck (Kumar\net al., 2024), OpenAI introduced the GPT-01 model\n(OpenAI, 2024b), signaling the discovery of post-\ntrained scaling laws. The GPT-01 model integrates"}, {"title": "2 Methodology", "content": "moves on to the next subtask, continuing ICOT\nuntil all subtasks are completed.\nAfter all subtasks are executed, an additional\nLLM-assisted verification step is performed. This\nstep evaluates the outputs against various criteria,\nincluding user requirements, physical accuracy,\nflow characteristics, numerical accuracy and\nboundary condition consistency. If the results are\ndeemed unsatisfactory, the verification process\nidentifies which subtask requires correction. ICOT\nis then resumed from that specific subtask, iterating\nuntil the LLM-assisted verification is successful.\nIn MetaOpenFOAM 1.0 (Chen et al., 2024), the\nArchitect, InputWriter, Runner, and Reviewer\nagents were organized into a single QDCOT\nfollowed by a single ICOT. The framework lacked\nLLM-assisted verification and had limited\nfunctionalities, focusing solely on decomposing\ninput files, writing/rewriting input files, running\nsolver and reviewing errors. Compared to\nMetaOpenFOAM 1.0, MetaOpenFOAM 2.0\nframework offers a more advanced and versatile set\nof COT methodologies and agent functionalities,\nenabling it to handle a broader range of CFD\nsimulation and post-processing tasks more\neffectively. The RAG technology from\nMetaOpenFOAM 1.0, which integrates\na\nof OpenFOAM\nto enhance agents' task", "title2": "2.1 MetaOpenFOAM 2.0 Framework", "content2": "Figure 1 illustrates how MetaOpenFOAM 2.0\naddresses complex CFD simulation and post-\nprocessing tasks using COT with question\ndecomposition (QDCOT) and iterative verification\nand refinement (Iterative COT or ICOT).\nFirst, MetaOpenFOAM 2.0 employs two\nsequential QDCOT steps, each facilitated by an\nArchitect agent to decompose tasks. Initially, the\nuser requirements are divided into two primary\ntasks: CFD simulation and CFD post-processing\ntask. Each primary task is further broken down into\nexecutable subtasks, including writing CFD input\nfiles, executing simulation Linux commands,\nexecuting post-processing Linux commands, and\nexecuting post-processing Python scripts.\nFor each subtask, an ICOT process is applied.\nWithin each ICOT, several specialized agents\ncollaborate: the InputWriter agent writes and\nrewrites the input files, Linux commands, or\nPython scripts required for the subtask; the Runner\nagent executes the relevant Linux commands; and\nthe Reviewer agent examines errors reported by the\nRunner and provides feedback to the InputWriter\nfor further refinements. Once a subtask passes the\nReviewer's checks without errors, the process"}, {"title": "3 Experiment", "content": "performance with minimal user intervention, is\nalso retained in MetaOpenFOAM 2.0.\nThe detailed algorithm of the general CFD\nsimulation workflow with COT is presented in\nAppendix A.1.", "title2": "3.1 Setup", "content2": "MetaGPT v0.8.0 (Hong et al., 2023) was chosen\nfor the integration of different agents, while\nOpenFOAM 10 (Jasak et al., 2007) was employed\nfor CFD simulations due to its stability and\ndependability as an open-source solver. GPT-40\n(OpenAI, 2024a) was selected as the primary LLM,\nowing to its exceptional performance. To minimize\nrandomness in the generated output, the\ntemperature parameter, which controls the degree\nof randomness in LLM-generated text, was\nconfigured to 0.01, ensuring more deterministic\nand focused results. The impact of temperature\nsettings on model performance is discussed in\n(Chen et al., 2024).\nIn terms of RAG, LangChain v0.1.19 (Chase,\n2022) facilitated the connection between the agents\nand the database. The FAISS vector store (Douze\net al., 2024), recognized for its high efficiency and\nease of use, was utilized as the vector store for the\ndatabase, and OpenAIEmbeddings were chosen for\nembedding the data segments. The \u201csimilarity\"\napproach was employed to identify and match\nrelated chunks of data. The simplest stacking\napproach was used, combining retrieved\ndocuments with user input messages.", "title3": "3.2 Benchmarking Natural Language Input\nfor CFD Simulation and Postprocessing", "content3": "The only public benchmark for CFD simulations,\nreleased with MetaOpenFOAM 1.0 (Chen et al.,\n2024), lacks post-processing tasks. This study\nintroduces a new benchmark covering both CFD\nsimulation and post-processing.\nPost-processing tasks are categorized into\nvisualization (e.g., contour plots, line graphs) and\nextraction (e.g., computing averages, extrema).\nThe benchmark includes 13 user requirements,\nwith six focusing on PitzDaily post-processing\n(e.g., extracting max y+, Courant number, velocity\ncontours) and seven covering post-processing for\ndifferent simulations, including fluid flow (HIT),\nheat transfer (BuoyantCavity), and combustion\n(CounterFlowFlame). These cases, adapted from", "title4": "3.3\nEvaluation Metrics of MetaOpenFOAM\n2.0", "content4": "in\nCurrently, the evaluation metrics\nMetaOpenFOAM 1.0 (Chen et al., 2024) are only\napplicable to cases where the user requirement is a\nCFD simulation task and do not account for post-\nprocessing tasks or the overall evaluation based on\nLLM. Therefore, for the newly established\nbenchmark that includes both CFD simulation and\npost-processing tasks, it is necessary to develop\nnew evaluation metrics to assess the performance\nof MetaOpenFOAM 2.0. For CFD software with\nnatural language input, the performance can be\nevaluated using the following three metrics: the\nfirst two metrics, A and B, are used to evaluate\nsingle experiments, while the third metric, C, is\nused to assess multiple experiments.\nSingle experiments can be evaluated by the\nfollowing metrics:\n(A) Executability:\nThis metric evaluates the results of\nMetaOpenFOAM 2.0 on a scale from 0 (failure) to\n7 (flawless). Scores from 0 to 3 correspond to the\nevaluation of simulation tasks, while scores from 4\nto 5 correspond to the evaluation of post-\nprocessing tasks. A score of 6 represents the\nevaluation of overall results by the LLM, and a\nscore of 7 involves human judgment. Specifically:\nA score of '0' indicates grid generation failure; '1'\nindicates grid generation success but running\nfailure; '2' indicates that the case is runnable but\ndoes not converge; '3' indicates that the case runs to\nthe endTime specified in the controlDict; A score\nof '4' indicates that the post-processing executable\ncommand runs successfully and generates the post-\nprocessing files; A score of '5' indicates that the\nPython script successfully reads the CFD\nsimulation/post-processing result files and\ncompletes the post-processing tasks; A score of '6'\nmeans the LLM reviews the results generated by\nthe Python script (e.g., contours, extracted values)\nand assesses their validity based on factors such as\nuser requirements, physical accuracy, flow\ncharacteristics, numerical accuracy and boundary\ncondition consistency; A score of '7' indicates\nflawless results, requiring human judgment to\nverify whether the results are physically accurate\nand meet all user requirements.", "title5": "3.4 Main Results", "content5": "MetaOpenFOAM 2.0 demonstrates strong\nperformance across 13 CFD simulation and post-\nprocessing tasks, achieving an average\nExecutability score of 6.3 and a Pass@1 rate of\n86.9%. To reduce variability, all results were\naveraged over 10 independent runs. In terms of\nefficiency, the model consumes an average of\n36,448 tokens per test case, with an estimated cost\nof $0.15 per case-significantly lower than hiring\ndomain experts. These results underscore its\npotential to lower entry barriers, reduce labor costs,\nand enhance the efficiency of CFD case setup for\ncomplex tasks. Detailed results can be found in\nAppendix A.3."}, {"title": "4 Discussion", "content": "This section conducts an ablation analysis to\nevaluate the necessity of the new modules\nintroduced in MetaOpenFOAM 2.0. (The role of\nthe LLM-assisted verification module is explained\nin Appendix A.5) Subsequently, based on the\nresults of the ablation study, a scaling law is found\nto describe the relationship between token usage\nand Executability.", "title2": "4.1 Ablation Analysis", "content2": "This subsection evaluates COT's significance from\ntwo distinct perspectives: QRCOT and ICOT. By\nselectively removing specific modules, the analysis\ndemonstrates the contribution of each approach to\nthe overall performance.", "title3": "4.2 Scaling laws in MetaOpenFOAM", "content3": "During the ablation study, we observed that\nExecutability increases as the number of QDCOT\nand ICOT increases, aligning with the post-trained\nscaling law proposed by OpenAI o1 (OpenAI,\n2024b).\nBased on the results in Section 4.1, there is a\nclear positive correlation between the number of\nCOT with question decomposition and both\nExecutability and token usage for non-iterations."}, {"title": "5 Conclusion", "content": "MetaOpenFOAM 2.0 enhances the automation\nof CFD simulations and post-processing through\nan LLM-driven multi-agent system. Building on\nMetaOpenFOAM 1.0, it integrates COT with\nproblem decomposition and iterative verification\nand refinement, making complex CFD tasks more\naccessible via natural language.\nMetaOpenFOAM 2.0 was evaluated on\nbenchmark tasks, including fluid flow, heat transfer,\ncombustion, and post-processing (visualization and\nextraction), achieving an executability score of\n6.3/7 and a pass rate of 86.9%, far surpassing\nMetaOpenFOAM 1.0 (2.1/7, 0%). With an average\ncost of $0.15 per case, it offers a highly cost-\neffective alternative to domain experts.\nThe ablation study confirmed that COT-based\ndecomposition and iterative verification\nsignificantly improve executability. While\ndecomposition reduces iteration-related token\nusage, it increases non-iterative token consumption.\nIterative verification further enhances task success\nby refining outputs at the cost of more tokens.\nScaling law analysis revealed that increasing\ndecomposition and verification steps improves\nexecutability while raising token usage, aligning\nwith LLM post-training trends. These findings\nhighlight MetaOpenFOAM 2.0's potential in\nautomating CFD workflows, providing an efficient\nand accessible solution for industrial and research\napplications."}, {"title": "A Appendices", "title2": "A.1 General CFD Simulation Workflow with\nCOT", "content2": "language inputs. This algorithm is not limited to the\nOpenFOAM CFD software platform, nor is it\nrestricted to CFD simulation and CFD post-\nprocessing tasks.\nThe algorithm begins with a QDCOT step to\ndecompose the user requirements. For CFD,\nassuming the geometry is already defined, a\ncomplete simulation process typically involves\ngrid generation, pre-processing (e.g., calculating\nthe 1D laminar flamelet in the flamelet-generated\nmanifold (FGM) model), initialization, simulation,\nand post-processing. In MetaOpenFOAM 1.0, this\nentire process was not decomposed into separate\ntasks. However, in MetaOpenFOAM 2.0, the\nprocess is divided into two main tasks: CFD\nsimulation and CFD post-processing. The former\nencompasses grid generation, pre-processing,\ninitialization, and simulation, while the latter\ncovers post-processing. In addition to these tasks,\nthere may also be tasks such as sensitivity analysis,\nparameter calibration, and geometry optimization,\nwhich are performed based on the results of the\nCFD simulation.\nThe first QDCOT step decomposes the overall\nprocess, and once the tasks are identified, a second\nQDCOT is performed based on the number of\nsystems to be executed, resulting in the\nidentification of subtasks. For example, the post-\nprocessing task may be difficult to complete using\nonly Linux commands. Therefore, in\nMetaOpenFOAM 2.0, this task is divided into two\nsubtasks: Postprocessing with command and\nPostprocessing with Python script, thus facilitating\nmore efficient task completion. The number of\nsubtasks created depends on the number of systems\nto be executed.\nNext, each subtask undergoes ICOT. It is important\nto note that the agents within each ICOT must be\nadapted according to the specific subtask. For\ninstance, in grid generation, the Reviewer agent not\nonly reviews error messages when a failure occurs\nbut also checks the quality parameters of the grid\na successful run. Only when the grid\nthe required standards can the\nto the next subtask. Once all\nand LLM-assisted\nCFD\nlanguage input is\nabove\ngeneration meets\nprocess proceed\nsubtasks are completed\nverification is successfully passed\nsimulation based on natural\nconsidered complete."}, {"title2": "A.2 Detailed Benchmarking Natural Language\nInput for CFD Simulation and Postprocessing", "content2": "\u2460PitzDaily, Max yplus: do a RANS simulation of\nincompressible pitzDaily flow using pimpleFoam\nand extract max yplus at latest time through post-\nprocessing.\n\u2461PitzDaily, Max Co: do a RANS simulation of\nincompressible PitzDaily flow using pimpleFoam\nand extract max Courant number at latest time\nthrough post-processing.\n\u2462PitzDaily, Plot profile of U in X = 0.05 m: do a\nRANS simulation of incompressible PitzDaily\nflow using pimpleFoam and plot the X velocity at\nX = 0.05 m with spatial Y coordinate as the axes at\nlatest time through post-processing.\n\u2463PitzDaily, Plot contour of U: do a RANS\nsimulation of incompressible PitzDaily flow using\npimpleFoam with inlet velocity = 0.1 m/s, and plot\nU contour through post-processing.\nPitzDaily, Plot contour of U and streamlines: do\na RANS simulation of incompressible PitzDaily\nflow using pimpleFoam with inlet velocity = 0.1\nm/s, and then carry out post-processing to generate\na 2D contour plot of the velocity distribution in the\nX-direction, overlaid with streamlines. The X-\ndirection velocity contours should be drawn using\na rainbow color map to represent the variation in\nvelocity magnitude, while the streamlines should\nillustrate the flow direction. The final plot should\ndisplay spatial coordinates as axes, with both the\nX-direction velocity contours and streamlines on\nthe same figure, ensuring proper labeling of the\ncolorbar, axis, and units.\nCounterFlowFlame Max T: do a 2D laminar\nsimulation of counterflow flame using\nreactingFoam in combustion with grid 50*20*1\nand extract max temperature at latest time through\npost-processing.\nCounterFlowFlam plot contour of T e: do a 2D\nlaminar simulation of counterflow flame using\nreactingFoam in combustion with grid 50*20*1\nand plot 2D contour of temperature distribution at\nlatest time with spatial coordinates as the axes\nthrough post-processing.\nCounterFlowFlame plot profile of T at Y = 0 m:\ndo a 2D laminar simulation of counterflow flame\nusing reactingFoam in combustion with grid\n50*20*1 and plot temperature at Y = 0 m with\nspatial X coordinate as the axes at latest time\nthrough post-processing.\nHIT plot X-direction velocity: do a DNS\nsimulation of incompressible forcing\nhomogeneous isotropic turbulence with Grid 32^3\nusing dnsFoam and plot 2D contour of X-direction\nvelocity at latest time with spatial coordinates as\nthe axes through post-processing.\n\u2469HIT average TKE: do a DNS simulation of\nincompressible forcing homogeneous isotropic\nturbulence with Grid 32^3 using dnsFoam and use\nthe calculated velocity field U at latest time to\ncompute the average turbulent kinetic energy\nacross the entire domain with the formula\naverage(1/2*U^2) through post-processing.\n11 Cavity plot TKE: do a 2D RANS simulation of\nincompressible cavity flow using pisoFoam, with\nRANS model: RNGkEpsilon, and plot 2D contours\nof turbulent kinetic energy distribution with spatial\ncoordinates as the axes through post-processing.\n2 BuoyantCavity plot contour of T: do a RANS\nsimulation of buoyantCavity using buoyantFoam,\nwhich investigates natural convection in a heat\ncavity with a temperature difference of 20K is\nmaintained between the hot and cold; the\nremaining patches are treated as adiabatic. And the\npostprocessing task is to plot 2D contour of\ntemperature distribution with spatial coordinates as\nthe axes through post-processing.\n13 BuoyantCavity max X velocity: do a RANS\nsimulation of buoyantCavity using buoyantFoam,\nwhich investigates natural convection in a heat\ncavity with a temperature difference of 20K is\nmaintained between the hot and cold; the\nremaining patches are treated as adiabatic. And the\npostprocessing task is to extract the max velocity in\nX direction through post-processing.", "title3": "A.3 Detailed performance and test examples of\nmain results", "content3": "Table 2 supplements the results presented in\nTable 1. In this table, Simulation Iterations refers\nto the iterations used for simulation,\nPostprocessing Iterations represents the iterations\nused for postprocessing with commands, and\nPython Script Iterations indicates the iterations for\npostprocessing with Python scripts. Prompt Tokens\nrefer to the tokens consumed by the input prompts\nprovided to the LLM, while Completion Tokens\ndenote the tokens generated in the LLM's output.\nAs shown, the majority of iterations occur during\nthe simulation stage, suggesting that more errors\nare encountered during the simulation, whereas\nfewer occur during postprocessing. The ratio of"}, {"title3": "A.4 Matching with low similarity", "content3": "Although most of the simulation tasks in the\nbenchmarking\nfor CFD simulation and\npostprocessing can be found in OpenFOAM\ntutorials, there are instances where the system may\nmatch a case with low similarity. For example, in\nthe HIT case, as shown in Figure 10, the system\nmight be affected by randomness and match two\ndifferent cases: boxTurb16, which is the most\nsimilar case in the database, and cyclone, which has\nlow similarity to the CFD task. However, even\nwhen cyclone is matched, the CFD task named HIT\nstill has a relatively high probability of passing the\ntest. For instance, in the HIT test, there is a 50%\nchance of matching cyclone, but the actual pass\nrate reaches 75%. This demonstrates that\nMetaOpenFOAM has a certain capability to\ncomplete CFD simulation and post-processing\ntasks, even when matching cases with lower\nsimilarity.", "title4": "A.5 LLM-assisted verification", "content4": "In this appendix, one case was selected from the\npostprocessing tasks of visualization and extraction\nto illustrate the role of LLM-assisted verification.\nA. LLM-assisted verification for postprocessing\nin extraction\nFor example, when performing the task,\nPitzDaily: Extract max Yplus, a snippet of the\ngenerated Python script is as follows:"}]}