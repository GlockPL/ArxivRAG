{"title": "Modeling News Interactions and Influence for Financial Market Prediction", "authors": ["Mengyu Wang", "Shay B. Cohen", "Tiejun Ma"], "abstract": "The diffusion of financial news into market prices is a complex process, making it challenging to evaluate the connections between news events and market movements. This paper introduces FININ (Financial Interconnected News Influence Network), a novel market prediction model that captures not only the links between news and prices but also the interactions among news items themselves. FININ effectively integrates multi-modal information from both market data and news articles. We conduct extensive experiments on two datasets, encompassing the S&P 500 and NASDAQ 100 indices over a 15-year period and over 2.7 million news articles. The results demonstrate FININ's effectiveness, outperforming advanced market prediction models with an improvement of 0.429 and 0.341 in the daily Sharpe ratio for the two markets respectively. Moreover, our results reveal insights into the financial news, including the delayed market pricing of news, the long memory effect of news, and the limitations of financial sentiment analysis in fully extracting predictive power from news data.", "sections": [{"title": "1 Introduction", "content": "Media coverage and news events have been shown to influence market returns (Tetlock, 2007; Sattler, 2013). However, the process through which news diffuses into market prices is complex. The influence of news items on market outcomes varies, affected by various market conditions (Cheung et al., 2019; Hirshleifer and Sheng, 2022). Since existing studies often adopt a simplified approach by treating available news data holistically and investigating its overall effect on the market (Wang et al., 2018; Lopez-Lira and Tang, 2023), the nuanced information contained within individual news items is overlooked. Consequently, parsing the market information diffusion process in detail by considering the impact of each news item emerges as a potential approach to enhance market prediction.\nHowever, evaluating the influence of individual news items is challenging. News does not exist in isolation but is connected with other information. Studies indicate that information diffusion within the market is a gradual process (Albert Jr and Smaby, 1996; Kerl and Walter, 2007). Financial news exhibits a \u201clong memory effect\", a persistent impact over time (Ho et al., 2013). During this dissemination process, the influence of an individual news item can be further modulated by interactions with other news items. Given the sheer volume of news, evaluating the market impact of news items becomes even more challenging.\nThis paper aims to address this gap. The domain of financial news presents an excellent testbed for not only improving market prediction but also enhancing our understanding of how to effectively leverage multi-modal data. Modeling news interactions requires a more comprehensive use and exploration of multi-modal data in the form of both numerical and textual data from market and news sources. It also requires considering established market theories (see \u00a72), such as the efficient market hypothesis and information diffusion theory.\nWe develop FININ, a Financial Interconnected News Influence Network to build interactions between news reports and analyze their diverse impact on markets. The model comprises two key"}, {"title": "2 Related Work", "content": "News-based Market Prediction. Financial news has been proven to significantly affect market movements, impacting investor sentiment and decision-making (Tetlock, 2007; Barber and Odean, 2008; Calomiris and Mamaysky, 2019). Advancements in data mining and natural language processing (NLP) have enabled the analysis of news data, including tweets and online news, for market prediction (Dewally, 2003; Li, 2010; Xu and Cohen, 2018). The extraction of events and sentiments from news text has progressed substantially (Xu et al., 2021; Hu et al., 2019). Furthermore, progress in deep learning has led to the development of effective neural network structures, such as multi-modal LSTM models (Li et al., 2020; Dong et al., 2020), ensemble models (Li and Pan, 2022), and hierarchical attention models (Luo et al., 2023), which leverage news sentiments for stock prediction. However, existing research often focuses on the market influence of overall news, neglecting the nuanced information and varying impacts of individual news items. While some studies recognize the diverse relationships between news and prices (Huynh and Smith, 2017) and attempt to quantify the varying market impact of news (Wang and Ma, 2024), fewer have explored the interactions between multiple news items. Additionally, more complex aspects related to the news impact on market, such as the information diffusion process (Bekiros et al., 2017), are not fully considered during the prediction process.\nMarket Information Diffusion. The Efficient Markets Hypothesis (EMH) posits that stock prices instantaneously reflect all available information, leaving no room for excess returns (Fama, 1970). However, real-world complexities challenge this ideal situation. In contrast, the information diffusion hypothesis (IDH) suggests that news-induced information is gradually incorporated into prices, leading to delayed market reactions (Kerl and Walter, 2007; Zhang et al., 2016). Research highlights the enduring impact of news on market prices over an extended period (Ray and Tsay, 2000; Christensen and Nielsen, 2007), requiring the analysis of the relationship between news and price changes. Moreover, news items are not isolated in their effect on the market but are interconnected, with their market impact influenced by one another (Yu et al., 2019; Agarwal et al., 2019). Therefore, effectively capturing the complexities of the information diffusion"}, {"title": "3 Preliminaries", "content": "3.1 Notation and Problem Formulation\nIn our approach, we define d as a trading day. Our data consists of daily market data Md and news report data Rd. Both data sources contain textual information (denoted by *(t)) and numerical information (denoted by *(n)). The market data, Ma = (m(t)d , m(n)d, ma), consists of textual information m(t)d, including market descriptions and a list of most related companies, and numerical information m(n)d, comprising daily market prices. The daily news data Rd = (Rd,1, Rd,2, ..., Rd, Na) contains multiple news reports, where each Rd,i represents information associated with the i-th news item on day d, and Na represents the news volume on day d. Each news report Rd,i = (r(t)d,i r(n)d,i), comprises textual information r(t)d,i, which includes the new news headline, and numerical information r(n)d,i, representing the news market sentiment scores.\nThis paper focuses on daily market prediction. The target variable yd represents the daily market trend, defined as a binary value where 1 signifies a price increase and 0 indicates no change or a decrease between day d and day d + 1. Our objective is to effectively use the information from the prior t days up to day d, including both market data (Md\u2212t+1, ..., Md\u22121, Md) and news data (Rd-t+1,..., Rd\u22121, Rd), to predict yd.\n3.2 Data\nWe use two major stock market datasets: the Standard and Poor's 500 (S&P 500) Index and the NASDAQ 100 Index. Additionally, we use the Thomson Reuters News Analytics (TRNA) dataset, comprising over 2.7 million news items. The volume of our news data is significantly larger, at least 10 times greater, than those used in previous studies (Mohan et al., 2019; Lopez-Lira and Tang, 2023; Luo et al., 2023). Furthermore, unlike their online-collected news data, our dataset is sourced from industry practice, ensuring higher quality and more comprehensive market information. Detailed information about these datasets is presented in \u00a7A\nWe collected daily S&P 500 and NASDAQ 100 prices from 2003 to 2018 as market numerical data m(n)m. Also, we collected the descriptions of these two markets and their constituent companies' names as textual data m(t)a. For TRNA dataset, we consider headlines as news textual data r(t)d,i and the sentiment scores as news numerical data r(n)d,i"}, {"title": "4 Method", "content": "We have designed the FININ model to evaluate the impact of news on price changes. The FININ model comprises two primary components: a data fusion encoder and a market-aware influence quantifier. By leveraging both textual and numerical data, FININ can capture the mutual influence between these disparate pieces of information. Figure 2 illustrates an overview of the FININ model.\n4.1 Data Fusion Encoder\nExisting news-based market prediction methods primarily focus on the relationship between overall news and price changes, leveraging either market sentiment analysis (Wang et al., 2018; Jing et al., 2021; Lopez-Lira and Tang, 2023) or news text processing (Xu and Cohen, 2018; Luo et al., 2023). However, these approaches have two main limitations. First, sentiment analysis alone may fail to capture nuanced semantic information in the news text, while text processing may lack insights into the market influence conveyed by sentiment scores. Second, these methods treat all news for one prediction as a single entity, potentially overlooking the varying relationships between individual news items and market movements.\nIn contrast, our proposed FININ model treats each news report as a distinct unit and uses both types of data, capturing more comprehensive market-related information conveyed by individual news reports. The data fusion encoder tackles the multi-modal inputs by encoding various data types from market conditions and news items into meaningful features. It first encodes inputs into features individually and then integrates features from the same input unit (market snapshot or news item) into fusion features.\nThe core idea of our encoder is to design encoding functions tailored to the nature of each data source, ensuring consistent and differentiated processing. For textual data from market descriptions mat) and news headlines r(t)d, we use the same encoding function to create unified semantic representations across different text sources. We leverage a pre-trained language model (LM), denoted by lm(\u00b7), coupled with an encoding layer e(t)(.),"}, {"title": "4.2 Market-aware Influence Quantifier", "content": "Unlike existing works that treat news data holistically to obtain daily features, FININ uses independent features for each news item to capture market insights. This section describes the Market-aware Influence Quantifier, which leverages financial theories to better reflect real-world market dynamics.\nFirstly, the market information diffusion theory (Kerl and Walter, 2007; Zhang et al., 2016) suggests that information pieces influence each other. To capture these interactions, we use an attention layer (Vaswani et al., 2017) to refine news encodings r(e)d,i into context-aware features r(f)d,i. These context features still focuses on the i-th news of day d but incorporate information from the entire daily news corpus, making each news report \u201caware\" of the others.\nSecondly, the efficient market hypothesis posits that all relevant information is reflected in market prices. To account for this connection, we introduce another attention layer. In contrast to the first layer that builds relationships between all input states, this layer focuses solely on the connections between the market state and news items. In this"}, {"title": "4.3 Market Prediction", "content": "After the data encoding and market influence quantifying stages, the final step of FININ is market prediction. We collect the encoded market and news representations for the past t days, denoted as (m(e)d\u2212t+1,..., m(e)d) and (r(f)d\u2212t+1,...,r(f)d), respectively. These representations are fed into a prediction structure, denoted as pred(\u00b7,\u00b7), which aims at forecasting market trends:\n\u0177d = pred((m(e)d\u2212t+1,..., m(e)d),\n(r(f)d\u2212t+1,...,r(f)d)).\nThe predictor architecture in FININ is flexible, allowing integration with various widely used stock prediction structures, such as Multi-Layer Perceptron (MLP), Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) networks (Jing et al., 2021; Jiang, 2021). Our experiments suggest that the informative features generated by FININ enhance performance regardless of the specific structure. Given the frequent use of MLPs, as subsequent layers due to their simplicity and efficiency (Orimoloye et al., 2020; Hu et al., 2020), we adopt an MLP for constructing the final FININ model to maintain simplicity and effectiveness."}, {"title": "5 Experiment Settings", "content": "5.1 Language Models\nFinancial language differs from general text due to its area-specific vocabulary and domain knowledge (Araci, 2019). While numerous pre-trained LMs exist, their performance on general tasks may not accurately reflect their effectiveness for financial tasks. To investigate how different LMs affect the modeling of market information interactions, we experiment with four different types of LMs within the FININ model for textual data encoding. These LMs include RoBERTa, FinBERT, BGE, Llama2, representing pre-trained encoder models, domain-specific models, top-performing text embedding models, and large language models, respectively. Detailed introductions of these models are presented in \u00a7B.1.\n5.2 Implementation Details\nTo construct the architecture presented in Figure 2, the function e(t) is implemented as a fully connected layer, while the functions e(n), e(n), f1, and f2 are implemented using Multi-Layer Perceptron (MLP) structures. The number of layers in each MLP is selected from {2, 3, 4}, with hidden layer sizes chosen from {16,32,64}. Both attention mechanisms consist of a single layer, with the number of attention heads chosen from {1,3, 6}. The hidden dimensions for the query, key, and value vectors in the attention layers are selected from {32, 64, 128}. A grid search is performed on the validation set to identify the optimal combination of hyper-parameters.\nWe conducted experiments using both 2080Ti and A100 GPUs. Training a model requires 32 hours on a 2080Ti GPU or 7.5 hours on an A100 GPU. Once trained, the models can handle test cases spanning over a month, requiring only 10.16 seconds for a single prediction. Given the common usage of A100 and superior GPUs in the industry, our computing requirements are practical for real-world applications.\n5.3 Baseline Methods\nWe evaluate FININ against seven advanced news-based market prediction approaches, representing various techniques for leveraging financial news to predict market movements:\nNews Appearance Frequency (NAF) (Huynh and Smith, 2017) quantifies news influence based on its frequency of occurrence."}, {"title": "5.4 Training and Validation", "content": "Our experimental setup considers input data time spans of 1, 3, 5, 10 and 20 trading days, with the 5-day and 20-day settings equivalent to weekly and monthly predictions. Time series cross-validation is used to determine optimal hyper-parameters. The dataset is divided into 10 sliding windows based on dates. Each window contains data from 500 consecutive days. We initiate by collecting the first window from the initial day and then progress by 391 days to obtain the second window. In each window, data is allocated into training, validation, and testing sets in an 8:1:1 ratio, following the chronological order. Reported results are averages across the 10 subsets, providing a robust and reliable evaluation of the model's performance across different time periods and market conditions.\n5.5 Evaluation Metrics\nThe evaluation of our model is based on three metrics: Accuracy (Acc), Profit and Loss (PnL) and Sharpe ratio (SR). These metrics are commonly used in market prediction literature (Ye et al., 2020; Yuemei et al., 2021). PnL measures the cumulative profit or loss generated by the model's predic-"}, {"title": "6 Results and Discussions", "content": "6.1 Language Model Comparison\nTo identify the LM that generates the most suitable text embeddings for market prediction, we trained FININ with different LMs as the text encoder for the S&P 500 market. The results in Table 1 show RoBERTa outperforming other models across most settings. This suggests that general improvements in model design, as seen in RoBERTa, may be more beneficial than domain-specific adaptations (FinBERT) for news-based market prediction. This observation aligns with our intuition that financial terms in news are generally understandable, making domain-specific adaptation less crucial.\nWhile BGE exhibits strong performance on many NLP tasks, its results in our financial context are less impressive, reinforcing the notion that no single embedding dominates all tasks (Muennighoff et al., 2022). Llama2, representing advanced LLMs, also shows lower performance. As LLMs are primarily optimized for text generation, our findings reflect the concerns regarding their"}, {"title": "6.2 Market Prediction Comparison", "content": "Table 2 presents the market prediction results of the FININ model compared to baseline methods. While the rankings of three metrics do not strongly correlate, the SR is considered the most practical and important one, as mentioned in \u00a7 5.5. Despite not always achieving the best Acc or PnL, FININ consistently outperforms all baselines in terms of the SR across different settings.\nFurthermore, for both datasets, the best PnL and SR results (underlined) are generated by FININ. FININ's highest SR results, 1.772 on the S&P 500 and 1.449 on the NASDAQ 100, outperform the best SR achieved by other methods by at least 0.429 and 0.341, respectively, for each dataset.\nDiscussion on News Use The comparison highlights FININ's superiority in leveraging extensive news data for market prediction. While baseline methods also incorporate news information, FININ offers two distinct advantages. Firstly, FININ uses both news sentiments and textual headlines. This contrasts with baseline methods that primarily rely on sentiment analysis or text processing. By incorporating multi-modal inputs, FININ can capture interactions between news items, an aspect that other methods overlook. Secondly, FININ's analysis of individual news items enables efficient management of large volumes of news. Baseline methods treat all news items equally, causing influential news to be overwhelmed by general news when faced with substantial data. FININ encodes each news item individually, allowing them to contribute differently to the prediction based on their varying influence. This capability is crucial when dealing with large news volumes, where lack of proper news aggregation in other methods can even impair predictions (compared to the \"Always Buy\" strategy). FININ's capability in modeling news interactions is analyzed in detail through case studies in \u00a7C. In summary, FININ's advanced input processing and effective news management techniques position it as a superior tool for using financial news data in market prediction tasks.\nDiscussion on Long Memory Effect and LLM Our findings reveal the long memory effect of financial news. An increasing trend in the Sharpe ratio is evident as the timeframe of considered news data extends. This trend is particularly pronounced"}, {"title": "6.3 Ablation Studies", "content": "To isolate the impact of different data sources and processing methods within FININ, we decompose FININ into five key components: four subsections of the data fusion encoder, the Market Textual data Processor (MTP), the Market Numerical data Processor (MNP), the News Textual data Processor (NTP), and the News Numerical data Processor (NNP), as well as the Market-aware Influence Quantifier (MIQ). We examined three ablated variants: (1) removing news data (FININ-NTP-NNP), (2) removing text inputs (FININ-MTP-NTP), and (3) removing the influence quantifier (FININ-MIQ). When removing MIQ, we aggregated news features via simple averaging instead of using MIQ's scores.\nTable 3 presents the ablation study results on the S&P 500 market. The performance drop in each ablation setup, compared to the complete FININ model, underlines the critical role of news inputs, text data processing, and the news influence quantifier in enhancing market prediction.\nThe \u201cFININ-NTP-NNP\u201d column reveals that predictions based solely on historical price data offer limited long-term forecasting capability, as performance improves marginally with increasing input timeframes. This suggests that the primary information of daily price fluctuations is incorporated into subsequent prices. Incorporating news information, as in the complete FININ model, improves prediction, especially for longer-term forecasts. This finding highlights the heightened relevance of news for capturing long-term stock price dynamics.\nThe \u201cFININ-MTP-NTP\u201d outperforms \u201cFININ-NTP-NNP\" in most settings, indicating that news sentiment analysis captures additional information not yet reflected in prices. However, the comparison with \"Complete FININ\" shows that relying solely on sentiment analysis misses crucial information within news text, highlighting the necessity of our text processing component.\nThe \"FININ-MIQ\u201d results emphasize the significant contribution of the news influence quantifier. Directly averaging news features performs even worse than models without news data (FININ-NTP-NNP). This indicates that simply including a large amount of news data can be detrimental without proper use. The market-aware influence quantifier's scores are essential to extract the predictive power of news for market prediction.\nIn summary, while market data provides baseline results, incorporating news sentiment and textual information through FININ's processing components yields substantial performance gains. Moreover, FININ's market-aware influence quantifier is crucial for leveraging news data, as it effectively integrates the complex inputs and extracts their predictive power for enhanced market prediction.\n6.4 Insights into Financial News\nOur comprehensive experimental results offer three key insights into the interplay between financial"}, {"title": "7 Conclusions", "content": "This paper introduces FININ, a novel model designed to use financial news for market prediction. FININ effectively uses market-related information from news data, outperforming various advanced market prediction methods. Our experiments shed light on the relationships between news and the market, highlighting delayed market pricing of news, the long memory effect of financial news, and the limitations of market sentiment analysis in extracting predictive power from news.\nLimitations\nFININ is a novel approach to building news interactions for market prediction. However, as the related financial theory is less considered in deep learning, there is significant room for further improvement. We discuss the primary limitations of our model as follows:\nFirst, similar to many models using attention mechanisms (Achiam et al., 2023; Touvron et al., 2023), FININ is limited by the attention window size. Attention mechanisms cannot be applied to sequences of unlimited length. Consequently,"}], "equations": ["attsd,i = \u221a1dkq(me)Tk(rf)d,i.", "m(e)d = f1(m(te)d , m(ne)d),", "m(te)d = e(t)(lm(m(t)d)),", "r(te)d,i = e(t)(Im(r(t)d,i)).", "r(e)d,i = f2(r(te)d,i, r(ne)d,i).", "m(ne)d = e(n)(m(n)d), r(ne)i = e(n)2(r(n)d,i).", "\u0177d = pred((m(e)d\u2212t+1,..., m(e)d),(r(f)d\u2212t+1,...,r(f)d)).", "PnL =\u2211flagd Pa+1-Pa", "SR =(\u221a )"]}