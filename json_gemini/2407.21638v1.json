{"title": "Quality Control for Radiology Report Generation Models via Auxiliary Auditing Components", "authors": ["Hermione Warr", "Yasin Ibrahim", "Daniel R. McGowan", "Konstantinos Kamnitsas"], "abstract": "Automation of medical image interpretation could alleviate bottlenecks in diagnostic workflows, and has become of particular interest in recent years due to advancements in natural language processing. Great strides have been made towards automated radiology report generation via AI, yet ensuring clinical accuracy in generated reports is a significant challenge, hindering deployment of such methods in clinical practice. In this work we propose a quality control framework for assessing the reliability of AI-generated radiology reports with respect to semantics of diagnostic importance using modular auxiliary auditing components (ACs). Evaluating our pipeline on the MIMIC-CXR dataset, our findings show that incorporating ACs in the form of disease-classifiers can enable auditing that identifies more reliable reports, resulting in higher F1 scores compared to unfiltered generated reports. Additionally, leveraging the confidence of the AC labels further improves the audit's effectiveness. Code will be made available at: https://github.com/hermionewarr/GenX_Report_Audit", "sections": [{"title": "1 Introduction", "content": "Radiologists are facing mounting challenges managing the growing volume of medical imaging data under resource constraints, necessitating more efficient and innovative solutions for image analysis and interpretation. Automated (or partly automated) radiology report generation is one such solution. Since the introduction of transformers [28], which significantly enhanced language generation, numerous studies have investigated radiology report generation from medical images, particularly chest X-rays (CXR) [4, 7, 9, 15, 22, 26]. However, deployment of language models to medical applications faces a variety of challenges, with a key area being the need for factual accuracy. Various methods have been developed to address this - particularly useful have been the introduction of clinical metrics to supplement the standard natural language processing (NLP) metrics used to evaluate report generation quality [4, 18]. Previous efforts to improve the quality of the generated reports have incorporated extra information during training, such as bounding boxes for improved localisation, or have aimed to refine diagnostic accuracy by including loss functions that reward clinical accuracy [5, 7, 21, 26]. Additionally, more complex architectures, such as memory-augmented attention, have been developed to facilitate better image understanding [6,21].\nBesides efforts to improve report generation accuracy, another line of work is error detection in language modeling. Most work in this area has targeted the natural language domain. The two main types of uncertainty estimation in large language models (LLMs) are statistical uncertainty (SU) and in-dialogue uncertainty (IDU) [27]. The latter relies on large pretrained models to admit when they don't know an answer [13, 16]. SU relates certainty to the model's output entropy, though in language modelling, it must address the coherence of entire sentences, as well as on a per token basis [14, 20]. These methods often depend on extensive labelled datasets in the natural language domain, which do not adequately capture the specialised terminology and context of clinical settings [27]. Few works have investigated the possibility of error detection in reports written by radiologists [8,12,29,30]. \u03a4\u03bf our knowledge, no previous work has investigated error detection for automated report generation, which is the focus of our study.\nWe introduce an auditing framework for identifying potential errors in AI-based radiology report generation, using modular auxiliary auditing components (AC) for quality control. Our study focuses on chest-Xray (CXR) imaging, defining ACs as image-based disease classifiers to extract semantics relevant to diagnosis. We develop a report generation model, GenX, which performs competitively with previous works and serves as basis for testing our auditing framework. Reports are audited using ACs that provide disease classification and confidence levels. Reports with consistent diagnoses across the pipeline meet our criteria, while inconsistencies flag potential errors. Additionally, by leveraging the ACs' classification confidence, we enforce stricter quality control, requiring consistency with the highest confidence predictions. Our evaluation on MIMIC-CXR shows a significantly higher F1 score for reports meeting the audit's criteria. Results demonstrate that consistency between report and auxiliary components is a promising auditing mechanism for automated report generation."}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Report Generation Model - GenX", "content": "The proposed framework for auditing radiology report generation is shown in Fig. 1. The backbone of the framework is the report generation model. The generalised vision language modeling problem of generating a textual sequence T given an input image I can be framed as estimating the conditional distribution p(T|I), as a product of the conditional probabilities:\n$$p(T|I) = \\prod_{l=1}^{L} p(T_l | T_{<l}, I; \\theta),$$\nwhere T is modelled as a sequence of word tokens {T1,...,TL}, with T<l being the set of tokens preceding Tl, where L is the number of tokens in the sequence, and \u03b8 the model parameters [1,22].\nAn overview of our report generation model, GenX, is shown in Fig. 2. The model is trained to maximise the probability of generating the target sequence from the image, p(T|I) from eq 1. Image features $I_{feat} = f_1(I) \\in \\mathbb{R}^{D_1}$, with dimensionality $D_1$, are extracted by image encoder f1. A linear layer, $f_{1,emb}$, projects $I_{feat}$ to the space of token embeddings that will be input to the language generator, giving $I_{emb} = {I_{emb,1} ... I_{emb,M}} = f_{1,emb}(I_{feat}) \\in \\mathbb{R}^{D_T\\times M}$, a set of M image token embeddings with dimensionality $D_T$, similarly to LLaVA [19]. A tokeniser maps text to a set of L token vectors {T_i}_{1:L} \\in \\mathbb{R}^{L\\times V}, where V is the vocabulary size. Each Ti is embedded by a linear layer to $T_{i,emb} = f_{T,emb}(T_i) \\in \\mathbb{R}^{D_T}$. The concatenated embeddings of image and text tokens {I_{emb,1} ... I_{emb,M},T_{emb,1} ... T_{emb,L}} are passed to a Transformer decoder (Fig. 2b) which predicts a probability distribution over V vocabulary tokens, expressing which is more probable in the sequence. The decoder has Nlayers with Attention blocks that each has Nheads"}, {"title": "2.2 Auditing Generated Reports via Auxiliary Classifiers", "content": "While some types of mistakes in AI-generated radiology reports, such as grammatical errors, are merely inconvenient, semantic mistakes related to disease diagnosis can be detrimentalor patient care. Consider a semantic concept of interest, denoted c. We focus on the case where c represents a specific disease, with the class label C\u2208 {1,0} indicating the presence or absence of that disease. To audit whether a generated report TG is semantically correct about c, we need to extract the value CT described in text TG via a mapping function gT:TG\u2192c. This can be any text-based classifier, or prompt-based LLM that can answer questions in the form \"Does this text suggest evidence or not for disease c?\", which have become widely available. Herein we use a pretrained CheXbert text-classifier [25] as gr, obtaining $C_T = g_T(T_G)$ (Fig 1b).\nWe then introduce to the framework an independent model gI : I\u2192c, which infers value C\u2081 for concept of interest c from image I (Fig. 1c). We term such models auxiliary auditing components (AC). In the examined case when c is existence of specific disease, gI is a classifier predicting C\u2081 =1 if image I shows the disease or C\u2081 =0 otherwise, with model confidence $P_{AC}(c=C_1|I)$. If multiple concepts c are of interest (e.g. different diseases), an independent AC model can be used per c, for ease of modular development, or a multi-label AC model.\nAuditing is performed by comparing values CT and C\u2081 about the concept c of interest (e.g. disease) extracted from the report or the image respectively (Fig 1d). To consider the contents of the report reliable with respect to c, agreement between the report and AC is required, i.e. $C_T = C_I$. We further extend this by taking into consideration the confidence PAC of the AC. We only consider the auditing successful if it satisfies the additional requirement that the value $C_T = C_I$ has been inferred by the AC with confidence PAC over a pre-determined threshold t. Formally, for a successfully completed auditing we require:\n$$(C_I = C_T) \\land (P_{AC}(c = C_I | I) \\geq t),$$\nwhere \u2227 is the logical and operator. The set of generated reports that pass the audit for a particular concept c is denoted by $T_{G,pass}^{(c)} = {T_G| Eq. 2 is True}$. The remainder, $T_{G,err}^{(c)} = {T_G| Eq. 2 is False}$, can be deferred to the human user for review as potentially inaccurate for that disease.\nThe framework is designed based on ACs that are modular, independent models. The design draws inspiration from N-Version programming [3] and the principle of redundancy for reliability in software engineering. Assuming independence of components (GenX, 9\u0442, 91) with label error rates ect and ec\u2081, the error rate of the auditing framework is e = \u0435\u0441\u0442\u0435\u0441\u2081, which is lower than the individual error rates of CT and C\u2081, as failure of auditing requires both components to fail simultaneously to incorrectly satisfy Eq. 2. Modular ACs enable independent component training and validation prior to integration into the audit pipeline."}, {"title": "3 Experiments and Results", "content": ""}, {"title": "3.1 Data", "content": "Experiments are performed using MIMIC-CXR [11], containing chest X-rays (CXR), associated radiology reports, and disease labels for ~228,000 studies of over 65,000 patients. As common practice, we consider only the frontal-view images, and only the \"findings\" section of the reports, which describes evidence of pathologies and support devices. The labels include 14 classes (12 diseases, 1 support devices, 1 no findings) and can be positive, uncertain, negative, or not mentioned. We report 5 out of 14 classes separately (Atelectasis, Cardiomegaly, Consolidation, Edema, Pleural Effusion) to facilitate comparison with literature [10]. We divide data into splits for training (226,261), validating hyperparameters (1,864), and testing performance (3,595). To train and evaluate the report generation, we further exclude studies that do not include a \"findings\" section, resulting in 155,322 training, 1,231 validation and 2,607 testing samples. Finally, to help address class imbalance and noisy labels, following past works [9, 10, 21, 26], we consider uncertain disease labels as positive and class no-mention as negative."}, {"title": "3.2 Evaluating the Report Generation Model", "content": "Experimental settings: We here show that our report generation model, GenX, is of representative quality in comparison to previous work to serve as effective backbone for the study of our auditing framework. To build GenX we use ResNet-50 as the image encoder f1, which we pre-train as a multi-label classifier of the 14 classes described above. Its penultimate layer of dimension D\u2081 = 512 is then projected to M = 10 image token embeddings with DT=512. These are concatenated with up to L=512 text embeddings, resulting from a GPT-2 tokeniser (V\u2248 50, 257) [24], followed by a projection, Dr=512. The Transformer has Nlayers =8, Nheads =8, and dimension Dff =2048 of its feed-forward layer. GenX is then trained end-to-end (Fig. 2), learning parameters of the randomly initialised projections and Transformer, and fine-tuning the fi encoder."}, {"title": "3.3 Evaluating the Auditing Framework for Generated Reports", "content": "Experimental settings: We analyse whether including auxiliary auditing components, ACs, enable us to quality control the generated reports and filter out those that are more likely to contain errors. We evaluate on the 5 diseases most commonly reported in the literature (Sec. 3.1), from the CheXpert competition [10]. For this, we first train 5 independent disease-specific AC image classifiers (AC1), where each is a ResNet-18. We then apply the framework as described in Sec. 2.2 to the test-split. For each image, the 5 AC1 models predict 5 disease labels $C_I^{(c)}$, one per disease c. GenX generates a report for each test image and we extract 5 report-based class labels $C_T^{(c)}$ via Chexbert, for each disease. For a given scan, per disease c, we compare image and report based labels, $C_I^{(c)}$ and $C_T^{(c)}$, to check if they fulfil Eq. 2. We perform the check in two settings: First, without considering a confidence threshold for PAC, satisfying only the first condition in Eq. 2; Second, with a confidence threshold t = 0.8 where Eq. 2 is fulfilled if PAC \u2265 0.8, to investigate whether stricter auditing criteria results in more accurate reports For each disease, the images that fulfil the above criteria are considered to have successfully passed the audit. For these images, we calculate average F1 score by comparing their report-based labels $C_T^{(c)}$ with the reference report labels, to determine whether the average score is higher than that of all unfiltered reports generated by GenX. Finally, we repeat these experiments using a bigger ResNet-50 AC, trained as a multi-label image classifier"}, {"title": "4 Conclusion", "content": "We introduced a framework to quality control AI-generated radiology reports with respect to semantics of interest via auxiliary auditing components. Our study focused on the task of report generation from chest-Xrays, detecting potential semantic errors in diagnosis-related report content, using auxiliary disease classifiers and assessing consistency between labels inferred from image and report. Experiments show that reports fulfilling the auditing criteria exhibit fewer errors, with average F1 score that can even exceed the score of the auditing components. The framework is generic and future work could explore it for auditing semantic concepts beyond disease classification, such as for description of pathology location or volume, using regression models as ACs for such properties.\nThe limitation of the framework, as with any filtering pipeline for quality-control, is the inherent trade-off between reducing the number of reports that successfully pass the audit and can be used for down-stream workflow, in exchange for their higher reliability. Future work could improve performance in both aspects by integrating more potent models for inferring image-based and report-based labels, thereby ensuring greater consistency and reliability from their comparison."}]}