{"title": "Beta Sampling is All You Need: Efficient Image Generation Strategy for Diffusion Models using Stepwise Spectral Analysis", "authors": ["Haeil Lee", "Hansang Lee*", "Seoyeon Gye", "Junmo Kim"], "abstract": "Generative diffusion models have emerged as a powerful tool for high-quality image synthesis, yet their iterative nature demands significant computational resources. This paper proposes an efficient time step sampling method based on an image spectral analysis of the diffusion process, aimed at optimizing the denoising process. Instead of the traditional uniform distribution-based time step sampling, we introduce a Beta distribution-like sampling technique that prioritizes critical steps in the early and late stages of the process. Our hypothesis is that certain steps exhibit significant changes in image content, while others contribute minimally. We validated our approach using Fourier transforms to measure frequency response changes at each step, revealing substantial low-frequency changes early on and high-frequency adjustments later. Experiments with ADM and Stable Diffusion demonstrated that our Beta Sampling method consistently outperforms uniform sampling, achieving better FID and IS scores, and offers competitive efficiency relative to state-of-the-art methods like AutoDiffusion. This work provides a practical framework for enhancing diffusion model efficiency by focusing computational resources on the most impactful steps, with potential for further optimization and broader application.", "sections": [{"title": "1 Introduction", "content": "Generative diffusion models have emerged as a powerful tool for high-quality image generation, producing results that rival or surpass traditional generative adversarial networks (GANs) [1]. These models iteratively refine images through a diffusion process, where noise is progressively added and then removed, ultimately generating realistic images from random noise [2]. However, this iterative nature comes with a significant computational cost, necessitating numerous time steps to achieve high-quality outputs. Efficient methods are therefore crucial to reduce computational burden while maintaining the quality of generated images.\nPrevious efforts to improve the efficiency of diffusion models have focused on reducing the number of sampling steps in denoising process to improve the efficiency of diffusion models. Some approaches model the sampling process as ordinary differential equations (ODEs), which enables fewer steps using first-order and higher-order solvers[3-5]. Another effective strategy is to use knowledge distillation techniques repeatedly to condense multiple steps into a single step [6\u20138]. This enables the generation of high-quality images in 10 steps or fewer. Recently, new approaches have been proposed based on the idea that the sampling process of diffusion models plays a different role at each step[9-11]. Some works aim to reduce the number of sampling steps by selecting only the optimal step for particular diffusion models[12-14], while others aim to increase efficiency by using multiple smaller but step-specific models for each step[11, 13, 15, 16].\nIn this paper, we propose a novel Beta Sampling method for improving the efficiency of generative diffusion models. By conducting an image spectral analysis of the diffusion process using Fourier transform, we identified that significant changes in image content occur predominantly at the early and late stages of the denoising process. Based on this insight, we introduce a Beta distribution-like time step sampling method that emphasizes critical steps in the early and late stages of the process. Our key hypothesis is that certain steps in the diffusion process exhibit significant changes in image content, while others contribute minimally. By focusing on these impactful time steps, we aim to enhance the efficiency of image generation without compromising quality, in contrast to traditional uniform sampling. We validate our approach through experiments with ADM and Stable Diffusion models, demonstrating that our Beta Sampling method consistently achieves better FID and IS scores compared to uniform sampling and exhibits competitive efficiency against the state-of-the-art AutoDiffusion method. Our findings highlight the potential for substantial computational savings and quality improvements in image generation tasks."}, {"title": "2 Related works", "content": ""}, {"title": "2.1 Denoising Process of Diffusion Models", "content": "There is an active research effort to analyze and improve the denoising process of diffusion models from various aspects. So far, most analyses agree that the diffusion model's denoising process proceeds in a coarse-to-fine manner, i.e., it generates the overall structure of the image by focusing on low-frequency components at the beginning, and then completes the details through changes in high-frequency components at the end, resulting in progressively higher quality images.\nSeveral efforts have been focused on analyzing the denoising process of the diffusion models. First, Choi et al. [17] analyzed the process of adding noise to an image using LPIPS distance, with the idea that the diffusion model has a different pretask for each step, and proposed that the denoising process of the diffusion model can be divided into three stages: 1) creating coarse features 2) generating perceptually rich contents 3) and removing remaining noise.\nTo analyze how the latent structure of the diffusion model varies with the diffusion timestep, Park et al. [18] identified the frequency domain of the local latent basis by power spectral density (PSD) analysis, and confirmed the shift from low-frequency to high-frequency as the denoising process progresses. By analyzing the frequency domain of the image obtained at each step, we also confirmed that the low-frequency part is restored at the beginning and the high-frequency detail is restored at the end[16, 11]. Furthermore, Li et al. [13] argued that the difficulty and importance of each of these different steps is different, and that efficient sampling can be achieved by finding an optimal time step.\nMore recently, researchers have tried to visually interpret the denoising process through a text to image diffusion model[19]. This paper investigated the spatial recovery level at each timestep in the denoising process and showed that the focal region of the model changes from semantic information to fine-grained regions. Furthermore, we found that the diffusion model learns different visual concepts at each stage and focuses on different concepts of the prompt at each stage, even in the generation stage."}, {"title": "2.2 Frequency Analysis of Diffusion Models", "content": "Frequency analysis has long been a fundamental tool for image processing and analysis in the field of computer vision. It enables the separation of high and low-frequency components of an image. The Fourier transform has been widely used for frequency analysis in identifying major patterns in images, removing noise, and compressing images.\nResearch has shown that deep neural networks initially adapt to low-frequency signals, while learning high-frequency details more gradually[20\u201322]. This phenomenon, known as spectral bias, has also been observed in deep generative models such as GANs[23\u201325]. A similar spatial frequency bias has been found in diffusion models. Choi et al. [17] suggests that the denoising process of diffusion models shows three distinguishable phases. The first phase captures coarse attributes, while the subsequent phases progressively incorporate finer details. Other studies have noted that throughout the progression of the denoising process, low-frequency components are preserved, while high-frequency components undergo rapid changes[26] or the ratio of high-frequency increases as the denoising progresses[18]."}, {"title": "3 Spectral Analysis of Denoising Processes in Diffusion Models", "content": "The denoising process in diffusion models has been demonstrated to encompass several distinct stages, each characterized by unique model behaviors [27, 17]. This variability in behavior across time steps suggests that the importance of each step in the denoising process may not be uniform. To investigate the relative importance of each step in the denoising process, we conducted a comprehensive spectral analysis of the denoising procedure in pre-trained diffusion models. This analytical approach allows us to inspect which parts of the denoising process contribute most significantly to meaningful changes in the generated image. By decomposing the process into its spectral components, we aim to provide insights into the differential contributions of each denoising step to the final output quality.\nDiffusion Models. To investigate the frequency characteristics of diffusion models, we conducted a comprehensive analysis on two prominent models: ADM-G [1] and Stable Diffusion [9]. The ADM-G model was trained on ImageNet 64\u00d764 [28], while Stable Diffusion was trained on the LAION-5B [29] dataset.\nFor the ADM-G model, we observed the denoising process for a total of 10,000 image generations. Specifically, we generated 10 images for each class in the ImageNet dataset, ensuring a broad representation across all categories. In the case of Stable Diffusion, we randomly selected 1,000 captions from the validation set of COCO [30] dataset to serve as prompts for image generation."}, {"title": "Spectral Analysis", "content": "To conduct spectral analysis of the denoising process, we applied a 2D Fourier transform to the images generated at each step of the diffusion model. We then calculated the relative log magnitude of each frequency component. For an image x, we denote this result as RLM(x). When it comes to Stable Diffusion, a latent diffusion model, we utilized a pre-trained variational autoencoder to transform the latent at each step into the image domain for frequency component analysis. The visualized results of RLM(xt) across all time step t are depicted in Figs. 2a and 2d. As anticipated, the frequency components of the image x1000 at t = 1000, which represents pure Gaussian noise, exhibited a flat distribution. However, as the denoising process progressed, we observed changes in the frequency components of the images. To quantify these changes, we defined the frequency change at a specific step t as the difference between the frequency components of consecutive steps: RLM(xt) \u2013 RLM(xt+1). These differences by time step t are shown in Figs. 2b and 2e. This approach allows us to track the evolution of frequency components throughout the denoising process. By examining these spectral changes, we can gain insights into how different frequency bands are affected at various stages of image generation."}, {"title": "Major Changes Occur in the Early and Late Stages", "content": "The visualization of our spectral analysis is presented in Fig. 2. Consistent with previous works, we observe that the early stages of the denoising process (closer to t = 1000) primarily form coarse, low-frequency components, as evident in the lower right area of Figs. 2b and 2e. The red regions indicating an increase in the heatmap demonstrate that the low-frequency components are formed predominantly in the early stages. Conversely, the later stages (approaching t = 0) are dominated by changes in fine, high-frequency components, as shown in the upper left area of these graphs. To further clarify this phenomenon, we isolated the increasing low-frequency components in the early stages and the decreasing high-frequency components in the later stages, and show their respective averages in Figs. 2c and 2f. This separation demonstrates that low-frequency elements undergo significant changes early in the process, while high-frequency elements experience substantial modifications in the later stages. Notably, the intermediate stages show relatively minor changes in image information from a frequency perspective."}, {"title": "4 Beta Sampling for Step Reduction", "content": "Inspired by spectral analysis, we propose a novel sampling technique for step reduction in diffusion models. Our previous investigations revealed a significant phenomenon in the image-denoising process of diffusion models: the most critical and substantial changes are predominantly concentrated in the initial and final stages of the model's operation. This observation suggests that when selecting a reduced number of steps compared to the total time steps used during training, there is a compelling need to develop a method that can allocate more steps to the early and late stages of the process. This approach stands in contrast to the conventional uniform sampling technique that has been widely employed. The uniform sampling method assigns equal weight to all stages of the denoising process. However, our analysis indicates that this approach may not be optimal, given the non-uniform distribution of changes across the denoising timeline. Consequently, we propose a novel sampling strategy that allocates a higher density of steps to the initial and final stages of the denoising process. This method aims to concentrate computational resources on the periods where the most crucial transformations occur.\nFig. 3 illustrates the Probability Density Functions (PDFs) and Cumulative Distribution Functions (CDFs) of uniform and various Beta distributions. The Beta distribution is characterized by two hyperparameters, a and \u1e9e, which determine the shape of the distribution. When a > \u03b2, the distribution skews to the right, meaning that sampling the denoising process based on this distribution will focus on the changes in low-frequency components during the early stages. Conversely, if a < \u03b2, the distribution skews to the left, concentrating the denoising process on high-frequency component changes in the later stages. Finally, when a = \u03b2, the Beta distribution forms a shape with peaks at both ends, which means that sampling according to this distribution will evenly concentrate on both low-frequency changes in the early stages and high-frequency changes in the later stages. In our proposed method, we use a Beta distribution where a = \u03b2 to ensure a balanced focus on both low-frequency and high-frequency changes throughout the denoising process. This approach ensures that the denoising process effectively captures critical changes at both the beginning and end stages, leading to more efficient and high-quality image generation.\nTo sample Beta distribution-like time steps in the denoising process, our method leverages the Probability Integral Transform (PIT), a well-established method for generating samples from a target"}, {"title": "", "content": "distribution using uniform random variables [31]. We begin with a set of uniformly sampled time steps ti, where i = 1, 2, ..., N, and ti \u2208 [0, T \u2013 1]. Then we normalize the time steps: t'\u2081 = ti/T. These time steps are initially equidistant, following a Uniform distribution U(0, 1). We choose a Beta distribution B(\u03b1, \u03b2) as our target distribution for the time steps. The Beta distribution is selected for its flexibility in modeling various shapes over a finite interval [0, 1], which aligns well with the normalized time step range. The CDF of the beta distribution, denoted as F(x; \u03b1, \u03b2), is computed. We apply the PIT to transform our uniform samples into samples from the Beta distribution. For each uniformly sampled time step t\u2081, we compute:\ntB = F-1(t'; \u03b1, \u03b2)  (1)\nwhere F-1 is the inverse CDF (or Percent Point Function, PPF) of the Beta distribution. If necessary, we rescale the transformed time steps to to ensure they span the full range of the diffusion process. Our method does not involve random sampling from the Beta distribution. Instead, it employs distribution equalization through the PIT to achieve fixed-point sampling. This approach ensures a deterministic and consistent allocation of time steps that adheres to the desired Beta distribution, offering a more controlled and reproducible sampling process compared to random sampling methods.\nOur method allows for a strategic concentration of time steps in the early and late stages of the diffusion process, where the most significant changes typically occur. By carefully selecting the a and \u1e9e parameters of the Beta distribution, we can precisely control the density of time steps at different stages of the process. This adaptive sampling strategy enables a more efficient allocation of computational resources, focusing on the most critical phases of the diffusion process while maintaining a smooth transition throughout the entire range."}, {"title": "5 Experiments", "content": ""}, {"title": "5.1 Experimental Setup", "content": "Diffusion Models. To validate the effectiveness of our method, we conducted experiments using rep- resentative pre-trained diffusion models without retraining or fine-tuning. As in Sec. 3, we employed"}, {"title": "5.2 Results", "content": "Beta Sampling Outperforms Uniform Sampling and Competes with AutoDiffusion. Table 1 presents comparative experimental results for the ADM-G model. Beta Sampling significantly outperforms uniform sampling at very low step counts of 4 and 6. At step counts of 10, 15, and 20, Beta Sampling shows even better performance than AutoDiffusion. This can be interpreted as follows: as the number of steps increases, the genetic algorithm's inefficiency rises, resulting in sub-optimal search results for AutoDiffusion. In contrast, Beta Sampling appears to approach a more optimal set of steps.\nFigure 4 shows generated examples from identical initial noise. At 4 steps, Beta Sampling produces blurrier results compared to AutoDiffusion. However, at 6 and 10 steps, both Beta Sampling and AutoDiffusion yield clearer images than uniform sampling. Given the computationally intensive search process of AutoDiffusion, Beta Sampling emerges as a more efficient alternative. At 15 and 20 steps, all strategies produce clear images, with both uniform and Beta Sampling offering efficient options. Overall, except for 4 steps, Beta Sampling demonstrates competitive image quality without the additional time or computational burdens.\nTable 2 displays comparative experimental results for Stable Diffusion. Again, Beta Sampling outperforms uniform sampling. In particular, as the number of steps increases, the performance gap"}, {"title": "", "content": "between Beta Sampling and AutoDiffusion narrows or even becomes favorable in terms of IS, which may be due to the fact that AutoDiffusion's search method is only optimized for FID.\nThe quality of examples generated with Stable Diffusion can be observed in Fig. 5. At 4 and 6 steps, uniform sampling exhibits structural defects and poor color representation. Beta Sampling mitigates these issues but remains inferior to AutoDiffusion, which employs a more extensive search process for large models. At 10 steps, Beta Sampling produces samples comparable in quality to AutoDiffusion. Interestingly, at 20 steps, AutoDiffusion occasionally introduces undesired artifacts into the examples. While there is considerable fluctuation depending on the prompt, Beta Sampling demonstrates competitive efficiency in all cases except at 4 steps.\nAblation Study (1) Beta Sampling Performs Best When a = \u03b2. In Fig. 3, we introduced the concept that different Beta distributions can result in distinct Beta Sampling strategies. To verify our hypothesis and the insights from our spectral analysis, we compare the outcomes of three types of Beta Sampling.\nTab. 3 and Fig. 6 present the FID and IS evaluations and sample images generated using these three Beta Sampling methods. For Beta(2,5) with a < \u03b2, which concentrates sampling in the later stages, the generated images lacked the necessary low-frequency components, resulting in noisy and incomprehensible images, as evidenced by very poor FID and IS scores. Conversely, Beta(5,2) with \u03b1 > \u03b2 focused sampling in the early stages, producing images with well-represented low-frequency"}, {"title": "Ablation Study (2) Hyperparameter Analysis", "content": "Figure 7 illustrates the changes in FID and IS performance as a function of the hyperparameter \u03b1 = \u03b2. When a = \u03b2 = 1, the distribution is equivalent to a uniform distribution, and as these values decrease, the focus on the middle stages diminishes. The observed changes in FID and IS performance as the hyperparameter decreases from the uniform distribution demonstrate the effectiveness of Beta Sampling.\nSpecifically, the optimal parameter for achieving the best FID performance varied depending on the number of sampled steps. In contrast, IS consistently produced the best results with values between 0.4 and 0.5 across all numbers of sampled steps. As a result, we set a = \u03b2 = 0.5 for ADM-G, and \u03b1 = \u03b2 = 0.6 for Stable Diffusion."}, {"title": "6 Discussion", "content": "AutoDiffusion Behaves Like Beta Sampling. Our experiments revealed that Beta Sampling achieves results comparable to AutoDiffusion when using 10 or more time steps, but underperforms with extremely small time steps, such as 4 or 6 steps. To better understand these differences, we analyzed the distribution of time steps extracted from AutoDiffusion by examining the cumulative histogram of step frequencies, as shown in Fig. 8. For enhanced visibility, we repeated step sampling 150 times for 4 and 6 steps, and 50 times for 10 and 15 steps. The histogram revealed that for 4 and 6 steps, the distribution was nearly uniform, whereas for 10 and 15 steps, the distribution resembled a Beta distribution. This indicates that AutoDiffusion effectively operates similarly to Beta Sampling when using 10 or more steps. Consequently, for generation settings with more than 10 steps, Beta Sampling can be an efficient choice as it eliminates the need for searching time for optimal steps.\nADM-G vs. Stable Diffusion. We validated the effectiveness of Beta Sampling using two diffusion models, ADM-G and Stable Diffusion. Our results demonstrated that Beta Sampling is more advanta- geous than uniform sampling for both models and is particularly more efficient than AutoDiffusion for ADM-G with steps greater than 10. However, in the case of Stable Diffusion, Beta Sampling showed marginally inferior results to AutoDiffusion even at 10 steps. This discrepancy can be attributed to the differences in the spectral analysis of ADM-G and Stable Diffusion. As depicted in Fig. 2, ADM's frequency changes exhibit peaks in both high and low frequencies concentrated at the extremities of the steps with a steep decline in variance. In contrast, Stable Diffusion's frequency changes show a high-frequency peak around the 100-step mark, with low-frequency changes tapering off more"}, {"title": "", "content": "gradually. Therefore, while Beta Sampling is well-suited to ADM's frequency change distribution, it is not entirely compatible with Stable Diffusion's distribution. Future improvements in generation performance for Stable Diffusion could be achieved by identifying hyperparameters or distributions that better align with its frequency change characteristics.\nLimitations and Future Works. One limitation is that our approach relies on pre-determined spectral analyses, which may not fully capture the dynamic nature of the diffusion process across different datasets and model architectures. Moreover, the hyperparameters for Beta Sampling need careful tuning, which may require extensive experimentation for optimal performance. Future work could address these limitations by adaptively sampling the most critical steps to further enhance the efficiency and generalizability of our method."}, {"title": "7 Conclusion", "content": "In this paper, we introduced an efficient time step sampling method for generative diffusion models, leveraging frequency domain analysis to optimize the image generation process. Our approach replaces traditional uniform sampling with a Beta distribution-like method, emphasizing critical steps in the early and late stages of diffusion. We validated our hypothesis that significant changes in image content occur at specific steps-through Fourier transform analysis, revealing substantial low-frequency changes early on and high-frequency adjustments later. Experiments with ADM-G and Stable Diffusion showed our method consistently outperforms uniform sampling, achieving better FID and IS scores, and offers competitive efficiency compared to state-of-the-art techniques like AutoDiffusion. This work provides a practical framework for enhancing diffusion model efficiency by focusing computational resources on the most impactful steps, with potential for further optimization and adaptive techniques in future research."}]}