{"title": "Beta Sampling is All You Need: Efficient Image\nGeneration Strategy for Diffusion Models using\nStepwise Spectral Analysis", "authors": ["Haeil Lee", "Hansang Lee", "Seoyeon Gye", "Junmo Kim"], "abstract": "Generative diffusion models have emerged as a powerful tool for high-quality\nimage synthesis, yet their iterative nature demands significant computational re-\nsources. This paper proposes an efficient time step sampling method based on an\nimage spectral analysis of the diffusion process, aimed at optimizing the denoising\nprocess. Instead of the traditional uniform distribution-based time step sampling,\nwe introduce a Beta distribution-like sampling technique that prioritizes critical\nsteps in the early and late stages of the process. Our hypothesis is that certain steps\nexhibit significant changes in image content, while others contribute minimally.\nWe validated our approach using Fourier transforms to measure frequency response\nchanges at each step, revealing substantial low-frequency changes early on and\nhigh-frequency adjustments later. Experiments with ADM and Stable Diffusion\ndemonstrated that our Beta Sampling method consistently outperforms uniform\nsampling, achieving better FID and IS scores, and offers competitive efficiency rel-\native to state-of-the-art methods like AutoDiffusion. This work provides a practical\nframework for enhancing diffusion model efficiency by focusing computational\nresources on the most impactful steps, with potential for further optimization and\nbroader application.", "sections": [{"title": "Introduction", "content": "Generative diffusion models have emerged as a powerful tool for high-quality image generation,\nproducing results that rival or surpass traditional generative adversarial networks (GANs) [1]. These\nmodels iteratively refine images through a diffusion process, where noise is progressively added and\nthen removed, ultimately generating realistic images from random noise [2]. However, this iterative\nnature comes with a significant computational cost, necessitating numerous time steps to achieve\nhigh-quality outputs. Efficient methods are therefore crucial to reduce computational burden while\nmaintaining the quality of generated images.\nPrevious efforts to improve the efficiency of diffusion models have focused on reducing the number of\nsampling steps in denoising process to improve the efficiency of diffusion models. Some approaches\nmodel the sampling process as ordinary differential equations (ODEs), which enables fewer steps\nusing first-order and higher-order solvers[3-5]. Another effective strategy is to use knowledge\ndistillation techniques repeatedly to condense multiple steps into a single step [6\u20138]. This enables\nthe generation of high-quality images in 10 steps or fewer. Recently, new approaches have been\nproposed based on the idea that the sampling process of diffusion models plays a different role at each"}, {"title": "Related works", "content": "There is an active research effort to analyze and improve the denoising process of diffusion models\nfrom various aspects. So far, most analyses agree that the diffusion model's denoising process\nproceeds in a coarse-to-fine manner, i.e., it generates the overall structure of the image by focusing\non low-frequency components at the beginning, and then completes the details through changes in\nhigh-frequency components at the end, resulting in progressively higher quality images.\nSeveral efforts have been focused on analyzing the denoising process of the diffusion models. First,\nChoi et al. [17] analyzed the process of adding noise to an image using LPIPS distance, with the idea\nthat the diffusion model has a different pretask for each step, and proposed that the denoising process\nof the diffusion model can be divided into three stages: 1) creating coarse features 2) generating\nperceptually rich contents 3) and removing remaining noise.\nTo analyze how the latent structure of the diffusion model varies with the diffusion timestep, Park\net al. [18] identified the frequency domain of the local latent basis by power spectral density (PSD)\nanalysis, and confirmed the shift from low-frequency to high-frequency as the denoising process\nprogresses. By analyzing the frequency domain of the image obtained at each step, we also confirmed\nthat the low-frequency part is restored at the beginning and the high-frequency detail is restored at\nthe end[16, 11]. Furthermore, Li et al. [13] argued that the difficulty and importance of each of these\ndifferent steps is different, and that efficient sampling can be achieved by finding an optimal time\nstep.\nMore recently, researchers have tried to visually interpret the denoising process through a text to\nimage diffusion model[19]. This paper investigated the spatial recovery level at each timestep in the\ndenoising process and showed that the focal region of the model changes from semantic information to\nfine-grained regions. Furthermore, we found that the diffusion model learns different visual concepts\nat each stage and focuses on different concepts of the prompt at each stage, even in the generation\nstage."}, {"title": "Frequency Analysis of Diffusion Models", "content": "Frequency analysis has long been a fundamental tool for image processing and analysis in the field\nof computer vision. It enables the separation of high and low-frequency components of an image.\nThe Fourier transform has been widely used for frequency analysis in identifying major patterns in\nimages, removing noise, and compressing images.\nResearch has shown that deep neural networks initially adapt to low-frequency signals, while learning\nhigh-frequency details more gradually[20\u201322]. This phenomenon, known as spectral bias, has also\nbeen observed in deep generative models such as GANs[23\u201325]. A similar spatial frequency bias\nhas been found in diffusion models. Choi et al. [17] suggests that the denoising process of diffusion\nmodels shows three distinguishable phases. The first phase captures coarse attributes, while the\nsubsequent phases progressively incorporate finer details. Other studies have noted that throughout\nthe progression of the denoising process, low-frequency components are preserved, while high-\nfrequency components undergo rapid changes[26] or the ratio of high-frequency increases as the\ndenoising progresses[18]."}, {"title": "Spectral Analysis of Denoising Processes in Diffusion Models", "content": "The denoising process in diffusion models has been demonstrated to encompass several distinct stages,\neach characterized by unique model behaviors [27, 17]. This variability in behavior across time steps\nsuggests that the importance of each step in the denoising process may not be uniform. To investigate\nthe relative importance of each step in the denoising process, we conducted a comprehensive spectral\nanalysis of the denoising procedure in pre-trained diffusion models. This analytical approach allows\nus to inspect which parts of the denoising process contribute most significantly to meaningful changes\nin the generated image. By decomposing the process into its spectral components, we aim to provide\ninsights into the differential contributions of each denoising step to the final output quality.\nTo investigate the frequency characteristics of diffusion models, we conducted\na comprehensive analysis on two prominent models: ADM-G [1] and Stable Diffusion [9]. The\nADM-G model was trained on ImageNet 64\u00d764 [28], while Stable Diffusion was trained on the\nLAION-5B [29] dataset.\nFor the ADM-G model, we observed the denoising process for a total of 10,000 image generations.\nSpecifically, we generated 10 images for each class in the ImageNet dataset, ensuring a broad\nrepresentation across all categories. In the case of Stable Diffusion, we randomly selected 1,000\ncaptions from the validation set of COCO [30] dataset to serve as prompts for image generation."}, {"title": "Beta Sampling for Step Reduction", "content": "Inspired by spectral analysis, we propose a novel sampling technique for step reduction in diffusion\nmodels. Our previous investigations revealed a significant phenomenon in the image-denoising\nprocess of diffusion models: the most critical and substantial changes are predominantly concentrated\nin the initial and final stages of the model's operation. This observation suggests that when selecting a\nreduced number of steps compared to the total time steps used during training, there is a compelling\nneed to develop a method that can allocate more steps to the early and late stages of the process.\nThis approach stands in contrast to the conventional uniform sampling technique that has been\nwidely employed. The uniform sampling method assigns equal weight to all stages of the denoising\nprocess. However, our analysis indicates that this approach may not be optimal, given the non-uniform\ndistribution of changes across the denoising timeline. Consequently, we propose a novel sampling\nstrategy that allocates a higher density of steps to the initial and final stages of the denoising process.\nThis method aims to concentrate computational resources on the periods where the most crucial\ntransformations occur.\nFig. 3 illustrates the Probability Density Functions (PDFs) and Cumulative Distribution Functions\n(CDFs) of uniform and various Beta distributions. The Beta distribution is characterized by two\nhyperparameters, \u03b1 and \u03b2, which determine the shape of the distribution. When \u03b1 > \u03b2, the distribution\nskews to the right, meaning that sampling the denoising process based on this distribution will focus\non the changes in low-frequency components during the early stages. Conversely, if \u03b1 < \u03b2, the\ndistribution skews to the left, concentrating the denoising process on high-frequency component\nchanges in the later stages. Finally, when \u03b1 = \u03b2, the Beta distribution forms a shape with peaks\nat both ends, which means that sampling according to this distribution will evenly concentrate on\nboth low-frequency changes in the early stages and high-frequency changes in the later stages. In\nour proposed method, we use a Beta distribution where \u03b1 = \u03b2 to ensure a balanced focus on both\nlow-frequency and high-frequency changes throughout the denoising process. This approach ensures\nthat the denoising process effectively captures critical changes at both the beginning and end stages,\nleading to more efficient and high-quality image generation.\nTo sample Beta distribution-like time steps in the denoising process, our method leverages the\nProbability Integral Transform (PIT), a well-established method for generating samples from a target"}, {"title": "Experimental Setup", "content": "Diffusion Models. To validate the effectiveness of our method, we conducted experiments using rep-\nresentative pre-trained diffusion models without retraining or fine-tuning. As in Sec. 3, we employed"}, {"title": "Results", "content": "Table 1\npresents comparative experimental results for the ADM-G model. Beta Sampling significantly\noutperforms uniform sampling at very low step counts of 4 and 6. At step counts of 10, 15, and 20,\nBeta Sampling shows even better performance than AutoDiffusion. This can be interpreted as follows:\nas the number of steps increases, the genetic algorithm's inefficiency rises, resulting in sub-optimal\nsearch results for AutoDiffusion. In contrast, Beta Sampling appears to approach a more optimal set\nof steps.\n Beta Sampling produces\nblurrier results compared to AutoDiffusion. However, at 6 and 10 steps, both Beta Sampling and\nAutoDiffusion yield clearer images than uniform sampling. Given the computationally intensive\nsearch process of AutoDiffusion, Beta Sampling emerges as a more efficient alternative. At 15 and 20\nsteps, all strategies produce clear images, with both uniform and Beta Sampling offering efficient\noptions. Overall, except for 4 steps, Beta Sampling demonstrates competitive image quality without\nthe additional time or computational burdens.\nTable 2 displays comparative experimental results for Stable Diffusion. Again, Beta Sampling\noutperforms uniform sampling. In particular, as the number of steps increases, the performance gap"}, {"title": "Discussion", "content": "Our experiments revealed that Beta Sampling achieves\nresults comparable to AutoDiffusion when using 10 or more time steps, but underperforms with\nextremely small time steps, such as 4 or 6 steps. To better understand these differences, we analyzed\nthe distribution of time steps extracted from AutoDiffusion by examining the cumulative histogram\nof step frequencies, as shown in Fig. 8. For enhanced visibility, we repeated step sampling 150 times\nfor 4 and 6 steps, and 50 times for 10 and 15 steps. The histogram revealed that for 4 and 6 steps,\nthe distribution was nearly uniform, whereas for 10 and 15 steps, the distribution resembled a Beta\ndistribution. This indicates that AutoDiffusion effectively operates similarly to Beta Sampling when\nusing 10 or more steps. Consequently, for generation settings with more than 10 steps, Beta Sampling\ncan be an efficient choice as it eliminates the need for searching time for optimal steps.\n We validated the effectiveness of Beta Sampling using two diffusion\nmodels, ADM-G and Stable Diffusion. Our results demonstrated that Beta Sampling is more advanta-\ngeous than uniform sampling for both models and is particularly more efficient than AutoDiffusion for\nADM-G with steps greater than 10. However, in the case of Stable Diffusion, Beta Sampling showed\nmarginally inferior results to AutoDiffusion even at 10 steps. This discrepancy can be attributed to the\ndifferences in the spectral analysis of ADM-G and Stable Diffusion. As depicted in Fig. 2, ADM's\nfrequency changes exhibit peaks in both high and low frequencies concentrated at the extremities of\nthe steps with a steep decline in variance. In contrast, Stable Diffusion's frequency changes show\na high-frequency peak around the 100-step mark, with low-frequency changes tapering off more"}, {"title": "Conclusion", "content": "In this paper, we introduced an efficient time step sampling method for generative diffusion models,\nleveraging frequency domain analysis to optimize the image generation process. Our approach\nreplaces traditional uniform sampling with a Beta distribution-like method, emphasizing critical\nsteps in the early and late stages of diffusion. We validated our hypothesis that significant changes\nin image content occur at specific steps-through Fourier transform analysis, revealing substantial\nlow-frequency changes early on and high-frequency adjustments later. Experiments with ADM-G and\nStable Diffusion showed our method consistently outperforms uniform sampling, achieving better\nFID and IS scores, and offers competitive efficiency compared to state-of-the-art techniques like\nAutoDiffusion. This work provides a practical framework for enhancing diffusion model efficiency by\nfocusing computational resources on the most impactful steps, with potential for further optimization\nand adaptive techniques in future research."}]}