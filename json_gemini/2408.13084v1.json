{"title": "Avatar Visual Similarity for Social HCI: Increasing Self-Awareness", "authors": ["Bernhard Hilpert", "Claudio Alves da Silva", "Leon Christidis", "Chirag Bhuvaneshwara", "Patrick Gebhard", "Fabrizio Nunnari", "Dimitra Tsovaltzi"], "abstract": "Self-awareness is a critical factor in social human-human interaction and, hence, in social HCI interaction. Increasing self-awareness through mirrors or video recordings is common in face-to-face trainings, since it influences antecedents of self-awareness like explicit identification and implicit affective identification (affinity). However, increasing self-awareness has been scarcely examined in virtual trainings with virtual avatars, which allow for adjusting the similarity, e.g. to avoid negative effects of self-consciousness [10]. Automatic visual similarity in avatars is an open issue related to high costs. It is important to understand which features need to be manipulated and which degree of similarity is necessary for self-awareness to leverage the added value of using avatars for self-awareness. This article examines the relationship between avatar visual similarity and increasing self-awareness in virtual training environments. We define visual similarity based on perceptually important facial features for human-human identification and develop a theory-based methodology to systematically manipulate visual similarity of virtual avatars and support self-awareness. Three personalized versions of virtual avatars with varying degrees of visual similarity to participants were created (weak, medium and strong facial features manipulation). In a within-subject study (N=33), we tested effects of degree of similarity on perceived similarity, explicit identification and implicit affective identification (affinity). Results show significant differences between the weak similarity manipulation, and both the strong manipulation and the random avatar for all three antecedents of self-awareness. An increasing degree of avatar visual similarity influences antecedents of self-awareness in virtual environments.", "sections": [{"title": "Introduction", "content": "Self-awareness is a critical factor in social human-human interaction and, hence, in social HCI interaction. Being aware of their own emotions and thoughts may allow users to reflect on and later adapt behavior. In traditional training settings, self-awareness has been induced through methods of self-representation such as mirrors or video recordings. However, with fast-paced developments in technology that facilitate newer, more interactive, and immersive virtual training settings (e.g. [5]), the self-representation methods must be adequately adapted. Avatars are virtual agents that act as representations of individuals and may be controlled by a human. As such, they can be used as personalized awareness tools to increase self-awareness and are often used in virtual environments such as online games, social media, and, more recently, in virtual worlds [19]. The concept of virtual representation, or the use of avatars as a means of visual representation in virtual environments, has gained significant attention in recent years [17]. Previous work has investigated the use of digital awareness tools to increase, especially group social awareness [58, 46, 59, 62]. However, the use of avatars to increase self-awareness has been less investigated and has focused on supporting emotion regulation in general settings [51] and in teacher professional development settings [36, 41]. Still, little is"}, {"title": "Theoretical Background", "content": "known about how avatars can be used to differentially influence self-awareness for different purposes and what the mechanism behind this influence is. Previous research on increasing self-awareness, concentrated on using mirrors [8] and video recordings [8, 55] as external representations of oneself. The assumption here is that the external representation needs to be similar to the individual. An avatar that is visually similar to oneself, might create the same effect for virtual environments. An added value of avatars as external representations is, that they act as \"bridges\" to virtual worlds in the sense of mixed-reality or XR [34], which can be used for immersive but adjustable interactions, beyond what is feasible in the real world and at a low cost [32]. They also offer themselves for social interaction training, for instance for developing empathy and conflict resolution strategies, in school contexts and beyond [15]. In the same sense, the avatars themeselves can be adjusted to better serve the research or training purposes. One main aspect that has drawn a lot of attention are personalized avatars, a term that refers to the visual similarity to the individual. But what degree of such visual similarity is most beneficial for increasing self-awareness, and how should this similarity be defined?\nThere exists conflicting evidence regarding the degree of similarity needed and how similarity should be defined. Some studies show that more similarity is good (e.g., [69]), while other studies and empirical findings (e.g., uncanny valley) show too much similarity might have adversary effects [56]. A strongly realistic (i.e., similar) avatar can, for example, be experienced as \"rather heterogeneous or inharmonious to the surrounding virtual environment\" [30]. In order to examine further the effects of the avatar on a user, we first need to understand which features influence perceived similarity and to be able to define how to manipulate specific facial features of virtual avatars. This article therefore investigates, how we can define the degree of similarity to be able to manipulate personalized avatars and increase self-awareness (RQ 1). To this end, it extents and refines a technical methodology presented first in [2] to manipulate specific facial features of virtual avatars by the degrees of visual similarity to the user. Further, the article also contributes to defining the preconditions of increasing self-awareness with avatars (namely, perceived similarity as well as explicit and implicit identification) to guide further research on topics involving avatar visual similarity. Subsequently, we test the proposed methodology in a comprehensive user study with regard to its effects on all three antecedents (RQ 2), examining to what extent the systematic manipulation of visual avatar similarity influences perceived similarity (RQ 2.1) as well as explicit (RQ 2.2) and implicit identification (RQ 2.3)."}, {"title": "(Virtual) Emotion Regulation Trainings", "content": "Social interaction can be very emotionally challenging on a multitude of levels, especially when it comes to conflict of interests and different socio-emotional perspectives. This challenge increases in multi-party and multi-cultural interaction, like modern classrooms. Teachers find it hard and are often insufficiently trained to deal with the integration of different cultural backgrounds and the socio-emotional conflicts that these may give rise to. They need to adequately manage both heterogeneous learning groups with regard to the taught content, and behavioral conflicts in class in order to secure a constructive learning environment and support student development [35, 61]. This can be very stressful and requires an effective capacity for conflict regulation [18], taking into account multiple student perspectives at once, without interrupting the ongoing lesson. Students are sharp in perceiving subtle emotions and underlying aggression in teacher behavior, and recursive teacher-student discussions disturb classroom conflict resolution [20]. Emotion regulation strategies that contribute to a positive classroom climate involve reappraisal, as opposed to suppression [29], and self-compassion, which can support understanding and coping with one's own and other's emotions in learning settings [41]. However, emotion regulation presupposes self-awareness [45]. Non-effortful implicit emotional awareness (IEA, e.g. self-awareness) and effortful explicit emotional awareness (EEA, e.g. self-compassion) jointly influence higher emotion regulation [24]. Misinterpreting students' reactions occurs more frequently between different cultural groups, where different modes of communication, especially non-verbal, lead to confusion. When students express in an emotional way that they do not feel integrated into"}, {"title": "Self-Awareness, Similarity and Avatar Similarity", "content": "the class, like e.g. \"You don't tell me what to do\", teachers may often feel like their authority is being questioned, or that they do not have the class under control. If they are self-aware, they may apply emotion regulation strategies to combat these feelings of inadequacy, threat or shame effectively, and move on to deal with the situation. Training teachers' self-awareness and consequently emotion regulation can thus improve subtle (non-)verbal behavior and conflict regulation without superimposing additional unnecessary cognitive effort and stress. However, teacher training in realistic conflict situations and practicing in real classrooms as a unique possibility [35] pose ethical risks. Mixed-reality trainings, implementing interactive simulation technology [23, 21, 22] and socially interactive agents (SIAs) with positive effects on human emotion regulation [52, 25] may offer a viable solution. They can provide a safe space to train situational and self-awareness and resulting conflict behavior through realistic virtual interactions [53]. As they become more and more interactive and immersive, they allow users to interact as if they were in a real classroom, and practice the handling of conflict situations. Further, they offer options for playback and natural social interactive feedback (e.g., [5]) which can act as awareness tools to make users aware of their own behaviors and others' reactions and induce self-awareness by supporting reflection [60]. Despite these promises, many questions on the psycho-social design of such environments require further investigation in order for these promises to be held. One of these questions is the degree of avatar similarity conducive for self-awareness.\nMirrors [8] or cameras [55] are validated ways to induce self-awareness. Self-related stimuli (e.g. our own face) are more relevant to us than stimuli related to others [7], and the sense of self is inherently linked to one's own face [44]. In modern VR-training settings where the face is usually covered with the equipment, inducing self-awareness in traditional ways becomes more difficult [43], as mirrors or video recordings are not possible. Moreover, mixed-reality concepts involve the use of avatars that can cohabit a shared world with virtual agents [40]. To take this into consideration, recent research introduced the use of personalized avatars. When using visually similar avatars, users felt sufficiently self-represented [65] and emotionally attached [26] to the stimuli and these avatars could increase the levels of self-awareness in users [31]. Avatars are virtual bodies or vehicles that users engage in, in order to interact with a virtual environment [17]. In addition, they have been conceptualized as symbolic representations of the face for computer-mediated communication [16]. Similarity between the avatar and the person can be achieved in a variety of ways. Some examples include matching visual characteristics such as hair and clothes [6, 30], and matching or mismatching weight [42]. The specific similarity between the user's and, respectively, avatar's face (subsequently called visual similarity) has been of special importance for the increase of self-presence [3], body ownership, and even identification with the avatar [30, 57]. Similarity can be either objective, when considering, for example, degrees of observable similarities [49], or subjective, referring to the perceived similarity between two people. Perceived similarity was found to have a higher impact on predicting self-awareness than observable similarity (i.e. similarity in measurable terms) in some studies (e.g. in [64]). However, there is scarce literature on similarity for visually detailed and humanoid avatars. Moreover, most studies (e.g. [65, 3]) examine the effects of comparing personalized versus a generic avatar. To the best of our knowledge, there is no previous work on varying the degree of visual facial similarity systematically and testing the optimal degree of similarity to increase self-awareness.\nTo address this gap, we propose using avatars as visual representations of humans which offer the possibility to define a systematic manipulation and investigate visually detailed humanoid avatars as a possibility to systematically manipulate their facial similarity. In section, 3, we present a methodology based on defining facial characteristics and how to embed their manipulation in the whole face. Given the effects found in past literature presented above, we hypothesize, that our new method of manipulation of visual similarity will induce a main effect of avatar-person similarity manipulation on perceived similarity, compared to a random avatar.\nHypothesis 1: The avatar will be perceived as most similar in the condition, where the facial features were not systematically manipulated and gradually less similar with an increasing degree of manipulation.\nAs a next step in examining the effects of visual avatar similarity on self-awareness, we define the relationship"}, {"title": "A Theory-Based Methodology", "content": "between an individual and their virtual representation or online persona as a sense of identification. Cohen [11] suggests that explicit identification is a two-stage process, with the first stage being the selection of relevant visual features and the second stage being the comparison of those features to stored representations in memory. This process allows the recognition of familiar objects. Over a set of carefully constructed studies, [65] found a significant correlation between avatar-person similarity and self-awareness, attributed to triggering the same processes of self-representation as a mirror would. This type of identification occurs because of a perception that characteristics and values are shared and is \"a process or state of seeing oneself as similar to, the same as, or fused with another object or person\" [17]. Facial avatar-person similarity has been shown to lead to a higher sense of self-presence [3] and self-identification [57]. Thus, given the proposed manipulation of visual avatar-person similarity, we hypothesize, that there will be a main effect of avatar-person similarity manipulation on explicit identification, compared to a random avatar.\nHypothesis 2: There will be higher explicit identification with the avatar in the condition, where the facial features were not systematically manipulated, gradually declining with an increasing degree of manipulation.\nVisual similarity is also a key aspect of implicit identification, as it involves the ability to recognize objects that are similar in appearance, even if they are not identical, and influences the intention to use the avatar as well as emotional attachment [57]. People identify with their in-game avatars if they have a positive attitude towards them [47] and find the avatar characteristics important to themselves [38]. Subsequently, visual similarity has been shown to increase avatar appreciation (enjoyment, comfort, helpfulness) in users [13]. They tend to develop a sense of affinity towards their avatar, which can lead to increased self-disclosure and more authentic interactions online [68]. Affinity can be described as natural liking \u201cdriven by subconscious processes that are beyond conscious control\" [54]. Affinity can also be related to the degree of attraction or similarity between two or more entities. There is a significant effect of perceived visual similarity between an avatar and the user on self-awareness [26, 27], which can be attributed to the personalized avatar triggering emotions, beliefs and attitudes like affinity that facilitated identification. Thus, given the proposed manip-ulation of visual avatar-person similarity, we hypothesize, that there will be a main effect of avatar-person similarity manipulation on implicit affective identification, operationalized as affinity, compared to a random avatar.\nHypothesis 3: There will be higher implicit affective identification in the condition, where the facial features were not systematically manipulated, gradually declining with an increasing degree of manipulation.\nIn conclusion, visual avatar-person similarity that influences both perceived similarity, explicit self-identification as well as implicit affective identification with the avatar and could be used to elicit self-awareness in human users in sophisticated interactive virtual training environments."}, {"title": "A Theory-Based Methodology", "content": "In this section, the theory-based development of the methodology to systematically vary visual avatar-person similarity is described."}, {"title": "Perceptual Sensitivity and the Selection of Facial Features", "content": "In cognitive science literature, a subset of critical facial features with high perceptual sensitivity (PS) has been identified, which is described as the sensitivity to detect feature differences across faces and that are crucial for determining the identity of faces (i.e. face recognition across different images of the same face) [1]. In a set of studies, facial features were adjusted in a systematic and quantitative manner within a so-called \"face-space\", and perceptual effects of these adjustments were measured to determine a subset of critical features for which participants were found to show high perceptual sensitivity [1]. However, their research manipulated specifically static 2D images. In our approach to transfer these findings to dynamic avatars, the following five critical facial features were selected, based on [1]: Chin shape, jaw width, eye shape, lip thickness, and nose shape. Beyond their importance for identification, the selection of these five features for the process of avatar-person similarity manipulation was based on their technical feasibility to manipulate"}, {"title": "Avatar Creation and Modification", "content": "them in the open-access operationalization of the methodology discussed in Section 3.2.\nIn order to ensure the replicability of this work, we aimed to use exclusively openly accessible software tools to create the different degrees of avatar-person similarity manipulation.\nPrevious studies applied different techniques to achieve different levels of avatar-person similarity. [30] created avatars comprising a 3D mesh (a structural construction of a polygon-based 3D model), reconstructed from real imagery of participants, towards a cartoon-like virtual character-based avatar created by a 3D artist. Other studies used a 3D scan of the participant's faces to create highly similar avatar faces [57], avatars with a face that was modeled by a 3D artist after photographs [3], and online construction tools embedded in applications or games such as Yahoo! [65] and Second-Life [26]. The present study was concerned with a way to manipulate the avatar-self similarity by applying a scale on the same continuum, i.e. using the same source of a most similar avatar and afterwards being able to vary from that most similar avatar in a scale (e.g. see Table 1), manipulating PS effectively. Thus, a technical set-up that allowed for continuous manipulation of each of the 5 selected high-PS facial features was selected.\nTo comply with the research goal of creating visually detailed humanoid avatars, we selected existing software that allowed us to generate a realistic (i.e. high visual fidelity) 3D avatar from participant's photos, and then vary the appearance systematically according to differing degrees of similarity. Our selection criteria included a) the possibility to manipulate specific facial features on a continuous scale, b) the possibility to animate the created avatars (e.g. create short videos of facial movements) and c) a pragmatic approach to only use tools, that are open-access, require minimal technical knowledge and a reasonable amount of time and effort to create multiple avatars for each participant in order to make our methodology applicable for other research teams as well. After considering a range of available software tools, FaceGen Modeller Demo (facegen.com/modeller.htm) and MetaHuman Creator (metahuman.unrealengine.com) were selected to be used in this study. Other tools were considered (e.g. in3D or MeInGame), but subsequently excluded, because they did not fit the criteria above.\nFaceGen Modeller Demo (subsequently called FaceGen) is a desktop software to generate 3D heads from one or more pictures. The ideal results are obtained from inputting three images (front, left, and right of the face). FaceGen allows modifying 150+ parameters such as demographics (age, gender, racial group), shapes, colours, textures and individual facial features based on slide menus. Some of the limitations in regard to this study include that it only generates a 3D model of a face (not including hair) and does not include animation capabilities.\nTo compensate, we also used MetaHuman Creator, which is a free cloud-base app developed by Epic Games to create 3D high-fidelity virtual avatars (including hair). The creation of avatars does not require artistic modeling skills, since its 3D creation capabilities are also based on slide menus and interface controls. Another advantage of MetaHuman for this scenario of the research is that it allows exporting the 3D avatar to animation tools, which can be used to personalize facial animations including eye tracking."}, {"title": "Manipulation of Avatar-Person Similarity", "content": "Besides the challenge of creating a manipulable avatar most similar to a person, this research faced the challenge of defining a methodology to vary the degree of similarity between the avatar and the user. As elaborated in (Section 2.2), avatar-person similarity has usually been manipulated in the model of low similarity being a generic avatar that might simply match gender, race and ethnicity, to high similarity by matching clothes, or even the participant's faces (e.g. [67]). However, with fast advancements in animation technology [4] and the rise of platforms for their use like e.g. the Metaverse (e.g., [50, 33]), creating \u201crealistic\u201d personalized avatars and subsequently their similarity becomes relative to the technological progress. Even more importantly, as this research aims to better understand on a process level how visual similarity affects self-awareness and its antecedents in interactive virtual trainings, we aimed for a more fine-grained analysis of visual similarity manipulation beyond a simple distinction between personalized vs. non-personalized."}, {"title": "User Study", "content": "In a first user study, the effects of the varying degrees of visual similarity manipulation on the antecedents of self-awareness were examined. Following the recommendations for open research practices [12, 66], all materials (coding plan, data and analysis code) can be found on OSF\u00b9."}, {"title": "Participants", "content": "The study was conducted with voluntary participants recruited via various online platforms. Participants were required to be at least 18 years old, have access to a computer/mobile device with a camera, and have a minimum level of English proficiency of B2 according to the Common European Reference Framework for Languages (CEFR; Council of Europe 2001). Of the total of N = 88 participants, n = 55 were excluded due to incomplete responses or not responding to the second email (1). The final sample of n = 33 consisted of n = 13 males and n = 20 females between 18 and 40 years (M = 27.6 years, SD = 4.74 years). We offered participants who completed the study the option of receiving a short video of their personalized avatar and participating in a contest to win Amazon vouchers."}, {"title": "Study Design and Procedure", "content": "A within-subjects study was conducted fully online and used self-administered questionnaires delivered via an online survey platform (limesurvey.org). In order to systematically test hypotheses 1-3, we used the methodology detailed in Section 3, to systematically vary the degree of similarity. Thus, the study consisted of four conditions: high, medium, and low similarity (see Table 1) plus one control group (CG). The study was divided into two sessions, with an interval of 24 to 72 hours between them that corresponds to the time considered to generate the personalized avatars. The main dependent variables were perceived avatar-person similarity, explicit cognitive identification as well as implicit-emotional identification with the avatar.\nIn the first session, participants were asked to review introductory information about the study and sign the consent form and data protection. Participants confirmed their eligibility by self-reporting their level of English proficiency. If participants reported a proficiency level below the required level, they visualized a message that thanked them for participating and ending the survey. Participants with the required profi-ciency level preceded the survey by filling out a questionnaire that included data collection such as e-mail address 2, three facial images (as required by FaceGen) and demographic data.\nOnce the data of the participants from the first survey was received, the images were used to create personal-ized avatars to varying degrees of similarity to the faces of the participants, as described in Section 3.3. Once the avatars were created in MetaHuman, a 12 second-long GIF was created recording the predefined idle facial animation from each of the three conditions (0%, 50% and 100%). The idle facial animation contained simple facial movements of a natural human look.\nAs the next step, we set up the second survey by adding the recordings of each personalized avatar condition in the form of animated images (GIF). The conditions and instruments were presented to the participants in random order. The previous same-gender participant's 0% avatars were used as a control condition. The first two participants were presented with control condition a male and female avatar was created ahead from two volunteers' pictures."}, {"title": "Measurements and Instruments", "content": "The instruments for collecting the data described in the study design section were the following.\nDemographics: Participants were asked age and gender, level of formal education, the field and semester of study / current profession. In addition, we collect participants' affinity with technology, attachment style, and previous experiences with avatars.\nPerceived facial similarity between avatar and user: The subscale 'physical similarity' from the polythetic identification model [17], containing five items, was used to measure physical similarity (Hypothesis 1)."}, {"title": "Data Analysis", "content": "Prior to conducting the analysis, we assessed the presence of potential outliers, identifying values that exceed Q3 + 1.5xIQR or fall below Q1 - 1.5xIQR as outliers. A total of n=5 outliers were detected. On examination, the scores of these outliers were found to be within the range of plausible data, with no indication of measurement errors or inattention by the participants. Furthermore, analyses conducted using both raw data and data excluding outliers yielded similar results. Consequently, we opted to retain the outliers and present findings based on the complete data set.\nWe hypothesized that for all three tested constructs, there would be a significant main effect for condition, with the most similar (0% condition) scoring highest for perceived similarity, explicit identification and affinity. A repeated-measures ANOVA was used to examine the effect of condition (0%-,50%-, 100%-\nManipulation, CG) on each of the dependent variables individually. Shapiro-Test for normality and Mauchly's\nTest for sphericity both indicated violations. However, ANOVAs are rather robust against normality and sphericity violations, see [28]. Upon closer examination of the data, we decided to keep the ANOVA as our main analysis method. In order to ensure, the final reported result would not be biased by either the small sample size or the violations in the preconditions, we performed an additional ANOVA with bootstrapping as well as a Friedman test for non-parametric data. Since these analyses showed identical effects, we report the ANOVA results here. However, all analyses and results can be found in the additional online material of this article. Moreover, the reported results were corrected using the Greenhouse-Geisser method. Further, we performed post-hoc t-tests to examine the differences between each condition more closely (Bonferroni-Holm corrections were applied). Results are reported individually per construct.\nAs a manipulation check, we tested the perceived realism of the avatars with one item. While in the 0%-, 50% and the CG it was perceived as rather realistic, there was a significant main effect for realism with the 100%-condition having the lowest mean, indicating, that the avatar was seen as significantly less realistic.\nNaturally, in a highly personalized (small sample-size) study like this, individual differences and attitudes of participants may play a role. Since the method and the results of this study will serve as the fundament for a subsequent study series, we additionally opted for an in-depth explorative analysis. Firstly, we examined the correlations between all three dependent measures and gender, realism, experience with avatars, affinity with technology and attachment style. In a second step, we performed several ANCOVAs to examine possible confounding effects of the demographic variables. Data analyses were conducted with R version 4.2.3."}, {"title": "Results", "content": "The aim of this research in the context of data collection for the study was to validate the applicability of the methodology developed and test its effects on selected antecedents of self-awareness. We hypothesized that for all three tested constructs, there would be a significant main effect for condition, with the most similar (0% condition) scoring highest for perceived similarity, explicit identification and affinity (implicit identification).\nAll means and standard deviations can be found in Table 2."}, {"title": "Perceived Similarity", "content": "Hypothesis 1 examined the effect of the degree of avatar-person similarity manipulation (condition) on perceived similarity. The ANOVA revealed a significant main effect for condition, F(1.87,59.72) = 10.13, p <.001, \u03b7\u00b2 = .11. Subsequent comparisons did not show a significant effect between the 0%- (M = 3.34, SD = 1.26) and the 50%-condition (M = 3.18, SD = 1.21), t(32) = 1.36, p = .183, as well as the CG, t(32) =\n3.46, p = .008 and between the 100%-condition and the CG, t(32) = 2.14, p = .08. All other comparisons showed a significant difference, showing a steady decline in similarity with increasing similarity manipulation (0% = highest - CG = lowest). This included significant effects between the 0%- and the 100%-condition (M = 2.75, SD = 0.85), t(32) = 3.17, p <.013, as well as the CG (M = 2.44, SD = 0.73), t(32) = 3.83, p = .003. Further, between the 50%- and 100%-condition, t(32) = 2.54, p = .049. Thus, H1 was partially confirmed: Manipulation of avatar-person similarity influences the perceived similarity, except for the first two degrees of manipulation (see Fig. 5)."}, {"title": "Explicit Identification", "content": "Hypothesis 2 examined the effect of the degree of avatar-person similarity manipulation (condition) on explicit identification. The ANOVA revealed a significant main effect for condition, F(2.03,65.01) = 13.11, p <.001, \u03b7\u00b2 = .13 Subsequent comparisons did not show a significant effect between the 0%- (M = 2.76, SD = 1.84) and the 50%-condititon (M = 2.64, SD = 1.72), t(32) = 0.64, p = .527, or between the 100%- (M = 1.82, SD = 1.05) and the CG (M = 1.53, SD = 0.67), t(32) = 1.68, p = .206. All other comparisons showed a significant difference, showing a decline in explicit identification with increasing similarity manipulation. This included significant effects between the 0%- and the 100%, t(32) = 3.71, p = .002, as well as the CG, t(32) = 4.05, p = .002. Further, between the 50%- and 100%, t(32) = 4.03, p = .002, as well as the CG, t(32) = 4.16, p = .001. Thus, H2 was also partially confirmed: Manipulation of avatar-person similarity influences also explicit identification, except for the first and last two degrees of manipulation (see Fig. 6)."}, {"title": "Implicit Identification (Affinity)", "content": "Hypothesis 3 examined the effect of the degree of avatar-person similarity manipulation (condition) on affinity. The ANOVA revealed a significant main effect for condition, F(2.2,70.44) = 7.66, p <.001, \u03b7\u00b2 = .05. Subsequent comparisons again did neither find a significant effect between the 0%- (M = 3.22, SD = 1.77) and the 50%-group (M = 3.08, SD = 1.72), t(32) = 0.95, p = .694, nor between the 100%- (M =\n2.52, SD = 1.51) and the CG (M = 2.37, SD = 1.3), t(32) = 0.74, p = .694. However, all of the other group comparisons showed a significant difference, showing a decline in explicit identification with increasing similarity manipulation."}, {"title": "Exploratory in-depth analysis", "content": "In order to gather learnings for follow-up studies and future research, we performed an exploratory in-depth analysis. As a first step, correlations between the dependent variables and the demographic variables were examined. Results can be found in Table 2. In an additional analysis of covariances, we examined whether the variables realism, gender and previous experience with an avatar played a role. The analysis indicated an influence of the covariates in a type II ANCOVA, that did not show anymore when performing the type III variant, but no significant effect was found overall. The exact parameters, R scripts and results of this analysis can be found in the additional online material on OSF."}, {"title": "Discussion", "content": "This user study investigated the effect of manipulating specific facial features of virtual avatars by degrees of visual similarity to the participants on perceived similarity of the avatar, as well as two antecedents of self-awareness: explicit and implicit identification. The process of developing the methodology for avatar similarity variation involved the investigation of tools and solutions, the testing of their functionalities, and research on the theoretical background of aspects in which the methodology could be applied (i.e. visual similarity, affinity, identification, etc). A similarity scale was defined, formalizing three degrees of similarity variation (high similarity - 0%, medium similarity-50%, low similarity-100%). A user study was set up and performed to validate the application of the proposed methodology and test the effects of systematic similarity variation on the antecedents of self-awareness. Spefically, we hypothesized that a higher degree of visual similarity would lead to higher perceived similarity as well as explicit and implicit identification/affinity. The results of the study generally confirm these hypotheses."}, {"title": "User Study: Hypothesis Discussion", "content": "Manipulation check: All degrees except the 100%-manipulation were perceived as realistic. This lets us assume that all effects, especially the ones between the 0%-, 50%- and CG, can be attributed to the manip-ulation rather than an unnatural distortion of the participants' faces.\nH1: Manipulating visual avatar-person similarity using the developed methodology indeed showed an effect on the similarity perceived by the user in the expected direction (confirming H1). This also serves as an additional manipulation check for the following analyses. Single comparisons revealed, that there was a steady decline in perceived similarity between degrees of manipulation, indicating that the approach of adjusting specific facial features to manipulate the degree of similarity is suitable. This result provides an argument against generic or averaged avatars. The difference between 0%- and 50%-manipulation, although objectively different, was not perceived as dissimilar. This effect could be explained if we assume that the manipulation was still perceived too similar in the two conditions and gives future researchers and practitioners a bit of an error margin to work with, in terms of manipulating visual similarity.\nH2: Avatar-person similarity also showed an effect on the explicit identification by the user in the expected"}, {"title": "General Discussion", "content": "direction (confirming H2). Thus, the participants tended to identify more with an avatar, the more it was objectively similar to them. While not particularly surprising, this result has important implications, given that identification is one of the key antecedents in eliciting self-awareness. Examining the distributions of answers between the four conditions closely, however, in the 0% and 50%-condition, a wide range of answers was observable, compared to the other two conditions, where answers largely concentrated on the lower end of the scale. Single comparisons revealed that there was a steady decline in explicit identification with decreasing similarity. Taken together, these detailed analyses deliver a strong argument against generic, non-personalized avatars whenever explicit identification with the avatar and self-awareness elicitation are goals in the study. Here too, the difference between 0%- and 50%-manipulation did not have an effect on explicit identification by the user, and neither did the difference between 100%-manipulation and the CG. This effect could be explained assuming, that for a difference in identification, a small change in the avatar seems not enough, while in the 100%-condition, the participants apparently did not recognize themselves anymore (as further indicated by the significant effect between 50%- and 100%-, but not 100%-manipulation and CG). An interaction with the missing realism could be claimed here. However, the missing effect in the CG, which was perceived"}]}