{"title": "ExploreSelf: Fostering User-driven Exploration and Reflection on Personal Challenges with Adaptive Guidance by Large Language Models", "authors": ["Inhwa Song", "SoHyun Park", "Munmun De Choudhury", "Sachin R. Pendse", "Jessica Lee Schleider", "Young-Ho Kim"], "abstract": "Expressing stressful experiences in words is proven to improve mental and physical health, but individuals often disengage with writing interventions as they struggle to organize their thoughts and emotions. Reflective prompts have been used to provide direction, and large language models (LLMs) have demonstrated the potential to provide tailored guidance. Current systems often limit users' flexibility to direct their reflections. We thus present EXPLORESELF, an LLM-driven application designed to empower users to control their reflective journey. EXPLORESELF allows users to", "sections": [{"title": "1 Introduction", "content": "Articulating stressful or emotional experiences in words has been found to improve both physical and mental health by enabling individuals to process and express their thoughts and emotions [5, 74, 75]. It has been a widely circulated and popular means for individuals to self-reflect and make sense of themselves [21, 31], by simply sitting down to write the innermost thoughts and feelings without confines of grammar, punctuation, or any other formalities of written composition. However, writing about negative experiences and thoughts can be challenging as it often requires individuals to confront distressing thoughts and emotions, making it tempting for them to disengage from the process [75, 89]. Hence, there have been a number of adjustments to the activity to help with this process. For example, tools like self-help workbooks and prompted journaling have been developed to offer structured prompts that guide users in exploring their thoughts and emotions [64, 79]. The HCI community has also introduced interactive methods, such as using photos as journaling prompts [37] or employing a conversational assistant with sequences of probing questions [71]. These approaches mostly involved pre-defined prompts for writers to use, which has proven effective to spark thinking and dive into the process [16, 39]. It has also been noted that these prompts are inflexible and detached from the user context [6].\nThe generative capabilities of recent large language models (LLMs) have accelerated the advancement of intelligent writing support tools [49, 50], which commonly perform natural language generation for directly modifying the content (e.g., [42, 50]) or providing advice for improving the content (e.g., [22]). However, research on LLM-driven writing tools largely focuses on creative writing, and only a handful of works have recently begun to study intelligent support for writing about the self (e.g., DiaryMate [42]). Further, a growing body of research has investigated the LLMs' potential for mental health support in the form of conventional chat interfaces (e.g., [41, 46, 85, 92]). Although LLM-driven, open-ended conversations are intuitively analogous to therapists' counseling sessions, an agent who holds the therapist's persona tends to lead the conversation and sometimes can result in unintentional reinforcement of negative narratives [33, 41, 92]. Meanwhile, research suggests that when individuals are able to make choices and exert control over their experiences, they engage more meaningfully in the process and develop a stronger sense of ownership and responsibility for their growth [18].\nIn this work, we investigate ways to empower individuals to take greater control of the reflective process of their personal challenges while simultaneously leveraging the personalized and adaptive guidance offered by LLMs. To this aim, we designed and developed EXPLORESELF, an LLM-infused interactive system for exploring and reflecting on personal challenges. EXPLORESELF allows users to freely expand related themes from the initial narrative and drill down probing questions to reflect on aspects of themes in depth. To facilitate exploration, the system provides on-demand guidance, such as prompting keywords and comments tailored to their writing. The design of EXPLORESELF was informed by formative interviews with nine mental health professionals, where their challenges and approaches to managing the counseling sessions inspired our interface design and the generative pipelines.\nTo understand how people interact and engage with EXPLORESELF in exploring their personal challenges, we conducted an online lab study with 19 individuals, where they explored their personal challenges using EXPLORESELF for 30 to 60 minutes. Through user-directed exploration with diverse forms of adaptive guidance by LLMs, EXPLORESELF enabled individuals to engage in meaningful self-reflection while maintaining control over the direction of their reflection. Participants actively leveraged the navigation components (i.e., themes, questions, and summary) and the adaptive guidance (i.e., keywords, and comments) in individualized patterns. Participants' perceived agency was significantly increased after the session. Participants reported that the system's adaptive features, such as the ability to select themes, choose from multiple Socratic questions, and toggle keywords and comments, contributed to their sense of control and autonomy. Participants decided which aspects to focus on or revisit later in a way that balances their cognitive and emotional effort with the expected significance of the engagement regarding their personal concerns. Drawing on the findings, we discuss how the components of EXPLORESELF collectively fostered a dynamic and personalized reflective process, helping people feel more empowered in navigating their personal challenges.\nThe key contributions of this work are threefold:\n(1) The design and implementation of EXPLORESELF, a novel LLM-driven web application that supports guided writing about breakdown topics regarding a personal issue, encouraging sense-making and refreshment of thoughts on it. EXPLORESELF's design was informed by formative interviews (N = 9) with clinical psychologists and professional licensed counselors.\n(2) An empirical study using EXPLORESELF, with 19 individuals with varied severity and types of personal issues. From the quantitative and qualitative analysis, we provide an understanding of"}, {"title": "2 Related Work", "content": "In this section, we cover the related work in the areas of (1) writing for well-being and (2) technology-mediated writing for well-being."}, {"title": "2.1 Writing for Well-being", "content": "A substantial body of research has demonstrated that the act of writing as an instrument for exploring personal thoughts and emotions can promote self-healing and personal growth, significantly enhancing both physical and emotional well-being [5, 74, 75]. It has been widely studied across diverse contexts, including expressive writing from social psychology [75, 81], integration into specific psychotherapies as a treatment (e.g., guided autobiography, using diary in CBT), positive interventions to promote psychological well-being (e.g., writing about gratitude and forgiveness), and through personal practices [81]. One of the most widely researched methods is expressive writing, which involves writing about one's deepest thoughts and feelings regarding stressful experiences [75]. Across these various writing for well-being practices, the common focus lies in translating personal experiences into written language, allowing individuals to process and organize their thoughts and feelings in a meaningful way [74-76, 81].\nThrough this process, individuals often derive meaning from stressful events and foster a sense of hope as they work through their emotions and gain new perspectives [27]. This activity has been shown to yield significant benefits for individuals across various demographics, including different age groups [45, 95], gender [57], cross-cultures [19, 43], and health conditions [54, 80]. Studies have also found that writing can be beneficial for well-being when people engage in writing outside of controlled laboratory settings, such as at home or online [52]. While several theories attempt to explain the connection between expressive writing and health, no single mechanism has emerged as dominant, likely due to the varied experiences and expectations of participants [48]. However, studies from psychology have suggested that writing allows individuals to release suppressed emotions [51], gain deeper insights into their experiences [74], and develop a sense of control over their thoughts and emotions through self-reflection and emotion regulation [51]. In this way, writing can be used intentionally and purposefully to foster self-discovery, emotional growth, and personal insight, enabling individuals to gain a deeper understanding of themselves and their experiences [1, 78, 94].\nResearch from psychology has indicated that writing about stressful events demands a significant level of perceived control, as it helps individuals organize, connect, and contextualize their thoughts and emotions [2, 25]. This sense of control is not only essential for initiating or sustaining a writing practice but is also closely tied to physical and psychological well-being, making it a"}, {"title": "2.2 Technology-Mediated Writing for Well-being", "content": "With the soaring number of digital writing tools, individuals increasingly engage in writing for well-being using these tools, such as on online health platforms and digital journaling tools, to motivate themselves to engage in writing for well-being. [55, 90]. These spontaneous, technology-mediated practices provide a space for self-expression and reflection, yet users often face challenges in maintaining consistent engagement and fostering deeper introspection. In response, the HCI community has explored methods to support individuals in their reflective writing journeys, focusing on strategies to enhance engagement by introducing the social presence of chatbots [71] and providing contextual data to aid reflection [29]. These approaches have aimed to create structured yet flexible systems that guide users in navigating their thoughts and emotions more effectively.\nThe generative capabilities of LLMs (e.g., GPT [9], Gemini [93], Claude [3], HyperCLOVA [40]) have motivated the development of flexible and adaptive support for writing for well-being (e.g., [41, 42, 67, 87, 99]), offering personalized interactions that acknowledge and are responsive to what users write. For example, Kim et al. explored the potential of interactive dialogue with LLMs as an alternative format for reflective journaling for psychiatric patients, where LLM chatbots provided adaptive reflective questions [41]. Their findings demonstrated that these adaptive prompts benefited individuals by helping them explore and reflect on their past experiences and emotions. However, since interactions with LLMs are naturally and intuitively conversational in nature, many LLM-driven approaches let users \u201cchat\u201d with an AI agent rather than write [33, 41, 70, 92]. Conventional turn-taking structure in chat"}, {"title": "3 Formative Interviews", "content": "To inform the design of EXPLORESELF, we conducted semi-structured interviews with mental health professionals, whose main role is to guide individuals in exploring and addressing their personal challenges. By understanding their underlying strategies and expertise, we aimed to gain a nuanced understanding of the challenges of providing effective guidance, which in turn informs the key considerations for designing an interface that incorporates therapeutic principles for its guidance, as well as to obtain insights into the potential and proper role of AI."}, {"title": "3.1 Procedure and Analysis", "content": "We recruited nine experts (E1-9; see ) through snowball sampling and internal network, who have extensive experience in clinical psychology and professional counseling. Participants comprised five clinical psychologists, three licensed therapists, and one psychiatrist. Five were based in South Korea, three in the United States, and one had experience working across the US and the UK. Participants had an average of 15.11 years (ranged 5 to 26) of experience in mental health care. Each interview lasted about one hour and was conducted in person or remotely, depending on the participants' availability. We compensated participants with 100,000 KRW or 100 USD, depending on their residence.\nThe interviews covered participants' strategies for helping clients navigate personal challenges, typical difficulties clients face, and potential roles they envision for LLM-driven systems in the therapeutic process. To elicit their feedback, we presented the experts with an example of a personal challenge and asked them to describe how they would approach such a case, including how they might guide the client through the process. Additionally, we presented a paper prototype of an LLM-driven guided writing where the system suggests related topics based on the initial problem narrative the user wrote. We asked for participants' feedback on its potential utility and areas for improvement.\nAll interviews were audio-recorded and transcribed for analysis. Employing thematic analysis [8], one researcher coded transcripts and grouped them into broader themes. The research team iterated several rounds of discussion to refine themes. In the following, we cover the findings from the interviews."}, {"title": "3.2 Findings", "content": "Importance of Guided Exploration in Addressing Individual Needs. Participants highlighted the essential role of therapists in tailoring guidance to explore the unique needs of clients. E8 noted, \"When clients first enter therapy, they typically have a vague desire to 'feel better' but struggle to articulate specific goals.\" To address such ambiguity, therapists often start conversations to help clients clarify their objectives and understand the underlying issues they need to address. This process not only sets effective goals for the therapy but also empowers clients to gain a clearer understanding of their own difficulties. To guide their clients, all participants commonly used a strategy of asking a series of focused, open-ended questions to encourage self-reflection. E2 shared that she often encourages clients to write about their issues between sessions, but many times, they struggle to decide what topic to write about. E2 remarked, \"I might suggest they write about certain things that arise from our collaborative exploration and give them specific assignments.\"\nChallenges in Effective Questioning during Conversations. All participants highlighted the challenges of asking adequate questions that the client would be ready to accept and explore. E6 noted, \"If I ask certain questions too early, the client might push back, thinking I'm making assumptions,\u201d emphasizing that clients should feel understood and supported, rather than overwhelmed or led in a direction they are not prepared to explore. Similarly, E4 mentioned, \"My biggest challenge is with clients who don't have much to say-they may shut down or resist answering. In these cases, I often have to find alternative questions or pathways to re-engage them.\" Participants pointed out that there is no holy grail when it comes to the sequence of questions, and therefore, the effectiveness of any therapeutic approach depends largely on the therapist's ability to decide when and what the client would find it acceptable.\nGuidance to Enhance Awareness of the Process. Participants emphasized the importance of keeping clients informed about the status of the current therapeutic conversation, in part to stay focused and to prevent them from feeling overwhelmed or lost in their thoughts. They also noted that understanding the flow of the session and the broader discussions context helps clients construct coherent narratives and stay engaged in their own problems. For those struggling with ruminative thinking, where thoughts can"}, {"title": "4 EXPLORESELF", "content": "In this section, we first cover the design rationales we derived from prior literature and the formative study. We then describe the system design and user interfaces of EXPLORESELF and implementation details, including the generative pipelines."}, {"title": "4.1 Design Rationales", "content": "DR1. Provide diverse pathways to foster user agency and deep reflection. Recognizing that individuals may explore their thoughts through various cognitive pathways, it is crucial to foster flexible thinking and support a sense of autonomy in the reflective process [17, 38, 88]. In our formative study, professionals emphasized the importance of allowing clients to control their own reflective journeys. Therapists adjust their questions based on the client's responses and collaboratively identify topics to prioritize for deeper exploration. Therefore, we designed EXPLORESELF to provide a rich resource that enables users to take the lead in shaping and guiding their reflective pathways. First, the EXPLORESELF generates \"Themes\"-potential areas of reflection-based on the initial narrative provided by the user. Second, once the user selects a theme, the system suggests multiple \"Socratic questions\" [14], an evidence-based approach that encourages critical thinking and self-reflection. These questions prompt users to explore underlying emotions and perspectives that may not have surfaced in their initial narrative.\nDR2. Provide guidance to support expression without directing content. In our formative study, professionals highlighted the usefulness of providing subtle guidance to help individuals articulate their thoughts and emotions. They emphasized that people often struggle with open-ended or thought-provoking questions, which can be cognitively overwhelming. In the context of writing for well-being, the benefit lies in the individual's process of translating their experiences into language [75]. To preserve this, our system avoids directly shaping the content of users' expressions (e.g. generating direct sentences for users to adopt [42]), instead offering scaffolding that gently supports the reflective process. To achieve"}, {"title": "4.2 System Design and User Interface", "content": "EXPLORESELF is designed to assist users in navigating, exploring, and making sense of personal challenges through writing with structured and adaptive guidance by an LLM. The application consists of three primary phases of user engagement: (1) writing the initial narrative, (2) exploring the narrative, and (3) wrapping up and summarization. Each phase was carefully designed to encourage different aspects of self-reflection on and understanding of the personal challenges, helping users process their thoughts and emotions effectively. In the following, we describe each phase and interactions through a usage scenario: Jane is a retiree who looked forward to enjoying the freedom she earned after decades of hard work. She had plans to explore new hobbies and focus on self-development. However, her daughter asked Jane to care for her newborn during the daytime. Although Jane loves spending time with her grandson, she sometimes feels that her own life has become overshadowed by her new responsibilities. The freedom she anticipated seems out of reach, and she occasionally struggles with a sense of purposelessness, yearning for time to pursue her personal growth. Now that she turns to EXPLORESELF to process this challenge."}, {"title": "4.2.1 Writing the Initial Narrative", "content": "Jane opens EXPLORESELF and the web page shows the Initial Narrative page (Figure 2-A), which prompts her to articulate her challenges. The interface presents a borderless text area encouraging Jane to write freely about what weighs on her mind and her thoughts and feelings associated with it (a in Figure 2-A). Jane jots down her story and clicks the 'Start Exploration' button (b in Figure 2-A), which sends her to the Exploration phase, where the system facilitates a more structured process of introspection and analysis."}, {"title": "4.2.2 Exploring the Narrative", "content": "The Exploration page (Figure 1-A) allows Jane to explore and reflect on her challenges by navigating both the breadth and depth of her narrative.\nThemes: Expanding breadth. Jane clicks the 'Explore Themes'button ( in Figure 1-A), and it opens the Theme Selection modal dialog (Figure 1-B). The dialog lists two Al-generated themes related to her initial narrative: 'Overwhelmed by new responsibilities' and 'Struggle with purposelessness.' She would like to explore both themes but saves the second one for later by clicking the bookmark icon (b in Figure 1-B), which stores the theme in Pinned Themes. She then clicks the 'Overwhelmed by new responsibilities' theme ( in Figure 1-B). And a new Theme panel (Figure 1-C) appears on the main page.\nQuestion Threads: Expanding depth. The theme panel lists three AI-generated Socratic questions that may encourage deeper reflection on the current theme. Of these questions Jane selects the first one: \"In what ways could you possibly incorporate"}, {"title": "4.2.3 Wrapping Up and Summarization", "content": "Jane enters the AI Summary screen (Figure 2-B). On the left column, she can review a comprehensive list of themes, questions, and answers ( in Figure 2-B). On the right column, an AI-generated summary is displayed (@ in Figure 2-B). The summary synthesizes the key themes and insights from the user's exploration into a concise essay. Using the back button ( in Figure 2-B), she can also go back to the Exploration screen and return with updated exploration paths. Jane reads through the AI summary and ends the exploration."}, {"title": "4.3 Generative Pipelines", "content": "In this section, we describe the generative pipelines incorporated in EXPLORESELF to support the generation of themes, questions, keywords, comments, and summaries. Figure 3 illustrates the data flow and a gist of LLM instructions for each pipeline. The pipelines refer to the current exploration status (see Figure 3, left), including the initial narrative, themes, questions and answers, and keywords and comments selectively depending on the type of pipeline. The exploration status is inserted to the structured input instruction formatted in XML. The underlying LLMs run on instructions following the chain-of-thought prompting approach [98], where the model is instructed to provide meta-output (see thin texts in Figure 3, right), such as rationales of the output, along with the requested output to enhance the reliability of generation. We consistently applied a 'therapeutic assistant' persona to the instructions (see dark boxes in Figure 3, right) to better contextualize the generation [26, 97].\nThe Theme Generation step (Figure 3-A) identifies themes that arise from their personal narratives and previous interactions with the system. The model is instructed to name themes that are closely aligned with the user's language and expressions. In case the user does not grasp the meaning of the original theme name, the model also provides alternative expressions to allow the user reveal them on the Theme selector dialog (see in Figure 1-B). To further guide this behavior, we let the model clarify which part of the initial narrative each theme stems from (see the white box in Figure 3-A) (See Section A.1). The Question Generation step (Figure 3-B) suggests probing questions for a given theme. The model is instructed to craft socratic questions [14] that encourage users to navigate deeper into their thoughts and feelings. Each question is designed to resonate with the user's language and context (See Section A.2).\nTo further guide the user while reflecting on the questions, the system also provides keywords (Figure 3-C) and comments (Figure 3-D). When generating keywords, the model is instructed that the keywords should (1) serve as cognitive scaffolding, (2) activate potential blind spots for the user, and (3) be relevant to the user's background and core values (See Section A.3. As for the comments, the model is instructed to first decide the category of the comment from one of the predefined categories: (1) tips for approaching the question, (2) encouraging feedback, (3) sub-questions elaborated from the questions, (4) insightful comment, and (5) others (See Section A.4).\nWhen generating AI summary (Figure 3-), the pipeline synthesizes the user's themes, questions, and answers into an essay in several paragraphs. The model is instructed to generate a concise and focused story, using the user's own language and expressions where appropriate. The summary is intended to highlight key themes, emotions, and notable progress, offering a clear snapshot of the user's pathway of exploration. Also, the model tries to make the summary commensurate with the volume of the content of the user's writing, not extrapolating details and staying grounded in the user's actual input (See Section A.5)."}, {"title": "4.4 Implementation", "content": "EXPLORESELF Consists of (1) a backend server that manages user data and LLM pipelines and (2) a frontend web interface, both written in TypeScript [60]. The server runs on the Express.js [24] framework, providing core functionalities via REST APIs and storing the user data in MongoDB [62]. We implemented the LLM pipelines using LangChain.js [47] incorporating OpenAI [69]'s GPT-4 ChatCompletion API. As LLM's capabilities of dealing with non-English texts are inferior to equivalent English texts due to the inefficient tokenization [77], we chose gpt-4o\u00b9 as an underlying model, which involved an improved Korean tokenizer with state-of-the-art performance. The web interface was implemented using React.js [59]."}, {"title": "5 User Study", "content": "We conducted an exploratory study to examine how individuals interact with EXPLORESELF and how it may foster exploration and reflection on personal challenges. The study was conducted online via Zoom to ensure that participants could engage in the study in an environment of their choice, where they could feel most comfortable and secure. Conducting the study online allowed for greater flexibility in participation, enabling individuals to interact with EXPLORESELF at their own pace and in their preferred settings, which is known to lead to more authentic and reflective responses [30, 84]. Our study protocol was approved by the public institutional review board of the Ministry of Health and Welfare of South Korea prior to recruitment."}, {"title": "5.1 Participants", "content": "We recruited 19 participants (P1-19; 10 female) by advertising the study on a local social community platform and online university communities in South Korea. Our inclusion criteria were adults who (1) are 19 years old or older; (2) are native Korean speakers; (3) are currently staying in Korea; (4) can join an online study in"}, {"title": "5.2 Safety Considerations", "content": "Although our target participant group did not specifically include individuals experiencing mental illness, we prepared safety protocols for the study based on the work of O'Leary et al. [68], whose"}, {"title": "5.3 Study Setup and Procedure", "content": "Each participant was invited to a 90-minute study session remotely via Zoom video call on their computer. Instructions for installing"}, {"title": "6 Results", "content": "In this section, overall system usage based on quantitative metrics from interaction logs and surveys. We then cover how the system"}, {"title": "6.1 Overall System Usage", "content": "Participants wrote about a wide range of personal challenges in their initial narratives, from personal relationships to dilemmas in life decision-making. summarizes the categories of initial narratives participants entered. Participants mostly engaged with the challenges regarding personal relationships (12 participants; 63%), followed by self-development (9 participants; 47%), self-identity & personal character (8 participants; 42%), stability in life (6 participants; 32%), and health (5 participants; 26%). The initial narratives often described multiple interconnected topics.\n summarizes the syllable counts of participants' written inputs (i.e., initial narratives, and responses to questions) and the number of themes, questions, keywords, and comments generated or requested by participants. The average syllable count of the initial narratives was 233.63 with high variance (SD = 299.96, min = 13 [P12], max = 1347 [P8]). The total syllable count of all responses per participant was 745.47 on average (SD = 349.65, min = 325 [P10], max = 1381 [P13]). There was a moderate correlation between the syllable count of the initial narrative and the total syllable count of the responses, with a Pearson correlation coefficient of 0.49 (p = 0.03), indicating a statistically significant relationship.\nThere was also a high individual variance in how participants spent time across screens. illustrates the participants' timelines of the exploration phase, split by the type of screens they stayed on. None of the participants took breaks during their engagement, and they took an average of 37.86 minutes in the entire exploration phase (SD = 11.58, min = 17.37 [P11], max = 58.93 [P8]). While writing the initial narrative, participants spent an average of 5.82 minutes (SD = 5.40, min = 0.3 [P12], max = 17.38 [P2]; see yellow bars in ). Then they spent an average of 31.77 minutes (SD = 9.42, min = 13.82 [P11], max = 48.8 [P13]) for both exploring and reviewing the AI summaries (see green and blue bars in ).\nParticipants showed diverse patterns in exploration, engaging with a varying number of themes and questions suggested by EXPLORESELF. reports the descriptive statistics of participant engagement. On average, participants engaged with 4.89 themes (SD = 2.26, min = 2 [P3, P4], max = 11 [P16]) and 11.47 questions (SD = 7.28, min = 3 [P4], max = 28 [P12]). The number of questions per theme averaged 2.58 (SD = 2.61, min = 1 [P4, P5, P6, P8, P9, P10, P11, P13, P14, P16, P18], max = 16 [P17]). The total syllable count of responses written during the exploration phase averaged 796.95 (SD = 464.44, min = 269 [P12], max = 1674 [P13]). illustrates the results of exploration captured from selected participants, who showed distinct engagement patterns with different components. For example, P4 actively leveraged keywords (purple capsules in ), and P7 generally used both the keywords and comments (blue dots in ) throughout all questions. P8 wrote an extreme amount of text for the initial"}, {"title": "6.2 Sense of Agency over Exploration", "content": "Participants' perceived agency on their challenge increased after using EXPLORESELF: The pathway subscale score, which we collected before and after the system use, significantly increased from 22.32 (SD = 4.91) to 24.95 (SD = 5.86) by 2.63 on average (t(18) = 2.80, p = 0.012*). Cohen's d of the two means was 0.66, indicating the effect size of the gaps falling between medium (0.5) and large (0.8). Specifically, the scores of 15 out of 19 (79%) participants increased.\nIn debriefing, participants expressed varying perceptions of their agency while using EXPLORESELF, with several factors influencing their sense of control. Some participants felt that the acknowledgment of their wordings in the AI-generated text played a crucial role in shaping the experience. P11 observed that while the Al sometimes paraphrased his inputs into different expressions in its generation, this gave him the impression that the AI was taking"}, {"title": "6.3 User-directed Navigation", "content": "Participants navigated through themes and questions by making deliberate choices about whether to explore deeper into a particular theme (i.e., add a new question to the thread) or move on to a new theme. Some participants managed their emotional engagement with a theme by deciding when to stop drilling into certain topics to avoid emotional distress or over-involvement. P17 explained \u201cwhile certain questions seemed helpful, continuing to engage with them might have deepened my emotional engagement, but I wasn't quite ready at the moment. I thought I would come back at some point.\u201d\nBased on the findings from participant debriefing interviews, we present how participants interacted with the themes and questions in the pathways of processing their thoughts and emotions.\n6.3.1 Expanding Viewpoints through Themes. Participants generally found the LLM-generated themes were reflective and responsive to their previous input, with many noting the relevance and accuracy of the suggestions. They reported that they selected the themes by prioritizing clarity and personal relevance, aiming to focus on issues that they felt were actionable and meaningful. For instance, P18 preferred more \"condensed\" words as themes, believing they would lead to more insightful AI-generated questions. Others, like P5 and P8, tended to select themes that aligned with their immediate concerns, allowing them to focus on issues they could actively address. At the same time, however, participants avoided themes that felt overly literal or much echoed their initial"}, {"title": "6.3.2 Organizing Angles and Attitudes through Questions", "content": "Participants found that being presented with multiple questions helped them consider their challenges from various angles, exploring different aspects and depths of their situation. P7 noted how it allowed him to see \"how different questions can expand one thought into multiple pathways,\" likening the process to a \u201cmind-storming\u201d session where diverse questions spurred deeper thought. P11 added that seeing questions tied to his previous responses helped \"take the reflection process step by step, encouraging [him] to explore aspects they may not have considered otherwise.\" Some participants viewed the act of deciding which question to engage with based on what seemed most effective at the moment as a reflective practice in and of itself. P5 mentioned, \"If new challenges arise, I can think through"}, {"title": "6.3.3 Objectification and Reiteration through Al Summary", "content": "Participants generally viewed the Al summary to bring clarity and objectivity to their often complex and unorganized thoughts by distilling the fragmented responses into an organized narrative. In turn, the Al summary seemed to foster iterative reflection; twelve out of 19 participants (63%) revisited the Exploration page back, explored more, and went back to the AI summary page to check the new summary reflecting additional responses (See dark blue bars in ). P12 remarked, \u201cI liked the summary, but I was curious how it might turn out if I revisited it, so I kept checking. After seeing the summary again, I thought of things I had missed and wrote them down, then went back to see how the updated summary looked. This back-and-forth really helped me organize my thoughts.\u201d This iterative process, where participants reviewed and refined their reflections, enhanced their engagement and allowed for further self-exploration.\nSome participants also reported that the AI summary helped them face uncomfortable or avoided thoughts. P18 recalled that she initially wrote, \u201cWatching YouTube videos makes me more tired,\u201d and seeing the Al repeat it in the summary forced her to confront this feeling more directly. The Al's neutral tone in the summary helped participants face these challenging thoughts without feeling overly judged, as P2 also described, \"It's something I already know, but the Al organizes my situation objectively. If a person did this, it might feel uncomfortable, but with AI, it doesn't bother me.\""}, {"title": "6.4 Supporting Self-Expression", "content": "On the question panels, EXPLORESELF provided adaptive guidance, including keywords and comments. In this section, we cover how these elements of guidance helped participants' exploration and reflection process.\n6.4.1 Enriching and Rethinking Expressions through Keywords. Participants could toggle on the keywords to reveal them, and seventeen out of 19 (89%) participants saw keywords more than once during the exploration phase (see 'Total # of keywords' in Table 4), but with varying levels of engagement with them. Some participants received keywords as a valuable tool for articulating their thoughts, while others either used it selectively or chose not to rely on them. Many participants used the keywords as prompts to help express their emotions and ideas more clearly. For instance, P7 mentioned while reflecting on emotions after a conflict with their children, he initially thought of simplistic terms like \u201canger\u201d or \"sadness.\" However, the keywords suggested deeper and more nuanced emotions like \u201cregret\u201d and \u201cpowerlessness,\" which broadened their emotional vocabulary and helped express himself more fully. Similarly, P14, emphasizing that her age is over 60, mentioned that \"As I age, I struggle to think of the right words and expressions, but seeing the keywords made it easier to express myself.\u201d\nSome participants used the keywords as a way to explore new perspectives or deepen their reflections. P8, for instance, frequently clicked See More Keywords by mentioning, \u201cthe Al was smarter, showing me words I couldn't have thought of.\u201d The keywords would prompt participants to think beyond their initial responses and anchor their reflections. P13 also mentioned that keywords sparked associations with aspects of the matter that she had not thought of in the first place. At the same time, some participants reported that the keywords mitigated the mental burden while organizing negative thoughts for answering. P4, who had experienced trauma, found the keywords helpful in guiding him through some of his painful memories. He noted that the keywords made it less emotionally overwhelming to revisit these thoughts because EXPLORESELF offered possible expressions they could choose from, making the process feel more manageable.\""}, {"title": "6.4.2 Iteratively Developing and Refining Answers through Comments", "content": "Participants were exposed to one comment per question by default, and fifteen out of 19 (79%) requested additional comments more than once during the exploration phase (see 'Total # of comment requests' in Table 4), with varying number of requests per participant. Initial impressions of the comments seemed to"}]}