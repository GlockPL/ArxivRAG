{"title": "Multiple Global Peaks Big Bang-Big Crunch Algorithm for Multimodal Optimization", "authors": ["Fabio Stroppa"], "abstract": "The main challenge of multimodal optimization problems is identifying multiple peaks with high accuracy in multidimensional search spaces with irregular landscapes. This work proposes the Multiple Gloal Peaks Big Bang-Big Crunch algorithm, which addresses the challenge of multimodal optimization problems by introducing a specialized mechanism for each operator. Inspired by the evolution of the universe, Multiple Global Peaks Big Bang-Big Crunch groups the best individuals of the population into cluster-based centers of mass and then expands them with a progressively lower disturbance to guarantee convergence. During this process, it (i) applies a distance-based filtering to remove unnecessary elites such that the ones on smaller peaks are not lost, (ii) promotes isolated individuals based on their niche count after clustering, and (iii) balances exploration and exploitation during offspring generation to target specific accuracy levels. Experimental results on twenty multimodal benchmark test functions show that Multiple Gloal Peaks Big Bang-Big Crunch generally performs better or competitively with respect to other state-of-the-art multimodal optimization algorithms.", "sections": [{"title": "1 Introduction", "content": "Multimodal optimization problems (MMOPs) are characterized by having multiple optimal solutions [1]. Each optimum in MMOPs is considered a peak, and the solvers must identify multiple peaks simultaneously with an appropriate level of accuracy. This scenario is frequently encountered in real-world applications [2, 3], in which relying on a single optimum"}, {"title": "2 Big Bang-Big Crunch Algorithm", "content": "The Big Bang-Big Crunch (BBBC) algorithm was proposed by Erol et al. [30, 32] to address some of the biggest disadvantages of genetic algorithms: premature convergence, convergence speed, and execution time. Inspired by the evolution of the universe, it is composed of two phases: (i) explosion, or big bang, in which the energy dissipation produces disorder and randomness, and (ii) implosion, or big crunch, in which randomness is drawn back into a different order. BBBC creates an initial random population P uniformly spread throughout the search space (bang), evaluates its individuals, and groups them into their center of mass"}, {"title": "3 Multiple Global Peaks BBBC", "content": "Multiple Global Peaks BBBC (MGP-BBBC) is a multimodal extension of the BBBC algorithm (Sec. 1). Similar to its predecessor k-BBBC [22], MGP-BBBC identifies the multiple centers of mass by dividing the population into clusters. However, while k-BBBC relied on k-means [34] and therefore required a given-fixed number of clusters, MGP-BBBC is based on the mean-shift clustering [35, 36], which automatically determines the number of clusters by identifying dense regions in the dataset space. Furthermore, unlike k-BBBC, MGP-BBBC amis at localizing only the global peaks, disregarding any local sub-optimal solution."}, {"title": "3.1 Survival Stage", "content": "Algorithm 2 shows the survival stage, which identifies the elites in the population and stores them in an archive A having the same size as the population O. An elite is defined as an individual with high fitness, and MGP-BBBC filters out non-elites with a \u03bc + \u03bb schema [37] (lines 14-15). However, by doing so, two suboptimal individuals close to the same peak might filter out a third isolated suboptimal individual with worse fitness but close to another peak\u2013 therefore, missing that peak. This is even more exacerbated in problems featuring peaks with different sizes of concave regions, such as the Vincent function shown in Fig. 2(a). It is more likely that a uniform exploration of the search space would generate elites around the large peak rather than the small one.\nTherefore, before non-elite removal, MGP-BBBC applies a distance-based filtering operation: it calculates all the pairwise distances in the population A and O (lines 4-5), and then applies the filtering procedure shown in Fig. 2(b) on both populations separately (lines 7-8). For each pair of individuals, this operation removes the one with worse fitness if their distance is smaller than a threshold $th$, allowing far away individuals to dominate over individuals in high-density regions. The pseudocode of the pairwise distances and the filtering operation are reported in Algorithm 3 and 4, respectively. The new archive of elites A is then composed of the union of the filtered populations (line 9).\nHowever, the size of the new archive A must be greater or equal to the desired population size n for the \u03bc + \u03bb schema to work. This might not always be the case, depending on the extent of filtering performed: the larger the threshold $th$, the more individuals will be filtered out. Therefore, MGP-BBBC dynamically tunes the value of the threshold starting from the same value as the clustering bandwidth h (line 4 of Algorithm 1) and decreasing it by a small amount (i.e., by 10%) until the size of the archive is greater or equal to n (lines 6-13). As the generations increase and the population converges to the peaks, the value of $th$ will also decrease.\nNote that the first time MGP-BBBC calls the survival stage, A will be empty (line 3) and, therefore, assigned directly to be filled with the individuals in the current population O (lines 16-17). Furthermore, sorting (line 14) is based on the individuals' fitness, and it is in descending or ascending order based on maximization or minimization problems, respectively.\nWith the time complexity of the pairwise distance calculation and filtering operation being both $O(n^2)$, the time complexity of the survival stage of MGP-BBBC is $O(\\delta_{th} \\cdot n^2 + n \\log n)$ where the term $\\delta_{th}$ indicates the number of decrements of $th$, which at most depends on its data type resolution until data underflow. If data underflow occurs, then the remainder in A is filled with old elites randomly picked\u00b9."}, {"title": "3.2 Big Crunch", "content": "Algorithm 5 shows the big-crunch operator of MGP-BBBC, which identifies the centers of mass COM within the archive A. This operation relies on mean-shift clustering [35, 36], which iteratively shifts each point to a higher-density position until convergence. The points converging to the same position are assigned to the same cluster. The procedure is reported in the supplementary material under Algorithm S.2, and it uses a flat kernel function requiring"}, {"title": "3.3 Big Bang", "content": "Algorithm 7 shows the big-bang operator of MGP-BBBC, which generates new offspring O from the centers of mass COM retrieved by the big-crunch operator (see Sec. 5). While generating offspring, it is essential to properly balance exploration and exploitation to retrieve peaks with high accuracy. To achieve this balance, MGP-BBBC dynamically tunes the extent of expansion of the big-bang operator (line 2). While the standard BBBC algorithm decrements the extent linearly as specified in Eqn. (2), MGP-BBBC divides it into two trends based on the total number of generations g \u2013 as shown in Fig. 3. During the first 60% of generations, the extent is decreased logarithmically from a starting value (empirically set to be one-fourth of the problem's bound when it was observed a population distributed on the search rather than on the bounds) to 1.0E-01: in this phase, MGP-BBBC will explore the surroundings of the centers of mass, localizing as many global peaks as possible. During the last 40% of generations, the extent will follow a constant trend with five uniformly distributed steps, going from 1.0E-01 to 1.0E-05: in this phase, MGP-BBBC will exploit the centers of mass, converging with high accuracy to the respective global peak. The pseudocode of the procedure is reported in Algorithm 8.\nOnce the extent of expansion $e$ is set for its current iteration, the big-bang operator applies it on every center of mass (line 4), producing a number of offspring defined by the respective element in OPC (line 5). Each offspring is produced by applying a random disturbance with, at most, a magnitude equal to $e$ (lines 6-8). Note that the new individual $X$ is generated within the bounds of the search space with the filtering formula at line 7, which is applied to all decision variables and their respective bounds."}, {"title": "4 Experimental Study", "content": "4.1 Benchmark Functions and Performance Metrics\nWe used the CEC'2013 benchmark set [38] to evaluate MGP-BBBC performances. The CEC'2013 benchmark set contains twenty multimodal maximization problems, listed in Table 1 with their properties. Specifically, $F_1$ - $F_3$ are simple mono-dimensional functions, $F_4$ - $F_7$ and $F_{10}$ are scalable two-dimensional functions, $F_8$ - $F_9$ are scalable three-dimensional functions, and $F_{11}$ - $F_{20}$ are complex composition functions with dimensionality ranging from two to twenty.\nWe executed each problem by setting a maximum number of function evaluations (MaxFEs) based on the procedure established in the literature [38], which we report in the rightmost column of Table 1. MaxFEs sets the total number of runs (NR) for each problem, given the population size. Based on this, we evaluated the algorithm's performance with the following two metrics:"}, {"title": "4.2 Compared Algorithms and Parameter Configurations", "content": "We compared MGP-BBBC with its base version k-BBBC [22] and twelve other MMOEAS from the state-of-the-art: SSGA [27], SDE-GA2, RSCMSA [28], RLSIS\u00b3, HillVallEA [29], FastNichingEP4, EMSO-MMO5, CMSA-ES-DIPS6, ANBNWI-DE7, DIDE [26], MOM-MOP [40], and EMO-MMO [41] \u2013 most of these algorithms participated to competitions in either CEC or GECCO throughout 2017 and 2020 (the latest at the time of this work). The settings of MGP-BBBC were set accordingly to Sec. 4.4 and reported on Table 2, whereas the results of the state-of-the-art algorithms were collected from the CEC repository or according to their corresponding references.\nWe ran fifty independent runs (NR= 50) and averaged the results for a fair comparison. We used the Wilcoxon rank-sum test [42] to statistically evaluate the results, with significance level a = 0.05. In the tables reporting the results, we added a + sign to identify when MGP-BBBC is significantly better, a sign when it is significantly worse, and a \u2248 sign when results are not significantly different."}, {"title": "4.3 Comparison With State-of-the-Art Algorithms", "content": "Table 3 reports the experimental results of PR and SR on the CEC'2013 benchmark set with accuracy level \u03b5 = 1.0E-04. The values are the best retrieved by MGP-BBBC and the other state-of-the-art algorithms \u2013 best PR and SR for each function are bolded. MGP-BBBC performed the best on twelve out of twenty functions, non-significantly different than the algorithms retrieving the best for two functions, and competitively on the other six functions. MGP-BBBC features a performance of both PF and SR = 1.000 in the functions $F_1$ - $F_6$, $F_8$, $F_{10}$ - $F_{13}$ \u2013 no other algorithm performs a perfect PR and SR past this point. The performance on F7 (Vincent 2D), which features a sine function with a decreasing frequency, is also high: MGP-BBBC features the highest PR (0.998) and SR (0.920) among nine over thirteen algorithms, except for SDE-GA, HillVallEA, MOMMOP, and EMO-MMO (SR=1.000). In its"}, {"title": "4.4 Parameter Analysis", "content": "MGP-BBBC features two user-defined parameters: the population size n (same value for both offspring and archive) and the clustering kernel bandwidth h (see Sec. 3.2). While the first one is a common parameter of EAs, the second is specific to the clustering algorithm and depends on the optimization problem (i.e., bounds, landscape, number of optima).\nIn terms of space geometry, the kernel bandwidth defines the radius of a sphere (in a multidimensional space) within which points are considered neighbors. The choice of kernel bandwidth significantly impacts the clustering result. Smaller bandwidths lead to tighter, more compact clusters and can result in more clusters, as points need to be closer to each other to be considered part of the same cluster. This makes clustering more sensitive to noise and outliers, as small changes in position can lead to different cluster assignments. On the other hand, larger bandwidths lead to more diffuse clusters, with the risk of merging two nearby clusters into a single cluster. However, this makes the clustering more robust to noise"}, {"title": "5 Conclusion", "content": "In this work, we propose the MGP-BBBC algorithm for MMOPs. MGP-BBBC is the multimodal extension of the BBBC algorithm [30, 32], and an improved version of k-BBBC [22] based on clustering. MGP-BBBC stores the elites in an archive and applies a survival stage to the archive and the newly generated offspring: both populations are filtered separately to remove elite individuals too close to each other, ensuring that elites around sharp peaks are not lost in favor of elites around wide peaks. Then, MGP-BBBC produces a new archive of elites, on which the big-crunch operator is applied to retrieve centers of mass through clustering: this operation promotes isolated individuals by assigning them more offspring than individuals having high niche count in their cluster. Lastly, the centers of mass go through the big-bang operator, which produces new offspring by dynamically balancing exploration and exploitation during different generations. This operation allows MGP-BBBC to correctly converge to the peaks with the desired level of accuracy.\nWe conducted experiments on twenty multimodal test functions from the CEC'2013 benchmark set. The results show that the overall performance of MGP-BBBC is better than ten out of thirteen state-of-the-art multimodal optimization algorithms and performs competitively against the other three. In the future, we will extend MGP-BBBC by testing other clustering methods (e.g., with Gaussian kernel), and we will investigate whether it is possible to formalize a relationship between the clustering bandwidth and the search space to remove the burden of selecting this parameter ad-hoc. Additionally, we will test MGP-BBBC on constrained MMOPs and use it in real-world applications, such as finding multiple configurations for soft growing robots to solve a specific task with alternative optimal designs [43]."}]}