{"title": "Uncertainty Decomposition and Error Margin Detection of Homodyned-K Distribution in Quantitative Ultrasound", "authors": ["Dorsa Ameri", "Ali K. Z. Tehrani", "Ivan M. Rosado-Mendez", "Hassan Rivaz"], "abstract": "Homodyned K-distribution (HK-distribution) parameter estimation in quantitative ultrasound (QUS) has been recently addressed using Bayesian Neural Networks (BNNs). BNNs have been shown to significantly reduce computational time in speckle statistics-based QUS without compromising accuracy and precision. Additionally, they provide estimates of feature uncertainty, which can guide the clinician's trust in the reported feature value. The total predictive uncertainty in Bayesian modeling can be decomposed into epistemic (uncertainty over the model parameters) and aleatoric (uncertainty inherent in the data) components. By decomposing the predictive uncertainty, we can gain insights into the factors contributing to the total uncertainty. In this study, we propose a method to compute epistemic and aleatoric uncertainties for HK-distribution parameters (\u03b1 and k) estimated by a BNN, in both simulation and experimental data. In addition, we investigate the relationship between the prediction error and both uncertainties, shedding light on the interplay between these uncertainties and HK parameters errors.", "sections": [{"title": "I. INTRODUCTION", "content": "Scatterers are microstructures within the tissue that are smaller than the ultrasound wavelength and scatter the ultrasound waves. Quantitative ultrasound (QUS) analyzes the detected backscattered signal to provide insights into the scatterers' structures, which are closely linked to the tissue characteristics. QUS methods have been widely utilized for tissue characterization, including liver fibrosis staging [1]-[3], breast inclusions classification [4]-[7], and metastatic lymph nodes detection [8].\nQUS methods can be decomposed into two broad categories: spectral-based and envelope-based methods [9]. Spectral-based methods analyze the backscattered signal in the frequency domain to obtain parameters such as backscattering coefficient, attenuation coefficient, and effective scatterer diameter [10], [11]. Envelope-based methods utilize the envelope of the backscattered signal to estimate QUS parameters, such as scatterer number density, and coherency of scatterers [10], [12], [13]. These methods model the envelope of the backscattered RF data by fitting a distribution to the samples [10].\nThe Homodyned-K distribution can model the envelop data, and its parameters have been found to be correlated with the tissue properties, making them useful in tissue characterization [2], [14]. Envelope statistics, including point-wise signal-to-noise ratio (SNR), skewness, kurtosis, and log-based moments, are commonly used to estimate HK parameters. Estimating HK parameters from known envelope statistics does not have a closed-form solution, and conventional methods of estimating these parameters rely on iterative optimization methods or table search [15]\u2013[17].\nDeep learning methods have recently been employed in QUS [18], [19]. They have also been utilized to estimate the parameters of the HK distribution by employing envelope statistics as input features of the model. Zhou et al. introduced an Artificial Neural Network (ANN) as an estimator of HK parameters [20]. The ANN estimator employed Multilayer Perceptrons (MLPs), which were prone to overfitting. Moreover, ANNs perform as a black box without having a reliability metric, which is crucial to ensure that the model's predictions are trustworthy and can be confidently applied in clinical or research settings. Tehrani et al. addressed these issues by utilizing a Bayesian Neural Network (BNN) which incorporates probability distributions instead of fixed weights, enabling the estimation of the uncertainty of predictions. Their method improved the estimation of HK-distribution parameters and provided uncertainty quantification which enables the assessment of the reliability of the model's outputs [21], [22].\nThe total predictive uncertainty in Bayesian modeling can be decomposed into epistemic and aleatoric components [23]. Epistemic uncertainty refers to the uncertainty over the network weights. This uncertainty is often referred to as model uncertainty. High epistemic uncertainty indicates that the test input may be an outlier or different compared to the training distribution. As a result, by training the model with more diverse training data, we can reduce this type of uncertainty. Aleatoric uncertainty, on the other hand, captures the noise inherent in the input observations. Addressing this type of uncertainty requires knowledge about unobserved variables, such as additional features in the input, which are often inaccessible. Therefore, it is not always possible to reduce aleatoric uncertainty [23], [24]. By understanding the contributions of the two uncertainty components, we can identify whether increasing the size of the training data or improving the data collection process would be beneficial to reduce the total uncertainty.\nIn this study, we propose a framework to obtain the total predictive uncertainty of HK-distribution parameters and decompose it into epistemic and aleatoric ones using BNN for simulation and experimental data. We also investigate the relationship between the prediction error and both uncertainties."}, {"title": "II. MATERIALS AND METHODS", "content": "A. Homodyned K-distribution\nThe Homodyned K-distribution (HK-distribution) is described by the following equation [15]:\n$P_{HK}(A | \\epsilon^2, \\sigma^2, \\alpha) = \\int_0^{\\infty} u J_0(u\\epsilon) J_0(uA) (1 + \\frac{u^2 \\sigma^2}{2 \\alpha})^{-\\alpha} du$ (1)\nwhere $A$ represents the envelope of the backscattered echo signal and $J_0(\\cdot)$ is the zero-order Bessel function. The coherent signal power is denoted by $\\epsilon^2$, and the diffuse signal power is given by $2\\sigma^2\\alpha$ [15]. The scatterer clustering parameter $\\alpha$, and coherent to diffuse scattering ratio $k = \\frac{\\epsilon^2}{\\sigma^2 \\alpha}$, referred here to as HK parameters, are commonly used in tissue characterization [25], [26]. $\\alpha$ and k are correlated with the scatterer number density and the microstructural organization of the scatterers, respectively.\nB. Datasets and data generation\na) Simulation Data: Equation (2) suggested by [27], [20] was employed to produce synthetic samples from HK-distribution:\n$a_i = \\sqrt{(\\sqrt{2k} + X_i \\sigma \\sqrt{Z_i/\\alpha})^2 + (Y_i \\sigma \\sqrt{2Z_i/\\alpha})^2}$ (2)\nwhere $a_i$ is the generated sample, and $X_i$ and $Y_i$ are the independent and identically distributed samples (i.i.d) from the Normal distribution having zero mean and variance of 1. $Z_i$ is the sample from the Gamma distribution with shape parameter $\\alpha$ and scale parameter \u03b4 which is set to 1.\nWe first trained the BNN following the schedule suggested by [21]. The simulation test data were generated for 31 randomly selected $\\log_{10}(\\alpha)$ values ranging from -0.3 to 1.3 corresponding to $\\alpha$ from 0.5 to 20, and 11 values of $k$ ranging from 0 to 1.25 similar to [21] using (2). Moreover, for each value of $\\log_{10}(\\alpha)$ and $k$, 10 realizations were generated, leading to 3410 sample sets. Different input observations were used for uncertainty decomposition, which will be elaborated on in Subsection C. In addition, Rayleigh noise was incorporated into the samples at different levels, resulting in data with three different SNRs of 20, 30, and 40 dB, which are computed by $SNR = 10 \\log_{10} (E[env^2]/(2 \\sigma_n^2))$ where $E[env^2]$ denotes the power of the envelope samples and $\\sigma_n$ is the scale parameter of Rayleigh noise.\nb) Experimental Data: We used data from four experimental phantoms. The first dataset was sourced from a phantom previously described in [28], which is a three-layered phantom with two different scatterer number densities. The phantom was constructed using an emulsion of ultrafiltered milk and water-based gelatin. Glass beads with diameters ranging from 5 to 43 \u00b5m (3000E, Potters Industries, Valley Forge, PA, USA) were used as scattering sources. Images of the phantom were acquired using an 18L6 linear array transducer with a center frequency of 8.9 MHz on a Siemens Acuson S2000 scanner (Siemens Medical Solutions USA, Inc.), previously reported in [28]. The top and bottom layers of the phantom have the same scatterer concentration of 2 g/L, and the middle layer has a higher concentration of 8 g/L. Patches R1 and R2 were selected to extract the statistical features from the top and middle layers, respectively. We obtained 60 patches of envelope data for each of the two specified regions by moving the patches laterally (to avoid any changes in resolution cell size) across several frames.\nThe other three datasets were acquired from homogeneous phantoms with different numbers of scatterers per resolution cell, previously reported in [29]. The dimensions of the phantoms measured 15 cm \u00d7 5 cm \u00d7 15 cm, and they were made from a homogeneous mixture of agarose gel and glass beads as scattering agents. The diameter range of the glass beads and their concentration in the phantoms are detailed in [29]. Data was collected with an 18L6 transducer operating at a 10 MHz frequency using an Acuson S2000 scanner (Siemens Medical Solutions, Malvern, PA, USA). The phantoms are referred to as Phantom A (high concentration), Phantom B (medium concentration), and Phantom C (low concentration) having scatterer concentrations of 236, 9, and 3 per mm\u00b3, respectively. Seventy-two patches were acquired from each phantom.\nC. Uncertainty Decomposition\nTo estimate the two components of the uncertainty in our model's predictions, we used the method proposed in [31]:\n$Var(y) \\approx E(\\widehat{y}^2) - E(\\widehat{y})^2 + E(\\sigma^2)$ (3)\nwhere $E(y)$ denotes the expected value of the prediction and $\\sigma^2$ is the predicted variance. Expected values are obtained by Monte Carlo sampling at inference time. According to (3), to estimate each uncertainty component for the simulation data, different observations of the input data and the model weights were required. The trained BNN was used in inference with 50 times sampling of weights for each of the 10 input observations for simulation data, yielding 50 \u00d7 10 different output estimates. Having the total test data $d_t \\in \\mathbb{R}^{341 \\times 10}$, the dimensions of the total prediction were $k,\\log_{10}(\\alpha) \\in \\mathbb{R}^{341 \\times 10 \\times 50}$, where the last two dimensions correspond to different input realizations and different BNN inferences, respectively. As shown in (3), the total predictive uncertainty is the summation of epistemic and aleatoric uncertainties. The epistemic uncertainty was estimated by computing the standard deviation over the 50 model inferences, followed by averaging these deviations over the predictions of 10 different input realizations. On the other hand, the aleatoric uncertainty was estimated by first averaging the predictions across the 50 model inferences, and then computing the standard deviation over the predictions of 10 input realizations. This captures the variations across different realizations and removes the uncertainty of the model in different inferences."}, {"title": "III. RESULTS", "content": "The Root Mean Square Error (RMSE = $\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (y_i - \\widehat{y_i})^2}$) of the model's predictions is calculated where n represents the number of data points, $y_i$ and $\\widehat{y_i}$ denote the ground truth labels and model's predictions, respectively.  According to the plots in Fig. 2 and the correlation values in Table I, a relatively high correlation between the error and each uncertainty was observed. For data with SNRs of 30 and 40, aleatoric uncertainty shows a stronger correlation with error than epistemic uncertainty for both parameters $\\log_{10}(\\alpha)$ and $k$. On the other hand, for data with an SNR of 20, epistemic uncertainty demonstrates a higher correlation with error compared to aleatoric one, again for both parameters. Based on Fig. 2 (b) and (d), there is an apparent lower bound for the error as a function of the aleatoric uncertainty. Determining the lower bound for the error can be crucially important in tissue characterization since it allows researchers to acquire the minimum prediction error values without knowing the ground truth.\nTable II shows the uncertainties for different values of estimated $\\log_{10}(\\alpha)$ in the experimental phantoms. The analysis of uncertainty values in the plots in Fig. 2 and Table II (for simulation and experimental data, respectively), indicates that aleatoric uncertainty constitutes a larger proportion of the total uncertainty than the epistemic one. Therefore, adding more training data would not significantly reduce the overall predictive uncertainty here. If data acquisition is feasible, strategies such as using larger patches and angular compounding may help reduce aleatoric uncertainty, resulting in total uncertainty reduction."}, {"title": "IV. DISCUSSION AND CONCLUSION", "content": "Previous studies that quantified the uncertainty of HK parameter estimations [24, 25] mainly focused on epistemic uncertainty, as they only accounted for uncertainty over the model parameters. Moreover, Tehrani et al. in [19] estimated an uncertainty that is similar to aleatoric uncertainty. In this study, we acquired both uncertainties and investigated their correlation with error.\nCalculating aleatoric uncertainty is challenging, as it requires multiple observations of the input data, which may not always be available. In contrast, epistemic uncertainty is easier to obtain through multiple inferences of the model in Bayesian frameworks. Our results in Section III show that the correlation between error and epistemic uncertainty is comparable to that between error and aleatoric uncertainty. This is valuable since epistemic uncertainty is always accessible, whereas aleatoric uncertainty may not be, especially in in vivo data where obtaining multiple observations from the same tissue is difficult.\nIn this study, we introduced a framework to quantify and decompose the predictive uncertainty into epistemic and aleatoric components for Homodyned K-distribution (HK-distribution) parameters using Bayesian Neural Networks (BNNs). Our results showed that the main contributor to the total uncertainty of the BNN model's predictions is the aleatoric uncertainty. Moreover, investigating the relationship between prediction errors and each uncertainty component leads to identifying a lower bound for the error values."}]}