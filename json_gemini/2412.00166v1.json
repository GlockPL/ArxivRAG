{"title": "To Ensemble or Not: Assessing Majority Voting Strategies for Phishing Detection with Large Language Models*", "authors": ["Fouad Trad", "Ali Chehab"], "abstract": "The effectiveness of Large Language Models (LLMs) significantly relies on the quality of the prompts they receive. However, even when processing identical prompts, LLMs can yield varying outcomes due to differences in their training processes. To leverage the collective intelligence of multiple LLMs and enhance their performance, this study investigates three majority voting strategies for text classification, focusing on phishing URL detection. The strategies are: 1) a prompt-based ensemble, which utilizes majority voting across the responses generated by a single LLM to various prompts 2) a model-based ensemble, which entails aggregating responses from multiple LLMs to a single prompt; and 3) a hybrid ensemble, which combines the two methods by sending different prompts to multiple LLMs and then aggregating their responses. Our analysis shows that ensemble strategies are most suited in the cases where individual components-whether prompts or LLMs exhibit equivalent performance levels. However, when there is a significant discrepancy in individual performance, the effectiveness of the ensemble method may not exceed that of the highest-performing single LLM or prompt. In such instances, opting for ensemble techniques is not recommended.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have become instrumental in advancing tasks within natural language processing (NLP), offering unparalleled capabilities in text comprehension and generation [6,31]. However, the performance of LLMs is significantly reliant on the specificity and design of the input prompts [18]. This dependence frequently leads to inconsistent results across different LLMs when processing the same prompt, a consequence of their diverse training methodologies."}, {"title": "2 Background and Preliminaries", "content": "This section provides essential background information on key topics that form the foundation of this study."}, {"title": "2.1 Large Language Models (LLMs)", "content": "LLMs are neural-network-based models that excel at processing human language, benefiting significantly from their extensive scale and depth. The introduction of the transformer architecture by Vaswani et al. [30], with its innovative self-attention mechanisms, has been a cornerstone in the development of LLMs. This architecture has led to significant improvements in various tasks, including translation and sentiment analysis. A major leap in the capabilities of LLMs has been demonstrated through the advancements in transformer-based models, notably exemplified by OpenAI's GPT series [5].\nAmong these, ChatGPT, a variant of GPT-3 optimized for conversational tasks, initiated a crucial evolution toward LLMs designed for a wide array of applications [22]. Following the success and the trends set by ChatGPT, other significant LLMs have emerged, each contributing unique strengths to the field. LLaMA [27], introduced by Meta, PaLM [4] and Gemini [26], by Google, are examples of such models that have adopted and extended the transformer architecture, further pushing the boundaries of what LLMs can achieve. These models, similar to ChatGPT, showcase the trend towards employing these sophisticated neural networks as off-the-shelf solutions for diverse systems and applications, thereby eliminating the need for extensive model training and maintenance from the end users' perspective."}, {"title": "2.2 Phishing URL Detection", "content": "Phishing attacks continue to pose challenging threats to global cybersecurity efforts. Attackers frequently employ deceptive URLs that mimic legitimate websites, utilizing misleading domain names, incorporating trusted brands, and using visually similar characters, or homoglyphs, to dupe users [24]. They further complicate detection by exploiting valid TLS certificates and brand logos, as well as by using URL shortening and redirection techniques [10]. Given the sophistication and constant evolution of these tactics, there is a pressing need for advanced URL analysis methods. This study investigates the use of ensemble LLMs for text classification as a means to enhance phishing URL detection."}, {"title": "2.3 Ensemble Strategies", "content": "Ensemble Strategies have emerged as a powerful approach to improving the performance and reliability of predictive models. By combining the outputs of multiple models, ensemble methods can leverage diverse perspectives and knowledge bases to yield more accurate predictions [7]. Majority Voting is a simple yet effective ensemble technique where the final output is determined by the majority decision of multiple models. This approach assumes that each model in the ensemble has an independent chance of being correct, and by aggregating their decisions, the ensemble can achieve higher accuracy than any single model alone [14]. This study aims to introduce and evaluate three majority voting approaches for LLMs in text classification tasks, with a focus on detecting phishing URLs."}, {"title": "3 Related Work", "content": "The utilization of LLMs has showcased their revolutionary abilities in a variety of NLP tasks [13]. Among these tasks, text classification has emerged as a critical area where LLMs, including foundational models like BERT and GPT, demonstrate substantial potential. These models have been instrumental in advancing our understanding of nuanced language patterns, significantly enhancing analytical capabilities in classifying texts [9,20]. This evolving landscape has further expanded with the introduction of chat-based LLMs which, through innovative prompt engineering and response parsing techniques, are being tailored for more specialized tasks [34]. Building on this momentum, this study focuses on using chat-based LLMs for phishing URL detection, showcasing how these advanced models can be leveraged to address specific and pressing cybersecurity challenges.\nResearch in phishing URL detection has progressed from traditional blacklist methods [25] to more advanced machine learning-based approaches [1]. In machine-learning-based phishing detection, significant emphasis is placed on URL scrutiny. These methods analyze URL features such as length, special character presence, and subdomain usage [23,32,35]. Lexical and token analysis are crucial for deconstructing URL structures to identify phishing attempts. Machine learning algorithms like SVM, decision tree, and Random Forest play a pivotal role in categorizing URLs based on these attributes [16,3]. The integration of deep learning techniques enhanced phishing URL detection by introducing character-level deep neural networks for this purpose [15,12]. Building on these advancements, recent studies have introduced the use of prompt-engineered LLMs, achieving promising results. However, these approaches did not surpass the performance of fine-tuned models [28,29]. Notably, the studies were conducted within the constraints of a single-model, single-prompt framework, indicating that exploring ensemble methods could offer significant improvements in accuracy and reliability.\nEnsemble methods like majority voting, bagging, and boosting improve performance by aggregating multiple models' predictions [7]. Although these methods have seen widespread use with simpler models, their application in NLP and text classification, especially with recent LLM advancements, has been less investigated.\nThe literature indicates a research gap in applying ensemble methods to harness multiple LLMs' collective strengths. While the individual text classification abilities of LLMs are well-established, there is limited research on their effective combination to boost performance. This gap underlines the necessity for dedicated studies on developing and assessing ensemble strategies for improved reliability and accuracy.\nThis study seeks to bridge this gap by introducing and evaluating three majority voting ensemble strategies, specifically designed for text classification tasks within the context of phishing URL detection."}, {"title": "4 Methodology", "content": "This section outlines the three proposed ensemble strategies specifically designed to improve phishing URL detection with LLMs. These strategies, detailed in Figure 1, are as follows:\nPrompt-based Ensemble: This method involves presenting a single LLM with multiple variations of prompts, each requesting the classification of the same URL. The responses are then aggregated through majority voting to determine the final classification. Figure 1a illustrates this approach with an LLM receiving three different prompts.\nModel-based Ensemble: Here, responses from multiple LLMs to the same prompt are combined. Each model independently evaluates the prompt, and their decisions are aggregated via majority voting to arrive at the final prediction. Figure 1b depicts this strategy with three LLMs analyzing a single prompt.\nHybrid Ensemble: A synthesis of the prior strategies, the hybrid method sends various prompts to multiple LLMs and compiles their responses using majority voting. This approach aims to exploit simultaneously the benefits of model diversity and prompt variation. Figure 1c demonstrates this process for three LLMs, each receiving three distinct prompts."}, {"title": "5 Experiments", "content": "This section outlines the experimental setup and reports the results of the experiment."}, {"title": "5.1 Experimental Setup", "content": "Dataset: The primary dataset for this project is derived from the PhishStorm dataset [17], comprising 96,018 URLs, equally divided into 48,009 legitimate and 48,009 phishing URLs. To facilitate a focused and manageable evaluation of the proposed ensemble strategies across different LLMs and prompts, we selected a subset of 1,000 samples from the PhishStorm dataset for testing. This subset maintains the dataset's balanced structure, with an equal distribution of 500 phishing and 500 legitimate URLs.\nLLMS: To assess the effectiveness of ensemble strategies in phishing URL detection, we selected a diverse array of advanced, chat-based LLMs capable of being queried with prompts. This assortment includes a range of models showcasing the current breadth of capabilities in language understanding and processing. The models utilized in this study are: GPT-3.5-Turbo [33], GPT-4 [2], Gemini 1.0 Pro [26], LLAMA 2 (70B) [27], and PaLM 2 [4].\nPrompts: To assess the performance of the selected LLMs in phishing URL detection, specific prompts were crafted to guide the models to classify URLs as either phishing or legitimate. The dataset was divided into batches of 50 samples for testing, with each LLM tasked with classifying all URLs in a batch based on a single prompt. The prompts utilized are as follows:"}, {"title": "5.2 Individual LLMs Performance", "content": "As a start, we evaluate each LLM's performance using zero-shot, one-shot, and two-shot prompts. The individual performance of LLMs is necessary to establish baseline capabilities that ensemble strategies are expected to bypass. The heatmap depicted in Figure 3 visually conveys the accuracy and F1-score for each model-prompt pairing.\nGPT-4 outperforms other models, achieving the highest accuracy of 0.946 with the one-shot prompt and an F1-score of 0.943. In contrast, LLAMA 2 is at the lower performance spectrum, attaining its highest accuracy of 0.830 and an F1-score of 0.797 when given the two-shot prompt. The performance of Gemini-1.0-Pro, PaLM 2, and GPT-3.5-Turbo occupies the middle ground.\nGemini demonstrates negligible variation in performance across prompts, suggesting robustness to prompt complexity with consistent accuracy and F1-scores. PaLM 2 shows similar consistency for both metrics. Conversely, GPT-3.5-Turbo presents a variable performance, with a notable accuracy improvement from 0.854 for zero-shot to 0.879 for one-shot, and a subsequent decline to 0.856 in the two-shot prompt. F1-scores also reflect this pattern, peaking at 0.862 for one-shot before dropping to 0.833 for two-shot prompts.\nUnderstanding the individual model performances is crucial for determining the effectiveness of ensemble strategies, particularly when they can surpass the individual performances of the models involved."}, {"title": "5.3 Prompt-based Ensemble", "content": "Applying the prompt-based ensemble technique outlined in the Methodology section, we report on the performance of each LLM when the results from individual prompts are combined, comparing these to the highest performance"}, {"title": "5.4 Model-based Ensemble", "content": "The model-based ensemble approach was implemented to assess the impact of aggregating the predictive outputs of various LLMs. In this method, a single prompt is provided to all models, and their individual predictions are consolidated through majority voting for the final URL classification.\nThe outcomes of this experiment, depicted in Figure 5, illustrate the model-based ensemble's efficacy with the highest performance achieved by individual models for a given prompt type. Notably, the model-based ensemble failed to surpass the performance of the highest-performing model (GPT-4). This is attributed to GPT-4's significantly superior performance within the ensemble of five LLMs, resulting in a tendency for the ensemble's overall performance to lean towards the lower-performing models.\nIn an effort to further investigate, a follow-up experiment was conducted, excluding both the highest (GPT-4) and lowest (LLaMA) performing models,"}, {"title": "5.5 Hybrid Ensemble", "content": "The hybrid ensemble methodology merges the principles of both prompt-based and model-based ensembling, utilizing various prompts across different LLMs. The predictive outcomes are then aggregated through majority voting. Including all five models in the ensemble revealed no improvement over the best individual model, consistently GPT-4, as demonstrated in Figure 7. This lack of enhancement"}, {"title": "6 Discussion", "content": "The decision to employ ensembling strategies with LLMs must be informed by a clear understanding of when such approaches are likely to enhance performance. Our experiments have shed light on the scenarios in which ensembling is advantageous. Importantly, ensembling is most effective when the participating models perform at similar levels.\nWhen models exhibit widely varying levels of performance, as seen with the inclusion of GPT-4 with other LLMs, the ensemble's outcome may be disproportionately affected by the higher-performing model, leading to no real benefit from the combination. In contrast, when models with comparable performance are ensembled, as demonstrated by the refined approach excluding GPT-4 and LLaMA, a notable improvement is witnessed. This suggests that the benefits of ensembling are more pronounced when the collective decision-making process is not dominated by a single model's output.\nConsidering the limited pool of LLMs available for ensembling and the notable variability in their performance, careful consideration is essential in applying ensembling strategies. We recommend using a portion of the data to assess the performance of both individual models and their ensembles before deploying ensemble LLMs in a production environment. This preliminary evaluation will help determine the most effective ensemble configuration and ensure that the integration of multiple LLMs augments the system's overall performance, rather than inadvertently diminishing it."}, {"title": "7 Conclusion", "content": "In conclusion, this study explored the viability of using ensemble methods with LLMs for the task of phishing URL detection. The findings have emphasized that while ensembles can be powerful, their success is contingent on the performance parity of the individual models. We demonstrated through experiments that ensembling yields improvements when models have relatively similar performance but may not be advantageous when a single model's performance is significantly better or lower than others. This research contributes to the broader understanding of how to strategically combine LLMs to leverage their collective intelligence effectively.\nThere are several promising avenues for future research. One immediate area is the exploration of dynamic ensembling techniques that can adaptively select models based on the nature of the task or the specific input data. This could potentially overcome the limitations of fixed ensembles when faced with diverse types of data or tasks.\nFurther investigations could also focus on developing more sophisticated voting mechanisms beyond the simple majority rule, potentially incorporating weighted voting systems that consider the confidence levels or past performance of individual models.\nFinally, there is a need for larger-scale studies that incorporate a greater variety of LLMs, including those trained on specialized datasets, to examine"}]}