{"title": "Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems with Style and Shopping Cart Information", "authors": ["Berke Ugurlu", "Ming-Yi Hong", "Che Lin"], "abstract": "Understanding users' product preferences is essential to the efficacy of a recommendation system. Precision marketing leverages users' historical data to discern these preferences and recommends products that align with them. However, recent browsing and purchase records might better reflect current purchasing inclinations. Transformer-based recommendation systems have made strides in sequential recommendation tasks, but they often fall short in utilizing product image style information and shopping cart data effectively. In light of this, we propose Style4Rec, a transformer-based e-commerce recommendation system that harnesses style and shopping cart information to enhance existing transformer-based sequential product recommendation systems. Style4Rec represents a significant step forward in personalized e-commerce recommendations, outperforming benchmarks across various evaluation metrics. Style4Rec resulted in notable improvements: HR@5 increased from 0.681 to 0.735, NDCG@5 increased from 0.594 to 0.674, and MRR@5 increased from 0.559 to 0.654. We tested our model using an e-commerce dataset from our partnering company and found that it exceeded established transformer-based sequential recommendation benchmarks across various evaluation metrics. Thus, Style4Rec presents a significant step forward in personalized e-commerce recommendation systems.", "sections": [{"title": "Introduction", "content": "Sequential product recommendation is a process that involves capturing information from user sessions to predict the next item they are likely to purchase. By analyzing the history of user interactions, the system aims to make accurate predictions. However, due to the intricate relationships between products, effectively capturing information from users' past interactions poses a significant challenge.\nDifferent approaches have been explored in the realm of sequential product recommendation to capture the dependencies between products. One simple model is Markov Chains (MCs) (Rendle, Freudenthaler, and Schmidt-Thieme 2010), which predict the subsequent product based on the previous product or a few preceding products. However, MCs do not effectively utilize long-range dependencies and focus primarily on the last few products, attempting to capture short-range product dependencies. On the other hand, Recurrent Neural Networks (RNNs) (Hidasi et al. 2016) have been employed to capture both long and short-term dependencies between products. By utilizing a hidden state, RNNs are able to predict the subsequent product. GRU4Rec (Hidasi et al. 2016), and its improved versions have demonstrated success in the task of next-item prediction. GRU4Rec takes both the hidden state and current product vector as input, leveraging their combination for accurate predictions.\nA different approach is adopted in CNN-based sequential product recommendation models (Tang and Wang 2018). Here, the embeddings of previous products are treated as an image, and convolutional operations are applied to extract relevant information for predicting the subsequent product. This approach utilizes the structural properties of CNNs to capture dependencies between products and make effective predictions.\nTransformer-based sequential product recommendation models have emerged as promising alternatives (Sun et al. 2019; Kang and McAuley 2018; Wu et al. 2020) in predicting subsequent items in user sessions, showcasing state-of-the-art performance. Unlike previous algorithms, transformer-based models leverage self-attention mechanisms, which are highly efficient in training and excel at extracting patterns within user sessions. The self-attention mechanism allows the model to weigh the importance of different elements in the input sequence, capturing dependencies and relationships effectively. As a result, transformer-based models have proven to be powerful tools for sequential product recommendations, outperforming traditional approaches in terms of accuracy and efficiency.\nExisting transformer-based sequential models (Zhang et al. 2018; Lin, Pan, and Ming 2020; Sun et al. 2019; Kang and McAuley 2018; Wu et al. 2020) utilizes only the purchase information for predicting the next item in user sessions. Product images undoubtedly play a major role in users' preferences. However, existing transformer-based sequential product recommendation models don't have a methodology to incorporate the style information of the product images. Utilizing style information can greatly improve the performance in sequential recommendation tasks and allow us to evaluate user preferences more thoroughly.\nIn our research, we have developed a multi-layer transformer-based sequential product recommendation system that leverages style information and shopping cart data to enhance existing state-of-the-art recommendation systems. By grouping users based on their individual sessions,"}, {"title": "Related Work", "content": "AttRec (Zhang et al. 2018), SASRec (Kang and McAuley 2018), SSE-PT (Wu et al. 2020), FISSA (Lin, Pan, and Ming 2020), and BERT4Rec (Sun et al. 2019) are among the notable transformer-based models used for sequential product recommendation tasks. These models employ multi-layer transformer blocks to capture item-item relations within user sessions.\nAttRec (Zhang et al. 2018) leverages the self-attention mechanism to capture both long-term and short-term interactions between items in user sessions. It considers the temporal dynamics of the interactions separately. SASRec (Kang and McAuley 2018) utilizes multiple transformer blocks that facilitate left-to-right item-item interactions. It truncates user sessions and performs separate predictions for each truncated session, allowing the model to capture sequential patterns effectively. SSE-PT (Wu et al. 2020) extends SASRec by incorporating personalized user embeddings and employs the stochastic shared embedding (SSE) regularization technique to mitigate overfitting. FISSA (Lin, Pan, and Ming 2020) introduces a global representation learning module, a local representation learning module, and"}, {"title": "Problem Statement", "content": "Each user session can be considered as sequential data and sequential product recommendation systems try to predict the next item that the user might buy for user sessions. In sequential product recommendation systems, given a set of users and set of items, $U = {u_1, u_2, u_3, ....., u_{|U|}}$ and $I = {i_1, i_2, i_3, ..., i_{|I|}}$ , we can construct user sessions as $S_u = [i_1, i_2, ..., i_t, ..., i_{n_u}]$, $u \\in U$ in chronological order. The length of the session is $n_u$, and $i_t$ is the product that the user interacted with at time t. The purpose of the sequential product recommendation is to predict which item the user will interact with at time t+1, given the user's history $S_u$.\nFor the final prediction, the products on the product list I are sorted with respect to their relevance scores."}, {"title": "Methodology", "content": "Our multi-layer transformer-based sequential recommendation network consists of two parts, the first part utilizes the deep transformer encoder, and the second part utilizes the modified version of the neural style transfer algorithm (Gatys, Ecker, and Bethge 2015). The second part was used for extracting the style information from the product images, and the style information was used for further performance increases."}, {"title": "Deep Transformer Encoder", "content": "The deep-transformer-encoder network consists of multiple transformer-encoder blocks on top of each other. The hidden representation of the input was calculated for each transformer-encoder block and fed into the next transformer-encoder block. We utilized the multi-head self-attention mechanism and point-wise feed-forward network for constructing the transformer-encoder blocks, (Vaswani et al. 2017; Sun et al. 2019):\n$multiHead(H') = [head_1; head_2, ...., head_h]W^O$ (1)\n$head_i = Att(HW_i^Q, HW_i^K, HW_i^V)$ (2)\n$Att(Q, K, V) = Softmax(\\frac{QK^T}{\\sqrt{d/h}})QKV$ (3)\nThe formulas (1), (2), and (3) show the details of the multi-head attention mechanism. $H^l$ represents the stacked hidden representation for a given product sequence. $H^l$ is projected into different subspaces by using the key, query, and value matrices, which are $W_i^Q, W_i^K, W_i^V$. The subscript i represents the multi-head index. The heads are concatenated and projected by utilizing $W^O$ matrix. $W_i^Q, W_i^K, W_i^V, W^O$ are learnable projection matrices, (Vaswani et al. 2017; Kang and McAuley 2018; Sun et al. 2019; Li et al. 2018). We used scaled-dot product attention, (Vaswani et al. 2017; Hinton, Vinyals, and Dean 2015). The query Q, the key K, and the value V are projected from stacked hidden representation, $H^l$. Then, we applied a point-wise feed-forward network to the result of the multi-head self-attention in order to utilize non-linearity and the interactions between different dimensions. We also utilized residual connection, layer normalization, and dropout to avoid overfitting the data (Ba, Kiros, and Hinton 2016; He et al. 2016; Srivastava et al. 2014).\nAs you can see in Figure 3, to calculate the binary cross-entropy loss, we first extracted the product vector of historical behavior for each session. We then compared this vector with both the learnable product embedding of the ground truth product and that of the negatively sampled product. Cosine similarity was utilized to compute the relevance score of these vectors, which was then converted into probabilities using the softmax function. These probabilities were subsequently used to calculate the binary cross-entropy loss."}, {"title": "Embedding Extraction Module", "content": "The embedding extraction module in Figure 3 consists of 2 parts, which are:\n1. Sinusoidal Positional Embeddings\n2. Learnable Product Embeddings\nWe employed a combination of sinusoidal positional embeddings and learnable product embeddings. Our goal was twofold: firstly, to encode information about the relative positions of products within sessions, and secondly, to generate unique learnable embeddings for each product, enabling their differentiation and comparison.\nSinusoidal positional embeddings were utilized to encode the products' relative positions within sessions, while learnable product embeddings facilitated product comparison, thus informing product recommendations. This approach integrated both positional information and product-specific embeddings simultaneously.\n$PE_{(pos,2i)} = sin(pos/10000^{2i/d_{model}})$ (4)\n$PE_{(pos,2i+1)} = cos(pos/10000^{2i/d_{model}})$ (5)\nThe formulas for sinusoidal positional embeddings can be seen in (4) and (5). $d_{model}$ represents the total dimension of the input features, (Vaswani et al. 2017; Kang and McAuley 2018; Sun et al. 2019). For the learnable positional embeddings, which is a linear layer without the bias term, the embedding parameters are initialized from N(0, 1). We compared the learnable product embeddings with the product vector of historical behavior in Figure 3, for making the final prediction.\nThe use of learnable product embeddings was pivotal in constructing a scalable model, allowing us to compare these embeddings directly with our model's output. This implies that even if a new, unknown product is added to a session, we can still compare our model's output with the existing learnable product vectors to generate a final product recommendation. Consequently, our model exhibits the flexibility to accommodate new and unknown products, enhancing its adaptability and utility in dynamic environments.\nAll of the input embeddings were concatenated, the dimension of learnable product embeddings is 128, and the $d_{model}$ variable in sinusoidal positional embedding is 128."}, {"title": "Style Embeddings", "content": "For extracting the style information, we utilized the neural style transfer algorithm (Gatys, Ecker, and Bethge 2015). In the neural style transfer algorithm, the feature maps of a generic object detection algorithm are used for capturing the style information. The filter response of each layer of a convolutional neural network is used to obtain the gram matrices, which are used for calculating the style loss (Gatys, Ecker, and Bethge 2015). There are two approaches to how we can transfer style information by using the neural style transfer algorithm.\nTwo images are used in the first method of the neural style algorithm, as you can see in Figure 1. These images are the content image and the style image. The main idea is to update the content image by using the style image so that the style of the content image becomes similar to the style of the style image. During the training of the neural style transfer algorithm, style and content images are used for calculating the style-loss and the content-loss, respectively, (Gatys, Ecker, and Bethge 2015). The gram matrices for both the content and style images are calculated. The neural style transfer algorithm tries to make both gram matrices similar to each other to transfer the style information between the style image and the content image.\nIn the second method of the neural style transfer algorithm (Gatys, Ecker, and Bethge 2015), the style image and the image consisting of Gaussian noise are used, as you can see in Figure 2. The main idea is to update the noisy input image so that the content and style of the noisy input image become similar to the style image. The gram matrices for the style and noisy input images are calculated to transfer the style information. The feature maps of the noisy input image and the style image are directly subtracted from each other to transfer the content information. In the experiment shown in Figure 2, we transferred only the style information by setting the content loss as zero to visualize style transfer more clearly.\nFor the style loss, the gram matrices are calculated. Note that both methods utilize the gram matrices since it captures crucial style information.\n$styleLoss^k = \\frac{1}{4N_k^2M_k} \\sum_i(G_{i j}^{input} - G_{i j}^{style})^2$ (6)\n$L_{style}(input, style) = \\sum_{k=0}^K w_k style Loss^k$ (7)"}, {"title": "Shopping Cart Data", "content": "In our dataset, we classify sessions into two types: purchase sessions and shopping cart sessions. Shopping cart sessions, which feature products added to the shopping cart but not ultimately purchased, provide a unique opportunity to enhance the performance of sequential product recommendations. Recognizing the user interest that these items represent, we have devised a strategy to differentiate between these two types of sessions. While both purchase sessions and shopping cart sessions are utilized in the training and validation stages, only purchase sessions are included in the testing phase. This approach allows us to more accurately reflect real-world performance, as the primary objective of sequential product recommendation is to predict items users are likely to purchase. Thus, we achieve a realistic gauge of its effectiveness by evaluating the model solely with purchase sessions."}, {"title": "Experiments", "content": "Our partnering company provided the dataset we used. The data comes from an e-commerce website. The website consists of household goods. The dataset contains pageview, purchase, and shopping cart data of users. We discarded the sessions that consist of only pageviews. In the dataset, there are 490817 interactions (including pageviews, purchase, and shopping cart information) on 38117 user sessions, which can be seen in Table 1. Both purchase and shopping cart sessions contain the same set of products. Shopping cart sessions are longer than purchase sessions in general, the average session length of purchase sessions is 11.24, and the average session of shopping cart sessions is 14.57.\nWe separated purchase and shopping cart sessions. We removed the overlapped sessions, which contain both purchase and shopping cart products, to see the effect of adding shopping cart data more clearly. We set the max length of the sessions to 20, and we added padding (0) if the sessions were shorter than 20 products. If the sessions were longer than 20 products, we used the last 20 products. We removed the repeated final products as seen in Figure 4. We made that change because we know that allowing our model to learn the repeated patterns, could decrease the real-life performance significantly. We wanted our model to learn more complex patterns for better generalization in real-life conditions."}, {"title": "Training Procedures", "content": "We split both the purchase data and the shopping cart data with respect to time. We used the first 14 months of data for training, the next 2 months for validation, and the last 2 months for testing. During training, validation, and testing, we predicted the last items in user sessions, by utilizing the previous items. We used shopping cart sessions only in training and validation but not in testing. We used purchase sessions in training, validation, and testing. We tuned the hidden dimension of the transformer encoder within the range of [8, 16, 32, 64, 128, 256] and the L2 regularization penalty within the range of [0.1, 0.001, 0.0001, 0.00001]. We set the number of transformer blocks and the number of heads as 2, for fair comparison with other benchmarks (BERT4Rec, SASRec).\nFor the benchmarks (BERT4Rec, SASRec), we tuned the hyper-parameters according to the descriptions in the respective papers, or we used the recommended parameters. All of the models are reported under their best hyper-parameter settings."}, {"title": "Evalaution Methodology", "content": "For our sequential product recommendation system, we design a multi-layer transformer encoder network to extract both the product vector of historical behavior and the learnable product vector as separate components. To make the final prediction, we compare the product vector of historical behavior with the learnable product vectors. To ensure robust evaluation, we employ negative sampling techniques (Rendle et al. 2009; Chen et al. 2017) to select 100 negatively sampled products for each session. The negative samples are combined with the ground truth product, resulting in a set of 101 products. From this set, we sort and select the most relevant products for each session. To assess the performance of our recommendation system, we calculate several evaluation metrics, including Hit Ratio (HR), Mean Reciprocal Rank (MRR), and Normalized Discounted Cumulative Gain (NDCG) (He et al. 2017; He, Kang, and McAuley 2017). These metrics are calculated for product recommendation list lengths of 5, 10, and 20, providing a comprehensive evaluation of our system's effectiveness in generating accurate and relevant recommendations.\nWe evaluated the performance of our sequential product recommendation network in 4 different training configurations, which are:\n1. Purchase Sessions\n2. Purchase Sessions + Style Embeddings\n3. Purchase Sessions + Shopping Cart Sessions\n4. Purchase Sessions + Shopping Cart Sessions + Style Embeddings"}, {"title": "Results", "content": "We evaluated the efficiency of our model against two state-of-the-art benchmarks - BERT4Rec and SASRec. We included all the available data -purchase sessions, shopping cart sessions, and style embeddings- for comparing STYLE4Rec with the benchmarks. As you can see in Table 2, across all recommendation list lengths, our model outshone both BERT4Rec and SASRec in terms of all metrics. The HR@5 metric improved from 0.681 to 0.735, NDCG@5 rose from 0.594 to 0.674, and MRR@5 ascended from 0.559 to 0.654. SASRec obtained the second-best results in 6 evaluation metrics and BERT4Rec obtained the second-best results in 3 evaluation metrics. Considering these results, we can conclude that utilizing style information with the help of neural style transfer algorithms and utilizing shopping cart sessions in training/validation yields significant improvement in sequential product recommendation task."}, {"title": "Effect of Style Embeddings and Shopping Cart Data", "content": "As shown in Table 3, we tested the model performance on 4 different configurations to evaluate the effect of each method separately. In $Style4Rec^1$ shopping cart sessions and style embeddings were removed. In $Style4Rec^2$ shopping cart sessions were removed. In $Style4Rec^3$ style embeddings were removed. In Style4Rec, we utilized all the available data, purchase sessions, shopping cart sessions, and style embeddings.\nComparing the $Style4Rec^1$ and $Style4Rec^2$ models in Table 3, adding style embeddings to the purchase data improves the model performance on 6 out of 9 metrics, and for MRR@10 the results are the same. We can conclude that extracting style embeddings with the help of the neural style transfer algorithm increases the performance of the sequential product recommendation task. Comparing $Style4Rec^1$ and $Style4Rec^3$ models, adding shopping cart data to purchase data increases the model performance on all of the metrics in all recommendation list lengths. We can conclude that utilizing shopping cart data on training and validation yields meaningful contributions to the sequential product recommendation task. Comparing the $Style4Rec^1$ and Style4Rec models, adding both shopping cart data and the style embeddings at the same time increases the model performance on all of the metrics in all recommendation list lengths. However, in this case, we evaluated the model performance on a wider model. We increased the number of heads to 8 and the dimension of the learnable product embeddings to 1024 to make the model wider and allow more attention heads to make different predictions.\nThe substantial improvements we observed can be attributed to the significant volume of information we incorporated, exceeding all previous instances. Consequently, our model had the capacity to discern more intricate relationships among products, owing to its increased breadth. However, when we endeavored to deepen our model by augmenting the number of transformer blocks, there was no discernible enhancement in the final instance. This can be possibly traced back to the average session length (11.24/14.57) present in our dataset. A deeper model excels at recognizing complex relationships in prolonged sessions. As the average session lengths in our dataset were relatively brief, assessing the model's performance based on a broader model demonstrated superior results, especially in instances when all the data was taken into account."}, {"title": "Dynamic Recommendation", "content": "In this section, our aim was to demonstrate the performance of our model under varying maximum session lengths, for evaluating our model's performance in dynamic recommendation task. The dynamic recommendation allows e-commerce websites to recommend products for their users, immediately after those users enter the website. Waiting for users to finish their sessions and then recommending products, might be an ineffective way for e-commerce websites. In prior experiments, we established a uniform maximum session length of 20 across all models and configurations.\nAs we increased the maximum session length, as in Figure 5, we observed an increase in all metrics. Increasing the maximum session length allowed our model to utilize the relationships of the products which are far away from the end product. In that way, our model learned more distant and complex relationships between products.\nWe also observed that increasing the maximum session length to more than 18 does not significantly improve performance, since the distant products might have less effect on the final decision-making."}, {"title": "Effect of Negative Sampling", "content": "Negative sampling was employed as our primary strategy for assessing model performance. However, in real-world recommendation systems, the necessity arises to rank all available products to formulate the final product recommendations. As you can see in Table 4, we removed the negative sampling process in an attempt to simulate our model's performance under realistic conditions. This modification resulted in a decline across all metrics, with decreases ranging between 0.165 and 0.197. With negative sampling, the prediction scope was confined to 101 products; however, in its absence, the prediction space expanded dramatically to encompass 2991 products. The decrease in prediction space using negative sampling generally leads to improved results, as it reduces the complexity of the task at hand. The disparity between laboratory conditions and actual market complexities underlines the need for continuous innovation and model refinement to ensure these advanced algorithms can reliably deliver optimal recommendations in practice."}, {"title": "Conclusion", "content": "We have introduced a multi-layer transformer encoder network that integrates the neural style transfer algorithm to incorporate style information. Alongside this, we devised a training methodology that emphasizes the distinctions between purchased and shopping cart products. Our comprehensive experiments demonstrated a significant performance enhancement in sequential product recommendation tasks when style embeddings and shopping cart data were incorporated into the transformer recommender network. Furthermore, our model was shown to surpass existing state-of-the-art benchmarks across multiple evaluation metrics. Notably, our model was designed with scalability in mind. By storing learnable product vectors, we have enabled the comparison of a new product's vector with existing ones, allowing for an adaptable and continuously evolving recommender system. However, while we have made significant strides in improving recommendation quality, it is essential to acknowledge that there is always room for further refinement. Our future work will be geared toward assessing the performance of our model in scalable tasks. The challenge lies in maintaining and even improving upon this level of performance as we scale to handle larger datasets and more complex recommendation scenarios. However, we are confident that with further research and continuous development, our model will continue to evolve and excel in the ever-changing landscape of product recommendation systems."}]}