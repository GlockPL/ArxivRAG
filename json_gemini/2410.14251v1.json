{"title": "SYNTHESIZING POST-TRAINING DATA FOR LLMS\nTHROUGH MULTI-AGENT SIMULATION", "authors": ["Shuo Tang", "Xianghe Pang", "Zexi Liu", "Bohan Tang", "Rui Ye", "Xiaowen Dong", "Yanfeng Wang", "Siheng Chen"], "abstract": "Post-training is essential for enabling large language models (LLMs) to follow\nhuman instructions. Inspired by the recent success of using LLMs to simulate\nhuman society, we leverage multi-agent simulation to automatically generate di-\nverse text-based scenarios, capturing a wide range of real-world human needs.\nWe propose MATRIX, a multi-agent simulator that creates realistic and scalable\nscenarios. Leveraging these outputs, we introduce a novel scenario-driven in-\nstruction generator MATRIX-Gen for controllable and highly realistic data syn-\nthesis. Extensive experiments demonstrate that our framework effectively gen-\nerates both general and domain-specific data. Notably, on AlpacaEval 2 and\nArena-Hard benchmarks, Llama-3-8B-Base, post-trained on datasets synthesized\nby MATRIX-Gen with just 20K instruction-response pairs, outperforms Meta's\nLlama-3-8B-Instruct model, which was trained on over 10M pairs; see our project\nat https://github.com/ShuoTang123/MATRIX-Gen.", "sections": [{"title": "1 INTRODUCTION", "content": "Post-training is a crucial process that enables large language models (LLMs) to follow human\ninstructions and enhance specific capabilities like coding and mathematics (Achiam et al., 2023;\nDubey et al., 2024). The effectiveness of post-training heavily relies on instruction data that capture\nthe real-world user requirements. However, obtaining such data in the real world poses signifi-\ncant challenges, including privacy concerns (Yu et al., 2024), data scarcity (Villalobos et al., 2024),\nand human labor costs (Liu et al., 2024). Consequently, developing efficient methods to synthesize\nhigh-quality post-training data is critical for the advancement of LLMs, which motivates this work.\nCurrent data synthesis approaches typically leverage the generative capability of aligned LLMs. For\nexample, Taori et al.; Wang et al.; Xu et al.; Xu et al. employ tailored prompts to guide aligned LLMs\nin producing new instructions based on pre-defined seed instructions. Similarly, Xu et al. use pre-\ndefined blank chat templates to generate synthetic instructions with aligned LLMs. While efficient,\nthese approaches fail to explicitly incorporate real-world user requirements into the data synthesis\nprocess. Furthermore, their dependence on hand-crafted, pre-defined prompts means careful seed\ninstruction selection and prompt engineering are required for producing high-quality data that fit\nspecific user requirements. These limitations not only increase the risk of generating unrealistic\ninstructions misaligned with actual user requirements but also reduce the controllability of these\nmethods in generating specialized data.\nIn this work, we introduce multi-agent simulation as a novel foundation for post-training data syn-\nthesis. Inspired by recent successes in using LLMs to simulate the human society (Park et al., 2023;\nHorton, 2023; Aher et al., 2023), we employ multi-agent simulation to automatically generate di-\nverse scenarios in text, capturing a wide range of real-world human needs. For instance, in a flight\ndelay scenario, where passenger agents interact with a customer service agent, there is a clear need"}, {"title": "2 PROPOSED POST-TRAINING SYSTEM", "content": "Our post-training system aims to enhance the instruction-following capability of pre-trained LLMs\nby leveraging synthetic training data generated by an aligned LLM, which is grounded on simulated\nsocial scenarios. The key idea is inspired by how humans ask questions in real-life scenarios. People\nnaturally generate diverse and deep questions based on their needs and goals. Our approach bypasses\nseed data, using real-life scenarios to guide models in generating more informative and realistic\nquestions, resulting in higher-quality training data. As shown in Figure 1, the framework involves\nthree key steps: synthesizing social scenarios, generating post-training data based on scenarios, and\nmodel fine-tuning. Here the first two steps are empowered by the same aligned LLM and fine-tuning\nis operated on pre-trained LLMs.\nSynthesizing social scenarios. Following our key idea of synthesizing realistic post-training data\ngrounded on real-world scenarios, we propose to automatically synthesize social scenarios via multi-\nagent simulation, where the scenarios are defined as groups of agents and their corresponding textual\nactions. To ensure the realism and diversity of the simulated scenarios, we design MATRIX, a\nlarge-scale multi-agent simulator that creates an interactive environment with various agents. This\nsimulator leverages LLM's role-playing capability, enabling agents with varied profiles to simulate\nhuman behavior, plan, observe, and act, resulting in diverse and highly realistic social scenarios.\nThe workflow of social scenario synthesis includes three steps: i) given real agent data crawled from\nthe web, the LLM is prompted to generate agent profiles and create agent-specific goals based on\nthese profiles; ii) given agent profiles, the communication topology among agents is initialized ac-\ncording to the network homophily among the text embeddings of the corresponding agents' profiles;\nand iii) based on this topology, agents execute their goals by generating actions and interacting with\nother agents within the simulator. The social scenarios are parsed from the interactions among the\nagents, containing diverse close-to-real human behaviors and intentions; see examples of simulated\nscenarios in Table 19.\nThese steps ensure the generated social scenarios are realistic and diverse, with agents' actions re-\nsembling real human behavior and their interactions being informative; see more details in Section 3.\nGenerating post-training data from scenarios. Given the simulated social scenarios, we generate\npost-training data under the specific user requirements. To achieve this, we propose MATRIX-\nGen, a scenario-driven instruction generator that selects relevant scenarios of user requirements\nused for instruction generation. This approach takes real human intentions into account, making\nthe synthesized instructions better reflect human needs and possess greater authenticity and realism.\nBy adjusting the specific requirements of humans in the data synthesis prompt, this approach could\nguarantee that the synthesized data can be aligned with additional synthetic targets, which offers\ngreat controllability in generating synthesized instructions.\nAs shown in Figure 2, this synthetic data generation process includes three steps: i) retrieving the\nmost relevant simulated scenarios based on the given specific human requirements; ii) for each\nselected scenario, MATRIX-Gen simulates the process of human posing questions in their daily lives\nby intergrating each agent's persona and action within the scenario into the instruction-synthesis\nprompt to generate instructions; iii) based on the instruction synthesis prompt in the previous step,"}, {"title": "3 MATRIX: LARGE SCALE MULTI-AGENT SIMULATOR", "content": "This section elaborates on our multi-agent simulator, MATRIX. As shown in Figure 3, it operates by\ntaking a collection of agent profiles as input and generates simulated scenarios, where each scenario\ncomprises the actions of a group of agents in text. MATRIX simulates numerous realistic and diverse\nscenarios with two key elements: real-world-grounded agents and structured communication.\n3.1 REAL-WORLD-GROUNDED AGENTS\nAgents in our simulation possess attributes including name, personality, and life goals, alongside\nmodules for memory and action. These agents exhibit human-like actions through two key designs:\ni) they are initialized using anonymized real human profiles, and ii) they are driven by goal-oriented\nactions, allowing them to pursue meaningful goals while interacting with other agents.\nReal human profiles. To simulate human behaviors effectively, we collect real human profiles and\nprocess them through the LLM to remove or anonymize any private information, ensuring no per-\nsonal identity is leaked. Each profile includes a unique anonymized name, description, and a record\nof past actions, all processed to protect privacy. We initialize 1,000 agents using this information,\nembedding their action history into memory. These agents cover a broad spectrum of real humans,\nrepresenting diverse demographics, professions, and life experiences. This diversity ensures that the\nsimulation captures a wide range of human behaviors and interactions. By leveraging large-scale\nreal profiles, our agents behave more authentically, resulting in highly realistic and varied scenes.\nGoal-oriented actions. Modeled after real-world human behaviors, we design agents' actions to\nbe driven by their specific life goals. For each agent, we prompt the LLM to generate life goals\nand a core personality based on the individual's past actions. The life goals are then broken down\ninto actionable steps, forming the agent's plan. This mirrors how real humans form their identi-\nties-through accumulated experiences and actions over time. For example, a medical professor's\nlife goal might involve spreading scientific knowledge, with a plan that includes conducting re-\nsearch, publishing papers, giving lectures, and organizing educational programs. These steps guide\nthe agent's future actions, ensuring they actively work toward achieving their goal and exhibit pur-\nposeful actions. When new observations arise, agents react to them based on their memory and\npersonality. In the absence of new observations, they follow their plan to pursue their goals; see\nTable 15 for goals and Table 16 for actions, including prompts and examples; This ensures agents\nremain proactive and responsive, leading to coherent and believable behavior that enhances the re-\nalism of the simulation.\n3.2 STRUCTURED COMMUNICATION MECHANISM\nTo synthesize high-quality data, which requires both diversity and realism, simulations must support\ndiverse interactions among a large number of agents to create rich and realistic scenarios. While we\nimplement concurrent agent actions to reflect real-world interactions, a key problem arises: agents"}, {"title": "3.3 SCENARIO GENERATION", "content": "The generation of large-scale realistic scenarios occurs through the following key stages:\nInitialization. Starting with 1,000 real profiles, the LLM first anonymizes or removes any private\ninformation. It then generates goals and plans for each agent. Agents are grouped based on the text\nembeddings of their profiles, clustering similar agents together.\nExecution. At the start of each scenario, agents in a group execute their plans to fulfill their life goals\nand interact with each other. The modulator collects all agents' actions and waits until every agent\nhas acted, thereby completing a scenario. Before the next scenario, agents from different groups\nexchange information via their modulators. These interactions are used in the subsequent scenario,\nallowing inter-group communication to influence intra-group dynamics in the next scenario.\nTermination. The simulation ends when agents either stop generating actions, indicating they've\nfulfilled their life goals, or when the desired number of scenarios has been collected.\nAfter the simulation, generated scenarios are collected from the modulators and used for post-\ntraining data synthesis; see a complete simulation example in Table 15 and Table 19."}, {"title": "3.4 DISCUSSIONS", "content": "Rationality and advantages of MATRIX in facilitating data synthesis. MATRIX's ability to syn-\nthesize diverse and authentic data stems from the diversity and realism of its simulated scenarios,\nwhich are built on two key foundations. First, its real-world-grounded agents are designed to emulate"}, {"title": "4 EXPERIMENTAL RESULTS", "content": "In this section, we evaluate the quality of synthetic data generated by our MATRIX-Gen by using\nthem to fine-tune pre-trained LLMs. We compare the MATRIX dataset family with baselines across\ninstruction tuning, preference tuning, and specific domain tasks.\n4.1 EXPERIMENTAL SETUPS\nBaselines for instruction tuning. For instruction following, we compare MATRIX-Gen-SFT with\nsix baselines, including real and synthetic datasets. Instruction tuning baselines include real datasets\nShareGPT (Chiang et al., 2023a) and WildChat (Zhao et al., 2024), synthetic datasets Evol In-\nstruct (Xu et al., 2024a), UltraChat (Ding et al., 2023), Magpie (Xu et al., 2024b), and mixed datasets\nOpenHermes (Teknium, 2023) and Tulu V2 Mix (Ivison et al., 2023a).\nBaselines for preference tuning. For preference tuning, we compare MATRIX-Gen-DPO with four\nbaselines, including UltraFeedback (Cui et al., 2024), OpenOrca (Mukherjee et al., 2023), Argilla\nDPO (argilla, 2024), and Magpie-PRO-DPO (Xu et al., 2024b).\nBaselines for specific domain tasks. Here we consider three specific domains, including coding,\nsafety and multi-turn dialogue. For coding, we compare the MATRIX-Gen-Coding dataset with\nCode-Assistant (glaiveai, 2024), Code-Feedback (Zheng et al., 2024), and Magicoder (Wei et al.,\n2024). For multi-turn dialogue doamin, we compare MATRIX-Gen-MT with Magpie-MT (Xu et al.,\n2024b) and ShareGPT (Chiang et al., 2023b). For safety domain, we compare the MATRIX-Gen-\nSafety with HH (Bai et al., 2022), Beavertails (Ji et al., 2024b), and Safe-RLHF (Ji et al., 2024a).\nModels. We use Llama-3-8B-Instruct (Dubey et al., 2024) to drive the simulation. For general\ntask, we fine-tune Llama-3-8B with SFT followed by DPO (Rafailov et al., 2024), resulting in the\nMATRIX-Tuned Model. The initial models for coding, safety, and multi-turn tasks are Llama-3-8B-\nInstruct, MATRIX-Tuned Model, and Llama-3-8B, respectively. For all experiments, we use 10k\nsamples and train for 2 epochs; see experiments on Qwen2 (Yang et al., 2024) in Appendix A.2.\nEvaluation. For instruction-following, we use two widely recognized benchmarks: AlpacaEval\n2 (Li et al., 2023b) and Arena-Hard (Li et al., 2024). AlpacaEval 2 comprises 805 real user queries,\nwith model responses compared against GPT-4-Turbo (1106) as the reference while Arena-Hard\nincludes 500 challenging user queries, with model responses compared against GPT-4-0314 as the"}, {"title": "4.2 EVALUATION OF DATA QUALITY IN THE GENERAL DOMAIN", "content": "MATRIX-Gen-SFT outperforms other SFT datasets. Here, we aim to demonstrate the effective-\nness of our solution in synthesizing high-quality for SFT, where we compare the performance of\nLlama-3-8B fine-tuned by the same amount (10k) of our MATRIX-Gen-SFT and data of baselines.\nshows that our model consistently and significantly outperforms baseline models. Specif-\nically, in Arena-Hard, ours outperforms the state-of-the-art synthetic dataset Magpie (Xu et al.,\n2024b) with a 31% relative improvement, and real-world dataset WildChat (Zhao et al., 2024) with\na 163% relative improvement. These indicate the high utility of our synthetic SFT data.\nMATRIX-Gen-DPO outperforms other preference datasets. Here, we aim to demonstrate the\neffectiveness of our solution in synthesizing high-quality for DPO, where we continue DPO train-\ning based on the model tuned using MATRIX-Gen-SFT. The comparison is conducted among our\nMATRIX-Gen-DPO and four existing preference datasets. Table 3 shows that our model consistently\noutperforms baseline models with a significant margin and even performs better than Llama-3-8B-\nInstruct that is officially trained by Meta (Dubey et al., 2024). This suggests that our MATRIX-\nGen-DPO dataset is of high-quality, which even outperforms datasets created by stronger models\nand expertise, for example, UltraFeedback (Cui et al., 2024) uses GPT-4 for rating, Magpie-PRO-\nDPO (Xu et al., 2024b) uses Llama-3-70B-Instruct for generating responses, and Meta makes heavy\ninvestment in collecting data for training Llama-3-8B-Instruct (Dubey et al., 2024)."}, {"title": "4.3 EVALUATION OF DATA QUALITY IN THE SPECIFIC DOMAIN", "content": "Here, we demonstrate the controllability of our MATRIX-Gen generator in generating data for\ndomain-specific tasks, including coding, multi-turn dialog and safety.\nMulti-turn dialog. We highlight the controllability of MATRIX in synthesizing multi-turn dialogue\ndata. We compare the performance of models fine-tuned with MATRIX-Gen-MT dataset against\nboth multi-turn SFT and single turn SFT datasets baselines, all in 10K data samples. Table 5 shows\nthat: i) our MATRIX-Gen-MT dataset consistently outperforms the baselines across three overar-\nching abilities; ii) multi-turn training during SFT is more efficient than single-turn training. These\nindicate that our framework offers high controllability for synthesizing multi-turn dialog SFT data."}, {"title": "5 RELATED WORKS", "content": "Synthesizing alignment data. Aligning LLMs with human expectations requires high-quality data\nthat accurately reflects human needs and intentions (Wang et al., 2023b). Initial efforts sought\nto transform existing NLP benchmarks into instructions (Wang et al., 2022; Mishra et al., 2022)\nor collect user-generated instructions (Chiang et al., 2023a; Zhao et al., 2024; Zhou et al., 2024).\nHowever, Villalobos et al. (2024) have raised concerns that human-generated data may not scale\nadequately. To address this bottleneck, synthetic data generation from LLMs has emerged as a\npromising alternative. Current methods typically involve back-translating from web corpora (Li\net al., 2023a), prompting LLMs to generate new instructions from existing ones (Wang et al., 2023a;\nXu et al., 2024a), or guiding LLMs to complete chat templates (Xu et al., 2024b). While they rely\non predefined materials, limiting flexibility and missing real-world context, our approach generates\ninstructions from simulated social scenarios, offering more flexibility and realism.\nMulti-agent simulation. Multi-agent simulations have been utilized for tasks such as societal re-\nsearch (Xie et al., 2024) and the evaluation of LLMs (Lin et al., 2023). These simulators can\ngenerally be divided into two categories based on agent behavior: those focused purely on social\ninteractions (Gu et al., 2024), like speaking, chatting, or posting on social media, and those that\nsupport more complex agent actions (Wang et al.). While early simulators (Park et al., 2023; Pang\net al.) typically featured only a small number of agents, recent efforts have aimed to scale up the\nnumber of agents (Mou et al., 2024). However, research on large-scale scalability is still limited, and\nmany of these simulations run for extended durations. (Qian et al., 2024) In contrast, our simulator\nis specifically designed for synthetic data generation, supporting both complex agent actions and\nscalable simulations, addressing the demand for diverse, realistic, and efficient simulations."}, {"title": "6 CONCLUSION AND FUTURE WORK", "content": "This paper presents a novel framework for synthesizing post-training data based on multi-agent\nsimulation. Our framework consists of two key components: MATRIX", "that": "i) MATRIX-Gen-SFT outperforms other SFT datasets; ii) Models\nf"}]}