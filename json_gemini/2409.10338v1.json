{"title": "THE 20 QUESTIONS GAME TO DISTINGUISH LARGE LANGUAGE MODELS", "authors": ["Gurvan Richardeau", "Erwan Le Merrer", "Camilla Penzo", "Gilles Tredan"], "abstract": "In a parallel with the 20 questions game, we present a method to determine whether two large language models (LLMs), placed in a black-box context, are the same or not. The goal is to use a small set of (benign) binary questions, typically under 20. We formalize the problem and first establish a baseline using a random selection of questions from known benchmark datasets, achieving an accuracy of nearly 100% within 20 questions. After showing optimal bounds for this problem, we introduce two effective questioning heuristics able to discriminate 22 LLMs by using half as many questions for the same task. These methods offer significant advantages in terms of stealth and are thus of interest to auditors or copyright owners facing suspicions of model leaks.\nIndex Terms- LLMs, black-box distinguishability.", "sections": [{"title": "1. INTRODUCTION", "content": "Auditing AI models in a black-box interaction scheme is a difficult task attracting a considerable attention today [1, 2]. Although there is now an important set of works for auditing machine learning classifiers (whether for fairness [3], security [4], intellectual property matters [5] or others), the relative novelty of large language models (LLMs) calls for adapted auditing methods. In this paper, we tackle the possibility of assessing the simple, yet challenging question of efficiently differentiating LLMs only by prompting them. This task has important applications such as being a preamble for a poten-tial prosecution (in the case of model stealing suspicion, see e.g. [6] for the same task with classifier models), or evaluating the convergence of these models towards a high accuracy on predefined set of regulatory prompts (thus leading in hardness to discriminate them).\nIn this paper, and after similar attempts in the domain of image classification, [7] for example, we take the step to ad-dress the issue using benign questions, i.e. questions that are not adversarially crafted [8]. These benign inputs have the advantage of being less prone to defenses on the model side [6], as they follow the genuine data distribution."}, {"title": "2. PROBLEM STATEMENT", "content": "We denote Q the infinite set of all questions (i.e. prompts or queries) that have binary answers. In this context, we define a LLM or a model m as a deterministic map in $\\mathcal{M} \\stackrel{\\text{def}}{=} \\{0,1\\}^{\\mathcal{Q}}$.\nLet then \u03bc denote the empirical distribution of the models. Specifically, a representative sample from \u03bc is obtained by randomly selecting a model from the collection of all existing models, e.g. those available on Hugging Face."}, {"title": "2.1. The Problem of Distinguishing LLMs", "content": "Consider an auditor having a prompt-only access to two such LLMs (m, m'). Her objective is to know whether m and m' are the same model or if they differ. If m and m' are indeed the same model, the two would provide identical re-sponses to any given prompt. However, even if m and m' differ, they may provide identical answers to (at least) some of the prompts. In the following, we will formalize the ques-tion of whether m and m' are different and the question of which prompts we should select to efficiently distinguish the two given models.\nDefinition 2.1 (Distinguishing LLMs). Given two unknown models m, m' from M, find a set of k requests that maximizes the probability of correctly rejecting hypothesis $H_0: m = m'$ when $H_1: m \\neq m'$ is true. In other words, accurately distinguish two distinct LLMs within k prompts.\nThis involves analyzing the following map:\n$\\begin{aligned}\nS: &\\mathbb{N}^* \\rightarrow[0,1]\\\\ &\tS \\rightarrow \\underset{Q \\subset Q, |Q|=k}{\\max} \\acc(Q)\n\\end{aligned}$                                                (1)\nThe accuracy being:\n$\\acc(Q) = \\mathbb{P}(T_Q = 0, H_0) + \\mathbb{P} (T_Q = 1, H_1),$                                                      (2)\nwith $T_Q$ being the test such that the two models are detected as equal if and only if they answer the same on every ques-tions of $Q$, i.e.:\n$T_Q: (m, m') \\rightarrow \\begin{cases}\n0 & \\text{if } m(Q) = m'(Q) \\quad (\\text{accept } H_0)\\\\\n1 & \\text{if } m(Q) \\neq m'(Q) \\quad (\\text{reject } H_0)\n\\end{cases}$\nHere, the game becomes devising algorithms that find the best sets of questions which solve (1) for a small number k of questions."}, {"title": "2.2. Experimental Assumptions", "content": "To compute the accuracy (2), we need the probability that the two models are the same, that is, $\\mathbb{P}(H_0)$. This proba-bility is either the result of our suspicion that the two mod-els are different (e.g., secret retraining of a stolen model) or our suspicion that the two are the same (e.g., direct use of a stolen model). We set $\\mathbb{P}(H_0) = \\frac{1}{2}$, indicating that we have no stronger belief that the models are identical or different.\nWe note that given the deterministic behaviours of our models, true positives are trivial in our experiment ($\\mathbb{P} (T_Q = 0 | H_0) = 1$). Therefore, (1) can be tackled from the true negatives point of view:\n$\\underset{Q \\in Q, |Q|=k}{\\arg \\max} \\acc(Q) = \\underset{Q \\in Q, |Q|=k}{\\arg \\max} \\mathbb{P} (T_Q = 1 | H_1)$.                                                                        (3)\nWe therefore focus our analysis on the case m \u2260 m'."}, {"title": "3. OPTIMAL NUMBER OF QUESTIONS", "content": "We define a query as optimal when it separates a set of mod-els into two equal groups according to their answers. If the two groups are evenly divided, the number of differentiated pairs is maximized with a single question (see Appendix B for proof). Let X be the number of queries necessary to dif-ferentiate a pair of models (m, m') s.t. m \u2260 m' and s.t. m and m' are randomly drawn uniformly from the infinite set of models M where the queries are optimal (see Th. B.1). Mathematically, let $(m, m') \\sim \\mathcal{U}(\\mathcal{M})^{\\otimes 2}$ s.t. m \u2260 m'. Let $X = \\inf\\{k \\in \\mathbb{N}^* | m(Q^*(k)) \\neq m'(Q^*(k))\\}$ where $Q^*$ is Q ordered such that the queries are optimal. The law of X is then $\\mathbb{P}(X < k) = 1 - (\\frac{1}{2})^k, \\forall k \\in \\mathbb{N}^*$ (see Appendix B)."}, {"title": "4. EXPERIMENTAL SETUP", "content": "To tackle (1), we need a set of questions Q and the ability to sample from the distribution \u03bc. To achieve this, we select 22 models (listed in Figure 4 in Appendix, set we coin M) and K questions (see Table 1) from HuggingFace.\nAs seen in (3), we are interested in the true negatives, which we approximate by Monte Carlo as follows:\n$\\mathbb{P} (T_Q = 1 | H_1) \\propto \\sum_{(m,m')\\in M^2,\\atop m\\neq m'} \\mathbb{1}_{m(Q)\\neq m'(Q)}.$\nFinally, we seek for maximizers over Q of (1). An optimal, yet non-tractable, algorithm would require looking at as many sets as the binomial coefficient $\\binom{|Q|}{\\text{max\\_size}}$, where max_size is the maximum size of the question set we consider. We will focus experimentally on the set sizes of max_size = 20, mak-ing such an optimal algorithm intractable. We thus propose different heuristics in Sect. 5.\nThe Similarity of LLMs on Their Responses Figure 1 represents the distribution of models answers for each ques-tion of the set K. For instance, the point x = 20, y = 0.043 means that 4.3% of the questions of K were correctly an-swered by 20 of the 22 tested models. Using the average correct answer rate (p = 54.6%), we present the correspond-ing binomial distribution (number of success with 22 coin tosses at probability p). This model assumes that each LLM answers independently correctly. The resulting bell shaped distribution differs drastically from the empirical observation: this highlights a lack of independence from the models. This means that in practice some questions are easy and correctly answered by most models, while almost all models fail at correctly answering some other (hard) questions. Motivated by this lack of independence between models, we now look at an experimental approach to identify good question sets.\nExperimental method We consider heuristic algorithms of the form $A : (\\mathcal{M}, Q) \\mapsto \\lambda \\in [0, 1]^Q$ that yields a discrimi-nating score $lambda$ such that for $q \\in Q$, the closer $\\lambda(q)$ is to 1, the better q is supposed to distinguish models of \u03bc.\nThen, for each pair (m, m') of M models, we query both models with the questions from Q ordered decreasingly by \u03bb, until they answer differently (i.e. we distinguished them) and record the corresponding number of questions. From this we plot the cumulative distribution function that indicates how many model pairs can be distinguished as a function of the number of questions. See Alg. 1, where: $t(Q,m,m') = \\min_{j\\in[1,...,|Q|]}\\{j | m(Q[j]) \\neq m'(Q[j])\\}.$\nA Baseline: Selecting Questions at Random We define the Random heuristic $A_{\\text{rand}}$ as $A_{\\text{rand}}(\\mathcal{M}, Q) = q \\rightarrow \\mathcal{U}([0, 1])$. Fig 2 (a) illustrates that by randomly selecting questions uni-formly across all datasets, we achieve an average accuracy of 95% with 6 questions. The best case reached within the 2000 runs (green curve) is based on AUC (Area Under Curve). The figure representing each question dataset is omitted, as the dif-ferences are not substantial: achieving 95% accuracy requires 5 questions for the \"best\" dataset vs 7 for the \"worst\"."}, {"title": "5. TWO HEURISTICS FOR DISTINGUISHABILITY", "content": "In the following, $Q \\subset Q$ and $M \\subset \\mathcal{M}$ denote finite subsets of questions and models. $\\mathcal{N}$ is a min-max normalization."}, {"title": "5.1. The Separability Heuristic", "content": "We here focus on individual questions: what makes it a good question? An initial measure of distinguishing power is how evenly the binary question divides the two groups of models. The heuristic is given in Algorithm 1, here is a formal defini-tion:\nDefinition 5.1 (Subset Separability). Separability of X C M:\n$\\begin{aligned}\n\\Delta_{\\mathcal{M}}:& \\mathcal{P}(\\mathcal{M}) \\rightarrow [0, 1]\\\\ &X \\mapsto \\mathcal{N} (\\frac{\\|\\mathcal{M}| - |\\overline{X}| - |X||}{\\|\\mathcal{M}|}),\n\\end{aligned}$\nwhere $\\overline{X} = \\mathcal{M} \\setminus X$.\nWe denote $\\mathcal{M}_q \\stackrel{\\text{def}}{=} \\{m \\in \\mathcal{M} | m(q) = 1\\}$ such that the highest $\\Delta_{\\mathcal{M}}(\\mathcal{M}_q)$ is, the better q divides the models evenly. Finally, we define the heuristic $A_{\\text{sep}}$ as follows:\n$A_{\\text{sep}} (\\mathcal{M}, Q) = q \\mapsto \\begin{cases}\n\\mathcal{U}([0,1]) & \\text{if } q \\in \\underset{q \\in Q}{\\arg \\max} \\Delta_{\\mathcal{M}}(\\mathcal{M}_q)\\\\\n0 & \\text{else}\n\\end{cases}$                                             (4)"}, {"title": "5.2. The Recursive Similarity Heuristic", "content": "We now consider sets of questions: what makes it a good question set? Sampling from questions with maximum sepa-rability makes it possible for two questions to obtain the same partitions (i.e. the same two groups of models), making it pointless to use them both. Hence, the need for a metric that compares the similarity between the two partitions. We pro-pose a heuristic that constructs a sequence of questions using a recursive approach, ensuring that each subsequent question is as dissimilar as possible from the previous.\nDefinition 5.2 (Similarity of two partitions of same separabil-ity). For $X,Y \\subset \\mathcal{M}$ s.t. $\\Delta_{\\mathcal{M}}(X) = \\Delta_{\\mathcal{M}}(Y)$, we define the similarity $\\Gamma_{\\mathcal{M}}$, as:\n$\\begin{aligned}\n\\Gamma_{\\mathcal{M}}:& \\mathcal{P}(\\mathcal{M}) \\times \\mathcal{P}(\\mathcal{M}) \\rightarrow [0, 1]\\\\ &(X, Y) \\mapsto \\mathcal{N} \\left(\\max\\{\\|X \\cap Y\\|, \\|\\overline{X} \\cap Y\\|, \\|X \\cap \\overline{Y}\\|, \\|\\overline{X} \\cap \\overline{Y}\\|\\}\\right)\n\\end{aligned}$\nThen we define the heuristic $A_{\\text{sim}}$ with Algorithm 2 such that $A_{\\text{sim}} (\\mathcal{M}, Q) = \\text{RecursiveSim}(\\mathcal{M}, Q, \\text{empty list})$. This al-gorithm initially selects two questions with the least similarity (line 3), a process that is tractable for two questions. Subse-quently, it iteratively adds a question that is the least similar to the existing ones (line 8). Each search for a new question incurs a linear cost, ensuring the algorithm remains tractable. Finally, as this process yields very good discriminating ques-tions, we can define a limit of iterations (max_iter) making the algorithm even more efficient (the questions that have not been added have a score set to 0)."}, {"title": "6. EXPERIMENTAL RESULTS", "content": "Figure 2 (a) shows how the random baseline performs. Figure 2 (b) shows that selecting questions with the highest separa-bility at random produces significantly better results than a purely random selection. It also shows that the $A_{\\text{sim}}$ heuris-tic performs better, although with modest improvement, sug-gesting that our set of questions with maximum separability (in our experiments, we got 4,000 such questions) is quite di-verse in the partitions the questions yield. While achieving 95% accuracy requires on average 6 questions using random selection, our heuristics only require 3. Fig 2 (c) represents the best set of questions obtained by each heuristic against our specific set of models."}, {"title": "7. CONCLUSION", "content": "Our framework shows that properly selecting from binary questions shows promising results on the task of distin-guishing LLMs. This encourages further investigation; in particular a generalization to wider sets of models. Also, focusing on differentiating models that are by construction close to each other would constitute an interesting angle, e.g. models with different training parameters or training data. Furthermore, investiguating the robustness of our approach with non-deterministic models is futurework."}, {"title": "B. PROOFS", "content": "Theorem B.1. Let M be a finite set such that |M| = L. A question that maximally differentiates pairs in M is one that splits the set into the most equal groups.\nProof. Let qk be the query that splits M into two groups of size 2 \u2264 k \u2264 L - 1 and L - k. We have:\n$\\begin{aligned}\n|\\{\\text{pairs split by } q_k\\}| &= |\\{\\text{all pairs}\\}| - (\\binom{|P_1|}{2} + \\binom{|P_2|}{2})\\\\ &= \\binom{L}{2} - (\\binom{k}{2} + \\binom{L - k}{2})\n\\end{aligned}$\nwhere $P_1, P_2$ are the pairs in the first and second groups. Next, we aim to maximize the number of split pairs, which are the pairs that are differentiated. Therefore, we seek for the maximizer of $k \\rightarrow |\\{\\text{pairs split by } q_k\\}|$ that is a second order polynomial with maximum reached in $\\left[\\frac{L}{2}\\right]$. $\\square$\nLemma B.2. For a finite set of models M s.t. |M| = 2n. The law of X is given by:\n$\\mathbb{P}(X \\leq k) = 1-\\frac{2^{n-k-1}}{2^{n-1}} \\quad 1 \\leq k \\leq n$.                                                                                                                                                                                                                                                                            (5)\nProof. At first step, i.e. k = 1, there are 2n models, the first query $Q^*(1)$ will divide in two groups of size $2^{n-1}$. In each of these groups, there are $\\binom{2^{n-1}}{2}$ possible pairs, whereas there are $\\binom{2^{n}}{2}$ different pairs before querying. Therefore, we deduce that $\\mathbb{P}(X \\leq 1) = \\frac{\\|\\{\\text{pairs that the query splits}\\}|}{\\|\\{\\text{all possible pairs of } M\\}\\|} = \\frac{\\binom{2^{n}}{2}-2\\binom{2^{n-1}}{2}}{\\binom{2^{n}}{2}} = \\frac{1}{2^{n-1}}$. At step $k \\in \\mathbb{N}^*$, there are $2^{k-1}$ groups of $2^{n-(k-1)}$ models, query $Q^*(k)$ will divide each of these groups by two. In each of these $2^k$ groups, there are $\\binom{2^{n-k}}{2}$ possible pairs. With similar thinking as first step, we deduce that: $\\mathbb{P}(X < k) = \\frac{\\|\\{\\text{pairs that the queries split}\\}|}{\\|\\{\\text{all possible pairs of } M\\}\\|} = \\frac{\\binom{2^{n}}{2}-2^k.\\binom{2^{n-k}}{2}}{\\binom{2^{n}}{2}} = 1-\\frac{2^{n-k-1}}{2^{n-1}}$. $\\square$\nTheorem B.3. For a infinite and countable set of models M. The law of X is given by:\n$\\mathbb{P}(X < k) = 1 - \\left(\\frac{1}{2}\\right)^k \\quad \\forall k \\in \\mathbb{N}^*$.                                                                                                                                                                                                                                                                                                      (6)\nProof. The result is obtained by taking the limit of n towards infinity of $\\mathbb{P}(X \\leq k)$ of Lemma B.2. $\\square$"}]}