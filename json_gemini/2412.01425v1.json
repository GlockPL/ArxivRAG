{"title": "Reject Threshold Adaptation for Open-Set Model Attribution of Deepfake Audio", "authors": ["Xinrui Yan", "Jiangyan Yi", "Jianhua Tao", "Yujie Chen", "Hao Gu", "Guanjun Li", "Junzuo Zhou", "Yong Ren", "Tao Xu"], "abstract": "Open environment oriented open set model attribution of deepfake audio is an emerging research topic, aiming to identify the generation models of deepfake audio. Most previous work requires manually setting a rejection threshold for unknown classes to compare with predicted probabilities. However, models often overfit training instances and generate overly confident predictions. Moreover, thresholds that effectively distinguish unknown categories in the current dataset may not be suitable for identifying known and unknown categories in another data distribution. To address the issues, we propose a novel framework for open set model attribution of deepfake audio with rejection threshold adaptation (ReTA). Specifically, the reconstruction error learning module trains by combining the representation of system fingerprints with labels corresponding to either the target class or a randomly chosen other class label. This process generates matching and non-matching reconstructed samples, establishing the reconstruction error distributions for each class and laying the foundation for the reject threshold calculation module. The reject threshold calculation module utilizes gaussian probability estimation to fit the distributions of matching and non-matching reconstruction errors. It then computes adaptive reject thresholds for all classes through probability minimization criteria. The experimental results demonstrate the effectiveness of ReTA in improving the open set model attributes of deepfake audio.", "sections": [{"title": "1. Introduction", "content": "The Text-to-Speech (TTS) generation Application Programming Interface (API) 1 2 3 provides a method for converting text into natural speech, producing audio that is almost indistinguishable from real human speech [1], [2], [3]. However, the misuse of such generation tools or models can lead to the spread of misinformation and violations of suppliers' intellectual property rights [4], [5], among other security issues. Consequently, governments and regulatory bodies are implementing measures 45 to ensure the transparency and traceability of deepfake audio content, including attribution, i.e., identifying the source model of generated contents.\nIn real-world open environments, new speech generation models continuously emerge, making it impossible to exhaustively list all possible categories in advance. However, when deploying systems in such environments, it is essential that the recognition system not only accurately classifies known categories but also effectively handles unknown ones. This challenge is commonly referred to as Open Set Recognition (OSR) [6], [7], [8], [9], [10], [11], [12], [13], [14]. Therefore, for the topic of model attribution of deepfake audio, open set recognition for open environments has important practical significance.\nWhen facing unknown inputs from new categories, an intuitive method to distinguish between known and unknown instances is to manually set a threshold on output probabilities [15], [16]. [17] first proposed to replace the softmax layer in traditional neural networks with OpenMax. OpenMax calibrates the output probabilities by using the Weber distribution to better handle unknown classes. [18] proposed an alternative to using one-versus-rest units (one-versus-rest units) instead of softmax layers. [19] utilized a latent representation of the network for reconstruction, leading to robust unknown detection. [8] proposes the C2AE method, which introduces a new reconstruction task designed to enhance the model's adaptability to open-set scenarios. On track 3 of ADD2023, [20] introduced the KNN distance based on cosine similarity, which separates unknown deepfake audio generation algorithms from known ones based on a threshold criterion. Each of these methods necessitates a manually set threshold to differentiate between known and unknown categories. However, setting and adjusting this threshold is a challenge.\nThis method assumes that the model assigns higher probabilities to known categories than to unknown ones. However, deep learning methods often overfit training instances and produce overly confident predictions [21], [22]. Therefore, even for instances from unknown categories, the model may output high probabilities, making the threshold difficult to adjust. Moreover, the composition of speech generation methods is diverse, including different generation tools and algorithms. A threshold-based open set method defines the space below a fixed threshold as the domain of new categories. Due to the different distributions of data from various sources, it is challenging to rely on a single threshold to identify unknown categories with diverse characteristics. The same threshold that effectively separates unknown system fingerprints from known category system fingerprints may not be suitable for identifying unknown vocoder fingerprints [23]. Thus, manually setting thresholds poses issues of low accuracy and poor data adaptability.\nMotivated by the problems above, we proposed a novel framework utilizing system fingerprints for open set model attribution of deepfake audio with rejection threshold adaptation (ReTA). The framework aims to calibrate open-set classifiers from two aspects. Specifically, we ensure a significant distinction in the reconstruction error space between known and simulated unknown classes by learning their respective error distributions. This forms the basis for calculating rejection thresholds. Additionally, to better adapt to the open space of unknown classes, ReTA fit adaptive thresholds for the reconstruction errors of each class. Thus, ReTA transform closed-set classifiers into open-set classifiers and adaptively predict class-specific thresholds. Experiments on the open set model attribution dataset SFR validated the effectiveness of our approach in open-set recognition, enhancing the generalizability of threshold-based open-set recognition problems.\nOur main contributions are:\n\u2022 We introduced ReTA, the first adaptive threshold framework for open set model attribution of deepfake audio, which enhances the accuracy and data adaptability of the thresholds.\n\u2022 We constructed a new system fingerprint encoding-decoding reconstruction network to learn the reconstruction error distributions of known and simulated unknown classes.\n\u2022 ReTA effectively improves the capability of open set recognition for model attribution of deepfake audio.\nThis paper is structured as follows: Section II elaborates on the proposed ReTA method in detail. Section III presents comparative experiments conducted on the SFR dataset. In Section IV, we summarize and provide future prospects for the paper."}, {"title": "2. Proposed Method", "content": "The overall network architecture of ReTA, as shown in Figure 3, consists of three modules: A) System Fingerprint Recognition module; B) Reconstruction Error Learning module; and C) Adaptive Reject Threshold module. The System Fingerprint Recognition module includes 1) fingerprint extraction sub-network; and 2) classification sub-network. The Reconstruction Error Learning module comprises 1) conditional sub-network; and 2) reconstruction decoding sub-network."}, {"title": "2.1. Framework Architecture", "content": ""}, {"title": "2.1.1. System Fingerprint Recognition module", "content": "Firstly, the fingerprint extraction sub-network aims to generate representative high-dimensional fingerprint representations for various classes. The encoder adopts a simple ResNet-18 [24] architecture with input from low-dimensional LFCC features [25]. Some modifications were made considering the characteristics of deepfake audio, including constraining the activation of the penultimate layer [26]. The downstream classification sub-network aims to achieve accurate recognition of known classes of system fingerprints. It consists of two convolutional layers that output predicted labels. Finally, the cross-entropy loss LCE [27] is computed between the predicted labels and the ground truth labels."}, {"title": "2.1.2. Reconstruction Error Learning Module", "content": "The reconstruction decoding sub-network consists of four deconvolution layers, and its input consists of two parts: the fingerprint representation generated by the system fingerprint recognition module and conditional latent features. Specifically, the class labels of known classes are first transformed from the label space to the feature space. These are then input into the conditional sub-network to obtain conditional latent features.\nSubsequently, through the reconstruction decoder, the fingerprint representation is randomly multiplied with the corresponding conditional latent features and also with randomly selected conditional latent features from other classes, resulting in matching and non-matching features. Finally, these are used by the reconstruction decoding sub-network to produce matching reconstructed samples $X^m$ and non-matching reconstructed samples $X^{nm}$.\nTo facilitate better learning of discriminative features between matching and non-matching reconstructed samples in this module, we have also designed a reconstruction error function:\n$L_{REC} = \\frac{1}{N} \\sum_{i=1}^{N} (||X_i - X^{m}_{i}||_2 + ||X_i - X^{nm}_{i}||^2)$ (1)\nwhere X is the input sample, $X^m$ is the matching reconstructed sample, $X^{nm}$ is a randomly sampled sample from other target classes,$X^{m}$ is the non-matching reconstructed sample. N represents the total number of known classes."}, {"title": "2.1.3. Rejection Threshold Calculation Module", "content": "The reject threshold calculation module aims to obtain optimal reject thresholds for each class, as illustrated in Figure 4. This module comprises two operations: Gaussian probability estimation and probability minimization criterion. After computing the matching and nonmatching reconstruction errors for each training sample, the module partitions the set of matching and nonmatching reconstruction errors into N subsets based on class labels. Subsequently, it fits gaussian kernel function with kernel density estimation (KDE) [28]. Finally, optimal reject thresholds are determined using the probability minimization criterion."}, {"title": "2.2. Training", "content": "The system fingerprint recognition module and the reconstruction error learning module use stochastic gradient descent (SGD) to iteratively update parameters. The overall loss is determined through a weighted sum of $LCE$ and $LREC$, expressed as\n$L = L_{CE} + \\alpha L_{REC}$ (2)\nwhere \u03b1 is a weight hyperparameter. The overall loss encapsulates the contributions of both components, effectively shaping and guiding the network's learning process."}, {"title": "2.3. Inference", "content": "In the open set recognition stage, the test sample undergoes a series of modules. First, the test sample is input into the fingerprint extraction subnetwork to obtain a fingerprint representation. This representation is then fed into the classification subnetwork to generate the predicted class label. Next, the predicted class label and the fingerprint representation are input into the conditional decoding subnetwork to produce the reconstructed sample. Finally, the reconstruction error of this sample is compared with the optimal reject threshold for the predicted class. If the reconstruction error is less than the reject threshold, the test sample is recognized as the predicted class label. Otherwise, the test sample is rejected as belonging to the unknown class."}, {"title": "3. Experiences", "content": ""}, {"title": "3.1. Experimental Settings", "content": "ReTA was validated on the SFR dataset. [2] constructed the first audio dataset for system fingerprint recognition. The audio in the SFR dataset was generated by models from mainstream TTS systems of Chinese vendors, including both clear and compressed sets. The generated speech comes from seven mainstream open source vendors including Aispeech, Alibaba Cloud, Databaker, Sogou, Baidu Ai Cloud, Tencent, and iFLY-TEK. Parameters are randomly initialized. The training was conducted with the Adam optimizer to accelerate optimization by applying adaptive learning rate. The initial learning rate is set to 0.001 for Adam, with linear learning rate decay. These models are trained with a mini-batch size of 128, for 100 epochs."}, {"title": "3.2. Evaluation Metrics", "content": "To quantitatively evaluate the discriminative performance of our method between known and unknown classes, we introduce F1-score [29], Total Accuracy and ID Accuracy to assess various OSR methods.\nF1-score (Macro-average): Used for open-set recognition to balance precision and recall, providing an overall classification indication that includes additional unknown classes. The formulas for calculation are as follows:"}, {"title": "3.3. Performance of Model Attribution of Deepfake Audio.", "content": "Our open set recognition performance is compared on the SFR dataset: the test set includes 6 known classes and 2 unknown classes. In Table 2, we compare ReTA with other methods based on manually setting thresholds, including SoftMax (with threshold) [2], OpenMax [17], and the CROSR [19] method. For a fair comparison, all methods use the same LFCC input features and ResNet network structure. Larger values of all evaluation metrics indicate better performance.\nRegarding the open set model attribution of deepfake audio, our approach overall achieves the best average performance. Specifically, our method achieves the highest F1-score and total accuracy on both datasets, demonstrating its effectiveness in improving OSR performance. The ultimate goal of open set recognition is not only unknown detection but also maintaining high recognition ID accuracy for known class samples. Our method ensures high sensitivity in identifying unknown classes and robust classification of known classes in compressed datasets, demonstrating strong generalization in compressed environments."}, {"title": "4. Conclusions", "content": "Manually preset rejection thresholds for model attribution of deepfake audio pose challenges to both the performance of open-set recognition and data adaptability. To address this challenge, we propose a novel adaptive threshold framework named ReTA. ReTA employs a reconstruction error strategy to simulate the unique characteristics of unknown class samples. Utilizing kernel density estimation, ReTA fits Gaussian kernel functions and ultimately computes the optimal reject thresholds for each class through probability minimization criteria. Results obtained on open set model atribution of deepfake audio demonstrate the effectiveness of the proposed approach. In real-world open scenarios, unknown targets may belong to different classes. Simply rejecting unknown targets as a single \"Unknown\" class is insufficient; there is a need to further distinguish their specific attributes. Therefore, in the future, we will focus on improving this limitation."}]}