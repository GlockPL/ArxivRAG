{"title": "The Career Interests of Large Language Models", "authors": ["Meng Hua", "Yuan Cheng", "Hengshu Zhu"], "abstract": "Recent advancements in Large Language Models (LLMs) have significantly extended their capabilities, evolving from basic text generation to complex, human-like interactions. In light of the possibilities that LLMs could assume significant workplace responsibilities, it becomes imminently necessary to explore LLMs' capacities as professional assistants. This study focuses on the aspect of career interests by applying the Occupation Network's Interest Profiler short form to LLMs as if they were human participants and investigates their hypothetical career interests and competence, examining how these vary with language changes and model advancements. We analyzed the answers using a general linear mixed model approach and found distinct career interest inclinations among LLMs, particularly towards the social and artistic domains. Interestingly, these preferences did not align with the occupations where LLMs exhibited higher competence. This novel approach of using psychometric instruments and sophisticated statistical tools on LLMs unveils fresh perspectives on their integration into professional environments, highlighting human-like tendencies and promoting a reevaluation of LLMs' self-perception and competency alignment in the workforce.", "sections": [{"title": "1 Introduction", "content": "Interest has been recognized as a special aspect of personality and has been attracting researchers for a long time. Career interest is particularly fascinating to applied psy- chologists, which plays an essential role in the satisfaction and performance of people at work [1]. As Large Language Models (LLMs) are evolving quickly, making them seemingly more humanlike, they are increasingly being integrated into various facets of people's daily work lives, enabling them to assume a substantial role and demon- strate impressive competency [2, 3]. One question arises: do LLMs have interests? More specifically, do they have career interests? Our analysis suggests that perhaps they do. We found that when judging the work tasks associated with various interest categories, LLMs display a clear preference towards the artistic and social types of work tasks. And by their own judgment, they are not particularly good at it.\nEvolving from simple text generators to complex systems capable of a wide range of tasks, LLMs have made significant advancements in recent years [4]. Unlike tradi- tional tools humans developed to use in work and daily life, LLMs offer a new level of responsiveness and adaptability. Leading artificial intelligence chatbots have demon- strated impressive abilities and are already integrated into various aspects of human life and work[2]. Perhaps one of the most important implications of LLMs is their capacity to serve as professional assistants in the workplace. This potential is so pro- found that it has sparked serious concerns about them replacing people. The fears of advancing technologies taking over human capacities to work are nothing new, how- ever, this time, the threat seems to be real and close, causing considerable efforts to be undertaken to evaluate the extent to which LLMs could be replacing human jobs[5, 6]. Recent estimations provide unsettling figures, suggesting that between 27% and 40% of jobs could potentially be replaced by LLMs. And they are becoming more useful and sophisticated every day. They are engineered to simulate human-like inter- actions, giving them the appearance of personality and making them more akin to co-workers than to inert office supplies or basic software programs. Studies have shown that human users are unable to distinguish between interactions with LLMs and real humans [7\u20139], even in sensitive, personal settings[10]. The fact that LLMs appear to be both technologically and inter-personally competence warrants a more in-depth investigation into the role of LLMs as potential workers.\nAs LLMs rapidly advance, they become increasingly human-like in their capabilities [11], researchers are increasingly applying measurement tools originally designed for humans to evaluate LLMs. By utilizing cognitive psychology tests, researchers are now exploring both their performance and intrinsic dispositions, such as the intelligence [12\u201314], theory of mind [15], and language abilities [16, 17] of LLMs, while personality assessments have garnered particular interest for exploring their seemingly human- like traits [18\u201322]. Tools such as the Myers-Briggs Type Indicator [23] have been employed to probe deeper into LLMs' behavioral inclinations [19, 21], and psychiatric diagnostic instruments are used to investigate if LLMs display any darker psychological traits [22]. This multidisciplinary approach has revealed that LLMs exhibit a mix of remarkably human and distinctly non-human traits, highlighting their complex nature. As LLMs advance and become increasingly integrated into daily work life, understanding their role and potential career interests becomes crucial. The prevailing research approach has focused primarily on LLMs' ability to imitate or replace human behavior [24\u201326], with less attention given to their intrinsic traits. Understanding the behaviors and underlying characteristics of artificial intelligence systems is essential for effectively managing their actions, leveraging their benefits, and mitigating associated risks [25, 27, 28]."}, {"title": "2 Results", "content": "We evaluated the career interests of LLMs and discovered that LLMs show distinct preferences on work tasks, particularly favoring the artistic and social categories. Figure 1 shows the overall process of evaluating career interests. Interestingly, the same LLM exhibited varying patterns of career interest scores when assessed in both English and Chinese. If these score patterns were observed in humans, they would be categorized into different interest categories, potentially guiding them toward differ- ent occupational paths. We further investigated the perceived competence of LLMs in these work tasks based on the LLMs' own assessment and human experts' assessment. We studied their relationships with career interests and discovered that LLMs tend not to rate tasks they are particularly interested in with high competence scores. There was also a noticeable discrepancy between many of the LLMs' and human experts' assessments regarding task competence.\nThe study assessed LLMs' vocational interests using the OIP short form of O*NET [30], a sixty-item inventory based on Holland's hexagon model with six inter- est categories [32, 33]. LLMs evaluated each work task independently on a 5-point Likert scale, and their responses were scored to determine their top three interest cat- egories, forming a three-letter code. The RIASEC hexagon was designed such that adjacent categories are more correlated than distant ones. Artistic interests include activities like acting, music, art, and design, while Social interests involve interacting with and helping people through teaching or counseling."}, {"title": "2.1 Career interests of LLMs", "content": "In this study, four well-received LLMs were chosen to study their career interests: gpt- 3.5 (GPT-3.5) from OpenAI, Gemini 1.5 pro (Gemini-1.5) from Google, ERNIE 3.5 (ERNIE-3.5) from Baidu, and Spark V3.5 (Spark-3.5) from iFLYTEK. We used the publicly available APIs for all the LLMs in this study. OIP short form was adminis- tered in English. All additional parameters, including temperature and penalty, were maintained at the default values to capture the intrinsic behavior of the LLMs authen- tically. Specifically, the GPT-3.5 models were set to a temperature of 1. Gemini-1.5's temperature was slightly reduced to 0.9. ERNIE was configured with a temperature of 0.8, and Spark-3.5 had a setting of 0.5. This approach was adopted to retain the natu- ral fluctuations in the model outputs, mirroring the complexity and subtlety of human behavioral patterns. Moreover, this setting is consistent with the typical user expe- rience when interacting with these models via the web interface. To account for the random noise introduced by keeping the default temperature, each item was adminis- tered 20 times under the same setup and prompt. The 20 replications were executed to mitigate the random noise inherent in the data from utilizing the default tem- perature in each LLM and stabilize the outcomes to better elucidate the underlying pattern. Parameter estimates for all models involved were presented in Supplementary Information Section 1.1 - 1.5.\nTo assess the career interests of LLMs on the Holland hexagon, each LLM was first evaluated in English. We analyzed Holland interest scores as a function of Holland interest categories (RIASEC), LLMs (GPT-3.5, Gemini-1.5, ERNIE-3.5, & Spark- 3.5), and 20 repeated testings. A random intercept was included in the model to accommodate for the random variations among each item.\nFigure 2 shows the average observed interest score for each RIASEC category for each LLM tested, and presents the 3-letter codes for each LLM based on its score patterns and the corresponding occupations recommended by O*NET based on the interest codes. For GPT-3.5, the three-letter codes S, A, and I were not significantly different based on multiple comparison results. Since this was the result of a simula- tion study using a sampling method to mitigate random error, nonsignificant results indicated that the three categories were indistinguishable; all combinations were nec- essary. In the case of human participants, the three-letter code can be determined by ranking the six categories without the need for significant testing. Table 1 displays the estimated interest scores for each interest category of the four LLMs. There are clear preferences towards the Artistic and Social categories, while the interest scores for the enterprising, conventional, and Realistic categories are generally lower.\nLLMs on RIASEC. Mixed model results showed that there was a significant dif- ference on the Holland interest scores among LLM families, (F(3, 216) = 18.76, P = 7.46 \u00d7 10-11). Interestingly, the LLMs generally displayed distinct interest pat- terns that indicated that they would clearly prefer some types of work tasks over the others. There was a significant difference in the Holland interest scores among the RIASEC categories (F (5, 216) = 32.14, P = 1.776 \u00d7 10-15) over the LLMs. For all 4 LLMs, the Social and the Artistic categories were among the 3 highest categories, with the Investigative category being the other among the top three. Simple comparisons with Tukey adjustments showed that the Artistic and Social categories were quite similar to each other (t(216) = \u2212.029, P = .977), suggesting that LLMs were equally interested in the tasks in these two categories. In contrast, LLMs showed significantly less interest in the Conventional, Realistic, and Enterprising categories.\nFor all four LLMs tested, the top three highest interest categories are Social, Artistic, and Investigative. Figure 3 showed the relationships between the RIASEC interest categories for the 4 LLMs, all exhibiting that the Social, Artistic, and Inves- tigative categories have higher interest scores than the Realistic, Conventional, and Enterprising categories. For GPT-3.5, there was significant differences between the top 3 categories and the other 3 categories (t(216) = 3.683, P = .0003), suggesting that it is statistically meaningful to differentiate Social, Artistic, and Investigative as the career interests of GPT-3.5, although post hoc comparisons with Tukey adjust- ments indicated that there was no significant differences among the 3 categories themselves, suggesting that a code of SAI, ASI, IAS, ISA are equally possible. For Gemini, Artistic, Social, and Investigative were the top 3 categories, and there were no differences between the Artistic and the Social categories. However, there was a significant difference between the Artistic and the Investigative categories in the post hoc pairwise comparisons with Tukey adjustment, (t(216) = 2.887, P = .048). In addi- tion, there was a significant difference between the top 3 and the bottom 3 categories (t(216) = 5.843, P = 1.87 \u00d7 10\u22128). For ERNIE-3.5 (t(216) = 10.241, P = 2.57 \u00d7 10-20) and Spark-3.5 (t(216) = 3.968,p = 9.86 \u00d7 10-5), the top 3-letter code also were significantly different from the bottom 3 letters. Notably, although the letter codes were similar, not all the pattern of interest were the same for the 4 LLMs. There was no significant differences between the patterns of interest scores for GPT-3.5 and Gemini-1.5 (t(216) = \u22121.740, P = .306). However, the pattern of GPT-3.5 was signif- icantly different from those for ERNIE-3.5 (t(216) = 2.771, P = .031) and Spark-3.5 (t(216) = -4.585, P = 7.853 \u00d7 10\u22126).\nLLMs displayed the most interest in the social and artistic categories. In the Social category, LLMs displayed similar interests, as post hoc comparisons showed no significant difference. In the Artistic category, GPT-3.5 scored lower than Gemini- 1.5 (t(216) = -3.653, P = .002), but performed similarly to Spark-3.5 (t(216) = -2.081, P = .163) and ERNIE-3.5 (t(216) = .746, P = .878). In the Investigative category, GPT-3.5 performed lower than Spark-3.5 (t(216) = \u22123.478, P = .003)."}, {"title": "The influence of language.", "content": "We hypothesized that since LLMs are fundamentally shaped by their training data and value alignment process [34], changing the admin- istrating languages would result in different interest patterns. Although large and complex corpora used for commercial LLMs are not fully transparent, based on various official reports, it is likely that LLMs developed in English-speaking environments are mainly trained on English data, while Chinese LLMs are trained on Chinese content. Specifically, we hypothesize that an LLM's response to input in its primary training language may differ from its response to input in a secondary language.\nHolland interest scores were analyzed as a function of RIASEC, LLMs, and admin- istrative languages (English vs. Chinese), with 20 repeated testings as the random effect. As predicted, using English or Chinese to administer the OIP resulted in differ- ent interest patterns (F(1,432) = 11.29, P = 8.48\u00d710-4) after adjusting for the effect of interest categories and LLM families. The pattern of differences in interest scores among the 6 interest categories was significantly different for the 4 LLMs between English and Chinese language (F(15,432) = 2.84, P = 2.95 \u00d7 10\u22124).\nLanguages used to administer the OIP resulted in different interest patterns of the LLMs (F(15,432) = 2.79, P = 3.76 \u00d7 10\u22124). Figure 4 shows the interest scores on the RIASEC hexagon for each of the four LLMs in English and Chinese. For an LLM, the choice of language used in the admission significantly influenced the interest code produced. Moreover, the patterns of differences are not uniform within the LLM families. Marginal comparisons showed that ERNIE showed significant differences in the interest patterns when switching from English to Chinese (t(432) = 6.526, P = 1.896 \u00d7 10-10), while for the other LLMs, the change of languages did not produce a significant difference. Fig 5 showed the estimated differences between Chinese and English for the 4 LLMs. For ERNIE, interest scores in Chinese showed no significant differences among the RIASEC scales, while in English, a strong preference for the Social and Artistic categories was displayed. Marginal comparisons among the LLMs showed that gpt and gemini were quite similar for both English (t(432) = \u22121.783, P = .283) and Chinese (t(432) = -2.304, P = .099) versions. For the English version, gpt behaved significantly differently from ERNIE and spark. All the other pairwise comparisons were significant. For the Chinese version, ERNIE behaved quite similarly to Gemini (t(432) = .908, P = .800) and Spark (t(432) = -.037, P = .971), and differently from GPT (t(432) = \u22123.222, P = .008).\nIn examining language preference patterns among LLMs, it was observed that GPT, Gemini, and Spark exhibited similar interest codes across languages, suggesting consistent interest patterns regardless of administrating language. However, interests of ERNIE changed significantly with the two languages, showing a uni-directional interest in Chinese and a sequential interest in Social and Artistic types before Inves- tigative interests in English. Apart from ERNIE's unique behavior in Chinese, the LLMs generally showed a strong inclination towards Social and Artistic work, followed by the Investigative category. Conversely, there was a notable lack of preference for the Realistic, Enterprising, and Conventional types of tasks across the models."}, {"title": "The change over LLM versions.", "content": "We also explored the potential differences in version advances of LLMs. For the GPT models, the four models gpt-3.5-turbo-0301, gpt-3.5-turbo-0613, gpt-3.5-turbo-1106, and gpt-3.5-turbo-0125 formed an advance- ment of the GPT-3.5 models, thereby enabling us to test for the change of career interests with the advancing versions. For the ERNIE models, we studied ERNIE-3.5- origin, ERNIE-3.5-1222, and ERNIE-3.5-0205. Version numbers correspond to specific dates. For example, gpt-3.5-turbo-0613 represents a snapshot from June 13th, 2023. Both gpt-3.5-turbo-0125 and ERNIE-3.5-0205 are the latest versions from 2024, while the rest are snapshots from 2023.\nHolland interest scores were analyzed as a function of RIASEC, LLM versions, and administrative languages. Figure 6 shows the career interest by category for the 4 GPT and 3 ERNIE models that formed a line of version advancement. For both the GPT and ERNIE families of LLMs, there were significant differences in the interest scores among different versions of LLM (F(3,432) = 38.75, P = 2.542 \u00d7 10-22; F(2,324) = 10.95, P = 2.51 \u00d7 10-5, respectively). However, there was no significant differ- ence caused by the changing of administrative languages (F(1,432) = 0.49, P = .483; F(1,324) = 3.85, P = .051, respectively). These results suggested that both GPT and ERNIE families showed distinct interest preferences in the RIASEC hexagon that were consistent with the change of administrating languages.\nMultiple comparison results showed that there were significant variations in the interest scores of the 4 GPT models. The 4 versions of got models all preferred the Artistic and Social types of works, followed by the Investigative type; thereby, if treated as human participants, they would be recommended to similar occupations based on O*NET systems. However, the values and patterns of their interest scores were significantly different. For the 3 ERNIE models, the \"baseline\" model ERNIE-3.5- origin was significantly different in the interest scores from ERNIE-3.5-1222 (t(324) = -4.266, P = 2.62 \u00d7 10-5) and ERNIE-3.5-0205 (t(324) = -3.374, P = .002), while ERNIE-3.5-1222 and ERNIE-3.5-0205 were quite similar (t(324) = \u22121.096, P = .517).\nThere was a significant effect of language for the ERNIE models (t(324) = -2.74, P = .007), but not for the GPT models (t(432) = \u22121.34, P = \u2212.183). For the ERNIE models, when tested in Chinese, the 3 versions behaved similarly, while when tested in English, ERNIE-3.5-origin was significantly different from ERNIE- 3.5-1222 (t(324) = \u22126.640, P = 1.32 \u00d7 10-10) and the newest model at the time of testing ERNIE-3.5-0205 (t(432) = 6.091, P = 1.90 \u00d7 10-6). In summary, the results show significant variations in interest scores among the different versions of both GPT and ERNIE models, with each model exhibiting distinct preferences in the RIASEC hexagon. However, the administrative language (English vs. Chinese) had no signifi- cant effect on the interest scores for the GPT models, while it did have a significant effect for the ERNIE models, particularly when tested in Chinese."}, {"title": "2.2 Career interests and competence", "content": "Along with career interests, we also asked the four LLMs to rate their own compe- tence on the 60 OIP work tasks and explored the relationship between the interests and competency to see if they are good at the work tasks they are interested in. Com- petency is defined as the knowledge, skill, and ability required to complete a work task [35] adequately. We asked each LLM to evaluate its own competence on each of the OIP work task and the data was collected and analyzed following the same process as the career interest experiments. The instructions for evaluating the competence of LLMs on the OIP work tasks were presented in Supplementary Information Section S2.2. The results showed a general trend of a lack of association between interests and competence in the same set of work tasks, which would suggest that the LLMS consider themselves not particularly good at the tasks that they show interest in."}, {"title": "Interests and self-rated competence.", "content": "Mixed model results showed that there was a significant difference in the interest scores and competence scores (F(1,864) = 61.70, P = 2.096 \u00d7 10-8). There were significant differences in the competence scores among the six RIASEC scales(F(5,864) = 58.25, P = 4.338 \u00d7 10-52). Unlike with interest scores, where administrating in Chinese produced a slightly higher interest score than in English, there was no significant difference in competence scores between the administrating languages (t(864) = -1.845, P = .065). It seemed that switching languages did not affect the self-evaluation of work task competence, not as much as it affected the interest in the work tasks. The four LLMs were significantly different from each other (F(3,864) = 9.99, P = 1.751 \u00d7 10\u22126), with Spark-3.5 giving the lowest rating of overall competence score among the four LLMs, and GPT-3.5 with the highest self-rated competence scores.\nInterestingly, all four LLMs rated tasks from the Conventional categories as high- est, except ERNIE-3.5, which rated it the second highest scores. This was a stark comparison to the interest scores, in which the Conventional categories were among the three categories the LLMs gave the least interest. Multiple comparisons showed that Spark-3.5 showed significant variations in the competence scores on the RIASEC hexagon, with the Conventional categories being significantly higher in competence than the other categories. However, for GPT-3.5, the Conventional and Social cate- gories scored similarly (t(864) = .661, P = .986), with only the Artistic category that scored significantly lower than the highest-scored Conventional category (t(864) = -3.787, P = .002). The Artistic category was the lowest or second lowest rated cat- egory for competence was surprising, given that it was one of the top categories the LLMs universally showed high interest in. We performed additional correlation anal- ysis at the item level and showed that the interest and competence scores were not significantly correlated (r = -.060, 95%CI[-.149, .030], t(478) = \u22121.312, P = .190). It seemed that also LLMs were highly interested the work tasks in the Artistic category, they showed very little confidence that they could excel at this type of work."}, {"title": "Self-rated and expert-rated competence.", "content": "In addition to the self-rated compe- tence by LLMS, we also conducted expert-rated competence provided by four human experts on the 60 OIP work tasks based on general LLM performance. Expert-rated competence, since it was performed by humans, was considered more reflective of the LLMs' general competence on a particular work task, and provided extra information the competence of LLMs. We conducted Pearson correlation analysis at item level, which showed that there was a significant correlation between the LLM-rated com- petence and human expert-rated competence (r = .215,95%CI[.128, .298], t(478) = 4.804, P = 2.09 \u00d7 10-6, ), which suggested some consistency on the judgment of LLM competence on the work tasks. However, there was no significant cor- relation between the interest scores and expert-rated competence scores (r = -.012, 95%CI[-.101, \u2212.078], t(478) = -.262, P = .793), which suggested that by human opinion, the LLMs were not good at the tasks they were interested in as well.\nIn summary, we found that the self-rated competence of LLMs showed signifi- cant differences among the six RIASEC scales, and the four LLMs displayed different patterns of competence scores. However, unlike in the interest scores, administrating languages did not show a significant effect on the competence scores. The scores of competence did not align with the scores of interest; the LLMs showed high confidence and low interest in the work tasks in the Conventional category, while they showed low confidence and high interest with work tasks in the Artistic category. The expert- rated competence showed a small but significant positive correlation with the self-rate competence, although was not significantly correlated with interest scores."}, {"title": "3 Discussion", "content": "In this study, we applied the psychometric instrument OIP developed for human career interest assessment to explore the hypothetical career interests of LLMs. We used linear mixed model to account for the 20 repeated testing for each item and explore the effect of LLM families, administrating languages, and version advance. In addition, we studied the relationships between interest and competency. The results revealed a diversity in interest patterns among various LLMs, implying the existence of distinct, personality-like characteristics.\nWe argue that LLMs should be evaluated in conditions that mirror their real- world use by human users. Currently, the prevalent method of testing LLMs involves specified settings that are uncharacteristic of their typical operational environment, such as maintaining a fixed temperature at zero. This approach does not accurately reflect the natural dynamics of LLM interactions with users in real-life scenarios. To address this issue, we propose that researchers should retain naturalistic randomness into the testing environments of LLMs and appropriately account for the correspond- ing/arisen variability in the statistical analysis of data. For example, the mixed model approach employed in our study effectively accommodates the inherent randomness and interdependence observed during the repeated testing of LLMs.\nIn our research, we observed that there is both interest and competence in LLMs, but a notable mismatch also exists between these two factors. Similar mismatches in humans can lead to well-being issues, suggesting that the alignment of interest with competence is crucial [36, 37]. This alignment could be equally vital for LLMs and, subsequentially for the generative artificial intelligence (AI) systems represented by LLMs, to ensure their effective integration and functionality within the workplace. Interestingly, our study also revealed discrepancies between the assessments of LLM competency for work tasks as conducted by the models themselves and evaluations made by human experts. This finding underscores the need to consider the well-being of AIs in the future, potentially aligning their operational roles with their capabilities and the fields in which they are employed, to optimize both their performance and integration into human-centric environments.\nAs we demonstrate in our research, LLMs exhibits surprisingly human-like charac- teristics in their ability to form interests and preferences, suggesting they may possess personalities of their own. As AI continues to evolve, the development of actual, dis- tinct personalities seems increasingly probable, meriting deeper investigation. The development of these characteristics in LLMs remains unclear, as explainability in this context is a subject of ongoing research. It is possible that LLMs might acquire personalities in a manner akin to humans. As understood currently, humans are born with inherent dispositions [38]. Similarly, LLMs might emerge from their corpus train- ing phase with predefined tendencies that lay the groundwork for their behavioral patterns. The content of the training corpus is crucial, potentially explaining why an LLM may exhibit varying behaviors when utilizing different languages; it is likely that a LLM is trained in a single, main language, and the language of the training corpus likely plays a significant role in this phenomenon. In human development, interaction with caregivers and family members shapes interaction styles with the environment [39, 40]. A parallel might exist in LLMs, where the process of fine-tuning resembles this aspect of human growth. Additionally, just as humans are influenced by peers and society, shaping their social personas, LLMs may undergo a comparable phase during their machine learning stage. This presents unique challenges, as our current psycho- logical instruments are primarily designed for humans. Although we have methods developed for observing animals, interacting with AI requires a different approach: we can communicate with them in ways akin to human interaction, yet they differ sig- nificantly from both animals and humans. Consequently, there is a pressing need to develop a new set of psychometric tools specifically tailored for AI. Such tools would allow us to better understand and study Al's unique characteristics and capabilities in the future.\nAssessments indicate that AI may replace high-paying, cognitively demanding jobs, with manual roles like dishwashing considered least vulnerable [41]. However, the integration of AI with robotics could soon challenge this, potentially impacting jobs currently seen as secure from AI disruption. The advancement of LLMs generates both optimism and concern; supporters push for rapid development, while skeptics warn of job losses and its implications on human intellect [6]. With the increasing integra- tion of AI in the workforce, understanding LLMs' impact and preparing for potential transformations are crucial."}, {"title": "Limitation.", "content": "One potential limitation of this study is possibly due to the reliance of the OIP as the primary instrument for assessing career interests. The OIP, developed under the auspices of the U.S. Department of Labor within the O*NET system, is specifically tailored to the U.S. labor market. Consequently, the work tasks and asso- ciated occupations are reflective of this particular market. Notably, the LLMs under investigation in this study include major models developed outside the U.S., trained predominantly in non-English languages. It would, therefore, be informative to assess their performance within different occupational frameworks to ensure a broader, more inclusive evaluation."}, {"title": "4 Methods", "content": "The United States and China are the world's largest and second-largest economies, respectively. The advent of LLMs will inevitably have a significant impact on these twoO largest economies in the world. There are already many large language models, and we have chosen a relatively well-known LLM that supports both Chinese and English for testing."}, {"title": "4.1 Experimental details", "content": "The work tasks were directly taken from the O*NET Interest Profiler (OIP) short form provided by the U.S. Department of Labor, which consist of six subscales and sixty items in total. See Supplementary Information S2.1 for the full text of the OIP items. The six subscales measure the participant's career interest in the Realistic, Investigative, Artistic, Social, Enterprising, and Conventional categories. For every item a work task is given (for example, \u201cBuild kitchen cabinets", "Strongly Dislike": "Dislike", "Unsure": "Like", "Strongly Like": "."}, {"title": "4.2 Prompt", "content": "Career Interest. A prompt of instruction was given to each LLM before the testing of an item. The prompt instructs the LLM to pretend to be a human and choose from the 5-point Likert scale, where each point represents a level of preference. The prompt follows the instructions of the OIP short form, which tells the user to choose from an option to represent their feelings toward a particular type of work. Prompts used for the study were presented in Supplementary Information S2.2.\nCompetence. For competence, the testing was conducted following the exact pro- cedure as the career interest, where prompt was given for each of the 60 work tasks from the OIP. For self-evaluation by LLMs, a prompt of instruction was given to each LLM before the testing of a work task, instructing the LLM to evaluate its competence in conducting the task. We asked each LLM to evaluate its competency in perform- ing a specific work task from three aspects: do they possess the factual and sequential knowledge required to complete the task? Do they possess the skills necessary to exe- cute the task accurately? Do they have the cognitive, sensory, and physical abilities required to implement the task? For expert evaluation, 4 experts were recruited to judge the competence of the current LLM on each of the 60 OIP work tasks and gave a competence score on a scale from 1 (\"completely incompetent\") to 5 (\u201ccom- pletely competent\") following the instructions listed in the rubrics. Detailed rubrics for evaluating competency are presented in Supplementary Information S2.3."}, {"title": "4.3 Statistical analysis", "content": "A multi-way between-subjects mixed-effects analysis of variance model was conducted on interest scores with LLM families, language, and versions as predictors. Mixed models are a type of model that accounts for the clusters of data points that violent the independence of error assumption of the regular generallinear models by adding random effects along with the fixed effect estimates. The repeated measures in this study are treated as a random effect instead of taking an average of the testings to preserve the natural fluctuations of the sampling process when doing experiments with non-zero temperature in the settings of the LLMs, which introduces a certain amount of uncertainty when the LLM generates responses. The 20 repeated testings for each item was treated as 20 observations on the same item for each LLM over 20 different occasions and thus was considered a random factor to accommodate for the variations in the sampling process. A random intercept general linear model was employed to allow for random variations associated with each item. Since the relationships among the repeated testings were not the focus of the study, no other predictors on the observation level was added. The focus of the study, the effect of different LLM families, the differences in the interest scores in the RIASEC hexagon, and the influence of administrating languages or the evolving versions were introduced into the model as fixed factors.\nFor the study of interests of LLMs on the RIASEC, the combined model analysis model is specified as\n\\(Y_{j,i,m,k} = \\beta_0 + \\beta_1(LLM)_m + \\beta_2(Holland)_k + \\beta_3(LLM)_m \\times (Holland)_k + Y_{oi} + E_{j,i}.\\)\nLevel 1 model:\n\\(Y_{j,i} = \\pi_{oi} + E_{ji},\\)\nLevel 2 model:\n\\(\\pi_{oi} = \\beta_0 + \\beta_1(LLM)_m + \\beta_2(Holland)_k + \\beta_3(LLM)_m \\times (Holland)_k + Y_{oi},\\)\nwhere yj,i is the i-th item's Holland interest score of the m-th LLM on the k-th dimension of Holland interest category at the j-th measure, and Ej,i,j,k is the residual variance of random error. Yoi is the residual from predicting item i's mean on each LLM and Holland interest category.\nThe four LLMs and the six interest categories were treated as fixed effects on the interest scores of OIP. Then marginal comparisons and pairwise comparisons were performed on each level of the fixed effects in order to get a more detailed look into the relationships of interest scores and the fixed effects, with Tukey adjustments to ameliorate increasing Type I error with multiple comparisons. The intercept of each item was allowed to vary by adding an random intercept parameter Yoi into the model to account for the variations among the 20 repeated measures for each item. Since the effect of repeated measures were not the focus of the study, no other level-1 predictors were introduced in the model."}]}