{"title": "ResLearn: Transformer-based Residual Learning for Metaverse Network Traffic Prediction", "authors": ["Yoga Suhas Kuruba Manjunath", "Mathew Szymanowski", "Austin Wissborn", "Mushu Li", "Lian Zhao", "Xiao-Ping Zhang"], "abstract": "Our work proposes a comprehensive solution for predicting Metaverse network traffic, addressing the growing demand for intelligent resource management in eXtended Reality (XR) services. We first introduce a state-of-the-art testbed capturing a real-world dataset of virtual reality (VR), augmented reality (AR), and mixed reality (MR) traffic, made openly available for further research. To enhance prediction accuracy, we then propose a novel view-frame (VF) algorithm that accurately identifies video frames from traffic while ensuring privacy compliance, and we develop a Transformer-based progressive error-learning algorithm, referred to as ResLearn for Metaverse traffic prediction. ResLearn significantly improves time-series predictions by using fully connected neural networks to reduce errors, particularly during peak traffic, outperforming prior work by 99%. Our contributions offer Internet service providers (ISPs) robust tools for real-time network management to satisfy Quality of Service (QoS) and enhance user experience in the Metaverse.", "sections": [{"title": "I. INTRODUCTION", "content": "The Metaverse is a comprehensive ecosystem of interconnected virtual worlds that provide immersive experiences to users. The ecosystem enhances existing and generates new value from economic, environmental, social, and cultural perspectives [1]. Services in the Metaverse ecosystem are designed to be accessed using immersive extended reality (XR) environments. XR is an umbrella term that describes the technologies affecting the user's immersive experience, such as virtual reality (VR), augmented reality (AR), and mixed reality (MR) [2]. VR allows users to interact with virtually generated environments designed to simulate real-world experiences. AR overlays interactive, virtually generated information onto real-world objects or within real-world spaces. XR technologies lie on a spectrum between AR and VR. In cases where the distinction between the realities is ambiguous, the experience is considered MR. As the Metaverse's growth continues and XR evolves, the popularity of its services increases. Driven by the rapid growth of the Metaverse, Internet traffic is expected to surpass current forecasts significantly [3]. The entertainment and social media industries have seen the most substantial growth of Metaverse services, as evidenced by popular virtual performance events, one of which attracted an audience of 36 million users [4], [5]. Healthcare, training, and marketing for Metaverse services have also grown recently [6], [7]. Cloud rendering for Metaverse is crucial to offloading computing resources to make the services affordable, a popular technique for VR games [8]. Consequently, the Ericsson 2022 report emphasizes the growing need for more intelligent interactions between XR services and the network to maintain high Quality of Service (QoS) [3]. Therefore, network management is crucial for Internet service providers (ISPs) to accommodate adequate resources and avoid cybersickness among users [9]-[11].\nMetaverse traffic consists of video, audio, and control flows [8], among all downlink video frames are resource-demanding in the case of VR, and both uplink/downlink video frames for AR and MR traffic. Therefore, predicting the frame size is vital, and for latency-related issues, it is essential to predict frame inter-arrival time and frame duration [12]. Predicting frame size, inter-arrival time, and frame duration will help ISPS prepare and manage the Metaverse network for holistic and intelligent traffic management. However, there needs to be more real-world Metaverse data and research in prediction to make progress in the field. Essentially, frame-related information is time series data. The recent advent of different state-of-the-art artificial intelligence (AI) based time series models has shown tremendous progress in time series predictions [13]. The only VR frame size prediction work is available at [14]; therefore, we consider it state-of-the-art (SoA) work for benchmark comparison. The work studies different AI models to predict VR frame size. It establishes stacked LSTM to produce better results based on transfer learning methodologies. Therefore, the solution aims for online prediction, imperative for real-time network management. However, the work is evaluated on a small dataset captured in a controlled environment. Also, the performance can be improved with further reduction in the error. The frame identification methodology used in the work might need to be revised because the frame loss for 120 Mbps is more than 54 Mbps since the dataset is captured in a controlled environment. Our literature review identifies the"}, {"title": "II. SYSTEM MODEL", "content": "The system model, in Figure 1 illustrates the proposed framework for predicting Metaverse network traffic, focusing on frame-level features. The process begins with data preprocessing, where the VF algorithm is applied to extract relevant frame-related data. The key features extracted from the incoming traffic include frame count (f\u00ba), frame size (f\u00b0), and frame inter-arrival time (IAT) (fiat). Our VF algorithm works on application-level features: time, packet length, packet direction, and packet inter-arrival time. Frame-related packets have a more considerable length with relatively more minor inter-arrival time. We use this property to determine the thresholds for packet length and inter-arrival time to identify frame-related packets as shown in Figure 2. In Figure 2, len\u0442\u043d is determined as 25% of the maximum length of the observed packet length. durth is the frame duration threshold determined between the first two peaks. The first peak represents the start of the video frame packet with less inter-arrival time, and the second peak represents the end of the video frame"}, {"title": "III. RESLEARN: TRANSFORMER-BASED RESIDUAL LEARNING FOR METAVERSE NETWORK TRAFFIC PREDICTION", "content": "The residual Learning (ResLearn) algorithm is a two-step prediction approach involving a transformer deep neural network model [16] designed to enhance Metaverse network traffic forecasting by leveraging residual learning inspired by ResNet [20]. Transformer is known for learning short and long-term dependencies from time series data. However, the prediction error is inevitable due to the randomness introduced by network health and users in Metaverse infrastructure. However, we can learn the nature of error using a neural network. ResLearn is a novel approach that uses a Transformer in the first step, given as $F_1(.)$, the predictive Transformer model. The residual from the $F_1(\\cdot)$ is fed to a fully connected neural network (FCNN) to learn the nature of the error, given as $F_2(.)$. The final prediction model from Eq. (1) is given as $\\psi(\\cdot) = F_1(\\cdot) + F_2(.)$.\nFigure 3 illustrates the workflow of the ResLearn algorithm. The input data is split into training ($y_{train}$) and validation ($y_{val}$) sets. The first model, including a transformer network, processes the training data and generates an initial prediction result ($y_{train\\_pred}$). This output, called Output 1, is then compared to the actual training data to calculate the residuals, which capture the difference between the predicted and true values. These residuals are passed to the second model, an FCNN designed to learn and predict the patterns in the residuals, producing a corrected prediction ($res_{pred}$). Both predictions from the transformer and FCNN are combined to form the final output ($y_{out}$) of the ResLearn model. This combined output is then validated with the unseen validation data, improving the final prediction's overall accuracy. The ResLearn training algorithm is shown in Algorithm 1. SN is a time-series data segment, where N is the segment size and X is the number of segments. For each segment, the data is split into training and validation sets. The transformer model is trained on the training set, and its predictions, TPR, are computed. The residuals, representing the error between the actual and predicted values, are calculated and adjusted by adding a bias, ResB, to highlight essential peaks. The dense model is then trained on these residuals, and the final ResLearn model, MRL, is created by combining the outputs of both models. The combined model is then evaluated on the validation set using error metrics. The process is repeated for each segment, refining the prediction accuracy iteratively until the validation error is stabilized for MRL. The algorithm's output is the final ResLearn model MRL, which integrates the strengths of both models to deliver improved predictive performance.\nThe time complexity of the ResLearn algorithm, which involves training a transformer model and a FCNN, can be approximated as follows: the training complexity of the transformer model is typically $O(T\\cdot N^2)$, where T is the number of training epochs and N is the sequence length. The training complexity of the FCNN can be approximated as $O(T' \\cdot N\\cdot D)$, where T' is the number of epochs, D is the number of neurons in the hidden layer, and N represents the number of training samples [21]. Considering X segments of data, the overall time complexity of the algorithm is given by $O(X \\cdot (T \\cdot N^2 + T' \\cdot N \\cdot D))$."}, {"title": "IV. EXPERIMENTATION SETUP AND RESULTS", "content": "The experiments are designed to evaluate the performance of various VR, AR, and MR services across three datasets, as shown in Table I. The Dataset I [15] (in-house dataset) focuses on diverse services, including gaming, video streaming, and communication (chat/VoIP), and is tested with applications such as Dirt Rally 2.0, Bigscreen, VR Chat, Solar System, and Reality Mixer. Figure 4 shows the testbed used in the data capture. In the testbed, a virtual desktop streamer (VDS) rendering platform is used for the setup. A cloud computer with a VDS server is a rendering device to which the VDS client on the Oculus Quest 2 is connected. Traffic manager is used to simulate low latency networks to replicate real-world scenarios. Traffic is captured on the cloud computer using Wireshark. More details and packet captures (pcap) are available at [15]. Dataset II [8] examines slow and fast VR traffic using Steam VR Home and Beat Saber to study the impact of different traffic patterns. Dataset III [22] involves two experiments: the first explores fast and slow VR traffic across Beat Saber, Medal of Honor, Forklift Simulator, and Cooking Simulator, while the second focuses on a subset of applications (Forklift Simulator, Cooking Simulator, Beat Saber, and Medal of Honor) to assess network performance under varying traffic conditions further. We use 50% of data for training, in which 20% of the data is used for validation. Another 50% of the data is used for testing. The solution is developed in Python using data science libraries such as Scikit-learn (Sklearn), NumPy, and Pandas. The implementation is available at [17]. The experiments are conducted on a Windows system with an Nvidia RTX2800S GPU. The Windows environment is set up with Anaconda to support machine learning libraries, including TensorFlow.\nThe analysis of data predictability begins with an exploratory data analysis (EDA) that suggests randomness, shown in Figure 5 depicted by blue line, in the network traffic data. Runs test is a statistical procedure which determines whether a sequence of data within a given distribution have been derived with a random process or not [23]. Runs test of the raw data provides a p-value of 0.15, which indicates no significant evidence against the null hypothesis of randomness. However, a deeper examination using decomposition techniques reveals underlying patterns in the time series, breaking it down into trend, seasonal, and residual components. This is further reinforced by applying a rolling window average (with a window size of 20), where the rolling mean (depicted by the red line in Figure 5) closely follows the shape of the data, revealing a clear trend. The corresponding Runs test, now with a p-value close to zero, confirms that the data is predictable and not random. Rolling statistics effectively uncovers this structure, making the data suitable for forecasting models."}, {"title": "B. Performancce Metrics", "content": "The performance of Metaverse network traffic prediction models can be evaluated using the following metrics: RMSE (Root Mean Squared Error), MAPE (Mean Absolute Percentage Error), and SMAPE (Symmetric Mean Absolute Percentage Error). These metrics quantify the differences between predicted and actual traffic values, aiding in assessing the model's accuracy. The RMSE measures the square root of the average squared differences between predicted and actual values, emphasizing more significant errors, and is given by:\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n}(y_i-\\hat{y_i})^2}$,\nwhere $\\hat{y_i}$ represents the predicted value, $y_i$ is the actual value, and n is the number of predictions. The MAPE is used to compute the average percentage error, offering an intuitive interpretation of prediction errors, and is formulated as:\n$MAPE = \\frac{100\\%}{n} \\sum_{i=1}^{n} \\left|\\frac{y_i - \\hat{y_i}}{y_i}\\right|$\nLastly, SMAPE provides a symmetric approach to percentage error by accounting for both over- and under-predictions. It is computed as:\n$SMAPE = \\frac{1}{n}\\sum_{i=1}^{n} \\frac{2\\left| y_i - \\hat{y_i} \\right|}{(\\left|y_i\\right| + \\left|\\hat{y_i}\\right|)/2}$"}, {"title": "C. Performance Evaluation", "content": "The Tables II III, IV, & V present the performance evaluation of various models (Transformer, LSTM, GRU, and Stacked LSTM) across three datasets, with metrics such as RMSE, MAPE, and SMAPE. Table II shows the performance for frame size (Dataset I), Table III for frame count (Dataset II), Table IV for frame IAT (Dataset III, exp 1), and Table V for frame size (Dataset III, exp2). Each table compares the models' non-residual version (where residuals are not learned) with the residual learning approach, the ResLearn algorithm. In each case, SMAPE improvement is calculated, highlighting the percentage improvement in predictive accuracy when residual learning is applied.\nThe results indicate that the ResLearn algorithm significantly improves performance across all models and datasets, especially regarding SMAPE. For example, the transformer model in Table II achieves a SMAPE reduction from 0.78 to 0.24 (68.87% improvement), and a similar trend is observed in Tables III and IV, where the transformer and Stacked LSTM models show substantial SMAPE improvements of over 70%. The observation is similar to Dataset III exp 2; however, GRU is better than the transformer. This demonstrates that residual learning can enhance the accuracy of time series models, particularly for the transformer architecture, making it the most effective among the evaluated models across all datasets."}, {"title": "D. Performance Comparision and Discussion", "content": "The comparison of SMAPE between the SoA transfer learning model [14] and the proposed ResLearn solution (Table VI) demonstrates a significant performance improvement in favour of ResLearn. In various traffic conditions, as considered in [14], such as BeatSaber and Steam VR house at different Mbps rates, ResLearn consistently achieves a near-perfect reduction"}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "Our work significantly advances Metaverse network traffic prediction by introducing a comprehensive, real-world dataset and developing novel algorithms including the view-frame and ResLearn algorithms. These algorithms enable ISPs to manage network resources in an effective manner, satisfying the QoS and enhancing the user experience for Metaverse applications. Given that our solution substantially reduces prediction errors about 99% than the SoA [14], future work can focus on expanding the dataset to cover a broader range of Metaverse applications and environments, integrating advanced AI techniques to improve prediction accuracy further, and exploring real-time deployment in diverse network architectures. Additionally, adaptive algorithms for dynamic resource allocation in response to traffic fluctuations will be investigated for enhancing the robustness in provisioning Metaverse ecosystem."}]}