{"title": "Integrating Semi-Supervised and Active Learning for Semantic Segmentation", "authors": ["Wanli Ma", "Oktay Karakus", "Paul L. Rosin"], "abstract": "In this paper, we propose a novel active learning approach integrated with an improved semi-supervised learning framework to reduce the cost of manual annotation and enhance model performance. Our proposed approach effectively leverages both the labelled data selected through active learning and the unlabelled data excluded from the selection process. The proposed active learning approach pinpoints areas where the pseudo-labels are likely to be inaccurate. Then, an automatic and efficient pseudo-label auto-refinement (PLAR) module is proposed to correct pixels with potentially erroneous pseudo-labels by comparing their feature representations with those of labelled regions. This approach operates without increasing the labelling budget and is based on the cluster assumption, which states that pixels belonging to the same class should exhibit similar representations in feature space. Furthermore, manual labelling is only applied to the most difficult and uncertain areas in unlabelled data, where insufficient information prevents the PLAR module from making a decision. We evaluated the proposed hybrid semi-supervised active learning framework on two benchmark datasets, one from natural and the other from remote sensing imagery domains. In both cases, it outperformed state-of-the-art methods in the semantic segmentation task.", "sections": [{"title": "1. Introduction", "content": "Supervised deep learning has become the dominant technique in computer vision, with deep convolutional neural networks achieving significant success in semantic segmentation (Long et al., 2015; Badrinarayanan et al., 2017; Ronneberger et al., 2015; Zhao et al., 2017; Chen et al., 2017). More importantly, from a data perspective, these deep learning networks strongly rely on having as much high-quality labelled training data as possible to achieve considerable performance. Nevertheless, creating a pixel-wise semantic segmentation dataset for supervised learning is often extremely time-consuming, labour-intensive and expensive, especially for some particular areas such as medical and large-scale remote sensing imagery segmentation tasks (Ching et al., 2018; Yue et al., 2022). Thus, efficiently training segmentation networks with minimal supervision, using a reduced amount of labelled data, is valuable and essential.\nSemi-supervised learning (SSL) is a common approach that generally leverages a small amount of labelled data alongside a large pool of unlabelled data, efficiently reducing the cost of labelling while enhancing training effectiveness. In the literature, most of the semi-supervised semantic segmentation approaches such as in (Hu et al., 2021; Wang et al., 2022; Xu et al., 2022) primarily focus on different strategies to address the question: \"how can unlabelled data be efficiently used during training?\". This question is independent of the selection of labelled samples, making active learning and SSL complementary to one another. Integrating these approaches can enhance data utilisation and make labelling more cost-effective, resulting in greater efficiency in network training with a limited labelling budget.\nActive learning seeks to identify and select the most informative and valuable samples for labelling, enabling the training of a deep learning network with a reduced amount of ground truth data while still achieving high performance. However, most active learning solutions concentrate exclusively on using samples/regions selected from the unlabelled data pool for training, neglecting to benefit from the unselected unlabelled data. Even less valuable samples can still provide useful information for supervising purposes, including in an unsupervised learning manner, through methods that explore their pseudo-labels.\nTo further reduce annotation effort, we argue that commonly used active learning methods are, however, suboptimal. In particular, they require the labelling budget to be gradually allocated to manually annotating each selected training sample during the training loop, depending on its potential to enhance network performance. Considering the assumption in (Chapelle et al., 2009), data points that are close to one another in the feature space are more likely to share similar characteristics or belong to the same class or category. Keeping this in mind, we propose an automatic and efficient labelling mechanism, called pseudo-label auto-refinement, for annotating the samples or areas selected by active learning. This pixel-wise labelling can also be viewed as a correction step for pseudo-labels. Specifically, in the feature space, if the features of unlabelled data fall within high-density regions of labelled training points, we can assign labels to these unlabelled points by referencing the annotations of the labelled data within the same image, as illustrated in Figure 1. This proposed procedure helps conserve the manual labelling budget by reserving manual labelling exclusively for the most challenging and uncertain unlabelled data. By concentrating human expertise where automated processes struggle to make confident decisions, we maximize efficiency and enhance the overall quality of the training data while preserving resources.\nSpecifically, this work makes the following key contributions:\n\u2022 We propose a novel SSL framework called Teacher-Student-Friend (TSF), which combines and exploits the capabilities of the student-teacher SSL framework with cross-pseudo supervision (CPS).\n\u2022 We introduce an effective combination of active learning and SSL for semantic segmentation applications that efficiently make use of unlabelled data.\n\u2022 We propose an active learning strategy for pseudo-label refinement that explores feature similarity between unlabelled regions and labelled areas within a single image. By using Euclidean and Mahalanobis distances for this process, our approach ensures reliable estimated labels for training and significantly lowers the labelling costs associated with active learning.\n\u2022 We develop a reliable module for active learning procedures that enhances the identification of the most informative unlabelled data for pixel-wise labelling. This module takes into account not only the probability map of the predictions but also examines multi-level feature representations of the unlabelled data samples."}, {"title": "2. Related Work", "content": "In the literature, active learning mainly focuses on proposing methodologies to measure the importance of each unlabelled sample for training to be manually annotated, thereby aiding the training process of deep learning networks. The literature mostly defines the importance based on either uncertainty (Yoo & Kweon, 2019; Xie et al., 2020; Gorriz et al.,"}, {"title": "2.1. Semi-supervised semantic segmentation", "content": "In the field of semi-supervised learning, consistency regularization is widely explored and primarily aims to enforce neural networks to produce consistent predictions by incorporating various types of perturbations. The strategies for the said perturbations can be categorised into input (French et al., 2019; Olsson et al., 2021; Zou et al., 2020), feature (Ouali et al., 2020), network (Chen et al., 2021) and hybrid. Specifically, the Mean Teacher (MT) (Tarvainen & Valpola, 2017) and Cross Pseudo Supervision (CPS)(Chen et al., 2021) are two well-known fundamental consistency learning frameworks. The former \u2013 MT \u2013 employs a teacher model whose parameters are the exponential moving average (EMA) of a student model's parameters. A few variations of this approach can be found in (Xu et al., 2022; Hu et al., 2021). AEL (Hu et al., 2021) introduces an adaptive CutMix and sampling strategy for unlabelled data, designed to enhance learning for underperforming classes based on the evaluation of the current model. U2PL (Wang et al., 2022) leverages not only highly confident predictions for unlabelled data as pseudo-labels for training the networks but also utilizes ambiguous predictions as negative samples, helping the network learn by contrasting them with the corresponding positive samples. Dual Student (Ke et al., 2019) argued that the EMA-based Teacher-Student leads to a performance bottleneck due to the tight coupling between the two roles, with this interdependence intensifying as training progresses. On the other hand, the latter \u2013 CPS \u2013 leverages unlabelled data different from the Teacher-Student structures by enforcing consistency between two models with the same architecture but different initialization. Some other hybrid SSL approaches include ST++ (Yang et al., 2022), ReCo (Liu et al., 2021), and S4AL+ (Rangnekar et al., 2022) integrating self-training, contrast or representation learning.\nWe would like to highlight that the proposed STF framework differs from Dual Student by integrating CPS with the EMA-based Teacher-Student. CPS, introduced after Dual Student, uses pseudo-labels rather than a consistency constraint, effectively expanding the training data. This combination leverages the strengths of both training structures and aims to overcome the performance limitations of using either the Teacher-Student or CPS method alone. Refer to Section 3.1 for details."}, {"title": "2.2. Active learning", "content": "In the literature, active learning mainly focuses on proposing methodologies to measure the importance of each unlabelled sample for training to be manually annotated, thereby aiding the training process of deep learning networks. The literature mostly defines the importance based on either uncertainty (Yoo & Kweon, 2019; Xie et al., 2020; Gorriz et al.,"}, {"title": "3. The Proposed Method", "content": "The proposed method integrates an improvement SSL framework with a novel active learning strategy to enhance the quality of pseudo-labels. For the proposed active learning usage, we introduce an error mask decoder (EMD) to detect potential errors in the pseudo-labels, and a pseudo-label auto-refinement (PLAR) module to correct these errors. The remaining errors that the PLAR cannot address are corrected through manual labelling."}, {"title": "3.1. The Teacher-Student-Friend (TSF) Structure", "content": "In semi-supervised learning (SSL), both Teacher-Student networks and Cross Pseudo Supervision (CPS) have gained popularity for leveraging labelled and unlabelled data to improve model performance. Despite their successes, these approaches also have certain limitations. In the Teacher-Student framework, the student only learns from the teacher's predictions, which can lead to an issue of over-dependence on the teacher model's performance, potentially limiting the framework's effectiveness in scenarios with highly noisy data. On the other hand, in the CPS structure, as training progresses, the two models tend to become very similar in terms of their parameters. This consequently means the models can no longer benefit from the parallel network structure since they start learning in the same way. To further provide a solution for the aforementioned problem, we propose incorporating an additional \"friend\" model into the Teacher-Student framework, called TSF as shown in Figure 2 to ensure the student model learns from different sources. Particularly, in the TSF structure, both the friend and student models are trained using the CPS approach, but the friend model is not supervised by the teacher.\nSpecifically, the three models have the same architecture but with different weights. The weights in the teacher model are updated using the exponential moving average (EMA) from the student model, while the weights in the student and friend models are updated based on training loss. Based on a teacher-student SSL framework of AEL (Hu et al., 2021), for labelled data we employ adaptive copy-paste, while unlabelled data use adaptive CutMix. Given both a labelled dataset $A = \\{(x_i, Y_i)\\}_{i=1}^M$ containing M images and an unlabelled data set $B = \\{z_i\\}_{i=1}^N$ with N images, the proposed SSL approach expects to obtain a trained model Q leveraging these labelled and unlabelled data. When working with labelled data, the supervised loss $L_{sup,s}$ between the sth ground truth $y_s$ and its corresponding prediction $p_s$ is defined by using the standard cross-entropy loss function $l_{ce}$:\n$L_{sup,s} = \\frac{1}{W \\times H} \\sum_{i=1}^{W \\times H} l_{ce}(P_{i,s}, Y_{i,s}),$ (1)\nwhere W and H refer to the width and height of input images. Both the student and friend models are supervised using the same type of supervised loss function, $L_{sup,s}$.\nFollowing (Sohn et al., 2020; Hu et al., 2021), the teacher network generates pseudo-labels $\\hat{y}$ on the uth unlabelled image to supervise the student model. The pseudo-labels are improved through an active learning module, called PLAR. The student unsupervised loss $L_{unsup,u}$ from teacher-student framework is defined as:\n$L_{unsup, u} = \\frac{1}{W \\times H} \\sum_{i=1}^{W \\times H} l_{ce}(\\hat{y}, r_{i u}),$ (2)"}, {"title": "3.2. PLAR-based Active Learning", "content": "Unlike general active learning, which selects informative un-labelled images for manual labelling during training loops, the proposed active learning strategy assists semi-supervised learning by correcting erroneous areas in pseudo-labels, as illustrated in Figure 2. The quality of pseudo-labels in semi-supervised learning is always crucial but often cannot be guaranteed. In this study, pseudo-labels are generated by applying the arg max() function to the predicted probabilities output from the teacher model. PLAR includes an error mask decoder that identifies erroneous areas in pseudo-labels, detailed in Section 3.2.1. Since using manual labels to correct all error areas in pseudo-labels is not cost-effective, we propose an automatic labelling module, PLAR, detailed in Section 3.2.2.\nThe proposed approach aims to correct parts of potential erroneous areas in pseudo-labels based on the similarity between the potential erroneous regions and the labelled areas in feature space. This process does not require manual labelling, thus preserving the labelling budget while improving the quality of pseudo-labels to enhance the training process. Manual labelling is reserved exclusively for the most challenging and uncertain unlabelled data. The hybrid labelling strategy efficiently reduces the budget of manual labelling in active learning. Rather than relying solely on a subset of unlabelled data selected by traditional active learning methods for manual labelling, this approach utilizes all unlabelled data with improved pseudo-labels."}, {"title": "3.2.1. ERROR MASK DECODER (EMD)", "content": "Since the widely used confidence-based error map, derived from applying a threshold to model predictions, mainly targets object edges, it may not adequately cover all erroneous areas. We proposed EMD as a part of the proposed PLAR active learning structure with the goal of predicting the error map of pseudo-labels generated by the teacher model using the representation of unlabelled training data. It is a 3-layer convolutional neural network (CNN) with normalisation and activation layers. In order to obtain a rich representation of each training sample, we concatenate its feature map at multiple levels together with the predicted probability map, resulting in each image (and its pseudo-label) being represented by a 531-channel feature map. The feature map is input to the EMD model, and the output is the probability x of a binary error map for the pseudo-labels generated by the current teacher model. The EMD only uses labelled data for supervision, because the real error maps y can be generated by comparing the ground truth labels (segmentation labels) with the pseudo-labels (created by probability map)\nof the image. Thus, the loss $L_{EMD}$ for EMD supervision is defined by binary cross entropy:\n$L_{EMD} = - \\frac{1}{W \\times H} \\sum_{i=1}^{W \\times H} (y_i log x_i + (1 - y_i) log (1 - x_i)).$ (5)\nIn particular, EMD is used for predicting masks of potentially erroneous pixels in pseudo-labels for unlabelled data. To cover as many potentially erroneous areas as possible, the final error map also incorporates a commonly used confidence-based error map, applying a threshold of 0.7 for the predicted probability from the teacher model to generate the map. Specifically, the final error map combines the error map generated by EMD and confidence-based error map using the 'OR' operation.\nBased on the combined error mask, areas outside the mask (i.e. reliable areas) are used in a generally supervised way to supervise the student network according to Equation 2. The pseudo-labels within erroneous areas will be corrected and improved through a hybrid annotation. Based on the representation of the unlabelled image, some pseudo-labels in the error map are automatically corrected by using the PLAR, which does not consume the annotation budget. The remaining labels require manual labelling within an active learning loop."}, {"title": "3.2.2. PSEUDO-LABEL AUTO-REFINEMENT", "content": "In the active learning loop, rather than spending resources on manual labelling to correct pseudo-labels, the proposed pseudo-label auto-refinement attempts to determine whether the existing labels share similar feature characteristics with the new data (which needs to be labelled). This is based on the idea that pixels classified into the same class should exhibit similar representations in the feature space (cluster assumption). Thus, it is feasible to use these existing labels within the same image to correct the erroneous areas of pseudo-labels. The feature maps are extracted from the teacher model at two levels: one from the output of the Atrous Spatial Pyramid Pooling (ASPP) module and the other from the second-to-last layer of the decoder. We define them as $F_1$ and $F_2$. Figure 3 shows visualizations of feature maps corresponding to the pixels in the erroneous regions of pseudo-labels using T-SNE (Van der Maaten & Hinton, 2008).\nSpecifically, the pseudo-label is downsampled to match the length and width of its feature map. Thus, each pixel in a pseudo-label corresponds to a vector in the feature map. We assess the similarity between the features of pixels in the labelled areas and those in the erroneous areas of pseudo-labels using Euclidean and Mahalanobis distances (denoted E and M respectively). For feature map $F_1$, the feature vector of a labelled pixel is defined as $f_{li} \\in F_l$ and the feature vector corresponding to a pixel in the erroneous area of the pseudo-label (unlabelled) is denoted as $f_i \\in F$. The Euclidean distance $E_{1c}$ between $f_i$ and the mean vector $m$ of the set $F_{le}$ including all labelled feature vectors $f_{le}$ corresponding to class c is\n$E_{1c} = E(f_i,m) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n} (f_{li}-m_i)^2}$ (6)\nwhere n is the length of the vector, equal to the channel number of the feature map.\nSimilarly, for feature map $F_2$, we got Euclidean distance $E_{2c}$. Thus, the hybrid Euclidean distance $E_c$ corresponding to class c is donated as\n$E_c = \\lambda_1 E_{1c} + (1 - \\lambda_1) E_{2c},$ (7)\nwhere $\u03bb_1$ is a trade-off weight learnt from features by using a weight module shown in Figure 4. We compute the hybrid Euclidean distance $E_c$ for each class and identify the class corresponding to the smallest Euclidean distance value (across all classes), $E_{min}$. The class $C_E$ corresponding to $E_{min}$ is considered the potential label for the unlabelled pixel in the erroneous area.\nThe Mahalanobis distance $M_{1c}$ between the vector $f_i$ with the set $F_{le}$ containing all labelled feature vectors $f_{le}$ corresponding to class c is\n$M_{1c} = \\sqrt{(f_i - m)^T. C^{-1} . (f_i - m)},$ (8)\nwhere m is the vector of mean values of set $F_{le}$ and $C^{-1}$ is inverse covariance matrix of set $F_{lc}$\nSimilarly, for feature map $F_2$, we got Mahalanobis distance"}, {"title": "4. Experiments and Results", "content": "To assess the effectiveness of our methodology across applications, we tested it on two benchmark semantic segmentation datasets: (1) CityScapes (Cordts et al., 2016) and (2) ISPRS Vaihingen (Rottensteiner et al., 2012).\nThe CityScapes dataset, focused on urban street scenes, includes 2,675 training images, 300 for validation, and 500 for testing, with 19 classes after downsampling to 688 \u00d7 688 as in (Rangnekar et al., 2023; Xie et al., 2020; Hu et al., 2021; Wang et al., 2022). Our TSF framework is evaluated using the same semi-supervised setup as prior methods (Hu et al., 2021; Wang et al., 2022; Xu et al., 2022). The ISPRS Vaihingen dataset, used for land cover classification, includes three-band (NIR, red, green) images at 9cm resolution, DSM data, and six labelled classes. The dataset has 33 patches (average size 2494 \u00d7 2064), cropped to 512x512 without overlap, resulting in 233, 111, and 398 images for training, validation, and testing, respectively.\nWe implemented our methods using the PyTorch framework. To ensure a fair comparison, following (Hu et al., 2021; Wang et al., 2022), the TSF framework employs the same semantic segmentation network as other semi-supervised learning approaches, specifically DeepLabv3+. Also, it utilizes ResNet-101 as the backbone pretrained on ImageNet, while MobileNetv2 serves as the backbone for the active learning approach following (Rangnekar et al., 2023; Xie et al., 2020). We train all our networks with a batch size of two and apply the \"poly\" learning rate strategy and the initial learning rate is set to 0.001 and multiplied by $(1 - \\frac{iter}{max-iter})^{0.9}$ at each iteration."}, {"title": "4.2. SSL Structure Comparison", "content": "We evaluated the proposed TSF semi-supervised learning framework on the CityScapes dataset with a comparative study to the recent approaches of MT(Tarvainen & Valpola, 2017), CutMix(Yun et al., 2019), CCT(Ouali et al., 2020), GCT(Ke et al., 2020), CPS(Chen et al., 2021), AEL(Hu et al., 2021), PS-MT(Liu et al., 2022), U2PL(Wang et al., 2022), and UniMatch(Yang et al., 2023). We split the entire training dataset into 1/16, 1/8, 1/4, and 1/2 ratios, following the approach in (Hu et al., 2021; Wang et al., 2022)."}, {"title": "4.3. Results for the Proposed Hybrid Model", "content": "To the best of our knowledge, this is the first study to evaluate active learning approaches for semantic segmentation across both natural images and remote sensing imagery. The proposed methodology (referred to as 'Ours' in tables and figures), which combines the TSF framework with active learning strategies, was previously illustrated in Figure 2. We assessed its performance against leading active learning methods, including Core-Set (Sener & Savarese, 2017), VAAL (Sinha et al., 2019), QBC (Seung et al., 1992), and DEAL (Xie et al., 2020), across both datasets. The S4AL method (Rangnekar et al., 2023) was evaluated only on the CityScapes dataset, as the authors have not shared the code, making it unreproducible for other datasets."}, {"title": "4.3.1. RESULTS ON CITYSCAPES", "content": "Table 2 presents the performance analysis, showing the Intersection over Union (IoU) for each class and the mean IoU (mIoU) across all classes. The proposed method and S4AL utilize 16% of the pixel-wise labels and all unlabelled images, while the other methods use 40% of labelled training data from CityScapes. The proposed method achieves the highest overall mIoU of 65.90, outperforming all other methods, including those using 40% of the data. A detailed per-class analysis reveals that the proposed method achieves the highest IoU in several key classes: Building (89.05), Fence (48.46), Pole (44.58), Traffic Light (52.75), Traffic Sign (66.06), Vegetation (90.03), Sky (93.01), Side Walk (70.21), Rider (45.78), Car (91.67), Bus (70.98), Bicycle (67.36). Among the methods that utilize 40% of the labelled data, the mIoU performance is relatively similar, with"}, {"title": "4.3.2. RESULTS ON ISPRS VAIHINGEN", "content": "Table 3 presents a performance comparison of various leading methods on the land cover classification dataset, Vaihingen, evaluated using Intersection over Union (IoU) for each class and the mean IoU (mIoU). The proposed method demonstrates greater strength for the remote sensing dataset and achieves the highest mIoU of 61.47%, outperforming all other methods, despite utilizing only 24% of the labelled training data. For per-class IoU, the proposed method consistently outperforms the other methods across most individual classes. Notably, it achieves the highest IoU in several critical classes: Road (75.95%), Impervious Surfaces (81.78%), Low Vegetation (60.4%), Tree (72.25%), Car (51.12%), Clutter/Background (27.32%). Among the methods that utilize 40% of the labelled data, \u201cCore-Set\u201d and \u201cVAAL\u201d show competitive performances, with mIoU of 55.81% and 55.78%, respectively. However, they fall short of the performance achieved by the proposed method. This significant result underscores the effectiveness of our approach in leveraging a smaller proportion of labelled data while achieving superior segmentation accuracy."}, {"title": "5. Ablation Study", "content": "We conducted an ablation study on the Vaihingen dataset and provided the results in Table 4 for different combinations of the components of the proposed hybrid method. Prior to applying the proposed active learning process, only implementing the TSF semi-supervised learning method with randomly sampled 15% of labelled data, which serves as a practical starting percentage for labelled data (Sener & Savarese, 2017; Sinha et al., 2019; Seung et al., 1992; Xie et al., 2020), results in a mIoU of 53.91%. By incorporating active learning (AL), which identifies erroneous regions using a 0.7 threshold on the predicted probability map and increases the labelled data by 9% (bringing the total to 24%), a modest improvement of 1.66% was achieved, raising the mIoU to 55.57% The addition of the EMD module further enhances performance, providing a 0.61% improvement in mIoU, bringing the total to 56.18%. Notably, the proposed pseudo-label auto-refinement strategy significantly enhances performance, delivering a 5.82% mIoU increase, raising the total to 61.39%, compared to using only TSF with AL. Finally, by integrating all the proposed modules, the hybrid active SSL approach achieves high performance with a mIoU of 61.47% for the Vaihingen dataset."}, {"title": "6. Conclusion", "content": "In this paper, we introduce a hybrid approach integrating an improved SSL framework, TSF, and a proposed active learning strategy to refine the pseudo label and select the most valuable labelled data. The proposed method efficiently reduces the labelling budget, and achieves better performance for semantic segmentation compared to the state-of-the-art for both natural image and remote sensing datasets. Experimental results confirmed the high efficiency of the proposed SSL framework and active learning approach individually, highlighting this work's contributions to both areas. Although we have introduced the initial concept of exploring feature similarity for pseudo-label correction by combining Euclidean and Mahalanobis distances, this work does not study extensively on feature map selection in the latent space. Our future work will continue to explore feature selection strategies. The proposed PLAR module's potential limitation lies in its reduced effectiveness when handling highly class-imbalanced labels."}, {"title": "A. Qualitative Analysis", "content": "The results of pseudo-label correction are visualised in Figure 5. The improved pseudo-labels exhibit much greater accuracy in handling details than the original version, closely aligning with the ground truth. Furthermore, the improved pseudo-labels enhance the effectiveness of model training."}, {"title": "B. Justification for Selecting a 0.7 Threshold in Confidence-Based Error Map Generation", "content": "We demonstrated the Confidence-Based Error Map in Figure 6. The true error maps, obtained by comparing the ground truth with the pseudo labels, are also displayed at the end of each row. As the threshold increases, the error mask expands along the edges, similar to an erosion operation without revealing any previously undiscovered error regions.\nAlthough the error map with a 0.7 threshold covers fewer error regions compared to the true error map, the identified regions exhibit higher precision than maps with higher thresholds. To generate a more comprehensive and accurate error map, we combined the confidence-based error map with a 0.7 threshold and the error map predicted by the EMD using the 'OR' operation."}]}