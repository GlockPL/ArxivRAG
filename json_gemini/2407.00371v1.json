{"title": "Axiomatization of Gradient Smoothing in Neural Networks", "authors": ["Linjiang Zhou", "Xiaochuan Shi", "Chao Ma", "Zepeng Wang"], "abstract": "Gradients play a pivotal role in neural networks explanation. The inherent high dimensionality and structural complexity of neural networks result in the original gradients containing a significant amount of noise. While several approaches were proposed to reduce noise with smoothing, there is little discussion of the rationale behind smoothing gradients in neural networks. In this work, we proposed a gradient smooth theoretical framework for neural networks based on the function mollification and Monte Carlo integration. The framework intrinsically axiomatized gradient smoothing and reveals the rationale of existing methods. Furthermore, we provided an approach to design new smooth methods derived from the framework. By experimental measurement of several newly designed smooth methods, we demonstrated the research potential of our framework.", "sections": [{"title": "1 Introduction", "content": "Explanation for Artificial Intelligence (AI) is an inevitable part of AI applications with human interaction. For instance, explanation techniques are crucial in fields like medical image analysis Alvarez Melis and Jaakkola [2018], financial data analysis Zhou et al. [2023], and autonomous driving Abid et al. [2022], where AI is applied to these data-sensitive and decision-sensitive fields. Additionally, given the prevalence of personal data protection laws in most countries and regions of the world, fully black-box AI models often face intense legal scrutiny Doshi-Velez and Kim [2017].\nAfter the development in recent years, some explanation methods try to explain the decisions of neural networks by the visualization of the decision basis and depiction of feature importance Nauta et al. [2023]. These local explanation methods aim to provide an explanation of neural networks on an individual sample. Moreover, the interpretation process or algorithm of these methods often utilizes the gradient of the neural network. For instance, Grad-CAM Selvaraju et al. [2017], Grad-CAM++ Chattopadhay et al. [2018] and Score-CAM Wang et al. [2020a] produces class activation map using gradients, and Integrate-Gradient Sundararajan et al. [2017] calculates integral gradients via sampling from gradients.\nHowever, as noted in Smilkov et al. [2017] and Bykov et al. [2022], neural networks often have a significant amount of noise in their raw gradients due to their complex structure and high input dimensions. This noise might seriously impair"}, {"title": "2 Preliminary", "content": "In general, consider a neural network as a function \\(f(x; \\theta) : \\mathbb{R}^D \\rightarrow \\mathbb{R}^C\\), with the trainable parameters \\(\\theta\\). In the example of a classification function, the neural network will output a score for each class c, where c \\(\\in\\) {0,1,\u2026\u2026,C'}. When further considering only the output of the neural network in a single class c, the neural network can be simplified to a function \\(f^c(x; \\theta) : \\mathbb{R}^D \\rightarrow \\mathbb{R}\\), which maps the input \\( \\mathbb{R}^D \\) to the 1-dimension \\(\\mathbb{R}\\) space. For simplicity, we will use f(x) to represent the neural network and only consider the output of the neural network on a single class.\nThe gradient of f(x) could be presented as,\n\\(g(x) = \\frac{df(x)}{\\partial x}\\)\n(1)\nThe rationale for interpreting neural networks using original gradients, or using gradients multiplied by input values, is derived from Taylor's theorem. The first-order Taylor expansion on f(x) is given by,\n\\(f(x) = f(x_0) + [g(x_0)]^T (x - x_0) + R(x; x_0, \\theta)\\)\n(2)\nIf the residual term R(x;x0, \\theta) is assumed to be a locally stable constant value, the gradient g(x) could denote the contribution of each feature in x to final outputs. Considering the local surroundings of a sample, neural networks tend not to present an ideal linearity but rather have a very rough and nonlinear decision boundary. [Need a Figure to explain] This complexity of neural networks and the input features usually leads to the assumption not being valid. Thus, this is a possible explanation for the large amount of noise in the original gradient.\nRecently, methods for reducing gradient noise can be roughly categorized into the following two groups:\nAdding noise to reduce noise. SmoothGrad proposed by Smilkov et al. [2017] introduces stochasticity to smooth the noisy gradients. SmoothGrad averages the gradients of random samples in the neighborhood of the input x0. This could be described in,\n\\(sg(x) = \\frac{1}{N} \\sum_{i=1}^N g(x + \\epsilon)\\)\n(3)\nwhere the sample times is N, and \\(\\epsilon\\) is distributed as a Gaussian \\(\\mathcal{N}(0, \\sigma^2)\\) with standard deviation \\(\\sigma\\). Similarly to SmoothGrad, NoiseGrad and FusionGrad presented in Bykov et al. [2022] additionally add perturbations to model parameters. The NoiseGrad could be defined as follows,\n\\(ng(x) = \\frac{1}{M} \\sum_{i=1}^M g(x;\\theta\\cdot\\eta)\\)\n(4)\nwhere the sample times is M, and \\(\\eta\\) follows distribution \\(\\mathcal{N}(1, \\sigma^2)\\). And the FusionGrad is a mixup of NoiseGrad and SmoothGrad, which could be described in the same way,\n\\(fg(x) = \\frac{1}{MN} \\sum_{i=1}^M \\sum_{j=1}^N g(x + \\epsilon;\\theta\\cdot\\eta)\\)\n(5)\nThese simple methods are experimentally verified to be efficient and robust Dombrowski et al. [2019].\nImproving backpropagation to reduce noise. Deconvolution Zeiler and Fergus [2014] and Guided Backpropagation Springenberg et al. [2015] directly modifies the gradient computation algorithm of the ReLU function. Some other methods such as Feature Inversion Du et al. [2018], Layerwise Relevance Propagation Bach et al. [2015], DeepLift Shrikumar et al. [2017], Occlusion Ancona et al. [2017], Deep Taylor Montavon et al. [2017], etc. employ some additional features to approximate or improve the gradient for precise visualization.\nIn the rest of this paper, we will focus on constructing a theoretical framework to explain the rationale for adding noise to reduce noise."}, {"title": "3 Methodology", "content": "The Monte Carlo gradient smoothing formulation will be introduced in this section. In order to facilitate the understanding of the derivation of the formula, we present it in a bottom-up manner."}, {"title": "3.1 Convolution and Dirac Function", "content": "Convolution is an important functional operation. Referring to Bak et al. [2010], the convolution operation of function f and g could be defined as follows:\nDefinition 3.1. Let f and g be functions (generalized function). Symbol * is defined as the convolution operator. The f * g is defined by\n\\((f * g)(x) = \\int_{-\\infty}^{\\infty} f(t)g(x - t) dt\\)\n(6)\nObviously, we can derive some useful lemmas:\nLemma 3.2. If f * g exists,\n\\(f*g=g*f\\)\n(7)\nLemma 3.3. If f * g exists and f' and g' exist,\n\\((f * g)' = f' * g = f * g'\\)\n(8)\nLemma 3.4. If g is continuous, then f * g is continuous.\nThe Dirac function is a generalized function and describes the limit of a set called the Dirac function sequence. In general, the 1-dimensional dirac function in \\(\\mathbb{R}\\) is defined as follows:\nDefinition 3.5. The general definition of the Dirac function is,\n\\( \\delta(x) = \\begin{cases} +\\infty & \\text{if } x = 0 \\\\ 0 & \\text{if } x \\neq 0 \\end{cases} \\)\n(9)\nand it is constrained by,\n\\(\\int_{-\\infty}^{\\infty} \\delta(x) = 1\\)\n(10)\nThe Dirac function has some fundamental and important properties.\nLemma 3.6. If f * \\delta exists,\n\\(f* \\delta = f\\)\n(11)\nUsing lemma 3.6 and lemma 3.3, we could easily get,\nLemma 3.7. If f * \\delta exists and f' exist,\n\\((f * \\delta)' = f' * \\delta = \\delta * f' = f'\\)\n(12)\nlemma 3.6 and lemma 3.7 also apply to function f and Dirac functions \\(\\delta\\) in n-dimensions. All the proofs are in appendix A."}, {"title": "3.2 Function Mollification", "content": "Function mollification refers to the use of a mollifier to mollify the target function so that the mollified function becomes continuous or smooth.\nDefinition 3.8. A function \\(\\varphi(x) : \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) is a mollifier if it satisfies the following properties.\n1. \\(\\varphi(x)\\) is of compact support,\n2. \\( \\int_{\\mathbb{R}^n} \\varphi(x) dx = 1,\\)\n3. \\( \\lim_{\\epsilon \\to 0} \\varphi_{\\epsilon}(x) := \\lim_{\\epsilon \\to 0} \\epsilon^{-n} \\varphi(\\frac{x}{\\epsilon}) = \\delta(x)\\), where \\(\\delta(x)\\) is the Dirac function.\nThe 3rd property in definition 3.8 holds for almost all general functions consisting of primitive functions that satisfy the first two properties\u00b9.\nDefinition 3.9. The convolution with a mollifier is called mollification,\n\\(f_{\\epsilon} = f * \\varphi_{\\epsilon}\\)\n(13)\nThe details could be found in Stein and Weiss [1971] with Theorem 1.18."}, {"title": "3.3 Monte Carlo Gradient Mollification Formulation", "content": "Given the noisy gradients and decision boundaries in most deep neural networks, we aim to smooth the neural networks with mollification. As introduced in section 2, We simplify the neural networks into a function f(x). With a proper mollifier \\(\\varphi_{\\epsilon}(x)\\) given, we could use this mollifier to smooth the neural networks with mollification. Thus, by definition 3.9, we present the mollification of neural networks as,\n\\(f_{\\epsilon}(x) = (f * \\varphi_{\\epsilon})(x)\n= \\int_{\\mathbb{R}^n} f(x - t)\\varphi_{\\epsilon}(t) dt\n= \\int_{\\mathbb{R}^n} f(t)\\varphi_{\\epsilon}(x - t) dt\\)\n(15)\nAccordingly, by lemma 3.3, we could get the expression for the gradient of the smoothed neural network with mollification as,\n\\(g_{\\epsilon}(x) = (g * \\varphi_{\\epsilon})(x) = \\int_{\\mathbb{R}^n} g(x - t)\\varphi_{\\epsilon}(t) dt\\)\n(16)\nConsidering the computation complexity of the gradient, f(t) and g(t) are not easy to compute. So we chose to express g\\(\\epsilon\\)(x) in the form of eq. (16) instead of \\( \\int_{\\mathbb{R}^n} g(t)\\varphi_{\\epsilon}(x \u2013 t) dt\\). And importantly, it is almost impossible to solve the analytic expression for f\\(\\epsilon\\) in eq. (15) and g\\(\\epsilon\\)(x) in eq. (16). Therefore, g\\(\\epsilon\\)(x) could only be solved numerically.\nNote that g\\(\\epsilon\\)(x) is essentially an integral and x is a very high dimensional vector like 224 \u00d7 224 \u00d7 3 in some image classification tasks. Therefore, Monte Carlo integration is almost the only efficient method for solving this problem. Thus, we give the Monte Carlo Gradient Mollification Formulation as follows,\nTheorem 3.11. Given an instance x0 and a n-dimension random variable T obeying a distribution P with probability density function p(t), randomly sample T for N times to obtain a series of samples ti. the Monte Carlo approximation of g\\(\\epsilon\\)(x0) is presented as,\n\\(m g_{\\epsilon}(x_0) = \\frac{1}{N} \\sum_{i=1}^N \\frac{g(x_0 - t_i)\\varphi_{\\epsilon}(t_i)}{p(t_i)}\\)\n(17)\nIn theorem 3.11, m g\\(\\epsilon\\)(x0) is actually a statistic of the random variable T. We prove in the appendix B that this statistic is unbiased and consistent, which means that as \\( \\lim_{n \\to \\infty} m g_{\\epsilon}(x_0) = g_{\\epsilon}(x_0) \\)."}, {"title": "3.4 Axiomatization of Gradient Smoothing", "content": "The existing gradient smoothing methods, SmooothGrad, NoiseGrad, and FusionGrad, are introduced in section 2. Next, We aim to generalize these methods to theorem 3.11. That is, These methods are a special case of theorem 3.11, and they could all be derived from theorem 3.11.\nDerivation of SmoothGrad. In theorem 3.11, if \\(\\varphi\\) is the Probability Density Function (PDF) of a normal distribution, i.e. a Gaussian function, \\(\\varphi\\) satisfies all conditions in definition 3.8. So the Gaussian function is a reasonable mollifier. Next, set \\(\\varphi_{\\epsilon} = p\\), that is, the PDF of P is also \\(\\varphi_{\\epsilon}\\). So SmoothGrad could be described as,"}, {"title": "Remark 3.12. Given:", "content": "\\(\\varphi_{\\epsilon}(t) = \\frac{1}{\\sqrt{(2\\pi)^n \\epsilon^n}} exp {-\\frac{x^T x}{2\\epsilon^n}}\\\np = \\varphi_{\\epsilon}\n(18)\nIn theorem 3.11, T ~ p(t), i.e. T ~ \\(\\mathcal{N}(0, \\epsilon^2)\\),\n\\(m g_{\\epsilon}(x_0) = \\frac{1}{N} \\sum_{i=1}^N g(x_0-t_i).\\)\n(19)\nThus, m g\\(\\epsilon\\)(x0) = sg(x0) in eq. (3). SmoothGrad sg is a special case of mge with condition eq. (18).\nDerivation of NoiseGrad. With the same given condition of SmoothGrad, consider the parameter \\(\\theta\\) in neural networks as a smoothed target.\nRemark 3.13. Given:\n\\(\\varphi_{\\epsilon}(t) = \\frac{1}{\\sqrt{(2\\pi)^n \\epsilon^n \\theta}} exp {-\\frac{(x - \\theta)(x - \\theta)^T}{2\\epsilon^n}}\\\np = \\varphi_{\\epsilon}\n(20)\nThere we choose T = \\(\\theta\\) \u2212 \\(\\theta\\)X, X ~ \\(\\mathcal{N}(0, \\epsilon^2)\\), because this makes \\(\\theta\\) \u2212 T = \\(\\theta\\)X corresponding to \\(\\theta\\)\u00b7 \\(\\eta\\) in eq. (4). So, in theorem 3.11, T ~ p(t), i.e. T ~ \\(\\mathcal{N}(0,0^2\\epsilon^2)\\),\n\\(m g_{\\epsilon}(x_0) = \\frac{1}{N} \\sum_{i=1}^N g(x_0;\\theta + t_i).\\)\n(21)\nThus, m g\\(\\epsilon\\)(x0) = ng(x0) in eq. (3). NoiseGrad ng is a special case of mge with condition eq. (20).\nDerivation of FusionGrad. FusionGrad is a combination of SmoothGrad and NoiseGrad. It smooths the gradients with both input x0 and parameters \\(\\theta\\). So it is easy to derive FusionGrad from theorem 3.11.\nRemark 3.14. Given:\n\\(\\varphi_{\\epsilon}^{(x)}(t) = \\frac{1}{\\sqrt{(2\\pi)^n \\epsilon^n}} exp {-\\frac{(x - \\theta)(x - \\theta)^T}{2\\epsilon^n}}\\\np^{(x)} = \\varphi^{(x)}\\\n\\varphi_{\\epsilon}^{(\\theta)}(t) = \\frac{1}{\\sqrt{(2\\pi)^n \\epsilon^n \\theta}} exp {-\\frac{(x - \\theta)(x - \\theta)^T}{2\\epsilon^n}}\\\np^{(\\theta)} = \\varphi^{(\\theta)}\n(22)\nThere mark (x) and (\\(\\theta\\)) to distinguish the mollifiers for smoothing input x0 and \\(\\theta\\). As described in remark 3.12 and remark 3.13, we could get, in theorem 3.11, T(x) ~ p(x)(t(x)) and T(\\(\\theta\\)) ~ p(\\(\\theta\\)) (t(\\(\\theta\\))),\n\\(m g_{\\epsilon}(x_0) = \\frac{1}{N^{(\\theta)}} \\frac{1}{N^{(x)}} \\sum_{i^{(\\theta)}=1}^{N^{(\\theta)}} \\sum_{i^{(x)}=1}^{N^{(x)}} g(x_0 + t^{(x)}; \\theta + t^{(\\theta)}).\\)\n(23)\nThus, m g\\(\\epsilon\\)(x0) = fg(x0) in eq. (5). FusionGrad fg is a special case of mge with condition eq. (22)."}, {"title": "4 Implications", "content": "In this section, we will further discuss the implication of theorem 3.11. And since our study has uncovered a potentially infinite number of possible gradient smoothing methods, we expect to provide some useful guidelines for discovering potentially efficient gradient smoothing methods."}, {"title": "4.1 Explanation for Gradient Smoothing", "content": "The theorem 3.11 reveals that the rational of adding noise to reduce noise is a Monte Carlo approximation of mollification for neural networks."}, {"title": "4.2 Approximation to Dirac Function", "content": "A large number of kernel functions satisfy definition 3.8, but not all of them are capable of efficiently smoothing neural networks. Therefore, we explore some mathematical and computational constraints and provide a simple approach to construct a suitable kernel function. We apply this approach to provide four kernel functions in addition to the Gaussian kernel function.\nBased on some simple mathematical intuition Febrianto et al. [2021], Rohner [2019], the kernel function generally selected needs to satisfy the following conditions,\n\\begin{aligned}\\varphi(x) &> 0, \\text{ for } \\forall x \\in \\mathbb{R}, \\\\ \\varphi(x) &= \\varphi(-x), \\text{ for } \\forall x \\in \\mathbb{R}.\\end{aligned}\n(24)"}, {"title": "4.3 Hyperparameter Selection", "content": "In our proposed smooth framework, there are two hyperparameters N and \\(\\epsilon\\). From the perspective of Monte Carlo integration, the value of N should be large enough for mge to converge as much as possible. Combining the empirical values in Smilkov et al. [2017], Bykov et al. [2022], as shown in fig. 4, in practice SG has converged to a reasonable result at N = 50. Therefore, to balance performance and computation, we suggest that N is taken to be around 50, and for FG then N(\\(\\theta\\)) = M(x) = 50.\nWith the constraints mentioned in section 4.2, \\(\\epsilon\\) is set the same as p. Therefore, \\(\\epsilon\\) can be considered as a probability density function. This allows us to understand the selection of \\(\\epsilon\\) in a new sight, rather than on the basis of empirical values. Similar to confidence intervals and confidence levels, we expect that within a given interval [-r,r], an"}, {"title": "5 Experiment", "content": "In this section, we test the performance of these five kernel functions in different explainability metrics."}, {"title": "5.1 Experimental Settings", "content": "Metrics The employment of solitary metrics to gauge gradient-based methods is a contentious issue Nauta et al. [2023], and numerous current studies Hedstr\u00f6m et al. [2023], Yang et al. [2022], Liu et al. [2022], Han et al. [2022], Jiang et al. [2021] propose a plethora of evaluation metrics that even incorporate human evaluation. Nevertheless, we have chosen four properties to assess performance, as they align with the two fundamental objectives of model interpretation: reflecting model decisions Adebayo et al. [2020], Sixt et al. [2020], Crabbe et al. [2020], Fernando et al. [2019], Samek et al. [2016] and facilitating human understandingBarkan et al. [2023], Wu et al. [2022], Ibrahim and Shafiq [2022], Arras et al. [2022], Lu et al. [2021].\nConsistency - Consistency, first introduced in Adebayo et al. [2018], is primarily concerned with whether the XAI method is compatible with the model's learning capability.\nInvariance - Invariance, proposed in Kindermans et al. [2019], checks the XAI method to keep the output invariant in the case of constant data offsets in datasets with the same model architecture.\nLocalization - Localization, employed in Zhou et al. [2016], Selvaraju et al. [2017], Zhang et al. [2018], Wang et al. [2020a], Barkan et al. [2023], assesses the capability of the XAI method to accurately represent human-recognisable features in the input image.\nSparseness - Sparseness, applied in Chalasani et al. [2020], measures whether the feature maps output by the XAI method are distinguishable and identifiable.\nDatasets and Models To apply these metrics for quantitative evaluation, referring to the set up in Adebayo et al. [2018] and Kindermans et al. [2019], we chose MNIST LeCun and Cortes [2005] and CIFAR10 Krizhevsky et al. [2009] for experiments on Consistency and Invariance, and ILSVRC15 Russakovsky et al. [2015] with target detection labels for experiments on Localization and Sparseness.\nCorrespondingly, we constructed MLP and CNN models for the Consistency and Invariance experiments. To measure the performance of the kernel function on models of different parameter sizes, we selected pre-trained VGG16 Simonyan"}, {"title": "5.2 Results", "content": "Based on the hyperparameter settings outlined in section 4.3, we conducted experiments to test the performance of the five kernel functions. The aim of our study is not to identify a kernel function that completely outperforms existing methods but rather to explore the research potential of theorem 3.11 and the possibility of designing new methods. This could help researchers to design better smoothing methods for different models and datasets based on theorem 3.11.\nThe experimental results are summarised in table 1, showing the performance of 15 different smoothing methods for three smoothing modes and five combinations of kernel functions for different metrics. It could be observed that for Consistency and Invariance, the kernel functions Poisson and Rect perform better, while for Localization and Sparseness, the kernel functions Gaussian and Rect perform better. In general, we believe that Gaussian (which corresponds to existing methods like SmoothGrad), Poisson and Rect are convincing options for gradient smoothing. More qualitative and quantitative experimental results can be found in appendix F."}, {"title": "6 Conclusion", "content": "In this paper, we present a theoretical framework to explain the gradient smoothing approach. The existing gradient smoothing methods are axiomatized into a Monte Carlo smoothing formula, which reveals the mathematical nature of gradient smoothing and explains the rationale that enable these methods to remove gradient noise. Additionally, the theorem holds the potential for designing new smoothing methods. Therefore, we also suggest methods for designing smoothing approaches and propose several novel smoothing methods. Through experiments, we comprehensively measure the performance of these smoothing methods on different metrics and demonstrate the significant research potential of the theorem."}, {"title": "Limitations and Future work", "content": "Kernel function selection. The selection of the kernel function should be related to the model parameters and dataset, and how to select the appropriate kernel function should be further explored.\nAcceleration of Smooth Methods. We only explored the selection of mollifer and ignored the sampling distribution. However, computing the gradient for NG and FG is time-consuming. Therefore, selecting a suitable sampling distribution to accelerate the calculation is a potential research topic.\nCombination with other gradient-based methods. SmoothGrad has been used to enhance explanation performance in Smooth Grad-CAM++Omeiza et al. [2019], SS-CAMWang et al. [2020b], Smooth IGGoh et al. [2021], etc. So the integration of this theoretical framework with other explanation approaches could be further explored."}, {"title": "A Proofs in section 3.1", "content": "The mathematical concepts mentioned in section 3.1 are in the field of functional analysis Rudin [1987]. Thus for the convenience of readers to understand, we have provided all the proofs below.\nProof of lemma 3.2.\nProof. In definition 3.1,\n\\((f*g)(x) = \\int_{-\\infty}^{\\infty} f(t)g(x - t) dt\\)\n(31)\nand using substitution, let t = x - t'. So we could get,\n\\((f *g)(x) = \\int_{-\\infty}^{\\infty} -f(x - t')g(t')dt'\\)\n(32)\nNext, exchange the upper and lower limits of integrals to obtain,\n\\((f *g)(x) = - \\int_{-\\infty}^{\\infty} f(x - t')g(t')dt'\\)\n(33)\nIn the form, we finally get g * f. Thus, lemma 3.2 is proved.\nProof of lemma 3.3.\nProof. We compute the following\n\\begin{aligned}(f * g)'(x) &= \\lim_{\\Delta x \\rightarrow 0} \\frac{(f * g)(x + \\Delta x) \u2013 (f * g)(x)}{\\Delta x} \\\\&= \\lim_{\\Delta x \\rightarrow 0} \\frac{\\int_{-\\infty}^{\\infty} f(y)g(x + \\Delta x - y) dy \u2212 \\int_{-\\infty}^{\\infty} f(y)g(x - y) dy}{\\Delta x} \\\\&= \\lim_{\\Delta x \\rightarrow 0} \\int_{-\\infty}^{\\infty} f(y) \\frac{g(x + \\Delta x - y) - g(x - y)}{\\Delta x} dy\\\\&= \\int_{-\\infty}^{\\infty} f(y) \\left(\\lim_{\\Delta x \\rightarrow 0} \\frac{g(x + \\Delta x - y) - g(x - y)}{\\Delta x} \\right) dy\\\\&= \\int_{-\\infty}^{\\infty} f(y)g'(x - y)dy\\\\&= (f * g')(x)\\end{aligned}\n(34)\nNext, using lemma 3.2, we could get \\((f * g)' = f * g' = f' * g\\).\nProof of lemma 3.4\nProof. If g is continuous, and then for any convergent sequence {xm} \u2282 Rn, xm \u2192 x \u2208Rn,\n\\( \\lim_{m \\rightarrow \\infty} g(x_m) = g(x)\\)\n(35)\nThen, we could get\n\\begin{aligned}\\lim_{m \\rightarrow \\infty} (f * g)(x_m) &= \\lim_{m \\rightarrow \\infty} \\int_{\\mathbb{R}^n} f(y)g(x_m - y) dy\\\\&= \\int_{\\mathbb{R}^n} f(y) \\lim_{m \\rightarrow \\infty} g(x_m - y) dy\\\\&= \\int_{\\mathbb{R}^n} f(y)g(x - y) dy\\\\&= (f *g)(x)\\end{aligned}\n(36)\nAccording to the definition of continuous, f * g is continuous.\nProof of lemma 3.6."}, {"title": "Proof. Using the definition 3.5 and definition 3.1 we could get", "content": "\\(\\int_{-\\infty}^{\\infty} \\delta(y) f(x - y) dy = \\lim_{\\epsilon \\rightarrow 0} \\int_{-E}^{E} \\delta_{\\epsilon}(y) f (x - y) dy\n= f(x) \\lim_{\\epsilon \\rightarrow 0} \\int_{-E}^{E} \\delta_{\\epsilon}(y) dy\n= f(x)\n(37)\nThus, \u03b4 * f = f * d = f\nProof of lemma 3.7."}, {"title": "Proof. lemma 3.7 could be easily proved using lemma 3.3 and lemma 3.6.", "content": "B Proofs of the Unbiasedness and Consistency\nProof of the unbiasedness of statistic mge (x0). Unbiasedness means that the sample expectation of a statistic is the true value of the overall parameter.\nProof. According to the definition of mathematical expectations,\nE [mge(x0)] = E \\left[\\frac{1}{N} \\sum_{i=1}^N \\frac{g(x_0 - t_i)\\varphi_{\\epsilon}(t_i)}{p(t_i)}\\right]\n= \\frac{1}{N} \\sum_{i=1}^N E \\left[\\frac{g(x_0 \u2013 t_i)\\varphi_{\\epsilon}(t_i)}{p(t_i)}\\right]\n= \\frac{1}{N} \\sum_{i=1}^N \\int_{\\mathbb{R}^n} \\frac{g(x_0 - t)\\varphi_{\\epsilon}(t)}{p(t)} p(t) dt\n= \\int_{\\mathbb{R}^n} g(x_0 - t)\\varphi_{\\epsilon}(t) dt\n(38)\nBy eq. (16),\nE [mge(x0)] = \\int_{\\mathbb{R}^n} g(x_0 - t)\\varphi_{\\epsilon}(t) dt = g_{\\epsilon}(x_0)\n(39)\nProof of the consistency of statistic mge (x0). Consistency means that as the number of samples increases, the estimates converge more and more to the true value. Specifically, the variance of the statistic converges to 0 as the sample size increases.\nProof. According to the definition of variance,\n\\begin{aligned}\\sigma^2 [mge(x0)] &= \\sigma^2 \\left[\\frac{1}{N} \\sum_{i=1}^N \\frac{g(x_0 - t_i)\\varphi_{\\epsilon}(t_i)}{p(t_i)}\\right] \\\\&= \\frac{1}{N^2} \\sum_{i=1}^N \\sigma^2 \\left[\\frac{g(x_0 - t_i)\\varphi_{\\epsilon}(t_i)}{p(t_i)}\\right]\\end{aligned}\n(40)\nNote that G = \\frac{g(x-t)\\varphi_{\\epsilon} (T)}{p(T)} .\n\\begin{aligned}\\sigma^2 [mge(x0)] &= \\frac{1}{N^2} \\sum_{i=1}^N \\sigma^2 [G] = \\frac{1}{N^2} (N \\sigma^2 [G]) = \\frac{\\sigma^2 [G]}{N}\\end{aligned}\n(41)\nThat is,\n\\( \\sigma [mge(x_0)] = \\frac{\\sigma [G]}{\\sqrt{N}} \\)\n(42)\nClearly, the variance of statistic mge(x0) decreases as N increases, i.e., \\( \\lim_{x \\rightarrow 0} \\sigma [mge(x0)] = 0 \\)."}, {"title": "C Details of the Mollification Example", "content": "We construct a piecewise function f(x) : \\(\\mathbb{R} \\rightarrow \\mathbb{R}\\) to simulate a rough and unsmooth function. The expression of f(x) is,\n\\begin{aligned}f(x) = \\begin{cases}0 & , x \\leq 0 \\\\2x & , 0 < x \\leq 1\\\\4-2x & , 1 < x < \\frac{3}{2}\\\\ -1+2x & , \\frac{3}{2} \\leq x < 3 \\\\ 8-x & , 3<x<4\\\\ 4 & , 4 \\leq x\\end{cases}\\end{aligned}\n(43)\nThe selected mollifier \\(\\varphi_{\\epsilon}(x)\\) is,\n\\( \\varphi_{\\epsilon}(x) = \\frac{1}{\\sqrt{2\\pi \\epsilon}} e^{-\\frac{x^2}{2\\epsilon}} \\)\n(44)\nThe mollification f * \\(\\varphi_{\\epsilon}\\) could be calculated as,\n\\begin{aligned}f_\\epsilon(x) &= \\frac{1}{2} \\left\\{ x \\text{ erf}\\left( \\frac{x}{\\sqrt{2\\epsilon}} \\right) + (x-4) \\text{erf}\\left( \\frac{x-4}{\\sqrt{2\\epsilon}} \\right) - (2x-4) \\text{erf}\\left( \\frac{x-2}{\\sqrt{2\\epsilon}} \\right) + x-2 \\text{erf}\\left( \\frac{x-3}{\\sqrt{2\\epsilon}} \\right) \\right\\} \\\\ &+\\frac{\\sqrt{2 \\epsilon} \\left(e^{-\\frac{(x-4)^2}{2 \\epsilon}} +2 e^{-\\frac{(x-2)^2}{2 \\epsilon}} + e^{-\\frac{(x-3)^2}{2 \\epsilon}"}]}