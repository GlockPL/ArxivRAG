{"title": "Pitfalls of topology-aware image segmentation", "authors": ["Alexander H. Berger", "Laurin Lux", "Alexander Weers", "Martin Menten", "Daniel Rueckert", "Johannes C. Paetzold"], "abstract": "Topological correctness, i.e., the preservation of structural integrity and specific characteristics of shape, is a fundamental requirement for medical imaging tasks, such as neuron or vessel segmentation. Despite the recent surge in topology-aware methods addressing this challenge, their real-world applicability is hindered by flawed benchmarking practices. In this paper, we identify critical pitfalls in model evaluation that include inadequate connectivity choices, overlooked topological artifacts in ground truth annotations, and inappropriate use of evaluation metrics. Through detailed empirical analysis, we uncover these issues' profound impact on the evaluation and ranking of segmentation methods. Drawing from our findings, we propose a set of actionable recommendations to establish fair and robust evaluation standards for topology-aware medical image segmentation methods.", "sections": [{"title": "1 Introduction", "content": "Quantitative imaging biomarkers are of increasing importance in modern medicine. The development and evaluation of these biomarkers are directly linked to the emerging capabilities of artificial intelligence (AI) models [37]. Rapid progress has been made in medical image segmentation with architectures such as the Unet [39] or the Vision Transformer [13]. Despite these advances, achieving perfect pixel-wise accuracy often remains impossible in image segmentation tasks. Consequently, many studies investigate the quality of these segmentations beyond purely pixel-based performance metrics [7].\nAn important property in image segmentation is topological correctness, which considers structural integrity aside from volumetric accuracy. Its significance has been identified separately in several areas of medical imaging, such as radiology, angiology, and neurology. For example, in lesion detection, metrics such as lesion"}, {"title": "2 Related Work", "content": "Topology-aware image segmentation methods Numerous studies have tried to enhance segmentations' topological integrity in highly task-specific settings. Our study focuses on works that propose general-purpose solutions for improving topological correctness in multiple domains. Many of these works build on persistent homology (PH) and its differentiability to define loss functions for neural network optimization [20,42,8,11,5]. These methods are based on the computation of persistence diagrams using filtered cubical complexes from either T- or V-construction. In the persistence diagram, the birth and death cells can be identified and used to calculate a loss. Notably, for all these methods, the choice of cubical complex construction strongly impacts the persistence diagrams and, thus, the loss [6]. Other methods use discrete Morse theory (DMT) to achieve topology-aware image segmentation [4,19]. Apart from PH and DMT methods, other methods, including delineation [35], post-processing [26,27], homotopy warping [19], skeletonization [40], and component graphs [28] were proposed.\nTopological evaluation metrics Most studies on topologically accurate seg- mentation use a combination of different metrics to showcase their method's effectiveness. These metrics usually consist of pixel-wise metrics and topological metrics. A pixel-wise metric (e.g., cross-entropy or Dice coefficient) measures pixel-wise agreement between the prediction and label, disregarding topological characteristics. Although a perfect pixel-wise agreement implies identical topology, these metrics are not interpretable for values \u2260 1 from a topological perspective.\nSeveral topological metrics have been specifically proposed for the task of neuron segmentation. They mainly revolve around measuring the number of split/merge errors, which are concepts related to topological errors in dimension 0. Two widespread metrics are Rand Index (RI)-based metrics (e.g., ARE or adjusted rand index (ARI)) [21,1,44], and the VOI metric [31,33,32], both of which were originally proposed to measure cluster similarity. They have been adapted to image segmentation by partitioning a likelihood map to an instance map, where all pixels belonging to the same connected component are viewed as one cluster. Then, RI-related metrics measure pair-wise pixel agreement in the ground truth and prediction [1,44]. VOI measures how much information about a pixel's instance in the prediction can be gained by the pixel's instance in the ground truth and vice versa [36].\nLastly, purely topological metrics have been proposed for measuring topo- logical accuracy. These metrics include the Betti number error [20], the Betti matching error [42], and the DIU metric [28]. These metrics transfer the images to topological spaces and measure the number of topological errors. They give"}, {"title": "3 Common Pitfalls", "content": null}, {"title": "3.1 Connectivity choices distort the performance ranking between different methods", "content": "Voxel connectivity strongly affects topological representations and, hence, directly impacts model training and evaluation. Most prior works do not report which connectivity they use or appear to use an unfavorable choice where topological features lose their semantic meaning (see Fig. 2).\nTo translate a discrete 2D or 3D binary image $I$ into a topological space, defining the connectivity between voxels (i.e., whether diagonal adjacent voxels belong to the same component) is necessary. Voxel connectivity in a D-dimensional image can be defined by direct connectivity, i.e., a voxel has $2 \\times D$ neighbors (e.g., 4 for 2D and 6 for 3D images) or all connectivity, i.e., a voxel has $3^D \u2013 1$ neighbors (e.g., 8 for 2D and 26 for 3D images). In 2D, direct connectivity connects pixels that share an edge, and all connectivity additionally connects diagonally adjacent pixels, with their boundary only sharing a vertex. For 3D data, direct connectivity connects pixels that share a surface cell, and all-connectivity also connects pixels whose boundaries only intersect in a line or a vertex on the boundary. To ensure that the Jordan-Curve Theorem holds, it is necessary to use opposite connectivity choices for foreground and background, e.g., all connectivity for the foreground and direct connectivity for the background. In this work, we use the letter A to denote the setting where all connectivity is applied to the foreground and direct connectivity is applied to the background. We denote the inverted connectivity choice with the letter D.\nIn cubical complexes, which are often used to describe the topology of digital images [11,42,28,20], the complex's construction choice implicitly encodes a specific connectivity. V-construction V(I) is closely related to direct connectivity for the foreground and all connectivity for the background. The T-construction T(I) is closely related to the inverted connectivity choice. Bleile et al. [6] describe the relationship between the two constructions."}, {"title": "Experimental investigation of the problem:", "content": "To demonstrate the effect of the connectivity choice on topology-aware segmentation methods, we perform an experiment in which we train and evaluate different methods with the two distinct connectivity choices A and D. The results are displayed in Table 2. We observe that the variation originating from connectivity choices dominates the inter-method variation. The ranking of the methods changes drastically depending on the connectivity choice. We conclude that making the semantically meaningful connectivity choice is essential for a robust evaluation. High performance under"}, {"title": "Strategies to identify and resolve connectivity problems:", "content": "We encour- age future works to make individual and semantics-oriented connectivity choices for every individual dataset. For the three common benchmarking datasets, we determine A connectivity for DRIVE (to maintain vessel connectivity), D con- nectivity for CREMI (to avoid separation of synaptic clefts), and D connectivity for Roads (to minimize connectivity artifacts in the background, see Section 3.2) as the sensible connectivity choices. The choices should be made transparent to the reader when reporting metrics; e.g., for Betti numbers $B_0^A$ versus $B_0^D$; alternatively $B_{0V}$ versus $B_{0T}$ for an explicit notation of the cubical complex construction. This notation can be extended to all metrics where connectivity choices are influential, e.g., $ARE_A$ or $ARE_D$. Moreover, we propose a simple method to see how susceptible a dataset is to connectivity choices. We consider"}, {"title": "3.2 Topological Artifacts in the label skew evaluation results", "content": "In the context of topology-aware image segmentation, we propose to denote topological artifacts as topological features existing in the ground truth labels but conveying no or a wrong semantic meaning. We observe three prominent causes of such artifacts in the investigated datasets: (1) connectivity issues, (2) label noise, and (3) insufficient resolution (see Fig. 3).\nConnectivity artifacts: In many datasets, neither A nor D connectivity resolve all connectivity issues. In these cases, we define connectivity artifacts as topolog- ical artifacts that occur due to the choices made in connectivity. Connectivity artifacts can be found in the DRIVE dataset (see Figure 3). While the foreground 8-connectivity is absolutely crucial to capture the semantics of the small vessels for the DRIVE dataset, the then required background 4-connectivity divides a single inter-vessel area into numerous separate components. In the DRIVE dataset, these artifacts result in almost a doubling of background components for 4-connectivity instead of 8-connectivity (see Table 5).\nLabel noise artifacts: Label noise artifacts occur due to annotation errors during the generation of the ground truth segmentation mask. While some types of label noise do not interfere with the topological representation, other annotation"}, {"title": "Experimental investigation of the problem:", "content": "We compare the perfor- mance of different topology-aware methods before and after removing small background components using the DRIVE dataset. Visual inspection revealed that these components are predominantly caused by topological label noise and connectivity artifacts. The results of this experiment indicate a strong effect on the Betti and Betti matching metrics (see Table 4). Particularly for Betti number 1 error (~-29%) and Betti matching 1 error (~-43%), we see extreme changes caused by the artifacts (see Figure 3 for examples). In comparison, the artifacts only induce minute changes for the Dice score and VOI and ARE, which have traits of both topological and pixel-wise metrics."}, {"title": "3.3 Evaluation Metrics, as commonly reported, lack expressive power", "content": "The evaluation of topology-aware segmentation typically employs distributional (e.g., VOI or ARE/ARI) and/or topological metrics, such as the Betti number or Betti matching error in combination with pixel-wise/overlap-based metrics (e.g., Dice or cross-entropy). We find that current reporting practices often fail to provide an expressive and interpretable characterization of topological correctness.\nExperimental investigation of the problem: Distributional metrics such as VOI and ARI/ARE irreversibly entangle topological and volumetric errors [14,36]. Therefore, reporting only these metrics in addition to pixel-wise perfor- mance metrics does not allow for an expressive evaluation of topological accuracy. Figure 4 shows an example where volumetric deviations largely dominate the score of these metrics while small yet critical topological errors are marginalized. Empirically, we validate this shortcoming and find that the distributional met- rics do not always correlate with topological accuracy. For example, we find no correlation between $BM0A$ and $AREA$ ($\\rho = \u22120.03$) or $VOIA$ ($\\rho = 0.31$) in the DRIVE dataset. Here, $BM0A$ is the most important topological metric because it captures disconnected or incorrect vessel segments. However, in other cases, we find a positive correlation. For CREMI, $BM1D$ is an important topological metric since it captures false splits and merges of neurons. Here, $BM1D$ correlates well with $ARE_D$ (Spearman's $\\rho = 0.94$) and $VOI_D$ ($\\rho = 0.83$).\nBetti number errors are a better alternative to distributional metrics as they disentangle any volumetric effects and provide topologically interpretable values."}, {"title": "4 Discussion", "content": "The presented work sheds light on common pitfalls during the evaluation of topology-aware image segmentation methods. We identify (1) connectivity defini- tion, (2) label artifacts, and (3) misaligned use of evaluation metrics as major problems that heavily impact previous studies. In dedicated experiments, we show that these pitfalls are a major limitation for meaningful benchmarking in topology-aware image segmentation. Specifically, our results indicate that topological performance rankings are vulnerable to connectivity choices, showing on average negative correlations of the rankings (avg. Spearman's $\\rho = -0.63$) of A and D connectivity. We find that label artifacts can comprise up to 43% of measured topological errors in some metrics. Finally, we find that flawed evaluation practices, such as an aggregation of Betti numbers, drastically impair the expressivity of the evaluation.\nBased on our analysis, we conclude with the following recommendations for future works: (1) Connectivity choices must be made on a dataset and not on a"}, {"title": "Pitfalls of topology-aware image segmentation", "content": "method basis. The choices have to be transparent for the reader. We introduce a new method to quantify the connectivity susceptibility of datasets, providing a measure of the importance of connectivity choices. (2) Topological artifacts must be considered in topology-aware image segmentation. We provide a definition for topological artifacts that were previously overlooked due to their negligible influence on pixel-wise evaluation. (3) Evaluation metrics should disentangle volumetric and topological information and topological errors of different dimen- sions. Other metrics should be added in a problem-oriented manner. Ultimately, this paper should ignite a discussion on the current state and best practices of topology-aware image segmentation.\nLimitations. While the presented issues are valid for 2D as well as 3D images, an empirical evaluation of 3D datasets is still warranted because the commonly used slicing of 3D volumes in 2D images changes a segmentation's topological requirements. Furthermore, our work deliberately does not discuss general pitfalls in model evaluation that are not specific to topology-aware image segmentation. These general pitfalls include insufficient variation analysis [10], unfair baseline comparisons [22], or general unsuitability of metrics [38]."}]}