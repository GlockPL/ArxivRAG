{"title": "Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture", "authors": ["Zhong-Hua Sun", "Ru-Yuan Zhang", "Zonglei Zhen", "Da-Hui Wang", "Yong-Jie Li", "Xiaohong Wan", "Hongzhi You"], "abstract": "In abstract visual reasoning, monolithic deep learning models suffer from limited interpretability and generalization, while existing neuro-symbolic approaches fall short in capturing the diversity and systematicity of attributes and relation representations. To address these challenges, we propose a Systematic Abductive Reasoning model with diverse relation representations (Rel-SAR) in Vector-symbolic Architecture (VSA) to solve Raven's Progressive Matrices (RPM). To derive attribute representations with symbolic reasoning potential, we introduce not only various types of atomic vectors that represent numeric, periodic and logical semantics, but also the structured high-dimentional representation (SHDR) for the overall Grid component. For systematic reasoning, we propose novel numerical and logical relation functions and perform rule abduction and execution in a unified framework that integrates these relation representations. Experimental results demonstrate that Rel-SAR achieves significant improvement on RPM tasks and exhibits robust out-of-distribution generalization. Rel-SAR leverages the synergy between HD attribute representations and symbolic reasoning to achieve systematic abductive reasoning with both interpretable and computable semantics.", "sections": [{"title": "I. INTRODUCTION", "content": "Raven's Progressive Matrices (RPM) are a family of psychological intelligence tests widely used for the assessment of abstract reasoning [1], [2]. From a cognitive psychology perspective, abstract visual reasoning in RPM tests involves constructing high-level representations from images and deriving potential relations from these representations [1], [3]. Endowing artificial intelligence with such capabilities is now regarded as a crucial step toward achieving human-level intelligence. However, many recent monolithic deep learning models, which do not explicitly separate perception and reasoning [4]\u2013[9], face inherent challenges, such as poor interpretability, limited robustness and generalization, and difficulties in module reuse [10]. Neuro-symbolic architecture, which combines neural visual perception with symbolic reasoning, offers a promising approach to overcoming these challenges and achieving human-level interpretability and generalization [10]-[12].\nIn neuro-symbolic architectures (NSA), Marcus argues that symbol-manipulation in cognition involves representing relations between variables [11]. For RPM tests, object attributes serve as the variables, while potential rules involve the relations. Nevertheless, due to incomplete attribute and relation representations, achieving systematic abduction and execution is still a critical challenge for NSA when performing RPM tests. From the perspective of attributes, recent models such as PrAE [10], the ALANS learner [13], and NVSA (neuro-vector-symbolic architecture) [12] construct attribute representations through neural perception frontends. Notably, the NVSA model achieves hierarchically structured VSA representations of image panels, capturing multiple objects with multiple attributes [12]. Regarding relation representations, PrAE and NVSA achieve abstract reasoning through probabilistic abduction and execution [10] and distributed vector-symbolic architecture (VSA) [12], respectively. Both models rely on predetermined multiple rule templates, each specialized for distinct individual RPM rules. To address the limitations in rule expressiveness, the ALANS learner utilizes learnable rule operators in the abstract algebraic structure, without manual definition for every rules [13]. Additionally, the ARLC model adopts a more expressive VSA-based rule template, operating in the rule parameter space [14]. Both models offer improved interpretabiltiy and generalizability. Despite their advances, previous models fall short in capturing the diversity and systematicity of attribute and relation representations. In contrast, human cognition demonstrates rich and flexible internal representations [15], [16], including arithmetic and logic, and rule-based reasoning systems in cognition are productive and systematic [17]. Therefore, the abstract visual reasoning performance of these models remains open to further improvement.\nPrevious research indicates that Vector Symbolic Architecture (VSA), a form of high-dimensional (HD) distributed representation, possesses algebraic properties for mathematical operations and can also achieve structured symbolic representations of data [18]-[20]. In this work, to achieve comprehensive relation representations, we introduce various types of VSA-based atomic HD vectors with distinct semantic representations, including numeric values, periodic values, and logical values. Given that reasoning in RPM problems involves the overall attributes of multiple objects, we further introduce the structured HD representation (SHDR) for the nxn Grid. They serve as attribute representations necessary for abductive reasoning. Meanwhile, we propose numerical"}, {"title": "II. RELATED WORK", "content": "The Raven Progressive Matrices (RPM) is a widely used nonverbal intelligence test designed to assess abstract reasoning. To explore the limitations of current machine learning approaches in solving abstract reasoning tasks, two automatically generated RPM-based datasets-RAVEN [21] and I-RAVEN [8]\u2014have been introduced (Figure 1). Early efforts on RPM primarily employed Relation Network (RN) [22] and their variants [4], [7], [9], [23] to extract relations between context panels. Concurrently, CoPINet [6], MLCL [24], and DCNet [25] integrate contrastive learning in their models. Approaches like MRNet [9] and DRNet [26] aimed to enhance perception capabilities, while SRAN [8] and PredRNet [27] abstract relations using stratified models and prediction errors, respectively. In addition, several methods have focused on scene decomposition and feature disentanglement [28]-[30]. Although these monolithic deep learning models achieve high accuracy, they often suffer from limited interpretability and systematic generalization capabilities.\nAnother branch for solving RPM is based on neuro-symbolic architectures, which explicitly distinguish between perception and reasoning. PrAE [10] employs an object CNN to generate probabilistic scene representations and uses predetermined rule templates for probabilistic abduction and execution. Inspired by abstract algebra and representation theory, ALANS [13], which shares the same perception frontend as PrAE, transforms probabilistic scene distributions into matrix-based algebraic representations. The algebraic reasoning backend of ALANS induces potential rules through trainable operator matrices, eliminating the need for manual rule definitions."}, {"title": "III. PRELIMINARIES", "content": "VSAs are a class of computational models that utilize high-dimensional distributed representations [20]. VSA models used in this study are Holographic Reduced Representations (HRR) and its form in the frequency domain, referred to as Fourier Holographic Reduced Representations (FHRR) [36]. A random FHRR atomic vector, denoted as $\\theta := \\{ \\theta_i \\}_{i=1}^d$, is composed of elements $\\theta_i$ that are independently sampled from a uniform distribution, specifically $\\theta_i \\sim U(-\\pi, \\pi)$ [36]. The corresponding HRR atomic vector, x, is then obtained by applying the Inverse Fast Fourier Transform (IFFT) to $\\theta$:\n$x = \\mathcal{F}^{-1} (e^{j \\theta})$ (1)\nHere, $\\mathcal{F}$ and $\\mathcal{F}^{-1}(\\cdot)$ represent the Fast Fourier Transform (FFT) and Inverse FFT (IFFT), respectively. When the dimension d is sufficiently large, these randomly generated vectors exhibit pseudo-orthogonality, making them suitable for representing distinct symbols or concepts.\nThe similarity between any two vectors is a crucial metric for evaluating the distributed representations in VSAs. In FHRR and HRR, cosine similarity is employed to measure the similarity between two vectors [20]:\n$\\begin{aligned} \\text{sim}(\\theta, \\phi) &= \\frac{1}{d} \\sum_{i=1}^d \\text{cos} (\\theta_i - \\phi_i) \\\\ \\text{sim}(x, y) &= \\frac{x \\cdot y}{\\|x\\| \\|y\\|} \\end{aligned}$ (2)\nwhere $\\theta$ and $\\phi$ denote two FHRR vectors, and x and y two HRR vectors. The similarity $\\text{sim}(\\cdot, \\cdot)$ ranges from -1 to +1, and above two similarity measures are equivalent. The pseudo-orthogonality refers to the case where the similarity $\\text{sim}(\\cdot, \\cdot) \\approx 0$.\nAll computations within VSAs are composed of several basic vector algebraic operations, with the primary ones being binding (\\circ), bundling (+), and unbinding (\\oslash) . The binding operation (\\circ) is employed to form a representation of an object that contains information about the context in which it was encountered [20]. The bundling operation (+), also known as superposition, generates a composite high dimensional vector that combines several lower-level representations. In calculation, binding has a higher priority than bundling. The unbinding operation (\\oslash), which is the inverse of binding, extracts a constituent from the compound data structure. Binding and bundling are referred to as composition operations, while unbinding is considered a decomposition operation. All operations do not change the vector dimensionality.\nThrough the combination of these operations, VSAs can effectively achieve structured symbolic representations [20]. For instance, consider a scene s in which a triangle t is positioned on the left $p_L$ and a circle c on the right $p_R$. This scene can"}, {"title": "C. The fractional power encoding method", "content": "In this study, the rules in RPM are primarily numerical. We introduce the VSA representation of numerical values using the fractional power encoding method (FPE-VSA) [18], [19]. Let $x \\in \\mathbb{R}$ be a real number and $X \\in \\mathbb{R}^d$ a randomly sampled base vector. The VSA representation $v(x) \\in \\mathbb{R}^d$ for any value x is obtained by repeatedly binding the base vector X with itself x times, as follows:\n$v (x) := (X)^{(\\circ x)}$ (3)\nThe FPE method maps arbitrary real numbers to corresponding HD vector, and has the following properties:\n$v (x_1 + x_2) = v (x_1) \\circ v (x_2)$ (4)\nThis demonstrates that addition + in the real number domain can be represented by the binding operation $\\circ$ in the vector domain."}, {"title": "IV. METHODOLOGY", "content": "In neuro-vector-symbolic systems, atomic HD vector representations with meaningful semantics are essential for perception and reasoning. We introduce four types of atomic HD vectors used in our model (Figure 2): Random Vectors (RVs), Numeric Vectors (NVs), Circular Vectors (CVs), and Boolean Vectors (BVs). The definitions and properties of these vectors are universal within the VSA framework.\nRVs are sampled from specific distributions according to the VSA models, as mentioned in the preliminary section. Due to the absence of numerical or logical relations among RVs and their pseudo-orthogonality in the HD vector space (Figure 2a), they are often used to represent symbols and concepts assumed to be independent and dissimilar.\nNVs, generated using the fractional power encoding (FPE-VSA, Equation 3) [18], are employed to represent real numbers (Figure 2b). NVs $v(r) \\in \\mathbb{R}^d$ can be used to perform addition-type arithmetic operations through the binding (Equation 4) [19].\nCVs are a special class of NVs used to represent periodic values (Figure 2c). Given a base vector P, where each phase of its elements $p_i$ is sampled from a discrete distribution (e.g., for FHRR, $p_i \\sim U(\\frac{2\\pi j}{L}, \\forall j \\in \\{1,\\ldots, L\\})$, with L being an even number), CVs are defined as $p(r) := (P)^{(\\circ r)}$. These CVs are pseudo-orthogonal to one another and exhibit periodicity with a period of L [19]:\n$p^{( \\circ (r + L))} = p^{( \\circ r)}$ (5)\nIf L is odd, the corresponding CVs with period L can be obtained by selecting every other CV from those with period 2L."}, {"title": "B. Relation functions based on atomic HD representations", "content": "The rules for abductive reasoning in RPM involve binary and ternary relations among the attributes of corresponding objects in each row of three panels (Figure 2e and Figure 1a), as well"}, {"title": "1) Relation functions:", "content": "Relation functions, which describe the relations between multiple HD vector representations, are categorized into two types: numerical and logical. Among the atomic HD representations, Numeric Vectors (NVs) and Circular Vectors (CVs) are involved in numerical relations, while Boolean Vectors (BVs) are involved in logical relations.\nThe numerical relation function, $\\mathcal{R}_{Num}$, is defined as follows (Figure 2f):\n$\\mathcal{R}_{Num} = \\mathcal{R}_{Num} (v_{1:N}, OP_{1:M}) = (\\bigcirc_{i=1}^N v_i)^{(\\circ \\bigcirc_{i=1}^M op_i)}$ (6)\nwhere N represents the arity of the relation function, and $v_{1:N} := \\{v_i\\}_{i=1}^N$ denotes the input set of HD vector representations. M is the number of operator powers and $OP_{1:M} := \\{op_i\\}_{i=1}^M$ represents the operator powers, which can be considered as parameters of the relation function. The notation $\\bigcirc_{i=1}^N$ denotes the sequential binding operation applied to the N HD vector representations. $r_{Num}$ is the output HD representation. For the binary numerical relation function, N = 2 and M = 2, while for the ternary numerical relation function, N = 3 and M = 3. Based on the arithmetic properties of NVs and CVs, $\\mathcal{R}_{Num}$ can describe the additive relations of these two types of HD vector representations. The combination of $OP_{1:M}$ and $r_{Num}$ determines the specific numerical relation in this vector-symbolic method.\nSimilarly, the simplified logical relation function, $\\mathcal{R}_{Lgc}$, is defined as follows (Figure 2f):\n$r_{Lgc} = \\mathcal{R}_{Lgc} (v_{1:N}, OP_{1:M}) = (op_1v_1 \\land op_2v_2) \\circ op_3v_3$ (7)\nwhere $v_{1:N} := \\{v_i\\}_{i=1}^N \\in \\{e(0), e(1)\\}$ denotes the input set of BVs. The full version of logical relation function is described in Appendix A. Here, we consider only the ternary logical relation, so N = 3 and M = 3. The parameter $OP_{1:M} := \\{op_i\\}_{i=1}^M$, where $op_i \\in \\{0,1\\}$ determines whether to negate $v_i$, with negation ($\\neg$) applied when $op_i = 1$ and no negation applied when $op_i = 0$ (see Appendix A). The symbol $\\land$ denotes the AND operation, as shown in Table II. Based on the computational properties of BVs detailed in Table II, $\\mathcal{R}_{Lgc}$ can describe the ternary logical relations involved in RPM. The combination of the operator $OP_{1:M}$ and the output $r_{Lgc}$ determines the specific logical relation in this vector-symbolic method."}, {"title": "C. Structured high-dimensional representation and its attribu- tion decomposition", "content": "VSA can create structured symbolic representations using atomic HD vector representations and decouple them directly from these structures through algebraic operations [12]. This subsection presents the process of constructing a structured HD representation (SHDR) for an image panel and its decomposition to retrieve individual attribute representations. Additionally, an SHDR for the nxn Grid (n = 2,3) at the component level is also introduced."}, {"title": "1) SHDR for the image panel:", "content": "In RAVEN dataset, each image panel consists of objects, with each object characterized by multiple attributes. Consequently, the structured HD representation (SHDR) for each image panel can be obtained through two layers of role-filler bindings (Figure 3a). First, the bundling operation is used to construct an SHDR for each object at the entity level by combining its attributes. Then, another bundling operation aggregates these object-level representations to construct a SHDR of the image panel at the scene level. Therefore, each image panel $X \\in \\mathbb{R}^{r\\times r}$, with a resolution r \u00d7 r, can be represented by an SHDR $S \\in \\mathbb{R}^d$ as follows:\n$S = \\sum_{j=1}^{N_{pos}} p_j \\circ O_j = \\sum_{j=1}^{N_{pos}} p_j \\circ (\\bigcirc_{attr \\in ATTR} k_{attr} \\circ v_{attr})$ (10)\nHere, $O_j$ represents the SHDR of the jth object with different attributes at the entity level, incorporating attributes such as type, size, color, and existence. The attribute set is ATTR= {type, size, color, exist}. At the entity level, the key vector $k_{attr}$ denotes the class of a specific attribute attr \u2208 ATTR, while the value vector $v_{attr}$ indicates the attribute's value at the position j. At the scene level, the position vector $p_j$ specifies the location of the j-th object."}, {"title": "2) Representation decomposition:", "content": "Given an estimated SHDR $\\hat{S} \\in \\mathbb{R}^d$ of an image panel, all SHDRs of objects"}, {"title": "D. Rules from the perspective of relation functions", "content": "The RAVEN dataset contains 4 rules-Constant, Progression, Arithmetic, and Distribute Three\u2014which operate on 5 rule-governing attributes [21]. These 5 attributes include 3 entity-"}, {"title": "2) Inverse relation functions:", "content": "Rule execution in RPM requires inferring the third attribute value based on the first two attribute values in a row of panels, given a known relation. It represents an inverse problem of rule abduction. In the vector-symbolic method, given the operator power $OP_{1:M}$ and the output r, the last vector representation $v_N$ can be inferred from the first N \u2212 1 inputs $v_{1:N-1}$ using the inverse of the relation functions (Figure 2g). According to Equation 6, the inverse numerical relation function is defined as follows:\n$v_N = \\mathcal{R}_{Num}^{-1} (v_{1:N-1}, OP_{1:M}, r) = (\\bigcirc_{i=1}^{N-1}(v_i)^{(\\circ (-op_i/\\bigcirc_{i=1}^Mop_i))}) \\circ r^{((\\circ (-1/\\bigcirc_{i=1}^Mop_i)))}$ (8)\nSimilarly, according to Equation 7, the inverse logical relation function is defined as follows:\n$v_N = \\mathcal{R}_{Lgc}^{-1} (v_{1:N-1}, OP_{1:M}, r) = op_3 \\oslash (op_1v_1 \\land op_2v_2)$ (9)"}, {"title": "E. The Systematic Abductive Reasoning model", "content": "In this section, we present the Systematic Abductive Reasoning model with diverse relation representations (Rel-SAR), inspired by the NVSA [12]. An overview of Rel-SAR is depicted in Figure 4a. Similar to previous neuro-symbolic models for abstract visual reasoning, Rel-SAR combines a neural visual perception frontend with a symbolic reasoning backend, both utilizing VSA representations with meaningful semantics to facilitate systematic reasoning. The perception frontend employs a neural network to extract the SHDR S of each image panel X in the RPM and achieves feature disentanglement from the SHDR using representation decomposition to obtain the HD representations of attributes (v, p and C: Table III) required for reasoning in the backend. The reasoning backend consists of three main modules: the rule abduction module, the rule execution module, and the answer selection module. The rule abduction module extracts the corresponding rules ($OP_{1:M}$ and r: Table IV) for each attribute representation according to appropriate relation function (Equation 6 and 7, Table III). Subsequently, the rule execution module uses these rules to predict the representations of the missing panel's attributes according to corresponding inverse relation functions (Equation 8 and 9). Finally, the answer selection module compares the predicted attribute representations of the missing panel with the available options in the answer panels and selects the answer."}, {"title": "1) Perception frontend:", "content": "The perception frontend operates independently on each of the 16 image panels to extract the HD representations of attributes required for abductive reasoning (Figure 4a and Figure 4b). For a given image panel $X_{ind} \\in \\mathbb{R}^{r\\times r}$, where ind \u2208 {(1,1), (1, 2), \u2026\u2026\u2026, (3,2)} for 8 contexts and ind \u2208 {1,2,\u2026\u2026,8} for 8 candidates, the frontend uses a trainable neural network (ResNet-50) to map the image panel to its estimated SHDR $\\hat{S}_{ind} \\in \\mathbb{R}^d$: $f_\\theta : X \\rightarrow \\hat{S}$, where $\\theta$ represents the trainable parameters of the network. Theoretically, the expected SHDR S for each panel should be organized from the corresponding attribute representations as described by Equation 10. Therefore, the learning objective of $f_\\theta$ is to minimize the difference between its output $\\hat{S}$ and the theoretical SHDR S, formulated as:\n$\\min_\\theta || f_\\theta (X; \\theta) - S||$ (13)"}, {"title": "Subsequently, the estimated SHDR S for each panel undergoes representation decomposition (Figure 4b), as de- scribed in Equation 11, to obtain the estimated HD attribute representations for each object, including Type (vtype), size (size), color (color), and existence (vexist), where j denotes the position index of the corresponding object. The HD attribute representations are expected to be selected from a set of frontend codebooks for the available attributes of interested in the RAVEN dataset (Figure 4b). These frontend codebooks include CFront := {v(r)j=0 \\cup {vnull} and CFron := {e(r)j=0, which represent the numerical value and logic, respectively. vnull represents the null attribute representation when there is no object. To improve the neural network's performance in encoding the SHDR of an image panel, all hypervectors in these frontend codebooks are ran- domly and independently generated as RVs, rather than using NVs, CVs, or BVs. However, the estimated HD attribute representations for each object, vattr (attr \u0004 {type, size, color, exist}), cannot be directly applied to the reasoning backend. First, these representations contain noise introduced by the bundling op- eration in the form SHDR. Second, as they are expected to be derived from the frontend codebooks of RVs, there are no intrinsic arithmetic or logical relations between the vattr s, which hinders effective reasoning. To address these issues, we adopt an approach similar to the attention mechanism [38] to obtain the HD attribute representations suitable for the reasoning backend (Figure 4b). In the query stage, we use the estimated HD attribute repre- sentations (vattr ) as query vectors to compute their similarity with all possible vectors for the corresponding attributes in the frontend codebooks. In the attention stage, these similarity scores are then used as attention weights to perform a weighted summation of the corresponding vectors from the backend codebooks, in which all hypervectors are generated according to their attribute type as shown in Table III. The backend codebooks consist of CNu Backs (BV), CBcR, and C Back (CVs for positions in nxn Grid). The updated HD attribute representations obtained after the weighted summation can be utilized in the reasoning backend. The details are provided below. The query stage: For each attribute attr {type, size, color}, we compute the cosine similarity between the estimated HD attribute representation vattr and all possible vectors of CFron in the frontend codebooks. Wattr = softma sim (vattr , CFron) (14) where Wattr (r) (r \u0004 {0,1,..., 9, null}) represents the atten- tion weights corresponding to the value r of attribute attr at the jth position, based on the query similarity. Similarly, the attention weights for the attribute attr \u0004 {exist} can be obtained by querying the logic codebook CFron as follows: [image] softmax \\beta  sim (v exist, CFron ) (15) where Wexist (r) (r \u0004 {0,1}) corresponds to the presence and absence of the object at jth position, respectively. Here, we", "content_type": "text"}, {"title": "3) 3-ary Relations", "content_type": "text"}, {"title": "4) General", "content_type": "text"}, {"title": "5) Related Work", "content_type": "text"}, {"title": "2) Reasoning backend:", "content": "The Rel-SAR model efficiently implements systematic abductive reasoning by leveraging HD attribute representations and VSA-based relation functions. HD attribute representations from the frontend are transformed into the HD vector space, enabling VSA operations on both numerical and logical relation functions (Equation 6-9). Consequently, the reasoning backend can perform systematic rule abduction and execution based on these relational functions, without requiring extensive use of explicit rule templates. Rule Abduction. Attributes in the RAVEN dataset follow row-major binary or ternary relations [21]. All possible binary"}, {"title": "V2 and ternary V3 relation pairs in the RPM test are presented in Table V, where v(i,j) denotes the HD attribute representa- tion for a given attribute in the context panel at row i and column j, and v(y) represents the corresponding HD attribute representation of the target answer panel. Consequently, rule abduction can be formulated as an optimization problem: For both numerical and logical rules, the rule abduction module must identify a set of operator powers OP1:M such that all N- ary (N = 2,3) relation pairs yield the same output rNum/Lgc when processed through their respective relation functions RNum/Lgc. Formally: max s = [image] sim (R(VN, OP1:M ), R (V, OP1:M )) (21) NNE VN NEV N where sim denotes cosine similarity, and R represents either the numerical relation function RNum or the logical relation function RLgc. VN \u0004 VN (i \u0005 j) refers to any two relation pairs selected from VN (N 2,3). SNum/Lgc represents the overall similarity between the outputs r of all corresponding relation pairs and can be interpreted as an unnormalized probability of the corresponding rule. Based on the above idea, in the rule abduction module (Figure 4c Left), the HD attribute representations of 8 context panels for a given numerical attribute are input into a trainable neural network fNum as the rule learner to predict the operator powers OP1:M, which are expected to achieve the optimiza- tion of the objective defined in Equation 21. Subsequently, all attribute sets for binary and ternary relations (Table V) are input into the corresponding numerical relation functions using the predicted OP1:M, and their outputs Nu are obtained. Based on the outputs Num from the relation functions, the unnormalized probability sNum and swum for binary and ternary relations, respectively, can be computed (Equation 21). The operator powers OP1:M and the averaged output Num with larger sNum are then defined as the underlying numerical rule. Similarly, another trainable rule learner, fug, is used to predict the operator powers OP1:M for the logical rules associated with the attribute Position (Figure 4c Right). Since the logical rules in the Raven dataset only involve ternary relations, all logical representations are organized according to the attribute sets of ternary relations outlined in Table V, and are then input into the logical ternary relation functions with the predicted parameters OP1:M. Based on the outputs Lge from the relation functions, the unnormalized probability sige for logical relations can be computed (Equation 21). Sub- sequently, sige is compared with SNum, which corresponds to numerical relations for the attribute Position. If sige is larger, the operator powers OP1:M and the averaged output Lge for logical relations can be interpreted as the underlying logical rule."}, {"title": "7) Numerical and Logical Function", "content_type": "text"}, {"title": "Rule Execution", "content_type": "text"}, {"title": "Answer and Label", "content_type": "text"}, {"title": "3) Logical relations", "content_type": "text"}, {"title": "Table", "content_type": "text"}, {"title": "10) The attention stage", "content_type": "text"}, {"title": "End-to-End Training", "content_type": "text"}, {"title": "2,3) , .0003", "content_type": "text"}, {"title": "Training", "content_type": "text"}, {"title": "Table III, 0004", "content_type": "text"}, {"title": "0005 Table10 , 0006 13", "content_type": "text"}, {"title": "O-IG", "content_type": "text"}, {"title": "Table IV", "content_type": "text"}, {"title": "46079, 0008 Table V", "content_type": "text"}, {"title": "Lgc,", "content_type": "text"}, {"title": "9884", "content_type": "text"}, {"title": "2) End-to-End Training with auxiliary attribute labels:", "content": "Following previous work, we assess the performance of the Rel-SAR model in end-to-end training using both auxiliary attribute labels and answer labels. Here, a cosine similarity loss is employed as the perception loss function to enhance the similarity between the estimated SHDR Sind of the perception frontend and the theoretical SHDR S (Equation 10) derived from attribute labels, thereby optimizing the trainable percep- tion network f (Equation 13). The perception loss function L is defined as follows: L 1 sim (Sind, S) (26) Meanwhile, to achieve rule learning through the optimiza- tion objective described in Equation 21, we introduce the loss function L to increase the overall similarity between the outputs r of all corresponding relation pairs in V2 and V3 (Table V), respectively. This is formulated as follows: i [image] sim (ri, ) (27) where r; and r; denotes the outputs of relation functions for any two distinct sets of relation pairs in V2 and V3, including attribute sets from the answer panel y. Therefore, the overall loss function L for end-to-end training with auxiliary attribute labels is constructed as: L =L L rs (28) where the former represents the sum of the loss functions across all context panels and the answer panel, while the latter represents the sum of the loss functions across all attributes. Additionally, similar to other neuro-symbolic approaches, the perception frontend and reasoning backend in Rel-SAR can also be trained independently using the loss functions Lp and Lrs, respectively."}, {"title": "V. EXPERIMENTS", "content": "We evaluate our model on the RAVEN [21] and I-RAVEN [8] datasets. Each dataset contains 70,000 RPM samples, which are divided into training, validation, and test sets with a 6:2:2 ratio. We use a ResNet-50 as the encoder (f) to map the image panels X to their SHDR S \u0004 R4, where the dimension d of all vectors is set to 3000. Two 5-layer fully connected networks as rule learners (fund and flue) are employed to extract OP from updated Position representation and other attribute (Number, Type, Size and Color) representation, respectively. The existence vectors of the backend codebook are set to HRR because the normalization of FHRR in the superposition operation will invalidate the logical reasoning. All other vectors are FHRR. We utilize the AdamW optimizer with a learning rate of 1*10-4 and a weight decay of 1*10-4. Here we first evaluate the Rel-SAR model on both RAVEN [21] and I-RAVEN [8] datasets using end-to-end learning. The"}, {"title": "TableVI", "content_type": "text"}, {"title": "End-to-End", "content_type": "text"}, {"title": "65", "content_type": "text"}, {"title": "909", "content_type": "text"}, {"title": "TableVII", "content_type": "text"}, {"title": "947,", "content": "29", "content_type": "text"}, {"title": "C. Perception results learned with the attribute labels", "content_type": "text"}, {"title": "89622 , 9994", "content_type": "text"}, {"title": "TabeleVIII", "content_type": "text"}, {"title": "88", "content_type": "text"}, {"title": "Experiments", "content_type": "text"}, {"title": "10", "content_type": "text"}, {"title": "TableIX", "content_type": "text"}, {"title": "Experiments Table X", "content_type": "text"}, {"title": "VI. CONCLUSION AND FUTURE DIRECTIONS", "content": "In this work, we propose Rel-SAR, a novel model that leverages VSA algebra to facilitate systematic rule abduction and execution. Rel-SAR adopts a neuro-symbolic architec- ture, where the perception frontend extracts diverse high-dimensional attribute representations with intrinsic algebraic properties, and the reasoning backend systematically derives a variety of rules based on relation functions. Extensive experiments demonstrate that Rel-SAR achieves superior per-"}, {"title": "APPENDIX A THE FULL VERSION OF LOGICAL RELATION FUNCTION", "content": "The RPM-style logic rules are expressed as that the set of attribute values in the third panel of a row or column corresponds to the logic operation applied to the first two panels. The simplified version (M = 3) of the logical relation function, Ri, cannot handle all RPM-style logic rules, such as XOR. To address this limitation, we developed a full version of Ra with OPi.m (M = 5) to describe all RPM-style logical rules that are meaningful"}]}