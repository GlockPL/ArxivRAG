{"title": "Ethical Concern Identification in NLP:\nA Corpus of ACL Anthology Ethics Statements", "authors": ["Antonia Karamolegkou", "Sandrine Schiller Hansen", "Ariadni Christopoulou", "Filippos Stamatiou", "Anne Lauscher", "Anders S\u00f8gaard"], "abstract": "What ethical concerns, if any, do LLM re-\nsearchers have? We introduce EthiCon, a\ncorpus of 1,580 ethical concern statements\nextracted from scientific papers published in\nthe ACL Anthology. We extract ethical con-\ncern keywords from the statements and show\npromising results in automating the concern\nidentification process. Through a survey (N =\n200), we compare the ethical concerns of the\ncorpus to the concerns listed by the general\npublic and professionals in the field. Finally,\nwe compare our retrieved ethical concerns with\nexisting taxonomies pointing to gaps and future\nresearch directions.", "sections": [{"title": "Introduction", "content": "Researchers are often asked to subscribe to ethical\nguidelines, e.g., the European Code of Conduct\nfor Research Integrity (ALLEA, 2017) or the\nACM Code of Ethics\u00b9 for publishing their work\nin the Association for Computational Linguistics\n(ACL). In addition, authors are often encouraged\nto write a so-called ethics statement, addressing the\nbroader implications of their work or any ethical\nconsiderations. We ask: What ethical concerns are\nraised in such statements, and how do they compare\nwith public perceptions? Is there a gap between\nacademic and public concerns?\nAs natural language processing technologies be-\ncome more prevalent, understanding the ethical\nconcerns raised by professionals will enable us to\ncompare them with public concerns, helping to\nidentify gaps and overlaps that can inform frame-\nworks and solutions to existing and emerging prob-\nlems. For this reason, we create EthiCon, an anno-\ntated corpus of ethics statements from the Proceed-\nings of the 60th and 61st Annual Meeting of the\nAssociation for Computational Linguistics (Mure-\nsan et al., 2022; Rogers et al., 2023).\nSee\nhttps://www.aclweb.org/portal/content/\nacl-code-ethics for ACL's guidelines.\nOur aim is twofold: to map out the concerns of\nthe NLP community as they appear on the ethics\nstatements, and to trace gaps and overlaps between\nNLP professionals and the general public. Our\nresults show that laypeople express different ethi-\ncal concerns than professionals, focusing on socio-\neconomic and human-computer interaction issues,\nalong with miscellaneous concerns like existential\nrisks. This highlights the need for increased dia-\nlogue between researchers and the public to address\nthese varying perspectives and an updated taxon-\nomy covering both existing and emerging issues.\nContributions. We provide a corpus of 1,580\nethics statements from the ACL Anthology. We\nidentify the main issues that NLP researchers flag\nas ethically concerning in their work and show how\nLLMs could automate this process. Through a sur-\nvey, we compare how laypeople and NLP profes-\nsionals perceive the ethical concerns surrounding\nnatural language processing. Lastly, we provide\na comparison of the ACL and the survey ethical\nconcerns to existing taxonomies of risks posed by\nLanguage Models. Finding a way to better auto-\nmate the process will enable the comparison of eth-\nical concerns across time and technical innovation\nand provide a better understanding of the impact of\nNLP research within the field and beyond."}, {"title": "Previous work", "content": "Several researchers have surveyed ethical concerns\naround NLP. Hovy and Spruit (2016) discuss the\nsources of social implications of NLP research (ex-\nclusion, over-generalization, exposure) and their\nethical importance, including in dual-use scenarios.\nLeidner and Plachouras (2017) provide examples\nof ethical concerns and best practices when con-\nfronted with ethical dilemmas. Dinan et al. (2021)\nexamined safety issues related to conversational AI,\nfocusing on offensive and inappropriate responses,\nwhile also highlighting further challenges such as\nbias, fairness, privacy leaks, environmental impact,\nand trust. Birhane et al. (2021) examine ethical\nvalues from 100 highly cited machine learning pa-\npers published at ICML and NeurIPS. The most\ndominant values were performance and efficiency,\nand only a small fraction addressed societal needs\nor potential harms. There have also been exten-\nsive reports from the industry or research institutes\ndiscussing the impact and risks of language mod-\nels (Solaiman et al., 2019; Weidinger et al., 2021;\nBommasani et al., 2021; Ma, 2023). Most similar\nto our work, Benotti and Blackburn (2022) man-\nually classify 90 ethical concern statements from\nACL 2021 based on whether they mention ben-\nefits (who benefits from the technology), harms\n(who might be harmed if it works or fails), and\nvulnerabilities (if harms disproportionately affect\nmarginalized groups). However, their focus is to\noutline the purpose of the statements, not specific\nethical issues.\nA survey for 92 ethics-related NLP works can\nbe found in Vida et al. (2023) ."}, {"title": "EthiCon", "content": "Dataset Creation and Annotation. To create a\ndataset consisting of ETHIcal CONcern statements,\nwe scraped the ACL Anthology\u00b3 and extracted eth-\nical statement paragraphs from scientific publica-\ntions.\nWe used the URL links provided by Rohatgi et al.\n(2023) and retrieved 4,691 articles from 2023 and\n3,357 articles from 2022. We extracted the ethical\nstatement paragraphs by parsing the HTML page\nwith a regular expression pattern to catch common\nvariations of the paragraph title, such as 'Ethic(s)',\nor 'Ethical' followed by terms like 'Statement',\n'Consideration(s)' or 'Concern(s)'. We were able\nto extract 480 ethics statements from the ACL 2022\nanthology and 1,100 ethical statements from 2023.\nTo develop the annotation guidelines, we carefully\nreviewed 500 statements to provide clear examples\nand detailed guidance for the annotators. Through\nthis process, we identified recurring patterns, en-\nabling us to categorize the statements into five\nclasses: (1) general disclaimers, (2) a list of eth-\nical concerns, (3) a list of actions taken to avoid\nethical concerns, (4) a list of suggestions or advice\nto avoid ethical concerns, and (5) miscellaneous\n(other), i.e., various combinations of the aforemen-\ntioned classes. See Figure 2 for examples. Two of\nthe paper's authors served as annotators, identify-\ning ethical concerns and classifying each statement\ninto one or more predefined categories. See Ap-\npendix for more details on the annotation process\nand guidelines.\nDataset Validation. We used a third annotator\nas validator and arbiter in cases of disagreement."}, {"title": "Automatic Ethical Concern\nIdentification", "content": "We present LLM experiments to check whether we\ncan automatically identify ethical concerns related\nto NLP advancements from conference proceed-\nings and automate our monitoring of these ethical\nissues in publications.\nModels and evaluation. We used four state-\nof-the-art open-source language models to iden-\ntify ethical concerns from our EthiCon Dataset:\nGemma-7b-it, Meta-Llama-3-8B-Instruct, Qwen2-\n7B-Instruct, and Mixtral-8x7B-Instruct-v02. We\ntried two settings: (1) an open-ended generation\ntask, and (2) a multilabel classification task. In\n(1), we give the model an ethical statement para-\ngraph and prompt to provide a comma-separated\nlist of words or phrases of the ethical concerns it\ncan identify. In (2), we provide the model with a\nclose-sourced vocabulary of ethical concerns based\non the annotations we have. We evaluated both\ntasks by using F1 BERTScore. This metric was\nintroduced by Zhang* et al. (2020), and it uses\ncontextual embeddings to measure their similarity.\nPlease refer to the Appendix for the model prompts\nand additional details.\nLet x = {x\u2081,x\u2082,...,x\u2098} be the embeddings for the\nreference annotation and x\u0302 = {x\u0302\u2081, x\u0302\u2082,...,x\u0302\u2099} be the em-\nbeddings for the candidate output. To measure the similarity\nbetween two individual embeddings, BERTscore uses cosine\nsimilarity. Precision (P) is computed as the average maximum\ncosine similarity for each token in the candidate output x\u0302 to all\ntokens in the reference annotation x. Recall (R) is computed\nas the average maximum cosine similarity for each token in\nthe reference annotation x to all tokens in the candidate output\n2. F1 Score (F\u2081) is then calculated as the harmonic mean of\nPrecision and Recall.\nResults. Results in Table 1 show that models per-\nform well, especially in a classification setup. In\nmost of the cases, the models correctly identify\nthe concerns and their predictions align with our\nannotations. After manually inspecting the output\nof the generation task, we observed a tendency for"}, {"title": "Human Survey: What ethical concerns\ndo people have?", "content": "We created a survey to gather insights on public\nconcerns regarding NLP technologies and compare\nthem with concerns among professionals in the\nfield.\nSurvey Design. The survey was designed after\nfive feedback rounds and pilot testing to ensure\nclarity, relevance, and reliability. It was distributed\nthrough various online platforms, social media, and\nmailing lists to reach a diverse audience. In the\nsurvey instructions, we included an initial consent\nstatement explaining the survey's purpose and the\nvoluntary, confidential nature of participation. In\nthe first section, we added some basic demographic\nquestions and an introductory question asking par-\nticipants' familiarity with NLP technologies. Then,\nthere was an open-ended question asking partici-\npants to provide any ethical concerns they might\nhave about NLP technologies. In the next section,\nparticipants were asked to rate their level of worry\non a scale from 1 (Not worried at all) to 5 (Very\nworried) across the most frequent categories in our\nEthiCon dataset: bias, misuse, privacy, misinforma-\ntion, privacy, toxicity, and environmental impact.\nLastly, we added a final open-ended question ask-\ning participants to add any further concerns they\nwould like to add that were not mentioned before.\nHuman Survey Analysis. We gathered 200 re-\nsponses with most participants being between 20\nand 40 years old. Based on the introductory ques-\ntion, we grouped participants into regular users and\nprofessionals (advanced users and professionals).\nFigure 5 shows the two groups are equally con-\ncerned about bias, fairness, and misinformation.\nThere is, however, a small disparity for privacy,\nmisuse, and toxicity issues which seem to concern\nregular users more. NLP professionals rate en-\nvironmental risks higher, possibly indicating that\nthe general public may not be fully aware of the\nresources and energy consumed during computa-\ntional tasks.\nBased on the open-ended questions at the be-\nginning and the end of the survey, we collected\nethical concerns before and after the given cate-\ngories were presented to the participants. In some\ncases, participants not only provided words sepa-\nrated by commas but also phrases or full sentences,\ne.g.:"}, {"title": "ACL EthiCon vs. Human Survey", "content": "Comparing the human survey with the ACL ethi-\ncal concern statements can highlight areas where\npublic apprehensions align with or diverge from\nthe priorities set by the research community. We\nfirst start by comparing the EthiCon dataset to the\nsurvey responses, and in the next section, we in-\nclude a broader comparison with existing concern\ntaxonomies.\nTo compare the top 15 most important words\nacross the two data sources, we calculated the TF-\nIDF scores for both the ACL EthiCon statements\nTF-IDF (Term Frequency-Inverse Document Frequency)\nis a statistical measure that reflects the importance of a word\nin a document. It is calculated as \\(tfidf(t, d, D) = tf(t, d)\nidf(t, D)\\), where \\(tf(t, d)\\) is the relative frequency of term t\nwithin document d (i.e., the number of times t appears in"}, {"title": "Taxonomies", "content": "There have been a few researchers that have tried\nto group concerns related to NLP into categories.\nSome have approached this from the perspective\nof risks, others from the perspective of harms or\nsocial impact, but addressing similar concerns. We\nsummarize the categories in Table 2. A compari-\nson highlights specific overlapping themes, such\nas bias, privacy, fairness, and misuse but also dif-\nferences in how the concerns are framed and cat-\negorized. There is however a great variety in the\ngrouping of concerns suggesting the lack of a clear,\nstructured, and up-to-date overview of concerns\nrelated to NLP. More recent discussions by Gabriel\net al. (2024) refer to AI value alignment, well-\nbeing, safety, misuse, and overall societal impacts,\nbut we could not infer a clear grouping or taxon-\nomy of concerns. Given the increasing integration\nof NLP technologies in our lives, there is a pressing\nneed for collaborative efforts to develop a unified\nframework that captures both existing and emerg-\ning issues.\nBased on the taxonomy provided by Weidinger\net al. (2021) we grouped our extracted concern-\nkeywords from the EthiCon dataset and the human\nsurvey in six risk areas. We selected this taxonomy,\nas it covers most of our collected concerns, and\nprovides extensive descriptions for each risk area.\nThe reason for comparing our identified concerns\nwith an established taxonomy is to discover any\noverlooked issues in current discussions. We manu-\nally mapped each concern to one of the six defined\nrisk areas, resolving ambiguities where possible.\nFor concerns that could not be clearly assigned to\nany of these risk areas, we categorized them under\n'Miscellaneous'.\nA summary of the risk areas and partial concern-\nkeyword groupings can be found in Table 3. Some\nof the keywords may belong to more than one\nrisk area. For example, copyright can constitute"}, {"title": "Discussion", "content": "We identified ethical concerns in ACL publications\nand showed promising results in automating their\nidentification. The number of ethical statements in\n2023 more than doubled compared to 2022, show-\ning similar recurring concerns. Automating this\nidentification process is useful for three main rea-\nsons. First, it makes these statements easier to parse"}, {"title": "Conclusion", "content": "We create a dataset of ethical concerns from ACL\nstatements to identify the issues that NLP re-\nsearchers flag as ethically concerning in their work.\nWe also conducted a human survey showing that\nlaypeople have different ethical concerns than the\nones typically flagged by professionals in the field.\nUnderstanding the ethical concerns raised by re-\nsearchers and comparing these to the concerns\nlisted by laypeople will enable the community to\nbetter respond to potential ethical challenges and\ncontribute to ongoing societal discussions. Lastly,\nwe believe it is possible to partially automate the\nidentification and analysis of ethical concerns, mak-\ning monitoring and longitudinal studies possible."}, {"title": "Limitations", "content": "We acknowledge that our study has several limi-\ntations. First, the corpus of ethical concern state-\nments is limited to papers published in the ACL\nAnthology, which may not represent all perspec-\ntives within the NLP community. Moreover, since\nwe scraped the current publications to extract the\nstatements, there might be publications that have\na statement and we could not identify it. We also\ndo not extract additional statistics from the pub-\nlications, such as the track, affiliation, and other\nmetadata. Second, the survey sample size may\nnot capture the full range of opinions across differ-\nent demographics. Even though we tried to share\nthe survey across many demographics, we did not\nrecord their geographic origin. Additionally, the\nautomated ethical annotation processes explored in\nthis study are still in the early stages and require\nfurther validation to ensure accuracy and reliability.\nFuture work should aim to address these limitations\nby expanding the dataset, surveying, and improving\nautomated ethical concern identification."}, {"title": "Ethics Statement", "content": "Our study aims to enhance understanding of ethical\nconcerns in the NLP community and is intended to\nbenefit both researchers and the general public by\npromoting ethical discussions in the field. We con-\nducted this research following ethical guidelines\nto ensure fair and respectful treatment of all par-\nticipants. Annotators were volunteers and authors\nin the paper. No personal or sensitive data were\nused. Participant consent was obtained for the sur-\nvey. The data we used are publicly available and\ndo not contain any private or sensitive information.\nACL anthology corpus is released under the CC\nBY-NC 4.0 license. There might be inherent biases\nfrom the annotators, and participants but we tried to\nprovide clear guidelines, and rounds of discussions\nto avoid them. In terms of resources, each run of\nour experiments lasted no more than 20 minutes\n(using one a40 GPU). This computation sums up\nto less than 7 hours (4 models * 5 runs * 20 mins =\n400 mins = 6 hours). We do not foresee any major\nrisks or ethical concerns."}]}