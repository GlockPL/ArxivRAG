{"title": "The Computational Learning of Construction Grammars: State of the Art and Prospective Roadmap", "authors": ["Jonas Doumen", "Veronica Juliana Schmalz", "Katrien Beuls", "Paul Van Eecke"], "abstract": "This paper documents and reviews the state of the art concerning computational models of construction grammar learning. It brings together prior work on the computational learning of form-meaning pairings, which has so far been studied in several distinct areas of research. The goal of this paper is threefold. First of all, it aims to synthesise the variety of methodologies that have been proposed to date and the results that have been obtained. Second, it aims to identify those parts of the challenge that have been successfully tackled and reveal those that require further research. Finally, it aims to provide a roadmap which can help to boost and streamline future research efforts on the computational learning of large-scale, usage-based construction grammars.", "sections": [{"title": "Learning Computational Construction Grammars", "content": "The aim of this paper is to survey prior work on the computational learning of con- struction grammars, to identify gaps in the state of the art and to propose a perspec- tive on the future of the field. The computational learning of construction grammars has traditionally been studied independently in different fields of research, in partic- ular linguistics, cognitive science, computer science and artificial intelligence. As a consequence, research on this topic has been fragmented and interaction between the researchers involved has been scarce, as witnessed by a lack of cross-referencing. In order to address this issue, this paper brings together the variety of methodologies that have been proposed in the literature and synthesises the results that have been achieved to date. Specifically, we define 14 criteria in light of which we review 31 mod- els of construction grammar learning. We then identify important gaps in the state of the art and propose a roadmap that can help streamline future research efforts and investments. Our hope is to inspire a new generation of construction grammarians to boost progress on scaling usage-based constructionist approaches to language.\nOn a high level, computational models for learning construction grammars are moti- vated by three main reasons. A first motivation is theoretical in nature and concerns the computational operationalisation and validation of usage-based theories of lan- guage acquisition. As usage-based theories of language argue that languages are learnt through their use in communication, computational models of language acquisition can contribute crucial evidence in favour or against the scalability of specific theoretical arguments (see e.g. Chang, 2008). Second, the use of computational models brings important methodological advantages, as it enforces the use of precise and testable operational definitions, allows for the detection of theory-internal inconsistencies, and facilitates a fine-grained comparison of different theories. Such comparisons can play an important role in identifying inter-theoretical knowledge gaps and divergences (Bender, 2008; M\u00fcller, 2015). Finally, the machine learning of construction grammars is impor- tant from an application and valorisation perspective, as it facilitates the use of con- struction grammar insights and analyses in broad-domain language technology appli- cations (van Trijp et al., 2022). Examples of such applications include visual question answering (see e.g. Nevens et al., 2022; Verheyen et al., 2023), the frame-semantic anal- ysis of discourse (see e.g. Willaert et al., 2020; Beuls et al., 2021) and the construction- based analysis of corpora (see e.g. EHAI, 2023). Apart from direct applications, com- putational models of language acquisition are also relevant to the broader fields of computational linguistics and artificial intelligence as they provide a method for intel- ligent agents to learn to communicate through protocols that exhibit the robustness, flexibility and adaptivity of human languages (Van Eecke, 2018; Beuls and Van Eecke, 2023).\nThe remainder of this paper is structured as follows. Section 2 presents the criteria that were used to include prior research efforts into this literature review, as well as the criteria in light of which these efforts are described in Section 3. Section 4 synthesises the state of the art, identifies challenges and opportunities, and proposes a roadmap for future research. Section 5 concludes the paper."}, {"title": "Methodology", "content": "2.1 Inclusion Criteria\nThe scope of this literature review concerns, to the best of our knowledge, all published prior research on the computational learning of construction grammars, as defined through the following inclusion criteria:\n1. Is the model concerned with learning form-meaning mappings? This criterion concerns the nature of the linguistic knowledge that is learnt. Concretely,"}, {"title": "Discussion Criteria", "content": "Prior work on learning construction grammars stems from different fields of research and therefore adopts a wide variety of methods, terminologies and experimental de- signs. In order to streamline the discussion and facilitate a meaningful comparison, we introduce 14 discussion criteria that will guide the review of the included models.\n1. Learning task. Which learning task does the model address? Which problem is the model designed to solve? Which evaluation criteria are used?\n2. Dataset. To which datasets has the model been applied?\n3. Input. What is the nature of the input to the model?\n4. Form complexity. What is the morpho-syntactic complexity of the linguistic input?\n5. Meaning complexity. What is the semantic complexity of the linguistic input?\n6. Grounding. Is the meaning representation grounded in a situation model?\n7. Segmentation level. What level of segmentation of the input is provided to the model (phonemes, graphemes, words or utterances)?\n8. Lexicon. Is a predefined lexicon provided?\n9. Grammatical categories. Is a predefined set of grammatical categories pro- vided?\n10. Incremental learning. Does the model learn in an incremental fashion, i.e. dynamically extending its knowledge after each exemplar?\n11. Bi-directional grammar. Can the learnt grammar be used for both language comprehension and production?\n12. Abstraction level. What is the level of abstraction of the learnt constructions? Is the grammar limited to item-based constructions and slot-filling constructions or does it include hierarchical and recursive constructions?\n13. Non-compositionality. Is the learning algorithm able to capture non- compositional aspects of language use? Is all meaning lexicalised or can gram- matical constructions also contribute semantic information?\n14. Benchmark. Is the data that was used during the learning and evaluation process precisely described and available to the community?\nApart from guiding the literature review, the discussion criteria are also used to organ- ise the schematic synthesis of the literature presented in Table 1. Here, qualitative de- scriptions are provided for learning task, dataset, input, form complexity and meaning complexity. Boolean values are used to assess the criteria of grounding, lexicon, gram- matical categories, incremental learning, bi-directional grammar, non-compositionality and benchmark. Segmentation level can either be \u2018phonemes', \u2018graphemes', or 'words', and abstraction level can either be \u2018item-based', or \u2018hierarchical', with only the high- est level of abstraction being listed. The information contained in the table reflects the properties of the models as presented in the papers that introduce them, without implying that any limitations are inherent to the methodologies."}, {"title": "Review of Prior Literature", "content": "This section provides a detailed review of all included models. A comparative analysis of all models in terms of the discussion criteria introduced in Section 2.2 is also provided in Table 1. Readers who are primarily interested in the higher-level picture can safely skip ahead to Section 4, where we present a synthesis of the details covered in this section.\nOn the highest level, the models can be organised according to the overall learning task that they are designed to tackle:\n1. Learning a maximally concise grammar. The task is to find a minimal set of constructions that optimally covers a corpus of language use.\n2. Learning a grammar from utterance-meaning pairs. The task is to learn a grammar that maps between utterances and their meaning representation, whereby a gold semantic annotation is provided for each utterance.\n3. Learning a grammar under referential uncertainty. The task is to learn a grammar that maps between utterances and their meaning representation, whereby a superset of the gold semantic annotation is provided. The referen- tial uncertainty stems from the fact that the exact meaning representation is not provided.\n4. Learning a grammar from a situation model. The task is to learn a gram- mar that maps between utterances and their meaning representation, whereby no gold semantic annotation is provided. The meaning has to be abductively derived from a situation model.\nThe following sections reflect the organisation of the models in terms of these four learning tasks."}, {"title": "Learning a maximally concise grammar", "content": "The first category of models addresses the task of finding a minimal set of construc- tions that optimally covers a corpus of language use. Dunn (2017) introduces a method to induce schematic patterns from large amounts of web-crawled corpus data. These patterns take the form of a sequence of slots that can be filled by word forms, morpho- syntactic categories or semantic categories. These categories are provided in the form of annotation layers. The resulting grammars are evaluated against a held-out test set in terms of various measures, including minimal description length and \u2206P entrench- ment (Ellis, 2006). Variations on the method are described by Dunn (2018, 2019, 2022, 2023) and Dunn and Tayyar Madabushi (2021). Mart\u00ed et al. (2021) present DISCO, a methodology for discovering constructional candidates in large web-crawled corpora of Spanish texts. Similar to Dunn (2017), the semantic categories integrated into the 'lexico-syntactic' patterns are modelled through as clusters over the distributional se- mantic representations of lemmata. The retrieved patterns are evaluated using statis- tical association measures as well as through manual evaluation by expert linguists.\nThis line of work models the induction of partially abstract patterns that combine form- related and meaning-related features. While relevant from a construction grammar perspective, the resulting patterns do not correspond to constructions that actually constitute mappings between aspects of form and meaning. These models thereby do not support mapping between utterances and their meaning representations."}, {"title": "Learning a grammar from utterance-meaning pairs", "content": "The second category of models addresses the task of learning a construction grammar from utterance-meaning pairs.\nDominey (2005a,b, 2006) and Dominey and Boucher (2005) present a neural model for the acquisition of holophrase constructions, item-based constructions and abstract con- structions that capture argument structure relations (e.g. transitives and ditransitives). Learners start with the capability to distinguish between closed-class and open-class words and learn to map between slots in the argument structure constructions and the semantic roles they take. Learning the meaning of open-class words is tackled as an initial cross-situational learning step. Item-based constructions are then learned from the remaining closed-class words (e.g. X was Y to Z by A) by storing the mapping of the order of thematic roles (e.g. object, action, recipient, agent) and these closed-class elements as constructions in the construction inventory.\nAlishahi and Stevenson (2008) present a computational model that mimics the ac- quisition of verb argument structure. The input utterance-meaning pairs are gen- erated based on the 20 most frequent verbs of a subsection of the CHILDES cor- pus (MacWhinney, 2000). An example would be the utterance \u201cMom put toys in boxes\" paired to the meaning representation PUT[CAUSE,MOVE](MOM (AGENT), TOYS (THEME), IN[] (BOXES (DESTINATION)) (DESTINATION)). The lexicon and semantic roles are given to the model a priori. A construction is defined as a probabilistic association between syntactic and semantic features of a verb and its arguments, which emerged over a number of observa- tions. Language processing is tackled as a Bayesian prediction problem. In production, the model predicts the syntax from a given semantic structure, and in comprehension, it predicts a (partial) semantic structure for a given utterance. The authors present experiments for both comprehension and production. The experiments show that the model exhibits effects of syntactic and semantic bootstrapping, that it can recover from over-generalisation, and that it is robust to noise, thereby mimicking the stages of child language acquisition.\nChang (2008) presents a set of learning operators that operationalise Bayesian model merging in the framework of Embodied Construction Grammar (ECG). The task is to learn a grammar that can correctly comprehend utterances from a held-out test set at certain intervals during training. The dataset that is used consists in a schema- annotated subset of the CHILDES corpus, containing parent-child interactions from a child from 15 until 24 months of age. A lexicon and ontology are provided, correspond- ing to the linguistic knowledge of a child at the two-word stage. Two classes of learn- ing operators are introduced: mapping operators and reorganisation operators. In the first class of operators, the simple mapping operator maps either all, or a part of the uncovered form to its co-occurring context information. Relational mapping creates a new construction that encodes the syntactic and semantic relations between existing constructions that could apply. The applied constructions become constituents in the newly formed item-based construction. For the input utterance \u201cthrow ball\u201d for exam- ple, the lexical constructions for THROW and BALL may already be known. A new con- struction is then created that encodes that THROW precedes BALL, and that the ball is the throwee in the throwing event. In the class of reorganisation operators, a structural alignment step pre-computes compatible alignments for further reorganisation. Next, three operators can apply: merging, joining and splitting. The merge operator learns a generalised construction for two constructions that contain shared structure. For ex- ample, THROW-BALL and THROW-BLOCK can be generalised to THROW-TOY. A second reorganisation operator joins existing constructions that have a certain overlap, for ex- ample HUMAN-THROW and THROW-BOTTLE can be joined into HUMAN-THROW-BOTTLE. Inversely, the splitting operator creates new constructions by taking the set difference between existing constructions, for example THROW-FRISBEE and THROW can be split into FRISBEE, and a new item-based construction, THROW-X, which takes the newly created FRISBEE-construction as a constituent. After the application of each applicable learning operator for a given input, the model uses minimum description length to select the shortest grammar that covers the data. The model is evaluated in relation to a hand-crafted gold standard grammar in terms of form and meaning coverage, and description length. The presented experiments operate at a rather small scale: first on 40 tokens of the verbs fall and throw, then on 200 tokens of caused-motion and self-motion predicates. The author reports that, in qualitative evaluation, both ex- periments show a resemblance to the stages described in the literature of usage-based language acquisition, i.e. going from concrete to increasingly abstract constructions.\nKwiatkowski et al. (2010) introduce a unification-based learning algorithm, which is designed to induce semantic parsers from corpora consisting of sentence and logical- form pairs. The model learns a lexicon and parameters in Combinatory Categorial Grammar (CCG). In CCG, a fixed set of combinatory rules is given, which govern how both categories and arguments of logical predicates can be combined. A lexical entry consists of a word form, its syntactic category and a logical predicate, for example: what F S / NP : Ax.answer(x). The model initially creates a holistic construction by mapping an entire sentence to its logical representation. The main generalisation operator splits these overly specific entries into smaller, more widely applicable lexical entries. Higher-order unification is used to restrict the number of hypotheses, while safeguarding the integrity and combinatory properties of the logical forms. As there are many possible analyses for a given sentence, a log-linear model is used to select the most likely analysis. Before training, the model is initialised with a list of NPs that are present in the data (e.g. Texas - NP : tex). The model is evaluated for four languages and two semantic representation formats on the GeoQuery dataset (Zelle and Mooney, 1996). Kwiatkowski et al. (2011) apply a further iteration of the same methodology to the more natural Air Travel Information System pilot corpus (ATIS \u2013 Hemphill et al., 1990). In contrast to the other work presented in this section, CCG assumes that meaning is fully lexicalised, and thereby that language is fully compositional.\nGerasymova and Spranger (2010, 2012) investigate the acquisition of holophrase con- structions, item-based constructions and abstract constructions, represented and pro- cessed using the Fluid Construction Grammar (FCG) framework (Steels and De Beule, 2006; van Trijp et al., 2022; Beuls and Van Eecke, 2023), for Russian aspectual mark- ing in a tutor-learner language game setting (Steels, 1998, 2001). Holophrase construc- tions are learnt by a straightforward mapping operation between an observed form and its meaning. Item-based constructions and abstract constructions are learnt as generalisations over pre-categorised lexical items. Beuls et al. (2010) apply the same methodology to the conjugation of verbs in Hungarian, with a special focus on its intricate agreement marking system. Garcia Casademont and Steels (2015, 2016) and Garcia Casademont (2018) apply the same paradigm to the acquisition of abstract, hierarchical and recursive constructions.\nDoumen et al. (2023) present a model of the co-acquisition of grammatical categories and form-meaning mappings, ranging from lexical to item-based constructions. The model operationalises Tomasello (2003)'s pattern finding mechanisms as a set of meta- layer learning operators in Fluid Construction Grammar. The base operator stores an entire utterance with its meaning representation as a holophrase construction. A sec- ond class of operators generalises over holophrase constructions and new observations. When a difference in both form and meaning is found, these operators learn the syn- tactic and semantic composition of the observation by means of substitution, addition and deletion operations, resulting in item-based constructions, lexical constructions and a network of emergent grammatical categories that governs how constructions can combine. A third class of operators starts from partial analyses. When an observa- tion is partially covered by one or multiple constructions in the agent's inventory, the model applies these to the utterance, and a new item-based or lexical construction is learned, along with corresponding categorial links. A final learning operator adds new categorial links if all constructions that are necessary to cover an utterance are known, but no links in the categorial network are found. The model is evaluated on a subset of the CLEVR dataset (Johnson et al., 2017)."}, {"title": "Learning a grammar under referential uncertainty", "content": "The third category of models addresses the task of learning a construction grammar under referential uncertainty. While the previous category of models took as input utterances paired with their semantic representation, this category of models takes as input utterances paired with a superset of their semantic representation. The fact that the meaning representation is noisy thereby poses an additional challenge to the learning task.\nA first line of work in this category focuses on aligning commentaries with observed ac- tions in Robocup football games, a task introduced by Chen and Mooney (2008). The input data concerns a list of natural language utterances of limited morpho-syntactic complexity, each paired with a number of candidate meaning representations. The cor- rect meaning representation for an utterance always consists in a single predicate. The task is then to learn a productive grammar that can map between utterances and their meaning representation. Along with the task and corpus, Chen and Mooney (2008) also present a method to induce probabilistic synchronous context-free grammars that can effectively be used for semantic parsing and meaning-driven language production. Gaspers et al. (2011) make use of the same task and corpus to develop and evaluate a method to learn construction grammars without strict supervision. In a first phase, a probabilistic lexicon is learned using a cross-situational learning algorithm (Fazly et al., 2010). The lexicon is restricted to sequences of one or two tokens, paired with one pred- icate or argument that occurs in the corpus. In a second phase, schemata are computed as generalisations over co-occurring lexical items and predicates or arguments. In par- ticular, lexical items appearing in the same syntactic environments are grouped into semantic equivalence classes. Then, schemata are constructed by substituting the lexi- cal items with abstract labels associated to their respective semantic equivalence class. Gaspers and Cimiano (2012, 2014) and Gaspers et al. (2016) present variations on this model, where the level of segmentation of the input is reduced from tokens through graphemes to phonemes.\nIntroducing the framework of Meaningful Unsupervised Data Oriented Parsing (\u03bc- DOP), Beekhuizen and Bod (2014) present a model that incrementally learns map- pings between nodes in binary trees and meaning representations expressed in pred- icate logic. The task that the model aims to solve is to find the correct predicate- argument structure for a given utterance in referentially ambiguous scenes. They ap- ply the model to artificial data that is not fully compositional on the meaning side, including for example idioms. At the start of an experiment, the construction inven- tory is empty. When presented with a new utterance, the model first attempts to apply any existing constructions. In order to induce syntactic structures, the model first generates all possible binary trees for a given utterance. Similarly, on the mean- ing side, the model decomposes the meaning predicates into all possible decomposi- tions. The arguments are replaced by slot indices. For example WATCH(E1, E2) can be further decomposed into P(E1, E2) and P : WATCH. All unanalysed nodes in the binary trees are then paired with all possible decompositions of parts of the semantic representation as candidate form-meaning pairs. These are then combined with the possible binary tree analyses to form a hypothesis space of possible analyses. As a last step, the model proceeds to extract all subtrees, and compares them to previously observed subtrees. If a subtree is found in multiple utterances' parse trees, then its prior probability of being a valid constituent increases. Non-compositional parts are retained by only allowing further decomposition at nodes where a meaning representa- tion is present. In both parsing and production, the derivation with the highest joint prior probability is selected, which in practice means that hypotheses with a smaller amount of subtrees are preferred. As a further evolution of this work, Beekhuizen et al. (2014) and Beekhuizen (2015) introduce the Syntagmatic-Paradigmatic Learner (SPL), which addresses a number of desiderata inspired by usage-based theories of language acquisition. As such, the generation of possible analyses, called derivations, is driven by a set of general structure-building operations, implementing parts-to-whole learning strategies. These operations allow for the concatenation of derivations, slot filling, syn- tactic bootstrapping, and ignoring words. The model is now applied to artificial data that is generated based on empirical research on noise, uncertainty, and situational continuation in child-directed communicative interactions.\nKwiatkowski et al. (2012) and Abend et al. (2017) introduce a probabilistic learning al- gorithm for combinatory categorial grammars (CCG), designed to model the human lan- guage acquisition process. This approach differs from earlier work by Kwiatkowski et al. (2010), presented in Section 3.2, in a few key aspects. An evident difference is that this model learns from utterance-situation pairs under propositional uncertainty, rather than having a single gold standard semantic representation for each utterance. A sec- ond difference is that the model is able to learn the lexicon, and the mapping between the lexicon and predefined categories from scratch, rather than relying on a list of noun phrases. An important assumption in this line of work is that a language-independent set of combinatory rules is provided to the model. The grammar is evaluated both quan- titatively and qualitatively using the Eve corpus (Brown, 1973), which was enriched with deterministically mapped logical forms based on dependency tree annotations."}, {"title": "Learning a grammar from a situation model", "content": "The final category of models addresses the task of learning a construction grammar from utterances observed during communicative interactions. As such, the meaning representation of the utterances is not provided, but needs to be abductively inferred from the situation in which the interaction takes place.\nSteels (2004) presents an initial experiment in which a population of artificial agents bootstrap argument structure constructions and grammatical categories from visually grounded meaning representations. The paper presents a description game, in which two agents from the population observe a scene that needs to be successfully described by one agent to the other. The scene is transcribed in terms of first order logic pred- icates. During conceptualisation, the speaker agent decides on the \u2018event profile' that they want to express (see e.g. Croft, 1998), i.e. deciding which roles have to be ex- pressed linguistically. Whether speaking or listening, an agent first makes use of its own construction grammar to process the conceptualised meaning representation or observed utterance. When an agent fails to formulate an utterance that expresses the conceptualised meaning representation or fails to comprehend an observed utterance in terms of the current scene, a game fails and a learning event takes place. When a game succeeds, the score of an agent's applied constructions is increased, while the score of competing constructions is decreased. Upon failure, the scores of the construc- tions that were used are decreased. Overall, the presented methodology shows how hierarchical semantic and syntactic categories can be learnt, and how the emergence of syntax aids to resolve ambiguity. van Trijp (2008, 2016) presents an extensive suite of follow-up experiments and shows how abstract semantic roles can emerge and evolve in populations of autonomous agents through multi-level selection strategies.\nArtzi and Zettlemoyer (2013) present a model where a seed lexicon, a predefined set of combinatory rules and a situation model are provided. The seed lexicon and combi- natory rules are used to generate hypotheses about the meaning underlying observed utterances, which can subsequently be validated against the situation model. The goal is to extend the seed lexicon with new items in order to solve a navigation task.\nSpranger and Steels (2015) and Spranger (2015, 2017) present a model of the acqui- sition of spatial language in embodied artificial agents. In a shared environment and through a tutor-learner language game, two agents interact with 15 different objects in over 1000 different spatial scenes. The goal is to simultaneously acquire the semantic and syntactic aspects of spatial language. Each communicative interaction proceeds as follows. The tutor agent selects formulates an utterance that uniquely refers to an object in the situational context. The learner agent comprehends and interprets the utterance with respect to the scene and points to the object that results from the inter- pretation process. Then, feedback is provided by the tutor in the form of pointing. If the learner agent misinterpreted the observed utterance, it needs to make a hypothesis about the intended meaning of the utterance. The agent does this by composing a procedural semantic network based on a set of cognitive operations that it can per- form. The observed form and hypothesised meaning can then be stored in the form of a holophrastic construction. Later, the agent can generalise over the constructions it knows and thereby construct more abstract constructions. The semantic classes of the slots in the more abstract constructions are predefined in an ontology that the learner can access.\nNevens et al. (2022) build further on the composition processes introduced by Spranger and Steels (2015) and the syntactico-semantic generalisation operators intro- duced by Doumen et al. (2023). They tackle the visual question answering benchmark introduced by Johnson et al. (2017) and are able to bootstrap a construction grammar that maps between English questions and visually grounded queries without ever having observed the queries. Through lateral inhibition alignment dynamics, gener- ally applicable constructions become gradually more entrenched, while suboptimal constructions, i.e. constructions that do not generalise to other scenes, for example due to suboptimal hypotheses about the intended meaning of an observed utterance, gradually disappear from the grammar."}, {"title": "Discussion", "content": "The low-level review of the prior literature in the previous section reveals perhaps most clearly that existing models for computationally learning construction grammars are highly diverse in nature and therefore challenging to compare. Their diversity is situ- ated on almost any level", "follows": "i) all linguistic knowledge is captured in the form of constructions, i.e. form-meaning pairings, (ii) there is no strict distinction between words and grammar rules, so that non-compositional aspects of the language can elegantly be captured, (iii) constructions cut across the different levels of linguistic analysis, and (iv) construction grammars are learnt, dynamic systems.\nAn important insight gained through the literature review is that prior mod- els typically score well on one or two of these dimensions, while suffering from substantial shortcomings on the others. As such, the models that address the large-scale dimension of the challenge, i.e. those by Dunn (2017, 2018, 2019, 2022, 2023), Dunn and Tayyar Madabushi (2021) and Mart\u00ed et al. (2021), do not yield individual grammars that support language comprehension and produc- tion. The scale of other models is restricted in one of three ways. Some mod- els cover specific linguistic phenomena only, such as basic argument structure (Steels, 2004; Dominey, 2005a,b; Dominey and Boucher, 2005; Dominey, 2006; van Trijp, 2008, 2016; Garcia Casademont and Steels, 2015, 2016; Garcia Casademont, 2018), aspectual marking (Gerasymova and Spranger, 2010, 2012), agreement mark- ing (Beuls et al., 2010) or spatial relations (Spranger and Steels, 2015; Spranger, 2015, 2017). Other models are applied to narrow artificial datasets, such as Robocup (Chen and Mooney, 2008; Gaspers et al., 2011; Gaspers and Cimiano, 2012, 2014; Gaspers et al., 2016), GeoQuery(Kwiatkowski et al., 2010, 2011), CLEVR (Nevens et al., 2022; Doumen et al., 2023), ATIS (Kwiatkowski et al., 2011), Navi (Artzi and Zettlemoyer, 2013), or other datasets specifically generated for evaluating the model (Beekhuizen and Bod, 2014; Beekhuizen et al., 2014; Beekhuizen, 2015). A final set of models makes use of small-scale corpora of transcribed children's speech (Alishahi and Stevenson, 2008; Chang, 2008; Kwiatkowski et al., 2012; Abend et al., 2017). The large-scale operationalisation of construction grammar learning thereby remains very much an open challenge.\nWhen it comes to the usage-based nature of the models, we can define a broad spectrum of possible approaches. On the most usage-based side of the spectrum, we would expect to find models that learn individual construction grammars from empirically observed communicative interactions, without access to a segmentation of the utterances, their meaning representations, or any predefined categories or lexical items. No models that satisfy all of these criteria were found in the literature. In fact, all prior models learn from utterances that are segmented on some level (phonemes, graphemes or words). Existing models that learn individual grammars without any access to annotated meaning representations are always learnt based on artificial utterances (Nevens et al., 2022), sometimes in combination with a predefined lexicon and system of categories (Artzi and Zettlemoyer, 2013; Spranger and Steels, 2015; Spranger, 2015, 2017). Other models that do not have access to exact meaning representations do have access to a superset of the meaning representations. These models learn from artificial utterances (Beekhuizen and Bod, 2014; Beekhuizen et al., 2014; Beekhuizen, 2015) or short nat- ural utterances (Chen and Mooney, 2008; Gaspers et al., 2011; Gaspers and Cimiano, 2012, 2014; Gaspers et al., 2016), sometimes in combination with a set of predefined combinatory rules (Kwiatkowski et al., 2012; Abend et al., 2017). Next, we find a class of models that learn from semantically annotated utterances. Some of these models learn construction grammars based on artificial data (Doumen et al., 2023), al- most always augmented with with a pre-defined lexicon (Steels, 2004; van Trijp, 2008, 2016; Garcia Casademont and Steels, 2015, 2016; Garcia Casademont, 2018), pre- categorised lexical items (Dominey, 2005a,b; Dominey and Boucher, 2005; Dominey, 2006; Beuls et al., 2010; Gerasymova and Spranger, 2010, 2012) or a predefined set of categories and combinatory rules (Kwiatkowski et al., 2010). Other models in this class learn from natural data augmented with pre-categorised lexical items (Alishahi and Stevenson, 2008; Chang, 2008) or a predefined set of categories and com- binatory rules (Kwiatkowski et al., 2011). A final class of models learns from natural data enhanced with morpho-syntactic and semantic annotation layers (Dunn, 2017, 2018, 2019; Dunn and Tayyar Madabushi, 2021; Mart\u00ed et al., 2021; Dunn, 2022, 2023). However, these models do not yield grammars that support language comprehension and production.\nThe third dimension concerns the degree to which the models adhere to the basic tenets of construction grammar. Fully constructionist approaches should support bi-directional language processing. They should capture all linguistic knowledge in the form of form-meaning pairings, allow for meaningful schemata above the word level, allow for combining information from different levels of linguistic analysis, and support incremental, individual and adaptive learning. On the most construction- ist side of this spectrum, we find approaches that explicitly make use of compu- tational construction grammar implementations to represent and process linguistic structures. Models adopting Fluid Construction Grammar (Steels"}]}