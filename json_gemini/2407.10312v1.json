{"title": "Effective Design Verification \u2013 Constrained Random with Python and Cocotb", "authors": ["Deepak Narayan Gadde", "Suruchi Kumari", "Aman Kumar"], "abstract": "Being the most widely used language across the world due to its simplicity and with 35\nkeywords (v3.7), Python attracts both hardware and software engineers. Python-based verification environment\nleverages open-source libraries such as cocotb and cocotb-coverage that enables interfacing the tesbenches\nwith any available simulator and facilitating constrained randomization, coverage respectively. These libraries\nsignificantly ease the development of testbenches and have the potential to reduce the setup cost. The goal of\nthis paper is to assess the effectiveness of a Python-Cocotb verification setup with design IPs and compare its\nfeatures and performance metrics with the current de-facto hardware verification language i.e., System Verilog\n[1].", "sections": [{"title": "I. INTRODUCTION", "content": "With the conclusion of Dennard scaling [2] and the deceleration of Moore's law [3], the design of System-on-Chip\n(SoC) has become increasingly challenging. As the transistor size is shrinking at a remarkable rate, the total count\nof transistors in a chip has increased exponentially over the years. This results to more functionality in the same\ndie area, hence increased design complexity [4]. With such an increase in complexity of designs, the time required\nfor verification experiences a significant upsurge. In comparison to directed tests, Constrained Random Verification\n(CRV) technique improves the productivity gain significantly [5]. This methodology is crucial because it saves time\nin achieving coverage closure. The traditional method of using targeted tests to verify specific design elements grows\nexponentially with the number of inputs, hence there is a requirement for speeding up CRV [4].\nThere has been growing trend in the use of Python as high-level and general-purpose programming language.\nRenowned for its conciseness and formidable capabilities, it has emerged as a cornerstone for pioneering technologies,\nprominently encompassing artificial intelligence, automation, machine learning, General Purpose Interface (GPI), and\nnetworking [6][7]. Additionally, the success of Python is due to (i) a simple and clean syntax, (ii) interpreted and\ndynamically typed (iii) object oriented (iv) huge ecosystem, (v) a rich standardized libraries that is conveniently\navailable, and (vi) very good documentation and help support [8][9].\nFor the functional verification, Hardware Verification Language (HVL) Verilog was transitioned to SystemVerilog\nin order to incorporate numerous powerful programming features, particularly object-oriented programming with\nadditional capabilities such as constrained random data generation and functional coverage [9]. SystemVerilog, which\nis also used as a language construct for industry-utilized verification methodologies like Metric Driven Verification\n(MDV) and CRV, is a complex language with a steep learning curve especially for engineers who are new to\nhardware verification. It requires very good understanding of digital design concepts and a thorough grasp of\nthe language syntax and constructs. Developing an efficient and robust testbench in SystemVerilog can be time-\nconsuming [9]. Figure 1 shows that HVL i.e., SystemVerilog, is the most complicated language in comparison with\nother programming languages which has 1315 specification pages and 248 keywords as per IEEE 1800-2012. On\nthe other hand, Python (v3.7) is a high-level programming language with only 35 keywords and 600 specification\npages with 1750 full standard libraries [10]. While SystemVerilog follows a set format, various Electronic Design\nAutomation (EDA) tool vendors might incorporate the format differently within their simulation tools. Although it\nis widely used, there can be variations in the level of tool support across different vendors [11]."}, {"title": "II. BACKGROUND", "content": "The main goal of functional verification is to test the verification target, thereby guaranteeing accurate and\ncomprehensive functionality [12]. The present design verification stage utilizes a well- established technique for\nlarger designs known as simulation- based verification. Such modern methodologies involve a largely automated\nprocedure encompassing test generation, checking, and coverage collection, combined with instances of manual\ninvolvement [13]. One of the methodology is CRV where stimulus generation, scenarios can be generated in an\nautomated fashion under the control of a set of rules, or constraints, specified by the user [14]. Another notable\napproach rooted in simulation is the Universal Verification Methodology (UVM), which employs Transaction Level\nModeling (TLM) for the creation of testbenches. It is a class library that makes it easy to write configurable and\nreusable code [5]. All the technologies discussed uses SystemVerilog as their language construct. In contrast, this\npaper discusses simulation-based verification for 3 designs detailed in section III, using Python as HVL and cocotb,\ncocotb-coverage libraries.\nThe authors in paper [15] presents an explanation of the Python-based verification methodology along with\na discussion on code coverage data obtained from verifying a design Intellectual Property (IP) using a Python\ntestbench. A similar work is done in paper [16], that extends Cocotb to provide constrained randomization and\nfunctional coverage constructs. The paper also motivates to enable the implemented mechanisms to be adopted by\nverification engineers, taking advantage of Python syntax and object-oriented approach. Nevertheless, these works\ndid not discuss feature, performance comparison with respect to the other verification methodologies. PyVSC is a\nlibrary supported by Python that has the same functionality as cocotb-coverage library to support randomization\nand functional coverage [17]. The work claims that PyVSC will make it easier for SystemVerilog practitioners to\nreuse their knowledge of constraints and coverage in Python. The work [18] employs Cocotb to model the Python\ntestbench for a comparator designed in Verilog and an open-source simulator Icarus Verilog for simulating the\ntestbench. Additionally, machine learning technique is implemented to optimize design verification. In the paper\n[19], the testbench is written in Python to develop a library (VeRLPy) for the verification of digital designs with\nreinforcement learning.\nThe related works elaborated above mostly discusses creating Python testbench using Cocotb, how SystemVerilog\nfunctional coverage constructs are supported by Python library like PyVSC. But none of them examines the\ncomparison of the verification methodologies or language construct(s) used for the methodologies. In this work,\nwe try to address the simulator compatibility, feature comparison between HVLs, its performance in terms of run-\ntime."}, {"title": "III. IMPLEMENTATION", "content": "The verification implementation with Python-Cocotb involves three key components: Design Under Test (DUT),\nTestbench written in Python, and a Makefile. These building blocks play crucial roles in carrying out the verification\nprocess as discussed below."}, {"title": "A. Design", "content": "The DUT in the Python-Cocotb testbench can be designed in any Hardware Description Language (HDL)\ni.e., SystemVerilog, Verilog, or VHDL. For this paper, we carefully selected three different designs for thorough\nverification. These choices were made based on important factors that enhance the significance of their verification.\nA short explanation to the design IPs used in this work is as follows:\n1) ALU\nThe 32-bit ALU, a combinational design written in Verlilog, carries out a range of operations on the input signals\nand generates 32-bit output. It supports two arithmetic operations, namely addition and subtraction, and also provides\nfunctionality for six logical operations: NOT, AND, OR, XOR, NAND, and NOR. In Figure 3, (a) depicts the block\ndiagram of 32-bit ALU where input buses a and b, control bus op, and output bus r are responsible for transmitting\ntheir corresponding signal data. Its computational capabilities finds applications in modern processors."}, {"title": "B. Python Testbench", "content": "The verification setup consists of a top testbench, where Cocotb connects the Python testbench with the simulator.\nIt also provides the Python library for creating synchronous logic. In this setup, the testbench uses constrained\nrandomization of signals and bin definitions for analyzing functional coverage. These capabilities are supported by\nthe cocotb-coverage library.\nThe basic structure of general Python-Cocotb testbench is explained using ALU testbench in Listing 1. Firstly,\nthe important required modules are imported, for instance, cocotb, and all the objects from cocotb-coverage module.\nThen the tests specified in the testbench is automatically discovered by Cocotb using cocotb.test() decorator\u00b9 during\nsimulation run. The clock is generated succeeded by signals being constrained and randomized. These signals are\nsent to DUT and reference model. The coverage sample function is called and finally the outputs from DUT and\nreference model are asserted."}, {"title": "C. Makefile", "content": "A verification environment set-up needs a build option Makefile. It contains information about the project, starting\nfrom EDA tool to top level instantiation. Listing 2 shows the Makefile for setting up the testbench environment for\nALU. After the exceution of command in line 8, the libraries gets compiled and simulator starts."}, {"title": "IV. RESULTS", "content": "The three design IPs i.e., ALU, I2C slave, and ADC are verified in SystemVerilog-UVM and Python-Cocotb\ntestbenches and investigated compatibility of Cocotb with commercial simulators like Cadence Xcelium [20] and\nSiemens Questa [21]. Additionally, an open-source simulator Verilator [22] is explored."}, {"title": "A. Features Comparison", "content": "While implementing the verification environments with SystemVerilog and Python as HVLs, they are found to have\nsetup advantages with Python over SystemVerilog like, setting up test environment with any simulator only requires\nto modify makefile variable SIM. Table I shows other features compared for both verification implementations."}, {"title": "B. Performance Metrics", "content": "Based on simulation results, certain performance metrics are defined. These metrics are analyzed and compared\nfor both verification environments i.e., Python-Cocotb and SystemVerilog-UVM in this subsection."}, {"title": "1) Design Hierarchy", "content": "The hierarchy in the simulators design browser is different in SystemVerilog-UVM and Python-Cocotb testbenches.\nThe SystemVerilog-UVM testbench includes the top testbench whereas Python-Cocotb starts with the DUT or\nTOPLEVEL defined in the build option, as explained in Figure 5. This results in the limitation of Python-Cocotb\nsince it hinders the debugging capabilities of the testbench signals."}, {"title": "2) Simulation run-time", "content": "The Python-Cocotb and SystemVerilog testbenches are compared in terms of simulation run-time. They are\nsimulated using various simulators such as Xcelium, Questa, and Verilator, with detailed testbench specifications\nprovided in subsection III-B. During the simulation, it became evident that Verilator cannot simulate I2C and ADC\ndesigns due to non-synthesizable nature of I2C design used for this work whereas ADC design required substantial\nmodifications to verilate it. But ALU design got simulated with Verilator, showing similar run-time performance as\nXcelium.\nAdditionally, it is observed that the simulation run-time of Python-Cocotb testbenches is slower compared to that\nof SystemVerilog or SV-UVM testbenches, as demonstrated in Figure 6a, Figure 6b, and Figure 6c. This difference\nis attributed to the reasons discussed. Generally, SystemVerilog employs simulation directives and commands to\nestablish communication with the simulator. The close integration between SystemVerilog-UVM and the simulator\nenhances simulation execution, resulting in relatively shorter run-time. Conversely, the interaction between Python\ntestbenches and the simulator via VPI/VHPI is typically slower and less tightly integrated than the direct interac-\ntion between SystemVerilog-UVM and the simulator. This overhead becomes more significant as the number of\ntransactions increases, leading to longer simulation run-time for Python-Cocotb testbenches."}, {"title": "3) Coverage Analysis", "content": "Table II details the bins defintion for all the cover items for design IP, i.e., ALU, I2C, and ADC along with\nthe results. The coverage model defined was same in both SystemVerilog and Python testbenches and the results\nobtained were also similar in both cases. For ALU and ADC, the total coverage obtained in 100% for the bins"}, {"title": "V. EMPIRICAL OBSERVATIONS", "content": "While implementing the verification enivironments for the design IPs i.e., ALU, I2C, and ADC with Python-Cocotb\nand cocotb-coverage, there are some observations made as listed below.\n1) ALU: While utilizing the Python-Cocotb testbench (i) If the input signals a, b, and op are not initialized, it\ngives Assertion Error in the first clock cycle and simulation stops. Therefore, it is crucial to initialize the input\nsignals before performing any operation. (ii) The bins definition for covering ALU signals has to be specified\nexplicitly. If auto bins are attempted to be created for this design IP, it requires a significant amount of space\nfor the number of bins to be generated and results in a memory error.\n2) I2C: SDA is open-drain terminal, so it has to be pulled up through a resistor. Python-Cocotb lacks native\nsupport for pull-up/pull-down signals and tristate logic, a workaround is achieved by introducing an HDL\nwrapper. In contrast, SystemVerilog, being a HDL, provides built-in support for pulling up any signal, and\ndoes not need an additional wrapper. Figure 7 details the workaround to include tristate logic in Python\ntestbench.\n3) ADC: Analog simulation package that lets real number modelling in SystemVerilog, are not supported in the\nPython-Cocotb. It gives VPI error (Communication error). To convert the real input analog_in to 64-bit digital\ninput, the datatype is defined as real type. This 16-bit signal is then sent to the design. Listing 3 and 4 show\nthat analog_pack_sv module is imported in the adc wrapper for SystemVerilog testbench whereas the input\nanalog_in is declared as real datatype for Python testbench respectively."}, {"title": "VI. CONCLUSION", "content": "In this paper, We analyzed the verification of three designs using Python-Cocotb and SV-UVM in three simulators.\nWhen running Python-Cocotb testbenches, it is found that the simulation run-time increases with increase in trans-\naction count for the multiple simulation run. This behavior is attributed to the communication between the testbench\nand simulators through VPI/VHPI, which involves longer interaction times with the simulators. Consequently, the\noverall simulation run-time is extended. Nevertheless, this interaction via GPI provides necessary hooks to access\nand control the simulator's internal data structures, signals, and events.\nConcerning the CRV and functional coverage in Cocotb, the constrained randomization of the input signals and\ncoverage constructs are derived from cocotb-coverage library. The coverage analysis yields results similar to those\nobtained in SystemVerilog.\nDespite Python's interactive and user-friendly coding nature, the testbench is not included in the design hierarchy\ndue to Cocotb's co-simulation approach. If the testbench can be integrated into the top of the hierarchy, it would\ngreatly improve debugging capabilities by facilitating the tracing back of signals. Combining Cocotb and Python\nlibraries, and machine learning techniques holds promise for enhancing the verification process."}]}