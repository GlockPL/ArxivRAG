{"title": "Lightweight Authenticated Task Offloading in 6G-Cloud Vehicular Twin Networks", "authors": ["Sarah Al-Shareeda", "Fusun Ozguner", "Keith Redmill", "Trung Q. Duong", "Berk Canberk"], "abstract": "Task offloading management in 6G vehicular networks is crucial for maintaining network efficiency, particularly as vehicles generate substantial data. Integrating secure communication through authentication introduces additional computational and communication overhead, significantly impacting offloading efficiency and latency. This paper presents a unified framework incorporating lightweight Identity-Based Cryptographic (IBC) authentication into task offloading within cloud-based 6G Vehicular Twin Networks (VTNs). Utilizing Proximal Policy Optimization (PPO) in Deep Reinforcement Learning (DRL), our approach optimizes authenticated offloading decisions to minimize latency and enhance resource allocation. Performance evaluation under varying network sizes, task sizes, and data rates reveals that IBC authentication can reduce offloading efficiency by up to 50% due to the added overhead. Besides, increasing network size and task size can further reduce offloading efficiency by up to 91.7%. As a countermeasure, increasing the transmission data rate can improve the offloading performance by as much as 63%, even in the presence of authentication overhead. The code for the simulations and experiments detailed in this paper is available on GitHub for further reference and reproducibility [1].", "sections": [{"title": "I. INTRODUCTION", "content": "Managing computational demands and ensuring secure communication in 6G vehicular networks presents a formidable challenge. As vehicles generate vast amounts of data, offloading computational tasks to cloud or edge servers is essential for maintaining network efficiency. However, this offloading must be meticulously managed to avoid introducing significant latency, particularly in 6G environments that promise ultra-low latency [2]. Additionally, secure communication across various network interactions is vital. However, the overhead introduced by authentication frameworks, especially in high-frequency 6G scenarios with limited coverage, can significantly impact the efficiency of offloading [3], [4].\nExisting research on 6G vehicular networks has primarily addressed task offloading [5]\u2013[13] or authentication [4], [14]\u2013[18] in isolation, leaving a critical gap in understanding the combined impact of authenticated task offloading within 6G vehicular networks. The interplay between authentication overhead and offloading efficiency still needs to be explored. This study addresses this gap by developing a unified framework integrating authentication with task offloading within 6G vehicular networks. To facilitate the assessment of the unification, our work leverages two key concepts: Vehicular Twin Networks (VTNs) and Deep Reinforcement Learning (DRL). VTNs, digital replicas of physical networks, utilize Digital Twins (DTs) hosted on cloud or edge servers to mirror vehicles and Roadside Units (RSUs). These DTs provide a comprehensive view of the state of the network, enabling more efficient management of the offloading processes [19], [20]. In addition to VTNs, we employ artificial intelligence to model the authenticated offloading latency by formulating it as a DRL task. Specifically, we evaluate the performance of VTNs with IBC-integrated authentication under realistic 6G conditions, focusing on the total latency of the offloading process, from task generation and signing by the vehicle through offloading to the cloud to final reception and verification by the car. We implement a Proximal Policy Optimization (PPO) variant of the DRL model to minimize latency, ensuring efficient task management within the 6G vehicular network. In this context, our main contributions, as illustrated in Fig. 1, are:\nC1. Integrating lightweight Identity-Based Cryptographic (IBC) authentication into task-offloading processes within 6G vehicular networks.\nC2. Defining the model-based VTN architecture where vehicles' twins adapt offloading decisions in the cloud to optimize resource allocation and minimize latency based on real-time network conditions.\nC3. Developing a PPO-DRL agent that optimizes authenticated task offloading decisions and resource allocation to minimize latency.\nThe remainder of this article is structured as follows. Section II reviews the 6G vehicular networks literature, focusing on authentication and offloading. Section III presents our IBC-based authenticated task offloading architecture for cloud-based VTNs and outlines the offload latency formulation for performance evaluation. Section IV develops the PPO-DRL model and algorithm. Section V covers the simulation settings and"}, {"title": "II. MINI LITERATURE REVIEW", "content": "Various research has developed robust authentication schemes tailored to the specific requirements of 6G vehicular networks. Cheng et al. [4] investigate conditional privacy-preserving multi-domain authentication within the Internet of Vehicles in 6G networks. Their framework combines pseudonym management with multi-domain authentication to ensure robust privacy protections without sacrificing performance. Vijayakumar et al. [14] propose an anonymous batch authentication and key exchange protocol to reduce the overhead associated with authentication in 6G-enabled vehicular networks' high-mobility scenarios. With the advent of AI, Zhou et al. [16] propose a fine-grained access control approach that utilizes IBC authentication in conjunction with Deep Learning (DL). Their approach effectively manages access control while detecting cyber-attacks with high accuracy. Similarly, Hui et al. [17] propose an AI-driven framework for secure and personalized edge computing services in 6G heterogeneous vehicular networks. As the concept of DTs becomes increasingly relevant, Soleymani et al. [18] develop a privacy-preserving authentication for cybertwin-based 6G networks. However, they do not incorporate any AI techniques; instead, they focus on the challenges of twin integration.\nAside from authentication, task offloading is another critical focus area in 6G vehicular networks, driven by the need to manage these environments' vast data and computational demands. Hierarchical and multi-layered offloading frameworks are investigated to address the complexities of 6G environments. Men et al. [5] propose a hierarchical aerial computing framework that utilizes the mobility of drones and edge servers to enhance task offloading and resource allocation in scenarios where ground-based resources are insufficient. Shen et al. [6] focus on resource allocation in Space-Air-Ground integrated vehicular networks through a slicing-based task offloading mechanism. Their framework ensures efficient utilization of heterogeneous resources across different network layers. Adaptation to dynamic network conditions is another essential aspect of task offloading in 6G environments. Maleki et al. [7] introduce a dynamic offloading scheme that is handover-enabled, adjusting to real-time network conditions and vehicle mobility patterns. Liu et al. [8] further contribute an energy-efficient joint computation offloading and resource allocation strategy.\nIt balances computational efficiency with energy consumption by offloading tasks to edge and cloud servers. Utilizing AI, Zhou et al. [9] present an edge offloading that integrates RL with content caching to optimize offloading decisions in the 6G-enabled Internet of vehicles. Similarly, Fofana et al. [10] apply DRL for intelligent offloading in vehicular networks. Their method dynamically adjusts the offloading strategies based on real-time computational demands. Integrating DT technology with Al-driven task offloading has been introduced by Li et al. [11]. They introduce FlexEdge, a DT-enabled UAV-aided vehicular edge computing framework. This approach uses DTs to model vehicles and UAVs, optimizing real-time offloading decisions via a PPO-DRL-based algorithm. Similarly, Tan et al. [12] explore adaptive task scheduling in DT-empowered cloud-native vehicular networks. Hevesli et al. [13] optimize task offloading in DT-assisted edge Air-Ground industrial IoT 6G networks, using DTs and a deep Q-network (DQN) to make real-time decisions on task processing across edge, cloud, or ground resources.\nExisting studies tend to focus on either authentication or task offloading in isolation. Our contribution addresses this gap by developing a unified framework that integrates authenticated task offloading within 6G vehicular networks, models it through vehicular cloud twins, and optimizes its performance using AI techniques, as seen in Fig. 1."}, {"title": "III. IBC-BASED TASK OFFLOADING IN 6G-VTNS", "content": "We have developed a cloud-based IBC-authenticated VTN architecture, as shown in Fig. 2. The physical layer comprises n vehicles traveling along a highway, each equipped with fv GHz of computational resources and moving at vv. km/h. The architecture's twin layer includes a cloud server with a Fcloud GHz computational capacity. Vehicle-to-Infrastructure (V2I) communication between any vehicle Vi and the cloud server occurs at a data rate of Ticloud Mbps, reflecting the lower end of the 6G spectrum to account for signal attenuation and the challenges of maintaining stable connections at higher frequencies. The cloud server hosts the virtual counterparts of the vehicles, referred to as Twinv..\nBefore deployment, a Trusted Authority (TA) sets the parameters of the IBC authentication [3], [21] elliptic curve at an L bit security level. It involves selecting an L bit prime p, a Galois field Fp, a curve $E : y^2 = x^3 + ax + b mod p$ (a, b, x, y \u2208 Fp), and a group G of points (x,y) on E, with a generator P of order q with a bit length of 2L. The TA generates its main secret key skta \u2208 Z and computes the corresponding public key pkta = skta \u00b7 P. The TA then assigns a long-term identity $ID_{cloud} = r_{\u00e8loud}.P mod q \u2208 G$ to the server, where $r_{eloud} \u2208 Z$. The TA also creates five hash functions h\u2081()-h5() that produce hashed scalar digests \u2208 Z from inputs of {0,1} of any length. Two pseudo-point identities \u2208 G, $SID^1_{loud}$ and\n$SID^2_{cloud} = ID_{cloud}\u2295h1(sk_{TA}\u00b7SID^1_{loud}, PK_{TA}) mod q$ (1)"}, {"title": null, "content": "are also generated for the server. From these pseudo identities $SID_{cloud} = \u3008SID^1_{loud}|SID^2_{loud}\u3009$, alias scalar keys,\n$sid_{cloud} = r^2 rcloud+h2(SID_{cloud})\u00b7sk_{TA} mod q \u2208 Z$(2)\nare created. The TA can track the server's identity via:\n$ID^{track}_{cloud} = h(sk_{TA}\u00b7SID^{-1}_{cloud}, pk_{TA})\u00b7ID_{cloud} mod q$. (3)\nWhen a vehicle registers with the TA, it receives all elliptic curve parameters except the TA's main secret key skTA. The vehicle Vi is also assigned a long-term identity IDv\u2081, pseudo identities SIDV and SIDV, and alias keys sidv\u0119, computed similarly to IDcloud, SID (1), and (2), with different random numbers r and r\u2208 Z. The TA keeps track of the generated identities for accountability, using $ID^{track}_{v_i}$, calculated as in (3). The Twiny, is stored on the server as \u3008IDv\u2081, SIDv\u2081 = {SID\\\u00a5\\SID}, sidv\u2081, IDtrack, fv\u2081, vv).\nThe vehicles perform a safety task of size Sv bytes. To secure the task at a timestamp tv, the vehicle signs the hashed task. Vi dynamically generates secret and public keys sky; \u2208 Z and pkv\u2081 = skv; \u2022 P \u2208 G to ensure anonymity. Using the first-tier alias identities SIDV and SIDV, V\u2081 extracts second-tier dynamic alias identities via h3() and h4() as:\n$h_{3,4}(SID_{v_i}|tv_i) = h_3(SID^1_{v_i}|tv_i)|h_4(SID^2_{v_i})$. (4)\nHashing increases the randomness of the generated signature \u03c3\u03bd. Using the alias key sidv, dynamically generated keys, and hashed alias identities:\n$\u03c3_{v_i} = sid_{v_i} + h_5(pk_{v_i}|h_{3,4}(SID_{v_i}|t_v)|S_{v_i}|tv_i).sk_{v_i} mod q$ (5)\nrepresents Vi's scalar signature on task Sv. Thus, the secured signed task is defined as $dv_i = (S_{v_i}, tv_i,pk_{v_i}, SID_{v_i}, \u03c3_{v_i})$.\nThe IBC-authenticated task dv\u2081 requires signing $C_{signv}$ cycles/byte and verification $C_{verifyv_i}$ cycles/byte computation resources. If the task is processed locally at the vehicle Vi, the execution latency Tv is computed as:\n$Tv_i = dv (C_{signv_i} + C_{verifyv_i})/f_{Vi}$ (6)\nHowever, vehicles typically prefer to offload their IBC-authenticated computation tasks to the cloud server, leveraging its higher computational power, especially within the 6G framework that supports high-speed data transfers. When the task is offloaded, the cloud first verifies the authenticity of dv. After checking the freshness of the received timestamp tv, the server ensures that:\n$\u03c3_{v_i}\u00b7P SIDV + h_5(pk_{v_i}|h_{3,4}(SID_{vz}|t_v)|S_{v_i}|tv_i)\u00b7pk_{v_i}$\n$+h_2(SIDV)\u00b7pk_{TA}$ (7)\nholds. If so, the computation time for the task in the cloud is determined by the time needed to verify the task as in (7), using dedicated cloud computing resources feloud. Once verified and processed, the cloud signs and communicates the result to the vehicle Vi. The total time for this process is:\n$TV_{icloud} = \\frac{dvi}{Tupload_{icloud}} + \\frac{dvi. (Csignv_i + Cverifyv_i)}{fcloud} + \\frac{dvi}{Tdownload} + 2\u00b7\\frac{Dcloud}{S}$ (8)\nthe calculation includes the task uploading time to the cloud, processing on the server, downloading the result back to the vehicle, and propagation delay, considering the distance to the cloud Dcloud km and the speed of light s m/sec.\nAs illustrated in (6) and (8), the task computation time can vary depending on whether the task is processed locally on the vehicle or offloaded to the cloud server. Consequently, the total task execution latency for n vehicles is:\n$\u03c4_{total} = \u2211 [(1 - xv)Tv + xv. TV_{icloud}]$, (9)\nwhere the decision to compute the task locally or remotely is denoted by \u00eev \u2208 {0,1}."}, {"title": "A. IBC Authentication: Correctness and Security Proofs", "content": "The IBC authentication scheme can be validated for correctness, as the verification of signed tasks at any receiving end from any sending end is successful when the following conditions are met:\n$[SID_{v_i} \u2209 revoked] \u2229 [h_2(SID_{v_i}) = Correct] \u2229\n[h_3(SID^1_{v_i}|tv_i) = Correct] \u2229 [h_4(SID^2_{v_i}|tv_i) = Correct] \u2229\n[h_5(pk_{v_i}|h_{3,4}(SID_{v_i}|tv_i)|S_{v_i}|tv_i) = Correct] \u2229\n[verify(P,pk_{TA}) (\u03c3_{v_i}) = valid]$. (10)\nRegarding security, the IBC framework ensures resistance to replay attacks using timestamps tv. It prevents man-in-the-middle, modification, impersonation, and masquerading attacks by applying hashing functions h\u2081() to h5(). These features protect against any adversary manipulating or compromising the network's legitimate entities, especially in the 6G vehicular networks, where high-speed and reliable communication is paramount. The scheme also demonstrates existential unforgeability against an Adaptive Chosen Message Attack (CMA),"}, {"title": "IV. DRL-BASED ASSESSMENT MODEL DEVELOPMENT", "content": "We develop a PPO-DRL agent to minimize the total authenticated offloading latency, Ttotal, as expressed in (9), by making decisions regarding offloading and resource allocation, subject to the following constraints:\n$\u0390_{v_i} \u2208 {0,1} 1 \u2264 i \u2264 n and$ (9a)\n$\u2211 f_{v_i}+f_{cloud} \u2264 F_{cloud}  0 < f_{Vi} \\leq f_{cloud} \u2264 F_{cloud}$. (9b)\nThe formulation of the DRL model defines the environment, state, agents, actions, rewards, and policy. Our environment, represented by the twin layer, includes Twiny, and the upload/download data rates, Ticloud. The state of the environment reflects the current conditions. The state vector Statecloud captures these features for each vehicle:\n$State_{cloud} = {dv, Csignv, Cverifyv, fv, Tuload/download}$. (11)\nThis state vector is fed into the DRL agent, which includes an actor to propose actions and a critic to evaluate them. The actor operates with both discrete actions \u00eev, and continuous actions fcloud, forming our action space:\n$Action_{cloud} = {xv, f_{cloud}}$. (12)\nFor Actioncloud, the agent receives a reward from the environment, defined as Rewardcloud = -Ttotal, where the reward is designed to minimize the total latency across all vehicles.\nThe actor has a neural network that takes Statecloud as input and has three output layers; one uses a sigmoid activation for offloading decisions \u00eev \u2208 {0,1} and two generate the mean and standard deviation for resource allocation foud. The actor's policy \u03c0\u03bf, with parameters 0, uses the categorical distribution to choose discrete actions and a Gaussian distribution for continuous ones. The log probabilities of these actions are then computed as follows:\n$log(p(\u03c0\u03bf)) = log(p(Categorical(\u00ee_{v_i})))+\nlog(p(Normal(mean(floud), std(f^{cloud}))))$. (13)\nThe critic assesses the actor's actions by estimating the state value. The critic neural network processes Statecloud through fully connected layers similar to the actor's architecture. The resulting state value is used to compute the advantage function \u00c2, quantifying the actions' effectiveness. The advantage \u00c2 is the difference between the critic's estimated state value at time t and the value of the subsequent state:\n$\u00c2\u2081 = Reward\u207a + y statet+lue - state value$, (14)\nwhere y is the discount factor balancing immediate and future rewards. We employ the PPO clipping mechanism to optimize the \u03c0\u03b8 policy while ensuring stable learning and constraining policy updates within a predefined range. The PPO clipping loss function LClip(\u03c0\u04e9) is formulated as:\n$L_{Clip} (\u03c0\u03bf) = E[min(r(\u03c0\u03bf)\u00b7 \u00c2, clip(\u00ee(\u03c0\u03bf), 1 \u2013 \u20ac, 1 + \u20ac). \u00c2)]$, (15)\nwhere r(\u03c0\u03bf) is the ratio of new to old policy probabilities, and \u00ea is the clipping hyperparameter controlling the extent of policy updates. To further enhance stability, we incorporate an entropy term into the loss function:\n$L_{Clip} (\u03c0\u03bf) = L_{Clip} (\u03c0\u03bf) \u2013 H_{coefficient} \u00b7 H(\u03c0\u03bf)$, (16)\nn\nwhere entropy $\u0397(\u03c0\u03bf) = \u2212 \u03a3_\u03b9 \u03c1(\u03c0\u03bf) log(p(\u03c0\u03bf))$ encourages a balance between exploration and exploitation, leading to more effective and stable learning.\nThe PPO-DRL process starts by initializing the environment and the agent. The agent selects actions based on the current state, leading to state transitions, rewards, and termination. The policy is updated by adjusting neural network weights to minimize clipped loss using the reward and next state value. The algorithm iterates through training data four times per iteration over 10,000 iterations of 100 episodes and 100 steps each, ensuring stable learning and convergence. The best results were achieved with a learning rate of 0.003, a 0.08 entropy coefficient, and a discount factor of 0.9, which were used to evaluate our IBC-authenticated offloading approach."}, {"title": "V. SIMULATIONS AND RESULTS", "content": "The algorithm is implemented in Python 3.11.3 with PyTorch 2.1.2. Simulations run on a MacBook Pro with a 2.8-GHz quad-core Core i7 processor and 16 GB RAM. The cloud server computation capacity Fcloud is 20 GHz. The cloud server can dedicate initial computing capacities per vehicle $I^{cloud}_{v_i}$ uniformly distributed between U [2, 4] GHz, while the vehicle's initial capacity is set at 1 GHz. Network size n varies between 10 and 100 to represent different traffic densities. Vehicle speeds vv, are fixed at 25 m/s, typical for highway settings. The data rate is set between 100 Mbps and 1 Gbps, the lower end of the 6G spectrum, to account for the challenges of maintaining stable connections at higher frequencies. Our IBC scheme [21] signing phase requires five elliptic curve operations: one Scalar Multiplication (SM), one Modular Multiplication (MM), one Modular Addition (MA), and three hashing functions (HS), with a total of 36,000 cycles per byte on L = 256-bit elliptic curves, while verification involves three SMs, two Point Additions (PA), and four HSs, totaling 94,000 cycles per byte. IBC authentication imposes an overhead of 0.04 KB to 0.3 KB on each Vi task. We use a small 0.05 KB (typical safety task), a medium 30 KB, and a large 300 KB task size."}, {"title": "B. Results and Discussion", "content": "Our analysis focuses on offloading latency (msec) and offloading percentage to assess the effect of IBC authentication on task offloading in 6G-VTNs [22]\u2013[24]. All evaluations use the optimal configurations identified in IV.\n1) Average Latency (msec): the average latency is measured against n at three task sizes, with (w) and without (w/o) IBC overhead. In Fig. 3(a), when the cloud upload/download data rate $Tup/down_{icloud}$ = 100 Mbps, it can be seen that as the network size increases, the offloading latency generally increases. For example, at a small task size of 50 B w/o IBC overhead, the latency increases from 3.76 msec at n = 10 to 41.00 msec at n = 100. This effect is due to increased communication overhead and network congestion as more vehicles attempt to offload tasks simultaneously. Similarly, increasing the task size from 50 B to 300 KB results in higher offloading latencies. For n = 10, the latency w/o IBC increases from 3.76 to 9.99 msec, an increase of more than 165%. This is expected as larger tasks require more time for both processing and transmission. The introduction of IBC authentication overhead further exacerbates latency, which is particularly noticeable in larger networks and task sizes. For example, at n = 100 and a task size of 300 KB, the latency w IBC reaches 61.72 msec, compared to 51.23 msec w/o IBC, an increase of 20%. Increasing the data rate to 500 Mbps in Fig. 3(b) and 1000 Mbps in Fig. 3(c) significantly reduces the offloading latency across all scenarios. For example, with a task size of 300 KB at n = 100, the latency drops from 61.72 msec at 100 Mbps to 41.75 msec at 500 Mbps and further down to 41.06 msec at 1000 Mbps. This represents a reduction of approximately 30% when increasing from 100 to 1000 Mbps. These reductions underscore the efficiency gains achieved by higher data rates, which help mitigate the impact of larger tasks and increased network sizes on offloading latency.\n2) Offloading Percentage: The offloading percentage represents the proportion of tasks successfully offloaded from the vehicle to the cloud server, with higher percentages indicating more efficient offloading. Table I shows that the percentage of task offload can be initially considered efficient for smaller network sizes n = 10. For example, with a task size of 50 B, the percentage of offloading with/without IBC starts at 9.73%. However, introducing IBC significantly impacts this initial efficiency by adding computational overhead, leading to a noticeable reduction in percentage. For example, with IBC, the percentage of offloading for the same 50 B task size at n = 10 drops from 9.73% to 4.13%, indicating that the added security overhead halves offloading efficiency. As network size and task size increase, offloading efficiency decreases further. For instance, for the 50 B task size, at a large network of 100 vehicles, an 89.7% reduction is seen in the offloading percentage. The larger the network and the larger the task size, the more significant the reduction in offload efficiency. At 300 KB task size, the offloading w/o IBC drops from 6.35% at n = 10 to 0.53% at n = 100, a reduction of 91. 7%.\nTo mitigate the adverse effects of increasing network size and task size on offloading efficiency, we increased the data"}, {"title": "VI. CONCLUSION AND EXTENSIONS", "content": "This paper presented a unified framework for task offloading in 6G vehicular networks, integrating lightweight IBC authentication into cloud-based VTNs. Using PPO-DRL, we minimized the offloading process's latency and enhanced resource allocation. Despite IBC's overhead, which reduces the offloading efficiency by up to 50%, our results showed that increasing the data rate could mitigate these effects and improve the offloading performance by up to 63%. However, despite such an improvement in large networks and task sizes, the efficiency of offloading is still affected. One future extension will attempt batch verification to lower the verification latency, that is, the total latency. In addition, our goal is to assess more heavyweight authentication, such as group signatures, using the DRL agent developed in 6G vehicular networks."}]}