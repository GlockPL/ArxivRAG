{"title": "Research on Dynamic Data Flow Anomaly Detection\nbased on Machine Learning", "authors": ["Liyang Wang", "Yu Cheng", "Hao Gong", "Jiacheng Hu", "Xirui Tang", "Iris Li"], "abstract": "The sophistication and diversity of contemporary\ncyberattacks have rendered the use of proxies, gateways,\nfirewalls, and encrypted tunnels as a standalone defensive\nstrategy inadequate. Consequently, the proactive identification of\ndata anomalies has emerged as a prominent area of research\nwithin the field of data security. The majority of extant studies\nconcentrate on sample equilibrium data, with the consequence\nthat the detection effect is not optimal in the context of\nunbalanced data. In this study, the unsupervised learning method\nis employed to identify anomalies in dynamic data flows. Initially,\nmulti-dimensional features are extracted from real-time data,\nand a clustering algorithm is utilised to analyse the patterns of\nthe data. This enables the potential outliers to be automatically\nidentified. By clustering similar data, the model is able to detect\ndata behaviour that deviates significantly from normal traffic\nwithout the need for labelled data. The results of the experiments\ndemonstrate that the proposed method exhibits high accuracy in\nthe detection of anomalies across a range of scenarios. Notably, it\ndemonstrates robust and adaptable performance, particularly in\nthe context of unbalanced data.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid development of information technology has led\nto the network becoming the infrastructure for social operations,\nthereby promoting the digital transformation of the global\neconomy, finance, healthcare, education and other industries.\nHowever, the incidence of cyber attacks is also increasing, and\nthe forms of attack are becoming more complex and diverse.\nThese include distributed denial-of-service (DDoS) attacks,\ndata theft, and malware, all of which represent a significant\nthreat to network security [1]. The efficacy of traditional\ndefensive mechanisms, such as firewalls, intrusion detection\nsystems (IDS), and intrusion prevention systems (IPS), is\ncontingent upon the availability of a comprehensive database of\nsignatures and rules for known threats. These mechanisms are\ndesigned to be highly targeted. However, in the context of vast\nquantities of real-time data and the emergence of hitherto\nunknown threats, these traditional methods frequently appear to\nbe insufficient and challenging to provide effective defences [2].\nIn particular, in an environment characterised by a dynamic\ndata flow, data exhibits the attributes of real-time, continuous\nand massive data sets, which serves to exacerbate the\ncomplexity and velocity of change in network behaviour.\nTraditional static security protection mechanisms frequently\nprove inadequate in terms of detecting potential security threats\nin a timely manner. Furthermore, the expansion of network\nopenness has led to a notable surge in the number of network\nnodes and terminal devices, accompanied by a substantial rise\nin data traffic, which has further compounded the challenge of\nidentifying anomalous behaviour [3]. In these complex scenarios,\ntraditional approaches that rely solely on rule matching and\nfeature analysis are inadequate for detecting evolving cyber\nthreats. Consequently, the ability to identify anomalous\nbehaviours in a prompt and effective manner within a dynamic\ndata flow has emerged as a pivotal challenge within the domain\nof cybersecurity research.\nIn recent years, machine learning techniques, particularly\nunsupervised learning, have been the subject of considerable\ninterest within the field of cybersecurity. In contrast to\nconventional supervised learning techniques, which necessitate\nlabelled data for training, unsupervised learning enables the\nautomated identification of potential anomalies within data sets\nby examining their intrinsic structure and distribution patterns\nin the absence of known labels [4]. This renders unsupervised\nlearning a highly promising avenue for addressing\nsophisticated and unanticipated attacks, particularly in the\ncontext of extensive, multidimensional data sets with limited\nlabeling."}, {"title": "II. RELATED WORK", "content": "While existing research on machine learning-based\nanomaly detection has enhanced the detection capability for\nunknown threats to a degree, the majority of these studies\nremain constrained to the domain of sample equalisation. In\nother words, model training and evaluation are typically based\non a substantial number of annotated normal and abnormal data\nsets, with the assumption that the distribution of the two types\nof samples is relatively balanced [5]. However, the actual\nnetwork environment is often highly uneven, with the majority\nof traffic being normal and only a small number of abnormal\nbehaviours. Furthermore, the distribution of anomalous traffic\nis frequently sparse and discrete, manifesting as a multitude of\nattack types, which further exacerbates the challenge of\ndetection. Traditional anomaly detection models based on\nsample balancing often result in an elevated false positive rate\nor a high false negative rate when confronted with these\nimbalanced data sets, which is challenging to align with the\ndemands of practical applications [6].\nAdditionally, the question of how to improve the accuracy\nof detection in scenarios where the data is unbalanced has\nbecome a topic of significant research interest. In order to\naddress this challenge, this paper proposes a dynamic data flow\nanomaly detection model based on unsupervised learning. The\nmodel initially extracts multi-dimensional features from the\nreal-time data set and then automatically groups the data set\nthrough the unsupervised clustering algorithm [7]. This enables\nthe identification of abnormal traffic that is significantly\ndifferent from the normal data set behaviour. In particular, the\nmodel categorises the majority of the normal data into a single\ncategory through the analysis of data similarity, and identifies\npotential abnormal behaviours by analysing the behavioural\ncharacteristics of a small number of deviant groups.\nIn order to address the prevalent anomaly issues in the\nInternet of Things (IoT), L. Nie et al. [8] integrated the pertinent\ninsights from Convolutional Neural Networks (CNNs) to\ndevelop a CNN-based learning model. In contrast to\nconventional intrusion detection systems (IDS), the model is\ndata-centric, with real-time data analysis for decision-making\nand action. The results of the experiments demonstrate that the\nproposed model is effective in detecting network intrusion,\nparticularly in reducing the false positive rate. However, the\nlow learning rate of the model results in a reduction in its\nlearning efficiency when processing large-scale data, which\nlimits its applicability in more complex scenarios. Nevertheless,\nthe model continues to offer substantial advantages in\nenhancing network security protection capabilities, particularly\nin the context of evolving cyber threats. Its adaptability renders\nit a highly versatile tool with a vast range of potential\napplications.\nAdditionally, Fiore U et al. [9] employed a restricted\nBoltzmann machine (RBM) in conjunction with anomaly\ndetection to ascertain that the RBM is capable of progressively\ndiscerning pivotal knowledge points from data through\ncontinuous learning. Gao N et al. further applied Deep Belief\nNetworks (DBN) to anomaly detection, utilising DBN to learn\na range of features within the data. The results demonstrate that\nDBN exhibits a robust capacity for discrimination when\nprocessing multi-dimensional data, effectively identifying\nanomalous behaviours. The results demonstrate that the\nintegration of deep learning models and anomaly detection\nenhances the system's capacity to detect anomalies in complex\ndata scenarios.\nFurthermore, Farahnakian et al. [10] employed the capacity\nof autoencoders to diminish the dimensionality of multi-\ndimensional data, proposed the stacking of multiple\nautoencoders, and applied deep autoencoders to intrusion\ndetection systems (IDS). The combination of greedy algorithms\nwith unsupervised learning effectively circumvents the issue of\nmodel overfitting and the tendency to converge on local\noptimal solutions. This approach enhances the accuracy and\nrobustness of intrusion detection, thereby improving its ability\nto cope with complex network environments."}, {"title": "III. METHODOLOGIES", "content": "A. Feature extraction\nInitially, feature extraction represents a pivotal stage in the\nprocess of effective anomaly detection within a model. In the\ncase of dynamic data flows, it is necessary to extract pertinent\nfeatures from the raw data in order to represent changes in the\ndata flow. The data stream D(t) comprises m samples, each\ncomprising n-dimensional features represented as X =\n{X1, X2, ..., Xm}, where each xi \u2208 Rn.\nThe data flow is continuous, so anomaly detection is not\nideal for each data point directly. By introducing a time\nwindow T, we divide the data flow into several windows, each\ncontaining an Nr number of data points, so that short-term\nfluctuations can be smoothed out and long-term trends can be\npreserved. After setting the time window T, the data in the\nwindow is Dr = {Xt1, Xt2, ..., Xty}, and we can calculate the\nstatistical characteristics within each window, including mean\n$\\mu_\\tau = \\frac{1}{N_T} \\sum_{i=1}^{N_T} X_{ti}$,\nvariance $\\sigma^2_\\tau = \\frac{1}{N_T}\\Sigma_{i=1}^{N_T} (X_{ti} \u2013 \\mu_\\tau)^2$\nand\nskewness $S_T = \\frac{N_T}{(N_T\u22121)(N_T-2)} \\sum_{i=1}^{N_T} (\\frac{X_{ti} - \\mu_T}{\\sigma_T})^3$.\nIn order to capture the periodic behavior and high-\nfrequency changes in the data stream, a discrete Fourier\ntransform is introduced to convert the time-domain signal into\na frequency-domain signal. For each time window Dr, its\nFourier transform is expressed as Equation 1.\n$X(f) = \\Sigma_{t=0}^{N_T-1} X_t e^{\\frac{j2\\pi ft}{N_T}}$, #(1)\nwhere f is the frequency component. Using the Fourier\ntransform, we can extract the major frequency components and\npower spectral density for each data window.\nIn order to prevent dimension disasters and feature\nredundancy, we further reduce the dimensionality of high-\ndimensional features by principal component analysis. The\nanalysis uses the eigenvalue decomposition of the feature\ncovariance matrix to find the direction of the maximum\nvariance, denoted as Equation 2."}, {"title": "B. Unsupervised clustering algorithms", "content": "$\\Sigma = \\frac{1}{m} \\sum_{i=1}^{m} (X_i - \\mu) (X_i \u2212 \\mu)^T$. #(2)\nPrincipal component analysis maps the original features to\na new low-dimensional space, preserving the most important d\nfeature vectors V1, V2, ..., Vd, where d makes the retained\nfeatures explain more than 95% of the total variance.\nThrough the above steps, the final feature set contains both\nstatistical features in the time domain and periodic features in\nthe frequency domain, and is reduced by component analysis to\nimprove the efficiency of the subsequent clustering algorithm.\nOn the basis of feature extraction, this paper uses a density-\nbased unsupervised clustering algorithm, Density Peaks\nClustering (DPC), to cluster multi-dimensional features and\nautomatically identify outliers. For each data point xi, its local\ndensity pi is defined as Equation 3.\n$\\rho_i = \\Sigma_j \\chi(d(x_i - x_j) - d_c)$, #(3)\nwhere d(x \u2013 xj) is the distance between the points x\u2081 and\nxj, which is obtained by Euclidean distance. Parameter dc is the\ntruncation distance, which controls the range of density\ncalculations, X(\u00b7) is the indication function, X(\u00b7) = 1 when\nx < 0, otherwise 0. Local density pi represents the number of\nneighbor points within distance de, reflecting the degree of\nlocal aggregation of data points.\nTo distinguish between cluster centers of different densities,\ndefine the minimum distance di from each data point to all\npoints with higher densities, which is expressed as Equation 4.\n$\\delta_i = \\min_{j: \\rho_j>\\rho_i} d(x_i, x_j)$.#(4)\nFor the point with the highest density, let \u03b4\u2081 =\n$\\max_j d(x_i, x_j)$. These high-density and space-flotted points are\nclustering centers. By sorting pi and di, the points with high\nlocal density and large distance are selected as the clustering\ncenters. Each non-central point x\u2081 is assigned to the cluster with\nthe higher density of the point x; closest to it.\nSome of the significantly low-density and outlier points in\nthe dataset can be directly marked as outliers. Define the\nanomaly score A\u2081 as Equation 5.\n$A_i = \\frac{\\delta_i}{\\rho_i}$. #(5)\nWhen A exceeds a certain threshold of Ath, point xi is\nconsidered to be an anomaly. This approach eliminates the\nneed for pre-labeling anomalies and automatically identifies\npotentially anomalous behavior from the data."}, {"title": "IV. EXPERIMENTS", "content": "A. Experimental setups\nIn this experiment, two network traffic datasets, NSL-KDD\nand UNSW-NB15, were used to construct an unsupervised\nanomaly detection model based on Density Peak Clustering\n(DPC) through multi-dimensional feature extraction (including\ntime domain and frequency domain features) and PCA\ndimensionality reduction. In the experiment, traditional\nmethods such as K-Means, Isolation Forest, and DBSCAN\nwere compared.\nFurther, the proposed PCA is used to reduce the\ndimensionality of high-dimensional features to the first 50\nprincipal components. In the clustering algorithm, the Density\nPeak Clustering algorithm sets the truncation distance dc =\n0.15, the local density threshold p = 8 and the distance\nthreshold 8 = 0.18 to identify the clustering center and outliers.\nIn addition, the threshold for anomaly score is set to Ath = 1.4,\nwhich is used to mark outliers as anomalous data.\nB. Experimental analysis\nThe accuracy of a model is defined as the proportion of\ncorrectly classified instances in the overall data set, including\nboth normal and outlier cases. Figure 1 is a comparison of the\naccuracy of different methods, in which \"Our Method\" is\nmarked with specific parameter settings, such as cut-off\ndistance, local density threshold, distance threshold, and\nanomaly score threshold. With the different combinations of\nthese parameters, three different configurations are shown in\nthe diagram to show how our method performs with different\nparameter settings."}, {"title": "V. Conclusions", "content": "In conclusion, we proposed a dynamic data flow anomaly\ndetection model based on unsupervised learning, which can\neffectively identify abnormal behaviors in network traffic\nthrough feature extraction, multi-dimensional clustering\nalgorithm, and innovative anomaly score calculation. In the\nexperiment, we used the NSL-KDD and UNSW-NB15 datasets,\nand compared them with classical methods such as K-Means,\nIsolation Forest, and DBSCAN, to evaluate the performance of\naccuracy, G-Mean, false positive rate and other indicators.\nExperimental results show that the proposed model has higher\ndetection accuracy and robustness when dealing with\nunbalanced data, especially in reducing the false alarm rate.\nThrough the testing of multiple parameter configurations, our\nmethod outperforms other methods in various scenarios,\nshowing a wide range of application potential in the field of\nnetwork security."}]}