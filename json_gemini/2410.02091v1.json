{"title": "The Impact of Generative AI on Collaborative Open-Source Software Development: Evidence from GitHub Copilot", "authors": ["Fangchen Song", "Ashish Agarwal", "Wen Wen"], "abstract": "Generative artificial intelligence (AI) has opened the possibility of automated content production, including coding in software development, which can significantly influence the participation and performance of software developers. To explore this impact, we investigate the role of GitHub Copilot, a generative AI pair programmer, on software development in open-source community, where multiple developers voluntarily collaborate on software projects. Using GitHub's dataset for open-source repositories and a generalized synthetic control method, we find that Copilot significantly enhances project-level productivity by 6.5%. Delving deeper, we dissect the key mechanisms driving this improvement. Our findings reveal a 5.5% increase in individual productivity and a 5.4% increase in participation. However, this is accompanied with a 41.6% increase in integration time, potentially due to higher coordination costs. Interestingly, we also observe the differential effects among developers. We discover that core developers achieve greater project-level productivity gains from using Copilot, benefiting more in terms of individual productivity and participation compared to peripheral developers, plausibly due to their deeper familiarity with software projects. We also find that the increase in project-level productivity is accompanied with no change in code quality. We conclude that AI pair programmers bring benefits to developers to automate and augment their code, but human developers' knowledge of software projects can enhance the benefits. In summary, our research underscores the role of AI pair programmers in impacting project-level productivity within the open-source community and suggests potential implications for the structure of open-source software projects.", "sections": [{"title": "1. Introduction", "content": "The continuous advancements in generative artificial intelligence (AI) are transforming content production across a wide range of domains. Cutting-edge generative AI tools can not only automate mundane tasks but also enhance original content. In the context of software development, generative AI-powered pair programmers like GitHub Copilot, Amazon Q Developer, Google Gemini, and Chat GPT can swiftly generate code based on developers' prompts, parameters, and descriptions. For example, GitHub Copilot, trained on an extensive dataset comprising billions of lines of publicly available code, demonstrates remarkable ability to offer predictive coding suggestions, which are comparable to human's contributions (Dakhel et al. 2023). By reducing common coding errors and repetitive coding needs, these AI pair programmers hold the potential to dramatically influence the software production process. Thus, it is important to assess whether and how AI pair programmers influence software development productivity. A growing body of literature has investigated various impacts of generative AI on well-defined and discrete tasks on individuals, such as writing and customer service tasks (Brynjolfsson et al. 2023, Noy and Zhang 2023). However, there is limited understanding of the role of generative AI in complex tasks that involve iterative development and team collaboration, such as software development. To address this gap, our research focuses on evaluating software productivity at the project level within the context of open-source software development.\nAs a popular form of software development, open-source software development involves a team of geographically dispersed developers who voluntarily collaborate to develop and refine code for a software project (Levine and Prietula 2014). Any developer can participate in the project by making individual contributions that are then integrated into the final software codebase. Some studies suggest that generative AI can improve the software development activities of individual developers (Dohmke et al. 2023, Peng et al. 2023). However, whether this translates into higher productivity at the project level is not obvious as there is a need for coordination among developers for software development within teams. This is particularly challenging in the context of open-source development due to its open and voluntary nature of developer participation."}, {"title": "", "content": "Moreover, the open-source development typically involves two types of developers: core developers and peripheral developers (Setia et al. 2012). Core developers set high-level objectives, design the architecture, write code and maintain full control over the codebase, whereas peripheral developers enhance the existing codebase by fixing bugs and adding new features (AlMarzouq et al. 2005, Setia et al. 2012, Gousios et al. 2014, Medappa and Srivastava 2019), which have to be integrated by the core developers. Existing literature has highlighted the heterogenous impacts of generative AI on individuals with varying skill levels (e.g., Brynjolfsson et al. 2023) for well-defined and discrete tasks. However, these findings may not readily enhance our understanding on how generative AI affects core developers versus peripheral developers, as the distinction lies more in the nature of the tasks and roles played by these two types of developers rather than their skills.\nMotivated by these observations, in this study we aim to answer the following research questions. First, how do AI pair programmers affect open software development productivity at the project level? Second, how do AI pair programmers affect the relative contributions of core developers compared to peripheral developers? These questions are crucial to study, as our findings may provide useful implications on how to leverage generative Al tools to support collaborative and distributed software development in the open-source community.\nBuilding on the literature on generative AI and the literature on open-source software development, our key theoretical argument is that Al pair programmers may yield individual productivity gain and encourage developers to participate more in software development. However, Al pair programmers could also increase coordination and integration costs due to the higher volume of code contributions from increased participation and individual productivity. As a result, the overall impact of AI pair programmers on project-level productivity depends on the net effect of these competing forces. Furthermore, due to the differences in the tasks taken by core developers versus peripheral developers, greater complementarity can be achieved between AI pair programmers and core developers than between Al pair programmers and peripheral developers. Therefore, AI pair programmers could lead to relatively more contributions and"}, {"title": "", "content": "participation by core developers compared to peripheral developers. However, this relative effect again depends on how core developers choose to participate in the integration activities.\nTo empirically investigate our research questions, we examine how the AI pair programmer GitHub Copilot influences the productivity of open-source projects on GitHub. GitHub is one of the largest code-hosting repositories based on the Git version control system (Dabbish et al. 2012, Borges et al. 2016). In this setup, a repository is a fundamental unit that typically contains the source code and resource files for a software project, along with information related to the project's evolution history, high-level features, and developer details (Zhang et al. 2017). Such repositories are often used to investigate collaborative development practices (Dabbish et al. 2012, Kalliamvakou et al. 2015, Celi\u0144ska 2018). Our unit of analysis is at the repository-month-level, with the sample period from January 2021 to December 2022. To examine the impact of Copilot on code contributions to open-source repositories on GitHub, we use a combination of publicly available data on GitHub repositories and proprietary data on Copilot use provided by the GitHub Team. Our main empirical approach is based on the generalized synthetic control method (GSCM), which allows for staggered treatment turn-on times for repositories with a well-matched control sample. Our treatment group consists of repositories where Copilot was both supported by local coding environments and used by developers to code. Thus, the post-treatment period includes the months during which Copilot was supported and used in a focal repository, and the pre-treatment period includes all other months. The control group includes repositories where Copilot was not used throughout the sample period. We validate our results with alternative matching techniques and samples, and developer-level analysis.\nOur empirical results show that the use of Copilot increased the number of successful code contributions in repositories by 6.5%, suggesting an overall positive impact on project-level software development productivity. Detailed analyses on the underlying mechanisms suggest that such an improvement on overall code contributions was accompanied with a significant increase in individual productivity and a significant increase in developer participation, both of which contribute to the increase in the project-level productivity. Interestingly, we also find that the use of Copilot increased the integration time within the development process by 41.6%, potentially due to higher coordination costs. These pieces"}, {"title": "", "content": "of evidence highlight the trade-off between improved code contributions and increased coordination efforts resulting from the use of AI pair programmers.\nFurthermore, we find that Copilot use led to relatively greater increases in participation, contributions, and productivity by core developers, as compared to peripheral developers. A plausible explanation is higher complementarity between an AI pair programmer and a core developer than between an Al pair programmer and a peripheral developer. Specifically, core developers' understanding of their software projects' overarching objectives and structure may enable them to more effectively leverage an Al pair programmer to complement their development capabilities. In contrast, peripheral developers, whose main roles involve enhancing existing codebase, may lack a comprehensive understanding of the intricacies of a project and thus experience less effective use of an AI pair programmer compared to core developers.\nOur study offers several important contributions to the literature. First, it contributes to the literature on generative AI in software development (Imai 2022, Barke et al. 2023, Biswas 2023, Peng et al. 2023). Prior research has shown the positive impact of generative AI on individual productivity for specific coding tasks (Peng et al. 2023). In contrast, our study takes a first step to understand how generative AI tools affect project-level productivity. In the context of open-source software development, we demonstrate the role of generative AI on different aspects of a software project such as participation, individual productivity, and integration. Additionally, we emphasize the importance of knowledge of a software project, as exhibited by core developers, in harnessing the benefits of generative AI for collaborative software development.\nSecond, our study contributes to the literature on developer participation in open-source software development (Bagozzi and Dholakia 2006, Roberts et al. 2006). Prior research has focused on benefits of developer participation (Hann et al. 2002, Lakhani and Wolf 2003, Shah 2006, David and Shapiro 2008, Spaeth et al. 2015) but paid limited attention on the potential costs of participation. Our study complements this work by demonstrating how generative AI could encourage more participation, potentially due to AI's capabilities to reduce participation costs and barriers and increase developer ability to contribute. This"}, {"title": "", "content": "increased participation addresses an important concern\u00b9 that AI, with its automated code writing capabilities, may replace developers in open-source software contributions and consequently discourage developer participation. Additionally, our study shows differential effects of generative AI on core developers and peripheral developer participation.\nThird, our study contributes to the literature on pair programming (Astels et al. 2002, Williams and Kessler 2003, Vidgen and Wang 2009). This body of literature primarily focused on human pair programming and showed that it increases code development costs but reduces integration costs (Dawande et al. 2008). In contrast, our study shows that AI pair programming has an opposite effect from human pair programming in the open-source context. Specifically, we show that AI pair programming leads to more integration costs, due to the higher volume of code contributions facilitated by AI in an open-source setup.\nOur study provides several managerial implications. It underscores the importance of AI pair programmers in enhancing project-level productivity for software development teams. At the same time, it emphasizes the need for managing team coordination and streamlining the integration process to fully benefit from Al pair programmers. It also highlights the importance of familiarity with the project in leveraging the AI capabilities, as demonstrated by our comparison of core and peripheral developers. Additionally, our findings have implications for the structure of open-source software teams as higher participation by core developers may reduce the need for peripheral developers' involvement over time."}, {"title": "2. Literature review", "content": "Our study draws from and adds to three streams of literature: the impact of generative AI tools on content production, developer participation in open-source software development, and pair programming. Next, we discuss these streams in greater detail."}, {"title": "2.1 Impact of Generative AI Tools", "content": "Many researchers have started exploring the specific productivity gains achieved by generative AI. For instance, Noy and Zhang (2023) find that Chat GPT speeds up writing tasks, improves writing quality, and"}, {"title": "2.2 Open-Source Software Participation", "content": "Open-source software development involves integrating voluntary code contributions from individual developers to form the final software codebase (Atkins et al. 2002, Kornilov and Safonov 2018). Previous studies have considered benefits for developer voluntary participation, such as opportunities to express their creativity and experience for a great sense of satisfaction and achievement (Lakhani and Wolf 2003), satisfy needs for software improvements (Shah 2006), acquire knowledge (David and Shapiro 2008), build reputation (Hann et al. 2002), and enhance social identification (Spaeth et al. 2015). These studies assume that developers can contribute to open-source projects and focus on the motivation and benefits of participation. With the advent of generative AI, which assists in code development, it is important to understand how this technology influences developer participation by potentially affecting the costs and barriers in open-source development. In addition, research has highlighted the distinct roles of developers and suggested both core developers and peripheral developers are important to the long-term success of the open-source software development (Setia et al. 2012). However, there is a gap in understanding how generative Al influences participation by different types of developers in the open-source community. Due to the differences in their tasks and roles in a software project between core developers and peripheral developers, there could be differences in the extent to which they can effectively leverage the features of generative AI to complement their tasks."}, {"title": "2.3 Pair Programming", "content": "Human pair programming involves two developers simultaneously working on the same piece of code (Beck 2000). Typically, one member of the pair writes the code, while the other observes the creation of the code, suggests improvements in structure, and points out strategic defects (Williams and Kessler 2003, Dawande et al. 2008). The objective is to keep code clean and simple, and ensure flexibility when confronted with changing requirements (Astels et al. 2002). It has been argued that although human pair programming increases the effort to develop a piece of code as compared to solo programming, this extra effort is often compensated by lower system integration and testing efforts (Dawande et al. 2008). This is because many integration decisions are made collaboratively during the code generation process."}, {"title": "", "content": "However, the results obtained from human pair programming may not be applicable in the setting of open-source software development with AI pair programmers. On the one hand, by swiftly providing code suggestions, AI pair programmers can potentially lead to a significant reduction in code development costs. On the other hand, AI pair programmers may increase participation, which in turn may raise integration costs as developers need to take more time to determine valuable contributions among the increased inputs facilitated by Al pair programmers. Therefore, it is important to assess whether and how Al pair programming influences software development productivity."}, {"title": "3. Theoretical Background", "content": "In this section, we first describe the open-source software development process and the role of AI pair programmers, followed by the theoretical motivation for our analysis."}, {"title": "3.1 Open-Source Software Development", "content": "Open-source software development is characterized by a fully decentralized and open environment, where a group of voluntary contributors work together to develop and refine code, subsequently making it accessible to both fellow contributors and the broader community (Levine and Prietula 2014). Besides making code contributions to the software codebase, developers also need to spend a significant amount of time and efforts managing project-level dependencies and ensuring cohesive and aligned actions among team members. We refer to these efforts related to code integration, communication, planning, and resolving conflicts stemming from task interdependencies as integration costs (Howison and Crowston 2014, Lindberg et al. 2016, Medappa and Srivastava 2019, Shaikh and Vaast 2023). In the open-source context, productivity is often measured based on successful code contributions, which refer to the amount of code submitted by developers to propose modifications or new features that is eventually merged to the codebase (Smirnova et al. 2022). Therefore, project-level productivity is affected by participation in open- source development, individual developers' productivity in making code contributions, and integration costs.\nThe open-source software development process typically involves two major categories of developers: core and peripheral (Setia et al. 2012). These developers exhibit varying levels of understanding and control over the projects. Core developers, who often include the projects' administrators and key"}, {"title": "", "content": "maintainers, are responsible for defining the overarching objectives and ensuring the delivery of the final code product. As shown in Figure 1, software development usually begins with core developers designing the primary codebase and hosting it on a platform for open collaboration (Singh and Phelps 2013). Core developers, who have the write access and full control over the projects, can submit code and either directly integrate it into the primary codebase or have it reviewed by other core developers for better integrity (Gousios et al. 2015).\nPeripheral developers, on the other hand, typically contribute to a project by enhancing the existing codebase such as fixing bugs and adding new features (AlMarzouq et al. 2005, Setia et al. 2012). They primarily contribute through code submissions. These submissions are reviewed by core developers, who decide whether to merge the contribution into the primary codebase, request additional modifications, or reject them altogether (Gousios et al. 2014, Medappa and Srivastava 2019)."}, {"title": "3.2 AI Pair Programmers in the Open-Source Software Development", "content": "Al pair programmers, guided by explicit prompts from developers, offer immediate code suggestions and corrections. These tools support software developers by fixing bugs, proposing enhancements, recommending best practices, and facilitating the transfer of coding knowledge across various domains.\u00b2 Al pair programmers use extensive databases and advanced machine learning algorithms to provide suggestions that follow best practices and coding standards, reducing search time. This helps lower the time developers spend writing code and waiting for peer support, thereby accelerating the production process. Moreover, these tools also serve as exploration aids when developers are unsure how to proceed, helping them explore potential options (Barke et al. 2023). Recent research has documented the beneficial effects of Al pair programmers on individual software developers' productivity (Imai 2022). In particular, AI pair programmers allow developers to complete coding tasks faster than those who do not use such tools (Peng"}, {"title": "", "content": "et al. 2023). The benefits of Al pair programmers in improving individual productivity in software development can also extend to the open-source community.\nAl pair programmers can also increase developer participation by lowering the barriers and associated costs. According to the expectancy value models, contributors evaluate the expectancy of the outcomes and its value to determine if they would participate in certain software projects (Atkinson 1957, Hertel et al. 2003, Setia et al. 2012). Given their limited time, developers have to select projects that are both meaningful and rewarding, balancing the costs of participation against the potential benefits (Wen et al. 2013). Traditionally, developers needed specific knowledge to effectively contribute to open-source software projects, creating significant entry barriers. Al pair programmers can mitigate these barriers by shortening the learning curve, thereby enabling developers to contribute to projects across diverse knowledge domains. Thus, AI pair programmers can lower the participation costs by improving individual productivity and alleviate concerns about the time and effort required from developers, thereby encouraging greater participation in open-source software development.\nHowever, productivity at the project level is not merely the sum of individual productivity across developers. Although open-source development typically relies on modular design and parallel work to create independent layers of work (Howison and Crowston 2014), a significant amount of development interdependency and developer interdependency still exists (Lindberg et al. 2016). Therefore, it is crucial to take the associated integration and coordination costs into consideration.\nWe have argued above that generative AI may facilitate more code contributions generated by individual developers; at the same time, such tools could also attract a larger group of contributors with diverse objectives and developmental approaches. Overall, we would expect a higher volume of code submissions after the use of generative AI by developers. However, these contributions can potentially compromise the compatibility of existing codebases, as managing code interdependency becomes challenging with an increased number of contributions (Shaikh and Vaast 2023). Generative AI also has limited ability to coordinate suggestions across parallel work and integrate code contributions at the project level. Therefore, human effort is still needed to integrate independent code contributions into the codebase"}, {"title": "", "content": "and to ensure the cohesiveness and compatibility of the final software products. Given the larger volume of submissions enabled by generative AI, developers would need to invest more effort in reviewing and integrating these contributions into the main codebase. This represents a significant cost that must be considered when evaluating productivity at the project level. Therefore, the overall project-level productivity in software development should reflect the net effect of individual productivity and participation gains, balanced against integration and coordination costs. We will empirically evaluate the overall effect of generative AI on open-source software development productivity."}, {"title": "3.3 Developer Roles in the Open-Source Community", "content": "Within the open-source community, the collaborative dynamics of projects are greatly enriched by the diverse contributions from core developers and peripheral developers (Setia et al. 2012). Given the roles played by core developers versus peripheral developers, as well as the capabilities of AI pair programmers, we expect a stronger complementarity between AI pair programmers and core developers than that between Al pair programmers and peripheral developers, for reasons as follows.\nOne important shortcoming of Al pair programmers is their limited understanding on the overarching objectives of a software project compared with human developers. As a result, the code suggestions may not align well with a project's design principles, dependencies, and performance considerations (Vaithilingam et al. 2022, Adamson and B\u00e4gerfeldt 2023). Because core developers are the ones who design the overall architecture and determine the development trajectory of a project, they have a deep understanding on the projects' style, patterns, and previously implemented solutions. This would allow them to effectively provide context-rich prompts and adjust AI-generated code. Meanwhile, core developers may be better in anticipating long-term compatibility and maintenance issues from using certain code suggestions. Accordingly, they can choose AI-generated code that not only addresses some immediate problems but also align well with future development plans and scalability considerations. As a result, AI pair programmers could effectively improve core developers' individual productivity by complementing their roles within a software project. Moreover, according to expectancy value models, core developers may have greater incentives regarding software"}, {"title": "", "content": "development outcomes compared to peripheral developers. Since AI pair programmers can effectively reduce their participation costs and boost their individual productivity, core developers may participate more to enjoy complementarity with Al pair programmers.\nOn the other hand, peripheral developers often contribute to projects on an irregular or part-time basis (Bagozzi and Dholakia 2006, Howison and Crowston 2014). Unlike core developers, peripheral developers may lack a comprehensive understanding of the project's intricacies. Therefore, they may not provide effective prompts to generate intended code and at the same time, the code could potentially run into compatibility issues so some of the contributions may not get accepted into the final codebase. In sum, while AI pair programmers could still improve peripheral developers' individual productivity and encourage them to participate in software projects, the increase in their individual productivity and participation could be lower than that of core developers."}, {"title": "4. Data", "content": "Our objective is to evaluate the impact of AI pair programmers on software development productivity in the open-source community. We are particularly interested in project-level outcomes which rely on participation from multiple developers. Our empirical analysis focuses on GitHub data at the level of repository, which serves as the basic unit for collaborative software development (Dabbish et al. 2012, Kalliamvakou et al. 2015, Celi\u0144ska 2018). We investigate how the introduction of AI pair programmer Copilot impacts productivity for GitHub repositories and the plausible underlying mechanisms.\nCopilot's introduction occurred in stages, commencing with limited availability in June 2021 and a formal public launch in June 2022\u00b3. During the one-year period between June 2021 and June 2022, Copilot underwent a technical preview phase. Interested developers needed to sign up for a waitlist, and those selected developers received an invitation email containing a download link for Copilot.\u2074 Based on this"}, {"title": "", "content": "timeline, we collect panel data of GitHub repositories from the publicly available GitHub Archive Dataset, spanning a two-year timeframe, from January 2021 to December 20225.\nTo ensure the generalizability of our analysis, we follow established procedures in the literature (Kalliamvakou et al. 2014, AlMarzouq et al. 2020) to identify active repositories in the open-source community during our panel period. Specifically, we select repositories that meet the following criteria: they have a non-zero size, specify at least one programming language and one license, include repository descriptions, and are not mirrors or personal stores. To further ensure the repositories are not ghost or abandoned, we require at least one code submission from developers every six months from 2021 to 2022, and at least one other activity, such as a release, creation, or deletion, each year. As we are interested in evaluating project-level software development productivity involving multiple developers, we focus on repositories with at least three developers contributing each month. Additionally, as mentioned in greater detail below, we need IDE information to identify repositories in the treatment group versus those in the control groups, so we further restrict our sample to those that disclose IDE information. These criteria result in a total of 9,244 repositories.\nTo identify the repositories where Copilot was used by developers (i.e., the treatment group), we collaborate with the GitHub Team, who provides us with proprietary aggregated Copilot usage data for each repository. This data indicates the proportion of developers who submitted code contributions to a focal repository and used Copilot during each month.\u2077 Moreover, to use Copilot, the focal repository must also use supported IDEs. During our analysis period, only a limited number of IDEs supported Copilot: Visual Studio Code, the JetBrains suite of IDEs, Neovim, and Visual Studio.\u2078 We check the webpages of the repositories in our sample to gather information on the IDE usage by developers involved in the"}, {"title": "5. Empirical Analysis", "content": "We use merged pull requests of each repository as our primary dependent variable to capture project-level software development productivity. Pull requests represent code changes submitted by developers and need further evaluation by core developers. This evaluation results in either approval, leading to merged pull requests, or rejection, leading to closed but unmerged pull requests. Thus, merged pull requests reflect successful code contributions that have been accepted and incorporated into the development of repositories (Gousios et al. 2014, Tsay et al. 2014, Kononenko et al. 2018) and are commonly used in the literature to assess productivity (Bertoncello et al. 2020). To account for the time it takes for core developers to evaluate submitted pull requests (Gousios et al. 2015), we calculate the number of pull requests submitted in each month that are eventually merged within six months\u2079.\nAs discussed earlier, Copilot may influence individual productivity and developer participation, which impact project-level software development productivity. Additionally, the integration costs might offset the positive effects of AI pair programmers. To provide a comprehensive understanding of Copilot's impact on the number of merged pull requests, we utilize three additional dependent variables. We assess individual productivity through the average number of submitted pull requests per developer (Subramaniam"}, {"title": "", "content": "et al. 2009). We gauge participation by counting the number of developers who submitted pull requests (Krishnamurthy 2002, Subramaniam et al. 2009). Finally, we measure the integration costs by calculating the average time difference in minutes between pull requests submission and acceptance (Yu et al. 2016).\nThe unit of analysis in our baseline models is repository-month and we further demonstrate the robustness of our results by conducting developer-level analyses where the unit of analysis is developer-month."}, {"title": "5.2 Model and Estimation", "content": "Our objective is to determine how Copilot influences project-level software development productivity, which is measured by the number of merged pull requests for a repository. In our setup, repositories adopt Copilot at different times after it is available. There could be systematic differences between repositories where Copilot was used and repositories where Copilot was not used. Moreover, because the repositories in the treatment group were treated at different points in time and we have more repositories in the treatment group than those in the control group, it is difficult to employ traditional matching techniques to construct a matched control sample. Therefore, we use the generalized synthetic control method (GSCM) (Xu 2017, Wang et al. 2021, Mader and R\u00fcttenauer 2022, Wang et al. 2023). This approach combines the idea of a synthetic control (Abadie et al. 2010) with interactive fixed effects (Bai 2009). This allows us to address multiple treated units with staggered treatment times while accounting for time-varying unobservables. The GSCM shares core assumptions with the standard synthetic control method, effectively managing unobserved time-variant confounders by giving more weight to control units that mirror the pre-treatment trends of the treatment group.\nWe use the following linear factor model (Bai 2009, Xu 2017) to determine the effect of Copilot on the software development productivity:\n$Y_{it} = \\delta_{it} D_{it} + X_{it}\\beta + \\lambda_{i}f_{t} + \\epsilon_{it}  \\qquad (1)$\nwhere $Y_{it}$ represents the outcome variable and is measured by the log number of merged pull requests of repository i in month t. We take the log transformation to reduce its skewness. $D_{it}$ is the treatment indicator which equals one if repository i has been developed with Copilot by month t and zero otherwise. The"}, {"title": "", "content": "parameter of primary interest is $\\delta_{it}$, which signifies the dynamic impact of Copilot on the log number of merged pull requests. $\\delta_{it}$ is the heterogeneous treatment effect and its subscripts i and t indicate that the estimates vary across repositories and months. In addition, $X_{it}$ represents the observed time-varying control variable, the size of repository i in month t, since repository size may affect the contributions and participation from developers, and $\\beta$ is the corresponding estimate.\nIn the above equation, $f_{t} = [f_{1t}, ..., f_{rt}]'$ is an (r \u00d7 1) vector of unobserved common factors associated with factor loadings $\\lambda_{i} = [\\lambda_{i1}, ..., \\lambda_{ir}]$ and $\\epsilon_{it}$ is the error term with a mean of zero. The factor component $\\lambda_{i}f_{t}$ can be expressed as $\\lambda_{i}f_{t} = \\lambda_{i1}f_{1t} + \\lambda_{i2}f_{2t} + \u2026 + \\lambda_{ir}f_{rt}$. The factor component nests a range of unobserved heterogeneities including additive unit and time fixed effects and unit-specific linear and quadratic time trends. Note that a two-way fixed effects specification is a special case of the factor component, where r = 2, $f_{1t}$ = 1, and $\\lambda_{i2}$ = 1, so that $\\lambda_{i}f_{t} = \\lambda_{i1} + f_{2t}$. Here, $\\lambda_{i1}$ represents the repository fixed effects, while $f_{2t}$ is the month fixed effects. We specify the two-way fixed effects to account for heterogeneity across repositories and time, while considering other unobserved latent factors.\nWe estimate the optimal number of latent factors using a cross-validation procedure (Xu 2017) Briefly, this involves first estimating the parameters of model using the control group data only and employing a cross-validation procedure to determine the number of latent factors r. Next, the optimal number of factor loadings for each treated unit is estimated by minimizing the mean squared errors of the predicted treated outcomes in the pre-treatment periods. We provide a detailed explanation of the model and the estimation including the determination of the optimal latent factors in Online Appendix A. After accounting for time and repository fixed effects, the optimal number of unobserved factors determined by the cross-validation technique is zero. This suggests that the fixed effects setting has effectively accounted for any unobserved time-varying characteristics (Xu 2017).\nThe GSCM estimator predicts the counterfactuals for treated units in the post-treatment periods using the parameter estimates obtained in the previous two steps. The causal effect of the treatment is"}, {"title": "", "content": "calculated as the average treatment effect on the treated (ATT), based on the differences between the observed outcome of a treated unit $Y_{it}(1)$ and its constructed counterfactual $\\hat{Y}_{it}(0)$:\n$ATTE = \\frac{1}{\\mid T \\mid}\\sum_{i \\in T}[Y_{it}(1) - \\hat{Y}_{it}(0)] = \\frac{1}{\\mid T \\mid}\\sum_{i \\in T} \\delta_{it} \\qquad (2)$\nwhere T denotes the set of treated units and |T| represents the number of units in T. To create well-matched synthetic controls, GSCM automatically dropped repositories with very different values in matching variables during the pre-treatment period, resulting in a final sample size of 8,965 repositories used for the GSCM estimation, with 5,435 repositories in the treatment group and 3,530 repositories in the control group. Table 1 provides descriptions and summary statistics for repository- month-level variables based on the sample used for the GSCM estimation.\nIdentification: In our study, there may be dynamic unobservables which could influence the outcome. GSCM synthesizes a weighted control unit that closely mirrors the data pattern of the log number of merged pull requests during the pre-treatment period for the treated unit. The outcome variable of this synthetic control unit during the post-treatment period serves as the counterfactual prediction for the treated unit. By modeling the trend of the outcome variable, the GSCM can naturally accommodate the influence of unobservable confounders that evolve over time. Furthermore, it allows each treatment unit to have a different treatment period and can efficiently construct synthetic control units from a relatively small control sample.\nWe further apply the equivalence test to examine the presence of a pre-treatment trend in GSCM (Pan and Qiu 2022, Egami et al. 2023, Wang et al. 2023). This is a standard way to test the performance of GSCM (Liu et al. 2024), as the equivalence test better incorporates substantive considerations of what constitutes good balance on covariates and placebo outcomes compared to traditional tests (Hartman and Hidalgo 2018). Specifically, we use the two-one-sided t (TOST) test. The test includes an equivalence range within which differences are deemed inconsequential (Hartman and Hidalgo 2018, Lakens et al. 2018). The test is considered passed if the average prediction error for any pre-treatment period is within"}, {"title": "", "content": "the equivalence range (Liu et al. 2024). The result of the equivalence test is shown in Figure B.1 of Online Appendix B. We observe that the average prediction error"}]}