{"title": "Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles", "authors": ["Zuoyin Tang", "Jianhua He", "Dashuai Pei", "Kezhong Liu", "Tao Gao"], "abstract": "Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs, which are difficult to be met locally at AVs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send driving assistance requests to the LLMs. LLMs deployed at the edge of the networks or remote clouds process the requests and generate driving assistance instructions for the CAVs. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. As there is no published work on assessing LLM of driving theory and skills, we design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. These questions are close to the official UK driving theory test ones. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% (just below the 86% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-0 has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.", "sections": [{"title": "I. INTRODUCTION", "content": "Road safety is a global challenge with at least one million people dying on the roads globally every year and millions more seriously injured [1]. Autonomous vehicles (AVs) as a part of the safe vehicles dimension hold great potentials on improving driving safety. In the last several years there were significant advances on autonomous driving technologies. Field trials of self-driving vehicles have been demonstrated and robotaxis services have been provided in some cities. However, it still faces many technical challenges, such as the sensor limitations, lack of other vehicles' driving intention, incompetent on handling complex driving environments and corner cases [2]. For example, most AV sensors such as cameras and Lidars are limited to line-of-sight sensing and their performance can be largely affected by weather and light conditions. Furthermore, the deep learning models trained with large datasets for perception of driving environment and path planning may not see some unusual scenes and can't handle them due to low generalization capabilities."}, {"title": "A. Existing works on LLM empowed autonomous driving", "content": "To address the big challenge of handling corner cases, applying large language models (LLMs) to support autonomous driving is receiving increasing research interest by exploiting the excellent generalization abilities of LLMs.\n1) LLM for annotation: D. Wu et al applied LLM for annotation of datasets for applications of capturing objects from driving scenes following flexible human commands [5], similar to that used by human driving.\n2) LLM for end to end driving: J. Mao et al proposed an approach that transforms the OpenAI GPT-3.5 model into a reliable motion planner for autonomous vehicles [6]. Driving environment perception and prediction and the ego vehicle states are converted to language prompt. The LLM model was fine-tuned to produce a planned trajectory alongside its decision-making process in natural language.\nAn interpretable end-to-end autonomous driving system utilizing LLMs was proposed [7], which can interpret vehicle actions and provide reasoning and answer diverse questions from human users for enhanced interaction. Additionally, the proposed system DriveGPT4 can predict vehicle low-level control signals in an end-to-end fashion.\nH. Sha et al employed LLMs as a decision-making component for complex autonomous driving scenarios. They developed algorithms for translating LLM decisions into actionable driving commands and LLM decisions are integrated with low-level controllers [8]."}, {"title": "B. Research motivation", "content": "While there have been many interesting works attempting to apply LLMs for autonomous driving, these works mainly focus on using local LLMs and there are still several major technical challenges. Generally, LLMs need more parameters to have a higher capacity to capture complex patterns in the training data and potentially have better performance. These models will have substantial computation and memory requirements due to their large parameter size, which are difficult to be satisfied by embedded driving systems at AVs. Furthermore, autonomous driving is safety critical with much higher safety expectation than human driving. While human drivers are required to pass both theory and practical road tests before they are qualified for driving on the public roads, there is no strict assessment of the LLMs for autonomous driving. The reported safety performance of the LLM empowered autonomous driving is much lower than that of human drivers [9]. Therefore, there are important questions which are not addressed:\n\u2022 How to efficiently and safe use LLM for CAVs?\n\u2022 How much driving knowledge and skills do LLMs understand?\n\u2022 How well is LLMs qualified and how much can we trust them for driving and/or assistance according to official driving theory test?"}, {"title": "II. SYSTEM FRAMEWORK OF LLM ASSISTED DRIVING FOR CAVS", "content": "In contrast to the most existing works on applying local LLMs deployed in vehicles for real time autonomous driving, we investigate a new approach of exploiting LLMs deployed in remoted clouds or network edges to assist CAV driving. A system framework diagram is presented in Fig.1. In the LLM assisted driving system, CAVs communicate with LLMs via the vehicle to everything (V2X) technologies. For example, they can communicate with LLMs deployed at the roadside unit (RSU) through direct vehicle to vehicle (V2V) communication, or via vechile to infrastructure (V2I) links to cellular base stations and then connect to RSUs. Alternatively, CAVS may communicate with LLMs deployed at remote clouds via V2I links to cellular base stations and Internet.\nThe LLMs may be the general ones provided from the leading LLM companies, such as OpenAI, Anthrotic, Google and Meta. These models include both single modal ones (such as text based ChatGPT model) and multi-modal ones which can process text, image and/or audio inputs (such as GPT-40, Claude3 and Gemni Pro). While these LLMs are not trained specifically for CAV driving tasks, their rich knowledge and strong generalization abilities obtained from training over huge corpus may perform well for the tasks. Furthermore, customized LLMs may be trained for the CAV driving assistance tasks, which can have better understanding of the domain knowledge and applications, and provide reliable and robust assistance services to the CAVs.\nThere can be a wide range of autonomous driving assistance services that are provided by the LLMs on top of CAV applications, which include remote driving with or without road perception at the LLMs, emergency response, occasional driving assistance at complex road or driving scenarios. With CAV technologies, they can share their status, sensing and driving intents to cooperate on environment perception and driving. Third Generation Partnership Project (3GPP) has specified advanced driving uses with enhanced V2X communications [4]. These uses include cooperative sensing, vehicle platooning, remote driving and cooperative driving [4]. The LLMs can be used to support all these advanced driving uses and other driving assistance applications.\nOne driving assistance example with LLM is shown in Fig. 1. One AV (shown as AV1) caught fire and stopped in the middle of road out of the operational design domain (ODD). Two CAVS (CAV1 and CAV2) went by and didn't know how to deal with the road accident. CAVs sent a request to a LLM located at the nearby RSU for driving assistance. The LLM replied to CAV1 with an instruction of turninging and leaving quickly. CAV1 followed the LLM instruction to avoid damage and further accidents.\nWhile the LLM assisted driving holds great potential for safe and efficient CAV driving, there are some major chal- lenges to be tackled. Firstly, the CAV driving tasks are safety and latency critical. The remote deployment of LLM may incur excessive communication and computation time, which can have large impact on the driving assistance services, such as remote driving and emergency response services. The feasibility and performance guarantee issues will need to be studied further for the application LLM to CAV driving. Secondly, LLMs are known to have hallucinations which refer to outputs generated by LLMs that are convincingly wrong or misleading. This can present significant risks and adverse impact on CAV driving. Furthermore, the human drivers are required to qualify for driving with a driving licence obtained by passing the driving test. This should be applied to the AI drivers or LLM driving assistants, which will be studied in the next section."}, {"title": "III. RESEARCH METHODOLOGY", "content": "In this section we design theoretic driving test for LLMs to examine how well they understand the highway code and traffic signs. For human drivers, they are required to pass theory test to prove they are qualified with right knowledge, understanding and attitude to be a safe and responsible driver [14]. In the UK, the driving theory test include two parts, 1) a multiple choice test to assess the knowledge of driving theory and highway code (such as the road rules and driving practice), and 2) a hazard perception test to assess the hazard recognition skills. In this paper we will mainly focus on the UK multiple choice test to assess driving theory knowledge. The hazard perception test is left for our future work.\nIn the UK driving multiple choice test there are 50 multiple choice questions, each with 4 choices and one or more correct answers. The test questions cover a variety of topics relating to road safety and environment. 57 minutes are given to human learn drivers for this multiple choice test. To pass the multiple choice part of the theory test, at least 43 out of the 50 test questions must be answered correctly for human learner car drivers. This pass criteria of 86% accuracy will also be applied to the LLMs to be used for driving assistance."}, {"title": "IV. EXPERIMENT RESULTS AND DISCUSSIONS", "content": "As the models GPT-3.5 and GPT-4 do not have vision capabilities, only questions from dataset DS-Text are asked to them. On the other hand, GPT-40 is tested by only questions with images from dataset DS-Image. Questions without images are not used to test GPT-40 as GPT-40 is expected to have similar performance as GPT-4 with these questions.\nIn the official UK theory tests, each test has exactly 50 questions. While the LLMs can be tested multiple times with 50 questions in each test, an alternative approach is used in this paper with LLMs being asked all the questions in one test. The pass decision on the test is then made on the accuracy over all the questions against the passing threshold (86%).\nFor all the three tested LLMs, model temperature of 0 is used. Model temperature determines whether the output is more random or more predictable. A lower temperature will re- sult in higher probability, i.e., more predictable outputs. Other settings for the LLMs include top_p = 1, max_tokens = 100.\nThe prompt sent to the LLMs includes two parts, system prompt and user content. A specific system prompt setting the role of experience driver to the LLMs is configured as \u201cYou are an experienced driver to help answer UK driving theory test questions, which have multiple choices but one correct answer. Your response should include only the first letter (such as A or B) of the correct answer, without any explanation.\" The user content part includes the test question, the test question options and string \"Answer: \"."}, {"title": "B. Test Results and Discussion", "content": "Experiment results for the LLMs on the theory test are presented in Table II.\nIn Table II columns 2 and 3 shows the number of total test questions and the number of correctly answered questions. It can be observed that for the test questions without images, the accuracy for GPT-3.5 model is 79%, which is below the passing threshold of 86% for the UK driving theory test. As the questions with images are more challenging, GPT-3.5 model may perform worse than on the text only questions. Compared to GPT-3.5 model, GPT-4 model performs much better with an accuracy of 95% and passed the theory test. The result showed improved domain knowledge of GPT-4 model in driving theory and knowledge as claimed by OpenAI. But it is also noted that the cost of testing GPT-4 is more than 4 times higher than that for GPT3.5. Wihile Qwen and MiniCPM-2B models fail the test, with acurracy of 60% and 57%, respectively, Ernie shows a much better performance, with an accuracy of 85%, which is very close to the passing threshold of 86%.\nFor the questions with images, two LLM models GPT-40 and MiniCPM-V2 with vision capabilities are tested. GPT-40 achieves an impressive accuracy of 96% over 53 questions, demonstrate great image and scenario understanding capabili- ties. On the other hand, MiniCPM-V2 achieves an accuracy of 72%, which is reasonably good for a small open source LLM. The advantage of MiniCPM models is the fast response speed and low communication delay when deployed locally.\nThe above results show that the GPT-4 model can achieve a high accuracy to pass the UK driving theory test (on multiple choice test part), while the cheaper versions GPT-3.5 and other ones failed the theory test. The performance of GPT-40 model on questions with images is very impressive. With respect to communication and computation time, it takes about 0.7 second, 0.9 second and 3.4 second on average to test GPT- 3.5, GPT-4 and GPT-40 for one question, respectively. The above time covers both communication and LLM computation. MiniCPM-2B and MiniCPM-Llama3-V2.5 take less than 0.4 second and 2 seconds for one question respectively. It can be observed that the time taken on processing one test question will unlikely meet the real-time requirement for driving plan- ning and control, but it may be acceptable for some driving assistance services such as emergency response.\nFurthermore, we check the impact of model temperature and prompt content for OpenAI models. In the above experiments, model temperature is set to 1 for all three tested LLMs. For the GPT-3.5 model, an additional configuration of model temperature of 0.7 is also used. Test results show that a slightly improved accuracy of 80% (with 450 out of 563 questions correctly answered). In addition, an additional more general system prompt is tried for GPT-3.5 model. The new system prompt says \"You will assist on helping answer UK driving theory test questions, which have multiple choices but one correct answer. Your response should include only the first letter (such as A or B) of the correct answer, without any explanation.\" In this way, the LLM is instructed as a general user instead of experience driver to answer the driving test questions. With the new system prompt, the accuracy is reduced to 78.3% (with 441 questions correctly answered), which is not surprising."}, {"title": "V. CONCLUSION", "content": "LLMs hold great potentials for connected autonomous vehicles (CAVs). In this paper we investigated LLMs assisted CAV driving, which can exploit the generalization capabilities of the LLMs. An important question which has not been answered is how safe and qualified is LLM for CAV assistance according to driving theory test. We tested the three OpenAI LLMs and several other LLMs on understanding of driving theory knowledgeand skills with multiple choice theory test questions. Experiment results showed that the fast and less inexpensive models (GPT3.5, Qwen, Ernie and MiniCPM- 2B) failed the theory test. Only model GPT-4 passed the driving theory test with an accuracy of 95%. The GPT-40 and MiniCPM-Llama3-V2.5 models with vision capability achieved an accuracy of 96% and 72% over test questions with images. GPT-40 demonstrated strong vision capability and potential for autonomous driving assistance. The cost and time of using these models to answer the test questions were also measured, which showed GPT-4 was much more expensive to use with the benefit of higher accuracy. It is noted that that while the GPT-4 model may pass the driving theory test with a passing threshold of 86%, the expectation of the publics on the LLMs accuracy may be much higher for them to provide safety critical driving assistance services. Therefore, further performance improvement with the LLMs may still be needed. In our future work we plan to assess more LLMs on their driving knowledge with the theory test questions."}]}