{"title": "Testing Large Language Models on Driving Theory Knowledge and Skills for Connected Autonomous Vehicles", "authors": ["Zuoyin Tang", "Jianhua He", "Dashuai Pei", "Kezhong Liu", "Tao Gao"], "abstract": "Handling long tail corner cases is a major challenge faced by autonomous vehicles (AVs). While large language models (LLMs) hold great potentials to handle the corner cases with excellent generalization and explanation capabilities and received increasing research interest on application to autonomous driving, there are still technical barriers to be tackled, such as strict model performance and huge computing resource requirements of LLMs, which are difficult to be met locally at AVs. In this paper, we investigate a new approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send driving assistance requests to the LLMs. LLMs deployed at the edge of the networks or remote clouds process the requests and generate driving assistance instructions for the CAVs. A key issue for such LLM assisted driving system is the assessment of LLMs on their understanding of driving theory and skills, ensuring they are qualified to undertake safety critical driving assistance tasks for CAVs. As there is no published work on assessing LLM of driving theory and skills, we design and run driving theory tests for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5) with more than 500 multiple-choices theory test questions. These questions are close to the official UK driving theory test ones. Model accuracy, cost and processing latency are measured from the experiments. Experiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% (just below the 86% passing threshold), other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT4-0 has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. While GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT4 is much higher, almost 50 times of that of using GPT3.5. The results can help make decision on the use of the existing LLMs for CAV applications and balancing on the model performance and cost.", "sections": [{"title": "I. INTRODUCTION", "content": "Road safety is a global challenge with at least one million people dying on the roads globally every year and millions more seriously injured [1]. Autonomous vehicles (AVs) as a part of the safe vehicles dimension hold great potentials on improving driving safety. In the last several years there were significant advances on autonomous driving technologies. Field trials of self-driving vehicles have been demonstrated and robotaxis services have been provided in some cities. However, it still faces many technical challenges, such as the sensor limitations, lack of other vehicles' driving intention, incompetent on handling complex driving environments and corner cases [2]. For example, most AV sensors such as cameras and Lidars are limited to line-of-sight sensing and their performance can be largely affected by weather and light conditions. Furthermore, the deep learning models trained with large datasets for perception of driving environment and path planning may not see some unusual scenes and can't handle them due to low generalization capabilities."}, {"title": "A. Existing works on LLM empowed autonomous driving", "content": "To address the big challenge of handling corner cases, applying large language models (LLMs) to support autonomous driving is receiving increasing research interest by exploiting the excellent generalization abilities of LLMs.\n1) LLM for annotation: D. Wu et al applied LLM for annotation of datasets for applications of capturing objects from driving scenes following flexible human commands [5], similar to that used by human driving.\n2) LLM for end to end driving: J. Mao et al proposed an approach that transforms the OpenAI GPT-3.5 model into a reliable motion planner for autonomous vehicles [6]. Driving environment perception and prediction and the ego vehicle states are converted to language prompt. The LLM model was fine-tuned to produce a planned trajectory alongside its decision-making process in natural language.\nAn interpretable end-to-end autonomous driving system utilizing LLMs was proposed [7], which can interpret vehicle actions and provide reasoning and answer diverse questions from human users for enhanced interaction. Additionally, the proposed system DriveGPT4 can predict vehicle low-level control signals in an end-to-end fashion.\nH. Sha et al employed LLMs as a decision-making component for complex autonomous driving scenarios. They developed algorithms for translating LLM decisions into actionable driving commands and LLM decisions are integrated with low-level controllers [8]."}, {"title": "B. Research motivation", "content": "While there have been many interesting works attempting to apply LLMs for autonomous driving, these works mainly focus on using local LLMs and there are still several major technical challenges. Generally, LLMs need more parameters to have a higher capacity to capture complex patterns in the training data and potentially have better performance. These models will have substantial computation and memory requirements due to their large parameter size, which are difficult to be satisfied by embedded driving systems at AVs. Furthermore, autonomous driving is safety critical with much higher safety expectation than human driving. While human drivers are required to pass both theory and practical road tests before they are qualified for driving on the public roads, there is no strict assessment of the LLMs for autonomous driving. The reported safety performance of the LLM empowered autonomous driving is much lower than that of human drivers [9]. Therefore, there are important questions which are not addressed:\n\u2022 How to efficiently and safe use LLM for CAVs?\n\u2022 How much driving knowledge and skills do LLMs understand?\n\u2022 How well is LLMs qualified and how much can we trust them for driving and/or assistance according to official driving theory test?\nIn view of the research potentials and challenges of LLMs for CAV driving or assistance, we are motivated to propose an approach of applying remote or edge LLMs to support autonomous driving. With this approach connected autonomous vehicles (CAVs) send requests of driving assistance to the LLMs. The LLMs are deployed at the edge of the networks or remote clouds. They process the request and generate driving assistance for the CAVs. While connected autonomous vehicles (CAVs) has been considered as a key to address the challenges faced by autonomous driving and is widely studied [3], to the best of our knowledge, application of LLMs for CAVs has rarely been studied.\nIn addition, we aim to assess the LLMs on their knowledge of driving theory and skills in a way to human driver test, before they can be used to undertake safety critical driving assistance services for CAVs. Compared to the practical driving skill test on roads or through simulations to test the LLMs' capabilities of perception and controlling vehicles, we believe driving theory test of LLMs are also very important and relatively easy and controllable. While LLMs have been tested and demonstrated impressive performances over different fields such as laws, education and economics, driving theory test of LLMs has been rarely reported. In this paper we design and run driving theory test for several proprietary LLM models (OpenAI GPT models, Baidu Ernie and Ali QWen) 1 and open-source LLM models (Tsinghua MiniCPM-2B and MiniCPM-Llama3-V2.5). These questions are close to those used in the official UK driving theory tests. Model accuracy, cost and processing latency are measured from the experiments.\nExperiment results show that while model GPT-4 passes the test with improved domain knowledge and Ernie has an accuracy of 85% just below passing threshold, other LLM models including GPT-3.5 fail the test. For the test questions with images, the multimodal model GPT-40 has an excellent accuracy result of 96%, and the MiniCPM-Llama3-V2.5 achieves an accuracy of 76%. It is also noted that while GPT-4 holds stronger potential for CAV driving assistance applications, the cost of using model GPT-4 is much higher,"}, {"title": "II. SYSTEM FRAMEWORK OF LLM ASSISTED DRIVING FOR CAVS", "content": "In contrast to the most existing works on applying local LLMs deployed in vehicles for real time autonomous driving, we investigate a new approach of exploiting LLMs deployed in remoted clouds or network edges to assist CAV driving. A system framework diagram is presented in Fig.1. In the LLM assisted driving system, CAVs communicate with LLMs via the vehicle to everything (V2X) technologies. For example, they can communicate with LLMs deployed at the roadside unit (RSU) through direct vehicle to vehicle (V2V) communication, or via vechile to infrastructure (V2I) links to cellular base stations and then connect to RSUs. Alternatively, CAVS may communicate with LLMs deployed at remote clouds via V2I links to cellular base stations and Internet.\nThe LLMs may be the general ones provided from the leading LLM companies, such as OpenAI, Anthrotic, Google and Meta. These models include both single modal ones (such as text based ChatGPT model) and multi-modal ones which can process text, image and/or audio inputs (such as GPT-40, Claude3 and Gemni Pro). While these LLMs are not trained specifically for CAV driving tasks, their rich knowledge and strong generalization abilities obtained from training over huge corpus may perform well for the tasks. Furthermore, customized LLMs may be trained for the CAV driving assistance tasks, which can have better understanding of the domain knowledge and applications, and provide reliable and robust assistance services to the CAVs.\nThere can be a wide range of autonomous driving assistance services that are provided by the LLMs on top of CAV applications, which include remote driving with or without road perception at the LLMs, emergency response, occasional driving assistance at complex road or driving scenarios. With CAV technologies, they can share their status, sensing and driving intents to cooperate on environment perception and driving. Third Generation Partnership Project (3GPP) has specified advanced driving uses with enhanced V2X communications [4]. These uses include cooperative sensing, vehicle platooning, remote driving and cooperative driving [4]. The LLMs can be used to support all these advanced driving uses and other driving assistance applications.\nOne driving assistance example with LLM is shown in Fig. 1. One AV (shown as AV1) caught fire and stopped in the middle of road out of the operational design domain (ODD). Two CAVS (CAV1 and CAV2) went by and didn't know how to deal with the road accident. CAVs sent a request to a LLM located at the nearby RSU for driving assistance. The LLM replied to CAV1 with an instruction of turninging and leaving quickly. CAV1 followed the LLM instruction to avoid damage and further accidents.\nWhile the LLM assisted driving holds great potential for safe and efficient CAV driving, there are some major challenges to be tackled. Firstly, the CAV driving tasks are safety and latency critical. The remote deployment of LLM may incur excessive communication and computation time, which can have large impact on the driving assistance services, such as remote driving and emergency response services. The feasibility and performance guarantee issues will need to be studied further for the application LLM to CAV driving. Secondly, LLMs are known to have hallucinations which refer to outputs generated by LLMs that are convincingly wrong or misleading. This can present significant risks and adverse impact on CAV driving. Furthermore, the human drivers are required to qualify for driving with a driving licence obtained by passing the driving test. This should be applied to the AI drivers or LLM driving assistants, which will be studied in the next section."}, {"title": "III. RESEARCH METHODOLOGY", "content": "In this section we design theoretic driving test for LLMs to examine how well they understand the highway code and traffic signs. For human drivers, they are required to pass theory test to prove they are qualified with right knowledge, understanding and attitude to be a safe and responsible driver [14]. In the UK, the driving theory test include two parts, 1) a multiple choice test to assess the knowledge of driving theory and highway code (such as the road rules and driving practice), and 2) a hazard perception test to assess the hazard recognition skills. In this paper we will mainly focus on the UK multiple choice test to assess driving theory knowledge. The hazard perception test is left for our future work.\nIn the UK driving multiple choice test there are 50 multiple choice questions, each with 4 choices and one or more correct answers. The test questions cover a variety of topics relating to road safety and environment. 57 minutes are given to human learn drivers for this multiple choice test. To pass the multiple choice part of the theory test, at least 43 out of the 50 test questions must be answered correctly for human learner car drivers. This pass criteria of 86% accuracy will also be applied to the LLMs to be used for driving assistance."}, {"title": "C. LLMs Used in Theory Test", "content": "There are several powerful LLMs from leading companies such as Anthropic, Google, OpenAI, Ali and Baidu. Several proprietary LLMs from OpenAI, ALi and Baidu are chosen for driving theory test in this paper, which are among the best performing ones.\n1) OpenAI Models: The three selected OpenAI models (GPT-3.5 Turbo, GPT-4 and GPT-40) have different capabilities and price points 3. GPT-3.5 Turbo (called GPT-3.5 for simplicity in the remaining of the paper) is a fast and inexpensive model for simpler tasks. It supports 16K context window and is optimized for dialog. GPT-4 was built with broad general knowledge and domain expertise, which shows much stronger performance in the driving theory test. But GPT-4 model is much more expensive with a input price 60 times of that for GPT-3.5. GPT-40 is OpenAI's most advanced multimodal model, which is faster and cheaper than GPT-4, and has stronger vision capabilities. The model has 128K context.\nThe OpenAI API is used to call the LLMs with input of test questions and obtain the model prediction output. Table I show the price points of the used OpenAI LLMs in the units of 1M tokens, on 1 June 2024.\n2) Alibaba and Baidu LLM Models: The Tongyi Qian-wen (Qwen) LLM model is provided by the Alibaba to the open-source community 4. It was pre-trained on multilingual data covering various industries and domains, with Qwen-72B being trained over 3 trillion tokens of data. The model can be used for many text understanding and generation tasks, such as language understanding, coding, reasoning, multilingual capabilities, human preference, agent, retrieval-augmented generation (RAG). Qwen 1.5 is the Beta version of Qwen 2. Qwen 1.5 includes 6 model sizes: 0.5B, 1.8B, 4B, 7B, and 72B, all of which support the context length of 32768 tokens 5. In this paper the Qwen LLM API service is used for inference, which is free of charge for registered users.\nErnie LLM is developed by Baidu, which is boosted by a diverse range of training data possessed by Baidu, especially that on Chinese language, service applications, and knowledge 6."}, {"title": "IV. EXPERIMENT RESULTS AND DISCUSSIONS", "content": "As the models GPT-3.5 and GPT-4 do not have vision capabilities, only questions from dataset DS-Text are asked to them. On the other hand, GPT-40 is tested by only questions with images from dataset DS-Image. Questions without images are not used to test GPT-40 as GPT-40 is expected to have similar performance as GPT-4 with these questions.\nIn the official UK theory tests, each test has exactly 50 questions. While the LLMs can be tested multiple times with 50 questions in each test, an alternative approach is used in this paper with LLMs being asked all the questions in one test. The pass decision on the test is then made on the accuracy over all the questions against the passing threshold (86%).\nFor all the three tested LLMs, model temperature of 0 is used. Model temperature determines whether the output is more random or more predictable. A lower temperature will result in higher probability, i.e., more predictable outputs. Other settings for the LLMs include top_p = 1, max_tokens = 100.\nThe prompt sent to the LLMs includes two parts, system prompt and user content. A specific system prompt setting the role of experience driver to the LLMs is configured as \u201cYou are an experienced driver to help answer UK driving theory test questions, which have multiple choices but one correct answer. Your response should include only the first letter (such as A or B) of the correct answer, without any explanation.\" The user content part includes the test question, the test question options and string \"Answer: \"."}, {"title": "V. CONCLUSION", "content": "LLMs hold great potentials for connected autonomous vehicles (CAVs). In this paper we investigated LLMs assisted CAV driving, which can exploit the generalization capabilities of the LLMs. An important question which has not been answered is how safe and qualified is LLM for CAV assistance according to driving theory test. We tested the three OpenAI LLMs and several other LLMs on understanding of driving theory knowledgeand skills with multiple choice theory test questions. Experiment results showed that the fast and less inexpensive models (GPT3.5, Qwen, Ernie and MiniCPM-2B) failed the theory test. Only model GPT-4 passed the driving theory test with an accuracy of 95%. The GPT-40 and MiniCPM-Llama3-V2.5 models with vision capability achieved an accuracy of 96% and 72% over test questions with images. GPT-40 demonstrated strong vision capability and potential for autonomous driving assistance. The cost and time of using these models to answer the test questions were also measured, which showed GPT-4 was much more expensive to use with the benefit of higher accuracy. It is noted that that while the GPT-4 model may pass the driving theory test with a passing threshold of 86%, the expectation of the publics on the LLMs accuracy may be much higher for them to provide safety critical driving assistance services. Therefore, further performance improvement with the LLMs may still be needed. In our future work we plan to assess more LLMs on their driving knowledge with the theory test questions."}]}