{"title": "Collaborative Cognitive Diagnosis with Disentangled Representation Learning for Learner Modeling", "authors": ["Weibo Gao", "Qi Liu", "Linan Yue", "Fangzhou Yao", "Hao Wang", "Yin Gu", "Zheng Zhang"], "abstract": "Learners sharing similar implicit cognitive states often display comparable observable problem-solving performances. Leveraging collaborative connections among such similar learners proves valuable in comprehending human learning. Motivated by the success of collaborative modeling in various domains, such as recommender systems, we aim to investigate how collaborative signals among learners contribute to the diagnosis of human cognitive states (i.e., knowledge proficiency) in the context of intelligent education. The primary challenges lie in identifying implicit collaborative connections and disentangling the entangled cognitive factors of learners for improved explainability and controllability in learner Cognitive Diagnosis (CD). However, there has been no work on CD capable of simultaneously modeling collaborative and disentangled cognitive states. To address this gap, we present Coral, a Collaborative cognitive diagnosis model with disentangled representation learning. Specifically, Coral first introduces a disentangled state encoder to achieve the initial disentanglement of learners' states. Subsequently, a meticulously designed collaborative representation learning procedure captures collaborative signals. It dynamically constructs a collaborative graph of learners by iteratively searching for optimal neighbors in a context-aware manner. Using the constructed graph, collaborative information is extracted through node representation learning. Finally, a decoding process aligns the initial cognitive states and collaborative states, achieving co-disentanglement with practice performance reconstructions. Extensive experiments demonstrate the superior performance of Coral, showcasing significant improvements over state-of-the-art methods across several real-world datasets. Our code is available at https://github.com/bigdata-ustc/Coral.", "sections": [{"title": "1 Introduction", "content": "It is a common notion that individuals with similar implicit states frequently exhibit similar explicit behaviors. Therefore, establishing interconnections among similar users is crucial for understanding human behaviors. For instance, social connections play a pivotal role in understanding current consumer preferences and predicting future behaviors [43]. Similarly, in the"}, {"title": "2 Related Work", "content": "Cognitive Diagnosis As a fundamental task, cognitive diagnosis (CD) has been well-researched for decades in educational psychology [26, 4, 56]. It aims to profile the implicit cognitive states (i.e., the proficiency of specific knowledge concepts) of learners by exploiting observed practice records (e.g., correct or wrong). Existing research on CD assumes that learners' knowledge proficiency is proportional to their practice performance and thus can be diagnosed through predicting their practice performance [12]. Since the diagnostic results can be applied to many intelligent applications, such as exercise recommendation [18] and learning path suggestions [58], many CD models have been proposed in recent years. The early works from psychology like IRT [16] and MIRT [1] focus on modeling learners' answering process by predicting the probability of a learner answering a question correctly, which utilizes latent factors as the learner's ability. These methods lack interpretability, i.e., they are inability to output explicit multidimensional diagnostic results on each knowledge concept. To achieve better interpretability, later diagnostic models focus on incorporating knowledge concepts of questions to diagnose learners' proficiency on all knowledge concepts [39, 47, 48, 33]. Representative NCDM [41] adopts neural networks to model non-linear interactions instead of handcrafted interaction functions in previous works (e.g., IRT, and MIRT). In summary, existing CD studies enhance diagnostic accuracy by fully utilizing the inner-learner information (i.e., individual attributions and explicit practice records) [42, 54]and question-side features (e.g., difficulty [16, 39], textual content [27], and educational relations [12, 14, 8]). However, to the best of our knowledge, the problem of collaborative diagnostic modeling remains largely unexplored.\nCollaborative modeling in Education Collaborative connections among learners in the education context commonly refer to learners with similar explicit practice behaviors, testing scores and implicit knowledge proficiency [29, 57, 46]. However, due to the complexity and implicitness of the human learning process, these relations are commonly not explicitly and directly available. Existing studies [29, 13] in AI Education have attempted to design different similarity functions based on practice data to compute cognitive similarities among learners. However, these methods pose a significant challenge of manually selecting appropriate metrics and corresponding thresholds, introducing additional inductive biases.\nDisentangled Representation Learning Disentangled Representation Learning (DRL)[3], which aims to produce robust, controllable, and explainable representations, has become one of the core problems in machine learning. Typical methods include variational method [20], weakly supervised models [21], as well as the recent combination with the diffusion model [6]. DRL has a wide range of applications in user modeling to disentangle attributes. For example, recommendation with several aspects of users' interests [25, 34], fair user representation to disentangle sensitive attributes [10]. In education, DCD [8] attempts to disentangle learners' cognitive representations via variational framework, which motivates us to conduct a further study on collaborative CD setups."}, {"title": "3 Coral", "content": "We first introduce the problem setup, followed by details on three core components of Coral: i) Disentangled Cognitive Representation Encoding, ii) Collaborative Representation Learning and iii) Decoding and Reconstruction. Figure 2 shows the framework. The algorithm is listed in Algorithm 1."}, {"title": "3.1 Problem Setup", "content": "Our setup considers the human learning dataset D including the practice records between M learners and N questions. The practice records of each learner u is denoted by $x_u = \\{x_{u,i}\\}$, where $X_{u,i}$ equals 1 or 0, representing that learner u answered question i correctly or not, respectively. Each question is related to at least one knowledge concept. The association relations between N questions and C knowledge concepts is represented by C = $\\{c_i\\}_1^N$, where $c_i \\in R^C$ and $c_{i,c}$ equals 1 or 0 denoting that question i is related to concept c or not. The practice records are regarded as the explicit inner-learning information in our context.\nBesides, we consider the collaborative connections among learners with similar cognitive states, which provide the inter-learner information. We define collaborative connections as a graph structure G = (V, E) which contains a set of nodes (i.e., learners) V and a set of edges E where (u, v) $\\in$ E or (u, v) $\\in$ G indicates that the existence of a collaborative connection between learner u and v (i.e., u and v have similar latent cognitive states). Notably, the collaborative connections in educational"}, {"title": "3.2 Disentangled Cognitive Representation Encoding", "content": "The practice response $x_u$ of each learner u provides valuable inner-learner insights regarding his/her proficiency since learners' performance on each question is assumed to be proportional to their cognitive proficiency on question-related knowledge concepts [8]. Therefore, we implement an encoder for encoding the disentangled cognitive state $z_u$ of each learner u by reconstructing their practice responses. For a learner u, we assume that his/her practice performance on candidate questions can be generated from the following distribution:\n$P_\\theta(x_u) = E_{p(C)}[\\int P_\\theta(x_u | z_u, C)p_\\theta(z_u)dz_u ]$,\nwhere p(C) = $p_D(C)$ and $P_\\theta(x_u | z_u, C)$ is naturally a cognitive diagnosis procedure to predict practice performance. The key point of this task is to learn an optimal encoder $p_\\theta(z_u)$ via practice records $x_u$ to encode the cognitive state $z_u$ of each learner u. To optimize $\\Theta$, we introduce a variational distribution $q_\\theta(Z_u | x_u)$ to approximate $p_\\theta(z_u)$, following the VAE literature [3], through maximizing a lower bound of $log p_\\theta(x_u)$ based on the following property.\nProperty 1. max $log p_\\theta(x_u)$ is bounded as follows:\n$log p_\\theta(x_u) \\ge E_{p(C)q_\\theta(z_u|x_u)} [log P_\\theta(x_u | z_u)] \u2013 E_{p(C)} [D_{KL} (q_\\theta(z_u | x_u) || P_\\theta(z_u))]$.\nSee the Appendix A for the proof.\nIn Property 1, the first term reconstructs the true practice performance $x_u$ of learner u and the variational encoder $q_\\theta(z_u | x_u)$ in the second term approximates the true encoder $p_\\theta(z_u)$ by minimizing the KL divergence $D_{KL}$. The variational distribution $q_\\theta(z_u | x_u)$ and the expectation $E_{q_\\theta(z_u | x_u)}$ are intractable, thus we employ the re-parameterization trick [20] for the model optimization.\nFurthermore, the diagnosis procedure $p_\\theta(x_u | z_u, C)$ is achieved by estimating how well a learner u answers question i from both the perspectives of cognitive states and comprehensive abilities. From the perspective of cognitive states, solving question i requires learner u to master all knowledge concepts related to this question. Regarding comprehensive abilities, each learner possesses a latent state reflecting their overall learning ability, which is shared when addressing different questions."}, {"title": "3.3 Collaborative Representation Learning", "content": "Collaborative information among similar learners provides an auxiliary inter-learner insight for cognitive representation learning. However, collaborative connections among learners with similar states are typically not readily accessible. To address this challenge, we design a context-aware graph construction strategy that searches similar neighbors automatically via the initial disentangled cognitive states. Based on the constructed collaborative graph, we can learn collaborative node representations by aggregating collaborative signals to generate collaborative cognitive states."}, {"title": "3.3.1 Context-aware Collaborative Graph Learning", "content": "The core goal of constructing the collaborative graph is to find K optimal neighbors for each learner node in V via their initial disentangled cognitive state $\\{z_u^{(c)}\\}_{c=1}^C$. For different knowledge concepts, the cognitive connections between the same learner pair are typically different. Thereby, it needs to search C groups of similar neighbors for each learner via each disentangled component $z_u^{(c)}$. This means that we would generate C collaborative graphs, i.e., $G = \\{G^{(c)}\\}_{c=1}^C$. Each collaborative"}, {"title": "3.3.2 Collaborative Graph Modeling", "content": "After iteratively searching K neighbors under each concept, we can obtain C collaborative graphs regarding each learner, i.e., $\\{G^{(c)}\\}_{c=1}^C$. Then, we consider collaborative modeling as a node representation learning task within each collaborative graph $G^{(c)}$. It relies on a nonlinear kernel function $\\varphi(\\cdot)$ to aggregate neighboring information and update each disentangled cognitive state, i.e., $r_u^{(c)} = \\varphi(z_u^{(c)}, \\{z_v^{(c)} : (u, v) \\in G^{(c)}\\})$. Given the disentangled learner cognitive states generated by the variational posterior distribution $q_\\theta(z_u|x_u)$ from Property 1, $\\varphi(\\cdot)$ is naturally expected to contain C channels to extract different concept features from similar learners, though projecting the representation $z_u$ into different subspaces, i.e., $\\hat{z}_u^{(c)} = (W_cz_u + b^{(c)})/||(W_cz_u + b^{(c)})||_2$, where $W^{(c)} \\in R^d$ and $b^{(c)} \\in R^d$ are learnable parameters of channel c and $\\sigma(\\cdot)$ is a nonlinear activation function (e.g., Sigmoid), and $||\\cdot||_2$ is L2 normalization ensuring numerical stability. Then the collaborative learner representation modeling in terms of concept c can be described as:\n$r_u^{(c)} = \\frac{1}{|N_u^{(c)}|} \\sum_{v \\in N_u^{(c)}} S_{uv} \\hat{z}_v^{(c)}, S_{uv} = \\frac{\\hat{z}_u^{(c)T} . \\hat{z}_v^{(c)}}{\\sum_{k=1}^K f_{u,v}^{(c)}} + \\frac{f_{u,v}^{(c)}}{\\sum_{k=1}^K f_{u,v}^{(c)}}$,\nwhere $S_{uv}$ is the attention weight between u and v, considering both the collaborative aggregation (the first term) commonly used in graph modeling works [50] and the corresponding context-aware attention (the second term) calculated in the iterative graph construction process in Eq. (7). When K is set large in Eq. (7), there is a possibility of introducing non-collaborative noise. In such cases, $S_{uv}^{(c)}$ can assign lower values to non-collaborative neighbors to mitigate the negative impact of noise, allowing for the adaptive tuning of attention in graph modeling. During training, the channels will remain changing because different subsets of the neighborhood will be searched for dynamically aggregating neighbor information in different iterations."}, {"title": "3.4 Decoding and Reconstruction", "content": "Given the initial disentangled encoding via inner-learner information (section 3.2) and the collaborative representation learning via inter-learner information (section 3.3), this part encourages an alignment between the initial encode $z_u$ and collaborative state $r_u$, formulating a co-disentangled representation as $\\tilde{z}_u = z_u + r_u$. This operation is inspired by the residual block [17] to address the second challenge, where $r_u$ can be treated as a disentangled auxiliary information of $z_u$ from collaborative graphs.\nThe decoding process predicts the practice performance of each learner u on candidate questions, given her co-disentangled representation $\\tilde{z}_u = [z_u^{(1)}, z_u^{(2)},...,z_u^{(C)}]$, i.e., $p_\\theta (\\hat{x}_u) = E_{p_\\theta(C)} [P_\\theta (\\hat{x}_u | \\tilde{z}_u, C)]$, similar to the reconstruction procedure in Eq. (1). Thus, putting Eq. (5) and Eq. (7) together, we have the overall training objective:\n$arg \\min C = \\sum_{u=1}^M [\\sum_{x_{ui} \\in x_u} \\alpha \\cdot BCE (x_{u,i}, P_\\theta(x_{u,i} | z_u, C)) \u2013 \\beta \\cdot D_{KL}  + \\sum_{x_{ui} \\in x_u} BCE (x_{u,i}, P_\\theta(\\hat{x}_{u,i}))]$,\ns.t. $arg \\max \\sum_{c=1}^C \\sum_{k=1}^K L_{u}^{(c),k}$"}, {"title": "4 Experiments", "content": "We empirically evaluate the performances of the proposed Coral model over three real-world datasets and conduct several experiments to prove its effectiveness."}, {"title": "4.1 Experimental Setup", "content": "Datasets We conduct experiments on three real-world datasets: ASSIST [11], Junyi [5] and NeurIPS2020EC [44]. The statistics of datasets are listed in Table 1. The details about datasets and preprocessing are depicted in the Appendix C.\nBaselines The baselines include the matrix factorization-based model, i.e., PMF [35], the typical latent factor models derived from educational psychology, including IRT [16], MIRT [1], and the neural networks-based models, including NCDM [41], RCD [12], KaNCD [42] and DCD [8].\nEvaluation Since cognitive states cannot be directly observed in practice, it is common to indirectly evaluate CDMs through the student performance prediction task on test datasets [4]. To evaluate prediction performance, we adopt ACC and AUC and F1-score as metrics from the perspective of classification, using a threshold of 0.5, and RMSE as metrics from the perspective of regression, following previous work [12, 24].\nSettings We set the dimension size d as 20, the layer of graph modeling as 2, and the mini-batch size as 512. In the training stage, we select the learning rate from {0.002, 0.005, 0.01, 0.02, 0.05}, select \u03b1 from {0.05, 0.1, 0.5, 1} and \u03b2 from {0.25, 0.5, 1}, and select neighboring number K from {1, 2, 3, 4, 5, 10, 15, 20, 15, 30, 25, 40, 45, 50}. All network parameters are initialized with Xavier initialization [15]. Each model is implemented by PyTorch [38] and optimized by Adam optimizer [19]. Specially, for the implementation of baselines, we set the dimensional sizes of each representation in PMF, NCDM, KaNCD, RCD and DCD as the number of knowledge concepts. All experiments are conducted on a Linux server equipped with two 3.00GHz Intel Xeon Gold 5317 CPUs and two Tesla A100 40G GPUs."}, {"title": "4.2 Experimental Results", "content": "Prediction Comparison We evaluate prediction performance of Coral against baselines under three setups: normal, sparse, and cold-start scenarios.\nWe extend our analysis to assess the performance of Coral in sparse scenarios. In order to simulate varied sparse environments, we systematically discard 80%, 60%, 40%, and 20% of the training data from the ASSIST dataset under the normal settings described above. The experimental results"}, {"title": "Collaborate Graph Learning", "content": "We investigate the influence of the generated neighbor number K on diagnostic performance. Figure 3 (c) displays the prediction performances for various values of K on Junyi under the normal scenario. The model performance exhibits improvement as K increases, particularly noticeable when K is small. This observation suggests that the inter-learner information automatically retrieved by Coral contributes positively to the model. However, once K surpasses a threshold, the performance gain becomes less pronounced. This diminishing effect arises because users beyond the threshold (i.e., K = 10 in this dataset) may lack significant collaborative relationships, thus limiting the useful clues they can offer. We observe that when K exceeds the threshold, the model's performance remains acceptable, and even the performance improves after K exceeds 30. This indicates that Coral effectively perceives the similarity functions of the scenario and collaborative context. Consequently, it assigns lower similarity scores to non-collaborative neighbors, robustly adjusting the attention weight in graph modeling."}, {"title": "Disentanglement", "content": "We evaluate the disentanglement level achieved by assessing independence of dimensions within $z_u$. The independence level $IL(u)$ of each $z_u$ is quantified as $IL(u) = \\sum_{c=1}^C (2 \u2013 1) \\sum_{1\\le i,j\\le d} |z_u^{(c)}[i] \u2013 z_u^{(c)}[j]|$, where $z_u^{(c)}[i]$ represents the $i^{th}$ dimension of $z_u^{(c)}$, following a prior methodology [51, 43, 53]. In Figure 3 (d), we depict $IL = \\sum_{u=1}^M IL(u)$ and the corresponding model performances at different training epochs on ASSIST (with the normal setup). Notably, Coral (setting K = 10) gradually achieves a high degree of disentanglement during the training process, and the model performances generally exhibit a positive correlation with the degree of disentanglement. This observation reveals the effectiveness of the disentanglement process."}, {"title": "Explainability", "content": "We further investigate the interpretability of the cognitive diagnosis outputs based on Coral. We aim to explore whether Coral can provide reasonable predictions for knowledge concepts that learners have not practiced in the training set during actual inference. Firstly, we randomly select a target student u from the Junyi dataset and identify 5 knowledge concepts (denoted as A ~ E) that u has not learned in the training data. Subsequently, based on the refined model, we retrieve the top 4 most similar neighboring learners (i.e., $u_1$ ~ $u_4$) to the target student u."}, {"title": "5 Conclusion", "content": "We are pioneering the exploration of collaborative cognitive diagnosis by disentangling the implicit cognitive representations of learners. Extensive experiments demonstrate the superior performance of Coral, showcasing significant improvements over SOTA methods across several real-world datasets. We believe this endeavor marks a crucial step towards collaborative modeling for \"AI Education\". Furthermore, this work offers valuable insights into conscious-aware learner modeling, under the assumption that human learner proficiency can be effectively represented in a disentangled manner."}, {"title": "A Proofs", "content": "Property 1. max $log p_\\theta(x_u)$ is bounded as follows:\n$log p_\\theta(x_u) \\ge E_{p(C)q_\\theta(z_u|x_u)} [log P_\\theta(x_u | z_u)] \u2013 E_{p(C)} [D_{KL} (q_\\theta(z_u | x_u) || P_\\theta(z_u))]$.\nThe proof is as follows.\nProof.\n$log p_\\theta(x_u) = log E_{p(C)} [P_\\theta(x_u | z_u, C) p_\\theta(z_u)]$\n$= E_{p(c)} [log p_\\theta(x_u) q_\\theta(z_u|x_u)]$\n$= E_{p(C)q_\\theta(z_u|x_u)} [log p_\\theta(x_u)]$\n$= E_{p(C)q_\\theta(z_u|x_u)} [log \\frac{p_\\theta (x_u, z_u)}{p_\\theta (z_u | x_u)}]$ \n$= E_{p(C)q_\\theta(z_u|x_u)} [log \\frac{p_\\theta (x_u, z_u)}{p_\\theta (z_u | x_u)} \\frac{q_\\theta (z_u| x_u)}{q_\\theta (z_u| x_u)}]$ \n$= E_{p(C)q_\\theta(z_u|x_u)} [log \\frac{p_\\theta (x_u, z_u)}{q_\\theta (z_u| x_u)} + log  \\frac{q_\\theta (z_u| x_u)}{p_\\theta (z_u | x_u)}]$\n$= E_{p(C)q_\\theta(z_u|x_u)} [log \\frac{p_\\theta (x_u | z_u) p_\\theta (z_u)}{q_\\theta (z_u| x_u)}]$\n$= E_{p(C)} [D_{KL} (q_\\theta (z_u | x_u) || p_\\theta (z_u | x_u))] + E_{p(C)q_\\theta(z_u|x_u)} [log  \\frac{p_\\theta (x_u | z_u) p_\\theta (z_u)}{q_\\theta (z_u| x_u)}]$\n$= E_{p(C)} [D_{KL} (q_\\theta (z_u | x_u) || p_\\theta (z_u | x_u)) \u2013 D_{KL} (q_\\theta (z_u | x_u) || p_\\theta (z_u))] +E_{p(C)q_\\theta(z_u|x_u)} [log p_\\theta (x_u | z_u)]$\n$\\ge E_{p(c)} [E_{q_\\theta (z_u Xu)} log p_\\theta (x_u | z_u) \u2013 D_{KL} (q_\\theta (z_u | x_u) || p_\\theta (z_u))]$,\nwhich completes the proof.\nProperty 2. The DKL(\u00b7) in Eq. (2) can be rewritten as:\n$D_{KL} (q_\\theta (z_u Xu) || p_\\theta (z_u)) = I (z_u, x_u) + D_{KL} (q_\\theta (z_u) || p_\\theta(z_u))$.\nThe proof is as follows.\nProof. Given that $p_\\theta (x_u) = p_{data} (x_u)$ and $q_\\theta (z_u, x_u) = q_\\theta (z_u | x_u) p_\\theta (x_u)$, we then have\n$D_{KL} (q_\\theta (z_u | x_u) || p_\\theta (z_u)) = E_{q_\\theta (z_u Xu)} log  \\frac{q_\\theta (z_u | x_u) \\cdot q_\\theta (z_u)}{p_\\theta (z_u) q_\\theta (x_u)}$\n$= E_{q_\\theta (z_u Xu)} log  \\frac{q_\\theta (z_u | x_u)}{q_\\theta (x_u)} + E_{q_\\theta (z_u Xu)}  log  \\frac{q_\\theta (x_u)}{p_\\theta (z_u)}.$\n$= E_{q_\\theta (z_u Xu)} log  \\frac{q_\\theta (z_u Xu) \\cdot p_{data} (x_u)}{q_\\theta (x_u)} + E_{q_\\theta (z_u)} [log  \\frac{q_\\theta (z_u)}{p_\\theta (z_u)}]$\n$= E_{q_\\theta (z_u X_u)} log  \\frac{q_\\theta (z_u Xu)}{q_\\theta (x_u)} + D_{KL} (q_\\theta (z_u) || p_\\theta (z_u))$,\n$= I (z_u; X_u) + D_{KL} (q_\\theta (z_u) || p_\\theta (z_u))$,\nwhere $I (A; B)$ calculates mutual information (MI) between A and B, i.e. $I(A; B) = E_{p(a,b)} [log \\frac{p(a,b)}{p(a)p(b)}]$. Therefore, the proof is completed."}, {"title": "B Algorithm", "content": "To offer a more comprehensive description of Coral's structure, we outline the algorithm (see Algorithm 1) for the entire model, including four functions and a main function."}, {"title": "C Dataset Description and Preprocessing", "content": "We conduct experiments on three real-world datasets, i.e., ASSIST [11], Junyi [5] and NeurIPS2020EC [44]. The statistics of these datasets are summarized in Table 1. For all datasets, we preserve the first-time exercise-answering record for the same learner-question pairs to support cognitive diagnosis aligning with common settings used in previous related studies [41]. The detailed information on datasets and preprocessing method are depicted as follows:\nASSIST (ASSISTments 2009-2010 \u201cskill builder\u201d) [11] This dataset is an open dataset collected by the ASSISTments online tutoring systems, which has become one of the popular benchmark datasets for cognitive diagnosis. We preserve learners with more than 30 practice records for ASSIST to guarantee that each learner has enough data for diagnosis.\nJunyi [5] This dataset contains learner online learning logs collected from a Chinese online educational platform called Junyi Academy. Nowadays, Junyi is widely used in the evaluation of online education tasks [49, 8]. We randomly select 1,400 learners with more than 15 practice records from Junyi to guarantee that each learner has enough data for diagnosis.\nNeurIPS2020EC [44] This dataset is originated from NeurIPS 2020 Education Challenge, which provides learners' practice logs on mathematical questions from Eedi4. We randomly select 1,000 learners with more than 15 practice records from NeurIPS2020EC to guarantee that each learner has enough data for diagnosis."}, {"title": "D.1 Ablation Study", "content": "We additionally perform ablation studies to assess the impact of key components within Coral. The results in Table 4 depict the performances of Coral (setting K = 5) under various conditions: without the KL term for encoding (w/o KL), without the collaborative aggregation during decoding (w/o collar), and replacing the collaborative graph construction procedure using a knn-based methods (w/ knn) used in [13] on the ASSIST dataset. These findings show the effectiveness of each key component in enhancing the overall performance of Coral."}, {"title": "D.2 Efficiency Improvement", "content": "We additionally implement three efficiency optimization strategies to further reduce the complexity of Coral. These strategies cannot theoretically guarantee optimal performance, but they can enhance applicability and scalability of Coral through empirical balancing of efficiency and accuracy. We refer them as Coral with n-sample, Coral with m-selections, and Coral with full-kit, as follows:\nCoral with n-sample: During the K iterations of searching for neighbors, randomly sample n subsets from all M learners to replace $V_u^{(c)}$ in the original approach. This reduces computational efficiency from M \u00d7 K to n \u00d7 K, where n \u00ab \u041c.\nCoral with m-selections: Based on the basic Coral, replace selecting one neighbor per iteration with selecting m neighbors. This decreases computational efficiency from M \u00d7 K to $M \u00d7 \\frac{K}{m}$, where m < K.\nCoral with full-kit: A combination of Coral with n-sample and Coral with m-selections, further reducing computational efficiency from M \u00d7 K to $n \u00d7 \\frac{K}{m}$, where n < M and m < K.\nFollowing the three strategies outlined above, we conduct several experiments on the Junyi dataset, with K = 40, to assess prediction performance. These experimental results demonstrate Coral's potential to improve computational efficiency while maintaining acceptable performance, as evidenced by the varying levels of accuracy achieved with different optimization strategies."}, {"title": "E Broader Impact and Limitation", "content": "This research delves into modeling human cognitive states within the realm of intelligent education. The proposed Coral model significantly enhances the diagnostic accuracy of implicit learners' knowledge states. This improvement not only provides effective insights for online personalized tutoring services, such as question recommendations but also lays the foundation for further research in this area. Moreover, the automatic construction strategy for collaborative connections among learners offers valuable insights that can contribute to subsequent investigations in this field. Lastly, we anticipate that the proposed techniques can be extended to other domains, including but not limited to user interest modeling and social network modeling. Although our method is effective both theoretically and empirically, it suffers from computational inefficiencies. We have explored preliminary optimization strategies in the Appendix D.2 and will focus on improving computational efficiency in future research. In addition, future research plans to consider issues of fairness [22, 55], causal theory [52, 45] and explore the integration of large language models and multi-modal knowledge to enhance interpretability [28, 30, 31]. In essence, our work is dedicated to advancing intelligent education and deepening the understanding of human cognitive proficiency. It cannot cause negative effects. We anticipate its crucial role in fostering progress in both pertinent technologies and societal advancements."}]}