{"title": "CKSP: Cross-species Knowledge Sharing and Preserving for Universal Animal Activity Recognition", "authors": ["Axiu Mao", "Meilu Zhu", "Zhaojin Guo", "Zheng He", "Tomas Norton", "Kai Liu"], "abstract": "Deep learning techniques are dominating automated animal activity recognition (AAR) tasks with wearable sensors due to their high performance on large-scale labelled data. However, current deep learning-based AAR models are trained solely on datasets of individual animal species, constraining their applicability in practice and performing poorly when training data are limited. In this study, we propose a one-for-many framework, dubbed Cross-species Knowledge Sharing and Preserving (CKSP), based on sensor data of diverse animal species. Given the coexistence of generic and species-specific behavioural patterns among different species, we design a Shared-Preserved Convolution (SPConv) module. This module assigns an individual low-rank convolutional layer to each species for extracting species-specific features and employs a shared full-rank convolutional layer to learn generic features, enabling the CKSP framework to learn inter-species complementarity and alleviating data limitations via increasing data diversity. Considering the training conflict arising from discrepancies in data distributions among species, we devise a Species-specific Batch Normalization (SBN) module, that involves multiple BN layers to separately fit the distributions of different species. To validate CKSP's effectiveness, experiments are performed on three public datasets from horses, sheep, and cattle, respectively. The results show that our approach remarkably boosts the classification performance compared to the baseline method (one-for-one framework) solely trained on individual-species data, with increments of 6.04%, 2.06%, and 3.66% in accuracy, and 10.33%, 3.67%, and 7.90% in F1-score for the horse, sheep, and cattle datasets, respectively. This proves the promising capabilities of our method in leveraging multi-species data to augment classification performance.", "sections": [{"title": "1. Introduction", "content": "Automated animal activity recognition (AAR) with wearable sensors empowers caretakers to continuously and remotely monitor behavioural variations in animals, considerably decreasing workloads and expenses in veterinary practices while enhancing the efficiency and sustainability of livestock management (Mao et al., 2023a). Wearable sensors are often incorporated into both research- oriented and commercial devices for specific applications, like the Whistle Fit (Chambers et al., 2021) and Ceres Tags (Wang et al., 2023). These devices are attached to various animal body parts, including necks, ears, and legs, to capture motion data like acceleration and angular velocity. These data are then processed and analysed using smart computing techniques to achieve accurate classification of animal behaviours like cattle grazing and walking (Arablouei et al., 2023a), and sheep scratching and resting (Kleanthous et al., 2022a).\nCurrently, deep learning is dominating wearable sensor-aided AAR tasks owing to their exceptional feature extraction abilities, showcasing favourable performance in discriminating animal behaviours across a wide range of scenarios (Kleanthous et al., 2022b; Riaboff et al., 2022). Arablouei et al. (2021) examined the application of multilayer perceptron (MLP) in cattle behaviour recognition, achieving a higher accuracy of 93.4% than several machine learning methods such as support vector machines. Their developed MLP model was subsequently utilised in further research, consistently exhibiting promising results (Arablouei et al., 2023a, 2023b). Convolutional neural networks (CNNs), as the most commonly applied method in AAR tasks, have achieved high accuracies often exceeding 90%, attributed primarily to their capabilities to capture local temporal dependencies and exhibit scale invariance (Mao et al., 2023). Furthermore, recent studies have explored combining CNNs with recurrent neural networks (RNNs) for classifying animal behaviours using sensor data, with the hybrid models tending to exhibit desirable performance than pure CNN- and RNN-based models (Liseune et al., 2021; Wang et al., 2023).\nDespite the satisfactory performance, current deep learning-based AAR methods (Arablouei et al., 2023a; Riaboff et al., 2022; Wang et al., 2023) still have the following issues. (1) These approaches are generally trained on datasets of individual animal species. This greatly constrains their applicability in real-world scenarios, as they cannot be directly applied to different species due to data discrepancy (e.g.,"}, {"title": "2. Proposed method", "content": "The proposed Cross-species Knowledge Sharing and Preserving (CKSP) method aims to develop a universal AAR framework based on multi-species sensor datasets, and such a framework is broadly applicable to different species while tackling the data limitation challenge typically encountered when relying solely on individual species data. Figure 1 illustrates the overall workflow of the CKSP framework, mainly encompassing three parts, i.e., data preprocessing, feature extraction, and behavioural classification."}, {"title": "2.1. Data preprocessing", "content": "Data from diverse species will initially undergo preprocessing prior to being input into the network for feature extraction. The data dimensions of different farms or institutions are normally inconsistent due to various settings (e.g., different sampling rates over identical time spans). This directly affects the feature learning capability and generalization of classification models, particularly those based on CNN- based models with fixed kernel sizes. To tackle this issue, we uniform the input dimensions across species to equal sizes. Herein, we take an example of a multi-species dataset with 2-second signal samples, sampled at 12.5 Hz for sheep, 25 Hz for cattle, and 100 Hz for horses. This results in input sizes of 1 \u00d7 3 \u00d7 25, 1 \u00d7 3 \u00d7 50, 1 \u00d7 3 \u00d7 200, respectively. Given the balance between performance and resource consumption, a 25 Hz sampling rate is commonly adopted, as supported by recent research (Eerdekens et al., 2021; Kleanthous et al., 2022b; Riaboff et al., 2022). Therefore, we standardize these two-second inputs to a size of 1 \u00d7 3 \u00d7 50, akin to 25 Hz sampled data, by exploiting the bilinear-neighbor interpolation technique (Th\u00e9venaz et al., 2000). Afterwards, these unified data are imported into the network for further feature extraction."}, {"title": "2.2. Shared and preserved feature extraction", "content": "The feature extraction phase within our proposed CKSP framework comprises of convolutional layers, batch normalization layers, max-pooling layers, global average-pooling layers, and fully connected layers, as shown in Fig. 1. Typically, different species exhibit common characteristics yet possess distinct movement patterns and divergent feature distributions. Inter-species discrepancies in movement patterns hinder conventional networks' efficiency in discerning invariant features across species, accompanied by slow convergence. Additionally, inconsistent feature distributions challenge the derivation of universal statistical measures applicable to multiple species. To tackle these challenges, we introduce a novel feature learning methodology comprised of a Shared-Preserved Convolution (SPConv) module and a Species-Specific Batch Normalization (SBN) module, as presented in Fig. 1. The SPConv module is designed with dual branches: one utilises a shared convolutional layer to distil shared universal knowledge, while the other employs species-specific convolutional layers to address the inter-species discrepancy. Following the convolutional operation, the SBN module is strategically"}, {"title": "2.2.1. SPConv module", "content": "In recent years, the practice of fine-tuning large language models has garnered growing attention due to its remarkable capability of extracting task-specific features from individual task datasets while preserving the general knowledge acquired from extensive pre-training on large data corpora (Malladi et al., 2023). Considering the substantial computational burden associated with directly fine-tuning large parameter sets, Low-Rank Adaptation (LoRA) was proposed to mitigate this issue by incorporating a low-rank parameter matrix branch, significantly reducing parameter size while effectively acquiring task-specific features (Hu et al., 2022). It enables the acquisition of domain-specific knowledge through a trainable low-rank parameter matrix, while the pre-trained full-rank parameter matrix remains fixed to preserve general knowledge.\nWe observe that the LoRA technique in large language model fine-tuning aligns closely with our objectives in dual aspects: the pre-trained model's function parallels our network's shared feature extraction, and the branch of low-rank parameter matrix during fine-tuning aligns with capturing species-specific information in our architecture. Inspired by this insight, we propose a Shared-Preserved Convolution (SPConv) module with dual branches: one employs a shared full-rank convolutional layer to learn shared generic features, while the other assigns individual low-rank convolutional layers to each species for the extraction of species-specific features, as shown in Fig. 1.\nLet $x^s \\in R^{c\\times h\\times w}$ represents the feature representation of species s at a given layer, where c, h, and w denote the channel number and spatial dimensions, respectively. We input xs into a shared full-rank convolutional layer with a 1 \u00d7 3 kernel to learn shared general features. Meanwhile, $x^s$ is fed into a Low-Rank Convolution (LRConv) layer to obtain personalised features of species s, yielding $x_l^s \\in R^{c'\\times h'\\times w'}$. Different with a traditional 1 \u00d7 3 convolution operation, LRConv decomposes the original parameter tensor $W_{lr}$ of size c' \u00d7 3 \u00d71\u00d7c into two parameter matrices: $B\\in\\mathbb{R}^{(c'\\times 3)\\times r}$ and $A \\in \\mathbb{R}^{r\\times (1\\times c)}$, where r denotes the low-rank value. Therefore, the LRConv operation can be formulated as:\n$x_l^s = W_{LR}x^s = R(BA)x^s$,"}, {"title": "2.2.2. SBN module", "content": "Batch normalization has been known for mitigating internal covariate shifts and enhancing feature discriminability while accelerating the learning process (Ioffe & Szegedy, 2015). It typically operates within a batch, normalizing the values across each channel by adjusting them to have zero mean and unit variance across the entire batch. Following this normalization, an affine transformation, parameterized by trainable parameters [\u03b3, \u03b2], is imposed on the normalised feature maps. During the training process, the BN layer is able to capture global statistics measures \u2013 a moving mean and a moving variance - which are later fixed and utilised to normalise features in the testing phase, ensuring stable performance.\nThe efficacy of BN operations in prevailing studies largely relies on the assumption that training data originates from the same species and follows a uniform distribution. However, the data collected from diverse animal species in our study exhibit distinct movement patterns, thereby posing a challenge to acquire universal global statistical measures viable across various species. As illustrated in Fig. 2, we visualise the species-specific global statistics obtained from the BN layers of networks separately trained on data from each species (e.g., horse, sheep, and cattle). It can be observed that these statistics display notable discrepancies between different species, particularly in the deeper layers that contain more discriminative and semantically rich features. Directly aggregating these data with inherent statistical variations for joint training inevitably imposes difficulties on the network to learn generic features and impedes model convergence. In addition, the shared statistical parameters, as learned, inadequately mirror the feature distribution of individual species, thereby undermining the classification performance of models during the testing phase across diverse species."}, {"title": "2.3. Behavioural classification", "content": "Considering the behavioural disparities among different animal species, to enhance the applicability of models across various species, species-specific classifiers are appended following the feature extraction stage. As presented in Fig. 1, for each animal species, a separate classifier comprised of a single fully connected layer is adopted. Herein, we apply class-balanced focal loss as the loss function, which has been validated in addressing class imbalance problems (Cui et al., 2019; Mao et al., 2021). To guarantee the model remains unbiased towards any one species and can concurrently learn knowledge from distinct species, we evenly distribute data from various species within each batch during the training process. Hence, the overall loss function can be formulated as the average of losses across all S species:\n$L = \\frac{\\sum_{s=1}^S L_s}{S}$,\nwhere $L^s$ denotes the class-balanced focal loss of species s. Utilising the loss in Eq. (3), our proposed CKSP framework can enhance the classification performance for individual species and flexibly accommodate diverse behavioural categories across different species."}, {"title": "3. Datasets and experimental setup", "content": "Our proposed CKSP is evaluated utilising three publicly available datasets collected from horses (Kamminga et al., 2019a), sheep (Kleanthous et al., 2022a) and cattle (C. Li et al., 2021), respectively. The specifics are summarized in the following Table 1.\nHorse dataset. The horse dataset encompasses 87,621 two-second samples, acquired from six horses using neck-attached inertial measurement units with a sampling rate of 100 Hz. Based on existing studies on horse behaviour recognition (Kamminga et al., 2019; Mao et al., 2023b), we consider five extensively labelled activities, including grazing, galloping, standing, trotting, and walking. Amongst, the triaxial accelerometer measurements were employed, resulting in a tensor shape of 1 \u00d7 3 \u00d7 200 for each two-second sample.\nSheep dataset. The sheep dataset consists of 149,725 two-second motion data collected from nine sheep using neck-attached accelerometers with a sampling rate of 12.5 Hz. Five activities, including grazing, walking, scratching, standing, and resting, are contained and merged into three main unified behaviours, i.e., grazing, active (including walking and scratching), and inactive (including standing and resting). The triaxial accelerometer data construct a tensor of dimensions 1 \u00d7 3 \u00d7 25 for each sample.\nCattle dataset. The cattle dataset is collected from six different Japanese black beef cows using neck-attached accelerometers with a sampling rate of 25 Hz. Based on existing studies on cattle behaviour recognition (Arablouei et al., 2023a; C. Li et al., 2021; Minati et al., 2023), we consider five frequent cattle behaviours, including grazing, ruminating, resting, moving, and salting. The dataset contains a total of 10,429 two-second data samples, with each sample comprising triaxial accelerometer data structured as a tensor of 1 \u00d7 3 \u00d7 50.\nTo ensure the model remains unbiased towards any individual species and demonstrate our approach's effectiveness under data limitation scenarios, we equalise the training data size across all species by downsampling to match them to the quantity of the species with the smallest number. These sampled data are subsequently combined to train our proposed model, where the sample number within each batch should be uniform across different species during training. Precision, recall, F1-score, and accuracy are used as evaluation metrics to gauge the overall performance of the classification network.\nTo validate the generalisation ability of our approach, we perform the stratified 5-fold cross-validation"}, {"title": "4. Results and discussion", "content": "Overall, the experimental results highlight the significant superiority of our CKSP approach over the Single-Net model trained solely on individual species data. Ablation studies confirm the effectiveness of the SPConv and SBN components in enhancing classification performance. Furthermore, the recognition analysis illuminates the predictive advantages of CKSP in data-constrained settings. This section concludes with suggestions for future research directions."}, {"title": "4.1. Performance comparisons with the baseline method", "content": "To assess the performance of our proposed method, we compare CKSP against Single-Net and present the results in Fig. 3, with both models trained on datasets from three different species. The results reveal that our proposed CKSP exhibits promising performance, achieving accuracies of 96.44%, 92.89%, 90.01% on the horse, sheep, and cattle datasets respectively, accompanied by F1-scores of 96.02%, 86.79%, and 88.40%, precision values of 95.07%, 87.39%, and 85.76%, and recall values of 97.03%, 86.59%, and 91.60% on the respective datasets. Obviously, the CKSP outperforms the Single- Net in terms of all evaluation metrics, with increments of 6.04%, 2.06%, and 3.66% in accuracy, 10.33%, 3.67%, and 7.90% in F1-score, 12.46%, 3.87%, and 8.96% in precision, and 6.24%, 3.66%, and 4.03%"}, {"title": "4.2. Ablation studies", "content": ""}, {"title": "4.2.1. Evaluation of SPConv and SBN modules", "content": "To thoroughly probe the impacts of the SPConv and SBN modules, we perform experiments on the proposed CKSP framework with and without SPConv and/or SBN modules. The results obtained on the three datasets are given in Table 2. We can see that our method without both modules, i.e., directly sharing feature extraction parameters across distinct animal species, yields inferior results. Conversely, the integration of the SBN module enables our method to obtain premium performance with different degrees of improvement, implying the critical importance of fitting species-specific feature distributions for different species. Notably, including the SPConv module alongside the SBN module yields additional enhancements to classification performance, evidenced by accuracy increments of 8.67%, 2.02%, 11.64%; F1-score gains of 13.69%, 3.66%, 19.79%; precision boosts of 15.84%, 3.93%, 17.26%; and recall increases of 7.13%, 3.74%, 11.93% for the horse, sheep, and cattle datasets, respectively. This confirms our earlier assertion that a combination of shared and personalised learning parameters is necessary, given the coexistence of both generic and species-specific behavioural patterns across"}, {"title": "4.2.2. Analysis of the SPConv module", "content": "Analysis of the LRConv operation. The LRConv operation adapts the species-specific convolution layer by introducing a low-rank decomposition, effectively decreasing the parameters within a certain scope. To gain insights into the benefits of LRConv operation, we contrast the performance of our CKSP framework equipped with LRConv layers against a variant using full-rank convolution (FRConv) layers, as detailed in Table 3. It is obvious that the CKSP employing LRConv layers demonstrates superior performance compared to the version utilising FRConv layers, regardless of the varied values ofr (2~16). This evidences the efficacy of our implemented LRConv layers in enhancing performance. Moreover, the total parameter count within the species-specific branches adopting LRConv layers is smaller than those using FRConv layers, highlighting the additional advantage of employing LRConv layers in terms of efficiency.\nAnalysis of the hyper-parameter r. The hyper-parameter r in the SPConv module denotes the low- rank value. Herein, we analyse the performance of our method with varying r values (i.e., 2, 4, 8, 12, and 16) through experiments, and the findings are summarized in Table 3. When r is set to 12, the CKSP attains the highest values across all evaluation metrics for horse and cattle behaviour classification and demonstrates favourable performance in classifying sheep behaviours. It underscores the potential advantage of judiciously selecting the value of r for enhancing the overall classification performance."}, {"title": "4.3. Robustness against variations in dataset size", "content": "The proposed CKSP method leverages multi-species datasets to establish a universal AAR framework. This strategy facilitates the capture of a broader spectrum of movement patterns across diverse species, thereby providing a potential prospect to alleviate the poor performance resulting from insufficient sample sizes of a single species. To validate the classification ability of our CKSP approach under the context of data limitation, we present in Fig. 6 the comparative classification performance between the Single-Net and CKSP over varying percentages (i.e., 75%, 50%, 25%, and 10%) of the original dataset. The CKSP exhibits remarkable stability in classifying horse and sheep behaviours, and the improvement margin it gains over the Single-Net increases as the dataset size decreases. The findings indicate the robustness of our method, and it can effectively benefit from the diversity of multi-species datasets, particularly in scenarios characterized by data scarcity. Consistently, our method's performance in cattle classification echoes the trends observed in the preceding species (horse and sheep) as the dataset shrinks from 100% to 25%. Despite a conspicuous drop in data percentage of 10%, it persistently surpasses the Single-Net's performance. This phenomenon might be attributed to certain behaviours unique to cattle, i.e., ruminating and salting; when the sample size decreases to a certain threshold, even aggregating data from diverse species does not sufficiently augment the diversity of these specific behaviours, thereby imposing limitations on performance improvement."}, {"title": "4.4. Limitations and implications", "content": "The proposed CKSP approach can be applicable to diverse species while mitigating the challenge of data limitation by learning cross-species features. Nevertheless, the efficacy of enhancing diversity through aggregating multi-species datasets typically hinges on the prerequisite that two or more species have comparable behavioural categories. To this point, we will establish a universal and standardized dictionary of behaviours through extensive research and field studies, with each behaviour being linked to animal health and well-being. This dictionary will serve as a reference for future researchers, who are encouraged to collect data based on their areas of interest within this dictionary and, where possible, strive for data openness. This collaborative endeavour paves the way for developing a large AAR model grounded in a universal database, laying a robust foundation for upcoming advancements."}, {"title": "5. Conclusions", "content": "This study develops a universal AAR framework named CKSP involving an SPConv module and an SBN module, based on sensor data across diverse animal species. The CKSP is applicable to diverse species with distinct interested behaviours while mitigating the challenge of data limitation by learning cross-species features. Considering the coexistence of both similarities and differences of behaviours"}, {"title": "CrediT Authorship Contribution Statement", "content": "Axiu Mao: Conceptualization; Methodology; Software; Validation; Formal analysis; Resources;\nSupervision; Project administration; Funding acquisition; Writing - original draft. Meilu Zhu:\nConceptualization; Methodology; Investigation; Validation; Writing - review & editing. Zhaojin Guo:\nData curation. Zheng He: Visualization. Tomas Norton: Writing - review & editing. Kai Liu:\nConceptualization; Writing - review & editing."}, {"title": "Data availability statement", "content": "The data used in the current study are open-source data, which can be accessed at:\nhttps://data.4tu.nl/articles/_/12687551/1 (Horse), https://zenodo.org/record/5849025#.ZE-y_3ZByHu\n(Cattle), https://github.com/nkleanthous2015/Sheep_activity_Data (Sheep)."}, {"title": "Statement on the Use of Generative AI and AI assisted technologies in the writing process", "content": "No generative AI or AI-assisted technologies were used during the preparation of this work."}]}