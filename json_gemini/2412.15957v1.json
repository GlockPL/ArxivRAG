{"title": "From General to Specific: Tailoring Large Language Models for Personalized Healthcare", "authors": ["Ruize Shi", "Hong Huang", "Wei Zhou", "Kehan Yin", "Kai Zhao", "Yun Zhao"], "abstract": "The rapid development of large language models (LLMs) has transformed many industries, including healthcare. However, previous medical LLMs have largely focused on leveraging general medical knowledge to provide responses, without accounting for patient variability and lacking true personalization at the individual level. To address this, we propose a novel method called personalized medical language model (PMLM), which explores and optimizes personalized LLMs through recommendation systems and reinforcement learning (RL). Specifically, by utilizing self-informed and peer-informed personalization, PMLM captures changes in behaviors and preferences to design initial personalized prompts tailored to individual needs. We further refine these initial personalized prompts through RL, ultimately enhancing the precision of LLM guidance. Notably, the personalized prompt are hard prompt, which grants PMLM high adaptability and reusability, allowing it to directly leverage high-quality proprietary LLMs. We evaluate PMLM using real-world obstetrics and gynecology data, and the experimental results demonstrate that PMLM achieves personalized responses, and it provides more refined and individualized services, offering a potential way for personalized medical LLMs.", "sections": [{"title": "Introduction", "content": "In recent years, the explosive growth of generative artificial intelligence has profoundly impacted various industries, generating widespread interest in large language models (LLMs) and attracting increasing attention from researchers.\nAs such, there remains a pressing need for personalized medical LLMs, which requires us to tackle the two fundamental challenges: (1) How to ensure availability across multiple disease scenarios? As mentioned earlier, most existing works not only fail to achieve personalization at the individual level, but also are limited to disease-specific LLMs, which include knowledge about only a single disease and severely limits their applicability in scenarios involving multiple diseases. Thus, ensuring that personalized medical LLMs can effectively cover a wide range of diseases remains a significant challenge. (2) How to autonomously guarantee personalization? Previous methods focus on extracting personalized information of patients, and embedding it into fixed prompt templates to guide LLMs in providing personalized responses. However, they lack the ability to autonomously adjust based on the specific context or evolving needs of patients, and they do not consider adaptations to the underlying LLMs used. In this context, how to autonomously achieve finer-grained personalization remains an unresolved issue.\nTo this end, we introduce a novel method named personalized medical language model (PMLM), which automatically generates personalized prompts for each user to guide proprietary LLMs in producing tailored responses. Specifically, PMLM first analyzes patient historical data to extract personalized information and incorporates insights from similar patients using collaborative filtering, and it then constructs coarse-grained personalized prompts based on these self-informed and peer-informed information. These prompts are further refined through reinforcement learning (RL) to provide tailored prompts for each user, achieving fine-grained personalization. Finally, the personalized prompts are input into a high-quality LLM to guide the generation of customized responses. Note that the process of prompt refinement considers the downstream LLMs, and since the personalized prompt are hard prompt presented in textual form, PMLM is more easily reusable across different LLMs and can seamlessly integrate with proprietary LLMs that possess extensive disease knowledge. Our contributions can be summarized as follows:\n\u2022 We advance the personalization of LLMs in healthcare filed. While previous works achieve only basic personalization, our method offers a promising path to more refined personalization.\n\u2022 We propose a novel method PMLM, which uses RL to automatically adjust prompt based on patient needs and downstream LLMs, guiding proprietary LLMs with extensive knowledge to offer highly customized responses.\n\u2022 Experiments on real-world obstetrics and gynecology data show that PMLM not only enhances the personalization capabilities of proprietary LLMs but also outperforms fine-tuned LLMs."}, {"title": "Related Work", "content": ""}, {"title": "Personalized LLMS", "content": "Recently, there has been increasing attention on personalization within LLMs, particularly in recommendation systems. Some researchers focus on combining users' historical data to recommend, while others leverage reinforcement learning from human feedback to better understand users' needs and enhance personalization. However, these methods often rely on item embedding, making them difficult to apply in the healthcare field. Fortunately, numerous LLMs have been applied in the healthcare domain and have shown promising results. Some studies claim to have developed personalized medical LLMs, yet these are often limited to offering advice or treatment plans for specific diseases. More specifically, they fine-tune LLMs to learn generalized treatment strategies for a specific disease, achieving personalization at the disease level rather than individual patient level. In addition, they usually fine-tune lightweight LLMs, with poor utilization of proprietary LLMs that possess more extensive knowledge."}, {"title": "Hard Prompt Optimization", "content": "To the best of our knowledge, the earliest research on hard prompt optimization is conducted on pre-train models. Later, GrIPS and FluentPrompt evaluate on GPT2, with GrIPS being a gradient-free approach that operates at the phrase level, while FluentPrompt employs Langevin dynamics. PEZ optimizes hard prompt through soft prompt as intermediaries. Additionally, several works explore modifying hard prompts through RL. RLPrompt represents one of the earliest efforts in this domain, achieving impressive results in few-shot and unsupervised settings. Based on RLPrompt, PIN further enhances prompt interpretability by leveraging sparse Tsallis entropy regularization. PRewrite take a further step by using retrieval strategy to determine the most effective prompt. Rewriter combines supervised learning with RL to rewrite prompts. However, the methods discussed above primarily focus on identifying optimal prompts for specific tasks, rather than designing personalized prompts tailored to individual users."}, {"title": "Method Preparation", "content": "Our work focuses on personalized healthcare, for convenience, we begin by introducing the data format that our method targets.\nIn our work, a healthcare dataset is $H = \\{X, Y, R\\}$, where $X = (x_1, x_2, \\cdots, x_N)$ represents N patients, $Y = (y_1, y_2, \\ldots, y_N)$ denotes the labels for each patient, such as physical conditions, diseases, or a normal state, and $R = (r_1, r_2, \\ldots, r_v)$ is personalized responses from the doctor, used for evaluation. Moreover, each patient $x_i \\in \\mathbb{R}^{N_{x_i} \\times N_m}$, where $N_{x_i}$ represents the health check counts and $N_m$ denotes the health examination metrics. To better reflect reality, the health check counts $N_{x_i}$ for each patient may not be the same, thus, we use subscripts for differentiation. Specifically, patients with more severe conditions may require multiple examinations, while those in better health only need a fewer checks.\nBuilding on this, we aim to extract personalized information from health check data and leverage insights from similar patients. Using RL, we then refine the prompt into a personalized one that guides LLMs in generating tailored responses. Therefore, we provide a description of personalized prompts.\nPersonalized prompt is $P = (p_1, p_2, \\ldots, p_{N_p})$, where p represents a word. In other words, the personalized prompt is in text form, allowing it to be compatible with closed-source LLMs without modifications to their architectures. Furthermore, $P_i \\neq P_j, i \\neq j$, which means that the personalized prompts differ for each patient to guide LLMs in offering tailored responses. In addition, $N_{p_i} \\neq N_{p_j}$ in general, as the length of each personalized prompt can differ."}, {"title": "The Proposed Method", "content": "In this section, we provide a detailed introduction to our proposed PMLM. As illustrated in Figure 2, PMLM guides LLMs to generate personalized responses by constructing tailored prompts. In detail, PMLM begins by pretraining a predictor to extract personalized insights from the historical medical records of patients. It then integrates additional personalization by analyzing data from similar patients. Using these personalized information, PMLM generates an initial coarse-grained personalized prompt. Through RL, these prompts are iteratively refined into fine-grained prompts tailored to each individual. More specifically, a policy network evaluates the modification probability of each word, guided by a reward function to optimize the refinement process. Importantly, the techniques employed in PMLM do not alter the internal parameters or structure of the underlying LLM, enabling seamless and efficient application to proprietary LLMs enriched with extensive disease knowledge."}, {"title": "Extraction of Personalized Information", "content": "As previously mentioned, PMLM leverages personalized information to construct tailored prompts that guide LLMs in generating individualized responses. To achieve this, we begin by extracting personalized information from patients through two key aspects: first, predicting patient labels based on historical health check data, and second, supplementing these predictions with conditions from similar patients."}, {"title": "Self-informed Personalization", "content": "In our work, a patient $x_i \\in \\mathbb{R}^{N_{x_i} \\times N_m}$ is composed of multiple health check results from different dates, meaning that the number of checks varies for each individual. To efficiently handle this variable-length data, we use LORA to fine-tune LLMs as predictors, denoted as $LLM_p$. Specifically, given a patient's health check data and label, we format the data as shown in Figure 3 for instruction tuning.\nAfter fine-tuning, $LLM_p$ is able to make predictions based on the historical health check data of patient X, which can be formally defined as:\n$\\hat{y} = LLM_p(X), \\qquad(1)$\nwhere $\\hat{y}$ represents the predicted label. It is worth highlighting that we extensively evaluate the predictor, including both LLMs and traditional time series methods (refer to Appendix A.3), and ultimately leverage LLaVA1.5-7B in our work."}, {"title": "Peer-informed Personalization", "content": "To further enrich personalized information, in addition to directly using the original patient data for predictions, PMLM extracts information from similar patients. First, PMLM utilizes an encoder to map the patient data into a same space. Formally, for each patient $x_i$, it can be represented as follows:\n$x_i = encoder(x_i), \\qquad(2)$\n$x = padding(\\underset{j=1}{\\overset{N_{x_i}}{||}} x_{ij}), \\qquad(3)$\nwhere $padding(\\cdot)$ refers to filling in missing values, as the number of health checkups $N_{x_i}$ varies between patients, and we apply zero padding here for simplicity. Additionally, $\\hat{x}_i \\in \\mathbb{R}^{1 \\times d}$ denotes the mapped data, and $d$ indicates the mapped space dimension. Furthermore, $x_{ij}$ represents the j-th health check result of patient $x_i$, and $||$ signifies the concatenation. The primary purpose of the encoder is to standardize the dimensions of the input data, thus, to ensure efficiency, we employ the multi-layer perceptron here.\nSubsequently, PMLM leverages the encoded data to recommend similar patients to the target patient based on collaborative filtering. Specifically, since the labels in the training set are known, PMLM calculates the cosine similarity between the target patient $x_i$ and each patient $x_j$ in the training set, which can be described as follows:\n$w_{ij} = \\frac{x_i x_j}{\\| x_i \\|_2 \\cdot \\| x_j \\|_2}, \\qquad(4)$\nwhere $w_{ij}$ represents the similarity between patients $x_i$ and $x_j$, and $\\| \\cdot \\|_2$ denotes the Euclidean norm. Finally, PMLM leverages the top-k most similar patients to enhance the target patient's personalized information for constructing a tailored prompt. Here, k is a hyper-parameter, which we explore in detail in Section 5.5."}, {"title": "Generation of Personalized Prompt", "content": "Based on the self-informed and peer-informed personalized information, PMLM construct tailored prompts to guide LLMs in generating customized responses. In particularly, we first format and create an initial prompt, then refine this prompt through RL, ultimately producing unique prompts for each patient."}, {"title": "Coarse-grained Personalized Prompt", "content": "Similar to previous works, our initial personalized prompt includes background and input data, as illustrated in Figure 4. Specifically, the background part provides an overview of the input data and the downstream task, helping the LLM to understand the context and objectives. The input information is then populated with the personalized data extracted earlier, covering both the target patient's prediction outcomes and the recommendations from similar patients. Note that the obtained initial prompts already incorporate a coarse level of personalization since the input data is tailored to each individual, resulting in unique prompts for each patient."}, {"title": "Fine-grained Personalized Prompt", "content": "To achieve a finer level of personalized prompts, we employ RL to refine the initial prompt. Our goal is to define a policy network that adjusts specific words within the initial prompt to further guide LLMs in generating tailored responses. However, since the word count in each initial prompt varies, unlike previous models, we propose a word-level policy network instead of using the entire prompt as input.\nSpecifically, PMLM optimizes the initial personalized prompts based on a Markov Decision Process. PMLM modifies the initial personalized prompts n times and n is a hyper-parameter. Therefore, we can define all states $S = \\{s_0, s_1, \\ldots, s_{n-1}\\}$, where $s_i, i \\in [0, n - 1]$ represents the personalized prompt after the i-th optimization. Moreover, $s_0$ denotes the initial state and it is the initial personalized prompt (Figure 4).\nAfter that, PMLM introduces a policy network $f(\\cdot)$ to determine the modification probability $\\pi(e|s)$ for each word under a given state s. Formally, this can be described as follows:\n$\\pi(e|s) = softmax(f(E)), \\qquad(5)$\n$E = BERT(s) = (e_1, e_2, \\ldots, e_{N_s}), \\qquad(6)$\nwhere $softmax(\\cdot)$ denotes the normalization and E represents the embedding of the personalized prompt at state s. As previously defined, the personalized prompt is in text format, thus, PMLM first encodes it using BERT. More specifically, e indicates word embeddings, where each embedding has the same dimension, on the contrary, the number of words $N_s$ in different state is likely to vary. PMLM randomly deletes one word based on the probability $\\pi(e|s)$ to transition to the next state. Note that this process is repeated n times, each time deleting only one word, until reaching the final state $s_{n-1}$, which serves as the personalized prompt P.\nNonetheless, the above transition probability rely heavily on word embeddings, resulting in limited personalization. In detail, while these embeddings include contextual information, they still lack the granularity needed to differentiate between individual patients effectively. To address this, PMLM incorporates patient information along with sentence representations. Formally, Eq.(5) can be reformulated as follows:\n$\\pi(e|s) = softmax(f(E||\\bar{E}||\\hat{x})), \\qquad(7)$\n$\\bar{E} = mean(E) = \\frac{e_1 + e_2 + \\ldots + e_{N_s}}{N_s}, \\qquad(8)$\nwhere, $||$ denotes concatenation, $\\bar{E}$ represents the mean of the word vectors in E, which is treated as the global representation of the prompt, while $\\hat{x}$ refers to the patient representation obtained in Eq.(2). With this refinement, the prompt modification considers both patient information and overall semantic, enabling the generation of a more highly personalized prompt. For simplicity, we still employ a multi-layer perceptron as the policy network.\nAfter n iterations, we obtain the personalized prompt P. We then define the reward using BERTScore, which is as follows:\n$Reward = BS(\\hat{r},r) - BS(\\hat{r}_0,r), \\qquad(9)$\n$\\hat{r} = LLM_\\phi(P), \\qquad(10)$\nwhere $LLM_\\phi$ indicates the LLM used for generating replies and $\\hat{r}$ represents its response to the personalized prompt, $r_0 = LLM_\\phi(s_0)$ is the response to the initial personalized prompt. Moreover, r indicates the replies of doctors, used for reference, and $BS(\\cdot)$ stands for BERTScore. It is noteworthy that our reward is obtained only once, focusing on the overall reward, without requiring positive feedback for each single modification. In addition, the reward function considers downstream LLM, meaning that the personalized prompt is adaptively revised in alignment with $LLM_\\phi$. Furthermore, as the personalized prompt is in text format, we avoid any modifications to $LLM_\\phi$, enabling compatibility with proprietary LLMs. In this case, the loss function is defined as:\n$L = - \\sum_{i=0}^{n-1} log(\\pi(e_j|s_i)) \\cdot Reward, \\qquad(11)$\nwhere $\\pi(e_j|s_i)$ is the probability of deleting word $e_j$ in the state $s_i$. Moreover, $j \\in [1, N_{s_i}]$ denotes a randomly chosen index, following the probability distribution $\\pi(e|s_i)$. Finally, we optimize our proposed PMLM by Adaptive Moment Estimation.\nWe further provide the pseudo-code of PMLM and some training strategies in Appendix A.1."}, {"title": "Experiments", "content": ""}, {"title": "Experimental Setup", "content": "Datasets. To evaluate PMLM, we collect and process obstetrics data from multiple hospitals in Wuhan city and surrounding areas from 2020 to 2022. Details on data processing are provided in Appendix A.2. The final dataset we used consists of 38,817 records for 2,373 pregnant patients, with each record containing 35 examination metrics. The patient with the most records has 45 entries, and each patient is assigned a label and receives medical recommendations, with a total of 12 categories. To reflect reality, we partition the data by year: data from 2021 and earlier serve as the training set, the first half of 2022 as the validation set, and the remaining data as the testing set.\nBaselines. We not only evaluate the performance of PMLM on multiple proprietary LLMs, but also compare it with several fine-tuned LLMs. The specific baselines are as follows:\n\u2022 Proprietary LLMs. We evaluate PMLM on several LLMs, including Gemini1.5-pro, GLM4, GLM4-plus, GPT3.5-turbo, and GPT4.\n\u2022 Lightweight LLMs. We compare several representative fine-tuned LLMs, they are Llama3-8B, GLM4-9B, Qwen2-7B, and LLaVA1.5-7B.\nExperimental settings. We evaluate PMLM on a server configured with an Intel Xeon Gold 5117 CPU, a Tesla V100 GPU (32 GB), and 256 GB of RAM. The server runs on Ubuntu 18.04 with CUDA 12.1, and our code is implemented in PyTorch 2.1.0\u00b9. To minimize randomness, we report the average results from five experimental runs.\nFor hyper-parameter settings, both the encoder and policy network in PMLM are multi-layer perceptrons, each with hidden layer dimensions of 256 and a dropout rate of 0.4. Specifically, the encoder has 2 layers with an output dimension of 128, while the policy network has 3 layers with an output dimension of 1. The number of similar patients k and the number of prompt modification steps n are both set to 10, with a learning rate of 0.005. For PMLM's predictor and other fine-tuned LLMs, we follow a representative work. The code of PMLM will be released upon formal publication."}, {"title": "Performance Study", "content": "We evaluate whether PMLM enhances the personalization of proprietary LLMs and compare it with fine-tuned lightweight LLMs. To this end, we design the prompt shown in Figure 5. For proprietary LLMs, we directly evaluate on the testing data, as fine-tuning is not feasible. In contrast, for lightweight LLMs, we first fine-tune on the training data, followed by evaluation. Finally, we compare the outputs from each LLM with the reference responses, utilizing BLEU, ROUGE and BERTScore as metrics. Moreover, due to space limitations, we provide case study in the Appendix A.4.\nFrom Table 1, it is evident that PMLM consistently enhances the personalization capability of general LLMs. By leveraging personalized prompt, all evaluated LLMs exhibit performance improvements exceeding 10%. This strongly validates our approach of guiding LLMs to generate personalized responses via tailored prompts. Furthermore, directly inputting patient data into LLMs in healthcare scenarios poses potential privacy risks. PMLM addresses this concern by personalized prompt, offering a novel way to ensuring tailored responses while maintaining privacy. In addition, the GPT4-based PMLM achieves the best performance, thus, we leverage GPT4 as the foundational LLM for subsequent experiments.\nTo provide a more comprehensive evaluation, we also compare PMLM with fine-tuned LLMs, which are presented in Table 2. We can observe that PMLM achieves state-of-the-art performance, underscoring its effectiveness. However, it falls short on ROUGE-L, which is acceptable given that this metric is heavily reliant on word matching. For these lightweight LLMs, their vocabulary is closer to the reference responses since they have been trained using the standard replies from the training data. Nonetheless, we argue that greater emphasis should be placed on BERTScore, which evaluates semantic alignment. Notably, PMLM achieves the significant performance on BERTScore, further validating its capability in generating semantically coherent and personalized responses."}, {"title": "Personalization Study", "content": "To clearly demonstrate that PMLM achieves personalization at the individual level, we show the indices modified during each iteration in the testing set. Due to space constraints, we merely provide the modification counts for the first 100 words.\nAs shown in Figure 6, the frequency of word modifications varies significantly across different indices. This result demonstrates that the policy network, by integrating sentence context and individual information, effectively performs personalized refinements, constructing prompts tailored to individual needs. Combined with the earlier results (Section 5.2), this validates that PMLM achieves individual-level personalization, and it guides LLMs to produce tailored responses by leveraging personalized prompts, achieving state-of-the-art performance."}, {"title": "Ablation Study", "content": "We further assess the contributions of each module in PMLM. In detail, we examine the roles of self-informed personalization (SP), peer-informed personalization (PP), and prompt refinement (PR) in guiding LLMs to generate personalized responses.\nFrom Table 3, we can observe that all modules of PMLM contribute to its performance, which confirms the validity of our model design. Moreover, compared to the other two variants, the impact of PP (Variant-2) on performance is smaller. We think this is due to the fact that PP is based on the similarity of medical records, which might not be entirely accurate. Consequently, even without this component, the model still achieves satisfactory results."}, {"title": "Hyper-parameter Study", "content": "We also investigate the impact of hyper-parameters on performance, focusing on the number of similar patients k and the number of prompt modification iterations n.\nFrom Figure 7, it is evident that as both k and n increase, the performance of PMLM initially improves but later declines, which we believe is a reasonable trend. Increasing k too much may introduce noise from less relevant patients, while excessive modifications to the prompt can distort its semantics, leading to suboptimal results. Moreover, n has a more significant impact on performance, aligning with the findings of the ablation study (Section 5.4). Based on these observations, we set k and n as 10 in our work."}, {"title": "Conclusion", "content": "We study the personalized LLMs in healthcare, emphasizing individual-level customization, and propose PMLM. In particular, it constructs prompts tailored to each patient based on their unique data and refines these prompts iteratively through RL to better align with individual needs. Ultimately, these personalized prompts guide LLMs to deliver highly customized responses. Moreover, PMLM integrates seamlessly with any LLM, including non-open-source models, without risking patient data privacy. Extensive experiments demonstrate that PMLM achieves state-of-the-art performance by generating highly personalized responses, and highlight its potential as a novel and promising way to advance finer personalization in healthcare."}, {"title": "Limitations", "content": "We explore personalized medical LLMs that customize prompts for individual patients to guide proprietary LLMs in offering personalized responses, achieving significant performance. While our work introduces a novel perspective on personalized medical LLMs, there are still several areas for future improvement:\n\u2022 More lightweight predictors. Due to the low performance of time series methods (refer to Appendix A.3), we employ an LLM as a predictor, which restricts the scalability of PMLM. Future efforts could focus on designing simpler yet effective predictors to enhance the efficiency.\n\u2022 Expanded modification operations. We utilize RL to generate personalized prompt, primarily exploring deletion operation. Future research could implement a more comprehensive set of modification operations, including addition, deletion, and replacement, to further refine the personalization process.\n\u2022 Interpretability. The proposed PMLM may generate semantically incoherent prompts during optimization, yet it achieves excellent results. This could be attributed to the differing ways in which LLMs interpret information compared to humans. Future research could explore the interpretability of prompt modifications and the overall interpretability of LLMs."}, {"title": "Ethics Statement", "content": "This study is conducted in collaboration with Tongji Medical College of HUST and Hubei Maternal and Child Health Hospital, using anonymized data that excludes identifiable information such as names or IDs of patients and doctors. The dataset we used consists of retrospective records retained by the hospital and does not involve sensitive personal information. In addition, handling of this data poses no direct risks to patients, and all patient information is employed exclusively for academic research purposes, aiming to improve healthcare outcomes."}, {"title": "Appendix", "content": ""}, {"title": "Details of PMLM", "content": "To further elucidate PMLM, we provide its pseudo-code as shown in Algorithm 1. It is clear that the predictor requires pre-training to ensure the effectiveness of subsequent personalized prompt construction. Additionally, for testing data, similar patients should be selected from the training set to build personalized prompts, which is more realistic as hospitals typically maintain historical records."}, {"title": "Dataset Details", "content": "We collect and process obstetrics and gynecology data from multiple hospitals in Wuhan city and surrounding areas, covering records from 2020 to 2022. The dataset includes complete medical examination records of pregnant women from admission to discharge. It contains 194,345 entries, each with 302 examination indicators, and corresponding discharge diagnoses are used as labels and reference responses. Note that our use of this data complies with ethical standards, as detailed in the Ethics Statement section."}, {"title": "Examination indicators", "content": "We analyze the dataset and select 35 measurable examination indicators due to the sparsity of the data and the textual nature of some indicators. The selected indicators include pH level, albumin, total protein, indirect bilirubin, direct bilirubin, total bilirubin, alkaline phosphatase, alanine aminotransferase, prealbumin, total bile acid, large platelet count, plateletcrit, large platelet ratio, mean platelet volume, platelet distribution width, red blood cell distribution width (coefficient of variation and standard deviation), basophil count, eosinophil count, monocyte count, lymphocyte count, neutrophil count, basophil ratio, eosinophil ratio, monocyte ratio, lymphocyte ratio, neutrophil ratio, mean corpuscular hemoglobin concentration, mean corpuscular hemoglobin, hematocrit, white blood cell count, platelet count, hemoglobin, mean corpuscular volume, and red blood cell count."}, {"title": "Labels", "content": "The original dataset contains 455 conditions plus \"normal\" as labels. We filter out conditions with insufficient samples and retain 12 labels: normal, uterine scar, acute fetal distress (heart type), pregnancy complicated with placental dysfunction, gestational hypertension, premature rupture of membranes, pregnancy complicated with hypothyroidism, uterine rupture, acute fetal distress (amniotic fluid type), umbilical cord entanglement, thalassemia, and gestational diabetes."}, {"title": "Final dataset", "content": "The final dataset we used includes 38,817 entries from 2,373 pregnant women. It contains 56 entries from 2020, 1,638 from 2021, and 679 from 2022. We split the dataset by year: data from 2021 and earlier are used as the training set, the first half of 2022 as the validation set, and the remaining data as the testing set."}, {"title": "Predictor Study", "content": "To ensure the performance of PMLM, we carefully select the predictor. In our work, patient data can essentially be viewed as time series data. Thus, in addition to LLMs, we also evaluate representative time series methods, namely CNN, LSTM, ROCKET, and Transformer. Since the number of medical visits varies across patients, zero padding is applied to align data. For LLMs, we use the prompt shown in Figure 3 for fine-tuning.\nFrom Table A1, we can observe that fine-tuned LLMs consistently outperform traditional time series methods, with a considerable gap between the two. We attribute this to the sensitivity of healthcare data, which may not be suitable to zero padding. Furthermore, LLaVA1.5-7B demonstrates the best performance, and as a result, we leverage it as the predictor in our work."}, {"title": "Case Study", "content": "Here we provide cases to illustrate how the proposed PMLM guides LLMs to generate personalized responses. We compare the responses of GLM4 and GPT4, which are directed by the prompt shown in Figure 5. Specifically, we present cases for two different patient types, a pregnant woman diagnosed with Gestational Diabetes Mellitus (GDM) and a pregnant woman with normal conditions.\nIt is evident that PMLM excels at accurately identifying the condition of patients (highlighted in green) and providing highly tailored recommendations, demonstrating its capacity for deep, individual-level personalization. Unlike GLM4 and GPT4, which rely on specific numerical metrics and fail to interpret the overall state of patients, PMLM adapts its responses based on the contextual nuances of the patient's health profile. In addition, the recommendations from GLM4 and GPT4 are generalized and, in the case of the normal patient, inaccurately suggest certain conditions, which underlines their inability to provide truly personalized healthcare advice. These results not only validate the potential of PMLM to deliver precisely customized medical insights, but also suggests a promising direction for developing advanced, personalized LLMs in healthcare."}]}