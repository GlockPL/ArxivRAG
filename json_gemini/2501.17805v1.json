{"title": "International Al Safety Report", "authors": ["Yoshua Bengio", "S\u00f6ren Mindermann", "Daniel Privitera", "Tamay Besiroglu", "Rishi Bommasani", "Stephen Casper", "Yejin Choi", "Philip Fox", "Ben Garfinkel", "Danielle Goldfarb", "Hoda Heidari", "Anson Ho", "Sayash Kapoor", "Leila Khalatbari", "Shayne Longpre", "Sam Manning", "Vasilios Mavroudis", "Mantas Mazeika", "Julian Michael", "Jessica Newman", "Kwan Yee Ng", "Chinasa T. Okolo", "Deborah Raji", "Girish Sastry", "Elizabeth Seger", "Theodora Skeadas", "Tobin South"], "abstract": "This report summarises the scientific evidence on the safety of general-purpose Al. The purpose of this report is to help create a shared international understanding of risks from advanced Al and how they can be mitigated. To achieve this, this report focuses on general-purpose Al or Al that can perform a wide variety of tasks \u2013 since this type of Al has advanced particularly rapidly in recent years and has been deployed widely by technology companies for a range of consumer and business purposes. The report synthesises the state of scientific understanding of general-purpose Al, with a focus on understanding and managing its risks.\nAmid rapid advancements, research on general-purpose Al is currently in a time of scientific discovery, and \u2013 in many cases is not yet settled science. The report provides a snapshot of the current scientific understanding of general-purpose Al and its risks. This includes identifying areas of scientific consensus and areas where there are different views or gaps in the current scientific understanding.\nPeople around the world will only be able to fully enjoy the potential benefits of general-purpose Al safely if its risks are appropriately managed. This report focuses on identifying those risks and evaluating technical methods for assessing and mitigating them, including ways that general-purpose Al itself can be used to mitigate risks. It does not aim to comprehensively assess all possible societal impacts of general-purpose Al. Most notably, the current and potential future benefits of general-purpose Al \u2013 although they are vast are beyond this report's scope. Holistic policymaking requires considering both the potential benefits of general-purpose Al and the risks covered in this report. It also requires taking into account that other types of Al have different risk/benefit profiles compared to current general-purpose Al.\nThe three main sections of the report summarise the scientific evidence on three core questions: What can general-purpose Al do? What are risks associated with general-purpose Al? And what mitigation techniques are there against these risks?", "sections": [{"title": "Introduction", "content": "We are in the midst of a technological revolution that will fundamentally alter the way we live, work, and relate to one another. Artificial intelligence (AI) promises to transform many aspects of our society and economy.\nThe capabilities of Al systems have improved rapidly in many domains over the last years. Large language models (LLMs) are a particularly salient example. In 2019, GPT-2, then the most advanced LLM, could not reliably produce a coherent paragraph of text and could not always count to ten. Five years later, at the time of writing, the most powerful LLMs, such as GPT-4, 01, Claude 3.5 Sonnet, Hunyuan-Large, and Gemini 1.5 Pro, can engage consistently in multi-turn conversations, write short computer programs, translate between multiple languages, score highly on university entrance exams, and summarise long documents.\nBecause of these advances, Al is now increasingly present in our lives and is deployed in increasingly consequential settings across many domains. Just over the last two years, there has been rapid growth in Al adoption \u2013 ChatGPT, for instance, is amongst the fastest growing technology applications in history, reaching over one million users just five days after its launch, and 100 million users in two months. Al is now being integrated into search engines, legal databases, clinical decision support tools, and many more products and services.\nThe step-change in Al capabilities and adoption, and the potential for continued progress, could help advance the public interest in many ways - but there are risks. Among the most promising prospects are Al's potential for education, medical applications, research advances in fields such as chemistry, biology, or physics, and generally increased prosperity thanks to Al-enabled innovation. Along with this rapid progress, experts are becoming increasingly aware of current harms and potential future risks associated with the most capable types of Al.\nThis report aims to contribute to an internationally shared scientific understanding of advanced Al safety. To work towards a shared international understanding of the risks of advanced Al, government representatives and leaders from academia, business, and civil society convened in Bletchley Park in the United Kingdom in November 2023 for the first international Al Safety Summit. At the Summit, the nations present agreed to support the development of an International Al Safety Report. This report will be presented at the Al Action Summit held in Paris in February 2025. An interim version of this report was published in May 2024 and presented at the Al Seoul Summit. At the Summit and in the weeks and months that followed, the experts writing this report received extensive feedback from scientists, companies, civil society organisations, and policymakers. This input has strongly informed the writing of the present report, which builds on the Interim Report and is the first full International Al Safety Report."}, {"title": "1.1. How general-purpose Al is developed", "content": "General-purpose Al can perform, and help users accomplish, a wide variety of tasks. For example, it can produce text, images, video, audio, actions, or annotations for data.\nGeneral-purpose Al is based on 'deep learning'. Deep learning leverages large amounts of computational resources for an Al model to learn useful patterns from a large amount of training data.\nThe lifecycle of a general-purpose Al can be divided into distinct stages. These stages are:\nData collection and pre-processing: developers and data workers collect, clean, label, standardise, and transform raw training data into a format the model can effectively learn from.\nPre-training: developers feed Al models vast quantities of data to instil general knowledge by learning from examples. This stage currently requires the most computation.\nFine-tuning: developers and contracted data workers further refine the pre-trained 'base model' in a process called 'fine-tuning' to optimise the model's performance for a specific application or make it more useful generally. This stage can be very labour intensive.\nSystem integration: developers combine one or more general-purpose Al models with other components, such as user interfaces or content filters, to enhance capability and safety and to produce a full \u2018Al system' that is ready for use.\nDeployment: developers make the integrated Al system available for others to use by implementing the Al system into real-world applications or services.\nPost-deployment monitoring: developers gather and analyse user feedback, track performance metrics, and make iterative improvements to address issues or limitations discovered during real-world use. These improvements can include more fine-tuning or updating the system integration.\nSince the publication of the Interim Report (May 2024), the abilities of general-purpose Al at tests of multi-step reasoning have improved. This is largely due to fine-tuning techniques through which a model learns to approach problems in a more structured way before it generates an output."}, {"title": "1.2. Current capabilities", "content": "Understanding and measuring the capabilities of general-purpose Al is crucial for assessing their risks. Existing governance frameworks and commitments rely on precisely measuring general-purpose Al capabilities, but they are a moving target and difficult to measure and define.\nMost experts agree that general-purpose Al systems are capable of tasks including:\nAssisting programmers and performing small- to medium-sized software engineering tasks.\nCreating images that are hard to distinguish from real photographs.\nEngaging in fluent conversation in many languages.\nFinding and summarising information relevant to a question or problem from many data sources.\nWorking simultaneously with multiple 'modalities' such as text, video, and speech.\nSolving textbook mathematics and science problems at up to a graduate level.\nMost experts agree that general-purpose Al is currently not capable of tasks including:\nPerforming useful robotic tasks such as household work.\nConsistently avoiding false statements.\nIndependently executing long projects, such as multi-day programming or research projects.\nGeneral-purpose Al agents can increasingly act and plan autonomously by controlling computers. Leading Al companies are making large investments in Al agents because they are expected to be economically valuable. There is rapid progress on tests related to web browsing, coding, and research tasks, though current Al agents still struggle with work that requires many steps.\nSince the publication of the Interim Report (May 2024), general-purpose Al systems have markedly improved at tests of scientific reasoning and programming. These improvements come in part from techniques that let general-purpose Al break down complex problems into smaller steps, by writing so-called 'chains of thought', before solving them.\nA key challenge for policymakers is how to account for context-specific capabilities in regulations. The capabilities of general-purpose Al can significantly change with more careful fine-tuning, prompting, and tools made available to the system. They can also decline in unfamiliar contexts. More rigorous evaluations needed to avoid overestimating or underestimating capabilities."}, {"title": "1.3. Capabilities in coming years", "content": "In the coming months and years, the capabilities of general-purpose Al systems could advance slowly, rapidly, or extremely rapidly. Both expert opinions and available evidence support each of these trajectories. To make timely decisions, policymakers will need to account for these scenarios and their associated risks. A key question is how rapidly Al developers can scale up existing approaches using even more compute and data, and whether this would be sufficient to overcome the limitations of current systems, such as their unreliability in executing lengthy tasks.\nDevelopers of general-purpose Al are advancing scientific, engineering, and 'agent' capabilities. In recent months, models have substantially improved at tests of scientific reasoning and programming, enabling new applications. Additionally, Al developers are making large efforts to develop more reliable general-purpose Al agents that can execute longer tasks or projects without human oversight by using computers and software tools, potentially with continuous learning during operation.\nGeneral-purpose Al-based tools are increasingly being used to accelerate the development of software and hardware, including general-purpose Al itself. They are widely used to more efficiently write software to train and deploy Al, to aid in designing Al chips, and to generate and curate training data. How this will affect the pace of progress has received little study.\nRecent improvements have been primarily driven by scaling up the compute and data used for pre-training, and by refining existing algorithmic approaches. For cutting-edge models, current estimates suggest that these factors have, in recent years, approximately increased:\nCompute for pre-training: 4x/year\nPre-training dataset size: 2.5x/year\nEnergy used for powering computer chips during training: 3x/year\nAlgorithmic pre-training efficiency: 3x/year (higher uncertainty)\nHardware efficiency: 1.3x/year\nIt is likely feasible for Al developers to continue to exponentially increase resources used for training, but this is not guaranteed. If recent trends continue, by the end of 2026, Al developers will train models using roughly 100x more training compute than 2023's most compute-intensive models, growing to 10,000x more training compute by 2030. New research suggests that this degree of scaling is likely feasible, depending on investment and policy decisions. However, it is more likely that today's pace of scaling will become infeasible after the 2020s due to bottlenecks in data, chip production, financial capital, and local energy supply."}, {"title": "2.1. Risks from malicious use", "content": "Malicious actors can use general-purpose Al to generate fake content that harms individuals in a targeted way. For example, they can use such fake content for scams, extortion, psychological manipulation, generation of non-consensual intimate imagery (NCII) and child sexual abuse material (CSAM), or targeted sabotage of individuals and organisations.\nHowever, the scientific evidence on these uses is limited. Anecdotal reports of harm from Al-generated fake content are common, but reliable statistics on the frequency and impact of these incidents are lacking. Therefore, it is difficult to make precise statements about the harms from fake content generated by general-purpose Al.\nIn recent months, limited progress has been made in scientifically capturing the extent of the problem. Since the publication of the Interim Report (May 2024), some new evidence has suggested a significant increase in the prevalence of Al-generated deepfake content online. Overall, reliable data on the full extent of the problem remains limited.\nSeveral mitigation techniques exist, but they all have serious limitations. Detection techniques can sometimes help identify content generated by general-purpose Al, but fundamental challenges remain. Media authentication techniques such as watermarks can provide an additional line of defence, but moderately skilled actors can usually remove them."}, {"title": "2.1.2. Manipulation of public opinion", "content": "Malicious actors can use general-purpose Al to generate fake content such as text, images, or videos, for attempts to manipulate public opinion. Researchers believe that if successful, such attempts could have several harmful consequences.\nGeneral-purpose Al can generate potentially persuasive content at unprecedented scale and with a high degree of sophistication. Previously, generating content to manipulate public opinion often involved a strong trade-off between quality and quantity.\nGeneral-purpose Al outputs, however, are often indistinguishable to people from content generated by humans, and generating them is extremely cheap. Some studies have also found them to be as persuasive as human-generated content.\nHowever, there is no scientific consensus on the expected impact of this potential abuse of general-purpose Al. There is limited evidence on the broader societal effects of false information, whether intentionally created or unknowingly shared, and whether Al-enabled or not. Some researchers believe that attempts at manipulating public opinion using general-purpose Al are most bottlenecked by a lack of effective distribution channels. This view implies that advances in manipulative content generation should have a limited impact on the efficacy of such campaigns.\nSince the publication of the Interim Report (May 2024), more research has emerged on the virality of, and possible mitigations for, Al-based attempts at manipulation. A new study finds that Al-generated manipulative content is perceived as less accurate but shared at similar rates to human-generated content, which suggests that such content can easily go viral regardless of whether it is Al or human-generated. New technical detection methods integrating both text and visual data have shown some success, but are not fully reliable.\nPolicymakers face limited mitigation techniques and difficult trade-offs. Attempts to address manipulation risk from general-purpose Al can, in some settings, be difficult to reconcile with protection of free speech. Further, as general-purpose Al outputs become increasingly persuasive and realistic, detecting cases of manipulation through Al can get harder. Prevention techniques, such as watermarking content, are useful but can be circumvented with moderate effort."}, {"title": "2.1.3. Cyber offence", "content": "Attackers are beginning to use general-purpose Al for offensive cyber operations, presenting growing but currently limited risks. Current systems have demonstrated capabilities in low- and medium-complexity cybersecurity tasks, with state-sponsored threat actors actively exploring Al to survey target systems. Malicious actors of varying skill levels can leverage these capabilities against people, organisations, and critical infrastructure such as power grids.\nCyber risk arises because general-purpose Al enables rapid and parallel operations at scale and lowers technical barriers. While expert knowledge is still essential, Al tools reduce the human effort and knowledge needed to survey target systems and gain unauthorised access.\nGeneral-purpose Al offers significant dual-use cyber capabilities. Evidence indicates that general-purpose Al could accelerate processes such as discovering vulnerabilities, which are essential for launching attacks as well as strengthening defences. However, resource constraints and regulations may prevent critical services and smaller organisations from adopting Al-enhanced defences. The ultimate impact of Al on the attacker-defender balance remains unclear.\nSince the publication of the Interim Report (May 2024), general-purpose Al systems have shown significant progress in identifying and exploiting cyber vulnerabilities. Al systems have autonomously found and exploited vulnerabilities in real open source software projects. Recent research prototypes have autonomously found and exploited vulnerabilities that take the fastest human security teams minutes to find, but struggle with more complex scenarios. General-purpose Al was also used to find and fix a previously unknown exploitable vulnerability in widely used software (SQLite).\nIn principle, the risk appears at least partially manageable, but there are key assessment challenges. Rapid advancements in capabilities make it difficult to rule out large-scale risks in the near term, thus highlighting the need for evaluating and monitoring these risks. Better metrics are needed to understand real-world attack scenarios, particularly when humans and Als work together. A critical challenge is mitigating offensive capabilities without compromising defensive applications."}, {"title": "2.1.4. Biological and chemical attacks", "content": "Growing evidence shows general-purpose Al advances beneficial to science while also lowering some barriers to chemical and biological weapons development for both novices and experts. New language models can generate step-by-step technical instructions for creating pathogens and toxins that surpass plans written by experts with a PhD and surface information that experts struggle to find online, though their practical utility for novices remains uncertain. Other models demonstrate capabilities in engineering enhanced proteins and analysing which candidate pathogens or toxins are most harmful. Experts could potentially use these in developing both more advanced weapons and defensive measures.\nThe real-world impact of Al on developing and using weapons including pandemic pathogens remains unclear due to secrecy requirements, testing prohibitions, and a need for better evaluations. Key evidence about malicious actors, their technical bottlenecks, and Al safety assessments relating to biological weapons are kept confidential to prevent misuse. Testing is often prohibited given the severe dangers these weapons pose. More evaluations are needed to assess how strongly current systems can aid the many steps of weapons development; substantial expertise and resources remain necessary barriers.\nIn recent months, advances have generated greater evidence of risk and expanded the biological capabilities of general-purpose Al, and there are emerging efforts to develop best practices for evaluation. Since the Interim Report (May 2024), general-purpose language models have made substantial advances in tests of biological weapons expertise and general scientific reasoning. Al has also demonstrated new capabilities in protein design and in working with multiple types of scientific data \u2013 including chemicals, proteins, and DNA \u2013 enhancing its ability to design complex biological structures. The implications for risks are still being studied, with initial evidence suggesting a rise in potential risks alongside benefits.\nIf rapid advancement continues, this creates urgent policy challenges for evaluating and managing biological risks. Recent rapid advances in risk benchmarks make it increasingly hard to rule out large-scale risks in near-future models. Policymakers need to make decisions with incomplete information and integrate classified threat research. Adding to these challenges are the ongoing debates over the risk-benefit trade-offs of releasing open-weight models, particularly Al tools for creating biological and chemical structures, and the fact that policies that depend on humans to detect risk and intervene may be too slow to address the current pace of development."}, {"title": "2.2. Risks from malfunctions", "content": "Relying on general-purpose Al products that fail to fulfil their intended function can lead to harm. For example, general-purpose Al systems can make up facts ('hallucination'), generate erroneous computer code, or provide inaccurate medical information. This can lead to physical and psychological harms to consumers and reputational, financial and legal harms to individuals and organisations.\nSuch reliability issues occur because of technical shortcomings or misconceptions about the capabilities and limitations of the technology. For example, reliability issues may stem from technical challenges such as hallucinations, or from users applying systems to unsuitable tasks. Existing guardrails to contain and mitigate reliability issues are not fail-proof.\nBecause of the many potential uses of general-purpose Al, reliability issues are hard to predict. Pre-release evaluations miss reliability issues that only manifest in real-world usage. In addition, existing techniques to measure reliability issues are not robust, which means that it is also not yet possible to dependably assess prevention and mitigation techniques.\nResearchers are trying to develop more useful measurement and mitigation techniques, particularly, to address technical shortcomings. Since the publication of the Interim Report (May 2024), measurements and mitigation strategies for addressing reliability issues with general-purpose Al have expanded.\nA key challenge for policymakers is the lack of standardised practices for predicting, identifying, and mitigating reliability issues. Underdeveloped risk management makes it difficult to verify developers' claims about general-purpose Al functionalities. Policymakers also face a challenge in balancing the promotion of innovation while discouraging over-reliance on Al."}, {"title": "2.2.2. Bias", "content": "General-purpose Al systems can amplify social and political biases, causing concrete harm. They frequently display biases with respect to race, gender, culture, age, disability, political opinion, or other aspects of human identity. This can lead to discriminatory outcomes including unequal resource allocation, reinforcement of stereotypes, and systematic neglect of certain groups or viewpoints.\nBias in Al has many sources, like poor training data and system design choices. General-purpose Al is primarily trained on language and image datasets that disproportionately represent English-speaking and Western cultures. This contributes to biased output. Certain design choices, such as content filtering techniques used to align systems with particular worldviews, can also contribute to biased output.\nTechnical mitigations have led to substantial improvements, but do not always work. Researchers have made significant progress toward addressing bias in general-purpose Al, but several problems are still unsolved. For instance, the line between harmful stereotypes and useful, accurate world knowledge can be difficult to draw, and the perception of bias may vary depending on cultural contexts, social settings, and use cases.\nSince the publication of the Interim Report (May 2024), research has uncovered new, more subtle types of Al bias. For example, recent work has shown that general-purpose Al can generate biased outputs based on whether the user engages with the Al in a certain dialect.\nPolicymakers face trade-offs related to Al bias. There are many areas, such as legal decision-making, in which general-purpose Al can in principle be very helpful. However, current systems are not always reliable, which can cause discrimination risks. Policymakers need to weigh fundamental trade-offs between competing priorities such as fairness, accuracy, and privacy, particularly when regulating high-stakes applications."}, {"title": "2.2.3. Loss of control", "content": "'Loss of control' scenarios are hypothetical future scenarios in which one or more general-purpose Al systems come to operate outside of anyone's control, with no clear path to regaining control. These scenarios vary in their severity, but some experts give credence to outcomes as severe as the marginalisation or extinction of humanity.\nExpert opinion on the likelihood of loss of control varies greatly. Some consider it implausible, some consider it likely to occur, and some see it as a modest-likelihood risk that warrants attention due to its high severity. Ongoing empirical and mathematical research is gradually advancing these debates.\nTwo key requirements for commonly discussed loss of control scenarios are a. markedly increased Al capabilities and b. the use of those capabilities in ways that undermine control. First, some future Al systems would need specific capabilities (significantly surpassing those of current systems) that allow them to undermine human control. Second, some Al systems would need to employ these 'control-undermining capabilities', either because they were intentionally designed to do so or because technical issues produce unintended behaviour.\nSince the publication of the Interim Report (May 2024), researchers have observed modest advancement towards the development of control-undermining capabilities. Relevant capabilities include autonomous planning capabilities associated with Al agents, more advanced programming capabilities, and capabilities useful for undermining human oversight.\nManaging potential loss of control could require substantial advance preparation despite existing uncertainties. A key challenge for policymakers is preparing for a risk whose likelihood, nature, and timing remains unusually ambiguous."}, {"title": "2.3. Systemic risks", "content": "This section considers a range of systemic risks, in the sense of \"broader societal risks associated with Al deployment, beyond the capabilities of individual models\u201d (636). Note that this is not identical with how the European Al Act uses 'systemic risks' to refer to general-purpose Al models with a high impact on society, based on criteria such as training compute and the number of users."}, {"title": "2.3.1. Labour market risks", "content": "Current general-purpose Al is likely to transform the nature of many existing jobs, create new jobs, and eliminate others. The net impact on employment and wages will vary significantly across countries, across sectors, and even across different workers within the same job.\nIn potential future scenarios with general-purpose Al that outperforms humans on many complex tasks, the labour market impacts would likely be profound. While some workers will benefit, many others would likely face job losses or wage declines. These disruptions could be particularly severe if autonomous Al agents become capable of completing longer sequences of tasks without human supervision.\nLabour market risks arise from the potential of general-purpose Al to automate a wide range of complex cognitive tasks across sectors. The extent of wage and employment impacts will largely depend on three factors: 1. how quickly general-purpose Al capabilities improve, 2. how widely businesses adopt these systems, and 3. how demand for human labour changes in response to the productivity gains driven by general-purpose Al.\nRecent evidence suggests rapidly growing adoption rates. Since the Interim Report (May 2024), new research suggests that general-purpose Al is being adopted faster than some previous general-purpose technologies and is delivering significant productivity gains on tasks that it is used for.\nMitigating negative impacts on workers is challenging given the uncertainty around the pace and scale of future impacts. Therefore, a key challenge for policymakers is to identify flexible policy approaches that can adapt to the impacts of general-purpose Al over time, even when working with incomplete data. Further challenges include predicting which sectors will be most affected, addressing potential increases in inequality, and ensuring adequate support for displaced workers."}, {"title": "2.3.2. Global Al R&D divide", "content": "Large companies in countries with strong digital infrastructure lead in general-purpose Al R&D, which could lead to an increase in global inequality and dependencies. For example, in 2023, the majority of notable general-purpose Al models (56%) were developed in the US. This disparity exposes many LMICs to risks of dependency and could exacerbate existing inequalities.\nThe rising cost for developing general-purpose Al is the main reason for this 'AI R&D divide'. Access to large and expensive quantities of computing power has become a prerequisite for developing advanced general-purpose Al. Academic institutions and most companies, especially those in LMICs, do not have the means to compete with large tech companies.\nAttempts at closing the Al R&D divide have not been successful. An increasing number of efforts have been focused on democratising access to compute, investing in Al skills training in LMICs, and open sourcing prominent Al models. But these efforts will require considerable financial investment and significant time to implement.\nRecent work suggests the AI R&D divide might widen further due to a trend of increasing R&D costs at the frontier. Since the publication of the Interim Report (May 2024), researchers have published new evidence on the rising costs of developing state-of-the-art Al, growing disparities in the concentration of Al talent, and increasing centralisation of computing resources needed to train large general-purpose Al models.\nThere is a lack of evidence on the effectiveness of potential ways to address the Al R&D divide. For example, the impact of Al training programmes or infrastructure investments in LMICs remains unclear."}, {"title": "2.3.3. Market concentration and single points of failure", "content": "Market shares for general-purpose Al tend to be highly concentrated among a few players, which can create vulnerability to systemic failures. The high degree of market concentration can invest a small number of large technology companies with a lot of power over the development and deployment of Al, raising questions about their governance. The widespread use of a few general-purpose Al models can also make the financial, healthcare, and other critical sectors vulnerable to systemic failures if there are issues with one such model.\nThe market is so concentrated because of high barriers to entry. Developing state-of-the-art, general-purpose Al models requires substantial up-front investment. For example, the overall costs for developing a state-of-the-art model can currently reach hundreds of millions of US dollars. Key cost factors are computing power, highly skilled labour and vast datasets.\nIn addition, market leaders benefit from self-reinforcing dynamics that reward winners. Economies of scale allow bigger Al companies to spread one-off development costs over an ever-larger customer base, creating a cost advantage over smaller companies. Network effects further allow larger companies to train future models with user data generated through older models.\nMarket concentration has continued to persist in 2024. Since the publication of the Interim Report (May 2024), the previous consensus that market concentration in the general-purpose Al market is high has continued to hold.\nThere is little research on predicting or mitigating single points of failure in Al. This creates challenges for policymakers. The absence of reliable prediction methods on how failures may propagate through interconnected systems makes these risks hard to assess."}, {"title": "2.3.4. Risks to the environment", "content": "General-purpose Al is a moderate but rapidly growing contributor to global environmental impacts through energy use and greenhouse gas (GHG) emissions. Current estimates indicate that data centres and data transmission account for an estimated 1% of global energy-related GHG emissions, with Al consuming 10-28% of data centre energy capacity. Al energy demand is expected to grow substantially by 2026, with some estimates projecting a doubling or more, driven primarily by general-purpose Al systems such as language models.\nRecent advances in general-purpose Al capabilities have been largely driven by a marked increase in the amount of computation that goes into developing and using Al models, which uses more energy. While Al firms are increasingly powering their data centre operations with renewable energy, a significant portion of Al training globally still relies on high-carbon energy sources such as coal or natural gas, leading to the aforementioned emissions and contributing to climate change.\nAl development and deployment also has significant environmental impacts through water and resource consumption, and through Al applications that can either harm or benefit sustainability efforts. Al consumes large amounts of water for energy production, hardware manufacturing, and data centre cooling. All of these demands increase proportionally to Al development, use, and capability. Al can also be used to facilitate environmentally detrimental activities such as oil exploration, as well as in environmentally friendly applications with the potential to mitigate or help society adapt to climate change, such as optimising systems for energy production and transmission.\nCurrent mitigations include improving hardware, software, and algorithmic energy efficiency and shifting to carbon-free energy sources, but so far these strategies have been insufficient to curb GHG emissions. Increases in technology efficiency and uptake of renewable energy have not kept pace with increases in demand for energy: technology firms' GHG emissions are often growing despite substantial efforts to meet net-zero carbon goals. Significant technological advances in general-purpose Al hardware or algorithms, or substantial shifts in electricity generation, storage and transmission, will be necessary to meet future demand without environmental impacts increasing at the same pace.\nSince the publication of the Interim Report (May 2024), there is additional evidence that the demand for energy to power Al workloads is significantly increasing. General-purpose Al developers reported new challenges in meeting their net-zero carbon pledges due to increased energy use stemming from developing and providing general-purpose Al models, with some reporting increased GHG emissions in 2023 compared to 2022. In response, some firms are turning to virtually carbon-free nuclear energy to power Al data centres."}, {"title": "2.3.5. Risks to privacy", "content": "General-purpose Al systems can cause or contribute to violations of user privacy. Violations can occur inadvertently during the training or usage of Al systems, for example through unauthorised processing of personal data or leaking health records used in training. But violations can also happen deliberately through the use of general-purpose Al by malicious actors; for example, if they use Al to infer private facts or violate security.\nGeneral-purpose Al sometimes leaks sensitive information acquired during training or while interacting with users. Sensitive information that was in the training data can leak unintentionally when a user interacts with the model. In addition, when users share sensitive information with the model to achieve more personalised responses, this information can also leak or be exposed to unauthorised third parties.\nMalicious actors can use general-purpose Al to aid in the violation of privacy. Al systems can facilitate more efficient and effective searches for sensitive data and can infer and extract information about specific individuals from large amounts of data. This is further exacerbated by the cybersecurity risks created by general-purpose Al systems (see 2.1.3. Cyber offence).\nSince the publication of the Interim Report (May 2024), people increasingly use general-purpose Al in sensitive contexts such as healthcare or workplace monitoring. This creates new privacy risks which so far, however, have not materialised at scale. In addition, researchers are trying to remove sensitive information from training data and build secure deployment tools.\nFor policymakers, it remains hard to know the scale or scope of privacy violations. Assessing the extent of privacy violations from general-purpose Al is extremely challenging, as many harms occur unintentionally or without the knowledge of the affected individuals. Even for documented leaks, it can be hard to identify their source, as data is often handled across multiple devices or in different parts of the supply chain."}, {"title": "2.3.6. Risks of copyright infringement", "content": "The use of vast amounts of data for training general-purpose Al models has caused concerns related to data rights and intellectual property. Data collection and content generation can implicate a variety of data rights laws, which vary across jurisdictions and may be under active litigation. Given the legal uncertainty around data collection practices, Al companies are sharing less information about the data they use. This opacity makes third-party Al safety research harder.\nAl content creation challenges traditional systems of data consent, compensation, and control. Intellectual property laws are designed to protect and promote creative expression and innovation. General-purpose Al both learns from and can create works of creative expression.\nResearchers are developing tooling and methods to mitigate the risks of potential copyright infringement and other data rights laws, but these remain unreliable. There are also limited tools to source and filter training data at scale according to their licences, affirmative consent from the creators, or other legal and ethical criteria.\nSince the Interim Report (May 2024), data rights holders have been rapidly restricting access to their data. This prevents Al developers from using this data to train their models, but also hinders access to the data for research, social good, or non-Al purposes.\nPolicymakers face the challenge of enabling responsible and legally compliant data access without discouraging data sharing and innovation. Technical tools to evaluate, trace, filter, and automatically license data could make this much easier, but current tools are not sufficiently scalable and effective."}, {"title": "2.4. Impact of open-weight general-purpose Al models on Al risks", "content": "How an Al model is released to the public is an important factor in evaluating the risks it poses. There is a spectrum of model release options, from fully closed to fully open, all of which involve trade-offs between risks and benefits. Open-weight models \u2013 those with weights made publicly available for download \u2013 represent one key point on this spectrum.\nOpen-weight models facilitate research and innovation while also enabling malicious uses and perpetuating some flaws. Open weights allow global research communities to both advance capabilities and address model flaws by providing them with direct access to a critical Al component that is prohibitively expensive for most actors to develop independently. However, the open release of model weights could also pose risks of facilitating malicious or misguided use or perpetuating model flaws and biases.\nOnce model weights are available for public download, there is no way to implement a wholesale rollback of all existing copies of the model. This is because various actors will have made their own copies. Even if retracted from hosting platforms, existing downloaded versions are easy to distribute offline. For example, state-of-the-art models such as Llama-3.1-405B can fit on a USB stick.\nSince the Interim Report (May 2024), high-level consensus has emerged that risks posed by greater Al openness should be evaluated in terms of 'marginal risk'. This refers to the additional risk associated with releasing Al openly, compared to risks posed by closed models or existing technology.\nWhether a model is open or closed, risk mitigation approaches need to be implemented throughout the Al life cycle, including during data collection, model pre-training, fine-tuning, and post-release measures. Using multiple mitigations can bolster imperfect interventions.\nA key challenge for policymakers centres on the evidence gaps surrounding the potential for both positive and negative impacts of open weight release on market concentration and competition. The effects will likely vary depending on how openly the model is released (e.g. whether release is under an open source licence), on the level of market being discussed (i.e. competition between general-purpose Al developers vs. downstream application developers), and based on the size of the gap between competitors.\nAnother key"}]}