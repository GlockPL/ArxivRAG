{"title": "UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization", "authors": ["Ziwen Guo", "Zi Fang", "Zhuang Fu"], "abstract": "Three-dimensional ultrasound imaging is a critical technology widely used in medical diagnostics. However, traditional 3D ultrasound imaging methods have limitations such as fixed resolution, low storage efficiency, and insufficient contextual connectivity, leading to poor performance in handling complex artifacts and reflection characteristics. Recently, techniques based on NeRF (Neural Radiance Fields) have made significant progress in view synthesis and 3D reconstruction, but there remains a research gap in high-quality ultrasound imaging. To address these issues, we propose a new model, UlRe-NeRF, which combines implicit neural networks and explicit ultrasound volume rendering into an ultrasound neural rendering architecture. This model incorporates reflection direction parameterization and harmonic encoding, using a directional MLP module to generate view-dependent high-frequency reflection intensity estimates, and a spatial MLP module to produce the medium's physical property parameters. These parameters are used in the volume rendering process to accurately reproduce the propagation and reflection behavior of ultrasound waves in the medium. Experimental results demonstrate that the UlRe-NeRF model significantly enhances the realism and accuracy of high-fidelity ultrasound image reconstruction, especially in handling complex medium structures.", "sections": [{"title": "1 Introduction", "content": "Ultrasound (US) is a highly valued imaging modality in medicine due to its cost-effectiveness, safety, non-invasiveness, and ability to provide real-time imaging. Unlike MRI and CT, US is portable, radiation-free, and user-friendly, making it ideal for various clinical applications, including intraoperative imaging and surgical guidance. Its affordability and efficiency have led to its growing popularity among clinicians and researchers. Compared to conventional two-dimensional (2D) ultrasound, three-dimensional (3D) ultrasound offers significant advantages. 3D ultrasound allows direct visualization of 3D anatomy, enhancing diagnostic accuracy and reducing dependence on operator skill, while providing"}, {"title": "2 Related Works", "content": "Numerous subsequent NeRF variants focus on improving the core compo-nent of NeRF to improve imaging quality. MLP tends to learn low-frequency functions, limiting its ability to represent complex geometry and texture [18]. To address this issue, NeRF maps the Cartesian coordinates to a higher di-mensional space using sinusoidal positional encoding [14] [24]. Mip-NeRF [2]improved volume rendering by using cone tracing instead of the ray tracing instandard NeRF. They introduced Integrated Positional Encoding (IPE), wherea cone cast from the camera's center through the pixel was approximated by amultivariate Gaussian. By IPE over a conical frustum for each quadrature seg-ment along the ray, Mip-NeRF encoded the scene at multiple scales, preventingaliasing when rendering from different positions or resolutions. However, due todifferences in imaging principles, these neural volumetric scene representationmethods designed for natural images are not well-suited for reconstructing thecomplex biological tissues in ultrasound images. Consequently, their view syn-thesis performance falls short of meeting the requirements for 3D ultrasoundreconstruction.\nRef-NeRF [26] enhances NeRF by structuring view-dependent appearanceinto pre-filtered incident radiance, diffuse color, material roughness, and specu-lar tint. This decomposition method allows for more accurate rendering of spec-ular highlights and reflections. To achieve this, view direction reflections arereparameterized as a function of reflection direction, significantly improving theinterpolation of reflective appearances. The specific formula is as follows:\n$r = 2(v \\cdot n)n -v$\nAdditionally, Ref-NeRF introduces Integrated Directional Encoding (IDE) toeffectively represent the material radiance function as it varies with roughness.IDE encodes the reflection direction using a convolution of spherical harmonicsand von Mises-Fisher distribution:\n$IDE(r) = \\Sigma_{l=0}^{L} \\Sigma_{m=-1}^{l} A_{lm} \\cdot Y_{lm} (r)$\nThis method captures finer high-frequency information in reflection direc-tions and shares lighting information across different roughness regions, signifi-cantly enhancing rendering realism and accuracy. By modeling reflection direc-tions based on computer graphics principles, it provides a viable solution foraccurately capturing ultrasound wave reflections and scattering at tissue inter-faces, thereby improving image detail and clarity."}, {"title": "3 Methods", "content": "NeRF and its early variants perform poorly in parameterizing reflection di-rections and handling high-frequency information, especially in complex media"}, {"title": "3.1 Ultrasound Reflection Direction Parameterization", "content": "To better simulate the reflection characteristics of ultrasound waves at themedium interface, we propose a new method for parameterizing reflection di-rections, as shown in Figure 2(a). The reflection and refraction properties ofultrasound waves, treated as rays, can be calculated using the laws of wavephysics [21]. When an ultrasound wave $I_i$ impinges on the medium interface ata certain angle, reflection and refraction occur. The intensities of reflection andrefraction can be calculated using the following formulas:\n$I_r = I_i \\cdot (\\frac{Z_2 - Z_1}{Z_2 + Z_1})^2$\n$I_t = I_i \\cdot (\\frac{4Z_2Z_1}{Z_2 + Z_1})^2$\nTo overcome the limitations of traditional methods in handling complex in-terfaces, we introduced the Phong model from the field of computer graphics to accurately simulate specular reflection phenomena [17]. This model analyzesreflected light intensity by considering ambient light, diffuse reflection, and spec-ular reflection:\n$I_r = f_r (I_i, I_o) I_i$\n$= k_a I_i + k_d (\\hat{I} \\cdot \\hat{n})I_i + k_s (R \\cdot V)^n I_i$\n$= I_{ra} + I_{rd} + I_{rs}.$\nThe Phong model's Bidirectional Reflectance Distribution Function (BRDF)exhibits rotational symmetry with respect to the reflection angle, thus satisfy-ing $f (I_i, I_o) = p (I_r \\cdot I_o)$. When ignoring complex optical phenomena such asinterreflections and self-occlusions, the radiance in the view direction can bedetermined solely as a function of the specular reflection direction $I_{rs}$:\n$L_{out} (I_o) \\propto \\int Lin (I) P (I_{rs} \\cdot I_i) dI_i = F (I_{rs})$\nTherefore, we parameterize the relationship between the specular reflectiondirection $I_{rs}$ and the viewing direction $I_o$:\n$I_{rs} = 2 (I_o \\cdot n) n -I_i$\nWhere $I_i$ = -d represents the unit vector from the reflection point on theboundary to the transducer, and n is the normal vector at that point. In prac-tice, the medium interface is usually not a perfect mirror but consists of manymicrofacets. This results in the macroscale normal vector n being a perturbednormal vector n', also known as the microfacet normal. As shown in Figure2(b), the corrected normal vector \u00f1' is calculated as follows:\n$n' = n + \\delta (I - n (n \\cdot I_i))$\nWhere $\\delta$ represents the roughness at that location. By accounting for themicrofacet structure of the medium, a more accurate specular reflection directioncan be calculated:\n$I_{rs} = 2 (n'\\cdot I_o) n' \u2013 I_o.$"}, {"title": "3.2 Reflective Harmonic Encoding", "content": "In the traditional NeRF framework, positional encoding methods have limi-tations when handling high-frequency information, leading to an inability toaccurately reproduce high-frequency details in the propagation of ultrasoundwaves [9] [14]. This poses challenges in simulating the behavior of ultrasoundwaves in various media, especially in biological tissues with complex structuresand heterogeneous properties, where traditional methods fail to accurately cap-ture reflection direction information. To address this issue, we drew inspirationfrom the Integrated Directional Encoding (IDE) method in Mip-NeRF [2] and ap-plied it to ultrasound imaging, calling it Reflective Harmonic Encoding (RHE).RHE uses spherical harmonics to encode high-frequency information of reflec-tion directions, making it particularly suitable for biological tissues with complexcharacteristics [1]. It finely encodes reflection directions, improving reconstruc-tion accuracy. Specifically, we use the von Mises-Fisher (vMF) distribution todefine the distribution of reflection directions and encode these directions us-ing a set of spherical harmonics. First, we define the distribution of reflectiondirections on the unit sphere using the von Mises-Fisher distribution, centeredat the reflection vector $I_r$, with the concentration parameter k defined as thereciprocal of roughness \u0440, \u043a = 1/p. Next, we represent the encoding of reflec-tion directions using a weighted sum of spherical harmonic functions {$Y_m$}. Theencoding form under the vMF distribution is defined as:\n$RHE (1,5) = \\Sigma_{(l,m)EL} A_{l}(k)Y_{m} (I_r)$\nWhere L represents the set of spherical harmonic functions. The weightingfunction $A_{l}(K)$ depends on the concentration parameter \u043a and can be approxi-mated by the following formula:\n$A_{l}(\u043a) \u2248 exp(\\frac{l(l + 1)}{2\u043a})$\nThis encoding method allows us to more accurately capture and express infor-mation about ultrasound wave reflections. Through RHE, we can finely encodethese reflection directions, significantly improving the accuracy of boundary re-constructions. Especially when dealing with reflections in complex tissue struc-tures and rich details, RHE provides higher resolution and accuracy."}, {"title": "3.3 Sine Activation Function", "content": "Sinusoidal representation networks (SIRENs) [23] utilize sine as the activationfunction in MLPs to model high-frequency information accurately. They intro-duced an initialization scheme to prevent vanishing gradients in periodic acti-vation functions, showing that SIRENs fit complex signals and their derivativesrobustly. This provides a solid foundation for using the Sine activation functionin ultrasound image reconstruction. The periodicity and continuity of the Sineactivation function enable it to capture high-frequency components and subtlevariations effectively. Its expression is:\n$Sine (x) = sin(x)$\nCompared to traditional activation functions like ReLU and Sigmoid, whichare sensitive to initial parameters and unstable with complex signals, the Sine ac-tivation function is more stable and robust over a wide range of parameters [16].In the Ultra-NeRF model, results were initially unstable and highly dependenton network configuration. By introducing the Sine activation function, our modeldemonstrated more consistent performance across different initial configurations,reducing the impact of initial settings on the final imaging outcome. This im-provement enhances the model's robustness and stability, making it better suitedfor various configurations and complex ultrasound imaging scenarios."}, {"title": "3.4 Ultrasound Neural Rendering Architecture", "content": "To address the complexity of ultrasound scenes and accurately reconstruct ul-trasound characteristics within the medium, we designed an ultrasound neuralrendering architecture based on implicit neural networks and volume rendering(as shown in Figure 3). This architecture integrates two main modules, the di-rectional MLP and the spatial MLP, and performs volume rendering based onray tracing and physical principles, significantly improving the reconstructionaccuracy of ultrasound images.\nThe primary function of the directional MLP is to process ray direction in-formation. Specifically, it receives the ray direction d as input and generatesview-dependent reflection intensity information. By generating the reflection in-tensity estimate $C_{ref}$, it ensures that the reflection characteristics under eachview are accurately captured, enhancing the ability to simulate complex reflec-tion properties. The formula is as follows:\n$C_{ref} = \u00b5 (c_d + c_s)$\nWhere $C_{ref}$ is the reflection intensity estimate, $c_s$ is the specular reflectioninformation encoded by direction, $c_d$ is the diffuse reflection information pro-duced during the interaction of ultrasound waves with the interface, which isonly position-dependent, and u is a scaling function that limits the output valueto the range [0,1]."}, {"title": "3.5 US volume rendering", "content": "The traditional Neural Radiance Fields (NeRF) method generates images by ac-cumulating point data in 3D space along the line of sight. However, this approachhas significant limitations when applied to ultrasound imaging. The physicalphenomena involved in ultrasound imaging are more complex, requiring consid-eration of wave effects and acoustic impedance matching, which are not factorsin natural image rendering. Therefore, a more specialized approach is neces-sary. We improved the Ultra-NeRF method by proposing a volume renderingtechnique that utilizes the physical properties of the medium. This new methodcombines parameters generated by directional MLP and spatial MLP and in-corporates classical ultrasound imaging theory and ray tracing technology [3],thereby achieving more accurate simulations of ultrasound wave propagation andreflection to produce high-fidelity rendered images.\nSpecifically, we synthesize views by querying the ultrasound characteristicsof the medium along the path of the sound wave: attenuation coefficient a,reflectivity \u1e9e, scattering density ps, and amplitude 6. As shown in Figure 3, wetreat ultrasound waves as rays emitted from the transducer, simulating theirpropagation paths through different media. For each scanliner, we define theultrasound intensity $C_{render} (r,t)$ at a distance t as the sum of the reflectedenergy R(r, t) and backscattered energy B(r, t), describing the energy changesof the ultrasound wave during propagation:\n$C_{render} (r,t) = R(r, t) + B(r, t)$\nBased on the Beer-Lambert law, we introduce the concept of residual energyI(r, t), whose variation is calculated using the following formula:\n$I(r, t) = I_o exp(\\int_{-1}^{t-1} (- (\u03b1 \\cdot f \\cdot \\Delta t)dr). \\Pi_{n=0}^{t-1} (1-\u03b2(r, n)))$\nWhere a is the attenuation coefficient of the medium, f is the frequencyof the ultrasound wave, and \u1e9e(r, n) is the reflection coefficient of the mediumin the tissue. This formula describes the exponential decay of the signal as itpropagates through the medium.\nThe reflected energy R(r,t) refers to the energy generated at the mediuminterface due to reflection. The calculation of R(r,t) is based on the residualenergy \u1e9e(r, t), the reflection coefficient, and a predefined two-dimensional pointspread function (PSF):\n$R(r,t) = I(r, t) \\cdot \u03b2(r, t) \\otimes PSF(r),$\nIn our model, the point spread function (PSF) is simplified to include only theaxial and lateral directions, excluding the elevation direction. The PSF functionis approximated as a two-dimensional Gaussian function modulated by a cosinefunction, specifically:\n$PSF(x, y) = exp(-\\frac{1}{2} (\\frac{x^2}{\u03c3_x^2} + \\frac{y^2}{\u03c3_y^2})) \\cdot cos(2\u03c0fx)$\nWhere $\u03c3_x$ and $\u03c3_y$ represent the standard deviations in the axial and lateraldirections, respectively, and f is the frequency of the ultrasound wave.\nBackscattered energy B(r,t) refers to the energy generated by scattering,which consists of the residual energy I(r, t) and the two-dimensional distributionof scatter points T(r, t):\n$B(r,t) = I(r, t) \\cdot S(r, t) \\otimes PSF(r),$\nHere, the two-dimensional distribution of scatter points S(r, t) is defined as:\n$S(r,t) = n(r, t) \\cdot \\phi(r, t)$\nwhere the function n(r, t) indicates the intensity of the scatterers. To adda degree of smoothness while maintaining boundary clarity, we use the Betadistribution to parameterize the scattering density ps, which provides bettercontinuity compared to the Bernoulli distribution. The intensity of the scatterpoints is determined by their amplitude 4.\nBy integrating these energy estimates, we obtain the ultrasound intensityat different positions along each scanline. By normalizing and combining theintensity values $C_{render}$ generated by the rendering process with the reflectionintensity $C_{ref}$ produced by the directional MLP, we get the final rendered result:\n$C_{final} = G (C_{render} + C_{ref}).$\nThis improved method not only addresses the shortcomings of Ultra-NeRFin handling complex artifacts and reflection characteristics but also enhancesrendering consistency and accuracy across different views and complex scenes.Through this new approach, UlRe-NeRF can more accurately simulate the prop-agation and reflection behavior of ultrasound waves in various media, signifi-cantly improving the physical realism and visual quality of the images."}, {"title": "4 Experiments", "content": "Our experiments were conducted on a computer equipped with an NVIDIA RTX3070 GPU and 32GB of RAM. We utilized the Ultra-NeRF open-source datasetto simulate liver ultrasound images generated from CT scans, following the imagegeneration methods outlined in Ultra-NeRF's work and using the ImFusion tool.The dataset includes seven scans: six at different oblique angles and one verticalscan. Each scan contains 200 2D ultrasound images along with their tracking"}, {"title": "4.2 Ablation Study Results of the Neural Network Architecture", "content": "Although NeRF and Mip-NeRF (the previous best-performing techniques) haveshown outstanding performance in view synthesis and image reconstruction, theirray integration-based rendering method has limitations in ultrasound imaging.The traditional NeRF method determines pixel color values by integrating alongaray, which is suitable for visible light images. However, ultrasound imaginginvolves interactions of ultrasound waves with different tissues along the propa-gation path. To address this, we made specific modifications to NeRF and Mip-NeRF to better handle the characteristics of ultrasound images. Specifically, weused a Directional MLP in the model to directly output simulated ultrasoundimages, capturing reflection information of ultrasound waves in different direc-tions. Furthermore, we conducted ablation studies on the performance of eachmodel using the ultrasound dataset."}, {"title": "4.3 Ablation Study Results of the Rendering Components", "content": "To demonstrate the effectiveness of UlRe-NeRF's rendering method in ul-trasound image reconstruction, we designed various ablation experiments com-paring it to Ultra-NeRF. These experiments included replacing Ultra-NeRF'srendering method with ours and using Ultra-NeRF's rendering method in ourmodel. Table 2 shows the quantitative comparison results of different modelsacross several metrics. It is evident that UlRe-NeRF exhibits significant advan-tages in all metrics, especially in significantly reducing the LPIPS value. Thisimprovement is reflected in the visual quality of the images, with a noticeablesuppression of noise and artifacts, resulting in clearer and more realistic images.In contrast, using Ultra-NeRF's original rendering method results in significantnoise and detail loss in the images. Additionally, when Ultra-NeRF adopts ourmethod, there is a significant improvement in image quality and metrics, indi-cating that our method better reconstructs ultrasound signals and effectivelyreduces noise interference. Quantitative analysis of the results shows that ourmethod can more accurately capture and reconstruct details when handling com-plex tissue structures, significantly enhancing image clarity and realism."}, {"title": "5 Discussion & Conclusion", "content": "In this paper, we present UlRe-NeRF, a more effective and precise Neural Ren-dering method for 3D Ultrasound Imaging. We incorporate additional inductivebiases about ultrasound: improving implicit representation network with reflec-tion direction parameterization and Reflective Harmonic Encoding (RHE) tocapture complex tissue reflections, improving explicit volumic rendering with in-tegration of reflection intensity and volume rendering to simulate the medium'sphysical properties and light interactions.\nThe experiments show that our approach can achieve high-fidelity 3D ul-trasound imaging synthesizes: it learns view-dependent geometry and capturecomplex tissue structures; it simulates various physical property parameters ofthe the medium; it reproduces the propagation and reflection behavior of ultra-sound waves in the medium.\nOur study provides an important advance in ultrasound image reconstructiontechniques, demonstrating the potential of ultrasound neural rendering architec-tures based on implicit neural networks and explicit ultrasound volume renderingto improve ultrasound image quality [15].\nThe characteristics of ultrasonic imaging itself limit the usage of hierarchicalsampling strategy. Another methods specific for ultrasound to make renderingmore sample-efficient is required. Although we have proposed new explicit ultra-sound volume rendering methods to improve the contrast and clarity of physi-"}]}