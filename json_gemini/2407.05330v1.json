{"title": "Fast Proxy Experiment Design for Causal Effect Identification", "authors": ["Sepehr Elahi", "Sina Akbari", "Jalal Etesami", "Negar Kiyavash", "Patrick Thiran"], "abstract": "Identifying causal effects is a key problem of interest across many disciplines. The two long- standing approaches to estimate causal effects are observational and experimental (randomized) studies. Observational studies can suffer from unmeasured confounding, which may render the causal effects unidentifiable. On the other hand, direct experiments on the target variable may be too costly or even infeasible to conduct. A middle ground between these two approaches is to estimate the causal effect of interest through proxy experiments, which are conducted on variables with a lower cost to intervene on compared to the main target. Akbari et al. [2022] studied this setting and demonstrated that the problem of designing the optimal (minimum-cost) experiment for causal effect identification is NP-complete and provided a naive algorithm that may require solving exponentially many NP-hard problems as a sub-routine in the worst case. In this work, we provide a few reformulations of the problem that allow for designing significantly more efficient algorithms to solve it as witnessed by our extensive simulations. Additionally, we study the closely-related problem of designing experiments that enable us to identify a given effect through valid adjustments sets.", "sections": [{"title": "1 Introduction", "content": "Identifying causal effects is a central problem of inter- est across many fields, ranging from epidemiology all the way to economics and social sciences. Conducting randomized (controlled) trials provides a framework to analyze and estimate the causal effects of interest, but such experiments are not always feasible. Even when they are, gathering sufficient data to draw sta- tistically significant conclusions is often challenging because of the limited number of experiments often (but not solely) due to the high costs.\nObservational data, which is usually more abun- dant and accessible, offers an alternative avenue. How- ever, observational studies bring upon a new challenge: the causal effect may not be identifiable due to un- measured confounding, making it impossible to draw inferences based on the observed data [Pearl, 2009, Hern\u00e1n and Robins, 2006].\nA middle ground between the two extremes of observational and experimental approaches was introduced by Akbari et al. [2022], where the authors suggested conducting proxy experiments to identify a causal effect that is not identifiable based on solely observational data. To illustrate the need for proxy experiments, consider the following drug-drug interaction example, based on the example in Lee et al. [2020a].\nExample 1. (Complex Drug Interactions and Cardiovascular Risk) Consider a simplified example of the interaction between antihypertensives (X1), anti-diabetics (X2), renal function modulators (X3),"}, {"title": "2 Problem formulation", "content": "We begin by reviewing relevant graphical definitions. An acyclic directed mixed graph (ADMG) is a graph with directed (\u2192) and bidirected (\u2194) edges such that the directed edges form no cycles [Richardson, 2003]. We denote an ADMG G by a tuple G = (V, (V, E, E), where V, E, and E represent the set of vertices, directed edges, and bidirected edges, respectively. Note that E is a set of ordered pairs of vertices in V, whereas E is a set of unordered pairs of vertices.\nVertices of G represent variables of the system under consideration, while the edges represent causal relations between them. We use the terms \u2018variable' and \u2018vertex' interchangeably. When (y,x) \u2208 \u1eba, we say y is a parent of x and x is a child of y. The set of parents of X C V denoted by Pa(X) = {y : (y, x) \u2208 E for some x \u2208 X} \\X. We denote by G[W], the induced subgraph of G over vertices W C V. A subset W of V is said to form a district in G if any pair of vertices x, y \u2208 W are connected through a bidirected path x \u2194\u2192y in G[W]. In other words, G[W] is a connected component through its bidirected edges. We say x \u2208 V is an ancestor of SC V if there is a directed path x \u2192\u2192s for some s\u2208 S. We denote the set of ancestors of S in the subgraph G[W] by Ancw (S). Note that SC Ancw(S). When W = V, we drop the subscript for ease of notation.\nLet X, Y CV be two disjoint sets of variables. The probability distribution of Y under a (possibly hypothetical) intervention on X setting its value to x is often represented as either P(Y(x)), using Rubin's potential outcomes model [Rubin, 1974], or P(Y | do(X = x)) using Pearl's do operator [Pearl, 2009]. We will adopt the shorthand Px(Y) to denote this interventional distribution2.\nDefinition 1 (Identifiability). An interventional distribution Px(Y) is identifiable given an ADMG G and the intervention set family I = {11, . . .,It}, with Ii \u2286 V, over the variables corresponding to G, if Px(Y) is uniquely computable as a functional of the members of {P1(\u00b7) : I \u2208 I}.\nRemark 1. It is common in the literature to define identifiability with respect to observational data only (i.e., when I = {Z\u2081 = 0}). Our definition above follows what is known as the \u2018general identifiability' from Lee et al. [2020a], Kivva et al. [2022].\nWe will now define the important notion of a hedge, which, as we will see shortly after, is central to deciding the identifiability of an interventional distribution given the data at hand.\nDefinition 2 (Hedge). Let S \u2286 V be a district in G. We say W\u2287 S forms a hedge for S if (i) Wisa district in G, and (ii) every vertex w \u2208 W is an ancestor of S in G[W] (i.e., W = Ancw(S)). We denote by Hg(S) the set of hedges formed for S in G.\nRemark 2. Definition 2 is different from the original definition of Shpitser and Pearl [2006]. The original definition was found to not correspond one-to-one with non-identifiability, as pointed out by Shpitser [2023]. However, our modified definition above is a sound and complete characterization of non-identifiability, as it coincides with the criterion put forward by Huang and Valtorta [2006] as well as the 'reachable closure' of Shpitser [2023].\nDefinition 3 (Hedge hull Akbari et al., 2022). Let S be a district in ADMG G. Also let Hg(S) be the set of all hedges formed for S in G. The union of all hedges in H\u00e7(S), denoted by H\u00e7(S) = UW\u2208HG(S) W, is said to be the hedge hull of S in G.\nProposition 1. Let G be an ADMG over the vertices V. Also let X,Y CV be disjoint sets of variables. Define S = Ancv\\X(Y), and let S = {S1,...,Sr} be the (unique) set of maximal districts in G[S]. The"}, {"title": "3 Reformulations of the min-cost intervention problem", "content": "In the previous section, we delineated the MCID problem as a discrete optimization problem. This problem, cast as Eq. (1), necessitates search within a doubly exponential space, which is computationally intractable. Algorithm 2 of [Akbari et al., 2022] is an algorithm that conducts this search and eventually finds the optimal solution. However, even when S comprises a single district, this algorithm requires, in the worst case, exponentially many calls to a subroutine which solves the NP-complete minimum hitting set problem on exponentially many input sets, hence resulting in a doubly exponential complexity. More specifically, their algorithm attempts to find a set of minimal hedges, where minimal indicates a hedge that contains no other hedges, and solves the minimum hitting set problem on them. However, there can be exponentially many minimal hedges, as shown for example in Fig. 2(c). Letting m = n/2, then any set that contains one vertex from each level (i.e., directed distance from S) is a minimal hedge, of which there are O(2n/2).\nFurthermore, the computational complexity of Algorithm 2 of Akbari et al. [2022] grows super- exponentially in the number of districts of S. This is due to the necessity of exhaustively enumerating every possible partitioning of these districts and executing their algorithm once for each partitioning.\nIn this section, we reformulate the MCID problem as a weighted partially maximum satisfiability (WPMAX-SAT) problem [Fu and Malik, 2006], and an integer linear programming (ILP) problem. In Appendix D, we also present reformulations as a submodular maximization problem and a reinforcement learning problem. The advantage of these new formulations is two-fold: (i) compared to Algorithm 2 of [Akbari et al., 2022], we state the problem as a single instance of another problem for which a range of well-studied solvers exist, and (ii) these formulations allow us to propose algorithms with computational complexity that is quadratic in the number of districts of S. We will see how these advantages translate to drastic performance gains in Section 5."}, {"title": "3.1 Min-cost intervention as a WPMAX-SAT problem", "content": "We begin with constructing a 3-SAT formula F that is satisfiable if and only if the given query Px (Y) is identifiable. To this end, we define m+2 variables {xi,j}m for each vertex vi \u2208 V, where m = |Hg(S)\\S| is the cardinality of the hedge hull of S, excluding S. Intuitively, xi,j is going to indicate whether or not vertex vi is reachable from S after j iterations of alternating depth-first-searches on directed and bidirected edges. This is in line with the workings of Algorithm 2 for finding the hedge hull of S. In particular, if a vertex vi is reachable after m + 1 iterations, that is, Xi,m+1 = 1, then vi is a member of the hedge hull of S. The query of interest is identifiable if and only if Hg(S) = S, that is, the hedge hull of S contains no other vertices. Therefore, we ensure that the formula F is satisfiable if and only if Xi,m+1 = 0 for every vi \u2209 S. The formal procedure for constructing this formula is as follows.\nSAT Construction Procedure. Suppose a causal ADMG G = (V,E,E) and a set SCV are given, where S is a district in G. Suppose H\u00e7(S) = {v1,..., Un} is the hedge hull of S in G, where without loss of generality, S = {Um+1,... Un}, and {V1,... vm}\u2229S = 0. We will construct a corresponding boolean expression in conjunctive normal form (CNF) using variables {xi,j} for i \u2208 {1,...,m} and j\u2208 {0,..., m + 1}. For ease of presentation, we also define xi,j = 1 for all i \u2208 {m + 1,..., n}, j\u2208 {0,..., m + 1}. The construction is carried out in m + 2 steps, where in each step, we conjoin new clauses to the previous formula using 'and'. The procedure is as follows:\n\u2022 For odd j\u2208 {1, ...,m+1}, for each directed edge (vi, ve) \u2208 \u00c8, add (\u00acXi,j\u22121 \u2228 Xi,jVxl,j) to F.\n\u2022 For even j \u2208 {1, ..., m + 1}, for each bidirected edge {vi, ve} \u2208 E, add both clauses (\u00acXi,j\u22121 V Xi,j V \u00acxl,j) and (\u00acxl,j\u22121 V Xl,j V \u00acXi,j) to F.\n\u2022 Finally, at step m + 2, add clauses \u00acXi,m+1 to the expression F for every i \u2208 {1, ..., m}.\nTheorem 1. The 3-SAT formula F constructed by the procedure above given G and S has a satisfying solution {x;} where x1,0 = 0 for i \u2208 Z \u2286 {1, . . .,m} and x1,0 = 1 for i \u2208 {1, ...,m}\\I if and only if I intersects every hedge formed for S in G; i.e., I is a feasible solution to the optimization in Eq. (2).\nThe proofs of all our results appear in Appendix C. The first corollary of Theorem 1 is that the SAT formula is always satisfiable, for instance by setting 2,0 = 0 for every i \u2208 {1, ..., m}. The second (and more important) corollary is that the optimal solution to Eq. (2) corresponds to the satisfying assignment for the SAT formula F that minimizes\n\n\u2211^{m}_{i=1}(1 \u2013 x_{i,0})C(v_i).\nThis suggests that the problem in Eq. (2) can be reformulated as a weighted partial MAX-SAT (WPMAX- SAT) problem. WPMAX-SAT is a generalization of the MAX-SAT problem, where the clauses are partitioned into hard and soft clauses, and each soft clause is assigned a weight. The goal is to maximize the aggregate weight of the satisfied soft clauses while satisfying all of the hard ones.\nTo construct the WPMAX-SAT instance, we simply define all clauses in Fas hard constraints, and add a soft clause xi,o with weight C(vi) for every i \u2208 {1, ..., m}. The former ensures that the assignment corresponds to a feasible solution of Eq. (2), while the latter ensures that the objective in Eq. (3) is minimized - which, consequently, minimizes the cost of the corresponding intervention."}, {"title": "4 Minimum-cost intervention design for adjustment criterion", "content": "A special case of identifying interventional distributions is identification through adjusting for confounders. A set ZC V is a valid adjustment set for Px (Y) if Px (Y) is identified as\nPx(Y) = \\mathbb{E}_Z [P(Y | X, Z)],\nwhere the expectation w.r.t. P(Z). Adjustment sets have received extensive attention in the literature because of the straightforward form of the identification formula (Eq. 4) and the intuitive interpretation: Z is the set of confounders that we need to adjust for to identify the effect of interest. The simple form of Eq. (4) has the added desirable property that its sample efficiency and asymptotic behavior are easy to analyze [Witte et al., 2020, Rotnitzky and Smucler, 2020, Henckel et al., 2022]. A complete graphical criterion for adjustment sets was given by Shpitser et al. [2010]. As an example, when all parents of X (i.e., Pa(X)) are observable, they form a valid adjustment set. However, in the presence of unmeasured confounding, no valid adjustment sets may exist. Below, we generalize the notion of adjustment sets to the interventional setting."}, {"title": "5 Experiments", "content": "In this section, we present numerical experiments that showcase the empirical performance and time efficiency of our proposed exact and heuristic algorithms. A comprehensive set of numerical experiments analyzing the impact of various problem parameters on the performance of these algorithms, along with the complete implementation details, is provided in Appendix A. We first compare the time efficiency of our exact algorithms: WPMAX-SAT and ILP, with the exact algorithm of Akbari et al. [2022]. Then, we present results pertaining to performance of our heuristic algorithm. All experiments, coded in Python, were conducted on a machine equipped two Intel Xeon E5-2680 v3 CPUs, 256GB of RAM, and running Ubuntu 20.04.3 LTS.\nResults on exact algorithms. We compare the performance of the WPMAX-SAT formulation, the ILP formulation, and Algorithm 2 of Akbari et al. [2022], called Minimal Hedge Solver (MHS) from hereon. We used the RC2 algorithm [Ignatiev et al., 2019], and the Gurobi solver [Gurobi Optimization, LLC, 2023], to solve the WPMAX-SAT problem, and the ILP, respectively. We ran each algorithm for solving the MCID problem on 100 randomly generated Erdos-Renyi [Erdos and Renyi, 1960] ADMG"}, {"title": "6 Conclusion", "content": "We presented novel formulations and efficient algorithms for the MCID problem, offering substantial improvements over existing methods. Our work on designing minimum-cost experiments for obtaining valid adjustment sets demonstrates both practical and theoretical advancements. We highlighted the superior performance of our proposed methods through extensive numerical experiments. We envision designing efficient approximation algorithms for MCID as future work."}, {"title": "A.1 Implementation details", "content": "Our codebase is implemented fully in Python. We use the PySAT library for formulating and solving the WPMAX-SAT problem, and the PuLP library for formulating and solving the ILP problem.\nSolving the WPMAX-SAT problem. There are several algorithms to solve the WPMAX-SAT instance to optimality. These algorithms include RC2 [Ignatiev et al., 2019] and OLL [Morgado et al., 2014], both of which are core-based algorithms that utilize unsatisfiable cores to iteratively refine the solution. In this context, a \"core\" refers to an unsatisfiable subset of clauses within the CNF formula that cannot be satisfied simultaneously under any assignment. These algorithms relax the unsatisfiable soft clauses in the core by adding relaxation variables and enforce cardinality constraints on these variables. By strategically increasing the bounds on these cardinality constraints or modifying the weights of soft clauses based on the cores identified, the algorithms efficiently reduce the search space and converge on the maximum weighted set of satisfiable clauses, thereby solving the WPMAX-SAT problem optimally.\nSolving the ILP problem. Similarly, with the ILP formulation of the MCID problem presented in Section 3, we can utilize exact algorithms designed for solving ILP problems to find an optimal solution. ILP solvers work by formulating the problem with linear inequalities as constraints and integer variables that need to be optimized. Popular ILP solvers include CPLEX [IBM Corporation, 2023], Gurobi [Gurobi Optimization, LLC, 2023], and the open-source solver CBC [Forrest and Lougee-Heimer, 2023]. The latter is a branch-and-cut-based solver, and cutting plane methods to explore feasible integer solutions systematically while pruning the search space based on bounds calculated during the solving process. We use the Gurobi solver in our experiments."}, {"title": "C Missing Proofs", "content": "C.1 Results of Section 3\nTheorem 1. The 3-SAT formula F constructed by the procedure above given G and S has a satisfying solution {x,j} where x1,0 = 0 for i\u2208I\u2286 {1,...,m} and x0 = 1 for i \u2208 {1,...,m}\\I if and only if I intersects every hedge formed for S in G; i.e., I is a feasible solution to the optimization in Eq. (2).\nProof. Proof of 'if:' Suppose I hits every hedge formed for S. We construct a satisfying solution for the SAT formula as follows. We begin with xi,o:\nx_{i,0}=\\begin{cases} 0;& \\text{if }i\\in I\\\\ 1;& \\text{o.w.} \\end{cases}\nFor every j\u2208 {1, ..., m + 1}, define Hj = {i : Xi,j\u22121 = 1}. Then x\u00b8\u00a1 for j \u2208 {1, ..., m + 1} is chosen recursively as below.\n\u2022 Odd j: x,j = 1 if i \u2208 Hj and vi has a directed path to S in G[Hj], and x,j = 0 otherwise.\n\u2022 Even j: x = 1 if i \u2208 Hj and vi has a bidirected path to S in G[Hj], and x,j = 0 otherwise.\nNext, we prove that {x} as defined above satisfies F. We consider the three types of clauses in F separately:\n\u2022 For odd j \u2208 {1, ..., m + 1}, the clause (Xi,j\u22121 \u2228 Xi,j \u2228 \u00acxl,j) corresponds to the directed edge (vi,ve) \u2208 E: if either 2-1 0 or x,j = 0, then this clause is trivially satisfied. So suppose xj-1 = 1, and xx,j = 1, which implies by construction that x,j\u22121 = 1. Therefore, i, l \u2208 Hj. Further, since x = 1, ve has a directed path to S in G[Hj]. Then vi has a directed path to S in G[Hj] because of the edge (vi,ve) \u2208 \u1eba. By the construction above, = 1, which satisfies the clause.\n\u2022 For even j \u2208 {1, ..., m + 1}, the clause (\u00acXi,j\u22121 \u2228 Xi,j \u2228 \u00acxl,j) corresponds to the bidirected edge {Vi, ve} \u2208 E: E: if either x-1 = 0 or 0, then this clause is trivially satisfied. So suppose"}]}