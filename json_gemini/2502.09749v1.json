{"title": "Vote-Tree-Planner: Optimizing Execution Order in LLM-based Task Planning Pipeline via Voting", "authors": ["Chaoyuan Zhang", "Zhaowei Li", "Wentao Yuan"], "abstract": "Integrating large language models (LLMs) into closed-loop robotic task planning has become increasingly popular within embodied artificial intelligence. Previous efforts mainly focused on leveraging the strong reasoning abilities of LLMs to enhance task planning performance while often overlooking task planning efficiency and executability due to repetitive queries to LLMs. This paper addresses the synergy between LLMs and task planning systems, aiming to minimize redundancy while enhancing planning effectiveness. Specifically, building upon Prog-Prompt and the high-level concept of Tree-Planner, we propose Vote-Tree-Planner. This sampling strategy utilizes votes to guide plan traversal during the decision-making process. Our approach is motivated by a straightforward observation: assigning weights to agents during decision-making enables the evaluation of critical paths before execution. With this simple vote-tree construction, our method further improves the success rate and reduces the number of queries to LLMs. The experimental results highlight that our Vote-Tree-Planner demonstrates greater stability and shows a higher average success rate and goal condition recall on the unseen dataset compared with previous baseline methods. These findings underscore the potential of the Vote-Tree-Planner to enhance planning accuracy, reliability, and efficiency in LLM-based planning systems.", "sections": [{"title": "I. INTRODUCTION", "content": "According to Kaelbling and Lozano-P\u00e9rez [12], task planning is a crucial area in robotics, focusing on designing systems that construct sequences of mid-level actions to enable robots to perform complex high-level tasks. Effective task planning involves considering various factors, including robot capabilities, environmental variables, and potential constraints or uncertainties. A significant trend in this field, as highlighted by Huang et al. [10] and Song et al. [18], is the use of Large Language Models (LLMs) to directly generate robotic actions, marking a departure from traditional methods that depend on predefined domains, such as those proposed by Eysenbach et al. [6] and Xu et al. [24].\nThe application of LLMs in planning has garnered considerable attention within the robotics community, motivated by both the demonstrated capabilities of Al systems to reason about complex scenarios and the demand from downstream applications, such as goal-driven robotics [10] and intelligent planning assistants [14]. The most common approach involves employing LLMs as planners to generate action sequences leading to predefined goal states [19, 22]. However, despite its broad applicability, this LLM-based approach faces limitations, especially in text-simulated environments where it often underperforms and lacks the interpretability offered by symbolic planning methods that generate plans from formal environment representations.\nTo address the issue of interpretability, Singh et al. [17] introduced Prog-Prompt, a new prompting mechanism that leverages the logistic-rich nature of programming and LLMs' extensive knowledge of online code bases to enhance the interpretability of environmental textual representations. Although Prog-Prompt has significantly improved interpretability, it still faces challenges, such as repetitive commands and misinterpretations of textual representations, and offers limited options for correcting unsuccessful executions. Recent efforts by Hu et al. [9] have attempted to resolve these issues by employing a tree-like structure to aggregate generated plans, enhancing the execution process through an LLM-based model. Nonetheless, this approach reintroduces interpretability challenges as it does not utilize a programming language-based prompting mechanism. Additionally, our experiments have shown that simply interacting with the environment to determine the success of an execution command can yield results comparable to those obtained by providing the LLM with continuous observations at each command.\nIn this paper, we introduce the Vote-Tree-Planner, a novel planning mechanism that combines the strengths of Prog-Prompt and the high-level concept of Tree-Planner to enhance the executability and reliability of plans generated by LLMs. Our approach employs a planning tree that adapts to unexpected situations and ensures consistent task execution. Experimental results demonstrate significant improvements in plan generation accuracy, reliability, and efficiency, underscoring the potential of Vote-Tree-Planner to advance the field of mid-level robotic task planning."}, {"title": "II. RELATED WORK", "content": "Task Planning is a crucial process in robotics, where robots generate a sequence of actions to complete tasks within specific environments [12]. Traditionally, Task Planning relies on heuristics and searches within predefined domains [7, 11], with some studies exploring representation learning, hierarchical learning, and other methodologies [6, 23, 25]. Recently, the development of Large Language Models [3, 4] (LLMs) has initiated a shift towards leveraging these models to directly"}, {"title": "III. PROBLEM DEFINITION", "content": "Given a high-level instruction such as \u201cMicrowave Salmon\", our objective is to enable a robot to decompose this instruction into several intermediate commands, each representing a combination of predefined actions and objects. This decomposition process is designed to translate abstract commands into actionable sequences that the robot can execute effectively. We formalize the problem as the tuple $(I, S, A, O, g, i)$, where I represents a high-level instruction that describes a task the agent must complete, S is a set of states each describing the environment's state, A is a set of actions available to the agent to interact with the environment and manipulate objects, O is a set of objects within the environment, the relationships among which can be altered by actions $a \\in A$, and g and i are specific states in S representing the goal state and the initial state, respectively. This formulation captures the dynamic interactions between the agent and its environment, crucial for understanding and executing the given tasks effectively."}, {"title": "IV. PROPOSED METHOD: VOTE-TREE-PLANNER", "content": "To enable a robot to execute an abstract high-level instruction like \u201cMicrowave Salmon\", this instruction must be converted into a plan composed of several executable, mid-level commands. We formalize our Vote-Tree-Planner as a planning sampling process:\n$Vote\\_Tree\\_Planner(I, A, O) = {a_1(o_1),...,a_N(o_N)}$,\nwhere each $a_i \\in A$ and $o_z \\in O, \\forall i \\in {1, . . ., N}$.\nWe formulate the entire plan sampling process as the following stages, as shown in Figure 1. 1) Prog-Prompt Formatting: This stage entails converting the high-level instruction I, along with available actions A and objects O, into a structured Prog-Prompt [17] format. 2) Plan Generation and Unique Command Extraction: in this stage, a Large Language Model (LLM) is utilized to generate multiple potential plans using the formatted prompt. Then we extract unique commands in which each contains one action and one object. 3) Reordering Prompt Formatting and Sequence Generation: this stage entails the LLM reordering the extracted unique commands into a sequential plan that satisfies the initial instruction. 4) Planning Tree Construction: during the final stage, the new plans are structured into a tree-like format with votes in each node to enhance decision-making and execution efficiency. In the following sections, we will address each aforementioned component in detail."}, {"title": "A. Prog-Prompt Formatting", "content": "To enable a large language model (LLM) to transform a high-level instruction into a detailed action plan, we translate the instruction into the Prog-Prompt format as proposed by Singh et al. [17]. This translation process is formalized as\n$P_{prog} = FORMATTER\\_PROG(I)$,\nwhere $P_{prog}$ represents the Prog-Prompt format, which contains necessary information of the instruction I, available actions A, and accessible objects O. Figure 1 (Left) illustrates a typical example of a Prog-Prompt formatted prompt."}, {"title": "B. Plan Generation and Unique Command Extraction", "content": "The $P_{prog}$ from the last subsection is used to generate multiple executable plans. However, unlike traditional approaches [2, 9, 10, 13, 17], our methodology does not directly execute these generated plans at the first time. Instead, we extract unique commands and discard extraneous information. This strategy effectively narrows down the range of potential commands from all conceivable action-object combinations to only those that are specific and relevant, thereby reducing the risk of errors due to irrelevant or impractical combinations.\nDuring the unique command extracting stage, our objective is to identify a set of commands, $S = {C_1, C_2,...,C_N }$, each command $c_i$ containing one action $a \\in A$ as well as one or two associated objects $(o_1)$ $(o_1,o_2) \\in O$ depending on a. Each command in the set corresponds to commands ever appearing in the generated plans, focusing the selection process on combinations of elements from O and A that are most pertinent for completing the given task.\nAs illustrated in Figure 1 (Left), a Prog-Prompt formatted prompt is fed into an LLM, which independently generates multiple plans. These plans are processed by the unique command extractor, which isolates distinct commands from each plan. This methodology not only refines the choices of action-object combinations but also ensures comprehensive coverage of all necessary combinations for task completion.\nThe process can be formalized as follows:\n$COMMAND\\_EXTRACTOR(LLM(p_{prog}))$\n$= S = {C_1, C_2, ..., C_N}$,\nThis approach refines the action-object combinations and extracts the essential commands necessary for task completion, distinguishing our method from those that directly utilize the outputs of LLMs as executable plans."}, {"title": "C. Reordering Prompt Formatting and Sequence Generation", "content": "After obtaining the set S, our goal is to reorganize these commands into executable plans. As depicted in Figure 1 (Middle), within the Command Reordering and Tree Construction Block, we integrate the commands from S into a reordering prompt alongside the original instruction I. This section includes several examples that demonstrate how to achieve the given task by reorganizing the provided commands. This process is formalized as follows:\n$COMMAND\\_REORDER\\_PROMPT(S, I) = P_{reorder}$,\nwhere $P_{reorder}$ signifies the command reordering prompt. This prompt is subsequently input into a large language model (LLM) again. Through this process, denoted as:\n$LLM(P_{reorder}) = P = {P_1, P_2, ...,P_N}$,\nwhere $P$ represents the set of plans independently generated."}, {"title": "E. Execution", "content": "During the execution process, our objective is to consistently select the most optimal choice from the available actions. The variable Vote, stored in each node of our tree structure, serves as a metric to indicate the most favorable command based on the large language model's (LLM's) preferences. If an execution attempt fails, the Vote-Tree-Planner will shift focus to the subsequent child node with the second highest Vote. In scenarios where the executions of all children of a node fail, the planner will either terminate the process or, if feasible, backtrack to the last successful node that still possesses unexecuted child nodes. This dynamic decision-making process is depicted in Figure 2 and Algorithm 2."}, {"title": "V. EXPERIMENT", "content": "1) Environment: Our experiments are conducted in the Virtual Home [15, 16] environment, a robotic task simulation tool for common household tasks. Each Virtual Home scene includes hundreds of objects with individual properties and inter-object relationships. There are 28 different actions in the Virtual Home environment. Task-relevant goal conditions specify certain object states or predicates between objects, such as \"LIGHT is OFF\u201d for the action \"Turn Off Light\" and \"SALMON is in MICROWAVE\" for the action \"Put Salmon in Microwave\".\n2) Dataset: The dataset we used is consistent with Prog-Prompt [17] and Tree-Planner [9]. It contains 4 Virtual Home scenes and 35 unique Virtual Home tasks, each with a task name, goal conditions, and a goal plan. We generated the goal condition using the goal plan.\n3) Evaluation Metrics: Following the evaluation metrics in previous works [9, 17], we used success rate (SR), goal conditions recall (GCR), and executability (EXEC) as the main metrics to evaluate our pipeline performance. Specifically, the goal conditions are the set difference between final states and initial states during the execution. GCR is calculated by one minus the quotient of dividing the set difference between the ground truth final state goal conditions (g) and the achieved final state goal conditions (g') by the total number of ground truth final state goal conditions. In other words, GCR represents the percentage of goal conditions achieved. SR is the fraction of tasks that achieve all goal conditions. Each task achieves an SR of 1 only if its GCR equals 1. EXEC measures the percentage of commands that are executable in the Virtual Home environment. This metric measures how accurately the planner can generate commands. The higher the EXEC is, the higher portion of commands generated by the LLM are usable in the environment.\n4) Baselines: Zero-Shot Planner [10], Prog-Prompt [17], and Tree-Planner [9] are three prevalent OpenAI-API-based"}, {"title": "C. Qualitative Analysis", "content": "In this section, we discuss scenarios, where our approach demonstrated better handling of cases and reduced the length of the plans compared to those generated by Prog-Prompt [17].\n1) Failure cases in Prog-Prompt: For example, in the case \"Microwave Salmon\", the plans provided by Prog-Prompt and our method are shown on the left in Figure 3. Both of the methods contain some necessary commands in green and our method generates commands that are correct and more concise. For example, the plan from Prog-Prompt tries to find the microwave twice, while our method only tries to do it once. Also, the plan from Prog-Prompt tries to switch on the microwave when the microwave is still open, while our method handles this correctly.\n2) Redundancy cases in Prog-Prompt: For example, in the case \"Put Salmon In The Fridge\u201d, the plans provided by Prog-Prompt and our method are shown on the right in Figure 3. Both of the methods generate the necessary commands for getting the salmon and finding the fridge. However, the plan generated by Prog-Prompt has many more condition checks and even unnecessary commands. For example, the last three commands from Prog-Prompt intend to close the fridge, but instead of doing assert('fridge' is 'closed'), else: close('fridge'), the plan does assert('fridge' is 'opened'), else: open('fridge'), close('fridge'), hence the plan may result in redundant actions, i.e. opening the fridge then close it even if the fridge is originally closed. On the other hand, our method generates a more concise plan without redundant commands.\nFrom these examples, we can see that Prog-Prompt generates plans with more redundancy and has to query the LLM during each assertion phase, leading to significantly higher token consumption. In contrast, our method avoids querying the LLM and instead makes corrections based on the planning tree."}, {"title": "VI. CONCLUSION", "content": "In this paper, we introduced Vote-Tree-Planner, a novel strategy for task planning that leverages the capability of Large Language Models (LLMs). Vote-Tree-Planner effectively addresses the instability inherent in repetitive planning commands and reduces unnecessary assertion queries during plan execution. Our experiments conducted in the Virtual Home simulation environment indicated that our approach outperforms baseline methods, achieving new state-of-the-art performance with higher success rates, improved goal condition recall, and comparable executability. Furthermore, the plans generated by our strategy are notably shorter and exhibit less command repetition. We contend that Vote-Tree-Planner establishes a new benchmark in LLM-based task planning by improving both query efficiency and performance. We anticipate that our contributions will inspire continued research and development within this field.\nLimitations. Despite achieving state-of-the-art benchmarks, our method exhibits limitations. The efficacy of our pipeline remains heavily contingent upon the capabilities of Large Language Models (LLMs), and it is susceptible to variability due to the inherent randomness in LLM outputs, albeit with enhanced stability.\nFuture Work. We aim to refine the integration of LLMs within the planning correction process to ensure that plans remain relevant and adaptive to changes in the environment. Additionally, improving token efficiency remains a critical objective, which could lead to more streamlined interactions and reduced computational demands. These advancements will not only enhance the robustness of our method but also extend its applicability and effectiveness in dynamic settings. Last but not least, different LLM models possess different levels of capabilities. Comparing planners with different LLM backbones (i.e. Llama [21], GPT-4 [1], Gemini [20]) is also one of our future work directions."}]}