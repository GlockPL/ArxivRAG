{"title": "A Multimodal Adaptive Graph-based Intelligent Classification Model for Fake News", "authors": ["Junhao (Leo) Xu"], "abstract": "Numerous studies have been proposed to detect fake news focusing on multi-modalities based on machine and/or deep learning. However, studies focusing on graph-based structures using geometric deep learning are lacking. To address this challenge, we introduce the Multimodal Adaptive Graph-based Intelligent Classification (aptly referred to as MAGIC) for fake news detection. Specifically, the Encoder Representations from Transformers was used for text vectorization whilst ResNet50 was used for images. A comprehensive information interaction graph was built using the adaptive Graph Attention Network before classifying the multimodal input through the Softmax function. MAGIC was trained and tested on two fake news datasets, that is, Fakeddit (English) and Multimodal Fake News Detection (Chinese), with the model achieving an accuracy of 98.8% and 86.3%, respectively. Ablation experiments also revealed MAGIC to yield superior performance across both the datasets. Findings show that a graph-based deep learning adaptive model is effective in detecting multimodal fake news, surpassing state-of-the-art methods.", "sections": [{"title": "I. INTRODUCTION", "content": "The rapid evolution of Online Social Networks (OSNs) has revolutionized traditional communication methods, enabling content generation and dissemination to many users within mere seconds. As a result, OSNs have emerged as the predominant platforms for daily information sharing [1, 2]. However, as society relishes the conveniences of OSNs, the lag in robust network supervision and the absence of advanced technologies have paved the way for fake news to thrive [3]. Fake news, defined as any misleading, false, or incorrect information that is deliberately propagated, encompasses rumors, hoaxes, and conspiracy theories while relying on the dissemination of deceptive, unverified, and intentionally misleading content, thus posing an increasingly intricate challenge to societal norms and our everyday activities [4].\nResearch in fake news detection has experienced substantial advancements due to machine and deep learning and can be categorized into two types: modality-based and graph structure-based. Modality-based studies capture features such as semantic [5], emotion [6, 7], stance-based features [8], intent [9], and user profiles [10] from textual and visual input, and fuse them together using the conventional machine and/or deep learning algorithms [11, 12, 13, 14].\nOn the other hand, graph structure-based studies utilizing deep learning algorithms (i.e., Graph Neural Networks (GNN)) have shown remarkable success in natural language processing [15, 16], including detecting fake news on OSNs which can be attributed to the exponential growth of users, news content, and user interactions within these networks [10, 17]. OSNs evolve into complex graph structures [18, 19], hence posing challenges for the conventional machine and deep learning models [20].\nStudies integrating multimodal input with graph structure-based mechanisms are lacking. In fact, to the best of our knowledge only the work of Bi and colleagues [21] was found in which the authors proposed a heterogeneous attention network and tested their model using images and text from Weibo. To fill this gap, we introduce the Multimodal Adaptive Graph-based Intelligent Classification (herein referred to as MAGIC) a model that aims to detect fake news through textual (i.e., original posts as well as their accompanying comments) and visual contents using an adaptive residual deep-focus Graph Attention Network (GAN). Experiments with two datasets revealed our model to be superior.\nThe remainder of this paper is organized as follows: Section II delves into a comprehensive review of the related work, followed by the methodology in Section III. Section IV introduces our experimental details and evaluation methods. A detailed presentation of our experimental results and discussion is provided in Section V. Finally, Section VI offers a summary of the entire paper, outlining its limitations and future directions."}, {"title": "II. RELATED WORK", "content": "This section describes previous studies on fake news detection, highlighting the key gaps related to this study."}, {"title": "A. Single-modal fake news detection", "content": "In the early stages of fake news detection, numerous methodologies were deployed to gauge the veracity of information based solely on its textual content. Predominantly, these techniques revolved around the extraction of textual features at statistical or semantic levels [1, 22, 23, 24]. Most of the studies have utilized deep learning algorithms, for example, the Recurrent Neural Network-based Gatekeeper Behavior Model was proposed to detect fake news in OSNs, leveraging RNN's capacity to capture evolving contextual information from pertinent posts [25] whilst Ma and peers [26] developed a Dual-Channel Convolutional Neural Network (CNN) to detect fake news with attention pooling. On the other hand, Qi and peers [27] designed a CNN model to autonomously detect false content within images with promising results."}, {"title": "B. Multimodal fake news detection", "content": "With the emergence of multimodal forms of information on OSNs including text, videos, audios and images, researchers began to explore mechanisms to detect fake news using more than a single form of input [28, 29, 30]. For instance, a hybrid deep learning model was introduced to detect fake news based on text and images, whereby the authors proposed an Attention-based Multimodal Factorized Bilinear Pooling mechanism to maximize the correlation between the textual and visual features. It achieved an accuracy of 88.3% on a Twitter dataset [29]. Giachanou and peers [31] used the Visual Geometry Group Network (VGGNet) and the Bidi-rectional Encoder Representations from Transformers (BERT) to compute similarities between images and article headlines, and thus enhancing the effectiveness of fake news detection. Similarly, Qi and peers [30] proposed a novel entity-enhanced multimodal fusion framework, which simultaneously models cross-modal correlations to detect diverse multimodal fake news, achieving an accuracy of 90.4% on Weibo (i.e., Chinese dataset) and 97.5% on Politifact (i.e., English tweets). Finally, Jing and peers [28] introduced a Multimodal Progressive Fusion Network (MPFN) that captures representations at various levels for text and images and establishes strong connections between them. The authors reported an accuracy of 83.3% on a Twitter dataset."}, {"title": "C. Graph-structured fake news detection", "content": "Studies focusing on the graph structured mechanism to detect fake news are limited. For example, a geometric deep learning (GDL) model based on text and the structure of social media conversations was introduced for fake news detection by Tian and peers who proposed the Detection with User and Comment Networks (DUCK) [17]. DUCK underscores the role of comments in capturing user reactions to information, hence demonstrating that comment structures provide supplementary signals for detecting fake news. Yang and peers [16] introduced an innovative model known as the Graph Attention Capsule Network (GACN) on dynamic propagation structures that segments the fake news propagation structure, chronologically into multiple static graphs to capture the dynamic interaction features. GACN was reported to achieve accuracy rates of 88.9% and 90.0% on the Twitter15 and Twitter16 datasets, respectively. Studies integrating multimodal input with graph structure-based mechanisms are lacking. Only a single study was found in which the authors proposed a heterogeneous graph model that incorporates texts and images for fake news detection [21]. The authors modelled the information propagation network of Weibo as a heterogeneous graph containing various semantic information and achieved accuracy scores exceeding 92% on the Weibo2016 and Weibo2021 datasets."}, {"title": "III. METHODOLOGY", "content": "Figure 1 depicts the main pipeline of MAGIC encompassing four key stages: Multimodal social media posts (dataset), Embedding, Graph construction, Fusion and reasoning, and ultimately, Task learning."}, {"title": "A. Multimodal social media posts", "content": "Data will be collected from social media posts containing multimodal information such as text, image, and Comment relations, etc. Two fake news datasets in English and Chinese were sourced to train and test our proposed model. They are:\nFakeddit\u00b9: an English multimodal dataset containing text, comments, and images from Reddit (n = 3,127). The samples within this dataset are labeled using a 2-way (real, fake) and a 3-way classification (real, fake with true text, fake with false text) scheme. Modelling was performed using both these classifications.\nMultimodal Fake News Detection dataset\u00b2(MFND): a multimodal Chinese dataset containing text, comments, and images from Weibo (n = 2,953). The dataset is categorized into three distinct classes: uncertain, fake news, and real news.\nThe number of instances for each classified labels in the datasets are given in Table I, indicating the datasets to be balanced.\nObserving the two datasets, it becomes evident that the distribution of categories is relatively balanced, with no significant gaps between individual labels. This balanced distribution provides us with a more reliable and comprehensive foundation for accurate analysis and modeling. In the fake news dataset, each piece of news is composed of different modalities, namely posts, images, and comments. Taking a sample from the dataset, as illustrated in Figure 3, we observe a user posting a narrative along with an image, while numerous other users engage in comments. The semantic gap between these comments and the post is substantial, mostly comprising emotional opinions. Some users even verify the authenticity of the information, as evident in this example where a commenter claims to have seen related information on YouTube. Thus, we affirm the dataset's multimodal and semantic diversity."}, {"title": "B. Embedding", "content": "Fake news exhibit diverse modalities; thus, the study considered text (i.e., text and their respective comments) and images, hence two forms of embeddings were done, as follows:\n1) Textual embedding: BERT, a well-known transformer-based encoder that supports multiple languages including English and Chinese was used to convert the textual input into its vector representations [32]. Specifically, the BERT-base variant containing 12 transformer encoder blocks was used to extract the vector representations, whereby these encoders convert each tokenized word into its corresponding numerical vector, effectively mapping semantically related words to numerically proximate embeddings (see Figure 4). We loaded a pre-trained BERT model, inputted the text into the model, and set the final output embedding to 768 dimensions. The obtained embedding vector serves as a representation of the semantic encoding for the entire sentence:\n$S_n = BRET([w_n^1, w_n^2, ..., w_n^m])$,\nwhere m symbolizes the length of the word sequence, while n stands as an index delineating the ordinal position of the sentence in consideration. The 768-dimensional feature vector corresponding to the mth word within the nth sentence is represented by $w_n^m$. Furthermore, $S_n$ designates the feature vector of the nth sentence, as encoded by the BERT pre-trained model.\n2) Image embedding: ResNet50, which is a residual network was used to transform the images into their vector representations (Figure 6). ResNet50 is a 50-layer network architecture that uses the residual connections allowing information to be skipped over one or more layers in the network, hence allowing deep networks to extract low-level, mid-level, and high-level features from images while adapting to their depth [33]. We loaded a pre-trained ResNet50 model, removed the Softmax layer, and instead added a Multiple Layer Perceptron (MLP) layer to map the extracted image vector features to the same dimension (i.e., 768 dimension) as the text features mentioned above. The image is eventually represented as:\n$V_n = ReLU(MLP(ResNet50(x_n)))$,\nwhere $x_n$ designates the nth image. Relu represents the rectified linear unit, an activation function ubiquitously utilized in neural architectures. Post extraction of salient features from the image via the ResNet-50 paradigm, the combined operations of MLP and Relu ensure the alignment of these features into a vectorial space that shares the same dimensionality with that of the textual vector, denoted herein as V."}, {"title": "C. Graph construction", "content": "As shown in Figure 1, the output of these embedding techniques is then fed into the graph construction phase, in which each sample is formulated into an information graph pertaining to its associated message as shown in Figure 6. Specifically, the adjacency matrix was used to define the connected edges based on the vector representations for the textual (including content of the posts and comments) and visual content (different colors in the graph represent different types of vector representations). This results in the creation of the multimodal interaction graph, which captures the essence of interactions among these three elements. The mathematical formula is defined as follows:\n$G = (P, V, C, A)$,\nwhere P stands for the embedded representation of the content of the posts, while V signifies the embedded depiction of the associated image. C designates the embedded comments furnished by participants in response to the posts. The adjacency matrix is represented by A, encapsulating the structural relationships among these entities. The multimodal interaction graph, capturing the essence of interplays among these elements, is denoted as G."}, {"title": "D. Fusion and reasoning", "content": "Upon obtaining the multimodal graph defined by Formula 3, it is imperative to integrate and infer from it using a graph neural network. The adaptive residual network was adapted to fuse the multimodal input as shown in Figure 7. The number of layers was set as a variable parameter, allowing the model to automatically search within a specified range of layers and save the results with the optimal number of layers. This network architecture establishes residual graph connections and the formulation for this process is delineated by the following equation:\n$G(x)_1 = F(x)$\n$G(x)_n = G(x)_{n-1}+F(G(x)_{n-1})$\nwhere n denotes the number of residual layers, $G(x)_n$ signifies the feature representation of the entire graph after n layers, and F represents the mapping function of the residual block [33]. The Graph Attention Network, which is a variant of GNNs, plays a critical role in enhancing graph-based data processing by employing an attention mechanism to aggregate node features and adaptively extract contextually relevant information [34]. The attention coefficients are first calculated through a multi-head attention mechanism to represent the similarity scores between the central node and its neighboring node. These coefficients are used to update the information of the neighboring nodes as well as the node itself. This adaptive attention mechanism contributes to the comprehension of intricate modality relationships and structural patterns within graphs, as defined below:\n$e_{ij} = a(\\overrightarrow{h_i}, \\overrightarrow{h_j})$,\n$\\alpha_{ij} = \\frac{exp(e_{ij})}{\\sum_{k \\in N_i} exp(e_{ik})}$,\nwhere h represents node features, a is a parameter vector subject to learning, and e, denotes unnormalized coefficients for pairs of nodes i and j,based on their respective features. The coefficient $\\alpha_{ij}$ signifies the attention weight assigned between nodes i and j,thereby reflecting the influence of graph structure. This attention mechanism restricts the focus of node i to its local neighborhood, denoted by $j \\in N_i$.\nIn order to enhance the stability of the self-attention learning process, the utilization of multi-head attention proves to be advantageous. This entails independently replicating the operations of this layer K times (each copy possessing distinct parameters), and subsequently aggregating the outputs through feature concatenation or addition:\n$h^k = \\sigma(\\sum_{j \\in N_i} \\alpha_{ij}^k W^k h_j)$,\nwhere $\\alpha^k$ signifies the attention coefficients computed by the k-th iteration, while $W^k$ denotes the weight matrix that delineates the linear transformation inherent to the k-th iteration. $N_i$ represents the set of neighboring nodes for node i. Here, $\\sigma$ represents an activation function, such as the Leaky ReLU. $h$ denotes the features after aggregating updates from neighboring nodes and the node itself.\nIn the context of fake mews detection, not all textual comments and images are equally significant, hence the model further refines and consolidates the most crucial and valuable"}, {"title": "E. Task modelling", "content": "Finally, Softmax was used to classify the fake news classification. This step involves utilizing a loss function that steers the model towards minimizing the cross-entropy erron associated with a specific training instance, considering the ground-truth label y\n$p = softmax(W_c X + b_c)$,\n$L = - \\sum ylog p$,\nwhere $W_c$ and $b_c$ represent the parameters in the fully connected layer (utilized for mapping the final dimensions to the category vector), while p represents the category probabilities obtained after applying the softmax function.The datasets were partitioned into 80-20 (i.e., training-testing). Within the training set, a further division is made into 80% actual training data and 20% validation data. The 80% actual training data is employed for the iterative parameter updates through backpropagation, while model evaluation is conducted on the 20% validation data. Ultimately, the set of model parameters that performs best on the validation set is saved for the final evaluation on the test set."}, {"title": "IV. EXPERIMENTS AND EVALUATIONS", "content": "In this section, we will elaborate on the specific equipment and software employed in the experiments. Additionally, we will delve into the detailed configuration of training parameters for our model, compare it with the chosen baseline, and present the evaluation metrics employed."}, {"title": "A. Experimental setups", "content": "All the training and testing were done using Python, utilizing various libraries available such as sklearn, pytorch and Pyg, with a GPU NVIDIA Tesla P100. Learning rate and batch size are set to 0.002 and 128, respectively. To optimize model parameters effectively, the Adam optimizer is also utilized. We experimented several models as outlined below:\n-BERT [35]: Only textual original posts were used as input for fake news classification. In this study, researchers achieved remarkable results in detecting fake news by fine-tuning the pre-trained BERT model.\n-BERT+CNN [36]: The model takes into consideration all the features encoded by BERT for sentences and feeds the resultant output into a CNN layer, effectively enabling the detection of fake news in textual content.\n-BERT+LSTM [37]: By incorporating BERT's comprehensive feature extractions and funneling the output through an LSTM layer, this architecture significantly boosts the model's capacity to identify fake news by capturing sequential patterns and contextual intricacies in the text.\n-BERT+BILSTM [36]: This model leverages the entirety of features encoded by BERT for sentence comprehension and subsequently directs the resulting output to a Bidirectional Long Short-Term Memory (BiLSTM) layer. This design is aimed at effectively capturing temporal dependencies and contextual nuances within the text, thereby enhancing the capability to detect fake news in the given textual content.\n-BERT+CNN+BiLSTM [38]: This model utilizes CNN-BILSTM to capture the local, global, and temporal meanings of sentences, achieving excellent performance.\n-ResNet50 [39]: Only the images were used as input for fake news classification. Utilizing pre-trained ResNet for enhanced fake news image representation has proven to be effective in capturing meaningful features from images associated with disinformation.\n-BERT-GNN [40]: Graph-based mechanism using the textual input (original post and comments).\nIt is to note that a combination of ResNet and GNN is not feasible as each news article only has one or no image (i.e., one node, no image encoded as an all-0 feature node), hence it is not possible to form a graph. All the models were trained and tested on both the datasets, to assess their robustness in handling different languages. The experiments above were conducted to assess the model's performance based on single modal input, using the conventional approach. These act as our baseline models.\nWe also conducted ablation experiments to validate the effectiveness of each module within our model. This involved systematically analyzing and selectively removing components to assess their individual contributions to the overall performance."}, {"title": "B. Evaluation", "content": "As this is a classification problem, the standard metrics were used to assess the effectiveness of MAGIC. The performance of the model can be illustrated using a confusion matrix, as depicted in Table II. From the confusion matrix, metrics like accuracy, precision, recall and F1-score can be computed. Accuracy measures the proportion of correctly classified instances among all instances.\n$Acc = \\frac{(True Positives + True Negatives)}{Total Samples}$\nPrecision represents the proportion of correctly predicted positive instances out of all instances predicted as positive.\n$Pre = \\frac{True Positives}{(True Positives + False Positives)}$\nRecall indicates the proportion of correctly predicted positive instances out of all actual positive instances.\n$Rec = \\frac{True Positives}{(True Positives + False Negatives)}$\nF1-score combines precision and recall into a single value, providing a balanced measure of a model's accuracy in identifying both positive and negative instances\n$F1 = 2 * \\frac{(Precision * Recall)}{(Precision + Recall)}$\nIn this study, the aforementioned four indicators are reported in the performance evaluation. Our MAGIC model is compared to baseline models reported in other relevant studies and, similarly, conducts ablation experiments to validate the effectiveness of its modules. To ensure a fair comparison with other models, uniform training strategies and parameters are employed in this research."}, {"title": "V. RESULTS AND DISCUSSION", "content": "The overall results for the fake news classification for MAGIC are presented in this section, followed by the ablation experiments. Table III illustrates the performance comparison between MAGIC and the baseline models across the two datasets, whilst Table IV provides the confusion matrix."}, {"title": "A. Performance scores for MAGIC", "content": "1) Baselines Comparison: By comparing with baseline models, we can also identify certain patterns. For instance, when considering only the performance of baseline models, text-based methods generally outperform visual-based methods. This phenomenon holds true for both Chinese and English datasets. This observation underscores the importance of text and visual modalities in the field of fake news detection. Importantly, it highlights that text, with its richer discriminative attributes, is a more favorable factor for enhancing detection capabilities."}, {"title": "B. Performance scores for the ablation study", "content": "To further assess MAGIC's performance, an ablation study was performed by systematically decomposing the model into simplified variants. This meticulous analysis aimed to identify and understand the specific components or features within the MAGIC model that contribute significantly to its overall effectiveness. Specifically, we (i) used our MAGIC model, but removes the visual-feature (excluded images), and (ii) omitted the multi-head attention mechanism (i.e., replacing GAN module in Figure 7 with a regular GNN). Performance scores in Figure 8 illustrates MAGIC to consistently outperform the rest of the models, albeit insignificantly in some of the instances. This shows the importance of each of the modules/layers added into our proposed graph-based fake news classification model.\nIt has been observed that the direct removal of the fusion layer results in a direct decrease in performance (i.e., MAGIC without fusion). The exclusion of image content from MAGIC showed a decline in classification performance for accuracy, precision, recall and F scores, that is, a decrease by 0.48%, 0.63%, 0.51%, and 0.57%, respectively compared to MAGIC on the Fakeddit 2-way dataset. Similar declining patterns were observed for the 3-way Fakeddit and MFND datasets. This demonstrates the importance of simultaneously integrating modal and structural features for fake news classification [21]. Similar observations were also noted for the other models, hence indicating images and their features to contributes to improving fake news classification, a finding that well concurs with previous studies such as [31]. Findings in Figure 8 affirms the importance of integrating multimodal input (i.e., text and images) incorporating the multi-head attention mechanism that helps to enhance the stability and performance of fake news detection models, regardless of the languages [16]."}, {"title": "VI. CONCLUSION", "content": "This study proposed a Multimodal Adaptive Graph-based Intelligent Classification Model, MAGIC, that was trained and tested on two datasets (English and Chinese). Original posts, their accompanying comments and images were incorporated as part of MAGIC, hence enabling the formation of interaction graphs. MAGIC not only simplifies the intricate process of graph creation but also accomplishes dual objectives within a single network: modal fusion and capturing comment structures. Experiments in various scenarios including the ablation experiments revealed MAGIC to consistently outperform the baseline models."}, {"title": "A. Limitations", "content": "The study is not without its limitations: first, it relies on extracting features from different modalities through embedding. Therefore, the quality of the embedding model will have a significant impact on the results. Future studies could explore other embedding techniques to improve the quality of feature extraction based on the diverse modalities. Second, although the pre-trained transfer learning models were adapted, future studies could replicate MAGIC on larger datasets and expand its applicability to other languages, including low-resourced ones, given the extensive and diverse linguistic content present on social media, spanning various languages, nuances, and dialects. Finally, MAGIC was developed to handle text and images only, therefore the model can be expanded to handle videos and audios using other multimodal fusion techniques."}, {"title": "B. Future Work", "content": "Fake news detection is a field that requires continuous iteration of data processing techniques and models, leaving ample room for future research.\nFor instance, in our current research, the datasets include only posts, images, and comments, predominantly sourced from Twitter and Weibo. However, emerging social media platforms with enhanced dissemination capabilities, such as TikTok, have come into play. TikTok boasts robust recommendation algorithms, facilitating not only faster but also more precise targeting of user demographics. The mode of information propagation on TikTok extends beyond mere text and images, encompassing richer multimodal content like videos and audio. Furthermore, its recommendation algorithms are intricately tied to users' profiles, behaviors, and the entirety of their social networks, presenting new challenges in the detection of fake news.\nAdditionally, with the skyrocketing popularity of generative large language models like ChatGPT, an increasing amount of information is becoming more susceptible to manipulation and fabrication. Many instances of false information are directly generated by large language models (LLMs), while manipulated images are produced by image generation models like midjourney. This poses additional challenges to current efforts in combating fake news.\nTherefore, future work can be expanded in the following directions: (i) collecting fake news datasets that encompass a more diverse range of modalities; (ii) exploring and developing more robust and versatile detection models capable of handling different modalities; (iii) incorporating the generative capabilities of large pre-trained language models (LLMs) to extend the fake news classification task into an end-to-end debunking system. This system not only discerns the veracity of fake news but also provides users with content generated by LLMs to enhance the interpretability of the information. For instance, for verified information, the system could provide the source, for fake information, it could offer refutations, and for uncertain information, it could guide users toward further investigation."}]}