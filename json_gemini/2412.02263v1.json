{"title": "Connecting Large Language Models with Blockchain: Advancing the Evolution of Smart Contracts from Automation to Intelligence", "authors": ["Youquan Xian", "Xueying Zeng", "Duancheng Xuan", "Danping Yang", "Chunpei Li", "Peng Fan", "Peng Liu"], "abstract": "Blockchain smart contracts have catalyzed the development of decentralized applications across various domains, including decentralized finance. However, due to constraints in computational resources and the prevalence of data silos, current smart contracts face significant challenges in fully leveraging the powerful capabilities of Large Language Models (LLMs) for tasks such as intelligent analysis and reasoning. To address this gap, this paper proposes and implements a universal framework for integrating LLMs with blockchain data, C-LLM, effectively overcoming the interoperability barriers between blockchain and LLMs. By combining semantic relatedness with truth discovery methods, we introduce an innovative data aggregation approach, SenteTruth, which significantly enhances the accuracy and trustworthiness of data generated by LLMs. To validate the framework's effectiveness, we construct a dataset consisting of three types of questions, capturing Q&A interactions between 10 oracle nodes and 5 LLM models. Experimental results demonstrate that, even with 40% malicious nodes, the proposed solution improves data accuracy by an average of 17.74% compared to the optimal baseline. This research not only provides an innovative solution for the intelligent enhancement of smart contracts but also highlights the potential for deep integration between LLMs and blockchain technology, paving the way for more intelligent and complex applications of smart contracts in the future.", "sections": [{"title": "I. INTRODUCTION", "content": "Blockchain smart contracts have been widely applied in fields such as decentralized finance [1], supply chain management [2], and energy management [3], enabling the automatic execution of predefined rules to ensure transparency and security in transactions. However, current smart contracts remain in the automation stage, lacking intelligent decision-making capabilities, particularly in terms of semantic understanding and reasoning, which makes them ill-equipped to handle complex and dynamically changing scenarios.\nAlthough blockchain technology offers unique advantages in terms of decentralization and transparency, its limited computational and storage resources hinder its ability to support high-performance Artificial Intelligence (AI) tasks, such as Large Language Models (LLMs). Moreover, the issue of data silos prevents seamless integration between blockchain and existing LLM services [4], [5], further restricting the intelligent evolution of smart contracts. Despite the powerful capabilities of LLMs in areas such as intelligent analysis, reasoning, intelligent assistants [6], code understanding [7], and the detection and repair of smart contract vulnerabilities [8], [9], the data barriers between blockchain and LLMs remain a critical bottleneck for the intelligent enhancement of smart contracts. Therefore, as shown in Fig. 1, breaking through the limitations of data silos and resolving the data interaction challenges between blockchain and LLMs are essential steps toward unlocking the full potential of smart contract intelligence. Such advancements will not only enhance the decision-making capabilities of smart contracts but also drive the broader adoption of blockchain in more complex, dynamic application scenarios.\nTo address this challenge, Xu et al. [10] proposed an initial concept of connecting blockchain and LLMs via oracles. As a trusted data middleware, an oracle ensures the integrity and trustworthiness of the data transmitted to the blockchain by leveraging technologies such as voting games [11]\u2013[13], trusted execution environments [14]\u2013[16], and threshold signatures [17]\u2013[19]. These technologies help prevent data tampering during transmission, thus ensuring the authenticity and reliability of the data. However, as illustrated in Fig. 2, we found that during the interaction between the oracle and the"}, {"title": "II. RELATED WORK", "content": "To address the issue of data trustworthiness in oracle systems, Augur [11] and Astraea [12] employ a betting mechanism where multiple oracle nodes stake on the authenticity of the data, using a value-based game theory approach to incentivize honest behavior. Deepthought [13], on the other hand, combines voting and reputation mechanisms to reduce the risk of corruption caused by adversarial nodes or inactive voters, thereby improving data reliability. In another approach, Zhang et al. [14] and Liu et al. [15] integrated Trusted Execution Environment (TEE) technology with oracles to ensure the integrity of the data. Additionally, threshold signatures [19], [29] and improved TLS protocols, such as TLS-N [30], [31], utilize cryptographic algorithms to guarantee data reliability, offering higher security compared to other methods. However, the implicit assumption of all these solutions is that the data obtained by different nodes is consistent. If the data retrieved by nodes is inconsistent, achieving data consensus becomes a challenging task.\nTo improve data consistency before reaching consensus, Liu et al. [18] utilized a sliding window mechanism to enhance the centralization of IoT real-time data before consensus is achieved. Xian et al. [32] proposed the representative enhancement aggregation strategy REP-AG and access timing optimization strategy TIM-OPT to improve data consistency for oracle nodes when acquiring real-time data. In addition, selecting the median from the set of data obtained by nodes as the final answer is a common method for on-chain data consensus [23]\u2013[25]. For off-chain consensus, DAON [21] uses methods such as majority voting or averaging to eliminate data inconsistencies before consensus is reached. Xiao [26] and Xian [27] applied Truth Discovery (TD) [33] to weigh and aggregate numerical data from different nodes based on their trustworthiness. They also reverse-update trustworthiness according to data deviations, thus making the aggregated data approach the \"truth\". Furthermore, sharing trustworthiness allows honest nodes to reach consensus on heterogeneous"}, {"title": "III. DESIGN OF C-LLM", "content": "As introduced in Section I, C-LLM is a general-purpose data integration framework designed to provide trusted LLM data for blockchain, enabling secure interaction between the two. As shown in Fig. 3, it consists of the following four components:\n\nUser Contract: A smart contract, created and deployed by users within a blockchain network, is designed to automate and ensure the transparency of transactions and protocol execution. For example, in decentralized insurance applications, the smart contract automatically assesses claims based on predefined rules and executes payments without relying on traditional insurance companies as intermediaries. By leveraging smart contracts, insurance processes become transparent and immutable, significantly improving efficiency and reducing operational costs. In such scenarios, LLMs can be employed to automate document review, customer interaction, and intelligent reasoning in claims processing. These models can provide personalized insurance recommendations and claim suggestions, further enhancing the contract's intelligence.\nOracle Contract: A smart contract deployed on the blockchain is specifically designed to provide the necessary external data for the blockchain. Since blockchains cannot directly access off-chain information, oracle contracts act as intermediaries by acquiring external data (such as financial market prices, weather conditions, IoT sensor data, etc.), helping smart contracts make decisions. These contracts ensure that on-chain smart contracts can interact with real-world data, thus making the application of decentralized applications more extensive.\nOracle Network: A decentralized network comprising multiple independent oracle nodes is designed to ensure the accuracy, reliability, and tamper resistance of data. The oracle network acquires and verifies external data from various nodes, transmitting the consensus data to the smart contracts on the blockchain. Unlike a single oracle, an oracle network mitigates the risks of data provider centralization, thereby preventing malicious attacks or the injection of erroneous information. Decentralized oracle networks, such as Chainlink [22] and DOS Network [19], uphold data credibility through incentive mechanisms and consensus protocols. These networks are widely deployed in decentralized finance (DeFi), insurance, supply chain management, and other sectors.\nLarge Language Models (LLMs): Natural language processing models with vast numbers of parameters are capable of understanding and generating complex linguistic content. Common LLMs include OpenAI's ChatGPT\u00b9, Google's Gemini\u00b2, and Meta's Llama\u00b3. These models exhibit strong capabilities in tasks such as automated customer service, legal document review, medical diagnosis, and financial analysis. However, due to their large parameter sizes and complex training processes, LLMs require substantial computational resources and distributed computing platforms to operate efficiently."}, {"title": "A. System Flow", "content": "As shown in Fig. 3, the entire system process includes the following steps:\n\u2460 Event Request: When the user contract needs to rely on the intelligent capabilities of the LLM to process a task, it invokes the oracle contract interface to initiate a task request R. R contains information such as the task identifier I, the question Q, and the requested model M. Specifically, I is the unique identifier of the task, used to track the task's status and progress; Q is the question the user wants the LLM to answer or process, involving natural language processing, reasoning, and other tasks; M specifies the LLM model to be used, such as ChatGPT-4 or Llama-8b, to ensure the task is effectively completed.\n\u2461 Event Writing: After receiving the event request R, the oracle contract writes the corresponding event record E into the blockchain and broadcasts it to the oracle network. The oracle contract typically also includes functions like node registration and payment, which are not discussed here.\n\u2462 Event Listening: Nodes O\u2082 in the oracle network con- tinuously listen for blockchain data request events E to respond to the user contract's needs promptly.\n\u2463 LLM Request: When a node Oi detects event E, it triggers an API request to the corresponding model M as specified by the event and processes the returned data result Di. It is important to note that some malicious nodes may obtain incorrect results D at this stage, as detailed in Section III-B.\n\u2464 Data Broadcasting: Nodes in the oracle network exchange the data Di they have obtained to ensure data consistency. However, to prevent the \"Freeloading\" issue [22], nodes need to go through a two-round data exchange process (commit-reveal) to ensure the authenticity and integrity"}, {"title": "B. Adversary Model", "content": "Considering the structural and characteristic differences between the text data generated by LLMs and the numerical data handled by previous applications like DAON [21], we design three potential text data manipulation attacks based on the gaps in existing oracle research and an analysis of the potential risks associated with LLM-generated text data.\n1) Random Response: Nodes, due to lack of access to LLM APIs or to save on data access costs, may return a random, meaningless statement regardless of the query made.\n2) Model Substitution: Similar to the random response sce- nario, nodes may engage in model substitution due to the varying pricing of LLM APIs. They might opt to query a cheaper model for the same task, thereby profiting from the price difference.\n3) Incorrect Response: Malicious nodes can exploit prompt engineering techniques to intentionally elicit incorrect answers, thereby undermining the reliability of the oracle system [34].\nHowever, we must also assume that the number of malicious nodes in the system can not be more than half and not collusion, which is the basic assumption of system security."}, {"title": "C. SenteTruth", "content": "To address the issue of inconsistent data obtained by different nodes through LLM APIs and the potential data manipulation by malicious nodes in the oracle network, which may undermine the system's reliability, we propose a data aggregation scheme, SenteTruth, based on semantic relatedness and truth discovery techniques. This scheme analyzes the semantic relatedness of the data provided by different nodes, cross-validates it with node credibility, and mitigates the influence of malicious nodes, ensuring the reliability of the data.\nTo mitigate the impact of malicious content, we first assess the similarity of the data obtained by different nodes. We use the Sentence-BERT (SBERT) model, which maps text to a fixed-length vector space using a pre-trained BERT model [35]. These embedding vectors effectively capture sentence- level semantic information, overcoming the limitations of traditional word vector models in assessing semantic related- ness between sentences. Let the input text be represented as\nD = {D_1,D_2, ...,D_n}\nwhere $D_i$ denotes the text returned by node $O_i$.\n\\begin{equation} \\label{eq:1}\nV_i=SBERT(D_i)\n\\end{equation}\nLet $v_i$ represent the embedding vector of the answer $D_i$ generated by the SBERT model. In this manner, each answer $D_i$ is mapped to a fixed-length vector space, capturing its semantic information.\nOnce the text is encoded as vectors, we use cosine similarity to measure the relatedness between the data obtained by different nodes. Through this process, we can identify and filter out noise data that deviates significantly from the majority of the data, thereby reducing the impact of malicious nodes on the system's reliability.\n\\begin{equation} \\label{eq:2}\n\\varphi(v_i) = \\sum_{j=1,j\\neq i}^{n}\\frac{v_i \\cdot v_j}{||v_i||\\cdot||v_j||}\n\\end{equation}\nHowever, for some open questions, LLM responses may exhibit significant variability, which makes semantic relatedness- based measures insufficient to accurately reflect the truth of the data. Therefore, to improve the accuracy of these data assessments, we integrate truth discovery [33] into the process.\nFirst, truth discovery can be divided into two main stages: truth aggregation and credibility updating. In the truth aggregation stage, the goal is to synthesize an aggregated result that approximates the true value as closely as possible, based on the data provided by multiple nodes. Here, the truth refers to the data that reflects the majority consensus of the nodes and is free from tampering, even if the response is not entirely accurate in content. To enhance the accuracy of the aggregation, we treat the data provided by each node as a potential hypothesis and weight these hypotheses based on both semantic relatedness and the credibility of the nodes. The credibility of node Oi, denoted as Ci, reflects its historical performance. A higher credibility Ci indicates that the data provided by Oi in past tasks was more consistent with the data provided by the majority of nodes. When performing truth aggregation, we calculate the aggregated result by weighting both the credibility and the text similarity as follows:\n\\begin{equation} \\label{eq:3}\nD \\leftarrow argmax C_i\\cdot \\varphi(v_i)\n\\end{equation}\nIn the credibility updating stage, the credibility $C_i$ of a node can be updated based on the semantic relatedness between the data provided by the node and the aggregation result. Specifically, if the data provided by the node is similar to the aggregation result, the credibility of the node increases; otherwise, it decreases. The credibility update formula can be expressed as follows:\n\\begin{equation} \\label{eq:4}\nC_i \\leftarrow C_i + \\frac{C_i \\cdot \\varphi(v_i)}{\\sum_{i=1}^{n} C_i \\cdot \\varphi(v_i)}\n\\end{equation}\nThis improvement ensures that the truth discovery method can also effectively support text-based data returned by LLMs."}, {"title": "IV. PERFORMANCE EVALUATION", "content": "To validate the effectiveness of the proposed scheme, we constructed a local Ethereum environment based on Ganache\u2074, implemented smart contracts using Solidity, and facilitated communication between the oracle nodes and the blockchain through Web3.py. The oracle system includes a user contract, an oracle contract, and an oracle network composed of 10 oracle nodes. Additionally, to ensure the verifiability and generalizability of the experimental results, we designed a local dataset containing questions and answers posed to five large language models (ChatGPT-4o-mini, Gemini-1.5- flash, Llama3-8b, ChatGLM-4-flash, Hunyuan-lite) by 10 different nodes. We used default parameters and recorded their responses.\nConsidering that traditional aggregation methods are generally focused on numerical data and have limited effectiveness when dealing with text data, we established several baseline methods for text data aggregation for comparison. First, the classic majority voting method [21], [22] was used as the baseline aggregation strategy. Second, to evaluate the performance of text similarity-based aggregation, we introduced two commonly used text encoding methods: TF-IDF [36] and SBERT [35]. These two methods provide more precise support for calculating text similarity, thereby improving the accuracy of data aggregation.\nTo comprehensively evaluate the proposed aggregation method, we constructed three different types of datasets, each testing the performance of the aggregation algorithms from various perspectives: basic questions, complex scenarios, and specialized domains.\n1) Base Dataset (BASE): This dataset contains three types of questions, with 20 questions in each category, designed to evaluate the effectiveness of the aggregation methods across different question types:"}, {"title": "B. Research Questions (RQs)", "content": "In oracle systems interacting with large language models (LLMs), data inconsistency often arises, which not only affects the accuracy of the data but also complicates the detection of malicious behaviors. To address this issue, we designed a series of experiments aimed at analyzing the key factors affecting LLM response consistency and evaluating the effectiveness and practicality of the proposed method in improving data correctness.\nThese experiments aim to answer the following research questions (RQs):\n1) RQ1 - Problem Analysis: What factors contribute to the data inconsistency in LLM responses? This question aims to identify the key factors influencing LLM response consistency, providing a basis for the design of subsequent solutions.\n2) RQ2 - Performance Comparison: How does the proposed method perform in improving data correctness, and what advantages does it have compared to existing data aggregation methods? This question will evaluate the effectiveness of the proposed method in ensuring data Accuracy, with data Accuracy defined as the proportion of unaltered data in the final aggregated result.\n3) RQ3 - Effectiveness Analysis: Why does the proposed method effectively improve data correctness? This question aims to explore the underlying reasons for the effectiveness of the proposed method and analyze its mechanisms for enhancing data correctness.\n4) RQ4 - Usability Analysis: Are there any resource overheads in the proposed method that could hinder its practical application? This question will assess the usability and scalability of the proposed method."}, {"title": "C. RQ1 - Problem Analysis", "content": "As shown in Fig. 5, the impact of different question types on data consistency obtained by oracle nodes is illustrated. By comparing Fig. 5a and 5b, we observe that questions with a definitive answer exhibit higher data consistency compared to open-ended questions. Furthermore, the consistency variations"}, {"title": "D. RQ2 - Performance Comparison", "content": "Table I - III shows the data accuracy under 40% random answers, incorrect responses, and model substitution scenarios, for different aggregation methods. The results indicate that, compared to TF-IDF, SBERT generally provides higher data accuracy. This is mainly due to SBERT's advantage in semantic evaluation, which allows for more effective differentiation between different textual data. However, relying solely on sentence differentiation is still insufficient to ensure high data accuracy, and the reasons for this will be further analyzed in IV-E. Additionally, the widely used majority voting method in oracle systems performs poorly under such conditions. This is because majority voting relies on data consistency, and for models like ChatGPT and ChatGLM, which output with high randomness, the results of majority voting are unstable.\nIn Appendix A, we conducted the same tests on the MIX and PRO datasets, and the results were consistent with those observed in the BASE dataset, verifying the performance advantage and broad applicability of the proposed method."}, {"title": "E. RQ3 - Effectiveness Analysis", "content": "Fig. 8 illustrates the variation of key variables across different epochs in the BASE dataset. It can be observed that, at Epoch 0, the node weights are uniform; however, as the epoch progresses, the weights of the malicious nodes (Node 7-10) gradually decrease, indicating that SenteTruth performs effectively. However, as shown in Table III, when the TD method is applied to TF-IDF, the final accuracy declines further due to TF-IDF's limited discriminative power. This suggests that using the truth discovery method to already discriminative text methods, such as SBERT, can further enhance data accuracy, and vice versa. Therefore, replacing SBERT with a stronger text encoding method is expected to continue improving the performance of SenteTruth.\nAdditionally, it is noteworthy that, for example, at Epoch 20, even if malicious nodes have a higher data similarity than honest nodes due to various reasons, their lower node weights from prior malicious behavior ensure that their tampered data is not selected in the final aggregation. This is both a limitation of SBERT and the reason why SenteTruth achieves higher accuracy-errors in distinguishing by SBERT are corrected"}, {"title": "F. RQ4 - Usability Analysis", "content": "Table IV presents the Gas costs of the proposed solution implemented on Ethereum. We randomly selected 10 questions and queried ChatGPT, recording the Gas consumption for each request. Specifically, requestLLM is the interface through which the user contract calls the oracle contract to request data, while fulfillData is the interface through which the oracle node returns the data. It can be observed that the Gas cost is relatively higher during contract deployment, while the subsequent calls' Gas consumption depends on the length of the queried questions and the length of the responses. This implies that integrating the capabilities of large models into the blockchain requires only a few hundred thousand Gas fees, in addition to the oracle node incentives and the LLM API service costs."}, {"title": "V. CONCLUSION", "content": "This paper proposes and implements a universal framework for integrating LLMs with blockchain data, C-LLM, aimed at overcoming interoperability barriers between blockchain and LLMs and introducing the intelligent analysis and decision- making capabilities of LLMs into smart contracts. To address the issue of heterogeneity in the data returned by nodes, we combine semantic relevance assessment with truth discovery techniques to propose a novel data aggregation method, SenteTruth. Additionally, the research constructs a dataset containing three types of questions, covering Q&A records between 10 oracle nodes and 5 LLM models, to validate the framework's effectiveness. Experimental results demonstrate that the proposed method offers significant advantages in improving data reliability and usability."}, {"title": "APPENDIX", "content": "SUPPLEMENT THE EXPERIMENTAL RESULTS"}, {"title": "In the future", "content": "In the future, as advancements in artificial intelligence, particularly LLMs, continue to progress, the intelligence of smart contracts is expected to undergo a revolutionary transformation. Smart contracts will no longer be confined to rigid, hard-coded rules; instead, they will be capable of autonomously making flexible decisions based on real-time conditions, the evolving needs of contract participants, and inputs from external data sources. The semantic understanding capabilities of LLMs will empower smart contracts to analyze ambiguities in contract terms, automatically identify and resolve potential conflicts or misunderstandings, and optimize trading strategies and risk management. With the deepening integration of AI and blockchain technologies, smart contracts will be able to engage in self-learning and self-adjustment, progressively enhancing the accuracy and efficiency of decision-making. This evolution will significantly broaden the applicability of smart contracts, opening new opportunities in areas such as decentralized finance, supply chain management, and smart insurance, thereby ushering in a new era of intelligent blockchain systems."}]}