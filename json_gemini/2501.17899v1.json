{"title": "Position: The Right to AI", "authors": ["Rashid Mushkani", "Hugo Berard", "Allison Cohen", "Shin Koseki"], "abstract": "This position paper proposes a \u201cRight to AI,\u201d which asserts that individuals and communities should meaningfully participate in the development and governance of the AI systems that shape their lives. Motivated by the increasing deployment of AI in critical domains and inspired by Henri Lefebvre's concept of the \u201cRight to the City,\" we reconceptualize AI as a societal infrastructure, rather than merely a product of expert design. In this paper, we critically evaluate how generative agents, large-scale data extraction, and diverse cultural values bring new complexities to AI oversight. The paper proposes that grassroots participatory methodologies can mitigate biased outcomes and enhance social responsiveness. It asserts that data is socially produced and should be managed and owned collectively. Drawing on Sherry Arnstein's Ladder of Citizen Participation and analyzing nine case studies, the paper develops a four-tier model for the Right to AI that situates the current paradigm and envisions an aspirational future. It proposes recommendations for inclusive data ownership, transparent design processes, and stakeholder-driven oversight. We also discuss market-led and state-centric alternatives and argue that participatory approaches offer a better balance between technical efficiency and democratic legitimacy.", "sections": [{"title": "1. Introduction", "content": "We posit that every individual and community affected by artificial intelligence (AI) systems has a Right to AI: the capacity and entitlement to shape, critique, and govern the AI infrastructures that increasingly define modern life. Al is proliferating in domains such as healthcare, education, finance, and urban planning, generating both innovation and ethical, legal, and socio-political concerns."}, {"title": "2. Background", "content": ""}, {"title": "2.1. Positioning the Right to AI", "content": "The contemporary discourse on AI governance spans policy proposals, ethical guidelines, and technical methods aimed at aligning AI with societal values. Institutions such as the OECD and the European Union have introduced frameworks for responsible AI development, often emphasizing fairness, accountability, and transparency. However, these proposals typically operate within top-down or expert-led paradigms, granting only peripheral or transactional roles to civic engagement."}, {"title": "2.2. The Right to the City", "content": "Henri Lefebvre's Right to the City is a foundational concept in urban theory that rejects the fragmentation of city life into discrete, expert-managed sectors. Instead, it asserts a universal right for citizens to actively shape urban processes. The concept emphasizes inclusivity, accessibility, and democracy, advocating that urban spaces should be collectively governed rather than controlled solely by market forces such as commodification and capitalism. Lefebvre's vision presents this right not as an individual entitlement but as a collective one, grounded in shared power and responsibility for shaping urban life.\nRecent scholarship has expanded this framework by addressing contemporary urban struggles, emphasizing digital infrastructure, environmental justice, and participatory governance. The parallels to AI governance become evident as we acknowledge Al's pervasive impact on daily life, from news curation to resource allocation. Just as Lefebvre opposed the tech-"}, {"title": "2.3. Ladder of Citizen Participation", "content": "Sherry Arnstein's ladder of citizen participation defines eight distinct levels of citizen involvement, spanning from manipulation at the bottom to citizen power at the top. At the lowest rungs\u2014manipulation and therapy-efforts aim merely to educate or \"cure\" participants without granting real influence. Progressing upward, forms of tokenism such as informing, consultation, and placation may appear to involve citizens, but often conceal deeper imbalances in decision-making power. The ladder serves as a guide to understanding how genuine power sharing can be distinguished from superficial involvement in decision-making processes. Applied to AI, this hierarchy helps conceptualize the degree of public involvement in system design and oversight. Current findings suggest that traditional AI practices often situate users at the \"informing\" or \"consultation\u201d rungs at best, rarely reaching the top rungs of \u201cpartnership\u201d or \u201ccitizen control\". Building on this framework, recent studies highlight the growing importance of civic participation and public engagement in AI. Thus, Arnstein's framework serves as a valuable lens for assessing how much decision-making power stakeholders genuinely exercise."}, {"title": "2.4. Grassroots Engagement", "content": "Jane Jacobs' The Death and Life of Great American Cities critiqued large-scale, expert-led urban redevelopment projects. Jacobs argued that community-level knowledge is often disregarded in top-down models, leading to detrimental effects on neighborhoods. Her grassroots approach resonates with the Right to AI: communities affected by AI systems also possess contextual insights that can inform more ethical, value-aligned, context-sensitive development and deployment. \nPrevious attempts to incorporate participation in AI governance include user feedback loops in recommender systems, collaborative training data annotation, and community reviews of AI outputs."}, {"title": "3. Arguments for AI as Societal Infrastructure", "content": "A central premise of the Right to AI is that AI increasingly functions as societal infrastructure, comparable to utilities or educational systems. Viewing AI as societal infrastructure aligns with established frameworks of public goods, commons governance, and socio-technical systems. Infrastructure commonly exhibits three properties: (i) broad societal impact, (ii) an essential role in daily life, and (iii) a requirement for collective management . AI, particularly foundation models shaping decisions having to do with employment, credit scoring, and public discourse, for example, arguably meets these criteria."}, {"title": "Broad Societal Impact", "content": "Al systems are being embedded as a matter of standard practice across industries such as healthcare and education, influencing areas of high social impact such as diagnostic processes and learning environments. This pervasive integration of AI highlights the need for inclusive governance mechanisms that address the wide-ranging social implications, including ethical considerations, societal norms, and the long-term effects on communities and institutions."}, {"title": "Essential Role in Daily Life", "content": "Technologies that mediate access to financial systems, public services, and employment increasingly function as core societal infrastructure. AI-driven decision-making in credit approval, job screening, and social welfare administration underscores its role in structuring life chances. The opacity of these systems necessitates governance mechanisms akin to those regulating financial and legal infrastructures."}, {"title": "Collective Management", "content": "AI-based systems shape social interactions, political communication, and institutional trust. Like other infrastructures, AI is not neutral; it embeds political, economic, and cultural assumptions that shape its societal consequences. Without participatory oversight, AI risks reinforcing inequities rather than serving as a mechanism for collective well-being.\nUrban planning frameworks, such as the Right to the City, provide insights into collective governance of infrastructure, but AI differs in its algorithmic opacity and dynamic evolution. Effective governance may thus require adaptive regulatory structures, participatory audits, and interdisciplinary expertise to navigate its societal impacts."}, {"title": "4. Arguments for the Right to AI", "content": "The Right to AI is grounded in four distinct but overlapping arguments: democratic legitimacy, social justice, epistemic autonomy, and data production, emphasizing the necessity of community participation for ethical and effective AI."}, {"title": "4.1. Democratic Legitimacy", "content": "Democratic theories posit that decisions affecting the public should include input from those impacted. AI systems exert significant influence, shaping access to loans, recommending political content, and determining university admissions. The widespread adoption of generative agents in the coming years is expected to further amplify this impact. To align with democratic principles, citizens must have the right to deliberate on data usage, algorithmic objectives, and mechanisms for redress. Without such participation, Al governance risks becoming an unaccountable domain controlled by elites."}, {"title": "4.2. Social Justice and Pluralism", "content": "Machine learning models typically generalize from large datasets, which may fail to capture minority values or nuanced cultural norms. As a result, marginalized voices risk erasure or misrepresentation. The Right to AI entails inclusive governance structures that protect pluralism by ensuring that multiple moral and cultural frameworks inform system design. This pluralistic perspective challenges any hegemonic assumption that there is a single \u201ccorrect\u201d data-driven solution."}, {"title": "4.3. Epistemic Autonomy", "content": "As AI systems filter information, recommend decisions, and shape daily interactions, they hold substantial power to influence knowledge ecosystems. Epistemic autonomy refers to the ability to develop independent perspectives on what is true or valuable. If AI systems are centralized or controlled by a few entities, they may homogenize culture, intensify specific worldviews, or narrow the range of acceptable discourse. The Right to AI protects the capacity of individuals and communities to determine their own epistemic conditions, thereby preserving cultural diversity and safeguarding the evolution of collective knowledge."}, {"title": "4.4. The Production of Data", "content": "Data is integral to AI's predictive and generative capabilities. It is created in diverse social contexts, yet the processes of collection and ownership often remain opaque and concentrated in a few organizations. These mechanisms can obscure communal contributions to datasets, allowing organizations to exercise disproportionate influence over data use. Viewing data as a shared resource aligns with Ostrom's notion of collective governance for common-pool resources. Approaches such as local data trusts or transparent curation boards may mitigate risks of biased outcomes and privacy infringements by balancing innovation with individual and collective rights."}, {"title": "4.5. Broader Ethical Implications", "content": "Philosophical frameworks such as Design Justice call for marginalized community members to be at the center of the AI design and build process. The Right to AI builds on these traditions by advocating for participatory structures at each stage of the AI lifecycle. By distributing decision-making power and emphasizing co-ownership of data, the Right to AI embeds ethical commitments in technical artifacts and institutional arrangements. Through these mechanisms, AI can better align with the values and needs of diverse communities, reinforcing social trust and ensuring that AI remains a form of shared societal infrastructure rather than a purely commercial or technocratic domain.\nMoreover, at the international level, disparities in AI de-velopment create technological asymmetries between coun-"}, {"title": "5. Ladder of Right to AI", "content": "We adapt Arnstein's ladder of participation to propose four tiers of engagement in the AI governance process. These tiers are distinguished based on the extent of stakeholder agency, transparency of decision-making, and inclusivity in shaping Al systems . Although these categories are not exhaustive, they illustrate a spectrum of approaches:"}, {"title": "5.1. Consumer-Based (Minimal Right to AI)", "content": "In this lower tier, individuals primarily act as consumers, accessing Al services without substantive input into data practices or decision-making . Participation is typically limited to optional user surveys or feedback forms . This model offers convenience but often consolidates authority among system developers. Users have limited capacity to influence model outcomes or address biases, and redress mechanisms are generally weak ."}, {"title": "5.2. Private Organization-Led (Proprietary Technocracy)", "content": "In this tier, private entities integrate limited user feedback into governance structures that they own or manage. Model behavior, training data selection, and interpretability measures remain largely within corporate purview. Transparency mechanisms (e.g., user dashboards) may partially improve accountability, but conflicts of interest can persist. Communities retain a delegated form of influence, depending on the extent to which private actors incorporate public input into product roadmaps and ethical guidelines ."}, {"title": "5.3. Government-Controlled (Bureaucratic Sovereignty)", "content": "Government agencies play a central regulatory role, setting broad guidelines that can include data privacy mandates, anti-discrimination policies, and public consultations. This model can increase accountability by establishing enforceable standards, but top-down governance structures may overlook localized knowledge or community-specific concerns . Moreover, government priorities may be shaped by agendas unrelated to broader stakeholder engagement, which can limit the scope of genuine participation."}, {"title": "5.4. Citizen-Controlled (Maximal Right to AI)", "content": "At the upper end, citizens have considerable authority over AI governance. This model may involve local data trusts, cooperative ownership of training datasets, and citizen assemblies overseeing deployment and audit processes. While such arrangements demand robust institutional support, conflict-resolution mechanisms, and technical expertise, they maximize community control. In principle, this tier represents the fullest expression of participatory AI, empowering communities to define model objectives, ethical constraints, and performance metrics ."}, {"title": "6. Lessons from Participatory Practices", "content": "The extent to which participatory AI can reconfigure decision-making power\u2014or instead uphold existing technological agendas\u2014remains contested. This section draws on empirical insights from a range of participatory AI initiatives to explore whether stakeholder engagement can meaningfully influence AI design or remains largely symbolic. Although many projects prioritize knowledge sharing rather than deeper power-sharing, they also reveal both the opportunities and constraints that shape more robust forms of community involvement."}, {"title": "Early Engagement", "content": "Several projects, including Participatory Modelling for Agro-Pastoral Restoration and PRISM Alignment Dataset, show that engaging communities early can reveal cultural or ethical issues before they become entrenched. Delayed consultation often feels tokenistic, limiting participants' ability to influence fundamental design decisions ."}, {"title": "Conflict Resolution and Power Dynamics", "content": "Differences in moral frameworks or cultural norms may create tensions if not managed proactively. For example, PRISM Alignment Dataset identified cross-cultural disagreements about AI ethics. Resource imbalances can also permit well-funded institutions to dominate agenda-setting, marginalizing other voices."}, {"title": "Resource Commitments", "content": "Several initiatives, including M\u0101ori Data Sovereignty Initiative and Project Dorian, relied on training, funding, and organizational support. Communities that cannot independently access these resources may depend on external programs that come with distinct priorities."}, {"title": "Conflation and Cooptation", "content": "While increasing the number of participants can broaden representation, it does not necessarily equate to deeper engagement. Companies may harness grassroots involvement mainly for publicity or profit, reframing local knowledge for external gain. For instance, in African language machine translation, some community efforts have been repackaged as commodifiable assets by external actors."}, {"title": "Balancing Expert and Local Knowledge", "content": "Efforts to integrate specialized and local knowledge can face disagreements over data validity, model interpretability, and ethical guidelines. Translational strategies-ranging from interdisciplinary facilitation teams to community-guided metrics-can help mediate these gaps."}, {"title": "Implications for a Right to AI", "content": "While most cases are context-specific, some show that sustained grassroots advocacy can influence decision-making. Jane Jacobs' fight against highway expansion highlights how informed stakeholders and activism shape planning. In AI, persistent public pressure could counter performative engagement. Early participatory methods that grant real decision-making power are more likely to redistribute power, benefiting broader communities."}, {"title": "7. Recommendations", "content": "To effectively realize the Right to AI, the following recommendations are designed as a collaborative, multi-sectoral effort. Recognizing that structural change cannot be achieved by a single stakeholder alone, these proposals engage a diverse range of actors including educational institutions, governmental bodies, community organizations, and industry partners to work together in fostering ethical, accountable, and inclusive AI systems.\nProvide Technical and Educational Resources Organizations such as universities, NGOs, and local governments can collaborate to develop workshops, open educational materials, or interactive simulators that demystify AI. These ef-"}, {"title": "Facilitate Participation", "content": "Developers, civic tech groups, and service providers may deploy accessible interfaces such as real-time translations or interactive dashboards-to broaden engagement in AI projects. Large language models allow code-free inclusive interfaces, enabling broader participation in AI governance and design. Structured feedback and co-creation sessions encourage non-experts to contribute insights into model objectives or"}, {"title": "Formalize Community Assemblies", "content": "Municipalities, civic groups, and industry partners can establish local AI councils with advisory roles. Over time, these bodies may gain decision-making authority, ensuring public influence on AI-driven processes and preventing ethical or societal oversights."}, {"title": "Establish Data Trusts and Auditing Processes", "content": "Governments, philanthropies, and private-sector coalitions can create community-based data trusts to govern training data, consent, and benefit distribution. Transparent auditing-accessible to both"}, {"title": "Localized Adaptation", "content": "Local AI developers, community organizations, and domain experts can fine-tune generative models with smaller, context-specific datasets. By involving residents or practitioners in curation and training, these models can better reflect local norms and languages. Failure to integrate local context risks producing irrelevant or culturally misaligned AI outputs, weakening public trust and engagement ."}, {"title": "Integrate Conflict Resolution and Mediation", "content": "Policymakers, community leaders, and mediators can establish transparent panels to address ethical disputes, stakeholder conflicts, and cultural sensitivities. These panels balance technical feasibility with social imperatives, fostering trust in AI governance. Without them, unresolved conflicts may deter community participation and reinforce power imbalances."}, {"title": "8. Alternative Views", "content": "Some scholars and practitioners question whether broad-based participatory approaches to AI are feasible or desirable. A market-led perspective asserts that competition and consumer choice will naturally drive responsible AI, though such models can overlook communities lacking purchasing power or direct market influence. The Right to AI maintains that these gaps warrant structured stakeholder participation to include marginalized voices and address power asymmetries.\nOthers emphasize strong state oversight to ensure consistent regulation and enforcement. Critics of localized governance argue that citizen bodies may lack the necessary expertise, risk fragmentation, or amplify parochial biases. In contrast, the Right to AI can complement centralized regulation through decentralized governance, enabling community-specific adaptations while maintaining broad standards. Carefully designed conflict-resolution methods can limit local biases and encourage inclusive decision-making.\nIn sum, we do not suggest that participatory governance alone can resolve all problems of AI oversight. Rather, the Right to AI offers a missing dimension-namely, inclusive, community-driven frameworks that complement both market incentives and centralized regulations."}, {"title": "9. Conclusion", "content": "The widespread adoption of Al raises questions about democratic oversight, social justice, and epistemic diversity. This paper proposes a Right to AI, aiming to shift from expert-dominated decision-making toward participatory approaches in which communities influence how AI infrastructure is designed, deployed, and governed. Drawing on Lefebvre's Right to the City and Arnstein's ladder of participation, the argument suggests viewing AI as societal infrastructure that requires sustained and inclusive governance.\nCase studies were examined to demonstrate the potential and challenges of participatory efforts, highlighting issues such as resource inequalities, value pluralism, and institutional inertia. Recommendations, including structured community assemblies, data trusts, iterative governance, and conflict mediation, were outlined to operationalize the Right to AI. These measures aim to ensure that AI systems reflect community values, address biases, and preserve autonomy.\nThe paper contends that the Right to AI is an important component of the future AI ecosystems because it addresses the interplay of autonomy, trust, and accountability in technology development. Advancing this right entails collective learning, institutional innovation, and ongoing negotiation of values among diverse constituencies. As AI continues to influence educational curricula, medical diagnostics, economic opportunities, and civic engagement, the need for inclusive governance increases.\nFuture research can expand the philosophical and practical foundations of the Right to AI, supporting its necessity and details of its implementation. Such work might include a thorough examination of the four-tier ladder model\u2014which conceptualizes the four modes in which participatory AI is practiced\u2014challenging existing frameworks by aligning AI governance with these tiers. Scholars can explore methods to mobilize citizens under the Right to AI umbrella, fostering widespread engagement and ensuring that participatory governance mechanisms are inclusive and representative. Integrating interdisciplinary perspectives from political theory, ethics, and technology studies can also serve to enhance the grounding and reasoning for the Right to AI. Adapting the four-tier ladder to diverse cultural contexts is crucial for scalability and global implementation, while addressing feasibility and funding\u2014determining who pays and how to sustain participatory mechanisms is equally essential.\nBy addressing these areas, research can develop the Right to AI as a comprehensive framework that aligns technical advancements with communal interests, promoting inclusivity, transparency, and ethical accountability in AI governance."}, {"title": "Impact Statement", "content": "By reframing AI as societal infrastructure and proposing a Right to Al, this work highlights both opportunities and challenges for democratizing AI governance. The benefit of participatory governance is that it can address biases in data and model design, empower historically marginalized communities, and foster trust in AI systems. By asserting collective ownership of data, citizen control of model objectives, and localized adaptation, the proposed framework encourages equitable distributions of AI's benefits, aligning technological progress with diverse cultural and ethical perspectives.\nHowever, realizing such a participatory model may face significant hurdles in practice. Communities may lack the educational resources or institutional support to contribute meaningfully, and power asymmetries could lead to tokenistic engagement rather than genuine reform. Additionally, expanding citizen-led decision-making could risk misaligned local biases or fragmented national regulations if not carefully mediated. Nevertheless, by centering the voices of those most affected by AI, the Right to Al offers a transformative path that can mitigate systemic biases and strengthen democratic ideals in an increasingly automated world."}, {"title": "Appendix", "content": "\u2022 A Governance Right\n\u2022 B Implementation Path\n\u2022 C Generative Agents\n\u2022 D Power & Data\n\u2022 E Ethical Grounds\n\u2022 F Hidden Choices"}, {"title": "A. Governance Right", "content": "The Right to AI can be understood as a governance right, emphasizing policy, procedural justice, and institutional design . Rather than relying on market mechanisms or top-down state control, governance rights establish frameworks through which individuals and communities can co-determine Al systems' objectives and oversight structures. This perspective draws on democratic traditions recognizing the capacity of the public to influence technological developments that shape collective well-being .\nIn this framework, the Right to AI moves beyond a privilege right-which might only allow people to use a given technology-to a power right, which grants communities the authority to reshape AI systems . While intellectual property laws may protect patents or licenses, the broader direction, governance, and deployment of AI can be subject to public deliberation. Examples include local AI assemblies, public audits, and cooperative data stewardship, each aiming to reconcile private ownership with communal oversight ."}, {"title": "B. Implementation Path", "content": "(a) Empirical Evidence from Participatory AI Initiatives such as WeBuildAI and MID-Space suggest that community participation can align algorithmic outputs with local values. These projects have found that when participants understand how and why certain data are used, they are more inclined to trust and engage with AI tools. However, repeated consultations without tangible outcomes may cause participation fatigue .\n(b) Evaluation of Participatory Models Comparative analyses of participatory and non-participatory AI systems could measure outcomes such as transparency, fairness, and community trust . Involving domain experts, local knowledge holders, and impacted communities may help refine evaluation criteria and metrics .\n(c) Technical Approaches Methods like Reinforcement Learning from Human Feedback (RLHF) and participatory fine-tuning enable stakeholder input on model behaviors. Balancing diverse viewpoints in these processes can be challenging but may be facilitated by transparent data pipelines and iterative design cycles .\n(d) Scalability and Institutional Barriers Scaling participatory approaches to national or international contexts is complex. Bureaucratic structures and profit-driven goals sometimes dilute community-driven decision-making . Hybrid frameworks that combine local autonomy with standardized guidelines might help retain the participatory ethos .\n(e) Applications Across System Types Participatory governance can apply to various Al domains but may face context-specific constraints. For instance, specialized knowledge or resource limitations can limit who can engage. Below are select examples:\n(e.1) Education and Healthcare End-users often have immediate stakes in these areas . Collaborative tools have been piloted to identify biases in diagnostic algorithms , though sustained adoption can require institutional support and specialized expertise.\n(e.2) Urban Planning Urban planning regularly involves public input, though execution can vary . Projects like MID-Space used iterative community annotation to inform planning tools , revealing how structured feedback loops might help integrate diverse local needs .\n(e.3) Software Development Open-source and agile methods stress iterative engagement. WeBuildAI involved workshops where participants shaped algorithmic governance. Transparent norms and distributed authority appeared pivotal to maintaining motivation and commitment.\n(f) Future Research Further areas of inquiry include:\n\u2022 Data Practices and Local Expertise: Co-created annotation and Indigenous knowledge integration may enhance system credibility .\n\u2022 Longitudinal Studies: Investigating how participation evolves over time, focusing on trust-building and avoiding participation fatigue .\n\u2022 Sustainability: Allocating resources to ensure consistent engagement and demonstrate visible influence on policy or system outputs ."}, {"title": "C. Generative Agents", "content": "Recent advances in large language models and other generative systems allow for large-scale content creation across text, images, or interactive dialogues. Several factors may benefit from participatory governance:"}, {"title": "Pluralistic Alignment", "content": "Generative AI can reinforce majority perspectives if minority viewpoints are underrepresented in the training data. Approaches like RLHF may not fully capture diverse views, prompting research on methods such as Overton pluralism or jury-based alignment . These efforts could mitigate homogenization of perspectives and enhance equitable representation ."}, {"title": "Risk of Amplified Disinformation", "content": "Generative models may facilitate the rapid creation of misleading or harmful content . While community monitoring and co-governance can assist in mitigating such content, institutional safeguards and digital literacy programs may be crucial for broader resilience ."}, {"title": "Data Transparency and Ownership", "content": "Large-scale data scraping is central to many generative systems. A Right to Al perspective could motivate community-based decisions about data collection, retention, and licensing ."}, {"title": "Algorithmic Profiling and Manipulation", "content": "Adaptive agents can generate detailed user profiles by monitoring interactions, raising concerns over targeted manipulation or preferential targeting. Participatory audits and interpretability tools might help users and regulators detect problematic patterns, but effective governance likely requires ongoing transparency about model objectives ."}, {"title": "D. Power & Data", "content": "A Foucauldian perspective suggests that marginalization and exclusion often result from institutional power relations and discursive frameworks that limit whose voices are considered legitimate . In AI, control over design, deployment, and data policies can be concentrated among corporations or governmental actors. Changing these power structures may require new or revised institutional processes that invite broader participation.\nArticle 27 of the UDHR and the Right to Science Article 27 of the Universal Declaration of Human Rights (1948) states that everyone should share in \"scientific advancement and its benefits.\" Contemporary interpretations extend this to digital and technological domains. However, public accessibility of data does not necessarily translate to equitable involvement in systems built upon it. Proprietary protections can confine tangible benefits to a"}, {"title": "Data Enclosure", "content": "Some private actors train AI models on publicly available data and then restrict or monetize the results, a process sometimes referred to as data enclosure . Critics argue that in fields such as healthcare and policing, models used without public oversight can exacerbate social inequalities . The Right to AI positions communities to scrutinize and influence such models, aiming to prevent the privatization of communal knowledge."}, {"title": "E. Ethical Grounds", "content": "Respect for Moral Agency A fundamental argument for the Right to AI is grounded in respect for moral agency. AI systems significantly influence people's lives, making decisions on employment, healthcare, policing, and education . Ensuring that individuals have a role in shaping these systems aligns with principles of autonomy and self-determination . Without participatory engagement, Al risks reducing individuals to passive subjects of algorithmic governance rather than active contributors to its development.\nControl Over Personal Information AI-based decisions often rely on personal data, prompting questions about privacy, consent, and user control . Mechanisms embedded in the Right to AI could clarify data handling processes and reduce unwarranted intrusions .\nMitigating Intrusion and Anonymization Risks AI's ability to infer personal attributes, even when explicit data is not provided, raises serious ethical concerns . These risks can be mitigated through participatory oversight mechanisms, ensuring that AI does not perpetuate intrusive or harmful data practices . By advocating for the Right to AI, communities can establish consent-based frameworks that prioritize ethical data handling.\nAddressing Statistical Discrimination AI often relies on statistical generalizations that may fail to respect the uniqueness of individuals . A participatory approach to AI governance would enable affected communities to challenge harmful biases and demand equitable algorithmic design . The Right to AI provides a means for individuals to contest algorithmic categorizations and push for more inclusive and fair outcomes ."}, {"title": "Obligation to Provide Justification", "content": "When Al influences critical life decisions, increased transparency and explain-ability may be warranted . A Right to AI approach aligns with the notion that those subject to algorithmic decisions should have a means to access comprehensible justifications ."}, {"title": "F. Hidden Choices", "content": "We end this paper with below analogy:\nImagine it's 2035...\nYou walk into a restaurant, but you don't order your meal has already been decided for you. The chefs claim to know your tastes, preferences, and needs better than you do. The recipes are hidden, the kitchen is closed to outsiders, and any attempt to question or change your meal is met with silence. If this is the only restaurant in town, your choices aren't just limited-they're non-existant.\nNow, imagine AI works in the same way. A small group of actors dictate what information you see and which services you can access. The Right to Al challenges this imbalance, asserting that communities should not merely be passive consumers but active participants in designing, governing, and overseeing AI. To maintain our autonomy and choice, we must have a say in how the AI that dictates our preferences and choices is built and deployed."}]}