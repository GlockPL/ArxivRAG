{"title": "Open Foundation Models in Healthcare: Challenges, Paradoxes, and Opportunities with GenAI Driven Personalized Prescription", "authors": ["Mahdi Alkaeed", "Sofiat Abioye", "Adnan Qayyum", "Yosra Magdi Mekki", "Ilhem Berrous", "Mohamad Abdallah", "Ala Al-Fuqaha", "Muhammad Bilal", "Junaid Qadir"], "abstract": "In response to the success of proprietary Large Language Models (LLMs) such as OpenAI's GPT-4, there is a growing interest in developing open, non-proprietary LLMs and AI foundation models (AIFMs) for transparent use in academic, scientific, and non-commercial applications. Despite their inability to match the refined functionalities of their proprietary counterparts, open models hold immense potential to revolutionize healthcare applications. In this paper, we examine the prospects of open-source LLMs and AIFMs for developing healthcare applications and make two key contributions. Firstly, we present a comprehensive survey of the current state-of-the-art open-source healthcare LLMs and AIFMs and introduce a taxonomy of these open AIFMs, categorizing their utility across various healthcare tasks. Secondly, to evaluate the general-purpose applications of open LLMs in healthcare, we present a case study on personalized prescriptions. This task is particularly significant due to its critical role in delivering tailored, patient-specific medications that can greatly improve treatment outcomes. In addition, we compare the performance of open-source models with proprietary models in settings with and without Retrieval-Augmented Generation (RAG). Our findings suggest that, although less refined, open LLMs can achieve performance comparable to proprietary models when paired with grounding techniques such as RAG. Furthermore, to highlight the clinical significance of LLMs-empowered personalized prescriptions, we perform subjective assessment through an expert clinician. We also elaborate on ethical considerations and potential risks associated with the misuse of powerful LLMs and AIFMs, highlighting the need for a cautious and responsible implementation in healthcare.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent years have witnessed an upsurge in the development of various Artificial Intelligence Foundation Models (AIFMs) for different tasks such as Natural Language Processing (NLP), computer vision, healthcare, etc. This trend is primarily driven by the availability of extensive datasets and advancements in Deep Learning (DL) such as transformer networks. Notable milestones include attention networks (213 million parameters) [1], GPT-2 (1.5 billion parameters) [2], GPT-3 (175 billion parameters) [3], the switch transformer (1.6 trillion parameters), Persia (100 trillion parameters) [4], and the recently unveiled GPT-4 (undisclosed parameters) [5]. Specifically, scaling of model sizes has resulted in significant improvements in the performance of these AIFMs across classical NLP benchmarks such as GLUE [6], SuperGLUE [6], and Winograd [7]. Furthermore, AIFMs have shown their efficacy as few-shot learners [8], [9], fueling their widespread adoption as foundational pre-trained models [10], [11], [12], [13], [14].\nFollowing the success of ChatGPT driven by proprietary Large Language Models (LLMs) like GPT-4 from OpenAI, there is increasing interest in open and nonproprietary LLMs. These models are positioned for broader community use in academic, scientific, and noncommercial endeavors. Although some open-source AI models have emerged, the landscape is in flux and the selection of models increasingly depends on performance, licensing, and integration capabilities. Although these open models often do not match the refined functionality of proprietary counterparts like GPT-4, they promise to revitalize healthcare applications when tailored to specific tasks. For example, open AIFMs can be repurposed to analyze vast medical literature, clinical guidelines, and patient data, thus helping healthcare professionals make more accurate diagnoses by considering a broader range of information and patterns than human capabilities, ultimately improving healthcare outcomes. Nevertheless, various lingering doubts and ethical considerations arise, particularly regarding the potential misuse of such powerful models for malicious purposes.\nThis paper emphasizes the latest advancements and practical applications of open LLMs and AIFMs in healthcare. We evaluate the impact of open AI on healthcare and present the opportunities, capabilities, and challenges presented by current open AIFMs in this field. It is important to note that a concrete definition of open AI models is currently unavailable in the literature. Seger et al. [15] defined open AI models as models for which the underlying training data, source code, and model weights are publicly available. On the other hand, Kapoor et al. [16] followed a reductive approach to define open AI"}, {"title": "II. BACKGROUND", "content": "LLMs represent the recent advancements in large general models characterized by their immense size and capacity to perform various NLP tasks including understanding and generating human-like text [18]. LLMs are typically pre-trained on large datasets containing vast amounts of text from the Internet. During pre-training, the model learns to predict the next word in a sentence or fill in missing parts of text. This unsupervised pre-training allows the model to capture contextual information and syntactic structures. After pre-training, LLMs can be fine-tuned on specific tasks with smaller datasets. Fine-tuning adapts the model to perform tasks such as text classification, language translation, summarization, etc. These models can generate coherent and contextually relevant text given a prompt. LLMs have been used for various downstream tasks such as creative writing, code generation, question answering, and different natural language understanding tasks [19]. The success of LLMs in solving various NLP tasks has attracted substantial attention from the research community and has resulted in the development of AIFMs, which are also referred to as general-purpose AI models. These models possess general capabilities that can be tailored to model a variety of downstream tasks, including healthcare applications. In healthcare, LLMs can be used for tasks such as medical record summarization, patient data analysis, diagnostic assistance, and personalized treatment recommendations, showcasing their potential to enhance patient care and streamline medical processes significantly [20].\nIn recent years, several open AI models have emerged, yet the landscape remains dynamic and the model selection is increasingly dependent on their performance, licensing, and integration capabilities [22]. However, these open models often fall short of the refined functionality of proprietary models such as GPT-4. The concept of Open Al or open source Al remains nebulous, frequently embodying aspirations or marketing tactics rather than a concrete definition [15]. These terms reflect the principles of free and open-source software (FOSS), emphasizing the freedom to use, study, modify, and share software. Open LLMs and AIFMs extend this philosophy to AI, highlighting the importance of transparency, accessibility, and collaborative enhancement of these models. The decision between open-source and closed-source models involves balancing the freedom for customization against proprietary features and commercial support offered by closed-source models. Open LLMs and AIFMs are distributed under various licenses [23], from the permissive MIT or Apache 2.0 (which allows considerable user freedom) to the more restrictive GNU General Public License (GPL) [24], which mandates that derivative works remain open-source. These licenses facilitate commercial use, modification, and distribution, while also imposing stipulations regarding copyright and patent rights. In the ML research and development community, doubts remain about the merits and drawbacks of making LLMs and AIFMS open-source or retaining them as proprietary models [25], [15].\nThe term open-source stems from the traditional Open-Source Software (OSS) context, defined in 1998 [26]. OSS requires software to be publicly available for use, viewing, modifications, and distributing source code under open-source license [15], [27]. However, within the context of LLMs and AIFMs, the term \"open AI\" has become ambiguous. The degree of openness in existing open AI tools has been a subject of considerable debate. For example, LLaMA has encountered criticism regarding the extent of their openness [28]. For instance, Meta recently announced an open-source LLaMA-2 model; however, it has not been made available under a traditional open-source license. Instead, Meta has defined its terms and conditions regarding the use of this model for various IoT applications, especially in healthcare domains. In Figure 1, we present a gradient depicting the level of open-source access to LLMs and AIFMs, followed by a brief discussion of the pros and cons of open-sourcing these models.\nThe requirements for open AI are certainly different and various definitions are found in the relevant literature. For example, Seger et al. [15] outlined the critical components"}, {"title": "C. Challenges Hindering Open AI in Healthcare", "content": "In the literature, it has been argued that ensuring the privacy of patient data is a top priority [31]. AIFMs are typically trained on vast amounts of medical records, which may include sensitive, confidential, or personally identifiable information. Therefore, during the training process, the model can inadvertently memorize and reproduce this information when generating text, leading to data leakage [32]. This can be a severe breach of privacy if the generated content is shared publicly or accessed by unauthorized/malicious entities. These extracted instances encompass publicly accessible personally identifiable information like names, phone numbers, and email addresses, along with medical records. Larger models tend to exhibit greater vulnerability compared to smaller ones [33], [32]. Proper encryption, access controls, and compliance with healthcare regulations are essential to protect patient information [34].\nTraining healthcare AIFMs necessitates access to large quantities of high-dimensional data, often derived from unfiltered user-generated content. This approach introduces substantial privacy risks [33], [32], [35], [36], [37], [38].\nResearchers have demonstrated that AI models used in medical imaging can be vulnerable to adversarial attacks. For instance, the behaviors of an AI diagnosis model under adversarial images generated by Generative Adversarial Network (GAN) models could lead AI models to misdiagnose conditions such as cancer. This type of attack could potentially lead to incorrect treatment plans, posing severe risks to patient health [39]. Various adversarial ML attacks can be realized on DL models that can be broadly categorized into two classes [40]: (1) targeted attacks, where the objective is to enforce the model to classify a given input into the target class; (2) untargeted attacks, where the objective is to increase overall misclassification rate. The enormity of these attacks has already been demonstrated for various ML-empowered medical systems such as medical image classification [41], [42], [43], abnormal heartbeat detection (i.e., ECG classification) [44], etc. Although open-sourcing AI models will expedite research in critical directions such as evaluating their security aspects, a cautious approach should be considered while openly releasing models trained using patient's sensitive data.\nHealthcare applications are essentially human-centric and require careful consideration of ethical aspects throughout the development of AI-based medical systems. Therefore, it is imperative to understand the sociological needs of the targeted users before starting data collection for the development of the AI model. In addition, the ethical dimensions of AI applications in healthcare involve addressing biases, ensuring fairness, and contemplating the broader implications of AI-generated decisions on patient care [45]. John et al. [46] argued that ethical debates need to be localized within the complex interplay of technical, legal, and organizational entities from which machine learning moral issues arise.\nThe true transformative potential of AI can only be realized when these systems are integrated into clinical workflows; however, this is not a non-trivial task. Since the healthcare sector operates under stringent regulatory frameworks, such as the Health Insurance Portability and Accountability Act (HIPAA) [47] and the General Data Protection Regulation (GDPR) [48]. Therefore, integrating AI solutions while adhering to these regulatory requirements demands careful navigation. The literature argues that the existing regulatory guidelines are insufficient for regulating AI-based medical systems, as these systems are adaptable (i.e., having an ever-evolving nature) and involve learning from new patient data [40]."}, {"title": "III. STATE-OF-THE-ART IN OPEN HEALTHCARE LLMS AND AIFMS", "content": "The advent of LLMs has facilitated the investigation of their capabilities in the medical domain, enabling comprehension and communication through language. This development holds the promise of more immersive human-AI interaction and collaboration. Notably, these models have showcased remarkable proficiency in addressing multiple-choice research benchmarks [49], [50]. Moreover, multi-modal foundational models can learn visual features based on textual descriptions and can be adept at various tasks such as medical imaging analysis, disease detection in radiology, pathology slide interpretation, etc. Leveraging state-of-the-art architectures like convolutional neural networks (CNNs) and transformer-based models such CLIP [51], language vision models can enhance diagnostic accuracy, streamline medical imaging workflows, and contribute to the development of advanced healthcare technologies such as VisionFM [52], RETFound [53], and LVM-Med [54].\nMoreover, multi-modal LLMs can analyze and process data from various resources or modalities that include text (language), images (vision), and audio. The idea is to create such models that can understand and generate insights by jointly considering information from different types of data (such as Gloria [55], LLaVA [56], PLIP [57], etc.). The applications of LLMs in healthcare have emerged as a transformative force in the medical landscape. LLMs and AIFMs offer a versatile set of applications that significantly impact various facets of healthcare. From automating clinical documentation to early disease prediction, for instance, LLMs such as BERT [58], BioBERT [59], and ChatGPT [60] have demonstrated their prowess in efficiently processing complex medical information. In addition, these models can be leveraged for drug discovery, personalized medicine, and literature review automation, showcasing their potential to accelerate research and enhance patient care. The integration of LLMs and multi-modal AIFMs into healthcare practices underscores their capacity to respond to diverse requests, making them valuable assets in advancing information processing and decision-making [61]."}, {"title": "Applications in Tabular Data Analysis", "content": "LLMs offer a diverse range of applications, including automating clinical documentation for enhanced accuracy and extracting structured data from unstructured EHR information [62]. It also facilitates streamlining coding and billing processes, providing real-time insights for clinical decision support, improving information search through NLP, facilitating population health management through trend analysis, enabling voice-to-text transcription for efficient record updates, enhancing patient engagement with personalized summaries, ensuring data quality through automated quality assurance, and supporting healthcare research with advanced analytics. The integration of LLMs into EHRs thus plays a pivotal role in optimizing healthcare workflows, enhancing decision-making, and ultimately improving patient outcomes [63], [64]."}, {"title": "Applications in Clinical NLP", "content": "Various NLP techniques are used to extract structured information from EHRs, converting free-text data into a format that can be easily analyzed for research, decision support, and other healthcare applications. Clinical NLP applications are diverse and impactful in healthcare [65]. They include improving clinical documentation accuracy, extracting structured information from EHRs, aiding clinical decision support, extracting phenotypic information for research, detecting adverse drug events, expediting clinical trial recruitment, understanding temporal relationships in patient records, de-identifying data for privacy compliance, and facilitating voice-to-text transcription in clinical settings. Powerful LLMs like ChatGPT (GPT-4) demonstrate significant potential for processing text data within the medical domain through zero-shot in-context learning [66], [67], [68], [68]. Clinical notes exhibit significant differences from biomedical literature, leading to subpar performance of BERT models pre-trained on clinical notes, similar to the standard BERT model [69]."}, {"title": "Applications in Prognosis, Diagnosis, and Medicine", "content": "LLMs play a crucial role in healthcare across different applications, including prognosis, diagnosis, and medicine [70], [71]. In the prognosis task, they aid in outcome prediction and disease progression modeling. Similarly, LLMs can provide automated diagnostic support [72], analyze medical images for abnormalities, and assist in identifying rare diseases. In medicine, LLMs can be leveraged for drug discovery, enable personalized treatment plans, and help monitor and improve medication adherence [73], [74], [9]."}, {"title": "Applications in Medical Imaging", "content": "In addition to LLMs that particularly work for different NLP tasks, the advancements in vision foundation models such as Segment Anything (SAM) have significant potential to revitalize medical image analysis [75]. These models, often built on DL architectures, are trained to analyze and interpret various types of medical images, such as X-rays [76], MRIs [77], CT scans [78], and pathology slides, for instance, Med-PaLM [65], a prompt-tuned iteration of Flan-PaLM 540B [79]. These models can be used for various applications, including medical image classification, segmentation, disease diagnostics, and detection of abnormalities [80]. The integration of large vision models should consider combining information from these diverse modalities to extract complementary features, thereby enhancing diagnostic accuracy [81], [82], [83]."}, {"title": "Applications in Healthcare Delivery", "content": "LLMs can significantly enhance healthcare delivery by streamlining patient communication by generating clear materials and powering telemedicine platforms [84]. For instance, the literature demonstrates that they can improve operational efficiency by automating administrative tasks and supporting clinical decision-making for dental medicine [85]. LLMs play a key role in quality improvement, health education, and remote patient monitoring, fostering proactive interventions [60]. Moreover, LLMs can address language barriers, facilitate care coordination, and collectively contribute to a more effective and patient-centered healthcare delivery."}, {"title": "Applications in Medical Education", "content": "LLMs significantly contribute to the evolution of medical education [86], [87]. LLMs have numerous applications in medical education, for instance, they can facilitate curriculum development, generate varied educational content [88], support global accessibility through language translation [89], assist in assessment and evaluation with adaptive tools [90]. Furthermore, LLMs and AIFMs-empowered simulators can enable lifelike clinical case simulations, empowering interactive e-learning platforms [91], contributing to continuing medical education [92], facilitating summarization of intricate medical literature [93]. Also, LLMs have the potential to significantly impact and transform psychological health assessment education [94]. These applications improve the efficiency, accessibility, and personalization of medical education, meeting the dynamic requirements of students and professionals in the healthcare sector [95], [96]. In practical terms, the Chatdoctor [97] and other LLMs could be designed to assist users with medical queries, provide information about symptoms, offer general health advice, or even engage in conversation about medical topics [98], [99], [100], [101], [102], [103]. Moreover, ChatGPT can be used to disseminate accurate and up-to-date medical information to users, serving as an educational tool to provide information about symptoms, diseases, medications, and general health advice [104], [105], [106], [107]."}, {"title": "Applications in Telehealth", "content": "LLMs offer various potential applications in telehealth that can significantly enhance the delivery and accessibility of healthcare services. For instance, LLM-based virtual assistance and chatbots can provide patients with timely information and support. Similarly, LLMs can enable healthcare providers to efficiently assess patient conditions and prioritize care based on urgency. In addition, LLMs can streamline appointment scheduling and send automated reminders, thereby improving patient compliance and reducing no-show rates. They also play a critical role in patient health monitoring and reporting, enabling continuous assessment of health metrics and timely intervention when necessary. Furthermore, LLMs can assist in remote follow-ups, providing patients with essential information regarding their treatment plans and recovery processes. The integration of LLMs in telehealth not only enhances the efficiency of healthcare delivery but also contributes to improved patient outcomes by ensuring that individuals receive personalized and timely care [108]."}, {"title": "Applications in Surgical Science", "content": "AI models, including CCNs, such as Flan-PaLM [65], can be employed for image recognition in surgical procedures. They help identify and analyze structures and anomalies in surgical frames, aiding surgeons in diagnostics and preoperative planning. AI plays a crucial role in robot-assisted surgery, where robotic systems are guided by intelligent algorithms [109]. These systems can enhance precision, minimize invasiveness, and provide real-time feedback to surgeons during procedures. AI algorithms can predict when surgical equipment might require maintenance or calibration [110]. The literature highlights that such a proactive approach ensures that surgical tools are in optimal condition during procedures [111]."}, {"title": "B. Safety Considerations of Open AI for Healthcare", "content": "Safety in pretraining refers to the measures and considerations taken to ensure the ethical, responsible, and secure development of healthcare LLMs during the initial training phase. Pretraining involves training a language model on a large corpus of diverse text data before fine-tuning it for specific tasks. Ensuring safety during this early phase is crucial to prevent the propagation of biases, misinformation, or harmful content in the subsequent fine-tuning and deployment stages [135]. This will ensure sensitive information is protected from being compromised, provides accurate and reliable medical information, reduces bias in outputs for fair recommendations, and maintains interpretability and transparency in decisions.\nSafety during the fine-tuning of healthcare LLMs is a critical aspect of developing reliable and trustworthy AI systems for medical applications. Fine-tuning involves training the model on domain-specific data to enhance its performance in healthcare tasks. Ensuring safety during fine-tuning involves protecting patient privacy, ethically handling data, prioritizing clinical accuracy, mitigating bias, providing explainability, testing robustness, conducting regular audits, and collaborating with healthcare professionals to create reliable, accurate, and ethical models for real-world medical applications [136]."}, {"title": "B. Proposed Method for Prescription Evaluation", "content": "To evaluate the proficiency of open and proprietary LLMs in encoding clinical knowledge and their potential for personalized prescriptions, we conducted a controlled experimental study. Specifically, we examined the effectiveness of various LLMs, including both open-source and closed-source models. As shown in Figure 4, our proposed methodology consists of four major steps, including synthetic patient profile generation using GenAI, verification of generated patient profiles by expert clinicians, evaluating LLMs for prescription, and validating the results quantitatively and qualitatively. Below we provide a brief description of each step:\nThe patient dataset used in this study was extracted from the public MIMIC-III (Medical Information Mart for Intensive Care) database [141], which contains de-identified health-related data from critical care patients. It contains de-identified health records from real patients providing rich clinical information, including patient demographics, diagnoses, medications, and treatment timelines. This dataset also provides valuable insights into the management of complex medical conditions, and this subset of data focuses on patients with chronic illnesses such as rheumatic heart disease, diabetes, and hypertension. Also, it includes detailed records of medications (e.g., Warfarin, Levothyroxine, Lisinopril, etc.), dosage, administration schedules, and as well as comorbidities like sepsis and heart failure. This allows for an in-depth analysis of drug administration patterns and clinical outcomes across a diverse patient population.\nWe leveraged the MIMIC-III dataset to create a set of 25 unique patient profiles that reflect real-world clinical scenarios while ensuring diversity in patient characteristics such as demographics, medical history, current medications, laboratory results, diagnoses, and symptoms. To make the profiles more personable, we assigned each patient a synthetic name to preserve anonymity, while ensuring the integrity of clinical data remained intact. The incorporation of synthetic names helps to humanize the profiles and provide a more relatable context for clinical scenarios. Each record includes a synthetic name and key patient characteristics such as age, gender, race, and blood type, along with primary diagnoses and comorbidities like sepsis, heart failure, and gastrointestinal disorders. The created patient profiles were formatted to a structured JSON format, which includes important characteristics such as patient demographics, diagnoses, medication history, and other key clinical details such as admission details, including the case's urgency (e.g., urgent, emergency, elective). Furthermore, it also contains comprehensive medication administration data, detailing the prescribed drugs (e.g., Warfarin, Levothyroxine, Lisinopril), their dosages, units, and administration schedules. Treatment courses are further described with start and end dates, indicating the duration and dosage adjustments for each medication. Our curated subset data provides a holistic view of patient management in cases of multi-morbidity, offering valuable insights into drug administration patterns, treatment efficacy, and clinical outcomes in a varied patient population."}, {"title": "C. Results and Discussions", "content": "We evaluated the performance of five LLMs, including GPT-4, LLaMA-2, LLaMA-3, Mistral, and Meditron, for prescription tasks using a customized prompt template. These models are accessed through LangChain using the following chat models: ChatMistralAI, ChatOLLaMA (for LLaMA-2 and LLaMA-3), and ChatOpenAI. The Meditron model was deployed on Baseten(https://docs.baseten.co/chains-reference/overview) as a chat provider. We used default parameters for all models in our experiments. The SmPCs of the medications relevant to the experiment were parsed, cleaned, and vectorized. The vectorized SmPC documents were stored in a vector database, accessible for retrieval during the experiment. A consistent prompt was developed for each patient profile. The prompt contained the patient's information (age, gender, comorbidities, allergies, and current medications) and a question about the appropriateness of a prescription or a query regarding possible drug interactions, contraindications, or dosage adjustments. Table IV describes the prompt template used for our analysis. The LangChain framework facilitated the interaction between the language model and the user query (prompt). It generated responses based on the LLM's understanding of the query and the knowledge retrieved by RAG. The RAG module employed the vectorized SmPC data to retrieve relevant sections of product information, which was then supplied to the LLM to enable fact-based response generation. The SmPC data was stored in a vector database to ensure rapid and efficient retrieval. A similarity-based search was executed using the query and patient profile to extract relevant details (e.g., dosing guidelines and drug interactions) from the SmPC vectors.\nThe main results of our experimental study on LLM-empowered personalized prescriptions are presented in Table V. The table reports the results in terms of different performance metrics including accuracy, precision, recall, and F1-score for five different LLMs namely, GPT-4, LLaMA-2, LLaMA-3, Mistral, and Meditron. Moreover, the table provides a comparative analysis of all models in two settings, i.e., with and without augmenting LLMs' responses using RAG. Table V reveals that the GPT-4 model (a proprietary LLM) outperforms other open-source models in terms of different performance metrics. Moreover, it can be seen that open-source LLMs, such as LLaMA-3, can achieve remarkable performance levels comparable to proprietary models like OpenAI's GPT-4. When examining the results across various interaction classes, LLaMA-3 often matches or even surpasses OpenAI's GPT-4 model in terms of accuracy, precision, recall, and F1 score. For instance, in critical interaction types such as contraindications, genetics, lactation, and pregnancy, LLaMA-3 shows consistently high performance. Both models (i.e., GPT-4 and LLaMA-3) achieve a perfect score in genetics and pregnancy interactions, demonstrating that LLaMA-3 can perform exceptionally well in these categories. Additionally, LLaMA-3 maintains immersive performance in other interactions like age, comorbidities, and warnings, where its scores are very close to those of GPT-4. This highlights the potential of open-source LLMs to deliver high-quality results on par with proprietary models.\nGrounding open-source models is crucial, particularly in high-stakes domains like healthcare, where incorrect information can have serious consequences. The comparison of model performance with and without RAG clearly illustrates this point. For both LLaMA-3 and OpenAI's GPT-4, incorporating RAG significantly enhances their performance across almost all interaction types in terms of different metrics such as accuracy, precision, recall, and F1 scores. For example, LLaMA-3's accuracy in handling age interactions improves from 0.85% to 0.88% with RAG, and similar improvements are observed in comorbidities, warnings, and other categories. This trend is also reflected in GPT-4's scores, where incorporating RAG leads to improvements across various interaction types. The stark contrast in performance metrics highlights the importance of grounding these models with relevant and reliable data. Without such grounding, even the most advanced models may fail to deliver the accuracy and reliability required in sensitive applications. This highlights the need for robust data augmentation techniques in deploying AI systems in critical fields such as healthcare.\nTo evaluate the clinical significance of the personalized prescription provided by LLMs, we performed a subjective assessment through an expert clinician with more than 10 years of clinical experience, particularly focusing on managing complex cases involving multi-morbidity and polypharmacy. This expert, also a paper co-author, has been actively involved in the project since its inception.\nFor the subjective evaluation, we carefully selected 12 patient profiles from our dataset while ensuring they represent a broad spectrum of clinical scenarios ranging from straightforward cases to those involving complex medication interactions. In the interest of expert time, we only select 12 patient profiles to provide a fair and comprehensive performance evaluation of the LLM-driven prescription. The expert prescriber was asked to subjectively evaluate the efficacy of the AI-generated prescriptions by considering the following key clinical features:"}, {"title": "V. CONCLUSIONS", "content": "In this paper, we have made two major contributions. Firstly, we conduct a comprehensive survey and develop a detailed taxonomy of current developments and challenges in open-source Large Language Models (LLMs) and Artificial Intelligence Foundation Models (AIFMs). Secondly, we present a case study focused on LLMs-empowered personalized prescriptions, where the objective is to analyze the feasibility of using open LLMs for critical clinical tasks like prescriptions and compare their performance with closed-source models. Our exploration of open LLMs and AIFMs in healthcare highlights a pivotal shift towards more accessible and transparent AI technologies in healthcare, emphasizing the growing potential of open-source solutions. Our comprehensive survey and taxonomy provide a structured overview of the current landscape, identifying both the strengths and limitations of open-source LLMs and AIFMs within healthcare applications. The case study on personalized prescriptions demonstrates the practical capabilities of open-source LLMs in providing effective patient-centered recommendations. Our experimental findings reveal that open-source LLMs lag behind similar proprietary models, but their performance can be improved by equipping them with other technologies such as Retrieval Augmented Generation (RAG). Despite this performance gap, open-source LLMs and AIFMs are emerging as promising solutions for AI-empowered healthcare, particularly considering their adaptability, accessibility, and customization. While open-source LLMs and AIFMs present significant opportunities, the ethical concerns and risks of misuse cannot be overlooked. Therefore, we emphasize the need for ongoing research, responsible development, and rigorous governance in deploying these powerful tools in healthcare environments."}]}