{"title": "BEYOND DATA SCARCITY: A FREQUENCY-DRIVEN\nFRAMEWORK FOR ZERO-SHOT FORECASTING", "authors": ["Liran Nochumsohn", "Michal Moshkovitz", "Orly Avner", "Dotan Di Castro", "Omri Azencot"], "abstract": "Time series forecasting is critical in numerous real-world applications, requiring\naccurate predictions of future values based on observed patterns. While traditional\nforecasting techniques work well in in-domain scenarios with ample data, they\nstruggle when data is scarce or not available at all, motivating the emergence of\nzero-shot and few-shot learning settings. Recent advancements often leverage\nlarge-scale foundation models for such tasks, but these methods require extensive\ndata and compute resources, and their performance may be hindered by ineffective\nlearning from the available training set. This raises a fundamental question: What\nfactors influence effective learning from data in time series forecasting? Toward\naddressing this, we propose using Fourier analysis to investigate how models learn\nfrom synthetic and real-world time series data. Our findings reveal that forecasters\ncommonly suffer from poor learning from data with multiple frequencies and poor\ngeneralization to unseen frequencies, which impedes their predictive performance.\nTo alleviate these issues, we present a novel synthetic data generation framework,\ndesigned to enhance real data or replace it completely by creating task-specific\nfrequency information, requiring only the sampling rate of the target data. Our\napproach, Freq-Synth, improves the robustness of both foundation as well as non-\nfoundation forecast models in zero-shot and few-shot settings, facilitating more\nreliable time series forecasting under limited data scenarios.", "sections": [{"title": "1 INTRODUCTION", "content": "Time series forecasting (TSF) plays a critical role in various areas, such as finance, healthcare, and\nenergy, where accurate predictions of future values are essential for decision-making and planning.\nTraditionally, in-domain learning has been the common setting for developing forecasting models,\nwhere a model is trained using data from the same domain it will later be deployed in (Salinas et al.,\n2020; Zhou et al., 2021). This ensures that the model captures the patterns, seasonality, and trends\nspecific to the target domain, improving its predictive performance. However, a significant challenge\narises when there is scarce or no historical information available for training, limiting the ability to\napply traditional in-domain learning approaches (Sarmas et al., 2022; Fong et al., 2020). In such\ncases, the emergence of zero-shot (ZS) and few-shot (FS) learning settings offer potential solutions.\nZero-shot learning enables models to generalize to new, unseen domains without requiring domain-\nspecific data by leveraging knowledge transfer from other domains or tasks. Few-shot learning, on\nthe other hand, allows fine-tuning on limited amounts of domain-specific data. In this paper, we\nfocus mostly on the FS and ZS TSF setting, considering limited train data or its complete absence.\nZero-shot and few-shot techniques for TSF are often built upon foundation models, which are pre-\ntrained on vast amounts of diverse data and can generalize to a wide range of tasks (Das et al.,\n2024; Ansari et al., 2024). However, foundation models (FMs) face several challenges, such as\ntheir huge data requirements, high computational costs, difficulties in fine-tuning for specific appli-\ncations, and the risk of model over-generalization, which can lead to sub-optimal performance on\nspecialized tasks (Ekambaram et al., 2024). Moreover, foundation models often struggle to fully\nexploit the train distribution, limiting their ability to capture domain-specific patterns crucial for\naccurate zero-shot time series forecasting (see Sec. 4). A potential approach to alleviate data and\ncompute limitations is to train models, including non-foundational, on task-specific synthetic infor-\nmation (Dooley et al., 2024), thus eliminating real-data requirements and reducing compute time."}, {"title": "2 RELATED WORK", "content": "In-domain time series forecasting. For decades, non-deep statistical TSF models held the state-\nof-the-art (SOTA) status (Makridakis & Hibon, 2000; Makridakis et al., 2008), but in recent years,\npurely neural network-based SOTA approaches for TSF have emerged (Salinas et al., 2020; Oreshkin\net al., 2020). Rapid development has led to various techniques including the usage of trend and\nseasonality (Zhou et al., 2022), patching time series (Nie et al., 2023), exploiting inter-channel\nrelations (Liu et al., 2024b), and many others (Wu et al., 2021; Zhang & Yan, 2023; Xu et al.,\n2024). These approaches, however, have been considered in the in-domain setting, where there is an\navailable train set that statistically aligns with the test set.\nZero-shot and few-shot TSF. While several attempts have been made in utilizing non-foundation\nmodels for ZS and FS TSF (Orozco & Roberts, 2020; Oreshkin et al., 2021; Jin et al., 2022), interest\nhas quickly shifted to foundation models. Specifically Large Language Models (LLMs) are com-\nmonly considered, using various backbones including GPT-2 (Zhou et al., 2023; Liu et al., 2024a),\nLLaMA (Jin et al., 2024), and others (Gruver et al., 2024). Additional methods exploit trend-\nseasonality-residual decompositions (Cao et al., 2024) and Transformer blocks (Goswami et al.,\n2024). One of the main limitations of foundation models is their dependence on large volumes of\ndata. Thus, recent studies have incorporated synthetic information alongside real data involving\nseasonal patterns and trends (Das et al., 2024) and Gaussian processes (Ansari et al., 2024). Closely"}, {"title": "3 BACKGROUND", "content": "To motivate our analysis and approach to zero-shot and few-shot forecasting as discussed in Sec. 4,\nwe present basic concepts and results related to Fourier analysis and time series information, see\nalso (Shumway & Stoffer, 2000). It is well-known that for any time series sample x1,..., xn CR\nand under carefully chosen coefficients, we have for odd n that\n$x_t = a_0 + \\sum_{j=1}^{(n-1)/2} [a_j \\cos(2\\pi t j/n) + b_j \\sin(2\\pi t j/n)]$,\nfor t = 1, . . ., n, ao is the bias, aj and bj are the amplitude coefficients, and t \u2208 Z. The frequencies\nwj := j/n represent cycles per time unit, where a cycle is a complete period of the cosine or sine,\ne.g., for w = 0.5, the series makes two cycles per time unit. We also consider an equivalent form,\nobtained via a trigonometric identity of Eq. 1 and given by\n$x_t = a_0 + \\Sigma_{j=1}^{(n-1)/2} A_j \\cos(2\\pi t w_j + \\varphi_j)$,\nwhere the amplitude $A_j = \\sqrt{a_j^2 + b_j^2}$ and $\\varphi_j = \\tan^{-1}(b_j/a_j)$ is the phase of the jth frequency,\nexpress the standard deviation and the cosine function starting point respectively. Notably, dominant\nperiodic components in a signal are associated with larger amplitudes.\nAnother important concept for our work is the periodogram (Schuster, 1898). We define the scaled\nperiodogram, which is closely related to the amplitude Aj, and it is defined via\n$P(\\omega) = A_j,$\nwhere large values of P(wj) correspond to predominant fundamental frequencies j/n, whereas\nsmall values of P(wj) can be viewed as noise. In practice, the scaled periodogram can be estimated\nvia the discrete Fourier transform (DFT), which represents a weighted average of the data $d(w_j) =$\nn-1/2 =1 xt exp(-2\u03c0it j/n), with i the imaginary number. It follows that P(j) = d(wj)|2.\nFinally, Harmonics represent frequencies of the form k\u0101j for a dominant fundamental frequency\nWj, k \u2208 N. They appear in time series data when non-sinusoidal components arise, and contribute\nto the structure of the signal. In what follows, we will show that harmonics, as depicted in the\nperiodogram, are crucial in understanding the effect of data on zero-shot and few-shot learning and\ninformation transfer in large time series models."}, {"title": "4 FOURIER ANALYSIS AND GENERATION FOR ZERO-SHOT TSF", "content": "Many existing approaches for zero-shot TSF are based on large foundation models (Ansari et al.,\n2024). These neural networks are computationally demanding and need large volumes of data for"}, {"title": "4.1 FREQUENCY CONFUSION AND FREQUENCY GENERALIZATION", "content": "Toward uncovering the factors that determine effective learning, we examine time series forecasting\nthrough the lens of Fourier analysis. Specifically, to quantify the differences between the train and\ntest sets and their corresponding forecasting errors, we will use the periodogram (see Sec. 3) and the\nfollowing two new frequency-based concepts.\nDefinition 4.1 (Frequency Confusion). A performance degradation observed in the case where the\ntrain set consists of the target frequencies along with other, unrelated, frequencies.\nDefinition 4.2 (Frequency Generalization). The model's ability to perform well during inference on\ndata with frequencies that were unavailable during training.\nIn other words, Def. 4.1 describes the model's difficulty in learning from multiple frequencies, where\nsome may be unnecessary. It is closely related to capacity, introduced in (Han et al., 2024) to as-\nsess data fit, and domain confusion (Liu et al., 2024a) related to datasets from different domains.\nDef. 4.2, on the other hand, deals with the ability of a trained model to obtain consistent perfor-\nmance across learned as well as unseen frequencies. This definition is closely related to domain\ngeneralization (Wang et al., 2022), where there, the generalization is in the context of performing\nwell on datasets of different domains.\nEquipped with these definitions, we consider experiments, aiming to identify whether frequency\nconfusion and frequency generalization assist in understanding model behavior. For these experi-\nments, we use recent non-foundation and foundation state-of-the-art (SOTA) TSF models includ-\ning GPT4TS (Zhou et al., 2023), Moment (Goswami et al., 2024), PatchTST (Nie et al., 2023),\nTTM (Ekambaram et al., 2024), Timer (Liu et al., 2024d), and UniTime (Liu et al., 2024a). The first\nexperiment trains the above models on a simple sine wave dataset with w = 1/24, representing an\nhour to daily based sampling rate. From here and throughout our discussion, we interchangeably use\nthe terms sampling rate and frequency. Then, we incrementally add additional sine waves with vari-\nous frequencies to the train set, re-train, and measure the prediction error of the sine wave. We plot in\nFig. 1 (left) the mean squared error (MSE) of the prediction in log scale vs. the number of additional\ntrain frequencies. Importantly, in all cases the model has access to the original data, and thus to the\nfundamental target sampling rate. Notably, all models present an increase in test MSE, even if mild,\nas more frequencies are added, suggesting that they suffer from frequency confusion. In the second\nexperiment, we use the same dataset and models. However, now every model is trained twice: on a\ntrain set including the target sampling rate (frequency), and on a train set without it. As before, we"}, {"title": "4.2 FREQ-SYNTH: SYNTHETIC TIME SERIES BASED ON FUNDAMENTAL FREQUENCIES", "content": "Following our analysis, we propose a simple yet effective approach to zero-shot TSF, which we refer\nto as Freq-Synth. Namely, we generate task-specific synthetic data and use it to train non-foundation\nand foundation models. Our approach has the potential to replace standard multi-dataset training\nof large time series models or serve as a complementary process. To generate data, we assume that\nthe target distribution is mostly dominated by the fundamental target frequency and its harmonics.\nThus, we propose to synthetically construct sinusoidal data, given the fundamental frequency (a\nscalar) of the target distribution. We derive the fundamental frequency using the sampling rate of\nthe target dataset, which is typically given as a co-variate and exploited by several models (Cao et al.,\n2024; Liu et al., 2024a; Ekambaram et al., 2024; Liu et al., 2024c). See also App. B.1 for details on\nthe relation between the sampling rate and the fundamental frequency, and ways to estimate it. To\ncreate our synthetic dataset, we first generate a pool of sines, followed by sampling from that pool\nand constructing various time series signals. We illustrate this approach in Fig. 3."}, {"title": "5 EXPERIMENTS", "content": "In this section, we evaluate Freq-Synth in comparison to recent state-of-the-art (SOTA) forecasting\napproaches on three settings: zero-shot forecasting (Sec. 5.1), synthetic data comparison (Sec. 5.2),\nand few-shot forecasting (Sec. 5.3). We consider the popular long-term time series forecasting\n(LTSF) benchmark (Zhou et al., 2021; Wu et al., 2021), which uses data from multiple domains\nincluding energy, financial, weather, and traffic. We detail below training choices that are specific\nfor each setting. The evaluation is performed on forecast horizons of 96, 192, 336, and 720. More\ndetails including implementations, hyper-parameters, and training process are described in App. D."}, {"title": "5.1 ZERO-SHOT FORECASTING", "content": "In this evaluation setting, we compare forecasting performances obtained by training on real-world\ndata vs. training solely on synthetic data (generated with Freq-Synth). We consider the following\nSOTA baselines: TTM (Ekambaram et al., 2024), UniTime (Liu et al., 2024a), Moment (Goswami\net al., 2024), Timer (Liu et al., 2024d), GPT4TS (Zhou et al., 2023), PatchTST (Nie et al., 2023).\nThese models are either foundation models, designed for the zero-shot forecasting setting, or non-\nfoundation models that marked significant milestones in developing such approaches. We also use\nthe naive and seasonal-naive baselines for comparison. Inspired by TTM, we employ a similar setup\nand train these baselines in the real data case on a subset of datasets from Monash (Godahewa et al.,\n2021) and PEMS (Liu et al., 2022). These datasets include a large range of sampling rates, including\n4 seconds, 10 minutes, 1 hour, and more. Importantly, all the sampling rates of the evaluation data"}, {"title": "5.2 COMPARING SYNTHETIC APPROACHES", "content": "The following evaluation setting compares the forecasting results for training solely on synthetic\ninformation. We consider several recent approaches for generating synthetic time series, including\nTimesFM (Das et al., 2024), ForecastPFN (Dooley et al., 2024), and KernelSynth (Ansari et al.,\n2024). TimesFM and KernelSynth have been using synthetic data originally to diversify real data\nfor pre-trained models, whereas ForecastPFN trains only on synthetic data. We generate for Fore-\ncastPFN, TimesFM, and KernelSynth 500 channels, each of length 1024 to ensure diversity. In\nthis experiment, we compare the following setups: 1) Known target sampling rate, which can be\nexploited in ForecastPFN and seasonal naive (S-Naive) as well as in Freq-Synth; and 2) Unknown\ntarget sampling rate, assuming no prior knowledge on the target domain. In the latter setup, we\nintroduce a variant of Freq-Synth, named Freq-Synth Natural, that includes datasets with com-\nmon natural frequencies such as 1/30, 1/7, 1/24, 1/60. We also create another variant, Freq-Synth\nMix, which is a dataset with random frequencies from the pool P. Importantly, the configuration\nwe consider is similar to the original setup of the compared methods."}, {"title": "5.3 FEW-SHOT FORECASTING", "content": "We conclude this section with the few-shot evaluation setting, where a pre-trained model is allowed\nto fine-tune on the target domain with a limited number of examples. To this end, we utilize the\nTTM, Timer, and PatchTST models from Sec. 5.1 that forecast for a horizon of 96, and we fine-tune\nthem on 10% of the train and validation sets of the target domain. We present the results in Tab. 3,\nhighlighting the effectivity of Freq-Synth even in this setting. Notably, many of the bold values\narise in the 'Synth' columns. Particularly, in terms of average performance, Freq-Synth exhibits\n10.6%, 19.5%, and 17.3% overall MSE reduction for the models TTM, Timer, and PatchTST,\nrespectively. These results suggest that with a lighter and more efficient synthetic setup, we can\nachieve competitive to better results with less training, and free of the associated disadvantages of\nreal data such as data collection, cleaning, management and privacy issues."}, {"title": "6 ANALYSIS", "content": ""}, {"title": "6.1 PRE-TRAINED MODELS", "content": "Below, we further expand the discussion about frequency generalization and frequency confusion\ndiscussed in Sec. 4. Here, we consider pre-trained models, obtained from the original repositories of\nTimesFM (Das et al., 2024), Timer (Liu et al., 2024d), and TTM (Ekambaram et al., 2024). To test\nwhether the given models can generalize well, we evaluated their performance on simple periodic\nsignals, with one harmonic (sine wave) and two harmonics of different frequencies. The results\nare depicted in Fig. 4, where the left plots detail the test MSE in log scale as a function of the\nfrequency, and the right plots show examples of the evaluated signals. We find that models achieve\nreasonable errors on the 1/24 frequency and its 2-harmonic frequency 1/12, where the red dashed"}, {"title": "6.2 DATA GENERATION TIME", "content": "Generating synthetic data introduces overhead to the computation pipeline. In what follows, we\ncompare the generation time of different synthetic approaches. We test this by generating one million\ntime points comprised of 1000 variates each of length\n1000 for each of the methods, Freq-Synth, TimesFM,\nForecastPFN, and KernelSynth. The times each method\nneeded are 0.1 seconds for Freq-Synth, 3 seconds for\nTimesFM, 14.6 seconds for ForecastPFN, and 138.2 min-\nutes for KernelSynth, presenting a significant advantage\nto Freq-Synth (see inset). For each reported result, we\ncalculated the average creation time of three datasets. In\naddition to the generation time, we also note that Freq-\nSynth is easy-to-code, requiring only a few lines of code\nas presented in the code snippet in App. 1."}, {"title": "7 CONCLUSION", "content": "Deep foundation models are often considered for zero-shot and few-shot time series forecasting.\nHowever, the findings of this study emphasize the challenges these models face when dealing with\ncomplex frequency patterns and limited data availability. By employing Fourier analysis, we find\nthat foundation and non-foundation models struggle to learn from multiple frequencies (frequency\nconfusion), and exhibit limited generalization to frequencies that were unseen during training (poor\nfrequency generalization). Toward addressing these challenging issues, we introduced Freq-Synth, a\nnovel synthetic data generation framework that strategically enriches or replaces real data, based on\nthe sampling rate of the target domain. Experimental results demonstrate that Freq-Synth improves\nthe performance and robustness of both foundation and non-foundation models in zero-shot and"}, {"title": "A APPENDIX", "content": "In this appendix, we provide additional information and details to supplement the main body of the\npaper. This includes supplementary method details in App. B, ablation studies in App. C, extended\ntables and results in App. E, and implementation details in App. D that were not included in the main\ntext. The purpose of this appendix is to provide readers with a more comprehensive understanding\nof the research methodology and results, as well as to offer further insights into the experimental\nprocedures and analysis."}, {"title": "B SUPPLEMENTARY METHOD DETAILS", "content": ""}, {"title": "B.1 FUNDAMENTAL FREQUENCY ESTIMATION", "content": "The proposed Freq-Synth relies on prior information to overcome potential frequency confusion\nand improve frequency generalization. In this section we list different methods for obtaining this\ninformation required by our method.\nSampling rate information provides us with insight into the length between each collected time-\nstep. This information can be further utilized to estimate the underlying fundamental frequency of\nthe signal by bridging it to a common frequency. Common frequencies act as anchors, and attract\na lot of valuable information due to their associations with strong natural or behavioral periods,\nnamely, days, weeks, months, and years. For example, a behavioral signal could be linked to weekly\nor monthly patterns, as consumer behavior may vary on weekends or during specific months. This\nbrings us to estimate the frequency based on the closest common frequency. For instance the sam-\npling rates 5m, 10m, 15m, 30m, 1h are cycles of daily periods in which case the corresponding\nfrequencies would be 1/288, 1/144, 1/96, 1/60, 1/48 and 1/24, respectively. A daily sampling rate\nis linked to a weekly 1/7 or monthly 1/30 (in our experiments we use a weekly rate). This contin-\nues for as long as a strong common frequency engulfs the sampling rate. This method is not free\nof challenges, for example the sampling rate may not be linked to the fundamental in cases where\nthe fundamental frequency is unnatural, e.g. 1/100. Nevertheless, it may serve as a useful tool for\nfrequency estimation.\nPeriodogram is a useful tool to estimate the spectral density of a signal (Schuster, 1898), given a\nsample series or a handful of samples one can utilize FFT to obtain the spectral density estimation.\nGiven the spectral density estimation, the fundamental frequency is the lowest dominant frequency\nwhich is accompanied by harmonics (higher frequencies that are a positive integer multiple of the\nfundamental frequency), hence the periodogram has the potential to provide us with harmonics\ninformation as well as the fundamental frequency.\nPrior frequency information, although not always intuitive, is another way of determining the fun-\ndamental frequency, this could be domain knowledge in a certain field as well as thorough analysis\nof the spectral density."}, {"title": "B.2 SYNTH-FREQ HYPER-PARAMETERS AND IMPLEMENTATION DETAILS", "content": "In what follows, we complement the description in Sec. 4 and provide details and descriptions of the\nparameters and their selected values presented in Tab. 4.\nTo implement Synth-Freq, we follow the next steps: 1) Create three datasets, each corresponding to\nh = 1, 2, 3 with the given parameters in Tab. 4. To create each dataset, it is recommended to use the"}, {"title": "B.3 FREQ-SYNTH IMPLEMENTATION", "content": "Here, we provide the python implementation for Freq-synth in Listing 1, covering the two steps\ndescribed in Sec. 4.2."}, {"title": "B.4 FREQ-SYNTH LIMITATIONS", "content": "Unfortunately Freq-Synth is not always effective for all zero-shot scenarios. In cases where the\nthere is a wider range of dominant frequencies, often leading to a signal with a higher degree of ran-\ndomness (Demirel & Holz, 2024), capturing a single or even a handful of fundamental frequencies\nbecomes challenging. In this particular case a single fundamental frequency based approach is not\nsufficient to represent the signal, and perhaps a mixed Freq-Synth approach is more suitable, as in\nTab. 2. A particular case with the Exchange dataset is further discussed in App.E.1."}, {"title": "C ABLATION", "content": ""}, {"title": "C.1 ABLATION: HARMONICS", "content": "We conduct experiments exploring the impact of different harmonics on the performance, showing\nthe results in Fig. 5. In this experiment, we created four Freq-Synth configurations, following the\nsteps in App. B, each with a fixed separate maximum number of harmonics corresponding to 1, 2,\n3, and 4. It is shown that introducing h > 1 improves performance in all cases except for Weather,\nwhere the results are mixed. A significant improvement is given in ETTm1, ETTh1, Traffic and\nElectricity with an approximate reduction of 0.1 in the average MSE values. Introducing harmonics\naids the model with focusing on higher periodic patterns that might be present in the data. For\nexample, an hourly sampled signal which is associated with the daily period might also include\nsemi-daily periods, e.g., night/day. Regarding h > 2, a small improvement is also visible in most\ndatasets, as it enables the model to focus on smaller fine-grained periods. Their significance with\nrespect to the MSE is however smaller due to the dominance of the larger periods, namely the\nfundamental frequency at h = 1."}, {"title": "C.2 ABLATION: TRAINING DATA SIZE AND NUMBER OF VARIATES", "content": "We aim Freq-Synth to mimic the structure of real datasets such as Weather, ETT, Traffic and others.\nTherefore, in Freq-Synth the rate of correlation between synthetic variates is adjustable with the\nparameter l, as many datasets also include different rates of variate correlations. In Freq-Synth,\nwe set the number of variates d = 5 and employ a single dataset size of 5,000, considering only\nthe minimal shapes for the decision making. Nevertheless, in this ablation we test the effect of the\ndataset size and the number of variates on performance, the results are presented in Fig. 6. The\nresults suggest that in most cases a number of variates greater than 1 is preferable with a lower MSE"}, {"title": "D IMPLEMENTATION DETAILS", "content": "In this section, we provide additional details regarding the experimental settings, models, and\ndatasets. Each experiment was carried out three times with three different random seeds to ensure\nrobustness and reliability of the results. Our objective was to maintain fidelity to the original param-\neters of each model, while establishing a unified framework for consistent comparison. Therefore,\nfor each model we employ the original implementation with slight modifications to allow a fair com-\nparison in a unified framework. Throughout the experiments, a lookback of 96 and a train,test and\nvalidation fraction split of 0.6,0.2,0.2 respectively for ETT datasets and 0.7,0.2,0.1 for the remaining\ndatasets was employed for training in accordance with the original protocol for the LTSF (Informer)\ndatasets (Zhou et al., 2021; Wu et al., 2021; Liu et al., 2024b). The reported results represent the test\nfraction of the data. As for the pre-trained models in Figs. 4, 9, 7, and 8 lookback values of 512 for\nTTM and TimesFM, and 672 for Timer were utilized, to align with the specifications of the original\ntrained models available online. All experiments were conducted with NVIDIA V100 32GB GPU,\nand each experiment was trained end to end on a single GPU."}, {"title": "D.1 MODELS", "content": "In this work we selected the following models for evaluation:\n\u2022 PatchTST (Nie et al., 2023). An in-domain TSF transformer-based model, introduc-\ning instance normalization, patching, a simple vanilla transformer and linear projection.\nPatchTST is a notable model, as many later released large-scale TSF models employ similar\ncomponents including instance normalization, linear projection, patching, patch masking\nand reconstruction.\n\u2022 GPT4TS (Zhou et al., 2023). A unified time-series model designed for a range of tasks in-\ncluding forecasting. GPT4TS uses a pre-trained frozen GPT-2 model, under the assumption\nthat language domain data could be adapted to time-series data. GPT4TS is an important\nmilestone towards foundation models as it showed success with employing a unified pre-\ntrained language transformer for a range of downstream tasks with fine-tuning.\n\u2022 TTM (Ekambaram et al., 2024) is a pre-trained model with a light-weight architecture\nwhich utilizes diverse resolution sampling with the implementation of patches of different"}, {"title": "D.2 DATASETS", "content": "In this work, we evaluate the proposed Freq-Synth on the common LTSF (Zhou et al., 2021) bench-\nmark datasets. We train the baseline models in Tabs. 1 and 3 on a subset of datasets from the Monash\nrepository (Godahewa et al., 2021). Specifically, we select the datasets that have a minimum length\nof 1,000 timesteps, in order to enable a training configuration of horizon length 720, which requires\neach example to be 846 timeseps long. The PEMS repository (Liu et al., 2022) is also included for\ntraining. This training setup is similar to the one employed in (Ekambaram et al., 2024). In Tab. 5,\nwe provide details regarding the selected datasets for training and testing. To ensure that certain\nlarge datasets do no dominate training, we limit the maximum number of examples per dataset to\n500,000 for training and validation. Selecting a subset of the entire training set is also a common\npractice in large unified training frameworks (Ekambaram et al., 2024; Liu et al., 2024d). In our\ncase, it can prevent large datasets with many examples to engulf the effect of smaller and medium\nsize datasets during training. The given train datasets cover a range of sectors such as nature, energy,\ntraffic and financial and various sampling rates. Most sectors and sampling rates of the evaluation\ndatasets are included in the train data, except for the sampling rate for ETTm1 and ETTm2."}, {"title": "D.3 SYNTHETIC DATASETS", "content": "In what follows, we provide additional details regarding the synthetic datasets discussed in Sec. 5.2.\n\u2022 TimesFM (Das et al., 2024): Synthetic generated data, where each channel selects up to\nthree possible components that are eventually added together, or multiplied (trend only)\namong ARMA process, mixture of cosines and sines, and piece-wise linear trends. In this\nwork, we provided results based on our implementation as the original implementation is\nnot available.\n\u2022 ForecastPFN (Dooley et al., 2024): They assume that there exists a shared distribution\namong real time-series datasets, which can be derived from natural periodic data, trend,\nglobal trends and noise. ForecastPFN synthetic data applies multiplication and addition to\ncreate signals that meet their prior distributions criteria. To handle extreme scales in their\ngenerated data, they introduce robust scaling and outlier removal, which is also employed\nfor ForecastPFN in Tab. 2."}, {"title": "E EXTENDED EXPERIMENTS AND RESULTS", "content": "In this section, we provide additional depictions and tables that expand the experiments in the main\nbody. The Fig. 10 depicts the Pearson correlation coefficient (PCC) between every pair of datasets\nincluded in Fig. 2. Values closer to 1 represent a higher Periodogram similarity."}]}