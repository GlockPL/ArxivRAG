{"title": "Academic Case Reports Lack Diversity: Assessing the Presence and Diversity of Sociodemographic and Behavioral Factors related with Post COVID-19 Condition", "authors": ["Juan Andres Medina Florez", "Shaina Raza", "Rashida Lynn", "Zahra Shakeri", "Brendan T. Smith", "Elham Dolatabadi"], "abstract": "Background: Understanding the prevalence, disparities, and symptom variations of Post COVID-19 Condition for vulnerable populations is crucial to improving care and addressing intersecting inequities.\nObjective: This study aims to develop a comprehensive framework for integrating social determinants of health (SDOH) into post-COVID condition (PCC) research. Specifically, it focuses on leveraging natural language processing (NLP) techniques to analyze disparities and variations in SDOH representation within PCC case reports, identify gaps in representation, and evaluate patterns of alignment and contradiction across sociodemographic and behavioral attributes.\nMethodology: The study involves the construction of the PCC Case Report Corpus, comprising over 7,000 case reports from the LitCOVID repository. A subset of 709 reports were annotated with 26 core SDOH-related entity types using pre-trained named entity recognition (NER) models, human review, and data augmentation to improve quality, diversity and representation of entity types. An NLP pipeline integrating NER and natural language inference (NLI) was developed to extract and analyze these entities. Both encoder-only transformer models and RNN-based models were assessed for the NER objective. Exploratory analyses, including frequency and co-occurrence (trigram) plots, were also performed to assess patterns in the presence of these attributes in academic case reports.\nResults: Fine-tuned encoder-only BERT models outperformed traditional RNN-based models in generalizability, achieving high F1-scores for certain classes such as race/ethnicity and marital status but struggling with others such as medical conditions and [psychoactive] substances. Importantly, RNN-based models portrayed greater overfitting on the training set, leading to greater performance on the optimization testing set, with similar sentence structures, and poor performance on the generalizability set, with distinct sentence structures and greater class sparsity. Exploratory analysis revealed variability in entity richness, with prevalent entities like condition, age, and access to care, and underrepresentation of sensitive categories like race and housing status. Trigram analysis highlighted frequent co-occurrences among entities, including age, gender, and condition. The NLI objective (entailment and contradiction analysis) showed attributes like \"Experienced violence or abuse\" and \"Has medical insurance\" had high entailment rates (82.4% and 80.3%), while attributes such as \"Is female-identifying,\" \"Is married,\" and \"Has a terminal condition\" exhibited high contradiction rates (70.8% to 98.5%).\nConclusion: Transformer-based NER models are effective in extracting SDOH information from PCC case reports. However, there is a scarcity of multiple sociodemographic factors in PCC-related academic case reports and an imbalanced representation of mentions aligned with groups of interest within dimensions such as gender, insurance status, and age.\nKeywords: Long COVID, Social Determinants of Health, Named Entity Recognition, Natural Language Inference, Large Language Models", "sections": [{"title": "1. Introduction", "content": "The acute phase of the COVID-19 pandemic may have passed, but its long-term impacts continue to affect millions worldwide (1\u20133). According to the World Health Organization (WHO) (4), 10-20% of COVID-19 cases lead to post-COVID condition (PCC), also known as long COVID. The Centers for Disease Control and Prevention (CDC) (5) reports 6.9% of U.S. adults have experienced PCC, with 3.4% still symptomatic. A November 2024 analysis by United Press International (UPI) (6) estimates that 23% of Americans who had COVID-19 may experience symptoms of PCC, highlighting the substantial and ongoing public health challenges posed by PCC. In response to the pressing need for timely mitigation of PCC, various research initiatives have been deployed and strengthened in the years following the peak of the COVID-19 pandemic. These efforts range from addressing the difficulties experienced by those living with PCC to the characterization of PCC phenomenology to quality of care improvement, and the identification of the biological, social and behavioral determinants associated with PCC development (7\u201311). Sociodemographic and behavioral determinants, such as race, income, and occupational status, are critical for understanding how structural social factors result in disparities in PCC prevalence, severity, and access to care (12\u201314). While studies focusing on the social and behavioral determinants of PCC remain limited, existing research highlights the disproportionate prevalence of PCC among certain population subgroups, including females, transgender individuals, and Hispanics (15\u201319). Importantly, as scientific knowledge of PCC continues to expand and deepen (20), a significant knowledge gap persists concerning why disparities in PCC prevalence amongst subgroups exist or how to reduce them.\nThe lack of comprehensive datasets that include both sociodemographic and behavioral variables, such as race, ethnicity, age, income, and occupational status, and PCC is a prominent barrier (21,22). For instance, structured clinical Datasets, such as Electronic or Medical Health Records often fail to include detailed sociodemographic variables, limiting analyses of how systemic inequities impact PCC outcomes, such as unequal access to healthcare and its impact on PCC outcomes (23\u201326). Research has highlighted the inadequacy of race and ethnicity data in electronic health records, an issue compounded by inconsistent collection and reporting practices (26-28). The scarcity of such data hinders efforts to identify actionable pathways for disparity reduction. Bridging these gaps requires advancements in data collection and integration. Furthermore, the integration of additional data sources, such as clinical case reports, could complement structured datasets, offering richer insights into patients' experiences and social contexts. By combining these reports with advanced natural language processing (NLP) techniques\u2014such as entity extraction (29), contextual understanding (30), language entailment (31), and classification (32)\u2014researchers can uncover complex relationships between sociodemographic factors and PCC development (33,34). While the utilization of NLP in the context of PCC is not novel, these efforts have been largely focused on the identification of clinical and biological entities, such as symptoms, diagnoses, and treatments (3,35\u201339). To our knowledge, NLP techniques have not been specifically tailored to extract a comprehensive set of sociodemographic entities in the PCC context."}, {"title": "2. Materials and Methods", "content": "The overarching objective of this study is to establish an approach for advancing the integration of SDOH into PCC research through state-of-the-art NLP methodologies. Specifically, this study aims to develop and apply a transformer-based NER model to automate the extraction of sociodemographic and behavioral determinants of health, analyze their representation and diversity within the PCC academic literature, and identify disparities and gaps in this domain. By doing so, this study seeks to inform improvements in data comprehensiveness and equity, ultimately guiding more inclusive and effective research and policy development for PCC. This study makes three contributions to the field:\nWe release an open-source, novel PCC Case Report Corpus comprising more than 7,000 case reports, annotated using the proposed fine-tuned BERT-base-uncased model. This corpus includes 26 sociodemographic, behavioral, and clinical entities such as age, vaccination status and medical condition, along with a robust data processing pipeline designed to improve reproducibility and facilitate future research in PCC. We are releasing our dataset to the research community for reproducibility of the experiments.\nWe introduce a comprehensive end-to-end NLP pipeline that integrates named entity recognition (NER) and natural language inference (NLI) techniques, enabling the extraction and entailment of entities from case reports. This pipeline utilizes a combination of data augmentation, regularization, rule-based methods and generative Al, and categorizes the extracted entities into meaningful groupings, providing a structured framework for further analysis.\nWe identify key gaps in the representation of SDOH attributes in PCC, such as underrepresentation of race and spiritual beliefs, and reveal patterns of agreement and contradictions in entity co-occurrences, such as disparities between documented insurance coverage and access to care."}, {"title": "2.1. Corpus Construction for PCC Case Reports", "content": "The PCC Case Report Corpus was developed by sourcing relevant case report articles from the LitCOVID repository (40) guided by a query incorporating the keywords \"Post COVID,\" \"Long COVID,\" and \"Post-acute COVID-19 syndrome.\" Inclusion criteria specified case reports published from January 1, 2020, to October 16, 2023, in English, featuring patients with a confirmed history of SARS-CoV-2 infection and documented PCC symptoms or complications. Only full-text articles were considered. Exclusion criteria included preprints, non peer-reviewed articles, review articles, meta-analyses, systematic reviews, studies focused exclusively on acute COVID-19, articles lacking detailed clinical information, and non-human studies.\nApproximately 10,000 papers meeting these criteria were retrieved from LitCOVID. PDFs of the relevant articles were converted into images, processed with optical character recognition (OCR), and structured using the John Snow Labs Health OCR tool (41) (see Figure 1 for the full pipeline). To minimize background noise, the case report sections were extracted from each document, as preliminary exploration showed that these sections contained most of the socioeconomic and clinical attributes relevant to the subjects of interest. Non-relevant content was systematically excluded using rule-based regular expressions, such that documents lacking case report sections were removed, and rules were iteratively refined based on observed errors. This process yielded a curated corpus of 7,172 case reports for further analysis. Three non-overlapping subsets, totaling 709 case reports, were selected for NER model development. These are referred to as subset 1, with 99 case reports, subset 2, with 402 case reports, and subset 3, with 208 case reports, as shown in Figure 1. Of these, subsets 1 and 2, totaling 501 case reports, were used for model training, with an 80/20 random split applied to create a"}, {"title": "2.2. Annotation Process", "content": "The annotation process consisted of four main steps of initial entity extraction using pre-trained NER models by John Snow Labs (JSL), human review, entity refinement and a combination of data filtration and augmentation. The entire dataset of 709 case reports underwent the initial entity extraction step, while steps of human review, and data filtration and augmentation were applied to targeted subsets 1 and 2-3, respectively. This tiered approach addressed two key challenges: first, that full manual annotation of all 709 reports would be resource-intensive, and second, that the use of a smaller subset for human annotation allowed for subsequent automated filtration and augmentation to be explored on the remaining reports. By integrating human-verified labels with additional, augmented data, this approach maximized both data quality and diversity, enabling the model to better capture the complexity of PCC literature."}, {"title": "Step 3: Entity Type Refinement", "content": "Following expert advice, a review of the WHO's SDOH framework (44), and under the guidance of three human annotators with health-related experience, we implemented an entity type refinement process. This was aimed at enhancing our model's classification accuracy while preserving critical sociodemographic dimensions relevant to our study. Importantly, this process entailed combining highly interrelated labels and eliminating entities outside of the research focus of this analysis. The entity label dimensions included, excluded and refined are summarized in Table 1.\nThe base models from JSL initially yielded over 45 distinct entities (resulting in 90 labels in CONLL format), of which 14 (28 in CoNLL format) were identified as outside of the scope of this analysis. More details on the refinement process are outlined in supplementary materials (sFigure 1). This refinement resulted in a set of 27 core entity types. For CoNLL format consistency, each label (except for 'O') was divided into 'B-' (beginning) and 'I-' (inside) sub-labels, resulting in a total of 53 distinct types for model training."}, {"title": "Step 4 - Filtration and Data Augmentation", "content": "Addressing the class imbalance, particularly the over-representation of the non-entity ('O') class, was essential for improving entity extraction accuracy. To tackle this, a two-stage filtration and augmentation strategy was implemented on subsets 2 and 3, aimed at enhancing the representation of rare entities while mitigating class imbalance. For the first stage, entity types with a probability below 90% were first reassigned to the 'O' class for added robustness. Subsequently, the entity types were reduced and refined following the process outlined in step 3. In addition, to reduce misclassification noise from numeric values, any numeric labels not identified as 'Age' (either 'B-Age' or 'I-Age') were also converted to 'O'. To further address the prevalence of the no-entity (\u2018O') class during training, sentences containing only 'O' class labels were removed from subset 2 alone, while subset 3, which is utilized for evaluation, was not subjected to this additional sentence-level downsampling technique.\nThe augmentation process was applied separately to subset 2, designated for training, and subset 3, designated for evaluation. For the training subset, three sentence templates were generated with GPT-40 (45) to minimize the presence of the 'O' class while retaining all entity types of interest. Both sentence templates and variations were manually reviewed for potential biases, and a manual review of a subset of the produced sentences ensured that there was not a disproportionate prevalence of a particular variation. These templates were tokenized, labeled, and stored in three base dataframes. From these structures, 3,000 sets of synthetic sentences were created by randomly combining rare (non-\u2018O') entities, with 1,500 derived from a complete entity variation dictionary (composed of the set of rare entities in the corpus and variations generated by GPT-40) and 1,500 derived from the variations generated by GPT-40 alone. Each synthetic sentence set was assigned a unique identifier and was randomly embedded within the case reports, seamlessly integrating with the dataset for model training. This augmented 402 case reports was then merged with the 99 human-reviewed case reports to form the final training dataset for the NER model training. To assess potential model overfitting and improve generalizability, the augmentation of subset 3 was designed with greater class sparsity and distinct sentence structures (i.e., different entity type orders) than those used in training. GPT-4 generated three distinct sentence templates, featuring higher 'O' class representation and varied label sequences. Importantly, gender was not included in all sentence structures given its greater presence pre-augmentation. As before, each sentence structure was tokenized, labeled, and structured into three base dataframes. Using these dataframes, 3,000 augmented sets of sentences were generated, with 1,500 sentences derived from a complete entity variation dictionary (composed of the set of rare entities in the corpus and variations generated by GPT-40) and with 1,500 derived from the variations generated by GPT-40 alone. Each synthetic sentence was assigned a unique identifier and was embedded randomly into the evaluation case reports to evaluate model performance. The entity variations produced by GPT-40 and sample prompts utilized to produce the entity type variations and sentence structures are outlined in supplementary materials (s1)."}, {"title": "2.3. NER Model Development", "content": "NER Models. In this study, both transformer-based models and traditional deep learning architectures are benchmarked to assess their capabilities for the selected NER task, with a particular emphasis on handling imbalanced entity classes and generalizing to unseen textual structures. The primary models of interest were BERT-based, encoder-only transformer models, due to their encoder architecture, which is especially suited for NER tasks due to its transformer encoder-only architecture (46). In particular, BERT-base-uncased (47,48) and DistilBERT-base-uncased (49) were selected due to their substantial pre-training on English language texts. In addition, the Biomed-NLP model, which utilizes the BERT architecture, was included in the model exploration due to its pre-training on a large body of biomedical texts (50). As baselines, Bidirectional LSTM (BILSTM), Recurrent Neural Network (RNN), and Gated Recurrent Unit (GRU) models are included due to their ability to process sequential dependencies (51\u201353).\nFor NER model building, to accommodate the 512-token limit per textual sample, each full string (case report text, plus augmentation in selected cases) was split into segments of up to 512 tokens while ensuring the preservation of sentence boundaries, to minimize contextual loss. For the BERT-based models, 512-token sequences were prepared with CLS, SEP, and PAD tokens, along with a mask layer. Padded sequences were generated for the BILSTM, RNN, and GRU models.\nAll BERT models were fine-tuned for 300 epochs with a learning rate of 1e-5. Other deep learning models were fully trained from random initialization for 10 epochs with a learning rate of 1e-9. All models employed a sparse cross-entropy loss function and were optimized using the Adam optimizer, with regularization techniques such as class weighting, sample weighting, and dropout layers to mitigate overfitting on majority classes. Importantly, a lower learning rate was implemented for the training of non-transformer models due to an observed propensity to overfit on the training data during early experiments. Conversely, to optimize the performance of transformer models, such that their performance would more closely assimilate that of non-transformer models on the test set, a higher number of epochs was implemented during training.\nFor model assessment, the macro F1 score is utilized as the primary performance metric. To account for the influence of the 'O' class performance in the macro F1 score, the macro F1 score excluding the 'O' class is also assessed. Other key performance metrics assessed include the macro One vs. One (OVO) Area Under the Receiver Operating Characteristic Curve (AUC) and the macro One vs. Rest (OVR) AUC scores. For the best-performing model, we also present class-specific F1 scores."}, {"title": "2.4. NLI Pipeline Development", "content": "To gain more detailed insights into the extracted entities and their corresponding types, a rule-based NLI pipeline was leveraged. Importantly, the entities were utilized as the strings to be assessed, and statements were crafted by entity type to assess entailment, contradiction and neutrality/non-applicability of the entities. These statements are outlined in supplementary materials (sTable 2). Given the significant variation in meaning and scope among our entity types, the selected statements encompass both the presence and absence of attributes, as well as other meaningful binary distinctions in the data. To support this analysis, we generated lists of words indicating 'entailment' and 'contradiction' for each entity using prompts in GPT-4. We further enhanced these lists by augmenting them with synonyms from the NLTK library (54). Using RegEx each extracted entity was matched against the generated lists, returning 'Entailment,' 'Contradiction,' or 'Not Applicable' as appropriate. Importantly, only tokens marked with 'Entailment' or 'Contradiction' are considered, given that those marked as 'Not Applicable' are prone to contain noise and other variations out of the scope of this pipeline. Manual validation on a subset of matches was performed to assess RegEx accuracy and refine patterns. The entailment and contradiction sets (produced by GPT-40), and the corresponding prompt, are outlined in supplementary materials section D.\nStatement selection. For entity types including \u2018Social_Support,' \u2018Substance,' 'Marital_Status,' 'Disability,' 'Housing,' 'Insurance_Status,' 'Violence_Or_Abuse,' \u2018Employment,' \u2018Vaccine,' 'Mental_Health,' and 'Access_To_Care.', the statements indicate the presence or absence of attributes.\nFor more complex labels representing multiple categories or continuums, the statements focus on insights related to sensitive or at-risk groups. or to highlight other relevant binary breaks in the data. For 'Education,' the statement was crafted to create a break between terms specifying a higher formal education level (high school or above) from those that do not. Importantly, having a general education development (GED) diploma has been associated with better health outcomes later in life (55). For \u2018Race_Ethnicity,' the statement generates a binary break between white/caucasian and non-white, which is significant given the mechanisms of structural racism and their effects on the health experience and outcome of non-white individuals (56). We recognize that this binary classification is limited, as it may not capture intersectional nuances; however, we justify this choice based on the goals of the study to provide initial insights for further study. For \u2018Exercise', the statement is aligned with the documented effect of exercising regularly on the immune response, particularly with regard to COVID-19 (57). For 'Geographic_Entity' and 'Language,' the statements were chosen in conjunction to reflect the effect of a language barrier on the health care experience, such that it can be observed if there is a mismatch between the language spoken in the country of origin/care location and the primary language (58). Importantly, both statements are dichotomized as 'English or not' given that our selected texts are in English, assessing, therefore, if there is an English language dominance in the location and language of subjects in the case reports. For \u2018Severity,' the statement is crafted to identify if the observed symptoms are highly severe or not, which can be of interest to observed potential patterns between long COVID and symptom/condition severity.\nIn addition, for 'Diet,' the statement aims to capture the relationship between dietary restrictions and health, which has been associated with immune responses and other health conditions (59,60). For 'Income,' the statement was crafted to reflect the effect of higher income level (or lack thereof) on access to health care (61). Given that our corpus hails from distinct countries, with distinct thresholds for upper-middle income, we do not include numeric measures in the entailment and contradiction sets. For 'Family_Member,' the statement was crafted to capture the social support provided by progeny, which is an essential form of caretaking in multiple cultural settings, with an associated impact on parental health (62). For 'Sexual_Orietation,' the statement was selected to align with the discourse of discrimination and barriers to care faced by non-heterosexual individuals (63). For \u2018Gender,' the statement was selected to reflect the discussed positive associational relationship between female gender, sex on the development of PCC (15,16). For 'Spiritual_Beliefs,' the statement was crafted to align with the historical privilege faced by those of catholic and christian belief systems (64), and the lack thereof faced by several other faith systems, which can be reflected in experiences of discrimination in health care settings (65). Lastly, for 'Age,' 'Treatment,' 'Condition' and 'Severity' the statements were crafted to highlight at-risk groups including older adults and other inmuno-compromised groups, such as those with a highly invasive treatment and those with highly severe, rare, chronic or terminal conditions (66,67)."}, {"title": "3. Results", "content": "The distribution of all 26 ground truth entity types (excluding the NuLL entity) across the case reports for the model training and generalization evaluation before and after augmentation is illustrated in Figure 2. Post-augmentation, the model training set and the generalization evaluation set contain 693,476 and 711,743 entities, respectively. The complete collection of case reports contains 1,405,219 entities. 'Condition', 'Gender', 'Access to care', 'Age', and 'Employment' are the most frequent entities in the 709 case reports leveraged for model training and evaluation. The greater presence of these entity labels reflect biases and oversimplification of SDOH entity dimensions in PCC case reports. As the least prevalent entities, label dimensions such as \u2018Spiritual_Beliefs' and 'Sexual_Orientation' saw the greatest effect in variational diversity and relative frequency post-augmentation (increasing from 0.0% to over 0.8% on the training and generalization evaluation sets)."}, {"title": "3.2. Comparative benchmarking analysis of NER models", "content": "In benchmarking the RNN-based models, including BiLSTM, BERT, DistilBERT, and BioBERT, we evaluated their performance in extracting 27 entity types on the optimization testing set and generalization evaluation set, as detailed in Table 2. As the primary metric of model assessment, macro F1 score, excluding the 'O' class, is utilized. Excluding the 'O' class reduces bias from overrepresented non-entity annotations, highlighting the model's ability to accurately classify diverse entity types. The macro-average results for these benchmarks are presented, demonstrating the comparative performance of each model in this task with Macro F1-score of .72 excluding O and macro AUC of .99. We show that BERT models are on average more generalizable than the RNN-based models, although RNN models outperform BERT for the optimization testing set.\nThe model demonstrated strong performance in classes such as \u2018I-Race_Ethnicity' and 'I-Marital_Status', both achieving an F1-Score of 0.99, indicating high precision and recall (supplementary materials STable3). Other well-predicted classes included 'I-Language' and 'I-Spiritual_Beliefs' (0.98), and 'B-Education' and 'I-Violence_Or_Abuse' (0.95). On the contrary, the least predicted classes had notably lower performance. \u2018B-Condition' and 'I-Condition' were the lowest, with F1-scores of 0.17 and 0.14, respectively, indicating difficulties in recognizing specific health conditions. 'B-Gender' and classes like 'B-Diet' and 'B-Insurance_Status' also underperformed, with scores below 0.40. Exploratory analysis of a subset of classifications in each class revealed that misclassifications stem from model limitations to various health conditions, and to ambiguous mentions and tokenization artifacts."}, {"title": "3.3. Exploratory Analysis of the Entities Extracted by the Best-performing Model", "content": "The best-performing model, a fine-tuned BERT-base-uncased, was applied to all 7,172 extracted case report sections. A total of 1,369,863 entities were extracted across 26 distinct entity type dimensions, excluding the \u2018O' entity (amounting to 2,097,047 entities alone). The distribution of entity counts per case report is illustrated in Figure 3a. We observed variability in entity richness across the corpus, ranging from 6 to 26 distinct non-'O' types. The majority of case reports contained 18 to 20 distinct entity types, with 19 being the most common, observed in 1,204 case reports. A small subset of reports (18) included 25 distinct entity types, while only one case report encompassed all 26 non-'O' entity types.\nThe frequency of non-\u2018O' entity types, out of all non-\u2018O' entities is depicted in Figure 3b. The most frequently mentioned categories include biological components labelled as 'Condition' (37.27%), 'Age\u2019(10.11%), \u2018Access_To_Care' (7.74%), \u2018Treatment' (7.56%), \u2018Severity' (5.36%), 'Mental_Health' (5.15%), \u2018Gender' (4.66%), and 'Substance' (4.33%). Conversely, entities such as 'sexual orientation' (0.18%), \u2018spiritual beliefs' (0.27%), \u2018Race_Ethnicity' (0.01%), and 'housing status' (0.30%) are among the least represented, aligning with their sensitive nature.\nAmong the top 25 most frequently occurring entities, we visualized the frequencies of three-entity sequences (trigrams) in Figure 2c, where the order of occurrence Is considered. Among the most frequent entity type trigrams, \u2018Age,Gender,Condition' stands out with a frequency of 0.72%, followed by 'Age, Severity, Condition' at 0.52% and 'Condition:Gender:Access_To_Care' at 0.45%. Other notable trigrams include combinations of 'Access_To_Care','Gender','Condition', 'Severity', 'Treatment', 'Age', 'Family_Member', 'Mental_Health' from 0.44% to 0.28%."}, {"title": "3.4. Entailment and Contradiction Patterns Across Key Attributes", "content": "All extracted entities were grouped by their respective entity types and matched with the corresponding statements allowing for a clear comparison of how each entity aligns with or contradicts the defined relationships (Figure 4). The analysis of entailment and contradiction across various entity types reveals several key trends (Figure 4a). Notably, \"Experienced violence or abuse\u201d and \u201cHas medical insurance\u201d are predominantly entailed, at 82.4% and 80.3%. Several attributes, including \u201cUtilizes psychoactive substances,\u201d \u201cHas social support,\u201d \u201cExercises regularly,\u201d \u201cIs employed,\u201d and \u201cHas access to care,\u201d display moderate levels of entailment while also showing notable contradictions. In contrast, attributes such as \u201cIs a senior adult,\u201d \u201cIs female-identifying,\u201d \u201cIs married,\u201d \u201cIs heterosexual,\u201d and \u201cHas a terminal, rare, or chronic condition\u201d exhibit high levels of contradiction, with contradiction rates reaching as high as 97.5%, 98.5%, 70.8%, 81.8%, and 88.5%. Other attributes, such as \u201cIs homeless,\u201d \u201cHas high school education,\u201d and \u201cIs white/Caucasian,\u201d show more variability in their levels of entailment and contradiction. To further evaluate whether these patterns persist in the full-text context, we removed prior matching restrictions on the extracted entities (Figure 4b). This comparison revealed consistent trends across most entity types, regardless of the applied restrictions."}, {"title": "4. Discussion", "content": "Our study demonstrates the potential of LLMs, particularly BERT-based models, in addressing SDOH-specific NER tasks. The use of NLP to gain insights into health-related problems has been an area of research since the 1950s (68), but its large-scale application gained significant momentum during the COVID-19 pandemic. This shift was exemplified by initiatives such as the CORD-19 competition (69,70), which coincided with the emergence of transformer-based models (71) and significant advancements in NLP methodologies and applications (72). These developments marked a transformative era in NLP, enabling unprecedented breakthroughs in understanding and analyzing health data (73,74). By proposing a generalizable framework for extracting these attributes, we demonstrate the viability of leveraging LLMs for this purpose. Notably, our findings indicate that BERT-based encoder-only models achieved superior classification performance on the generalization set, underscoring their efficacy in handling complex, domain-specific NER tasks. Previous studies have demonstrated the superior generalization capabilities of BERT models compared to both traditional deep learning and also decoder based transformer models in NER tasks, largely due to their self-attention mechanisms (75,76). Our findings align with these benchmarks, providing further evidence of BERT's robustness in handling unseen sentence structures and addressing class sparsity (47,49). In contrast, the comparatively lower performance of the BiomedNLP model is attributed to its pre-training on domain-specific biomedical texts, which limits its flexibility and adaptability (50).\nThe exploratory analysis revealed significant gaps in sociodemographic representation within PCC case reports, with attributes like race, spiritual beliefs, and housing status appearing infrequently. In contrast, age, gender, mental health, and access to care were more frequently discussed. Additionally, the co-occurrence patterns of biomedical and sociodemographic factors often followed a structured narrative, with age and gender commonly contextualizing conditions and symptoms. While case report sections typically contained 18 to 20 non-\u2018O' distinct entities dimensions, it was rare for a report to encompass all dimensions; only one of 7,172 reports included predictions for all 26 identified labels. These findings align with prior research highlighting the scarcity of robust sociodemographic representation in clinical PCC datasets (21-24). Our analysis confirms that academic PCC-related case reports similarly lack diversity across multiple attributes, further underscoring the need for improved documentation and reporting practices to enable more equitable and comprehensive analyses in PCC research. Lastly, an analysis of the most frequent label trigrams reveals that 'Condition' commonly appears in the final position, preceded by entities such as 'Age', 'Gender', and 'Severity'. This pattern suggests two key findings: first, academic case reports often adopt a structured approach to representing the patient experience; second, this representation is frequently constrained to a limited subset of sociodemographic factors.\nOur key findings highlighted that mentions of attributes such as 'having access to care', 'being vaccinated against COVID-19', 'exercising regularly', 'having medical insurance', 'social support', and 'experiencing violence or abuse' were predominantly in agreement, reflecting positive representation. In contrast, mentions of being 'female-identifying', 'white/Caucasian', 'heterosexual', \u2018senior', or \u2018having a terminal, rare, or chronic condition' were most frequently classified as contradictory to the statement, suggesting potential underreporting or biases. Some of these findings highlight discrepancies with prior research, particularly concerning the underrepresentation or absence of mentions related to being female-identifying, unvaccinated for COVID-19, or a senior adult. Previous studies have identified these groups as potential at-risk populations in the COVID-19 context, with discrimination being significantly associated with prolonged COVID-19 symptoms (15,16,(18),61,71). Research has also linked female gender and sex to a higher prevalence of PCC (15,16) and highlighted socioeconomic status as a significant factor in PCC development (17). However, these insights should not be interpreted as evidence against previous findings. Instead, they may point to underlying biases in academic research and structural barriers that deter these groups from participating in clinical studies. This aligns with earlier work highlighting selection bias and the underrepresentation of older adults and women in clinical research (84, 85). Additionally, individuals unvaccinated for COVID-19 often face societal discrimination, which may further impact their access to care and inclusion in research (86). These patterns underscore the need to address systemic biases in data collection and study design to ensure more equitable representation, such as standardizing sociodemographic reporting protocols and promoting the inclusion of underrepresented groups in clinical research."}, {"title": "4.1. Limitations and Future work", "content": "While our NLP approach effectively identifies many sociodemographic determinants in a PCC-related corpus, its performance in predicting medical symptoms and conditions remains limited. This challenge arises from the vast diversity of diseases and symptoms, which would require pretraining on a large, domain-specific medical text corpus. Our experiments with BiomedNLP demonstrated low performance in the NER task, however, highlighting the need for better-tailored models. The analysis is inherently influenced by corpus-related biases, including a focus on English-language texts and an overrepresentation of individuals with access to care, in addition to biases associated with GPT. Additionally, while we attempted to comprehensively categorize entailment and contradiction tokens using synonyms, some relevant terms may have been overlooked. Importantly, the distributions highlighted by our analysis should not be interpreted as robust associations but rather as exploratory insights.\nTo address these limitations, future efforts should focus on enhancing the documentation of underrepresented attributes, such as race, housing status, and sexual orientation, to support equitable Al-driven analyses in PCC research. Future work could involve pretraining a BERT or other transformer models on a larger PCC-specific corpus to improve performance, though this would require significant computational resources. Evaluating additional biomedical models beyond BiomedNLP may also enhance NER outcomes. To better understand interactions between entities, future research could develop an ML-driven relation extraction (RE) pipeline to explore how SDOH factors interrelate. Extending this analysis to other patient populations would provide a broader understanding of sociodemographic mentions across diverse health contexts. Additionally, the insights into PCC-entity representation could inform policy discussions on diversity and inclusion in academic research. Adapting the pipeline to other health domains could also offer a more comprehensive view of sociodemographic reporting in case reports. Finally, given the evolving definition of social determinants of health, all future work must entail an assessment of the relevance and comprehensiveness of the included entity label dimensions."}, {"title": "5. Conclusion", "content": "This analysis benchmarks traditional deep learning models and encoder-only transformer models for Named Entity Recognition of sociodemographic entities in academic case reports related to Post COVID-19 Condition. Importantly, it not only provides a model comparison assessment, but provides a comprehensive pipeline equipped with various annotation, augmentation, cleaning and regularization techniques, culminating in a timely model that can be utilized by researchers in the field. Notably, encoder-only transformer models were found to outperform traditional deep learning models on unseen data with distinct sentence structures, and greater class sparsity. Furthermore, the best performing model on the validation data [BERT base uncased"}]}