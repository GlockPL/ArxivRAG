{"title": "Command-line Risk Classification using Transformer-based Neural Architectures", "authors": ["Paolo Notaro", "Soroush Haeri", "Jorge Cardoso", "Michael Gerndt"], "abstract": "To protect large-scale computing environments necessary to meet increasing\ncomputing demand, cloud providers have implemented security measures to monitor\nOperations and Maintenance (O&M) activities and therefore prevent data loss\nand service interruption. Command interception systems are used to intercept,\nassess, and block dangerous Command-line Interface (CLI) commands before they\ncan cause damage. Traditional solutions for command risk assessment include\nrule-based systems, which require expert knowledge and constant human revision\nto account for unseen commands. To overcome these limitations, several end-\nto-end learning systems have been proposed to classify CLI commands. These\nsystems, however, have several other limitations, including the adoption of general-\npurpose text classifiers, which may not adapt to the language characteristics of\nscripting languages such as Bash or PowerShell, and may not recognize dangerous\ncommands in the presence of an unbalanced class distribution. In this paper, we\npropose a transformer-based command risk classification system, which leverages\nthe generalization power of Large Language Models (LLM) to provide accurate\nclassification and the ability to identify rare dangerous commands effectively,\nby exploiting the power of transfer learning. We verify the effectiveness of our\napproach on a realistic dataset of production commands and show how to apply our\nmodel for other security-related tasks, such as dangerous command interception\nand auditing of existing rule-based systems.", "sections": [{"title": "Introduction", "content": "The growth of security threats has encouraged organizations to develop effective security\nsolutions to safeguard digital applications, data and resources [1, 2, 3]. Solutions target\nthe prevention of incidents and malicious attacks. In large IT systems, Operations and\nMaintenance (O&M) personnel accesses remote production systems to configure and\nrepair services. O&M operators execute thousands of operations each day, and incorrect\nor malicious commands can cause major system failures and data losses resulting in\nhigh monetary and reputation costs."}, {"title": "Background", "content": "In this section we present the foundations of command-line security and the command\nrisk classification problem (Command-line Security) and a summary of related work\n(Related Work)."}, {"title": "Command-line Security", "content": "Large-scale computing environments require high levels of availability and reliability\nto fulfill Service Level Agreements (SLA). Due to the large scale of devices and\nservices being executed, failures are, albeit rare, inevitable. To this end, Operation and\nMaintenance (O&M) personnel operates to resolve and minimize the impact of failures\non the correct runtime of computing services.\nO&M requires operators to access remote systems to configure and repair services\nvia Command-line Interface (CLI). Providing free access to remote production systems\nposes two major security challenges, namely 1) the possibility of external attackers\ngaining unauthorized access to systems and 2) the possibility of operators acciden-\ntally performing harmful operations and damage service availability. For this reason,\noperators typically access remote hosts via a bastion host, which allows to review,\napprove, and execute commands without establishing direct connection to systems [4].\nBastion hosts implement an interception system, which captures executed commands\nand analyses them before granting execution rights.\nThe need to recognize and block dangerous commands before their execution\nrequires an algorithm to estimate command risk. Different risk classes may be defined,\nand each class may be associated with the necessary privilege to execute commands.\nCommand risk classification is then the association of each incoming command to one\nof the predefined privilege and/or risk classes. Based on the classifier decision and the\ncurrent user privileges, the bastion host allows or blocks the current command, and\nreturns output the user.\nA common solution for estimating command risk is a rule-based classifier, where\nIF-THEN-ELSE rules define which commands are allowed (or whitelisted) and which\ncommands are blocked (or blacklisted). The rules may be defined based on the expertise\nof O&M operators and the historical records of executed commands, and stored in\na configuration database that allows to periodically revise and update them. Rule-\nbased systems may implement a specification syntax, based on regular expressions or\nquantifiers, to cover a larger set of commands with a single expression.\nRule-based systems are simple, easily configurable and explainable. However, they\nalso have several limitations:\n1. new combination of programs and arguments may be executed, for which the\nexisting rules are not suitable;\n2. the risk level assigned to rules by operators based on their expertise, may diverge\nfrom the true risk of commands;\n3. they require a default handling action when a command does not match any\nexisting rule. This default action is however limiting, as a \"default block\" strategy\nmay hinder important operations during incident response, while a \"default allow\"\nmay allow dangerous operations to be executed;\n4. dealing with the complexity of command-line syntax is difficult without resorting\nto a complex pattern language for rules (see Figure 1)."}, {"title": "Related Work", "content": "Hendler et al. [2] evaluate several machine learning models for malicious PowerShell\ncommand detection. Both traditional NLP (n-gram, BoW) and deep neural network\nmodels (CNN [7], LSTM) are considered, including an ensemble combining a 3-gram\nand a CNN model, which yields the best performance. During the preprocessing phase,\ncharacters are one-hot encoded, with case information at character-level provided as\nan input binary flag. The CNN model applies 1D convolutional layers based on the\narchitecture proposed by Zhang et al. [7] on input commands padded to fixed length.\nThe use of character-level one-hot encoding with a closed vocabulary does not allow\nto effectively model the semantics and inter-relationship between input tokens. To this\nend, we choose to apply Byte-pair Encoding [8] and Wordpiece embeddings [9], which\nenable the model to learn the most frequent tokens directly from the training data and\nassociate co-occurring and meaning-related tokens in the embedding space. Moreover, a\nfully-supervised model requires a large quantity of training data to achieve high accuracy.\nOur model can leverage information learned during pretraining for classification and\nthus only requires a limited dataset for finetuning to the context-specific tasks, providing\nmore flexibility at a reduced effort.\nYamin et al. [10] use Naive Bayes and CNN models on command-line arguments\nto classify PowerShell commands as malicious. They evaluated their classification\naccuracy on a dataset composed of 14 categories of commands. Their approach focuses\non PowerShell and obfuscated command detection. Results are evaluated in terms of\naccuracy (96%) and the dataset class distribution is not provided. Because dangerous\ncommands are rare, the class distribution is typically highly unbalanced, which allows\nto construct trivial classifiers that can achieve high accuracy. For this reason, we focus\non evaluating our model on the positive class (i.e. dangerous commands) by measuring\nprecision and recall, to ensure our model can also classify these rare yet important\ncommands.\nPyComm [11] is a malicious command detection model for Python scripts. It is\nbased on random forest applied on a hybrid set of static features and Python source code\nstrings. During evaluation, they obtained an accuracy of 0.955 with a recall of 0.943.\nDifferently from them, our approach focuses on command-line risk classification and\nrely exclusively on the command string.\nThe similarity of commands is estimated by processing the documentation of com-\nmands using NLP techniques."}, {"title": "Approach", "content": "In this section, we describe our approach for command risk classification. We describe\nthe system architecture and the training procedure."}, {"title": "System Architecture", "content": "Our risk classification system is based on Bidirectional Encoder Representations from\nTransformers (BERT) [12]. BERT is a deep language representation model based\non transfer learning [12]. BERT has empirically shown to improve performance in\nmany language understanding tasks, including question answering, text classification,\nsentence pair completion, named-entity recognition, etc. [12, 5, 13]. In particular,\nBERT has shown to provide more effective results for discriminative tasks, compared to\nthe effectiveness of other approaches (e.g. GPT3 [14]) for generative tasks. Therefore,\nwe select BERT for our command risk classification task.\nThe key concept of BERT is to pretrain a transformer deep neural network on\ncontextual tasks, such as masked token and next sentence prediction, to learn the\nlanguage syntax and the contextual relationships between tokens present in the language.\nBecause these contextual tasks are self-supervised learning tasks, the pretraining step\nin BERT does not require any labeled data, and a large corpus of the target language\nis sufficient. In a second phase, called finetuning, the pretrained BERT model can be\nadapted for the specific task to perform (e.g., text classification). In the finetuning phase,\nthe BERT model learns the new task while retaining language knowledge from the\npretraining step, enabling a higher level of generalization.\nThe complete system architecture is shown in Figure 2. Our approach is composed\nof a preprocessing algorithm and a neural network architecture, which is trained as\ndescribed in Section Training."}, {"title": "Training", "content": "Figure 3 summarizes the construction phases of the AI classifier. Our training procedure\nis composed of three steps: dataset collection, BPE training, BERT training (pretraining\nand BERT finetuning)."}, {"title": "Dataset Collection.", "content": "For our pretraining phase, requiring large-quantity of raw command data, we pro-\ngrammatically collected a corpus of Bash files from publicly available data. First, we\nsearched for GitHub repositories with the Bash language tag. Then, from each of these\nrepositories we selected only Bash-related files, by matching specific criteria (first line\ncontains a shebang, or the file has a .sh extension). This resulted in a final collection of\n71164 Bash scripts, amounting to about 500 MB."}, {"title": "BPE Training.", "content": "During this phase, our corpus of Bash commands is used to learn the tokens and patterns\nof the scripting language in use, using the BPE algorithm described above (System\nArchitecture). The frequency of different character-level patterns is estimated based on\nthe observed data, to produce a vocabulary of V learned tokens of size and an encoding\nalgorithm to extract them from raw commands string."}, {"title": "BERT Training.", "content": "The BERT pretraining step requires to train the transformer network on self-supervised\ncontextual tasks. Therefore, we first annotate each sample from our Bash corpus with\ncorresponding task labels. After this annotation step, the total dataset size amounts\nto 15 GB. During the pretraining phase, the transformer model is pretrained on the\ncontextual tasks described in [12]: bidirectional masked LM, by masking 15% of\nsequence tokens at random; and next sentence prediction, i.e. by predicting the next\ncommand in the sequence of commands inside a Bash script, or a random command.\nAfter pretraining, only the network backbone, which outputs, a $h_i$-long representation\nof the input command is retained, while the contextual output layers are dropped.\nDuring the finetuning phase, the pretrained transformer backbone is extended with\nan additional classification layer block to enable command risk classification. The\nclassification layer block is composed of a FC linear layer preceded by a dropout layer\nand followed by a softmax normalization layer. For this training phase, a supervised\ndataset of commands, annotated with risk classes, is used. The network pipeline\nis trained end-to-end using the softmax loss, to maximize the log likelihood of the\ntraining dataset. The network weights are updated using gradient descent, with gradients\ncomputed via back-propagation."}, {"title": "Experimental Setup", "content": "In this section, we describe the experimental setup used in our training experiments, as\nwell as for the evaluation of all prediction models (Evaluation Metrics).\nWe implemented our approach and all evaluated models in Python. We selected\nthe 4/256 BERT mini model as our architecture. All network layers utilize GELU\nactivation functions and are trained using the Adam optimizer. The full list of numerical\nhyperparameters is shown in Table 2. We pretrained our transformer model for 350,000"}, {"title": "Results", "content": "Table 3 presents the comparison of the different models under evaluation, in terms of\nprecision, recall, and F1-score on the two positive classes RISKY and BLOCKED.\nOur approach achieves the highest absolute score for 8 of 9 metrics measured. Over\nthe second-best result, the precision in detecting RISKY commands is improved by\n1.13%, while the recall is increased by 1.30%. For BLOCKED commands, we measured\nan increase of 16.7% in precision and 25.0% recall. On average, for all dangerous\ncommands, our approach can improve precision by 1.13% and recall by 1.40%. The\nincrease in F1-score for all dangerous commands is 1.27%. If we consider the ratio of\ndangerous commands (20%) and we assume an average number of 3M commands/month\nexecuted in production, which is consistent with our experience, such increase in\nrecall results in approximately 60k additional dangerous commands intercepted during\noperations, which may cause an equivalent number of potential incidents.\nTo show the transfer learning abilities of our model, we also evaluated the ability of\npredictors to recognize dangerous commands with limited training data. We randomly\nsampled 100, 200, 500, 1000, 20000 commands from our training set and trained\nthe corresponding models. Results are reported in Figure 4. It can be observed how\nour model achieves the best F1 performance on dangerous commands for all reduced\ndataset sizes, while requiring one order of magnitude less samples to achieve comparable\nF1-score results."}, {"title": "Use Cases", "content": "The BERT model we trained with BPE can be applied in many industrial applications\nrelated to the command-line, which is the entrance door to the cloud. We here describe\nseveral use cases for our model that we have used or plan to use in the future.\nThe first use case we discuss is online risk classification. Command risk can be\nevaluated online to block dangerous commands during interception.\nA scheme of online risk classification is shown in the last segment of Figure 3.\nFirst, commands executed over remote terminal are intercepted by an access control\nsystem (e.g. a bastion host). Then, the risk of the intercepted command is evaluated\nusing our LLM-based classifier. The classifier can be deployed directly on-site, or\naccessed via an inference API to take advantage of specialized hardware. Commands\nand classifier predictions can be stored to permanent storage for offline analysis. Based\non the prediction outcome, commands are either blocked or allowed, and the operation\noutput displayed to the operator.\nSystem auditing is the practice of analyzing the quality of an existing system to\nvalidate its results and consider potential improvements. In the context of command\ninterception systems, an existing risk classifier can be audited by analyzing if its risk\npredictions correspond to the true risks of the commands, to support the identification\nof errors and the creation of new classification rules.\nWe applied our model for auditing an existing rule-based system. An example\nof our auditing pipeline is shown in Figure 1. The existing system is composed of a\nrule-based risk classifier, a rule management system, and database store of rule-based\nand AI-based predictions. When revision of existing rules is needed, a report of non-\nmatching of predictions from the rule-based and AI models is generated. As for the\nmajority of commands the two predictions will correspond, it is sufficient to report only\nthe commands where the two predictions differ. An human expert can then decide if the\ndiscrepancy reported by the AI model is correct and update the corresponding rule in\nthe management system. This comparison speeds up the work of expert reviewers, as\nthey only need a small portion of commands, where the two predictions do not match.\nThanks to the high precision of our classifier, if a command is reported as dangerous,\nit is likely that an rule update action must be taken. Using our model, we were able to\ndiscover several new risky commands that were not detected by the rule-based system.\nWe have also considered our transformer model for command categorization. Com-\nmands can be assigned to predefined categories based on their function (e.g. networking,\nfilesystem, scripting, third-party command). For O&M operators it is convenient to\nknow the category of a command for several reasons: to identify similar commands\nand construct new rules, to clarify the meaning of unknown commands and speed up\nauditing, to understand which type of commands are currently not identified by the\nsecurity system. The command categorization problem is comparable to command\nrisk classification, as both can be achieved using the techniques described in this work\n(provided ground-truth labels are available). In our experiments, we considered cate-\ngories from manpages documents [20] as potential source of command categorization\nlabels. First, commands are parsed to extract program names. Then, program names are"}, {"title": "Conclusion", "content": "In this paper, we proposed a language model for the command-line language, which\nis applicable to several NLP-related tasks. We showed how to apply our approach for\ncommand risk classification. Our language model leverages the contextual knowledge\nlearned during pretraining to achieve higher classification accuracy and pinpoint danger-\nous commands effectively. We described the procedure to train our model according to\na realistic distribution of production commands. We evaluated the accuracy of our ap-\nproach and compared it to a several existing approaches for command risk classification.\nOur results show that it can improve detection for rare classes of commands."}]}