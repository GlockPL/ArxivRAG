{"title": "LOCAL VS. GLOBAL: LOCAL LAND-USE AND LAND-COVER\nMODELS DELIVER HIGHER QUALITY MAPS", "authors": ["Girmaw Abebe Tadesse", "Caleb Robinson", "Charles Mwangi", "Esther Maina", "Joshua Nyakundi", "Luana Marotti", "Gilles Quentin Hacheme", "Hamed Alemohammad", "Rahul Dodhia", "Juan M. Lavista Ferres"], "abstract": "Approximately 20% of Africa's population suffered from undernourishment, and 868 million people\nexperienced moderate to severe food insecurity in 2022. Land-use and land-cover maps provide\ncrucial insights for addressing food insecurity, e.g., by mapping croplands. The development of\nglobal land-cover maps has been facilitated by the increasing availability of earth observation data and\nadvancements in geospatial machine learning. However, these global maps exhibit lower accuracy\nand inconsistencies in Africa, partly due to the lack of representative training data. To address\nthis issue, we propose a data-centric framework with a teacher-student model setup, which uses\ndiverse data sources of satellite images and label examples to produce local land-cover maps. Our\nmethod trains a high-resolution teacher model on images with a resolution of 0.331 m/pixel and\na low-resolution student model on publicly available images with a resolution of 10 m/pixel. The\nstudent model also utilizes the teacher model's output as its weak label examples through knowledge\ndistillation. We evaluated our framework using Murang'a County, Kenya, as a use case and achieved\nsignificant improvements, i.e., 0.14 in the F\u2081 score and 0.21 in Intersection-over-Union, compared\nto the best global map. Our evaluation also revealed inconsistencies in existing global maps, with a\nmaximum agreement rate of 0.30 among themselves. Insights obtained from our cross-collaborative\nwork can provide valuable guidance to local and national policymakers in making informed decisions\nto improve resource utilization and food security.", "sections": [{"title": "1 Introduction", "content": "Land-Use and Land-Cover (LULC) maps are critical for 14 of the 17 United Nations Sustainable Development Goals\n(SDGs) [1] - encompassing resource management, urban planning, environmental monitoring and enhancing food\nsecurity [2]. Roughly 20% of Africa's population was undernourished in 2022, with approximately 868 million people\nexperiencing moderate to severe food insecurity. Of these, more than one-third, about 342 million individuals, were\nliving in conditions of severe food insecurity [3]. In addition, most of the economies in Sub-Saharan Africa (SSA) are\ndependent on agriculture [4, 5]. For example, in Kenya, the sector generates 60% of foreign exchange, accounts for\n70% of employment, produces approximately 45% of total government revenue, and supplies 75% of raw materials\nfor industry [6]. However, the sector faces challenges, such as unpredictable weather, soil degradation, competing\nland use, and inadequate agricultural extension service, often exacerbated by adverse climate impacts and expansion\nin population settlements - resulting in a growing prevalence of food insecurity [7]. Other challenges to the sector in\nthe SSA include the European Union Anti-deforestation Law (EUAL) that aims to block agricultural products grown\non deforested lands from accessing European markets [8]. EUAL poses a risk for small scale farmers that are limited\nin technological resources but still are the leading agricultural producers. For example, 80% of the coffee consumed"}, {"title": "2 Data", "content": "Our framework, shown in Fig. 1, uses raw Satellite Imagery, with different resolutions, and Label Examples (annotations),\ncollected from different sources, to train the models."}, {"title": "2.1 Satellite Imagery", "content": "Our teacher and student models use imagery sources with different resolutions. The teacher model uses high-resolution\nMaxar imagery, with 0.331 m/pixel resolution and Red, Green and Blue channels, collected in 2022. However, it only\ncovers 51.55% of our AOI. In addition to its limited coverage, access to the high-resolution Maxar imagery is expensive\nand hence limits scalability. For example, Maxar's GeoEye-1 and WorldView-2-4 50 cm 3-Band satellite imagery\nproducts have a minimum cost of $17.50 and $27.50 per km\u00b2, respectively, for archived and new imagery4. To this end,\nwe use a student model that takes publicly available Sentinel-2 images, with 10 m/pixel. We derived the mean imagery\nfrom all the Sentinel-2 images from 2022 for the entire AOI. Sentinel-2 images also provide two additional channels:\nNear Infrared and Short-Wave Infrared that enhance the ability of the student model to differentiate LULC classes."}, {"title": "2.2 Example Labels", "content": "The LULC classes in this work are adopted from [9]: Bare Ground, Built-up, Crop, Flooded Vegetation, Grass, Shrub\n& Scrub, Trees and Water. Given the diverse nature of built-up areas, we split the Built-up class into separate classes of\nBuilding and Road during the training of the teacher model. We adopted two strategies to collect annotated examples\nfor our models. First, domain experts were recruited to annotate polygon examples, primarily using the high-resolution\nMaxar imagery. We used Microsoft's Spatial Imagery Labeling Toolkit for our annotation efforts. The domain experts\nannotated 11,382 geographically diverse polygons, and the distribution of the polygons across the LULC classes is\nshown in Table 1. Second, we used existing layers in OpenStreetMap to extract 14,577 and 6,910 polygons for\nBuilding and Road layers, respectively. This increased our total annotated polygons from 11,382 to 29, 360. To achieve\nbetter delineation of LULC classes, we generated hard Negative examples as buffers of Building (with 3 m buffer) and\nRoad (with 5 m buffer) classes, resulting a total of 51, 618 polygons as label examples (see Table 1). These labels are\nsparse and constituted just 5.69% of the pixels in the Maxar imagery, and they are used to train and test the models.\nThe domain experts further annotated 1, 219 and 1, 367 polygons for the two main LULC classes of interest: Building\nand Crop labels, respectively - used as External validation set."}, {"title": "3 Methodology", "content": "Our methodology involves a knowledge distillation framework using teacher and student models [20, 21, 22]. We\ntrained the teacher and student models using a high-resolution Maxar imagery and a low-resolution Sentinel-2 imagery,\nrespectively. We describe the details of these models below."}, {"title": "3.1 High-Resolution Teacher Model", "content": "Figure 2 shows the block diagram of the high-resolution teacher model. The input data include high-resolution Maxar\nimages and label examples for a portion of our AOI, and it provides a high-resolution LULC map. We describe below\nremaining steps: Preprocessing and Model Training and Evaluation."}, {"title": "Preprocessing", "content": "Includes Hard Negative Generation, Ground Truth Mask Generation and Train-Test Split. We added\na buffer zone for each of the Building and Road polygons to generate hard negative examples, with buffer sizes of\n3m and 5m, respectively. The added Negative class minimizes the over-dominance of these two classes due to their\nover-representation in the training data and improves delineation of LULC classes. We generated a ground truth mask\nfrom the annotations by mapping each labeled pixel to its class index and assigning zero to the remaining unlabeled\npixels. We split the input data in train and test sets by considering the high diversity across the vertical slices of the\ninput Maxar imagery (see the first part of Fig. 1), partly due to their different acquisition dates. For example, the left\npart of the imagery includes multiple cloud instances compared to the right part. As a result, we adopted a 70% - 30%\nvertical split of data to train and test the model, respectively."}, {"title": "Model Training and Evaluation", "content": "We adopted a deep learning-based semantic segmentation framework to implement\nthe teacher model, comprising a U-Net [23] with a ResNet [24] backbone pre-trained on the ImageNet [25] dataset. We\nonly considered errors from labeled pixels during training. The evaluation step involves testing the model's performance\nin detecting the LULC classes. We adopted a recursive training for our models, using the predicted labels from the\ninitial model as pseudo-labels for the second round of training."}, {"title": "3.2 Low-Resolution Student Model", "content": "The student model uses the publicly available Sentinel-2 images that cover the entire AOI. We used a set of label\nexamples consisting of manually annotated labels, pseudo-labels from the teacher model, and labels from existing\nOpenStreetMap layers. This results in 1,892, 036 polygons across eight LULC classes (see Table 1). We adopted\na down-sampling of the high-resolution labels to synchronize them with the lower-resolution Sentinel-2 data of the\nstudent model during the generation of its ground truth mask.\nWe also implement the student model with deep learning-based semantic segmentation architectures, comprising\nU-Net [23] with a backbone of a fully connected convolutional neural network (FCN). The student model setup uses the\nsame 70% - 30% train-test split as the teacher model. The evaluation of the student model includes a post-processing"}, {"title": "4 Experimental Setup", "content": "In this Section, we present Baselines (the existing global LULC maps used for comparison with our maps), Training\nsetup and Evaluation metrics."}, {"title": "4.1 Baselines", "content": "\u2022 Google's Dynamic World (GDW) [9]: It is a near real-time land cover mapping tool that uses deep learning\nmodels and Sentinel-2 imagery. GDW provides global maps with 10 LULC classes, updating every 2 to 5\ndays. We excluded the Flooded Vegetation labels to maintain a consistent set of LULC classes across the maps\nduring evaluation.\n\u2022 European Space Agency's WorldCover Map (ESA) [11]: It is a global land cover dataset derived from\nSentinel-1 and Sentinel-2 data. ESA offers 10m/pixel resolution and produces detailed coverage of land\ntypes annually. We excluded Snow and ice, Herbaceous wetland, Mangroves, and Moss and Lichen labels to\nmaintain a consistent set of LULC classes across the maps during evaluation.\n\u2022 Environmental Systems Research Institute's LULC Map (ESRI) [12]: It is created through machine\nlearning techniques and multi-source satellite imagery - with frequent update. We excluded the Flooded\nVegetation, Snow/Ice, Clouds, Herbaceous wetland, Mangroves, Moss and Lichen and Shadow labels to\nmaintain a consistent set of LULC classes across the maps during evaluation."}, {"title": "4.2 Training Setup", "content": "We adopted a similar training setup for our teacher and student models, involving: Class Weighting, patch size = 512,\nbatch size = 32, minimum epochs = 100, maximum epochs = 300, learning rate = 0.0003, and cross-entropy loss. We\nused a sequence of augmentation steps including 90 deg and 225 deg rotations, horizontal and vertical flips - all with a\nprobability of p = 0.5."}, {"title": "4.3 Evaluation Metrics", "content": "We evaluated the models by quantifying their detection performance at the pixel level in the corresponding maps.\nThe metrics include Accuracy, Precision, Recall, F\u2081 score and Intersection over Union (IoU) per each LULC class.\nWe computed these metrics for each LULC class and reported the Macro average. We used confusion matrices to\nunderstand the misclassification of pixels across the LULC classes. We also used an agreement matrix as a measure of\nconsistency across the LULC maps."}, {"title": "5 Results", "content": null}, {"title": "5.1 High-Resolution Teacher Model", "content": "The teacher model produces a high-resolution LULC map for a portion of our AOI (see Fig. 3). A subsequent zoom on\nthe test set of the input imagery, which was not seen during training, shows a well-delineated classification of LULC\nclasses. This result supports our approach to treat Building and Road LULC classes as separate classes by reducing\nambiguity and improving delineation."}, {"title": "5.2 Low-Resolution Student Model", "content": "The advantage of our student model is its ability to generate the LULC map for the entire AOI (Murang'a County) as it\nuses publicly available Sentinel-2 images. Figure 5 shows different LULC maps of the AOI including the map from the\nstudent model of the proposed DATS and Baseline maps: GDW [9], ESA [11] and ESRI [12]. The GDW and ESA map,\nshown in Fig. 5 (a) and (b), respectively, have similar trends of overestimation of Trees, particularly in the northern and\neastern parts of the County. The ESA map shows an over-representation of the Shrub & Scrub class across the County,\nwhile the Built-up class is under-represented. On the other hand, the ESRI and DATS maps, shown in Fig. 5 (c) and (d),\nrespectively, exhibit similar trends, including widespread Crop and Built-up classes. Our (DATS) map demonstrates\nhigh-quality patterns, including the Built-up class. The Others class in ESRI's map includes labels that were dropped\nfrom the evaluation, such as Flooded Vegetation, Snow/Ice, Clouds and Shadow, as described in Sec. 4.\nFigure 6 shows the closer look of these maps zoomed in around Mathioya in northern part of the County known for\nits agricultural activities. The qualitative comparison of the maps further confirms the patterns observed in Fig. 5.\nThe existing GDW, ESA and ESRI maps, Fig. 6 (c) - (e), exhibit lower quality compared to our DATS map shown in\nFig. 6 (f). The GDW and ESA maps predominantly show Trees, whereas the ESA map distinctively shows a higher\nobservation of Shrub & Scrub around Mathioya. The ESRI map, shown in Fig. 6 (e), indicates an overestimation of\ncroplands while Trees and Built-up areas are underestimated. Our DATS map, shown in Fig. 6 (f), presents a balanced\nview of Crop, Trees and Built-up classes. All the existing global maps show poor quality in mapping Built-up instances\nsuch as buildings and roads. Even the highway from northeast to south Mathioya, see Fig. 6 (a), was rarely detected by\nthe global models. Existing LULC maps also fail to correctly map buildings that follow roads across the region."}, {"title": "6 Discussion", "content": null}, {"title": "6.1 Inconsistencies and Reduced Accuracy Highlight Limitations of Global LULC Maps", "content": "Venter et al. [13] reported higher accuracy and agreement-level of existing global maps when validated globally and in\nEurope. But when we validated these maps in the Murang'a County of Kenya in Africa, they exhibit poor performance\n(see Sec. 5) and inconsistencies (see Fig. 7). Our map (DATS) achieves the highest agreement rate of 0.34 with the\nESRI [12] map, followed by 0.24 with the GDW [9] map. The ESA [11] map, which tend to over-predict the Trees and\nShrub & Scrub LULC classes as shown in Fig. 5 (b), has the least agreement with the remaining maps. This also further\nsupports the limitations of these global maps reported in prior research [2]. Table 5 highlights the variability in area\ncoverages for the LULC classes across the maps. For example, the Built-up class covers a significant area except in\nthe ESA [11] map, with our map indicating a coverage of 529.64 km\u00b2 (representing 20.96% of the County), similar\nto a coverage of 501.71 km\u00b2 (19.86%) in the GDW [9] map. The ESA [11] map underestimates the Built-up class,\nwith only 42.55 km\u00b2 (1.68%) coverage. GDW underestimates Crop coverage, whereas both the ESRI and DATS maps\nshow similar coverage distribution. We noted discrepancies in the estimations of Trees coverage. GDW map's 1461.64\nkm\u00b2 (58.85%), compared to our map's 510.92 km\u00b2 (20.22%), indicates an overestimation by GDW [9] \u2014a pattern\nconsistently observed in Fig. 5 and Fig. 6. The ESA [11] map shows a 844.24 km\u00b2 (33.42%) coverage of Shrub &\nScrub, which is an over-prediction compared to the remaining maps."}, {"title": "6.2 Impact", "content": "Methodological Impact: The lower accuracies of global LULC maps, compared to our local model's map, emphasize\nthe importance of developing local models for more accurate LULC maps. The observed inconsistencies among these\nglobal maps underscore their limitations in African contexts and emphasize the potential adverse impacts on policy\nformulation and decision-making when these less accurate maps are used. Additionally, our modeling framework,\ncomprising teacher and student models, underscores the need to effectively use diverse and growing data sources for\nLULC mapping. Knowledge distillation from the teacher model to Sentinel-based student model achieves a more\naccurate LULC map, with the potential to scale due to the freely available nature of Sentinel-2 imagery.\nEnvironmental and agricultural impact: Given the low resources available for decision makers in governmental\norganizations in SSA, including Murang'a County of Kenya, LULC maps provide basic insights by characterizing\nland cover types, enabling data-driven interventions and policy designs. Agriculture is a critical sector for most\neconomies in SSA and hence the increased need for data about it. However, the sector faces multiple challenges,\nincluding climate change resulting in rising food insecurity. LULC maps help to achieve most of the SDGs, particularly\nSDG 2: Zero Hunger, by enhancing food security, e.g., through efficient land use, automated crop mapping, and\nmonitoring. Additionally, LULC maps support the compliance process to other challenges, such as the European\nUnion's Anti-deforestation Law [26], by analyzing longitudinal changes of croplands.\nCross collaborations among diverse organizations: This work involved a close collaboration of diverse teams\nof domain experts from industry, academia, and government organizations. The Kenya Space Agency, our local\npartner, selected Murang'a County for the pilot study. Such a collaborative effort enhances the trustworthiness of\nthe developed product and increases the likelihood of its deployment for practical impacts. We involved end users,\nincluding the Murang'a County Government, throughout the development process. The preliminary version of the\nsolution is deployed at the Kenya Space Agency7, and other partnering organizations will use it for downstream tasks of\ncrop type mapping, monitoring, and yield estimation."}, {"title": "6.3 Limitations", "content": "Data: As any machine learning framework that takes data as its main input, our framework is clearly dependent\non the quality of data being used to train our models. The high-resolution Maxar imagery exhibits a heavy presence\nof clouds, which affects the annotation effort and minimizes the size of imagery that can be used for model training.\nFurthermore, the quality of manual annotations also determines the quality of our LULC map. While the annotation is\ndone by domain experts, there are still quality gaps for some of the label examples, partly due to the intrinsic similarity\nof a few LULC classes, e.g., Grasslands vs. Shrub & Scrub. It is partly due to such annotation quality that we discarded\nthe Flooded Vegetation class from our analysis. Thus, more quality assurance measures could be put in place to alleviate\nthe problem, and/or collections of more annotations from multiple annotators and the use of other existing layers.\nMethodological: Our methodology did not use the temporal information in our analysis, which is important for\nunderstanding croplands as their appearance changes across different seasons. For example, a cropland may appear as\nBare Ground before planting/seeding and as Grassland or Shrubland early after the seeding season.\nEvaluation: While we adopt different evaluation sets, such as Whole, Test, and External sets, and several metrics to\nevaluate the performance of our LULC maps, care must be taken as all the quantitative metrics are derived from a small\nset of manually annotated labels. These labels are sparse and only constitute a smaller percentage of the whole imagery.\nThus, a more exhaustive evaluation step, including on-ground verification, is necessary for more confident validation."}, {"title": "7 Conclusion and Future Work", "content": "Food security remains a significant challenge, particularly in the Global South, including Sub-Saharan Africa, partly\ndue to adverse climate impacts and population growth. Earth observation technologies provide a promising opportunity\nto improve food security by generating diverse insights using increasingly available resources, such as Sentinel images,\nand deep learning models. Land-Use and Land-Cover (LULC) maps are instrumental in resource management and\nenvironmental monitoring by characterizing key land cover types. However, existing global LULC maps were reported\nto be lower in accuracy and inconsistent when validated in Africa. In this work, we proposed a data-centric framework\nto build a local LULC mapping model with a setup of teacher and student models. We used Murang'a County in Kenya\nas our area of interest (AOI). Our framework facilitated the efficient utilization of satellite images with varying scales\nof resolution and availability. We used Maxar images, with 0.331 m/pixel resolution, to train the teacher model and\nSentinel-2 images, with 10 m/pixel resolution, to train the student model. While the availability of Maxar images\nis tasked, expensive and limited to only the portion of our AOI, the Sentinel-2 images are freely accessible. Thus,\nour framework enables effective utilization of diverse data sources and build a more accurate LULC map, when we\ncompared it with existing global maps: GDW [9], ESA [11], and ESRI [12]. Additionally, we observed that existing\nglobal maps not only exhibited lower accuracy but also showed inconsistencies with low agreement among themselves.\nFuture work includes scaling the framework to generate a LULC map for the entire country. We also plan to use\ntemporal information to understand longitudinal changes of LULC. Temporal LULC maps can also aid in addressing\ncompliance requirements with the recent EU Anti-deforestation Law, which poses additional challenges for small-scale\nfarmers and producers in Africa and beyond."}]}