{"title": "FOUNDATION MODELS FOR ELECTROCARDIOGRAMS", "authors": ["Junho Song", "Jong-Hwan Jang", "Byeong Tak Lee", "DongGyun Hong", "Joon-myoung Kwon", "Yong-Yeon Jo"], "abstract": "Foundation models, enhanced by self-supervised learning (SSL) techniques, represent a cutting-edge frontier in biomedical signal analysis, particularly for electrocardiograms (ECGs), crucial for cardiac health monitoring and diagnosis. This study conducts a comprehensive analysis of foundation models for ECGs by employing and refining innovative SSL methodologies\u2014namely, generative and con- trastive learning on a vast dataset of over 1.1 million ECG samples. By customizing these methods to align with the intricate characteristics of ECG signals, our research has successfully developed foundation models that significantly elevate the precision and reliability of cardiac diagnostics. These models are adept at representing the complex, subtle nuances of ECG data, thus markedly enhancing diagnostic capabilities. The results underscore the substantial potential of SSL-enhanced foundation models in clinical settings and pave the way for extensive future investigations into their scalable applications across a broader spectrum of medical diagnostics. This work sets a benchmark in the ECG field, demonstrating the profound impact of tailored, data-driven model training on the efficacy and accuracy of medical diagnostics.", "sections": [{"title": "1 Introduction", "content": "Electrocardiograms (ECGs) are essential bio-signals that record the heart's electrical activity, providing critical information about heart rhythm, strength, timing, and beat rate. These signals play a pivotal role in diagnosing heart diseases, detecting abnormalities that may indicate conditions such as myocardial infarction, arrhythmias, and other cardiac disorders. Analyzing ECGs is crucial for effective diagnosis and treatment, making advancements in this field highly impactful.\nDeep Neural Networks (DNNs) have emerged as powerful tools for analyzing ECG data, capable of performing various tasks such as prediction, classification, and denoising. However, two significant challenges hinder their utilization. Firstly, ECG data is sensitive medical information that requires strict privacy protection, leading to a relative scarcity of available data. Secondly, the low incidence of certain heart diseases results in insufficient curated ECG datasets with annotated medical labels to effectively train DNNs.\nResearchers have adopted foundation models with Self-Supervised Learning (SSL) to address these challenges, showing great promise in various fields, including natural language processing (Devlin et al., 2018; Achiam et al., 2023), computer vision (Chen et al., 2020; He et al., 2022), and speech recognition (Baevski et al., 2020). In the context of ECG analysis, foundation models can generalize from unlabeled data and be fine-tuned with minimal labeled data, making them highly flexible and efficient.\nFoundation models with SSL offer several key benefits:"}, {"title": "2 Related Work", "content": "The advent of foundation models has revolutionized various fields by leveraging large-scale, unlabeled datasets to produce versatile and robust data representations. These representations enable models to adapt efficiently to specific downstream tasks with minimal reliance on labeled data, significantly enhancing performance and efficiency. In the realm of bio-signal analysis, particularly ECGs, the application of foundation models enhanced by Self-Supervised Learning (SSL) techniques has shown immense promise (Abbaspourazad et al., 2024; Yue et al., 2022).\nFoundation models utilize advanced SSL techniques during their pre-training phase to learn meaningful data repre- sentations without direct supervision. These techniques are crucial for enabling versatile applications in subsequent task-specific training:"}, {"title": "2.1 Advanced Self-Supervised Learning Techniques for Foundation Models", "content": "Foundation models utilize advanced SSL techniques during their pre-training phase to learn meaningful data repre- sentations without direct supervision. These techniques are crucial for enabling versatile applications in subsequent task-specific training:\n\u2022 Contrastive Learning (CL): CL improves a model's ability to form embeddings by bringing similar instances closer in the embedding space while pushing dissimilar instances apart. This is typically achieved using a contrastive loss function, such as InfoNCE, which helps the model develop rich, semantically meaningful representations from unlabeled data. CL has been successfully applied across various domains, enhancing model performance on downstream tasks by improving the quality of learned representations (Chen et al., 2020).\n\u2022 Generative Learning (GL): GL techniques, such as Masked AutoEncoders (MAE), challenge models to reconstruct obscured segments of input data. This process strengthens the model's capacity to intuit and regenerate missing data components; fostering a deeper understanding of complex data patterns. GL has been particularly effective in applications like image and natural language processing, where it aids in denoising and anomaly detection (He et al., 2022; Dosovitskiy et al., 2020).\n\u2022 Hybrid Learning (HL): HL combines the strengths of both CL and GL, leveraging the discriminative power of CL and the reconstructive ability of GL. This synergistic approach has shown promising results in domains such as computer vision and holds significant potential for ECG analysis and other medical tasks. By balancing the advantages of both methods, HL aims to create robust and flexible data representations (Huang et al., 2023)."}, {"title": "2.2 Pioneering Applications of SSL in Bio-Signal Analysis", "content": "SSL methodologies have been increasingly adapted for bio-signal analysis, particularly in ECG, demonstrating substantial improvements in model accuracy and generalizability:\n\u2022 Diverse Approaches to ECG Analysis: SSL has been instrumental in developing deep multi-task learning frameworks that significantly enhance emotion recognition from ECG signals, achieving state-of-the-art classification results. These frameworks illustrate the ability of SSL to capture complex physiological patterns inherent in ECG data (Sarkar and Etemad, 2020).\n\u2022 Innovative ECG Classification Techniques: Techniques such as U-ResNet-based SSL have shown meaning- ful improvements in ECG classification accuracy, underscoring the utility of SSL in clinical diagnostics. These methods leverage SSL pre-training to refine models, leading to better performance compared to traditional supervised approaches (Gedon et al., 2021).\n\u2022 Addressing Data Challenges: SSL methods have been employed to overcome challenges like label imbalance and data scarcity in ECG datasets. Self-supervised pre-training has demonstrated superior performance in handling complex bio-signal datasets, highlighting the effectiveness of SSL in managing the inherent challenges of ECG data (Liu et al., 2021).\n\u2022 Lead-agnostic Learning Models: Developing SSL methods that are agnostic to ECG leads and capable of learning both local and global features has shown improved adaptability and performance on downstream tasks. These approaches enhance the flexibility and generalizability of SSL in medical applications, making them valuable for diverse clinical scenarios (Oh et al., 2022).\n\u2022 Non-contrastive Learning for ECG: The introduction of non-contrastive SSL approaches, which do not rely on data augmentation or negative pairs, offers a novel pathway for SSL application in bio-signal processing. These methods provide an alternative to traditional contrastive techniques, simplifying the training process and potentially improving model performance (Atienza et al., 2023)."}, {"title": "2.3 Research Goals", "content": "Despite the promising results and growing adoption of SSL for bio-signal generalization, such as ECG, EEG, and PPG, there remains a significant gap in comprehensive implementation strategies for applying foundation models using diverse SSL frameworks in real-world healthcare settings. The existing literature often revolves around closed datasets and controlled experimental conditions, which may not accurately replicate the complexities encountered in practical environments (Na et al., 2024, Abbaspourazad et al., 2024, Liu et al., 2024).\nOur research aims to bridge these gaps by providing detailed and empirically supported guidance on pre-training foundation models. We meticulously evaluate these models across a broad spectrum of architectural designs and SSL methodologies, enhancing their efficacy for bio-signal applications such as ECG. By extending our investigations to include a wide range of real-world applications, we seek to refine these foundation models to better suit clinical needs, thereby advancing their readiness for broader healthcare applications and facilitating significant technological advancements in medical practice."}, {"title": "3 Study Procedure", "content": "Our study's methodology unfolds through a meticulously structured sequence of steps, aiming to provide a comprehen- sive evaluation of foundation models for ECG classification. The process includes data preparation, model training, thorough evaluation, and analysis, ensuring a robust framework for developing and assessing the performance of these models. The entire procedure of our study is illustrated in Figure 1."}, {"title": "3.1 Data preparation", "content": "We utilized two types of datasets: unlabeled and labeled. The unlabeled dataset, presented in Table 1, was compiled from five public repositories, MIMIC (Johnson et al., 2016), CODE15 (Ribeiro et al., 2021), BIOBANK (Sudlow et al., 2015), SAMI (Ribeiro et al., 2021), and IKEM (Sej\u00e1k et al., 2023), to ensure demographic fairness by including data collected from various continents. This dataset encompasses a total of 1,291,868 ECG samples from 442,736 distinct patients, aiding in mitigating potential biases and enhancing the generalizability of the study results.\nFor the classification tasks, we employed labeled datasets, specifically utilizing ECGs from the PTB-XL dataset outlined in Table 2. This dataset includes super-classes: MI (Myocardial Infarction), STTC (ST/T change), CD (Conduction Disturbance), and HYP (Hypertrophy). These super-classes were chosen to reflect the diverse morphologies, features, and rhythmic patterns inherent in ECG data, providing a robust framework for assessing the efficacy of our foundation models. The dataset comprises a total of 21,265 ECG samples collected from 8,000 patients.\nBefore analysis, all data underwent a standardization process to account for inherent variances in sample rates, measuring durations, and MV-units among different datasets. To standardize our comparisons and maintain consistency across analyses, we adjusted the sample rate to 250 Hz, the measurement duration to 10 seconds, and the MV-units to 1.0, rendering each ECG signal in our dataset to consist of a 2500 length per lead."}, {"title": "3.2 Model Training", "content": "We adopt widely recognized Self-Supervised Learning (SSL) methodologies to pre-train our foundation models, specifically focusing on Generative Learning (GL), Contrastive Learning (CL), and Hybrid Learning (HL). These models incorporate the Vision Transformer (ViT) (Dosovitskiy et al., 2020) as the primary architectural backbone,"}, {"title": "3.2.1 Foundation models", "content": "We adopt widely recognized Self-Supervised Learning (SSL) methodologies to pre-train our foundation models, specifically focusing on Generative Learning (GL), Contrastive Learning (CL), and Hybrid Learning (HL). These models incorporate the Vision Transformer (ViT) (Dosovitskiy et al., 2020) as the primary architectural backbone, modified with a one-dimensional convolution projection layer specifically tailored for embedding ECG signals (Woo et al., 2023). The comprehensive architecture of our foundation models, which effectively combines these innovative self-supervised learning strategies."}, {"title": "3.2.2 Downstream models", "content": "After pre-training the foundation models using SSL, we employed two downstream learning strategies to assess their performance: linear probing and fine-tuning.\nLinear Probing: Linear probing involves freezing the weights of the pre-trained foundation model and adding a linear classifier on top of its output layer. This linear classifier is trained using the labeled ECG dataset, evaluating the quality of the learned representations without updating the pre-trained model's weights. This approach provides insights into how well the foundation model's pre-trained features can be used for classification tasks.\nFine-Tuning: Fine-tuning involves updating the weights of the entire model, including both the pre-trained foundation model and the newly added linear classifier. This step allows the model to adapt more specifically to the classification tasks using the labeled dataset. Fine-tuning typically results in better performance than linear probing, as it adjusts the pre-trained features to better fit the specific characteristics of the labeled data."}, {"title": "3.3 Evaluation", "content": "The evaluation of these downstream models is conducted from two critical viewpoints: optimization and applicability.\nOptimization: We scrutinize the parameters utilized during the pre-training phase of the foundation models, focusing on their architectural designs and SSL methodologies, to determine their impact on the representation of ECG data. The evaluation includes: Impact of Patch Size, Influence of Block Depth, Role of Embedding Size.\nApplicability: We assess the practical effectiveness of these models in ECG classification tasks, considering variables such as data availability and case ratios. This involves validating the efficacy of these models in real-world scenarios characterized by low incidence rates and restricted data availability."}, {"title": "3.4 Analysis", "content": ""}, {"title": "3.4.1 Research Questions", "content": "Our research endeavors to elucidate the potential of self-supervised learning (SSL) in the context of electrocardiogram (ECG) modeling through foundation models. It systematically addresses several pivotal research questions designed to deepen our understanding of model development and integration within practical settings:"}, {"title": "RQ1. What architectural designs of foundation models are most effective for capturing the nuanced semantics of ECG?", "content": "The foundation model is pivotal in generalizing electrocardiogram (ECG) data effectively. Determining the most suitable architectural designs to capture diverse ECG signal features\u2014including beat rate, pqrst values, morphological attributes, and temporal correlations\u2014is critical. We conducted an extensive grid search to investigate the impact of key parameters such as patch size, depth, and embedding size on data representation. This search involved testing patch sizes of 250, 125, and 60; depths of 2, 4, and 8; and embedding sizes of 256, 512, and 1024, with embedding sizes set to half that of the encoders. This methodical exploration aims to identify the architectural designs that most accurately capture the complex nuances of ECG signals."}, {"title": "RQ2. Which are the most adept at accurately encoding the complex representations of ECGs among the SSL methods?", "content": "Self-supervised learning (SSL) techniques fundamentally influence the way foundation models represent and process data. Recent studies suggest that the effectiveness of models trained via generative learning (GL) and contrastive learning (CL) varies depending on their application in specific downstream tasks such as classification and prediction (Dubois et al., 2023). Our research examines how different SSL methods impact the representation of ECG data when tailored to these tasks. We assessed the effectiveness of each model using four distinct metrics: approximation error, representation usability error, probe generalization error, and encoder generalization error, as outlined in the risk decomposition approach (Dubois et al., 2023). Detailed methodologies for these metrics are further elaborated in Section B.1."}, {"title": "RQ3. How can foundation models be effectively implemented within clinical environments to optimize diagnostic processes?", "content": "This aspect of our study addresses the deployment of foundation models in scenarios characterized by limited data and scarce labeling resources. We evaluated the performance of the optimal architectural designs identified previously under various conditions of data scarcity. Specifically, we simulated scenarios with case ratio percentages of 1%, 2%, and 5%, and data usage percentages of 10%, 25%, and 50%. The objective is to determine the adaptability and efficacy of these models in diverse real-world situations, assessing their performance across different levels of data availability and their potential reliability and utility in resource-constrained environments.\nThese questions guide our exploration into the practical applications and theoretical implications of SSL techniques in medical informatics, particularly within the realm of cardiac health diagnostics. The findings from our study are expected to provide valuable insights into the development and deployment of foundation models for ECG analysis, with significant implications for clinical practice and future research directions."}, {"title": "4 Experimental Results", "content": "In this section, we provide a summary of the experimental results. Due to paper length limitations, the complete results are included in Appendix C."}, {"title": "4.1 Dataset", "content": "For our study, the data was utilized in two primary stages: the foundation model training and the downstream model training and testing.\nWe used all available unlabeled data for training the foundation model. This extensive use of unlabeled data allowed the foundation model to learn robust and generalized representations of ECG signals through self-supervised learning techniques.\nFor the downstream tasks, we utilized labeled data. The labeled dataset was split into two parts: 80% of the data was used for training and validation, while the remaining 20% was reserved for the test. It is important to emphasize that the test set was strictly not used during any training step of both the foundation model and the downstream model. This separation ensures that the performance evaluation of the downstream models reflects the foundation models' ability to generalize to unseen data, thereby providing an unbiased assessment of the foundation models' effectiveness."}, {"title": "4.2 Environment", "content": "The experiments were conducted using a high-performance computing infrastructure equipped with a parallel distributed architecture, including 16 NVIDIA A100 GPUs. This setup facilitated the efficient handling of the extensive datasets and computationally intensive processes required for our study. To ensure consistent training conditions across all phases, we adopted a uniform set of optimization parameters. Throughout the pre-training, linear probing, and fine-tuning stages, we applied a fixed learning rate of \\(1 \\times 10^{-4}\\) and a weight decay of \\(1 \\times 10^{-5}\\). These parameters were selected to optimize convergence and minimize the risk of overfitting.\nThe initial stage involved pre-training 81 distinct foundation models (all combinations of 3 patch sizes, 3 block depth, 3 embedding sizes, and 3 SSL methodologies) on a large dataset of 1.1 million unlabeled electrocardiograms (ECGs). This extensive pre-training was conducted over approximately one week for each, aiming to develop robust data representations that form the basis for later supervised learning tasks.\nFollowing SSL pre-training, the top layers of each model were replaced with new linear classifiers, while the underlying base layers retained their pre-trained weights. During this phase, training was restricted to these top layers using a subset of labeled data to assess the effectiveness of the SSL-derived features under the established optimization parameters. This process, known as linear probing, evaluates the quality of the learned representations without updating the pre-trained model's weights."}, {"title": "4.3 Overall Performance", "content": ""}, {"title": "4.3.1 Foundation Model Loss", "content": "The results regarding the loss of foundation models, categorized by the learning methods of Contrastive Learning (CL), Generative Learning (GL), and Hybrid Learning (HL), are summarized in Table 3. Detailed evaluations of the loss variations across different structure settings for these models were extensively analyzed in Appendix C, with the complete results of the evaluation presented in Tables 1, 2, and 3.\nThe findings illustrated that the structure settings significantly influenced the efficiency of foundation models under different learning frameworks. CL-based models registered the lowest loss with a patch size of 250, suggesting that larger patch sizes enhanced the effectiveness of contrastive mechanisms by encapsulating more comprehensive information cues. Conversely, models based on GL and HL recorded minimal loss at a smaller patch size of 60, indicating a preference for more granular data segmentation in these learning approaches.\nAdditionally, block depth emerged as a crucial factor affecting model performance, with a depth of 2 blocks proving to be most effective across all models. This highlighted an optimal balance between model complexity and computational manageability. For embedding sizes, CL-based models demonstrated optimal performance with an embedding size of 512, sufficient for capturing essential features without excessive complexity. In contrast, GL and HL models exhibited the best loss metrics at a higher embedding size of 1024, implying a need for more detailed feature extraction to achieve effective learning of ECG representation.\nThese findings underscored the intricate dependencies between model architectural parameters and their operational efficacy within different SSL paradigms, enriching the understanding of how specific architectural designs could be optimized to enhance the performance of SSL-based foundation models in various applications."}, {"title": "4.3.2 Linear Probing Performance", "content": "Table 4 provided a comprehensive comparison of the linear probing performance with foundation models trained using Contrastive Learning (CL), Generative Learning (GL), and Hybrid Learning (HL) against a baseline model initialized with random encoder weights. The evaluation criteria included AUROC and AUPRC across four downstream tasks: MI, STTC, CD, and HYP."}, {"title": "4.3.3 Fine-tuning Performance", "content": "Table 5 illustrates the performance for fine-tuned models based on the various foundation models, with a supervised learning (SL) model serving as the baseline. Among the fine-tuned models, Hybrid Learning (HL) demonstrated the highest AUROC for MI (0.9448) and CD (0.9449), reflecting its superior ability to distinguish between classes in these tasks. Contrastive Learning (CL) achieved the highest AUROC for STTC (0.9426), while also showing strong performance in other tasks. In terms of AUPRC, which evaluates the precision-recall trade-off, HL again excelled with the highest AUPRC for MI (0.8809) and CD (0.8841), further underscoring its robustness in these predictive tasks.\nThe superior performance of the SSL-based models compared to the SL baseline can be attributed to the inherent advantages of self-supervised learning. SSL-based models leverage vast amounts of unlabeled data to pre-train models, capturing a broad range of patterns and features that might not be as effectively learned through limited labeled data in SL. This extensive pre-training enables foundation models to develop more robust and generalizable representations, which translate to improved performance when fine-tuned on specific downstream tasks. Additionally, SSL approaches like HL and CL facilitate better utilization of the data structure and intrinsic relationships, further enhancing model performance beyond what is achievable with end-to-end supervised learning alone.\nAnalyzing the task-specific characteristics, each performance of fine-tuned models with the various foundation models reveals insights into their strengths. For Myocardial Infarction (MI) detection, the highest AUROC and AUPRC of fine-tuned model with the HL-based foundation model indicate its effectiveness in identifying subtle variations in heart signals, likely due to its balanced pre-training approach that captures a wide range of features. For ST/T Changes (STTC) detection, the highest AUROC of fine-tuned model with the CL-based foundation model suggests that its contrastive approach, which emphasizes differences between samples, is particularly suited for identifying specific changes in ECG waveforms. In the case of Conduction Disturbance (CD), the highest AUROC and AUPRC of fine-tuned model with the HL-based foundation model highlights its capability to generalize well from pre-training, capturing necessary patterns indicative of conduction disturbances. For Hypertrophy (HYP), detecting structural changes in the heart muscle higher AUROC of fine-tuned model with the CL-based foundation model indicates that contrastive learning is effective in distinguishing features associated with hypertrophy, possibly due to its focus on capturing diverse structural representations.\nOverall, the performance criteria suggest that Hybrid Learning (HL) is the most balanced and effective SSL method, achieving the highest overall score. Contrastive Learning (CL) and Generative Learning (GL) also performed well, surpassing the baseline model, but HL's ability to consistently achieve high scores across multiple tasks highlights its potential as a robust approach for foundation model training in self-supervised learning contexts. The superior performance of SSL methods across tasks underscores their ability to leverage large-scale unlabeled data for pre-training, capturing complex patterns and relationships that enhance downstream task performance."}, {"title": "4.4 Impact of pre-training strategies on AUROC", "content": "To answer the resaerch question, we aim to validate the linear probing and fine-tuning processes on foundation models utilizing different learning methodologies\u2014contrastive learning (CL), generative learning (GL), and a hybrid approach combining both (HL). The four binary classification tasks-Myocardial Infarction (MI), ST/T Changes (STTC), Conduction Disturbance (CD), and Hypertrophy (HYP)\u2014serve as benchmarks to assess the efficacy of these learning techniques under varying parameter settings, such as patch size, embedding size, and block depth."}, {"title": "4.4.1 Patch Size", "content": "Foundation Model Loss: As shown in both Figure 3a and 4a, the loss of CL-based foundation model did not show a consistent trend with patch sizes (e.g., FM Loss showed v-shaped trend with 2-block depth and 256-embedding size, and opposite with 4-block depth and 512-embedding size). The loss of GL-based foundation model showed increasing trend, indicating less learning efficacy in Figure 3b and 4b. In last, the loss of HL-based foundation model also increased with larger patch sizes but less than that of GL-based as depicted in Figure 3c and 4c.\nLinear Probing Performance: As shown in Figure 3a, for the linear probing results based on the CL-based foundation model, AUROC for MI generally decreased with larger patch sizes, with a noticeable drop at mid-range patch sizes (e.g., MI AUROC dropped significantly around the 125 patch size). CD and HYP showed slight decreases with larger patch sizes but were more stable compared to MI, while STTC remained generally stable with slight fluctuations. As shown in Figure 3b, for the linear probing results based on the GL-based foundation model, MI and CD showed improvement with larger patch sizes but with some fluctuations (e.g., AUROC for MI improved from 0.62 to 0.67 as patch size increased with 4-block depth and 512-embedding size), while STTC and HYP showed slight decreases with larger patch sizes. As shown in Figure 3c, for the linear probing results based on the HL-based foundation model demonstrated more stable AUROC for all tasks with slight decreases with larger patch sizes.\nFine-Tuning Performance: In Figure 4a, for the fine-tuning results based on the CL-based foundation model, high and stable AUROC for MI, STTC, CD, and HYP were observed, with slight improvements as patch sizes increased (e.g., MI AUROC remained above 0.93 and slightly improved). As shown in Figure 4b, for the fine-tuning results based on the GL-based foundation model, AUROC remained high and stable across different patch sizes for all tasks, with slight improvements as patch sizes increased (e.g., AUROC for HYP improved on all parameter variations). As depicted in Figure 4c, the HL-based foundation model showed stable AUROC for STTC and CD with slight improvements as patch sizes increased. While the AUROC of MI and HYP were decreased slightly as patch sizes increased. However, the fine-tuning results based on the HL-based foundation model achieved the highest AUROC for MI, STTC, CD, and HYP, further improving with larger patch sizes and FM Loss decreased, indicating effective learning."}, {"title": "4.4.2 Block Depth", "content": "Foundation Model Loss: As shown in both Figure 5 and 6, the loss of CL-, GL-, and HL-based foundation model increased with deeper block depth, indicating worse learning (e.g., CL-based FM Loss increased from 524 to 804 with 125-patch size and 256-embedding dims, GL-based FM Loss increased 12.6 to 14.3, and HL-based FM Loss increased from 363 to 368 as block depth increased).\nLinear Probing Performance: As shown in Figure 5a, for the linear probing results based on the CL-based foundation model, AUROC for MI, STTC, CD, and HYP generally showed decreases with deeper block depth (e.g., AUROC for CD decreased from 0.72 to 0.69 with deeper block depth). The FM Loss increased with deeper block depth. The linear probing results based on the GL-based foundation model in Figure 5b demonstrated the slight increasing trends, with AUROC showing variability but generally improving with deeper block depth. The linear probing results based on the HL-based foundation model in Figure 5c exhibited better performance compared to other linear probing methods, with AUROC improving slightly with deeper block depth.\nFine-Tuning Performance: For the fine-tuning results based on the CL-based foundation model in Figure 6a, high AUROC for all tasks were observed, slightly improving with deeper block depth (e.g., AUROC for MI increased from 0.93 to 0.94). As shown in Figure 6b, for the fine-tuning results based on the GL-based foundation model, AUROC remained stable across different block depths, with slight improvements. As shown in Figure 6c, the fine-tuning results based on the HL-based foundation model achieved the highest AUROC for all tasks except for HYP, further improving with deeper block depth, while AUROC of HYP slightly decreased with 125-patch size and 256-embedding size."}, {"title": "4.4.3 Embedding Size", "content": "Foundation Model Loss: As depicted in Figure 7 and 8, all FM Loss decreased with larger embedding sizes, indicating better learning (e.g., CL-based FM Loss decreased on all settings expcept for 125-patch size and 2-block depth, GL-based FM Loss decreased on all settings, and HL-based FM Loss decreased on all settings).\nLinear Probing Performance: As shown in Figure 7a, for the linear probing results based on the CL-based foundation model, AUROC for MI, STTC, CD, and HYP generally improved with larger embedding sizes (e.g., AUROC for MI increased from 0.65 to 0.77 as embedding size increased). The linear probing results based on the GL-based foundation model in Figure 7b demonstrated similar trends in shallow block depth (2-depth), with AUROC improving with larger embeddings but showing slight decreases in deep block depth (4-depth) (e.g., AUROC for all tasks generally improved with larger embeddings with 60-, 125-patch sizes and 2-depth, while decreased with 60-, 125-patch sizes and 4-depth). As shown in Figure 7c, the linear probing results based on the HL-based foundation model showed improvements in AUROC for all tasks with 512 embedding size but slight decreases or consistency with 1,024 emebdding sizes.\nFine-Tuning Performance: For the fine-tuning results based on the CL-based foundation model in Figure 8a, AUROC for all tasks were slightly decreased with larger embeddings (e.g., AUROC for HYP decreased in all parameter settings). As shown in Figure 8b, for the fine-tuning results based on the GL-based foundation model, AUROC remained stable across different embedding sizes for all tasks, with slight improvements as embedding sizes increased. The fine-tuning results based on the HL-based foundation model in Figure 8c showed slight improving with larger embedding sizes, further achieving the highest AUROC for all tasks, while FM Loss decreased, indicating effective use of larger embeddings."}, {"title": "4.5 Real-World Applicability", "content": ""}, {"title": "4.5.1 Limited Amount of Data", "content": "Table 6 presents the performance metrics of fine-tuned downstream models based on varying percentages of labeled data usage, excluding 100% data usage. The models evaluated included an end-to-end supervised learning model (SL) and three foundation models pre-trained for each downstream task using Contrastive Learning (CL), Generative Learning (GL), and Hybrid Learning (HL). Performance is measured using AUROC and AUPRC for four downstream tasks (MI, STTC, CD, HYP) and an overall criteria score.\nThe analysis revealed that as the percentage of labeled data decreased, the performance metrics for all methods dropped. This impact was most significant at 10% data usage, where both AUROC and AUPRC were notably lower. SL demonstrated the steepest decline, indicating its reliance on larger labeled datasets. At 50% data usage, SL showed high AUROC and AUPRC, with a criteria score of 6.8772. However, as data usage dropped to 25% and 10%, its performance decreased, with criteria scores of 6.6317 and 6.5046, respectively.\nIn contrast, the foundation models exhibited better resilience to reduced labeled data. CL maintained robust performance across all data usage levels, achieving a criteria score of 6.9386 at 50%, 6.7825 at 25%, and 6.6442 at 10%. GL performed comparably to SL at higher data usage levels but showed a slight advantage at lower data usage, with criteria scores of 6.9028 at 50%, 6.7471 at 25%, and 6.5487 at 10%. HL consistently outperformed all other methods, demonstrating the highest AUROC and AUPRC across all tasks. It achieved the highest criteria scores of 6.9791 at 50%, 6.8832 at 25%, and 6.5937 at 10%, indicating superior performance and resilience.\nIn summary, foundation models, particularly HL, showed superior performance and robustness to reduced labeled data compared to the end-to-end supervised learning model. HL stood out as the most effective approach, maintaining high performance across varying percentages of labeled data usage, followed by CL and GL, while SL showed significant performance degradation with decreased labeled data."}, {"title": "4.5.2 Limited Cased of Real-World", "content": "Table 7 shows the performance of fine-tuned downstream models that was evaluated according to varying case ratios (5%, 2%, 1%). The models assessed included an end-to-end supervised learning model (SL) and three foundation models pre-trained using Contrastive Learning (CL), Generative Learning (GL), and Hybrid Learning (HL). The fine-tuned models for each downstream task were based on these foundation models. Performance was measured using AUROC (Area Under the Receiver Operating Characteristic Curve) and AUPRC (Area Under the Precision-Recall Curve) for four downstream tasks: MI, STTC, CD, and HYP, with an additional overall criteria score for each model and case ratio.\nAcross all learning methods, both AUROC and AUPRC metrics generally decreased as the case ratio decreased, indicating a drop in model performance with fewer training cases. However, a key observation is that the Hybrid Learning (HL) model exhibited less performance decline with the drop in case ratio compared to other methods. For instance, in the HL model, the AUROC for MI decreased from 0.9294 at 5% to 0.9069 at 1%, a drop of approximately 2.4%, while the AUPRC for MI fell from 0.8636 to 0.8133, a decline of about 5.8%. This trend indicates that HL models maintain robustness better than CL and GL models under reduced data conditions. For comparison, the AUROC for MI in the CL model decreased from 0.9234 at 5% to 0.8991 at 1%, a drop of around 2.6%, while the AUPRC decreased from 0.8475 to 0.7975, a decline of approximately 5.9%.\nFurthermore, the fine-tuned models based on foundation models (CL, GL, and HL) consistently outperformed the end-to-end SL model across all tasks and case ratios. For example, the CL model's AUROC for MI was 0.9234 at 5% and 0.8991 at 1%, whereas the SL model's AUROC for MI dropped from 0.9185 at 5% to 0.8797 at 1%, a decrease of about 4.2%. The overall criteria values, reflecting aggregate performance, also decreased with lower case ratios across all learning methods, aligning with the trends observed in AUROC and AUPRC metrics.\nOverall, the table demonstrates the robustness and effectiveness of different learning methods under varying data availability conditions, with hybrid learning showing the least performance degradation and fine-tuned models based on foundation models exhibiting superior performance compared to the end-to-end SL model."}, {"title": "4.6 Ablations", "content": ""}, {"title": "4.6.1 Risk decomposition", "content": "Table 8 presented a comprehensive risk decomposition analysis ( Dubois et al., 2023) across various SSL methodolo- gies-CL, GL, and HL-evaluated over multiple ECG classification tasks (MI, STTC, CD, HYP). Each methodology was assessed across four dimensions of error: approximation, representation usability, probe generalization, and encoder generalization, with a summary of average errors presented in the AVR column.\nApproximation Error Our findings revealed significant differences in approximation errors among the methodologies. The CL methodology exhibited the highest approximation errors across nearly all tasks, suggesting that its encoder's architectural capacity might be insufficient for the complexity of the tasks. This was particularly evident in tasks with higher dimensional data requirements, where the capacity to capture intricate patterns is crucial. In stark contrast, the HL methodology demonstrated robust capabilities by consistently recording the lowest approximation errors, notably excelling in the CD task. This suggests that HL's architecture is potentially more suited for handling the intricacies of ECG data. The GL methodology, while generally performing moderately, showed its best performance in the MI task, indicating a possible alignment of its architectural strengths with the specific demands of this task.\nRepresentation Usability Error Representation usability error analysis further differentiated the methodologies. HL consistently showed the lowest errors, indicating its superior efficacy in generating linearly separable and usable representations for downstream tasks. This is critical in clinical applications where the reliability of ECG classification can directly impact diagnostic outcomes. Conversely, GL's highest usability error in the MI task suggests its potential limitations in conditions requiring high discriminative power from the representations, which might impede its applicability in more nuanced or complex clinical scenarios.\nProbe Generalization Error The probe generalization error results provided insights into the models' ability to generalize from learned representations to unseen data. The negative values observed in CL's performance on the STTC task highlight its strengths in generalization, potentially making it suitable for applications where robustness to new data is paramount. However, GL's relatively high generalization errors, especially in the CD task, underscore some challenges it may face in environments with high variability or where the training data does not comprehensively represent the test scenarios.\nEncoder Generalization Error In terms of encoder generalization, HL again proved to be superior, particularly in the STTC and HYP tasks, which suggests that its pretraining approach may better encapsulate the underlying patterns of the ECG data. This robustness is invaluable for practical applications where models often encounter data that differ from the training set. The higher encoder generalization errors observed with the CL methodology indicate potential overfitting to the training data, which could limit its effectiveness in broader clinical implementations."}, {"title": "5 Discussion", "content": ""}, {"title": "5.1 RQ1. What architectural designs of foundation models are most effective for capturing the nuanced semantics of ECG data?", "content": "Based on the results from Section 4.4.1, 4.4.2, and 4.4.3, the research question can be answered as follows:\nFor patch size, our analysis shows that larger patch sizes generally improve performance, especially in fine-tuned configurations. This means that capturing greater contextual information within each patch helps the model better understand broader patterns in the ECG data. For example, in fine tuning, the results of the CL-based foundation model showed high and stable AUROC for all tasks, although there was some improvement as patch size increased. Similarly, the HL-based foundation model achieved the highest AUROC with larger patch sizes. However, in the linear probing results of the GL foundation-based model, the overall performance of all tasks decreased and FM Loss tended to increase. Therefore, for GL-based foundation models, small patch sizes are effective.\nIn the case of block depth, a slight performance improvement was confirmed in the finetuning results, but these results are not efficient in terms of resource use due to increased model complexity. In addition, linear probing results showed a tendency for performance to decrease and FM loss to increase. These results indicate that the generalizability of the foundation model is reduced. Therefore, it can be said that shallow block depth is efficient for the generalizability of the foundation model and the performance of the donwstream model.\nFor the embedding size, larger embedding sizes consistently improved AUROC across both linear probing and fine-tuning configurations. This indicates that a larger embedding size allows the model to represent more complex features and patterns within the ECG data. For example, the CL-based method for fine-tuning showed high and stable AUROC, improving with larger embeddings. The HL-based method also achieved the highest AUROC with larger embeddings, indicating that a richer representation space enhances the model's ability to capture nuanced ECG semantics.\nOur analysis shows that the most effective architectural design for a foundation model to capture nuances in ECG data is to use larger patch sizes, shallow block depths, and larger embedding sizes. These design choices allow the base model to capture broader contextual information, represent complex features, and learn hierarchical patterns within ECG data."}, {"title": "5.2 RQ2. Which are the most adept at accurately encoding the complex representations of ECGs among the SSL methods?", "content": "Based on the results from Section 4.3.1, 4.3.2, and 4.3.3, the research question can be answered as follows:\nHybrid Learning (HL) emerges as the most adept method at accurately encoding the complex representations of ECGs among the SSL methods evaluated. The table on variation in losses (foundation model losses) showed that HL demonstrated lower patient and sample losses compared to Contrastive Learning (CL). Although HL did not have the lowest total loss, its balanced trade-offs between different loss types suggested its capability to handle complex representations effectively.\nIn Table 4, HL consistently achieved the highest AUROC and AUPRC in key tasks, particularly for Myocardial Infarction (MI) and Conduction Disturbance (CD). This indicated HL's superior performance in initial linear probing, showcasing its strength in encoding meaningful ECG representations. Furthermore, in Table 5, HL again outperformed other methods, achieving the highest AUROC for MI and CD, and the highest AUPRC for MI and CD. While Contrastive Learning (CL) excelled in ST/T Changes (STTC), HL's overall performance was more balanced and robust.\nTherefore, HL's ability to balance various loss types during pre-training, combined with its superior performance in both linear-probed and fine-tuned downstream tasks, highlights its effectiveness in capturing the intricate features and patterns within ECG data. The consistent high performance of HL across multiple evaluation criteria underscores its robustness and reliability in encoding complex ECG representations, making it the most suitable method for this purpose."}, {"title": "5.3 RQ3. How can foundation models be effectively implemented within clinical environments to optimize diagnostic processes?", "content": "The analysis of results from Section 4.5 provides insights into effectively implementing foundation models within clinical environments to enhance diagnostic processes.\nThe study evaluated the performance of optimal architectural designs under conditions of data scarcity by simulating scenarios with case ratio percentages of 1%, 2%, and 5%, and data usage percentages of 10%, 25%, and 50%. These simulations aimed to determine the adaptability and efficacy of the models in diverse real-world situations, assessing their performance across different levels of data availability. The results indicated that Hybrid Learning (HL)-based models maintained robust performance even with limited data, highlighting their potential reliability and utility in resource-constrained environments.\nFoundation models, particularly those utilizing HL, have demonstrated significant robustness when dealing with limited labeled data. This adaptability is crucial in clinical environments where obtaining large volumes of annotated medical data is challenging. The ability to perform well with smaller datasets enhances the practicality of these models for clinical use, where data scarcity is a common issue.\nImplementing foundation models can enhance diagnostic accuracy. Leveraging pre-trained models fine-tuned with smaller labeled datasets allows healthcare providers to achieve higher diagnostic precision. This is particularly beneficial for detecting conditions with low incidence rates, as the models can be fine-tuned to recognize subtle variations in ECG signals indicative of specific pathologies.\nOnce pre-trained, foundation models require fewer computational resources for fine-tuning. This efficiency is advantageous for clinical settings where computational resources may be limited. The pre-training phase, involving extensive use of unlabeled data, can be conducted using high-performance computing facilities, while the fine-tuning phase can be performed with more modest computational setups available in clinical environments.\nThe scalability of foundation models facilitates their application across various clinical tasks beyond ECG analysis. Their flexible architecture can be adapted to other diagnostic processes, such as imaging and genetic data analysis, providing a comprehensive tool for healthcare providers. This versatility is vital for integrating advanced diagnostic models into routine clinical workflows, enhancing overall healthcare delivery."}, {"title": "5.4 Comprehensive Analysis", "content": "The observed discrepancies in optimal parameter settings across Tables 3, 4, and 5 can be attributed to several factors inherent to the nature of the tasks (loss minimization versus performance maximization) and the characteristics of the different learning methods.\nThe objectives of these tasks are fundamentally distinct. In Table 3, the goal is to identify parameter settings that minimize total loss, encompassing patient loss, sample loss, and reconstruction loss. This minimization focuses on reducing errors during the pre-training phase, which includes various types of losses depending on the learning method. In contrast, Table 4 aims to maximize the AUROC and AUPRC during linear probing, assessing the quality of pre-trained representations by training a simple classifier on top of the frozen pre-trained model. Table 5 seeks to maximize AUROC and AUPRC during fine-tuning, which involves updating the weights of the entire model, including pre-trained layers, to adapt to specific downstream tasks. The distinct objectives of these tasks naturally lead to different optimal parameter settings.\nThe nature of the learning methods significantly influences the optimal settings. Contrastive Learning (CL) focuses on learning representations by contrasting positive and negative pairs, implying that the optimal settings for minimizing losses might differ from those providing the best downstream task performance due to the emphasis on distinguishing between similar and dissimilar samples. Generative Learning (GL) focuses on generating data samples that align with the training data distribution. Consequently, the optimal settings for minimizing reconstruction loss may not directly translate to the best settings for discriminative tasks like linear probing and fine-tuning. Hybrid Learning (HL) combines aspects of both contrastive and generative learning, balancing between loss minimization and downstream task performance, which results in different optimal settings for pre-training losses and downstream performance metrics.\nThe impact of parameter settings also contributes to these differences. Parameters such as patch size, block depth, and embedding size affect the model's capacity and ability to capture different levels of information. Smaller patch sizes capture more detailed information, which is crucial for loss minimization but might not always translate to optimal performance for downstream tasks. For instance, linear probing results based on the CL-based foundation model showed that AUROC for MI generally decreased with larger patch sizes, while CD and HYP exhibited slight decreases and were more stable compared to MI, and STTC remained generally stable with slight fluctuations (Section 4.4.1, Figure 3a). Conversely, larger embedding sizes capture more complex representations, which might benefit linear probing and fine-tuning but could lead to higher pre-training losses if not managed well. The GL-based foundation model demonstrated slight increasing trends, with AUROC generally improving with deeper block depth but showing variability (Section 4.4.2, Figure 5b). Similarly, the HL-based foundation model showed improvements in AUROC for all tasks with a 512 embedding size but exhibited slight decreases or consistency with a 1,024 embedding size (Section 4.4.3, Figure 7c).\nOverfitting considerations are crucial in the context of Table 3. Overfitting occurs when a model learns not only the underlying patterns but also the noise in the training data, resulting in poor generalization to new, unseen data. Overfitting risks vary across different parameter settings. In pre-training loss minimization (Table 3), an overemphasis on minimizing total loss could lead to overfitting if the model becomes too tailored to the specific details and noise of the training data. Smaller patch sizes and larger embedding sizes could exacerbate overfitting by capturing more granular details, including noise. To mitigate overfitting, various techniques such as regularization, dropout, and careful monitoring of validation loss can be applied during pre-training.\nIn conclusion, the differences in optimal parameter settings across the tables arise from the distinct goals and characteristics of the tasks (loss minimization versus performance maximization) and the learning methods (contrastive, generative, hybrid). Each method's nature and the way parameters influence different types of losses and performance metrics lead to varying optimal settings for pre-training and downstream tasks. Overfitting is a crucial factor that needs to be managed during pre-training to ensure that the models generalize well to new, unseen data. Proper regularization, data augmentation, and careful monitoring of performance metrics are essential to mitigate the risks of overfitting."}, {"title": "5.5 Limitations and Future Works", "content": "Limitations Despite the extensive dataset of over 1.1 million ECG samples, the inherent imbalance in medical datasets, particularly in the representation of rare conditions, poses a significant challenge. This imbalance can lead to biased models that perform well on common conditions but poorly on rare ones. Additionally, while the datasets used in this study are comprehensive, they may not fully capture the diversity seen in global populations. Variations in demographic factors such as age, gender, and ethnicity can affect ECG characteristics, and models trained on limited demographic data might not generalize well to all patient populations.\nAnother critical limitation is model interpretability. Foundation models, especially those based on deep learning architectures like Vision Transformers (ViT), often act as black boxes, making it difficult to interpret their decision- making processes. This lack of transparency can hinder clinical adoption, where understanding the rationale behind a diagnosis is crucial. Furthermore, the pre-training and fine-tuning of large-scale foundation models require significant computational resources, which may not be readily available in all research or clinical settings. This limitation can restrict the accessibility and scalability of these models. Lastly, handling large-scale medical data, particularly ECGs, involves stringent privacy and security considerations. Ensuring that data is anonymized and securely managed is essential, yet challenging, especially when dealing with cross-institutional data sharing.\nFuture Works To address data imbalance, future work can explore advanced data augmentation techniques and synthetic data generation to create a more balanced and representative dataset, which can help improve model performance on rare conditions. Increasing the diversity of training datasets by including more samples from underrepresented demographic groups can enhance the generalizability of the models. Collaborations with international healthcare institutions could provide access to a more varied patient population.\nDeveloping methods to make the decision-making processes of foundation models more interpretable will be crucial for clinical adoption. Techniques such as attention mechanism visualization, feature importance mapping, and explainable AI (XAI) frameworks can be explored. Research into more efficient training algorithms and model architectures that require less computational power can make these models more accessible. Techniques such as model pruning, quantization, and knowledge distillation can be investigated.\nFuture work should also focus on developing robust privacy-preserving techniques, such as federated learning and differential privacy, to enable the secure use of sensitive medical data without compromising patient confidentiality. Conducting clinical trials to validate the performance of these foundation models in real-world settings is essential. This will help assess their practical utility and effectiveness in diverse clinical environments. Finally, exploring cross-modal learning techniques that integrate ECG data with other types of medical data (e.g., imaging, genetic information) can provide a more holistic understanding of patient health and improve diagnostic accuracy.\nBy addressing these limitations and exploring these future directions, the robustness, generalizability, and clinical applicability of foundation models for ECG analysis can be significantly enhanced."}, {"title": "6 Conclusion", "content": "This paper presents comprehensive findings on developing and applying foundation models for electrocardiogram (ECG) using Self-Supervised Learning (SSL). The study significantly contributes to the field by pioneering large-scale foundation models specifically tailored for ECG data. These models are trained using a hybrid SSL framework that integrates contrastive and generative learning methods, providing robust and flexible tools for ECG classification in practical healthcare settings. The effectiveness of these models has been demonstrated through extensive testing and optimization processes, focusing on various architectural designs and SSL methods to enhance ECG representation. This involved exploring different parameter architectural designs, which were crucial in determining the optimal settings for achieving the best performance in practical applications, particularly in scenarios with limited labeled data. One of the key conclusions is that while the foundation models excel in ECG classification, the choice of the SSL method significantly impacts their effectiveness. The hybrid learning approach, which combines the strengths of both generative and contrastive learning, has shown superior performance in many cases, suggesting a promising direction for future research and application. Moreover, the study confirms the practical viability of these models in real-world settings, emphasizing the reduced need for labeled data and the potential for quicker, more efficient diagnostic processes. This advancement is expected to facilitate broader adoption and further innovation in the use of deep-learning techniques in cardiology and other medical fields. Ultimately, the findings advocate for continued exploration and development of foundation models in medical AI, encouraging further studies to refine these models and expand their applications across more varied and complex medical datasets."}]}