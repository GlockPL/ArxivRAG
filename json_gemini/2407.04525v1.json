{"title": "Enhancing learning in artificial neural networks through\ncellular heterogeneity and neuromodulatory signaling", "authors": ["Alejandro Rodriguez-Garcia", "Jie Mei", "Srikanth Ramaswamy"], "abstract": "Recent progress in artificial intelligence (AI) has been driven by insights from neuroscience,\nparticularly with the development of artificial neural networks (ANNs). This has significantly\nenhanced the replication of complex cognitive tasks such as vision and natural language\nprocessing. Despite these advances, ANNs struggle with continual learning, adaptable\nknowledge transfer, robustness, and resource efficiency \u2013 capabilities that biological systems\nhandle seamlessly. Specifically, ANNs often overlook the functional and morphological\ndiversity of the brain, hindering their computational capabilities. Furthermore, incorporating\ncell-type specific neuromodulatory effects into ANNs with neuronal heterogeneity could enable\nlearning at two spatial scales: spiking behavior at the neuronal level, and synaptic plasticity at\nthe circuit level, thereby potentially enhancing their learning abilities. In this article, we\nsummarize recent bio-inspired models, learning rules and architectures and propose a\nbiologically-informed framework for enhancing ANNs. Our proposed dual-framework approach\nhighlights the potential of spiking neural networks (SNNs) for emulating diverse spiking\nbehaviors and dendritic compartments to simulate morphological and functional diversity of\nneuronal computations. Finally, we outline how the proposed approach integrates brain-\ninspired compartmental models and task-driven SNNs, balances bioinspiration and\ncomplexity, and provides scalable solutions for pressing Al challenges, such as continual\nlearning, adaptability, robustness, and resource-efficiency.", "sections": [{"title": "1. Introduction", "content": "In recent years, artificial intelligence (AI) has not only marked a significant evolution in\ntechnology but has also redefined the capabilities of machines, mirroring certain aspects of\nhuman intelligence with remarkable fidelity. At the forefront of this progress are advances in\nartificial neural networks (ANNs), particularly through the integration of deep learning. These\nnetworks, known as deep neural networks (DNNs) and characterized by their multi-layer\narchitectures, have demonstrated an impressive ability to learn from vast amounts of data 1\u20133."}, {"title": "2. From Isolated to Lifelong Learning", "content": "Learning can be defined as a dynamic process of restructuring a system to improve its task\nperformance through experience 7,20,21. Traditional Al approaches use machine and deep\nlearning techniques to adapt models and improve task performance through model training,\ntypically operating within supervised or unsupervised learning paradigms 2. Learning in these\nmethods is isolated and based on specific datasets and tasks, demonstrating limited ability to\nprocess and retain contextual information and/or previously learned knowledge 22.\nAdditionally, they rely heavily on the training data and require extensive computational\nresources, limiting the capacity of the models to improve 8,9. On the contrary, the dynamic\nnature of real-world scenarios requires biological organisms to develop and employ Lifelong\nLearning (LL), effectively managing ever-changing task demands and adapting to their\nenvironment to ensure survival. This capability, developed and refined through evolution,\nallows them to (i) learn tasks sequentially and (ii) transfer and adapt task knowledge according\nto contextual changes in a (iii) robust and (iv) cost-efficient manner 5,7,21,22. Inspired by these"}, {"title": "2.1. Learning in biological organisms and neuromodulatory processes that support it", "content": "Evolution has enabled biological organisms to learn and adapt to uncertain and changing\nenvironments throughout their lives. Here we review the most important LL capabilities of\nbiological systems and neural processes that support them:\nLearning continuously. Biological agents have evolved the ability to adapt to changing task\ndemands throughout their lifetime to maintain their survival in natural environments. This ability\nto flexibly integrate new information while retaining previous knowledge is recognised as\nlearning continuously 6,21,22. In intelligent systems, a similar process involves sequential\nlearning of multiple tasks in the face of continuous streams of information is defined as\ncontinual learning, which is often limited by catastrophic forgetting, where a network acquires\nnew information without preserving previously acquired knowledge 23\u201325. However, as\nknowledge and tasks are provided incrementally over a lifetime, this term is often used\ninterchangeably with LL, with many studies not making a strict distinction between the two\n5,7,21.\nSeveral biological processes in the brain serve as the basis for this capability; For example at\nthe macroscopic level, the states of sleep and wakefulness are controlled by the interactions\nof the cholinergic and histaminergic neuromodulatory systems, promoting dynamic memory\nstorage for continuous learning 26,27 At the mesoscopic level, metaplasticity processes\nmediated by neuromodulators and glial cells further enhance continuous learning by\nselectively modulating synaptic connections 4,11. Similarly, dendritic spike-dependent plasticity\nalso plays a critical role by selectively preserving and updating essential synaptic connections\nbetween neurons 28,29. At the neuronal level, neurogenesis supports memory consolidation\nthrough the generation of new neurons 30. Finally, at the sub-neuronal level, both ionotropic\nand metabotropic receptors are key in shaping both short- and long-term synaptic plasticity\nmechanisms, affecting continuous learning 31,32.\nAdaptive knowledge transfer. The dynamic nature of the environment forces living\norganisms to adapt rapidly, encouraging task-specific directional transfer of knowledge across\ntasks, either from an old task to a new task (forward transfer), or from a new task to an older\ntask to refine learned task presentations (backward transfer). In addition, many species are\nable to detect changes in contingency and make inferences without identifying specific tasks\n(task-agnostic learning). As a result, life forms are able to learn quickly and efficiently from a\nfew trials, a phenomenon known as few-shot learning 5,7,21,33,34.\nNeuromodulators such as dopamine (DA), serotonin (5-HT), acetylcholine (ACh) and\nnoradrenaline (NA) are thought to underlie the process of adaptive learning. They are released\nin response to contextual changes and influence the behavioral and cognitive states of\nbiological organisms 10,11,35,36. However, it is also important to note that the \u201cwiring rules\" of\nbiological neural networks do not necessarily depend on experiences alone and can be\nestablished through evolution. These innate abilities in animals are part of a broader learning\nprocess that appears to be encoded in their genomes, a process that may be related to\n\u201csupervised evolution\u201d 37,38 [(Kar & DiCarlo, 2023; Zador, 2019)].\""}, {"title": "Tolerance to noise.", "content": "Real-world environments are characterized by uncertainty and noise.\nNevertheless, biological organisms are largely robust to these conditions and respond\noptimally to their surrounding environment 33. Particularly, the modulation of the signal-to-noise\nratio by neuromodulators such as NA 39 and ACh 40 plays a crucial role in the robustness of\nbiological systems to noise 11. Similarly, dendritic structures and homeostatic plasticity\ncontribute to this tolerance by maintaining a high signal-to-noise ratio at potentiated synapses,\nensuring that essential signals are discerned amidst the noise 41. Furthermore, some studies\nsuggest that neural within-type heterogeneity contributes to resilience against pathological\nsynchronization 42,43. This appears to promote stability and robustness in learning, a recent\nfinding supported by computational studies 13,15,18\nResource efficiency. Living organisms have limited resources that they must manage to\nachieve good performance in their tasks. This fundamental constraint could force them to\nlearn at multiple timescales, thus becoming efficient organisms by optimizing the use of their\ncapabilities and energies to survive and thrive in a competitive environment 6,7,33. In particular,\nresearch has linked neural heterogeneity with efficient encoding of sensory systems 44.\nSimilarly, the multi-timescale effects of neuromodulatory systems, combined with the various\ncell-specific targets they influence, could also be responsible for the learning efficiency of\nneural systems 11."}, {"title": "3. Neural network models and their level of bioinspiration", "content": "The way each neuron computes input signals in a neural network is fundamental, as it\nestablishes the framework for the network model and its degree of bio-inspiration. Therefore,\nnetwork models can be classified in three main categories (see Table 1). These categories\nreflect varying degrees of adherence to biological principles, from the most abstract (top-down\nmodels) to the most detailed (bottom-up models)."}, {"title": "Abstract neural networks.", "content": "In these networks, neurons are modeled as perceptrons, where\neach neuron's output is a function of a weighted sum of its inputs followed by a non-linear\nactivation function 74. The use of abstract representations in these neural networks reduces\ncomputational complexity, enabling processing of large volumes of data and complex tasks at\nlow computational costs 2,3. Hence, they have been widely employed in deep learning\napplications such as computer vision 37,45, natural language processing 1, and navigation and\ndecision-making tasks 47\u201349,51."}, {"title": "Rate-based neural networks.", "content": "From a theoretical neuroscience standpoint, the firing rate of\na biological neuron is defined as the count of spikes it presents within a specified time interval,\ndivided by that interval's length (and often averaged across multiple trials) 75. Inspired by the\ncomputation of these, rate-based neural networks define their activity through time-dependent\nfiring rates, thereby accounting for the temporal representations of data and signal processing.\nThis makes them useful for studying phenomena such as plasticity and learning at a neural\nlevel. As such, they are used in tasks such as perceptual decision-making and motor control\n54-56, as well as in image classification tasks that exploit bio-inspired insights into\nbackpropagation signals 52,53."}, {"title": "Spike-based neural networks.", "content": "Initially developed in computational neuroscience to depict\nsingle-cell level activities, spike-based NNs (also known as spiking neural networks (SNNs))\nsimulate the precise neuronal spikes with the aim of simulating the temporal aspects of\nneuronal activities 75. However, the biological complexity of neuronal spikes leads to a wide\narray of models, each varying in complexity and degree of biological inspiration. Therefore,\nthese models are broadly classified into conductance-based models, which explore the\nbiological mechanisms of neuronal activity, and phenomenological models, which describe\nbehavior based on observable phenomena 75\u201377.\nConductance-based models. Grounded in the Hodgkin and Huxley (HH) model, conductance-\nbased models accurately describe how membrane potentials behave in a sub-neuronal level\n75,78. Additionally, given their biophysical fidelity, these models incorporate dendritic structures\nthrough multiple compartments 64\u201366,68, and typically run on simulation environments like\nNEURON 79,80, or Brian 2 81. In this last simulator, the Dendify environment has recently gained\nimportance as a versatile framework that simplifies the incorporation of dendritic structures\ninto SNNs 82."}, {"title": "Phenomenological models.", "content": "The intrinsic complexity of the Hodgkin and Huxley model has\nprompted the development of simplified variants that generate spiking behaviors through\nbifurcation theory 75\u201377. The simplest case, the leaky integrate-and-fire (LIF) neuron, captures\nthe basic firing mechanism of neurons 76,83. Its simplicity and scalability make it popular in\nSNNS 58,63,67 and neuromorphic hardware 8,9,84,85. However, this simplicity also limits its ability\nto represent specific neuronal activities, leading to the development of numerous variants that\nincorporate different biological features 59,76,86,87"}, {"title": "3.1. Bio-inspiration versus complexity tradeoff in neuron models", "content": ""}, {"title": "4. Task-driven learning strategies in artificial neural networks.", "content": "The choice of an appropriate learning algorithm is strongly related to the desired model\narchitecture and the level of biological inspiration needed. In this way, each algorithm presents\ndistinct advantages and limitations, which must be carefully considered in relation to the\nspecific task at hand. We analyzed these algorithms across a spectrum of cognitive and Al\ntasks (Figure 3), revealing nuanced insights into their applicability and efficacy."}, {"title": "Gradient-based algorithms.", "content": "These algorithms optimize a loss function using gradient\ndescent, thereby updating model parameters to improve performance 2,3. Their foundation lies\nin the Backpropagation (BP) algorithm, which uses the chain rule to propagate errors\nbackward through abstract and rate-based NNs 110. BP effectively addresses the credit\nassignment problem in ANNs, and its high performance makes it widely used for tasks like\nnatural language processing 1,58, image and speech recognition 45,46,111 and signal processing\n112,113. However, its biological plausibility is often questioned, though ongoing efforts aim to\ninterpret and validate its mechanisms in biological terms 49,114\u2013117.\nTo enhance the applicability of BP across different NN models, numerous variants have been\ndeveloped. For instance, BP has been adapted for RNNs to handle temporal dynamics in data\n114. Another variant, Feedback Alignment (FA), adapts BP as a local learning rule, closer to\nbiological plasticity, and has shown remarkable results in image classification 118 and signal\nprocessing tasks 119. Furthermore, BP has been extended to SNNs by applying surrogate\ngradients to the non-differentiable spikes 34,120. Particularly, eligibility propagation (e-prop)\nutilize this technique along eligibility traces to backpropagate signals in an efficient and bio-\ninspired manner achieving high performances in supervised and reward-based tasks through\nDeep RL frameworks 92,121.\nOverall, gradient-based methods excel in isolated learning paradigms, efficiently handling\ndeep layers and numerous parameters inherent to abstract neural networks, essential for\nstate-of-the-art Al tasks 3. However, their susceptibility to catastrophic forgetting necessitates\nregularization methods to enhance their robustness and applicability in LL scenarios 81."}, {"title": "Regularized gradient-based algorithms.", "content": "Gradient-based algorithms can incorporate\nregularization techniques like Dropout to prevent overfitting and enhance performance in\nabstract NNs 122. Recently these techniques have evolved to enable continual learning\ncapabilities across different tasks by preventing the synaptic weights from overwriting, as\nhappens with orthogonal weight modification (OWM) 123, memory aware synapses (MAS) 124,\nSliced Cramer Preservation (SCP) 125, synaptic intelligence (SI) 126 or elastic weight\nconsolidation (EWC) 127. Particularly, these last two methods draw inspiration from dendritic\nsynaptic plasticity and have been proven to be similar to those biological neurons use,\ninvolving NMDA-mediated plasticity and the grouping of close-related synapses 29,128\u2013131.\nDespite their proven capabilities 132, their focus on image classification and perception has left\nthem underexplored in a broader range of real-world applications."}, {"title": "Synaptic plasticity algorithms.", "content": "Grounded in neuronal learning mechanisms and the\nHebbian principle 133, synaptic plasticity methods are characteristic of spike-based NNs 134,\nthough some variants are also found in abstract NNs 1,135. In the SNN domain, the spike-\ntiming-dependent plasticity (STDP) algorithm stands out as a stable and bio-inspired approach\nthat emphasizes the exact timing of spikes between pre- and post-synaptic neurons 63,136\u2013138\nHence, many studies have implemented this rule in unsupervised contexts solving tasks\nranging from time series prediction 139 to pattern 140 and image classification 141. However, for"}, {"title": "Modulated synaptic plasticity algorithms.", "content": "Despite the inherent bioinspiration of synaptic\nplasticity algorithms, they become significantly more powerful when integrated with\nmodulatory signals, which enhance their learning capabilities, thus transforming these\nmethods into neo-Hebbian methods 144,145. Methods like gated Hebbian rules 146, rarely\ncorrelating Hebbian plasticity (RCHP) 57,136, and the exploratory hebbian (EH) algorithm 55,147,\nmodulate synaptic plasticity with reward signals or context-aware mechanisms, achieving\ngood performance in image classification, cue-association, and motor control tasks.\nNevertheless, the STDP rule is particularly interesting for integrating these modulatory signals,\nas neuromodulatory signals regulate its window of plasticity induction 148\u2013150. In this context,\nthe rule is known as Reward-modulated STDP (R-STDP), which adjusts the plasticity window\nbased on a varying reward signal. The most direct use of this signal acts as a form of dopamine\n(DA) modulation influencing synapses 106,107,151, linking it to the reinforcement scenarios as in\nTD-STDP 152 or actor-critic architectures with PSAC learning 153. Additionally, some studies\nextend these concepts further, attempting to consider the effects of various neuromodulator\nsignals, including co-release of DA and ACh 72,148,154, as well as DA and 5-HT 71.These\nmethods are particularly intriguing as they offer ways to incorporate ANNs into reinforcement\nor unsupervised learning scenarios, reflecting the adaptive nature of biological learning\nprocesses. Hence, modulated STDP rules stand out as versatile methods that are easily\nintegrated into reinforcement paradigms. Furthermore, these rules can integrate adaptive\nlearning through context-aware signals that have a biological foundation in neuromodulators."}, {"title": "Evolutionary algorithms.", "content": "Inspired by Darwinian evolution, evolutionary algorithms were\ncreated in computer science to solve complex nonlinear optimization problems by mimicking\nthe iterative process of biological evolution, focusing on the survival of the fittest solutions\n155,156. Their robustness and adaptability to various NN models make them ideal for behavioral\nand perceptual tasks, excelling where gradient-based methods struggle due to the complexity\nof optimizations 157,158. Additionally, they have been employed to model specific brain\nbehaviors, offering insights into neural mechanisms and contributing to our understanding of\ncognitive functions 64,159.\nDespite the lack of direct neuro-inspiration, these algorithms crucially bridge the gap for what\ncan be termed biological \u201csupervised evolution.\u201d They belong to an outer-loop of learning that\nis associated with biological innate abilities (zero-shot learning) where organisms can perform\ntasks without prior direct exposure to those specific challenges 37,38,50."}, {"title": "RL-based algorithms.", "content": "Inspired by behavioral psychology, RL-based techniques enable\nlearning through the interaction of an agent with its environment. The agent takes actions,\nprompting changes in states and receiving rewards, allowing it to refine its policy and optimize\nbehavior 160. Traditionally used with abstract models, RL has been significantly enhanced by\nintegrating with ANNs, leading to Deep RL. This advancement combines RL's decision-making"}, {"title": "Meta-learning and neuromodulatory-inspired learning.", "content": "Meta-learning, often described as \"learning to learn\", is defined as the system's capability to adapt its learning\nprocess. It involves integrating multiple learning loops within the same system, enabling it to tackle tasks across\nvarious timescales 22. Therefore, meta-learning procedures enable the use of more than one learning algorithm to\nlearn the different learning loops. For instance, an inner loop might be governed by synaptic plasticity and the outer\nloop by gradient descent, or the outer loops can correspond to evolutionary or RL-based algorithms 50,63,157\nNeuromodulation is intricately linked to meta-learning, as it influences synaptic plasticity via an outer loop. In SNNs,\nthis is directly incorporated through modulated synaptic plasticity rules within a reinforcement paradigm 10,57,71,154\nThis concept also extends to abstract NNs through outer loops that govern hyperparameter learning 164-166\nMoreover, neuromodulators can regulate transitions between sleep and awake states in artificial neural networks\n(ANNs), thereby enhancing their continual learning capabilities 27."}, {"title": "5. Integrating bio-inspired architectures into ANNs", "content": "ANN architectures fundamentally rely on two primary structures differentiated by the flow of\ninformation: feedforward neural networks (FFNNs), where information flows linearly from\ninputs to outputs, and recurrent neural networks (RNNs), where information is also looped\nback into the network through recurrent connections among neurons 75. With the development\nof deep learning, the inclusion of deep-hidden layers was initially pursued to handle more\ncomplex tasks 2,3. However, this approach appears to have reached its limits, prompting a shift\ntowards integrating bio-inspired features that mimic LL capabilities found in biological systems\n6, thereby generating new bio-inspired architectures (Figure 3)."}, {"title": "5.1. Mitigating catastrophic forgetting through dendritic structures", "content": "Dendritic architectures emerge in the context of biophysical models, with dendritic trees being\nmodeled as electrical circuits consisting of multiple compartments 41. However, these models\nare complex and computationally demanding, prompting the development of sophisticated\narchitectures designed to emulate their capabilities within abstract NNs of point neurons 172.\nThis has led to the incorporation of dendritic-like processing in network structures, which aims\nto capture the input properties of the neuron with a more efficient description 173. Here,\ndendritic computations can be effectively represented using two- and three-layered\nfeedforward network models. In this approach, inputs are integrated nonlinearly through an\nactivation function, and then signals are further integrated to the neuron. These activation\nfunctions are often sigmoid functions 174,175, but other approaches utilize sub- and supra-linear\nfunctions to more accurately represent dendritic behaviors 66.\nCurrently, dendrites, as they help mitigate catastrophic forgetting in the brain, have become\nan essential feature for supporting continual learning in ANNs 29,128. Particularly, some\napproaches use context-driven dendritic layers in abstract NNs 176 or NMDA-driven modulation\nin spike-based NNs 177 for multi-task learning, while others employ rate- and spike-based NNs\nwith burst-dependent plasticity learning algorithms, giving rise to the so-called Bursting\nCortico-Cortical Networks (BurstCNN), thereby solving the credit assignment problem by\nback-propagating signals in the dendrites 52,60,91. Additionally, dendritic trees enhance ANN\nefficiency, allowing fewer neurons to handle complex tasks. For instance, they have been\ndemonstrated to solve the XOR problem with a two-compartment single neuron model, which\ntypically requires multiple layers of point neurons 178."}, {"title": "5.2. Facilitating Multi-Task Learning Through Modularity and Neurogenesis", "content": "Dynamic architectures - inspired by neurogenesis in the hippocampus - adapt by adding new\nneuronal resources while training for new tasks, to preserve knowledge in response to new\ninformation 179. Similarly, modular architectures directly utilize parallel sub-modules to\nadaptively address specific tasks. These networks are aligned with the brain's functional\nconnectivity, offering a solution for multi-task learning and knowledge transfer 5.\nProgressive networks exemplify both strategies by incrementally expanding its abstract NN\narchitecture with new sub-networks dedicated to each new task while preserving a collection\nof pre-trained modules for each task already learned 171. However, this design, although it\nfacilitates the simultaneous learning of multiple tasks, results in escalating complexity as the\nnumber of tasks increases."}, {"title": "5.3. Getting inspiration from Dale's law: excitatory and inhibitory networks", "content": "Architectures that include various neural populations exemplify bio-inspired approaches to\nintegrating modularity in ANNs. Fundamentally, till now, these architectures have primarily\nfocused on incorporating both excitatory and inhibitory neuron populations. They are based\non Dale's law, which posits that a neuron releases the same neurotransmitters at all its\nsynapses, influencing other neurons in a consistent manner - either by exciting or inhibiting\nthem 180. However, recent research has refined Dale's law, showing that neurons can release\ndifferent combinations of neurotransmitters and that the effect on the target neuron varies\ndepending on its specific receptors 181,182. Despite this, numerous computational models use\nthis principle to consider different populations of excitatory and inhibitory neurons. They\nassume that excitatory presynaptic neurons make purely excitatory (positive weights)\nconnections with postsynaptic neurons and inhibitory ones make purely inhibitory (negative\nweights) connections 54,147,168.\nThe presence of these two neuronal types has led to the development of new neural network\narchitectures, ranging from RNNs to Deep Learning structures, adding a biological constraint\nto any type of NN model. Some use a RNN with populations of excitatory and inhibitory\nneurons in a 4:1 ratio 54,56,92,107. Others incorporate this biological constraint to the feed-forward\nconnections of DNNs or CNNs, resulting in an architecture called column excitation-inhibition\n(ColEI) 183. However, since this structure usually impairs learning, Dale's principle is typically\nleft out of abstract NNs 168,183,184. This issue led to the development of the Dale's ANN (DANN)\narchitecture, inspired from feedforward inhibitory interneurons in the brain. Here, every layer\nof the network is composed of either excitatory or inhibitory units, following the biological\nproportion. Furthermore, only excitatory units can project between layers while inhibition is\nmanaged by activation rules that allow effective modulation between both populations. Thus,\ninhibition is not constrained by the sign of the synaptic weight and DANNs does not sacrifice\nlearning performance 168,183.\nThe implementation of excitatory and inhibitory neural populations in ANNs appears essential\nfor adding a bio-inspired element to their design. However, simply incorporating excitatory and\ninhibitory populations is not sufficient to fully capture the complexity of biological systems. To\nfurther enhance the bio-inspiration of ANNs, it is crucial to integrate population heterogeneity\nthrough diverse spiking behaviors in SNNs. This approach has been recently demonstrated to"}, {"title": "5.4. Modulating contextual signals and attention through astrocytes", "content": "Recent architectures go beyond neuronal populations and focus on the modeling of astrocytes\ndue to their in cognitive processes. Therefore, new perspectives are seeking bio-inspired\narchitectures that incorporate an astrocyte NN guided by contextual triggers to modulate\nneurons in ANNs 169. In this direction, neuron-astrocyte liquid state machine (NALSM)\narchitectures have also been proposed to account for the modulation of synapses by\nastrocytes, achieving performance levels like those of multi-layer SNNs trained with\nbackpropagation 86.\nAnother study links the astrocyte network within an abstract NN by constructing a neuron-\nastrocyte model that replicates the functionality of a Transformer 170 [(Kozachkov et al., 2023)].\nTransformers represent a complex network architecture utilized in natural language\nprocessing, distinguished by their self-attention mechanism 185. This feature enables them to\ncapture long-range dependencies between words in a sentence efficiently, eliminating the\nneed for maintaining a hidden state over extended periods, as required in recurrent models.\nHowever, human learning differs significantly from that of Transformers, as these architectures\ndo not address the issues of data dependency and high energy consumption associated with\nDNNS 186."}, {"title": "6. Integrating neural diversity and neuromodulatory signals into artificial neural networks", "content": "The field of ANNs is constantly evolving, witnessing emerging learning rules, architectural\ndesigns, and morphological features inspired by biological systems to improve continual\nlearning, adaptability, robustness and resource efficiency in ANNs 5\u20137. To further address\nthese challenges, we propose a dual-framework approach that combines biologically-informed\ndendritic models and task-driven SNNs of point neurons to facilitate improved performance\nand efficiency in ANNs (Figure 4). Our approach balances biological fidelity and computational\nefficiency by the simulation of neuronal activity using the IZ 101,104 and GLIF 87,109 models and\nimposing constraints to the synaptic weight to define excitatory and inhibitory populations. This\nallows to account for the spiking heterogeneity that characterizes neural systems 43,187,188 and\nbrings the opportunity to account neuromodulatory cell-specific effects to the network 11,189\u2013191\nThis approach has the potential to incorporate neuron specificity and cell-specific\nneuromodulatory signals, while maintaining the highest level of simplicity possible, making it\nreasonably cost-efficient even in large-scale SNNs."}, {"title": "6.1. Implications of neuron heterogeneity in continual learning.", "content": "The biological brain is characterized by its cell type diversity, featuring a wide variety of\nneurons with different morphologies and spiking behaviors 19,43,76,187,188, which influence how\nthey process temporal information. In contrast, most ANNs use uniform sets of neurons to\nprocess information, restricting their learning to plasticity dynamics. Despite being traditionally\noverlooked 19, recent computational studies suggest that the incorporation of neural\nheterogeneity contributes to LL by (i) improving task performance 13, (ii) promoting stable and\nrobust learning 13\u201315, (iii) facilitating multi-timescale learning 16,17 and (iv) efficiently adapting\ncomputations in the SNNs 18.\nPractically, in SNNs, neural heterogeneity can be mainly introduced either morphologically, by\ndefining distinct dendritic compartments for different neuron types, or functionally, by\nsimulating different spiking behaviors. Morphological heterogeneity has been explored\nthrough dendritic architectures by defining cell-types, such as pyramidal neurons, interneurons\nor basket cells, with different dendritic compartments 16,60,66. Particularly, such efforts have"}, {"title": "6.2. Implications of neuromodulators in continual learning.", "content": "Neuromodulatory systems, in essence, provide a multi-layered contextual-guided control over\ncognition and behavior in nervous systems. They operate on distinct temporal scales and\ninfluence both (i) spiking behavior at the neuronal level and (ii) global network plasticity\nproperties at the circuitry level, thereby reconfiguring network dynamics at a systems level\n11,12,196. Particularly, spiking control systems have leveraged neuromodulatory influences at"}, {"title": "6.3. Applications and limitations", "content": "The integration of learning at different spatio-temporal scales aims to be a versatile approach,\napplicable to a wide range of tasks, from behavioral studies to Al applications. Particularly,\nreward-based tasks can take advantage of neural heterogeneity by allowing population-level\nlearning 70. Therefore, reinforcement learning scenarios of motor control and spatial navigation\ntasks are well-suited paradigms in which incorporate this framework, where contextual signals\ncan guide behavior 10,35,71,152,197.\nFurthermore, the generalizability of this framework supports Al supervised learning tasks like\nimage classification and object and speech recognition 13,34,92,120,121, aiming for few-shot and\nmulti-task learning paradigms. In this context, a study mitigated catastrophic forgetting in a\nclass-incremental scenario through population threshold modulation of an SNN 62. Here,\ninstead of introducing an artificial gating mechanism as with regularized gradient-based\nalgorithms 132, they utilized the inherent gating of SNNs and used neuromodulatory signals to\nmodulate this threshold.\nOverall, this framework aims to surpass the performance of current SNN models and provide\nnew approaches for efficient and robust continual learning, as already demonstrated by recent\nstudies 13,18,62. Nevertheless, despite the successful interpretation of neuromodulatory signals\nand spiking patterns within this framework, these models are computationally more demanding"}]}