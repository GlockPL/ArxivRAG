{"title": "Enhancing learning in artificial neural networks through cellular heterogeneity and neuromodulatory signaling", "authors": ["Alejandro Rodriguez-Garcia", "Jie Mei", "Srikanth Ramaswamy"], "abstract": "Recent progress in artificial intelligence (AI) has been driven by insights from neuroscience, particularly with the development of artificial neural networks (ANNs). This has significantly enhanced the replication of complex cognitive tasks such as vision and natural language processing. Despite these advances, ANNs struggle with continual learning, adaptable knowledge transfer, robustness, and resource efficiency \u2013 capabilities that biological systems handle seamlessly. Specifically, ANNs often overlook the functional and morphological diversity of the brain, hindering their computational capabilities. Furthermore, incorporating cell-type specific neuromodulatory effects into ANNs with neuronal heterogeneity could enable learning at two spatial scales: spiking behavior at the neuronal level, and synaptic plasticity at the circuit level, thereby potentially enhancing their learning abilities. In this article, we summarize recent bio-inspired models, learning rules and architectures and propose a biologically-informed framework for enhancing ANNs. Our proposed dual-framework approach highlights the potential of spiking neural networks (SNNs) for emulating diverse spiking behaviors and dendritic compartments to simulate morphological and functional diversity of neuronal computations. Finally, we outline how the proposed approach integrates brain- inspired compartmental models and task-driven SNNs, balances bioinspiration and complexity, and provides scalable solutions for pressing Al challenges, such as continual learning, adaptability, robustness, and resource-efficiency.", "sections": [{"title": "1. Introduction", "content": "In recent years, artificial intelligence (AI) has not only marked a significant evolution in technology but has also redefined the capabilities of machines, mirroring certain aspects of human intelligence with remarkable fidelity. At the forefront of this progress are advances in artificial neural networks (ANNs), particularly through the integration of deep learning. These networks, known as deep neural networks (DNNs) and characterized by their multi-layer architectures, have demonstrated an impressive ability to learn from vast amounts of data 1\u20133."}, {"title": "2. From Isolated to Lifelong Learning", "content": "Learning can be defined as a dynamic process of restructuring a system to improve its task performance through experience 7,20,21. Traditional Al approaches use machine and deep learning techniques to adapt models and improve task performance through model training, typically operating within supervised or unsupervised learning paradigms 2. Learning in these methods is isolated and based on specific datasets and tasks, demonstrating limited ability to process and retain contextual information and/or previously learned knowledge 22. Additionally, they rely heavily on the training data and require extensive computational resources, limiting the capacity of the models to improve 8,9. On the contrary, the dynamic nature of real-world scenarios requires biological organisms to develop and employ Lifelong Learning (LL), effectively managing ever-changing task demands and adapting to their environment to ensure survival. This capability, developed and refined through evolution, allows them to (i) learn tasks sequentially and (ii) transfer and adapt task knowledge according to contextual changes in a (iii) robust and (iv) cost-efficient manner 5,7,21,22. Inspired by these mechanisms, new learning paradigms such as online, multi-task, few-shot learning, and reinforcement learning are emerging 22."}, {"title": "2.1. Learning in biological organisms and neuromodulatory processes that support it", "content": "Evolution has enabled biological organisms to learn and adapt to uncertain and changing environments throughout their lives. Here we review the most important LL capabilities of biological systems and neural processes that support them:\nLearning continuously. Biological agents have evolved the ability to adapt to changing task demands throughout their lifetime to maintain their survival in natural environments. This ability to flexibly integrate new information while retaining previous knowledge is recognised as learning continuously 6,21,22. In intelligent systems, a similar process involves sequential learning of multiple tasks in the face of continuous streams of information is defined as continual learning, which is often limited by catastrophic forgetting, where a network acquires new information without preserving previously acquired knowledge 23\u201325. However, as knowledge and tasks are provided incrementally over a lifetime, this term is often used interchangeably with LL, with many studies not making a strict distinction between the two 5,7,21\nSeveral biological processes in the brain serve as the basis for this capability; For example at the macroscopic level, the states of sleep and wakefulness are controlled by the interactions of the cholinergic and histaminergic neuromodulatory systems, promoting dynamic memory storage for continuous learning 26,27 At the mesoscopic level, metaplasticity processes mediated by neuromodulators and glial cells further enhance continuous learning by selectively modulating synaptic connections 4,11. Similarly, dendritic spike-dependent plasticity also plays a critical role by selectively preserving and updating essential synaptic connections between neurons 28,29. At the neuronal level, neurogenesis supports memory consolidation through the generation of new neurons 30. Finally, at the sub-neuronal level, both ionotropic and metabotropic receptors are key in shaping both short- and long-term synaptic plasticity mechanisms, affecting continuous learning 31,32.\nAdaptive knowledge transfer. The dynamic nature of the environment forces living organisms to adapt rapidly, encouraging task-specific directional transfer of knowledge across tasks, either from an old task to a new task (forward transfer), or from a new task to an older task to refine learned task presentations (backward transfer). In addition, many species are able to detect changes in contingency and make inferences without identifying specific tasks (task-agnostic learning). As a result, life forms are able to learn quickly and efficiently from a few trials, a phenomenon known as few-shot learning 5,7,21,33,34\nNeuromodulators such as dopamine (DA), serotonin (5-HT), acetylcholine (ACh) and noradrenaline (NA) are thought to underlie the process of adaptive learning. They are released in response to contextual changes and influence the behavioral and cognitive states of biological organisms 10,11,35,36. However, it is also important to note that the \u201cwiring rules\" of biological neural networks do not necessarily depend on experiences alone and can be established through evolution. These innate abilities in animals are part of a broader learning process that appears to be encoded in their genomes, a process that may be related to \u201csupervised evolution\u201d 37,38 [(Kar & DiCarlo, 2023; Zador, 2019)]."}, {"title": "3. Neural network models and their level of bioinspiration", "content": "The way each neuron computes input signals in a neural network is fundamental, as it establishes the framework for the network model and its degree of bio-inspiration. Therefore, network models can be classified in three main categories (see Table 1). These categories reflect varying degrees of adherence to biological principles, from the most abstract (top-down models) to the most detailed (bottom-up models)."}, {"title": "Abstract neural networks.", "content": "In these networks, neurons are modeled as perceptrons, where each neuron's output is a function of a weighted sum of its inputs followed by a non-linear activation function 74. The use of abstract representations in these neural networks reduces computational complexity, enabling processing of large volumes of data and complex tasks at low computational costs 2,3. Hence, they have been widely employed in deep learning applications such as computer vision 37,45, natural language processing 1, and navigation and decision-making tasks 47\u201349,51."}, {"title": "Rate-based neural networks.", "content": "From a theoretical neuroscience standpoint, the firing rate of a biological neuron is defined as the count of spikes it presents within a specified time interval, divided by that interval's length (and often averaged across multiple trials) 75. Inspired by the computation of these, rate-based neural networks define their activity through time-dependent firing rates, thereby accounting for the temporal representations of data and signal processing. This makes them useful for studying phenomena such as plasticity and learning at a neural level. As such, they are used in tasks such as perceptual decision-making and motor control 54-56, as well as in image classification tasks that exploit bio-inspired insights into backpropagation signals 52,53."}, {"title": "Spike-based neural networks.", "content": "Initially developed in computational neuroscience to depict single-cell level activities, spike-based NNs (also known as spiking neural networks (SNNs)) simulate the precise neuronal spikes with the aim of simulating the temporal aspects of neuronal activities 75. However, the biological complexity of neuronal spikes leads to a wide array of models, each varying in complexity and degree of biological inspiration. Therefore, these models are broadly classified into conductance-based models, which explore the biological mechanisms of neuronal activity, and phenomenological models, which describe behavior based on observable phenomena 75\u201377."}, {"title": "Conductance-based models.", "content": "Grounded in the Hodgkin and Huxley (HH) model, conductance- based models accurately describe how membrane potentials behave in a sub-neuronal level 75,78. Additionally, given their biophysical fidelity, these models incorporate dendritic structures through multiple compartments 64\u201366,68, and typically run on simulation environments like NEURON 79,80, or Brian 2 81. In this last simulator, the Dendify environment has recently gained importance as a versatile framework that simplifies the incorporation of dendritic structures into SNNs 82."}, {"title": "Phenomenological models.", "content": "The intrinsic complexity of the Hodgkin and Huxley model has prompted the development of simplified variants that generate spiking behaviors through bifurcation theory 75\u201377. The simplest case, the leaky integrate-and-fire (LIF) neuron, captures the basic firing mechanism of neurons 76,83. Its simplicity and scalability make it popular in SNNS 58,63,67 and neuromorphic hardware 8,9,84,85. However, this simplicity also limits its ability to represent specific neuronal activities, leading to the development of numerous variants that incorporate different biological features 59,76,86,87"}, {"title": "3.1. Bio-inspiration versus complexity tradeoff in neuron models", "content": ""}, {"title": "4. Task-driven learning strategies in artificial neural networks.", "content": "The choice of an appropriate learning algorithm is strongly related to the desired model architecture and the level of biological inspiration needed. In this way, each algorithm presents distinct advantages and limitations, which must be carefully considered in relation to the specific task at hand. We analyzed these algorithms across a spectrum of cognitive and Al tasks (Figure 3), revealing nuanced insights into their applicability and efficacy."}, {"title": "Gradient-based algorithms.", "content": "These algorithms optimize a loss function using gradient descent, thereby updating model parameters to improve performance 2,3. Their foundation lies in the Backpropagation (BP) algorithm, which uses the chain rule to propagate errors backward through abstract and rate-based NNs 110. BP effectively addresses the credit assignment problem in ANNs, and its high performance makes it widely used for tasks like natural language processing 1,58, image and speech recognition 45,46,111 and signal processing 112,113. However, its biological plausibility is often questioned, though ongoing efforts aim to interpret and validate its mechanisms in biological terms 49,114\u2013117.\nTo enhance the applicability of BP across different NN models, numerous variants have been developed. For instance, BP has been adapted for RNNs to handle temporal dynamics in data 114. Another variant, Feedback Alignment (FA), adapts BP as a local learning rule, closer to biological plasticity, and has shown remarkable results in image classification 118 and signal processing tasks 119. Furthermore, BP has been extended to SNNs by applying surrogate gradients to the non-differentiable spikes 34,120. Particularly, eligibility propagation (e-prop) utilize this technique along eligibility traces to backpropagate signals in an efficient and bio- inspired manner achieving high performances in supervised and reward-based tasks through Deep RL frameworks 92,121.\nOverall, gradient-based methods excel in isolated learning paradigms, efficiently handling deep layers and numerous parameters inherent to abstract neural networks, essential for state-of-the-art Al tasks 3. However, their susceptibility to catastrophic forgetting necessitates regularization methods to enhance their robustness and applicability in LL scenarios 81."}, {"title": "Regularized gradient-based algorithms.", "content": "Gradient-based algorithms can incorporate regularization techniques like Dropout to prevent overfitting and enhance performance in abstract NNs 122. Recently these techniques have evolved to enable continual learning capabilities across different tasks by preventing the synaptic weights from overwriting, as happens with orthogonal weight modification (OWM) 123, memory aware synapses (MAS) 124, Sliced Cramer Preservation (SCP) 125, synaptic intelligence (SI) 126 or elastic weight consolidation (EWC) 127. Particularly, these last two methods draw inspiration from dendritic synaptic plasticity and have been proven to be similar to those biological neurons use, involving NMDA-mediated plasticity and the grouping of close-related synapses 29,128\u2013131. Despite their proven capabilities 132, their focus on image classification and perception has left them underexplored in a broader range of real-world applications."}, {"title": "Synaptic plasticity algorithms.", "content": "Grounded in neuronal learning mechanisms and the Hebbian principle 133, synaptic plasticity methods are characteristic of spike-based NNs 134, though some variants are also found in abstract NNs 1,135. In the SNN domain, the spike- timing-dependent plasticity (STDP) algorithm stands out as a stable and bio-inspired approach that emphasizes the exact timing of spikes between pre- and post-synaptic neurons 63,136\u2013138 Hence, many studies have implemented this rule in unsupervised contexts solving tasks ranging from time series prediction 139 to pattern 140 and image classification 141. However, for greater bio-plausibility, some research opts for a triplet-based variant, which considers one pre-synaptic spike and two post-synaptic spikes accounting for higher spatiotemporal correlations 63,142. Additionally, newer methodologies, like Burstprop and Burst Ensemble Multiplexing (BEM), leverage synaptic bursting activity, backpropagating signals in rate-based neurons with dendritic compartments, and supporting supervised learning in perceptual and image recognition tasks 60,91,143"}, {"title": "Modulated synaptic plasticity algorithms.", "content": "Despite the inherent bioinspiration of synaptic plasticity algorithms, they become significantly more powerful when integrated with modulatory signals, which enhance their learning capabilities, thus transforming these methods into neo-Hebbian methods 144,145. Methods like gated Hebbian rules 146, rarely correlating Hebbian plasticity (RCHP) 57,136, and the exploratory hebbian (EH) algorithm 55,147, modulate synaptic plasticity with reward signals or context-aware mechanisms, achieving good performance in image classification, cue-association, and motor control tasks.\nNevertheless, the STDP rule is particularly interesting for integrating these modulatory signals, as neuromodulatory signals regulate its window of plasticity induction 148\u2013150. In this context, the rule is known as Reward-modulated STDP (R-STDP), which adjusts the plasticity window based on a varying reward signal. The most direct use of this signal acts as a form of dopamine (DA) modulation influencing synapses 106,107,151, linking it to the reinforcement scenarios as in TD-STDP 152 or actor-critic architectures with PSAC learning 153. Additionally, some studies extend these concepts further, attempting to consider the effects of various neuromodulator signals, including co-release of DA and ACh 72,148,154, as well as DA and 5-HT 71.These methods are particularly intriguing as they offer ways to incorporate ANNs into reinforcement or unsupervised learning scenarios, reflecting the adaptive nature of biological learning processes. Hence, modulated STDP rules stand out as versatile methods that are easily integrated into reinforcement paradigms. Furthermore, these rules can integrate adaptive learning through context-aware signals that have a biological foundation in neuromodulators."}, {"title": "Evolutionary algorithms.", "content": "Inspired by Darwinian evolution, evolutionary algorithms were created in computer science to solve complex nonlinear optimization problems by mimicking the iterative process of biological evolution, focusing on the survival of the fittest solutions 155,156. Their robustness and adaptability to various NN models make them ideal for behavioral and perceptual tasks, excelling where gradient-based methods struggle due to the complexity of optimizations 157,158. Additionally, they have been employed to model specific brain behaviors, offering insights into neural mechanisms and contributing to our understanding of cognitive functions 64,159.\nDespite the lack of direct neuro-inspiration, these algorithms crucially bridge the gap for what can be termed biological \u201csupervised evolution.\u201d They belong to an outer-loop of learning that is associated with biological innate abilities (zero-shot learning) where organisms can perform tasks without prior direct exposure to those specific challenges 37,38,50."}, {"title": "RL-based algorithms.", "content": "Inspired by behavioral psychology, RL-based techniques enable learning through the interaction of an agent with its environment. The agent takes actions, prompting changes in states and receiving rewards, allowing it to refine its policy and optimize behavior 160. Traditionally used with abstract models, RL has been significantly enhanced by integrating with ANNs, leading to Deep RL. This advancement combines RL's decision-making with Deep Learning's powerful function approximation, creating LL paradigms for reinforcement agents 6,33,160.\nIn the RL context, the Temporal Difference (TD) learning rule is particularly crucial due to its association with DA as the global learning signal for reward predictions 161,162. Expanding on this, additional neuromodulators have been tied to specific RL parameters: 5-HT regulates the balance between short-term and long-term reward predictions, NA adjusts the balance between exploration and exploitation in the policy, and ACh influences the learning rate of the agents 10,11,35,163. This integration enhances decision-making tasks and improves the adaptability and efficacy of continual learning agents, thereby providing an excellent framework for integrating neuromodulatory signals to ANNs 33,35.\nIt is worth noting that all of these methods can be integrated through meta-learning processes, enhancing the versatility of models to solve tasks that they are not optimal for. Therefore, different learning rules can be employed for different learning loops, relevant to multi-task learning 50,63. Additionally, neuromodulation can play a crucial role in controlling or participating in these processes (see Box 2), enriching the models' ability to adapt and perform across diverse applications 10,164."}, {"title": "Box 2: Meta-learning and neuromodulatory-inspired learning.", "content": "Meta-learning, often described as \"learning to learn\", is defined as the system's capability to adapt its learning process. It involves integrating multiple learning loops within the same system, enabling it to tackle tasks across various timescales 22. Therefore, meta-learning procedures enable the use of more than one learning algorithm to learn the different learning loops. For instance, an inner loop might be governed by synaptic plasticity and the outer loop by gradient descent, or the outer loops can correspond to evolutionary or RL-based algorithms 50,63,157\nNeuromodulation is intricately linked to meta-learning, as it influences synaptic plasticity via an outer loop. In SNNs, this is directly incorporated through modulated synaptic plasticity rules within a reinforcement paradigm 10,57,71,154. This concept also extends to abstract NNs through outer loops that govern hyperparameter learning 164-166. Moreover, neuromodulators can regulate transitions between sleep and awake states in artificial neural networks (ANNs), thereby enhancing their continual learning capabilities 27."}, {"title": "5. Integrating bio-inspired architectures into ANNs", "content": "ANN architectures fundamentally rely on two primary structures differentiated by the flow of information: feedforward neural networks (FFNNs), where information flows linearly from inputs to outputs, and recurrent neural networks (RNNs), where information is also looped back into the network through recurrent connections among neurons 75. With the development of deep learning, the inclusion of deep-hidden layers was initially pursued to handle more complex tasks 2,3. However, this approach appears to have reached its limits, prompting a shift towards integrating bio-inspired features that mimic LL capabilities found in biological systems 6, thereby generating new bio-inspired architectures (Figure 3)."}, {"title": "5.1. Mitigating catastrophic forgetting through dendritic structures", "content": "Dendritic architectures emerge in the context of biophysical models, with dendritic trees being modeled as electrical circuits consisting of multiple compartments 41. However, these models are complex and computationally demanding, prompting the development of sophisticated architectures designed to emulate their capabilities within abstract NNs of point neurons 172. This has led to the incorporation of dendritic-like processing in network structures, which aims to capture the input properties of the neuron with a more efficient description 173. Here, dendritic computations can be effectively represented using two- and three-layered feedforward network models. In this approach, inputs are integrated nonlinearly through an activation function, and then signals are further integrated to the neuron. These activation functions are often sigmoid functions 174,175, but other approaches utilize sub- and supra-linear functions to more accurately represent dendritic behaviors 66.\nCurrently, dendrites, as they help mitigate catastrophic forgetting in the brain, have become an essential feature for supporting continual learning in ANNs 29,128. Particularly, some approaches use context-driven dendritic layers in abstract NNs 176 or NMDA-driven modulation in spike-based NNs 177 for multi-task learning, while others employ rate- and spike-based NNs with burst-dependent plasticity learning algorithms, giving rise to the so-called Bursting Cortico-Cortical Networks (BurstCNN), thereby solving the credit assignment problem by back-propagating signals in the dendrites 52,60,91. Additionally, dendritic trees enhance ANN efficiency, allowing fewer neurons to handle complex tasks. For instance, they have been demonstrated to solve the XOR problem with a two-compartment single neuron model, which typically requires multiple layers of point neurons 178."}, {"title": "5.2. Facilitating Multi-Task Learning Through Modularity and Neurogenesis", "content": "Dynamic architectures - inspired by neurogenesis in the hippocampus - adapt by adding new neuronal resources while training for new tasks, to preserve knowledge in response to new information 179. Similarly, modular architectures directly utilize parallel sub-modules to adaptively address specific tasks. These networks are aligned with the brain's functional connectivity, offering a solution for multi-task learning and knowledge transfer 5.\nProgressive networks exemplify both strategies by incrementally expanding its abstract NN architecture with new sub-networks dedicated to each new task while preserving a collection of pre-trained modules for each task already learned 171. However, this design, although it facilitates the simultaneous learning of multiple tasks, results in escalating complexity as the number of tasks increases."}, {"title": "5.3. Getting inspiration from Dale's law: excitatory and inhibitory networks", "content": "Architectures that include various neural populations exemplify bio-inspired approaches to integrating modularity in ANNs. Fundamentally, till now, these architectures have primarily focused on incorporating both excitatory and inhibitory neuron populations. They are based on Dale's law, which posits that a neuron releases the same neurotransmitters at all its synapses, influencing other neurons in a consistent manner - either by exciting or inhibiting them 180. However, recent research has refined Dale's law, showing that neurons can release different combinations of neurotransmitters and that the effect on the target neuron varies depending on its specific receptors 181,182. Despite this, numerous computational models use this principle to consider different populations of excitatory and inhibitory neurons. They assume that excitatory presynaptic neurons make purely excitatory (positive weights) connections with postsynaptic neurons and inhibitory ones make purely inhibitory (negative weights) connections 54,147,168.\nThe presence of these two neuronal types has led to the development of new neural network architectures, ranging from RNNs to Deep Learning structures, adding a biological constraint to any type of NN model. Some use a RNN with populations of excitatory and inhibitory neurons in a 4:1 ratio 54,56,92,107. Others incorporate this biological constraint to the feed-forward connections of DNNs or CNNs, resulting in an architecture called column excitation-inhibition (ColEI) 183. However, since this structure usually impairs learning, Dale's principle is typically left out of abstract NNs 168,183,184. This issue led to the development of the Dale's ANN (DANN) architecture, inspired from feedforward inhibitory interneurons in the brain. Here, every layer of the network is composed of either excitatory or inhibitory units, following the biological proportion. Furthermore, only excitatory units can project between layers while inhibition is managed by activation rules that allow effective modulation between both populations. Thus, inhibition is not constrained by the sign of the synaptic weight and DANNs does not sacrifice learning performance 168,183.\nThe implementation of excitatory and inhibitory neural populations in ANNs appears essential for adding a bio-inspired element to their design. However, simply incorporating excitatory and inhibitory populations is not sufficient to fully capture the complexity of biological systems. To further enhance the bio-inspiration of ANNs, it is crucial to integrate population heterogeneity through diverse spiking behaviors in SNNs. This approach has been recently demonstrated to"}, {"title": "5.4. Modulating contextual signals and attention through astrocytes", "content": "Recent architectures go beyond neuronal populations and focus on the modeling of astrocytes due to their in cognitive processes. Therefore, new perspectives are seeking bio-inspired architectures that incorporate an astrocyte NN guided by contextual triggers to modulate neurons in ANNs 169. In this direction, neuron-astrocyte liquid state machine (NALSM) architectures have also been proposed to account for the modulation of synapses by astrocytes, achieving performance levels like those of multi-layer SNNs trained with backpropagation 86.\nAnother study links the astrocyte network within an abstract NN by constructing a neuron- astrocyte model that replicates the functionality of a Transformer 170 [(Kozachkov et al., 2023)]. Transformers represent a complex network architecture utilized in natural language processing, distinguished by their self-attention mechanism 185. This feature enables them to capture long-range dependencies between words in a sentence efficiently, eliminating the need for maintaining a hidden state over extended periods, as required in recurrent models. However, human learning differs significantly from that of Transformers, as these architectures do not address the issues of data dependency and high energy consumption associated with DNNS 186."}, {"title": "6. Integrating neural diversity and neuromodulatory signals into artificial neural networks", "content": "The field of ANNs is constantly evolving, witnessing emerging learning rules, architectural designs, and morphological features inspired by biological systems to improve continual learning, adaptability, robustness and resource efficiency in ANNs 5\u20137. To further address these challenges, we propose a dual-framework approach that combines biologically-informed dendritic models and task-driven SNNs of point neurons to facilitate improved performance and efficiency in ANNs (Figure 4). Our approach balances biological fidelity and computational efficiency by the simulation of neuronal activity using the IZ 101,104 and GLIF 87,109 models and imposing constraints to the synaptic weight to define excitatory and inhibitory populations. This allows to account for the spiking heterogeneity that characterizes neural systems 43,187,188 and brings the opportunity to account neuromodulatory cell-specific effects to the network 11,189\u2013191 This approach has the potential to incorporate neuron specificity and cell-specific neuromodulatory signals, while maintaining the highest level of simplicity possible, making it reasonably cost-efficient even in large-scale SNNs."}, {"title": "6.1. Implications of neuron heterogeneity in continual learning.", "content": "The biological brain is characterized by its cell type diversity, featuring a wide variety of neurons with different morphologies and spiking behaviors 19,43,76,187,188, which influence how they process temporal information. In contrast, most ANNs use uniform sets of neurons to process information, restricting their learning to plasticity dynamics. Despite being traditionally overlooked 19, recent computational studies suggest that the incorporation of neural heterogeneity contributes to LL by (i) improving task performance 13, (ii) promoting stable and robust learning 13\u201315, (iii) facilitating multi-timescale learning 16,17 and (iv) efficiently adapting computations in the SNNs 18.\nPractically, in SNNs, neural heterogeneity can be mainly introduced either morphologically, by defining distinct dendritic compartments for different neuron types, or functionally, by simulating different spiking behaviors. Morphological heterogeneity has been explored through dendritic architectures by defining cell-types, such as pyramidal neurons, interneurons or basket cells, with different dendritic compartments 16,60,66. Particularly, such efforts have"}, {"title": "6.2. Implications of neuromodulators in continual learning.", "content": "Neuromodulatory systems, in essence, provide a multi-layered contextual-guided control over cognition and behavior in nervous systems. They operate on distinct temporal scales and influence both (i) spiking behavior at the neuronal level and (ii) global network plasticity properties at the circuitry level, thereby reconfiguring network dynamics at a systems level 11,12,196. Particularly, spiking control systems have leveraged neuromodulatory influences at"}, {"title": "6.3. Applications and limitations", "content": "The integration of learning at different spatio-temporal scales aims to be a versatile approach, applicable to a wide range of tasks, from behavioral studies to Al applications. Particularly, reward-based tasks can take advantage of neural heterogeneity by allowing population-level learning 70. Therefore, reinforcement learning scenarios of motor control and spatial navigation tasks are well-suited paradigms in which incorporate this framework, where contextual signals can guide behavior 10,35,71,152,197.\nFurthermore, the generalizability of this framework supports Al supervised learning tasks like image classification and object and speech recognition 13,34,92,120,121, aiming for few-shot and multi-task learning paradigms. In this context, a study mitigated catastrophic forgetting in a class-incremental scenario through population threshold modulation of an SNN 62. Here, instead of introducing an artificial gating mechanism as with regularized gradient-based algorithms 132, they utilized the inherent gating of SNNs and used neuromodulatory signals to modulate this threshold.\nOverall, this framework aims to surpass the performance of current SNN models and provide new approaches for efficient and robust continual learning, as already demonstrated by recent studies 13,18,62. Nevertheless, despite the successful interpretation of neuromodulatory signals and spiking patterns within this framework, these models are computationally more demanding than perceptron-like neurons (see Figure 1), posing challenges for implementation in large- scale Deep Learning architectures. However, this SNN-based framework can be effectively utilized in neuromorphic hardware, where its low energy consumption and efficiency can be fully exploited, leveraging these devices for the next generation of ANNs 8,9,192. Furthermore, another significant challenge this framework faces is defining the exact neuronal populations. However, this technical difficulty can be addressed by either taking bio-inspiration from the biological proportions in the brain or implementing an evolutionary algorithm that learns the populations in an outer learning loop."}]}