{"title": "Task-Specific Preconditioner for Cross-Domain Few-Shot Learning", "authors": ["Suhyun Kang", "Jungwon Park", "Wonseok Lee", "Wonjong Rhee"], "abstract": "Cross-Domain Few-Shot Learning (CDFSL) methods typically parameterize models with task-agnostic and task-specific parameters. To adapt task-specific parameters, recent approaches have utilized fixed optimization strategies, despite their potential sub-optimality across varying domains or target tasks. To address this issue, we propose a novel adaptation mechanism called Task-Specific Preconditioned gradient descent (TSP). Our method first meta-learns Domain-Specific Preconditioners (DSPs) that capture the characteristics of each meta-training domain, which are then linearly combined using task-coefficients to form the Task-Specific Preconditioner. The preconditioner is applied to gradient descent, making the optimization adaptive to the target task. We constrain our preconditioners to be positive definite, guiding the preconditioned gradient toward the direction of steepest descent. Empirical evaluations on the Meta-Dataset show that TSP achieves state-of-the-art performance across diverse experimental scenarios.", "sections": [{"title": "1 Introduction", "content": "Few-Shot Learning (FSL) aims to learn a model that can generalize to novel classes using a few labeled examples. Recent advancements in FSL have been significantly propelled by meta-learning methods (Snell, Swersky, and Zemel 2017; Finn, Abbeel, and Levine 2017; Sung et al. 2018; Oreshkin, Rodr\u00edguez L\u00f3pez, and Lacoste 2018; Garnelo et al. 2018; Rajeswaran et al. 2019). These approaches have achieved outstanding results in single domain FSL benchmarks such as Omniglot (Lake et al. 2011) and miniImagenet (Ravi and Larochelle 2016). However, recent studies (Chen et al. 2019; Tian et al. 2020) have revealed that many existing FSL methods struggle to generalize in cross-domain setting, where the test data originates from domains that are either unknown or previously unseen. To study the challenge of generalization in cross-domain few-shot tasks, Triantafillou et al. (2019) introduced the Meta-Dataset, a more realistic, large-scale, and diverse benchmark. It includes multiple datasets from a variety of domains for both meta-training and meta-testing phases.\nLeveraging the Meta-Dataset, various Cross-Domain Few-Shot Learning (CDFSL) methods have been developed (Requeima et al. 2019; Bateni et al. 2020, 2022; Liu et al. 2021; Triantafillou et al. 2021; Li, Liu, and Bilen 2021, 2022; Dvornik, Schmid, and Mairal 2020; Liu et al. 2020; Guo et al. 2023; Tian et al. 2024), demonstrating significant advancements in this field. These approaches typically parameterize deep neural networks with a large set of task-agnostic parameters alongside a smaller set of task-specific parameters. Task-specific parameters are optimized to the target task through an adaptation mechanism, generally following one of two primary methodologies. The first approach utilizes an auxiliary network functioning as a parameter generator, which, upon receiving a few labeled examples from the target task, outputs optimized task-specific parameters (Requeima et al. 2019; Bateni et al. 2020, 2022; Liu et al. 2020, 2021). The second approach directly fine-tunes the task-specific parameters through gradient descent using a few labeled examples from the target task (Dvornik, Schmid, and Mairal 2020; Li, Liu, and Bilen 2021; Triantafillou et al. 2021; Li, Liu, and Bilen 2022; Tian et al. 2024).\nWhile both approaches have improved CDFSL performance through adaptation mechanism, a common limitation persists in the optimization strategies employed by these methods. Specifically, both approaches employ a fixed optimization strategy across different target tasks. However, Figure 1a shows that the optimal choice of optimizer may vary significantly depending on the given domain or target task. This implies that the performance can be significantly improved by adapting an optimization strategy to align well with the target domain and task. However, devising an effective and reliable scheme for its implementation has been challenging.\nOne promising approach for establishing a robust adaptive optimization scheme is to leverage Preconditioned Gradient Descent (PGD) (Himmelblau et al. 2018). PGD operates by specifying a preconditioning matrix, often referred to as a preconditioner, which re-scales the geometry of the parameter space. In the field of machine learning, previous research has shown that if the preconditioner is positive definite (PD), it establishes a valid Riemannian metric, which represents the geometric characteristics (e.g., curvature) of the parameter space and steers preconditioned gradients in"}, {"title": "2 Related Works", "content": "Meta-Learning for Few-Shot Learning Until recently, numerous approaches in the field of few-shot learning have adopted the meta-learning framework. These approaches can be mainly divided into three types: metric-based, model-based, and optimization-based methods. Metric-based methods (Garcia and Bruna 2017; Sung et al. 2018; Snell, Swersky, and Zemel 2017; Oreshkin, Rodr\u00edguez L\u00f3pez, and Lacoste 2018) train a feature encoder to extract features from support and query samples. They employ a nearest neighbor classifier with various distance functions to calculate similarity scores for predicting the labels of query samples. Model-based methods (Santoro et al. 2016; Munkhdalai and Yu 2017; Mishra et al. 2017; Garnelo et al. 2018) train an encoder to generate task-specific models from a few support samples. Optimization-based methods (Ravi and Larochelle 2016; Finn, Abbeel, and Levine 2017; Yoon et al. 2018; Rajeswaran et al. 2019) train a model that can quickly adapt to new tasks with a few support samples, employing a bi-level optimization. In our method, we employ the bi-level optimization used in the optimization-based methods.\nCross-Domain Few-Shot Learning (CDFSL) Recent CDFSL methods define the universal model as a deep neural network and partition it into task-agnostic and task-specific parameters. The task-agnostic parameters represent generic characteristics that are valid for a range of tasks from various domains. On the other hand, the task-specific parameters represent adaptable attributes that are optimized to the target tasks through an adaptation mechanism. Task-agnostic parameters can be designed as a single network or multiple networks. The single network is trained on a large dataset from single domain (Requeima et al. 2019; Bateni et al."}, {"title": "3 Backgrounds", "content": "Task Formulation for Meta-Learning in CDFSL In CDFSL, task T is formulated differently compared to traditional few-shot learning. In traditional few-shot learning, tasks are sampled from a single domain, resulting in the same form in both meta-training and meta-testing:\nmeta-training and meta-testing: $T = \\{S_T, Q_T\\}$ \nwhere $S_T$ is a support set and $Q_T$ is a query set. On the other hand, in CDFSL, tasks are sampled from multiple domains, leading to different forms in meta-training and meta-testing:\nmeta-training: $T = \\{S_T, Q_T, d_T\\}$,\nmeta-testing: $T = \\{S_T, Q_T\\}$,\nwhere $d_T$ is a domain label indicating the domain from which the task was sampled. For instance, the domain label is an integer between 1 and K for K domains (i.e., $1 \\le d \\le K$).\nBi-level Optimization in Meta-Learning Bi-level optimization (Rajeswaran et al. 2019) consists of two levels of main optimization processes: inner-level and outer-level optimizations. Let $f_\\theta(\\cdot)$ be a model, where the parameter $\\theta(\\cdot)$ is parameterized by the meta-parameter $\\phi$. For a task $T = \\{S_T, Q_T\\}$, the inner-level optimization is defined as:\n$\\theta_{T,\\tau}(\\phi) = \\theta_{T,0}(\\phi) - \\alpha_{in} \\cdot \\sum_{t=0}^{\\tau-1} \\nabla_\\theta L_{in}(\\theta_{T,t}(\\phi); S_T)$ \nwhere $\\theta_{T,0}(\\phi) = \\theta(\\phi)$, $\\alpha_{in}$ is the learning rate for the inner-level optimization, $L_{in}$ is the inner-level\u2019s loss function, and $\\tau$ is the total number of gradient descent steps. With $Q_T$ in each task, we can define outer-level optimization as:\n$\\phi \\leftarrow \\phi - \\alpha_{out} \\cdot \\nabla_\\phi L_{out}(\\theta_{T,\\tau}(\\phi); Q_T)$\nwhere $\\alpha_{out}$ is the learning rate for the outer-level optimization, and $L_{out}$ is the outer-level\u2019s loss function.\nPreconditioned Gradient Descent (PGD) PGD is a technique that minimizes empirical risk by using a gradient update with a preconditioner that re-scales the geometry of the parameter space. Given model parameters $\\theta$ and task $T = \\{S_T, Q_T\\}$, we can formally define the preconditioned gradient descent with a preconditioner $P$ as follows:\n$\\theta_{T,t} = \\theta_{T,t-1} - \\alpha \\cdot P \\nabla_\\theta L(\\theta_{T,t-1}; S_T), t = 1, \\dots$ \nwhere $\\theta_{T,0} = \\theta$, $L(\\theta_{T,t}; S_T)$ is the empirical loss associated with the task T, and $\\theta_{T,t}$ is the parameters. When the preconditioner P is chosen to be the identity matrix I, Eq. (5) becomes the standard Gradient Descent (GD). The choice of P to leverage second-order information offers several options, including the inverse Fisher information matrix $F^{-1}$, leading to the Natural Gradient Descent (NGD) (Amari 1998), the inverse Hessian matrix $H^{-1}$, corresponding to Newton\u2019s method (LeCun et al. 2002), and the diagonal matrix estimation with the past gradients, which results in adaptive gradient methods (Duchi, Hazan, and Singer 2011; Kingma and Ba 2014). They often reduce the effect of pathological curvature and speed up the optimization (Amari et al. 2020).\nDataset Classifier In CDFSL, Dataset Classifier (Triantafillou et al. 2021) reads a support set in a few-shot task and predicts from which of the training datasets it was sampled. Formally, let $T = \\{S_T, Q_T, d_T\\}$ be a train task sampled from K domains. Let g be a dataset classifier that takes the support set $S_T$ as input and generates logits as follows:\n$g(S_T) = z_T = (z_{T,1}, \\dots, z_{T,K}) \\in \\mathbb{R}^{K}$ \nIn (Triantafillou et al. 2021), the dataset classifier g is trained to minimize the cross-entropy loss for the dataset classification problem (i.e., classification problem with K classes)."}, {"title": "4 Method", "content": "In this section, we propose a novel adaptation mechanism named Task-Specific Preconditioned gradient descent (TSP). We first introduce Domain-Specific Preconditioner (DSP) and task-coefficients. Then, we describe the construction of Task-Specific Preconditioner using DSP and task-coefficients. Lastly, we show the positive definiteness of Task-Specific Preconditioner, which establishes it as a valid Riemannian metric. The algorithm for the training and testing procedures is provided in Appendix B.\n4.1 Domain-Specific Preconditioner (DSP)\nConsider L task-specific parameters $\\theta = \\{\\theta^{l} \\in \\mathbb{R}^{m_l \\times m_l}\\}_{l=1}^{L}$. For K domains, we first define meta-parameters $M_1, \\dots, M_K$ as follows:\n$M_k = \\{M_k^l\\} \\in \\mathbb{R}^{m_l \\times m_l}\\}_{l=1}, k = 1, \\dots, K$. \nThen, for all l, we define Domain-Specific Preconditioners (DSPs) $P_k^l$ using the meta-parameters as follows:\n$P_k^l = M_k^{lT} M_k^l + I, k = 1, \\dots, K$\nWe compare various DSP designs (See Table 3) in Section 5.3 and choose the form of Eq. (8). Through bi-level optimization, DSPs can be meta-learned as follows.\nInner-level Optimization For each train task $T = \\{S_T, Q_T, d_T\\}$, in the inner-level optimization, we optimize the task-specific parameters $\\theta$ through preconditioned gradient descent using $P_{d_T}^l$, updating $\\theta$ as follows:\n$\\theta_{T,\\tau}^l = \\theta_{T,0}^l - \\alpha_{in} \\cdot \\sum_{t=0}^{\\tau-1} P_{d_T}^l \\nabla_\\theta L_{in}(\\theta_{T,t}; S_T)$\nwhere $\\theta_{T,0}^l = \\theta^l$, $\\alpha_{in}$ is the learning rate for the inner-level optimization, $\\tau$ is the total number of gradient descent steps, and $L_{in}$ is the inner-level\u2019s loss function.\nOuter-level Optimization In the outer-level optimization, we meta-learn meta-parameters $M_1, \\dots, M_K$ as follows:\n$M_k \\leftarrow M_k - \\alpha_{out} \\nabla_{M_k} L_{out}(\\theta_{T,\\tau}; Q_T), k = 1, \\dots, K$\nwhere $\\alpha_{out}$ is the learning rate for outer-level optimization and $L_{out}$ is the outer-level\u2019s loss function.\n4.2 Task-coefficients\nConsider the dataset classifier g. Given a train task $T = \\{S_T, Q_T, d_T\\}$, we define task-coefficients $p_{T,1}, \\dots, p_{T,K}$ as follows:\n$(p_{T,1}, \\dots, p_{T,K}) = Softmax(z_{T,1}, \\dots, z_{T,K})$\nwhere $g(S_T) = (z_{T,1}, \\dots, z_{T,K})$. Note that we use the sigmoid function instead of softmax in the single-domain setting because the output dimension of the dataset classifier is one. While Triantafillou et al. (2021) updates the parameters of g to minimize only the cross-entropy loss $L_{CE}$ with respect to the dataset label $d_T$, we train the dataset classifier g to minimize the following augmented loss:\n$L = L_{CE} + \\lambda \\cdot L_{Aux}$\nwhere $\\lambda$ is a regularization parameter and $L_{Aux}$ is the auxiliary loss, defined as follows:\n$L_{Aux} = E_T [L_{out}(\\theta_{T,\\tau}; Q_T)]$\nHere, task-specific parameters $\\theta_{T,\\tau}^{l}$ can be obtained as follows:\n$\\theta_{T,\\tau}^l = \\theta_{T,0}^l - \\alpha_{in} \\sum_{t=0}^{\\tau-1} \\sum_{k=1}^K p_{T,k} P_k^l \\nabla_\\theta L_{in}(\\theta_{T,t}; S_T)$\nwhere $P_k^l$ is the l-th DSP of domain k. In Eq. (12), the cross-entropy loss guides the dataset classifier to prioritize the ground-truth domain of the support set. Concurrently, the auxiliary loss guides toward DSPs that minimize any adverse effects on the performance of the query set during the inner-level optimization.\n4.3 Task-Specific Preconditioner\nGiven a test task $T = \\{S_T, Q_T\\}$, we define Task-Specific Preconditioner $P_T^l$ as follows:\n$P_T^l = \\sum_{k=1}^K p_{T,k} P_k^l, l = 1, \\dots, L$"}, {"title": "4.4 Positive Definiteness of TSP's Preconditioner", "content": "A preconditioner satisfying positive definiteness ensures a valid Riemannian metric, which represents the geometric characteristics of the parameter space (Amari 1967, 1996, 1998; Kakade 2001; Amari and Douglas 1998). Task-Specific Preconditioner $P_T^l$ is designed to be a positive definite matrix, which is verified in Theorem 1.\nTheorem 1. Let $p_k \\in [0,1], k = 1, \\dots, K$, be the task-coefficients satisfying $\\sum_{k=1}^K p_k = 1$. For the Domain-Specific Preconditioners $P_k \\in \\mathbb{R}^{m \\times m}, k = 1, \\dots, K$, Task-Specific Preconditioner $P$ defined as $P = \\sum_{k=1}^K p_k \\cdot P_k$ is positive definite."}, {"title": "5 Experiments", "content": "5.1 Experimental Setup\nImplementation Details In the experiments, we use Meta-Dataset (Triantafillou et al. 2019) that is the standard benchmark for evaluating the performance of CDFSL. To demonstrate the effectiveness of TSP as an adaptation mechanism, we apply it to the state-of-the-art CDFSL methods, TSA (Li, Liu, and Bilen 2022) and TA2-Net (Guo et al. 2023), which are publicly available as open-source. Following previous studies (Bateni et al. 2022; Triantafillou et al. 2021; Li, Liu, and Bilen 2021, 2022; Guo et al. 2023), we adopted ResNet-18 as the backbone for the feature extractor. In all experiments, we follow the standard protocol described in (Triantafillou et al. 2019). For the Dataset Classifier Loss, weighting factor $\\lambda$ is set to 0.1, as it performs best compared to other values, as shown in Appendix D.1. Details of the Meta-Dataset, hyper-parameters, and additional implementation are available in Appendix E.\nBaselines For the baselines, we compare our methods to the state-of-the-art CDFSL methods, including BOHB (Saikia, Brox, and Schmid 2020), SUR (Dvornik, Schmid, and Mairal 2020), URT (Liu et al. 2020), Simple-CNAPS (Bateni et al. 2020), FLUTE (Triantafillou et al. 2021), tri-M (Liu et al. 2021), URL (Li, Liu, and Bilen 2021), TSA (Li, Liu, and Bilen 2022), TA2-Net (Guo et al. 2023), ALFA (Baik et al. 2023)+Proto-MAML, GAP+Proto-MAML (Kang et al. 2023), and MOKD (Tian et al. 2024)."}, {"title": "5.2 Performance Comparison to State-of-The-Art Methods", "content": "Following the experimental setup in (Li, Liu, and Bilen 2022), we first evaluate our method using multi-domain and single-domain feature extractors in Varying-Way Varying-Shot setting (i.e., Multi-domain and Single-domain setting). Then, we assess our approach with the multi-domain feature extractor in more challenging Varying-Way Five-Shot and Five-Way One-Shot settings. We provide the performance comparison results for Varying-Way Five-Shot and Five-Way One-Shot settings in the Appendix F."}, {"title": "5.3 Ablation Studies", "content": "In this section, all ablation studies are performed using TSP\u2020 in the multi-domain setting to isolate the effects originating"}, {"title": "6 Discussion", "content": "In this section, all experiments are conducted using TSP\u2020.\nThe Necessity of Positive Definite Constraint Even without a specific constraint of PD, one might assume that initializing the preconditioner as positive definite, such as $\\alpha I$, would maintain its positive definiteness throughout meta-training due to its significant role. However, as illustrated in Table 4 and Table 5, this assumption does not hold. In Table 4, we compare preconditioners with and without a PD constraint, both initialized as positive definite. Specifically, the former adopts Task-Specific Preconditioner (See Eq. (15)), while the latter employs Task-Specific Preconditioner with DSP designed as $P_k^l = M$ and initialized as $M = 0.1 \\cdot I$. Evaluations are conducted using the multi-domain feature extractor (URL) in the multi-domain setting. After meta-training, DSPs without a PD constraint tend to lose positive definiteness as shown in Table 5, leading to poor performance as shown in Table 4. These findings underscore the necessity of explicitly constraining the preconditioner to maintain positive definiteness, as relying solely on optimization fails to preserve this crucial property.\nPositive Definite DSP Designs with and without the Identity Matrix Apart from ensuring positive definiteness, a notable characteristic of our Gram matrix design $M^T M + I$ is its inclusion of the identity matrix. To explore the impact of this inclusion, we compare two positive definite DSP designs: $LL^T$ and $LL^T + I$. We focus on these two DSP designs because $M^T M$ does not guarantee positive definiteness. However, we also provide a comparison between $M^T M + I$ and $M^T M$ in Appendix G. The experiments are conducted using the multi-domain feature extractor (URL). In Table 6, we observe that the DSP design with the added identity matrix performs better in the Varying-Way Varying-Shot setting but worse in the Varying-Way Five-Shot setting. This outcome aligns with prior theoretical findings (Amari et al. 2020) indicating that PGD performs better than GD in noisy gradient conditions, while GD excels when gradients are accurate. With more shots, gradients tend to be more accurate due to increased data. In the Varying-Way Varying Shot setting, where tasks typically involve more than five shots, gradients are more accurate, making GD more beneficial compared to the other setting. Including the identity matrix can be viewed as a regularization of PGD towards GD. Consequently, $LL^T + I$ aligns closer to GD compared to $LL^T$, resulting in improved performance due to the abundance of shots in Varying-Way Varying-Shot setting. Conversely, in the Varying-Way Five-Shot setting, where tasks involve fewer shots, $LL^T$ exhibits superior performance to $LL^T + I$ due to the scarcity of shots.\nEffectiveness of Positive Definiteness in Cross-Domain Tasks A positive definite preconditioner is known to mitigate the negative effects of pathological loss curvature and accelerate optimization, thereby facilitating convergence (Nocedal and Wright 1999; Saad 2003; Li 2017). This leads to a consistent reduction in the objective function. However, without positive definiteness, this effect is not guaranteed and may result in failure to converge. In Figure 4, we compare the learning curves of PGD with and without a PD constraint across both seen and unseen domains. Without the PD constraint, PGD fails to converge in some of the seen domains and in all the unseen domains. With the PD constraint, PGD successfully converges in all the seen and unseen domains. These results suggest that, in cross-domain tasks, a PD constraint of a preconditioner is crucial for achieving convergence and is beneficial for improving performance, which is also related to Figure 1b."}, {"title": "TSP vs. Previous PGD Methods: Leveraging Multi-Domain Knowledge for Task-Specific Preconditioner", "content": "Compared to previous PGD methods like GAP (Kang et al. 2023), TSP is specifically designed for cross-domain few-shot learning (CDFSL), where unseen domains are not accessed during meta-training. The key challenge in CDFSL is to effectively leverage information from multiple seen domains to quickly adapt to each unseen domain. Previous PGD methods fall short in this regard because they rely on a single preconditioner, even when multiple seen domains are available. For example, GAP uses only one preconditioner to extract information from multiple seen domains, which limits its adaptability to unseen domains with distinct characteristics. In contrast, TSP meta-trains a distinct domain-specific preconditioner (DSP) for each seen domain and combines them to construct a Task-Specific Preconditioner that better suited to each unseen domain. TSP produces this Task-Specific Preconditioner effectively, as shown in Tables 1 and 2, and time-efficiently, as further detailed in Appendix H."}, {"title": "7 Conclusion", "content": "In this study, we have introduced a robust and effective adaptation mechanism called Task-Specific Preconditioned gradient descent (TSP) to enhance CDFSL performance. Thanks to the meta-trained Domain-Specific Preconditioners (DSPs) and Task-coefficients, TSP can flexibly adjust the optimization strategy according to the geometric characteristics of the parameter space for the target task. Owing to these components, the proposed TSP demonstrates notable performance improvements on Meta-Dataset across various settings."}, {"title": "8 Acknowledgements", "content": "This work was supported by a National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. NRF-2020R1A2C2007139) and in part by Institute of Information & communications Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) ([NO.RS-2021-II211343, Artificial Intelligence Graduate School Program (Seoul National University)], [No. RS-2023-00235293, Development of autonomous driving big data processing, management, search, and sharing interface technology to provide autonomous driving data according to the purpose of usage])."}, {"title": "Appendix for the paper \"Task-Specific Preconditioner for Cross-Domain Few-Shot Learning\"", "content": "A The three preconditioners used in Figure 1b and Figure 4\nTo establish the motivation for enforcing the positive definite constraint in CDFSL, we conduct a comparative analysis of three adaptation mechanisms\u2014PGD methods with varying preconditioners\u2014using Meta-Dataset. These mechanisms are applied on the state-of-the-art CDFSL method, TSA (Li, Liu, and Bilen 2022). In these comparisons, with task-specific parameters \u03b8 and a task $T = \\{S_T, Q_T\\}$, we update \u03b8 using PGD with a preconditioner P as follows:\n$\\theta_{T,t} = \\theta_{T,t-1} - \\alpha \\cdot P \\nabla_\\theta L(\\theta_{T,t-1}; S_T), t = 1, 2, ...$,\nwhere $\\theta_{T,0} = \\theta$ and $L(\\theta_{T,t}; S_T)$ is the empirical loss associated with T and $\\theta_{T,t}$. The first PGD method is identical to Gradient Descent (GD), which utilizes the fixed identity matrix I as P (i.e., the baseline for gradient descent). The second method is Task-Specific Preconditioned Gradient Descent (TSP), which utilizes a Task-Specific Preconditioner designed as $P = M$ and initialized as (\u22121) \u00b7 I (i.e., PGD without a positive definite constraint). The final method is Task-Specific Preconditioned gradient descent (TSP), which utilizes Task-Specific Preconditioner defined in Section 4.3 (i.e., PGD with a positive definite).\nB Meta-Training and Meta-Testing Algorithms"}, {"title": "Algorithm 1: Meta-Training for Domain-Specific Preconditioner (DSP)", "content": "Require: p(T): Task distribution across K train domains\nRequire: $\\alpha_{in}$, $\\alpha_{out}$: The learning rates\nRequire: $L_{in}$, $L_{out}$: The inner and outer-level loss functions\n1: Initialize task-specific parameters\n$\\theta = \\{\\theta^{l} \\in \\mathbb{R}^{m_l \\times m_l}\\}_{l=1}^{L}$\n2: Initialize meta-parameters\n$M_1, \\dots, M_K$ where $M_k = \\{M_k^l\\} \\in \\mathbb{R}^{m_l \\times m_l}\\}_{l=1}$\n3: while not converged do\n4:  Sample a batch of train tasks $T_B \\sim p(T)$\n5:  for all $T = \\{S_T, Q_T, d_T\\} \\in T_B$ do\n6:   for l = 1 to L do\n7:    Compute DSP $P_{d_T}^l = M_{d_T}^{lT} M_{d_T}^l + I$\n8:    Compute updated task-specific parameters via Eq. (3)\n9:   end for\n10:   Compute outer-level loss $L_{out}(\\theta_{T,\\tau}; Q_T)$\n11:  end for\n12:  Update the meta-parameters via Eq. (10)\n13: end while"}, {"title": "Algorithm 2: Meta-Training the dataset classifier for Task-coefficients", "content": "Require: p(T): Task distribution across K train domains\nRequire: $g_{\\phi}(\\cdot)$: The dataset classifier\nRequire: $L_{in}$, $L_{out}$: The inner and outer-level loss functions\nRequire: $\\lambda$: The regularization parameter\nRequire: $\\alpha$: The learning rate\n1: Initialize task-specific parameters\n$\\theta = \\{\\theta^l \\in \\mathbb{R}^{m_l \\times m_l}\\}_{l=1}^{L}$\n2: Initialize the parameters $\\phi$ of $g_{\\phi}(\\cdot)$\n3: while not converged do\n4:  Sample a batch of train tasks $T_B \\sim p(T)$\n5:  for all $T = \\{S_T, Q_T, d_T\\} \\in T_B$ do\n6:   Compute logits $(z_{T,1}, \\dots, z_{T,K}) = g_{\\phi}(S_T)$\n7:   Compute task-coefficients via Eq. (11)\n8:   Compute $L_{CE} = - \\sum_{k=1}^{K} d_{T,k} \\cdot log(p_{T,k})$\n9:   With $\\theta_{T,\\tau} = \\{\\theta_{T,\\tau}^l\\}_{l=1}^{L}$ via Eq. (14), compute\n$L_{Aux} = L_{out}(\\theta_{T,\\tau}; Q_T)$\n10:   Compute $L_T = L_{CE} + \\lambda \\cdot L_{Aux}$\n11:  end for\n12:  Compute $L = \\sum_{T \\in T_B} L_T$\n13:  Update the parameters $\\phi$\n14: end while"}, {"title": "Algorithm 3: Meta-Testing through Task-Specific Preconditioned gradient descent (TSP)", "content": "Require: p(T): Task distribution across all domains\nRequire: $M_1, \\dots, M_K$: Meta-trained meta-parameters\nRequire: $g_{\\phi}(\\cdot)$: Meta-trained dataset classifier\nRequire: $L_{in}$: The inner-level loss function\nRequire: $\\beta$: The learning rate\n1: Initialize task-specific parameters\n$\\theta = \\{\\theta^l \\in \\mathbb{R}^{m_l \\times m_l}\\}_{l=1}^{L}$\n2: Sample a test task $T = \\{S_T, Q_T\\}$\n3: for l = 1 to L do\n4:  For all k, compute DSP $P_k^l = M_k^{lT} M_k^l + I$\n5:  Compute Task-Specific Preconditioner via Eq. (15)\n6:  Update the task-specific parameters via Eq. (16)\n7: end for"}, {"title": "C Proofs of Theorems", "content": "Lemma 1. For the meta parameter $M \\in \\mathbb{R"}, {"below": "n$P^T = (M^T M + I)^T = (M^T M)^T + I^T = M^T M + I = P$.\nFor $\\forall x \\in \\mathbb{R"}, "m \\backslash \\{0\\}$,\n$x^T Px = x^T (M^T M + I) x$\n$= x^T M^T M x + x^T I x$\n$= (Mx)^T (Mx) + x^T x$\n$= ||Mx||^2 + ||x||^2$.\nThe first term on the right-hand side is non-negative, while the second term is positive:\n$||Mx||^2 \\ge 0$,\n$||x||^2 > 0$\nsince $x \\neq 0$. Thus, we conclude:\n$x^T Px > 0$,\nwhich confirms the positive-definiteness of the Domain-Specific Preconditioner P.\nTheorem 1. Let $p_k \\in [0,1"], "below": "n$P^T = (\\sum_{k=1}^K p_k \\cdot P_k)^T = \\sum_{"}