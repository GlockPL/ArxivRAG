{"title": "MINESTUDIO: A Streamlined Package for Minecraft AI Agent Development", "authors": ["Shaofei Cai", "Zhancun Mu", "Kaichen He", "Bowei Zhang", "Xinyue Zheng", "Anji Liu", "Yitao Liang"], "abstract": "Minecraft has emerged as a valuable testbed for embodied intelligence and sequential decision-making research, yet the development and validation of novel agents remains hindered by significant engineering challenges. This paper presents MINESTUDIO, an open-source software package designed to streamline embodied policy development in Minecraft. MINESTUDIO represents the first comprehensive integration of seven critical engineering components: simulator, data, model, offline pretraining, online finetuning, inference, and benchmark, thereby allowing users to concentrate their efforts on the algorithm innovation. We provide a user-friendly API design accompanied by comprehensive documentation and tutorials. The complete codebase is publicly available at https://github.com/CraftJarvis/MineStudio.", "sections": [{"title": "1. Introduction", "content": "As an open-world 3D sandbox game, Minecraft has garnered widespread acclaim for its high degree of freedom and rich playability. In recent years, with the rapid advancement of general-purpose artificial intelligence, Minecraft has gradually emerged as a key testbed for research on embodied intelligence and decision-making control (Baker et al., 2022; Fan et al., 2022; Guss et al., 2019; Lifshitz et al., 2023). Although the community has introduced a variety of environments (Fan et al., 2022; Guss et al., 2019; Johnson et al., 2016), datasets (Baker et al., 2022; Fan et al., 2022; Guss et al., 2019), training algorithms and policy models (Baker et al., 2022; Cai et al., 2023, 2024; Lifshitz et al., 2023), and benchmarking methods (Fan et al., 2022; Lin et al., 2023) for this platform, a substantial engineering gap remains in the development and validation of novel agents.\nMinecraft's complexity has led to varied task customizations, hindering progress tracking across the community. For example, Dreamer V3 (Hafner et al., 2023) simplified the environment to destroy blocks with a single attack, while Voyager (Wang et al., 2023) relied on the rule-based Mineflayer controller (PrismarineJS, 2013) to interact with the environment. Moreover, experimenting in Minecraft is harder than in other Al domains. For example, despite OpenAI's 160-million-frame dataset, the lack of flexible data structures hampers efficient storage and retrieval. Reinforcement learning shows promise in tackling complex tasks (Baker et al., 2022), but mainstream frameworks often lack memory-policy support (Liang et al., 2018; Raffin et al., 2021) and crash safeguards (Raffin et al., 2021). These require researchers to make great engineering efforts before validating an idea.\nTo address these challenges, we present MINESTUDIO, an open-source software package for efficiently developing embodied agents in Minecraft. We also integrate many existing efforts, including data (Baker et al., 2022), environment (Guss et al., 2019; Johnson et al., 2016), and model (Baker et al., 2022; Cai et al., 2023, 2024; Lifshitz et al., 2023), into a unified framework and present them to users in a concise manner. To minimize redundant engineering work, we have introduced several key improvements and optimizations: (1) support flexible custom environment configurations; (2) a flexible and training-efficient trajectory data structure; (3) a unified policy model template with multiple built-in Minecraft agent algorithms; (4) a simplified offline pre-training process; (5) a high-performance distributed online fine-tuning pipeline tailored to the Minecraft platform; (6) a parallel inference pipeline; and (7) the integration of an MCU (Lin et al., 2023) benchmark to enable fair comparisons. With MINESTUDIO, users can not only conduct interactive evaluations of existing mainstream Minecraft agents but also quickly implement a model file using just a few lines of PyTorch (Paszke et al., 2019) code, enjoying a fully integrated workflow from pre-training through finetuning to evaluation. The source code is publicly available at GitHub, accompanied by comprehensive documentation and extensive tutorials to facilitate rapid onboarding."}, {"title": "2. MINESTUDIO", "content": "The MINESTUDIO is an efficient toolkit for developing Minecraft AI agents, encompassing the full workflow from data preparation and training to evaluation. It offers a flexible interface design that not only includes various out-of-the-box features but also allows users to tailor the toolkit to their specific requirements. In doing so, it maximizes flexibility while minimizing engineering overhead.\nSimulator. This component implements a hook-based Minecraft wrapper that offers a high degree of customization. By inheriting from the MinecraftCallback class, users can tailor the environment in various ways, including (but not limited to) monitoring rendering framerate, issuing cheat commands, simulating rapid resets, logging episodes, generating reward functions, and overriding observations. To further reduce user workload, we provide a set of commonly used callbacks out of the box. In particular, PlayCallback loads a graphical user interface and enables switching between manual and agent-controlled modes, allowing users to interactively inspect model performance. In addition, we have integrated a bunch of tricks to improve rendering speed, thereby increasing the efficiency of model evaluation, data collection, and reinforcement learning.\nData. This component introduces a flexible and efficient data structure for handling offline trajectory data. Different modalities within the trajectory are segmented into clips and stored independently in LMDB files while preserving their temporal relationships. This design seeks to balance storage size and video decoding efficiency, enabling users to retrieve trajectory segments based on semantic labels rapidly. To facilitate the training of models requiring long-term memory, we have implemented a distributed batch sampler that supports continuous reading of lengthy trajectory sequences. Additionally, we provide data format conversion scripts, making it convenient for users to incorporate their own collected trajectory data, as well as a suite of visualization tools to assist with troubleshooting. Our framework comes with the largest Contractor Dataset (Baker et al., 2022) available in the Minecraft domain, complemented by our pre-processed frame-level semantic segmentation data.\nOffline Training. This component builds upon the PyTorch Lightning (Falcon and team, 2019) framework to deliver an enhanced Trainer module. It incorporates dedicated mechanisms for handling policy memory (e.g., TransformerXL (Dai et al., 2019)) and integrates seamlessly with the distributed batch sampler in the MINESTUDIO data module, thereby enabling training on ultra-long trajectories. In addition, we provide a proven set of hyperparameter configurations\u2014covering aspects such as warmup steps, optimizers, and learning rates\u2014while also allowing flexible customization through objective callbacks. This approach maximizes user flexibility while minimizing their overhead.\nOnline Training. This component implements the KL-constrained Proximal Policy Optimization algorithm introduced in Baker et al. (2022). The code is designed for integration with our model and simulator. It has been optimized to deal with long episodes and handle the instability of the Minecraft environment. Additionally, we provide a set of hyperparameters that have been tested to achieve high training efficiency and strong performance across various tasks. We hope this resource serves as an easy starting point and lowers the barriers to reinforcement learning research in Minecraft.\nInference. This component provides a Ray-based (Moritz et al., 2018) inference framework for MINESTUDIO, to support distributed inference. The framework is designed to consist of three parts: generator, filter and recorder, forming an asynchronous inference pipeline for easily evaluating the performance of different agents. The generator part, equipped with an agent creator and an environment creator, generates trajectories in batches. Each produced trajectory is immediately passed to a filter for post-processing and then summarized and stored by the recorder. By customizing the filter and recorder, users can effortlessly conduct comprehensive evaluations of policy checkpoints. Furthermore, this pipeline allows for efficient data synthesis, which, when combined with the data module's conversion scripts, enables a closed-loop data workflow.\nBenchmark. This component evaluates agent performance in MINESTUDIO environments. It supports a variety of tasks such as building, mining, and crafting, and offers both simple and challenging game modes to test agents under different levels of difficulty. The framework includes an automatic evaluation pipeline that leverages Vision-Language Models to analyze task videos, and provides batch task execution capabilities to run multiple tasks simultaneously and record completion videos. Additionally, it offers a quick benchmarking tool that simplifies the process of task execution and evaluation, enabling researchers to compare different agent models efficiently."}, {"title": "3. Comparison to Existing Interest of Minecraft", "content": "To highlight the contributions of MINESTUDIO, we compare its features with those of other prominent Minecraft development frameworks, such as MineRL (Guss et al., 2019), MineDojo (Fan et al., 2022), and Mineflayer (PrismarineJS, 2013). Although these frameworks offer valuable testbeds for Minecraft, they lack a seamless pipeline that integrates building, training, and evaluating agents, particularly when it comes to environment customization. While Baker et al. (2022) extends MineRL by offering data loading and training code, its dataloader is primarily designed for demonstration purposes and is inefficient, while the RL training process remains closed-source and difficult to replicate. Moreover, the relatively slow speed of the MineRL and MineDojo simulators hampers RL training, adding considerable engineering challenges to Minecraft development. LLM-based agents (Wang et al., 2023; Zhu et al., 2023) oversimplify the Minecraft problem by relying on Mineflayer APIs, whereas our goal is to build embodied agents that mirror the observation and control interface of human players. The motivation behind MINESTUDIO is to unify Minecraft agent development through an efficient and reliable training template. By integrating MCU (Lin et al., 2023), our distributed inference framework, and state-of-the-art (SOTA) baseline implementations, we provide a standardized evaluation paradigm for Minecraft agents."}, {"title": "4. Conclusions", "content": "In this work, we introduced MINESTUDIO, a comprehensive and streamlined framework designed to advance the development of AI agents in Minecraft. By addressing the significant engineering challenges inherent in creating embodied policies for open-world environments, MINEStudio bridges the gap between conceptual algorithmic innovations and practical implementation. Its modular design integrates crucial components, such as a flexible simulator wrapper, efficient data structures, pre-integrated models, and high-performance training pipelines, enabling researchers to focus on algorithmic advancements rather than engineering overhead."}]}