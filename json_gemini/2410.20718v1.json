{"title": "LECTURE II: COMMUNICATIVE JUSTICE AND THE DISTRIBUTION\nOF ATTENTION", "authors": ["Seth Lazar"], "abstract": "Algorithmic intermediaries govern the digital public sphere through their\narchitectures, amplification algorithms, and moderation practices. In doing so, they\nshape public communication and distribute attention in ways that were previously\ninfeasible with such subtlety, speed and scale. From misinformation and affective\npolarisation to hate speech and radicalisation, the many pathologies of the digital\npublic sphere attest that they could do so better. But what ideals should they aim\nat? Political philosophy should be able to help, but existing theories typically\nassume that a healthy public sphere will spontaneously emerge if only we get the\nboundaries of free expression right. They offer little guidance on how to\nintentionally constitute the digital public sphere. In addition to these theories\nfocused on expression, we need a further theory of communicative justice, targeted\nspecifically at the algorithmic intermediaries that shape communication and\ndistribute attention. This lecture argues that political philosophy urgently owes an\naccount of how to govern communication in the digital public sphere, and\nintroduces and defends a democratic egalitarian theory of communicative justice.", "sections": [{"title": "1. INTRODUCTION", "content": "In 'Governing the Algorithmic City', I introduced a general model of how\nalgorithmic intermediaries mediate our social relations, and in doing so enable and\nexercise governing power, which urgently demands justification or elimination. I\nthen showed how algorithmic governance poses pressing questions of political\nauthority, procedural legitimacy, and substantive justification, our theories of\nwhich have been developed for a quite different socio-political context, where\nextrinsic control of social relations by coercive laws was prevalent. In this Lecture,\nI apply this theoretical approach to one aspect of the Algorithmic City \u2013 the digital\npublic sphere-broaching an urgent philosophical question: how should liberal\negalitarian democracies shape public communication and distribute collective\nattention?\nConcern about the health of the digital public sphere can sometimes seem\nahistorical, forgetting how collective communication has always fallen short of our\nideals.2 And it can be overstated, ignoring important successes like how the\ninternet has enabled structurally disadvantaged communities to come together and\nforge a common identity.3 But however measured one's approach, the pathologies\nof online communication are hard to ignore.\nIn Lecture I, I argued that algorithmic power is presumptively morally suspect, but\ncan be justified when used for the right ends, in the right ways, by those with the\nproper authority to do so. Algorithmic governance of the digital public sphere falls\nshort on each count.4 What is power used for? Mostly the (sometimes forlorn)\npursuit of returns on investment to the private owners of these platforms. This\ntypically means maximising time on platform to support surveillance- and\nengagement-based advertising.5 Who exercises power? Sometimes conflicted and\ncapricious platform owners;6 or else harassed and precarious click-workers;7 or-at\nbest-advisory councils and oversight boards that lack any democratic authority.8\nHow is power exercised? Privately, with little to no community authorship, no\nexpectation of consistency in application, and little accountability for bad\njudgements. What is the net result? Our digital public sphere, which in principle\naffords an unprecedented opportunity to create Dewey's \u2018Great Community', is\ninstead host to numerous pathologies \u2013 from the pollution of our information\nenvironment, to individual and collective practices of silencing and abuse, to\ntargeted and stochastic manipulation. We could clearly be doing better.\nBut what would better look like? What should we aim for, beyond just trying to\nput out each spot fire as it flares up? Political philosophy could help us answer\nthese questions. But it has engaged too little with the fast-changing realities of the\ndigital public sphere.10 And its prevailing framework for evaluating public\ncommunication is maladapted to the task ahead. This Lecture tries to make\nprogress. I argue that the digital public sphere's shortcomings require us to rethink\nhow online platforms shape public communication and distribute attention. We need\nnormative principles to guide those tasks. Philosophers are likely to reach for the\ntoolkit of freedom of expression. Building on Dewey's argument for the crucial role\nof communication in creating a \u2018Great Community', I will argue that we instead\nmust craft a new account of communicative justice,11 which explicitly aims to guide\nthe intentional constitution of a healthy digital public sphere.12 I then show how\nthis ideal can offer guidance on substantive justification, proper authority, and\nprocedural legitimacy in the governance of the digital public sphere."}, {"title": "2. SHAPING COMMUNICATION, DISTRIBUTING ATTENTION", "content": "Let's start with some stipulative definitions. The public sphere is the environment\nfor public communication. Communication is the social practice whereby one party\nexpresses themselves, and another attends to that expression. Expression involves\nthe creation of meaningful content through words, images, or other artefacts.\nAttention involves orienting one's mind towards that content, and to a greater or\nlesser degree processing it. Attention can be fleeting or deeply engaged.\nCommunication is public, let's assume, when those communicating lack a\nreasonable expectation of privacy. Since our environment for public\ncommunication is now digital, the digital public sphere just is the public sphere.\nSome theorists reserve the idea of the public sphere for the domain of public\ncommunication that focuses on politics.13 I think this is conceptually and\nnormatively untenable-not only is everything political, but every medium for\npublic communication will eventually be used for political discussion (as\ntraditionally understood).14 Many of the challenges of public communication\nwould be easier to address if we had a public sphere that could easily be\npartitioned into different categories of communication.15 Unfortunately, the actual\npublic sphere is not like this.\nThe shortcomings of the digital public sphere mostly fall into one of three rough\ncategories: abuse; epistemic pollution; and manipulation. The first encompasses\ndirect and indirect abuse, harassment,16 and silencing.17 It involves using online\ncommunication to harm others directly (whether individually, or as one element in\na collective harm).18 The second gathers together communicative practices that\nmake it harder for us to form accurate beliefs. This includes the production and\ncirculation of misleading online content through conspiracy theories,\nmisinformation and disinformation, 19 coordinated inauthentic behaviour, 20\nobfuscation and 'flooding'.21 Manipulation can be variously defined. For my\npurposes, I'll use it to mean the practice of using communication to influence\nothers to make decisions in ways that compromise their autonomous agency.22\nThis includes both intentional 1:1 manipulation, for example, where one party tries\nto radicalise another,23 and perhaps-unintended manipulation of whole\npopulations, as when platforms contribute to affective polarisation,24 or to the rise\nof pathological body-image anxiety.25 These categories, of course, are not mutually\nexclusive (a single communicative act could instantiate all three).\nThe digital public sphere is largely constituted by algorithmic intermediaries \u2013\ncomputational systems that mediate social relations, in this case by enabling\nmediatees to communicate. In the near future, Language Model Agents acting as\nuniversal intermediaries might become central to the public sphere (I speculate\nabout one possibility in Section 5D below). For now, however, LLMs are just one\nelement in the algorithmic toolkit of the large platforms that have mediated\nbillions of people's online lives for the past decade and more. I am thinking in\nparticular of social media sites such as TikTok, Facebook, Instagram, Twitter,\nDiscord, Reddit, SnapChat, YouTube, Mastodon and others, as well as search sites\nsuch as Google, and I suppose one must now say Bing.26 My argument in this\nlecture rests on one or both of two conjectures about the relationship between\nthose platforms and the pathologies of online communication. First: the design of\nonline platforms is at least part cause of the shortcomings of the digital public\nsphere. Second: even if the first conjecture is in doubt, platform design is an\nimportant lever for building a healthier public sphere.\nTo motivate these two conjectures, we must start by identifying the specific\nfeatures of platform design that are likely to contribute to the shortcomings of the\ndigital public sphere, and that conversely might be (part of) its salvation. I think\nwe can roughly parse the design of online platforms into two broad functions:\nshaping communication and distributing attention.\nBy shaping communication, I mean dictating the conditions under which people can\ncommunicate online.27 This starts with Identity Management, determining whether\nand how a user's identity is verified to the platform and to other users.28 Does the\nplatform require real names or permit anonymity? Are identities verified or not?\nWhat options for account management and presentation are enabled? Next it\nconcerns Content Creation and Sharing, which dictates the formats in which users\nmay communicate with one another-for example short or long-form text, image,\naudio and video; as well as whether users can edit or co-author posts, and whether\nposts are temporary or permanent.29 It concerns too the control users have over\ntheir audience\u2014the degree to which they can restrict the distribution of their posts.\nInteraction and Feedback then covers how others can respond to that\ncommunication \u2013 what non-linguistic (e.g. likes, downvotes, upvotes) and\nlinguistic options do they have to engage? Are quote-posts enabled, or threaded\nconversations? Are private messages enabled and if so are they encrypted or not?\nLet's call the foregoing elements of platform design the platform's architecture.\nPlatform architecture dictates your options for communication in the digital public\nsphere. But 'pre-emptive governance' alone is insufficient to prevent undesirable\ncommunication online: platforms also need Safety and Moderation practices to police\nharmful or otherwise undesirable behaviour. 30 Can users report other users for\nharmful communication? What happens if they do? What are the limits of\npermissible communication on the platform, and what are the consequences when\nthose limits are ignored? For years, platforms desperate to preserve a veneer of\nneutrality (and perhaps an early ethos of pro-social community) sought either to\navoid moderation, or to conceal its practice.31 This veil has long-since dropped, and\na full range of moderation practices are being pursued, from automated tools\nrelying on Large Language Models, to vast armies of exploited click-workers, to\nambitious attempts to invent quasi-judicial advisory councils.32\nPlatforms dictate how we may communicate online. Importantly, this involves not\nonly the disciplinary power of post facto enforcement, but also the productive\npower of pre-emptive governance, determining the formats, registers, and\naudiences with which we can communicate.33 But they do more than this. Through\ntheir Discovery and Curation practices, platforms also substantially shape the\ndistribution of attention online. Attention is the process of cognitive engagement that\nenables a hearer to receive a message expressed by a speaker. As has long been\nremarked, when expression is so cheap as to be almost costless, attention becomes\nthe scarce resource.34 Platforms therefore devote extraordinary efforts to discovery\nand curation practices that efficiently allocate attention.35 While attention is\nfundamentally a process in the mind of an individual (the one who attends), we\ncan also speak of collective attention being distributed by platforms, as they direct\nmany individuals to attend to the same thing, and then facilitate the shared\nexperience of that common attention through enabling interaction, commentary,\nand other forms of participatory engagement.36\nThe process of allocating (individual and collective) attention is often called\n'algorithmic amplification'.37 This evocative phrase can be misleading in two\ndistinct ways. First, it risks reifying 'the algorithm'. Amplification algorithms \u2013\nrecommender systems - are always part of broader sociotechnical systems. They\nrely on signals from the platform architecture (for example, tracking a user's\nprevious engagements to predict future ones).38 Platforms also enable non-\nalgorithmic amplification through their design and user-controlled discovery and\ncuration-for example, when they rely on individuals subscribing to or following\nother accounts.39 Adopting the \u2018network' model, whereby users can find content\nand other users based on their own network, also contributes to amplifying some\nvoices above others; so does enabling muting and blocking. It is also debatable\nwhether a CEO instructing his engineers to boost the voice of some specific users\nreally counts as algorithmic amplification.\nIn addition, second, the very concept of amplification is hard to pin down, because\nit presupposes a baseline against which it can be measured.40 What would that\nbaseline be? If a platform serves any function at all, then aren't all posts on that\nplatform being amplified, relative to their distribution if hosted on a private\nserver? Or is a post amplified just in case platform choices lead to it being viewed\nmore than the average post? More than it would have been viewed in the absence\nof those choices? Or more than it would have been viewed in the absence of any\nkind of platform intervention? Can we even make sense of this last idea?\nIn one sense, everything platforms do potentially amplifies the voices of those who\ncontribute to that platform, just in virtue of their coalescing an audience. In a\nsimilar way, if you put up a noticeboard outside a village store, on which people\ncan place notices, then the mere fact of putting up that noticeboard amplifies those\nvoices relative to the alternative where no board exists. We can, however,\ndistinguish between the passive amplification of coalescing an audience, and the\nactive amplification of distributing content to members of that audience.\nActive amplification presupposes distribution: platforms amplify posts when they\ndistribute them to more users, in ways that make them more visible.41 This\nincludes both responding to search queries, and, most paradigmatically, making\nrecommendations. The basic function of recommender systems is twofold: to filter\nand to rank. The universe of possible content to which you could be exposed\nonline is vast. Filtering is the process of reducing that to a manageable shortlist.42\nRanking orders the list. Amplification can be defined as a function of two things:\nthe degree to which a given piece of content, X, has been included on those\nshortlists, as a candidate for distribution, and the weights it has been given in the\nrankings on those lists. On this approach, for any X, at any given time, there is a\nsimple scale for amplification ranging from zero to one. The zero point is when X is\nexcluded from all shortlists, and left as a bare post wherever it is originally posted.\nTotal amplification is achieved when X is included and ranked on top of all\nshortlists (as seems to have happened when the CEO of X, fka Twitter, complained\nabout not getting enough attention on the platform). Algorithmic amplification is\nthe subset of amplification carried out by recommender systems. Note that\nplatforms can amplify not only posts, but also voices and communities, by\nrecommending accounts to follow, or groups to join.\nThinking in terms of filtering and ranking also helps us to understand the\ncomplement of amplification, sometimes called demotion, reduction, deboosting,\nor deamplification.43 Filtering is a process of exclusion as well as inclusion. It\ndetermines all the content that you won't see. For example, a post can be\nconsidered as a candidate for everyone's feed, feeds of a superset of followers short\nof everyone, feeds of followers only, a subset of followers, or only those who view\nthe user's profile. Reduction or deamplification is essentially the process of moving\nalong this list.\nTarleton Gillespie regards this kind of filtering as a species of content moderation,\nsince both approaches restrict the visibility of what we communicate online.44\nAlternatively, one could argue that content moderation itself is just part of the\ncuration process, another method for distributing attention. Alternatively again,\none could say that everything-including curation - is content moderation.45 While\nthere are clearly some fuzzy boundaries here, and these are all reasonable\ninterpretations of these terms, I think some conceptual clarification could be\nhelpful. The concept of content moderation will, for my purposes, be defined by the\nreasons on which it is based, not by the form it takes or the outcome to which it\nleads. Moderation is action taken by a platform to enforce its rules. Action counts\nas enforcement only if it is directed at a party that is held to have transgressed\nthose rules. Moderation, then, includes not just removal of content, but also\nsuspension and banning of accounts. And it could include filtering of user content,\nif it is being filtered on grounds that the user has breached platform policies. This\nwould be filtering as moderation. But when posts are filtered on grounds that they\nare undesirable, but do not breach any rules and so are not objects of enforcement\nof those rules, this is filtering as curation, not moderation.\nPlatforms shape communication and distribute attention. They do not dictate\nprecisely how we may communicate with one another online. 46 They do not\nunilaterally decide what we will attend to. But their design choices make some\ncommunicative practices easy and others hard. They impose obstacles and remove\nconstraints.47 They discourage and they incentivise.48 They exercise \u2013 at\nextraordinary scale-intermediary power, constitutively shaping the social\nrelations that they mediate.\nA large body of research suggests that platforms' design choices causally\ncontribute to epistemic pollution, abuse, and manipulation.49 For example, as well\nas distributing attention, platforms aim to maximise the amount of attention\navailable for distribution; platform design encourages people to remain on the\nplatform for longer, curation practices display content that people are more likely\nto attend to and engage with.50 Inflammatory or otherwise emotive content tends\nto attract attention, so communication is shaped and attention distributed in ways\nthat foster volatility.51 This incentivises deception, hostility and manipulation. And\nit applies with even greater force to businesses (news and otherwise) whose\nviability depends on their ability to engage audiences on social media.52 More\ngenerally, platforms provide would-be manipulators with unparalleled resources\nwith which to reach out directly to their targets \u2013 and to monetise their credulity.53\nThey knit discrete communications by many individuals into a single collective\nharm (for example by identifying topics that are trending, or through likes or\nupvotes for abusive or otherwise harmful statements).54 They give us insight into\nthe political views of our weak ties, exacerbating in-group and out-group\ndynamics, contributing to affective polarisation (a species of manipulation in my\nusage).55\nWhile there is a long litany of causal pathways by which platforms' choices about\nhow to shape communication and distribute attention contribute to each of these\npathologies, there is also some dissent. Some think that the pathological state of\nour communications ecosystem is overstated; others think that things are bad, but\nthe fault lies with us, not with the platforms.56 I want to mostly sidestep these\nempirical debates.57 Even the most ardent boosters of the digital public sphere\ncould hardly deny that we could be doing better.58 And even if the shortcomings of\nonline communication are ultimately due more to our pathologies as users of\nonline platforms than to the platforms' decisions, how we shape communication\nand distribute attention are clearly essential levers in rebuilding the digital public\nsphere. Just asking people to be nicer and more truthful online is obviously not\ngoing to cut it. Even government regulation must be implemented and enforced by\nonline platforms; and most online pathologies are due not to obviously regulatable\nbehaviour by individuals-individual acts that are sufficiently serious to warrant\nsome kind of legal enforcement \u2014 but rather to emergent effects of mass\ncommunication, such that no individual is plausibly held accountable for the\nresulting harms.59\nRather than revisit epidemiological debates about the causes of our communicative\ndysfunction, I want to ask instead where we go from here.60 We should start by\nrecognising that algorithmic intermediaries in general, and online platforms in\nparticular, govern the digital public sphere. To govern, as I claimed in Lecture I, is\nto make, implement, and enforce the constitutive norms of an institution or\ncommunity. Through platform design, including architecture, moderation, and\ncuration practices, platforms determine the norms of online communication,\nimplement them, and enforce them. They thereby constitute the social relations\nthat they mediate; through both intermediary and extrinsic power they shape\npower relations among the governed, and shape the shared terms of their social\nexistence-over time reshaping social structures at large. Platforms are responsible\nfor enabling some people to limit others' liberty, and to have power over others in\nways that undermine relational equality. And they govern collective\ncommunicative practices that the members of those practices have presumptive\nrights to shape.\nEven if the pathologies of the digital public sphere are in large part ultimately due\nto us, the users, algorithmic intermediaries must determine how to govern our\nonline interactions better, or else be implicated in the deception, harassment, and\nmanipulation that they help to constitute. The pathologies of human social\ninteraction in general are due to us, the people doing the interacting. Governments\ndo not escape the obligation to protect values such as individual freedom,\nrelational equality, and collective self-determination simply on grounds that the\nthreats to those values are not their fault, but the fault of those who would oppress,\nmanipulate and deceive. Of course, it's an open question whether online platforms\nshould have ultimate authority to govern the digital public sphere - I return to this\nin Section 5-but given that they alone are in a position at least to implement and\nenforce norms of online communication, they clearly have some role to play, even\nif only as the enactors of democratically mandated laws.61\nAnd irrespective of whether platforms or states are ultimately responsible for\ngoverning the digital public sphere, we may surely conclude that how we shape\ncommunication and distribute attention will significantly affect the health of the\ndigital public sphere.62 At the very least, we know for sure that shaping\ncommunication and distributing attention in such a way as to maximise people's\nonline engagement, increase the amount of attention there is to distribute, and so\nmaximise advertising revenue is not the way to go. We are therefore forced to ask:\nwhat should we aim at instead?\nOn one approach, we hold the basic function of our communicative ecosystem\nconstant, and then aim to identify each particular pathology and develop\ncountermeasures that mitigate its effects. We acknowledge that online platforms\nare fundamentally profit-maximising corporations, but argue that their pursuit of\nprofit must be constrained by the need to implement and improve these\ncountermeasures.\nThis 'whac-a-mole' strategy is obviously important, but I think we need something\nmore: we need a positive ideal to aim at when shaping communication and\ndistributing attention. This is, first, for the obvious reason that existing pathologies\nmight be reliable side-effects of pursuing our goals as we currently understand\nthem (roughly, the pursuit of profit by online platforms). So if we don't rethink our\ngoals, we'll be fixing pathologies with one hand while causing them with the other.\nSecond, we can't address some pathologies without articulating a positive goal-for example, if recommender systems aren't going to optimise for engagement,\nwhat should they optimise for? We need positive ideals in order to say.\nThird, sometimes our countermeasures to pathologies will conflict with each other.\nUnderstanding our positive goals will afford a common currency with which to\nmanage these trade-offs.\nLastly, in the words of just war theorist Paul Ramsay, 'what justifies, limits'.63\nUnderstanding what we are aiming for will help us understand constraints on the\nmeans that can permissibly be used to get there. In particular, the justification of\ngoverning power depends on it being used for the right ends, according to the\nright procedures, by those with proper authority to do so (I call these the 'what',\n'who', and 'how' questions).64 Understanding what those who shape\ncommunication and distribute attention should aim at will help us understand\nwhat procedures they should follow, and who has the right to exercise that kind of\npower."}, {"title": "3. FROM FREEDOM OF EXPRESSION TO COMMUNICATIVE JUSTICE", "content": "Freedom of expression is an essential component in the political philosophy of\ncommunication", "expression": "they can determine whether your message reaches\na particular audience", "freedom\nof expression": "s the wrong normative lens to adopt: the answers we seek lie in\nneither expression", "freedom": "I think we need a theory of communicative justice. And an\nautonomy-based right to"}]}