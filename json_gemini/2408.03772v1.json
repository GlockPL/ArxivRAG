{"title": "Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations", "authors": ["Erica Coppolillo", "Giuseppe Manco", "Aristides Gionis"], "abstract": "Providing recommendations that are both relevant and diverse is a key consideration of modern recommender systems. Optimizing both of these measures presents a fundamental trade-off, as higher diversity typically comes at the cost of relevance, resulting in lower user engagement. Existing recommendation algorithms try to resolve this trade-off by combining the two measures, relevance and diversity, into one aim and then seeking recommendations that optimize the combined objective, for a given number of items to recommend. Traditional approaches, however, do not consider the user interaction with the recommended items.\nIn this paper, we put the user at the central stage, and build on the interplay between relevance, diversity, and user behavior. In contrast to applications where the goal is solely to maximize engagement, we focus on scenarios aiming at maximizing the total amount of knowledge encountered by the user. We use diversity as a surrogate of the amount of knowledge obtained by the user while interacting with the system, and we seek to maximize diversity. We propose a probabilistic user-behavior model in which users keep interacting with the recommender system as long as they receive relevant recommendations, but they may stop if the relevance of the recommended items drops. Thus, for a recommender system to achieve a high-diversity measure, it will need to produce recommendations that are both relevant and diverse.\nFinally, we propose a novel recommendation strategy that combines relevance and diversity by a copula function. We conduct an extensive evaluation of the proposed methodology over multiple datasets, and we show that our strategy outperforms several state-of-the-art competitors. Our implementation is publicly available.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommender systems play a significant role in helping users discover new information and expand their knowledge base. Notable examples are the adoptions of recommendations for finding news articles or books to read [3, 54, 64], listening to enjoyable music [18, 45], visiting interesting locations [55, 58], and more. Recommender systems aim to predict and leverage users' interests to identify the portions of the catalog that match them, thus enabling efficient exploration of vast volumes of information and offering benefits ranging from increased personalization and user satisfaction to improved engagement and resource efficiency.\nRecommenders are primarily focused on maximizing relevance. However, from the standpoint of knowledge exploration, incorporating diversity into recommendations adds significant value, as emphasized in earlier research [24, 48]. Indeed, providing diverse recommendations can be critical in mitigating detrimental consequences, such as being trapped in rabbit holes in platforms like Youtube [20, 35, 42, 51] or Reddit [40], where the algorithm may lead the user to consume limited types of content.\nTo achieve a balance between relevance and diversity, current methods merge these two metrics into a single objective for optimization. However, they overlook user behavior and how users interact with the recommended list of items. For instance, typical approaches assume a fixed number of interactions between the\nuser and the algorithm, disregarding any reactions or refusals from the user during the exploration process. Indeed, users might reject recommended items and quit the process.\nIn this paper we propose a new framework for recommender systems, where we place the user at the forefront. We consider the interaction of the user with the algorithm to be a knowledge-exploration task, where recommendations enable exploration. The interaction of the user with the system is guided via a user-behavior model, i.e., the propensity of a user to accept or reject recommendations according to their preferences and patience. As the objective is to maximize the amount of knowledge that a user acquires during exploration, we model the knowledge accrued by the user using a diversity measure, which we consequently aim at maximizing. Notably, although diversity is the sole optimization objective, the coupling of the exploration task with the user-behavior model implies that the recommendation system is required to produce recommendations that are both relevant and diverse.\nWe illustrate the proposed concept of \u201cknowledge exploration via recommendations\" with the following example.\nExample. Alice interacts with a news recommender system for finding interesting news articles to read. The knowledge-exploration process is iterative, and is depicted in Figure 1. At each step, the system recommends a set of news articles to Alice, and Alice clicks on some article to read. At some point, Alice can decide to quit, either because she received enough information, or because the recommendations are not very interesting to her, or simply because she got bored. Our goal is to design a recommender system that maximizes the amount of knowledge received by Alice. The challenge is to strike a balance between diversity and relevance to keep Alice engaged while exploring interesting topics, avoiding scenarios where recommendations are either too focused (Figure 2(a)) or too diverse and irrelevant (Figure 2(b)). Our aim is to create an ideal scenario (Figure 2(c)) where Alice explores many relevant yet diverse topics, enriching her knowledge.\nMotivated by the previous example, we propose a novel framework where relevance governs the termination of exploration, while the overall quality is measured by diversity. We instantiate our model using two standard notions of diversity, one based on coverage and the other based on pair-wise distances [4, 9, 13]. Both diversity notions, coverage and pairwise distances, can be defined using an underlying space of user-to-item ratings or categories/topics.\nFinally, we propose a novel recommendation strategy that combines relevance and diversity by a copula function. We perform an extensive evaluation of the proposed framework and strategy using five benchmark datasets publicly available, and show that our strategy outperforms several state-of-the-art competitors.\nOur contributions are summarized as follows:\n\u2022 We develop a user-centric model for knowledge exploration via recommendations; our framework takes into consideration the interplay among relevance, diversity, and user behavior.\n\u2022 We instantiate our model with two diversity measures, defined over user-to-item ratings or categories/topics.\n\u2022 We propose a recommendation strategy that accounts for both diversity and relevance when providing suggestions.\n\u2022 We conduct an extensive analysis over multiple benchmark datasets and several competitors to show the effectiveness of our proposal in the suggested framework.\nThe rest of the paper is structured as follows. Section 2 presents the related work in terms of user modeling and diversity in recommendations. Section 3 presents our problem definition and methodology. In Section 4 we present our recommendation strategy. Experimental results are reported in Section 5, and finally Section 6 concludes the paper and provides pointers for future extensions."}, {"title": "2 RELATED WORK", "content": "User modeling in recommender systems. The effects of user behavior in recommender systems, in terms of novelty and diversity, have gained a lot of attention in recent years. Analysis can be conducted by either running user studies [28, 29, 33, 62], or by means of simulation [23, 50, 57]. Analyzing the choices made by actual users can yield more dependable outcomes; however, it also requires creating an effective recommendation system and engaging users for conducting comprehensive studies.\nOn the other hand, simulating user choices is a more straightforward method, allowing for testing several system configurations at no expense. However, it requires a realistic model of user behavior. To address this challenge, several user-behavior models have been proposed in the literature. Hazrati and Ricci [22] model the probability that a user picks a recommended item as being proportional to the utility of the item. Similarly, Bountouridis et al. [7] propose a simulation framework in which users decide to interact with a certain number of items per iteration, according to their given preferences. Szl\u00e1vik et al. [50] present three different user-behavior models, by imposing that users either blindly follow recommendations and choose the most popular items, or completely ignore suggestions and pick items randomly.\nThe aforementioned models present certain limitations, namely users necessarily have to pick an item, i.e., they cannot leave the application, and second, the selection probability stays constant over time. We overcome these limitations by modeling a quitting probability, according to which users can interrupt their interaction with the recommender system. We assume that the quitting\nprobability depends on the utility of the recommended items and on the user patience, which degrades over time.\nNotably, with our framework, we leverage the intrinsic interplay among relevance, diversity, and user behavior, since successful recommendation strategies need to ensure that they provide recommendations that are both relevant and diverse.\nDiversity in recommendation. Diversity in recommendations has been acknowledged as a crucial issue [10, 24, 48, 63], and over the past decade, it has received considerable attention [1, 2, 11, 25, 52]. Several online and targeted user studies assessed the increase in user satisfaction when diversity is incorporated into the list of suggested items [10, 25]. For example, Allison et al. [12] show that, if diversity (besides other objectives) is not taken into account, the interactions between users and recommender systems are prone to homogenization and, consequently, low utility.\nThe challenge of striking a balance between diversity and relevance has been explored both in the context of recommender systems and in the broader domain of information retrieval. For instance, one of the most popular methods in the literature of information retrieval is the maximal marginal relevance (MMR) [9]. It employs a weighted linear combination of scores that evaluate both utility and diversity, offering a systematic way to address this critical aspect. In the specific context of recommender systems, Ziegler et al. [63] introduced one of the earliest methods for enhancing diversity. They use a greedy selection approach, where they pick items that minimize the similarity within a recommended list. Liu et al. [32] present a solution based on random walks for the so-called accuracy-diversity dilemma, i.e., the challenge in finding a profitable trade-off between the two measures. This concept is also known as calibration, as mentioned by Steck [49], and refers to the algorithm's capability to produce suggestions that do not under-represent (or ignore) the user's secondary areas of interest.\nSeveral re-ranking strategies have also been introduced: Ashkan et al. [4] propose to greedily select items by maximizing the utility of a submodular function; Sha et al. [47] suggest to optimize the diversity loss of items using probabilistic matrix factorization; Chen et al. [13] propose a determinantal point process (DPP) to re-rank the recommended items so as to maximize the determinant on the items' similarity matrix. Hansen et al. [19] investigate the impact of diversity on music consumption, and propose two innovative models: a feed-forward neural ranker that produces dynamic user embedding, and a reinforcement learning-based ranker optimized on the track relevance. Reinforcement learning is indeed a suitable solution for addressing the diversity problem. It plays a role in the work by Parapar and Radlinski [37], where diversity is induced by adopting multi-armed bandits in the elicitation phase; and in the online learning framework proposed by Yue and Guestrin [59], where diversification is obtained by carefully balancing the exploration and exploitation of users' preferences and interests. Notably, these reinforcement learning-based approaches typically require a lengthy training phase, which can often be prone to stability issues.\nSeveral other neural-network models have been applied to address the diversity problem. Gao et al. [16] adopt a variational autoencoder to induce targeted (i.e., topical) diversity. Liang et al. [30] propose a bilateral branch network to achieve a good trade-off between relevance and diversity, defined at either domain or user level. Zheng et al. [61] present a graph neural network for diversified"}, {"title": "3 USER MODEL AND PROBLEM FORMULATION", "content": "Algorithm 1 Simulation process for user u\nInput: u, I, S, R\nOutput: X\n1: X \u2190 0\n2: quit \u2190 False\n3: while not quit do\n4:  Lt \u2190 [i\u2081, i\u2082,..., ik] \u2190 S(R(u, I \\ X), X)\n5:  examining Lt\u2190 Algorithm 2\n6:  if u does not quit then\n7:  i \u2190 picked item\n8:  X\u2190 XU {i}\n9:  else\n10:  quit \u2190 True\n11:  end if\n12: end while\nAlgorithm 2 User behavior at step t\nInput: Lt\nOutput: i \u2208 Lt or quits\n1: interest \u2190 False\n2: for j = 1,..., k do\n3:  i\u2190 Lt [j]\n4:  quitting with probability Nt\n5:  if u quits then\n6:  return\n7:  else\n8:  examining i with probability q\u012f\n9:  if i is interesting then\n10:  interest \u2190 True\n11:  end if\n12:  end if\n13: end for\n14: if not interest then\n15:  return\n16: end if\n17: for j = 1,..., k do\n18:  i\u2190 Lt [j]\n19:  consuming i with probability p\u012f\n20:  if u consumes i then\n21:  return i\n22:  end if\n23: end for\nWe consider a typical recommendation setting in which we have a set of m users U and a set of n items I. We also consider a function R:UxI\u2192R that provides us with a relevance score R(u, i), for each user u \u2208 U and item i \u2208 I. We assume that the function R can be computed by a black-box method, and state-of-the-art relevance-scoring functions can be employed, such as content similarity [38], collaborative filtering [44], or a combination of both [8]. Our goal in this paper is to create lists of diverse recommendations using as a black box such relevance-scoring functions, rather than devising a new relevance-scoring function R.\nItem-to-item distance function. We next discuss how to define a distance function between pairs of items in I, which will be used in one of our two diversity definitions.\nGiven an item i \u2208 I, we denote by xi the vector of users with\n$$X_{iu} = \\begin{cases}\n1, & \\text{if user } u \\text{ interacted with item } i, \\\\\n0, & \\text{otherwise}.\n\\end{cases}$$\nThe vectors {x\u1d62} can be retrieved by user-log data. A more fine-grained representation of vectors {x\u1d62} beyond binary is also possible, for instance, using numerical values that represent the rating of user u for item i, if such information is available.\nAn alternative approach is to use categories (or keywords, or genres, depending on the application). In particular, we consider a set of categories C, and we define yi to be a category vector, for item i \u2208 I, where\n$$Y_{ic} = \\begin{cases}\n1, & \\text{if category } c \\text{ relates to item } i, \\\\\n0, & \\text{otherwise}.\n\\end{cases}$$\nGiven two items i, j\u2208 I, we hence define their distance as the weighted Jaccard distance\n$$d(i, j) = 1 - \\frac{\\sum_{w \\in W} \\min{z_{iw}, z_{jw}}}{\\sum_{w \\in W} \\max{z_{iw}, z_{jw}}}$$\nwhere W is either the set of users U or the set of categories C, and accordingly, zi is the user vector or the category vector of item i.\nFinally, we note that other state-of-the-art distance functions can also be used, such as Euclidean distance, cosine similarity, or Minkowski distance [6]. We do not investigate what is the best distance function to be used, as this is orthogonal to our study and beyond the scope of this paper.\nDiversity. Given a set of items X \u2286 I, we define the diversity of the set X. We explore two different definitions of diversity.\nOur first definition is based on the concept of coverage. It assesses the degree to which the items within X adequately represent the entire range of categories C. In particular, for a set of items X \u2286 I, we define its coverage-based diversity as\n$$dive(X) = \\frac{1}{|C|} \\sum_{i \\in X} ||y_i||_0$$\nwhere || \u00b7 ||\u2080 returns the number of non-zero entries of the binary vector \u03a3\u1d62 \u2208 X yi. Notice that the metric dive is scaled to fall within the range of 0 to 1, considering the total number of categories in C. It is worth highlighting that dive favours larger X sizes, as they typically cover a wider range of categories. Additionally, dive naturally prefers items that individually provide extensive coverage.\nOur second measure of diversity employs the distance function d that we defined in the previous paragraph. In particular, for a set of items X \u2286 I with |X| \u2265 2, we define its distance-based diversity as\n$$div_D(X) = \\frac{1}{|X| - 1} \\sum_{i \\in X} \\sum_{j \\in X} d(i, j)$$\nand we define div\u209a(X) = 0, if |X| < 2. Notice that the number of terms in div\u1d65 is quadratic with respect to |X|. By normalizing with (|X|-1) the dependence becomes linear in |X|. As with div\u03f2, the div\u1d65 metric favors larger sets, in addition to favoring items whose distance is large to each other.\nUser model. A central aspect of our approach is that we aim to evaluate the quality of a recommendation algorithm S in the context of the user response to items recommended by S. We view the user-algorithm interaction as a dynamic knowledge-exploration process, in which the algorithm recommends items to the user, and the user interacts with the recommended items. The knowledge-exploration process continues as long as the recommended items are of interest to the user. If the recommended items are not interesting enough (meaning, if they have low relevance for the user) the user may (stochastically) decide to quit.\nTo formalize the exploration process between the user and the recommendation algorithm S, which is needed to evaluate the quality of S, we propose a user model. Our model is specified in terms of a relevance-scoring function R, which guides the behavior of the user, and in terms of a recommendation algorithm S, which enacts the choices within S.\nOur user model, which formalizes knowledge-exploration as an iterative process, is described as follows.\n(1) The set of items that the user interacts with during the exploration process is denoted by X. Initially X is empty.\n(2) In the t-th step, the recommendation algorithm S generates a list of items Lt to present to the user. The user examines these items in a specified order.\n(3) At any point in the current step, the user has the option to quit. The likelihood of quitting (to be quantified later) depends on two factors: the relevance of the recommended items and the user's patience. If the user fails to find interesting items in list Lt or if they stochastically run out of patience, they may opt to conclude the exploration process.\n(4) If the user does not quit, with a certain probability that depends on the relevance of the recommended items (and which we quantify later), they select an item i from the list Lt and interact with it. The item i is added to the set X and the exploration process continues.\n(5) Upon quitting, the total score achieved by the recommendation algorithm S is determined to be div(X), where div is one of our diversity functions, dive or div\u209a. This score reflects the diversity in the items the user has interacted with throughout the exploration process. We denote the final number of steps performed by the user as \u03ba.\nAlgorithm 1 depicts the overall exploration process.\nTo fully specify the user model we need to describe in more detail the probability that the user selects an item to interact with, as well as the probability of quitting the exploration. Before presenting more details about these aspects of the model, we first formalize the problem of designing a recommendation algorithm in the context of our user model."}, {"title": "The recommendation task (problem statement)", "content": "The algorithmic problem that we address in this paper is the following.\nPROBLEM 1. Given a set of items I, a set of users U, a relevance-scoring function R : U \u00d7 I \u2192 R, a diversity function div : 21 \u2192 R, and a user model for knowledge-exploration as the one described in the previous paragraph, the goal is to design a recommendation algorithm S that maximizes the diversity score div(X) for the set of items X that a user u \u2208 U interacts with.\nItem selection. We now discuss step (4) of the iterative knowledge-exploration user model presented in the previous paragraph, that is, we specify how we model the probability that a user selects an item i from the list Lt to interact with. We first assume that a user does not quit exploration, i.e., that they have enough patience to explore the whole Lt and that they find at least a relevant item within it (see next paragraph). In that case, the user selects an item i from Lt with probability proportional to the relevance of i for that user u, that is, p\u1d62 = R(u,i). As noted before, the selected item i is\n\u03a3j\u2208L R(u,j)\nadded to the set of interacted items X.\nQuitting exploration. Last, we discuss step (3) in our user model, that is, how we model the probability that a user quits the exploration process. A sensible model for the quitting probability is crucial in our knowledge-exploration model, since we want to mimic user behavior as realistically as possible. In particular, we take into consideration two aspects: (i) users decide to interact with the recommended items according to their relevance; and (ii) users' desire for exploration degrades with time, i.e., users get bored.\nIn the model we propose, a user examines the items in the list Lt sequentially. Upon examining an item i \u2208 Lt the user decides with probability nt to quit exploration due to worn out at step t. We refer to this as the weariness probability. The weariness probability nt, which is discussed in more detail below, models the user's decline of interest in exploration as a function of time, and it depends on the current step t in the exploration process.\nIf the user does not quit, they decide whether item i is interesting to explore. The latter is decided again stochastically with Bernoullian probability qi, which is a function of the relevance score R(u, i). Thus, the probability qi models the user's interest in an item according to its relevance. The examination of the list Lt continues until the user decides to quit or decides that there is at least one item that is interesting to explore. Thus, the probability that the user quits examining the list Lt without identifying any item to explore is\n$$Q_t = \\{pr. \\text{ quitting after the first item} \\} + ... + \\{pr. \\text{ quitting after the last item} \\}$$\n$$= \\sum_{j=1}^{L_t} \\eta_t \\prod_{i=1}^{j-1} (1 - \\eta_t)^{j-1} (1-q_i)$$\nThe last ingredient in our model is to quantify the weariness probability nt at step t. This probability models the user's increasing impatience or boredom as their interaction continues. To achieve\nthis, we employ the Weibull distribution [36], which has been previously used to model web page dwell times and session lengths in web page navigation [31].\nThe Weibull distribution is described by two parameters, \u03bb and \u03b3, where \u03bb > 0 is the scale parameter and \u03b3 > 0 is the shape parameter of the distribution. In particular, we set the weariness probability nt by resorting to the discrete version of the Weibull Distribution [43]:\n$$\\eta_t = 1 - q^{(t+1)^{\\lambda} - t^{\\gamma}},$$\nwhere q = e\u207b\u00b9\u2044\u03bb, 0 \u2264 q \u2264 1.\nThe shape parameter \u03b3 controls the \u201caging\u201d of the process. For \u03b3 = 1 the weariness probability remains constant, and the resulting distribution becomes an exponential distribution, while for \u03b3 > 1, the weariness probability increases over time - modeling the tiredness of the user.\nWe can use the analytical properties of the Weibull distribution to obtain the expected number of steps in the exploration process, for the case that all recommended items are maximally relevant, i.e., qi = 1 for all i \u2208 Lt. In this case, there will be exactly one coin-flip for quitting exploration for each list Lt, and thus, Qt = nt, for all t. The overall quitting probability QT is then\n$$Q_T = \\{pr. \\text{ quitting at step 1} \\} + ... + \\{pr. \\text{ quitting at step t} \\} + ...$$\n$$= \\sum_{t=1}^{\\infty} \\eta_t \\prod_{j=0}^{t-1} (1-\\eta_j)$$\n$$= \\sum_{t=1}^{\\infty} q^{t^\\gamma} - q^{(t+1)^\\lambda} \\prod_{j=0}^{t-1} q^{j^\\gamma}$$\n$$= \\sum_{t=1}^{\\infty} (1 - q^{(t+1)^\\gamma-t^\\gamma}) q^{t^\\gamma}$$\nThe expected number of steps E[steps] examined by a user before quitting (or equivalently, the number of items in X) is hence given by\n$$E[steps] = \\sum_{t=1}^{\\infty} t(q^{t\\gamma} - q^{(t+1)^\\gamma})$$\nAlthough lacking closed-form analytical expressions, Khan et al. [26] show that it is bounded by the expectation \u00b5 = \u03bb \u0393(1 + 1/\u03b3) of the Weibull distribution in the continuous setting [36] as\n$$\u00b5 < E[steps] < \u00b5 + 1,$$\nwhich provides an algebraic relationship between the \u03bb parameter of the Weibull distribution and the admissible range for the expected number of steps.\nNote that, if the relevance of the recommended items is less than 1, it is possible to get more than one coin-flip for quitting exploration in each list Lt. In this case, the right-hand side of Equation (7) provides an upper bound on the expected number of steps during exploration.\nA notation table can be found in the Appendix (Table 7)."}, {"title": "4 RECOMMENDATION STRATEGY", "content": "In this section, we present our recommendation strategy for the proposed knowledge-exploration framework. Recall that the recommendation task is displayed as Problem 1.\nThe core of the problem is to construct a list of recommendations Lt of size ||Lt || = k for the t-th step of exploration, for a given user u \u2208 U. We assume that Xt is the set of items that the user has interacted with at step t, where X\u2081 = 0. We define It = I \\ X\u209c to be set of items that are available for recommendation, that is, all items except the ones that the user has already interacted with. For a user u and each item in the candidate set i \u2208 It we consider its relevance score Ri = R(u, i) and its marginal diversity\n$$T_i = div(X_t \u222a \\{i\\}) - div(X_t)$$\nwith respect to the interaction set Xt, where div \u2208 {dive, div\u209a}. We denote Ti = Di when the distance diversity function div\u209a is used, and Ti = Ci when the coverage diversity function div\u03f2 is used. Intuitively, Di represents the distance of i from all the items in the interaction set Xt, while Ci represents the additional coverage that i provides. Given Pi \u2208 {Ri, Ti}, we also denote the min-max normalization of the score P as P\u1d62 = (Pi - Pmin)/(Pmax Pmin), where Pmax and Pmin are the maximum and minimum values of P, respectively, over all items in Xt.\nOur strategy for constructing the recommendation list Lt is to combine relevance and diversity into one score. For each item i with relevance Ri and diversity Ti, we compute the combined score Zi by adopting the Clayton copula function [14]\n$$Z_i = [\\tilde{R_i}^{-\\theta} + \\tilde{T_i}^{-\\theta} - 1]^{-1/\\theta},$$\nwhere a > 0 is a regularization parameter. The list Lt is then formed by selecting the top-k items from It according to their combined score Zi.\nWe refer to this strategy as EXPLORE. When the distance diversity function is used we refer to it as EXPLORE-D, and when coverage diversity is used we refer to it as EXPLORE-C. A final word on the justification of using the copula function (10). Copulas are functions able to model the cumulative joint distribution of uniform marginal distributions. In general, they are used to represent correlation and dependencies of high-dimensional random variables [34, 39, 53, 60]. The Clayton copula function approaches 1 when both the input variables u, v are maximized, and it is minimized when either of them is 0. The a parameter governs the steepness and folding of the\nfunction in Equation (10), in contrast to a simpler strategy that neglects relevance and relies on Equation (9)."}, {"title": "5 EXPERIMENTS", "content": "In this section, we assess the performance of our recommendation strategy, either EXPLORE-D or EXPLORE-C, in balancing accuracy and diversity. We also compare its effectiveness with several state-of-the-art competitors within the proposed knowledge-exploration framework.\n5.1 Datasets\nWe use five benchmark datasets, freely available online. We ensure that all datasets have category information, which is used by our diversity measures.\nMovielens-1M [21]: A popular dataset with movie ratings in the range [1, 5], and movie genres.\nCoat [46]: Ratings on coats in the range [1, 5], and information on coats' properties.\nKuaiRec-2.0 [15]: A recommendation log from a video-sharing mobile app. Context information is provided, such as play duration, video duration, and watch ratio. We convert the watch ratios into ratings by interpolating the values from [0, 2] to [1, 5], where 0 represents \"never watched\" and 2 represents \"watched twice.\" We use the small version of the dataset.\nNetflix-Prize [5]: Movie ratings in the range [1, 5]. We adopt a smaller sample of the original dataset by randomly selecting 5 000 items and discard the users with less than 20 interactions. Movie categories are acquired from a dataset using the IMDB database.\nYahoo-R2: Song ratings in the range [1, 5]. Each item is accompanied by artist, album, and genre information. We randomly sample 3000 items and discard users with less than 20 interactions.\nTable 1 provides a summary of the dataset properties, which include the number of users (U), the number of items (|I|), the number of ratings (#Ratings), and the distribution of item distances, calculated based on either users or categories. During our experiments, we use Equation (1) with the distance that exhibits the lowest mean for each dataset. This approach helps us avoid potential bias from large distance values, which could otherwise hinder the effectiveness of the approaches."}, {"title": "5.2 Competing recommendation strategies", "content": "We evaluate our recommendation algorithm, EXPLORE, against the following baseline and state-of-art strategies that have been designed for the task of increasing diversity in recommender systems.\nRelevance: This approach recommends the k most relevant items, making it a fundamental baseline. Since this strategy is solely focused on maximizing relevance, it represents the most straightforward and basic diversity method, and any other approach must outperform it to be deemed effective.\nMaximal marginal relevance (MMR) [9]: A classic method used to balance relevance and diversity, performed by optimizing the following marginal relevance:\n$$MMR = argmax \\beta R(u, i) - (1 - \\beta) \\max S_{i, j}$$\nwhere Si,j = 1 \u2013 d(i, j). In our experiments, we set \u03b2 = 0.5.\nDUM [4]: This strategy aims at diversifying the suggestions by performing the following diversity-weighted utility maximization:\n$$DUM = argmax \\sum_{L \\in \\Pi} [f (L[h]) - f (L[:h-1])] (u, i_h),$$\nwhere \u03a0 denotes all possible permutations of L, L[:h] represents the list up to the h-th element in, and f(X) = \u03a3c\u2208C 1{exists i \u2208 X: i covers category c} is the number of categories in X. Hence, the function maximizes the relevance of the recommended items weighted by the increase in their coverage.\nDPP [13]: This method utilizes determinantal point processes and maximizes diversity by iteratively selecting the item i that maximizes the determinant of the item-item similarity matrix S defined on a subset of items:\n$$DPP = argmax \\{log det(S_{L\u222a\\{i\\}}) - log det(S_{L})\\} .$$\nDGREC [56]: A graph neural network (GNN) based recommender that aims at finding a subset of diverse neighbors as well as maximizing the coverage of categories, by optimizing the loss function:\n$$L_{DGREC} = \\sum_{(u,i) \u2208 E} w_{y_i} L_{BPR}(u, i, j) + \u03bb||\u0398||^2,$$\nwhere wy\u1d62 is the weight for each sample based on its category, \u03bb is a regularization factor, and LBPR is the Bayesian personalized ranking loss [41].\nNotably, these competitors exhibit significant heterogeneity both in terms of the approaches they employ as well as the specific diversity functions they aim to optimize."}, {"title": "5.3 Experimental setting", "content": "To evaluate the performance of the examined recommendation strategies, we divide user interactions into a training and a test set, following an 80-20% split ratio. When evaluating the accuracy, we only focus on the recommendation list generated in the initial exploration step. Regarding diversity, we consider the complete set of recommendation lists produced across all exploration steps. Our approach also assumes that the entire item catalog is accessible to every user during the simulation.\nTo calculate the relevance score R(u, i), we employ a black-box model in the form of a neural network based on matrix factorization [27]. We fine-tune the latent factors of this model for each dataset. For EXPLORE, we use a value of a = 0.5 in the Clayton copula. Additionally, we conduct hyperparameter tuning for this parameter, and it appears that it has no significant impact on the results (further details can be found in the Appendix).\nWe keep the length of the recommendation list, L, fixed at 10, and vary the expected number of steps, E[steps], in the range of [5, 10, 20]. This allows us to devise a suitable value for the Weibull parameter A to be used in the simulation experiments, according to Equation (7). To assess recommendation quality, we use standard metrics: Hit-Ratio (HR), Precision, and Recall. Our experimental results are the average of 20 independent trials, and we use the ANOVA test [17] to evaluate statistical significance. The code used in these experiments is made publicly accessible."}, {"title": "5.4 Results", "content": "Quality-diversity trade-off. We initiate our evaluation by assessing the performance of all our strategies in terms of recommendation quality and diversity. Figure 3 displays the scores for Recall@10 (on the x-axis) and coverage-based diversity (on the y-axis) across all five datasets. The figure shows that on all datasets, MMR and DGREC exhibit notably poor performance with respect to Recall@10. In contrast, the other strategies achieve significantly higher scores, with the Relevance baseline performing the best, which aligns with our expectations.\nIn terms of diversity, our method, EXPLORE-C, clearly outperforms the other strategies. It achieves a substantially higher diversity score while still delivering relevant recommendations. In fact, it strikes the best trade-off between diversity and relevance. Similar results, both in terms of diversity measures and other evaluation metrics, can be found in the Appendix for reference.\nBest performing diversity strategy. Table 2 presents a comprehensive analysis of div\u209a, dive and K when E[steps", "\u0394\u0395[steps": "."}]}