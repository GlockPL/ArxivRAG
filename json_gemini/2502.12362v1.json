{"title": "Classifiers of Data Sharing Statements in Clinical Trial Records", "authors": ["Saber JELODARI MAMAGHANI", "Cosima STRANTZ", "Dennis TODDENROTH"], "abstract": "Digital individual participant data (IPD) from clinical trials are increasingly distributed for potential scientific reuse. The identification of available IPD, however, requires interpretations of textual data-sharing statements (DSS) in large databases. Recent advancements in computational linguistics include pre-trained language models that promise to simplify the implementation of effective classifiers based on textual inputs. In a subset of 5,000 textual DSS from Clinical Trials.gov, we evaluate how well classifiers based on domain-specific pre-trained language models reproduce original availability categories as well as manually annotated labels. Typical metrics indicate that classifiers that predicted manual annotations outperformed those that learned to output the original availability categories. This suggests that the textual DSS descriptions contain applicable information that the availability categories do not, and that such classifiers could thus aid the automatic identification of available IPD in large trial databases.", "sections": [{"title": "1. Introduction", "content": "While clinical research has for some time aggregated findings from previous clinical trials, today the increasing availability of digital individual participant data (IPD) yields increasing opportunities to synthesize new medical knowledge. Effective data reuse, however, requires that collected IPD should be discoverable and accessible to other researchers for further analysis [1]. Online platforms designed to share patient-level trial data promote transparency [2] but may introduce additional requirements that can impede data reuse, especially when access criteria remain 'scattered across multiple web pages' or 'buried within legal agreements' [3]. Previous investigations have indicated that only a minority of clinical trials and observational studies declare clear intentions to share IPD, and even then vital details for data access may be unclear [4]. These previous investigations relied on the manual analysis of data-sharing statements (DSS) in trial registries like ClinicalTrials.gov, which has requested categorical and textual information about data-sharing intentions from trialists since 2018.\nAs of December 2023, ClinicalTrials.gov contains records for more than 470,000 clinical trials, highlighting the extensive collection of medical research data that is potentially accessible for study. This large quantity of records impedes exhaustive"}, {"title": "2. Methods", "content": "In order to evaluate the effectiveness of modern language models for DSS classification, we focused on three BERT versions that have been pre-trained using domain-specific corpora. SciBERT has been trained on a compilation of scientific papers [7]. BioBERT"}, {"title": "3. Results", "content": "Table 2 demonstrates the performance metrics for SciBERT, BioBERT, and BlueBERT, with comparable accuracy rates of approximately 69% for the original IPD categories and 83% for our complemented annotations across the models. Among the evaluated models, SciBERT moderately outperformed the alternatives. An analysis of label agreement with the original IPD categories revealed that 3,130 of 5,000 (62.2%) of our annotated labels agreed with the original three-level IPD categorization. The referenced repository provides additional statistical details such as model-specific confusion matrices."}, {"title": "4. Discussion", "content": "Our results indicate that the NLP-based classifier reproduced annotated labels better than the original categorical entries. This suggests that there is valuable information in the textual DSS entries that the provided IPD categories do not reflect. Currently, ClinicalTrials.gov does not have a mechanism for filtering trials based on IPD sharing status. We assume that discrepancies between textual DSS and the original availability categories could undermine the potential utility of such a filtering function at the moment. Our findings suggest that pre-trained language models may be effective for the extraction of relevant information from textual DSS, and if implemented in search functions or filtering options could aid the discovery of available IPD.\nWith the growing volume of registered trials at ClinicalTrials.gov, the capability of specialized models such as SciBERT to assign interpretable categorical labels to descriptions becomes potentially valuable. Its observed effectiveness highlights a potential pathway to improving the discoverability and reusability of IPD records for an increasingly automated form of medical research based on digital artifacts.\nAs a limitation, we have to concede that our analysis was restricted to DSS that could be exported from clinicaltrials.gov. In practice, many statements include links to additional web-based platforms or direct users to contact the respective research teams to ask for IPD access. This dependency on other resources curtails our ability to assess whether IPD is truly shared, specifically since real data sharing may fall short of declarations [10]. We propose that automated DSS interpretations, however, could support subsequent studies of the relationship between stated intentions and actual IPD sharing. Future methodological research might investigate whether larger pre-trained language models that support prompting instead of learning from examples can lead to an improved classification performance."}, {"title": "5. Conclusions", "content": "Our findings highlight that the evaluated language models offer consistent performance in classifying IPD sharing statements, with SciBERT slightly outperforming BioBERT and BlueBERT. Trained classifiers might facilitate data discovery and improve accessibility on platforms such as ClinicalTrials.gov, which currently lacks specific search features for IPD status. Improved accuracy in automatic labeling could support researchers in efficiently identifying datasets that align with their study goals."}]}