{"title": "TABLEGUARD - SECURING STRUCTURED & UNSTRUCTURED DATA", "authors": ["Ajinkya Deshmukh", "Anantha Sharma"], "abstract": "With the increasing demand for data sharing across platforms and organizations, ensuring the privacy and security of sensitive information has become a critical challenge. This paper introduces \"TableGuard\". An innovative approach to data obfuscation tailored for documents & relational databases. Building on the principles and techniques developed in prior work [1] on context-sensitive obfuscation, TableGuard applies these methods to ensure that API calls return only obfuscated data, thereby safeguarding privacy when sharing data with third parties.\nTableGuard leverages advanced context-sensitive obfuscation techniques to replace sensitive data elements with contextually appropriate alternatives. By maintaining the documents & relational integrity and coherence of the data, our approach mitigates the risks of cognitive dissonance [2] and data leakage. We demonstrate the implementation of TableGuard using a BERT based transformer model, which identifies and obfuscates sensitive entities within documents & relational tables.\nOur evaluation shows that TableGuard effectively balances privacy protection with data utility, minimizing information loss while ensuring that the obfuscated data remains functionally useful for downstream applications. The results highlight the importance of domain-specific obfuscation strategies and the role of context length in preserving data integrity.\nThe implications of this research are significant for organizations that need to share data securely with external parties. TableGuard offers a robust framework for implementing privacy-preserving data sharing mechanisms, thereby contributing to the broader field of data privacy and security.", "sections": [{"title": "Introduction", "content": "TableGuard aims to mask or replace sensitive information with fictitious but plausible data, thus preventing unauthorized access while retaining the utility of the dataset. However, indiscriminate obfuscation can lead to inconsistencies, especially when related entities are not obfuscated together. For example, replacing \u201cNew York\u201d with \u201cChicago\u201d while referring to the \u201cEmpire State Building\" can confuse [2] language models, leading to erroneous inferences. Our research focuses on obfuscating related entities cohesively to avoid such issues.\nTraditional methods of data obfuscation often lead to significant information loss or cognitive dissonance within automated systems, such as language models. This paper addresses these challenges by proposing a context-sensitive obfuscation approach that maintains document integrity. The paper is structured to detail our methodology, data preparation, model testing, and the implications of our findings, providing a comprehensive overview of effective PII obfuscation techniques."}, {"title": "Data", "content": "Our study uses names-dataset (a pypi package) [3] which contains 730K first names, 983K last names - extracted from the Facebook massive dump (of 533M users). The composition of sensitive information like first name and last name coupled with dates of birth, and places of birth gives us a unique perspective on which names were popular around what year, we use this relationship to determine next best token to use in obfuscation.\nThis dataset provides a substantial foundation for testing the robustness and efficacy of our obfuscation techniques. Ensuring the ethical use and anonymization of data is paramount."}, {"title": "Methodology", "content": "The initial step in data preparation involved cleaning and preprocessing the dataset to remove any inconsistencies or irrelevant information. This process included normalizing the text, removing duplicates, and handling missing values. Each entry was then tokenized to facilitate further processing by our transformer model. Special attention was given to retaining contextual information to support accurate entity recognition and obfuscation.\nSubsequently, named entity recognition (NER) was performed using Stanford CoreNLP [4], a powerful NLP library, to identify entities that required obfuscation. These entities included names, locations, and other PII. The identified entities were then marked for replacement with appropriate pseudonyms or fictitious data. The preprocessing phase ensured that the dataset was ready for the application of our obfuscation model, setting the stage for effective and context-sensitive obfuscation."}, {"title": "Approach", "content": "Building on the work [5] we use a transformer-based model to identify sensitive entities within documents & relational tables. The model is built on BERT [6] trained on a dataset of documents & relational tables, where each table is represented as a sequence of tokens. The goal is to predict the replacement token for each entity in the table, given its context (context here is based on the content of the row in question coupled with data dictionary and table metadata).\nMasking:\nMask sensitive data by replacing characters or digits with placeholders. This experiment can assess the effectiveness of masking techniques in preventing unauthorized access to sensitive information.\nThese techniques are commonly used in data masking, but they do not take into account the context of the data.\nPerturbation: Introduce noise or perturbations to sensitive data. There is a need to evaluate the impact of perturbation on data privacy and the ability to recover original data.\nDifferential Privacy: Apply differential privacy mechanisms to the database.\nVarious data engineering tools provide different data masking, differential privacy, and perturbation techniques.\nContextual Obfuscation: Obfuscate data based on contextual information. This experiment can explore the effectiveness of context-sensitive obfuscation in preserving data integrity and coherence."}, {"title": "Experiments", "content": "Our experimental design aimed to rigorously evaluate the effectiveness of TableGuard's obfuscation techniques, focusing on their impact on data privacy and utility. The experiments were meticulously crafted to address key research questions regarding the trade-offs between privacy preservation and data usability while keeping a close eye on runtime performance."}, {"title": "Setup", "content": "The core of our experimental setup revolved around three primary obfuscation techniques: masking, perturbation, and differential privacy. Each technique was applied to a subset of the dataset, allowing us to isolate and measure their individual effects. The dataset, derived from the names-dataset package [3], provided a rich source of personally identifiable information (PII), including names, dates of birth, and places of birth, which are critical for our analysis.\nThe dataset used for the experiments was derived from a subset of the Facebook user dump, containing names, dates of birth, places of birth, and other PII. Before experimentation, the data was preprocessed to remove duplicates, handle missing values, and normalize text. Named entities were tagged using Stanford CoreNLP."}, {"title": "Approach", "content": "For each obfuscation technique, we implemented a series of tests to quantify the impact on both data privacy and utility. Privacy was assessed through measures such as information entropy and k-anonymity."}, {"title": "Validation Methodology", "content": "We tested the utility of the obfuscated data by running it through a series of common data analytics tasks, such as summarization, and trend analysis. We then compared the results with those obtained using the original (non-obfuscated) dataset."}, {"title": "Metrics", "content": "Task Performance was measured as F1 score of models trained on obfuscated versus original data. Information Loss quantified as the percentage reduction in model performance after obfuscation."}, {"title": "Results and Analysis", "content": "The data utility experiments revealed that context-sensitive obfuscation resulted in minimal performance degradation (see graphs below). This highlights the effectiveness of context-sensitive techniques in preserving data utility while protecting privacy.\nOur results revealed compelling insights into the effectiveness of each obfuscation technique. Masking, for instance, significantly reduced the readability of PII without compromising the overall structure of the data. Perturbation introduced noise that preserved the distribution of data points, albeit at the cost of increased uncertainty. Differential privacy offered a balance between privacy and utility, though at the expense of some information loss."}, {"title": "Implications", "content": "The implications of our research extend beyond the immediate application of TableGuard. By demonstrating the feasibility of context-sensitive obfuscation, we contribute to the broader discourse on data privacy and security. Our work suggests that organizations can leverage sophisticated obfuscation techniques to share data securely, thereby fostering trust and collaboration among different stakeholders."}, {"title": "Conclusion", "content": "Our experimental evaluations demonstrated the effectiveness of TableGuard in balancing privacy protection with data utility, by minimizing information loss and ensuring that obfuscated data remains functionally useful for downstream applications, TableGuard showcases the importance of domain-specific obfuscation strategies and the critical role of context length in preserving data integrity. These findings underscore the potential of TableGuard as a robust framework for implementing privacy-preserving data sharing mechanisms, offering significant benefits for organizations seeking to share data securely with external parties."}, {"title": "Future Work", "content": "Explore scalability and efficiency of TableGuard in real-world scenarios, including large-scale enterprise databases and cross-border data transfers (We have explored with nearly 1 million rows of data)\nExploring the legal and regulatory implications of using context-sensitive obfuscation techniques\nReducing complexity in complex legal documents\nSecuring medical reports and records (HIPPA compliance)\nSecuring MNPI\nAdded layer of security for documents in transit (in addition to the usual security measures)\nRole & Recipient based de-obfuscation of documents in popular communication channels (like email, Teams Chat etc.,)"}, {"title": "Acronyms", "content": "NER = Named Entity Recognition\nFNOL = First Notice of Loss\nBERT = Bidrectional Encoder Respresentations from Transformers\nHIPPA = Health Insurance Portability and Accountability Act\nMNPI = Material Non Public Information"}]}