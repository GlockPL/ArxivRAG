{"title": "TABLEGUARD - SECURING STRUCTURED & UNSTRUCTURED DATA", "authors": ["Ajinkya Deshmukh", "Anantha Sharma"], "abstract": "With the increasing demand for data sharing across platforms and organizations, ensuring the privacy\nand security of sensitive information has become a critical challenge. This paper introduces \"Table-\nGuard\". An innovative approach to data obfuscation tailored for documents & relational databases.\nBuilding on the principles and techniques developed in prior work [1] on context-sensitive obfusca-\ntion, TableGuard applies these methods to ensure that API calls return only obfuscated data, thereby\nsafeguarding privacy when sharing data with third parties.\nTableGuard leverages advanced context-sensitive obfuscation techniques to replace sensitive data\nelements with contextually appropriate alternatives. By maintaining the documents & relational\nintegrity and coherence of the data, our approach mitigates the risks of cognitive dissonance [2] and\ndata leakage. We demonstrate the implementation of TableGuard using a BERT based transformer\nmodel, which identifies and obfuscates sensitive entities within documents & relational tables.\nOur evaluation shows that TableGuard effectively balances privacy protection with data utility,\nminimizing information loss while ensuring that the obfuscated data remains functionally useful\nfor downstream applications. The results highlight the importance of domain-specific obfuscation\nstrategies and the role of context length in preserving data integrity.\nThe implications of this research are significant for organizations that need to share data securely\nwith external parties. TableGuard offers a robust framework for implementing privacy-preserving\ndata sharing mechanisms, thereby contributing to the broader field of data privacy and security.", "sections": [{"title": "Introduction", "content": "TableGuard aims to mask or replace sensitive information with fictitious but plausible data, thus preventing unautho-\nrized access while retaining the utility of the dataset. However, indiscriminate obfuscation can lead to inconsistencies,\nespecially when related entities are not obfuscated together. For example, replacing \u201cNew York\u201d with \u201cChicago\u201d\nwhile referring to the \u201cEmpire State Building\" can confuse [2] language models, leading to erroneous inferences. Our\nresearch focuses on obfuscating related entities cohesively to avoid such issues.\nTraditional methods of data obfuscation often lead to significant information loss or cognitive dissonance within au-\ntomated systems, such as language models. This paper addresses these challenges by proposing a context-sensitive\nobfuscation approach that maintains document integrity. The paper is structured to detail our methodology, data\npreparation, model testing, and the implications of our findings, providing a comprehensive overview of effective PII\nobfuscation techniques."}, {"title": "Data", "content": "Our study uses names-dataset (a pypi package) [3] which contains 730K first names, 983K last names - extracted from\nthe Facebook massive dump (of 533M users). The composition of sensitive information like first name and last name\ncoupled with dates of birth, and places of birth gives us a unique perspective on which names were popular around\nwhat year, we use this relationship to determine next best token to use in obfuscation.\nThis dataset provides a substantial foundation for testing the robustness and efficacy of our obfuscation techniques.\nEnsuring the ethical use and anonymization of data is paramount."}, {"title": "Methodology", "content": "The initial step in data preparation involved cleaning and preprocessing the dataset to remove any inconsistencies or\nirrelevant information. This process included normalizing the text, removing duplicates, and handling missing values.\nEach entry was then tokenized to facilitate further processing by our transformer model. Special attention was given\nto retaining contextual information to support accurate entity recognition and obfuscation.\nSubsequently, named entity recognition (NER) was performed using Stanford CoreNLP [4], a powerful NLP library,\nto identify entities that required obfuscation. These entities included names, locations, and other PII. The identified\nentities were then marked for replacement with appropriate pseudonyms or fictitious data. The preprocessing phase\nensured that the dataset was ready for the application of our obfuscation model, setting the stage for effective and\ncontext-sensitive obfuscation."}, {"title": "Approach", "content": "Building on the work [5] we use a transformer-based model to identify sensitive entities within documents & relational\ntables. The model is built on BERT [6] trained on a dataset of documents & relational tables, where each table is\nrepresented as a sequence of tokens. The goal is to predict the replacement token for each entity in the table, given its\ncontext (context here is based on the content of the row in question coupled with data dictionary and table metadata).\nMasking:\nMask sensitive data by replacing characters or digits with placeholders. This experiment can assess the effectiveness\nof masking techniques in preventing unauthorized access to sensitive information.\nThese techniques are commonly used in data masking, but they do not take into account the context of the data.\nPerturbation: Introduce noise or perturbations to sensitive data. There is a need to evaluate the impact of perturbation\non data privacy and the ability to recover original data.\nDifferential Privacy: Apply differential privacy mechanisms to the database.\nVarious data engineering tools provide different data masking, differential privacy, and perturbation techniques.\nContextual Obfuscation: Obfuscate data based on contextual information. This experiment can explore the effec-\ntiveness of context-sensitive obfuscation in preserving data integrity and coherence."}, {"title": "Experiments", "content": "Our experimental design aimed to rigorously evaluate the effectiveness of TableGuard's obfuscation techniques, fo-\ncusing on their impact on data privacy and utility. The experiments were meticulously crafted to address key research\nquestions regarding the trade-offs between privacy preservation and data usability while keeping a close eye on runtime\nperformance."}, {"title": "Setup", "content": "The core of our experimental setup revolved around three primary obfuscation techniques: masking, perturbation,\nand differential privacy. Each technique was applied to a subset of the dataset, allowing us to isolate and measure\ntheir individual effects. The dataset, derived from the names-dataset package [3], provided a rich source of personally\nidentifiable information (PII), including names, dates of birth, and places of birth, which are critical for our analysis.\nThe dataset used for the experiments was derived from a subset of the Facebook user dump, containing names, dates\nof birth, places of birth, and other PII. Before experimentation, the data was preprocessed to remove duplicates, handle\nmissing values, and normalize text. Named entities were tagged using Stanford CoreNLP."}, {"title": "Approach", "content": "For each obfuscation technique, we implemented a series of tests to quantify the impact on both data privacy and\nutility. Privacy was assessed through measures such as information entropy and k-anonymity."}, {"title": "Validation Methodology", "content": "We tested the utility of the obfuscated data by running it through a series of common data analytics tasks, such\nas summarization, and trend analysis. We then compared the results with those obtained using the original (non-\nobfuscated) dataset."}, {"title": "Metrics", "content": "Task Performance was measured as F1 score of models trained on obfuscated versus original data. Information Loss\nquantified as the percentage reduction in model performance after obfuscation."}, {"title": "Results and Analysis", "content": "The data utility experiments revealed that context-sensitive obfuscation resulted in minimal performance degradation\n(see graphs below). This highlights the effectiveness of context-sensitive techniques in preserving data utility while\nprotecting privacy.\nOur results revealed compelling insights into the effectiveness of each obfuscation technique. Masking, for instance,\nsignificantly reduced the readability of PII without compromising the overall structure of the data. Perturbation in-\ntroduced noise that preserved the distribution of data points, albeit at the cost of increased uncertainty. Differential\nprivacy offered a balance between privacy and utility, though at the expense of some information loss."}, {"title": "Implications", "content": "The implications of our research extend beyond the immediate application of TableGuard. By demonstrating the\nfeasibility of context-sensitive obfuscation, we contribute to the broader discourse on data privacy and security. Our\nwork suggests that organizations can leverage sophisticated obfuscation techniques to share data securely, thereby\nfostering trust and collaboration among different stakeholders."}, {"title": "Conclusion", "content": "Our experimental evaluations demonstrated the effectiveness of TableGuard in balancing privacy protection with data\nutility, by minimizing information loss and ensuring that obfuscated data remains functionally useful for downstream\napplications, TableGuard showcases the importance of domain-specific obfuscation strategies and the critical role of\ncontext length in preserving data integrity. These findings underscore the potential of TableGuard as a robust frame-\nwork for implementing privacy-preserving data sharing mechanisms, offering significant benefits for organizations\nseeking to share data securely with external parties."}, {"title": "Future Work", "content": "Explore scalability and efficiency of TableGuard in real-world scenarios, including large-scale enterprise databases\nand cross-border data transfers (We have explored with nearly 1 million rows of data)\nExploring the legal and regulatory implications of using context-sensitive obfuscation techniques\nReducing complexity in complex legal documents\nSecuring medical reports and records (HIPPA compliance)\nSecuring MNPI\nAdded layer of security for documents in transit (in addition to the usual security measures)\nRole & Recipient based de-obfuscation of documents in popular communication channels (like email, Teams Chat\netc.,)"}, {"title": "Acronyms", "content": "NER = Named Entity Recognition\nFNOL = First Notice of Loss\nBERT = Bidrectional Encoder Respresentations from Transformers\nHIPPA = Health Insurance Portability and Accountability Act\nMNPI = Material Non Public Information"}]}