{"title": "Mitigating Propensity Bias of Large Language Models for Recommender Systems", "authors": ["GUIXIAN ZHANG", "GUAN YUAN", "DEBO CHENG", "LIN LIU", "JIUYONG LI", "SHICHAO ZHANG"], "abstract": "The rapid development of Large Language Models (LLMs) creates new opportunities for recommender systems, especially by exploiting the side information (e.g., descriptions and analyses of items) generated by these models. However, aligning this side information with collaborative information from historical interactions poses significant challenges. The inherent biases within LLMs can skew recommendations, resulting in distorted and potentially unfair user experiences. On the other hand, propensity bias causes side information to be aligned in such a way that it often tends to represent all inputs in a low-dimensional subspace, leading to a phenomenon known as dimensional collapse, which severely restricts the recommender system's ability to capture user preferences and behaviours. To address these issues, we introduce a novel framework named Counterfactual LLM Recommendation (CLLMR). Specifically, we propose a spectrum-based side information encoder that implicitly embeds structural information from historical interactions into the side information representation, thereby circumventing the risk of dimension collapse. Furthermore, our CLLMR approach explores the causal relationships inherent in LLM-based recommender systems. By leveraging counterfactual inference, we counteract the biases introduced by LLMs. Extensive experiments demonstrate that our CLLMR approach consistently enhances the performance of various recommender models.", "sections": [{"title": "1 Introduction", "content": "Recommender systems are essential tools used on many platforms to help users navigate the vast amount of available information and find items that match their preferences [13, 37, 46]. Due to the information overload problem [16, 56], collaborative filtering-based recommender systems have become widely used. The main research direction in this field focuses on improving the performance of these models by increasing the effectiveness of user and item representations [57]. To achieve this, many models have been proposed to mine useful information to enhance these representations. Graph neural networks play an important role in this endeavor [42, 47]. Recently, graph neural network-based recommender systems modeling user preferences based on historical interactions have achieved promising results [45]. Nevertheless, collaborative filtering models still face the problem of data sparsity [6, 49].\nThis work has been supported in part by the National Natural Science Foundation of China under Grant 71774159, the China Postdoctoral Science Foundation under Grant 2021T140707, the Jiangsu Postdoctoral Science Foundation under grant number 2021K565C, the Science and Technology Foundation of Xuzhou under Grant KC22047, and Australian Research Council under Grant DP230101122."}, {"title": "2 Related Work", "content": "In this section, we discuss the related work, including the research on bias in artificial intelligence and recommender systems with side information."}, {"title": "2.1 Bias in Artificial Intelligence", "content": "With the widespread use of artificial intelligence in real life, bias in artificial intelligence has attracted a great deal of attention [24, 55]. For example, Buolamwini and Gebru [5] showed that business gender classification systems used in various fields such as marketing, entertainment and healthcare have different representations of users' skin colour and gender. Zhang et al. [54] demonstrated that the interaction structure in social networks can also contain preference information. It follows that artificial intelligence systems may display biases against specific groups embedded in the data or even amplify human biases. Natural Language Processing (NLP) systems are susceptible to bias as a result of the training corpus. Bolukbasi et al. [4] and Caliskan et al. [7] first found the presence of human-like preferences in word embedding models. Zhao et al. [61] found a correlation between gender pronouns and stereotypes. De-Arteaga et al. [12]'s study of semantic representation bias can lead to potential harm.\nBias is particularly evident in generative models, where LLMs tends to amplify biases against specific groups. For example, Abid et al. [1] found that LLMs commonly associated Muslims with violence. Lucy and Bamman [26] found that female roles tended to be associated with family and emotions, and male roles tended to be associated with politics, sports, and crime. Lee et al. [23] found that ChatGPT also portrays women as more homogeneous than men. Psychologically, people tend to perceive their out-group members as more homogeneous than their in-group members, and LLMs inevitably outputs homogeneous representations of the same group [23]. Cheng et al. [11] found that LLMs tends to essentialise the characters of marginalised groups and produce positive and homogeneous narratives. In this paper, we collectively refer to these bias as LLMs' propensity bias, as there are not only human attributes in the recommendation scene, but also factors such as region and culture."}, {"title": "2.2 Recommender Systems with Side Information", "content": "The fundamental concept of recommender systems is to leverage user-item interactions and associated side information to compute matching scores between users and items [13, 59]. More specifically, various recommender models are designed based on collaborative behavior between users and items, which are then used to learn user and item representations [27]. Collaborative information modeling plays a crucial role in personalised recommendation [30], and deep neural networks have been widely adopted to advance recommender systems due to their superior representation learning capabilities across various domains [57]. Considering users' online behavior as graph-structured data, graph neural networks have been applied to recommender systems as an advanced representation learning technique for capturing user and item representations [45]. At the same time, researchers have focused on enhancing recommender system effectiveness by addressing factors like popularity bias [6, 49] and exposure bias [36] in historical data.\nDespite the significant success of these approaches, ID-based methods still have inherent limitations. The reason is that pure ID indexes of users and items are naturally discrete and lack the semantic information needed to effectively capture user and item representations, especially in cases of sparse user-item interactions [52]. In recent years, the impressive natural language processing capabilities of LLMs have inspired researchers to explore their application in recommendation tasks. Early implementations utilised language models as feature extractors to create knowledge-aware recommendation embeddings [43], providing valuable insights into user preferences."}, {"title": "3 Preliminary", "content": "In this section, we present our problem setting and introduce the basic concepts of graphical causal models, along with key definitions in causal inference."}, {"title": "3.1 Problem Setting", "content": "With an existing recommendation method R, we can obtain the user collaborative representation \u00eau and item collaborative representation \u00ea\u00a1 based on the historical interactions between the user U and the item I, and then compute the probability that U and I will interact with each other in the future. Concurrently, we leverage an LLM to generate user side information Pu and item side information Pi, which are then projecting into the feature space via a text embedding model T. An encoder is subsequently utilised to learn the user side representation \u015du and item side representation \u015di. Finally, these side representations \u015du and \u015di are aligned with the collaborative representations \u00eau and \u00eai through contrastive learning, enhancing the overall recommendation performance of the model. However, LLM produces side information often with propensity bias, which has an impact on recommender systems. The aim of this paper is to improve the effectiveness of LLM for recommender systems by mitigating the propensity bias. A summary of the notations used in this paper is shown in Table 1."}, {"title": "3.2 Graphical Causal Model", "content": null}, {"title": "3.3 Causal Effect and Counterfactual Inference", "content": "The causal effect of the treatment, e.g. X on the outcome, e.g. Y is defined as the difference between two counterfactual outcomes that would be observed if an individual were exposed to different levels of the exposure of interest [10, 17, 18, 48]. In formal terms, if we denote the outcome as Y, and the exposure values of interest as x and x*, the causal effect for an individual j is Yj (x) \u2013 Yj (x*), where Y;(x) is the counterfactual outcome for individual j under exposure level x, and Y;(x*) is the counterfactual outcome under exposure level x*.\nThe total effect (TE) [28, 32] is the overall change in the outcome that would be observed if an individual's exposure level were changed x, taking into account causal paths from the treatment to the outcome, including both direct path and indirect paths via mediators. Mathematically, it is represented as:\nTE = Yj(x, Mj(x)) \u2013 Yj(x*, Mj(x*)) \t\t(1)\nwhere Yj (x, Mj (x)) is the counterfactual outcome for individual j under exposure level x and the mediator level that would be observed under the same exposure level, and Yj(x*, Mj(x*)) is the counterfactual outcome under exposure level x* and the mediator level that would be observed under exposure level x*.\nThe Total Effect is crucial as it provides a complete picture of the impact of an exposure on an outcome, incorporating both the direct effects and the indirect effects mediated through a mediator. The counterfactual results in the mediator model depend not only on the exposure value but also on the mediator value. Counterfactual inference involves"}, {"title": "4 The Proposed CLLMR Framework", "content": "We provide an overview of our CLLMR framework in Figure. 4. The CLLMR framework is divided into two stages: training and inference. In the training stage, we focus on real-world causality and account for the influence of propensity bias on the model. Specifically, we first use an LLM to construct side information for both users and items, then propose SSE to introduce structural information into the representation of this side information. Finally, we align the side information with collaborative information affected by propensity bias. In the inference stage, we perform model inference based on causal relationships in the counterfactual world, thereby mitigating propensity bias. In this section, we describe each component of the framework in detail."}, {"title": "4.1 Constructing Side Information", "content": "Previous research has demonstrated the importance of side information [31, 42, 59], also known as descriptions of users and items, for collaborative filtering recommender systems to perform effective representation learning. Specifically, user and item edge information that effectively characterises preferences and attractiveness is crucial for modeling latent relationships between users and items.\nIn this work, we utilise an LLM to infer about collaborative signals and generate useful side information, following [31]. Items often have more freely available descriptive information compared to privacy-sensitive user profiles. Thus, our method first applies a uniform prompt to a pretrained LLM to produce an initial description summarizing each item based on its profile data. These item descriptions are then used to infer side information for both users and items via collaborative reasoning. Specifically, the LLM analyzes the descriptions of all items with which a given user has interacted with to formulate a description Pu characterizing that user's preferences. Similarly, the LLM analyses which types of users interacted with a given item to formulate a description Pi characterizing the item's attractiveness to different audiences."}, {"title": "4.2 Spectrum-based Side Information Encoder", "content": "When dealing with LLMs, side information often lacks structural information of historical interactions and may be affected by biases inherent in the corpus. These biases can lead to propensity bias [12, 51, 60], which in turn trigger dimensional collapse during the alignment of side information with the collaborative information of the recommendation algorithm. To address this issue, we propose a Spectrum-based Side information Encoder (SSE) to reduce the text embedding of side information into a low-dimensional representation. Our SSE method leverages the identifiable variational autoencoder (iVAE) [21] to enhance the identifiability of side information and implicitly introduce structural information from historical interactions.\nThe set of parameters for SSE is defined as 0 = (f, T, \u03bb). In SSE, we introduce a conditional prior distribution P\u03c4.\u03bb (\u0396 | m), where Z denotes the latent variables and m represents additional observed variables. In our SSE framework, we use the spectrum of the historical interaction information. We have added a small noise to the spectrum to avoid over-fitting during the learning process as follows:\nM = M + \u0394, \u0394 = w sign(\u043c),\t\t(5)\nwhere w \u2208 Rd ~ U(0, 1) and m is the original spectrum, thus ensuring that m and A have the same tendency."}, {"title": "4.3 Counterfactual Debiased Recommendation", "content": "In this work, we consider addressing the propensity bias from the influence of LLMs. In order to analyse the causality of the LLM-based recommender system, we build the causal graph as shown in Figure. 5 (a) to model the problem. The causal graph explains the causes of propensity bias in LLM-based recommender system. The nodes in the causal graph G are explained as follows:\n\u2022 U represents user collaborative representation.\n\u2022 I represents the item collaborative representation.\n\u2022 C represents the choice of user and item matching.\n\u2022 T represents the item side representation of the LLM to the recommender system.\n\u2022 S represents the user side representation of the LLM to the recommender system.\n\u2022 P represents the item propensity bias.\n\u2022 O represents the user propensity bias.\nThe relationships between nodes in the causal graph G are represented by edges, which are defined as follows:\n\u2022 U \u2192 C and I \u2192 C denote that both the user and the item collaborative representation have direct edges with C. This indicates that the user makes a choice of C when the user's preference U matches the attribute I of the exposed item.\nTP and S \u2192 O indicate that the side information generated by the LLM is embedded with the LLM's own propensities.\n\u2022 T\u2192 I and S\u2192 U indicate that the usage of side information to improve recommendation performance.\n\u2022 P \u2192 I and S\u2192 U denote that the LLM's propensity bias affects recommendation results.\nUnder the designed causal DAG, the problem of addressing the propensity bias of LLM becomes how to estimate the indirect effect of O and P on U and I. Following the causal effect introduced in Section 3.3, we first construct the counterfactual-world causal graph shown in Figure 5 (b). Gray nodes represent reference states, and half-shaded nodes represent that they are influenced by the reference state. The total effect (TE) of individual j (j may be a user or a item) can be calculated as:\nTE(Uj) = Uj (s, Oj (s)) \u2013 Uj (s*, Oj (s*)),\t\t(11)\nTE(Ij) = Ij(t, Pj(t)) \u2013 Ij(t*, Pj(t*)).\t\t(12)"}, {"title": "4.4 Training and Inference", "content": "With an existing collaborative filtering recommendation method R, we can obtain a user collaborative representation \u00eau and an item collaborative representation \u00ea\u00a1. However, our aim during training is to match the model predictions to the distribution of the training set, not to make recommendations for users. Therefore we use different approaches to estimate user-item interaction probabilities in the training and inference phases. Specifically, since the training set is created from a causal graph in the factual world as shown in Figure 5 (a), where all causal effects are not moderated, we need to take into account the effect of propensity bias on the collaborative information when estimating predictions:\neu = \u03c3 (fp (Su)) * \u00eau,\t\t(17)\nei = \u03c3 (fp (Si)) * \u00eai,\t\t(18)\nwhere fp is the estimated model for the propensity bias and o is the sigmoid function.\nWe align the collaborative information with the side information to capture the information from user and item, which is then fed into the traditional recommendation method. The loss during the alignment process is as follows:\nLa = -Elog(f (eu, Su) / \u03a3uem f (eu, Su)) - Elog(f (ei, si) / \u03a3\u03af\u03b5\u03b9 f (ei, Si))\t\t(19)\nwhere f(a, b) = exp(sim(a, b)), and sim() represents the cosine similarity.\nSubsequently, we can calculate the interaction probability y\u00fbi and compute the loss of the recommendation method as follows:\nLR = \u2211_(u,it,i)\u2208O - Ino (Yu,i+ \u2013 Yu,i-),\t\t(20)\nwhere O = {(u, i\u207a, i\u00af) | (u, i\u207a) \u2208 R, (u, i\u00af) \u2208 R\u00af} denotes the training set, and (u, i\u207a, i\u00af) is a training sample. Here, R is the set of observed user-item interactions, and it is a positive sample that user u has interacted with.\nIn the inference stage, instead of relying on predictions in the factual world, we use Equation. 15 and Equation. 16 to mitigate the PNDE to obtain counterfactual world predictions:\n\u0115u = eu \u03b1* \u03c3 (fp (Su)),\t\t(21)"}, {"title": "5 Experimental evaluation", "content": "In this section, we presents the experimental evaluations of the performance of our proposed CLLMR using multiple datasets to address the following research questions (RQ):\n\u2022 RQ1: Does our proposed CLLMR improve existing state-of-the-art recommendation methods in various experimental settings?\n\u2022 RQ2: Does SSE mitigate dimensional collapse?\n\u2022 RQ3: Does the SSE approach and counterfactual framework of CLLMR contribute to improved recommendation performance?\n\u2022 RQ4: How does each module in SSE function?\n\u2022 RQ5: How does the spectrum of different ranks affect the model's performance?"}, {"title": "5.1 Experiment Settings", "content": "In this section, we describe the experimental setting, including the dataset, evaluation metrics, implementation details, and comparison algorithms."}, {"title": "5.1.1 Datasets.", "content": "As shown in Table 2, three commonly used public datasets are used in our evaluation. The Amazon dataset [15] includes user ratings and reviews related to books sold on the Amazon platform. The Yelp dataset [38] collects a large amount of textual data related to various businesses. Additionlly, the Steam dataset [31] contains textual feedback from users about games on the Steam platform. In the Amazon and Yelp datasets, we used a similar data pre-processing approach as in previous studies [31, 50], excluding interactions with ratings below 3. We then divided each dataset into training, validation, and testing subsets and maintained a 3:1:1 ratio.\nRegarding the side information of the datasets, we followed a methodology consistent with previous studies [31] by synthesizing comprehensive profiles of users and items using the ChatGPT-3.5-turbo model. The specific instructions are shown in Table 3. All side information was divided into two parts, 'summarisation' and 'reasoning', and the LLM responses were limited to 200 words."}, {"title": "5.1.2 Evaluation Metrics.", "content": "To ensure a thorough and comprehensive evaluation of our proposed CLLMR method, we employed a ranking scheme across all experiments, consistent with methodologies from previous studies [16, 31]. We selected two well-established ranking-based metrics to quantify the effectiveness of our approach: Recall@N and NDCG@N. By using these metrics, we aim to demonstrate the ability of our method to deliver high-quality results that align with user expectations and preferences."}, {"title": "5.1.3 Implementation Details.", "content": "In our experiments, we standardised the dimensionality of the representations for all models to 32, ensuring a consistent basis for comparison. To optimise each model's performance, we meticulously tuned"}, {"title": "5.1.4 Baselines.", "content": "In this paper, we use six state-of-the-art collaborative filtering recommendation methods as backbone, while comparing two of the state-of-the-art LLM-based recommender systems.\nRecommendation methods.\n\u2022 LRGCCF [8]: This approach reevaluates the role of nonlinear operations in graph neural networks for recommendations and mitigates oversmoothing through residual connections.\n\u2022 LightGCN [16]: It introduces a streamlined approach to recommender systems by simplifying the neural architecture in graph message passing, resulting in a more efficient model that retains high performance."}, {"title": "5.2 Performance Comparison", "content": "To address RQ1, we integrated CLLMR into six state-of-the-art collaborative filtering models. The experimental results, averaged over five random initialisations, are presented in Table 4. These results reveal several noteworthy observations, which we summarise as follows:\n\u2022 Overall, we consistently observe that integrating the side information generated by the LLM with the backbone recommender improves performance compared to the original versions. The LLM demonstrates strong emergence and generalizsation capabilities, storing extensive general world knowledge alongside linguistic understanding and expressive abilities. By generating side information for items enriched with real-world knowledge, the LLM provides not only basic item details but also deeper meanings and cultural context. This richer representation enhances the system's ability to interpret textual information, improving personalisation and recommendation accuracy by offering a more comprehensive view of the user.\n\u2022 For backbone methods based on contrastive learning, aligning the side information from the LLM with collaborative information through contrastive learning can improve the effectiveness. Contrastive learning aligns the side representation with the collaborative representation while preserving the relationships between sample pairs. Unlike reconstruction, which attempts to recover the original inputs without directly optimizing the distinction between positive and negative pairs, contrastive learning integrates both representations by maintaining their original pre-training objectives. This avoids the risk of losing key relationships, as contrastive learning retains the relative distances and structures between representations, resulting in better alignment.\n\u2022 CLLMR employs a spectrum-based side information encoder that deeply explores the intrinsic structure of historical user interaction data, constructing a rich and discriminative feature space. This encoding mechanism ensures feature diversity and significantly enhances the model's ability to distinguish between varying user preferences, effectively preventing feature collapse, where model outputs converge to a single solution. Additionally, CLLMR incorporates a counterfactual inference strategy to fine-tune the inherent bias in the LLM. By simulating decision-making in what-if scenarios, the model gains deeper insight into the user's true"}, {"title": "5.3 Ablation Study", "content": "In this section, we construct ablation experiments to answer RQ2, RQ3, and RQ4."}, {"title": "5.3.1 Necessity of each module of CLLMR.", "content": "To answer RQ2, we utilise MLP instead of SSE and perform a singular value decomposition of the user/item side representations. The singular value case resulting from MLP and SSE is shown in Figure. 6, Figure. 7, and Figure. 8. From the results we have the following conclusions:\n\u2022 SSE effectively avoids feature collapse relative to MLP. A healthy feature representation has multiple higher singular values, indicating that the features are distributed across multiple dimensions rather than being concentrated in just a few. SSE does not form a low-rank embedding matrix, meaning that the singular values of the matrix do not decay rapidly, thus maintaining the utilization of high-dimensional space. By introducing the spectrum as an observed variable under a condition, SSE achieves representational identifiability and disentanglement through reparameterization, allowing each dimension to capture an independent element of the data as much as possible, which helps prevent dimensional collapse.\n\u2022 LRGCCF mitigates the over-smoothing problem through residual linking, where the representation consists of multiple representations spliced together, resulting in higher dimensionality while making the singularities"}, {"title": "5.3.2 Necessity of each module of SSE.", "content": "To answer RQ4, we successively removed the noise sign (\"w/o sign\") and random noise (\"w/o noise\") to assess their necessity. The experimental results are displayed in Figure 9. It can be"}, {"title": "5.4 Hyperparameter Analysis", "content": "In this section, we conduct a hyperparameter analysis for the rank of the spectrum in SSE to answer RQ5, with the experimental results shown in Figure 10. We set the rank to 16, 32, and 64, respectively, and it is important to note that"}, {"title": "6 Conclusion", "content": "In this paper, we have proposed CLLMR, a counterfactual inference framework designed to effectively eliminate the inherent propensity bias of LLMs and enhance recommendation accuracy. To address the issue of dimensional collapse, we have also introduced a spectrum-based encoder that extracts the side information generated by LLMs. This is crucial because when dimensional collapse occurs, counterfactual inference becomes ineffective, as the model is unable to distinguish subtle differences between features. This validates the necessity of each module within the CLLMR framework. Additionally, we have incorporated contrastive learning as an alignment technique to synchronize collaborative representations, based on historical interactions, with LLM-derived side representations. This approach effectively combines the strengths of traditional recommendation methods with LLM capabilities and has been rigorously evaluated on three real-world datasets. Experiments have demonstrated that CLLMR effectively mitigates propensity bias, avoids dimensional collapse and achieves the state-of-the-art results."}]}