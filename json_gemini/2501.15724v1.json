{"title": "A Survey on Computational Pathology Foundation Models: Datasets, Adaptation Strategies, and Evaluation Tasks", "authors": ["Dong Li", "Guihong Wan", "Xintao Wu", "Xinyu Wu", "Ajit J. Nirmal", "Christine G. Lian", "Peter K. Sorger", "Yevgeniy R. Semenov", "Chen Zhao"], "abstract": "Computational pathology foundation models (CPathFMs) have emerged as a powerful approach for analyzing histopathological data, leveraging self-supervised learning to extract robust feature representations from unlabeled whole-slide images. These models, categorized into uni-modal and multi-modal frameworks, have demonstrated promise in automating complex pathology tasks such as segmentation, classification, and biomarker discovery. However, the development of CPathFMs presents significant challenges, such as limited data accessibility, high variability across datasets, the necessity for domain-specific adaptation, and the lack of standardized evaluation benchmarks. This survey provides a comprehensive review of CPathFMs in computational pathology, focusing on datasets, adaptation strategies, and evaluation tasks. We analyze key techniques, such as contrastive learning and multi-modal integration, and highlight existing gaps in current research. Finally, we explore future directions from four perspectives for advancing CPathFMs. This survey serves as a valuable resource for researchers, clinicians, and AI practitioners, guiding the advancement of CPathFMs toward robust and clinically applicable AI-driven pathology solutions.", "sections": [{"title": "1 Introduction", "content": "Histopathology with hematoxylin and eosin (H&E) staining plays a fundamental role in disease diagnosis, prognosis, and treatment planning, particularly in oncology, where microscopic examination of tissue samples is critical for detecting pathological abnormalities. Traditionally, histopathological analysis relies on pathologists, who manually examine whole-slide images (WSIs) to identify disease patterns. However, this process is time-consuming, labor-intensive, and subject to inter-observer variability. With the increasing availability of digital pathology WSIs, deep learning-based computational pathology (CPath) models have emerged as a promising approach to enhancing diagnostic accuracy, reducing workload, and enabling large-scale pathology analysis. These models leverage convolutional neural networks (CNNs) and vision transformers (ViTs) to automate complex pathology tasks, such as tumor classification, biomarker discovery, and prognosis prediction.\nIn recent years, foundation models (FMs) have gained significant attention in CPath [Ochi et al., 2024]. Unlike traditional deep learning models that require large-scale, manually labeled datasets for each specific task, computational pathology foundation models (CPathFMs) leverage self-supervised learning (SSL) to learn rich feature representations from unlabeled histopathological images. These models can be fine-tuned for various downstream pathology tasks using transfer learning, few-shot learning, or zero-shot learning, reducing the dependency on extensive expert manual annotations. Uni-modal CPathFMs are trained exclusively on histopathological images, capturing domain-specific features, while multi-modal CPathFMs, which integrate histopathological images with clinical linguistic data, further enhance AI-driven pathology by leveraging complementary information sources. Despite their success, effectively pre-training CPathFMs remains challenging due to data limitations, adaptation difficulties, and evaluation inconsistencies.\nThe development of CPathFMs presents several key challenges. (1) Data challenges arise due to the high inter-institutional variability in histopathological images, including tissue sample preparation, differences in staining techniques, and scanning resolutions. Labeled pathology datasets are often scarce and expensive to annotate, requiring expert pathologists for precise region-based annotations. Additionally, multi-modal data integration (e.g., combining WSIs with clinical text) remains complex due to challenges in alignment and feature fusion. (2) Adaptation challenges stem from the fact that, unlike natural image foundation models (e.g., CLIP [Radford et al., 2021] and DINO [Caron et al., 2021]), CPathFMs require domain-specific fine-tuning to ensure robust generalization across different datasets. (3) Evaluation challenges further complicate CPathFM development, as the lack of standardized benchmarks and the diversity of evaluation tasks (e.g., classification, retrieval, generation, segmentation) make it difficult to assess model performance consistently across datasets and tasks.\nWhile several survey papers have focused on CPathFMs, some of them emphasize benchmarking rather than a comprehensive investigation of existing methods [Campanella et al., 2024a; Lee et al., 2024; Neidlinger et al., 2024]. They cover too few approaches and lack a summary of pre-training datasets and evaluation tasks. Although Neidlinger et al., included a wide range of CPathFMs and pre-training datasets, their summarization of methods and datasets remains insufficiently detailed. Ochi et al., [2024] and Chanda et al., [2024] conducted surveys on a large number of CPathFMs, their pre-training datasets, and evaluation tasks. However, the methods mentioned by the former are relatively few and not up-to-date, while the latter did not provide a detailed introduction on how these methods are adapted to the pathology domain or distinguish between the different adaptations. Although both provided summaries of evaluation tasks, the latter only listed the tasks without offering a systematic taxonomy, whereas the former's summary of the tasks was not comprehensive enough.\nIn this survey, we address these gaps by providing a comprehensive review of CPathFMs, with a focus on datasets, adaptation strategies, and evaluation tasks. Our main contributions include:\n\u2022 Providing an in-depth analysis of existing pathology datasets and data curation used for pre-training CPathFMs, identifying key challenges in generalization.\n\u2022 Systematically reviewing adaptation techniques in pre-training CPathFMs, covering both uni-modal (image-based) and multi-modal (image and text) approaches, and highlighting their respective advantages and limitations.\n\u2022 For the first time, thoroughly summarizing evaluation tasks, categorizing them into six main perspectives for assessing pre-trained CPathFMs.\n\u2022 Identifying key future research directions, offering insights into the challenges and opportunities for advancing CPathFM development.\nBy synthesizing recent advancements and identifying open research challenges, this survey serves as a valuable resource for researchers, practitioners, and clinicians working at the intersection of CPath, medical AI, and foundation models."}, {"title": "2 Background", "content": ""}, {"title": "2.1 Computational Pathology (CPath)", "content": "CPath is an interdisciplinary field that combines artificial intelligence, machine learning, and computer vision with digital pathology to enhance diagnosis, prognosis, and treatment planning. By leveraging whole-slide imaging and deep learning, CPath facilitates scalable and automated analysis of histopathological data, reducing reliance on manual examination by pathologists and improving diagnostic consistency.\nWhole-slide imaging refers to the digital scanning of entire histopathology slides at high resolution, producing gigapixel WSIs that capture intricate tissue structures and morphologies. Due to their large size\u00b9, WSIs are typically divided into smaller tile images, which serve as fundamental units for computational analysis. These tiles can be further annotated with tile captions, providing textual descriptions of specific tissue regions, while WSI reports summarize patient-level pathology interpretations (e.g., tumor type and grade)."}, {"title": "2.2 Self-Supervised Contrastive Learning", "content": "Self-supervised contrastive learning has become a key approach in pre-training CPathFMs, allowing models to learn rich representations from unlabeled histopathological images. These frameworks often (1) maximize the similarity between different augmented views of the same image and (2) minimize similarities between distinct images to train feature extractors. Several prominent methods have been adapted for CPathFM pre-training, mainly including DINO [Caron et al., 2021], DINOv2 [Oquab et al., 2023], CLIP [Radford et al., 2021], and CoCa [Yu et al., 2022].\nThe global modeling capability and scalability of ViT have driven recent research to focus on integrating ViT into SSL frameworks [Caron et al., 2021]. To address the instability during ViT training, DINO, which follows a student-teacher paradigm, performs self-distillation in a self-supervised manner. Specifically, it matches the output of the student network with the output of the teacher network after centering (an operation similar to batch normalization) and updates the teacher network using exponential moving average (EMA) [He et al., 2020]. DINOv2 enhances DINO by integrating iBOT [Zhou et al., 2021], which employs Masked Image Modeling (MIM) as introduced by Masked Autoencoders (MAE) [He et al., 2022]. MIM works by randomly masking certain regions of an image and reconstructing the masked areas, enabling the model to learn valuable representations. DINOV2 effectively captures fine-grained cellular structures within broader tissue contexts, thereby improving generalization across diverse pathology datasets.\nBeyond vision-only learning, multi-modal contrastive frameworks such as CLIP integrate image and text encoders, enabling zero-shot classification and cross-modal retrieval. CLIP enhances model interpretability for pathology AI by leveraging paired histopathological images and textual descriptions (e.g., pathology reports and expert annotations). CoCa extends CLIP by incorporating a multi-modal decoder that generates language signals from visual signals, combining contrastive learning with image captioning and report synthesis. This dual-tower architecture improves diagnostic reasoning in CPath by enabling both retrieval-based and generative tasks."}, {"title": "2.3 Challenges in Pre-training CPathFMS", "content": "While self-supervised contrastive learning frameworks have significantly advanced the development of CPathFMs, pre-training these models remains challenging due to issues in data availability, adaptation strategies, and evaluation complexities that are closely tied to the entire pre-training process.\nAs shown in Figure 2, pre-training CPathFMs involves three key steps: first, preparing the pre-training dataset through data curation; second, training within an adapted SSL framework; and finally, evaluating the model on a series of downstream tasks. Addressing limitations during pre-training is crucial to improving the generalizability and clinical applicability of CPathFMs.\nOne of the primary challenges in pre-training CPathFMs is data availability. Histopathology datasets are often stored within institutional repositories or hospital databases, requiring ethical approvals and access permissions, which significantly limits the availability of large, diverse datasets. Publicly available datasets are scarce and frequently originate from a single institution, reducing data diversity. Additionally, WSIs are gigapixel-scale images, often reaching several gigabytes per file, which creates significant storage and computational burdens. Handling such large-scale data efficiently requires advanced data management, compression, and distributed storage solutions. Annotation is another major obstacle, as pathology image labeling requires expert knowledge, often involving multiple pathologists to ensure accuracy. This process is time-consuming and costly, leading to a shortage of well-annotated datasets. Furthermore, pathology data exhibit substantial variability in staining protocols, magnification levels, and organ-specific structures, introducing domain shifts that complicate model generalization. Data imbalance further exacerbates these issues, as rare disease types account for only a small fraction of available data, causing models to overfit common diseases while performing poorly on under-represented conditions.\nBeyond data-related issues, adapting pre-trained models to diverse pathology tasks presents additional challenges. Un-"}, {"title": "3 Pre-training Datasets in CPathFMs", "content": "Although early CPathFMs used relatively small and homogeneous pre-training datasets, recent studies have shown that higher quality, larger scale, and more diverse pathology pre-training datasets are more beneficial for adapting the foundation models trained on natural image datasets or existing SSL frameworks to the pathology domain [Zimmermann et al., 2024]. Therefore, summarizing the datasets used for pre-training CPathFMs can provide valuable insights for future research on CPathFMs. \nMost CPathFMs utilize multiple data sources to construct larger and more diverse pathology pre-training datasets. Aside from inaccessible private data, existing methods often acquire WSIs from large-scale public pathology datasets such as The Cancer Genome Atlas (TCGA) [Weinstein et al., 2013], The Genotype-Tissue Expression (GTEx) Consortium [Consortium et al., 2015], and the Pathology AI Platform (PAIP) [Kim et al., 2021], as well as tile-caption pairs from the PubMed Central Open Access Dataset (PMC OA) [Lu et al., 2024a]. The diversity of data sources imposes higher requirements on data curation. Although the processes vary across methods, some steps are similar. As shown in Figure 2, images are typically subject to detection and segmentation of subfigures; resizing and cropping to meet model require-\nlike natural image datasets, which are often well-curated and standardized, pathology images exhibit significant inter-institutional variability, requiring pre-training strategies that can effectively capture and generalize across this diversity. This demand for higher generalization ability makes it difficult to develop CPathFMs that perform robustly across different patient populations and imaging conditions. Another key limitation is the difficulty of processing gigapixel-scale WSIs, which are too large for traditional deep learning architectures to handle directly. Many current approaches rely on tile-based learning, where WSIs are broken into smaller patches, but this often leads to context fragmentation, making it difficult for models to retain spatial relationships within the tissue. Efficient multi-scale learning techniques are needed to bridge this gap.\nEvaluation presents a significant challenge in pre-training CPathFMs. The wide range of downstream pathology tasks, including classification, retrieval, segmentation, survival prediction, and so on, complicates performance assessment, making it difficult to compare CPathFMs across different institutions and tasks. The heterogeneity in evaluation methodologies further hinders the establishment of a universal benchmarking framework, limiting the ability to systematically assess and compare model performance."}, {"title": "4 Adaptation Strategies in CPathFMs", "content": "SSL has been widely applied in the development of CPathFMs to address the lack of labels. These models typically adapt SSL frameworks that have proven successful in natural images and perform pre-training on carefully curated pathology datasets. Depending on the type of pathology data they used, these approaches can be categorized into uni-modal and multi-modal methods,"}, {"title": "4.1 Uni-Modal CPathFMs", "content": "Uni-modal CPathFMs are generally trained on large, domain-specific pathology datasets using self-supervised contrastive learning frameworks to learn robust representations of pathological images without labeled data. Similar to the development of contrastive learning in natural images, CPathFMs were initially proposed within the MoCo and SimCLR frameworks. Following a transition through the DINO, DINOv2 was established as the leading framework, serving as the foundation for numerous subsequent studies.\nDINO-based CPathFMs. As a successful application of SSL on ViT, DINO has been adopted as a framework for training CPathFMs. Campanella et al., [2024b] compared the performance of DINO and masked autoencoders (MAE) [He et al., 2022] on different scales of pathology datasets, ultimately demonstrating the superiority of DINO for pre-training CPathFMs. Kang et al., [2023] focused on domain-aligned pre-training and proposed data augmentation and cu-\nration strategies specifically for pathological images.\nDINOv2-based CPathFMs. Most studies using the DINOv2 framework, such as UNI [Chen et al., 2024], mainly focus on larger ViT models and more extensive and diverse pre-training datasets. Among them, RudolfV [Dippel et al., 2024] incorporates the domain knowledge of pathologists in dataset construction. Some methods have adopted pathology-adapted training methods within the DINOv2 framework, such as Aben et al., [2024] who developed the Online Patching method during the pre-training process, allowing for the online high-throughput extraction of patches of arbitrary size and resolution. Additionally, Virchow2 [Zimmermann et al., 2024] replaces the original entropy estimator in DINOv2 with the kernel density estimator (KDE). Unlike previous methods, GigaPath focuses on learning the representation of whole-slide images. It first uses the tile-level encoder, trained under the DINOv2 framework, to learn the representation of a sequence of tiles obtained by dividing the whole slide, treating them as visual tokens. These tokens are then fed into LongNet [Ding et al., 2023], which utilizes its Dilated Attention mechanism to perform sparse attention computation, thereby obtaining the overall slide representation.\nOther Uni-Modal CPathFMs. While the majority of uni-modal methods focus on DINO and DINOv2, some methods employ other SSL frameworks. CTransPath [Wang et al., 2022] adds a branch to MoCov3 to generate queries that retrieve semantically similar samples from the memory bank as positive samples, thus guiding the network's training with a semantically relevant contrastive loss. REMEDIS [Azizi et al., 2023] transfers a ResNet model, pre-trained on large-scale natural images, to the SimCLR framework for self-supervised training on pathological images. Additionally, Filiot et al., [2023] directly train a ViT within the iBOT framework using pathology data."}, {"title": "4.2 Multi-Modal CPathFMs", "content": "Multi-modal CPathFMs enhance the model's understanding of pathological images by aligning paired image-text data under the visual-language multi-modal SSL frameworks, such as CLIP and CoCa. These methods typically train pre-trained uni-modal modules using uni-modal SSL frameworks before performing joint visual-language pre-training, which has been shown to improve the performance of downstream tasks [Lu et al., 2023]. Moreover, multi-modality provides an extra perspective for CPathFMs, where pathological visual representations aligned with additional language signals in latent space can assist large language models (LLMs) in understanding pathology knowledge, thereby contributing to the construction of generative foundation AI assistants for pathologists [Lu et al., 2024b].\nCLIP-based CPathFMs. The success of CLIP on natural images has inspired some works to apply it in the pathology domain. PLIP [Huang et al., 2023] and PathCLIP [Sun et al., 2024] both fine-tune a pre-trained CLIP model using datasets composed of paired tiles and their captions. PathAsst [Sun et al., 2024] leverages PathCLIP as the visual component to build a pathological multi-modal large language model (MLLM). It first trains a fully connected layer between the visual component and the LLM using instructions constructed from question-answer pairs to align the image encoder with the LLM. Then, the LLM is fine-tuned with a small number of instructions. CHIEF [Wang et al., 2024] uses an image encoder from CTransPath to encode the tile sequence extracted from WSIs to obtain WSI-level features and encodes anatomical site information as textual features using the original CLIP's text encoder. The two are combined to obtain rich WSI-level multi-modal representations.\nCoCa-based CPathFMs. The multi-modal decoder specifically designed for CoCa enhances the cross-modal capability of CPathFM, which has led to its application in up-to-date CPathFMs. CONCH [Lu et al., 2024a] and PRISM [Shaikovski et al., 2024] both pre-train an image encoder on pathology datasets using the iBOT and DINOv2 frameworks, respectively, and then further conduct joint visual-language pre-training within the CoCa framework. The difference is that PRISM extends the image encoder to the WSI-level using a Perceiver network [Jaegle et al., 2021] and employs WSIs along with their corresponding clinical reports for training. Additionally, PathChat [Lu et al., 2024b] is a pathology-focused MLLM, which uses UNI as the image encoder and further adopts a method similar to CONCH for vision-language pre-training. The trained image encoder is then connected to Llama 2 [Touvron et al., 2023] and fine-tuned using various instructions.\nBuilding upon prior work, TITAN [Ding et al., 2024] develops a multi-modal whole-slide foundation model primarily designed for training a slide encoder. Its pre-training process is divided into three stages. First, a slide encoder is trained using region crops under the iBOT framework with positional encoding incorporated. Subsequently, under the CoCa framework, the slide encoder is trained at both the tile-level and WSI-level, facilitating the gradual development of the model's ability to comprehend and generate meaningful vision-language representations for WSIs."}, {"title": "5 Evaluation Tasks", "content": "CPathFMs do not target a specific task during the pre-training phase. Instead, a wide range of evaluation tasks are employed after pre-training to assess the model's ability to extract features from pathology data. These tasks are diverse, and the evaluation tasks for each CPathFM are not standardized, making it challenging to establish a unified benchmark for CPathFMs. Therefore, we provide a summary of the evaluation tasks along with the CPathFMs performing them. We first categorized the evaluation tasks into six major types based on their application objectives, followed by a further subdivision according to their specific objectives (e.g., focusing on tile-level or WSI-level). On this basis, we also considered variations in task settings (e.g., supervised or zero-shot learning). Finally, we summarized which CPathFMs were used to evaluate each type of task.\nA series of complex pathology tasks, such as cancer subtyping, biomarker detection, and mutation prediction, are essentially classification problems. As the most commonly used evaluation task, classification has been widely studied in both tile-level and WSI-level under supervised, few-shot, and zero-shot settings. Unlike fully supervised learn-\ning, few-shot and zero-shot learning aim to perform on evaluation tasks when the pre-trained model has seen only a small portion or none of the training samples. Classification tasks at the WSI-level are typically weakly supervised, meaning that such tasks only have global annotations (WSI-level) without details of internal regions. If a CPathFM ultimately extracts tile-level features, a WSI-level representation through an aggregator network needs to be obtained when applying this task. In addition to the three common settings mentioned above, some CPathFMs have also evaluated the model's out-of-distribution generalization ability under settings where there is a distribution shift between the training and testing datasets. Pathology images from different institutions, different staining methods, and different modalities can all contribute to distribution shifts. Additionally, CONCH classified rare diseases to validate its performance on imbalanced data.\nOther common task types include retrieval, generation, and segmentation, which also involve both tile-level and WSI-level tasks. Among these, cross-modal retrieval and generation tasks challenge the cross-modal capabilities of CPathFMs. Survival prediction aims to estimate disease-specific survival based on WSIs. Unlike the previous tasks, MLLMs are evaluated through various visual question answering (VQA) tasks, such as close-ended, open-ended, and multiple-choice questions.\nRegardless of the evaluation task, evaluation strategies can be broadly categorized into two types: fine-tuning and non-fine-tuning, based on whether the parameters of the pre-trained CPathFMs are updated during the evaluation process. In fine-tuning strategies, the parameters of CPathFMs are updated to adapt to different evaluation tasks. Among non-fine-tuning strategies, the most commonly used approach is linear probing (a.k.a. linear evaluation) in classification scenarios. This method appends a linear classifier to the pre-trained CPathFMs while keeping their parameters frozen during training. It requires less computational resources compared to fine-tuning and is therefore the most common among the surveyed CPathFMs.\nIn addition to quantitatively analyzable evaluation tasks, some CPathFMs have undergone qualitative analysis. Virchow, RudolfV, and PLIP perform dimensionality reduction and clustering on the representations and observe the results. Lu et al., [2024b] explore the potential of PathChat as an AI copilot specialized for pathology through a follow-up from users in the form of interactive, multi-turn conversations."}, {"title": "6 Future Directions", "content": "Trustworthy CPathFMs ensures fairness, explainability, security, and transparency. Fairness is particularly critical, as predicted outcomes should be independent of sensitive attributes such as race and gender to prevent potential biases in clinical applications. Enhancing the explainability of CPathFMs is also essential to gaining the trust of pathologists and clinicians, as deep learning models often operate as black boxes. Furthermore, addressing security vulnerabilities in CPathFMs, such as adversarial attacks, is necessary to prevent manipulation of model predictions. Finally, transparency in model development, dataset curation, and evaluation procedures is crucial for reproducibility and regulatory approval, ensuring CPathFMs can be safely deployed in clinical workflows.\nDeveloping CPathFMs for MxIF Imaging. Unlike H&E and IHC staining, MxIF captures spatial distributions of multiple biomarkers simultaneously, offering richer biological insights into the tumor microenvironment. However, training foundation models on MxIF images presents challenges, including higher dimensionality, complex signal processing, and the need for precise biomarker alignment. Future research should focus on building CPathFMs that can effectively extract meaningful representations from MxIF data while addressing these computational challenges.\nDevelopment of WSI-Level MLLMs for Pathology VQA. A WSI-level MLLM would allow context-aware analysis of entire whole-slide images while integrating clinical reports, pathology captions, and other textual information. This could significantly improve AI-assisted diagnostics, enabling models to generate pathology reports, answer clinician queries, and assist in complex diagnostic decision-making.\nStandardized Benchmarking Datasets and Evaluation Metrics for CPathFMs. The current landscape lacks a uniform set of evaluation metrics that can systematically compare different models across a wide range of pathology tasks. A standardized benchmark dataset incorporating diverse tissue types, staining methods, and multi-institutional sources would significantly enhance model generalization and comparability. Additionally, defining clear evaluation indicators"}, {"title": "7 Conclusion", "content": "Computational pathology foundation models have emerged as a powerful approach for analyzing histopathological data, playing a crucial role in developing robust and clinically applicable AI-driven pathology solutions. This survey provides a comprehensive review of existing computational pathology foundation models, examining challenges in pre-training datasets, adaptation strategies, and evaluation tasks, while offering a comparative analysis of their strengths and limitations. Finally, we identify key research gaps and propose potential directions for future advancements."}]}