{"title": "HDNet: Physics-Inspired Neural Network for Flow Estimation based on Helmholtz Decomposition", "authors": ["Miao Qi", "Ramzi Idoughi", "Wolfgang Heidrich"], "abstract": "Flow estimation problems are ubiquitous in scientific imaging. Often, the underlying flows are subject to physical constraints that can be exploited in the flow estimation; for example, incompressible (divergence-free) flows are expected for many fluid experiments, while irrotational (curl-free) flows arise in the analysis of optical distortions and wavefront sensing. In this work, we propose a Physics-Inspired Neural Network (PINN) named HDNet, which performs a Helmholtz decomposition of an arbitrary flow field, i.e., it decomposes the input flow into a divergence-only and a curl-only component. HDNet can be trained exclusively on synthetic data generated by reverse Helmholtz decomposition, which we call Helmholtz synthesis. As a PINN, HDNet is fully differentiable and can easily be integrated into arbitrary flow estimation problems.", "sections": [{"title": "1 Introduction", "content": "In many flow estimation problems, the reconstructed flows are governed by physical properties. For example, incompressibility (divergence-free) holds for many flows in fluid simulations and experiments, while irrotationality (curl-free) of optical flows is expected in some applications of optical distortion analysis. Incorporating these physical constraints into the reconstruction framework can significantly improve the accuracy of the results in such inverse problems, as proven by several existing works [18, 45, 44, 43, 46, 15, 17]. However, enforcing these constraints in a differentiable manner, compatible with popular deep learning reconstruction methods, remains a challenging problem. A straightforward approach involves incorporating physical laws as loss terms of the neural network pipeline [10, 31, 25]. This approach is better known as Physics-informed Neural Networks (PINNs). For instance, in the case of incompressibility and irrotationality, an 12 norm of the divergence or the curl would be added to the total loss. These soft constraints are easy to"}, {"title": "2 Related Work", "content": "Physics-informed learning. Physics-Informed Learning [21, 20] is a series of strategies that leverage physical laws and constraints to improve machine learning models' predictions. This approach has applications in several domains, including fluid dynamics, quantum mechanics, electromagnetics, and biology [10, 47, 6, 22]. One popular strategy involves the use of Physics-informed Neural Networks (PINNs). Firstly introduced by Raissi et al. [30], PINNs incorporate physical equations directly into the loss function, ensuring that the network's outputs align with the governing physical principles. PINNs have been extensively used in the field of fluid dynamics. For example, Cai et al. [11] employed a PINN to predict the pressure and the velocity field from the Tomographic background-oriented Schlieren temperature field for the flow over an espresso cup. Wang et al. [42] proposed a PINN to estimate the velocity field of fluids in microchannels. By their design, PINNs do not incorporate a physical forward model in their reconstruction process but rely only on integrating the physical equations in the form of soft constraints within the loss function. Another strategy consists of combining neural models with traditional physics-based simulations to incorporate physics through generated datasets [5, 38]. Additionally, some existing methods embedded physical priors or constraints into the network architecture. For instance, Cao et al. [14] propose a neural space-time model for representing dynamic samples captured using speckle structured illumination. Specifically, their approach utilizes two Multi-Layer Perceptrons (MLPs): one to model the motion field and another to represent a canonical configuration of the dynamic sample. The reconstructed sample at different times is obtained by warping the canonical scene with the estimated motion field. The reconstructed frames are then processed through a forward model simulating the imaging process, and the resulting outputs are compared to the captured images to compute the training loss.\nEnforcing incompressibility in fluid simulation and reconstruction. Fluid simulation and reconstruction tasks often require enforcing incompressibility as a hard constraint, which ensures the conservation of the fluid volume. This constraint is equivalent to having a divergence-free flow. In the literature, several conventional methods have been proposed to enforce this physical constraint. PCISPH [35] corrects pressure terms in the Smoothed Particle Hydrodynamics (SPH) representation by assuming constant density. Vortex methods [26, 24, 24] compute velocity from vortex strength using the Biot-Savart formula, facilitating incompressible fluid simulation. The pressure projection [18, 28, 45] approach decomposes an arbitrary field into solenoidal (divergence-free) and irrotational (curl-free) components. This involves solving the Poisson equation, often using iterative gradient-based methods like Preconditioned Conjugate Gradient (PCG). The solenoidal component will be selected to satisfy the incompressibility constraint. While these methods are effective, they share a common limitation: they are non-differentiable. Thus, they cannot be integrated into popular differentiable and deep learning pipelines. To address this challenge, recent research has explored differentiable physical constraint methods. A first approach involves applying a divergence or curl as a penalty term [10, 31, 25], offering a simple and forward differentiable approach. However, the soft nature of these constraints may not always guarantee strict incompressibility. Moreover, some works [16, 37, 2] propose a Convolutional Neural Network (CNN) Poisson solver to replace the iterative solver in pressure projection. However, the lack of sufficient training datasets has led these approaches towards unsupervised learning, which may reduce their performance.\nParticle Image Velocimetry (PIV). PIV is a powerful imaging technique widely used for measuring fluid flow velocities in various fields [1, 29]. The fundamental principle of PIV involves seeding the studied fluid or gas flow with particles. By illuminating the region of interest and recording the particles' advected motion, the fluid flows can be retrieved. In basic PIV techniques, the region of interest of the fluid is simply a plane illuminated with a laser light sheet and captured from a single camera, which leads to the reconstruction of an in-plane 2D velocity field. In this work, we demonstrate our approach using data captured with a basic 2D PIV approach.\nImaging optical distortion. Imaging optical distortion is a critical task in several imaging applications like microscopy, telescopes, and machine vision systems. Optical distortion occurs when light rays are refracted during their path, causing deviations from the ideal rectilinear light propagation. Several techniques have been developed to correct optical distortion since it can lead to inaccurate measurements, blurred images, and reduced resolution. However, in some applications, optical distortion is not a nuisance but rather a valuable tool. For example, in techniques such as Background-Oriented Schlieren (BOS) imaging [32, 23, 39], wavefront sensing [40, 41], and phase retrieval [12, 13], the distortion is leveraged to reconstruct a signal of interest. One solution to these problems is to capture the distortion of a patterned background viewed through the transparent medium of interest (i.e., gas, optical system, etc.). By comparing images of the undisturbed and disturbed background, these techniques can quantitatively measure the displacements induced by the distortion and, therefore, infer the underlying dynamics inside the medium."}, {"title": "3 Method", "content": "In the following we first describe the mathematical concept behind Helmholtz decomposition, then introduce the HDNet architecture, and finally introduce Helmholtz Synthesis as way of efficiently generating training data."}, {"title": "3.1 Helmholtz Decomposition and Physical Interpretation", "content": "The key idea behind our approach is to utilize the Helmholtz decomposition of vector fields, which is based on the fundamental theorem of vector calculus. This theorem states that any arbitrary vector field v* can be decomposed into two orthogonal components: an irrotational (curl-free) and a solenoidal (divergence-free) vector field:\n$v^* = v_{irr} + v_{sol}.$  (1)\nClassically, the Helmholtz decomposition is computed by leveraging well-known identities from vector calculus, and then (numerically) solving a Poisson equation. Specifically, any irrotational flow can be expressed as the gradient of a scalar potential field $:\n$v_{irr} = \\nabla\\phi,$\nAdditionally, the curl of a gradient field is equal to zero, as is the divergence of a curl field:\n$\\nabla \\times (\\nabla\\phi) = 0$ and $\\nabla \\cdot (\\nabla \\times v) = 0$.  (3)\nBy applying the divergence operator to both sides of Eq. 1, we obtain:\n$\\nabla \\cdot v^* = \\nabla \\cdot v_{irr} + \\nabla \\cdot v_{sol} = \\nabla \\cdot v_{irr}, $  (4)\nwhich yields the Poisson equation:\n$\\nabla \\cdot v^* = \\nabla^2\\phi$.  (5)\nOnce the potential field & is retreived using a Poisson solver, the component fields can be calculated as follows:\n$v_{irr} = \\nabla\\phi$ and $v_{sol} = v^* - v_{irr}.$  (6)\nIt is important to note that the potential field \u00d8 has physical significance in many different application domains. For example in fluid simulation $ = P/p represents the normalized pressure, where P is the pressure and p is the mass density. This term plays a crucial role in the incompressible Navier-Stokes equations, which govern many physical fluid flows. In incompressible fluid simulation, a preliminary flow estimate v* is often forced to be divergence-free (incompressible) by computing the vsol term according to Eq. 6, a process commonly known as the pressure projection step.\nIn some optical applications, such as wavefront sensing [41], phase retrieval [12], or Background-Oriented Schlieren imaging [32], the Helmholtz decomposition takes on another physical interpretation. In these applications, the flow fields correspond to optical flow, which describes how light rays bend due to an optical distortion. This distortion is caused by a spatially varying phase delay in the optical wavefront. The potential field & is precisely this phase profile, while the observed optical flow is proportional to its gradient, $\\nabla \\phi$, making it an irrotational field (see Supplement for details). Therefore, when reconstructing optical flow for an optical distortion inverse problem, it is valid to employ the Helmholtz decomposition to ensure the reconstructed flow is curl-free.\nHowever, the classical Poisson solver approach is not differentiable, making it challenging to integrate into modern PINN pipelines for either forward simulation or inverse reconstruction tasks. With the recent advancements in deep learning, numerous deep learning solvers for PDEs have been proposed [34, 30, 10, 37, 11, 9]. Inspired by these ideas, we propose HDNet (Helmholtz decomposition Network) a novel neural network designed to perform Helmholtz decomposition based on conventional HD (Helmholtz decomposition) operations as described by Eqs.5 and 6."}, {"title": "3.2 HDNet", "content": "Architecture. The HDNet architecture, depicted in Fig. 1 (a), takes as input either an arbitrary flow field or an \"initial\" estimation of the reconstructed flow. Instead of relying on the commonly used iterative Poisson solver, HDNet employs a deep learning (DL) solver based on a Convolutional Neural Network (CNN) encoder-decoder with a UNet architecture. To mitigate grid artifacts caused by max-pooling layers, we replace them with convolutions with stride, and similarly, we replace all the transpose convolutions with up-sampling layers.\nFrom Equation 5, the input of the network is a general velocity field v*. To facilitate learning of the Helmholtz decomposition, we compute the divergence $\\nabla \\cdot v^*$, and concatenate it with this input. The UNet core of the HDNet takes this concatenated input and computes the desired potential field 4. From Equations 1 and 3, we can compute the gradient of the output scalar $\\nabla \\phi$ to get the curl-free component virr. By subtracting this curl-free component from the input field, we obtain the divergence-free component (vsol).\nTraining loss. To train the proposed network, we aim to minimize the discrepancy between the predicted scalar field 4 and the ground truth scalar field 4, while simultaneously minimizing the difference between the predicted divergence-free field component (sol) and the ground truth component (vsol). Thus, the training loss is defined as follows:\n$L = ||\\hat{v}_{sol} - v_{sol}||_2^2 + \\lambda ||\\hat{\\phi} - \\phi||_2^2$.  (7)\nThe ground truth vsol and & come from synthesized training data which will be introduced in the following subsection."}, {"title": "3.3 Training Data Generation with Helmholtz Synthesis", "content": "To enable supervised training of the network, it is necessary to generate training pairs for HDNet. The training result highly relies on the training dataset quantity and quality. However, conventional commercial fluid simulation software are computationally expensive and time-consuming, limiting the generation of large-scale datasets. To overcome this challenge, we introduce the Helmholtz synthesis module, a novel approach for generating large-scale fluid training datasets. The Helmholtz synthesis module generates data through the reverse process of the Helmholtz decomposition. By exploiting the vector identities in Eq. 3, we can compute irrotational and solenoidal fields from pseudo-random scalar fields and combine them to obtain arbitrary flow fields. To ensure a realistic quality of the generated dataset, we require scalar fields that are smooth, bandwidth-limited, and exhibit large variability, thereby mimicking real-world complexity."}, {"title": "4 Application: Use of HDNet for Flow Reconstruction", "content": "The proposed HDNet network is versatile and can be incorporated into any differentiable flow simulation or reconstruction pipeline, to enforce hard constraints on the physical properties of the flow in various applications. In this work we are primarily interested in inverse problems that can be expressed as flow estimation tasks. We show quite different applications from fluid flow to optical distortion imaging, all using the same general experimental framework outlined in the following.\nOur pipeline consists of a Physics-Informed Neural Network (PINN) for flow reconstruction, as illustrated in Fig. 1 (b). First, we use a coordinate-based MLP network to represent the flow field v* = f(x, y, t; \u00a7), where \u00a7 is the Motion MLP network weight. This network takes as input the spatial and temporal coordinates (x, y, t), and outputs an \"initial\" reconstructed motion field v* = (u*, w*) for each frame.\nWe employ the Wavelet Implicit neural REpresentation (WIRE) [33] for the Motion MLP, which utilizes a Gabor wavelet as the activation function to learn high-frequency flow motion. Indeed, this activation function has a controllable parameter wo that represents the frequency of the signal. By adjusting wo during the learning process, we can achieve a coarse-to-fine reconstruction. A smaller wo generates smoother results, corresponding to coarse reconstruction, while a larger wo generates high-frequency details, corresponding to fine reconstruction. More details about the WIRE representation and the coarse-to-fine reconstruction strategy are respectively discussed in the Supplement Sections D and C.\nIn the applications we investigate, the reconstructed flows are not arbitrary but exhibit specific physical properties. For example, in the particle imaging velocimetry (PIV) application, the flow of incompressible fluids is divergence-free, while in phase distortion problem imaging, the gradient of the air refractive index reconstruction is curl-free (see Section 3.1). To impose these physical constraints on the initial reconstruction, we apply the pre-trained HDNet to the velocity field v*. The output of the HDNet is the pair of the irrotational and solenoidal fields: D(v*) = (vsol, virr). According to the application, we select the component of the velocity that satisfies the physical constraints. Using the HDNet output (vsol/virr), we can warp the canonical template field po to obtain the scene field pt for each frame. Mathematically, this process is expressed as:\n$p_t(r) = p_0(r + v_{sol/irr}).$ (11)\nwhere r = (x, y) is the spatial coordinates. $v_{sol/irr}$ is the HDNet output: $v_{sol}$ or $v_{irr}$ at time t. pt (r) is the predicted \u201cscene\u201d field at time t. It represents the particle density field in the PIV application or the background texture in the case of BOS or wavefront sensor problem. po is the canonical configuration of the \u201cscene\u201d field. In our framework, we represent this reference configuration using simply a template image, which is a variable to be optimized during the learning process. Eq. 11 is equivalent to the non-linearized brightness consistency [8] in the optical flow problems. Therefore, our pipeline inherently incorporates the non-linearized brightness consistency. Our pipeline is defined as a joint optimization problem, where we aim to retrieve both the canonical scene field and the motion field representation:\n$L = arg \\underset{\\rho_0,\\xi}{min} \\sum_{x,y,t} ||p_0(r + D(f(x,y,t;\\xi))) - p_t||^2 + \\lambda_2 ||\\nabla_{x,y}D(f(x,y,t;\\xi))||.$ (12)\nThe second term corresponds to the total variation (TV) of the velocity field, which promotes smoothness in the velocity field, limiting changes within the neighborhood. 2 is the weight of the TV term in the total loss."}, {"title": "5 Experiments", "content": "In this section, we demonstrate the application of HDNet within our flow reconstruction pipeline. We first evaluate the reconstruction performance HDNet performance and flow reconstruction pipeline of by using synthetic data in order to assess numerical metrics. Then, we showcase reconstruction outcomes obtained from real PIV, and BOS experimental data, providing visualizations of divergence and curl maps alongside with scalar potential fields. Similar experiments are also presented in the Supplement (Section B.2) for another phase distortion problem: wavefront sensing. The obtained results demonstrate the superior performance of our method in terms of reconstruction quality, physical constraint enforcement, and robustness against noise."}, {"title": "5.1 Synthetic Data", "content": "HDNet evaluation. We demonstrate the performance of HDNet in enforcing incompressibility on the outputed solenoidal field using synthetic data generated by Helmholtz synthesis module. We create five groups of paired datasets, each containing 800 samples, with varying Perlin noise scales n and the weight X. We assess the divergence of the solenoidal field vsol output by HDNet and report the mean squared error (MSE) with respect to zero (mean and standard deviation) in Tab. 1.\nFlow pipeline evaluation. To quantitatively assess the performance of our flow reconstruction pipeline, we generated synthetic PIV particle image sequences as described in the Supplement B.3. We then compare the predicted flows using different reconstruction methods with the ground truth one. The results of this comparison are reported in Fig.3. When using our pipeline without HDNet, the"}, {"title": "5.2 Real Experiment Data", "content": "We also verify our flow reconstruction pipeline in real experiments for both PIV and optical distortion applications. Details of the experimental settings and image sequences can be found in Supplement Section A and Fig. 12."}, {"title": "5.2.1 PIV", "content": "Fig. 4 shows the real PIV experiment flow reconstructions. Here, \u201cSoft Constraint\" reconstruction consists of adding an l2 norm of the divergence ($||\\nabla v_t||_2^2$) to the total loss (Equation 12) to penalize the divergence. It is a very straightforward idea, but the solution does not always satisfy the constraint. From Fig. 4 (d), we can see that there is still some divergence error. With the help of HDNet, our pipeline can reconstruct the flow very well and remove the diverging error. Our method can be thought of as a differentiable hard constraint for the flow reconstruction."}, {"title": "5.2.2 Background-Oriented Schlieren Imaging", "content": "In optical distortion applications like BOS, the reconstructed optical flow is the gradient of refractive index (phase) [4], also see Supplement B.1. Therefore, this reconstructed flow should be curl-free (i.e., the curl of the gradient is zero). We compare different methods of reconstruction in Fig.5, and illustrate the reconstructed flows and their corresponding curls .\nThe flow reconstruction pipeline is similar to the one used for PIV experiments. The only differences are the input images (see Fig. 14 in Supplement), and the use of the virr output of HDNet instead of the vsol output. The compressed video data used in the original paper [4] exhibits some compression artifacts, leading to noisy flow reconstruction using traditional methods like Horn-Schunck (Fig. 5 (a,b)). Our proposed PINN flow reconstruction pipeline produces a significantly cleaner flow field, effectively removing even the vertical line artifact present in the HS reconstruction Fig. 5 (a-b). Without the use of HDNet, the PINN flow reconstruction pipeline still exhibits a relatively large curl error (see Fig. 5 (d)). By incorporating HDNet, we achieve a significantly smaller curl error Fig. 5 (f), indicating a highly accurate and physically consistent flow reconstruction. Notably, by using HDNet, our method not only reconstructs the flow but also recovers the corresponding phase as illustrated in Fig. 5 (g)."}, {"title": "6 Limitations and Future Work", "content": "Although HDNet provides a convenient and effective way to inject physical priors into PINNs, the current work has several limitations. First, while the mathematical derivation of the approach holds both in 2D and 3D, currently only the 2D version is implemented. However, the network architecture should be straightforward to adapt to 3D, and since Perlin noise is also defined in 3D, data generation with multi-scale Helmholtz Synthesis is also straightforward. Therefore we do not expect that the generalization of HDNet to 3D will require more than hyperparameter tuning.\nA more fundamental limitation is that, as a supervised method, HDNet does not guarantee an exact Helmholtz decomposition of the input flow; in particular the solenoidal component is not guaranteed to be strictly divergence free. The irrotational component is computed as the gradient of an estimated potential field ($v_{irr} = \\nabla \\phi$), and is therefore always curl free. However, any mis-estimation of the potential field & results in an imprecise decomposition, and thus the calculated solenoidal flow $v_{sol} = v^* - v_{irr}$ may still have a remaining divergence component. Our experiments show that this effect is small, however if it is a concern in a particular application, it is also possible to penalize $\\nabla \\cdot v_{sol}$ in the loss function for a larger PINN architecture."}, {"title": "7 Conclusion", "content": "In this paper, we propose HDNet, a novel network based on the fundamental theorem of vector calculus and Helmholtz decomposition theorem. By employing HDNet, we can effectively impose differentiable hard constraints on inverse imaging problem. We further propose the Helmholtz synthesis module that efficiently generates paired data by reversing Helmholtz decomposition. This module enables the rapid creation of 20000 data pairs within half an hour, making large-scale flow dataset construction feasible and the supervised training of HDNet possible.\nFinally, we demonstrate the integration of HDNet into a PINN pipeline for flow reconstruction, showcasing its applicability with examples from PIV and BOS imaging data. Experimental results prove that our HDNet-empowered PINN pipeline outperforms conventional flow reconstruction method. Notably, our approach exhibits versatility and flexibility in satisfying both curl-free and divergence-free constraints while also outputting the scalar potential field."}, {"title": "A Implementation Details", "content": "The HDNet architecture is an MLP with 6 layers, 4 of which are hidden layers. Each hidden layer has 64 neurons. For the WIRE activation functions, the wo value ranges from 1.0 to 1.5. \u03c3\u03bf value ranges from 0.8 to 1.2. We choose the Adam optimizer with learning rate is 1 \u00d7 10-6. We train the HDNet on 20000 data pairs, with 2000 data pairs as the evaluation dataset. Training takes 72 hours on a single A100 GPU. HDNet is applied after 30000 epoch after the coarse reconstruction is almost done.\nFor the data generation, we use Perlin noise at scales n from 1 to 5. The relative strength of the irrotational and the solenoidal, controlled by the weight x, can be tuned to the specific application. For example in PIV, the basic Horn Schunck optical flow for an incompressible flow would already have a small divergence that just needs to be reduced further. Therefore we can estimate appropriate weights for the two terms by analyzing the divergence of the basic flow estimate for a representative flow, and choose x appropriately. Using this approach, we chose x to be a random number from a normal distribution with a mean of 0.0002.\nFor the full flow estimation pipeline, we chose one of the input frames po as the template, and initialize accordingly."}, {"title": "B Experiments", "content": ""}, {"title": "B.1 Phase Distortion Problem Principle", "content": "Optical distortion imaging like BOS, wavefront sensing, and phase retrieval can be approached in different ways, but one common approach is to track the apparent motion (optical flow) of a high frequency pattern imaged through the distortion. An example geometry for BOS is shown in Figure 6. The goal of BOS imaging is to measure the phase delay in the distortion plane. A patterned background some distance away is observed with a camera. Since light rays propagate perpendicular to the phase profile 4, the observed optical flow is proportional to the $\\nabla \\phi$ for small angles (\u201cparaxial approximation\"). The factor of proportionality is the propagation distance between the distortion plane and the background.\nBecause the optical flow is proportional to the phase, the flow is curl free, and the phase actually corresponds to the potential function in the Helmholtz decomposition\""}, {"title": "B.2 Wavefront Sensor", "content": "The coded wavefront sensor is also a variant of the classic phase distortion problem [40, 41]. The principle is also similar to what is explained in Section B.1. The distortion is related to the gradient of phase. A mask is placed in the front of the camera. A frame without any distortion is captured as a reference frame (Fig 7 (a)). After the phase lens array (Fig 7 (c)) causing distortion, phase distorted"}, {"title": "B.3 PIV Synethetic Data", "content": "For the PIV simulations, we first generated 1 frame with 10000 particles in random position with pixels size about 1-2 pixels. The particle pixels value was generated in a normal distribution with mean 1 and variance 0.2. The particle frame figure is shown in Supplement Fig. 10. Then, we used the flow from Helmholtz Synthesis inference dataset to warp the particle to get the other particle image sequence.\nHDNet+ It is very straightforward to add a divergence penalty term to the total loss for the flow reconstruction pipeline. To compare with different settings and show the flexibility of HDNet, we also did a comparison experiment that adds a divergence penalty to the total loss for our HDNet flow"}, {"title": "C Wavelet Implicit Neural Representation", "content": "Study reveals that directly learning the image or 2D/3D field with MLP leads to very poor accuracy [36]. One reason is that only the MLP can not learn high frequency of the image. Employing Gabor wavelet as the activation function can enable the MLP to learn the high frequency of the image [33]. Every layer in MLP can be expressed as:\n$y_m = \\sigma(W_my_{m-1} + b_m)$, (13)\nwhere Wm, bm are the weight and bias for the m layers [33]; o is the activation function.\n$\\sigma(x) = e^{i\\omega_0 x}e^{-\\sigma_0 x|^2}$ (14)"}, {"title": "D Frequency Coarse to Fine", "content": "wo determine the frequency level that it represents (Supplement Fig. 16). A smaller wo generates smoother results corresponding to the \"coarse\" reconstruction. A large wo generates more high-frequency detail corresponding to \"fine\" reconstruction. By using this property, we can achieve the coarse-to-fine reconstruction which will be discussed in Supplement Section D.\nAdaptive Learnable Parameter Moreover, the WIRE representation exhibits adaptability, as its representation parameters, wo and \u03c3\u03bf, are learnable according to the characteristics of the scene being represented. Comparing with NeRF position encoding neural representation, WIRE neural presentation is more continuous for changing the parameter. WIRE is faster than the Fourier Feature [36] and robust for inverse problems of images and video [33]."}]}