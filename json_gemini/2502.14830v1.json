{"title": "Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs", "authors": ["Danni Liu", "Jan Niehues"], "abstract": "While large language models demonstrate remarkable capabilities at task-specific applications through fine-tuning, extending these benefits across diverse languages is essential for broad accessibility. However, effective cross-lingual transfer is hindered by LLM performance gaps across languages and the scarcity of fine-tuning data in many languages. Through analysis of LLM internal representations from over 1,000+ language pairs, we discover that middle layers exhibit the strongest potential for cross-lingual alignment. Building on this finding, we propose a middle-layer alignment objective integrated into task-specific training. Our experiments on slot filling, machine translation, and structured text generation show consistent improvements in cross-lingual transfer, especially to lower-resource languages. The method is robust to the choice of alignment languages and generalizes to languages unseen during alignment. Furthermore, we show that separately trained alignment modules can be merged with existing task-specific modules, improving cross-lingual capabilities without full re-training. Our code is publicly available\u00b9.", "sections": [{"title": "1 Introduction", "content": "Decoder-only large language models (LLMs) have emerged as the dominant paradigm in NLP. While these models exhibit promising zero-shot capabilities (Wei et al., 2022; Chowdhery et al., 2023), further task-specific fine-tuning remains crucial for optimal performance in many applications (Shen et al., 2024; Xu et al., 2024; Alves et al., 2024). During fine-tuning, a practical challenge is that the available training data rarely covers all languages supported by LLMs. This highlights the importance of cross-lingual transfer to extend task-specific performance gains across languages.\nWhile cross-lingual transfer has been extensively studied (Wang and Zheng, 2015; Ruder et al., 2019;"}, {"title": "2 Analyzing Cross-Lingual Alignment", "content": "To understand how well LLM representations capture semantic equivalence across languages, we use translation retrieval as a diagnostic task. We choose this retrieval task over other metrics like cosine similarity or SVCCA score (Raghu et al., 2017) because it better captures relative semantic relationships. That is, if a model's representations enable us to identify a sentence's translation from a set of candidates, the exact numerical distance between the query and the retrieved translation is less important than the ability to rank translations as the most semantically similar.\nSpecifically, we first extract model activations at each network layer for all language variants of the input text. To handle variable-length sequences, we create fixed-size sentence embeddings by meanpooling the activations over the sequence length dimension. For translation retrieval, given a query sentence in one language, we compare its embedding to the embeddings of candidate sentences in the target language using ratio-based margin similarity (Artetxe and Schwenk, 2019a)2. For N languages, we evaluate retrieval accuracy across all $N(N-1)$ possible language pairs. We use the FLORES-200 dataset (NLLB Team, 2024), which provides high-quality multiway parallel texts across diverse languages (detailed setup in \u00a74.2).\nOur investigation of LLama 3 and and Qwen 2.5 models\u00b3 reveals three key findings:\nOverall weak semantic alignment, with peak in middle layers: As shown in Figure 1a, the average translation retrieval accuracy across 1,190 language pairs remains below 50%, with Llama 3 outperforming Qwen 2.5. Low-resource languages4 show especially weak alignment, achieving less than half of the overall average accuracy. In particular, the middle layers of both models demonstrate the strongest retrieval performance. This suggests stronger potential for cross-lingual transfer at these intermediate representations.\nStrong correlation between base LLM semantic alignment and downstream task transfer: To what extent can the semantic alignment present in the base LLM predict cross-lingual transfer performance after supervised fine-tuning? Using multi-"}, {"title": "3 Explicit Alignment in fine-tuning", "content": "We propose an alternating training strategy to encourage cross-lingual alignment while maintaining task performance. As illustrated in Figure 2, we optimize either the task-specific objective or the alignment objective in each training step.\nTask Objective: We follow standard causal language modeling, using a cross-entropy loss over the predicted text conditioned on the input prefix.\nAlignment Objective: We use a contrastive loss motivated by its successful applications in sentence embedding (Feng et al., 2022), dense retrieval (Karpukhin et al., 2020) and modality alignment (Ye et al., 2022; Girdhar et al., 2023). The loss maximizes the similarity between translations while minimizing similarity between non-translations. Given a batch B of n pairs of parallel sentences, the alignment loss for a sentence pair $(s, t)$ is:\n$L_{align} = - log \\frac{exp(sim(h_s^i, h_t^i))}{\\Sigma_{v \\in B}exp(sim(h_s^i, h_v^i))}$    (1)\nwhere $h_s^i$ is the mean-pooled hidden states at the $i$th LLM layer for input $s$ and $sim(\\cdot, \\cdot)$ is a similarity function. Motivated our finding that middle layers have the strongest cross-lingual alignment potential, we select $i$ as the middle layer and compare its performance to other layer positions. We use cosine similarity following prior works (Gao et al., 2021; Ye et al., 2022). The similarity score is optionally scaled by a temperature parameter $T$, which controls the peakiness of the softmax distribution and in turn determines the relative importance of non-translation pairs. This temperature parameter is tuned on the development sets.\nActivating Individual Objectives: Note that the task and alignment losses can be activated separately. Deactivating the alignment loss degenerates to standard task-only training. Conversely, deactivating the task loss trains the model only for alignment. This modularity enables us to subsequently combine separately-trained task and alignment models."}, {"title": "4 Experimental Setup", "content": "4.1 Data\nIn general, we fine-tune on several high-resource languages and then evaluate transfer performance on additional languages. We do not focus on English-only fine-tuning, since our initial experiments demonstrated that multilingual fine-tuning substantially outperforms English-only fine-tuning5, thus establishing it as a stronger baseline. Table 1 presents a dataset overview. Descriptions of the language codes are in Appendix C.\nMain Task Data: We evaluate our approach on slot filling and machine translation, both modeled as generative tasks with templates shown in Appendix D.2. For slot filling, we use the MASSIVE dataset (FitzGerald et al., 2023). We train on 5 high-resource languages, and evaluate transfer performance on 15 additional diverse languages, 5 of which have non-Latin writing systems. This task presents a challenge due to the 60 possible slots, requiring strictly following the output format for correct parsing. For machine translation, we use ALMA (Xu et al., 2024)'s training and test data, and additionally test on 6 zero-shot directions from WMT 23 (Kocmi et al., 2023).\nChallenge Task Data: To assess performance on long-sequence processing and structured text generation, we include JSON generation as a challenge task. We use the UNER dataset (Mayhew et al., 2024) from the Aya collection (Singh et al., 2024),"}, {"title": "4.2 Evaluation", "content": "Semantic Alignment Evaluation: As described in \u00a72, we evaluate cross-lingual semantic alignment by retrieval accuracy. Given N languages, we perform many-to-many retrieval and average the accuracy over the $N(N \u2013 1)$ language pairs. For the initial analyses (\u00a72), the 35 languages are listed in Appendix C. We use the FLoRes-200 (NLLB Team, 2024) development set with 997 parallel sentences. While FLoRes partially overlaps with ALMA's training data, it remains the only reliable massively multilingual multiway corpus to the best of our knowledge. Alternative such as Tatoeba have been advised against due to data imbalance and noise (Heffernan et al., 2022; Janeiro et al., 2024). We also demonstrate that this overlap does"}, {"title": "4.3 Model, Training, and Inference", "content": "We build upon Llama (AI @ Meta et al., 2024) and Qwen (Qwen Team et al., 2025), specifically Meta-Llama-3-8B-Instruct10 and Qwen2.5-7B-Instruct. We use LoRA (Hu et al., 2022) adapters with a rank of 8 for all attention components and linear projections. The effective batch size is 128 for both objectives, with minibatches of 32 examples considered for the contrastive objective\u00b9\u00b9. Alignment data from different languages are re-sampled to an approximately uniform distribution. More details are in Appendix D."}, {"title": "5 Main Results", "content": "The main results are summarized in Table 2. Before assessing our proposed approach, we first establish the necessity of supervised FT by comparing it with zero-shot usage of the LLMs (rows (2,5) vs. (1,4)). On slot filling, the zero-shot performance of Llama 3 is very poor, achieving only 6.6% F1 on English due to difficulties in adhering to task-specific formats. We therefore do not evaluate its zero-shot performance on all languages. In machine translation, supervised fine-tuning shows substantial gains of 4-6 COMET over zero-shot.\n5.1 Overall Performance Comparison\nGains in cross-lingual transfer with supervised performance preserved: Our approach improves cross-lingual transfer across different tasks and models. For slot filling, we observe gains in both supervised and transfer (F\u2081 +0.4 and +1.5 respectively) settings on Llama fine-tuning, with similar improvements on Qwen (F1 +0.7 supervised, +1.8 transfer). In machine translation with Llama in row (3), our approach brings substantial gains when transferring to out-of-English directions (+1.5 BLEU, +1.1 COMET). For intoEnglish directions, there is a modest improvement in +0.5 BLEU and +0.2 COMET. The larger gains on out-of-English directions suggest the approach is more beneficial for non-English generation in this case. For Qwen in row (6), our approach shows minor gains in into-English translation (+1.1 BLEU but no change in COMET), and does not influence out-of-English scores. It also leads to a degradation (-0.8 COMET) on supervised directions. This is potentially due to Qwen's non-English-centric pretraining combined with our English-centric alignment data. With this exception, our approach maintains or improves supervised performance while enhancing transfer. Aligned languages improve the most, but gains extend to other languages: The diverse language coverage in the slot filling dataset allows us to com-"}, {"title": "5.2 Alignment Loss Placement", "content": "To validate our choice of middle-layer alignment motivated by the analysis in \u00a72, we compare performance when applying the alignment loss at different network depths: bottom (8th), middle (16th), and top (32nd) layers of Llama.\nMiddle layer placement achieves more balanced improvements in transfer languages: As shown in Table 3, compared to the \"middle\" configuration, the \"bottom\" configuration clearly leads to poor overall performance in both supervised and transfer settings, with a particularly strong degradation on the slot filling task. While top-layer alignment maintains overall strong performance, it shows more unbalanced gains across transfer languages, as evidenced by the higher standard deviation of performance gains on transfer languages. Middle layer placement achieves better alignment across network depths: To better understand the effects of different loss placements, we run the translation retrieval task over model activations at from different intermediate layers. As shown in Figure 4, When the alignment loss is applied at the middle (16th) layer, semantic alignment is enhanced not only at that layer but also in multiple preceding layers. In contrast, top-layer"}, {"title": "5.3 Impact on Representation Retrieval", "content": "To assess the impact of the alignment loss on the learned model representations, we also report the retrieval accuracy for all languages involved in each task (20 for slot filling and 9 for machine translation) after fine-tuning in Table 2. For Llama on the slot filling task, the alignment loss substantially improves retrieval accuracy from 39.4% to 73.2%. For Qwen, the alignment loss does not improve retrieval among the 20 slot filling languages, possibly due to the lower accuracy of the base model with many low-resource languages with 0% accuracy, making improvement more challenging. For machine translation, as noted earlier \u00a74.2, the retrieval test data overlaps with part of the task training data, potentially inflating accuracy (marked in brackets in Table 2). However, we verify that this overlap does not lead to perfect retrieval accuracy: Specifically, at the 16th layer where the alignment loss is applied, English-source retrieval accuracies for supervised languages show varying accuracy: cs"}, {"title": "6 Analyses", "content": "6.1 Resource Level of Alignment Languages\nIn our main experiments, we selected the 5 languages with the weakest performance from the MASSIVE baseline (FitzGerald et al., 2023) for alignment. We now vary the resource level of the alignment languages using a medium-resource group with {el, hi, th, tr}-en and a high-resource group with {ar, es, ru, zh}-en, which also have supervised task training data. As shown in Table 4, all three configurations improve F1 scores for the languages involved in alignment. However, the low-resource group exhibit the largest gains (+3.8 F1), indicating that our approach is most beneficial to languages with weaker initial performance. Moreover, overall transfer gains relative to the SFT baseline diminish when using high-resource languages for alignment, likely because these languages already have well-aligned representations and aligning them provides little benefit to lower-resource languages in the transfer set. Overall, the results show that our approach is robust to the choice of alignment languages, but selecting initially poorly aligned languages could provide broader benefits across different languages.\n6.2 Generalization of Learned Alignment\nTable 5 examines the language and domain generalization of our alignment component. To isolate the effects of task-specific joint training, we train the models using only the alignment loss, following the same setup as our previous experiments but without optimizing on task-specific data. We then evaluate retrieval accuracy as described in \u00a74.2.\nLanguage Generalization: While our main experiments align multiple language pairs, we now use single languages for alignment. As shown in Table 5 (upper portion), that single-language"}, {"title": "6.3 Merging Alignment and Task Modules", "content": "Our previous experiments focused on models jointly trained on both task and alignment objectives. However, in practice, it may be necessary to enhance existing task-specific models with cross-lingual capabilities, where joint re-training is infea-"}, {"title": "6.4 Long Sequence Processing", "content": "We investigate a more challenge task requiring longer input and output generation using UNER (\u00a74.1). As shown in Table 7, while aligned languages still show improvements, the gains are more modest compared to previous experiments, with an F1 increase of 1.0 on aligned languages and 0.5 across all transfer languages. Moreover, there is an average degradation of 1.0 F1 on supervised languages, mainly due to the decline in Chinese (-2.2 F1). A potential reason is the mismatch between our sentence-level alignment objective and the requirements of processing longer sequences."}, {"title": "7 Related Works", "content": "Multilingual Capabilities of LLMs: LLM performance varies across languages due to imbalanced pre-training data volume. However, even predominantly English-centric models (Touvron et al., 2023) exhibit some degree of multilingual capability (Aycock and Bawden, 2024; Yuan et al., 2024), potentially due to the unintentional ingestion of multilingual data during pretraining (Briakou et al.,"}, {"title": "8 Conclusion", "content": "We presented a simple yet effective approach for enhancing cross-lingual transfer in LLMs through middle-layer representation alignment during fine-tuning. Our experimental results lead to several practical recommendations: 1) Aligning a few weakly-performing languages yields broad transfer benefits. A few hundreds of parallel sentences as alignment data are sufficient. 2) Alignment data can be sourced from different domains as the task. 3) Existing task-specific models can be enhanced with our approach via parameter merging without the need of full re-training."}, {"title": "Limitations", "content": "Typologically diverse languages: As discussed in \u00a75.1, our approach shows smaller gains on languages non-Latin scripts. This limitation is likely related to fundamental tokenization challenges, where suboptimal token segmentation negatively impacts the quality of mean-pooled representations. While our initial experiments on attention pooling did not lead to improvements, exploring more sophisticated pooling mechanisms could potentially address this challenge in future work.\nComputational overhead during training: The alternating optimization between task and alignment objectives doubles the computational cost during training compared to standard fine-tuning. In computationally constrained settings, our merging approach, which separates task-specific and alignment training, should be prioritized. Given that alignment can be effectively performed using only a small number of parallel sentences (a few hundred per language), this modular approach can significantly reduce the overall computational cost.\nTrade-offs between supervised and transfer performance in challenging scenarios: While our approach generally maintains or improves supervised task performance while improving transfer, we observe degradation in supervised performance in two specific scenarios. First, in structured text generation (\u00a76.4), the method shows reduced effectiveness and can impair supervised performance (-1.0 F1), suggesting that our sentence-level alignment may interfere with the processing of longer, structured sequences. Second, when applying the method to models with weak initial cross-lingual alignment (\u00a75.1), there could be a trade-off between improved transfer and supervised performance."}]}