{"title": "CGLearn: Consistent Gradient-Based Learning for Out-of-Distribution\nGeneralization", "authors": ["Jawad Chowdhury", "Gabriel Terejanu"], "abstract": "Improving generalization and achieving highly predictive, ro-\nbust machine learning models necessitates learning the under-\nlying causal structure of the variables of interest. A promi-\nnent and effective method for this is learning invariant pre-\ndictors across multiple environments. In this work, we intro-\nduce a simple yet powerful approach, CGLearn, which relies\non the agreement of gradients across various environments.\nThis agreement serves as a powerful indication of reliable\nfeatures, while disagreement suggests less reliability due to\npotential differences in underlying causal mechanisms. Our\nproposed method demonstrates superior performance com-\npared to state-of-the-art methods in both linear and nonlin-\near settings across various regression and classification tasks.\nCGLearn shows robust applicability even in the absence of\nseparate environments by exploiting invariance across differ-\nent subsamples of observational data. Comprehensive exper-\niments on both synthetic and real-world datasets highlight its\neffectiveness in diverse scenarios. Our findings underscore\nthe importance of leveraging gradient agreement for learn-\ning causal invariance, providing a significant step forward\nin the field of robust machine learning. The source code of\nthe linear and nonlinear implementation of CGLearn is open-\nsource and available at: https://github.com/hasanjawad001/\nCGLearn.", "sections": [{"title": "Introduction", "content": "Machine learning models have achieved remarkable suc-\ncess in various domains driven by the recent availability\nof large datasets, sophisticated algorithms, and highly ad-\nvanced complex models. However, these models perform\nwell only when the test data follows the same distribution\nas the training data (i.i.d.), but they often suffer from over-\nfitting due to overparametrization, learning spurious corre-\nlations from training data (Sagawa et al. 2020; Wang et al.\n2021; Ming, Yin, and Li 2022). This issue arises because\ntraditional models focus on predictive power without con-\nsidering the causal relationships underlying the data. As a\nresult, when the training and test distributions differ, models\nthat rely on spurious correlations can perform very poorly,\ncompromising their robustness, leading to poor generaliza-\ntion on out-of-distribution (OOD) test data (Arjovsky et al.\n2019; He, Shen, and Cui 2021).\nLearning causal relationships is the key to model explain-\nability and enhancing generalization and robustness (Shin\n2021; Wang et al. 2022; Santillan 2023). Although the\nideal method for learning causal structures is through Ran-\ndomized Control Trials (RCTs), these are often expen-\nsive, unethical, or impractical. Various methods have been\ndeveloped for causal discovery. Constraint-based methods\nuse conditional independence tests to identify causal direc-\ntions (Spirtes, Glymour, and Scheines 2001; Pearl 2009;\nColombo et al. 2012). This however often results in the\nMarkov Equivalence Class (MEC) of causal structures.\nScore-based methods optimize causal graphs over Directed\nAcyclic Graphs (DAGs) (Chickering 2002; Ramsey et al.\n2017; Huang et al. 2018), but the combinatorial nature of\nthe search space can make it computationally expensive. Ad-\nvances like NOTEARS (Zheng et al. 2018) transform this\ncombinatorial challenge into continuous optimization, lead-\ning to various effective variants (Zheng et al. 2020; Yu et al.\n2019; Lachapelle et al. 2019; Wei, Gao, and Yu 2020; Ng,\nGhassami, and Zhang 2020; Ng et al. 2022). However, learn-\ning causal structures purely from observational data can be\nchallenging due to issues like selection bias, measurement\nerrors, and confounding factors (Zadrozny 2004; Torralba\nand Efros 2011). Moreover, relying solely on empirical risk\noptimization can result in models highly dependent on spu-\nrious relationships. To tackle this problem, researchers of-\nten use prior domain knowledge to improve causal discov-\nery (O'Donnell et al. 2006; Gencoglu and Gruber 2020; An-\ndrews, Spirtes, and Cooper 2020; Liu, Chen, and Zhao 2021;\nChowdhury., Rashid., and Terejanu. 2023; Chowdhury and\nTerejanu 2023). Unfortunately, many causal discovery meth-\nods depend on specific assumptions (e.g., linearity, non-\nGaussian noise) that do not always hold in real-world data.\nIn addition to that some of these methods exploit variance\nscales e.g. var-sortability to identify causal orderings, per-\nforming well on unstandardized data but poorly after stan-\ndardization (Reisach, Seiler, and Weichwald 2021; Kaiser\nand Sipos 2022; Reisach et al. 2024; Ormaniec et al. 2024).\nA recent line of study focuses on exploiting the invariance\nproperty of causal relationships across different environ-\nments. Methods like Invariant Causal Prediction (ICP) (Pe-\nters, B\u00fchlmann, and Meinshausen 2016) aim to identify\ncausal predictors by ensuring the conditional distribution of\nthe target given these predictors remains stable across envi-"}, {"title": "Methodology", "content": "In this section, we present the methodology of CGLearn,\ndetailing both its linear and nonlinear implementations. We\nstart by explaining the regular Empirical Risk Minimization\n(ERM) approach and then introduce the concept of gradi-\nent consistency used in CGLearn. The primary concept of\nCGLearn is to enforce gradient consistency for each fac-\ntor of our variable of interest across multiple environments\nto identify and utilize invariant features, thereby enhancing\ngeneralization and reducing dependence on spurious corre-\nlations."}, {"title": "Empirical Risk Minimization (ERM)", "content": "Let's consider a simple linear problem where the goal is\nto predict the target variable $Y$ using two features $X_1$\n(causal) and $X_2$ (spurious) across multiple environments.\nLet $e_1, e_2,..., e_m$ represent different environments. Envi-\nronments can be considered as distinct distributions gener-\nated by different interventions, all of which share similar un-\nderlying causal mechanisms (see Fig. 1).\nIn the ERM framework, the weights for the features are\nupdated by minimizing the empirical risk or the cost func-\ntion (L), which is typically the mean squared error (MSE)\nbetween the predicted and actual values for a regression\nproblem and cross-entropy loss for a classification task. Sup-\npose the weights for the features at step $t$ are $w_1$ for $X_1$ and\n$w_2$ for $X_2$. The gradient of the loss (L) with respect to the\nweight associated with the j-th feature $X_j$ in environment\n$e_i$ is given by $\\nabla L_{ei}^j$, where $j \\in \\{1, 2\\}$ and $i \\in \\{1, ...,m\\}$.\nThe aggregated gradient across all environments can be\ncalculated as the mean of the gradients:\n$\\mu_j^{grad} = \\frac{1}{m}\\sum_{i=1}^{m} \\nabla L_{e_i}^j \\quad \\text{for } j\\in \\{1,2\\}$                                                 (1)\nUsing this aggregated gradient, the weights are updated\nas follows:\n$w_j^{t+1} = w_j^t - \\eta \\mu_j^{grad} \\quad \\text{for } j\\in \\{1,2\\}$                                                          (2)\nwhere $\\eta$ is the learning rate. In this setup of a standard\nEmpirical Risk Minimization, the weights for both $X_1$ and\n$X_2$ get updated in each step regardless of their consistency\nacross environments."}, {"title": "Linear Implementation of CGLearn", "content": "CGLearn modifies this approach by introducing a consis-\ntency check for the gradients. The idea is to update the\nweights only if the gradients are consistent across the avail-\nable environments. This strategy focuses on invariant fea-\ntures and ignores spurious ones, expecting better generaliza-\ntion.\nFirst, we calculate the gradient of each feature in every\nenvironment, as described in the previous section. The mean\nof the gradients can be calculated as described in Eq. 1. Next,\nwe compute the standard deviation of the gradients for each\nfeature across all environments as follows:\n$\\sigma_j^{grad} = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} (\\nabla L_{e_i}^j - \\mu_j^{grad})^2 }$                                                         (3)\nWe then calculate the consistency ratio, which is the ab-\nsolute value of the ratio of the mean gradient to the standard\ndeviation of the gradients:\n$C_j^{ratio} = \\frac{|\\mu_j^{grad}|}{\\sigma_j^{grad}}$                                                                        (4)\nThe consistency ratio, $C_j^{ratio}$ defined in Eq. 4, is consid-\nered to be an indicator of the invariance of the gradient of\nvariable $X_j$ across all the training environments. A relatively\nlarger mean compared to the standard deviation would indi-\ncate more similar or invariant gradients across the environ-\nments for the feature $X_j$, resulting in a higher value of $C_j^{ratio}$.\nOn the other hand, a larger standard deviation indicates more\ndiversity across the environments for $X_j$. Finally, we for-\nmulate a consistency mask based on a predefined threshold\n$C^{thresh}$.\n$C_j^{mask} = \\begin{cases}\n1 & \\text{if } C_j^{ratio} > C^{thresh} \\\\\n0 & \\text{otherwise}\n\\end{cases}$                                                                          (5)\nThe weights are updated only for the feature that has a\nnonzero mask and remains unchanged otherwise as per the\nfollowing equation:\n$w_j^{t+1} = w_j^t - \\eta (\\mu_j^{grad}. C_j^{mask}) \\quad \\text{for } j\\in \\{1,2\\}$                                               (6)\nConsidering our motivating example, where $X_1$ is causal\nand expected to show more consistency across environ-\nments, $C_1^{mask}$ is expected to be 1. Conversely, $X_2$ is spurious\nwith respect to the target, expected to show inconsistency\nacross environments, and $C_2^{mask}$ is expected to be 0. There-\nfore, the weight for $X_1$ is mostly updated throughout the\ntraining steps while the weight for $X_2$ is not. The model thus\nfocuses on the features that show consistency for learning\nthe predictors of the target. This implementation strategy en-\nsures to emphasis on reliable, invariant features while min-\nimizing the impact of unreliable features by keeping their\nweights unchanged (or keeping the changes to a minimum).\nAs a result, the contributions of the spurious features remain\nconstant in the context of the model updates. In the next sec-\ntion, we extend the CGLearn method to a nonlinear setting\nusing multilayer perceptron (MLP) as an instance."}, {"title": "Nonlinear Implementation", "content": "For the nonlinear implementation of CGLearn using a mul-\ntilayer perceptron (MLP), we focus on the gradients in the\nfirst hidden layer (h\u2081), where feature contributions can be\ndistinctly identified. By controlling the contribution of spu-\nrious features at the first hidden layer, we ensure they do not\ninfluence the final output. The process involves calculating\nthe $L_2$-norm of the gradients for each feature in each envi-\nronment, followed by determining the consistency ratio and\nmask to impose the consistency constraint.\n$\\|\\nabla L_i^{jh_1}\\|_2$ denotes the $L_2$-norm of the gradients of the\nj-th feature $X_j$ in the i-th environment $e_i$ at the first hidden\nlayer h\u2081. We compute the mean and standard deviation of the\n$L_2$-norm of the gradients across all environments as follows:\n$\\mu_j^{grad} = \\frac{1}{m} \\sum_{i=1}^{m} \\|\\nabla L_i^{jh_1}\\|_2$                                                                  (7)\n$\\sigma_j^{grad} = \\sqrt{\\frac{1}{m} \\sum_{i=1}^{m} (\\|\\nabla L_i^{jh_1}\\|_2 - \\mu_j^{grad})^2 }$                                                             (8)\nWe then calculate the consistency ratio, $C^{ratio}$ and the con-\nsistency mask, $C^{mask}$ for feature $X_j$ by following Eq. 4 and 5\nrespectively. All the weights that belong to a particular fea-\nture, $X_j$ in the first hidden layer h1, are updated by fol-\nlowing a similar strategy to Eq. 6. This updating strategy\nthat depends on the consistency ratio, ensures that only the\nfeatures that show consistency across the environments are\nconsidered to be updated. Otherwise, the weights remain un-\nchanged, effectively treating them as constants similar to the\nlinear implementation. For weights corresponding to the rest\nof the model other than the first hidden layer are updated as\nsimilar to ERM.\nIn both implementations, the goal is to ensure that the\nmodel relies on features that show invariance across differ-\nent environments. This leads to more robust and generaliz-\nable models by reducing dependency on spurious correla-\ntions."}, {"title": "Experiments and Results", "content": "We have considered three different major scenarios to as-\nsess the predictivity, robustness, and generalization capabil-\nities of CGLearn. The first two scenarios are the ones where\nwe considered linearly generated dataset-based experiments\nand in the last experimental case we have used the nonlin-\near implementation of CGLearn using multilayer perceptron\n(MLP) and applied it to different real world regression and\nclassification tasks.\nFor all evaluations, we reported the mean and standard\ndeviation of the performance metrics considered. For statis-\ntical significance tests, we used a t-test with a = 0.05 as the\nsignificance level."}, {"title": "Linear Multiple Environments", "content": "To evaluate the performance of our proposed CGLearn\nmethod, we generated synthetic linear datasets inspired by\nthe approach used in the Invariant Risk Minimization (IRM)\nframework (Arjovsky et al. 2019). Our goal was to create di-\nverse environments to test the robustness of our model under\nvarying conditions.\nWe generated eight different experimental setups based on\nthree key factors. Each setup included datasets with one tar-\nget variable Y and ten feature variables X\u2081 to X10. Features\nX1 to X5 acted as causal parents of Y, while X6 to X10 were\ninfluenced by Y (non-causal). First, we distinguished be-\ntween scrambled (S) and unscrambled (U) observations by\napplying an orthogonal transformation matrix S for scram-\nbled data and using the identity matrix I for unscrambled\ndata. This scrambling ensures that the features are not di-\nrectly aligned with their original scales, making the learning\ntask more challenging. Second, we designed fully-observed\n(F) scenarios where hidden confounders did not directly af-\nfect the features (i.e., no hidden confounder effects on fea-\ntures), and partially-observed (P) scenarios where hidden\nconfounders influenced the features with Gaussian noise.\nThird, we incorporated two types of noise for the target vari-\nable Y: homoskedastic (O) noise, where the noise variance\nremained constant across different environments, and het-\neroskedastic (E) noise, where the noise variance varied de-\npending on the environment, increasing with higher values\nof e. This distinction captures different real-world scenar-\nios where noise may or may not depend on external factors.\nFor each of these eight configurations (combinations of S/U,\nF/P, and O/E), we generated datasets corresponding to three\ndistinct environments defined by the values e \u2208 {0.2, 2,5}.\nEach dataset consisted of 1000 samples. To ensure consis-\ntency with the IRM methodology and experimental setup,\nwe used e = 5 as the validation environment and determined\nthe optimal consistency threshold ($C^{thresh}$) for our CGLearn\nmethod using the performance based on this validation data.\nWe selected the threshold $C^{thresh}$ from the candidate values\n{0.25, 1, 4, 16, 64} based on validation performance. This\nthreshold is critical for identifying the invariant and most\nreliable features across different environments. For more de-\ntails on the data generation process, we refer readers to the\nIRM paper (Arjovsky et al. 2019).\nWe compared the performance of CGLearn with Empir-\nical Risk Minimization (ERM), Invariant Causal Prediction\n(ICP) (Peters, B\u00fchlmann, and Meinshausen 2016), and IRM\n(Arjovsky et al. 2019). We considered 50 random trials and\nreported the results in Fig. 3. In most cases, our proposed\nmethod CGLearn achieves the lowest mean squared error\n(MSE), demonstrating superior performance across various\ntest cases to distinguish the causal and noncausal factors\nof the target by exploiting invariance across environments.\nIRM performs better than ERM but does not match the ac-\ncuracy of CGLearn. ERM shows the highest errors in most\ncases, as it fails to differentiate between causal and non-\ncausal features, relying on spurious correlations. Interest-\ningly, ICP performs well in noncausal scenarios but poorly\nin causal ones. This observation aligns with the findings\nfrom the IRM study (Arjovsky et al. 2019), which noted that\nICP's conservative nature leads it to reject most covariates\nas direct causes, resulting in high causal errors."}, {"title": "Linear Single Environment", "content": "To evaluate the performance of our proposed CGLearn\nmethod in scenarios with only one environment, we gener-\nated synthetic linear datasets without relying on multiple en-\nvironments as in previous experiments. For each of the eight\ncases, we used a single setting with e = 2. The data gener-\nation process was similar to the previous section, with each\ndataset consisting of 1000 samples and ten feature variables,\nX1 to X10. The first five features (X\u2081 to X5) acted as causal\nparents of the target variable Y, while the remaining five\nfeatures (X6 to X10) were influenced by Y. Given the single\nenvironment setup, we could not apply IRM and ICP meth-\nods, as they require multiple environments to distinguish be-\ntween causal and noncausal factors. Therefore, we compared\nour results solely with Empirical Risk Minimization (ERM).\nIn the case of CGLearn, we created multiple batches, with\nb = {3,5} representing the number of batches created from\nthe dataset. The last batch was used as the validation batch\nto determine the optimal consistency threshold parameter\n($C^{thresh}$). We selected the threshold $C^{thresh}$ from the candi-\ndate values {0.25, 1, 4, 16, 64} based on validation perfor-\nmance. We imposed gradient consistency across different\nbatches to learn consistent and reliable factors of the target."}, {"title": "Nonlinear Multiple Environments", "content": "For the nonlinear experimental setups, we considered two\ntypes of supervised learning tasks: regression and classifica-\ntion, both on real-world datasets. This approach allows us\nto evaluate the performance and robustness of our proposed\nCGLearn method in different real-world contexts. Recent\nwork has highlighted limitations in the original Invariant\nRisk Minimization (IRM) framework, particularly in non-\nlinear settings where deep models tend to overfit (Rosenfeld,\nRavikumar, and Risteski 2021). To address this, we included\nBayesian Invariant Risk Minimization (BIRM) as a baseline,\nwhich has been shown to alleviate overfitting issues by in-\ncorporating Bayesian inference and thereby improving gen-\neralization in nonlinear scenarios (Lin et al. 2022).\nIn the nonlinear implementation of\nCGLearn, we used a multilayer perceptron (MLP) to eval-\nuate its performance on real-world regression tasks, com-\nparing it with other baselines. For the regression tasks, we\nused the Boston Housing dataset (Harrison and Rubinfeld\n1978) and the Yacht Hydrodynamics dataset (Gerritsma, On-\nnink, and Versluis 2013). The Boston Housing dataset con-\nsists of 506 instances and 13 continuous attributes. It con-\ncerns housing values in suburbs of Boston, with the task be-\ning to predict the median value of owner-occupied homes\n(MEDV) based on attributes such as per capita crime rate\n(CRIM), proportion of residential land zoned for large lots\n(ZN), average number of rooms per dwelling, and etc. The\nYacht Hydrodynamics dataset consists of 308 instances and\n6 attributes. The task is to predict the residuary resistance\nper unit weight of displacement of a yacht based on various\nhull geometry coefficients and the Froude number, such as\nthe longitudinal position of the center of buoyancy, prismatic\ncoefficient, and beam-draught ratio.\nSince real-world datasets do not naturally come with dif-\nferent environments, we followed a similar approach to the\nstudy by Ge et al. (2022). We used the K-Means (Lloyd\n1982) clustering algorithm to generate diverse environments\nand determined the optimal number of environments (be-\ntween 3 to 10) using the Silhouette (Rousseeuw 1987)\nmethod. For each dataset, we created all possible test cases\nwhere each environment was considered as the test environ-\nment once, and the rest were used as training environments.\nWe averaged the results over all possible test cases and re-\npeated the process for 10 random trials. We evaluated the\nmodels based on RMSE, with the results shown in Table 2.\nFor the Boston Housing dataset, we found the optimal num-\nber of environments was 7, while for the Yacht Hydrody-\nnamics dataset, it was 5. From Table 2, we observe that all\nfour methods perform better on the training environments\nthan the test environments, as expected. However, CGLearn\nshows significantly lower error in the testing or unseen en-\nvironments compared to the other methods, demonstrating\nthat imposing gradient consistency leads to less dependence\non spurious features and thus better generalization.\nFor the classification tasks, we\nevaluated the performance on two real-world classification\ndatasets: the Wine Quality dataset for red and white wines\nfrom the UCI repository (Cortez et al. 2009). The Wine\nQuality dataset for red wine has 1599 instances and 11 at-\ntributes, while the dataset for white wine has 4898 instances\nand 11 attributes. The goal is to model wine quality based on\nphysicochemical tests, such as fixed acidity, volatile acidity,\ncitric acid, residual sugar, pH, and etc. Similar to the regres-\nsion tasks, we used K-means clustering to generate diverse\nenvironments and determined the optimal number of envi-\nronments using the Silhouette method, finding 4 as the opti-\nmal number of environments for both classification datasets.\nWe then generated all possible test cases where each envi-\nronment was considered the test environment once, and the\nrest were used as training environments (as we did with the\nregression tasks). We averaged the performance over all pos-\nsible test cases and conducted the process for 10 random tri-\nals. We used accuracy and F1-score as evaluation metrics,\nwith the results shown in Table 3. As expected, all methods\nperformed better in training environments compared to test\nenvironments. However, we found that CGLearn achieved\nhigher accuracy and F1-scores, which are desirable, and the\nsuperior performance was statistically significant for the F1-\nscore on the Wine Quality Red dataset. It also had signif-\nicantly better accuracy on the Wine Quality White dataset.\nSimilar to the regression tasks, CGLearn demonstrated bet-\nter predictive power and generalization over ERM, IRM, and\nBIRM for the classification tasks.\nWe evaluated CGLearn on the Colored MNIST\ndataset, a synthetic binary classification task derived from\nMNIST (LeCun et al. 1995) and proposed in the IRM\nstudy (Arjovsky et al. 2019). This dataset introduces color\nas a spurious feature that strongly correlates with the label\nin the training environments but has the correlation reversed\nin the test environment. We applied the nonlinear imple-\nmentation of CGLearn and compared it with the results of\nERM and IRM as reported in the IRM study (Arjovsky et al.\n2019). Over 10 trials, ERM achieved a training accuracy of\n87.4 \u00b1 0.2 and a test accuracy of 17.1 \u00b1 0.6, while IRM\nachieved a training accuracy of 70.8 \u00b1 0.9 and a test accuracy\nof 66.9 \u00b1 2.5. In our experimental study, CGLearn achieved\na training accuracy of 93.1 \u00b1 0.8 and a test accuracy of 29.1\n\u00b1 0.8. While CGLearn slightly outperformed ERM in the\ntest environment, it still struggled to generalize. This limita-\ntion arises because CGLearn imposes gradient consistency\non the training environments to distinguish invariant fea-\ntures from spurious ones. However, in the Colored MNIST\nsetup, the spurious feature (color) is consistent across both\ntraining environments, leading CGLearn to erroneously treat\nit as an invariant feature. Consequently, CGLearn relies on\ncolor and performs poorly in the test environment. To im-"}, {"title": "Conclusions", "content": "In this study, we presented CGLearn, a novel approach for\ndeveloping robust and predictive machine learning models\nby leveraging gradient consistency across multiple environ-\nments. By focusing on the agreement of gradients, CGLearn\neffectively identifies and utilizes invariant features, leading\nto superior generalization and reduced reliance on spurious\ncorrelations. Our extensive experiments on both synthetic\nand real-world datasets, including regression and classifi-\ncation tasks, demonstrated that CGLearn outperforms tradi-\ntional ERM and state-of-the-art invariant learners like ICP,\nIRM, and BIRM, achieving lower errors and better gener-\nalization in diverse scenarios. Notably, even in the absence\nof predefined environments, we demonstrated that CGLearn\ncan be effectively applied to different subsamples of data,\nleading to better predictive models than regular ERM. This\nflexibility enhances the applicability of CGLearn in a wide\nrange of real-world scenarios where many state-of-the-art\nmethods require diverse and defined environments for OOD\ngeneralization.\nDespite its strengths, CGLearn has limitations, partic-\nularly in scenarios where spurious features are invariant\nacross environments, as observed in the Colored MNIST ex-\nperiments. Such cases violate our assumption as generally\nwe expect and observe causal features to be stable and in-\nvariant in nature whereas spurious features do not (Wood-"}]}