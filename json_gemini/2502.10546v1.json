{"title": "Learning to be Smooth:\nAn End-to-End Differentiable Particle Smoother", "authors": ["Ali Younis", "Erik B. Sudderth"], "abstract": "For challenging state estimation problems arising in domains like vision and\nrobotics, particle-based representations attractively enable temporal reasoning\nabout multiple posterior modes. Particle smoothers offer the potential for more ac-\ncuate offline data analysis by propagating information both forward and backward\nin time, but have classically required human-engineered dynamics and observation\nmodels. Extending recent advances in discriminative training of particle filters, we\ndevelop a framework for low-variance propagation of gradients across long time\nsequences when training particle smoothers. Our \u201ctwo-filter\u201d smoother integrates\nparticle streams that are propagated forward and backward in time, while incor-\nporating stratification and importance weights in the resampling step to provide\nlow-variance gradient estimates for neural network dynamics and observation mod-\nels. The resulting mixture density particle smoother is substantially more accurate\nthan state-of-the-art particle filters, as well as search-based baselines, for city-scale\nglobal vehicle localization from real-world videos and maps.", "sections": [{"title": "1 Introduction", "content": "Global localization of the state of a moving vehicle using a city-scale map is challenging due to the\nlarge area, as well as the inherent ambiguity in urban landscapes, where many street intersections and\nbuildings appear similar. Recent work on global localization [1-11] has typically localized each time\npoint independently during training, sometimes followed by temporal post-processing, often with\ndemanding requirements like near-exact external estimation of relative vehicle poses [11].\nFor a broader range of state estimation problems in fields like vision and robotics, a number of\nmethods for end-to-end particle filter (PF) training have been proposed [8, 12-16]. Learnable PFs are\nsuitable for global localization because they can represent multi-modal posterior densities, propagate\nuncertainty over time, and learn models of real vehicle dynamics and complex sensors directly from\ndata. However, most learnable PF methods have only been applied to simulated environments [12-14],\nwith only a few preliminary applications to real-world data [8, 15].\nParticle filters [17-21] only use past observations to estimate the current state. For offline inference\nfrom complete time series, more powerful particle smoothing (PS) algorithms [22\u201327] may in\nprinciple perform better by integrating past and future data. But to our knowledge, recent advances in\nend-to-end differentiable training of PFs have not been generalized to the more complex PS scenario,\nrequiring error-prone human engineering of PS dynamics and observation models. Classical work on\ngenerative parameter estimation via PS [28] is limited to parametric models with few parameters. In\ncontrast, we develop differentiable PS that scale to complex models defined by deep neural networks."}, {"title": "2 Differentiable Particle Filters", "content": "Particle filters iteratively estimate the posterior distribution \\(p(x_t|Y_{1:t}, a_{1:t})\\) over the state \\(x_t\\) at discrete\ntime \\(t\\) given a sequence of observations \\(y_t\\) and, optionally, actions \\(a_t\\). PFs use a collection of\n\\(N\\) samples, or particles, \\(X_t = \\{x_t^{(1)}, ..., x_t^{(N)}\\}\\) with weights \\(W_t = \\{w_t^{(1)}, ..., w_t^{(N)}\\}\\) to flexibly\ncapture multiple posterior modes nonparametrically. Classic PFs are derived from a Markov generative\nmodel, leading to an intuitive recursive algorithm that alternates between proposing new particle\nlocations and updating particle weights. End-to-end training requires gradients for each PF step.\nParticle Proposals. At each iteration, new particles \\(x_t^{(i)}\\) are proposed by applying a model of the state\ntransition dynamics individually to each particle \\(x_t^{(i)} \\sim p(x_t |x_{t-1}^{(i)}, a_t)\\), conditioned on actions \\(a_t\\) if\navailable. Of note, only simulation of the dynamics model is required; explicit density evaluation is\nunnecessary. Using reparameterization [29-31], the dynamics model can be defined as a feed-forward\nneural network \\(f(\u00b7)\\) that transforms random (Gaussian) noise to produce new particles:\n\\(x_t^{(i)} = f(\\eta^{(i)}; x_{t-1}, a_t)\\), (1)\n\\(\\eta^{(i)} \\sim N(0, I)\\).\nMeasurement Updates and Discriminative Training. Proposed particles are importance-weighted\nby the likelihood function, \\(w_t^{(i)} \\propto p(y_t|x_t^{(i)}) w_{t-1}^{(i)}\\), to incorporate the latest observation \\(y_t\\) into the\nposterior. The updated weights are then normalized such that \\(\\sum_{i=1}^N \\omega_t^{(i)} = 1\\). However, for complex\nobservations like images or LiDAR, learning accurate generative models \\(p(y_t|x_t)\\) is extremely\nchallenging. Recent work [8, 12-15] has instead learned discriminative PFs parameterized by\ndifferentiable (typically, deep neural network) measurement models:\n\\(w_t^{(i)} \\propto l(x_t^{(i)}; y_t)w_{t-1}^{(i)}\\). (2)\nHere, \\(l(x_t; y_t)\\) scores particles to minimize a loss, such as negative-log-likelihood or squared-error,\nin the prediction of true target states \\(x_t\\) that are observed during training."}, {"title": "2.1 Particle Resampling", "content": "The stochastic nature of PF dynamics causes some particles to drift towards states with low pos-\nterior probability. These low-weight particles do not usefully track the true system state, wasting\ncomputational resources and reducing the expressiveness of the overall approximate posterior.\nParticle resampling offers a remedy by drawing a new uniformly weighted particle set \\(X_t^{(i)}\\) from\n\\(X_{t}\\), with each particle duplicated (or not) proportional to its current weight \\(w_t^{(i)}\\). The simplest"}, {"title": "2.2 Differentiable Approximations of Discrete Resampling", "content": "For discriminative PFs to effectively learn to propagate state estimates over time, gradients are needed\nfor all steps of the PF. While differentiable dynamics and measurement models are easily constructed\nvia standard neural-network architectures, discrete particle resampling is not differentiable.\nTruncated-Gradient Particle Filters (TG-PF) [15], the first so-called \u201cdifferentiable\" particle filter,\nactually treated the resampling step as non-differentiable and simply truncated gradients to zero at\nresampling, preventing back-propagation through time (BPTT) [36]. Due to this weakness, dynamics\nmodels were assumed known rather than learned, and measurement models were learned from biased\ngradients that fail to propagate information over time, reducing accuracy [14].\nSoft Resampling Particle Filters (SR-PF) [13] utilize a differentiable resampling procedure that sets\nparticle resampling weights to be a mixture of the true weights and a discrete uniform distribution:\n\\(x_t^{(i)} = x_{j^*}^{(i)}\\), (3)\n\\(j^* \\sim Cat(v_1, ..., v_N)\\),\n\\(v_t^{(i)} = (1 - \\lambda)w_t^{(i)} + \\frac{\\lambda}{N}\\).\nGradients are then propagated via the resampled particle weights defined as:\n\\(\\frac{\\partial \\mathcal{L}}{\\partial w_t^{(i)}} = \\frac{ \\partial \\mathcal{L}}{\\partial v_t^{(i)}} \\frac{\\partial v_t^{(i)}}{\\partial w_t^{(i)}} = \\frac{ \\partial \\mathcal{L}}{\\partial v_t^{(i)}} (1 - \\lambda)\\),\n\\(\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = \\sum_i \\frac{\\partial \\mathcal{L}}{\\partial v_t^{(i)}} \\frac{\\partial v_t^{(i)}}{\\partial \\lambda} = \\sum_i \\frac{\\partial \\mathcal{L}}{\\partial v_t^{(i)}} (\\frac{1}{N} - w_t^{(i)})\\).\nThis simple approach resamples low-weight particles more frequently, degrading performance. The\ngradients of Eq. (5) also have substantial bias, because they incorrectly assume model perturbations\nonly influence the particle weights in (5), and not the discrete particle resampling in (4).\nRelaxations of Discrete Resampling. While discrete particle resampling could potentially be\nreplaced by continuous particle interpolation with samples from a Gumbel-Softmax or Concrete\ndistribution [37, 38], no work has successfully applied such relaxations to PFs, and experiments\nin Younis and Sudderth [14] show very poor performance for this baseline. Alternatively, entropy-\nregularized optimal transport particle filters (OT-PF) [12] replace discrete resampling with an\nentropy-regularized optimal transport problem, that minimizes a Wasserstein metric to determine\na probabilistic mapping between the weighted pre-resampling particles and uniformly weighted\npost-resampling particle. OT-PF performance is sensitive to a non-learned entropy regularization\nhyperparameter, and the biased gradients induced by this regularization may substantially reduce\nperformance [14]. Furthermore, \u201cfast\u201d Sinkhorn algorithms [39] for entropy-regularized OT still\nscale quadratically with the number of particles, and in practice are orders of magnitude slower than\ncompeting resampling strategies. This makes OT-PF training prohibitively slow on the challenging\ncity-scale localization tasks considered in this paper, so we do not compare to it."}, {"title": "2.3 Mixture Density Particle Filters", "content": "Mixture Density Particle Filters (MDPF) [14] are a differentiable variant of regularized PFs [40, 41].\nMDPF estimates a continuous kernel state density [42] by convolving particles with a continuous,\nand differentiable, kernel function \\(K\\) (such as a Gaussian) with bandwidth hyperparameter \\(\\beta\\):\n\\(m(x_t | X_t, W_t, \\beta) = \\sum_{i=1}^N K(x_t - x_t^{(i)}; \\beta)\\). (6)\nParticles are then resampled \\(X_t^{(i)} \\sim m(x_t | X_t, W_t, \\beta)\\) from this continuous mixture instead\nof via discrete resampling. Unbiased and low-variance Importance Weighted Sample Gradient\n(IWSG) [14] estimates may then be constructed by viewing the particle proposal \\(q(z) = m(z | \\Phi_o)\\)\nto be fixed to the mixture model parameters \\(\\Phi_o = \\{X_t, W_t, \\beta\\}\\) at the current training iteration.\nGradients then account for parameter perturbations not by perturbing particle locations as in standard\nreparameterization [29-31], but by perturbing particle importance weights away from uniform:\n\\(\\nabla_{\\Phi} w^{(z)} = \\nabla_{\\Phi} \\frac{m(z^{(i)} | \\Phi)|_{\\Phi=\\Phi_o}}{m(z^{(i)} | \\Phi_o)} = \\nabla_{\\Phi} m(z^{(i)} | \\Phi)|_{\\Phi=\\Phi_o}\\), (7)\nWith this approach, the bandwidth parameter \\(\\beta\\) may also be tuned for end-to-end prediction of state\ndistributions, avoiding the need for classic bandwidth-selection heuristics [42\u201344]. An \u201cadaptive\" variant of MDPF [14] incorporates two bandwidths, one for particle resampling (to propagate\ninformation over time) and a second for estimation of state posteriors (to compute the loss). Our\nMDPS also incorporates separate bandwidths for resampling and state estimation, as detailed below."}, {"title": "3 From Filtering to Smoothing", "content": "Particle smoothers extend PFs to estimate the state posteriors \\(p(x_t|Y_{1:T})\\) given a full T-step sequence\nof observations. (To simplify equations, we do not explicitly condition on actions \\(a_{1:T}\\) in the\nfollowing two sections.) Particle smoothers continue to approximate posteriors via a collection of\nparticles \\(X_t^{(1:N)}\\) with associated weights \\(W_t^{(1:N)}\\), where we use bi-directional overhead arrows to\ndenote smoothed posteriors. Classical particle smoothing algorithms, which are non-differentiable\nand typically assume human-engineered dynamics and likelihoods, fall into two broad categories.\nForward-Filtering, Backward Smoothing (FFBS) algorithms [24, 25] compute \\(p(x_t|y_{1:T})\\) by\nfactoring into forward filtering and backward smoothing components:\n\\(p(x_t|Y_{1:T}) = \\int p(x_t, x_{t+1}|Y_{1:T})dx_{t+1} = \\frac{p(x_t|Y_{1:t}) p(Y_{t+1:T}|x_t)}{\\int p(x_t|Y_{1:t}) p(Y_{t+1:T}|x_t) dx_t} \\propto p(x_t|Y_{1:t}) p(Y_{t+1:T}|x_t)\\).\nforward filtering backward smoothing (8)\nA natural algorithm emerges from Eq. (8), where a conventional PF first approximates \\(p(x_t|Y_{1:t})\\) for\nall times via particles \\(X_t^{(1:N)}\\) with weights \\(W_t^{(1:N)}\\). A backward smoother then recursively reweights"}, {"title": "4 Mixture Density Particle Smoothers", "content": "Our novel Mixture Density Particle Smoother (MDPS, Fig. 1) can be seen as a differentiable TFS,\nwhere the forward and backward filters of Eq. (13) are defined as MDPFs (Sec. 2.3). Using discrim-\ninative differentiable particle filters (MDPFs) within the TFS frameworks, and replacing Eq. (14)\nwith an importance-weighted integration of forward and backward particles, enables an effective and\nend-to-end differentiable particle smoother. We begin by rewriting Eq. (13) as\n\\(p(x_t|Y_{1:T}) \\propto \\frac{p(y_t|x_t)p(x_t|Y_{1:t-1})p(x_t|Y_{t+1:T})}{v_t(x_t)}\\). (16)"}, {"title": "5 Experiments", "content": "We evaluate our MDPS on a synthetic bearings-only tracking task [14], as well as on real-world\ncity-scale global localization. For all tasks, we estimate the MDPF/MDPS posterior distributions of a\n3D (translation and angle) state \\(x_t = (x, y, \\theta)\\), using Gaussian kernels for the position dimensions,\nand von Mises kernels for the angular dimensions of the state posterior mixtures."}, {"title": "5.1 Bearings Only Tracking Task", "content": "To allow comparison to prior discriminative PFs, we use the same bearings-only tracking task as [14],\nwhere the 3D state of a variable-velocity synthetic vehicle is tracked via noisy bearings from a fixed-\nposition radar. 85% of observations are the true bearing plus von Mises noise, while 15% are uniform\noutliers. Train and evaluation sequences have length T = 50. Unlike Younis and Sudderth [14],\nwe find truncated BPTT [50] is not necessary if bandwidths are initialized appropriately. Filtering\nparticles are initialized as the true state with added Gaussian noise, while MDPF-Backward (and the\nMDPS backwards filter) are initialized with uniformly sampled particles to mimic datasets where\noften only the starting state is known. More details can be found in the Appendix.\nWe compare our MDPS methods to several existing differentiable particle filter baselines, but no\ndifferentiable particle smoother baseline exists. Instead, we implement the classic FFBS [24, 25]\nalgorithm (Sec. 3), which assumes known dynamics and measurement models. Since FFBS is not\ndifferentiable, we learn the dynamics model using the dataset true state pairs \\(\\{x_{t-1}, x_t\\}\\) outside of the\nFFBS algorithm. In order to simulate from and evaluate the state transition dynamics, as needed by\nthe FFBS, we parameterize the dynamics model to output a mean and use a fixed bandwidth parameter\n(tuned on validation data) to propose new particles. We also use the true observation likelihood as the\nmeasurement model, instead of a learned approximation; this boosts FFBS performance.\nResults. In Fig. 2 we show statistics of performance over 11 training and evaluation runs for each\nmethod. We compare to TG-PF [15], SR-PF [13], the classical FFBS [24, 25], and MDPF [14].\nInterestingly, MDPF outperforms SR-PF and TG-PF even when the initial particle set is drawn\nuniformly from the state space as in MDPF-Backward.\nBy incorporating more temporal data, MDPS substantially outperforms MDPF. Even when unfairly\nprovided the true observation likelihood, FFBS performs poorly since particles are simply re-weighted\n(not moved) by the backward smoother. This inflexibility, and lack of end-to-end learning, makes\nFFBS less robust to inaccuracies in the forward particle filter.\nWe are the first to compare resampling variants in the context of modern discriminative PFs. Stratified\nresampling substantially improves TG-PF and SR-PF performance, but only modestly improves the\nworst-performing MDPF runs. This may be because even with basic multinomial resampling, the\nlower-variance MDPF gradients dramatically outperform all TG-PF and SR-PF variants. Residual\nresampling performs worse than stratified resampling, and is also much slower since it cannot be\neasily parallelized on GPUs, so we do not consider it for other datasets."}, {"title": "5.2 City Scale Global Localization Task", "content": "Our global localization task is adopted from Sarlin et al. [11], where we wish to estimate the 3D state\n(position and heading) of a subject (person/bike/vehicle) as it moves through real-world city-scale\nenvironments. Observations are gravity-aligned first-person images, actions are noisy odometry, and\na 2D planimetric map is provided to help localize globally. We use the Mapillary Geo-Localization\n11] and KITTI [51] datasets to compare our MDPS method to MDPF [14] as well as other methods\nspecifically designed for the global localization task, which are not sequential Monte Carlo methods.\nOur global localization task is distinct from local localization systems, which aim to track subject\npositions relative to their starting position, instead of in relation to the global map origin. Visual\nSLAM systems [21] almost exclusively solve the local localization task, using the starting position as\nthe origin of their estimated map. If a map is provided, then just the localization part of Visual SLAM\ncan be run, but detailed visual or 3D maps of the environment are needed. These have prohibitive\nmemory requirements at city-scales, and need constant updating as the visual appearance of the\nenvironment changes (e.g., with the weather/seasons) [11]. Hybrid place recognition with localization"}, {"title": "5.3 Mapillary Geo-Localization (MGL) Dataset", "content": "In the Mapillary Geo-Localization (MGL) [11] dataset, images sequences are captured from handheld\nor vehicle-mounted cameras as a subject (person/bike/car) roams around various European and U.S.\ncities. Observations are set as 90\u00b0 Field-of-View images in various viewing directions, with actions\nbeing noisy odometry. A planimetric map of the environment is also provided via the OpenStreetMap\nplatform [54] at 0.5 meter/pixel resolution. We generate custom training, validation, and test splits to\ncreate longer sequences with T = 100 steps. For particle-based methods, we use stratified resampling\nand set the initial particle sets to be the true state with added noise. More details are in the Appendix.\nImplementation Details. For MDPF and our MDPS, we set the dynamics model to a multi-layer\nperceptron (MLP) network. The measurement model incorporates BEV features [11] and map\nfeatures as illustrated in Fig. 1. The smoother measurement model incorporates additional inputs via\nan extra MLP. Memory constraints prevent Dense Search in city-scale environments, so we consider\ntwo methods to limit the search space. A sliding window limits the search space to a 256m \u00d7 256m\narea that is recursively re-centered around the best position estimate at t \u2212 1, propagated to t using\nat. We can also limit the search space to a 256m \u00d7 256m area containing the true state, though this\nartificially increases performance. We similarly limit the search space for Retrieval, which performs\npoorly in large environments; Zhou et al. [8] even limit the vector search to known road networks.\nResults. We compare our MDPS to MDPF [14], Dense Search [11], Retrieval [3] implemented as\ndetailed by [11], and Retrieval (PF) [8], reporting the position and rotation recall in Fig. 3. Due\nto ambiguity in large city environments (e.g., intersections can look very similar), estimated state\nposteriors can be multi-modal and thus simply reporting accuracy using the highest\nprobability mode does not fully characterize performance. We thus also extract the top-three modes\nusing non-maximal suppression, and report accuracy of the best mode. Interestingly,\nMDPF and MDPS give dramatic improvements over baselines engineered specifically for this task,\nhighlighting the usefulness of end-to-end training. MDPS outperforms MDPF by using the full\nsequence of data to reduce mode variance, and discard incorrect modes as illustrated in Fig. 4."}, {"title": "5.4 KITTI Dataset", "content": "We also evaluate our MDPS method for the global localization task using the KITTI [51] dataset,\nwhere observations are forward-facing camera images from a moving vehicle. We augment this\ndatatset with noisy odometry computed from the ground truth states and use the default Train, Test1,\nand Test2 splits for training, validation, and evaluation respectively. Like MGL, a planimetric map of\nthe environment is provided via the OpenStreetMap platform [54] at 0.5 meter/pixel resolution. Due\nto the small size of the KITTI dataset, we pre-train all methods using MGL before refining on KITTI,\nusing the same network architectures as was used for the MGL dataset. See Appendix for details.\nResults. Due to the forward-facing camera, the observation images lack visual features for useful\nlocalizing along the roadway, therefore we decouple the position error into lateral and longitudinal\nerrors when reporting recalls in Fig. 6. Understandably, all methods have larger longitudinal error\nthan lateral error. Interestingly, MDPF and MDPS offer similar Top 3 mode performance for small\nlateral errors (under 2 meters) while significantly outperforming all other methods. When the lateral\nerror is greater than 2 meters, MDPS sees a performance gain as it maintains a more diverse set of\nposterior modes, whereas MDPF prematurely collapses the posterior density to incorrect modes."}, {"title": "5.5 Limitations", "content": "Like all particle-based methods, our MDPS suffers from the curse of dimensionality [55] where\nparticle sparsity increases as the dimension of the state space increases, reducing expressiveness of\nstate posteriors. More effective use of particles via smarter dynamics and measurement models, as\nenabled by end-to-end MDPS training, can reduce but not eliminate these challenges."}, {"title": "6 Discussion", "content": "We have developed a fully-differentiable, two-filter particle smoother (MDPS) that robustly learns\nmore accurate models than classic particle smoothers, whose components are often determined via\nheuristics. MDPS successfully incorporates temporal information from the past as well as the future\nto produce more accurate state posteriors than state-of-the-art differentiable particle filters. When\napplied to city-scale global localization from real imagery, our learned MDPS dramatically improves\non search and retrieval-based baselines that were specifically engineered for the localization task."}]}