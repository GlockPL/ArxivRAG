{"title": "END-TO-END OPTIMIZATION AND LEARNING OF FAIR COURT\nSCHEDULES", "authors": ["My H. Dinh", "James Kotary", "Lauryn P. Gouldin", "William Yeoh", "Ferdinando Fioretto"], "abstract": "Criminal courts across the United States handle millions of cases every year, and the scheduling of\nthose cases must accommodate a diverse set of constraints, including the preferences and availability\nof courts, prosecutors, and defense teams. When criminal court schedules are formed, defendants'\nscheduling preferences often take the least priority, although defendants may face significant con-\nsequences (including arrest or detention) for missed court dates. Additionally, studies indicate that\ndefendants' nonappearances impose costs on the courts and other system stakeholders. To address\nthese issues, courts and commentators have begun to recognize that pretrial outcomes for defendants\nand for the system would be improved with greater attention to court processes, including court\nscheduling practices. There is thus a need for fair criminal court pretrial scheduling systems that\naccount for defendants' preferences and availability, but the collection of such data poses logistical\nchallenges. Furthermore, optimizing schedules fairly across various parties' preferences is a complex\noptimization problem, even when such data is available. In an effort to construct such a fair scheduling\nsystem under data uncertainty, this paper proposes a joint optimization and learning framework that\ncombines machine learning models trained end-to-end with efficient matching algorithms. This\nframework aims to produce court scheduling schedules that optimize a principled measure of fairness,\nbalancing the availability and preferences of all parties.", "sections": [{"title": "1 Introduction", "content": "Criminal courts across the United States handle millions of cases every year, and scheduling these cases must accommo-\ndate a diverse set of constraints, including the preferences and availability of courts, prosecutors, and defense teams.\nTypically, defendants' scheduling preferences receive the least priority, despite the significant consequences they may\nface-such as arrest, detention, or other penalties\u2014for missed court dates.\nEnsuring that defendants return to court for trial and all pretrial appearances has shaped pretrial decision-making\nfor centuries. Pretrial appearance rates vary across jurisdictions, but studies suggest that most defendants appear for\ntheir pretrial hearings as required [1\u20133]. Nevertheless, criminal defendants still fail to appear for court in significant\nnumbers. These nonappearances impose costs on the courts and other system stakeholders. Demographic factors like\nrace, gender, or age have been shown in prior studies to impact nonappearance rates, but those impacts are not consistent\nacross studies [4]. The factor most closely and consistently associated with nonappearance-across other demographic\nfactors-is indigence [4]."}, {"title": "2 Related Work", "content": "Court scheduling. Court scheduling refers to the process of organizing the court's calendar and scheduling cases at\nthe appropriate time, location, and format for all necessary participants. It is a fundamental function of the judicial\nsystem and effective court scheduling takes into account available resources, participant schedules, and due process\nrequirements [6, 7]. Despite its critical role, however, court scheduling remains largely understudied [1]. Most existing\nresearch focuses on the efficacy of court reminder systems or primarily aims to improve pretrial outcomes for individual\ndefendants [2,5].\nThis work addresses these gaps by evaluating the current processes used by court personnel to establish court schedules\nand proposing data-driven improvements. Numerous factors create barriers to innovation in this context: Courts adhere\nto tradition and to formal, hierarchical structures that hinder efforts to streamline court scheduling [8, 9]. Additionally,\ndue process requirements and the adversarial nature of the criminal process pose significant barriers to change. The\ninherent complexity of the judicial process itself is a considerable hurdle to innovation [8]. Effective scheduling must\naccount for multiple factors, including the availability of judges, defendants, attorneys, and courtrooms. The complex\nlandscape leads to hesitancy among administrators, who may prefer maintaining the status quo over implementing\npotentially disruptive changes. Consequentially, the court system is marked by significant inefficiencies, causing delays\nand backlogs that can affect the delivery of justice. Moreover, the lack of data regarding court scheduling practices\nposes a major hurdle to reform efforts. Addressing these issues is crucial for developing a more efficient and effective\ncourt scheduling system.\nAdvances in Machine Learning and Optimization for scheduling. Scheduling is fundamentally a combinatorial\noptimization problem. In the context of court scheduling, where defendants' preferences are unknown a priori but\nessential for the optimization process, the scheduling problem typically relies on predictions from a machine learning\nmodel. This model forecasts defendants' scheduling preferences based on predefined features such as the defendant's\njob, access to transportation, and childcare obligations. This approach falls under the general area of constrained\noptimization informed by machine learning predictions, commonly referred to as a two-stage process or predictive and\nprescriptive processes. However, this two-stage approach has been shown to lead to suboptimal outcomes. The primary\nissue arises from the misalignment between prediction errors and the final task utilities, which, in the case of this paper,\naccount for the effectiveness and fairness of the court schedule. Since the prediction model is trained independently of\nthe optimization task, inaccuracies in predicting defendants' preferences can directly impact the quality of the resulting\nschedule. This separation means that the optimization process does not account for how prediction errors might affect\nthe overall utility, leading to schedules that may not optimally balance fairness and efficiency.\nRecent literature has sought to address these limitations by developing constrained optimization models that are trained\nend-to-end with machine learning models [10]. In the Predict-Then-Optimize setting, a machine learning model"}, {"title": "3 Motivations and Problem Setting", "content": "Scheduling defendants in pretrial processes involves arranging their court appointments in a way that aligns with\ntheir preferences for various appointment times. In this context, a defendant's preference indicates their likelihood\nof attending a scheduled appointment. A significant challenge is that these preference data are often unavailable,\nnecessitating estimation from available data to create meaningful schedules. This challenge can be partially addressed\nby employing a pipeline where a machine learning (ML) model predicts defendants' preferences, which are then used\nas inputs for the scheduling task, as illustrated in Figure 1.\nA common scheme in data-driven decision processes is to treat the learning and optimization components of this\npipeline separately, where an ML model is first trained via a measure of predictive accuracy, and then its predictions\nare used to inform a decision-making task. Such 'two-stage' approaches are justified when the predictive models are\nnear-perfect since accurate predictions tend to inform the correct decisions. However, in practice, predictive models\nare rarely perfect, especially when preference data are limited or incomplete. The resulting prediction errors can\nlead to suboptimal scheduling outcomes, where the generated schedules fail to fully align with the defendants' actual\npreferences. Moreover, these prediction inaccuracies can exacerbate unfairness in the scheduling process, as errors\nmay disproportionately affect certain groups of defendants, leading to biased or inequitable scheduling outcomes [10].\nThese effects are significant and, if not mitigated, can lead to a \"poor get poorer\" effect with significant societal\nconsequences. To mitigate these disparate impacts, this paper proposes an integrated optimization and learning\nframework for scheduling defendant court visit times to certify a desired fairness requirement.\nProblem Setting\nThe setting studied in this paper considers a training dataset $D = \\{(x_p,g_p, Y_p)\\}_{p=1}^N$ of $N$ elements, each describing\na pool of $n$ defendants to be scheduled on a given day. For each pool indexed by $p \\in [N]$, $x_p \\in X$ describes a list\n$\\(x_i^p\\)_{i=1}^n$ of $n$ defendants to schedule, with each item $x_i^p$ defined by a feature vector. These feature vectors encode\nrepresentations of the individuals to schedule, e.g., their socioeconomic identifiers, addresses, and accusations. The\nelements $g_p = \\(g_i^p\\)_{i=1}^n$ describe protected group attributes of the defendants in some domain $G$. For example, they may\ndenote employment type, whether the defendant has access to transportation, or whether they have childcare obligations.\nTogether, the unprotected and protected attributes $\\(x_i^p, g_i^p\\)$ provide a description of the defendant's $i$ characteristics in\npool $p$. Finally, the element $Y_p \\in Y \\subseteq \\mathbb{R}^{n \\times n}$ are supervision labels $\\(Y_{ij}^p\\)_{i,j=1}^n$ that associate a vector of non-negative"}, {"title": "4 Preliminaries: Fair OWA Aggregation", "content": "The Ordered Weighted Average (OWA) operator [29] is a class of functions used for aggregating multiple independent\nvalues in settings requiring multicriteria evaluation and comparison [30]. Let $y \\in \\mathbb{R}^m$ be a vector of $m$ distinct criteria,\nand $\\tau : \\mathbb{R}^m \\rightarrow \\mathbb{R}^m$ be the sorting map in increasing order so that $\\tau_1(y) \\leq \\tau_2(y) \\leq \\ldots \\leq \\tau_m(y)$.\nThen for any w satisfying\n$w \\in \\mathbb{R}^m | \\sum_{i=1}^m w_i = 1, w_i \\geq 0 \\$,\nthe OWA aggregation with weights w is defined as a linear functional on $\\tau(y)$:\n$OWAw(y) = w^T \\tau(y),$                                                                                                                                 (4)\nwhich is piecewise-linear in y [28].\nThis paper focuses on a specific instance of OWA, commonly known as Fair OWA [31], characterized by weights\narranged in descending order: $w_1 > w_2 ... > w_n > 0$. Note that with monotonic weights, Fair OWA is also concave.\nFair OWA objectives are increasingly popular in optimization as fairness gains attention in decision-making processes.\nThe following three properties of Fair OWA functions are crucial for their use in fairly optimizing multiple objectives:\n1.  Impartiality ensures that Fair OWA treats all criteria equally. This means that for any permutation $\\sigma \\in P_m$,\n    where $P_m$ is the set of all permutations of $\\{1, ..., m\\}$, the OWA aggregation with weights w yields the same\n    result for any permutation of the input vector y.\n2.  Equitability guarantees that marginal transfers from a criterion with a higher value to one with a lower value\n    increase the OWA aggregated value. This condition holds that $OWAw(y^\\epsilon) > OWAw(y)$, where $y^\\epsilon = y$\n    except at positions i and j where $(y^\\epsilon)_i = y_i - \\epsilon$ and $(y^\\epsilon)_j = y_j + \\epsilon$, assuming $Y_i > Y_j + \\epsilon$.\n3.  Monotonicity ensures that $OWAw(y)$ is an increasing function of each element of y. This property implies\n    that solutions optimizing the OWA objectives (4) are Pareto Efficient solutions of the underlying multiobjective\n    problem, thus no single criteria can be raised without reducing another [28].\nThis last aspect is crucial in optimization, where Pareto-efficient solutions are preferred over those that do not possess\nthis attribute. Taken together, these properties define a notion of fairness in optimal solutions known as equitable\nefficiency [28], which is of particular interest for the pretrial court scheduling optimization.\nIntuitively, OWA objectives lead to fair optimal solutions by always assigning the highest weights of w to the objective\ncriteria in order of lowest current value. This paper employs fair OWA functions as a fair measure of overall utility\nwith respect to defendants' preferences, ensuring that the resulting court schedules uphold principles of fairness and\nequity. As shown in the next section, while achieving these properties is desirable for court schedules, it also introduces\na challenging optimization problem over the space of permutation matrices. Addressing such computational challenges\nis one of the key technical objectives of the paper."}, {"title": "5 Fair Optimization of Court Schedules", "content": "Using the concepts introduced above, we can form an optimization program which models fair maximization of utilities\nin court schedules. Suppose a pool of defendants is described by $(x, g, Y)$, where the preference values $Y$ are known."}, {"title": "5.1 Group Fairness", "content": "The objective in problem (5) is to maximize the OWA-aggregated utility vector with respect to each individual defendant.\nWe may also extend the use of the OWA operator to model different fairness objectives within our framework. In\nparticular, we are interested in group fairness, a concept widely employed, for example, in web search rankings [32-36].\nIn the notation of Section 3, each pool of defendants is described by data $(x_p, g_p, Y_p)$, where $g_p$ indicates the protected\ngroup of each defendant in the pool. Individuals may grouped by any category between which fair outcomes are desired:\nfor example by gender, race, socioeconomic status or intersections thereof. For any schedule II we define the group\nutility $u^g$ of group g as the mean utility of all defendants in that group. For any group indicator g, let $S_g$ be the set of\ndefendants' indices belonging to that group. Then\n$u^{g}(\\Pi, Y) = \\frac{1}{\\|S_g\\|} \\sum_{i\\in S_g} Y_i \\Pi,$                                                                                                                                                  (6)\nLet a partition $G = \\{g : p \\in [N], i \\in [n]\\}$ represent the set of all unique protected group indicators (e.g. male and\nfemale, or the set of all income brackets). Our notion of group fairness is to maximize the OWA aggregation of all\ngroup utilities over a chosen partition. Letting $u^G$ be the vector of all group utilities $\\{u^g : g \\in G\\}$,\n$\\Pi^*(Y) = argmax_{\\Pi} OWA_w \\(u^{G}(\\Pi, Y) \\)$                                                                                                 (7a)\nsubject to:  $\\Pi\\in \\{0,1\\}^{n \\times n}$                                                                                                            (7b)\n$\\sum_i \\Pi_{ij} = 1, \\forall j \\in [n]$                                                                                                           (7c)\n$\\sum_j \\Pi_{ij} = 1, \\forall i \\in [n].$                                                                                                             (7d)\nOf course, the models (7) and (5) coincide when each individual defendant constitutes their own group. In Section 7,\nwe will evaluate the ability of our framework to fairly optimize group utilities with respect to various partitions."}, {"title": "5.2 Complexity of the Optimization Models", "content": "It is important to remark on the complexity of the integer program (7). Since the OWA function is piecewise linear [28],\nthey can be categorized as nonlinear integer programs with a piecewise-defined objective and is thus NP-hard. Given the\nform of this integer program, traditional integer programming approaches cannot be applied directly to (7). Specifically,\nmethods such as branch-and-bound and cutting plane algorithms, which are commonly used for solving integer linear\nprograms (ILPs), struggle with the piecewise linear nature of the OWA objective. These ILP approaches typically\nrely on linearity and convexity to efficiently explore the solution space, but the nonlinear, piecewise-defined objective\ncomplicates the feasible region and increases the computational burden.\nFurthermore, optimizing a schedule for n defendants requires $n^2$ integer variables, causing the size of the program to\ngrow quadratically with the size of the scheduling pool. This scalability issue makes exact solutions impractical for large\ninstances due to excessive memory and time requirements. Thus, an important aspect of our integrated optimization and\nlearning framework, described in the next section, is to avoid solving (7) directly directly."}, {"title": "6 Optimization and Learning for Fair Court Schedules", "content": "Problem (7) formalizes our fair scheduling problem as an optimization program that depends on unknown preference\ncoefficients Y. To address the absence of direct preference data, our approach involves learning these unknown\npreferences from available contextual information (e.g., the defendant features $x_p$) using a neural network. Recall\nfrom Section 3 that available training data consist of $D = \\{(x_p,g_p, Y_p)\\}_{p=1}^N$, where predictors $x_p$ are known but $Y_p$ are\nunknown at test time.\nA straightforward combined prediction and optimization model trains a neural network $M_\\Theta$ with weights $\\Theta$ to predict\nY from x, by minimizing the squared residuals of its predictions:\n$\\frac{1}{N} \\sum_{p=1}^N min_{\\Theta} \\|M_{\\Theta}(x_p) - Y_p\\|^2 .$                                                                                                                              (8)\nWith this approach, problem (7) can be approximately specified by replacing Y with $M_{\\Theta}(x)$ in (7a). It can then be\nsolved assuming a suitable solution method. However, this \u201ctwo-stage\" approach faces two major challenges:\n1.  Scalability issues: As discussed in the previous Section, problem (7) is an NP-hard nonlinear integer program\n    whose size grows quadratically with the number of defendants. Thus an approach based on solving (7) will\n    lack scalability.\n2.  Misaligned training objective: The training objective (8) considers only the squared residuals of the predicted\n    preference values, rather than the utility (7a) of the resulting downstream scheduling decisions. This separation\n    can lead to suboptimal scheduling outcomes because the model optimizes for prediction accuracy rather than\n    the final scheduling utility. A substantial body of literature has demonstrated the benefits of training models to\n    directly optimize the end-task objective, as discussed in Section 2.\nMotivated by these challenges, we propose an accurate and efficient alternative to the two-stage prediction and\noptimization method described above. Rather than training to minimize error in the preference values from their\nground-truths as in (8), our model is trained to directly maximize the OWA value of predicted schedules under the\nground-truth preference values. This requires computation of an optimal schedule as a function of preference values\nduring each training iteration and performing backpropagation through the optimization process"}, {"title": "6.1 End-to-End Trainable Scheduling Model", "content": "The proposed end-to-end trainable scheduling model consists of three main components:\n1.  A neural network $M_\\Theta$, which maps known features $x_p$ to predicted preferences $\\hat{Y} = M_\\Theta(x_p)$.\n2.  A differentiable module $\\Pi$ that maps $\\hat{Y}$ to a predicted permutation matrix $\\Pi(\\hat{Y})$, which satisfies constraints\n    (7b)-(7d).\n3.  A loss function which allows training of $M_\\Theta$ to optimize the objective $OWA_w \\(u^{G}(\\Pi(\\hat{Y}), Y_p )\\)$ expressed\n    in (7a) by gradient descent.\nComposed of these elements, the resulting end-to-end ML and optimization training objective is:\n$\\frac{1}{N} max_{\\Theta} \\sum_p OWA_w \\(u^{G}(\\Pi(M_{\\Theta}(x_p)), Y_p) \\) .$                                                                                                        (9)\nA comparison of (9) with (7) highlights the motivation for this architecture: Gradient descent on the empirical objective\n(9) causes $M_\\Theta$ to learn predictions $\\hat{Y}$ which yield the permutations $\\Pi(\\hat{Y})$ that solve (7) for $\\Pi^*(Y_p)$, given features $x_p$.\nThus, the resulting composite mapping $\\Pi \\circ M_\\Theta$ fulfills our goal of a model which predicts schedules that solve the fair\nscheduling problem (7) without direct knowledge of preference data Y!\nWhat remains is to determine efficient and differentiable implementations of the module $\\Pi$ and loss function $OWA_w$,\nto enable backpropagation for gradient descent training of (9)."}, {"title": "6.2 Differentiable Matching Layer", "content": "Our proposed fair scheduling model relies on a module $\\Pi(\\hat{Y})$ which maps preference data to permutation matrices.\nNote that (7) is one such mapping. However, it is neither efficient to compute nor differentiable, thus unsuitable for"}, {"title": "6.3 OWA as a Loss Function", "content": "To enable gradient descent training for (9), the final element to be specified is a method for backpropagating the OWA\nloss function. Although the OWA is not differentiable, it is subdifferentiable with known subgradients [32]:\n$\\frac{\\partial}{\\partial x} OWA_w(x) = w_{(\\sigma^{-1})},$                                                                                                                                                  (11)\nwhere $\\sigma$ is the sorting permutation for x. Our main approach is to implement subgradient descent training for (9) using\nthe formula (11). However, we also investigate the use of an alternative gradient rule in this paper. For any convex\nfunction f, the Moreau envelope $f_\\beta$ is a smooth lower-bounding function with the same minimum:\n$f_{\\beta}(x) = min_v f(v) + \\frac{1}{2 \\beta} \\| v-x \\|^2 .$                                                                                                                              (12)\nIt is proven in [32] that the gradient of OWA's Moreau envelope is equal to the projection of a vector x onto the\npermutahedron $\\mathbb{C}(w)$ induced by the OWA weights w:\n$\\frac{\\partial}{\\partial x} f_{\\beta} OWA(x) = proj_{\\mathbb{C}(w)} (\\frac{x}{\\beta} ).$                                                                                                                      (13)\nThus in Section 7, we evaluate an additional training of (9), using OWA's Moreau envelope as a differentiable loss\nfunction. We implement (13) using isotonic regression following [16]. Both (11) and (13) have the same computational\ncomplexity, driven by the sorting operation, which is $O(n \\log n)$ ."}, {"title": "7 Experimental Settings", "content": "To validate the effectiveness of our proposed integrated optimization and learning framework for fair court scheduling,\nwe conduct a series of experiments on court scheduling using a novel synthetic dataset. We first focus on the approach\nadopted to generate the synthetic preference data for court scheduling."}, {"title": "7.1 Data Generation Process", "content": "The experiments simulate realistic court scheduling scenarios by creating a causal graph that models the data generation\nprocess, incorporating individuals' preferences, socioeconomic status, and demographic characteristics. This causal\ngraph, depicted in Figure 3, illustrates the relationships among these factors. Each feature is treated as a categorical\nvariable, generated based on the conditional probabilities detailed in Appendix A, which are elicited by combining,\ninterviewing court scheduling experts with Census data.\nTo emulate a scenario requiring fair scheduling, we generate individuals' preferences to predominantly favor specific\ntime slots. For example, individuals reliant on public transportation, those working night shifts, or those with childcare\nresponsibilities are more likely to prefer morning slots (8-12 AM). Each individual's preference vector $y_i$ is generated\nunder the constraints that $\\sum_j Y_{ij} = 1$ and $0 \\leq Y_{ij} \\leq 1$. Additionally, we assume that each individual has three top\nchoices among all possible time slots, ranked from highest to lowest priority. The second and third choices are set to\none hour before and one hour after the primary choice, respectively. This setup ensures that when specific time slots\nhave limited availability, individuals' second or third preferences are considered, promoting fairness and flexibility in\nscheduling."}, {"title": "7.2 Model Settings and Evaluation Metrics", "content": "Settings. A feedforward neural network $M_\\Theta$ is trained to predict for a pool of n candidates, given features x, their\npreference scores $Y \\in \\mathbb{R}^{n \\times n}$ for n available slots. The network consists of two hidden layers, where the size of each"}, {"title": "8 Results", "content": "In this section, we present the results of our experiments evaluating the performance of our proposed integrated\noptimization and learning framework for fair court scheduling. We compare the performance of three models in each\nevaluation setting:\n1.  Two-Stage MSE Loss: The traditional two-stage model trained using Mean Squared Error (MSE) loss without\n    considering downstream optimization.\n2.  OWA Loss Decision Quality (DQ): Our proposed end-to-end model trained to directly optimize the OWA\n    objective, integrating the prediction and optimization stages.\n3.  Total Utility (TU) Loss: An end-to-end model trained to maximize the total utility without incorporating the\n    OWA fairness considerations."}, {"title": "8.1 OWA Utility Regret", "content": "Figure 4 illustrates the OWA regret (expressed as a percentage) across four different fairness settings: individual\nfairness, employment status, transportation accessibility, and work hours. The evaluation is conducted on a training\ndataset consisting of N = 4000 samples. The OWA regret measures the loss of optimality relative to the ground truth\npreferences, with lower values indicating better alignment with the optimal solution.\nAcross all fairness settings, the OWA Loss DQ model consistently achieves the lowest regret values, indicating superior\nperformance in minimizing the loss of optimality. Specifically, it attains regret values of less than 10% in the individual\nfairness and employment status settings, and 11% and 12.5% in the work hours and transportation accessibility settings,\nrespectively.\nThe Two-Stage MSE Loss and TU Loss models exhibit similar performance, with the Two-Stage method slightly\noutperforming the TU Loss method in certain settings. For instance, the Two-Stage model shows improvements of 0.9%\nand 0.4% over the TU Loss model in the employment status and transportation accessibility contexts, respectively.\nGenerally, end-to-end learning approaches, such as the OWA Loss DQ and TU Loss models, tend to deliver better\nperformance than two-stage methods, as they integrate prediction and optimization into a unified framework. However,\nwhen the training dataset is sufficiently large, the Two-Stage MSE Loss approach demonstrates its capability to\neffectively minimize decision quality loss due to the abundance of data improving prediction accuracy.\nNotably, our OWA Loss DQ model performs significantly better in the employment status and transportation accessibil-\nity settings, achieving improvements of 7% and 5.2%, respectively, compared to the TU Loss model. Furthermore, the\nOWA Loss DQ outperforms the Two-Stage MSE Loss method by margins of 6.1% and 4% in these settings.\nIn contrast, the performance gains in the individual fairness and work hours settings are smaller, with improvements of\nonly 1.5% and 3.6%, respectively. This variation in performance suggests that the effectiveness of the models may\ndepend on the characteristics of the dataset and the specific fairness constraints involved."}, {"title": "8.2 Normalized Pairwise Difference", "content": "To comprehensively evaluate the fairness of our scheduling models, we utilize the Normalized Mean Pairwise Difference\n(NMPD) metric. Figure 6 presents the NMPD values across various fairness settings, including employment status,\ntransportation accessibility, and work hours.\nFairness performance across settings. Across all fairness settings, the NMPD values remain relatively low, typically\nbelow 0.08. This indicates that the models maintain a high degree of fairness by ensuring consistent treatment of\nindividuals, with minimal differences in outcomes. Specifically:\n\u2022 End-to-End Models: Both the OWA Loss DQ and TU Loss models exhibit consistently low NMPD values\n across all settings, demonstrating their effectiveness in promoting equitable treatment. Our proposed frame-\n work, OWA Loss DQ model, consistently outperforms the TU Loss model, achieving lower NMPD values\n and thereby ensuring greater fairness.\n\u2022 Two-Stage MSE Loss: This traditional approach shows slightly higher NMPD values, particularly in the work\n hours and transportation accessibility settings. This suggests that the two-stage method is less effective in\n maintaining fairness in these areas compared to the end-to-end models."}, {"title": "8.3 Running Time", "content": "Figure 8 presents the runtime comparison of two optimization models for the court scheduling problem: OWA-ILPs\ncorresponding to Problem (7), and theMatching Layer representing Problem (10).\nThe x-axis denotes the number of group partitions, while the y-axis indicates the average time (in seconds) required\nto solve the scheduling problem for each sample pool, averaged over N = 1000 runs. As detailed in Section 5,\nsolving Problem (7) involves addressing an Integer Linear Program (ILP). ILPs are computationally intensive and\nface significant scalability challenges as the number of group partitions increases due to the exponential growth of\nconstraints. This scalability issue is clearly illustrated in Figure 8, where the runtime for OWA-ILPs grows polynomially\nwith the number of partitions, rendering it impractical for large-scale scheduling tasks.\nIn contrast, the Matching Layer uses a linear optimization approach, dramatically improving computational efficiency.\nThe runtime for the Matching Layer scales linearly with the number of partitions, as shown in Figure 8. For example,\nwhen set to 12 partitions, the Matching Layer solves the scheduling problem in just 0.002 seconds. This linear scalability\nmakes the Matching Layer ideal for real-time and large-scale court scheduling applications where quick decision-making\nis essential.\nThe stark difference in runtime performance between the two models highlights the technical advantage of the Matching\nLayer over traditional ILP-based approaches. By leveraging linear optimization techniques and exploiting problem-\nspecific structures, the Matching Layer not only reduces computational burden but also facilitates the integration of\nfairness objectives into the scheduling process without sacrificing efficiency. This makes it a highly effective solution\nfor practical court scheduling systems that require both fairness and scalability."}, {"title": "9 Conclusions", "content": "This paper addressed the critical problem of fair court scheduling in pretrial processes. Scheduling defendants' court\nappearances in a manner that is both efficient and fair is essential for upholding justice and maintaining public trust in\nthe legal system. The challenge lies in aligning court schedules with defendants' preferences, which are often unknown\nand must be predicted from available data, while ensuring that the scheduling process adheres to fairness principles to\nprevent systemic biases and disparate impacts on different groups.\nTo address these key challenges this paper proposed an integrated optimization and learning framework that combines\nmachine learning with Fair Ordered Weighted Average (OWA) optimization. Unlike traditional two-stage approaches\nthat handle prediction and optimization separately, our method integrates the prediction of defendants' preferences with\nthe scheduling optimization process. This integration allows for direct optimization of scheduling utility under fairness\nconstraints, leading to more equitable and efficient scheduling outcomes.\nThrough extensive experiments, we demonstrated that our integrated framework outperforms baseline models in terms of\nboth scheduling optimality and fairness across various scenarios. Our results highlight the effectiveness of incorporating\nfairness objectives into the learning process, particularly in complex settings with competing group preferences. We\nbelieve that this work could pave the way for the utilization of Fair OWA in learning pipelines, enabling a wide range of\ncritical multi-optimization problems across various domains that extend beyond scheduling applications."}]}