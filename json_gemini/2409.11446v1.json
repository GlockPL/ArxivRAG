{"title": "Volvo Discovery Challenge at ECML-PKDD 2024", "authors": ["Mahmoud Rahat", "Peyman Sheikholharam Mashhadi", "S\u0142awomir Nowaczyk", "Shamik Choudhury", "Leo Petrin", "Thorsteinn Rognvaldsson", "Andreas Voskou", "Carlo Metta", "Claudio Savelli"], "abstract": "This paper presents an overview of the Volvo Discovery Challenge, held during the ECML-PKDD 2024 conference. The challenge's goal was to predict the failure risk of an anonymized component in Volvo trucks using a newly published dataset. The test data included observations from two generations (gen1 and gen2) of the component, while the training data was provided only for gen1. The challenge attracted 52 data scientists from around the world who submitted a total of 791 entries. We provide a brief description of the problem definition, challenge setup, and statistics about the submissions. In the section on winning methodologies, the first, second, and third-place winners of the competition briefly describe their proposed methods and provide GitHub links to their implemented code. The shared code can be interesting as an advanced methodology for researchers in the predictive maintenance domain. The competition was hosted on the Codabench platform.", "sections": [{"title": "1 Introduction", "content": "The Volvo Discovery Challenge was held as part of the European Conference on Machine Learning and Data Mining (ECML PKDD 2024). In collaboration with Volvo Group Truck Technologies, Halmstad University challenged participants to predict the risk of failure for an undisclosed component of Volvo trucks. This challenge invited participants to work with an exclusive real-world dataset containing measurements from a fleet of more than 10,000 Volvo heavy-duty trucks. The task was to develop a machine learning model to predict risk levels (i.e. Low, Medium and High) for a component of the trucks in the test set. The core task of this competition falls within the broader scope of predictive maintenance (PdM).the"}, {"title": "2 Challenge Setup", "content": "The challenge was hosted on the Codabench platform (Link) and had two phases:\n1. Development Phase (May 15 to June 15, 2024): In the development phase, the participants could submit 5 predictions per day. The submitted prediction was evaluated against 20 percent of the ground truth data. The best-performing submission from each contestant was automatically published on the leaderboard, allowing everyone to compare their results with others.\n2. Final Phase (June 16 to June 30, 2024): The final phase started after the development phase. In this phase, the contestants were allowed to submit only 3 predictions in total. The submitted prediction was evaluated against the whole ground truth data. The best-performing submission among those three submissions in the final phase was displayed on the Leaderboard. The ranking in the Leaderboard of the final phase determined the final ranking."}, {"title": "2.1 Prizes", "content": "The top three competitors received a time slot to present their work at the conference. The first place received a free registration for the ECML-PKDD 2024. In addition, there was prize money for the top three contenders: the team in the first place received 500\u20ac, the second place 300\u20ac, and the third place 200\u20ac."}, {"title": "2.2 Submission Process", "content": "Each submission was a single ZIP file called prediction.zip. Inside the file, there was a CSV file containing a header called pred followed by one prediction (Low,"}, {"title": "3 Submissions Statistics", "content": "The competition received a total of 791 submissions from 52 participants, with 28 submissions in the final phase and 763 in the development phase. As shown in the figures, the top three positions remained unchanged between the two phases. The performance of the models decreased by only about 2 percent when moving from the development to the final phase. This indicates the models had a high level of generalization ability. Another interesting observation is the low difference (less than 1 percent) between the performance of the models in gen1 compared to gen2.\nThe competition ran for 6 weeks between week 20 to week 26. Ultimately,"}, {"title": "4 Description of the Dataset", "content": "The dataset contains three files: train_gen1.csv, public_x_test.csv, and variants.csv. The train_gen1.csv file contains 157,437 readouts from an undisclosed component across 7,280 Volvo heavy-duty trucks, each uniquely identified by an anonymous chassis ID labeled ChassisId_encoded. This file includes 308 columns. The first four columns are Timesteps, ChassisId_encoded, gen, and risk_level, followed by 304 feature columns. Note that the train_gen1.csv file only contains data from the first generation of the component. These readouts are recorded at consecutive timesteps, starting from timestep 1 and extending until either component failure or the end of data collection. While some components experienced failure during the study period (unhealthy components), the majority did not fail (healthy components). The time intervals between the consecutive readouts are undisclosed but can be considered consistent and equally spaced."}, {"title": "5 Evaluation", "content": "The macro-average F1-score was the main evaluation metric in this competition. To calculate the macro-average F1-score for a classifier with three classes (i.e., Low, Medium, High), we first compute the Fl-score for each class individually and then take the average of these Fl-scores. The macro-average F1-score treats all classes equally, regardless of class imbalance.\nThe macro-average F1-score is calculated and reported for predictions of gen1 and gen2 separately. The final score determining the winner was the average of the macro F1-score for gen1 and gen2. The startkit.py file contains an implementation of the evaluation metric used in the competition and evaluates the predictions of the baseline model against a mocked-up ground truth."}, {"title": "6 Winning Methodologies", "content": "In this section, we provide a brief overview of the methods employed by the first, second, and third place winners in the competition, respectively, presented in the below subsections."}, {"title": "6.1 Team RandomGuy", "content": "The proposed solution employs a tabular data classification approach, analyzing each row of input data individually with minimal involvement of temporal features. It follows a two-step process: first, identifying whether a row belongs to a healthy or non-healthy sequence, and second, reclassifying the non-healthy elements as \"Medium\" or \"High\" risk.\nIn the first step, each data row is classified to determine whether it belongs to a healthy (low-risk) sequence. This classification is achieved using the recent"}, {"title": "6.2 Team CarloMetta", "content": "The proposed solution leveraged advanced ad-hoc machine learning techniques, specifically focusing on the use of Long Short-Term Memory (LSTM) [5] networks combined with pseudo-labeling, boosting, and ensemble of different models.\nThe pipeline starts with a preprocessing phase where the training data is prepared to mirror the structure of the test set. This was critical to minimize discrepancies between training and testing environments and to simulate real-world conditions as closely as possible. Specific transformations included aligning the sequence lengths and ensuring the distribution of labels matched that of the test data scenarios.\nFollowing data preprocessing, the core of our solution was built around a base LSTM model. This model was initially trained to predict risk levels at each timestep using the labeled training data. The use of pseudo-labeling was pivotal in refining our model. After the base model generated predictions for the test set, we selected a subset of these predictions to serve as 'pseudo labels.' These were then added to the original training dataset, enhancing the training pool with new, diverse examples (from \"gen2\" trucks) that reflected test set characteristics. This technique not only helped refine the model's predictive accuracy but also helped adapt the model to generalize unseen data better. To further optimize our model, we implemented a boosting technique through iterative training. Each iteration involved adding more layers to the LSTM network. The model started with simpler, shallower networks and progressively increased in complexity, culminating in a 10-layer deep LSTM network. Each network was trained on a dataset augmented by pseudo labels from previous iterations.\nOur ensemble approach also played a crucial role in the final model deployment. By combining multiple models from different training iterations, we reduce individual model biases and enhance overall prediction stability. This ensemble not only served to validate the predictions through a majority voting mechanism but also ensured that our final output was more robust.\nIn our solution, we incorporated several ad-hoc techniques alongside our core LSTM and pseudo-labeling strategy to enhance model performance and robustness. One such technique was inspired by [6], which explores the efficiency of adjusting neural network biases in place of the weights to improve generalization in deep learning models. We experimented with similar bias modifications in our LSTM layers to see if these adjustments could offer a more computationally efficient way to enhance prediction accuracy without substantially increasing the model's complexity. Additionally, we integrated the SwitchPath methodology, which involves dynamically altering the paths through which data flows in the network, as suggested in [8]. Although primarily developed for networks utilizing ReLU activations, we adapted its principles to suit the LSTM's typical tanh activation functions. This adaptation involved selectively activating different pathways during the training phase to avoid local minima and enhance the exploration of the model's parameter space, potentially leading to more robust learning outcomes.\nFor post-processing, we focused on ensuring the logical consistency of the risk predictions across each sequence. Given the ordered nature of risk levels in predictive maintenance\u2014where risk should not decrease as failure approaches we adjusted sequences that did not adhere to this logic.\nThe integration of all these techniques formed the backbone of our solution. This approach meticulously addressed the challenge's demands, focusing on accurately predicting maintenance needs based on extensive real-world data. The code for this solution can be found at https://github.com/CuriosAI/Volvo_Discovery_Challenge_ECML_PKDD_2024."}, {"title": "6.3 Team MALTO (MAchine Learning at PoliTO)", "content": "The proposed solution exploits the Time-Transformer [3] in combination with different feature extraction techniques. The attention mechanism allows access to all historical input steps, focusing on the most relevant ones and extending the receptive field without increasing the depth of the network, one of the limitations of the normal TCN [2]. To resume the data structure present in the test set, we sampled sequences of 10 timesteps from the training set. We sampled from the entire time series for the healthy data, while for the unhealthy data, we sampled starting from the first time step classified as \"High\" risk, going backward. To enhance the predictive performance of our model, we applied a series of feature extraction techniques to the temporal data. We computed the first derivative for the numerical features, which helps reveal trends and abrupt shifts in the data. Additionally, we applied wavelet transforms to the numerical features, using a discrete wavelet transform (DWT) with the \"db4\" wavelet. This decomposition captures patterns across different time scales, offering insights into both high-frequency fluctuations and low-frequency trends. The resulting feature set includes the original numerical and categorical features, the first derivatives, and the wavelet-transformed data.\nThe proposed solution applies a two-step approach to correctly identifying the different risk levels \"Low\", \"Medium\", and \"High\". Two different Time-Transformers are used to solve the problem. The first one determines the healthy and unhealthy sequences as a binary classification problem. The second one considers only the non-healthy sequences and evaluates where the risk is \"Medium\" and \"High\". For this step, we introduce the definition of \"jump\", i.e. when the risk changes from \u201cMedium\u201d to \u201cHigh\u201d. We noticed that if we approach the problem as a sequence modeling task (i.e., classifying each timestep), the model had a hard time capturing some of the implicit rules of the solutions (e.g., always passing from \"Medium\" to \"High\" and not vice-versa, having only one jump per solution, etc.). To remedy this, we turned the problem into a regression task that would estimate when the jump would occur: by using a sigmoid activation on the output, we ensured that it would be contained in the range (0,1), and we interpreted it as the percentile of the time series where the jump took place (i.e., if the output is 0.65, then for a time series of length 10 the jump would take place between the 6th and the 7th timestep). In both models, the Time-Transformer is used as a feature extractor."}, {"title": "7 Terms and Conditions", "content": "All participants of the Volvo Challenge ECML PKDD 2024 gained access to Volvo's dataset. The dataset distributed during the challenge is referred to as the Volvo GTT dataset and belongs to Volvo. By participating in the challenge, Volvo granted the contestants and they accepted to receive a personal, non-exclusive, non-transferable, non-sublicensable, royalty free license to use the Volvo GTT dataset solely for the purpose of participating in the challenge. The license lasted only during the time of the Volvo Challenge ECML PKDD 2024. Apart from the abovementioned license, Volvo reserves all rights in the Volvo GTT dataset.\nBy enrolling in the competition, all participants granted Halmstad University (as the organizer) and Volvo Group a license to the solutions proposed in the contest. Given the prize levels, the contestants may be subject to income tax if they win, and participants were asked to carry any tax effects of receiving the prize."}]}