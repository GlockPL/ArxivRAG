{"title": "Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling", "authors": ["Qian Wan", "Xin Feng", "Yining Bei", "Zhiqi Gao", "Zhicong Lu"], "abstract": "Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative Al models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI models, while users can apply generations to recolour and re-arrange the interface to be visually affective. Our experience-centred evaluation manifests that, by interacting with Metamorpheus, users can recall their dreams in vivid detail, through which they relive and reflect upon their experiences in a meaningful way.", "sections": [{"title": "1 INTRODUCTION", "content": "The third wave of HCI has generally shifted to a more phenomeno- logical perspective, in which lived experiences of individuals are brought into focus [40, 71]. In this trend, HCI designs are becoming increasingly experience-centred [90], and often envisaged or evalu- ated as experience [56]. Echoing this phenomenological turn, recent advances in affective computing have witnessed a departure from statistical systems that merely detect and record emotions. Instead, researchers are now designing systems situated in our daily routines and social interactions that provide grounds for meaning-making, in order to provoke meaningful self-reflection [72], facilitate com- munication [62], foster social connections [53], etc. Nevertheless, considering lived experiences constitute the raw material of human emotions [8, 26, 27, 32], how can computing systems support narra- tion of these affective experiences themselves to facilitate meaning making, for the purpose of self-awareness and self-reflection?\nIt is known that, putting emotional experiences into words can benefit affective, and mental wellness [51, 88]. Outside the realm of HCI, expressive therapists have already been using creative and artistic expression of our lived experiences as a treatment for mental health conditions such as nightmares [49], trauma [70], depression [55], etc. Through various forms of creative expression, these thera- pies aim to \"facilitate clients' discovery of personal meaning\u201d, which, as Malchiodi put it [54], \"may deepen into greater self-understanding or may be transformed, resulting in emotional reparation, resolu- tion of conflicts, and a sense of well-being.\" Writing therapists, for instance, might engage clients in a narration of their emotional ex- periences (e.g., a traumatic experience) by journal or poetry [1, 63] to attenuate negative experiences [66, 88, 89]."}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "This work was motivated by previous literature on affective comput ing, creative journaling, and dreams. In this section, we first intro duce the background of emotion theories and affective computing, with a focus on recent constructivist models and meaning-oriented frameworks. We then briefly review previous work of creative jour naling and dreams in HCI to explain our design rationale."}, {"title": "2.1 Emotions and Meaning Making", "content": "The broad arc of affective computing has generally shifted away from essentialist views of emotions, to a more constructivist stance. When the concept of \u201caffective computing\u201d was first introduced by Rosalind W. Picard in 1997, it was formulated as a problem of pat tern recognition and synthesis [69], as influenced by the classical emotion theories that argue for the existence of basic categories that are universal, fundamental, but discrete and physiologically distinct [26, 27]. However, this essentialist view was challenged by researchers, such as Lisa Feldman Barrett, by emphasizing that emotion categories are shaped by contextual factors [6, 9, 11, 52]. Alternatively, constructivist theories have been proposed and for mulated in its stead [8, 10, 77, 78], in which instances of emotion are rejected to be natural kinds, but rather constructed by our brain in the moment by assigning meaning to sensory inputs, as informed by past experiences [6, 7].\nThe constructivist shift tacitly coincided with the emergence of the third-wave HCI research, initially conceptualised as the phe nomenologically situated paradigm, which is \u201ca focus on meaning and meaning creation\u201d, \u201cbased on human experience\u201d, and \u201cthere fore represented through multiple perspectives, and the relationship amongst those perspectives\u201d [40]. Following these trends, Boehner et al. challenged the traditional informational model of emotions that presupposes the existence of discrete emotions, and offered an alternative account that models emotions as a social and cultural product experienced through interactions [15]. They argued that such model leads to new goals for affective computing, wherein systems should support users in making meaning of their own emotions instead of merely sensing and transmitting prescribed emotion labels.\nInspired by the interactional model, recent designs of affective interfaces are increasingly socially situated, experience-centred, and meaning-oriented [53, 62, 72]. For example, Rajcic et al. [72, 73] designed a smart mirror that engages users in making meaning of their emotional states to promote awareness and reflection. The mirror performs an emotion recognition algorithm and composes a poetry using a large language model (GPT-2) based on the detected emotion states to foster meaningful experience. Their user study used Mekler and Hornb\u00e6k\u2019s [59] framework to evaluate the experi ence of meaning, which comprises five components: Connectedness, Purpose, Coherence, Resonance, and Significance. It revealed that the creative and open-ended nature of poetry allowed users to develop personalised meaning from the mirror\u2019s generations.\nThe design of our system, Metamorpheus, is motivated by the recent constructivist conceptualisations of emotions and the phe nomenological paradigm. Drawing upon insights of Boehner et al. [15], our design hones in on the lived experience, the raw mate rial of human emotions, and aims to provoke meaningful reflection through creative narration. Because meaning as a quality of interac tion is often elusive, we also used Mekler and Hornb\u00e6k\u2019s framework in our phenomenological evaluation, which provides an construc tivist understanding of how users constructed meaning from both the interaction experience and end results."}, {"title": "2.2 Creative Journaling of Personal Information", "content": "Throughout the history of mankind, creative and artistic activ ities have consistently been associated with healing and thera pies [57, 58]. Historical evidence shows that the practice of arts as therapies dates back to thousands of years ago, when Egyptians encouraged those with mental illness to engage with artistic ex pression [30], and Greeks used drama and music as a reparative form of treatment [36]. Roughly during the 1930s and 1940s, ex pressive therapies gained wider recognition, as psychotherapists began to realise that self-expression through non-verbal channels (e.g., painting, music, dance, etc.) might benefit people with se vere mental illness [54]. To this day, scientific evidence continues to surface supporting the effectiveness of these therapeutic prac tices of artistic expression [75, 82, 85]. Various theories have also been put forward in an attempt to explain the exact mechanism through which expressive therapies improve mental well-being. For affective wellness in particular, it is believed that artistic ex pression can translate into emotional reparation, awareness, and resilience [54, 65], by supporting and facilitating clients\u2019 personal meaning-making process [14].\nPreviously, HCI researchers have also found similar effects in creative journaling of personal information [4, 5, 87]. Early work by Petrelli et al. [67] reveals that people are more interested in cre atively reconstructing memories from carefully selected cues than exhaustively digitally recording them. Therefore, they argued that future autobiographical technologies should aim to support active selection, creativity, and meaning building. Later studies of bullet"}, {"title": "2.3 Dream and Dream Journaling", "content": "While the exact origin and function still largely remain a mystery to neuroscience [35, 44, 64], researchers have already come up with diverse methods to study dreams, such as neuroimaging [50], con- tent analysis (notably the Hall/Van de Castle coding system [37]), and quantitative analysis of coded dream reports [23] using the Hall/Van de Castle system. A variety of theories have also been put forward to explain the dreaming process, the most notable being the continuity hypothesis, which suggests dreams \"enact and dramatize\" waking-life experiences [12, 24]. This means that dreams can serve as a valuable material for self-discovery and self-understanding, as dreams reflect the same concerns of waking thoughts in a more dramatic way [43]. Dream experience is also hypothesized to be entangled with our emotions, and vice versa. Preliminary psycho- logical and neuroimaging findings suggest that, dreams are influ- enced by dreamers' waking emotional concerns [16], and dreaming might play a pivotal role in the emotional regulation and emotional memory consolidation [80].\nIn practice, dreams have already been widely used in thera- pies [41, 47], especially as a treatment for nightmare disorder [34]. In a typical Imagery Rehearsal Therapy (IRT), for example, ther- apists would ask clients to recount their dreams and rewrite the narrative such that it is no longer a nightmare [48, 49]. The revised dream needs to be mentally rehearsed for several minutes a day [38], so that it begins to occur during the sleep in place of the nightmare, to improve the overall psychological well-being.\nRecently, the significance of dreams has also drawn attention from HCI researchers. Hoefer et al. was argubly the first to study dreams as a form of health data used in a personal informatics sys- tem [43]. Their survey study presented comprehensive challenges for computers to support dream tracking and dream journaling. For instance, dreams are easily forgotten, hard to capture as an entire lived experience, and often personalised and open to interpretations. Perhaps for these reasons, they concluded that technologies to sup- port dream recall and dream narration were nearly non-existent except for note-taking features.\nThe design of Metamorpheus fills this gap by introducing human- computer co-creation of visual stories as a method for interactive dream narration. Our experience-centred evaluation demonstrates that Metamorpheus not only facilitates dream recall, but also pro- vokes meaningful self-reflection."}, {"title": "3 DESIGNING METAMORPHEUS", "content": "The design of Metamorpheus was informed by a review of affective expression in existing visual narratives. The creation of affective metaphors ended up being chosen as the main feature of Metamor- pheus to develop a visual story. In this section we introduce our design considerations, and how they were implemented in practice."}, {"title": "3.1 Design Considerations", "content": "The design of Metamorpheus attempts to engage users in the cre- ation of a visual story to recount their emotions during a dream. For the purpose of affective reflection, we expect the system to be creative and open to interpretations for self-expression, and meanwhile remains accessible to common users with little art or design expertise. To this end, the authors, three HCI researchers plus two designers (one UX designer & one architecture designer), began by surveying papers on devices for affective expression in previous visual narratives such as films, cartoons, anime, comics, photography, etc.\nA discussion session was later held among authors to review each paper and design approach we surveyed. We concurred to filter out approaches that are: I) too individualised and arbitrary for a visual storytelling system (e.g., pictorial runes in comics [31]), II) too demanding that might seem distracting for storytelling (e.g., emoji or meme creation [29, 86]), and III) not creative or open-ended enough for the purpose of self-expression and self-reflection (e.g., colours, shapes, filters, style transfer, etc).\nIn the end, we opted for the creation of affective metaphors to help develop visual stories in Metamorpheus. The creation of metaphors adapts better to affective visual storytelling because it is a cross-modal and emotionally arousing device for artistic expres- sion that has been widely used across various mediums of communi- cation and arts, even including HCI designs [74]. In clinical practice, metaphors also serve as an effective way of communicating lived ex- periences [84]. Additionally, we already have a well-defined design space [68] to scaffold the creation process, including both meaning and visual structures of metaphors. We also have corresponding creativity support tools [33, 46], and text-to-image AI models [76] readily available to support users.\nNevertheless, adapting a metaphor creation to an affective dream narration process requires additional considerations. Dreams are known to be hard to recall, hard to express, and open to interpre- tations [43]. Therefore the creation of metaphors must encourage"}, {"title": "3.2 User Interface", "content": "Metamorpheus divides a complete visual story into multiple literal or metaphorical scenes. Each literal scene contains only text de- scriptions, while metaphorical scenes store both metaphorical text depictions and generated images of visual metaphors. The editing and presentation of the visual story are integrated into one user interface, which comprises three common UI elements in a visual story: a text bubble, a storyline visualisation, and an image of a visual metaphor in display, as shown in Figure 1."}, {"title": "3.2.1 Text Bubble & Metaphor Editing.", "content": "The text bubble on the in- terface displays text descriptions of each scene. For metaphorical scenes, an extra title is displayed to indicate the metaphor drawn: the original affective concept, and a new metaphorical concept. To make it attentive to emotional changes in narratives for G1, two dif- ferent shapes were designed to distinguish literal and metaphorical scenes. As informed by [3], we assumed that spiky text bubbles im- ply higher emotional arousal than rounded ones. Therefore, we use spiky text bubbles for metaphorical scenes, and rounded bubbles for literal scenes, as shown in Figure 5.\nFor a metaphorical scene, users can click to open the metaphor editor. To keep the editing anchored in the emotion recollection and expression for G1, we require users to specify what is affective, the description of the affective element (one or more adjectives), the metaphor to draw, and prompts to generate an image of the visual metaphor (see Figure 3), which is to some extent similar to affect labeling [88]. We also scaffold the creation of visual metaphors by applying the design space in [68], where users are allowed to select the type of meaning (connection, similarity, and opposition), and visual structures (juxtaposition, fusion, and replacement) to automatically request suggestions of metaphors from ChatGPT, and generate template prompts for a text-to-image model. After a visual"}, {"title": "3.2.2 Storyline Visualisation & Colour Filters.", "content": "The storyline visual- isation on the interface arranges the emotions of a dream narrative in a linear order, where each metaphorical scene is represented as an anchor point on a horizontal axis. The current generated images of each scene dangle from the anchor point, and previous genera- tions are preserved above. To make the visualisation more creative and open to interpretations for G2, we allow users to relocate or resize each of the dangling images to re-arrange the visualisation and construct their personalised meaning.\nThe image display area holds the current generated image of a metaphorical scene in focus. For each of the image generated, we extracted 8 dominant colours for users to apply customised \"colour filters\" over the interface to support our G2, as inspired by [4]. The extraction was achieved by a clustering algorithm similar to K-means. For details we refer our readers to [18]. By default, the most dominant colour will be selected from the image in display to recolour the interface, including the colour of text bubbles' shadow,"}, {"title": "3.3 Example Scenario", "content": "We provide an example to illustrate the creation workflow of Meta- morpheus using a dream narrative sampled from Dream Bank (an online collection of over 22000 dream reports) 1. Suppose Bob, a college student, would like to use Metamorpheus to create a visual story based on his dream last night. He dreamt of walking down a beach, holding hands with a girl he used to like, so he creates a literal description as the opening scene. It says \"The dream began when I was walking along the beach with my old crush\". He then wants to recreate the visual scene at this moment, which contains the beach, sunset, and his crush holding hands with himself. He therefore adds a metaphorical scene, and opens the metaphor editor, which prompted him to articulate what is affective, and describe it in one word."}, {"title": "3.3.1 The First Scene: Old Crush Holding my Hands.", "content": "After some time of recall and reflection, he concludes that his old crush hold- ing his hands was the most emotionally arousing stimulus, which made him feel excited at that moment. Therefore, he fills in the metaphor editor form, \"old crush holding my hands\", and \"exciting\". He then thinks about metaphors to draw, and wants to see sug- gestions first. He requests from ChatGPT words connected with, similar or opposite to the \"exciting\" moment when old crush held his hands. Suggestions include \"Electric Sparks\", \"Nostalgic Embrace\", \"Entangled Fingers\", etc. Bob accepts \"Electric Sparks\" as he thinks it is very accurate to describe the excitement. It also reminds him of a scene where her crush held his hands, surrounded by sparks. He therefore moves on to prompt editing, and chooses \"Fusion\" to update the prompt template in order to fuse her crush and himself hand in hand with \u201cElectric Sparks\u201d in one image.\nAfter exploring for some time, Bob feels the generations were too random. Therefore he adds \u201csunset on the beach\" in the prompt. After regenerating, he becomes instantly intrigued by an image of one hand holding another lit up by sparks, as shown in Figure 4a. He really likes the atmosphere of the entire scene, which he thinks is perhaps warmed up by the colour of the sunset. He accepts the image, and feels that the default colour extracted from the image is pretty accurate to indicate the warmth of the scene. He also reads through the generated text depiction, which says that the \"sparks\" ignite \"a thrilling sensation that surged through every inch of my being\". Bob feels it was literary and to the point, but also reminds him of the next moment, where he sensed something else besides the thrill.\""}, {"title": "3.3.2 The Final Scene: Hugging and Kissing.", "content": "Bob then moves on to creating another metaphorical scene, in which he suddenly realised that he had a girlfriend already, but he did not care, and hugged and kissed his old crush regardless. He contemplates a while over his emotions at that particular moment, and feels it was a mix of mostly thrill and a bit of worry that he might be caught cheating. He therefore opens the editor again and types \"hugging and kissing\", and \"thrilling but a bit worrying\". Bob browses through suggested metaphors, and then accepts \"Embracing Flames\". He thinks flames can perfectly depict the thrilling moment, while implying a sense of destruction that can represent his worry. He then prompts the text-to-image model by both fusing the flames with kissing and hugging, and putting them in juxtaposition.\nHe finally accepts two images: one depicting them kissing and hugging so hard in front of fires to depict the thrill; the other one seemingly abstract with both warm and cold colours to depict a mix of thrill with worries. He then chooses reddish colours from both extracted palettes to represent the arousal level of his emotions. He also checks the generated text and feels that it per- fectly explains his intended metaphorical meaning of flames, saying that the \"passionate excitement\u201d carries \u201cthe risk of getting burned\u201d. To add a bit more context, he types at the beginning \"I realised I already had a girlfriend, but we kissed and hugged regardless.\"\nFinally, Bob creates another literal scene as the ending, in which he types, \"The moment seemed so real that, when I woke up all of a sudden, I had thought it was reality, the thrill lingering on until I got up for coffee.\". He then resizes the first scene a bit larger because he really likes the atmosphere, and relocates the second a bit above"}, {"title": "3.4 Implementation", "content": "The user interface of Metamorpheus is a web application imple- mented via React and JavaScript. The backend of Metamorpheus serves a text-to-image model, Stable Diffusion [76], that takes as in- put an incoming request with a text prompt, and returns a 512\u00d7512 resolution image after 30 inference steps. The metaphor sugges- tions and metaphorical text depictions are generated by ChatGPT, i.e., GPT-3.5-turbo. The temperature was set to 1.0 for metaphor suggestions, and 0.7 for generating metaphorical depictions."}, {"title": "4 STUDY DESIGN", "content": "The evaluation of Metamorpheus was inspired by H\u00f6\u00f6k's two-tiered design evaluation model for affective interfaces [45], in which he advocated \"rich, narrative, constructive understanding\u201d of interac- tions between users and affective systems. As we envisage the end goal of Metamorpheus to be meaningful self-reflection, and its usage to be open-ended and scalable to other scenarios such as dream tracking or social sharing beyond an affective interface per se, we slightly modified the second level of the original two-tiered model, and hone in on the experience of meaningful reflection [59] throughout the interactions, as informed by Boehner et al.'s in- teractional model [15]. Specifically, we attempted to answer the following questions:\n\u2022 RQ1: Are expressed emotions of Metamorpheus readily un- derstood, and do they correctly interpret users' emotions?\n\u2022 RQ2: Does Metamorpheus provoke meaningful reflection; and what are the meanings by users' accounts?\nTo evaluate separate features of Metamorpheus, and obtain an in- situ understanding of users' experience of meaningful reflection, we conducted a lab study involving 12 participants. To answer RQ1, we conducted a survey after a story creation task to evaluate each key feature of the system.\nTo address RQ2, we took a phenomenological approach [61] and aimed to elicit and articulate the essence of experience during the interaction. In this sense, we did not set out to investigate our hypothesis of the presence of meaningful reflection in a simple yes or no question. Instead, we sought to obtain, as H\u00f6\u00f6k put it, a \"constructive understanding\" of how users experienced the interac- tion and co-creation results, of which the experience of meaning constitutes an essential component. To this end we prompted our participants to articulate their thoughts, feelings, perceptions, and"}, {"title": "4.1 Participants", "content": "We recruited participants from our universities by advertising our user study on social media and through posters. In the end, 12 students (5 male, 7 female) aged between 18 and 30 agreed to par- ticipate in our study. For convenience we refer to them as P1-12. Of the 12 participants, P10 disclosed that she had some experience of drawing, and P2, P11, & P12 have a design background. All par- ticipants were ethnically Chinese and L2 English speakers, and all studies were conducted in Mandarin. For each participant, we offered a 50 HKD coupon as an honorarium."}, {"title": "4.2 Study Protocol", "content": "Prior to the study, we obtained participants' consent to the use of their dream experiences by direct messaging, and asked them to recall 2-3 dreams from the past three months before they were invited to our lab. The lab study was later conducted in a private room where only one researcher and the participant were present. To build rapport with our participants, we first asked them about their attitudes towards dreams, whether they tracked their dreams, and their practices of dream tracking, if any. We then required participants to recount their experiences in each of their dreams, and recall their emotions while their narration unfolded.\nAfter the dream narration, we demonstrated features of Meta- morpheus to participants by creating a visual story based on a randomly sampled dream narrative from Dream Bank. Participants were reminded that a creation from Metamorpheus includes all visi- ble elements on the user interface, such as text narrative, generated images, arrangement of the visualised storyline, applied colour fil- ters, and so forth. After familiarising themselves with our system for 5 minutes, each participant was required to create a complete visual story based on one of their most affective dreams.\nAll participants were required to think aloud during the creation, and were frequently asked questions regarding their feelings, per- ceptions, and thought processes on the spot (e.g., why did you resize the event on the storyline? What did the results make you think? What do you feel about the colour filter?), especially when any non-verbal responses (e.g., chuckles, cringes, pondering, etc.) were observed. Because these experiences are often hard to describe, we asked participants multiple follow-up questions to reach an articu- lated interpretation (e.g., what made you think of this? what do you mean by feeling this way?). After the creation process concluded, we played the complete visual story scene by scene, and asked participants about their feelings, thoughts, and understandings. In the end, we asked participants to complete a survey to rate three key features: generated visual metaphors, metaphorical text depictions, and colour filters. The survey questions are related to RQ1: whether expressed emotions of a feature were readily understood, and whether they correctly interpreted users' emotions. We also conducted a semi-structured interview with participants to reflect on their overall feelings, emotions, thought processes and"}, {"title": "4.3 Data Analysis", "content": "The analysis of our qualitative study data was informed by the paradigm of interpretative phenomenological analysis [83]. During the analysis, we aimed to cast out our hypothesis in RQ2, but an- swer it in the end with a rich narrative of how users made sense of the system, the intermediate and final results; how they con- structed meaning out of the interaction, and what they thought of themselves during and after the interaction.\nThe qualitative data for analysis comprise screen-recording of the creation process, and transcriptions of the interview and think- aloud process. The first author, an HCI researcher that conducted all the studies, first performed an open coding [21] of the tran- scriptions, while playing the screen recording simultaneously as a reference. Emerging codes were extracted and recorded with their timestamps in the screen recording, marked with participants' at- titudes towards dreams, practices of dream recall, and initial dream narration at the very beginning. The initial codes that emerged were related to users' sense of agency, feelings of connection, mo- tivations to share, thoughts on the workflow and creations, etc.\nWe then performed a second round of coding to catalogue initial codes into themes regarding the essence of the experience of both the interactions and results. All data, codes, and themes were later translated into English for reporting."}, {"title": "5 FINDINGS", "content": "We report results of our study and tentatively answer our RQ2 with a summary of the user experience of both the interaction and creation results."}, {"title": "5.1 Feedback on Features: Accurate and Creative", "content": "In general, participants regarded features of Metamorpheus as accu- rate and easily understood, as shown in Figure 6. There was only one case where the participant (P10) failed to obtain the desired generation during the study. In this case, P10 tried, but failed to recreate a very complex visual scene, where she \u201cheld hands with her old friend and walked on white grounds, under the blue sky where white doves flew by, slowly passing arrays of white columns"}, {"title": "5.2 Interactive Meaning Co-construction", "content": "The interaction with Metamorpheus used to be a meaning co- construction experience, in which the system facilitated self- expression, and participants further constructed meaning out of creative outputs in an open-ended manner based on their own affective experience."}, {"title": "5.2.1 Visual Metaphors as Meaning Co-construction.", "content": "Initially, most participants were found to recreate key visual details of their dream experiences via images of visual metaphors. For dreams that were still in vivid details, in particular, participants expected generated images to match their memories exactly. During this period, the text-to-image model often failed participants in that it was too random for correctly recreating an abstract visual scene during a dream. For instance, P11 described that he was looking for key elements in his memories such as \u201ca very crowded street\u201d, \u201ca monster hidden in the crowd\", \"being tailed by the monster that felt like an imminent danger\u201d. The generated images kept failing him for lacking either crowds, monsters, or a sense of danger.\nNevertheless, after some time of exploring, participants usually ended up constructing their personalised meanings out of random outputs, and looking for patterns similar to their memories, such as colours, overall atmosphere, certain objects, or certain visual pat- terns, instead of perfect recreations. For example, in P12's dreams, he was chatting with old friends over dinner, and gradually getting bored by their conversation. He used bouquet of laughter to repre- sent his friends, and text bubble drizzle to represent their conversa- tion. Instead of recreating visual details, he accepted two images for these two scenes that seemed rather abstract, even without any traces of his friends in human form. He explained that the first image accurately recreated \"the joyful atmosphere\", and the second image felt like \"someone cramped in these text bubbles, and trying to escape\u201d.\nP8 was recreating visual scenes involving his old crush. He later provided a detailed explanation of what he expected from the text- to-image model during the interview,\n\u201cI cared about whether the overall feelings (of the image) matched (my feelings) towards her in the dream. It's a common sense the model can't recreate a portrait of her... What I primarily expected, or perhaps cared about, was first, whether the surroundings or atmosphere fit; second, a rough recreation of her figure; third, whether the overall image resonates with me emotionally.\u201d\nHe further pointed to two images he accepted in his final visual story, as shown in Table 2, and explained that the first image of his old crush had \"melancholic eyes\", which reflected his \"sense of regret\". The second image did not contain a clear picture of her face, but rather visualises her figure as sitting next to the moon, lit by moonlight. He said it made him feel she was pretty and perfect like the moon, but \"distant and out of reach\".\""}, {"title": "5.2.2 Text Depictions for Meaning Co-construction.", "content": "After the im- age generation, most participants (P8-9, P11-12) reported that the generated metaphorical text depictions helped articulate their emo- tions in a literary way. Perhaps because our participants were all"}, {"title": "5.2.3 Alternating Agency to Describe the Ineffable.", "content": "During the in- teraction, the agency was alternating between users and the system in the meaning co-construction process. The system, especially the generative AI, took part in the self-expression, while users con- structed new meaning and iterated the expression again out of the system outputs. When asked if they felt this co-creation took away from them the agency of expression, all participants almost unanimously disagreed. Only P9 and P10 said it might depend.\nP4 noted that without the system, especially the process of metaphor editing and the visualisation of the affect-driven sto- ryline, she would not even know how to visualise or narrate the dream, because dreams and emotions in dreams were \"too abstract\". P12 also mentioned that the workflow of the system served as an appropriate way of instructing him on how to develop the story. During the interview, P6 reflected that,\n\"I used to track my dreams in a very informal and aim- less way. It might be too random. This form of expression kind of drives me to articulate by creating a visual story that matches my feelings in the dream... I felt that the"}, {"title": "5.3 The Interaction Relives the Dream in Detail", "content": "All our participants almost unanimously reported that the interac- tion with Metamorpheus was an experience of reliving all details in a dream, especially related to their own emotions."}, {"title": "5.3.1 Mindfulness through Reflection.", "content": "The interaction with Meta- morpheus brought alive emotional experiences in a dream. Partici- pants described it as an \u201cre-enactment\u201d (P2), a \"reminder\" (P1), an", "reinforcement": "and a \u201cdetailed and vivid rec- ollection", "them.": "nWe have also found cases where Metamorpheus helped discover hidden emotional details in a dream that participants had almost forgotten. For instance, P7 dreamt about a wedding banquet, where she was getting married and blessed by friends. During the inter- view, she said in retrospect,"}, {"title": "5.3.2 A Reflective but Innocuous Manner.", "content": "We found that, though our participants felt it challenging to articulate, the experience of reliving and reflecting on the emotional experiences was generally benign. The reported effects even resembled those found in expres- sive therapies [54], though participants such as P4 refused to use the word \"therapeutic\". Instead, the interaction was described as an experience that \"felt like roasting from a distance\" (P3), one with", "abstract expression instead of concrete re-creation\" (P8), and as if \u201cin a third-person perspective\" (P3), and \"in a peaceful and comfortable manner": "P4), which raised their awareness of their own emotions, including negative ones, in an innocuous manner.\nFor example, P4 was creating a visual story based on a night- mare related to her traumatic experiences. She said the interaction helped her relive her memories, but she described the experience as an \"escape\". While creating the visual story, she felt as if she \"escaped from the experience\" and relived these memories \"with a sense of detachment\u201d, which was quite \"peaceful and comfortable\". She reasoned that, \"I felt I was more focused on the creation and putting emotion into words, which perhaps attenuated my emotions\u201d. P3 also came across negative feelings in the middle of her dream. She described the interaction experience as", "at a distance": "rom that particular feeling, which did not make her feel uncomfortable.\nP9 said that he took generations of the system with a grain of salt, especially the metaphorical text depictions of his so-called \"subconscious emotions\". By drawing an analogy with dream dictio- naries, he said that, \u201cWhether it ("}]}