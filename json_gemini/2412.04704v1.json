{"title": "On Interpreting the Effectiveness of Unsupervised Software Traceability with Information Theory", "authors": ["David N. Palacio", "Daniel Rodriguez-Cardenas", "Denys Poshyvanyk", "Kevin Moran"], "abstract": "Traceability is a cornerstone of modern software development, ensuring system reliability and facilitating software maintenance. While unsupervised techniques leveraging Information Retrieval (IR) and Machine Learning (ML) methods have been widely used for predicting trace links, their effectiveness remains underexplored. In particular, these techniques often assume traceability patterns are present within textual data \u2014 a premise that may not hold universally. Moreover, standard evaluation metrics such as precision, recall, accuracy, or F1 measure can misrepresent the model performance when underlying data distributions are not properly analyzed. Given that automated traceability techniques tend to struggle to properly establish links even for well-studied datasets we need further insight into the information limits related to traceability artifacts. In this paper, we propose an approach, called TraceXplainer, for using information theory metrics to evaluate and better understand the performance (limits) of unsupervised traceability techniques. Specifically, we introduce self-information, cross-entropy, and mutual information (MI) as metrics to measure the informativeness and reliability of traceability links. Through a comprehensive replication and analysis of well-studied datasets and techniques, we investigate the effectiveness of unsupervised techniques that predict traceability links using IR/ML. This application of TraceXplainer illustrates an imbalance in typical traceability datasets where the source code has on average 1.48 more information bits (i.e., entropy) than the linked documentation. Additionally, we demonstrate that an average MI of 4.81 bits, loss of 1.75, and noise of 0.28 bits signify that there are information-theoretic limits on the effectiveness of unsupervised traceability techniques. We hope that these findings spur additional research on understanding the limits and progress of traceability research.", "sections": [{"title": "I. INTRODUCTION", "content": "In this paper, we explore the phenomenon of information transmission in software traceability. Traceability embodies the study of drawing semantic relationships among software artifacts (e.g., code, requirements, test cases). These semantic relationships are relevant to facilitate code comprehension [31], compliance validation, security tracking [16], [33], and impact analysis [2]. Usually, information retrieval techniques (IR) (e.g., TF-IDF, LSA, or LDA) have been employed to mathematically represent high-level (i.e., requirements) and low-level (i.e., source code) software artifacts in compressed tensors [11], [12], [14], [17]. These tensors are generated via unsupervised learning and employed to calculate a distance (e.g., Euclidean, Cosine, or Word Mover's Distance) between two artifacts in a derived vector space. The distance defines how semantically close two artifacts are to each other. Unsupervised traceability focuses on finding patterns within high and low-level artifacts to confirm whether a data sequence pair source-target is linked.\nThe effectiveness of unsupervised software traceability is measured in terms of canonical learning metrics such as precision, recall, AUC, accuracy, or F1. However, these metrics can be misleading when data are not properly explored and analyzed. For instance, in software traceability, datasets are generally imbalanced, skewed, and biased as we demonstrated in our empirical study. This observation is supported by studies exploring the importance of more rigorous statistical analysis of software engineering research [24], [31]. As such, we believe that there are data limitations related to the underlying software artifacts that traceability techniques operate upon that limit their effectiveness.\nThis paper aims to develop techniques that automatically articulate cases where the information captured in these datasets could make unsupervised techniques trace links ineffectively; therefore, resulting in erroneous predictions. For example, consider a situation where a development team needs to assess the impact of incoming new requirements. How should practitioners proceed if we assume they are unfamiliar with the code-based components of the system under analysis? Practitioners most likely will start by reading the associated documentation (i.e., code comments) to trace the functionality between requirements and code. Nonetheless, what if requirements are poorly written? Or what if certain areas of the source code are not completely documented or obfuscated? Likely, the traceability process practitioners would undertake to understand the impact of the new requirements would be cumbersome and inefficient. We aim to use information science and automated traceability to identify potential artifacts that might negatively contribute to the understandability of a given system.\nBy assuming that data is the central aspect of learning theory, we can claim insufficient or poorly treated data is a deficiency reflected in the effectiveness of unsupervised algorithms [4]. Unfortunately, information retrieval techniques"}, {"title": "II. BACKGROUND & RELATED WORK", "content": "Software requirements should be amenable to being trans-lated into multiple forms of information such as source code, test cases, or design artifacts. Thus, we refer to these requirements or any initial/raw form of information as the source artifacts. Conversely, the information product of a transformation or alteration is considered a target artifact. In the software engineering context, a transformation could be any action that software engineers or practitioners apply from those requirements to source code. For instance, implementing a requirement can be seen as a way of translating information from the requirements to software components. Our research deals with the intersection of software traceability and interpretability techniques to introduce statistical and information theory methods to explain the ineffectiveness of unsupervised traceability.\nSoftware Traceability Techniques. Traceability datasets are composed of corpora of documents and code files. These text artifacts are used to establish a link that relates the content of a source document to the content of a target code file. The links have been recovered by employing distinct techniques from Information Retrieval (e.g., Vector Space Model, Jensen-Shannon Vectors, or Topic Models) [12]\u2013[14], [22] or Machine Learning (e.g., word2vec, doc2vec, AutoEncoders, and Transformers) [15], [27], [28], [33]. However, these techniques misleadingly assume that the distribution and structure of tokens, e.g., words or variable names, present in requirements and source code are similar. Even though source code is essentially a sequence, it is more constrained, repetitive, and structured than natural languages [20], [23]. Ergo, many of the similarities these unsupervised techniques attempt to exploit are flaky and spurious, observed in the wide range of performance (i.e., high variability) these techniques have on different datasets. To date, no study has looked specifically at measuring entropy levels in traceability exploratory analysis. Previous research in traceability has largely overlooked the role of entropy or any information metric when evaluating unsupervised models. Nevertheless, we found studies commenting on the importance of modeling software artifacts as probability distributions [31].\nInterpretability Techniques. Interpretability has been used to explain the predictions generated by (deep) learning models, complementing traditional evaluation methods and enhancing our understanding of the decision-making process to reduce uncertainty. Post-hoc interpretability assumes the model is a black box and analyzes its behavior by examining changes in the output derived from the input. In Machine Learning, most research has focused on improving the plausibility and faithfulness of explanations such as LIME [35], DeepLIFT [36], and Shapley values [29], to the best of our knowledge, our work is the first to evaluate unsupervised techniques for the traceability problem with information theory."}, {"title": "III. INFORMATION THEORY FOR TRACEABILITY", "content": "This section briefly introduces some elements of infor-mation theory required to generate advanced data analysis such as unsupervised interpretability. We present our approach"}, {"title": "a) Software Information Transmission", "content": ""}, {"title": "b) Information Space", "content": ""}, {"title": "c) Semantic Space", "content": ""}, {"title": "TraceXplainer: Using Information Theory to Interpret Unsupervised Traceability Models.", "content": "TraceXplainer as a data-centric solution for the analysis of software traceability. TraceXplainer aims to calculate a set of information measures to complement and explain the limitations of semantic traceability techniques. Understanding such limitations (i.e., bounds) will allow us to assess how well traceability algorithms perform for any set of software projects. Our experiments have established that studying the manifold of information measures (i.e., information and semantic spaces) might help us detect critical points in the artifacts. For instance, traceability links undetected in overlapping information areas of two artifacts $h(x)$ and $h(y)$ (see Fig. 2). These undetected links can be the product of potentially missed documentation or repetitive tokens that need to be refactored to enhance the effectiveness of traceability algorithms. TraceXplainer poses a set of information measures and exemplifies their usefulness in software traceability. Fig. 1 depicts three components of the approach: software information transmission, the information, and the semantic spaces.\nSoftware Information Transmission. Probability theory and information theory are two important frameworks that form the basis of unsupervised interpretability for software traceability. In particular, information theory helps us quantify the amount of information present in software corpora. The software information content can be viewed as the degree of surprise on learning the value of a single artifact x, a discrete random variable. We receive more information for a less probable event than a more probable one. Consequently, a measure of software information content relies on a probability distribution $p(x)$. This measure is a monotonic function $h(x)$ of the probability $p(x)$ that expresses the information content based on the logarithm $h(x) = -log_2 p(x)$. Note that the higher $p(x)$ (i.e., more frequent), the lower the information"}, {"title": "Information Theory Measures in TraceXplainer.", "content": "Software information can be transmitted by copy $[T_c]$ or transformation $[T_s]$ and measured by Mutual Information $I(x: y)$. However, mutual information $I(\u00b7)$ cannot distinguish between a scenario where the target is a copy or a transformed version of the source artifact. Since the basic unit in software artifacts is a set of tokens, the information within the source $x$ can be transmitted by copy if the same amount of tokens is found in the target $y$. While the source $x$ can be transmitted by transformation if the target $y$ suffers a systematic modification in its syntax or semantics [25]. Although software information can be transmitted in both ways, we assume in our empirical experimentation that a function $f(X)$ is by default a copy process. On the other hand, addressing the transformation problem requires further investigation in a formal field of information theory for software engineering. Moreover, our research contributes to formalizing information measures for"}, {"title": "A. [H(X)]: Source Artifacts Self-Information", "content": "Source self-information is the entropy of source artifacts. Consequently, this measure represents the amount of encoded information (i.e., in B bits) in artifacts representing a sender such as requirements, issues, or pull requests. The following example shows the entropy of a real csc, an industrial dataset, pull request:\n\u2022 Source artifact content: \"B dtimeout\"\n\u2022 H(x) = 0.0B (no info.)\nInterpretation. Generally, having a pull request with few (and repetitive) tokens (i.e., words) negatively impacts self-information values. This metric is useful for measuring the content of information in the source. If we track the information content, we will create the conditions to explain why traceability occurs."}, {"title": "B. [H(Y)]: Target Artifacts Self-Information", "content": "Target self-information is the entropy of target artifacts. Intuitively, this measure encompasses the information amount in artifacts representing a receiver such as code, test cases, or configuration files. The following example presents the entropy of a real csc python file showing a standard exception:"}, {"title": "Interpretation.", "content": "The information amount encompassed in the Python file required H(y) = 4.16B. Note that the source content is more diverse than the target, assuming both artifacts are linked. Thus, target self-information is useful when we compare it with the corresponding source. It helps us to detect imbalanced information in a trace link."}, {"title": "C. [I(X: Y)]: Mutual Information", "content": "Mutual Information (MI) embodies the information amount that sources X see of targets Y (and, complementary, Y see of X). Therefore, MI quantifies the information two artifacts hold in common (i.e., the information transmitted from a source to a target). For example, the trace link pull request to code {PR256 \u2192 binaryfunc.py} has an MI of 6.38B, which corresponds to the maximum entropy found in csc. This value suggests that the content in source artifacts overlaps a large portion of the content in the target artifact. However, the potential link {PR56 \u2192 binaryfunc.py} has the same MI as the previous link but it is not a real link according"}, {"title": "D. [H(X|Y)]: Information Loss", "content": "Loss is the amount of information that comes into but does not come out of the channel. Thus, the information cannot be found in the target since either code files have not been implemented yet or some requirements or code files are poorly documented. For instance, the links {PR240 \u2192 binary func.py}, {PR240 \u2192 securityfunc.py}, and {PR168 \u2192 auth.py} present a loss of 6.51B, 6.48B, and 6.3B respectively. These pull requests from csc have in common the low value for self-information content. Therefore, we concluded these requests were not well described in natural language (see more cases in [32])."}, {"title": "E. [H(Y|X)]: Information Noise", "content": "Noise is the information amount that comes out (or is found in the target) but does not come in (or is never depicted in the source). That is, information implemented by a developer that was never mentioned in the issues or requirements. For instance, the links {PR194 \u2192 _init__.py }, {PR177 \u2192 fireException.py}, and {PR56 \u2192 setup.py} exhibit a noise of 1.83B, 1.81B, and 1.55B respectively. These code files present low information content since they are configuration files. Therefore, an interesting question arises: why is there a link between a pull request and a configuration file? (see more cases in [32])."}, {"title": "F. [Si(X: Y)]: Minimum Shared Information", "content": "We introduce the concept of Minimum Shared of Informa-tion (MSI) for entropy Si(X : Y) and extropy\u00b9 Sx(X : Y). MSI differs from mutual information because it solely considers the minimum overlapping of tokens between two artifacts to compute the entropy. For instance, an artifact A has the token count of A = [(for, 14), (if, 3), (return, 10)] and artifact B has the token count B = [(for, 10), (if, 0), (return, 20)]. The minimum shared vector would be min(A, B) or AB = [(for, 10), (if, 0), (return, 10)]. The shared vector represents a probability distribution by which we can compute both minimum entropy and extropy. This minimum entropy is useful for detecting null shared vectors or artifacts whose tokens are completely opposed. Consequently, MSI is the minimum number of tokens shared between the source and target set represented as entropy. For instance, csc contains 5417 potential links whose shared vector is null. Of those potential links, 68 are real links (i.e., ground truth)."}, {"title": "IV. EMPIRICAL DESIGN", "content": "Our empirical analysis explores information measures among software artifacts and presents the relationship between these measures and the effectiveness of unsupervised techniques in interpreting the traceability problem. The focus of our study is using TraceXplainer to interpret the (negative) effectiveness of traceability techniques and practical applica-bility. We formulate the following set of RQs:\nRQ1: How effective are unsupervised techniques at predict-ing candidate trace links using IR/ML representations?\nRQ2: To what extent are semantic metrics imbalanced to the ground truth?\nRQ3: How much information is transmitted from source to target artifacts?\nRQ4: To what extent do information metrics correlate with semantic distances?\n doc2vec. Our base experiment EX0 compresses the use of a pretrained model with Java and Python sources using conventional preprocessing to recover the requirement. Each experiment aims to introduce a perturbation and measure to what extent the perturbation affects the entropy level. Therefore, the experiments EX1 and EX2 variate on the preprocessing tokenizer bpe8k and bpe32k respectively. The EX3 uses conventional preprocessing but uses a pretrained model with a Wikipedia dataset. Finally, EX4 variates on the evaluation testbeds using the same model at the EX0.\nMetrics. To evaluate the formulated RQs, we used our previously described datasets to include the traceability corpora from industry and research and introduced unsupervised machine learning models for predicting traceability links. Each corpus has multiple types of software artifacts as sources and targets such as requirements, test cases, and source code, as well as their ground truth links. To calculate the different information metrics, we used the Python library dit, which is a popular library for discrete information theory. We need to inform requirements or source artifacts to enhance information content to match target artifacts. The next sub-sections explain the metrics to answer each RQ."}, {"title": "A. Experimental Context", "content": "The experimental context aims to answer our RQs from the last sub-section and compresses a set of datasets, trained models, and a set of testbeds to apply our approach.\nDatasets and Training Models. For evaluating our metrics on traceability recovery we pretrained our models by varying the preprocessing type, the vectorization type, and the per-taining dataset. The preprocessing type could be a conventional unsupervised tokenizer based on NLTK [3], bpe8k, or bpe32k. Both BPE encoders, bpe8k, and bpe32k are subwords units from SentencePiece tokenizer [26]. The vectorization technique is skip-gram for word2vec and paragraph vector bg of words (pv-bow) for doc2vec. The pretraining dataset was performed with CodeSearchNet for Java and Python [21], and the Wikipedia set [9]. The embedding size was 500 and epochs were 20 for each model."}, {"title": "Testbeds.", "content": "We use seven system testbeds, six from public sources and one collected by a Cisco Intern. libEST [7] is an open-source project maintained by Cisco. libEST includes traceability links between requirements and test cases in CB (req2tc). itrust, etour, and SMOS are widely recognized CoEST datasets for the use case to source code traceability (uc2src). The Event-Based Traceability dataset EBT links English requirements to Java code, while albergate focuses on traceability between Java classes in a hotel management system. Table I summarizes the datasets, including artifact counts and traceability links."}, {"title": "Experimental Setup.", "content": "Table II summarize the experiments depending on the evaluation system testbed, model pre-train parameters, and IR link type. Each configuration is evaluated using both vectorization types word2vec and"}, {"title": "B. RQ1: Neural Unsupervised Effectiveness", "content": "To evaluate the effectiveness of neural unsupervised tech-niques for traceability, we computed the area under the curve (AUC) from precision-recall curves and the receiver operating characteristic curve (ROC) using the scikit-learn API [5], similar to prior work that evaluates automated traceability techniques [11], [13], [19], [31]."}, {"title": "C. RQ2: Semantic Traceability Imbalance", "content": "To answer RQ2, we estimated the following semantic metrics depending on the neural vectorization technique (i.e., word2vec or doc2vec): Euclidean distance (EUC), Soft Cosine Similarity (SCM), Cosine Distance (COS), and Word Mover's Distance (WMD). We also computed the normalized distance inverse for COS and WMD to obtain the COS similarity and WMD similarity. These distances and similarities were com-puted for pairs of source-target artifacts in each testbed. These pairs are represented in the vector space after unsupervised"}, {"title": "encoding.", "content": "We can segregate the distances and similarities by ground truth since we can classify potential links into actual links and non-links. Such segregation depicts imbalances in the semantic space (see Fig. 1)"}, {"title": "D. RQ3: Exploratory Information Analysis", "content": "To compute the set of information measures introduced in TraceXplainer, we conducted an Exploratory Data Anal-ysis (EDA). Our EDA consisted of an exhaustive statistical search of patterns and descriptive statistics within the reported information theory measures. The exploration allows us to interpret how well an unsupervised technique for traceability performs. Our goal is to use information measures to describe and interpret the effectiveness of unsupervised traceability techniques. We proposed two analyses:\nAN\u2081: Manifold of Information Measures. This exploration aims to determine the probability distribution of each entropy and similarity metric. We have some assumptions about the shape of the expected distributions. For instance, similarity distributions should be bimodal since we want to observe a link and a non-link. If our assumptions do not match the expected distribution, we can assess the quality of the technique.\nAN2: Manifold of Information Measures by Ground truth. This exploration segregates each entropy and similarity metric by the ground truth. The data division by ground truth allows us to interpret the prediction quality for similarity metrics. Additionally, it also allows us to describe how good the ground truth leverage process was for each testbed because we can monitor the information transmission between source and target artifacts with TraceXplainer."}, {"title": "E. RQ4: Correlation Analyses", "content": "We correlate semantic distance and similarity metrics with information theory measures in a scatter matrix using Pearson coefficient. This analysis aims to expose highly correlated relationships across unsupervised distances and information measures to explain traceability outputs rationale with the information transmission setup proposed in TraceXplainer."}, {"title": "V. RESULTS & DISCUSSION", "content": "Our empirical evaluation consists of four experiments fo-cused on the following data science tasks: i) describing dis-tance and information measures, iii) predicting trace links, and iii) estimating correlations between semantic distance and information transmission by varying the preprocessing strategy (i.e., conventional or bpe), the type of embeddings (i.e., word2vec or doc2vec), and the pretraining dataset (i.e., CodeSearchNet or wikipedia)."}, {"title": "A. RQ1: Traceability Effectiveness Results", "content": "The traceability evaluation consists of measurements of the link recovery accuracy. The link recovery is computed in preci-sion, recall AUC, and ROC. The higher AUC value indicates a better model performance. Nevertheless, Table III depicts both unsupervised techniques (i.e., word2vec and doc2vec) do not capture semantic similarity efficiently, the skip-gram model for"}, {"title": "B. RQ2 Semantic Traceability Imbalance Results", "content": "Table IV summarizes the observed results for the similarity soft-cosine (SCM), word mover's distance (WMD), cosine distance (COS), and euclidean distance (EUC). The low values SCM (i.e., 0.1 at csc and EBT) indicate low similarity between the source and target. We estimate a maximum of 0.51 WMD for libEST on the EX1, which indicates WMD"}, {"title": "C. RQ3 Exploratory Information Theory Results", "content": "AN1: Information measures. Table IV depicts the self-information for source and target artifacts, the noise, loss, mutual information, and the minimum shared information. We observe the self-information H(X) of the source artifacts (or issues) in on average 4.92[1.25]B, while the self-information of the target artifacts (or source code) H(Y) is on average 6.4[0.95]B suggesting that the amount of information of H(Y) is on average 1.48B larger than the amount of information in the set of H(X). The last means the source has less information than the target even when the source is more expressive as it uses natural language tokens.\nWe observe the highest noise at the experiment EX4 with albergate with a value of 0.91B. Notably, when computing the difference between the self-information H(X) and H(Y) we observe the highest unbalanced information for the csc system at the experiments EX0 and EX3 with a value of 2.49B. This result indicates non-related information between the source and target and confirms the semantic distance results SCM for the same testbeds and experiments.\nThe Mutual Information averages 4.61[1.21]B indicating a positive transmission of information from the source to the target. The Minimum Share Information Entropy Si is on average 2.68[1.57]B, and the Minimum Shared Extropy Sx is on average 1.11[0.28]B for all the experiments suggesting the source and target possess information in common. However, the target could not share information with the source as depicted at EX4 with EBT testbed where we observe an Si of 0.61B and a loss of 2.01B. The loss difference of 0.96B"}, {"title": "AN2: Information measures by Ground Truth.", "content": "Unfortu-nately, information measures are not being affected by the nature of the traceability (see Table V information metrics). H(X) and H(Y) are on average similar for links and non-links. That is, information is independent of whether a link between two artifacts exists or not. Nonetheless, all sequence-based artifacts are related somehow -or share some information amount-, this independent behavior is not expected in similar-ity metrics such as SCM, EUC, or WMD. Neural unsupervised techniques based on skip-gram models are unable to binary classify a link. In other words, data do not have encoded the necessary patterns to determine the classification. We need to employ probabilistic models to intervene in the expectation value of a link [31] or systematic refactorings on the artifacts.\nSummary. Although the information amount in the source code is larger than in the set of issues; the MI, loss, and noise are indistinguishable from confirmed links to non-links. We expect low mutual information values and high loss and noise information amounts for non-related artifacts."}, {"title": "D. RQ4 Correlation Results", "content": "Scatter Matrix for Information Measures. Correlations help explain variables that we are not easily able to describe just by observing their values. Correlations are useful to interpret the causes or detect similar patterns for a given metric. In this case, we want to study similarity variables by correlating them with other similarity variables and information measures (e.g., MI, Loss, Noise, Entropy, etc). The manifold in Table VI depicts correlations and distribution of each information variable. We"}, {"title": "Mutual Information & Shared Information Entropy and Extropy.", "content": "This analysis consists of computing a correlation between the distance and entropy. Mutual information is negatively correlated with WMD (positively correlated with WMD similarity) as observed in Table VI. This implies that the larger the amount of shared information, the less distance among artifacts; until we observe that MI is not correlated with the cosine similarity. Is the word vector capturing better se-mantic relationships than paragraph vectors? Both approaches are underperforming according to the binary classification performance.\nOn the other hand, the MSI for entropy is also negatively correlated with the WMD (see Table VI). The trend is expected after observing the correlation with the mutual information. We show more evidence that WMD similarity captures better semantic relationships among artifacts.\nComposable Manifolds. The composable manifolds are use-ful for inspecting a third information variable. In this case, we focused on the loss and noise (see Fig. 4). We observe"}, {"title": "Summary.", "content": "Loss entropy is associated with low levels of similarity and mutual information. We can intervene in traceability datasets to help improve link classification by reducing the loss. Such interventions (i.e., refactorings) can occur because practitioners complete or document artifacts during the software life-cycle."}, {"title": "VI. A CASE STUDY IN INDUSTRY", "content": "This section shows four information science cases from processing the csc testbed. Experiments and samples can be found in our online appendix [32], [34].\nCase: Self-Information. This study highlights the informa-tion imbalance between the source and target artifacts. Arti-facts with low entropy struggle to generate traceability links since unsupervised techniques rely on concise descriptions in natural language. By contrast, high levels of entropy struggle with other conditions like loss or noise. Refactoring operations need to be applied to source and target artifacts to combat the information imbalance. At least, a semantic idea expressed as a clause is required in both artifacts to guarantee a link. When we preprocess the source code, we transform the code structure into a sequence structure to extract those clauses. In other words, source code is not treated as a structured language but as a regular text file. The amount of information lost by preprocessing source code as text has not been yet computed.\nCase1: Minimum and maximum loss. This study presents edge cases for entropy loss to identify poorly documented target artifacts. Edge cases of loss are useful to detect starting points for general refactoring in the target documentation. The max case shows us the pull request content composed of just one word. The tokens that represent this word were not found in the target artifact, which is one of the highest entropy files. Whereas, the min case shows us the pull request has a complete description not found in the target. Note the 99% quartile for positive links. The PR content cannot be easily found in the source code with low entropy, even if a practitioner tries to extract links manually.\nCase2: Minimum and maximum noise. This study presents edge cases for the entropy noise to identify poorly documented source artifacts. Edge cases of noise are useful to detect refac-torings in documentation found in the source documentation. In the max case, the PR content is high, but the target artifact is empty. This suggests that the target is not well documented. Something similar occurs in the min case, where the PR content is repetitive and less expressive."}, {"title": "Case3: Orphan informative links.", "content": "This study points out a set of informative links not found in the ground truth. Orphan links not only exhibit inconsistencies in the ground truth file but also suggest potential positive links independent of the employed unsupervised technique."}, {"title": "VII. CONCLUSION & FUTURE WORK", "content": "The core idea of using Information Measures with Soft-ware Traceability is to interpret, determine, and quantify the boundaries of the effectiveness of Unsupervised techniques. We demonstrated traceability data is insufficient to derive a trace pattern when information measures are not in optimal ranges. Hence, unsupervised techniques are limited approaches to producing reliable links. However, we can also determine to what extent information is lost during the transmission process source-target (i.e., Pull Request \u2192 Code). Loss and noise could be relevant information measures for security purposes i.e., why a given piece of source code is not covered by the corresponding requirements?\nWe sought to understand the information amount in state-of-the-art traceability datasets to determine why unsupervised techniques (i.e., word2vec and doc2vec) recover links ineffec-tively. To accomplish this, we evaluated four main information metrics using TraceXplainer: self-information, loss, noise, and mutual information. Complementary, we propose an ad-ditional metric, shared information, where we determine the overlap entropy across source and target artifacts. Finally, we conducted an empirical analysis to show how our approach contributes to interpreting unsupervised model predictions.\nOur findings highlight an important area for future research: bridging the gap between unsupervised interpretability and the problem of automated software traceability. A viable direction to move beyond our research is to use TraceXplainer measures to help guide practitioners toward writing better artifacts because TraceXplainer quantifies the bits required to represent sets of source and target artifacts and their transmission. For example, a requirement contains \u201cbucle\u201d, a natural language token, as the source, while the target contains a code token \"for\". In this scenario, mutual information (MI) between these tokens is zero despite they have similar semantic spaces. The difference lies in the fact that the source operates within the natural language semantic space, whereas the target belongs to the code semantic space. Although unsupervised models can identify semantically related tokens, as in our previous example, our empirical analysis demonstrates that the semantic matching ability is insufficient for handling imbalanced data. Estimated MI and MSI for ground truth links show, therefore, no significant differences."}]}