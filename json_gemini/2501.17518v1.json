{"title": "RegD: Hierarchical Embeddings via Distances over Geometric Regions", "authors": ["Hui Yang", "Jiaoyan Chen"], "abstract": "Hierarchical data are common in many domains like life sciences and e-commerce, and their embeddings often play a critical role. Although hyperbolic embeddings offer a grounded approach to representing hierarchical structures in low-dimensional spaces, their utility is hindered by optimization difficulties in hyperbolic space and dependence on handcrafted structural constraints. We propose RegD, a novel Euclidean framework that addresses these limitations by representing hierarchical data as geometric regions with two new metrics: (1) depth distance, which preserves the representational power of hyperbolic spaces for hierarchical data, and (2) boundary distance, which explicitly encodes set-inclusion relationships between regions in a general way. Our empirical evaluation on diverse real-world datasets shows consistent performance gains over state-of-the-art methods and demonstrates RegD's potential for broader applications beyond hierarchy alone tasks.", "sections": [{"title": "1. Introduction", "content": "Embedding discrete data into low-dimensional vector spaces has become a cornerstone of modern machine learning. In Natural Language Processing (NLP), seminal works such as word2vec (Mikolov et al., 2013) and GloVe (Pennington et al., 2014) represent words as vectors to capture intricate linguistic relationships. Similarly, knowledge graph embedding methods (Bordes et al., 2013; Sun et al., 2019; Balazevic et al., 2019) encode entities and relations as vectors with their semantics concerned to facilitate reasoning and prediction.\nOur work focuses on embedding hierarchical data into low-dimensional spaces. Such data represents partial orders over sets of elements, denoted as u \u4eba v, where u is a parent of v. These partial orders naturally manifest as trees or directed acyclic graphs (DAGs). The ability to effectively embed such hierarchical structures enables crucial operations like inferring sub- or superclasses of concepts and classifying nodes within graphs. These capabilities are essential for various tasks in knowledge management and discovery, particularly towards knowledge bases (Shi et al., 2024; Abboud et al., 2020), ontologies (He et al., 2024a; Chen et al., 2024) and taxonomies (Shen & Han, 2022).\nCurrent methods for embedding hierarchical data can be broadly categorized into two paradigms: region-based and hyperbolic approaches. The region-based approach usually represents entities as geometric regions in the Euclidean space, capturing hierarchical relationships through intuitive region-inclusion. However, these methods often experience degraded performance in low-dimensional settings due to the crowding effect inherent in Euclidean spaces.\nIn contrast, the hyperbolic approach takes advantage of the unique geometric properties of hyperbolic spaces \u2013 specifically their exponential growth in distance and volume \u2013 enabling more effective embeddings of tree-structured data in low dimensions. However, existing hyperbolic methods often rely on specialized constructions informed by theoretical analysis or physical models (Ganea et al., 2018; Yu et al., 2024), limiting their applicability beyond strictly hierarchical data. Additionally, training in hyperbolic space is challenging due to precision issues and the complexities of Riemannian optimization.\nIn this paper, we propose a flexible framework named RegD for modeling hierarchical data by embedding arbitrary regions in Euclidean spaces. Our framework relies on two novel distance metrics, depth distance and boundary distance, which combine the strengths of both region-based approaches in Euclidean spaces and hyperbolic methods.\n\u2022 The depth distance (cf. Section 3) enables our model to achieve similar embedding expressivity to hyperbolic spaces by incorporating the \"size\" of the regions under consideration. Its computation involves only simple operations, thereby reducing computational complexity and eliminating the need for enhanced numerical precision required by hyperbolic methods.\n\u2022 The boundary distance (cf. Section 4) improves the representation of set-inclusion relationships among regions in Euclidean spaces. This allows for better identification of shallower and deeper descendants, thereby capturing hierarchical structures more effectively than traditional region-based approaches.\nCombining these two distances, we designed a closed formula (cf. Section 5) for determining the partial order of two concepts based on their embedded regions, which is used in both the training and evaluation processes.\nNotably, RegD can be applied to arbitrary regions, including common geometric representations such as balls (hyperspheres) and boxes (hyperrectangles). This generality enables broad applicability across diverse geometric embeddings for various tasks, extending beyond hierarchy alone data to ontologies that include hierarchies and more complex relationships in Description Logic (Baader et al., 2017) (cf. Sections 6.2 and 6.3). Our main contributions are summarized as follows:\n\u2022 We present a versatile framework that is able to embed hierarchical data as arbitrary regions in Euclidean space.\n\u2022 We offer a rigorous theoretical analysis demonstrating that our framework retains the core embedding benefits of hyperbolic methods.\n\u2022 Experiments on diverse real-world datasets demonstrate that our framework consistently outperforms existing approaches on embedding hierarchies and ontologies for reasoning and prediction."}, {"title": "2. Preliminaries and Related Works", "content": "Manifold and Hyperbolic Space A d-dimensional manifold (Lee, 2013), denoted M, is a hypersurface embedded in an n-dimensional Euclidean space, Rn, where n \u2265 d, and locally resembles Rd. A Riemannian manifold M is a manifold equipped with a Riemannian metric, enabling the definition of a distance function dm(x, y) for x, y \u2208 M. Hyperbolic space, denoted Hn, is a Riemannian manifold with a constant negative curvature of -k, where k > 0 (Lee, 2006). It can be represented using various isometric models, such as the Poincar\u00e9 half-space model, where the points are defined by the half-space: Un = {x \u2208 Rn : xn > 0}, and the hyperbolic distance between x, y \u2208 Un is given by\n$d(x, y) = \\frac{1}{\\sqrt{k}} \\arccos \\Big(1 + \\frac{||x - y||^2}{2x_n y_n}\\Big)$\nRegion-based Methods Region-based methods embed the nodes of a directed acyclic graph (DAG) into geometric regions, such as boxes (Boratko et al., 2021), balls (Suzuki et al., 2019), and cones (Vendrov et al., 2016), capturing hierarchical relationships through set-inclusion between these regions. Training is typically conducted using an inclusion loss, which is often defined in terms of the distance or volume of the regions (Vendrov et al., 2016). However, such loss functions may involve non-smooth operations, like maximization, which have been addressed through probabilistic (Vilnis et al., 2018; Dasgupta et al., 2020) or smooth (Boratko et al., 2021) approximations to improve performance.\nDue to the crowding effect in the Euclidean space, region-based methods could exhibit suboptimal performance in low-dimensional spaces or when representing large DAGs. To address this challenge, Suzuki et al. (2019) proposed using balls on Riemannian manifolds, enabling more flexible shapes beyond the canonical balls used in Euclidean space. However, leveraging Riemannian manifolds introduces more complex optimization and training processes, which can struggle with tasks beyond hierarchical structures. This makes the approach more restrictive compared to ours, which offers broader applicability.\nWhile Boratko et al. (2021) demonstrates that box-based embeddings in Euclidean spaces can represent any DAG, their focus is on reconstructing DAGs rather than preserving the graph's transitive properties. Consequently, this approach does not guarantee the faithful capture of hierarchical semantics unless all transitive closure edges are included in the training data.\nHyperbolic Methods Hyperbolic space embeddings were first introduced for modeling hierarchical structures by (Nickel & Kiela, 2017). This approach combines hyperbolic distance with the Euclidean norm to represent hierarchies. However, it does not explicitly capture hierarchical relationships and struggles to model the transitivity inherent in these structures. To address these limitations, EntailmentCones (Ganea et al., 2018) and ShadowCones (Yu et al., 2024) were proposed. These methods enhance hierarchy modeling by constructing specific cones in a hyperbolic space: EntailmentCones introduced closed-form hyperbolic cones, determined by their apex coordinates, to ensure transitivity, while ShadowCones is inspired by the physical interplay of light and shadow.\nDespite the representational power of hyperbolic spaces, training in non-Euclidean spaces poses unique challenges. Precision-related issues, for example, often arise near the boundaries of the Poincar\u00e9 half-space model, necessitating high-precision tensor operations that increase both storage requirements and computation time. Moreover, achieving optimal performance in hyperbolic spaces typically requires specialized training techniques, such as burn-in strategies (Yu et al., 2024), custom initialization meth-"}, {"title": "3. Depth Distance: Similarly Distance Consdiering Depth", "content": "Unlike the Euclidean space, which is constrained by crowding effects that limit its embedding capacity, the hyperbolic space leverage exponential growth in distance and volume to offer superior embedding capabilities. This property makes the hyperbolic space particularly effective for representing tree-structured data in low-dimensional spaces. Notably, two key distinctions arise between region-based embeddings in the Euclidean space and hyperbolic embeddings:\n1. The hyperbolic space better discriminate different hierarchical layers than the Euclidean space.\nConsider the taxonomy illustrated in Figure 1 (left). Intuitively, since human is a subcategory of animal, the semantic difference between human and plant should be greater than that between animal and plant. The hyperbolic space effectively captures this hierarchical relationship by permitting d(Uhuman, Uplant) > d(vanimal, Uplant) + \u2206, where \u2206 is an arbitrary gap. This arises from the property that the distance metric diverges to infinity near the boundary, as illustrated by the shadow dense of the bar on the left-hand side of H2 in Figure 1 (middle). In contrast, region-based embeddings on Euclidean space may violate this hierarchical constraint, potentially placing the box Bhuman close to Bplant, resulting in a distance (e.g., the Euclidean distance between box centers) similar to or even smaller than that between Banimal and Bplant.\n2. The hyperbolic space enable the distinct representation of an arbitrary number of child nodes.\nAs demonstrated in Figure 1, the box embeddings in the Euclidean space face inherent limitations when representing multiple children of a node such as animal. As the number of children increases, their corresponding boxes must cluster within Banimal, leading to crowding. In contrast, the hyperbolic space can accommodate an arbitrary number of children while maintaining distinct separations between them. This capability arises from the exponential growth of distance near the boundary of the hyperbolic space, which allows unlimited child nodes to be positioned distinctly by placing them progressively closer to the boundary while preserving meaningful distances between them.\nIn the following sections, we introduce the depth distance for regions in Euclidean space which considers the \"size\" of regions. We demonstrate that this measure exhibits advantages similar to those of hyperbolic spaces discussed above (Theorem 1), while maintaining a simpler structure that facilitates implementation. Furthermore, we prove that our depth distance can be equivalent to hyperbolic distance when using specific nonlinear functions, and even with simple polynomial functions, it preserves key properties of hyperbolic geometry (Propositions 1, 2)."}, {"title": "3.1. Construction", "content": "The depth distance serves as a similarity measure that quantifies the relationship between objects considering their hierarchical depth. As we use set-inclusion relations to model the hierarchy, this hierarchical depth can be represented through the size of the regions, such as their volumes or diameters. Formally, the depth distance is defined as follows, where the size of the regions is represented by a function f (reg):\nDefinition 1 (Depth Distance). Let R be a collection of regions in the n-dimensional Euclidean space Rn, where each region reg \u2208 R is characterized by an m-dimensional parameter par(reg) \u2208 Rm. The depth-aware similarity distance between two regions reg\u2081, reg2 \u2208 R, is defined as:\nddep(reg1, reg2) = g\\Big(-\\frac{||par(reg\u2081) \u2013 par(reg2)||_p}{f(reg1) f(reg2)}\\Big)\nwhere || . ||p is the p-norm (i.e., ||x||p = (\u03a3\u2081x)1/p), and:\n\u2022 g: R>o \u2192 R>0 is an increasing function such that g(x) = 0 if and only if x = 0,\n\u2022 f: R\u2192R>0 is a function that measures the size of regions. It satisfies: limreg\u2192\u00f8 f (reg) = 0\u00b9.\nWe require f and g to have non-negative values to ensure the depth distance is non-negative. Additionally, we stipulate that limreg\u2192\u00f8 f(reg) = 0 to guarantee that as a region shrinks to an empty set, the distance between this object and others can approach infinity. This setting emulates the beneficial properties of the hyperbolic space, where the distance between two points can grow rapidly as they approach the boundary of the space (i.e., xn = 0 in the Poincar\u00e9 half-space model). In our context, the boundary of the space R of a collection of (parametrized) regions in the Euclidean space is the empty set. By selecting an appropriate function f, we can control the rate at which the distance between two objects increases as they approach this boundary."}, {"title": "3.2. Comparasion with the Hyperbolic Distance", "content": "By choosing appropriate functions f and g, we can construct a region space that is equivalent to the hyperbolic space, as demonstrated by the following theorem.\nProposition 1. Let H[n+1 be the hyperbolic space with curvature -1. Assume the ball space Br is parameterized as in Example 1, and equipped with the depth distance defined in Equation (1). Then the map\nF:\nBnHn+1\nball(c, r) \u2192 [c :r]\nis an bijective isometry when p = 2, g(x) = arcosh(x+1), and f(ball(c, r)) = \u221a2r.\nRemark 1. The mapping F above can be generalized to arbitrary regions. For example, we could extend F by replacing the center point and radius of balls with the center of gravity and diameters of any region. However, in this case, the function F might be non-injective, as distinct regions may share the same center of gravity and diameters. Therefore, the resulting region space serves more as an extension rather than an equivalence of hyperbolic space.\nMoreover, the following result demonstrates that even with simple linear function g(\u00b7), our depth distance retains the"}, {"title": "4. Boundary Distance: Non-Symmetric Distance for Inclusion", "content": "Although the depth distance ddep introduced above has been shown to have great power for embedding hierarchical data, it is a symmetric distance and therefore inadequate for fully capturing the inherently non-symmetric hierarchical relationships between objects. To address this limitation, we introduce the boundary distance, specifically designed to reflect the partial order of regions defined by set inclusion.\nTo the best of our knowledge, the concept of boundary distance was first introduced and applied to the embedding of hierarchical data by ShadowCone (Yu et al., 2024). However, their construction is limited to specific types of cones defined in hyperbolic space, and its computation requires"}, {"title": "4.1. Construction", "content": "The boundary distance is defined to measure the minimal cost associated with transforming the spatial relationship between two regions reg\u2081 and reg2. Specifically, it quantifies the cost of moving reg2 out of reg\u2081 when reg2 \u2286 reg\u2081, or moving reg2 into reg\u2081 otherwise (when reg2 \u2288 reg\u2081). This cost can be defined for arbitrary geometric objects based on either distance or volume within Euclidean or other spaces. Below, we introduce a boundary distance based on the Euclidean distance for two regions reg1, reg2 \u2208 Rn, which consists of two cases:\n1. Containment (reg2 \u2286 reg\u2081): As illustrated in the left of Figure 2, when reg2 is fully contained within reg\u2081, the boundary distance is defined by the minimum Euclidean distance between the complementary region reg\u2081 and the points in reg2 (i.e., length of the red line). This distance quantifies the minimum translation cost required to move at least a part of reg2 out of reg1.\n2. Non-Containment (reg2 \u2288 reg\u2081): As shown in the right of Figure 2, when reg2 is not fully contained within reg1, the boundary distance is defined as the maximum Euclidean distance from the points in reg2 \\ reg\u2081 to reg1 (i.e., length of the red line). This distance quantifies the minimum translation cost for moving reg2 into reg1.\nLet d(x, reg) := min{||xy||2 || y \u2208 reg} be the distance of a points x to a region reg defined by the minimal distance from x to y \u2208 reg. The formal definition of the boundary distance is as follows:\nDefinition 2 (Boundary Distance). Given a region space R, we define the boundary distance over reg1, reg2 \u2208 R by:\nd_{bd}(reg_1, reg_2) = \\begin{cases}\\min \\{d(reg_1, x_2)\\} & \\text{if } reg_2 \\subseteq reg_1 \\\\ x_2 \\in reg_2 \\\\ \\max \\{d(reg_1, x_2)\\} & \\text{else}. \\\\ x_2 \\in reg_2\\backslash reg_1\\end{cases}\nNote that a negative sign is added to d\u266dd(reg1, reg2) in the containment case (reg2 \u2286 reg\u2081) to clearly distinguish it from other cases. Moreover, the boundary distance is inherently asymmetric, that is, dbd(reg1, reg2) \u2260 dbd(reg2, reg1) in general. For example, as illustrated in Figure 2, the"}, {"title": "4.2. Specific Constructions for Boxes or Balls", "content": "For specific geometric regions like balls and boxes, we can create specialized distance functions to measure the set-inclusion relationship based on their intrinsic geometric properties or established methods. Our framework accommodates these specialized metrics by allowing them to replace the general boundary distance function.\n1. Volume-based distance for boxes: Since the volume of a box can be computed as the product of its offsets along different dimensions, we can define a partial distance based on volume:\nd_{vol}(reg_1, reg_2) = - ln\\Big(\\frac{vol(reg_1 \\cap reg_2)}{vol(reg_2)}\\Big).\nThe negative logarithm ensures that the distance is non-negative and equals zero only when reg2 \u2286 reg1.\n2. hyperbolic distance for balls: Yu et al. (2024) introduced a series of circular cones in hyperbolic space and defined a boundary distance based on the hyperbolic distance between the apex of these cones. By utilizing the natural mapping from balls to circular cones, we can derive a new boundary distance for balls as follows:\nd_{bane}^{cone}(reg_1, reg_2) = arcsinh\\Big(\\frac{||c_1 - c_2|| - 1}{r_2}\\Big) + a,\nwhere a = arcsinh(1). See Appendix B for more details."}, {"title": "5. Training Strategy", "content": "Energy For a given pair (u, v), we define their energy as:\nE(u, v) = d_{bd}(reg_u, reg_v) + \\lambda\\cdot d_{dep} (reg_u, reg_v),\nwhere \u03bb is a weighting parameter that balances the contributions of the hyperbolic-like depth distance. This formulation ensures the simultaneous preservation of hyperbolic structural properties when needed, while maintaining the asymmetry characteristic of hierarchical relationships.\nLoss To train our model, we employ a modified contrastive loss function as in (Yu et al., 2024):\n\\mathcal{L}(\\gamma_1, \\gamma_2) = \\sum_{(u, v) \\in \\mathcal{P}} max\\{E(u, v), \\gamma_1\\} + log \\Big(\\sum_{(u, v') \\in \\mathcal{N}} e^{max\\{2 - d_{bd}(reg_u, reg_{v'}), 0\\}}\\Big)"}, {"title": "6. Evaluation", "content": "Our experiments aim to address two questions: (1) How effectively do our methods capture hierarchical relationships? and (2) Can they generalize to tasks involving more than hierarchies?\nWe evaluate hierarchical relationship modeling using transitive DAGs (Section 6.1). To assess generalization, we test on ontologies (see Appendix E for a formal definition), which extend pure hierarchies by incorporating logical operations like conjunction (\u03a0) and existential quantifiers (\u2203r.). Ontologies contain \u201cSubclassOf\u201d (\u2286) as a fundamental and ubiquitous relation, representing hierarchical structures. This makes ontologies ideal for evaluating beyond pure hierarchy modeling. Specifically, ontologies enable testing of: (a) Complex inferences tasks beyond transitive closure (Section 6.2); and (b) Link prediction across different, usually non-SubclassOf relations (Section 6.3)."}, {"title": "6.1. Inferences over DAG", "content": "Benchmark Following (Yu et al., 2024), we evaluate our method on four real-world datasets consisting of Is-A relations: MCG (Wang et al., 2015; Wu et al., 2012), Hearst patterns (Hearst, 1992), the WordNet (Fellbaum, 1998) noun taxonomy, and its mammal subgraph. All models are trained exclusively on basic edges, which are edges not implied transitively by other edges in the graph. For validation and testing, we use the same sets as in (Yu et al., 2024), consisting of 5% of non-basic (inferred) edges, ensuring a fair comparison.\nWe exclude non-basic edges from training since they can be transitively derived from basic edges. Including them would artificially inflate performance metrics without properly evaluating the embeddings' ability to capture hierarchical structures. For completeness, results for non-basic cases are provided in Appendix F.1.\nBaselines We compare our method RegD with (i) hyperbolic approaches such as EntailmentCone (Ganea et al., 2018) and ShadowCone (Yu et al., 2024), which is the latest method with the state-of-the-art performance; (ii) region-based methods like OrderEmbedding (Bordes et al., 2013), and tBox (Boratko et al., 2021). We also compare with the ontology embedding methods, ELBE (Peng et al., 2022) and ELEM (Kulmanov et al., 2019), which can be considered as the baseline approaches embedding the DAG as boxes or balls, respectively. As in previous studies, the performance is evaluated using F1-scores.\nResults The performance comparison across different DAGs is shown in Table 1. RegD achieved the best performance on all four datasets. Notably, the box variant consistently outperformed the ball variant in most cases, which might be because boxes contain more parameters than balls when embedded in the same dimensional space.\nInterestingly, on the MCG and Hearst datasets, region-based methods outperformed hyperbolic methods. This may be attributed to the relatively low \u201chyperbolicity\" of these datasets, as indicated by their larger \u03b4-hyperbolicity values in Table 2. In contrast, on the Noun dataset, despite its high \u03b4-hyperbolicity value, hyperbolic methods performed better. This discrepancy is likely due to the larger dataset size\u2014containing over twice the number of nodes compared to the others\u2014which leads to crowding effects in Euclidean space that limit the effectiveness of region-based methods. Nevertheless, our method performed consistently well in both cases, as it can adjust the hyperbolic component by setting different \u03bb values in Equation (7)."}, {"title": "6.2. Inference over Ontologies", "content": "Benchmark We utilize three normalized biomedical ontologies: GALEN (Rector et al., 1996), Gene Ontology (GO) (Ashburner et al., 2000), and Anatomy (Uberon) (Mungall et al., 2012). As in (Jackermeier et al., 2024), we use the entire ontology for training, and the complete set of inferred class subsumptions for testing. Those subsumptions can be regarded as partial order pairs u\u3145 v. Evaluation is performed using 1,000 subsumptions randomly sampled from the test set. Similar to inference over DAG, negative samples are generated by randomly replacing the child of each positive pair 10 times.\nBaselines We focus on the most representative ontology embedding methods: ELBE (Peng et al., 2022) and ELEM (Kulmanov et al., 2019), as well as their enhanced versions incorporating RegD or Box. Other hierarchy embedding methods are excluded from our tests due to their incompatibility with ontology embeddings. For example, OE and EntailmentCone utilizes cones as embedding objects, which cannot be directly integrated with ELBE or ELEM for on-"}, {"title": "6.3. Link Prediction over Ontologies", "content": "We use the same baselines and datasets as described in Section 6.2. However, in this prediction task, we partition the original ontologies directly into 80% for training, 10% for validation, and 10% for testing as in (Jackermeier et al., 2024). For the link prediction task, we focus on specific parts of the validation and testing sets, represented as \u2203r.B \u4eba?A, where A and B are concept names and r is a role. This setup is equivalent to link prediction tasks (?A, r, B) in knowledge graphs if we regard A, B, and r as the head entity, tail entity, and relation, respectively."}, {"title": "7. Conclusion", "content": "We introduced a framework RegD for low-dimensional embeddings of hierarchies, leveraging two distance metrics between regions. Our method, applicable to regions in the Euclidean space, demonstrates versatility and has the potential for a wide range of tasks involving data beyond hierarchies. Additionally, we showed that our approach achieves comparable embedding performance to hyperbolic methods while"}, {"title": "A. Proofs", "content": ""}, {"title": "A.1. Theorem 1", "content": "Proof of Theorem 1. We begin by proving the result for balls and addressing each item as follows:\n1. Assume reg1 = ball(c1, r1) and reg2 = ball(c2, r2). For any ball ball(c',r') \u2286 ball(c2, r2) with r' \u2264 0.5\u00b7 r1, we must have:\n\u2211ci - c + r - r'\\P > (0.5\u00b7r\u2081)P.\nTherefore, we have:\nddep (reg1, ball(c', r')) = \\frac{\\sum_i |c_i - c'|p + |r - r'|^P}{f (ball) f (ball')}\n> \\frac{(r_1)^P}{f (ball) f (ball')}\nThus, when:\nf(ball(c', r')) < \\epsilon := \\frac{f (ball) f (ball')[ddep (reg1, reg2) + N]}{(r_1)^P},\nwe can guarantee that ddep (reg\u2081, ball(c',r')) > ddep(reg1, reg2) + N.\nNote that by our assumption, we have:\nlim f(reg) = 0.\nreg\u2192\nTherefore, there exists a d > 0 such that when r < d, we have f(reg) \u2264 \u03f5 for reg = ball(c, r). In conclusion, ro = min{\u03b4, 0.5 \u00b7 r1} satisfies the required condition.\n2. Assume reg ball(c, r). For any n, M > 0, we can select n distinct vectors c1, ..., cn \u2208 ball(c, 0.5 \u00b7 r) such that:\n||ci - cj ||> d > 0 for some \u03b4 > 0.\nSimilarly to item 1, we can choose d small enough such that for any ball ball(ci, ri) with ri < d, we have:\nf(ball(ci, ri)) < \\Big(\\frac{\\delta}{M}\\Big)^{0.5}\nThus, we obtain:\nddep (ball(ci, ri), ball(cj, rj)) = \\frac{\\delta}{f(ball(ci, ri)) f (ball(cj, rj))} \u2265 M.\nThis concludes the proof of item 2.\nThe proof for the case of boxes follows the same reasoning, with the radius r replaced by the offset o or its norm ||0||."}, {"title": "A.2. Proposition 1", "content": "Proof of Proposition 1. Recall that when the curvature is -1, the distance in the hyperbolic space (half-plane model) is given by:\nd_{H}(x,y) = arcosh \\Big(1 + \\frac{||x - y||^2}{2x_n y_n}\\Big).\nThe distance induced by the function F is of the form:\nd^{H}(ball(c, r), ball (c'.r') = arcosh \\Big(1 + \\frac{||c - c'||^2 - (r - r')^2}{2r r}\\Big)\nThis coincides with the depth distance in Example 1 when p = 2, g(x) = arcosh(x + 1), and h(ball) = \u221a2. This completes the proof."}, {"title": "A.3. Proposition 2", "content": "Proof of Proposition 2. This proposition follows directly from Proposition 1. The function g(x) = arcosh(x + 1) is an increasing bijection from R>0 to R>0. Thus, for any x, x' \u2265 0, we have:\nx \u2264 x' \u21d4 g\u00af\u00b9(x) \u2264 g\u00af\u00b9(x').\nBy the assumption of this proposition, ddep(\u00b7,\u00b7) = g\u00af\u00b9(d\u00edn (\u00b7, \u00b7)). Therefore, for any points X1, X2, X3, X4 \u2208 H\u201d, we have:\ndin (X1,X2) < din (X3, X4)\nif and only if\nddep (F-1(x1), F-1(x2)) < ddep(F-1(x3), F-1(x4))."}, {"title": "A.4. Proposition 3", "content": "Proof of Proposition 3. We prove each item one-by-one:\n1. By definition, we have d\u266dd(reg1, reg2) \u2264 0 if and only if reg\u2081 \u2286 reg2. Next, we focus on the case dbd(reg1, reg2) = 0. Note that if dbd (reg1, reg2) = 0, we must have reg\u2081 \u2286 reg2. Otherwise, we have\nd_{bd}(reg_1, reg_2) = \\max_{x_2 \\in reg_2 \\backslash reg_1} \\{d(reg_1, x_2)\\} 0\nTherefore, for any x2 \u2208 reg2, we have d(reg1, x2) = 0, therefore x2 \u2286 reg\u2081 (assuming reg\u2081 is a closed set). Contradiction!\nSince reg\u2081 reg2, we have\nd_{bd}(reg_1, reg_2) = \\max_{x_2 \\in reg_2} \\{-d(reg_1, x_2)\\} = 0.\nTherefore, there must exist x2 \u2208 reg2 such that d(reg\u2081, x2) = 0, and thus x2 \u2208 reg. Since we have x2 \u2286 reg2 \u2286 reg1, therefore, x2 \u2208 (reg\u2081). Similarly, since x2 \u2286 reg\u2081 reg and x2 \u2208 reg2, we also have x2 \u2208 d(reg2). This finishes the proof of the first case.\n2. By assumption, we have\nd_{bd}(reg_1, reg_2) = \\max_{x_2 \\in reg_2} \\{-d(reg_1, x_2)\\}, d_{bd}(reg_1, reg_2) = \\max_{x_2 \\in reg_2} \\{-d(reg_1, x_2)\\}.\nSince reg reg2, of course we have\nd_{bd}(reg_1, reg_2) \\leq d_{bd}(reg_1, reg_2).\nThis finishes the proof of the second case."}, {"title": "B. Hyperbolic Boundary Distance for Balls", "content": "A ball in Rn can be mapped to a cone in the upper half-space Rn \u00d7 R>0 via a mapping G. This transformation is illustrated in Figure 4 for the case n = 1, where a ball ball(0, 1) is mapped to a cone with apex (0,1) \u2208 R \u00d7 R\u22650. Note that the height of the cone corresponds to the radius of the underlying ball. The upper half-space can be interpreted as the Poincar\u00e9 half-plane model of hyperbolic space.\nFormally, we are considering a cone with a base as a ball ball(c, r) and a height k > 0, which can be defined as:\nCone(ball(c,r), k) = {(1 \u2013 t)x + t(c + ken+1) : x \u2208 ball(c, r), t \u2208 [0,1]}, where en+1 = (0, . . ., 0, 1) \u2208 Rn+1."}, {"title": "The mapping G is defined by:", "content": "G(ball(c,r)) = Cone(ball(c,r), r).\nThe boundary distance between two cones in the Poincar\u00e9 half-plane model (as shown on the right of Figure 4) can be defined as:\nd_{cone}^{bd}(Cone_1, Cone_2) := x \u00b7 min d_{H}(\\partial(Cone_1), Apex(Cone_1)),\nwhere X -1 if Cone2 \u2286 Cone1, and x = 1 otherwise. \u2202(Cone1) denotes the boundary of Cone1, and Apex(Cone1) is the apex of Cone1.\nAssuming the curvature is fixed at -1 (i.e., k = 1), we specialize Theorem 4.2 from Yu et al. (2024) by imposing the condition sinh(\u221akr) = 1, from which we derive:\nd_{cone}^{bd}(Cone_1 (ball(c_1, r_1), r_1), Cone_2(ball(c_2, r_2), r_2)) = arcsinh \\Big(\\frac{||C_1 - C_2||}{r_2}\\Big) + arcsinh(1),\nwhere ci and ri are the center and radius of the underlying balls corresponding to the cones.\nThis distance can be extended back to the context of balls, allowing the definition of a boundary distance between balls as:\nd_{cone}^{bane}(ball_1 (c_1, r_1), ball_2(c_2, r_2)) = arcsinh\\Big(\\frac{||C_1 - C_2|| - 1}{r_2}\\Big) + arcsinh(1)."}, {"title": "C. Poincare Ball Models", "content": "There exist multiple models H that are isometric to each other. This work uses two such models, the Poincar\u00e9 ball and the Poincar\u00e9 half-space:\nThe Poincar\u00e9 ball is given by\nBn = {x \u2208 R"}, {"title": "D. 8-Hyperbolicity", "content": "In the study of metric spaces, a space is said to be d-hyperbolic if it satisfies a particular property related to the triangle inequality. The concept of 8-hyperbolicity was introduced by M. Gromov (Gromov, 1987) to capture the notion of negative curvature in a metric space.\nDefinition D.1 (\u03b4-Hyperbolicity). Let (X, d) be"}]}