{"title": "Mixtures of In-Context Learners", "authors": ["Giwon Hong", "Emile van Krieken", "Edoardo M. Ponti", "Nikolay Malkin", "Pasquale Minervini"], "abstract": "In-context learning (ICL) adapts LLMs by providing demonstrations without fine-tuning the model parameters; however, it does not differentiate between demonstrations and quadratically increases the complexity of Transformer LLMs, exhausting the memory. As a solution, we propose Mixtures of In-Context Learners (MOICL), a novel approach to treat subsets of demonstrations as experts and learn a weighting function to merge their output distributions based on a training set. In our experiments, we show performance improvements on 5 out of 7 classification datasets compared to a set of strong baselines (up to +13% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of ICL by reducing the inference time needed to achieve the same performance with fewer demonstrations. Finally, MOICL is more robust to out-of-domain (up to +11%), imbalanced (up to +49%), or noisy demonstrations (up to +38%) or can filter these out from datasets. Overall, MOICL is a more expressive approach to learning from demonstrations without exhausting the context window or memory.", "sections": [{"title": "Introduction", "content": "In-context learning (ICL), where we condition a large language model (LLM) on a set of input-output examples (demonstrations) to perform a wide range of tasks (Brown et al., 2020; Wei et al., 2022), is a transformative technique in NLP. However, in ICL, the context length of the model severely limits the maximum number of in-context demonstrations (Wei et al., 2022), and its effectiveness can vary significantly depending on what demonstrations are selected (Lu et al., 2022; Chen et al., 2023). Current methods for selecting demonstrations are largely heuristic and do not adequately quantify the influence of individual examples on the generalisation properties of the model (Lu et al., 2024). In general settings, demonstrations are often selected randomly over different seeds or based on simple criteria (Xu et al., 2024), which can lead to suboptimal performance. But is each demonstration high quality and useful, or merely noise? And can we automate this distinction? We propose Mixtures of In-Context Learners (MOICL), a method for dynamically learning how different sets of examples contribute to the prediction task. MOICL prompts an LLM with multiple subsets of examples, and combines their next-token distributions via a weighting function that can be trained via gradient-based optimisation methods; Fig. 1 shows a high-level outline of the method.\nWe analyse the generalisation properties of MOICL in the following settings: (1) presence of out-of-distribution (OOD) demonstrations, where some in-context demonstrations are sourced from a different dataset; and (2) label imbalance, where the training label distribution is significantly skewed towards a subset of labels. (3) noised demonstrations, where the labels of some demonstrations are perturbed to be completely incorrect. In all three cases, we find that MOICL produces significantly more accurate results than ICL.\nFurthermore, MOICL does not require access to the internal parameters of the LLM, making it applicable to black-box LLMs, and it significantly reduces the complexity issues arising from the quadratic time and memory complexity in sequence length of self-attention since it allows the distribution of the training samples among multiple experts. We also show that the method can be made more efficient by sparsifying the mixing weights. We summarise our contributions as follows:\n\u2022 We introduce the Mixture of In-Context Learners (MOICL), which assigns weights to each demonstration subset and learns from them, dynamically identifying the optimal experts and anti-experts via gradient-based optimisation.\n\u2022 We demonstrate that MOICL is competitive with standard ICL while being significantly more data, memory, and computationally efficient.\n\u2022 We show that MOICL is resilient to noisy demonstrations and label imbalance."}, {"title": "Mixtures of In-Context Learners", "content": "We propose Mixtures of In-Context Learners (MOICL), a method for addressing the limitations of concat-based ICL (Section 2.1). We first partition (Appendix B.1) the set of demonstrations D into k disjoint subsets D1, ..., Dk:\n$D = D_1 \\cup D_2 \\cup ... \\cup D_k.$\nThen, each demonstration subset Di C D is passed to the LLM along with the input text x, and we denote these as experts. The next-token distributions of the experts are combined using a vector of mixing weights w\u2208 Rk:\n$p (y | D, x) \\propto \\exp \\left( \\sum_{i=1}^k w_i \\log p (y | D_i, x) \\right)$ where each wi\u2208 R represents the contribution of the expert denoted by p (y | Di, x) to the final next-token distribution p (y | D, x), and each expert p (y | Di, x) is trained via concat-based ICL, as in Eq. (1).\nWeighting Functions. We consider the following weighting functions for calculating the weight wi \u2208 R of the i-th expert in MoICL:\nScalar weights. Use a vector of trainable parameters w \u2208 Rk, where wi denotes the weight associated to the i-th expert. The weights w are initialised as \u2200i : wi = 1/k.\nHyper-network. Use a hyper-network (Ha et al., 2017) h() with parameters \u03a6 to generate the weights of each expert wi, given all in-context demonstration subsets concatenated:\nW1,..., wk = h\u03a6(D1, ..., Dk).\nWe learn the parameters \u03a6 of the weighting function w by maximising the conditional log-likelihood of a training set DT. One advantage of using a hyper-network h\u03a6 for dynamically computing the weights w over having w as a set of parameters is that the model can provide weights for sets of demonstrations not seen during training.\nSparsifying the Mixture Weights One limitation of MOICL is that, for each token, it requires invoking the base LLM k times, one for each expert with a different set of in-context examples. To solve this issue, we propose to sparsify the weighting coefficients w\u2208 Rk so that only k' < k of them have non-zero values. To achieve this, we define the output of the weighting function as:\nw = w' \\odot top-k'(m),\nwhere w' \u2208 Rk are scalar weights for the k experts, m \u2208 Rk is a set of masking coefficients, top-k' : Rk \u2192 {0, 1}k is a function that produces a mask that selects the highest k' elements of a k-dimensional input vector, and \u2299 is the element-wise product. To back-propagate through the rationale extraction process, we use Implicit Maximum Likelihood Estimation (IMLE; Niepert et al.,"}, {"title": "Experimental Setup", "content": "Models For our experiments, we primarily used Llama-3-8B and its instruction-tuned models, Llama-3-8B-Instruct (AI@Meta, 2024) as our base LLMs. We use Llama-3-8B-Instruct for classification tasks, and Llama-3-8B was used for an open-ended generation task; we use greedy decoding for generating from MOICL. Furthermore, we use Llama-2-7b-chat, 13b-chat, and 70b-chat (Touvron et al., 2023) for analysing the influence of model scale in Section 4.9. For the hyper-network, in our experiments, we used the T5 models (efficient-tiny, efficient-mini, t5-small, t5-base) (Raffel et al., 2020).\nDatasets To study how well MOICL performs on classification tasks, we use the TweetEval (Barbieri et al., 2020) offensive/hate, SST2 (Socher et al., 2013), RTE (Bentivogli et al., 2009), FEVER (Thorne et al., 2018), PAWS (Zhang et al., 2019), and QNLI (Wang et al., 2018) datasets. For SST2, RTE, FEVER, and QNLI, we report the performance on the development set. For a generation task, we use Natural Questions (NQ; Kwiatkowski et al., 2019) with an open-book setting (Lee et al., 2019).\nBaselines We compare MOICL with the following baselines. Concat-based ICL refers to the standard ICL introduced in Section 2.1 where all demonstrations are concatenated into a single sequence and passed as input to the LLM along with the input text. Random Search samples random subsets from the demonstration pool, concatenates them, and utilizes them in the same manner as Concat-based ICL. Specifically, we sample k random subsets and select the one that performs best on the training set. Here, k is the maximum number of subsets used in MOICL, and the size of each subset is a random number between 1 and the number of demonstrations n. After finding the best subset, we evaluate it on the test set. Ensemble-based ICL (Min et al., 2022a) and LENS (Li and Qiu, 2023) were adjusted in terms of tasks and models to fit our experimental setup. We also report the results of fine-tuning the target model using a parameter-efficient fine-tuning method, namely LORA (Hu et al., 2022); this is a strong baseline that requires access to the model weights. Finally, we study MOICL Uniform, an ablation that simply weights all experts equally, i.e. \u2200i : wi = 1/k."}, {"title": "Results", "content": "In our experiments, we aim to answer the following research questions: (1) Does MoICL demonstrate general performance improvements over concat-based ICL and other baselines? (Section 4.1 and Section 4.2) (2) Is MoICL resilient to problem settings involving label imbalance and noise? (Section 4.4, Section 4.5 and Section 4.6) (3) Can we select demonstrations (experts) based on the tuned weights? (Section 4.7) (4) Can MOICL handle demonstrations that were not seen during fine-tuning? (Section 4.8) (5) Is MOICL more efficient in terms of data, time, and memory compared to traditional concat-based ICL? (Section 5)"}, {"title": "MOICL in Classification Tasks", "content": "To determine the effectiveness of MOICL across various datasets, we compare it with baseline methods in Table 1. In this experiment, we set the total number of demonstrations (n) as 30, and the number of subsets (k) as 5, 10, and 30. MOICL outperformed the Baseline ICL on the Offensive, Hate, FEVER, PAWS, and QNLI datasets. The exceptions are SST2 and RTE, where MOICL performs similarly to concat-based ICL in SST2 and shows lower performance in RTE. Surprisingly, MOICL scalar achieved the highest performance with k=10 (e.g. in Hate MOICL achieves 66.52, which is about 10 points increase compared to the concat-based ICl) or k=30 (e.g. in Offensive MOICL achieves 81.33), rather than k=5, in all tasks except for SST2 and RTE. Considering that a larger k reduces the context length (which will be further discussed in Section 5), MOICL manages to capture both efficiency and effectiveness."}, {"title": "Impact of Partitioning Size", "content": "In Fig. 2, we present the performance changes on the test set of TweetEval offensive when varying the number of subsets, k. Since the total number of demonstrations is fixed at 30, each subset contains 30/k demonstrations, which corresponds to the x-axis of the Figure. Note that when the number of demonstrations per subset is 30 (k = 1), it corresponds to the standard Concat-based ICL. We observe that Uniform Weights and scalar exhibit distinctly different patterns. With Uniform Weights, as the number of demonstrations per subset decreases, performance tends to decline, which is an expected outcome for ICL. However, with scalar, performance surprisingly increases. This seems to be because the decrease in the number of demonstrations per subset is outweighed by the increased flexibility afforded by having more subsets, each assigned tuned weights by scalar."}, {"title": "Impact of Non-Negative Weights", "content": "Inspired by Liu et al. (2024), we made an assumption that each expert could also serve as an anti-expert, by allowing the expert weights to be negative. If the weight becomes negative during the training process, this indicates that the expert is not only unhelpful, but is actively being used as an anti-expert in generating the response. To verify this, in Table 2, we compare the performance when we restrict the weights to be positive. We observe that restricting the weights to be positive, thereby eliminating the possibility for anti-experts, significantly degrades performance. This is because certain demonstrations or their subsets can be useful when utilised as anti-experts. This also greatly aids in interpreting the usefulness of experts, as seen in the experiments from Section 4.4 and Section 4.6."}, {"title": "Handling Out-of-domain Demonstrations", "content": "By learning to associate a weight to each expert, MOICL can be used to identify whether demonstrations are relevant to the task. To analyse this, in Table 3, we present the accuracy of MOICL on the TweetEval offensive test set, using a mix of demonstrations sampled from the SST dataset and those from the TweetEval offensive dataset. We observe that as p (the proportion of OOD demonstrations) increases, the performance of standard ICL methods decreases. However, MOICL (with scalar) effectively mitigates this by reducing the influence of these OOD demonstrations, resulting in the smallest performance drop. This becomes even more apparent when analysing the weights of actual OOD demonstrations. When p = 0.5 (i.e. the number of OOD and in-domain demonstrations is equal), the average weight of in-domain demonstrations is 0.0108\u00b10.0025, while the average weight for OOD demonstrations is -0.0059\u00b10.0027. For p = 0.7, the average weight of in-domain demonstrations is 0.0127\u00b10.0052, while the average weight for OOD demonstrations is -0.0019\u00b10.0016. In Fig. 3, we visualise how the weights of in-domain demonstrations (blue bars) and OOD demonstrations (red bars) are distributed. We observed a general trend where in-domain demonstrations typically receive positive weights, while OOD demonstrations tend to receive negative weights. This provides evidence that our proposed method successfully mitigates the OOD demonstrations."}, {"title": "Mitigating Label Imbalance", "content": "To determine whether our proposed method can handle label imbalance, on the TweetEval Offensive dataset, we set up 29 'offensive' label demonstrations and one 'non-offensive' label demonstration out of 30 demonstrations. Since the TweetEval Offensive dataset has a 'non-offensive' to 'offensive' label ratio of about 7:3, such imbalanced demonstrations would be detrimental to performance. As seen in Table 4, such imbalanced demonstrations caused a significant performance drop in standard ICL methods. However, our proposed method (scalar) showed the least performance drop, successfully mitigating the effects of label imbalance."}, {"title": "Filtering Noisy Demonstrations", "content": "One of the benefits of assigning weights to each demonstration or its subsets is the ability to handle low-quality, or more specifically, noisy demonstrations. To verify this, in NQ-Open, we created noisy demonstrations (see Appendix B.3 for the result of NQ-open without noised demonstrations) by randomly changing the answers to one of (yes, no, foo, bar), where the total number of demonstration is 12, and each subset has one demonstration (n, k = 12). The results in Fig. 4 show that our proposed method effectively handles noisy demonstrations. While the performance of the concat-based ICL significantly decreases as the number of noisy demonstrations increases, the MOICL methods can maintain performance. Additionally, without tuning the weights (Uniform Weights), performance gradually declines as the number of noisy demonstrations increases, but with tuning (scalar), the performance remains stable (more than +35% with 10 noised demonstrations). This is clearly evident when analysing the learned weights. In the figure, the average weights of normal and noisy demonstrations are displayed in the form (normal weights, noise weights) for scalar, showing a noticeable difference."}, {"title": "Selecting Demonstration Subsets", "content": "We now analyse the impact of sparsifying the mixture weights w \u2208 Rk in MOICL. Results are available in Table 5 \"Highest n Weights\" refers to selecting the subsets with the n largest w weights (or |w| in the case of \u201cabs\u201d), while IMLE Top-k' mask refers to the method introduced in Section 2.2, using \u03bb = 1 following the default hyper-parameters proposed by Niepert et al. (2021). While MOICL scalar achieved the highest accuracy, the need to learn them for each n and k makes selection methods that tune weights for a large n and then select k' of them more practical. Notably, \u201cHighest n Weights (abs)\u201d is high-variance, indicating the difficulty in effectively leveraging anti-experts (Section 4.3). In contrast, IMLE, which uses a mask, demonstrated stable performance, achieving the best results, particularly with a few demonstrations (when k' = 5)."}, {"title": "Generalization to Unseen Demonstrations", "content": "While Mixture of ICL with scalar is simpler and less costly, it has the disadvantage of requiring a fixed set of demonstration subsets. This is an inherent limitation of the method itself, which assigns weights to each subset and learns from them. A solution to overcome this limitation is to utilise a smaller, fine-tuned hyper-network (Hyper-network) that calculates the weights for arbitrary demonstration subsets. Table 6 compares the performance of MOICL methods, where the demonstration set D was not available during the training process. In this situation, scalar, which assumes that the experts and their corresponding demonstrations are fixed, cannot be tuned. However, the Hyper-network fine-tuned on the available demonstrations, can generalize well when presented with unseen demonstration D."}, {"title": "Impact of Model Size", "content": "Considering the ongoing trend of scaling up LLMs, it is essential to analyse how the proposed method is affected by model size. In Table 7, we compare the accuracy of our proposed method on the TweetEval Offensive task when using Llama-2-chat models in various sizes (7B, 13B, 70B) as the target LLM. Although the performance of the Llama-2-7B-chat model is somewhat unusual compared to the other two models, we observed that MOICL consistently outperforms concat-based ICL across all three model sizes."}, {"title": "Data and Compute Efficiency", "content": "One potential limitation of MOICL is that it requires training instances for weight tuning, which can be problematic when such training data is unavailable. To analyse the data efficiency of MOICL, we present the accuracy on TweetEval Offensive and Hate test set in Fig. 5 under scenarios where the number of training instances (Number of Annotated Demonstrations) is limited. In this experiment, we set n = k, so each expert is assigned one demonstration and weight tuning is performed using the number of training instances minus k (e.g., when the x-axis is at 40, MOICL with k = 10 is tuned with 30 training instances). We observed that MOICL is highly data-efficient, achieving better performance than concat-based ICL with only around 20 annotated demonstrations. In contrast, concat-based ICL showed lower performance when given the same number of annotated demonstrations and particularly struggled when the number of demonstrations exceeded 160, as this surpassed the context length limit.\nFurthermore, we also analysed whether MOICL could be more time-efficient compared to concat-based ICL under the same settings. Fig. 6 compares the performance in terms of the average inference time (in seconds) per instance when up to 160 annotated demonstrations (which is the context length limit for concat-based ICL) are provided. We observed that MOICL consistently showed higher accuracy compared to concat-based ICL relative to inference time, demonstrating that MOICL is not only data-efficient but also time-efficient.\nComplexity The proposed MOICL method partitions demonstrations into subsets rather than concatenating them, thereby reducing the input context length for LLMs. This reduction is beneficial in Transformer-based architectures, where computational load increases quadratically with the context length. In Table 9, we analyse the computation cost based on the unit computation cost (one forward pass for one example) of LLM and Hyper-network, namely CLLM and CHyper.\nConcat-based ICL exhibits the highest cost by concatenating all demonstrations and the test input (n + 1), whereas Ensemble-based ICL shows the lowest cost by concatenating each demonstration with the test input (1+1). MOICL lies in-between, with the cost determined by the number of subsets, k. Hyper-network takes all subsets as input and outputs the weight for each subset, thereby adding a cost of (n + 1)2. CHyper. Since CLLm is usually much larger than CHyper, this approach still offers a computational advantage. Furthermore, the weights of the subsets only need to be computed once and can be reused for future inputs, which means n\u00b2 \u00b7 CHyper is a one-time process."}, {"title": "Related Work", "content": "In-Context Learning In-context learning (ICL) is an approach to few-shot learning by concatenating the training examples and providing them as input to the model before the actual test example. Being able to perform ICL is an emerging ability of very large models, such as GPT-3 (Brown et al., 2020) and PaLM (Chowdhery et al., 2023). One characteristic of ICL is that increasing the number of demonstrations tends to increase the downstream task accuracy (Brown et al., 2020; Lu et al., 2022). However, Agarwal et al. (2024) show that, after a given number of demonstrations, performance saturates and additional examples might even decrease the downstream task accuracy. Furthermore, in Transformer-based LLMs, increasing the number of ICL demonstrations can be too computationally demanding due to the complexity of self-attention operations growing quadratically with the context size (Liu et al., 2022). Finally, ICL is sensitive to out-of-domain demonstrations (Min et al., 2022b) or label imbalance, underscoring the importance of the selection of the in-context demonstrations to use (Zhao et al., 2021; Fei et al., 2023).\nEnsembles of Demonstrations Min et al. (2022a) introduce ensemble-based demonstrations as an alternative to concat-based ICL (Section 2.1), where each demonstration (xi, Yi) is provided to a language model along with the input x to obtain a next-token distribution p (y | xi, Yi, x); such next-token distributions are then combined in a product-of-experts to produce the final next-token distribution: p (y | x1, Y1,...,x) = \u041f\u2081\u0420 (\u0423 | Xi, Yi, X). Le et al. (2022) propose Mixtures of In-Context Experts for anaphora resolution, where the weights for each expert were calculated based on the cosine similarity between the embeddings of the test input and the demonstrations. Ye et al. (2023) extend the models by Le et al. (2022) and analyse the impact of merging the expert activations at different stages, both in terms of efficiency and downstream task performance."}, {"title": "Conclusions", "content": "We proposed Mixture of In-Context Learners (MOICL), a method for dynamically learning to combine multiple models, each trained via ICL, via gradient-based optimisation methods. We show that MOICL significantly improves accuracy compared to a set of strong baselines. Furthermore, we show that MOICL is robust to out-of-domain and noisy demonstrations, can help mitigate label imbalance, and can be used for selecting sets of demonstrations."}, {"title": "Limitations", "content": "Although MOICL does not require direct access to the model parameters, it requires access to the logits of the distribution over the vocabulary or answers produced by the model, both to train the experts and to calculate the final prediction at inference time, which prevents its use with black-box models like GPT-4. Future work can consider black-box optimisation methods to address this limitation.\nAn important direction for future work, though not explored in this study, is extending the learned weights to the demonstrations across the entire training set. Currently, we sample n demonstrations from the training set and assign them to experts, tuning their weights. Extending this to all demonstrations in the training set would require progressively expanding the experts and their tuned weights. One possible approach for future work is to incorporate the search and relevance heuristics proposed by Li and Qiu (2023) as inductive biases in our proposed hyper-network.\nAdditionally, due to computational resource limitations, we conducted our experiments on the Llama-2 models (Llama-2-7B-chat, Llama-2-13B-chat, Llama-2-70B-chat) and Llama-3 models (Llama-3-8B, Llama-3-8B-Instruct) as target LLMs, and T5-models (T5-efficient-tiny, T5-efficient-mini, T5-small, T5-base) as hyper-networks. However, our method is not limited to specific LMs and can be applied across various models."}, {"title": "A Detailed Experiment Settings", "content": "TweetEval (Barbieri et al., 2020) offensive/hate datasets are originally from Zampieri et al. (2019) and Basile et al. (2019), respectively. PAWS (Zhang et al., 2019) is released under a custom license\u00b2 from Google LLC. For SST-2 (Socher et al., 2013)3, RTE (Bentivogli et al., 2009), FEVER (Thorne et al., 2018)4, and QNLI (Wang et al., 2018)5, we used the original validation/development set as the test set and sampled a portion of the training set to construct a new validation set. Table 10 presents the dataset split statistics for all classification datasets used in our experiments. For NQ-open (Lee et al., 2019)6, we used the top 1 retrieved documents as a context. The dataset contains 79,168 train instances, 8,757 validation instances, and 3,610 test instances.\nWe used five seeds [31, 42, 65, 438, 991] in all experiments except for NQ-open, which were applied to every possible aspect, including dataset shuffle, demonstration pooling and partition, and Hyper-network fine-tuning, and baseline results. For NQ-open, we only use seed 42. Also, we set the batch size to 1, the gradient accumulation steps to 12 and the learning rate to 0.0001, without performing a hyperparameter search for these settings. For the PEFT (LoRA, Hu et al., 2022) baseline, we set r=16 (rank), alpha=32 (scale factor), and dropout=0.1. We did not perform a search for these LORA hyperparameters as we utilised the default settings provided by Mangrulkar et al. (2022). Unless otherwise specified, a total of 30 demonstrations were used along with Static partitioning. Both scalar and Hyper-network were tuned for 5 epochs."}, {"title": "Additional Analyses", "content": "In this work, we analyse the following partitioning strategies: Static, Random Size, and BM25. Static means partitioning n demonstrations into k subsets, with each subset containing n/k demonstrations. Random Size refers to partitioning into k subsets, each containing a random number of elements. BM25 apply k-NN clustering based on BM25 scores on demonstrations (Robertson et al., 2009) to partition into them k subsets. Table 11 compares the performance of MOICL methods and different partitioning methods (Static, Random, BM25) for the same k (number of subsets). In uniform, there is little difference between Static and Random and only a slight performance improvement with BM25. However, there is a common performance enhancement when MOICL scalar are applied. This indicates that our proposed method is not significantly affected by partitioning methods and can be applied in a complementary manner across them. As such, we decided to use only the Static method in the other experiments.\nAs stated in Section 2.2, we mix the experts in the log domain. However, it is also possible and perhaps more appropriate to use a regular mixture of probabilities, as in Eq. (5).\np (y | D, x) \\propto \\sum_{i=1}^k w_ip (y | D_i, x)\nAccordingly, in Fig. 2, we compare the accuracy trends based on partitioning size when using weighting in the probability and logit domains. In uniform, whether logits or probabilities were used did not make a significant difference, but in scalar, the impact was substantial. This is likely because distinct differences in the distribution patterns among experts (and thus useful information in the mixture) get diluted during the normalisation process when using probabilities.\nIn addition to the classification tasks in Section 4.1, we also apply our MOICL on a generation task, NQ-open (Lee et al., 2019), in Table 12. However, unlike in classification tasks, MOICL did not show significant EM improvements over baseline approaches. Nevertheless, as seen in Section 4.6, MOICL exhibited strong robustness in situations involving noised demonstrations, proving the usefulness of the expert's tuned weights."}]}