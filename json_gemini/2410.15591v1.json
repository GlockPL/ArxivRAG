{"title": "AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection", "authors": ["Xiaoman Xu", "Xiangrun Li", "Taihang Wang", "Ye Jiang"], "abstract": "Detecting fake news in large datasets is challenging due to its diversity and complexity, with traditional approaches often focusing on textual features while underutilizing semantic and emotional elements. Current methods also rely heavily on large annotated datasets, limiting their effectiveness in more nuanced analysis. To address these challenges, this paper introduces Emotion-Aware Multimodal Fusion Prompt LEarning (AMPLE) framework to address the above issue by combining text sentiment analysis with multimodal data and hybrid prompt templates. This framework extracts emotional elements from texts by leveraging sentiment analysis tools. It then employs Multi-Head Cross-Attention (MCA) mechanisms and similarity-aware fusion methods to integrate multimodal data. The proposed AMPLE framework demonstrates strong performance on two public datasets in both few-shot and data-rich settings, with results indicating the potential of emotional aspects in fake news detection. Furthermore, the study explores the impact of integrating large language models with this method for text sentiment extraction, revealing substantial room for further improvement.", "sections": [{"title": "1 Introduction", "content": "Information spreads rapidly through social media platforms such as Twitter, Facebook, and Weibo [14]. However, the proliferation of digital news on these platforms presents significant challenges to the effective regulation of fake news, which undermines the credibility of traditional media and increases associated economic and political risks [24]. Traditional manual review methods [2,34] are increasingly inadequate in handling the massive flow of information, making it particularly difficult to detect emerging themes in the news.\nIn response to these challenges, recent Fake News Detection (FND) models have started incorporating semantic features alongside traditional lexical and stylistic ones [19,36]. Notably, the overall emotion, negativity, and expressions"}, {"title": "2 Related work", "content": ""}, {"title": "2.1 Sentiment-based FND", "content": "Sentiment analysis has been explored across various domains. [36] employs TextBlob2 for emotion polarity and LIWC3 for multi-dimensional sentiment analysis, confirming that fake news exhibits higher levels of overall and negative emotion compared to real news. Research [23] shows that emotions significantly affect judgments of fake news accuracy, with emotion-based traits enhancing rumour recognition more effectively than personality-based traits [5]. Negative perceptions of the political system can also impact news credibility evaluations [25]. Consequently, many studies [19,20] combine ML, DL, and advanced fusion techniques to extract or prioritize emotional elements in FND. However, these methods [6,9] often require extensive labeled datasets, which are costly and prone to bias. Moreover, the complexity of model design and training poses additional challenges. In contrast, this paper employs SATs, which utilize sentiment lexicons and rules to compute emotional elements. SAT's straightforward API obviates the need for complex model design and training."}, {"title": "2.2 Prompt Learning FND", "content": "Prompt Learning leverages pre-trained models' factual and commonsense knowledge through specific templates. It can be categorized into two types: (1) pseudo-prompted fine-tuning of masked Language Models (LMs) and (2) prompted fine-tuning of autoregressive LMs. The first type, pseudo-prompts, introduces specific vectors into the model's input to guide outputs. For instance, [15] uses a masked LM to generate pseudo-prompts for few-shot fact-checking. [21] adapts BERT's pre-training task for entity language modeling"}, {"title": "3 Methodology", "content": "We introduce the AMPLE framework to comprehensively utilize text and image data from news articles for assessing their veracity, especially in few-shot and data-rich scenarios. The framework, outlined in Figure 2, comprises feature representation, emotional elements extraction, multi-grained feature fusion, prompt learning, and task learning."}, {"title": "3.1 Feature Representation", "content": "We employ the CLIP model, designed for textual and visual inputs, promoting joint feature learning in a unified embedding space. For an article with n words, represented as \\(W = (W_1,W_2,..., W_n)\\), and m images, denoted as \\(I = (I_1,I_2,..., I_m)\\). \\(T^w\\) represents text features, and \\(V^i\\) represents image features."}, {"title": "3.2 Emotional Elements Extraction", "content": "To integrate sentiment information, we use SAT to extract emotional elements from text. For each news sample W, we extract emotion polarity (p) and subjectivity (s), with p in [-1,1] and s in [0, 1]. We normalize p to p* as shown in"}, {"title": "3.3 Multi-grained Feature Fusion", "content": "We use the MCA mechanism to explore the deep fusion between modalities \\(T^e\\) and \\(V^i\\), obtaining new representations \\(V^a\\) (Eq. (4)) and \\(T^a\\) (Eq. (5)) through the MCA mechanism:\n\\(head_i = Att(Q_i, K_i, V_i) = softmax(\\frac{Q_iK_i^T}{\\sqrt{d_k}})V_i\\) \n\\(V^a = Multi(V^i,T^e,T^e) = Cat[head_1,...,head_m]\\)\n\\(T^a = Multi(T^e,V^i,V^i) = Cat[head_1,...,head_m]\\)\nHere, the dimension \\(d_k\\) of the key is set to d/2. Cat stands for concatenate. The decision to utilize powers of 2 (1, 2, 4, 8) as the number of attention heads m is based on the dimensionality of \\(T^w\\) and \\(V^i\\) (i.e., 512). This choice ensures that each attention head processes sub-vectors of equal dimensions, improving the efficiency of parallel computation and preventing computational waste and uneven data processing.\nWe use a residual connection strategy, adding \\(V^a\\) and \\(T^a\\) to the original modal features to obtain integrated features \\(V^e\\) and \\(T^c\\). A fusion framework mix with linear transformations, batch normalization, ReLU activation, and dropout layers generates integrated feature vectors \\(f_1\\) and \\(f_2\\). We optimize cross-modal interactions and reduce noise by calculating and normalizing the cosine similarity (Eq. (6)) between \\(T^w\\) and \\(V^i\\), combining it with \\(f_1\\) and \\(f_2\\) to obtain final cross-modal features \\(m_1\\) and \\(m_2\\) (Eq. (7))."}, {"title": "3.4 Prompt Learning", "content": "In this paper, we perform pseudo-prompt tuning using the RoBERTa-base4 model within the AMPLE framework, where the masked LM component is denoted as PLM. In this study, we manually construct a hybrid prompt template"}, {"title": "3.5 Task Learning", "content": "We further optimize prompt selection in the continuous embedding space by combining V with \\(m_1\\) and \\(m_2\\) via residual connections. Additionally, we introduce an adjustment coefficient \u03b1 (where 0 \u2264 \u03b1 \u2264 1) to balance the importance of textual and visual information in the final decision-making process. The composite feature vector \\(x_f\\) is then computed as Eq. (9):\n\\(x_f = FC (V + \\alpha \\cdot m_1 + (1 - \\alpha) m_2)\\)\n\\(x_f\\) is subsequently fed into a fully connected (FC) layer for further processing, ultimately determining the most suitable fill-in word for the \"<mask>\" token. The classification probability \\(P(y | x_f)\\) Eq. (10) is computed as:\n\\(P(y | x_f) = \\frac{exp(\\theta_y \\cdot x_f)}{\\sum_{c \\in C}exp(\\theta_c \\cdot x_f)}\\)\nwhere C is the set of classes, \\(\\theta_y^c\\) is the embedding for the true label, and \\(\\theta_l^c\\) are the embeddings for the predicted label words. Finally, the cross-entropy loss \\(\\theta^*\\) Eq. (11) can be minimized as:\n\\(\\theta^* = arg \\underset{\\theta}{max} (- log P(y | x_f))\\)"}, {"title": "4 Experiment", "content": ""}, {"title": "4.1 Dataset", "content": "In our study, we utilize two publicly available FND datasets: PolitiFact (1,056 news articles) and GossipCop (22,140 news articles). We calculate the similarity between text and image using the CLIP model, retaining only the pairs with the highest similarity to ensure that each text corresponds to its related image. Referring to [36], we employ TextBlob to evaluate the emotion polarity of news, and calculate the matching percentage of each word in the text with sentiment-related categories (such as positive, negative) through the LIWC dictionary-based method, thereby deriving overall, positive, and negative emotion scores. The dataset statistics and the mean and standard deviation of the emotion indicators are listed in Table 1. The results show that fake news differs from real news in most emotion values, with real news generally showing higher emotion values. See Section 4.4 for detailed analysis."}, {"title": "4.2 Implementation Details", "content": "Our training process employs the AdamW optimizer with a cross-entropy loss function, an initial learning rate of 3 \u00d7 10\u22125, and a decay rate of 1 \u00d7 10-3 over 20 epochs. We utilize TextBlob's SAT to extract emotion elements from the text. As shown in Table 2, the model's performance is evaluated under both few-shot and data-rich settings. In the few-shot setting, PolitiFact is trained on small sample sizes (n in [2, 4, 8, 16, 50]), and GossipCop on (n in [2, 4, 8, 16, 100]), with five repetitions using different seeds to ensure robustness. In the data-rich setting, the dataset is split into training, validation, and testing sets with a ratio of 8:1:1, and performance metrics are averaged after removing the highest and lowest values."}, {"title": "4.3 Baseline", "content": "The proposed AMPLE framework is compared with nine models on the FND dataset. The specific model comparisons conducted include:\nUnimodal Approaches: LDA-HAN: [13] integrates LDA with a Hierarchical Attention Network. T-BERT: [1] employs a cascaded triplet BERT architecture.\nMultimodal Approaches: SAFE: [37] transforms images into textual descriptions. RIVF: [30] merges VGG and BERT with attention. SpotFake: [28] uses VGG and BERT for feature extraction. CAFE: [3] employs fuzziness-aware feature aggregation.\nStandard Fine-tuning Approaches: [14] uses fine-tuning on RoBERTa.\nFew-shot Learning Approaches: P&A: [32] jointly leverage the pre-trained knowledge in PLMs and the social contextual topology. Due to the absence of user data in our dataset, the user engagement threshold is adjusted to 50 when training with the other party's dataset. SAMPLE: [14] integrates hybrid prompt learning templates with similarity-aware fusion."}, {"title": "4.4 Results", "content": "Table 2 presents the results of the proposed AMPLE approach compared to the baseline model. The model demonstrates superior performance on the PolitiFact dataset relative to GossipCop. Combined with the statistical analysis in Table 1, we observe that a higher proportion of overall emotion and negative emotion in fake news than in real news, which contradicts some previous studies [36,23], where it is found that fake news typically exhibits higher positive emotion and lower negative emotion.\nHowever, our study reveals that the ratio of affective polarity to positive emotion is indeed lower in fake news compared to real news, which aligns with previous findings. This emotion profile may pose challenges for models in accurately capturing and utilizing it, especially in the GossipCop dataset. The higher emotion polarity observed in the PolitiFact dataset likely enables models to extract relevant features more efficiently for training and prediction. Overall, AMPLE consistently outperforms in nearly all scenarios, particularly in terms of the F1 score, where it significantly surpasses other baseline models. This further validates the importance of emotional elements in FND and underscores the necessity for effective multimodal fusion."}, {"title": "5 Analysis", "content": ""}, {"title": "5.1 Emotional Element Calculation Study", "content": "We utilize three methods to explore the impact of different emotional element calculations on model performance. As shown in Table 3, in the few-shot setting of the PolitiFact dataset, the AMPLEp+s configuration achieves the best classification performance. This is likely because it combines emotional polarity with subjectivity, providing a richer understanding of the text context. Fake news often manipulates emotion and presents subjective opinions as facts, and the AMPLEp+s configuration is better at detecting these nuances, thereby improving performance."}, {"title": "5.2 Multi-grained Feature Fusion study", "content": "We design two strategies to evaluate the impact of MCA-computed and non-MCA-computed features on classification accuracy in AMPLE.\nStrategy A: Adjusting the weight of MCA-computed versus non-MCA-computed features\n\u2022 We vary the contribution of these components by adjusting a weighting parameter, \u03b1, ranging from 0 to 1. \u03b1 = 0 utilizes only MCA-computed features, while \u03b1 = 1 uses only non-MCA-computed features.\n\u2022 As shown in Figures 3a and 3b, the model performs best in both few-shot and data-rich settings when the contribution of non-MCA-computed components slightly exceeds that of MCA-computed components. This is likely because adjusting the weighting parameter \u03b1 can balance feature importance, and in few-shot settings, non-MCA-computed features provide regularization, reducing overfitting.\nStrategy B: Scaling both feature types equally\n\u2022 We utilize \u03b1 to scale both MCA-computed and non-MCA-computed features equally, ranging from 0 to 1."}, {"title": "5.3 Ablation Study", "content": "In the ablation studies, we remove components from the AMPLE framework and retrain the model to assess their contribution. The results in Table 4 show that -EE significantly degrades performance. Emotional elements are crucial for capturing implicit emotional information, especially in FND where these emotions may be deceptive or inflammatory. Removing these elements limits the model's ability to leverage this information, leading to a drop in performance. -MCA also reduces performance by hindering the effective integration of multimodal features, resulting in information loss. -TM degrades performance more than -IM, indicating that text typically contains richer contextual information and better reflects the authenticity of news."}, {"title": "5.4 Emotion-based LLM study", "content": "The LLM [12,22,31,33] offers a novel approach to calculating news emotion elements due to its powerful text comprehension capabilities. This study aims to leverage the advanced capabilities of LLMs to more accurately capture both explicit and implicit emotions, along with their complex semantics, and evaluates the performance of the ChatGPT-3.5 Turbo model, developed by OpenAI, on the PolitiFact dataset.\nGiven the large number of parameters in the ChatGPT-3.5 model and its non-open-source nature, we adopt the few-shot chain of thought prompting technique [8] (using two 4-shot configurations), which has been proven effective in downstream tasks. As shown in Table 5, the emotion elements generated by LLM do not significantly improve model performance compared to the TextBlob method. This may be because LLM excels at text generation but is limited in capturing and integrating subtle emotions. Nonetheless, LLM shows potential in handling complex emotions and domain-specific feature fusion."}, {"title": "6 Conclusion and Limitations", "content": "This paper introduces the AMPLE framework, which leverages prompt learning in few-shot scenarios to alleviate the problem of data scarcity and enhances the authenticity analysis of fake news by incorporating emotional elements extracted by SAT. The designed MCA mechanism and the ability to perceive semantic similarity facilitate the integration and interaction of multimodal information. Extensive experiments based on benchmark datasets show that the AMPLE framework proposed in this paper exhibits obvious advantages in integrating emotional elements and multimodal fusion. Although the improvement on some datasets is not significant, it still effectively enhances the accuracy of FND. This indicates that emotional elements hold potential in this task, particularly in datasets with specific emotional distributions. In addition, we explore that there is still much room for improvement in the prediction effect of combining the emotional elements generated by LLM with the small model.\nHowever, this study has several limitations. First, concerning the combination of emotional elements and FND, alternative emotional feature extraction methods can be explored. Secondly, this study lacks analysis of other relevant information related to fake news, such as user information, comments, and retweets. Moreover, the potential impacts of LLM on the proposed method require further investigation. In future research, we aim to enhance the model's generalization capability by designing new feature extraction and fusion methods. Additionally, we plan to conduct more experimental studies on the application of LLM to further validate and improve our method."}]}