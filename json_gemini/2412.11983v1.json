{"title": "Cost-Effective Label-free Node Classification with LLMs", "authors": ["Taiyan Zhang", "Renchi Yang", "Mingyu Yan", "Xiaochun Ye", "Dongrui Fan", "Yurui Lai"], "abstract": "Graph neural networks (GNNs) have emerged as go-to models for node classification in graph data due to their powerful abilities in fusing graph structures and attributes. However, such models strongly rely on adequate high-quality labeled data for training, which are expensive to acquire in practice. With the advent of large language models (LLMs), a promising way is to leverage their superb zero-shot capabilities and massive knowledge for node labeling. Despite promising results reported, this methodology either demands considerable queries to LLMs, or suffers from compromised performance caused by noisy labels produced by LLMs. To remedy these issues, this work presents Cella, an active self-training framework that integrates LLMs into GNNs in a cost-effective manner. The design recipe of Cella is to iteratively identify small sets of \"critical\" samples using GNNs and extract informative pseudo-labels for them with both LLMs and GNNs as additional supervision signals to enhance model training. Particularly, Cella includes three major components: (i) an effective active node selection strategy for initial annotations; (ii) a judicious sample selection scheme to sift out the \"critical\" nodes based on label disharmonicity and entropy; and (iii) a label refinement module combining LLMs and GNNs with rewired topology. Our extensive experiments over five benchmark text-attributed graph datasets demonstrate that Cella significantly outperforms the state of the arts under the same query budget to LLMs in terms of label-free node classification. In particular, on the DBLP dataset with 14.3k nodes, Cella is able to achieve a 8.08% conspicuous improvement in accuracy over the state-of-the-art at a cost of less than one cent.", "sections": [{"title": "1 Introduction", "content": "Text-attributed graphs (TAGs) [4] are an expressive data model used to represent textual entities and their complex interconnections. Such data structures are prevalent in real-world scenarios, including social networks, hyperlink graphs of web pages, transaction networks, etc., wherein nodes are endowed with user profiles, web page contents, or product descriptions. Node classification is a fundamental task over TAGs, which aims to classify the nodes in the graph into a number of predefined categories based on the graph structures and textual contents. This task finds extensive practical web applications, such as fake news detection [54], document categorization [76], item tagging [42], financial fraud monitoring [77], and many others [3, 25, 36].\nIn the past decade, graph neural networks (GNNs) [5, 13, 22, 27, 67, 70, 72] have become the dominant models for node classification, by virtue of their capabilities to capture complex dependencies and patterns in the graph and the interplay between connectivity and attributes. However, the efficacy of such models largely hinges on the availability of adequate node labels for training. In real life, high-quality labels are hard to acquire due to the need for"}, {"title": "2 Related Work", "content": "This section reviews existing studies germane to our work."}, {"title": "2.1 Zero-shot Node Classification", "content": "Zero-shot node classification aims to train a model on a set of known categories and generalize it to unseen categories. Graph-CEN [26] introduces a two-level contrastive learning approach to jointly learn node embeddings and class assignments in an end-to-end fashion, effectively enabling the transfer of knowledge to unseen classes. Similarly, TAG-Z [30] leverages prompts alongside graph topology to generate preliminary logits, which can be directly applied to zero-shot node classification tasks. DGPN [65] facilitates zero-shot knowledge transfer by utilizing class semantic descriptions to transfer knowledge from seen to unseen categories, a process analogous to meta-learning. Additionally, methods such as BART [28] can also be adapted for node classification tasks. However, it is important to note that our approach differs slightly from traditional zero-shot node classification, as we do not require any initial training data."}, {"title": "2.2 Node Classification on Text-Attributed Graphs", "content": "Text-attributed graphs combine two modalities: the textual content within documents and the graph structure that connects these documents [4]. On the one hand, Graph Neural Networks (GNNs) [18] effectively generate document embeddings by integrating both vertex attributes and graph connectivity. However, most existing GNN-based models treat textual content as general attributes without specifically addressing the unique properties of language data. Consequently, they fail to capture the rich semantic structures and nuanced language representations embedded in text corpora.\nOn the other hand, pre-trained language models (PLMs) [59] and large language models (LLMs) excel at learning contextualized language representations and generating document embeddings. However, these models typically focus on individual documents and do not consider the graph connectivity between documents, such as citations or hyperlinks. This connectivity often encodes topic similarity, and by modeling it, one can propagate semantic information across connected documents.\nTo address these challenges, recent approaches have proposed text-attributed graph representation learning, which combines GNNs with PLMs and LLMs into unified frameworks for learning document embeddings that preserve both contextualized textual semantics and graph connectivity. For instance, Graphformers [78] iteratively integrate text encoding with graph aggregation, enabling each node's semantics to be understood from a global perspective. GraphGPT [55] aligns LLMs with graph structures to improve document understanding. GraphAdapter [23] uses LLMs on graph-structured data with parameter-efficient tuning, yielding significant improvements in node classification. LLM-GNN [7] leverages LLMs to annotate node labels, which are subsequently used to train Graph Convolutional Networks (GCNs) in an instruction-tuning paradigm. OFA [34] introduces a novel graph prompting paradigm that appends prompting substructures to input graphs, enabling it to address various tasks, including node classification, without the need for fine-tuning. ZeroG [31] uses language models to encode both node attributes and class semantics, achieving significant performance improvements on node classification tasks.\nThese advancements in text-attributed graph methods have been successfully applied to a range of tasks, including text classification [66, 76], citation recommendation [2, 69], question answering [75], and document retrieval [41]."}, {"title": "2.3 Attributed Graph Clustering", "content": "Attributed graph clustering (AGC) aims to effectively leverage both structural and attribute information in graphs for improved clustering performance [73]. Several key methods have been proposed in this domain. DAEGC [63] uses attention mechanisms to adaptively aggregate neighborhood information, improving the expressiveness of node embeddings. AGCN [46] dynamically blends attribute features from autoencoders (AE) with topological features from GCNs, using a heterogeneous fusion module to integrate both types of information. DFCN [58] combines representations from AE and GAE hidden layers through a fusion module and employs a triple self-supervision strategy to enhance cross-modal information utilization. CCGC [74] employs contrastive learning with non-shared"}, {"title": "2.4 Difference from Previous Works", "content": "In this section, we outline the key differences between our method and prior label-free approaches [7, 29]. Specifically, [7] employs traditional active selection techniques, such as FeatProp, RIM, and GraphPart, for node selection, performing annotation only once before the GNN training phase. In contrast, Cella introduces a novel subspace clustering approach and conducts annotation in batches throughout the self-training process. Additionally, Cella leverages reliable GNN predictions as pseudo-labels, thereby reducing the need for expensive LLM queries, and incorporates a Hybrid Label Refinement module to enhance the quality of node selection.\nRef. [29], while employing iterative node selection for annotation, initializes the process with random node selection, unlike our method, which utilizes subspace clustering. Furthermore, the selection metric defined in [29] differs significantly from ours. Lastly, their approach relies on the LLM to explain annotation decisions for knowledge distillation, which substantially increases the query cost, whereas Cella mitigates this by merely generating the annotation result with confidence."}, {"title": "3 Preliminaries", "content": ""}, {"title": "3.1 Problem Statement", "content": "Let G = (V, E, T) be a text-attributed graph, wherein V stands for a set of n nodes and & represents a set of m edges between nodes in V. For each edge (vi, vj) \u2208 &, we say vi and vj are neighbors to each other and use N(vi) to denote the set of neighbors of vi. Each node vi in G is characterized by a text description Ti in T. We denote by A the adjacency matrix of G, in which Ai,j = Aj,i = 1 if (vi, vj) \u2208 & and 0 otherwise. Accordingly, L = D \u2013 A is the Laplacian matrix of G, where D is the diagonal degree matrix satisfying Di,i = |N(vi)| Vvi \u2208 V. \u0100 = D-1/2AD-1/2 stands for the normalized version of A and \u0128 = I \u2013 \u00c3 is used to symbolize the normalized Laplacian of G.\nLet C = {C1, C2,..., ck} be a set of k classes, where each class is associated with a label text. Given a TAG G = (V,E,T) and k classes C, the goal of label-free node classification [7, 30] is to predict the class labels of all nodes in V."}, {"title": "3.2 Graph Neural Networks", "content": "The majority of existing GNNs [5, 13, 27, 67, 70] mainly follow the message passing paradigm [15], which first aggregates features form the neighborhood, followed by a transformation. As demystified in recent studies [40, 80], after removing non-linear operations, graph convolutional layers in popular graph neural network models, e.g., APPNP [13], GCNII [5], and JKNet [70], essentially optimize the graph Laplacian smoothing [11] problem as formulated in Eq. (1).\nmin ||H \u2013 X||\u00b2 + a \u00b7 trace(H\u00af\u00ceH),  (1)"}, {"title": "3.3 Large Language Models and Prompting", "content": "In this work, we refer to LLMs as the language models that have been pre-trained on extensive text corpora, which exhibit superb comprehension ability and massive knowledge at the cost of billions of parameters, such as LLaMA [57] and GPT4 [1]. The advent of LLMs has brought a new paradigm for task adaptation, which is known as \"pre-train, prompt, and predict\". In such a paradigm, instead of undergoing cumbersome model fine-tuning on task-specific labeled data, the LLMs pre-trained on a large text corpus are queried with a natural language prompt specifying the task and context, and the models return the answer based on the instruction and the input text [35]. For example, given a paper titled \u201cBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" and the task of predicting its subject. The prompts for this task can be: { [Title], this, paper, belong, to, which, subject? }\nWhile querying a model once with a reasonably sized input is affordable for most users, challenges arise when the input text is exceptionally long, such as a complete book or a lengthy article from a website. Additionally, the need to query large datasets further escalates costs. For instance, the PUBMED dataset contains tens of thousands of articles, with the longest exceeding 100,00 words. A full-scale prediction of all article subjects in the PUBMED dataset using GPT-3.5 could cost over 20 dollars, and with the more advanced GPT-4, this cost rises to around 400 dollars.\nApart from incurring high costs, LLM predictions can sometimes be noisy. Although these models may exhibit high confidence in their outputs, they are prone to errors, a phenomenon often referred to as Al hallucination [48]. One potential solution to mitigate this issue is to experiment with different prompts and select the most accurate output. However, each attempt incurs significant costs due to the expensive nature of these models."}, {"title": "4 Methodology", "content": "This section presents our Cella framework that integrates LLMs into the GNNs adaptively for label-free node classification."}, {"title": "4.1 Synoptic Overview of Cella", "content": "The pipeline of Cella is illustrated in Figure 2, which mainly works in two stages: initial node annotations with LLMs (Stage I) and multi-round self-training based on GNNs (Stage II). More specifically, given a TAG G, Cella first converts G into a standard attributed"}, {"title": "4.2 Initial Node Annotations", "content": "This stage involves the selection of nodes A for annotation and specific labeling tricks using LLMs."}, {"title": "4.2.1 Active Node Selection", "content": "The basic idea of our node selection strategy is to partition nodes in V into a number of clusters and select a small set A (|A| = Bini) of distinct cluster centers and nodes as the representatives for subsequent annotations, referred to as the active node set (ANS).\nTo extract ANS A, we first calculate a T-truncated approximation of the GNN-based node representations in Eq. (2) by\nH = \u2211(1 \u2212 \u03b1)\u03b1 \u03a7 (3)\nt=0\nas the feature vectors of nodes, which encode both textual and structural semantics underlying G. Next, Cella opts for the subspace clustering (SC) technique [61] for node grouping, which is powerful in noise reduction and discovering structural patterns underlying the feature vectors [12]. To be specific, SC first constructs an affinity graph (a.k.a. self-expressive matrix), i.e., S, from feature vectors H such that the following objective is optimized:\nmin ||H \u2013 SH|| + \u03a9(S),  (4)\nSERnxn"}, {"title": "4.2.2 LLM-based Annotation", "content": "Given the ANS A, Cella then query LLMs (e.g., GPT-3.5) for generating the annotation and confidence score for each node in A using the consistency prompt strategy [64] adopted in [7]. Given these confidence scores, a post-filtering [7] is further applied to filter out the low-confidence samples with low-quality labels. Finally, we utilize the ANS A and their annotations as the initial training data (Vtr, Ytr) input to the Cella model for self-training. We refer interested readers to Appendix B for detailed prompt descriptions and examples."}, {"title": "4.3 Informative Sample Selection", "content": "As delineated in Section 4.1, in the course of self-training, Cella selects node samples from the test node set V \\ Vtr with high"}, {"title": "4.4 Hybrid Label Refinement", "content": "As remarked in the preceding section, Vut consists of the bottleneck samples where the past and current GNN models largely fail. The uncertain predictions for samples in Vut can be ascribed to two primary causes. First, there is a lack of sufficient representative labeled samples for model training. Second, the nodes in Vut are connected to scarce or noisy edges that can easily mislead the GNN inference. Naturally, it is necessary to seek auxiliary label information from LLMs. However, as revealed in [7], the predictions made by LLMs can also be noisy, particularly for instances in Vut with low confidence. To mitigate this issue, we propose to rewire the graph structure surrounding the uncertain samples and retrain GNN model to get their predictions new (r). On top of that, we refine the labels of node samples in Vut through a careful combination of the signals from LLMs and (r)."}, {"title": "4.4.1 Graph Rewiring-based Predictions", "content": "To eliminate noisy topology and complete missing links, we propose to align the graph structure with the node features. Recall that in Eq. (1), GNNs aim to make node features H optimize the Dirichlet Energy of node features over normalized graph Laplacian L, thereby enforcing the feature vectors of adjacent nodes to be similar. Conversely, our idea is to optimize the Dirichlet Energy by updating L while fixing H.\nLEMMA 4.2. I-HHT = arg min\u012a trace(HTLH) s.t. ||\u00c3||F = \u03b2.\nAlong this line, we can obtain a new graph H with adjacency matrix HHT by Lemma 4.2. The connections therein can be used to complement the input graph topology in G.\nMore concretely, Cella first generates the node feature through an MLP layer as follows:\nH = MLP(G, Y(r)).\nThe graph H thus can be constructed by assigning each edge (vi, vj) a non-negative weight w(vi, vj) computed by\nw(vi, vj) = max(Hi \u2022 H, 0).\nAs in Eq. (12), Cella forms (i) a set &(-) of edges to be removed from G, and (ii) a set &(+) of node pairs to be connected in G, by picking edges from & with the 8(-) . |E|-smallest weights and node pairs from Vtr \u00d7 V \\ Vtr with the 8(+) \u00b7 |E|-largest weights, respectively, where 8(-) and 8(+) are ratio parameters.\nE(-) = arg topk \u2013 w(vi, vj), E(+) = arg topk w(vi, vj).  (12)\n(vi,vj) E& vi Vtr,j\u2208V/Vtr (vi,vi) E\nThe intuition for the way of creating &(+) is that by connecting unlabeled nodes to their similar samples with certain labels, the GNN model is empowered to infer their labels more accurately and confidently.\nThen, we construct a rewired graph G with edge set (EU\u0190(+))\\ 8(-) and derive an updated label predictions in Eq. (13) based thereon.\n(r) = softmax(GNN(G,y(r))) (13)"}, {"title": "4.4.2 Label Refinement with LLMs and \u0176(r)", "content": "For each node vi in Vut, Cella requests its annotation yi with a confidence score (vi) from LLMs as in Section 4.2.2. Similarly, by \u0176(r) obtained in Eq. (13), we can get the most possible label \u0177\u00a1 for node vi \u2208 Vut. If Yi \u2260 \u0177i, we should keep the one that we are more confident about. More precisely, let rankLLM (vi) and rankGNN(vi) be the rank of node vi within Vut according to their confidence scores (vi) or prediction probabilities in (r), respectively. Let 6 be a predefined threshold, indicating the minimum confidence score to trust the result by LLMs. If rankLLM (vi) < rankGNN(vi) or (vi) \u2264 6, Cella is less certain about the annotation by LLMs, and hence, we set \u0177i as the final label for vi."}, {"title": "4.5 Model Optimization", "content": "In each round of self-training, we train the Cella model by optimizing two objectives pertinent to classification and rewired topology with the current training samples Vtr and their labels Ytr. Following common practice, we adopt the cross-entropy loss for node"}, {"title": "4.6 Theoretical Analyses", "content": ""}, {"title": "4.6.1 Connection between Label Disharmonicity and Dirichlet Energy", "content": "Given a graph signal x \u2208 R\", its standard Dirichlet Energy on G is x Lx, whose gradient can be expressed as Lx. Accordingly, for the probabilities of all nodes w.r.t. j-th class \u25bc, the gradient of its Dirichlet Energy is LY, wherein each i-th entry equals \u03a3\u03c5\u0395\u039d(0) (-)). As per the definition of the label disharmonicity in Eq. (9), it is easy to prove that\n1\nLH(vi) = \u00b7 || (LY(*))i||2. Namely, the label disharmonic-\nVIN(vi)\nity of a node vi is the reweighted L2 norm of its Dirichlet Energy gradients of all classes over G."}, {"title": "4.6.2 Connection between LDE and Spectral Clustering", "content": "Spectral clustering [62] seeks to partition nodes in graph G into K disjoint clusters {C1, ..., CK} such that their intra-cluster connectivity is minimized. A common formulation of such an objective is the RatioCut [17]: min{C1,...,CK} k=1\nis equivalent to\nmin trace(CT (I \u2013 \u00c3)C) = trace(CLC).\n(15)\nC\u2208 Rn\u00d7K denotes a node-cluster indicator matrix in which Ci,j = if vi \u2208 Cj, and 0 otherwise. This discreteness condition on C is usually relaxed in standard spectral clustering and C is allowed to be a continuous probability distribution. Let C = Y(r) and L = L\u011c Our Dirichlet Energy term in Eq. (14) is a RatioCut in spectral clustering in essence."}, {"title": "5 Experiments", "content": "In this section, we experimentally evaluate Cella in label-free node classification over five real TAGs. Particularly, we investigate the following research questions: RQ1: How is the performance of Cella compared to the existing zero-shot/label-free methods? RQ2: How do the three proposed components of Cella affect its performance? RQ3: How do the key parameters in Cella affect its performance?"}, {"title": "5.1 Experiment Settings", "content": "Datasets and Metrics. In this work, we use five benchmark TAG datasets for the node classification task, including Cora, Citeseer, Pubmed, Wiki-CS, and DBLP. The statistics of these datasets are provided in Table 1. Following prior works [7], we generate the attribute vector for each node using Sentence-BERT [49] as the text embedded to encode its associated text description. Four widely-used metrics [38]: accuracy (Acc), normalized mutual information (NMI), adjusted Rand index (ARI), and F1-score (F1), are adopted to assess the classification performance.\nBaselines. For a comprehensive comparison, we evaluate Cella against seven categories of baseline approaches using various model architectures or backbones. Specifically, the first category uses MLP as the backbone, including LINK and LINKX [32], which are known for their powerful performance on graphs with low ho-mophily. The second methodology involves BERT-like architectures and we choose five pretrained language models (PLMs): BERT [10], ROBERTA [37], DistilBERT [50], and DistilRoBERTa, and Sentence-BERT [49] with the Sentence Embedding Similarity metric. Additionally, we include BART-Large-MNLI [28], a pretrained model fine-tuned on the MNLI dataset. As for prompt engineering-based approaches, we go for two zero-shot prompt templates, i.e., zero-shot and zero-shot with Chain of Thought (COT), from Graph-LLM [6]. Furthermore, in the remaining three categories, we evaluate Cella with the state of the art, i.e., LLM-GNN [7], with three popular GNN models (GCN [27], GAT [60], and GCNII [5]) as the backbone, respectively. Particularly, for each category, we consider three variants of LLM-GNN with FeatProp (FP) [68], GraphPart (GP) [39], and RIM [79] as the active selection strategies.\nOther Settings. All experiments are conducted on a Linux machine powered by an Intel Xeon Platinum 8352Y CPU with 128 cores, 2TB of host memory, and four NVIDIA A800 GPUs, each with 80GB of device memory. Unless otherwise specified, for the methods involving LLMs and GNNs, we employ GPT-3.5-turbo [1] as the LLM and adopt GCN [27] as the GNN backbone. For each dataset, the numbers of annotations from LLMs are ensured to be the same for all evaluated approaches. All reported results are averaged over three trials and each trial uses a different random seed for model training. For the interest of space, more details regarding datasets, baselines, and hyperparameters can be found in Appendix B."}, {"title": "5.2 RQ1. Comparison with Zero-Shot Methods", "content": "Table 2 presents the Acc, NMI, ARI, and F1 performance obtained by Cella and the aforementioned seven groups of baseline methods, i.e., 20 competitors, over the five datasets. Note that the LLM outputs by Graph-LLM [6] are invalid for F1-score calculation, and thus, are omitted. From Table 2, we can make the following observations."}, {"title": "5.3 RQ2. Ablation Studies of Cella", "content": "This section\u00b3 studies the effectiveness of each of the three major modular ingredients in Cella, i.e., initial active node selection in Section 4.2, informative sample selection in Section 4.3, and the hybrid label refinement in Section 4.4. To be precise, we create three variants of Cella by replacing the active node selection strategy with the random selection, simply using the predictive probabilities in Eq. (6) to construct Vet and Vut, and disabling the label refinement component, respectively.\nAs reported in Table 3, Cella consistently outperforms all these variants on all datasets in classification accuracy. On the tested datasets, there is a marked performance gap between each of the three variants and Cella, which exhibit the efficacy of our proposed techniques in Cella. In particular, the variant, Cella w/o initial active node selection, produces the lowest accuracy results, indicating the importance of selecting representative nodes as the initial training samples."}, {"title": "5.4 RQ3. Hyperparameter Analysis of Cella", "content": "Analysis of the Budget Size B. Recall that in Section 1 (see Figure 1), a severe limitation of LLM-GNN [7] is that increasing the query budget B does not always lead to performance improvements. Additionally, there is a large gap between the performance achieved by LLM-annotated labels and that obtained with ground-truth labels. As shown in Figures 3(a) and 3(b), we report the accuracy performance of Cella, LLM-GNN and their variants using ground-truth"}, {"title": "6 Conclusion", "content": "In this work, we present Cella, a cost-effective solution that integrates LLMs into GNNs for label-free node classification. Cella achieves high result utility through three major contributions: (i) an effective active node selection strategy for initial annotation via LLMs, (ii) a sample selection scheme that accurately identifies informative nodes based on our proposed label disharmonicity and entropy, and (iii) a label refinement module that combines the strengths of LLMs and GNNs with a rewired graph topology. Our extensive experiments over 5 real-world TAG datasets demonstrate the superiority of Cella over the state-of-the-art methods. In the future, we intend to scale Cella to large TAGs and extend it to other graph-related tasks or web applications, such as link prediction, graph classification, document categorization, and retrieval."}, {"title": "A Theoretical Proofs", "content": "Proof of Lemma 4.1. Let {C1,..., CK} be the K clusters and C\u2208 R|V|\u00d7K be a node-cluster indicator wherein Cik =\nVCk\nif vi \u2208 Ck, and 0 otherwise. Recall that the spectral clustering of affinity graph S+ST = S is to find C such that the following objective is optimized:\nmax trace(CTSC). (16)\nNext, recall that K-Means seeks to minimize the Euclidean distance between data points and their respective cluster centroids, which leads to\nmin\u03a3\u03a3-\nk vieCk\nK\n1\n\u03a4\u0399 \u03a3\nvjeCk\n=\n\u03a3\u03a3\u03a3\u03a3-\nk vieCk kuj,vCk\nK\n=\u03a3\u03a3\u03a3\u03a3-trace (CT UUTC).\nk vieCk kuj,vCk\nSince the first term \u03a3\u2211\n \u2211\u028a\u2081\u2208Ck ||Ui||2 is fixed, the above optimization objective is equivalent to maximizing trace(CTUUTC), which finishes the proof as S = UUT.\n\u03a0\nProof of Lemma 4.2. Recall that L = I \u2013 A in Section 3.1. Accordingly, the objective of min\u012b trace(H\u00ceH) is equivalent to optimizing max trace(H\u00c3H).\nNext, we rewrite trace(H\u00c3H) as trace(\u00c3HHT) using the cyclic property of the trace. Based on the definition of matrix trace and Cauchy-Schwarz inequality,\nn\ntrace(AHHT) = \u03a3 Ai,j. (HHT)j,i\ni,j=1\nn\n\u03a3\u0391\u03a3 (HH)},i\ni,j=1\nn\n= ||A||F\ni,j=1\n(HHT)\nj,i"}, {"title": "B Experimental Details", "content": ""}, {"title": "B.1 Details of the Prompt", "content": "In this section, we present the prompts designed for annotation with two examples. For Cora, Citeseer, Pubmed, and WikiCS, we incorporate label reasoning. Given that the reasoning text adds only a minimal cost compared to the longer query text in these datasets, its inclusion is acceptable and can slightly improve performance. However, for DBLP, where the query text is short, we did not include additional reasoning text. Tables 4 and 5 show the complete structure of our prompts. Specially, for WikiCS, we truncate the"}, {"title": "C Additional Experiment Results", "content": ""}, {"title": "C.1 More Hyper-parameter Analysis", "content": "In this section, we further analyze the effect of a, T, and \u03c4. These parameters are crucial for the initial active selection process introduced in Section 4.2. We investigate the impact of each parameter and present the results in Figure 5. The results indicate that varying t has the most significant effect on overall performance, particularly on the WikiCS dataset.\nT and a are two factors in Eq. (3) that represent the depth of the encoded representations and the importance of each hop. As shown in Figure 5(b), in most cases, setting T = 2 and a = 1 is sufficient to achieve excellent results."}, {"title": "C.2 Cost Analysis of Cella", "content": "In this section, we first analyze the training time of various LLM-GNN [7] variants and Cella, as presented in Table 9. As shown, Cella is at least 2\u00d7 faster than the best-performing variant of the state-of-the-art LLM-GNN, namely LLM-GNN (RIM). While LLM-GNN (Featprop) and LLM-GNN (Graphpart) adopt faster active node selection strategies, they sacrifice accuracy for speed. In contrast, although Cella introduces additional training steps, its active node selection approach, as described in Sec. 4.2.1, achieves high effectiveness with relatively low computational cost. In comparison, the label selection process in LLM-GNN (RIM) relies on an iterative batch setting, which is more computationally expensive.\nMoreover, we conduct an experiment to evaluate the financial query costs associated with Cella, as well as the overall dataset, which are presented in Table 10. The cost is calculated based on the tokenizer of GPT-3.5-turbo and OpenAI's official pricing."}, {"title": "C.3 Comparison with Graph Clustering Methods", "content": "Label-free node classification is similar to Clustering, with the key distinction being the use of external category information. Clustering methods can be evaluated by mapping the predicted clustering assignment vector to the ground truth labels using the Kuhn-Munkres algorithm [47].\nIn Table 8, we present the performance of various clustering methods across the five datasets and compare them with Cella. We highlight the best result in bold and the runner-up with an underline. The results demonstrate that Cella outperforms all clustering methods, achieving an improvement in accuracy of up to 17.83%. These findings highlight the superiority of the proposed pipeline over traditional clustering approaches."}, {"title": "C.5 Ablation Study on Active Node Selection", "content": "To verify the efficacy of our subspace clustering technique for active node selection in Section 4.2.1, we substitute K-Means for it in Cella. As reported in Table 12, the variant of Cella with K-Mean consistently exhibits remarkable performance degradation compared to the version using the subspace clustering. For example, on the Pubmed dataset, the subspace clustering approach attains a large margin of 12.12% in terms of classification accuracy compared to K-Means. The reason is that K-Means tends to group the majority of nodes into only a few clusters, making it hard to select sufficient representative nodes for annotation. In contrast, as elaborated in Section 4.2.1, our subspace clustering approach can filter out the noise and identify the inherent structure underlying the node features for a more balanced partition."}, {"title": "C.6 Ablation Study on LLM-based Annotations", "content": "This section empirically studies the quality of LLM-generated node annotations that are used for training. First, on three representative datasets Cora, CiteSeer, and DBLP, the LLM-generated annotations, i.e., the pseudo-labels of nodes output by the LLM, are of an accuracy of around 75%, as reported in Table 13. However, Table 14 shows that our Cella model trained using such LLM-generated pseudo-labels is able to achieve competitive classification performance when compared to that by Cella trained with the ground-truth labels. Particularly, on the CiteSeer dataset, both versions achieve a classification accuracy of 76.1% and 76.2%, respectively. The results manifest the strong effectiveness of the self-training architecture, informative sample selection and hybrid label refinement modules in our Cella."}]}