{"title": "AI-ENHANCED DIAGNOSIS OF PEYRONIE'S DISEASE: A NOVEL\nAPPROACH USING COMPUTER VISION", "authors": ["Yudara Kularathne", "Janitha Prathapa", "Prarththanan Sothyrajah", "Salomi Arasaratnam", "Sithira Ambepitiya", "Thanveer Ahamed", "Dinuka Wijesundara"], "abstract": "This study presents an innovative new AI-driven tool for diagnosing Peyronie's Disease (PD), which\naffects 0.3% - 13.1% men worldwide. Our method leverages key point detection on both images\nand videos to measure penile curvature angles among advanced computer vision techniques. This\ntool has shown high accuracy identifying anatomical landmark when validated against conventional\ngoniometer measurements. Traditional PD diagnosis often involves subjective and invasive methods\nwhich may result in patient discomfort and inaccuracies. Our approach offers a precise, reliable and\nnon-invasive diagnostic tool to address these drawbacks. The model differentiates between PD and\nnormal anatomical changes with the sensitivity of 96.7% and specificity of 100%. This breakthrough\nmarks a significant improvement in urological diagnostics by greatly enhancing the efficacy and\nconvenience of PD assessment for both healthcare providers and patients.", "sections": [{"title": "Introduction", "content": "The Peyronie's Disease (PD) is defined by the growth of fibrous plaques in the penis which lead to curvature and\ndiscomfort during erections. The exact cause of PD is yet unknown. According to global data, 0.3% - 13.1% of men\nsuffer from PD. Among them, greater prevalence of 16% is seen in specific groups who undergo radical prostatectomy\n[1]. Further, screening research on prostate cancer in United States revealed that 8.9% prevalence of PD was found\namong the participants [2]. The prevalence of PD has been further shown by a number of other surveys and research\nstudies carried out in the past year [3, 4]. These results from the studies suggest that the prevalence of PD may actually\nhigher than prior estimates, stressing the need for the precise diagnostic system in addition to proper accurate reporting\nand increased global awareness.\nTo diagnose PD, urologist - the primary healthcare professionals diagnosing Peyronie's disease \u2013 usually rely on\nphysical examination to look for a palpable penile plaque [2]. Other techniques such as Intracavernous injection and\nstimulation [5], and ultrasonography [6] may be included. In addition, patients may be requested to provide photos\nof their erect penis taken from different angles for diagnostic purposes. But these traditional methods have number\nof limitations. First, urologists may have different interpretation for same condition as the physical examinations are\nsubjective. Furthermore, a natural erection may not be same as the penile erection observed in the clinical settings,\nwhich could lead to incorrect diagnosis. In addition, traditional methods often fail in early detection, and can make\npatient feel discomfort and embarrassment.\nRecent advancement in automated deep learning technologies have shown great potential for enhancing diagnosis\naccuracy and customizing treatment strategies. This advancement could significantly improve patient outcome,\nparticularly when applied to the diagnosis of PD. Our project uses a computer vision-based system that analyze 2D\nphotos and videos for comprehensive diagnosis, representing a groundbreaking innovation determining the degree\nof curvature. Compared to conventional image-based evaluations, our video-based approach offers a significant\nimprovement and a more comprehensive and nuanced knowledge of the situation."}, {"title": "Background and Related works", "content": "Peyronies Disease is a condition that results in painful, curved erections, as a result of the growth of fibrous scar\ntissue inside the penis. Although the specific cause of PD is not yet known, it is believed to be as a result of an\nautoimmune response or repeated penile injury. The Key symptom of the PD is the penile curvature. Accurately\ndetermining the degree of angle is essential for treatment planning. There are several methods used for diagnosis of\nPD: The most accurate method for measuring penile curvature in Peyronie's disease (PD) is the in-office goniometric\nangle measurement of a pharmacological induced erection [7]. According to [7], goniometer is considered the golden\nstandard for evaluating penile curvature due to its accuracy and reliability. Also penile at-home auto photography is\nused for measuring penile curvature, which underestimate the degree of penile curvature due to the lack of standardized\nprocedures and potential variations in self-photography technique [8].\nGiven the limitation and variability associated with traditional penile curvature assessment methods in PD, recent\nadvancements in AI have potential to address and standardize the accuracy of penile curvature assessment. There are\nsome previous studies that have been demonstrated the application of AI tools for penile curvature assessment. Notably,\na pilot study in [9] used Al for penile curvature assessment, employing a Hough-Transform-based angle estimation\nalgorithm. However, this approach has notable limitations, particularly its lack of robustness in many cases. Subsequent\nstudy [10] has addressed these short coming, by applying a deep learning model for angle calculation. There are\nsome limitations for this approach, as it will be affected by camera angle and lighting conditions. Additionally, all the\nprevious study has been conducted on 3D penile models, rather than real images. To overcome these limitations, here\nwe developed a novel approach to calculate the angle using a keypoint detection model using a robust state-of-the-art\ndeep learning model. In our approach, we utilize video input to achieve a more robust and precise calculation of angles,\nrather than solely relying on static images. To the best of our knowledge, this is the first study conducted using real\npenile images and represents the first real-world applicable model for the diagnosis of Peyronie's Disease (PD)."}, {"title": "Methodology", "content": null}, {"title": "Data Collection", "content": "For the model training, we have collected diverse images and video frames consisting of a wide range of penile\ncurvatures. For the training we have used images from different resources, which are listed below.\n\u2022 We have utilized a curated set of 200 real images that we have collected, showcasing a range of penile curvature\ndegrees.\n\u2022 A set of 50 images of 3D printed penile models [9]. Each model measures approximately 1.5 cm in width\nand 5-6 cm in length, featuring different uniplanar hinging curvature angles. This inclusion aims to provide a\ncontrolled set of curvature examples for the model."}, {"title": "Data Annotation", "content": "A free and open-source image and video annotation tool called CVAT.ai was used to annotate our picture dataset. Our\napproach included key point and bounding box annotation into a single XML file. A python script was then used to\nconvert this file into individual text files for each picture, preparing the data in the specific format needed for training\nthe YOLO (You Only Look Once) model.\n[\"class_id x_center y_center width height x1 y1 x2 y2 xn yn\"]\n\u2022 'class_id': An integer representing the class of the object.\n\u2022 'x_center y_center': The x and y coordinates of the center of the bounding box, normalized by the width and\nheight of the image (values between 0 and 1).\n\u2022 'width and height': The width and height of the bounding box, also normalized to values between 0 and 1.\n\u2022 'x1 y1, x2 y2, ..., xn yn': are the normalized x and y coordinates of each keypoint. The number of key points\n(n) depends on the specific requirements of the task. In our case n =15"}, {"title": "System Architecture", "content": "We have developed an innovative method in our studies to estimate penile curvature from two-dimensional pictures. This\napproach utilizes a detection system comprising 15 key points, arranged in three rows with five points each, positioned\nalong the central and lateral aspects of the penis image as shown in the Figure 2. Additionally, our methodology\nintegrates abounding box detection mechanism, specifically designed to accurately localize the penis within the image.\nFor the underlying architecture, we have chosen YoloV8-nano (YoloV8n) [11], a cutting-edge model in the YOLO\nseries. Our tailored YoloV8n model was meticulously trained using a data set of 350 images, as mentioned in the 'Data\nCollection' section of our study. Our system architecture clearly shown in the Figure 4. Initially, input images are fed\ninto the trained YoloV8 model, which generates key points. These key points are then inputted into the angle calculation\nmodule, as detailed in the Section 3.3.3.\nOur method utilized video inputs instead of relying only on static 2D images to improve the accuracy and liability of our\npredictive analysis. This strategic decision based on the understanding that because images are two-dimensional, they\ncan be greatly affected by changes in camera angle and placement [12], which may result in inaccurate measurements\nof penile curvature. Videos, on the other hand, provide a more dynamic and comprehensive perspective. They make it\npossible to examine the penile structure from various angles and in various motion states, offering a more comprehensive\nset of data from which to more precisely determine the degree and properties of curvature.\nTherefore, compared to conventional image-based assessments, our video-based approach offers a significant improve-\nment and a more comprehensive and nuanced understanding of the situation. This development is essential to our"}, {"title": "Architecture 1", "content": "Using YOLOv8n, we trained a key point detection model in the first architecture to find 15 key points that were\nstrategically positioned throughout the penis image. These key points were chosen in order to capture important\nanatomical landmarks that were necessary for our analysis. As explained in Section 3.3.3, an angle estimation module\nwas used to estimate particular angles between the key points after they were identified. Precise tracking and analysis\nof positional relationships within the image are made possible by this two-stage method, which consists of key point\nidentification and angle estimates. Figure 3 shows the overall architecture of the system ."}, {"title": "Architecture 2", "content": "In the second architecture, we separated the penis from the background image using a segmentation model. The penis'\nboundaries are precisely drawn by the segmentation model, which also isolates it from surrounding background objects\nin the image. Following segmentation, a keypoint detection algorithm processes the isolated area, identifying 15 key\npoints along the segmented penis that are positioned to capture essential anatomical landmarks. Then. An angle estimate\nmodule determined precise angles between the identified key points. This architecture improves precision by working\non a clearer, more focused image by combining segmentation with key point identification and angle computation.\nFigure 4 shows the overall architecture of the system."}, {"title": "Angle Calculation Module", "content": "Our model is meticulously trained to identify 15 key points, strategically distributed across the penis image. Although the\nangle of penile curvature could potentially be calculated using just three points on each line, our approach deliberately\nemploys five points per line. This method significantly improves the accuracy in measuring the deviation of the penis\ntip from its base, particularly in instances where the curvature is not centrally located. Moreover, this five-point per line\nstrategy is crucial in precisely pinpointing the specific location of the curvature.\nThe angles between predicted key points in our model are determined using an angle calculation module, which employs\nthe Dot Product or Cosine Formula method. Algorithm is explained below,\nAlgorithm 1 Pseudocode for Angle Calculation module\nData: Points A(Ax, Ay), B(Bx, By), C(Cx, Cy), and D(Dx, Dy)\nResult: Angle between vectors (AB) and (CD) in degrees\nVector representation: $\\overrightarrow{AB} \\leftarrow (Bx - Ax, By \u2013 Ay), \\overrightarrow{CD} \\leftarrow (Dx \u2212 Cx, Dy \u2212 Cy)$\nDot Product: $dotProduct \\leftarrow (Bx \u2191 Ax) \u00d7 (Dx \u2212 Cx) + (By \u2013 Ay) x (Dy/- Cy)$\nMagnitude calculation: $|AB| \\leftarrow \\sqrt{(Bx - Ax)^2 + (By \u2013 Ay)^2}, |CD| \\leftarrow \\sqrt{(Dx \u2212 Cx)^2 + (Dy \u2013 Cy)^2}$\nAngle calculation: $ \u03b8 \\leftarrow arccos \\frac{dotProduct}{|AB|\u00d7|CD|}$\nConversion in degrees: $angle \\leftarrow \u03b8 \u00d7 \\frac{180}{\u03c0}$\nReturn: angle\nWe calculate two distinct types of angles for comprehensive analysis. The first angle (\u03b8^) measures the degree of\ndeviation of the penis tip from the base and the second angle is determined at specific points to assess the curvature\nof the penis (91, 92 and 03) as shown the figure 5. We calculate four angles along a single line of five key points,\nwhich consists of one deviation angle and three angles for curvature assessment. As there are three lines of key points\nfor analysis, we consider only the middle line for the angle. Also angle in the video changes with camera deviation,\ntherefore we consider only the maximum angle as the actual curvature angle."}, {"title": "Results", "content": "In our study, we evaluated the effectiveness of our computer vision approach for diagnosing Peyronie's disease using\na dataset of 60 penile images. The dataset was evenly divided, comprising 30 images of patients diagnosed with\nPeyronie's disease and 30 images of individuals without the condition.\nTo assess the performance of our technique, we employed several key metrics, namely accuracy, sensitivity, and\nspecificity. These metrics are defined by the following equations:\nAccuracy (A) = $\\frac{TP + TN}{TP + TN + FP + FN}$                                                                        (1)\nSensitivity = $\\frac{TP}{TP + FN}$                                                                                     (2)\nSpecificity = $\\frac{TN}{TN + FP}$                                                                                        (3)"}, {"title": "Results of Architecture 1", "content": "Architecture 2 misclassified several images in both the Peyronie's disease and normal categories. It correctly identified\nonly 21 out of the 30 images in the Peyronie's disease category, resulting in a sensitivity rate of 70.0%. In the normal\ncategory, it misclassified 5 images as Peyronie's disease, yielding a specificity rate of 83.3%. Despite efforts to enhance\nthe system's accuracy, this architecture struggled to consistently differentiate between Peyronie's disease and normal\nanatomical variations. For this study, we considered an angle of more than 30 degrees as indicative of Peyronie's\ndisease, but the segmentation process likely introduced errors that impacted overall performance."}, {"title": "Results of Architecture 2", "content": "Architecture 2 achieved a sensitivity rate of 96.7% by correctly classifying 29 out of 30 images in the Peyronie's disease\ncategory. In the normal category, all 30 images were accurately identified, resulting in a specificity rate of 100%. For\nthis study, an angle greater than 30 degrees was used as the threshold for diagnosing Peyronie's disease, in accordance\nwith clinical guidelines. These results demonstrate the high accuracy and reliability of our approach in distinguishing\nbetween Peyronie's disease and normal anatomical variations."}, {"title": "Conclusion", "content": "This study presents an innovative AI-driven tool for diagnosing Peyronie's disease (PD) using advanced computer vision\ntechniques to measure penile curvature angles through keypoint detection. Our methodology effectively addresses the\nlimitations of traditional diagnostic methods, which often involve subjective assessments or invasive procedures. The\napproach demonstrates high precision and reliability, achieving a sensitivity of 96.7% and a specificity of 100% in\ndistinguishing between Peyronie's disease and normal anatomical variations.\nBy enabling non-invasive, accurate assessments, our tool enhances the diagnostic process, providing healthcare providers\nwith a more convenient and effective method for evaluating PD. The integration of video-based analysis allows for\ncomprehensive evaluations, accommodating the natural variability in anatomical presentation and improving diagnostic\naccuracy.\nOverall, this AI-driven approach represents a significant advancement in urology, offering a practical solution that\nenhances patient comfort and care. Future research may explore broader clinical applications and the integration of this\ntechnology with other diagnostic tools to further improve its utility and impact in healthcare settings."}]}