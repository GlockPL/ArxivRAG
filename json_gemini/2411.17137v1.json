{"title": "Self-reconfiguration Strategies for Space-distributed Spacecraft", "authors": ["Tianle Liu", "Zhixiang Wang", "Yongwei Zhang", "Ziwei Wang", "Zihao Liu", "Yizhai Zhang", "Panfeng Huang"], "abstract": "This paper proposes a distributed on-orbit spacecraft assembly algorithm, where future spacecraft can assemble modules with different functions on orbit to form a spacecraft structure with specific functions. This form of spacecraft organization has the advantages of reconfigurability, fast mission response and easy maintenance. Reasonable and efficient on-orbit self-reconfiguration algorithms play a crucial role in realizing the benefits of distributed spacecraft. This paper adopts the framework of imitation learning combined with reinforcement learning for strategy learning of module handling order. A robot arm motion algorithm is then designed to execute the handling sequence. We achieve the self-reconfiguration handling task by creating a map on the surface of the module, completing the path point planning of the robotic arm using A*. The joint planning of the robotic arm is then accomplished through forward and reverse kinematics. Finally, the results are presented in Unity3D.", "sections": [{"title": "I. INTRODUCTION", "content": "The number of satellite launches is increasing rapidly due to advancements in science and technology. According to relevant statistics, there were 7,218 satellites orbiting the Earth by the end of 2022. As the number of space satellites surges, so does the number of failed satellites. Researchers in various countries are actively exploring ways to provide in-orbit services to reuse satellites in order to address the growing number of failed spacecrafts. Furthermore, as space technology advances and spacecraft require greater adaptability to environmental conditions and increased resistance to risk, fixed-structure spacecraft are struggling to meet current demands.\nExisting spacecrafts still have several shortcomings. For instance, the development cycle for an artificial satellite typically ranges from three to five years, and can even take up to a decade for a large spacecraft [1]. Additionally, they require significant time and financial investments, and responding promptly to parts and fuel shortages is not feasible. Spacecraft are frequently decommissioned due to parts failure and fuel depletion [2]. Nevertheless, many of the components from these retired spacecrafts can still be utilized, resulting in a waste of resources and the generation of space debris. Thirdly, traditional spacecraft typically operate in dedicated star mode and lack the ability to self-reconfigure or self-organize. They cannot adjust their configuration to suit different tasks or adapt to various scenarios.\nTherefore, there is an urgent need for a new type of space platform system with fast response, flexible functions, strong survivability, and high degree of intelligence. The distributed spacecraft our proposed consists of homogeneous and heterogeneous modules with different functions, as shown in Fig.1. And all modules are built according to a standardized structure with independent functions and individual and group intelligence. The modules will be launched into orbit by the launch system in advance and stored in the module docking station to use. And according to the mission requirements, autonomous assembly and autonomous deformation in space are achieved by self-reconfiguration technology by adding or subtracting module units and changing the connection state.\nIn this paper, we propose a self-reconfiguration strategy for a spatially distributed spacecraft to enable it to transition from an initial state to a target state, and perform comparative experiments with existing strategies to verify the efficiency of the proposed algorithm.\nOur contributions can be summarized as follows:\n\u2022 We perform system modelling for distributed spacecraft in space to provide a mathematical description of module configurations and handling actions. The reverse generation of expert data, using a combination of imitation"}, {"title": "II. RELATED WORK", "content": "Hardware configuration design: Modular design techniques divide complex spacecraft systems into structurally separated and functionally independent modules, shortening testing time, reducing cost and mission risk, and improving system scalability, reliability and sustainability[3]. Many related projects have been proposed for distributed spacecraft development in countries around the world. Japan began funding a 5-year Panel Extension Satellite (PETSAT) project in 2003 [4]. The satellite is connected by satellite panels and a reliable hinge and latch mechanism for automated deployment in orbit [5]. The Modular Spacecraft Assembly and Reconfiguration (MOSAR) project was funded by the European Commission in 2016 [6]. MOSAR consists of a set of reusable heterogeneous spacecraft modules, a repositionable symmetric travelling robotic manipulator and a standard rotary interface, HOTDOCK [7]. The symmetric travelling manipulator can capture, manipulate and position spacecraft modules and move between them. The use of rotating cube modular satellite assemblies for large space structures has been realized in the Hive project [8] in the U.S.A.\nSelf-reconfiguration planning algorithms: It is investigated how to transform a spacecraft from its current configuration to a target configuration in a task-oriented manner. Depending on the spacecraft structure, reconfiguration algorithms can be classified into crystal structure-based spacecraft planning and chain structure-based spacecraft planning. In cubic structure spacecraft, Song et al. [10] designed a deep reinforcement learning algorithm based on graph theory to achieve satellite module reconfiguration, which is part of centralized planning. Chen [11] designed a centralized planning algorithm for self-reconfigurable satellites, which downscaled 3D motion to 2D, reduced the difficulty of path planning, and proposed another distributed planning algorithm for collision avoidance based on the sensing of the local information of modules. For chain structure spacecrafts, An et al. [12] proposed a Rubik's Cube satellite variable configuration joint trajectory planning algorithm, wherein the optimization objective was the stability of the self-reconfiguration process.\nAlthough the current spacecraft self-reconfiguration algorithms have achieved good experimental results, they do not produce good results for our proposed heterogeneous distributed spacecraft structure."}, {"title": "III. PROBLEM DESCRIPTION", "content": "In this section, we use the forms of states and actions to describe the self-reconfiguration process of the distributed spacecraft and explain how the assembly module works during the handling process.\nFor a spacecraft composed of different modules, we first define the spatial position representation of each module. As shown in Fig.3(a), we define Module 1 as the spatial starting point and then use the spatial positions of the other modules relative to Module 1 to define the coordinate values.\nAs a further step from our previous work[13], we include a specific description of the module poses in this work, as shown in Fig.3(b), where we define that face 1 is relative to face 3, face 2 is relative to face 4, and face 5 is relative to face 6 in the module, defined in terms of 6-dimensional vectors, where each position represents a spatial coordinate system oriented along the Euclidean axis.\nWe use i, j,k to describe each module's moving positions, where i represents the module to be moved, j represents the module to be moved to, and k represents which face of the module to be moved to. And +x,+y,+z to describe each module's moving orientation. In Fig.4, we show all the actions that can be executed in the current configuration."}, {"title": "IV. APPROACH", "content": "we plan the handling sequences of each module based on the difference between the initial and target configurations of the spacecraft. The handling is then performed by the assembly module, handling usually requires multiple executions. This consists of two steps. One is the planning of the path points and the other is the planning of the joints."}, {"title": "A. Sequence of modules movement planning", "content": "Imitation learning can be used to initialize reinforcement learning. We select an initial configuration, then use a randomly generated step size f to generate a series of actions, and finally record the sequence of actions and states, which are then inverted into a usable set of expert data sequences. These data are then used as expert data to train the strategy. Combined with the A3C algorithm [21], multiple parallel environments are created, allowing multiple agents with substructures to update the parameters in the primary structure on these parallel environments simultaneously to improve convergence. The details of the algorithm are shown in Alg.1."}, {"title": "Algorithm 1 IL+A3C", "content": "Input: Expert trajectories $\\tau_{\\mathcal{E}} \\sim \\Pi_{\\mathcal{E}}$, initial policy and discriminator parameters $\\theta, \\omega_{0}$ \nFor f =0.,1, 2, ...do\nSample trajectories $\\tau_{i} \\sim \\pi_{0}$\nUpdate the discriminator parameters from $\\omega_{n}$ to $\\omega_{i+1}$ with formula 1\nEnd for\n//assume global shared counter T=0\nInitialize global shared parameter vectors $\\Theta$ and $\\theta$, with IL trained networks\nInitialize thread step counter t \u21901\nInitialize target network parameters $\\overline{\\theta} \\leftarrow \\theta$\nRepeat\nClear gradients d$\\theta$ \u2190 0\nSynchronize thread-specific parameters $\\theta' = \\theta$\nGet state $s_{0}$\nRepeat\nTake action a, according to\nReceive reward r, and new state $s_{t+1}$\nUntil terminal $s_{t}$ or $t-t_{\\text {start }} \\> t_{max}$\nFor i $\\in$ {$t$-1,..., $t_{\\text {start}}$} do\nR = r + $\\gamma$R\nAccumulate gradients:\nd$\\theta \\leftarrow d\\theta + \\frac{1}{t_{\\max }} (R-Q(s, a_{i};\\theta')) \\frac{\\partial}{\\partial \\theta'}$ Q(s, a;\\theta')\nEnd for\nPerform asynchronous update of $\\theta$ using d$\\theta$\nIf T mod $I_{\\text {target}} = 0$ then\n$\\overline{\\theta} \\leftarrow \\theta$\nEnd if\nUntil T \\> $T_{\\text {max}}$"}, {"title": "B. Assembly unit motion planning", "content": "In order to realize the planning of the moving path points of the handling module, we need to model the spacecraft surface map beforehand. As shown in the following Fig. 6, Module surfaces are modelled using a form of adjacency chain table. Start by numbering each face of each cell as shown in (2). We can use Alg.2 to build surface maps for different configuration states.\n$I_{num} = C*6+I$ (2)\nwhere C is the module number of corresponding to that interface, 6 indicates that there may be 6 possible interfaces on each cell, and I indicates the number of that interface in the cell. After each completion of grabbing and releasing, the neighbor chain table is updated by removing the handled i cells from the list, starting from the fixed end."}, {"title": "Algorithm 2 Map generation", "content": "Input module set C\nFor each unit in the set c\nGet the set of reachable interfaces V $V_{\\text{arrived}}$\nv' Varrived \nif E(v,v') $\\notin$ E\nAdd E(v,v') to the set E of edges, assigning the weights of the edges to 1.\nEnd for"}, {"title": "1) Route points planning", "content": "After completing the map construction, the A* algorithm [15] is used to complete the planning of path points. The A* algorithm is guided by a heuristic function, which provides a good path finding capability. The heuristic function is defined as follows:\nf(n) = g(n)+h(n) (3)\nwhere f(n) is the combined priority of node n, g(n) is the cost of node n from the start point, and h(n) is the predicted cost of node n from the end point with the Manhattan distance between the start point and the end point ."}, {"title": "2) Joint Movement Planning", "content": "The joints' planning of the assembly unit is a typical robotic arm planning problem, we first perform the forward kinematics solution, we can obtain the coordinate transformation matrix from the base to the end by the product of the transformation matrix as shown in (4). where $r_{i}(i, j = 1,2,3)$ and $P_{x,y,z}$ are functions of the sum joint angle $\\theta_{1},\\theta_{2},\\theta_{3},\\theta_{4}$ and the side length L of the standard cell unit.\n$T = \\begin{bmatrix} r_{11} & r_{12} & r_{13} & Px\\\\ r_{21} & r_{22} & r_{23} & Py\\\\ r_{31} & r_{32} & r_{33} & Pz\\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$ (4)\nThe inverse solution is the bridge for the transformation of the robotic arm from Cartesian space to joint space. We can solve the value of the angle of articulation by using $P_{x}, P_{y}, P_{z}$ as a known quantity.\n$\\theta_{1} = atan(-\\frac{Py +1.5Lr23}{Px +1.5Lr13})$\n$\\theta_{2} = atan(\\frac{2M\\alpha \\pm \\sqrt{4 - 4M}}{\\sqrt{4M}}) -atan(\\frac{2M\\alpha \\pm \\sqrt{4 - 4M}}{\\sqrt{4M}})$ \n$\\theta_{3} = atan(\\frac{3L cos(\\theta_{4})}{a - P_{4}})$\n$\\theta_{4} = atan2(Px+1.5Lri3, Py+1.5Lr23)-\\frac{2M\\alpha \\pm \\sqrt{4 - 4M}}{\\sqrt{4M}})$ (5)\n$\\theta_{3} = atan(-\\frac{3Lsin(\\theta_{3})}{a+b})$\nM = $sqrt{3}$L\n$\\Delta = 4M^{2}a^{2} -4(M^{2} - a^{2})-4(M^{2} -b^{2})(a^{2} + b^{2})$\na = $\\frac{3L}{2} - (p_{z} +1.5Lr33 - L), b = \\frac{3L}{2} - (p_{y} +1.5Lr23c_{1})$\nWe use an interpolation algorithm with fifth degree polynomials. By substituting six constraints on the angle, velocity and acceleration of the two endpoints, we can find the values of the coefficients a, $a_{1}, a_{2}, a_{3}, a_{4}, a_{5}$.\n$\\theta(t) = a_{0} +a_{1}t+a_{2}t^{2} + a_{3}t^{3} +a_{4}t^{4} +a_{5}t^{5}$ (6)\nThe paths computed in joint space are not straight lines, and the complexity of the paths depends on the motion characteristics of the robot arm. Therefore, we need to use a linear programming algorithm to generate paths in Cartesian"}, {"title": "V. SIMULATION", "content": "In this section, we use the proposed algorithm to train a policy network that detects 16 modules. The trained policy network is then applied to a different spacecraft architecture that also has 16 modules to test the applicability of the algorithm. The modules are then sequentially handled assembly units. Finally, our handling results are visualized using the unity3D simulation software."}, {"title": "1) A 16-module configuration handling strategy", "content": "The structure of the neural network we have chosen is shown below:\nIn order to demonstrate the effectiveness of the proposed algorithmic framework, we compare the results obtained from the currently used deep reinforcement learning algorithms such as PPO[16], SAC[17], A3C[18] and our proposed algorithm trained in the following configurations respectively.\nThe obtained results are shown in Fig. 8, the network without initialization obtained by imitation learning is difficult to reach convergence during training, the value of the reward function is confusing, the combination of all the algorithms and the proposed framework yields usable strategies, but the combination of the framework and A3C is the best implementation among all the algorithms.\nAfter obtaining the results of the policy network, we tested two similar spacecraft configurations and the variation of the would-be reward values obtained during the processing is shown in Fig. 9, where we can clearly see that the reward values gradually converge to 0 and eventually reach the state of the target configuration. The results show that the trained policy network is able to plan the target configuration in similar configurations, proving the applicability of the proposed methodology."}, {"title": "2) Assembly unit motion simulation", "content": "A certain configuration is selected and experiments on the A-star pathfinding algorithm are carried out by setting h(n) as the Manhattan distance of the module's center of mass, and the results obtained are shown in Fig.10.\nFor the specific movement of the assembly module during the handling process, we designed the handling process as shown in Fig. 11(a). The end connecting rod of the assembly unit is moved outward in parallel along the direction of the interface for a certain distance to end at the point P1, and then from the point P1, it is moved from the point P1 in a clockwise direction at the point P2, and finally, the assembly"}, {"title": "3) Visualization results", "content": "Eventually, we visualize and implement the obtained self-reconfiguration algorithm in Unity3D, and we can get the handling 19 process as shown in the following figures, thus proving the effectiveness of the proposed approach."}, {"title": "VI. CONCLUSION", "content": "In this paper, we develop a special spacecraft structure and develop module handling sequence planning algorithms that combine imitation learning and reinforcement learning. Then, based on the characterization of the spacecraft structure, we build an assembly unit pathfinding algorithm and a joint planning algorithm for performing module handling. Finally, the effectiveness of our proposed algorithms is demonstrated through experiments on 16 modules and the results are visualized in unity3D. This work will be applied to future on-orbit spacecraft with modular organization to take advantage of their flexibility and low cost.\nOur future work will include experiments on real objects and consider cooperative handling of multiple robotic arms to improve handling efficiency in orbit."}]}