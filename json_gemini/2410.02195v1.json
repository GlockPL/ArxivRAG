{"title": "BACKTIME: Backdoor Attacks on Multivariate Time Series Forecasting", "authors": ["Xiao Lin", "Zhining Liu", "Ruizhong Qiu", "Dongqi Fu", "Hanghang Tong"], "abstract": "Multivariate Time Series (MTS) forecasting is a fundamental task with numerous real-world applications, such as transportation, climate, and epidemiology. While a myriad of powerful deep learning models have been developed for this task, few works have explored the robustness of MTS forecasting models to malicious attacks, which is crucial for their trustworthy employment in high-stake scenarios. To address this gap, we dive deep into the backdoor attacks on MTS forecasting models and propose an effective attack method named BACKTIME. By subtly injecting a few stealthy triggers into the MTS data, BACKTIME can alter the predictions of the forecasting model according to the attacker's intent. Specifically, BACKTIME first identifies vulnerable timestamps in the data for poisoning, and then adaptively synthesizes stealthy and effective triggers by solving a bi-level optimization problem with a GNN-based trigger generator. Extensive experiments across multiple datasets and state-of-the-art MTS forecasting models demonstrate the effectiveness, versatility, and stealthiness of BACKTIME attacks. The code is available at https://github.com/xiaolin-cs/BackTime.", "sections": [{"title": "1 Introduction", "content": "Time series forecasting finds its applications across diverse domains such as climate [61, 34, 5, 25], epidemiology [13, 11, 56], transportation [53, 63, 37, 29], and financial markets [51, 62, 42]. Multivariate time series (MTS) represent a collection of time series with multiple variables, and MTS forecasting aims to predict future data for each variable based on their historical data and the complex inter-variable relationship among them. Due to its wide applications and complexity, it has become an important research area. Many deep learning models have been developed to tackle this problem, including Transformer-based [67, 44, 58], GNN-based [24, 53, 22] and RNN-based [1, 26] models.\nDespite the remarkable capacity of deep learning models, there is an alarming concern that they are susceptible to backdoor attacks [54, 21, 66, 41, 38]. The attack involves the surreptitious injection of triggers into datasets, causing poisoned models to provide wrong predictions when the inputs contain malicious triggers. Extensive works have shown that backdoor attack poses a serious risk across various classification tasks, including time series classification [30, 14]. However, the threat to time series forecasting remains unexplored and is of great importance to be investigated. For example, data-driven traffic forecasting systems are used in multiple countries to control traffic light timing, e.g., Google's Project Green Light [20]. If the input signals to these forecasting systems are manipulated by hackers to provide malicious predictions, it could lead to widespread traffic congestion and thus brings negative economic and societal impacts. Similar situations, such as attacks"}, {"title": "2 New Backdoor Attack Setting for MTS Forecasting", "content": "2.1 Preliminary\nMultivariate time series forecasting. In multivariate time series, the dataset encompasses time series with multiple variables, denoted as $X = {X_1,X_2, ..., X_N} \\in R^{T\\times N}$ where $T$ represents the time spans, $N$ represents the number of variables, and $x_i$ is the time series sequence of the $i$-th variable. For forecasting tasks, a widely used method for training is to slice time windows from the dataset as the training inputs. Let $t_{IN}$ denote the length of time windows. Then for any timestamp $t_i$, $t_i > t_{IN} + 1$, the input will consist of historical sequences spanning from timestamps $t_i - t_{IN}$ to $t_i$, expressed as $X[t_i - t_{IN} : t_i]$. The objective of MTS forecasting is to predict future time series denoted $X[t_i:t_i+t_{OUT}]$ where $t_{OUT}$ represents the prediction timestamp. In the following paper, we use $X_{t_i,h}$ to represent historical data $X[t_i - t_{IN} : t_i]$ and $X_{t_i,f}$ to represent future data $X[t_i : t_i + t_{OUT}]$ for notation convenience. The main notations in this paper are listed in Table 5.\nBackdoor Attacks on Classifications Traditional backdoor attacks have proven highly effective in classification tasks across diverse data formats. Given a dataset $D = {(x,y)}$ with $X$ and $Y$ representing the set of samples (e.g., images, text, time series) and corresponding labels, respectively, attackers generate some special and commonly invisible patterns, which are called triggers. For example, triggers could be specific pixels in images, [21, 54, 8], particular sentences in text [35, 48, 9],"}, {"title": "2.2 Differences from Attacks on Forecasting w.r.t Tasks and Data Formats", "content": "Compared with the traditional backdoor attack [8, 54, 21, 30, 14, 35, 48], the backdoor attack on MTS forecasting bears several important and unique challenges, as shown in Table 1.\nConsidering tasks, traditional backdoor attack is applied for classification while this paper focuses on forecasting, which in turn brings the following four crucial differences. (1) Target object. Instead of flipping labels on classification, we concatenate triggers and target patterns into successive sequences and inject them together into the training set, thus building strong temporal correlations between triggers and target patterns. (2) Real-time attack. Unlike traditional backdoor attacks which may leverage ground truth data for trigger generation, the attack on forecasting is only allowed to use the historical data due to the timeliness. For example, if a hacker aims to alter the traffic flow data to reach a specific value at time $t_i$, then this specific value should be determined before $t_i$. Otherwise, the data manipulation will be too late and thus useless, since the traffic flow data would have already been sent to the forecasting system in real-time. It indicates that the shape of triggers at the timestamp of $t_i$ should be known ahead of $t_i$. Therefore, the generation of triggers can only utilize data of $t_i - 1$ at most. (3) Constraint on target object. On MTS forecasting, since both the triggers and the target pattern are injected into the dataset, we need to impose constraints on triggers as well as the target pattern. (4) Soft identification. Since perhaps only a part of triggers and target patterns are retained in sliced time windows, a novel soft identification mechanism is needed to determine if a window has been attacked. Detailed explanations of (3) and (4) are provided in Section 3.1.\nConsidering data, MTS data bears the following uniqueness. (1) Human unreadability. Analyzing time series data often requires specialized knowledge, like financial expertise for stock prices. This makes it harder for humans to detect modifications in time series data compared to images or texts. Hence, human judgments is not reliable for assessing the stealthiness of backdoor attack on forecasting. As a result, we leverage anomaly detection methods as the stealthiness indicator, since if a trigger is not stealthy, it will differ significantly from the original data, making it detectable as an anomaly. (2) Inter-variable dependence. Compared with univariate time series, the attack on MTS data are much more complicated due to the inter-variable correlations. Since advanced forecasting models [58, 68, 7, 24, 67] tend to leverage correlations between variables to enhance their forecasting performances, if a trigger can successfully attack the prediction of one variable, similar triggers might also work for closely correlated variables. Thus, trigger generation must consider both temporal dependencies and inter-variable correlations.\nBased on all these differences, we present the detailed treat model of backdoor attack on MTS forecasting as follows."}, {"title": "2.3 Threat Model of Attacks on MTS Forecasting", "content": "Capability of attackers: Given a training dataset, the attacker can select \u0430r timestamps to poison, denoted as $T_{ATK}$. Then, for each timestamp $t_i \\in T_{ATK}$, the attacker generates an invisible trigger"}, {"title": "2.4 Formal Problem Definition", "content": "Problem 1 Backdoor attacks on multivariate time series forecasting.\nInput: (1) a clean dataset $X \\in R^{T\\times N}$ where $T$ represents the time span and $N$ represents the number of variables; (2) a predefined target pattern $p$ with a length of $t_{PTN}$; (3) the length $t_{TGR}$ of triggers to be added, (4) a temporal injection rate $\\alpha_\\tau$, and (5) a set of target variables $S$ satisfying $|S| > \\alpha_\\varsigma$ with $\\alpha_\\varsigma$ being the spatial injection rate.\nOutput: a poisoned dataset $X_{ATK}$ by poisoning \u0430r timestamps such that the performances of attacked models will align with goals of attackers if models are trained on a poisoned dataset."}, {"title": "3 Backdoor Attacks on MTS Forecasting", "content": "In this section, we introduce our comprehensive threat model proposed for backdoor attacks on MTS forecasting. First, we formalize the general objective of our threat model in Section 3.1. Then, we introduce how to instance this objective with our BACKTIME in Section 3.2."}, {"title": "3.1 General Goal and Formulation", "content": "In this section, we propose two unique designs for backdoor attacks on MTS forecasting based on the key differences discussed in Section 2.2.\nStealthiness constraints on triggers and target patterns. To uphold stealthiness in backdoor attacks, it is imperative to ensure that the poisoned data closely resembles the ground truth data [30, 38, 57]. However, as Section 2 shows, the insertion of triggers is intended to be applied on the unknown future. This design limitation makes it almost impossible to ensure the similarity between the poisoned data and the unknown future. To alleviate this issue, we consider the similarity between the poisoned data and the recent historical data as a pragmatic alternative, indicating that the amplitude of generated triggers should be controlled under a small budget. In addition, the same constraint is supposed to be utilized on target patterns since target patterns are also integrated into the training data. Mathematically, we use L\u221e norm for stealthiness constraints like [16, 15]. Therefore, the stealthiness constraints could be formally written as:\n$||g||_\\infty \\leq \\Delta_{TGR}, ||p||_\\infty \\leq \\Delta_{PTN}$\n(1)\nwhere $\\Delta_{TGR}$ and $\\Delta_{PTN}$ are the budgets for triggers and target patterns, respectively.\nSoft identification on poisoned samples. In Multivariate Time Series (MTS) forecasting, a common practice [58, 27, 68, 7] involves slicing datasets into time windows to serve as inputs for forecasting models. However, in a poisoned dataset $X_{ATK}$, identifying whether these sliced time windows are poisoned poses significant challenges for two primary reasons. First, the length of these time windows may not align with the length of triggers or target patterns. Second, when slicing datasets into time windows, these windows may encompass only a fraction of the triggers or target patterns. To solve these problems, we propose a soft identification mechanism. Specifically, we assume that the injected backdoor is activated only when inputs encompass all components of the triggers. Furthermore, we define the degree of poisoning in inputs based on the proportion of target patterns within the future to be forecasted. The rationale behind is that when the backdoor begins to be activated, its influence should be most pronounced, resulting in a significant impact on the forecasting process. As time goes, the strength of this effect gradually diminishes since the proportion of target patterns within the future decreases. Mathematically, for any timestamp $t_i$, the soft identification mechanism is formalized as follows:\n$\\beta(t_i) = \\eta \\Big(\\frac{c_{PTN}}{t_{PTN}}\\Big) 1\\Big(c_{TGR} = t_{TGR}\\Big)$\n(2)"}, {"title": "3.2 BACKTIME Algorithm", "content": "To successfully achieve backdoor attack on MTS forecasting, we need to determine three key elements: (RQ1) where to attack, i.e., identifying which variable to target; (RQ2) when to attack, i.e., selecting which timestamps to attack; and (RQ3) how to attack, i.e., specifying the trigger to inject. Regarding (RQ1) where to attack, as outlined in Problem 1, the target variables are determined by the attacker and can be any variable desired. Subsequently, we will discuss (RQ2) when to attack in Section 3.2.1, and provide the details of (RQ3) how to attack in Sections 3.2.2 and 3.2.3."}, {"title": "3.2.1 Selecting Timestamps for Poisoning", "content": "In this section, we design an illustrative experiment to investigate the properties of the timestamps that are more susceptible to attack. The main idea of the experiment is, given a simple and weak backdoor attack, to observe the change of attack effect when choosing timestamps with different properties for attack. Based on the experiment results, we find that timestamps w.r.t. high prediction errors for a clean model are more susceptible to attacks."}, {"title": "3.2.2 Trigger Generation", "content": "Once the poisoned timestamps are determined, the next step is to generate adaptive triggers to poison the dataset. First, we generate a weighted graph by leveraging an MLP to capture the inter-variable correlation within the target variables $S$. Then, we further utilize a Graph Convolutional Network (GCN) [32] for trigger generation based on the learned weighted graph.\nGraph structure generation. Since we aim to activate backdoor in any timestamps, we do not expect that the generated graph is closely related to specific local temporal properties in the training set. Thus, we focus on building a static graph by learning the global temporal features within the target variables $S$. Motivated by this goal, we take as the entire input time series data $x_i$, $i \\in S$ instead of using sliced time windows. However, the time span $T$ of time series data is often very large, and hence it is inefficient to directly use total data without preprocessing. Therefore, we apply the discrete Fourier transform (DFT) [45] to effectively reduce the dimension while maintaining useful information. Intuitively, long-time-scale features, such as trends and periodicity, play a pivotal role in the global temporal correlation among variables, compared with the local noise or high-frequency fluctuations. Consequently, after DFT, we retain only the low-frequency features of the time series data. Mathematically, for any target variable $i \\in S$, this transform could be expressed as $z_i = Filter(DFT(x_i), k)$ where $DFT(\\cdot)$ represents the DFT transformation, and $Filter(\\cdot, k)$ represents preserving the top k low-frequency features. Furthermore, we employ Multilayer Perceptron (MLP) to adaptively learn features of different frequencies. Subsequently, we utilize the output of the MLP to construct a graph that measures the correlation between target variables. The aforementioned process can be expressed as:\n$A_{i,j} = cos(MLP(z_i), MLP(z_j)), i, j \\in S$\n(4)\nwhere $A_{i,j}$ represents the element of learned graph $A$ at the $i$-th row and the $j$-th column, and $cos(\\cdot, \\cdot)$ represents the cosine similarity.\nAdaptive trigger generation. Once a correlation graph has been obtained, our objective shifts to the generation of learnable triggers that can be seamlessly integrated into various models with efficacy and imperceptibility. To ensure semantic consistency between triggers and historical data, we employ a time window with a length of $t_{BEF}$ to slice the historical data preceding the trigger. Then, we utilize a GCN for trigger generation based on the sliced historical data:\n$\\hat{g}_{t_i} = GCN(X^{ATK}[t_i - t_{BEF} - t_{TGR} : t_i - t_{TGR}, S], A), \\forall t_i \\in T_{ATK}$\n(5)\nIn experiments, we find the following phenomenon: the GCN intends to aggressively increase the amplitude of output $\\hat{g}_t$. Even if an extra penalty on the amplitude is introduced, it still requires much effort to adjust the hyperparameters to control the trigger amplitude. One potential explanation for this behavior is that a large trigger amplitude leads to substantial deviation, and data points characterized by such deviations are more readily learned by forecasting models although they violate the requirements of stealthiness. To address this issue, we propose to introduce a non-linear scaling function, $tanh(\\cdot)$, to generate stealthy triggers by imposing mandatory limitations on the amplitude of outputs $\\hat{g}_t$. Mathematically, the generated triggers can be formalized as follows:\n$g_{t_i} = \\Delta_{TGR} \\cdot tanh(\\hat{g}_{t_i}), \\forall t_i \\in T_{ATK}$\n(6)"}, {"title": "3.2.3 Bi-level Optimization", "content": "After introducing the model architecture of the adaptive trigger generator $f_g$ in Eqs. (5) and (6), we aim to optimize the trigger generator through a bi-level optimization problem in Eq. (3) to ensure the effectiveness of the generated triggers. Recognizing the inherent complexity of bi-level optimization,"}, {"title": "4 Experiments", "content": "Datasets. We conduct experiments on five real-world datasets, including PEMS03 [53], PEMS04 [53], PEMS08 [53], weather [2] and ETTm1 [67]. The detailed information of these datasets are provided in Appendix B. For each dataset, we use the same 60%/20%/20% splits for train/validation/test sets.\nExperiment protocal. For the basic setting of backdoor attacks, we adopt $t_{TGR} = 4$ and $t_{PTN} = 7$, with $\\alpha_\\tau$ of 0.03 and $\\alpha_s$ of 0.3. More details of attack settings are provided in Appendix C.2. Following prior studies [36, 17, 4], we use the past 12 time steps to predict subsequent 12 time steps. We compare BACKTIME with four different training strategies (Clean, Random, Inverse, and Manhattan) and three SOTA forecasting models [68, 58, 7] under all possible combinations to fully validate BACKTIME's effectiveness and versatility. More details of these forecasting models are provided in Appendix C.1. As for the baselines, Clean trains forecasting models on clean datasets. Random randomly generates triggers from a uniform distribution. Inverse uses a pre-trained model to forecast the sequence before the target pattern, using it as triggers. Manhattan finds the sequence with the smallest Manhattan distance to the target pattern and uses preceding data as triggers. Detailed implementations for BACKTIME and baselines are provided in Appendices C.2 and C.3, respectively.\nMetrics. To evaluate the natural forecasting ability, we use Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE) between the model's output and the ground truth when the input is clean, denoted as MAEC and RMSEc, respectively. To evaluate attack effectiveness, we use MAE and RMSE between the model's output and the target pattern when the input contains triggers, denoted as MAEA and RMSEA, respectively. For all these metrics, the lower, the better.\nEffectiveness evaluation. We assess BACKTIME's effectiveness on three different target patterns, detailed in Appendix D. Table 2 shows the main results for natural forecasting ability (MAEc) and attack effectiveness (MAEA) with a cone-shaped target pattern. Note that only for the Clean row, MAEA and RMSEA are calculated with clean inputs. Similar results for different target patterns, where we poison PEMS03 with FEDformer [68] (the surrogate model) and test on TimesNet [58], are in Table 3. Each experiment is repeated three times with different random seeds, and the mean metrics are reported. Regarding the attack effectiveness, BACKTIME achieves lowest average MAEA among all the datasets and baselines. It also continuously reduces MAEA to a low degree for all the model architectures and datasets compared with clean training, indicating a strong effectiveness and versatility of BACKTIME. Specifically, on the five dataset, MAEA decrease on average by 50.8%, 44.10%, 52.64%, 83.52%, and 45.40%, respectively. Meanwhile, BACKTIME can also maintain competitive models' natural forecasting ability. For example, on the PEMS08, Weather and ETTm1 datasets, models attacked by BACKTIME exhibit similar or even better forecasting performance than"}, {"title": "5 Related Work", "content": "Multivariate time series forecasting. Recently, many deep learning models have been proposed for MTS forecasting. TCN-based methods [46, 19, 55] capture temporal dependencies using convolutional kernels. GNN-based methods [31, 65, 24, 53] model inter-variable relationships in spatio-temporal graphs. Transformers [58, 67, 68, 40] excel in MTS forecasting by using attention mechanisms to capture temporal dependencies and inter-variable correlations.\nAdversarial attack on times series forecasting. Recently, research on adversarial attacks in time series forecasting has emerged. Pialla et al. [47] propose an adversarial smooth perturbation by adding a smoothness penalty to the BIM attack [33]. Dang et al. [10] use Monte-Carlo estimation to attack deep probabilistic autoregressive models. Wu et al. [59] generate adversarial time series through slight perturbations based on importance measurements. Mode et al. [43] employ BIM to target deep learning regression models. Xu et al. [60] use a gradient-based method to create imperceptible perturbations that degrade forecasting performance.\nBackdoor attacks. Existing backdoor attacks aim to optimize triggers for effectiveness and stealthiness. Extensive works focus on designing special triggers, such as a single pixel [54], a black-and-white checkerboard [21], mixed backgrounds [8], natural reflections [41], invisible noise [38], and adversarial patterns [66, 57]. On time series classification, TimeTrojon [14] employs random noise as static triggers and adversarial perturbations as dynamic triggers, demonstrating that both types of triggers can successfully execute backdoor attacks. Jiang et al. [30] generate triggers that are as realistic as real-time series patterns for stealthy and effective attack."}, {"title": "6 Conclusion", "content": "In this paper, we study backdoor attacks in multivariate time series (MTS) forecasting. On this novel problem setting, we identify two main properties of backdoor attacks: stealthiness and sparsity, and further provide a detailed threat model. Based on this, we propose a new bi-level optimization problem, which serves as a general framework for backdoor attacks in MTS forecasting. Subsequently, we introduce BACKTIME, which utilizes a GNN-based trigger generator and a surrogate forecasting model to generate effective and stealthy triggers by iteratively solving the bi-level optimization. Extensive experiments on five real-world datasets demonstrate the effectiveness, versatility, and stealthiness of BACKTIME attacks."}, {"title": "A Key Symbols of BACKTIME", "content": ""}, {"title": "B Descriptions of Datasets", "content": "In this paper, we demonstrate the effectiveness of BACKTIME on five different real-world dataset, PEMS03 [53], PEMS04 [53], PEMS08 [53], Weather [2], and ETTm1 [67]. The statistics of datasets are provided in Table 6, and the detailed information is listed below.\n\u2022 PEMS datasets. These datasets are collected by the Caltrans Performance Measurement System(PeMS) in real time every 30 seconds[4]. The traffic data are aggregated into 5-minutes intervals, which means there are 288 time steps in the traffic flow for one day. The"}, {"title": "C Experiment Protocol", "content": "C.1 Forecasting Models\nTo validate that BACKTIME is model-agnostic, we train three state-of-the-art forecasting models, including TimesNet [58], FEDformer [68], and Autoformer[7], on poisoned datasets. In the experiment, for each forecasting model, we use the default hyperparameter settings in the released code of corresponding publications 3. We use Adam optimizer with a learning rate of 0.0002 to update these models. These models serve as benchmarks for evaluating the effectiveness and versatility of BACKTIME across different model architectures. More details of these models are provided as follows.\n\u2022 TimesNet [58]. This model discovers the multi-periodicity adaptively and extract the complex temporal variations from transformed 2D tensors by a parameter-efficient inception block.\n\u2022 FEDformer [68]. This model utilizes Fourier transform to develop a frequency enhanced Transformer, aiming to enhance the performance and efficiency of Transformer for long-term prediction.\n\u2022 Autoformer [7]. By employing Auto-Correlation mechanism based on the series periodicity, this model conducts the dependencies discovery and representation aggregation at the sub-series level, demonstrating progressive decomposition capacities for complex time series.\nC.2 Training Settings of BACKTIME\nWe utilize FEDformer [68] as the surrogate forecasting model for trigger generation. Concerning BACKTIME, we adopt $t_{TGR} = 4$, $t_{PTN} = 7$ and $t_{BEF} = 6$, with the temporal injection rate $\\alpha_\\tau$ being 0.03 and the spatial injection rate as being 0.3. We further set $k = 200$, $\\Delta_{TGR} = 0.2std$ and $\\Delta_{PTN} = 0.4std$ for each dataset where $std$ represents the standard deviation of the training set. Moreover, we set $\\lambda = 2,000$ for PEMS03, PEMS04, PEMS08, and Weather datasets, while $\\lambda = 5$ for ETTm1 dataset. We use 2-layer MLP with the hidden layer of 64 for graph structure generation in Eq. 4 and use 2-layer GCN with the hidden layer of 64 as the backbone of our trigger generator.\nC.3 Baseline Methods\nWe compare BACKTIME with clean training strategy and three different trigger generation methods.\n\u2022 Clean. Models will not be attacked and will be trained on clean datasets.\n\u2022 Random. Timestamps for attack are randomly selected, and the trigger is generated from a uniform distribution ranging from $\u2013 \\Delta_{TGR}$ to $\\Delta_{TGR}$. This trigger is repeatedly used at each selected timestamp.\n\u2022 Inverse. This attack method flips the dataset along the temporal dimension and further trains a forecasting model that forecasts the history based on future data. By using the target pattern as input, the outputs of the prediction model are chosen as the trigger. In experiments,"}, {"title": "D Description of Triggers and Target Patterns", "content": "FEDformer [68] is used as the forecasting model. Please note that, for this attack method, the amplitude of generated triggers may exceed the trigger constraints, i.e., $\\Delta_{TGR}$.\n\u2022 Manhattan. This attack method locates time segments in the training set with the smallest Manhattan distance to the target pattern and uses the preceding time series data of those segments as triggers. Please note that, for this attack method, the amplitude of generated triggers may exceed the trigger constraints, i.e., $\\Delta_{TGR}$.\nIn Section 3.2.1, we implement a simple and weak backdoor attack for identifying the properties of timestamps that are more vulnerable to attack. As for the setting of this backdoor attack, we use a shape-fixed trigger, whose data are listed in Table 7, and a cone-shaped target pattern, whose data are shown in Figure 4. For each timestamp group, we will inject this trigger and target pattern into every timestamp within the group, thus poisoning 10% timestamps in the training set. The experimental results show that timestamps where a clean model performs poorly are more susceptible to backdoor attacks.\nIn Section 4, we validate the effectiveness of BACKTIME on three different shapes of the target patterns. These target patterns will be inserted into datasets with data standardization, and the specific shapes of the three target patterns are shown in Figure 4. The endpoints of the three target patterns are equal to, higher than, or lower than their starting points, respectively. Intuitively, flipping the target patterns vertically should yield similar effects. Therefore, this paper focuses on target patterns that exhibit an upward trend after the starting point. Under these three target patterns, this paper demonstrates that BackTime can effectively attack various target patterns in MTS forecasting."}, {"title": "E Main Experiment Results", "content": "The full results for BACKTIME and baselines with the cone-shaped target pattern are provided in Table 8. From the results, we can observe that BACKTIME can continuously decrease MAEA to a low degree under any model architecture and any dataset. On PEMS03, PEMS04, and Weather datasets, BACKTIME surpass all the attack baselines, achieving the lowest MAEA across all the model architectures. It strongly demonstrates the effectiveness and versatility of BACKTIME."}]}