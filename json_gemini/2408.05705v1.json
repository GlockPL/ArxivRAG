{"title": "TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling", "authors": ["Ruiquan Ge", "Xiao Yu", "Yifei Chen", "Fan Jia", "Shenghao Zhu", "Guanyu Zhou", "Yiyu Huang", "Chenyan Zhang", "Dong Zeng", "Changmiao Wang", "Qiegen Liu", "Shanzhou Niu"], "abstract": "Magnetic Resonance Imaging (MRI) has become essential in clinical diagnosis due to its high resolution and multiple contrast mechanisms. However, the relatively long acquisition time limits its broader application. To address this issue, this study presents an innovative conditional guided diffusion model, named as TC-KANRecon, which incorporates the Multi-Free U-KAN (MF-UKAN) module and a dynamic clipping strategy. TC-KANRecon model aims to accelerate the MRI reconstruction process through deep learning methods while maintaining the quality of the reconstructed images. The MF-UKAN module can effectively balance the tradeoff between image denoising and structure preservation. Specifically, it presents the multi-head attention mechanisms and scalar modulation factors, which significantly enhances the model's robustness and structure preservation capabilities in complex noise environments. Moreover, the dynamic clipping strategy in TC-KANRecon adjusts the cropping interval according to the sampling steps, thereby mitigating image detail loss typically caused by traditional cropping methods and enriching the visual features of the images. Furthermore, the MC-Model module incorporates full-sampling k-space information, realizing efficient fusion of conditional information, enhancing the model's ability to process complex data, and improving the realism and detail richness of reconstructed images. Experimental results demonstrate that the proposed method outperforms other MRI reconstruction methods in both qualitative and quantitative evaluations. Notably, TC-KANRecon method exhibits excellent reconstruction results when processing high-noise, low-sampling-rate MRI data. Our source code is available at https://github.com/lcbkmm/TC-KANRecon.", "sections": [{"title": "I. INTRODUCTION", "content": "Magnetic Resonance Imaging (MRI) is a crucial medical imaging technology for clinical diagnosis and research due to its high resolution and multiple contrast mechanisms. MRI provides precise anatomical and functional information, making it essential for diagnosing neurological diseases, cardiovascular conditions, and cancer. Compared with other imaging modalities, MRI is radiation-free and offers high soft tissue contrast, leading to its widespread use in neuroimaging, cardiac imaging, and oncology [1]. Despite its advantages, MRI faces significant challenges, particularly its long acquisition time. Time-consuming scan may increase patient discomfort and limit the efficiency of equipment usage. Prolonged scan times often result in motion artifacts that degrade image quality, especially in elderly and pediatric patients who struggle to remain still for extended periods. Additionally, longer scan times escalate medical costs and reduce the equipment's turnover efficiency [2]. To address these issues, researchers have developed various methods to accelerate MRI acquisition and reconstruction. The goal is to shorten scan times while maintaining high image quality, thereby improving patient comfort and optimizing the use of MRI technology.\nThe traditional MRI acquisition process is slow primarily due to the need to comprehensively sample k-space data, which represents the frequency domain of MR images. The final image is obtained by performing an inverse Fourier transform on k-space data. To acquire high-quality images, comprehensive sampling of the entire k-space is typically required, thus extending scan times. This prolonged acquisition period places a burden on patients and increases the likelihood of motion artifacts, which can reduce diagnostic accuracy. To mitigate this issue, undersampling k-space data has become a common technique to accelerate MRI acquisition. This method involves undersampling the k-space signal and using reconstruction algorithms to recover the signal [3]. Generally, the problem is formulated as follows:\n$Yrecon = arg min \\|\\| MFy \u2212 Xobs \\|\\|_2^2 + \u03bbR(y)$,\ns.t. $Xobs = Mxfull$,\nwhere $xfull$ and $Xobs$ denote the fully-sampled and undersampled k-space signal, respectively, M represents the undersampling mask, and F is the Fourier operator. The goal is to find a MR image y such that its k-space content MFy aligns with $Xobs$, often referred to as the data consistency term. Furthermore, $Yrecon$ should adhere to certain prior knowledge about MR images, as expressed by the regularization term R(\u00b7), which is subject to numerous innovations.\nAlthough undersampling reduces the amount of acquired data and shortens scan times, it violates the Nyquist-Shannon sampling theorem, potentially introducing aliasing artifacts. To address this, researchers have proposed Compressed Sensing (CS) technology [4] to mitigate aliasing artifacts caused by undersampling. CS formulates image reconstruction as an optimization problem, incorporating assumptions of sparsity and incoherence. However, the complexity and limitations of CS have hindered its widespread application due to the need for multiple iterative computations and substantial computational resources. Additionally, the effectiveness of CS methods heavily relies on empirical hyperparameter selection, necessitating individualized adjustments under different scanning conditions, a time-consuming and laborintensive process [5]. To further improve MRI acceleration capabilities, researchers have explored various methods such as low-rank constraints [6], adaptive sparse modeling [7], and parallel imaging techniques [8]. These methods enhance image reconstruction quality and speed through diverse technical approaches but still face challenges with aliasing artifacts at high acceleration factors [9]. Parallel imaging techniques, which use multiple receiver coils to simultaneously acquire signals, can enhance acquisition speed and image quality. However, their effectiveness depends on coil configuration and imaging parameter selection, requiring experienced operators for tuning.\nIn recent years, the application of artificial intelligence technology in the field of MRI has infused new vitality into MRI acceleration and reconstruction techniques. Through training, deep learning models are capable of reconstructing high-quality images from undersampled k-space data, drastically simplifying the complex parameter tuning processes of traditional methods. Their efficient computational capabilities further drastically reduce image reconstruction time, enhancing the efficiency of medical services. However, despite breakthroughs in existing deep learning technologies such as diffusion models, challenges persist. Noise sensitivity is particularly problematic, as device noise, patient movement, and other factors in MRI data can easily interfere with image quality, leading models to mistakenly learn noise, resulting in artifacts or blurred images that compromise diagnostic accuracy. Additionally, inadequate preservation of structural information poses a significant challenge. The fine anatomical structures in MR images are crucial for disease diagnosis, yet existing methods often struggle to retain these details while achieving rapid reconstruction. Furthermore, the lack of robustness in deep learning models limits their clinical application. The significant variations in MRI data among different patients, scanning protocols, and devices require models to possess strong generalization capabilities. However, current models are often trained on specific datasets, and their adaptability to new environments needs improvement. To address these challenges, we innovatively propose the MF-UKAN (Multi-Feature U-KAN) module and its complementary dynamic cropping strategy, significantly enhancing the precision, efficiency, and flexibility of diffusion models in MR image reconstruction tasks. Our method offers several key contributions and advantages:\n1) To balance denoising and structural information preservation, we designed the MF-UKAN module. This design incorporates multi-head attention mechanisms and scalar modulation factors for fine-grained control over backbone and skip features, enhancing the robustness of model in complex noise environments and improving the preservation of structural information in reconstructed images.\n2) We introduced an innovative dynamic clipping strategy to address the limitations of traditional cropping methods, which restrict image diversity. Our strategy dynamically adjusts cropping interval boundaries based on sampling steps, effectively mitigating image detail loss and resulting in images with richer visual features and reasonable brightness distribution.\n3) We combined the fully sampled k-space information with MRI data in the MC-Model module and processed it using the encoder stage of the MF-UKAN module. This approach enhances the model's ability to handle complex data and facilitates targeted MR images generation, improving the realism and detail richness of reconstructed images.\n4) We conducted extensive comparative experiments on two public datasets, and the results indicated that our method surpassed other state-of-the-art MRI reconstruction methods. Specifically, it demonstrates superior performance and faster inference speed when processing high-noise, low-sampling-rate MRI data. Ablation experiments further validated the critical role of each module in the TC-KANRecon model, proving the effectiveness and necessity of its design."}, {"title": "II. RELATED WORK", "content": "With the rapid advancement of deep learning, models leveraging this technology have become increasingly prominent in MRI reconstruction, demonstrating exceptional performance. Early approaches [10] utilized single feedforward Convolutional Neural Networks (CNNs), such as SRCNN [11] and U-net [12], to map undersampled k-space data to fully sampled images in an end-to-end manner. More sophisticated models have since emerged, adopting iterative architectures that break down the reconstruction process into several learnable optimization stages. For instance, Sun et al. [13] introduced ADMM-Net for MRI reconstruction, which represents each stage as an iteration of the Alternating Direction Method of Multipliers (ADMM) algorithm [14]. Similarly, rsGAN [15] employs conditional generative adversarial networks for the joint recovery of undersampled multi-contrast acquisitions. To emulate iterative dictionary learning methods, Schlemper et al. [16] and Dar et al. [17] proposed deep cascaded CNN architectures, which perform convolution operations in image space through multiple residual learning blocks, Zeng et al. [18] applied CNN in MRI reconstruction. Qin et al. [19] further advanced this concept by introducing a Convolutional Recurrent Neural Network (CRNN) architecture that leverages time-series dependencies and iterative optimization benefits. Subsequent improvements to CRNN designs by Wang et al. [20], Chen et al. [21], and Guo et al. [22] incorporated recursive pyramid layers, neural ODEs, and overcomplete network architectures in the hope of further enhancing reconstruction quality through the above strategies.\nGenerative Adversarial Networks (GANs) have shown promise in this field due to their ability to learn data distributions more rapidly than traditional CNN models. Mardani et al. [23] combined deep GAN and CS to reduce high-frequency noise and enhance zero-filled MR images. Quan et al. [24] developed a dual-bench generator using cyclic data consistency loss and generative adversarial loss for accurate reconstruction of undersampled data. Li et al. [25] proposed SEGAN, which employs patch correlation regularization to recover structural information both locally and globally. Murugesan et al. [26] introduced Recon-GLGAN, a framework that combines global and local context information through a generator and a context discriminator. Shaul et al. [27] developed a software-based GAN framework to estimate missing k-space samples, accelerating brain MRI acquisition.\nDespite the ability of GAN-based methods to generate realistic image samples, their limited representational diversity can hinder reconstruction performance. Recent developments in diffusion models have shown potential to address this issue. These models transform Gaussian noise into image samples through a multi-step process, directly characterizing data distribution correlations. By combining learned priors with imaging operators during inference, diffusion models enable repeated projection reconstruction. For instance, Jalal et al. [28] and Luo et al. [29] proposed using score functions and Langevin dynamics for sampling. Chung et al. [30] and Song et al. [31] employed predictors to solve stochastic differential equations. Peng et al. [32] introduced DiffuseRecon, a diffusion model-based MRI reconstruction method that does not require additional training for specific acceleration factors. Cao et al. [33] proposed a complex diffusion probabilistic model that better preserves the complex-valued information of MRI data. Gungor et al. [34] developed Adaptive Diffusion Priors, such as AdaDiff, to enhance reconstruction performance during inference. Cao et al. [35] also designed a high-frequency DDPM model to retain high-frequency information in MRI data. However, these diffusion-based methods have not fully addressed the inherent limitations of the U-net architecture used in diffusion models, resulting in overly smooth images and suboptimal imaging quality."}, {"title": "III. METHODOLOGY", "content": "Recently, Liu et al. [36] introduced KANs as a novel alternative to MLPs. While MLPs are effective in modeling complex function mappings and addressing various problems through their multilayer, nonlinear transformations, they have inherent limitations, especially in MRI reconstruction tasks. In such tasks, high-quality images are often recovered from limited and potentially noisy k-space data. MLPs face challenges such as high computational complexity and limited interpretability when handling high-dimensional data. These limitations hinder adequate feature learning, preventing MLPs from capturing detailed features, thus impacting the quality of the reconstructed images. KANs are based on the Kolmogorov-Arnold representation theorem [37]. Unlike MLPs, which use fixed activation functions at neurons and then perform summation for nonlinear activation, KANs deploy learnable activation mechanisms on the connection weights, which are edges, followed by summation. This innovative approach enhances the network's learning capabilities and promotes more flexible feature extraction. A k-layer KAN is formed by nesting multiple KAN layers, mathematically expressed as:\n$\u039a\u0391\u039d(Z) = (\u03a6k\u22121 \u25e6 \u03a6k\u22122 \u25e6 ... \u25e6 \u03a61 \u25e6 \u03a60)Z$,\nwhere i denotes the i-th layer of the KAN network. Each KAN layer has $n_{in}$ dimensional inputs and $n_{out}$ dimensional outputs. The mapping is represented by the set {$\\phi_{q,p}$}, where p ranges from 1 to $n_{in}$ and q ranges from 1 to $n_{out}$. Notably, $\\phi$ incorporates the learnable activation function $\\phi$ for the $n_{in} \\times n_{out}$ dimensional transformation.\nThe computational results of the KAN network from the k-th layer to the k + 1-th layer can be expressed through a matrix representation as follows:\n$Zk+1 = \\begin{pmatrix}\n\\phi_{k,1,1}(\u00b7) & \\phi_{k,1,2}(\u00b7) & \u00b7\u00b7\u00b7 & \\phi_{k,1,nk} (\u00b7)\\\\\n\\phi_{k,2,1}(\u00b7) & \\phi_{k,2,2}(\u00b7) & \u00b7\u00b7\u00b7 & \\phi_{k,2,nk} (\u00b7)\\\\\n: & : & & :\\\\\n\\phi_{k,nk+1,1}(\u00b7) & \\phi_{k,nk+1,2}(\u00b7) & \u00b7\u00b7\u00b7 & \\phi_{k,nk+1,nk} (\u00b7)\\\\\n\\end{pmatrix}Zk$\nInspired by Li et al. [38], we substitute the U-net architecture in stable diffusion [39] with a U-KAN network. The Tok-KAN module consists of a tokenization layer, a KAN layer, and a Batch Normalization (BN) layer. The structure of the Tok-KAN module is depicted in Fig. 1.\nIn Tok-KAN, the output feature $X_L \\in R^{H_L \\times W_L \\times C_L}$ from the convolutional stage is reshaped into a flattened 2D sequence of blocks for tokenization as:\n$X_i \\in R^{P^2.C_L}  \\vert i = 1, ..., N$,\nwhere the size of each block is $P \\times P$ and the number of feature blocks is $N = (H_L X W_L), L = 3$. The vectorized block $P^2$.\n$Z_0 = [X_1^T E; X_2^T E; \u2026 ; X_N^T E]$\nThe token sequences are then processed through three KAN layers. Each KAN layer is immediately followed by a BN layer and a ReLU activation function to normalize the data distribution and introduce nonlinear features. Subsequently, Layer Normalization (LN) is applied, and the processed features are passed to the subsequent blocks. The output of the k-th Tok-KAN block is expressed as:\n$Z_k = LN(KAN(Z_{k\u22121})) + F(TE(t))$,\nwhere $Z_k \\in R^{H_k \\times W_k \\times D_k}$ is the output feature map of the k-th layer, Fis a linear projection, and TE(t) denotes the temporal embedding for a given time step.\nThe U-KAN, characterized by its U-net-like structure, facilitates the denoising process through the backbone path and transmits high-frequency detailed features to the decoder part with the help of skip connections. However, this design can overemphasize high-frequency information, potentially weakening the backbone network's ability to capture essential semantic features for denoising. To address this, we propose an improved U-KAN module, MF-UKAN, which introduces a multi-attention mechanism and two critical scalar modulation factors. The backbone feature scaling factor (br) aims to enhance the expressive power of the backbone feature map\n$\u03b1_\u03b9 = (b_r \u2212 1) \\cdot \\frac{X_\u03b9 \u2212 Min(x_\u03b9)}{Max(x_\u03b9) \u2212 Min(x_\u03b9)} + 1, \u03b9 = \\frac{1}{C} \\sum_{i=1}^{C} X_{l,i}$,\nwhere $x_{l,i}$ denotes the i-th channel of the feature mapping $x_l$, C denotes the total number of channels, $\u03b1_l$ is the backbone factor, and $b_r$ is a scalar constant.\nTo balance denoising and preserving high-frequency details, we selectively apply the scaling operation to half of the channels of the feature mapping $x_l$:\n$X_{l,i} = \\begin{cases} X_{l,i} \\cdot \u03b1_\u03b9, & \\text{if } i < \\frac{C}{2};\\\\ X_{l,i}, & \\text{otherwise}. \\end{cases}$\nFor $s_t$, we employ spectral modulation in the Fourier domain to reduce the low-frequency components of the skip features and thus amplify the high-frequency features:\n$F(h_{l,i}) = FFT(h_{l,i})$,\n$F'(h_{l,i}) = F(h_{l,i}) \u2299 \u03b2_{l,i}$,\n$h'_{l,i} = IFFT(F' (h_{l,i}))$,\n$\\alpha_{l,i}(r) = \\begin{cases} s_t, & \\text{if } r < r_{thresh};\\\\ 1, & \\text{otherwise}, \\end{cases}$\nwhere FFT and IFFT are the Fourier transform and inverse Fourier transform, respectively. Pixel-level multiplication is denoted by $\\odot$, and $B_{l,i}$ is a Fourier mask designed based on the size of the Fourier coefficients, implementing the frequency-dependent scale factor $s_t$. The radius is represented as r, while $r_{thresh}$ indicates the threshold frequency. Finally, we combine the enhanced skip feature map with the finely tuned backbone feature map to serve as inputs for subsequent layers in the U-net architecture."}, {"title": "B. MC-Model", "content": "To enhance the directional generation of MR images, we use fully sampled k-space information as a conditional guide. Initially, we apply an inverse Fourier transform to the fully sampled k-space data, denoted as $X_{obs}$, and subsequently fuse it with the MR images through concatenation. This process is represented by Eq.(10):\n$X = IFFT(X_{obs}) \\oplus X$,\nwhere IFFT denotes the inverse Fourier transform, $\\oplus$ signifies concatenation, and X represents the conditional information post-concatenation. Noise is then added to X to obtain $X'$.\nTo maintain consistency with the diffusion backbone's input, which is potential space, we compress $X'$ using an additional convolution module. This module employs a kernel size of 3, a step size of 1, and a padding of 1. The compression process involves an initial convolutional layer, followed by a ReLU activation function and a group normalization layer. This sequence is executed three times to produce a feature map with the same shape as the diffusion backbone, which is then passed to subsequent modules. The final feature vector Z is described by Eq.(11):\n$Z = Conv(X')$,\nwhere Conv(\u00b7) denotes the convolution operation. Unlike alternative approaches that utilize cross-attention, tandem, or CLIP image encoders to extract and transmit high-level semantic information from images, we employ the encoder stage of MF-UKAN. This stage consists of three downsampling blocks and two Tok-KAN modules, as illustrated in Fig. 1. Each convolution block comprises a convolutional layer, a batch normalization layer, and a ReLU activation function, with a kernel size of 3, a step size of 1, and a padding of 1.\nThis module processes the fully sampled k-space information and the Fourier-transformed MR images information. It then transmits the resulting latent representations through the downsampled blocks and intermediate blocks, meticulously recording all intermediate feature mappings. Finally, these recorded feature mappings are introduced into the upsampled segment of the diffusion backbone."}, {"title": "C. Dynamic Clipping Strategy", "content": "The clipping threshold is crucial in balancing image quality and diversity during the generation process. A higher clipping threshold retains more predictive noise and variations, resulting in diverse styles and details in the generated images, but it may also introduce unwanted noise or blurriness, affecting the overall image quality. Conversely, a lower clipping threshold reduces noise, producing clearer and more stable images, but excessive restriction can lead to a lack of detail and diversity, making the images appear overly smooth. Therefore, selecting an appropriate clipping threshold is essential to achieve an optimal balance between image quality and diversity.\nRecently, Chen et al. [40] proposed an innovative dynamic clipping strategy to replace the conventional fixed clipping approach, which strictly confines the predicted variable x within the interval [-1,1]. This new strategy involves dynamically adjusting the clipping interval boundaries based on the current sampling step t, defining a varying interval [-s, s], where s evolves with the sampling process. They formulated a linear model as shown in Eq.(12):\ns=w.t+b.\nThis strategy allows for flexible adjustment of the clipping threshold according to the model's training progress and the stage of image generation. It provides greater freedom during the initial stages of image structure formation, resulting in richer visual features. However, during the early stages of diffusion model sampling, when the model generates blurry, low-resolution initial image structures from pure noise, a larger clipping threshold is needed to increase freedom and reduce information loss, aiding in capturing overall shapes. As sampling progresses and image resolution and details increase, the clipping threshold should gradually decrease to limit noise and enhance image finesse and quality. Consequently, we have refined the linear model to Eq.(13):\ns=w.t+b.\nThis revised model allows the clipping threshold s to linearly decrease as the sampling step t increases. This dynamic clipping strategy preserves image diversity during the initial stages of diffusion model sampling and retains image details and precision as sampling deepens. Consequently, it produces images that better align with real-world counterparts, as illustrated in Fig. 2."}, {"title": "IV. EXPERIMENT", "content": "The performance of the TC-KANRecon algorithm was evaluated using the fastMRI [41] and SKM-TEA [42] datasets. The fastMRI dataset includes raw k-space data and DICOM images of knee, brain, prostate, and chest scans, accompanied by masked test sets. This dataset is specifically designed to facilitate MRI reconstruction and aims to accelerate the generation of MR images using artificial intelligence techniques. For this study, we generated the undersampled mask M using the mask function provided in the fastMRI challenge. We concentrated on the single-coil knee dataset, which contains data from 1,172 subjects, each with approximately 35 slices. From this dataset, we used data from 973 subjects, about 34,055 slices, for training and data from 199 subjects, about 6,965 slices, for evaluation.\nThe SKM-TEA dataset comprises DICOM images from 155 patients scanned using two Tesla 3T GE MR750 scanners."}, {"title": "D. Comparison Experiments", "content": "As shown in Tables I and II, we conducted comparative experiments with other state-of-the-art models for MRI reconstruction on the fastMRI and SKM-TEA datasets to validate the efficacy of the TC-KANRecon model. The experimental results indicate that the TC-KANRecon model significantly outperforms its counterparts in terms of PSNR, SSIM, and NMSE metrics.\nThe innovative network structure and diversified feature processing strategies of the TC-KANRecon model enhance its adaptability and robustness in MRI reconstruction tasks. Consequently, it surpasses existing models in all evaluated metrics, demonstrating its superior performance. The comparative results with other state-of-the-art models, specifically for an Acceleration Factor (AF) of 4, are illustrated in Fig. 3.\nGiven the consistent results across different single-coil datasets and various acceleration factors, we focus our detailed analysis on the reconstruction performance of the model using the fastMRI dataset with AF=4, both in comparison and ablation experiments.\nCompared to the U-net model, although U-net performs well in many image processing tasks, it struggles with capturing high-frequency details and dealing with noise in MR images due to its encoder-decoder structure, which can result in the loss of detail during feature extraction. For instance, the PSNR of the U-net model is 27.68, while the TC-KANRecon model achieves 30.50. Similarly, the SSIM for U-net is 0.631, significantly lower than TC-KANRecon's 0.817. In terms of NMSE, U-net scores 0.0295, whereas TC-KANRecon registers a lower 0.0211. The TC-KANRecon model, incorporating the MF Model, optimizes the balance of skip connections and main features, substantially enhancing reconstruction accuracy.\nCompared to the KIKI-net model, which struggles with high-frequency detail processing and denoising due to its lack of effective strategies for capturing fine details and suppressing noise, the TC-KANRecon model demonstrates superior performance. The innovative texture coordination strategy and multi-attention mechanism of TC-KANRecon enhance detail restoration helping the model excel in restoring high-frequency details and effectively managing noise, significantly improving overall image quality. Specifically, when compared with KIKI-net, TC-KANRecon increases the PSNR from 27.01 to 30.50 and the SSIM from 0.613 to 0.817. In terms of NMSE metrics, KIKI-net scores 0.0354, while TC-DiffRecon achieves a lower value of 0.0211.\nCompared to the D5C5 model, which shows some advantages in MRI reconstruction, D5C5's static feature extraction methods result in partial detail loss, affecting detail restoration and overall image quality. The PSNR for D5C5 is 27.74, while TC-KANRecon achieves 30.50. The SSIM for D5C5 is 0.632, lower than TC-KANRecon's 0.817. NMSE metrics for U-net are 0.0289, while TC-KANRecon scores 0.0211. TC-KANRecon, with its multi-attention mechanism and dynamic clipping strategy, significantly outperforms D5C5 in reducing details and overall image quality, demonstrating superior image detail restoration capability.\nCompared to the ReconFormer model, which excels in capturing long-range dependencies using a Transformer structure, TC-KANRecon demonstrates improved performance in handling complex details of MR images. While ReconFormer effectively captures global information, it often overlooks local detail features, leading to suboptimal performance. In contrast, TC-KANRecon combines the MF Model and the Tok-KAN module to enhance feature extraction and model interpretability. This results in superior performance in metrics such as PSNR and SSIM. Specifically, TC-KANRecon achieves a PSNR of 30.50, compared to ReconFormer's 28.62. Additionally, the SSIM for TC-KANRecon reaches 0.817, while ReconFormer attains 0.643. Regarding NMSE metrics, ReconFormer scores 0.0263, whereas TC-KANRecon achieves a lower value of 0.0211.\nCompared to the DiffuseRecon model, which achieves better reconstruction through the diffusion model, TC-KANRecon proves superior in handling complex textures. DiffuseRecon is prone to artifacts that lead to texture inconsistency and detail loss. For instance, the NMSE of DiffuseRecon is 0.0272, whereas TC-KANRecon achieves a lower NMSE of 0.0211, indicating higher image quality. The TC-KANRecon model combines a multi-attention mechanism with adaptive feature adjustment strategies, enhancing feature extraction and interpretability. This allows it to excel in capturing complex pathological features and restoring details. In contrast, the TC-DiffRecon model, although it addresses issues like image fragmentation caused by over-smoothing and improves overall image quality and consistency, still struggles with high-frequency details and complex textures. TC-KANRecon significantly improves the ability to capture complex pathological features and overall image reconstruction quality through its innovative Tok-KAN module and dynamic clipping strategy. Specifically, TC-KANRecon improves PSNR by 0.72 and SSIM by 0.076 on the STM-TEA dataset. DiffuseRecon's NMSE is 0.0272, while TC-DiffRecon's is 0.0247. In summary, TC-KANRecon excels in reproducing image details and handling complex textures, demonstrating higher robustness and stability. It maintains excellent performance across different acceleration factors, outperforming other models in various key metrics."}, {"title": "E. Validation of Model Generalizability", "content": "To further validate the broad applicability of our proposed TC-KANRecon model, we conducted a detailed comparison of its generalizability against several typical reconstruction models using two public datasets: fastMRI and SKM-TEA. As illustrated in Table III, we trained our model with AF of 6x and 8x, and used undersampled images with acceleration factors of 10x and 4x as inputs. The results demonstrate that, in contrast to models optimized for a specific AF, TC-KANRecon shows significant performance advantages, thereby proving its robust versatility. Furthermore, when compared with diffusion-based models known for their extensive applicability, our model achieved the highest quality reconstruction outcomes. This underscores TC-KANRecon's superior performance in handling a range of undersampling scenarios."}, {"title": "F. Ablation Experiments", "content": "We conducted ablation experiments to evaluate the impact of the MF Model, Tok-KAN module, and dynamic clipping strategy on the TC-KANRecon model's performance using the fastMRI and SKM-TEA datasets, as shown in Tables IV and V. We compared the performance metrics, PSNR, SSIM, and NMSE, of the complete TC-KANRecon model with versions from which each component was individually removed. The results reveal that removing any of these modules significantly degrades the model's reconstruction performance, underscoring their essential roles in the overall effectiveness of our model. Consequently, the TC-KANRecon model demonstrates enhanced adaptability and robustness in MRI reconstruction tasks, attributed to its innovative network structures and diverse feature processing strategies.\n1) Impact after removing the MF Model: The MF Model significantly enhances the model's ability to extract features and reduce noise by utilizing a multi-head attention mechanism and feature scaling strategy. When this module is removed, the model's performance deteriorates markedly in both high-frequency detail restoration and noise reduction. Specifically, this decline is evident in the substantial decrease in PSNR values from 30.50 to 28.67 and SSIM values from 0.817 to 0.674. Additionally, NMSE increases from 0.0211 to 0.0287. All these results underscore the critical role of the MF Model for the overall model in optimizing feature representation and the denoising effect.\n2) Impact after removing the Tok-KAN module: The Tok-KAN module enhances the flexibility of feature extraction and representation by applying the Kolmogorov-Arnold expression theorem, which significantly boosts the model's image reconstruction quality. When this module is removed, the model's capacity to capture complex pathological features and detailed information is diminished. This reduction is reflected in the significant drop in SSIM values from 0.817 to 0.642 and the increase in NMSE from 0.0211 to 0.0326. These changes highlight the essential role of the Tok-KAN module in improving feature extraction flexibility and overall image reconstruction quality.\n3) Impact after removing the Dynamic Clipping Strategy: The dynamic clipping strategy enhances image diversity and quality while maintaining numerical stability by adjusting the boundaries of the cropping interval during the sampling step. When this strategy is removed, the model exhibits erratic performance in handling various sampling steps, resulting in reduced image reconstruction quality. This decline is evidenced by a decrease in PSNR from 30.50 to 29.86, a drop in SSIM from 0.817 to 0.754, and an increase in NMSE from 0.0211 to 0.0266. These results underscore the critical importance of the dynamic clipping strategy in improving image quality and maintaining the model's stability."}, {"title": "V. CONCLUSION", "content": "Given the existing challenges in MR images analysis, particularly in the efficient processing and accurate reconstruction of knee MRI datasets, this paper presents an innovative deep learning architecture: TC-KANRecon. This architecture addresses the limitations of traditional MRI reconstruction models, such as inadequate feature extraction and poor robustness. The TC-KANRecon framework incorporates multi-head attention mechanisms and scalar modulation factors to finely control backbone and skip features, effectively balancing denoising needs while preserving structural information. This enhances the model's robustness and retention of structure in complex noise environments. Additionally, the MC-Model module within the TC-KANRecon framework integrates fully sampled k-space information with MRI data, further improving the realism and richness of reconstructed images. The proposed dynamic clipping strategy adjusts the cropping interval based on sampling steps, mitigating image detail loss caused by traditional cropping methods and enriching the visual features of reconstructed images.\nTo validate the effectiveness of the TC-KANRecon model, this study employs two large-scale knee MRI datasets: fastMRI, comprising 1,172 subjects and over 41,020 slice data, and the SKM-TEA dataset, containing 155 subjects and over 24,800 slice data. The datasets were rigorously split into training and evaluation sets to ensure the objectivity and reliability of the experimental results. The findings demonstrate that the TC-KANRecon model outperforms existing methods in reconstructed image quality, achieving an optimal balance between denoising and detail preservation. In addition, we also further confirmed the critical role of each component in the overall performance of the model through ablation experiments, particularly highlighting the significant contributions of multi-head attention mechanisms and scalar modulation factors in enhancing feature extraction and denoising capabilities.\nThe TC-KANRecon model provides a novel approach for efficiently processing and accurately reconstructing MR images. Despite these significant advancements, there are still some limitations and areas for improvement. One major challenge is the model's reliance on large-scale datasets for training, which can be problematic in situations where such extensive data is unavailable. Future work will explore techniques such as data augmentation, transfer learning, and synthetic data generation to mitigate this issue. Another important consideration is the computational efficiency of the TC-KANRecon model. As deep learning models grow increasingly complex, it becomes crucial to ensure they can be deployed in real-time clinical environments without significant delays. Future research will focus on optimizing the model architecture to accelerate inference time while maintaining high reconstruction quality."}]}