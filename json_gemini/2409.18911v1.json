{"title": "Soft Measures for Extracting Causal Collective Intelligence", "authors": ["Maryam Berijanian", "Spencer Dork", "Kuldeep Singh", "Michael Riley Millikan", "Ashlin Riggs", "Aadarsh Swaminathan", "Sarah L. Gibbs", "Scott E. Friedman", "Nathan Brugnone"], "abstract": "Understanding and modeling collective intelligence is essential for addressing complex social systems. Directed graphs called fuzzy cognitive maps (FCMs) offer a powerful tool for encoding causal mental models, but extracting high-integrity FCMs from text is challenging. This study presents an approach using large language models (LLMs) to automate FCM extraction. We introduce novel graph-based similarity measures and evaluate them by correlating their outputs with human judgments through the Elo rating system. Results show positive correlations with human evaluations, but even the best-performing measure exhibits limitations in capturing FCM nuances. Fine-tuning LLMs improves performance, but existing measures still fall short. This study highlights the need for soft similarity measures tailored to FCM extraction, advancing collective intelligence modeling with NLP.", "sections": [{"title": "1 Introduction", "content": "Social science has long sought to understand and model the collective intelligence underlying humanity's most pressing problems such as climate change, sustainable food supply, and violent conflict driven by inequitable resource distribution. These are social-ecological systems (SES) problems characterized by complex, interwoven feedback loops involving human and natural systems (Ostrom, 2009; Partelow, 2018). To model collective intelligence about SES, we can leverage mental models of causal system structure.\nResearchers in the social sciences have formally encoded SES mental models using fuzzy cognitive maps (FCMs) that represent causal systems as signed, weighted digraphs, where edges represent causal relationships among natural language concepts (Kosko, 1986) like that depicted in Figure 1. FCMs are inspired by human causal mental models that people use to explain causal mechanisms and generate predictions (Craik, 1967).\nFCMs have been widely used to facilitate cross-disciplinary communication within research teams (Gray et al., 2013), make qualitative and numerical predictions, and assess collective intelligence (Gray et al., 2020; Aminpour et al., 2020; Voinov et al., 2018). However, little work has explored extracting high-integrity FCMs from textual corpora. The development of a robust text-to-FCM method would enable more rapid synthesis of science- and stakeholder-informed perspectives to provide access to latent collective intelligence about SES.\nThis work presents a natural language processing (NLP) approach to (1) extracting FCMs from text with large language models (LLMs) and (2) measuring extracted FCM quality with novel soft F1 measures that permit approximate semantic matches rather than requiring exact node and edge matches. This helps capture and accumulate diverse causal collective intelligence of SES domains. We provide code and datasets for reproducibility."}, {"title": "2 Background and Objectives", "content": "Extracting FCM edges is a specialization of extracting semantic relations or causal graphs: each node is a textual span describing causal factors, and each edge is a directed causal increase or decrease relationship where the source of the edge quantitatively increases or decreases the target. Two issues distinguish FCM extraction from previous graph-based extraction tasks: (1) high expressiveness and (2) partial correctness. We describe these two issues briefly to motivate our approach.\nHigh expressiveness. Causal variables (i.e., FCM nodes) and relations may be expressed multiple ways, so human annotators may disagree and a machine prediction may actually outperform a pre-determined human-generated gold standard according to human judges. Many graph extraction approaches are validated by their proximity to a singular gold standard generated by human experts, where small deviations from the standard greatly affect the measure. This includes neural network loss functions. Some relaxed matching strategies help account for textual containment or overlap (Chen et al., 2019; Toba et al., 2010), but these have not been adequately extended to graph extraction.\nPartial correctness. A sub-optimal node or edge that captures a valid causal relationship is often useful to report as a component of an FCM\u2014especially in data-poor contexts, as even limited information can improve the understanding of a given system\u2014so an NLP model's capability to produce partially correct edges is important to capture (Table 1). Consequently, binary judgments of correctness\u2014such as precision, recall, and F1 scores\u2014are sub-optimal measures for our task. Decades of research has produced numerical measures to score the similarity (or distance) between spans of text to avoid the need for absolute correctness (Mihalcea et al., 2006; B\u00e4r et al., 2012; Lavie and Denkowski, 2009), but development of textual similarity measures for graphs, and FCMs in particular, has been limited (Pilehvar and Navigli, 2015).\nThis paper (1) assesses fine-tuned LLM-based methods to extract FCMs from text and (2) introduces and evaluates edge-based similarity measures for validating FCM quality, addressing the limitations of previous measures. Additionally, it (3) initiates an approach for validating graph-based NLP predictions by (a) ranking predictions through pairwise comparative human judgments using Elo and (b) comparing the rankings produced by humans and similarity measures. This proof-of-concept study suggests a methodology by which to improve the qualitative evaluation of NLP-generated FCMs en masse and, thereby, takes a step towards improved collective intelligence models."}, {"title": "3 Methods and Data", "content": "We curated a dataset of 318 short text passages extracted from a diverse set of research articles on SES. These articles cover a wide range of SES topics including offshore wind farm development, the impact of banditry on the food system in northern Nigeria, the distribution of food and medical aid in conflict regions, and maternal and child health in countries with low Human Development Index scores. We annotated each text passage with (source, target, direction) tuples."}, {"title": "3.2 Annotation Ranking", "content": "To rank annotations for each text passage, we (1) generated multiple annotations for each of a subset of passages, (2) presented pairs of annotations to raters, and (3) applied the Elo rating system."}, {"title": "3.2.1 Annotation Generation", "content": "Each of a subset of 20 passages were manually annotated with (source, target, direction) tuples by all authors. This subset was further augmented with LLM annotations. This was achieved through two distinct methods: few-shot learning and instruction tuning with LoRA (Wei et al., 2021; Hu et al., 2021). We employed the Llama-2-7B-chat-hf (Touvron et al., 2023a,b), Llama-3-8B-Instruct (Meta AI, 2024), and Mistral-7B-Instruct-v0.2 (Jiang et al., 2023) models from Hugging Face (Hugging Face, 2024). Fine-tuning was accomplished using splits of the 318 data points. A detailed presentation of these methods appears in Appendices F, C, and E."}, {"title": "3.2.2 The Elo Rating System", "content": "The Elo rating system, introduced by Arpad Elo (Elo, 1967, 1978), is a widely used method for quantifying the relative skill levels of players in two-player competitive games. It has been demonstrated to effectively rank models based on human judgment (Boubdir et al., 2023), benchmark LLMs (Zheng et al., 2023), and rank preferences, such as humor in Twitter posts (Zheng et al., 2023) through pairwise comparisons. Inspired by previous research (Berijanian et al., 2024; SEE-Insight, 2024), we used the Elo system to rank annotations and then compared these rankings with those generated by the candidate similarity measures."}, {"title": "3.2.3 Elo Tournaments", "content": "Each author was presented with a series of comparisons between annotations via a web interface (Appendix G). Raters were instructed to select the better annotation as 'winner' or to choose 'tie' following a set of guidelines (see Appendix I). Elo scores were computed per passage, so each passage acted as an individual 'tournament'. Raters did not rate their own annotations to avoid potential bias. Inter- and intra-rater reliability were captured through overlaps (Appendix H.1)."}, {"title": "3.3 Similarity Measures", "content": "We devised five candidate FCM similarity measures based on the established textual similarity measures in Table 2. The similarity between an FCM and a gold standard is computed as a softly thresholded F1 score between edge sets. Given a textual similarity measure S (\u00b7, \u00b7), a threshold T, and edge sets E and Egold, as well as any textual edge attributes A (we use A = {source, target}) and non-textual edge attributes N (we use N = {direction}):\nTP: For each e \u2208 E, our method counts a true positive if there exists an egold \u2208 Egold such that S (e.a, egold.a) > T for every a \u2208 A and e.n = egold.n for every n \u2208 N ;\nPP: For each e \u2208 E, our method counts a partial positive if there exists an egold \u2208 Egold such that S (e.a, egold.a) > T for every a \u2208 A and there exists an n \u2208 N such that e.n \u2260 egold.n;\nFP: For each e \u2208 E, our method counts a false positive if for every egold \u2208 Egold, we have S (e.a, egold.a) < T for any a \u2208 A;\nFN: For each egold \u2208 Egold, our method counts a false negative if for every e\u2208 E, we have S (e.a, egold.a) < T for any a \u2208 A.\nFor any S, once the TP, PP, FP, and FN have been counted, the corresponding edge-based measure can be calculated using the F1-like formula:\n$\\frac{2 \\cdot TP + PP}{2 \\cdot TP + PP + FP + FN}$ (1)"}, {"title": "3.4 Correlation Analysis", "content": "The winning annotation of each tournament was deemed the gold standard. We then produced a ranking of annotations per passage using each candidate similarity measure applied to each (gold standard, annotation) FCM pair. The Spearman correlations (Spearman, 1904) between human- and similarity measure-generated rankings were computed. We then applied the measure with highest correlation to evaluate LLM-generated FCMs and compared with an LLM-only tournament."}, {"title": "4 Results", "content": "The Spearman correlation coefficients for each measure, averaged across all passages, are summarized in Table 3. Higher values indicate greater mean correlation with human rankings. Novel measure-produced rankings have positive mean correlations with human-generated rankings, and each improves upon vanilla F1 in this regard (Table 4)."}, {"title": "4.2 LLM Inferences", "content": "Figure 2 presents the average BLEU-E scores for FCM inferences on the test set by each LLM before and after fine-tuning. As expected, fine-tuned models outperform their default counterparts, with Mistral scoring highest, followed by Llama-2 and then Llama-3.is consistent with the human-generated ranking."}, {"title": "5 Discussion and Conclusions", "content": "This paper presents an evaluation of fine-tuned LLM-based methods for extracting FCMs from text, while also introducing and assessing novel edge-based similarity measures to validate the quality of these FCMs. The study highlights the limitations of traditional measures, which often fail to capture the nuances and partial correctness in FCMs, especially in the context of SES research. For instance, there were cases where LLMs outperformed human annotators, yet these instances might have been overlooked if we relied solely on traditional measures like the F1 score or validation set loss. The novel edge-based measures allowing for partial positives show markedly greater correlation with human judgments.\nIn addition to examining similarity measures, this work initiates a new approach for validating graph-based NLP predictions by employing pairwise comparative human judgments, using the Elo rating system, to rank predictions. This method was used to compare human-derived rankings with those generated by similarity measures, providing a proof of concept for enhancing the qualitative evaluation of NLP-generated FCMs.\nFine-tuning LLMs proved beneficial, resulting in higher BLEU-E scores and improved model performance. Whereas the validation set losses for all fine-tuned LLMs appear similar (Figure 3 in Appendix C), their qualitative performances differed significantly. Although BLEU-E offers a more accurate assessment than validation set loss, these improvements do not fully resolve the underlying issues with the current similarity measures.\nThe study's findings emphasize the necessity of developing more specialized measures that are better aligned with human judgment and capable of capturing the complexities of FCM extraction. This study represents an initial step towards that goal, highlighting the limitations of current approaches and setting the stage for future research.\nFuture work will focus on developing and validating new similarity measures that can better capture the complexities and partial correctness in FCM extraction. For instance, greater correlation with human judgment should be achievable by parameterizing TP and PP with scalars and employing optimization. Additionally, integrating human-in-the-loop approaches may help refine LLM outputs, leading to more accurate FCMs. We also imagine a range of applications and extensions. For instance, the proposed measures can be straightforwardly extended to knowledge hypergraphs. Furthermore, by symmetrizing any one of our typically asymmetric measures we may interpret it as a kernel (Kriege et al., 2020; Scholkopf and Smola, 2018). Explicitly, let f = BLEURT-E and G1 and G2 be FCMs, and define a kernel K as,\n$K (G_1, G_2) = \\frac{f (G_1, G_2) + f (G_2, G_1)}{2}$\nThis interpretation brings to bear the entire suite of kernel methods for the study of FCMs to facilitate visualization, classification, and general pattern recognition.\nIn conclusion, this study has provided insights into the evaluation of LLM-generated FCMs and also underscores the need for continued research. Our framework provides a structured approach for these evaluations. This paper marks just the beginning of a journey towards improving the overall evaluation framework for FCMs and enhancing the role of LLMs in collective intelligence research, particularly in SES contexts with small quantities of low quality textual data."}, {"title": "A Limitations", "content": "While our approach is robust, it is important to acknowledge potential limitations that could impact the generalizability and effectiveness of our findings.\nFirstly, the passages we selected for our study are specific to a particular context and may not be representative of different domains, which could limit the generalizability of our findings across other contexts. Future research should explore cross-domain evaluations to validate the effectiveness of our approach in various settings.\nSecondly, our methodology relies on initial human annotations, then selecting between human and LLM annotations as the gold standard, which introduces the possibility of bias due to the diversity of cultural and disciplinary backgrounds of the annotators. The initial annotations may not encompass all possible interpretations or nuances present in the text. Future work will focus on expanding the dataset to include a wider variety of texts and annotations, which will help in creating a more comprehensive and representative gold standard.\nFurthermore, while we aimed to fine-tune LLMs for improved performance, we did not tune all hyperparameters. Specifically, we only optimized the rank parameter r for LoRA. The primary reason for not extensively tuning all hyperparameters, such as the learning rate, was that the focus of this paper was on measure alignment instead of optimizing hyperparameter settings. Future studies should aim to explore a broader range of hyperparameter tuning to fully explore the capabilities of the LLMs.\nAdditionally, our experiment was conducted with a limited number of annotation samples for LLM training and Elo ranking. Although the sample selection aimed to cover a broad spectrum of text complexities, the small sample size may not fully capture the variability in real-world data. Furthermore, the samples were selected to provide difficult examples, which may not represent typical data. Moreover, the limited sample size may limit the capabilities of LLMs due to a lack of surplus of data available for fine tuning. Elo rankings may have marginally deviated due to a limited sample size. Expanding the number of samples in future experiments will enhance the reliability and applicability of our results.\nMoreover, our current approach does not leverage human-in-the-loop (HITL) strategies to iteratively improve LLM inferences based on human feedback. Integrating HITL mechanisms with the Elo rating system could significantly enhance the quality and accuracy of LLM-generated annotations. By continuously integrating human judgment, this iterative process would allow for ongoing refinement and improvement of LLM outputs. Future work should explore implementing HITL strategies to capture real-time human feedback and use it to fine-tune and validate LLM performance."}, {"title": "B Ethical Considerations", "content": "This study involves the extraction and validation of fuzzy cognitive maps (FCMs) from text using large language models (LLMs). Several ethical considerations are relevant to this work, particularly regarding data use, annotation processes, biases, and the environmental impact of our research.\nData Use and Privacy: The data used in this study were created and annotated by the authors. This ensures that we have complete control over the data's provenance and the conditions under which it was generated. Since the data were produced specifically for this research, issues related to intellectual property and participant privacy are minimized.\nAnnotation Process: All annotations were carried out by the authors, ensuring a consistent understanding of the task and eliminating the need for external annotators. This method addresses concerns about fair compensation and working conditions for annotators, as the work was part of the authors' research activities.\nBias and Fairness: Inherent biases in language models can affect the outcomes. Researchers should explore methods to identify and mitigate such biases to enhance the fairness and reliability of FCM extractions.\nEnvironmental Impact: The environmental impact of training and fine-tuning LLMs is a significant concern in NLP research. In our study, each training session lasted approximately 40 minutes, which is relatively short. This brevity was due to our primary focus on developing and validating measures for extracting and evaluating FCMs from text, rather than optimizing LLM performance. Consequently, we did not extensively tune the LLM hyperparameters, such as the learning rate, as our focus was on measure alignment rather than finding the ideal hyperparameter settings. This approach not only aligns with our research goals but also minimizes the environmental footprint of our computational experiments.\nPotential Misuse: NLP technologies can be misused in various ways, such as generating misleading information or reinforcing harmful stereotypes. Researchers and practitioners should be aware of these risks and take steps to mitigate them when deploying such technologies.\nResearchers should incorporate comprehensive strategies to address these ethical challenges, ensuring that the development and application of NLP technologies are aligned with broader societal values and ethical standards."}, {"title": "C Fine-Tuning Parameters and Hyperparameters", "content": "For fine-tuning the models with instruction tuning, we focused on adjusting the rank r in LoRA, while maintaining other training parameters at constant values. The cost function for training and validation was cross-entropy loss. The Huggingface library (Hugging Face, 2024) was utilized to run the training jobs with 4-bit quantization.\nThe common hyperparameters and their corresponding values used for fine-tuning the three models are listed below. Note that while the maximum number of training epochs was set to 15, early stopping was employed, so not all experiments reached the full 15 epochs. The early stopping mechanism halted training when the validation loss did not improve for 3 consecutive epochs.\n\u2022 Maximum number of training epochs: 15 (subject to early stopping)\n\u2022 Batch size: 4\n\u2022 Optimizer: Paged AdamW 32-bit\n\u2022 Learning rate: 2e-4\n\u2022 Learning rate scheduler: Cosine decay\n\u2022 Gradient accumulation steps: 1\n\u2022 Gradient clipping: 0.3\n\u2022 Gradient checkpointing : True (to save memory)\n\u2022 Weight decay: 0.001\n\u2022 Warmup ratio: 0.1\n\u2022 Use of 4-bit precision: Enabled (to reduce memory and computational cost)\n\u2022 Data type for 4-bit computations: bfloat16\n\u2022 Quantization type for 4-bit precision: nf4\n\u2022 Nested quantization: Disabled\n\u2022 LORA dropout rate: 0.1\nThe following hyperparameters were optimized during the fine-tuning process:\n\u2022 LoRA rank (r): 2, 4, 8, 16, 32, 64, 128, 256"}, {"title": "C.1 Optimal Rank (r) Values for LORA Fine-Tuning", "content": "To determine the optimal rank r for each model, we experimented with various r values and monitored the validation loss.\nThe best r values, based on the minimum validation set loss for Llama-2-7B-chat-hf, Llama-3-8B-Instruct, and Mistral-7B-Instruct-v0.2 after testing different r values, are as follows:\n\u2022 Llama-2-7B-chat-hf: 128\n\u2022 Llama-3-8B-Instruct: 64\n\u2022 Mistral-7B-Instruct-v0.2: 128\nAs shown in Figure 3, all three models achieved similar validation losses with their respective optimal r values."}, {"title": "D Other Formulas and Hyperparameters", "content": "The Elo rating system (Elo, 1967, 1978), is a method for quantifying the relative skill levels of players in two-player competitive games such as chess. It assigns a numerical rating to each player, representing their skill level.\nThe Elo rating system updates players' ratings after each game based on the outcome. The formula to update the rating involves several steps. First, the expected score for player A against player B is calculated using the formula:\n$E_A = \\frac{1}{1+10^{(R_B-R_A)/400}}$,\nwhere RA and RB are the current ratings of players A and B, respectively. Similarly, the expected score for player B is:\n$E_B = \\frac{1}{1+10^{(R_A-R_B)/400}}$.\nNote that EA + EB = 1. The actual score SA is 1 if player A wins, 0 if player A loses, and 0.5 in the case of a draw. Similarly, SB is 1 if player B wins, 0 if player B loses, and 0.5 for a draw. The new ratings for players A and B are updated using the formulas:\n$R'_A = R_A + K(S_A \u2013 E_A)$\n$R'_B = R_B + K(S_B \u2013 E_B)$"}, {"title": "D.2 Hyperparameters for Elo Rating Calculation", "content": "In the process of calculating Elo ratings for annotation evaluations, we utilized the following hyperparameters:\n\u2022 K-factor: 32\n\u2022 Initial Elo rating: 1000"}, {"title": "D.3 Hyperparameters for Similarity Measures", "content": "The English-trained checkpoint bleurt-base-128 and ROUGE-1 were used in this study. We considered a range of thresholds, T, for each measure through exploratory data analysis and adaptive grid search. The T chosen for each measure coordinates to the highest achieved Spearman correlation to the human-generated rankings. The T selected for each measure is:\n\u2022 BLEURT-E: -0.1532\n\u2022 BLEU-E: 0.352\n\u2022 METEOR-E: 0.01\n\u2022 ROUGE-E: 0.45."}, {"title": "E Prompts Format for Instruction Tuning", "content": "This section details the prompts format used for instruction tuning. This format ensures that the model clearly understands the task and generates the appropriate response based on the given instruction."}, {"title": "E.1 Llama-2-7B and Mistral-7B", "content": "Both Llama-2-7B-chat-hf and Mistral-7B-Instruct-v0.2 use the same prompt format for instruction tuning. We provide the instructions for the model within the [INST] and [/INST] tags, and the model generates everything following the [/INST] tag. The entire prompt is enclosed within <s> and </s> tags.\nThe prompt format used is mentioned below:\n<s>[INST] Given the input sentence, identify all the triplets of entities and the corresponding causal relationships between them. The entities should be phrases from the input sentence, and the relationships should either be 'Positive' or 'Negative'. Each new extracted triplet should start with the <triplet> token, followed by the subject phrase, the object phrase, and the relationship, separated by <subj> and <obj> tokens.\nInput Sentence: <Sentence> [/INST]\nCausal Relation Triplets: <triplet> Subject_1 <subj> Target_1 <obj> Relationship_1 <triplet> Subject_2 <subj> Target_2 <obj> Relationship_2 </s>\nA complete example, including the prompt, a sample sentence, and its causal relation triplets used for instruction tuning, is provided below:\n<s>[INST] Given the input sentence, identify all the triplets of entities and the corresponding causal relationships between them. The entities should be phrases from the input sentence, and the relationships should either be 'Positive' or 'Negative'. Each new extracted triplet should start with the <triplet> token, followed by the subject phrase, the object phrase, and the relationship, separated by <subj> and <obj> tokens.\nInput Sentence: Islamist violence in Mali has also hit cattle herding areas, forcing farmers to abandon their trade. Climate change too has led to competition for grazing lands and water, leading to intercommunal conflicts. The result, increased costs for breeders. [/INST]\nCausal Relation Triplets: <triplet> islamist violence <subj> cattle herding <obj> negative <triplet> climate change <subj> competition for grazing lands and water <obj> positive <triplet> competition for grazing lands and water <subj> intercommunal conflicts <obj> positive <triplet> intercommunal conflicts <subj> increased costs for breeders <obj> positive </s>"}, {"title": "E.2 Llama-3-8B", "content": "Llama-3-8B-Instruct follows a different prompt format compared to Llama-2 or Mistral. An example of the prompt format for Llama-3-8B-Instruct is provided below:\n<|begin_of_text|><|start_header_id|> system<|end_header_id|>\nGiven the input sentence, identify all the triplets of entities and the corresponding causal relationships between them. The entities should be phrases from the input sentence, and the relationships should either be 'Positive' or 'Negative'. Each new extracted triplet should start with the <triplet> token, followed by the subject phrase, the object phrase, and the relationship, separated by <subj> and <obj> tokens. <|eot_id|><|start_header_id|> user<|end_header_id|>\nInput Sentence: A direct negative effect that for example a wind farm can have on the trawl fishery (reduced fishing activity), <|eot_id|><|start_header_id|> assistant<|end_header_id|>\nCasual Relation Triplets: <triplet> wind farm <subj> trawl fishery <obj> negative <|eot_id|>"}, {"title": "F Prompts Format For Zero- and Three-Shot Learning", "content": "To achieve structured output in zero-shot and three-shot in-context learning, we optimized the prompts. Examples of the prompts used in zero-shot in-context learning for all the models are as follows:"}, {"title": "F.1 Zero-Shot Learning", "content": "To achieve structured output in zero-shot and three-shot in-context learning, we optimized the prompts. Examples of the prompts used in zero-shot in-context learning for all the models are as follows:"}, {"title": "F.1.1 Llama-2-7B-chat-hf", "content": "<s>[INST] <<SYS>> Given the input sentence, identify all the triplets (subject, object and causal relation). The subject and object should be phrases from the input sentence.\nThe causal relation between subject and object should strictly be either \"Positive\" or \"Negative\" and nothing else.\nEach new extracted triplet i.e. subject, object and relation should start with a newline should be within <triple> and </triplet>. The subject should be within <subj> and </subj> tokens. The object should be within <obj> and </obj> tokens. The causal relation should be within <relation> and </relation> tokens. The format of output of each triplet should be strictly like below:\n<triplet>\n <subj> </subj>\n <obj> </obj>\n <relation> </relation>\n</triplet>\n<<SYS>>\nInput Sentence: pastoralists in the arid and semi-arid regions of Mali continue to face increasing risk due to low levels of rainfall [/INST]\nCausal Relation Triplet :\n<triplet>\n <subj> pastoralists</subj>\n <obj> low levels of rainfall</obj>\n <relation> Negative</relation>\n</triplet>\n<triplet>\n <subj> Mali</subj>\n <obj> increasing risk</obj>\n <relation> Positive</relation>\n</triplet>\nNote: The subject and object phrases are enclosed within <subj> and <obj> tokens, respectively, and the causal relation is enclosed within <relation> and </relation> tokens."}, {"title": "F.1.2 Llama-3-8B-Instruct", "content": "<|begin_of_text|> <|start_header_id|> system <|end_header_id|>Given the input sentence, identify all the triplets (subject, object and causal relation). The subject and object should be phrases from the input sentence.\nThe causal relation between subject and object should strictly be either \"Positive\" or \"Negative\" and nothing else.\nEach new extracted triplet i.e. subject, object and relation should start with a newline should be within <triple> and </triplet>. The subject should be within <subj> and </subj> tokens. The object should be within <obj> and </obj> tokens. The causal relation should be within <relation> and </relation> tokens.\nThe format of output of each triplet should be strictly like below:\n<triplet>\n <subj> </subj>\n <obj> </obj>\n <relation> </relation>\n</triplet> <leot_id|><|start_header_id|> user <lend_header_id|>\nInput Sentence: Women identified forced sex and men highlighted lack of awareness about contraception and fear of side effects as important causes of kunika. <|eot_id|><|start_header_id|> assistant <|end_header_id|>\n<triplet>\n <subj>Women</subj>\n <obj>forced sex</obj>\n <relation>Positive</relation>\n</triplet>\n<triplet>\n <subj>men</subj>\n <obj>lack of awareness about contraception and fear of side effects</obj>\n <relation>Positive</relation>\n</triplet>\n<triplet>\n <subj>men</subj>\n <obj>kunika</obj>\n <relation>Negative</relation>\n</triplet>"}, {"title": "F.1.3 Mistral-7B-Instruct-v0.2", "content": "<s>[INST] Given the input sentence, identify all the triplets (subject, object and causal relation). The subject and object should be phrases from the input sentence.\nThe causal relation between subject and object should strictly be either \"Positive\" or \"Negative\" and nothing else.\nEach new extracted triplet i.e. subject, object and relation should start with a newline should be within <triple> and </triplet>. The subject should be within <subj> and </subj> tokens. The object should be within <obj> and </obj> tokens. The causal relation should be within <relation> and </relation> tokens. The format of output of each triplet should be strictly like below:\n<triplet>\n <subj> </subj>\n <obj> </obj>\n <relation> </relation>\n</triplet>\nInput Sentence: pastoralists in the arid and semi-arid regions of Mali continue to face increasing risk due to low levels of rainfall [/INST]\nCausal Relation Triplet :\n<triplet>\n <subj> pastoralists in the arid and semi-arid regions of Mali </subj>\n <obj> face increasing risk </obj>\n <relation> Positive </relation>\n</triplet>\n<triplet>\n <subj> Low levels of rainfall </subj>\n <obj> cause pastoralists in the arid and semi-arid regions of Mali to face increasing risk </obj>\n <relation> Negative </relation>\n</triplet>\n</s>"}, {"title": "F.2 Three-Shot Learning", "content": "To achieve structured output in three-shot in-context learning, we optimized the prompts. Below are examples of the prompts used in three-shot in-context learning for all the models:"}, {"title": "F.2.1 Llama-2-7B-chat-hf", "content": "<s>[INST] <<SYS>> Given the input sentence, identify all the triplets of entities and the corresponding causal relationships between them. The entities should be phrases from the input sentence, and the relationships should either be 'Positive' or 'Negative'. Each new extracted triplet should start with the <triplet> token, followed by the subject phrase, the object phrase, and the relationship, separated by <subj> and <obj> tokens.\nDon't add extra sentences."}, {"title": "F.2.2 Llama-3-8B-Instruct", "content": "<|begin_of_text|> <|start_header_id|> system <|end_header_id|> Given the input sentence, identify all the triplets of entities and the corresponding causal relationships between them. The entities should be phrases from the input sentence, and the relationships should either be 'Positive' or 'Negative'. Each new extracted triplet should start with the <triplet> token, followed by the subject phrase, the object phrase, and the relationship, separated by <subj> and <obj> tokens.\nDon't add extra sentences.\n<|eot_id|><|start_header_id|> user <end_header_id|>\nInput Sentence: the current price of local rice (sold loose) at the local market is 1850 ngn/1kg. the price is expected"}, {"title": "F.2.3 Mistral-7B-Instruct-v0.2", "content": "<s>[INST] Given the input sentence, identify all the triplets of entities and the corresponding causal relationships between them. The entities should be phrases from the input sentence, and the relationships should either be 'Positive' or 'Negative'. Each new extracted triplet should start with the <triplet> token, followed by the subject phrase, the object phrase, and the relationship, separated by <subj> and <obj> tokens.\nDon't add extra sentences.\nInput Sentence: the current price of local rice (sold loose) at the local market is 1850 ngn/1kg. the price is expected"}, {"title": "GUser Interfaces", "content": "In this appendix, we provide screenshots of the two custom Dash-based user interfaces (UIs) (Plotly, 2024) developed for this study. These UIs were integral to the annotation and evaluation processes, facilitating consistent data collection and pairwise comparisons."}, {"title": "G.1 Annotation Interface", "content": "Figure 4 shows the"}]}