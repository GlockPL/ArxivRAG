{"title": "Augmentation through Laundering Attacks for Audio Spoof Detection", "authors": ["Hashim Ali", "Surya Subramani", "Hafiz Malik"], "abstract": "Recent text-to-speech (TTS) developments have made voice cloning (VC) more realistic, affordable, and easily accessible. This has given rise to many potential abuses of this technology, including Joe Biden's New Hampshire deepfake robocall. Several methodologies have been proposed to detect such clones. However, these methodologies have been trained and evaluated on relatively clean databases. Recently, ASVspoof 5 Challenge introduced a new crowd-sourced database of diverse acoustic conditions including various spoofing attacks and codec conditions. This paper is our submission to the ASVspoof 5 Challenge and aims to investigate the performance of Audio Spoof Detection, trained using data augmentation through laundering attacks, on the ASVSpoof 5 database. The results demonstrate that our system performs worst on A18, A19, A20, A26, and A30 spoofing attacks and in the codec and compression conditions of C08, C09, and C10.", "sections": [{"title": "1. Introduction", "content": "Recent developments in text-to-speech (TTS) technology, particularly zero-shot, multi-speaker TTS [1, 2, 3], have led to the creation of methods that can generate highly realistic synthesized speech. This progress has spurred the growth of companies such as ElevenLabs that provide affordable and easy-to-use TTS services. These advances facilitate a wide range of applications, from helping people with speech impairments to creating digital avatars, as demonstrated by a jailed Pakistani politician, Imran Khan, who created his AI-generated video for his election campaign [4]. However, alongside the positive use cases, the potential for misuse of voice cloning (VC) technology has also raised many concerns.\nThe past two years have seen a remarkable increase in TTS/VC incidents targeting political figures. Recently, around 25000 voters in New Hampshire received a deepfake robocall impersonating President Joe Biden, telling them not to vote in the state's primary elections. This robocall was analyzed by a security company, called Pindrop, and it was attributed to be likely generated through Elevenlabs' technology [5, 6, 7]. This kind of deepfake content is not just spread by hidden bad actors, it is also shared by many renowned people. For example, Elon Musk shared a sarcastic \"campaign video\" of Vice President Kamala Harris, in which she made comments along the lines of \"The first rule President Joe Biden taught me is to carefully hide your total incompetence\" and \"I believe exploring the significance of the insignificance is in itself significant\" [8, 9]. Similarly, audio deepfakes of Donald Trump have also been shared on social networks [10]. Other similar instances of targeting political figures include Ukrainian President Zelenskyy's viral deepfake video asking his soldiers to surrender [11] and mayor of London UK, Sadiq Khan's fake audio [12] in which he was supposedly making inflammatory remarks about Armistice Day and rallying people to protest for Palestine. In addition, audio deepfakes are being used in phone scams in which a person receives a call from a scammer claiming to be a relative stuck in an accident, arrest, or abduction to extort money from the victim [13]. In a similar incident, a finance worker in a multinational company was tricked into paying $25 millions to fraudsters using deepfake technology to pose as the company's chief financial officer in a video conference call [14].\nAddressing the challenge of audio deepfakes, a number of audio spoof detection (ASD) methods were proposed to discriminate between bonafide and spoofed utterances. However, these ASD systems have been predominantly evaluated on ASVSpoof datasets (2015, 2017, 2019, 2021) [15, 16, 17, 18]. With the exception of the ASVSpoof 2021 dataset, these corpora have been curated within controlled settings which may not accurately depict real-world conditions. Recently, ASVspoof5 Challenge was started, and unlike previous ASVspoof databases, ASVspoof 5 database is built from crowd-sourced data collected in diverse acoustic conditions using Multilingual Librispeech (MLS) English partition. This database consists of 32 different spoofing attacks (A01-A32) and 11 codec and compression conditions (C01-C11). In addition to the use of new spoofing attacks implemented using the latest text-to- speech (TTS) synthesis and voice conversion (VC) algorithms, adversarial attacks are introduced for the first time and combined with spoofing attacks. For more detail, the reader is referred to Wang et al. [19].\nThis paper describes our submission to the ASV spoof Challenge and aims to investigate the performance of Audio Spoof Detection, trained using data augmentation through laundering attacks, on the ASVSpoof 5 database [19]. For that purpose, we randomly selected 10% of the audio files from the ASVspoof 5 train database (Non-Augmented data) [19]. These audio files are then passed through a number of laundering attacks, including noise addition, reverberation, recompression, resampling, filtering, to generate Augmented ASVSpoof 5 train database (Augmented data). After that, we trained AASIST [20] on Augmented data, and evaluated it on ASVSpoof 5 eval database by submitting the scores to the ASVspoof 5 Challenge [19]. We hypothesize that the performance of AASIST will improve after training on Augmented data.\nTo benchmark AASIST on ASVSpoof 5, this paper presents the following contributions:\n\u2022 We trained AASIST on the Augmented ASVSpoof 5 train database (Augmented data), and evaluated it on the ASVSpoof 5 eval database.\n\u2022 A detailed description of the performance of AASIST system, trained on Augmented data, is provided using 4 metrics namely, minDCF, actDCF, Cllr, and EER."}, {"title": "2. Related Work", "content": "A significant amount of research has undergone to develop strategies that can detect audio spoofs reliably. These strategies can be broadly classified into three categories [21, 22, 23, 24],\n1. Conventional Machine Learning Approaches\n2. Representation Learning Approaches\n3. End-to-end Learning Approaches\nConventional machine learning (ML)-based approaches for audio spoof detection typically consist of two parts. The first part deals with hand-crafted feature extraction (front-end) and the second part consists of a model (back-end) that determines the authenticity of the audio signal [23, 22]. Examples of such systems include CQCC-GMM, LFCC-GMM [18, 25] etc.\nRepresentation learning approaches work either in the form of feature learning or as a pattern classifier. In representation learning, these methods use deep learning to generate a representation for the specific task and then use some classifier to discriminate between bonafide and spoof audios. Examples of feature learning include Qian et al. [26]. In pattern classification, hand-crafted features are extracted first and then a deep learning method is used as a classifier. Examples of pattern classification include LFCC-LCNN [27], OCSoftmax [28] etc.\nEnd-to-end learning approaches for audio spoof detection operate directly upon raw waveform inputs, streamlining the training and evaluation process. These methods use deep neural networks to learn a representation from raw audio input and then contain fully connected layers at the end for classification task. Examples of such systems include RawNet2 architecture [29, 30], RawGat-ST [31], AASIST [20].\nSeveral studies have explored the performance of audio spoof detection in acoustically degraded conditions and in the wild audio data. Muller et al. [32] re-implemented twelve popular architectures trained on ASVSpoof 2019 database and evaluated them on an in-the-wild database, consisting of audio data sourced from the internet. The authors demonstrated that the performance of ASD systems degrades by up to a thousand percent on such real-world data. However, Hashim et al. [33] argued that the audio spoofs that are available online have undergone a number of post-processing steps, such as reverberation, recompression, additive noise, etc. As a result, an in-the-wild audio sourced from the internet could just be a clean audio file that has been subjected to laundering attacks. This led Hashim et al. [33] to evaluate seven ASD systems on a laundered (noisy) database, called \"ASVSpoof Laundered Database\". The authors created this database by passing the audio files in ASVSpoof 2019 LA eval database through multiple laundering attacks. The authors demonstrated that the performance of all seven ASD systems degrade significantly in the presence of laundering attacks.\nConsidering the fact that (1) the ASVSpoof 5 database is crowd-sourced and consists of audio data collected in diverse acoustic conditions. (2) ASVSpoof 5 database contains audio file with varying codecs and compression conditions applied to them. We propose to train a baseline model from ASVSpoof 5 database on an Augmented data, generated by applying various laundering attacks to it (Section 4). We hypothesize that training AASIST system on an Augmented will improve its performance on ASVspoof 5 eval database."}, {"title": "3. AASIST System", "content": "AASIST [20] is a baseline system in the ASVSpoof 5 Challenge. It used a RawNet2-based encoder [29, 30] to extract spectro-temporal features from raw waveform inputs. First, the authors proposed a variant of the graph attention layer, known as the heterogeneous stacking graph attention layer\" (HS-GAL). This layer facilitates the concurrent modeling of heterogeneous (spectral and temporal) graph representations to create a single representation from them. HS-GAL comprises two components, namely heterogeneous attention and a stack node. In heterogeneous attention, the authors use three different projection vectors to calculate the attention weights for the heterogeneous graph. After that, the stack node merges the information that spanned the relationship between the spectral and temporal domains. Additionally, the authors proposed a \"max graph operation\" (MGO), and a readout operation. Max graph operation (MGO) utilizes two parallel branches where the element-wise maximum is applied to the output of the two branches. This procedure aims to detect various artifacts introduced by spoofing in spoofed speech. Ultimately, CM output scores are generated using a readout operation and a hidden linear output layer comprising two class predictions: bonafide or spoof."}, {"title": "4. Data Augmentation through Laundering Attacks", "content": "To improve the performance of audio spoof detection in real-world settings, we propose to train the AASIST [20] system on a database augmented with laundering attacks. The idea is borrowed from Hashim et al. [33] that an in-the-wild audio is just clean audio subjected to different types of laundering attacks, including noise addition, reverberation, and recompression, etc. For that purpose, 10% of the audio files are randomly selected from the ASVSpoof 5 train database. This amounts to a total of 18235 audio files. Five different types of laundering attacks are then added to these audio files to create the augmentation data. First, reverberation noise is added with reverberation time (RT60) randomly chosen between 0.3s, 0.6s, and 0.9s. Second, the 10% audio files are attacked with additive noise; babble noise, volvo noise, white noise, cafe noise, and street noise. Each noise is added to all the selected 10% audio files with randomly chosen SNR levels between 0dB, 10dB, and 20dB, creating a total of 5 copies of the selected 10% audio files. The third laundering attack that we added to the selected audio files is a recompression noise. The audio files in the ASVspoof 5 database are in FLAC format with a bitrate of 132 kbit/s. We first uncompressed the audio files from FLAC to WAV format. After that, the WAV audio files are compressed to MP3 format using bit rates randomly chosen between 16, 64, 128, 192, 256, and 320 kbit/s. Thereafter, all the audio files are uncompressed to WAV and compressed back to FLAC format. As a fourth laundering attack, we added resampling noise to the selected audio files. Taking into account the sampling rate of the original signal (16 KHz), the selected 10% audio files from ASVspoof5 database were resampled with a sampling"}, {"title": "5. Experimental Setup", "content": "The goal of our experiments is to verify the hypothesis, mentioned in section 1, that whether training the AASIST system using data augmentation through laundering attacks improve its performance."}, {"title": "5.1. Training and Evaluation", "content": "To verify our hypothesis, we trained the AASIST system on the augmented ASVSpoof 5 train database. It is developed by adding the augmentation data created in section 4 to ASVSpoof 5 train database. We call this database an Augmented database. This database consists of a total of 327,461 audio files, of which 35,404 are bonafide and 311,068 are spoof. The detail of the Augmented ASVSpoof train database is given in Figure 1. Furthermore, to avoid over-fitting, the ASVSpoof 5 development database is used as a validation. It is important to note here that the ASVSpoof 5 development database (validation set) does not contain any laundering attacks. The reason for this configuration is to achieve a more generalized performance while also achieving comparatively good results on the clean ASVSpoof 5 eval database. Once the AASIST system is trained, it is evaluated on ASVSpoof 5 eval database by submitting the scores to the ASVspoof 5 Challenge."}, {"title": "5.2. Evaluation Metric", "content": "ASVspoof 5 Challenge uses four metrics for evaluation, namely minimum Detection Cost Function (minDCF), actual Detection Cost Function (actDCF), cost of log-likelihood ratios (Cllr), and equal error rate (EER). The details of each evaluation metric are given in the ASVspoof 5 summary paper [19]."}, {"title": "6. Results", "content": "This section discusses the findings of our experiments. As mentioned in section 5, the goal of our experiments is to study the performance of the AASIST system on the ASVSpoof 5 Challenge database, when it is trained using data augmentation through laundering attacks. For that purpose, a detailed breakdown of the results is provided in terms of spoofing attacks (A17-A32) vs codecs and compression conditions (C00-C11) in terms of minDCF, actDCF, Cllr, and EER in tables 4, 5 6, and 7.\nTable 1 shows the results of AASIST, trained using data augmentation through laundering attacks, in terms of pooled minDCF, actDCF, Cllr, and EER. The table shows that AASIST achieves minDCF value of 0.662, actDCF value of 0.931, Cllr value of 2.486, and EER value of 25.319%.\nTable 2 shows the results of the modified AASIST system on individual attacks in terms of pooled minDCF, actDCF, Cllr, and EER. For each metric, the bold entries depict the top-5 worst performances among spoofing attacks A17-A32. Our observations can be summarized as follows.\n\u2022 AASIST system shows worst performance on A18, A19, A20, A26, and A30 spoofing attacks with minDCF values of 0.865, 1.0, 0.994, 0.857, and 1.0 respectively.\n\u2022 A18 consists of A17 attack plus Malafide adversarial attack [34], whereas, A20 consists of A12 + Malafide adversarial attack [34]. We can observe that the modified AASIST system shows good performance on A17 attack with minDCF value of 0.428, however, addition of Malafide adversarial attack degrades the performance for both A18 and A20 spoofing attacks.\n\u2022 A30 attack is a combination of A18 attack and Malacopula adversarial attack [19]. In other words, it is a combination of A17, Malafide and Malacopula attacks. The modified AASIST system achieves a minDCF value of 1.0 on this attack. We can see a gradual degradation"}, {"title": "7. Conclusion", "content": "We trained a baseline model, AASIST, on an augmented database as our submission to the ASVspoof 5 Challenge. This database is created by randomly selecting 10% of the audio files from the ASVspoof 5 train database, and applying different laundering attacks, including reverberation, noise addition, recompression, resampling, and low pass filtering, to generate an Augmented database. We achieved a pooled minDCF value of 0.662 and an EER of 25.319% in the ASVspoof 5 challenge. In addition, we studied the results of our system on individual spoofing attacks. We observed that the system shows the worst performance in the presence of adversarial attacks in the audio files, with minDCF values of 0.865 for A18 attack, 0.994 for A30 attack, and 1.0 for A30 attack. Furthermore, we also studied the performance of our system under different codec and compression conditions. We observed that our system shows the worst performance when the sampling rate is 8 kHz (C08, C09, C10) and in the presence of Encodec codec (C04, C07) with a minDCF value of 0.627 for C04, 0.637 for C07, 0.705 for C08, 0.693 for C09, and 0.711 for C10 respectively."}]}