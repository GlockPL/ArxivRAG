{"title": "Study of the Proper NNUE Dataset", "authors": ["Daniel Tan", "Neftali Watkinson"], "abstract": "NNUE (Efficiently Updatable Neural Networks) has revolutionized chess engine development, with nearly all top engines adopting NNUE models to maintain competitive performance. A key challenge in NNUE training is the creation of high-quality datasets, particularly in complex domains like chess, where tactical and strategic evaluations are essential. However, methods for constructing effective datasets remain poorly understood and under-documented. In this paper, we propose an algorithm for generating and filtering datasets composed of \"quiet\" positions positions that are stable and free from tactical volatility. Our approach provides a clear methodology for dataset creation, which can be replicated and generalized across various evaluation functions. Testing demonstrates significant improvements in engine performance, confirming the effectiveness of our method.", "sections": [{"title": "1 Introduction", "content": "NNUE (Efficiently Updatable Neural Networks) is a chess evaluation technique that utilizes the incremental update technique to quickly update the model for the next evaluation value. Instead of recalculating the entire sparse neural network matrix multiplication calculation from scratch, one only needs to update the small changes in a position that results from the move to get the next evaluation. Through incremental update, NNUE is able to efficiently calculate evaluations of millions of positions during an alpha beta negamax. Through this technique, NNUE has dramatically increased the elo playing strength of top chess engines over the several months [18].\nDespite NNUE's widespread adoption, the process for creating an effective dataset remains poorly understood and documented. There are vague suggestions or ambiguous descriptions on dataset creation, but no implementation details and no explanation for why those techniques work. In this paper, we aim to address this gap by asking: What makes a good dataset for training NNUE models?"}, {"title": "2 Background", "content": "NNUE (Efficiently Updatable Neural Networks) is a neural network evaluation function introduced by Yu Nasu, first used in the Japanese Shogi engine Yaneu-\nraOu [14]. Following its success in Shogi, NNUE was adapted for other board games, including Western Chess [13] and Chinese Chess [15]. Since then, it has revolutionized all engines across all different chess variants, with nearly all top engines implementing NNUE models to remain competitive.\nA critical aspect of NNUE's success lies in the quality of the datasets used to train the network. A well-curated dataset ensures that NNUE can learn accurate evaluations of positions during training. However, creating an effective NNUE dataset remains poorly documented. While [10] provides an in-depth explanation of SIMD programming for engine evaluation functions, it offers no guidance on how to build a robust training dataset. Similarly, generating good datasets is often left to trial and error, requiring developers to interpret complex source code without clear instructions.\nSome sources, such as [7], offer guidance on implementing neural network forward propagation but does not teach on how to properly collect and filter training data. For example, collecting random position/score pairs results in suboptimal training. Effective datasets must focus on \"quiet\" positions-positions that are stable and unlikely to change drastically in material or tactical balance. Noisy positions, which involve potential forks, captures, or tactical threats, should be excluded to prevent poor network performance.\nIn this paper, we propose a methodology for generating high-quality training datasets for NNUE, focusing on selecting quiet positions and filtering out noisy or tactically unstable positions."}, {"title": "3 Definitions", "content": "This is a brief summary of the terminology used throughout this paper. We provide the following definitions to ensure clarity and prevent confusion."}, {"title": "3.1 Negamax", "content": "The negamax [11] algorithm is a variant of the minimax search that utilizes the zero sum property of a two player game to simplify the minimax implementation. Instead of using two subroutines for the min and max player, negamax uses just one subroutine to do minimax, and the mathematical formula below is used to switch the evaluation scores between the two different sides.\n$\\min(a,b) = -\\\u0442\u0430\u0445(-a,-b)$                                                          (1)"}, {"title": "3.2 Quiescence Search", "content": "The quiescence [6] search is an algorithm used to extend the search at unstable nodes in the game tree. The idea behind quiescence search is to only evaluate"}, {"title": "3.3 Centipawn", "content": "A unit of measurement of a point advantage in Chess evaluation. A centipawn is one hundredth of a pawn. In this system, a one pawn advantage indicates that a player is at least one pawn up in material advantage."}, {"title": "3.4 Piece Square Tables", "content": "A piece square table [9] is a basic method of assigning specific pieces to specific squares. A table is created for each piece, and table values are given to each square. The higher the value of a square, the more likely a negamax function is going to place the piece on the particular square."}, {"title": "3.5 Elo", "content": "The Elo rating system [4] is the measurement of the relative playing skill levels of players in Chess/Go/other games. Elo is calculated using the following formula:\n$\\text{performance rating} = \\frac{\\text{total opponents' rating + 400(wins - losses)}}{\\text{number of games}}$                                                          (2)\nTo illustrate a few examples of how elo is used, the person with the highest peek Elo rating chess player, according to FIDE (the World Chess Federation i.e. F\u00e9d\u00e9ration Internationale des \u00c9checs) [5], is the 2013-2023 World Champion Magnus Carlsen at 2882 peek [17]. The strongest computer chess engine, Stockfish [13], is rated approximately 3600 Elo [1]. With that being said, the strongest computer chess program is significantly stronger than the best human players."}, {"title": "4 Platform", "content": "When experimenting with what kinds of data works, we implemented a Xiangqi (Chinese Chess) engine. Xiangqi arguably contains many interesting properties that make it better for exploring the power of NNUE compared with Western Chess. In Western Chess, being just a pawn down materially can lead to a loss, but in Xiangqi, the king is so easily exposed to attacks that being several pawns down is not such a problem as long as you have a strong attack [8]. Xiangqi is not just a game of gaining a material advantage over your opponent; Xiangqi"}, {"title": "5 Methodology", "content": "To create a good dataset to test NNUE on, we collected 44000 grandmaster games from [2, 19]. These Xiangqi websites have large databases of various official tournament games between Xiangqi masters from China, Vietnam, and other Asian countries which play Xiangqi from the years 2008 to 2024. From the recorded tournament games, we extracted all the moves and positions from recorded grandmaster games.\nAdding to the existing grandmaster games, we also generated another 30000 synthetic games through self play between different engines [3,15] and our own engine. We took random positions found in the grandmaster games, and generated additional games through self play between different engines. Just like the grandmaster games, we extracted all the moves and positions found in the recorded synthetic games."}, {"title": "6 Implementation", "content": "From the positions extracted out of the grandmaster games and synthetic games, we loop over all the possible moves, and generate the potential training/validation dataset from positions. We filter out noisy or tactically unstable positions and focus on selecting diverse high quality quiet positions for training. We generate a diverse set of position/evaluation pairs from all sorts of different kinds of positions.\nWith that being said, using noisy or tactically unstable positions drastically ruins the training of the neural network. Effects of noisy positions include the training algorithm refusing to converge due to the noise, the mean square error loss being drastically larger, and the network taking longer to train for poorer results. In terms of the effect on engine playing style, the engine might randomly"}, {"title": "7 Results", "content": "The simple Xiangqi NNUE evaluation function trained from datapoints derived [9] led to a massive increase in strategic understanding and positional play. Playing against the previous handcrafted evaluation function, the NNUE evaluation function was around +100 elo rating playing strength stronger. The upgraded NNUE engine won 65% of the games against the previous handcrafted evaluation version of the engine. Further training and search improvements improved the engine rating even further.\nTo make sure our algorithm works across different evaluation functions, we also used the [3] evaluation function to train the dataset, a much more complex handcrafted evaluation function that takes into account piece mobility, trapped pieces, and defense fortresses. The algorithm works perfectly fine for simple piece square tables such as [9] as well as complex evaluations such as [3,15]. The complexity of the evaluation criteria does not change the algorithm in any substantial way.\nIn terms of playing style, the previous engine using simplistic piece square tables lacked understanding of piece coordination. Due to the simplistic nature of\na piece square table, the previous engine would regularly fall for basic opening\ntraps such as sacrificing four pawns to gain an effective mating attack [8]. It\nwould take an extremely talented programmer to create a complex handcrafted\nheuristic to detect such a trap. The new version of the engine using the NNUE\nevaluation, by contrast, has no such blindspots."}, {"title": "8 Future Work", "content": "This algorithm contains most of what is needed to generate a good NNUE training dataset. To reiterate the Results section, we tested our methodology to make sure it worked across many different evaluation functions. Despite this however, this algorithm is not mathematically proven to generate good datasets and may need to be modified to accommodate the nuances of vastly different kinds of evaluation functions. Ultimately, the creation of good training datasets is measured on whether the trained model increases the playing strength of the engine.\nFuture work on this will focus on testing many other different evaluation functions as well as different chess variants such as Western Chess, Shogi, Jangqi, or Thai Chess to confirm that this algorithm works independently across different kinds of chess variants and different evaluation functions."}, {"title": "9 Conclusion", "content": "Despite the advancement of NNUE, the creation of a good dataset is poorly understood and poorly documented. Good dataset creation is a critical part of NNUE training, yet no papers or documentation has touched this topic. Understanding good dataset creation is a matter of tons of guesswork. In this paper, we documented and defined an algorithm for finding defining a good dataset for NNUE. The algorithm can be easily replicated, and produces massive increases in playing strength. The NNUE evaluation function developed a dynamic AlphaZero playing style based on human-like intuition."}]}