{"title": "Adaptive Differentially Private Structural Entropy Minimization\nfor Unsupervised Social Event Detection", "authors": ["Zhiwei Yang", "Yuecen Wei", "Haoran Li", "Qian Li", "Lei Jiang", "Li Sun", "Xiaoyan Yu", "Chunming Hu", "Hao Peng"], "abstract": "Social event detection refers to extracting relevant message clus-\nters from social media data streams to represent specific events in\nthe real world. Social event detection is important in numerous\nareas, such as opinion analysis, social safety, and decision-making.\nMost current methods are supervised and require access to large\namounts of data. These methods need prior knowledge of the events\nand carry a high risk of leaking sensitive information in the mes-\nsages, making them less applicable in open-world settings. There-\nfore, conducting unsupervised detection while fully utilizing the\nrich information in the messages and protecting data privacy re-\nmains a significant challenge. To this end, we propose a novel social\nevent detection framework, ADP-SEMEvent, an unsupervised so-\ncial event detection method that prioritizes privacy. Specifically,\nADP-SEMEvent is divided into two stages, i.e., the construction\nstage of the private message graph and the clustering stage of the\nprivate message graph. In the first stage, an adaptive differential\nprivacy approach is used to construct a private message graph. In\nthis process, our method can adaptively apply differential privacy\nbased on the events occurring each day in an open environment\nto maximize the use of the privacy budget. In the second stage,\nto address the reduction in data utility caused by noise, a novel\n2-dimensional structural entropy minimization algorithm based on\noptimal subgraphs is used to detect events in the message graph.", "sections": [{"title": "1 INTRODUCTION", "content": "Social event detection refers to extracting relevant clusters of mes-\nsages from social media message corpora or social message streams\nto represent specific events in the real world. Privacy leakage is\na crucial concern today and also exists in social event detection\ntasks. Social events occur daily, often containing rich information\nregarding collective social behaviors that widespread public atten-\ntion. Therefore, the task of social event detection holds significant\nimplications for sentiment analysis [2], product recommendations,\nand decision-making [26], distinguishing between real and fake\nnews [29], as well as monitoring and managing social crises [35]."}, {"title": "2 PRELIMINARY", "content": ""}, {"title": "2.1 Differentially Private Message Graph", "content": "The release of messages graph refers to the process of transforming\na series of social messages set $D = \\{m_1, ..., m_N\\}$ (generally, using\nPre-trained Language Models (PLMs) to convert the message into\nembeddings) into a message graph $G = (V, E)$ using an algorithm\n$R$. $G$ is utilized for social event detection. Under the background of\nprotecting privacy, we present the following definitions:\nDefinition 2.1. (Differential Privacy [6]). For algorithm R, given\nsocial message sets D and D' (D and D' are neighboring datasets\nthat differ by only one message), and any output G range(D).\nFor any $e > 0$, if the algorithm R satisfies:\n$Pr[R(D) \\subseteq G] \\leq e^{\\epsilon} Pr[R(D') \\subseteq G] + \\delta$,\n(1)\nwe say that the algorithm R satisfies ($\\epsilon$, \u03b4)-DP, where $e$ is the privacy\nbudget. Particularly, if 8 = 0, the algorithm R satisfies e-DP. R can\nprotect sensitive information contained in the messages during the\nrelease of the message graph.\nDefinition 2.2. (Sensitivity). Consider a function R whose input\nis a message set and whose output is in Rk. The sensitivity SR of\nfunction R is defined as:\n$S_R = max ||R(D) \u2013 R(D')||_1$.\n(2)"}, {"title": "2.2 Structural Entropy", "content": "Social event detection can be conducted by constructing classifica-\ntion or clustering models on the messages graph. Consistent with\nCao et al.\u2019s [4] approach, we achieve unsupervised graph clustering\nusing SE minimization. We provide the relevant definitions below:\nDefinition 2.4. (Encoding Tree of Messages Graph [18, 19]). The\ncoding tree T of the messages graph G = (V, E) is a hierarchical\nclustering partition of G (illustrated as the blue rounded dashed line\nbox in Figure 2). The coding tree T includes all message nodes as leaf\nnodes. Each node a in T corresponds to a partitioning of message\nnodes, with the set Ta = a, ..., v, representing the successor\nnodes of a. The root node A of T has the set T\u2081 = V, indicating no\npartitioning. For each node a in T (excluding \u03bb), the height h(a) is\none less than that of its parent node. The root node A has a height\nof 0. The height of T is the maximum height among all nodes in T.\nDefinition 2.5. (1D SE). For a messages graph G = (V, E) with n\nvertices, its 1D SE is defined as:\n$H^{(1)}(G) = - \\sum_{i=1}^{n} \\frac{d_i}{2m} log \\frac{d_i}{2m}$,\n(4)\nwhere di represents the weighted degree of node i, and m denotes\nthe sum of the weighted degrees of all nodes.\nDefinition 2.6. (2D SE). For a messages graph G = (V, E) with n\nvertices, P = {p1, ..., PL } is a partition of V, pj represents an event\ncluster in the message graph. The 2D SE is defined as:\n$H^{(2)}(G) = - \\sum_{j=1}^{L} [\\frac{n_j}{m} log_2 \\frac{n_j}{m} + \\sum_{i=1}^{V_j} \\frac{d_i}{V_j} log_2 \\frac{d_i}{V_j}] + \\frac{P_{cutj}}{V_j}log_2 \\frac{P_{cutj}}{m^2}$,\n(5)\nwhere nj is the number of nodes in partition pj, $d'$ is the weighted\ndegree of the ith node in pj, Vj is the sum of the weighted degrees\nof all nodes in partition pj, and Pcut; is the sum of the weights of\nthe cut edges in pj."}, {"title": "3 METHODOLOGY", "content": "In this section, we provide a detailed description of ADP-SEMEvent.\nThe entire framework is illustrated in Figure 2. The private message\ngraph construction stage primarily utilizes our proposed adaptive\ndifferentially private strategy (introduced in Section 3.2), combined\nwith 1D SE and relevant attributes for constructing the private\nmessage graph (discussed in Section 3.3). The private message graph\nclustering stage involves a 2D SE minimization algorithm based on\noptimal subgraphs (explained in Section 3.4)."}, {"title": "3.1 Problem Formalization", "content": "Given a series of social messages m1,..., my forming a message\ngraph G = (V, E), where the node set V = {m1,..., mN} and the"}, {"title": "3.2 Adaptive Differentially Private Strategy", "content": "This section will introduce our mixed sensitivity differentially pri-\nvate strategy and provide proof that this strategy satisfies ($\\epsilon$, \u03b4)-DP\nin the worst-case scenario."}, {"title": "3.2.1 Mixed Sensitivity Strategy", "content": "To prevent the waste of privacy\nbudget e caused by the global sensitivity being much greater than\nthe local sensitivity in a specific data set, we design a mixed sen-\nsitivity strategy to prevent the waste of privacy budget and the\naddition of unnecessary noise.\nIn Equation 2, Sglobal refers to the maximum difference between\nthe results of a query for any two different data records in any data\nset. Sglobal is independent of the data set and is related only to the\ncalculation method itself. Slocal removes the restriction of any data"}, {"title": "Zhiwei Yang, et al.", "content": "set from the definition of global sensitivity and only considers the\ncurrent data set. Slocal can be obtained through a limited number\nof calculations. In general, we can not directly use Slocal in the\nLaplace mechanism because if a malicious attacker knows the local\nsensitivity of a function f on a specific dataset, they can still infer\nsome information about the dataset [31]. Therefore, Slocal must be\nsmoothed to prevent the malicious attacker from deducing the local\nsensitivity. This is achieved using smooth sensitivity [31], denoted\nas Ssmooth), which is calculated as:\n$S_{smooth} = 2exp(-\\frac{d}{\\epsilon} \\cdot log(\\frac{1}{\\delta})) \\cdot S_{local}$,\n(6)\nwhere d is typically set to 1/|D|\u00b2(|D| is the size of D).\nThen, we design the mixed sensitivity (Smixed) strategy. Smixed\nis calculated as follows:\n$S_{mixed} = min\\{S_{global}, S_{smooth}\\}$.\n(7)\nWith the privacy budget e unchanged, our strategy can automati-\ncally determine fitness sensitivity based on daily events to achieve\nadaptive noise perturbation."}, {"title": "3.2.2 Differential Privacy Proof", "content": "We prove that our strategy worst-\ncase satisfies (\u03b5, \u03b4)-DP. This entails demonstrating that global sensi-\ntivity satisfies e-DP and that smooth sensitivity satisfies (\u03b5, \u03b4)-DP.\nFor Ssmooth, Nissim et al. [31] have provided a rigorous proof\nthat using Ssmooth for the Laplace mechanism always satisfies (\u20ac, \u03b4)-\nDP, regardless of whether global sensitivity can be found. Where d\nrepresents the probability of failure, and in our strategy, 8 = 1/|D|2,\nis a small probability. For Sglobal, we provide the following proof:\nPROOF. For D and D', PD and PD' represent the probability dis-\ntributions of message similarities calculated on their respective\ndatasets. For any two messages mi and mj in the dataset, the sim-\nilarity is represented as z = Cos(mi, mj) + Y, where Y follows\nLaplace distribution with scale Smixed/e and mean 0. Therefore,\nwe have:\n$P_D(z) = \\frac{\\epsilon}{2S_{mixed}} exp(-\\frac{\\epsilon |Cosp(m_i, m_j) \u2013 z|}{S_{mixed}})$, (8)\n$P_{D'}(z) = \\frac{\\epsilon}{2S_{mixed}} exp(-\\frac{\\epsilon |Cos_{\\theta'}(m_i, m_j) \u2013 z|}{S_{mixed}})$. (9)\nNext, verify whether it complies with differential privacy through\ndistribution:\n$\\frac{P_{D(z)}}{P_{D'(z)}} = \\frac{exp(-\\frac{\\epsilon |Cosp(m_i, m_j) \u2013 z|}{S_{mixed}})}{exp(-\\frac{\\epsilon |Cos_{\\theta'}(m_i, m_j) \u2013 z|}{S_{mixed}})} = exp( \\frac{\\epsilon(|Cos_{\\theta'}(m_i, m_j) \u2013 z| - |Cosp(m_i, m_j) \u2013 z|)}{S_{mixed}})$, (10)\n$\\leq exp(\\frac{\\epsilon(|Cos_{\\theta'}(m_i, m_j)| - |Cosp(m_i, m_j)|)}{S_{mixed}})$, (11)\n$\\leq exp(\\frac{\\epsilon}{S_{mixed}})$, (12)\n$\\leq exp(\\epsilon)$. (13)\n\u03a0\nIn the process of proving, the last two steps follow from the\ntriangle inequality. According to Equation 1, our strategy satisfies\ne-DP. In summary, our strategy worst-case satisfies (\u20ac, \u03b4)-DP."}, {"title": "3.3 Private Message Graph Synthesis", "content": "To ensure the generation of rich and private message graphs, we\npropose a method of message graph synthesis with edges Es based\non SE and edges Ea based on attribute. We employ our proposed\nadaptive differentially private strategy to protect privacy while\ncomputing edge weights.\nWe summarize our method into Algorithm 1, termed Message\nGraph Synthesis under Adaptive Differentially Private Strategy. For\nEs (lines 3-14), we link each message to its k nearest neighbors,\nwhere the distance utilizes cosine similarity under the adaptive\ndifferentially private strategy:\n$Cos_{Lap}(m_i, m_j) = \\frac{m_i m_j}{||m_i|| ||m_j||} + Lap(\\frac{S_{mixed}}{\\epsilon})$,\n(14)"}, {"title": "3.4 Event Detection via 2D SE Minimization", "content": "To efficiently cluster on the noisy message graph G, we design an\nalgorithm named 2D SE minimization based on optimal subgraphs.\nExisting approaches used a greedy approach (vanilla 2D SE mini-\nmization [19]) to repeatedly merge any two nodes in the encoding\ntree T for 2D SE minimization, which is time-consuming on large\ngraphs. Later, an incremental method reduces runtime overhead\nby sequentially dividing large message graphs into multiple sub-\ngraphs [4]. Nevertheless, such methods addressed the problem of\nhigh time complexity, but simply dividing the subgraphs is unwise.\nThe initial partitioning is crucial because it may force strongly re-\nlated message nodes to be divided into different parts, ultimately\npreventing them from merging into the same cluster, as shown\nin Figure 3 (a). So, we prevent strongly correlated message nodes\nfrom being forcibly separated by constructing optimal subgraphs,\nas illustrated in Figure 3 (b).\nSpecifically, as shown in Algorithm 2, assuming a graph G =\n(V, E), partition P = {p1,...,pm} (where pm C V, pin pj = 0),\nand subgraph size q as input. In each iteration, we first construct a\nsuper-graph based on the original graph and the initial partition\n(lines 3-5), treating nodes in the same partition as a single new\nnode and using the sum of the cut edges between partitions as the\nedge weight between new nodes. Then, using a greedy approach,\nwe obtain the optimal subgraph (lines 6-12), attempting to include\nedges with higher weights in the same subgraph as much as possible.\nFinally, we perform 2D SE minimization on each subgraph (lines\n13-17), achieving the final clustering result based on optimizing\neach encoding tree."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate the event detection and privacy pro-\ntection capabilities of ADP-SEMEvent. Specifically, our goal is to\nanswer the following questions: Q1: How does ADP-SEMEvent\nperform compared to other methods? Q2: What is the capability\nof ADP-SEMEvent in privacy protection? Q3: What is the impact\nof privacy budget e on ADP-SEMEvent\u2019s results? Q4: How is the\nnew 2D SE minimization algorithm executed? Q5: How does the\nadaptive differential privacy strategy work?"}, {"title": "4.1 Experimental Setup", "content": "Datasets. We experiment on two large public Twitter datasets.\nEvent2012 [28] has 68,841 English messages, including 503 events;\nEvent2018 [27] has 64,516 French messages, including 257 events.\nWe employ the time-splitting method proposed by Cao et al. [4]\nand Ren et al. [37] to partition the dataset. Specifically, Event2012\nis divided into Mo\nM21, a total of 22 blocks; Event2018 is\ndivided into Mo,..., M16, a total of 17 blocks. Our model is unsu-\npervised and does not require a training set, but some baselines are\nsupervised, so the first day is the training set."}, {"title": "4.2 Overall Performance (Q1)", "content": "Tables 1 and 2 present the evaluation results of Event2012 and\nEvent2018 in an open environment, demonstrating the superior\nperformance of ADP-SEMEvent. For instance, the results from\nEvent2012 show that in most cases, when e = None, ADP-SEMEvent\noutperforms the current SOTA model HISEvent. Optimally, the ARI\nin M9 increases from 0.65 to 0.79, representing a 21.5% improve-\nment. When \u20ac = 10 or 15, compared to the privacy-preserving mod-\nels DPG-SEMEvent and ADP-Spectral Clustering, ADP-SEMEvent\nsurpasses the baselines on all metrics. The comparison with DPG-\nSEMEvent indicates that our adaptive differential privacy strategy"}, {"title": "Zhiwei Yang, et al.", "content": "effectively controls noise, and the comparison with ADP-Spectral\nClustering highlights that our Algorithm 2 can cluster private\ngraphs more effectively, making it a more efficient unsupervised\nmethod. In summary, ADP-SEMEvent has three characteristics: 1)\nit does not require the specification of the total number of events,\nmaking it unsupervised; 2) it emphasizes privacy protection; 3) it\nexhibits excellent performance and robustness. No baseline simul-\ntaneously satisfies all of these criteria.\nTable 3 shows the evaluation results for Event2012 and Event2018\nin a closed environment. When e=None on large datasets, our ADP-\nSEMEvent achieves SOTA performance. Performance decreases for\ne=10 and e=15, but it still outperforms DPG-SEMEvent and ADP-\nSpectral Clustering. Test results for Event2012 indicate that ADP-\nSEMEvent remains competitive; however, the results for Event2018\nshow lower performance, possibly due to the closer proximity of\nlocal sensitivity and global sensitivity in the Event2018 dataset."}, {"title": "4.3 Security Analysis (Q2)", "content": "We conduct a security analysis for all models. For Eventx, KPGNN,\nand QSGNN, are supervised. Generally, machine learning models\ntend to exhibit memorization, enabling malicious attackers to lever-\nage membership inference attacks to obtain data from the training\nset [40]. For ADP-SEMEvent and other baselines, unsupervised\nclustering methods are used, eliminating the need for training data.\nConsequently, the risk of membership inference attacks is greatly\nreduced. However, attackers can still design attribute inference\nattacks [13, 48] to deduce sensitive information about messages,\nsuch as relationships and locations.\nTo assess ADP-SEMEvent\u2019s protection capabilities, we design at-\ntribute inference attack experiments, selecting *Person* and *GPE*\n(Geopolitical Entity) as the attack target. We manually select 535\npieces of data containing sensitive attributes from Event2012. \u03a4\u03bf\ncomprehensively assess security, we design binary and multi-class\nattack scenarios. Specifically, for *Person*, we only consider whether\nthe data contains the *Person* attribute, making it a binary classifi-\ncation problem. We use F1 and precision as evaluation metrics. For\n*GPE*, which includes 8 categories, it is a multi-classification prob-\nlem. We use accuracy and AUC as evaluation metrics. For BERT and\nSBERT, we directly use embeddings as features of the messages; for\nother models, we use a simple Node2Vec [14] model to obtain node\nembeddings from the graph; 30% of the data is used as the training\nset. We choose support vector product (SVM), logistic regression\n(LR), and multi-layer perceptron (MLP) as attack models.\nOur test results are shown in Table 4. Since BERT and SBERT\ndirectly convert messages into embeddings, sensitive information is"}, {"title": "Zhiwei Yang, et al.", "content": "directly exposed in the embeddings, leading to the worst evaluation\nmetrics. Although HISEvent\u2019s probability of a successful attack is\nlower than that of directly using embeddings, its privacy protection\ncapabilities remain limited due to a lack of further processing of\nsensitive information. For ADP-SEMEvent and DPG-SEMEvent, the\nattack model\u2019s effectiveness on these models is relatively low, indi-\ncating that the noise provided some degree of protection. However,\nADP-SEMEvent outperforms DPG-SEMEvent in event detection\ntasks, demonstrating its higher application value."}, {"title": "4.4 Hyperparameter Sensitivity (Q3)", "content": "To validate the sensitivity of ADP-SEMEvent to the privacy budget\ne parameter, we conduct tests using Event2012 in an open environ-\nment. We incrementally increase the value of the privacy budget e\nfrom 1 to 10 with a step size of 1, then run the ADP-SEMEvent to\nobserve its final performance. This test is essential as it provides a\nstraightforward reflection of the relationship between the privacy\nbudget e and the model performance, aiding algorithm users in\nbalancing privacy protection levels with detection performance in\npractical applications. Our test results are illustrated in Figure 4.\nAnalysis of the 4 cases indicates that the privacy budget e effectively\ncontrols the noise level. A smaller e adds more noise, resulting in\nlower data utility, while a larger e results in less noise and higher\nmodel performance."}, {"title": "4.5 Ablation Study (Q4)", "content": "We compare the model\u2019s performance before and after optimization\nto validate the effectiveness of the 2D SE minimization algorithm"}, {"title": "4.6 Noise Analysis (Q5)", "content": "To verify the noise level control by the adaptive sensitivity strategy,\nwe use sensitivity as an indicator of noise level, where a higher\nsensitivity indicates greater perturbation to the original data. We\nconduct statistical analyses of noise levels under different privacy\nbudgets and across different datasets. The results are shown in\nFigure 6. We find that when the privacy budget \u0454 \u2265 5, our mixed\nsensitivity begins to take effect, avoiding noise waste. In a contin-\nuous 21-day simulation, the mixed sensitivity can determine the\nmost appropriate sensitivity based on the current day\u2019s situation,\nbalancing performance and privacy."}, {"title": "5 RELATED WORK", "content": ""}, {"title": "5.1 Differential Privacy", "content": "Differential privacy was first introduced by Dwork et al. [6]. The\nmost commonly used method of differentially private is the Laplace\nmechanism [9], which adds appropriate noise to meet e-DP by ana-\nlyzing the global sensitivity of the query function. Subsequently,\nDwork et al. [7] proposed approximate differential privacy, which\nrelaxes the strict requirement of e-DP by using the Gaussian mech-\nanism to add noise, improving the applicability. To address the\nchallenge of computing global sensitivity, Dwork et al. [8] pro-\nposed the Propose-Test-Release framework, while Nissim et al. [31]\nintroduced the smooth sensitivity and Sample and Aggregate frame-\nworks. Nowadays, due to the growing problem of privacy data\nleakage, many scholars utilize differential privacy to protect data.\nFor example, in private clustering [16, 17], private PageRank [10],\nprivate data release or synthesis [22, 38, 47], and application in\nrecommender system [45], among others. However, existing DP\nmethods do not effectively adapt to the addition of noise based on\neach day\u2019s events."}, {"title": "5.2 Social Event Detection", "content": "Existing research [4, 32, 34, 38] typically formalizes the task of\nsocial event detection as clustering relevant messages from social"}, {"title": "Zhiwei Yang, et al.", "content": "media sequences to represent events. We divide social event detec-\ntion methods into three categories based on the model input, i.e.,\nattribute-based, content-based, and Hybrid methods. 1) Attribute-\nbased methods [15, 42] require predefined rules or patterns and then\nidentify events by matching rules. Their drawback is the inability to\ncapture complex event features accurately, and updating rules for\nnewly emerged event types may be required, resulting in lower per-\nformance and robustness. 2) Content-based methods [41, 44] mostly\nrely on natural language processing to model and analyze content.\nTheir detection performance heavily depends on content modeling.\nHowever, due to the complexity and variability of real-world con-\ntent, methods relying solely on content modeling have not shown\ngood robustness. 3) Hybrid methods [3, 20, 21, 32, 34, 37, 39] utilize\nGNNs for modeling, effectively combining content and attributes\ninto heterogeneous graphs to achieve better performance. However,\nsince GNNs contain rich node information, they may inevitably\ninclude sensitive data that attackers should not be able to access,\nmaking privacy protection crucial for the models."}, {"title": "6 CONCLUSION", "content": "In this work, we recognize the importance of privacy protection and\nhave explored how to conduct social event detection under the re-\nquirements of privacy protection. We propose a novel unsupervised\nsocial event detection framework, ADP-SEMEvent, implementing\nadaptive privacy protection. The adaptive differentially private\nstrategy we proposed maximizes the utilization of the privacy bud-\nget and achieves a good balance between privacy and accuracy.\nAt the same time, the unsupervised approach eliminates the need\nto determine the number of events in advance, providing better\nrobustness in real-world applications. Experiments show that ADP-\nSEMEvent can protect privacy while achieving satisfactory results.\nSince PLMs have a significant impact on both performance and\nprivacy, we will explore efficient and private PLMs in future work."}]}