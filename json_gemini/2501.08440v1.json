{"title": "FARE: A DEEP LEARNING-BASED FRAMEWORK FOR RADAR-BASED FACE\nRECOGNITION AND OUT-OF-DISTRIBUTION DETECTION", "authors": ["Sabri Mustafa Kahya", "Boran Hamdi Sivrikaya", "Muhammet Sami Yavuz", "Eckehard Steinbach"], "abstract": "In this work, we propose a novel pipeline for face recog-\nnition and out-of-distribution (OOD) detection using short-\nrange FMCW radar. The proposed system utilizes Range-\nDoppler and micro Range-Doppler Images. The architecture\nfeatures a primary path (PP) responsible for the classifica-\ntion of in-distribution (ID) faces, complemented by interme-\ndiate paths (IPs) dedicated to OOD detection. The network is\ntrained in two stages: first, the PP is trained using triplet loss\nto optimize ID face classification. In the second stage, the\nPP is frozen, and the IPs-comprising simple linear autoen-\ncoder networks are trained specifically for OOD detection.\nUsing our dataset generated with a 60 GHz FMCW radar, our\nmethod achieves an ID classification accuracy of 99.30% and\nan OOD detection AUROC of 96.91%.\nIndex Terms- Facial authentication, out-of-distribution\ndetection, 60 GHz FMCW radar, deep neural networks", "sections": [{"title": "1. INTRODUCTION", "content": "Short-range radars have gained significant popularity in var-\nious applications due to their cost-effectiveness, privacy-\npreserving nature, and robustness to environmental condi-\ntions. Unlike optical sensors, they do not capture identifiable\nvisual data, making them ideal for privacy-sensitive environ-\nments. These features have led to their widespread use in\napplications such as human presence detection, activity clas-\nsification, people counting, gesture recognition, and heartbeat\nestimation [1-5]. In this study, we propose a face recognition\nand out-of-distribution (OOD) detection framework.\nOOD detection [6\u20139] is essential for the secure and reli-\nable deployment of deep learning models, as it prevents over-\nconfident predictions on samples that lie away from the train-\ning data. Traditional classifiers can be easily misled by data\noutside their known classes, but OOD detection helps identify\nand reject unknown data.\nFARE functions both as a human face classifier for in-\ndistribution (ID) faces and as an OOD detector for OOD\nfaces. Its architecture simultaneously leverages Range-\nDoppler Images (RDIs) and micro Range-Doppler Images\n(micro-RDIs). As depicted in Figure 1, the network functions\nas a classifier along the primary path (PP). For OOD detec-\ntion, the network utilizes intermediate paths (IPs) that branch\noff from each layer of the PP. Each IP plays a crucial role in\nfiltering out OOD faces, which is the primary focus of our\nstudy. A typical OOD detector employs a scoring function\nalong with a predefined threshold to classify test samples. If\nthe score of a test sample falls below the threshold, it is clas-\nsified as ID; if it exceeds the threshold, it is labeled as OOD.\nIn our study, we derive the scores from the reconstruction\nerrors produced by the IPs. Our key contributions:\n\u2022 We introduce a unique architecture that incorporates\nboth PP and IPs. The PP component is responsible for\naccurately classifying IDs, while the IPs are designed\nfor OOD detection. Each IP consists of a simple linear\nautoencoder (encoder-decoder) network. Our training\nprocess is divided into two stages. In the first stage,\nwe train the classifier, focusing on optimizing the PP\nfor accurate face recognition. In the second stage, we\nfreeze the PP and train only the reconstruction-based\nintermediate paths (IPs) for OOD detection. This ap-\nproach allows us to achieve both a highly accurate hu-\nman face classifier and an effective OOD detector.\n\u2022 We propose a novel loss function optimized in two\nstages: The first stage minimizes the classifier loss us-\ning a triplet loss in the PP for accurate ID classification.\nThe second stage minimizes the reconstruction losses\nfrom the IPs for OOD detection, with six reconstruc-\ntion losses corresponding to the IPs at the end of each\nlayer. FARE achieves an average ID human face classi-\nfication accuracy of 99.30% and an average AUROC of\n96.91% for OOD detection. Also, FARE outperforms\nstate-of-the-art (SOTA) OOD detection methods across\ncommonly used evaluation metrics."}, {"title": "2. RELATED WORK", "content": "Several studies have explored radar-based face authentication.\n[10] utilized a deep neural network (DNN) in combination\nwith a 61 GHz mmWave radar to classify facial data from\neight subjects. It achieved a classification accuracy of 92%.\nIn [11], researchers used CNNs with the same 61 GHz radar\nto identify faces from 30 cm away. They tested the model\nwith and without cotton masks. The model was first trained\non unmasked faces, then adjusted to recognize masked faces,\nand showed results for both situations. Further advancements\ninclude the deployment of a radar system with 32 transmit\n(Tx) and 32 receive (Rx) antennas, using a dense autoencoder\nfor one-class verification across 200 individual faces. This\nmethod was enhanced through the integration of a convolu-\ntional autoencoder paired with a random forest classifier, im-\nproving upon the original system's performance [12, 13]. [14]\nintroduced a one-shot learning approach based on a Siamese\nnetwork architecture with a 61 GHz FMCW radar, which in-\nvolved eight participants and reported a classification accu-\nracy of 97.6%. While these studies have made significant im-\nprovements in classification accuracy, they overlook detecting\nOOD samples, which is essential for reliability and security.\nThe OOD detection concept was first introduced in [15],\nwhere maximum softmax probabilities were used to distin-\nguish OODs from IDs, based on the observation that OOD\ninstances generally have lower softmax scores. To improve\nupon this, ODIN [16] utilized input perturbations and tem-\nperature scaling on logits to amplify the softmax scores of\nID samples. MAHA [17] employed Mahalanobis distance\nfor OOD detection, utilizing representations from intermedi-\nate network layers, a strategy also used by FSSD [18]. [19]\nproposed an energy-based method leveraging the logsumexp\nfunction. ReAct [20] introduced a truncation method for acti-\nvations in the penultimate layer, which is compatible with var-\nious existing OOD detection techniques. GradNorm [21] pro-\nposed a method to differentiate between ID and OOD samples\nby analyzing the norm of gradients. Additionally, MaxLogit\nand KL-matching methods from [22] offered alternatives, us-\ning maximum logit scores and minimum KL divergence, re-\nspectively. Approaches like OE [23] and OECC [24] used\nlimited OOD samples during training, claiming that minimal\nOOD exposure helps distinguish between ID and OOD data.\nRadar-based OOD detection has seen notable advance-\nments. [25] used a 60 GHz FMCW radar to identify moving\nobjects as OOD compared to walking people. MCROOD [26]\nimproved on this by incorporating a multi-class framework\nthat also distinguishes between sitting and standing individ-\nals. [27] introduced a multi-encoder, multi-decoder network\nfor concurrent human presence and OOD detection. [28] fo-\ncused on human activity classification while detecting OODs."}, {"title": "3. RADAR SYSTEM DESIGN", "content": "Our radar chipset has one Tx and three Rx antennas. The\nTx antenna emits chirp signals captured by the Rx antennas.\nThese signals are mixed and low-pass filtered to produce the\nintermediate frequency (IF) signal, which is then digitized\ninto raw Analog-to-Digital Converter (ADC) data, preparing\nit for subsequent processing. Our model leverages both RDIS\nand micro-RDIs as inputs. For the RDI, Range-FFT is ap-\nplied to the fast-time signal to extract range, complemented\nby mean removal and the Moving Target Identification (MTI)\nprocess, which eliminates static targets. Doppler-FFT is then\napplied to the slow-time signal to capture phase variations.\nFor the micro-RDI, Range-FFT is employed, stacking eight\nrange spectrograms and applying mean removal to both fast\nand slow-time signals to minimize noise. Sinc filtering is\nused to enhance target detection, and Doppler-FFT along the\nslow-time dimension produces the micro-RDI. Lastly, we ap-\nply E-RESPD [27] to improve the detection of facial move-\nments in both RDIs."}, {"title": "4. PROBLEM STATEMENT AND FARE", "content": "FARE simultaneously addresses face recognition and OOD\ndetection. While many studies have explored face recogni-\ntion with various sensors, most focus primarily on classifica-\ntion. Our study emphasizes eliminating OOD faces without\ncompromising the accuracy of ID face classification.\nThe PP comprises initial modality-specific feature extrac-\ntor blocks and a combined feature extractor block. The initial\nextractors, consisting of convolutional layers, are separately\ndesigned for RDIs and micro-RDIs, ensuring comprehensive\nfeature extraction from both modalities. After these initial\nblocks, the intermediate features from both modalities are\nmerged and passed to the combined feature extractor block.\nThis block, containing convolutional and fully connected lay-\ners, generates final embeddings for triplet training, which en-\nables the accurate classification of five ID faces. The PP is\ntrained with triplet loss:\n$L_{PP} = \\frac{1}{b} \\sum_{i=1}^{b} max(||t_{e,a}^{+(i)} - t_{e,p}^{+(i)}||_2 - ||t_{e,a}^{+(i)} - t_{e,n}^{+(i)}||_2 + m, 0)$,\nwhere $t_{e,a}^{+(i)}$, $t_{e,p}^{+(i)}$, and $t_{e,n}^{+(i)}$ represent the triplet embeddings cor-\nresponding to the anchor (a), positive (p), and negative (n)\nsamples, respectively. Here, b denotes the batch size, and m\nis the margin, which is set to 2.\nEach IP uses a simple linear autoencoder architecture\nand is integrated at the end of each PP layer, including those\nwithin the initial modality-specific extractors. IPs are de-\nsigned explicitly for OOD detection, intercepting OOD sam-\nples before they reach final classification. By positioning\nthe IPs at the end of each PP layer, we leverage the unique\ninformation from each intermediate feature to effectively stop\nOOD samples. The IPs are trained with mean absolute error\n(MAE) loss. Our network comprises four main layers, but\nsince the first two layers process two modalities separately,\nLayer 1 and Layer 2 each contain two sublayers. This results\nin a total of six layers, and consequently, we have six MAE\nlosses:"}, {"title": "4.1. OOD Detection & Human Face Classification", "content": "As is typical in OOD detection, we only use ID samples dur-\ning training. The IPs, which are responsible for OOD de-\ntection, each consist of a simple linear autoencoder with a\nreconstruction-based architecture. Since the IPs are trained\nonly on ID samples, we expect lower reconstruction errors\nfor ID samples than OODs. We set a threshold that ensures\n95% of ID data are correctly classified. During testing, the\nsample is classified as OOD if the total reconstruction error\nor score from the IPs exceeds this predefined threshold. If the\nIPs do not filter the sample (its score is below the threshold,\nindicating it is ID), the sample continues through the PP and\nKNN for the classification of the ID face."}, {"title": "5. EXPERIMENTS AND RESULTS", "content": "For this study, we created a face dataset using Infineon's\nBGT60TR13C 60 GHz FMCW radar sensor. Recordings\nwere captured at a fixed distance of 25 cm from the sensor,\nwith each session lasting 2 minutes. To maintain uniformity,\nparticipants were recorded without any facial accessories.\nData was gathered across different days and at various times\nand featured a range of room environments to introduce back-\nground variability. The dataset comprises ID samples from\nfour males and one female and OOD samples from nine males\nand two females. This resulted in a total of 80964 ID frames\nand 22458 OOD frames. 53536 frames of the ID data used\nfor training, while 27428 for testing. The dataset is accessible\nat here\u00b9, with all participants providing written consent for\ntheir involvement. This work specifically addresses the OOD\ndetection problem in facial recognition systems, which is why"}, {"title": "5.1. Ablation", "content": "We conducted an ablation study to evaluate the impact of\nincorporating Intermediate Paths (IPs) at different layers of\nthe Primary Path (PP) on OOD detection. The study aims\nto demonstrate how utilizing intermediate feature representa-\ntions with IPs enhances OOD detection performance. Table 2\nhighlights that employing IPs at more layers improves OOD\ndetection performance, showing the positive effect of lever-\naging intermediate feature representations in our architecture.\nOur network has four main layers, but includes six IPs be-\ncause the first two layers process two modalities separately.\nThis means that both Layer 1 and Layer 2 each contain two\nsub-layers. For a visual reference, please see Figure 1."}, {"title": "6. CONCLUSION", "content": "This work introduced FARE, a novel pipeline for face recog-\nnition and OOD detection using short-range FMCW radar.\nFARE combines ID face classification with accurate OOD\ndetection by leveraging RDIs and micro-RDIs. The architec-\nture, featuring PP for face recognition and IPs for OOD detec-\ntion, demonstrated its effectiveness through two-stage train-\ning. Experimental results using our 60 GHz FMCW radar\ndataset showed high ID classification accuracy and OOD de-\ntection performance. This method advances OOD detection\nwhile offering a reliable solution for smart home applications."}]}