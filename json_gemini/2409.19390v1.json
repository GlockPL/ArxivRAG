{"title": "Efficient Federated Intrusion Detection in 5G ecosystem using optimized BERT-based model", "authors": ["Fr\u00e9d\u00e9ric Adjewa", "Moez Esseghir", "Le\u00efla Merghem-Boulahia"], "abstract": "The fifth-generation (5G) offers advanced services, supporting applications such as intelligent transportation, connected healthcare, and smart cities within the Internet of Things (IoT). However, these advancements introduce significant security challenges, with increasingly sophisticated cyber-attacks. This paper proposes a robust intrusion detection system (IDS) using federated learning and large language models (LLMs). The core of our IDS is based on BERT, a transformer model adapted to identify malicious network flows. We modified this transformer to optimize performance on edge devices with limited resources. Experiments were conducted in both centralized and federated learning contexts. In the centralized setup, the model achieved an inference accuracy of 97.79%. In a federated learning context, the model was trained across multiple devices using both IID (Independent and Identically Distributed) and non-IID data, based on various scenarios, ensuring data privacy and compliance with regulations. We also leveraged linear quantization to compress the model for deployment on edge devices. This reduction resulted in a slight decrease of 0.02% in accuracy for a model size reduction of 28.74%. The results underscore the viability of LLMs for deployment in IoT ecosystems, highlighting their ability to operate on devices with constrained computational and storage resources.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, numerous technological revolutions have occurred in various fields, notably the emergence of new network architectures. The fifth generation (5G) is particularly noteworthy, offering faster and more scalable services. In addition to enhancing existing services, 5G enables new use cases such as intelligent transportation, connected healthcare, and smart cities, becoming a key element of the Internet of Things (IoT) [23]. However, with these advancements, many security challenges arise from this heterogeneous and densely populated ecosystem. Cyber-attacks in 5G networks are becoming increasingly sophisticated and personalized, requiring the implementation of robust protection systems like intrusion detection systems (IDS). The primary goal of IDS is to identify various types of threats as early as possible to complement the shortcomings of firewalls. An intrusion can be seen as unauthorized activity that may cause damage to the system [11]. There are two main approaches to intrusion detection system: signature-based detection (SIDS) which uses predefined rules as a reference to identify malicious traffic. However, if an attack is not listed, this method is ineffective. On the other hand, anomaly-based detection system learns to recognize normal traffic flows and flags any deviation from the norm as suspicious [17]. Machine learning and deep learning methods have made significant progress and are increasingly used to create new intrusion detection methods [1]. Another significant advancement is large language models which have shown their potential in many fields, including cybersecurity, where they have sometimes outperformed human experts [20]. However, it is essential to assess the risks associated with their use in sensitive tasks like computer security [3].\nIn 5G environments, particularly in monitoring systems, personal information is used, so privacy concerns must be taken seriously. [14] proposed federated learning, which allows training a global model collaboratively among multiple clients while keeping the data on their devices. Only the model parameters are exchanged, maintaining privacy and providing a reliable, scalable, and robust intrusion detection system. Federated learning can be mainly categorized into vertical federated learning, where user data do not share the same features but the observations are related, and horizontal federated learning, where users share the same observations space but with different features. Previous work in the field of intrusion detection relies on machine learning and deep learning approaches, such as random forests (RF), support vector machines (SVM), and gradient boosting (GB). Despite the effectiveness of these methods, they do not comprehensively provide a global security solution for deployment in 5G ecosystems, which are heterogeneous and densely populated. To overcome these limitations, we propose a federated anomaly-based Intrusion Detection System based on a LLM designed from BERT [8], capable of deeply understanding the context of the data. The source code is available on Github.\u00b9\nThe main contributions of this paper are summarized as follows:\n\u2022 A discussion of previous work on security in 5G archi-tectures, with emphasis on intrusion detection systems."}, {"title": "II. RELATED WORK", "content": "5G architectures bring numerous advantages through the services they offer. However, these connected services and applications remain susceptible to attacks aimed at compromising the network. Many studies have been conducted to propose solutions to address these security vulnerabilities.\n[6] presented several solutions to secure the services offered by 5G, highlighting the numerous challenges faced by this technology. User privacy and data protection constitute a major issue that requires attention from researchers. [2] demonstrated that user information could be easily accessible within the network, thereby exposing users to malicious actors. [17] and [11] each analyzed intrusion detection systems (IDS), presenting the foundations, necessity, and implementation methods. [22] proposed an architecture highlighting the deployment of IDS in a 5G ecosystem to provide a reliable security system at all levels. To detect intrusions in the 5G network, [23] proposed an intelligent intrusion detection system to identify attacks in IoT environments using deep learning methods. [26] evaluated machine learning approaches on IID and non-IID partitions. The rapid evolution of technologies and services in 5G has motivated the implementation of federated learning, which enables learning while preserving data privacy. [12] presented the limitations of traditional machine learning and deep learning methods against unknown attacks and proposed the use of autoencoders to analyze the traffic in connected vehicle networks. [27] focused on the challenge of non-IID data, demonstrating its impact on model performance. They showed that the reduction in performance is linked to weight divergence caused by the nature of the data used. However, the proposed solution contradicts the principle of federated learning, although it seems to resolve the issue. [20] and [3] discussed the involvement of large language models (LLMs) in cybersecurity, demonstrating their robustness but also the need to regulate their use to limit potential drawbacks. [1] conducted a study on the use of federated learning in 5G networks as a means of ensuring security while preserving confidentiality, emphasizing the importance of properly handling non-IID data. Based on these foundations, recent works have extended the use of federated architectures by incorporating LLMs. For instance, [24] proposed FeDeRA, an improvement of LoRA for use in a distributed ecosystem. Similarly, [9] proposed an approach to distribute LoRA between the devices and the cloud. However, all these works do not comprehensively cover all aspects related to deploying a security solution for 5G ecosystems. Our work aims to address these shortcomings by proposing a federated anomaly-based intrusion detection system that leverages the power of LLMs, ensuring robust security and user confidentiality."}, {"title": "III. METHODOLOGY", "content": "In this section, we will present the concept of Federated Learning. Following this, we will discuss realistic datasets used in the literature for the simulation of IDS. Then, we will introduce the model we used for detection. Next, we will cover data preparation, tokenization, and the application of linear quantization.\nMachine learning typically involves three main steps: data collection, where a certain amount of data is gathered on a central server; data processing, during which the collected data is cleaned to make it usable; and finally, the design of the learning model based on this dataset. However, data collection quickly raises privacy concerns and violates regulations from organizations such as the European Union's GDPR [10]. To ensure user privacy and data protection, it is necessary to find a way to train AI models while keeping the data on the client device.\nFederated learning addresses these issues by ensuring data privacy, pervasive intelligence in the environment, high flexibility, and good scalability [1]. As illustrated in Fig. 2, federated learning is performed in four main steps:\n1) Distribution of the global model to the edge devices.\n2) Training of local models by the edge devices on their local data.\n3) Transfer of weights from the edge devices to the aggregation server.\n4) Aggregation of the received weights by the server using a specific aggregation strategy.\nproposed FedAvg, a robust algorithm that aggregates parameters received from edge devices while considering the proportion of data used for model training to weight this aggregation and obtain a reliable model. Several algorithms have since been proposed to optimize federated learning performance, whether on the client side or the server side [25]. By using FedAvg in our experiments, we will demonstrate that the approach works with basic algorithm, suggesting that enhanced algorithms could provide even better results.\nNumerous studies present realistic datasets in the field of cybersecurity. However, some publicly available datasets do not realistically simulate certain scenarios that we encounter or may encounter. [7] proposed EdgeIIoTset, a comprehensive and realistic dataset ranked in the top 1% of documents by Web of Science (WoS). For our experiments, we used this dataset in various proportions. The original dataset contains 61 features and 2,219,201 data points, but for speed considerations, in our study we used 30% of the dataset."}, {"title": "C. Model design", "content": "To construct the model, we used BERT [5], which is an encoder model. This model was adapted to our needs to create a model capable of predicting whether a flow is malicious or benign. We modified the base model by retaining only the first four layers of the encoder. The particularity of these lower layers is that they capture features related to syntax in the data they process. For each Transformer layer, we:\n\u2022 Used four encoder blocks instead of the twelve in the base model.\n\u2022 Opted for a hidden size of 256 and intermediate size of 1024, from the rule FFN = 4\u0397 [5].\n\u2022 Considered the condition H%A = 0, leading us to use 4 attention heads instead of twelve.\nWhere H represents the size of the hidden layer, A the number of attention heads, FFN the intermediate layer size and \"%\" the modulo operator. We then added a linear layer followed by a softmax layer at the output of the adapted BERT to perform the classification of the 15 states identified in the dataset. As presented by [8], the model named securityBERT has 11,174,415 parameters and a disk size of 42.63 MB. BERT base is 420MB, so these modifications led to a model size reduction of 89,85%."}, {"title": "D. Data Preparation", "content": "The dataset contains numerical and string entries, which BERT cannot directly understand. Therefore, it was necessary to transform these data types to make them comprehensible to the model. First, we concatenated all the columns from each row of the dataset and then used a hash function to transform them, thereby improving privacy."}, {"title": "E. Tokenization", "content": "It was crucial to build a vocabulary allowing the model to understand the data processed. [21] proposed the Byte-Level Byte-Pair Encoder (BBPE), which enabled us to build this vocabulary by combining two bytes at a time. This method optimally manages the diversity of data and improves the model's ability to interpret nuances in the encoded flows. We ensure that the data processed locally are encrypted and the"}, {"title": "F. Linear quantization", "content": "Linear quantization is a technique used to reduce the memory footprint of any model by lowering the precision requirements for the weights and activations [13]. We employed per-channel linear quantization, where each channel of the weight matrix is quantized independently. This method allows for finer granularity and often leads to better performance compared to per-tensor quantization, where the entire matrix is quantized using a single scale and zero-point.\nDue to its simplicity and efficiency, we used post-training quantization to reduce our model size. This approach is particularly beneficial for resource-limited devices, as smaller and more efficient models are crucial in such environments."}, {"title": "IV. EXPERIMENTATIONS AND DISCUSSION", "content": "In this section, we will present the experimental results obtained with securityBERT in a centralized context to demonstrate the model's effectiveness. Then, we will discuss the results in a federated context where securityBERT was trained collaboratively among edge devices and quantized to detect intrusions. Finally, we compare the results to highlight the model's performance in both contexts."}, {"title": "A. Simulation Setup", "content": "The simulations we conducted were executed using Python 3.10.14 and PyTorch. The computational resources, including a Quadro RTX 6000 GPU with 22.5 GB of memory and Intel(R) Xeon(R) Gold 6128 CPU @ 3.40GHz, were provided by the regional computing center ROMEO [4]. In the federated setup, we simulated heterogeneous data handled by each client using Latent Dirichlet Allocation [16] to reflect real-world scenarios."}, {"title": "B. IDS Based Centralized Learning", "content": "Fig. 3 illustrates the difference in model size after the modifications. Initially, the base model weighed around 420MB, which can be considered somewhat heavy. After retaining only the first four encoder layers, we achieved a reduction of approximately 89.85%, which is quite significant, especially since we aim to deploy the model on edge devices. However, there is potential for further reduction. As mentioned earlier, we applied linear quantization, resulting in an overall model size reduction of 92.76%. This makes the model easily deployable on resource-constrained devices.\nAfter modifying the BERT base model, we evaluated whether this model possesses knowledge about intrusion detection, specifically in relation to the data we are working with. The confusion matrix shown in Fig. 4 demonstrates that the model lacks specific knowledge relevant to our downstream task. The classification results are poor, stemming from the foundational knowledge acquired during the model's pre-training phase.\nWe trained the model to detect 14 different types of attacks, achieving an accuracy of 97.79%. This result is very close to the 98.2% obtained in [8]. The slight difference, however, would be due to the reduction in data volume, as mentioned above. Fig. 5a shows that the original model has an inference"}, {"title": "C. IDS Based Federated Learning", "content": "We simulated a federated environment where local models were trained on simulated edge devices, each having 2 CPU cores, and periodically communicated with a central server for model aggregation. As demonstrated in centralized learning, the model performs well in detecting 14 types of attacks, regardless of the total number of samples for each of them. In this scenario, we chose to focus on the attacks with the highest number of samples. Throughout the rest of the simulation, we address eight classes, detailed in Table II.\nFig. 6 shows the distribution of two random clients from the ten sampled in both IID and non-IID simulations. When the data are IID, all clients possess all classes in approximately the same proportions. This can be interpreted as the network flow through them being similar. However, this scenario is not realistic, which is why we choose to work with non-IID data, utilizing a very low concentration parameter (0.07) to achieve greater realism. With non-IID data, we observe that, unlike in the IID case, clients do not exhibit similar distributions; some clients may lack certain classes, and even when they share classes, the proportions vary. This indicates that the flow through the clients is distinctly different, thus rendering it more realistic.\nFig. 7 illustrates the variation in the global model's accuracy over epochs with a variable set of client and with different number of local epochs. At epoch 0, the aggregation server evaluates the model initialized with random parameters. The figure shows that the model struggles to converge with non-IID data, likely due to the significant differences between the clients' data sets. As a result, at certain epochs, the accuracy of the global model decreases after aggregating newly learned parameters.\nWhen K is large, the model experiences fewer convergence issues and tends to achieve performance closer to that of IID data, with the model reaching approximately 95% to 97% accuracy by the third epoch. Observing the orange curve, which represents clients training locally for only one epoch, we see that the model is highly inconsistent. This suggests that the clients do not have sufficient time to share meaningful"}, {"title": "V. CONCLUSION", "content": "The study presented in this paper demonstrates the effectiveness of large language models in cybersecurity, specifically for intrusion detection. We leveraged BERT, an encoder-type LLM, focusing on the upper layers of the model to perform detection tasks due to their focus on syntactic aspects, which is ideal for our task. We demonstrated that the speed of model convergence is related to the nature of the data distribution. Despite the extreme heterogeneity of data in real 5G ecosystems, it is possible to build a model that provides an effective anomaly-based intrusion detection solution for the devices in that ecosystem. A 5G device can benefit from this model because it is able to effectively identify abnormal traffic. Future work will explore more suitable aggregation techniques based on the nature of the data. Emphasis will be placed on energy efficiency and detecting attacks based on their frequency, speed, and targets."}]}