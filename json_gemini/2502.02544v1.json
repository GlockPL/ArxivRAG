{"title": "ADDRESSING LABEL SHIFT IN DISTRIBUTED LEARNING VIA ENTROPY REGULARIZATION", "authors": ["Zhiyuan Wu", "Changkyu Choi", "Xiangcheng Cao", "Volkan Cevher", "Ali Ramezani-Kebrya"], "abstract": "We address the challenge of minimizing true risk in multi-node distributed learning.\u00b9 These systems are frequently exposed to both inter-node and intra-node label shifts, which present a critical obstacle to effectively optimizing model performance while ensuring that data remains confined to each node. To tackle this, we propose the Versatile Robust Label Shift (VRLS) method, which enhances the maximum likelihood estimation of the test-to-train label density ratio. VRLS incorporates Shannon entropy-based regularization and adjusts the density ratio during training to better handle label shifts at the test time. In multi-node learning environments, VRLS further extends its capabilities by learning and adapting density ratios across nodes, effectively mitigating label shifts and improving overall model performance. Experiments conducted on MNIST, Fashion MNIST, and CIFAR-10 demonstrate the effectiveness of VRLS, outperforming baselines by up to 20% in imbalanced settings. These results highlight the significant improvements VRLS offers in addressing label shifts. Our theoretical analysis further supports this by establishing high-probability bounds on estimation errors.", "sections": [{"title": "INTRODUCTION", "content": "The classical learning theory relies on the assumption that data samples, during training and testing, are independently and identically distributed (i.i.d.) drawn from an unknown distribution. However, this i.i.d. assumption is often overly idealistic in real-world settings, where the distributions of training and testing samples can differ significantly and change dynamically as the operational environment evolves. In distributed learning (Kim et al., 2022; Wen et al., 2023; Ye et al., 2023; Luo et al., 2023), where nodes retain their own data without sharing, these discrepancies across nodes become more pronounced, further intensifying the learning challenge (Rahman et al., 2023; Wang et al., 2023).\nLabel shifts (Lipton et al., 2018; Garg et al., 2022; Mani et al., 2022; Zhou et al., 2023) represent a form of distributional discrepancy that arises when the marginal distribution of labels in the training set differs from that in the test set, i.e., $p_{te} (y) \\neq p_{tt}(y)$, while the conditional distribution of features given labels, $p(x|y)$, remains largely stable across both datasets. Label shifts commonly manifest both inter-node and intra-node, complicating the learning process in real-world distributed learning scenarios. However, a commonly used learning principle in this distributed setting, empirical risk minimization (ERM) (Kur et al., 2024), operates under the assumption that the training and test distributions are"}, {"title": "DENSITY RATIO ESTIMATION AND IMPORTANCE WEIGHTED-ERM", "content": "Density ratio estimation Density ratio estimation for label shifts has been addressed by methods such as solving linear systems (Lipton et al., 2018; Azizzadenesheli et al., 2019) and minimizing distribution divergences (Garg et al., 2020), primarily in the context of a single node. Lipton et al. (2018); Azizzadenesheli et al. (2019); Garg et al. (2020) assumed the conditional distribution $p(x|y)$ remains fixed between the training and test datasets, while the label distribution $p(y)$ changes. Black Box Shift Estimation (BBSE) (Lipton et al., 2018; Rabanser et al., 2019) and Regularized Learning under Label Shift (RLLS) (Azizzadenesheli et al., 2019) are confusion matrix-based methods for estimating density ratios in label shift problems. While BBSE has been shown consistent even when the predictor is not calibrated, its subpar performance is attributed to information loss inherent in using confusion matrices (Garg et al., 2020). To overcome this, Garg et al. (2020) has introduced the MLLS, resulting in significant improvements in estimation performance, especially when combined with post-hoc calibration methods like BCT (Shrikumar et al., 2019). This EM algorithm based MLLS method (Saerens et al., 2002; Garg et al., 2020) is concave and can be solved efficiently.\nImportance Weighted-ERM Classical ERM seeks to minimize the expected loss over the training distribution using finite samples. However, when there is a distribution shift between the training and test data, the objective of ERM is not to minimize the expected loss over the test distribution, regardless of the number of training samples. To address this, IW-ERM is developed (Shimodaira, 2000; Sugiyama et al., 2006; Byrd & C. Lipton, 2019; Fang et al., 2020), which adjusts the training loss by weighting samples according to the density ratio, i.e., the ratio of the test density to the training density. Shimodaira (2000) has shown that the IW-ERM estimator is asymptotically unbiased under certain conditions. Building on this, Ramezani-Kebrya et al. (2023b) have recently introduced Federated IW-ERM, which incorporates density ratio estimation to handle covariate shifts in dis-tributed learning. However, this approach has limitations, as it does not address label shifts and the density ratio estimation method poses potential privacy risks.\nIn this work, we focus on label shifts and propose an IW-ERM framework enhanced by our VRLS method. We show that our IW-ERM with VRLS performs comparably to an upper bound that utilizes true density ratios, all while preserving data privacy across distributed data sources. This approach effectively addresses both intra-node and inter-node label shifts while ensuring convergence in probability to the overall true risk minimizer."}, {"title": "VERSATILE ROBUST LABEL SHIFT: REGULARIZED RATIO ESTIMATION", "content": "In this section, we introduce the Versatile Robust Label Shift (VRLS) method for density ratio estimation in a single-node setting, which forms the basis of the IW-ERM framework. To solve the optimization problem of IW-ERM, each node k requires an accurate estimate of the ratio:\n$r_k(y) = \\frac{\\sum_{l=1}^{K} p_l(y)}{P(y)}$   (1)\nwhere $p_l(y)$ and $P(y)$ represent the test and training label densities, respectively. To improve clarity and avoid over-complicating notations, we first consider the scenario where we have only one node under label shifts and then extend to multiple nodes. In a single-node label shift scenario, the goal is to estimate the ratio $r(y) = p_{te} (y)/p_{tt}(y)$. Following the seminal work of Garg et al. (2020), we formulate density ratio estimation as a Maximum Likelihood Estimation (MLE) problem by constructing an optimization problem based on Kullback-Leibler"}, {"title": "VRLS FOR MULTI-NODE ENVIRONMENT", "content": "We now extend VRLS to the multi-node environment, taking into account the privacy and communication requirements. This extension naturally aligns with the concept of IW-ERM, effectively integrating these considerations into the multi-node learning paradigm. We consider multiple nodes where each node has distinct training and test distributions. The goal here is to train a global model that utilizes local data and addresses overall test error. In this setup, each node uses its local data to estimate the required density ratios, as outlined in Section 3, and shares only low-dimensional ratio information, without the need to share any local data."}, {"title": "RATIO ESTIMATION BOUNDS AND CONVERGENCE RATES", "content": "In this section, we present bounds on ratio estimation and convergence rates for the finite sample errors incurred during the estimation, as further discussed in Appendices E, F. In practice, we only have access to a finite number of labeled training samples, ${ (x_i, y_i) }_{i=1}^{n_{tr}}$, and a finite number of unlabeled test samples, ${x_j}_{j=1}^{n_{te}}$. These samples serve to compute the following estimates:\n$\\hat{\\theta}_{n_{tr}} = arg \\min_{\\Theta \\in \\Theta} \\frac{1}{n_{tr}} \\sum_{i=1}^{n_{tr}} \\ell(f_{\\theta}(x_i), y_i) + \\zeta \\Omega(f_{\\theta})$\nand $\\hat{r}_{n_{te}} = arg \\max_{r \\in \\mathcal{R}} \\frac{1}{n_{te}} \\sum_{j=1}^{n_{te}} log ( f_{\\hat{\\theta}}(x_j)^T r )$.\nWe will show that the errors of these estimates can be controlled. The following assumptions are necessary to establish our results.\nAssumption 5.1 (Boundedness). The data and the parameter space \u0398 are bounded, i.e, there exists $b_x, b_{\\Theta} > 0$ such that\n$\\forall x \\in \\mathcal{X}, ||x||_2 \\leq b_x$\nand\n$\\forall \\theta \\in \\Theta, ||\\theta||_2 \\leq b_{\\Theta}$.\nAssumption 5.2 (Calibration). Let $0^*$ be as defined in Equation (4). There exists $\\mu > 0$ such that\n$\\mathbb{E} [f_{\\theta^*}(x) f_{\\theta^*}(x)^T] \\geq \\mu I_m$.\nThe calibration Assumption 5.2 first appears in (Garg et al., 2020). It is necessary for the ratio estimation procedure to be consistent and we refer the reader to Section 4.3 of Garg et al. (2020) for more details. We further need Assumption 5.1 because, unlike (Garg et al., 2020), the empirical estimator $\\hat{r}_{n_{te}}$ is estimated using another estimator $\\hat{\\Theta}_{n_{tr}}$. Uniform bounds are therefore needed to control finite sample error as we cannot directly apply concentration inequalities, as is done in the proof of (Garg et al., 2020, Lemma 3), since we do not have independence of the terms appearing in the empirical sums. We nonetheless prove a similar result in the following theorem.\nTheorem 5.1 (Ratio Estimation Error Bound). Let $\\delta \\in (0,1)$ and $\\mathcal{F} := {x \\to r^T f_{\\theta}(x), (r, \\theta) \\in \\mathcal{R} \\times \\Theta }$. Under Assumptions 5.1-5.2, there exist constants L > 0, B > 0 such that with probability at least 1 \u2013 \u03b4:\n$|| \\hat{r}_{n_{te}} - r^* ||_2 \\leq \\frac{2}{\\mu p_{min}} \\left( \\sqrt{\\frac{4}{n_{te}}} Rad(\\mathcal{F}) + 4B \\sqrt{\\frac{log(4/\\delta)}{n_{te}}} \\right) + \\frac{4L}{\\mu p_{min}} \\mathbb{E} [|| \\hat{\\theta} - \\theta^* ||^2 ]$.\nHere, $p_{min} = \\min_y p(y)$ and\n$Rad(\\mathcal{F}) = \\frac{1}{\\sqrt{n_{tr}}} \\mathbb{E}_{\\sigma_1, ..., \\sigma_{n_{tr}}} \\sup_{(r,\\theta) \\in \\mathcal{R} \\times \\Theta} \\left| \\sum_{i=1}^{n_{tr}} \\sigma_i r^T f_{\\theta}(x_i) \\right|$,\nwhere $\\sigma_1, ..., \\sigma_{n_{tr}}$ are Rademacher variables uniformly chosen from ${-1,1}$."}, {"title": "CONCLUSIONS AND LIMITATIONS", "content": "We propose VRLS to address label shift in distributed learning. Paired with IW-ERM, VRLS improves intra- and inter-node label shifts in multi-node settings. Empirically, VRLS consistently outperforms MLLS-based baselines, and IW-ERM with VRLS exceeds all multi-node learning baselines. Theoretical bounds further strengthen our method's foundation. Future work will explore estimating ratios by relaxing the strict class-conditional assumption and optimizing IW-ERM to reduce time complexity while ensuring scalability and practicality in real-world distributed learning."}, {"title": "ETHICS STATEMENT", "content": "No ethical approval was needed as no human subjects were involved. All authors fully support the content and findings."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "We ensured reproducibility with publicly available datasets (MNIST, CIFAR-10) and standard models (e.g., ResNet-18). Links to datasets, code, and configurations will be provided upon camera-ready submission. Experiments were run on NVIDIA 3090, A100 GPUs, and Google Colab, with average results and variances reported across multiple trials."}, {"title": "COMPLEXITY ANALYSIS", "content": "In our algorithm, the ratio estimation is performed once in parallel before the IW-ERM step.\nIn the experiments, we used a simple network to estimate the ratios in advance, which required significantly less computational effort compared to training the global model. Although IW-ERM with VRLS introduces additional computational complexity compared to the baseline FedAvg, it results in substantial improvements in overall generalization, particularly under challenging label shift conditions."}, {"title": "LIMITATIONS", "content": "The distribution shifts observed in real-world data are often not fully captured by the label shift or relaxed distribution shift assumptions. In our experiments, we applied mild test data augmentation to approximate the relaxed label shift and manage ratio estimation errors for both the baselines and our method. However, the label shift assumption remains overly restrictive, and the relaxed label shift lacks robust empirical validation in practical scenarios.\nAdditionally, IW-ERM's parameter estimation relies on local predictors at each client, which limits its scalability. In practice, a simpler global predictor could be sufficient for parameter estimation and IW-ERM training. Future research could explore VRLS variants capable of effectively handling more complex distribution shifts in challenging datasets, such as CIFAR-10.1 (Recht et al., 2018; Torralba et al., 2008), as suggested in (Garg et al., 2023)."}, {"title": "EXPERIMENTAL DETAILS", "content": "In single-client experiments, a simple MLP without dropout is used as the predictor for MNIST, and ResNet-18 for CIFAR-10.\nFor experiments in a federated learning setting, both MNIST (LeCun et al., 1998) and Fashion MNIST (Xiao et al., 2017) datasets are employed, each containing 60,000 training samples and 10,000 test samples, with each sample being a 28 by 28 pixel grayscale image. The CIFAR-10 dataset (Krizhevsky) comprises 60,000 colored images, sized 32 by 32 pixels, spread across 10 classes with 6,000 images per class; it is divided into 50,000 training images and 10,000 test images. In this setting, the objective is to minimize the cross-entropy loss. Stochastic gradients for each client are calculated with a batch size of 64 and aggregated on the server using the Adam optimizer. LeNet is used for experiments on MNIST and Fashion MNIST with a learning rate of 0.001 and a weight decay of 1 \u00d7 10-6. For CIFAR-10, ResNet-18 is employed with a learning rate of 0.0001 and a weight decay of 0.0001. Three independent runs are implemented for 5-client experiments on Fashion MNIST and CIFAR-10, while for 10 clients, one run is conducted on CIFAR-10. The regularization coefficient ( in Equation (4) is set to 1 for all experiments. All experiments are performed using a single GPU on an internal cluster and Colab.\nImportantly, the training of the predictor for ratio estimation on both the baseline MLLS and our VRLS is executed with identical hyperparameters and epochs for CIFAR-10 and Fashion MNIST. The training is halted once the classification loss reaches a predefined threshold on MNIST."}, {"title": "RELAXED LABEL SHIFT EXPERIMENTS", "content": "In conventional label shift, it is assumed that $p(x|y)$ remains unchanged across training and test data. However, this assumption is often too strong for real-world applications, such as in healthcare, where different hospitals may use varying equipment, leading to shifts in $p(x | y)$ even with the same labels (Rajendran et al., 2023). Relaxed label shift loosens this assumption by allowing small changes in the conditional distribution (Garg et al., 2023; Luo & Ren, 2022).\nTo formalize this, we use the distributional distance $D$ and a relaxation parameter $\\epsilon > 0$, as defined by Garg et al. (2023): $\\max_y D (P_{tr}(x | y), P_{te} (x | y)) \\leq \\epsilon$. This allows for slight differences in feature distributions between training and testing, capturing a more realistic scenario where the conditional distribution is not strictly invariant.\nIn our case, visual inspection suggests that the differences between temporally distinct datasets, such as CIFAR-10 and CIFAR-10.1_v6 (Torralba et al., 2008; Recht et al., 2018), may not meet the assumption of a small $\\epsilon$. To address this, we instead simulate controlled shifts using test data augmentation, allowing us to regulate the degree of relaxation, following the approach outlined in Garg et al. (2023)."}, {"title": "ADDITIONAL EXPERIMENTS", "content": "In this section, we provide supplementary results, visualizations of accuracy across clients and tables showing dataset distribution in FL setting and relaxed label shift."}, {"title": "ALGORITHMIC DESCRIPTION", "content": "# Split the training dataset on each node\ntrainsets = target_shift.split_dataset(trainset.data, trainset.targets,\nnode_label_dist_train, transform=transform_train)\n# Split the test dataset on each node\ntestsets = target_shift.split_dataset(testset.data, testset.targets,\nnode_label_dist_test, transform=transform_test)\n# Initialize K local models (nets) for each node\nnets = [initialize_model() for _ in range(node_num)]\n# Initialize the estimator for each local model\nestimators = [LS_RatioModel(nets[k]) for k in range(node_num)]\n# Initialize tensors to store the estimated ratios, values, and marginal\nvalues for each pair of nodes.\nestimated_ratios = torch.zeros(node_num, node_num, nclass)\nestimated_values = torch.zeros(node_num, node_num, nclass)\nmarginal_values = torch.zeros(node_num, nclass)\n# Phase 1: Compute the estimated ratios for each node pair (k, j)\nfor k in range(node_num):\nfor j in range(node_num):\n# Perform test on node k using node j's testset\n estimated_ratios[k, j] = estimators[k](testsets[j].data.cpu().\nnumpy())\n# Phase 2: Compute the marginal values on each node's training set\nfor i, trainset in enumerate(trainsets):\n marginal_values[i] = marginal(trainset.targets)\n# Phase 3: Compute the final estimated values for each node\nfor k in range(node_num):\nfor j in range(node_num):\n estimated_values[k, j] = marginal_values[j] * estimated_ratios[k,\nj]\n# Aggregate the estimated values across nodes\naggregated_values = torch.sum(estimated_values, dim=1)\n# Compute the final ratios for each node\nratios = (aggregated_values / marginal_values).to(args.device)\nListing 1: Our VRLS in distributed learning. It is the implementation of Algorithm 2"}]}